{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab9f55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(r\"D:\\Vscode\\Self\\Data Science\\Book Notes\\IntroDS\\23127538\\src\")\n",
    "\n",
    "\n",
    "from config import START_ID, END_ID, START_YEAR_MONTH, END_YEAR_MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aae18841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   arxiv_id              5000 non-null   float64\n",
      " 1   success               5000 non-null   bool   \n",
      " 2   runtime_s             5000 non-null   float64\n",
      " 3   references_count      5000 non-null   int64  \n",
      " 4   mem_before_mb         5000 non-null   float64\n",
      " 5   mem_after_mb          5000 non-null   float64\n",
      " 6   mem_max_mb            5000 non-null   float64\n",
      " 7   mem_avg_mb            5000 non-null   float64\n",
      " 8   size_before_mb        5000 non-null   float64\n",
      " 9   size_after_mb         5000 non-null   float64\n",
      " 10  disk_max_mb           5000 non-null   float64\n",
      " 11  final_output_size_mb  5000 non-null   float64\n",
      "dtypes: bool(1), float64(10), int64(1)\n",
      "memory usage: 434.7 KB\n",
      "None\n",
      "\n",
      "Column: runtime_s\n",
      "            count       mean  median        std  min    max\n",
      "runtime_s  5000.0  21.409996  14.495  36.581555  9.0  970.3\n",
      "\n",
      "Column: size_before_mb\n",
      "                 count      mean    median        std  min         max\n",
      "size_before_mb  5000.0  7.425313  1.918974  17.746215  0.0  539.729014\n",
      "\n",
      "Column: size_after_mb\n",
      "                count      mean    median       std  min         max\n",
      "size_after_mb  5000.0  0.990282  0.235508  6.070182  0.0  250.115962\n",
      "\n",
      "Column: mem_max_mb\n",
      "             count       mean     median       std        min        max\n",
      "mem_max_mb  5000.0  36.677686  37.482422  5.706315  20.867188  46.640625\n",
      "\n",
      "Column: mem_avg_mb\n",
      "             count       mean     median       std        min        max\n",
      "mem_avg_mb  5000.0  36.453876  37.162083  5.707081  19.929755  46.580468\n",
      "\n",
      "Column: disk_max_mb\n",
      "              count         mean       median          std       min  \\\n",
      "disk_max_mb  5000.0  2489.283866  2399.179005  1545.663852  0.577949   \n",
      "\n",
      "                     max  \n",
      "disk_max_mb  5068.935671  \n",
      "\n",
      "Column: final_output_size_mb\n",
      "                       count         mean       median          std       min  \\\n",
      "final_output_size_mb  5000.0  2486.064455  2397.793337  1546.062372  0.436975   \n",
      "\n",
      "                              max  \n",
      "final_output_size_mb  5059.692628  \n",
      "\n",
      "Column: references_count\n",
      "                   count     mean  median        std  min    max\n",
      "references_count  5000.0  18.7656    12.0  23.109917  0.0  357.0\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"D:\\Vscode\\Self\\Data Science\\Book Notes\\IntroDS\\23127538\\stats\\stats.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "bytes_cols = {\n",
    "    \"mem_before_rss\": \"mem_before_mb\",\n",
    "    \"mem_after_rss\": \"mem_after_mb\",\n",
    "    \"mem_max_rss\": \"mem_max_mb\",\n",
    "    \"mem_avg_rss\": \"mem_avg_mb\",\n",
    "    \"size_before_bytes\": \"size_before_mb\",\n",
    "    \"size_after_bytes\": \"size_after_mb\",\n",
    "    \"disk_max_bytes\": \"disk_max_mb\",\n",
    "    \"final_output_size_bytes\": \"final_output_size_mb\"\n",
    "}\n",
    "\n",
    "for old_col, new_col in bytes_cols.items():\n",
    "    if old_col in df.columns:\n",
    "        df[new_col] = df[old_col] / (1024 * 1024)  # bytes â†’ MB\n",
    "        df.drop(columns=[old_col], inplace=True)\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "cols = [\n",
    "    \"runtime_s\", \"size_before_mb\", \"size_after_mb\",\n",
    "    \"mem_max_mb\", \"mem_avg_mb\", \"disk_max_mb\",\n",
    "    \"final_output_size_mb\", \"references_count\"\n",
    "]\n",
    "\n",
    "for c in cols:\n",
    "    if c in df.columns:\n",
    "        print(f\"\\nColumn: {c}\")\n",
    "        print(df[c].agg(['count','mean','median','std','min','max']).to_frame().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eed6e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUCCESS METRICS ===\n",
      "Total papers: 5000\n",
      "Success: 4972\n",
      "Failed: 28\n",
      "Success rate: 99.44%\n",
      "\n",
      "=== RUNTIME METRICS ===\n",
      "Total runtime (seconds): 107049.98\n",
      "Total runtime (hours): 29.74 h\n",
      "Average runtime per paper: 21.41 s\n",
      "Average runtime per SUCCESS paper: 20.62 s\n",
      "Min runtime: 9.00 s\n",
      "Max runtime: 970.30 s\n",
      "\n",
      "=== MEMORY FOOTPRINT ===\n",
      "Maximum RAM used (MB): 46.64\n",
      "Average RAM consumption (MB): 36.45\n",
      "Minimum RAM consumption (MB): 19.93\n",
      "\n",
      "Maximum disk storage required (MB): 5068.94\n",
      "Average disk storage used (MB): 2489.28\n",
      "\n",
      "Final output storage size (MAX MB): 5059.69\n",
      "Final output storage size (AVG MB): 2486.06\n",
      "\n",
      "=== REFERENCES STATISTICS ===\n",
      "Average references per paper: 18.77\n",
      "Min references: 0\n",
      "Max references: 357\n"
     ]
    }
   ],
   "source": [
    "# ========== SUCCESS METRICS ==========\n",
    "total = len(df)\n",
    "num_success = df[\"success\"].sum()\n",
    "num_failed = total - num_success\n",
    "success_rate = num_success / total * 100\n",
    "\n",
    "print(\"=== SUCCESS METRICS ===\")\n",
    "print(\"Total papers:\", total)\n",
    "print(\"Success:\", num_success)\n",
    "print(\"Failed:\", num_failed)\n",
    "print(f\"Success rate: {success_rate:.2f}%\\n\")\n",
    "\n",
    "\n",
    "# ========== RUNTIME METRICS ==========\n",
    "total_runtime = df[\"runtime_s\"].sum()\n",
    "avg_runtime = df[\"runtime_s\"].mean()\n",
    "avg_runtime_success_only = df[df[\"success\"]==True][\"runtime_s\"].mean()\n",
    "min_runtime = df[\"runtime_s\"].min()\n",
    "max_runtime = df[\"runtime_s\"].max()\n",
    "\n",
    "print(\"=== RUNTIME METRICS ===\")\n",
    "print(f\"Total runtime (seconds): {total_runtime:.2f}\")\n",
    "print(f\"Total runtime (hours): {total_runtime/3600:.2f} h\")\n",
    "print(f\"Average runtime per paper: {avg_runtime:.2f} s\")\n",
    "print(f\"Average runtime per SUCCESS paper: {avg_runtime_success_only:.2f} s\")\n",
    "print(f\"Min runtime: {min_runtime:.2f} s\")\n",
    "print(f\"Max runtime: {max_runtime:.2f} s\\n\")\n",
    "\n",
    "\n",
    "# ========== MEMORY FOOTPRINT ==========\n",
    "max_ram_used = df[\"mem_max_mb\"].max()\n",
    "avg_ram_consumption = df[\"mem_avg_mb\"].mean()\n",
    "min_ram = df[\"mem_avg_mb\"].min()\n",
    "\n",
    "max_disk_storage = df[\"disk_max_mb\"].max()\n",
    "avg_disk_storage = df[\"disk_max_mb\"].mean()\n",
    "\n",
    "final_output_size_max = df[\"final_output_size_mb\"].max()\n",
    "final_output_size_mean = df[\"final_output_size_mb\"].mean()\n",
    "\n",
    "print(\"=== MEMORY FOOTPRINT ===\")\n",
    "print(f\"Maximum RAM used (MB): {max_ram_used:.2f}\")\n",
    "print(f\"Average RAM consumption (MB): {avg_ram_consumption:.2f}\")\n",
    "print(f\"Minimum RAM consumption (MB): {min_ram:.2f}\")\n",
    "\n",
    "print(f\"\\nMaximum disk storage required (MB): {max_disk_storage:.2f}\")\n",
    "print(f\"Average disk storage used (MB): {avg_disk_storage:.2f}\")\n",
    "\n",
    "print(f\"\\nFinal output storage size (MAX MB): {final_output_size_max:.2f}\")\n",
    "print(f\"Final output storage size (AVG MB): {final_output_size_mean:.2f}\\n\")\n",
    "\n",
    "\n",
    "# ========== REFERENCES METRICS ==========\n",
    "avg_refs = df[\"references_count\"].mean()\n",
    "min_refs = df[\"references_count\"].min()\n",
    "max_refs = df[\"references_count\"].max()\n",
    "\n",
    "print(\"=== REFERENCES STATISTICS ===\")\n",
    "print(f\"Average references per paper: {avg_refs:.2f}\")\n",
    "print(f\"Min references: {min_refs}\")\n",
    "print(f\"Max references: {max_refs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8f8d722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 10\n",
      "=== TOTAL RUNTIME PER 10%-PAPER GROUP (BY ARXIV ID) ===\n",
      "2307.11657 - 2307.12156: 10422.35 s\n",
      "2307.12157 - 2307.12656: 12192.32 s\n",
      "2307.12657 - 2307.13156: 11508.74 s\n",
      "2307.13157 - 2307.13656: 9634.45 s\n",
      "2307.13657 - 2307.14156: 9491.83 s\n",
      "2307.14157 - 2307.14656: 17135.57 s\n",
      "2307.14657 - 2307.15156: 8643.24 s\n",
      "2307.15157 - 2307.15656: 9498.67 s\n",
      "2307.15657 - 2307.16156: 9239.33 s\n",
      "2307.16157 - 2307.16656: 9283.48 s\n",
      "\n",
      "=== GROUP WITH SMALLEST TOTAL RUNTIME ===\n",
      "Group 7 (2307.14657 - 2307.15156): 8643.24 s\n"
     ]
    }
   ],
   "source": [
    "START_FLOAT = float(f\"{START_YEAR_MONTH}.{START_ID}\")\n",
    "END_FLOAT   = float(f\"{END_YEAR_MONTH}.{END_ID}\")\n",
    "\n",
    "percent = 0.1 \n",
    "\n",
    "df_range = df[(df[\"arxiv_id\"] >= START_FLOAT) & (df[\"arxiv_id\"] <= END_FLOAT)].copy()\n",
    "\n",
    "# Safety sort\n",
    "df_range = df_range.sort_values(\"arxiv_id\").reset_index(drop=True)\n",
    "\n",
    "# group size = 10%\n",
    "group_size = int(len(df_range) * percent)\n",
    "num_groups = int(1 / percent)\n",
    "print(group_size, num_groups)\n",
    "\n",
    "group_runtimes = []\n",
    "\n",
    "print(\"=== TOTAL RUNTIME PER 10%-PAPER GROUP (BY ARXIV ID) ===\")\n",
    "\n",
    "for i in range(num_groups):\n",
    "    start_idx = i * group_size\n",
    "    end_idx = start_idx + group_size\n",
    "    \n",
    "    group_df = df_range.iloc[start_idx:end_idx]\n",
    "\n",
    "    id_start = str(group_df[\"arxiv_id\"].iloc[0])\n",
    "    id_end   = str(group_df[\"arxiv_id\"].iloc[-1])\n",
    "\n",
    "    total_runtime = group_df[\"runtime_s\"].sum()\n",
    "\n",
    "    group_runtimes.append({\n",
    "        \"group_index\": i + 1,\n",
    "        \"arxiv_start\": id_start,\n",
    "        \"arxiv_end\": id_end,\n",
    "        \"total_runtime_s\": total_runtime\n",
    "    })\n",
    "\n",
    "    print(f\"{id_start} - {id_end}: {total_runtime:.2f} s\")\n",
    "\n",
    "\n",
    "# ====== GROUP WITH SMALLEST TOTAL RUNTIME ======\n",
    "min_group = min(group_runtimes, key=lambda x: x[\"total_runtime_s\"])\n",
    "\n",
    "print(\"\\n=== GROUP WITH SMALLEST TOTAL RUNTIME ===\")\n",
    "print(f\"Group {min_group['group_index']} \"\n",
    "      f\"({min_group['arxiv_start']} - {min_group['arxiv_end']}): \"\n",
    "      f\"{min_group['total_runtime_s']:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae86862",
   "metadata": {},
   "source": [
    "Okay, so I will choose 14657 - 15156 to run 10% as the teacher's new requirement.\n",
    "\n",
    "Maybe I will try to run on Colab.\n",
    "\n",
    "But for the performance report, we can easily that just get the statistics from 14657 -  15156."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9014aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year_run_time = float(f\"{START_YEAR_MONTH}.{14657}\")\n",
    "end_year_run_time  = float(f\"{END_YEAR_MONTH}.{15156}\")\n",
    "\n",
    "df_range_min = df[(df[\"arxiv_id\"] >= start_year_run_time) & (df[\"arxiv_id\"] <= end_year_run_time)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "548b544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 3000 to 3499\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   arxiv_id              500 non-null    float64\n",
      " 1   success               500 non-null    bool   \n",
      " 2   runtime_s             500 non-null    float64\n",
      " 3   references_count      500 non-null    int64  \n",
      " 4   mem_before_mb         500 non-null    float64\n",
      " 5   mem_after_mb          500 non-null    float64\n",
      " 6   mem_max_mb            500 non-null    float64\n",
      " 7   mem_avg_mb            500 non-null    float64\n",
      " 8   size_before_mb        500 non-null    float64\n",
      " 9   size_after_mb         500 non-null    float64\n",
      " 10  disk_max_mb           500 non-null    float64\n",
      " 11  final_output_size_mb  500 non-null    float64\n",
      "dtypes: bool(1), float64(10), int64(1)\n",
      "memory usage: 47.4 KB\n",
      "None\n",
      "\n",
      "Column: runtime_s\n",
      "           count      mean  median        std  min     max\n",
      "runtime_s  500.0  17.28648  13.975  13.374289  9.0  128.62\n",
      "\n",
      "Column: size_before_mb\n",
      "                count     mean    median        std      min         max\n",
      "size_before_mb  500.0  7.14059  1.792984  16.752587  0.00057  251.403922\n",
      "\n",
      "Column: size_after_mb\n",
      "               count      mean   median        std      min         max\n",
      "size_after_mb  500.0  1.658025  0.24563  12.006337  0.00057  250.115962\n",
      "\n",
      "Column: mem_max_mb\n",
      "            count       mean     median       std        min        max\n",
      "mem_max_mb  500.0  35.714336  37.755859  4.173273  28.992188  41.292969\n",
      "\n",
      "Column: mem_avg_mb\n",
      "            count       mean     median       std        min        max\n",
      "mem_avg_mb  500.0  35.440346  37.541504  4.159016  28.347656  41.039062\n",
      "\n",
      "Column: disk_max_mb\n",
      "             count         mean       median         std          min  \\\n",
      "disk_max_mb  500.0  3245.089859  3372.756049  303.360262  2775.807744   \n",
      "\n",
      "                     max  \n",
      "disk_max_mb  3622.795523  \n",
      "\n",
      "Column: final_output_size_mb\n",
      "                      count        mean       median         std          min  \\\n",
      "final_output_size_mb  500.0  3242.49733  3363.603966  303.335529  2775.813128   \n",
      "\n",
      "                              max  \n",
      "final_output_size_mb  3609.849547  \n",
      "\n",
      "Column: references_count\n",
      "                  count    mean  median        std  min    max\n",
      "references_count  500.0  21.066    14.0  25.491907  0.0  291.0\n"
     ]
    }
   ],
   "source": [
    "print(df_range_min.info())\n",
    "\n",
    "cols = [\n",
    "    \"runtime_s\", \"size_before_mb\", \"size_after_mb\",\n",
    "    \"mem_max_mb\", \"mem_avg_mb\", \"disk_max_mb\",\n",
    "    \"final_output_size_mb\", \"references_count\"\n",
    "]\n",
    "\n",
    "for c in cols:\n",
    "    if c in df_range_min.columns:\n",
    "        print(f\"\\nColumn: {c}\")\n",
    "        print(df_range_min[c].agg(['count','mean','median','std','min','max']).to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04c68be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUCCESS METRICS ===\n",
      "Total papers: 500\n",
      "Success: 500\n",
      "Failed: 0\n",
      "Success rate: 100.00%\n",
      "\n",
      "=== RUNTIME METRICS ===\n",
      "Total runtime (seconds): 8643.24\n",
      "Total runtime (hours): 2.40 h\n",
      "Average runtime per paper: 17.29 s\n",
      "Average runtime per SUCCESS paper: 17.29 s\n",
      "Min runtime: 9.00 s\n",
      "Max runtime: 128.62 s\n",
      "\n",
      "=== MEMORY FOOTPRINT ===\n",
      "Maximum RAM used (MB): 41.29\n",
      "Average RAM consumption (MB): 35.44\n",
      "Minimum RAM consumption (MB): 28.35\n",
      "\n",
      "Maximum disk storage required (MB): 3622.80\n",
      "Average disk storage used (MB): 3245.09\n",
      "\n",
      "Final output storage size (MAX MB): 3609.85\n",
      "Final output storage size (AVG MB): 3242.50\n",
      "\n",
      "=== REFERENCES STATISTICS ===\n",
      "Average references per paper: 21.07\n",
      "Min references: 0\n",
      "Max references: 291\n"
     ]
    }
   ],
   "source": [
    "# ========== SUCCESS METRICS ==========\n",
    "total = len(df_range_min)\n",
    "num_success = df_range_min[\"success\"].sum()\n",
    "num_failed = total - num_success\n",
    "success_rate = num_success / total * 100\n",
    "\n",
    "print(\"=== SUCCESS METRICS ===\")\n",
    "print(\"Total papers:\", total)\n",
    "print(\"Success:\", num_success)\n",
    "print(\"Failed:\", num_failed)\n",
    "print(f\"Success rate: {success_rate:.2f}%\\n\")\n",
    "\n",
    "\n",
    "# ========== RUNTIME METRICS ==========\n",
    "total_runtime = df_range_min[\"runtime_s\"].sum()\n",
    "avg_runtime = df_range_min[\"runtime_s\"].mean()\n",
    "avg_runtime_success_only = df_range_min[df_range_min[\"success\"]==True][\"runtime_s\"].mean()\n",
    "min_runtime = df_range_min[\"runtime_s\"].min()\n",
    "max_runtime = df_range_min[\"runtime_s\"].max()\n",
    "\n",
    "print(\"=== RUNTIME METRICS ===\")\n",
    "print(f\"Total runtime (seconds): {total_runtime:.2f}\")\n",
    "print(f\"Total runtime (hours): {total_runtime/3600:.2f} h\")\n",
    "print(f\"Average runtime per paper: {avg_runtime:.2f} s\")\n",
    "print(f\"Average runtime per SUCCESS paper: {avg_runtime_success_only:.2f} s\")\n",
    "print(f\"Min runtime: {min_runtime:.2f} s\")\n",
    "print(f\"Max runtime: {max_runtime:.2f} s\\n\")\n",
    "\n",
    "\n",
    "# ========== MEMORY FOOTPRINT ==========\n",
    "max_ram_used = df_range_min[\"mem_max_mb\"].max()\n",
    "avg_ram_consumption = df_range_min[\"mem_avg_mb\"].mean()\n",
    "min_ram = df_range_min[\"mem_avg_mb\"].min()\n",
    "\n",
    "max_disk_storage = df_range_min[\"disk_max_mb\"].max()\n",
    "avg_disk_storage = df_range_min[\"disk_max_mb\"].mean()\n",
    "\n",
    "final_output_size_max = df_range_min[\"final_output_size_mb\"].max()\n",
    "final_output_size_mean = df_range_min[\"final_output_size_mb\"].mean()\n",
    "\n",
    "print(\"=== MEMORY FOOTPRINT ===\")\n",
    "print(f\"Maximum RAM used (MB): {max_ram_used:.2f}\")\n",
    "print(f\"Average RAM consumption (MB): {avg_ram_consumption:.2f}\")\n",
    "print(f\"Minimum RAM consumption (MB): {min_ram:.2f}\")\n",
    "\n",
    "print(f\"\\nMaximum disk storage required (MB): {max_disk_storage:.2f}\")\n",
    "print(f\"Average disk storage used (MB): {avg_disk_storage:.2f}\")\n",
    "\n",
    "print(f\"\\nFinal output storage size (MAX MB): {final_output_size_max:.2f}\")\n",
    "print(f\"Final output storage size (AVG MB): {final_output_size_mean:.2f}\\n\")\n",
    "\n",
    "\n",
    "# ========== REFERENCES METRICS ==========\n",
    "avg_refs = df_range_min[\"references_count\"].mean()\n",
    "min_refs = df_range_min[\"references_count\"].min()\n",
    "max_refs = df_range_min[\"references_count\"].max()\n",
    "\n",
    "print(\"=== REFERENCES STATISTICS ===\")\n",
    "print(f\"Average references per paper: {avg_refs:.2f}\")\n",
    "print(f\"Min references: {min_refs}\")\n",
    "print(f\"Max references: {max_refs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
