\section{Experimental Results}\label{sec:results}
    \subsection{General Results}
        The basic ResSAN model is used to determine reference results which our expanded model can be compared to as it is structurally similar to ResLAN but does not possess the Lidar adaptive components of it. Further, we compare with the full-size PackNet-SAN and the unmodified NLSPN architecture. 
        As it can be seen from Tab.\,\ref{tab:sota-results}, our LiDAR-adaptive ResLAN achieves competitive performance compared to state-of-the-art standard depth completion methods, which are specialized to the unfiltered 64-beam-LiDAR. The performance differences are in the range of a few centimetres in terms of MAE, which is acceptable given the practical advantage that ResLAN can generalize to different beam patterns as will be shown below.

        Furthermore, we compared the architectures for a set of three different input types that contained 64, 32 or 16 LiDAR channels using both filter types on the metrics from the KITTI benchmark. The NLSPN model was trained for the standard depth completion task and then evaluated with different input data. As for the ResSAN models, we trained one model for each input type and tested it for the corresponding one which serve serve as the \emph{Baseline} in Tab.\,\ref{tab:overall-results}. Our ResLAN model was jointly trained for all three settings. As listed in Tab.\,\ref{tab:overall-results}, the ResLAN models outperform the challenging baseline in all metrics for FOV filtering and all but one for sparse filtering. This implies that our LiDAR adaptive model is able to outperform dedicated models in case of very sparse input depth. Fig.\,\ref{fig:comp-plot} shows this is indeed the case for 32 and even more for 16 channels. For FOV-filtered inputs with 16 channels, the ResLAN exhibits approx. $10\%$ smaller MAE than the baseline. As for the NLSPN, it becomes apparent that it is not capable of generalizing to other input types since it shows clearly worse results. The difference is especially pronounced for the FOV filtering where on average more than every fourth predicted pixel is more than $25 \%$ deviating from the ground truth\,($\delta_{1.25}$). Therefore, using a weight-adapting network in combination with differently filtered input depths allows us to train models that outperform their non-adaptive counterparts.

        \begin{table}[]
            \centering
    	    \small
            \vspace{0.4cm}
            \caption{\textbf{Depth estimation result for standard depth completion} when the ResSAN model was only trained for 64 channels and the ResLAN model for multiple tasks. The PackNet-SAN and NLSPN models were trained with the setup that was also used for our model architecture.}
            \footnotesize
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{@{}lrrrrl@{}}
            \toprule
            \multicolumn{6}{c}{\textbf{Standard LiDAR Depth Completion}}                                                                                                                         \\ \midrule
            \multicolumn{1}{l|}{Method}          & RMSE $\downarrow$            & MAE  $\downarrow$            & iRMSE $\downarrow$             & iMAE $\downarrow$ & $\delta_{1.25}$ $\uparrow$ \\
            \multicolumn{1}{l|}{}                & \multicolumn{1}{l}{{[}mm{]}} & \multicolumn{1}{l}{{[}mm{]}} & \multicolumn{1}{l}{{[}1/km{]}} & {[}1/km{]}        &                            \\ \midrule
            \multicolumn{1}{l|}{PackNet-SAN}     &  914                            &  298                            &  2.78                              &  1.4                 &  99.65 \%                          \\
            \multicolumn{1}{l|}{NLSPN}           &  \textbf{889}                            &   \textbf{263}                           &  \textbf{2.62}                              &   \textbf{1.3}                &   \textbf{99.61} \%                         \\ \midrule
            \multicolumn{1}{l|}{ResSAN (Ours)}   & 948                             &  275                            &  2.75                              &    1.4               &   99.58 \%                         \\
            \multicolumn{1}{l|}{ResLAN (Ours)} &   969                           &  283                            &   2.83                             &   1.4                &  99.56 \%                          \\ \bottomrule
            \end{tabular}
            \vspace{0.2cm}
            \label{tab:sota-results}
        \end{table}

        \begin{table}[]
    	    \centering
    	    \small
    	    \caption{\textbf{Depth estimation results of the two baseline setups and the explicit and implicit ResSAN} when evaluated on a combination of 16, 32 and 64 channel depth inputs. Please note that Specialist Methods need to train three specialized networks, one for each of the three types of inputs while our method only uses one network.}
            \footnotesize
            \setlength{\tabcolsep}{4.8pt}
            \begin{tabular}{@{}lrrrrl@{}}
                \toprule
                \multicolumn{6}{c}{\textbf{Sparse Channel Filter}}                                                                                                                                  \\ \midrule
                \multicolumn{1}{l|}{Method}        & RMSE $\downarrow$            & MAE  $\downarrow$            & iRMSE $\downarrow$             & iMAE $\downarrow$ & $\delta_{1.25}$ $\uparrow$  \\
                \multicolumn{1}{l|}{}              & \multicolumn{1}{l}{{[}mm{]}} & \multicolumn{1}{l}{{[}mm{]}} & \multicolumn{1}{l}{{[}1/km{]}} & {[}1/km{]}        &                             \\ \midrule
                \multicolumn{1}{l|}{NLSPN}         &  1396                            &  437                            & 5.54                               &  2.2                 &  98.82 \%                           \\
                \multicolumn{1}{l|}{Baseline}      & \textbf{1207}                             &  381                            & 4.41                               &  1.8                 &  \textbf{99.37} \%                           \\
                \multicolumn{1}{l|}{ResLAN (Ours)} &  1215                            &  \textbf{378}                            &  \textbf{4.27}                              &  \textbf{1.7}                 &  99.31 \%                           \\ \toprule
                \multicolumn{6}{c}{\textbf{Field-of-View Filter}}                                                                                                                                   \\ \midrule
                \multicolumn{1}{l|}{Method}        & RMSE $\downarrow$            & MAE  $\downarrow$            & iRMSE $\downarrow$             & iMAE $\downarrow$ & $\delta_{1.25}$ $\uparrow$ \\
                \multicolumn{1}{l|}{}              & \multicolumn{1}{l}{{[}mm{]}} & \multicolumn{1}{l}{{[}mm{]}} & \multicolumn{1}{l}{{[}1/km{]}} & {[}1/km{]}        &                             \\ \midrule
                \multicolumn{1}{l|}{NLSPN}         &  2738                            &  1702                            & 12.3                              &  4.3                 &  74.69 \%                           \\
                \multicolumn{1}{l|}{Baseline}      &  1556                            &  525                            &  6.8                              &  3.0                 & 98.14 \%                            \\
                \multicolumn{1}{l|}{ResLAN (Ours)} &  \textbf{1548}                            &  \textbf{519}                            &  \textbf{6.44}                              &  \textbf{2.8}                 & \textbf{98.52 \%}                            \\ \bottomrule
            \end{tabular}
            \label{tab:overall-results}
        \end{table}

        
        
        % Figure environment removed
        
        % Figure environment removed

    \subsection{Filter Effects}
        Comparing the effect of the two different types of depth input filters on the model performance, it becomes apparent that FOV filtering is the more challenging task. In that setting, reducing LiDAR channels is more detrimental to the performance than sparse filtering as it creates regions where no depth information is available. Effectively, the model is forced to perform depth prediction in these regions. These effects are highlighted in the depth images in Fig.\,\ref{fig:dense-maps} where the effect of a 16-channel sparse depth filter and a 16-channel FOV can be compared.

    \subsection{Generalization Capabilities}
        We trained three models for both filter types eaach, so the combinations and number of filtered depth inputs they receive are different. This serves the purpose of testing the generalization capabilities of the ResLAN architecture as well as the robustness to different filter settings. After training, the models were evaluated for the depth input settings they were trained for, as well as for ones they weren't exposed to. Overall, ResLAN shows good generalization capabilities. As one can gather from Fig.\,\ref{fig:explicit-comp} and Fig.\,\ref{fig:implicit-comp}, the consequences of slightly varying sets of input depth settings are limited. The most considerable deviations can be seen when the model is tasked to extrapolate. For instance, the model $\{64, 32, 16\}$ shows a noticeably higher MAE for eight-channel depth inputs than the model that was trained for it. Similar behaviour can be seen for the FOV filtering case as well for the model $\{64, 48, 32\}$ when tasked to generalize for a 16-channel input. There is no such pronounced effect for generalization tasks that lie between two filter settings the model was trained for. At most, it can be observed that models that were trained for a smaller range of filter values perform slightly better than ones that have to cover a wider range. The number of filter settings used in a fixed range does not relevantly influence the model performance, as can be seen, when comparing the two models in Fig.\,\ref{fig:implicit-comp}, which are both trained for a range of 64 to 32 channels but one with three filter settings and the other one with five.
    
    % Figure environment removed
    
    
    % Figure environment removed