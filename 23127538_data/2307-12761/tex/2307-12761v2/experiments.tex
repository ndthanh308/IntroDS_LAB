\section{Experimental Procedure}
    \paragraph{Dataset}
        We train and evaluate our method using the KITTI depth completion dataset\,\cite{geiger_are_2012} with the Eigen split\,\cite{eigen_depth_2014}. Following common practice\,\cite{lee_big_2021}, we apply color jitter, random crop and horizontal flipping to the training inputs. Moreover, the input images are down-sampled to 640x192 pixels to reduce computational load.

    
	\paragraph{Implementation details}
	    We train our models using PyTorch on a single Nvidia Titan Xp GPU with a batch size of 8, using the Adam\,\cite{kingma_adam_2017} optimizer with a learning rate of $10^{-4}$, $\beta_1 = 0.9$, $\beta_2 = 0.999$ and decay of $10^{-2}$. We apply  SILoss\,\cite{eigen_depth_2014}, and for runs including multiple styles of depth input, all types were applied with the same loss weight and number of samples shown. The training schedule is as follows: For the first 10 epochs, we train our model with RGB images only, with the depth encoder, weight adaption and NLSPN being disabled. Then, we fix the RGB-encoder and resume training the complete model using depth inputs for another 10 epochs.
    