\documentclass[9pt,conference]{IEEEtran}
\usepackage{amssymb,amsthm,amsmath,array}
\usepackage{graphicx}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{xspace}
\usepackage[sort&compress, numbers]{natbib}
\usepackage{stmaryrd}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{float}
\usepackage{textcomp}
\usepackage{bbm}
\input{commands.tex}
\input{preambule.tex}
\begin{document}
\title{Implicit Reconstructions from Deformed Projections for CryoET}
\author{\IEEEauthorblockN{
        Vinith Kishore\IEEEauthorrefmark{1}, 
        Valentin Debarnot\IEEEauthorrefmark{1}, and 
        Ivan Dokmani\'{c}\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}
    }
    \IEEEauthorblockA{
        \IEEEauthorrefmark{1} University of Basel.\\
        \IEEEauthorrefmark{2} University of Illinois at Urbana-Champaign.}
}
\maketitle
\begin{abstract}
    Cryo-electron tomography (cryoET) is a technique that captures images of biological samples at different tilts, preserving their native state as much as possible. Along with the partial tilt series and noise, one of the major challenges in estimating the accurate 3D structure of the sample is the deformations in the images incurred during the acquisition. We model these deformations as continuous operators and estimate the unknown 3D volume using implicit neural representations. This framework allows to easily incorporate the deformation and estimate jointly the deformation parameters and the volume using a standard optimization algorithm. This approach doesn't require training data and can benefit from standard prior in the optimization procedure.
\end{abstract}

\section{Introduction}
% Define the cryoET problems and use cases. 
Cryo-Electron Tomography (cryoET) \cite{doerr2017cryo} is an emerging imaging modality used to image biological samples such as cells, tissue, etc. These samples are flash-frozen and imaged using an electron microscope. The process is very similar to cryo Electron Microscopy (cryoEM) which has gained much attention due to its ability to resolve larger bio-molecules on a nanometer scale. Unlike cryoEM, cryoET is used for larger scale samples, where we can almost capture the interaction between the components in situ. In cryoET multiple images of the sample are acquired by tilting the thin frozen sample along its axis, at a discrete set of tilt angles.  Unlike cryoEM, we have a limited number of images to recover the complete information of the structure, this is known as the missing wedge in the Fourier domain, thus making the problem ill-possed. The tilt-series obtained from an unknown volume is defined as: 
\begin{equation}\label{eq:formation_model}
    \yb_m = \boldsymbol{P}(\boldsymbol{R}_{\theta_m}(\boldsymbol{\rho})) + \boldsymbol{\epsilon}_m
\end{equation}
where $\boldsymbol{\rho} \in \mathbbm{R}^{N \times N \times N}$ is the volume density of the sample we are imaging. The 3D-rotation operator $\boldsymbol{R}_{\theta}(\cdot)$ tilts the volume by an angle $\theta$ around a fixed axis, $\boldsymbol{P}: \mathbbm{R}^{N \times N \times N } \mapsto \mathbbm{R}^{N \times N}$ is the projection operator and  $\boldsymbol{\epsilon}$ is the Gaussian noise which accounts for the low dose electron beam. The tilt $\theta_m$ can only vary between -70 and +70 degrees resulting in a \textit{missing wedge} of measurements. 

This model accounts for the image formation case in which there are no mechanical faults or the sample is not affected by the electron beam. However, this is hardly the case in many applications of cryoET. Accounting for these deformations is crucial to obtain a high resolution reconstruction \cite{mastronarde2006fiducial} and can be taken into account by the following forward model:
\begin{equation}
\label{eq:deformation_model}
     \yb_m = \Db_m(\Pb(\Rb_{\theta_m}(\rhob))) + \boldsymbol{\epsilon}_m,
\end{equation}
where $\Db_m$ models deformations appearing in cryoET. Deformations are composed of rigid deformations due to the sample slightly moving between tilts, and local and non-rigid deformations due to the electron beam interacting with the sample. In this paper, we consider independent deformations on the tilt-series.


% \sout{
% The physical effects of the acquisition process on the molecule cannot be accounted for using the Gaussian noise as it changes the internal structure of the sample itself, this can be seen and is not limited to  small movements in certain regions of the sample. Thus in practice to ameliorate such problems, practitioners  use Fiducial markers to align the images in one angle to images from angles close by \cite{mastronarde2006fiducial}. However, a disadvantage of such methods is that they require special sample preparation techniques to make the sample viable for imaging, which might not be feasible for many biological specimens. Thus there have been many attempts at aligning images from one angle to the other using certain properties of the image itself. }


\subsection{Related work}

AreTomo \cite{zheng2022aretomo} is one such approach where patches from images are tracked to account for and correct deformations. Such methods that use patch-based tracking can be useful in many applications but cannot track small-scale deformations that can occur within the patch nor deformations that appear between patches. Our approach is similar to AreTomo with the difference that we track all pixels simultaneously.


Neural fields (or implicit neural networks) represent continuous signals as maps from coordinates to function values \cite{mildenhall2021nerf}. 
Such models have been used extensively in inverse rendering problems \cite{sitzmann2020implicit}. 
% Inverse rendering problems aim to recover the 3D geometry of the scene from its 2D images, and one of the important problems in Computer Graphics. Current advances in using differentiable rendering and implicit neural representations have gained a lot of attention due to their performance. Sirens \cite{sitzmann2020implicit}, and Nerfs \cite{mildenhall2021nerf} are some of the early approaches to using differentiable rendering along with implicit neural networks to recover the geometry from the  2D scene.
Nerfies \cite{park2021nerfies} was proposed in this problem to capture the deformations that vary continuously between scenes. 
Lately, it has also been successfully applied to model the volume density in cryoEM \cite{zhong2021cryodrgn,levy2022cryoai}, obtaining accurate reconstructions even with strong structural heterogeneity and noise. 
This was extended to Scanning Transmission Electron Microscopy \cite{kniesel2022clean}. 
In this paper, we propose to model both the unknown volume and the unknown deformation using neural fields in cryoET. Contrary to \cite{park2021nerfies}, we capture deformations that change randomly between images of the tilt-series.

Recently, \cite{debarnot2022joint} showed that global deformations (shear, rotations, and shifts) in the images can be recovered by appropriately modeling them and estimating the deformation parameters.
In this paper, we employ a similar approach but we model directly the unknown volume using an implicit neural network. We also consider a wider class of deformations.

\subsection{Contributions}
We propose an unsupervised method to jointly reconstruct the volume and the deformation from noisy and deformed tilt-series in cryoET. 
We extend previous work \cite{debarnot2022joint} by considering a rich class of deformation that accurately model cryoET acquisitions. Moreover, our original framework allows a significant gain in computation time and resources, while offering the possibility to be paired with sophisticated priors in order to compensate for the missing wedge.
\def\sc{0.16}
% Figure environment removed
\section{Methods}
 % Descibe the forward model for ideal  cryoET problem and connect to the  extreneous problems encounterd while reading the observations from the electronb microscope.
% Volume pipeline 
We approximate the volume $\rhob$ by an implicit representation $ \Vb(\psib): \R^3 \to \R,$ parameterized by $\psib$. We use an MLP (Multi-Layer Perceptron) with Fourier feature as positional encoding.
Using an implicit representation of the volume allows fast computation of the formation model \eqref{eq:formation_model} using discretization. The same benefit holds for any deformation acting on the coordinate space.

We approximate the deformations $\Db_m$ as:
\begin{equation*}
  \Db(\phib_m) \eqdef \Lb_m(\gammab_m) \Sb(\taub_m) \Rb_{2D}(\alpha_m)
\end{equation*}

where $\Rb_{2D}(\alpha)$ is a 2D rotation operator by angle $\alpha$, $\Sb(\taub)$ is a shift operator with displacement $\taub = (\tau_x, \tau_y)$ and $\Lb(\gammab): \R^2 \to \R^2$ is an implicit representation, parameterized by $\gammab$, which models local deformations
\begin{align*}
    \left(\Lb(\gammab) v\right)(\xb) = v(\xb+\lb(\gammab)(\xb) ), \forall v\in\Cc^0(\R^2), \forall \xb\in\R^2,
\end{align*}
where $\lb(\gammab):\R^2 \to \R^2$ is a continuous operator in each of its output.
% We use the forward model defined in \cite{debarnot2022joint}.
% We incorporate the  deformations in  each  image as an operator which acts on the projected images. The forward model accounting for deformation is given as:
% \begin{equation}
% \label{eq:deformation_model}
%      y_m = \boldsymbol{D}(\boldsymbol{P}(\boldsymbol{R}_{\theta_m}(\boldsymbol{\rho})), \boldsymbol{\phi_m}) + \boldsymbol{\epsilon}
% \end{equation}
% Where, $\boldsymbol{D}(\cdot, \boldsymbol{\phi}_m))$, is the deformation operator, with a parameter $\boldsymbol{\phi}$ to account for randomness from one image to the other. This parameter is split into three: rotations, shifts, and local deformations $\boldsymbol{\phi} = (\alpha,\tau, \gamma(.))$. Where, rotation $\alpha$, accounts for the in-plane rotations of the image, we assume there is no in-plane rotation in the standard forward model. The vector $\tau = (\tau_x, \tau_y)$ accounts for any global shifts in the sample from one observation to another along the tilt series. Finally, $\gamma(.): \mathbbm{R}^{2} \mapsto \mathbbm{R}^{2}$, is a neural network, Which gives the local deformations for the projections. 
To account for randomness in the local deformations, we use as many networks as there are images, as each network learns the local deformation of its image. 
The implicit representations $\Lb_m$ could also be used to learn the inplane roatation and the shift operators, but we observe better performance when explicitly dissociate these three operators. Similar observation has already been made in Nerfies \cite{park2021nerfies}. %They argue that rotation and shifts can be estimated using 3 parameters instead of a complex function. 
Unlike Nerfies, we use separate networks to capture local deformations from one image to the other, as we do not have continuous deformations between them. %However, we define these networks to be much smaller than the one used to estimate the volume.
% We model the volume density with an implicit neural network $\phi: \boldsymbol{R}^2 \mapsto \boldsymbol{R}$. This helps us sample the volume intensities  along the rays of the electron beam easily compared to the  use of standard interpolation techniques. Thus we can formulate the image value at position $\boldsymbol{x} = (x,y)$ when the sample is tilted at angle $\theta$ as : 
% \begin{equation*}
%     \tilde{y}_{\theta}(\boldsymbol{x}) = \int_t \rho(\boldsymbol{R}_{\theta}x + \boldsymbol{d}_{\theta}t)dt 
% \end{equation*}
% Where $\boldsymbol{d}_{\theta}$ is the direction of the parallel beam and the integral is approximated by a sum. 
% For a given set of $M$ observations in the title-series, we have $M + 1$ neural networks and $3m$ free parameters, which as to be estimated. 
We learn the parameters $\{\phib_m = (\gammab_m,\taub_m,\alpha_m)\}_{m=1}^M$ and  $\{\psib_m \}_{m=1}^M$ jointly by minimizing the mean square error between the observations and the estimated tilt-series:
\begin{equation}\label{eq:opt}
    \min_{\{\phib_m\}_{m=1}^M, \{\psib_m\}_{m=1}^M}  \sum_{m=1}^M\|\yb_m - \boldsymbol{D}(\phib_m)(\boldsymbol{P}(\boldsymbol{R}_{\theta_m}(\boldsymbol{\Vb(\psib_m)})) \|_2^2
\end{equation}
Notice that the above formulation allows mini-batch optimization in the pixel space contrary to \cite{debarnot2022joint}.
% It is easy to notice that the deformations recovery need not be unique as the local deformation function has the capacity to learn rotations or shifts. Thus we cannot compare the shifts estimated from the data with known shifts directly, so we need to rely on the reconstructed volume to estimate the efficacy of the model. 
 % Volume reconstruction  without deformation, colume with deformations 



 
 \section{Experiment and Results}
We use the voxelized  M. pneumoniae cell \cite{tegunov2021multi} (dataset DOI on EMPIAR 10.6019/EMPIAR-10499) model to test the recovery capacity of the model when there are deformations present. We simulate the cryoET observation by projecting the volume after rotation along a fixed axis at $M=90$ angles uniformly spaced between $-70$ degrees to $70$ degrees. 
We define the signal to noise ration (SNR) between two signals $\sb, \sb_{\text{true}}\in\R^N$ as 
\begin{equation*}
\SNR(\sb, \sb_{\text{true}}) = 10\log_{10}\left(\frac{\var(\sb)}{\var(\sb_{\text{true}})}\right). 
\end{equation*}
We add Gaussian noise so that the noisy projections have an SNR of 0dB.
% \sout{Note that, for the experiments, SNR is computed before incorporating the deformations.  We experiment at SNRs: $100$ dB (clean image), $10$ dB, $0$dB, -10$dB$.}
In the simulations, the true unknown deformations $\Db_m$ are the composition of a smooth random diffeomorphism  as defined in \cite{ronneberger2015u}, a random shift with maximum $\pm 10\%$ of the image size, and a random in-plane rotation with angle between $\pm 10$ degrees.

%The volume network, deformation networks, and parameters are learned jointly by solving Problem \eqref{eq:opt} with the Adam optimizer, with a learning rate of $1e-3$ for $500$ iterations.
In the following, we compare our approach that involves estimating deformations (EST) with our approach where we  simply fit an implicit neural network to estimate the volume but without accounting for the deformation (EST W/O). We also compare with the filtered-back projection (FBP) \cite{harauz1986exact}, a standard reconstruction algorithm.


%\subsection{Results}
We display a snapshot of the true and estimated volumes in Figure \ref{fig:volume}.
We asses the quality of the reconstruction using the Fourier Shell correlation (FSC) in Figure \ref{fig:fsc}. The FSC indicates the correlation between the frequencies of the estimated volume and the original. This is a standard metric used to compare recovered volumes in practice \cite{harauz1986exact}. 
Figure \ref{fig:fsc} shows that estimating the deformation allows a significant increase in the resolution. Notice that all three methods don't compensate for the missing wedge, and we expect a higher gain when incorporating additional prior in Problem \eqref{eq:opt}.

We asses the quality of the estimation of deformation in Table \ref{tab:SNR}. We display the average error on the global deformations (shift and in-plane rotation). We also report the average SNR of the noise-free and non-deformed projections between the true and estimated volume. While the deformation parameters are well estimated, the gain of SNR in the projections also indicates that the volume is better estimated than when no deformation is estimated.

\begin{table}
 \begin{center}
\begin{tabular}{ |c|c|c|c| } 
\hline
% & \multicolumn{ 2}{|c|}{Estimate Projection SNR} \\ 
% \hline
 & EST & EST (W/O) & FBP  \\ 
\hline
 Shifts (pixel) & 0.7396 & 3.3863 & 3.3863 \\ 
 In-plane rotation (degree)  & 1.5837 & 5.067 & 5.067 \\ 
local deformation (pixel) & 1.284 & 1.282 &  1.282 \\ 
SNR of projections (dB)  & 14.962 & 11.999 & -6.873 \\ 
 \hline
 \end{tabular}
 \caption{Estimation quality of the parameters at SNR 0dB.}
\label{tab:SNR}
\end{center}
\vspace{-0.5cm}
\end{table}


% Figure environment removed

% Figure environment removed





\section{Conclusion}
We show that pixel-level deformations, widely present in many cryoET applications, can be mitigated using a small set of parameters and networks. Along with this, we use an implicit network to represent the undistorted volume and jointly learn to recover it even in the presence of unknown deformations. We see improvements in the reconstructions. The current setup relies on the inductive bias of the implicit network to accurately recover volume. However, our framework is flexible enough to allow the use of advanced prior, helping to compensate for the missing wedge.  

% TODO: Add prilminary work here not compared with others yet.
% TODO: Talk about miising wedge but we see improvements, use prior for the missing wedge

 % Experiment includes the a toy model where we use the cell proteing for the experiments.

 % Recover parpameter of deformations



 %% Discussion: \


%  1. Write intro + motivation + contribution + relatedworks
%  2. Experiment: true data + comparison
% AreTomo paper to show deformations 
% Check cryoET papper where cryoEM molecules are used.
 
 % \section{Introduction}
% Please follow the outlined formatting when submitting
% your manuscript to the International Symposium on Computational Sensing (ISCS). This section provides guidelines for abstract submissions for all types of presentations in ISCS 2023, \textit{i.e.,} platform, poster, and show-and-tell presentations. Specific requirements for show-and-tell abstracts are highlighted in Sec.~\ref{sec:show-and-tell}.
% \subsection{Paper length}
% The length of the paper must be up to 2 pages for technical content, figures, and references, and one optional third page containing only references.
% \subsection{Font size}
% Use a font size that is no smaller than 9 points throughout the paper, including figure captions.
% \subsection{Bibliography}
% List and number all bibliographical references at the end of
% the paper. The references can be numbered in alphabetic order
% or in order of appearance in the document.
% When referring to
% them in the text, type the corresponding reference number in
% square brackets as shown at the end of this sentence \cite{code1}.

% \section{Specific Guidelines for Show-and-Tell Abstract} \label{sec:show-and-tell}
% The extended abstract for show-and-tell demos must follow the aforementioned format. The manuscript should 
% \begin{itemize}
% \item include pictures of the set-up;
% \item include a clear explanation of the targeted application and computational method developed;
% \item include a representative example of acquisitions using the set-up and its associated processing. 
% \end{itemize}

% \section{Conclusion}


\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}
