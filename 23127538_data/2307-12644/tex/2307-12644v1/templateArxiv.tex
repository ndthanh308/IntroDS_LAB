\documentclass{article}


\usepackage{PRIMEarxiv}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\usepackage{listings}
\usepackage{xcolor}
\usepackage{threeparttable}
\graphicspath{{media/}}     % organize your images and other figures under media/ folder
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{subfig}
\usepackage{adjustbox}
\usepackage{longtable}


\lstdefinestyle{yaml}{
     basicstyle=\color{blue}\footnotesize,
     rulecolor=\color{black},
     string=[s]{'}{'},
     stringstyle=\color{blue},
     comment=[l]{:},
     commentstyle=\color{black},
     morecomment=[l]{-}
 }
\hfuzz=40pt

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{Remote Bio-Sensing: Open Source Benchmark Framework for Fair Evaluation of rPPG}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}
  
%% Title
\title{Remote Bio-Sensing: Open Source Benchmark Framework for Fair Evaluation of rPPG
%%%% Cite as
%%%% Update your official citation here when published 
%\thanks{\textit{\underline{Citation}}: 
%\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Dae Yeol Kim, Eunsu Goh, KwangKee Lee \\
  Innopia Tech \\
  Gyeonggi-do, Korea\\
  \texttt{\{wagon0004, dmstn96, kklee\}@innopiatech.com} \\
  %% examples of more authors
   \And
  JongEui Chae, JongHyeon Mun, Junyeong Na, Chae-bong Sohn  \\
  Electronics \& Communications Engineering, Kwangwoon University \\
  Seoul, Korea\\
  \texttt{\{paperc, mjh110311, najubae, cbsohn\}@kw.ac.kr} \\
  \And
  Do-Yup Kim\\
  Department of Information and Communication AI Engineering, Kyungnam University\\
  Gyeongsangnam-do, Korea\\
  \texttt{doyup09@kyungnam.ac.kr}\\
}


\begin{document}
\maketitle

\begin{abstract}
Remote Photoplethysmography (rPPG) is a technology that utilizes the light absorption properties of hemoglobin, captured via camera, to analyze and measure blood volume pulse (BVP). By analyzing the measured BVP, various physiological signals such as heart rate, stress levels, and blood pressure can be derived, enabling applications such as the early prediction of cardiovascular diseases. rPPG is a rapidly evolving field as it allows the measurement of vital signals using camera-equipped devices without the need for additional devices such as blood pressure monitors or pulse oximeters, and without the assistance of medical experts.
Despite extensive efforts and advances in this field, serious challenges remain, including issues related to skin color, camera characteristics, ambient lighting, and other sources of noise, which degrade performance accuracy. We argue that fair and evaluable benchmarking is urgently required to overcome these challenges and make any meaningful progress from both academic and commercial perspectives. In most existing work, models are trained, tested, and validated only on limited datasets. Worse still, some studies lack available code or reproducibility, making it difficult to fairly evaluate and compare performance. Therefore, the purpose of this study is to provide a benchmarking framework to evaluate various rPPG techniques across a wide range of datasets for fair evaluation and comparison, including both conventional non-deep neural network (non-DNN) and deep neural network (DNN) methods.\\
GitHub URL: \url{https://github.com/remotebiosensing/rppg}.
\end{abstract}



% keywords can be removed
\keywords{rPPG \and fair eveluation \and remote bio-sensing}


\section{Introduction}
rPPG, a method that utilizes cameras to capture facial images and measure blood volume pulse (BVP) based on optical principles, has gained significant attention in recent years. By analyzing the BVP, rPPG can measure various vital signs such as heart rate, respiration, and blood pressure. Its high usability stems from the fact that it only requires a device equipped with a camera to measure vital signs. Recently, clinical validation and trials for rPPG are widely underway by various institutions \cite{clinical,hospitaltrial}. According to \cite{cvd}, rPPG can accurately measure Hear Rate(HR) in subjects with Cardiovascular disease (CVD).

There also has been a surge of interest in rPPG research, resulting in numerous published papers and datasets. In response to this trend, the Remote Physiological Signal Sensing (Repss) challenge was held at ICCV \cite{repss1st} and CVPM \cite{repss2nd}, while the Vision for Vitals (V4V) challenge took place at ICCV\cite{V4V1st}.

The study of rPPG can be divided into three main perspectives: dataset, preprocessing, and model training. From the dataset perspective, rPPG algorithms should consider various characteristics such as subject movement\cite{motionICE,motionRR,BCGMotion,motionRobust,realworldmotion}, Region of Interest(RoI)\cite{region+deepphys, assesmentROI, po2018roi, kwon2015roi, lempe2013roi,niu2017roi,zhao2022roi, van2014roi,calvo2015roi}, Color Space\cite{jaiswal2023color}, light intensity\cite{lowlight,colorillumination,lowlightimageENhancement}, gender, skin color\cite{genderskin, skintonestyle} ]. Various datasets are being created, but only a few cover those factors widely enough. In terms of preprocessing, facial cropping methods can be categorized into: 1) cropping based on the size of the face, typically a certain multiple of the face's size, and 2) tracking the face's movement. After facial cropping, different processing methods can be applied, including: 1) Continuous Method, where the cropped videos are used as inputs\cite{Physnet,physformer,physformer++}, 2) Differential Normalization Method, which utilizes the differences between frames as inputs\cite{DeepPhys,MTTS,metaphys,efficientphys,bigsmall}, and 3) Spatial Temporal Map (STMap) Method, that expresses video as an image, and some deep learning networks create and use STMap within the Deep Learning Network\cite{APNET}.

Lastly, from the perspective of model training, approaches can be categorized as follows: 1) non-DNN Methods, which involve unsupervised inference\cite{green,ICA,PCA,CHROM,PBV,POS,SSR,LGI,EEMD-MCCA,EEMD+FastICA}, and 2) Deep Learning Methods, which utilize various deep learning models.

In order to address the various challenges and issues mentioned earlier, numerous papers have been published in the field of rPPG. However, a significant portion of these papers does not openly share their code, making a fair evaluation and comparison difficult for the newly proposed algorithm. Lack of code availability often leads researchers to reimplement the algorithms from scratch and the algorithm to be not reproducible, as crucial details such as experimental preprocessing and post-processing techniques, as well as the specific configurations of deep learning models, are not disclosed. Moreover, even if these challenges are overcome, the lack of clear information regarding the train/test/evaluation dataset, such as the time at which the data was collected, hinders reproducibility and makes it impossible to conduct fair evaluations and comparisons among different algorithms.

Due to these challenges, the field of rPPG research tends to be less transparent and more closed off compared to other research domains. It is highly inefficient for researchers to spend time on reproducing previous work in rPPG. Therefore, this paper aims to provide guidelines for rPPG research and introduces an open-source benchmarking framework that strives to promote reproducibility and transparency in this reasearch area.

By offering this benchmark project, our goal is to overcome the existing limitations and facilitate the implementation and evaluation of rPPG algorithms, enabling researchers to have a standardized and comprehensive platform for conducting fair and reliable comparisons.


The key contributions covered in this paper are as follows:
\begin{description}
    \item[$\cdot$ Providing rPPG preprocessing techniques]: Since the directory structure and file structure vary for each public dataset, different preprocessing methods are required for each. In addition, various methods are used depending on the deep learning model, such as whether to track faces, initial face area-based video cropping, cropping larger than face size, and cropping ROI areas (cheeks, forehead).
    \item[$\cdot$ Providing rPPG dataset lists]: Numerous datasets have been created and made publicly available, but there is no organized information about them. We will publicly release a table of supported biometric information and video types (RGB, NIR) for each dataset.
    \item[$\cdot$ Providing rPPG models]: New researchers spend a considerable amount of time implementing previous research works. We aim to reduce this time by providing implementation of various deep learning models.
    \item[$\cdot$ Providing a research framework]: New researchers spend a considerable amount of time implementing and reproducing previous research models. We aim to reduce this time by providing implementation of various deep learning models.
    \item[$\cdot$ Providing dataset analysis functions]: Generally, datasets provide both PPG labels and HR labels, but there may be some differences in the generated values when creating HR using PPG labels. We visually represent which method for generating HR, using FFT or peak detection, is closer to the actual HR label.
    \item[$\cdot$ Fair evaluation results publication]: Transparent evaluation results announced: Some works are not clearly reproduced and their performance and accuracy are not to be verified. A fairer and more transparent evaluation is possible by presenting the results produced through this open-source framework.
\end{description}

\section{Related Works}
 In the field of rPPG, there are several open-source projects available that facilitate easy model reproduction and testing. These projects aim to provide researchers with resources for implementing and evaluating rPPG models more efficiently, enhancing reproducibility and reliability of research results. Here are some notable examples:
\paragraph{rPPG-Toolbox\cite{liu2022tool}:} 
The rPPG-Toolbox provides a research, development, and evaluation pipeline for rPPG. It offers six unsupervised methods: Green\cite{green}, ICA\cite{ICA}, CHROM\cite{CHROM}, LGI\cite{LGI}, PBV\cite{PBV}, and POS\cite{POS}. Additionally, it provides six deep learning models, including PhysNet\cite{Physnet} and four subsequent models of Deepphys\cite{DeepPhys,MTTS,efficientphys,bigsmall}. One of the distinguishing features of this project is the inclusion of Motion Augment Training and the latest multi-task learning rPPG model called Bigsmall. It also offers preprocessing for datasets such as SCAMPS\cite{scamps}, UBFC-rppg\cite{ubfc-rppg}, PURE\cite{pure}, BP4D+\cite{BP4d}, UBFC-phys\cite{ubfc-phys}, and MMPD\cite{3mmpd}.

\paragraph{iPhys-Toolbox\cite{iphys}:} iPhysToolbox is a project designed for conducting rPPG experiments in the MATLAB environment. It provides a total of six unsupervised methods: Green\cite{green}, ICA\cite{ICA}, CHROM\cite{CHROM}, POS\cite{POS}, and BCG\cite{bcg}. These methods are utilized for rPPG analysis and experimentation.

\paragraph{PPG-I Toolbox\cite{ppgi}:}Launched in 2019, this open source is being updated to the relatively recent date of October 2022 and focuses on supporting unsupervised methods in rPPG research. Although it lacks support for deep learning-based methods, it offers functionality for six unsupervised methods: Green\cite{green,greenthesis}, Spatial Subspace Rotation (SSR)\cite{SSR}, Plane-Orthogonal-to-Skin (POS)\cite{POS}, Local Group Invariance (LGI)\cite{LGI}, Diffusion Process (DP)\cite{DP1,DP2}, and Riemannian-PPGI (SPH)\cite{ppgi}. In terms of evaluation metrics, the project supports five metrics: Correlation, Bland-Altman, RMSE, MSE, and SNR. These metrics can be utilized to assess the performance and accuracy of the rPPG algorithms implemented within the project.

\paragraph{pyVHR\cite{pyvhr}:} It includes its own pipeline for rPPG, offering pre-processing capabilities for 11 open datasets such as PURE\cite{pure}, LGI-PPGI\cite{LGI}, UBFC-rPPG\cite{ubfc-rppg}, UBFC-Phys\cite{ubfc-phys}, ECG-Fitness\cite{hrcnn}, MANOB\cite{MANOHOB}, Vicar-PPG-2\cite{vicar}, V4V\cite{V4V1st}, VIPL\cite{vipl-hr}, among others. The project provides a range of methods, including traditional approaches such as ICA, PCA, Green, CHROM, POS, SSR, PBV\cite{PBV}, OMIT\cite{omit}, as well as deep learning methods like hr-cnn\cite{hrcnn} and mtts-can\cite{MTTS}. It is worth noting that this project is unique among Python-based open-source projects, as it provides an API, offering convenience and ease of use. Additionally, the project offers visual representation of evaluation metrics, which can provide analytical advantages for researchers. By visualizing the evaluation metrics, it enables easier analysis and interpretation of the results. Overall, this project appears to be a comprehensive resource that encompasses various rPPG methods, pre-processing capabilities, open datasets, and evaluation metrics, facilitating reproducibility, development, and comparison in the field of rPPG research.

\paragraph{PhysBench\cite{physbench}:} Physbench offers pre-processing capabilities for seven rPPG datasets, including RLAP\cite{physbench}, UBFC-rPPG\cite{ubfc-rppg}, UBFC-PHYS\cite{ubfc-phys}, MMPD\cite{3mmpd}, PURE\cite{pure}, COHFACE\cite{cohface}, and SCAMPS\cite{scamps}.
In terms of deep learning models, Physbench provides five different models: DeepPhys\cite{DeepPhys}, TS-CAN\cite{MTTS}, EfficientPhys\cite{efficientphys}, PhysNet\cite{Physnet}, and Seq-rPPG. Additionally, it offers three unsupervised methods: CHROM\cite{CHROM}, ICA\cite{ICA}, and POS\cite{POS}. It's worth noting that the Physformer model is implemented using the PyTorch framework, while the rest of the models are implemented using TensorFlow. In addition to the provided models and pre-processing capabilities, Physbench also offers a data set generator that synchronizes videos and labels. This feature allows researchers to generate synchronized datasets, which can be beneficial for training and evaluating rPPG algorithms.

\paragraph{Terb\cite{Terbe}:} This project is specifically designed to run rPPG on the edge device Jetson Nano. It provides two deep learning methods: DeepPhys and PhysNet. These methods are tailored for executing rPPG on the Jetson Nano platform.

\paragraph{bob\cite{bob2017}:} This project offers three unsupervised methods: SSR\cite{SSR}, CHROM\cite{CHROM}, and Li's CVPR14 method\cite{bobref}. These methods are provided for conducting rPPG analysis and experimentation within the project.


\section{Remote Bio-sensing : Open Source Benchmark Framework for Fair Evaluation of rPPG}
\label{sec:headings}

We provide an open-source benchmark tool that ensures reproducibility of rPPG algorithms and enables fair evaluation. Unlike the current tools that are limited to certain deep learning models and unsupervised methods, our benchmark tool aims to include all newly published methods in the evaluation list. We strive to provide a framework where researchers have the freedom to perform preprocessing, add their own deep learning models, and conduct analysis. By offering such flexibility, we promote a more comprehensive and inclusive evaluation of rPPG algorithms within the research community.

\begin{table}[ht]
\caption{rppg open-source project list}
    \centering
\begin{tabular}{cccccccccc}
\hline
\multicolumn{2}{c}{Project}                        & \multicolumn{1}{l}{\cite{liu2022tool}} & \multicolumn{1}{l}{\cite{iphys}} & \multicolumn{1}{l}{\cite{ppgi}} & \multicolumn{1}{l}{\cite{pyvhr}} & \multicolumn{1}{l}{\cite{physbench}} & \multicolumn{1}{l}{\cite{Terbe}} & \multicolumn{1}{l}{\cite{bob2017}} & \multicolumn{1}{l}{\textbf{Ours}} \\ 
\hhline{==========}
\multirow{3}{*}{Open Dataset} & Support            & O                                & X                                 & X                                 & O                         & O                             & X                         & X                       & O                        \\ \cline{2-10} 
                              & \# of Dataset      & 6                                & -                                 & -                                 & 11                        & 7                             & -                         & -                       & 6                        \\ \cline{2-10} 
                              & Dataset Analysis   & X                                & -                                 & -                                 & O                         & X                             & -                         & -                       & O                        \\ \hline
non-DNN Method                & \# of Method       & 6                                & 6                                 & 6                                 & 8                         & 3                             & -                         & 3                       & 7                        \\ \hline
\multirow{3}{*}{DNN Method}   & Train Support      & O                                & X                                 & X                                 & X                         & O                             & O                         & X                       & O                        \\ \cline{2-10} 
                              & Evaluation Support & O                                & X                                 & X                                 & O                         & O                             & O                         & X                       & O                        \\ \cline{2-10} 
                              & \# of Method       & 5                                & -                                 & -                                 & 2                         & 5                             & 2                         & -                       & 10                       \\ \hline
\end{tabular}
    \label{tab:tabel1}
\end{table}
Table \ref{tab:tabel1} provides an overview of the characteristics of the previously mentioned open-source projects. In this paper, our Open-Source Project stands out by offering a dataset analyzer, which is not available in other open-source projects. Additionally, our project provides a larger variety of methods compared to other existing tools. This allows researchers to explore and evaluate rPPG algorithms using a wider range of techniques, promoting a more comprehensive analysis and comparison of different approaches.

% Figure environment removed

figure \ref{fig:project overview} provides an overview of the proposed open-source project. It consists of several layers that facilitate the implementation and evaluation of rPPG algorithms.

\begin{itemize}
    \item \textbf{Dataset Analysis Layer:} This layer focuses on dataset analysis and provides tools and functions for analyzing the rPPG datasets. It allows researchers to gain insights into the characteristics and properties of the datasets before conducting further preprocessing and modeling.
    \item \textbf{Preprocessing Layer:} This layer is responsible for preprocessing the input data to make it suitable for the specific methods being used. It includes various preprocessing techniques and functions to handle data normalization, filtering, alignment, and other necessary preprocessing steps.
    \item \textbf{Methods Layer:} This layer encompasses the implementation of various rPPG methods. It includes both unsupervised and deep learning-based methods. Researchers can choose from a wide range of available methods based on their specific requirements and preferences.
    \item \textbf{Train and Evaluation Layer:} This layer facilitates the training of deep neural network (DNN) methods and the evaluation of all the implemented methods. It provides tools and functions for training the DNN models using the available datasets and for evaluating the performance of all the methods using suitable evaluation metrics.
    \item \textbf{Application Layer:} This layer showcases the application of the implemented methods by providing demos and examples. It allows researchers to visualize and interpret the results of the rPPG algorithms in practical applications.
\end{itemize}

Overall, the proposed open-source project offers a comprehensive framework that covers dataset analysis, preprocessing, method implementation, training, evaluation, and application demonstration, providing researchers with a flexible and integrated platform for their rPPG research and development.

\subsection{Data Analysis Layer}

The Data Analysis Layer provides functionalities related to data collection, retrieval, and analysis. There are over 20 open datasets available, and each dataset has been generated considering different types of noise.

\begin{table}[h]
\caption{OpensDataset List}
\centering
\begin{threeparttable}
\begin{tabular}{rclrcc}
\hline
\textbf{\#} & \textbf{year} & \textbf{name} & \textbf{subject} & \textbf{video} & \textbf{label} \\ \hhline{======}
1           & 2011          & MAHNOB\_HCI\cite{MANOHOB}       & 27               & RGB            & ECG\tnote{*}            \\ \hline
2           & 2012          & DEAP\cite{DEAP}                 & 22               & RGB            & PPG            \\ \hline
3           & 2014          & AFRL\cite{AFRL}                 & 25               & RGB            & PPG            \\ \hline
4           & 2014          & PURE\cite{pure}                 & 10               & RGB            & PPG/SPo2\tnote{*}       \\ \hline
5           & 2016          & BP4D+\cite{BP4d}                & 140              & RGB/NIR        & PPG/HR\tnote{*}/BP\tnote{*}      \\ \hline
6           & 2016          & MMSE-HR\cite{MMSE}              & 40               & RGB            & HR/BP          \\ \hline
7           & 2017          & COHFACE\cite{cohface}           & 40               & RGB            & PPG/HR/RR\tnote{*}      \\ \hline
8           & 2017          & BIDMC\cite{BIDMC}               & -                & -              & PPG/BP         \\ \hline
9           & 2018          & LGGI\cite{LGI}                  & 25               & RGB            & -              \\ \hline
10           & 2018          & ECG-Fitness\cite{hrcnn}         & 17               & RGB            & ECG            \\ \hline
11           & 2018          & VIPL-HR\cite{vipl-hr}           & 107              & -              & PPG/HR         \\ \hline
12          & 2018          & OBF\cite{OBF}                   & 100              & RGB/NIR        & PPG/HR         \\ \hline
13          & 2018          & MR-NIRP(ind)\cite{mrnirp_indoor}& 8                & RGB/NIR        & PPG/HR         \\ \hline
14          & 2019          & UBFC-rPPG\cite{ubfc-rppg}       & 42               & RGB            & PPG/HR         \\ \hline
15          & 2020          & VicarPPG\cite{vicar}            & 10               & RGB            & PPG/HR/ECG     \\ \hline
16          & 2020          & MR-NIRP(DRV)\cite{mrnirp_drv}   & 18               & RGB/NIR        & PPG/HR         \\ \hline
17          & 2020          & mori-ppg\cite{morippg}          & 30               & RGB            & ECG            \\ \hline
18          & 2020          & BSIPL-rPPG\cite{pulsegan}       & 37               & RGB            & PPG            \\ \hline
19          & 2020          & EatingSet\cite{vicar}           & 20               & RGB            & PPG/HR         \\ \hline
20          & 2020          & StableSet\cite{vicar}           & 24               & RGB            & HR/HRV/ECG     \\ \hline
21          & 2021          & UBFC-Phys\cite{ubfc-phys}       & 56               & RGB            & PPG/HR/EDA     \\ \hline
22          & 2021          & MPSC-rPPG\cite{mpsc-rPPG}       & 9                & RGB            & HR/RR/HRV      \\ \hline
23          & 2021          & V4V\cite{V4V1st}                & 140              & RGB/NIR        & HR/RR/BP       \\ \hline
24          & 2022          & MTHS\cite{MTHS}                 & 62               & RGB            & PPG/RR         \\ \hline
25          & 2022          & BAMI-rPPG\cite{BAMI}            & 14               & -              & PPG/HR         \\ \hline
26          & 2023          & MMPD\cite{3mmpd}                & 33               & RGB            & PPG            \\ \hline
27          & 2023          & Vital Videos\cite{vitalvideos}  & 900              & -              & -             \\\hline
\end{tabular}
%\begin{tablenotes}\footnotesize
%\item [*] ECG : electrocardiogram, HR : Heart Rate, SPo2 : Oxygen Saturation,\\ RR : Respiration %Rate
%\end{tablenotes}
\end{threeparttable}

\label{tab:table2}
\end{table}

Table \ref{tab:table2} presents a list of open datasets. Since the datasets have different structures, it can be time-consuming for new researchers to analyze the data structure. To address this, the Open Dataset Loader assists in easily loading the data based on the analyzed data structure. The Dataset Analyzer offers features such as analyzing the alignment between labels and videos in the open datasets and determining skin color biases. Additionally, the project provides a feature for collecting datasets using a Gold Standard Device in a desktop environment.

\subsubsection{Open Dataset Analyzer}


rPPG utilizes the optical principle of hemoglobin's light absorption to observe vascular changes associated with the contraction and relaxation of blood vessels. However, the degree of variation in reflected light due to light absorption is influenced by the thickness of the skin and the content of melanin. Therefore, it is important to consider these factors as well.

% Figure environment removed

Fig \ref{fig:fig2} represents the absorption spectra of hemoglobin and melanin at different wavelengths. Hemoglobin exhibits the highest light absorption at 432nm, but camera sensors have lower light sensitivity at this wavelength. Therefore, when measuring rPPG, it is necessary to consider wavelengths with both high light sensitivity and high hemoglobin absorption, which typically fall within the range of 500nm to 600nm. However, within this range, melanin has a higher light absorption rate compared to hemoglobin.

% Figure environment removed

Fig \ref{fig:Fitz} illustrates the melanin content based on the Fitzpatrick scale. As the skin type approaches Type 6, the melanin content increases. This can have an impact on the actual measurement results. However, it is rare for open datasets to provide Fitzpatrick scale as a label, making it challenging to ensure fair evaluations. Therefore, to address this issue, it is necessary to measure skintype. However, measuring the Fitzpatrick scale is a difficult task. In our proposed project, we provide a feature that utilizes \cite{fitzeccv} to distinguish skin tones, enabling more accurate analysis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 수정 예정 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Figure environment removed

% 내용도 수정예정
Figure \ref{fig:Fitz_15} depicts the results of performing Fitzpatrick scale classification using our Open Dataset Analyzer. By utilizing the predominant color, we were able to distinguish the most similar Fitzpatrick type among the six types. This classification helps in understanding the skin tone variations within the dataset and provides valuable insights for further analysis and evaluation.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

rPPG open datasets typically consist of video data and PPG, HR, RR measurements obtained from an pulse oximeter. The oximeter measures PPG by using wavelengths in the IR and RED bands. It compares the emitted light source with the absorbed values to measure the PPG signal and then processes it through a bandpass filter (BPF) and further post-processing to generate vital signs such as HR and RR.
% Figure environment removed

Figure \ref{fig:oximeter} represents a block diagram of a Pulse Oximeter. Generally, when we refer to PPG, it denotes the output of the probe. The internal components of the Oximeter, such as the Filter, ADC, and HR/RR Converter, are responsible for obtaining the heart rate (HR) and respiratory rate (RR) from the PPG signal. However, the settings of the filters and converters can vary across different measurement devices (e.g., window size, filter band), leading to inconsistencies in the labels provided by open datasets.

To address this issue, when evaluating the performance of algorithms using the PPG labels, it is important to take into consideration the mismatch that can occur between the HR labels and the PPG labels derived from datasets. It is necessary to carefully account for these variations and ensure appropriate alignment between the PPG-based predictions and the corresponding HR labels during evaluation.

% Figure environment removed


Figure \ref{fig:ppg evaluate} shows the results of label evaluation using the Open Dataset Analyzer with the VIPL-HR dataset. Two methods were employed to measure the HR: one using peak detection from the PPG signal and the other using Fast Fourier Transform (FFT). The bottom right graph illustrates the outcomes. The blue line represents the HR provided as the label, the red line corresponds to the HR measured using peak detection, and the black line represents the HR obtained through FFT. It can be observed that there is some discrepancy between the provided label and the actual label, indicating differences in the measured HR values.

\subsubsection{Dataset Collector with Golden Standard Device}

\subsection{Preprocessing Layer}
preprocessing is a time-consuming and challenging task before training DNN-based rPPG algorithms. With the presence of various open datasets that lack a standardized structure and have different formats, we aimed to simplify the preprocessing process for new users by analyzing the storage formats. Our goal was to enable users to preprocess the datasets without the need to understand the underlying structure, and subsequently save the processed data.

To achieve this, we categorized the preprocessing methods into four approaches:
\begin{itemize}
    \item \textbf{DiffNorm}: DiffNorm preprocesses the data by considering the differences between consecutive frames. It takes advantage of the fact that the reflected light from the skin surface changes due to the pulsatile blood flow. By subtracting the current frame from the previous frame, the variations caused by factors such as lighting conditions, camera noise, and static skin properties can be reduced.
    \begin{equation}
D(t) = \frac{{C'(t) \cdot C(t)}}{{C(t + \Delta t) - C(t)}}
\label{eq:1}
\end{equation}
    Equation  represents the preprocessing method of DiffNorm. D(t) denotes the Diff Normalized data at time T, C(t) denotes the image captured by the camera at time t. It is based on Shafer's dichromatic reflection model and aims to eliminate the quantization noise from the camera and the component of light reflection.
    The goal of DiffNorm is to enhance the pulsatile component of the signal while attenuating the non-pulsatile components. By removing the noise and unwanted reflections, it helps to improve the quality and reliability of the rPPG signal for subsequent analysis and modeling.
    \item \textbf{Z-score normalize}: The Z-score normalize method standardizes the data by subtracting the mean and dividing by the standard deviation. It helps in normalizing the data distribution and reducing the influence of outliers.
    \item \textbf{STmap}: STmap refers to representing the video data as a spatial-temporal map, which captures the spatiotemporal information for further analysis. This representation can help in extracting meaningful features and patterns from the video frames.
    % Figure environment removed
    Figure \ref{fig:STMap} illustrates the process of generating an STmap from a facial video. STmap, or Spatial Temporal map, incorporates spatial transformation information for each frame of video data into a 2D image. This transformation information describes dynamic changes such as object movement, rotation, and scaling.
    \item \textbf{Raw}: The raw method involves using the data in its original form without any preprocessing. This approach is useful when the data is already in a suitable format for further processing.
\end{itemize}

By providing these preprocessing methods, we aimed to alleviate the burden of data preprocessing for users, allowing them to choose and apply the desired preprocessing technique without the need for extensive knowledge of the dataset structure. Additionally, the processed data can be saved for further analysis and training of DNN-based rPPG algorithms.

\subsection{Methods Layer}
rPPG is a field that is still being researched using both DNN and non-DNN approaches. Many methods have been proposed in this area. However, unlike other research fields, rPPG has been characterized by a lack of open-source code. This closed nature of the rPPG field has hindered its progress and created high entry barriers for researchers.

To address this issue, our goal is to tackle the problem by implementing and openly sharing as many rPPG methods as possible. By providing access to the source code of various methods, we aim to promote transparency, reproducibility, and collaboration within the rPPG research community. We believe that by making the implementations available, we can facilitate knowledge sharing, accelerate research progress, and ultimately contribute to the advancement of the rPPG field.

\subsubsection{Non-DNN Methods}
The mentioned methods are all non-DNN approaches that leverage the domain characteristics of rPPG to compute the signals:

\begin{table}[h]
\caption{Summary of Non-DNN  rppg measurement methods}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{c|c|l}
\hline
\textbf{input}                                                      & \textbf{Method} & \multicolumn{1}{c}{\textbf{Representation}}                                                                                                                                                                                                                                                                                                                                              \\ \hhline{===}
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & GREEN  & \begin{tabular}[c]{@{}l@{}}This method considers the spectral sensitivity of the camera sensor and  the light absorption of hemoglobin. \\ It identifies the Green channel as the most suitable for measuring the specular reflection component. It \\ calculates the average Green channel signal and utilizes predominant frequency analysis to estimate the HR.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & ICA    & \begin{tabular}[c]{@{}l@{}}Independent Component Analysis (ICA) is employed to separate  different signal components mixed within \\ a signal matrix. By applying the JADE algorithm and whitening matrix, the original signals are separated.\\  Empirically, the second separated component is often used as the PPG signal.\end{tabular}                                     \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & PCA    & \begin{tabular}[c]{@{}l@{}}Principal Component Analysis (PCA) is a well-known dimensionality  reduction technique. In this context,\\  PCA is applied to analyze the main  components of RGB video signals and reconstruct the PPG signal.\end{tabular}                                                                                                                         \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & CHROM  & \begin{tabular}[c]{@{}l@{}}The CHROM method aims to remove noise caused by light reflection and estimates the PPG signal by \\ filtering out unwanted noise.\end{tabular}                                                                                                                                                                                                       \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & PBV    & \begin{tabular}[c]{@{}l@{}}PBV proposes a vector that distinguishes motion noise from pulse-related noise in RGB signals \\ to observe variations in heartbeat.\end{tabular}                                                                                                                                                                                                    \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & POS    & \begin{tabular}[c]{@{}l@{}}POS aims to mitigate specular reflection noise. It projects the PPG waveform onto a plane \\ orthogonal to the skin tone, which helps in signal recovery.\end{tabular}                                                                                                                                                                               \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & SSR    & \begin{tabular}[c]{@{}l@{}}SSR utilizes the absorbance characteristics of hemoglobin. By applying Subspace Rotation and \\ Temporal Rotation, it extends the pulse amplitude and reduces distortion caused by light reflection.\end{tabular}                                                                                                                                    \\ \hline
\begin{tabular}[c]{@{}c@{}}Raw\\ {[}0 $\cdots$ 255{]}\end{tabular} & LGI    & \begin{tabular}[c]{@{}l@{}}LGI suggests a robust algorithm using differentiable local transformations to handle \\ various environmental conditions.\end{tabular}                                                                                                                                                                                                               \\ \hline
\end{tabular}
\end{adjustbox}
\label{tab:non-dnn}
\end{table}

Table \ref{tab:non-dnn} provides summary of non-DNN rPPG measurement methods. These methods utilize different principles and techniques to extract and estimate the rPPG signal from video data without relying on DNN models.
\subsubsection{DNN Methods}
DNN-based methods in the rPPG field can be categorized based on their input formats, and in our Open-Source Framework, they have been implemented using PyTorch for reproducibility.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[h]
\caption{Summary of DNN  rppg measurement methods}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{l|c|c|l}
\hline
\multicolumn{1}{c|}{Type}                                                  & input                                                            & Method         & \multicolumn{1}{c}{Representation}                                                                                                                                        \\ \hhline{====}
\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Diff\\ Normalized\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Z-score\\ Diff Norm\end{tabular}      & DeepPhys\cite{DeepPhys}       & \begin{tabular}[c]{@{}l@{}}The first deep learning model based on Shafer's Drm. \\ Measure BVP between two $\Delta$ T using two branch CNN\end{tabular}     \\ \cline{2-4} 
                                                                           & \begin{tabular}[c]{@{}c@{}}Avg(Z-score)\\ Diff Norm\end{tabular} & MTTS\cite{MTTS}           & \begin{tabular}[c]{@{}l@{}}Model applying TSM(Temporal Shift Model) to DeepPhys to \\ reduce motion noiseMulti-task model aimed at measuring HR and RR.\end{tabular}      \\ \cline{2-4} 
                                                                           & Diff Norm(Z-score)                                               & EfficentPhys-C\cite{efficientphys} & \begin{tabular}[c]{@{}l@{}}End-to-End model aimed at simplifying the existing DeepPhys \\ and MTTS pre-processing and operating on mobile devices.\end{tabular}           \\ \cline{2-4} 
                                                                           & \begin{tabular}[c]{@{}c@{}}Z-Score\\ DiffNorm\end{tabular}       & BigSmall\cite{bigsmall}       & \begin{tabular}[c]{@{}l@{}}A Wrapping Temporal Shift Model (WTSM) proposal that produces\\ highly accurate results even with a small number of input frames.\end{tabular} \\ \hline
\multirow{3}{*}{Continuos}                                                 & \begin{tabular}[c]{@{}c@{}}Raw\\ {[}-1 .. 1{]}\end{tabular}      & PhysNet\cite{Physnet}        & \begin{tabular}[c]{@{}l@{}}Using negative pearson loss and 3D CNN,\\  rPPG reasoning ability was confirmed.\end{tabular}                                                  \\ \cline{2-4} 
                                                                           & \begin{tabular}[c]{@{}c@{}}Raw\\ {[}-1 .. 1{]}\end{tabular}      & PhysFormer\cite{physformer}     & \begin{tabular}[c]{@{}l@{}}Propose Curriculum Learning Guided Dynamic Loss and \\ verify rPPG inference performance using Transformer.\end{tabular}                       \\ \cline{2-4} 
                                                                           & \begin{tabular}[c]{@{}c@{}}RAW\\ {[}TBD{]}\end{tabular}          & APNET\cite{APNET}          &                                                                                                                                                                           \\ \hline
STmap                                                                      & YUV STmap                                                        & RhythmNet\cite{Rhythmnet}      & Validation of Heart Rate Estimation via Video to STmap.                                                                                                                   \\ \hline
\end{tabular}
\end{adjustbox}
\label{tab4:dnnmethods}
\end{table}

Table \ref{tab4:dnnmethods} provides summary of DNN rPPG measurement methods. Deep learning methods are still dependent on the shape of the input, and convergence is determined by the shape of the input.

\subsection{Train and Evaluation Layer}

One of our main objectives is to provide researchers with a convenient research environment. To achieve this, we have incorporated a \emph{fit.yaml} that allows users to easily modify specific configurations, enabling them to customize various aspects of the pipeline, including preprocessing, training, Meta Leaernig(MAML)\cite{MAML}, and evaluation. Researchers can make necessary adjustments to suit their experimental setups and research goals by modifying this yaml file.

Furthermore, we have recorded the benchmark's hyperparameters in the \emph{model\_preset.yaml} . This allows for better reproducibility by ensuring that the same hyperparameters can be applied consistently across experiments. Additionally, we have implemented a sweep functionality to facilitate the reproducibility of experiments. Researchers can refer to the Appendix for more detailed information regarding these configurations and implementation details.

To ensure fair evaluation of our training models, we divided the dataset into human-level segments. Additionally, to compare the model's prediction accuracy over time, we concatenated the results in units of [10s, 20s, 30s] and conducted evaluations.

The evaluation methods we employed are as follows:

\begin{itemize}
    \item Correlation: We calculated the correlation coefficient between the predicted values and ground truth values to assess the linear relationship.    
    \begin{equation}
      Correlation = \frac{T\sum_{1}^{T}\hat{y}y - \sum_{1}^{T}\hat{y}\sum_{1}^{T}y }{\sqrt{(T\sum_{1}^{T} \hat{y}^2 - (\sum_{1}^{T} y)^2 ) T\sum_{1}^{T}y^2 - (\sum_{1}^{T}y)^2})}
    \end{equation}
    \item Bland-Altman Analysis: This analysis allowed us to evaluate the agreement between the predicted values and ground truth values by examining the mean difference and limits of agreement.
    \item Root Mean Square Error (RMSE): RMSE provided a measure of the overall difference between the predicted values and ground truth values.
    \begin{equation}
        RMSE = \sqrt{\frac{1}{N} \sum(\hat{y}-y)^2}
    \end{equation}
    \item Mean Absolute Error (MAE): MAE was used to assess the average absolute difference between the predicted values and ground truth values.
    \begin{equation}
        MAE = \frac{1}{N} \sum|\hat{y}-y|
    \end{equation}    
    \item Mean Absolute Percentage Error (MAPE) : MAPE measures the average percentage difference between the predicted values and the ground truth values.
    \begin{equation}
        MAPE = \frac{1}{N} \sum|\frac{\hat{y} - y}{y}|
    \end{equation}  
    \item Signal-to-Noise Ratio (SNR)\cite{CHROM}: SNR was calculated to evaluate the signal quality of the predicted values compared to the background noise.
    % 수정 필요
    \begin{equation}
        SNR = 10log_(10)(\frac{\sum_{f=HR_{min}}^{HR_{max}}(U_t(f)\hat{S}(f))^2}{{\sum_{f=HR_{min}}^{HR_{max}}(1-U_t(f))\hat{S}(f))^2}})
    \end{equation}  where $\hat{S}(f)$ is the spectrum of the pulse signal, S,f is the frequency in beats per minute, and $U_t(f)$ is a binary template window as shown in Fig. 3.
    %%%%%%%%%%%%%%%%%%%%%
\end{itemize}

By employing these evaluation methods, we aimed to provide a comprehensive assessment of the model's performance and ensure a fair and objective evaluation of our trained models.

\subsection{Application Layer}
TBD


\section{Reproducibility and Benchmark Results}

We provide evidence of the reproducibility of our code and present benchmark results for a fair evaluation of each model. For cross-dataset evaluation, we utilized the UBFC and PURE datasets. Deep learning models such as DeepPhys, TSCAN, EfficentPhys, and Bigsmall were evaluated, while non-DNN methods including CHROM and POS were also assessed.

Among the evaluated models, Bigsmall is a multi-task learning method, but we conducted the evaluation using a single-task learning approach. We assessed the performance of each model using evaluation metrics such as MAE (Mean Absolute Error), RMSE (Root Mean Square Error), MAPE (Mean Absolute Percentage Error), and Pearson-Correlation. These metrics were calculated for time periods of 3, 5, 10, 20, and 30 seconds.

    % Figure environment removed
Figure \ref{fig:time_bar_white} is the inference result according to the length of time. If you increase it from 3 seconds to 10 seconds, the evaluation result improves rapidly, and there is no significant change beyond that, but it can be seen that there is no change in the result.

    % Figure environment removed

Figure \ref{fig:10s} is the cross-dataset evaluation result. If the dataset has a variety of variables, and the model converges well for the various variables, it can be seen that cross-data set evaluation yields good results. Additional results can be found in the appendix.


By providing these benchmark results and evaluation metrics, we aim to ensure a fair assessment of each model's performance. Researchers can use these results as a reference for comparing different models and making informed decisions based on their specific requirements.

\section{Conclusion}

We argue that fair and evaluable benchmarking is urgently needed to overcome the challenges in the rPPG technology and make further advancements. To this end, we are proposing a benchmarking framework that enables various rPPG techniques - all existing and future research works - over wide datasets to be fairly evaluated and compared, including both conventional Non-DNN and DNN methods.

\section{future work}

We intend to keep adding important research and conduct fair evaluations in this environment. We welcome your participation and contribution to this effort.

\section*{Acknowledgments}
This was was supported in part by......

%Bibliography
\bibliographystyle{unsrt}  
\bibliography{references}  

\section{Appendix}

\begin{table}[h]
    \centering
    \caption{fit.yaml}
    \begin{adjustbox}{width=0.9\textwidth}
    \begin{tabular}{|l|}
    \hline
    \begin{lstlisting}[style=yaml]
model_save_path: ""     # model save path
preprocess:
  flag: true            # true: preprocess, false: not preprocess
wandb:
  flag: false
  project_name: DeepPhys
  entity: wandb_entitiy

fit:
  model: DeepPhys       # model name
  type: DIFF            # model type ( DIFF, CONT )
  time_length: 180      # model's target length
  overlap_interval: 0   # default 0
  img_size: 72          # model's input size
  train_flag: True      
  eval_flag: True       
  eval_interval: 100    # force evaluation step
  debug_flag: False     # True: debug mode, False: train mode

  train:
    dataset: UBFC
    shuffle: True
    fs: 30              # video fps
    batch_size: 4       # batch size
    learning_rate: 0.009# learning rate
    epochs: 30          # epochs
    loss: MSE           # loss function
    optimizer: AdamW    # optimizer
    meta:               # meta Learning Configuration for MAML
      flag: false
      inner_optim: adam
      inner_loss: MSE
      inner_lr: 0.01

  test:
    dataset: PURE
    shuffle: False
    fs: 30 
    batch_size: 4
    cal_type: FFT       # Heart rate calculation method
    metric: [ 'MAE','RMSE','MAPE','Pearson' ]
    eval_time_length: 10 # second
    \end{lstlisting}
    \\
    \hline
    \end{tabular}
    \end{adjustbox}
\end{table}

\textbf{results}

\begin{longtable}{|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{MODEL} & \textbf{TRAIN} & \textbf{TEST} & \textbf{IMG\_SIZE} & \textbf{Time\_len} & \textbf{MAE} & \textbf{RMSE} & \textbf{MAPE} & \textbf{Pearson} \\ \hline
BigSmall       & PURE           & PURE          & 72                 & 10                 & 0.68         & 1.547         & 0.98          & 0.981            \\ \hline
BigSmall       & PURE           & PURE          & 72                 & 20                 & 0.117        & 0.454         & 0.163         & 0.999            \\ \hline
BigSmall       & PURE           & PURE          & 72                 & 30                 & 0.176        & 0.556         & 0.333         & 0.998            \\ \hline
BigSmall       & PURE           & PURE          & 72                 & 5                  & 1.598        & 3.568         & 2.529         & 0.914            \\ \hline
BigSmall       & PURE           & UBFC          & 72                 & 10                 & 3.419        & 11.862        & 3.338         & 0.817            \\ \hline
BigSmall       & PURE           & UBFC          & 72                 & 20                 & 3.999        & 13.953        & 3.533         & 0.725            \\ \hline
BigSmall       & PURE           & UBFC          & 72                 & 3                  & 6.285        & 15.475        & 6.353         & 0.711            \\ \hline
BigSmall       & PURE           & UBFC          & 72                 & 30                 & 5.323        & 15.329        & 4.851         & 0.69             \\ \hline
BigSmall       & PURE           & UBFC          & 72                 & 5                  & 5.251        & 14.283        & 5.156         & 0.75             \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 10                 & 5.819        & 18.685        & 5.468         & 0.636            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 20                 & 4.634        & 16.923        & 4.015         & 0.706            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 3                  & 9.238        & 19.944        & 10.24         & 0.501            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 30                 & 6.071        & 19.852        & 5.304         & 0.573            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 5                  & 7.516        & 19.226        & 8.346         & 0.603            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 10                 & 23.555       & 35.99         & 22.892        & 0.415            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 5                  & 23.547       & 35.466        & 24.815        & 0.33             \\ \hline
BigSmall       & UBFC           & UBFC          & 72                 & 10                 & 0.586        & 1.435         & 0.538         & 0.994            \\ \hline
BigSmall       & UBFC           & UBFC          & 72                 & 20                 & 2.539        & 4.184         & 2.43          & 0.947            \\ \hline
BigSmall       & UBFC           & UBFC          & 72                 & 30                 & 0            & 0             & 0             & 1                \\ \hline
BigSmall       & UBFC           & UBFC          & 72                 & 5                  & 0.721        & 2.252         & 0.712         & 0.979            \\ \hline
BigSmall       & UBFC           & PURE          & 72                 & 10                 & 5.718        & 17.785        & 5.532         & 0.677            \\ \hline
BigSmall       & PURE           & UBFC          & 72                 & 10                 & 3.291        & 11.376        & 3.186         & 0.825            \\ \hline
DeepPhys       & PURE           & PURE          & 72                 & 10                 & 0.68         & 1.547         & 1.079         & 0.981            \\ \hline
DeepPhys       & PURE           & PURE          & 72                 & 20                 & 0.117        & 0.454         & 0.163         & 0.999            \\ \hline
DeepPhys       & PURE           & PURE          & 72                 & 30                 & 0.176        & 0.556         & 0.333         & 0.998            \\ \hline
DeepPhys       & PURE           & PURE          & 72                 & 5                  & 1.004        & 2.658         & 1.511         & 0.949            \\ \hline
DeepPhys       & PURE           & UBFC          & 72                 & 10                 & 1.855        & 7.763         & 1.904         & 0.913            \\ \hline
DeepPhys       & PURE           & UBFC          & 72                 & 20                 & 1.516        & 5.287         & 1.557         & 0.957            \\ \hline
DeepPhys       & PURE           & UBFC          & 72                 & 3                  & 4.646        & 12.756        & 4.812         & 0.778            \\ \hline
DeepPhys       & PURE           & UBFC          & 72                 & 30                 & 1.684        & 5.988         & 1.745         & 0.949            \\ \hline
DeepPhys       & PURE           & UBFC          & 72                 & 5                  & 2.609        & 9.021         & 2.647         & 0.884            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 10                 & 5.635        & 17.641        & 6.076         & 0.674            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 20                 & 4.896        & 17.153        & 4.673         & 0.701            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 3                  & 7.857        & 17.698        & 9.472         & 0.627            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 30                 & 3.662        & 13.585        & 3.588         & 0.819            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 5                  & 7.111        & 17.926        & 8.497         & 0.663            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 10                 & 26.719       & 39.369        & 26.05         & 0.178            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 20                 & 25.195       & 39.839        & 22.811        & 0.019            \\ \hline
DeepPhys       & UBFC           & PURE          & 72                 & 5                  & 23.027       & 33.922        & 24.852        & 0.392            \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 10                 & 0.977        & 2.748         & 1.069         & 0.975            \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 20                 & 2.148        & 3.262         & 2.04          & 0.965            \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 30                 & 3.809        & 9.329         & 3.283         & 0.537            \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 5                  & 0.721        & 2.252         & 0.722         & 0.981            \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 10                 & 0.879        & 1.758         & 0.893         & 1                \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 20                 & 0            & 0             & 0             & 1                \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 30                 & 0            & 0             & 0             & 1                \\ \hline
DeepPhys       & UBFC           & UBFC          & 72                 & 5                  & 4.688        & 11.951        & 4.663         & 0.775            \\ \hline
EfficientPhys  & PURE           & PURE          & 72                 & 10                 & 0.567        & 1.412         & 0.94          & 0.991            \\ \hline
EfficientPhys  & PURE           & PURE          & 72                 & 20                 & 0            & 0             & 0             & 1                \\ \hline
EfficientPhys  & PURE           & PURE          & 72                 & 30                 & 0.176        & 0.556         & 0.333         & 0.999            \\ \hline
EfficientPhys  & PURE           & PURE          & 72                 & 5                  & 0.974        & 2.616         & 1.474         & 0.969            \\ \hline
EfficientPhys  & PURE           & UBFC          & 72                 & 10                 & 1.278        & 6.402         & 1.313         & 0.938            \\ \hline
EfficientPhys  & PURE           & UBFC          & 72                 & 20                 & 1.376        & 5.991         & 1.373         & 0.942            \\ \hline
EfficientPhys  & PURE           & UBFC          & 72                 & 3                  & 4.344        & 12.343        & 4.412         & 0.792            \\ \hline
EfficientPhys  & PURE           & UBFC          & 72                 & 30                 & 1.43         & 5.837         & 1.395         & 0.942            \\ \hline
EfficientPhys  & PURE           & UBFC          & 72                 & 5                  & 2.208        & 8.455         & 2.197         & 0.892            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 10                 & 3.33         & 12.931        & 3.543         & 0.834            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 20                 & 2.49         & 11.287        & 2.514         & 0.873            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 3                  & 8.358        & 18.714        & 10.177        & 0.566            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 30                 & 1.743        & 8.45          & 2.02          & 0.93             \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 5                  & 5.794        & 15.515        & 7.061         & 0.748            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 10                 & 13.887       & 23.307        & 14.522        & 0.746            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 20                 & 15.625       & 28.416        & 14.746        & 0.633            \\ \hline
EfficientPhys  & UBFC           & PURE          & 72                 & 5                  & 15.044       & 26.045        & 15.182        & 0.668            \\ \hline
EfficientPhys  & UBFC           & UBFC          & 72                 & 10                 & 0.586        & 2.269         & 0.675         & 0.979            \\ \hline
EfficientPhys  & UBFC           & UBFC          & 72                 & 20                 & 2.197        & 3.479         & 2.035         & 0.95             \\ \hline
EfficientPhys  & UBFC           & UBFC          & 72                 & 30                 & 3.516        & 8.292         & 3.048         & 0.536            \\ \hline
EfficientPhys  & UBFC           & UBFC          & 72                 & 5                  & 0.27         & 1.379         & 0.268         & 0.99             \\ \hline
TSCAN          & PURE           & PURE          & 72                 & 10                 & 0.68         & 1.547         & 1.079         & 0.981            \\ \hline
TSCAN          & PURE           & PURE          & 72                 & 20                 & 0.117        & 0.454         & 0.163         & 0.999            \\ \hline
TSCAN          & PURE           & PURE          & 72                 & 30                 & 0.176        & 0.556         & 0.333         & 0.998            \\ \hline
TSCAN          & PURE           & PURE          & 72                 & 5                  & 0.959        & 2.596         & 1.48          & 0.954            \\ \hline
TSCAN          & PURE           & UBFC          & 72                 & 10                 & 2.296        & 9.068         & 2.315         & 0.884            \\ \hline
TSCAN          & PURE           & UBFC          & 72                 & 20                 & 1.435        & 5.3           & 1.44          & 0.956            \\ \hline
TSCAN          & PURE           & UBFC          & 72                 & 3                  & 4.424        & 12.432        & 4.623         & 0.796            \\ \hline
TSCAN          & PURE           & UBFC          & 72                 & 30                 & 1.634        & 6.089         & 1.488         & 0.942            \\ \hline
TSCAN          & PURE           & UBFC          & 72                 & 5                  & 2.388        & 8.85          & 2.467         & 0.89             \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 10                 & 3            & 12.098        & 3.286         & 0.859            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 20                 & 3.249        & 12.525        & 3.265         & 0.846            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 3                  & 8.232        & 18.453        & 9.62          & 0.588            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 30                 & 1.628        & 7.435         & 1.924         & 0.948            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 5                  & 5.093        & 14.907        & 6.069         & 0.777            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 10                 & 24.609       & 37.156        & 24.768        & 0.366            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 20                 & 24.805       & 38.792        & 21.923        & 0.417            \\ \hline
TSCAN          & UBFC           & PURE          & 72                 & 5                  & 22.075       & 34.563        & 22.586        & 0.364            \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 10                 & 1.367        & 3.612         & 1.48          & 0.955            \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 20                 & 2.148        & 3.262         & 2.04          & 0.965            \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 30                 & 4.688        & 9.574         & 4.064         & 0.513            \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 5                  & 0.361        & 1.592         & 0.368         & 0.989            \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 10                 & 0            & 0             & 0             & 1                \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 20                 & 0            & 0             & 0             & 1                \\ \hline
TSCAN          & UBFC           & UBFC          & 72                 & 5                  & 4.922        & 13.525        & 4.911         & 0.763            \\ \hline
\end{longtable}


\end{document}
