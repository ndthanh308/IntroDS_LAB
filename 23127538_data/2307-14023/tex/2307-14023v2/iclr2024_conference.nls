
\begin{thenomenclature} 
\nomgroup{A}
  \item [{\(a\)}]\begingroup A scalar\nomeqref {20}\nompageref{18}
  \item [{\(\va\)}]\begingroup A vector\nomeqref {20}\nompageref{18}
  \item [{\(\mA\)}]\begingroup A matrix\nomeqref {20}\nompageref{18}
  \item [{$n$}]\begingroup The length of an input sequence\nomeqref {20}\nompageref{18}
  \item [{$N$}]\begingroup The number of input sequences\nomeqref {20}\nompageref{18}
  \item [{$C$}]\begingroup The number of output classes\nomeqref {20}\nompageref{18}
  \item [{$d$}]\begingroup Embedding dimension\nomeqref {20}\nompageref{18}
  \item [{\(\mX^{(i)}\)}]\begingroup $i$-th input sequence, consisting of $n$ tokens of embedding dimension $d$\nomeqref {20}\nompageref{18}
\nomgroup{B}
  \item [{\(\R\)}]\begingroup Set of real numbers\nomeqref {20}\nompageref{18}
  \item [{\(\mathbb{N}_+\)}]\begingroup Set of positive integers\nomeqref {20}\nompageref{18}
  \item [{\([m]\)}]\begingroup Set of all integers from $1$ to $m$\nomeqref {20}\nompageref{18}
  \item [{\([a,b]\)}]\begingroup Closed interval from $a$ to $b$\nomeqref {20}\nompageref{18}
  \item [{\(\mathcal{V}^{(i)}\)}]\begingroup $i$-th vocabulary set\nomeqref {20}\nompageref{18}
\nomgroup{C}
  \item [{\(a_i\)}]\begingroup Element $i$ of vector $\va$, with indexing starting at $1$\nomeqref {20}\nompageref{18}
  \item [{\(A_{i,j}\)}]\begingroup Element $i, j$ of matrix $\mA$\nomeqref {20}\nompageref{18}
  \item [{\(\mA_{:, i}\)}]\begingroup Column $i$ of matrix $\mA$\nomeqref {20}\nompageref{18}
  \item [{\(\mA_{i, :}\)}]\begingroup Row $i$ of matrix $\mA$\nomeqref {20}\nompageref{18}
\nomgroup{F}
  \item [{$\lVert\vx\rVert$}]\begingroup $\ell^2$ norm of $\vx$\nomeqref {20}\nompageref{18}
  \item [{$\lVert\vx\rVert_p$}]\begingroup $\ell^p$ norm of $\vx$\nomeqref {20}\nompageref{18}
  \item [{\(\1_\mathrm{condition}\)}]\begingroup is 1 if the condition is true, 0 otherwise\nomeqref {20}\nompageref{18}
  \item [{$\dist_p(f_1,f_2)$}]\begingroup $\left(\int\left\lVert f_1(\mathbf{X})-f_2(\mathbf{X})\right\rVert_p^p \mathrm{d} \mathbf{X}\right)^{1 / p}$\nomeqref {20}\nompageref{18}
  \item [{$\sigma_S$}]\begingroup Softmax function\nomeqref {20}\nompageref{18}
  \item [{$\sigma_H$}]\begingroup Hardmax function\nomeqref {20}\nompageref{18}
  \item [{$\sigma_R$}]\begingroup ReLU activation function\nomeqref {20}\nompageref{18}
  \item [{$\mathcal{F}^{(SA)}_H$}]\begingroup Hardmax-based self-attention mechanism with a skip-connection\nomeqref {20}\nompageref{18}
  \item [{$\mathcal{F}^{(SA)}_S$}]\begingroup Softmax-based self-attention mechanism with a skip-connection\nomeqref {20}\nompageref{18}
  \item [{$\mathcal{F}^{(FF)}$}]\begingroup Feed-forward neural network with a skip-connection\nomeqref {20}\nompageref{18}
  \item [{$\boltz$}]\begingroup Boltzmann opeartor\nomeqref {20}\nompageref{18}

\end{thenomenclature}
