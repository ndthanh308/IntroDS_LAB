@book{BoydVandenbergheConvex2004,
  author = {Boyd, Stephen and Vandenberghe, Lieven},
  publisher = {{Cambridge University Press}},
  title = {Convex Optimization},
  url = {https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf},
  year = 2004
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@phdthesis{littman_algorithms_1996, author = {Littman, Michael Lederman}, title = {Algorithms for Sequential Decision-Making}, year = {1996}, isbn = {0591163500}, publisher = {Brown University}, address = {USA}, abstract = {Sequential decision making is a fundamental task faced by any intelligent agent in an extended interaction with its environment; it is the act of answering the question "What should I do now?" In this thesis, I show how to answer this question when "now" is one of a finite set of states, "do" is one of a finite set of actions, "should" is maximize a long-run measure of reward, and "I" is an automated planning or learning system (agent). In particular, I collect basic results concerning methods for finding optimal (or near-optimal) behavior in several different kinds of model environments: Markov decision processes, in which the agent always knows its state; partially observable Markov decision processes (scPOMDPS), in which the agent must piece together its state on the basis of observations it makes; and Markov games, in which the agent is in direct competition with an opponent. The thesis is written from a computer-science perspective, meaning that many mathematical details are not discussed, and descriptions of algorithms and the complexity of problems are emphasized. New results include an improved algorithm for solving scPOMDPS exactly over finite horizons, a method for learning minimax-optimal policies for Markov games, a pseudopolynomial bound for policy iteration, and a complete complexity theory for finding zero-reward scPOMDP policies.}, note = {AAI9709069} }


@article{hornik_approximation_1991,
title = {Approximation capabilities of multilayer feedforward networks},
journal = {Neural Networks},
volume = {4},
number = {2},
pages = {251-257},
year = {1991},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(91)90009-T},
url = {https://www.sciencedirect.com/science/article/pii/089360809190009T},
author = {Kurt Hornik},
keywords = {Multilayer feedforward networks, Activation function, Universal approximation capabilities, Input environment measure, () approximation, Uniform approximation, Sobolev spaces, Smooth approximation},
abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(μ) performance criteria, for arbitrary finite input environment measures μ, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.}
}

@article{funahashi_on_1989,
title = {On the approximate realization of continuous mappings by neural networks},
journal = {Neural Networks},
volume = {2},
number = {3},
pages = {183-192},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90003-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900038},
author = {Ken-Ichi Funahashi},
keywords = {Neural network, Back propagation, Output function, Sigmoid function, Hidden layer, Unit, Realization, Continuous mapping},
abstract = {In this paper, we prove that any continuous mapping can be approximately realized by Rumelhart-Hinton-Williams' multilayer neural networks with at least one hidden layer whose output functions are sigmoid functions. The starting point of the proof for the one hidden layer case is an integral formula recently proposed by Irie-Miyake and from this, the general case (for any number of hidden layers) can be proved by induction. The two hidden layers case is proved also by using the Kolmogorov-Arnold-Sprecher theorem and this proof also gives non-trivial realizations.}
}

@ARTICLE{huang_upper_1998,
  author={Guang-Bin Huang and Babri, H.A.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Upper bounds on the number of hidden neurons in feedforward networks with arbitrary bounded nonlinear activation functions}, 
  year={1998},
  volume={9},
  number={1},
  pages={224-229},
  doi={10.1109/72.655045}}

@ARTICLE{huang_learning_2003,
  author={Guang-Bin Huang},
  journal={IEEE Transactions on Neural Networks}, 
  title={Learning capability and storage capacity of two-hidden-layer feedforward networks}, 
  year={2003},
  volume={14},
  number={2},
  pages={274-281},
  doi={10.1109/TNN.2003.809401}}

@article{vershynin_memory_2020,
author = {Vershynin, Roman},
title = {Memory Capacity of Neural Networks with Threshold and Rectified Linear Unit Activations},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {2},
number = {4},
pages = {1004-1033},
year = {2020},
doi = {10.1137/20M1314884},

URL = {

        https://doi.org/10.1137/20M1314884



},
eprint = {

        https://doi.org/10.1137/20M1314884



}
,
    abstract = { Overwhelming theoretical and empirical evidence shows that mildly overparametrized neural networks---those with more connections than the size of the training data---are often able to memorize the training data with 100\% accuracy. This was rigorously proved for networks with sigmoid activation functions [M. Yamasaki, Proceedings of the International Conference on Artificial Neural Networks, 1993, pp. 546--549; G.-B. Huang, IEEE Trans. Neural Netw., 14 (2003), pp. 274--281] and, very recently, for rectified linear unit (ReLU) activations [C. Yun, S. Sra, and A. Jadbabaie, Proceedings of the Conference on Neural Information Processing Systems, 2019, pp. 15532--15543]. Addressing a open question of Baum [J. Complexity, 4 (1988), pp. 193--215], we prove that this phenomenon holds for general multilayered perceptrons, i.e., neural networks with threshold activation functions, or with any mix of threshold and ReLU activations. Our construction is probabilistic and exploits sparsity. }
}

@article{
belkin_reconciling_2019,
author = {Mikhail Belkin  and Daniel Hsu  and Siyuan Ma  and Soumik Mandal },
title = {Reconciling modern machine-learning practice and the classical bias–variance trade-off},
journal = {Proceedings of the National Academy of Sciences},
volume = {116},
number = {32},
pages = {15849-15854},
year = {2019},
doi = {10.1073/pnas.1903070116},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1903070116},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1903070116},
abstract = {Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias–variance trade-off, appears to be at odds with the observed behavior of methods used in modern machine-learning practice. The bias–variance trade-off implies that a model should balance underfitting and overfitting: Rich enough to express underlying structure in data and simple enough to avoid fitting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This “double-descent” curve subsumes the textbook U-shaped bias–variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine-learning models delineates the limits of classical analyses and has implications for both the theory and the practice of machine learning.}}

@inproceedings{kratsios_universal_2021,
        title = {Universal {Approximation} {Under} {Constraints} is {Possible} with {Transformers}},
        url = {https://openreview.net/forum?id=JGO8CvG5S9},
        abstract = {Many practical problems need the output of a machine learning model to satisfy a set of constraints, \$K\$. Nevertheless, there is no known guarantee that classical neural network architectures can exactly encode constraints while simultaneously achieving universality. We provide a quantitative constrained universal approximation theorem which guarantees that for any non-convex compact set \$K\$ and any continuous function \$f:{\textbackslash}mathbb\{R\}{\textasciicircum}n{\textbackslash}rightarrow K\$, there is a probabilistic transformer \${\textbackslash}hat\{F\}\$ whose randomized outputs all lie in \$K\$ and whose expected output uniformly approximates \$f\$. Our second main result is a ``deep neural version'' of Berge's Maximum Theorem (1963). The result guarantees that given an objective function \$L\$, a constraint set \$K\$, and a family of soft constraint sets, there is a probabilistic transformer \${\textbackslash}hat\{F\}\$ that approximately minimizes \$L\$ and whose outputs belong to \$K\$; moreover, \${\textbackslash}hat\{F\}\$ approximately satisfies the soft constraints. Our results imply the first universal approximation theorem for classical transformers with exact convex constraint satisfaction. They also yield that a chart-free universal approximation theorem for Riemannian manifold-valued functions subject to suitable geodesically convex constraints.},
        language = {en},
        urldate = {2023-11-17},
        author = {Kratsios, Anastasis and Zamanlooy, Behnoosh and Liu, Tianlin and Dokmanić, Ivan},
        month = oct,
        year = {2021},
        file = {Full Text PDF:/Users/tokio/Zotero/storage/W5YE6MW5/Kratsios et al. - 2021 - Universal Approximation Under Constraints is Possi.pdf:application/pdf},
}

@article{bartlett_nearly_2019,
  author  = {Peter L. Bartlett and Nick Harvey and Christopher Liaw and Abbas Mehrabian},
  title   = {Nearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {63},
  pages   = {1--17},
  url     = {http://jmlr.org/papers/v20/17-612.html}
}