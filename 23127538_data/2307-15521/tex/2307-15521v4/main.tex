% =========================================================================
% SciPost LaTeX template
% Version 2021-08
%
% Submissions to SciPost Journals should make use of this template.
%
% INSTRUCTIONS: simply look for the `TODO:' tokens and adapt your file.
%
% You can also make use of our empty "skeleton" templates for each Journal,
% e.g. SciPostPhys_skeleton.tex
% =========================================================================

% TODO: uncomment ONE of the class declarations below

% Class declaration format: \documentclass[submission, {DOI label of journal}]{SciPost}
% where the DOI label of the journal should be one of:
% Phys          (for SciPost Physics)
% PhysCore      (for SciPost Physics Core)
% PhysLectNotes (for SciPost Physics Lecture Notes)
% PhysProc      (for SciPost Physics Proceedings -> !! Please use the conference-specific template which you will find on our website !!
% PhysCodeb     (for SciPost Physics Codebases)
% Astro         (for SciPost Astronomy)
% Bio           (for SciPost Biology)
% Chem          (for SciPost Chemistry)
% CompSci       (for SciPost Computer Science)
% Math          (for SciPost Mathematics)

%% PHYSICS:
% If you are submitting a paper to SciPost Physics: uncomment next linehttps://www.overleaf.com/project/64057a62ee02d2f3c664122d
\documentclass[submission,Phys]{SciPost}
% If you are submitting a paper to SciPost Physics Core: uncomment next line
%\documentclass[submission, PhysCore]{SciPost}
% If you are submitting a paper to SciPost Physics Lecture Notes: uncomment next line
%\documentclass[submission, PhysLectNotes]{SciPost}
% If you are submitting a paper to SciPost Physics Proceedings: uncomment next line
%\documentclass[submission, PhysProc]{SciPost}
% If you are submitting a paper to SciPost Physics Codebases: uncomment next line
%\documentclass[submission, PhysCodeb]{SciPost}

\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\jj}{$J_1$--$J_2$}
\usepackage{soul}

% Prevent all line breaks in inline equations.
\binoppenalty=10000
\relpenalty=10000

\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\usepackage[bitstream-charter]{mathdesign}
\urlstyle{sf}

% Fix \cal and \mathcal characters look (so it's not the same as \mathscr)
\DeclareSymbolFont{usualmathcal}{OMS}{cmsy}{m}{n}
\DeclareSymbolFontAlphabet{\mathcal}{usualmathcal}

\begin{document}

% TODO: write your article's title here.
% The article title is centered, Large boldface, and should fit in two lines
% Article Title, as descriptive as possible, ideally fitting in two lines (approximately 150 characters) or less
\begin{center}{\Large \textbf{
Scalable Imaginary Time Evolution with Neural Network Quantum States \\
}}\end{center}

% TODO: write the author list here. Use first name (+ other initials) + surname format.
% Separate subsequent authors by a comma, omit comma and use "and" for the last author.
% Mark the corresponding author with a superscript star.
\begin{center}
Eimantas Ledinauskas\textsuperscript{1,2$\star$} and
Egidijus Anisimovas\textsuperscript{1}
\end{center}

% TODO: write all affiliations here.
% Format: institute, city, country
\begin{center}
{\bf 1} Institute of Theoretical Physics and Astronomy, Vilnius University\\
Saul\.{e}tekio al.\ 3, LT-10257, Vilnius, Lithuania
\\
{\bf 2} Baltic Institute of Advanced Technology, Pilies St. 16-8, LT-01403, Vilnius, Lithuania
\\

% TODO: provide email address of corresponding author
${}^\star$ {\small \sf eimantas.ledinauskas@ff.stud.vu.lt}
\end{center}

\begin{center}
\today
\end{center}

% For convenience during refereeing (optional),
% you can turn on line numbers by uncommenting the next line:
%\linenumbers
% You should run LaTeX twice in order for the line numbers to appear.

\section*{Abstract}
{\bf
% TODO: write your abstract here.

The representation of a quantum wave function as a neural network quantum state (NQS) provides a powerful variational ansatz for finding the ground states of many-body quantum systems. Nevertheless, due to the complex variational landscape, traditional methods often employ the computation of quantum geometric tensor, consequently complicating optimization techniques. Contributing to efforts aiming to formulate alternative methods, we introduce an approach that bypasses the computation of the metric tensor and instead relies exclusively on first-order gradient descent with Euclidean metric. This allows for the application of larger neural networks and the use of more standard optimization methods from other machine learning domains. Our approach leverages the principle of imaginary time evolution by constructing a target wave function derived from the Schrödinger equation, and then training the neural network to approximate this target. We make this method adaptive and stable by determining the optimal time step and keeping the target fixed until the energy of the NQS decreases. We demonstrate the benefits of our scheme via numerical experiments with 2D \jj\, Heisenberg model, which showcase enhanced stability and energy accuracy in comparison to direct energy loss minimization. Importantly, our approach displays competitiveness with the well-established density matrix renormalization group method and NQS optimization with stochastic reconfiguration.
}

% TODO: include a table of contents (optional)
% Guideline: if your paper is longer that 6 pages, include a TOC
% To remove the TOC, simply cut the following block
\vspace{10pt}
\noindent\rule{\textwidth}{1pt}
\tableofcontents\thispagestyle{fancy}
\noindent\rule{\textwidth}{1pt}
\vspace{10pt}

\section{Introduction}
\label{sec:intro}

The remarkable accomplishments in applying machine learning techniques to a wide range of practical \cite{LeCun2015,attention_is_all_you_need,vision_transformer,Liu2021,Otter2021,patches_are_all_you_need} and curiosity-driven \cite{Silver2016,Silver2018,Perolat2022} tasks have prompted the adoption of innovative concepts and approaches in the field of physical sciences; see e.g.\ Refs.\ \cite{Mehta2019,rmp_review,carra_review,carra_tutorial,neupert_lect,dawid_lect} for recent physics-motivated reviews and tutorials. 
In particular, in the numerical study of quantum many-body systems \cite{AvellaMancini2013} one promising line of development rests on the observation that, given a suitable many-body basis, a pure quantum-mechanical state can be represented by a multivariate function that assigns a complex number to a given basis element. For a typical quantum state of interest, such a wave function is an overwhelmingly complex entity, as the amount of information needed to fully encode a state in this manner grows exponentially with the system size. 
On the other hand, it is fitting to note that  many classes of neural network architectures are recognized \cite{Kolmogorov,Hornik1989,Cybenko1992,devore2020,Blanchard2021} as efficient function approximators: an arbitrary well-behaved function can be represented with a desired accuracy given a sufficient number of parameters, i.e.\ a sufficient neural network width or depth. Note, however, that such \emph{universal approximation theorems} \cite{devore2020} only establish that a representation of a given function is possible, without providing an explicit scheme to construct such a representation.

The idea to represent a quantum wave function as a neural network quantum state (NQS) \cite{Carleo_first_NQS,rmp_review,dawid_lect,Netket0,Netket,rnn_nqs_allah,autoregressive_CNN_NQS,j1j2_1d_transformer,real_time_evolution_2019}, can be viewed as a very powerful variational ansatz that aligns well with the well-established variational Monte-Carlo (VMC) \cite{qmc2001,Becca2017} techniques to search for the ground state. In the general application framework, the approach typically includes the following elements: (I) The variational wavefunction $\psi_{\theta}$ is parameterized in terms of the network weights $\theta$, and the expectation value of the studied Hamiltonian $H$ (the variational energy) 
$E (\theta) = \langle \psi_{\theta} | H | \psi_{\theta} \rangle$ 
is identified as the objective function to be minimized, i.e. the \emph{loss} function. (II) Since a direct computation of $E (\theta)$ is not feasible due to prohibitively large configuration space, $E(\theta)$ is estimated as a stochastic average from a set of sampled configurations. Note that sampling can be performed either relying on a Markov chain of configurations \cite{Carleo_first_NQS,j1j2_challenges} or direct sampling from a neural network endowed with the autoregressive property \cite{rnn_nqs_allah,autoregressive_CNN_NQS,gauge_invariant_autoregressive_NQS}. (III) Since the variational landscapes of NQS states are rugged and difficult to navigate in the search of the ground state (see, e.g., the study reported in Ref.~\cite{j1j2_challenges}), the stochastic reconfiguration (SR) method \cite{SR_paper,Sorella2001} is often used instead of some variant of direct gradient-based descent \cite{Ruder2017grad}. According to the geometric interpretation \cite{Park2020,Amari1998}, the benefits provided by the SR method stem from the correct determination of the non-Euclidean manifold structure of the space of quantum states. Thus, the minimization direction suggested by the raw gradient, $- \nabla_{\theta} E(\theta)$, is less meaningful than the 'natural' Riemannian gradient \cite{Amari1998,Stokes2020quantumnatural} corrected by the inverse of the local metric tensor $G(\theta)$. The educated update of parameters is made along the direction of $-G^{-1}(\theta) \nabla_{\theta} E (\theta)$. However, while using the metric tensor may improve the convergence, it comes with a substantial computational cost since the metric tensor is of the order $N_\theta \times N_\theta$, where $N_\theta$ represents the number of NQS variational parameters. Consequently, determining and calculating the (pseudo)inverse of the metric tensor becomes computationally expensive \cite{Mehta2019} and results in poor scaling with the system size \cite{Zhang2023}. This issue imposes significant limitations on the practical size of neural networks that can be utilized. The scaling of SR can be enhanced by employing iterative solvers that avoid forming or inverting the tensor (e.g., see the implementation of SR in NetKet \cite{netket2_2019,netket3_2022}). However, this still adds a significant computational cost and also increases the numerical instability, which necessitates adding a small diagonal shift to stabilize the method, which, in turn, reduces the precision of the estimated metric.

An alternative approach emerged recently, in which energy is not minimized directly. Rather, a target wave function, more proximate to the ground state, is crafted by employing the approximate imaginary time evolution and the issue is reformulated into a conventional regression problem \cite{supervised_opt_Kochkov2018, nqs_power_iteration_2023, supervised_ITE_Atanasova2023}. In the present paper, we focus on this alternative methodology, refining and integrating modifications to shape it into a novel scheme that enhances its performance and stability. Firstly, we employ the more natural overlap loss function instead of the mean square error loss function, as introduced in works concerned with the real-time evolution \cite{Bjarni2018_overlap_loss, Medvidovic2021_overlap_loss, Sinibaldi2023_overlap_loss}. Secondly, we derive the expression for the adaptive optimal imaginary time step. Thirdly, instead of updating the target wave function after each step, we fix the target for multiple steps to stabilize the learning process and establish criteria for determining when the target should be updated. We also explore the relationship between our scheme and direct energy minimization, demonstrating that they become equivalent when the target wave function is updated after every time step. This may elucidate why utilizing energy as a loss function does not always work well and requires more sophisticated methods like SR. Our simulations indicate that, with our proposed optimization scheme, the NQS is able to avoid being trapped in the numerous saddle points of the optimization landscape, eliminating the need for metric tensor computations and operating effectively with solely first-order gradient descent. We validate the efficacy of this scheme by applying it to the two-dimensional \jj\, Heisenberg model \cite{Wang2018,Ferrari2020}, demonstrating that the proposed approach is competitive with direct energy loss minimization using first-order gradients or SR, as well as with density-matrix renormalization (DMRG) \cite{Schollwock2011,Orus2019}.

Our paper is organized as follows. Section~\ref{sec:method} provides an overview of the proposed scheme for ground-state search and describes the neural network optimization procedure. While the process assumes that the state is represented by a neural network, it is versatile and can be used with diverse network architectures. Thus, in Section~\ref{sec:nnqs} we describe the specific architecture used in our work. It is based on a multilayer perceptron (MLP) \cite{goodfellow2016deep} coupled with a preprocessing step inspired by vision transformers \cite{vision_transformer,patches_are_all_you_need}. The physical model used for testing, i.e.\ the two-dimensional spin-$\tfrac{1}{2}$ \jj\, model, and the results of numerical experiments are discussed in Section~\ref{sec:results}. Finally, we conclude with a brief summarizing Section~\ref{sec:conclusion}. A number of technical derivations are included in Appendices.


\section{Proposed method for ground state search with NQS}
\label{sec:method}

\subsection{Problem definition and notation}

The focus of our work is the ground-state search for many-particle quantum systems defined on a lattice. More specifically, we study two-dimensional (2D) square lattices, however, the described methods can be straightforwardly generalized to other lattice geometries and dimensionalities. In such systems, the space of quantum states can be modeled as a Cartesian product of identical single-site state spaces $\mathcal{\mathscr{H}} = \bigotimes_{j=1}^{N}\mathcal{\mathscr{H}}_{1}$, where $N$ is the number of lattice sites and $\mathcal{\mathscr{H}}_{1}$ is the state space characterizing a single site. 

We choose to work in the product basis $|\boldsymbol{s}\rangle = \bigotimes_{j=1}^{N}|s_{j}\rangle$, where $|s_{j}\rangle$ corresponds to a basis vector of $\mathcal{\mathscr{H}}_{1}$ on the $j$-th site. These basis states can be indexed with $N$-tuples $\boldsymbol{s}=(s_{1},...,s_{N})$, thus we can introduce the notation $|\boldsymbol{s}\rangle=|s_{1},...,s_{N}\rangle$. For example, in the case of spin-1/2 particles occupying lattice sites we can choose $|s_{j}\rangle\in\{|\uparrow\rangle,|\downarrow\rangle\}$, where $|\uparrow\rangle$ and $|\downarrow\rangle$ are the eigenstates of the spin operator $\hat{S}_{z}$. In this basis, the wave function is represented as a complex-valued vector
\begin{equation}
    |\psi\rangle=\sum_{s_{1},...,s_{N}} \psi_{s_{1},...,s_{N_{s}}}|s_{1},...,s_{N} \rangle     \,.
\end{equation}
The dimension of the vector space spanned by the basis vectors $|s_{1},...,s_{N}\rangle$ grows exponentially with increasing system size and rather quickly it becomes impractical to numerically represent and manipulate the wave function directly as an array. To model such directly intractable systems, Ref.~\cite{Carleo_first_NQS} proposed using a neural network which maps basis vectors $|s_{1},...,s_{N}\rangle$ to the corresponding wave function amplitudes $\psi_{s_{1},...,s_N}$; this representation has become known as the NQS. The overarching motivation stems from the observation that in spite of the exponential scaling of the number of basis elements, typical ground states of physically realizable Hamiltonians  have a simplified internal structure \cite{Orus2019} that should allow for representations in terms of a relatively small number of parameters. On the other hand, neural networks excel precisely at the task of finding efficient representations of intricate data structures.

\subsection{Imaginary time evolution with NQS}
\label{sec:imag_time_evolution}
Imaginary time evolution is a well-known method for extracting the ground state from an arbitrary initial ansatz that is not strictly orthogonal to the sought ground state. In the energy-eigenstate basis the time-dependent Schr\"{o}dinger equation is solved by:
\begin{equation}
    |\psi\rangle =\sum_{j}\Psi_{j}(t)|e_{j}\rangle
\end{equation}
with
\begin{equation}
    \Psi_{j}(t) = \Psi_{j,0}e^{-iE_{j}t}
\end{equation}
where $E_{j}$, $|e_{j}\rangle$ are the $j$-th eigenvalue and eigenvector pair of the Hamiltonian $\hat{H}$ and the amplitudes $\Psi_{j,0}$ encode an arbitrary intial condition. If we now substitute in the imaginary time $\tau = it$, then with increasing $\tau$ the solution is expressed as an exponentially decaying (rather than the usual oscillating) superposition of energy eigenstates. The contributions of all the excited states decay exponentially relative to the ground state $|e_{0}\rangle$:
\begin{equation}
    \frac{|\Psi_{j}|}{|\Psi_{0}|}\propto e^{-(E_{j}-E_{0})\tau} \,.
\end{equation}
Thus, as $\tau \rightarrow \infty$, any initial state with nonzero overlap with $|e_{0}\rangle$ converges toward the ground state. It is important to note that with imaginary time the evolution becomes non-unitary and the norm of the wave function increases or decreases exponentially with time.

% \subsection{Imaginary time evolution with NQS}
% \label{sec:imag_time_evolution}

In Ref.~\cite{real_time_evolution_2019}, the authors demonstrate that real time evolution of a quantum system can be modeled with NQS by minimizing the error between the variational wave function and the target wave function which is obtained with discrete ODE solver:
\begin{equation}
    \label{eq:real_time_evo}
    \left\| |\psi_{m+1}\rangle - \Phi^{\Delta t}| \psi_{m}\rangle \right\|
\end{equation}
where $\Phi^{\Delta t}$ is the discrete ODE flow operator. Minimizing this error draws the variational wave function closer to the target, computed approximately from the Schrödinger equation, thereby simulating the temporal evolution of the NQS. A similar approach has also been applied to simulate imaginary time evolution \cite{supervised_opt_Kochkov2018, nqs_power_iteration_2023, supervised_ITE_Atanasova2023}.

In this work, we use the Euler method to compute the target wave function:
\begin{equation}
\label{eq:euler_step}
    |\psi_{T}\rangle=|\psi \rangle - \Delta\tau \hat{H}|\psi\rangle \,,
\end{equation}
that is, the wave function that is reached from the current wave function by a single linearized imaginary time evolution step $\Delta\tau$. We note that for Hamiltonians consisting of only local terms, the matrix $H_{\mathbf{ss}'} = \langle \mathbf{s} | \hat{H} | \mathbf{s}' \rangle$ is sparse, i.e., given some $\mathbf{s}'$, only a small number of elements $H_{\mathbf{ss}'}$ are non-zero. This enables the efficient computation of the target wave function
\begin{equation}
    \label{eq:euler_step_elements}
    \psi_T(\mathbf{s}) = \psi(\mathbf{s}) - \Delta \tau \sum_{\mathbf{s}'} H_{\mathbf{ss}'} \psi(\mathbf{s}'),
\end{equation}
from the current state of the neural network. We perform a single time step to obtain a target and then train the variational NQS. Performing a second time step is not practical for large systems, as it would necessitate an additional application of the Hamiltonian to the resulting target wave function. This would change the copmutational complexity scaling from linear to quadratic with respect to system size (as similarly described in Eq. \ref{eq:energy_norms_4}).  

As NQS cannot perfectly fit the target function, the resulting evolution is inherently noisy. Nevertheless, Ref. \cite{nqs_power_iteration_2023} has established a convergence guarantee for this type of evolution.

\subsection{Loss function}
\label{sec:loss_func}

Multiple different loss functions can be used to maximize the consistency between the current wave function, $|\psi \rangle$, and the target wave function, $| \psi_T \rangle$. We experimented with several variants and found that the following loss function based on overlap works well in practice:
\begin{equation}
\label{eq:loss_func}
    L =-\log \left[ \frac{|\langle\psi|\psi_{T}\rangle|^{2}}{\langle\psi|\psi\rangle\langle\psi_{T}|\psi_{T}\rangle} \right]
\end{equation}
where $|\psi\rangle$ denotes the NQS to be optimized and $|\psi_{T}\rangle$ denotes the target constructed by Eq.~(\ref{eq:euler_step}). This kind of overlap loss function has been employed in previous studies within the context of real-time evolution (e.g. \cite{Bjarni2018_overlap_loss, Medvidovic2021_overlap_loss, Sinibaldi2023_overlap_loss}). In the subsequent text, we will refer to this loss together with the target $|\psi_T \rangle$ as the \emph{ITE loss}. The gradient of ITE loss with respect to the variational NQS parameters $\theta$ can be estimated by using the following expression  (derivation is presented in the appendix, Sec.~\ref{sec:app_grad_of_ite_loss}):
\begin{equation}
\label{eq:loss_grad}
    \frac{\partial L}{\partial\theta} =2\Re\left\{ \left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}-\frac{1}{\left\langle \frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\right\rangle _{\boldsymbol{s}}}\left\langle \frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\right\} \,.
\end{equation}
The averages appearing in this equation can be estimated by sampling states, $\mathbf{s}$, according to the probability distribution, $|\psi(\mathbf{s})|^2$, and then utilizing $\langle f(\boldsymbol{s}) \rangle_{\boldsymbol{s}} \approx \frac{1}{N}\sum_{\boldsymbol{s}_j} f(\boldsymbol{s}_j)$, where $\boldsymbol{s}_j$ represents individual states from a finite sample. During optimization Eq.~(\ref{eq:loss_grad}) can be used directly without actually computing the loss. The gradients of NQS $\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})$ can be calculated by utilizing the automatic differentiation provided by deep learning libraries.

The intuition behind the approach can be explained as follows: The ITE loss pushes for an alignment between the current wave function $|\psi\rangle$ and the target $|\psi_T\rangle$. On the other hand, the two states are related by an imaginary time step, hence, in the target $|\psi_T\rangle$ all components spanned by low-energy eigenstates are exponentially amplified, and all components spanned by high-energy eigenstates are exponentially suppressed. Now, since the target is kept fixed for a number of optimization steps, the update of the weights of the neural network encoding the current state $|\psi\rangle$ will effectively drive towards the minimization of the state energy, i.e., towards the ground state.

\subsection{Adaptive imaginary time step}
\label{sec:adaptive_tau}

In the case of the Euler's method, Eq.~(\ref{eq:euler_step}) can be used to obtain the following relation between the average energy of the target wave function and imaginary time step, $\Delta \tau$:
\begin{equation}
    \label{eq:next_step_energy}
    \langle E_T \rangle = \frac{\langle\psi_{T}| \hat{H} |\psi_{T}\rangle}{\langle \psi_T | \psi_T \rangle} = \frac{\langle E \rangle - 2\Delta\tau \langle E^2 \rangle + \Delta\tau^2 \langle E^3 \rangle}{1 - 2\Delta\tau\langle E \rangle + \Delta\tau^2 \langle E^2 \rangle}
\end{equation}
where $\langle E^n \rangle = \langle\psi| \hat{H}^n |\psi\rangle / \langle \psi | \psi \rangle$. Setting $ \partial_{\Delta \tau} \langle E_T \rangle = 0$ one obtains a quadratic equation which is solved by:
\begin{equation}
    \label{eq:step_solution}
    \Delta\tau=\frac{B\pm\sqrt{B^{2}+4A\sigma^{2}}}{2A}
\end{equation}
where $A=\langle E^{2}\rangle^{2}-\langle E\rangle\langle E^{3}\rangle$, $B=\langle E\rangle\langle E^{2}\rangle-\langle E^{3}\rangle$, and $\sigma^2 = \langle E^2 \rangle - \langle E \rangle^2$. We use Eq.~(\ref{eq:step_solution}) to find the optimal time step which minimizes the energy of the target wave function. This significantly accelerates the convergence to the ground state. The energy averages required in Eq.~(\ref{eq:next_step_energy}), similar to the averages appearing in Eq.~(\ref{eq:loss_grad}), can be estimated by sampling basis states $\mathbf{s}$ according to the probability distribution, $|\psi(\mathbf{s})|^2$, and using the following equations:
\begin{align}
    \label{eq:energy_norms_1}
    \langle E\rangle  & =\left\langle H_{loc}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\,,\\
    \label{eq:energy_norms_2}
    \langle E^{2}\rangle  & =\left\langle |H_{loc}(\boldsymbol{s})|^{2}\right\rangle _{\boldsymbol{s}}\,,\\
    \label{eq:energy_norms_3}
    \langle E^{3}\rangle  & =\left\langle H_{loc}^{*}(\boldsymbol{s}) \left (H^2 \right)_{loc}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}
\end{align}
where $H_{loc}$ is defined by:
\begin{equation}
    H_{loc}(\boldsymbol{s}) = \sum\limits _{\boldsymbol{s}'}\frac{\psi(\boldsymbol{s}')}{\psi(\boldsymbol{s})}\langle \boldsymbol{s} |\hat{H}|\boldsymbol{s}' \rangle
\end{equation}
and $\left (H^2 \right)_{loc}$ is defined analogously but using $\hat{H}^2$ instead of $\hat{H}$. These expressions are widely known but for the sake of completeness, the derivations are presented in Appendix  \ref{sec:app_energy_moments}. The computation of $H_{loc}$ is efficient because in systems with local interactions (e.g. between nearest neighbors), the Hamiltonians are represented by highly sparse matrices, and only a small fraction of the terms in the sum need to be calculated.

In the case of local interactions the computational complexity of $H_{loc}$ scales linearly with system size and for $\left (H^2 \right)_{loc}$ it scales quadratically because it requires computing nested sums of matrix elements:
\begin{align}
    H_{loc}^{2}(\boldsymbol{s}) & =\sum_{\boldsymbol{s'}}\frac{\psi(\boldsymbol{s'})}{\psi(\boldsymbol{s})}\sum_{\boldsymbol{s''}}H_{\boldsymbol{ss''}}H_{\boldsymbol{s''s'}}\\
 & =\frac{1}{\psi(\boldsymbol{s})}\sum_{\boldsymbol{s''}}H_{\boldsymbol{ss''}}\sum_{\boldsymbol{s'}}\psi(\boldsymbol{s'})H_{\boldsymbol{s''s'}}
\end{align}
where $H_{\boldsymbol{ss'}} = \langle \boldsymbol{s} |\hat{H}| \boldsymbol{s'} \rangle$.
This means that the computation of $\langle E^{3} \rangle$ quickly becomes impractical with increasing system size. However, by experimenting we found that the following expression gives sufficient accuracy for the optimal time step calculation even though it is not strictly correct:
\begin{equation}
    \label{eq:energy_norms_4}
    \langle E^{3}\rangle \approx \left\langle H_{loc}(\boldsymbol{s}) |H_{loc}(\boldsymbol{s})|^{2}\right\rangle _{\boldsymbol{s}} \,.
\end{equation}

Consequently, with this approximation, the computational complexity of all required energy moments for our method scales linearly with the system size. 

\subsection{Relation between ITE loss and E loss}
\label{sec:relation_with_E_loss}

In many standard applications of NQS for the ground state search it is performed by directly utilizing the energy as the loss function. In that case, the gradient of the loss with respect to variational parameters is given by:
\begin{equation}
    \frac{\partial L_E}{\partial\theta} = 2\Re\left\{ \left\langle H_{loc}(\boldsymbol{s})  \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s}) \right\rangle _{\boldsymbol{s}}-\left\langle H_{loc}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\right\} \,.
\end{equation}
In this work, we refer to $L_E$ as \emph{E loss}. By plugging the expression for $| \psi_T \rangle$ from Eq.~(\ref{eq:euler_step_elements}) into Eq.~(\ref{eq:loss_func}) it can be shown that ITE loss with Euler step target becomes proportional to E loss (for derivation see Appendix \ref{sec:app_relation_between_losses}):
\begin{equation}
    \label{eq:loss_relation}
    \frac{\partial L}{\partial\theta} = \frac{\Delta\tau}{1 - \Delta\tau \langle E \rangle} \frac{\partial L_E}{\partial\theta} \,.
\end{equation}
So it would appear that ITE loss does not offer any advantages and it should perform more or less the same as E loss. However, it is only so in the case when the target wave function $|\psi_T \rangle$ is updated after every optimizer step. If instead it is held fixed for more than one step, Eq.~(\ref{eq:loss_relation}) does not apply.

The relationship presented in Eq.~(\ref{eq:loss_relation}) suggests an explanation for the poor performance of first-order gradient descent methods within the context of NQS ground state search. Using E loss is equivalent to fitting a constantly shifting target described by Eq.~(\ref{eq:euler_step_elements}). This perpetually changing target can destabilize stochastic gradient descent. A similar problem also arises within the context of deep reinforcement learning. For example, it is well established that using fixed targets significantly improves the performance of deep Q learning methods \cite{rl_dqn}. Similarly, in this work, we also demonstrate in Sec.~\ref{sec:E_vs_ITE_loss_experiment} that employing ITE loss with a fixed target can enhance stability and yield lower energy errors compared to E loss.

%\hl{<other possibility to improve E loss is to use midpoint instead of Euler>}

\subsection{NQS training procedure}
\label{sec:training_procedure}

As described in Sec.~\ref{sec:relation_with_E_loss}, computing $| \psi_T \rangle$ with the latest NQS parameters every optimizer step would make ITE loss equivalent to E loss up to a learning-rate multiplier. There are two simple methods to slow down the shift of the target: 1) using a duplicate neural network with weights given by the moving average of the neural network that is optimized; 2) using a duplicate neural network with fixed weights that are repeatedly updated after a certain number of optimizer steps. Both of these methods are widely used in reinforcement learning literature within the context of action value function learning \cite{rl_survey}. We chose to use the second method because in that case it is straightforward to utilize the optimal time step described in Sec.~\ref{sec:adaptive_tau} and also because it is a more natural fit for evolution with discrete time steps. 

We explored various approaches to control the update frequency of the fixed parameters and found that the following approach provides good consistency and efficiency. The target is fixed until the mean energy of the optimized NQS becomes smaller than $\langle E \rangle - \sigma_{E}$ where $\langle E \rangle$ is the energy of the fixed NQS and $ \sigma_{E}$ is the standard error of the mean-energy estimate.

In this paragraph, we provide a concise summary of the training procedure that simulates the imaginary time evolution. Training is split into multiple epochs where each epoch corresponds to a single discrete time step $\Delta \tau$. At the start of each epoch the energy moments $\left\langle E \right\rangle$, $\langle E^{2}\rangle$, $\langle E^{3}\rangle$ are estimated by sampling $N_E$ states according to the NQS with the latest parameters and utilizing Eqs.\ (\ref{eq:energy_norms_1}), (\ref{eq:energy_norms_2}), and (\ref{eq:energy_norms_4}). These estimates are then used to calculate the adaptive time step $\Delta \tau$ that minimizes the expected energy of $|\psi_T \rangle \rangle$ given by Eq.~(\ref{eq:next_step_energy}). The duplicate NQS that is used to compute the target wave function, $| \psi_{T} \rangle$, is updated only at the start of the epoch and is kept fixed until the next epoch. Conceptually this can be understood as fixing $| \psi_T \rangle$ until the next epoch. During the epoch, the loss function, given by Eq. (\ref{eq:loss_func}), is gradually minimized with stochastic gradient optimizer (ADAM\cite{adam_paper} in our case) so the optimized NQS becomes increasingly similar to $|\psi_T\rangle$ and the energy decreases. The epoch is terminated once the energy becomes smaller than the threshold value described in the previous paragraph. Accurately estimating the energy with a large number of basis state samples can be computationally expensive. To address this, we reuse the samples used in gradient estimation and then apply a running average to the resulting energies, reducing the noise. Please note that we employ this approximate scheme solely for energy estimation during the epoch to compare with the threshold. The threshold itself is computed more accurately with a large number of samples $N_E$, as described in the beginning of this paragraph. A simplified pseudocode of the training algorithm is provided in Alg. \ref{alg:training}.

\begin{algorithm}
\caption{NQS training with ITE loss} \label{alg:training}
\begin{algorithmic}

\State $\text{NQS} \, \gets \Call{randomInitialization}{ }$

\For{$N_\text{epochs}$}
    \State $\langle E \rangle, \, \langle E^2 \rangle, \, \langle E^3 \rangle, \, \sigma_E \, \gets \, \Call{energyStatistics}{NQS}$
    \State $\Delta \tau \, \gets \, \Call{optimalTimeStep}{\langle E \rangle, \, \langle E^2 \rangle, \, \langle E^3 \rangle}$
    \State $E_{\text{thr}} \, \gets \, \langle E \rangle - \sigma_E$
    \State $\text{NQS}_{\text{fixed}} \, \gets \, \Call{copy}{\text{NQS}} $
    \State $s_{\text{mcmc}} \, \gets \, \Call{warmupMCMC}{\text{NQS}}$ \Comment{initial batch of basis states for MCMC sampling}

    \While{$\langle E \rangle > E_{\text{thr}}$}
        \State  $ s_{\text{batch}}, \, s_{\text{mcmc}} \gets \Call{sampleMCMC}{\text{NQS}, \, s_{\text{mcmc}}}$
        \State $\psi_{\text{target}} \, \gets \, \Call{computeTarget}{\text{NQS}_{\text{fixed}}, \, s_{\text{batch}}, \, \Delta\tau}$
        \State $\text{grad} \, \gets \, \Call{lossGradient}{\text{NQS}, \, \psi_{\text{target}}, \, s_{\text{batch}}}$
        \State $\text{NQS} \, \gets \, \Call{updateParameters}{\text{NQS}, \, \text{grad}}$
        \State $\langle E \rangle \, \gets \, \Call{movingAverageEnergy}{\text{NQS}, \, s_{\text{batch}}}$
    \EndWhile
\EndFor

\end{algorithmic}
\end{algorithm}

The optimization scheme we presented has similarities with the one described in Ref. \cite{supervised_opt_Kochkov2018}. However, we employ a different loss function, utilize different criteria for epoch termination, and incorporate an adaptive time step, which significantly enhances the convergence rate.

\section{Neural network quantum state}
\label{sec:nnqs}

\subsection{Neural network architecture}

The existing literature on NQS encompasses a wide range of neural network architectures. For example, Ref.~\cite{saito2017_mlp_hubbard} used multilayer perceptrons (MLPs), Ref.~\cite{stokes2020_cnn_fermions} used convolutional neural networks (CNNs), Ref.~\cite{rnn_nqs_allah} used recurrent neural networks (RNNs), and Ref.~\cite{j1j2_1d_transformer} used transformers. In this work, we chose to employ MLPs since our preliminary experiments indicated that they offer the best balance between the required computational resources, simplicity, and performance. We do not claim that MLPs are the best architecture for NQS and acknowledge that a more detailed analysis is required. However, in this work, our focus is on introducing a novel NQS training method rather than achieving the best possible performance in modeling a specific system. The resulting architecture imposes minimal assumptions on the physical system, enabling its application to cases beyond the scope of this work. This includes diverse lattice patterns, different symmetries, and varying numbers of dimensions. 

In the case of 2D spin lattice models the most straightforward way to encode the input basis states would be to apply the following map on lattice site states: $|\uparrow \rangle \rightarrow -1$ and $|\downarrow \rangle \rightarrow 1$. The resulting matrix can be flattened and used as input for the first layer of MLP. However, we discovered that a better performance can be obtained by utilizing the encoding based on 2D patches that is used with vision transformers \cite{vision_transformer}. The matrix described above is divided into patches of size $d_p \times d_p$, which are subsequently mapped to vectors of dimension $d_{enc}$ using a linear transformation with trainable weights. The resulting vectors are concatenated and then used as input for the first layer of MLP. This kind of encoding has been demonstrated to be beneficial in image processing, not only with transformers but also with other architectures (e.g. \cite{patches_are_all_you_need}).

There are two general approaches for defining the output of the neural network within the context of NQS. The first approach is to simply output a complex number that corresponds to the  amplitude of the non-normalized wave function (e.g. \cite{Carleo_first_NQS, j1j2_with_cnn, j1j2_challenges}). The second approach involves factorizing the wave function into conditional factors, akin to the chain rule of probabilities, and autoregressively generating these conditional wave functions as output (e.g. \cite{rnn_nqs_allah, autoregressive_CNN_NQS, gauge_invariant_autoregressive_NQS}). In this work, we opted to utilize the first approach. Nevertheless, our method could be applied using the second approach as well.

For the sake of simplicity, we maintain a constant number of neurons across all hidden layers of the MLP. The final layer of the model produces two output values. The first value represents the log-amplitude of the wave function, while the second value represents the phase. Because only the fractions of different wave function elements have meaning, the output amplitudes could grow indefinitely during training. To prevent that we follow Ref.~\cite{j1j2_challenges} and utilize the following nonlinearity for the log-amplitude value: $f(x) = a \tanh(x/a)$. We set $a = 20$ which allows to express amplitudes within the range of 17 orders of magnitude. For the phase value, we do not apply any nonlinearities and allow values outside the $(0, 2\pi)$ range. All of the variational parameters of the neural network are real. The neural network's architecture is illustrated in Fig. \ref{fig:architecture_scheme}.

% Figure environment removed

\subsection{Sampling of basis states}

As described in Sec.~\ref{sec:loss_func} and \ref{sec:adaptive_tau}, the estimation of the gradient and energy statistics requires sampling the basis states according to the probability distribution associated with the wave function, $p(\mathbf{s}) = |\psi(\mathbf{s})|^2$. Due to the high dimensionality of the problem and the fact that our NQS outputs unnormalized amplitudes, direct sampling is not feasible. Instead, we employ Markov chain Monte Carlo (MCMC) sampling, specifically the Metropolis-Hastings algorithm \cite{Metropolis1953,Hastings1970}, which has become a standard practice in the field of NQS.

Here we provide a brief overview of the algorithm specifically for a spin-lattice model with fixed magnetization. Starting basis state, $\mathbf{s}_0$, is sampled according to the uniform distribution. At the $m$-th step a new basis state candidate, $\mathbf{s}_m'$, is generated by randomly choosing a pair of neighbor sites in $\mathbf{s}_{m-1}$ and interchanging their spin states. This candidate is accepted by setting $\mathbf{s}_m = \mathbf{s}_m'$ if $u \leq |\psi(\mathbf{s'})|^2 / |\psi(\mathbf{s})|^2$ where $u \in [0,1]$ is a random uniform number. If a candidate is not accepted, then the basis state is kept unchanged: $\mathbf{s}_m = \mathbf{s}_{m-1}$. The algorithm proceeds to randomly walk in the sample space and generates samples that eventually start to follow the probability distribution $|\psi(\mathbf{s})|^2$. The initial samples may follow a different distribution. To address this, we incorporate a warm-up period lasting $N_\text{warmup}=10 d_\text{lat}^2$ steps, during which the generated samples are discarded. To reduce sample correlation, we selectively retain samples at a regular interval of $N_\text{skip}=4$.

To enhance the efficiency of MCMC sampling, we parallelize the algorithm by initializing multiple random basis states and subsequently conducting independent MCMC random walks for each of them. We also perform the warm-up period only at the beginning of the epoch and then reuse the MCMC walker values from the last step as initial values for the current step. These two optimizations increase the training speed by orders of magnitude. In this work, we set the number of MCMC walkers equal to the batch size, $N_\text{b}$. Consequently, we only need to evaluate the NQS $N_\text{skip}$ times to generate a batch of basis states sufficient for a single optimizer step.     

\subsection{Implementation details}

The code was written in Python \cite{python3}. Numerically demanding parts were implemented by using \textsc{JAX} \cite{jax_github} package. Neural network computation and training parts were implemented by using \textsc{Flax} \cite{flax_github} and \textsc{Optax} \cite{deepmind_jax_ecosystem} packages. In this work, \textsc{JAX} was useful not only because of its automatic differentiation but also because of its just-in-time compilation and automatic vectorization (\textit{vmap}). With these capabilities, we could easily parallelize and optimize local energy computation and state sampling functions which led to significant computation time improvements. 

For SR computations we used the implementation in \textsc{NetKet} \cite{netket2_2019,netket3_2022}. For exact diagonalization (ED) and DMRG computations based on \textsc{QuSpin} \cite{QuSpin2017,QuSpin2019} and \textsc{TeNPy} \cite{tenpy}, we utilized the AMD Ryzen Threadripper 2990WX CPU. NQS training was conducted using the Nvidia RTX 4090 GPU.

\section{Numerical experiments}
\label{sec:results}

\subsection{\texorpdfstring{$J_1$}{J1} - \texorpdfstring{$J_2$}{J2} Heisenberg model on a 2D square lattice}

Let us now benchmark the performance of the proposed approach by treating a specific numerical example. For this purpose, we choose the two-dimensional \jj\,  Heisenberg model, defined by the Hamiltonian
\begin{equation}
    H = J_1 \sum_{\langle ij \rangle} \vec{S}_i \cdot \vec{S}_j
    + J_2 \sum_{\langle\!\langle ij \rangle\!\rangle} \vec{S}_i \cdot \vec{S}_j,
\end{equation}
with $\vec{S}_j$ denoting the spin-$\tfrac{1}{2}$ operators defined on the sites (indexed by $j$) of 2D $d_\text{lat} \times d_\text{lat}$ square lattice with periodic boundary conditions. The model features competing antiferromagnetic interactions: $J_1 > 0$ act between the nearest-neighbor spin pairs ($\langle ij \rangle$), and $J_2 \geqslant 0$ couple the next-nearest neighboring pairs situated on the opposite ends of diagonals of the square plaquettes. In the absence of the second term, these nearest-neighbor interactions stabilize the N\'{e}el order with two opposite-magnetization sublattices intertwined in a checkerboard pattern. In the opposite limit of dominant long-range interactions $J_2 \gg J_1$, the model features a striped antiferromagnetic phase. In the vicinity of the classical boundary $J_2 / J_1 = 0.5$ the model is frustrated and the exact phase diagram is subject to an ongoing debate, see e.g.\ Refs.~\cite{Wang2018,Ferrari2020,Nomura2021} and references therein.

This particular model exhibits several symmetries: 1) translation along the x-axis and y-axis; 2) rotation by multiples of 90 degrees; 3) reflection about the x-axis, y-axis, and diagonal; 4) spin inversion; 5) SU(2) spin rotation. These symmetries can be leveraged to effectively reduce the dimensionality of the problem, as was done in many previous studies (e.g. \cite{j1j2_with_cnn, j1j2_challenges} and references therein). However, in this work we do not enforce the NQS to be invariant with respect to any of the aforementioned transformations. By adopting this approach, we aim to demonstrate that when utilizing large neural networks, there is no need for specialized architectures tailored to specific systems.

\subsection{Hyperparameters}

The values of various hyperparameters, defined in the text, are listed in Table \ref{hyperparams_table}. Unless explicitly stated otherwise, these values were consistently applied across all our numerical experiments.

In all our numerical experiments, we optimize NQS using ADAM optimizer with first order gradient descent. The learning rate is adjusted using an exponential decay schedule, with the initial learning rate $\alpha_0$ and the final learning rate $\alpha_\text{f}$.  

To identify suitable values for the neural network width (number of neurons per hidden layer) and depth (number of hidden layers), we conducted a small grid search. We explored three width values (128, 256, 512) and varied the depth from 1 to 5. As a performance metric, we utilized the achieved energy error (relative to ED results) for a $6 \times 6$ lattice with $J_2 / J_1 = 0.5$. The results are illustrated in Fig. \ref{fig:architecture_variation}. It is evident that, in general, accuracy tends to improve with an increase in the number of parameters in the network. This is expected, as larger neural networks possess the capacity to represent a broader subspace of all possible wave functions. In fact, the accuracy does not appear to plateau as the network width increases. It is likely that further improvement in accuracy can be achieved by increasing the network width even more. However, the depth does exhibit an optimal value, as the accuracy tends to decline when the depth exceeds 4. This is also expected  since training deeper neural networks necessitates additional techniques such as residual connections \cite{resnets_He2015} or specific initialization \cite{dynamical_isometry_10k_layers_cnn}. Based on these results, we employ a depth of 4 and a width of 512 in the subsequent numerical experiments, as this configuration demonstrated the best performance. This particular network has 893994 variational parameters.  

\begin{table}[!h]
\begin{center}
\begin{tabular}{ |c|c|c| }
 \hline
 \textbf{Hyperparameter} & \textbf{symbol} & \textbf{value} \\
 \hline
 Input patch size & $d_\text{p}$ & 2 \\ 
 Patch encoding size & $d_\text{enc}$ & 8 \\
 Training batch size & $N_\text{b}$ & 256 \\
 Initial learning rate & $\alpha_0$ & $10^{-3}$ \\
 Final learning rate & $\alpha_\text{f}$ & $10^{-5}$ \\
 Number of samples for energy statistics during training & - & $10^5$ \\
 Number of samples for final energy estimation & - & $10^6$ \\
 Total number of optimizer steps & - & $5 \cdot 10^5$ \\
 MCMC warm-up steps & $N_\text{warmup}$ & $10 d_\text{lat}^2$ \\
 MCMC sample skip interval & $N_\text{skip}$ & 4 \\
 \hline
\end{tabular}
\caption{\label{hyperparams_table} Hyperparameters table.}
\end{center}
\end{table}

% Figure environment removed

\subsection{Comparison with E loss}
\label{sec:E_vs_ITE_loss_experiment}

In this section, we compare the training of NQS using our proposed method with a more standard approach that utilizes the energy as a loss function (with and without SR). In all cases, we investigate the performance on $6\times6$ lattice, while keeping all shared hyperparameters unchanged. The only exceptions are for SR, where we employ vanilla stochastic gradient descent instead of ADAM and increase the learning rate by a factor of 10. Due to the longer optimization time required for SR (which varies from 4 to 6 times due to the iterative solver used), we also reduce the total number of optimizer steps by a factor of 5, bringing it down to $10^5$. The energy error is calculated by comparing the achieved energy with ED results. 

Figure \ref{fig:compare_with_E_loss}(a) shows three energy minimization curves for each loss, with each curve representing different random initializations of the NQS variational parameters. It is evident that training NQS with E loss and vanilla gradient is highly unstable since the minimization curves exhibit sudden jumps in energy and converge to significantly different energy values depending on initialization. In contrast, with ITE loss there are no abrupt energy jumps and the final energy value has almost no dependence on the initial variational parameters. Moreover, employing the ITE loss consistently leads to a lower final energy for the NQS compared to the E loss approach. This instability of training with E loss likely arises because it is equivalent to ITE loss with a constantly changing target (see Sec. \ref{sec:relation_with_E_loss}).

Figure \ref{fig:compare_with_E_loss}(b) depicts the energy error's dependence on $J_2 / J_1$. Given that the final energy with E loss exhibits significant variation from run to run, we conduct 5 runs for each $J_2 / J_1$ value and only plot the best result. The figure clearly illustrates that our proposed method achieves superior accuracy compared to E loss with vanilla gradient not only in the vicinity of the maximum frustration point at $J_2 / J_1 = 0.5$ but also over a wider parameter range. Our method also demonstrates competitiveness with SR, achieving slightly lower energy errors at some points and slightly higher errors at others. With all losses, a distinct trend is visible: the energy error reaches its maximum near $J_2 / J_1 = 0.5$ and subsequently decreases as it moves further from this point. However, the trend is noisier in the case of E-loss due to the instability of convergence.

In terms of computational time, the proposed scheme generally takes approximately 30\% - 50\% longer in practice than training with E loss and vanilla gradient. The primary reason for this increase is the additional energy estimation performed after each optimizer step to determine when to update the target wave function (see Sec. \ref{sec:training_procedure}). The calculation of the loss function requires a similar amount of computation in both cases. This is because energy estimation in E loss and target computation in ITE loss involves computing the same terms, namely $\sum_\mathbf{s'} H_{\mathbf{ss'}} \psi(\mathbf{s'})$, which dominate the computational cost. Compared to SR, our proposed method took, on average, about 5 times less computational time per iteration. However, SR iterations seem to be more effective in reducing energy, as the final energy accuracy achieved in similar computation times (despite SR having 5 times fewer iterations) is comparable.

% Figure environment removed

\subsection{Benchmarking}

In this section, we benchmark NQS trained with our proposed method against the well-established DMRG method. We do this by investigating the relationship between the predicted ground state energy and lattice size, specifically when exceeding the practical modeling limits of ED. Additionally, we compare some of our results with those achieved in other studies.

Figure \ref{fig:system_scaling} shows the predicted ground state energy dependence on lattice border length, while keeping $J_2/J_1 = 0.5$. Since the performance of DMRG strongly depends on the number of bond dimensions, $\chi$, we present the data for two values: 128 and 1024. Regarding the NQS, we observed that extending the training duration significantly can lead to a slight improvement in the predicted energy. As a result, we also present the data for NQS with $5 \cdot 10^6$ optimizer steps, which is an order of magnitude higher than our default value. This decrease in final energy becomes increasingly prominent with larger lattice sizes.

From the presented data, it is evident that NQS clearly outperforms DMRG with $\chi=128$. However, when $\chi=1024$, the situation becomes more intricate. Both NQS and DMRG achieve practically the same energy as ED for the $4 \times 4$ lattice. For the $6 \times 6$ and $8 \times 8$ lattices, NQS slightly outperforms DMRG, but only when using the extended training time. However, for larger lattice sizes beyond $8 \times 8$, DMRG starts to outperform NQS, and the difference appears to grow with increasing lattice size. In the matrix product state used in DMRG, the number of variational parameters grows proportionally with the lattice size. On the other hand, for NQS, the number of variational parameters remains almost constant as it increases only in the first hidden layer of the network, which represents a small fraction of the total number of parameters. This disparity in the scaling of variational parameters could provide an explanation for why DMRG eventually outperforms NQS with increasing lattice size.

Regarding the computational resources, it is hard to compare since we utilized CPU for DMRG and GPU for NQS. However, the actual time it took to compute the models was on a similar scale for DMRG with $\chi=1024$ and NQS with $5 \cdot 10^6$ optimizer steps (e.g. about 20 hours for $12 \times 12$ lattice).

% Figure environment removed

For $J_2 / J_1 = 0.5$ and $6 \times 6$ lattice, Ref. \cite{j1j2_challenges} identified an energy error limit that appears to be hard to overcome for NQS. Multiple other works \cite{j1j2_with_cnn, j1j2_gutzwiller, j1j2_szabo_2020}, including theirs, have achieved energy errors comparable to $2 \cdot 10^{-3}$, despite using different NQS architectures and optimization procedures. In Fig. \ref{fig:compare_with_E_loss} (b) one can see that our method also achieves a similar value at $J_2 / J_1 = 0.5$. After increasing the total number of optimizer steps to $5 \cdot 10^6$, our method achieves $1.4 \cdot 10^{-3}$, which is still comparable. Here we used neural networks with a substantially larger number of variational parameters than the mentioned studies and still were unable to significantly surpass the $2 \cdot 10^{-3}$ limit. This adds more evidence that the problem is related to the variational landscape rather than the representation power of neural networks.

Several studies have explored the $J_2 - J_1$ model using NQS. In Table \ref{energy_compare_table}, we present some of the best energies per site achieved with a $J_2 / J_1 = 0.5$ on a $10 \times 10$ lattice. All the other studies mentioned utilized translation-invariant CNNs and incorporated various symmetries of the physical system. In our study, we achieved competitive results with a straightforward and generic MLP architecture, even though we used gradient descent with Euclidean metric and did not explicitly integrate symmetries into NQS.

\begin{table}[!h]
\begin{center}
\begin{tabular}{ |c|c|c| }
 \hline
 \textbf{Method} & \textbf{$E/N$} \\
 \hline
 CNN, REMD \cite{j1j2_with_cnn_2} & $-0.4736$ \\ 
 CNN, SR \cite{j1j2_with_cnn} & $-0.4952$ \\
 CNN, SR \cite{j1j2_with_cnn_3} & $-0.4958$ \\
 CNN, minSR \cite{j1j2_minSR} & $-0.4976$ \\
 MLP, ITE (ours) & $-0.4894$ \\
 \hline
\end{tabular}
\caption{\label{energy_compare_table} Comparison of energy estimates with NQS for $10 \times 10$ lattice with $J_2 / J_1 = 0.5$.}
\end{center}
\end{table}

%\section{Discussion}

\section{Conclusions}
\label{sec:conclusion}
%\section{Discussion and conclusions}

In this study, we proposed and analyzed an adaptive scheme for searching the ground state with NQS, built upon the principle of imaginary time evolution. In this method, we construct the target wave function by combining the current wave function with the discretized flow obtained from the Schrödinger equation with imaginary time. Subsequently, we train the neural network to approximate this target wave function. Through repeated iterations of this process, the state approximated by the neural network converges to the ground state. We employ a loss function based on the overlap of wave functions, utilize an adaptive, optimal imaginary time step and also fix the target wave function for multiple time steps, until a decrease in energy is observed. Differently from the commonly used SR approach, our method uses the vanilla gradient with Euclidean metric.

In our exploration of the relationship between our proposed scheme and the direct minimization of energy, we uncovered a potential explanation for the unstable convergence often observed when employing energy as a loss function. Using the energy loss is equivalent to our method but with a target that changes after every optimizer step. The instability might arise due to a constantly shifting target. In our approach, this issue is addressed by fixing the target for some number of optimizer steps, resulting in a more stable training process.

Our investigation included numerical experiments with the \jj\ Heisenberg model on a 2D square lattice, providing compelling evidence that our method offers higher stability and final energy accuracy than the optimization of NQS with energy as a loss function. Moreover, it showcases competitiveness with the well-established DMRG method and NQS optimization with SR.

We emphasize that our numerical experiments were performed without leveraging the symmetries of the physical system, which significantly increases the difficulty of the problem. Yet by utilizing neural networks with a large number of parameters compared to the commonly used values in this research area, we managed to achieve comparable accuracy to the results reported in works that do exploit symmetries and use specialized neural network architectures. This highlights the primary advantage of our proposed method: the capability to utilize large neural networks and apply standard optimization methods from other areas of machine learning. 


\section*{Acknowledgements}
% Acknowledgements should follow immediately after the conclusion.
The authors express their gratitude to Julius Ruseckas and Artūras Acus for discussions that prompted new insights. Furthermore, the authors extend their thanks to Marin Bukov for valuable correspondence regarding \textsc{QuSpin}, and to Giuseppe Carleo for useful comments.

% TODO: include author contributions
% \paragraph{Author contributions}
% This is optional. If desired, contributions should be succinctly described in a single short paragraph, using author initials.

% TODO: include funding information
\paragraph{Funding information}
% Authors are required to provide funding information, including relevant agencies and grant numbers with linked author's initials. Correctly-provided data will be linked to funders listed in the \href{https://www.crossref.org/services/funder-registry/}{\sf Fundref registry}.
This work was performed under the "Universities' Excellence Initiative" programme.

\begin{appendix}

%\section{Derivations}
%\label{sec:derivations}

\section{Energy moments}
\label{sec:app_energy_moments}

First, we show that the mean value corresponding to any operator, $\hat{A}$, is equal to the mean of its local value $ A_{loc}(\boldsymbol{s}) \coloneqq \sum\limits _{\boldsymbol{s'}}\frac{\psi(\boldsymbol{s'})}{\psi(\boldsymbol{s})} A_{\boldsymbol{ss'}} $:

\begin{equation}
\begin{aligned}
\left\langle A\right\rangle  & =\langle\psi|\hat{A}|\psi\rangle=\sum\limits _{\boldsymbol{s}}\sum\limits _{\boldsymbol{s'}}\psi^{*}(\boldsymbol{s})\psi(\boldsymbol{s'})A_{\boldsymbol{ss'}}\\
 & =\sum\limits _{\boldsymbol{s}}|\psi(\boldsymbol{s})|^{2}\sum\limits _{\boldsymbol{s'}}\frac{\psi(\boldsymbol{s'})}{\psi(\boldsymbol{s})}A_{\boldsymbol{ss'}}=\left\langle \sum\limits _{\boldsymbol{s'}}\frac{\psi(\boldsymbol{s'})}{\psi(\boldsymbol{s})}A_{\boldsymbol{ss'}}\right\rangle _{\boldsymbol{s}}\\
 & =\left\langle A_{loc}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\,.
\end{aligned}
\end{equation}
By substituting $\hat{A} = \hat{H}$, we obtain Eq.~(\ref{eq:energy_norms_1}).

Now we show that the mean value corresponding to the product of any two operators, $\hat{A}$ and $\hat{B}$, can also be computed with their local values:
\begin{equation}
\begin{aligned}
\langle\hat{A}\hat{B}\rangle & =\sum_{\boldsymbol{s'}}\sum_{\boldsymbol{s''}}\psi^{*}(\boldsymbol{s'})\psi(\boldsymbol{s''})(AB)_{\boldsymbol{s's''}}\\
 & =\sum_{\boldsymbol{s'}}\sum_{\boldsymbol{s''}}\psi^{*}(\boldsymbol{s'})\psi(\boldsymbol{s''})\sum_{\boldsymbol{s}}A_{\boldsymbol{s's}}\hat{B}_{\boldsymbol{ss''}}\\
 & =\sum_{\boldsymbol{s}}|\psi(\boldsymbol{s})|^{2}\sum_{\boldsymbol{s'}}\frac{\psi^{*}(\boldsymbol{s'})}{\psi^{*}(\boldsymbol{s})}A_{\boldsymbol{s's}}\sum_{\boldsymbol{s''}}\frac{\psi(\boldsymbol{s''})}{\psi(\boldsymbol{s})}\hat{B}_{\boldsymbol{ss''}}\\
 & =\sum_{\boldsymbol{s}}|\psi(\boldsymbol{s})|^{2} A_{loc}^{*}(\boldsymbol{s}) B_{loc}(\boldsymbol{s})\\
 & =\langle A_{loc}^{*}(\boldsymbol{s}) B_{loc}(\boldsymbol{s})\rangle \,.
\end{aligned}
\end{equation}

By substituting $\hat{A} = \hat{B} = \hat{H}$, we obtain Eq.~(\ref{eq:energy_norms_2}). By susbstituting $\hat{A} = \hat{H}$ and $\hat{B} = \hat{H}^2$ we obtain Eq.~(\ref{eq:energy_norms_3}).

In both derivations, we made the simplifying assumption of a normalized state, $|\psi\rangle$. However, it is clear that the same steps can be performed without this assumption, resulting in identical final expressions.

\section{Gradient of ITE loss}
\label{sec:app_grad_of_ite_loss}

First we split the gradient into two terms:
\begin{equation}
    \label{eq:ite_loss_grad_derivation}
    \frac{\partial L }{\partial\theta} = -\frac{\partial}{\partial\theta}\log\frac{|\langle\psi|\psi_{T}\rangle|^{2}}{\langle\psi|\psi\rangle\langle\psi_{T}|\psi_{T}\rangle} =\frac{\partial}{\partial\theta}\log\langle\psi|\psi\rangle-\frac{\partial}{\partial\theta}\log|\langle\psi|\psi_{T}\rangle|^{2} \,,
\end{equation}
then calculate each term separately:
\begin{equation}
\begin{aligned}
-\frac{\partial}{\partial\theta}\log|\langle\psi|\psi_{T}\rangle|^{2} & =-2\Re\left\{ \frac{\partial}{\partial\theta}\log\langle\psi|\psi_{T}\rangle\right\} \\
 & =-2\Re\left\{ \frac{1}{\sum_{\boldsymbol{s'}}\psi^{*}(\boldsymbol{s'})\psi_{T}(\boldsymbol{s'})}\sum_{\boldsymbol{s}}\psi_{T}(\boldsymbol{s})\frac{\partial}{\partial\theta}\psi^{*}(\boldsymbol{s})\right\} \\
 & -2\Re\left\{ \frac{1}{\sum_{\boldsymbol{s'}}|\psi(\boldsymbol{s'})|^{2}\cdot\frac{\psi_{T}(\boldsymbol{s'})}{\psi(\boldsymbol{s'})}}\sum_{\boldsymbol{s}}|\psi(\boldsymbol{s})|^{2}\frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\} \\
 & -2\Re\left\{ \frac{1}{\left\langle \frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\right\rangle _{\boldsymbol{s}}}\left\langle \frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{s}\right\} \,,
\end{aligned}
\end{equation}

\begin{equation}
\begin{aligned}
\frac{\partial}{\partial\theta}\log\langle\psi|\psi\rangle & =\frac{1}{\langle\psi|\psi\rangle}\frac{\partial}{\partial\theta}\sum_{\boldsymbol{s}}\psi(\boldsymbol{s})\psi^{*}(\boldsymbol{s})\\
 & =2\Re\left\{ \frac{1}{\langle\psi|\psi\rangle}\sum_{\boldsymbol{s}}\psi(\boldsymbol{s})\frac{\partial}{\partial\theta}\psi^{*}(\boldsymbol{s})\right\} \\
 & =2\Re\left\{ \frac{1}{\langle\psi|\psi\rangle}\sum_{\boldsymbol{s}}|\psi(\boldsymbol{s})|^{2}\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\} \\
 & =2\Re\left\{ \left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\right\} \,.
\end{aligned}
\end{equation}
Finally, putting these results back into Eq.~(\ref{eq:ite_loss_grad_derivation}), we obtain Eq.~(\ref{eq:loss_grad}).

\section{Relation between gradients of ITE loss and E loss}
\label{sec:app_relation_between_losses}

The ratio between the target wave function [Eq.~(\ref{eq:euler_step_elements})] and the current wave function is related to the local value of the Hamiltonian:
\begin{equation}
\begin{aligned}
\frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})} & =\frac{\psi(\boldsymbol{s})-\Delta\tau\sum_{\boldsymbol{s'}}\hat{H}_{\boldsymbol{ss'}}\psi(\boldsymbol{s'})}{\psi(\boldsymbol{s})} \\ & = 1-\Delta\tau\sum_{\boldsymbol{s'}}\frac{\psi(\boldsymbol{s'})}{\psi(\boldsymbol{s})}\hat{H}_{\boldsymbol{ss'}} \\ & = 1-\Delta\tau H_{loc}(\boldsymbol{s}) \,.
\end{aligned}
\end{equation}
By substituting this ratio into Eq.~(\ref{eq:loss_grad}) we obtain Eq.~(\ref{eq:loss_relation}):
\begin{equation}
\begin{aligned}
\frac{\partial L}{\partial\theta} & =2\Re\left\{ \left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}-\frac{1}{\left\langle \frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\right\rangle _{\boldsymbol{s}}}\left\langle \frac{\psi_{T}(\boldsymbol{s})}{\psi(\boldsymbol{s})}\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\right\} \\
 & =2\Re\left\{ \left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}-\frac{\left\langle \left(1-\Delta\tau H_{loc}(\boldsymbol{s})\right)\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}}{\left\langle 1-\Delta\tau H_{loc}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}}\right\} \\
 & =2\Re\left\{ \frac{\Delta\tau\left\langle H_{loc}(\boldsymbol{s})\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}-\Delta\tau\left\langle E\right\rangle \left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}}{1-\Delta\tau\left\langle E\right\rangle }\right\} \\
 & =\frac{\Delta\tau}{1-\Delta\tau\left\langle E\right\rangle }2\Re\left\{ \left\langle H_{loc}(\boldsymbol{s})\frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}-\left\langle E\right\rangle \left\langle \frac{\partial}{\partial\theta}\log\psi^{*}(\boldsymbol{s})\right\rangle _{\boldsymbol{s}}\right\} \\
 & =\frac{\Delta\tau}{1-\Delta\tau\left\langle E\right\rangle }\frac{\partial L_{E}}{\partial\theta}\,.
\end{aligned}
\end{equation}
Here in the first line we used the result from Sec.~\ref{sec:app_grad_of_ite_loss}.

% Add material that is better left outside the main text in a series of Appendices labeled by capital letters.

% \section{About references}
% Your references should start with the comma-separated author list (initials + last name), the publication title in italics, the journal reference with volume in bold, start page number, publication year in parenthesis, completed by the DOI link (linking must be implemented before publication). If using BiBTeX, please use the style files provided  on \url{https://scipost.org/submissions/author_guidelines}. If you are using our \LaTeX template, simply add
% \begin{verbatim}
% \bibliography{your_bibtex_file}
% \end{verbatim}
% at the end of your document. If you are not using our \LaTeX template, please still use our bibstyle as
% \begin{verbatim}
% \bibliographystyle{SciPost_bibstyle}
% \end{verbatim}
% in order to simplify the production of your paper.
\end{appendix}


%\newpage
\bibliography{references.bib}

\nolinenumbers

\end{document}
