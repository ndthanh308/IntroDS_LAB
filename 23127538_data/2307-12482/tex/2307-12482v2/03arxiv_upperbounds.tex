\section{Upper Bounds}\label{sec:upper}
%\hadi{I cut down and rewrote this section.. the original one is commented out.}\rik{I like the changes}

The hardness of achieving optimal envy even on simple classes of graphs (e.g.,~disjoint unions of paths) \citep{canon} immediately gives rise to the question of whether we can approximate optimal solutions. As stated before, we need to assume connectivity in general.

We start by making a trivial observation (Proposition \ref{prop:trivialgeneral}): \textit{any} allocation of values to a connected graph is an $O(n^2)$-approximation to the optimal envy, and in fact an $O(n)$-approximation when the graph is a tree. This is due to the fact that every smallest subinterval of the valuation interval is covered by at most $|E|$ edges, but connectivity requires that it be covered by at least one edge. 

\begin{proposition}\label{prop:trivialgeneral}
    For \emph{any} instance of {\GHA} on a connected graph $G = (V, E)$, \emph{any} allocation is an $|E|$-approximation to the optimal value.
\end{proposition}

In what follows, we first discuss how to improve this bound for bounded-degree trees and then generalize this result to graphs based on a structural parameter called the \emph{cutwidth}. Finally, we showcase how our bounds can be significantly improved for the special class of random (Erd\H{o}s-Renyi) graphs.


\begin{comment}

Several results in \citep{canon} show that the house allocation problem is a very hard one to solve in general, if we care about an exact solution. Finding the exact optimal envy is NP-hard even on particularly easy classes of graphs, such as disjoint unions of paths, cycles, or stars. 
% In fact, even if we contend ourselves with finding approximately optimal values, \citep{bj92} tells us that the problem in general is hard to approximate to within a factor of $n^{2 - \varepsilon}$ \vignesh{This seems to be an additive factor}. 
This immediately implies that we need to consider restricted classes of graphs to have any possibility of approaching interesting approximability results. In this section, we present the first few results for such classes of graphs.

At the outset, we make the following important trivial observation, stated as a proposition for the sake of convenience.

% \begin{proposition}\label{prop:trivialgeneral}
%     For \emph{any} instance of {\GHA} on a connected graph $G = (V, E)$, \emph{any} allocation whatsoever is an $n^2$-approximation to the optimal value.
% \end{proposition}

\begin{proposition}\label{prop:trivialgeneral}
    For \emph{any} instance of {\GHA} on a connected graph $G = (V, E)$, \emph{any} allocation whatsoever is an $|E|$-approximation to the optimal value.
\end{proposition}


The result follows simply by observing that in any allocation, every subinterval of the valuation interval is covered by at most $|E|$ edges, but connectivity requires that it be covered by at least one edge. Note that Proposition \ref{prop:trivialgeneral} immediately implies that every allocation is an $O(n^2)$-approximation to the optimal envy, and in fact an $O(n)$-approximation when the graph is a tree.
% The second result is exactly similar, but $|E| = n - 1$. We omit the details of both proofs, as they are trivial.

In what follows, we first present a result on bounded-degree trees, and then generalize this to a class of results on graphs based on a structural parameter called the \emph{cutwidth}.

\end{comment}

% \vignesh{Should we label the following section as warm up maybe?}
\subsection{Trees}\label{sec:boundeddegreetrees}

In this section, we will present a recursive polynomial-time $O(\Delta\log n)$-approximation algorithm for any instance of {\GHA} where the underlying graph is any tree with maximum degree $\Delta$. Thus, for any tree with maximum degree $\Delta = o(n/\log n)$, our algorithm provides a better approximation than \Cref{prop:trivialgeneral}.

We will use the following folklore fact\footnote{ For a proof of this fact, see, for instance, \citet{mlatrees}, who attributes this as a folklore result to \citet{seidvasser}, who claims the fact is well-known, but proves it anyway.} without a proof.

\begin{fact}[Folklore]\label{fact:folklore}
    Every $n$-vertex tree $T$ has a \emph{center of gravity}: i.e., a vertex $v$ such that all connected components of $T - v$ have at most $n/2$ vertices. This vertex $v$ can be found in $O(n)$ time.
\end{fact}

\begin{algorithm}[t]
    \caption{Recursive Algorithm $\mathsf{TrickleDown}(T, H)$}
    \hspace{\algorithmicindent} 
    \textbf{Input:} {A {\GHA} instance on a tree $T$ and a set of values $H = \{h_1, \ldots, h_n\}$.} \\
    % \hspace*{-\algorithmicindent} 
    \textbf{Output:} {An $O(\Delta\log n)$-approximate allocation.}
    \begin{algorithmic}[1]
        \If{$|T| = 1$}
        \State \textbf{Allocate} the only house to the only vertex.
        \Comment{Base case}
        \Else
        \State Find a center of gravity $v$ of $T$.
        \State Let $T - v = T_1 + \ldots + T_k$, with $|T_i| = n_i$. 
        \Comment{$k \leq \Delta$, $n_i \leq n/2$.}
        \State Partition $H$ into the following contiguous sets: %\hadi{we may say instead: Partition $H$ such that $H_1 = \{h_1, \ldots, h_{n_1}\}$, ... }
        % \begin{align*}
        %     H_1 &= \{h_1, \ldots, h_{n_1}\}, \\
        %     H_2 &= \{h_{n_1+1}, \ldots, h_{n_1 + n_2}\}, \\
        %     \vdots \\
        %     H_k &= \{h_{n_1 + \ldots + n_{k-1} + 1}, \ldots, h_{n_1 + \ldots + n_k}\}.
        % \end{align*}
        \begin{align*}
            H_1 &= \{h_1, \ldots, h_{n_1}\}, \\
            H_2 &= \{h_{n_1+1}, \ldots, h_{n_1 + n_2}\} \\
            &\vdots \\
            H_k &= \{h_{n_1 + \ldots + n_{k-1} + 1}, \ldots, h_{n_1 + \ldots + n_k}\}. 
        \end{align*}
        \State \textbf{Allocate} $h_n$ to vertex $v$.
        \For{$i \in \{1, \ldots, k\}$}
            \State Recursively call $\mathsf{TrickleDown}(T_i, H_i)$.
        \EndFor
        \EndIf
    \State \Return the resulting allocation.
    \end{algorithmic}
    \label{alg:treelogn}
\end{algorithm}


%\hadi{we need a filler here to show how Fact 3.2 is related to our result and explain a bit of our algorithm (high level). Something like...}

We will use Fact \ref{fact:folklore} in developing a recursive algorithm (Algorithm~\ref{alg:treelogn}) that obtains an $O(\Delta\log n)$-approximation on trees. In each call, the algorithm first finds a center of gravity of the tree and subsequently uses this vertex to identify disjoint subtrees and solve the subproblems recursively on disjoint subintervals of the valuation interval. 


% The following theorem serves as the analysis for Algorithm \ref{alg:treelogn}.



\begin{restatable}{theorem}{thmtreelogn}\label{thm:treelogn}
There is an $O(n\log n)$-time algorithm that, given any instance on a tree with maximum degree $\Delta$, returns an allocation whose envy is at most $\Delta\log n$ times the optimal envy.
%Algorithm \ref{alg:treelogn} runs in time $\tilde{O}(n)$, and returns an $O(\Delta\log n)$-approximation to the optimal envy.
\end{restatable}
\begin{proof}

% Figure environment removed

We will show that Algorithm \ref{alg:treelogn} provides the desired guarantee. The algorithm starts by locating the center of gravity $v$ of the given tree $T$ (which is guaranteed to exist by Fact \ref{fact:folklore}). Then it assigns the largest (i.e., rightmost) value to node $v$, and recursively constructs the assignment for each of the disjoint subtrees in $T - v$.
      %Note that, by Fact \ref{fact:folklore}, line 4 in Algorithm \ref{alg:treelogn} can always be done, and therefore it is well-specified.
      
      It is easiest to visualize the allocation resulting from Algorithm \ref{alg:treelogn} as in Figure \ref{fig:treelogn}. All recursive calls in line 9 occur in a single ``level'' of the figure, and all subsequent recursive calls from the subtrees $T_1, \ldots, T_k$ can also be packed into a single level, as the edges in $T_i$ and the edges in $T_j$ do not overlap, for any $i \neq j$. The crucial point is that the envy incurred strictly within disjoint subtrees $T_i$ and $T_j$ cannot involve the same smallest subintervals of the original instance.

      Let us analyze the total envy in the final allocation that is output by Algorithm \ref{alg:treelogn}. There are at most $\Delta$ edges adjacent to $v$, and each of them incur their envy in level $1$ of Figure \ref{fig:treelogn}. Each edge gets an envy of at most $(h_n - h_1)$, and therefore, the total envy on these edges is at most $\Delta\cdot(h_n - h_1)$. The total envy along the edges adjacent to $v_1, \ldots, v_k$ (except the ones accounted for in the levels above) are at most $\Delta\cdot(h_{n_1} - h_1), \ldots, \Delta\cdot(h_{n_1+\ldots+n_k} - h_{n_1+\ldots+n_{k-1}+1})$. Since the subintervals are all disjoint, this level accounts for an envy of at most $\Delta\cdot(h_n - h_1)$ as well. We can continue this argument through the lower levels.

      How many levels are there? Because each vertex picked at each recursive call is a center of gravity of the next subtree, the size of each subtree is at most half the size of the subtree at its parent level. The number of levels, therefore, is at most $\log n$. This gives us a total envy of $\Delta\cdot(h_n - h_1)\cdot\log n$.

      Note that the optimum envy has to be at least $h_n - h_1$ for any connected graph. This gives us an approximation ratio of $\Delta\log n$.

      The bound on the running time also arises from Fact \ref{fact:folklore}, which ensures that line 4 can be done in time $O(n)$. For each subtree $T_i$ in level $1$, we can find a center of gravity in time $O(n_i)$, so the total amount of work done to find the centers of gravity at this level is $O(n_1) + \ldots + O(n_k) = O(n)$. Since this is summed over $\log n$ recursive levels, the total running time is $O(n\log n)$.
\end{proof}

We remark that with a slightly more careful analysis,\footnote{  Technically this involves tweaking the algorithm such that the center of gravity is assigned slightly differently in line 7, and the partition of $H$ is consistent with this.} we can improve the approximation ratio to $(1/2)\cdot(1 + \Delta +\Delta\log n)$. In particular, for any instance on a binary tree, the optimal envy can be $(2\log n)$-approximated in $O(n\log n)$ time. % The following observation readily follows from \Cref{thm:treelogn}. \andrew{personally, i'd skip this corollary. but if we keep it, note that $\Delta=3$ for a binary tree so while a $2\log n$ approximation is possible, you'd only get $3\log n$ from the above theorem.}

%\begin{corollary}\label{cor:bintrees}
%    For any instance of {\GHA} on a binary tree, the optimal envy can be $(2\log n)$-approximated $O(n\log n)$ time. 
%\end{corollary}

\if 0
We remark here that Algorithm \ref{alg:treelogn} and Theorem \ref{thm:treelogn} apply to an even more general problem, the \emph{weighted} version of {\GHA}.
This version in general asks: given an edge-weighted graph $G = (V, E, w)$, where $w : E \to \R_{\geq 0}$ is a weight function on the edges, and a set of $n$ values $H$, how do we find an allocation $\pi : V \to H$ minimizing the total \emph{weighted} envy, i.e., $\sum_{(i, j) \in E}|\pi(i) - \pi(j)|\cdot w(i, j)$? Of course, this problem is at least as hard as {\GHA}. There is some known work for weighted variants of {\MLA} \citep{richarao2005mla}.

Clearly, Algorithm \ref{alg:treelogn} is well-defined on weighted instances $(T, H)$, where $T = (V, E, w)$ is an edge-weighted tree. WLOG assume each weight is at least $1$ (otherwise, scale all the weights appropriately, at the cost of introducing this scaling factor in the subsequent result). Define the maximum degree of the weighted tree $T$ as $\Delta_w(T) := \max_{v \in V}\sum_{u \in \text{Nbd}_T(v)}w(u, v)$, i.e., the maximum weight of edges leaving any vertex in $T$. Of course, if all weights were $1$, this is the same as the maximum degree.
%
Thus, we have the following corollary for weighted variant of the \GHA{} on trees.
% The following corollary to Theorem \ref{thm:treelogn} shows us that we can approximate the optimal envy on this instance.

\begin{corollary}\label{cor:weightedtrees}
    There is an $O(n\log n)$ time algorithm that returns an $O(\Delta_w(T)\cdot\log n)$-approximation to the optimal envy on $(T, H)$ for \emph{weighted} trees $T$.
\end{corollary}

\begin{proof}
    Because we ignore the weights, the proof of termination and running time remain unchanged.  To check the approximation, note that the total envy in level $1$ is incurred by the edges incident on the vertex $v$, which has a total maximum weight of $\Delta_w(T)$, and so the total envy accounted for in this level is at most $\Delta_w(T)\cdot(h_n - h_1)$. Because each set of weighted edges in the subsequent levels remain disjoint, and span disjoint subintervals of $H$, the rest of the argument carries through. The optimum envy is at least $h_n - h_1$ under the assumption that each weight is at least $1$, and this gives us the result.
\end{proof}

\fi



\subsection{Cutwidth}\label{sec:cutwidth}

In this section, we generalize the result from Section \ref{sec:boundeddegreetrees} using the structural graph theoretic property of cutwidth (Definition \ref{def:cutwidth}). This will enable us to have a black-box process to obtain envy approximations parameterized by the cutwidth. All of these algorithms will be value-agnostic.

\begin{restatable}{theorem}{thmcwgeneric}\label{thm:cwgeneric}
Let $(G, H)$ be a {\GHA} instance defined on a connected graph $G$. Given a layout $\sigma$ that $\beta$-approximates $\cw(G)$, we can efficiently construct an allocation $\pi$ that is a $(\beta \cdot \cw(G))$-approximation to the optimal envy.
\end{restatable}
\begin{proof}
We construct the allocation $\pi$ as follows: for each agent $i \in V$, if $\sigma(i) = j$, we set $\pi(i) = h_j$; that is, we give $i$ the $j$-th least-valued house. 
Since $G$ is connected, the total envy of any allocation is at least $(h_n - h_1)$. In the allocation $\pi$, the number of edges of $G$ spanning any smallest subinterval of the valuation interval is at most $\mathsf{width}(\sigma, G)$ by definition, and therefore the envy from $\pi$ is at most $\sum_{i = 1}^{n-1}\mathsf{width}(\sigma, G)\cdot(h_{i+1} - h_i) = \mathsf{width}(\sigma, G)\cdot(h_n - h_1)$. Hence, if $\sigma$ is an $\beta$-approximation for the cutwidth, then $\pi$ is an $\beta \cdot \cw(G)$-approximation to the optimal envy of $G$, as claimed.
\end{proof}
% \begin{proof}[Proof Sketch]
%     For each agent $i \in V$, if $\sigma(i) = j$, we give $i$ the $j$-th least-valued house. The number of edges spanning any smallest subinterval of the valuation interval is $\mathsf{width}(\sigma, G) \leq \beta\cdot\cw(G)$. So our total envy is at most $\beta\cdot\cw(G)\cdot(h_n - h_1)$, but the minimum envy is at least $(h_n - h_1)$.
% \end{proof}


The next corollary follows from Theorem \ref{thm:cwgeneric} and Equation \ref{eq:twpwcw} when combined with existing bounds on the cutwidth, treewidth, or pathwidth \citep{korach1993cutwidth, leighton1999cutwidthapprox, djidjev2006cutwidth} of certain graph families along with the best known approximation results of these quantities \citep{yannakakis1985treecutwidth,leighton1999cutwidthapprox}.

\begin{corollary}\label{cor:cutwidth-upperbounds}
There exist polynomial-time value-agnostic approximation algorithms for the following classes:
\begin{enumerate}[(i)]
    \item An $O(\Delta \log n)$-approximation algorithm on trees,\label{cor:cwtrees}
    \item An $O(\sqrt{n \Delta} \log^{1.5} n)$-approximation algorithm on planar graphs,\label{cor:cwplanar}
    \item An $ O(\tw(G) \cdot \Delta \log^{2.5} n)$-approximation algorithm on general connected graphs.\label{cor:cwgeneral}
\end{enumerate}
%\begin{proof}
%We first compute the exact or approximate cutwidth layout and then use Theorem \ref{thm:cwgeneric} to construct allocations from the computed cutwidth layout. To analyze the approximation guarantee for a class of graphs, it suffices to upper bound the cutwidth for the specific class of graphs. 
%
%The first result uses the fact that there is an efficient algorithm to compute the exact cutwidth for trees. Combining this with the fact that the cutwidth of a tree is $O(\Delta \log n)$ \citep{korach1993cutwidth} using Theorem \ref{thm:cwgeneric}, we get the required result.
%
%The second and third result uses the $O(\log^{1.5}n)$ approximation algorithm for cutwidth \citep{leighton1999cutwidthapprox}. The second result combines this approximation algorithm with the fact that for any planar graph $G$, $\cw(G) \le O(\sqrt{n\Delta})$ \citep{djidjev2006cutwidth}. The third result directly plugs in \eqref{eq:twpwcw} to get the required result.
%\end{proof}
\end{corollary}

Note that for each class of graphs listed above $\Delta$ can be $O(n)$ in the worst case, and for general connected graphs, $\tw(G)$ can be $O(n)$ in the worst case as well. So, in the worst case, the first and third results are asymptotically worse than the trivial bound given by \Cref{prop:trivialgeneral}. However, for many natural subclasses of these graphs, such as bounded-degree graphs and bounded-degree trees, \Cref{cor:cutwidth-upperbounds} yields strictly better approximation guarantees.


\subsection{Random Graphs}\label{subsec:random-graphs}
We next consider random graphs, specifically Erd\H{o}s-Renyi graphs, where $G\sim {\mathcal G}_{n,1/2}$ denotes a random graph on $n$ nodes where every edge is present with probability $1/2$ and all edges are independent. We show that \GHA{} on such graphs can be approximated up to a factor $1+o(1)$ regardless of the valuation interval. The central observation is that for any subset of nodes $S$, $\delta_G(S)$ is tightly concentrated around $|S|(n-|S|)/2$. 
% The proof is relegated to Appendix \ref{apdx:upper}.
\begin{restatable}{lemma}{randomlemma}\label{lem:random}
    For $G\sim {\mathcal G}_{n,1/2}$, \[\Pr \left [ \forall S\subseteq V, (1-\epsilon) \leq \frac{\delta_G(S)}{|S|(n-|S|)/2} \leq (1+\epsilon) \right ] \geq 1- \exp(-\Omega(\epsilon^2 n)) \ , \]
for any $\epsilon \geq \sqrt{24 \ln (n)/n}$.

% \vignesh{I think you mean \[\Pr \left [ \forall A\subseteq V~,~ (1-\epsilon) \leq \frac{\delta_G(A)}{|A|(n-|A|)/2} \leq (1+\epsilon) \right ] \ge 1 - \exp(-\Omega(\epsilon^2 n)) \ , \]
% for any $\epsilon=O(\sqrt{\ln (n)/n})$.}
\end{restatable}
\begin{proof}
The expected size of the cut $\delta_G(S)$ is $E[\delta_G(S)]=|S|(n-|S|)/2$. By applying the Chernoff bound, we obtain:
\[\Pr[|\delta_G(S)-E[\delta_G(S)]|\geq \epsilon E[\delta_G(S)]] \leq  2 \exp( -\epsilon^2 E[\delta_G(S)]/3) \ . \]
Hence, by the union bound the probability there exists a set $S$ of size $k \le n/2$ such that $|\delta_G(S)-E[\delta_G(S)]|\geq \epsilon E[\delta_G(S)]$ is at most
\begin{align*}    
2\exp( - \epsilon^2 k(n-k)/6) \binom{n}{k}
& \leq 2 \exp( - \epsilon^2 kn/12 + k \ln n) \\
%& \leq & 2 \exp( - \epsilon^2 kn/12 + k \ln n) \\ 
& \leq 2 \exp( - \epsilon^2 kn/24),
\end{align*}
  assuming $\epsilon \geq \sqrt{24 \ln (n)/n}$. 
 % \vignesh{Should this be $\epsilon = O(\sqrt{\ln (n)/n})$?}
% Hence, the probability there exists two subsets of nodes of the same size where the number of edges leaving the subsets differs by more than a factor $(1+\epsilon)/(1-\epsilon) = 1+O(\epsilon)$
The lemma then follows by taking the union bound over $k$ and noting that \[\sum_{k=1}^{n/2} 2 \exp( - \epsilon^2 kn/24)=\exp(-\Omega(\epsilon^2 n)) \ .\qedhere \]
\end{proof}

Lemma \ref{lem:random}, with $\epsilon=\sqrt{24 \ln(n)/n},$ implies that with high probability, the cost of the optimum solution is at least \[\sum_{i=1}^{n-1} (h_{i+1}-h_{i}) \delta_G(i)\geq \sum_{i=1}^{n-1} (h_{i+1}-h_{i})(1-\epsilon) i(n-i)/2, \]
whereas the cost of an arbitrary allocation is at most  \[\sum_{i=1}^{n-1} (h_{i+1}-h_{i})(1+\epsilon) i(n-i)/2  . \]
Therefore an arbitrary allocation is a $(1+\epsilon)/(1-\epsilon)= 1+ O(\sqrt{\ln (n)/n})$-approximation.

\begin{theorem}\label{thm:random}
For  $G \sim \cal G_{n, 1/2}$, any allocation is a $1+ O(\sqrt{\ln (n)/n})$ approximation with probability at least $1 - 1/\poly(n)$.
\end{theorem}

