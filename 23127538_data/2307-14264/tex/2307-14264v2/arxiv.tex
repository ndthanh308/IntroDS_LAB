\documentclass[11pt,letterpaper]{scrartcl}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{verbatim}
\usepackage[capitalise]{cleveref}
\usepackage{relsize}
\usepackage{xspace}
\usepackage{nicematrix}
\usepackage{fullpage}
\usepackage{float}

\allowdisplaybreaks

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{plain}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{corollary}[definition]{Corollary}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{observation}[definition]{Observation}



\usepackage{macros}
\bibliographystyle{plainurl}

\title{A tight Monte-Carlo algorithm for Steiner Tree parameterized by clique-width}
\author{Narek Bojikian\hspace{2cm}Stefan Kratsch}

\begin{document}

\maketitle

\thispagestyle{empty}

\begin{abstract}
 \small

 \noindent Recently, Hegerfeld and Kratsch [ESA 2023] obtained the first tight algorithmic results for hard connectivity problems parameterized by clique-width. Concretely, they gave one-sided error Monte-Carlo algorithms that given a $k$-clique-expression solve \textsc{Connected Vertex Cover} in time $6^kn^{\Oh(1)}$ and \textsc{Connected Dominating Set} in time $5^kn^{\Oh(1)}$. Moreover, under the Strong Exponential-Time Hypothesis (SETH) these results were showed to be tight. Their work builds on a research program of determining tight complexity bounds that was initiated by work of Lokshtanov et al.~[SODA 2011 \& TALG 2018], about the first tight lower bounds relative to treewidth (modulo SETH), and work of Cygan et al.~[FOCS 2011 \& TALG 2022], about the cut-and-count framework and tight bounds for connectivity problems parameterized by treewidth.
 
 Hegerfeld and Kratsch [2023] leave open, however, several important benchmark problems, whose complexity relative to treewidth had been settled by Cygan et al., namely \textsc{Steiner Tree}, \textsc{Connected Odd Cycle Transversal}, and \textsc{(Connected) Feedback Vertex Set}. As a key obstruction they point out the exponential gap between the rank of certain compatibility matrices, which is often used for algorithms, and the largest triangular submatrices therein, which is essential for current lower bound methods. E.g., for \textsc{Steiner Tree} parameterized by clique-width the GF(2)-rank is at least $4^k$, while no triangular submatrix larger than $3^k\times 3^k$ was known. This at best yields an upper bound of time $4^kn^{\Oh(1)}$, while the obtainable lower bound of time $(3-\varepsilon)^kn^{\Oh(1)}$ under SETH was already known relative to pathwidth.
 
 We close this gap by showing that, somewhat surprisingly, \Stp\ can be solved in time $3^kn^{\Oh(1)}$ when given a $k$-clique-expression. Hence, for all parameters between cutwidth and clique-width it has the same tight complexity. We first show that there is a ``representative submatrix'' of GF(2)-rank $3^k$ (also ruling out larger than $3^k\times 3^k$ triangular submatrices). In principle, this could be used for an algorithm via the representative sets-based (or rank-based) approach of Bodlaender et al.~[ICALP 2013 \& IANDC 2015] but such an algorithm would not be sufficiently fast. It is tempting to additionally leverage the ``low'' GF(2)-rank of the submatrix but, at first glance, this leaves us with a useless combination of algorithmic approaches: Representative sets-based algorithms are slower and preserve \emph{existence} of a solution, whereas leveraging ``low'' GF(2)-rank, e.g., by cut-and-count, usually gives faster algorithms but preserves the \emph{parity} of the number of solutions. An outright combination of the two approaches cannot be expected to always yield the correct outcome because representation may change the parity of solutions (even when assuming isolation of a single solution). We nevertheless show how to reconcile these two worlds, thereby obtaining the claimed time complexity. We believe that our approach will be instrumental for settling further open problems in this research program.
\end{abstract}
\setcounter{page}{0}
\newpage


\section{Introduction}

Leveraging input structure to get faster algorithms is a fundamental strategy for coping with \classNP-hardness and other forms of intractability. This quickly leads to asking \emph{``how does structure affect complexity?''} This question lies at the heart of \emph{parameterized complexity}, where one quantifies input structure through so-called \emph{parameters} and seeks to determine the complexity of the corresponding \emph{parameterized problems} as a function of input size $n$ \emph{and} parameter value $k$. Initially, this has led to the classification of many hard problems as either being solvable in time $f(k)\cdot n^{\Oh(1)}$ for some function $f$, i.e., being \emph{fixed-parameter tractable} (\classFPT), or as being \classW{1}-hard and thereby unlikely to be \classFPT. Later, it became possible to prove tight bounds on the parameter dependence $f(k)$ for many problems subject to the (Strong) Exponential-Time Hypothesis (ETH/SETH).\footnote{ETH is the hypothesis that there is $c>1$ such that \textsc{3-CNF SAT} with $n$ variables cannot be solved in time $\Oh(c^n)$, while SETH is the hypothesis that for each $c<2$ there is $q\in\naturals$ such that \textsc{$q$-CNF SAT} cannot be solved in time $\Oh(c^n)$. It is known that SETH implies ETH, which in turn implies $\classFPT\neq\classW{1}$ and $\classP\neq\classNP$.} Typically, for a problem solvable in time $\alpha^k\cdot n^{\Oh(1)}$ one may be able to rule out time $2^{o(k)}\cdot n^{\Oh(1)}$ assuming ETH, while for some problems even time $(\alpha-\varepsilon)^k\cdot n^{\Oh(1)}$ can be ruled out for all $\varepsilon>0$ assuming SETH. In the following, we focus on the latter type of tight lower bounds, i.e., getting exact bases~$\alpha$.

This endeavor has been most successful for problems parameterized by \emph{treewidth},\footnote{Intuitively, the treewidth of a graph $G$, denoted $\tw(G)$, is the smallest value $k$ such that $G$ can be completely decomposed by non-crossing vertex separators of size at most $k$ each. Two important obstructions are cliques and grids as minors of $G$. Generally, only sparse graphs may have small treewidth as number of edges $m\leq \tw(G)\cdot n$.} a ubiquitous measure of graphs not just in parameterized complexity. The program of determining exact complexity was initiated by Lokshtanov et al.~\cite{DBLP:conf/soda/LokshtanovMS11a,DBLP:journals/talg/LokshtanovMS18} who showed that many well-known algorithms for problems parameterized by treewidth are essentially optimal modulo SETH, e.g., \textsc{Vertex Cover[$\tw$]}\footnote{We often write \textsc{Foo[$bar$]} to mean the parameterization of problem \textsc{Foo} by parameter $bar$.} can be solved in time $2^{tw}\cdot n^{\Oh(1)}$ but not in time $(2-\varepsilon)^{tw}\cdot n^{\Oh(1)}$, for any $\varepsilon>0$, assuming SETH. Another breakthrough was obtained by Cygan et al.~\cite{DBLP:journals/talg/CyganNPPRW22} who used their novel \emph{cut-and-count} technique to show, surprisingly, that many important connectivity-related problems have single-exponential (randomized) algorithms too. Moreover, they showed the obtained bounds to be optimal modulo SETH, e.g., \textsc{Connected Vertex Cover[$\tw$]} and \textsc{Steiner Tree[$\tw$]} can be solved in time $3^{tw}\cdot n^{\Oh(1)}$ but not in time $(3-\varepsilon)^{tw}\cdot n^{\Oh(1)}$ for any $\varepsilon>0$, assuming SETH. Since then, there has been much progress on tight bounds relative to treewidth (and the closely related \emph{pathwidth}), see, e.g.,~\cite{DBLP:conf/iwpec/BorradaileL16,DBLP:conf/soda/CurticapeanM16,DBLP:conf/soda/CurticapeanLN18,DBLP:journals/jacm/CyganKN18,DBLP:conf/esa/OkrasaPR20,DBLP:journals/tcs/HanakaKS21,DBLP:conf/icalp/MarxSS21,DBLP:journals/siamcomp/OkrasaR21,DBLP:journals/corr/abs-2210-10677/EsmerFMR22,DBLP:conf/soda/FockeMR22,DBLP:journals/dam/KatsikarelisLP22,DBLP:conf/soda/FockeMINSSW23}.

While treewidth and pathwidth quantify how well a graph can be decomposed along (small) vertex separators, it is natural to ask for decomposition along (small) edge cuts, which is more restrictive and may permit faster algorithms for well-decomposable graphs. This leads us to \emph{cutwidth} as an analogue of pathwidth (along with several tree-like variants, e.g.,~\cite{DBLP:conf/mfcs/GanianKS15,DBLP:conf/wg/BrandCGHK22,DBLP:conf/iwpec/GanianK22}). There are a number of tight bounds known relative to cutwidth~\cite{DBLP:journals/jgaa/GeffenJKM20,DBLP:journals/tcs/JansenN19,DBLP:conf/icalp/MarxSS21,DBLP:conf/stacs/PiecykR21,DBLP:conf/stacs/GroenlandMNS22,DBLP:conf/stacs/BojikianCHK23}, including tight bounds for
\textsc{Connected Vertex Cover}, \textsc{Connected Dominating Set}, \textsc{Feedback Vertex Set}, \textsc{Steiner Tree}, and \textsc{Connected Odd Cycle Transversal}~\cite{DBLP:conf/stacs/BojikianCHK23} as well as for counting connected edge sets~\cite{DBLP:conf/stacs/GroenlandMNS22}.
As treewidth (and more restrictive parameters like cutwidth and its variants) can only be small on sparse graphs, however, we need to look towards more general structure/parameters to understand the complexity of problems relative to structure present in dense/general graphs.

For this goal, \emph{clique-width} and \emph{rank-width} clearly stand out as canonical targets. The former measures how well the graph can be constructed when adjacency is controlled via $k$ labels/colors; the latter measures how well the graph can be decomposed by non-crossing cuts of small $\bin$-rank. Recently, Bergougnoux et al.~\cite{DBLP:conf/stacs/BergougnouxKN23} gave the first lower bounds for problems parameterized by rank-width, assuming ETH, but we are not aware of any results with tight bases even under SETH.\footnote{It should be noted that typical upper bounds relative to rank-width are not analyzed to exact bases and constants in the exponents, nor do the algorithms seem likely to be optimal. Such tight bounds may still be far off.} Complementing this, there is by now a handful of tight complexity bounds relative to clique-width (modulo SETH)~\cite{DBLP:conf/esa/IwataY15,DBLP:conf/soda/CurticapeanM16,DBLP:journals/dam/KatsikarelisLP19,DBLP:journals/siamdm/Lampis20,DBLP:conf/icalp/GanianHKOS22,DBLP:conf/esa/HegerfeldK23}. 
However, among these tight bounds there are almost none about connectivity-related problems (or problems with other kinds of non-local constraints), which are a natural target for theory development, especially when compared to what we know relative to treewidth/pathwidth as well as cutwidth. Only very recently did Hegerfeld and Kratsch~\cite{DBLP:conf/esa/HegerfeldK23} show how to solve \textsc{Connected Vertex Cover[$\cw$]} in time $6^{\cw}\cdot n^{\Oh(1)}$ and \textsc{Connected Dominating Set[$\cw$]} in time $5^{\cw}\cdot n^{\Oh(1)}$; moreover, they proved matching lower bounds modulo SETH. They conclude, however, that using their techniques they are unable to settle the complexity of other benchmark problems for which tight bounds are known relative to other width parameters, among them \textsc{Steiner Tree}, \textsc{Connected Odd Cycle Transversal}, and \textsc{Feedback Vertex Set}. What are these techniques and what seems to be the obstruction?

\paragraph{State of the art.}
Dynamic programming (DP) is the dominant (if not sole) algorithmic paradigm for dealing with problems on graphs of small width, i.e., problems parameterized by treewidth, cutwidth, clique-width, etc. The corresponding decomposition of the graph is traversed in a bottom-up manner while managing a sufficiently large selection of partial solutions or just some fingerprint thereof. Naive DP often relies on understanding the different ways in which a partial solution can interact with the rest of the graph (at cut or separator that is small or structured, depending on the used width parameter), and maintaining information for each type of interaction: 
Existence, optimal cost/value, or number of such partial solutions. 
Advanced DP, such as the cut-and-count technique~\cite{DBLP:journals/talg/CyganNPPRW22} or the so-called \emph{rank-based} approach~\cite{DBLP:journals/iandc/BodlaenderCKN15}, often relies on properties of certain \emph{matrices} that are already implicit in naive DP:
Rows of the matrix correspond to the possible interactions of partial solutions for a subgraph (for part of the decomposition); columns correspond to the ways of completing a partial solution to a solution for the full graph (not all of these need to be possible for any given graph). The entries of the matrix capture which combinations are possible. In this way, the dimensions of these matrices are usually equal to the number of types of partial solutions that are considered in a naive DP. Crucially, however, such a matrix may have favorable properties such as low rank (or even a useful low-rank factorization) or at least absence of large triangular/permutation submatrices, i.e., these may be much smaller than implied by its dimensions. (Now seems a good time to direct the reader to the insightful survey by Nederlof~\cite{DBLP:conf/birthday/Nederlof20}.)

So far, specific matrix properties seem aligned with the different problem types: Complexity of counting solutions over a field \fieldF depends on the \fieldF-rank of the matrix, complexity of finding an optimum cost/value solution (for small weights) depends on the maximum size of triangular submatrices, and complexity of decision depends on the maximum size of permutation submatrices.\footnote{A recent survey talk by Jesper Nederlof at Lorentz Center in Leiden (NL) helped (re)enforce this perspective.} Fortunately for settling complexity of optimization/decision problems, in most cases rank over some sensible field and dimensions of largest triangular/permutation submatrices coincide.\footnote{Overwhelmingly, such as with cut-and-count, one uses GF(2)-rank, which, however, corresponds to counting solutions modulo two. The well-known Isolation Lemma~\cite{MulmuleyVV87,DBLP:journals/talg/CyganNPPRW22} allows the necessary reduction of (small weight) optimization/decision to counting solutions of specified small weight modulo two.} This often enables the use of low-rank factorizations, i.e., intuitively a transformation of the space of partial solutions to a more convenient (i.e., smaller) one, with dimension then matching the rank, leading to the required fast DP algorithm. Apart from this, we still lack general methods for leveraging directly the absence of large triangular/permutation submatrices when the rank is larger. In principle, triangular/permutation submatrices are strongly related to bounds for so-called \emph{representative (sub)sets} of partial solutions,\footnote{Roughly, this means that having any set $\calS$ of partial solutions, there is a ``small'' \emph{representative} subset $\calS'\subseteq\calS$ that permits the same extensions to complete solutions, though not the same number of complete solutions.} so upper bounds on the dimensions of such submatrices are upper bounds on the required size of representative sets. Several results for (non-tight) DP algorithms rely on representative sets~\cite{DBLP:journals/iandc/BodlaenderCKN15,DBLP:journals/jacm/FominLPS16,DBLP:journals/talg/FominLPS17,DBLP:journals/tcs/BergougnouxK19,DBLP:journals/siamdm/BergougnouxK21}, often building on the \emph{rank}-based approach of Bodlaender et al.~\cite{DBLP:journals/iandc/BodlaenderCKN15}, so, not at all surprisingly, upper bounds on the rank are the means by which one leverages absence of the large triangular/permutation submatrices.\footnote{On the positive side, this works over any field, solves optimization with arbitrary weights, and works without randomization, such as required for the Isolation Lemma.}
For lower bounds, the story so far seems simpler, by comparison at least. Since the work of Lokshtanov et al.~\cite{DBLP:conf/soda/LokshtanovMS11a,DBLP:journals/talg/LokshtanovMS18} and Cygan et al.~\cite{DBLP:journals/corr/abs-1103-0534/CyganNPPRW11,DBLP:journals/talg/CyganNPPRW22}, lower bounds have certainly become increasingly complicated but the underlying principles largely remain the same. In particular, with current techniques there is no reason to hope for higher lower bounds than what we can get via the corresponding matrix property, e.g., not more than dimensions of largest triangular submatrix for optimization problems.\footnote{Notably, the situation for counting problems over some field $\fieldF$ seems easier as complexity appears to depend directly on the \fieldF-rank. That being said, crafting lower bound gadgets for these may be harder (see, e.g.,~\cite{DBLP:conf/soda/CurticapeanM16,DBLP:conf/soda/CurticapeanLN18,DBLP:conf/stacs/GroenlandMNS22,DBLP:conf/icalp/MarxSS21,DBLP:conf/soda/FockeMINSSW23}).}

\paragraph{Steiner Tree.}
Returning to \textsc{Steiner Tree[$\cw$]}, the $GF(2)$-rank of the relevant matrix, using graphs with $k=\cw$ labels, turns out to be (at least) $4^k$ while the largest known triangular submatrix is $3^k\times 3^k$ (basically inherited from \textsc{Steiner Tree} parameterized by treewidth or pathwidth). Current methods (such as in~\cite{DBLP:conf/esa/HegerfeldK23}) therefore yield an upper bound of time $4^{cw}\cdot n^{\Oh(1)}$ while there is no $(3-\varepsilon)^{\cw}\cdot n^{\Oh(1)}$ time algorithm, for any $\varepsilon>0$, assuming SETH. The most convenient solution would be to identify a $4^k\times 4^k$ triangular submatrix as this would likely lead to ruling out time $(4-\varepsilon)^{\cw}\cdot n^{\Oh(1)}$ (spoiler: this does not exist). Otherwise, one needs to leverage the absence of larger triangular submatrices but without the usual help of having a matching rank bound. Using representative sets (like in the rank-based approach) is unlikely to give a tight bound, due to the cost of reducing partial solutions to representative subsets via Gaussian elimination. We are aware of only two works so far that manage to overcome such a gap between rank and maximum size of relevant submatrices and obtain tight complexity bounds; both are for problems parameterized by cutwidth~\cite{DBLP:journals/tcs/JansenN19,DBLP:conf/stacs/BojikianCHK23}. Their approaches do not seem to transfer due to dependence on the specific problems and, crucially, on properties of graphs of small cutwidth.

\begin{table}
\newcommand{\expk}[1]{$\Oh^*({#1}^k)$}%
\newcommand{\tablespacing}{\hspace{0.25cm}}
\centering
\begin{tabular}{l@{\tablespacing}|@{\tablespacing}c@{\tablespacing}c@{\tablespacing}c@{\tablespacing}c}%
     & cutwidth & treewidth & modular-tw & clique-width\\%
    \hline%
    \\[-1em]
    \textsc{\textsc{$q$-Coloring}} & \expk{2} & \expk{q} & \expk{\binom{q}{\lfloor q/2\rfloor}} & \expk{(2^q-2)} \\%
    \textsc{Vertex Cover} & \expk{2} & \expk{2} & \expk{2} & \expk{2} \\
    \textsc{Connected Vertex Cover} & \expk{2} & \expk{3} & \expk{5} & \expk{6} \\
    \textsc{Connected Dominating Set} & \expk{3} & \expk{4}	& \expk{4} & \expk{5} \\
    \textsc{Steiner Tree}  & \expk{3} & \expk{3} & \expk{3} & $\boldsymbol{\ostar(3^k)}$ \\
    \textsc{Feedback Vertex Set} & \expk{2} & \expk{3} & \expk{5} & ? \\
    \textsc{Connected Odd Cycle Transversal} & \expk{4} & \expk{4} & ? & ? \\
    \hline%
    \\[-1em]
    References & \cite{DBLP:conf/stacs/BojikianCHK23,DBLP:journals/tcs/JansenN19,DBLP:journals/jgaa/GeffenJKM20} & \cite{DBLP:journals/corr/abs-1103-0534/CyganNPPRW11,DBLP:journals/talg/CyganNPPRW22,DBLP:journals/talg/LokshtanovMS18} & \cite{DBLP:conf/wg/HegerfeldK23,DBLP:journals/siamdm/Lampis20} & \cite{DBLP:conf/esa/HegerfeldK23,DBLP:journals/siamdm/Lampis20}%
\end{tabular}%
\caption{\label{table:tight-bounds}Tight complexity bounds (modulo SETH) for a selection of (connectivity) problems relative to cutwidth, treewidth, modular-treewidth, and clique-width. (Table adapted from~\cite{DBLP:conf/esa/HegerfeldK23}.)}
\end{table}

\paragraph{Our work.}
We close the gap for \textsc{Steiner Tree[$\cw$]} by developing a one-sided Monte Carlo algorithm (with false negatives only) that runs in time $3^{\cw}\cdot n^{\Oh(1)}$. Because $\cw(G)\leq\pw(G)+2$ for each graph $G$ (folklore), the known lower bound for \textsc{Steiner Tree[$\pw$]}~\cite{DBLP:journals/corr/abs-1103-0534/CyganNPPRW11} immediately rules out time $(3-\varepsilon)^{\cw}$ for all $\varepsilon>0$ assuming SETH. In fact, this lower bound holds already relative to cutwidth~\cite{DBLP:conf/stacs/BojikianCHK23}, so we get the same tight complexity of time $3^{k}\cdot n^{\Oh(1)}$ relative to all parameters between cutwidth and clique-width. This is a surprising behavior when compared with the behavior of other connectivity problems (see \cref{table:tight-bounds}) where complexity increases significantly for more general input structure. The following theorem formally states our main result.

%main result
\begin{theorem}\label{theorem:intro:mainresult}
 There is a one-sided error Monte Carlo algorithm (no false positives) that, given a graph $G=(V,E)$, a set of terminals $T\subseteq V$, a number $\budget$, and a $k$-clique-expression of $G$, takes time $3^k\cdot n^{\Oh(1)}$ and determines, with high probability, whether a connected subgraph $H$ of $G$ of exactly $\budget$ vertices exists that spans all of $T$.
\end{theorem}

Apart from settling the complexity of \textsc{Steiner Tree[$\cw$]}, the main interest of course lies in how the gap between $\bin$-rank and largest triangular submatrix could be overcome. We should remark that the description of the algorithm does not explicitly talk about any matrices and works entirely on the level of \emph{(connectivity) patterns}, i.e., on how partial solutions connect the different label classes in a partial graph corresponding to a part of the $k$-clique-expression.\footnote{We will still delve a little into the matrix perspective in \cref{sec:technicalcontribution} because we find it more instructive. After all, the project started by trying (and failing) to computationally find larger than $3^k\times 3^k$ triangular submatrices.} We identify a family of patterns, called \emph{complete patterns}, that are representative for the class of all patterns in a strong and constructive sense: For each pattern $p$ there is a set $R_p=\{q_1,\ldots,q_{\ell}\}$ of complete patterns that together completes into exactly the same solutions as $p$ does.
Crucially, we also identify a specific basis $\CSP$ of size $3^k$ to the submatrix induced by complete patterns only; so it has rank~$3^k$.

Hence, one might feel compelled to apply known techniques to leverage this small basis in a tight algorithm. However, a direct application might fall short of achieving this, since using the resulting basis, one can only count representations of partial solutions, but not the solutions themselves (see \cref{sec:technicalcontribution}). Instead, in addition to the usual step of isolating some optimal solution, we set up a second layer of isolation that assigns small random weights to actions in the DP, i.e., to the different contributions in the DP recurrences. The crux is that adding, e.g., a join between labels $i$ and $j$ creates connectivity patterns that are no longer complete and, in general, it takes several complete patterns to represent them. By giving each possible action at a node in the expression tree (there are never more than four different ones) its own random weight, we effectively isolate a single representation of the previously isolated solution (with sufficient probability). Beyond these technical contributions, we apply established tools for fast DP, e.g., fast convolutions~\cite{DBLP:conf/esa/RooijBR09,BjorklundHKKNP16, DBLP:conf/csr/Rooij21, DBLP:conf/esa/HegerfeldK23}. Let us nevertheless remark that our low-rank transformation is not via a corresponding cut-and-count basis but using a different set of (connectivity) states that is related to states in lower bounds in previous work~\cite{DBLP:conf/stacs/BojikianCHK23}.\footnote{This is purely for convenience though it seems interesting that exact cut-and-count is not mandatory. There is no reason to believe that this part of the algorithm could not be done via a cut-and-count-like factorization/basis.}

We think that our work will be instrumental for settling the (parameterized) complexity of further problems relative to less restrictive parameters like clique-width: First, \textsc{Steiner Tree[$\cw$]} isolates the hardness of connectivity and our approach via complete patterns may transfer more or less directly to other connectivity problems parameterized by clique-width. Second, more generally, we think that our method of isolating different representations of a solution via weighted actions in DP is a general and robust way of dealing with further cases, not just for connectivity, where we find a gap between the rank and the largest triangular/permutation submatrices, i.e., when the rank of the matrix is not the correct answer for the (parameter dependence in the) complexity.

\paragraph{Further related work.}
Clique-width was introduced by Courcelle and Olariu~\cite{CourcelleO00} building on work of Courcelle et al.~\cite{DBLP:journals/jcss/CourcelleER93} and it is similar to the NLC-width of Wanke~\cite{DBLP:journals/dam/Wanke94}. Courcelle et al.~\cite{DBLP:journals/mst/CourcelleMR00} showed that every graph problem expressible in MSO$_1$ logic (monadic second order logic of graphs with quantification over vertex sets but not edge sets) can be solved in linear time for graphs with a given $k$-clique-expression. In other words, all these problems are FPT when parameterized by clique-width, time $f(k)\cdot n$, though the function $f$ depends on the formula capturing the problem and may be non-elementary (cf.~\cite{DBLP:conf/icalp/Lampis13}), so likely far from being tight.\footnote{This is not an artifact of clique-width but fully analogous to Courcelle's theorem for graphs of bounded treewidth~\cite{DBLP:journals/iandc/Courcelle90,DBLP:journals/ita/Courcelle92} and corresponding lower bounds~\cite{DBLP:journals/apal/FrickG04}.} This tractability is not restricted to MSO$_1$-expressible problems but many other important problems are \classFPT with respect to clique-width or at least in \classXP, i.e., admitting a time $n^{f(\cw)}$ algorithm (see, e.g.,~\cite{DBLP:conf/wg/EspelageGW01}). Nevertheless, some problems, like \textsc{Disjoint Paths}, are \classNP-complete on graphs of bounded clique-width, while being \classFPT with respect to treewidth (cf.~\cite{DBLP:journals/tcs/GurskiW06}). The first single-exponential time algorithms for connectivity problems parameterized by clique-width were given by Bergougnoux and Kant\'e~\cite{DBLP:journals/tcs/BergougnouxK19,DBLP:journals/siamdm/BergougnouxK21}, e.g., \textsc{Steiner Tree}, \textsc{Connected Dominating Set}, and \textsc{Connected Vertex Cover} each in time $2^{\Oh(\cw)}\cdot n$, but building on the rank-based approach these bounds are likely not tight.

The main drawback of clique-width lies in the difficulty of finding good expressions, i.e., good bounds on the clique-width of given graphs, in reasonable time. Fellows et al.~\cite{DBLP:journals/siamdm/FellowsRRS09} showed that it is \classNP-complete to determine, on input of graph $G$ and integer $k$, whether the clique-width of $G$ is at most $k$. It is open, however, whether for each fixed value of $k$ there is an efficient algorithm for recognizing graphs of clique-width at most $k$; such algorithms are known only for $k\leq 3$~\cite{DBLP:journals/dam/CorneilHLRR12}. In particular, there is neither an \classFPT-algorithm for \textsc{Clique-Width[$k$]} known, nor is it known to be \classW{1}-hard with respect to $k$. The arguably best way for using low clique-width is an exponential-ratio \classFPT-algorithm due to Seymour and Oum~\cite{DBLP:journals/jct/OumS06} (made faster by Oum~\cite{DBLP:journals/talg/Oum08}). That being said, better algorithms for computing clique-width are still possible, and there may be variants of clique-width that give similar complexity (used as parameters) but are easier to compute.

Regarding further parameters relative to which there are tight bounds (modulo SETH) there is another width parameter called \emph{modular-treewidth/pathwidth}~\cite{DBLP:journals/siamdm/Lampis20,DBLP:conf/wg/HegerfeldK23}, which essentially falls between treewidth/pathwidth and clique-width.\footnote{It should be noted that the clique-width of a graph is at most exponential in its treewidth and, unfortunately, this bound is tight, making some comparisons of parameters and bounds a little awkward.} Generally, tight bounds modulo SETH seem mostly confined to parameterization by width parameters, where building gadgets for lower bounds seems easier. There are, though, a few examples where a tight bound holds for a so-called \emph{modulator} parameter or even for parameterization by \emph{solution size} (see, e.g.,~\cite{DBLP:conf/swat/Cygan12,DBLP:conf/stacs/PiecykR21,DBLP:journals/dam/JaffkeJ23,DBLP:conf/iwpec/HegerfeldK22}).

\paragraph{Organization.}
In \cref{sec:technicalcontribution} we provide a short review of our technical contribution, and outline our methods more formally. \cref{sec:pre} introduces the required notation.
In \cref{sec:pats} we define \emph{patterns} and prove a handful of their properties.
In \cref{sec:sol-pat}, we show how to represent partial solutions using patterns, and show that one can build all patterns corresponding to partial solutions over a syntax tree of a clique-expression recursively.
In \cref{sec:rep}, we show how to represent any set of patterns using complete patterns only.
In \cref{sec:rep-count} we show that one can compute the parity of weighted representations of weighted partial solutions using complete patterns recursively over the syntax tree. We also show that using the isolation lemma, one can isolate a single representation of the minimum weight solution with high probability.
In \cref{sec:parity-rep} we show that one can reduce any set of complete patterns into a set of $CS$-patterns in a way that preserves counting (over $\bin$). 
In \cref{sec:algo} we show how to compute the parity of representations of partial solutions using $CS$-patterns efficiently, proving the main theorem of this work.
We conclude in \cref{section:conclusion}.

\input{full.tex}

\section{Conclusion}\label{section:conclusion}

We design a one-sided Monte Carlo algorithm for the \textsc{Steiner Tree[$\cw$]} problem that given a graph $G=(V,E)$, a set $T\subseteq V$ of terminals, and a $k$-clique-expression computes in time $3^k\cdot n^{\Oh(1)}$ the minimum number of vertices over all connected subgraphs $H$ of $G$ that span $T$. Due to an existing lower bound for \textsc{Steiner Tree[$\pw$]} this establishes (modulo SETH) that the basis for the correct parameter dependence for \textsc{Steiner Tree[$\cw$]} is $3$. This answers an open problem of Hegerfeld and Kratsch~\cite{DBLP:conf/esa/HegerfeldK23} and settles the complexity of arguably \emph{the} prototypical connectivity problem relative to clique-width. 

One technical contribution is the identification of so-called \emph{complete patterns} for dealing with connectivity in the setting of clique-width and labeled graphs, as these are representative for all patterns. This alone may be sufficient to settle the complexity of further connectivity problems such as \textsc{Connected Odd Cycle Transversal[$\cw$]} (cf.~\cite{DBLP:conf/esa/HegerfeldK23}). Our second technical contribution, to \emph{isolate a representative solution}, is likely more broadly applicable: By giving weights to the possible actions in a DP, which in particular may create new representatives for a given partial solution, we are able to isolate among representatives. Thus, if there is also a unique solution to begin with (as can be ensured w.h.p.), then we also have a unique representative (again w.h.p.). This permits the combined use of both representative sets as well as low-rank factorization-based approaches for matrices of low GF(2)-rank and may be instrumental in overcoming rank-submatrix gaps beyond the immediate realm of connectivity problems.

Apart from \textsc{Connected Odd Cycle Transversal[$\cw$]}, both \textsc{Feedback Vertex Set[$\cw$]} and \textsc{Connected Feedback Vertex Set[$\cw$]} are good problems whose exact complexity to aim for. In particular, \textsc{Feedback Vertex Set[$\cw$]} brings a known difficulty in counting the number of edges outside the solution to enforce the acyclicity requirement (see Hegerfeld and Kratsch~\cite{DBLP:conf/esa/HegerfeldK23} and Bergougnoux and Kant\'e~\cite{DBLP:journals/tcs/BergougnouxK19,DBLP:journals/siamdm/BergougnouxK21}).


\bibliography{ref}
\end{document}
