% ****** Start of file apssamp.tex ******
%
%   This file is part of the APS files in the REVTeX 4.2 distribution.
%   Version 4.2a of REVTeX, December 2014
%
%   Copyright (c) 2014 The American Physical Society.
%
%   See the REVTeX 4 README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.2
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex apssamp.tex
%  2)  bibtex apssamp
%  3)  latex apssamp.tex
%  4)  latex apssamp.tex
%
\documentclass[aip,
 reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose, 
%preprint,
%preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4-2}


\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage{etoolbox}

\usepackage{chemformula}
\usepackage{chemfig}
\usepackage{mhchem}
\usepackage{physics} %$\bra{\Psi}\ket{\Psi}$ $\expval{A}{\Psi}$
\usepackage{amsfonts}

%% Apr 2021: AIP requests that the corresponding 
%% email to be moved after the affiliations
\makeatletter
\def\@email#1#2{%
 \endgroup
 \patchcmd{\titleblock@produce}
  {\frontmatter@RRAPformat}
  {\frontmatter@RRAPformat{\produce@RRAP{*#1\href{mailto:#2}{#2}}}\frontmatter@RRAPformat}
  {}{}
}%
\makeatother
\begin{document}

%\preprint{AIP/123-QED}

\title{ Molecular dynamics-driven global tetra-atomic potential energy surfaces: Application to the AlF dimer}

% Force line breaks with \\
\author{Xiangyue Liu}%
\author{Weiqi Wang}

\affiliation{Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, 14195 Berlin, Germany
}%

\author{Jes\'us P\'erez-R\'ios}
\affiliation{Department of Physics and Astronomy, Stony Brook University, Stony Brook 11794, New York (USA)}
\affiliation{Institute for Advanced Computational Science, Stony Brook University, Stony Brook, NY 11794-3800, USA}%
\email{jesus.perezrios@stonybrook.edu}

\date{\today}% It is always \today, today,
             %  but any date may be explicitly specified

\begin{abstract}

In this work, we present a general machine learning approach for full-dimensional potential energy surfaces for tetra-atomic systems. Our method employs an active learning scheme trained on {\it ab initio} points, which size grows based on the accuracy required. The training points are selected based on molecular dynamics simulations, choosing the most suitable configurations for different collision energy and mapping the most relevant part of the potential energy landscape of the system. The present approach does not require long-range information and is entirely general. As an example, we provide the full-dimensional AlF-AlF potential energy surface, requiring $\lesssim 0.1\%$ of the configurations to be calculated {\it ab initio}. Furthermore, we analyze the general properties of the AlF-AlF system, finding key difference with other reported results on CaF or bi-alkali dimers.  



\end{abstract}

\maketitle

\begin{quotation}

\end{quotation}




\section{Introduction}

The concept of potential energy surface (PES) is critical for understanding atomic and molecular systems' spectroscopic and scattering properties. As a result, the development of accurate potential energy surfaces (PESs) is one of the most active research areas in chemical physics. Using machine learning (ML) methods, new techniques have been developed for constructing accurate PESs. Precisely, the system's energy is calculated via high-level electronic structure methods for a given set of configurations used to train and test a given ML algorithm. Next, the same ML model is employed to predict the energy of new configurations. Several ML methods have been proposed ~\cite{ML1,ML2,ML3,ML4,christianen2019six,Activelearning,Activelarning2}, for example, one pioneering approach is the permutation invariant polynomial-neural network (PIP-NN)~\cite{jiang2013permutation}, in which permutation invariant polynomials~\cite{braams2009permutationally} depending on the inverse of interatomic distances or Morse-like potentials~\cite{permutation,permutation1,permutation2,permutation3,permutation4}, for a given geometry, are used as the input of a feed-forward neural network, yielding promising results up to systems with 15 degrees of freedom~\cite{Bin2016}. However, for tetra-atomic systems, it requires more than 70000 \textit{ab initio} points to reach a global root mean square error of 40~cm$^{-1}$ ~\cite{Bin2016}. In a different vein, it has been possible to use piece-wise Ml methods such that a Gaussian process regression (GPR) is employed in the short-range interaction region. At the same time, the long-range tail of the potential is fitted given a particular functional form~\cite{christianen2019six}. In this approach, the overall accuracy is not as good as in the case of PIP-NN. However, with only 2000 \textit{ab initio} points, it was possible to reach a root mean square error between 140 and 4~cm$^{-1}$, depending on the region of the PES. Therefore, using more training points in a particular region, the accuracy of the PES improves, as it has been shown via active learning approaches~\cite{Activelearning,Activelarning2,rasheeda2022high}.

Most ML models rely on uniform sampling of the degrees of freedom or interatomic distances. Hence, many training points are required to achieve a given accuracy. However, when calculating scattering properties based on a given underlying PES, it is well-known that the collision energy (or temperature in the case of a canonical ensemble) establishes the relevance of specific configurations, generally related to transition states and local minima. Therefore, when ML-based PESs are used for dynamics calculations, the prediction for relevant configurations may have considerable uncertainty, thus, yielding significant errors in the scattering observables. However, this situation can be avoided after identifying the most pertinent configurations contributing to a given collision energy and including those into the training set, reducing the number of required \textit{ab initio} points while reaching a high accuracy. 

This paper presents a general method to construct PESs for tetra-atomic systems based on an ML approach exploiting a novel selection of atomic configurations. The training configurations are chosen from molecular dynamics (MD) simulations in various temperatures to ensure they sample the same configurational space as their practical usage. Next, the training set is enlarged by including more required configurations via an active learning scheme, leading to an optimal strategy for dynamics calculations for tetra-atomic systems. As a proof of concept, we apply our method to the PES of the AlF dimer, being of interest in the study of ultracold molecules from direct cooling techniques~\cite{Truppe2019, Simon, Max} and showing very intriguing chemistry in buffer gas cells~\cite{Liu2022,Sidney2022}. 

%However, ultracold molecule-molecule collisions may lead to the formation of long-lived complexes, as observed in bi-alkali molecules~\cite{sticky,stickyRbCs,christianen2019quasiclassical,toymodel,Croft2014,Mayle2012,Mayle2013}, resulting in a significant unexpected molecular loss~\cite{observationRbCs,Bimolecular} and compromising the utility of ultracold molecules in many applications. Therefore, it is crucial to comprehend the dynamical behavior of the AlF-AlF complex through molecular dynamics (MD) simulations. By employing the active-learning scheme proposed in this study, an accurate PES for the AlF-AlF complex has been efficiently constructed.

%As a result, we find that only 0.001$\%$ of the configurations visited by a molecular dynamics trajectory are calcualted \textit{ab initio} for the computation of a trajectory. 

%Therefore, we provide an optimal fitting approach for dynamics calculations on tetra-atomic PESs. 


\section{Theory and methods{\label{sec:method}}}

In molecular interactions, the Coulomb and exchange interactions dominate at short range. In contrast, the dispersion and induction interactions dominate at distances beyond the LeRoy radius. As a result, a machine learning-based PES should encode the system's geometry with sufficient structural information to establish the structure-energy relationship as a non-linear regression problem.


\subsection{Dimer representation}

% The representation of geometry
%The geometry of a system can be described with different sets of coordinates. For example, 

The interaction between two diatomic molecules has six degrees of freedom, and it is better described using Jacobi coordinates. As shown in Fig.\ref{fig:Jacobi} for the case of the AlF-AlF dimer, the Jacobi coordinates consist of two interatomic distances, three angles, and the intermolecular distance $R$ joining the center of mass of the two molecules. In principle, a representation should obey the same symmetries preserving or changing the energy \cite{bowman2011high,jiang2013permutation,mbtrhuo2017unified}. In this respect, Jacobi coordinates maintain translational and rotational symmetry. In contrast, they can not keep the permutational invariant of the system. However, the permutational invariant symmetry is restored using a representation given by a series of $n$-body interaction terms $\{G(\mathbf{x},\mathbf{i})\}$ with a symmetrization operator $\hat{S}$ accounting for the permutational symmetry of the system.

The energy for a given configuration of atoms is described via a Gaussian process as

\begin{equation}
    E(\mathbf{x}) \sim \text{GP}(m(f(\mathbf{x})), k(f(\mathbf{x}), f(\mathbf{x}'))),
\end{equation}
where
\begin{equation}
f(\mathbf{x}) = \hat{S} \{ G(\mathbf{x},\mathbf{i}) \},
\end{equation}
$\mathbf{x}$ represents any geometry variable, and $i$ labels atoms within the molecular system. In order to capture both Coulomb and long-range interactions, we consider two-body interactions described by the inverse interatomic distances $1/\bar{r}_{ij}$ between atoms $i$ and $j$, as well as Morse-like exponential terms $e^{-\bar{r}_{ij}}$.~\footnote{We have also tested the performance with additional representations of higher orders, e.g. three-body polar angles and four-body dihedral angles, however, the improvement is negligible in the AlF-AlF system.} To differentiate the chemical distinctions between various pairs of atoms, the interatomic distance $\bar{r}_{ij}$ has been normalized by the equilibrium interatomic distance $r^*_{ij}$, i.e. $\bar{r}_{ij}=r_{ij}/r^*_{ij}$.  



    % Figure environment removed



%\textcolor{red}{More details about different kernel combinations?}
%The final model is selected by minimizing the root-mean-square error (RMSE) of the validation set and tested on a separate test set. In particular, we find that the Matérn kernel with $\nu=2.5$ plays an essential role in the model to provide acceptable accuracy. Furthermore, the non-fixed hyperparameters of the kernels are optimized by maximizing the marginal likelihood with gradient ascent. 

\subsection{\textit{Ab initio} calculations}

We have calculated \textit{ab initio} energies using coupled-cluster theory with single, double, and perturbation triples [CCSD(T)] implemented in the Molpro package~\cite{molpro,werner2012molpro}. During MD simulations, the \textit{ab initio} forces have been calculated at the second‐order Møller–Plesset perturbation theory (MP2) level. The calculations were performed with the aug-cc-pVQZ basis set~\cite{avqzdunning1989gaussian,avqzkendall1992electron, avqzwoon1993gaussian}. 

\subsection{Construction of the PES}
\label{Construction_PES}

Herein, GPR \cite{gprwilliams2006gaussian} is used to find the relationship between the structural representation and the energy of the system, leading to a non-parametric fitting of the PES, i.e., no functional form is assumed for the representation of the PES. GPR assumes a Gaussian distribution of functions over a function space, and kernel functions are employed as the covariance of the Gaussian process random variables. Once exposed to a data set, a posterior of the function distribution for new structures can be obtained following the Bayes theorem.

%for input representations of new structures. 

%. Then the posterior is used to make predictions 

The kernel function determines the shape of the prior and posterior distribution. We have tested different kernel function combinations by analyzing the mean absolute error (MAE) and median absolute error of the test set predictions. As a result, the Matérn kernel with $\nu=5/2$ turns out to be the most accurate kernel. Furthermore, the non-fixed hyperparameters of the kernels are optimized by maximizing the marginal likelihood with gradient ascent.   

The reference datasets have been created using initial sets of energies from eight \textit{ab initio} MD trajectories and later extended configurations obtained through active learning during the MD simulation. The initial MD trajectories were run within the canonical ensemble at 200 and 800~K, starting from different initial configurations. As a result, we sample configurations relevant to short-range as well as long-range interactions. Specifically, the sampled data's intermolecular distance $R$ ranges from approximately 1.5 to 17.5 \AA ~. From these trajectories, different numbers of configurations are randomly chosen and taken as training sets. In contrast, the GPR predictions are tested against the configurations visited in a different MD trajectory of 3633 steps. In a second version of the approach, we have selected 2271 and 5026 ``landmarks'' for two additional training sets, which are the configurations with the longest high-dimensional distances from the others in the representation space, chosen from the eight trajectories and tested against the same MD trajectory of 3633 steps.

%From the MD trajectories we have chosen 2000, 5000 and 10000 random configurations to construct three training sets and tested against another \textit{ab initio} MD trajectory consisting of 3633 steps. Additionally, we have selected 2271 and 5026 ``landmarks'' for two additional training sets, the configurations with the longest high-dimensional distances from the others in the representation space, chosen from the eight trajectories.

%To study the practicability of our approach, 2000, 5000, and 10000 configurations have been randomly selected from the MD trajectories to construct three training sets and tested against another \textit{ab initio} MD trajectory consisting of 3633 steps. Additionally, we have selected 2271 and 5026 ``landmarks'' for two additional training sets, the configurations with the longest high-dimensional distances from the others in the representation space, chosen from the eight trajectories.
    % Figure environment removed

\subsection{Active learning scheme}
\label{sec.activelearning}

It is well-known that the accuracy of ML or any fitting approach depends on the region of the PES under consideration. Particularly, the repulsive wall of the PES is the hardest to describe, leading to considerable uncertainty in the predictions. In the meantime, some regions in the training sets might be sparsely sampled, leading to larger prediction uncertainty in those areas. However, these effects can be mitigated by including more configurations in the training set. But, more configurations require more \textit{ab initio} points, leading to longer computational times. Here, we avoid this situation via an active learning approach. 


Our active learning scheme is illustrated in Fig.~\ref{fig:active_learning}. First, we are ready to predict the energy value of a new configuration after training the model on a given initial training set of \textit{ab initio} points. We will have a prediction based on the GPR and its uncertainty for this new configuration sampled by the next MD step. Then, if the uncertainty is smaller than a given threshold, we use the GPR prediction. Otherwise, we require an \textit{ab initio} point. In this case, the new configuration is included in the training set for the next prediction and will be used in the next MD step. This process is repeated as many times as required until the configuration sampling converges. %This process is repeated as many times as required, depending on the accuracy threshold and the number of new configurations under consideration. 

%Specifically, the uncertainty of GPR predictions in comparison with a given convergency thrshol, is the key parameter to determine wheter has been utilized at each MD step as a criterion to determine whether a configuration requires \textit{ab initio} calculation. By revealing the correlation between the prediction uncertainty and the absolute error across all models, Fig.~\ref{fig:error_vs_uncertainty} provides further evidence supporting the effectiveness of using uncertainty $>0.01$ eV as a criterion. 




%In addition to the MD-sampled reference datasets, we construct a training set through a random hypercube sampling of the Jacobi coordinates of the dimer, as depicted in Fig.~\ref{fig:Jacobi}. Specifically, we varied the Al-F bond length $r_{Al-F}$ and the intermolecular distance $R$ over a range of $2.5$ to $25$ and $1.5$ to $75$ \AA, respectively. The angular degrees of freedom $\theta_1$, $\theta_2$, and $\phi$ were varied over a range of $0$ to $\pi$.



%\subsection{Thermodynamic stability}

\section{Results and discussions}

To test the accuracy and efficiency of the present method, the PES models have been trained with several different initial training sets constructed as described in Sec.\ref{Construction_PES}. Fig.\ref{fig:energy_ML_vs_CCSDt} compares the model predictions against a test set generated from an \textit{ab initio} MD trajectory of 3633 steps simulated at 800~K. As expected, the performance of the models trained with randomly-selected configurations improves with increasing training set size. Increasing the size of the training set from 2000 to 5000 reduces the error by approximately 25$\%$, as shown in Table~\ref{tab:error_range}, with the mean and median absolute errors for the 5000-configuration training set of 0.78 meV/atom and 0.018 meV/atom, respectively, demonstrating high accuracy of the models with more training data. With 10000 training configurations, the accuracy remains the same as with 5000 configurations, but the predictions on the outliers with the highest energies become closer to the reference energy. On the other hand, despite the impressive overall accuracy of the models, they show a lower accuracy for configurations yielding high interaction energies, corresponding to the repulsive region with short intermolecular distance $R$.

 % Figure environment removed



\begin{table*}[]
\footnotesize
\caption{The mean absolute error and median absolute error for the test set with 3633 MD steps, presented in meV/atom, with the errors reported for the entire test set, as well as for configurations within different intermolecular ranges of $R$ (in \AA).}
\label{tab:error_range}
\begin{tabular}{lclllllllllllllll}
\hline
              & \multicolumn{8}{c}{Mean absolute error (meV/atom)}                                                            & \multicolumn{8}{c}{Median absolute error (meV/atom)}                                                           \\

              & all & {[}0,2.5{]} & {[}2.5,5{]} & {[}5,7.5{]} & {[}7.5,10{]} & {[}10,12.5{]} & {[}12.5,15{]} & {[}15,17.5{]} & all & {[}0,2.5{]} & {[}2.5,5{]} & {[}5,7.5{]} & {[}7.5,10{]} & {[}10,12.5{]} & {[}12.5,15{]} & {[}15,17.5{]} \\
              
              \hline
Model 2000    & 1.18  & 15.1        & 2.9         & 0.41        & 0.088        & 0.013         & 0.0088        & 0.022         & 0.024 & 4.49        & 1.51        & 0.25        & 0.048        & 0.009         & 0.0068        & 0.0069        \\
Model 5000    & 0.78  & 6.80        & 2.67        & 0.36        & 0.070        & 0.014         & 0.0077        & 0.0080        & 0.018 & 3.05        & 1.37        & 0.19        & 0.031        & 0.010         & 0.0055        & 0.0047        \\
Model 10000   & 0.85  & 6.50        & 3.06        & 0.49        & 0.071        & 0.014         & 0.0077        & 0.0071        & 0.019 & 2.74        & 1.65        & 0.19        & 0.071        & 0.010         & 0.0052        & 0.0039        \\
Landmark 2271 & 0.81  & 4.70        & 3.16        & 0.52        & 0.074        & 0.032         & 0.023         & 0.027         & 0.044 & 2.24        & 1.57        & 0.27        & 0.047        & 0.021         & 0.019         & 0.021         \\
Landmark 5026 & 0.85  & 5.99        & 3.18        & 0.51        & 0.065        & 0.016         & 0.012         & 0.012         & 0.024 & 2.14        & 1.63        & 0.22        & 0.034        & 0.010         & 0.0093        & 0.0089       \\

\hline

\end{tabular}
\end{table*}


To further understand the accuracy of our model as a function of $R$, we have computed the mean absolute error for different regions of $R$, as shown in Fig.~\ref{fig:MAE_vs_R}. This figure shows that the region with $R \in [0,2.5]$, shows the largest mean absolute error across all models. On the contrary, for $R > 7.5$ \AA\, the errors are less than 0.1 meV/atom with all models. A more detailed study is presented in Table~\ref{tab:error_range}, where we report on the mean and median absolute errors, and both error estimators point to a lack of configurations with $R \in [0,2.5]$. 


As introduced in Sec.~\ref{Construction_PES}, two additional training sets have been constructed with 2271 and 5026 landmark configurations. This approach aims at reducing the number of training data, thereby expediting the training process, assuming that the landmarks are representative of the sampled configurational space. Indeed, the training set with landmarks provides similar overall accuracy as the models constructed from the training set with 10000 randomly selected configurations. However, keeping in mind that the accuracy of randomly sampled points is not enough in the short-range region, and given that trajectories in the thermal regime will visit the short-range interaction region, we conclude that using the most relevant configurations visited by the MD simulations as training points leads to a more accurate PES model.  

%that at high temperatures the MD simulation samples massively configurations in the free collision region


%Then, taking into accoutn that at 

%However, the errors in the long-range tail of the PES are much larger than the models constructed from randomly selected configurations (see Table~\ref{tab:error_range}). Given that at high temperatures the MD simulation samples massively configurations in the free collision region, it suggests that these models may not be ideal for use in the simulation. Therefore, using as training points the most relevant configurations visited by the MD simulations leads to a more accurate PES model. 

% Figure environment removed


We switch to our active learning scheme introduced in Sec.~\ref{sec.activelearning} to generate more training points. First, we check the correlation between the prediction uncertainty and the absolute error across all models. The results are shown in Fig.~\ref{fig:error_vs_uncertainty}, where a correlation is noticed between the absolute error of a GPR prediction and its uncertainty. Hence, the uncertainty of the prediction is a good parameter to estimate the quality of the prediction when compared against a given accuracy threshold.  

To compare the efficiency of the initial PES models trained using training sets of varying sizes, we have applied our active learning strategy based on different initial training sets, and the results are displayed in Fig.~\ref{fig:N_new_points}. All models are exposed to 3633 new configurations from a single MD simulation. With the uncertainty threshold set to be 0.01~eV, the models trained on the configurations randomly selected from eight MD trajectories require around $10\%$ of the configurations to be calculated \textit{ab initio}. As expected, the models with more training data require fewer additional \textit{ab initio} calculations. We have also observed a convergence behavior of new \textit{ab initio} points with respect to the number of MD steps. This indicates that in longer simulations, it is likely that fewer than $10\%$ of the configurations need to undergo \textit{ab initio} calculations. Similarly, training sets with landmark configurations show an almost identical efficiency. On the contrary, the initial model trained on hypercubic grids requires the \textit{ab initio} evaluation of almost $65\%$ of the configurations, showing the poor efficiency of Latin hypercube sampling schemes specifically in the case of MD simulations. Therefore, a Latin hypercube sampling will lead to long computational times, whereas a sampling using our MD-driven PES model will be more efficient. 



%We have also compared the efficiency of the initial PES models trained using training sets of varying sizes, which is indicated by the number of additional configurations that require \textit{ab initio} calculations when using a prediction uncertainty threshold of $>0.01$ eV as the criterion. As shown in Fig.~\ref{fig:N_new_points}, with models trained on the configurations randomly selected from eight MD trajectories, additionally around $1/10$ of the configurations in the 3633 test-set MD steps require \textit{ab intio} calculation. As expected, the models with more training data require fewer additional calculations. Using training sets with landmark configurations can not significantly improve the efficiency. On the contrary, the initial model trained on hypercubic grids requires almost $2/3$ configurations to be re-calculated and is therefore inefficient for the MD simulation. We have also noticed a convergence behavior with respect to the MD steps, therefore we expect only a smaller percentage of additional \textit{ab intio} points are required in the practical MD simulation on the lifetime of AlF-AlF complex. 


%As discussed in Sec.~\ref{sec:PES}, the model predictions exhibit a substantially bigger inaccuracy in the repulsive region compared to free collision regions. However, by introducing more configurations in the training set, this can be changed. As a result, employing an active learning strategy during MD simulation can be useful. This approach has been illustrated by Fig.~\ref{fig:active_learning}. Specifically, the uncertainty of GPR predictions has been utilized at each MD step as a criterion to determine whether a configuration requires \textit{ab initio} calculation.

%By revealing the correlation between the prediction uncertainty and the absolute error across all models, Fig.~\ref{fig:error_vs_uncertainty} provides further evidence supporting the effectiveness of using uncertainty $>0.01$ eV as a criterion. 



    % Figure environment removed




    % Figure environment removed
%The previous tests are conducted on the test set with 3633 configurations from an MD trajectory. 
In practice, MD simulations can be much longer than this test case to sample the configurational space and reach equilibrium adequately. To further assess the feasibility of our approach in realistic simulations, we have performed a simulation using the replica-exchange molecular dynamics (REMD) method \cite{REMDmarinari1992simulated, REMDsugita1999replica}. REMD is an enhanced sampling technique that facilitates the attainment of dissociation equilibrium at low temperatures more efficiently. In particular, we simultaneously simulated 10 trajectories at temperatures ranging from 200 K to 1000 K. The total simulation time reaches 5.4 ns in each of the ten replicas. The active learning approach described above has been employed with an initial PES model trained with 22,365 configurations obtained from all of the nine MD trajectories. During the REMD simulation, a total of 2038 configurations ($\sim0.008\%$) out of 26,891,350 REMD steps have been selected to be further calculated with CCSD(T) method, based on a criterion of prediction uncertainty $0.05$ eV. These additional configurations are primarily located at the regions with intermolecular distance $R<5$ \AA, as depicted in Fig.~\ref{fig:distribution_R_PEC} (a). The accuracy of this model is tested by a comparison between the CCSD(T) reference energies and the model predictions for a one-dimensional profile of the PES, as shown in Fig.~\ref{fig:distribution_R_PEC} (b). The model demonstrates a high global accuracy, although the uncertainty is notably more significant in the repulsive region than in the long-range one. 


    % Figure environment removed


    
\section{Properties of the PES}

We start by analyzing the general properties of the \textit{ab initio} PES, and the results are summarized in Table~\ref{tab:energies}. Among them,  it is worth highlighting that the reactants need to surmount 11.56~eV of energy to yield \ce{AlF} + \ce{AlF} $\rightarrow$ \ce{Al2} +  \ce{F2}. Therefore, this reaction is highly endothermic.  

%The reaction between two AlF molecules is basically non-reactive since the only stable product \ce{AlF} + \ce{AlF} $\rightarrow$ \ce{Al2} +  \ce{F2} is a highly endothermic reaction pathway with an energy of 11.56 eV (Table~\ref{tab:energies}). As a result, we will focus on the transitions between AlF molecules and the complex \ce{AlF-AlF}.

\begin{table}[h]
\caption{The CCSD(T)/aug-cc-pVQZ relative energies of various configurations. The energies are referenced to the potential energy of two AlF molecules with the intermolecular distance $R$ = 20 \AA. In this case, the geometry of AlF molecule has been fixed to its CCSD(T)-optimized geometry with $d$(AlF) = 1.669 \AA.}
\label{tab:energies}
\begin{tabular}{cc}
\hline
Configuration                            & Relative energy (eV) \\ 
\hline
AlF + AlF ($d$(AlF-AlF) = 20 \AA)        & 0.0                  \\ 
AlF-AlF complex                          & -0.696               \\ 
Al$_2$ + F$_2$ ($d$(Al$_2$-F$_2$) = 20 \AA)    & 11.561               \\ 
Dissociated 4 atoms ($d$(Al-F) = 20 \AA) & 18.167               \\ 
\hline
\end{tabular}
\end{table}


    
The stable configuration of the AlF-AlF complex has been optimized with the PES model with the Fast Inertial Relaxation Engine (FIRE) method \cite{bitzek2006structural}. The resulting geometry shows a D$_{2h}$ symmetry, with all Al-F bond lengths being the same. This geometry reproduces CCSD(T)-optimized geometry, with differences in Al-F bond lengths of less than 0.0004 \AA, while the predicted energy is 0.0025 eV higher than CCSD(T) result. It turns out that there is no barrier for the atom-exchange reaction Al$^{(1)}$F$^{(2)}$ + Al$^{(3)}$F$^{(4)}$ = Al$^{(1)}$F$^{(4)}$ + Al$^{(3)}$F$^{(2)}$. Indeed, this reaction has frequently been observed during the reported MD simulations for the AlF dimer. 

%such a reaction has been frequently observed during the MD simulations of the AlF-AlF complex. 

    % Figure environment removed

Interestingly, the D$_{2h}$ configuration is the only stable configuration in the PES, in contrast to the behavior observed in CaF\cite{sardar2023four} or NaK \cite{christianen2019six}. Regardless of the initial configurations used, the geometry optimization of AlF-AlF consistently converges to the stable D$_{2h}$ configuration. Other configurations, such as the local minimum configuration found for the CaF-CaF complex with C$_s$ symmetry, are unstable for the AlF-AlF complex. 

\section{Conclusions}

In this work, we have introduced a general ML method to fit tetra-atomic potential energy surfaces. The method exploits the most relevant configurations for a given MD simulation at a given temperature as the training set to feed a GPR to predict the energy of new configurations. This process can be adapted to satisfy a given threshold criteria, reaching the required accuracy for a given system. As a result, it is possible to construct highly accurate tetra-atomic potential energy surfaces requiring $\lesssim 0.1\%$ of the configurations to be calculated \textit{ab initio}. Hence, delivering accurate results with low computational effort. 

We have applied the method to AlF-AlF as proof of concept, finding a single minimum contrary to previous results in bi-alkali molecules or CaF. The four-body complex shows a binding energy of 0.69~eV. Therefore, it may be the case that AlF-AlF offers a very different complex lifetime than CaF or bi-alkali systems. This topic is under consideration in our group and will be published elsewhere. 

Finally, our method opens up a new avenue for MD simulations in tetra-atomic systems by delivering accurate but computationally cheap, full-dimensional potential energy surfaces. On the other hand, extending our approach to a larger system is possible when combined with a representation that considers the system's symmetry. 

%The method is fully general and adapted to any particular energetic condition under consideration thanks to our adaptative learning approach, in which the number of required points depend on the configurations explored and the accuracy required. As a proof of concept, we have applied the method to AlF-AlF, finding a single minimum contrary to previous results in bi-alkali molecules or CaF. 

%with applications in MD simulations. The method:

%\begin{itemize}
%\item Employs MD simulations to generate the configurations. These configurations are encoded via new features that make our methodology highly efficient.

%\item Is in principle applicable to any tetra-atomic system.
%\end{itemize}

%In particular, we have applied the method to AlF-AlF, finding a single minimum contrary to previous results in bi-alkali molecules or CaF. Furthermore, the four-body complex shows a binding energy of 0.69~eV. 


%In addition, our method can deliver an accurate PES for dimers by using GPR predictions for $99\%$ of the required configurations.




%Furthermore, we have shown that AlF-AlF collisions lead to nonreactive processes due to the formation of intermediate van der Waals complexes. Indeed, the nature of the intermediate complex, in virtue of the RRKM theory, will lead to shorter lifetimes than in the case of bi-alkali molecules, thus binding AlF from trap losses as opposed to the case of bi-alkali molecules. The same should apply to AlCl due to its similarity to AlF. Therefore, AlF and ClF molecules should not present stability issues when trapped in an optical field. Finally, it is worth mentioning that with our hybrid method followed by MD simulations, it would be possible to study complex lifetimes and properties of polyatomic systems.

%thus, making of direct cooling molecules an advantage over indirect cooling molecules.  

%Finally, this work is the first to show that the effort to perform direct cooling in some molecules could pay back once the ultracold regime is finally reached. 


%Furthermore, we have shown that AlF-AlF collisions are non reactive process due to the formation of intermediate van der Waals complexes that impede an efficient energy transfer between the bond length of the AlF molecules and the intermolecular distance. In the framework of the Rice–Ramsperger–Kassel–Marcus (RRKM) theory, the van der Waals nature of the intermediate complex clearly indicates that the density of states should be much lower than in the case of bi-alkali molecules, presenting a covalent type of complex. As a result, the lifetime of the \ce{AlF-AlF} complex in the ultracold regime should be much shorter than bi-alkali systems; thus, shielding AlF from unwanted loss in optical trapping experiments. 






\begin{acknowledgments}
J. P.-R. acknowledges discussions with Gerrit Groenenboom and the support of the Air Force Office of Scientific Research under award number FA9550-23-1-0202. 
X. Liu acknowledges the support of the Deutsche Forschungsgemeinschaft (DFG – German Research Foundation) under grant number PE 3477/2 - 493725479.
W. W acknowledges funding by the Max Planck-Radboud University Center for Infrared Free Electron Laser Spectroscopy. 

%For presentations (especially outside the center) and publications: the financial support of the Max Planck Radboud University Center for Infrared Free Electron Laser Spectroscopy must be acknowledged. For a publication with a center PhD student named "Firstname Lastname" as (co-)author the text is:
%F.L. acknowledges funding by the Max Planck-Radboud University Center for Infrared Free Electron Laser Spectroscopy. 
%After publication, a PDF file (in journal layout) must be mailed to giel.berden@ru.nl

\end{acknowledgments}

\section*{Data Availability Statement}
The datasets and the computer codes for the training and test of the potential energy surface model are available at the git repository \url{https://github.com/onewhich/AlF_dimer}.

%\appendix

%\section{Appendixes}


\nocite{*}
\bibliography{apssamp}% Produces the bibliography via BibTeX.

\end{document}
%
% ****** End of file aipsamp.tex ******
