% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in
  context,'' in \emph{ECCV}.\hskip 1em plus 0.5em minus 0.4em\relax Springer,
  2014, pp. 740--755.

\bibitem{hendrycks2019benchmarking}
D.~Hendrycks and T.~Dietterich, ``Benchmarking neural network robustness to
  common corruptions and perturbations,'' \emph{arXiv preprint
  arXiv:1903.12261}, 2019.

\bibitem{thoppilan2022lamda}
R.~Thoppilan, D.~De~Freitas, J.~Hall, N.~Shazeer, A.~Kulshreshtha, H.-T. Cheng,
  A.~Jin, T.~Bos, L.~Baker, Y.~Du \emph{et~al.}, ``Lamda: Language models for
  dialog applications,'' \emph{arXiv preprint arXiv:2201.08239}, 2022.

\bibitem{chowdhery2022palm}
A.~Chowdhery, S.~Narang, J.~Devlin, M.~Bosma, G.~Mishra, A.~Roberts, P.~Barham,
  H.~W. Chung, C.~Sutton, S.~Gehrmann \emph{et~al.}, ``Palm: Scaling language
  modeling with pathways,'' \emph{arXiv preprint arXiv:2204.02311}, 2022.

\bibitem{openai2023gpt4}
OpenAI, ``Gpt-4 technical report,'' \emph{arXiv preprint arXiv:2303.08774},
  2023.

\bibitem{Bing-chat}
Microsoft, ``Bing chat enterprise announced, multimodal visual search rolling
  out to bing chat,'' 2023, available online at:
  \url{https://blogs.bing.com/search/july-2023/Bing-Chat-Enterprise-announced,-multimodal-Visual-Search-rolling-out-to-Bing-Chat},
  last accessed on 27.07.2023.

\bibitem{LLaVA-Bench}
``Llava-bench: In the wild,'' 2023, available online at:
  \url{https://github.com/haotian-liu/LLaVA/blob/main/docs/LLaVA_Bench.md},
  last accessed on 27.07.2023.

\bibitem{Li_2019_CVPR}
S.~Li, I.~B. Araujo, W.~Ren, Z.~Wang, E.~K. Tokuda, R.~H. Junior,
  R.~Cesar-Junior, J.~Zhang, X.~Guo, and X.~Cao, ``Single image deraining: A
  comprehensive benchmark analysis,'' in \emph{CVPR}, June 2019.

\bibitem{hassan2020visual}
S.~Z. Hassan, K.~Ahmad, S.~Hicks, P.~Halvorsen, A.~Al-Fuqaha, N.~Conci, and
  ichael Riegler, ``Visual sentiment analysis from disaster images in social
  media,'' 2020.

\bibitem{fan2022concealed}
D.-P. Fan, G.-P. Ji, M.-M. Cheng, and L.~Shao, ``Concealed object detection,''
  \emph{IEEE TPAMI}, vol.~44, no.~10, pp. 6024--6042, 2022.

\bibitem{maji2013fine}
S.~Maji, E.~Rahtu, J.~Kannala, M.~Blaschko, and A.~Vedaldi, ``Fine-grained
  visual classification of aircraft,'' \emph{arXiv preprint arXiv:1306.5151},
  2013.

\bibitem{sun2023indiscernible}
G.~Sun, Z.~An, Y.~Liu, C.~Liu, C.~Sakaridis, D.-P. Fan, and L.~Van~Gool,
  ``Indiscernible object counting in underwater scenes,'' in \emph{CVPR}, 2023,
  pp. 13\,791--13\,801.

\bibitem{fan2023advances}
D.-P. Fan, G.-P. Ji, P.~Xu, M.-M. Cheng, C.~Sakaridis, and L.~Van~Gool,
  ``Advances in deep concealed scene understanding,'' \emph{Visual
  Intelligence}, 2023.

\bibitem{singh2019towards}
A.~Singh, V.~Natarjan, M.~Shah, Y.~Jiang, X.~Chen, D.~Parikh, and M.~Rohrbach,
  ``Towards vqa models that can read,'' in \emph{CVPR}, 2019, pp. 8317--8326.

\bibitem{ji2022video}
G.-P. Ji, G.~Xiao, Y.-C. Chou, D.-P. Fan, K.~Zhao, G.~Chen, and L.~Van~Gool,
  ``Video polyp segmentation: A deep learning perspective,'' \emph{Machine
  Intelligence Research}, vol.~19, no.~6, pp. 531--549, 2022.

\bibitem{lobry2020rsvqa}
S.~Lobry, D.~Marcos, J.~Murray, and D.~Tuia, ``Rsvqa: Visual question answering
  for remote sensing data,'' \emph{IEEE TGRS}, vol.~58, no.~12, pp. 8555--8566,
  2020.

\end{thebibliography}
