\section{Evaluation Results}
\label{sec:experiments}



We now discuss detailed evaluation results of DCA using our data sets and over a variety of settings.
\begin{table*}
\vspace{-0.1in}
\label{effectivness-table}
\centering
\begin{tabular}{|p{100pt}|p{50pt}|p{40pt}|p{40pt}|p{40pt}||p{40pt}|}
\hline
{\textbf{Baseline Disparity}}  &Low-Income&ELL&ENI&Special Ed&Norm \\
 \hline
 \hline
 \textbf{Training} 2016-2017 &-0.252&-0.106&-0.176&-0.191&0.377\\
 \hline
 \textbf{Test}  2017-2018&-0.24&-0.105&-0.179&-0.191&0.37\\
 \hline
 \hline
 %\hline

  {\textbf{Core DCA}}  &Low-Income&ELL&ENI&Special Ed&Norm\\
\hline
\textbf{Bonus Points}&2.0&11.0&11.0&14.0&-\\
\hline
\textbf{Training} 2016-2017&0.051&0.018&0.001&0.049&0.073\\
\hline
\textbf{Test} 2017-2018&0.052&-0.006&-0.001&0.029&0.06\\
 
 \hline
 \hline

  {\textbf{DCA}}  &Low-Income&ELL&ENI&Special Ed&Norm\\
\hline
\textbf{Bonus Points}&1.0&11.5&12.0&12.0&-\\
\hline
\textbf{Training} 2016-2017&-0.018&0.001&0.001&-0.014&0.023\\
\hline
\textbf{Test} 2017-2018&-0.01&-0.017&0.005&-0.028&0.034\\

\hline

\end{tabular}
\caption{\em Disparity vectors for the NYC high schools data before and after bonus points}
\label{tab_disparityreduction}
\vspace{-0.15in}
\end{table*}


\subsection{Results on the School Dataset}
\label{sec:resschools}

\subsubsection{Disparity Reduction}

Table~\ref{tab_disparityreduction} shows the disparity values for each target fairness dimension and overall (Norm). The top part of the table shows the Baseline disparity when the school ranking function is used to select $5\%$ of students without any disparity correction. We can see that for both years and for all our fairness targets the disparity is high: for example, low-income students appear $25\%$ less in the selection than in the total population. Overall, the disparity is at 0.37. Note that a disparity of 0 is the goal, the highest the absolute value, the more disparate impacts exist. The sign of the disparity gives the direction of this impact: negative for underrepresentation, positive for overrepresentation.

The bottom portion of the table shows the bonus points produced by the DCA algorithm and the resulting reduced disparity. We can see that for all target attributes the disparity is almost at 0 after the bonus points are applied for both training and test datasets. The overall disparity is also close to 0. The number of bonus points needed to achieve these results is easily understandable: for instance, as ELL students are disadvantaged by the inclusion of ELA grades and scores, they receive 11.5 bonus points on the ranking function to even the playing field. The number of bonus points to address the disparity suffered by low-income students is surprisingly low: giving them just 1 bonus point brings them to statistical parity in the selected set, possibly because the ENI also captures economic disadvantage. 



\subsubsection{Utility}
In fair ranking applications, utility measures how much the disparity compensation approach impacts the original rankings. In simpler terms, it measures how far the new ranking is from the uncorrected one.  


A common measure of utility is the $nDCG$, or normalized discounted cumulative gain~\cite{jarvelin2002cumulated,zehlike2017fa}. The standard discounted cumulative gain $DCG$ is defined as:
$$ \sum_{i=1}^{k}\frac{w_i}{log_2(i+1)}$$
$nDCG$ is defined as the ratio of the measured $DCG$ to the ideal $DCG$. In fairness ranking applications, the ideal $DCG$ is that of the original ranking before fairness compensation is applied.


 A score of 1 would mean that the fairness compensation comes at no loss in utility at all: the ranking is unchanged. For our default selection set of $5\%$ of students, the $nDCG@0.05$ of DCA is  0.957. This is comparable to other fair ranking  algorithms that handle multiple  fairness dimensions.  \cite{zehlike2022fair}. Figure~\ref{fig:ndcg_k} reports the  $nDCG@k$ where $k$ represents the proportion of selected students, showing good utility for all selection percentages.
    
        % Figure environment removed

DCA can  easily be calibrated for different desired fairness thresholds or utility values. Bonus points may be adjusted by a weight multiplicative factor to reduce the importance of the bonus points and increase the utility (as measured by $nDCG$). The correct proportion of bonus points to apply can be selected through a binary search. Figure \ref{fig:utility_adjust} shows the impact on  utility and disparity of applying a reducing weight to bonus points. 

Figure \ref{fig:full_disp_adjust} shows a detailed breakdown of the disparity as we adjust the total proportion of the bonus points. The step nature of the function is due to our restriction that the bonus points be a multiple of 0.5. The function is near linear, applying half of the optimal disparity reduction bonus points, provides about half the disparity reduction. This shows that DCA can be easily adjusted to  provide a solution for any given utility or fairness threshold.


\subsubsection{Effect of Varying the Percentage of Selected Objects}
\label{sec:varying}
    % Figure environment removed

 

Some applications determine the number of selected objects in advance (e.g, vaccine allocation). Others may be impacted that external factors that will vary the number of selected objects, for example through a waitlist process. As explained in Section~\ref{sec:motivations}, the NYC school admissions are handled by a matching algorithm. Schools do not know in advance how far down their ranked list they will accept students as this will depend on many factors: student choices, other schools' rankings and enrollment targets. 




As discussed in Section~\ref{sec:log_discount}, our algorithm can account for variations in the percentage of selected objects $k$ in different ways: 
\begin{itemize}
    \item If $k$ is known, our algorithm can optimize for the specific value and give excellent results. In Figure \ref{fig:school_all_k}, the disparity before (dashed line) and after (full line) correction is shown for varying $k$. In every case, given the selectivity, DCA succeeds in essentially eliminating disparity. \remove{The associated bonus points for each value of $k$ are shown in Figure \ref{fig:school_bonus}.}
    \item If $k$ is not known \yehuda{at the time of bonus point assignment} but can be approximated, DCA can be optimized for the approximation and results in good results \yehuda{when this estimate is close to the real value} (Figure \ref{fig:school_5}). The disparity results degrade however when $k$ is not estimated properly.
    \item If $k$ is unknown, or several different $k$ values are important, we use our logarithmically-discounted  approach (Section~\ref{sec:log_discount})  to set bonus points to the setting that will provide the best disparity outcome for a weighted average of many different $k$ values in the ranked list. This means that DCA's goal is to minimize the weighted average of disparities across many values of $k$ instead of only minimizing the disparity at a specific $k$. However, if the exact value of k is known \yehuda{when bonus points are chosen}, selecting a bonus vector that minimizes the disparity  for that exact value of $k$ provides better results for that specific $k$, at the cost of a higher average across the other values of $k$. This can be seen by comparing the disparity in Figure \ref{fig:school_5} and Figure \ref{fig:log_discount k} at $k=0.05$. While Figure \ref{fig:log_discount k} has a lower disparity at most $k$, Figure \ref{fig:school_5} shows DCA specifically targeting $k$ near 0.05 and has better results when $k$ is near 0.05.
\end{itemize}



   % Figure environment removed



\subsubsection{Maximum Bonus Limits}

DCA can easily be adapted to bound the bonus values it allocates using preset minimum and maximum bonus values. All experiments in this paper cap DCA to never give negative bonuses, as these can be perceived as penalties. If desired, maximum bonuses can also be set. The number of bonus points can be capped at every refinement step; this may cause adjustments in correlated non-capped attributes. Figure \ref{fig:max_bonus} shows the logarithmically discounted disparity for $k<0.05$ when the bonus amount is limited between 0 and 20. The resulting disparity is obviously impacted, with worst results when the maximum number of bonus points is small, however  as the maximum number of bonus points increases, the disparity gets smaller. 



\subsubsection{Impact of the Refinement Step}
\label{sec:refine}
    % Figure environment removed

  
    
Table \ref{tab_disparityreduction} shows that the refinement step of Algorithm~\ref{refine_function} results in improvements over the results of the Core DCA Algorithm~\ref{algo_SGD} alone. Over the school dataset, those improvements are about threefold. Figure \ref{fig:school_all_k_noref} shows the same settings as Figure~\ref{fig:school_all_k}, but without the refinement step. We see that in addition to better Disparity compensation, the refinement step produces smoother results. 

 

Figure \ref{fig:school_time_comparison} shows the time taken by both the Core DCA and DCA with refinement. In most cases, the refinement step takes approximately 10 seconds. As seen in the figure, the cost is higher for small values of $k$. This is due to the fact that the sample size needed for DCA depends on $max(\frac{1}{k},\frac{1}{r})$. When k is small the sample size therefore needs to be increased, which leads to longer execution times. Once $\frac{1}{k}$ becomes small enough at 5\%, the sample size is based on $r$, the frequency of the least
common group in the dataset, which is the same for all settings over the dataset. As k increases however, the computation of the centroid as part of the Disparity $\vec{D_k}$ computation takes longer as more elements are considered.

These results show the benefit of the refinement step.
In cases where faster execution times are desireable, this step can be omitted with some loss in quality.




\subsection{Results on the COMPAS dataset}
\label{sec:rescompas}

    % Figure environment removed

Figure~\ref{fig:compas_unchanges} shows the baseline disparity of the COMPAS decile scores based on race (dashed line). The disparity is notable for Black people who are significantly more likely to be flagged for recidivism risk, and for white people who are significantly less likely. The bonus point compensation offered by DCA (full line) allows to significantly reduce that disparity.

A difficulty with trying to address disparity in the COMPAS data is that its scores are very coarse: they are only 10 possible scores, which makes it difficult to have an impact with bonus points. This can be seen most clearly when the log discount mode of DCA is used in Figure \ref{fig:compas_log_discount}: As each new bucket moves into the selected set, the disparity moves sharply. \yehuda{However, shown in figures \ref{fig:compas_unchanges} and \ref{fig:compas_log_discount}, all cases still result in significant disparity reduction.}


\remove{
There are a few ways to mitigate this problem. First, we note that the decile score is not the actual score computed by COMPAS, but a decile-rank representation of that score. If the underlying score, or its distribution,  were available, we could simply convert the decile into its underlying score. We simulated this approach by assuming that COMPAS scores were taken from a normal distribution and then selecting from each decile a score from the underlying distribution (using uniform  random sampling). DCA was applied on these scores, the results are shown in Figure~\ref{fig:compas_underlying}. Another option is to accept reduced disparity mitigation. Since the underlying COMPAS algorithm has large buckets, it makes sense for the fairness compensation. As is shown in figures \ref{fig:compas_unchanges} and \ref{fig:compas_log_discount}  this still results in significant disparity reduction.
}

\subsection{Comparison with Existing Approaches and Metrics}
\label{sec:Comparison}
\subsubsection{Comparison to a Real-world Quota System}



\yehuda{As discussed earlier, quota-based
approaches are difficult to extend to the multinomial case. Many real-world settings, such as the NYC school system, use one single quota for all the different fairness dimensions. Figure \ref{fig:school_quota} shows that this approach does result in  disparity reduction, but does not achieve results as good as DCA (Figure~\ref{fig:School_DCA}).}  
\subsubsection{Comparison to Multinomial FA**IR}
We also compared DCA with the Multinomial FA**IR method~\cite{zehlike2022fair} on the school dataset. Multinomial FA**IR is a post-processing method that re-ranks the dataset with fairness guarantees. Multinomial FA**IR only works on non-overlapping fairness parameters, so we looked at the Cartesian product of all our parameters and picked the 3 most-discriminated against subgroups as our barometers of fairness, as suggested in~\cite{zehlike2022fair}. Because of efficiency limitations of Multinomial FA**IR, we were only able to run their code on a single district of NYC schools, consisting of 2,500 students, instead of the whole dataset. We report our results in Table~\ref{tab:mfair}. We see that, while both methods significantly improve disparity, DCA results in better outcomes due to its ability to handle overlapping subgroups.


\begin{table}
\centering
\begin{tabular}{|p{60pt}|p{32pt}|p{30pt}|p{30pt}||p{30pt}|}
\hline
{}  &Low-Inc&ELL&Sp. Ed&Norm \\
 \hline 
 \textbf{Baseline } &-0.262&-0.036&-0.179&0.320\\

\hline \hline
\textbf{Bonus Points}&2&9&5&-\\
\hline 
\textbf{DCA}&0.009&-0.011&0.001&0.007\\

\hline
\hline
\textbf{Mult. FA**IR}&-0.084&-0.036&-0.052&0.105\\
\hline
\end{tabular}
\caption{\em Comparison of DCA and Multinomial FA**IR}
\label{tab:mfair}
\vspace{-0.2in}

\end{table}



\subsubsection{Comparison to ($\Delta$ + 2)-approximation\  algorithm}
\label{sec:deltaplustwo}
Because of the time complexity of Multinomial FA**IR, we also include a comparison to a faster approximation algorithm, ($\Delta$  + 2), from \cite{celis2017ranking}. This algorithm works by looking at all (position,item) pairs and greedily selecting the one that most improves the utility (in our case measured by nDCG) without violating a preset (input) fairness constraints on the maximum number of items of each type. To make a fair comparison, we gave ($\Delta$ + 2) the disparity achieved by DCA as its input preset fairness constraint. Unlike DCA, ($\Delta$ + 2) is a post-processing step which only works on existing results; therefore we compared it to the results of DCA on a single year. 
As is shown in Figure \ref{fig:utility_comparison}, ($\Delta$ + 2) achieves results very similar  to DCA. In terms of efficiency, this algorithm depends heavily on the proportion of items selected $k$. For small values of $k$, such as 5\%, it performs similarly to DCA, around 30 seconds, for larger values, such as 30\%, it takes around 30 minutes, making DCA a faster option. 

\remove{In general, our results  show that across a number of settings, in utility, fairness and efficiency, DCA performs similarly or better than similar non-explainable counterparts. In addition, DCA allows for {\em transparent and explainable fairness mitigation}.}

\subsubsection{Exposure}
\label{sec:exposure}

Exposure is a common metric for measuring fairness in ranking. It is defined as the sum of the probability of an object having a position in the ranked order times the value of that position. The value of a position has been defined in different ways in different sources; we used the definition from \cite{gupta2021online}.  They define exposure as $$ Exposure(G|R) = \sum_{i\in G} \frac{1}{lg(r(i) + 1)}$$ Where G is a group, R is a ranking, and r(i) is the rank of an object. They define a fairness metric based on this definition: demographic disparity constraint or DDP, defined as 
$$DDP(R) = max(G_j,G_k) \frac{exposure(G_j|R)}{|G_j|} - \frac{exposure(G_k|R)}{|G_k|} $$
Intuitively, this means that no group should have very different exposure from any other group. A value of zero would mean perfect fairness. The exact values are not comparable across datasets of different sizes since the value of exposure shrinks as the dataset grows. 

We calculated the exposure value on the school dataset without the ENI attribute, as DDP does not handle non-binary fairness attributes. Since exposure considers the entire ranking, the logarithmic discounting mode of DCA was used. The resulting bonus point vector was \texttt{\{'Special-Ed': 14, 'Low-Income': 5, 'ELL': 11\}}. 

Under the baseline disparity setting, the DDP value is 0.00899. After DCA compensatory bonus points are applied, the DDP becomes 0.00166. This 5-fold reduction in DDP is in line with the disparity experiments from Section~\ref{sec:resschools}, confirming that important improvements in fairness can be achieved with reasonable size bonus point vectors.
\subsubsection{Using DCA with other fairness metrics}


Our DCA algorithm can be used to minimize fairness metrics other than disparity. A limitation is that the minimization metric must be represented as the norm of a vector, and it must provide bounds between -1,1 with -1 representing complete unfairness to one group and 1 representing complete unfairness to another, and 0 representing fairness. 

To show the behavior of DCA with other metrics, we have implemented a slight variation of one of the most popular fairness metrics: {\em disparate impact (DI)}. DI sets limits on the ratio of positive (selected) objects in the protected and unprotected groups. We use the slightly modified version from\cite{zafar2017fairness}. Specifically, for each fairness dimension, the disparate impact is measured as:
$$
min \left( \frac{P(O=1|F=0)}{P(O=1|F=1)}, \frac{P(O=1|F=1)}{P(O=1|F=0)} \right)
$$
Where F=0 represents the object not having a protected (fairness) attribute (e.g., not being low-income) and O=1 represents the object being selected. To make it usable by  DCA, we had to scale it to the [-1;1] range. With this modification, disparate impact can be directly applied in the discrete case (including the logarithmically-discounted variation) leading to a bonus vector of {'Special Ed': 14 pts, 'Low-Income': 5.5 pts, 'ELL': 12.5 pts} compared to the similar bonus vector using disparity of  {'Special Ed': 14 pts, 'Low-Income': 5 pts, 'ELL': 11.5 pts}. We show the comparison of using Disparity and DI with DCA Figure~\ref{fig:Disparate_impact}. Both versions perform similarly. The disparate impact version of DCA took 164 seconds compared to  64 seconds for regular DCA with these settings.

\yehuda{This type of expansion is not limited to statistical parity measures: When data is available, DCA can also be used with equalized odds measures such as the False Positive Rate. The FPR is defined as the proportion of real negative cases that were misidentified as positive by the algorithm. Disparities in this rate between different groups is one of the original criticisms of the COMPAS algorithm. To minimize this difference we subtract the overall FPR from the per-group FPR. This difference has the required properties for DCA. \remove{It is between -1,1, since the FPR is between 0 and 1. -1 represents that all false positives are in other groups, 1 represents that all false positives are in this group, and 0 representing an equal FPR for this group and the distribution as a whole.} Using this metric with DCA results in an algorithm that finds the number of bonus points to minimize the differences in FPRs between groups. Figure \ref{fig:compas_FPR}, shows that the FPR difference is reduced across a range of $k$s.}

