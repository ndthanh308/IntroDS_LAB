\section{Conclusion}
%
\vspace{-0.5mm}
We have presented a novel method that synthesizes a variety of styles in a joint vision-language space via learnable style words without exploiting any images to deal with source-free domain generalization.
PromptStyler simulates various distribution shifts in the latent space of a large-scale pre-trained model, which could effectively improve its generalization capability.
The proposed method achieves state-of-the-art results without using any source domain data on multiple domain generalization benchmarks.
We hope that future work could apply our method to other tasks using different large-scale vision-language models.
%