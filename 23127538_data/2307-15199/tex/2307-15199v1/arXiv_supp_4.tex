\setcounter{figure}{0}
\setcounter{table}{0}
\renewcommand\thefigure{D\arabic{figure}}
\renewcommand\thetable{D\arabic{table}}

\section{Discussion}
\label{supp:supp_4}
%
PromptStyler aims to improve model's generalization capability by simulating various distribution shifts in the latent space of a large-scale pre-trained model.
To achieve this goal, the proposed method leverages a joint vision-language space where a text feature could effectively represent image features.
It does not strictly mean that text features and image features should be perfectly interchangeable in the joint vision-language space.
Even though such features are not totally interchangeable,
our method could still be effective.

Consider CLIP~\cite{radford2021clip} latent space as an example. 
As implicitly demonstrated in text-to-image synthesis work~\cite{unCLIP},
image features and text features are not perfectly interchangeable in CLIP latent space.
However, even in this case, we could still simulate various distribution shifts via a variety of style word vectors using the CLIP text encoder.
Given that the text encoder is exploited to synthesize classifier weights in zero-shot CLIP,
our method improves its decision boundary by generating diverse style-content features and then training a new classifier with the synthesized features using ArcFace~\cite{ArcFace} loss. 
In other words, 
if the proposed method is implemented with CLIP,
then the trained classifier (Fig.~\redcolornumber{3} of the main paper) could be considered as an improved version of the synthesized classifier used in zero-shot CLIP.
%