\section{Limitation}
\label{main:main_5}
%
\vspace{-0.5mm}
The performance of our method depends on the quality of the joint vision-language space constructed by the chosen vision-language model.
For example, although PromptStyler largely outperforms its base model (\ie, CLIP~\cite{radford2021clip}) in all evaluations, 
our method shows lower accuracy on the Terra Incognita dataset~\cite{TerraDataset} compared with other methods which utilize several images from the dataset as shown in Table~\ref{table:terra_limitation}.
The main reason for this might be due to the low accuracy of CLIP on the dataset.
Nevertheless, given that our method consistently outperforms its base model in every evaluation, this limitation could be alleviated with the development of large-scale vision-language models.
%