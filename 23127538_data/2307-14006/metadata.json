{
  "title": "Learning Snippet-to-Motion Progression for Skeleton-based Human Motion Prediction",
  "authors": [
    "Xinshun Wang",
    "Qiongjie Cui",
    "Chen Chen",
    "Shen Zhao",
    "Mengyuan Liu"
  ],
  "submission_date": "2023-07-26T07:36:38+00:00",
  "revised_dates": [],
  "abstract": "Existing Graph Convolutional Networks to achieve human motion prediction largely adopt a one-step scheme, which output the prediction straight from history input, failing to exploit human motion patterns. We observe that human motions have transitional patterns and can be split into snippets representative of each transition. Each snippet can be reconstructed from its starting and ending poses referred to as the transitional poses. We propose a snippet-to-motion multi-stage framework that breaks motion prediction into sub-tasks easier to accomplish. Each sub-task integrates three modules: transitional pose prediction, snippet reconstruction, and snippet-to-motion prediction. Specifically, we propose to first predict only the transitional poses. Then we use them to reconstruct the corresponding snippets, obtaining a close approximation to the true motion sequence. Finally we refine them to produce the final prediction output. To implement the network, we propose a novel unified graph modeling, which allows for direct and effective feature propagation compared to existing approaches which rely on separate space-time modeling. Extensive experiments on Human 3.6M, CMU Mocap and 3DPW datasets verify the effectiveness of our method which achieves state-of-the-art performance.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14006",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 7699152,
  "size_after_bytes": 118627
}