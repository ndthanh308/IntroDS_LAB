\begin{thebibliography}{10}

\bibitem{ahmad2015properties}
Subutai Ahmad and Jeff Hawkins.
\newblock Properties of sparse distributed representations and their
  application to hierarchical temporal memory.
\newblock {\em arXiv preprint arXiv:1503.07469}, 2015.

\bibitem{aljundi2018memory}
Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and
  Tinne Tuytelaars.
\newblock Memory aware synapses: Learning what (not) to forget.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 139--154, 2018.

\bibitem{aljundi2019gradient}
Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio.
\newblock Gradient based sample selection for online continual learning.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{bellec2020solution}
Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj,
  Robert Legenstein, and Wolfgang Maass.
\newblock A solution to the learning dilemma for recurrent networks of spiking
  neurons.
\newblock {\em Nature communications}, 11(1):3625, 2020.

\bibitem{bishop2006pattern}
Christopher~M Bishop and Nasser~M Nasrabadi.
\newblock {\em Pattern recognition and machine learning}, volume~4.
\newblock Springer, 2006.

\bibitem{chaudhry2018riemannian}
Arslan Chaudhry, Puneet~K Dokania, Thalaiyasingam Ajanthan, and Philip~HS Torr.
\newblock Riemannian walk for incremental learning: Understanding forgetting
  and intransigence.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 532--547, 2018.

\bibitem{chaudhry2019tiny}
Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan,
  Puneet~K Dokania, Philip~HS Torr, and Marc'Aurelio Ranzato.
\newblock On tiny episodic memories in continual learning.
\newblock {\em arXiv preprint arXiv:1902.10486}, 2019.

\bibitem{crick1989recent}
Francis Crick.
\newblock The recent excitement about neural networks.
\newblock {\em Nature}, 337:129--132, 1989.

\bibitem{davies2018loihi}
Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham Chinya, Yongqiang Cao,
  Sri~Harsha Choday, Georgios Dimou, Prasad Joshi, Nabil Imam, Shweta Jain,
  et~al.
\newblock Loihi: A neuromorphic manycore processor with on-chip learning.
\newblock {\em Ieee Micro}, 38(1):82--99, 2018.

\bibitem{dempster1977maximum}
Arthur~P Dempster, Nan~M Laird, and Donald~B Rubin.
\newblock Maximum likelihood from incomplete data via the em algorithm.
\newblock {\em Journal of the royal statistical society: series B
  (methodological)}, 39(1):1--22, 1977.

\bibitem{friston2009predictive}
Karl Friston and Stefan Kiebel.
\newblock Predictive coding under the free-energy principle.
\newblock {\em Philosophical transactions of the Royal Society B: Biological
  sciences}, 364(1521):1211--1221, 2009.

\bibitem{gallardo2021self}
Jhair Gallardo, Tyler~L Hayes, and Christopher Kanan.
\newblock Self-supervised training enhances online continual learning.
\newblock {\em arXiv preprint arXiv:2103.14010}, 2021.

\bibitem{george2017generative}
Dileep George, Wolfgang Lehrach, Ken Kansky, Miguel L{\'a}zaro-Gredilla,
  Christopher Laan, Bhaskara Marthi, Xinghua Lou, Zhaoshi Meng, Yi~Liu, Huayan
  Wang, et~al.
\newblock A generative vision model that trains with high data efficiency and
  breaks text-based captchas.
\newblock {\em Science}, 358(6368):eaag2612, 2017.

\bibitem{gershman2012tutorial}
Samuel~J Gershman and David~M Blei.
\newblock A tutorial on bayesian nonparametric models.
\newblock {\em Journal of Mathematical Psychology}, 56(1):1--12, 2012.

\bibitem{hayes2022online}
Tyler~L Hayes and Christopher Kanan.
\newblock Online continual learning for embedded devices.
\newblock {\em arXiv preprint arXiv:2203.10681}, 2022.

\bibitem{heckerman1998tutorial}
David Heckerman.
\newblock {\em A tutorial on learning with Bayesian networks}.
\newblock Springer, 1998.

\bibitem{hopfield1982neural}
John~J Hopfield.
\newblock Neural networks and physical systems with emergent collective
  computational abilities.
\newblock {\em Proceedings of the national academy of sciences},
  79(8):2554--2558, 1982.

\bibitem{khetarpal2022towards}
Khimya Khetarpal, Matthew Riemer, Irina Rish, and Doina Precup.
\newblock Towards continual reinforcement learning: A review and perspectives.
\newblock {\em Journal of Artificial Intelligence Research}, 75:1401--1476,
  2022.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kirkpatrick2017overcoming}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the national academy of sciences},
  114(13):3521--3526, 2017.

\bibitem{krotov2016dense}
Dmitry Krotov and John~J Hopfield.
\newblock Dense associative memory for pattern recognition.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{kumaran2016learning}
Dharshan Kumaran, Demis Hassabis, and James~L McClelland.
\newblock What learning systems do intelligent agents need? complementary
  learning systems theory updated.
\newblock {\em Trends in cognitive sciences}, 20(7):512--534, 2016.

\bibitem{lee2020neural}
Soochan Lee, Junsoo Ha, Dongsu Zhang, and Gunhee Kim.
\newblock A neural dirichlet process mixture model for task-free continual
  learning.
\newblock {\em arXiv preprint arXiv:2001.00689}, 2020.

\bibitem{li2019tutorial}
Yuelin Li, Elizabeth Schofield, and Mithat G{\"o}nen.
\newblock A tutorial on dirichlet process mixture modeling.
\newblock {\em Journal of mathematical psychology}, 91:128--144, 2019.

\bibitem{li2017learning}
Zhizhong Li and Derek Hoiem.
\newblock Learning without forgetting.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  40(12):2935--2947, 2017.

\bibitem{lillicrap2020backpropagation}
Timothy~P Lillicrap, Adam Santoro, Luke Marris, Colin~J Akerman, and Geoffrey
  Hinton.
\newblock Backpropagation and the brain.
\newblock {\em Nature Reviews Neuroscience}, 21(6):335--346, 2020.

\bibitem{mai2022online}
Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, and Scott
  Sanner.
\newblock Online continual learning in image classification: An empirical
  survey.
\newblock {\em Neurocomputing}, 469:28--51, 2022.

\bibitem{mallya2018piggyback}
Arun Mallya, Dillon Davis, and Svetlana Lazebnik.
\newblock Piggyback: Adapting a single network to multiple tasks by learning to
  mask weights.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 67--82, 2018.

\bibitem{mallya2018packnet}
Arun Mallya and Svetlana Lazebnik.
\newblock Packnet: Adding multiple tasks to a single network by iterative
  pruning.
\newblock In {\em Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 7765--7773, 2018.

\bibitem{matsuda1999quantized}
Satoshi Matsuda.
\newblock Quantized hopfield networks for integer programming.
\newblock {\em Systems and computers in Japan}, 30(6):1--12, 1999.

\bibitem{matsuda1999theoretical}
Satoshi Matsuda.
\newblock Theoretical analysis of quantized hopfield network for integer
  programming.
\newblock In {\em IJCNN'99. International Joint Conference on Neural Networks.
  Proceedings (Cat. No. 99CH36339)}, volume~1, pages 568--571. IEEE, 1999.

\bibitem{mcculloch1943logical}
Warren~S McCulloch and Walter Pitts.
\newblock A logical calculus of the ideas immanent in nervous activity.
\newblock {\em The bulletin of mathematical biophysics}, 5:115--133, 1943.

\bibitem{mcnaughton2010cortical}
Bruce~L McNaughton.
\newblock Cortical hierarchies, sleep, and the extraction of knowledge from
  memory.
\newblock {\em Artificial Intelligence}, 174(2):205--214, 2010.

\bibitem{millidge2022universal}
Beren Millidge, Tommaso Salvatori, Yuhang Song, Thomas Lukasiewicz, and Rafal
  Bogacz.
\newblock Universal hopfield networks: A general framework for single-shot
  associative memory models.
\newblock {\em arXiv preprint arXiv:2202.04557}, 2022.

\bibitem{millidge2022theoretical}
Beren Millidge, Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz, and Rafal
  Bogacz.
\newblock A theoretical framework for inference and learning in predictive
  coding networks.
\newblock {\em arXiv preprint arXiv:2207.12316}, 2022.

\bibitem{ming2011adult}
Guo-li Ming and Hongjun Song.
\newblock Adult neurogenesis in the mammalian brain: significant answers and
  significant questions.
\newblock {\em Neuron}, 70(4):687--702, 2011.

\bibitem{neftci2019surrogate}
Emre~O Neftci, Hesham Mostafa, and Friedemann Zenke.
\newblock Surrogate gradient learning in spiking neural networks: Bringing the
  power of gradient-based optimization to spiking neural networks.
\newblock {\em IEEE Signal Processing Magazine}, 36(6):51--63, 2019.

\bibitem{o1996biologically}
Randall~C O'Reilly.
\newblock Biologically plausible error-driven learning using local activation
  differences: The generalized recirculation algorithm.
\newblock {\em Neural computation}, 8(5):895--938, 1996.

\bibitem{o2017deep}
Randall~C O'Reilly, Dean~R Wyatte, and John Rohrlich.
\newblock Deep predictive learning: a comprehensive model of three visual
  streams.
\newblock {\em arXiv preprint arXiv:1709.04654}, 2017.

\bibitem{parisi2019continual}
German~I Parisi, Ronald Kemker, Jose~L Part, Christopher Kanan, and Stefan
  Wermter.
\newblock Continual lifelong learning with neural networks: A review.
\newblock {\em Neural networks}, 113:54--71, 2019.

\bibitem{parisi2020online}
German~I Parisi and Vincenzo Lomonaco.
\newblock Online continual learning on sequences.
\newblock In {\em Recent Trends in Learning From Data: Tutorials from the INNS
  Big Data and Deep Learning Conference (INNSBDDL2019)}, pages 197--221.
  Springer, 2020.

\bibitem{ramsauer2020hopfield}
Hubert Ramsauer, Bernhard Sch{\"a}fl, Johannes Lehner, Philipp Seidl, Michael
  Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner, Milena Pavlovi{\'c},
  Geir~Kjetil Sandve, et~al.
\newblock Hopfield networks is all you need.
\newblock {\em arXiv preprint arXiv:2008.02217}, 2020.

\bibitem{rao1999predictive}
Rajesh~PN Rao and Dana~H Ballard.
\newblock Predictive coding in the visual cortex: a functional interpretation
  of some extra-classical receptive-field effects.
\newblock {\em Nature neuroscience}, 2(1):79--87, 1999.

\bibitem{ritter2018online}
Hippolyt Ritter, Aleksandar Botev, and David Barber.
\newblock Online structured laplace approximations for overcoming catastrophic
  forgetting.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{rozell2008sparse}
Christopher~J Rozell, Don~H Johnson, Richard~G Baraniuk, and Bruno~A Olshausen.
\newblock Sparse coding via thresholding and local competition in neural
  circuits.
\newblock {\em Neural computation}, 20(10):2526--2563, 2008.

\bibitem{rugg2003human}
Michael~D Rugg and Andrew~P Yonelinas.
\newblock Human recognition memory: a cognitive neuroscience perspective.
\newblock {\em Trends in cognitive sciences}, 7(7):313--319, 2003.

\bibitem{rumelhart1995backpropagation}
David~E Rumelhart, Richard Durbin, Richard Golden, and Yves Chauvin.
\newblock Backpropagation: The basic theory.
\newblock {\em Backpropagation: Theory, architectures and applications}, pages
  1--34, 1995.

\bibitem{sacramento2018dendritic}
Jo{\~a}o Sacramento, Rui Ponte~Costa, Yoshua Bengio, and Walter Senn.
\newblock Dendritic cortical microcircuits approximate the backpropagation
  algorithm.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{salvatori2021associative}
Tommaso Salvatori, Yuhang Song, Yujian Hong, Lei Sha, Simon Frieder, Zhenghua
  Xu, Rafal Bogacz, and Thomas Lukasiewicz.
\newblock Associative memories via predictive coding.
\newblock {\em Advances in neural information processing systems},
  34:3874--3886, 2021.

\bibitem{scellier2017equilibrium}
Benjamin Scellier and Yoshua Bengio.
\newblock Equilibrium propagation: Bridging the gap between energy-based models
  and backpropagation.
\newblock {\em Frontiers in computational neuroscience}, 11:24, 2017.

\bibitem{schuman2022opportunities}
Catherine~D Schuman, Shruti~R Kulkarni, Maryam Parsa, J~Parker Mitchell,
  Prasanna Date, and Bill Kay.
\newblock Opportunities for neuromorphic computing algorithms and applications.
\newblock {\em Nature Computational Science}, 2(1):10--19, 2022.

\bibitem{shiffrin1997model}
Richard~M Shiffrin and Mark Steyvers.
\newblock A model for recognition memory: Remâ€”retrieving effectively from
  memory.
\newblock {\em Psychonomic bulletin \& review}, 4:145--166, 1997.

\bibitem{shin2017continual}
Hanul Shin, Jung~Kwon Lee, Jaehong Kim, and Jiwon Kim.
\newblock Continual learning with deep generative replay.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{stork1989backpropagation}
Stork.
\newblock Is backpropagation biologically plausible?
\newblock In {\em International 1989 Joint Conference on Neural Networks},
  pages 241--246. IEEE, 1989.

\bibitem{teyler1986indexing}
T.~J. Teyler and P.~DiScenna.
\newblock The hippocampal memory indexing theory.
\newblock {\em Behav Neurosci}, 100(2):147--54, 1986.

\bibitem{teyler2007indexing}
T.~J. Teyler and J.~W. Rudy.
\newblock The hippocampal indexing theory and episodic memory: updating the
  index.
\newblock {\em Hippocampus}, 17(12):1158--69, 2007.

\bibitem{wang2023comprehensive}
Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu.
\newblock A comprehensive survey of continual learning: Theory, method and
  application.
\newblock {\em arXiv preprint arXiv:2302.00487}, 2023.

\bibitem{whittington2017approximation}
James~CR Whittington and Rafal Bogacz.
\newblock An approximation of the error backpropagation algorithm in a
  predictive coding network with local hebbian synaptic plasticity.
\newblock {\em Neural computation}, 29(5):1229--1262, 2017.

\bibitem{yang2021generalized}
Jingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei Liu.
\newblock Generalized out-of-distribution detection: A survey.
\newblock {\em arXiv preprint arXiv:2110.11334}, 2021.

\bibitem{yin2023accurate}
Bojian Yin, Federico Corradi, and Sander~M Boht{\'e}.
\newblock Accurate online training of dynamical spiking neural networks through
  forward propagation through time.
\newblock {\em Nature Machine Intelligence}, pages 1--10, 2023.

\bibitem{yoo2022bayespcn}
Jinsoo Yoo and Frank Wood.
\newblock Bayespcn: A continually learnable predictive coding associative
  memory.
\newblock {\em Advances in Neural Information Processing Systems},
  35:29903--29914, 2022.

\bibitem{yoon2017lifelong}
Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung~Ju Hwang.
\newblock Lifelong learning with dynamically expandable networks.
\newblock {\em arXiv preprint arXiv:1708.01547}, 2017.

\bibitem{zenke2017continual}
Friedemann Zenke, Ben Poole, and Surya Ganguli.
\newblock Continual learning through synaptic intelligence.
\newblock In {\em International conference on machine learning}, pages
  3987--3995. PMLR, 2017.

\end{thebibliography}
