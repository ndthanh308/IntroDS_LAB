\section{Evaluation}
\label{sec:eval}
\subsection{Experimental Setup}
In this section, we describe the primary performance indicators for evaluating the model, the datasets, and the experimental environment.

\subsubsection{Performance Metrics}
We employ F1 scores and accuracy to assess our model. These two metrics are widely used for evaluating model performance. We provide a brief explanation of these two metrics.\par
\textbf{Accuracy: }Accuracy is the ratio of the number of samples correctly predicted by the model to the total number of samples.\par
\textbf{Precision: }Precision is the ratio of the number of files correctly classified as vulnerable to the number of files classified as vulnerable.\par
\textbf{Recall: }Recall is the ratio of the number of files correctly classified as vulnerable to the total number of genuinely vulnerable files.\par
\textbf{F1 Scores: }F1 scores are the harmonic mean of precision and recall, calculated as follows:
\begin{equation}
	2 \times \frac{Recall \times Precision}{Recall + Precision}
\end{equation}

\subsubsection{Dataset}
We use thirteen datasets to evaluate our model, including CWE datasets and the PROMISE dataset\footnote{http://openscience.us/repo/defect/}. We selected CWE datasets from the NIST Software Assurance Reference Dataset\footnote{https://samate.nist.gov}, which is the software certification and evaluation division of the National Institute of Standards and Technology (NIST). This division is responsible for researching and developing software security assessment and certification standards. We chose six CWE datasets from SARD (shown in Table ~\ref{table:cwe_dataset}), including CWE 15, CWE 23, CWE 36, CWE 89, CWE 259, and CWE 606. These datasets consist of simplified vulnerability source codes derived from real software but have been artificially modified and patched. The PROMISE Repository is a publicly available repository specializing in software engineering research datasets. We selected the following Java project datasets: Camel, jEdit, Lucene, POI, Synapse, Xalan, and Xerces, which contain real software vulnerabilities without manual modification (shown in Table ~\ref{table:promise_dataset}).

\begin{table*}[htbp]
	\centering
	\caption{CWE Dataset Information}
	\label{table:cwe_dataset}
	\begin{tabular}{ccccc|cc}
		\hline
		Project & Training Set & Validation Set & Test Set & Total & Vul  & Non-Vul \\ \hline
		CWE259  & 218          & 27             & 28       & 273   & 111  & 162     \\
		CWE606  & 775          & 97             & 97       & 969   & 333  & 636     \\
		CWE36   & 1046         & 131            & 131      & 1308  & 660  & 648     \\
		CWE15   & 1046         & 131            & 131      & 1308  & 660  & 648     \\
		CWE23   & 1046         & 131            & 131      & 1308  & 660  & 648     \\
		CWE89   & 3876         & 484            & 485      & 4845  & 1665 & 3180    \\ \hline
	\end{tabular}
\end{table*}

\begin{table*}[htpb]
	\centering
	\caption{PROMISE Dataset Information}
	\label{table:promise_dataset}
	\begin{tabular}{ccccc|cc}
		\hline
		Project & Training Set & Validation Set & Test Set & Total & Vul & Non-Vul \\ \hline
		camel   & 2156         & 269            & 270      & 2695  & 562 & 2133    \\
		jedit   & 1309         & 164            & 164      & 1637  & 277 & 1360    \\
		lucene  & 600          & 75             & 75       & 750   & 437 & 313     \\
		poi     & 1086         & 136            & 136      & 1358  & 706 & 652     \\
		synapse & 494          & 62             & 62       & 618   & 157 & 461     \\
		xalan   & 1831         & 229            & 229      & 2289  & 893 & 1396    \\
		xerces  & 835          & 104            & 105      & 1044  & 214 & 830     \\ \hline
	\end{tabular}
\end{table*}

\subsubsection{Environment Configuration}
Our experiment's hardware configuration was executed on a multi-core computing server featuring a 16-core 2.10 GHz Intel Xeon CPU and an NVIDIA 3090 GPU. The server has 256 GB of RAM and 24 GB of VRAM. The software configuration includes TensorFlow v2.7.0 and Keras v2.7.0 running on Windows 10. For MVSA, we set the head number to 4 for CSS, CFG, DFG, and AST. For the convolutional and fully connected layers, we use the Adam optimizer with a learning rate of 1e-5 and a batch size of 16. The overall training process takes approximately 5 minutes for each dataset. The final trained model has over 4,000,000 hyperparameters.

\subsection{Baseline Methods}
\subsubsection{Traditional~\cite{tradictional}}The traditional method employs a Logistic Regression classifier based on 20 features.
\subsubsection{DBN~\cite{DBN}}DBN utilizes a Deep Belief Network on source code to extract semantic features for defect prediction.
\subsubsection{DBN+\cite{DBN+DP-CNN}}DBN+, an improved version of DBN, combines semantic features with traditional features.
\subsubsection{CNN\cite{cnn}}CNN treats source codes as natural languages, with Word2Vec used for embedding initialization. It employs a CNN to extract features from source codes.
\subsubsection{Defect Prediction via Convolutional Neural Network (DP-CNN)\cite{DBN+DP-CNN}}DP-CNN uses a CNN for automated feature generation from source code while preserving semantic and structural information. It employs word embedding and combines CNN-learned features with traditional hand-crafted features to further improve defect prediction.
\subsubsection{Improved CNN\cite{improvecnn}}The improved CNN model can learn semantic representations from source-code ASTs. It enhances global pattern capture ability and improves the model for better generalization.
\subsubsection{Achilles~\cite{Achilles}}Achilles is a Java source code security vulnerability detection tool based on LSTM RNN models. It can be trained using vulnerability source code datasets, analyze Java programs, and predict security vulnerabilities at the method level.
\subsubsection{Intelligent Sentence-level Vulnerability Self-Detection Framework(ISVSF)~\cite{ISVSF}}ISVSF considers the syntax characteristics of Java and adopts sentence-level method representation and pattern exploration.

\subsection{Experimental Results}
We evaluate our model on thirteen datasets shown in Table ~\ref{table:cwe_dataset} and Table ~\ref{table:promise_dataset}. JFinder outperforms all baselines in both conventional and highly complex datasets, demonstrating that our model represents the state of the art in Java vulnerability detection. According to the experimental results (shown in Table ~\ref{table:cwe_acc} and Table ~\ref{table:promise_f1}), we summarize the following findings:

\begin{itemize}
	\item \textbf{Code structural information improves vulnerability identification performance.} Compared to Achilles and ISVSF, which incorporate ASTs without other structural information, our model's accuracy is more than 5\% higher. Additionally, ISVSF outperforms Achilles in some datasets due to its inclusion of ASTs.
	\item \textbf{Pre-trained code semantic models enhance the ability of models to learn code representation semantics.} None of the baseline methods use a pre-training mechanism, resulting in their poor performance on real datasets. JFinder outperforms them by up to 35\% in F1 scores.
	\item \textbf{Quadruple self-attention layer extracts code vulnerability patterns, and aggregates structural information and semantic representation of source code.} Comparing CNN, DP-CNN, and improved CNN, JFinder's F1 scores are more than 25\% higher, indicating the positive effect of the quadruple self-attention layer.
	\item \textbf{JFinder performs better on highly complex datasets compared to conventional datasets.} Although JFinder surpasses all baseline methods in evaluations with commonly used datasets, its distinctiveness is not readily apparent. This is primarily due to the robust nature of the baseline methods, as well as researchers' adeptness in identifying elementary vulnerabilities. To underscore JFinder's superior performance, we employed a real-world dataset, which revealed JFinder to be 25\% more effective in terms of F1 scores than the baseline method, signifying industry-ready performance standards. \textcolor{blue}{Notwithstanding, we discerned notable disparities in the model's performance across different datasets. The CWE dataset, being artificially created, comprises vulnerabilities that are relatively simplistic and easy to detect. Conversely, the PROMISE dataset, derived from open-source projects, encompasses more concealed and challenging-to-detect vulnerabilities. Yet, in the face of such complexity, our model demonstrates commendable performance.}
	\item \textbf{JFinder achieves satisfactory performance with a short training time.} As seen in Fig.~\ref{fig:val_inf}, accuracy and F1 scores increase dramatically in a short period of time. The model is trained in less than five minutes. 
\end{itemize}



\begin{table*}[]
	\centering
	\caption{Experimental Results on PROMISE}
	\label{table:promise_f1}
	\begin{tabular}{llllllll}
		\hline
		\multirow{2}{*}{\textbf{Method}} & \textbf{camel} & \textbf{jEdit} & \textbf{synpase} & \textbf{xerces} & \textbf{lucene} & \textbf{xalan} & \textbf{poi} \\ \cline{2-8} 
		& F1             & F1             & F1               & F1              & F1              & F1             & F1           \\ \hline
		Traditional~\cite{tradictional}                  & 0.329          & 0.573          & 0.500            & 0.273           & 0.618           & 0.627          & 0.748        \\
		DBN~\cite{DBN}                    & 0.335          & 0.480          & 0.503            & 0.261           & 0.758           & 0.681          & 0.780        \\
		DBN+~\cite{DBN+DP-CNN}                        & 0.375          & 0.549          & 0.486            & 0.276           & 0.761           & 0.681          & 0.782        \\
		CNN ~\cite{cnn}                & 0.505          & 0.631          & 0.512            & 0.311           & 0.761           & 0.676          & 0.778        \\
		DP-CNN~\cite{DBN+DP-CNN}               & 0.508          & 0.580          & 0.556            & 0.374           & 0.761           & 0.696          & 0.784        \\
		Improved CNN~\cite{improvecnn}                  & 0.487          & 0.590          & 0.655            & 0.667           & 0.701           & 0.780          & 0.444        \\
		JFinder                          & 0.7637         & 0.8084         & 0.8233           & 0.7502          & 0.8391          & 0.8324         & 0.7899       \\ \hline
	\end{tabular}
\end{table*}



% Figure environment removed

% Figure environment removed




% Figure environment removed

\begin{table*}[htbp]
	\centering
	\caption{Experimental Results on CWE}
	\label{table:cwe_acc}
	\begin{tabular}{ccccccc}
		\hline
		\multirow{2}{*}{\textbf{Method}} & \textbf{CWE259} & \textbf{CWE606} & \textbf{CWE36} & \textbf{CWE15} & \textbf{CWE23} & \textbf{CWE89} \\ \cline{2-7} 
		& ACC             & ACC             & ACC            & ACC            & ACC            & ACC            \\ \hline
		Achilles~\cite{Achilles}                      & 0.925           & 0.943           & 0.818          & 0.929          & 0.894          & 0.934          \\
		ISVSF ~\cite{ISVSF}                       & 0.8732          & 0.9421          & 0.9321         & 0.9289         & 0.9305         & 0.9523         \\
		JFinder                          & 0.9643          & 0.9691          & 0.9771         & 0.9466         & 0.9542         & 0.9610         \\ \hline
	\end{tabular}
\end{table*}

\subsection{Ablation Study}
We conducted an ablation study to explore the impact of various components of our model on its performance. We utilized the PROMISE datasets to test the performance of the model components.

\textbf{Structural Information}

In the ablation experiment, we removed one of the structural information matrices, as shown in Table \ref{table:ablation}. According to the table, removing any of the structural information matrices resulted in a decrease in F1 scores, indicating that structural information provides a significant number of features to the model. Upon analyzing the results further, we found that CFG and DFG are more critical than AST. When either CFG or DFG was removed, the F1 scores dropped more substantially. However, for the \texttt{poi} dataset, they played similar roles. Thus, we infer that CFG and DFG provide the model with data flow and control flow information containing more vulnerability patterns. In summary, it is unwise to remove any of the graphs, even if they appear less important.

\textbf{Semantic Information and Pre-trained Model}

Based on Table \ref{table:ablation}, we conclude that the semantic information of the source code is highly important, as it is the origin of most vulnerability features. Removing CSS resulted in a significant drop in F1 scores to 0.51. Evidently, CSS is the most critical information. Our novel quadruple self-attention layer design and pre-training mechanism play the most significant role. If this component is removed, the model becomes inoperative.
\begin{table*}[htpb]
	\centering
	\caption{Ablation Study}
	\label{table:ablation}
	\begin{tabular}{cccccccc}
		\hline
		\multirow{2}{*}{\textbf{Method}} & \textbf{camel} & \textbf{jEdit} & \textbf{synpase} & \textbf{xerces} & \textbf{lucene} & \textbf{xalan} & \textbf{poi} \\ \cline{2-8} 
		& F1             & F1             & F1               & F1              & F1              & F1             & F1           \\ \hline
		JFinder                          & 0.7637         & 0.8084         & 0.8233           & 0.7502          & 0.8391          & 0.8324         & 0.7899       \\
		Jfinder w/o AST                  & 0.7204         & 0.7904         & 0.8164           & 0.7443          & 0.8273          & 0.8085         & 0.7730       \\
		JFinder w/o CFG                  & 0.7343         & 0.7551         & 0.8199           & 0.6982          & 0.6292          & 0.7028         & 0.7603       \\
		JFinder w/o DFG                  & 0.5963         & 0.7378         & 0.7763           & 0.7342          & 0.5814          & 0.7283         & 0.7764       \\
		JFinder w/o CSS                  & 0.4895         & 0.5933         & 0.7111           & 0.5159          & 0.6882          & 0.6760         & 0.7166       \\ \hline
	\end{tabular}
\end{table*}

\subsection{Case Study}
To further assess the robustness and intelligence of JFinder, we examined four representative vulnerability cases in the CWE dataset. Our model correctly identified each case. First, we analyzed the vulnerability specifications. Next, we manually patched the vulnerabilities and input them into our model to determine if it no longer flagged them, checking its ability to deeply understand the meaning of the vulnerabilities.
\subsubsection{Case 1}
%CWE606
In Case 1 (Fig.\ref{fig:case1}), the program did not check input and read data from the console using \texttt{readLine()}, potentially causing a denial of service or other consequences due to excessive looping. The data originated from a malicious source, as shown in Fig.\ref{fig:case1 vul} Line 10. To remediate the vulnerability (Fig.~\ref{fig:case1 fix}), we replaced user-controlled data for loop conditions with a hardcoded string. Afterward, JFinder no longer flagged this source code, indicating its ability to learn the reason behind unchecked input for loop condition problems.
	
% Figure environment removed

\subsubsection{Case 2}
In Case 2 (Fig.\ref{fig:case2}), the code snippet exhibited a vulnerability involving the use of a hard-coded password. A hard-coded password can lead to significant authentication failures that may be difficult for system administrators to detect and fix. In extreme cases, administrators may be forced to disable the product entirely. As seen in Fig.\ref{fig:case2_vul} Line 5, the program established a hard-coded password, suggesting that if such passwords are used, malicious users are likely to gain access through the account in question. To patch the vulnerability, we set \texttt{data} via external input, as shown in Fig.~\ref{fig:case2_fix}. After testing, JFinder no longer flagged the program as vulnerable.
% Figure environment removed

\subsubsection{Case 3}
In Case 3 (Fig.\ref{fig:case3}), a vulnerability appeared in Line 7, as depicted in Fig.\ref{fig:case3_vul}. In Line 8, the program read data from a properties file, leading to SQL injection. Without sufficient removal or quoting of SQL syntax in user-controllable inputs, the generated SQL query can cause those inputs to be interpreted as SQL rather than ordinary user data. This can be exploited to alter query logic, bypass security checks, or insert additional statements that modify the back-end database, potentially including the execution of system commands. To fix the vulnerability, we set \texttt{data} to be passed through the function instead of being read from the properties file. Afterward, JFinder considered the code snippet non-vulnerable.
% Figure environment removed

\subsubsection{Case 4}
In Case 4 (Fig.\ref{fig:case4}), a vulnerability arose from allocating memory based on an untrusted, large size value. The program did not ensure that the size was within expected limits, allowing arbitrary amounts of memory to be allocated. As shown in Fig.\ref{fig:case4_vul} Line 5, the program set \texttt{data} to a random value. To address this issue, we used a hardcoded number that would not cause underflow, overflow, divide by zero, or loss-of-precision problems. After fixing it in Fig.~\ref{fig:case4_fix}, JFinder no longer deemed it a vulnerability.
% Figure environment removed
