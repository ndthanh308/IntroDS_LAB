\section{Approach}
\label{sec:approach}
In this section, we detail the design of JFinder, illustrated in Fig.~\ref{fig:model}. The model workflow is as follows: we input a code snippet and parse it to obtain the AST, CFG, DFG, and CSS matrices. These matrices are then fed into the Quad Self-Attentive Layer and merged into a single matrix. Finally, a convolutional neural network and a multilayer perceptron predict whether the input code snippet is vulnerable or not.
% Figure environment removed
\subsection{Structural Information}

%% Figure environment removed
% Figure environment removed
\subsubsection{Abstract Syntax Tree (AST)} AST is a tree representation of the abstract syntactic structure of code written in a formal language. Each node of the tree denotes a construct occurring in the code, while each edge represents the inclusion relationship between the parent node and child nodes. In the tree, every sentence links to its tokens. Specifically, a sentence forms a concatenation graph with its tokens. For example, in Fig.\ref{fig:structural information}, "int result = 1" links "int", "result", "=", and "1".
\subsubsection{Control Flow Graph (CFG)} The CFG is a graph-based representation of all pathways that a program may take during its execution. In other words, it illustrates how the program runs under various settings. All nodes belong to the branch set, which includes \texttt{switch}, \texttt{if}, \texttt{for}, and \texttt{while} statements. Each directed edge represents the program's jumps between neighboring nodes and must follow a specific jump direction. The CFG has a unique entry and exit point. The program starts at the entry point and ends at the exit point. In Fig.\ref{fig:structural information}, the \texttt{public int square(int n)} block is the entry point for the program shown in Fig.~\ref{fig:code}, and the \texttt{return result} block is the exit point. When the program reaches the \texttt{for(int i=0; i<n; i++)} block, the computer determines whether the value of the \texttt{i} variable is less than the value of the \texttt{n} variable. If the value of \texttt{i} is less than the value of \texttt{n}, the \texttt{for} block is executed; otherwise, the \texttt{return} block is executed. Thus, the \texttt{for} block is linked to both the \texttt{result*=2} block and the \texttt{return result} block.
\subsubsection{Data Flow Graph (DFG)}DFG is a graph that depicts the data dependencies between various operations, i.e., it records all variable creation and modification. In DFG, each node represents the creation or modification of variables, and each directed edge represents variables that have been modified. For example, in Fig.~\ref{fig:structural information}, the variable \texttt{result} is initialized in the \texttt{int result=1} block and is modified in the \texttt{return*=2} block. Therefore, we connect two nodes from \texttt{int result=1} to \texttt{result*=2} with a directed edge.
\subsection{MetaPath}
\label{sec:metapath}
A MetaPath is a series of object-type relations that define a new composite relation between its initial and terminating type. It is represented as a path in the form of $\theta = A_1\stackrel{R_1}{\longrightarrow}A_2\stackrel{R_2}{\longrightarrow} ... \stackrel{R_l}{\longrightarrow} A_{l+1}$, where $A_i$ is a state and $R_i$ is a composite relation between $A_i$ and $A_{i+1}$\cite{nguyen2022dsaa}. It defines a composite relation $R = R_1 \circ R_2 \circ \cdots \circ R_l$ between type $A_1$ and $A_{l+1}$, and $\circ$ denotes the composition operator on relations. The length of a MetaPath depends on the number of relations in different contexts. Predefining all potential MetaPaths of any length based on all conceivable node and edge types is challenging due to the exponential expansion of MetaPaths, increased data sparsity, and decreased training accuracy. A length-N MetaPath can be decomposed into (N-1) length-2 MetaPaths. We focus on length-2 MetaPaths\cite{10.1145/3308558.3313562,10.14778/3402707.3402736} through reflective connections between adjacent nodes to extract multiple MetaPaths, i.e., we add a reverse directed edge for a pair of nodes with a directed edge. AST, CFG, and DFG are mostly tree-like, with very few back-edges. Adding the "back" relations improves the completeness of the extracted MetaPaths and enhances the connectivity of the graph to reduce overfitting.
%Code Snippet Embedding?
\subsection{Code Snippet Sequence (CSS)} CSS is a novel program language encoder that represents the semantic information of a code snippet by encoding code snippets into feature information matrices. The key to CSS is using a pre-trained program language model. Compared to traditional encoding methods, pre-trained models achieve satisfactory results without training, while significantly reducing the computing power requirements. A program language pre-training model can obtain more appropriate features than a natural language pre-training model. We calculate CSS as follows:
\begin{equation}
	C_i=model(x_i) \label{CSS}
\end{equation}
where $x_i$ is an input code snippet, $C_i$ is a representation of a code snippet and \texttt{model} represents a pre-trained program language model.
\subsection{Multi-View Self-Attention Encoder(MVSA)}
% Figure environment removed
After obtaining the structural information (AST, CFG, and DFG) and code semantic representation (CSS), we need to merge these representations and focus on location-specific information to extract more features. To achieve this, we design a Multi-View Self-Attention Encoder (MVSA) based on the multi-head attention mechanism. The input of MVSA consists of three matrices, $Q$, $K$, and $V$, which represent query, key, and value, respectively. Due to the self-attention mechanism, $Q$, $K$, and $V$ are the same. We compute the dot products of the query with all keys, divide each by $\sqrt{d_k}$, and apply a softmax function to obtain the weights on the values. Single-head attention is calculated as shown in Eq.~\ref{eq:sigle-att}:

\begin{equation}
	\label{eq:sigle-att}
	h_i=softmax\left(
	\frac{Q_iK_i^T}{\sqrt{d_k}}\right)
\end{equation}

where $Q_i$, $K_i$, and $V_i$ denote the $i$-th submatrix of $Q$, $K$, and $V$, respectively. $d_k$ refers to the dimension of $K$. We concatenate all $h_i$ from the scaled dot-product attention layer, calculated as shown in Eq.~\ref{eq:multi-att}:

\begin{equation}
	\label{eq:multi-att}
	G=Concat(h_i, \cdots ,h_n)W^o
\end{equation}

where $W^o$ is a weight matrix that is trained jointly with the model, and \texttt{n} is a user-defined parameter. We concatenate all $h_i$ as $H$ and multiply it with $W^o$. The resulting \texttt{G} matrix captures information from all $h_i$. Finally, we assemble four MVSAs into a quadruple self-attention layer, calculated as follows:

\begin{equation}
	\label{eq:layer}
	Q=Layer(AST, DFG, CFG, CSS)
\end{equation}

where $Q$ is a single matrix fusing of four matrices, containing both structural and semantic information.