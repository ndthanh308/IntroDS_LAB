\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balas et~al.(2019)Balas, Roy, Sharma, and Samui]{balas2019handbook}
Balas, V.~E., Roy, S.~S., Sharma, D., and Samui, P.
\newblock \emph{Handbook of deep learning applications}, volume 136.
\newblock Springer, 2019.

\bibitem[Balunovi{\'c} \& Vechev(2020)Balunovi{\'c} and
  Vechev]{balunovic2020adversarial}
Balunovi{\'c}, M. and Vechev, M.
\newblock Adversarial training and provable defenses: Bridging the gap.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Brent(1973)]{brent1973algorithmsfor}
Brent, R.~P.
\newblock Algorithms for minimization without derivatives.
\newblock \emph{Prentice Hall, Englewood Cliffs, NJ}, 1973.

\bibitem[Cheng et~al.(2022)Cheng, Lei, Chen, Dhillon, and Hsieh]{cheng2022cat}
Cheng, M., Lei, Q., Chen, P.~Y., Dhillon, I., and Hsieh, C.~J.
\newblock Cat: Customized adversarial training for improved robustness.
\newblock In \emph{International Joint Conferences on Artificial Intelligence},
  pp.\  673--679, 2022.

\bibitem[De~Palma et~al.(2022)De~Palma, Bunel, Dvijotham, Kumar, and
  Stanforth]{de2022ibp-r}
De~Palma, A., Bunel, R., Dvijotham, K., Kumar, M.~P., and Stanforth, R.
\newblock Ibp regularization for verified adversarial robustness via
  branch-and-bound.
\newblock In \emph{ICML 2022 Workshop on Formal Verification of Machine
  Learning}, 2022.

\bibitem[Ding et~al.(2020)Ding, Sharma, Lui, and Huang]{Ding2020MMA}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock Mma training: Direct input space margin maximization through
  adversarial training.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Dvijotham et~al.(2018)Dvijotham, Stanforth, Gowal, Mann, and
  Kohli]{dvijotham18dual}
Dvijotham, K., Stanforth, R., Gowal, S., Mann, T., and Kohli, P.
\newblock A dual approach to scalable verification of deep networks.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pp.\
  162--171, 2018.

\bibitem[Gowal et~al.(2019)Gowal, Dvijotham, Stanforth, Bunel, Qin, Uesato,
  Arandjelovic, Mann, and Kohli]{gowal2019ibp}
Gowal, S., Dvijotham, K.~D., Stanforth, R., Bunel, R., Qin, C., Uesato, J.,
  Arandjelovic, R., Mann, T., and Kohli, P.
\newblock Scalable verified training for provably robust image classification.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  4842--4851, 2019.

\bibitem[Jovanovi{\'c} et~al.(2022)Jovanovi{\'c}, Balunovic, Baader, and
  Vechev]{jovanovic2022paradox}
Jovanovi{\'c}, N., Balunovic, M., Baader, M., and Vechev, M.
\newblock On the paradox of certified training.
\newblock \emph{Transactions on Machine Learning Research}, 2022.
\newblock ISSN 2835-8856.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
Katz, G., Barrett, C., Dill, D.~L., Julian, K., and Kochenderfer, M.~J.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In \emph{International Conference on Computer Aided Verification},
  pp.\  97--117, 2017.

\bibitem[Krizhevsky(2009)]{Krizhevsky2009LearningML}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Master's thesis, University of Toronto}, 2009.

\bibitem[Le \& Yang(2015)Le and Yang]{le2015tiny}
Le, Y. and Yang, X.
\newblock Tiny imagenet visual recognition challenge.
\newblock \emph{CS 231N}, 7\penalty0 (7):\penalty0 3, 2015.

\bibitem[LeCun(1998)]{LeCun2005TheMD}
LeCun, Y.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann.lecun.com/exdb/mnist/}, 1998.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mirman et~al.(2018)Mirman, Gehr, and Vechev]{mirman2018differentiable}
Mirman, M., Gehr, T., and Vechev, M.
\newblock Differentiable abstract interpretation for provably robust neural
  networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3578--3586, 2018.

\bibitem[Mueller et~al.(2021)Mueller, Balunovic, and
  Vechev]{mueller2021certify}
Mueller, M.~N., Balunovic, M., and Vechev, M.
\newblock Certify or predict: Boosting certified robustness with compositional
  architectures.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[M{\"u}ller et~al.(2022)M{\"u}ller, Brix, Bak, Liu, and
  Johnson]{muller2022third}
M{\"u}ller, M.~N., Brix, C., Bak, S., Liu, C., and Johnson, T.~T.
\newblock The third international verification of neural networks competition
  (vnn-comp 2022): Summary and results.
\newblock \emph{arXiv preprint arXiv:2212.10376}, 2022.

\bibitem[M{\"u}ller et~al.(2023)M{\"u}ller, Eckert, Fischer, and
  Vechev]{muller2023sabr}
M{\"u}ller, M.~N., Eckert, F., Fischer, M., and Vechev, M.
\newblock Certified training: Small boxes are all you need.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8024--8035. Curran Associates, Inc., 2019.

\bibitem[Press et~al.(2007)Press, Teukolsky, Vetterling, and
  Flannery]{press2007numerical}
Press, W.~H., Teukolsky, S.~A., Vetterling, W.~T., and Flannery, B.~P.
\newblock \emph{Numerical recipes 3rd edition: The art of scientific
  computing}.
\newblock Cambridge university press, 2007.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018certified}
Raghunathan, A., Steinhardt, J., and Liang, P.
\newblock Certified defenses against adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Shi et~al.(2021)Shi, Wang, Zhang, Yi, and Hsieh]{shi2021fast}
Shi, Z., Wang, Y., Zhang, H., Yi, J., and Hsieh, C.-J.
\newblock Fast certified robust training with short warmup.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  18335--18349, 2021.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{wong2018provable}
Wong, E. and Kolter, Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5286--5295, 2018.

\bibitem[Wong et~al.(2018)Wong, Schmidt, Metzen, and Kolter]{wong2018scaling}
Wong, E., Schmidt, F., Metzen, J.~H., and Kolter, J.~Z.
\newblock Scaling provable adversarial defenses.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Xu et~al.(2020)Xu, Shi, Zhang, Huang, Chang, Kailkhura, Lin, and
  Hsieh]{xu2020automatic}
Xu, K., Shi, Z., Zhang, H., Huang, M., Chang, K.-W., Kailkhura, B., Lin, X.,
  and Hsieh, C.-J.
\newblock Automatic perturbation analysis on general computational graphs.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Xu et~al.(2023)Xu, Sun, Goldblum, Goldstein, and
  Huang]{xu2023exploring}
Xu, Y., Sun, Y., Goldblum, M., Goldstein, T., and Huang, F.
\newblock Exploring and exploiting decision boundary dynamics for adversarial
  robustness.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Zhang et~al.(2018)Zhang, Weng, Chen, Hsieh, and
  Daniel]{zhang2018efficient}
Zhang, H., Weng, T.-W., Chen, P.-Y., Hsieh, C.-J., and Daniel, L.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Zhang et~al.(2020)Zhang, Chen, Xiao, Gowal, Stanforth, Li, Boning, and
  Hsieh]{zhang2019crownibp}
Zhang, H., Chen, H., Xiao, C., Gowal, S., Stanforth, R., Li, B., Boning, D.,
  and Hsieh, C.-J.
\newblock Towards stable and efficient training of verifiably robust neural
  networks.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Lou, Wang, Wu, Lu, and
  Jia]{zhang2021driving}
Zhang, J., Lou, Y., Wang, J., Wu, K., Lu, K., and Jia, X.
\newblock Evaluating adversarial attacks on driving safety in vision-based
  autonomous vehicles.
\newblock \emph{IEEE Internet of Things Journal}, 9\penalty0 (5):\penalty0
  3443--3456, 2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Zhu, Niu, Han, Sugiyama, and
  Kankanhalli]{zhang2021geometryaware}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.

\end{thebibliography}
