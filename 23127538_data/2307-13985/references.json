{
  "2209-02997": {
    "title": "On the Transferability of Adversarial Examples between Encrypted Models",
    "authors": [
      "Miki Tanaka",
      "I. Echizen",
      "H. Kiya"
    ],
    "submission_date": "2022-09-07",
    "semantic_scholar_id": "b1c3a939218cd643916392262906158e897fb96b"
  },
  "2204-07707": {
    "title": "Privacy-Preserving Image Classification Using an Isotropic Network",
    "authors": [
      "Maungmaung Aprilpyone",
      "H. Kiya"
    ],
    "submission_date": "2022-04-01",
    "semantic_scholar_id": "8172cde9e068a60156d402339d267be5ee46c930"
  },
  "2201-11006": {
    "title": "An Overview of Compressible and Learnable Image Transformation with Secret Key and Its Applications",
    "authors": [
      "H. Kiya",
      "AprilPyone Maungmaung",
      "Yuma Kinoshita",
      "Shoko Imaizumi",
      "Sayaka Shiota"
    ],
    "submission_date": "2022-01-26",
    "semantic_scholar_id": "cbfa06d250acd895b3d2d6fe2a8562c3dea35a67"
  },
  "2109-00224": {
    "title": "A Protection Method of Trained CNN Model Using Feature Maps Transformed With Secret Key From Unauthorized Access",
    "authors": [
      "Maungmaung Aprilpyone",
      "H. Kiya"
    ],
    "submission_date": "2021-09-01",
    "semantic_scholar_id": "7253abe8805c22b6e918a2823472176e74157d1a"
  },
  "2010-00801": {
    "title": "Block-Wise Image Transformation With Secret Key for Adversarially Robust Defense",
    "authors": [
      "Maungmaung Aprilpyone",
      "H. Kiya"
    ],
    "submission_date": "2020-10-02",
    "semantic_scholar_id": "31f9a4fb569600a94e887a8f8c8b5ca33847fe48"
  },
  "2009-14720": {
    "title": "DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles",
    "authors": [
      "Huanrui Yang",
      "Jingyang Zhang",
      "Hongliang Dong",
      "Nathan Inkawhich",
      "Andrew B. Gardner",
      "Andrew Touchet",
      "Wesley Wilkes",
      "Heath Berry",
      "H. Li"
    ],
    "submission_date": "2020-09-30",
    "semantic_scholar_id": "b3b88cb29938a5445edd543b0498a51c4931f840"
  },
  "2005-07998": {
    "title": "Encryption Inspired Adversarial Defense For Visual Classification",
    "authors": [
      "Maungmaung Aprilpyone",
      "H. Kiya"
    ],
    "submission_date": "2020-05-16",
    "semantic_scholar_id": "c45132f8a83a85a15eb8c88d00a8e5c941972ef6"
  },
  "2003-01690": {
    "title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
    "authors": [
      "Francesco Croce",
      "Matthias Hein"
    ],
    "submission_date": "2020-03-03",
    "semantic_scholar_id": "18939eadc9c4460c8385e0591cde214a1ead067b"
  },
  "1912-00049": {
    "title": "Square Attack: a query-efficient black-box adversarial attack via random search",
    "authors": [
      "Maksym Andriushchenko",
      "Francesco Croce",
      "Nicolas Flammarion",
      "Matthias Hein"
    ],
    "submission_date": "2019-11-29",
    "semantic_scholar_id": "8733fe2371b615609b04e2e910b1ecfa8e77cbc2"
  },
  "1907-02044": {
    "title": "Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack",
    "authors": [
      "Francesco Croce",
      "Matthias Hein"
    ],
    "submission_date": "2019-07-03",
    "semantic_scholar_id": "91a05cb84f1c7dbb0354da2ff11ae92549152435"
  },
  "1905-13736": {
    "title": "Unlabeled Data Improves Adversarial Robustness",
    "authors": [
      "Y. Carmon",
      "Aditi Raghunathan",
      "Ludwig Schmidt",
      "Percy Liang",
      "John C. Duchi"
    ],
    "submission_date": "2019-05-31",
    "semantic_scholar_id": "b3f1aa12dde233aaf543bb9ccb27213c494e0fd5"
  },
  "1901-08846": {
    "title": "Improving Adversarial Robustness via Promoting Ensemble Diversity",
    "authors": [
      "Tianyu Pang",
      "Kun Xu",
      "Chao Du",
      "Ning Chen",
      "Jun Zhu"
    ],
    "submission_date": "2019-01-25",
    "semantic_scholar_id": "676e40050453ddeb1387f8314478c0ac3681a8c6"
  },
  "1901-08573": {
    "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
    "authors": [
      "Hongyang Zhang",
      "Yaodong Yu",
      "Jiantao Jiao",
      "E. Xing",
      "L. Ghaoui",
      "Michael I. Jordan"
    ],
    "submission_date": "2019-01-24",
    "semantic_scholar_id": "6c405d4b5dc41a86be05acd59c06ed19daf01d14"
  },
  "1706-06083": {
    "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
    "authors": [
      "A. MaÌ§dry",
      "Aleksandar Makelov",
      "Ludwig Schmidt",
      "Dimitris Tsipras",
      "Adrian Vladu"
    ],
    "submission_date": "2017-06-19",
    "semantic_scholar_id": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386"
  },
  "1611-01236": {
    "title": "Adversarial Machine Learning at Scale",
    "authors": [
      "Alexey Kurakin",
      "I. Goodfellow",
      "Samy Bengio"
    ],
    "submission_date": "2016-11-03",
    "semantic_scholar_id": "e2a85a6766b982ff7c8980e57ca6342d22493827"
  },
  "1608-04644": {
    "title": "Towards Evaluating the Robustness of Neural Networks",
    "authors": [
      "Nicholas Carlini",
      "D. Wagner"
    ],
    "submission_date": "2016-08-16",
    "semantic_scholar_id": "df40ce107a71b770c9d0354b78fdd8989da80d2f"
  },
  "1511-04599": {
    "title": "DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks",
    "authors": [
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Alhussein Fawzi",
      "P. Frossard"
    ],
    "submission_date": "2015-11-14",
    "semantic_scholar_id": "52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35"
  },
  "1412-6572": {
    "title": "Explaining and Harnessing Adversarial Examples",
    "authors": [
      "I. Goodfellow",
      "Jonathon Shlens",
      "Christian Szegedy"
    ],
    "submission_date": "2014-12-19",
    "semantic_scholar_id": "bee044c8e8903fb67523c1f8c105ab4718600cdb"
  }
}