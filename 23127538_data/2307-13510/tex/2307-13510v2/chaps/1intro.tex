\section{Introduction}

Vision-based Bird's Eye View (BEV) representation\cite{lu2021graph,xie2023x, yang2023bevformer, bartoccioni2023lara, lin2022sparse4d} is an emerging perception formulation for autonomous driving. It transforms and maps the information from the image space to a unified 3D BEV space, which can be used for various perception tasks like 3D object detection and BEV map segmentation. Moreover, the unified BEV space can directly fuse other modalities like LiDAR without any cost, which is of great scalability.

As shown in \cref{fig:first}, the essence of BEV representation is the 2D to 3D mapping, which is a one-to-many ill-posed problem because a point in the image space corresponds to infinite collinear 3D points along the camera ray. To resolve this problem, we need to add an extra condition to make the 2D to 3D mapping a one-to-one well-posed problem. For the added extra condition, there are two kinds of methods, which are LSS\cite{philion2020lift} and OFT\cite{roddick2018orthographic}. LSS proposes to predict latent depth as the extra condition, which is implicitly estimated by end-to-end training. OFT directly maps the 2D information to 3D in the one-to-many fashion, while a network in BEV space is needed to implicitly select the dense mapped information in the vertical or height direction, which is also realized by end-to-end training. Both methods use extra depth or height conditions to resolve the mapping problem, but the extra condition is implicitly trained and used. In this way, the correctness of the mapping is not guaranteed, which might affect the performance of BEV representation.

% Figure environment removed

Motivated by the above observations, we propose to explicitly add and model extra conditions to realize better 2D to 3D mapping.
Similarly, some works\cite{park2021pseudo,li2022bevdepth} propose to directly learn depth as the extra condition with depth pre-training or LiDAR information. Different from using depth, we explicitly model the height condition in the mapping for the following reasons. First, we prove that height in the BEV space is equivalent to depth in the image space for the 2D to 3D mapping problem. Both ways can provide equivalent conditions to resolve the problem of mapping. In this way, we can realize well-defined one-to-one mapping between 2D and 3D. Second, the height information in the BEV space can be retrieved from the BEV annotations without any other data modalities like LiDAR, while depth condition needs extra pre-training or LiDAR. In this work, we use the height information from the object's 3D bounding box, which can be directly accessed from the ground truth. Third, the modeling in height can fit arbitrary camera rigs and types. For example, on NuScenes\cite{nuscenes2019}, the focal length of the backward camera is different from other cameras, resulting in different depth estimation patterns. In other words, different depth estimation network is needed for different cameras. While for the height condition, no matter which kind of camera configuration is used, it is processed with the same pattern in the BEV space. In this way, the height condition is more robust and flexible.

In this work, we propose a network that explicitly models height in the BEV space, which fulfills the condition needed for 2D to 3D mapping, termed as HeightFormer. Moreover, based on the height modeling, self-recursive height predictors are proposed to introduce the uncertainty of heights and segmentation maps which are used in the BEV query mask mechanism to produce high-precision detection results. In summary, the main contributions of our work are summarized as follows:
% \begin{itemize}
    % \item
    1) We give theoretical proof of the equivalence between height-based methods in BEV and depth-based methods in images, which is the basis of our work. The proof also demonstrates the feasibility of detection in the BEV space generated with predicted heights.
    % \item 
    2) {{\color{blue}}We propose to explicitly model heights in the BEV space without extra LiDAR supervision. A self-recursive predictor is proposed to model heights and a corresponding segmentation-based query mask is designed to handle positions whose heights cannot be defined.
    % \item 
    3) Experiments on NuScenes\cite{nuscenes2019} show that the proposed HeightFormer achieves the SOTA performance. Extensive quantitative and qualitative results show that it is feasible and effective to model heights in the BEV space and construct the BEV representation with predicted heights. The generalization analysis also shows that the proposed method can be applied to different methods, as a plugin and as compensation for depth modeling. }
% \end{itemize} 
