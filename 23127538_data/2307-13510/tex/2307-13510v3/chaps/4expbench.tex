

\subsection{Benchmark results}


\paragraph{NuScenes \uwave{{\it validation} set}}
We report the results on NuScenes \uwave{{\it validation} set} in \cref{tab:exp1} and compare the proposed HeightFormer with state-of-the-art camera-only methods.
Compared with BEVFormer, HeightFormer improves the NDS by 1.5 percentage points.
Compared with the SOTA BEVDepth which introduces LiDAR in training and takes data augmentation in both image space and BEV space, the proposed HeightFormer has one percentage point of improvement in mAP, which is the key metric of detection.

{{\color{blue}}
After a detailed analysis of all sub-metrics, we find that the improvement of mAP mainly comes from AP at small thresholds, for example, AP@1.0m. In the meanwhile, the improvement in the detection of rare classes is larger than that of common classes: the improvements of AP about ``bus", ``trailer" and ``motorcycle" are larger than that of ``car".
% bus, trailer, and motorcycle
A potential reason is that the proposed query mask filters out the background and thus reduces false positives. This is helpful for the detection of rare classes.}


\begin{table}[bth]
    \centering
    \caption{3D detection results on NuScenes \uwave{{\it validation} set}. The listed models mostly take R101-DCN as the backbone and require no extra LiDAR data except for BEVDepth. $\dag$: Trained with CBGS\cite{zhu2019class}. *: Take LiDAR as auxiliary information in the training phase.
    }
    \begin{tabular}{l|c|cc}
        \toprule
        Model                             & Backbone & NDS$\uparrow$ & mAP$\uparrow$ \\
        \midrule
        BEVDepth$^*$\cite{li2022bevdepth} & R101-DCN & 0.538         & 0.419         \\
        \midrule
        FCOS3D\cite{wang2021fcos3d}       & R101-DCN & 0.372         & 0.295         \\
        DETR3D\dag\cite{wang2022detr3d}   & R101-DCN & 0.434         & 0.349         \\
        PGD\cite{wang2022probabilistic}   & R101-DCN & 0.428         & 0.369         \\
        BEVDet\dag\cite{huang2021bevdet}  & Swin-T   & 0.472         & 0.393         \\
        PolarDETR-T\cite{chen2022polar}   & R101-DCN & 0.488         & 0.383         \\
        UVTR\cite{li2022unifying}         & R101-DCN & 0.483         & 0.379         \\
        PETR\dag\cite{liu2022petr}        & R101-DCN & 0.442         & 0.370         \\
        Ego3RT\cite{lu2022learning}       & R101-DCN & 0.450         & 0.375         \\
        BEVFormer\cite{li2022bevformer}   & R101-DCN & 0.517         & 0.416         \\
        Ours                         & R101-DCN & {\bf 0.532}   & {\bf 0.429}   \\
        \bottomrule
    \end{tabular}
    \label{tab:exp1}
\end{table}

\begin{table}[htb]
    \centering
    \caption{3D detection results on NuScenes {\it test} set. The listed models are all camera-only methods. The proposed HeightFormer is trained without tricks. *: Extra LiDAR supervision.}
    \begin{tabular}{l|c|c|c}
        \toprule
        Model                           & Backbone & NDS$\uparrow$ & mAP$\uparrow$ \\
        \midrule
        BEVDepth$^*$\cite{li2022bevdepth}   & V2-99    & 0.600         & 0.503 \\
        \midrule
        DD3D\cite{park2021pseudo}       & V2-99    & 0.477         & 0.418         \\
        BEVDet\cite{huang2021bevdet}    & V2-99    & 0.488         & 0.424         \\
        DETR3D\cite{wang2022detr3d}     & V2-99    & 0.479         & 0.412         \\
        UVTR\cite{li2022unifying}       & V2-99    & 0.551         & 0.472         \\
        PETR\cite{liu2022petr}          & V2-99    & 0.504         & 0.441         \\
        Ego3RT\cite{lu2022learning}     & V2-99    & 0.473         & 0.425         \\
        BEVFormer\cite{li2022bevformer} & V2-99    & 0.569         & 0.481         \\
        HeightFormer                       & V2-99    & {\bf 0.573}   & {\bf 0.481}   \\
        \bottomrule
    \end{tabular}
    \label{tab:exptest}
\end{table}


\paragraph{NuScenes {\it test} set}
We report the results on NuScenes {\it test} set in \cref{tab:exptest}. The listed models all take VoVNet (V2-99)\cite{lee2019energy} initialized from DD3D\cite{park2021pseudo} as the backbone. The proposed HeightFormer improves the NDS of BEVFormer by 0.4\%. \uwave{However, this improvement is not significant compared with the improvement on the {\it validation} set. A potential reason is that the commonly adopted VoVNet backbone is pre-trained on a depth estimation task, which does not bring much benefit to height modeling.}
