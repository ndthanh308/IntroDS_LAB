\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\def\UrlFont{\rmfamily}
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{wang2006computational}
D.~Wang and G.~J. Brown, \emph{Computational auditory scene analysis:
  Principles, algorithms, and applications}.\hskip 1em plus 0.5em minus
  0.4em\relax Wiley-IEEE press, 2006.

\bibitem{hershey2016deepclustering}
J.~R. Hershey, Z.~Chen, J.~Le~Roux, and S.~Watanabe, ``Deep clustering:
  Discriminative embeddings for segmentation and separation,'' in \emph{Proc.
  ICASSP}, 2016, pp. 31--35.

\bibitem{Isik2016Interspeech09}
Y.~Isik, J.~Le~Roux, Z.~Chen, S.~Watanabe, and J.~R. Hershey, ``Single-channel
  multi-speaker separation using deep clustering,'' in \emph{Proc.
  Interspeech}, 2016, pp. 545--549.

\bibitem{Yu2017PIT}
D.~Yu, M.~Kolb{\ae}k, Z.-H. Tan, and J.~Jensen, ``Permutation invariant
  training of deep models for speaker-independent multi-talker speech
  separation,'' in \emph{Proc. ICASSP}, 2017, pp. 241--245.

\bibitem{ZQwang2022tf}
Z.-Q. Wang, S.~Cornell, S.~Choi, Y.~Lee, B.-Y. Kim, and S.~Watanabe,
  ``Tf-gridnet: Making time-frequency domain models great again for monaural
  speaker separation,'' \emph{arXiv preprint arXiv:2209.03952}, 2022.

\bibitem{schulze2019weakly}
K.~Schulze-Forster, C.~Doire, G.~Richard, and R.~Badeau, ``Weakly informed
  audio source separation,'' in \emph{Proc. WASPAA}, 2019, pp. 273--277.

\bibitem{tzinis2020improving}
E.~Tzinis, S.~Wisdom, J.~R. Hershey, A.~Jansen, and D.~P. Ellis, ``Improving
  universal sound separation using sound classification,'' in \emph{Proc.
  ICASSP}, 2020, pp. 96--100.

\bibitem{chen2014feature}
J.~Chen, Y.~Wang, and D.~Wang, ``A feature study for classification-based
  speech separation at low signal-to-noise ratios,'' \emph{IEEE/ACM
  Transactions on Audio, Speech, and Language Processing}, vol.~22, no.~12, pp.
  1993--2002, 2014.

\bibitem{xin2023improving}
Y.~Xin, X.~Peng, and Y.~Lu, ``Improving speech enhancement via event-based
  query,'' \emph{arXiv preprint arXiv:2302.11558}, 2023.

\bibitem{zeghidour2021wavesplit}
N.~Zeghidour and D.~Grangier, ``Wavesplit: End-to-end speech separation by
  speaker clustering,'' \emph{IEEE/ACM Transactions on Audio, Speech, and
  Language Processing}, vol.~29, pp. 2840--2849, 2021.

\bibitem{turpault2020improvingSoundEventDetectionusingSeparation}
N.~Turpault, S.~Wisdom, H.~Erdogan, J.~R. Hershey, R.~Serizel, E.~Fonseca,
  P.~Seetharaman, and J.~Salamon, ``Improving sound event detection in domestic
  environments using sound separation,'' in \emph{Proc. DCASE Workshop}, 2020.

\bibitem{meseguer2019conditioned}
G.~Meseguer-Brocal and G.~Peeters, ``Conditioned-u-net: Introducing a control
  mechanism in the u-net for multiple source separations,'' in \emph{Proc.
  ISMIR}, 2015, pp. 159--165.

\bibitem{wang2019voicefilter}
Q.~Wang, H.~Muckenhirn, K.~Wilson, P.~Sridhar, Z.~Wu, J.~Hershey, R.~A.
  Saurous, R.~J. Weiss, Y.~Jia, and I.~L. Moreno, ``{VoiceFilter}: Targeted
  voice separation by speaker-conditioned spectrogram masking,'' in \emph{Proc.
  Interspeech}, 2019, pp. 2728--2732.

\bibitem{ochiai20_interspeech}
T.~Ochiai, M.~Delcroix, Y.~Koizumi, H.~Ito, K.~Kinoshita, and S.~Araki,
  ``{Listen to What You Want: Neural Network-Based Universal Sound Selector},''
  in \emph{Proc. Interspeech}, 2020, pp. 1441--1445.

\bibitem{liu22w_interspeech}
X.~Liu, H.~Liu, Q.~Kong, X.~Mei, J.~Zhao, Q.~Huang, M.~D. Plumbley, and
  W.~Wang, ``{Separate What You Describe: Language-Queried Audio Source
  Separation},'' in \emph{Proc. Interspeech}, 2022, pp. 1801--1805.

\bibitem{kilgour22_interspeech}
K.~Kilgour, B.~Gfeller, Q.~Huang, A.~Jansen, S.~Wisdom, and M.~Tagliasacchi,
  ``{Text-Driven Separation of Arbitrary Sounds},'' in \emph{Proc.
  Interspeech}, 2022, pp. 5403--5407.

\bibitem{dong2023clipsep}
H.-W. Dong, N.~Takahashi, Y.~Mitsufuji, J.~McAuley, and T.~Berg-Kirkpatrick,
  ``{CLIPS}ep: Learning text-queried sound separation with noisy unlabeled
  videos,'' in \emph{Proc. ICLR}, 2023.

\bibitem{tzinis2022audioscopev2}
E.~Tzinis, S.~Wisdom, T.~Remez, and J.~R. Hershey, ``Audioscopev2: Audio-visual
  attention architectures for calibrated open-domain on-screen sound
  separation,'' in \emph{Proc. ECCV}, 2022, pp. 368--385.

\bibitem{tzinis22_interspeech}
E.~Tzinis, G.~Wichern, A.~S. Subramanian, P.~Smaragdis, and J.~{Le Roux},
  ``{Heterogeneous Target Speech Separation},'' in \emph{Proc. Interspeech},
  2022, pp. 1796--1800.

\bibitem{tzinis2022optimal}
E.~Tzinis, G.~Wichern, P.~Smaragdis, and J.~{Le Roux}, ``Optimal condition
  training for target source separation,'' in \emph{Proc. ICASSP}, 2023.

\bibitem{panayotov2015librispeech}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur, ``Librispeech: an asr corpus
  based on public domain audio books,'' in \emph{Proc. ICASSP}, 2015, pp.
  5206--5210.

\bibitem{desplanques20_interspeech}
B.~Desplanques, J.~Thienpondt, and K.~Demuynck, ``{ECAPA-TDNN: Emphasized
  Channel Attention, Propagation and Aggregation in TDNN Based Speaker
  Verification},'' in \emph{Proc. Interspeech}, 2020, pp. 3830--3834.

\bibitem{perez2018film}
E.~Perez, F.~Strub, H.~De~Vries, V.~Dumoulin, and A.~Courville, ``Film: Visual
  reasoning with a general conditioning layer,'' in \emph{Proc. AAAI}, vol.~32,
  no.~1, 2018.

\bibitem{ioffe2015batch}
S.~Ioffe and C.~Szegedy, ``Batch normalization: Accelerating deep network
  training by reducing internal covariate shift,'' in \emph{Proc. ICML}, 2015,
  pp. 448--456.

\bibitem{kong2020panns}
Q.~Kong, Y.~Cao, T.~Iqbal, Y.~Wang, W.~Wang, and M.~D. Plumbley, ``Panns:
  Large-scale pretrained audio neural networks for audio pattern recognition,''
  \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  vol.~28, pp. 2880--2894, 2020.

\bibitem{tzinis2022compute}
E.~Tzinis, Z.~Wang, X.~Jiang, and P.~Smaragdis, ``Compute and memory efficient
  universal sound source separation,'' \emph{Journal of Signal Processing
  Systems}, vol.~94, no.~2, pp. 245--259, 2022.

\bibitem{adam}
D.~P. Kingma and J.~Ba, ``Adam: {A} method for stochastic optimization,'' in
  \emph{Proc. ICLR}, 2015.

\bibitem{le2019sdr}
J.~Le~Roux, S.~Wisdom, H.~Erdogan, and J.~R. Hershey, ``Sdr--half-baked or well
  done?'' in \emph{Proc. ICASSP}, 2019, pp. 626--630.

\end{thebibliography}
