\section{Results \& Discussion}
\label{sec:results}

\subsection{Missing Attribute Completion}
\label{ssec:completion}

First, we conduct a set of experiments evaluating the performance of the completion models in the Easy and Hard dataset. In Tables~\ref{tab:comp_easy},~\ref{tab:comp_hard} we summarize the results in terms of completion accuracy for every combination of condition $\mathcal{C} \in \mathscr{C}$ and source attributes. The completion model given the mixture $\mathbf{x}$ and a condition vector $\mathbf{c}$, in the form of a one-hot vector, is tasked with estimating the rest of the source attribute values corresponding to the same target source.

Overall, we note that the model achieves impressive completion accuracy in both datasets. We observe that some attributes are easier to predict that others, for instance gender and spatial position, which are absolute attributes, are easier to predict compared to source energy and source order, which are relative instead. A possible explanation could be that in order to predict relative attributes the completion module is required to perform some degree of semantic separation and identification of the sources, rendering the prediction task more difficult. Furthermore, we note that there is a rough symmetry in the accuracy matrix; that is, the model can predict $\mathcal{O}$ given $\mathcal{S}$ roughly as well as predict $\mathcal{S}$ given $\mathcal{O}$.

Comparing the performance between the two datasets, we first notice that even though we train for fewer epochs on the Easy dataset the model accuracy is very high. In the case of the Hard dataset, we mostly observe an expected drop in performance in the relative attributes of source energy $\mathcal{E}$ and source order $\mathcal{O}$. However, the accuracy of $\mathcal{G}$ and $\mathcal{S}$ pairs remains unaffected.   


\begin{table}[!tb]
    \caption{Prediction accuracy of the completion module in the Easy dataset (at least 60\% overlap and 5 dB maximum SNR). Each row corresponds to a different input to the completion model, which is tasked with predicting the source attributes $\mathcal{G}$, $\mathcal{E}$, $\mathcal{O}$ and $\mathcal{S}$. }
    \label{tab:comp_easy}
    \centering
    \sisetup{
    detect-weight, % Make siunitx detect align bold cells correctly
    mode=text, % Make siuntix print tables in text mode (causes width of bold characters to be the same as non-bold)
    tight-spacing=true,
    round-mode=places,
    round-precision=1,
    table-format=2.1
    }
    %\resizebox{\linewidth}{!}
    \begin{tabular}{lllll}
\toprule
& \multicolumn{4}{c}{Completion Accuracy (Easy)} \\   \cmidrule(lr){2-5}
&  $\mathcal{G}$ & $\mathcal{E}$ & $\mathcal{O}$ & $\mathcal{S}$ \\ \midrule
Given $\mathcal{G}$ & - & 87.5\% & 92.6\% & 97.5\% \\ 
Given $\mathcal{E}$ & 88.1\% & - & 83.8\% & 89.2\% \\ 
Given $\mathcal{O}$ & 93.0\% & 85.0\% & - & 94.6\% \\ 
Given $\mathcal{S}$ & 98.1\% & 88.9\% & 93.6\% & - \\ \bottomrule
\end{tabular}
\vspace{-5pt}
\end{table}

\begin{table}[!tb]
    \caption{Prediction accuracy of the completion module in the Hard dataset (at least 80\% overlap and 2.5 dB maximum SNR). }
    \label{tab:comp_hard}
    \centering
    \sisetup{
    detect-weight, % Make siunitx detect align bold cells correctly
    mode=text, % Make siuntix print tables in text mode (causes width of bold characters to be the same as non-bold)
    tight-spacing=true,
    round-mode=places,
    round-precision=1,
    table-format=2.1
    }
     \begin{tabular}{lllll}
\toprule
& \multicolumn{4}{c}{Completion Accuracy (Hard)} \\   \cmidrule(lr){2-5}
& $\mathcal{G}$ & $\mathcal{E}$ & $\mathcal{O}$ & $\mathcal{S}$  \\ \midrule
Given $\mathcal{G}$ & - & 76.8\% & 90.8\% & 98.7\% \\ 
Given $\mathcal{E}$ & 80.8\% & - & 73.6\% & 76.8\% \\ 
Given $\mathcal{O}$ & 91.2\% & 74.1\% & - & 93.3\% \\ 
Given $\mathcal{S}$ & 99.1\% & 73.1\% & 93.6\% & - \\ \bottomrule
\end{tabular}
    \vspace{-15pt}
\end{table}


\subsection{Conditional Separation}
\label{ssec:separation}

\begin{table*}[t]
    \caption{Mean test SI-SDR (dB) separation performance on both the ``Easy" and the ``Hard" partitions of the spatial LibriSpeech dataset for conditional models which are evaluated using different input-condition vectors. $^*$ denotes an oracle ensemble which contains specialist single-conditioned models trained and evaluated on the corresponding condition vector.}
    \label{tab:sep_easy}
    \centering
    \sisetup{
    detect-weight, % Make siunitx detect align bold cells correctly
    mode=text, % Make siuntix print tables in text mode (causes width of bold characters to be the same as non-bold)
    tight-spacing=true,
    round-mode=places,
    round-precision=1,
    table-format=2.1
    }
    %\resizebox{\linewidth}{!}
    {
    \begin{tabular}{lccccc|ccccc}
    \toprule
    & \multicolumn{5}{c}{``Easy" partition} & \multicolumn{5}{c}{``Hard" partition} \\   \cmidrule(lr){2-6} \cmidrule(lr){7-11}
    \multicolumn{1}{l}{Input condition vector} & $\mathcal{G}$ & $\mathcal{E}$ & $\mathcal{O}$ & $\mathcal{S}$ & Overall & $\mathcal{G}$ & $\mathcal{E}$ & $\mathcal{O}$ & $\mathcal{S}$ & Overall  \\ \midrule
    HCT \cite{tzinis22_interspeech} & 11.9 & 11.2 & 8.9 & 11.8 & 10.9 & 10.9 & 9.8 & 6.8 & 10.9 & 9.6 \\
    Compeltion (Ours) & 12.5 & 11.7 & 11.1 & 12.7 & 12.0 & 11.5 & 9.8 & 9.8 & 11.6 & 10.7 \\ \midrule
    Single-condition ensemble$^*$ & 13.0 & 10.2 & 8.5 & 12.6 & 11.1 & 11.8 & 4.9 & 2.1 & 11.6 & 7.6 \\ \midrule
    PIT Oracle & & & & & 12.7 & & & & & 12.0 \\
    Completion Oracle & & & & & 13.1 & & & & & 12.1 \\
    \bottomrule
    \end{tabular}
    }
    \vspace{-5pt}
\end{table*}


In this core set of experiments, we assess our proposed approach in the task of conditional separation as formulated in Section~\ref{ssec:task}. In brief, the module given the mixture $\mathbf{x}$ and a one-hot condition vector $\mathbf{c}$, is tasked with recovering the corresponding target source $\mathbf{s}_T$. We compare against a number of baselines, with the main one being HCT as described in Section~\ref{ssec:hct}, which is a multi-condition model. A second baseline consists of all the single-condition models which are trained and evaluated conditioned only on one source attribute. Subsequently, we evaluate in relation to two oracle models. The first entails Permutation Invariant Training (PIT) \cite{Yu2017PIT} followed by oracle selection of the output source that best matches the target source. The second is the completion oracle trained with the complete attribute vector, which is equivalent to training the conditional separation model with a perfect completion module. 

In Table~\ref{tab:sep_easy} we summarize the results in terms of separation performance in the Easy and Hard datasets, respectively. First, we note that the oracle models outperform almost all of the models, with the completion oracle providing a boost over the PIT oracle, suggesting that the presence of conditional information enhances performance. As we shift our focus to single-condition models, we observe that certain attributes when employed as conditions exhibit consistently better performance, indicating that they are more discriminative compared to the others. For instance, conditioning on gender $\mathcal{G}$ yields remarkable results, comparable to those of the completion oracle and even surpassing those of the PIT oracle in the Easy setting. Nevertheless, other single-condition models employing relative conditions, such as source order $\mathcal{O}$ and source energy $\mathcal{E}$, face challenges in terms of performance, especially in the Hard setting. While, the multi-condition model HCT appears to be able to address this performance degradation to some extent, there is still potential for further improvement, as suggested by the top performing models. This indicates that the incorporation of a completion approach may be necessary or beneficial to enhance the performance of separation.

Shifting our attention to the perfomance of our proposed approach, we observe that it outperforms the HCT multi-condition model in every scenario, with an overall margin of $1.1$ dB in both settings, significantly reducing the gap to the oracle models. Our method demonstrates an improvement in performance for every type of given attribute, especially low performing ones, such as source order $\mathcal{O}$. Moreover, it drastically outperforms the single-condition models based on relative attributes, while matching or approaching the performance of the specialized signle-conditioned models based on absolute attributes. Finally, in Fig.~\ref{fig:scatterplot} we compare the performance of our approach to the HCT model by plotting the performance of each test set sample. The results presented in the figure illustrate the improvement in the mean performance achieved by our approach as compared to the HCT model. Additionally, it shows a reduction in the number of samples with negative SI-SDR, which implies that our approach has the potential to reduce the number of erroneous target source selections. 


 % Figure environment removed 




% \begin{table}[!tb]
%     \caption{Mean test SI-SDR (dB) performance on the Easy dataset.}
%     \label{tab:sep_easy}
%     \centering
%     \sisetup{
%     detect-weight, % Make siunitx detect align bold cells correctly
%     mode=text, % Make siuntix print tables in text mode (causes width of bold characters to be the same as non-bold)
%     tight-spacing=true,
%     round-mode=places,
%     round-precision=1,
%     table-format=2.1
%     }
%     %\resizebox{\linewidth}{!}
%     {
%     \begin{tabular}{llllll}
%     \toprule
%     & \multicolumn{5}{c}{Separation Performance (Easy)} \\   \cmidrule(lr){2-6}
%     Given: & $\mathcal{G}$ & $\mathcal{E}$ & $\mathcal{O}$ & $\mathcal{S}$ & Overall  \\ \midrule
%     HCT & 11.9 & 11.2 & 8.9 & 11.8 & 10.9 \\
%     Compeltion (Ours) & 12.5 & 11.7 & 11.1 & 12.7 & 12.0 \\ \midrule
%     Single cond. $\mathcal{G}$ & 13.0 & - & - & - & - \\ 
%     Single cond. $\mathcal{E}$ & - & 10.2 & - & - & - \\ 
%     Single cond. $\mathcal{O}$ & - & - & 8.5 & - & - \\ 
%     Single cond. $\mathcal{S}$ & - & - & - & 12.6 & - \\ \midrule
%     PIT Oracle & - & - & - & - & 12.7 \\
%     Completion Oracle & - & - & - & - & 13.1 \\
%     \bottomrule
%     \end{tabular}
%     }
%     % \vspace{-5pt}
% \end{table}


% \begin{table}[!tb]
%     \caption{Mean test SI-SDR (dB) performance on the Hard dataset.}
%     \label{tab:sep_hard}
%     \centering
%     \sisetup{
%     detect-weight, % Make siunitx detect align bold cells correctly
%     mode=text, % Make siuntix print tables in text mode (causes width of bold characters to be the same as non-bold)
%     tight-spacing=true,
%     round-mode=places,
%     round-precision=1,
%     table-format=2.1
%     }
%     %\resizebox{\linewidth}{!}
%     {
%     \begin{tabular}{llllll}
%     \toprule
%     & \multicolumn{5}{c}{Separation Performance  (Hard)} \\   \cmidrule(lr){2-6}
%     Given: & $\mathcal{G}$ & $\mathcal{E}$ & $\mathcal{O}$ & $\mathcal{S}$ & Overall  \\ \midrule
%     HCT & 10.9 & 9.8 & 6.8 & 10.9 & 9.6 \\
%     Compeltion (Ours) & 11.5 & 9.8 & 9.8 & 11.6 & 10.7 \\ \midrule
%     Single cond. $\mathcal{G}$ & 11.8 & - & - & - & - \\ 
%     Single cond. $\mathcal{E}$ & - & 4.9 & - & - & - \\ 
%     Single cond. $\mathcal{O}$ & - & - & 2.1 & - & - \\ 
%     Single cond. $\mathcal{S}$ & - & - & - & 11.6 & - \\ \midrule
%     PIT Oracle & - & - & - & - & 12.0 \\
%     Completion Oracle & - & - & - & - & 12.1 \\
%     \bottomrule
%     \end{tabular}
%     }
%     % \vspace{-5pt}
% \end{table}


