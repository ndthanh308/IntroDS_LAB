\section{Statistical Formalization of Skills}
\label{sec:basictheory}

This section gives a mathematical framework for thinking about skills and how they might relate to language comprehension. 
Since our theory assumes scaling laws such as (\ref{eqn:scaling}) it will have the luxury of ignoring issues of training and generalization, allowing us to reason directly about the model's behavior on the test distribution, i.e., the distribution from which the training data was drawn.   Furthermore, this distribution is assumed to consist of long stream of text-pieces, and the model's comprehension is being tested via a suitable {\em prediction loss}.


\begin{definition}[Test stream and skill graph] Test data  consists of an arbitrarily large set of {\em text-pieces}, denoted by $T$, each consisting of $C_{test}$ tokens. Each text piece has an associated {\em prediction loss}. Language has an underlying set  $S$ of {\em skills}. 

The {\em skill graph} is a bipartite graph $(S, T, E)$ where nodes in $S$ correspond to skills, 
nodes in $T$ correspond to text-pieces,  and  $(s, t)$ is in the edge set $ E$ if attaining low prediction loss on (i.e., ``comprehending'') text-piece $t$  requires using skill $s$.
\end{definition}


In this full generality no theory seems possible,  since the full skill set and the skill graph are unknown to us humans. So our theory makes some mild  assumptions. 

First, we assume that the model's ``comprehension'' of a text piece is  testable via suitable Cloze prompts\footnote{Note that cloze prompts are popular  for  evaluating  language development in children~\cite{brown2020language}, and most language comprehension skills are believed to be testable via Cloze prompts. See \cite{saunshiexplore20} for earlier use of Cloze prompts in theory of LLMs.} analogous to the Winograd example in Section~\ref{sec:excessentropy}. Specifically we assume that an (unknown) process {\sc cloze} has been used to add such suitable Cloze prompts  to the test stream (see Assumption~\ref{assum:proportionalloss}). % text-piece.

Second,  we make an assumption about how skills are mixed up in text-pieces. Such mixing is evident from  Winograd's example: {\em The city councilmen refused the demonstrators a permit because they feared violence}.  Winograd implicitly assumes that the trickiest skill needed here is pronoun/anaphora  resolution, but of course, applying that skill in this context requires other skills: understanding of causality (i.e., interpretation of ``because'') as well as world knowledge about ``city councilmen,''  ``permit,'' ``demonstrators,'' etc.  This example highlights that  if we were to look at random places in text that require pronoun disambiguation, we would encounter random real-world scenarios, whose comprehension requires very different set of skills. Moreover, the scenarios (and hence the relevant skills) could have different probabilities of occurring in the corpus. A crucial assumption in our theory is that text is generated using random combinations of skills\footnote{While our framework is suggested as a plausible way to think about a diverse text corpus, it seems a particularly good match for productions of a chat agent, since it has to generate short pieces of text in response to a user query, which usually requires a subset of skills.}. For simplicity we assume that each text-piece requires exactly $k$ skills for some $k$.
(Allowing $k$  to be a random variable is doable, but  makes notation more complicated.) Thus the skill graph has random edges ---each text piece is connected to a set of $k$ skills, which were chosen iid from an underlying skill distribution.  

Third,  to confront the issue that the distribution of text-pieces has no simple description, we assume there is an {\em unknown} procedure {\sc gen} for converting a randomly sampled tuple of skills into a text-piece exhibiting those skills, as well as an associated measure (i.e., probability) associated with that text piece. 

The next definition  formalizes the above framework in form of a {\em skill cluster}. A text corpus will in general consist of many skill clusters (e.g., wikipedia, science, coding, etc.).  We assume each text-piece appears in only a single cluster but each skill may appear in text-pieces to more than one cluster. Extensions of this framework are left for future work. 

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    % Figure removed
    \caption{Skill Graph.}
    \label{fig:skillgraph}
\vspace{-3mm}
\end{wrapfigure}

\begin{definition}[Degree-$k$ skill cluster] \label{def:nature} This is a collection of text pieces generated by ``nature'' as follows. It picks a subset of $k$ skills via iid sampling from an underlying measure $\mu_1$ on skills, and then uses a procedure {\sc gen} to create a text-piece $t$ whose comprehension requires these skills, as well as a measure $\mu_2(t)$ associated\footnote{Note that the measure on text-pieces has to have the correct marginals  e.g., the $\mu_2$-measure of all text-pieces containing a skill $s$ is $\mu_1(s)$. There are many measures satisfying this weak condition, since the number of text pieces is way larger than the number of skills.} with this text piece $t$.  Then it uses process {\sc cloze} to add cloze prompts to test comprehension on $t$. The {\em prediction loss}  on the text-piece is the cross-entropy loss on predicting the answers to the cloze questions. The average prediction loss over all text-pieces is computed with respect to this measure $\mu_2()$. %with the generated text-piece.
We call the skill-graph thus produced  a {\em degree-$k$ skill cluster}.
%associated with is the skill graph  produces by this process. \qed
\end{definition}
\noindent{\bf Note:} (1) The prediction loss does not require (i.e., penalize) the model to predict the location or contents of the prompt in the cloze question: the model has to merely predict which of the  presented multiple-choices in the cloze question is correct. This setup is implicitly assuming that the cloze questions  are easy to comprehend for a reasonably capable language model ---the only tricky part about cloze questions is answering the multiple choice question at the end. (2) As discussed earlier in Section~\ref{sec:excessentropy}, if the cloze prompt is assumed to be perfectly answerable by a human then any incorrect answers  by the model  can be interpreted as contributing to excess cross entropy. The next assumption  says that the cloze questions capture excess cross-entropy of the model as defined in (\ref{eqn:CEloss}), and from now on the theory will assume that this excess loss goes down in accordance with the scaling law.

 




\begin{assumption}\label{assum:proportionalloss}[Cloze tasks are meaningful]
{\em  The model's average prediction loss, averaged on the distribution of text pieces, closely tracks (within a small multiplicative factor)  the overall  excess cross-entropy of the pre-trained model for next-word prediction.} 
\end{assumption}
%, which have the advantage 


Definition~\ref{def:nature} allows us to interpret ``skill'' in the more familiar setting of statistical learning theory, specifically by letting us associate a statistical task with it. The task involves predicting cloze questions in a sub-distribution of text pieces that contain that skill.  

\begin{definition}[Statistical view of Skill] \label{defn:statsviewskill}
In the setting of  Definition~\ref{def:nature}, for each skill cluster and each skill $s \in S$ {\em statistical task  $T_{s}$ corresponding to $s$ and this cluster} is defined as follows. The  learner is given a text-piece  created by sampling $s_1, \ldots, s_{k-1}$  via iid sampling $(k-1)$ times from measure $\mu_1$, and applying apply {\sc gen} and {\sc cloze} to the skill-tuple $(s, s_1, \ldots, s_{k-1})$ to convert it into a text piece $t$ with an associated measure $\mu_2(t)$ (but the measure is re-scaled so that the total measure of the inputs to this task $T_s$ is $1$). 
The {\em error rate} of the model at the statistical tasks is the  expected prediction loss  on text-pieces drawn from the above distribution.

For every  $k'$-tuple of skills $(s_1, s_2,\ldots, s_{k'})$ (where $k' \leq k$)  the  statistical task 
$T_{s_1, s_2,\ldots, s_{k'}}$ corresponding to that $k$'-tuple is similarly defined. The inputs to the task are generated by completing the $k'$-tuple to a $k$-tuple $\vec{s}$ by iid sampling  of $k- k'$ additional skills from $\mu_1$  and then using {\sc gen} and {\sc cloze} to convert it into a text-piece. 
\end{definition}

To illustrate with an example, if the text-piece consists of the Winograd sentence and it involves $5$ skills, then that text-piece will appear in $5$ statistical tasks corresponding to individual skills, ${5 \choose 2}$ tasks corresponding to pairs of skills, and so on.  However, our method of measuring the loss incurred on these statistical tasks implicitly assumes that if the model incorrectly answered this cloze question (i.e., it assigned significant probability to the wrong answer), then that loss was incurred in {\em all} these statistical tasks. This accounting ignores the possibility that a prediction error may occur because just a subset of the skills were misapplied rather than all. For example a model could in principle have perfect understanding of the meaning of ``city councilmen'' but have still failed the cloze question because it doesn't correctly apply ``causality'' skill. (That said, we don't think there is a general method ---even for a human---to partition ``blame''  for wrong answers to misapplication of individual skills.) Definition~\ref{defn:statsviewskill}  can be thought of as a lower bound on the model's ``competence''  on task $T_s$. In practice, the model may be able to apply the skill more on other distributions of text-pieces than the one seen in training, which is ---as usual---ignored in the statistical view.

\iffalse 
\subsection{Connecting skills and cross-entropy}

\label{subsec:understandingskills}

%While the framework above is fairly general and could apply to many situations, this paper uses it to  understand emergence behavior in LLMs trained with a standard text corpus. %We will first make the simplifying assumption that every  
%We first do a simplified presentation of our theory of Emergence, and flesh it out with more realistic assumptions in Sections~\ref{subsec:ktuples}~\ref{subsec:multipleclusters} and~\ref{subsec:measure}.  
% The family of tasks of interest involve comprehending text-pieces. Say $s$ is a $k$-tuple of skills and $t$ is a text piece generated using this tuple. 



This assumption intuitively says that the additional text in the cloze prompt is simple and thus unambiguous for a model that is minimally competent. The model cannot predict the cloze questions themselves,  but after it reads them it is able to understand them.  It is penalized only for its answer to the cloze questions,  

%The second assumption is in effect saying that the model's gaps of understanding ---quantified earlier excess cross-entropy---can be captured via suitable cloze prompts. 

%Two questions arise: {\em (Question 1)} What are skills and who decides the complete list of skills being used in a piece of text? {\em (Question 2)} Who adds suitable cloze prompts to test the model's  capabilities at these skills? 
 
  Thus we have arrives at the core mathematical issue around convergence: {\em as  model's excess cross entropy goes down (due to scaling), how does this improve  performance on the associated statistical tasks connected with skills as well as on tuples of skills?} 
  
 
  The reader may wonder how this could be exactly calculated given our minimalistic assumptions. For example, suppose 
    a text-piece involves $k$ skills and the model gives the wrong answer to the cloze prompt for that text-piece. Which of the $k$ skills did it fail at? The assumptions give no guidance here.  Our calculation will assume that when the model succeeded in {\em correctly} answering the cloze prompt,   {\em all} skills that were needed in this text-piece were correctly applied.  Contrarily, when the model fails at the prediction task, our calculation assumes all  individual skills were incorrectly applied.) A little thought shows that this accounting gives us lower bound on model's competence at skills --and this lower bound will be shown to improve with scaling. 

\fi 
 %Second: {\em Cloze prompts do not naturally appear in text. Who is inserting them and which skills are being tested?}  Formally, we address the above formal hurdles via  the concept of an {\em Omniscient Rater}, who is assumed to know the full catalog of skills as well as where they appear in the text.  The rater is allowed to add cloze prompts in appropriate places in the test data where those skills appear. Answering the prompts adds no excess cross-entropy for the human. The model is not penalized for cross-entropy loss on words in the cloze prompts  but it incurs cross-entropy loss for its prediction in the blank slot/multiple choice occuring in the cloze prompt. The next definition makes this precise.%is made clear in the following definition.

%{\sc stopped edits here}

%\end{asummption}

%\begin{definition}[Failure rate on skill]
%Competence on a $k'$-tuple of skills is measured analogously.
%\end{definition}






\section{Deriving Emergence (uniform cluster)}
\label{subsec:emergence}

Having set up a framework for modeling skills and (via Assumption~\ref{assum:proportionalloss}) connecting them to the cross-entropy loss of the model, we have  arrived at the core mathematical issue around emergence: {\em As  model's excess cross entropy goes down (due to scaling), this improves the model's performance on cloze tasks inserted in the test stream. 
How does this improve  performance on the  statistical tasks connected with skills as well as on tuples of skills?}

This section analyzes a simple setting where the test-stream consists of a single degree-$k$ skill cluster, and the skills are uniformly distributed and so are the text-pieces---in other words, the  distributions $\mu_1$ and $\mu_2$ in Definition~\ref{def:nature} are uniform. Section~\ref{subsec:measure} will extend the analysis to the general setting.  


  First we point out the naive but incorrect way to reason about this.  Since each text piece is connected to a random $k$-tuple  of skills, say $\vec{s}$, one is tempted to reason about emergence via linearity of expectations, specifically, the following relation about prediction loss: 
\begin{equation}\label{eqn:incorrectreln}
    k \cdot E_t[\text{loss}(t)] = E_s[\text{failure rate of statistical task}~T_{s}].~~~ (\text{\bf Incorrect!})
\end{equation}
To see that this is incorrect,  let $Y$ be the subset of such text pieces where the model makes mistakes on cloze questions. This $Y$ depends upon the skill graph, and the unknown processes {\sc gen} and {\sc cloze} of Definition~\ref{def:nature}, which may introduce arbitrary correlations on text-pieces. Since the model ``saw'' part of the test stream (namely, the portion corresponding to training data) it has picked some  information about the skill cluster that is unknown. Thus at the end of training, locations of errors in the test stream  --i.e., the set $Y$---are arbitrary and dependent upon the skill-cluster. Thus our analysis is allowed to assume an upper bound on the test loss, but nothing about which text-pieces it occurs on. Thus (\ref{eqn:incorrectreln}) cannot be inferred. This is the key mathematical hurdle and our proof will surmount it using  random graph theory.

Let's say the model {\em makes a  mistake} on a text-piece if the prediction loss on the included cloze-questions is at least $1/2$ (which is the kind of error incurred if the incorrect answer is chosen with noticeable probability  on a single multiple-choice question). Since average cross-entropy loss for the text-pieces is $\delta$ we conclude $Y$ consists of at most $2\delta$ fraction of text pieces. The following result guarantees that statistical tasks corresponding to most skills do not assign significant probability to text pieces in $Y$ --in other words, the model has good performance on statistical tasks connected with these skills. The theorem follows from (and is a simple rephrasing of) Lemma~\ref{lem:mixing} in the appendix. 
\begin{theorem}[Main]\label{corr:emerge1}
  Irrespective of the details of {\sc gen} and {\sc cloze} processes, the following property holds with very high probability in a single skill-cluster with uniform distribution of skills and text pieces.  Let $Y$ be an arbitrary subset of text pieces consisting of $\theta$ fraction of text pieces.  Let $\alpha, \beta >0, \beta >1, \alpha \beta <1$ satisfy
\begin{equation} \label{eqn:mix2a}
    H(\theta) + k\theta (H(\beta \alpha)  - \beta \alpha  \log \frac{1}{\alpha} - (1- \beta \alpha)  \log (\frac{1}{1-\alpha}))<0
\end{equation}
 Then are at least $1-\alpha$ fraction of skills that have at most $\beta \theta$ fraction of their edges connected to $Y$.
 \end{theorem}
 Note that as the model is scaled up, the set $Y$ will shrink ---i.e., $\theta$ will go down. Since edges between a skill node $s$ and set $Y$ correspond to errors in the statistical task $T_s$, the theorem is giving an upper bound on the prediction error in statistical tasks corresponding to $(1-\alpha)$ fraction of skills.  Figure~\ref{fig:sub1} gives {\em performance curves}, i.e., the contour plot of the set of
$\alpha, \beta$ combinations satisfying Theorem~\ref{corr:emerge1} for a given $\theta, k$.     The horizontal axis plots $(1-\alpha)$ and the vertical axis plots $\beta \theta$, so  point $(0.8, 0.16)$ on a curve    means at least $0.8$ fraction of skills have at most $0.16$ fraction of their edges in the ``error set'' $Y$ (hence $0.84$ fraction of their edges are outside the error set). The emergence curves shift down noticeably (i.e., imply emergence of more skills) as we increase $k$. The next lemma shows this trend always holds; follows from the fact that 
$H(\theta)/\theta$ is a decreasing function in the interval $(0, 1)$. 

\begin{lemma}[Monotonicity] If $\theta' < \theta$ then the performance curve for $\theta', k$ lies below that for $\theta, k$. 

If $k' > k$ then  the performance curve of $\theta, k'$ lies  below that for $k, \theta$.
\end{lemma}
\noindent{\bf Note:}  Theorem~\ref{corr:emerge1} shows that for a fixed prediction loss $\theta$, using higher $k$ implies better emergence of skills. Since $k$ is the number of skills being used in a text-piece, it intuitively measures how {\em complex} the text is (e.g., a college text would be expected to have higher $k$ than a primary school text).   Since $\theta$ scales as per the scaling law,   our theorem predicts that more complex text  will be more effective at inducing skills, provided the scaling laws don't change.  This prediction generally matches experts' intuition, although we are not aware of a study  of scaling laws for text of different quality.

% Figure environment removed

\iffalse
\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
  \vspace{-10mm}
  % Figure removed
  \caption{Performance Curves: We give $\alpha, \beta$ combinations satisfying Corollary~\ref{corr:emerge1} for $k=8$ when $\theta=0.05, 0.1, 0.2$.  The horizontal axis plots $(1-\alpha)$ and the vertical axis plots $\beta \theta$. For example, the point $(0.8, 0.16)$ on the red curve means at least $0.8$ fraction of skills have at most $0.16$ fraction of their edges in the ``error set'' $Y$.  Section~\ref{subsec:ktuples} clarifies that these curves also describe the model's performance curve for $t$-tuples of skills for for $\theta =0.05$ and $t=1, 2, 4$ respectively . Thus for example the blue curve describes performance on $4$-tuples of skills when $\theta =0.05$.}
  \label{fig:mixing_lemma}
  \vspace{-4mm}
\end{wrapfigure}
\fi

\subsection{Emergence for $k'$-tuples of skills}
\label{subsec:ktuples}
Now we estimate the model's failure rate on statistical tasks corresponding to $k'$-tuples for $k'\leq k$.
The basic idea is to consider $k'$-tuples of skills as `composite-skills,' and then re-do the calculation.

\noindent{\bf Naive estimate:} This consists of observing that a random $k$-tuple is a union of $k/k'$ random $k'$-tuples. Considering $k'$-tuples as `composite-skills,' we get a skill-graph  with degree $k/k'$, and Theorem~\ref{corr:emerge1} can let us derive performance curves for $k'$-tuples. However, this is a weak and often trivial estimate.

\noindent{\bf 2nd estimate (better):} Consider the following {\em $k'$-wise recombination} operation on the test stream. First randomly partition the test stream into subsets of size $k'$, and then concatenate  the $k'$ text pieces within each subset to create a larger piece of text that we refer to as a ``$k'$-piece.''  All cloze questions for the old test-pieces are retained and no new cloze questions are inserted. Clearly, if the error of the model per average text-piece was $\delta$, then the  error per average $b$-piece is $k'\delta$. 
However, each $k'$-piece is now using  a random $k'k$-tuple of skills,   which we can alternatively view as $k$  random $k'$-tuples. Thus viewing $k'$-tuples of skills as `composite skills' we can use this as the skill set in  the setting of Theorem~\ref{corr:emerge1}, which gives us an easy corollary quantifying the   performance on tasks corresponding to $k'$-tuples of skills. % Thus the same proof yields the following.
%we have the following Corollary of Lemma~\ref{lem:mixing}.

\begin{lemma}[Emergence for $k'$-tuples of skills] \label{corr:emerge2}
     Consider the skill-graph $(S', T', E)$ where $S'$ consists of all $k'$-tuples of skills, $T'$ consists of $k'$-pieces, and $E$ consists of $(s', t')$ where $s'$ is a $k'$-tuple of skills and $t'$ is a $k'$-piece where this tuple of skills is used. Let $Y$ consist of $\theta$ fraction of $k'$-pieces. Then for any $\alpha, \beta >0, \beta >1, \alpha \beta <1$ satisfying (\ref{eqn:mix1}) there are at least $1-\alpha$ fraction of $k'$-tuples of skills that have at most $\beta \theta$ fraction of their edges connected to $Y$.
\end{lemma}

The next corollary presents a somewhat surprising general principle that's also hinted at in caption of Figure~\ref{fig:mixing_lemma}. Assume (for simplicity) a Chinchilla-like scaling law that $10$x up-scaling leads to  factor $2$ reduction in excess cross-entropy. If a model is considered to have reasonable performance on individual skills at current scaling, then after further up-scaling of $10x$ one would see similar reasonable performance on skill-pairs, and scaling up by yet another $10$x after that will yield similar reasonable performance on $4$-tuples of skills, etc. 
Note that these are {\em provable lower bounds} on performance gains---actual gains could  be higher. 
Figure~\ref{fig:mixing_lemma} illustrates the phenomenon.
%from scaling may  stronger boost on performance. 
%The alludes to this Corollary. 

\begin{corollary} \label{corr:emerge3} When the model $M_1$ with loss $\delta$ is scaled up (e.g., as per equation~(\ref{eqn:scaling}))  so that the new model $M_2$ has loss  $\delta/k'$,  then the performance curve inferred by our method for $k'$-tuples of skills using $M_2$ is identical to the curve inferred for individual skills on model $M_1$.
\end{corollary}  
\begin{proof}
    As noted above, a loss of $\delta$ still allows the model to make significant mistakes on $2\delta$ fraction of test pieces, which we denote by $\theta$. Thus Theorem~\ref{corr:emerge1} describes the performance curve for skills. 
    Making the loss drop to $\delta/k'$ but creating $k'$-pieces makes the fraction of errors $\theta =2\delta$ again. (Note that ``error'' now means an erroneous answer  on {\em any} cloze question in the entire $k'$-piece ---again, this is a conservative definition of error.) Applying Lemma~\ref{corr:emerge2} we get the same emergence curve as Theorem~\ref{corr:emerge1}.
\end{proof}

\textbf{Discussion of Paucity of stimulus.}  We now point out how this result leads to a  paucity of stimulus situation.  
Suppose we trained a language model with $D$ tokens. After scaling by $k$ orders of magnitude (i.e., increasing dataset size to $c^{k'}D$ tokens, where in the Chinchilla framework $c$ is around $10$) the performance on $k'$-tuples of skills is as good as what the performance was on  individual skills before the scaling. Note that the number of $k'$ tuples of skills is around $|S|^{k'}$ where $S$ is the set of skills.  This quickly leads to paucity of stimulus for some fixed $k'$, specifically, if $Dc^{k'} \ll |S|^{k'}$. To give an example, suppose $c =10$ and $|S|=10^4$ and the model's proficiency on individual skills was considered good when it was trained with $D = 10^{10}$ tokens (roughly the dataset size for GPT-2 style models).   Then a larger model trained on with $10$ trillion tokens ($10^{13}$) --  closer to the size of corpora used in training today's models-- should display proficiency in most $8$-tuples of skills, despite never not having seen most of those combinations in training (which we can be sure of because $10^{10} \times 10^8 \ll (10^4)^8$). See also Section~\ref{sec:digits} for a toy example.





%Figure~\ref{fig:mixing_lemma} shows that our theory implies nontrivial performance curves on  statistical tasks corresponding to a constant fraction of $4$-tuples, while lagging somewhat behind the performance on individual skills. Furthermore,  the Scaling Law and Corollary~\ref{corr:emerge2} imply that after two orders of magnitude of scaling,  the performance on $4$-tuples of skills catches up with individual skills, . This significant better performance on many/most $4$-tuples of skills highlights the strong inductive bias implicit in the scaling laws. The improvement happened with a constant factor increase in data-set size  whereas the number of skill combinations scales as the $4$th power of number of skills.  The model learns combinations of skills  because it only sees skills being applied in context of  random subsets of other skills, and the  model has no option but to learn this ability. See Section~\ref{sec:digits} as well.

 \iffalse 
The following easy lemma shows that failure on the average skill in the cluster tracks the average cross-entropy loss on text pieces.
\fi 


%{\sc need a different term than competence since this quantity goes up with loss.}



\iffalse 

\subsection{Deriving Emergence for skills}




This section assumes  the corpus consists of a single Skill Cluster; see Section~\ref{subsec:multipleclusters} for the  case with multiple clusters. Our analysis will proceed by tracking the excess cross-entropy loss on the test stream, which by Assumption~\ref{assum:proportionalloss} gets reduced as the  model size and dataset size are scaled up. Note that Lemma~\ref{lem:lossvsfailure} already implies that average failure rate of the model improves as we scale up. But improvement in average performance in principle does not rule out large holes in the model's capabilities on the skills. For example if the excess failure rate per text-piece is $0.5$,  this does not rule out high failure rate on half the skills.  We now show that improvement happens across a broad set of skills. This uses random graph theory from Section~\ref{subsec:randomgraphs}. The hurdle is that the reduction of loss happens on an arbitrary subset of the test stream, and Lemma~\ref{lem:mix} applies to every  $Y$ and every $Z$.



%The following lemma shows that almost all skills in the cluster improve in the process. This relies upon Lemma~\ref{lem:measure}.

{\sc Lemma to be rewritten} 
 \begin{lemma} When failure rate in a skill cluster is less than $\delta$ then there is a set of size $(1-\alpha)$ fraction of skills whose failure rate is at most $(1-\beta(1- 2\delta)$,  where $(\alpha, \beta)$ satisfy (\ref{eqn:mix2}) for $\theta = 1-2\delta$.
 \end{lemma}

Now we argue that emergence happens for many $k$-tuples of skills, which for exposition we refer to as a ``meta-skill.''  (Emergence of $k'$-tuples for $k' <k$ is similarly derived.) It again relies upon Lemma~\ref{lem:mix}.  The skill-graph for $k$-tuples is completely analogous, except the  ``new skills'' now correspond to $k$-tuples of the skills. Now each text piece
only depends on a {\em single} randomly-chosen ``new skill.'' In other words, this is just the subcase $k=1$ of the skill-cluster, and Lemma~\ref{lem:measure} continues to apply. 


\begin{lemma} \label{lem:ktuple}
When the cross-entropy loss on the test stream for the skill cluster is $\theta$ then for  at least 
$1-\alpha$ fraction of $k$-tuples of skills, the failure on that $k$-tuple  is at least $\beta\theta$,
where where $(\alpha, \beta)$ satisfy (\ref{eqn:mix2}) upon setting $k=1$.
\end{lemma}

\noindent{\bf Discussion:} The theory predicts equally fast emergence on $k$-tuples and individual skills. However, part of the reason is our decision to blame the error made on a cloze task equally to all skills. 
\fi 

\vspace{-2mm}
\section{Emergence analysis with general  measure on text and skills}
\label{subsec:measure}
\vspace{-2mm}

Now we turn to analysis of the general setting of Definition~\ref{def:nature} where text piece $t$ has measure $\mu_2(t)$ and  skill $s$ has measure $\mu_1(s)$.  In this setup, our lemma statements (e.g., Lemma~\ref{lem:mixing} as well as the ones in Sections~\ref{subsec:emergence} and \ref{subsec:ktuples}) hold -----the claim is the same but with cardinalities replaced by measure!

\begin{theorem}[Emergence of skills and $k$'-tuples of skills] \label{thm:genmeasure} Let $Y$ be any subset of text pieces consisting of text pieces with total measure $\theta$, and every text-piece has measure substantially less than $\theta$.  Let $\alpha, \beta >0, \beta >1, \alpha \beta <1$ satisfy
\begin{equation} \label{eqn:mix2a}
    H(\theta) + k\theta (H(\beta \alpha)  - \beta \alpha  \log \frac{1}{\alpha} - (1- \beta \alpha)  \log (\frac{1}{1-\alpha}))<0
\end{equation}
 Then the measure of skills that have at most $\beta \theta$ fraction of their edges connected to $Y$ is at least $1-\alpha$.

 For $k'$-tuples of skills the statement of Lemma~\ref{corr:emerge2}  holds with the same modification of cardinality to ``measure.''
 \end{theorem}
\begin{proof}
  The measure $\mu_1$ on skills is trivial to reason about  by just replacing each skill $s$ by a  number of copies that is proportional to $\mu_1(s)$. This converts the measure to a uniform measure ---specifically, $k$ iid draws  from this uniform measure are equivalent to $k$ iid  draws from the  $\mu_1$.
  
For the measure $\mu_2(\cdot)$ on texts, the above trick doesn't work. Recall that a text-piece is connected in the skill graph to a random $k$-tuple of skills. If we try to replace $\mu_2()$ with a uniform measure by replacing the text piece with identical copies, then these copies must still all connect to the {\em same}  subset of $k$ skills ---meaning these connections are correlated and not random. We need a more subtle argument. The key part is the proof of Lemma~\ref{lem:mixing} is where we
choose  random subset of text-pieces, $Y$  whose size is $\theta |T|$ and subset $Z$ of skills of size $\alpha |S|$, and then upper bound by (\label{eqn:mix1}) the expectation of the event that the latter has more than $\alpha \beta \theta k$ fraction of its edges going to
$Y$.  In presence of measure $\mu_2()$ let's pick $Y$ as follows: Independently pick text-pieces, choosing $t$ with probability $\theta \mu_2(t)$. (Note: $|Y|$ is  tightly concentrated around $\theta |T|$.) We still pick $Z$ randomly as before. Then we apply Jensen's Inquality on the same calculation to end up with the same upper bound as before. See Lemma~\ref{lem:mixing+measure} in the Appendix.
\end{proof}









\iffalse 
\begin{lemma}
If ${\mathcal T}$ is the set of all text-pieces, then each measure $\mu(t)$ on text pieces can be $(1+\epsilon)$-approximated by a weighted sum $\alpha_i \mu_i(t)$ where each $\mu_i$ is the uniform measure on some subset of ${\mathcal T}$.
\end{lemma}
\fi 
\vspace{-2mm}
\subsection{Extending theory to multiple clusters}
\label{subsec:multipleclusters}
\vspace{-2mm}
Above we assumed a single skill cluster in the language. Real-life text  might contain multiple skill clusters. For example,  standard corpora must contain a large skill cluster involving pieces of  ``everyday'' text pieces 
and a set of basic language skills and  world knowledge needed to comprehend them. Smaller clusters may correspond to specialized topics, e.g., finance, science, mathematical reasoning, etc.  We assume each piece of text appears in only one cluster but skills may appear in different clusters. When each text-piece appears in a single cluster, the  analysis of Section~\ref{sec:slingshot}) continues to apply.  The overall loss is the weighted sum of measure of text in the individual clusters. Thus overall reduction in loss will drive emergence within individual clusters. But lacking any mechanistic insight, our theory cannot predict the rate at which loss decrease (and hence emergence) happens within clusters. This pertains to the point made earlier in the paper about lack of detailed study of scaling laws for different kinds of corpora, as well as for training on mixes of corpora.


%We later discuss what it might mean for a skill to appear in different clusters. 

%\begin{lemma}[Skill emergence with multiple clusters]
 %   TBD.  As loss goes down, it may go down at different rates in different clusters. Loss decrease within each cluster drives emergence of skills within that cluster.
%\end{lemma}

We leave a more fine-grained analysis, including possibly allowing hierarchical structure in clusters, for future work. As usual, simpler settings probably give the main insight. 


\section{Toy Illustration} \label{sec:digits}



Our theory can explain the surprising phenomenon that the inductive bias of pretraining implies that combinations of skills emerge as naturally as the individual skills. Now we give a simple experiment illustrating such a phenomenon involving vision tasks on pretrained ViT models.

%We conducted an experiment to test the theory of emergence using a pre-trained Vision Transformer (ViT-CLIP) model on a custom dataset. The dataset was designed to assess the emergence of combinations of skills in vision tasks.

\begin{wrapfigure}{r}{0.5\textwidth}
    %\centering
    \vspace{-4mm}
    % Figure removed
    \caption{Composite image setup. Number of underlying skills is $10$ and the model learns to apply all $4$ skills needed for the composite image.}
    \label{fig:4tuple}
    \vspace{-2mm}
\end{wrapfigure}



Our labeled dataset consisted of $10^3$ composite images created from random selecting four images from the MNIST dataset of handwritten digit images and putting each in one quadrant of the composite image. The composite image was assigned a fixed label, which is the label of one of the four digits, randomly selected.  This is the ``target'' label, while the remaining three digits were considered ``background'' labels not made available during training.



Supervised training on this dataset used a linear probe on top of input  embeddings of the composite images output by a pre-trained Vision Transformer (ViT-CLIP) model (pre-trained on a custom image dataset). The training used mini-batch SGD. Testing was done using held out images, which were composites constructed from  MNIST images that had not been used to create the training set. This also ensured the model faced novel composite images during evaluation. 
%The goal was to predict the label of the target digit when presented with individual composite images. A subset of the images was held out for testing to evaluate the model's generalization ability.

 %This required the model to generalize its learning to correctly identify the target digit in previously unseen images.

 


The final classifier, being softmax, can  be used to output top-$4$ labels just as easily as as top-$1$. Doing so achieved approximately $92$\% accuracy in classifying the four-digit tuples even though trained using only $10^3$ examples labeled with a single digit.  Full fine-tuning of the model yielded around $95$\% accuracy with $10^3$ labeled examples.

To understand why this happened, note that since the provided label is fixed by  randomly picking one of the four digits in the image, the  optimum softmax output should learn to give   equal logit values to labels of all four digits present in the image.
Figure~\ref{fig:4tuple} describes the skill-cluster implicit here.





\iffalse 


Below, for $S \subseteq V_2$ we define $\rho(S) = \frac{|S|}{|V_2|}$ and for $T \subseteq V_2$ we define $\rho(T) = \frac{|T|}{|V_1|}$.
Also $\Gamma(s)$ denotes the neighbor set of $s$ in $V_1$. 

{\sc also need to write down asymptotics wrt $|V_1|, |V_2|$}

\subsection{Deriving Emergence} 

The important thing about the next lemma is that it holds for {\em every} $T$ and not just the average or most $T$ (which would not suffice to derive emergence). 
\begin{lemma} For any fixed $\beta$, and every $T \subseteq V_1$ with $\rho(T) =\beta$ the following is true for $1- \epsilon_1(\beta)$ fraction of $s \in V_2$:
\begin{equation}
    \rho(\Gamma(s) \cap T) \geq \beta - \epsilon_2(\beta)
\end{equation}
where $\epsilon_1(), \epsilon_2()$ are functions of $\beta$ as well as $|V_1|, |V_2|$ that go to $0$ as  the sizes of $V_1, V_2$ are increased. 
\end{lemma}
\begin{proof}
Mixing lemma for random bipartite graphs.
\end{proof}
\fi 




%{\sc sketch} Let $\mu(t) =$ excess cross-entropy on piece of text $t$. Scaling forces $\mu(V_2)$ down. Now apply the corollary to conclude that for almost all skills the excess cross-entropy goes down.


\iffalse \section{Statistical Formalization of Skills and Explanation of Emergence}
\label{sec:basictheory}

Our theory relies on scaling laws to ignore issues of training and generalization, and thus has the luxury of reasoning directly about test distribution, i.e., the distribution from which the training data was drawn.   Furthermore, this distribution is assumed to consist of long stream of text-pieces with piece $t$ having an associated measure $\mu(t)$. 
%(which do not need to be semantically related).  % to perform its  {\em test task} on it. 

\begin{definition}[Test stream and skill graph] Test data  consists of an arbitrarily long stream of {\em text-pieces}, each consisting of $C_{test}$ tokens, and an associated {\em test task}. Language has an underlying set $V_2$ of {\em skills}. Performing well on the test task associated with a text-piece $t$ requires using a subset of $V_2$.

The {\em skill graph} is a bipartite graph $(V_1, V_2, E)$ where nodes in $V_1$ correspond to text-pieces in the test stream,  nodes in $V_2$ correspond to skills, and $(v_1, v_2) \in E$ if solving the task in text-piece $v_1$ uses skill $v_2$. \end{definition}
Note that skill set $V_2$ is long and presumably hard to catalog  even for humans. We are interested here in skills as they might be defined using language models, of which we know even less. 



% LLMs are thought of as  can now be thought of as a bipartite graph.
%\begin{definition}[Skill graph]     \end{definition}
In this full generality (with skill set and the graph being unknown), no theory seems possible. So we make a (mild)  assumption about how the  test stream and skill graph are related. To motivate the assumptions, we return to Winograd's example: {\em The city councilmen refused the demonstrators a permit because they feared violence}. The Winograd challenge implicitly assumes that the trickiest skill needed here is pronoun/anaphora  resolution, but of course, applying that skill requires other skills: understanding of causality (i.e., interpretation of ``because'') as well as world knowledge about ``citycouncilmen,''  ``permit,'' ``demonstrators,'' etc.  We quickly realize, as Winograd did, that skills are intertwined and mixed up when they get used in a piece of text. This random mixing of skills is an essential feature captured in our model. 


  In the next definition note that we make no assumptions about process ${\mathcal N}$, nor about the measures $\mu_1, \mu_2$. For simplicity of notation,   our exposition treats a distribution on a finite set as a multiset.

\begin{definition}[Text generation assumption and degree-$k$ skill cluster] \label{def:nature} There is an underlying distribution $\mu_1$ on skills and a distribution $\mu_2$ on text pieces. There is an underlying process (``nature'') ${\mathcal N}$ that, given a subset $s$ of skills, can generate a text piece ${\mathcal N}(s)$ whose associated task requires the skills in the given subset, and also associates a measure $\mu_2(t)$ with the generated text-piece.

A {\em degree-$k$ skill cluster} is generated as follows.  Nature draws a subset of skills $s$ by sampling $k$ times independently from measure $\mu_1$. Then it produces a text-piece $t$  from the process ${\mathcal N}(v_2)$, and associates a measure $\mu_2(t)$ with this text-piece. Then the edges connecting $t$ to each of the $k$ skills in $v_2$ are added to the graph. (In particular,  every node in $V_1$ has degree $k$.)
\end{definition}

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    % Figure removed
    \caption{Skill Graph.}
    \label{fig:skillgraph}
\vspace{-3mm}
\end{wrapfigure}

Now we see that ``skill'' can be brought down to familiar setting of statistical learning theory:  a skill involves a distribution on text pieces, and ability to compute a desired answer for each text-piece drawn from the distribution. 

\begin{definition}[Statistical view of Skill]
In the degree-$k$ cluster of  Definition~\ref{def:nature}, define for each skill $v_2 \in V_2$ the {\em statistical task  corresponding to $v_2$} as follows. Randomly pick a  
$k$-tuple $s$ of skills  that contains $v_2$ (i.e., by iid sampling $(k-1)$ times from $\mu_1$), and then solve the prediction task corresponding to $t ={\mathcal N}(s)$).

For each  $k'$-tuple of skills for  $k' \leq k$ the  statistical task corresponding to that $k$'-tuple is simimlarly defined  ---sample a text-piece that relies upon those $k'$ skills, and do the statistical task on it. 
%{\em Failure rate} of the model on a skill-tuple is the average cross-entropy loss on the corresponding statistical task.
\end{definition}


%A {\em skill cluster} is a set of skills and set of pieces of text where each text involves a random combination of some subset of skills in the cluster. Thus the corresponding skill graph is a random bipartite graph. 
\iffalse 
\begin{definition}[Degree-$k$ Skill Cluster] A {\em degree-$k$ skill cluster}  consists of a skill graph $(V_1, V_2, E)$ where $V_2$ correspond to  subsets of $k$ skills appearing with some multiplicity, and for each $s \in V_2$ the text-piece in $V_2$  
\end{definition}
\fi 


%We point out that the above framework has in effect recast ``skills'' as a statistical task. 

\subsection{Connecting skills, cross-entropy, and emergence}

While the framework above is fairly general and could apply in many settings, we focus from now on on emergence phenomena in LLMs trained in the standard setting with a text corpus. 
%We first do a simplified presentation of our theory of Emergence, and flesh it out with more realistic assumptions in Sections~\ref{subsec:ktuples}~\ref{subsec:multipleclusters} and~\ref{subsec:measure}.  
Emergence is usually quantified by performance on various tasks. Our theory will concern skills that are testable using Cloze prompts introduced in Section~\ref{sec:excessentropy} (and used already in theory of LLMs~\cite{saunshiexplore20}). Many language comprehension skills --such as the Winograd task---are testable via Cloze prompts and testing using cloze prompts is also common in evaluations of language development in children~\cite{brown2020language}.%, which have the advantage 

\noindent{\bf Assumptions in our Theory:} {\em (1) Tasks associated with text-pieces in the test stream involve answering cloze questions. (2) The model's error on these tasks, when measured using cross-entropy loss (in context of prediction), tracks the overall excess cross-entropy of the model.} 

The second assumption is in effect saying that the model's gaps of understanding ---quantified as excess cross-entropy---can be extracted out via suitable cloze prompts. 

%Two questions arise: {\em (Question 1)} What are skills and who decides the complete list of skills being used in a piece of text? {\em (Question 2)} Who adds suitable cloze prompts to test the model's  capabilities at these skills? 
  Thus to understand emergence we arrive at the core mathematical issue: as scaling reduces the model's loss, how does this improve  performance on skills as well as on tuples of skills? But some technical issues arise. 
  
  First: {\em if a text-piece involves $k$ skills and the model gives the wrong answer to the cloze prompt for that text-piece, then which of the $k$ skills did it fail at?} For our theory, it will suffice to only consider the case when the model succeeded in {\em correctly} answering the prompt, in which case we assume it correctly applied  {\em all} skills that were needed in this sentence. (In other words, when the model fails,  our calculation will not need to assign blame to individual skills.) 


 Second: {\em Cloze prompts do not naturally appear in text. Who is inserting them and which skills are being tested?}  Formally, we address the above formal hurdles via  the concept of an {\em Omniscient Rater}, who is assumed to know the full catalog of skills as well as where they appear in the text.  The rater is allowed to add cloze prompts in appropriate places in the test data where those skills appear. Answering the prompts adds no excess cross-entropy for the human. The model is not penalized for cross-entropy loss on words in the cloze prompts  but it incurs cross-entropy loss for its prediction in the blank slot/multiple choice occuring in the cloze prompt. The next definition makes this precise.%is made clear in the following definition.

{\sc stopped edits here}


\begin{definition}[Test stream and Model's Failure Rate] Test data  consists of an arbitrarily long stream of {\em text-pieces}, each consisting of $C_{test}$ tokens. (The theory considers different $C_{test}$ values.)  The ominiscient rater has inserted  cloze prompts  at suitable places.  The {\em failure rate} of the model is its average cross-entropy loss at the cloze prompts.

Language is assumed to have an underlying measure $\mu()$, meaning each text-piece $t$  has an associated probability $\mu(t)$.
\end{definition}
\noindent{\bf Note:} For simplicity  our exposition below assumes a uniform measure on text; Section~\ref{subsec:measure} sketches how to  extend the analysis when a general measure exists on text-pieces and skills. 

Intuitively, the failure rate of the model measures how well it has picked up language skills that occur in natural text.

\begin{assumption}[Excess cross-entropy vs failure rate] \label{assum:proportionalloss} The average cross-entropy loss of the model per cloze question scales roughly in proportion to excess per-token cross-entropy loss on the full text.     
\end{assumption} 
\noindent{\bf Note:} This assumption intuitively says that the additional text in the cloze prompt is simple and thus unambiguous for a model that is minimally competent. The model cannot predict the cloze questions themselves,  but after it reads them it is able to understand them.  It is penalized only for its answer to the cloze questions,  which are assumed to collectively condense out the overall difficulty of understanding the text-piece. 

%\end{asummption}

%\begin{definition}[Failure rate on skill]
%Competence on a $k'$-tuple of skills is measured analogously.
%\end{definition}

\subsection{Deriving Emergence}
\label{subsec:emergence}

 By Assumption~\ref{assum:proportionalloss}, the average cross-entropy loss on the cloze questions tracks the excess cross entropy of the language model. Thus as the model is scaled up, the loss on cloze-questions will go down.  Since each text piece is connected to a random $k$-tuple of skills, one is tempted to reason about emergence via linearity of expectations, specifically, the following relation: 
\begin{equation}\label{eqn:incorrectreln}
    k \cdot E_t[\text{loss}(t)] = E_s[\text{failure rate of}~s].~~~ (\text{\bf Incorrect!})
\end{equation}
This is incorrect!  Let $Y$ be the subset of such text pieces where the model makes mistakes on cloze questions. This $Y$ depends upon the skill-cluster graph, which the model ``saw''  during training (at least, the portion corresponding to training data).  Thus the graph cannot be treated as random after $Y$ has been revealed and (\ref{eqn:incorrectreln}) cannot be infered. Our proof will surmount this mathematical hurdle using random graph theory. 

Let's say the model {\em makes a  mistake} on a text-piece if the cross-entropy loss on the included cloze-questions is at least $1/2$ (which is the kind of error associated with incorrect answer being chosen with noticeable probability  on a multiple-choice question). Since average cross-entropy loss for the average text-piece is $\delta$ we conclude $Y$ consists of at most $2\delta$ fraction of text pieces. The following result guarantees that many individual skills do not get used too often in text pieces in $Y$ --in other words, the model has good performance on statistical tasks connected with these skills.

\begin{corollary}(to Lemma~\ref{lem:mixing}) \label{corr:emerge1}
   Viewing the skill-cluster as a degree-$k$ bipartite graph, let $Y$ consist of $\theta$ fraction of text pieces.  For any $\alpha, \beta >0, \beta >1, \alpha \beta <1$ satisfying (\ref{eqn:mix1}) there are at least $1-\alpha$ fraction of skills that have at most $\beta \theta$ fraction of their edges connected to $Y$.
 \end{corollary}
Figure~\ref{fig:sub1} gives performance curves, i.e. 
$\alpha, \beta$ combinations satisfying Corollary~\ref{corr:emerge1}.  The horizontal axis plots $(1-\alpha)$ and the vertical axis plots $\beta \theta$, so  point $(0.8, 0.16)$ on a curve    means at least $0.8$ fraction of skills have at most $0.16$ fraction of their edges in the ``error set'' $Y$ (hence $0.84$ fraction of their edges are outside the error set). 
% Figure environment removed

\iffalse
\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
  \vspace{-10mm}
  % Figure removed
  \caption{Performance Curves: We give $\alpha, \beta$ combinations satisfying Corollary~\ref{corr:emerge1} for $k=8$ when $\theta=0.05, 0.1, 0.2$.  The horizontal axis plots $(1-\alpha)$ and the vertical axis plots $\beta \theta$. For example, the point $(0.8, 0.16)$ on the red curve means at least $0.8$ fraction of skills have at most $0.16$ fraction of their edges in the ``error set'' $Y$.  Section~\ref{subsec:ktuples} clarifies that these curves also describe the model's performance curve for $t$-tuples of skills for for $\theta =0.05$ and $t=1, 2, 4$ respectively . Thus for example the blue curve describes performance on $4$-tuples of skills when $\theta =0.05$.}
  \label{fig:mixing_lemma}
  \vspace{-4mm}
\end{wrapfigure}
\fi

\subsection{Emergence for $k'$-tuples of skills}
\label{subsec:ktuples}
Now we estimate the model's failure rate on statistical tasks corresponding to $k'$-tuples for $k'\leq k$.

\noindent{\bf Naive estimate:} This consists of observing that a random $k$-tuple is a union of $k/k'$ random $k'$ tuples. Considering $k'$-tuples as `new-skills,' we get a skill-graph  with degree $k/k'$, and Corollary~\ref{corr:emerge1} can let us derive performance curves for $k'$-tuples. However, this is a weak and sometimes trivial estimate.

\noindent{\bf 2nd estimate (better):} Consider a {\em $t$-wise recombination} operation on the test stream. First it randomly divides the test stream into subsets of size $t$, and then it concatenates  the $t$ text pieces within each subset to create a larger piece of text that we refer to as a ``$t$-piece.''  All cloze questions for the old test-pieces are retained and no new cloze questions are inserted. Clearly, if the error of the model per average text-piece was $\delta$, then the  error per average $t$-piece is $t\delta$. 
However, each $t$-piece is now using  a random $tk$-tuple of skills,   which we can alternatively view as $k$  random $t$-tuples. Thus we can use the random graph theory to derive performance on $t$-tuples of skills. 
%we have the following Corollary of Lemma~\ref{lem:mixing}.

\begin{corollary}(Emergence for $t$-tuples of skills) \label{corr:emerge2}
     In setting of Lemma~\ref{lem:mixing} consider the bipartite random graph of degree $k$ where $V_1$ consists of $t$-pieces and  $V_2$ consists of $t$-tuples of skills.  Let $Y$ consist of $\theta$ fraction of $t$-pieces. Then for any $\alpha, \beta >0, \beta >1, \alpha \beta <1$ satisfying (\ref{eqn:mix1}) there are at least $1-\alpha$ fraction of $t$-tuples of skills that have at most $\beta \theta$ fraction of their edges connected to $Y$.
\end{corollary}

The next corollary presents a somewhat surprising general principle (alluded to in caption of Figure~\ref{fig:mixing_lemma}): if the model is considered to have reasonable performance on individual skills, then scaling it up by one order of magnitude will yield same reasonable performance on skill-pairs, and scaling up by yet another order of magnitude will yield same performance on $4$-tuples of skills, etc. (Recall that the Chinchilla law predicts roughly a factor $2$ reduction in excess cross-entropy with one magnitude of up-scaling.)
%another scaling by one order of magnitude will yield reasonable performance on quadruples, and so on. We caution 
Note that these are {\em provable bounds} on performance gains---actual gains could  be higher.
%from scaling may  stronger boost on performance. 
%The alludes to this Corollary. 

\begin{corollary} \label{corr:emerge2} When the model $M_1$ with loss $\delta$ is scaled up (e.g., as per equation~(\ref{eqn:scaling})) so that its loss drops from $\delta$ to $\delta/t$ then the performance curve inferred by our method for $t$-tuples of skills using $M_2$ is identical to the curve inferred for individual skills on $M_1$.
\end{corollary}  
\begin{proof}
    As noted above, a loss of $\delta$ still allows the model to make significant mistakes on $2\delta$ fraction of test pieces, which we denote by $\theta$. Thus Corollary~\ref{corr:emerge1} describes the performance curve for skills. 
    Making the loss drop to $\delta/t$ but creating $t$-pieces makes the fraction of errors $\theta =2\delta$ again. (Note that ``error'' now means an erroneous answer  on {\em any} cloze question in the entire $t$-piece.) Applying Corollary~\ref{corr:emerge2} we get the same emergence curve. 
\end{proof}




\iffalse 
\begin{corollary}(performance on tuples of skills) \label{corr:emerge1}
   Let $Y$ consist of $\theta$ fraction of text pieces.  For any $\alpha, \beta >0, \beta >1, \alpha \beta <1$ satisfying (\ref{eqn:mix1}) there are at least $1-\alpha$ fraction of skills that have at most $\beta \theta$ fraction of their edges connected to $Y$.
 \end{corollary}
\fi 
\vspace{-4mm}
\textbf{Discussion of Paucity of stimulus.} Figure~\ref{fig:mixing_lemma} illustrates that our theory predicts interesting performance curves for statistical tasks involving a constant fraction of 4-tuples, although they are slightly behind the performance on individual skills. Moreover, according to the Scaling Law and Corollary~\ref{corr:emerge2}, after scaling by two orders of magnitude, the performance on 4-tuples of skills catches up with that of individual skills. This substantial improvement in performance on most 4-tuples of skills highlights the strong inductive bias inherent in the scaling laws. Notably, this improvement occurred with a constant factor increase in the size of the dataset, while the number of $4$-tuples of skills grows as the $4$th power of the number of skills. The model learns combinations of skills because it only observed skills being applied within random subsets of other skills. See also Section~\ref{sec:digits}.


%Figure~\ref{fig:mixing_lemma} shows that our theory implies nontrivial performance curves on  statistical tasks corresponding to a constant fraction of $4$-tuples, while lagging somewhat behind the performance on individual skills. Furthermore,  the Scaling Law and Corollary~\ref{corr:emerge2} imply that after two orders of magnitude of scaling,  the performance on $4$-tuples of skills catches up with individual skills, . This significant better performance on many/most $4$-tuples of skills highlights the strong inductive bias implicit in the scaling laws. The improvement happened with a constant factor increase in data-set size  whereas the number of skill combinations scales as the $4$th power of number of skills.  The model learns combinations of skills  because it only sees skills being applied in context of  random subsets of other skills, and the  model has no option but to learn this ability. See Section~\ref{sec:digits} as well.

 \iffalse 
The following easy lemma shows that failure on the average skill in the cluster tracks the average cross-entropy loss on text pieces.
\fi 


%{\sc need a different term than competence since this quantity goes up with loss.}



\iffalse 

\subsection{Deriving Emergence for skills}




This section assumes  the corpus consists of a single Skill Cluster; see Section~\ref{subsec:multipleclusters} for the  case with multiple clusters. Our analysis will proceed by tracking the excess cross-entropy loss on the test stream, which by Assumption~\ref{assum:proportionalloss} gets reduced as the  model size and dataset size are scaled up. Note that Lemma~\ref{lem:lossvsfailure} already implies that average failure rate of the model improves as we scale up. But improvement in average performance in principle does not rule out large holes in the model's capabilities on the skills. For example if the excess failure rate per text-piece is $0.5$,  this does not rule out high failure rate on half the skills.  We now show that improvement happens across a broad set of skills. This uses random graph theory from Section~\ref{subsec:randomgraphs}. The hurdle is that the reduction of loss happens on an arbitrary subset of the test stream, and Lemma~\ref{lem:mix} applies to every  $Y$ and every $Z$.



%The following lemma shows that almost all skills in the cluster improve in the process. This relies upon Lemma~\ref{lem:measure}.

{\sc Lemma to be rewritten} 
 \begin{lemma} When failure rate in a skill cluster is less than $\delta$ then there is a set of size $(1-\alpha)$ fraction of skills whose failure rate is at most $(1-\beta(1- 2\delta)$,  where $(\alpha, \beta)$ satisfy (\ref{eqn:mix2}) for $\theta = 1-2\delta$.
 \end{lemma}

Now we argue that emergence happens for many $k$-tuples of skills, which for exposition we refer to as a ``meta-skill.''  (Emergence of $k'$-tuples for $k' <k$ is similarly derived.) It again relies upon Lemma~\ref{lem:mix}.  The skill-graph for $k$-tuples is completely analogous, except the  ``new skills'' now correspond to $k$-tuples of the skills. Now each text piece
only depends on a {\em single} randomly-chosen ``new skill.'' In other words, this is just the subcase $k=1$ of the skill-cluster, and Lemma~\ref{lem:measure} continues to apply. 


\begin{lemma} \label{lem:ktuple}
When the cross-entropy loss on the test stream for the skill cluster is $\theta$ then for  at least 
$1-\alpha$ fraction of $k$-tuples of skills, the failure on that $k$-tuple  is at least $\beta\theta$,
where where $(\alpha, \beta)$ satisfy (\ref{eqn:mix2}) upon setting $k=1$.
\end{lemma}

\noindent{\bf Discussion:} The theory predicts equally fast emergence on $k$-tuples and individual skills. However, part of the reason is our decision to blame the error made on a cloze task equally to all skills. 
\fi 

\vspace{-2mm}
\subsection{Allowing a measure on text and another measure on skills}
\label{subsec:measure}
\vspace{-2mm}

The above setup involved a uniform distribution on skills and on text-pieces. In practice, text pieces have different probabilities and very likely the skills too. We denote by $\mu(t)$ the probability of text-piece $t$, and by $\rho(s)$ the probability of skill $s$. Each text-piece has edges to $k$ skills, where the $k$-tuple of skills is chosen via $k$ independent draws\footnote{Concretely, this corresponds to a generative process for text where nature generates a text-piece by first randomly picking a $k$-tuple of skills via iid sampling on $\rho()$ and then generates a text piece $t$ that uses that $k$-tuple of skills, and then assigns it the measure $\mu(t)$.} according to measure $\rho(\cdot)$.  In this setup, our lemma statements (e.g., Lemma~\ref{lem:mixing} as well as the ones in Sections~\ref{subsec:emergence} and \ref{subsec:ktuples}) hold but instead of cardinality of sets we need to use their measure. 

\noindent{\bf Allowing measure on skills.} The measure $\rho$ on skills is trivial to reason about  by just replacing each skill $s$ by a  number of copies that is proportional to $\rho(s)$. This converts the measure to a uniform measure ---specifically, random draw from this uniform measure is equivalent to random draw from measure $\rho$.   

\noindent{\bf Allowing measure on texts.} For the measure $\mu(t)$ on texts, the above trick doesn't work. Recall that a text-piece is connected in the skill graph to a random $k$-tuple of skills. If we try to replace $\mu()$ with a uniform measure by replacing the text piece with identical copies, then these copies must still all connect to the {\em same}  subset of $k$ skills ---meaning we no longer have a random graph. We need a more subtle argument. 

The key part is the proof of Lemma~\ref{lem:mixing} where 
choose  random subset $Y \subseteq V_1$ of size $\theta V_1$ and subset $Z \subseteq V_2$ of size $\alpha N_2$, and then upper bound by (\label{eqn:mix1}) the expectation of the event that the latter has more than $\alpha \beta \theta k$ fraction of its edges going to
$Y$.  In presence of measure $\mu()$ let's pick $Y \subseteq V_1$ as follows: Independently pick text-pieces, choosing $t$ with probability $\theta \mu(t)$. (Note: $|Y|$ is  tightly concentrated around $\theta N_1$.) We still pick $Z$ randomly as before. Then we apply Jensen's Inquality on the same calculation to end up with the same upper bound as before. See Appendix.

\iffalse 
\begin{lemma}
If ${\mathcal T}$ is the set of all text-pieces, then each measure $\mu(t)$ on text pieces can be $(1+\epsilon)$-approximated by a weighted sum $\alpha_i \mu_i(t)$ where each $\mu_i$ is the uniform measure on some subset of ${\mathcal T}$.
\end{lemma}
\fi 
\vspace{-2mm}
\subsection{Extending theory to multiple clusters}
\label{subsec:multipleclusters}
\vspace{-2mm}
Above we assumed a single skill cluster in the language. Real-life text  might contain multiple skill clusters. For example,  standard corpora must contain a large skill cluster involving pieces of  ``everyday'' text pieces 
and a set of basic language skills and  world knowledge needed to comprehend them. Smaller clusters may correspond to specialized topics, e.g., finance, science, mathematical reasoning, etc.  We assume each piece of text appears in only one cluster but skills may appear in different clusters. The disjoint clusters of text is reminiscent of the setup considered in Section~\ref{sec:slingshot}). The overall loss is the weighted sum of measure of text in the individual clusters. Thus overall reduction in loss will drive emergence within individual clusters, but lacking any mechanistic insight, our theory cannot predict the rate at which loss decrease (and hence emergence) happens within clusters. 


%We later discuss what it might mean for a skill to appear in different clusters. 

%\begin{lemma}[Skill emergence with multiple clusters]
 %   TBD.  As loss goes down, it may go down at different rates in different clusters. Loss decrease within each cluster drives emergence of skills within that cluster.
%\end{lemma}

We leave a more fine-grained analysis, including possibly hierarchical structure in clusters, for future work. We do not attempt it here because the basic insights about emergence of skills are clearer in the simple settings discussed above. 


\section{Toy Illustration} \label{sec:digits}
Our theory can explain the surprising phenomenon that the inductive bias of pretraining implies that combinations of skills emerge as naturally as the individual skills. Now we give a simple experiment illustrating such a phenomenon involving vision tasks on pretrained ViT models.

%We conducted an experiment to test the theory of emergence using a pre-trained Vision Transformer (ViT-CLIP) model on a custom dataset. The dataset was designed to assess the emergence of combinations of skills in vision tasks.





Our labeled dataset consisted of $10^3$ composite images created from random selecting four images from the MNIST dataset of handwritten digit images and putting each in one quadrant of the composite image. The composite image was assigned a fixed label, which is the label of one of the four digits, randomly selected.  This is the ``target'' label, while the remaining three digits were considered ``background'' labels not made available during training.

\begin{wrapfigure}{r}{0.5\textwidth}
    %\centering
    \vspace{-4mm}
    % Figure removed
    \caption{Composite image setup. Number of underlying skills is $10$ and the model learns to apply all $4$ skills needed for the composite image.}
    \label{fig:4tuple}
    \vspace{-2mm}
\end{wrapfigure}

Supervised training on this dataset used a linear probe on top of input  embeddings of the composite images output by a pre-trained Vision Transformer (ViT-CLIP) model (pre-trained on a custom image dataset). The training used mini-batch SGD. Testing was done using held out images, which were composites constructed from  MNIST images that had not been used to create the training set. This also ensured the model faced novel composite images during evaluation. 
%The goal was to predict the label of the target digit when presented with individual composite images. A subset of the images was held out for testing to evaluate the model's generalization ability.

 %This required the model to generalize its learning to correctly identify the target digit in previously unseen images.

The final classifier, being softmax, can  be used to output top-$4$ labels just as easily as as top-$1$. Doing so achieved approximately $92$\% accuracy in classifying the four-digit tuples even though trained using only $10^3$ examples labeled with a single digit.  Full fine-tuning of the model yielded around $95$\% accuracy with $10^3$ labeled examples.

To understand why this happened, note that since the provided label is fixed by  randomly picking one of the four digits in the image, the  optimum softmax output should learn to give   equal logit values to labels of all four digits present in the image.
Figure~\ref{fig:4tuple} describes the skill-cluster implicit here.



\iffalse 


Below, for $S \subseteq V_2$ we define $\rho(S) = \frac{|S|}{|V_2|}$ and for $T \subseteq V_2$ we define $\rho(T) = \frac{|T|}{|V_1|}$.
Also $\Gamma(s)$ denotes the neighbor set of $s$ in $V_1$. 

{\sc also need to write down asymptotics wrt $|V_1|, |V_2|$}

\subsection{Deriving Emergence} 

The important thing about the next lemma is that it holds for {\em every} $T$ and not just the average or most $T$ (which would not suffice to derive emergence). 
\begin{lemma} For any fixed $\beta$, and every $T \subseteq V_1$ with $\rho(T) =\beta$ the following is true for $1- \epsilon_1(\beta)$ fraction of $s \in V_2$:
\begin{equation}
    \rho(\Gamma(s) \cap T) \geq \beta - \epsilon_2(\beta)
\end{equation}
where $\epsilon_1(), \epsilon_2()$ are functions of $\beta$ as well as $|V_1|, |V_2|$ that go to $0$ as  the sizes of $V_1, V_2$ are increased. 
\end{lemma}
\begin{proof}
Mixing lemma for random bipartite graphs.
\end{proof}
\fi 




%{\sc sketch} Let $\mu(t) =$ excess cross-entropy on piece of text $t$. Scaling forces $\mu(V_2)$ down. Now apply the corollary to conclude that for almost all skills the excess cross-entropy goes down.
\fi 