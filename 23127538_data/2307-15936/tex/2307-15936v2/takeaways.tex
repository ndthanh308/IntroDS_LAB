\section{Takeaways about skill emergence}
\label{sec:skilltakeaways}

It may be useful to note the following takeaways about skill emergence as per  our theory.

%\begin{description}
\noindent{\bf 1. How scaling improves competence on $k'$-tuples of skills:}
Theorem~\ref{thm:genmeasure} and Corollary~\ref{corr:emerge3} implies that the effect of reducing $\theta$ by a factor $2$ (which as per scaling laws corresponds to roughly one order of scaling up in model parameters) 
has the effect of raising competence on $2k'$-tuples to at least the same level as what it was on $k'$-tuples before scaling. 


\noindent{\bf 2. Effect of  using ``high quality'' text:} Theorem~\ref{corr:emerge1} shows that for a fixed prediction loss $\theta$, using higher $k$ implies better emergence of skills. Since $k$ is the number of skills being used in a single text-piece, it intuitively measures how {\em complex} the text is ---e.g., a college text would be expected to have higher $k$ than a primary school text.   If the scaling law is same for both types of text (i.e., how $\theta$ reduces from scaling) our theorem predicts that more complex text  will be more effective at inducing skills.  This prediction generally matches experts' intuition, although we are not aware of a study  of scaling laws that tries to separate out texts of different quality. 

\noindent {\bf 3. More frequent skills tend to reach competence level quicker than less frequent skills:} This effect is  hidden in the proof of Theorem~\ref{thm:genmeasure}. Specifically, the proof reduces the case of skills appearing with different frequencies in the corpus to the uniform case by replacing a skill node with a set of nodes whose cardinality scales in proportion to the skill frequency. But note that by definition, the competence on all copies of the same skill must be the same. Thus essentially the calculation says that $k'$-tuples  that include more frequent skills will tend to emerge faster.

\noindent{\bf 4. Learning despite Paucity of stimulus.}  We discuss how the improvement of
competence on $k'$-tuple of skills (as discussed in item 1. above) leads to a paucity of stimulus situation. 
Suppose we trained a language model with $D$ tokens. After scaling by $k$ orders of magnitude (i.e., increasing dataset size to $c^{k'}D$ tokens, where in the Chinchilla framework $c$ is around $10$) the performance on $k'$-tuples of skills is as good as what the performance was on  individual skills before the scaling. Note that the number of $k'$ tuples of skills is around $|S|^{k'}$ where $S$ is the set of skills.  This quickly leads to paucity of stimulus for some fixed $k'$, specifically, if $Dc^{k'} \ll |S|^{k'}$. We give an example just for illustration. Suppose $c =10$ and $|S|=10^4$ and the model's proficiency on individual skills was considered good when it was trained with $D = 10^{10}$ tokens (roughly the dataset size for GPT-2 style models).   Then a larger model trained with $10$ trillion tokens ($10^{13}$) --  closer to the size of corpora used in training today's models-- would display proficiency in most $8$-tuples of skills, despite never not having seen most of those combinations in training (which we can be sure of because $10^{10} \times 10^8 \ll (10^4)^8$). 

