\vspace{-3pt}
\section{Preliminaries}


Let $x$ be a real image. A latent diffusion model (LDM) consists of an encoder $\gE: x \mapsto z_0$, decoder $\mathcal{D}: z_0 \mapsto \hat{x}$, and a denoising U-Net $\eps_\theta: (z_t; t, c_{\rm{text}}, c_{\rm{pose}}) \mapsto \hat{\eps}$. The timestep $t$ indexes a diffusion process, in which latent vectors $z_0$ derived from real images are mapped to a Gaussian distribution $z_T \sim \normal(0, I)$ by composing small amounts of i.i.d. noise at each step. Each noisy latent vector $z_t$ can be related to the original input as $z_t = \alpha_t z_0 + \sigma_t \eps$, $\eps \sim \mathcal{N}(0,I)$, for parameters $\alpha_t$ and $\sigma_t$. The role of the denoising U-Net is to estimate $\eps$ \cite{ddpm}. An LDM performs gradual denoising over several iterations, producing high quality outputs that faithfully incorporate conditioning information. $c_{\rm{text}}$ is text that describes the desired image (optionally including a negative prompt), and $c_{\rm{pose}}$ represents an optional conditioning pose for human or anthropomorphic subjects. The mechanics of text conditioning is described in \cite{ldm}, and pose conditioning is described in \cite{controlnet}.

% Pre-trained latent diffusion models like Stable Diffusion can produce high-quality reconstructions, $\norm{E(D(x)) - x}$ is small for a very wide range of images $x$.
