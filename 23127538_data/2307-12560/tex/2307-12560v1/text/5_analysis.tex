\vspace{-3pt}
\section{Experiments}\label{analysis}
\vspace{-3pt}

We analyze the effect of various design choices when applying Stable Diffusion v2.1 \cite{ldm} with pose-conditioned ControlNet on a curated set of \numpairs pairs of images spanning diverse domains (see Fig. \ref{fig:more_interps}-\ref{fig:last_interps} for more examples). They include photographs, logos and user interfaces, artwork, ads and posters, cartoons, and video games. %We include examples with landscapes, buildings, and multiple subjects., and the full set of inputs and interpolations is available at \url{masked_url}

\subsection{Latent Interpolation}

We compare our approach for latent vector interpolation against several baselines: interpolating without denoising (interpolate only), interpolating between noisy versions of the input vectors (interpolate-denoise), interpolating partially denoised versions of generated latents (denoise-interpolate-denoise), and denoise-interpolate-denoise with no shared noise added to the input latents.

\paragraph{Interpolate only}
The naive interpolation scheme simply interpolates the clean latent codes of the input images without performing any diffusion. We set $z_0^0 := \gE(x^0)$, $z_0^N := \gE(x^N)$, and all images are generated via $z_0^i = \texttt{slerp}(z_0^0, z_0^N, i/N)$, $x^i := \mathcal{D}(z_0^i)$. This approach completely fails to generate reasonable images as the denoised latent space in LDMs is not well-structured. 

\paragraph{Interpolate-denoise}
We choose a sequence of increasing timesteps $\mathcal{T}=(0,\dots,T)$ and create sequences of corresponding noisy latents $\{z_t^0\}_{t \in \mathcal{T}}, \{z_t^N\}_{t \in \mathcal{T}}$, such that:
\begin{gather}
z_t^0 = \alpha_t z_{t-1}^0 + \beta_t \eps_t, \\
z_t^N = \alpha_t z_{t-1}^N + \beta_t \eps_t,
\end{gather}
where $\eps_t \sim \normal(0,I)$ is shared for both images, and $z_0^0, z_0^N$ are obtained as before.
Each intermediate image is assigned a particular timestep $t := \texttt{frame\char`_schedule}(i)$ to generate its interpolated latent code: $z_t^i := \texttt{slerp}(z_t^0, z_t^N, i/N)$. \texttt{frame\char`_schedule} is a function that monotonically decreases as its input approaches 0 or $N$, to support smooth interpolation close to the input images. We then perform denoising with the LDM: $z_0^i := \mu_\theta(z_t^i, t)$ and use the decoder to produce the image. 
% We then generate interpolated latent codes , $x^i := \mathcal{D}(z_0^i)$assign lower timesteps to frames near the beginning and end of the sequence so that they remain similar to the input images. 
% This interpolation scheme diffuses the interpolated latent codes in the sequence such that , using shared noise in the forward diffusion process.

\paragraph{Denoise-interpolate-denoise}
If we rely on $\{z_t^0\}$ and $\{z_t^N\}$ to generate all intermediate latents, adjacent images at high noise levels may diverge significantly during the denoising process. Instead, we can interpolate images in a branching pattern as follows: we first generate $z_{t_1}^{N/2}$ as an interpolation of $z_{t_1}^0$ and $z_{t_1}^N$, denoise it to time $t_2$, then generate $z_{t_2}^{N/4}$ as an interpolation of $z_{t_2}^0$ and $z_{t_2}^{N/2}$, and generate $z_{t_2}^{3N/4}$ similarly. These two new latents can be denoised to time $t_3$, and so on. The branching factor can be modified at any level so the total number of frames does not need to be a power of 2. This interpolation scheme is similar to latent blending \cite{latentblending}.

% is visualized in Fig. \ref{fig:interp} and
% Because the latent space traversed between $\{z_t^0\}$ and $\{z_t^N\}$ is not necessarily well-behaved.
% This interpolation scheme performs interpolation of noisy latent codes. We perform forward diffusion on the latents of the input images using shared noise. We first generate the midpoint latent by interpolating these noisy latents. We reverse diffuse this latent for some number of steps, then generate quartile latents by interpolating the partially denoised midpoint latent with the input latents at the same noise level. This interpolation scheme is visualized in Fig. \ref{fig:interp}.


\input{figs/3_comparison}

Qualitatively we found that the most convincing and interesting interpolations were achieved by our method (Fig. \ref{fig:comparison}). Other interpolation schemes either fully couple the noise between all frames, which results in less creative outputs that resemble alpha blending rather than a semantic transformation, or do not perform any noise coupling, which can result in abrupt changes between adjacent frames. 
Interestingly this phenomenon is not captured by distributional metrics such as Fr\'echet inception distance (FID) \cite{fid} or smoothness metrics such as perceptual path length (PPL) \cite{stylegan2} (see Table \ref{tbl:performance}). We computed the FID between the distribution of input images and distribution of output images (two random frames sampled from every interpolation) as a proxy for the degree to which output images lie on the image manifold. We compute PPL as the sum of Inception v3 distances between adjacent images in 17-frame sequences, to measure the smoothness of the interpolations and the degree to which the interpolation adheres to the appearance of the input images. We find that both these metrics favor interpolations that resemble simple alpha composites rather than more creative interpolations, as the latter deviate more in feature statistics from the original set of images, even if they would be preferred by users. Thus current metrics are insufficient to capture the effectiveness of an interpolation, an open question that we hope to tackle in future work.

\input{tables/compare}


\vspace{-3pt}
\subsection{Extensions}
% The original formulation of diffuse then interpolate uses the same 

\paragraph{Interpolation schedule}
In all examples presented in this paper, we use a uniform interpolation schedule. But evenly spaced interpolations in the latent space do not necessarily translate to a constant rate of perceptual changes in the image space. While coloration and brightness seem to evolve at a constant rate between frames, we observe that stylistic changes can occur very rapidly close to the input images (for example, the transition from real to cartoon eyes in the third row of Fig. \ref{fig:teaser}). Thus in applications where the user would like to control the rate of particular changes, it can be helpful to specify a non-uniform interpolation schedule.
% Empirically, we find that rapid latents encoded from real images tend to be less stable, meaning that even small steps in latent space can yield images that appear very different from the original image. To counteract this effect, we schedule the interpolation coefficient so that steps in latent space are smaller close to the original images, which yields a more perceptually smooth sequence of intermediate images.

\paragraph{Adding motion}
Interpolation can be combined with affine transforms of the image in order to create the illusion of 2D or 3D motion (Fig. \ref{fig:zoom}). Before interpolating each pair of images, we can warp the latent of one of the images to achieve the desired transform.
\input{figs/d_zoom}
