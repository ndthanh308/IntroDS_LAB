\section{Limitations and Future Work}

\subsection*{Study Limitations}

\subsubsection*{\textbf{Limitations of Walkthrough Demonstration}}
While the experts were generally excited about the system, our expert interviews had certain limitations. The majority of the interview was based on a walkthrough demonstration of the AR interface, due to the limited time. Although this provided valuable insights into the system's utility, it did not evaluate the usability of the authoring flow of the system~\cite{ledo2018evaluation}. The experts briefly interacted with our system either through mobile AR (for in-person interviews) and/or desktop interfaces (for remote interviews), but a more comprehensive assessment of the authoring interface is necessary. Additionally, the experts were presented with a pre-defined math textbook and asked how they could incorporate it into their teaching. While this ensured that all experts were exposed to all system features, it would have been interesting to explore how the experts would utilize their own teaching materials.

\subsubsection*{\textbf{Real-World Deployment}}
Although the preliminary user evaluation and expert interviews suggest a potential for using \system{} in math education, deploying the system in actual teaching situations would offer further insights into its possibilities. Future work should examine which features instructors would use with their own teaching materials and whether they would discover other features that should be supported. Moreover, evaluating the system in an actual classroom setting with students would be valuable, observing how they interact with the system and exploring its potential benefits for their learning experience.




\subsection*{Improving Usability and Interaction}

\subsubsection*{\textbf{Supporting More Flexible Authoring Practices}}
In order to simplify the authoring process and enable non-technical users to create their own explorable explanations, the system relies on OCR and computer vision to automate as much of the process as possible. This includes automatically extracting math formulas and graphs. Although the system accurately detects most content, it occasionally fails.The system also automatically creates \textit{step-by-step hints} based on existing calculations. While most participants in our usability study appreciated these hints, P2 felt that there were too many steps to consume, asking for more flexible control to modify them. Moreover, E2 pointed out that the system should let users not only select from the presented equation but also directly and manually type a new equation to show on a graph.
This suggests the need for flexible authoring practice to customize the content for their own needs. Future implementations should allow users to manually input equations and graph boundaries. A detection confidence value can also be shown to inform users that they may have to adjust some things.

\subsubsection*{\textbf{Improving Interaction for Mobile AR}}
Although participants in the usability study found the AR system to be the most engaging, they rated the usability of the web system higher. Participants encountered difficulties interacting with the AR system due to various reasons, such as small text (P1, P9), shakiness of their hands (P5) and the device itself (P2, P10), and image detection issues (P3). Further work is needed to explore how AR interaction can be improved. For example, future work would explore different possibilities such as magnifying the selected content for better usability or enabling users to take snapshots of the content and interact with it flat on the table instead of directly in AR. Additionally, more work is needed to examine how AR information is presented to the user. For example, the content could be visualized outside the page instead of on top, or AR could be used to simplify the page so that only relevant information is visible.

% \subsubsection*{\textbf{Errors Mitigation}}
% To mitigate errors, future systems should also let the users manually input equations to bind them. The interaction would help with common soft-errors in graph detection such as incorrect scaling and position. This is especially important as the current detection system assume that there is a 1-to-1 scaling between the x- and y-axis. The detection confidence value can also be shown to inform users that they may have to adjust some things. Letting the users adjust scaling and bounding box will allow for the product of the system to be more consistent. 

\subsection*{Beyond Augmenting Math Textbooks}
\subsubsection*{\textbf{Adapting to Various Topics and Educational Contexts}}
Our approach has the potential to be applied in subjects beyond mathematics. In language education, for example, \textit{relationship highlight} and \textit{concrete examples} could be employed to connect abstract grammar rules with examples in the text, such as by highlighting subjects or commas in the text that pertain to the demonstrated rule. 
In social sciences, \textit{relationship highlight} could also be utilized to emphasize connections between different people and parties or dates and events. 
In music education, notes and songs on a page could be augmented with sound, enabling users to hear the tone or song. Our approach could also be used to enhance physics education by incorporating physics simulations, allowing users to interact with textbooks in more engaging ways. 

\subsubsection*{\textbf{Extensibility}}
Our system relies on computer algebra systems (CAS) like MathJS or SymPy, which are difficult to scale for more complex math. We expect that a different approach would be necessary to support broader topics. For example, an LLM-based approach like ChatGPT + Wolfram Alpha API or Googleâ€™s Minerva could be an exciting direction to integrate in the future.


\subsubsection*{\textbf{Integrating Other AR Interfaces}}
Finally, we are also interested in exploring other AR interfaces. For example, using projection mapping instead of mobile AR could enhance the teacher's live explanations by augmenting a whiteboard. This approach facilitates different affordances for collaborative learning experiences, enabling students to learn and explore with a group rather than individually. On the other hand, we are also interested in developing explorable explanations for immersive environments through mixed reality headsets. While our presented approach may not be directly applicable due to the lack of precision and resolution of the interaction, it instead opens up new opportunities for immersive explorable explanations beyond 2D interfaces. Future work should continue to investigate this exciting domain by leveraging advanced AR and machine learning techniques for the future of education.