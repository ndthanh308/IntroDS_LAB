% Figure environment removed

\section{\system{}: System and Design}

\subsection{Overview}
This section introduces \system{}, an authoring tool for AR-based explorable explanations. 
The system aims to empower non-technical users, such as students and instructors, to create interactive explanations without programming expertise. To achieve this, our system augments static math textbooks by embedding and overlaying interactive content.
The authoring workflow comprises the following steps: 1) \textit{scan}: users first scan a math textbook or handout with a camera, 2) \textit{extract}: the system automatically extracts math formulas and graphs shown in the document using OCR and computer vision, 3) \textit{select}: users select extracted content like symbols, values, equations, and graphs to make them interactive, 4) \textit{bind}: users bind selected elements together, 5) \textit{manipulate}: users manipulate the values and data of selected elements by dragging, and 6) \textit{update}: the system propagates changes responsively updates based on data binding and manipulation.
The system supports both mobile AR and desktop interfaces for making printed paper or scanned PDFs interactive, respectively.

\subsection{Scope} 
We largely focus our investigations around high-school level mathemetics based on the United States standard curriculum. Specifically, the primary topics are: algebra, trigonometry, geometry, and calculus.  \system{} does not have features such as complex illustration nor abstract equations to support higher level topics such as statistics probability and quantum-mecahnics. 

\subsection{Example Authoring Walkthrough}
In this section, we describe an example authoring and interaction walkthrough using our system. We use an example from a high-school calculus textbook (Single Variable Calculus~\cite{stewart2015single} P.39) that presents an equation, $y = x^2 + 6x + 10 = (x + 3)^2 + 1$, and its corresponding graph. The purpose of this augmentation is to visualize how values of $a$, $b$, $c$, and $n$ affect the graph of $y = (x - a)^{n} + b$. We describe how users can transform this static content into an explorable explanation using our system. 

\subsubsection*{\textbf{Step 1: Scan and Extract Math Textbook or Handout}}
The first step is to scan a printed document or PDF from an existing math textbook. After the user takes a photo to scan it, the system automatically extracts text, math formulas, and graphs using OCR and computer vision. In \autoref{fig:example-walkthrough}-1, math formulas captured by our system are shown as extracted content. Our system converts math equations to computer-readable LaTeX expressions like \verb|y = (x + 3)^{2} + 1|, enabling semantic understanding of the given math formula. OCR extracts written text and math formulas, while custom computer vision algorithms extract figures and graphs, allowing users to select and draw a graph overlaid on the existing figure. 

\subsubsection*{\textbf{Step 2: Select Equations and Bind them to Graphs}}
After scanning and extracting the document, users can author augmented content via mobile AR or desktop interfaces. 
To make the textbook interactive, users first select extracted values, symbols, equations, and graphs. 
When a user selects a graph, the system highlights the selection as illustrated in \autoref{fig:example-walkthrough}-1. 
The system automatically extracts the x-axis, y-axis, origin, and drawn graph line using computer vision.
When the user also selects the equation $y = (x + 3)^2 + 1$, the system automatically binds and draws a graph based on the selected equation (\autoref{fig:example-walkthrough}-2).
This AR-embedded graph enables dynamic manipulation and updating based on user interaction.
Users can also bind multiple equations to a single graph to visually compare equations by overlaying them. 

\subsubsection*{\textbf{Step 3: Drag to Change the Variable Values}}
Users can dynamically change values by dragging symbols or variables.
For example, in Figure~\ref{fig:example-walkthrough}-4, when the user drags the $3$ in the equation $y = (x + 3)^2 + 1$, the system automatically replaces the value of $3$, treating it as a dynamic variable. 
In Figure~\ref{fig:example-walkthrough}-7, users can specify values for variables like $x$ and $y$, displaying horizontal and vertical lines related to the current $x$ and $y$ values on the graph.
Changing a value alters the corresponding variable and equation based on dynamic calculation.

\subsubsection*{\textbf{Step 4: Enable Bi-Directional Binding between Variable and Graph}}
Changing a value prompts the system to update the graph dynamically. 
Figure~\ref{fig:example-walkthrough}-5 and -8 show how users can modify the graph plot of $(x + a)^n + b$ by dragging the graph or the variable values of $b$ and $n$, respectively.
For example, adjusting the $a$ value of $(x + a)^2 + b$ shifts the graph horizontally, while changing the $b$ moves it vertically. Bi-directional binding allows users to drag the graph, which in turn changes the corresponding variable value. 
This reactive feature facilitates user interaction with numerical values, graphs, and charts. By adjusting variables in a formula, users can observe their effects on the final output, allowing them to develop an intuition of abstract relationships, which are otherwise hard to understand.

\subsection{Supported Augmentation Features}
To facilitate diverse interactive explorations for high-school level mathematics, we have developed the following five augmentation techniques: 1) \textit{dynamic values}, 2) \textit{interactive figures}, 3) \textit{relationship highlights}, 4) \textit{concrete examples}, and 5) \textit{step-by-step hints}.
These features are designed to be automatically generated based on the extracted content, with the goal of encompassing a wide range of strategies identified through analysis. 

\subsubsection{\textbf{Dynamic Values}}
Dynamic values allow users to insert and manipulate concrete values for extracted symbols and variables found in the document. 
This feature is inspired by \textit{``strategy 1: exemplify through concrete values''} from our taxonomy analysis. 
For instance, Figure~\ref{fig:dynamic-value} demonstrates users setting and adjusting values of $h$, $k$, and $r$ in the equation $\sqrt{(x-h)^2 + (y-k)^2} = r^2$. 

% Figure environment removed

\noindent
Since the system processes mathematical equations as LaTeX expressions rather than plain text, it can semantically comprehend and dynamically compute equations based on the inserted values. 
Additionally, the system enables users to manipulate these values across various formulas throughout the document, generating responsive explanations that demonstrate how specific changes impact multiple equations through dynamic calculations. 
Dynamic values can be integrated with other features, such as interactive figures, which we discuss next.

\subsubsection{\textbf{Interactive Figures}}
Interactive figures offer users the opportunity to comprehend concepts through explorable visual representations. Unlike static images, these interactive figures promote intuitive understanding by allowing users to interact with them. 
This feature is inspired by \textit{``strategy 2: visualize through interactive and animated graphs''} from our taxonomy analysis. 

% Figure environment removed

\noindent
Users can make a graph interactive by selecting and binding equations to it, as described in the previous section. 
For instance, Figure~\ref{fig:interactive-figure} demonstrates how changing the value of $r$ dynamically affects the circle's radius in the graph accordingly. 

% Figure environment removed 

\noindent
Interactive figures also enhance the understanding of geometric concepts. 
For example, Figure~\ref{fig:interactive-triangle} shows how changing a variable in the equation $a^2 + b^2 = c^2$ updates the corresponding triangle shape, enabling users to grasp the geometric concept more effectively.
These interactive figures support bi-directional binding, allowing users to drag the graph or shape, which in turn updates the values accordingly.

\subsubsection{\textbf{Relationship Highlights}}
Relationship highlights enable users to visualize connections between different variables and visual references. 
This feature is inspired by \textit{``strategy 2: visualize through interactive and animated graphs''} from our taxonomy analysis. 
Relationship highlights can explicitly reveal the connection between variables and visual references,  facilitating intuitive comprehension for subjects like geometry or calculus.

% Figure environment removed

\noindent
For example, Figure~\ref{fig:relationship-highlights} shows the relationship highlights in the graph by holding the pen over $x$ to show the current values on the graph.
Similarly, when users hold over $a$ in the triangle example (Figure~\ref{fig:interactive-triangle}), the corresponding line is highlighted, showing which variable represents the associated visual reference in the figure and graphs. 

\subsubsection{\textbf{Concrete Examples}}
Concrete examples aid users by illustrating abstract concepts through specific instances. 
This feature is inspired by both \textit{``strategy 1: exemplify through concrete values''} and \textit{``strategy 3: guide through contextual hints or exercises''} from our taxonomy analysis.
By identifying operations such as summation, the system can present concrete examples to contextualize and break down abstract formulas. 

% Figure environment removed

\noindent
For instance, Figure~\ref{fig:concrete-examples} illustrates the user dragging the values of $20$ and $n$ in both $\sum_{i=1}^{20} i$ and $\sum_{i=1}^{n} a_i$. The system then exemplifies the formula by showing $1 + 2 + \cdots + n$ or $a_1 + a_2 + \cdots + a_n$.
Concrete examples provide users with explorable instances to enhance their understanding of abstract concepts. 

\subsubsection{\textbf{Step-by-Step Hints}}
Step-by-step hints offer contextual assistance by breaking down complex math problems or equations into a series of step-by-step instructions and solutions. 
This feature is inspired by \textit{``strategy 3: guide through contextual hints or exercises''} from our taxonomy analysis.
The system automatically computes the breakdown of a formula by performing arithmetic operations, simplifications, and decompositions.

% Figure environment removed

\noindent
For example, Figure~\ref{fig:step-by-step} demonstrates the user selecting an inequality $1.55192 t - 2734.55 > 400$ and then breaking it down into a series of step-by-step operations. 
Step-by-step hints are applicable to various equations and problems, such as solving quadratic equations like $x^2 - 7x + 10 = 0 \Rightarrow (x - 5) (x - 2) = 0 \Rightarrow x = 2, 5$. 
By decomposing and breaking down the equation through automated step-by-step instructions, users receive contextual feedback that enhances their understanding.



\subsection{Implementation}
Our system is implemented using WebAR interface that leverages A-Frame, 8th Wall, and HTML Canvas. 
For graph manipulation and symbolic computation, we employ the MathJS library.
For text and math formula extraction, we utilize Google Cloud, MathPix, and CnSTD OCR.
Finally, we develop a custom computer vision algorithm based on OpenCV for figure and graph extraction.
To enhance reproducibility, we make our source code publicly available as open-source~\footnote{\url{https://github.com/ucalgary-ilab/augmented-math}} and a desktop interface is accessible through a live demo link~\footnote{\url{https://ilab.ucalgary.ca/augmented-math}}.

\subsubsection{Math Formula Extraction}
To extract text and math formulas from the input document, we employ OCR techniques. 
We first apply Google Cloud OCR to detect all text and localize the position of each letter and word. 
Google Cloud OCR outputs plain text without appropriate math expressions, making it difficult to understand the mathematical content semantically. 
Therefore, we implement other techniques to convert the scanned document to the LaTeX expression with MathPix OCR~\footnote{\url{https://mathpix.com}}.
Since MathPix does not provide location information for each detected formula, we also employ CnSTD~\footnote{\url{https://github.com/breezedeus/CnSTD}}, an OCR toolkit based on PyTorch and MXNet, that can detect the accurate position of inline and independent line math formulas within the document. 
CnSTD math formula detection algorithm is trained with CnMFD Dataset~\footnote{\url{https://github.com/breezedeus/CnMFD_Dataset}} that contains various math formulas across 17,500 pages of documents. 
Upon localizing the math in the document, we compare the similarity between detected plain text and math formulas based on the position of the localized math equation, allowing us to accurately localize the position of each math expression and overlay it on the printed document. 

% Figure environment removed

\subsubsection{Figure and Graph Extraction}
Since OCR only enables the detection and extraction of textual information, we developed a custom computer vision algorithm to accurately localize the positions  of graphs and diagrams.
To achieve this, we first remove text and extract only  diagrams from the given document by using OpenCV contour line extraction. 
By setting the minimum length of the contour line length, we filter out text and extract only graphs and diagrams.
Once the figures are extracted, the system processes the contour line data to detect bounding boxes, x-axes, y-axes, origins, and graph paths. 
To identify appropriate x-y coordinates, we extract the longest horizontal and vertical lines in the given figure and use them as the x-axis and y-axis. We then use graph paths to identify the appropriate ratio for a given pixel value. 

\subsubsection{Authoring Interface and Document Tracking}
Our authoring interface is implemented using A-Frame, a WebAR framework based on JavaScript and HTML. 
Visual elements are rendered through an HTML Canvas element embedded as a dynamic texture of a plane object in the A-Frame scene. 
We use the Konva library for Canvas manipulation. 
The detected mathematical expressions are rendered using SVG with the MathJax library. 
Graphs and diagrams are dynamically rendered through a series of lines, with points computed using the MathJS~\footnote{\url{https://mathjs.org/}} symbolic computation engine. 
We also employ the MathJS library for step-by-step hints and concrete examples features. 
The overall interface is developed using JavaScript and the React.js framework.
For document tracking, we utilize 8th Wall's image tracking features~\footnote{\url{https://www.8thwall.com/}}, which provide more reliable tracking than alternatives like MindAR and AR.js.

\subsection{Technical Evaluation}
\subsubsection{Method}
To evaluate the accuracy of our pipeline, we collected 14 different textbooks which include 5 Algebra, 4 Trigonometry, 2 Geometry, and 3 Calculus textbooks. We selected 10 random pages from each of the textbooks for our sample. We performed our detection pipeline to a total of 140 pages of the collected samples and then check the results manually (as there is no standardized data set or method).
We measured the error rate for \textbf{textual} equation recognition (MathPix, CnSTD, Google OCR), as well as \textbf{visual} graph and geometry detection (OpenCV and Custom Detection).

\subsubsection{Results}
The results suggest that the math equation recognition works fairly well with 75\% correctness. These are often very minor errors such as and extra spaces and an extra newline. Among 140 pages, there are 63 pages with graphs and 20 pages with geometries, which makes up 59\% of all the samples. Out of these 83 image samples, graph detection was accurate 48 out of 63 times (76\%), while geometry detection was only accurate 8 out of 20 times (40\%). By investigating these results, we also noticed some error patterns. For graph detection, we noticed that decoration lines or tables are detected as false positives and multiple X-Y scale lines were detected as the X-Y axis. In addition, for geometry detection, the auxiliary lines often introduce the difficulty of the appropriate detection. In general, a visually cluttered textbook with a lot of colors, shapes, or visuals often generates many errors. 
%Based on this technical evaluation, we also expand the discussion about the current limitations and failure examples.


