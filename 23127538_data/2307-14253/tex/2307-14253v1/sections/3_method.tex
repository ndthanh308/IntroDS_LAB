\section{Sparse Double Descent and ViT}
% Figure environment removed
\begin{algorithm}[t]
\caption{Iterative algorithm to detect Sparse Double Descent.}
\label{Algo}
\begin{algorithmic}[1]
\Procedure{DETECT\_SDD ($\boldsymbol{w}^{\text{init}}$, $\Xi$, $\lambda$, $\zeta^{\text{iter}}$,$\zeta^{\text{end}}$)}{}
\State $\boldsymbol{w} \gets$ Train($\boldsymbol{w}^{\text{init}}$, $\Xi^{\text{train}}$, $\lambda$)\label{line:dense}
\State $p_{i-1} \gets $ Performance($\boldsymbol{w}$,$\Xi^{\text{val}}$)
\State prev\_increasing, prev\_decreasing, already\_increased, already\_decreased $\gets$ False
\State SDD $\gets$ False
\While{Sparsity($\boldsymbol{w}, \boldsymbol{w}^{\text{init}}$) $< \zeta^{end}$}\label{line:endcond}
\State $\boldsymbol{w} \gets$ Prune($\boldsymbol{w}$, $\zeta^{\text{iter}}$) \label{line:prune}
\State $\boldsymbol{w} \gets$ Train($\boldsymbol{w}$,$\Xi^{\text{train}}$, $\lambda$)\label{line:wd} 
\State $p_i \gets $ Performance($\boldsymbol{w}$,$\Xi^{\text{val}}$)
\If {($p_i < p_{i-1}$ {\bf and} already\_decreased {\bf and not} prev\_decreasing) {\bf or}\\~~~~~~~~~~~~($p_i > p_{i-1}$ {\bf and} already\_increased {\bf and not} prev\_increasing)}
    \State SDD $\gets$ True
\EndIf
\If {$p_i \neq p_{i-1}$}
\State prev\_decreasing $\gets p_i < p_{i-1}$; prev\_increasing $\gets p_i > p_{i-1}$
\State already\_decreasing $\gets$already\_decreasing {\bf or} $ p_i < p_{i-1}$
\State already\_increasing $\gets$already\_increasing {\bf or} $ p_i > p_{i-1}$
\State $ p_i \gets p_{i-1}$
\EndIf
\EndWhile
\State {\bf Return }SDD
\EndProcedure
\end{algorithmic}
\end{algorithm}
In this section, we will discuss the background for Double Descent and Sparse Double Descent, moving then to the potential impact on ViT architectures.

\noindent \textbf{Double descent.} It is known that when comparing a model performance (on unseen data) and model complexity, as the complexity grows (from right to left), we observe a first region where the performance improves (under-fitting - blue region in Fig.~\ref{fig:SDD}) and then, at some point, a trend inversion where the performance decreases while increasing the model's complexity (over-fitting). When exposed to real-world noisy data, however, neural networks tend to exhibit the DD phenomenon~\cite{Nakkiran2021Deep}: instead of being monotonous in that region, the performance inverts, at some point, its trend (critical region - orange in Fig.~\ref{fig:SDD}), and starts back decreasing (overfit region - green in Fig.~\ref{fig:SDD}).\\  
DD has been observed in regression tasks and successfully averted with optimally-tuned $\ell_2$ regularization~\cite{nakkiran2021optimal}. However, for classification tasks, this problem is not easily mitigated. It has been shown that the more challenging the dataset and classification task, the harder it is to avoid DD~\cite{qu√©tu2023avoid}. The authors in~\cite{Nakkiran2021Deep} demonstrate the DD not only depending on the model width but also depending on the number of epochs during training. Similarly to DD, an SDD phenomenon happens in the transition from the complex model toward the sparse, pruned model (as illustrated in Fig.~\ref{fig:SDD})~\cite{SparseDoubleDescent}. SDD has implications for model selection, regularization techniques, and understanding the behavior of complex models in high-dimensional settings, as the presence of SDD makes many criteria, like when to stop the pruning, unclear.\\
\noindent\textbf{Addressing the Sparse Double Descent}. We introduce here Alg.~\ref{Algo}, designed to demonstrate the eventual occurrence of the sparse double descent phenomenon. The algorithm begins by training the model on the learning task $\Xi$ for the first time, incorporating $\ell_2$ regularization weighted by $\lambda$ (line~\ref{line:dense}). Following this initial training step, a magnitude pruning stage is set up (line~\ref{line:prune}). Neural network pruning aims to reduce the size of a large network while maintaining its accuracy by removing irrelevant weights, filters, or other structures. As in \cite{SparseDoubleDescent}, we use in this algorithm an unstructured pruning method called magnitude-based pruning, popularized by~\cite{han2015learning}, in which a fixed amount of weights below some specific threshold, are pruned (line~\ref{line:prune}). Here, every time we prune, a fixed $\zeta^{\text{iter}}$ fraction of parameters from the model is removed.
We highlight that more complex pruning approaches exist, but magnitude-based pruning shows its competitiveness despite very low complexity~\cite{Gale_Magnitude}. The accuracy of the model typically decreases after pruning. To improve the performance of the model, we retrain it using the same original learning policy (line~\ref{line:wd}). Recent works have shown that this approach leads to the best performance at the highest sparsities~\cite{quetu2023dodging}. This approach allows us to determine whether a sparsely-parameterized model, starting from its initialization, has the potential to successfully learn a given target task. We end our pruning procedure once we reach a sparsity $\zeta^{\text{end}}$ (line~\ref{line:endcond}).

\noindent\textbf{ViT and Sparse Double Descent.} The number of parameters in ViT architectures is proportional to the model depth and quadratic function of the width. There is a tendency to scale these models even further, to increase their performance~\cite{dehghani2023scaling}, even though this is becoming very computationally expensive. Looking from that perspective, the understanding of the comportment of the ViT models becomes essential. Having a completely different learning architecture from other models, like CNNs, it is not easy to predict the behavior of ViT when pruning is applied. Our work addresses this issue and performs an extensive study with different levels of label noise and various model sparsity levels. In the next section, we will conduct a quantitative study on ViT, determining whether SDD is a real threat to ViT as it is to CNNs or not.
