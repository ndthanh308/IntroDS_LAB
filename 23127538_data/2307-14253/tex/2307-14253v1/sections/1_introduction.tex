\section{Introduction}
\let\svthefootnote\thefootnote
\newcommand\freefootnote[1]{%
  \let\thefootnote\relax%
  \footnotetext{#1}%
  \let\thefootnote\svthefootnote%
}
Deep\freefootnote{Article accepted for publication at the 22nd International Conference on Image Analysis and Processing (ICIAP23).} neural networks (DNNs) have revolutionized the field of computer vision by achieving state-of-the-art results in tasks such as segmentation~\cite{chaudhry2022lung}, classification~\cite{barbano2022two}, and object detection~\cite{mazzeo2022image}. DNNs outperform conventional machine learning algorithms on many visual recognition tasks as they can automatically learn feature representations from raw input~\cite{dosovitskiy2021an}. In addition, they can process a lot of data and generalize well to novel, unseen examples. For a long time, convolutional neural architectures (CNN) like VGG and ResNet models have been dominant in computer vision, thanks to their ability to learn, simultaneously, feature extraction (typically handled by convolutional layers) and classification (by multi-layer perceptrons, or in some cases even by convolutional layers themselves, like in ALL-CNN~\cite{SpringenbergDBR14}).\\ 
A new, deep architecture called Transformer has been pioneered by~\cite{vaswani2017attention}, and it has, at first, been conceived for natural language processing tasks~\cite{brown2020language}, resulting in a break-through for the community. Given its big potential, the computer vision world has recently begun to adopt it~\cite{Liu2021SwinTH}. Vision Transformers (ViT), which are Transformer architectures adapted for computer vision, quickly became state-of-the-art for many tasks, out of which we cite generative models~\cite{esser2021taming}. However, the lack of strong inductive biases causes them to be even more data-hungry than traditional CNN architectures, and this poses severe performance drops when noisy data are available to train such a model.\\
In image classification tasks, noisy labels are a frequent issue that can negatively impact the performance of deep learning models~\cite{sukhbaatar2014training}. Incorrect labels in the training data can mislead the model during the learning process and result in sub-optimal performance. Various approaches have been proposed to address this issue, including label smoothing, data augmentation, and robust loss functions~\cite{ma2020normalized}. The expected behavior, in such cases, is that the higher the noise in the data, the higher the overfit the model will suffer. As opposed to the traditional bias-variance trade-off, a phenomenon has been recently discovered, called Double Descent (DD)~\cite{Nakkiran2021Deep}. Namely, enlarging the model size in the over-fitting regime worsens the performance of an over-parametrized network; then, the trend reverses. DD represents an important challenge in finding the optimal set of parameters since it shows that it is possible to potentially improve generalization in an over-parametrized regime, but without real indicators on the best model's size to adopt. This behavior is observed in various architectures, stretching from machine learning models to DNNs, such as standard CNNs and ResNet~\cite{yilmaz2022regularization}. Analogously, a sparse double descent (SDD) phenomenon is observed when moving the model from an over-parametrized towards a sparser regime~\cite{SparseDoubleDescent}, via parameter pruning. \\
In this paper, we show that ViTs also suffer from the SDD phenomenon: besides the burden of the lack of an inductive bias that could help these models to generalize, the occurrence of SDD makes the performance even worse in intermediate compression regimes, when only a part of the parameters is removed. This is a possible explanation for the fact that typical ViT architectures can not be pruned to similar extreme rates as traditional CNNs~\cite{yu2022width}. However, contrarily to what is suggested for traditional CNNs~\cite{quetu2023dodging}, ViTs can avoid SDD with the optimal tuning of $\ell_2$ regularization, a result which was suggested by the theory~\cite{nakkiran2021optimal}. We postulate this is possible thanks to the lack of an inductive bias embedded in the architecture, which favors the strong regularization necessary to avoid SDD. Such a discovery enables back all the traditional compression mechanisms, having as a stop criterion a worsening in performance on the validation set. Everything, however, comes at a cost: we observe that optimally regularized models are significantly less compressible, due to the strong prior we impose to avoid SDD. %To summarize, here below you can find our key messages and contributions.
We summarize, here below, our key messages and contributions.
\begin{itemize}[nolistsep, noitemsep, topsep=-\parskip]
    \item To the best of our knowledge, this is the first paper raising concerns on the potential occurrence of the sparse double descent phenomenon in ViT models. Through this work, we compare the behavior of ViT and ResNet in the typically employed test scenarios~\cite{Nakkiran2021Deep}, also including a test on real annotated data (CIFAR-100N), observing SDD also on ViT.
    \item We propose a quantitative study over the $\ell_2$ regularization parameter, supported by the theory~\cite{nakkiran2021optimal} but already proven as inapplicable to traditional CNNs~\cite{qu√©tu2023avoid}. We observe that, in ViT models, avoiding SDD is possible with a properly tuned value for the regularization, which nicely imposes a strong prior on the model's parameters, impossible in traditional architectures suffering from inductive bias.
    \item We interestingly observe a trade-off between avoidance of SDD and compressibility of the model. More specifically, to avoid SDD (to employ typical pruning schemes with a stop criterion once the performance on a validation set worsens below some given threshold) we want to have a strong $\ell_2$ regularization, which however makes the model less compressible as a higher number of parameters will have a similar relevance. Depending on what we are targeting (high performance or high compressibility) we might want or not want to avoid SDD.
\end{itemize}