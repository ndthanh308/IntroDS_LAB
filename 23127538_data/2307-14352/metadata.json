{
  "title": "General Image-to-Image Translation with One-Shot Image Guidance",
  "authors": [
    "Bin Cheng",
    "Zuhao Liu",
    "Yunbo Peng",
    "Yue Lin"
  ],
  "submission_date": "2023-07-20T16:37:49+00:00",
  "revised_dates": [
    "2023-08-08T00:17:20+00:00",
    "2023-09-21T00:16:27+00:00"
  ],
  "abstract": "Large-scale text-to-image models pre-trained on massive text-image pairs show excellent performance in image synthesis recently. However, image can provide more intuitive visual concepts than plain text. People may ask: how can we integrate the desired visual concept into an existing image, such as our portrait? Current methods are inadequate in meeting this demand as they lack the ability to preserve content or translate visual concepts effectively. Inspired by this, we propose a novel framework named visual concept translator (VCT) with the ability to preserve content in the source image and translate the visual concepts guided by a single reference image. The proposed VCT contains a content-concept inversion (CCI) process to extract contents and concepts, and a content-concept fusion (CCF) process to gather the extracted information to obtain the target image. Given only one reference image, the proposed VCT can complete a wide range of general image-to-image translation tasks with excellent results. Extensive experiments are conducted to prove the superiority and effectiveness of the proposed methods. Codes are available at https://github.com/CrystalNeuro/visual-concept-translator.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14352",
  "pdf_url": null,
  "comment": "accepted by ICCV 2023",
  "num_versions": null,
  "size_before_bytes": 91444661,
  "size_after_bytes": 303022
}