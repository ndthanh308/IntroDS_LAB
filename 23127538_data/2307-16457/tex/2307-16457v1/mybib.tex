\begin{thebibliography}{0}
\bibitem{Recipes}
Roller, S., et al.: Recipes for Building an Open-Domain Chatbot. In: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 300-325 (2021)

\bibitem{GU2023EVA}
Gu, Y., et al.: Eva2. 0: Investigating open-domain chinese dialogue systems with large-scale pre-training. In: Machine Intelligence Research, 20(2), 207-219 (2023)

\bibitem{blenderbot3}
Shuster, et al.: Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage. In: arXiv preprint, arXiv:2208.03188 (2022)

\bibitem{Baheti2021Just}
Baheti, A., Sap, M., Ritter, A., Riedl, M.: Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts. In: Proceedings of EMNLP, pp. 4846-4862 (2021)

\bibitem{Rosenthal2021Offensive}
Rosenthal, S., Atanasova, P., Karadzhov, G., Zampieri, M., Nakov, P.: SOLID: A Large-Scale Semi-Supervised Dataset for Offensive Language Identification. In: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 915-928 (2021)

\bibitem{Hada2021Offensiveness}
Hada, R., Sudhir, S., Mishra, P., Yannakoudakis, H., Mohammad, S., Shutova, E.: Ruddit: Norms of Offensiveness for English Reddit Comments. In: ACL-IJCNLP, pp. 2700-2717 (2021)

\bibitem{Dinan2019Build}
Dinan, E., Humeau, S., Chintagunta, B., Weston, J.: Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack. In: EMNLP-IJCNLP, pp. 4537-4546 (2019)

\bibitem{Sun2021Safety}
Sun, H., et al.: On the Safety of Conversational Models: Taxonomy, Dataset, and Benchmark. In: Findings of the Association for Computational Linguistics: ACL 2022, pp. 3906-3923 (2022)

\bibitem{Dinan2022SafetyKit}
Dinan, E., Abercrombie, G., Bergman, A., Spruit, S. L., Hovy, D., Boureau, Y. L., Rieser, V.: SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems. In: ACL 2022, pp. 4113-4133 (2022)

\bibitem{Hartvigsen2022Hate}
Hartvigsen, T., Gabriel, S., Palangi, H., Sap, M., Ray, D., Kamar, E.: ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection. In: ACL 2022, pp. 3309-3326 (2022)

\bibitem{Lee2021Mental}
Lee, A., Kummerfeld, J. K., An, L., Mihalcea, R.: Micromodels for Efficient, Explainable, and Reusable Systems: A Case Study on Mental Health. In: Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 4257-4272 (2021)

\bibitem{li2023understanding}
Li, A., Ma, L., Mei, Y., He, H., Zhang, S., Qiu, H., Lan, Z.: Understanding Client Reactions in Online Mental Health Counseling. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, pp. 10358-10376 (2023)


\bibitem{APA2002Principles}
American Psychological Association.: Ethical principles of psychologists and code of conduct. In: American psychologist, 57(12), pp. 1060-1073 (2002)

\bibitem{Gros2022Robots}
Gros, D., Li, Y., Yu, Z.: Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 3266-3284 (2022)

\bibitem{Thoppilan2022Lamda}
Thoppilan, R., et al.: Lamda: Language models for dialog applications. In: arXiv, preprint arXiv:2201.08239 (2022)

\bibitem{Fleiss1971Raters}
Fleiss, J. L.: Measuring nominal scale agreement among many raters. In: Psychological bulletin, 76(5), 378 (1971)

\bibitem{bert2018}
Devlin, J., Chang, M. W., Lee, K., Toutanova, K.: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186 (2019)

\bibitem{roberta2019}
Liu, Y., et al.: Roberta: A robustly optimized bert pretraining approach. In: arXiv, preprint arXiv:1907.11692 (2019)

\end{thebibliography}