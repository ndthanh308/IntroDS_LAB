% Generated by IEEEtranS.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranS.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{CACTI}
\BIBentryALTinterwordspacing
Cacti. [Online]. Available: \url{http://www.hpl.hp.com/research/cacti/}
\BIBentrySTDinterwordspacing

\bibitem{Tesseract}
J.~Ahn, S.~Hong, S.~Yoo, O.~Mutlu, and K.~Choi, ``A scalable processing-in-memory accelerator for parallel graph processing,'' in \emph{Proceedings of the 42nd Annual International Symposium on Computer Architecture}, 2015, pp. 105--117.

\bibitem{A2N}
T.~Bansal, D.-C. Juan, S.~Ravi, and A.~McCallum, ``A2n: Attending to neighbors for knowledge graph inference,'' in \emph{Proceedings of the 57th annual meeting of the association for computational linguistics}, 2019, pp. 4387--4392.

\bibitem{GNNMark}
T.~Baruah, K.~Shivdikar, S.~Dong \emph{et~al.}, ``Gnnmark: A benchmark suite to characterize graph neural network training on gpus,'' in \emph{2021 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 2021, pp. 13--23.

\bibitem{in_depth_concurrency_analysis}
M.~Besta and T.~Hoefler, ``Parallel and distributed graph neural networks: An in-depth concurrency analysis,'' \emph{arXiv preprint arXiv:2205.09702}, 2022.

\bibitem{workloadbalance}
\BIBentryALTinterwordspacing
R.~D. Blumofe and C.~E. Leiserson, ``Scheduling multithreaded computations by work stealing,'' \emph{J. ACM}, vol.~46, no.~5, p. 720–748, sep 1999. [Online]. Available: \url{https://doi.org/10.1145/324133.324234}
\BIBentrySTDinterwordspacing

\bibitem{ReGNN}
C.~Chen, K.~Li, Y.~Li, and X.~Zou, ``Regnn: A redundancy-eliminated graph neural networks accelerator,'' in \emph{2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, 2022, pp. 429--443.

\bibitem{MetaNMP}
\BIBentryALTinterwordspacing
D.~Chen, H.~He, H.~Jin \emph{et~al.}, ``Metanmp: Leveraging cartesian-like product to accelerate hgnns with near-memory processing,'' in \emph{Proceedings of the 50th Annual International Symposium on Computer Architecture}, ser. ISCA '23.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2023. [Online]. Available: \url{https://doi.org/10.1145/3579371.3589091}
\BIBentrySTDinterwordspacing

\bibitem{chen2017task}
T.~Chen and Y.~Sun, ``Task-guided and path-augmented heterogeneous network embedding for author identification,'' in \emph{Proceedings of the tenth ACM international conference on web search and data mining}, 2017, pp. 295--304.

\bibitem{hgnn_survey_tangjie}
Y.~Dong, Z.~Hu, K.~Wang, Y.~Sun, and J.~Tang, ``Heterogeneous network representation learning.'' in \emph{IJCAI}, vol.~20, 2020, pp. 4861--4867.

\bibitem{fan2019metapath}
S.~Fan, J.~Zhu, X.~Han \emph{et~al.}, ``Metapath-guided heterogeneous graph neural network for intent recommendation,'' in \emph{Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining}, 2019, pp. 2478--2486.

\bibitem{PyG}
M.~Fey and J.~E. Lenssen, ``Fast graph representation learning with {PyTorch Geometric},'' in \emph{ICLR Workshop on Representation Learning on Graphs and Manifolds}, 2019.

\bibitem{MAGNN}
X.~Fu, J.~Zhang, Z.~Meng, and I.~King, ``Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding,'' in \emph{Proceedings of The Web Conference 2020}, 2020, pp. 2331--2341.

\bibitem{GNN_dataflow_taxonomy}
R.~Garg, E.~Qin, F.~Muñoz-Matrínez, R.~Guirado, A.~Jain, S.~Abadal, J.~L. Abellán, M.~E. Acacio, E.~Alarcón, S.~Rajamanickam, and T.~Krishna, ``Understanding the design-space of sparse/dense multiphase gnn dataflows on spatial accelerators,'' in \emph{2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 2022, pp. 571--582.

\bibitem{awbgcn}
T.~Geng, A.~Li, R.~Shi \emph{et~al.}, ``Awb-gcn: A graph convolutional network accelerator with runtime workload rebalancing,'' in \emph{2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 2020, pp. 922--936.

\bibitem{igcn}
\BIBentryALTinterwordspacing
T.~Geng, C.~Wu, Y.~Zhang \emph{et~al.}, ``I-gcn: A graph convolutional network accelerator with runtime locality enhancement through islandization,'' in \emph{MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture}, ser. MICRO '21.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2021, p. 1051–1063. [Online]. Available: \url{https://doi.org/10.1145/3466752.3480113}
\BIBentrySTDinterwordspacing

\bibitem{HGL}
Y.~Gui, Y.~Wu, H.~Yang \emph{et~al.}, ``Hgl: Accelerating heterogeneous gnn training with holistic representation and optimization,'' in \emph{SC22: International Conference for High Performance Computing, Networking, Storage and Analysis}, 2022, pp. 1--15.

\bibitem{characterize_gnn_accelerators}
R.~Guirado, A.~Jain, S.~Abadal, and E.~Alarcón, ``Characterizing the communication requirements of gnn accelerators: A model-based approach,'' in \emph{2021 IEEE International Symposium on Circuits and Systems (ISCAS)}, 2021, pp. 1--5.

\bibitem{Graphicionado}
T.~J. Ham, L.~Wu, N.~Sundaram, N.~Satish, and M.~Martonosi, ``Graphicionado: {{A}} high-performance and energy-efficient accelerator for graph analytics,'' in \emph{2016 49th {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}} ({{MICRO}})}, Oct. 2016, pp. 1--13.

\bibitem{FTW-GAT}
Z.~He, T.~Tian, Q.~Wu, and X.~Jin, ``Ftw-gat: An fpga-based accelerator for graph attention networks with ternary weights,'' \emph{IEEE Transactions on Circuits and Systems II: Express Briefs}, pp. 1--1, 2023.

\bibitem{NTGAT}
\BIBentryALTinterwordspacing
W.~Hou, K.~Zhong, S.~Zeng, G.~Dai, H.~Yang, and Y.~Wang, ``Ntgat: A graph attention network accelerator with runtime node tailoring,'' in \emph{Proceedings of the 28th Asia and South Pacific Design Automation Conference}, ser. ASPDAC '23.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2023, p. 645–650. [Online]. Available: \url{https://doi.org/10.1145/3566097.3567869}
\BIBentrySTDinterwordspacing

\bibitem{understand_and_bridge}
\BIBentryALTinterwordspacing
K.~Huang, J.~Zhai, Z.~Zheng, Y.~Yi, and X.~Shen, ``Understanding and bridging the gaps in current gnn performance optimizations,'' in \emph{Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming}, ser. PPoPP '21.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2021, p. 119–132. [Online]. Available: \url{https://doi.org/10.1145/3437801.3441585}
\BIBentrySTDinterwordspacing

\bibitem{REFLIP-HUAKE}
\BIBentryALTinterwordspacing
Y.~Huang, L.~Zheng, P.~Yao \emph{et~al.}, ``Accelerating graph convolutional networks using crossbar-based processing-in-memory architectures,'' in \emph{{IEEE} International Symposium on High-Performance Computer Architecture, {HPCA} 2022, Seoul, South Korea, April 2-6, 2022}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2022, pp. 1029--1042. [Online]. Available: \url{https://doi.org/10.1109/HPCA53966.2022.00079}
\BIBentrySTDinterwordspacing

\bibitem{GROW}
\BIBentryALTinterwordspacing
R.~Hwang, M.~Kang, J.~Lee, D.~Kam, Y.~Lee, and M.~Rhu, ``{GROW:} {A} row-stationary sparse-dense {GEMM} accelerator for memory-efficient graph convolutional neural networks,'' in \emph{{IEEE} International Symposium on High-Performance Computer Architecture, {HPCA} 2023, Montreal, QC, Canada, February 25 - March 1, 2023}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2023, pp. 42--55. [Online]. Available: \url{https://doi.org/10.1109/HPCA56546.2023.10070983}
\BIBentrySTDinterwordspacing

\bibitem{TPU}
N.~P. Jouppi, C.~Young, N.~Patil \emph{et~al.}, ``In-datacenter performance analysis of a tensor processing unit,'' in \emph{Proceedings of the 44th Annual International Symposium on Computer Architecture}, ser. {ISCA} '17.\hskip 1em plus 0.5em minus 0.4em\relax {ACM}, pp. 1--12.

\bibitem{ramulator}
Y.~Kim, W.~Yang, and O.~Mutlu, ``Ramulator: A fast and extensible dram simulator,'' \emph{IEEE Computer architecture letters}, vol.~15, no.~1, pp. 45--49, 2015.

\bibitem{GRIP}
K.~Kiningham, P.~Levis, and C.~Ré, ``Grip: A graph neural network accelerator architecture,'' \emph{IEEE Transactions on Computers}, vol.~72, no.~4, pp. 914--925, 2023.

\bibitem{GCN}
\BIBentryALTinterwordspacing
T.~N. Kipf and M.~Welling, ``Semi-supervised classification with graph convolutional networks,'' in \emph{International Conference on Learning Representations, {ICLR} 2017}, 2017. [Online]. Available: \url{https://openreview.net/forum?id=SJU4ayYgl}
\BIBentrySTDinterwordspacing

\bibitem{li2022disentangled}
A.~Li, Z.~Cheng, F.~Liu, Z.~Gao, W.~Guan, and Y.~Peng, ``Disentangled graph neural networks for session-based recommendation,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, 2022.

\bibitem{GCN_Bidirectional_Fusion}
H.~Li, M.~Yan, X.~Yang \emph{et~al.}, ``Hardware acceleration for gcns via bidirectional fusion,'' \emph{IEEE Computer Architecture Letters}, vol.~20, no.~1, pp. 66--4, 2021.

\bibitem{GCNAX}
\BIBentryALTinterwordspacing
J.~Li, A.~Louri, A.~Karanth, and R.~C. Bunescu, ``{GCNAX:} {A} flexible and energy-efficient accelerator for graph convolutional neural networks,'' in \emph{{IEEE} International Symposium on High-Performance Computer Architecture, {HPCA} 2021, Seoul, South Korea, February 27 - March 3, 2021}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2021, pp. 775--788. [Online]. Available: \url{https://doi.org/10.1109/HPCA51647.2021.00070}
\BIBentrySTDinterwordspacing

\bibitem{Hyperscale}
\BIBentryALTinterwordspacing
S.~Li, D.~Niu, Y.~Wang \emph{et~al.}, ``Hyperscale fpga-as-a-service architecture for large-scale distributed graph neural network,'' in \emph{Proceedings of the 49th Annual International Symposium on Computer Architecture}, ser. ISCA '22.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2022, p. 946–961. [Online]. Available: \url{https://doi.org/10.1145/3470496.3527439}
\BIBentrySTDinterwordspacing

\bibitem{EnGN}
S.~Liang, Y.~Wang, C.~Liu \emph{et~al.}, ``Engn: A high-throughput and energy-efficient accelerator for large graph neural networks,'' \emph{IEEE Trans. Comput.}, vol.~70, no.~9, p. 1511–1525, sep 2021.

\bibitem{understand_distributed_gnn}
H.~Lin, M.~Yan, X.~Yang \emph{et~al.}, ``Characterizing and understanding distributed gnn training on gpus,'' \emph{IEEE Computer Architecture Letters}, vol.~21, no.~1, pp. 21--24, 2022.

\bibitem{Comprehensive_Survey_GNN_Distributed_Training}
H.~Lin, M.~Yan, X.~Ye \emph{et~al.}, ``A comprehensive survey on distributed training of graph neural networks,'' \emph{arXiv preprint arXiv:2211.05368}, 2022.

\bibitem{gpu_drawback}
E.~Lindholm, J.~Nickolls, S.~Oberman, and J.~Montrym, ``Nvidia tesla: A unified graphics and computing architecture,'' \emph{IEEE micro}, vol.~28, no.~2, pp. 39--55, 2008.

\bibitem{ReGNN-HUAKE}
\BIBentryALTinterwordspacing
C.~Liu, H.~Liu, H.~Jin \emph{et~al.}, ``Regnn: a reram-based heterogeneous architecture for general graph neural networks,'' in \emph{{DAC} '22: 59th {ACM/IEEE} Design Automation Conference, San Francisco, California, USA, July 10 - 14, 2022}, R.~Oshana, Ed.\hskip 1em plus 0.5em minus 0.4em\relax {ACM}, 2022, pp. 469--474. [Online]. Available: \url{https://doi.org/10.1145/3489517.3530479}
\BIBentrySTDinterwordspacing

\bibitem{liu2018heterogeneous}
Z.~Liu, C.~Chen, X.~Yang, J.~Zhou, X.~Li, and L.~Song, ``Heterogeneous graph neural networks for malicious account detection,'' in \emph{Proceedings of the 27th ACM international conference on information and knowledge management}, 2018, pp. 2077--2085.

\bibitem{luo2021imas}
F.~Luo, Y.~Zhang, and X.~Wang, ``Imas++ an intelligent medical analysis system enhanced with deep graph neural networks,'' in \emph{Proceedings of the 30th ACM International Conference on Information \& Knowledge Management}, 2021, pp. 4754--4758.

\bibitem{Simple-HGN}
Q.~Lv, M.~Ding, Q.~Liu \emph{et~al.}, ``Are we really making much progress? revisiting, benchmarking and refining heterogeneous graph neural networks,'' in \emph{Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining}, 2021, pp. 1150--1160.

\bibitem{mao2020item}
K.~Mao, X.~Xiao, J.~Zhu, B.~Lu, R.~Tang, and X.~He, ``Item tagging for information retrieval: a tripartite graph neural network based approach,'' in \emph{Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval}, 2020, pp. 2327--2336.

\bibitem{niu2020dual}
X.~Niu, B.~Li, C.~Li \emph{et~al.}, ``A dual heterogeneous graph attention network to improve long-tail performance for shop search in e-commerce,'' in \emph{Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining}, 2020, pp. 3405--3415.

\bibitem{oh2018knowledge}
B.~Oh, S.~Seo, and K.-H. Lee, ``Knowledge graph completion by context-aware convolutional learning with multi-hop neighborhoods,'' in \emph{Proceedings of the 27th ACM International Conference on Information and Knowledge Management}, 2018, pp. 257--266.

\bibitem{ozdal_energy_2016}
M.~M. Ozdal, S.~Yesil, T.~Kim \emph{et~al.}, ``Energy efficient architecture for graph analytics accelerators,'' in \emph{2016 {ACM}/{IEEE} 43rd Annual International Symposium on Computer Architecture ({ISCA})}, pp. 166--177.

\bibitem{7pj}
M.~O’Connor, ``Highlights of the high-bandwidth memory (hbm) standard,'' in \emph{Memory forum workshop}, vol.~3, 2014.

\bibitem{FlowGNN}
R.~Sarkar, S.~Abi-Karam, Y.~He, L.~Sathidevi, and C.~Hao, ``Flowgnn: A dataflow architecture for real-time workload-agnostic graph neural network inference,'' in \emph{2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}.\hskip 1em plus 0.5em minus 0.4em\relax Los Alamitos, CA, USA: IEEE Computer Society, mar 2023, pp. 1099--1112.

\bibitem{R-GCN}
M.~Schlichtkrull, T.~N. Kipf, P.~Bloem, R.~v.~d. Berg, I.~Titov, and M.~Welling, ``Modeling relational data with graph convolutional networks,'' in \emph{European semantic web conference}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2018, pp. 593--607.

\bibitem{HG_survey}
C.~Shi, Y.~Li, J.~Zhang, Y.~Sun, and S.~Y. Philip, ``A survey of heterogeneous information network analysis,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, vol.~29, no.~1, pp. 17--37, 2016.

\bibitem{socher2013reasoning}
R.~Socher, D.~Chen, C.~D. Manning, and A.~Ng, ``Reasoning with neural tensor networks for knowledge base completion,'' \emph{Advances in neural information processing systems}, vol.~26, 2013.

\bibitem{GraphR}
L.~Song, Y.~Zhuo, X.~Qian, H.~Li, and Y.~Chen, ``Graphr: Accelerating graph processing using reram,'' in \emph{2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 531--543.

\bibitem{MultiGCN}
G.~Sun, M.~Yan, D.~Wang \emph{et~al.}, ``Multi-node acceleration for large-scale gcns,'' \emph{IEEE Transactions on Computers}, vol.~71, no.~12, pp. 3140--3152, 2022.

\bibitem{sun2012mining}
Y.~Sun and J.~Han, ``Mining heterogeneous information networks: principles and methodologies,'' \emph{Synthesis Lectures on Data Mining and Knowledge Discovery}, vol.~3, no.~2, pp. 1--159, 2012.

\bibitem{sun2011pathsim}
Y.~Sun, J.~Han, X.~Yan, P.~S. Yu, and T.~Wu, ``Pathsim: Meta path-based top-k similarity search in heterogeneous information networks,'' \emph{Proceedings of the VLDB Endowment}, vol.~4, no.~11, pp. 992--1003, 2011.

\bibitem{tajeuna2018modeling}
E.~G. Tajeuna, M.~Bouguessa, and S.~Wang, ``Modeling and predicting community structure changes in time-evolving social networks,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, vol.~31, no.~6, pp. 1166--1180, 2018.

\bibitem{CompGCN}
\BIBentryALTinterwordspacing
S.~Vashishth, S.~Sanyal, V.~Nitin, and P.~Talukdar, ``Composition-based multi-relational graph convolutional networks,'' in \emph{International Conference on Learning Representations}, 2020. [Online]. Available: \url{https://openreview.net/forum?id=BylA_C4tPr}
\BIBentrySTDinterwordspacing

\bibitem{GAT}
\BIBentryALTinterwordspacing
P.~Veli{\v{c}}kovi{\'{c}}, G.~Cucurull, A.~Casanova, A.~Romero, P.~Li{\`{o}}, and Y.~Bengio, ``{Graph Attention Networks},'' \emph{International Conference on Learning Representations, {ICLR} 2018}, 2018. [Online]. Available: \url{https://openreview.net/forum?id=rJXMpikCZ}
\BIBentrySTDinterwordspacing

\bibitem{technology_scale}
O.~{Villa}, D.~R. {Johnson}, M.~{Oconnor} \emph{et~al.}, ``Scaling the power wall: A path to exascale,'' in \emph{SC '14: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, Nov 2014, pp. 830--841.

\bibitem{R-GAT}
K.~Wang, W.~Shen, Y.~Yang, X.~Quan, and R.~Wang, ``Relational graph attention network for aspect-based sentiment analysis,'' in \emph{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, 2020, pp. 3229--3238.

\bibitem{DGL}
M.~Y. Wang, ``Deep graph library: Towards efficient and scalable deep learning on graphs,'' in \emph{ICLR workshop on representation learning on graphs and manifolds}, 2019.

\bibitem{M2GNN}
S.~Wang, X.~Wei, C.~N. Nogueira~dos Santos \emph{et~al.}, ``Mixed-curvature multi-relational graph neural network for knowledge graph completion,'' in \emph{Proceedings of the Web Conference 2021}, 2021, pp. 1761--1771.

\bibitem{hgnn_survey_shichuan}
X.~Wang, D.~Bo, C.~Shi, S.~Fan, Y.~Ye, and P.~S. Yu, ``A survey on heterogeneous graph embedding: methods, techniques, applications and sources,'' \emph{arXiv preprint arXiv:2011.14867}, 2020.

\bibitem{HAN}
X.~Wang, H.~Ji, C.~Shi \emph{et~al.}, ``Heterogeneous graph attention network,'' in \emph{The world wide web conference}, 2019, pp. 2022--2032.

\bibitem{analysis_of_bottlenecks}
\BIBentryALTinterwordspacing
Z.~Wang, Y.~Wang, C.~Yuan, R.~Gu, and Y.~Huang, ``Empirical analysis of performance bottlenecks in graph neural network training and inference with gpus,'' \emph{Neurocomputing}, vol. 446, pp. 165--191, 2021. [Online]. Available: \url{https://www.sciencedirect.com/science/article/pii/S0925231221003659}
\BIBentrySTDinterwordspacing

\bibitem{comprehensive_gnn_survey}
Z.~Wu, S.~Pan, F.~Chen, G.~Long, C.~Zhang, and S.~Y. Philip, ``A comprehensive survey on graph neural networks,'' \emph{IEEE transactions on neural networks and learning systems}, vol.~32, no.~1, pp. 4--24, 2020.

\bibitem{understand_GCN}
M.~Yan, Z.~Chen, L.~Deng \emph{et~al.}, ``Characterizing and understanding gcns on gpu,'' \emph{IEEE Computer Architecture Letters}, vol.~19, no.~1, pp. 22--25, 2020.

\bibitem{HyGCN}
M.~Yan, L.~Deng, X.~Hu \emph{et~al.}, ``Hygcn: A gcn accelerator with hybrid architecture,'' in \emph{2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 15--29.

\bibitem{GraphDynS}
\BIBentryALTinterwordspacing
M.~Yan, X.~Hu, S.~Li \emph{et~al.}, ``Alleviating irregularity in graph analytics acceleration: A hardware/software co-design approach,'' in \emph{Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture}, ser. MICRO '52.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: Association for Computing Machinery, 2019, p. 615–628. [Online]. Available: \url{https://doi.org/10.1145/3352460.3358318}
\BIBentrySTDinterwordspacing

\bibitem{understand_HGNN}
M.~Yan, M.~Zou, X.~Yang \emph{et~al.}, ``Characterizing and understanding hgnns on gpus,'' \emph{IEEE Computer Architecture Letters}, vol.~21, no.~2, pp. 69--72, 2022.

\bibitem{FPGAN}
W.~Yan, W.~Tong, and X.~Zhi, ``Fpgan: An fpga accelerator for graph attention networks with software and hardware co-optimization,'' \emph{IEEE Access}, vol.~8, pp. 171\,608--171\,620, 2020.

\bibitem{hgnn_survey_hanjiawei}
C.~Yang, Y.~Xiao, Y.~Zhang, Y.~Sun, and J.~Han, ``Heterogeneous network representation learning: A unified framework with survey and benchmark,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, 2020.

\bibitem{SeHGNN}
X.~Yang, M.~Yan, S.~Pan, X.~Ye, and D.~Fan, ``Simple and efficient heterogeneous graph neural network,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, vol.~37, 2023.

\bibitem{yasunaga2019scisummnet}
M.~Yasunaga, J.~Kasai, R.~Zhang \emph{et~al.}, ``Scisummnet: A large annotated corpus and content-impact models for scientific paper summarization with citation networks,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, vol.~33, no.~01, 2019, pp. 7386--7393.

\bibitem{SGCN}
\BIBentryALTinterwordspacing
M.~Yoo, J.~Song, J.~Lee, N.~Kim, Y.~Kim, and J.~Lee, ``Sgcn: Exploiting compressed-sparse features in deep graph convolutional network accelerators,'' in \emph{2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}.\hskip 1em plus 0.5em minus 0.4em\relax Los Alamitos, CA, USA: IEEE Computer Society, mar 2023, pp. 1--14. [Online]. Available: \url{https://doi.ieeecomputersociety.org/10.1109/HPCA56546.2023.10071102}
\BIBentrySTDinterwordspacing

\bibitem{GCoD}
H.~You, T.~Geng, Y.~Zhang, A.~Li, and Y.~Lin, ``Gcod: Graph convolutional network acceleration via dedicated algorithm and accelerator co-design,'' in \emph{2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, 2022, pp. 460--474.

\bibitem{understand_gnn_computational_graph}
H.~Zhang, Z.~Yu, G.~Dai \emph{et~al.}, ``Understanding gnn computational graph: A coordinated computation, io, and memory perspective,'' 2021.

\bibitem{zhang2019iteratively}
W.~Zhang, B.~Paudel, L.~Wang \emph{et~al.}, ``Iteratively learning embeddings and rules for knowledge graph reasoning,'' in \emph{The World Wide Web Conference}, 2019, pp. 2366--2377.

\bibitem{DNNBuilder}
X.~Zhang, J.~Wang, C.~Zhu \emph{et~al.}, ``Dnnbuilder: an automated tool for building high-performance dnn hardware accelerators for fpgas,'' in \emph{2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}, 2018, pp. 1--8.

\bibitem{hgnn_survey_shiruipan}
X.~Zheng, Y.~Liu, S.~Pan, M.~Zhang, D.~Jin, and P.~S. Yu, ``Graph neural networks for graphs with heterophily: A survey,'' \emph{arXiv preprint arXiv:2202.07082}, 2022.

\bibitem{zheng2020clustering}
Y.~Zheng, R.~Hu, S.-f. Fung \emph{et~al.}, ``Clustering social audiences in business information networks,'' \emph{Pattern Recognition}, vol. 100, p. 107126, 2020.

\bibitem{zhou2015cross}
X.~Zhou, X.~Liang, H.~Zhang, and Y.~Ma, ``Cross-platform identification of anonymous identical users in multiple social media networks,'' \emph{IEEE transactions on knowledge and data engineering}, vol.~28, no.~2, pp. 411--424, 2015.

\end{thebibliography}
