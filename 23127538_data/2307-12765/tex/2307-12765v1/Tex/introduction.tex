% \todo{
%%全文图字体、大小统一
%%修改实验章节数据以及命名
%%全文图风格统一
%% 引用加染色


%% 4.1.1一句话写技术核心，对原有阶段进行划分和重组，将不同bound的部分进行融合，从而两种硬件资源的利用率都能得到提升  √
%% 先写技术核心，再写技术细节，技术核心写的时候配上key idea和最直接的效果，两三行字  √
%% Fig.5讨论  √
%% 编程模型FP_task_list修改  √
%% 去掉编程模型关于RAB的内容  √
%% 可编程性的体现 √
%% Fig.5 给出了一个实例说明相对于传统模型的优势 √
%% hardware datapath 部分一半编程模型一半硬件，目的是两者的绑定，数据流动说一下  √
%% 逻辑 / 语句 润色 


%% 实验部分：补充FP-buf根据顶点总入度比例分配固定区域的机制，否则Fig 14横坐标比例为1时解释不通

%% 4.2.1缺少总分的几句话，先告诉大家motivation: NA阶段的执行时间长 / NA阶段的执行时间和子图数量成正比 / 凸显independency √
%% 模块之间的协调 / 模块之间的数据流动  / 负载的分配  /  控制  /  逻辑优化 √
%% 怎么利用 independency √
%% 画一个半栏图  左边是multi-lane设计， 右边是负载均衡的流程，凸显怎么检测到需要负载均衡，和怎么做 √
%% off-chip 改DRAM √


%% similarity-aware的方法，edge-cut的方式适合分层级的cache结构
% }

\section{Introduction}\label{sec:intro}


\IEEEPARstart{M}{any} real-world data in complex systems are naturally represented as heterogeneous graphs (HetGs), which possess not only structural information but also rich semantic information~\cite{HG_survey}.
HetGs consist of multiple types of entities and relations which are embodied by various types of vertices and edges, respectively.
This is the major difference of that with homogeneous graphs (HomoGs), which contain only a single type of vertices and edges and thus only represent structural information.
Due to the powerful representation ability of HetG, it has been widely adopted in many critical fields such as knowledge graph~\cite{oh2018knowledge, socher2013reasoning, zhang2019iteratively, chen2017task}, social network~\cite{yasunaga2019scisummnet,zhou2015cross,tajeuna2018modeling,zheng2020clustering}, and many others.


%Take the DBLP citation network as an example of HetG.
%It includes several types of vertices (e.g., Paper (P), Author (A), and Venue (V)), as well as many relations with different semantic meanings, such as Author$\xrightarrow{\rm writes}$Paper, Paper$\xrightarrow{\rm cites}$Paper, Paper$\xrightarrow{\rm publishes~in}$Venue (abbreviated as AP, PP, and PV).

Heterogeneous graph neural networks (HGNNs) originate from the insufficiency of using graph neural networks (GNNs) to process HetGs' semantic information.
%Designed for HomoGs to capture their structural rather than semantic information, GNNs follow a neighborhood aggregation scheme, where the representation embedding vector of each vertex is computed by recursively aggregating the feature vectors of neighboring vertices~\cite{GCN,comprehensive_gnn_survey}.
Designed for HomoGs to capture their structural rather than semantic information, GNNs recursively aggregate the feature vectors of neighboring vertices~\cite{GCN,comprehensive_gnn_survey,Comprehensive_Survey_GNN_Distributed_Training} to generate the final embedding vector for each vertex.
In contrast, HGNNs use a different execution semantic to capture both pieces of information.
They usually can be partitioned into four major execution stages~\cite{R-GCN,R-GAT,HAN,Simple-HGN,SeHGNN}:
\blackcircledempty{1} \textit{Semantic Graph Build} (SGB) stage partitions the original HetG into several semantic graphs; 
\blackcircledempty{2} \textit{Feature Projection} (FP) stage transforms the feature vector of each vertex in each semantic graph to a new one using a multi-layer perceptron (MLP); 
\blackcircledempty{3} \textit{Neighbor Aggregation} (NA) stage aggregates features from neighbors for each vertex in each semantic graph; 
\blackcircledempty{4} \textit{Semantic Fusion} (SF) stage fuses semantic information revealed by all semantic graphs, i.e., fuses the results of the NA stage across different semantic graphs for each vertex.
%They first partition the graph into semantic graphs, then apply an independent GNN module on each semantic graph, and finally fuse the results of all semantic graphs to get the final output.
HGNNs have achieved excellent prediction accuracy in the processing of HetG and become at the heart of a broad range of critical fields~\cite{hgnn_survey_tangjie,hgnn_survey_hanjiawei,hgnn_survey_shichuan,hgnn_survey_shiruipan} such as recommendation systems~\cite{li2022disentangled,fan2019metapath}, medical analysis~\cite{luo2021imas}, knowledge inference~\cite{CompGCN,A2N,M2GNN}, malicious account detection~\cite{liu2018heterogeneous}, information retrieval~\cite{mao2020item}, shop search~\cite{niu2020dual}, etc.



%Due to the aforementioned workflow, 
%Based on our characterization of HGNNs on GPUs, the different stages of HGNNs present different challenges, in terms of compute as well as memory access pattern -- often resulting in low compute utilization and low DRAM bandwidth utilization in the execution on the GPU.
%At the same time, HGNNs provide an opportunity for acceleration by exploiting the parallelism and data reusability that exists in the semantic graphs. 

Deriving from the above workflow, HGNNs exhibit different performance bottlenecks and new acceleration opportunities, compared with GNNs.
According to our quantitative characterization, different stages of HGNNs face different execution bounds, causing low utilization of compute and memory components. 
In addition, HGNNs earn the opportunity to exploit the high-degree parallelism and data reusability in the parallel processing of semantic graphs, which brings the possibility to improve overall performance and efficiency.


Unfortunately, existing GNN accelerators lack the HGNN-oriented design and optimization to efficiently accelerate HGNNs. In particular, a stage-fusion methodology specific to the execution semantics of HGNNs is missed in their designs~\cite{HyGCN,awbgcn}, to improve the utilization of hardware components. Besides, they fail to efficiently exploit the high-degree inter-semantic-graph parallelism and data reusability in the processing of HGNNs.
%While GPUs offer more flexibility, they perform HGNNs poorly due to the irregular memory accesses in the NA stage~\cite{HyGCN,awbgcn,understand_HGNN}. 
%\revise{In addition, existing software frameworks usually execute stages with different execution bounds in serial to take advantage of hardware-optimized coarse-grained operations on GPUs, causing low compute utilization and DRAM bandwidth utilization.}

%and hard to efficiently exploit high-degree data reusability.

%\todo{revise, design also revise, refine contribution summary, copy to here}


In this work, we quantitatively characterize a set of representative HGNN models on GPU to ferret out the execution patterns, performance bottlenecks, and acceleration opportunities of HGNNs.
Guided by the characterizations, we design a high-performance HGNN accelerator, called HiHGNN, to exploit the newfound parallelism and data reusability in HGNNs.
Specifically, 
we first propose a novel stage-fusion methodology tailoring to HGNNs, called bound-aware stage fusion. It decomposes and reorganizes coarse-grained stages of HGNNs into fine-grained stages with explicit execution bounds, enabled by a stage-fusion programming model. Then, these fine-grained stages are fused and allowed pipelined execution through a stage-fusion hardware datapath, ensuring higher compute and memory utilization.
%
Second, we propose an independency-aware parallel execution design to exploit the inter-semantic-graph parallelism. 
This design is built by a multi-lane architecture equipped with workload-aware scheduling, which exploits the high-degree parallelism exposed by the independencies between the processing of semantic graphs, thereby additional hardware resources can be added to further improve performance.
%
Third, we propose a similarity-aware execution scheduling to harness the potential inter-semantic-graph data reusability. The degree of data reusability between semantic graphs is proportionate to their similarity. To leverage this insight, we construct a hypergraph by taking each semantic graph as a vertex and the similarity between them as edge weights. By conducting the shortest Hamilton path algorithm on this hypergraph, we generate an execution order for the semantic graphs to maximally exploit the inter-semantic graph data reusability.


To summarize, we list our contributions as follows: \par
\squishlist
  \item
  We conduct a quantitative characterization of HGNNs on GPU to uncover the execution patterns, performance bottlenecks, and acceleration opportunities of HGNNs.

  \item
  We propose a high-performance HGNN accelerator, called HiHGNN, to alleviate performance bottlenecks and exploit the newfound parallelism and data reusability in HGNNs. 
  
  \item 
  We propose a bound-aware stage fusion methodology that tailors to HGNN acceleration, including a novel programming model and hardware datapath. Moreover, we propose an independency-aware parallel execution and a similarity-aware execution scheduling to respectively exploit the inter-semantic-graph parallelism and data reusability.
  
  \item
  We implement HiHGNN in RTL and evaluate it through a detailed microarchitectural simulation and on FPGA. 
  %We use four well-known HGNN models on three popular heterogeneous graph datasets. 
  Compared to the state-of-the-art software framework running on NVIDIA GPU T4 and GPU A100, HiHGNN achieves an average 41.5$\times$ and 8.6$\times$ speedup with 106$\times$ and 73$\times$ energy efficiency, respectively.

  
  
\squishend




\begin{comment}




%\todo{Structure: 
%%先写图
%%首句：GNNs被广泛用于处理图数据，但他们无法处理异构图数据
%%接着：同构图的概念。GNN是啥，怎么处理同构图。异构图是啥，为什么GNN不能处理。
%%
%%
%%得益于针对异质图的令人惊讶的学习能力， Heterogeneous Graph Neural Network, GNN)被广泛应用各种重要的应用场景中。
%
%相对于传统的(Graph Neural Network, GNN)算法主要是为仅具有单一类型顶点和单一类型连接边的同构图（如图\ref{fig:graph_examples}(a) 所示）设计的\cite{HGNN,HAN,MAGNN,1stChebNet,GINConv}，遵循邻域聚合的方式来捕获图数据上的结构信息，最终为每个图顶点生成用于下游任务的表示向量，


%传统的GNN算法主要是为仅具有单一类型顶点和单一类型连接边的同构图设计的，遵循邻域聚合的方式来捕获图数据上的结构信息，最终为每个图顶点生成用于下游任务的表示向量。然而在现实生活中，复杂系统中的许多数据都天然地表示为异构图。即多种类型的实体及其之间多种类型的关系分别由各种类型的顶点和各种类型的连接边表示。例如，ACM

%这些关系可以相互组合形成高级语义关系，即元路径 (metapath)。
%例如，2跳元路径Director-Movie-Director (DMD) 表示的高级语义关系是合作导演关系，4跳元路径Actor-Movie-Director-Movie-Actor (AMDMA) 表示的高级语义关系是两位演员与同一位导演合作过。
%可见，异构图包含更全面的信息和丰富的语义，比同构图具有更强的表示能力，并具有更广泛的应用场景。但是因为传统的GNN算法模型只能捕获结构信息无法捕获高级语义信息，所以它们对异构图数据的处理力不从心。

%得益于针对异质图的令人惊讶的学习能力，Heterogeneous Graph Neural Network（HGNN)被广泛应用各种重要的应用场景中。
%}

Many real-world data in complex systems are naturally represented as heterogeneous graphs (HetGs) which possess not only structural information but also rich semantic information~\cite{HG_survey}.
HetGs consist of multiple types of entities and relations which are embodied by various types of vertices and edges, respectively.
For example, the DBLP citation network includes several types of vertices: Paper (P), Author (A), and Venue (V), as well as many relations with different semantic meanings, such as Author$\xrightarrow{\rm writes}$Paper, Paper$\xrightarrow{\rm cites}$Paper, Paper$\xrightarrow{\rm publishes~in}$Venue (abbreviated as AP, PP, and PV).



Graph neural networks (GNNs) are insufficient to deal with HetGs because they are inherently designed to capture structural information rather than semantic information. 
They are primarily designed for homogeneous graphs (homoGs) associated with a single type of vertices and edges, following a neighborhood aggregation scheme to capture structural information of a graph, where the representation embedding vector of each vertex is computed by recursively aggregating the feature vectors of neighboring vertices~\cite{GCN,comprehensive_gnn_survey}. Therefore, they fail to leverage the high-level semantic information in HetGs for better prediction performance.

HGNNs use a different execution semantic to capture both the structural and semantic information, which first partition the graph into semantic graphs, apply an independent GNN module on each semantic graph, and at last fuse the results of all semantic graphs to get the final output. These semantic graphs are generated by different relations or metapaths (hyper-relation which reflects multi-hop relationship). For example, each semantic graph in R-GCN~\cite{R-GCN} contains only one type of relations, such as AP and PP, while HAN~\cite{HAN} partitions HetGs based on metapaths~\cite{sun2011pathsim,sun2012mining}, such as author$\rightarrow$paper$\leftarrow$author (abbreviated as APA) representing a two-hop coauthor relationship in the original graph.

Plenty of heterogeneous graph neural networks (HGNNs) have been proposed to capture both structural and semantic information, widely used in many critical fields \cite{hgnn_survey_tangjie,hgnn_survey_hanjiawei,hgnn_survey_shichuan,hgnn_survey_shiruipan}. HGNNs have achieved excellent prediction performance in HetG representation learning and become at the heart of a broad range of critical fields such as recommendation systems~\cite{li2022disentangled,fan2019metapath}, medical analysis \cite{luo2021imas}, knowledge graph inference~\cite{CompGCN,A2N,M2GNN}, malicious account detection~\cite{liu2018heterogeneous}, information retrieval~\cite{mao2020item}, shop search~\cite{niu2020dual}, and so forth.

% 每个阶段的主要行为，不必要介绍为什么要这么做

The workflow of the most prevalent HGNNs usually can be divided into four major execution stages~\cite{R-GCN,R-GAT,HAN,Simple-HGN,SeHGNN}: The \textit{Semantic Graph Build} (SGB) stage partitions the original HetG into several semantic graphs based on relations or predefined metapaths; the \textit{Feature Projection} (FP) stage transforms the feature vector of each vertex to a new one using a multi-layer perceptron (MLP) in each semantic graph; the \textit{Neighbor Aggregation} (NA) stage maintains the most graph processing behaviors and aggregating features from neighbors in each semantic graph; the \textit{Semantic Fusion} (SF) stage fuses semantic information revealed by all semantic graphs, i.e., aggregates the results of NA stage across different semantic graphs for each vertex. Relatively,
GNNs only contain FP and NA stages. HGNNs can be viewed as a list of several GNN models in each semantic graph and fuse outputs of all GNNs to generate final embeddings.


% 感觉前面篇幅有点过于长了，到第一页快结束了才引出来accelerate的问题，试着改短一些
% 以及试着把长难句改短一些

\end{comment}