\section{Introduction}

NLP research can have different aims. Some NLP research focuses on developing new algorithms or building practical NLP applications. Another line of NLP work constructs computational models that aim to explain human language and language use; this line of work has been dubbed \textit{NLP-as-Science}~\citep{van2022role}. Among other things, NLP-as-Science demands that we ask ourselves to what extent NLP research findings generalise along a range of dimensions.

In addition to the practical applications of Referring Expression Generation~\citep[REG, ][]{reiter-2017-commercial}, REG is also one of the typical tasks in NLP-as-Science, where REG algorithms are built to model and explain the reference production of human beings \cite{krahmer-van-deemter-2012-computational, van2016computational}. In the computational linguistics and cognitive science community, REG can be divided into two distinct tasks: \emph{one-shot REG}, finding a referring expression (RE) to single out a referent from a set, and \emph{REG-in-context}, generating an RE to refer to a referent at a given point in a discourse. 

In a classic setup, REG-in-context is often approached in two steps: The first is to decide on the form of an RE at a given point in the discourse, and the second is to decide on its content. Many researchers have been interested in the first sub-task, referential form selection: the task to decide which referential form (e.g., pronoun, proper name, description, etc.) an RE takes~\citep{mccoy1999generating, henschel2000pronominalization, kibrik2016referential}. Nearly 15 years ago, \citet{belz-etal-2008-grec} introduced the GREC shared tasks and a number of English REG corpora with two goals: (1) assessing the performance of computational models of reference production~\citep{belz2009generating}, and (2) understanding the contribution of linguistically-inspired factors to the choice of referential form~\citep{greenbacker2009feature, kibrik2016referential, same-van-deemter-2020-linguistic}.

15 years have passed since the GREC challenge was organised, and many new models and corpora have been proposed in the meantime (e.g., \citet{castro-ferreira-etal-2018-neuralreg,cunha-etal-2020-referring}, and \citet{same-etal-2022-non}). We, therefore, decided that it was time to ask, in the spirit of NLP-as-Science, how well the lessons that GREC once taught our research community %about human RE use 
hold up when scrutinised in light of all these developments. In other words, we will investigate to what extent the findings from GREC can be {\em generalised} to other corpora and other models. 

To this end, we pursue the following objectives: (1) We extend GREC by testing its REG algorithms not only on the GREC corpora but also on a corpus that was not originally considered and that has a different genre, namely the Wall Street Journal (WSJ) portion of OntoNotes~\citep{hovy2006ontonotes, weischedel2013ontonotes}; (2) We fine-tune pre-trained language models on the task of REG-in-context and assess them in the GREC framework. 

In Section \ref{sec:grec}, we detail the GREC shared tasks and introduce the corpora used in GREC. 
Section~\ref{sec:rq} spells out our research questions.
In Section~\ref{sec:algorithm} and Section~\ref{sec:corpus}, we introduce the algorithms and corpora that we use. Section~\ref{sec:evaluation} reports the performance of each algorithm on each corpus, followed by analyses in Section~\ref{sec:analysis}.
Section~\ref{sec:discussion} will discuss our findings and draw some lessons. 
