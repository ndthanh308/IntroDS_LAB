\section{REG Algorithms} \label{sec:algorithm}

In what follows, we introduce the REG algorithms that are considered in this study.

\subsection{ML-based REG} 

For this study, we have narrowed our focus to feature-based ML algorithms that predict the type of RE. Consequently, we reconstruct five ML-based REG algorithms, namely \udel, \icsi, \cnts, \isg, and \osu, along with their respective feature sets, while excluding \texttt{JUNLG}. Note that we implement \cnts slightly differently from \citet{hendrickx-etal-2008-cnts}. Concretely, \citet{hendrickx-etal-2008-cnts} have mentioned that they have used the TiMBL package \citep{daelemans2007timbl} for implementing the Memory Based Learning algorithm. Instead, we implemented the k-Nearest Neighbors algorithm. According to \citet{daelemans2007timbl}, Memory Based Learning is the direct descendant of k-Nearest Neighbors. More information on the implementation of these models can be found in Appendix \ref{sec:appendixML}.

\subsection{PLM-based REG}

% Figure environment removed

Deep learning approaches have been used in many previous works on REG~\citep{castro-ferreira-etal-2019-neural, cao-cheung-2019-referring, cunha-etal-2020-referring, chen-etal-2021-neural-referential}. Different from previous work\footnote{Note that \citet{chen-etal-2021-neural-referential,chen2023neural} also leveraged a PLM, but did not fine-tune it. Instead, they used the word representations from the PLM as static inputs to an RNN and made predictions using the RNN.}, we fine-tune PLMs on REG corpora in this study. 

To fine-tune PLMs on REG corpora, we began by pre-processing each corpus using the same paradigm as described by ~\citet{cunha-etal-2020-referring}. More precisely, each referent in a given document was replaced with its corresponding proper name. For example, all underlined REs in Example (1) were replaced by ``David Chang''. Subsequently, as depicted in Figure~\ref{fig:plm}, we fed the data into a PLM, and, for each referent (e.g., ``David Chang'' ), we extracted the representations of its first token and its last token and summed them. The final representations were then sent to a fully connected layer for predicting the RE forms. In this study, we use \texttt{BERT} and \texttt{RoBERTa} (see section \ref{sec:implementation} for more details).