% newly added references in the 3nd submission

@inproceedings{banerjee-lavie-2005-meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}

@inproceedings{sellam-etal-2020-bleurt,
    title = "{BLEURT}: Learning Robust Metrics for Text Generation",
    author = "Sellam, Thibault  and
      Das, Dipanjan  and
      Parikh, Ankur",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.704",
    doi = "10.18653/v1/2020.acl-main.704",
    pages = "7881--7892",
}

@misc{2109.02550,
Author = {Kris Cao and Laura Rimell},
Title = {You should evaluate your language model on marginal likelihood over tokenisations},
Year = {2021},
Eprint = {arXiv:2109.02550},
}

@misc{2112.10508,
Author = {Sabrina J. Mielke and Zaid Alyafeai and Elizabeth Salesky and Colin Raffel and Manan Dey and Matthias Gallé and Arun Raja and Chenglei Si and Wilson Y. Lee and Benoît Sagot and Samson Tan},
Title = {Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP},
Year = {2021},
Eprint = {arXiv:2112.10508},
}

@misc{1911.04997,
Author = {Rohit Gupta and Laurent Besacier and Marc Dymetman and Matthias Gallé},
Title = {Character-based NMT with Transformer},
Year = {2019},
Eprint = {arXiv:1911.04997},
}

@inproceedings{galle-2019-investigating,
    title = "Investigating the Effectiveness of {BPE}: The Power of Shorter Sequences",
    author = "Gall{\'e}, Matthias",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1141",
    doi = "10.18653/v1/D19-1141",
    pages = "1375--1381",
}

@misc{1808.06226,
Author = {Taku Kudo and John Richardson},
Title = {SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
Year = {2018},
Eprint = {arXiv:1808.06226},
}

@misc{1804.10959,
Author = {Taku Kudo},
Title = {Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates},
Year = {2018},
Eprint = {arXiv:1804.10959},
}

@inproceedings{koehn-knight-2003-empirical,
    title = "Empirical Methods for Compound Splitting",
    author = "Koehn, Philipp  and
      Knight, Kevin",
    booktitle = "10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2003",
    address = "Budapest, Hungary",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E03-1076",
}

@inproceedings{teh-2006-hierarchical,
    title = "A Hierarchical {B}ayesian Language Model Based On {P}itman-{Y}or Processes",
    author = "Teh, Yee Whye",
    booktitle = "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2006",
    address = "Sydney, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P06-1124",
    doi = "10.3115/1220175.1220299",
    pages = "985--992",
}

@misc{1610.03035,
Author = {William Chan and Yu Zhang and Quoc Le and Navdeep Jaitly},
Title = {Latent Sequence Decompositions},
Year = {2016},
Eprint = {arXiv:1610.03035},
}

% NMT Sec

%  Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units.
@inproceedings{kalchbrenner-blunsom-2013-recurrent-continuous,
    title = "Recurrent Continuous Translation Models",
    author = "Kalchbrenner, Nal  and
      Blunsom, Phil",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1176",
    pages = "1700--1709",
}

@incollection{NIPS2014_5346,
title = {Sequence to Sequence Learning with Neural Networks},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {3104--3112},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf}
}

@ARTICLE{2014arXiv1409.0473B,
       author = {{Bahdanau}, Dzmitry and {Cho}, Kyunghyun and {Bengio}, Yoshua},
        title = "{Neural Machine Translation by Jointly Learning to Align and Translate}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = 2014,
        month = sep,
          eid = {arXiv:1409.0473},
        pages = {arXiv:1409.0473},
archivePrefix = {arXiv},
       eprint = {1409.0473},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014arXiv1409.0473B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

% CNN based
@inproceedings{10.5555/3305381.3305510,
author = {Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N.},
title = {Convolutional Sequence to Sequence Learning},
year = {2017},
publisher = {JMLR.org},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {1243–1252},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}


@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

% Addressing the Rare Word Problem in Neural Machine Translation (find the OOV place in the source sentence and do post-processing the OOV)
@inproceedings{luong-etal-2015-addressing,
    title = "Addressing the Rare Word Problem in Neural Machine Translation",
    author = "Luong, Thang  and
      Sutskever, Ilya  and
      Le, Quoc  and
      Vinyals, Oriol  and
      Zaremba, Wojciech",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-1002",
    doi = "10.3115/v1/P15-1002",
    pages = "11--19",
}

% On Using Very Large Target Vocabulary for Neural Machine Translation
% there are still OOV when testing even if we include all words in the train corpus
@inproceedings{jean-etal-2015-using,
    title = "On Using Very Large Target Vocabulary for Neural Machine Translation",
    author = "Jean, S{\'e}bastien  and
      Cho, Kyunghyun  and
      Memisevic, Roland  and
      Bengio, Yoshua",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-1001",
    doi = "10.3115/v1/P15-1001",
    pages = "1--10",
}

% Character Sec




% On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines,
@article{Kim_Jernite_Sontag_Rush_2016, title={Character-Aware Neural Language Models}, volume={30}, url={https://ojs.aaai.org/index.php/AAAI/article/view/10362}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Kim, Yoon and Jernite, Yacine and Sontag, David and Rush, Alexander}, year={2016}, month={Mar.} }

% En-German up to 3 points
@inproceedings{costa-jussa-fonollosa-2016-character,
    title = "Character-based Neural Machine Translation",
    author = "Costa-juss{\`a}, Marta R.  and
      Fonollosa, Jos{\'e} A. R.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-2058",
    doi = "10.18653/v1/P16-2058",
    pages = "357--361",
}

@misc{1511.04586,
Author = {Wang Ling and Isabel Trancoso and Chris Dyer and Alan W Black},
Title = {Character-based Neural Machine Translation},
Year = {2015},
Eprint = {arXiv:1511.04586},
}

% Character level decoding SMT
@inproceedings{tiedemann-2012-character,
    title = "Character-Based Pivot Translation for Under-Resourced Languages and Domains",
    author = {Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2012",
    address = "Avignon, France",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E12-1015",
    pages = "141--151",
}

% hybrid word-character models
%  it is much faster and easier to train than character-based ones; at the same time, it never produces unknown words as in the case of word-based models.
@misc{1604.00788,
Author = {Minh-Thang Luong and Christopher D. Manning},
Title = {Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models},
Year = {2016},
Eprint = {arXiv:1604.00788},
}

% character based method require deeper model
@inproceedings{cherry-etal-2018-revisiting,
    title = "Revisiting Character-Based Neural Machine Translation with Capacity and Compression",
    author = "Cherry, Colin  and
      Foster, George  and
      Bapna, Ankur  and
      Firat, Orhan  and
      Macherey, Wolfgang",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1461",
    doi = "10.18653/v1/D18-1461",
    pages = "4295--4305",
}





% utf-8 based
@inproceedings{shaham-levy-2021-neural,
    title = "Neural Machine Translation without Embeddings",
    author = "Shaham, Uri  and
      Levy, Omer",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.17",
    doi = "10.18653/v1/2021.naacl-main.17",
    pages = "181--186",
    abstract = "Many NLP models operate over sequences of subword tokens produced by hand-crafted tokenization rules and heuristic subword induction algorithms. A simple universal alternative is to represent every computerized text as a sequence of bytes via UTF-8, obviating the need for an embedding layer since there are fewer token types (256) than dimensions. Surprisingly, replacing the ubiquitous embedding layer with one-hot representations of each byte does not hurt performance; experiments on byte-to-byte machine translation from English to 10 different languages show a consistent improvement in BLEU, rivaling character-level and even standard subword-level models. A deeper investigation reveals that the combination of embeddingless models with decoder-input dropout amounts to token dropout, which benefits byte-to-byte models in particular.",
}

% Subword Sec


% BPE
@inproceedings{sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}

% BPE the compression algo
@article{gage1994new,
  title={A new algorithm for data compression},
  author={Gage, Philip},
  journal={C Users Journal},
  volume={12},
  number={2},
  pages={23--38},
  year={1994},
  publisher={McPherson, KS: R \& D Publications, c1987-1994.}
}

@INPROCEEDINGS{6289079,  author={M. {Schuster} and K. {Nakajima}},  booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Japanese and Korean voice search},   year={2012},  volume={},  number={}, url = "https://ieeexplore.ieee.org/abstract/document/6289079", pages={5149-5152},}

% byte-based BPE (BBPE)
@misc{1909.03341,
Author = {Changhan Wang and Kyunghyun Cho and Jiatao Gu},
Title = {Neural Machine Translation with Byte-Level Subwords},
Year = {2019},
Eprint = {arXiv:1909.03341},
}

@inproceedings{xu-etal-2021-vocabulary,
    title = "Vocabulary Learning via Optimal Transport for Neural Machine Translation",
    author = "Xu, Jingjing  and
      Zhou, Hao  and
      Gan, Chun  and
      Zheng, Zaixiang  and
      Li, Lei",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.571",
    doi = "10.18653/v1/2021.acl-long.571",
    pages = "7361--7373",
}

% BPE drop
@inproceedings{provilkov-etal-2020-bpe,
    title = "{BPE}-Dropout: Simple and Effective Subword Regularization",
    author = "Provilkov, Ivan  and
      Emelianenko, Dmitrii  and
      Voita, Elena",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.170",
    doi = "10.18653/v1/2020.acl-main.170",
    pages = "1882--1892",
}

% SPM
@inproceedings{kudo-richardson-2018-sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-2012",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
}

% SPM regularization
@inproceedings{kudo-2018-subword,
    title = "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates",
    author = "Kudo, Taku",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1007",
    doi = "10.18653/v1/P18-1007",
    pages = "66--75",
}

% DPE
@inproceedings{he-etal-2020-dynamic,
    title = "Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation",
    author = "He, Xuanli  and
      Haffari, Gholamreza  and
      Norouzi, Mohammad",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.275",
    doi = "10.18653/v1/2020.acl-main.275",
    pages = "3042--3051",
}

% Downstream task optimized word segmentation
% OpTok explores a tokenization that yields a better score for a downstream task. 
@inproceedings{hiraoka-etal-2020-optimizing,
    title = "Optimizing Word Segmentation for Downstream Task",
    author = "Hiraoka, Tatsuya  and
      Takase, Sho  and
      Uchiumi, Kei  and
      Keyaki, Atsushi  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.120",
    doi = "10.18653/v1/2020.findings-emnlp.120",
    pages = "1341--1351",
}

% Optimization of the tokenization part
% learn word boundaries to improve the performance of a Chinese-to-English MT systems by a Bayesian generative model.
@inproceedings{xu-etal-2008-bayesian,
    title = "{B}ayesian Semi-Supervised {C}hinese Word Segmentation for Statistical Machine Translation",
    author = "Xu, Jia  and
      Gao, Jianfeng  and
      Toutanova, Kristina  and
      Ney, Hermann",
    booktitle = "Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008)",
    month = aug,
    year = "2008",
    address = "Manchester, UK",
    publisher = "Coling 2008 Organizing Committee",
    url = "https://aclanthology.org/C08-1128",
    pages = "1017--1024",
}

% an unsupervised method that incorporate information available from parallel corpus to determine a good tokenization for machine translation
@inproceedings{chung-gildea-2009-unsupervised,
    title = "Unsupervised Tokenization for Machine Translation",
    author = "Chung, Tagyoung  and
      Gildea, Daniel",
    booktitle = "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing",
    month = aug,
    year = "2009",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D09-1075",
    pages = "718--726",
}

% morphological subword segmentation, define some rules, slightly improvement.
% background: suffix prefix infix, circumfix transfix in some language...
% investigation of the effects of morphological word segmentation for multilingual ZeroShot NMT models. we  we improve the rule-based affix splitter %  helps Zero-Shot NMT models in better capturing morphological variations and grammatical structure compared to BPE-based models, resulting in more fluent (and possibly adequate) translations compared to BPE-based models, as confirmed by the informal human evaluation we conducted.
@book{giulio2018,
  title={Morphological Zero-Shot Neural Machine Translation},
  author={Zhou, Giulio},
  year={2018},
    booktitle = {Master’s thesis},
  publisher={University of Edinburgh}
}

% morphological subword segmentation, target side
% In this paper, we investigate word segmentation strategies that incorporate more linguistic knowledge. We demonstrate that linguistically informed target word segmentation is better suited for NMT, leading to improved translation quality on the order of magnitude of +0.5 BLEU and −0.9 TER for a medium-scale English→German translation task
@inproceedings{huck-etal-2017-target,
    title = "Target-side Word Segmentation Strategies for Neural Machine Translation",
    author = "Huck, Matthias  and
      Riess, Simon  and
      Fraser, Alexander",
    booktitle = "Proceedings of the Second Conference on Machine Translation",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4706",
    doi = "10.18653/v1/W17-4706",
    pages = "56--67",
}


%  we formulate the quest of vocabularization – finding the best token dictionary with a proper size – as an optimal transport (OT) problem. We propose VOLT, a simple and efficient solution without trial training


% BPE makes the corpus easy to learn and predict
@article{1606.04289,
Author = {Dimitrios Alikaniotis and Helen Yannakoudakis and Marek Rei},
Title = {Automatic Text Scoring Using Neural Networks},
Year = {2016},
Eprint = {arXiv:1606.04289},
Doi = {10.18653/v1/P16-1068},
}


% Sequence modeling
@misc{1702.07463,
Author = {Chong Wang and Yining Wang and Po-Sen Huang and Abdelrahman Mohamed and Dengyong Zhou and Li Deng},
Title = {Sequence Modeling via Segmentations},
Year = {2017},
Eprint = {arXiv:1702.07463},
}

% word segmentation

% segmental language model
@inproceedings{kawakami-etal-2019-learning,
    title = "Learning to Discover, Ground and Use Words with Segmental Neural Language Models",
    author = "Kawakami, Kazuya  and
      Dyer, Chris  and
      Blunsom, Phil",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1645",
    doi = "10.18653/v1/P19-1645",
    pages = "6429--6441",
}

% KFTT
@misc{neubig11kftt,
	author = {Graham Neubig},
	title = {The {Kyoto} Free Translation Task},
	howpublished = {http://www.phontron.com/kftt},
	year = {2011}
}

% segmental language model
@inproceedings{sun-deng-2018-unsupervised,
    title = "Unsupervised Neural Word Segmentation for {C}hinese via Segmental Language Modeling",
    author = "Sun, Zhiqing  and
      Deng, Zhi-Hong",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1531",
    doi = "10.18653/v1/D18-1531",
    pages = "4915--4920",
    abstract = "Previous traditional approaches to unsupervised Chinese word segmentation (CWS) can be roughly classified into discriminative and generative models. The former uses the carefully designed goodness measures for candidate segmentation, while the latter focuses on finding the optimal segmentation of the highest generative probability. However, while there exists a trivial way to extend the discriminative models into neural version by using neural language models, those of generative ones are non-trivial. In this paper, we propose the segmental language models (SLMs) for CWS. Our approach explicitly focuses on the segmental nature of Chinese, as well as preserves several properties of language models. In SLMs, a context encoder encodes the previous context and a segment decoder generates each segment incrementally. As far as we know, we are the first to propose a neural model for unsupervised CWS and achieve competitive performance to the state-of-the-art statistical models on four different datasets from SIGHAN 2005 bakeoff.",
}

% masked segmental language model
@misc{2104.07829,
Author = {C. M. Downey and Fei Xia and Gina-Anne Levow and Shane Steinert-Threlkeld},
Title = {A Masked Segmental Language Model for Unsupervised Natural Language Segmentation},
Year = {2021},
Eprint = {arXiv:2104.07829},
}

% sequence modeling via segmentation for LM
@inproceedings{grave-etal-2019-training,
    title = "Training Hybrid Language Models by Marginalizing over Segmentations",
    author = "Grave, Edouard  and
      Sukhbaatar, Sainbayar  and
      Bojanowski, Piotr  and
      Joulin, Armand",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1143",
    doi = "10.18653/v1/P19-1143",
    pages = "1477--1482",
}

% sequence modeling via segmentation for NMT
@misc{1810.01480,
Author = {Julia Kreutzer and Artem Sokolov},
Title = {Learning to Segment Inputs for NMT Favors Character-Level Processing},
Year = {2018},
Eprint = {arXiv:1810.01480},
}

% Heaps' law
@book{herdan1960type,
  title={Type-token mathematics},
  author={Herdan, Gustav},
  volume={4},
  year={1960},
  publisher={Mouton}
}


% Self-supervision

%CV
@article {Hinton504,
	author = {Hinton, G. E. and Salakhutdinov, R. R.},
	title = {Reducing the Dimensionality of Data with Neural Networks},
	volume = {313},
	number = {5786},
	pages = {504--507},
	year = {2006},
	doi = {10.1126/science.1127647},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/313/5786/504},
	eprint = {https://science.sciencemag.org/content/313/5786/504.full.pdf},
	journal = {Science}
}


@inproceedings{10.1145/1390156.1390294,
author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
title = {Extracting and Composing Robust Features with Denoising Autoencoders},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390156.1390294},
doi = {10.1145/1390156.1390294},
abstract = {Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
pages = {1096–1103},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}


@article{1604.07379,
Author = {Deepak Pathak and Philipp Krahenbuhl and Jeff Donahue and Trevor Darrell and Alexei A. Efros},
Title = {Context Encoders: Feature Learning by Inpainting},
Year = {2016},
Eprint = {arXiv:1604.07379},
Howpublished = {CVPR 2016},
}

@InProceedings{Doersch_2015_ICCV,
author = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A.},
title = {Unsupervised Visual Representation Learning by Context Prediction},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={European conference on computer vision},
  pages={649--666},
  year={2016},
  organization={Springer}
}

@misc{1603.08561,
Author = {Ishan Misra and C. Lawrence Zitnick and Martial Hebert},
Title = {Shuffle and Learn: Unsupervised Learning using Temporal Order Verification},
Year = {2016},
Eprint = {arXiv:1603.08561},
}

@InProceedings{Wei_2018_CVPR,
author = {Wei, Donglai and Lim, Joseph J. and Zisserman, Andrew and Freeman, William T.},
title = {Learning and Using the Arrow of Time},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Vondrick_2018_ECCV,
author = {Vondrick, Carl and Shrivastava, Abhinav and Fathi, Alireza and Guadarrama, Sergio and Murphy, Kevin},
title = {Tracking Emerges by Colorizing Videos},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

% NLP pretrain
% BERT
@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

%mbart
@article{10.1162/tacl_a_00343,
    author = {Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
    title = "{Multilingual Denoising Pre-training for Neural Machine Translation}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {8},
    pages = {726-742},
    year = {2020},
    month = {11},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00343},
    url = {https://doi.org/10.1162/tacl\_a\_00343},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00343/1923401/tacl\_a\_00343.pdf},
}

% bart
@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
}





% T5: character-level
@misc{1910.10683,
Author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
Title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
Year = {2019},
Eprint = {arXiv:1910.10683},
}
% GPT3 BPE over raw bytes
@misc{2005.14165,
Author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
Title = {Language Models are Few-Shot Learners},
Year = {2020},
Eprint = {arXiv:2005.14165},
}
% RoBERTa: BPE over raw bytes
@misc{1907.11692,
Author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
Title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
Year = {2019},
Eprint = {arXiv:1907.11692},
}
% MASS
@ARTICLE{2019arXiv190502450S,
       author = {{Song}, Kaitao and {Tan}, Xu and {Qin}, Tao and {Lu}, Jianfeng and
         {Liu}, Tie-Yan},
        title = "{MASS: Masked Sequence to Sequence Pre-training for Language Generation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = 2019,
        month = may,
          eid = {arXiv:1905.02450},
        pages = {arXiv:1905.02450},
archivePrefix = {arXiv},
       eprint = {1905.02450},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190502450S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@inproceedings{ren-etal-2019-explicit,
    title = "Explicit Cross-lingual Pre-training for Unsupervised Machine Translation",
    author = "Ren, Shuo  and
      Wu, Yu  and
      Liu, Shujie  and
      Zhou, Ming  and
      Ma, Shuai",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1071",
    doi = "10.18653/v1/D19-1071",
    pages = "770--779",
}

% curriculum learning
@inproceedings{bengio2009curriculum,
  title={Curriculum Learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

% fairseq framework
@inproceedings{ott-etal-2019-fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle  and
      Edunov, Sergey  and
      Baevski, Alexei  and
      Fan, Angela  and
      Gross, Sam  and
      Ng, Nathan  and
      Grangier, David  and
      Auli, Michael",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-4009",
    doi = "10.18653/v1/N19-4009",
    pages = "48--53",
    abstract = "fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at https://www.youtube.com/watch?v=OtgDdWtHvto",
}

% ALT dataset

@inproceedings{thu-etal-2016-introducing,
    title = "Introducing the {A}sian Language Treebank ({ALT})",
    author = "Thu, Ye Kyaw  and
      Pa, Win Pa  and
      Utiyama, Masao  and
      Finch, Andrew  and
      Sumita, Eiichiro",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/L16-1249",
    pages = "1574--1578",
}

% tokenizer

%moses
@inproceedings{koehn-etal-2007-moses,
    title = "{M}oses: Open Source Toolkit for Statistical Machine Translation",
    author = "Koehn, Philipp  and
      Hoang, Hieu  and
      Birch, Alexandra  and
      Callison-Burch, Chris  and
      Federico, Marcello  and
      Bertoldi, Nicola  and
      Cowan, Brooke  and
      Shen, Wade  and
      Moran, Christine  and
      Zens, Richard  and
      Dyer, Chris  and
      Bojar, Ond{\v{r}}ej  and
      Constantin, Alexandra  and
      Herbst, Evan",
    booktitle = "Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P07-2045",
    pages = "177--180",
}

% indic nlp
@misc{kunchukuttan2020indicnlp,
author = "Anoop Kunchukuttan",
title = "{The IndicNLP Library}",
year = "2020",
howpublished={\url{https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/docs/indicnlp.pdf}}
}

%deepcut
@MISC{2019zndo...3457707K,
       author = {{Kittinaradorn}, Rakpong and {Chaovavanich}, Korakot and
         {Achakulvisut}, Titipat and {Srithaworn}, Kittinan and
         {Chormai}, Pattarawat and {Kaewkasi}, Chanwit and {Ruangrong}, Tulakan and
         {Oparad}, Krichkorn},
        title = "{DeepCut: A Thai word tokenization library using  Deep Neural Network.}",
         year = 2019,
        month = sep,
          eid = {10.5281/zenodo.3457707},
          doi = {10.5281/zenodo.3457707},
      version = {v1.0},
    publisher = {Zenodo},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019zndo...3457707K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}




% Juman++
@inproceedings{tolmachev-etal-2018-juman,
    title = "{J}uman++: A Morphological Analysis Toolkit for Scriptio Continua",
    author = "Tolmachev, Arseny  and
      Kawahara, Daisuke  and
      Kurohashi, Sadao",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-2010",
    doi = "10.18653/v1/D18-2010",
    pages = "54--59",
}

% standford tokenizer
@inproceedings{manning-etal-2014-stanford,
    title = "The {S}tanford {C}ore{NLP} Natural Language Processing Toolkit",
    author = "Manning, Christopher  and
      Surdeanu, Mihai  and
      Bauer, John  and
      Finkel, Jenny  and
      Bethard, Steven  and
      McClosky, David",
    booktitle = "Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P14-5010",
    doi = "10.3115/v1/P14-5010",
    pages = "55--60",
}

%WAT
@article{ding2018nova,
	title={NOVA: A Feasible and Flexible Annotation System for Joint Tokenization and Part-of-Speech Tagging},
	author={Ding, Chenchen and Utiyama, Masao and Sumita, Eiichiro},
	journal={ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)},
	url = "https://dl.acm.org/doi/10.1145/3276773",
	volume={18},
	number={2},
	pages={17},
	year={2018},
	publisher={ACM}
	}
	
@article{ding2019towards,
        title={Towards {Burmese} ({Myanmar}) Morphological Analysis: Syllable-based Tokenization and Part-of-speech Tagging},
        author={Ding, Chenchen and {Hnin Thu Zar Aye} and {Win Pa Pa} and {Khin Thandar Nwet} and {Khin Mar Soe} and Utiyama, Masao and Sumita, Eiichiro},
        journal={ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)},
        url="https://dl.acm.org/doi/10.1145/3325885",
        volume={19},
        number={1},
        pages={5},
        year={2019},
        publisher={ACM}
        }
@article{ding2020a,
        title={A {Burmese} ({Myanmar}) Treebank: Guildline and Analysis},
        author={Ding, Chenchen and {Sann Su Su Yee} and {Win Pa Pa} and {Khin Mar Soe} and Utiyama, Masao and Sumita, Eiichiro},
        journal={ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)},
        url="https://dl.acm.org/doi/abs/10.1145/3373268",
        volume={19},
        number={3},
        pages={40},
        year={2020},
        publisher={ACM}
        }

% sacreBLEU
@inproceedings{post-2018-call,
  title = "A Call for Clarity in Reporting {BLEU} Scores",
  author = "Post, Matt",
  booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
  month = oct,
  year = "2018",
  address = "Belgium, Brussels",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/W18-6319",
  pages = "186--191",
}

% significance test
@inproceedings{koehn-2004-statistical,
    title = "Statistical Significance Tests for Machine Translation Evaluation",
    author = "Koehn, Philipp",
    booktitle = "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W04-3250",
    pages = "388--395",
}

% adam
@misc{1412.6980,
Author = {Diederik P. Kingma and Jimmy Ba},
Title = {Adam: A Method for Stochastic Optimization},
Year = {2014},
Eprint = {arXiv:1412.6980},
}

@misc{vien,
Author = {Stefan Schweter},
Title = {Neural Machine Translation System for English to Vietnamese},
Year = {2018},
url = {https://github.com/stefan-it/nmt-en-vi},
}


@ARTICLE{2014arXiv1412.6980K,
       author = {{Kingma}, Diederik P. and {Ba}, Jimmy},
        title = "{Adam: A Method for Stochastic Optimization}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning},
         year = 2014,
        month = dec,
          eid = {arXiv:1412.6980},
        pages = {arXiv:1412.6980},
archivePrefix = {arXiv},
       eprint = {1412.6980},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014arXiv1412.6980K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



% layer norm
@ARTICLE{2016arXiv160706450L,
       author = {{Lei Ba}, Jimmy and {Kiros}, Jamie Ryan and {Hinton}, Geoffrey E.},
        title = "{Layer Normalization}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2016,
        month = jul,
          eid = {arXiv:1607.06450},
        pages = {arXiv:1607.06450},
archivePrefix = {arXiv},
       eprint = {1607.06450},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160706450L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



% low resource paper that uses monolingual corpus to improve translation quality

@InProceedings{mao-EtAl:2020:LREC,
  author    = {Mao, Zhuoyuan  and  Cromieres, Fabien  and  Dabre, Raj  and  Song, Haiyue  and  Kurohashi, Sadao},
  title     = {JASS: Japanese-specific Sequence to Sequence Pre-training for Neural Machine Translation},
  booktitle      = {Proceedings of The 12th Language Resources and Evaluation Conference},
  month          = {May},
  year           = {2020},
  address        = {Marseille, France},
  publisher      = {European Language Resources Association},
  pages     = {3683--3691},
  url       = {https://www.aclweb.org/anthology/2020.lrec-1.454}
}

@InProceedings{N16-1004,
  author = 	"Zoph, Barret
		and Knight, Kevin",
  title = 	"Multi-Source Neural Translation",
  booktitle = 	"Proceedings of the 2016 Conference of the North American Chapter of the      Association for Computational Linguistics: Human Language Technologies    ",
  year = 	"2016",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"30--34",
  address = 	"San Diego, California",
  doi = 	"10.18653/v1/N16-1004",
  url = 	"http://aclweb.org/anthology/N16-1004"
}


@InProceedings{firat16,
  author = 	"Firat, Orhan
		and Cho, Kyunghyun
		and Bengio, Yoshua",
  title = 	"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism    ",
  booktitle = 	"Proceedings of the 2016 Conference of the North American Chapter of the      Association for Computational Linguistics: Human Language Technologies    ",
  year = 	"2016",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"866--875",
  address = 	"San Diego, California",
  doi = 	"10.18653/v1/N16-1101",
  url = 	"http://aclweb.org/anthology/N16-1101"
}

@InProceedings{firat16b,
  author = 	"Firat, Orhan
		and Sankaran, Baskaran
		and Al-Onaizan, Yaser
		and Yarman Vural, Fatos T.
		and Cho, Kyunghyun",
  title = 	"Zero-Resource Translation with Multi-Lingual Neural Machine Translation",
  booktitle = 	"Proceedings of the 2016 Conference on Empirical Methods in Natural      Language Processing    ",
  year = 	"2016",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"268--277",
  address = 	"Austin, Texas",
  doi = 	"10.18653/v1/D16-1026",
  url = 	"http://aclweb.org/anthology/D16-1026"
}

% WMT preprocessing
@inproceedings{sennrich-etal-2016-edinburgh,
    title = "{E}dinburgh Neural Machine Translation Systems for {WMT} 16",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-2323",
    doi = "10.18653/v1/W16-2323",
    pages = "371--376",
}

@article{DBLP:journals/mt/RubinoMDFUS20,
  author    = {Raphael Rubino and
               Benjamin Marie and
               Raj Dabre and
               Atsushi Fujita and
               Masao Utiyama and
               Eiichiro Sumita},
  title     = {Extremely low-resource neural machine translation for Asian languages},
  journal   = {Mach. Transl.},
  volume    = {34},
  number    = {4},
  pages     = {347--382},
  year      = {2020},
  url       = {https://doi.org/10.1007/s10590-020-09258-6},
  doi       = {10.1007/s10590-020-09258-6},
  timestamp = {Fri, 14 May 2021 08:32:40 +0200},
  biburl    = {https://dblp.org/rec/journals/mt/RubinoMDFUS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}