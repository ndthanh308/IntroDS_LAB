\section{Introduction}
We consider a question by Deng, Li and Rabani \cite{deng2023generalized} about scheduling jobs to minimize makespan on unrelated machines in the setting of more general norms.
Recall that in the unrelated machines setting, we are given $n$ jobs and $m$ machines where each job $j \in [n]$ has some arbitrary processing time $p_{ij}$ 
on machine $i \in [m]$. Given an assignment of jobs to machines, the load on a machine is the sum of the processing times of all the jobs assigned to it. 
In a seminal result, Lenstra, Shmoys and Tardos \cite{lenstra1990approximation} gave a $2$-approximation for minimizing the makespan (the maximum machine load).
These results were later extended to the problem of minimizing the $\ell_p$-norm of the machine loads \cite{alon1998approximation,azar2005convex,kumar2009unified,makarychev2018optimization}.

In a breakthrough work \cite{chakrabarty2019approximation}, Chakrabarty and Swamy introduced a substantial generalization of the problem to general symmetric monotone norms. Recall that a function $\phi:\R^m\rightarrow \R_{\geq 0}$ is a norm if it satisfies (i) $\phi(u)=0$ iff $u=0^n$, (ii)
$\phi(\alpha u) = |\alpha|u$ for all $u$ and $\alpha \in R$ and, 
(iii) $\phi(u+v) \leq \phi(u) + \phi(v)$. 
We say that $\phi$ is {\em symmetric} if $\phi(u)=\phi(u')$ where $u'$ is some permutation of $u$, 
and it is monotone if $\psi(u) \leq \psi(v)$ for all  $u,v$ satisfying 
$ 0\leq u(i) \leq v(i)$ for all $i\in [m]$.

Surprisingly, they showed that for any arbitrary symmetric monotone norm $\phi:\R^m\rightarrow \R_{\geq 0}$,
that determines the overall objective as a function of the individual machine loads, there is an $O(1)$ approximation. The approximation ratio was subsequently improved to $4+\epsilon$ \cite{chakrabarty2019simpler} and more recently to $2+\epsilon$ \cite{ibrahimpur2021minimum}, which remarkably almost matches the bound for makespan. These results introduce  several new ideas to handle general norms by relating them to the special class of top-$k$ norms\footnote{The top-$k$ norm of a non-negative vector $v$ is the sum of its largest $k$ entries.}, and algorithmic techniques to work with them.

\medskip
{\bf General inner and outer norms.}
An even further generalization was considered by Deng, Li and Rabani \cite{deng2023generalized}, which we refer to as the generalized load-balancing (GLB) problem.
Here, additionally, each machine $i$ also has an arbitrary symmetric monotone norm
 $\psi_i:\R^n\rightarrow \R_{\geq 0}$ referred to as the {\em inner-norm},
that determines the machine's load as a function of the sizes of the jobs assigned to
it (note that all the results described previously have inner norm $\ell_1$). 
Formally, given an assignment $\schedule:[n] \rightarrow [m]$ of jobs to machines, the load on machine $i$ is $\Load(i)= \psi_i(p_i^\schedule)$ where $p_i^\schedule$ is the vector of sizes of jobs assigned to $i$, i.e.,~$p_i^\schedule(j)=p_{ij}$ if $\schedule(j)=i$ and $0$ otherwise. The overall objective is $\phi(\Load)$, where $\Load = (\Load(1),\ldots,\Load(m))$ is the vector of machine loads (where $\phi:\R^m\rightarrow \R_{\geq 0}$ is the norm as in \cite{chakrabarty2019approximation}).

 We shall refer to $\phi$ as the {\em outer-norm}.
Throughout this paper a general norm always means a symmetric monotone norm.




In its full generality (when the $\psi_i$ and $\phi$ are general), GLB becomes $\Omega(\log n)$ hard to approximate, as it generalizes\footnote{Given subsets $S_1,\ldots,S_m$ of $[n]$, consider the scheduling instance on $m$ machines (one per set) and $n$ jobs (one per element), with $p_{ij}=1$ iff element $j \in S_i$ and $p_{ij}=\infty$ otherwise. That is, only jobs in $S_i$ can be assigned to $i$. The point is that as $\psi=\ell_\infty$, we have $\Load(i)=0$ if no job is assigned to $i$, and exactly $1$ otherwise (even if all jobs in $S_i$ are assigned to $i$). As $\phi=\ell_1$, the objective is exactly the number of machines (sets) needed to cover all the jobs.}  the Set Cover problem when $\psi=\ell_\infty$ and $\phi=\ell_1$.
Interestingly, \cite{deng2023generalized} gave a matching 
$O(\log n)$ approximation for general $\psi$ and $\phi$, based on
solving and rounding a novel configuration LP.
 

\medskip

{\bf Generalized Makespan Problem (GMP).}
Given the $\Omega(\log n)$ hardness for the general case, 
\cite{deng2023generalized} also consider the interesting and natural special case where the outer-norm $\ell_\infty$, but the inner norm is general (i.e.,~the goal is to minimize makespan but where the machine loads are given by general inner-norms $\psi_i$). 
We refer to this problem as the {\em Generalized Makepsan Problem} (GMP).
In a sense, this problem can be considered as a ``dual'' of the problem considered by Chakrabarty and Swamy (where the inner-norm is $\ell_1$, but the outer-norm is general).

For GMP, 
Deng, Li and Rabani gave a $3$-approximation for the special case when each $\psi_i$ is a top-$k$ norm. The main open question they ask is whether an $O(1)$ approximation is achievable for general inner-norms. Apriori this seems quite plausible as there is close connection between top-$k$ norms and general norms (see e.g.~\cite{chakrabarty2019approximation,chakrabarty2019simpler}). Moreover, the $O(1)$ approximation of Chakrabarty and Swamy \cite{chakrabarty2019approximation} for the ``dual'' problem, also suggests that GMP may have an $O(1)$ approximation.


\subsection{Our Results}
Our main result is that GMP does not admit an $O(1)$-approximation under standard complexity-theoretic assumptions, answering the main open problem in \cite{deng2023generalized}.

Our starting point is an integrality gap instance for the natural configuration LP for GMP.
\begin{restatable}{theorem}{integralitygap}
\label{thm1}
There is an instance of GMP with a symmetric monotone norm $\psi$, for which the natural configuration LP has an integrality gap of $\Omega((\log n)^{1/2})$.
\end{restatable} 
The gap instance is based on a probabilistic construction and a key idea is to work with a suitably chosen norm $\psi$, defined as the sum of top-$k$ norms at various different scales, that interacts nicely with properties of random set cover instances. This construction is described in \Cref{sec:int-gap}, and it forms a key gadget in our following hardness result.

\begin{restatable}{theorem}{hardnessresult}
\label{thm2}
There is a universal constant $\delta>0$, such that any polynomial-time
 approximation algorithm for GMP has approximation ratio $\Omega(\log^{\delta} n)$ provided that $\emph{\textsf{NP}} \not\subseteq \emph{\textsf{ZTIME}}(n^{O(\log \log n)})$.
\end{restatable}
 
Our construction for this hardness result builds on the ideas of Lund and Yannakakis \cite{lund1994hardness}, who showed the $\Omega(\log n)$
hardness of Set Cover by a gap reduction from the Label Cover problem.
However, we require some additional ideas as reducing the Label Cover problem to a scheduling instance and exploiting the properties of the norm $\psi$ requires much more care. Specifically, even though our gadget in \Cref{thm1} has
the $\Omega((\log n)^{1/2})$ gap, embedding it into Label Cover imposes extra constraints on the number of labels in the Label Cover instance, and only leads to an $\Omega(\log^{\delta} n)$ hardness, for some constant $\delta>0$. 
Interestingly, this constant $\delta$ depends on the soundness parameter of label cover as a function of the number of labels, based on Raz's parallel repetition theorem \cite{raz1995parallel} and its subsequent improvements \cite{holenstein2007parallel,rao2008parallel}. 

\medskip

{\bf Remark.}
The constant $\delta$ can be computed explicitly, but we do not attempt to do this here. This construction is described in \Cref{sec: reduction}. We remark that there are extensive work on improving the soundness in PCP constructions as a function of the number of labels. The best known result in this direction is due to Chan \cite{Chan16} that achieves soundness roughly $L^{-1/2}$ for $L$ labels. However, Chan's result does not have perfect completeness and hence cannot be used in our constructions. Roughly speaking, this is because each job must be assigned to some machine (this is similar to the  reason that one requires perfect completeness in reducing label cover to set cover, as each element must be covered). 

\medskip

{\bf Remark.} In personal communication, Amey Bhangale has pointed out that in an unpublished manuscript, they can show that assuming the $2$-to-$2$ conjecture with perfect completeness, there is a label cover instance with $L$ labels that has perfect completeness and soundness $L^{-1/2}$. Using a such a label cover, our construction in \Cref{sec: reduction} would imply a hardness of $\Omega(\log^{1/8} n)$ in \Cref{thm2}.
We note that currently, proving the $2$-to-$2$ conjecture with perfect completeness remains open, and in particular the breakthrough results of Khot, Minzer and Safra \cite{KhotMS18} on the $2$-to-$2$ conjecture assume imperfect completeness.


