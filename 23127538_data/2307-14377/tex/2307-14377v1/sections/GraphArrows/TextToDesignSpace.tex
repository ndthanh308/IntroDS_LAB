\section{Text-To-Design-Space}
\label{sec:text_to_design_space}


%\begin{fi}
%\begin{lstlisting}

\hfill

% Figure environment removed
%\todo{how to make a vertical line between these minipages?}

%\paragraph{Overview}
%\begin{itemize}
%    \item Explain that one design is useful but in many cases you want to specify the design space.
%    \item This is in many ways implicit constraints.
%    \item Examples include parameterizations, graphs, grammars.
%    \item These design spaces are generators of individual designs from which an LLM can then intelligently sample.
%    \item Typical methods for design space generation are ML generative models
%\end{itemize}

A design is a sequence of construction operations which take input values and which modify the current state of the design.
These input values can directly be represented as numbers. For example in Fig.~\ref{fig:gear_model} (left), the design of a 3D gear is constructed by directly using 3D coordinates and dimensions.
While this representation has the merit of being direct, without any references to previous code, it does not expose the degrees of freedom of a design.
To modify the thickness of the gear, we have to modify several input values at once to obtain the desired 3D model.
The introduction of \emph{design parameters} in Fig.~\ref{fig:gear_model} (right) makes this change easier by modifying a single variable, namely \lstinline{gear_thickness}.
We call this representation a \emph{parametric design}.
Note that design parameters can be continuous or discrete, e.g. \lstinline{gear_thickness} or \lstinline{tooth_count} respectively.

To explore different design variations, either manually or automatically, having a parametric design is not enough.
We still need to know which specific values we can assign to the design parameters.
For this, we introduce lower and upper \emph{bounds} for each design parameter.
Each design parameter can take any value within its specific bounds.
Together, a parametric design and parameter bounds define a \emph{design space} which is the set of all possible design variations.

Design spaces are an import tool to understand what a design can accommodate for.
This is important for both the manual and automatic optimization of designs.
With this in mind, we want to investigate the following questions:
\begin{itemize}
    \item \textbf{Q1} Can GPT-4 create a design space from text?
    \item \textbf{Q2} Can GPT-4 create a design space from an existing design?
    \item \textbf{Q3} Can GPT-4 create a design space from multiple designs?
    \item \textbf{Q4} Can GPT-4 explore a given design space?
\end{itemize}

For each of these questions, we want to find out what is currently possible and what seems to be beyond its capabilities.

\subsection{Generating a Design Space from Text (Q1)}
In Sec.\ref{sec:text_to_design}, we showed that GPT-4 is capable of generating designs.
The next step towards generating a design space is to test if it can also generate \emph{parametric} designs.
To enforce the generation of parametric designs in our prompts, we ask it to \lstinline{explicitly use high-level design parameters} and to use \lstinline{as few variables as possible}.
It should be noted that GPT-4 often introduces variables to improve readability by itself, without explicitly being asked to do so.
However, we found that including this in our prompts \emph{always} resulted in parametric designs.

We also notice that when asking for a simple design and asking for a parametric design of the same object, there are generally fewer mistakes in the reuse of certain dimensions.
For example, in Fig.~\ref{fig:chair_dimensions}, at first, \gpt positions the backrest on top of the seat using the correct numerical values, but not for the correct dimensions.

% Figure environment removed

%% Figure environment removed
Whereas when asked for a parametric design, the use of \lstinline{width} and \lstinline{length} suffixes in the parameter names seem to be more consistently associated with the corresponding 3D axis.


%Wrong positioning of parts can also be frequently observed when asking for \emph{multi-part} models.
%While the semantic specification of part relationships is usually correct, it does not get translated correctly.
%Commonly found issues are wrongly positioned or oriented parts and intersecting 3D geometries.
%We tested this for OpenSCAD code (global coordinate system) and a sketch-extrude DSL (local coordinate systems).


%\begin{wrapfigure}{r}{0.5\textwidth}
% Figure environment removed
To generate a design space, we need parameter bounds.
When asked for lower and upper bounds for parameters, GPT-4 proposes bounds that are \lstinline{based on typical proportions} of the designed object.
This implies that the scale is often arbitrary but that bounds are semantically reasonable relative to each other.
For example, when asked to design a parametric car with exposed parameter bounds, GPT-4 returns lower and upper bounds and arguments for these bounds in terms of inequalities, see Fig.~\ref{fig:car_bounds}.
According to GPT-4, the width of the car body \lstinline{should be less than the length but larger than the height} and the radius for the cylindrical wheels \lstinline{should be less than the height of the car's body so the wheels don't exceed the height of the body}.
These constraints between design parameters can also be queried in the form of actual inequalities, which is useful for downstream optimization when combined with parameter bounds.


However, these bounds are based on semantic knowledge about the object and not on the geometric design sequence.
For example, for a pen holder, the angle of a rotated cylinder will get a lower bound of $45^{\circ}$ to prevent any pen from falling out, but not to prevent the 3D object from creating unwanted intersections with other parts.
Constraints in real-world design sequences often need to also consider purely geometric aspects of a design.


%\paragraph{Tasks}
%\begin{itemize}
%    \item Task 1.1: can you ask it to create a design where high-level editing parameters are automatically exposed. This implicitly creates aspects of a design space (it tells you degrees of freedom but not their bounds)
%    \item Task 1.2: can you ask it to create a design where high-level parameters are exposed and their ranges are also defined?  
%    \item Comparison: can you compare this task to generating a design without these exposed parameters? Does forcing GPT to expose the parameters help makes things more cohesive (e.g. things will be symmetric without it having to run all the computations to ensure it) ?
%\end{itemize}

%\paragraph{Results: Generating a Design Space from Text}
%\begin{itemize}
%
%    \item Task 1.1: Yes, we can ask it to create designs with exposed high-level editing parameters. This works for continuous and discrete parameters. Discrete parameters will be exposed in loops. (Chair example, temple pillar example). 
%    
%    \item Task 1.2: Yes, we can ask it for bounds which are linked to design parameters.
%    Interestingly, it will give reasons for these bounds by comparing a particular dimension with other dimensions.
%
%
%    \item Comparison: GPT-4 is often introducing variables itself. 50\% of the time no use of variables. Without variables, it can mistake what numbers it used for a previous operation, e.g. it confuses dimensions.
%\end{itemize}

\subsection{Generate a Design Space from an existing design (Q2)}
Given the current limitations of creating designs and design spaces from text prompts alone, it is interesting to understand how \gpt can create design spaces from existing designs, made by human designers.
Just as regular code, input designs for \gpt can vary in quality of semantic annotations and comments about what is being constructed.
%Input designs for GPT-4 come in a variety of quality and annotations, where the following presents a non-exhaustive list, going from weakly annotated to strongly annotated designs:
%\begin{enumerate}
%    \item Non-parametric design without any indication about the design object
%    \item Non-parametric design with an object name but without semantic information about the designed parts of the object
%    \item Non-parametric design with semantic object and part names
%    \item Parametric design with semantic object and part names 
%\end{enumerate}
For all of these inputs, we are interested in how easy it is for \gpt to create a design space, i.e., a parametric design with parameter bounds. 
We investigate how helpful semantic context is to parametrize designs.
%\question{do we consider constraints being part of a design space definition?}
For the prompts of the following experiments, we have found that we get more consistently a good parametrization when we include that it should \lstinline{expose high-level design parameters} while using \lstinline{as few variables as possible} and that it should \lstinline{keep the same program structure and the resulting input values to modeling functions}.
These constraints prevent it from slightly modifying operator input values to extract fewer design parameters.

%\begin{enumerate}
First, when given a design with no semantic context, we observe that \gpt exposes design parameters based on equivalence between numerical values and based on which design operators these values were used in.
For example, in Fig.\ref{fig:chair_parametrization}, it introduces a variable \lstinline{cube_size} which replaces the value \lstinline{19} which was used for both the chair's width and length.
For the mug in Fig.\ref{fig:mug_parametrization}, we can observe that the exposed variables also stay close to their original usage for a given geometric operator.

Second, we repeat the previous experiment with additional semantic context.
Providing \gpt with the name of the object that is being modeled proves useful for generating a parametric design.
We can see that now, design parameters get exposed which are semantically more useful for modifying the design.
For example, the cylinder radii in Fig.~\ref{fig:mug_parametrization} gets replaced for a parameter \lstinline{mug_wall_thickness} which controls the thickness of the mug by considering both radii jointly.
Also, some ambiguity caused by numerical equivalence can be resolved and produce more useful parametrizations.
In Fig.~\ref{fig:chair_parametrization}, the \lstinline{cube_size} from the previous parametrization without any semantic context, gets disentangled into a \lstinline{length} and a \lstinline{width} parameter, allowing to have more control over the shape.
This might prove especially useful in this case, since all the slats are associated to the chair's width and not its length.

% Figure environment removed

% Figure environment removed

Once parametrized, we can complete the design space by asking for parameter bounds, see Fig.~\ref{fig:mug_bounds}.
Again, notice how these bounds are \lstinline{somewhat arbitrary} and not based on the 3D design sequence.

While these results are encouraging, GPT-4 is easily confused by the final effect of a series of geometric transformations.
An example for this is the generated parameter \lstinline{handle_thickness} in Fig.~\ref{fig:mug_parametrization} which actually modifies the $y$ position of the handle.
Once again, it is limited by cases where geometric computation prevails over semantic reasoning.
%\afterpage{\FloatBarrier}



%\begin{itemize}
%     \item Task 2.1: you are given a single program with many parameters to describe a design and you want to abstract away a few high-level parameters and their ranges to  define the design space.  
%    \item Task 2.2: Given a set of examples, can it generate a program with high-level parameters where configurations of these parameters generates each of these examples. (like library learning) 
% 
%\end{itemize}
%\paragraph{Results: Generate a Design Space from Existing Designs}
%\begin{itemize}
%    \item Initial promising result for finding the total car length of a three-part car body. TODO: find ranges and more complex example.
%     \item Task 2.1: Yes, it can do that. OpenScad examples.
%\end{itemize}

\subsection{Can GPT-4 create a design space from multiple designs? (Q3)}
Design spaces based on a single design are useful to explore the family of possible shapes generated by varying the design parameters.

However, sometimes a designer might want to make more structural changes, inspired by another design of the same object class, they want to interpolate them.
Interpolating two designs can be difficult to achieve and there are a number of difficult questions which arise:
Are two designs modeled in a similar way?
Do they have the same dimensions and if not, how do you match the dimensions between two sub-designs?
Do you have to add extra operations to combine two parts?
Can you actually extract a subpart of an object from a design?
If you cannot exactly extract a sub-design, can you design something which is \textit{inspired} by two design sequences?
How do you accurately refer to two sub-designs in a text prompt?

To investigate if \gpt can help with design interpolation, we test three different design scenarios.
All of the designs were presented to \gpt in our sketch-based parametric CAD DSL, explained in Sec.~\ref{sec:text_to_design}.



% Figure environment removed

% Figure environment removed

%% Figure environment removed

First, we present it with two chairs which are modeled similarly, but the first chair has cylindrical legs and the second chair has a backrest with splats, see Fig.~\ref{fig:interpolation_chairs}.
In our prompt, we ask if it can \lstinline{mix these two designs to create a chair with cylindrical legs and splats in the back}.
The result can be seen in Fig.~\ref{fig:interpolation_chairs} (c).
It should be noted that variables in the code are descriptive, e.g. \lstinline{leg4_solid} and \lstinline{splat_3_sketch}, which helps provide semantic cues.
Also, in our designs, the first half of the code describes the construction of the seat and the legs and the second part describes the construction of the backrest.
This means that mixing these two designs comes down to replacing the second half of the first design with the second half of the second design.

% Figure environment removed
Next, we present \gpt with two designs of a temple, involving a different number of pillars, one with 4 pillars and one with 10 pillars on each side, see Fig.~\ref{fig:temple_interpolation}.
In our prompt, we ask it to \lstinline{design a temple with steps, a roof and 6 pillars on the left and right side}.
For this, \gpt has to find how these pillars have been modeled and how to model a varying number of pillars, given the two input examples.
The code for the design of the pillars did not contain any looping structures nor variables and it was more spread out throughout the program than in the chair example, to make it more challenging.
Despite these challenges, \gpt manages to extract the construction logic of the pillars and introduces variables and a looping structure to place them correctly, see Fig.~\ref{fig:temple_interpolation} (c).
Note that we have mentioned the steps and the roof in the prompt. We have noticed that without this reminder, it would solely focus on the construction of the pillars and forget about the rest of the design.

% Figure environment removed
Our last test is structurally more challenging.
We present \gpt with a design of a bicycle and a design of a quad-bike, see Fig.~\ref{fig:bicycle_interpolation}. 
The two designs differ not only by the number of wheels in the front and the back, but also by the construction of the bike forks.
In the case of the bicycle, the fork surrounds the wheel and in the case of the quad-bike, the wheels are connected by a horizontal bar to the vertical bar of the frame.
This makes the mixing of sub-designs more complex.
And indeed, when asked to design a tricycle, \gpt reasons correctly about the number of wheels in the front and the back, and where to find these structures.
It also adjusts the size of the quad-bike's vertical bar such that the two back wheels and the front wheel are on the same plane.
This was not the case for the quad-bike and the bicycle in the input designs.
But it does not succeed at extracting the complete fork from the bicycle design, as can be seen in Fig.~\ref{fig:bicycle_interpolation} (c). 
Note that this experiment was performed via a single prompt and \gpt would likely be able to copy the missing part via further interaction with the user.
%\wojciech{Is it possible to fix this with more prompt engineering?} \FH{At the time of the experiments, I worked in a single prompt fashion and tried multiple times with different prompts to make it work. But it never would. But I think that it would be able to fix it in an iterative discussion.}

We find these examples promising, as they show how \gpt manages to combine its general knowledge about part relationships and its coding abilities.
One of the observed limitations is the ability to extract long sub-sequences and to detect which other parts are still important for plausible interpolation.

%\todo{}
%\paragraph{Generate Design Variations}
%\begin{itemize}
%    \item Given a design and a textual description of a modification, can you find that modification? This is hard because you don't really know how the design can be modified and what are the constraints. -> remove the armrests from the chair?  
%    \item If you have a design space -> design variations happen by simply searching over that space to find a match. gpt can typically do this correctly because it doesn't have to worry about constraints. 
%\end{itemize}
%

\subsection{Exploration of a given Design Space (Q4)}
A design space is conceptually useful to reliably generate variations of a given design.
However, coming up with parameters which represent \textit{meaningful} design variations can be a time-consuming iterative process.

To investigate if \gpt can help with this task, we perform the following experiment.
We present it with a parametric design of a Lego brick, see Fig.~\ref{fig:lego_parametric_design}.
Then, we ask it to generate \lstinline{parameter bounds} and \lstinline{parameter constraints}.
Interestingly, \gpt generated the non-trivial constraint that the length and width of the brick should be multiples of 3.
We ask it to use the design space to \lstinline{come up with 10 different parameter settings which correspond to meaningful lego bricks}.
Finally, it should \lstinline{give each variation a name}, see Fig.~\ref{fig:lego_exploration}.

% Figure environment removed
%\afterpage{\FloatBarrier}

% Figure environment removed
We can observe that the proposed parameter settings respect the previously generated bounds and constraints and that they lead to distinct 3D models, for which it generates plausible semantic labels.


\subsection{Discussion}

In this section, we summarize the key capabilities (C), limitations (L), and dualisms (D) specific to the creation and manipulation of design spaces.

\noindent \textbf{C.1 Extensive Knowledge Base in Design and Manufacturing:} 
We observe that we can leverage \gpt's semantic knowledge base to create parameters, bounds and constraints for text-based designs and already existing designs.
Additionally, \gpt can be useful for finding semantically meaningful design variations in a given design space.

\noindent \textbf{C.3 Modularity Support:} 
We observe that \gpt can interpolate existing designs by extracting and adapting sub-designs based on their program representations.
Interestingly, even when designs are not presented in a modular fashion, it tries to recognize and abstract sub-modules in input designs.

\noindent \textbf{L.1 Reasoning Challenges:} 
The design spaces created by \gpt are based both on semantic knowledge and on code interpretation. 
However, it does not take into account geometric considerations, such as intersecting or non-connecting parts.
As a result, generated parameter bounds can create non-valid geometry and it has proven difficult to make \gpt correct these.
However, in general the generation of valid parameter bounds and constraints is a difficult problem for which mainly approximations have been proposed \cite{mathur2021constraint}.

\noindent \textbf{L.3 Scalability:} 
The interpolation task revealed that \gpt has limited capabilities to infer what parts of a design should be linked to a semantic part specified in a prompt. 
One promising future direction to manage increasingly complex designs is to make them increasingly modular by adding intermediate levels of abstraction.

\noindent \textbf{D.1 Context Information:}
We observe that the generation of correct parametric designs and the reparametrization of already existing designs can be improved by providing semantic cues, such as the name of the modeled object.
As seen in Sec.\ref{sec:text_to_design}, \gpt creates designs which contain a lot of semantic information and it generally performs even better when using meaningful variable names.
Leveraging this aspect in the generation of design spaces and throughout other aspects in the design process should prove extremely useful.

% \afterpage{\FloatBarrier}
%\noindent \textbf{C.1 Generation of parametric designs:} 
%We observe that \gpt is able to generate parametric designs and that explicitly introducing parameters increases the chances of generating correct designs.
%Design parameters can be continuous or discrete.
%In the latter case, they will be programmed via loop structures.
%
%\noindent \textbf{C.2 Generation of bounds and constraints:} 
%We observe that \gpt can generate parameter bounds and constraints which are based on general semantic knowledge about the object.
%
%\noindent \textbf{C.3 Parametrization:} 
%We observe that \gpt can be useful for taking a design created in a modeling software and augmenting it with a design space.
%
%\noindent \textbf{C.4 Interpolation:} 
%We observe that \gpt's capability to parse code and to reason semantically can be used to manipulate multiple existing designs and to create new ones.
%
%\noindent \textbf{C.5 Exploration:}  
%We observe that \gpt can be useful for starting the design process and overcoming the blank canvas by generating multiple, semantically meaningful design variations.
%
%\noindent \textbf{L.1 Geometric reasoning:}
%The design spaces created by \gpt are based both on semantic knowledge and on code analysis.
%However, they do not consider geometric considerations, such as intersecting or non-connecting parts.
%
%\noindent \textbf{L.2 Linking semantic knowledge to parts:}
%The interpolation task revealed that \gpt has limited capabilities to infer what parts of a design should be linked to a semantic part specified in a prompt.
%
%\noindent \textbf{O.1 Linking geometry and semantics:}
%One major opportunity for improving the generation of design spaces and design variations is to enforce geometric reasoning.


%% Figure environment removed

%\begin{itemize}
%    \item Given a design space (e.g. the output of the previous task) can it explore it given high-level prompts? 
%   \item Can GPT interpolate 2 designs? How does the interpolation task compare to Task 2.2? 
%
%\end{itemize}
%\textbf{Old description of the section}
%
%\paragraph{Parametric Designs}
%How to make one design and how add parameters.
%How to create design variations based on these parameters.
%
%Allan's example could go here:
%Given a code example for a quadcopter, give me a design for hexacopter.
%
%\paragraph{Interpolation (and extrapolation) between designs}
%Given two designs (specified using code), can you mix these two designs?
%Given that you have two types of chairs, can you get something that is in between?  Examples include a square-shaped back and a circle-shaped back, interpolating smoothly with rounded corners.
%
%Can you interpolate over discrete parameters; e.g. Given a table with 10 legs, and a table with 4 legs, can you generate tables with 5, 6, 7, 8, and 9 legs?  You'd want them to be constrained such that they would be placed concentrically in a circle.
%
%\paragraph{Specifying design spaces using grammar}
% Show how to specify a design space using a grammar. 
% Show how to create regular context free grammars. Show shape grammars.
%
% Show examples using robots/graphs. Show molecules as well.