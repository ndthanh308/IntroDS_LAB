% \item \textbf{Q2} Is \gpt able to incorporate abstractions used by human designers, such as modular (de)composition?

As we have seen from previous examples, \gpt is inclined to use some abstractions like variables by default.
It is also clear that \gpt is well suited to the use of modular or hierarchical design, as in the case of the pre-fabricated L-brackets that it was able to instantiate several copies of, and distribute throughout a design. 
However, there are often instances where a user might want to impose their own specific modules -- for example, a certain hierarchical grouping may facilitate easier debugging or cleaner code.

To test \gpt's abilities in this area, we revisit the cabinet example, and try to modify it such that it contains multiple shelves. Because we have already incorporated pre-fabricated brackets, this modification is non-trivial, as \gpt must instantiate and position the appropriate number of shelves \textit{and} all associated support brackets. 
We began by directly asking \gpt to make this modification on top of the existing code, by generating two evenly spaced shelves within the cabinet instead of one. 
\gpt correctly identifies the elements which must be duplicated, and it instantiates the correct number of them. 
However, it is unable to correctly adjust the position of each module; after the initial request, neither the shelves nor the brackets were in reasonable locations. 
It took 4 additional user prompts to correct the relative positions of these components. 
After this correction, \gpt did seem able to generalize its logic directly to generate cabinets with a varying number of shelves. 
However, the code itself is fairly convoluted.

To avoid these issues, it may be more natural to consider a shelf with its appropriate supporting brackets as a single module.
This way, the entire ``subassembly'' could be instantiated and positioned as a unit on future calls. 
We asked \gpt to implement this plan, by requesting the creation of a module named \lstinline{supportedShelves()}, which instantiates and appropriately positions a shelf and its associated support brackets within the design.
Then, we asked \gpt to refactor the original script such that it used the new module to generate a cabinet with two evenly-spaced shelves.
The initial response had a minor compilation error, a shelf tolerance issue, and a bracket alignment issue, as before, but each of these issues were immediately corrected after a single user prompt. 

Overall, the approaches resulting from both experiments seem equally effective and flexible once they have been fine-tuned. 
Thus, we conclude that \gpt is able to effectively create and use modules, whether they are explicit (\eg, in the form of a function, as in the second experiment) or implicit (\eg, in the form of a for-loop, as in the first experiment).
However, it seems as if the explicit module made it slightly easier for \gpt to reason about a challenging alignment problem.
Moreover, it is useful to know that users can effectively request this kind of hierarchical refactoring, as most human programmers/designers would generally find it easier to reason over a function in this scenario. 
% \todo{(liane) generate figure with the incorrect/corrected placements}