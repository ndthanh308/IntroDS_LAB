%% Text to Design: robots from graph description
% \team{Allan}

% \todo{describe the tie to graph-based design, and also how this representation is different from URDF discussed before.}
% \liane{We also want to reduce the amount of direct copy/paste chat history. Can you summarize the chats' key processes/challenges/successes in text, and reduce the chat history to illustrate only a few specific points with visualizations? The full chat history should be in the github repo, and you can include some longer snippets in the appendix too, if you like.}

While designing an entire robot end-to-end using LLMs may not be feasible, we find that \gpt has the ability to reason about the spatial layout of robot components. These spatial layouts are naturally represented as graphs where the nodes are components and edges are connections between them. Unlike URDF, this representation is more general and is applicable in domains outside of simulation.

To generate robot design graphs using \gpt, we first need a text-based graph representation. Our first approach involved asking \gpt to output the popular GraphViz format. While convenient, this format makes it difficult for \gpt to provide metadata for each part (such as motor torque, size) in a format usable by downstream applications. Instead, we take advantage of \gpt's ability to generate Python code that conforms to a provided domain-specific language (DSL). The full DSL is detailed in \appref{sec:appx_graph_robots}. 

When prompted with a small DSL embedded in Python, \gpt is able to write code that selects and places robot components at a high level of abstraction. By supplying a function that translates components in three-dimensional space, we can extract \gpt's concept of each component's position relative to the others. 
% \adriana{This is way too big, please crop also please discuss the limitaitons}

% Figure environment removed

In this example, we ask \gpt to generate a humanoid robot using the provided functions. \gpt makes appropriate calls to \texttt{add\_link} to create nodes in the design graph, \texttt{add\_joint} to create edges between them, and \texttt{translate} to establish their relative positions.

We manually implement the functions described in the prompt in order to visualize the resulting robot topology. The arms are positioned beside the torso, the legs are positioned below, and the head rests on top as expected for a humanoid robot.

We saw similar success when asking \gpt to construct a snake robot, car robot, and scorpion robot. When requesting a robot dog, however, \gpt only adds two legs initially. Specifying a ``robot dog with four legs'' was necessary to obtain the expected behavior. We also encountered difficulties when attempting to obtain a more detailed design for the robot dog. Asking for a ``robot dog with four legs, two links per leg'' produced a graph with two nodes per leg, but \gpt did not position them relative to each other.