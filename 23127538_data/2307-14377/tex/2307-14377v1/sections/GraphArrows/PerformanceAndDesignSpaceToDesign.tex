\section{Performance-and-Design-Space To Design (Liang and Andy)}

While generative algorithms can produce candidates for designs, there is no guarantee concerning their quality.  Computational design or inverse design is focused on producing designs that are, by some metric, as close to optimal as possible, given the constraints.  
Put in the vocabulary of the preceding sections, given a design space and performance metrics (which can define values to be optimized or constraints to be satisfied), which design in that space satisfies the given constraints and provides optimal performance?

A design generated by an LLM must therefore satisfy several constraints: \textit{1)} it must be valid,  \textit{2)}, \textit{3)} it must be performant, it must satisfy design constraints, and, in the context of manufacturing \textit{4)} it must be buildable.  With \textit{3) and 4)}, we note the persistent reality of the sim-to-real gap --- objective and constraint values may differ \textit{in silico} and \textit{in situ}.  Basic challenges involve specifications of the inverse problem to an LLM (much of which was described in previous sections), as well as generation of an efficacious algorithm for design optimization.

While LLMs cannot natively search for optimal solutions to a novel problem, they can make educated starting guesses and formulate code to be executed by function calling.  Much of this section is thus focused on prompting LLMs to generate meaningful code for problems dependent on aspects such as their parameterization support (\textit{e.g.} continuous versus discrete domains), performance objective landscape, or fabrication constraints.  

Real-world problems introduce nuanced challenges, including exploring over multiple competing objectives, difficult-to-specify objectives (such as aesthetics and objectives that depend on long-term use), and an evolving landscape of emerging methods that an LLM may not know about.  In this context, we could consider whether LLMs can propose novel strategies that free  designers from some of the typical burdens associated with the optimization pipeline.

With these considerations, we aim to investigate the following questions:

\textbf{Q1} Can GPT identify optimal designs when a design space and performance metric are provided?

 \textbf{1.1} When can GPT solve a problem analytically, and when does it need to resort to using an outside tool? (\textit{i.e.} a programmed algorithm). 
% table example 
 
 \textbf{1.2} Can GPT choose reasonable algorithms for different types of supports for constraints, objectives, and decision spaces (\textit{e.g.} continuous, discrete, binary, \textit{etc.}
% 3D printing example
% Robotics example


\textbf{Q2} Can this tool support optimization in contexts that require additional knowledge?

\textbf{2.1} Can GPT assist designers in navigating the landscape of possible trade-offs when multiple conflicting objectives are present?




\textbf{2.2} Can GPT support design exploration and optimization when the design 
space is not properly defined or fully bounded?

\textbf{2.3} Can GPT support design optimization when objectives are not easily quantifiable?

\subsection{GPT: Analytical vs. Outside Tools (Q1.1)}
We know that GPT has the ability to reason about many mathematical operations, including both algebra and calculus, which is sufficient to solve many real-world engineering problems.  We say reasoning, here, because it is not obvious that GPT is truly performing the operations; and, as we'll see, this often does yield mathematical errors.  Still, it is reasonable to wonder if its own internal reasoning is sufficient (perhaps, when augmented by search or a plugin), and when it one must resort to code and external libraries.  Each of these approaches has its own pitfalls that suggest caution for developers.

Consider the following example of maximizing the stability of a table.  For those unfamiliar, an object is statically stable when its center of mass lies within its support polygon.  One considers stability of an object to be maximized when it is still stable under as large of a perturbation as possible.  In principle, that typically means two things: 1) moving the center of mass as far away from the boundary of the support polygon as possible, 2) decreasing the experienced motion (typically caused by gravitational torquing) when perturbed.  

In the following example, the Wolfram plugin is enabled, which GPT can selectively call.

TODO: fix this math

% \begin{enumerate}
%     \item User:
%     \begin{lstlisting}
%     Let's say I want to design a table with four legs and a top.  Assume that the four legs are radially symmetric, and the top is a cylinder and the legs are cylinders.  Can you give me the equation for the center of mass of the table in x, y, and z, as a function of the natural parameters of the primitives?
%     \end{lstlisting}
%     \item GPT:
%     \begin{lstlisting}
%         Sure, let's denote the following parameters:

% �
% R is the radius of the table top.
% �
% r is the radius of each leg.
% �
% H is the height of the table top.
% ℎ
% h is the height of each leg.
% �
% ρ is the uniform density of the material the table is made of.
% The mass of the table top 
% �
% �
% �
% �
% M 
% top
% ​
%   and each leg 
% �
% �
% �
% �
% M 
% leg
% ​
%   can be calculated using the volume of a cylinder 
% �
% =
% �
% �
% 2
% ℎ
% V=πr 
% 2
%  h and the definition of density 
% �
% =
% �
% �
% ρ= 
% V
% M
% ​
%  , which gives us:

% �
% �
% �
% �
% =
% �
% �
% �
% 2
% �
% M 
% top
% ​
%  =ρπR 
% 2
%  H
% �
% �
% �
% �
% =
% �
% �
% �
% 2
% ℎ
% M 
% leg
% ​
%  =ρπr 
% 2
%  h
% The total mass of the table 
% �
% M is the mass of the top plus the mass of four legs:

% �
% =
% �
% �
% �
% �
% +
% 4
% �
% �
% �
% �
% M=M 
% top
% ​
%  +4M 
% leg
% ​
 
% The center of mass of the table in the z-direction 
% �
% �
% �
% z 
% cm
% ​
%   can be calculated by taking the weighted average of the centers of mass of the top and the legs. The center of mass of a cylinder is at its midpoint, so for the top it's at 
% �
% 2
% 2
% H
% ​
%   and for the legs it's at 
% ℎ
% 2
% 2
% h
% ​
%  . This gives us:

% �
% �
% �
% =
% 1
% �
% (
% �
% �
% �
% �
% �
% 2
% +
% 4
% �
% �
% �
% �
% ℎ
% 2
% )
% z 
% cm
% ​
%  = 
% M
% 1
% ​
%  (M 
% top
% ​
  
% 2
% H
% ​
%  +4M 
% leg
% ​
  
% 2
% h
% ​
%  )
% Since the table is radially symmetric, the center of mass in the x and y directions will be at the origin (0,0):

% �
% �
% �
% =
% �
% �
% �
% =
% 0
% x 
% cm
% ​
%  =y 
% cm
% ​
%  =0
% So the center of mass of the table is at (0, 0, 
% �
% �
% �
% z 
% cm
% ​
%  ).
%     \end{lstlisting}
% \item: User:
% \begin{lstlisting}
%     Ok.  Let's say the bounds for the height of the legs are between 1cm and 3 cm, and the height of the table is between 1 and 5 cm.  Show me an equation that would measure static stability, and find the minimum of that equation.
% \end{lstlisting}
% \item: GPT:
% \begin{lstlisting}
%     The static stability of a table can be quantified by the height of the center of mass. The lower the center of mass, the more stable the table is. Therefore, we can use the equation for 
% �
% �
% �
% z 
% cm
% ​
%   as our measure of static stability.

% To find the minimum of this equation, we can treat it as an optimization problem. We want to minimize 
% �
% �
% �
% z 
% cm
% ​
%   subject to the constraints 
% 1
% ≤
% ℎ
% ≤
% 3
% 1≤h≤3 and 
% 1
% ≤
% �
% ≤
% 5
% 1≤H≤5.

% The equation for 
% �
% �
% �
% z 
% cm
% ​
%   is:

% �
% �
% �
% =
% 1
% �
% (
% �
% �
% �
% �
% �
% 2
% +
% 4
% �
% �
% �
% �
% ℎ
% 2
% )
% z 
% cm
% ​
%  = 
% M
% 1
% ​
%  (M 
% top
% ​
  
% 2
% H
% ​
%  +4M 
% leg
% ​
  
% 2
% h
% ​
%  )
% Substituting the expressions for 
% �
% �
% �
% �
% M 
% top
% ​
%   and 
% �
% �
% �
% �
% M 
% leg
% ​
%   we get:

% �
% �
% �
% =
% 1
% �
% �
% �
% 2
% �
% +
% 4
% �
% �
% �
% 2
% ℎ
% (
% �
% �
% �
% 2
% �
% �
% 2
% +
% 4
% �
% �
% �
% 2
% ℎ
% ℎ
% 2
% )
% z 
% cm
% ​
%  = 
% ρπR 
% 2
%  H+4ρπr 
% 2
%  h
% 1
% ​
%  (ρπR 
% 2
%  H 
% 2
% H
% ​
%  +4ρπr 
% 2
%  h 
% 2
% h
% ​
%  )
% Simplifying, we get:

% �
% �
% �
% =
% �
% 2
% �
% 2
% +
% 2
% �
% 2
% ℎ
% 2
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% z 
% cm
% ​
%  = 
% R 
% 2
%  H+4r 
% 2
%  h
% R 
% 2
%  H 
% 2
%  +2r 
% 2
%  h 
% 2
 
% ​
 
% Since 
% �
% R, 
% �
% r, and 
% �
% ρ are constants, we can treat this as a function of 
% ℎ
% h and 
% �
% H only:

% �
% (
% ℎ
% ,
% �
% )
% =
% �
% 2
% �
% 2
% +
% 2
% �
% 2
% ℎ
% 2
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% f(h,H)= 
% R 
% 2
%  H+4r 
% 2
%  h
% R 
% 2
%  H 
% 2
%  +2r 
% 2
%  h 
% 2
 
% ​
 
% We can find the minimum of this function within the given bounds using calculus or numerical optimization methods. However, because this is a complex optimization problem, it would be best to use a numerical method.

% Let's use the Wolfram Language to find the minimum of this function within the given bounds.

% Used Wolfram
% I apologize for the inconvenience. It seems that the computation took longer than expected. This is a complex optimization problem that might require a significant amount of computational resources. Let's try a different approach.

% We can make a reasonable assumption that the minimum of the function will occur at the boundary of the constraints. This is often the case for physical systems. Therefore, we can evaluate the function at the four corners of the parameter space:

% �
% (
% 1
% ,
% 1
% )
% f(1,1)
% �
% (
% 1
% ,
% 5
% )
% f(1,5)
% �
% (
% 3
% ,
% 1
% )
% f(3,1)
% �
% (
% 3
% ,
% 5
% )
% f(3,5)
% Let's calculate these four values.

% Used Wolfram
% The four values of the function at the corners of the parameter space are:

% �
% (
% 1
% ,
% 1
% )
% =
% 2
% �
% 2
% +
% �
% 2
% 4
% �
% 2
% +
% �
% 2
% f(1,1)= 
% 4r 
% 2
%  +R 
% 2
 
% 2r 
% 2
%  +R 
% 2
 
% ​
 
% �
% (
% 1
% ,
% 5
% )
% =
% 2
% �
% 2
% +
% 25
% �
% 2
% 4
% �
% 2
% +
% 5
% �
% 2
% f(1,5)= 
% 4r 
% 2
%  +5R 
% 2
 
% 2r 
% 2
%  +25R 
% 2
 
% ​
 
% �
% (
% 3
% ,
% 1
% )
% =
% 18
% �
% 2
% +
% �
% 2
% 12
% �
% 2
% +
% �
% 2
% f(3,1)= 
% 12r 
% 2
%  +R 
% 2
 
% 18r 
% 2
%  +R 
% 2
 
% ​
 
% �
% (
% 3
% ,
% 5
% )
% =
% 18
% �
% 2
% +
% 25
% �
% 2
% 12
% �
% 2
% +
% 5
% �
% 2
% f(3,5)= 
% 12r 
% 2
%  +5R 
% 2
 
% 18r 
% 2
%  +25R 
% 2
 
% ​
 
% The minimum of these four values will give us an approximation of the minimum of the function within the given bounds. However, please note that this is an approximation based on the assumption that the minimum occurs at the boundary, which might not be the case. For a more accurate result, a more sophisticated numerical optimization method would be needed.
% \end{lstlisting}
% \end{enumerate}

While the Wolfram plugin was a natural choice for solving what appears to be a more simple analytical optimization problem, not enough time was alotted for it to complete the calculation.  (TODO: can we finish it ourselves on the website?)  Although it might seem like it would be trivial to provide Wolfram more time to complete the computation, in practice, the user has no feedback on how long the computation would take.  It is unreasonable to ask a user to wait for long periods of time without feedback, and it is unlikely that all computations would be able to provide meaningful feedback about progress.

GPT reasons that the optimum value will occur near the boundary of the constraints.  While this is correct, it does not prove its claim.  However, with this reasoning in tow, it then successfully uses the Wolfram Plugin to correctly compute the equations for the extremal values, which depend on $r$ and $R$.  Despite this, it fails to realize that certain solutions dominate others, and does not prune out bad candidates.

In follow-up, GPT is asked to perform the same optimization task but using code, choosing a reasonable, easily accessible (though not state-of-the-art) solver for the continuous valued problem) --- namely, L-BFGS-B, a second-order gradient-based optimizer.  It does not realize, however, that it can expedite the computation by providing explicit gradient computations, until prompted.  This is an issue for performance, because not all users will be intimately familiar with all optimization libraries, and they may not realize that by providing explicit gradients, the computation can be expedited.  GPT also does not elect to make use of Wolfram or Autodifferentiation for the gradient calculation, which could, in practice, lead to errors.

% \begin{enumerate}
%     \item User:
%     \begin{lstlisting}
%         Since Wolfram is having trouble, can you instead provide me code to find the optimum in the general case?
%     \end{lstlisting}
%     \item GPT:
%     \begin{lstlisting}
%         Sure, I can provide you with a Python code snippet that uses the scipy.optimize library to find the minimum of the function. This library provides several methods for function optimization.

% Here's a Python code snippet that defines the function and uses the scipy.optimize.minimize function to find its minimum within the given bounds:

% python
% Copy code
% import numpy as np
% from scipy.optimize import minimize

% # Define the function
% def f(x, r, R):
%     h, H = x
%     return (R**2 * H**2 + 2 * r**2 * h**2) / (R**2 * H + 4 * r**2 * h)

% # Define the bounds and initial guess
% bounds = [(1, 3), (1, 5)]
% x0 = [2, 3]  # initial guess

% # Define the parameters r and R
% r = 0.1  # replace with the actual value
% R = 1.0  # replace with the actual value

% # Find the minimum of the function
% res = minimize(f, x0, args=(r, R), bounds=bounds)

% print("The minimum of the function is at h = {:.2f} cm, H = {:.2f} cm".format(*res.x))
% In this code, x0 is the initial guess for the values of h and H. The bounds variable defines the lower and upper bounds for h and H. The args parameter of the minimize function is used to pass the parameters r and R to the function f. The result of the minimize function is an object that contains information about the optimization result, including the values of h and H at the minimum (res.x).

% Please replace r and R with the actual values for the radius of the legs and the table top, respectively.
%     \end{lstlisting}
%     \item User:
%     \begin{lstlisting}
%         Which optimization method does minimize use?
%     \end{lstlisting}
%     \begin{lstlisting}
%     \item GPT:
%     The scipy.optimize.minimize function in Python uses the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm by default for unconstrained problems. The BFGS method is a quasi-Newton method that uses function values and gradients to build up a picture of the surface to be optimized.

% However, when bounds are provided (as in your case), minimize defaults to the Limited-memory BFGS (L-BFGS-B) method. The L-BFGS-B method is a modification of the BFGS method that is more suitable for problems with many variables and constraints on the variable values.

% The method to be used can be specified using the method parameter of the minimize function. Other methods available include 'Nelder-Mead', 'Powell', 'CG', 'TNC', 'COBYLA', 'SLSQP', and others. The choice of method depends on the nature of the problem (e.g., whether it's constrained, whether the function is smooth, whether gradients are available, etc.).
% \end{lstlisting}
%     \item User: 
%     \begin{lstlisting}
%         What do you think is the best choice here?
%     \end{lstlisting}
%     \item GPT:
%     \begin{lstlisting}
%         Given that we have bounds on the variables, the Limited-memory BFGS (L-BFGS-B) method is a good choice for this problem. L-BFGS-B is an optimization algorithm in the family of quasi-Newton methods that approximates the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm using a limited amount of computer memory. It's a popular choice for optimization problems where there are constraints on the parameters.

% The L-BFGS-B method is particularly suitable for high-dimensional problems, and it can handle the bounds on the parameters efficiently. It also doesn't require the computation of the second derivatives (the Hessian matrix), which can be computationally expensive for complex functions.

% Therefore, using the L-BFGS-B method with the scipy.optimize.minimize function, as in the provided Python code, would be a good approach for finding the minimum of the function within the given bounds.
%     \end{lstlisting}
%     \item User:
%     \begin{lstlisting}
%         Can you compute expressions for the gradients of this problem, and provide code that uses them to accelerate the L-BFGS-B call?
%     \end{lstlisting}
%     \item GPT:
%     \begin{lstlisting}
%         Sure, the gradient of a function is a vector of its partial derivatives with respect to each of the variables. In this case, the gradient of the function 
% �
% (
% ℎ
% ,
% �
% )
% =
% �
% 2
% �
% 2
% +
% 2
% �
% 2
% ℎ
% 2
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% f(h,H)= 
% R 
% 2
%  H+4r 
% 2
%  h
% R 
% 2
%  H 
% 2
%  +2r 
% 2
%  h 
% 2
 
% ​
%   is a vector with two components: the partial derivative with respect to 
% ℎ
% h and the partial derivative with respect to 
% �
% H.

% Let's compute these partial derivatives:

% ∂
% �
% ∂
% ℎ
% =
% 4
% �
% 2
% ℎ
% (
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% )
% −
% 2
% �
% 2
% ℎ
% 2
% (
% 4
% �
% 2
% )
% (
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% )
% 2
% ∂h
% ∂f
% ​
%  = 
% (R 
% 2
%  H+4r 
% 2
%  h) 
% 2
 
% 4r 
% 2
%  h(R 
% 2
%  H+4r 
% 2
%  h)−2r 
% 2
%  h 
% 2
%  (4r 
% 2
%  )
% ​
 
% ∂
% �
% ∂
% �
% =
% 2
% �
% 2
% �
% (
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% )
% −
% �
% 2
% �
% 2
% (
% �
% 2
% )
% (
% �
% 2
% �
% +
% 4
% �
% 2
% ℎ
% )
% 2
% ∂H
% ∂f
% ​
%  = 
% (R 
% 2
%  H+4r 
% 2
%  h) 
% 2
 
% 2R 
% 2
%  H(R 
% 2
%  H+4r 
% 2
%  h)−R 
% 2
%  H 
% 2
%  (R 
% 2
%  )

 
% We can then provide these gradients to the minimize function to accelerate the optimization process. Here's the updated Python code:

% python
% Copy code
% import numpy as np
% from scipy.optimize import minimize

% # Define the function
% def f(x, r, R):
%     h, H = x
%     return (R**2 * H**2 + 2 * r**2 * h**2) / (R**2 * H + 4 * r**2 * h)

% # Define the gradient of the function
% def grad_f(x, r, R):
%     h, H = x
%     dfdh = (4 * r**2 * h * (R**2 * H + 4 * r**2 * h) - 2 * r**2 * h**2 * (4 * r**2)) / (R**2 * H + 4 * r**2 * h)**2
%     dfdH = (2 * R**2 * H * (R**2 * H + 4 * r**2 * h) - R**2 * H**2 * (R**2)) / (R**2 * H + 4 * r**2 * h)**2
%     return np.array([dfdh, dfdH])

% # Define the bounds and initial guess
% bounds = [(1, 3), (1, 5)]
% x0 = [2, 3]  # initial guess

% # Define the parameters r and R
% r = 0.1  # replace with the actual value
% R = 1.0  # replace with the actual value

% # Find the minimum of the function
% res = minimize(f, x0, args=(r, R), jac=grad_f, bounds=bounds)

% print("The minimum of the function is at h = {:.2f} cm, H = {:.2f} cm".format(*res.x))
% In this code, jac=grad_f tells minimize to use the function grad_f to compute the gradient of the function at each step. This can significantly speed up the optimization process, especially for complex functions or large problems.
%     \end{lstlisting}
% \end{enumerate}

In later sections, we will demonstrate how GPT struggles to solve a (much) more difficult version of this optimization problem.

There is one more pitfall.  If users do not prompt GPT to explicitly show its work, it may resort to ``common-sense'' reasoning about a problem.  Although this could be correct, it provides no certificate to a user.  GPT does just that, in an alternate second query in this chain, showin in Listing TODO.

\iffalse

\begin{enumerate}
    \item User:
    \begin{lstlisting}
         Ok.  Let's say the bounds for the height of the legs are between 1cm and 3 cm, and the height of the table is between 1 and 5 cm.  Please optimize the parameters such that the table is as statically stable as possible, and explain the process.
    \end{lstlisting}
    \item GPT:    
    \begin{lstlisting}
   
ChatGPT
The static stability of a table is primarily determined by its center of mass and the area of its base. A table is more stable if its center of mass is lower and the area of its base is larger.

In this case, the table's base is defined by the placement of the four legs. If we assume that the legs are placed at the maximum radius from the center of the table, the base area is maximized and thus the stability is also maximized.

The center of mass is determined by the heights of the table top and the legs. To lower the center of mass, we want to minimize the height of the table top and maximize the height of the legs.

Given the bounds you provided, the optimal parameters for the table would be:

Height of the legs (h): 3 cm
Height of the table top (H): 1 cm
This configuration maximizes the height of the legs and minimizes the height of the table top, thus lowering the center of mass and increasing the table's static stability.

Please note that this analysis assumes that the table is on a flat surface and that the weight distribution in the table top is uniform. If the weight distribution is not uniform (for example, if there is a heavy object on one side of the table), the table may still tip over.

Also, this analysis does not take into account the dynamic stability of the table, which involves how the table responds to forces and movements. For example, a table with very tall, thin legs may be statically stable but not dynamically stable.

Finally, this analysis assumes that the table is made of a uniform material. If the table top is made of a heavier material than the legs, the center of mass will be higher and the table will be less stable.
    \end{lstlisting}
\end{enumerate}
\fi

There are problems in which the usual pitfalls regarding GPT arise --- if it is difficult to find a library to solve a particular task, it might give up or try writing its own code; if the code is detail-heavy, it may be too difficult for GPT to write correctly and the solution may be incorrect; if a library does exist but it is uncommonly used, it may give incorrect instructions on how to install that library; or, in some cases, it may hallucinate a library.


TODO: Add renders

\paragraph{ \textbf{Q1.2} Can GPT reason about different problem types and choose a correct solver? }

GPT manages to be extremely robust in reasoning about problems and choosing an adequate solver for that problem.  In cases where a more sophisticated algorithm was needed, it tended to choose at least the correct algorithm class, but was not always aware of the best version or implementation.  A notable example is in optimizing robot topologies for ground locomotion, where GPT identified an evolutionary algorithm as an effective optimization method, but did not choose any state-of-the-art specific algorithms or implementations.

Below we highlight some different classes of problems:

TODO:
Format as: Name, Search Space, Constraint Space, Objective Space, Other considerations, Chosen optimization method.

-Robot Arm optimization - Continuous Search Space, Reachability (continuous) constraint, Continuous Objective, 2nd order gradient-based optimization.

-Robot topology design - Graph-search space, No constraints, objective continuous, TODO, Evolution optimization method

-Printing Parameters - Continuous search space, bound constraints, objective continuous, very expensive evaluation function, Bayesian Optimization

-Multicopter Optimization - Continuous search space, bound constraints, objective continuous, requires simulation in the loop and knowledge of quadcopter materials, Grid Search

-Mixed Optimization?  Bookshelf. TODO

-Logical Constraints, continuous objective --- Robot motion planning TODO


TODO: Add renders

% Figure environment removed


\subsection{Can this tool support optimization in contexts that require additional knowledge?}

In some cases, non-expert, and even some expert users may find that a given inverse design problem has nuances that they have not considered.  In this section, we examine how LLMs can help less experienced users to specify and navigate inverse design problems.  Further, we demonstrate the ability of LLMs to aid in generating design specifications that are difficult to specify or quantify mathematically.



\textbf{2.1} Can GPT assist designers in navigating the landscape of possible trade-offs when multiple conflicting objectives are present?

Listing TODO shows the design process of a chair.  The first query demonstrates the breadth of knowledge of GPT in design considerations, as GPT proposes a list of facets one must care about in furniture construction.  From that list, the user chooses two design criteria, and asks GPT to generate a parameterized chair design by selecting important design parameters as well creating a parameterized template.  When asked how to optimize for both design parameters (without hinting at the need for tradeoffs), GPT informs the user that this is a multi-objective design problem, and suggests a common algorithm for multi-objective optimization (NSGA-II).  A Pareto Front of ``optimal'' chair designs for the parameters found from running the algorithm can be found in Fig. TODO.


\textbf{2.2} Can GPT support design exploration and optimization when the design 
space is not properly defined or fully bounded?

The previous chair example similarly demonstrates the ability for GPT to recommend reasonable parameters for a design without needing to be manually prompted by a user, applying its knowledge of the target domain.  Here, a user simply asks for ``parameters''; GPT (reasonably) offers continuous parameterizations of a typical chair (and provides a 3D model on request) and offers reasonable ranges without neededing to be prompted.  While discrete parameters are possible with a chair, they are less likely to have a significant impact than its raw dimensions, and most chairs are comprised specifically of four legs, a seat, and a back. 

This cannot translate to completely novel problems, but it can apply knowledge of aspects of a problem to new problems in familiar domains.  Listing TODO shows an example of a new type of GPT helping to design a novel machine invented by a user; since it is synthesized from existing ideas, GPT can use its knowledge of those preexisting domains and their components to recommend reasonable design parameter ranges. 

\textbf{2.3} Can GPT support design optimization when objectives are not easily quantifiable?

Some objectives, typically those requiring human feedback and opinion, are difficult to specify as a mathematical objective; in those cases, a numerical optimization approach is intractable.  One solution sometimes employed is to train a surrogate model of user opinions (TODO: cite); however, as GPT is a large language model that encodes human knowledge, it is reasonable to wonder if GPT can aid in directly modifying designs for high level objectives.

Listing TODO presents an example of CLIP (TODO: cite) being used to steer the design process.  Starting with a base design for a cabinet, the user asks GPT to alter the design stylistically, \textit{e.g.} to make it look ``Mid-Century Modern'' or ``Egyptian'' styled.  GPT provides new designs to try to match those styles.  We use CLIP as feedback on renders of the designs to determine if they have become more or less like the style requested.  Figure TODO: shows the evolution of designs through this process, with the prompts displayed in Listing TODO.  As can be seen, the fidelity of designs generated through this process is low, and G

\iffalse
-GPT has the ability to do basic math.
-That math is not always error-proof.
-In addition, it has the ability to resort to two other tools at its disposal: a) Plugins, b) Code that can be run by a user (or by a program calling into GPT).
-Each of these approaches has certain pitfalls, as we discuss

P1: The Table example.
-Setup the problem
-Why is this straightforward?
-An intuitive answer exists
-GPT finds the intuitive answer.

-Approach 1: Wolfram Alpha
-The problem: Timeout

-Approach 2: GPT's own math
-The problem: Reasoning is not super robust about complex algebra.
-As we'll see, GPT's internal calculus is also limited by the fact that it can make mistakes, somethign that will rear its head in the section TODO.



P2: The arm example (code)

\fi

\iffalse
% Robot arm reaching a target location 
% Plan to move a robot arm to reach a location
% Cabinet 


- propose modifications of a single design (no need to create a design space) (capacitor examples)
- create from library 
( drone example) 


The remainder of this section begins by walking through a simple end-to-end example.  We then examine a number of questions regarding the capabilities of LLMs.  For each of these questions, we aim to determine what LLMs are currently capable of, and what still seems to be beyond their capabilities.


\subsection{A Simple Example}
A general effective strategy for optimizing designs is to begin by asking for a \textit{forward model} of the problem, and then asking for a means for searching over that forward model in order to solve the \textit{inverse problem}.  This first query can include detailed information about the design space and/or the performance space, but the user can in some cases trust the LLM to define these reasonably.

Listing TODO shows a very simple example of optimizing over a two-linked robot arm, for a reachability task.  The first query creates the model.  In the second query, the LLM chooses to optimize the geometry over LLM, constrained on the task constraints, using L-BFGS, a constrained gradient-based second-order optimizer.  Following this example, we show demonstrations of inserting priors of design and performance metrics.


\iffalse
User:
\begin{lstlisting}
    I'm trying to design a robot arm that can move its end effector directly vertically half a meter.  Can you help by providing a design for such a robot?  It should only use rotational motors.  I need to know the morphology of the robot - the dimensions of the links, and how they are connected.  Or, if you don't know the dimensions or the morphology, you can provide code to search for dimensions that would work for the task (through simulation).
\end{lstlisting}
GPT:
\begin{lstlisting}
import numpy as np

# Set the desired vertical distance
d = 0.5  # 0.5 meters

# Set the initial length of the arm links (randomly or based on prior knowledge)
l1 = 0.25  # 0.25 meters
l2 = 0.25  # 0.25 meters

# Calculate the angles using inverse kinematics
theta2 = np.arccos((d**2 - l1**2 - l2**2) / (2 * l1 * l2))
theta1 = np.arctan2(l2 * np.sin(theta2), l1 + l2 * np.cos(theta2))

# Confirm that the end effector reaches the desired position
x = l1 * np.cos(theta1) + l2 * np.cos(theta1 + theta2)
y = l1 * np.sin(theta1) + l2 * np.sin(theta1 + theta2)

print("The end effector is at position: ", (x, y))

# Now you can run a loop to iterate over various lengths for l1 and l2
# within a feasible range and see which combination gives you the best result.
# You would have to define "best" - could be smallest, lightest, simplest, etc.
\end{lstlisting}

User:
\begin{lstlisting}
    Can you write the code for that parameter search?
\end{lstlisting}

GPT:
\begin{lstlisting}
    import numpy as np
from scipy.optimize import minimize

# Set the desired vertical distance
d = 0.5  # 0.5 meters

# Define the objective function (the function to minimize)
def objective(x):
    return x[0] + x[1]

# Define the constraint (the robot arm must reach the desired height)
def constraint(x):
    l1, l2 = x[0], x[1]
    
    theta2 = np.arccos((d**2 - l1**2 - l2**2) / (2 * l1 * l2))
    theta1 = np.arctan2(l2 * np.sin(theta2), l1 + l2 * np.cos(theta2))
    
    y = l1 * np.sin(theta1) + l2 * np.sin(theta1 + theta2)
    
    # The constraint function must return a value greater than 0 for feasible solutions
    return y - d

# Define the initial guess for the lengths
x0 = np.array([0.25, 0.25])

# Define the bounds for the lengths (in this case, each link must be between 0.1 and 0.5 meters long)
bnds = [(0.1, 0.5), (0.1, 0.5)]

# Define the constraint dictionary
con = {'type': 'ineq', 'fun': constraint}

# Solve the optimization problem
solution = minimize(objective, x0, bounds=bnds, constraints=con)

print("The optimal lengths are: ", solution.x)
\end{lstlisting}
\fi
\
Here, GPT created the specified constraint and chose the design space (including parameter bounds) and a performance metric, and chose an adequate optimization method that's easily accessible from Python.  We do note that GPT did not provide gradient information about any of the objectives or constraints, which would help accelerate the search.

Listing TODO refines the above example to include these aspects.
\iffalse

User:
\begin{lstlisting}
Scipy's minimize defaults go L-BFGS.  That can use gradient information.  Can you provide code for the gradient computation and update the example to use that?
\end{lstlisting}

GPT: (TODO: check correctness)
\begin{lstlisting}
    import numpy as np
from scipy.optimize import minimize

# Set the desired vertical distance
d = 0.5  # 0.5 meters

# Define the objective function (the function to minimize)
def objective(x):
    return np.sum(x)

# Gradient of the objective function
def grad_objective(x):
    return np.array([1.0, 1.0])

# Define the constraint (the robot arm must reach the desired height)
def constraint(x):
    l1, l2 = x[0], x[1]
    
    theta2 = np.arccos((d**2 - l1**2 - l2**2) / (2 * l1 * l2))
    theta1 = np.arctan2(l2 * np.sin(theta2), l1 + l2 * np.cos(theta2))
    
    y = l1 * np.sin(theta1) + l2 * np.sin(theta1 + theta2)
    
    # The constraint function must return a value greater than 0 for feasible solutions
    return y - d

# Gradient of the constraint
def grad_constraint(x):
    l1, l2 = x[0], x[1]
    
    theta2 = np.arccos((d**2 - l1**2 - l2**2) / (2 * l1 * l2))
    theta1 = np.arctan2(l2 * np.sin(theta2), l1 + l2 * np.cos(theta2))
    
    dtheta2_dl1 = -(l1 + l2 * np.cos(theta2)) / (l1 * l2 * np.sqrt(1 - ((d**2 - l1**2 - l2**2) / (2 * l1 * l2))**2))
    dtheta2_dl2 = -(l1 + l2 * np.cos(theta2)) / (l1 * l2 * np.sqrt(1 - ((d**2 - l1**2 - l2**2) / (2 * l1 * l2))**2))
    
    dtheta1_dl1 = (l2 * np.cos(theta2) * dtheta2_dl1 - (l1 + l2 * np.cos(theta2))) / (l1**2 + l2**2 + 2*l1*l2*np.cos(theta2))
    dtheta1_dl2 = (l2 * np.cos(theta2) * dtheta2_dl2 - (l1 + l2 * np.cos(theta2))) / (l1**2 + l2**2 + 2*l1*l2*np.cos(theta2))
    
    dy_dl1 = np.sin(theta1) - l1 * np.cos(theta1) * dtheta1_dl1 + np.sin(theta1 + theta2) * (dtheta1_dl1 + dtheta2_dl1)
    dy_dl2 = np.sin(theta1 + theta2) * (dtheta1_dl2 + dtheta2_dl2)
    
    return np.array([dy_dl1, dy_dl2])

# Define the initial guess for the lengths
x0 = np.array([0.25, 0.25])

# Define the bounds for the lengths (in this case, each link must be between 0.1 and 0.5 meters long)
bnds = [(0.1, 0.5), (0.1, 0.5)]

# Define the constraint dictionary
con = {'type': 'ineq', 'fun': constraint, 'jac': grad_constraint}

# Define the options for the solver
options = {'disp': True, 'iprint': 1, 'eps': 1.4901161193847656e-08}

# Solve the optimization problem
solution = minimize(objective, x0, jac=grad_objective, bounds=bnds, constraints=con, method='L-BFGS-B', options=options)

print("The optimal lengths are: ", solution.x)
\end{lstlisting}


User:
\begin{lstlisting}
Let's say we wanted to make the objective function something else, something related to the configuration space.  Specifically, we want to find a design such that the joint connecting the two links is as "straight" as possible when it reaches its target point with its end effector.  How would we modify the code to do that?
\end{lstlisting}

GPT (TODO: check correctness):
\begin{lstlisting}
    import numpy as np
from scipy.optimize import minimize

# Set the desired vertical distance
d = 0.5  # 0.5 meters

# Define the objective function (the function to minimize)
def objective(x):
    l1, l2 = x[0], x[1]
    
    theta2 = np.arccos((d**2 - l1**2 - l2**2) / (2 * l1 * l2))
    
    return (theta2 - np.pi)**2

# Gradient of the objective function
def grad_objective(x):
    l1, l2 = x[0], x[1]
    
    theta2 = np.arccos((d**2 - l1**2 - l2**2) / (2 * l1 * l2))
    
    dtheta2_dl1 = -(l1 + l2 * np.cos(theta2)) / (l1 * l2 * np.sqrt(1 - ((d**2 - l1**2 - l2**2) / (2 * l1 * l2))**2))
    dtheta2_dl2 = -(l1 + l2 * np.cos(theta2)) / (l1 * l2 * np.sqrt(1 - ((d**2 - l1**2 - l2**2) / (2 * l1 * l2))**2))
    
    d_obj_dl1 = 2 * (theta2 - np.pi) * dtheta2_dl1
    d_obj_dl2 = 2 * (theta2 - np.pi) * dtheta2_dl2
    
    return np.array([d_obj_dl1, d_obj_dl2])

# Define the constraint (the robot arm must reach the desired height)
# The same as before...

# Gradient of the constraint
# The same as before...

# Define the initial guess for the lengths
x0 = np.array([0.25, 0.25])

# Define the bounds for the lengths (in this case, each link must be between 0.1 and 0.5 meters long)
bnds = [(0.1, 0.5), (0.1, 0.5)]

# Define the constraint dictionary
con = {'type': 'ineq', 'fun': constraint, 'jac': grad_constraint}

# Define the options for the solver
options = {'disp': True, 'iprint': 1, 'eps': 1.4901161193847656e-08}

# Solve the optimization problem
solution = minimize(objective, x0, jac=grad_objective, bounds=bnds, constraints=con, method='L-BFGS-B', options=options)

print("The optimal lengths are: ", solution.x)
\end{lstlisting}

User:
\begin{lstlisting}
I'm not sure how we know if these are good parameter bounds.  Can you provide a systematic way for choosing them, or a principled justification for bounds you choose?  Please provide new bounds and concrete reasoning about why these are the maximum and minimum, and why going beyond them would not help our optimization problem find any better results.  Also, please choose an initial guess for the decision vector and explain why it is a good choice.  This for the problem in which we want to reach a target of 0.5 vertically with the end-effector.
\end{lstlisting}

\begin{lstlisting}
The selection of the parameter bounds and initial guess is often driven by practical constraints and prior knowledge about the problem.

In the context of this robot arm design problem, here are some aspects to consider when defining the bounds and initial guess:

Bounds

Physical constraints: The length of the robot arm's links cannot be negative or zero, so the lower bound must be greater than zero. On the other hand, the upper bound may be limited by factors such as the materials used to construct the arm, the strength of the motors, and the size of the workspace. For instance, an excessively long arm might be too heavy for the motors to move, or it might be too large to fit in the intended workspace.

Reachability constraints: The robot arm must be able to reach the desired vertical distance. The sum of the lengths of the links should be at least equal to this distance. This provides a lower bound for the sum of l1 and l2.

Given the target distance of 0.5 meters, we can refine the bounds as follows:

Lower bound: To ensure that the arm can reach the target, each link should be at least 0.25 meters long if we consider a straight line reach scenario. A smaller value could still be feasible if we allow the arm to bend, but 0.25 meters is a conservative lower bound.

Upper bound: This depends on the practical constraints mentioned earlier, but let's say we limit each link to 1 meter. This would allow for a straight reach to targets up to 2 meters away, which seems reasonable for a desktop or industrial robot arm.

These bounds are (0.25, 1) for both l1 and l2.

Initial Guess

The initial guess can influence the speed and success of the optimization. It's typically chosen based on prior knowledge or assumptions about the problem.

In this case, a reasonable initial guess could be to set both l1 and l2 to 0.5, which would allow the arm to reach the target in a straight line. This seems like a good starting point because it satisfies the reachability constraint and is within the defined bounds.

Here's how you would define the bounds and initial guess:

python
Copy code
# Define the bounds for the lengths
bnds = [(0.25, 1), (0.25, 1)]

# Define the initial guess for the lengths
x0 = np.array([0.5, 0.5])
These values should provide a good balance between ensuring feasibility (the arm can reach the target) and leaving room for the optimization to find a better solution (the arm's joint is as straight as possible). However, keep in mind that the effectiveness of these choices may depend on the specifics of the robot arm and the target.
\end{lstlisting}

\fi



\subsection{Major Questions}


\paragraph{ \textbf{Q1} Can GPT identify optimal designs when a design space and performance metric are provided? }
 
TODO:

-Yes, walk through the example above, and the zoo, and summarize.

When is GPT unable to give reasonable recommendations?
a) If anything, it tends to be extra conservative (give examples).
b) When it has a bad sense of scale of the problem.  This is especially true in novel problems, or when dealing with somewhat abstract problems


\paragraph{\textbf{Q2} Can GPT assist designers in navigating the landscape of possible trade-offs when multiple conflicting objectives are present?}

TODO

\paragraph{ \textbf{Q3} Can GPT support design exploration and optimization when the design space is not properly defined or fully bounded?}

Yes.  In many cases, ChatGPT will actually ``fill in'' or autocomplete objectives and constraints.

Motivators: Table - automatically chose certain variables to be constant when it ran into issues.  Robot reaching example (chose an objective and a constraint).


\paragraph{\textbf{Q4} Can GPT support design optimization when objectives are not easily quantifiable?}

TODO: Unclear.

\paragraph{\textbf{Q5} Can GPT choose reasonable algorithms for different types of supports for constraints, objectives, and decision spaces (\textit{e.g.} continuous, discrete, binary, \textit{etc.}}

Yes.  See the Zoo.

When does it fail?  If anything, it doesn't always have knowledge about some of the state-of-the-art methods.  It tends to almost always recommend scipy's minimize (sometimes smartly selecting the algorithm), and sometimes provides its own, more naive implementations of other methods (such as evolutionary algorithms).  TODO: Does using the Bing Plugin help with this?

\textbf{Q6} When can GPT solve a problem analytically, and when does it need to resort to using an outside tool? (\textit{i.e.} a programmed algorithm).  And, when does it fail?

a) If there is a common-sense solution (table example, or the robot arm).

b) When it is a straightforward Analysis problem where the gradients tend to exist --- but in this case, it also is sometimes overly confident about its domain knowledge and will provide wrong information (TODO: show the quadcopter).

c) When it can make a call to a tool like Wolfram Alpha and it isn't too difficult in complexity

Failure case: Cannot create an analytical/evaluation model (e.g. FEM) or when it hallucinates libraries.


\subsection{The Zoo}
Below we show some demonstrations of inverse design methods used by LLMs.

TODO:
To add: 
1. Evolutionary algorithm for robot topology search.

2. Baysian Optimization for Printing Parameters

3. Table example




\subsubsection{Optimizing Cabinet Design w.r.t. Constraint}

We investigate whether GPT can output a reasonable cost function and design that optimizes the function when provided an example design, a parameterization of the design space, and a text description of the objective. One instantiation of this problem setting is with furniture: can GPT optimize the design of a cabinet such that the result has a user-specified volume while minimizing the cost to build it? First, we prompt \gpt with an example cabinet design in OpenSCAD and a parameterization of the design, which includes bounds for the parameters, and ask it to generate the functions to compute volume and material cost. Once the user verifies the accuracy of the functions, we have \gpt  output a python script that can minimize the cabinet's material cost with respect to a given volume constraint. The resulting code is shown in Fig. \ref{fig:cabinet_opt} and an example of an optimized cabinet is shown in Fig. \ref{fig:cabinet_opt_render}.

% Figure environment removed
% % Figure environment removed

% GPT is able to output reasonable functions computing the storage capacity and material cost, though there was an error in computing shelf volume. 

\subsubsection{Planning for Robot Manipulation}

We now study a planning problem, where given a claw attached to an arm and an environment with objects and bins, \gpt must control the arm-claw robot with a sequence of commands that picks up all objects and places them into bins. We present an interface for the arm-claw such that the physical embodiment of the arm-claw robot does not matter, allowing \gpt to simply reason about the movement of the claw and whether the claw should grasp or release an object. Due to the nature of the problem, an important constraint is that the claw must visit an object to pick it up before dropping it off at a bin. Another is that a bin can only hold one object. While formalizing the constraint that the claw must visit an object before a bin is not a trivial task, the performance objective is minimizing the distance that the claw travel. To simplify the problem, we also add that the maximum number of objects and bins is 3 each, making brute force a valid solution. The initial prompt and result is shown in Fig. \ref{fig:claw1}.

% Figure environment removed

Though GPT understands that it needs to keep track of the position of the claw to compute the correct distances and that the claw should move to an object before moving to a bin, it does not able to output an optimal solution, even when the problem statement limits the total number of objects and bins. We thus directly specify while prompting that the outputted function should guarantee that the minimum distance is traveled. 

% Figure environment removed

As seen in Fig. \ref{fig:claw2}, the code does not consider all possible bins that an object can be placed in once it has been picked up. We note that the solutions have high variance -- on a different run, \gpt does produce a correct brute force solution. A third rerun produces code that guarantees an optimal solution but is less efficient as it computes the translation for paths that do not obey the constraint that a claw must pick up an object before placing it in a bin.

% GPT (Version 2):
% \begin{lstlisting}
% Given the constraints you've provided and since the problem is constrained to small numbers of objects and bins (each less than or equal to 3), it's feasible to use a brute-force method to find the optimal solution. We will generate all permutations of objects and bins, compute the total energy cost for each permutation, and return the one with the minimum energy cost.

% Here is the function:

% ```python
% import itertools
% import math

% def optimal_arm_movement(claw_initial, objects_initial, bins, T_max):
%     def translation_distance(p1, p2):
%         # Calculate total translation distance between two points
%         return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1]) + abs(p1[2] - p2[2])

%     best_actions = None
%     min_energy = float('inf')

%     # Generate all permutations of objects and bins
%     object_orders = list(itertools.permutations(objects_initial))
%     bin_orders = list(itertools.permutations(bins))

%     for object_order in object_orders:
%         for bin_order in bin_orders:
%             actions = []
%             energy = 0
%             claw_pos = claw_initial

%             for obj, bin in zip(object_order, bin_order):
%                 # Move to object
%                 actions.append(('translate_x', obj[0] - claw_pos[0]))
%                 actions.append(('translate_y', obj[1] - claw_pos[1]))
%                 actions.append(('translate_z', obj[2] - claw_pos[2]))
%                 actions.append(('grasp',))
%                 energy += translation_distance(claw_pos, obj)
%                 claw_pos = obj

%                 # Move to bin
%                 actions.append(('translate_x', bin[0] - claw_pos[0]))
%                 actions.append(('translate_y', bin[1] - claw_pos[1]))
%                 actions.append(('translate_z', bin[2] - claw_pos[2]))
%                 actions.append(('release',))
%                 energy += translation_distance(claw_pos, bin)
%                 claw_pos = bin

%                 if energy > T_max:
%                     break

%             # Update best actions if this order uses less energy
%             if energy < min_energy:
%                 best_actions = actions
%                 min_energy = energy

%     if best_actions is None:
%         return "No solution found within power limit"
%     else:
%         return best_actions

% claw_initial = (0, 0, 0)
% objects_initial = [(10, 10, 0), (20, 20, 0), (30, 30, 0)]
% bins = [(5, 5, 0), (15, 15, 0), (25, 25, 0)]
% T_max = 200

% print(optimal_arm_movement(claw_initial, objects_initial, bins, T_max))
% ```

% This function works by generating all permutations of objects and bins, then for each permutation, it calculates the total energy required to move the claw to each object, grasp it, move to the corresponding bin, and release the object. The permutation with the minimum energy usage that does not exceed `T_max` is then returned. If no solution is found within the power limit, it returns a message indicating this. 

% Remember that this method, while it guarantees an optimal solution, could be computationally expensive and may not scale well for larger numbers of objects and bins. For scenarios with larger numbers of objects and bins, you might want to consider different algorithms like Greedy Algorithm, Genetic Algorithm, or other optimization techniques.

% \end{lstlisting}


% GPT (Version 3):
% \begin{lstlisting}
% Sure, with the constraint that we have 0 <= n, m <= 3, a brute force approach to solve this problem to find the globally optimal solution is feasible, considering every possible sequence of objects and bins.

% Here's how the function would look:

% ```python
% import itertools
% import sys

% def total_translation(path):
%     total = 0
%     for i in range(len(path) - 1):
%         total += abs(path[i][0] - path[i+1][0]) + abs(path[i][1] - path[i+1][1]) + abs(path[i][2] - path[i+1][2])
%     return total

% def find_optimal_path(claw_initial, objects_initial, bins, T_max):
%     # combine objects and bins in one list and permute them
%     objects_bins = objects_initial + bins
%     permutations = list(itertools.permutations(objects_bins, len(objects_bins)))

%     # add claw initial position as the start of each permutation
%     paths = [[claw_initial] + list(perm) for perm in permutations]

%     min_translation = sys.maxsize
%     optimal_path = None

%     for path in paths:
%         # check if the sequence of object and bin is valid (object followed by bin)
%         is_valid = True
%         for i in range(0, len(path) - 1, 2):
%             if path[i] in objects_initial and path[i+1] in bins:
%                 continue
%             else:
%                 is_valid = False
%                 break
        
%         if not is_valid:
%             continue

%         translation = total_translation(path)

%         if translation < min_translation and translation <= T_max:
%             min_translation = translation
%             optimal_path = path[1:]

%     if optimal_path is None:
%         return "No solution found within power limit"
    
%     return optimal_path

% claw_initial = (0, 0, 0)
% objects_initial = [(10, 10, 0), (20, 20, 0), (30, 30, 0)]
% bins = [(5, 5, 0), (15, 15, 0), (25, 25, 0)]
% T_max = 200

% print(find_optimal_path(claw_initial, objects_initial, bins, T_max))
% ```

% In the above function, the `find_optimal_path` function generates all permutations of objects and bins, checks if each permutation is a valid sequence (object followed by bin), and then finds the one with the minimum total translation that does not exceed the maximum allowed. If no valid path is found within the power limit, it returns a message indicating this.
% \end{lstlisting}

% Version 3 combines the object and bin positions into a single list and checks if permutations of the combined list are valid. However, this is a less efficient implementation as many permutations will be invalid solutions.
TODO: \url{https://chat.openai.com/share/828d9af0-2c88-4a0e-92da-9c33aec2dc67} --- analytical optimization and its limitations.

%A fundamental aspect of design involves searching for solutions that achieve optimal performance. This can be computationally intensive, particularly if the domain is expansive and if performance evaluation is computationally demanding. Typical approaches first establish a bounded design space to be searched over, and define objectives that can be computationally evaluated. We have already discussed both these factors in previous sections. The next step is to select the best algorithm to explore this domain, while taking into account various considerations - Is the domain discrete or continuous? Can we compute derivatives? How expensive is it to evaluate the objectives? How many objectives do we have and, if more than one, are they conflicting?

%Considering this landscape, one way GPT can support designers is by aiding them in finding the most effective method to execute the search when the domain and objectives are well-defined. We can also contemplate how GPT might handle multi-objective optimization, guiding users through a potentially complex landscape of trade-offs.

%Moreover, the creation of the design space can present challenges, as designers must clearly define boundaries, a task that can be difficult. In addition, some objectives may be challenging to quantify, as discussed in the previous section. In this context, we could consider whether GPT can propose novel strategies that free  designers from some of the typical burdens associated with the optimization pipeline.




%NOTES:
% Case 1: How good is it in search when it is given a design space and a metric?
% 1.1 can it just find the solution 
% 1.2 can it generate a correct algorithm that finds the solution?
% conclusion: maybe but is really that much better than not using it?
% examples: Robot arm -> shows that 1.2 does work (done) simple test: see if robot arm works for 1.1 
% Question: what other performance metrics we can (see if we can use stuff from the performance team)



Interesting design problems:
Look at the cartesian product of:

Analytical vs. simulation in the loop.

Constraints: Continuous, discrete, equality, bounded
Performance metrics: Continuous, discrete, binary, real-world only
Design space: Continuous, discrete, structured (graph?), unbounded vs. bounded
Multi-objective?

Examples: Format is Constraint type, Performance Metric, Design Space type

Robot arm: Continuous equality, continuous, Continuous bounded
Quadcopter: Continuous equality, continuous and real-world, Continuous bounded
Furniture (stabilization): None or material use (continuous), Binary (does it stand?), Unbounded
Will also come up with some purely analytical examples for these, or try solving some of these in an analytical way.

Can we do a simple stochastic turbulent flow example?


\paragraph{\textbf{Q2} Can GPT assist designers in navigating the landscape of possible trade-offs when multiple conflicting objectives are present?}

\paragraph{\textbf{Q3} Can GPT support design exploration and optimization when the design space is not properly defined or fully bounded?}

% NOTES:
% Case 2: what happens when the design space is ill-defined? 
% - can it maybe stay within some reasonable bounds which would be hard to do without some kind of domain understanding
%come up with an example where something is unbounded and see if chatgpt can optimize it? 
%system identification?

\paragraph{\textbf{Q4} Can GPT support design optimization when objectives are not easily quantifiable?}
Case 3: what happens when the performance metrics are more abstract?
again here we should talk to perfomance team! 















































% Inverse Design: What are the questions that we're trying to answer?

% 0. What is inverse design?

% 1. What is GPT capable of?

% 2. Where does it struggle?

% 3. Where does it need help?  i.e. what human problem-solving priors need to be placed on the workflow of generating solutions.

% 4. What external tools does GPT need to leverage or what custom tools do we need to develop as glue and tell GPT that they exist.


% -In this section, we:

% a) Provide a description of the inputs and ouptputs of inverse design.

% b) Provide a working example (TBD) showing how all aspects of design optimization can be generated using GPT.

% c) Show a ``Zoo'' 

%\paragraph{Overview}



\iffalse


\paragraph{Overview}
If you just specify, I want a table that can support 100kg, this might not work. You need to specify what the design space is. You need to specify some design space for tables.
Let's give a simple example of this.

The output is a design (specified as some point in the design space). One specific table that can do the job. It might be also possible that none of these design can satisfy the goals. 

\paragraph{Specifying Performance Goal}
This can be minimum (e.g., design with minimum performance in the set), maximum, given value (supports at least 100kg).

In the case of generative design, the output could be a collection of different designs.  One may desire to optimize over statistics of that set, \textit{e.g.}: maximize diversity (standard deviation) and so on.


\paragraph{Constraints on Performance Goal}
In either case, constraints may come into play.  "I only have 10 kg of material to work with" or "Ensure that the robot uses no more than its battery life to complete its task."  This can be especially challenging in the case of collection outputs, as different objectives, such as optimization, diversity, and parsimony can be in direct conflict with one another.

\paragraph{Examples}
"Make me a table that supports a person with as little compliance as possible with the amount of material I have on hand."

"Make me four robots with as different shapes as possible according to Hausdorff metric that complete a task in 1 minute."

design iteration based on what we think will work (using LLM or other tools), resampling from design space.

\fi
\fi

\subsection{Discussion}
TODO: format and expand.


The good:
1. Able to find an adequate choice for an algorithm for many problems - Able to also justify it - it doesn't always give you options right out of the gate - can sometimes get confused and rely on the domain to choose the algorithm.
2. Autocompletes a lot of content even before you ask (parameter bounds, constraints, objective function)
3. Can transfer some knowleldge to novel domains based on components - it can be fooled.
4. When the problem has an intuitive answer, can sometimes give that directly. (but can a user trust that?)

The Bad:
1. Some domains, ChatGPT will assume that it knows libraries that don't exist.  This also came up in performance evaluation.
2. Sometimes runs into memory issues setting up the problem.
3. Bad at spaital reasoning.

The Ugly:
1. Plugins can help, but sometimes lead to trouble.
2. Not always choosing the absolute best algorithm, especially if code doesn't exist.  So don't expect the most advanced algorithm.
3. Doesn't always set up problems in the most efficient way (e.g. analytical gradients)