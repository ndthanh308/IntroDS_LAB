\section{Performance And Design Space To Design (Inverse Design)}\label{sec:inverse}
Although generative algorithms can produce candidates for designs, there is no guarantee concerning their quality. Inverse design is focused on producing designs that are, by some metric, as close to optimal as possible, given the constraints.  
Put in the vocabulary of the preceding sections, given a design space and performance metrics (which can define values to be optimized or constraints to be satisfied), inverse design answers the following question: which design in our space provides optimal performance without violating any constraints?

A design generated by an \llm must therefore satisfy several requirements: \textit{1)} it must be valid,  \textit{2)}  it must be performant, \textit{3)} it must satisfy design constraints, and, \textit{4)} in the context of manufacturing, it must be buildable.  With \textit{3)} and {4)}, we note the persistent reality of the sim-to-real gap --- that is, objective and constraint values may differ \textit{in silico} and \textit{in situ}.  Basic challenges involve specifications of the inverse problem to an \llm (much of which was described in previous sections), as well as generation of an effective algorithm for design optimization.
Although {\llm}s cannot natively search for optimal solutions to a novel problem, they can make educated starting guesses and output optimization code that users can execute.  Much of this section is thus focused on prompting {\llm}s to generate meaningful code for problems dependent on aspects such as their parameterization support (\textit{e.g.} continuous versus discrete domains), performance objective landscape, or fabrication constraints.  
% formulate code to be executed by function calling\wojciech{Reword}
Real-world problems introduce nuanced challenges, including exploring over multiple competing objectives, difficult-to-specify objectives (such as aesthetics and objectives that depend on long-term use), and an evolving landscape of emerging methods that an \llm may not know about.  In this context, we could consider whether \gpt can propose strategies (even novel ones) that free designers from some of the typical burdens associated with the optimization pipeline. 
% \wojciech{Replace LLM with GPT}

With these considerations, we aim to investigate the following questions:


\textbf{Q1} When can \gpt solve a problem analytically, and when does it need to resort to using an outside tool (\eg, a programmed algorithm)? 
% table example 
 
 \textbf{Q2} Can \gpt choose reasonable algorithms for different types of supports for constraints, objectives, and decision spaces (\eg, continuous, discrete, binary)?

 \textbf{Q3} Can \gpt assist designers in navigating the landscape of possible trade-offs when multiple conflicting objectives are present?

 \textbf{Q4} Can \gpt support optimization in contexts that require additional knowledge, specifically when a design space is not properly defined or is missing constraints?

In this section, we investigate, generally speaking, modern {\llm}s' abilities to navigate and (semi-)automate design optimization problems.



\subsection{\gpt: Analytical vs. Outside Tools \textbf{(Q1)} }
We know that \gpt has the ability to reason about many mathematical operations, including both algebra and calculus, which is sufficient to solve many real-world engineering problems.  We emphasize ``reasoning'' because, although \gpt clearly proposes reasonable analysis steps, is not obvious that \gpt is correctly executing those steps;  as we'll see, \gpt often makes mathematical errors.  Still, it is reasonable to wonder if \gpt's own internal reasoning is sufficient for inverse design.  Where are the limits of that reasoning?  When must it  resort to code and external libraries, or plugins?  Each of these approaches has its own pitfalls that suggest caution for developers.

Consider an example in which we maximize the stability of a table (Fig.~\ref{fig:table_intuitive}).  \gpt correctly describes that an object is statically stable when its center of mass lies within its support polygon.  One considers stability of an object to be maximized when it remains stable under as large of a perturbation as possible.  In principle, that typically means two things: \textit{1)} moving the center of mass as far away from the boundary of the support polygon as possible, \textit{2)} decreasing the object's experienced motion (typically caused by gravitational torquing) when perturbed. \gpt is able to apply these intuitive principles to reason about the optimal solution within given bounds in this case. 

In a similar example shown in Fig. \ref{fig:table_wolfram}, the Wolfram plugin is enabled, which \gpt can selectively call at its discretion.  While the Wolfram plugin was a natural choice for solving what appears to be a simple analytical optimization problem, \gpt timed out. In practice, this can happen for at least three reasons: \textit{1)} not enough time was allotted for the computation, \textit{2)} the problem is too difficult for Wolfram to handle, or, more generally, \textit{3)} the query may produce a problem that is not tractable or -- in the extreme case -- not computable \cite{turing1936computable}.  Although it might seem like it would be trivial to provide Wolfram with more time to complete the computation, in practice, the user has no feedback on how long the computation would take.  It is unreasonable to ask a user to wait indefinitely without feedback, and most numerical optimization algorithms will be unable to provide a reasonable estimate of progress. In this case, ``anytime algorithms'' (which can return a valid partial or approximate solution even if interrupted early)  may be especially practical \cite{zilberstein1996using}.

\input{sections/GraphArrows/InverseDesignExperiments/TableExperimentWolfram}

% \input{sections/GraphArrows/InverseDesignExperiments/TableExperimentPython}

After failing to optimize over the full space using Wolfram, \gpt continues the conversation by reasoning that the optimum value will occur near the boundary of the constraints (Figure~\ref{fig:table_wolfram}). By exploiting this reasoning, it successfully uses the Wolfram Plugin to compute and evaluate the equations corresponding to a small set of extremal points in the design space.  Despite this, it fails to realize that certain solutions dominate others, and does not prune out bad candidates. Moreover, \gpt neglects to justify or prove its claim that the optimum should occur near the boundaries; though it was correct in this case, this approach may fail in general.

In a follow-up experiment (Fig. \ref{fig:table_python1}), \gpt is asked to perform the same optimization task via Python code, which enables it to use an external library.  It chooses L-BFGS-B, which is a reasonable, standard, and easily accessible (though not state-of-the-art) solver for continuous valued problems.  It does not, however, provide gradients that can expedite the computation unless prompted for them. We explicitly prompt \gpt to provide the gradients (Fig. \ref{fig:table_python2}) and visualize the results in Fig. \ref{fig:table_opt_render}. Generally speaking, the unoptimized approach on \gpt's part is an issue \wrt performance, as not all users will be intimately familiar with all (or perhaps any) optimization libraries, and they may not realize that by providing additional information (\eg. gradients), the computation can be expedited. \gpt also does not elect to make use of Wolfram or autodifferentiation; in practice, lack of direct computation can lead to errors.
Later in this section, we demonstrate how \gpt struggles to solve a (much) more difficult version of this optimization problem.

\input{sections/GraphArrows/InverseDesignExperiments/TableExperimentPython}


% (\todo{}: timings comparison)

\input{sections/GraphArrows/InverseDesignExperiments/Table}



Throughout these experiments, we noticed several common issues in \gpt's approach.  First, if users do not prompt \gpt explicitly to show its work, it may resort to ``common-sense'' reasoning about a problem.  Although this reasoning \textit{could} be correct, \gpt provides no certificate to a user, as seen in the ``intuitive''  physics of Fig. \ref{fig:table_intuitive}, or the boundary-aligned optima assertion in \fref{fig:table_wolfram}.
Another issue occurs if it is difficult to find a library to solve a particular task; in this case, \gpt often gives up or attempts to write its own code. If the code is detail-heavy, it may be too difficult for \gpt to write correctly and the code/solution may be incorrect. If a library does exist but is used uncommonly, \gpt may give incorrect instructions on how to install/use that library; or, in some cases, \gpt may hallucinate a library altogether. 


\subsection{Reasoning about different problem types and selecting appropriate solvers (\textbf{Q2}) }

To test \gpt's understanding of various problem domains and its ability to identify appropriate solutions for each, we conducted several experiments spanning a wide range of search spaces, constraint spaces, performance spaces. In some cases, the problems have additional real-world considerations of which \gpt must be cognizant in order to choose a suitable optimization approach.
Tables \ref{tab:inverse_table1} and \ref{tab:inverse_table2} provide a comparison of different problems that \gpt was asked to solve.  We describe each example in additional detail below, with the exception of the table stability optimization (which was presented in the previous section).

Overall, we found that even over varying problem types, \gpt exhibits extreme robustness when reasoning about and choosing an adequate solver for any given problem.  In cases where a more sophisticated algorithm was needed, it tended to choose at least the correct algorithm class, even if it was not always aware of the best version or implementation.  One notable example was in optimizing robot topologies for ground locomotion: \gpt identified an evolutionary algorithm as an effective optimization method, but did not choose any state-of-the-art specific algorithms or implementations.

 

\begin{table}[bt]
\small
\begin{tabular}{|c|c|c|}
 \hline
 \multicolumn{3}{|c|}{Inverse Design Problems} \\
 \hline
 Problem Name & Search Space & Constraint Space \\
 \hline
 Table Stability & Continuous & Parameter Bounded \\
 \hline
 Robot Arm & Continuous  & Parameter Bounded \& Continuous Function\\
 \hline
 3D Printer Parameters & Continuous  & Parameter Bounded \\
 % \hline
 %Robot Topology Design & Graph  & None & Continuous & None & Evolutionary Algorithm\\
 %\hline
 % Multicopter Optimization & Continuous  & Parameter Bounded & Continuous & LQR Control Synthesis Subroutine & Second-Order Gradient-Based/Grid Search\\
 \hline
 %Topology Optimization & Continuous  & Parameter \& Function Bounded \\
 %\hline
 Cabinet Optimization & Continuous  & Parameter Bounded \\
 \hline
 Robot Arm Planning & Continuous  & Continuous \\
 \hline
 Chair Design & Continuous  & Continuous \& Bounded  \\
 \hline
\end{tabular}
\caption{\label{tab:inverse_table1} \textbf{Descriptions of Search and Constraint Space of Inverse Design Problems.}}
\vspace{-5mm}
\end{table}

\begin{table}[bt]
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c|c|}
 \hline
 \multicolumn{4}{|c|}{Inverse Design Problems} \\
 \hline
  Problem Name & Objective Space & Other Considerations & Chosen Optimization Method\\
 \hline
 Table Stability &   Continuous & None & Analytical/Second-Order Gradient-Based \\
 \hline
 Robot Arm  & Continuous & None & Second-Order Gradient-Based\\
 \hline
 3D Printer Parameters & Continuous & Expensive Real-World Experiments & Bayesian Optimization\\
 % \hline
 %Robot Topology Design & Graph  & None & Continuous & None & Evolutionary Algorithm\\
 %\hline
 % Multicopter Optimization & Continuous  & Parameter Bounded & Continuous & LQR Control Synthesis Subroutine & Second-Order Gradient-Based/Grid Search\\
 \hline
 %Topology Optimization  & Continuous & None & N/A \\
 %\hline
 Cabinet Optimization  & Function Bounded & None & Second-Order Gradient-Based\\
 \hline
 Robot Arm Planning & Continuous & Logical Reasoning with High-level Primitives & Greedy Search, Brute Force\\
 \hline
 Chair Design & Continuous & Multi-Objective & NSGA-II (Evolutionary Algorithm) \\
 \hline
\end{tabular}}
\caption{\label{tab:inverse_table2}\textbf{ Results of the Inverse Design Queries to \gpt.}}
\vspace{-5mm}
\end{table}
% \begin{adjustbox}{angle=90}
% \small
% \begin{tabular}{ |c|c|c|c|c|c|  }
%  \hline
%  \multicolumn{6}{|c|}{Inverse Design Problems} \\
%  \hline
%  Problem Name & Search Space & Constraint Space & Objective Space & Other Considerations & Chosen Optimization Method\\
%  \hline
%  Table Stability & Continuous & Parameter Bounded & Continuous & None & Analytical/Second-Order Gradient-Based \\
%  \hline
%  Robot Arm & Continuous  & Parameter Bounded \& Continuous Function & Continuous & None & Second-Order Gradient-Based\\
%  \hline
%  3D Printer Parameters & Continuous  & Parameter Bounded & Continuous & Expensive Real-World Experiments & Bayesian Optimization\\
%  % \hline
%  %Robot Topology Design & Graph  & None & Continuous & None & Evolutionary Algorithm\\
%  %\hline
%  % Multicopter Optimization & Continuous  & Parameter Bounded & Continuous & LQR Control Synthesis Subroutine & Second-Order Gradient-Based/Grid Search\\
%  \hline
%  Topology Optimization & Continuous  & Parameter \& Function Bounded & Continuous & None & N/A \\
%  \hline
%  Cabinet Optimization & Continuous  & Parameter Bounded & Function Bounded & None & Second-Order Gradient-Based\\
%  \hline
%  Robot Arm Planning & Continuous  & Continuous & Continuous & Logical Reasoning with High-level Primitives & Greedy Search, Brute Force\\
%  \hline
%  Chair Design & Continuous  & Continuous \& Bounded & Continuous & Multi-Objective & NSGA-II (Evolutionary Algorithm) \\
%  \hline
%  \caption{Results of the inverse design queries to \gpt.}
%  \label{tab:inverse}
% \end{tabular}
% \end{adjustbox}



\paragraph{Robot Arm Optimization}
In this example, shown in \fref{fig:robot_arm_exp}, a robot arm is to be optimized such that it reaches a target location in space.  As requested, \gpt generates a two-link robot design parametrized by the link lengths, and then uses inverse kinematics to provide a solution for the link lengths so as to reach a target location in space.  When asked to transform this into a design optimization problem, \gpt sets up an optimization problem, creating an appropriate constraint (end-effector touching goal), an objective (sum of link lengths, as a proxy for material cost), and parameters with reasonable bounds.  All of these were automatically provided by \gpt, without explicit request.  Notably, the optimization code is easily generalizable to arbitrary locations in space (though certain aspects like parameter bounds may need to be modified). As an optimization procedure, \gpt chooses L-BFGS; a reasonable choice given the continuous nature of the problem. A rendering of the optimized robot can be seen in \fref{fig:robot_arm_opt}.

\input{sections/GraphArrows/InverseDesignExperiments/RobotArmExperiment}

\input{sections/GraphArrows/InverseDesignExperiments/RobotArm}


% \paragraph{\textbf{Robot Topology Design}}
% In this example, a user asks for help in generating robots that can efficiently locomote forward.  Notably, it is important to be specific about the dimensions of the problem --- asking for a ``robot'' could lead to a 2D planar robot, which abstracts away complex real-world dynamics.  \gpt initially provides code to generate the simulation environment, as prompted, and then subsequently provides a way to programmatically intantiate and optimize robot designs.  We note that if the entire problem is queried to \gpt, it will tend to say that the problem is too difficult, but if broken up in this way --- first asking for a performance evaluation method, then asking for code for the design space, and then asking for code for the inverse design problem, \gpt can do an adequate job.  The evolutionary algorithm provided by \gpt was one it had to be prompted to fill out in detail; it is worth noting that open-source software options for such optimization exist, but \gpt did not opt to employ them for this problem.  The example can be seen in Listing (TODO), while example outputs can be seen in Fig. (TODO). \wojciech{Not enough details. Anything about the constrains. Which BO library.}
\input{sections/GraphArrows/InverseDesignExperiments/PrintingParameters}

\paragraph{Optimizing 3D Printing Parameters}
In this more abstract example, \gpt is simply asked which algorithm to use in order to optimize the parameters of a slicer used in 3D printing.  It chooses Bayesian optimization, which is a good choice for problems with real-world experiments where it is preferable to minimize the number of required experiments. \gpt also provides skeleton code for the optimization.  As this is a more abstract example, specifics are not supplied. The listing can be found in \fref{fig:printingparams}.

%\paragraph{\textbf{Material Topology Optimization}}
%In this ``failure'' example, \gpt is asked to optimize the material distribution of an input geometry for structural loading.  However, upon many repeated attempts, \gpt continually either \textit{a)} hallucinates software libraries and/or their capabilities, or \textit{b)} does not provide useful instructions for installing \wojciech{We never ask for installing libraries. Just using the libraries. Explain. } them, making it difficult to provide an on-ramp for users.  Without a way to evaluate a finite element system, inverse design becomes hopeless. \wojciech{Maybe move this to the end. Give more details on the problem. Is it 2D/3D? }


\paragraph{Cabinet Optimization}

We investigate whether GPT can output a reasonable cost function and design that optimizes the function when provided an example design, a parameterization of the design space, and a text description of the objective. One instantiation of this problem setting is with furniture: can GPT optimize the design of a cabinet such that the result has a user-specified volume while minimizing the cost to build it? First, we prompt \gpt with an example cabinet design in \jscad (\sref{sec:textToDesign_JSCAD_basic}) and a parameterization of the design (including bounds for the parameters). Then, we ask it to generate functions to compute volume and material cost. Once the user verifies the accuracy of the functions, we have \gpt  output a python script that can minimize the cabinet's material cost with respect to a given volume constraint. The resulting code is shown in \fref{fig:cabinet_opt}, with renders of an optimized cabinet in \fref{fig:cabinet_opt_render}.

\input{sections/GraphArrows/InverseDesignExperiments/CabinetOptimization}

\paragraph{Robot Arm Planning}

We now study a planning problem: given a claw attached to an arm and an environment with objects and bins, \gpt must control the arm-claw robot with a sequence of commands that efficiently picks up all objects and places them into bins. Each bin an only hold one object. In the arm-claw interface provided to \gpt, the physical embodiment of the arm-claw robot does not matter; this allows \gpt to simply reason about the movement of the claw and whether the claw should grasp or release an object. Due to the nature of the problem, there is one critical constraint to consider: the claw must visit an object to pick it up before dropping it off at a bin. Formalizing this constraint is non-trivial, but the performance objective is much simpler: minimize the claw's travel distance. To simplify the problem, we also add that the maximum number of objects and bins is 3 each, making brute force a valid solution. The initial prompt and result are shown in \fref{fig:claw1}.

\input{sections/GraphArrows/InverseDesignExperiments/RobotArmPlanning1}

Overall, \gpt understands that it needs to keep track of the claw's position to compute the correct distances and that the claw should move to an object before moving to a bin. Still, it is unable to output an optimal solution, even when the problem statement permits a brute force approach 

\input{sections/GraphArrows/InverseDesignExperiments/RobotArmPlanning2}

To address this, we explicitly emphasize that the output function should guarantee that the minimum distance is traveled. Even in this case, the optimal solution is not necessarily reached. As shown in \fref{fig:claw2}, \gpt's code fails to consider all possible bins that an object could be placed into once it has been picked up. However, we note that the solutions have high variance -- on a different run, \gpt does produce a correct brute force solution. A third run produces code that guarantees an optimal solution but is inefficient, as it computes the translation for paths that do not obey the constraint that a claw must pick up an object before placing it in a bin.






 \subsection{ Navigating trade-offs between multiple conflicting objectives  (\textbf{Q3})}\label{sec:chair_opt}

Although our previous experiments focused on optimizing a single performance objective, we now explore the scenario where a user wishes to navigate a higher-dimensional (\ie. multi-objective) performance space.  The user begins by asking \gpt for reasonable performance metrics for evaluating a chair. After \gpt provides eight such metrics, our user purposefully selects stability and sustainability, since they can be mathematically quantified by tipping angle and volume respectively. The user then asks for parameters over which to search. Since \gpt has not been given a design template, \gpt proposes parameters abstractly; we note that it might have been more useful if \gpt first proposed a skeleton for the chair geometry, especially so that a user could understand the ramifications of these parameters. After iterating with \gpt to generate correct \scad code for the design, the user requests code to evaluate and optimize the chair. \gpt proposes the use of NSGA-II -- a very common evolutionary method for computing the Pareto front of the multi-objective trade-off space -- and provides code for the optimization.  As an oversight, \gpt initially excludes design parameters bounds from the optimization, despite verbally providing ideas earlier in the conversation.  When prompted to add the bounds into the optimization code, because of its limited memory, \gpt suggests reasonable, but notably different parameter bounds. Additionally, \gpt must be prompted again to enforce the bounds consistently throughout the algorithm (specifically, in the crossover and selection operators).  Results can be found in \fref{fig:chair_opt}.



\input{sections/GraphArrows/InverseDesignExperiments/Chair}

Through this example, we conclude that \gpt has the potential to aid users in both \textit{a)} understanding the trade-offs involved in different candidate designs, and \textit{b)} providing pointers to a reasonable algorithm that can help navigate that space.


\iffalse

TODO:
Format as: Name, Search Space, Constraint Space, Objective Space, Other considerations, Chosen optimization method.

-Robot Arm optimization - Continuous Search Space, Reachability (continuous) constraint, Continuous Objective, 2nd order gradient-based optimization.

-Robot topology design - Graph-search space, No constraints, objective continuous, TODO, Evolution optimization method

-Printing Parameters - Continuous search space, bound constraints, objective continuous, very expensive evaluation function, Bayesian Optimization

-Multicopter Optimization - Continuous search space, bound constraints, objective continuous, requires simulation in the loop and knowledge of quadcopter materials, Grid Search

-Mixed Optimization?  Bookshelf. TODO

-Logical Constraints, continuous objective --- Robot motion planning TODO

\fi



\subsection{Supporting optimization in contexts that require additional knowledge (\textbf{Q4})}

In many cases, it can be daunting to fully specify a given inverse design problem in a new domain: for example, it may be difficult to specify appropriate design spaces and objective functions, and it may be unclear how to deal with underspecified/unknown constraints.  In this section, we briefly examine how \llms may reduce the burden of this process to make inverse design more accessible.  %Further, we demonstrate the ability of LLMs to aid in generating design specifications that are difficult to specify or quantify mathematically.

%  has nuances \wojciech{what are these nuances?} that they have not considered \wojciech{improve this sentence}

The chair example discussed in Section \ref{sec:chair_opt} demonstrates \gpt's ability to recommend reasonable parameters for a design without needing explicit, low-level prompts from a user. Indeed, when prompted for ``parameters'', \gpt is able to apply its knowledge of the target domain to offer continuous parameterizations of a typical chair (and provide a 3D model on request), along with reasonable ranges for each parameter.  Although discrete parameters are possible with a chair, they are less likely to have a significant impact relative to its raw dimensions, and most chairs are comprised specifically of four legs, a seat, and a back. 

For completely novel problems, \gpt cannot rely on its existing knowledge to generate an exact design space. However, it can apply knowledge of aspects of a problem to new problems in familiar domains. The conversation in \fref{fig:fworp_example} presents a brief example of \gpt being queried about a novel invention: the Fworp\footnote{Name chosen to be deliberately nonsensical so as not to give context clues to \gpt.}.  The Fworp is a robot car with a body made of silicone rubber.  While the value of such a device is unclear (perhaps shock absorption),  it is synthesized from existing ideas: namely, remote control vehicles and soft robotics.  \gpt uses its knowledge of those preexisting domains and their components to recommend reasonable design parameters, and their ranges, including analyzing size, weight, wheel size, power source, peripherals/sensors, and build material properties.  It also provides guidance on performance metrics without being prompted, but classifies these under ``parameters,'' which may confuse users.  Further, when queried about the advantages and disadvantages of such a device when compared with non-rubbery autonomous vehicles and soft robots without wheels, it provides reasonable comparisons.  In particular, it notes that, compared with non-soft robot vehicles, the fworp could (possibly) be more durable, shock absorbent, safer, and quieter, while also potentially being more expensive to produce and tacky.  Compared with non-vehicular soft robots, it has the potential to be more mobile, stable, energy-efficient, and simple to produce and control, but would lack the versatility and human-interaction potential typically afforded by most soft robots; further, while safer than a typical vehicle, it would be more dangerous than most current soft robots.

This experiment highlights the notion the \gpt can be an effective partner when formulating a novel inverse design problem, as it can make connections between the proposed problems and more established domains. Then, \gpt is able to use its existing knowledge base about those related domains to provide reasonable starting points for the problem at hand. With continued user interaction, \gpt can also help to refine, formalize, evaluate, and ultimately act upon the newly created formulation.


\input{sections/GraphArrows/InverseDesignExperiments/fworpExperiment}

\subsection{Discussion}

This section elaborates on \gpt's key capabilities (C), limitations (L), and dualisms (D) in the realm of inverse design.


\noindent \textbf{C.1 Extensive Knowledge Base in Design and Manufacturing:}  \gpt has knowledge of how to formulate design spaces, objectives, and constraints. It also successfully selects suitable search algorithm for a given problem, suggesting that \llms are useful as a building block when formulating inverse design systems. In its current form, \gpt exhibits a number of abilities that make it highly usable.  For example, it was able to choose an adequate design optimization algorithm for almost every problem it was given; when asked, \gpt was also able to justify its choice of algorithm. 

\gpt is also helpful in automatically providing code for a significant portion of a problem formulation without requiring user input. These aspects include parameter choice, parameter ranges, and objective functions.  In the best case, this feature can relieve a user of much of the ``busywork'' associated with a problem (loose bounds, necessary constraints, \etc.). Even when \gpt falls short of this ideal, \gpt is usually able to recommend a useful starting point.

\gpt's reasoning capabilities can also further provide value in novel domains.  If a user is inexperienced with a particular domain or if they are working on a novel problem, \gpt has the capability to synthesize from the problem's constituent domains to provide suitable advice, as demonstrated with the fworp example.  

\noindent \textbf{L.1 Reasoning Challenges:}   When asking for help in setting up a problem, \gpt's advice can be confusing. For example, it often does not disambiguate between the design parameters (which practitioners have direct control over) and performance metrics (which are emergent from the design).  Less experienced designers may then find themselves confused, believing there must be a way to modify a system's performance directly.
\textit{Potential Solutions:} By following up with \gpt about how a given ``parameter'' is computed, one can attempt to disambiguate parameters from metrics.  In general, however, this verbal confusion is difficult to systematically address.

The addition of function calling in \llms, and specifically plugins using \gpt, can eventually allow for direct execution of arbitrary code, even code that \gpt writes.  However, there are no guarantees on the execution time of that code, and it is unclear how to manage problems that might arise, such as long runtimes (which are common in hard optimization problems), or even infinite loops.  In our experiments, the Wolfram plugin was given a brief time window for computation before it timed out, which largely negated its value in the face of more challenging problems.

\textit{Potential Solutions:} Methods to allow for function calling while providing guarantees or control by a user (say, in the form of anytime algorithms) would be beneficial.  For now, writing one's own plugin may allow greater granularity over the type of algorithm being used.  Thus, the algorithms can at least be catered to \gpt's behavior.





\noindent \textbf{L.3 Scalability:} Inverse design relies on several complex building blocks, including the specification of design spaces and objective functions. However, as discussed in previous sections, \gpt frequently encounters difficulties when faced with these tasks. Such errors prohibit \gpt from scaling to inverse design exploration altogether. This occurred twice during our experiments.  In one failure case, we had difficulty in evaluating the performance of a soft body system using finite elements; although the example is not detailed in the paper, \sref{sec:design_to_perf} has already shown this to be difficult. In effect, this failure currently prevents \gpt-assisted inverse design of a soft robot \wrt FEA-derived metrics. In a different example, we attempted to design a long, multi-link arm, but found that \gpt struggled with properly geometrical alignment of the links and rotation axes (as shown in \sref{sec:textToDesign_urdf}).

\textit{Potential Solutions:}  
Pointing out problems with solutions (such as runtime errors) can allow \gpt to iterate, but requires intervention and potentially fine-grain coding or engineering knowledge by a user.  In practice, it is often effective to blindly ask \gpt to assess its own output and report any errors it finds until \gpt is satisfied with its own work. In our experiments, this frequently converged to a correct solution.  However, this is not foolproof and can be slow and computationally costly.  Further, without access to web search, \gpt may not know how to reconcile out-of-date knowledge about an API.

A second scalability issue is that \gpt does not always choose the best algorithm for solving a problem, and sometimes does not use a given method in the most efficient way (such as not providing gradient information).  Since \gpt tends to be coy about available methods and how to best use them, a more novice user may be unsure how to navigate the intricacies of optimization and diagnose issues.  Furthermore, although \gpt tends to choose adequate algorithm classes, it does not always choose state-of-the-art methods; instead, it tends to default to standard methods that are highly popular.  Because of its knowledge cutoff, without access to web search, any given \llm may not be aware of state-of-the-art methods or how to implement them. Even if an easy-to-use implementation exists on an online repository (\eg. Github), the \llm may not be aware of the code's existence or how to use it.

\textit{Potential Solutions:} Web search, which has been previously available for \gpt, can help to mitigate these issues, as one could ask for the latest, state-of-the-art methods, and \gpt could provide solutions based on current repository code.  However, there is no guarantee that \gpt will be able to understand what makes newer methods optimal for a problem without sizeable crowd knowledge, which may not be available.

The third scalability issue is that, as mentioned in previous sections, \gpt's ``short memory'' can cause it to forget specifics it had generated earlier in a context; this notably occurred in the multi-objective chair example.  While this problem emerged in other aspects of the design-to-manufacturing pipeline, its impacts were most salient when defining inverse problems, whose specification can be especially long.

\textit{Potential Solutions:} Since inverse design problems can be quite lengthy to define and specify, it may be easier to decompose a problem in the following order: \textit{1)} Ask \gpt for a definition of a design space (including its implementation), \textit{2} Ask \gpt for a definition of a performance metric and constraints (including their implementations) while abstracting away the code from \textit{1)} as an API call; \textit{3)} Ask \gpt to write code for the inverse design search, abstracting away the code from \textit{2)} as an API call.  This can keep definitions shorter and easier to manage.


 \noindent \textbf{D.2 Unprompted Responses:}
Throughout our experiments, \gpt always unilaterally selected an optimization algorithm and proceeded to generate code. In particular, \gpt never provided the user with options for possible optimization algorithms, unless it was explicitly asked to provide such options as an intermediate step. Although \gpt's automated selection may satisfy many users, it runs the risk of creating mistakes that would be difficult to diagnose. This is particularly true because \gpt rarely justified its choice to users.  Furthermore, \gpt's assertion may imply that there is a single ``correct'' algorithm for a given problem, and they may not realize that there are better (or even \textit{alternative}) options available in any given circumstance.  

\gpt's tendency to fill in aspects of an inverse design problem before being asked about them may also lead to mathematical problem definitions which are ill-suited or otherwise suboptimal for a user's real-world design problem.  In these cases, \gpt's tendency to autocomplete and plow ahead could lead users to blindly follow the \llm down bad ``rabbit holes,'' only to discover that a fundamental problem existed much earlier.  Furthermore, since \gpt does not have a native way to execute arbitrary code, it will not always realize that a codeblock has errors.
















\iffalse


The good:
1. Able to find an adequate choice for an algorithm for many problems - Able to also justify it - it doesn't always give you options right out of the gate - can sometimes get confused and rely on the domain to choose the algorithm.
2. Autocompletes a lot of content even before you ask (parameter bounds, constraints, objective function)
3. Can transfer some knowleldge to novel domains based on components - it can be fooled.
4. When the problem has an intuitive answer, can sometimes give that directly. (but can a user trust that?)

The Bad:
1. Some domains, ChatGPT will assume that it knows libraries that don't exist.  This also came up in performance evaluation.
2. Sometimes runs into memory issues setting up the problem.
3. Bad at spaital reasoning.

The Ugly:
1. Plugins can help, but sometimes lead to trouble.
2. Not always choosing the absolute best algorithm, especially if code doesn't exist.  So don't expect the most advanced algorithm.

\fi
