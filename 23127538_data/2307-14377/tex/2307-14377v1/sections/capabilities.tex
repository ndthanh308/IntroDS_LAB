\subsubsection{Observed Capabilities and Limitations} \label{sec:capabilities}

Our examination of \llm's performance in the fields of design and manufacturing has underscored several crucial capabilities instrumental in supporting the design processes, in addition to pinpointing significant limitations. \amy{underscored that \gpt has several crucial capabilities, or \gpt needs these capabilities? Or that we think these should be capabilities \gpt has that would be useful? It feels a little weird to have a discussion about our observations on what \gpt can do before we've shown the evidence we observed it from} Next, we outline these observations and discuss various methods to mitigate the identified limitations. Each of these points will be further detailed and exemplified in the following sections.

\noindent \textbf{Capabilities:} \linebreak
\noindent \textbf{C.1 Extensive Knowledge Base in Design and Manufacturing:} \llm boasts a comprehensive knowledge base in the realms of design and manufacturing. Its capabilities extend to solving a wide array of problems and automatically completing specifications, making it a versatile tool across various domains.

\noindent \textbf{C.2 Iteration Support:} \llm incorporates an iterative approach to problem-solving. When feedback is provided on errors, it attempts to rectify them. This ability to adapt and learn, \amy{might be worth clarifying what "learning" means here (incorporating past responses? collecting data?) since that is a term of art...} although not always successful, is a valuable facet of an \llm's performance.

\noindent \textbf{C.3 Modularity Support:} \llm supports modular design, demonstrating the ability to reuse or adapt previous designs or solutions when explicitly instructed. While it does not inherently retain memory of past interactions, explicit instructions can help leverage its modular capabilities effectively.


\noindent \textbf{Limitations:} \linebreak
\noindent \textbf{L.1 Reasoning Challenges:} \llm encounters difficulties with certain types of reasoning, particularly those involving analytical reasoning and computations. These limitations can manifest as notable challenges in the design and manufacturing domain, for instance, a general lack of spatial reasoning capabilities.

\noindent \textit{Potential Solutions:} Implementing well-crafted domain-specific languages (DSLs) can help address these challenges. DSLs, widely used in computer science, encapsulate recurring knowledge, rules, and valuable abstractions, thereby filling knowledge gaps. Alternatively, APIs that can perform the complex computations can be integrated. \llm's proficiency in creating high-level abstractions can be utilized to generate inputs that be processed through APIs by computational solvers.

\noindent \textbf{L.2 Correctness and Verification:} \llm often produces inaccurate results or justifications for its solutions and lacks the ability for self-verification.

\noindent \textit{Potential Solutions:} Apart from relying on human verification, automated verification can be accomplished by utilizing APIs that conduct checks and validations. By leveraging \llm's iterative capabilities (C.2), we can create a feedback loop that continues until a satisfactory solution is obtained.

\noindent \textbf{L.3 Scalability:} As tasks become larger or more complex, \llm's performance can deteriorate, often struggling to manage multiple tasks concurrently.

\noindent \textit{Potential Solutions:} One strategy is to partition larger tasks into multiple sub-tasks. For instance, rather than requesting it to evaluate multiple performance metrics simultaneously, it may be more effective to request them individually. When constructing more complex models, employing an incremental design process can prove beneficial. Components can be designed and verified separately before being assembled into the final model. \llm's modularity support (C.3) can be used to facilitate the creation of complex models from a series of instructions.

\noindent \textbf{L.4 Iterative Editing:} When a design needs modifications, specifying those changes as a prompt will often lead to unsatisfactory behaviors. This is because the \llm, upon receiving a change prompt, will regenerate the design, often overlooking elements specified in previous prompts. This situation poses challenges to design editing.

\noindent \textit{Potential Solutions:} Our solutions involved either feeding the prompts back in to create a full specification in a single prompt, though this also caused challenges due to the scalability limitations discussed above. The alternative was explicit modularization to enable parts to be designed and reused, though the latter was not possible in some cases.

\noindent \textbf{Dualism:}

\noindent \textbf{D.1 Context Information:} \llm's performance improves significantly with the provision of context information. The more detailed the domain description, the better it performs. Furthermore, \llm is adept at providing context for its actions, making it an asset in sequential workflows. This characteristic proves particularly beneficial when using \llm generated content in subsequent tasks, as these tasks can utilize the context included in the output from the initial task.
\noindent \textbf{D.2 Unprompted Responses:} \gpt often infers aspects that are not specified in the prompt, either auto-completing specifications or finding ways to make decisions without enough information. While this is interesting in the design context in terms of allowing for partial specifications that can be auto-completed, it can sometimes be overly proactive, guiding the design in some aspects, which may limit creativity.


