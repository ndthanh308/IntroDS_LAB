

%%% format for review
\documentclass[12pt, onecolumn]{IEEEtran} % try this
%\documentclass[12pt, onecolumn]{IEEEtran} % for review purposes     % turned off
\linespread{1.6} % this is 'double spacing'                         % turned off

%%%% format for final version (2 col)
%\documentclass[10pt, letterpaper]{IEEEtran}

\usepackage{url}% my addition
\usepackage{makecell}% my addition
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx, colordvi, psfrag}% my addition
\usepackage{calc,pstricks, pgf, xcolor}% my addition
\usepackage{epsfig, cite}% my addition
\usepackage{bm} % my addition
\usepackage{bbm} % my addition
%\usepackage[font=footnotesize,labelfont=bf]{caption} % my addition
\usepackage{enumerate}
%\usepackage{dsfont} % my addition
%\usepackage[font=small,labelfont=bf]{caption} % my addition

\newcommand{\Renyi}{R\'{e}nyi\ }
\newcommand{\Csiszar}{Csisz\'{a}r\ }

\newcommand{\OPTA}{\mathrm{OPTA}}

\renewcommand{\thesubsubsection}{\Alph{subsubsection}.}
%\renewcommand{\baselinestretch}{1.9}
%\newcommand{\mod}{{\rm \ mod \ }}
%\newcommand{\ubx}{\underline{{\bf x}}}
%\newcommand{\ubc}{\underline{{\bf c}}}
%\newcommand{\ubX}{\underline{{\bf X}}}
%\newcommand{\bu}{\underline{{\bf u}}}
%\newcommand{\ubZ}{\underline{{\bf Z}}}
%\newcommand{\ubY}{\underline{{\bf Y}}}
%-----------
%\newcommand{\ubN}{\underline{{\bf N}}}
%\newcommand{\ubN'}{\underline{{\bf N'}}}
\newcommand{\snr}{{\rm SNR}}
\newcommand{\SNR}{{\rm SNR}}
\newcommand{\modulo}{\mbox{\ mod \ }}


\newcommand{\be}{{{\bf e}}}
\newcommand{\br}{{{\bf r}}}
\newcommand{\ubx}{{{\bf x}}}
\newcommand{\ubc}{{{\bf c}}}
\newcommand{\ubX}{{{\bf X}}}
\newcommand{\ubU}{{{\bf U}}}
\newcommand{\ubu}{{{\bf u}}}
\newcommand{\ubZ}{{{\bf Z}}}
\newcommand{\ubY}{{{\bf Y}}}

%-----------
\newcommand{\ubN}{{{\bf N}}}
%\newcommand{\ubN'}{{{\bf N'}}}

%--------------------
\newcommand{\omod}{{\rm \ mod_{\Omega_1} \ }}
\newcommand{\vmod}{{\rm \ mod_{\cV} \ }}
\newcommand{\omodg}{{\rm \ mod_{\Omega} \ }}
\newcommand{\bU}{{\bf U}}
%\newcommand{\ubN}{\underline{\bf N }}
\newcommand{\bB}{{\bf B}}
\newcommand{\bG}{{\bf G}}
\newcommand{\zz}{{\Bbb Z}}
\newcommand{\Zt}{{\bZ_{\cV}}}
\newcommand{\Nt}{{\bN_{\cV_2}}}
\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\ZZ}{{\Bbb Z}}
\newcommand{\EE}{{\Bbb E}}
\newcommand{\tN}{\bN_{\cV_2}}
\newcommand{\brho}{\bar{\rho}}
\newcommand{\vol}{{\rm Vol }}
%\newcommand{\k}{{\Omega_1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{alias}  INSERTED ALIAS.TEX FROM RAMI

%   UNDERLINE
\newcommand{\uzer}{\underline{0}}
\newcommand{\uV}{\underline{V}}
\newcommand{\uA}{\underline{A}}
\newcommand{\uD}{\underline{D}}
\newcommand{\uv}{\underline{v}}
\newcommand{\uT}{\underline{T}}
\newcommand{\ut}{\underline{t}}
\newcommand{\ur}{\underline{r}}
\newcommand{\uR}{\underline{R}}
\newcommand{\uc}{\underline{c}}
\newcommand{\uC}{\underline{C}}
\newcommand{\ul}{\underline{l}}
\newcommand{\uL}{\underline{L}}
\newcommand{\uh}{\underline{h}}
\newcommand{\uH}{\underline{H}}
\newcommand{\ue}{\underline{e}}
\newcommand{\uE}{\underline{E}}
\newcommand{\uG}{\underline{G}}
\newcommand{\ug}{\underline{g}}
\newcommand{\uz}{\underline{z}}
\newcommand{\uZ}{\underline{Z}}
\newcommand{\uu}{\underline{u}}
\newcommand{\uU}{\underline{U}}
\newcommand{\uj}{\underline{j}}
\newcommand{\uJ}{\underline{J}}
\newcommand{\uX}{\underline{X}}
\newcommand{\ux}{\underline{x}}
\newcommand{\uY}{\underline{Y}}
\newcommand{\uy}{\underline{y}}
\newcommand{\uW}{\underline{W}}
\newcommand{\uw}{\underline{w}}
\newcommand{\uth}{\underline{\theta}}
\newcommand{\uTh}{\underline{\Theta}}
\newcommand{\uph}{\underline{\phi}}
\newcommand{\ual}{\underline{\alpha}}
\newcommand{\uxi}{\underline{\xi}}
\newcommand{\us}{\underline{s}}
\newcommand{\uS}{\underline{S}}
\newcommand{\un}{\underline{n}}
\newcommand{\uN}{\underline{N}}
\newcommand{\up}{\underline{p}}
\newcommand{\uq}{\underline{q}}
\newcommand{\uf}{\underline{f}}
\newcommand{\ua}{\underline{a}}
\newcommand{\ub}{\underline{b}}
\newcommand{\uDelta}{\underline{\Delta}}
%  CALLIGRAPHIC
\newcommand{\cA}{{\cal A}}
\newcommand{\cB}{{\cal B}}
\newcommand{\cC}{{\cal C}}
\newcommand{\cc}{{\cal c}}
\newcommand{\cD}{{\cal D}}
\newcommand{\cE}{{\cal E}}
\newcommand{\cI}{{\cal I}}
\newcommand{\cK}{{\cal K}}
\newcommand{\cL}{{\cal L}}
\newcommand{\cN}{{\cal N}}
\newcommand{\cP}{{\cal P}}
\newcommand{\cQ}{{\cal Q}}
\newcommand{\cR}{{\cal R}}
\newcommand{\cS}{{\cal S}}
\newcommand{\cs}{{\cal s}}
\newcommand{\cT}{{\cal T}}
\newcommand{\ct}{{\cal t}}
\newcommand{\cU}{{\cal U}}
\newcommand{\cV}{{\cal V}}
\newcommand{\cW}{{\cal W}}
\newcommand{\cX}{{\cal X}}
\newcommand{\cx}{{\cal x}}
\newcommand{\cY}{{\cal Y}}
\newcommand{\cy}{{\cal y}}
\newcommand{\cZ}{{\cal Z}}
%  TILDE
\newcommand{\tE}{\tilde{E}}
\newcommand{\tZ}{\tilde{Z}}
\newcommand{\tz}{\tilde{z}}
%   HAT
\newcommand{\hX}{\hat{X}}
\newcommand{\hY}{\hat{Y}}
\newcommand{\hZ}{\hat{Z}}
\newcommand{\huX}{\hat{\uX}}
\newcommand{\huY}{\hat{\uY}}
\newcommand{\huZ}{\hat{\uZ}}
\newcommand{\indp}{\underline{\; \| \;}}
\newcommand{\diag}{\mbox{diag}}
\newcommand{\sumk}{\sum_{k=1}^{K}}
\newcommand{\beq}[1]{\begin{equation}\label{#1}}
\newcommand{\eeq}{\end{equation}}
%%% FROM SHLOMO SHAMAI
\newcommand{\req}[1]{(\ref{#1})}
\newcommand{\beqn}[1]{\begin{eqnarray}\label{#1}}
\newcommand{\eeqn}{\end{eqnarray}}
\newcommand{\limn}{\lim_{n \rightarrow \infty}}
\newcommand{\limN}{\lim_{N \rightarrow \infty}}
\newcommand{\limr}{\lim_{r \rightarrow \infty}}
\newcommand{\limd}{\lim_{\delta \rightarrow \infty}}
\newcommand{\limM}{\lim_{M \rightarrow \infty}}
\newcommand{\limsupn}{\limsup_{n \rightarrow \infty}}
\newcommand{\imii}{\int_{-\infty}^{\infty}}
\newcommand{\imix}{\int_{-\infty}^x}
\newcommand{\ioi}{\int_o^\infty}
%%%
\newcommand{\bphi}{\mbox{\boldmath \begin{math}\phi\end{math}}}
\newcommand{\bth}{\mbox{\boldmath \begin{math}\theta\end{math}}}
\newcommand{\bhth}{\mbox{\boldmath \begin{math}\hat{\theta}\end{math}}}
%  \newcommand{\by}{\mbox{\boldmath \begin{math}y\end{math}}}
%  \newcommand{\bx}{\mbox{\boldmath \begin{math}x\end{math}}}
\newcommand{\bg}{\mbox{\boldmath \begin{math}g\end{math}}}
\newcommand{\bc}{{\bf c}}
\newcommand{\bbf}{{\bf f}}
\newcommand{\bn}{{\bf n}}
\newcommand{\bs}{{\bf s}}
\newcommand{\bt}{{\bf t}}
\newcommand{\bu}{{\bf u}}
\newcommand{\bx}{{\bf x}}
\newcommand{\by}{{\bf y}}
\newcommand{\bz}{{\bf z}}
\newcommand{\bC}{{\bf C}}
\newcommand{\bJ}{{\bf J}}
\newcommand{\bN}{{\bf N}}
\newcommand{\bS}{{\bf S}}
\newcommand{\bT}{{\bf T}}
\newcommand{\bX}{{\bf X}}
\newcommand{\bY}{{\bf Y}}
\newcommand{\bZ}{{\bf Z}}
% \newcommand{\bth}{{\bf \theta}}
\newcommand{\oI}{\overline{I}}
\newcommand{\oD}{\overline{D}}
\newcommand{\oh}{\overline{h}}
\newcommand{\oV}{\overline{V}}
\newcommand{\oR}{\overline{R}}
\newcommand{\oH}{\overline{H}}
\newcommand{\ol}{\overline{l}}
\newcommand{\E}{{\cal E}_d}
\newcommand{\el}{\ell}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{macros}   FILE MACROS.TEX TAKEN FROM RAMI

% special commands defined for this paper
%from mmc
\newcommand{\yesindent}{\hspace*{\parindent}}	% use before 1st parag. of
	% a section, to force an indentation (kludge)
\newtheorem{thmbody}{Theorem}
\newenvironment{thm}{
%	\begin{singlespace}
\begin{thmbody}
	}{
	\end{thmbody} % \end{singlespace}
	}
\newtheorem{dfnbody}{Definition}
\newenvironment{dfn}{
%	\begin{singlespace}
\begin{dfnbody}
	}{
	\end{dfnbody} %  \end{singlespace}
	}
\newtheorem{corbody}{Corollary}
\newenvironment{cor}{
	% \begin{singlespace}
\begin{corbody}
	}{
	\end{corbody} %  \end{singlespace}
	}
\newtheorem{lemmabody}{Lemma}
\newenvironment{lemma}{
	% \begin{singlespace}
\begin{lemmabody}
	}{
	\end{lemmabody} %  \end{singlespace}
	}
\newtheorem{propbody}{Proposition}
\newenvironment{prop}{
	%  \begin{singlespace}
\begin{propbody}
	}{
	\end{propbody} %  \end{singlespace}
	}
% draws a cute little box at the end of a proof
\newenvironment{proof}{
	{\it Proof:}
	}{
%	\  \rule{.1in}{.1in}
 $\Box$
	}
\newenvironment{example}{
	\begin{small} %  \begin{singlespace}
{\it Example:}
	}{
% 	\end{singlespace}
\end{small}
	}
\newcommand{\pderiv}[2]{\frac{ \partial {#1}}{ \partial {#2}}}
\newcommand{\overr}[2]{\left({\begin{array}{l}#1\\#2\end{array}}\right)}
%\newcommand{\Ddef}{\stackrel{\raisebox{-.02in}{\Delta}}{\raisebox{-.02in}{=}}}
 \newcommand{\Ddef}{\stackrel{\Delta}{=}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{../epsfig}
%includeonly{GUI}
%\begin{document}


%\newenvironment{cor}{
%         \begin{corbody}
%        }{
%        \end{corbody}
%        }


%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%  TITLE  %%%%%%%%%%%%%%%

%
%        \pagestyle{empty}
%        %\baselineskip0.7cm
%
%
%\renewcommand{\baselinestretch}{1.4}
%\baselineskip1.1cm
%
%        %\baselineskip0.7cm
%        \pagestyle{plain}
%
%       \normalsize
%




%
%
%
%
%
%
%
%
%
%
%
%
%%\usepackage{hyperref}
%\usepackage{graphicx}
%\usepackage{amssymb}
%\usepackage{amsmath}
\usepackage{dsfont}
%\usepackage{url}
%\usepackage{psfrag}
%\usepackage{subfigure}
%% ----------------------------------------------------------------
%\vfuzz2pt % Don't report over-full v-boxes if over-edge is small
%\hfuzz2pt % Don't report over-full h-boxes if over-edge is small
%% THEOREMS -------------------------------------------------------
%%\newtheorem{thm}{Theorem}[section]
%\newtheorem{theorem}{Theorem}
%\newtheorem{cor}{Corollary}
%\newtheorem{lem}{Lemma}
%\newtheorem{prop}[theorem]{Proposition}
%%\newtheorem{prop}{Proposition}[theorem]
%%\theoremstyle{definition}
%\newtheorem{defn}{Definition}
%%%\theoremstyle{remark}
%\newtheorem{rem}[theorem]{Remark}
%%\numberwithin{equation}{section}
%% MATH -----------------------------------------------------------
%
%\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
%\newcommand{\abs}[1]{\left\vert#1\right\vert}
%\newcommand{\set}[1]{\left\{#1\right\}}
%\newcommand{\brkt}[1]{\langle#1\rangle}
%\newcommand{\comb}[2]{\left( \begin{array}{c}  #1 \\ #2 \\  \end{array}  \right)}
%\newcommand{\ceil}[1]{\lceil #1 \rceil }
%
%


%\newcommand{\Reals}{\mathds R}


%\newcommand{\Integers}{\mathds Z}
%\newcommand{\Naturals}{\mathds N}
%\newcommand{\argmin}[1]{\underset{#1}{\operatorname{argmin}\ }}
%
%
%\newcommand{\bx}{\mathbf{x}}
%\newcommand{\by}{\mathbf{y}}
%\newcommand{\bz}{\mathbf{z}}
%\newcommand{\bs}{\mathbf{s}}
%\newcommand{\bb}{\mathbf{b}}
%\newcommand{\bd}{\mathbf{d}}
%\newcommand{\bB}{\mathbf{\mathbf{B}}}
%\newcommand{\bw}{\mathbf{\mathbf{w}}}
%
%\newcommand{\bX}{\mathbf{X}}
%\newcommand{\bY}{\mathbf{Y}}
%\newcommand{\bZ}{\mathbf{Z}}
%\newcommand{\bS}{\mathbf{S}}
%\newcommand{\bC}{\mathbf{C}}
%\newcommand{\bV}{\mathbf{V}}
%
%\newcommand{\Wbicm}{\widetilde{W}} % causes a warning in YAP about a missing font...
%%\newcommand{\Wbicm}{\tilde{W}}
%\newcommand{\WbicmSym}{\overline{W}}
%%\newcommand{\WbicmSym}{\overline{\overline{\overline{\overline{W}}}}}
%\newcommand{\PBICM}{\textrm{PBICM}}
%\newcommand{\BICM}{\textrm{BICM}}
%
%
%
%
%\newcommand{\bW}{\mathbf{W}}
%
%
%\renewcommand{\P}{\mathcal{P}}
%
%\newcommand{\nhs}{\hspace{-.04in}}
%\newcommand{\nvs}{\vspace{-.1in}}
%
%\newcommand{\eps}{\varepsilon}
%\newcommand{\To}{\longrightarrow}
%\newcommand{\A}{\mathcal{A}}
%\newcommand{\Y}{\mathcal{Y}}
%\newcommand{\X}{\mathcal{X}}
%\newcommand{\C}{\mathcal{C}}
%\newcommand{\bc}{\mathbf{c}}
%
%\newcommand{\Ell}{\mathcal{L}}
%\newcommand{\R}{\mathbf{R}}
%\newcommand{\E}{\mathbf{E}}
%\newcommand{\B}{\mathcal{B}}
%\newcommand{\Err}{\mathcal{E}}
%\newcommand{\M}{\mathcal{M}}
%
%
%\newcommand{\EE}{\mathbb{E}}
%\newcommand{\VAR}{V\!AR}
%%\newcommand{\VAR}{\mathbb{V\!AR}}
%\newcommand{\ra}{\rightarrow}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    \oddsidemargin  0.0in
%    \evensidemargin 0.0in
%    \textwidth      in
%    \headheight     0.0in
%    \topmargin      0.0in
     \textheight     9.5in

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\newenvironment{proof}{\begin{IEEEproof}}{\end{IEEEproof}}

% correct bad hyphenation here
\hyphenation{deno-minator}



\begin{document}
%\title{Gaussian Types}
\title{The Method of Types for the AWGN Channel}


\author{
\IEEEauthorblockN{Sergey Tridenski and Anelia Somekh-Baruch}\\
\IEEEauthorblockA{Faculty of Engineering\\Bar-Ilan University\\ Ramat-Gan, Israel\\
Email: tridens@biu.ac.il, somekha@biu.ac.il}
%\thanks{
%The material in this paper was partially presented in ITW2020 \cite{TridenskiSomekhBaruch20}.}
%\thanks{
%This work was supported by the Israel Science Foundation (ISF) under grant \#631/17.}
}











%\author{
%Sergey~Tridenski, Anelia~Somekh-Baruch, and %~\IEEEmembership{Fellow},~\IEEEmembership{IEEE},
%Ram~Zamir}

%\thanks{
%The material in this paper was partially presented in ISIT2017 \cite{TridenskiZamir17} and ISIT2018 \cite{TridenskiZamir18}.}
%\thanks{This work of S. Tridenski and R. Zamir was partially supported by the Israel Science Foundation (ISF), grant \# 676/15,
%and by the US-Israel Binational and US-National Science Foundations (BSF-NSF), grant \# 2018690.}
%}



% make the title area
\maketitle
\begin{abstract}
For the discrete-time AWGN channel with a power constraint,
we %rederive the
give an alternative derivation of
Shannon's
sphere-packing upper bound on the optimal block error exponent
and prove for the first time %a similar
an analogous lower bound on the optimal correct-decoding exponent.
The derivations
use the method of types with finite alphabets of sizes
%cardinalities
%growing with
depending on the block length $n$
and with the
%The corresponding
number of types %is
sub-exponential in $n$.
\end{abstract}

%\begin{IEEEkeywords}
%Correct-decoding exponent, Arimoto algorithm, Blahut algorithm.
%%,\newline maximum mutual information, erasure decoder.
%\end{IEEEkeywords}

%\markboth
%{To be Submitted to the IEEE Trans. on Information Theory}
%{Submitted to the IEEE Trans. on Information Theory, Revised April 2019}
%{Tridenski and Zamir: Channel input adaptation via natural type selection} % TODO: use the final title

% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
%
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
%
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
%
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
%
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.


%\IEEEPARstart{T}{he}






%\bigskip


\section{Introduction}\label{Int}

%\bigskip

%In this paper
We study reliability %properties
of the discrete-time additive white Gaussian noise (AWGN) channel
with a power constraint imposed on blocks of its inputs. %the channel
Consider the capacity of this channel, found by Shannon:
\begin{equation} \label{eqShannonCapacity}
C \; = \; \tfrac{1}{2}\,{\log\mathstrut}_{\!2} (1 + s^{2}/\sigma^{2}),
%\text{\rm SNR}),
\end{equation}
where $\sigma^{2}$ is the channel noise variance and $s^{2}$ is the power constraint.
This capacity corresponds to the maximum of the mutual information $I(\,{p\mathstrut}_{X}, \, w)$ over ${p\mathstrut}_{X}$,
under the power constraint on
${p\mathstrut}_{X}$, where $w$ stands for the channel transition probability density function (PDF)
and ${p\mathstrut}_{X}$ is the channel input PDF.
%Denoting the channel noise variance by $\sigma^{2}$ and the power constraint by $s^{2}$,
%so that $\text{\rm SNR} = s^{2}/\sigma^{2}$,
Let us briefly recall the technicalities \cite{CoverThomas} of how the expression (\ref{eqShannonCapacity}) is obtained %as the maximum of
from the mutual information:
\begin{align}
\max_{\substack{\\{p\mathstrut}_{X}:\;\mathbb{E}[X^{2}] \, \leq \, s^{2}}}
I(\,{p\mathstrut}_{X}, \, w)
\;\; = \;\; &
\max_{\substack{\\{p\mathstrut}_{X}:\;\mathbb{E}[X^{2}] \, \leq \, s^{2}}}
\;
\Big\{
D\big(\, w \, \| \, \,{\widehat{p}\mathstrut}_{Y} \, | \, \, {p\mathstrut}_{X}\big)
\, - \,
D\big(\,{p\mathstrut}_{Y} \, \| \, \,{\widehat{p}\mathstrut}_{Y}\big)
\Big\}
\nonumber \\
= \;\; &
\max_{\substack{\\{p\mathstrut}_{X}:\;\mathbb{E}[X^{2}] \, \leq \, s^{2}}}
\;
\bigg\{
\frac{1}{2}\,{\log\mathstrut}_{\!2}\left(1 +\frac{s^{2}}{\sigma^{2}}\right)
\, + \,
\underbrace{\frac{\mathbb{E}\big[X^{2}\big] - s^{2}}{2\ln(2)(s^{2} + \sigma^{2})}
\, - \,
D\big(\,{p\mathstrut}_{Y} \, \| \, \,{\widehat{p}\mathstrut}_{Y}\big)}_{\leq \; 0}
\bigg\}.
\label{eqGaussOpt}
\end{align}
Here
${\widehat{p}\mathstrut}_{Y}(y) \triangleq \frac{1}{\sqrt{2\pi(s^{2} \,+\, \sigma^{2})}}e^{-\frac{y^{2}}{2(s^{2} \,+\, \sigma^{2})}}$
and ${p\mathstrut}_{Y}(y) \equiv \int_{\mathbb{R}}{p\mathstrut}_{X}(x)w(y\,|\,x)dx$,
the operator $\mathbb{E}[\,\cdot\,]$ denotes the expectation,
and $D$ is the Kullback–Leibler divergence between two probability densities.
In this paper we consider the optimal exponents in the block error/correct-decoding probability
of the AWGN channel.
We propose explanations, similar to (\ref{eqGaussOpt}), both
for Shannon's sphere-packing converse bound on the optimal error exponent \cite[Eq.~3,~4,~11]{Shannon59}
and for a similar converse bound on the optimal correct-decoding exponent,
an expression for which has been given by Oohama \cite[Eq.~22]{Oohama17} without proof.





In the case of discrete memoryless channels,
the mutual information enters into the expressions for correct-decoding and error exponents through the method of types \cite{CsiszarKorner},
\cite{DueckKorner79}.
%offers access to the mutual information.
For %now
the moment
without any %justification,
interpretation,
let us rewrite the sphere-packing
constant-composition %error
exponent %bound
\cite[Eq.~5.19]{CsiszarKorner}
with PDF's:
%probability densities:
\begin{equation} \label{eqLagrangeMultipliers}
\min_{\substack{\\{p\mathstrut}_{Y|X}: \;\;
 I(\,{\widehat{p}\mathstrut}_{X}, \,\, {p\mathstrut}_{Y|X}) \; \leq \; R
}}
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big),
\end{equation}
where ${\widehat{p}\mathstrut}_{X}$ %is
denotes
the Gaussian density with variance $s^{2}$ which maximizes (\ref{eqGaussOpt}),
and $R>0$ is
%denotes
the information rate.
%In the Gaussian case,
When ${\widehat{p}\mathstrut}_{X}$ is Gaussian,
the minimum (\ref{eqLagrangeMultipliers}) allows an explicit solution by the method of Lagrange multipliers.
The minimizing solution ${p\mathstrut}_{Y|X}^{*}$ %(\,\cdot\,\,|\,x)$
of (\ref{eqLagrangeMultipliers}) %is a
%are conditional Gaussian distributions,
is Gaussian,
and we obtain that (\ref{eqLagrangeMultipliers}) is the same as
Shannon's %sphere-packing
converse bound on the error exponent \cite[Eq.~3,~4,~11]{Shannon59}
in the limit of a large block length:
\begin{align}
E_{sp}(R) \; & = \; %\frac{1}{\ln 2}\,
\big[\,
\tfrac{1}{2}A^{2}
\, - \,
\tfrac{1}{2} AG\cos \theta \, - \, \ln(G \sin \theta)
\,\big] \,{\log\mathstrut}_{\!2} \,e , %/ \ln 2,
\label{eqShannonExponent} \\
G \; & = \; \tfrac{1}{2}
(
A \cos \theta \, + \, \sqrt{A^{2}\cos^{2}\theta + 4}
),
\;\;\;
\sin \theta \, = \, 2^{\,-\min\,\{R, \,C\}},
\;\;\;
A \, = \, s/\sigma.
\nonumber
\end{align}
Then it turns out that ${p\mathstrut}_{Y|X}^{*}$ of (\ref{eqLagrangeMultipliers}) and the $y$-marginal PDF
%${\widehat{p}\mathstrut}_{Y}^{\,*}$
of the product ${\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X}^{*}$
%${\widehat{p}\mathstrut}_{Y}^{\,*}(y) \equiv \int_{\mathbb{R}}{\widehat{p}\mathstrut}_{X}(x){p\mathstrut}_{Y|X}^{*}(y\,|\,x)dx$
play the same roles in the derivation of the converse bound,
%the optimal exponent,
as $w$ and ${\widehat{p}\mathstrut}_{Y}$, respectively, in the maximization (\ref{eqGaussOpt}).

In this paper, in order to %justify
derive expressions similar to (\ref{eqLagrangeMultipliers}), we extend the method of types \cite[Ch.~11.1]{CoverThomas},
\cite{Csiszar98}
to include
countable alphabets consisting of real numbers, with the help of power constraints on types.
The countable alphabets depend on the block length $n$ and the number of types
satisfying the power constraints
is kept sub-exponential in $n$.
The latter idea is inspired by a different subject --- of ``runs'' in a binary sequence.
If we treat every ``run'' of ones or zeros in a binary sequence as a separate symbol
from the countable alphabet of run-lengths,
then the number of different empirical distributions of such symbols in a binary sequence of length $n$
is equivalent to the number of different partitions of the integer $n$
into sum of positive integers, which is $\sim e^{c\sqrt{n}}$
\cite[Eq.~5.1.2]{Andrews}.
Thus it is sub-exponential, and the method of types can be %applied in
extended to
that case.
In our present case, however, the types are empirical distributions
%probability mass functions
%frequency distributions
of
uniformly quantized real numbers
%symbols in uniformly
in quantized versions of real channel input and output vectors
of length $n$. The quantized versions serve %are used
only for classification of channel input and output vectors and not for %in
the communication itself.
The uniform quantization step is %are %not the same
different for the quantized versions of channel inputs and outputs,
and %they are
in both cases it
is chosen to be a decreasing function of $n$.

Similarly as (\ref{eqGaussOpt}),
the proposed derivations demonstrate, that, in order to achieve the converse bounds
on the correct-decoding and error exponents,
it is necessary for
the types of the quantized versions of codewords to converge to the Gaussian distribution
in characteristic function (CF), or, equivalently, in
cumulative distribution function (CDF).

The contributions of the current paper are twofold.
Firstly, we successfully apply the method of types %for derivation of the
to derive
converse bounds on the exponents of the AWGN channel.
Secondly, we %derive
prove the converse bound on the correct-decoding exponent \cite[Eq.~22]{Oohama17}
for the first time.
%, an expression for which although appears in \cite[Eq.~22]{Oohama17},
%but %to our knowledge has
%seems to have never been proved before now.
This underscores the advantage of the method of types.

In Sections~\ref{ComSys} and~\ref{Defs}
we describe the communication system and introduce other definitions.
%In Section~\ref{Defs}
In Section~\ref{Main} we present the main results of the paper,
which consist of two theorems and a proposition.
Section~\ref{MOT} provides an extension to the method of types.
In Section~\ref{ConvLemma} we prove a converse lemma,
which is then used %in the derivations
for derivation of both the correct-decoding and error exponents
in Sections~\ref{CorDecExp} and~\ref{ErrExp}, respectively.
Section~\ref{PDFtypePDF} %is dedicated to the connection
connects between PDF's and types.


\section*{Notation}\label{Not}


Countable alphabets consisting of real numbers
%Discrete alphabets
are denoted by ${\cal X}_{n}$, ${\cal Y}_{n}$.
The set of types with denominator $n$ over %the alphabet
${\cal X}_{n}$
is denoted by ${\cal P}_{n}({\cal X}_{n})$.
Capital `$P\,$' denotes probability mass functions, which are types:
${P\mathstrut}_{\!X}$, ${P\mathstrut}_{\!Y}$, ${P\mathstrut}_{\!XY}$, ${P\mathstrut}_{\!Y|X}$.
%A type class and a conditional type class are denoted as $T({P\mathstrut}_{\!X})$
%and
The type class and the support of a type ${P\mathstrut}_{\!X}$ are denoted by
$T({P\mathstrut}_{\!X})$ and ${\cal S}({P\mathstrut}_{\!X})$, respectively.
The expectation w.r.t. a probability distribution ${P\mathstrut}_{\!X}$ is denoted by $\mathbb{E}_{{P\mathstrut}_{\!X}}[\,\cdot\,]$.
Small `$p$' denotes probability density functions: ${p\mathstrut}_{X}$, ${p\mathstrut}_{Y}$, ${p\mathstrut}_{XY}$,
${p\mathstrut}_{Y|X}$.
Thin letters $x$, $y$ represent real values, while thick letters ${\bf x}$, ${\bf y}$ represent real vectors. %of length $n$.
Capital letters $X$, $Y$ %, $J$, $L$, $U$, $D$
represent random variables, %while
boldface ${\bf Y}$ %, ${\bf U}$, ${\bf D}$
represents a random vector of length $n$.
The conditional type class of ${P\mathstrut}_{\!X|\,Y}$ given ${\bf y}$ is denoted by $T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$.
The %respective
quantized versions of variables are denoted by a superscript `$q$': $x^{q}_{k}$, ${\bf x}^{q}$, ${\bf Y}^{q}$.
%The channel conditional PDF is denoted by $w$.
Small $w$ stands for a conditional PDF, and
%Notation
${W\mathstrut}_{\!n}$ stands for a discrete positive measure, which does not necessarily add up to $1$.
%The related discrete positive measure, which doesn't necessarily sum up to $1$, is denoted as ${W\mathstrut}_{\!n}$.
All information-theoretic quantities %like the entropy
such as joint and conditional entropies
$H({P\mathstrut}_{\!XY})$, $H(Y\,|\,X)$, the mutual information
$I({P\mathstrut}_{\!XY})$,
$I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)$,
$I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)$, the Kullback-Leibler divergence
$D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)$,
$D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)$,
and the information rate $R$
are defined with respect to the
logarithm to a base $b>1$, denoted as
$\,{\log\mathstrut}_{\!b}(\cdot)$.
It is assumed that $0 \,{\log\mathstrut}_{\!b} (0) = 0$.
The natural logarithm is denoted as $\ln$.
The cardinality of a discrete set is denoted by $|\,\cdot\,|$, while the volume of a continuous region is denoted by $\text{vol}\,(\cdot)$.
The complementary set of a set $A$ is denoted by $A{\mathstrut}^{c}$.
Logical ``or'' and ``and'' are represented by the symbols $\lor$ and $\land$, respectively.
In Appendix B, ${p\mathstrut}_{XY}^{q}$ represents the rounded down version of the PDF ${p\mathstrut}_{XY}$.
%The $y$-marginal of ${p\mathstrut}_{XY}^{q}$ is denoted by ${p\mathstrut}_{Y}^{q}$.
%The related mutually-complementary probability mass functions, which sum up separately to less than $1$,
%are denoted there by ${P\mathstrut}_{\!XY}^{q}$, ${P\mathstrut}_{\!XY}^{a}$,
%${P\mathstrut}_{\!Y}^{q}$, ${P\mathstrut}_{\!Y}^{a}$.





%$\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[





%`` ''










































\newpage


\section{Communication system}\label{ComSys}

%\bigskip

We consider communication over the time-discrete %memoryless
additive white Gaussian noise
channel
with real channel inputs $x \in \mathbb{R}$ and channel outputs $y \in \mathbb{R}$
and a %Gaussian
transition probability density
\begin{displaymath}
w(y \, | \, x) \;\; \triangleq \;\; \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(y\, - \,x)^{2}}{2\sigma^{2}}}.
\end{displaymath}

Communication is performed by blocks of $n$ channel inputs. Let $R > 0$ denote a nominal information rate.
Each block is used for transmission of one out of $M$ messages,
where $M = M(n, R) \triangleq \lfloor b^{\,n R}\rfloor$, for some logarithm base $b > 1$.
The encoder is a deterministic function $f: \{1, 2, .\,.\,.\, , \, M\} \rightarrow \mathbb{R}{\mathstrut}^{n}$,
which converts a message into a transmitted block,
such that
\begin{displaymath}
f(m) \; = \; {\bf x}(m)
\; = \; \big(
x_{1}(m), \,x_{2}(m), .\,.\,.\, , \, x_{n}(m)
\big),
\;\;\;\;\;\;\;\;\; m = 1, 2, .\,.\,.\, , \, M,
\end{displaymath}
where $x_{k}(m) \in \mathbb{R}$, for all $k = 1, 2, .\,.\,.\, , \, n$.
The set of all the %used
codewords ${\bf x}(m)$, $m = 1, 2, .\,.\,.\, , \, M$, constitutes a codebook ${\cal C}$.
Each codeword ${\bf x}(m)$ in ${\cal C}$ satisfies the power constraint:
\begin{equation} \label{eqPowerConstraint}
\frac{1}{n}\sum_{k \, = \, 1}^{n}x_{k}^{2}(m) \; \leq \; s^{2},
\;\;\;\;\;\;\;\;\; m = 1, 2, .\,.\,.\, , \, M.
\end{equation}
The decoder is another deterministic function
$g: \mathbb{R}{\mathstrut}^{n} \rightarrow \{0, 1, 2, .\,.\,.\, , \, M\}$,
which converts the received block of $n$ channel outputs ${\bf y} \in \mathbb{R}{\mathstrut}^{n}$
into an estimated message, or, possibly, to %the
a special error symbol `$0$':
\begin{equation} \label{eqDec}
g({\bf y})
\;\; = \;\;
%\left\{
\Bigg\{
\begin{array}{r l}
0, & \;\;\; {\bf y} \in \bigcap_{\,m \, = \, 1}^{\,M} {\cal D}{\mathstrut}_{m}^{c}, \\
m, & \;\;\; {\bf y} \in {\cal D}{\mathstrut}_{m}, \;\;\; %\;\;\;\;\;\;\;\;\;
m \in \{1, 2, .\,.\,.\, , \, M\},
\end{array}
%\right.
%\;\;\;\;\;\;\;\;\; m = 1, 2, .\,.\,.\, , \, M,
\end{equation}
where each set ${\cal D}{\mathstrut}_{m} \subseteq \mathbb{R}{\mathstrut}^{n}$ is either an open region or the empty set, %. The
and the
regions are disjoint:
${\cal D}{\mathstrut}_{m} \cap \,{\cal D}{\mathstrut}_{m'} = \varnothing$
for $m \neq m'$. %^{\,'}$.
Observe that the maximum-likelihood decoder with open decision regions ${\cal D}{\mathstrut}_{m}^{*}\,$, defined for $m = 1, 2, .\,.\,.\, , \, M$
as
\begin{displaymath}
{\cal D}{\mathstrut}_{m}^{*}
\;\; = \;\;
%\left\{
%\begin{array}{l l}
%\displaystyle
\mathbb{R}{\mathstrut}^{n} \setminus
\bigcup_{
%\substack{
m':\;\;
(m' \, < \; m)
\; \lor \;
\big(\,m' \, > \, m \;\, \land \;\, {\bf x}(m') \, \neq \, {\bf x}(m)\,\big)
}
\Big\{
{\bf y}: \;
\|
{\bf y} - {\bf x}(m')
\|
\, \leq \,
\|
{\bf y} - {\bf x}(m)
\|
\Big\},
%& \;\;\;
%{\bf x}(m) \neq {\bf x}(j), \; \forall j < m
%, \\
%\varnothing, & \;\;\; \text{o.w.},
%\end{array}
%\right.
%\;\;\;\;\;\;\;\;\; m = 1, 2, .\,.\,.\, , \, M,
\end{displaymath}
is a special case of (\ref{eqDec}).
%The
Note that the formal
definition of ${\cal D}{\mathstrut}_{m}^{*}$ includes the undesirable possibility of ${\bf x}(m') = {\bf x}(m)$ for $m' \neq m$.


















%\bigskip


\section{Definitions}\label{Defs}

%\bigskip

For each $n$, we define two discrete countable alphabets ${\cal X}_{n}$ and ${\cal Y}_{n}$ %to be
as
one-dimensional lattices:
%, as follows.
\begin{align}
&
\alpha, \beta, \gamma \in (0, 1), \;\;\;
\alpha + \beta + \gamma = 1,
%\;\;\;\;\;\;
\nonumber \\
%\end{align}
%\begin{align}
&
\Delta_{\alpha,\,n} \; \triangleq \; 1/n^{\alpha},
\;\;\;
\Delta_{\beta,\,n} \; \triangleq \; 1/n^{\beta},
\;\;\;
\Delta_{\gamma,\,n} \; \triangleq \; 1/n^{\gamma},
\label{eqDelta} \\
%\end{align}
%\begin{align}
& \Delta_{\alpha,\,n}\cdot \Delta_{\beta,\,n}\cdot \Delta_{\gamma,\,n} \;\; = \;\; 1/n,
\label{eqCube}
\end{align}
\begin{align}
&
{\cal X}_{n} \;\; \triangleq \;\;
\bigcup_{i \, \in \, \mathbb{Z}}\big\{i\Delta_{\alpha,\,n}\big\},
\;\;\;\;\;\;
{\cal Y}_{n} \;\; \triangleq \;\;
\bigcup_{i \, \in \, \mathbb{Z}}\big\{i\Delta_{\beta,\,n}\big\}.
\label{eqAlphabets}
\end{align}
For each $n$, we define also a discrete positive measure (not necessarily a distribution), which will approximate the channel $w$:
\begin{align}
{W\mathstrut}_{\!n}(y \, | \, x) \;\; & \triangleq \;\;
w(y \, | \, x)\cdot\Delta_{\beta,\,n},
\;\;\; \forall x \in {\cal X}_{n}, \; \forall y \in {\cal Y}_{n}.
\label{eqChanApprox}
\end{align}
%\bigskip
%\newpage
%\begin{align}
%{\cal F}_{n} \; & \triangleq \;
%\bigg\{
%f\! : \mathbb{R} \rightarrow \mathbb{R}_{\,\geq\, 0}
%\;\; \Big| \;\;
%f \in
%C_{\text{bounded}}^{0}\Big(\cup_{\,j \, \in \, \mathbb{Z}}\big( (j - 1/2)\Delta_{\beta,\,n}, \; (j + 1/2)\Delta_{\beta,\,n}\big)\Big);
%\;
%\int_{\mathbb{R}}f(y)dy = 1
%\bigg\},
%\nonumber
%\end{align}
Denoting by $C^{0}(A)$ a class of functions $f\! : \mathbb{R} \rightarrow \mathbb{R}_{\,\geq\, 0}$
continuous on an open subset $A \subseteq \mathbb{R}$,
we define %the following
%a set of functions:
\begin{align}
%{\cal F} \; & \triangleq \;
%\bigg\{
%f\! : \mathbb{R} \rightarrow \mathbb{R}_{\,\geq\, 0}
%\;\;\; \Big| \;\;\;
%f \in
%C^{0}(\mathbb{R});
%\;\;
%\int_{\mathbb{R}}|\,f(y)\ln f(y)\,| \,dy \, < \, +\infty;
%\;\;
%\int_{\mathbb{R}}f(y)dy = 1
%\bigg\},
%\label{eqFiniteEntropy} \\
%\end{align}
%\begin{align}
{\cal F}_{n} \; & \triangleq \;
\bigg\{
f\! : \mathbb{R} \rightarrow \mathbb{R}_{\,\geq\, 0}
\;\;\; \Big| \;\;\;
\sup_{y\,\in\,\mathbb{R}}f(y)< +\infty; \;\;\;
f \in
C^{0}\big(\mathbb{R} \setminus \{ {\cal Y}_{n} +  %\tfrac{1}{2}
\Delta_{\beta,\,n}/2 \}\big);
\;\;
\int_{\mathbb{R}}f(y)dy = 1
\bigg\}.
\label{eqBoundedContinuous}
\end{align}
The %second
set (\ref{eqBoundedContinuous}), defined for a given $n$, will be used only in the derivation of the correct-decoding exponent,
while the following set of functions will be used only in the derivation of the error exponent:
%\begin{align}
%{\cal F}_{n} \; & \triangleq \;
%\bigg\{
%f\! : \mathbb{R} \rightarrow \mathbb{R}_{\,\geq\, 0}
%\;\; \Big| \;\;
%\sup_{y\,\in\,\mathbb{R}}f(y)< +\infty; \;\;
%f \in
%C^{0}\Big(\mathbb{R} \setminus \bigcup_{\,j \, \in \, \mathbb{Z}}\big\{ (j + 1/2)\Delta_{\beta,\,n}\big\}\Big);
%\;
%\int_{\mathbb{R}}f(y)dy = 1
%\bigg\},
%%\label{eqBoundedContinuous}
%\nonumber
%\end{align}
\begin{align}
{\cal L} \; & \triangleq \;
\bigg\{
f\! : \mathbb{R} \rightarrow \mathbb{R}_{\,\geq\, 0}
\;\; \Big| \;\;
|f(y_{1}) - f(y_{2})| \leq  %\frac{|y_{1} - y_{2}|}{\sigma^{2}\sqrt{2\pi e}},
K|y_{1} - y_{2}|,
\; \forall y_{1}, y_{2}\,;
\;
\int_{\mathbb{R}}f(y)dy = 1
\bigg\}, \;\; K  \triangleq \frac{1}{\sigma^{2}\sqrt{2\pi e}}.
\label{eqLipschitz} %\\
%&
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
%K \; \triangleq \; \tfrac{1}{\sigma^{2}\sqrt{2\pi e}}.
%\nonumber
\end{align}
Note that ${\cal L}$ is a convex set and also %the maximum value of
each function $f \in {\cal L}$ is %automatically
bounded and cannot exceed $\sqrt{K}$.

With a parameter $\rho \in (-1, \, +\infty)$, we define the following Gaussian probability density functions: %(PDF):
\begin{align}
{p\mathstrut}_{Y|X}^{(\rho)}(y \, | \, x) \;\; & \triangleq \;\; \tfrac{1}{\sigma{\mathstrut}_{Y|X}(\rho)\sqrt{2\pi}}
\exp\Big\{\!-\tfrac{(y \, - \, k_{\rho} %_{\,Y|X}^{(\rho)}\cdot
\, \cdot \, x)^{2}}{2\sigma_{Y|X}^{2}(\rho)}
\Big\},
%\;\;\;\;\;\; \rho \, > \, -1,
\label{eqSolution} \\
k_{\rho} %_{\,Y|X}^{(\rho)}
%\; = \; \tfrac{\sigma_{Y|X}^{2}(\rho)}{(1\, + \,\rho)\sigma^{2}}
\;\; & \triangleq \;\;
\tfrac{
\text{SNR} \, - \, \rho \, - \, 1
\; + \;
\sqrt{(\text{SNR} \, - \, \rho \, - \, 1)^{2} \; + \; 4\,\cdot\,\text{SNR}}
}
{2\,\cdot\,\text{SNR}},
\;\;\;\;\;\; \text{SNR} \,\triangleq \, s^{2}/\sigma^{2},
\label{eqSquareroot} \\
\sigma_{Y|X}^{2}(\rho) \;\; & \triangleq \;\;
(1 + \rho)k_{\rho}\,\sigma^{2},
\label{eqSigmaYXDef} \\
{\widehat{p}\mathstrut}_{Y}^{\,(\rho)}(y) \;\; & \triangleq \;\; \tfrac{1}{\sigma{\mathstrut}_{Y}(\rho)\sqrt{2\pi}}
\exp\Big\{\!-\tfrac{y^{2}}{2\sigma_{Y}^{2}(\rho)}
\Big\},
\label{eqIdealYPDF} \\
\sigma_{Y}^{2}(\rho)
\;\; & \triangleq \;\;
\sigma^{2} \, + \, k_{\rho}\, %_{\,Y|X}^{(\rho)}
s^{2},
\label{eqSigmaY} \\
{\widehat{p}\mathstrut}_{X}(x) \;\; & \triangleq \;\;
\tfrac{1}{s\sqrt{2\pi}}\exp\Big\{\!-\tfrac{x^{2}}{2s^{2}}
\Big\}.
\label{eqIdealXPDF}
\end{align}
The first property of the following lemma shows that ${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$
is the $y$-marginal PDF of the product $\,{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X}^{(\rho)}$.

\bigskip

\begin{lemma}[Properties of (\ref{eqSolution})-(\ref{eqIdealXPDF})] \label{LemSigmaZ}%\newline
%{\em PDF $\,{\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$ %defined by (\ref{eqIdealYPDF}) and (\ref{eqSigmaY})
%is the marginal of the product $\,{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X}^{(\rho)}$:}
%%, with ${\widehat{p}\mathstrut}_{X}$ and ${p\mathstrut}_{Y|X}^{(\rho)}$
%%defined by (\ref{eqIdealXPDF}), (\ref{eqSolution}), (\ref{eqSquareroot})
{\em The following properties hold:}
\begin{align}
\sigma_{Y}^{2}(\rho)
\;\; & = \;\;
\sigma_{Y|X}^{2}(\rho) \, + \, k_{\rho}^{2}\, %_{\,Y|X}^{(\rho)}
s^{2},
\label{eqIdealYMarginal} \\
%\end{align}
%{\em Further}
%\begin{align}
%\frac{1 + \rho}{\sigma_{Y|X}^{2}(\rho)} \;\; & = \;\; \frac{\rho}{\sigma_{Y}^{2}(\rho)} \, + \, \frac{1}{\sigma^{2}}.
\frac{1 + \rho}{\sigma_{Y|X}^{2}(\rho)} \;\; & = \;\; \frac{\rho}{\sigma_{Y}^{2}(\rho)} \, + \, \frac{1}{\sigma^{2}},
\label{eqProperty} \\
\sigma_{Y|X}^{2}(\rho)
\;\; & = \;\;
\sigma^{2} \, + \, k_{\rho}(1 - k_{\rho})
s^{2},
\label{eqSigmaYX} \\
%\end{align}
%\begin{align}
1 \, & \geq \,k_{\rho} \, > \, 0, \;\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,\,
\rho \geq 0,
\label{eqPropk} \\
\tfrac{1}{2}
\big[ 1
\; + \;
\sqrt{1 \; + \; 4 \sigma^{2}s^{-2}}\,
\big]
\, & \geq \,k_{\rho} \, \geq \, 1, \;\;\;\;\;\; -1 \leq \rho \leq 0,
\label{eqPropk2} \\
{p\mathstrut}_{Y|X}^{(\rho)}(\,\cdot\,\,|\,x) \, & \in \, {\cal L}, \;\;\;\;\;\; \forall \rho \geq 0, \;
\forall x \in \mathbb{R},
\label{eqInL}
%\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}^{(\rho)}}\!\big[(Y-X)^{2}\big]
%\;\; & \leq \;\; \sigma^{2} \, + \, \sigma_{X}^{2},
%\;\;\;\;\;\; \forall \rho \geq 0.
%%\label{eqSigmazBound}
%\nonumber
\end{align}
%{\em Let ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ be a type,
%such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] = \sigma_{X}^{2} \, \leq \, s^{2} + \epsilon$, $\;\epsilon > 0$. Then
%}
{\em %Let $(X, Y)$ be
and for any two jointly distributed random variables $(X, Y)$, such that
$\mathbb{E}%_{{P\mathstrut}_{\!X}}\!
\big[X^{2}\big] = \sigma_{X}^{2} \, \leq \, s^{2} + \epsilon$, $\;\epsilon > 0$,
and $Y \,|\, X = x \; \sim \; {\cal N}\big(k_{\rho}\,x, \, \sigma_{Y|X}^{2}(\rho)\big)$, %Then
it holds that
}
\begin{align} %\label{eqSigmaZ}
\mathbb{E}%_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}^{(\rho)}}\!
\big[(Y-X)^{2}\big]
\;\; & = \;\;
\sigma^{2} \, + \, (1 - k_{\rho})s^{2} \, + \, (1 - k_{\rho})^{2}
%\big(\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big]
(\sigma_{X}^{2}
- s^{2})
\label{eqSigmaZ} \\
& \leq \;\;
\Bigg\{
\begin{array}{l r}
\sigma^{2} \, + \, s^{2} \, + \, \epsilon, &
\;\;\;\;\;\;  \rho \geq 0, \\
\sigma^{2} \, + \,
\epsilon\sigma^{2}s^{-2}, &
\;\;\;\;\;\;
 -1 < \rho \leq 0.
\end{array}
\label{eqSigmazBound}
\end{align}
\end{lemma}
%\bigskip
\begin{proof}
The first property (\ref{eqIdealYMarginal}) can be verified using (\ref{eqSigmaY}), (\ref{eqSigmaYXDef}), (\ref{eqSquareroot}).
Then (\ref{eqProperty}) can be obtained from (\ref{eqIdealYMarginal}), (\ref{eqSigmaY}), (\ref{eqSigmaYXDef}).
Property (\ref{eqSigmaYX}) follows by (\ref{eqIdealYMarginal}) and (\ref{eqSigmaY}).
It can be verified from (\ref{eqSquareroot}) that $k_{\rho}$ is a positive monotonically decreasing function of $\rho$,
such that $k_{0} = 1$. Then we get (\ref{eqPropk}) and (\ref{eqPropk2}).
From (\ref{eqSigmaYX}) and (\ref{eqPropk}) we see that $\sigma_{Y|X}^{2}(\rho) \geq \sigma^{2}$ for all $\rho \geq 0$,
which gives (\ref{eqInL}).
Equality (\ref{eqSigmaZ}) can be obtained using (\ref{eqSigmaYX}).
Then, using (\ref{eqPropk}) and (\ref{eqPropk2}), we obtain (\ref{eqSigmazBound}).
\end{proof}

The following expressions will describe our results for the error and correct-decoding exponents:
\begin{align}
E_{e}(R) \;\; & \triangleq \;\;
\;\;
\sup_{\rho\,\geq\,0}
\;\;
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho
\big[
I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big)
\, - \,
R
\big]
\Big\},
\label{eqEDef} \\
E_{c}(R) \;\; & \triangleq \;\;
\sup_{\!\!\!\!\! -1 \, < \, \rho\,\leq\,0}
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho
\big[
I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big)
\, - \,
R
\big]
\Big\}.
\label{eqECDef}
\end{align}
The following identity can be obtained
using %the definitions of ${p\mathstrut}_{Y|X}^{(\rho)}$ and ${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$
%in
(\ref{eqSolution}),  %and their properties
(\ref{eqSigmaYXDef}), (\ref{eqIdealYPDF}), (\ref{eqIdealXPDF}), (\ref{eqProperty}):
\begin{align}
& D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho
I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big)
\;\; \equiv \;\;
c_{0}(\rho) \, + \, c_{1}(\rho)s^{2},
\nonumber \\
& c_{0}(\rho) \;\; \triangleq \;\; \frac{1}{\ln b} %{\log\mathstrut}_{\!b}
\ln\bigg(\frac{\sigma \cdot \sigma_{Y}^{\rho}(\rho)}{\sigma_{Y|X}^{1\,+\,\rho}(\rho)}\bigg),
\;\;\;\;\;\;\;\;\;
c_{1}(\rho) \;\;
\triangleq \;\; \frac{1 - k_{\rho}}{2\sigma^{2}\ln b}.
\label{eqC0C1}
\end{align}
We note also that $c_{0}(\rho) \rightarrow 0$, as $\rho \rightarrow +\infty$, which can be verified using the properties (\ref{eqSigmaYXDef}), (\ref{eqSigmaY}), and (\ref{eqSigmaYX}).
It can be verified that the expression inside the supremum of (\ref{eqEDef})
is equivalent to the expression for the Gaussian random-coding
error exponent of Gallager before the maximization over $\rho$ \cite[Eq.~7.4.24 with Eq.~7.4.28]{Gallager}.
Therefore, with the supremum over $\rho \geq 0$,
the expression (\ref{eqEDef}) coincides with the converse sphere-packing bound of Shannon
(\ref{eqShannonExponent}).
%\cite[Eq.~3,~4,~11]{Shannon59}.










%\bigskip


%\begin{prop}[Parametric representation] \label{prpErrorExp}
%{\em For $R \,\leq\, \frac{1}{2}\,{\log\mathstrut}_{\!b} (1 + \text{\rm SNR})$}
%\begin{align}
%R \, & = \, I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big),
%\;\;\;\;\;\;
%%\nonumber \\
%E_{e}(R) \, = \, D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big),
%\;\;\;\;\;\; \rho \geq 0.
%\nonumber
%\end{align}
%\end{prop}























%\bigskip

\section{Main results}\label{Main}

%\bigskip

In this section we present two theorems and a proposition.
The proof of the first theorem relies on Lemmas~\ref{LemAllCodebooks} and~\ref{LemPDFtoT},
which appear in Sections~\ref{ErrExp} and~\ref{PDFtypePDF}, respectively.

\bigskip

\begin{thm}[Error exponent] \label{thmErrorExp}
{\em
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
Then
}
\begin{align}
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;
\sup_{{\cal C}}
\;
\sup_{g}
\;
\bigg\{\!
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) \neq J \big\}
\bigg\}
%\nonumber \\
\;\; & \leq \;\;
E_{e}(R),
%\sup_{\substack{\rho\,\geq\,0}}
%\;
%\Big\{
%D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
%\, + \,
%\rho
%\big[
%I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big)
%\, - \,
%R
%\big]
%\Big\}.
\nonumber
\end{align}
{\em where $E_{e}(R)$ is defined by (\ref{eqEDef}), decoder functions $g$ are defined by (\ref{eqDec}), and codebooks ${\cal C}$ satisfy (\ref{eqPowerConstraint}).}
\end{thm}

\bigskip

%{\em Proof of Theorem~\ref{thmErrorExp}:}
\begin{proof}
Starting from Lemma~\ref{LemAllCodebooks}, we can write the following sequence of inequalities:
\begin{align}
&
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;\;\;
\sup_{{\cal C}}
\;\;
\sup_{g}
\;\;
\left\{
- \frac{1}{n}\,{\log\mathstrut}_{\!b} \Pr \big\{
g({\bf Y}) \neq J \big\}
\right\}
\label{eqReliabilityF} \\
\overset{a}{\leq} \;\; &
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;
\max_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;\;\;\;\;
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \sigma^2 \, + \, s^{2} \, + \, 2\epsilon, %c(\sigma, \, s, \,\epsilon),
\\ I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X}) \; \leq \; R \, - \, \epsilon
}}
\!\!\!\!\!
\!
%\,\,
\;\,\,
%\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
%\Big\}
\label{eqCCExponent} \\
\overset{b}{\leq} \;\; &
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;
\max_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;\;\;\;\;\,
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal L}, \; \forall x,
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \sigma^2 \, + \, s^{2} \, + \, \epsilon,
\\ I({P\mathstrut}_{\!X}, \,\, {p\mathstrut}_{Y|X}) \; \leq \; R \, - \, 2\epsilon
}}
\!\!\!\!\!
\;\,\,
%\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
%\Big\}
\label{eqInf1} \\
%\overset{\text{a.e.}}{\underset{c}{=}}  \,\,\,
\overset{c}{=}
\;\; &
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;
\max_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;
\sup_{\substack{\rho\,\geq\,0}}
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal L}, \; \forall x,
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \sigma^2 \, + \, s^{2} \, + \, \epsilon
}}
\!\!\!\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\, + \,
\rho
\Big[
I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
 -
R
+
2\epsilon
\Big]
\Big\}
\label{eqInf2} \\
\overset{d}{\leq}  \;\; &
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;
\max_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;
\sup_{\substack{\rho\,\geq\,0}}
\!\!\!\!\!
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\, + \,
\rho
\Big[
I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}^{(\rho)}\big)
 -
R
+
2\epsilon
\Big]
\Big\}
\nonumber \\
\overset{e}{\equiv}  \;\; &
\limsup_{\substack{n\,\rightarrow\,\infty}}
\;
\max_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;
\sup_{\substack{\rho\,\geq\,0}}
\!\!\!\!\!
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\Big\{
c_{0}(\rho) \, + \, c_{1}(\rho)\,%\cdot
\mathbb{E}\big[X^{2}\big]
\, + \,
\rho
\Big[
\! - \!
D\big(\,{p\mathstrut}_{Y}^{\,(\rho)}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\rho)} \big)
-
R
+
2\epsilon
\Big]
\Big\}
\label{eqMax} \\
\overset{f}{\leq}  \;\; &
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
\sup_{\substack{\rho\,\geq\,0}}
\!\!\!\!\!
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\Big\{
c_{0}(\rho) \, + \, c_{1}(\rho)%\cdot
(s^{2} + \epsilon)
%\mathbb{E}\big[X^{2}\big]
\, - \,
\rho (R - 2\epsilon)
\Big\},
\label{eqWithEpsilon}
\end{align}
%Commentary:
where:

($a$) holds for any $\epsilon > 0$ by Lemma~\ref{LemAllCodebooks} with $c_{XY} = \sigma^2 + s^{2} + 2\epsilon$.
Note also
that $D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)$ in (\ref{eqCCExponent})
denotes the Kullback–Leibler divergence %of
between
the probability distribution ${P\mathstrut}_{\!Y|X}$ %from
and
the positive measure ${W\mathstrut}_{\!n}$ defined in (\ref{eqChanApprox}),
which is not a probability distribution but only approximates the channel $w$.

($b$) follows by Lemma~\ref{LemPDFtoT} for the alphabet parameters $\alpha \in \big(0, \tfrac{1}{4}\big)$
and $\tfrac{1}{3} + \tfrac{2}{3}\alpha < \beta < \tfrac{2}{3} - \tfrac{2}{3}\alpha$.

($c$) holds %with the equality
for all $R > 0$ with the possible exception of the {\em single point} on $R$-axis
where (\ref{eqInf1}) may transition between a finite value and $+\infty$.
%a jump to infinity of (\ref{eqInf1}).
%as a function of $R$.
For the equality, let us compare the infimum of (\ref{eqInf1}) and the supremum over $\rho \geq 0$ in (\ref{eqInf2})
as functions of $R \in \mathbb{R}$.
First, it can be observed that the supremum %over $\rho \geq 0$
of (\ref{eqInf2})
is the lower convex envelope of the infimum of (\ref{eqInf1}). %, and therefore it is the lower semicontinuous version of this infimum.
Second, the infimum of (\ref{eqInf1}) itself
is a convex ($\cup$) %and lower semicontinuous
function of $R$. Then they coincide for all values of $R$, except possibly for the single point where
%there is a jump to infinity
%of the infimum of (\ref{eqInf1}).
%of both these functions.
they both jump to $+\infty$.
%Then this %behavior
This
property carries over to the external %``$\limsup \; \max$''
`$\limsup \; \max$'
as well.

($d$) follows because
by (\ref{eqSigmazBound}) and (\ref{eqInL}) function ${p\mathstrut}_{Y|X}^{(\rho)}$
satisfies the conditions under the infimum of (\ref{eqInf2}).

($e$) holds as equality inside the supremum over $\rho \geq 0$, separately for each $\rho$.
In (\ref{eqMax})
by ${p\mathstrut}_{Y}^{\,(\rho)}$ we denote the corresponding marginal PDF of the product
${P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}^{(\rho)}$ and use the %following
definitions (\ref{eqC0C1}).
%\begin{align}
%c_{0}(\rho) \;\; & \triangleq \;\; \frac{1}{\ln b} %{\log\mathstrut}_{\!b}
%\ln\bigg(\frac{\sigma \cdot \sigma_{Y}^{\rho}(\rho)}{\sigma_{Y|X}^{1\,+\,\rho}(\rho)}\bigg),
%%\;\; \leq \;\;
%%\frac{1}{\ln b}\bigg[
%%\ln\bigg(\frac{\sigma^{2}}{\sigma_{Y}^{2}(\rho)}\bigg) \, + \, \frac{\sigma_{Y|X}^{2}(\rho)s^{2}}{2(1 + \rho)\sigma^{4}}
%%\bigg]
%%\;\; \underset{\rho\, \rightarrow \,+\infty}{\longrightarrow} \;\; 0,
%%\nonumber \\
%\;\;\;\;\;\;\;\;\;
%c_{1}(\rho) \;\; %&
%\triangleq \;\; \frac{1 - k_{\rho}}{2\sigma^{2}\ln b}.
%\nonumber
%\end{align}
Then ($e$) follows by the definitions of ${p\mathstrut}_{Y|X}^{(\rho)}$ and ${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$
in (\ref{eqSolution}), (\ref{eqIdealYPDF}), and by their properties (\ref{eqSigmaYXDef}), (\ref{eqProperty}).
%We note also that $c_{0}(\rho) \rightarrow 0$, as $\rho \rightarrow +\infty$, which can be verified using the properties (\ref{eqSigmaYXDef}), (\ref{eqSigmaY}), and %(\ref{eqSigmaYX}).

($f$) follows by the non-negativity of the divergence, and by the condition under the maximum of (\ref{eqMax}),
since $c_{1}(\rho)\geq 0$ for $\rho \geq 0$.

In conclusion, according to ($c$) we obtain that the inequality between (\ref{eqReliabilityF}) and (\ref{eqWithEpsilon}),
as functions of $R$, holds for all $R > 0$,
%with the possible exception of
except possibly for
the single point $R = 2\epsilon$, where the jump to $+\infty$ in (\ref{eqWithEpsilon}) occurs.
Therefore, taking the limit as $\epsilon \rightarrow 0$, we obtain that (\ref{eqReliabilityF}) is upper-bounded for all $R > 0$ by
\begin{displaymath}
\sup_{\substack{\rho\,\geq\,0}}
\;
\big\{
c_{0}(\rho) \, + \, c_{1}(\rho)s^{2}
\, - \,
\rho R
\big\},
\end{displaymath}
which is the same as (\ref{eqEDef}).
\end{proof}

%\bigskip

The second theorem relies on Lemmas~\ref{LemCorDec} and~\ref{LemTtoPDF},
which appear in Sections~\ref{CorDecExp} and~\ref{PDFtypePDF}, respectively.

\bigskip



\begin{thm}[Correct-decoding exponent] \label{thmCorDecExp}
{\em
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
Then}
\begin{align}
\liminf_{\substack{n\,\rightarrow\,\infty}}
\;
\inf_{{\cal C}}
\;
\inf_{g}
\;
\bigg\{\!
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) = J \big\}
\bigg\}
%\nonumber \\
\;\; & \geq \;\;
E_{c}(R),
\nonumber
\end{align}
{\em where $E_{c}(R)$ is defined by (\ref{eqECDef}), decoder functions $g$ are defined by (\ref{eqDec}), and codebooks ${\cal C}$ satisfy (\ref{eqPowerConstraint}).}
\end{thm}


\bigskip

\begin{proof}
Starting from Lemma~\ref{LemCorDec}, for each $R > 0$ we can choose a different parameter $\widetilde{\sigma} = \widetilde{\sigma}(R) \geq \sigma$,
such that there is equality $E(\widetilde{\sigma}(R)) = E_{c}(R)$ between (\ref{eqOutlierExp}) and (\ref{eqECDef}).
Then by (\ref{eqMinofTwoExponents2}) we obtain
\begin{align}
\liminf_{\substack{n\,\rightarrow\,\infty}}
\;
\inf_{{\cal C}}
\;
\inf_{g}
\;
\bigg\{\!
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) = J \big\}
\bigg\}
\;\; & \geq \;\;
\min\Big\{
\liminf_{\substack{n\,\rightarrow\,\infty}}
\,
E_{n}(R, \,\widetilde{\sigma}(R), \, \widetilde{\epsilon}, \, \epsilon), \;\;
E_{c}(R)
\Big\}.
\nonumber
\end{align}
%The first term
%in the minimum
%$E_{n}(R, \,\widetilde{\sigma}(R), \, \widetilde{\epsilon}, \, \epsilon)$ in the minimum of (\ref{eqMinofTwoExponents2})
With the choice $2\widetilde{\epsilon} = \epsilon\sigma^{2}s^{-2}$,
the first term
in the minimum
can be lower-bounded as follows:
\begin{align}
&
\liminf_{\substack{n\,\rightarrow\,\infty}}
\,
\min_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2}(R) \, + \, \widetilde{\epsilon}
%\;\, \leq \;\, \widetilde{\sigma}^{2}(R) \; + \; \epsilon %\, \cdot \,
%\sigma^{2}s^{-2}
}}
\!\!
\,
\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\, + \,
\big|\,
R \, - \, I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)
\,\big|^{+}
\Big\}
\nonumber \\
\overset{a}{\geq} \;
&
\liminf_{\substack{n\,\rightarrow\,\infty}}
\min_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}_{n}, \; \forall x,
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2}(R) \, + \, 2\widetilde{\epsilon}
%\;\, \leq \;\, \widetilde{\sigma}^{2}(R) \; + \; 2\epsilon %\, \cdot \,
%\sigma^{2}s^{-2}
}}
\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\, + \,
\big|\,
R \, - \, I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
\,\big|^{+}
\Big\}
%\; + \; o(1)
\nonumber \\
\overset{b}{\geq} \;
&
\liminf_{\substack{n\,\rightarrow\,\infty}}
\min_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}_{n}, \; \forall x,
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2}(R) \, + \, 2\widetilde{\epsilon}
}}
\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\, - \,
\rho \Big[
R
\, - \,
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\rho)} \,|\, {P\mathstrut}_{\!X}\big)
\Big]%\cdot
%\rho
\Big\}
%\; + \; o(1)
\nonumber
\end{align}
\begin{align}
\overset{c}{\equiv} \;
&
\liminf_{\substack{n\,\rightarrow\,\infty}}
\min_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}_{n}, \; \forall x,
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2}(R) \, + \, 2\widetilde{\epsilon}
}}
\!\!
\Big\{
c_{0}(\rho) \, + \, c_{1}(\rho)\,%\cdot
\mathbb{E}\big[X^{2}\big]
\, - \, \rho R
\, + \,
(1 + \rho)
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {p\mathstrut}_{Y|X}^{(\rho)} \,|\, {P\mathstrut}_{\!X}\big)
\Big\}
%\; + \; o(1)
\nonumber \\
%\end{align}
%\begin{align}
\overset{d}{=} \;
&
\liminf_{\substack{n\,\rightarrow\,\infty}}
\min_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,\,
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
%\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,\,
\!\!
\Big\{
c_{0}(\rho) \, + \, c_{1}(\rho)\,%\cdot
\mathbb{E}\big[X^{2}\big]
\, - \, \rho R
\Big\}
%\; + \; o(1)
\label{eqMin2} \\
%\end{align}
%\begin{align}
\overset{e}{\geq} \;
&
\!\!
\;\;\;\;\;\;\;\;\;\;\;\;\;
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\;\;
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,
%\Big\{
c_{0}(\rho) \, + \, c_{1}(\rho)%\cdot
(s^{2} + \epsilon)
\, - \, \rho R,
%\Big\}
%\; + \; o(1)
\label{eqAnyRho}
\end{align}
%Commentary:
where:

($a$) follows by Lemma~\ref{LemTtoPDF} with $c_{XY} = \widetilde{\sigma}^{2}(R) + \widetilde{\epsilon}$.

($b$) holds for $\rho \in (-1, 0]$, because
$\big|\,
R \, - \, I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
\,\big|^{+} \, \geq \, -\rho \big[\,
R \, - \, I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
\,\big]$ for any such $\rho$, and because
$I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big) \leq D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\rho)} \,|\, {P\mathstrut}_{\!X}\big)$,
where ${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$ is the Gaussian PDF defined in (\ref{eqIdealYPDF}).

($c$) holds as an identity inside the infimum by the definitions (\ref{eqSolution}), (\ref{eqIdealYPDF}), (\ref{eqC0C1}),
and properties (\ref{eqSigmaYXDef}), (\ref{eqProperty}).

($d$) holds if $2\widetilde{\epsilon} \geq \epsilon\sigma^{2}s^{-2}$ and $\rho \in (-1, 0]$, because then
by (\ref{eqSigmazBound}) and (\ref{eqBoundedContinuous})
the function ${p\mathstrut}_{Y|X}^{(\rho)}$
satisfies the conditions under the infimum
and achieves
the infimum.

($e$) follows by the condition under the minimum of (\ref{eqMin2}) since $c_{1}(\rho) \leq 0$
for $\rho \in (-1, 0]$.

In conclusion,
since (\ref{eqAnyRho}) is the lower bound for any $\rho \in (-1, 0]$ and $2\widetilde{\epsilon} \geq \epsilon\sigma^{2}s^{-2}$,
we obtain
\begin{displaymath}
\liminf_{\substack{n\,\rightarrow\,\infty}}
\,
E_{n}\big(R, \,\widetilde{\sigma}(R), \, \epsilon\sigma^{2}s^{-2}/2, \, \epsilon\big)
\;\; \geq \;\;
\sup_{\!\!\!\!\! -1 \, < \, \rho\,\leq\,0}
\big\{
c_{0}(\rho) \, + \, c_{1}(\rho)
(s^{2} + \epsilon)
\, - \, \rho R
\big\}
\;\; \overset{\epsilon\, \rightarrow \,0}{\longrightarrow} \;\; E_{c}(R).
\end{displaymath}
\end{proof}
%\bigskip

{\em Remark:} Observe that %both
neither
the inequality ($f$) in the proof of Theorem~\ref{thmErrorExp}
%and
nor the inequality ($b$) in the proof of Theorem~\ref{thmCorDecExp}
%cannot
can be met with equality unless
$D\big(\,{p\mathstrut}_{Y}^{\,(\rho)}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\rho)} \big) \rightarrow 0$,
where ${p\mathstrut}_{Y}^{\,(\rho)}$ is the $y$-marginal PDF of
${P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}^{(\rho)}$.
%Since both ${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$ and ${p\mathstrut}_{Y|X}^{(\rho)}$ are Gaussian,
%It follows, that,
Accordingly, since ${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$ is Gaussian, while ${p\mathstrut}_{Y}^{\,(\rho)}$
is a convolution of ${P\mathstrut}_{\!X}$ with the Gaussian PDF ${p\mathstrut}_{Y|X}^{(\rho)}$,
%\footnote{By the characteristic function argument, if
%%there is a unique Gaussian PDF ${p\mathstrut}_{X}$
%%such that
%${\widehat{p}\mathstrut}_{Y}^{\,(\rho)}$ is the marginal PDF of ${p\mathstrut}_{X}{p\mathstrut}_{Y|X}^{\,(\rho)}$
%for some PDF ${p\mathstrut}_{X}$,
%%(y) = \int_{\mathbb{R}}{p\mathstrut}_{X}(x){p\mathstrut}_{Y|X}^{\,(\rho)}(y\,|\,x)dx$,
%then ${p\mathstrut}_{X}$ is necessarily Gaussian.},
%%the Gaussian PDF ${\widehat{p}\mathstrut}_{X}$.},
the type ${P\mathstrut}_{\!X}$ must converge to the Gaussian
distribution
in CF\footnote{It follows because the expression for the characteristic function of the zero-mean Gaussian distribution also has a Gaussian form.} and CDF
in order to achieve the %corresponding
exponents of Theorems~\ref{thmErrorExp} and~\ref{thmCorDecExp}.
In both proofs the type ${P\mathstrut}_{\!X}$ represents the histograms of codewords,
i.e., the empirical distributions of their %uniformly
quantized versions.
%represents the empirical distributions of uniformly quantized versions of codewords,
%and therefore the histograms of codewords.


\bigskip

\begin{prop}[Parametric representations of $E_{c}$ and $E_{e}\,$]
\label{prpCorErrExp}

{\em For every %each %$\,+\infty \, > \,
$R \, \geq \, I(\,{\widehat{p}\mathstrut}_{X}, \,w)$ there exists a unique $\rho \in (-1, 0]$,
such that}
%\frac{1}{2}\,{\log\mathstrut}_{\!b} (1 + \text{\rm SNR})$:}
%$\;\;\;
%R \, = \, I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big),
%\;\;\;
%E_{c}(R) \, = \, D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big),
%\;\;\;
%-1 < \rho \leq 0,$
\begin{align}
R \, & = \, I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big),
\;\;\;\;\;\;
%\nonumber \\
E_{c}(R) \, = \, D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big).
%\;\;\;\;\;\; %\text{for} \;\;
%-1 < \rho \leq 0. %\in (-1, 0].
\label{eqParC}
\end{align}

{\em For every %each
$R \, \leq \, I(\,{\widehat{p}\mathstrut}_{X}, \,w)$
there exists a unique $\rho \geq 0$, such that}
\begin{align}
R \, & = \, I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big),
\;\;\;\;\;\;
E_{e}(R) \, = \, D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big).
\label{eqParE}
\end{align}
%%\frac{1}{2}\,{\log\mathstrut}_{\!b} (1 + \text{\rm SNR})$:}
%$\;\;\;
%R \, = \, I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big),
%\;\;\;
%E_{e}(R) \, = \, D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big),
%\;\;\;\;\;\;\;\;\;\;\;\,\,
%\rho \geq 0.$
\end{prop}

%\bigskip

\begin{proof}
Let us denote $R_{\beta} \triangleq I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\beta)}\big)$. Then
for $\beta \in (-1, 0]$ %with (\ref{eqFiniteEntropy})
we can write a sandwich proof:
\begin{align}
&
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X} \, \in \; {\cal N}
%(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x
}}
\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\big|\,
R_{\beta}  -  I\big(\,{\widehat{p}\mathstrut}_{X}, \, {p\mathstrut}_{Y|X}\big)
\,\big|^{+}
\Big\}
\label{eqUseInf} \\
\overset{a}{\geq} \;
\sup_{\!\!\!\!\! -1 \, < \, \rho\,\leq\,0}
&
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X} \, \in \; {\cal N}
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x
}}
\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, - \,
\rho \big[
R_{\beta}
 -
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\rho)} \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\big]
\Big\}
\nonumber \\
\overset{b}{\equiv} \;
\sup_{\!\!\!\!\! -1 \, < \, \rho\,\leq\,0}
&
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X} \, \in \; {\cal N}
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x
}}
\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, - \,
\rho
\big[
R_{\beta}
 -
R_{\rho}
\big]
\, + \,
(1 + \rho)
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {p\mathstrut}_{Y|X}^{(\rho)} \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\Big\}
\nonumber \\
\overset{c}{=} \;
\sup_{\!\!\!\!\! -1 \, < \, \rho\,\leq\,0}
&
\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,\,
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, - \,
\rho
\big[
R_{\beta}
 -
R_{\rho}
\big]
\Big\}
\; \equiv \; E_{c}(R_{\beta})
\; \overset{d}{\geq} \;
D\big(\,{p\mathstrut}_{Y|X}^{(\beta)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big),
\label{eqSandwich}
%\nonumber \\
%\overset{d}{\geq} \;\;
%\;\;\;\;\;\;\;\;\,\,\,\,
%&
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;%\,\,
%\;\;\;\,
%D\big(\,{p\mathstrut}_{Y|X}^{(\beta)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
%\nonumber \\
%\geq \;
%\;\;\;\;\;\;\;\;\,\,\,\,
%&
%\inf_{\substack{{p\mathstrut}_{Y|X}:\\
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x
%}}
%\!\!
%\Big\{
%D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
%\, + \,
%\big|\,
%R_{\beta}  -  I\big(\,{\widehat{p}\mathstrut}_{X}, \, {p\mathstrut}_{Y|X}\big)
%\,\big|^{+}
%\Big\}.
%\nonumber
\end{align}
where ${\cal N}$ denotes the set of all bivariate non-degenerate Gaussian PDF's.
Here ($a$) follows similarly to the inequality ($b$) in Theorem~\ref{thmCorDecExp};
($b$) is an identity;
%follows by the properties of the divergence;
%definitions (\ref{eqSolution}) and (\ref{eqIdealYPDF});
($c$) follows because ${\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X}^{(\rho)}$ %satisfy
%conform to(\ref{eqFiniteEntropy})
is %a
Gaussian %PDF
and ${p\mathstrut}_{Y|X}^{(\rho)}$ achieves the infimum;
($d$) is a lower bound on the supremum %with the choice
at $\rho = \beta$.
Finally, since %all the %inequalities
%inequalities %are in fact
%turn out to be
%equalities,
the RHS of (\ref{eqSandwich}) is further lower-bounded by the infimum (\ref{eqUseInf}),
we conclude that $E_{c}(R_{\beta}) = D\big(\,{p\mathstrut}_{Y|X}^{(\beta)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)$.
%\end{proof}
%\begin{prop}[Parametric representation of $E_{e}\,$] \label{prpErrExp}
%{\em For %$\,+\infty \, > \,
%$R \, \leq \, \frac{1}{2}\,{\log\mathstrut}_{\!b} (1 + \text{\rm SNR})$}
%\begin{align}
%R \, & = \, I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big),
%\;\;\;\;\;\;
%%\nonumber \\
%E_{e}(R) \, = \, D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big),
%\;\;\;\;\;\; %\text{for} \;\;
%\rho \geq 0. %\in (-1, 0].
%\nonumber
%\end{align}
%\end{prop}
%\bigskip
%\begin{proof}
%Similarly

For $\beta \geq 0$, besides $R_{\beta}$
let us define
$R_{\beta}^{(\rho)} \triangleq D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\beta)} \,|\, \,{\widehat{p}\mathstrut}_{X}\big)$.
Then %for $\beta \geq 0$
%with (\ref{eqFiniteEntropy}) we can write
\begin{align}
&
%\;\,
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x,
{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X} \, \in \; {\cal N}, \\
D(\,{p\mathstrut}_{Y|X}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\beta)} \,|\, \,{\widehat{p}\mathstrut}_{X})
\; \leq \; R_{\beta}%^{(\beta)}
}}
\!\!\!\!\!\!\!\!\,\,\,
%\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
%\Big\}
\label{eqUseInf2} \\
\overset{a}{\geq} \;
&
\sup_{\rho \, \geq \, 0}
\,\,\,
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X} \, \in \; {\cal N}
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x
}}
\,\,\,\,
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho \big[
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\beta)} \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
 -
R_{\beta}%^{(\beta)}
\big]
\Big\}
\nonumber \\
\overset{b}{\equiv} \;
&
\sup_{\rho\,\geq\,0}
\,\,\,
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X} \, \in \; {\cal N}
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x
}}
\,\,\,\,
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho
\big[
R_{\beta}^{(\rho)}
 -
R_{\beta}%^{(\beta)}
\big]
\, + \,
(1 + \rho)
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, {p\mathstrut}_{Y|X}^{(\rho)} \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\Big\}
\nonumber \\
\overset{c}{=} \;
&
\sup_{\rho\,\geq\,0}
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho
\big[
R_{\beta}^{(\rho)}
 -
R_{\beta}%^{(\beta)}
\big]
\Big\}
%\;\; \equiv \;\; E_{c}(R_{\beta})
\nonumber \\
\overset{d}{\geq} \;
&
\sup_{\rho\,\geq\,0}
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
\Big\{
D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
\, + \,
\rho
\big[
R_{\rho}%^{(\rho)}
 -
R_{\beta}%^{(\beta)}
\big]
\Big\}
\; \equiv \; E_{e}(R_{\beta})%^{(\beta)}\big)
\; \overset{e}{\geq} \;
D\big(\,{p\mathstrut}_{Y|X}^{(\beta)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big).
\label{eqSandwich2}
%\overset{e}{\geq} \;\;
%&
%\;\;\;\;\;\;\;\;
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,
%D\big(\,{p\mathstrut}_{Y|X}^{(\beta)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)
%\nonumber \\
%\geq \;
%&
%\;\,
%\inf_{\substack{{p\mathstrut}_{Y|X}:\\
%{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}, \; \forall x, \\
%D(\,{p\mathstrut}_{Y|X}\,\|\, \, {\widehat{p}\mathstrut}_{Y}^{\,(\beta)} \,|\, \,{\widehat{p}\mathstrut}_{X})
%\; \leq \; R_{\beta}%^{(\beta)}
%}}
%\!\!\!\!\!\!\!\!\,\,\,
%%\Big\{
%D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big).
%%\Big\}.
%\nonumber
\end{align}
Here ($a$) follows due to the inequality under the first infimum;
($b$) is an identity;
($c$) follows because %${p\mathstrut}_{Y|X}^{(\rho)}(\, \cdot \,\,|\, x)$ conform to (\ref{eqFiniteEntropy}) and achieve the infimum;
${\widehat{p}\mathstrut}_{X}{p\mathstrut}_{Y|X}^{(\rho)}$
is %a
Gaussian %PDF
and ${p\mathstrut}_{Y|X}^{(\rho)}$ achieves the infimum;
($d$) follows because $R_{\beta}^{(\rho)} \geq R_{\rho}^{(\rho)} \equiv R_{\rho}$;
($e$) is a lower bound on the supremum at $\rho = \beta$.
%Finally, %by sandwich we obtain
Since the RHS of (\ref{eqSandwich2}) is %further
%in turn
lower-bounded by the infimum (\ref{eqUseInf2}),
we obtain
$E_{e}(R_{\beta}) = D\big(\,{p\mathstrut}_{Y|X}^{(\beta)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)$.
From $I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(\rho)}\big) =
\frac{1}{2}\,{\log\mathstrut}_{\!b}\big(\sigma_{Y}^{2}(\rho)/\sigma_{Y|X}^{2}(\rho)\big)$
using (\ref{eqSigmaY}) and (\ref{eqSigmaYX}) we obtain
$\frac{d R_{\rho}}{d\rho} =  \frac{dR_{\rho}}{d k_{\rho}}\cdot\frac{d k_{\rho}}{d\rho}< 0$.
%Therefore
Hence for every %each
$R > 0$ the parameter $\rho(R) \in (-1, +\infty)$ is unique.
%By the continuity of the definitions (\ref{eqSolution})-(\ref{eqIdealXPDF}), we conclude that for each
%$R \geq R_{0}$, %I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(0)}\big)$,
%resp. $0 < R \leq R_{0}$, %I\big(\,{\widehat{p}\mathstrut}_{X}, \,{p\mathstrut}_{Y|X}^{(0)}\big)$,
%there exists a unique $\rho \in (-1, 0]$, resp. $\rho \in [0, +\infty)$,
%such that $R = R_{\rho}$ and $E_{c}(R)$, resp. $E_{e}(R)$,
%equals $D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)$.
%%$E_{c}(R) = D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)$,
%%resp. $E_{e}(R) = D\big(\,{p\mathstrut}_{Y|X}^{(\rho)}\,\|\, \, w \, \,|\, \,{\widehat{p}\mathstrut}_{X}\big)$.
\end{proof}


\bigskip

The parametric representation (\ref{eqParC}) is equivalent to \cite[Eq.~22]{Oohama17}.



\section{Method of types}\label{MOT}

%\bigskip

In this section we extend the method of types \cite{CoverThomas} to include the countable alphabets of reals
(\ref{eqAlphabets})
by using %the
power constraints on the types. The results of this section are then used
%in the proofs of the lemmas
in the rest of the paper.

%\bigskip

\subsection*{\underline{Alphabet size}}


%{\em Alphabet size}

%\bigskip

Consider all the types ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$
satisfying the power constraint $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$.
Let ${\cal X}_{n}(c_{X}) \subseteq {\cal X}_{n}$ denote the subset of the %infinite
alphabet
%${\cal X}_{n}$ defined in (\ref{eqAlphabets}), (\ref{eqDelta})
used by these types. Every letter $x = i\Delta_{\alpha,\,n} \in {\cal X}_{n}(c_{X})$ must satisfy $|\, i\Delta_{\alpha,\,n}\,| \,\leq\, \sqrt{n c_{X}}$.
Then ${\cal X}_{n}(c_{X})$ is finite and we obtain

%\bigskip

\begin{lemma}[Alphabet size] \label{LemAlphabetSize}
{\em $\;\;|\, {\cal X}_{n}(c_{X}) \,| \;\; \leq \;\; 2\sqrt{c_{X}} n^{1/2 \, + \, \alpha} + 1 \;\; \leq \;\; (2\sqrt{c_{X}} + 1) n^{1/2 \, + \, \alpha}$.}
%\begin{equation} \label{eqAlphabetSize}
%|\, {\cal X}_{n}(c_{X}) \,| \; \leq \; 2\sqrt{c_{X}} n^{1/2 \, + \, \alpha} + 1
%\end{equation}
\end{lemma}


%\bigskip

%\bigskip
\subsection*{\underline{Size of a type class}}
%{\em Size of a type class}

%\bigskip

For %${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ and
${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ let us define
\begin{align}
{\cal S}({P\mathstrut}_{\!XY}) \;\; & \triangleq \;\;
\big\{
(x, y) \in {\cal X}_{n}\times {\cal Y}_{n} : \;\; {P\mathstrut}_{\!XY}(x, y) > 0
\big\},
\nonumber \\
{\cal S}({P\mathstrut}_{\!X}) \;\; & \triangleq \;\;
\big\{
x \in {\cal X}_{n}: \;\; {P\mathstrut}_{\!X}(x) > 0
\big\},
%\nonumber \\
\;\;\;\;\;\;
{\cal S}({P\mathstrut}_{\!Y}) \;\; \triangleq \;\;
\big\{
y \in {\cal Y}_{n}: \;\; {P\mathstrut}_{\!Y}(y) > 0
\big\}.
\nonumber
\end{align}

%\bigskip

\begin{lemma}[Support of a joint type] \label{LemSupportXY}
{\em %Let ${\cal X}_{n}$ and ${\cal Y}_{n}$ be defined as in (\ref{eqAlphabets}), (\ref{eqDelta}).
Let ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ be a joint type,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$
and $\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$.
Then}
\begin{align}
|\, {\cal S}({P\mathstrut}_{\!XY}) \,| \;\; & \leq \;\; \sqrt{2\pi (c_{X} + c_{Y} + 1/6)}\cdot n^{(1 \, + \, \alpha \, + \, \beta)/2}.
\nonumber
\end{align}
\end{lemma}
The proof is given in the Appendix A.

%\bigskip

\begin{lemma}[Support of a type] \label{LemSupportX}
{\em %Let ${\cal X}_{n}$ and ${\cal Y}_{n}$ be defined as in (\ref{eqAlphabets}), (\ref{eqDelta}).
Let ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$
and
${P\mathstrut}_{\!Y} \in {\cal P}_{n}({\cal Y}_{n})$
be types,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$
and $\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$.
Then}
\begin{align}
|\, {\cal S}({P\mathstrut}_{\!X}) \,| \;\; & \leq \;\; (12c_{X} + 1)^{1/3}\cdot n^{(1 \, + \, 2\alpha)/3},
\nonumber \\
|\, {\cal S}({P\mathstrut}_{\!Y}) \,| \;\; & \leq \;\; (12c_{Y} + 1)^{1/3}\cdot n^{(1 \, + \, 2\beta)/3}.
\nonumber
\end{align}
\end{lemma}
The proof for ${P\mathstrut}_{\!X}$ is given in the Appendix A.
For ${P\mathstrut}_{\!Y}$, the parameters $c_{Y}$, $\beta$ replace, respectively, $c_{X}$, $\alpha$.


\bigskip


\begin{lemma}[Size of a type class] \label{LemTypeSize}
{\em Let ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ be a joint type,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$
and $\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$.
Then}
\begin{align}
H({P\mathstrut}_{\!XY})
\; - \;
c_{1}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{\gamma/2}}
\;\; & \leq \;\;
\frac{1}{n}\,{\log\mathstrut}_{\!b}\,|\, T({P\mathstrut}_{\!XY}) \,|
\;\; \leq \;\;
H({P\mathstrut}_{\!XY}),
\label{eqJointExp} \\
H({P\mathstrut}_{\!X})
\; - \;
c_{2}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{2(1\,-\,\alpha)/3}}
\;\; & \leq \;\;
\frac{1}{n}\,{\log\mathstrut}_{\!b}\,|\, T({P\mathstrut}_{\!X}) \,|
\;\;
\;\;
\leq \;\;
H({P\mathstrut}_{\!X}),
\label{eqMargExpX} \\
H({P\mathstrut}_{\!Y})
\; - \;
c_{3}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{2(1\,-\,\beta)/3}}
\;\; & \leq \;\;
\frac{1}{n}\,{\log\mathstrut}_{\!b}\,|\, T({P\mathstrut}_{\!Y}) \,|
\;\;
\;\,\,
\leq \;\;
H({P\mathstrut}_{\!Y}),
\label{eqMargExpY}
\end{align}
{\em where $c_{1} \triangleq \sqrt{2\pi (c_{X} + c_{Y} + 1/6)}$,
$\;c_{2} \triangleq (12c_{X} + 1)^{1/3}$, and
$c_{3} \triangleq (12c_{Y} + 1)^{1/3}$}.
\end{lemma}


\bigskip

\begin{proof}
Observe that the standard type-size bounds (see, e.g.,\cite[Eq.~11.16]{CoverThomas}) can be rewritten as
\begin{equation} \label{eqMOTSup}
\frac{1}{(n + 1)^{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|}}\,b^{\,n H({P\mathstrut}_{\!XY})}
\;\; \leq \;\;
|\, T({P\mathstrut}_{\!XY}) \,|
\;\; \leq \;\;
b^{\,n H({P\mathstrut}_{\!XY})}.
\end{equation}
%Further,
Here
$|\, {\cal S}({P\mathstrut}_{\!XY}) \,|$ %in (\ref{eqMOTSup})
can be replaced
with its upper bound of Lemma~\ref{LemSupportXY}.
This gives (\ref{eqJointExp}).
The remaining bounds of (\ref{eqMargExpX}) and (\ref{eqMargExpY})
are obtained similarly using Lemma~\ref{LemSupportX}.
\end{proof}



\bigskip


Since it holds for any ${\bf y} \in T({P\mathstrut}_{\!Y})$ that
$|\, T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})\,| \, = \, |\, T({P\mathstrut}_{\!XY}) \,| \, / \, |\, T({P\mathstrut}_{\!Y}) \,|$,
and similarly for ${\bf x} \in T({P\mathstrut}_{\!X})$,
%for any ${\bf x} \in T({P\mathstrut}_{\!X})$ that
%$|\, T({P\mathstrut}_{\!Y|X}\,|\, {\bf x})\,| \, = \, |\, T({P\mathstrut}_{\!XY}) \,| \, / \, |\, T({P\mathstrut}_{\!X}) \,|$,
as a corollary of the previous lemma we also obtain

\bigskip

\begin{lemma}[Size of a conditional type class] \label{LemCondTypeSize}
{\em Let ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ be a joint type,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$
and $\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$.
%Let ${\bf y} \in T({P\mathstrut}_{\!Y})$.
Then for ${\bf y} \in T({P\mathstrut}_{\!Y})$ and ${\bf x} \in T({P\mathstrut}_{\!X})$ respectively}
\begin{align}
H(X\,|\,Y)
\; - \;
c_{1}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{\gamma/2}}
\;\; & \leq \;\;
\frac{1}{n}\,{\log\mathstrut}_{\!b}\,|\, T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}) \,|
\;\; \leq \;\;
H(X\,|\,Y)
\; + \;
c_{3}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{2(1\,-\,\beta)/3}},
\label{eqXgivenY} \\
%\end{align}
%{\em and for ${\bf x} \in T({P\mathstrut}_{\!X})$}
%\begin{align}
H(Y\,|\,X)
\; - \;
c_{1}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{\gamma/2}}
\;\; & \leq \;\;
\frac{1}{n}\,{\log\mathstrut}_{\!b}\,|\, T({P\mathstrut}_{\!Y|X}\,|\, {\bf x}) \,|
\,
\;\; \leq \;\;
H(Y\,|\,X)
\; + \;
c_{2}\,
\frac{{\log\mathstrut}_{\!b}\,(n + 1)}{n^{2(1\,-\,\alpha)/3}},
\label{eqYgivenX}
\end{align}
{\em where $c_{1}$, $c_{2}$, and $c_{3}$ are defined as in Lemma~\ref{LemTypeSize}.}
\end{lemma}

%\bigskip

%\bigskip

\subsection*{\underline{Number of types}}
%{\em Number of types}

%\bigskip

Let ${\cal P}_{n}\big({\cal X}_{n}, \,c_{X}\big)$
be the set of all the types ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$
satisfying the power constraint $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$.
Then its cardinality can be upper-bounded as follows:
\begin{equation} \label{eqNumberofTypes}
\big|\,  {\cal P}_{n}\big({\cal X}_{n}, \,c_{X}\big) \,\big|
\;\; \overset{(a)}{\leq} \;\;
\big|\,  {\cal P}_{n}\big({\cal X}_{n}(c_{X})\big) \,\big|
\;\; \overset{(b)}{\leq} \;\;
(n + 1)^{|\, {\cal X}_{n}(c_{X})\,|}
\;\; \overset{(c)}{\leq} \;\;
(n + 1)^{(2\sqrt{c_{X}} \, + \, 1) n^{1/2 \, + \, \alpha}},
\end{equation}
where ($a$) follows by the definition of ${\cal X}_{n}(c_{X})$
preceding Lemma~\ref{LemAlphabetSize}, ($b$) follows by \cite[Eq.~11.6]{CoverThomas},
and ($c$) follows by Lemma~\ref{LemAlphabetSize}.
This bound is sub-exponential in $n$ for $\alpha < 1/2$.
This can be also further improved and made sub-exponential in $n$ for all $\alpha \in (0, 1)$
using Lemma~\ref{LemSupportX}, as follows.

\bigskip

\begin{lemma}[Number of types] \label{LemNumofTypes}
\begin{equation} \label{eqImprovement}
\big|\,  {\cal P}_{n}\big({\cal X}_{n}, \,c_{X}\big) \,\big| \;\; \leq \;\;
\big((n + 1)c\big)^{\tilde{c}\, n^{(1\,+\, 2\alpha)/3}},
\end{equation}
{\em where $c \,\triangleq\, (2\sqrt{c_{X}} + 1)^{1/(3/2 \, + \, \alpha)}$
and $\tilde{c} \,\triangleq\, (3/2 + \alpha)(12 c_{X} + 1)^{1/3}$.}
\end{lemma}

\bigskip

\begin{proof}
Denoting $k \, \triangleq \, |\, {\cal X}_{n}(c_{X})\,|$ and
$\ell \, \triangleq \, \max_{\,{P\mathstrut}_{\!X} \, \in \;{\cal P}_{n}({\cal X}_{n}, \; c_{X})} \,|\, {\cal S}({P\mathstrut}_{\!X}) \,|$,
we can upper-bound as follows
\begin{equation} \label{eqKchooseL}
\big|\,  {\cal P}_{n}\big({\cal X}_{n}, \,c_{X}\big) \,\big| \;\; \leq \;\;
\tbinom{k}{\ell} (n + 1)^{\ell} \;\; \leq \;\;
k^{\ell}(n + 1)^{\ell}.
\end{equation}
Substituting %in place of
for
$k$ and $\ell$ their upper bounds of Lemma~\ref{LemAlphabetSize} (with $n + 1$) and Lemma~\ref{LemSupportX},
we obtain (\ref{eqImprovement}).
\end{proof}


\bigskip

Similarly, let ${\cal P}_{n}\big({\cal X}_{n}\times {\cal Y}_{n}, \,c_{X}, \,c_{Y}\big)$
denote the set of all the joint types ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$
and $\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$. Then its cardinality can be bounded as follows.

\bigskip

\begin{lemma}[Number of joint types] \label{LemNumofJTypes}
\begin{equation} \label{eqNJRypes}
\big|\,  {\cal P}_{n}\big({\cal X}_{n}\times {\cal Y}_{n}, \,c_{X}, \,c_{Y}\big) \,\big| \;\; \leq \;\;
\big((n + 1)c\big)^{\tilde{c}\, n^{(1\,+\, \alpha \, + \, \beta)/2}},
\end{equation}
{\em where $\,c \,\triangleq\, \big[(2\sqrt{c_{X}} + 1)(2\sqrt{c_{Y}} + 1)\big]^{1/(2 \, + \, \alpha \, + \, \beta)}$
and $\,\tilde{c} \,\triangleq\, (2 + \alpha + \beta)\sqrt{2\pi (c_{X} + c_{Y} + 1/6)}$.}
\end{lemma}

\bigskip

\begin{proof}
Denoting $k \, \triangleq \, |\, {\cal X}_{n}(c_{X})\,|\cdot |\, {\cal Y}_{n}(c_{Y})\,|$ and
$\ell \, \triangleq \,
\max_{\,{P\mathstrut}_{\!XY} \, \in \;{\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}, \; c_{X}, \; c_{Y})}
\,|\, {\cal S}({P\mathstrut}_{\!XY}) \,|$,
we repeat the steps of (\ref{eqKchooseL}) and use the bounds of Lemma~\ref{LemAlphabetSize} and Lemma~\ref{LemSupportXY} to
obtain (\ref{eqNJRypes}).
\end{proof}










%\bigskip


\section{Converse lemma}\label{ConvLemma}

%\bigskip

In this section %after Lemma~\ref{LemPDFExponent}
we prove a converse Lemma~\ref{LemConvLem}, which is then used both for the error exponent in Section~\ref{ErrExp}
and for the correct-decoding exponent in Section~\ref{CorDecExp}.

In order to determine exponents in channel probabilities, %we will require
it is convenient to %have
take hold of
the exponent in the channel probability {\em density}.
Let ${\bf x} = (x_{1}, x_{2}, .\,.\,. \,, x_{n})\in \mathbb{R}{\mathstrut}^{n}$
be a vector of $n$ channel inputs
and let ${\bf x}^{q} = (x_{1}^{q}, x_{2}^{q}, .\,.\,. \,, x_{n}^{q}) \in {\cal X}_{n}^{n}$
be its quantized version, with components
\begin{equation} \label{eqQuantizer}
x_{k}^{q} \; = \; Q_{\alpha}(x_{k}) \; \triangleq \; \Delta_{\alpha,\,n}\cdot \lfloor x_{k}/\Delta_{\alpha,\,n} + 1/2\rfloor,
\;\;\;\;\;\; k = 1, .\,.\,.\,, n.
\end{equation}
%for all $k = 1, .\,.\,.\,, n$.
Similarly,
let ${\bf y} = (y_{1}, y_{2}, .\,.\,. \,, y_{n}) \in \mathbb{R}{\mathstrut}^{n}$
be a vector of $n$ channel outputs
and let ${\bf y}^{q} = (y_{1}^{q}, y_{2}^{q}, .\,.\,. \,, y_{n}^{q}) \in {\cal Y}_{n}^{n}$
be its quantized version, with $y_{k}^{q} = Q_{\beta}(y_{k})$ for all $k = 1, .\,.\,.\,, n$.
Then we have the following

\bigskip

\begin{lemma}[PDF exponent] \label{LemPDFExponent}
{\em Let ${\bf x}\in \mathbb{R}{\mathstrut}^{n}$ and ${\bf y}\in \mathbb{R}{\mathstrut}^{n}$
be two channel input and output vectors,
with their respective quantized versions $({\bf x}^{q}, {\bf y}^{q}) \in T({P\mathstrut}_{\!XY})$,
%belong to a joint type ${P\mathstrut}_{\!XY}$ with the property that
such that $\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$. Then
}
\begin{align}
&
-\frac{1}{n}\,{\log\mathstrut}_{\!b}\, w({\bf y}^{q} \, | \, {\bf x}^{q})
\, + \, \frac{
(\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})\sqrt{c_{XY}} +
(\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})^{2}/4
}{2\sigma^{2}\ln b}
%\, + \,
\;\; \geq \;\;
-\frac{1}{n}\,{\log\mathstrut}_{\!b}\, w({\bf y} \, | \, {\bf x})
\nonumber \\
\geq \;\;
&
-\frac{1}{n}\,{\log\mathstrut}_{\!b}\, w({\bf y}^{q} \, | \, {\bf x}^{q})
\, - \, \frac{(\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})\sqrt{c_{XY}}}{2\sigma^{2}\ln b}.
\nonumber
\end{align}
\end{lemma}

%\bigskip

\begin{proof}
The exponent can be equivalently rewritten as
\begin{equation} \label{eqRealW}
-\frac{1}{n}\,{\log\mathstrut}_{\!b}\, w({\bf y} \, | \, {\bf x})
\;\; \equiv \;\;
{\log\mathstrut}_{\!b}\,(\sigma\sqrt{2\pi}) \; + \;
\frac{1}{2\sigma^{2}\ln b}\cdot
\frac{1}{n}\sum_{k \, = \, 1}^{n}(y_{k} - x_{k})^{2}.
\end{equation}
Defining $\delta_{k} \, \triangleq \, (y_{k} - x_{k}) - (y_{k}^{q} - x_{k}^{q})$,
we observe that
\begin{equation} \label{eqRealAverage}
\frac{1}{n}\sum_{k \, = \, 1}^{n}(y_{k} - x_{k})^{2} \;\; = \;\;
\frac{1}{n}\sum_{k \, = \, 1}^{n}(y_{k}^{q} - x_{k}^{q})^{2}
\, + \,
\frac{2}{n}\sum_{k \, = \, 1}^{n}(y_{k}^{q} - x_{k}^{q})\delta_{k}
\, + \,
\frac{1}{n}\sum_{k \, = \, 1}^{n}\delta_{k}^{2}.
\end{equation}
The second term on the RHS is bounded as:
\begin{align}
\bigg|\,
\frac{2}{n}\sum_{k \, = \, 1}^{n}(y_{k}^{q} - x_{k}^{q})\delta_{k}
\,\bigg|
\;\; & \leq \;\;
\frac{2}{n}\sum_{k \, = \, 1}^{n}|\,y_{k}^{q} - x_{k}^{q}\,|\cdot|\,\delta_{k}\,|
\;\; \overset{a}{\leq} \;\;
(\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})\cdot \frac{1}{n}\sum_{k \, = \, 1}^{n}|\,y_{k}^{q} - x_{k}^{q}\,|
\nonumber \\
& \overset{b}{\leq} \;\;
(\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})\bigg[
\frac{1}{n}\sum_{k \, = \, 1}^{n}(y_{k}^{q} - x_{k}^{q})^{2}
\bigg]^{1/2}
\; \overset{c}{\leq} \;\; (\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})\sqrt{c_{XY}},
\label{eqRealBounded}
\end{align}
where ($a$) follows because $|\, \delta_{k} \,| \,\leq\, (\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})/2$,
($b$) follows by Jensen's inequality for the concave ($\cap$) function $f(t) = \sqrt{t}$,
and ($c$) follows by the condition of the lemma.
The third term is bounded as
\begin{equation} \label{eqRealBounded2}
\frac{1}{n}\sum_{k \, = \, 1}^{n}\delta_{k}^{2} \;\; \leq \;\; (\Delta_{\alpha,\,n} + \Delta_{\beta,\,n})^{2}/4.
\end{equation}
Since the %``ideal''
exponent with the quantized versions
$-\frac{1}{n}\,{\log\mathstrut}_{\!b}\, w({\bf y}^{q} \, | \, {\bf x}^{q})$, in turn,
can also be rewritten similarly to (\ref{eqRealW}), the result of the lemma follows by
(\ref{eqRealW})-(\ref{eqRealBounded2}).
%(\ref{eqRealAverage})
%(\ref{eqRealBounded})
%(\ref{eqRealBounded2})
\end{proof}




\bigskip


The following lemma will be used both for the upper bound on the error exponent and for the lower bound on the correct-decoding exponent.

\bigskip


\begin{lemma}[Conditional probability of correct decoding] %[Converse lemma]
\label{LemConvLem}
{\em Let ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ be a joint type,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$, $\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$,
and $\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$, and
let ${\cal C}$ be a codebook, %of size $M(n, R)$,
such that the quantized versions (\ref{eqQuantizer}) of %all %the
its codewords ${\bf x}(m)$, $m = 1, 2, .\,.\,.\, , \, M(n, R)$,
are all of the %same
type ${P\mathstrut}_{\!X}$, that is:
%such that for each codeword ${\bf x}(m)$
%its quantized version
\begin{displaymath} %\label{eqConstantComposition}
{\bf x}^{q}(m) \; = \; Q_{\alpha}({\bf x}(m))
\; = \;
\big(Q_{\alpha}(x_{1}(m)), Q_{\alpha}(x_{2}(m)), .\,.\,.\, , \,Q_{\alpha}(x_{n}(m))\big)
\; \in \;
T({P\mathstrut}_{\!X}), \;\;\; \forall m.
\end{displaymath}
%Let $J$ be a random variable distributed uniform over $\{1, 2, .\,.\,.\, , \, M\}$,
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
Let ${\bf Y}^{q} = Q_{\beta}({\bf Y})\in {\cal Y}_{n}^{n}$. Then}
\begin{displaymath}
\Pr \Big\{
g({\bf Y}) = J \; \big| \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\;\; \leq \;\;
b^{\,-n\big(\widetilde{R} \, - \, I({P\mathstrut}_{\!XY})  %I(X;\,Y)
\, + \, o(1)\big)},
\end{displaymath}
{\em where $\widetilde{R} = \frac{1}{n}\,{\log\mathstrut}_{\!b}\,M(n, R)$,
and $o(1)\rightarrow 0$, as $n\rightarrow \infty$, %and depends
depending only on %the parameters
$\alpha$, $\beta$, $c_{X}$, $c_{Y}$, $c_{XY}$, and $\sigma^{2}$.}
\end{lemma}

\bigskip

\begin{proof}
%For convenience,
First,
from the single code $({\cal C}, g)$ we create an ensemble of codes, where each member code has the same probability
of error/correct-decoding as the original code $({\cal C}, g)$.
Then we %will
upper bound the ensemble average probability of correct decoding.

Considering the codebook ${\cal C}$ as an $M\times n$ matrix, we permute its $n$ columns.
This produces a set of %$n!$
codebooks: ${\cal C}_{\ell}$, $\ell = 1, .\,.\,.\, , \, n!$.
The quantized versions of all the codewords of each codebook ${\cal C}_{\ell}$ %retain the property (\ref{eqConstantComposition}).
%remain in the
belong to the same type class $T({P\mathstrut}_{\!X})$.
In accordance with ${\cal C}_{\ell}$, we permute also
%the $n$ coordinates of the decision regions $A{\mathstrut}_{m}$ in the definition (\ref{eqDec})
%of the decoder $g$,
%or, more specifically, we permute
the $n$ coordinates of each ${\bf y} \in {\cal D}{\mathstrut}_{m}$
of the decision regions ${\cal D}{\mathstrut}_{m}$ in the definition (\ref{eqDec})
of the decoder $g$, % . This results in
obtaining
%the
open sets ${\cal D}{\mathstrut}_{m}^{(\ell)}$ and
creating in this way an ensemble of codes $({\cal C}_{\ell}, g_{\ell})$, $\ell = 1, .\,.\,.\, , \, n!$.

Let ${\bf x}_{\ell}(J) \rightarrow {\bf Y}_{\!\ell}$ denote the random channel-input and channel-output vectors, respectively,
when using the code with an index $\ell \in \{1, .\,.\,.\, , \, n!\}$.
Let ${\bf x}_{\ell}^{q}(J)$ and ${\bf Y}_{\!\ell}^{q}$ denote their respective quantized versions.
Since the additive channel noise is i.i.d., permutation of %the
components does not change the distribution of the noise vector ${\bf Y}_{\!\ell} - {\bf x}_{\ell}(J)$,
and
we obtain %for the original code
\begin{align}
\Pr \Big\{
g({\bf Y}) = J, \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\; & = \;
\Pr \Big\{
g_{\ell}({\bf Y}_{\!\ell}) = J, \;
\big({\bf x}_{\ell}^{q}(J), \,{\bf Y}_{\!\ell}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\},
\;\;\; \forall \ell,
\label{eqJointEvent} \\
\Pr \Big\{
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\; & = \;
\Pr \Big\{
\big({\bf x}_{\ell}^{q}(J), \,{\bf Y}_{\!\ell}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\},
\;\;\; \forall \ell.
\label{eqTypeEvent}
\end{align}
Suppose that one of the codes $({\cal C}_{\ell}, g_{\ell})$, $\ell = 1, .\,.\,.\, , \, n!$,
is %chosen to be
used for communication with probability $1/n!$,
chosen independently of the sent message $J$ and of the channel. Let $L \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, n!\}\big)$
be the random variable denoting the index of this code.
Then, using (\ref{eqJointEvent}) and (\ref{eqTypeEvent}) we obtain
\begin{align}
\Pr \Big\{
g({\bf Y}) = J \; \big| \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\; & = \;
\Pr \Big\{
g_{L}({\bf Y}_{\!L}) = J \; \big| \;
\big({\bf x}_{L}^{q}(J), \,{\bf Y}_{\!L}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}.
\label{eqEnsembleAverage}
\end{align}
In what follows, we upper bound the RHS of (\ref{eqEnsembleAverage}) with an added condition that ${\bf Y}_{\!L}^{q} = {\bf y} \in T({P\mathstrut}_{\!Y})$:
\begin{displaymath}
\Pr \Big\{\;
g_{L}({\bf Y}_{\!L}) = J \;\; \big| \;\;
{\bf x}_{L}^{q}(J) \in T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}), \; {\bf Y}_{\!L}^{q} = {\bf y}
\Big\}.
\end{displaymath}

The total number of codes in the ensemble can be rewritten as
\begin{equation} \label{eqTotalCodes}
n! \;\; = \;\; |\, T({P\mathstrut}_{\!X}) \,| \prod_{x \, \in \, {\cal S}({P\mathstrut}_{\!X})}\big(n{P\mathstrut}_{\!X}(x)\big)!
\;\; \triangleq \;\; |\, T({P\mathstrut}_{\!X}) \,|\cdot \Pi({P\mathstrut}_{\!X}).
\end{equation}
Given ${\bf y} \in T({P\mathstrut}_{\!Y})$, the total number of all the codewords
in the ensemble such that their quantized versions belong to the same conditional type class
$T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$
(counted as distinct if the codewords %themselves
belong to different ensemble member codes or represent different messages) is
given by
\begin{equation} \label{eqTotalCodewords}
S \; = \; \underbrace{|\, T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}) \,| \,
\cdot \, \Pi({P\mathstrut}_{\!X})}_{\text{for a message $m$}} \,\, \cdot \,\, M. %\, b^{\,n \widetilde{R}}.
\end{equation}
Let $N(\ell)$ denote the number of the codewords in a codebook ${\cal C}_{\ell}$
such that their quantized versions belong to $T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$.
Given that ${\bf Y}_{\!L}^{q} = {\bf y}$, the channel output vector ${\bf Y}_{\!L}$ falls
into a hypercube region of $\mathbb{R}{\mathstrut}^{n}$:
\begin{displaymath}
{\cal B} \;\; \triangleq \;\; \{\widetilde{\bf y} \in \mathbb{R}{\mathstrut}^{n}: \; Q_{\beta}(\widetilde{\bf y}) = {\bf y}\}.
\end{displaymath}
%The probability, that, given some input codeword with the quantized version in $T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$,
%the channel produces an output vector
%in $B$, is given according to Lemma~\ref{LemPDFExponent} by
For any ${\bf x} \in \mathbb{R}{\mathstrut}^{n}$ such that $Q_{\alpha}({\bf x}) \in T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$
and any open region ${\cal D}\subseteq \mathbb{R}{\mathstrut}^{n}$,
by Lemma~\ref{LemPDFExponent} we obtain
\begin{align}
%e^{n\big(\mathbb{E}_{{P\mathstrut}_{\!XY}}\![\,{\log\mathstrut}_{\!b}\, w(Y \, | \, X)\,] \; + \; o(1)\big)}\cdot\text{vol}(B)
%\; \leq \;
&
b^{\,n\big(\mathbb{E}_{{P\mathstrut}_{\!XY}}\![\,{\log\mathstrut}_{\!b}\, w(Y \, | \, X)\,] \; + \; o_{1}(1)\big)}\cdot\text{vol}({\cal B}\cap {\cal D})
\;\; \geq \;\;
%\; \leq \;
\Pr \big\{
{\bf Y}_{\!L} \in {\cal B}\cap {\cal D} \; | \;
{\bf x}_{L}(J) = {\bf x}
\big\}
\nonumber \\
\geq \;\; &
%\; \leq \;
b^{\,n\big(\mathbb{E}_{{P\mathstrut}_{\!XY}}\![\,{\log\mathstrut}_{\!b}\, w(Y \, | \, X)\,] \; + \; o_{2}(1)\big)}\cdot\text{vol}({\cal B}\cap {\cal D}).
\label{eqBoxProb}
\end{align}
%\begin{equation} \label{eqBoxProb}
%e^{n\big(\mathbb{E}_{{P\mathstrut}_{\!XY}}\![\,{\log\mathstrut}_{\!b}\, w(Y \, | \, X)\,] \; + \; o(1)\big)}\cdot\text{vol}(B).
%\end{equation}
Then, %by (\ref{eqBoxProb})
%given that ${\bf Y}_{\!L}^{q} = {\bf y}$ and ${\bf x}_{L}^{q}(J) \in T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$,
since all the %codewords having their quantized versions in $T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$
codes and messages
are equiprobable,
the conditional probability of the code with the index $\ell$ is %$\; N(\ell)e^{n \cdot o(1)}/S$.
upper-bounded as
\begin{equation} \label{eqCondCode}
\Pr \Big\{\;
L = \ell \;\; \big| \;\;
{\bf x}_{L}^{q}(J) \in T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}), \; {\bf Y}_{\!L}^{q} = {\bf y}
\Big\}
\;\; \leq \;\;
b^{\,n %\,\cdot \,
\big(o_{1}(1)\; - \; o_{2}(1)\big)}N(\ell)/S.
\end{equation}
For $N(\ell) > 0$, let $m_{1} < m_{2} <  .\,.\,. < m_{N(\ell)}$ be the indices of all the codewords in the codebook ${\cal C}_{\ell}$
with their quantized versions in $T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y})$.
Given that indeed the codebook %with the index $\ell$
${\cal C}_{\ell}$ has been used for communication,
similarly to (\ref{eqCondCode}),
by (\ref{eqBoxProb})
the conditional probability of correct decoding can be upper-bounded as
\begin{align}
\Pr \Big\{\,
g_{\ell}({\bf Y}_{\!\ell}) = J \; \big| \;
{\bf x}_{\ell}^{q}(J) \in T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}), \, {\bf Y}_{\!\ell}^{q} = {\bf y},
\, L = \ell
\Big\}
%\;\;
\,
& \leq
\,
%\;\;
\sum_{j \, = \, 1}^{N(\ell)}
\frac{\text{vol}\big({\cal B}\cap {\cal D}{\mathstrut}_{m_{j}}^{(\ell)}\big)b^{\,n \,\cdot \, o(1)}}
{N(\ell)\text{vol}({\cal B})}%\cdot
%\;\;
\,
\leq
\,
%\;\;
\frac{b^{\,n \,\cdot \, o(1)}}{N(\ell)},
\label{eqCondCorDec}
\end{align}
where the second inequality follows because the decision regions ${\cal D}{\mathstrut}_{m_{j}}^{(\ell)}$ are disjoint.
Summing up over all the codes, we finally obtain:
\begin{align}
&
\Pr \Big\{\;
g_{L}({\bf Y}_{\!L}) = J \;\; \big| \;\;
{\bf x}_{L}^{q}(J) \in T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}), \; {\bf Y}_{\!L}^{q} = {\bf y}
\Big\}
\;\;
\overset{a}{\leq} \;\;
\sum_{\substack{1 \, \leq \, \ell \, \leq \, n! \, : \;
%\ell \, \in \, \{1, \, . \, . \, . \,, \, n!\}:
N(\ell)\, > \, 0}}
\frac{N(\ell)}{S}
\cdot
\frac{1}{N(\ell)}\cdot b^{\,n \,\cdot \, o(1)}
\nonumber \\
= \;\; &
\sum_{\substack{1 \, \leq \, \ell \, \leq \, n! \, : \; N(\ell)\, > \, 0}}
\frac{1}{S}\cdot b^{\,n \,\cdot \, o(1)}
\;\; \leq \;\;
\frac{n!}{S}\cdot b^{\,n \,\cdot \, o(1)}
%\nonumber \\
\;\; \overset{b}{=} \;\;
\frac{|\, T({P\mathstrut}_{\!X}) \,|}{|\, T({P\mathstrut}_{\!X|\,Y}\,|\, {\bf y}) \,| \,  \, M}\cdot b^{\,n \,\cdot \, o(1)}
\;\; \overset{c}{\leq} \;\;
b^{\,-n\big(\widetilde{R} \, - \, I({P\mathstrut}_{\!XY})  %I(X;\,Y)
\, + \, o(1)\big)},
\nonumber
\end{align}
where ($a$) follows by (\ref{eqCondCode}) and (\ref{eqCondCorDec}),
($b$) follows by (\ref{eqTotalCodes}) and (\ref{eqTotalCodewords}),
and ($c$) follows by (\ref{eqMargExpX}) of Lemma~\ref{LemTypeSize} and (\ref{eqXgivenY}) of Lemma~\ref{LemCondTypeSize}.
\end{proof}

In the next two sections we derive converse bounds on the error and correct-decoding exponents in terms of types.


%\bigskip


\section{Error exponent}\label{ErrExp}

%\bigskip
The end result of this section is given by Lemma~\ref{LemAllCodebooks} and represents a converse bound on the error exponent by the method of types.

\begin{lemma}[Error exponent of %quasi constant
mono-composition codebooks]
%[Decoding error in codebooks with the constant-composition quantized versions]
\label{LemConstComp}
{\em %Let ${\cal X}_{n}$ and ${\cal Y}_{n}$ be two alphabets defined as in (\ref{eqAlphabets}), (\ref{eqDelta}).
Let ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ be a type,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$,
%$\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$,
%and $\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$,
and
let ${\cal C}$ be a codebook, %of size $M(n, R)$,
such that the quantized versions (\ref{eqQuantizer}) of %all %the
its codewords ${\bf x}(m)$, $m = 1, 2, .\,.\,.\, , \, M(n, R)$,
are all of the %same
type ${P\mathstrut}_{\!X}$, that is:
%such that for each codeword ${\bf x}(m)$
%its quantized version
\begin{displaymath} %\label{eqConstantComposition}
{\bf x}^{q}(m) \; = \; Q_{\alpha}({\bf x}(m))
\; = \;
\big(Q_{\alpha}(x_{1}(m)), Q_{\alpha}(x_{2}(m)), .\,.\,.\, , \,Q_{\alpha}(x_{n}(m))\big)
\; \in \;
T({P\mathstrut}_{\!X}), \;\;\; \forall m.
\end{displaymath}
%Let $J$ be a random variable distributed uniform over $\{1, 2, .\,.\,.\, , \, M\}$,
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
%Let ${\bf Y}^{q} = Q_{\beta}({\bf Y})\in {\cal Y}_{n}^{n}$.
Then for any parameter $c_{XY}$
}
\begin{equation} \label{eqCCBound}
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) \neq J \big\}
\;\; \leq \;\;
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; c_{XY},
\\ I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X}) \; \leq \; \widetilde{R} \, - \, o(1)
}}
\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\Big\} \; + \; o(1),
\end{equation}
{\em where
$\widetilde{R} = \frac{1}{n}\,{\log\mathstrut}_{\!b}\,M(n, R)$,
and
$o(1)\rightarrow 0$, as $n\rightarrow \infty$, %and depends
depending only on %the parameters %$R$,
$\alpha$, $\beta$, $c_{X}$, $c_{XY}$, and $\sigma^{2}$.}
\end{lemma}

\bigskip

\begin{proof}
For a joint type ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ with the marginal type ${P\mathstrut}_{\!X}$,
such that
$\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$, we have also
\begin{displaymath}
\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big]
\;\; %\overset{(*)}{\leq}
\leq
\;\;
\Big(
\mathbb{E}_{{P\mathstrut}_{\!X}}^{1/2}\big[X^{2}\big]\,+\,
\mathbb{E}_{{P\mathstrut}_{\!XY}}^{1/2}\!\big[(Y-X)^{2}\big]
\Big)^{2}
\;\; \leq \;\;
\big(
\sqrt{c_{X}} \, + \, \sqrt{c_{XY}}
\big)^{2}
\;\; \triangleq \;\;
c_{Y}.
\end{displaymath}
Then with $\,{\bf Y}^{q} = Q_{\beta}({\bf Y})\in {\cal Y}_{n}^{n}\,$ for any $1 \leq j \leq M$ we obtain
%for any $1 \leq m \leq M$:
\begin{align}
\Pr \Big\{
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY}) \; \big| \;
J = j
\Big\}
\;\; & \overset{a}{\geq} \;\;
\big|\, T\big({P\mathstrut}_{\!Y|X}\,|\, {\bf x}^{q}(j)\big) \,\big| \cdot \Delta_{\beta,\,n}^{n}\cdot
b^{\,n\big(\mathbb{E}_{{P\mathstrut}_{\!XY}}\![\,{\log\mathstrut}_{\!b}\, w(Y \, | \, X)\,] \; + \; o(1)\big)}
\nonumber \\
& \overset{b}{\geq} \;\;
b^{\,-n\big(D({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}) \; + \; o(1)\big)},
\;\;\;\;\;\; \forall j,
\label{eqConTypeExp}
\end{align}
where ($a$) follows by Lemma~\ref{LemPDFExponent}, and ($b$) follows by (\ref{eqYgivenX}) of Lemma~\ref{LemCondTypeSize} and (\ref{eqChanApprox}).
This gives
\begin{align}
\Pr \Big\{
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\;\; & \geq \;\;
b^{\,-n\big(D({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}) \; + \; o(1)\big)}.
\label{eqPrior}
\end{align}
Now we are ready to apply Lemma~\ref{LemConvLem}:
\begin{align}
\Pr \big\{
g({\bf Y}) \neq J \big\}
\;\; & \geq \;\;
\Pr \Big\{
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}\cdot
\Pr \Big\{
g({\bf Y}) \neq J \; \big| \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\nonumber \\
& \overset{a}{\geq} \;\;
b^{\,-n\big(D({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}) \; + \; o(1)\big)}
\cdot
\Big[
1 \, - \,
b^{\,-n\big(\widetilde{R} \; - \; I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X})  %I(X;\,Y)
\; + \; o(1)\big)}
\Big]
\nonumber \\
& \overset{b}{\geq} \;\;
b^{\,-n\big(D({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}) \; + \; o(1)\big)}
\cdot 1/2,
\nonumber
\end{align}
where ($a$) follows by (\ref{eqPrior}) and Lemma~\ref{LemConvLem},
and ($b$) holds for $I({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}) \,\leq \, \widetilde{R} - {\log\mathstrut}_{\!b}(2)/n + o(1)$.
\end{proof}

\bigskip

\begin{lemma}[Type constraint] \label{LemTypeConstraint}
{\em
For any $\epsilon > 0$ there exists $n_{0} = n_{0}(\alpha, s^{2}, \epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$ and any codeword ${\bf x} \in \mathbb{R}{\mathstrut}^{n}$,
satisfying the power constraint (\ref{eqPowerConstraint}), the quantized version of that codeword, %${\bf x}^{q} = Q_{\alpha}({\bf x})$,
defined by (\ref{eqQuantizer}),
satisfies the power constraint (\ref{eqPowerConstraint}) within $\epsilon$, that is
with $s^{2}$ replaced by $s^{2} + \epsilon$.
%$\tilde{s}^{2} = s^{2} + \epsilon$.
}
%\begin{displaymath}
%\frac{1}{n}\sum_{k \, = \, 1}^{n}x_{k}^{2} \; \leq \; s^{2} \, + \, \epsilon.
%\end{displaymath}
\end{lemma}
The proof is the same as (\ref{eqRealAverage})-(\ref{eqRealBounded2}).


\bigskip


\begin{lemma}[Error exponent] \label{LemAllCodebooks}
{\em
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
Then for any %parameters
$c_{XY}$ and $\epsilon > 0$ there exists
$n_{0} = n_{0}(\alpha, \,\beta, \,s^{2}, \, \sigma^{2}, \,c_{XY}, %\,R,
\,\epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$
}
\begin{equation} \label{eqBoundTypes}
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) \neq J \big\}
\;\; \leq \;\;
\max_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
\;\;
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; c_{XY},
\\ I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X}) \; \leq \; R \, - \, \epsilon
}}
\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\Big\} \; + \; o(1),
\end{equation}
{\em where $o(1)\rightarrow 0$, as $n\rightarrow \infty$, %and depends
depending only on the parameters
$\alpha$, $\beta$, $s^{2} + \epsilon$, $c_{XY}$, and $\sigma^{2}$.}
\end{lemma}

\bigskip

\begin{proof}
For a type ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ let us define $\,M({P\mathstrut}_{\!X}) \, \triangleq \,
\big|\,
\big\{
j : \,
{\bf x}^{q}(j) \in T({P\mathstrut}_{\!X})
\big\}\,\big|$.
%\begin{displaymath}
%{\cal C}({P\mathstrut}_{\!X}) \;\; \triangleq \;\;
%\big\{
%{\bf x} \in {\cal C} : \;
%{\bf x}^{q} \in T({P\mathstrut}_{\!X})
%\big\}.
%\end{displaymath}
Then for any $n$ greater than $n_{0}$ of Lemma~\ref{LemTypeConstraint}
there exists at least one type ${P\mathstrut}_{\!X}$ such that
\begin{equation} \label{eqFrequentType}
M({P\mathstrut}_{\!X})
\;\; \geq \;\;
\frac{M}{\big|\,  {\cal P}_{n}\big({\cal X}_{n}, \,s^{2} + \epsilon\big) \,\big|}
\;\; \geq \;\;
\frac{M}{\big((n + 1)c\big)^{\tilde{c}\, n^{(1\,+\, 2\alpha)/3}}},
\end{equation}
where the second inequality follows by Lemma~\ref{LemNumofTypes} applied with $c_{X} = s^{2} + \epsilon$.
%and the constants $c$ and $\tilde{c}$ are as defined in Lemma~\ref{LemNumofTypes}.
Then we can use such a type for a bound:
\begin{align}
& \Pr \big\{
g({\bf Y}) \neq J \big\} \;\; = \;\; \frac{1}{M}\sum_{j \, = \, 1}^{M} \Pr \big\{{\bf Y} \notin {\cal D}{\mathstrut}_{J} \; | \; J = j\big\}
\;\; \geq \;\;
\frac{1}{M}\sum_{\substack{1\,\leq\,j\,\leq\,M \, : \\
{\bf x}^{q}(j) \, \in \, T({P\mathstrut}_{\!X})
}} \Pr \big\{{\bf Y} \notin {\cal D}{\mathstrut}_{J} \; | \; J = j\big\}
\nonumber \\
%&
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
%\geq \;\;
%\frac{1}{\big((n + 1)c\big)^{\tilde{c}\, n^{(1\,+\, 2\alpha)/3}}}\cdot
%\frac{1}{|\,{\cal C}({P\mathstrut}_{\!X})\,|}\sum_{\substack{1\,\leq\,j\,\leq\,M \, : \\
%{\bf x}^{q}(j) \, \in \, T({P\mathstrut}_{\!X})
%}} \Pr \big\{g({\bf Y}) \neq J \; | \; J = j\big\}
%\nonumber \\
&
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
%\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\;\;\;\;\;\;\;\;\;\;\;\,\,\,\,
\overset{a}{\geq} \;\;
b^{\,n \,\cdot \, o(1)}\,
\frac{1}{M({P\mathstrut}_{\!X})}\sum_{\substack{1\,\leq\,j\,\leq\,M \, : \\
{\bf x}^{q}(j) \, \in \, T({P\mathstrut}_{\!X})
}} \Pr \big\{{\bf Y} \notin {\cal D}{\mathstrut}_{J} \; | \; J = j\big\}
\nonumber \\
&
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
%\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\;\;\;\;\;\;\;\;\;\;\;\,\,\,\,
\overset{b}{=} \;\;
b^{\,n \,\cdot \, o(1)}\,
\Pr \big\{\,
\widetilde{g}(\widetilde{\bf Y}) \,\neq\, \widetilde{J} \,\big\},
%\;\; \geq \;\;
%b^{\,n \,\cdot \, o(1)}\,
%\inf_{\substack{\\ \widetilde{g}}}\,
%\Pr \big\{\,
%\widetilde{g}(\widetilde{\bf Y}) \,\neq\, \tilde{J} \,\big\}
\label{eqSmallerCodebook}
\end{align}
where ($a$) follows by (\ref{eqFrequentType}),
and ($b$) holds for the random variable $\widetilde{J} \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M({P\mathstrut}_{\!X})\}\big)$,
independent of the channel,
and the %communication system
channel input/output
random vectors
${\bf x}\big(m_{\widetilde{J}}\big) \rightarrow \widetilde{\bf Y}$
with the decoder
\begin{displaymath} %\label{eqDec}
\widetilde{g}({\bf y})
\;\; \triangleq \;\;
\left\{
\begin{array}{r l}
0, & \;\;\; {\bf y} \in \bigcap_{\,j \, = \, 1}^{\,M({P\mathstrut}_{\!X})} {\cal D}{\mathstrut}_{m_{j}}^{c}, \\
j, & \;\;\; {\bf y} \in {\cal D}{\mathstrut}_{m_{j}}, \;\;\; %\;\;\;\;\;\;\;\;\;
j \in \{1, 2, .\,.\,.\, , \, M({P\mathstrut}_{\!X})\},
\end{array}
\right.
\end{displaymath}
where $m_{1} < .\,.\,. < m_{M({P\mathstrut}_{\!X})}$ are the indices of the codewords in ${\cal C}$ with
their quantized versions in $T({P\mathstrut}_{\!X})$.
%${\bf x}^{q} = T({P\mathstrut}_{\!X})$.

It follows now from (\ref{eqSmallerCodebook}) that the LHS of (\ref{eqBoundTypes}) can be upper-bounded by
(\ref{eqCCBound}) of Lemma~\ref{LemConstComp}
with $\widetilde{R} = \frac{1}{n}\,{\log\mathstrut}_{\!b}\,M({P\mathstrut}_{\!X})$.
Substituting then (\ref{eqFrequentType}) in place of $M({P\mathstrut}_{\!X})$
we obtain a stricter condition under the minimum of (\ref{eqCCBound}), leading to %another
an upper bound with
a condition $I({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}) \,\leq \, R - o(1)$
and to (\ref{eqBoundTypes}).
%\begin{align}
%- \frac{1}{n}\,{\log\mathstrut}_{\!b}\,\Pr \big\{
%g({\bf Y}) \neq J \big\}
%\;\; & \leq \;\;
%\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
%{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
%\\
%\mathbb{E}[(Y-X)^{2}] \; \leq \; c_{XY},
%\\ I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X}) \; \leq \;
%\frac{1}{n}\,{\log\mathstrut}_{\!b}\,|\,{\cal C}({P\mathstrut}_{\!X})\,| \, - \, o(1)
%}}
%\Big\{
%D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
%\Big\} \; + \; o(1)
%\nonumber \\
%& \leq \;\;
%\;\;\;\;\;\,\,\,
%\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
%{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
%\\
%\mathbb{E}[(Y-X)^{2}] \; \leq \; c_{XY},
%\\ I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X}) \; \leq \;
%\widetilde{R} \, - \, o_{1}(1)
%}}
%\;\;\;\;\;\,\,\,
%\Big\{
%D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
%\Big\} \; + \; o(1)
%\nonumber
%\end{align}
\end{proof}


%\bigskip


\section{Correct-decoding exponent}\label{CorDecExp}

%\bigskip
The end result of this section is Lemma~\ref{LemCorDec}, which is a converse bound on the correct-decoding exponent by the method of types.

\begin{lemma}[Joint type constraint] \label{LemTypeNoise}
{\em
For any $\epsilon > 0$ and $\widetilde{\sigma}^{2}$ there exists $n_{0} = n_{0}(\alpha, \,\beta, \,\widetilde{\sigma}^{2}, \,\epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$ and any pair of vectors
${\bf x}, {\bf y} \in \mathbb{R}{\mathstrut}^{n}$ %and ${\bf y}\in \mathbb{R}{\mathstrut}^{n}$,
satisfying}
\begin{displaymath}
\frac{1}{n}\sum_{k \, = \, 1}^{n}(y_{k} - x_{k})^{2} \;\; \leq \;\; \widetilde{\sigma}^{2},
\end{displaymath}
{\em the respective quantized versions ${\bf x}^{q} = Q_{\alpha}({\bf x})$ and ${\bf y}^{q} = Q_{\beta}({\bf y})$,
defined as in (\ref{eqQuantizer}),
satisfy}
\begin{displaymath}
\frac{1}{n}\sum_{k \, = \, 1}^{n}(y_{k}^{q} - x_{k}^{q})^{2} \;\; \leq \;\; \widetilde{\sigma}^{2} \, + \, \epsilon.
\end{displaymath}
\end{lemma}
The proof is the same as (\ref{eqRealAverage})-(\ref{eqRealBounded2}).

%\bigskip


We use a Chernoff bound for the probability of an event when the method of types cannot be applied:

\begin{lemma}[Chernoff bound] \label{LemChernoff}
{\em Let $Z_{k} \sim {\cal N}(0, \sigma^{2})$, $k = 1, 2, .\,.\,.\, , \, n$, be $n$ independent random variables.
Then for $\,\widetilde{\sigma}^{2} \geq \sigma^{2}\,$
and $\,f(x) \,\triangleq\, \tfrac{1}{2}\big[x - 1 - \ln(x)\big]$:
}
\begin{displaymath}
\Pr\bigg\{
\frac{1}{n}\sum_{k \, = \, 1}^{n}Z_{k}^{2} \; \geq \; \widetilde{\sigma}^{2}
\bigg\}
\;\; \leq \;\; \exp\big\{-nf(\widetilde{\sigma}^{2}/\sigma^{2})\big\}.
%\;\;\;\;\;\;\;\;\; \widetilde{\sigma}^{2} \geq \sigma^{2},
\end{displaymath}
%{\em where $\,f(x) \,\triangleq\, \tfrac{1}{2}\big[x - 1 - \ln(x)\big]$.}
\end{lemma}


%\bigskip


\begin{lemma}[Correct-decoding exponent of %quasi constant
mono-composition codebooks]
%[Decoding error in codebooks with the constant-composition quantized versions]
\label{LemConstComp2}
{\em %Let ${\cal X}_{n}$ and ${\cal Y}_{n}$ be two alphabets defined as in (\ref{eqAlphabets}), (\ref{eqDelta}).
Let ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ be a type,
such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$,
%$\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq c_{Y}$,
%and $\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$,
and
let ${\cal C}$ be a codebook, %of size $M(n, R)$,
such that the quantized versions (\ref{eqQuantizer}) of %all %the
its codewords ${\bf x}(m)$, $m = 1, 2, .\,.\,.\, , \, M(n, R)$,
are all of the %same
type ${P\mathstrut}_{\!X}$, that is:
%such that for each codeword ${\bf x}(m)$
%its quantized version
\begin{displaymath} %\label{eqConstantComposition}
{\bf x}^{q}(m) \; = \; Q_{\alpha}({\bf x}(m))
\; = \;
\big(Q_{\alpha}(x_{1}(m)), Q_{\alpha}(x_{2}(m)), .\,.\,.\, , \,Q_{\alpha}(x_{n}(m))\big)
\; \in \;
T({P\mathstrut}_{\!X}), \;\;\; \forall m.
\end{displaymath}
%Let $J$ be a random variable distributed uniform over $\{1, 2, .\,.\,.\, , \, M\}$,
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
%Let ${\bf Y}^{q} = Q_{\beta}({\bf Y})\in {\cal Y}_{n}^{n}$.
Then for any $\epsilon > 0$ and $\,\widetilde{\sigma}^{2} \geq \sigma^{2}$
there exists $n_{0} = n_{0}(\alpha, \,\beta, \,\widetilde{\sigma}^{2}, \,\epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$
}
\begin{align}
%&
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) = J \big\}
\;\; \geq \;\; &
%-\frac{1}{n}\,{\log\mathstrut}_{\!b} \, 2 \, + \,
\min \big\{E_{n}({P\mathstrut}_{\!X}, \,R, \,\widetilde{\sigma}, \, \epsilon), \; E(\widetilde{\sigma})\big\}
\, + \, o(1),
\label{eqMinofTwoExponents} \\
%\end{displaymath}
%{\em where}
%\begin{align} %\label{eqCCBound}
E(\widetilde{\sigma}) \;\; \triangleq \;\; & \frac{1}{2\ln b}
\big[\,\widetilde{\sigma}^{2}/\sigma^{2} \, - \, 1 \, - \, \ln\,(\widetilde{\sigma}^{2}/\sigma^{2})
\,\big],
%f(\widetilde{\sigma}^{2}/\sigma^{2}),
\label{eqOutlierExp} \\
E_{n}({P\mathstrut}_{\!X}, \,R, \,\widetilde{\sigma}, \, \epsilon)
\;\; \triangleq \;\; &
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2} \, + \, \epsilon
%\;\, \leq \;\, \widetilde{\sigma}^{2} \; + \; \epsilon \,\cdot \,\sigma^{2}/s^{2}
}}
\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\, + \,
\big|\,
%\widetilde{R}
R \, - \, I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)
\,\big|^{+}
\Big\}, %\; + \; o(1),
\label{eqPartialExp}
\end{align}
{\em where $|\,t\,|^{+}\triangleq \max\,\{0, t\}$,
%$\widetilde{R} = \frac{1}{n}\,{\log\mathstrut}_{\!b}\,M(n, R)$,
and
$o(1)\rightarrow 0$, as $n\rightarrow \infty$, %and depends
depending only on %the parameters
$\alpha$, $\beta$, $c_{X}$, $\widetilde{\sigma}^{2} + \epsilon$, and $\sigma^{2}$.}
\end{lemma}

\bigskip

\begin{proof}
We consider probabilities of two disjoint events:
\begin{align}
\Pr \big\{
g({\bf Y}) = J \big\}
\;\, & \leq \;\,
\Pr \big\{
g({\bf Y}) = J, \;
\|{\bf Y} - {\bf x}(J)\|^{2}
\leq n\widetilde{\sigma}^{2}
\big\} \; + \;
\Pr \big\{
\|{\bf Y} - {\bf x}(J)\|^{2}
%\geq
>
n\widetilde{\sigma}^{2}
\big\}
\nonumber \\
& \leq \;\,
2 \max \Big\{
\Pr \big\{
g({\bf Y}) = J, \;
\|{\bf Y} - {\bf x}(J)\|^{2}
\leq n\widetilde{\sigma}^{2}
\big\}, \;\,
\Pr \big\{
\|{\bf Y} - {\bf x}(J)\|^{2}
\geq n\widetilde{\sigma}^{2}
\big\}
\Big\}.
\label{eqTwoEvents}
\end{align}
For the first term in the maximum we obtain:
\begin{align}
&
\;\,\,
\Pr \big\{
g({\bf Y}) = J, \;
\|{\bf Y} - {\bf x}(J)\|^{2}
\leq n\widetilde{\sigma}^{2}
\big\}
\;\; \overset{a}{\leq} \;\;
\Pr \big\{
g({\bf Y}) = J, \;
\|{\bf Y}^{q} - {\bf x}^{q}(J)\|^{2}
\leq n(\widetilde{\sigma}^{2} + \epsilon)
\big\}
\nonumber \\
&
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,
\overset{b}{=}
\sum_{\substack{{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2} \, + \, \epsilon
}}
\Pr \big\{
g({\bf Y}) = J, \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\big\}
\nonumber \\
& \overset{c}{\leq} \;\;
\big|\,  {\cal P}_{n}\big({\cal X}_{n}\times {\cal Y}_{n}, \,c_{X}, \,c_{Y}\big) \,\big|
\max_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}[(Y-X)^{2}] \; \leq \; \widetilde{\sigma}^{2} \, + \, \epsilon
}}
\Pr \big\{
g({\bf Y}) = J, \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\big\},
\label{eqMaxoverTypes}
\end{align}
where ($a$) holds
with ${\bf Y}^{q} = Q_{\beta}({\bf Y})\in {\cal Y}_{n}^{n}\,$
for all $n > n_{0}(\alpha, \,\beta, \,\widetilde{\sigma}^{2}, \,\epsilon)$ of Lemma~\ref{LemTypeNoise},
($b$) holds because ${\bf x}^{q}(J) \in T({P\mathstrut}_{\!X})$,
in ($c$) we use the notation %of Lemma~\ref{LemNumofJTypes}
${\cal P}_{n}\big({\cal X}_{n}\times {\cal Y}_{n}, \,c_{X}, \,c_{Y}\big)$ for the set of all
the joint types ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$
satisfying both $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$
and
$\mathbb{E}_{{P\mathstrut}_{\!Y}}\!\big[Y^{2}\big] \leq \big(\sqrt{c_{X}} + \sqrt{\widetilde{\sigma}^{2} + \epsilon}\big)^{2} \triangleq c_{Y}$.
By the same steps as in (\ref{eqConTypeExp}) we further obtain
\begin{align}
\Pr \Big\{
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\;\; & \leq \;\;
b^{\,-n\big(D({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}) \; + \; o(1)\big)},
\label{eqPrior2}
\end{align}
while Lemma~\ref{LemConvLem} gives
\begin{equation} \label{eqPositivePart}
\Pr \Big\{
g({\bf Y}) = J \; \big| \;
\big({\bf x}^{q}(J), \,{\bf Y}^{q}\big) \, \in \, T({P\mathstrut}_{\!XY})
\Big\}
\;\; \leq \;\;
b^{\,-n\big(|\, %\widetilde{R}
R \; - \; I({P\mathstrut}_{\!XY})\,
|{\mathstrut}^{+}
\, + \; o(1)\big)}.
\end{equation}
Now by Lemma~\ref{LemNumofJTypes} for the number of joint types and (\ref{eqMaxoverTypes})-(\ref{eqPositivePart})
we obtain
\begin{displaymath}
%- \frac{1}{n}\,{\log\mathstrut}_{\!b}
\Pr \big\{
g({\bf Y}) = J, \;
\|{\bf Y} - {\bf x}(J)\|^{2}
\leq n\widetilde{\sigma}^{2}
\big\}
\;\; %\geq
\leq
\;\;
b^{\,-n\big(
E_{n}({P\mathstrut}_{\!X}, \,R, \,\widetilde{\sigma}, \, \epsilon) \, + \, o(1) \big)
},
\end{displaymath}
where $E_{n}({P\mathstrut}_{\!X}, \,R, \,\widetilde{\sigma}, \, \epsilon)$ denotes the expression (\ref{eqPartialExp}).
Applying Lemma~\ref{LemChernoff} to the second term in the maximum of (\ref{eqTwoEvents})
we obtain %(\ref{eqOutlierExp}) and
(\ref{eqMinofTwoExponents})-(\ref{eqPartialExp}).
\end{proof}


%\bigskip


\begin{lemma}[Correct-decoding exponent] \label{LemCorDec}
{\em
Let $J \sim \text{Unif}\,\big(\{1, 2, .\,.\,.\, , \, M\}\big)$ be a random variable,
independent of the channel, and let ${\bf x}(J) \rightarrow {\bf Y}$ be the random channel-input and channel-output vectors, respectively.
%Let ${\bf Y}^{q} = Q_{\beta}({\bf Y})\in {\cal Y}_{n}^{n}$.
Then for any $\widetilde{\epsilon}, \,\epsilon > 0$ and $\,\widetilde{\sigma}^{2} \geq \sigma^{2}$
there exists $n_{0} = n_{0}(\alpha, \,\beta, \,s^{2}, \,\widetilde{\sigma}^{2}, \, \widetilde{\epsilon}, \,\epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$}
\begin{align}
%&
- \frac{1}{n}\,{\log\mathstrut}_{\!b}\Pr \big\{
g({\bf Y}) = J \big\}
\;\; \geq \;\; &
%-\frac{1}{n}\,{\log\mathstrut}_{\!b} \, 2 \, + \,
\min \big\{E_{n}(R, \,\widetilde{\sigma}, \, \widetilde{\epsilon}, \, \epsilon), \; E(\widetilde{\sigma})\big\}
\, + \, o(1),
\label{eqMinofTwoExponents2} \\
E_{n}(R, \,\widetilde{\sigma}, \, \widetilde{\epsilon}, \, \epsilon)
\;\; \triangleq \;\; &
\min_{\substack{\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n}),
\\
\mathbb{E}[X^{2}] \; \leq \; s^{2}\, + \, \epsilon}}
E_{n}({P\mathstrut}_{\!X}, \,R, \,\widetilde{\sigma}, \,\widetilde{\epsilon}\,)
\label{eqPartialExp2}
\end{align}
{\em where $E(\widetilde{\sigma})$ and $E_{n}({P\mathstrut}_{\!X}, \,R, \,\widetilde{\sigma}, \, \widetilde{\epsilon}\,)$
are as defined in (\ref{eqOutlierExp}) and (\ref{eqPartialExp}), respectively,
and
$o(1)\rightarrow 0$, as $n\rightarrow \infty$, %and depends
depending only on the parameters
$\alpha$, $\beta$, $s^{2} + \epsilon$, $\widetilde{\sigma}^{2} + \widetilde{\epsilon}$, and $\sigma^{2}$.}
\end{lemma}

%\bigskip


\begin{proof}
Similarly as in \cite[Lemma~5]{DueckKorner79}:
\begin{align}
\Pr \big\{
g({\bf Y}) = J \big\} \; = \;
\frac{1}{M}
\sum_{\substack{
{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n})}}
&
\sum_{\substack{1\,\leq\,j\,\leq\,M \, : \\
{\bf x}^{q}(j) \, \in \, T({P\mathstrut}_{\!X})
}} \Pr \big\{{\bf Y} \in {\cal D}{\mathstrut}_{J} \; | \; J = j\big\}
\nonumber \\
\overset{a}{\leq} \;
\big|\,  {\cal P}_{n}\big({\cal X}_{n}, \,s^{2} + \epsilon\big) \,\big| \cdot
\frac{1}{M}
\max_{\substack{%\\{P\mathstrut}_{\!X{\color{white}|}}\!\!:\\
\\{P\mathstrut}_{\!X}\,\in \, {\cal P}_{n}({\cal X}_{n})}}
&
\sum_{\substack{1\,\leq\,j\,\leq\,M \, : \\
{\bf x}^{q}(j) \, \in \, T({P\mathstrut}_{\!X})
}} \Pr \big\{{\bf Y} \in {\cal D}{\mathstrut}_{J} \; | \; J = j\big\}
\label{eqMaximumoverTypes} \\
\overset{b}{\leq} \;
b^{\,n \,\cdot \, o(1)}\,\frac{1}{M}
&
\sum_{\substack{1\,\leq\,j\,\leq\,M \, : \\
{\bf x}^{q}(j) \, \in \, T({P\mathstrut}_{\!X}^{*})
}} \Pr \big\{{\bf Y} \in {\cal D}{\mathstrut}_{J} \; | \; J = j\big\}
%\nonumber \\
\; \overset{c}{=} \;
b^{\,n \,\cdot \, o(1)}
%&
\Pr \big\{
\widetilde{g}(\widetilde{\bf Y}) = J \big\},
\label{eqCorDecCC}
\end{align}
where:

($a$) holds for $n > n_{0}(\alpha, s^{2}, \epsilon)$ of Lemma~\ref{LemTypeConstraint};

($b$) follows by Lemma~\ref{LemNumofTypes} %for the number of types,
with $c_{X} = s^{2} + \epsilon$,
while ${P\mathstrut}_{\!X}^{*} \in {\cal P}_{n}({\cal X}_{n})$
is a maximizer of (\ref{eqMaximumoverTypes});

($c$) holds for
the channel input/output random vectors $\widetilde{\bf x}(J) \rightarrow \widetilde{\bf Y}$ and
a code $(\widetilde{\cal C}, \widetilde{g})$, such that
$\widetilde{\bf x}(j) = {\bf x}(m_{j})$ with $\widetilde{\cal D}{\mathstrut}_{j} = {\cal D}{\mathstrut}_{m_{j}}$ for
$1 \leq j \leq M({P\mathstrut}_{\!X}^{*})$,
and $\widetilde{\bf x}^{q}(j) \in T({P\mathstrut}_{\!X}^{*})$ with $\widetilde{\cal D}{\mathstrut}_{j} = \varnothing$
for $M({P\mathstrut}_{\!X}^{*}) < j \leq M$, where
$m_{1} < .\,.\,. < m_{M({P\mathstrut}_{\!X}^{*})}$ are the indices of the codewords
in the original codebook ${\cal C}$
with their quantized versions in $T({P\mathstrut}_{\!X}^{*})$.
Since all the codewords of $\widetilde{\cal C}$ have their quantized versions in $T({P\mathstrut}_{\!X}^{*})$,
we can apply Lemma~\ref{LemConstComp2} with $c_{X} = s^{2} + \epsilon$ for the RHS of (\ref{eqCorDecCC}) to obtain (\ref{eqMinofTwoExponents2}), (\ref{eqPartialExp2}).
\end{proof}



















%\bigskip


\section{PDF to type}\label{PDFtypePDF}

%\bigskip

Lemmas~\ref{LemPDFtoT} and~\ref{LemTtoPDF} of this section relate between minimums over types and over PDF's.
%Lemma~\ref{LemPDFtoT} is used for the error exponent derivation, while Lemma~\ref{LemTtoPDF} is used for the correct-decoding exponent.
The next Lemma~\ref{LemQuant}, which has a laborious proof, is required only in the proof of %the next
Lemma~\ref{LemPDFtoT}, used for Theorem~\ref{thmErrorExp}.

\bigskip

\begin{lemma}[Quantization of PDF] \label{LemQuant}
{\em Let ${\cal X}_{n}$ be an alphabet defined as in (\ref{eqAlphabets}), (\ref{eqDelta})
with $\alpha \in \big(0, \tfrac{1}{4}\big)$.
Let ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ be a type and ${p\mathstrut}_{Y|X}(\,\cdot\,|\,x) \in {\cal L}$, $\forall x \in {\cal X}_{n}\,$,
be a collection of functions from (\ref{eqLipschitz}), such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big] \leq c_{X}$,
 $\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[Y^{2}\big]\leq c_{Y}$,
and $\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$.
Then
for any alphabet ${\cal Y}_{n}$ defined as in (\ref{eqAlphabets}), (\ref{eqDelta})
with $\tfrac{1}{3} + \tfrac{2}{3}\alpha < \beta < \tfrac{2}{3} - \tfrac{2}{3}\alpha$,
there exists a joint type ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$ with the marginal type ${P\mathstrut}_{\!X}$,
such that}
\begin{align}
\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y|X}(y\,|\,x)dy
\;\; & \geq \;\;
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}(x, y){\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!Y|X}(y\,|\,x)}{\Delta_{\beta,\,n}}
\, + \, o(1),
\label{eqCondEntropy} \\
\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
(y - x)^{2}dy
\;\; & \geq \;\;
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}(x, y)(y - x)^{2} \, + \, o(1),
\label{eqLogGaussian} \\
\int_{\mathbb{R}}{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)dy
\;\; & \leq \;\;
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}(y){\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!Y}(y)}{\Delta_{\beta,\,n}}
\, + \, o(1),
\label{eqMargEntropy}
\end{align}
{\em where ${p\mathstrut}_{Y}(y) = \sum_{\,x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x){p\mathstrut}_{Y|X}(y\,|\,x)$, $\forall y \in \mathbb{R}$,
and $o(1)\rightarrow 0$, as $n\rightarrow \infty$, and depends only on the parameters $\alpha$, $\beta$, $c_{X}$, $c_{Y}$, $c_{XY}$,
and $\sigma^2$ (through (\ref{eqLipschitz})).}
\end{lemma}
The proof is given in the Appendix B.

\bigskip



\begin{lemma}[PDF to type]\label{LemPDFtoT}
{\em Let ${\cal X}_{n}$ and ${\cal Y}_{n}$ be two alphabets defined as in (\ref{eqAlphabets}), (\ref{eqDelta})
with $\alpha \in \big(0, \tfrac{1}{4}\big)$
and $\tfrac{1}{3} + \tfrac{2}{3}\alpha < \beta < \tfrac{2}{3} - \tfrac{2}{3}\alpha$.
Then for any $c_{X}$, $c_{XY}$, and $\epsilon > 0$ there exists $n_{0} = n_{0}(\alpha, \,\beta, \,c_{X}, \,c_{XY}, \,\sigma^{2}, \,\epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$ and
for any type ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$ with $\mathbb{E}_{{P\mathstrut}_{\!X}}\!
\big[X^{2}\big] \leq c_{X}$:
}
\begin{equation} \label{eqTransitionB}
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal L}, \; \forall x,
\\
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}[(Y-X)^{2}] \; \leq \; c_{XY}\! ,
\\ I({P\mathstrut}_{\!X}, \,\, {p\mathstrut}_{Y|X}) \; \leq \; R \, - \, 2\epsilon
}}
\!\!\!\!
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\Big\}
\; \;
\geq
%\;
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}_{{P\mathstrut}_{\!XY}}[(Y-X)^{2}] \; \leq \; c_{XY} \, + \, \epsilon,    %c(c_{X}\!, \, c_{XY}\!, \,\epsilon),
\\ I({P\mathstrut}_{\!X}, \, {P\mathstrut}_{\!Y|X}) \; \leq \; R \, - \, \epsilon
}}
\!\!\!\!
\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\Big\} \; + \; o(1),
\end{equation}
{\em where $o(1)\rightarrow 0$, as $n\rightarrow \infty$,
and depends only on the parameters $\alpha$, $\beta$, $c_{X}$, $c_{XY}$, and $\sigma^{2}$.}
\end{lemma}

\bigskip

\begin{proof}
For a type ${P\mathstrut}_{\!X}$ with a collection of ${p\mathstrut}_{Y|X}$ such that $\mathbb{E}_{{P\mathstrut}_{\!X}}\!
\big[X^{2}\big] \leq c_{X}$
 %$\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[Y^{2}\big]\leq c_{Y}$,
and $\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[(Y-X)^{2}\big]\leq c_{XY}$,
we can find also an upper bound $c_{Y}$ on $\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[Y^{2}\big]$.
For example, using the Cauchy-Schwarz inequality:
%also define $c_{Y}$:
\begin{displaymath}
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[Y^{2}\big]
\;\; %\overset{(*)}{\leq}
\leq
\;\;
\Big(
\mathbb{E}_{{P\mathstrut}_{\!X}}^{1/2}\big[X^{2}\big]\,+\,
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}^{1/2}\!\big[(Y-X)^{2}\big]
\Big)^{2}
\;\; \leq \;\;
\big(
\sqrt{c_{X}} \, + \, \sqrt{c_{XY}}
\big)^{2}
\;\; \triangleq \;\;
c_{Y}.
\end{displaymath}
%where ($*$) is a consequence of the Cauchy-Schwarz inequality.
Then by Lemma~\ref{LemQuant} there exists a joint type ${P\mathstrut}_{\!XY}$
with the marginal type ${P\mathstrut}_{\!X}$, such that simultaneously
the three inequalities (\ref{eqCondEntropy})-(\ref{eqMargEntropy}) are satisfied
and it also follows by (\ref{eqLogGaussian}) and (\ref{eqChanApprox}) that
\begin{equation} \label{eqConseq4}
-\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[{\log\mathstrut}_{\!b}\,w(Y\,|\,X)\big]
\;\; \geq \;\;
-\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[{\log\mathstrut}_{\!b}\,{W\mathstrut}_{\!n}(Y\,|\,X)\big]
 \, + \,
{\log\mathstrut}_{\!b}\,\Delta_{\beta,\,n}
\, + \, o(1).
\end{equation}
Then the sum of (\ref{eqCondEntropy}) and (\ref{eqConseq4}) gives
\begin{equation} \label{eqObjective}
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\;\; \geq \;\;
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\, + \, o(1),
\end{equation}
%\begin{align}
%-{h\mathstrut}_{b}(\,{p\mathstrut}_{Y|X}\,|\,{P\mathstrut}_{\!X})
%\;\; & \geq \;\;
%-{H\mathstrut}_{b}({P\mathstrut}_{\!Y|X}\,|\,{P\mathstrut}_{\!X}) \, - \,
%{\log\mathstrut}_{\!b}\,\Delta_{\beta,\,n}
%\, + \, o(1),
%\label{eqConseq1} \\
%\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[(Y - X)^{2}\big]
%\;\; & \geq \;\;
%\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y - X)^{2}\big]
%\, + \, o(1),
%\label{eqConseq2} \\
%-{h\mathstrut}_{b}(\,{p\mathstrut}_{Y})
%\;\; & \leq \;\;
%-{H\mathstrut}_{b}({P\mathstrut}_{\!Y}) \, - \,
%{\log\mathstrut}_{\!b}\,\Delta_{\beta,\,n}
%\, + \, o(1),
%\label{eqConseq3}
%\end{align}
while the difference of
(\ref{eqCondEntropy})
%(\ref{eqConseq1})
and
(\ref{eqMargEntropy}) gives
%(\ref{eqConseq3})
\begin{equation} \label{eqMutualIneq}
I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)
\;\; \leq \;\;
I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
\, + \, o(1).
\end{equation}
Note that all $o(1)$ in the above relations are independent %of the specific choice of the type ${P\mathstrut}_{\!X}$
of the joint type ${P\mathstrut}_{\!XY}$
and the functions
${p\mathstrut}_{Y|X}$. Therefore
by (\ref{eqObjective}), (\ref{eqMutualIneq}), and (\ref{eqLogGaussian})
we conclude, that
given any $\epsilon > 0$ for $n$ sufficiently large
for every type ${P\mathstrut}_{\!X}$ with the prerequisites of this lemma and every collection of ${p\mathstrut}_{Y|X}$
which satisfy the conditions under the infimum on the LHS of (\ref{eqTransitionB})
there exists a joint type ${P\mathstrut}_{\!XY}$
such that simultaneously
\begin{align}
I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)
\;\; & \leq \;\;
I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
\, + \, \epsilon,
\nonumber \\
\mathbb{E}_{{P\mathstrut}_{\!XY}}\!\big[(Y - X)^{2}\big]
\;\; & \leq \;\;
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[(Y - X)^{2}\big]
\, + \, \epsilon,
\nonumber
\end{align}
and (\ref{eqObjective}) %is satisfied.
holds with a uniform $o(1)$, i.e., independent of ${P\mathstrut}_{\!XY}$ and ${p\mathstrut}_{Y|X}$.
It follows that such
${P\mathstrut}_{\!XY}$
satisfies also the conditions under the {\em minimum} on the RHS of (\ref{eqTransitionB})
and results in the objective function of (\ref{eqTransitionB}) %as in
satisfying (\ref{eqObjective}) with the uniform $o(1)$.
Then the minimum itself, which can only possibly be taken over %the same or
a greater variety of ${P\mathstrut}_{\!XY}$,
satisfies the inequality (\ref{eqTransitionB}).
\end{proof}




\bigskip



\begin{lemma}[Type to PDF]\label{LemTtoPDF}
{\em For any $c_{XY}$ and $\epsilon > 0$ there exists $n_{0} = n_{0}(\beta, \,c_{XY}, \,\epsilon) \in \mathbb{N}$,
such that for any $n > n_{0}$ and
for any type ${P\mathstrut}_{\!X} \in {\cal P}_{n}({\cal X}_{n})$:
%with $\mathbb{E}_{{P\mathstrut}_{\!X}}\!
%\big[X^{2}\big] \leq c_{X}$:
}
\begin{align}
\min_{\substack{\\{P\mathstrut}_{\!Y|X}:\\
{P\mathstrut}_{\!XY}\,\in \, {\cal P}_{n}({\cal X}_{n}\,\times\, {\cal Y}_{n}),
\\
\mathbb{E}_{{P\mathstrut}_{\!XY}}[(Y-X)^{2}] \; \leq \; c_{XY}
%\;\, \leq \;\, \widetilde{\sigma}^{2} \; + \; \epsilon \,\cdot \,\sigma^{2}/s^{2}
}}
\;\;\;\;
&
\Big\{
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)
\, + \,
\big|\,
%\widetilde{R}
R \, - \, I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)
\,\big|^{+}
\Big\}
\nonumber \\
\geq \;\;
\inf_{\substack{{p\mathstrut}_{Y|X}:\\
{p\mathstrut}_{Y|X}(\, \cdot \, \,|\, x) \, \in \, {\cal F}_{n}, \; \forall x,
\\
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}[(Y-X)^{2}] \; \leq \; c_{XY} \, + \, \epsilon
}}
&
\Big\{
D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)
\, + \,
\big|\,
%\widetilde{R}
R \, - \, I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)
\,\big|^{+}
\Big\}
\; + \; o(1),
\label{eqTypePDF}
\end{align}
{\em where
$o(1)\rightarrow 0$, as $n\rightarrow \infty$,
and depends only on the parameters $\beta$ and $c_{XY}$.}
\end{lemma}

\bigskip

\begin{proof}
Observe first that any collection of conditional PDF's ${p\mathstrut}_{Y|X}$, which satisfies the conditions under the infimum of (\ref{eqTypePDF}),
has finite differential entropies and well-defined quantities $D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)$
and $I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big)$.
For any
%each
conditional type ${P\mathstrut}_{\!Y|X}$ from the LHS of (\ref{eqTypePDF}) %let us
we can define a
set of histogram-like conditional
PDF's:
\begin{align}
{p\mathstrut}_{Y|X}(y\,|\,x) \; & \triangleq \;
\frac{{P\mathstrut}_{\!Y|X}(j\Delta_{\beta,\,n} \, | \, x)}{\Delta_{\beta,\,n}},
\;\;\;\;\;
\forall y \in \big[(j - 1/2)\Delta_{\beta,\,n}, \;  (j + 1/2)\Delta_{\beta,\,n}\big),
\;\forall j \in \mathbb{Z}, \;\forall x \in {\cal S}({P\mathstrut}_{\!X}),%{\cal X}_{n},
\label{eqStepFunction}
\end{align}
which are step functions of $y \in \mathbb{R}$ for each $x \in {\cal S}({P\mathstrut}_{\!X}) $. %{\cal X}_{n}$. %, resembling a histogram.
Then
$I\big({P\mathstrut}_{\!X}, \, {p\mathstrut}_{Y|X}\big) = I\big({P\mathstrut}_{\!X}, {P\mathstrut}_{\!Y|X}\big)$,
and
${p\mathstrut}_{Y|X}(\,\cdot \, \, | \, x) \in {\cal F}_{n}$,
as defined in (\ref{eqBoundedContinuous}).
Analogously to (\ref{eqRealAverage})-(\ref{eqRealBounded2}), it can be obtained that
\begin{displaymath}
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\big[(Y-X)^{2}\big] \;\; \leq \;\;
\mathbb{E}_{{P\mathstrut}_{\!XY}}\big[(Y-X)^{2}\big]  \, + \,\Delta_{\beta,\,n}
\sqrt{c_{XY}}
\, + \, \Delta_{\beta,\,n}^{2}/4.
\end{displaymath}
Then also
$D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big)  \leq
D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big)  +  o(1)$.
%\begin{align}
%%\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\big[(Y-X)^{2}\big] \;\; & \leq \;\;
%%\mathbb{E}_{{P\mathstrut}_{\!XY}}\big[(Y-X)^{2}\big]  \, + \, o(1),
%%\nonumber \\
%D\big(\,{p\mathstrut}_{Y|X}\,\|\, \, w \, \,|\, {P\mathstrut}_{\!X}\big) \;\; & \leq \;\;
%D\big({P\mathstrut}_{\!Y|X}\,\|\, {W\mathstrut}_{\!n} \,|\,  {P\mathstrut}_{\!X}\big) \, + \, o(1),
%\nonumber
%\end{align}
%It follows that the minimum taken over all the sets of conditional PDF %as in
%(\ref{eqStepFunction})
%will satisfy the inequality (\ref{eqTypePDF}).
%Finally,
Then the lemma follows.
\end{proof}

%\bigskip

We use Lemmas~\ref{LemPDFtoT} and~\ref{LemTtoPDF} in Section~\ref{Main}
in the derivation of Theorems~\ref{thmErrorExp} and~\ref{thmCorDecExp},
%the error exponent and the correct-decoding exponent,
respectively.



%\section{Conclusion}\label{Conclusion}





























%\bigskip

\section*{Appendix A}\label{AppendixA}

%\bigskip




%\begin{proof}
\subsection*{Proof of Lemma~\ref{LemSupportXY}:}
%{\em Proof of Lemma~\ref{LemSupportXY}:}
Adding the two power constraints together, we successively obtain the following inequalities:
\begin{align}
\sum_{(x, \, y) \, \in \, {\cal S}({P\mathstrut}_{\!XY})}{P\mathstrut}_{\!XY}(x, y) (x^{2} + y^{2})
\;\; & \leq \;\;
c_{X} + c_{Y},
\nonumber \\
\sum_{(x, \, y) \, \in \, {\cal S}({P\mathstrut}_{\!XY})}\frac{1}{n} (x^{2} + y^{2})
\;\; & \leq \;\;
c_{X} + c_{Y},
\nonumber \\
\sum_{(x, \, y) \, \in \, {\cal S}({P\mathstrut}_{\!XY})}\frac{1}{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|} (x^{2} + y^{2})
\;\; & \leq \;\;
\frac{n(c_{X} + c_{Y})}{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|},
\nonumber \\
\mathbb{E} \big[\|{\bf U}\|^{2}\big]
\;\; & \leq \;\;
\frac{n(c_{X} + c_{Y})}{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|},
\nonumber
\end{align}
where ${\bf U} \sim \text{Discrete-Uniform}\big({\cal S}({P\mathstrut}_{\!XY})\big)$. To this let us add a {\em continuously} distributed random vector
\begin{displaymath}
{\bf D} \; \sim \; \text{Continuous-Uniform}\big(\,[-\Delta_{\alpha,\,n}/2, \, \Delta_{\alpha,\,n}/2) \, \times \,
[-\Delta_{\beta,\,n}/2, \, \Delta_{\beta,\,n}/2)
\,\big),
\end{displaymath}
independent of ${\bf U}$.
Then $\widetilde{\bf U} \, = \, {\bf U} + {\bf D} \, \sim \, \text{Continuous-Uniform}(A)$,
where
\begin{displaymath}
A \;\; \triangleq \;\; \bigcup_{(x, \, y) \, \in \, {\cal S}({P\mathstrut}_{\!XY})}
\big\{
x \, + \, [-\Delta_{\alpha,\,n}/2, \, \Delta_{\alpha,\,n}/2)
\big\}
\, \times \,
\big\{
y \, + \, [-\Delta_{\beta,\,n}/2, \, \Delta_{\beta,\,n}/2)
\big\}
.
\end{displaymath}
So we have

\begin{align}
\frac{n(c_{X} + c_{Y})}{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|}
\, + \,
\frac{\Delta_{\alpha,\,n}^{2} + \Delta_{\beta,\,n}^{2}}{12}
\;\; & \geq \;\;
\mathbb{E} \big[\|{\bf U}\|^{2}\big] \, + \, \mathbb{E} \big[\|{\bf D}\|^{2}\big]
\;\; = \;\;
\mathbb{E} \big[\|\widetilde{\bf U}\|^{2}\big]
%\nonumber \\
\;\; = \;\;
\frac{1}{\text{vol}(A)}
\int_{A}\|\widetilde{\bf u}\|^{2}d^{2}\widetilde{\bf u}
\nonumber \\
& = \;\;
\frac{1}{\text{vol}(A)}
\bigg[
\int_{A\,\cap\,B}\|\widetilde{\bf u}\|^{2}d^{2}\widetilde{\bf u}
\, +
\int_{A\,\cap\,B{\mathstrut}^{c}}\|\widetilde{\bf u}\|^{2}d^{2}\widetilde{\bf u}
\bigg]
\nonumber \\
& \overset{a}{\geq} \;\;
\frac{1}{\text{vol}(A)}
\bigg[
\int_{A\,\cap\,B}\|\widetilde{\bf u}\|^{2}d^{2}\widetilde{\bf u}
\, +
\int_{A{\mathstrut}^{c}\,\cap\,B}\|{\bf t}\|^{2}d^{2}{\bf t}
\bigg]
\nonumber \\
& = \;\;
\frac{1}{\text{vol}(A)}
\int_{B}\|{\bf t}\|^{2}d^{2}{\bf t},
\label{eqCenteredDisk}
\end{align}
where for ($a$) we use the disk set $B \, \triangleq \, \big\{{\bf t}: \; \pi\|{\bf t}\|^{2} \, \leq \, \text{vol}(A)\big\}$,
centered around zero and of the same total area as $A$,
and the resulting property
\begin{align}
\text{vol}(A\cap B) \, + \, \text{vol}(A\cap B{\mathstrut}^{c})
\;\; = \;\;
\text{vol}(A)
\;\; & = \;\;
\text{vol}(B)
\;\; = \;\;
\text{vol}(A\cap B) \, + \, \text{vol}(A{\mathstrut}^{c}\cap B),
\nonumber \\
\text{vol}(A\cap B{\mathstrut}^{c})
\;\; & = \;\;
\text{vol}(A{\mathstrut}^{c}\cap B),
\nonumber \\
%\end{align}
%so that
%\begin{displaymath}
\int_{A\,\cap\,B{\mathstrut}^{c}}\|\widetilde{\bf u}\|^{2}d^{2}\widetilde{\bf u}
\;\; \geq \;\;
\frac{\text{vol}(A)}{\pi}\int_{A\,\cap\,B{\mathstrut}^{c}}d^{2}\widetilde{\bf u}
\;\; & = \;\;
\frac{\text{vol}(A)}{\pi}\int_{A{\mathstrut}^{c}\,\cap\,B}d^{2}{\bf t}
\;\; \geq \;\;
\int_{A{\mathstrut}^{c}\,\cap\,B}\|{\bf t}\|^{2}d^{2}{\bf t}.
\nonumber
%\end{displaymath}
\end{align}
Integrating on the RHS of (\ref{eqCenteredDisk}), we obtain
\begin{align}
\frac{\text{vol}(A)}{2\pi}
\;\; = \;\;
\frac{|\, {\cal S}({P\mathstrut}_{\!XY}) \,| \cdot \Delta_{\alpha,\,n}\Delta_{\beta,\,n}}{2\pi}
\;\; & \leq \;\;
\frac{n(c_{X} + c_{Y})}{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|}
\, + \,
\frac{\Delta_{\alpha,\,n}^{2} + \Delta_{\beta,\,n}^{2}}{12},
\nonumber \\
\frac{|\, {\cal S}({P\mathstrut}_{\!XY}) \,|^{\,2} \cdot \Delta_{\alpha,\,n}\Delta_{\beta,\,n}}{2\pi n}
\;\; & \leq \;\;
c_{X} + c_{Y} \, + \,
\frac{\Delta_{\alpha,\,n}^{2} + \Delta_{\beta,\,n}^{2}}{12}\cdot
\underbrace{\frac{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}{n}}_{\leq \; 1}
%\nonumber \\
\;\; \leq \;\;
c_{X} + c_{Y} + 1/6,
\nonumber \\
|\, {\cal S}({P\mathstrut}_{\!XY}) \,|^{\,2}
\;\; & \leq \;\;
2\pi(c_{X} + c_{Y} + 1/6)\cdot n\Delta_{\alpha,\,n}^{-1}\Delta_{\beta,\,n}^{-1}
\nonumber \\
& = \;\;
2\pi(c_{X} + c_{Y} + 1/6)\cdot n^{1 \, + \, \alpha \, + \, \beta}.
\nonumber
\end{align}
%\end{proof}
$\square$

%\newpage

\bigskip

%\begin{proof}
\subsection*{Proof of Lemma~\ref{LemSupportX}:}
Similarly as in Lemma~\ref{LemSupportXY}, the power constraint gives the following succession of inequalities:
\begin{align}
\sum_{x \, \in \, {\cal S}({P\mathstrut}_{\!X})}{P\mathstrut}_{\!X}(x) x^{2}
\;\; & \leq \;\;
c_{X},
\nonumber \\
\sum_{x \, \in \, {\cal S}({P\mathstrut}_{\!X})} \frac{1}{n} x^{2}
\;\; & \leq \;\;
c_{X},
\nonumber \\
\sum_{x \, \in \, {\cal S}({P\mathstrut}_{\!X})} \frac{1}{|\, {\cal S}({P\mathstrut}_{\!X}) \,|} x^{2}
\;\; & \leq \;\;
\frac{n}{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}c_{X},
\nonumber \\
\mathbb{E} \big[U^{2}\big]
\;\; & \leq \;\;
\frac{n}{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}c_{X},
\nonumber
\end{align}
where $U \sim \text{Discrete-Uniform}\big({\cal S}({P\mathstrut}_{\!X})\big)$. To this let us add a {\em continuously} distributed random variable
\begin{displaymath}
D \; \sim \; \text{Continuous-Uniform}\big(\,[-\Delta_{\alpha,\,n}/2, \, \Delta_{\alpha,\,n}/2)\,\big),
\end{displaymath}
independent of $U$.
Then $\widetilde{U} \, = \, U + D \, \sim \, \text{Continuous-Uniform}(A)$,
where
\begin{displaymath} %\label{eqContSupp}
A \;\; \triangleq \;\; \bigcup_{x \, \in \, {\cal S}({P\mathstrut}_{\!X})}
\big\{
x + [-\Delta_{\alpha,\,n}/2, \, \Delta_{\alpha,\,n}/2)
\big\}.
\end{displaymath}
So we have
\begin{align}
\frac{n}{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}c_{X}
\, + \,
\frac{\Delta_{\alpha,\,n}^{2}}{12}
\;\; %&
\geq \;\;
\mathbb{E} \big[U^{2}\big] \, + \, \mathbb{E} \big[D^{2}\big]
\;\; = \;\;
\mathbb{E} \big[\widetilde{U}^{2}\big]
%\nonumber \\
\;\; & = \;\;
\frac{1}{\text{vol}(A)}
\int_{A}\widetilde{u}^{\,2}d\widetilde{u}
\nonumber \\
& = \;\;
\frac{1}{\text{vol}(A)}
\bigg[
\int_{A\,\cap\,B}\widetilde{u}^{\,2}d\widetilde{u}
\, +
\int_{A\,\cap\,B{\mathstrut}^{c}}\widetilde{u}^{\,2}d\widetilde{u}
\bigg]
\nonumber \\
& \overset{a}{\geq} \;\;
\frac{1}{\text{vol}(A)}
\bigg[
\int_{A\,\cap\,B}\widetilde{u}^{\,2}d\widetilde{u}
\, +
\int_{A{\mathstrut}^{c}\,\cap\,B}t^{\,2}dt
\bigg]
\nonumber \\
& = \;\;
\frac{1}{\text{vol}(A)}
\int_{B}t^{\,2}d t,
\label{eqCentered}
\end{align}
where for ($a$) we use the interval set $B \, \triangleq \, \big[-\!\text{vol}(A)/2, \; \text{vol}(A)/2 \,\big]$,
centered around zero and of the same total length as $A$
with the resulting property that $\text{vol}(A\cap B{\mathstrut}^{c}) = \text{vol}(A{\mathstrut}^{c}\cap B)$,
%\begin{align}
%\text{vol}(A\cap B) \, + \, \text{vol}(A\cap B{\mathstrut}^{c})
%\;\; = \;\;
%\text{vol}(A)
%\;\; & = \;\;
%\text{vol}(B)
%\;\; = \;\;
%\text{vol}(A\cap B) \, + \, \text{vol}(A{\mathstrut}^{c}\cap B),
%\nonumber \\
%\text{vol}(A\cap B{\mathstrut}^{c})
%\;\; & = \;\;
%\text{vol}(A{\mathstrut}^{c}\cap B),
%\nonumber
%\end{align}
so that
\begin{displaymath}
\int_{A\,\cap\,B{\mathstrut}^{c}}\widetilde{u}^{\,2}d\widetilde{u}
\;\; \geq \;\;
\frac{(\text{vol}(A))^{2}}{4}\int_{A\,\cap\,B{\mathstrut}^{c}}d\widetilde{u}
\;\; = \;\;
\frac{(\text{vol}(A))^{2}}{4}\int_{A{\mathstrut}^{c}\,\cap\,B}dt
\;\; \geq \;\;
\int_{A{\mathstrut}^{c}\,\cap\,B}t^{\,2}dt.
\end{displaymath}
Integrating on the RHS of (\ref{eqCentered}), we obtain
\begin{align}
\frac{(\text{vol}(A))^{2}}{12}
\;\; = \;\;
\frac{(|\, {\cal S}({P\mathstrut}_{\!X}) \,|\cdot \Delta_{\alpha,\,n})^{2}}{12}
\;\; & \leq \;\;
\frac{n}{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}c_{X}
\, + \,
\frac{\Delta_{\alpha,\,n}^{2}}{12},
\nonumber \\
%\frac{(|\, {\cal S}({P\mathstrut}_{\!X}) \,|\cdot \Delta_{x,\,n})^{2}}{12}
%\;\; & \leq \;\;
%\frac{n}{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}c_{X}
%\, + \,
%\frac{\Delta_{x,\,n}^{2}}{12}
%\nonumber \\
|\, {\cal S}({P\mathstrut}_{\!X}) \,|^{\,3}
\;\; & \leq \;\;
12c_{X}n\Delta_{\alpha,\,n}^{-2} \, + \, |\, {\cal S}({P\mathstrut}_{\!X}) \,|
\nonumber \\
%|\, {\cal S}({P\mathstrut}_{\!X}) \,|^{\,3}
& = \;\;
12c_{X}n^{1\,+\,2\alpha} \, + \, \underbrace{|\, {\cal S}({P\mathstrut}_{\!X}) \,|}_{\leq \; n}
%\nonumber \\
%|\, {\cal S}({P\mathstrut}_{\!X}) \,|^{\,3}
%&
\;\; \leq \;\;
(12c_{X} + 1)n^{1\,+\,2\alpha}.
\nonumber
\end{align}
%\end{proof}
$\square$



%\bigskip

%\newpage

\section*{Appendix B}\label{AppendixB}

%\bigskip

\subsection*{Proof of Lemma~\ref{LemQuant}:}
%{\em Proof of Lemma~\ref{LemQuant}:}

%\bigskip

%\begin{proof}
Using ${P\mathstrut}_{\!X}$ and ${p\mathstrut}_{Y|X}$, it is convenient to define a joint probability density function over $\mathbb{R}^{2}$ as
\begin{align}
{p\mathstrut}_{XY}(x, y) \;\; & \triangleq \;\;
\frac{{P\mathstrut}_{\!X}(i\Delta_{\alpha,\,n})}{\Delta_{\alpha,\,n}}
{p\mathstrut}_{Y|X}(y\,|\,i\Delta_{\alpha,\,n}),
\nonumber \\
& \;\;\;\;\;\;\;\;\;\;\;\;\;
\forall x \in \big[(i - 1/2)\Delta_{\alpha,\,n}, \;  (i + 1/2)\Delta_{\alpha,\,n}\big),
\;\forall i \in \mathbb{Z}, \;\forall y \in \mathbb{R},
\label{eqJointPDF}
\end{align}
which is changing only stepwise in $x$-direction.
Note that ${p\mathstrut}_{Y}$ %from
of (\ref{eqMargEntropy}) is the $y$-marginal of ${p\mathstrut}_{XY}$.
This gives

\begin{equation} \label{eqJPDFVariance}
\mathbb{E}_{{p\mathstrut}_{XY}}\!\big[X^{2}\big]  \; = \; \mathbb{E}_{{P\mathstrut}_{\!X}}\!\big[X^{2}\big]
\, + \,
\frac{\Delta_{\alpha,\,n}^{2}}{12},
\;\;\;\;\;\;
\mathbb{E}_{{p\mathstrut}_{XY}}\!\big[Y^{2}\big] \; = \;
\mathbb{E}_{{P\mathstrut}_{\!X}{p\mathstrut}_{Y|X}}\!\big[Y^{2}\big].
\end{equation}
We proceed in two stages. First we quantize ${p\mathstrut}_{XY}(x, y)$ by rounding it {\em down} and check
the effect of this on the LHS of (\ref{eqCondEntropy})-(\ref{eqMargEntropy}).
Then we complement the total probability back to $1$, so that the type ${P\mathstrut}_{\!X}$ is conserved,
and check the effect of this on the RHS of (\ref{eqCondEntropy})-(\ref{eqMargEntropy}).

The quantization of ${p\mathstrut}_{XY}(x, y)$ is done by first replacing it with its infimum in each
rectangle $$\big[(i-1/2)\Delta_{\alpha,\,n}, \; (i+1/2)\Delta_{\alpha,\,n}\big) \; \times \;
\big[(j-1/2)\Delta_{\beta,\,n}, \; (j+1/2)\Delta_{\beta,\,n}\big):$$
\begin{align}
{p\mathstrut}_{XY}^{\inf}(x, y)
\;\; & \triangleq \;\;
\inf_{(j \, - \, 1/2)\Delta_{\beta,\,n} \; \leq \; \tilde{y} \; < \; (j \, + \, 1/2)\Delta_{\beta,\,n}}
{p\mathstrut}_{XY}(x, \tilde{y})
,
\nonumber \\
&
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\forall y \in \big[(j - 1/2)\Delta_{\beta,\,n}, \;  (j + 1/2)\Delta_{\beta,\,n}\big),
\;\forall j \in \mathbb{Z}, \;\forall x \in \mathbb{R},
\label{eqInf}
\end{align}
and then quantizing this infimum
down
to the nearest value $k\Delta_{\gamma,\,n}$, $k = 0, 1, 2, .\,.\,.\,$:  %, not above it:
\begin{align}
{p\mathstrut}_{XY}^{q}(x, y)
\;\; & \triangleq \;\;
\left\lfloor
{p\mathstrut}_{XY}^{\inf}(x, y)/\Delta_{\gamma,\,n}\right\rfloor\cdot\Delta_{\gamma,\,n},
\;\;\;\;\;\;
\forall (x, y) \in \mathbb{R}^{2}.
\label{eqQuantized}
\end{align}
%\begin{align}
%{p\mathstrut}_{XY}^{q}(x, y)
%\;\; & \triangleq \;\;
%\left\lfloor \inf_{(j \, - \, 1/2)\Delta_{y,\,n} \; \leq \; \tilde{y} \; < \; (j \, + \, 1/2)\Delta_{y,\,n}}
%\frac{{p\mathstrut}_{XY}(x, \tilde{y})}{\Delta_{z,\,n}}\right\rfloor\cdot\Delta_{z,\,n},
%\nonumber \\
%&
%\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
%\forall y \in \big[(j - 1/2)\Delta_{y,\,n}, \;  (j + 1/2)\Delta_{y,\,n}\big),
%\;\forall j \in \mathbb{Z}, \;\forall x \in \mathbb{R}.
%\nonumber
%\end{align}
Due to (\ref{eqCube}), the integral of ${p\mathstrut}_{XY}^{q}$ over $\mathbb{R}^{2}$ can be smaller than $1$ only by an integer %number
multiple
of $1/n$.
The resulting difference from ${p\mathstrut}_{XY}(x, y)$ at each point $(x, y) \in \mathbb{R}^{2}$ can be bounded %accordingly
by a sum of two terms as
\begin{align}
0 \;\; \leq \;\;
{p\mathstrut}_{XY}(x, y) \, - \, {p\mathstrut}_{XY}^{q}(x, y)
\;\; & \leq \;\;
\underbrace{(K/\Delta_{\alpha,\,n})\cdot\Delta_{\beta,\,n}}_{\text{minimization}} \; + \!\!
\underbrace{\Delta_{\gamma,\,n}}_{\text{quantization}}
\nonumber \\
& = \;\;
K n^{\alpha \, - \, \beta}
\, + \, n^{\alpha \, + \, \beta \, - \, 1}
%\nonumber \\
%&
\;\; \leq \;\;
(K + 1)n^{-\delta}
\;\; \triangleq \;\; h,
%\;\;\; \delta \triangleq \min\{\beta, 1-\beta\} - \alpha.
\label{eqDifference}
\end{align}
where $\delta \,\triangleq\, \min\,\{\beta, \, 1-\beta\} \, - \, \alpha$ and $K$ is the parameter from (\ref{eqLipschitz}).

For (\ref{eqMargEntropy}) we will require the $y$-marginal of ${p\mathstrut}_{XY}^{q}$ from (\ref{eqQuantized}), defined in the usual manner:
\begin{align}
{p\mathstrut}_{Y}^{q}(y) \;\; \triangleq \;\;
\int_{\mathbb{R}}{p\mathstrut}_{XY}^{q}(x, y)dx
\;\; & \overset{a}{=} \;\;
\sum_{x\,\in\, {\cal S}({P\mathstrut}_{\!X})}{p\mathstrut}_{XY}^{q}(x, y)\Delta_{\alpha,\,n}
\;\; \overset{b}{\geq} \;\;
\sum_{x\,\in\, {\cal S}({P\mathstrut}_{\!X})}({p\mathstrut}_{XY}(x, y) - h)\Delta_{\alpha,\,n}
\label{eqMargUsual} \\
& = \;\;
\sum_{x\,\in\, {\cal S}({P\mathstrut}_{\!X})}{p\mathstrut}_{XY}(x, y)\Delta_{\alpha,\,n} \; - \; h\sum_{x\,\in\, {\cal S}({P\mathstrut}_{\!X})}\Delta_{\alpha,\,n}
\nonumber \\
& = \;\; {p\mathstrut}_{Y}(y) \; - \; h \,\,|\, {\cal S}({P\mathstrut}_{\!X}) \,|\,\,\Delta_{\alpha,\,n},
\;\;\;\;\;\; \forall y \in \mathbb{R},
\nonumber
\end{align}
where
%\begin{displaymath}
%A_{x} \;\; \triangleq \;\; \bigcup_{x \, \in \, {\cal S}({P\mathstrut}_{\!X})}
%\big\{
%x + [-\Delta_{x,\,n}/2, \, \Delta_{x,\,n}/2)
%\big\}
%\end{displaymath}
%is the set of all $x \in \mathbb{R}$ for which there exist
%$y \in \mathbb{R}$
%such that
%${p\mathstrut}_{XY}(x, y) > 0$,
%encountered also in (\ref{eqContSupp}),
the equality
($a$) follows from (\ref{eqJointPDF}), (\ref{eqInf}), (\ref{eqQuantized}),
%$0 \leq {p\mathstrut}_{XY}^{q}(x, y)\leq {p\mathstrut}_{XY}(x, y)$,
and the inequality ($b$) follows by (\ref{eqDifference}).
Then
\begin{align}
0 \;\; \leq \;\;
{p\mathstrut}_{Y}(y) \, - \, {p\mathstrut}_{Y}^{q}(y)
\;\; & \leq \;\;
h \,\,|\, {\cal S}({P\mathstrut}_{\!X}) \,|\,\,\Delta_{\alpha,\,n}
%\nonumber \\
\;\; \leq \;\;
(K + 1)(12c_{X} + 1)^{1/3}n^{-\delta_{1}} \;\; \triangleq \;\; \widetilde{h},
\label{eqYDifference}
\end{align}
where the last inequality follows by Lemma~\ref{LemSupportX}, (\ref{eqDifference}), (\ref{eqDelta}),
with $\delta_{1} \,\triangleq\, \min\,\{\beta, \, 1-\beta\} \, - \, (1 + 2\alpha)/3$.
Note that the previously defined $\delta > \delta_{1}$, %of (\ref{eqDifference}) and $\delta_{y}$ of (\ref{eqYDifference})
while $\delta_{1} > 0$ if and only if $\alpha \in \big(0, \tfrac{1}{4}\big)$ and
$\tfrac{1}{3} + \tfrac{2}{3}\alpha < \beta < \tfrac{2}{3} - \tfrac{2}{3}\alpha$.


\bigskip

{\em The LHS of (\ref{eqCondEntropy})}

%\bigskip



Now %we examine
consider
the LHS of (\ref{eqCondEntropy}).
Note that each function ${p\mathstrut}_{Y|X}(\,\cdot\,|\,x)$ in (\ref{eqCondEntropy})
%has a maximum value and
is bounded and has
a finite variance. It follows that it has %also
a finite
differential entropy.
With (\ref{eqJointPDF}) we can rewrite the LHS of (\ref{eqCondEntropy}) as
\begin{align}
\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y|X}(y\,|\,x)dy
\;\; = \;\; &
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
\nonumber \\
&
- \sum_{x\,\in\,{\cal X}_{n}}
{P\mathstrut}_{\!X}(x){\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!X}(x)}{\Delta_{\alpha,\,n}}.
\label{eqCondEntIdeal}
\end{align}
Let us examine the possible increase in (\ref{eqCondEntIdeal})
when ${p\mathstrut}_{XY}$ is replaced with ${p\mathstrut}_{XY}^{q}$ defined by (\ref{eqInf})-(\ref{eqQuantized}).
%With respect to the parameter $h$ of (\ref{eqDifference}), let us define a set in $\mathbb{R}^{2}$:
For this, let us define a set in $\mathbb{R}^{2}$ with respect to the parameter $h$ of (\ref{eqDifference}):
\begin{align}
A \;\; & \triangleq \;\;
\big\{
(x, y): \;\; {p\mathstrut}_{XY}(x, y) > h
\big\},
\label{eqCountableUnion}
\end{align}
which is a countable union of disjoint rectangles
by the definition of ${p\mathstrut}_{XY}$ in (\ref{eqJointPDF}). Then
\begin{align}
&
\;\;\;\;
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
\, - \,
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
\nonumber \\
%\leq
=  &
\;\;
\bigg[\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
\, - \,
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
\bigg]
\nonumber \\
&
+
%\bigg[
\int\!\!\!\!\int_{A}
\big[\,{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)%dxdy
\, - \,
%\int\!\!\!\!\int_{A}
{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)\big]
\, dxdy.
%\bigg].
\label{eqByParts}
\end{align}
%Consider the first term in (\ref{eqByParts}).
Note that the minimum of the function $f(t) = t\,{\log\mathstrut}_{\!b} \,t$ occurs at $t = 1/e$.
Then for $h \leq 1/e$
we have ${p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y) \, \leq \, {p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y) \, \leq \, 0$
for all $(x, y) \in A{\mathstrut}^{c}$
and the first of the two terms in (\ref{eqByParts}) is upper-bounded as
\begin{align}
&
\;\;\,\,\,
%\left|\,
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
\, - \,
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
%\,\right|
\label{eqLocalEntropy} \\
\overset{h\, \leq \, 1/e}{\leq} \;\; &
-\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
%\nonumber \\
\;\; \overset{(*)}{=} \;\;
-p
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{c}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{c}(x, y)dxdy
\, - \,
p\,{\log\mathstrut}_{\!b}\,p,
\nonumber
\end{align}
where the equality ($*$) is appropriate
for the case when the upper bound is positive, %not zero,
with the definitions:
\begin{align}
p \;\; & \triangleq \;\;
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)dxdy,
\label{eqP} \\
{p\mathstrut}_{XY}^{c}(x, y)
\;\; & \triangleq \;\;
%\left\{
\Bigg\{
\begin{array}{r r}
{p\mathstrut}_{XY}(x, y)/p, & (x, y) \in  A{\mathstrut}^{c}, \\
0, & \text{o.w.}
\end{array}
%\right.
\nonumber
\end{align}
Next we upper-bound the entropy of the probability density function ${p\mathstrut}_{XY}^{c}$ on the RHS of (\ref{eqLocalEntropy})
by that of %the
a Gaussian PDF.
By (\ref{eqJPDFVariance}) we have

\begin{align}
&
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
c_{X} \, + \, 1/12 \, + \, c_{Y}
\, \geq \,
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)(x^{2} + y^{2})dxdy
\, = \,
p\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{c}(x, y)(x^{2} + y^{2})dxdy,
\label{eqPartialMoment} \\
&
\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,
(c_{X} \, + \, 1/12 \, + \, c_{Y})/p
\, \geq \,
\int_{\mathbb{R}}{p\mathstrut}_{X}^{c}(x)x^{2}dx
\, + \,
\int_{\mathbb{R}}{p\mathstrut}_{Y}^{c}(y)y^{2}dy,
\nonumber \\
&
{\log\mathstrut}_{\!b}\,\big(2\pi e(c_{X} \, + \, 1/12 \, + \, c_{Y})/p\big)
\, \geq \,
-\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{c}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{c}(x, y)dxdy.
\nonumber
\end{align}
So we can rewrite the bound of (\ref{eqLocalEntropy}) in terms of $p$ defined by (\ref{eqP}):
\begin{align}
&
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
\, - \,
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
\nonumber \\
\overset{h\, \leq \, 1/e}{\leq} \;\; &
-2p\,{\log\mathstrut}_{\!b}\,p
\, + \, p\,{\log\mathstrut}_{\!b}\,\big(2\pi e(c_{X} + c_{Y} + 1/12)\big).
\label{eqLocalp}
\end{align}
From (\ref{eqP}) and (\ref{eqCountableUnion}) it is clear that $p \rightarrow 0$ as $h \rightarrow 0$.
In order to relate between them, let us rewrite the inequality in (\ref{eqPartialMoment})
again as
\begin{align}
& c_{X} \, + \, 1/12 \, + \, c_{Y}
\;\; \geq \;\;
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)(x^{2} + y^{2})dxdy
\nonumber \\
%\overset{a}{=}
= \;\; &
\int\!\!\!\!\int_{B{\mathstrut}_{1}}h\cdot(x^{2} + y^{2})dxdy
\; + \;
\int\!\!\!\!\int_{A{\mathstrut}^{c}\,\cap\,B{\mathstrut}^{c}_{1}}{p\mathstrut}_{XY}(x, y)(x^{2} + y^{2})dxdy
\; - \;
\int\!\!\!\!\int_{A\,\cap\,B{\mathstrut}_{1}}h\cdot(x^{2} + y^{2})dxdy
\nonumber \\
&
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
-\int\!\!\!\!\int_{A{\mathstrut}^{c}\,\cap\,B{\mathstrut}_{1}}\big(h - {p\mathstrut}_{XY}(x, y)\big)(x^{2} + y^{2})dxdy
\nonumber \\
%\overset{b}{\geq}
\geq \;\; &
\int\!\!\!\!\int_{B{\mathstrut}_{1}}h\cdot(x^{2} + y^{2})dxdy
\; + \;
\frac{p}{h\pi}\int\!\!\!\!\int_{A{\mathstrut}^{c}\,\cap\,B{\mathstrut}^{c}_{1}}{p\mathstrut}_{XY}(x, y)dxdy
\; - \;
\frac{p}{h\pi}\int\!\!\!\!\int_{A\,\cap\,B{\mathstrut}_{1}}hdxdy
\nonumber \\
&
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,
-\frac{p}{h\pi}\int\!\!\!\!\int_{A{\mathstrut}^{c}\,\cap\,B{\mathstrut}_{1}}\big(h - {p\mathstrut}_{XY}(x, y)\big)dxdy
\nonumber \\
= \;\; &
\int\!\!\!\!\int_{B{\mathstrut}_{1}}h\cdot(x^{2} + y^{2})dxdy \;\; = \;\; \frac{p^{2}}{2\pi h},
\nonumber
\end{align}
where %the equality ($a$) can be written with any bounded set $B{\mathstrut}_{1} \subset \mathbb{R}^{2}$ with finite area, while
%for the inequality ($b$)
we use the disk set $B{\mathstrut}_{1} \triangleq \big\{ (x, y): \; h\pi(x^{2} + y^{2}) \, \leq \, p\big\}$,
centered around zero.
%\begin{align}
%B{\mathstrut}_{1} \;\; & \triangleq \;\;
%\big\{
%(x, y): \; h\pi(x^{2} + y^{2}) \, \leq \, p
%\big\},
%\nonumber \\
%p_{1 %B{\mathstrut}^{c}
%} \;\; & \triangleq \;\;
%\int\!\!\!\!\int_{A{\mathstrut}^{c}\,\cap\,B{\mathstrut}^{c}_{1}}{p\mathstrut}_{XY}(x, y)dxdy,
%\nonumber \\
%{p\mathstrut}_{XY}^{a %B{\mathstrut}^{c}
%}(x, y)
%\;\; & \triangleq \;\;
%\left\{
%\begin{array}{r r}
%{p\mathstrut}_{XY}(x, y)/p_{1}, & \;\;\;(x, y) \in  A{\mathstrut}^{c}\cap B{\mathstrut}^{c}_{1}, \\
%0, & \;\;\;\text{o.w.},
%\end{array}
%\right.
%\nonumber \\
%{p\mathstrut}_{XY}^{b %B
%}(x, y)
%\;\; & \triangleq \;\;
%\left\{
%\begin{array}{r r}
%(h - {p\mathstrut}_{XY}(x, y))/p_{1}, & \;\;\;(x, y) \in  A{\mathstrut}^{c}\cap B{\mathstrut}_{1}, \\
%h/p_{1}, & \;\;\;(x, y) \in  A\cap B{\mathstrut}_{1}, \\
%0, & \;\;\;\text{o.w.},
%\end{array}
%\right.
%\nonumber
%\end{align}
%provided that $p_{1} > 0$.
This results in the following upper bound on $p$ in terms of $h$:
\begin{equation} \label{eqHP}
c_{1} h^{1/2}
%\sqrt{h}
%\sqrt{2\pi(c_{X} + c_{Y} + 1/12)}
\;\; \geq \;\; p,
\end{equation}
where $c_{1} \triangleq \sqrt{2\pi(c_{X} + c_{Y} + 1/12)}$.
Substituting the LHS of (\ref{eqHP}) in (\ref{eqLocalp})
in place of $p$, we obtain the following upper bound on
the first half %term %of the two terms
of (\ref{eqByParts}) in terms of $h$
of (\ref{eqDifference}), (\ref{eqCountableUnion}):
\begin{align}
&
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
\, - \,
\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
\nonumber \\
\leq \;\; &
c_{1}
h^{1/2}
%\sqrt{h}
%\sqrt{2\pi(c_{X} + c_{Y} + 1/12)}
\,{\log\mathstrut}_{\!b}\,(e/h),
\;\;\;\;\;\;
h \,\leq \,
%\frac{1}{2\pi(c_{X} + c_{Y} + 1/12)e^{2}},
1/(c_{1}e)^{2}.
\label{eqFirstTerm}
\end{align}

%To bound the second term in (\ref{eqByParts}), we can write
%\begin{align}
%&
%%\left|\,
%\int\!\!\!\!\int_{A}{p\mathstrut}_{XY}^{q}(x, y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
%\, - \,
%\int\!\!\!\!\int_{A}{p\mathstrut}_{XY}(x, y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
%%\,\right|
%\nonumber \\
%%\leq
%= \;\; &
%\int\!\!\!\!\int_{A}
%\big[\,
%{p\mathstrut}_{XY}^{q}(x, y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)
%\, - \,
%{p\mathstrut}_{XY}(x, y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)
%\big]\,
%dxdy.
%\nonumber
%\end{align}
In the second term of (\ref{eqByParts})
for $(x, y) \in A$ the integrand can be upper-bounded by Lemma~\ref{Lemxlogx} with its parameters $t$ and $t_{1}$ such that
\begin{align}
t_{1} \; = \; {p\mathstrut}_{XY}^{q}(x, y)
\; & \leq \; {p\mathstrut}_{XY}(x, y) \; = \; t_{1} + t,
\;\;\;\;\;\;\;\;\;
t \, \leq \, h \, \leq \, 1/e.
%\nonumber \\
%t_{1} + t \;\; & = \;\; {p\mathstrut}_{XY}(x, y)
%\;\; \leq \;\; \sup_{(x, \, y)\, \in \, \mathbb{R}^{2}}{p\mathstrut}_{XY}(x, y)
%\;\; \leq \;\; \sqrt{K}/\Delta_{\alpha, \, n}
%\;\; = \;\; \sqrt{K} (K + 1)^{\alpha/\delta}h^{-\alpha/\delta},
%\nonumber \\
%t \; & \leq \; h \; \leq \; 1/e.
\nonumber
\end{align}
%where $K$, $\Delta_{\alpha, \, n}$, and $h$ with $\delta$ can be found in (\ref{eqLipschitz}), (\ref{eqDelta}), and
%(\ref{eqDifference}), respectively.
This gives
\begin{align}
&
%\left|\,
\int\!\!\!\!\int_{A}
\big[\,{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)%dxdy
\, - \,
%\int\!\!\!\!\int_{A}
{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)\big]
\,
dxdy
%\,\right|
\nonumber \\
%\overset{h\, \leq \, 1/e}{\leq}
\;\; %&
\leq
\;\; &
\text{vol}(A)\,
h\,%\cdot
{\log\mathstrut}_{\!b}\,(1/h),
%\max
%\big\{
%{\log\mathstrut}_{\!b}\,(1/h),
%\;
%(\alpha/\delta)%\cdot
%{\log\mathstrut}_{\!b} (c_{2}/h)
%\big\},
\;\;\;\;\;\; h \, \leq \, 1/e,
\label{eqVolh}
\end{align}
where
%$c_{2} \triangleq (K + 1)(e\sqrt{K})^{\delta/\alpha}$ and
$\text{vol}(A)$ is the total area of $A$.
To find an upper bound on $\text{vol}(A)$, we use (\ref{eqJPDFVariance}):
\begin{align}
c_{X} \, + \, 1/12 \, + \, c_{Y}
\;\; & \geq \;\;
\int\!\!\!\!\int_{A}{p\mathstrut}_{XY}(x, y)(x^{2} + y^{2})dxdy
%\nonumber \\
\;\; \geq \;\;
\int\!\!\!\!\int_{A}h \cdot(x^{2} + y^{2})dxdy
\nonumber \\
& = \;\;
h\left[
\int\!\!\!\!\int_{A\,\cap\,B{\mathstrut}_{2}}(x^{2} + y^{2})dxdy
\, +
\int\!\!\!\!\int_{A\,\cap\,B{\mathstrut}^{c}_{2}}(x^{2} + y^{2})dxdy
\right]
\nonumber \\
& \overset{a}{\geq} \;\;
h\left[
\int\!\!\!\!\int_{A\,\cap\,B{\mathstrut}_{2}}(x^{2} + y^{2})dxdy
\, +
\int\!\!\!\!\int_{A{\mathstrut}^{c}\,\cap\,B{\mathstrut}_{2}}(x^{2} + y^{2})dxdy
\right]
\nonumber \\
& = \;\;
\int\!\!\!\!\int_{B{\mathstrut}_{2}}h \cdot(x^{2} + y^{2})dxdy
\;\; = \;\;
\frac{h}{2\pi}(\text{vol}(A))^{2},
\nonumber
\end{align}
where in ($a$) we use the disk set
$B{\mathstrut}_{2} \, \triangleq \, \big\{(x, y): \; \pi(x^{2} + y^{2}) \, \leq \, \text{vol}(A)\big\}$,
centered around zero,
of the same total area as $A$, and the resulting property that
$\text{vol}(A{\mathstrut}^{c}\cap B{\mathstrut}_{2}) = \text{vol}(A\cap B{\mathstrut}^{c}_{2})$.
So that
\begin{equation} \label{eqVol}
c_{1}h^{-1/2}
\;\; \geq \;\;
\text{vol}(A).
%\sqrt{2\pi(c_{X} + c_{Y} + 1/12)}.
\end{equation}
Continuing (\ref{eqVolh}), therefore we obtain the following
upper bound on the second term in (\ref{eqByParts}):
%, in terms of $h$
%of (\ref{eqDifference}), (\ref{eqCountableUnion}):
\begin{align}
%&
%\left|\,
\int\!\!\!\!\int_{A}
\big[\,{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)%dxdy
\, - \,
%\int\!\!\!\!\int_{A}
{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)
\big]
%\,
dxdy
%\,\right|
%\nonumber \\
%\overset{h\, \leq \, 1/e}{\leq}
\;
& \leq
\; %&
c_{1}
h^{1/2}\,
{\log\mathstrut}_{\!b}\,(1/h),
%\max
%\big\{
%{\log\mathstrut}_{\!b}\,(1/h),
%\;
%(\alpha/\delta)%\cdot
%{\log\mathstrut}_{\!b} (c_{2}/h)
%\big\},
\;\;\; h \leq 1/e.
\label{eqSecondTerm}
\end{align}
Putting (\ref{eqByParts}), (\ref{eqFirstTerm}) and (\ref{eqSecondTerm}) together:
\begin{align}
&
%\left|\,
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy
\, - \,
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}(x, y)dxdy
%\,\right|
\nonumber \\
\leq \;\; &
2c_{1}
h^{1/2}
\,{\log\mathstrut}_{\!b} (\sqrt{e}/h),
%\Big[
%{\log\mathstrut}_{\!b} (e/h)
%\, + \,
%\max
%\big\{
%{\log\mathstrut}_{\!b}\,(1/h),
%\;
%(\alpha/\delta)%\cdot
%{\log\mathstrut}_{\!b} (c_{2}/h)
%\big\}
%\Big],
\;\;\;\;\;\; h \, \leq \, 1/(c_{1}e)^{2},
\label{eqPutting}
\end{align}
where $c_{1}$ %, %$c_{2}$,
and $h$ are such as in (\ref{eqHP}) %, %(\ref{eqFirstTerm})
%(\ref{eqVolh}),
and (\ref{eqDifference}), respectively.
So that if $\delta > 0$ in (\ref{eqDifference}), then the %difference
possible increase in (\ref{eqCondEntIdeal})
caused by substitution of ${p\mathstrut}_{XY}^{q}$ in place of ${p\mathstrut}_{XY}$ is at most $o(1)$.

Later on, for the RHS of (\ref{eqCondEntropy})-(\ref{eqMargEntropy}) we will require also
the loss in the total probability incurred in the replacement of ${p\mathstrut}_{XY}$ by ${p\mathstrut}_{XY}^{q}$.
This loss is strictly positive and tends to zero with $h$ of (\ref{eqDifference}): %, and can be bounded as follows:

\begin{align}
0 \;\; < \;\; p_{1} \;\; & \triangleq \;\;
\underbrace{\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}(x, y)dxdy}_{= \; 1} \; - \;
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{q}(x, y)dxdy
\nonumber \\
& \overset{a}{\leq} \;\;
\underbrace{\int\!\!\!\!\int_{A{\mathstrut}^{c}}{p\mathstrut}_{XY}(x, y)dxdy}_{= \; p} \; + \;
\int\!\!\!\!\int_{A}\underbrace{\big({p\mathstrut}_{XY}(x, y) - {p\mathstrut}_{XY}^{q}(x, y)\big)}_{\leq \; h}dxdy
\nonumber \\
& \overset{b}{\leq} \;\;
p \, + \, h\cdot\text{vol}(A) \;\; \overset{c}{\leq} \;\;
c_{1}h^{1/2} \, + \, c_{1}h^{1/2} \;\; = \;\; 2c_{1}h^{1/2},
\label{eqProbLoss}
\end{align}
where the set $A$ in ($a$) is defined in (\ref{eqCountableUnion}),
($b$) follows by (\ref{eqP}) and (\ref{eqDifference}),
and ($c$) follows by (\ref{eqHP}), %and
(\ref{eqVol}).



\bigskip

%{\em Marginal PDF ${p\mathstrut}_{Y}$}

{\em The LHS of (\ref{eqMargEntropy})}

%\bigskip

Consider next the LHS of (\ref{eqMargEntropy}). Since ${p\mathstrut}_{Y} \in {\cal L}$
and has a finite variance, its differential entropy is finite.
Let us examine the possible decrease in the LHS of (\ref{eqMargEntropy})
when ${p\mathstrut}_{Y}$ is replaced with ${p\mathstrut}_{Y}^{q}$ defined in (\ref{eqMargUsual}).
%With respect to the parameter $\widetilde{h}$ of (\ref{eqYDifference}), let us define a set in $\mathbb{R}$:
For this, let us define a set in $\mathbb{R}$ with respect to the parameter $\widetilde{h}$ of (\ref{eqYDifference}):
\begin{align}
\widetilde{A} \;\; & \triangleq \;\;
\big\{
y: \;\; {p\mathstrut}_{Y}(y) > \widetilde{h}
\big\},
\label{eqCountableUnion2}
\end{align}
which is a countable union of disjoint open intervals. Then
\begin{align}
&
%\left|\,
\int_{\mathbb{R}}{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)dy
\, - \,
\int_{\mathbb{R}}{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)dy
%\,\right|
\nonumber \\
%\leq
= \; &
%\left|\,
%\bigg[
\int_{\widetilde{A}{\mathstrut}^{c}}
\big[\,{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)%dy
\, - \,
%\int_{\widetilde{A}{\mathstrut}^{c}}
{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)
\big]
\,dy
%\bigg]
%\,\right|
%\nonumber \\
\; + \, %&
%\left|\,
%\bigg[
\int_{\widetilde{A}}
\big[\,
{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)%dy
\, - \,
%\int_{\widetilde{A}}
{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)
\big]
\,dy.
%\bigg].
%\,\right|.
\label{eqByParts2}
\end{align}
%As before,
For $\widetilde{h} \leq 1/e$
we have ${p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y) \, \leq \, {p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y) \, \leq \, 0$
for all $y \in \widetilde{A}{\mathstrut}^{c}$
and the first of the two terms in (\ref{eqByParts2}) is non-positive:
%upper-bounded as
\begin{align}
&
%\;\;
%\left|\,
\int_{\widetilde{A}{\mathstrut}^{c}}
\big[\,
{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)%dy
\, - \,
%\int_{\widetilde{A}{\mathstrut}^{c}}
{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)
\big]
\,dy
%\,\right|
\;\; \leq \;\; 0.
\label{eqLocalEntropy2} %\\
%\overset{\widetilde{h}\, \leq \, 1/e}{\leq} \;\; &
%-\int_{\widetilde{A}{\mathstrut}^{c}}{p\mathstrut}_{Y}(y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)dy
%\nonumber \\
%\;\; \overset{(*)}{=} \;\;
%-\widetilde{p}
%\int_{\mathbb{R}}\widetilde{p}{\mathstrut}_{Y}^{\,c}(y)
%{\log\mathstrut}_{\!b}\,\widetilde{p}{\mathstrut}_{Y}^{\,c}(y)dy
%\, - \,
%\widetilde{p}\,{\log\mathstrut}_{\!b}\,\widetilde{p},
%\nonumber
\end{align}

In the second term of (\ref{eqByParts2})
for $y \in \widetilde{A}$ the integrand can be upper-bounded by Lemma~\ref{Lemxlogx} with its parameters $t$ and $t_{1}$ such that
\begin{align}
t_{1} \; & = \; {p\mathstrut}_{Y}^{q}(y)%,
%\nonumber \\
\; \leq \; t_{1} + t \; %&
= \; {p\mathstrut}_{Y}(y)
\; \leq \; \sup_{y\, \in \, \mathbb{R}}{p\mathstrut}_{Y}(y)
\; \leq \; \sqrt{K},
\;\;\;\;\;\;\;\;\;
%\nonumber \\
t \, %&
\leq \, \widetilde{h} \, \leq \, 1/e,
\nonumber
\end{align}
where $K$
is the parameter from (\ref{eqLipschitz}).
%and $\widetilde{h}$ can be found in (\ref{eqLipschitz}) and
%(\ref{eqYDifference}), respectively.
This gives
\begin{align}
%\left|\,
\int_{\widetilde{A}}
\big[\,
{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)%dy
\, - \,
%\int_{\widetilde{A}}
{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)
\big]
\,dy
%\,\right|
%\nonumber \\
\;\;
&
\overset{\widetilde{h}\, \leq \, 1/e}{\leq}
\;\;
%\leq
%&
\text{vol}(\widetilde{A})\,
\widetilde{h}\cdot
\max
\big\{
{\log\mathstrut}_{\!b}\,(1/\widetilde{h}),
\;
{\log\mathstrut}_{\!b} (e\sqrt{K})
\big\},
%\;\;\;\;\;\; \widetilde{h} \, \leq \, 1/e,
\label{eqVolh2}
\end{align}
where $\text{vol}(\widetilde{A})$ is the total length of $\widetilde{A}$.
It remains to find an upper bound on $\text{vol}(\widetilde{A})$. %for which
We use (\ref{eqJPDFVariance}):

\begin{align}
c_{Y}
\;\; \geq \;\;
\int_{\widetilde{A}}{p\mathstrut}_{Y}(y)y^{2}dy
%\nonumber \\
%&
\;\; %&
\geq \;\;
\int_{\widetilde{A}}\widetilde{h} \cdot y^{2}dy
%\nonumber \\
%&
\;\; & = \;\;
\widetilde{h}\left[
\int_{\widetilde{A}\,\cap\,\widetilde{B}{\mathstrut}_{2}}y^{2}dy
\, +
\int_{\widetilde{A}\,\cap\,\widetilde{B}{\mathstrut}^{c}_{2}}y^{2}dy
\right]
\nonumber \\
& \overset{a}{\geq} \;\;
\widetilde{h}\left[
\int_{\widetilde{A}\,\cap\,\widetilde{B}{\mathstrut}_{2}}y^{2}dy
\, +
\int_{\widetilde{A}{\mathstrut}^{c}\,\cap\,\widetilde{B}{\mathstrut}_{2}}y^{2}dy
\right]
\nonumber \\
& = \;\;
\int_{\widetilde{B}{\mathstrut}_{2}}\widetilde{h} \cdot y^{2}dy
\;\; = \;\;
\frac{\widetilde{h}}{12}(\text{vol}(\widetilde{A}))^{3},
\nonumber
\end{align}
where in ($a$) we use the interval set
$\widetilde{B}{\mathstrut}_{2} \, \triangleq \, \big[
-\!\text{vol}(\widetilde{A})/2, \;
\text{vol}(\widetilde{A})/2
\,\big]$, centered around zero, and
of the same total length as $\widetilde{A}$ with the resulting property that
$\text{vol}(\widetilde{A}{\mathstrut}^{c}\cap \widetilde{B}{\mathstrut}_{2}) = \text{vol}(\widetilde{A}\cap \widetilde{B}{\mathstrut}^{c}_{2})$.
So that
\begin{equation} \label{eqVol2}
\widetilde{c}_{1}\widetilde{h}^{-1/3}
\;\; \geq \;\;
\text{vol}(\widetilde{A}),
\end{equation}
where $\widetilde{c}_{1} \triangleq (12c_{Y})^{1/3}$.
Continuing (\ref{eqVolh2}), with (\ref{eqVol2}) we obtain the following
upper bound on the second term in (\ref{eqByParts2}), which is by (\ref{eqLocalEntropy2}) also
an upper bound
on both terms of (\ref{eqByParts2}):
%, in terms of $h$
%of (\ref{eqDifference}), (\ref{eqCountableUnion}):
\begin{align}
&
%\left|\,
\int_{\mathbb{R}}
%\big[\,
{p\mathstrut}_{Y}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)dy
\, - \,
\int_{\mathbb{R}}
{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)
%\big]
%\,
dy
%\,\right|
%\nonumber \\
\;\;
\overset{\widetilde{h}\, \leq \, 1/e}{\leq}
\;\;
%&
\widetilde{c}_{1}
\widetilde{h}^{2/3}
\max
\big\{
{\log\mathstrut}_{\!b}\,(1/\widetilde{h}),
\;
{\log\mathstrut}_{\!b} (e\sqrt{K})
\big\}.
%\;\;\;\;\;\; \widetilde{h} \, \leq \, 1/e.
\label{eqSecondTerm2}
\end{align}
%By (\ref{eqLocalEntropy2}) this is also an upper bound on (\ref{eqByParts2}) as a whole.
%Putting (\ref{eqByParts2}), (\ref{eqFirstTerm2}) and (\ref{eqSecondTerm2}) together:
%\begin{align}
%&
%\left|\,
%\int_{\mathbb{R}}{p\mathstrut}_{Y}(y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}(y)dy
%\, - \,
%\int_{\mathbb{R}}{p\mathstrut}_{Y}^{q}(y)
%{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)dy
%\,\right|
%\nonumber \\
%\leq \;\; &
%\widetilde{c}_{1}
%\widetilde{h}^{2/3}
%\Big[
%{\log\mathstrut}_{\!b} (\widetilde{c}_{2}/\widetilde{h})
%\, + \,
%\max
%\big\{
%{\log\mathstrut}_{\!b}\,(1/\widetilde{h}),
%\;
%{\log\mathstrut}_{\!b} (e\sqrt{K})
%\big\}
%\Big],
%\;\;\;\;\;\; \widetilde{h} \, \leq \, \min\big\{1/e, \; 1/(\widetilde{c}_{1}e)^{3/2}\big\},
%\nonumber
%\end{align}
%where $\widetilde{c}_{1}$, $\widetilde{c}_{2}$, and $\widetilde{h}$ are such as in (\ref{eqHP2}), %(\ref{eqFirstTerm})
%(\ref{eqFirstTerm2}), and (\ref{eqYDifference}), respectively.
So that if $\delta_{1} > 0$ in (\ref{eqYDifference}), then the possible decrease
caused by substitution of ${p\mathstrut}_{Y}^{q}$ in place of ${p\mathstrut}_{Y}$ on the LHS of (\ref{eqMargEntropy}) is at most $o(1)$.

\bigskip

{\em The LHS of (\ref{eqLogGaussian})}

%\bigskip

Let us define two functions of $y \in \mathbb{R}$:
\begin{equation} \label{eqRelationship}
Q_{\beta}(y) \; \triangleq \; \Delta_{\beta,\,n}\cdot\lfloor y/\Delta_{\beta,\,n} + 1/2\rfloor,
\;\;\;\;\;\;
r_{\beta}(y) \; \triangleq \; y \, - \, Q_{\beta}(y).
\end{equation}
%and let %$y_{d}(y) \triangleq j(y)\Delta_{\beta,\,n}$ and
%$r_{\beta}(y) \, \triangleq \, y - Q_{\beta}(y)$ be another function.
Then
with ${p\mathstrut}_{XY}^{q}$ defined in (\ref{eqQuantized}) we can obtain a lower bound for the expression on the LHS of (\ref{eqLogGaussian}):
\begin{align}
%&
%\sigma_{2}^{2}
%\; \triangleq \;
&
\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{p\mathstrut}_{XY}^{q}(x, y)
(y - x)^{2}
\;\; = \;\;
\Delta_{\alpha,\,n}
\sum_{x\,\in\,{\cal X}_{n}}
\int_{\mathbb{R}}
{p\mathstrut}_{XY}^{q}(x, y)
\big(y - x - r_{\beta}(y)\big)^{2}dy
\nonumber \\
%\leq \;\; &
%\Delta_{\alpha,\,n}
%\sum_{x\,\in\,{\cal X}_{n}}
%\int_{\mathbb{R}}
%{p\mathstrut}_{XY}^{q}(x, y)
%(y - x)^{2}dy
%\; + \;
%2\Delta_{\alpha,\,n}
%\sum_{x\,\in\,{\cal X}_{n}}
%\int_{\mathbb{R}}
%{p\mathstrut}_{XY}^{q}(x, y)
%|\, y - x \,| \,| r(y) | \, dy
%\nonumber \\
%& \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,
%+ \;
%\Delta_{\alpha,\,n}
%\sum_{x\,\in\,{\cal X}_{n}}
%\int_{\mathbb{R}}
%{p\mathstrut}_{XY}^{q}(x, y)
%r^{2}(y)dy
%\nonumber \\
\overset{a}{\leq} \;\; &
\Delta_{\alpha,\,n}
\sum_{x\,\in\,{\cal X}_{n}}
\int_{\mathbb{R}}
{p\mathstrut}_{XY}(x, y)
(y - x)^{2}dy
\; + \;
\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}^{2}
\sum_{x\,\in\,{\cal X}_{n}}
\int_{\mathbb{R}}
{p\mathstrut}_{XY}(x, y)dy
\nonumber \\
& \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\,\,\,
+ \;
\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}
\sum_{x\,\in\,{\cal X}_{n}}
\int_{\mathbb{R}}
{p\mathstrut}_{XY}(x, y)
| y - x | dy
\nonumber \\
%= \;\; &
%\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
%(y - x)^{2}dy
%\; + \;
%\Delta_{\beta,\,n}^{2}
%\; + \;
%\Delta_{\beta,\,n}
%\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
%|\, y - x \,| \, dy
%\nonumber \\
\overset{b}{\leq} \;\; &
\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
(y - x)^{2}dy
\; + \;
\Delta_{\beta,\,n}^{2}
\; + \;
\Delta_{\beta,\,n}
\bigg[
\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
(y - x)^{2} dy
\bigg]^{1/2}
\nonumber \\
\overset{c}{\leq} \;\; &
\sum_{x\,\in\,{\cal X}_{n}}{P\mathstrut}_{\!X}(x)\int_{\mathbb{R}}{p\mathstrut}_{Y|X}(y\,|\,x)
(y - x)^{2}dy
\; + \;
\underbrace{
\Delta_{\beta,\,n}^{2}
\; + \;
\Delta_{\beta,\,n}
\sqrt{c_{XY}}
}_{o(1)}
%\; \triangleq \; \sigma_{1}^{2}
,
\label{eqLHS}
\end{align}
where ($a$) follows because ${p\mathstrut}_{XY}^{q}(x, y)\leq {p\mathstrut}_{XY}(x, y)$
and $|\,r_{\beta}(y)\,|\,\leq\, \Delta_{\beta,\,n}/2$, ($b$) follows by (\ref{eqJointPDF}) and Jensen's inequality
for the concave ($\cap$) function $f(t) = \sqrt{t}$,
and ($c$) follows by the condition of the lemma.
%and the first term is the LHS of (\ref{eqLogGaussian}).

\bigskip

{\em Joint type ${P\mathstrut}_{\!XY}$}

%\bigskip

Let us define two mutually-complementary probability masses for each $(x, y) \in {\cal X}_{n} \times {\cal Y}_{n}$:
\begin{align}
{P\mathstrut}_{\!XY}^{q}(x, y) \;\; & \triangleq \;\;
{p\mathstrut}_{XY}^{q}(x, y)\Delta_{\alpha,\,n}\Delta_{\beta,\,n},
\label{eqPDFtoType} \\
{P\mathstrut}_{\!XY}^{a}(x, y) \;\; & \triangleq \;\;
%\left\{
\Bigg\{
\begin{array}{r r}
{P\mathstrut}_{\!X}(x) -
\sum_{\tilde{y}\,\in\,{\cal Y}_{n}}{P\mathstrut}_{\!XY}^{q}(x, \tilde{y}), & \;\;\;
y =  Q_{\beta}(x), \\
0, & \;\;\; \text{o.w.},
\end{array}
%\right.
\label{eqDiagonal} %\\
%d \;\; & \triangleq \;\; \sqrt{(\sigma_{1}^{2} - \sigma_{2}^{2})/p_{1}},
%\label{eqD}
\end{align}
where $Q_{\beta}(\cdot)$ is defined in (\ref{eqRelationship}).
%and $d$ is some constant to be determined later.
%\begin{equation} \label{eqD}
%d \;\; \triangleq \;\; \sqrt{(\sigma_{1}^{2} - \sigma_{2}^{2})/p_{1}},
%\end{equation}
%with
%and $p_{1} > 0$, $\sigma_{1}^{2} \geq \sigma_{2}^{2}$ are defined in (\ref{eqProbLoss}), (\ref{eqLHS}), respectively.
It follows from %the definition
(\ref{eqQuantized}) and (\ref{eqCube}),
that each number ${P\mathstrut}_{\!XY}^{q}(x, y)$
is an integer multiple of $1/n$
and $\sum_{y\,\in\,{\cal Y}_{n}}{P\mathstrut}_{\!XY}^{q}(x, y) \leq {P\mathstrut}_{\!X}(x)$
for each $x \in {\cal X}_{n}$.
Then a joint type can be formed with the two definitions above:
\begin{equation} \label{eqJointType}
{P\mathstrut}_{\!XY}(x, y) \;\; \triangleq \;\; {P\mathstrut}_{\!XY}^{q}(x, y) \, + \, {P\mathstrut}_{\!XY}^{a}(x, y),
\;\;\;\;\;\; \forall (x, y) \in {\cal X}_{n}\times {\cal Y}_{n},
\end{equation}
such that ${P\mathstrut}_{\!XY} \in {\cal P}_{n}({\cal X}_{n}\times {\cal Y}_{n})$
and $\sum_{y\,\in\,{\cal Y}_{n}}{P\mathstrut}_{\!XY}(x, y) = {P\mathstrut}_{\!X}(x)$ for each $x \in {\cal X}_{n}$.

\bigskip

{\em The RHS of (\ref{eqLogGaussian})}

%\bigskip



%By (\ref{eqJointType}) the expression found on the RHS of (\ref{eqLogGaussian}) can be written as a sum of two terms:
%With respect to the definitions (\ref{eqPDFtoType})-(\ref{eqJointType}),
Having defined ${P\mathstrut}_{\!XY}$ and ${P\mathstrut}_{\!XY}^{q}$,
let us examine the possible decrease in the expression found on the RHS of (\ref{eqLogGaussian}) when %its
${P\mathstrut}_{\!XY}$ inside that expression is replaced with ${P\mathstrut}_{\!XY}^{q}$:
\begin{align}
&
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}(x, y)
(y - x)^{2}
\; - \;
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{q}(x, y)
(y - x)^{2}
\nonumber \\
\overset{a}{=} \;\; &
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{a}(x, y)
(y - x)^{2}
\;\; \overset{b}{=} \;\;
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{a}(x, y)
r_{\beta}^{2}(x)
\;\;
\overset{c}{\leq} \;\; %&
p_{1}\Delta_{\beta,\,n}^{2}/4
\;\; \overset{d}{\leq} \;\;
\underbrace{c_{1}h^{1/2}\Delta_{\beta,\,n}^{2}/2}_{o(1)},
\label{eqRHS}
\end{align}
where ($a$) follows by (\ref{eqJointType}),
($b$) follows according to the definitions (\ref{eqDiagonal}) and (\ref{eqRelationship}),
%with the function
%$r_{\beta}(x) = x - Q_{\beta}(x)$,
($c$) follows because $|\,r_{\beta}(x)\,| \, \leq \, \Delta_{\beta,\,n}/2$ and because
\begin{align}
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{a}(x, y)
\;\; & \overset{(\ref{eqJointType})}{=} \;\;
1 \, - \,
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{q}(x, y)
%\nonumber \\
\;\; \overset{(\ref{eqPDFtoType})}{=} \;\;
1 \, - \,
\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{p\mathstrut}_{XY}^{q}(x, y)
\nonumber \\
& \overset{(\ref{eqQuantized})}{=} \;\;
1 \, - \,
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{q}(x, y)dxdy
\;\; \overset{(\ref{eqProbLoss})}{=} \;\; p_{1},
\label{eqLostProb}
\end{align}
then ($d$) follows by the upper bound on $p_{1}$ of (\ref{eqProbLoss}).
Since by definition (\ref{eqPDFtoType})
we also have
\begin{displaymath}
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{q}(x, y)
(y - x)^{2} \;\; %\overset{(\ref{eqPDFtoType})}{=}
=
\;\;
\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{p\mathstrut}_{XY}^{q}(x, y)
(y - x)^{2},
%\;\; \overset{(\ref{eqLHS})}{=} \;\; \sigma_{2}^{2},
\end{displaymath}
which is exactly the beginning of (\ref{eqLHS}),
then combining (\ref{eqLHS}) and (\ref{eqRHS}) we obtain (\ref{eqLogGaussian}).
The remainder of the proof for (\ref{eqCondEntropy}) and (\ref{eqMargEntropy}) will easily follow by Lemma~\ref{Lemxlogx}
applied to corresponding discrete entropy expressions with probability masses.

\bigskip

{\em The RHS of (\ref{eqCondEntropy})}

%\bigskip

In order to upper-bound the expression on the RHS of (\ref{eqCondEntropy}), it is convenient to write:
\begin{align}
&
%\bigg|
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}(x, y)\,{\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!XY}(x, y)}
{\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}}
\, - \,
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{q}(x, y)\,{\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!XY}^{q}(x, y)}
{\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}}
%\,\bigg|
\nonumber \\
\overset{a}{=} \;\; &
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
\Big[\,
{P\mathstrut}_{\!XY}(x, y)\,{\log\mathstrut}_{\!b}\,{P\mathstrut}_{\!XY}(x, y)
\, - \,
{P\mathstrut}_{\!XY}^{q}(x, y)\,{\log\mathstrut}_{\!b}\,{P\mathstrut}_{\!XY}^{q}(x, y)
\,\Big]
\; + \;
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{a}(x, y)\,{\log\mathstrut}_{\!b}\,\frac{1}{\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}}
\nonumber \\
\overset{b}{\leq} \;\; &
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
\max\Big\{\!
-{P\mathstrut}_{\!XY}^{a}(x, y)\,{\log\mathstrut}_{\!b}\,{P\mathstrut}_{\!XY}^{a}(x, y), \;\;
{P\mathstrut}_{\!XY}^{a}(x, y)\,{\log\mathstrut}_{\!b}\,e
\Big\}
\; + \;
(1-\gamma)p_{1}\,{\log\mathstrut}_{\!b}\,n
\nonumber \\
\overset{c}{\leq} \;\; &
%-
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{a}(x, y)\,{\log\mathstrut}_{\!b}\,n
\; + \;
(1-\gamma)p_{1}\,{\log\mathstrut}_{\!b}\,n
\;\; \overset{d}{=} \;\; (2-\gamma)p_{1}
\,{\log\mathstrut}_{\!b}\,n
\;\; \overset{e}{\leq} \;\;
\underbrace{4c_{1}h^{1/2}\,{\log\mathstrut}_{\!b}\,n}_{o(1)}
, \;\;\; n > 2,
\label{eqDiscreteEntropy}
\end{align}
where ($a$) follows by (\ref{eqJointType});
in ($b$) we use (\ref{eqLostProb}), (\ref{eqDelta}),
and apply Lemma~\ref{Lemxlogx} with its parameters $t_{1} = {P\mathstrut}_{\!XY}^{q}(x, y)$
and $t_{1} + t = {P\mathstrut}_{\!XY}(x, y) \leq 1$
with $t = {P\mathstrut}_{\!XY}^{a}(x, y)$ by (\ref{eqJointType});
%and the inequality is %also
%trivially satisfied when ${P\mathstrut}_{\!XY}^{q}(x, y) = 0$ or ${P\mathstrut}_{\!XY}^{a}(x, y) = 0$;
($c$) follows for $n > 2$ since ${P\mathstrut}_{\!XY}^{a}(x, y) \geq 1/n$ when positive;
%if ${P\mathstrut}_{\!XY}^{a}(x, y) > 0$ then
%finally,
($d$) and ($e$) follow respectively by (\ref{eqLostProb}) and (\ref{eqProbLoss}).
Now since
\begin{displaymath}
\sum_{\substack{x\,\in\,{\cal X}_{n}\\
y\,\in\,{\cal Y}_{n}}}
{P\mathstrut}_{\!XY}^{q}(x, y)\,{\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!XY}^{q}(x, y)}
{\Delta_{\alpha,\,n}
\Delta_{\beta,\,n}}
\;\; = \;\;
\int\!\!\!\!\int_{\mathbb{R}^{2}}{p\mathstrut}_{XY}^{q}(x, y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{XY}^{q}(x, y)dxdy,
\end{displaymath}
the inequality in (\ref{eqCondEntropy}) follows by comparing (\ref{eqCondEntIdeal}), (\ref{eqPutting}), and (\ref{eqDiscreteEntropy}).

\bigskip

{\em The RHS of (\ref{eqMargEntropy})}

%\bigskip

With ${P\mathstrut}_{\!Y}^{q}(y) \triangleq \sum_{x\,\in \,{\cal X}_{n}}{P\mathstrut}_{\!XY}^{q}(x, y)$
and ${P\mathstrut}_{\!Y}^{a}(y) \triangleq \sum_{x\,\in \,{\cal X}_{n}}{P\mathstrut}_{\!XY}^{a}(x, y)$
we have
\begin{align}
&
%\bigg|
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}(y)\,{\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!Y}(y)}
{\Delta_{\beta,\,n}}
\, - \,
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}^{q}(y)\,{\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!Y}^{q}(y)}
{\Delta_{\beta,\,n}}
%\,\bigg|
\nonumber \\
\overset{a}{=} \;\; &
\sum_{y\,\in\,{\cal Y}_{n}}
\Big[\,
{P\mathstrut}_{\!Y}(y)\,{\log\mathstrut}_{\!b}\,{P\mathstrut}_{\!Y}(y)
\, - \,
{P\mathstrut}_{\!Y}^{q}(y)\,{\log\mathstrut}_{\!b}\,{P\mathstrut}_{\!Y}^{q}(y)
\,\Big]
\; + \;
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}^{a}(y)\,{\log\mathstrut}_{\!b}\,\frac{1}{\Delta_{\beta,\,n}}
\nonumber \\
\overset{b}{\geq} \;\; &
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}^{a}(y)\,{\log\mathstrut}_{\!b}\,{P\mathstrut}_{\!Y}^{a}(y)
\; + \;
\beta p_{1}\,{\log\mathstrut}_{\!b}\,n
\nonumber \\
\overset{c}{\geq} \;\; &
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}^{a}(y)\,{\log\mathstrut}_{\!b}\,(1/n)
\; + \;
\beta p_{1}\,{\log\mathstrut}_{\!b}\,n
\;\; \overset{d}{=} \;\; -(1 - \beta)p_{1}
\,{\log\mathstrut}_{\!b}\,n
\;\; \overset{e}{\geq} \;\;
\underbrace{-2c_{1}h^{1/2}\,{\log\mathstrut}_{\!b}\,n}_{o(1)},
\label{eqDiscreteMargEntropy}
\end{align}
where ($a$) follows by (\ref{eqJointType});
in ($b$) we use (\ref{eqLostProb}), (\ref{eqDelta}),
and apply Lemma~\ref{Lemxlogx} with its parameters $t_{1} = {P\mathstrut}_{\!Y}^{q}(y)$
and $t_{1} + t = {P\mathstrut}_{\!Y}(y)$
with $t = {P\mathstrut}_{\!Y}^{a}(y)$ by (\ref{eqJointType});
%and the inequality is %also
%trivially satisfied when ${P\mathstrut}_{\!XY}^{q}(x, y) = 0$ or ${P\mathstrut}_{\!XY}^{a}(x, y) = 0$;
($c$) follows because ${P\mathstrut}_{\!Y}^{a}(y) \geq 1/n$ whenever positive;
($d$) and ($e$) follow respectively by (\ref{eqLostProb}) and (\ref{eqProbLoss}).
From (\ref{eqMargUsual}) and (\ref{eqPDFtoType}) we observe that ${P\mathstrut}_{\!Y}^{q}(y) = {p\mathstrut}_{Y}^{q}(y)\Delta_{\beta,\,n}$.
Since the function ${p\mathstrut}_{Y}^{q}(y)$
is piecewise constant in $\mathbb{R}$ by the definition of ${p\mathstrut}_{XY}^{q}$,
it follows that
\begin{displaymath}
\sum_{y\,\in\,{\cal Y}_{n}}
{P\mathstrut}_{\!Y}^{q}(y)\,{\log\mathstrut}_{\!b}\,\frac{{P\mathstrut}_{\!Y}^{q}(y)}
{\Delta_{\beta,\,n}}
\;\; = \;\;
\int_{\mathbb{R}}
{p\mathstrut}_{Y}^{q}(y)
{\log\mathstrut}_{\!b}\,{p\mathstrut}_{Y}^{q}(y)dy.
\end{displaymath}
Then the inequality (\ref{eqMargEntropy}) follows by comparing (\ref{eqSecondTerm2}),
%with
(\ref{eqDiscreteMargEntropy}).
This concludes the proof of Lemma~\ref{LemQuant}.
$\square$
%\end{proof}


\bigskip


\begin{lemma}\label{Lemxlogx}
{\em Let $f(x) = x\ln x\,$, then for $0 < t \leq 1/e$ and $t_{1} > 0\,$,}
\begin{displaymath}
t \ln t
\;\; \leq \;\;
%|\,
f(t_{1} + t) - f(t_{1})
%\,|
\;\; \leq \;\; t\,\ln \max
\big\{
1/t, \; (t_{1} + t)e
\big\}.
\end{displaymath}
%\begin{displaymath}
%|\,f(t_{1} + t) - f(t_{1})\,| \;\; \leq \;\;
%t\max
%\big\{
%-\ln t, \;\;
%\ln(t_{1} + t) + 1
%\big\}.
%\end{displaymath}
\end{lemma}

%\bigskip

\begin{proof}
For $t \leq 1/e$,
the magnitude of the derivative %$|\, f'(x)\,|$
of $f(x)$ in the interval $(0, t)$ is monotonically decreasing and its average there
is $-\ln t$,
while in the adjacent interval $[\,t , \,1/(et)\,]$ the magnitude of the derivative is upper-bounded by $-\ln t$:
$\;\;\; |\, f'(x)\,| \; \leq \; -\ln t,
\;\;\; t \leq x \leq 1/(et)$.
%\begin{displaymath} %\label{eqDerivative}
%|\, f'(x)\,| \; \leq \; -\ln t,
%\;\;\;\;\;\; t \leq x \leq 1/(et).
%\end{displaymath}

Then there are three possible cases:

1) $\; t_{1} \, < \, t \, < \, t_{1} + t \, < \, 1/(et)\,$:
\begin{align}
|\,f(t_{1} + t) - f(t_{1})\,|
\;\; & \leq \;\;
|\,f(t_{1} + t) - f(t)\,| \, + \,
|\,f(t_{1}) - f(t)\,|
\nonumber \\
& = \;\;
|\,f(t_{1} + t) - f(t)\,| \, + \,
t_{1} \ln t_{1} \, - \,
t \ln t
\nonumber \\
&
%\overset{(\ref{eqDerivative})}{\leq}
\leq \;\;
-t_{1} \ln t
\, + \, t_{1} \ln t_{1}
\, - \, t \ln t
\nonumber \\
& \leq \;\;
-t \ln t.
\nonumber
\end{align}

2) $\; t \, \leq \, t_{1} \, < \, t_{1} + t \, \leq \, 1/(et)\,$:
$\;\;\;\;\;\;\;\;
 |\,f(t_{1} + t) - f(t_{1})\,| \;\; \leq \;\;
-t \ln t$.
%\begin{align}
%|\,f(t_{1} + t) - f(t_{1})\,|
%\;\; &
%%\overset{(\ref{eqDerivative})}{\leq}
%\leq
%\;\;
%-t \ln t.
%\nonumber
%\end{align}

3) $\; 1/(et)\, < \, t_{1} + t\,$:
$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
0 \;\; \leq \;\;
f(t_{1} + t) - f(t_{1})
\;\; \leq \;\;
f'(t_{1} + t)
\, t
\;\; = \;\;
\big(\ln(t_{1} + t) + 1\big) \, t$.
%\begin{align}
%0
%\;\; \leq \;\;
%%|\,
%f(t_{1} + t) - f(t_{1})
%%\,|
%\;\; & \leq \;\;
%%|\,
%f'(t_{1} + t)
%%\,|
%\, t
%\;\; = \;\;
%\big(\ln(t_{1} + t) + 1\big) \, t.
%\nonumber
%\end{align}
\end{proof}












































































%\newpage

\bibliographystyle{IEEEtran}
%%\bibliography{researchproposal}

\begin{thebibliography}{1}


%`` ''


\bibitem%[Cover and Thomas, 1991]{CoverBook}
{CoverThomas}
T.~M.~Cover and J.~A.~Thomas,
\newblock {\em ``Elements of Information Theory,''}
\newblock John Wiley \& Sons, 2006.



\bibitem
{Shannon59}
C.~E.~Shannon,
\newblock ``Probability of Error for Optimal Codes in a Gaussian Channel,''
\newblock {\em The Bell System Technical Journal}, vol. 38, no. 3, pp. 611--656, May 1959.





\bibitem
{Oohama17}
Y.~Oohama,
\newblock ``The Optimal Exponent Function for the Additive White Gaussian Noise Channel at Rates above the
Capacity,''
\newblock in {\em IEEE International Symposium on Information Theory (ISIT)}, Aachen, Germany, Jun 2017.





\bibitem
{CsiszarKorner}
I.~Csisz\'ar and J.~K{\"o}rner,
\newblock {\em ``Information Theory: Coding Theorems for Discrete Memoryless Systems,''}
\newblock Academic Press, 1981.






\bibitem
{DueckKorner79}
G.~Dueck and J.~K{\"o}rner,
\newblock ``Reliability Function of a Discrete Memoryless Channel at Rates above Capacity,''
\newblock {\em IEEE Trans. on Information Theory}, vol. 25, no. 1, pp. 82--85, Jan 1979.







\bibitem
{Csiszar98}
I.~Csisz\'ar,
\newblock ``The Method of Types,''
\newblock {\em IEEE Trans. on Information Theory}, vol. 44, no. 6, pp. 2505--2523, Oct 1998.





\bibitem
{Andrews}
G.~E.~Andrews,
\newblock {\em ``The Theory of Partitions,''}
\newblock Cambridge University Press, 1976.











\bibitem
{Gallager}
R.~G.~Gallager,
\newblock {\em ``Information Theory and Reliable Communication,''}
\newblock John Wiley \& Sons, 1968.








%\bibitem
%{Arimoto73}
%S.~Arimoto,
%\newblock ``On the Converse to the Coding Theorem for Discrete Memoryless Channels,''
%\newblock {\em IEEE Trans. on Information Theory}, vol. 19, no. 3, pp. 357--359, May 1973.
















\end{thebibliography}


\end{document}


