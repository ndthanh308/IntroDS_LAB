
@misc{zhang_adding_2023,
	title = {Adding {Conditional} {Control} to {Text}-to-{Image} {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2302.05543},
	urldate = {2023-06-23},
	publisher = {arXiv},
	author = {Zhang, Lvmin and Agrawala, Maneesh},
	month = feb,
	year = {2023},
	note = {arXiv:2302.05543 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Human-Computer Interaction, Computer Science - Multimedia},
}


@misc{rampas_novel_2023,
	title = {A {Novel} {Sampling} {Scheme} for {Text}- and {Image}-{Conditional} {Image} {Synthesis} in {Quantized} {Latent} {Spaces}},
	url = {http://arxiv.org/abs/2211.07292},
	language = {en},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Rampas, Dominic and Pernias, Pablo and Aubreville, Marc},
	month = may,
	year = {2023},
	note = {arXiv:2211.07292 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{xiong_layer_2020,
	title = {On {Layer} {Normalization} in the {Transformer} {Architecture}},
	url = {http://arxiv.org/abs/2002.04745},
	urldate = {2022-12-28},
	publisher = {arXiv},
	author = {Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tie-Yan},
	month = jun,
	year = {2020},
	note = {arXiv:2002.04745},
}

@misc{loshchilov_decoupled_2019,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {http://arxiv.org/abs/1711.05101},
	doi = {10.48550/arXiv.1711.05101},
	urldate = {2022-12-27},
	publisher = {arXiv},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = jan,
	year = {2019},
	note = {arXiv:1711.05101},
}

@misc{hendrycks_gaussian_2020,
	title = {Gaussian {Error} {Linear} {Units} ({GELUs})},
	url = {http://arxiv.org/abs/1606.08415},
	doi = {10.48550/arXiv.1606.08415},
	urldate = {2022-12-27},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	month = jul,
	year = {2020},
	note = {arXiv:1606.08415},
}

@misc{wu_group_2018,
	title = {Group {Normalization}},
	url = {http://arxiv.org/abs/1803.08494},
	doi = {10.48550/arXiv.1803.08494},
	urldate = {2022-12-27},
	publisher = {arXiv},
	author = {Wu, Yuxin and He, Kaiming},
	month = jun,
	year = {2018},
	note = {arXiv:1803.08494},
}

@misc{loshchilov_sgdr_2017,
	title = {{SGDR}: {Stochastic} {Gradient} {Descent} with {Warm} {Restarts}},
	shorttitle = {{SGDR}},
	url = {http://arxiv.org/abs/1608.03983},
	doi = {10.48550/arXiv.1608.03983},
	urldate = {2022-12-27},
	publisher = {arXiv},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = may,
	year = {2017},
	note = {arXiv:1608.03983},
}

@misc{huang_unet_2020,
	title = {{UNet} 3+: {A} {Full}-{Scale} {Connected} {UNet} for {Medical} {Image} {Segmentation}},
	shorttitle = {{UNet} 3+},
	url = {http://arxiv.org/abs/2004.08790},
	doi = {10.48550/arXiv.2004.08790},
	urldate = {2022-12-27},
	publisher = {arXiv},
	author = {Huang, Huimin and Lin, Lanfen and Tong, Ruofeng and Hu, Hongjie and Zhang, Qiaowei and Iwamoto, Yutaro and Han, Xianhua and Chen, Yen-Wei and Wu, Jian},
	month = apr,
	year = {2020},
	note = {arXiv:2004.08790},
}

@misc{ho_denoising_2020,
	title = {Denoising {Diffusion} {Probabilistic} {Models}},
	url = {http://arxiv.org/abs/2006.11239},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	year = {2020},
	note = {arXiv:2006.11239 [cs, stat]},
	keywords = {cited},
	file = {Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\67KX325X\\Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf:application/pdf},
}

@misc{bhat_zoedepth_2023,
	title = {{ZoeDepth}: {Zero}-shot {Transfer} by {Combining} {Relative} and {Metric} {Depth}},
	shorttitle = {{ZoeDepth}},
	url = {http://arxiv.org/abs/2302.12288},
	urldate = {2023-06-25},
	publisher = {arXiv},
	author = {Bhat, Shariq Farooq and Birkl, Reiner and Wofk, Diana and Wonka, Peter and Müller, Matthias},
	month = feb,
	year = {2023},
	note = {arXiv:2302.12288 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{dhariwal_diffusion_2021,
	title = {Diffusion {Models} {Beat} {GANs} on {Image} {Synthesis}},
	url = {http://arxiv.org/abs/2105.05233},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Dhariwal, Prafulla and Nichol, Alex},
	month = jun,
	year = {2021},
	note = {arXiv:2105.05233 [cs, stat]},
	keywords = {guidance, cited},
	file = {Dhariwal and Nichol - 2021 - Diffusion Models Beat GANs on Image Synthesis.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\UPJ275MR\\Dhariwal and Nichol - 2021 - Diffusion Models Beat GANs on Image Synthesis.pdf:application/pdf},
}

@misc{nichol_improved_2021,
	title = {Improved {Denoising} {Diffusion} {Probabilistic} {Models}},
	url = {http://arxiv.org/abs/2102.09672},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Nichol, Alex and Dhariwal, Prafulla},
	month = feb,
	year = {2021},
	note = {arXiv:2102.09672 [cs, stat]},
	keywords = {fast\_sampling},
	file = {Nichol and Dhariwal - 2021 - Improved Denoising Diffusion Probabilistic Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\YIPI9U2R\\Nichol and Dhariwal - 2021 - Improved Denoising Diffusion Probabilistic Models.pdf:application/pdf},
}

@misc{saxena_monocular_2023,
	title = {Monocular {Depth} {Estimation} using {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2302.14816},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Saxena, Saurabh and Kar, Abhishek and Norouzi, Mohammad and Fleet, David J.},
	month = feb,
	year = {2023},
	note = {arXiv:2302.14816 [cs]},
	keywords = {depth\_estimation, cited},
	file = {Saxena et al. - 2023 - Monocular Depth Estimation using Diffusion Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\5AESK2PE\\Saxena et al. - 2023 - Monocular Depth Estimation using Diffusion Models.pdf:application/pdf},
}

@inproceedings{choi_perception_2022,
	address = {New Orleans, LA, USA},
	title = {Perception {Prioritized} {Training} of {Diffusion} {Models}},
	isbn = {978-1-66546-946-3},
	url = {https://ieeexplore.ieee.org/document/9879163/},
	doi = {10.1109/CVPR52688.2022.01118},
	language = {en},
	urldate = {2023-04-03},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Choi, Jooyoung and Lee, Jungbeom and Shin, Chaehun and Kim, Sungwon and Kim, Hyunwoo and Yoon, Sungroh},
	month = jun,
	year = {2022},
	pages = {11462--11471},
	file = {Choi et al. - 2022 - Perception Prioritized Training of Diffusion Model.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\QB95SMYY\\Choi et al. - 2022 - Perception Prioritized Training of Diffusion Model.pdf:application/pdf},
}

@misc{rombach_high-resolution_2022,
	title = {High-{Resolution} {Image} {Synthesis} with {Latent} {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2112.10752},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
	month = apr,
	year = {2022},
	note = {arXiv:2112.10752 [cs]},
	keywords = {latent\_model},
	file = {Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\GW2MISTW\\Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf:application/pdf},
}

@misc{ho_classifier-free_2022,
	title = {Classifier-{Free} {Diffusion} {Guidance}},
	url = {http://arxiv.org/abs/2207.12598},
	language = {en},
	urldate = {2023-04-03},
	author = {Ho, Jonathan and Salimans, Tim},
	month = jul,
	year = {2022},
	note = {arXiv:2207.12598 [cs]},
	keywords = {cited, guidance},
	file = {Ho and Salimans - 2022 - Classifier-Free Diffusion Guidance.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\PBICKHZI\\Ho and Salimans - 2022 - Classifier-Free Diffusion Guidance.pdf:application/pdf},
}

@inproceedings{choi_ilvr_2021,
	address = {Montreal, QC, Canada},
	title = {{ILVR}: {Conditioning} {Method} for {Denoising} {Diffusion} {Probabilistic} {Models}},
	isbn = {978-1-66542-812-5},
	shorttitle = {{ILVR}},
	url = {https://ieeexplore.ieee.org/document/9711284/},
	doi = {10.1109/ICCV48922.2021.01410},
	language = {en},
	urldate = {2023-04-03},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Choi, Jooyoung and Kim, Sungwon and Jeong, Yonghyun and Gwon, Youngjune and Yoon, Sungroh},
	month = oct,
	year = {2021},
	keywords = {guidance},
	pages = {14347--14356},
	file = {Choi et al. - 2021 - ILVR Conditioning Method for Denoising Diffusion .pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\RQFPMCMV\\Choi et al. - 2021 - ILVR Conditioning Method for Denoising Diffusion .pdf:application/pdf},
}

@article{kreis_denoising_nodate,
	title = {Denoising {Diffusion}-based {Generative} {Modeling}: {Foundations} and {Applications}},
	language = {en},
	author = {Kreis, Karsten and Gao, Ruiqi and Vahdat, Arash},
	file = {Kreis et al. - Denoising Diffusion-based Generative Modeling Fou.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\J8R53C9V\\Kreis et al. - Denoising Diffusion-based Generative Modeling Fou.pdf:application/pdf},
}

@misc{song_denoising_2022,
	title = {Denoising {Diffusion} {Implicit} {Models}},
	url = {http://arxiv.org/abs/2010.02502},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	month = oct,
	year = {2022},
	note = {arXiv:2010.02502 [cs]},
	keywords = {fast\_sampling, cited},
	file = {Song et al. - 2022 - Denoising Diffusion Implicit Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\J9NDJMQR\\Song et al. - 2022 - Denoising Diffusion Implicit Models.pdf:application/pdf},
}

@misc{ranftl_towards_2020,
	title = {Towards {Robust} {Monocular} {Depth} {Estimation}: {Mixing} {Datasets} for {Zero}-shot {Cross}-dataset {Transfer}},
	shorttitle = {Towards {Robust} {Monocular} {Depth} {Estimation}},
	url = {http://arxiv.org/abs/1907.01341},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Ranftl, René and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
	month = aug,
	year = {2020},
	note = {arXiv:1907.01341 [cs]},
	keywords = {depth\_estimation, cited},
	file = {Ranftl et al. - 2020 - Towards Robust Monocular Depth Estimation Mixing .pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\PWNRSMXH\\Ranftl et al. - 2020 - Towards Robust Monocular Depth Estimation Mixing .pdf:application/pdf},
}

@misc{tang_improved_2023,
	title = {Improved {Vector} {Quantized} {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2205.16007},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Tang, Zhicong and Gu, Shuyang and Bao, Jianmin and Chen, Dong and Wen, Fang},
	month = feb,
	year = {2023},
	note = {arXiv:2205.16007 [cs]},
	keywords = {vector\_quantized, latent\_model, discrete\_diffusion},
	file = {Tang et al. - 2023 - Improved Vector Quantized Diffusion Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\SPRSBF92\\Tang et al. - 2023 - Improved Vector Quantized Diffusion Models.pdf:application/pdf},
}

@misc{gu_vector_2022,
	title = {Vector {Quantized} {Diffusion} {Model} for {Text}-to-{Image} {Synthesis}},
	url = {http://arxiv.org/abs/2111.14822},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining},
	month = mar,
	year = {2022},
	note = {arXiv:2111.14822 [cs]},
	keywords = {vector\_quantized, latent\_model, discrete\_diffusion},
	file = {Gu et al. - 2022 - Vector Quantized Diffusion Model for Text-to-Image.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\VWVQTJUE\\Gu et al. - 2022 - Vector Quantized Diffusion Model for Text-to-Image.pdf:application/pdf},
}

@inproceedings{zhou_3d_2021,
	address = {Montreal, QC, Canada},
	title = {{3D} {Shape} {Generation} and {Completion} through {Point}-{Voxel} {Diffusion}},
	isbn = {978-1-66542-812-5},
	url = {https://ieeexplore.ieee.org/document/9711332/},
	doi = {10.1109/ICCV48922.2021.00577},
	language = {en},
	urldate = {2023-04-03},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Zhou, Linqi and Du, Yilun and Wu, Jiajun},
	month = oct,
	year = {2021},
	keywords = {depth\_estimation, cited},
	pages = {5806--5815},
	file = {Full Text:C\:\\Users\\ksi2lr\\Zotero\\storage\\82S76ZIX\\Zhou et al. - 2021 - 3D Shape Generation and Completion through Point-V.pdf:application/pdf},
}

@misc{ho_cascaded_2021,
	title = {Cascaded {Diffusion} {Models} for {High} {Fidelity} {Image} {Generation}},
	url = {http://arxiv.org/abs/2106.15282},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J. and Norouzi, Mohammad and Salimans, Tim},
	month = dec,
	year = {2021},
	note = {arXiv:2106.15282 [cs]},
	keywords = {superres, cited},
	file = {Ho et al. - 2021 - Cascaded Diffusion Models for High Fidelity Image .pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\F8M9B6SQ\\Ho et al. - 2021 - Cascaded Diffusion Models for High Fidelity Image .pdf:application/pdf},
}

@inproceedings{chung_come-closer-diffuse-faster_2022,
	address = {New Orleans, LA, USA},
	title = {Come-{Closer}-{Diffuse}-{Faster}: {Accelerating} {Conditional} {Diffusion} {Models} for {Inverse} {Problems} through {Stochastic} {Contraction}},
	isbn = {978-1-66546-946-3},
	shorttitle = {Come-{Closer}-{Diffuse}-{Faster}},
	url = {https://ieeexplore.ieee.org/document/9879691/},
	doi = {10.1109/CVPR52688.2022.01209},
	language = {en},
	urldate = {2023-04-03},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Chung, Hyungjin and Sim, Byeongsu and Ye, Jong Chul},
	month = jun,
	year = {2022},
	keywords = {fast\_sampling},
	pages = {12403--12412},
	file = {Chung et al. - 2022 - Come-Closer-Diffuse-Faster Accelerating Condition.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\B6YQX5MI\\Chung et al. - 2022 - Come-Closer-Diffuse-Faster Accelerating Condition.pdf:application/pdf},
}

@misc{batzolis_conditional_2021,
	title = {Conditional {Image} {Generation} with {Score}-{Based} {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2111.13606},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Batzolis, Georgios and Stanczuk, Jan and Schönlieb, Carola-Bibiane and Etmann, Christian},
	month = nov,
	year = {2021},
	note = {arXiv:2111.13606 [cs, stat]},
	keywords = {score\_based, cited},
	file = {Batzolis et al. - 2021 - Conditional Image Generation with Score-Based Diff.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\7PMRQ72Y\\Batzolis et al. - 2021 - Conditional Image Generation with Score-Based Diff.pdf:application/pdf},
}

@misc{kim_dag_2023,
	title = {{DAG}: {Depth}-{Aware} {Guidance} with {Denoising} {Diffusion} {Probabilistic} {Models}},
	shorttitle = {{DAG}},
	url = {http://arxiv.org/abs/2212.08861},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Kim, Gyeongnyeon and Jang, Wooseok and Lee, Gyuseong and Hong, Susung and Seo, Junyoung and Kim, Seungryong},
	month = jan,
	year = {2023},
	note = {arXiv:2212.08861 [cs]},
	keywords = {depth\_estimation, cited},
	file = {Kim et al. - 2023 - DAG Depth-Aware Guidance with Denoising Diffusion.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\XKZPK37X\\Kim et al. - 2023 - DAG Depth-Aware Guidance with Denoising Diffusion.pdf:application/pdf},
}

@misc{sohl-dickstein_deep_2015,
	title = {Deep {Unsupervised} {Learning} using {Nonequilibrium} {Thermodynamics}},
	url = {http://arxiv.org/abs/1503.03585},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Sohl-Dickstein, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},
	month = nov,
	year = {2015},
	note = {arXiv:1503.03585 [cond-mat, q-bio, stat]},
	keywords = {cited},
	file = {Sohl-Dickstein et al. - 2015 - Deep Unsupervised Learning using Nonequilibrium Th.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\XCHKVSHD\\Sohl-Dickstein et al. - 2015 - Deep Unsupervised Learning using Nonequilibrium Th.pdf:application/pdf},
}

@misc{preechakul_diffusion_2022,
	title = {Diffusion {Autoencoders}: {Toward} a {Meaningful} and {Decodable} {Representation}},
	shorttitle = {Diffusion {Autoencoders}},
	url = {http://arxiv.org/abs/2111.15640},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Preechakul, Konpat and Chatthee, Nattanat and Wizadwongsa, Suttisak and Suwajanakorn, Supasorn},
	month = mar,
	year = {2022},
	note = {arXiv:2111.15640 [cs]},
	keywords = {latent\_model},
	file = {Preechakul et al. - 2022 - Diffusion Autoencoders Toward a Meaningful and De.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\PXXJJQKT\\Preechakul et al. - 2022 - Diffusion Autoencoders Toward a Meaningful and De.pdf:application/pdf},
}

@misc{karras_elucidating_2022,
	title = {Elucidating the {Design} {Space} of {Diffusion}-{Based} {Generative} {Models}},
	url = {http://arxiv.org/abs/2206.00364},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
	month = oct,
	year = {2022},
	note = {arXiv:2206.00364 [cs, stat]},
	keywords = {score\_based},
	file = {Karras et al. - 2022 - Elucidating the Design Space of Diffusion-Based Ge.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\82H2SFFH\\Karras et al. - 2022 - Elucidating the Design Space of Diffusion-Based Ge.pdf:application/pdf},
}

@misc{harvey_flexible_2022,
	title = {Flexible {Diffusion} {Modeling} of {Long} {Videos}},
	url = {http://arxiv.org/abs/2205.11495},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
	month = dec,
	year = {2022},
	note = {arXiv:2205.11495 [cs]},
	file = {Harvey et al. - 2022 - Flexible Diffusion Modeling of Long Videos.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\DES8UX2Q\\Harvey et al. - 2022 - Flexible Diffusion Modeling of Long Videos.pdf:application/pdf},
}

@misc{song_generative_2020,
	title = {Generative {Modeling} by {Estimating} {Gradients} of the {Data} {Distribution}},
	url = {http://arxiv.org/abs/1907.05600},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Song, Yang and Ermon, Stefano},
	month = oct,
	year = {2020},
	note = {arXiv:1907.05600 [cs, stat]},
	file = {Song and Ermon - 2020 - Generative Modeling by Estimating Gradients of the.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\99G64X7T\\Song and Ermon - 2020 - Generative Modeling by Estimating Gradients of the.pdf:application/pdf},
}

@misc{meng_sdedit_2022,
	title = {{SDEdit}: {Guided} {Image} {Synthesis} and {Editing} with {Stochastic} {Differential} {Equations}},
	shorttitle = {{SDEdit}},
	url = {http://arxiv.org/abs/2108.01073},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
	month = jan,
	year = {2022},
	note = {arXiv:2108.01073 [cs]},
	keywords = {score\_based, guidance, cited},
	file = {Meng et al. - 2022 - SDEdit Guided Image Synthesis and Editing with St.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\43D8KCSW\\Meng et al. - 2022 - SDEdit Guided Image Synthesis and Editing with St.pdf:application/pdf},
}

@misc{saharia_image_2021,
	title = {Image {Super}-{Resolution} via {Iterative} {Refinement}},
	url = {http://arxiv.org/abs/2104.07636},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J. and Norouzi, Mohammad},
	month = jun,
	year = {2021},
	note = {arXiv:2104.07636 [cs, eess]},
	keywords = {superres, cited},
	file = {Saharia et al. - 2021 - Image Super-Resolution via Iterative Refinement.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\XRKLB85F\\Saharia et al. - 2021 - Image Super-Resolution via Iterative Refinement.pdf:application/pdf},
}

@misc{song_improved_2020,
	title = {Improved {Techniques} for {Training} {Score}-{Based} {Generative} {Models}},
	url = {http://arxiv.org/abs/2006.09011},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Song, Yang and Ermon, Stefano},
	month = oct,
	year = {2020},
	note = {arXiv:2006.09011 [cs, stat]},
	keywords = {score\_based},
	file = {Song and Ermon - 2020 - Improved Techniques for Training Score-Based Gener.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\WGVENVG7\\Song and Ermon - 2020 - Improved Techniques for Training Score-Based Gener.pdf:application/pdf},
}

@misc{baranchuk_label-efficient_2022,
	title = {Label-{Efficient} {Semantic} {Segmentation} with {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2112.03126},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Baranchuk, Dmitry and Rubachev, Ivan and Voynov, Andrey and Khrulkov, Valentin and Babenko, Artem},
	month = mar,
	year = {2022},
	note = {arXiv:2112.03126 [cs]},
	file = {Baranchuk et al. - 2022 - Label-Efficient Semantic Segmentation with Diffusi.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\VLDH6CWK\\Baranchuk et al. - 2022 - Label-Efficient Semantic Segmentation with Diffusi.pdf:application/pdf},
}

@misc{song_maximum_2021,
	title = {Maximum {Likelihood} {Training} of {Score}-{Based} {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2101.09258},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Song, Yang and Durkan, Conor and Murray, Iain and Ermon, Stefano},
	month = oct,
	year = {2021},
	note = {arXiv:2101.09258 [cs, stat]},
	keywords = {score\_based},
	file = {Song et al. - 2021 - Maximum Likelihood Training of Score-Based Diffusi.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\4BLQGQ5S\\Song et al. - 2021 - Maximum Likelihood Training of Score-Based Diffusi.pdf:application/pdf},
}

@misc{ruan_mm-diffusion_2023,
	title = {{MM}-{Diffusion}: {Learning} {Multi}-{Modal} {Diffusion} {Models} for {Joint} {Audio} and {Video} {Generation}},
	shorttitle = {{MM}-{Diffusion}},
	url = {http://arxiv.org/abs/2212.09478},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Ruan, Ludan and Ma, Yiyang and Yang, Huan and He, Huiguo and Liu, Bei and Fu, Jianlong and Yuan, Nicholas Jing and Jin, Qin and Guo, Baining},
	month = mar,
	year = {2023},
	note = {arXiv:2212.09478 [cs]},
	keywords = {multi-modal, cited},
	file = {Ruan et al. - 2023 - MM-Diffusion Learning Multi-Modal Diffusion Model.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\MZ3PV6N4\\Ruan et al. - 2023 - MM-Diffusion Learning Multi-Modal Diffusion Model.pdf:application/pdf},
}

@misc{zhan_multimodal_2022,
	title = {Multimodal {Image} {Synthesis} and {Editing}: {A} {Survey}},
	shorttitle = {Multimodal {Image} {Synthesis} and {Editing}},
	url = {http://arxiv.org/abs/2112.13592},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Zhan, Fangneng and Yu, Yingchen and Wu, Rongliang and Zhang, Jiahui and Lu, Shijian and Liu, Lingjie and Kortylewski, Adam and Theobalt, Christian and Xing, Eric},
	month = jul,
	year = {2022},
	note = {arXiv:2112.13592 [cs]},
	file = {Zhan et al. - 2022 - Multimodal Image Synthesis and Editing A Survey.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\3PNKS9AQ\\Zhan et al. - 2022 - Multimodal Image Synthesis and Editing A Survey.pdf:application/pdf},
}

@misc{saharia_palette_2022,
	title = {Palette: {Image}-to-{Image} {Diffusion} {Models}},
	shorttitle = {Palette},
	url = {http://arxiv.org/abs/2111.05826},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris A. and Ho, Jonathan and Salimans, Tim and Fleet, David J. and Norouzi, Mohammad},
	month = may,
	year = {2022},
	note = {arXiv:2111.05826 [cs]},
	keywords = {cited},
	file = {Saharia et al. - 2022 - Palette Image-to-Image Diffusion Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\VVNLNF7F\\Saharia et al. - 2022 - Palette Image-to-Image Diffusion Models.pdf:application/pdf},
}

@misc{lee_priorgrad_2022,
	title = {{PriorGrad}: {Improving} {Conditional} {Denoising} {Diffusion} {Models} with {Data}-{Dependent} {Adaptive} {Prior}},
	shorttitle = {{PriorGrad}},
	url = {http://arxiv.org/abs/2106.06406},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Lee, Sang-gil and Kim, Heeseung and Shin, Chaehun and Tan, Xu and Liu, Chang and Meng, Qi and Qin, Tao and Chen, Wei and Yoon, Sungroh and Liu, Tie-Yan},
	month = feb,
	year = {2022},
	note = {arXiv:2106.06406 [cs, eess, stat]},
	file = {Lee et al. - 2022 - PriorGrad Improving Conditional Denoising Diffusi.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\EJXJSVCM\\Lee et al. - 2022 - PriorGrad Improving Conditional Denoising Diffusi.pdf:application/pdf},
}

@misc{salimans_progressive_2022,
	title = {Progressive {Distillation} for {Fast} {Sampling} of {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2202.00512},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Salimans, Tim and Ho, Jonathan},
	month = jun,
	year = {2022},
	note = {arXiv:2202.00512 [cs, stat]},
	keywords = {fast\_sampling},
	file = {Salimans and Ho - 2022 - Progressive Distillation for Fast Sampling of Diff.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\IWD52388\\Salimans and Ho - 2022 - Progressive Distillation for Fast Sampling of Diff.pdf:application/pdf},
}

@article{dabral_stochastic_nodate,
	title = {Stochastic {Differential} {Equations} and {Diffusion} {Models}},
	language = {en},
	author = {Dabral, Tanmaya Shekhar},
	keywords = {score\_based},
	file = {Dabral - Stochastic Differential Equations and Diffusion Mo.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\9Z2TQXPQ\\Dabral - Stochastic Differential Equations and Diffusion Mo.pdf:application/pdf},
}

@misc{kingma_variational_2022,
	title = {Variational {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2107.00630},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Salimans, Tim and Poole, Ben and Ho, Jonathan},
	month = dec,
	year = {2022},
	note = {arXiv:2107.00630 [cs, stat]},
	file = {Kingma et al. - 2022 - Variational Diffusion Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\MXNXINQG\\Kingma et al. - 2022 - Variational Diffusion Models.pdf:application/pdf},
}

@misc{ho_video_2022,
	title = {Video {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2204.03458},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J.},
	month = jun,
	year = {2022},
	note = {arXiv:2204.03458 [cs]},
	keywords = {video},
	file = {Ho et al. - 2022 - Video Diffusion Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\RLZSA4UZ\\Ho et al. - 2022 - Video Diffusion Models.pdf:application/pdf},
}

@misc{xiao_tackling_2022,
	title = {Tackling the {Generative} {Learning} {Trilemma} with {Denoising} {Diffusion} {GANs}},
	url = {http://arxiv.org/abs/2112.07804},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Xiao, Zhisheng and Kreis, Karsten and Vahdat, Arash},
	month = apr,
	year = {2022},
	note = {arXiv:2112.07804 [cs, stat]},
	file = {Xiao et al. - 2022 - Tackling the Generative Learning Trilemma with Den.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\4GPNRIGS\\Xiao et al. - 2022 - Tackling the Generative Learning Trilemma with Den.pdf:application/pdf},
}

@misc{luo_diffusion_2021,
	title = {Diffusion {Probabilistic} {Models} for {3D} {Point} {Cloud} {Generation}},
	url = {http://arxiv.org/abs/2103.01458},
	language = {en},
	urldate = {2023-04-03},
	publisher = {arXiv},
	author = {Luo, Shitong and Hu, Wei},
	month = jun,
	year = {2021},
	note = {arXiv:2103.01458 [cs]},
	keywords = {depth\_estimation, cited},
	file = {Luo and Hu - 2021 - Diffusion Probabilistic Models for 3D Point Cloud .pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\Z58H7MXT\\Luo and Hu - 2021 - Diffusion Probabilistic Models for 3D Point Cloud .pdf:application/pdf},
}

@misc{nichol_towards_2022,
	title = {Towards {Photorealistic} {Image} {Generation} and {Editing} with {Text}-{Guided} {Diffusion} {Models}},
	shorttitle = {{GLIDE}},
	url = {http://arxiv.org/abs/2112.10741},
	language = {en},
	urldate = {2023-04-04},
	publisher = {arXiv},
	author = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
	month = mar,
	year = {2022},
	note = {arXiv:2112.10741 [cs]},
	keywords = {guidance, text-to-image},
	file = {Nichol et al. - 2022 - GLIDE Towards Photorealistic Image Generation and.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\6LHR35XB\\Nichol et al. - 2022 - GLIDE Towards Photorealistic Image Generation and.pdf:application/pdf},
}

@misc{saharia_photorealistic_2022,
	title = {Photorealistic {Text}-to-{Image} {Diffusion} {Models} with {Deep} {Language} {Understanding}},
	url = {http://arxiv.org/abs/2205.11487},
	language = {en},
	urldate = {2023-04-04},
	publisher = {arXiv},
	author = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J. and Norouzi, Mohammad},
	month = may,
	year = {2022},
	note = {arXiv:2205.11487 [cs]},
	keywords = {superres, text-to-image, cited},
	file = {Saharia et al. - 2022 - Photorealistic Text-to-Image Diffusion Models with.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\2JFNEMPU\\Saharia et al. - 2022 - Photorealistic Text-to-Image Diffusion Models with.pdf:application/pdf},
}

@misc{ramesh_hierarchical_2022,
	title = {Hierarchical {Text}-{Conditional} {Image} {Generation} with {CLIP} {Latents}},
	url = {http://arxiv.org/abs/2204.06125},
	language = {en},
	urldate = {2023-04-04},
	publisher = {arXiv},
	author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
	month = apr,
	year = {2022},
	note = {arXiv:2204.06125 [cs]},
	keywords = {guidance, text-to-image},
	file = {Ramesh et al. - 2022 - Hierarchical Text-Conditional Image Generation wit.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\JQX8CEYD\\Ramesh et al. - 2022 - Hierarchical Text-Conditional Image Generation wit.pdf:application/pdf},
}

@misc{hoogeboom_argmax_2021,
	title = {Argmax {Flows} and {Multinomial} {Diffusion}: {Learning} {Categorical} {Distributions}},
	shorttitle = {Argmax {Flows} and {Multinomial} {Diffusion}},
	url = {http://arxiv.org/abs/2102.05379},
	language = {en},
	urldate = {2023-04-04},
	publisher = {arXiv},
	author = {Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forré, Patrick and Welling, Max},
	month = oct,
	year = {2021},
	note = {arXiv:2102.05379 [cs, stat]},
	file = {Hoogeboom et al. - 2021 - Argmax Flows and Multinomial Diffusion Learning C.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\9DDNUSIA\\Hoogeboom et al. - 2021 - Argmax Flows and Multinomial Diffusion Learning C.pdf:application/pdf},
}

@misc{yang_diffusion_2022,
	title = {Diffusion {Probabilistic} {Modeling} for {Video} {Generation}},
	url = {http://arxiv.org/abs/2203.09481},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
	month = dec,
	year = {2022},
	note = {arXiv:2203.09481 [cs, stat]},
	keywords = {video},
	file = {Yang et al. - 2022 - Diffusion Probabilistic Modeling for Video Generat.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\33KTEESQ\\Yang et al. - 2022 - Diffusion Probabilistic Modeling for Video Generat.pdf:application/pdf},
}

@misc{kong_diffwave_2021,
	title = {{DiffWave}: {A} {Versatile} {Diffusion} {Model} for {Audio} {Synthesis}},
	shorttitle = {{DiffWave}},
	url = {http://arxiv.org/abs/2009.09761},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
	month = mar,
	year = {2021},
	note = {arXiv:2009.09761 [cs, eess, stat]},
	keywords = {audio},
	file = {Kong et al. - 2021 - DiffWave A Versatile Diffusion Model for Audio Sy.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\XGG5PXVK\\Kong et al. - 2021 - DiffWave A Versatile Diffusion Model for Audio Sy.pdf:application/pdf},
}

@misc{brock_large_2019,
	title = {Large {Scale} {GAN} {Training} for {High} {Fidelity} {Natural} {Image} {Synthesis}},
	url = {http://arxiv.org/abs/1809.11096},
	doi = {10.48550/arXiv.1809.11096},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
	month = feb,
	year = {2019},
	note = {arXiv:1809.11096 [cs, stat]},
	keywords = {GAN, cited},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\KA2PJXAB\\Brock et al. - 2019 - Large Scale GAN Training for High Fidelity Natural.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\RSDW8J4K\\1809.html:text/html},
}

@misc{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	doi = {10.48550/arXiv.1406.2661},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv:1406.2661 [cs, stat]},
	keywords = {GAN, cited},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\3NLGAWHV\\Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\6S376LVX\\1406.html:text/html},
}

@misc{kirch_vologan_2022,
	title = {{VoloGAN}: {Adversarial} {Domain} {Adaptation} for {Synthetic} {Depth} {Data}},
	shorttitle = {{VoloGAN}},
	url = {http://arxiv.org/abs/2207.09204},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Kirch, Sascha and Pagés, Rafael and Arnaldo, Sergio and Martín, Sergio},
	month = jul,
	year = {2022},
	note = {arXiv:2207.09204 [cs, eess]},
	keywords = {GAN, cited},
	file = {Kirch et al. - 2022 - VoloGAN Adversarial Domain Adaptation for Synthet.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\DJLQL7B2\\Kirch et al. - 2022 - VoloGAN Adversarial Domain Adaptation for Synthet.pdf:application/pdf},
}

@misc{kingma_auto-encoding_2022,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2022},
	note = {arXiv:1312.6114 [cs, stat]},
	keywords = {VAE},
	file = {Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\MCY5ZXCE\\Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf:application/pdf},
}

@misc{razavi_generating_2019,
	title = {Generating {Diverse} {High}-{Fidelity} {Images} with {VQ}-{VAE}-2},
	url = {http://arxiv.org/abs/1906.00446},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Razavi, Ali and Oord, Aaron van den and Vinyals, Oriol},
	month = jun,
	year = {2019},
	note = {arXiv:1906.00446 [cs, stat]},
	keywords = {VAE},
	file = {Razavi et al. - 2019 - Generating Diverse High-Fidelity Images with VQ-VA.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\GTEUBZMD\\Razavi et al. - 2019 - Generating Diverse High-Fidelity Images with VQ-VA.pdf:application/pdf},
}

@misc{durkan_neural_2019,
	title = {Neural {Spline} {Flows}},
	url = {http://arxiv.org/abs/1906.04032},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
	month = dec,
	year = {2019},
	note = {arXiv:1906.04032 [cs, stat]},
	keywords = {normalizing\_flow, cited},
	file = {Durkan et al. - 2019 - Neural Spline Flows.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\IN7SA6SQ\\Durkan et al. - 2019 - Neural Spline Flows.pdf:application/pdf},
}

@misc{dinh_density_2017,
	title = {Density estimation using {Real} {NVP}},
	url = {http://arxiv.org/abs/1605.08803},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	month = feb,
	year = {2017},
	note = {arXiv:1605.08803 [cs, stat]},
	keywords = {normalizing\_flow},
	file = {Dinh et al. - 2017 - Density estimation using Real NVP.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\KUIQHEQY\\Dinh et al. - 2017 - Density estimation using Real NVP.pdf:application/pdf},
}

@inproceedings{khan_differentiable_2021,
	address = {Nashville, TN, USA},
	title = {Differentiable {Diffusion} for {Dense} {Depth} {Estimation} from {Multi}-view {Images}},
	isbn = {978-1-66544-509-2},
	url = {https://ieeexplore.ieee.org/document/9577844/},
	doi = {10.1109/CVPR46437.2021.00880},
	language = {en},
	urldate = {2023-04-05},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Khan, Numair and Kim, Min H. and Tompkin, James},
	month = jun,
	year = {2021},
	keywords = {depth\_estimation, cited},
	pages = {8908--8917},
	file = {Khan et al. - 2021 - Differentiable Diffusion for Dense Depth Estimatio.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\IX4GIN5R\\Khan et al. - 2021 - Differentiable Diffusion for Dense Depth Estimatio.pdf:application/pdf},
}

@misc{duan_diffusiondepth_2023,
	title = {{DiffusionDepth}: {Diffusion} {Denoising} {Approach} for {Monocular} {Depth} {Estimation}},
	shorttitle = {{DiffusionDepth}},
	url = {http://arxiv.org/abs/2303.05021},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Duan, Yiqun and Zhu, Zheng and Guo, Xianda},
	month = mar,
	year = {2023},
	note = {arXiv:2303.05021 [cs]},
	keywords = {depth\_estimation, cited},
	file = {Duan et al. - 2023 - DiffusionDepth Diffusion Denoising Approach for M.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\YJNGR5UE\\Duan et al. - 2023 - DiffusionDepth Diffusion Denoising Approach for M.pdf:application/pdf},
}

@misc{watson_novel_2022,
	title = {Novel {View} {Synthesis} with {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2210.04628},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Watson, Daniel and Chan, William and Martin-Brualla, Ricardo and Ho, Jonathan and Tagliasacchi, Andrea and Norouzi, Mohammad},
	month = oct,
	year = {2022},
	note = {arXiv:2210.04628 [cs]},
	keywords = {depth\_estimation, novel\_view\_synthesis, cited},
	file = {Watson et al. - 2022 - Novel View Synthesis with Diffusion Models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\R28X7IRN\\Watson et al. - 2022 - Novel View Synthesis with Diffusion Models.pdf:application/pdf},
}

@misc{nichol_point-e_2022,
	title = {Point-{E}: {A} {System} for {Generating} {3D} {Point} {Clouds} from {Complex} {Prompts}},
	shorttitle = {Point-{E}},
	url = {http://arxiv.org/abs/2212.08751},
	doi = {10.48550/arXiv.2212.08751},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Nichol, Alex and Jun, Heewoo and Dhariwal, Prafulla and Mishkin, Pamela and Chen, Mark},
	month = dec,
	year = {2022},
	note = {arXiv:2212.08751 [cs]},
	keywords = {depth\_estimation, cited},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\VF2D2TGW\\Nichol et al. - 2022 - Point-E A System for Generating 3D Point Clouds f.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\C2IL6CWP\\2212.html:text/html},
}

@misc{rockwell_pixelsynth_2021,
	title = {{PixelSynth}: {Generating} a {3D}-{Consistent} {Experience} from a {Single} {Image}},
	shorttitle = {{PixelSynth}},
	url = {http://arxiv.org/abs/2108.05892},
	doi = {10.48550/arXiv.2108.05892},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Rockwell, Chris and Fouhey, David F. and Johnson, Justin},
	month = aug,
	year = {2021},
	note = {arXiv:2108.05892 [cs]},
	keywords = {depth\_estimation, cited},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\GUMTD5NJ\\Rockwell et al. - 2021 - PixelSynth Generating a 3D-Consistent Experience .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\TA7JGXI9\\2108.html:text/html},
}

@misc{poole_dreamfusion_2022,
	title = {{DreamFusion}: {Text}-to-{3D} using {2D} {Diffusion}},
	shorttitle = {{DreamFusion}},
	url = {http://arxiv.org/abs/2209.14988},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},
	month = sep,
	year = {2022},
	note = {arXiv:2209.14988 [cs, stat]},
	keywords = {depth\_estimation, cited},
	file = {Poole et al. - 2022 - DreamFusion Text-to-3D using 2D Diffusion.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\P74V4D75\\Poole et al. - 2022 - DreamFusion Text-to-3D using 2D Diffusion.pdf:application/pdf},
}

@misc{liu_infinite_2021,
	title = {Infinite {Nature}: {Perpetual} {View} {Generation} of {Natural} {Scenes} from a {Single} {Image}},
	shorttitle = {Infinite {Nature}},
	url = {http://arxiv.org/abs/2012.09855},
	language = {en},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Liu, Andrew and Tucker, Richard and Jampani, Varun and Makadia, Ameesh and Snavely, Noah and Kanazawa, Angjoo},
	month = nov,
	year = {2021},
	note = {arXiv:2012.09855 [cs]},
	keywords = {depth\_estimation, cited},
	file = {Liu et al. - 2021 - Infinite Nature Perpetual View Generation of Natu.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\S467UJJV\\Liu et al. - 2021 - Infinite Nature Perpetual View Generation of Natu.pdf:application/pdf},
}

@misc{liu_swin_2021,
	title = {Swin {Transformer}: {Hierarchical} {Vision} {Transformer} using {Shifted} {Windows}},
	shorttitle = {Swin {Transformer}},
	url = {http://arxiv.org/abs/2103.14030},
	language = {en},
	urldate = {2023-04-06},
	publisher = {arXiv},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	month = aug,
	year = {2021},
	note = {arXiv:2103.14030 [cs]},
	keywords = {cited},
	file = {Liu et al. - 2021 - Swin Transformer Hierarchical Vision Transformer .pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\HTREGCJ9\\Liu et al. - 2021 - Swin Transformer Hierarchical Vision Transformer .pdf:application/pdf},
}

@misc{karras_style-based_2019,
	title = {A {Style}-{Based} {Generator} {Architecture} for {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1812.04948},
	language = {en},
	urldate = {2023-04-06},
	publisher = {arXiv},
	author = {Karras, Tero and Laine, Samuli and Aila, Timo},
	month = mar,
	year = {2019},
	note = {arXiv:1812.04948 [cs, stat]},
	file = {Karras et al. - 2019 - A Style-Based Generator Architecture for Generativ.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\KTYYHQVX\\Karras et al. - 2019 - A Style-Based Generator Architecture for Generativ.pdf:application/pdf},
}

@article{lu_self-supervised_2022,
	title = {Self-supervised learning of monocular depth using quantized networks},
	volume = {488},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231221017483},
	doi = {10.1016/j.neucom.2021.11.071},
	language = {en},
	urldate = {2023-04-06},
	journal = {Neurocomputing},
	author = {Lu, Keyu and Zeng, Chengyi and Zeng, Yonghu},
	month = jun,
	year = {2022},
	keywords = {non\_diffusion\_depth, stereo-train\_mono\_inference},
	pages = {634--646},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\SA8IVU9F\\Lu et al. - 2022 - Self-supervised learning of monocular depth using .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\IGCX9CMV\\S0925231221017483.html:text/html},
}

@misc{chen_self-supervised_2018,
	title = {Self-{Supervised} {Monocular} {Image} {Depth} {Learning} and {Confidence} {Estimation}},
	url = {http://arxiv.org/abs/1803.05530},
	doi = {10.48550/arXiv.1803.05530},
	urldate = {2023-04-06},
	publisher = {arXiv},
	author = {Chen, Long and Tang, Wen and John, Nigel},
	month = mar,
	year = {2018},
	note = {arXiv:1803.05530 [cs]},
	keywords = {non\_diffusion\_depth, stereo-train\_mono\_inference},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\FJLWW6M3\\Chen et al. - 2018 - Self-Supervised Monocular Image Depth Learning and.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\REY8MFKD\\1803.html:text/html},
}

@article{zhang_unsupervised_2020,
	title = {Unsupervised detail-preserving network for high quality monocular depth estimation},
	volume = {404},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231220308109},
	doi = {10.1016/j.neucom.2020.05.015},
	language = {en},
	urldate = {2023-04-06},
	journal = {Neurocomputing},
	author = {Zhang, Mingliang and Ye, Xinchen and Fan, Xin},
	month = sep,
	year = {2020},
	keywords = {non\_diffusion\_depth, stereo-train\_mono\_inference},
	pages = {1--13},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\RLIGFREM\\Zhang et al. - 2020 - Unsupervised detail-preserving network for high qu.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\CYR8WVXM\\S0925231220308109.html:text/html},
}

@article{bian_unsupervised_2021,
	title = {Unsupervised {Scale}-consistent {Depth} {Learning} from {Video}},
	volume = {129},
	issn = {0920-5691, 1573-1405},
	url = {http://arxiv.org/abs/2105.11610},
	doi = {10.1007/s11263-021-01484-6},
	language = {en},
	number = {9},
	urldate = {2023-04-06},
	journal = {International Journal of Computer Vision},
	author = {Bian, Jia-Wang and Zhan, Huangying and Wang, Naiyan and Li, Zhichao and Zhang, Le and Shen, Chunhua and Cheng, Ming-Ming and Reid, Ian},
	month = sep,
	year = {2021},
	note = {arXiv:2105.11610 [cs]},
	keywords = {non\_diffusion\_depth, video\_depth},
	pages = {2548--2564},
	file = {Bian et al. - 2021 - Unsupervised Scale-consistent Depth Learning from .pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\Y5WPKKPF\\Bian et al. - 2021 - Unsupervised Scale-consistent Depth Learning from .pdf:application/pdf},
}

@misc{watson_temporal_2021,
	title = {The {Temporal} {Opportunist}: {Self}-{Supervised} {Multi}-{Frame} {Monocular} {Depth}},
	shorttitle = {The {Temporal} {Opportunist}},
	url = {http://arxiv.org/abs/2104.14540},
	abstract = {Self-supervised monocular depth estimation networks are trained to predict scene depth using nearby frames as a supervision signal during training. However, for many applications, sequence information in the form of video frames is also available at test time. The vast majority of monocular networks do not make use of this extra signal, thus ignoring valuable information that could be used to improve the predicted depth. Those that do, either use computationally expensive test-time reﬁnement techniques or off-theshelf recurrent networks, which only indirectly make use of the geometric information that is inherently available.},
	language = {en},
	urldate = {2023-04-06},
	publisher = {arXiv},
	author = {Watson, Jamie and Mac Aodha, Oisin and Prisacariu, Victor and Brostow, Gabriel and Firman, Michael},
	month = jul,
	year = {2021},
	note = {arXiv:2104.14540 [cs]},
	keywords = {non\_diffusion\_depth, video\_depth},
	file = {Watson et al. - 2021 - The Temporal Opportunist Self-Supervised Multi-Fr.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\SU29WGRJ\\Watson et al. - 2021 - The Temporal Opportunist Self-Supervised Multi-Fr.pdf:application/pdf},
}

@article{yue_self-supervised_2022,
	title = {Self-supervised monocular depth estimation in dynamic scenes with moving instance loss},
	volume = {112},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197622001105},
	doi = {10.1016/j.engappai.2022.104862},
	language = {en},
	urldate = {2023-04-06},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Yue, Min and Fu, Guangyuan and Wu, Ming and Zhang, Xin and Gu, Hongyang},
	month = jun,
	year = {2022},
	keywords = {non\_diffusion\_depth, multi\_task},
	pages = {104862},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\QWQH44YQ\\Yue et al. - 2022 - Self-supervised monocular depth estimation in dyna.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\8VB5B4ZM\\S0952197622001105.html:text/html},
}

@article{zhao_joint_2022,
	title = {Joint {Learning} of {Salient} {Object} {Detection}, {Depth} {Estimation} and {Contour} {Extraction}},
	volume = {31},
	issn = {1057-7149, 1941-0042},
	url = {http://arxiv.org/abs/2203.04895},
	doi = {10.1109/TIP.2022.3222641},
	urldate = {2023-04-06},
	journal = {IEEE Transactions on Image Processing},
	author = {Zhao, Xiaoqi and Pang, Youwei and Zhang, Lihe and Lu, Huchuan},
	year = {2022},
	note = {arXiv:2203.04895 [cs]},
	keywords = {non\_diffusion\_depth, multi\_task},
	pages = {7350--7362},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\BJ2ADXBR\\Zhao et al. - 2022 - Joint Learning of Salient Object Detection, Depth .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\R7HUVLIN\\2203.html:text/html},
}

@misc{micikevicius_mixed_2018,
	title = {Mixed {Precision} {Training}},
	url = {http://arxiv.org/abs/1710.03740},
	language = {en},
	urldate = {2023-04-07},
	publisher = {arXiv},
	author = {Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
	month = feb,
	year = {2018},
	note = {arXiv:1710.03740 [cs, stat]},
	file = {Micikevicius et al. - 2018 - Mixed Precision Training.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\L58V5J5C\\Micikevicius et al. - 2018 - Mixed Precision Training.pdf:application/pdf},
}

@misc{wang_linformer_2020,
	title = {Linformer: {Self}-{Attention} with {Linear} {Complexity}},
	shorttitle = {Linformer},
	url = {http://arxiv.org/abs/2006.04768},
	language = {en},
	urldate = {2023-04-07},
	publisher = {arXiv},
	author = {Wang, Sinong and Li, Belinda Z. and Khabsa, Madian and Fang, Han and Ma, Hao},
	month = jun,
	year = {2020},
	note = {arXiv:2006.04768 [cs, stat]},
	file = {Wang et al. - 2020 - Linformer Self-Attention with Linear Complexity.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\W8YXEI6Y\\Wang et al. - 2020 - Linformer Self-Attention with Linear Complexity.pdf:application/pdf},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	language = {en},
	urldate = {2023-04-07},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	file = {Vaswani et al. - 2017 - Attention Is All You Need.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\JFSXK35N\\Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf},
}

@misc{liu_convnet_2022,
	title = {A {ConvNet} for the 2020s},
	url = {http://arxiv.org/abs/2201.03545},
	language = {en},
	urldate = {2023-04-08},
	publisher = {arXiv},
	author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	month = mar,
	year = {2022},
	note = {arXiv:2201.03545 [cs]},
	keywords = {stochastic\_depth},
	file = {Liu et al. - 2022 - A ConvNet for the 2020s.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\EABY6SS8\\Liu et al. - 2022 - A ConvNet for the 2020s.pdf:application/pdf},
}

@misc{huang_deep_2016,
	title = {Deep {Networks} with {Stochastic} {Depth}},
	url = {http://arxiv.org/abs/1603.09382},
	language = {en},
	urldate = {2023-04-08},
	publisher = {arXiv},
	author = {Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian},
	month = jul,
	year = {2016},
	note = {arXiv:1603.09382 [cs]},
	keywords = {stochastic\_depth},
	file = {Huang et al. - 2016 - Deep Networks with Stochastic Depth.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\VIDZFEDJ\\Huang et al. - 2016 - Deep Networks with Stochastic Depth.pdf:application/pdf},
}

@misc{piao_dynamic_2021,
	title = {Dynamic {Fusion} {Network} {For} {Light} {Field} {Depth} {Estimation}},
	url = {http://arxiv.org/abs/2104.05969},
	doi = {10.48550/arXiv.2104.05969},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Piao, Yongri and Zhang, Yukun and Zhang, Miao and Ji, Xinxin},
	month = apr,
	year = {2021},
	note = {arXiv:2104.05969 [cs]},
	keywords = {multi-modal, non\_diffusion\_depth},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\HTTJSSR8\\Piao et al. - 2021 - Dynamic Fusion Network For Light Field Depth Estim.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\FHVL4PH6\\2104.html:text/html},
}

@article{eldesokey_confidence_2020,
	title = {Confidence {Propagation} through {CNNs} for {Guided} {Sparse} {Depth} {Regression}},
	volume = {42},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {http://arxiv.org/abs/1811.01791},
	doi = {10.1109/TPAMI.2019.2929170},
	number = {10},
	urldate = {2023-04-09},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Eldesokey, Abdelrahman and Felsberg, Michael and Khan, Fahad Shahbaz},
	month = oct,
	year = {2020},
	note = {arXiv:1811.01791 [cs]},
	keywords = {multi-modal, non\_diffusion\_depth},
	pages = {2423--2436},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\4GDD4MIW\\Eldesokey et al. - 2020 - Confidence Propagation through CNNs for Guided Spa.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\KLD67IVE\\1811.html:text/html},
}

@article{zhang_lidar-guided_2022,
	title = {{LiDAR}-guided {Stereo} {Matching} with a {Spatial} {Consistency} {Constraint}},
	volume = {183},
	issn = {09242716},
	url = {http://arxiv.org/abs/2202.09953},
	doi = {10.1016/j.isprsjprs.2021.11.003},
	urldate = {2023-04-09},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Zhang, Yongjun and Zou, Siyuan and Liu, Xinyi and Huang, Xu and Wan, Yi and Yao, Yongxiang},
	month = jan,
	year = {2022},
	note = {arXiv:2202.09953 [cs, eess]},
	keywords = {multi-modal, non\_diffusion\_depth},
	pages = {164--177},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\MBW5E55J\\Zhang et al. - 2022 - LiDAR-guided Stereo Matching with a Spatial Consis.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\BL5UEW9C\\2202.html:text/html},
}

@misc{liu_pseudo-lidar_2020,
	title = {Pseudo-{LiDAR} {Point} {Cloud} {Interpolation} {Based} on {3D} {Motion} {Representation} and {Spatial} {Supervision}},
	url = {http://arxiv.org/abs/2006.11481},
	doi = {10.48550/arXiv.2006.11481},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Liu, Haojie and Liao, Kang and Lin, Chunyu and Zhao, Yao and Guo, Yulan},
	month = jun,
	year = {2020},
	note = {arXiv:2006.11481 [cs]},
	keywords = {multi-modal, non\_diffusion\_depth},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\7SVZCEQG\\Liu et al. - 2020 - Pseudo-LiDAR Point Cloud Interpolation Based on 3D.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\5KG6LKEH\\2006.html:text/html},
}

@misc{hoogeboom_autoregressive_2022,
	title = {Autoregressive {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2110.02037},
	language = {en},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Hoogeboom, Emiel and Gritsenko, Alexey A. and Bastings, Jasmijn and Poole, Ben and Berg, Rianne van den and Salimans, Tim},
	month = feb,
	year = {2022},
	note = {arXiv:2110.02037 [cs, stat]},
	file = {2110.02037.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\FTVZCWRQ\\2110.02037.pdf:application/pdf},
}

@misc{sinha_d2c_2021,
	title = {{D2C}: {Diffusion}-{Denoising} {Models} for {Few}-shot {Conditional} {Generation}},
	shorttitle = {{D2C}},
	url = {http://arxiv.org/abs/2106.06819},
	doi = {10.48550/arXiv.2106.06819},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Sinha, Abhishek and Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	month = jun,
	year = {2021},
	note = {arXiv:2106.06819 [cs]},
	keywords = {latent\_model},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\D54GZV4R\\Sinha et al. - 2021 - D2C Diffusion-Denoising Models for Few-shot Condi.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\GEXHV2BS\\2106.html:text/html},
}

@misc{song_score-based_2021,
	title = {Score-{Based} {Generative} {Modeling} through {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2011.13456},
	doi = {10.48550/arXiv.2011.13456},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	month = feb,
	year = {2021},
	note = {arXiv:2011.13456 [cs, stat]},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\SIGBGAM2\\Song et al. - 2021 - Score-Based Generative Modeling through Stochastic.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\R3EG6UTG\\2011.html:text/html},
}

@article{stucker_resdepth_2022,
	title = {{ResDepth}: {A} {Deep} {Residual} {Prior} {For} {3D} {Reconstruction} {From} {High}-resolution {Satellite} {Images}},
	volume = {183},
	issn = {09242716},
	shorttitle = {{ResDepth}},
	url = {http://arxiv.org/abs/2106.08107},
	doi = {10.1016/j.isprsjprs.2021.11.009},
	urldate = {2023-04-09},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Stucker, Corinne and Schindler, Konrad},
	month = jan,
	year = {2022},
	note = {arXiv:2106.08107 [cs, eess]},
	keywords = {multi-stage, non\_diffusion\_depth},
	pages = {560--580},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\IVCQ5F4L\\Stucker and Schindler - 2022 - ResDepth A Deep Residual Prior For 3D Reconstruct.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\JHSWNBT5\\2106.html:text/html},
}

@misc{cheng_exploiting_2022,
	title = {Exploiting {Correspondences} with {All}-pairs {Correlations} for {Multi}-view {Depth} {Estimation}},
	url = {http://arxiv.org/abs/2205.02481},
	doi = {10.48550/arXiv.2205.02481},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Cheng, Kai and Chen, Hao and Yin, Wei and Xu, Guangkai and Chen, Xuejin},
	month = may,
	year = {2022},
	note = {arXiv:2205.02481 [cs]},
	keywords = {multi-stage, non\_diffusion\_depth},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\VWQ9FQGE\\Cheng et al. - 2022 - Exploiting Correspondences with All-pairs Correlat.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\Q9QVS4LL\\2205.html:text/html},
}

@article{zhao_monocular_2020,
	title = {Monocular {Depth} {Estimation} {Based} {On} {Deep} {Learning}: {An} {Overview}},
	volume = {63},
	issn = {1674-7321, 1869-1900},
	shorttitle = {Monocular {Depth} {Estimation} {Based} {On} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2003.06620},
	doi = {10.1007/s11431-020-1582-8},
	language = {en},
	number = {9},
	urldate = {2023-04-09},
	journal = {Science China Technological Sciences},
	author = {Zhao, Chaoqiang and Sun, Qiyu and Zhang, Chongzhen and Tang, Yang and Qian, Feng},
	month = sep,
	year = {2020},
	note = {arXiv:2003.06620 [cs]},
	keywords = {cited, non\_diffusion\_depth, survey},
	pages = {1612--1627},
	file = {Zhao et al. - 2020 - Monocular Depth Estimation Based On Deep Learning.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\55YPH9ZU\\Zhao et al. - 2020 - Monocular Depth Estimation Based On Deep Learning.pdf:application/pdf},
}

@misc{baltrusaitis_multimodal_2017,
	title = {Multimodal {Machine} {Learning}: {A} {Survey} and {Taxonomy}},
	shorttitle = {Multimodal {Machine} {Learning}},
	url = {http://arxiv.org/abs/1705.09406},
	doi = {10.48550/arXiv.1705.09406},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Baltrušaitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
	month = aug,
	year = {2017},
	note = {arXiv:1705.09406 [cs]},
	keywords = {cited, multi-modal, survey},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\YIY59YUN\\Baltrušaitis et al. - 2017 - Multimodal Machine Learning A Survey and Taxonomy.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\EP8VFIG4\\1705.html:text/html},
}

@misc{bhoi_monocular_2019,
	title = {Monocular {Depth} {Estimation}: {A} {Survey}},
	shorttitle = {Monocular {Depth} {Estimation}},
	url = {http://arxiv.org/abs/1901.09402},
	language = {en},
	urldate = {2023-04-09},
	publisher = {arXiv},
	author = {Bhoi, Amlaan},
	month = jan,
	year = {2019},
	note = {arXiv:1901.09402 [cs]},
	keywords = {cited, survey},
	file = {Bhoi - 2019 - Monocular Depth Estimation A Survey.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\I7XMWA6Y\\Bhoi - 2019 - Monocular Depth Estimation A Survey.pdf:application/pdf},
}

@article{masoumian_monocular_2022,
	title = {Monocular {Depth} {Estimation} {Using} {Deep} {Learning}: {A} {Review}},
	volume = {22},
	issn = {1424-8220},
	shorttitle = {Monocular {Depth} {Estimation} {Using} {Deep} {Learning}},
	url = {https://www.mdpi.com/1424-8220/22/14/5353},
	doi = {10.3390/s22145353},
	language = {en},
	number = {14},
	urldate = {2023-04-09},
	journal = {Sensors},
	author = {Masoumian, Armin and Rashwan, Hatem A. and Cristiano, Julián and Asif, M. Salman and Puig, Domenec},
	month = jul,
	year = {2022},
	keywords = {cited, survey},
	pages = {5353},
	file = {Full Text:C\:\\Users\\ksi2lr\\Zotero\\storage\\QRVT5LAA\\Masoumian et al. - 2022 - Monocular Depth Estimation Using Deep Learning A .pdf:application/pdf},
}

@article{ming_deep_2021,
	title = {Deep learning for monocular depth estimation: {A} review},
	volume = {438},
	issn = {0925-2312},
	shorttitle = {Deep learning for monocular depth estimation},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231220320014},
	doi = {10.1016/j.neucom.2020.12.089},
	language = {en},
	urldate = {2023-04-09},
	journal = {Neurocomputing},
	author = {Ming, Yue and Meng, Xuyang and Fan, Chunxiao and Yu, Hui},
	month = may,
	year = {2021},
	keywords = {cited, survey},
	pages = {14--33},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\V3RM2TAE\\Ming et al. - 2021 - Deep learning for monocular depth estimation A re.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\WTA92EJF\\S0925231220320014.html:text/html},
}

@article{noauthor_interpretation_1979,
	title = {The interpretation of structure from motion},
	volume = {203},
	issn = {0080-4649, 2053-9193},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspb.1979.0006},
	doi = {10.1098/rspb.1979.0006},
	language = {en},
	number = {1153},
	urldate = {2023-04-09},
	journal = {Proceedings of the Royal Society of London. Series B. Biological Sciences},
	month = jan,
	year = {1979},
	keywords = {non\_deep\_learning},
	pages = {405--426},
	file = {Submitted Version:C\:\\Users\\ksi2lr\\Zotero\\storage\\FX9XE6YH\\1979 - The interpretation of structure from motion.pdf:application/pdf},
}

@inproceedings{ji_stereo_2020,
	title = {Stereo matching algorithm based on binocular vision},
	doi = {10.1109/IFEEA51475.2020.00177},
	booktitle = {2020 7th {International} {Forum} on {Electrical} {Engineering} and {Automation} ({IFEEA})},
	author = {Ji, Yuanfa and Li, Yongchun and Sun, Xiyan and Yan, Suqing and Guo, Ning},
	month = sep,
	year = {2020},
	keywords = {non\_deep\_learning},
	pages = {843--847},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\ksi2lr\\Zotero\\storage\\L79DGP8C\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\X2824BIC\\Ji et al. - 2020 - Stereo matching algorithm based on binocular visio.pdf:application/pdf},
}

@misc{theis_note_2016,
	title = {A note on the evaluation of generative models},
	url = {http://arxiv.org/abs/1511.01844},
	language = {en},
	urldate = {2023-04-10},
	publisher = {arXiv},
	author = {Theis, Lucas and Oord, Aäron van den and Bethge, Matthias},
	month = apr,
	year = {2016},
	note = {arXiv:1511.01844 [cs, stat]},
	file = {Theis et al. - 2016 - A note on the evaluation of generative models.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\UB7CSF87\\Theis et al. - 2016 - A note on the evaluation of generative models.pdf:application/pdf},
}

@misc{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	language = {en},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv:1502.03167 [cs]},
	file = {Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\DMYAL3GC\\Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf},
}

@misc{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	language = {en},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv:1505.04597 [cs]},
	file = {Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\7FB5TDH3\\Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf},
}

@misc{ulyanov_instance_2017,
	title = {Instance {Normalization}: {The} {Missing} {Ingredient} for {Fast} {Stylization}},
	shorttitle = {Instance {Normalization}},
	url = {http://arxiv.org/abs/1607.08022},
	doi = {10.48550/arXiv.1607.08022},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
	month = nov,
	year = {2017},
	note = {arXiv:1607.08022 [cs]},
	file = {arXiv Fulltext PDF:C\:\\Users\\ksi2lr\\Zotero\\storage\\RE6U949S\\Ulyanov et al. - 2017 - Instance Normalization The Missing Ingredient for.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ksi2lr\\Zotero\\storage\\XPHJID8C\\1607.html:text/html},
}

@misc{ba_layer_2016,
	title = {Layer {Normalization}},
	url = {http://arxiv.org/abs/1607.06450},
	abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This signiﬁcantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
	language = {en},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	month = jul,
	year = {2016},
	note = {arXiv:1607.06450 [cs, stat]},
	file = {Ba et al. - 2016 - Layer Normalization.pdf:C\:\\Users\\ksi2lr\\Zotero\\storage\\A3LA9HXD\\Ba et al. - 2016 - Layer Normalization.pdf:application/pdf},
}


@article{guo2019relightables,
  title={The relightables: Volumetric performance capture of humans with realistic relighting},
  author={Guo, Kaiwen and Lincoln, Peter and Davidson, Philip and Busch, Jay and Yu, Xueming and Whalen, Matt and Harvey, Geoff and Orts-Escolano, Sergio and Pandey, Rohit and Dourgarian, Jason and others},
  journal={ACM Transactions on Graphics (ToG)},
  volume={38},
  number={6},
  pages={1--19},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{collet2015high,
  title={High-quality streamable free-viewpoint video},
  author={Collet, Alvaro and Chuang, Ming and Sweeney, Pat and Gillett, Don and Evseev, Dennis and Calabrese, David and Hoppe, Hugues and Kirk, Adam and Sullivan, Steve},
  journal={ACM Transactions on Graphics (ToG)},
  volume={34},
  number={4},
  pages={1--13},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{pages2018affordable,
  title={Affordable content creation for free-viewpoint video and VR/AR applications},
  author={Pag{\'e}s, Rafael and Amplianitis, Konstantinos and Monaghan, David and Ond{\v{r}}ej, Jan and Smoli{\'c}, Aljosa},
  journal={Journal of Visual Communication and Image Representation},
  volume={53},
  pages={192--201},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{escribano2022texture,
  title={Texture improvement for human shape estimation from a single image},
  author={Escribano, Jorge Gonz{\'a}lez and Ruano, Susana and Swaminathan, Archana and Smyth, David and Smolic, Aljosa},
  booktitle={24th Irish Machine Vision and Image Processing Conference},
  year={2022}
}

@inproceedings{saito2019pifu,
  title={Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization},
  author={Saito, Shunsuke and Huang, Zeng and Natsume, Ryota and Morishima, Shigeo and Kanazawa, Angjoo and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2304--2314},
  year={2019}
}


@inproceedings{saito2020pifuhd,
  title={Pifuhd: Multi-level pixel-aligned implicit function for high-resolution 3d human digitization},
  author={Saito, Shunsuke and Simon, Tomas and Saragih, Jason and Joo, Hanbyul},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={84--93},
  year={2020}
}

@inproceedings{xiu2022icon,
  title={Icon: Implicit clothed humans obtained from normals},
  author={Xiu, Yuliang and Yang, Jinlong and Tzionas, Dimitrios and Black, Michael J},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={13286--13296},
  year={2022},
  organization={IEEE}
}

@article{volograms2021,
  title={Volograms \& {V-SENSE} {V}olumetric {V}ideo {D}ataset},
  author={Pag{\'e}s, Rafael and Zerman, Emin and Amplianitis, Konstantinos and Ond{\v{r}}ej, Jan and Smolic, Aljosa},
  journal={ISO/IEC JTC1/SC29/WG07 MPEG2021/m56767},
  year={2021}
}

@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}