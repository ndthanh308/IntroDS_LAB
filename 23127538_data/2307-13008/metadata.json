{
  "title": "Adaptation of Whisper models to child speech recognition",
  "authors": [
    "Rishabh Jain",
    "Andrei Barcovschi",
    "Mariam Yiwere",
    "Peter Corcoran",
    "Horia Cucu"
  ],
  "submission_date": "2023-07-24T12:54:45+00:00",
  "revised_dates": [],
  "abstract": "Automatic Speech Recognition (ASR) systems often struggle with transcribing child speech due to the lack of large child speech datasets required to accurately train child-friendly ASR models. However, there are huge amounts of annotated adult speech datasets which were used to create multilingual ASR models, such as Whisper. Our work aims to explore whether such models can be adapted to child speech to improve ASR for children. In addition, we compare Whisper child-adaptations with finetuned self-supervised models, such as wav2vec2. We demonstrate that finetuning Whisper on child speech yields significant improvements in ASR performance on child speech, compared to non finetuned Whisper models. Additionally, utilizing self-supervised Wav2vec2 models that have been finetuned on child speech outperforms Whisper finetuning.",
  "categories": [
    "eess.AS",
    "cs.AI"
  ],
  "primary_category": "eess.AS",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13008",
  "pdf_url": null,
  "comment": "Accepted in Interspeech 2023",
  "num_versions": null,
  "size_before_bytes": 0,
  "size_after_bytes": 0
}