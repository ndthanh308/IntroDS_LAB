\begin{thebibliography}{10}

\bibitem{beck2021deep}
Christian Beck, Sebastian Becker, Patrick Cheridito, Arnulf Jentzen, and Ariel
  Neufeld.
\newblock Deep splitting method for parabolic pdes.
\newblock {\em SIAM Journal on Scientific Computing}, 43(5):A3135--A3154, 2021.

\bibitem{beck2019machine}
Christian Beck, Weinan E, and Arnulf Jentzen.
\newblock Machine learning approximation algorithms for high-dimensional fully
  nonlinear partial differential equations and second-order backward stochastic
  differential equations.
\newblock {\em Journal of Nonlinear Science}, 29:1563--1619, 2019.

\bibitem{beck2020overcoming}
Christian Beck, Lukas Gonon, and Arnulf Jentzen.
\newblock Overcoming the curse of dimensionality in the numerical approximation
  of high-dimensional semilinear elliptic partial differential equations.
\newblock {\em arXiv preprint arXiv:2003.00596}, 2020.

\bibitem{beck2020overcoming_ac}
Christian Beck, Fabian Hornung, Martin Hutzenthaler, Arnulf Jentzen, and Thomas
  Kruse.
\newblock Overcoming the curse of dimensionality in the numerical approximation
  of allen--cahn partial differential equations via truncated full-history
  recursive multilevel picard approximations.
\newblock {\em Journal of Numerical Mathematics}, 28(4):197--222, 2020.

\bibitem{becker2020numerical}
Sebastian Becker, Ramon Braunwarth, Martin Hutzenthaler, Arnulf Jentzen, and
  Philippe von Wurstemberger.
\newblock Numerical simulations for full history recursive multilevel picard
  approximations for systems of high-dimensional partial differential
  equations.
\newblock {\em arXiv preprint arXiv:2005.10206}, 2020.

\bibitem{becker2021solving}
Sebastian Becker, Patrick Cheridito, Arnulf Jentzen, and Timo Welti.
\newblock Solving high-dimensional optimal stopping problems using deep
  learning.
\newblock {\em European Journal of Applied Mathematics}, 32(3):470--514, 2021.

\bibitem{bellman1966dynamic}
Richard Bellman.
\newblock {\em Dynamic programming}.
\newblock Princeton University Press, 1957.

\bibitem{cai2021physics}
Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George~Em
  Karniadakis.
\newblock Physics-informed neural networks (pinns) for fluid mechanics: A
  review.
\newblock {\em Acta Mechanica Sinica}, 37(12):1727--1738, 2021.

\bibitem{chan2019machine}
Quentin Chan-Wai-Nam, Joseph Mikael, and Xavier Warin.
\newblock Machine learning for semi linear pdes.
\newblock {\em Journal of scientific computing}, 79(3):1667--1712, 2019.

\bibitem{chinesta2011short}
Francisco Chinesta, Pierre Ladeveze, and Elias Cueto.
\newblock A short review on model order reduction based on proper generalized
  decomposition.
\newblock {\em Archives of Computational Methods in Engineering}, 18(4):395,
  2011.

\bibitem{cho2022separable}
Junwoo Cho, Seungtae Nam, Hyunmo Yang, Seok-Bae Yun, Youngjoon Hong, and
  Eunbyung Park.
\newblock Separable pinn: Mitigating the curse of dimensionality in
  physics-informed neural networks.
\newblock {\em arXiv preprint arXiv:2211.08761}, 2022.

\bibitem{darbon2016algorithms}
J{\'e}r{\^o}me Darbon and Stanley Osher.
\newblock Algorithms for overcoming the curse of dimensionality for certain
  hamilton--jacobi equations arising in control theory and elsewhere.
\newblock {\em Research in the Mathematical Sciences}, 3(1):19, 2016.

\bibitem{fehrman2020convergence}
Benjamin Fehrman, Benjamin Gess, and Arnulf Jentzen.
\newblock Convergence rates for the stochastic gradient descent method for
  non-convex objective functions.
\newblock {\em The Journal of Machine Learning Research}, 21(1):5354--5401,
  2020.

\bibitem{goswami2023learning}
Somdatta Goswami, Ameya~D Jagtap, Hessam Babaee, Bryan~T Susi, and George~Em
  Karniadakis.
\newblock Learning stiff chemical kinetics using extended deep neural
  operators.
\newblock {\em arXiv preprint arXiv:2302.12645}, 2023.

\bibitem{goswami2022physics}
Somdatta Goswami, Minglang Yin, Yue Yu, and George~Em Karniadakis.
\newblock A physics-informed variational deeponet for predicting crack path in
  quasi-brittle materials.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  391:114587, 2022.

\bibitem{goyal2017accurate}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock {\em arXiv preprint arXiv:1706.02677}, 2017.

\bibitem{haghighat2021physics}
Ehsan Haghighat, Maziar Raissi, Adrian Moure, Hector Gomez, and Ruben Juanes.
\newblock A physics-informed deep learning framework for inversion and
  surrogate modeling in solid mechanics.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  379:113741, 2021.

\bibitem{hammer1962adaptive}
PC~Hammer.
\newblock Adaptive control processes: a guided tour (r. bellman), 1962.

\bibitem{han2018solving}
Jiequn Han, Arnulf Jentzen, and Weinan E.
\newblock Solving high-dimensional partial differential equations using deep
  learning.
\newblock {\em Proceedings of the National Academy of Sciences},
  115(34):8505--8510, 2018.

\bibitem{han2017deep}
Jiequn Han, Arnulf Jentzen, et~al.
\newblock Deep learning-based numerical methods for high-dimensional parabolic
  partial differential equations and backward stochastic differential
  equations.
\newblock {\em Communications in mathematics and statistics}, 5(4):349--380,
  2017.

\bibitem{he2023learning}
Di~He, Shanda Li, Wenlei Shi, Xiaotian Gao, Jia Zhang, Jiang Bian, Liwei Wang,
  and Tie-Yan Liu.
\newblock Learning physics-informed neural networks without stacked
  back-propagation.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3034--3047. PMLR, 2023.

\bibitem{henry2017deep}
Pierre Henry-Labordere.
\newblock Deep primal-dual algorithm for bsdes: Applications of machine
  learning to cva and im.
\newblock {\em Available at SSRN 3071506}, 2017.

\bibitem{hu2021extended}
Zheyuan Hu, Ameya~D. Jagtap, George~Em Karniadakis, and Kenji Kawaguchi.
\newblock When do extended physics-informed neural networks (xpinns) improve
  generalization?
\newblock {\em SIAM Journal on Scientific Computing}, 44(5):A3158--A3182, 2022.

\bibitem{hure2020deep}
C{\^o}me Hur{\'e}, Huy{\^e}n Pham, and Xavier Warin.
\newblock Deep backward schemes for high-dimensional nonlinear pdes.
\newblock {\em Mathematics of Computation}, 89(324):1547--1579, 2020.

\bibitem{hutzenthaler2020overcoming}
Martin Hutzenthaler, Arnulf Jentzen, Thomas Kruse, Tuan Anh~Nguyen, and
  Philippe von Wurstemberger.
\newblock Overcoming the curse of dimensionality in the numerical approximation
  of semilinear parabolic partial differential equations.
\newblock {\em Proceedings of the Royal Society A}, 476(2244):20190630, 2020.

\bibitem{hutzenthaler2021multilevel}
Martin Hutzenthaler, Arnulf Jentzen, Thomas Kruse, et~al.
\newblock Multilevel picard iterations for solving smooth semilinear parabolic
  heat equations.
\newblock {\em Partial Differential Equations and Applications}, 2(6):1--31,
  2021.

\bibitem{jagtap2022deep}
Ameya~D Jagtap, Dimitrios Mitsotakis, and George~Em Karniadakis.
\newblock Deep learning of inverse water waves problems using multi-fidelity
  data: Application to serre--green--naghdi equations.
\newblock {\em Ocean Engineering}, 248:110775, 2022.

\bibitem{ji2020three}
Shaolin Ji, Shige Peng, Ying Peng, and Xichuan Zhang.
\newblock Three algorithms for solving high-dimensional fully coupled fbsdes
  through deep learning.
\newblock {\em IEEE Intelligent Systems}, 35(3):71--84, 2020.

\bibitem{karniadakis2021physics}
George~Em Karniadakis, Ioannis~G Kevrekidis, Lu~Lu, Paris Perdikaris, Sifan
  Wang, and Liu Yang.
\newblock Physics-informed machine learning.
\newblock {\em Nature Reviews Physics}, 3(6):422--440, 2021.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em ICLR}, 2015.

\bibitem{lei2019stochastic}
Yunwen Lei, Ting Hu, Guiying Li, and Ke~Tang.
\newblock Stochastic gradient descent for nonconvex learning without bounded
  gradient assumptions.
\newblock {\em IEEE transactions on neural networks and learning systems},
  31(10):4394--4400, 2019.

\bibitem{lu2021priori}
Jianfeng Lu, Yulong Lu, and Min Wang.
\newblock A priori generalization analysis of the deep ritz method for solving
  high dimensional elliptic equations.
\newblock {\em arXiv preprint arXiv:2101.01708}, 2021.

\bibitem{lu2019deeponet}
Lu~Lu, Pengzhan Jin, Guofei Pang, Zhongqiang Zhang, and George~Em Karniadakis.
\newblock Learning nonlinear operators via deeponet based on the universal
  approximation theorem of operators.
\newblock {\em Nature machine intelligence}, 3(3):218--229, 2021.

\bibitem{Luo2020TwoLayerNN}
Tao Luo and H.~Yang.
\newblock Two-layer neural networks for partial differential equations:
  Optimization and generalization theory.
\newblock {\em ArXiv}, abs/2006.15733, 2020.

\bibitem{martens2020neural}
Kaspar M{\"a}rtens and Christopher Yau.
\newblock Neural decomposition: Functional anova with variational autoencoders.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2917--2927. PMLR, 2020.

\bibitem{mertikopoulos2020almost}
Panayotis Mertikopoulos, Nadav Hallak, Ali Kavis, and Volkan Cevher.
\newblock On the almost sure convergence of stochastic gradient descent in
  non-convex problems.
\newblock {\em Advances in Neural Information Processing Systems},
  33:1117--1128, 2020.

\bibitem{mishra2020estimates}
Siddhartha Mishra and Roberto Molinaro.
\newblock Estimates on the generalization error of physics informed neural
  networks (pinns) for approximating pdes.
\newblock {\em arXiv preprint arXiv:2006.16144}, 2020.

\bibitem{narayanan2021efficient}
Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa
  Patwary, Vijay Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie
  Bernauer, Bryan Catanzaro, et~al.
\newblock Efficient large-scale language model training on gpu clusters using
  megatron-lm.
\newblock In {\em Proceedings of the International Conference for High
  Performance Computing, Networking, Storage and Analysis}, pages 1--15, 2021.

\bibitem{perdikaris2016multifidelity}
Paris Perdikaris, Daniele Venturi, and George~Em Karniadakis.
\newblock Multifidelity information fusion algorithms for high-dimensional
  systems and massive data sets.
\newblock {\em SIAM Journal on Scientific Computing}, 38(4):B521--B538, 2016.

\bibitem{raissi2018forward}
Maziar Raissi.
\newblock Forward-backward stochastic neural networks: Deep learning of
  high-dimensional partial differential equations.
\newblock {\em arXiv preprint arXiv:1804.07010}, 2018.

\bibitem{raissi2018hidden}
Maziar Raissi and George~Em Karniadakis.
\newblock Hidden physics models: Machine learning of nonlinear partial
  differential equations.
\newblock {\em Journal of Computational Physics}, 357:125--141, 2018.

\bibitem{raissi2019physics}
Maziar Raissi, Paris Perdikaris, and George~E Karniadakis.
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock {\em Journal of Computational Physics}, 378:686--707, 2019.

\bibitem{shafahi2019adversarial}
Ali Shafahi, Mahyar Najibi, Mohammad~Amin Ghiasi, Zheng Xu, John Dickerson,
  Christoph Studer, Larry~S Davis, Gavin Taylor, and Tom Goldstein.
\newblock Adversarial training for free!
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{shin2020convergence}
Yeonjong Shin, Jerome Darbon, and George~Em Karniadakis.
\newblock On the convergence of physics informed neural networks for linear
  second-order elliptic and parabolic type pdes.
\newblock {\em arXiv preprint arXiv:2004.01806}, 2020.

\bibitem{shukla2023deep}
Khemraj Shukla, Vivek Oommen, Ahmad Peyvan, Michael Penwarden, Luis Bravo,
  Anindya Ghoshal, Robert~M Kirby, and George~Em Karniadakis.
\newblock Deep neural operators can serve as accurate surrogates for shape
  optimization: a case study for airfoils.
\newblock {\em arXiv preprint arXiv:2302.00807}, 2023.

\bibitem{wang20222}
Chuwei Wang, Shanda Li, Di~He, and Liwei Wang.
\newblock Is \$l{\textasciicircum}2\$ physics informed loss always suitable for
  training physics informed neural network?
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{wang2022tensor}
Yifan Wang, Pengzhan Jin, and Hehu Xie.
\newblock Tensor neural network and its numerical integration.
\newblock {\em arXiv preprint arXiv:2207.02754}, 2022.

\bibitem{wang2022solving}
Yifan Wang, Yangfei Liao, and Hehu Xie.
\newblock Solving schr$\backslash$"$\{$o$\}$ dinger equation using tensor
  neural network.
\newblock {\em arXiv preprint arXiv:2209.12572}, 2022.

\bibitem{yang2019adversarial}
Yibo Yang and Paris Perdikaris.
\newblock Adversarial uncertainty quantification in physics-informed neural
  networks.
\newblock {\em Journal of Computational Physics}, 394:136--152, 2019.

\bibitem{zang2020weak}
Yaohua Zang, Gang Bao, Xiaojing Ye, and Haomin Zhou.
\newblock Weak adversarial networks for high-dimensional partial differential
  equations.
\newblock {\em Journal of Computational Physics}, 411:109409, 2020.

\bibitem{zhang2020learning}
Dongkun Zhang, Ling Guo, and George~Em Karniadakis.
\newblock Learning in modal space: Solving time-dependent stochastic pdes using
  physics-informed neural networks.
\newblock {\em SIAM Journal on Scientific Computing}, 42(2):A639--A665, 2020.

\bibitem{zhang2012error}
Zhongqiang Zhang, Minseok Choi, and George~Em Karniadakis.
\newblock Error estimates for the anova method with polynomial chaos
  interpolation: Tensor product functions.
\newblock {\em SIAM Journal on Scientific Computing}, 34(2):A1165--A1186, 2012.

\end{thebibliography}
