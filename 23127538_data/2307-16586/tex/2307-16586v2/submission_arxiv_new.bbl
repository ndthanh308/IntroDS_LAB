\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Butler et~al.(2012)Butler, Wulff, Stanley, and
  Black}]{butler2012sintel}
Butler, D.~J.; Wulff, J.; Stanley, G.~B.; and Black, M.~J. 2012.
\newblock A naturalistic open source movie for optical flow evaluation.
\newblock In \emph{Computer Vision--ECCV 2012: 12th European Conference on
  Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part VI
  12}, 611--625. Springer.

\bibitem[{Chen et~al.(2020)Chen, Kornblith, Norouzi, and
  Hinton}]{chen2020contrastive}
Chen, T.; Kornblith, S.; Norouzi, M.; and Hinton, G. 2020.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, 1597--1607.
  PMLR.

\bibitem[{Dong, Cao, and Fu(2023)}]{dong2023rethinking}
Dong, Q.; Cao, C.; and Fu, Y. 2023.
\newblock Rethinking Optical Flow from Geometric Matching Consistent
  Perspective.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 1337--1347.

\bibitem[{Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly
  et~al.}]{dosovitskiy2020ViT}
Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai, X.;
  Unterthiner, T.; Dehghani, M.; Minderer, M.; Heigold, G.; Gelly, S.; et~al.
  2020.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}.

\bibitem[{Dosovitskiy et~al.(2015)Dosovitskiy, Fischer, Ilg, Hausser, Hazirbas,
  Golkov, Van Der~Smagt, Cremers, and Brox}]{dosovitskiy2015flownet}
Dosovitskiy, A.; Fischer, P.; Ilg, E.; Hausser, P.; Hazirbas, C.; Golkov, V.;
  Van Der~Smagt, P.; Cremers, D.; and Brox, T. 2015.
\newblock Flownet: Learning optical flow with convolutional networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 2758--2766.

\bibitem[{Gaidon et~al.(2016)Gaidon, Wang, Cabon, and Vig}]{VirtualKITTI}
Gaidon, A.; Wang, Q.; Cabon, Y.; and Vig, E. 2016.
\newblock Virtual Worlds as Proxy for Multi-Object Tracking Analysis.
\newblock In \emph{CVPR}.

\bibitem[{Gao et~al.(2020)Gao, Saraf, Huang, and Kopf}]{video_completion}
Gao, C.; Saraf, A.; Huang, J.-B.; and Kopf, J. 2020.
\newblock Flow-edge guided video completion.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XII 16}, 713--729.
  Springer.

\bibitem[{Geiger et~al.(2013)Geiger, Lenz, Stiller, and
  Urtasun}]{geiger2013kitti}
Geiger, A.; Lenz, P.; Stiller, C.; and Urtasun, R. 2013.
\newblock Vision meets robotics: The kitti dataset.
\newblock \emph{The International Journal of Robotics Research}, 32(11):
  1231--1237.

\bibitem[{He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick}]{he2022MAE}
He, K.; Chen, X.; Xie, S.; Li, Y.; Doll{\'a}r, P.; and Girshick, R. 2022.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 16000--16009.

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016resnet}
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 770--778.

\bibitem[{Horn and Schunck(1981)}]{horn1981HS}
Horn, B.~K.; and Schunck, B.~G. 1981.
\newblock Determining optical flow.
\newblock \emph{Artificial intelligence}, 17(1-3): 185--203.

\bibitem[{Huang et~al.(2022{\natexlab{a}})Huang, Shi, Zhang, Wang, Cheung, Qin,
  Dai, and Li}]{huang2022flowformer}
Huang, Z.; Shi, X.; Zhang, C.; Wang, Q.; Cheung, K.~C.; Qin, H.; Dai, J.; and
  Li, H. 2022{\natexlab{a}}.
\newblock Flowformer: A transformer architecture for optical flow.
\newblock In \emph{European Conference on Computer Vision}, 668--685. Springer.

\bibitem[{Huang et~al.(2022{\natexlab{b}})Huang, Zhang, Heng, Shi, and
  Zhou}]{RIFE}
Huang, Z.; Zhang, T.; Heng, W.; Shi, B.; and Zhou, S. 2022{\natexlab{b}}.
\newblock Real-time intermediate flow estimation for video frame interpolation.
\newblock In \emph{European Conference on Computer Vision}, 624--642. Springer.

\bibitem[{Hui, Tang, and Loy(2018)}]{hui2018liteflownet}
Hui, T.-W.; Tang, X.; and Loy, C.~C. 2018.
\newblock Liteflownet: A lightweight convolutional neural network for optical
  flow estimation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 8981--8989.

\bibitem[{Hui, Tang, and Loy(2020)}]{hui2020liteflownet2}
Hui, T.-W.; Tang, X.; and Loy, C.~C. 2020.
\newblock A lightweight optical flow cnnâ€”revisiting data fidelity and
  regularization.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 43(8): 2555--2569.

\bibitem[{Jaegle et~al.(2021)Jaegle, Borgeaud, Alayrac, Doersch, Ionescu, Ding,
  Koppula, Zoran, Brock, Shelhamer et~al.}]{jaegle2021perceiver}
Jaegle, A.; Borgeaud, S.; Alayrac, J.-B.; Doersch, C.; Ionescu, C.; Ding, D.;
  Koppula, S.; Zoran, D.; Brock, A.; Shelhamer, E.; et~al. 2021.
\newblock Perceiver IO: A General Architecture for Structured Inputs \&
  Outputs.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Jiang et~al.(2021{\natexlab{a}})Jiang, Campbell, Lu, Li, and
  Hartley}]{jiang2021GMA}
Jiang, S.; Campbell, D.; Lu, Y.; Li, H.; and Hartley, R. 2021{\natexlab{a}}.
\newblock Learning to estimate hidden motions with global motion aggregation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 9772--9781.

\bibitem[{Jiang et~al.(2021{\natexlab{b}})Jiang, Lu, Li, and
  Hartley}]{jiang2021FMRAFT}
Jiang, S.; Lu, Y.; Li, H.; and Hartley, R. 2021{\natexlab{b}}.
\newblock Learning optical flow from a few matches.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 16592--16600.

\bibitem[{Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson,
  Xiao, Whitehead, Berg, Lo et~al.}]{kirillov2023SAM}
Kirillov, A.; Mintun, E.; Ravi, N.; Mao, H.; Rolland, C.; Gustafson, L.; Xiao,
  T.; Whitehead, S.; Berg, A.~C.; Lo, W.-Y.; et~al. 2023.
\newblock Segment anything.
\newblock \emph{arXiv preprint arXiv:2304.02643}.

\bibitem[{Kondermann et~al.(2016)Kondermann, Nair, Honauer, Krispin, Andrulis,
  Brock, Gussefeld, Rahimimoghaddam, Hofmann, Brenner
  et~al.}]{kondermann2016hd1k}
Kondermann, D.; Nair, R.; Honauer, K.; Krispin, K.; Andrulis, J.; Brock, A.;
  Gussefeld, B.; Rahimimoghaddam, M.; Hofmann, S.; Brenner, C.; et~al. 2016.
\newblock The hci benchmark suite: Stereo and flow ground truth with
  uncertainties for urban autonomous driving.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition Workshops}, 19--28.

\bibitem[{Krizhevsky, Sutskever, and Hinton(2012)}]{krizhevsky2012imagenet}
Krizhevsky, A.; Sutskever, I.; and Hinton, G.~E. 2012.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 25.

\bibitem[{Lucas and Kanade(1981)}]{lucas198LK}
Lucas, B.~D.; and Kanade, T. 1981.
\newblock An iterative image registration technique with an application to
  stereo vision.
\newblock In \emph{IJCAI'81: 7th international joint conference on Artificial
  intelligence}, volume~2, 674--679.

\bibitem[{Mayer et~al.(2016)Mayer, Ilg, Hausser, Fischer, Cremers, Dosovitskiy,
  and Brox}]{mayer2016flyingthings}
Mayer, N.; Ilg, E.; Hausser, P.; Fischer, P.; Cremers, D.; Dosovitskiy, A.; and
  Brox, T. 2016.
\newblock A large dataset to train convolutional networks for disparity,
  optical flow, and scene flow estimation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 4040--4048.

\bibitem[{Mehl et~al.(2023)Mehl, Schmalfuss, Jahedi, Nalivayko, and
  Bruhn}]{mehl2023spring}
Mehl, L.; Schmalfuss, J.; Jahedi, A.; Nalivayko, Y.; and Bruhn, A. 2023.
\newblock Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene
  Flow, Optical Flow and Stereo.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 4981--4991.

\bibitem[{Shi et~al.(2023)Shi, Huang, Li, Zhang, Cheung, See, Qin, Dai, and
  Li}]{shi2023flowformer++}
Shi, X.; Huang, Z.; Li, D.; Zhang, M.; Cheung, K.~C.; See, S.; Qin, H.; Dai,
  J.; and Li, H. 2023.
\newblock Flowformer++: Masked cost volume autoencoding for pretraining optical
  flow estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 1599--1610.

\bibitem[{Simonyan and Zisserman(2014)}]{simonyan2014vgg}
Simonyan, K.; and Zisserman, A. 2014.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}.

\bibitem[{Sui et~al.(2022)Sui, Li, Geng, Wu, Xu, Liu, Goh, and
  Zhu}]{sui2022craft}
Sui, X.; Li, S.; Geng, X.; Wu, Y.; Xu, X.; Liu, Y.; Goh, R.; and Zhu, H. 2022.
\newblock Craft: Cross-attentional flow transformer for robust optical flow.
\newblock In \emph{Proceedings of the IEEE/CVF conference on Computer Vision
  and Pattern Recognition}, 17602--17611.

\bibitem[{Sun et~al.(2021)Sun, Vlasic, Herrmann, Jampani, Krainin, Chang,
  Zabih, Freeman, and Liu}]{sun2021autoflow}
Sun, D.; Vlasic, D.; Herrmann, C.; Jampani, V.; Krainin, M.; Chang, H.; Zabih,
  R.; Freeman, W.~T.; and Liu, C. 2021.
\newblock Autoflow: Learning a better training set for optical flow.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10093--10102.

\bibitem[{Sun et~al.(2018{\natexlab{a}})Sun, Yang, Liu, and Kautz}]{sun2018pwc}
Sun, D.; Yang, X.; Liu, M.-Y.; and Kautz, J. 2018{\natexlab{a}}.
\newblock Pwc-net: Cnns for optical flow using pyramid, warping, and cost
  volume.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 8934--8943.

\bibitem[{Sun et~al.(2019)Sun, Yang, Liu, and Kautz}]{sun2019PWC++}
Sun, D.; Yang, X.; Liu, M.-Y.; and Kautz, J. 2019.
\newblock Models matter, so does training: An empirical study of cnns for
  optical flow estimation.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 42(6): 1408--1423.

\bibitem[{Sun et~al.(2022)Sun, Chen, Zhu, Guo, and Li}]{sun2022skflow}
Sun, S.; Chen, Y.; Zhu, Y.; Guo, G.; and Li, G. 2022.
\newblock Skflow: Learning optical flow with super kernels.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:
  11313--11326.

\bibitem[{Sun et~al.(2018{\natexlab{b}})Sun, Kuang, Sheng, Ouyang, and
  Zhang}]{video_action}
Sun, S.; Kuang, Z.; Sheng, L.; Ouyang, W.; and Zhang, W. 2018{\natexlab{b}}.
\newblock Optical flow guided feature: A fast and robust motion representation
  for video action recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 1390--1399.

\bibitem[{Teed and Deng(2020)}]{teed2020raft}
Teed, Z.; and Deng, J. 2020.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, 402--419.
  Springer.

\bibitem[{Vincent et~al.(2008)Vincent, Larochelle, Bengio, and
  Manzagol}]{vincent2008autoencoding}
Vincent, P.; Larochelle, H.; Bengio, Y.; and Manzagol, P.-A. 2008.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, 1096--1103.

\bibitem[{Xu et~al.(2022)Xu, Zhang, Cai, Rezatofighi, and Tao}]{xu2022gmflow}
Xu, H.; Zhang, J.; Cai, J.; Rezatofighi, H.; and Tao, D. 2022.
\newblock Gmflow: Learning optical flow via global matching.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 8121--8130.

\bibitem[{Yin, Darrell, and Yu(2019)}]{yin2019HD3}
Yin, Z.; Darrell, T.; and Yu, F. 2019.
\newblock Hierarchical discrete distribution decomposition for match density
  estimation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 6044--6053.

\bibitem[{Zhang et~al.(2023)Zhang, Han, Qiao, Kim, Bae, Lee, and
  Hong}]{zhang2023mobileSAM}
Zhang, C.; Han, D.; Qiao, Y.; Kim, J.~U.; Bae, S.-H.; Lee, S.; and Hong, C.~S.
  2023.
\newblock Faster Segment Anything: Towards Lightweight SAM for Mobile
  Applications.
\newblock \emph{arXiv preprint arXiv:2306.14289}.

\bibitem[{Zhang et~al.(2021)Zhang, Woodford, Prisacariu, and
  Torr}]{zhang2021separable}
Zhang, F.; Woodford, O.~J.; Prisacariu, V.~A.; and Torr, P.~H. 2021.
\newblock Separable flow: Learning motion cost volumes for optical flow
  estimation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, 10807--10817.

\bibitem[{Zhao et~al.(2022)Zhao, Zhao, Zhang, Zhou, and
  Metaxas}]{zhao2022gmflownet}
Zhao, S.; Zhao, L.; Zhang, Z.; Zhou, E.; and Metaxas, D. 2022.
\newblock Global matching with overlapping attention for optical flow
  estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 17592--17601.

\end{thebibliography}
