@inproceedings{RIFE,
  title={Real-time intermediate flow estimation for video frame interpolation},
  author={Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},
  booktitle={European Conference on Computer Vision},
  pages={624--642},
  year={2022},
  organization={Springer}
}

@inproceedings{video_completion,
  title={Flow-edge guided video completion},
  author={Gao, Chen and Saraf, Ayush and Huang, Jia-Bin and Kopf, Johannes},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XII 16},
  pages={713--729},
  year={2020},
  organization={Springer}
}

@inproceedings{video_action,
  title={Optical flow guided feature: A fast and robust motion representation for video action recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1390--1399},
  year={2018}
}

@inproceedings{dosovitskiy2015flownet,
  title={Flownet: Learning optical flow with convolutional networks},
  author={Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Van Der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2758--2766},
  year={2015}
}

@inproceedings{sun2018pwc,
  title={Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8934--8943},
  year={2018}
}

@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  pages={402--419},
  year={2020},
  organization={Springer}
}

@inproceedings{jiang2021GMA,
  title={Learning to estimate hidden motions with global motion aggregation},
  author={Jiang, Shihao and Campbell, Dylan and Lu, Yao and Li, Hongdong and Hartley, Richard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9772--9781},
  year={2021}
}

@inproceedings{huang2022flowformer,
  title={Flowformer: A transformer architecture for optical flow},
  author={Huang, Zhaoyang and Shi, Xiaoyu and Zhang, Chao and Wang, Qiang and Cheung, Ka Chun and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  booktitle={European Conference on Computer Vision},
  pages={668--685},
  year={2022},
  organization={Springer}
}

@inproceedings{mayer2016flyingthings,
  title={A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation},
  author={Mayer, Nikolaus and Ilg, Eddy and Hausser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4040--4048},
  year={2016}
}

@inproceedings{sun2021autoflow,
  title={Autoflow: Learning a better training set for optical flow},
  author={Sun, Deqing and Vlasic, Daniel and Herrmann, Charles and Jampani, Varun and Krainin, Michael and Chang, Huiwen and Zabih, Ramin and Freeman, William T and Liu, Ce},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10093--10102},
  year={2021}
}

@inproceedings{shi2023flowformer++,
  title={Flowformer++: Masked cost volume autoencoding for pretraining optical flow estimation},
  author={Shi, Xiaoyu and Huang, Zhaoyang and Li, Dasong and Zhang, Manyuan and Cheung, Ka Chun and See, Simon and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1599--1610},
  year={2023}
}

@inproceedings{dong2023rethinking,
  title={Rethinking Optical Flow from Geometric Matching Consistent Perspective},
  author={Dong, Qiaole and Cao, Chenjie and Fu, Yanwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1337--1347},
  year={2023}
}

@article{kirillov2023SAM,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@inproceedings{butler2012sintel,
  title={A naturalistic open source movie for optical flow evaluation},
  author={Butler, Daniel J and Wulff, Jonas and Stanley, Garrett B and Black, Michael J},
  booktitle={Computer Vision--ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part VI 12},
  pages={611--625},
  year={2012},
  organization={Springer}
}

@article{geiger2013kitti,
  title={Vision meets robotics: The kitti dataset},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1231--1237},
  year={2013},
  publisher={Sage Publications Sage UK: London, England}
}

@inproceedings{lucas198LK,
  title={An iterative image registration technique with an application to stereo vision},
  author={Lucas, Bruce D and Kanade, Takeo},
  booktitle={IJCAI'81: 7th international joint conference on Artificial intelligence},
  volume={2},
  pages={674--679},
  year={1981}
}

@article{horn1981HS,
  title={Determining optical flow},
  author={Horn, Berthold KP and Schunck, Brian G},
  journal={Artificial intelligence},
  volume={17},
  number={1-3},
  pages={185--203},
  year={1981},
  publisher={Elsevier}
}

@inproceedings{mehl2023spring,
  title={Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo},
  author={Mehl, Lukas and Schmalfuss, Jenny and Jahedi, Azin and Nalivayko, Yaroslava and Bruhn, Andr{\'e}s},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4981--4991},
  year={2023}
}

@inproceedings{kondermann2016hd1k,
  title={The hci benchmark suite: Stereo and flow ground truth with uncertainties for urban autonomous driving},
  author={Kondermann, Daniel and Nair, Rahul and Honauer, Katrin and Krispin, Karsten and Andrulis, Jonas and Brock, Alexander and Gussefeld, Burkhard and Rahimimoghaddam, Mohsen and Hofmann, Sabine and Brenner, Claus and others},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={19--28},
  year={2016}
}

@article{simonyan2014vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{vaswani2017transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020ViT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@inproceedings{chen2020contrastive,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{vincent2008autoencoding,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008}
}

@inproceedings{he2022MAE,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@article{zhang2023control,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Agrawala, Maneesh},
  journal={arXiv preprint arXiv:2302.05543},
  year={2023}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver IO: A General Architecture for Structured Inputs \& Outputs},
  author={Jaegle, Andrew and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Doersch, Carl and Ionescu, Catalin and Ding, David and Koppula, Skanda and Zoran, Daniel and Brock, Andrew and Shelhamer, Evan and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{yin2019HD3,
  title={Hierarchical discrete distribution decomposition for match density estimation},
  author={Yin, Zhichao and Darrell, Trevor and Yu, Fisher},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6044--6053},
  year={2019}
}

@inproceedings{hui2018liteflownet,
  title={Liteflownet: A lightweight convolutional neural network for optical flow estimation},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8981--8989},
  year={2018}
}

@article{hui2020liteflownet2,
  title={A lightweight optical flow cnnâ€”revisiting data fidelity and regularization},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={8},
  pages={2555--2569},
  year={2020},
  publisher={IEEE}
}

@article{sun2019PWC++,
  title={Models matter, so does training: An empirical study of cnns for optical flow estimation},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={6},
  pages={1408--1423},
  year={2019},
  publisher={IEEE}
}

@inproceedings{zhang2021separable,
  title={Separable flow: Learning motion cost volumes for optical flow estimation},
  author={Zhang, Feihu and Woodford, Oliver J and Prisacariu, Victor Adrian and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10807--10817},
  year={2021}
}

@inproceedings{jiang2021FMRAFT,
  title={Learning optical flow from a few matches},
  author={Jiang, Shihao and Lu, Yao and Li, Hongdong and Hartley, Richard},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16592--16600},
  year={2021}
}

@inproceedings{xu2022gmflow,
  title={Gmflow: Learning optical flow via global matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8121--8130},
  year={2022}
}

@inproceedings{zhao2022gmflownet,
  title={Global matching with overlapping attention for optical flow estimation},
  author={Zhao, Shiyu and Zhao, Long and Zhang, Zhixing and Zhou, Enyu and Metaxas, Dimitris},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17592--17601},
  year={2022}
}

@inproceedings{sui2022craft,
  title={Craft: Cross-attentional flow transformer for robust optical flow},
  author={Sui, Xiuchao and Li, Shaohua and Geng, Xue and Wu, Yan and Xu, Xinxing and Liu, Yong and Goh, Rick and Zhu, Hongyuan},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={17602--17611},
  year={2022}
}

@article{sun2022skflow,
  title={Skflow: Learning optical flow with super kernels},
  author={Sun, Shangkun and Chen, Yuanqi and Zhu, Yu and Guo, Guodong and Li, Ge},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={11313--11326},
  year={2022}
}

@article{zhang2023mobileSAM,
  title={Faster Segment Anything: Towards Lightweight SAM for Mobile Applications},
  author={Zhang, Chaoning and Han, Dongshen and Qiao, Yu and Kim, Jung Uk and Bae, Sung-Ho and Lee, Seungkyu and Hong, Choong Seon},
  journal={arXiv preprint arXiv:2306.14289},
  year={2023}
}

@inproceedings{VirtualKITTI,
author = {Gaidon, A and Wang, Q and Cabon, Y and Vig, E},
title = {Virtual Worlds as Proxy for Multi-Object Tracking Analysis},
booktitle = {CVPR},
year = {2016}
}

@article{shi2023videoflow,
  title={Videoflow: Exploiting temporal cues for multi-frame optical flow estimation},
  author={Shi, Xiaoyu and Huang, Zhaoyang and Bian, Weikang and Li, Dasong and Zhang, Manyuan and Cheung, Ka Chun and See, Simon and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2303.08340},
  year={2023}
}

@misc{cheng2023contextaware,
      title={Context-Aware Iteration Policy Network for Efficient Optical Flow Estimation}, 
      author={Ri Cheng and Ruian He and Xuhao Jiang and Shili Zhou and Weimin Tan and Bo Yan},
      year={2023},
      eprint={2312.07180},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{zhang2022dino,
  title={DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel and Shum, Heung-Yeung},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}