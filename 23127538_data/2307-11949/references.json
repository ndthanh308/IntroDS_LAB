{
  "2304-04782": {
    "title": "Reinforcement Learning from Passive Data via Latent Intentions",
    "authors": [
      "Dibya Ghosh",
      "Chethan Bhateja",
      "S. Levine"
    ],
    "submission_date": "2023-04-10",
    "semantic_scholar_id": "abec4dcbff2c6be5578ee5bf6c96347e7901b6a0"
  },
  "2304-01203": {
    "title": "Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning",
    "authors": [
      "Tongzhou Wang",
      "A. Torralba",
      "Phillip Isola",
      "Amy Zhang"
    ],
    "submission_date": "2023-04-03",
    "semantic_scholar_id": "1ad85b1a902cd37c855dbedf5bd17c536628b611"
  },
  "2303-15810": {
    "title": "Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization",
    "authors": [
      "Haoran Xu",
      "Li Jiang",
      "Jianxiong Li",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Victor Chan",
      "Xianyuan Zhan"
    ],
    "submission_date": "2023-03-28",
    "semantic_scholar_id": "18d82f2a4aa1e2c1c4b447876c95b8f7e717e1a1"
  },
  "2303-11166": {
    "title": "Imitating Graph-Based Planning with Goal-Conditioned Policies",
    "authors": [
      "Junsup Kim",
      "Younggyo Seo",
      "Sungsoo Ahn",
      "Kyunghwan Son",
      "Jinwoo Shin"
    ],
    "submission_date": "2023-03-20",
    "semantic_scholar_id": "4a425aacde98c2099f721c8557a84f571af56ed7"
  },
  "2301-02328": {
    "title": "Extreme Q-Learning: MaxEnt RL without Entropy",
    "authors": [
      "Divyansh Garg",
      "Joey Hejna",
      "M. Geist",
      "Stefano Ermon"
    ],
    "submission_date": "2023-01-05",
    "semantic_scholar_id": "2c2180fbe7f38e88b1123e5fab43785b66814e5d"
  },
  "2210-13435": {
    "title": "Dichotomy of Control: Separating What You Can Control from What You Cannot",
    "authors": [
      "Mengjiao Yang",
      "D. Schuurmans",
      "P. Abbeel",
      "Ofir Nachum"
    ],
    "submission_date": "2022-10-24",
    "semantic_scholar_id": "834c8c95ff1129eb197bfdfa18f6bdf3c11c205c"
  },
  "2210-08323": {
    "title": "A Policy-Guided Imitation Approach for Offline Reinforcement Learning",
    "authors": [
      "Haoran Xu",
      "Li Jiang",
      "Jianxiong Li",
      "Xianyuan Zhan"
    ],
    "submission_date": "2022-10-15",
    "semantic_scholar_id": "60380ee913d20e722368245f23e0d4baf52e139a"
  },
  "2210-06518": {
    "title": "Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories",
    "authors": [
      "Qinqing Zheng",
      "Mikael Henaff",
      "Brandon Amos",
      "Aditya Grover"
    ],
    "submission_date": "2022-10-12",
    "semantic_scholar_id": "3aea4d8765e5677ce38d5d35b35b5ef82b7e5277"
  },
  "2210-06601": {
    "title": "Generalization with Lossy Affordances: Leveraging Broad Offline Data for Learning Visuomotor Tasks",
    "authors": [
      "Kuan Fang",
      "Patrick Yin",
      "Ashvin Nair",
      "H. Walke",
      "Ge Yan",
      "S. Levine"
    ],
    "submission_date": "2022-10-12",
    "semantic_scholar_id": "87a00037444092e8ada8d3bb4c1f8c6baededdc0"
  },
  "2210-00030": {
    "title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training",
    "authors": [
      "Yecheng Jason Ma",
      "Shagun Sodhani",
      "Dinesh Jayaraman",
      "Osbert Bastani",
      "Vikash Kumar",
      "Amy Zhang"
    ],
    "submission_date": "2022-09-30",
    "semantic_scholar_id": "3fbe2e8413df0207c26ff393c9aaa8488e3ca4c3"
  },
  "2209-08959": {
    "title": "Latent Plans for Task-Agnostic Offline Reinforcement Learning",
    "authors": [
      "Erick Rosete-Beas",
      "Oier Mees",
      "Gabriel Kalweit",
      "Joschka Boedecker",
      "Wolfram Burgard"
    ],
    "submission_date": "2022-09-19",
    "semantic_scholar_id": "bd3a0bbabae3260098e06bfb615147fb6d34e55a"
  },
  "2209-01947": {
    "title": "MO2: Model-Based Offline Options",
    "authors": [
      "Sasha Salter",
      "Markus Wulfmeier",
      "Dhruva Tirumala",
      "N. Heess",
      "Martin A. Riedmiller",
      "R. Hadsell",
      "Dushyant Rao"
    ],
    "submission_date": "2022-09-05",
    "semantic_scholar_id": "a7934cf662959e452636f9f90adf3cc4fe40caa2"
  },
  "2208-10291": {
    "title": "Efficient Planning in a Compact Latent Action Space",
    "authors": [
      "Zhengyao Jiang",
      "Tianjun Zhang",
      "Michael Janner",
      "Yueying Li",
      "Tim Rocktaschel",
      "Edward Grefenstette",
      "Yuandong Tian"
    ],
    "submission_date": "2022-08-22",
    "semantic_scholar_id": "748c9aa5a31f279fa07b84238aa5ba748e9df40d"
  },
  "2207-10295": {
    "title": "Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning",
    "authors": [
      "Adam R. Villaflor",
      "Zheng Huang",
      "Swapnil Pande",
      "J. Dolan",
      "J. Schneider"
    ],
    "submission_date": "2022-07-21",
    "semantic_scholar_id": "7b604cd12bfd735f16d2097357b3d6ca584d53a1"
  },
  "2207-07560": {
    "title": "Skill-based Model-based Reinforcement Learning",
    "authors": [
      "Lu Shi",
      "Joseph J. Lim",
      "Youngwoon Lee"
    ],
    "submission_date": "2022-07-15",
    "semantic_scholar_id": "8e9d84a7b2db57adda8d639c6d54c8977ef10761"
  },
  "2206-11795": {
    "title": "Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos",
    "authors": [
      "Bowen Baker",
      "Ilge Akkaya",
      "P. Zhokhov",
      "Joost Huizinga",
      "Jie Tang",
      "Adrien Ecoffet",
      "Brandon Houghton",
      "Raul Sampedro",
      "J. Clune"
    ],
    "submission_date": "2022-06-23",
    "semantic_scholar_id": "65fc1f1c567801fee3788974e753cdbf934f07e9"
  },
  "2206-07568": {
    "title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Benjamin Eysenbach",
      "Tianjun Zhang",
      "R. Salakhutdinov",
      "S. Levine"
    ],
    "submission_date": "2022-06-15",
    "semantic_scholar_id": "53dcf467fbded741dd08902d4203a9b57e889c87"
  },
  "2206-03023": {
    "title": "How Far I'll Go: Offline Goal-Conditioned Reinforcement Learning via f-Advantage Regression",
    "authors": [
      "Yecheng Jason Ma",
      "Jason Yan",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "submission_date": "2022-06-07",
    "semantic_scholar_id": "cb3631f12b4465f4396380b61a651f0c74763480"
  },
  "2205-11790": {
    "title": "Hierarchical Planning Through Goal-Conditioned Offline Reinforcement Learning",
    "authors": [
      "Jinning Li",
      "Chen Tang",
      "M. Tomizuka",
      "Wei Zhan"
    ],
    "submission_date": "2022-05-24",
    "semantic_scholar_id": "f593dc96b20ce8427182e773e3b2192d707706a8"
  },
  "2205-09991": {
    "title": "Planning with Diffusion for Flexible Behavior Synthesis",
    "authors": [
      "Michael Janner",
      "Yilun Du",
      "J. Tenenbaum",
      "S. Levine"
    ],
    "submission_date": "2022-05-20",
    "semantic_scholar_id": "3ebdd3db0dd91069fa0cd31cbf8308b60b1b565e"
  },
  "2205-08129": {
    "title": "Planning to Practice: Efficient Online Fine-Tuning by Composing Goals in Latent Space",
    "authors": [
      "Kuan Fang",
      "Patrick Yin",
      "Ashvin Nair",
      "S. Levine"
    ],
    "submission_date": "2022-05-17",
    "semantic_scholar_id": "3b51a29424b619ec5ce29125c4b88d8e24a09328"
  },
  "2204-13695": {
    "title": "Bilinear value networks",
    "authors": [
      "Zhang-Wei Hong",
      "Ge Yang",
      "Pulkit Agrawal"
    ],
    "submission_date": "2022-04-28",
    "semantic_scholar_id": "f1b306268ca7e61852f100334b8e969a34822bdc"
  },
  "2204-12458": {
    "title": "Learning Value Functions from Undirected State-only Experience",
    "authors": [
      "Matthew Chang",
      "Arjun Gupta",
      "Saurabh Gupta"
    ],
    "submission_date": "2022-04-26",
    "semantic_scholar_id": "c3053ff94d26b1416ac8828b8cce0f1cdd47df99"
  },
  "2203-13880": {
    "title": "Reinforcement Learning with Action-Free Pre-Training from Videos",
    "authors": [
      "Younggyo Seo",
      "Kimin Lee",
      "Stephen James",
      "P. Abbeel"
    ],
    "submission_date": "2022-03-25",
    "semantic_scholar_id": "1c35807e1a4c24e2013fa0a090cee9cc4716a5f5"
  },
  "2203-12601": {
    "title": "R3M: A Universal Visual Representation for Robot Manipulation",
    "authors": [
      "Suraj Nair",
      "A. Rajeswaran",
      "Vikash Kumar",
      "Chelsea Finn",
      "Abhi Gupta"
    ],
    "submission_date": "2022-03-23",
    "semantic_scholar_id": "c9bdc9ad2c3cf3230ba9aac7b5783ab411f0d204"
  },
  "2202-04478": {
    "title": "Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL",
    "authors": [
      "Rui Yang",
      "Yiming Lu",
      "Wenzhe Li",
      "Hao Sun",
      "Meng Fang",
      "Yali Du",
      "Xiu Li",
      "Lei Han",
      "Chongjie Zhang"
    ],
    "submission_date": "2022-02-09",
    "semantic_scholar_id": "7f712d58084e32ddc1b0cd60932f8bc0a0916330"
  },
  "2112-04716": {
    "title": "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
    "authors": [
      "Aviral Kumar",
      "Rishabh Agarwal",
      "Tengyu Ma",
      "Aaron C. Courville",
      "G. Tucker",
      "S. Levine"
    ],
    "submission_date": "2021-12-09",
    "semantic_scholar_id": "c271b4d25bc184bc94622cef6c9aba80e8e2cce3"
  },
  "2112-03227": {
    "title": "CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks",
    "authors": [
      "Oier Mees",
      "Lukás Hermann",
      "Erick Rosete-Beas",
      "Wolfram Burgard"
    ],
    "submission_date": "2021-12-06",
    "semantic_scholar_id": "4be02694125b71876552900a53c85c47a2a83614"
  },
  "2111-09858": {
    "title": "Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Christopher Hoang",
      "Sungryull Sohn",
      "Jongwook Choi",
      "Wilka Carvalho",
      "Honglak Lee"
    ],
    "submission_date": "2021-11-18",
    "semantic_scholar_id": "6a6ecd775a0d021528ef294302d120b22c494966"
  },
  "2111-06377": {
    "title": "Masked Autoencoders Are Scalable Vision Learners",
    "authors": [
      "Kaiming He",
      "Xinlei Chen",
      "Saining Xie",
      "Yanghao Li",
      "Piotr Doll'ar",
      "Ross B. Girshick"
    ],
    "submission_date": "2021-11-11",
    "semantic_scholar_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7"
  },
  "2110-13625": {
    "title": "Landmark-Guided Subgoal Generation in Hierarchical Reinforcement Learning",
    "authors": [
      "Junsup Kim",
      "Younggyo Seo",
      "Jinwoo Shin"
    ],
    "submission_date": "2021-10-26",
    "semantic_scholar_id": "27bc680bf6a115cc3f28c4da462b6d25cf04cb09"
  },
  "2110-12080": {
    "title": "C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",
    "authors": [
      "Tianjun Zhang",
      "Benjamin Eysenbach",
      "R. Salakhutdinov",
      "S. Levine",
      "Joseph E. Gonzalez"
    ],
    "submission_date": "2021-10-22",
    "semantic_scholar_id": "52aeb38922f1f60ef4032012c70f9d5363547e03"
  },
  "2110-06169": {
    "title": "Offline Reinforcement Learning with Implicit Q-Learning",
    "authors": [
      "Ilya Kostrikov",
      "Ashvin Nair",
      "S. Levine"
    ],
    "submission_date": "2021-10-12",
    "semantic_scholar_id": "348a855fe01f3f4273bf0ecf851ca688686dbfcc"
  },
  "2110-01548": {
    "title": "Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble",
    "authors": [
      "Gaon An",
      "Seungyong Moon",
      "Jang-Hyun Kim",
      "Hyun Oh Song"
    ],
    "submission_date": "2021-10-04",
    "semantic_scholar_id": "9560080a2c32682bd1c1a9850a54ca6163f1956e"
  },
  "2108-13264": {
    "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "authors": [
      "Rishabh Agarwal",
      "Max Schwarzer",
      "P. S. Castro",
      "Aaron C. Courville",
      "Marc G. Bellemare"
    ],
    "submission_date": "2021-08-30",
    "semantic_scholar_id": "558ca2e8c7eb56edd77a52b084e6cc24dffe5bcd"
  },
  "2107-00541": {
    "title": "Goal-Conditioned Reinforcement Learning with Imagined Subgoals",
    "authors": [
      "Elliot Chane-Sane",
      "C. Schmid",
      "I. Laptev"
    ],
    "submission_date": "2021-07-01",
    "semantic_scholar_id": "fb95d6e6e5f78f6e5c339e2058ce9ae9e803182b"
  },
  "2106-08909": {
    "title": "Offline RL Without Off-Policy Evaluation",
    "authors": [
      "David Brandfonbrener",
      "William F. Whitney",
      "R. Ranganath",
      "Joan Bruna"
    ],
    "submission_date": "2021-06-16",
    "semantic_scholar_id": "a3b82f4fc10caf6243afbd77c9c990ce03ae36d1"
  },
  "2106-01345": {
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "authors": [
      "Lili Chen",
      "Kevin Lu",
      "A. Rajeswaran",
      "Kimin Lee",
      "Aditya Grover",
      "M. Laskin",
      "P. Abbeel",
      "A. Srinivas",
      "Igor Mordatch"
    ],
    "submission_date": "2021-06-02",
    "semantic_scholar_id": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500"
  },
  "2105-13345": {
    "title": "Adversarial Intrinsic Motivation for Reinforcement Learning",
    "authors": [
      "Ishan Durugkar",
      "Mauricio Tec",
      "S. Niekum",
      "P. Stone"
    ],
    "submission_date": "2021-05-27",
    "semantic_scholar_id": "acacd119213ff03453816f6cb51402109d443007"
  },
  "2104-07749": {
    "title": "Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills",
    "authors": [
      "Yevgen Chebotar",
      "Karol Hausman",
      "Yao Lu",
      "Ted Xiao",
      "Dmitry Kalashnikov",
      "Jacob Varley",
      "A. Irpan",
      "Benjamin Eysenbach",
      "Ryan C. Julian",
      "Chelsea Finn",
      "S. Levine"
    ],
    "submission_date": "2021-04-15",
    "semantic_scholar_id": "677b103eecc4d34e378502d60147456875e8741b"
  },
  "2104-05859": {
    "title": "RECON: Rapid Exploration for Open-World Navigation with Latent Goal Models",
    "authors": [
      "Dhruv Shah",
      "Benjamin Eysenbach",
      "G. Kahn",
      "Nicholas Rhinehart",
      "S. Levine"
    ],
    "submission_date": "2021-04-13",
    "semantic_scholar_id": "16486b905177860b5b68b7f4da9e499562c674b0"
  },
  "2011-12491": {
    "title": "World Model as a Graph: Learning Latent Landmarks for Planning",
    "authors": [
      "Lunjun Zhang",
      "Ge Yang",
      "Bradly C. Stadie"
    ],
    "submission_date": "2020-11-25",
    "semantic_scholar_id": "5cf549e26b4dce19d5bc783de83047479ce6218a"
  },
  "2011-08909": {
    "title": "C-Learning: Learning to Achieve Goals via Recursive Classification",
    "authors": [
      "Benjamin Eysenbach",
      "R. Salakhutdinov",
      "S. Levine"
    ],
    "submission_date": "2020-11-17",
    "semantic_scholar_id": "f0901642e339d17b3eb66daae112f5d62556c637"
  },
  "2011-06507": {
    "title": "Reinforcement Learning with Videos: Combining Offline Observations with Interaction",
    "authors": [
      "Karl Schmeckpeper",
      "Oleh Rybkin",
      "Kostas Daniilidis",
      "S. Levine",
      "Chelsea Finn"
    ],
    "submission_date": "2020-11-12",
    "semantic_scholar_id": "7d99f5dc92678f61576427f92adba9bef43dfd65"
  },
  "2010-13611": {
    "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning",
    "authors": [
      "Anurag Ajay",
      "Aviral Kumar",
      "Pulkit Agrawal",
      "S. Levine",
      "Ofir Nachum"
    ],
    "submission_date": "2020-10-26",
    "semantic_scholar_id": "0a321a38ba98499f17a2423f84972de29a5b2e7f"
  },
  "2010-11944": {
    "title": "Accelerating Reinforcement Learning with Learned Skill Priors",
    "authors": [
      "Karl Pertsch",
      "Youngwoon Lee",
      "Joseph J. Lim"
    ],
    "submission_date": "2020-10-22",
    "semantic_scholar_id": "b68b8b980db62308864b2a7d33718182c5f8335b"
  },
  "2007-15588": {
    "title": "Data-efficient Hindsight Off-policy Option Learning",
    "authors": [
      "Markus Wulfmeier",
      "Dushyant Rao",
      "Roland Hafner",
      "Thomas Lampe",
      "A. Abdolmaleki",
      "Tim Hertweck",
      "M. Neunert",
      "Dhruva Tirumala",
      "Noah Siegel",
      "N. Heess",
      "Martin A. Riedmiller"
    ],
    "submission_date": "2020-07-30",
    "semantic_scholar_id": "9e38bbf16a458f9101fab5cae39a4f49d35dcb51"
  },
  "2007-11091": {
    "title": "EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL",
    "authors": [
      "Seyed Kamyar Seyed Ghasemipour",
      "D. Schuurmans",
      "S. Gu"
    ],
    "submission_date": "2020-07-21",
    "semantic_scholar_id": "fa7f88f77de02ae9389e514a1cd13083a624ec78"
  },
  "2006-15134": {
    "title": "Critic Regularized Regression",
    "authors": [
      "Ziyun Wang",
      "Alexander Novikov",
      "Konrad Zolna",
      "Jost Tobias Springenberg",
      "Scott E. Reed",
      "Bobak Shahriari",
      "Noah Siegel",
      "J. Merel",
      "Caglar Gulcehre",
      "N. Heess",
      "Nando de Freitas"
    ],
    "submission_date": "2020-06-26",
    "semantic_scholar_id": "7acbdb961f67d50fef359066f2a1d7755cf16ee2"
  },
  "2006-11485": {
    "title": "Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning",
    "authors": [
      "Tianren Zhang",
      "Shangqi Guo",
      "Tian Tan",
      "Xiaolin Hu",
      "Feng Chen"
    ],
    "submission_date": "2020-06-20",
    "semantic_scholar_id": "361ccae6cb40343c8824c9d64104ff8261a7c089"
  },
  "2006-09359": {
    "title": "Accelerating Online Reinforcement Learning with Offline Datasets",
    "authors": [
      "Ashvin Nair",
      "Murtaza Dalal",
      "Abhishek Gupta",
      "S. Levine"
    ],
    "submission_date": "2020-06-16",
    "semantic_scholar_id": "0272b14dd471fe7b81df703af1b71d7600b77215"
  },
  "2006-04779": {
    "title": "Conservative Q-Learning for Offline Reinforcement Learning",
    "authors": [
      "Aviral Kumar",
      "Aurick Zhou",
      "G. Tucker",
      "S. Levine"
    ],
    "submission_date": "2020-06-08",
    "semantic_scholar_id": "28db20a81eec74a50204686c3cf796c42a020d2e"
  },
  "2005-14165": {
    "title": "Language Models are Few-Shot Learners",
    "authors": [
      "Tom B. Brown",
      "Benjamin Mann",
      "Nick Ryder",
      "Melanie Subbiah",
      "J. Kaplan",
      "Prafulla Dhariwal",
      "Arvind Neelakantan",
      "Pranav Shyam",
      "Girish Sastry",
      "Amanda Askell",
      "Sandhini Agarwal",
      "Ariel Herbert-Voss",
      "Gretchen Krueger",
      "T. Henighan",
      "R. Child",
      "A. Ramesh",
      "Daniel M. Ziegler",
      "Jeff Wu",
      "Clemens Winter",
      "Christopher Hesse",
      "Mark Chen",
      "Eric Sigler",
      "Ma-teusz Litwin",
      "Scott Gray",
      "Benjamin Chess",
      "Jack Clark",
      "Christopher Berner",
      "Sam McCandlish",
      "Alec Radford",
      "I. Sutskever",
      "Dario Amodei"
    ],
    "submission_date": "2020-05-28",
    "semantic_scholar_id": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0"
  },
  "2005-01643": {
    "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
    "authors": [
      "S. Levine",
      "Aviral Kumar",
      "G. Tucker",
      "Justin Fu"
    ],
    "submission_date": "2020-05-04",
    "semantic_scholar_id": "5e7bc93622416f14e6948a500278bfbe58cd3890"
  },
  "2004-13649": {
    "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels",
    "authors": [
      "Ilya Kostrikov",
      "Denis Yarats",
      "R. Fergus"
    ],
    "submission_date": "2020-04-28",
    "semantic_scholar_id": "6568423cfaca7e24c88ea208cb0e67129e43aa9b"
  },
  "2004-07219": {
    "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
    "authors": [
      "Justin Fu",
      "Aviral Kumar",
      "Ofir Nachum",
      "G. Tucker",
      "S. Levine"
    ],
    "submission_date": "2020-04-15",
    "semantic_scholar_id": "a326d9f2d2d351001fece788165dbcbb524da2e4"
  },
  "2002-05709": {
    "title": "A Simple Framework for Contrastive Learning of Visual Representations",
    "authors": [
      "Ting Chen",
      "Simon Kornblith",
      "Mohammad Norouzi",
      "Geoffrey E. Hinton"
    ],
    "submission_date": "2020-02-13",
    "semantic_scholar_id": "7af72a461ed7cda180e7eab878efd5f35d79bbf4"
  },
  "2002-11708": {
    "title": "Generalized Hindsight for Reinforcement Learning",
    "authors": [
      "Alexander C. Li",
      "Lerrel Pinto",
      "P. Abbeel"
    ],
    "submission_date": "2020-02-01",
    "semantic_scholar_id": "7b0871c783e721bfbf9b5d16e575130a07a672cd"
  },
  "1912-01588": {
    "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning",
    "authors": [
      "K. Cobbe",
      "Christopher Hesse",
      "Jacob Hilton",
      "John Schulman"
    ],
    "submission_date": "2019-12-03",
    "semantic_scholar_id": "8d814620a1ca77e745bc8a33b96b86148f2804fe"
  },
  "1911-08453": {
    "title": "Planning with Goal-Conditioned Policies",
    "authors": [
      "Soroush Nasiriany",
      "Vitchyr H. Pong",
      "Steven Lin",
      "S. Levine"
    ],
    "submission_date": "2019-11-19",
    "semantic_scholar_id": "7b4848bad51ebd38fb068e73abc3c6d865fd692f"
  },
  "1910-11956": {
    "title": "Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning",
    "authors": [
      "Abhishek Gupta",
      "Vikash Kumar",
      "Corey Lynch",
      "S. Levine",
      "Karol Hausman"
    ],
    "submission_date": "2019-10-25",
    "semantic_scholar_id": "8c54e8575e7c17a4097838305915e6e7b00fd4af"
  },
  "1910-00177": {
    "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning",
    "authors": [
      "Xue Bin Peng",
      "Aviral Kumar",
      "Grace Zhang",
      "S. Levine"
    ],
    "submission_date": "2019-10-01",
    "semantic_scholar_id": "ad14227e4f51276892ffc37aa43fd8750bb5eba8"
  },
  "1911-11361": {
    "title": "Behavior Regularized Offline Reinforcement Learning",
    "authors": [
      "Yifan Wu",
      "G. Tucker",
      "Ofir Nachum"
    ],
    "submission_date": "2019-09-25",
    "semantic_scholar_id": "9be492858863c8c7c24be1ecb75724de5086bd8e"
  },
  "1908-05451": {
    "title": "Mapping State Space using Landmarks for Universal Goal Reaching",
    "authors": [
      "Zhiao Huang",
      "Fangchen Liu",
      "Hao Su"
    ],
    "submission_date": "2019-08-15",
    "semantic_scholar_id": "a3a39ace904a9f3960da0dbfdd7b660a05b9ee66"
  },
  "1906-05838": {
    "title": "Goal-conditioned Imitation Learning",
    "authors": [
      "Yiming Ding",
      "Carlos Florensa",
      "Mariano Phielipp",
      "P. Abbeel"
    ],
    "submission_date": "2019-06-13",
    "semantic_scholar_id": "b668ba0900ddcdacd0a07ff9983172f525c3c4d6"
  },
  "1906-05253": {
    "title": "Search on the Replay Buffer: Bridging Planning and Reinforcement Learning",
    "authors": [
      "Benjamin Eysenbach",
      "R. Salakhutdinov",
      "S. Levine"
    ],
    "submission_date": "2019-06-12",
    "semantic_scholar_id": "e0889fcee1acd985af76a3907d5d0029bf260be9"
  },
  "1903-01973": {
    "title": "Learning Latent Plans from Play",
    "authors": [
      "Corey Lynch",
      "Mohi Khansari",
      "Ted Xiao",
      "Vikash Kumar",
      "Jonathan Tompson",
      "S. Levine",
      "P. Sermanet"
    ],
    "submission_date": "2019-03-05",
    "semantic_scholar_id": "99a7df93a2e16bd7ac3349d52cc34417cda7909d"
  },
  "1812-02900": {
    "title": "Off-Policy Deep Reinforcement Learning without Exploration",
    "authors": [
      "Scott Fujimoto",
      "D. Meger",
      "Doina Precup"
    ],
    "submission_date": "2018-12-07",
    "semantic_scholar_id": "5285cb8faada5de8a92a47622950f6cfd476ac1d"
  },
  "1810-01257": {
    "title": "Near-Optimal Representation Learning for Hierarchical Reinforcement Learning",
    "authors": [
      "Ofir Nachum",
      "S. Gu",
      "Honglak Lee",
      "S. Levine"
    ],
    "submission_date": "2018-10-02",
    "semantic_scholar_id": "e4a89a978f747d0b548f5887b2380c5f618061f0"
  },
  "1805-08296": {
    "title": "Data-Efficient Hierarchical Reinforcement Learning",
    "authors": [
      "Ofir Nachum",
      "S. Gu",
      "Honglak Lee",
      "S. Levine"
    ],
    "submission_date": "2018-05-21",
    "semantic_scholar_id": "39b7007e6f3dd0744833f292f07ed77973503bfd"
  },
  "1805-01954": {
    "title": "Behavioral Cloning from Observation",
    "authors": [
      "F. Torabi",
      "Garrett Warnell",
      "P. Stone"
    ],
    "submission_date": "2018-05-04",
    "semantic_scholar_id": "35da1cd669ad5492a6358ea53aea95de28d39ded"
  },
  "1802-09081": {
    "title": "Temporal Difference Models: Model-Free Deep RL for Model-Based Control",
    "authors": [
      "Vitchyr H. Pong",
      "S. Gu",
      "Murtaza Dalal",
      "S. Levine"
    ],
    "submission_date": "2018-02-15",
    "semantic_scholar_id": "852c931b5d9f9d4256befd725ee4185945c4964c"
  },
  "1803-00653": {
    "title": "Semi-parametric Topological Memory for Navigation",
    "authors": [
      "Nikolay Savinov",
      "Alexey Dosovitskiy",
      "V. Koltun"
    ],
    "submission_date": "2018-02-15",
    "semantic_scholar_id": "c0d96d1ea69855a5a3abf614f17095c29b3339a4"
  },
  "1802-01561": {
    "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures",
    "authors": [
      "L. Espeholt",
      "Hubert Soyer",
      "R. Munos",
      "K. Simonyan",
      "Volodymyr Mnih",
      "Tom Ward",
      "Yotam Doron",
      "Vlad Firoiu",
      "Tim Harley",
      "Iain Dunning",
      "S. Legg",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2018-02-05",
    "semantic_scholar_id": "80196cdfcd0c6ce2953bf65a7f019971e2026386"
  },
  "1711-00937": {
    "title": "Neural Discrete Representation Learning",
    "authors": [
      "Aäron van den Oord",
      "O. Vinyals",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2017-11-02",
    "semantic_scholar_id": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e"
  },
  "1710-05421": {
    "title": "DDCO: Discovery of Deep Continuous Options for Robot Learning from Demonstrations",
    "authors": [
      "S. Krishnan",
      "Roy Fox",
      "Ion Stoica",
      "Ken Goldberg"
    ],
    "submission_date": "2017-10-15",
    "semantic_scholar_id": "ed9f58f4e8ee8dcacafdf06ffa58deaa6404ad69"
  },
  "1707-01495": {
    "title": "Hindsight Experience Replay",
    "authors": [
      "Marcin Andrychowicz",
      "Dwight Crow",
      "Alex Ray",
      "Jonas Schneider",
      "Rachel Fong",
      "Peter Welinder",
      "Bob McGrew",
      "Joshua Tobin",
      "P. Abbeel",
      "Wojciech Zaremba"
    ],
    "submission_date": "2017-07-05",
    "semantic_scholar_id": "429ed4c9845d0abd1f8204e1d7705919559bc2a2"
  },
  "1706-03762": {
    "title": "Attention is All you Need",
    "authors": [
      "Ashish Vaswani",
      "Noam M. Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "Lukasz Kaiser",
      "I. Polosukhin"
    ],
    "submission_date": "2017-06-12",
    "semantic_scholar_id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776"
  },
  "1703-01161": {
    "title": "FeUdal Networks for Hierarchical Reinforcement Learning",
    "authors": [
      "A. Vezhnevets",
      "Simon Osindero",
      "T. Schaul",
      "N. Heess",
      "Max Jaderberg",
      "David Silver",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2017-03-03",
    "semantic_scholar_id": "049c6e5736313374c6e594c34b9be89a3a09dced"
  },
  "1703-00956": {
    "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning",
    "authors": [
      "Marlos C. Machado",
      "Marc G. Bellemare",
      "Michael Bowling"
    ],
    "submission_date": "2017-03-02",
    "semantic_scholar_id": "8423cc50c18d68f797adaa4f571f5e4efbe325a5"
  },
  "1609-05140": {
    "title": "The Option-Critic Architecture",
    "authors": [
      "Pierre-Luc Bacon",
      "J. Harb",
      "Doina Precup"
    ],
    "submission_date": "2016-09-16",
    "semantic_scholar_id": "15b26d8cb35d7e795c8832fe08794224ee1e9f84"
  },
  "1607-06450": {
    "title": "Layer Normalization",
    "authors": [
      "Jimmy Ba",
      "J. Kiros",
      "Geoffrey E. Hinton"
    ],
    "submission_date": "2016-07-21",
    "semantic_scholar_id": "97fb4e3d45bb098e27e0071448b6152217bd35a5"
  },
  "1606-08415": {
    "title": "Gaussian Error Linear Units (GELUs)",
    "authors": [
      "Dan Hendrycks",
      "Kevin Gimpel"
    ],
    "submission_date": "2016-06-27",
    "semantic_scholar_id": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d"
  },
  "1604-06057": {
    "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation",
    "authors": [
      "Tejas D. Kulkarni",
      "Karthik Narasimhan",
      "A. Saeedi",
      "J. Tenenbaum"
    ],
    "submission_date": "2016-04-20",
    "semantic_scholar_id": "d37620e6f8fe678a43e12930743281cd8cca6a66"
  },
  "1412-6980": {
    "title": "Adam: A Method for Stochastic Optimization",
    "authors": [
      "Diederik P. Kingma",
      "Jimmy Ba"
    ],
    "submission_date": "2014-12-22",
    "semantic_scholar_id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8"
  },
  "1312-5602": {
    "title": "Playing Atari with Deep Reinforcement Learning",
    "authors": [
      "Volodymyr Mnih",
      "K. Kavukcuoglu",
      "David Silver",
      "Alex Graves",
      "Ioannis Antonoglou",
      "D. Wierstra",
      "Martin A. Riedmiller"
    ],
    "submission_date": "2013-12-19",
    "semantic_scholar_id": "2319a491378867c7049b3da055c5df60e1671158"
  },
  "1810-04805": {
    "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "authors": [
      "Jacob Devlin",
      "Ming-Wei Chang",
      "Kenton Lee",
      "Kristina Toutanova"
    ],
    "submission_date": null,
    "semantic_scholar_id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992"
  }
}