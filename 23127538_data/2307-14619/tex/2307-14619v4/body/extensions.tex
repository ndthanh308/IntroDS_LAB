%!TEX root = ../main.tex
\section{Extensions and Further Results}\label{app:extensions}


\subsection{Removing the necessity for minimal chunk length via stronger synthesis oracle}\label{sec:no_min_chunk_length}

\begin{theorem}\label{thm:simpler_TVC_thm} Support we replace \Cref{asm:iss_body} in \Cref{prop:TVC_main} with the assumption that our trajectory oracle produces \emph{entire sequences of gains} $\sfk_{1:T}$ which satisfy time-varying incremental stability (\Cref{defn:tiss}) on the whole trajectory. Then, 
\begin{itemize}
\item The conclusion of \Cref{prop:TVC_main} holds
\item we no longer need the condition $\tauc \ge c_3$; taking $\tauc = 1$ suffices.
\item The constants $c_1,c_2$ depend only on $\cgamma$ and $\cbargamma$. That is, $\cxi$ and terms associated with $\betaiss$ can be vaucuously large.  
\end{itemize}
Analogoues, if we replace \Cref{asm:tis} in \Cref{prop:TVC_main_general} with the assumption that $\sfk_{1:T}$ satisfies the time-varying incremental stability condition, then 
\begin{itemize}
\item The conclusion of \Cref{prop:TVC_main_general} holds
\item We no longer need the condition $\tauc \ge c_3$; taking $\tauc = 1$ suffices. Moreover, we can replace the condition \eqref{eq:eps_cond_general} of $\epsilon$ with the simpler condition $\epsilon \le \cgamma$.
\item Lastly, one can replace $ \epsilon_1 = 2\betaiss(2\gammaiss(\epsilon),0) $  in \eqref{eq:TVC_main} with the term $\epsilon_1 = \gammaiss(\epsilon)$. 
\end{itemize}
\end{theorem}
The proof of \Cref{thm:simpler_TVC_thm} follows by replacing \Cref{lem:iss_ips} with the following simpler lemma that recapitulates \citet[Proposition 3.1]{pfrommer2022tasil}, and propogating the argument through the proof.
\begin{lemma}\label{lem:iss_simpler_lemma} Consider two consistent trajectories $(\bx_{1:T+1},\bu_{1:T})$ and $(\bx_{1:T+1}',\bu_{1:T}')$, as well as sequences of primitive controller $\sfk_{1:T},\sfk_{1:T}'$,  such that $\bx_1 = \bx_1'$, and $\bu_t = \sfk_t(\bx_t)$, $\bu_t' = \sfk_t'(\bx_t')$. Suppose that 
\begin{align}
\max_{t}\sup_{\bx:\|\bx - \bx_t\| \le \gammaiss(\epsilon)} \|\sfk_t(\bx)-\sfk_t'(\bx_t)\| \le \epsilon.
\end{align}
Then, $\max_t \|\bu_t - \bu_t'\| \le \epsilon$ and $\max_t \|\bx_t - \bx_t'\| \le \gammaiss(\epsilon)$
\end{lemma}


\subsection{Noisy Dynamics}\label{ssec:noisy_dynamics}


\newcommand{\seqw}{\mathsf{w}}
\newcommand{\Pnoiseh}[1][h]{\distfont{P}_{\mathrm{noise},#1}}
\newcommand{\Fnoise}[1][h]{F^{\mathrm{noise}}}

We can directly extend our imitation guarantees in the composite MDP to settings with noise:
\begin{align}
\seqs_{h+1} \sim \Fnoise_h(\seqs_h,\seqa_h,\seqw_h), \quad \seqw_h \sim \Pnoiseh, \label{eq:with_noise}
\end{align}
where the noises are idependent of states and of each other. Indeed, \eqref{eq:with_noise} can be directly reduced to the no-noise setting by lifting ``actions'' to pairs $(\seqa_h,\seqw_h)$, and policies $\pi$ to encompass their distribution of actions, and over noise. 

Another approach is instead to condition on the noises $\seqw_{1:H}$ first, and treat the noise-conditioned dynamics as deterministic. Then one can take expectation over the noises and conclude. The advantage of this approach is that the couplings constructed thereby is that the trajectories experience identical sequences of noise with probability one. 

Extending the control setting to incorporate noise is doable but requires more effort:
\begin{itemize}
	\item If the \emph{demonstrations are noiseless}, then one can still appeal to the synthesis oracle to synthesis stabilizing gains. However, one needs to (ever so slightly) generalize the proofs of the various stability properties (e.g. IPS in \Cref{prop:ips_instant}) to accomodate system noise. 
	\item If the demonstrations themselves have noise, one may need to modify the synthesis oracle setup somewhat. This is because the synthesis oracle, if it synthesizes stabilizing gains, will attempt to get the learner to stabilize to a noise-perturbed trajectory. This can perhaps be modified by synthesizing controllers which stabilize to smoothed trajectories, or by collecting demonstrations of desired trajectories (e.g. position control), and stabilizing to the these states than than to actual states visited in demonstrations. 
\end{itemize}



\subsection{Robustness to Adversarial Perturbations}
\newcommand{\seqe}{\mathsf{e}}
\newcommand{\Fadv}{F^{\mathtt{adv}}}
\newcommand{\piadv}{\pi^{\mathtt{adv}}}

Our results can accomodate an even more general framework where there are both noises as well  adversarial perturbations. We explain this generalization in the composite MDP. 

Specifical, consider a space $\cE$ of adversarial perturbations, as well as $\cW$ of noises as above. We may posite a dynamics function $\Fadv: \cS \times \cA \times \cW \times \cA \to \cS$, and consider the evolution of an imitator policy $\pihat$ under the adversary
\begin{align}
\shat_{h+1} &= \Fadv_h(\shat_h,\seqahat_h,\seqw_h,\seqe_h),  \quad \seqw_h \sim \Pnoiseh\\
&\ahat_h \sim \pihat_h(\seqs_h)\\
&\seqe_h \sim \piadv_h(\shat_{1:h},\seqa_{1:h},\seqw_{1:h},\seqe_{1:h-1}), \\
&\shat_{1} \sim \piadv_0(\seqs_1), \quad \seqs_1 \sim \Dinit.
\end{align}

By constrast, we can model the demonstrator trajectory as arising from noisy, but otherwise unperturbed trajectories:
\begin{align}
\sstar_{h+1} \sim \Fadv_h(\sstar_h,\seqa^\star_h,\seqw_h,0), \quad \seqw_h \sim \Pnoiseh, \quad \seqa_h^\star \sim \pist_h(\sstar_h), \quad \sstar_1 \sim \Dinit. \label{eq:pist_unpert}
\end{align}
To reduce the composite-MDP in \Cref{sec:analysis}, we can view the combination of adverary $\piadv$ and imitator $\pihat$ as a combined policy, and the $\pist$ with zero augmentation as another policy; here, we would them treat actions as $\tilde \seqa = (\seqa,\seqe)$. Then, one can consider modified senses of stability which preserve trajectory tracking, as well as a modification of $\distA$ to a function measuring distances between $\tilde \seqa = (\seqa,\seqe)$ and $\tilde \seqa' = (\seqa',\seqe')$. The extension is rather mechanical, and we fit details. Note further that, by including a $\piadv_0(\seqs_1)$, we can modify the analysis to allow for subtle differences in initial state distribution. This would in turn require strengthening our stability asssumptions to allow stability to initial state (e.g., the definition of incremental stability as exposited by \cite{pfrommer2022tasil}).


\subsection{Deconvolution Policies and Total Variation Continuity}\label{app:deconv_smooth}

While our strongest guarantees hold for the replica policies, where we add noise both as a data augmentation at training time \emph{and} at test time, many practitioners have seen some success with the deconvolution policies where noise is only added at training time.  We note that \Cref{prop:IS_general_body} holds when the learned policy is TVC; without noise at training time this certainly will not hold when the expert policy is not TVC.  We show here that the deconvolution expert policy is TVC under mild assumptions, which lends some credence to the empirical success of deconvolution policies.

Precisely, we show that, under reasonable conditions, deconvolution is total variation continuous.  In particular, suppose that $\mu \in \Delta(\rr^d)$ is a Borel probabilty measure and $p$ is a density with respect to $\mu$.  Further suppose that $Q$ is a density with respect to the Lebesgue measure on $\rr^d$.  Suppose that $\bx \sim p$, $\bw \sim Q$, and let $\xtil = \bx + \bw$.  Denote the deconvolution measure of $\bx$ given $\xtil$ as $p(\cdot | \xtil)$. We show that this measure is continuous in $\tv$.  
\begin{proposition}\label{prop:deconvolutioncontinuity}
    Let $\bx, \bx' \in \rr^d$ be fixed, let $p: \rr^d \to \rr$ denote a probability density, and let $Q: \rr^d \to \rr$ denote a function such that $\nabla^2 Q$ and $\nabla \log Q$ exist and are continuous on the set
    \begin{align}
        \cX  = \left\{ (1- t) \xtil + t \xtil' - x | \bx \in \supp p \text{ and } t \in [0,1] \right\}
    \end{align}
    Then it holds that
    \begin{align}
        \tv\left( p(\cdot | \xtil), p(\cdot | \xtil') \right) \leq \norm{\xtil - \xtil'} \cdot \sup_{\bx \in \cX} \norm{\nabla \log Q(\bx)}.
    \end{align}
\end{proposition}
By \Cref{cor:tv_two}, any policy composed with the total variation kernel is thus total variation continuous with a linear $\gamtvc$; moreover, the Lipschitz constant is given by the maximal norm of the score of the noise distribution.  For example, if $Q$ is the density of a Gaussian with variance $\sigma^2$, then $\gamtvc(u) \leq \frac{\sup_{\cX} \norm{\bx}}{\sigma^2}$ is dimension independent.
\begin{remark}
    Note that our notation is intentionally different from that in the body to emphasize that this is a general fact about abstract probability measures.  We may intantiate the guarantee in the control setting of interest by letting $\bx = \pathm$ and consider $Q$ to be a Gaussian (for example) kernel.  In this case, we see that the deconvolution policy of \Cref{defn:dec_cond} is automatically TVC.
\end{remark}


To prove \Cref{prop:deconvolutioncontinuity}, we begin with the following lemma:
\begin{lemma}\label{lem:gradientposterior}
    Let $\xtil \in \rr^d$ be fixed and suppose that $\nabla \log Q(\xtil - \bx) $ exists for all $\bx \in \supp p$.  Then, for all $\bx \in \supp p$, it holds that $\nabla_{\xtil} p(\bx | \xtil)$ exists.  Furthermore,
    \begin{align}
        \int \norm{\nabla p(\bx | \xtil)} d \mu(\bx) \leq 2\sup_{\bx \in \supp p} \norm{\nabla \log Q(\xtil - \bx)},
    \end{align}
    where the gradient above is with respect to $\xtil$.
\end{lemma}
\begin{proof}
    We begin by noting that if $\nabla \log Q(\xtil - \bx)$ exists, then so does $\nabla Q(\xtil - \bx)$.  By Bayes' rule,
    \begin{align}
        p(\bx | \xtil) = \frac{p(\bx) Q(\xtil - \bx)}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')}.
    \end{align}
    We can then compute directly that
    \begin{align}
        \nabla p(\bx | \xtil) &= \frac{p(\bx) \nabla Q(\xtil - \bx)}{\int Q(\xtil - \bx')  p(\bx') d \mu(\bx')} - \frac{p(\bx) Q(\xtil - \bx) \cdot \int \nabla Q(\xtil - \bx')  p(\bx') d \mu(\bx')}{\left( \int Q(\xtil - \bx') p(\bx') d \mu(\bx') \right)^2},
    \end{align}
    where the exchange of the gradient and the integral is justified by Lebesgue dominated convergence and the assumption of differentiability of $Q$ and thus existence is ensured.  We have now that
    \begin{align}
        \norm{\nabla p(\bx|\xtil)} &= \frac{p(\bx) Q(\xtil - \bx)}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')} \cdot \norm{  \nabla \log Q(\xtil - \bx) - \frac{\int \nabla Q(\xtil - \bx') p(\bx') d \mu(\bx')}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')} } \\
        &= \frac{p(\bx) Q(\xtil - \bx)}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')} \cdot \norm{  \nabla \log Q(\xtil - \bx) - \frac{\int (\nabla \log Q(\xtil - \bx')) \cdot Q(\xtil - \bx) p(\bx') d \mu(\bx')}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')} } \\
        &\leq \left( \sup_{\bx \in \supp p} \norm{\nabla \log Q(\xtil - \bx)} \right) \cdot \frac{p(\bx) Q(\xtil - \bx)}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')} \cdot \left( 1 +  \frac{\int Q(\xtil - \bx) p(\bx') d \mu(\bx')}{\int Q(\xtil - \bx) p(\bx') d \mu(\bx')}\right) \\
        &= \left( 2\sup_{\bx \in \supp p} \norm{\nabla \log Q(\xtil - \bx)} \right) \cdot \frac{p(\bx) Q(\xtil - \bx)}{\int Q(\xtil - \bx') p(\bx') d \mu(\bx')}.
    \end{align}
    Now, integrating over $\bx$ makes the second factor 1, concluding the proof.
\end{proof}
We will now make use of the theory of Dini derivatives (\citep{hagood2006recovering}) to prove a bound on total variation.
\begin{lemma}\label{lem:ftcdini}
    For fixed $\xtil, \xtil'$ and $0 \leq t \leq 1$, let the upper Dini derivative
    \begin{align}
        D^+ \tv(p(\cdot | \xtil), p(\cdot | \xtil_t)) = \limsup_{h \downarrow 0} \frac{\tv(p(\cdot | \xtil), p(\cdot| \xtil_{t + h})) - \tv(p(\cdot | \xtil), p(\cdot | \xtil_t))}{h},
    \end{align}
    where
    \begin{align}
        \xtil_t = (1 -t) \xtil + t \xtil'.
    \end{align}
    If $\nabla \log Q(\xtil_t - \bx)$ exists and is finite for all $\bx \in \supp p$ and $t \in [0,1]$, then
    \begin{align}
        \tv(p(\cdot | \xtil), p(\cdot | \xtil')) \leq \int_0^1 D^+ \tv\left( p(\cdot | \xtil), p(\cdot | \xtil_t) \right) d t. \label{eq:ftcdini}
    \end{align}
\end{lemma}
\begin{proof}
    We compute:
    \begin{align}
        2 \abs{ \tv(p(\cdot | \xtil), p(\cdot| \xtil_{t + h})) - \tv(p(\cdot | \xtil), p(\cdot | \xtil_t)) } &= \abs{\int  \abs{p(\bx | \xtil) - p(\bx| \xtil_{t+h})} - \abs{p(\bx|\xtil) - p(\xtil_{t})} d \mu(\bx)} \\
        &\leq \int \abs{p(\bx | \xtil_{t+h}) - p(\bx | \xtil_t)} d \mu(\bx). \label{eq:tvtriangle}
    \end{align}
    Observe that by the assumption on $Q$ and \Cref{lem:gradientposterior}, $p(\bx | \xtil_t)$ is differentiable and thus continuous in $\xtil_t$.  We therefor see that the function
    \begin{align}
         t \mapsto \tv(p(\cdot | \xtil), p(\cdot | \xtil_t))
    \end{align}
    is continuous as $\xtil_t$ is linear in $t$.  By \citet[Theorem 10]{hagood2006recovering}, \eqref{eq:ftcdini} holds.
\end{proof}
We now bound the Dini derivatives:
\begin{lemma}\label{lem:diniderivativeupperbound}
    Let $\xtil, \xtil' \in \rr^d$ such that for all $t \in [0,1]$it holds that
    \begin{align}
        \sup_{\bx \in \supp p} \abs{\frac{d^2}{d t^2}\left( p(\bx | \xtil_t) \right)} = C < \infty,
    \end{align}
    where the derivative is applied on $\xtil_t$.  If the assumptions of \Cref{lem:gradientposterior,lem:diniderivativeupperbound} hold, then
    \begin{align}
        D^+ \tv(p(\cdot | \xtil), p(\cdot | \xtil_t)) \leq \norm{\xtil - \xtil'} \cdot \sup_{\substack{\bx \in \supp p \\ t \in [0,1]}} \norm{\nabla \log Q(\xtil_t - x)}.
    \end{align}
\end{lemma}
\begin{proof}
    By definition,
    \begin{align}
        D^+ \tv(p(\cdot | \xtil), p(\cdot | \xtil_t)) = \limsup_{h \downarrow 0} \frac{\tv(p(\cdot | \xtil), p(\cdot| \xtil_{t + h})) - \tv(p(\cdot | \xtil), p(\cdot | \xtil_t))}{h}.
    \end{align}
    Fix some $t$ and some small $h$.  By \eqref{eq:tvtriangle}, it holds that
    \begin{align}
        \abs{\tv(p(\cdot | \xtil), p(\cdot| \xtil_{t + h})) - \tv(p(\cdot | \xtil), p(\cdot | \xtil_t))} \leq \frac 12 \cdot \int \abs{p(\bx | \xtil_{t + h}) - p(\bx | \xtil_t)} d \mu(\bx).
    \end{align}
    By Taylor's theorem, it holds that
    \begin{align}
        p(\bx| \xtil_{t+h}) - p(\bx|\xtil_t) = h \cdot \frac{d}{d t}\left( p(\bx|\xtil_t) \right) + h^2 \cdot \frac{d^2}{dt^2}\left( p(\bx|\xtil_{t'}) \right)
    \end{align}
    for some $t' \in [0,1]$.  By the chain rule, we have
    \begin{align}
        \frac{d}{d t}\left( p(\bx|\xtil_t) \right)  &= \inprod{\xtil' - \xtil}{\nabla p(\bx | \xtil_t)},
    \end{align}
    and thus,
    \begin{align}
        \abs{p(\bx | \xtil_{t + h}) - p(\bx | \xtil_t)}  \leq h \cdot \norm{\xtil - \xtil'} \cdot \norm{\nabla p(\bx | \xtil_t)} + h^2 C
    \end{align}
    Now, applying \Cref{lem:gradientposterior} and plugging into the previous computation concludes the proof.
\end{proof}
We are finally ready to state and prove our main result:

\begin{proof}[Proof of \Cref{prop:deconvolutioncontinuity}]
    Note that
    \begin{align}
        \frac{d^2}{d t^2}\left( p(\bx | \xtil_t) \right) = \left( \xtil - \xtil' \right)^T \nabla^2 p(\bx | \xtil_t) (\xtil - \xtil')
    \end{align}
    and thus is bounded if and only if $\nabla^2 p(\bx | \xtil_t)$ is bounded.  An elementary computation shows that if $\nabla^2 Q$ exists and is continuous on $\cX$, then $\nabla^2 p(\bx | \xtil_t)$ is bounded in operator norm on $\cX$.  Thus the assumption in \Cref{lem:diniderivativeupperbound} holds.  Applying \Cref{lem:ftcdini} then concludes the proof.
\end{proof}
