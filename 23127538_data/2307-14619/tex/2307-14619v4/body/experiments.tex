%!TEX root = ../neurips_main.tex

% Figure environment removed

\section{Simulation Study of Test-Time Noise-Injection}\label{sec:experiments}

We empirically evaluate the effect on policy performance of our proposal to inject noise back into the dynamics at inference time.  We consider three challenging robotic manipulation tasks studied in prior work: PushT block-pushing \citep{chi2023diffusion}; Robomimic Can Pick-and-Place and Square Nut Assembly \citep{mandlekar2021matters}.  We explain the environments in greater detail, along with all training and computational details in \Cref{app:exp_details}.
% Since \Cref{alg:imitation_augmentation} produces a policy which intentionally injects noise into the observation during evaluation, we naturally wish to understand the practical impact of this noise on policy performance. We principally consider challenging robotic manipulation tasks studied in prior work, including the PushT block-pushing task \citep{chi2023diffusion}, the Robomimic Can Pick-and-Place task, and the Robomimic Square Nut Assembly task \citep{mandlekar2021matters}. See \Cref{app:exp_details} for the environment details, DDPM architecture, and training methodology. 
The learned diffusion policy generates state trajectories over a $\tau_c = 8$ chunking horizon using fixed feedback gains provided by the $\synth$ oracle to perform position-tracking of the DDPM model output. We direct the reader to \citet{chi2023diffusion} for an extensive empirical investigation into the performance of diffusion policies in the noiseless $\sigma = 0$ setting. We display the results of our experiments in \Cref{fig:noise_sweep}.  Observe that the performance degredation of the replica policy from the unsmoothed $\sigma = 0$ variant is minimal across all environments and even leads to a slight but noticeable improvement in the small-noise regime for PushT (and low-data Can Pick and Place). In the presence of non-negligible noise $\toda$ significantly outperforms the conventional policy $\pihat$ (obtained by adding augmentation at training but not test time), as predicted by our theory. 