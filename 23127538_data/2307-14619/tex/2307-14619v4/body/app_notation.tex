%!TEX root = ../main.tex

\section{Notation, Organization of Appendix, and Full Related Work}\label{app:notation_and_org}

In this appendix, we collect the notation we use throughout the paper, as well as providing a high level organization of the appendices.  

\subsection{Notation Summary}

In this section, we summarize some of the notation used throughout the work, divided by subject.



\paragraph{Measure Theory} We always let $\cX$ denote a Polish space, $\scrB(\cX)$ the Borel-algebra on $\cX$, and $\laws(\cX)$ the set of borel probability measures on $\cX$.  For a random variable $X$ on $\cX$, we let $\lawP_X$ denote the law of $X$.  For random variables $X,Y$, we let $\couple(\lawP_X, \lawP_Y)$ denote the set of couplings of these measures and for laws $\lawP_1, \lawP_2$. We write $\lawP_1 \otimes \lawP_2$ for the product measure. 
We will generally reserve $\lawP$ to denote measure,  $\lawQ$ and $\lawW$ for probability kernels, and $\coup$ for a joint measure on several random variables. 

 When $\lawP_1,\lawP_2 \in \laws(\cX)$ are laws on the sampe space, we let $\tvof{\lawP_1}{\lawP_2}$ denote the total variation distance.  We write $\lawP_1 \ll \lawP_2$ if $\lawP_1$ is absolutely continuous with respect to $\lawP_2$.  Given a Polish space $\cX$ and element $x \in \cX$, we let $\dirac_{x} \in \laws(\cX)$ denote the dirac-delta measure supported on the set $\{x\} \in \Borel(\cX)$ (note that, in a Polish space, the singleton $\{x\}$ set is closed, and therefore Borel).



\paragraph{Norms and linear algebra notation. } We use bold lower case vector $\bz$ to denote vectors, and bold upper case $\bZ$ to denote matrices. We let $\bz_{1:K} = (\bz_1,\dots,\bZ)$ and $\bZ_{1:K} = (\bZ_1,\dots,\bZ_K)$ denote concatenations. The norms $\|\cdot\|$ denote Euclidean norms on vectors and operator norms on matrices. We identify the spaces $\scrP_k$ with Euclidean vectors in the standard sence. Given a Euclidean vector $\bz \in \R^d$, $\cN(\bz,\sigma^2 \eye)$ denote the multivariate normal distribution on $\R^d$ with covariance $\sigma^2 \eye$. 




\paragraph{Control notation.} We let $\bx_t \in \R^{\dimx}$ denote control states, $\bu_t \in \R^{\dimu}$ denote control inputs, and $\ctraj_{\tau} \in \scrP_{\tau}$ denotes trajectories $(\bx_{1:\tau+1},\bu_{1:\tau})$.  $T$ denotes the time horizon of imitation, so  $\ctraj_T \sim \scrP_T$. Our dynamics are $\bx_{t+1} = f(\bx_t,\bu_t)$; for our main results (\Cref{sec:results}), we suppose $f(\bx,\bu) = \bx + \eta\feta(\bx,\bu)$, parametrizing dynamics in the form of an Euler discretization with step $\eta > 0$. 

Recall that primitive controllers $\sfk$ take the form $\sfk(\bx) = \bbarK(\bx - \bbarx) + \bbaru$, where terms with $\bar{(\cdot)}$, $\bbarK,\bbarx,\bbaru$, denote parameters of the primitive controller. The space of these is $\cK$. %\abcomment{minor: why do we denote the linear part of the primitive controller with a bar?}

We also recall the chunk-length $\tauc$ and observation length $\taum$ satisfying $0 \le \taum \le \tauc$. We recall the definition of the trajectory-chunk $\pathc$ and observation-chunk in $\pathm$ in \Cref{sec:setting}, which introduced the indexing $h$, such that $t_h = (h-1)\tauc + 1$. Recall also the composite actions $\seqa_h = (\sfk_{t_h:t_{h+1}-1}) \in \cA = \cK^{\tauc}$ as the concatenation of $\tauc$ primitive controllers. 

\paragraph{Abstractions in the composite MDP.} The composite MDP is a deterministic MDP with composite-states $\seqs \in \cS$ and composite-actions $\seqa \in \cA$, and (possibly time-varying) deterministic transition dynamics $F_h:\cS \times \cA \to \cS$ for $1 \le h \le H$. The goal is to imitate a policy $\pist = (\pist_h)_{1 \le h \le H}$, in terms of imitation gaps $\gapjoint$ and $\gapmarg$ defined in \Cref{defn:imit_gaps}.
We refer the reader to \Cref{sec:analysis} for the relevant terminology, and to \Cref{sec:control_instant_body} for its instantiation in our original control setting. 









\subsection{Organization of the Appendix}
We now describe the organization of our many appendices. In \Cref{app:gen_controllers}, we generalize some of our results to accomodate general incrementally stabilizing primitive controllers.  In \Cref{sec:comparison_to_prior}, we \iftoggle{arxiv}{}{expand on our abbreviated discussion of related work in the body as well as} provide a more detailed comparison of our notion of stability \Cref{defn:ips_body} with those found in prior work.

After the preliminaries on organization, notation, and related work, we divide our appendices into two parts.  

\paragraph{Part 1: The Composite MDP.} In the first part of the Appendix, we expand on and provide rigorous proofs of statements and results pertaining to the composite MDP as considered in \Cref{sec:analysis}.  We begin by providing a detailed background in \Cref{app:prob_theory} on the requisite measure theory we use to make our arguments rigorous.  In particular, we provide definitions of probability kernels and couplings, as well as measurability properties of optimal transport couplings.  In \Cref{app:no_augmentation}, we provide the foull proof of \Cref{prop:IS_general_body}, as warm-up to the proof of \Cref{thm:smooth_cor}.  In particular, the argument substantially simplifies if we consider the case of no added augmentation (when $\sigma = 0$ in $\toda$) and we present a coupling construction that implies the analogous bound in the presence of an additional assumption.  The heart of the first part of our appendices is \Cref{sec:imit_composite}, where we rigorously prove a generalization of \Cref{thm:smooth_cor} by constructing a sophisticated coupling between the imitator and demonstrator trajectories.  We conclude the first part of our appendices by proving a number of lower bounds in the composite MDP setting in \Cref{app:lbs}, which demonstrate the tightness of our arguments in \Cref{sec:imit_composite}.

\paragraph{Part II: Instantiations}
We continue our appendices in the second part, which is concerned with the instantiation of the composite MDP in with incremental stability. 
The heart of the second part of our appendices is \Cref{app:end_to_end}, which provides the final, end-to-end guarantees and the proof of \Cref{prop:TVC_main} and \Cref{thm:main_template,thm:main}.   We also provide a number of variations on this result, including stronger guarantees on imitation of the joint trajectories (\Cref{ssec:end_to_end_demonstrator_tvc}), guarantees on $\toda$ under the aassumption that sampling is close in total variation (\Cref{app:imititation_in_tv}).  We also show in \Cref{prop:imit_bounds_lipschitz} that most natural cost funtions have similar expected values on imitator and demonstrator trajectories assuming that the imitation losses are small. 
 In \Cref{app:control_stability}, we provide a detailed proof that the control setting considered in \Cref{sec:setting} satisfies the stability properties required by our analysis of the composite MDP and prove \Cref{prop:ips_instant}, and  \Cref{sec:ric_synth} in particular explains how to synthesize stabilizing gains, as assumed in \Cref{sec:setting}.  With the stability properties thus proven, we proceed in \Cref{app:scorematching} to instantiate our conditional sampling guarantees with DDPMs.  In particular, by applying earlier work, we state and prove \Cref{thm:samplingguarantee}, which guarantees that with sufficiently many samples, in our setting we can ensure that the learned DDPM provides samples close in the relevant optimal transport distance to the expert distribution.  We also explain in \Cref{rmk:notvguarantee} why stronger total variation guarantees on sampling are unrealistic in our setting.  

\Cref{app:gen_controllers_proofs} generalizes the proofs in \Cref{app:end_to_end} to the generic primitive controllers considered in \Cref{app:gen_controllers}. We then provide a number of extensions of our main results in \Cref{app:extensions}, including to the setting of noisy dynamics (\Cref{ssec:noisy_dynamics}).  Finally, in \Cref{app:exp_details}, we expand the discussion of our experiments, including training and compute details, environment details, and a link to our code for the purpose of reproducibility.






