%!TEX root = ../main.tex

\section{Sampling and Score Estimation}

Regarding sampling with Denoising Diffusion Models, the tightest bounds I know of are in \citet{chen2022sampling}.  To recall, let $q \in \Delta(\rr^d)$ be a distribution and let $X_t$ satisfy
\begin{align}
    d X_t = - X_t d t + \sqrt{2} d B_t, && X_0 \sim q
\end{align}
be the OU process started at $q$ and let $q_t$ denote the law of $X_t$.  Let $s_t: \rr^d \to \rr^d$ be a vector field for $t \in [0, T]$.  Generate a sample as follows.  For some small $h > 0$ and $\tau = \frac Th$, generate $\Xhat_0 \sim \cN(0, \eye)$.  For $1 \leq k \leq \tau$, let $\Xhat_k = \Xhat_{k-1} + 2 h s_{T - kh}(\Xhat_k-1) + \sqrt{2 h} \gamma_k$, where $\gamma_k \sim \cN(0, \eye)$ are independent.  Letting $p_\tau$ denote the law of $\Xhat_\tau$, \citet[Theorem 2]{chen2022sampling} controls $\tv(p_\tau, q)$ as follows:
\begin{theorem}\label{thm:sinho}
    Suppose that following hold:
    \begin{enumerate}
        \item For all $t \geq 0$, $\nabla \log q_t$ is $L$-Lipschitz.
        \item For some $\eta > 0$, $q$ has a finite $(2+\eta)$-moment; furhter, $m_2 = \ee_{q}\left[ \norm{X}^2 \right]$.
        \item For all $1 \leq k \leq \tau$, it holds that $\norm{s_{kh} - \nabla \log q_{kh}}_{L^2(q_{kh})}^2 \leq \epsilon^2$.
    \end{enumerate}
    If $h \lesssim L^{-1} \wedge 1$, then
    \begin{align}
        \tv(p_{\tau}, q) \lesssim \sqrt{\dkl{q}{\cN(0, \eye)}} e^{- \tau h} + \left( L \sqrt{d h} + L m_2 h \right) \sqrt{\tau h} + \epsilon \sqrt{\tau h}.
    \end{align}
\end{theorem}
Note that they also have results when $q$ is supported on an arbitrary compact set.  This reduces the problem to estimating the score, $\nabla \log q_t$.

By \Cref{thm:sinho}, in order to sample from $q$, it suffices to have a good score estimate.  While there are no off the shelf results that do this for the specific setting that I know of, if we assume that $\nabla \log q$ is dissipative and we let $\qtil_t = q \ast \cN(0, t \eye)$, then \citet[Proposition 12]{block2020generative} provides a sample complexity bound in terms of Rademacher complexity that scales like $\BigOh{t^{-2}}$.  Assumedly something similar can be done with $q_t$ evolved according to the OU process instead of the heat kernel.


