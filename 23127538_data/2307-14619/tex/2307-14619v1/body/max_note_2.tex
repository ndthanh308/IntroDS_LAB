%!TEX root = ../main.tex

\newcommand{\asq}{a^{\square}}

\newcommand{\leftsig}{\leftarrow \sigma}


\newcommand{\arep}{a^{\circlearrowleft}}

\newcommand{\atilst}{\tilde{a}^\star}
\newcommand{\Wassd}{\cW_{\distA,\epsilon}}


\newcommand{\true}{\bmsf{true}}
\newcommand{\zetrep}{\zeta^{\circlearrowleft}}
\newcommand{\atilrep}{\tilde{\seqa}^{\circlearrowleft}}

\newcommand{\gamsttvc}{\gamma_{*\mathrm{tvc}}}
\newcommand{\diststil}{\dist^{}_{\cS}}




\newcommand{\Ind}{\mathbb{I}}
\newcommand{\Pstconv}{\Pst_{*\sigma}}
\begin{comment}
\begin{definition}\label{defn:rfis}We say that $\sfk$ is $(\betais,\gamis,\epsilon)$-\emph{robustly feedback incrementally input-state stable} at $\xi$ ($(\betais,\gamis,\epsilon)$-RFIS at $\xi$) if the following holds. Consider the dynamics $s_{1:H}$ given by $s_1 = \xi$ and  
\begin{align}
s_{h+1} = F_h(s_h,a_h), \quad a_h = \sfk_h(s_h,s_h\mid \seed_{h}), s_1 = \xi
\end{align}
And let $\sbar_{1:H} \in \cS^H$ be any sequence of states satisfying $\max_{h \in [H]}\dists(s_h,\sbar_h) \le \epsilon.$. 
Then, for every $\xi' \in \cS$, $a_{1:H}' \in \cA^H$, and $\seed_{1:H}\in \zspace^H$, the states $s'_1 = \xi'$ given by $ s'_{h+1} = F_h(a'_h,s'_h)$ satisfy
%,s_1' = \xi'
satisy, for all $h \in [H]$, and for $\tilde{\bar{a}}_h = \sfk_h(s_h', \sbar_h \mid \seed_h)$
\begin{align}
\dists(\sbar_h,s_h') \le \betais( \dists(\xi,\xi')) + \gamis(\max_{j \in [h-1]}\dista(\tilde{\bar{a}}_j, a_j' )).
\end{align}
%We say $\sfk$ is $(\betais,\gamis,\etaiss,\etaisa)$-locally FIS if the above only holds for all $\dists(\xi,\xi') \le \etais$ and $\dista(a_h,a_h') \le $
\end{definition}  
In words, robust-feedback incremental stability strengthens \Cref{defn:fis} to require feedback stability with respect to the policy along some sequence $\sbar_{1:H}$ close to $s_{1:H}$.

\begin{proposition}
\end{proposition}
\subsubsection{Proof}
Again, we inductively construct a coupling measure $\mu \in \couple(\Drand^{\otimes H},\Drand^{\otimes H},\Drand^{\otimes H})$ over not
\begin{align}
\seedst_{1:H}, \quad \seedhat_{1:H}, \quad \seedbar_{1:H}.
\end{align}
For these seeds, we maintain corresponding actions $\ahat_h,\abar_h,\astar_h \in \cA$ and states $\shat_h,\sstar_h \in \cS$ which are given by 
\begin{align}
&\sstar_{h+1} = F_h(\sstar_h,\astar_h),
\quad \sbar_{h+1} = F_h(\sbar_h,\abar_h), \quad \shat_{h+1} = F_h(\shat_h,\shat_h), 
\qquad  \sstar_1 = \sbar = \xist, \quad \shat_1 = \xihat \label{eq:sdefs_two}\\
&\astar_h = \sfkst_h(\sstar_h,\sstar_h \mid  \seedbar_h), \quad \abar_h = \sfkst_h(\sstar_h,\shat_h \mid \seedbar_h), \quad  \ahat_h = \sfkhat_h(\shat_h,\shat_h\mid \seedhat_h),  \label{eq:adefs_two}
\end{align}
In words, the construction is nearly identical to the construction in $\dots$, except now  the interpolating sequence $\sbar_h$ starts at $\xist$, and evolves according to $\abar_h = \sfkst_h(\sstar_h,\shat_h \mid \seedbar_h)$. 
\end{comment}

\section{General Smoothing}
Let $\Psth \in \laws(\cS)$ denote the marginal distribution of $s_h$ under $\Dist_{\pist}$ \ab{This should be defined once above and then referred to}.  A \emph{smoothing family} is a family of distributions  $(\Wsig)_{\sigma > 0} \in \laws(\cW)$ is a family of probability kernels on $\cS$. \mscomment{define probability kernel and dirac delta}
\newcommand{\dirac}{\bm{\updelta}}




\newcommand{\Dtel}{\Dist^{\mathrm{tel}}}


\begin{comment}
\ab{It is a bit confusing that we are referring to the initial states both by $\xi$ and by $\ssq_1$ or $\stel_1$}

\begin{definition}[Teleporting Distribution] We define $\Dtel$ as the distribution over $\stel_{1:H},\ssq_{1:H},\ktel_{1:H}$ generated as follows: 
\begin{align}
\stel_1 &\sim \Dinit, \quad\qquad\qquad\qquad\qquad\qquad\qquad \ssq_h \mid \stel_{1:h},\ssq_{1:h-1},\ktel_{1:h-1} \sim \Psthrep(\stel_h),  \\
\ktel_{h} &\mid \stel_{1:h},\ssq_{1:h},\ktel_{1:h-1} \sim \bpolst_h(\ssq_h), \qquad\qquad \stel_{h+1} = F_h(\ssq_h,\ktel_h).
\end{align}
We define $\Dist_{\pirep}$ as the distribution over states $\{\srep_{1:H},\krep_{1:H}\}$ given by 
\begin{align}
\srep_1 \sim \Dinit, \quad \krep_h \mid \srep_{1:h},\krep_{1:h-1}\sim \pistreph(\srep_h), \quad \srep_{h+1} = F_h(\srep_h,\krep_h).
\end{align}
\end{definition}
\msedit{
The difference between the replica and teleporting sequence is subtle but significant. First, their similarities: in the \emph{teleporting} sequence, we generate an intermediate state $\ssq_h \sim \Psthrep(\stel_h)$, and drawn $\ktel_h$ from $\bpolst_h(\ssq_h)$. Marginalizing over $\ssq_h$ ensures that $\ktel_h \mid \stel_{1:h},\ktel_{1:h-1} \sim \pireph(\stel_h) $. The same occurs in the \emph{replica} sequence: $\krep_h \mid \srep_{1:h},\krep_{1:h-1} \sim \pireph(\srep_h)$. The key \emph{difference} is in the dynamic update. Whereas the replica sequence proceeds as $\srep_{h+1} = F_h(\srep_h,\krep_h)$, the update in the teleporting sequence updates with $\stel_{h+1} = F_h(\ssq_h,\ktel_h)$ using the \emph{intermediate state} $\ssq_h$, rather than $\stel_h$, as its point of departure. Intuitively, $\stel_h$ ``teleports'' to $\ssq_h$ before updating to $\stel_{h+1}$; in the replica distribution, teleportation does not occur. Notice that replacing $\stel_{h+1} = F_h(\ssq_h,\ktel_h)$ with the update $\stel_{h+1} \gets F_h(\stel_h,\ktel_h)$ would ensure that $(\stel_{1:H},\ktel_{1:H})$ and $(\srep_{1:H},\krep_{1:H})$ are identically distributed.  }

Unlike the actual replical sequence, the \emph{teleporting} sequence satisfies what we call a \emph{marginal-preservation} property.


\newcommand{\Sinit}{\cS_{\mathrm{init}}}
\begin{remark}\mscomment{$\gamos(r) \lesssim e^{-\Omega(\ell)} r$ by stabilization. A trajectory is $H$ steps of $\ell$-step rollouts. Each $h \in [H]$, we rollout $\ell$ things}
\end{remark}




\begin{proposition}\label{prop:rep_sig_imitation} 
Suppose that (a) $\pist$ is $\gamos$-OSS, (b) that $\Psthrep(\cdot)$ is $\gamsttvc$-TVC, and that (c) $\iota_{\sigma}(\cdot)$ is a concentration function for $\Wsig$. Then, for any $\rsmooth > 0$ satisfying  $\gamos(2 \rsmooth) \le \rsmooth$, 
\begin{align}\label{eq:coup_bound}
\inf_{\coup}\Pr_{\coup}[\exists h: \dists(\srep_{h},\stel_{h}) > \gamos(2\rsmooth) \text{ or } \ktel_h \ne \krep_h ] \le H\left(2\pconc(\rsmooth) + \gamsttvc(\gamos(2\rsmooth))\right)
\end{align}
where the infinum is over all couplings $\coup \in \couple(\Dtel,\Dist_{\polst_{\repsig}})$, where $\srep_{1:H},\krep_{1:H} \sim \Dist_{\polst_{\repsig}}$,  $\stel_{1:H},\ktel_{1:H} \sim \Dtel$. 
\end{proposition}
\mscomment{fix - write out correct coupling}
\mscomment{this ininfum should be over couplings with some structure so we can do gluing later}

\begin{corollary} Suppose that the distribution $\Wsig$ is such that (a) that $\pist$ is $\gamos$ w.r.t. $\diststil$, 
(b) $\Pconv(\cdot)$ is $\gamsttvc$ with respect to $\diststil$,   and (c) that for all $r > 0$,  $\sup_{s} \Pr_{w \sim \Wsig}[\diststil(w(s),s) >  r] \le \pconc(r)$. Then, \eqref{eq:coup_bound} holds for any for any $\rsmooth > 0$ satisfying  $\gamos(2 \rsmooth) \le \rsmooth$.
\end{corollary}
\begin{proof}
It is clear that condtions (a) and (c) of the corollary imply the corresponding conditions in \Cref{prop:deconvolutioncontinuity}. It remains to show that if $\Pconv(\cdot)$ is $\gamsttvc$ with respect to $\diststil$, then so its $\Psthrep(\cdot)$. 
\end{proof}

\begin{remark} The above bound holds under the weaker condition in \eqref{eqqq:concentration_conv}. 
\end{remark}

\subsection{Imitiation Learning Under Smoothing}

\begin{align}
\Exp_{\stel_h}\left[\drob(\polhat,\polst \mid \stel_h,h)\right] = \Exp_{\stel_h}\inf_{\coup}\Pr_{\coup}\left[\sup_{s':\dists(s,s') \le \epsilon }\distA\left(\eval_h(s',\hat \sfk_h),\eval_h(s',\sfkst_h)\right) \le \eta \right].
\end{align}
\end{comment}






