%!TEX root = ../main.tex

\section{Warmup: Analysis Without Augmentation}\label{app:no_augmentation}
In this section, we give a simplified analysis that replaces the smoothing kernels $\Wsig$ with the assumption that the learner policy $\pihat$ is already total variation continuous.  The removal of the coupling kernel makes the coupling construction considerably simpler while still communicating some intuition for the full proof in \Cref{sec:imit_composite}.

Throughout this section, we make the following assumptions on the state and action spaces, along with their associated metrics:
\begin{assumption} \label{ass:polishspaces}
    We assume that $\cS$ and $\cA$ are Polish spaces. This means they are metrizable, but we do not annotate their metrics because, e.g. the metric on $\cS$ may be other than $\dists$. We further assume that 
\begin{itemize}
\item $\dists,\disttvc$ are pseudometrics and Borel measurable function from $\cS \times \cS \to \R_{\ge 0}$
\item For any $\epsilon \ge 0$, the set $\{(\seqa,\seqa') \in \cA \times \cA : \dista(\seqa,\seqa') > \epsilon\}$ is an open subset of $\cA\times \cA$; i.e. $\dista(\cdot,\cdot)$ is lower semicontinuous. In particular, this means $\dista$ is a Borel measurable function.
\end{itemize}
\end{assumption}
Recall the definitions of total variation continuity (TVC) and input-stability in \Cref{sec:analysis}. The main result of this section is as follows. 

\begin{proposition}\label{prop:IS_general} Let $\polst$ be input-stable w.r.t. $(\dists,\phia)$ and let $\polhat$ be $\gamma$-TVC. Then, for all $\epsilon > 0$, 
\begin{align}\gapjoint(\polhat \parallel \pist) \le  H\gamma(\epsilon) + \sum_{h=1}^H \Exp_{\sstar_h \sim \Psth}\drob(\polhat_h(\sstar_h) \parallel \polst(\sstar_h) ).
\end{align}
\end{proposition}


\begin{proof}
The key to the proof is to construct an appropriate ``interpolating sequence'' of actions $\ainter_{1:H}$ to which we couple both $(\sstar_{1:H+1},\seqa^\star_{1:H})$ and $(\shat_{1:H+1},\seqahat_{1:H})$.  This technique will be used in a significantly more sophisticated manner in the sequel to prove the analogous result with smoothing.

Let $\cF_h$ denote the $\upsigma$-algebra generated by $(\sstar_{1:h},\seqa^\star_{1:h})$, $(\shat_{1:h},\seqahat_{1:h})$, and $\ainter_{1:h}$, and let $\cF_0$ denote the $\upsigma$-algebra generated by $\sstar_1,\shat_1$. We construct couplings of the following form:
\begin{itemize}
    \item The initial states are generated as $\sstar_1 = \shat_1  \sim \Dinit$.
    \item The dynamics are determined by $F_h$:
    \begin{align}
&\sstar_{h+1} = F_h(\sstar_h,\seqast_h), \quad \shat_{h+1} = F_h(\shat_h,\seqahat_h) \label{eq:imitiation_dyn}
\end{align}
In particular, $\sstar_{h+1},\shat_{1:h+1}$ are $\cF_h$ measurable.
\item The conditional distributions of the primitive controllers satisfy the following 
\begin{align}
\seqast_h \mid \cF_{h-1} \sim \pist_h(\sstar_h), \quad \seqahat_{h-1} \mid \cF_{h-1} \sim \pihat_h(\shat_h), \quad \ainter_h \mid \cF_h \sim \pihat_h(\sstar_h). \label{eq:inter_acts}
\end{align}
\end{itemize}
Note that if $\coup$ satisfies the above construction,  then $(\sstar_{1:H+1},\sstar_{1:H}) \sim \Dist_{\pist}$ and $(\shat_{1:H+1},\seqahat_{1:H}) \sim \Dist_{\pihat}$.

\paragraph{Specifying the rest of the coupling.} It remains to specify the coupling of the terms in \eqref{eq:inter_acts}.
We establish our coupling sequentially. Let $\coup^{(0)}$ denote the coupling of $\shat_1 = \sstar_1 \sim \Dinit$.

Assume we have constructed the coupling up to state $h-1$.For ease, let $Y_{h-1}$ denote the random variable corresponding to $(\sstar_{1:h},\shat_{1:h},\seqa^\star_{1:h-1},\seqahat_{1:h-1},\ainter_{1:h-1})$; note that $Y_{h-1}$ is $\cF_{h-1}$-measurable (as $\shat_h,\sstar_h$ are determined by the dynamics \eqref{eq:imitiation_dyn}). Observe that, by the assumption of $\pihat_h$ being TVC, it holds that  
\begin{align}
\TV(\Pr_{\seqahat_h  \mid Y_{h-1}}, \Pr_{\ainter_h  \mid Y_{h-1}}) \le \gamma(\disttvc(\shat_{h},\sstar_h)).
\end{align}
Thus by \Cref{lem:tv_coupling_equiv}, there exists a coupling $\coup^{(h)}_{1}$ between $Y_{h-1},\seqahat_h,\ainter_h$, with $Y_{h-1} \sim \coup^{(h-1)}$ such that it holds that
\begin{align}
\Pr[\seqahat_h \ne \ainter_h] \le \Exp_{\coup^{(h-1)}}[\gamma(\disttvc(\shat_{h},\sstar_h))].
\end{align}
Similarly by \Cref{prop:MK_RCP}, there is a coupling $\coup^{(h)}_{2}$ of $Y_{h-1},\ainter_h,\astar_h$ such that
\begin{align}
\Pr_{\coup^{(h)}_2}[\dista(\ainter_h,\astar_h) \ge \epsilon] \le \Exp_{\sstar_h \sim \coup^{(h-1)}}[\drob(\pihat_h(\sstar_h),\pist_h(\sstar_h))].
\end{align}
By the gluing lemma \Cref{lem:couplinggluing} and a union bound, we may construct a coupling $\coup^{(h)}$ of $Y_h,\ainter_h,\astar_h,\seqahat_h$ such that  (almost surely),
\begin{align}
&\Pr_{\coup^{(h)}}[\{\dista(\ainter_h,\astar_h) \ge \epsilon\} \cup \{\seqahat_h \ne \ainter_h\} \mid \cF_{h-1}] \\
&=\Pr_{\coup^{(h)}}[\{\dista(\ainter_h,\astar_h) \ge \epsilon\} \cup \{\seqahat_h \ne \ainter_h\} \mid Y_{h-1}] \\
&\qquad\le \gamma(\disttvc(\shat_{h},\sstar_h))] + \drob(\pihat_h(\sstar_h),\pist_h(\sstar_h)) \label{eq:simple_imitation_intermediate}
\end{align}
Thus inductively, we may continue this construction for $h \leq H$ and let $\coup = \coup^{(H)}$. 

\paragraph{Concluding the proof.} Define the event $\cB_h := \{\dista(\seqa_h,\ainter_h) \le \epsilon\}$ and $\cC_h =\{\ainter_h = \ahat_h\}$. Then, by \Cref{lem:peeling_lem}
\begin{align}
\Pr_{\coup}\left[(\bigcap_{h=1}^H \cB_h \cap \cC_h)^c\right] &\le  \sum_{h=1}^H\Pr_{\coup}\left[(\bigcap_{j=1}^{h-1} \cB_j \cap \cC_j) \cap(\cB_h^c \cup \cC_h^c)\right]. \label{eq:peeling_easy}
\end{align}
Note first that $(\bigcap_{j=1}^{h-1} \cB_j \cap \cC_j)$ is $\cF_{h-1}$ measurable. On this event, input stability at $\ainter_j = \ahat_j$, $1 \le j \le h-1$, implies that 
\begin{align}
\dists(\sstar_h,\shat_h) \le \epsilon.
\end{align}
Thus, \eqref{eq:simple_imitation_intermediate} implies that 
\begin{align}
\Pr_{\coup}\left[(\bigcap_{j=1}^{h-1} \cB_j \cap \cC_j) \cap(\cB_h^c \cup \cC_h^c)\right] &\le \Exp_{\coup}[\gamma(\disttvc(\shat_{h},\sstar_h))\I\{\disttvc(\shat_{h},\sstar_h) \le \epsilon\} + \drob(\pihat_h(\sstar_h),\pist_h(\sstar_h)) \mid \cF_{h-1}]\\
&\le \gamma(\epsilon) + \ee_{\coup}\left[\Exp_{\coup}[\drob(\pihat_h(\sstar_h),\pist_h(\sstar_h)) \mid \cF_{h-1}]\right]\\
&= \gamma(\epsilon) + \Exp_{\coup}[\drob(\pihat_h(\sstar_h),\pist_h(\sstar_h))] \\
&= \gamma(\epsilon) + \Exp_{\sstar_h \sim \Psth}\Exp_{\coup}[\drob(\pihat_h(\sstar_h),\pist_h(\sstar_h))],
\end{align}
where the first equality follows from the tower rule for conditional expectations and the second follows because $\sstar_h \sim \lawP_h^\star$ under $\coup$.  Summing and applying \eqref{eq:peeling_easy} implies that 
\begin{align}
\Pr_{\coup}\left[(\bigcap_{h=1}^H \cB_h \cap \cC_h)^c\right] &\le H\gamma(\epsilon) + \sum_{h=1}^H\Exp_{\sstar_h \sim \Psth}[\drob(\pihat_h(\sstar_h),\pist_h(\sstar_h))].
\end{align}
Again, invoking input stability and the definitions $\cB_h := \{\dista(\seqa_h,\ainter_h) \le \epsilon\}$ and $\cC_h =\{\ainter_h = \ahat_h\}$, $(\bigcap_{h=1}^H \cB_h \cap \cC_h)^c$ implies that 
\begin{align}
\max_{1 \le h \le H} \max\{\dists(\sstar_{h+1},\shat_{h+1}) , \dista(\seqa^\star_h,\seqahat_h)\} \le \epsilon.
\end{align}
This concludes the proof. 


\end{proof}