%!TEX root = ../main.tex


\paragraph{A simplified guarantee. } Before we sketch the proof of \Cref{thm:smooth_cor}, we present a simpler guarantee with \emph{no smoothing}, but where $\polhat$ is guaranteed to be $\gamma$-TVC. This result is more transparent, and its proof sketch will inform our sketch of \Cref{thm:smooth_cor} below. 

\begin{restatable}{proposition}{Isgen}\label{prop:IS_general_body} Suppose for simplicity that $\dists = \disttvc$. Let $\polst$ be input-stable w.r.t. $(\dists,\phia)$ and let $\polhat$ be $\gamma$-TVC. Then, for all $\epsilon > 0$, 
\begin{align}\gapjoint(\polhat \parallel \pist) \le  H\gamma(\epsilon) + \sum_{h=1}^H \Exp_{\sstar_h \sim \Psth}\drob(\polhat_h(\sstar_h) \parallel \polst(\sstar_h) ) \label{eq:gap_joint_bound}
\end{align}
\end{restatable}
\begin{remark} One can show that, if $\pihat$ is implemented as a DDPM with a Lipschitz activation with bounded-magnitude parameters, it is indeed $\gamma$-TVC where $\gamma$ depends on some Lipschitz constant of the neural network. Unfortunately, these Lipschitz constants can be sufficiently large as to be meaningless in most practical scenarios, scaling exponentially with network depth. Hence, we require the additional sophistication of smoothing noise, as is studied in \Cref{thm:smooth_cor}.
\end{remark}
\begin{proof}[Proof Sketch] We couple a trajectory $(\sstar_h,\astar_h)$ induced by $\pist$ with a trajectory $(\shat_h,\ahat_h)$ induced by $\pihat$. To do so, consider an inductive event on which all past states and actions are close
\begin{align}
\cE_h = \{\forall  j \le h, ~ \disttvc(\shat_{j},\sstar_{j}) \vee \dists(\shat_{j},\sstar_{j}) \le \epsilon\} \cap \{\forall j \le h-1, ~ \dista(\ahat_{j},\astar_{j}) \le \epsilon\} \label{eq:inductive_hyp},
\end{align}
which can be made to hold with probability one for $h = 1$ by ensuring $\shat_1 = \sstar_1 \sim \Dinit$. It suffices to find a $\coup$ coupling under which $\Pr_{\coup}[\cE_{H+1}]$ is bounded by the righthand side of \eqref{eq:gap_joint_bound}. 

When $\cE_h$ holds, then as $\polhat$ is $\gamma$-TVC, $\ahat_h \sim \polhat_h(\shat_h)$ is $\gamma(\epsilon)$-close in $\tv$ distance to an interpolating action $\ahat^{\mathrm{inter}}_h \sim \polhat_h(\sstar_h)$. Thus, there is a coupling under which $\Pr[\ahat_h \ne \ahat^{\mathrm{inter}}_h ] \le \gamma(\epsilon)$. Moreover, by definition of $\drob$, there exists a coupling under which $\Pr[\distA(\ahat_h^{\mathrm{inter}}, \astar_h) > \epsilon] \le \Exp_{\sstar_h \sim \Psth}\drob(\polhat_h(\sstar_h) \parallel \polst(\sstar_h) )]$. 
Thus, by ``gluing'' the couplings together (an operation rigorously justified in \Cref{app:prob_theory}), we have 
\begin{align}
\Pr[\cE_h \cap\{\distA(\ahat_h, \astar_h) > \epsilon\}] \le \gamma(\epsilon) + \Exp_{\sstar_h \sim \Psth}\drob(\polhat_h(\sstar_h) \parallel \polst(\sstar_h) )]. \label{eq:Eh_bound_easy}
\end{align}
Invoking the defition of input stability (\Cref{defn:fis}), $\cE_h$ and $\distA(\ahat_h, \astar_h) \le \epsilon$ imply $\cE_{h+1}$. Therefore, by selecting couplings appropriately, $\Pr[\cE_h \cap \cE_{h+1}^c]$ is also bounded by the righthand side of \eqref{eq:Eh_bound_easy}.  As the events $(\cE_h)$ are nested, we can finally telescope to bound $\Pr[\cE_{H+1}]$ by summing up these terms for each $h$. A full proof is given in \Cref{app:no_augmentation}.
\end{proof}

 \subsection{Proof Overview of \Cref{thm:smooth_cor}}

In this sketch, we focus on bounding $\gapjoint (\pihat \circ \Wsig \parallel \pistrep)$; we adress $\gapmarg[\epsilon'] (\pihat \circ \Wsig \parallel \pist)$ at the end of the section. 
Our argument constructs a  coupling between a \emph{replica trajectory} over $(\srep_h, \arep_h)$ sampled using the replica policy $\pistrep$, and an  \emph{imitator trajectory} $(\shat_h, \seqahat_h)$  sampled from $\pihat_{\sigma}$. The construction of this coupling  draws inspiration from the notion of replica pairs in statistical physics (hence, the name replica) \citep{mezard2009information}.  






  \paragraph{The replica kernel.} A central object in our proof is the \emph{replica kernel}  $\Qreph: \cS \to \laws(\cS)$, defined so that $\pireph = \pisth \circ \Qreph$, and constructed by analogy to the replica policy in \Cref{defn:body_replica}. The key property of the replica kernel is that it preserves marginals: if $\seqs_h \sim \Psth$ is drawn from the distribution of states under the expert demonstrations, then $\seqs_h' \sim \Qreph(\seqs_h)$ is also distributed as $\Psth$; in other words, $\Psth$ is a fixed point of $\Qreph$:
  \begin{fact}[Replica Property] It holds that $\Psth = \Qreph \circ \Psth $.   \label{fact:Psth_Qreph_inductively}
  \end{fact}
  A second crucial property is that we can represent the replica kernel as a convolution between $\Wsig$ and a deconvolution kernel. Thus, data-processing implies that $\Qreph$ inherits TVC from $\Wsig$.
  \begin{fact}[Replica Kernel is TVC] If $\Wsig$ is $\gamtvc$-TVC, $\Qreph$ is as well.
  \end{fact}


  \paragraph{Constructing the replica and \emph{teleporting} trajectories.} Because the replica kernel satisfies $\pistreph = \Qreph \circ \pist$, we can realize the replica trajectory via 
  \begin{align}
  \sreptil_h \sim \Qreph(\srep_h), \quad \arep_h \sim \pisth(\sreptil_h), \quad \srep_{h+1} = F_h(\srep_h,\arep_h), \quad \srep_1 \sim \Dinit.
  \end{align} 
  We then introduce a  \emph{teleporting}  trajectory obeying the an almost identical generative process:
  \begin{align}
  \ssq_h \sim \Qreph(\stel_h), \quad \arep_h \sim \pisth(\ssq_h), \quad \stel_{h+1} = F_h(\ssq_h,\atel_h), \quad \atel_1 \sim \Dinit.
  \end{align} 
  In words, $\stel_h$ ``teleports'' to an independent and identically distributed copy conditional on the noise agumentation $\ssq_h$, and draws an action from the expert policy evaluated on the new state. The replica and teleporting sequences differ only in the transitions: whereas $\srep_{h+1} = F_h(\srep_h,\arep_h)$ transitions from its \emph{current} state $\srep_h$, the telporting trajectory transition $\stel_{h+1} = F_h(\ssq_h,\atel_h)$ from the \emph{replica-drawn}, ``teleported'' state $\ssq_h \sim \Qreph(\stel_h)$.  By iteratively applying \Cref{fact:Psth_Qreph_inductively}, and the fact that $\stel_h \sim \pisth(\ssq_h)$, we can make the following claim:
  \begin{fact} For each $h$, $\stel_h$ and $\ssq_h$ are distributed according to $\Psth$, the marginal distribution of states under the expert policy. Hence, because $\stel_h \sim \Psth$, we know that $\pihat$ and $\pisth$ are close under the distribution of states induced teleporting sequence.
  \end{fact}
  
  \paragraph{Constructing the coupling.} We now describe how to use the teleporting trajectory to couple the replica and imitator trajectory. We begin by coupling the replica and imitator trajectories. The following diagram explains how we construct the coupling: 
  \begin{align}
    \underbrace{(\sreptil\leftrightarrow \ssq),(\arep \leftrightarrow \atel)}_{\text{$\gamtvc$, $\gamipsone$, and induction}} \to \underbrace{(\atel \leftrightarrow \atelinter)}_{\text{learning and sampling}} \to \underbrace{(\atelinter \leftrightarrow \arepinter)}_{\gamtvc \text{ and induction}} \to \underbrace{(\arepinter \leftrightarrow \seqahat)}_{ \text{$\gamtvc$, input-stability, and induction}}. \label{eq:mainproofoutlinebody}
  \end{align}
  As the dynamics are deterministic, \eqref{eq:mainproofoutlinebody} determines the coupling of states $\srep_h,\stel_h,\shat_h$ as well. 
  \begin{itemize}
  	\item[(a)] We begin by arguing that replica and teleporting trajectories are close to one another. The argument is inductive: suppose that $\disttvc(\srep_h,\stel_h)$ are close. By TVC of the replica kernel, $\sreptil_h$ and $\ssq_h$ are close in $\tv$, and so there is a coupling under which 
  	\begin{align}
  	\Pr[(\arep_h,\sreptil_h) \ne (\atel_h,\ssq_h)] \text{ is small. }
  	\end{align} 
  	Next, recall $ p_r := \sup_{\seqs}\Pr_{\seqs' \sim \Wsig(\seqs)}[\distips(\seqs',\seqs) >  r]$ as defined in \Cref{thm:smooth_cor}, which describes the concentration behavior of $\Wsig$. We use a Bayesian concentration argument (\Cref{lem:rep_conc}) to ensure that with probability of failure at most $2p_r$, $\distips(\sreptil_h,\srep_h) \le 2r$. We then use IPS (\Cref{defn:ips_body}) to argue that, with the same failure probability,
  	\begin{align}
  	\srep_{h+1} = F_h(\srep_h,\arep_h) \text{ is within $\cO(r)$ $\disttvc$-distance of }  F_h(\sreptil_h,\arep_h).
  	\end{align}
  	Thus, when $(\arep_h,\sreptil_h) = (\atel_h,\ssq_h)$, we obtain that $\srep_{h+1}$ is close to $F_h(\atel_h,\ssq_h) = \stel_{h+1}$ in $\disttvc$ as well. For more detail, consult \Cref{fig:coupling_illustration} in the appendix.
  	\item[(b)] Because the marginals of $\stel_h$ are distributed according to $\Psth$,  we can argue that a (fictitious) action $\atelinter_h \sim  (\pihat_{h}\circ \Wsig)(\stel_h)$ is close to $\atel_h$. Indeed, by the data processing inequality, it is bounded by the closeness of $\pihat_h$ and $\pidech$ on $\ssq_h \sim \Wsig(\stel_h)$, $\stel_h \sim \Psth$; this is controlled by the contribution of $\drob( \pihat_{h}(\sstartil_h) \parallel \pidec(\sstartil_h))$ on the right-hand-side of \eqref{eq:smooth_ub}. 
  	\item[(c)] From part (a) of the coupling, we expect that $\srep_h$ and $\stel_h$ are close.  As $\pihat \circ \Wsig$ is $\gamtvc$ by the data-processing inequality, it follows that $\atelinter_h$ is close in TV distance to another fictious action $\arepinter_h \sim  (\pihat_{h}\circ \Wsig)(\srep_h)$. 
  	\item[(d)] Finally, we argue that that trajectory of actions induced by taking the replica-interpolating action $\arepinter_h$ is close to $\tv$ to the imitation trajectories induced by taking $\ahat_h$. The argument is similar in spirit to the proof of \Cref{prop:IS_general_body} sketched above, and uses both TVC of the smoothed policy $\pihat \circ \Wsig$, and the form of input-stability guaranteed by \Cref{defn:ips_body}. 
  \end{itemize}
  


   %$\srep_{h+1} = F_h(\srep_h, \arep_h)$, and $\stel_{h+1} = F_h(\ssq_h, \atel_h)$, where $\ssq_h$ is sampled from the replica distribution of $\stel_h$ and $\atel_h \sim \pist_h(\ssq_h)$; 


   %$(\stel_h, \atel_h)$ and trajectories $(\stel_h, \atelinter_h)$ and $(\srep_h, \arepinter_h)$ which interpolate between the teleporting and replica trajectories.  We sample $\shat_1 = \srep_1 = \stel_1$  according to $\Dinit$ and we let $\shat_{h+1} = F_h(\shat_h, \ahat_h)$,  To define the actions, we let $\arep_h$ be sampled from $\pistreph[h](\srep_h)$, $\ahat_h$ from $\pihatsigh[h](\shat_h)$, $\atelinter_h$ from $\pihatsigh[h](\stel_h)$, and $\arepinter$ from $\pihatsigh[h](\srep_h)$.  

 
   \paragraph{Bounding the marginal gap.} Because the {teleporting sequence} $\stel_h$ has marginals $\Psth$, bounding the marginal gap amounts to controlling the distance between $\stel_h$ and $\shat_h$. This follows from more-or-less the same manipulations.\footnote{A key difference is that we pick up an additive factor of $\gamipstwo$ (measuring sensitivity of $\dists$ to the smoothing from $\Wsig$) in our tolerance $\epsilon'$.}


  \paragraph{Measure-theoretic considerations.} 
   We construct conditional couplings between pairs of the aforementioned trajectories, each of which corresponds to a certain optimal transport cost. That past trajectories can be associated to optimal couplings measurably is non-trivial, and proven in \Cref{prop:MK_RCP}. To conclude, we apply a measure theoretic result (\Cref{lem:couplinggluing}) to ``glue'' the pairwise couplings together and establish the main result. The full proof is given in \Cref{sec:imit_composite}, relying on measure-theoretic details in \Cref{app:prob_theory}.
\qed