%!TEX root = ../neurips_main.tex


The role of a synthesis oracle satisfying \Cref{asm:iss_body} is to replace a strong assumption on the stability of an \emph{expert demonstration} with an \emph{algorithmic assumption} that allows post-hoc stabilizing of expert demonstrations.  This approach presents a natural question: in what sense is this tradeoff a sensible one?  To answer this, consider a paradigmatic case, where the demonstrations solve some complicated task in a smooth, nonlinear control system. Suppose further that the one-step dynamics of the system are known, but that the expert demonstrations come from some optimal control law which is computationally prohibitive to compute, or possibly even some mixture of different, mutually-incompatible trajectories. Assuming the Jacobian linearizations of the nonlinear system are stabilizable (see \Cref{app:control_stability} for further details), one can implement a synthesis oracle for affine gains directly by solving a Ricatti recursion on the Jacobian-linearized dynamics around each expert trajectory. \iftoggle{arxiv}{Note that both steps require only reasonably accurate models of system dynamics, but no long horizon planning}{}. 
%
Conceptually, this has the following interpretation: \textbf{Our framework reduces the problem of imitating a complex expert trajectory to (i) supervised generative modeling and (ii) solving strictly \emph{local} control problems}.

That is, we offload complex behavior of the expert being imitated, and reduce the learner's burden to solving  local control problems that are significantly simpler than global planning. For more general systems, \Cref{app:gen_controllers} addresses possibly non-affine stabilizing gains, and discusses how these may arise from standard practices of using robotic position control or inverse dynamics.  \Cref{sec:comparison_to_prior} compares our hierarchical approach to  stability to standard formulations that apply to the expert distribution, and we show how the latter rule out the possibility for complex behaviors such as bifurcated trajectories.  

\paragraph{Limitations and Future Directions.} Our above example required access to differentiable (indeed, smooth) system dynamics. Stabilizing systems with contact dynamics remains an outstanding challenge. More generally, an overtly hierarchical approach may be inefficient for many reasons, notably (1) the dimension of the primitive controller may be much higher than the dimension of raw control inputs; and (2) when the high-level and low-level controllers are parametrized by the neural networks, explicit heirarchy with separate models may preclude shared representation learning. Developing a more comprehensive approach to stability (perhaps one that does not require explicit gain synthesis, and extends to non-smooth systems) is an exciting direction for future work.  Nevertheless, we think that \textbf{our conceptual contribution of decoupling low-level stability and generative matching of demonstrated behavior will prove useful in future endeavors for reliable and performant behavior cloning.}