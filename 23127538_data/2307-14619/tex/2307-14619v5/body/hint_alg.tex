%!TEX root = ../neurips_main.tex

\section{\toda: Instantiating Data Noising with DDPMs}
\label{sec:algorithm}
We now instantiate \Cref{thm:main_template} by showing that one can learn a policy $\pihat$ for which the error terms in \Cref{thm:main_template,prop:TVC_main} are small  by fitting a DDPM to noise-smoothed data.
\iftoggle{arxiv}
{
  
}
{}
\begin{algorithm}\iftoggle{arxiv}{[!t]}{[h]}
  \begin{algorithmic}[1]
  \State{}\textbf{Initialize} Synthesis oracle $\synth$, sample sizes $\Nsample,\Naug \in \N$, $\sigaug \ge 0$, DDPM step size $\dpstep > 0$, DDPM horizon $\dphorizon$, function class $\{\scoref_{\theta}\}_{\theta \in \Theta}$, gain magnitude $R >0$, empty data buffer $\Imitdata \gets \emptyset$. 
  \Statex{} \algcomment{For no smoothing, set $\sigaug = 0$ and $\Naug = 1$}
  \For{$n =1,2,\dots \Nsample$}
  \State{}Sample $\ctraj_T = (x_{1:T+1},u_{1:T}) \sim \Dexp$ and set $\sfk_{1:T} = \synth(\ctraj)$ 
  \Statex{}~~~~\algcomment{Segment $ \pathm[1:H]$ from $\ctraj_T$ and $ \seqa_{1:H}$ from $\sfk_{1:T}$}
  \For{$i = 1,2,\dots,\Naug$ and $h = 1,2,\dots,H$}
  \State{}Sample $\pathmtil \sim \cN(\pathm,\sigaug^2 \eye_{})$,  $\dpind_h \sim \mathrm{Unif}([\dphorizon])$ and $\bgamma_h \sim \cN(0, (\dpind_h \alpha)^2 \eye)$.
    %
    \State{} $\Imitdata \gets \Imitdata.\mathrm{append}\left(\{ (\seqa_{h}, \pathmtil[h],  \dpind_{h}, \bgamma_{h},h) \}\right)$
    \EndFor
  \EndFor
  \State{}Fit $\theta \in \argmin_{\theta \in \Theta}\Lddpm(\theta, \Imitdata)$, and let $\pihat = (\pihat_h)$ be given by $\pihat(\cdot \mid \pathm) = \ddpm(\bs_{\theta,h}, \pathm)$. \label{line:DDPM_train}
  \State{}\label{line:test_time} \textbf{return} $\pihat_{\sigma} = (\hat \pi_{\sigma,h})$, by smoothing $\pihat$ as per \Cref{defn:smoothed_policy}. 
  \caption{ \
  \textbf{H}ierarchical \textbf{I}mitation via \textbf{N}oising at Inference \textbf{T}ime ($\toda$)}
  \label{alg:imitation_augmentation}
  \end{algorithmic}
\end{algorithm}
\iftoggle{arxiv}{\paragraph{Algorithm.}}{} Our proposed algorithm, $\toda$ (\Cref{alg:imitation_augmentation}) combines DDPM-learning of chunked policies as in \cite{chi2023diffusion} with a popular form of data-augmentation \citep{ke2021grasping}. We collect $\Nsample$ expert trajectories, synthesize gains, and segment trajectories into observation-chunks $\pathm$ and composite actions $\seqa_h$ as described in \Cref{sec:setting}. We perturb  each $\pathm$ to form $\Naug$ chunks $\pathmtil$, as well as horizon indices $\dpind \in [\dphorizon]$ and inference noises $\bgamma \sim \cN(0, (\dpstep \dpind_h)^2 \eye)$, 
and add these tuples $(\seqa_h, \pathmtil, \dpind_h, \bgamma_h,h)$ to our  data $\Imitdata$. We end the training phase by minimizing the standard DDPM loss \citep{song2019generative}\iftoggle{workshop}{ $\Lddpm(\theta, \Imitdata)$:
  \begin{align}
     \sum \norm{\bgamma_h - \scoref_{\theta,h}\left(e^{-\dpstep \dpind}\seqa_h + \sqrt{1 - e^{-2\dpstep \dpind}}\bgamma_h, \pathmtil, \dpind_h\right)}^2,\label{eq:ddpmcond}
  \end{align}
  where the sum is over $(\seqa_h, \pathctil,  \dpind_{h}, \bgamma_h,h) \in \Imitdata$.
}{:
\begin{align}
  \iftoggle{arxiv}{}{\textstyle}\Lddpm(\theta, \Imitdata) = \sum_{(\seqa_h, \pathctil,  \dpind_{h}, \bgamma_h,h) \in \Imitdata} \norm{\bgamma_h - \scoref_{\theta,h}\left(e^{-\dpstep \dpind}\seqa_h + \sqrt{1 - e^{-2\dpstep \dpind}}\bgamma_h, \pathmtil, \dpind_h\right)}^2.\label{eq:ddpmcond}
\end{align}
}
Our algorithm differs subtly from past work in \Cref{line:test_time}: motivated by \Cref{thm:main_template}, we add smoothing noise \emph{back in} at test time. Here, the notation $\ddpm(\bs_{\theta,h}, \cdot) \circ \cN(\pathm, \sigaug^2 \eye)$ means, given $\pathm$, we perturb it to $\pathmtil \sim \cN(\pathm, \sigaug^2 \eye)$, and sample $\seqa_h \sim \ddpm(\bs_{\theta,h}, \pathmtil[h])$. 
\iftoggle{arxiv}{}{
We now state an informal guarantee for \toda{}, deferring a formal statement to  \Cref{sec:formal_hint_guars}. 
\begin{theorem*}[Informal Theorem] Suppose that the system dynamics are smooth and that \Cref{asm:iss_body} holds for the linearized system.  Then there is a choice of the parameters in $\toda$ that is polynomial in all problem parameters such that for $\Nsample$, polynomially large in problem parameters, $\Imitmarg(\widehat{\pi}_\sigma) \leq \Theta\left(\epsilon H \sqrt{\taum}(\sqrt{\dimx} + \log(1/\epsilon )) \right)$ with high probability.
\end{theorem*}
}

%\mscomment{TODO experimental results}

\iftoggle{arxiv}
{
  \input{body/arxiv_experiments}
} 
{
  \input{body/neurips_experiments}
}

%%%%%%HINT RESULTS
\iftoggle{arxiv}
{
  \input{body/hint_formal_results}
}
{

}