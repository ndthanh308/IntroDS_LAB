%!TEX root = ../main.tex


As with \Cref{prop:TVC_main}, the key ideas of the proof are given  \Cref{sec:analysis}, expressed in terms of a general abstraction for behavior cloning we call the ``composite MDP''.  This template is instantiated with a details in \Cref{app:end_to_end}. Moreso than \Cref{prop:TVC_main}, the proof of \Cref{thm:main_template} requires sophisticated couplings between expert and learner trajectories, and in particular. The intuition is based on the observation that $\pihat_{\sigma,h}$ mimic $\pirepsigh := (\pidecsigh)_{\sigma}$, the smoothing of the deconvolution policy. Inspired by replica pairs in statistical physics, we call $\pirepsig$ the ``replica'' policy because actions from $\pirepsigh$ can be thought of as actions from $\pist_h$ that have been noised and deconvolved. This implies:
\begin{fact} Let $\pathm \sim \cDh$. Then, the distributions of $\seqa_h \sim \pist_h(\pathm)$, and $\seqa_h' \sim \pirepsigh(\pathm)$, marginalized over $\pathm$, are identical. 
\end{fact}

This observation can be interpreted as meaning that smoothing and deconvolution are inverse operations at the distributional level. In particular, for a moment, consider an idealized environment where $\seqa_h$, and not $\pathm$, perfectly determined the dynamics (e.g. by teleportation), then $\pirepsig = (\pirepsigh)$ and $\pist = (\pist_h)$ would induce the same dynamics (and, as remarked above, $\Imitmarg(\pist) = 0$).

For non-idealized  environments, the argument goes as follows: We  couple  $\seqa_h \sim \pist_h(\pathm)$, and $\seqa_h' \sim \pirepsigh(\pathm)$ so that $\seqa_h'$ has the distribution of $\seqa_h' \sim \pist(\pathm')$, where $\pathm'$ is distributed as $\pathm$ and, with high probability, $\pathm'$ and $\pathm$ are $\tilde{O}(\sigma)$-close in Euclidean norm. This coupling is depicted \Cref{fig:replica_fig}. We then argue that the dynamics induced by $\pirepsig$ track those of $\pist$ by roughly a similar margin. Moreover, by smoothing $\pihat_h$ and $\pidech$ and applying Jensen's inequality, 
 \begin{align}
  \Exp_{\pathm \sim \cDh} \left[\Delta_{(\epsilon^2)}\left(\pirepsigh\left(\pathm\right),\,\pihat_{\sigma,h}\left(\pathm\right) \right)\right] \le 
 \Exp_{\pathmtil \sim \cDhsig} \left[\Delta_{(\epsilon^2)}\left(\pidecsigh\left(\pathmtil\right),\,\pihat_h\left(\pathmtil\right) \right)\right].
 \end{align}
 Consequently, when the right hand side of the above inequality is small, the noised policy $\pihat_{\sigma}$ tracks the replica policy $\pirepsig$, which we have shown to be track $\pist$ (and thus track $\Dexp$).