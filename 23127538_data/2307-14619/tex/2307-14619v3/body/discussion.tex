%!TEX root = ../main.tex

\section{Discussion}

This work considerably loosened assumptions placed on the \emph{expert distribution}; nevertheless, to facilitate our analysis we require the \emph{dynamics} to be sufficiently smooth and regular.  While such assumptions hold for a range of high-level tasks, a major remaining open question is what happens when discontinuities (or even non-smoothness) are allowed in the dynamics; these arise for example, when considering contact dynamics for applications in robotics.  In addition, while our theory allows for time-varying policies, in many robotics applications, time-invariant policies are more natural; understanding what changes in this regime also remains open.  Despite these limitations, our work presents a significant step toward understanding the imitation of complex trajectories in natural control systems.


Lastly, as per \Cref{rem:TVC}, our guarantees \emph{can} hold for zero ($\sigma = 0$) smoothing if the learned policy $\pihat$ is total variation continuous (TVC). While uniform TVC is unrealistic for DDPMs, there might be some form of local or distributional TVC in the support of training data. It is an interesting direction for future work to investigate if this property does hold, as our experiment suggests that imitation is successful in the $\sigma = 0$ regime. 

