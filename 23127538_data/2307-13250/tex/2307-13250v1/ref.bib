% method-features
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  year={2016}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2009}
}

@article{ren2016faster,
  title={{Faster R-CNN}: towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2016},
  publisher={IEEE}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

% GloVe
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proc. EMNLP},
  pages={1532--1543},
  year={2014}
}

%%% related works
% attention
@article{tvqa,
author = {Jie Lei and Licheng Yu and Mohit Bansal and Tamara L. Berg},
title = {Tvqa: Localized, compositional video question answering},
journal = {Conference on Empirical Methods in Natural Language Processing},
year = 2018
}

@article{li19,
author = {Xiangpeng Li and Lianli Gao and Xuanhan Wang and Wu Liu and Xing Xu and Heng Tao Shen and Jingkuan Song},
title = {Learnable aggregating net with diversity learning for video question answering},
journal = {ACMMM},
pages = {1166--1174},
year = 2019
}

@article{jin19,
author = {Weike Jin and Zhou Zhao and Mao Gu and Jun Yu and Jun Xiao and Yueting Zhuang},
title = {Multi-interaction network with object relation for video question answering},
journal = {ACMMM},
pages = {1193--1201},
year = 2019
}


@inproceedings{comem,
  title={Motion-appearance co-memory networks for video question answering},
  author={Gao, Jiyang and Ge, Runzhou and Chen, Kan and Nevatia, Ram},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@inproceedings{zhao18,
  title={Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network.},
  author={Zhao, Zhou and Jiang, Xinghua and Cai, Deng and Xiao, Jun and He, Xiaofei and Pu, Shiliang},
  booktitle={IJCAI},
  volume={2018},
  pages={27th},
  year={2018}
}


@inproceedings{kim18,
  title={Multimodal dual attention memory for video story question answering},
  author={Kim, Kyung-Min and Choi, Seong-Ho and Kim, Jin-Hwa and Zhang, Byoung-Tak},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2018}
}

% hierarchical
@inproceedings{hcrn,
  title={Hierarchical conditional relation networks for video question answering},
  author={Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2020}
}

% Graph
@inproceedings{lgcn,
  title={Location-aware graph convolutional networks for video question answering},
  author={Huang, Deng and Chen, Peihao and Zeng, Runhao and Du, Qing and Tan, Mingkui and Gan, Chuang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2020}
}

@article{gu2021graph,
  title={Graph-Based Multi-Interaction Network for Video Question Answering},
  author={Gu, Mao and Zhao, Zhou and Jin, Weike and Hong, Richang and Wu, Fei},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={2758--2770},
  year={2021},
  publisher={IEEE}
}

@inproceedings{seo2021masn,
	title   = {Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering},
	author  = {Seo, Ahjeong and Kang, Gi-Cheon and Park, Joonhan and Zhang, Byoung-Tak},
	booktitle = {ACL},
	pages     = {6167--6177},
	year    = {2021}
}

@inproceedings{jiang2020r,
  title={Reasoning with heterogeneous graph alignment for video question answering},
  author={Jiang, Pin and Han, Yahong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2020}
}


@inproceedings{park2021b,
  title={Bridge to Answer: Structure-aware Graph Interaction Network for Video Question Answering},
  author={Park, Jungin and Lee, Jiyoung and Sohn, Kwanghoon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}


% comapring methods

@inproceedings{da2021hrac,
title={Hierarchical Object-oriented Spatio-Temporal Reasoning for Video Question Answering},
author={Dang, Long Hoang and Le, Thao Minh and Le, Vuong and Tran, Truyen},
booktitle={Proceedings of the 30th International Joint Conference on Artificial Intelligence (IJCAI)},
month = {August},
year={2021}
}


@inproceedings{tgif-qa,
  title={Tgif-qa: Toward spatio-temporal reasoning in visual question answering},
  author={Jang, Yunseok and Song, Yale and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2758--2766},
  year={2017}
}


@inproceedings{msvd-qa,
  title={Video question answering via gradually refined attention over appearance and motion},
  author={Xu, Dejing and Zhao, Zhou and Xiao, Jun and Wu, Fei and Zhang, Hanwang and He, Xiangnan and Zhuang, Yueting},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  year={2017}
}

@inproceedings{msrvtt-qa,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5288--5296},
  year={2016}
}


@inproceedings{psac,
  title={Beyond rnns: Positional self-attention with co-attention for video question answering},
  author={Li, Xiangpeng and Song, Jingkuan and Gao, Lianli and Liu, Xianglong and Huang, Wenbing and He, Xiangnan and Gan, Chuang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2019}
}



@inproceedings{quest,
  title={Divide and conquer: Question-guided spatio-temporal contextual attention for video question answering},
  author={Jiang, Jianwen and Chen, Ziqiang and Lin, Haojie and Zhao, Xibin and Gao, Yue},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2020}
}

@article{hra,
author = {Muhammad Iqbal Hasan Chowdhury and Kien Nguyen and Sridha Sridharan and Clinton Fookes},
title = {Hierarchical Relational Attention for Video Question Answering},
journal = "ICIP",
pages = {599--603},
year = 2018
}



@article{jang2019video,
  title={Video question answering with spatio-temporal reasoning},
  author={Jang, Yunseok and Song, Yale and Kim, Chris Dongjoo and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  journal={International Journal of Computer Vision},
  volume={127},
  number={10},
  pages={1385--1412},
  year={2019},
  publisher={Springer}
}

% method BAN
@inproceedings{kim2018bilinear,
  title={Bilinear Attention Networks},
  author={Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
  booktitle={NeurIPS},
  year={2018}
}


%DynamicGCN
@article{wang2019dynamic,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={Acm Transactions On Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}

% implemantation
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}



@inproceedings{dong2018fast,
  title={Fast parameter adaptation for few-shot image captioning and visual question answering},
  author={Dong, Xuanyi and Zhu, Linchao and Zhang, De and Yang, Yi and Wu, Fei},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={54--62},
  year={2018}
}

@article{zhu2017uncovering,
  title={Uncovering the temporal context for video question answering},
  author={Zhu, Linchao and Xu, Zhongwen and Yang, Yi and Hauptmann, Alexander G},
  journal={International Journal of Computer Vision},
  volume={124},
  number={3},
  pages={409--421},
  year={2017},
  publisher={Springer}
}

@inproceedings{wang2021integrating,
  title={Integrating Subgraph-Aware Relation and Direction Reasoning for Question Answering},
  author={Wang, Xu and Zhao, Shuai and Cheng, Bo and Han, Jiale and Yingting, Li and Yang, Hao and Sekulic, Ivan and Nan, Guoshun},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7808--7812},
  year={2021},
  organization={IEEE}
}

@inproceedings{wang2020hgman,
  title={HGMAN: multi-hop and multi-answer question answering based on heterogeneous knowledge graph (student abstract)},
  author={Wang, Xu and Zhao, Shuai and Cheng, Bo and Han, Jiale and Li, Yingting and Yang, Hao and Nan, Guoshun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={10},
  pages={13953--13954},
  year={2020}
}

@inproceedings{li2022compositional,
  title={Compositional temporal grounding with structured variational cross-graph correspondence learning},
  author={Li, Juncheng and Xie, Junlin and Qian, Long and Zhu, Linchao and Tang, Siliang and Wu, Fei and Yang, Yi and Zhuang, Yueting and Wang, Xin Eric},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3032--3041},
  year={2022}
}

@inproceedings{li2021adaptive,
  title={Adaptive hierarchical graph reasoning with semantic coherence for video-and-language inference},
  author={Li, Juncheng and Tang, Siliang and Zhu, Linchao and Shi, Haochen and Huang, Xuanwen and Wu, Fei and Yang, Yi and Zhuang, Yueting},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1867--1877},
  year={2021}
}

@inproceedings{nan2021interventional,
  title={Interventional video grounding with dual contrastive learning},
  author={Nan, Guoshun and Qiao, Rui and Xiao, Yao and Liu, Jun and Leng, Sicong and Zhang, Hao and Lu, Wei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2765--2775},
  year={2021}
}

@inproceedings{zhu2020actbert,
  title={Actbert: Learning global-local video-text representations},
  author={Zhu, Linchao and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8746--8755},
  year={2020}
}

@inproceedings{wang2021t2vlad,
  title={T2vlad: global-local sequence alignment for text-video retrieval},
  author={Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5079--5088},
  year={2021}
}

@article{zhao2022centerclip,
  title={CenterCLIP: Token Clustering for Efficient Text-Video Retrieval},
  author={Zhao, Shuai and Zhu, Linchao and Wang, Xiaohan and Yang, Yi},
  journal={arXiv preprint arXiv:2205.00823},
  year={2022}
}

@article{fan2020recurrent,
  title={Recurrent attention network with reinforced generator for visual dialog},
  author={Fan, Hehe and Zhu, Linchao and Yang, Yi and Wu, Fei},
  journal={ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)},
  volume={16},
  number={3},
  pages={1--16},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{li2019entangled,
  title={Entangled transformer for image captioning},
  author={Li, Guang and Zhu, Linchao and Liu, Ping and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8928--8937},
  year={2019}
}


@article{li2022fine,
  title={Fine-Grained Semantically Aligned Vision-Language Pre-Training},
  author={Li, Juncheng and He, Xin and Wei, Longhui and Qian, Long and Zhu, Linchao and Xie, Lingxi and Zhuang, Yueting and Tian, Qi and Tang, Siliang},
  journal={arXiv preprint arXiv:2208.02515},
  year={2022}
}


@inproceedings{xiao2022video,
  title={Video as Conditional Graph Hierarchy for Multi-Granular Question Answering},
  author={Xiao, Junbin and Yao, Angela and Liu, Zhiyuan and Li, Yicong and Ji, Wei and Chua, Tat-Seng},
  year={2022},
  organization={AAAI}
}

@article{DBLP:journals/tip/YangWDDWC22,
  author    = {Xun Yang and
               Shanshan Wang and
               Jian Dong and
               Jianfeng Dong and
               Meng Wang and
               Tat{-}Seng Chua},
  title     = {Video Moment Retrieval With Cross-Modal Neural Architecture Search},
  journal   = {{IEEE} Trans. Image Process.},
  volume    = {31},
  pages     = {1204--1216},
  year      = {2022}
}

@inproceedings{DBLP:conf/nips/SimonyanZ14,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Two-Stream Convolutional Networks for Action Recognition in Videos},
  booktitle = {NeurIPS},
  year      = {2014}
}



@ARTICLE{8811730,
  author={Zhang, Wenqiao and Tang, Siliang and Cao, Yanpeng and Pu, Shiliang and Wu, Fei and Zhuang, Yueting},
  journal={IEEE Transactions on Multimedia}, 
  title={Frame Augmented Alternating Attention Network for Video Question Answering}, 
  year={2020},
  volume={22},
  number={4},
  pages={1032-1041},
  doi={10.1109/TMM.2019.2935678}}




@article{zhong2022video,
  title={Video question answering: datasets, algorithms and challenges},
  author={Zhong, Yaoyao and Ji, Wei and Xiao, Junbin and Li, Yicong and Deng, Weihong and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2203.01225},
  year={2022}
}  


@ARTICLE{9465732,
  author={Zhang, Xi and Zhang, Feifei and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia}, 
  title={Explicit Cross-Modal Representation Learning for Visual Commonsense Reasoning}, 
  year={2022},
  volume={24},
  number={},
  pages={2986-2997},
  doi={10.1109/TMM.2021.3091882}}
  
@ARTICLE{zhang2021DVC,
  author={Zhang, Zhiwang and Xu, Dong and Ouyang, Wanli and Zhou, Luping},
  journal={IEEE Transactions on Multimedia}, 
  title={Dense Video Captioning Using Graph-Based Sentence Summarization}, 
  year={2021},
  volume={23},
  number={},
  pages={1799-1810},
  doi={10.1109/TMM.2020.3003592}}

  @ARTICLE{8970556,
  author={Zhu, Wenwu and Wang, Xin and Gao, Wen},
  journal={IEEE Transactions on Multimedia}, 
  title={Multimedia Intelligence: When Multimedia Meets Artificial Intelligence}, 
  year={2020},
  volume={22},
  number={7},
  pages={1823-1835},
  doi={10.1109/TMM.2020.2969791}}


  @ARTICLE{10017364,
  author={Yang, Xiaofeng and Liu, Fayao and Lin, Guosheng},
  journal={IEEE Transactions on Multimedia}, 
  title={Effective End-to-End Vision Language Pretraining with Semantic Visual Loss}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  doi={10.1109/TMM.2023.3237166}}


  @ARTICLE{8768045,
  author={Li, Junnan and Wong, Yongkang and Zhao, Qi and Kankanhalli, Mohan S.},
  journal={IEEE Transactions on Multimedia}, 
  title={Video Storytelling: Textual Summaries for Events}, 
  year={2020},
  volume={22},
  number={2},
  pages={554-565},
  doi={10.1109/TMM.2019.2930041}}

% large pretraining
  @article{zellers2021merlot,
  title={Merlot: Multimodal neural script knowledge models},
  author={Zellers, Rowan and Lu, Ximing and Hessel, Jack and Yu, Youngjae and Park, Jae Sung and Cao, Jize and Farhadi, Ali and Choi, Yejin},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23634--23651},
  year={2021}
}

@article{yu2021learning,
  title={Learning from inside: Self-driven siamese sampling and reasoning for video question answering},
  author={Yu, Weijiang and Zheng, Haoteng and Li, Mengfei and Ji, Lei and Wu, Lijun and Xiao, Nong and Duan, Nan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26462--26474},
  year={2021}
}

@inproceedings{yang2021just,
  title={Just ask: Learning to answer questions from millions of narrated videos},
  author={Yang, Antoine and Miech, Antoine and Sivic, Josef and Laptev, Ivan and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1686--1697},
  year={2021}
}

@InProceedings{Li_2022_CVPR,
    author    = {Li, Dongxu and Li, Junnan and Li, Hongdong and Niebles, Juan Carlos and Hoi, Steven C.H.},
    title     = {Align and Prompt: Video-and-Language Pre-Training With Entity Prompts},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {4953-4963}
}

@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2630--2640},
  year={2019}
}