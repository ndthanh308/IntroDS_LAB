\section{Datasets}
We visualize the data distributions under different degrees of non-IID, i.e., $\alpha =\{0.1, 0.5, 5\}$ for EMNIST, FMNIST, Cifar10, and Cifar100 in Fig.~\ref{fig:alpha01}-Fig.~\ref{fig:alpha5}.

% Figure environment removed


% Figure environment removed

% Figure environment removed


\section{Details of Comparison Methods}
We compare \modelname~with three categories of state-of-the-art approaches according to their optimization goals, i.e., (1) optimizing global model: \textbf{FedAvg}~\cite{mcmahan2017communication}, \textbf{FedProx}~\cite{li2020federated}, \textbf{SCAFFOLD}~\cite{karimireddy2019scaffold}, \textbf{FedDYN}~\cite{acar2020federated}, \textbf{MOON}~\cite{li2021model}, (2) optimizing local personalized models: \textbf{FedMTL}~\cite{smith2017federated}, \textbf{FedPer}~\cite{arivazhagan2019federated}, \textbf{pFedMe}~\cite{t2020personalized}, \textbf{Ditto}~\cite{li2021ditto},
\textbf{APPLE}~\cite{luo2021adapt}, and (3) optimizing both global and local models: \textbf{Fed-RoD}~\cite{chen2021bridging}, \textbf{FedBABU}~\cite{oh2021fedbabu}, \textbf{SphereFed}~\cite{dong2022spherefed}. 
% 
% 
\textbf{FedAvg} is the first vanilla federated learning framework to collaborate among server and clients.
% 
\textbf{FedProx} takes a proximal term to regularize the change from global model to the local model.
% 
\textbf{SCAFFOLD} considers the variance of global model and local model when updating local gradients.
% 
\textbf{FedDYN} applies an dynamic regularizer to pull local model close to the global model, while to push local model away from  historical local model.
% 
\textbf{MOON} introduces contrastive learning to federated learning.
% 
\textbf{FedMTL} is an algorithm that takes personalized learning as a multi-task learning objective.
% 
\textbf{FedPer} decouples the global representation and local personalized classification.
% 
\textbf{pFedMe} uses Moreau envelopes as clientsâ€™ regularized loss functions to decouple personalized model optimization from the global model learning. 
% 
\textbf{Ditto} is a multi-task learning objective for federated learning that provides personalization while retaining similar efficiency. 
% 
\textbf{APPLE} adaptively learns to personalize the client models.
% 
\textbf{Fed-RoD}  explicitly decouples a model's dual duties with two prediction tasks. 
% 
\textbf{FedBABU} only updates the representation body of the model during federated training, and the head is fine-tuned for personalization during the evaluation process. 
% 
\textbf{SphereFed} is a hyperspherical federated learning framework to 
 address PFL problem.

We conduct all of the experiments on one NVIDIA RTX 3090 GPU with 24Gb Memory.
% 
% 
In the first category of methods, a hyper-parameter $\mu$ is mainly set to balance the local objective and regularization term (between the global model and local model).
% 
According to the optimal results, we set $\mu =0.01,1,0.1, $ for FedProx,  MOON, and FedDYN, respectively.
% 
Besides, we set $\tau=0.5$, the default temperature of MOON as specified in the original paper. 
% 
For all of the second category of methods as well as the third category of methods, we follow the personalized way as their original setting.
% 
We similarly finetune \modelname~and FedBABU with additional 5 local steps in P-FL.
% 
For pFedMe, we set regularization parameter $\mu=1$ for controlling the strength of personalized model, computation complexity $k=5$, the interpolation parameter $\beta=1$ for global weights.
% 
We choose hyper-parameter controlling the interpolation between global and local model , i.e., $\lambda=1 $ and local personalized iteration as 1 for Ditto.
% 
In APPLE, we take the hyper-parameter $\mu=0.001$, and the round number  $L=0.2$ for loss scheduler.

\section{Theoretical Analysis}
\subsection{Convex Optimization}
% Figure environment removed
% % Figure environment removed

For the simplified optimization of the convex combination between the toughest deviation and the virtual deviation:
\begin{equation}
\operatornamewithlimits{min}\limits_{p_{\tau}\in [0,1]} \frac{1}{2} \|p_{\tau}\Delta_{{\tau}}+(1-p_{\tau})\Delta_{{\text{vir}}}\|^2_2,
\end{equation}
we rewrite it as:
\begin{equation}
\min _{p_{\tau} \in[0,1]} J = \frac{1}{2} \left\|p_{\tau}\left(\Delta_{{\tau}}- \Delta_{{\text{vir}}}\right)+\Delta_{{\text{vir}}}\right\|_2^2.
\end{equation}

Next, we can analyze the solution according to its geometry, i.e., analyzing the directions among the toughest deviation, the virtual deviation, and their difference.  
% 
% 
As the geometry suggests in Fig.~\ref{fig:CU}, the solution of finding the minimized norm is either a perpendicular vector or an edge case.
% 
Thus we obtain the three cases as bellow:

\paragraph{Case 1} When it has the condition as:
\begin{equation}
\left\{ 
\begin{array}{l}  
\left(\Delta_{{\tau}}-\Delta_{{\text{vir}}}\right)^{\top} \cdot \Delta_{{\tau}}\ >0  \\
\left(\Delta_{{\tau}}-\Delta_{{\text{vir}}}\right)^{\top} \cdot \Delta_{{\text{vir}}} <0 ,
\end{array}
\right.
\end{equation}
%
Then we should take the differentiation $\frac{\partial J}{\partial p_{\tau}}=0$ and get:
\begin{equation}
\left(\Delta_{{\tau}}-\Delta_{{\text{vir}}}\right)^{\top}\left(p_{\tau} \Delta_{{\tau}} + (1-p_{\tau}) \Delta_{{\text{vir}}}\right)=0.
\end{equation}
%
Hence the solution is given:
\begin{equation}
\begin{gathered}
    p_{\tau}^*=\frac{\left(\Delta_{{\text{vir}}} - \Delta_{{\tau}} \right)^{\top} \cdot \Delta_{{\text{vir}}}}{\left\|\Delta_{{\tau}}- \Delta_{{\text{vir}}}\right\|_2^2} \quad \Leftrightarrow \quad \\
\Delta_{\boldsymbol{\theta}}^{t+1} =(1-p_{\tau}^*)\Delta_{{\text{vir}}}+ {p_{\tau}^*}\Delta_{\tau}.
\end{gathered}
\end{equation}
In this scenario, we find the perpendicular vector of the difference between the virtual deviation and the toughest deviation to obtain the minimum-norm.

\paragraph{Case 2} When it has the condition as:
\begin{equation}
\left(\Delta_{{\tau}}-\Delta_{{\text{vir}}}\right)^{\top} \cdot \Delta_{{\text{vir}}} \geq 0,
\end{equation}
the solution
\begin{equation}
p_{\tau}^*=0 \quad \Leftrightarrow \quad \Delta_{\boldsymbol{\theta}}^{t+1} =\Delta_{{\text{vir}}}.
\end{equation}
In this scenario, the $\left\|\Delta_{{\text{vir}}}\right\|_2^2$ is smaller than $\left\|\Delta_{{\tau}}\right\|_2^2$. The smaller deviation will hurdle the optimization on the virtual client. Therefore, we add weight on the virtual client.

\paragraph{Case 3} When it has the condition as:
\begin{equation}
\left(\Delta_{{\tau}}-\Delta_{{\text{vir}}}\right)^{\top} \cdot \Delta_{{\tau}} \leq 0,
\end{equation}
%
the solution
\begin{equation}
p_{\tau}^*=1, \quad \Leftrightarrow \quad \Delta_{\boldsymbol{\theta}}^{t+1} =\Delta_{{\tau}}.
\end{equation}
In this scenario, the $\left\|\Delta_{{\tau}}\right\|_2^2$ is smaller than $\left\|\Delta_{{\text{vir}}}\right\|_2^2$. The smaller deviation will hurdle the optimization on the toughest client. Therefore, we add weight on the toughest client.



