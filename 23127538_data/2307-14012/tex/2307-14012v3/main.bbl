\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghajanyan et~al.(2023)Aghajanyan, Yu, Conneau, Hsu, Hambardzumyan, Zhang, Roller, Goyal, Levy, and Zettlemoyer]{aghajanyan2023scaling}
Armen Aghajanyan, Lili Yu, Alexis Conneau, Wei-Ning Hsu, Karen Hambardzumyan, Susan Zhang, Stephen Roller, Naman Goyal, Omer Levy, and Luke Zettlemoyer.
\newblock Scaling laws for generative mixed-modal language models.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning}, ICML'23. JMLR, 2023.

\bibitem[Brock et~al.(2019)Brock, Donahue, and Simonyan]{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chung et~al.(2023)Chung, Kim, Mccann, Klasky, and Ye]{chung2023reconstrguidance}
Hyungjin Chung, Jeongsol Kim, Michael~Thompson Mccann, Marc~Louis Klasky, and Jong~Chul Ye.
\newblock Diffusion posterior sampling for general noisy inverse problems.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. IEEE, 2009.

\bibitem[Deng(2012)]{mnist}
Li~Deng.
\newblock The mnist database of handwritten digit images for machine learning research [best of the web].
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0 141--142, 2012.
\newblock \doi{10.1109/MSP.2012.2211477}.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffbeatgan}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat {GAN}s on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Du et~al.(2023)Du, Durkan, Strudel, Tenenbaum, Dieleman, Fergus, Sohl-Dickstein, Doucet, and Grathwohl]{du2023reduce}
Yilun Du, Conor Durkan, Robin Strudel, Joshua~B. Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, and Will~Sussman Grathwohl.
\newblock Reduce, {R}euse, {R}ecycle: Compositional generation with energy-based diffusion models and {MCMC}.
\newblock In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, \emph{Proceedings of the 40th International Conference on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning Research}, pages 8489--8510. PMLR, 23--29 Jul 2023.

\bibitem[Duane et~al.(1987)Duane, Kennedy, Pendleton, and Roweth]{duane1987hmc}
Simon Duane, A.D. Kennedy, Brian~J. Pendleton, and Duncan Roweth.
\newblock Hybrid {M}onte {C}arlo.
\newblock \emph{Physics Letters B}, 195\penalty0 (2):\penalty0 216--222, 1987.
\newblock ISSN 0370-2693.

\bibitem[G{\"u}ng{\"o}r et~al.(2023)G{\"u}ng{\"o}r, Dar, {\"O}zt{\"u}rk, Korkmaz, Bedel, Elmas, Ozbey, and {\c{C}}ukur]{gungor2023adaptive}
Alper G{\"u}ng{\"o}r, Salman~UH Dar, {\c{S}}aban {\"O}zt{\"u}rk, Yilmaz Korkmaz, Hasan~A Bedel, Gokberk Elmas, Muzaffer Ozbey, and Tolga {\c{C}}ukur.
\newblock Adaptive diffusion priors for accelerated mri reconstruction.
\newblock \emph{Medical Image Analysis}, page 102872, 2023.

\bibitem[Hastings(1970)]{hasting1970mh}
W.~K. Hastings.
\newblock {M}onte {C}arlo sampling methods using {M}arkov chains and their applications.
\newblock \emph{Biometrika}, 57\penalty0 (1):\penalty0 97--109, 1970.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Hinton(2002)]{hinton2002training}
Geoffrey~E Hinton.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 14\penalty0 (8):\penalty0 1771--1800, 2002.

\bibitem[Ho and Salimans(2021)]{ho2021classifierfree}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock In \emph{NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications}, 2021.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and Fleet]{ho2022guidance}
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David~J Fleet.
\newblock Video diffusion models.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems}, volume~35, pages 8633--8646. Curran Associates, Inc., 2022.

\bibitem[Horvat and Pfister(2024)]{horvat2024gauge}
Christian Horvat and Jean-Pascal Pfister.
\newblock On gauge freedom, conservativity and intrinsic dimensionality estimation in diffusion models.
\newblock \emph{arXiv preprint arXiv:2402.03845}, 2024.

\bibitem[Jacobs et~al.(1991)Jacobs, Jordan, Nowlan, and Hinton]{jacobs1991adaptive}
Robert~A Jacobs, Michael~I Jordan, Steven~J Nowlan, and Geoffrey~E Hinton.
\newblock Adaptive mixtures of local experts.
\newblock \emph{Neural computation}, 3\penalty0 (1):\penalty0 79--87, 1991.

\bibitem[Krizhevsky and Hinton(2009)]{krizhevsky2009cifar}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical Report~0, University of Toronto, Toronto, Ontario, 2009.
\newblock URL \url{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, Huang, et~al.]{lecun2006tutorial}
Yann LeCun, Sumit Chopra, Raia Hadsell, M~Ranzato, Fujie Huang, et~al.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 1\penalty0 (0), 2006.

\bibitem[Li et~al.(2022)Li, Choi, Chung, Kushman, Schrittwieser, Leblond, Eccles, Keeling, Gimeno, Dal~Lago, et~al.]{li2022competition}
Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R{\'e}mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal~Lago, et~al.
\newblock Competition-level code generation with alphacode.
\newblock \emph{Science}, 378\penalty0 (6624):\penalty0 1092--1097, 2022.

\bibitem[Liu et~al.(2022)Liu, Li, Du, Torralba, and Tenenbaum]{liu2022compositional}
Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua~B Tenenbaum.
\newblock Compositional visual generation with composable diffusion models.
\newblock In \emph{European Conference on Computer Vision}, pages 423--439. Springer, 2022.

\bibitem[L{\"u}dke et~al.(2023)L{\"u}dke, Bilo{\v s}, Shchur, Lienen, and Günnemann]{ludke2023diff_tpp}
David L{\"u}dke, Marin Bilo{\v s}, Oleksandr Shchur, Marten Lienen, and Stephan Günnemann.
\newblock Add and thin: Diffusion for temporal point processes.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Mayraz and Hinton(2000)]{mayraz2000recognizing}
Guy Mayraz and Geoffrey~E Hinton.
\newblock Recognizing hand-written digits using hierarchical products of experts.
\newblock \emph{Advances in neural information processing systems}, 13, 2000.

\bibitem[Metropolis et~al.(1953)Metropolis, Rosenbluth, Rosenbluth, and Teller]{metropolis1953mh}
Nicholas Metropolis, Arianna~W. Rosenbluth, Marshall~N. Rosenbluth, and Augusta~H. Teller.
\newblock Equation of state calculations by fast computing machines.
\newblock \emph{The Journal of Chemical Physics}, 21\penalty0 (6):\penalty0 1087--1092, 1953.

\bibitem[Neal(2001)]{neal2001annealed}
Radford~M Neal.
\newblock Annealed importance sampling.
\newblock \emph{Statistics and computing}, 11:\penalty0 125--139, 2001.

\bibitem[Neal et~al.(1996)Neal, Diggle, and Fienberg]{neal1996bayes}
Radford~M. Neal, P.~Diggle, and S.~Fienberg.
\newblock \emph{Bayesian Learning for Neural Networks.}
\newblock Lecture Notes in Statistics Ser.: v.118. Springer New York, 1996.
\newblock ISBN 9781461207450.

\bibitem[Nichol and Dhariwal(2021)]{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In \emph{International Conference on Machine Learning}, pages 8162--8171. PMLR, 2021.

\bibitem[Radosavovic et~al.(2020)Radosavovic, Kosaraju, Girshick, He, and Doll{\'a}r]{radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10428--10436, 2020.

\bibitem[Roberts and Stramer(2002)]{roberts2002mala}
G.~O. Roberts and O.~Stramer.
\newblock Langevin diffusions and {M}etropolis--{H}astings algorithms.
\newblock \emph{Methodology \& Computing in Applied Probability}, 4\penalty0 (4):\penalty0 337 -- 357, 2002.
\newblock ISSN 13875841.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 36479--36494, 2022.

\bibitem[Salimans and Ho(2021)]{salimans2021should}
Tim Salimans and Jonathan Ho.
\newblock Should {EBM}s model the energy or the score?
\newblock In \emph{Energy Based Models Workshop - ICLR 2021}, 2021.
\newblock URL \url{https://openreview.net/forum?id=9AS-TF2jRNb}.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages 2256--2265. PMLR, 2015.

\bibitem[Song and Ermon(2019)]{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2021scorebased}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Villani(2009)]{villani2009opttransp}
C{\'e}dric Villani.
\newblock \emph{The {W}asserstein distances}, pages 93--111.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2009.
\newblock ISBN 978-3-540-71050-9.
\newblock URL \url{https://doi.org/10.1007/978-3-540-71050-9_6}.

\bibitem[Wang et~al.(2024)Wang, Xu, Zhou, Zang, Darrell, Liu, and You]{wang2024neural}
Kai Wang, Zhaopan Xu, Yukun Zhou, Zelin Zang, Trevor Darrell, Zhuang Liu, and Yang You.
\newblock Neural network diffusion, 2024.

\bibitem[Wynn and Turmukhambetov(2023)]{wynn2023diffusionerf}
Jamie Wynn and Daniyar Turmukhambetov.
\newblock Diffusio{N}e{RF}: Regularizing neural radiance fields with denoising diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4180--4189, 2023.

\end{thebibliography}
