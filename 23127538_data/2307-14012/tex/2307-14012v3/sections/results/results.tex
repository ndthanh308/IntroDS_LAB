\section{Results}

In this section, we present an empirical evaluation of our MH-like correction method, examining both the accuracy of the pseudo-energy differences and the quality of the generated samples. The experiments are designed to span a spectrum of difficulty: from controlled, low-dimensional setups where models can be trained from scratch and analytical solutions are available, to more realistic high-dimensional scenarios involving pre-trained models. Our two primary objectives are (1) to compare our proposed approach against a true energy parameterization when available, and (2) to assess the sampling improvements achieved over the standard reverse process when augmented with MCMC steps.

The experiments in Sections~\ref{section:pseudo-energy}, \ref{section:2dcomp}, and the first part of \ref{section:guideddiffusion} involve training diffusion models using both energy and score parameterizations. The score parameterization follows a noise prediction model, $\epsP(\x_t, t)$, while the energy parameterization defines an energy function as $\energy(\x_t, t) = \twoNorm{\x_t - \score(\x_t, t)}^2$, as in~\citep{du2023reduce}. We use identical network architectures for $\epsilon_\theta$ and $s_\theta$. Both models are trained with the standard diffusion loss~\citep{ho2020denoising}, with the energy model’s score function obtained through explicit differentiation.

The later experiments utilize only pre-trained score-based diffusion models, as pre-trained energy-based models are unavailable for direct comparison. We evaluate both unadjusted and MH-corrected versions of Langevin and Hamiltonian Monte Carlo, comparing them against the standard reverse process, which serves as the baseline.

For the MH-like correction, we examine two types of integration paths: line and curve. The line follows a direct path between $\x^\tau$ and $\xCand$, while the curve integrates along the trajectory formed by HMC leapfrog steps. The number of points for the trapezoidal rule’s mesh is treated as a hyperparameter. Since points like $\x^\tau$ and $\xCand$ are already included, the hyperparameter refers to the additional points, which are evenly distributed along the curve.

Complete training details, hyperparameter settings, and implementation specifics are deferred to Appendix~\ref{sec:expdetails}.


\input{sections/results/two_d_analytical}
\input{sections/results/two_d_comp.tex}
\input{sections/results/guided}
\input{sections/results/tapestries.tex}