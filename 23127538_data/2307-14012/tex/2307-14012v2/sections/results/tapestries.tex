\subsection{Image tapestry}
We conduct a so-called image tapestry experiment, similar to the one in \cite{du2023reduce} and based on their code\footnote{https://github.com/yilundu/reduce\_reuse\_recycle}, as our final experiment. This experiment involves not only the composition of guidance---in this case, classifier-free guidance---but also the composition of combining multiple overlapping text-to-image models. This approach allows us to construct an image with specified content at different spatial locations. Here, we use a pre-trained DeepFloyd-IF\footnote{Available at https://huggingface.co/DeepFloyd/IF-I-XL-v1.0} model. For each diffusion step ($T=100$), 15 extra LA steps were added, with three additional evaluation points for line integration for each step. The guidance scale $\lambda = 20.0$. For more details, see the \cref{sec:expdetails:image_tapestry}. In \cref{fig:tapestry}, we can see a generated tapestry image, and in \cref{fig:tapestry_content}, we can see the specified content at the corresponding spatial locations. There are, in total, nine overlapping content boxes: four are positioned in each corner with different content, while the remaining five are arranged to create a unified image using the same content prompt.

% Figure environment removed