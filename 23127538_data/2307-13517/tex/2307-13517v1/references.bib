
@misc{tsilivis_what_2023,
	title = {What {Can} the {Neural} {Tangent} {Kernel} {Tell} {Us} {About} {Adversarial} {Robustness}?},
	url = {http://arxiv.org/abs/2210.05577},
	doi = {10.48550/arXiv.2210.05577},
	abstract = {The adversarial vulnerability of neural nets, and subsequent techniques to create robust models have attracted significant attention; yet we still lack a full understanding of this phenomenon. Here, we study adversarial examples of trained neural networks through analytical tools afforded by recent theory advances connecting neural networks and kernel methods, namely the Neural Tangent Kernel (NTK), following a growing body of work that leverages the NTK approximation to successfully analyze important deep learning phenomena and design algorithms for new applications. We show how NTKs allow to generate adversarial examples in a ``training-free'' fashion, and demonstrate that they transfer to fool their finite-width neural net counterparts in the ``lazy'' regime. We leverage this connection to provide an alternative view on robust and non-robust features, which have been suggested to underlie the adversarial brittleness of neural nets. Specifically, we define and study features induced by the eigendecomposition of the kernel to better understand the role of robust and non-robust features, the reliance on both for standard classification and the robustness-accuracy trade-off. We find that such features are surprisingly consistent across architectures, and that robust features tend to correspond to the largest eigenvalues of the model, and thus are learned early during training. Our framework allows us to identify and visualize non-robust yet useful features. Finally, we shed light on the robustness mechanism underlying adversarial training of neural nets used in practice: quantifying the evolution of the associated empirical NTK, we demonstrate that its dynamics falls much earlier into the ``lazy'' regime and manifests a much stronger form of the well known bias to prioritize learning features within the top eigenspaces of the kernel, compared to standard training.},
	urldate = {2023-07-13},
	publisher = {arXiv},
	author = {Tsilivis, Nikolaos and Kempe, Julia},
	month = jan,
	year = {2023},
	note = {arXiv:2210.05577 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{mialon_self-supervised_2023,
	title = {Self-{Supervised} {Learning} with {Lie} {Symmetries} for {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2307.05432},
	doi = {10.48550/arXiv.2307.05432},
	abstract = {Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation models for PDEs.},
	urldate = {2023-07-12},
	publisher = {arXiv},
	author = {Mialon, Grégoire and Garrido, Quentin and Lawrence, Hannah and Rehman, Danyal and LeCun, Yann and Kiani, Bobak T.},
	month = jul,
	year = {2023},
	note = {arXiv:2307.05432 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{shankar_differentiable_2023,
	title = {Differentiable {Turbulence}},
	url = {http://arxiv.org/abs/2307.03683},
	abstract = {Deep learning is increasingly becoming a promising pathway to improving the accuracy of sub-grid scale (SGS) turbulence closure models for large eddy simulations (LES). We leverage the concept of differentiable turbulence, whereby an end-to-end differentiable solver is used in combination with physics-inspired choices of deep learning architectures to learn highly effective and versatile SGS models for two-dimensional turbulent flow. We perform an in-depth analysis of the inductive biases in the chosen architectures, finding that the inclusion of small-scale non-local features is most critical to effective SGS modeling, while large-scale features can improve pointwise accuracy of the a-posteriori solution field. The filtered velocity gradient tensor can be mapped directly to the SGS stress via decomposition of the inputs and outputs into isotropic, deviatoric, and anti-symmetric components. We see that the model can generalize to a variety of flow configurations, including higher and lower Reynolds numbers and different forcing conditions. We show that the differentiable physics paradigm is more successful than offline, a-priori learning, and that hybrid solver-in-the-loop approaches to deep learning offer an ideal balance between computational efficiency, accuracy, and generalization. Our experiments provide physics-based recommendations for deep-learning based SGS modeling for generalizable closure modeling of turbulence.},
	urldate = {2023-07-10},
	publisher = {arXiv},
	author = {Shankar, Varun and Maulik, Romit and Viswanathan, Venkatasubramanian},
	month = jul,
	year = {2023},
	note = {arXiv:2307.03683 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@article{lu_priori_2007,
	title = {A priori tests of one-equation {LES} modeling of rotating turbulence},
	volume = {8},
	url = {https://doi.org/10.1080/14685240701493947},
	doi = {10.1080/14685240701493947},
	abstract = {A priori tests of subgrid-scale (SGS) models are performed using results of 1283 direct numerical simulations for forced isotropic (Reλ = 100) and rotating turbulence (0.1 {\textless} Ro ω3 {\textless} 0.4). A range of SGS models is tested varying from algebraic, gradient, and scale similarity, to one-equation viscosity and non-viscosity dynamic structure models. Anisotropy and material frame indifference (MFI) requirements for SGS models in rotating systems are reviewed and used to help construct new models based on the dynamic structure approach. The models are evaluated primarily using correlation and regression coefficients of individual components of the SGS tensor, components of the divergence of the SGS stresses, and the kinetic energy transfer term between large and small scales. For all measures examined, the MFI-consistent dynamic structure models perform significantly better, especially for rotating turbulence.},
	urldate = {2023-07-10},
	journal = {Journal of Turbulence},
	author = {Lu, Hao and Rutland, Christopher J. and Smith, Leslie M.},
	month = jan,
	year = {2007},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/14685240701493947},
	pages = {N37},
}

@misc{noauthor_cs1114_nodate,
	title = {{CS1114} {Spring} 2010 - {Introduction} to {Computing} using {Matlab} and {Robotics}},
	url = {https://www.cs.cornell.edu/courses/cs1114/2011sp/},
	urldate = {2023-07-10},
}

@misc{noauthor_batch_nodate,
	title = {Batch {Normalization} \& {Layer} {Normalization整理}（代码实现下载）\_batchnormalization下载\_AI\_盲的博客-{CSDN博客}},
	url = {https://blog.csdn.net/xwd18280820053/article/details/70237664},
	urldate = {2023-07-10},
}

@misc{thompson_computational_2022,
	title = {The {Computational} {Limits} of {Deep} {Learning}},
	url = {http://arxiv.org/abs/2007.05558},
	abstract = {Deep learning's recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image classification, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article catalogs the extent of this dependency, showing that progress across a wide variety of applications is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationally-efficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.},
	urldate = {2023-07-10},
	publisher = {arXiv},
	author = {Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
	month = jul,
	year = {2022},
	note = {arXiv:2007.05558 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{lipton_mythos_2017,
	title = {The {Mythos} of {Model} {Interpretability}},
	url = {http://arxiv.org/abs/1606.03490},
	doi = {10.48550/arXiv.1606.03490},
	abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
	urldate = {2023-07-10},
	publisher = {arXiv},
	author = {Lipton, Zachary C.},
	month = mar,
	year = {2017},
	note = {arXiv:1606.03490 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{murdoch_definitions_2019,
	title = {Definitions, methods, and applications in interpretable machine learning},
	volume = {116},
	url = {https://www.pnas.org/doi/10.1073/pnas.1900654116},
	doi = {10.1073/pnas.1900654116},
	abstract = {Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.},
	number = {44},
	urldate = {2023-07-10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Murdoch, W. James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
	month = oct,
	year = {2019},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {22071--22080},
}

@misc{ras_explainable_2021,
	title = {Explainable {Deep} {Learning}: {A} {Field} {Guide} for the {Uninitiated}},
	shorttitle = {Explainable {Deep} {Learning}},
	url = {http://arxiv.org/abs/2004.14545},
	abstract = {Deep neural networks (DNNs) have become a proven and indispensable machine learning tool. As a black-box model, it remains difficult to diagnose what aspects of the model's input drive the decisions of a DNN. In countless real-world domains, from legislation and law enforcement to healthcare, such diagnosis is essential to ensure that DNN decisions are driven by aspects appropriate in the context of its use. The development of methods and studies enabling the explanation of a DNN's decisions has thus blossomed into an active, broad area of research. A practitioner wanting to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field has taken. This complexity is further exacerbated by competing definitions of what it means ``to explain'' the actions of a DNN and to evaluate an approach's ``ability to explain''. This article offers a field guide to explore the space of explainable deep learning aimed at those uninitiated in the field. The field guide: i) Introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning, ii) discusses the evaluations for model explanations, iii) places explainability in the context of other related deep learning research areas, and iv) finally elaborates on user-oriented explanation designing and potential future directions on explainable deep learning. We hope the guide is used as an easy-to-digest starting point for those just embarking on research in this field.},
	urldate = {2023-07-10},
	publisher = {arXiv},
	author = {Ras, Gabrielle and Xie, Ning and van Gerven, Marcel and Doran, Derek},
	month = sep,
	year = {2021},
	note = {arXiv:2004.14545 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{fang_mathematical_2021,
	title = {Mathematical {Models} of {Overparameterized} {Neural} {Networks}},
	volume = {109},
	issn = {1558-2256},
	doi = {10.1109/JPROC.2020.3048020},
	abstract = {Deep learning has received considerable empirical success in recent years. However, while many ad hoc tricks have been discovered by practitioners, until recently, there has been a lack of theoretical understanding for tricks invented in the deep learning literature. Known by practitioners that overparameterized neural networks (NNs) are easy to learn, in the past few years, there have been important theoretical developments in the analysis of overparameterized NNs. In particular, it was shown that such systems behave like convex systems under various restricted settings, such as for two-layer NNs, and when learning is restricted locally in the so-called neural tangent kernel space around specialized initializations. This article discusses some of these recent signs of progress leading to a significantly better understanding of NNs. We will focus on the analysis of two-layer NNs and explain the key mathematical models, with their algorithmic implications. We will then discuss challenges in understanding deep NNs and some current research directions.},
	number = {5},
	journal = {Proceedings of the IEEE},
	author = {Fang, Cong and Dong, Hanze and Zhang, Tong},
	month = may,
	year = {2021},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Artificial neural networks, Deep learning, Linear programming, Mathematical model, Mean-field (MF) analysis, Neural networks, Optimization, Radio frequency, Training data, neural networks (NNs), neural tangent kernel (NTK), overparameterization, random features},
	pages = {683--703},
}

@inproceedings{brutzkus_why_2019,
	title = {Why do {Larger} {Models} {Generalize} {Better}? {A} {Theoretical} {Perspective} via the {XOR} {Problem}},
	shorttitle = {Why do {Larger} {Models} {Generalize} {Better}?},
	url = {https://proceedings.mlr.press/v97/brutzkus19b.html},
	abstract = {Empirical evidence suggests that neural networks with ReLU activations generalize better with over-parameterization. However, there is currently no theoretical analysis that explains this observation. In this work, we provide theoretical and empirical evidence that, in certain cases, overparameterized convolutional networks generalize better than small networks because of an interplay between weight clustering and feature exploration at initialization. We demonstrate this theoretically for a 3-layer convolutional neural network with max-pooling, in a novel setting which extends the XOR problem. We show that this interplay implies that with overparamterization, gradient descent converges to global minima with better generalization performance compared to global minima of small networks. Empirically, we demonstrate these phenomena for a 3-layer convolutional neural network in the MNIST task.},
	language = {en},
	urldate = {2023-07-10},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Brutzkus, Alon and Globerson, Amir},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {822--830},
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore} {Full}-{Text} {PDF}:},
	url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9326403},
	urldate = {2023-07-10},
}

@book{reed_neural_1999,
	address = {Cambridge, Mass},
	title = {Neural smithing: supervised learning in feedforward artificial neural networks},
	isbn = {978-0-262-18190-7},
	shorttitle = {Neural smithing},
	language = {en},
	publisher = {The MIT Press},
	author = {Reed, Russell D. and Marks, Robert J.},
	year = {1999},
	keywords = {Neural networks (Computer science)},
}

@book{hastie_elements_2001,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {The {Elements} of {Statistical} {Learning}},
	isbn = {978-1-4899-0519-2 978-0-387-21606-5},
	url = {http://link.springer.com/10.1007/978-0-387-21606-5},
	language = {en},
	urldate = {2023-07-10},
	publisher = {Springer New York},
	author = {Hastie, Trevor and Friedman, Jerome and Tibshirani, Robert},
	year = {2001},
	doi = {10.1007/978-0-387-21606-5},
}

@article{cotter_uses_2020,
	title = {Uses of {Complex} {Wavelets} in {Deep} {Convolutional} {Neural} {Networks}},
	url = {https://www.repository.cam.ac.uk/handle/1810/306661},
	abstract = {Image understanding has long been a goal for computer vision. It has proved to be an exceptionally difficult task due to the large amounts of variability that are inherent to objects in a scene. Recent advances in supervised learning methods, particularly convolutional neural networks (CNNs), have pushed forth the frontier of what we have been able to train computers to do. Despite their successes, the mechanics of how these networks are able to recognize objects are little understood, and the networks themselves are often very difficult and time-consuming to train. It is very important that we improve our current approaches in every way possible. A CNN is built from connecting many learned convolutional layers in series. These convolutional layers are fairly crude in terms of signal processing - they are arbitrary taps of a finite impulse response filter, learned through stochastic gradient descent from random initial conditions. We believe that if we reformulate the problem, we may achieve many insights and benefits in training CNNs. Noting that modern CNNs are mostly viewed from and analyzed in the spatial domain, this thesis aims to view the convolutional layers in the frequency domain (viewing things in the frequency domain has proved useful in the past for denoising, filter design, compression and many other tasks). In particular, we use complex wavelets (rather than the Fourier transform or the discrete wavelet transform) as basis functions to reformulate image understanding with deep networks. In this thesis, we explore the most popular and well-developed form of using complex wavelets in deep learning, the ScatterNet from Stephane Mallat. We explore its current limitations by building a DeScatterNet and found that while it has many nice properties, it may not be sensitive to the most appropriate shapes for understanding natural images. We then develop a locally invariant convolutional layer, a combination of a complex wavelet transform, a modulus operation, and a learned mixing. To do this, we derive backpropagation equations and allow gradients to flow back through the (previously fixed) ScatterNet front end. Connecting several such locally invariant layers allows us to build learnable ScatterNet, a more flexible and general form of the ScatterNet (while still maintaining its desired properties). We show that the learnable ScatterNet can provide significant improvements over the regular ScatterNet when being used as a front end for a learning system. Additionally, we show that the locally invariant convolutional layer can directly replace convolutional layers in a deep CNN (and not just at the front-end). The locally invariant convolutional layers naturally downsample the input (because of the complex modulus) while increasing the channel dimension (because of the multiple wavelet orientations used). This is an operation that often happens in a CNN by a combination of a pooling and convolutional layer. It was at these locations in a CNN where the learnable ScatterNet performed best, implying it may be useful as learnable pooling layer. Finally, we develop a system to learn complex weights that act directly on the wavelet coefficients of signals, in place of a convolutional layer. We call this layer the wavelet gain layer and show it can be used alongside convolutional layers. The network designer may then choose to learn in the pixel or wavelet domains. This layer shows a lot of promise and affords more control over what regions of the frequency space we want our layer to learn from. Our experiments show that it can improve on learning in the pixel domain for early layers of a CNN.},
	language = {en},
	urldate = {2023-07-06},
	author = {Cotter, Fergal},
	month = jun,
	year = {2020},
}

@article{lee_pywavelets_2019,
	title = {{PyWavelets}: {A} {Python} package for wavelet analysis},
	volume = {4},
	issn = {2475-9066},
	shorttitle = {{PyWavelets}},
	url = {https://joss.theoj.org/papers/10.21105/joss.01237},
	doi = {10.21105/joss.01237},
	abstract = {Lee et al., (2019). PyWavelets: A Python package for wavelet analysis. Journal of Open Source Software, 4(36), 1237, https://doi.org/10.21105/joss.01237},
	language = {en},
	number = {36},
	urldate = {2023-07-06},
	journal = {Journal of Open Source Software},
	author = {Lee, Gregory R. and Gommers, Ralf and Waselewski, Filip and Wohlfahrt, Kai and O’Leary, Aaron},
	month = apr,
	year = {2019},
	pages = {1237},
}

@article{shnirelman_nonuniqueness_1997,
	title = {On the nonuniqueness of weak solution of the {Euler} equation},
	volume = {50},
	copyright = {Copyright © 1997 John Wiley \& Sons, Inc.},
	issn = {1097-0312},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0312%28199712%2950%3A12%3C1261%3A%3AAID-CPA3%3E3.0.CO%3B2-6},
	doi = {10.1002/(SICI)1097-0312(199712)50:12<1261::AID-CPA3>3.0.CO;2-6},
	abstract = {Weak solution of the Euler equations is defined as an L2-vector field satisfying the integral relations expressing the mass and momentum balance. Their general nature has been quite unclear. In this work an example of a weak solution on a 2-dimensional torus is constructed that is identically zero outside a finite time interval. This example is simpler and more transparent than the previous example of V. Scheffer (J. Geom. Anal. 3(4), 1993, pp. 343–401). © 1997 John Wiley \& Sons, Inc.},
	language = {en},
	number = {12},
	urldate = {2023-07-04},
	journal = {Communications on Pure and Applied Mathematics},
	author = {Shnirelman, A.},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-0312\%28199712\%2950\%3A12\%3C1261\%3A\%3AAID-CPA3\%3E3.0.CO\%3B2-6},
	pages = {1261--1286},
}

@misc{noauthor_navier-stokes_nodate,
	title = {Navier-{Stokes} {Equation}},
	url = {https://www.claymath.org/millennium/navier-stokes-equation/},
	abstract = {This is the equation which governs the flow of fluids such as water and air. However, there is no proof for the most basic questions one can ask: do solutions exist, and are they unique? Why ask for a proof? Because a proof gives not only certitude, but also understanding.},
	language = {en-US},
	urldate = {2023-07-04},
	journal = {Clay Mathematics Institute},
}

@article{fefferman_existence_nodate,
	title = {{EXISTENCE} {AND} {SMOOTHNESS} {OF} {THE} {NAVIER}–{STOKES} {EQUATION}},
	language = {en},
	author = {Fefferman, Charles L},
}

@inproceedings{raudys_small_1990,
	title = {Small sample size effects in statistical pattern recognition: recommendations for practitioners and open problems},
	shorttitle = {Small sample size effects in statistical pattern recognition},
	url = {https://www.computer.org/csdl/proceedings-article/icpr/1990/00118138/12OmNyKa64x},
	doi = {10.1109/ICPR.1990.118138},
	abstract = {The authors discuss the effects of sample size on the feature selection and error estimation for several types of classifiers. In addition to surveying prior work in this area, they give practical advice to today's designers and users of statistical pattern recognition systems. It is pointed out that one needs a large number of training samples if a complex classification rule with many features is being utilized. In many pattern recognition problems, the number of potential features is very large and not much is known about the characteristics of the pattern classes under consideration: thus, it is difficult to determine a priori the complexity of the classification rule needed. Therefore, even when the designer believes that a large number of training samples has been selected, they may not be enough for designing and evaluating the classification problem at hand. It is further noted that a small sample size can cause many problems in the design of a pattern recognition system.},
	language = {English},
	urldate = {2023-06-30},
	publisher = {IEEE Computer Society},
	author = {Raudys, S. J. and Jain, A. K.},
	month = jan,
	year = {1990},
	pages = {417,418,419,420,421,422,423--417,418,419,420,421,422,423},
}

@article{figueroa_predicting_2012,
	title = {Predicting sample size required for classification performance},
	volume = {12},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/1472-6947-12-8},
	doi = {10.1186/1472-6947-12-8},
	abstract = {Supervised learning methods need annotated data in order to generate efficient models. Annotated data, however, is a relatively scarce resource and can be expensive to obtain. For both passive and active learning methods, there is a need to estimate the size of the annotated sample required to reach a performance target.},
	number = {1},
	urldate = {2023-06-30},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Figueroa, Rosa L. and Zeng-Treitler, Qing and Kandula, Sasikiran and Ngo, Long H.},
	month = feb,
	year = {2012},
	keywords = {Active Learning, Annotate Data, Learning Curve, Mean Absolute Error, Root Mean Square Error},
	pages = {8},
}

@misc{ruhe_clifford_2023,
	title = {Clifford {Group} {Equivariant} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2305.11141},
	doi = {10.48550/arXiv.2305.11141},
	abstract = {We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing \${\textbackslash}mathrm\{E\}(n)\$-equivariant networks. We identify and study the \${\textbackslash}textit\{Clifford group\}\$, a subgroup inside the Clifford algebra, whose definition we slightly adjust to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, including their grade projections, constitutes an equivariant map with respect to the Clifford group, allowing us to parameterize equivariant neural network layers. Notable advantages are that these layers operate directly on a vector basis and elegantly generalize to any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional \$n\$-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment.},
	urldate = {2023-06-28},
	publisher = {arXiv},
	author = {Ruhe, David and Brandstetter, Johannes and Forré, Patrick},
	month = may,
	year = {2023},
	note = {arXiv:2305.11141 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{kim_turbulence_1987,
	title = {Turbulence statistics in fully developed channel flow at low {Reynolds} number},
	volume = {177},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/turbulence-statistics-in-fully-developed-channel-flow-at-low-reynolds-number/308DCF387F4488D6A0FB189D8206DF7B},
	doi = {10.1017/S0022112087000892},
	abstract = {A direct numerical simulation of a turbulent channel flow is performed. The unsteady Navier-Stokes equations are solved numerically at a Reynolds number of 3300, based on the mean centreline velocity and channel half-width, with about 4 × 106 grid points (192 × 129 × 160 in x, y, z). All essential turbulence scales are resolved on the computational grid and no subgrid model is used. A large number of turbulence statistics are computed and compared with the existing experimental data at comparable Reynolds numbers. Agreements as well as discrepancies are discussed in detail. Particular attention is given to the behaviour of turbulence correlations near the wall. In addition, a number of statistical correlations which are complementary to the existing experimental data are reported for the first time.},
	language = {en},
	urldate = {2023-06-27},
	journal = {Journal of Fluid Mechanics},
	author = {Kim, John and Moin, Parviz and Moser, Robert},
	month = apr,
	year = {1987},
	note = {Publisher: Cambridge University Press},
	pages = {133--166},
}

@misc{mortensen_spectral-galerkin_2017,
	title = {A spectral-{Galerkin} turbulent channel flow solver for large-scale simulations},
	url = {http://arxiv.org/abs/1701.03787},
	abstract = {A fully (pseudo-)spectral solver for direct numerical simulations of large-scale turbulent channel flows is described. The solver utilizes the Chebyshev base functions suggested by J. Shen [SIAM J. Sci. Comput., 16, 1, 1995], that lead to stable and robust numerical schemes, even at very large scale. New and fast algorithms for the direct solution of the linear systems are devised, and algorithms and matrices for all required scalar products and transforms are provided. We validate the solver for very high Reynolds numbers. Specifically, the solver is shown to reproduce the first order statistics of Hoyas and Jim{\textbackslash}'\{e\}nez [Phys. Fluids, 18(1), 2006], for a channel flow at \$Re\_\{{\textbackslash}tau\}=2000\$. The solver is available through the open source project spectralDNS [https://github.com/spectralDNS].},
	urldate = {2023-06-27},
	publisher = {arXiv},
	author = {Mortensen, Mikael},
	month = jan,
	year = {2017},
	note = {arXiv:1701.03787 [physics]
version: 1},
	keywords = {Mathematics - Numerical Analysis, Physics - Fluid Dynamics},
}

@article{mortensen_high_2016,
	title = {High performance {Python} for direct numerical simulations of turbulent flows},
	volume = {203},
	issn = {00104655},
	url = {http://arxiv.org/abs/1602.03638},
	doi = {10.1016/j.cpc.2016.02.005},
	abstract = {Direct Numerical Simulations (DNS) of the Navier Stokes equations is an invaluable research tool in fluid dynamics. Still, there are few publicly available research codes and, due to the heavy number crunching implied, available codes are usually written in low-level languages such as C/C++ or Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS code that nearly matches the performance of C++ for thousands of processors and billions of unknowns. We also describe a version optimized through Cython, that is found to match the speed of C++. The solvers are written from scratch in Python, both the mesh, the MPI domain decomposition, and the temporal integrators. The solvers have been verified and benchmarked on the Shaheen supercomputer at the KAUST supercomputing laboratory, and we are able to show very good scaling up to several thousand cores. A very important part of the implementation is the mesh decomposition (we implement both slab and pencil decompositions) and 3D parallel Fast Fourier Transforms (FFT). The mesh decomposition and FFT routines have been implemented in Python using serial FFT routines (either NumPy, pyFFTW or any other serial FFT module), NumPy array manipulations and with MPI communications handled by MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT in Python for a slab mesh decomposition using 4 lines of compact Python code, for which the parallel performance on Shaheen is found to be slightly better than similar routines provided through the FFTW library. For a pencil mesh decomposition 7 lines of code is required to execute a transform.},
	urldate = {2023-06-27},
	journal = {Computer Physics Communications},
	author = {Mortensen, Mikael and Langtangen, Hans Petter},
	month = jun,
	year = {2016},
	note = {arXiv:1602.03638 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Mathematical Software},
	pages = {53--65},
}

@article{ketcheson_more_2020,
	title = {More efficient time integration for {Fourier} pseudospectral {DNS} of incompressible turbulence},
	volume = {92},
	copyright = {© 2019 John Wiley \& Sons, Ltd.},
	issn = {1097-0363},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/fld.4773},
	doi = {10.1002/fld.4773},
	abstract = {Time integration of Fourier pseudospectral DNS is usually performed using the classical fourth-order accurate Runge-Kutta method or other second- or third-order methods, with a fixed step size. We investigate the use of higher-order Runge-Kutta pairs and automatic step size control based on local error estimation. We find that the fifth-order accurate Runge-Kutta pair of Bogacki and Shampine gives much greater accuracy at a significantly reduced computational cost. Specifically, we demonstrate speedups of 2× to 10× for the same accuracy. Numerical tests (including the Taylor-Green vortex, Rayleigh-Taylor instability, and homogeneous isotropic turbulence) confirm the reliability and efficiency of the method. We also show that adaptive time stepping provides a significant computational advantage for some problems (like the development of a Rayleigh-Taylor instability) without compromising accuracy.},
	language = {en},
	number = {2},
	urldate = {2023-06-27},
	journal = {International Journal for Numerical Methods in Fluids},
	author = {Ketcheson, David I. and Mortensen, Mikael and Parsani, Matteo and Schilling, Nathanael},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/fld.4773},
	keywords = {adaptivity, error estimation, incompressible flow, spectral, time integration, turbulent flow},
	pages = {79--93},
}

@misc{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2023-06-23},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{noauthor_understanding_2023,
	title = {Understanding {Convolutional} {Neural} {Networks}: {A} {Complete} {Guide}},
	shorttitle = {Understanding {Convolutional} {Neural} {Networks}},
	url = {https://learnopencv.com/understanding-convolutional-neural-networks-cnn/},
	abstract = {In this post, we will introduce many concepts associated with Convolutional Neural Networks (CNN) in the context of an image classification problem.},
	language = {en-US},
	urldate = {2023-06-23},
	month = jan,
	year = {2023},
}

@article{bengio_representation_2013,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	volume = {35},
	issn = {1939-3539},
	shorttitle = {Representation {Learning}},
	doi = {10.1109/TPAMI.2013.50},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = aug,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Abstracts, Boltzmann machine, Deep learning, Feature extraction, Learning systems, Machine learning, Manifolds, Neural networks, Speech recognition, autoencoder, feature learning, neural nets, representation learning, unsupervised learning},
	pages = {1798--1828},
}

@misc{hu_neural_2022,
	title = {Neural {Operator} with {Regularity} {Structure} for {Modeling} {Dynamics} {Driven} by {SPDEs}},
	url = {http://arxiv.org/abs/2204.06255},
	doi = {10.48550/arXiv.2204.06255},
	abstract = {Stochastic partial differential equations (SPDEs) are significant tools for modeling dynamics in many areas including atmospheric sciences and physics. Neural Operators, generations of neural networks with capability of learning maps between infinite-dimensional spaces, are strong tools for solving parametric PDEs. However, they lack the ability to modeling SPDEs which usually have poor regularity due to the driving noise. As the theory of regularity structure has achieved great successes in analyzing SPDEs and provides the concept model feature vectors that well-approximate SPDEs' solutions, we propose the Neural Operator with Regularity Structure (NORS) which incorporates the feature vectors for modeling dynamics driven by SPDEs. We conduct experiments on various of SPDEs including the dynamic Phi41 model and the 2d stochastic Navier-Stokes equation, and the results demonstrate that the NORS is resolution-invariant, efficient, and achieves one order of magnitude lower error with a modest amount of data.},
	urldate = {2023-06-21},
	publisher = {arXiv},
	author = {Hu, Peiyan and Meng, Qi and Chen, Bingguang and Gong, Shiqi and Wang, Yue and Chen, Wei and Zhu, Rongchan and Ma, Zhi-Ming and Liu, Tie-Yan},
	month = jul,
	year = {2022},
	note = {arXiv:2204.06255 [physics]},
	keywords = {Computer Science - Machine Learning, Mathematics - Analysis of PDEs, Physics - Computational Physics},
}

@misc{michalowska_neural_2023,
	title = {Neural {Operator} {Learning} for {Long}-{Time} {Integration} in {Dynamical} {Systems} with {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2303.02243},
	doi = {10.48550/arXiv.2303.02243},
	abstract = {Deep neural networks are an attractive alternative for simulating complex dynamical systems, as in comparison to traditional scientific computing methods, they offer reduced computational costs during inference and can be trained directly from observational data. Existing methods, however, cannot extrapolate accurately and are prone to error accumulation in long-time integration. Herein, we address this issue by combining neural operators with recurrent neural networks to construct a novel and effective architecture, resulting in superior accuracy compared to the state-of-the-art. The new hybrid model is based on operator learning while offering a recurrent structure to capture temporal dependencies. The integrated framework is shown to stabilize the solution and reduce error accumulation for both interpolation and extrapolation of the Korteweg-de Vries equation.},
	urldate = {2023-06-21},
	publisher = {arXiv},
	author = {Michałowska, Katarzyna and Goswami, Somdatta and Karniadakis, George Em and Riemer-Sørensen, Signe},
	month = may,
	year = {2023},
	note = {arXiv:2303.02243 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{sipka_differentiable_2023,
	title = {Differentiable {Simulations} for {Enhanced} {Sampling} of {Rare} {Events}},
	url = {http://arxiv.org/abs/2301.03480},
	doi = {10.48550/arXiv.2301.03480},
	abstract = {Simulating rare events, such as the transformation of a reactant into a product in a chemical reaction typically requires enhanced sampling techniques that rely on heuristically chosen collective variables (CVs). We propose using differentiable simulations (DiffSim) for the discovery and enhanced sampling of chemical transformations without a need to resort to preselected CVs, using only a distance metric. Reaction path discovery and estimation of the biasing potential that enhances the sampling are merged into a single end-to-end problem that is solved by path-integral optimization. This is achieved by introducing multiple improvements over standard DiffSim such as partial backpropagation and graph mini-batching making DiffSim training stable and efficient. The potential of DiffSim is demonstrated in the successful discovery of transition paths for the Muller-Brown model potential as well as a benchmark chemical system - alanine dipeptide.},
	urldate = {2023-06-21},
	publisher = {arXiv},
	author = {Šípka, Martin and Dietschreit, Johannes C. B. and Grajciar, Lukáš and Gómez-Bombarelli, Rafael},
	month = jan,
	year = {2023},
	note = {arXiv:2301.03480 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Chemical Physics},
}

@book{batchelor_introduction_2010,
	address = {Cambridge},
	edition = {14. print},
	series = {Cambridge mathematical library},
	title = {An {Introduction} to fluid dynamics},
	isbn = {978-0-521-66396-0},
	language = {en},
	publisher = {Cambridge Univ. Press},
	author = {Batchelor, G. K.},
	year = {2010},
}

@misc{yu_climsim_2023,
	title = {{ClimSim}: {An} open large-scale dataset for training high-resolution physics emulators in hybrid multi-scale climate simulators},
	shorttitle = {{ClimSim}},
	url = {http://arxiv.org/abs/2306.08754},
	abstract = {Modern climate projections lack adequate spatial and temporal resolution due to computational constraints. A consequence is inaccurate and imprecise prediction of critical processes such as storms. Hybrid methods that combine physics with machine learning (ML) have introduced a new generation of higher fidelity climate simulators that can sidestep Moore's Law by outsourcing compute-hungry, short, high-resolution simulations to ML emulators. However, this hybrid ML-physics simulation approach requires domain-specific treatment and has been inaccessible to ML experts because of lack of training data and relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset designed for hybrid ML-physics research. It comprises multi-scale climate simulations, developed by a consortium of climate scientists and ML researchers. It consists of 5.7 billion pairs of multivariate input and output vectors that isolate the influence of locally-nested, high-resolution, high-fidelity physics on a host climate simulator's macro-scale physical state. The dataset is global in coverage, spans multiple years at high sampling frequency, and is designed such that resulting emulators are compatible with downstream coupling into operational climate simulators. We implement a range of deterministic and stochastic regression baselines to highlight the ML challenges and their scoring. The data (https://huggingface.co/datasets/LEAP/ClimSim\_high-res) and code (https://leap-stc.github.io/ClimSim) are released openly to support the development of hybrid ML-physics and high-fidelity climate simulations for the benefit of science and society.},
	urldate = {2023-06-20},
	publisher = {arXiv},
	author = {Yu, Sungduk and Hannah, Walter M. and Peng, Liran and Bhouri, Mohamed Aziz and Gupta, Ritwik and Lin, Jerry and Lütjens, Björn and Will, Justus C. and Beucler, Tom and Harrop, Bryce E. and Hillman, Benjamin R. and Jenney, Andrea M. and Ferretti, Savannah L. and Liu, Nana and Anandkumar, Anima and Brenowitz, Noah D. and Eyring, Veronika and Gentine, Pierre and Mandt, Stephan and Pathak, Jaideep and Vondrick, Carl and Yu, Rose and Zanna, Laure and Abernathey, Ryan P. and Ahmed, Fiaz and Bader, David C. and Baldi, Pierre and Barnes, Elizabeth A. and Behrens, Gunnar and Bretherton, Christopher S. and Busecke, Julius J. M. and Caldwell, Peter M. and Chuang, Wayne and Han, Yilun and Huang, Yu and Iglesias-Suarez, Fernando and Jantre, Sanket and Kashinath, Karthik and Khairoutdinov, Marat and Kurth, Thorsten and Lutsko, Nicholas J. and Ma, Po-Lun and Mooers, Griffin and Neelin, J. David and Randall, David A. and Shamekh, Sara and Subramaniam, Akshay and Taylor, Mark A. and Urban, Nathan M. and Yuval, Janni and Zhang, Guang J. and Zheng, Tian and Pritchard, Michael S.},
	month = jun,
	year = {2023},
	note = {arXiv:2306.08754 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
}

@article{tripura_wavelet_2023,
	title = {Wavelet {Neural} {Operator} for solving parametric partial differential equations in computational mechanics problems},
	volume = {404},
	issn = {00457825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782522007393},
	doi = {10.1016/j.cma.2022.115783},
	abstract = {With massive advancements in sensor technologies and Internet-of-things (IoT), we now have access to terabytes of historical data; however, there is a lack of clarity on how to best exploit the data to predict future events. One possible alternative in this context is to utilize an operator learning algorithm that directly learns the nonlinear mapping between two functional spaces; this facilitates real-time prediction of naturally arising complex evolutionary dynamics. In this work, we introduce a novel operator learning algorithm referred to as the Wavelet Neural Operator (WNO) that blends integral kernel with wavelet transformation. WNO harnesses the superiority of the wavelets in time–frequency localization of the functions and enables accurate tracking of patterns in the spatial domain and effective learning of the functional mappings. Since the wavelets are localized in both time/space and frequency, WNO can provide high spatial and frequency resolution. This offers learning of the finer details of the parametric dependencies in the solution for complex problems. The efficacy and robustness of the proposed WNO are illustrated on a wide array of problems involving Burger’s equation, Darcy flow, Navier–Stokes equation, Allen–Cahn equation, and Wave advection equation. A comparative study with respect to existing operator learning frameworks is presented. Finally, the proposed approach is used to build a digital twin capable of predicting Earth’s air temperature based on available historical data.},
	language = {en},
	urldate = {2023-06-16},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Tripura, Tapas and Chakraborty, Souvik},
	month = feb,
	year = {2023},
	pages = {115783},
}

@misc{lensink_fully_2020,
	title = {Fully {Hyperbolic} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1905.10484},
	abstract = {Convolutional Neural Networks (CNN) have recently seen tremendous success in various computer vision tasks. However, their application to problems with high dimensional input and output, such as high-resolution image and video segmentation or 3D medical imaging, has been limited by various factors. Primarily, in the training stage, it is necessary to store network activations for back propagation. In these settings, the memory requirements associated with storing activations can exceed what is feasible with current hardware, especially for problems in 3D. Motivated by the propagation of signals over physical networks, that are governed by the hyperbolic Telegraph equation, in this work we introduce a fully conservative hyperbolic network for problems with high dimensional input and output. We introduce a coarsening operation that allows completely reversible CNNs by using a learnable Discrete Wavelet Transform and its inverse to both coarsen and interpolate the network state and change the number of channels. We show that fully reversible networks are able to achieve results comparable to the state of the art in 4D time-lapse hyper spectral image segmentation and full 3D video segmentation, with a much lower memory footprint that is a constant independent of the network depth. We also extend the use of such networks to Variational Auto Encoders with high resolution input and output.},
	urldate = {2023-06-16},
	publisher = {arXiv},
	author = {Lensink, Keegan and Peters, Bas and Haber, Eldad},
	month = jul,
	year = {2020},
	note = {arXiv:1905.10484 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{gupta_multiwavelet-based_2021,
	title = {Multiwavelet-based {Operator} {Learning} for {Differential} {Equations}},
	url = {http://arxiv.org/abs/2109.13459},
	abstract = {The solution of a partial differential equation can be obtained by computing the inverse operator map between the input and the solution space. Towards this end, we introduce a {\textbackslash}textit\{multiwavelet-based neural operator learning scheme\} that compresses the associated operator's kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, we learn the projection of the kernel onto fixed multiwavelet polynomial bases. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. Compare to the prior works, we exploit the fundamental properties of the operator's kernel which enable numerically efficient representation. We perform experiments on the Korteweg-de Vries (KdV) equation, Burgers' equation, Darcy Flow, and Navier-Stokes equation. Compared with the existing neural operator approaches, our model shows significantly higher accuracy and achieves state-of-the-art in a range of datasets. For the time-varying equations, the proposed method exhibits a (\$2X-10X\$) improvement (\$0.0018\$ (\$0.0033\$) relative \$L2\$ error for Burgers' (KdV) equation). By learning the mappings between function spaces, the proposed method has the ability to find the solution of a high-resolution input after learning from lower-resolution data.},
	urldate = {2023-06-16},
	publisher = {arXiv},
	author = {Gupta, Gaurav and Xiao, Xiongye and Bogdan, Paul},
	month = oct,
	year = {2021},
	note = {arXiv:2109.13459 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Analysis of PDEs},
}

@article{tripura_wavelet_2023-1,
	title = {Wavelet {Neural} {Operator} for solving parametric partial differential equations in computational mechanics problems},
	volume = {404},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782522007393},
	doi = {10.1016/j.cma.2022.115783},
	abstract = {With massive advancements in sensor technologies and Internet-of-things (IoT), we now have access to terabytes of historical data; however, there is a lack of clarity on how to best exploit the data to predict future events. One possible alternative in this context is to utilize an operator learning algorithm that directly learns the nonlinear mapping between two functional spaces; this facilitates real-time prediction of naturally arising complex evolutionary dynamics. In this work, we introduce a novel operator learning algorithm referred to as the Wavelet Neural Operator (WNO) that blends integral kernel with wavelet transformation. WNO harnesses the superiority of the wavelets in time–frequency localization of the functions and enables accurate tracking of patterns in the spatial domain and effective learning of the functional mappings. Since the wavelets are localized in both time/space and frequency, WNO can provide high spatial and frequency resolution. This offers learning of the finer details of the parametric dependencies in the solution for complex problems. The efficacy and robustness of the proposed WNO are illustrated on a wide array of problems involving Burger’s equation, Darcy flow, Navier–Stokes equation, Allen–Cahn equation, and Wave advection equation. A comparative study with respect to existing operator learning frameworks is presented. Finally, the proposed approach is used to build a digital twin capable of predicting Earth’s air temperature based on available historical data.},
	language = {en},
	urldate = {2023-06-16},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Tripura, Tapas and Chakraborty, Souvik},
	month = feb,
	year = {2023},
	keywords = {Nonlinear mappings, Operator learning, Scientific machine learning, Wavelet, Wavelet neural operator},
	pages = {115783},
}

@misc{noauthor_optax_2023,
	title = {Optax},
	copyright = {Apache-2.0},
	url = {https://github.com/deepmind/optax},
	abstract = {Optax is a gradient processing and optimization library for JAX.},
	urldate = {2023-06-14},
	publisher = {DeepMind},
	month = jun,
	year = {2023},
	note = {original-date: 2020-06-12T15:45:35Z},
}

@misc{noauthor_flax_2023,
	title = {Flax: {A} neural network library and ecosystem for {JAX} designed for flexibility},
	copyright = {Apache-2.0},
	shorttitle = {Flax},
	url = {https://github.com/google/flax},
	abstract = {Flax is a neural network library for JAX that is designed for flexibility.},
	urldate = {2023-06-14},
	publisher = {Google},
	month = jun,
	year = {2023},
	note = {original-date: 2020-01-10T09:48:37Z},
	keywords = {jax},
}

@misc{pascanu_difficulty_2013,
	title = {On the difficulty of training {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1211.5063},
	doi = {10.48550/arXiv.1211.5063},
	abstract = {There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
	urldate = {2023-06-14},
	publisher = {arXiv},
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	month = feb,
	year = {2013},
	note = {arXiv:1211.5063 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{sohl-dickstein_infinite_2020,
	title = {On the infinite width limit of neural networks with a standard parameterization},
	url = {http://arxiv.org/abs/2001.07301},
	abstract = {There are currently two parameterizations used to derive fixed kernels corresponding to infinite width neural networks, the NTK (Neural Tangent Kernel) parameterization and the naive standard parameterization. However, the extrapolation of both of these parameterizations to infinite width is problematic. The standard parameterization leads to a divergent neural tangent kernel while the NTK parameterization fails to capture crucial aspects of finite width networks such as: the dependence of training dynamics on relative layer widths, the relative training dynamics of weights and biases, and overall learning rate scale. Here we propose an improved extrapolation of the standard parameterization that preserves all of these properties as width is taken to infinity and yields a well-defined neural tangent kernel. We show experimentally that the resulting kernels typically achieve similar accuracy to those resulting from an NTK parameterization, but with better correspondence to the parameterization of typical finite width networks. Additionally, with careful tuning of width parameters, the improved standard parameterization kernels can outperform those stemming from an NTK parameterization. We release code implementing this improved standard parameterization as part of the Neural Tangents library at https://github.com/google/neural-tangents.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Sohl-Dickstein, Jascha and Novak, Roman and Schoenholz, Samuel S. and Lee, Jaehoon},
	month = apr,
	year = {2020},
	note = {arXiv:2001.07301 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{hron_infinite_2020,
	title = {Infinite attention: {NNGP} and {NTK} for deep attention networks},
	shorttitle = {Infinite attention},
	url = {http://arxiv.org/abs/2006.10540},
	abstract = {There is a growing amount of literature on the relationship between wide neural networks (NNs) and Gaussian processes (GPs), identifying an equivalence between the two for a variety of NN architectures. This equivalence enables, for instance, accurate approximation of the behaviour of wide Bayesian NNs without MCMC or variational approximations, or characterisation of the distribution of randomly initialised wide NNs optimised by gradient descent without ever running an optimiser. We provide a rigorous extension of these results to NNs involving attention layers, showing that unlike single-head attention, which induces non-Gaussian behaviour, multi-head attention architectures behave as GPs as the number of heads tends to infinity. We further discuss the effects of positional encodings and layer normalisation, and propose modifications of the attention mechanism which lead to improved results for both finite and infinitely wide NNs. We evaluate attention kernels empirically, leading to a moderate improvement upon the previous state-of-the-art on CIFAR-10 for GPs without trainable kernels and advanced data preprocessing. Finally, we introduce new features to the Neural Tangents library (Novak et al., 2020) allowing applications of NNGP/NTK models, with and without attention, to variable-length sequences, with an example on the IMDb reviews dataset.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Hron, Jiri and Bahri, Yasaman and Sohl-Dickstein, Jascha and Novak, Roman},
	month = jun,
	year = {2020},
	note = {arXiv:2006.10540 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{novak_fast_2022,
	title = {Fast {Finite} {Width} {Neural} {Tangent} {Kernel}},
	url = {http://arxiv.org/abs/2206.08720},
	abstract = {The Neural Tangent Kernel (NTK), defined as \${\textbackslash}Theta\_{\textbackslash}theta{\textasciicircum}f(x\_1, x\_2) = {\textbackslash}left[{\textbackslash}partial f({\textbackslash}theta, x\_1){\textbackslash}big/{\textbackslash}partial {\textbackslash}theta{\textbackslash}right] {\textbackslash}left[{\textbackslash}partial f({\textbackslash}theta, x\_2){\textbackslash}big/{\textbackslash}partial {\textbackslash}theta{\textbackslash}right]{\textasciicircum}T\$ where \${\textbackslash}left[{\textbackslash}partial f({\textbackslash}theta, {\textbackslash}cdot){\textbackslash}big/{\textbackslash}partial {\textbackslash}theta{\textbackslash}right]\$ is a neural network (NN) Jacobian, has emerged as a central object of study in deep learning. In the infinite width limit, the NTK can sometimes be computed analytically and is useful for understanding training and generalization of NN architectures. At finite widths, the NTK is also used to better initialize NNs, compare the conditioning across models, perform architecture search, and do meta-learning. Unfortunately, the finite width NTK is notoriously expensive to compute, which severely limits its practical utility. We perform the first in-depth analysis of the compute and memory requirements for NTK computation in finite width networks. Leveraging the structure of neural networks, we further propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK, dramatically improving efficiency. Our algorithms can be applied in a black box fashion to any differentiable function, including those implementing neural networks. We open-source our implementations within the Neural Tangents package (arXiv:1912.02803) at https://github.com/google/neural-tangents.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Novak, Roman and Sohl-Dickstein, Jascha and Schoenholz, Samuel S.},
	month = jun,
	year = {2022},
	note = {arXiv:2206.08720 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{novak_neural_2019,
	title = {Neural {Tangents}: {Fast} and {Easy} {Infinite} {Neural} {Networks} in {Python}},
	shorttitle = {Neural {Tangents}},
	url = {http://arxiv.org/abs/1912.02803},
	abstract = {Neural Tangents is a library designed to enable research into infinite-width neural networks. It provides a high-level API for specifying complex and hierarchical neural network architectures. These networks can then be trained and evaluated either at finite-width as usual or in their infinite-width limit. Infinite-width networks can be trained analytically using exact Bayesian inference or using gradient descent via the Neural Tangent Kernel. Additionally, Neural Tangents provides tools to study gradient descent training dynamics of wide but finite networks in either function space or weight space. The entire library runs out-of-the-box on CPU, GPU, or TPU. All computations can be automatically distributed over multiple accelerators with near-linear scaling in the number of devices. Neural Tangents is available at www.github.com/google/neural-tangents. We also provide an accompanying interactive Colab notebook.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Novak, Roman and Xiao, Lechao and Hron, Jiri and Lee, Jaehoon and Alemi, Alexander A. and Sohl-Dickstein, Jascha and Schoenholz, Samuel S.},
	month = dec,
	year = {2019},
	note = {arXiv:1912.02803 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{pennington_emergence_2018,
	title = {The {Emergence} of {Spectral} {Universality} in {Deep} {Networks}},
	url = {http://arxiv.org/abs/1802.09979},
	abstract = {Recent work has shown that tight concentration of the entire spectrum of singular values of a deep network's input-output Jacobian around one at initialization can speed up learning by orders of magnitude. Therefore, to guide important design choices, it is important to build a full theoretical understanding of the spectra of Jacobians at initialization. To this end, we leverage powerful tools from free probability theory to provide a detailed analytic understanding of how a deep network's Jacobian spectrum depends on various hyperparameters including the nonlinearity, the weight and bias distributions, and the depth. For a variety of nonlinearities, our work reveals the emergence of new universal limiting spectral distributions that remain concentrated around one even as the depth goes to infinity.},
	urldate = {2023-06-08},
	publisher = {arXiv},
	author = {Pennington, Jeffrey and Schoenholz, Samuel S. and Ganguli, Surya},
	month = feb,
	year = {2018},
	note = {arXiv:1802.09979 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{banerjee_physics-informed_2023,
	title = {Physics-{Informed} {Computer} {Vision}: {A} {Review} and {Perspectives}},
	shorttitle = {Physics-{Informed} {Computer} {Vision}},
	url = {http://arxiv.org/abs/2305.18035},
	doi = {10.48550/arXiv.2305.18035},
	abstract = {Incorporation of physical information in machine learning frameworks are opening and transforming many application domains. Here the learning process is augmented through the induction of fundamental knowledge and governing physical laws. In this work we explore their utility for computer vision tasks in interpreting and understanding visual data. We present a systematic literature review of formulation and approaches to computer vision tasks guided by physical laws, known as physics-informed computer vision. We begin by decomposing the popular computer vision pipeline into a taxonomy of stages and investigate approaches to incorporate governing physical equations in each stage. Existing approaches in each task are analyzed with regard to what governing physical processes are modeled for integration and how they are formulated to be incorporated, i.e. modify data (observation bias), modify networks (inductive bias), and modify losses (learning bias) to include physical rules. The taxonomy offers a unified view of the application of the physics-informed capability, highlighting where physics-informed machine learning has been conducted and where the gaps and opportunities are. Finally, we highlight open problems and challenges to inform future research avenues. While still in its early days, the study of physics-informed computer vision has the promise to develop better computer vision models that can improve physical plausibility, accuracy, data efficiency and generalization in increasingly realistic applications.},
	urldate = {2023-06-01},
	publisher = {arXiv},
	author = {Banerjee, Chayan and Nguyen, Kien and Fookes, Clinton and Karniadakis, George},
	month = may,
	year = {2023},
	note = {arXiv:2305.18035 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{lee_vision_2021,
	title = {Vision {Transformer} for {Small}-{Size} {Datasets}},
	url = {http://arxiv.org/abs/2112.13492},
	abstract = {Recently, the Vision Transformer (ViT), which applied the transformer structure to the image classification task, has outperformed convolutional neural networks. However, the high performance of the ViT results from pre-training using a large-size dataset such as JFT-300M, and its dependence on a large dataset is interpreted as due to low locality inductive bias. This paper proposes Shifted Patch Tokenization (SPT) and Locality Self-Attention (LSA), which effectively solve the lack of locality inductive bias and enable it to learn from scratch even on small-size datasets. Moreover, SPT and LSA are generic and effective add-on modules that are easily applicable to various ViTs. Experimental results show that when both SPT and LSA were applied to the ViTs, the performance improved by an average of 2.96\% in Tiny-ImageNet, which is a representative small-size dataset. Especially, Swin Transformer achieved an overwhelming performance improvement of 4.08\% thanks to the proposed SPT and LSA.},
	urldate = {2023-05-30},
	publisher = {arXiv},
	author = {Lee, Seung Hoon and Lee, Seunghyun and Song, Byung Cheol},
	month = dec,
	year = {2021},
	note = {arXiv:2112.13492 [cs]
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{gupta_maskvit_2023,
	title = {{MaskViT}: {Masked} {Visual} {Pre}-{Training} for {Video} {Prediction}},
	shorttitle = {{MaskViT}},
	url = {https://openreview.net/forum?id=QAV2CcLEDh},
	abstract = {The ability to predict future visual observations conditioned on past observations and motor commands can enable embodied agents to plan solutions to a variety of tasks in complex environments. This work shows that we can create good video prediction models by pre-training transformers via masked visual modeling. Our approach, named MaskViT, is based on two simple design decisions. First, for memory and training efficiency, we use two types of window attention: spatial and spatiotemporal. Second, during training, we mask a variable percentage of tokens instead of a fixed mask ratio. For inference, MaskViT generates all tokens via iterative refinement where we incrementally decrease the masking ratio following a mask scheduling function. On several datasets we demonstrate that MaskViT outperforms prior works in video prediction, is parameter efficient, and can generate high resolution videos (\$256 {\textbackslash}times \$256). Further, we demonstrate the benefits of inference speedup (up to \$512 {\textbackslash}times\$) due to iterative decoding by using MaskViT for planning on a real robot. Our work suggests that we can endow embodied agents with powerful predictive models by leveraging the general framework of masked visual modeling with minimal domain knowledge.},
	language = {en},
	urldate = {2023-05-30},
	author = {Gupta, Agrim and Tian, Stephen and Zhang, Yunzhi and Wu, Jiajun and Martín-Martín, Roberto and Fei-Fei, Li},
	month = feb,
	year = {2023},
}

@article{ye_video_2023,
	title = {Video prediction by efficient transformers},
	volume = {130},
	issn = {0262-8856},
	url = {https://www.sciencedirect.com/science/article/pii/S0262885622002414},
	doi = {10.1016/j.imavis.2022.104612},
	abstract = {Video prediction is a challenging computer vision task that has a wide range of applications. In this work, we present a new family of Transformer-based models for video prediction. Firstly, an efficient local spatial–temporal separation attention mechanism is proposed to reduce the complexity of standard Transformers. Then, a full autoregressive model, a partial autoregressive model and a non-autoregressive model are developed based on the new efficient Transformer. The partial autoregressive model has a similar performance with the full autoregressive model but a faster inference speed. The non-autoregressive model not only achieves a faster inference speed but also mitigates the quality degradation problem of the autoregressive counterparts, but it requires additional parameters and loss function for learning. Given the same attention mechanism, we conducted a comprehensive study to compare the proposed three video prediction variants. Experiments show that the proposed video prediction models are competitive with more complex state-of-the-art convolutional-LSTM based models. The source code is available at https://github.com/XiYe20/VPTR.},
	language = {en},
	urldate = {2023-05-30},
	journal = {Image and Vision Computing},
	author = {Ye, Xi and Bilodeau, Guillaume-Alexandre},
	month = feb,
	year = {2023},
	keywords = {Autoregressive generative models, Non-autoregressive generative models, Transformers, Video prediction, Video representation learning},
	pages = {104612},
}

@misc{ye_vptr_2022,
	title = {{VPTR}: {Efficient} {Transformers} for {Video} {Prediction}},
	shorttitle = {{VPTR}},
	url = {http://arxiv.org/abs/2203.15836},
	doi = {10.48550/arXiv.2203.15836},
	abstract = {In this paper, we propose a new Transformer block for video future frames prediction based on an efficient local spatial-temporal separation attention mechanism. Based on this new Transformer block, a fully autoregressive video future frames prediction Transformer is proposed. In addition, a non-autoregressive video prediction Transformer is also proposed to increase the inference speed and reduce the accumulated inference errors of its autoregressive counterpart. In order to avoid the prediction of very similar future frames, a contrastive feature loss is applied to maximize the mutual information between predicted and ground-truth future frame features. This work is the first that makes a formal comparison of the two types of attention-based video future frames prediction models over different scenarios. The proposed models reach a performance competitive with more complex state-of-the-art models. The source code is available at {\textbackslash}emph\{https://github.com/XiYe20/VPTR\}.},
	urldate = {2023-05-30},
	publisher = {arXiv},
	author = {Ye, Xi and Bilodeau, Guillaume-Alexandre},
	month = mar,
	year = {2022},
	note = {arXiv:2203.15836 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{dresdner_learning_2022,
	title = {Learning to correct spectral methods for simulating turbulent flows},
	url = {http://arxiv.org/abs/2207.00556},
	doi = {10.48550/arXiv.2207.00556},
	abstract = {Despite their ubiquity throughout science and engineering, only a handful of partial differential equations (PDEs) have analytical, or closed-form solutions. This motivates a vast amount of classical work on numerical simulation of PDEs and more recently, a whirlwind of research into data-driven techniques leveraging machine learning (ML). A recent line of work indicates that a hybrid of classical numerical techniques with machine learning can offer significant improvements over either approach alone. In this work, we show that the choice of the numerical scheme is crucial when incorporating physics-based priors. We build upon Fourier-based spectral methods, which are considerably more efficient than other numerical schemes for simulating PDEs with smooth and periodic solutions. Specifically, we develop ML-augmented spectral solvers for three model PDEs of fluid dynamics, which improve upon the accuracy of standard spectral solvers at the same resolution. We also demonstrate a handful of key design principles for combining machine learning and numerical methods for solving PDEs.},
	urldate = {2023-05-30},
	publisher = {arXiv},
	author = {Dresdner, Gideon and Kochkov, Dmitrii and Norgaard, Peter and Zepeda-Núñez, Leonardo and Smith, Jamie A. and Brenner, Michael P. and Hoyer, Stephan},
	month = jul,
	year = {2022},
	note = {arXiv:2207.00556 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@misc{wang_improved_2021,
	title = {Improved architectures and training algorithms for deep operator networks},
	url = {http://arxiv.org/abs/2110.01654},
	abstract = {Operator learning techniques have recently emerged as a powerful tool for learning maps between infinite-dimensional Banach spaces. Trained under appropriate constraints, they can also be effective in learning the solution operator of partial differential equations (PDEs) in an entirely self-supervised manner. In this work we analyze the training dynamics of deep operator networks (DeepONets) through the lens of Neural Tangent Kernel (NTK) theory, and reveal a bias that favors the approximation of functions with larger magnitudes. To correct this bias we propose to adaptively re-weight the importance of each training example, and demonstrate how this procedure can effectively balance the magnitude of back-propagated gradients during training via gradient descent. We also propose a novel network architecture that is more resilient to vanishing gradient pathologies. Taken together, our developments provide new insights into the training of DeepONets and consistently improve their predictive accuracy by a factor of 10-50x, demonstrated in the challenging setting of learning PDE solution operators in the absence of paired input-output observations. All code and data accompanying this manuscript are publicly available at {\textbackslash}url\{https://github.com/PredictiveIntelligenceLab/ImprovedDeepONets.\}},
	urldate = {2023-05-26},
	publisher = {arXiv},
	author = {Wang, Sifan and Wang, Hanwen and Perdikaris, Paris},
	month = oct,
	year = {2021},
	note = {arXiv:2110.01654 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{yang_scalable_2022,
	title = {Scalable uncertainty quantification for deep operator networks using randomized priors},
	volume = {399},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782522004595},
	doi = {10.1016/j.cma.2022.115399},
	abstract = {We present a simple and effective approach for posterior uncertainty quantification in deep operator networks (DeepONets); an emerging paradigm for supervised learning in function spaces. We adopt a frequentist approach based on randomized prior ensembles, and put forth an efficient vectorized implementation for fast parallel inference on accelerated hardware. Through a collection of representative examples in computational mechanics and climate modeling, we show that the merits of the proposed approach are fourfold. (1) It can provide more robust and accurate predictions when compared against deterministic DeepONets. (2) It shows great capability in providing reliable uncertainty estimates on scarce data sets with multi-scale function pairs. (3) It can effectively detect out-of-distribution and adversarial examples. (4) It can seamlessly quantify uncertainty due to model bias, as well as noise corruption in the data. Finally, we provide an optimized JAX library called UQDeepONet that can accommodate large model architectures, large ensemble sizes, as well as large data sets with excellent parallel performance on accelerated hardware, thereby enabling uncertainty quantification for DeepONets in realistic large-scale applications. All code and data accompanying this manuscript will be made available at https://github.com/PredictiveIntelligenceLab/UQDeepONet.},
	language = {en},
	urldate = {2023-05-26},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Yang, Yibo and Kissas, Georgios and Perdikaris, Paris},
	month = sep,
	year = {2022},
	keywords = {Deep learning, Operator learning, Uncertainty quantification},
	pages = {115399},
}

@article{iglesias_data_2023,
	title = {Data {Augmentation} techniques in time series domain: {A} survey and taxonomy},
	volume = {35},
	issn = {0941-0643, 1433-3058},
	shorttitle = {Data {Augmentation} techniques in time series domain},
	url = {http://arxiv.org/abs/2206.13508},
	doi = {10.1007/s00521-023-08459-3},
	abstract = {With the latest advances in Deep Learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using Data Augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state-of-the-art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.},
	number = {14},
	urldate = {2023-05-24},
	journal = {Neural Computing and Applications},
	author = {Iglesias, Guillermo and Talavera, Edgar and González-Prieto, Ángel and Mozo, Alberto and Gómez-Canaval, Sandra},
	month = may,
	year = {2023},
	note = {arXiv:2206.13508 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.6},
	pages = {10123--10145},
}

@article{shorten_survey_2019,
	title = {A survey on {Image} {Data} {Augmentation} for {Deep} {Learning}},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	number = {1},
	urldate = {2023-05-23},
	journal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	month = jul,
	year = {2019},
	keywords = {Big data, Data Augmentation, Deep Learning, GANs, Image data},
	pages = {60},
}

@misc{workshop_bloom_2023,
	title = {{BLOOM}: {A} {176B}-{Parameter} {Open}-{Access} {Multilingual} {Language} {Model}},
	shorttitle = {{BLOOM}},
	url = {http://arxiv.org/abs/2211.05100},
	doi = {10.48550/arXiv.2211.05100},
	abstract = {Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.},
	urldate = {2023-05-23},
	publisher = {arXiv},
	author = {Workshop, BigScience and Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ilić, Suzana and Hesslow, Daniel and Castagné, Roman and Luccioni, Alexandra Sasha and Yvon, François and Gallé, Matthias and Tow, Jonathan and Rush, Alexander M. and Biderman, Stella and Webson, Albert and Ammanamanchi, Pawan Sasanka and Wang, Thomas and Sagot, Benoît and Muennighoff, Niklas and del Moral, Albert Villanova and Ruwase, Olatunji and Bawden, Rachel and Bekman, Stas and McMillan-Major, Angelina and Beltagy, Iz and Nguyen, Huu and Saulnier, Lucile and Tan, Samson and Suarez, Pedro Ortiz and Sanh, Victor and Laurençon, Hugo and Jernite, Yacine and Launay, Julien and Mitchell, Margaret and Raffel, Colin and Gokaslan, Aaron and Simhi, Adi and Soroa, Aitor and Aji, Alham Fikri and Alfassy, Amit and Rogers, Anna and Nitzav, Ariel Kreisberg and Xu, Canwen and Mou, Chenghao and Emezue, Chris and Klamm, Christopher and Leong, Colin and van Strien, Daniel and Adelani, David Ifeoluwa and Radev, Dragomir and Ponferrada, Eduardo González and Levkovizh, Efrat and Kim, Ethan and Natan, Eyal Bar and De Toni, Francesco and Dupont, Gérard and Kruszewski, Germán and Pistilli, Giada and Elsahar, Hady and Benyamina, Hamza and Tran, Hieu and Yu, Ian and Abdulmumin, Idris and Johnson, Isaac and Gonzalez-Dios, Itziar and de la Rosa, Javier and Chim, Jenny and Dodge, Jesse and Zhu, Jian and Chang, Jonathan and Frohberg, Jörg and Tobing, Joseph and Bhattacharjee, Joydeep and Almubarak, Khalid and Chen, Kimbo and Lo, Kyle and Von Werra, Leandro and Weber, Leon and Phan, Long and allal, Loubna Ben and Tanguy, Ludovic and Dey, Manan and Muñoz, Manuel Romero and Masoud, Maraim and Grandury, María and Šaško, Mario and Huang, Max and Coavoux, Maximin and Singh, Mayank and Jiang, Mike Tian-Jian and Vu, Minh Chien and Jauhar, Mohammad A. and Ghaleb, Mustafa and Subramani, Nishant and Kassner, Nora and Khamis, Nurulaqilla and Nguyen, Olivier and Espejel, Omar and de Gibert, Ona and Villegas, Paulo and Henderson, Peter and Colombo, Pierre and Amuok, Priscilla and Lhoest, Quentin and Harliman, Rheza and Bommasani, Rishi and López, Roberto Luis and Ribeiro, Rui and Osei, Salomey and Pyysalo, Sampo and Nagel, Sebastian and Bose, Shamik and Muhammad, Shamsuddeen Hassan and Sharma, Shanya and Longpre, Shayne and Nikpoor, Somaieh and Silberberg, Stanislav and Pai, Suhas and Zink, Sydney and Torrent, Tiago Timponi and Schick, Timo and Thrush, Tristan and Danchev, Valentin and Nikoulina, Vassilina and Laippala, Veronika and Lepercq, Violette and Prabhu, Vrinda and Alyafeai, Zaid and Talat, Zeerak and Raja, Arun and Heinzerling, Benjamin and Si, Chenglei and Taşar, Davut Emre and Salesky, Elizabeth and Mielke, Sabrina J. and Lee, Wilson Y. and Sharma, Abheesht and Santilli, Andrea and Chaffin, Antoine and Stiegler, Arnaud and Datta, Debajyoti and Szczechla, Eliza and Chhablani, Gunjan and Wang, Han and Pandey, Harshit and Strobelt, Hendrik and Fries, Jason Alan and Rozen, Jos and Gao, Leo and Sutawika, Lintang and Bari, M. Saiful and Al-shaibani, Maged S. and Manica, Matteo and Nayak, Nihal and Teehan, Ryan and Albanie, Samuel and Shen, Sheng and Ben-David, Srulik and Bach, Stephen H. and Kim, Taewoon and Bers, Tali and Fevry, Thibault and Neeraj, Trishala and Thakker, Urmish and Raunak, Vikas and Tang, Xiangru and Yong, Zheng-Xin and Sun, Zhiqing and Brody, Shaked and Uri, Yallow and Tojarieh, Hadar and Roberts, Adam and Chung, Hyung Won and Tae, Jaesung and Phang, Jason and Press, Ofir and Li, Conglong and Narayanan, Deepak and Bourfoune, Hatim and Casper, Jared and Rasley, Jeff and Ryabinin, Max and Mishra, Mayank and Zhang, Minjia and Shoeybi, Mohammad and Peyrounette, Myriam and Patry, Nicolas and Tazi, Nouamane and Sanseviero, Omar and von Platen, Patrick and Cornette, Pierre and Lavallée, Pierre François and Lacroix, Rémi and Rajbhandari, Samyam and Gandhi, Sanchit and Smith, Shaden and Requena, Stéphane and Patil, Suraj and Dettmers, Tim and Baruwa, Ahmed and Singh, Amanpreet and Cheveleva, Anastasia and Ligozat, Anne-Laure and Subramonian, Arjun and Névéol, Aurélie and Lovering, Charles and Garrette, Dan and Tunuguntla, Deepak and Reiter, Ehud and Taktasheva, Ekaterina and Voloshina, Ekaterina and Bogdanov, Eli and Winata, Genta Indra and Schoelkopf, Hailey and Kalo, Jan-Christoph and Novikova, Jekaterina and Forde, Jessica Zosa and Clive, Jordan and Kasai, Jungo and Kawamura, Ken and Hazan, Liam and Carpuat, Marine and Clinciu, Miruna and Kim, Najoung and Cheng, Newton and Serikov, Oleg and Antverg, Omer and van der Wal, Oskar and Zhang, Rui and Zhang, Ruochen and Gehrmann, Sebastian and Mirkin, Shachar and Pais, Shani and Shavrina, Tatiana and Scialom, Thomas and Yun, Tian and Limisiewicz, Tomasz and Rieser, Verena and Protasov, Vitaly and Mikhailov, Vladislav and Pruksachatkun, Yada and Belinkov, Yonatan and Bamberger, Zachary and Kasner, Zdeněk and Rueda, Alice and Pestana, Amanda and Feizpour, Amir and Khan, Ammar and Faranak, Amy and Santos, Ana and Hevia, Anthony and Unldreaj, Antigona and Aghagol, Arash and Abdollahi, Arezoo and Tammour, Aycha and HajiHosseini, Azadeh and Behroozi, Bahareh and Ajibade, Benjamin and Saxena, Bharat and Ferrandis, Carlos Muñoz and Contractor, Danish and Lansky, David and David, Davis and Kiela, Douwe and Nguyen, Duong A. and Tan, Edward and Baylor, Emi and Ozoani, Ezinwanne and Mirza, Fatima and Ononiwu, Frankline and Rezanejad, Habib and Jones, Hessie and Bhattacharya, Indrani and Solaiman, Irene and Sedenko, Irina and Nejadgholi, Isar and Passmore, Jesse and Seltzer, Josh and Sanz, Julio Bonis and Dutra, Livia and Samagaio, Mairon and Elbadri, Maraim and Mieskes, Margot and Gerchick, Marissa and Akinlolu, Martha and McKenna, Michael and Qiu, Mike and Ghauri, Muhammed and Burynok, Mykola and Abrar, Nafis and Rajani, Nazneen and Elkott, Nour and Fahmy, Nour and Samuel, Olanrewaju and An, Ran and Kromann, Rasmus and Hao, Ryan and Alizadeh, Samira and Shubber, Sarmad and Wang, Silas and Roy, Sourav and Viguier, Sylvain and Le, Thanh and Oyebade, Tobi and Le, Trieu and Yang, Yoyo and Nguyen, Zach and Kashyap, Abhinav Ramesh and Palasciano, Alfredo and Callahan, Alison and Shukla, Anima and Miranda-Escalada, Antonio and Singh, Ayush and Beilharz, Benjamin and Wang, Bo and Brito, Caio and Zhou, Chenxi and Jain, Chirag and Xu, Chuxin and Fourrier, Clémentine and Periñán, Daniel León and Molano, Daniel and Yu, Dian and Manjavacas, Enrique and Barth, Fabio and Fuhrimann, Florian and Altay, Gabriel and Bayrak, Giyaseddin and Burns, Gully and Vrabec, Helena U. and Bello, Imane and Dash, Ishani and Kang, Jihyun and Giorgi, John and Golde, Jonas and Posada, Jose David and Sivaraman, Karthik Rangasai and Bulchandani, Lokesh and Liu, Lu and Shinzato, Luisa and de Bykhovetz, Madeleine Hahn and Takeuchi, Maiko and Pàmies, Marc and Castillo, Maria A. and Nezhurina, Marianna and Sänger, Mario and Samwald, Matthias and Cullan, Michael and Weinberg, Michael and De Wolf, Michiel and Mihaljcic, Mina and Liu, Minna and Freidank, Moritz and Kang, Myungsun and Seelam, Natasha and Dahlberg, Nathan and Broad, Nicholas Michio and Muellner, Nikolaus and Fung, Pascale and Haller, Patrick and Chandrasekhar, Ramya and Eisenberg, Renata and Martin, Robert and Canalli, Rodrigo and Su, Rosaline and Su, Ruisi and Cahyawijaya, Samuel and Garda, Samuele and Deshmukh, Shlok S. and Mishra, Shubhanshu and Kiblawi, Sid and Ott, Simon and Sang-aroonsiri, Sinee and Kumar, Srishti and Schweter, Stefan and Bharati, Sushil and Laud, Tanmay and Gigant, Théo and Kainuma, Tomoya and Kusa, Wojciech and Labrak, Yanis and Bajaj, Yash Shailesh and Venkatraman, Yash and Xu, Yifan and Xu, Yingxin and Xu, Yu and Tan, Zhe and Xie, Zhongli and Ye, Zifan and Bras, Mathilde and Belkada, Younes and Wolf, Thomas},
	month = mar,
	year = {2023},
	note = {arXiv:2211.05100 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{yin_continuous_2023,
	title = {Continuous {PDE} {Dynamics} {Forecasting} with {Implicit} {Neural} {Representations}},
	url = {http://arxiv.org/abs/2209.14855},
	doi = {10.48550/arXiv.2209.14855},
	abstract = {Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by introducing a new data-driven approach, DINo, that models a PDE's flow with continuous-time dynamics of spatially continuous functions. This is achieved by embedding spatial observations independently of their discretization via Implicit Neural Representations in a small latent space temporally driven by a learned ODE. This separate and flexible treatment of time and space makes DINo the first data-driven model to combine the following advantages. It extrapolates at arbitrary spatial and temporal locations; it can learn from sparse irregular grids or manifolds; at test time, it generalizes to new grids or resolutions. DINo outperforms alternative neural PDE forecasters in a variety of challenging generalization scenarios on representative PDE systems.},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Yin, Yuan and Kirchmeyer, Matthieu and Franceschi, Jean-Yves and Rakotomamonjy, Alain and Gallinari, Patrick},
	month = feb,
	year = {2023},
	note = {arXiv:2209.14855 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{park_deepsdf_2019,
	title = {{DeepSDF}: {Learning} {Continuous} {Signed} {Distance} {Functions} for {Shape} {Representation}},
	shorttitle = {{DeepSDF}},
	url = {http://arxiv.org/abs/1901.05103},
	doi = {10.48550/arXiv.1901.05103},
	abstract = {Computer graphics, 3D computer vision and robotics communities have produced multiple approaches to representing 3D geometry for rendering and reconstruction. These provide trade-offs across fidelity, efficiency and compression capabilities. In this work, we introduce DeepSDF, a learned continuous Signed Distance Function (SDF) representation of a class of shapes that enables high quality shape representation, interpolation and completion from partial and noisy 3D input data. DeepSDF, like its classical counterpart, represents a shape's surface by a continuous volumetric field: the magnitude of a point in the field represents the distance to the surface boundary and the sign indicates whether the region is inside (-) or outside (+) of the shape, hence our representation implicitly encodes a shape's boundary as the zero-level-set of the learned function while explicitly representing the classification of space as being part of the shapes interior or not. While classical SDF's both in analytical or discretized voxel form typically represent the surface of a single shape, DeepSDF can represent an entire class of shapes. Furthermore, we show state-of-the-art performance for learned 3D shape representation and completion while reducing the model size by an order of magnitude compared with previous work.},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
	month = jan,
	year = {2019},
	note = {arXiv:1901.05103 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{chen_crom_2023,
	title = {{CROM}: {Continuous} {Reduced}-{Order} {Modeling} of {PDEs} {Using} {Implicit} {Neural} {Representations}},
	shorttitle = {{CROM}},
	url = {http://arxiv.org/abs/2206.02607},
	abstract = {The long runtime of high-fidelity partial differential equation (PDE) solvers makes them unsuitable for time-critical applications. We propose to accelerate PDE solvers using reduced-order modeling (ROM). Whereas prior ROM approaches reduce the dimensionality of discretized vector fields, our continuous reduced-order modeling (CROM) approach builds a low-dimensional embedding of the continuous vector fields themselves, not their discretization. We represent this reduced manifold using continuously differentiable neural fields, which may train on any and all available numerical solutions of the continuous system, even when they are obtained using diverse methods or discretizations. We validate our approach on an extensive range of PDEs with training data from voxel grids, meshes, and point clouds. Compared to prior discretization-dependent ROM methods, such as linear subspace proper orthogonal decomposition (POD) and nonlinear manifold neural-network-based autoencoders, CROM features higher accuracy, lower memory consumption, dynamically adaptive resolutions, and applicability to any discretization. For equal latent space dimension, CROM exhibits 79\${\textbackslash}times\$ and 49\${\textbackslash}times\$ better accuracy, and 39\${\textbackslash}times\$ and 132\${\textbackslash}times\$ smaller memory footprint, than POD and autoencoder methods, respectively. Experiments demonstrate 109\${\textbackslash}times\$ and 89\${\textbackslash}times\$ wall-clock speedups over unreduced models on CPUs and GPUs, respectively. Videos and codes are available on the project page: https://crom-pde.github.io},
	urldate = {2023-05-22},
	publisher = {arXiv},
	author = {Chen, Peter Yichen and Xiang, Jinxu and Cho, Dong Heon and Chang, Yue and Pershing, G. A. and Maia, Henrique Teles and Chiaramonte, Maurizio M. and Carlberg, Kevin and Grinspun, Eitan},
	month = mar,
	year = {2023},
	note = {arXiv:2206.02607 [physics]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Graphics, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@misc{lou_reflected_2023,
	title = {Reflected {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2304.04740},
	abstract = {Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalized score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our method is competitive with or surpasses the state of the art and, for classifier-free guidance, our approach enables fast exact sampling with ODEs and produces more faithful samples under high guidance weight.},
	urldate = {2023-05-18},
	publisher = {arXiv},
	author = {Lou, Aaron and Ermon, Stefano},
	month = apr,
	year = {2023},
	note = {arXiv:2304.04740 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{guastoni_non-intrusive_2023,
	title = {Non-intrusive sensing in turbulent boundary layers via deep fully-convolutional neural networks},
	url = {http://arxiv.org/abs/2208.06024},
	abstract = {Fully-convolutional neural networks (FCN) were proven to be effective for predicting the instantaneous state of a fully-developed turbulent flow at different wall-normal locations using quantities measured at the wall. In Guastoni et al. [J. Fluid Mech. 928, A27 (2021)], we focused on wall-shear-stress distributions as input, which are difficult to measure in experiments. In order to overcome this limitation, we introduce a model that can take as input the heat-flux field at the wall from a passive scalar. Four different Prandtl numbers \$Pr = {\textbackslash}nu/{\textbackslash}alpha = (1,2,4,6)\$ are considered (where \${\textbackslash}nu\$ is the kinematic viscosity and \${\textbackslash}alpha\$ is the thermal diffusivity of the scalar quantity). A turbulent boundary layer is simulated since accurate heat-flux measurements can be performed in experimental settings, paving the way for the implementation of a non-intrusive sensing approach for the flow in practical applications. This is particularly important for closed-loop flow control, which requires an accurate representation of the state of the flow to compute the actuation.},
	urldate = {2023-05-16},
	publisher = {arXiv},
	author = {Guastoni, L. and Balasubramanian, A. G. and Güemes, A. and Ianiro, A. and Discetti, S. and Schlatter, P. and Azizpour, H. and Vinuesa, R.},
	month = mar,
	year = {2023},
	note = {arXiv:2208.06024 [physics]},
	keywords = {Physics - Fluid Dynamics},
}

@misc{bengio_representation_2014,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	shorttitle = {Representation {Learning}},
	url = {http://arxiv.org/abs/1206.5538},
	doi = {10.48550/arXiv.1206.5538},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	urldate = {2023-05-15},
	publisher = {arXiv},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = apr,
	year = {2014},
	note = {arXiv:1206.5538 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{benner_survey_2015,
	title = {A {Survey} of {Projection}-{Based} {Model} {Reduction} {Methods} for {Parametric} {Dynamical} {Systems}},
	volume = {57},
	issn = {0036-1445},
	url = {https://epubs.siam.org/doi/10.1137/130932715},
	doi = {10.1137/130932715},
	abstract = {The optimal H2H2{\textbackslash}mathcal\{H\}\_2 model reduction problem is of great importance in the area of dynamical systems and simulation. In the literature, two independent frameworks have evolved focusing either on solution of Lyapunov equations on the one hand or interpolation of transfer functions on the other, without any apparent connection between the two approaches. In this paper, we develop a new unifying framework for the optimal H2H2{\textbackslash}mathcal\{H\}\_2 approximation problem using best approximation properties in the underlying Hilbert space. This new framework leads to a new set of local optimality conditions taking the form of a structured orthogonality condition. We show that the existing Lyapunov- and interpolation-based conditions are each equivalent to our conditions and so are equivalent to each other. Also, we provide a new elementary proof of the interpolation-based condition that clarifies the importance of the mirror images of the reduced system poles. Based on the interpolation framework, we describe an iteratively corrected rational Krylov algorithm for H2H2{\textbackslash}mathcal\{H\}\_2 model reduction. The formulation is based on finding a reduced order model that satisfies interpolation-based first-order necessary conditions for {\textbackslash}cHtwo{\textbackslash}cHtwo{\textbackslash}cHtwo optimality and results in a method that is numerically effective and suited for large-scale problems. We illustrate the performance of the method with a variety of numerical experiments and comparisons with existing methods.},
	number = {4},
	urldate = {2023-05-15},
	journal = {SIAM Review},
	author = {Benner, Peter and Gugercin, Serkan and Willcox, Karen},
	month = jan,
	year = {2015},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {483--531},
}

@article{greif_decay_2019,
	title = {Decay of the {Kolmogorov} {N}-width for wave problems},
	volume = {96},
	issn = {0893-9659},
	url = {https://www.sciencedirect.com/science/article/pii/S0893965919301983},
	doi = {10.1016/j.aml.2019.05.013},
	abstract = {The Kolmogorov N-width dN(M) describes the rate of the worst-case error (w.r.t. a subset M⊂H of a normed space H) arising from a projection onto the best-possible linear subspace of H of dimension N∈N. Thus, dN(M) sets a limit to any projection-based approximation such as determined by the reduced basis method. While it is known that dN(M) decays exponentially fast for many linear coercive parameterized partial differential equations, i.e., dN(M)=O(e−βN), we show in this note, that only dN(M)=O(N−1∕2) for initial–boundary-value problems of the hyperbolic wave equation with discontinuous initial conditions. This is aligned with the known slow decay of dN(M) for the linear transport problem.},
	language = {en},
	urldate = {2023-05-09},
	journal = {Applied Mathematics Letters},
	author = {Greif, Constantin and Urban, Karsten},
	month = oct,
	year = {2019},
	keywords = {Kolmogorov -width, Wave equation},
	pages = {216--222},
}

@article{rowley_model_2017,
	title = {Model {Reduction} for {Flow} {Analysis} and {Control}},
	volume = {49},
	issn = {0066-4189, 1545-4479},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-010816-060042},
	doi = {10.1146/annurev-fluid-010816-060042},
	abstract = {Advances in experimental techniques and the ever-increasing ﬁdelity of numerical simulations have led to an abundance of data describing ﬂuid ﬂows. This review discusses a range of techniques for analyzing such data, with the aim of extracting simpliﬁed models that capture the essential features of these ﬂows, in order to gain insight into the ﬂow physics, and potentially identify mechanisms for controlling these ﬂows. We review well-developed techniques, such as proper orthogonal decomposition and Galerkin projection, and discuss more recent techniques developed for linear systems, such as balanced truncation and dynamic mode decomposition (DMD). We then discuss some of the methods available for nonlinear systems, with particular attention to the Koopman operator, an inﬁnite-dimensional linear operator that completely characterizes the dynamics of a nonlinear system and provides an extension of DMD to nonlinear systems.},
	language = {en},
	number = {1},
	urldate = {2023-05-05},
	journal = {Annual Review of Fluid Mechanics},
	author = {Rowley, Clarence W. and Dawson, Scott T.M.},
	month = jan,
	year = {2017},
	pages = {387--417},
}

@misc{ohlberger_reduced_2016,
	title = {Reduced {Basis} {Methods}: {Success}, {Limitations} and {Future} {Challenges}},
	shorttitle = {Reduced {Basis} {Methods}},
	url = {http://arxiv.org/abs/1511.02021},
	doi = {10.48550/arXiv.1511.02021},
	abstract = {Parametric model order reduction using reduced basis methods can be an effective tool for obtaining quickly solvable reduced order models of parametrized partial differential equation problems. With speedups that can reach several orders of magnitude, reduced basis methods enable high fidelity real-time simulations of complex systems and dramatically reduce the computational costs in many-query applications. In this contribution we analyze the methodology, mainly focussing on the theoretical aspects of the approach. In particular we discuss what is known about the convergence properties of these methods: when they succeed and when they are bound to fail. Moreover, we highlight some recent approaches employing nonlinear approximation techniques which aim to overcome the current limitations of reduced basis methods.},
	urldate = {2023-05-05},
	publisher = {arXiv},
	author = {Ohlberger, Mario and Rave, Stephan},
	month = jan,
	year = {2016},
	note = {arXiv:1511.02021 [math]},
	keywords = {41A45, 41A46, 41A65, 65M60, 65N30, Mathematics - Numerical Analysis},
}

@misc{chen_crom_2023-1,
	title = {{CROM}: {Continuous} {Reduced}-{Order} {Modeling} of {PDEs} {Using} {Implicit} {Neural} {Representations}},
	shorttitle = {{CROM}},
	url = {http://arxiv.org/abs/2206.02607},
	doi = {10.48550/arXiv.2206.02607},
	abstract = {The long runtime of high-fidelity partial differential equation (PDE) solvers makes them unsuitable for time-critical applications. We propose to accelerate PDE solvers using reduced-order modeling (ROM). Whereas prior ROM approaches reduce the dimensionality of discretized vector fields, our continuous reduced-order modeling (CROM) approach builds a low-dimensional embedding of the continuous vector fields themselves, not their discretization. We represent this reduced manifold using continuously differentiable neural fields, which may train on any and all available numerical solutions of the continuous system, even when they are obtained using diverse methods or discretizations. We validate our approach on an extensive range of PDEs with training data from voxel grids, meshes, and point clouds. Compared to prior discretization-dependent ROM methods, such as linear subspace proper orthogonal decomposition (POD) and nonlinear manifold neural-network-based autoencoders, CROM features higher accuracy, lower memory consumption, dynamically adaptive resolutions, and applicability to any discretization. For equal latent space dimension, CROM exhibits 79\${\textbackslash}times\$ and 49\${\textbackslash}times\$ better accuracy, and 39\${\textbackslash}times\$ and 132\${\textbackslash}times\$ smaller memory footprint, than POD and autoencoder methods, respectively. Experiments demonstrate 109\${\textbackslash}times\$ and 89\${\textbackslash}times\$ wall-clock speedups over unreduced models on CPUs and GPUs, respectively. Videos and codes are available on the project page: https://crom-pde.github.io},
	urldate = {2023-05-05},
	publisher = {arXiv},
	author = {Chen, Peter Yichen and Xiang, Jinxu and Cho, Dong Heon and Chang, Yue and Pershing, G. A. and Maia, Henrique Teles and Chiaramonte, Maurizio M. and Carlberg, Kevin and Grinspun, Eitan},
	month = mar,
	year = {2023},
	note = {arXiv:2206.02607 [physics]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Graphics, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@article{bonev_modelling_2023,
	title = {{MODELLING} {ATMOSPHERIC} {DYNAMICS} {WITH} {SPHERICAL} {FOURIER} {NEURAL} {OPERATORS}},
	abstract = {Fourier Neural Operators (FNOs) have established themselves as an efficient method for learning resolution-independent operators in a wide range of scientific machine learning applications. This can be attributed to their ability to effectively model long-range dependencies in spatio-temporal data through computationally efficient global convolutions. However, the use of discrete Fourier transforms (DFTs) in FNOs leads to spurious artifacts and pronounced dissipation when applied to spherical coordinates, due to the incorrect assumption of flat geometry. To address the issue, we introduce Spherical FNOs (SFNOs), which use the generalized Fourier transform for learning operators on spherical geometries. We demonstrate the effectiveness of the method for forecasting atmospheric dynamics, producing stable auto-regressive results for a simulated time of one year (1,460 steps) while retaining physically plausible dynamics. This development has significant implications for machine learning-based climate dynamics emulation, which could play a crucial role in accelerating our response to climate change.},
	language = {en},
	author = {Bonev, Boris and Kurth, Thorsten and Hundt, Christian and Pathak, Jaideep and Baust, Maximilian and Kashinath, Karthik},
	year = {2023},
}

@article{xiong_controlled_2023,
	title = {Controlled physics-informed data generation for deep learning-based remaining useful life prediction under unseen operation conditions},
	volume = {197},
	issn = {08883270},
	url = {http://arxiv.org/abs/2304.11702},
	doi = {10.1016/j.ymssp.2023.110359},
	abstract = {Limited availability of representative time-to-failure (TTF) trajectories either limits the performance of deep learning (DL)-based approaches on remaining useful life (RUL) prediction in practice or even precludes their application. Generating synthetic data that is physically plausible is a promising way to tackle this challenge. In this study, a novel hybrid framework combining the controlled physics-informed data generation approach with a deep learning-based prediction model for prognostics is proposed. In the proposed framework, a new controlled physics-informed generative adversarial network (CPI-GAN) is developed to generate synthetic degradation trajectories that are physically interpretable and diverse. Five basic physics constraints are proposed as the controllable settings in the generator. A physics-informed loss function with penalty is designed as the regularization term, which ensures that the changing trend of system health state recorded in the synthetic data is consistent with the underlying physical laws. Then, the generated synthetic data is used as input of the DL-based prediction model to obtain the RUL estimations. The proposed framework is evaluated based on new Commercial Modular Aero-Propulsion System Simulation (N-CMAPSS), a turbofan engine prognostics dataset where a limited avail-ability of TTF trajectories is assumed. The experimental results demonstrate that the proposed framework is able to generate synthetic TTF trajectories that are consistent with underlying degradation trends. The generated trajectories enable to significantly improve the accuracy of RUL predictions.},
	urldate = {2023-05-05},
	journal = {Mechanical Systems and Signal Processing},
	author = {Xiong, Jiawei and Fink, Olga and Zhou, Jian and Ma, Yizhong},
	month = aug,
	year = {2023},
	note = {arXiv:2304.11702 [cs]},
	keywords = {Computer Science - Machine Learning},
	pages = {110359},
}

@misc{karras_elucidating_2022,
	title = {Elucidating the {Design} {Space} of {Diffusion}-{Based} {Generative} {Models}},
	url = {http://arxiv.org/abs/2206.00364},
	abstract = {We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.},
	urldate = {2023-05-05},
	publisher = {arXiv},
	author = {Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
	month = oct,
	year = {2022},
	note = {arXiv:2206.00364 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{kingma_variational_2023,
	title = {Variational {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2107.00630},
	doi = {10.48550/arXiv.2107.00630},
	abstract = {Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the variance of the resulting VLB estimator, leading to faster optimization. Combining these advances with architectural improvements, we obtain state-of-the-art likelihoods on image density estimation benchmarks, outperforming autoregressive models that have dominated these benchmarks for many years, with often significantly faster optimization. In addition, we show how to use the model as part of a bits-back compression scheme, and demonstrate lossless compression rates close to the theoretical optimum. Code is available at https://github.com/google-research/vdm .},
	urldate = {2023-04-27},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Salimans, Tim and Poole, Ben and Ho, Jonathan},
	month = apr,
	year = {2023},
	note = {arXiv:2107.00630 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{song_denoising_2022,
	title = {Denoising {Diffusion} {Implicit} {Models}},
	url = {http://arxiv.org/abs/2010.02502},
	doi = {10.48550/arXiv.2010.02502},
	abstract = {Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that DDIMs can produce high quality samples \$10 {\textbackslash}times\$ to \$50 {\textbackslash}times\$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	month = oct,
	year = {2022},
	note = {arXiv:2010.02502 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{meng_sdedit_2022,
	title = {{SDEdit}: {Guided} {Image} {Synthesis} and {Editing} with {Stochastic} {Differential} {Equations}},
	shorttitle = {{SDEdit}},
	url = {http://arxiv.org/abs/2108.01073},
	doi = {10.48550/arXiv.2108.01073},
	abstract = {Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user input (e.g., hand-drawn colored strokes) and realism of the synthesized image. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide of any type, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit significantly outperforms state-of-the-art GAN-based methods by up to 98.09\% on realism and 91.72\% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
	month = jan,
	year = {2022},
	note = {arXiv:2108.01073 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{varley_information_2023,
	title = {Information {Theory} for {Complex} {Systems} {Scientists}},
	url = {http://arxiv.org/abs/2304.12482},
	doi = {10.48550/arXiv.2304.12482},
	abstract = {In the 21st century, many of the crucial scientific and technical issues facing humanity can be understood as problems associated with understanding, modelling, and ultimately controlling complex systems: systems comprised of a large number of non-trivially interacting components whose collective behaviour can be difficult to predict. Information theory, a branch of mathematics historically associated with questions about encoding and decoding messages, has emerged as something of a lingua franca for those studying complex systems, far exceeding its original narrow domain of communication systems engineering. In the context of complexity science, information theory provides a set of tools which allow researchers to uncover the statistical and effective dependencies between interacting components; relationships between systems and their environment; mereological whole-part relationships; and is sensitive to non-linearities missed by commonly parametric statistical models. In this review, we aim to provide an accessible introduction to the core of modern information theory, aimed specifically at aspiring (and established) complex systems scientists. This includes standard measures, such as Shannon entropy, relative entropy, and mutual information, before building to more advanced topics, including: information dynamics, measures of statistical complexity, information decomposition, and effective network inference. In addition to detailing the formal definitions, in this review we make an effort to discuss how information theory can be interpreted and develop the intuition behind abstract concepts like "entropy," in the hope that this will enable interested readings to understand what information is, and how it is used, at a more fundamental level.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Varley, Thomas F.},
	month = apr,
	year = {2023},
	note = {arXiv:2304.12482 [physics, q-bio, stat]},
	keywords = {Computer Science - Information Theory, Physics - Data Analysis, Statistics and Probability, Quantitative Biology - Quantitative Methods, Statistics - Other Statistics},
}

@misc{balestriero_cookbook_2023,
	title = {A {Cookbook} of {Self}-{Supervised} {Learning}},
	url = {http://arxiv.org/abs/2304.12210},
	doi = {10.48550/arXiv.2304.12210},
	abstract = {Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Balestriero, Randall and Ibrahim, Mark and Sobal, Vlad and Morcos, Ari and Shekhar, Shashank and Goldstein, Tom and Bordes, Florian and Bardes, Adrien and Mialon, Gregoire and Tian, Yuandong and Schwarzschild, Avi and Wilson, Andrew Gordon and Geiping, Jonas and Garrido, Quentin and Fernandez, Pierre and Bar, Amir and Pirsiavash, Hamed and LeCun, Yann and Goldblum, Micah},
	month = apr,
	year = {2023},
	note = {arXiv:2304.12210 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{chattopadhyay_long-term_2023,
	title = {Long-term stability and generalization of observationally-constrained stochastic data-driven models for geophysical turbulence},
	volume = {2},
	issn = {2634-4602},
	url = {https://www.cambridge.org/core/journals/environmental-data-science/article/longterm-stability-and-generalization-of-observationallyconstrained-stochastic-datadriven-models-for-geophysical-turbulence/ABEA9E61B94E06B009A530A7895829D6},
	doi = {10.1017/eds.2022.30},
	abstract = {Recent years have seen a surge in interest in building deep learning-based fully data-driven models for weather prediction. Such deep learning models, if trained on observations can mitigate certain biases in current state-of-the-art weather models, some of which stem from inaccurate representation of subgrid-scale processes. However, these data-driven models, being over-parameterized, require a lot of training data which may not be available from reanalysis (observational data) products. Moreover, an accurate, noise-free, initial condition to start forecasting with a data-driven weather model is not available in realistic scenarios. Finally, deterministic data-driven forecasting models suffer from issues with long-term stability and unphysical climate drift, which makes these data-driven models unsuitable for computing climate statistics. Given these challenges, previous studies have tried to pre-train deep learning-based weather forecasting models on a large amount of imperfect long-term climate model simulations and then re-train them on available observational data. In this article, we propose a convolutional variational autoencoder (VAE)-based stochastic data-driven model that is pre-trained on an imperfect climate model simulation from a two-layer quasi-geostrophic flow and re-trained, using transfer learning, on a small number of noisy observations from a perfect simulation. This re-trained model then performs stochastic forecasting with a noisy initial condition sampled from the perfect simulation. We show that our ensemble-based stochastic data-driven model outperforms a baseline deterministic encoder–decoder-based convolutional model in terms of short-term skills, while remaining stable for long-term climate simulations yielding accurate climatology.},
	language = {en},
	urldate = {2023-04-18},
	journal = {Environmental Data Science},
	author = {Chattopadhyay, Ashesh and Pathak, Jaideep and Nabizadeh, Ebrahim and Bhimji, Wahid and Hassanzadeh, Pedram},
	year = {2023},
	note = {Publisher: Cambridge University Press},
	keywords = {Data-driven climate model, long-term stability, transfer learning, variational autoencoder},
	pages = {e1},
}

@book{temam_infinite-dimensional_1997,
	address = {New York, NY},
	series = {Applied {Mathematical} {Sciences}},
	title = {Infinite-{Dimensional} {Dynamical} {Systems} in {Mechanics} and {Physics}},
	volume = {68},
	isbn = {978-1-4612-6853-6 978-1-4612-0645-3},
	url = {http://link.springer.com/10.1007/978-1-4612-0645-3},
	urldate = {2023-04-18},
	publisher = {Springer},
	author = {Temam, Roger},
	editor = {Marsden, J. E. and Sirovich, L. and John, F.},
	year = {1997},
	doi = {10.1007/978-1-4612-0645-3},
	keywords = {Degrees of freedom, differential equation, fluid mechanics, functional analysis, mechanics, partial differential equation, wave equation},
}

@article{alexander_operator-theoretic_2020,
	title = {Operator-theoretic framework for forecasting nonlinear time series with kernel analog techniques},
	volume = {409},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S016727891930377X},
	doi = {10.1016/j.physd.2020.132520},
	abstract = {Kernel analog forecasting (KAF), alternatively known as kernel principal component regression, is a kernel method used for nonparametric statistical forecasting of dynamically generated time series data. This paper synthesizes descriptions of kernel methods and Koopman operator theory in order to provide a single consistent account of KAF. The framework presented here illuminates the property of the KAF method that, under measure-preserving and ergodic dynamics, it consistently approximates the conditional expectation of observables that are acted upon by the Koopman operator of the dynamical system and are conditioned on the observed data at forecast initialization. More precisely, KAF yields optimal predictions, in the sense of minimal root mean square error with respect to the invariant measure, in the asymptotic limit of large data. The presented framework facilitates, moreover, the analysis of generalization error and quantification of uncertainty. Extensions of KAF to the construction of conditional variance and conditional probability functions, as well as to non-symmetric kernels, are also shown. Illustrations of various aspects of KAF are provided with applications to simple examples, namely a periodic flow on the circle and the chaotic Lorenz 63 system.},
	language = {en},
	urldate = {2023-04-18},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Alexander, Romeo and Giannakis, Dimitrios},
	month = aug,
	year = {2020},
	keywords = {Conditional expectation, Kernel methods, Koopman operators, Statistical forecasting},
	pages = {132520},
}

@article{dellnitz_approximation_1999,
	title = {On the {Approximation} of {Complicated} {Dynamical} {Behavior}},
	volume = {36},
	issn = {0036-1429},
	url = {https://epubs.siam.org/doi/10.1137/S0036142996313002},
	doi = {10.1137/S0036142996313002},
	abstract = {The Multiplicative Ergodic theorem, which gives information about the dynamical structure of a cocycle ΦΦ{\textbackslash}Phi , or a linear skew product flow ππ{\textbackslash}pi , over a suitable base space MM\{{\textbackslash}bf M\}, asserts that for every invariant probability measure μμ{\textbackslash}mu  on MM\{{\textbackslash}bf M\} there is a measurable decomposition of the vector bundle over MM\{{\textbackslash}bf M\} into invariant measurable subbundles, and that every solution with initial conditions in any of these subbundles has strong Lyapunov exponents. These exponents depend on the measure μμ{\textbackslash}mu , and when μμ{\textbackslash}mu  is ergodic, they are constant (almost everywhere) on MM\{{\textbackslash}bf M\} and form a finite set mess Σ(μ)Σ(μ){\textbackslash}Sigma ({\textbackslash}mu ). The dynamical spectrum dyn ΣΣ{\textbackslash}Sigma  consists of those values λ∈Rλ∈R{\textbackslash}lambda  {\textbackslash}in \{{\textbackslash}bf R\} for which the shifted flow πλπλ{\textbackslash}pi \_{\textbackslash}lambda   fails to have an exponential dichotomy over MM\{{\textbackslash}bf M\}. The Spectral theorem for linear skew product flows states that when MM\{{\textbackslash}bf M\} is compact and dynamically connected then dyn ΣΣ{\textbackslash}Sigma  is the finite union of k disjoint compact intervals and the vector bundle over MM\{{\textbackslash}bf M\} is the sum of k continuous invariant subbundles. We show that Boundary dyn Σ⊆∪μ meas Σ(μ)⊆ dyn ΣBoundary dyn Σ⊆∪μ⁡ meas Σ(μ)⊆ dyn Σ \{{\textbackslash}text\{Boundary dyn \}\}{\textbackslash}Sigma  {\textbackslash}subseteq {\textbackslash}mathop  {\textbackslash}cup {\textbackslash}limits\_{\textbackslash}mu  \{{\textbackslash}text\{ meas \}\}{\textbackslash}Sigma ({\textbackslash}mu ) {\textbackslash}subseteq \{{\textbackslash}text\{ dyn \}\}{\textbackslash}Sigma  where the union above is over all ergodic measures μμ{\textbackslash}mu  on MM\{{\textbackslash}bf M\}. Also we show that the measurable invariant subbundles which arise in the Multiplicative Ergodic theorem form a refinement of the continuous invariant subbundles described in the Spectral theorem. A new proof of the Multiplicative Ergodic theorem is presented here. This proof is a substantial simplification over other arguments. Applications of the theory of Lyapunov exponents to “spiral” systems, products of “random” matrices, stochastic differential equations, and the almost periodic Schrödinger operator are included.},
	number = {2},
	urldate = {2023-04-18},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Dellnitz, Michael and Junge, Oliver},
	month = jan,
	year = {1999},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {491--515},
}

@article{humphries_runge-kutta_1994,
	title = {Runge-{Kutta} methods for dissipative and gradient dynamical systems},
	volume = {31},
	issn = {0036-1429},
	url = {https://doi.org/10.1137/0731075},
	doi = {10.1137/0731075},
	number = {5},
	urldate = {2023-04-18},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Humphries, A. R. and Stuart, A. M.},
	month = oct,
	year = {1994},
	keywords = {Runge-Kutta methods, attractors, dissipativity, dynamical systems, gradient systems},
	pages = {1452--1485},
}

@misc{wang_respecting_2022,
	title = {Respecting causality is all you need for training physics-informed neural networks},
	url = {http://arxiv.org/abs/2203.07404},
	doi = {10.48550/arXiv.2203.07404},
	abstract = {While the popularity of physics-informed neural networks (PINNs) is steadily rising, to this date PINNs have not been successful in simulating dynamical systems whose solution exhibits multi-scale, chaotic or turbulent behavior. In this work we attribute this shortcoming to the inability of existing PINNs formulations to respect the spatio-temporal causal structure that is inherent to the evolution of physical systems. We argue that this is a fundamental limitation and a key source of error that can ultimately steer PINN models to converge towards erroneous solutions. We address this pathology by proposing a simple re-formulation of PINNs loss functions that can explicitly account for physical causality during model training. We demonstrate that this simple modification alone is enough to introduce significant accuracy improvements, as well as a practical quantitative mechanism for assessing the convergence of a PINNs model. We provide state-of-the-art numerical results across a series of benchmarks for which existing PINNs formulations fail, including the chaotic Lorenz system, the Kuramoto-Sivashinsky equation in the chaotic regime, and the Navier-Stokes equations in the turbulent regime. To the best of our knowledge, this is the first time that PINNs have been successful in simulating such systems, introducing new opportunities for their applicability to problems of industrial complexity.},
	urldate = {2023-04-18},
	publisher = {arXiv},
	author = {Wang, Sifan and Sankaran, Shyam and Perdikaris, Paris},
	month = mar,
	year = {2022},
	note = {arXiv:2203.07404 [nlin, physics:physics, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Nonlinear Sciences - Chaotic Dynamics, Physics - Fluid Dynamics, Statistics - Machine Learning},
}

@article{shu_physics-informed_2023,
	title = {A physics-informed diffusion model for high-fidelity flow field reconstruction},
	volume = {478},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999123000670},
	doi = {10.1016/j.jcp.2023.111972},
	abstract = {Machine learning models are gaining increasing popularity in the domain of fluid dynamics for their potential to accelerate the production of high-fidelity computational fluid dynamics data. However, many recently proposed machine learning models for high-fidelity data reconstruction require low-fidelity data for model training. Such requirement restrains the application performance of these models, since their data reconstruction accuracy would drop significantly if the low-fidelity input data used in model test has a large deviation from the training data. To overcome this restraint, we propose a diffusion model which only uses high-fidelity data at training. With different configurations, our model is able to reconstruct high-fidelity data from either a regular low-fidelity sample or a randomly measured sample, and is also able to gain an accuracy increase by using physics-informed conditioning information from a known partial differential equation when that is available. Experimental results demonstrate that our model can produce accurate reconstruction results for 2d turbulent flows based on different input sources without retraining.},
	language = {en},
	urldate = {2023-04-14},
	journal = {Journal of Computational Physics},
	author = {Shu, Dule and Li, Zijie and Barati Farimani, Amir},
	month = apr,
	year = {2023},
	keywords = {Computational fluid dynamics, Denoising diffusion probabilistic models, Super-resolution},
	pages = {111972},
}

@misc{maust_fourier_2022,
	title = {Fourier {Continuation} for {Exact} {Derivative} {Computation} in {Physics}-{Informed} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2211.15960},
	abstract = {The physics-informed neural operator (PINO) is a machine learning architecture that has shown promising empirical results for learning partial differential equations. PINO uses the Fourier neural operator (FNO) architecture to overcome the optimization challenges often faced by physics-informed neural networks. Since the convolution operator in PINO uses the Fourier series representation, its gradient can be computed exactly on the Fourier space. While Fourier series cannot represent nonperiodic functions, PINO and FNO still have the expressivity to learn nonperiodic problems with Fourier extension via padding. However, computing the Fourier extension in the physics-informed optimization requires solving an ill-conditioned system, resulting in inaccurate derivatives which prevent effective optimization. In this work, we present an architecture that leverages Fourier continuation (FC) to apply the exact gradient method to PINO for nonperiodic problems. This paper investigates three different ways that FC can be incorporated into PINO by testing their performance on a 1D blowup problem. Experiments show that FC-PINO outperforms padded PINO, improving equation loss by several orders of magnitude, and it can accurately capture the third order derivatives of nonsmooth solution functions.},
	urldate = {2023-04-13},
	publisher = {arXiv},
	author = {Maust, Haydn and Li, Zongyi and Wang, Yixuan and Leibovici, Daniel and Bruno, Oscar and Hou, Thomas and Anandkumar, Anima},
	month = nov,
	year = {2022},
	note = {arXiv:2211.15960 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{li_learning_2022,
	title = {Learning {Dissipative} {Dynamics} in {Chaotic} {Systems}},
	url = {http://arxiv.org/abs/2106.06898},
	abstract = {Chaotic systems are notoriously challenging to predict because of their sensitivity to perturbations and errors due to time stepping. Despite this unpredictable behavior, for many dissipative systems the statistics of the long term trajectories are governed by an invariant measure supported on a set, known as the global attractor; for many problems this set is finite dimensional, even if the state space is infinite dimensional. For Markovian systems, the statistical properties of long-term trajectories are uniquely determined by the solution operator that maps the evolution of the system over arbitrary positive time increments. In this work, we propose a machine learning framework to learn the underlying solution operator for dissipative chaotic systems, showing that the resulting learned operator accurately captures short-time trajectories and long-time statistical behavior. Using this framework, we are able to predict various statistics of the invariant measure for the turbulent Kolmogorov Flow dynamics with Reynolds numbers up to 5000.},
	urldate = {2023-04-13},
	publisher = {arXiv},
	author = {Li, Zongyi and Liu-Schiaffini, Miguel and Kovachki, Nikola and Liu, Burigede and Azizzadenesheli, Kamyar and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = sep,
	year = {2022},
	note = {arXiv:2106.06898 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems},
}

@misc{wang_respecting_2022-1,
	title = {Respecting causality is all you need for training physics-informed neural networks},
	url = {http://arxiv.org/abs/2203.07404},
	abstract = {While the popularity of physics-informed neural networks (PINNs) is steadily rising, to this date PINNs have not been successful in simulating dynamical systems whose solution exhibits multi-scale, chaotic or turbulent behavior. In this work we attribute this shortcoming to the inability of existing PINNs formulations to respect the spatio-temporal causal structure that is inherent to the evolution of physical systems. We argue that this is a fundamental limitation and a key source of error that can ultimately steer PINN models to converge towards erroneous solutions. We address this pathology by proposing a simple re-formulation of PINNs loss functions that can explicitly account for physical causality during model training. We demonstrate that this simple modification alone is enough to introduce significant accuracy improvements, as well as a practical quantitative mechanism for assessing the convergence of a PINNs model. We provide state-of-the-art numerical results across a series of benchmarks for which existing PINNs formulations fail, including the chaotic Lorenz system, the Kuramoto-Sivashinsky equation in the chaotic regime, and the Navier-Stokes equations in the turbulent regime. To the best of our knowledge, this is the first time that PINNs have been successful in simulating such systems, introducing new opportunities for their applicability to problems of industrial complexity.},
	urldate = {2023-04-13},
	publisher = {arXiv},
	author = {Wang, Sifan and Sankaran, Shyam and Perdikaris, Paris},
	month = mar,
	year = {2022},
	note = {arXiv:2203.07404 [nlin, physics:physics, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Nonlinear Sciences - Chaotic Dynamics, Physics - Fluid Dynamics, Statistics - Machine Learning},
}

@misc{pfaff_learning_2021,
	title = {Learning {Mesh}-{Based} {Simulation} with {Graph} {Networks}},
	url = {http://arxiv.org/abs/2010.03409},
	doi = {10.48550/arXiv.2010.03409},
	abstract = {Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.},
	urldate = {2023-04-13},
	publisher = {arXiv},
	author = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter W.},
	month = jun,
	year = {2021},
	note = {arXiv:2010.03409 [cs]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@misc{solera-rico_beta-variational_2023,
	title = {\${\textbackslash}beta\$-{Variational} autoencoders and transformers for reduced-order modelling of fluid flows},
	url = {http://arxiv.org/abs/2304.03571},
	abstract = {Variational autoencoder (VAE) architectures have the potential to develop reduced-order models (ROMs) for chaotic fluid flows. We propose a method for learning compact and near-orthogonal ROMs using a combination of a \${\textbackslash}beta\$-VAE and a transformer, tested on numerical data from a two-dimensional viscous flow in both periodic and chaotic regimes. The \${\textbackslash}beta\$-VAE is trained to learn a compact latent representation of the flow velocity, and the transformer is trained to predict the temporal dynamics in latent space. Using the \${\textbackslash}beta\$-VAE to learn disentangled representations in latent-space, we obtain a more interpretable flow model with features that resemble those observed in the proper orthogonal decomposition, but with a more efficient representation. Using Poincar{\textbackslash}'e maps, the results show that our method can capture the underlying dynamics of the flow outperforming other prediction models. The proposed method has potential applications in other fields such as weather forecasting, structural dynamics or biomedical engineering.},
	urldate = {2023-04-13},
	publisher = {arXiv},
	author = {Solera-Rico, Alberto and Vila, Carlos Sanmiguel and Gómez, M. A. and Wang, Yuning and Almashjary, Abdulrahman and Dawson, Scott T. M. and Vinuesa, Ricardo},
	month = apr,
	year = {2023},
	note = {arXiv:2304.03571 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@misc{wiewel_latent_2020,
	title = {Latent {Space} {Subdivision}: {Stable} and {Controllable} {Time} {Predictions} for {Fluid} {Flow}},
	shorttitle = {Latent {Space} {Subdivision}},
	url = {http://arxiv.org/abs/2003.08723},
	doi = {10.48550/arXiv.2003.08723},
	abstract = {We propose an end-to-end trained neural networkarchitecture to robustly predict the complex dynamics of fluid flows with high temporal stability. We focus on single-phase smoke simulations in 2D and 3D based on the incompressible Navier-Stokes (NS) equations, which are relevant for a wide range of practical problems. To achieve stable predictions for long-term flow sequences, a convolutional neural network (CNN) is trained for spatial compression in combination with a temporal prediction network that consists of stacked Long Short-Term Memory (LSTM) layers. Our core contribution is a novel latent space subdivision (LSS) to separate the respective input quantities into individual parts of the encoded latent space domain. This allows to distinctively alter the encoded quantities without interfering with the remaining latent space values and hence maximizes external control. By selectively overwriting parts of the predicted latent space points, our proposed method is capable to robustly predict long-term sequences of complex physics problems. In addition, we highlight the benefits of a recurrent training on the latent space creation, which is performed by the spatial compression network.},
	urldate = {2023-04-12},
	publisher = {arXiv},
	author = {Wiewel, Steffen and Kim, Byungsoo and Azevedo, Vinicius C. and Solenthaler, Barbara and Thuerey, Nils},
	month = mar,
	year = {2020},
	note = {arXiv:2003.08723 [cs, stat]},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{simonyan_very_2015-1,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2023-04-07},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{es_hyperparameter_2022,
	title = {Hyperparameter {Tuning} in {Python}: a {Complete} {Guide}},
	shorttitle = {Hyperparameter {Tuning} in {Python}},
	url = {https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide},
	abstract = {Choosing the correct hyperparameters for machine learning or deep learning models is one of the best ways to extract the last juice out of your models. In this article, I will show you some of the best ways to do hyperparameter tuning that are available today. What is the difference between parameter and hyperparameter? First,…},
	language = {en-US},
	urldate = {2023-04-05},
	journal = {neptune.ai},
	author = {ES, Shahul},
	month = jul,
	year = {2022},
}

@misc{weerts_importance_2020,
	title = {Importance of {Tuning} {Hyperparameters} of {Machine} {Learning} {Algorithms}},
	url = {http://arxiv.org/abs/2007.07588},
	abstract = {The performance of many machine learning algorithms depends on their hyperparameter settings. The goal of this study is to determine whether it is important to tune a hyperparameter or whether it can be safely set to a default value. We present a methodology to determine the importance of tuning a hyperparameter based on a non-inferiority test and tuning risk: the performance loss that is incurred when a hyperparameter is not tuned, but set to a default value. Because our methods require the notion of a default parameter, we present a simple procedure that can be used to determine reasonable default parameters. We apply our methods in a benchmark study using 59 datasets from OpenML. Our results show that leaving particular hyperparameters at their default value is non-inferior to tuning these hyperparameters. In some cases, leaving the hyperparameter at its default value even outperforms tuning it using a search procedure with a limited number of iterations.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Weerts, Hilde J. P. and Mueller, Andreas C. and Vanschoren, Joaquin},
	month = jul,
	year = {2020},
	note = {arXiv:2007.07588 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{wu_group_2018,
	title = {Group {Normalization}},
	url = {http://arxiv.org/abs/1803.08494},
	abstract = {Batch Normalization (BN) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- BN's error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits BN's usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization (GN) as a simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization. GN's computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6\% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN-based counterparts for object detection and segmentation in COCO, and for video classification in Kinetics, showing that GN can effectively replace the powerful BN in a variety of tasks. GN can be easily implemented by a few lines of code in modern libraries.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Wu, Yuxin and He, Kaiming},
	month = jun,
	year = {2018},
	note = {arXiv:1803.08494 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{ba_layer_2016,
	title = {Layer {Normalization}},
	url = {http://arxiv.org/abs/1607.06450},
	abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	month = jul,
	year = {2016},
	note = {arXiv:1607.06450 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv:1502.03167 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{liu_variance_2021,
	title = {On the {Variance} of the {Adaptive} {Learning} {Rate} and {Beyond}},
	url = {http://arxiv.org/abs/1908.03265},
	abstract = {The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Here, we study its mechanism in details. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate (i.e., it has problematically large variance in the early stage), suggest warmup works as a variance reduction technique, and provide both empirical and theoretical evidence to verify our hypothesis. We further propose RAdam, a new variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Extensive experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the effectiveness and robustness of our proposed method. All implementations are available at: https://github.com/LiyuanLucasLiu/RAdam.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},
	month = oct,
	year = {2021},
	note = {arXiv:1908.03265 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{zhuang_adabelief_2020,
	title = {{AdaBelief} {Optimizer}: {Adapting} {Stepsizes} by the {Belief} in {Observed} {Gradients}},
	shorttitle = {{AdaBelief} {Optimizer}},
	url = {http://arxiv.org/abs/2010.07468},
	abstract = {Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient descent (SGD) with momentum). For many models such as convolutional neural networks (CNNs), adaptive methods typically converge faster but generalize worse compared to SGD; for complex settings such as generative adversarial networks (GANs), adaptive methods are typically the default because of their stability.We propose AdaBelief to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the "belief" in the current gradient direction. Viewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step. We validate AdaBelief in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on ImageNet, AdaBelief achieves comparable accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer. Code is available at https://github.com/juntang-zhuang/Adabelief-Optimizer},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Zhuang, Juntang and Tang, Tommy and Ding, Yifan and Tatikonda, Sekhar and Dvornek, Nicha and Papademetris, Xenophon and Duncan, James S.},
	month = dec,
	year = {2020},
	note = {arXiv:2010.07468 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{zeiler_adadelta_2012,
	title = {{ADADELTA}: {An} {Adaptive} {Learning} {Rate} {Method}},
	shorttitle = {{ADADELTA}},
	url = {http://arxiv.org/abs/1212.5701},
	abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Zeiler, Matthew D.},
	month = dec,
	year = {2012},
	note = {arXiv:1212.5701 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{liu_variance_2021,
	title = {On the {Variance} of the {Adaptive} {Learning} {Rate} and {Beyond}},
	url = {http://arxiv.org/abs/1908.03265},
	doi = {10.48550/arXiv.1908.03265},
	abstract = {The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Here, we study its mechanism in details. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate (i.e., it has problematically large variance in the early stage), suggest warmup works as a variance reduction technique, and provide both empirical and theoretical evidence to verify our hypothesis. We further propose RAdam, a new variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Extensive experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the effectiveness and robustness of our proposed method. All implementations are available at: https://github.com/LiyuanLucasLiu/RAdam.},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},
	month = oct,
	year = {2021},
	note = {arXiv:1908.03265 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{zhuang_adabelief_2020-1,
	title = {{AdaBelief} {Optimizer}: {Adapting} {Stepsizes} by the {Belief} in {Observed} {Gradients}},
	shorttitle = {{AdaBelief} {Optimizer}},
	url = {http://arxiv.org/abs/2010.07468},
	doi = {10.48550/arXiv.2010.07468},
	abstract = {Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient descent (SGD) with momentum). For many models such as convolutional neural networks (CNNs), adaptive methods typically converge faster but generalize worse compared to SGD; for complex settings such as generative adversarial networks (GANs), adaptive methods are typically the default because of their stability.We propose AdaBelief to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the "belief" in the current gradient direction. Viewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step. We validate AdaBelief in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on ImageNet, AdaBelief achieves comparable accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer. Code is available at https://github.com/juntang-zhuang/Adabelief-Optimizer},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Zhuang, Juntang and Tang, Tommy and Ding, Yifan and Tatikonda, Sekhar and Dvornek, Nicha and Papademetris, Xenophon and Duncan, James S.},
	month = dec,
	year = {2020},
	note = {arXiv:2010.07468 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{zeiler_adadelta_2012-1,
	title = {{ADADELTA}: {An} {Adaptive} {Learning} {Rate} {Method}},
	shorttitle = {{ADADELTA}},
	url = {http://arxiv.org/abs/1212.5701},
	doi = {10.48550/arXiv.1212.5701},
	abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Zeiler, Matthew D.},
	month = dec,
	year = {2012},
	note = {arXiv:1212.5701 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{nesterov_method_1986,
	title = {A method of solving a convex programming problem with convergence rate mathcal \{{O}\}(1/kˆ \{2\})},
	volume = {27},
	booktitle = {Sov. {Math}. {Dokl}},
	author = {Nesterov, Y.},
	year = {1986},
}

@article{noauthor_method_nodate,
	title = {A method of solving a convex programming problem with convergence rate mathcal \${\textbackslash}\{\${O}\${\textbackslash}\}\$(1/kˆ \${\textbackslash}\{\$2\${\textbackslash}\}\$)},
}

@inproceedings{sutskever_importance_2013,
	title = {On the importance of initialization and momentum in deep learning},
	url = {https://proceedings.mlr.press/v28/sutskever13.html},
	abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.     Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
	month = may,
	year = {2013},
	note = {ISSN: 1938-7228},
	pages = {1139--1147},
}

@article{polyak_methods_1964,
	title = {Some methods of speeding up the convergence of iteration methods},
	volume = {4},
	issn = {0041-5553},
	url = {https://www.sciencedirect.com/science/article/pii/0041555364901375},
	doi = {10.1016/0041-5553(64)90137-5},
	abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, …, xn, …, which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ⩽ t ⩽ ∞ is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t → ∞ (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, …, xn−k+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0.},
	language = {en},
	number = {5},
	urldate = {2023-03-28},
	journal = {USSR Computational Mathematics and Mathematical Physics},
	author = {Polyak, B. T.},
	month = jan,
	year = {1964},
	pages = {1--17},
}

@article{pinkus_approximation_1999,
	title = {Approximation theory of the {MLP} model in neural networks},
	volume = {8},
	issn = {1474-0508, 0962-4929},
	url = {https://www.cambridge.org/core/journals/acta-numerica/article/approximation-theory-of-the-mlp-model-in-neural-networks/18072C558C8410C4F92A82BCC8FC8CF9},
	doi = {10.1017/S0962492900002919},
	abstract = {In this survey we discuss various approximation-theoretic problems that arise in the multilayer feedforward perceptron (MLP) model in neural networks. The MLP model is one of the more popular and practical of the many neural network models. Mathematically it is also one of the simpler models. Nonetheless the mathematics of this model is not well understood, and many of these problems are approximation-theoretic in character. Most of the research we will discuss is of very recent vintage. We will report on what has been done and on various unanswered questions. We will not be presenting practical (algorithmic) methods. We will, however, be exploring the capabilities and limitations of this model.},
	language = {en},
	urldate = {2023-03-27},
	journal = {Acta Numerica},
	author = {Pinkus, Allan},
	month = jan,
	year = {1999},
	note = {Publisher: Cambridge University Press},
	pages = {143--195},
}

@misc{hendrycks_gaussian_2020,
	title = {Gaussian {Error} {Linear} {Units} ({GELUs})},
	url = {http://arxiv.org/abs/1606.08415},
	abstract = {We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is \$x{\textbackslash}Phi(x)\$, where \${\textbackslash}Phi(x)\$ the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs (\$x{\textbackslash}mathbf\{1\}\_\{x{\textgreater}0\}\$). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.},
	urldate = {2023-03-27},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	month = jul,
	year = {2020},
	note = {arXiv:1606.08415 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	copyright = {1986 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	language = {en},
	number = {6088},
	urldate = {2023-03-27},
	journal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	month = oct,
	year = {1986},
	note = {Number: 6088
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {533--536},
}

@book{minsky_perceptrons_2017,
	title = {Perceptrons: {An} {Introduction} to {Computational} {Geometry}},
	shorttitle = {Perceptrons},
	url = {https://direct.mit.edu/books/book/3132/PerceptronsAn-Introduction-to-Computational},
	abstract = {The first systematic study of parallelism in computation by two pioneers in the field.Reissue of the 1988 Expanded Edition with a new foreword by Léon BottouIn},
	language = {en},
	urldate = {2023-03-27},
	author = {Minsky, Marvin and Papert, Seymour A.},
	month = sep,
	year = {2017},
	doi = {10.7551/mitpress/11301.001.0001},
}

@article{sohil_introduction_2022,
	title = {An introduction to statistical learning with applications in {R}: by {Gareth} {James}, {Daniela} {Witten}, {Trevor} {Hastie}, and {Robert} {Tibshirani}, {New} {York}, {Springer} {Science} and {Business} {Media}, 2013, \$41.98, {eISBN}: 978-1-4614-7137-7},
	volume = {6},
	issn = {2475-4269, 2475-4277},
	shorttitle = {An introduction to statistical learning with applications in {R}},
	url = {https://www.tandfonline.com/doi/full/10.1080/24754269.2021.1980261},
	doi = {10.1080/24754269.2021.1980261},
	language = {en},
	number = {1},
	urldate = {2023-03-24},
	journal = {Statistical Theory and Related Fields},
	author = {Sohil, Fariha and Sohali, Muhammad Umair and Shabbir, Javid},
	month = jan,
	year = {2022},
	pages = {87--87},
}

@incollection{bousquet_introduction_2004,
	address = {Berlin, Heidelberg},
	title = {Introduction to {Statistical} {Learning} {Theory}},
	volume = {3176},
	isbn = {978-3-540-23122-6 978-3-540-28650-9},
	url = {http://link.springer.com/10.1007/978-3-540-28650-9_8},
	abstract = {The goal of statistical learning theory is to study, in a statistical framework, the properties of learning algorithms. In particular, most results take the form of so-called error bounds. This tutorial introduces the techniques that are used to obtain such results.},
	language = {en},
	urldate = {2023-03-24},
	booktitle = {Advanced {Lectures} on {Machine} {Learning}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bousquet, Olivier and Boucheron, Stéphane and Lugosi, Gábor},
	editor = {Bousquet, Olivier and von Luxburg, Ulrike and Rätsch, Gunnar},
	year = {2004},
	doi = {10.1007/978-3-540-28650-9_8},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {169--207},
}

@book{mitchell_machine_1997,
	address = {New York},
	series = {{McGraw}-{Hill} series in computer science},
	title = {Machine {Learning}},
	isbn = {978-0-07-042807-2},
	language = {en},
	publisher = {McGraw-Hill},
	author = {Mitchell, Tom M.},
	year = {1997},
	keywords = {Computer algorithms, Machine learning},
}

@article{cayton_algorithms_2015,
	title = {Algorithms for manifold learning},
	abstract = {Manifold learning is a popular recent approach to nonlinear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artiﬁcially high; though each data point consists of perhaps thousands of features, it may be described as a function of only a few underlying parameters. That is, the data points are actually samples from a low-dimensional manifold that is embedded in a high-dimensional space. Manifold learning algorithms attempt to uncover these parameters in order to ﬁnd a low-dimensional representation of the data. In this paper, we discuss the motivation, background, and algorithms proposed for manifold learning. Isomap, Locally Linear Embedding, Laplacian Eigenmaps, Semideﬁnite Embedding, and a host of variants of these algorithms are examined.},
	language = {en},
	author = {Cayton, Lawrence},
	year = {2015},
}

@article{linot_stabilized_2023,
	title = {Stabilized neural ordinary differential equations for long-time forecasting of dynamical systems},
	volume = {474},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999122009019},
	doi = {10.1016/j.jcp.2022.111838},
	abstract = {In data-driven modeling of spatiotemporal phenomena careful consideration is needed in capturing the dynamics of the high wavenumbers. This problem becomes especially challenging when the system of interest exhibits shocks or chaotic dynamics. We present a data-driven modeling method that accurately captures shocks and chaotic dynamics by proposing a new architecture, stabilized neural ordinary differential equation (ODE). In our proposed architecture, we learn the right-hand-side (RHS) of an ODE by adding the outputs of two NN together where one learns a linear term and the other a nonlinear term. Specifically, we implement this by training a sparse linear convolutional NN to learn the linear term and a dense fully-connected nonlinear NN to learn the nonlinear term. This contrasts with the standard neural ODE which involves training a single NN for the RHS. We apply this setup to the viscous Burgers equation, which exhibits shocked behavior, and show stabilized neural ODEs provide better short-time tracking, prediction of the energy spectrum, and robustness to noisy initial conditions than standard neural ODEs. We also apply this method to chaotic trajectories of the Kuramoto-Sivashinsky equation. In this case, stabilized neural ODEs keep long-time trajectories on the attractor, and are highly robust to noisy initial conditions, while standard neural ODEs fail at achieving either of these results. We conclude by demonstrating how stabilizing neural ODEs provide a natural extension for use in reduced-order modeling by projecting the dynamics onto the eigenvectors of the learned linear term.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Journal of Computational Physics},
	author = {Linot, Alec J. and Burby, Joshua W. and Tang, Qi and Balaprakash, Prasanna and Graham, Michael D. and Maulik, Romit},
	month = feb,
	year = {2023},
	keywords = {Neural ordinary differential equations, Partial differential equations, Reduced-order models},
	pages = {111838},
}

@inproceedings{zang_neural_2020,
	address = {New York, NY, USA},
	series = {{KDD} '20},
	title = {Neural {Dynamics} on {Complex} {Networks}},
	isbn = {978-1-4503-7998-4},
	url = {https://doi.org/10.1145/3394486.3403132},
	doi = {10.1145/3394486.3403132},
	abstract = {Learning continuous-time dynamics on complex networks is crucial for understanding, predicting, and controlling complex systems in science and engineering. However, this task is very challenging due to the combinatorial complexities in the structures of high dimensional systems, their elusive continuous-time nonlinear dynamics, and their structural-dynamic dependencies. To address these challenges, we propose to combine Ordinary Differential Equation Systems (ODEs) and Graph Neural Networks (GNNs) to learn continuous-time dynamics on complex networks in a data-driven manner. We model differential equation systems by GNNs. Instead of mapping through a discrete number of neural layers in the forward process, we integrate GNN layers over continuous time numerically, leading to capturing continuous-time dynamics on graphs. Our model can be interpreted as a Continuous-time GNN model or a Graph Neural ODEs model. Our model can be utilized for continuous-time network dynamics prediction, structured sequence prediction (a regularly-sampled case), and node semi-supervised classification tasks (a one-snapshot case) in a unified framework. We validate our model by extensive experiments in the above three scenarios. The promising experimental results demonstrate our model's capability of jointly capturing the structure and dynamics of complex systems in a unified framework.},
	urldate = {2023-03-03},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Zang, Chengxi and Wang, Fei},
	month = aug,
	year = {2020},
	keywords = {continuous-time GNNs, continuous-time graph neural networks, continuous-time network dynamics prediction, differential deep learning on graphs, graph neural nodes, graph neural ordinary differential equations, graph semi-supervised learning, structured sequence prediction},
	pages = {892--902},
}

@inproceedings{huang_coupled_2021,
	address = {New York, NY, USA},
	series = {{KDD} '21},
	title = {Coupled {Graph} {ODE} for {Learning} {Interacting} {System} {Dynamics}},
	isbn = {978-1-4503-8332-5},
	url = {https://doi.org/10.1145/3447548.3467385},
	doi = {10.1145/3447548.3467385},
	abstract = {Many real-world systems such as social networks and moving planets are dynamic in nature, where a set of coupled objects are connected via the interaction graph and exhibit complex behavior along the time. For example, the COVID-19 pandemic can be considered as a dynamical system, where objects represent geographical locations (e.g., states) whose daily confirmed cases of infection evolve over time. Outbreak at one location may influence another location as people travel between these locations, forming a graph. Thus, how to model and predict the complex dynamics for these systems becomes a critical research problem. Existing work on modeling graph-structured data mostly assumes a static setting. How to handle dynamic graphs remains to be further explored. On one hand, features of objects change over time, influenced by the linked objects in the interaction graph. On the other hand, the graph itself can also evolve, where new interactions (links) may form and existing links may drop, which may in turn be affected by the dynamic features of objects. In this paper, we propose coupled graph ODE: a novel latent ordinary differential equation (ODE) generative model that learns the coupled dynamics of nodes and edges with a graph neural network (GNN) based ODE in a continuous manner. Our model consists of two coupled ODE functions for modeling the dynamics of edges and nodes based on their latent representations respectively. It employs a novel encoder parameterized by a GNN for inferring the initial states from historical data, which serves as the starting point of the predicted latent trajectories. Experiment results on the COVID-19 dataset and the simulated social network dataset demonstrate the effectiveness of our proposed method.},
	urldate = {2023-03-03},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Zijie and Sun, Yizhou and Wang, Wei},
	month = aug,
	year = {2021},
	keywords = {dynamical systems, graph neural networks, graph representationlearning, network evolution, neural ode},
	pages = {705--715},
}

@misc{poli_graph_2021,
	title = {Graph {Neural} {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1911.07532},
	doi = {10.48550/arXiv.1911.07532},
	abstract = {We introduce the framework of continuous--depth graph neural networks (GNNs). Graph neural ordinary differential equations (GDEs) are formalized as the counterpart to GNNs where the input-output relationship is determined by a continuum of GNN layers, blending discrete topological structures and differential equations. The proposed framework is shown to be compatible with various static and autoregressive GNN models. Results prove general effectiveness of GDEs: in static settings they offer computational advantages by incorporating numerical methods in their forward pass; in dynamic settings, on the other hand, they are shown to improve performance by exploiting the geometry of the underlying dynamics.},
	urldate = {2023-03-03},
	publisher = {arXiv},
	author = {Poli, Michael and Massaroli, Stefano and Park, Junyoung and Yamashita, Atsushi and Asama, Hajime and Park, Jinkyoo},
	month = jun,
	year = {2021},
	note = {arXiv:1911.07532 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{gupta_learning_2022,
	title = {Learning {Modular} {Simulations} for {Homogeneous} {Systems}},
	url = {http://arxiv.org/abs/2210.16294},
	doi = {10.48550/arXiv.2210.16294},
	abstract = {Complex systems are often decomposed into modular subsystems for engineering tractability. Although various equation based white-box modeling techniques make use of such structure, learning based methods have yet to incorporate these ideas broadly. We present a modular simulation framework for modeling homogeneous multibody dynamical systems, which combines ideas from graph neural networks and neural differential equations. We learn to model the individual dynamical subsystem as a neural ODE module. Full simulation of the composite system is orchestrated via spatio-temporal message passing between these modules. An arbitrary number of modules can be combined to simulate systems of a wide variety of coupling topologies. We evaluate our framework on a variety of systems and show that message passing allows coordination between multiple modules over time for accurate predictions and in certain cases, enables zero-shot generalization to new system configurations. Furthermore, we show that our models can be transferred to new system configurations with lower data requirement and training effort, compared to those trained from scratch.},
	urldate = {2023-03-03},
	publisher = {arXiv},
	author = {Gupta, Jayesh K. and Vemprala, Sai and Kapoor, Ashish},
	month = oct,
	year = {2022},
	note = {arXiv:2210.16294 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@article{pawar_interface_2020,
	title = {Interface learning in fluid dynamics: {Statistical} inference of closures within micro–macro-coupling models},
	volume = {32},
	issn = {1070-6631},
	shorttitle = {Interface learning in fluid dynamics},
	url = {https://aip.scitation.org/doi/full/10.1063/5.0024670},
	doi = {10.1063/5.0024670},
	abstract = {Many complex multiphysics systems in fluid dynamics involve using solvers with varied levels of approximations in different regions of the computational domain to resolve multiple spatiotemporal scales present in the flow. The accuracy of the solution is governed by how the information is exchanged between these solvers at the interface, and several methods have been devised for such coupling problems. In this Letter, we construct a data-driven model by spatially coupling a microscale lattice Boltzmann method (LBM) solver and macroscale finite difference method (FDM) solver for reaction–diffusion systems. The coupling between the micro–macro-solvers has one to many mapping at the interface leading to the interface closure problem, and we propose a statistical inference method based on neural networks to learn this closure relation. The performance of the proposed framework in a bifidelity setting partitioned between the FDM and LBM domains shows its promise for complex systems where analytical relations between micro–macro-solvers are not available.},
	number = {9},
	urldate = {2023-03-02},
	journal = {Physics of Fluids},
	author = {Pawar, Suraj and Ahmed, Shady E. and San, Omer},
	month = sep,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {091704},
}

@misc{auzina_invariant_2023,
	title = {Invariant {Neural} {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2302.13262},
	abstract = {Latent neural ordinary differential equations have been proven useful for learning non-linear dynamics of arbitrary sequences. In contrast with their mechanistic counterparts, the predictive accuracy of neural ODEs decreases over longer prediction horizons (Rubanova et al., 2019). To mitigate this issue, we propose disentangling dynamic states from time-invariant variables in a completely data-driven way, enabling robust neural ODE models that can generalize across different settings. We show that such variables can control the latent differential function and/or parameterize the mapping from latent variables to observations. By explicitly modeling the time-invariant variables, our framework enables the use of recent advances in representation learning. We demonstrate this by introducing a straightforward self-supervised objective that enhances the learning of these variables. The experiments on low-dimensional oscillating systems and video sequences reveal that our disentangled model achieves improved long-term predictions, when the training data involve sequence-specific factors of variation such as different rotational speeds, calligraphic styles, and friction constants.},
	urldate = {2023-03-02},
	publisher = {arXiv},
	author = {Auzina, Ilze Amanda and Yıldız, Çağatay and Magliacane, Sara and Bethge, Matthias and Gavves, Efstratios},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13262 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{lakshminarayanan_simple_2017,
	title = {Simple and {Scalable} {Predictive} {Uncertainty} {Estimation} using {Deep} {Ensembles}},
	url = {http://arxiv.org/abs/1612.01474},
	doi = {10.48550/arXiv.1612.01474},
	abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
	month = nov,
	year = {2017},
	note = {arXiv:1612.01474 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{blundell_weight_2015,
	title = {Weight {Uncertainty} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.05424},
	doi = {10.48550/arXiv.1505.05424},
	abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	month = may,
	year = {2015},
	note = {arXiv:1505.05424 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{blundell_weight_nodate,
	title = {Weight {Uncertainty} in {Neural} {Networks}},
	abstract = {We introduce a new, efﬁcient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classiﬁcation. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	language = {en},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
}

@inproceedings{welling_bayesian_2011,
	address = {Madison, WI, USA},
	series = {{ICML}'11},
	title = {Bayesian learning via stochastic gradient langevin dynamics},
	isbn = {978-1-4503-0619-5},
	abstract = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a "sampling threshold" and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients.},
	urldate = {2023-03-01},
	booktitle = {Proceedings of the 28th {International} {Conference} on {International} {Conference} on {Machine} {Learning}},
	publisher = {Omnipress},
	author = {Welling, Max and Teh, Yee Whye},
	month = jun,
	year = {2011},
	pages = {681--688},
}

@book{neal_mcmc_2011,
	title = {{MCMC} using {Hamiltonian} dynamics},
	url = {http://arxiv.org/abs/1206.1901},
	abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
	urldate = {2023-03-01},
	author = {Neal, Radford M.},
	month = may,
	year = {2011},
	doi = {10.1201/b10905},
	note = {arXiv:1206.1901 [physics, stat]},
	keywords = {Physics - Computational Physics, Statistics - Computation},
}

@article{lampinen_bayesian_2001,
	title = {Bayesian approach for neural networks—review and case studies},
	volume = {14},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608000000988},
	doi = {10.1016/S0893-6080(00)00098-8},
	abstract = {We give a short review on the Bayesian approach for neural network learning and demonstrate the advantages of the approach in three real applications. We discuss the Bayesian approach with emphasis on the role of prior knowledge in Bayesian models and in classical error minimization approaches. The generalization capability of a statistical model, classical or Bayesian, is ultimately based on the prior assumptions. The Bayesian approach permits propagation of uncertainty in quantities which are unknown to other assumptions in the model, which may be more generally valid or easier to guess in the problem. The case problem studied in this paper include a regression, a classification, and an inverse problem. In the most thoroughly analyzed regression problem, the best models were those with less restrictive priors. This emphasizes the major advantage of the Bayesian approach, that we are not forced to guess attributes that are unknown, such as the number of degrees of freedom in the model, non-linearity of the model with respect to each input variable, or the exact form for the distribution of the model residuals.},
	language = {en},
	number = {3},
	urldate = {2023-03-01},
	journal = {Neural Networks},
	author = {Lampinen, Jouko and Vehtari, Aki},
	month = apr,
	year = {2001},
	keywords = {Bayesian data analysis, Comparison of models, Hirarchical models, Neural networks},
	pages = {257--274},
}

@misc{gal_dropout_2016,
	title = {Dropout as a {Bayesian} {Approximation}: {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	shorttitle = {Dropout as a {Bayesian} {Approximation}},
	url = {http://arxiv.org/abs/1506.02142},
	doi = {10.48550/arXiv.1506.02142},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	month = oct,
	year = {2016},
	note = {arXiv:1506.02142 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	shorttitle = {{ImageNet}},
	doi = {10.1109/CVPR.2009.5206848},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	month = jun,
	year = {2009},
	note = {ISSN: 1063-6919},
	keywords = {Explosions, Image databases, Image retrieval, Information retrieval, Internet, Large-scale systems, Multimedia databases, Ontologies, Robustness, Spine},
	pages = {248--255},
}

@article{krizhevsky_learning_nodate,
	title = {Learning {Multiple} {Layers} of {Features} from {Tiny} {Images}},
	language = {en},
	author = {Krizhevsky, Alex},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {1558-2256},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Character recognition, Feature extraction, Hidden Markov models, Machine learning, Multi-layer neural network, Neural networks, Optical character recognition software, Optical computing, Pattern recognition, Principal component analysis},
	pages = {2278--2324},
}

@misc{takamoto_pdebench_2023,
	title = {{PDEBENCH}: {An} {Extensive} {Benchmark} for {Scientific} {Machine} {Learning}},
	shorttitle = {{PDEBENCH}},
	url = {http://arxiv.org/abs/2210.07182},
	doi = {10.48550/arXiv.2210.07182},
	abstract = {Machine learning-based modeling of physical systems has experienced increased interest in recent years. Despite some impressive progress, there is still a lack of benchmarks for Scientific ML that are easy to use but still challenging and representative of a wide range of problems. We introduce PDEBench, a benchmark suite of time-dependent simulation tasks based on Partial Differential Equations (PDEs). PDEBench comprises both code and data to benchmark the performance of novel machine learning models against both classical numerical simulations and machine learning baselines. Our proposed set of benchmark problems contribute the following unique features: (1) A much wider range of PDEs compared to existing benchmarks, ranging from relatively common examples to more realistic and difficult problems; (2) much larger ready-to-use datasets compared to prior work, comprising multiple simulation runs across a larger number of initial and boundary conditions and PDE parameters; (3) more extensible source codes with user-friendly APIs for data generation and baseline results with popular machine learning models (FNO, U-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers to extend the benchmark freely for their own purposes using a standardized API and to compare the performance of new models to existing baseline methods. We also propose new evaluation metrics with the aim to provide a more holistic understanding of learning methods in the context of Scientific ML. With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community. The code is available at https://github.com/pdebench/PDEBench.},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Takamoto, Makoto and Praditia, Timothy and Leiteritz, Raphael and MacKinlay, Dan and Alesiani, Francesco and Pflüger, Dirk and Niepert, Mathias},
	month = feb,
	year = {2023},
	note = {arXiv:2210.07182 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Physics - Fluid Dynamics, Physics - Geophysics},
}

@misc{noauthor_fair_nodate,
	title = {{FAIR} {Principles}},
	url = {https://www.go-fair.org/fair-principles/},
	abstract = {In 2016, the ‘FAIR Guiding Principles for scientific data management and stewardship’ were published in Scientific Data. The authors intended to provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability (i.e., the capacity of… Continue reading →},
	language = {en-US},
	urldate = {2023-03-01},
	journal = {GO FAIR},
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	issn = {2052-4463},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4792175/},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	urldate = {2023-03-01},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A.C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = mar,
	year = {2016},
	pmid = {26978244},
	pmcid = {PMC4792175},
	pages = {160018},
}

@misc{noauthor_2022_nodate,
	title = {2022 {Symposium} on {Turbulence} {Modeling}: {Roadblocks}, and the {Potential} for {Machine} {Learning}},
	url = {https://turbmodels.larc.nasa.gov/turb-prs2022.html},
	urldate = {2023-03-01},
}

@inproceedings{bonnet_extensible_2022,
	title = {An extensible {Benchmarking} {Graph}-{Mesh} dataset for studying {Steady}-{State} {Incompressible} {Navier}-{Stokes} {Equations}},
	url = {https://openreview.net/forum?id=rqUUi4-kpeq},
	abstract = {Recent progress in Geometric Deep Learning (GDL) has shown its potential to provide powerful data-driven models. This gives momentum to explore new methods for learning physical systems governed by Partial Differential Equations (PDEs) from Graph-Mesh data. However, despite the efforts and recent achievements, several research directions remain unexplored and progress is still far from satisfying the physical requirements of real-world phenomena. One of the major impediments is the absence of benchmarking datasets and common physics evaluation protocols. In this paper, we propose a 2-D graph-mesh dataset to study the airflow over airfoils at high Reynolds regime (from \$10{\textasciicircum}6\$ and beyond). We also introduce metrics on the stress forces over the airfoil in order to evaluate GDL models on important physical quantities. Moreover, we provide extensive GDL baselines. Code: https://github.com/Extrality/ICLR\_NACA\_Dataset\_V0 Dataset: https://data.isir.upmc.fr/extrality/},
	language = {en},
	urldate = {2023-03-01},
	author = {Bonnet, Florent and Mazari, Jocelyn Ahmed and Munzer, Thibaut and Yser, Pierre and Gallinari, Patrick},
	month = apr,
	year = {2022},
}

@inproceedings{bonnet_airfrans_2023,
	title = {{AirfRANS}: {High} {Fidelity} {Computational} {Fluid} {Dynamics} {Dataset} for {Approximating} {Reynolds}-{Averaged} {Navier}–{Stokes} {Solutions}},
	shorttitle = {{AirfRANS}},
	url = {https://openreview.net/forum?id=Zp8YmiQ_bDC},
	abstract = {Surrogate models are necessary to optimize meaningful quantities in physical dynamics as their recursive numerical resolutions are often prohibitively expensive. It is mainly the case for fluid dynamics and the resolution of Navier–Stokes equations. However, despite the fast-growing field of data-driven models for physical systems, reference datasets representing real-world phenomena are lacking. In this work, we develop {\textbackslash}textsc\{AirfRANS\}, a dataset for studying the two-dimensional incompressible steady-state Reynolds-Averaged Navier–Stokes equations over airfoils at a subsonic regime and for different angles of attacks. We also introduce metrics on the stress forces at the surface of geometries and visualization of boundary layers to assess the capabilities of models to accurately predict the meaningful information of the problem. Finally, we propose deep learning baselines on four machine learning tasks to study {\textbackslash}textsc\{AirfRANS\} under different constraints for generalization considerations: big and scarce data regime, Reynolds number, and angle of attack extrapolation.},
	language = {en},
	urldate = {2023-03-01},
	author = {Bonnet, Florent and Mazari, Jocelyn Ahmed and Cinnella, Paola and Gallinari, Patrick},
	month = jan,
	year = {2023},
}

@article{vinuesa_turbulent_2018,
	title = {Turbulent boundary layers around wing sections up to {Rec}=1,000,000},
	volume = {72},
	issn = {0142-727X},
	url = {https://www.sciencedirect.com/science/article/pii/S0142727X17311426},
	doi = {10.1016/j.ijheatfluidflow.2018.04.017},
	abstract = {Reynolds-number effects in the adverse-pressure-gradient (APG) turbulent boundary layer (TBL) developing on the suction side of a NACA4412 wing section are assessed in the present work. To this end, we analyze four cases at Reynolds numbers based on freestream velocity and chord length ranging from Rec=100,000 to 1,000,000, all of them with 5° angle of attack. The results of four well-resolved large-eddy simulations (LESs) are used to characterize the effect of Reynolds number on APG TBLs subjected to approximately the same pressure-gradient distribution (defined by the Clauser pressure-gradient parameter β). Comparisons of the wing profiles with zero-pressure-gradient (ZPG) data at matched friction Reynolds numbers reveal that, for approximately the same β distribution, the lower-Reynolds-number boundary layers are more sensitive to pressure-gradient effects. This is reflected in the values of the inner-scaled edge velocity Ue+, the shape factor H, the components of the Reynolds-stress tensor in the outer region and the outer-region production of turbulent kinetic energy. This conclusion is supported by the larger wall-normal velocities and outer-scaled fluctuations observed in the lower-Rec cases. Thus, our results suggest that two complementing mechanisms contribute to the development of the outer region in TBLs and the formation of large-scale energetic structures: one mechanism associated with the increase in Reynolds number, and another one connected to the APG. Future extensions of the present work will be aimed at studying the differences in the outer-region energizing mechanisms due to APGs and increasing Reynolds number.},
	language = {en},
	urldate = {2023-03-01},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Vinuesa, R. and Negi, P. S. and Atzori, M. and Hanifi, A. and Henningson, D. S. and Schlatter, P.},
	month = aug,
	year = {2018},
	keywords = {Large-eddy simulation, Pressure gradient, Turbulent boundary layer, Wing section},
	pages = {86--99},
}

@article{vinuesa_minimum_2015,
	title = {On minimum aspect ratio for duct flow facilities and the role of side walls in generating secondary flows},
	volume = {16},
	url = {https://doi.org/10.1080/14685248.2014.996716},
	doi = {10.1080/14685248.2014.996716},
	abstract = {To the surprise of some of our colleagues, we recently recommended aspect ratios of at least 24 (instead of accepted values over last few decades ranging from 5 to 12) to minimise effects of side walls in turbulent duct flow experiments, in order to approximate the two-dimensional channel flow. Here we compile available results from hydraulics and civil engineering literature, where this was already documented in the 1980s. This is of great importance due to the large amount of computational studies (mainly direct numerical simulations, DNSs) for spanwise-periodic turbulent channel flows, and the extreme complexity of constructing a fully developed duct flow facility with aspect ratio of 24 for high Reynolds numbers with adequate probe resolution. Results from this non-traditional literature for the turbulence community are compared to our recent database of DNS of turbulent duct flows with aspect ratios ranging from 1 to 18 at Reτ, c values of 180 and 330, leading to very good agreement between their experimental and our computational results at these low Reynolds numbers. The DNS results also reveal the complexity of a multitude of streamwise vortical structures in addition to the secondary corner flows (which extend up to z ≃ 5h). These time-dependent and meandering streamwise structures are located at the core of the duct and scale with its half-height. Comparisons of these structures with the vortical motions found in spanwise-periodic channels reveal similitudes in their time-averages and the same rate of decay of their mean kinetic energy ∼ T− 1A, with TA being the averaging time. However, differences between the two flows are identified and ideas for their future analysis are proposed.},
	number = {6},
	urldate = {2023-03-01},
	journal = {Journal of Turbulence},
	author = {Vinuesa, Ricardo and Schlatter, Philipp and Nagib, Hassan M.},
	month = jun,
	year = {2015},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/14685248.2014.996716},
	keywords = {direct numerical simulation, hydraulics, oil film interferometry, secondary motions, turbulent duct flow, wall turbulence},
	pages = {588--606},
}

@article{bobke_history_2017,
	title = {History effects and near equilibrium in adverse-pressure-gradient turbulent boundary layers},
	volume = {820},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/history-effects-and-near-equilibrium-in-adversepressuregradient-turbulent-boundary-layers/39C38082C380F396D004B65F438C296A},
	doi = {10.1017/jfm.2017.236},
	abstract = {Turbulent boundary layers under adverse pressure gradients are studied using well-resolved large-eddy simulations (LES) with the goal of assessing the influence of the streamwise pressure-gradient development. Near-equilibrium boundary layers were characterized through the Clauser pressure-gradient parameter β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\}. In order to fulfil the near-equilibrium conditions, the free stream velocity was prescribed such that it followed a power-law distribution. The turbulence statistics pertaining to cases with a constant value of β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} (extending up to approximately 40 boundary-layer thicknesses) were compared with cases with non-constant β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} distributions at matched values of β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} and friction Reynolds number ReτRe𝜏Re\_\{{\textbackslash}unicode[STIX]\{x1D70F\}\}. An additional case at matched Reynolds number based on displacement thickness Reδ∗Re𝛿∗Re\_\{{\textbackslash}unicode[STIX]\{x1D6FF\}{\textasciicircum}\{{\textbackslash}ast \}\} was also considered. It was noticed that non-constant β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} cases appear to approach the conditions of equivalent constant β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} cases after long streamwise distances (approximately 7 boundary-layer thicknesses). The relevance of the constant β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} cases lies in the fact that they define a ‘canonical’ state of the boundary layer, uniquely characterized by β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} and ReReRe. The investigations on the flat plate were extended to the flow around a wing section overlapping in terms of β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} and ReReRe. Comparisons with the flat-plate cases at matched values of β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} and ReReRe revealed that the different development history of the turbulent boundary layer on the wing section leads to a less pronounced wake in the mean velocity as well as a weaker second peak in the Reynolds stresses. This is due to the weaker accumulated effect of the β𝛽{\textbackslash}unicode[STIX]\{x1D6FD\} history. Furthermore, a scaling law suggested by Kitsios et al. (Intl J. Heat Fluid Flow, vol. 61, 2016, pp. 129–136), proposing the edge velocity and the displacement thickness as scaling parameters, was tested on two constant-pressure-gradient parameter cases. The mean velocity and Reynolds-stress profiles were found to be dependent on the downstream development. The present work is the first step towards assessing history effects in adverse-pressure-gradient turbulent boundary layers and highlights the fact that the values of the Clauser pressure-gradient parameter and the Reynolds number are not sufficient to characterize the state of the boundary layer.},
	language = {en},
	urldate = {2023-03-01},
	journal = {Journal of Fluid Mechanics},
	author = {Bobke, A. and Vinuesa, R. and Örlü, R. and Schlatter, P.},
	month = jun,
	year = {2017},
	note = {Publisher: Cambridge University Press},
	keywords = {turbulent boundary layers, turbulent flows},
	pages = {667--692},
}

@misc{noauthor_databases_nodate,
	title = {{DATABASES} – {VinuesaLab}},
	url = {https://www.vinuesalab.com/databases/},
	language = {es},
	urldate = {2023-03-01},
}

@article{choi_grid-point_2012,
	title = {Grid-point requirements for large eddy simulation: {Chapman}’s estimates revisited},
	volume = {24},
	issn = {1070-6631},
	shorttitle = {Grid-point requirements for large eddy simulation},
	url = {https://aip.scitation.org/doi/10.1063/1.3676783},
	doi = {10.1063/1.3676783},
	abstract = {Resolution requirements for large eddy simulation (LES), estimated by Chapman [AIAA J. 17, 1293 (1979)], are modified using accurate formulae for high Reynolds number boundary layer flow. The new estimates indicate that the number of grid points (N) required for wall-modeled LES is proportional to ReLx, but a wall-resolving LES requires ÑRe
13/7
Lx
, where Lx is the flat-plate length in the streamwise direction. On the other hand, direct numerical simulation, resolving the Kolmogorov length scale, requires ÑRe
37/14
Lx
.},
	number = {1},
	urldate = {2023-02-28},
	journal = {Physics of Fluids},
	author = {Choi, Haecheon and Moin, Parviz},
	month = jan,
	year = {2012},
	note = {Publisher: American Institute of Physics},
	pages = {011702},
}

@misc{charton_what_2022,
	title = {What is my math transformer doing? -- {Three} results on interpretability and generalization},
	shorttitle = {What is my math transformer doing?},
	url = {http://arxiv.org/abs/2211.00170},
	abstract = {This paper investigates the failure cases and out-of-distribution behavior of transformers trained on matrix inversion and eigenvalue decomposition. I show that incorrect model predictions still retain deep mathematical properties of the solution (e.g. correct eigenvalues, unit norm of eigenvectors), and that almost all model failures can be attributed to, and predicted from, properties of the problem or solution. This demonstrates that, when in doubt, math transformers do not hallucinate absurd solutions (as was sometimes proposed) but remain ``roughly right''. I also show that the careful choice of a training dataset can accelerate training, while allowing the model to generalize out of its training distribution, invalidating the idea that transformers ``merely interpolate'' from memorized examples.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Charton, François},
	month = oct,
	year = {2022},
	note = {arXiv:2211.00170 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{charton_linear_2022,
	title = {Linear algebra with transformers},
	url = {http://arxiv.org/abs/2112.01898},
	doi = {10.48550/arXiv.2112.01898},
	abstract = {Transformers can learn to perform numerical computations from examples only. I study nine problems of linear algebra, from basic matrix operations to eigenvalue decomposition and inversion, and introduce and discuss four encoding schemes to represent real numbers. On all problems, transformers trained on sets of random matrices achieve high accuracies (over 90\%). The models are robust to noise, and can generalize out of their training distribution. In particular, models trained to predict Laplace-distributed eigenvalues generalize to different classes of matrices: Wigner matrices or matrices with positive eigenvalues. The reverse is not true.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Charton, François},
	month = nov,
	year = {2022},
	note = {arXiv:2112.01898 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{fawzi_discovering_2022,
	title = {Discovering faster matrix multiplication algorithms with reinforcement learning},
	volume = {610},
	copyright = {2022 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-05172-4},
	doi = {10.1038/s41586-022-05172-4},
	abstract = {Improving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems—from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero1 for discovering efficient and provably correct algorithms for the multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a finite factor space. AlphaTensor discovered algorithms that outperform the state-of-the-art complexity for many matrix sizes. Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2. We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on specific hardware. Our results highlight AlphaTensor’s ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.},
	language = {en},
	number = {7930},
	urldate = {2023-02-28},
	journal = {Nature},
	author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J. and Schrittwieser, Julian and Swirszcz, Grzegorz and Silver, David and Hassabis, Demis and Kohli, Pushmeet},
	month = oct,
	year = {2022},
	note = {Number: 7930
Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Computer science},
	pages = {47--53},
}

@article{ozbay_poisson_2021,
	title = {Poisson {CNN}: {Convolutional} neural networks for the solution of the {Poisson} equation on a {Cartesian} mesh},
	volume = {2},
	issn = {2632-6736},
	shorttitle = {Poisson {CNN}},
	url = {https://www.cambridge.org/core/journals/data-centric-engineering/article/poisson-cnn-convolutional-neural-networks-for-the-solution-of-the-poisson-equation-on-a-cartesian-mesh/8CDFD5C9D5172E51B924E9AA1BA253A1},
	doi = {10.1017/dce.2021.7},
	abstract = {The Poisson equation is commonly encountered in engineering, for instance, in computational fluid dynamics (CFD) where it is needed to compute corrections to the pressure field to ensure the incompressibility of the velocity field. In the present work, we propose a novel fully convolutional neural network (CNN) architecture to infer the solution of the Poisson equation on a 2D Cartesian grid with different resolutions given the right-hand side term, arbitrary boundary conditions, and grid parameters. It provides unprecedented versatility for a CNN approach dealing with partial differential equations. The boundary conditions are handled using a novel approach by decomposing the original Poisson problem into a homogeneous Poisson problem plus four inhomogeneous Laplace subproblems. The model is trained using a novel loss function approximating the continuous  norm between the prediction and the target. Even when predicting on grids denser than previously encountered, our model demonstrates encouraging capacity to reproduce the correct solution profile. The proposed model, which outperforms well-known neural network models, can be included in a CFD solver to help with solving the Poisson equation. Analytical test cases indicate that our CNN architecture is capable of predicting the correct solution of a Poisson problem with mean percentage errors below 10\%, an improvement by comparison to the first step of conventional iterative methods. Predictions from our model, used as the initial guess to iterative algorithms like Multigrid, can reduce the root mean square error after a single iteration by more than 90\% compared to a zero initial guess.},
	language = {en},
	urldate = {2023-02-28},
	journal = {Data-Centric Engineering},
	author = {Özbay, Ali Girayhan and Hamzehloo, Arash and Laizet, Sylvain and Tzirakis, Panagiotis and Rizos, Georgios and Schuller, Björn},
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {Convolutional neural network, Poisson equation, partial differential equations},
	pages = {e6},
}

@incollection{ajuria_illarramendi_towards_2020,
	series = {{AIAA} {AVIATION} {Forum}},
	title = {Towards an hybrid computational strategy based on {Deep} {Learning} for incompressible flows},
	url = {https://arc.aiaa.org/doi/10.2514/6.2020-3058},
	urldate = {2023-02-28},
	booktitle = {{AIAA} {AVIATION} 2020 {FORUM}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Ajuria Illarramendi, Ekhi and Alguacil, Antonio and Bauerheim, Michaël and Misdariis, Antony and Cuenot, Benedicte and Benazera, Emmanuel},
	month = jun,
	year = {2020},
	doi = {10.2514/6.2020-3058},
	keywords = {Advection, Boussinesq Approximation, Buoyancy Effects, Continuity Equation, Deep Convolutional Neural Network, Fluid Mechanics, Incompressible Flow, Jacobi Method, Machine Learning, Poisson's Equation},
}

@misc{zhang_solving_2018,
	title = {Solving {Poisson}'s {Equation} using {Deep} {Learning} in {Particle} {Simulation} of {PN} {Junction}},
	url = {http://arxiv.org/abs/1810.10192},
	doi = {10.48550/arXiv.1810.10192},
	abstract = {Simulating the dynamic characteristics of a PN junction at the microscopic level requires solving the Poisson's equation at every time step. Solving at every time step is a necessary but time-consuming process when using the traditional finite difference (FDM) approach. Deep learning is a powerful technique to fit complex functions. In this work, deep learning is utilized to accelerate solving Poisson's equation in a PN junction. The role of the boundary condition is emphasized in the loss function to ensure a better fitting. The resulting I-V curve for the PN junction, using the deep learning solver presented in this work, shows a perfect match to the I-V curve obtained using the finite difference method, with the advantage of being 10 times faster at every time step.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Zhang, Zhongyang and Zhang, Ling and Sun, Ze and Erickson, Nicholas and From, Ryan and Fan, Jun},
	month = oct,
	year = {2018},
	note = {arXiv:1810.10192 [physics]},
	keywords = {Computer Science - Artificial Intelligence, Electrical Engineering and Systems Science - Signal Processing, Physics - Computational Physics},
}

@article{shan_study_2020,
	title = {Study on a {Fast} {Solver} for {Poisson}’s {Equation} {Based} on {Deep} {Learning} {Technique}},
	volume = {68},
	issn = {1558-2221},
	doi = {10.1109/TAP.2020.2985172},
	abstract = {Fast and efficient computational electromagnetic simulation is a long-standing challenge. In this article, we propose a data-driven model to solve Poisson's equation that leverages the learning capacity of deep learning techniques. A deep convolutional neural network (ConvNet) is trained to predict the electric potential with different excitations and permittivity distribution in 2-D and 3-D models. With a careful design of cost function and proper training data generated from finite-difference solvers, the proposed network enables a reliable simulation with significant speedup and fairly good accuracy. Numerical experiments show that the same ConvNet architecture is effective for both 2-D and 3-D models, and the average relative prediction error of the proposed ConvNet model is less than 3\% in both 2-D and 3-D simulations with a significant reduction in computation time compared to the finite-difference solver. This article shows that deep neural networks have a good learning capacity for numerical simulations. This could help us to build some fast solvers for some computational electromagnetic problems.},
	number = {9},
	journal = {IEEE Transactions on Antennas and Propagation},
	author = {Shan, Tao and Tang, Wei and Dang, Xunwang and Li, Maokun and Yang, Fan and Xu, Shenheng and Wu, Ji},
	month = sep,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Antennas and Propagation},
	keywords = {Computational modeling, Convolutional neural network (ConvNet), Convolutional neural networks, Machine learning, Mathematical model, Permittivity, Poisson equations, Poisson’s equation, Two dimensional displays, deep learning, finite-difference method (FDM), learning capacity},
	pages = {6725--6733},
}

@inproceedings{tang_study_2017,
	title = {Study on a {Poisson}'s equation solver based on deep learning technique},
	doi = {10.1109/EDAPS.2017.8277017},
	abstract = {In this work, we investigated the feasibility of applying deep learning techniques to solve 2D Poisson's equation. A deep convolutional neural network is set up to predict the distribution of electric potential in 2D. With training data generated from a finite difference solver, the strong approximation capability of the deep convolutional neural network allows it to make correct prediction given information of the source and distribution of permittivity. Numerical experiments show that the predication error can reach below one percent, with a significant reduction in CPU time compared with the traditional solver based on finite difference methods.},
	booktitle = {2017 {IEEE} {Electrical} {Design} of {Advanced} {Packaging} and {Systems} {Symposium} ({EDAPS})},
	author = {Tang, Wei and Shan, Tao and Dang, Xunwang and Li, Maokun and Yang, Fan and Xu, Shenheng and Wu, Ji},
	month = dec,
	year = {2017},
	note = {ISSN: 2151-1233},
	keywords = {Computational modeling, Convolutional Neural Network, Deep Learning, Electric potential, Finite Difference Method, Frequency division multiplexing, Machine learning, Mathematical model, Neural networks, Permittivity, Poisson's Equation},
	pages = {1--3},
}

@misc{stevens_finitenet_2020,
	title = {{FiniteNet}: {A} {Fully} {Convolutional} {LSTM} {Network} {Architecture} for {Time}-{Dependent} {Partial} {Differential} {Equations}},
	shorttitle = {{FiniteNet}},
	url = {http://arxiv.org/abs/2002.03014},
	doi = {10.48550/arXiv.2002.03014},
	abstract = {In this work, we present a machine learning approach for reducing the error when numerically solving time-dependent partial differential equations (PDE). We use a fully convolutional LSTM network to exploit the spatiotemporal dynamics of PDEs. The neural network serves to enhance finite-difference and finite-volume methods (FDM/FVM) that are commonly used to solve PDEs, allowing us to maintain guarantees on the order of convergence of our method. We train the network on simulation data, and show that our network can reduce error by a factor of 2 to 3 compared to the baseline algorithms. We demonstrate our method on three PDEs that each feature qualitatively different dynamics. We look at the linear advection equation, which propagates its initial conditions at a constant speed, the inviscid Burgers' equation, which develops shockwaves, and the Kuramoto-Sivashinsky (KS) equation, which is chaotic.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Stevens, Ben and Colonius, Tim},
	month = feb,
	year = {2020},
	note = {arXiv:2002.03014 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics, Physics - Fluid Dynamics, Statistics - Machine Learning},
}

@article{jeon_fvm_2021,
	title = {{FVM} {Network} to {Reduce} {Computational} {Cost} of {CFD} {Simulation}},
	abstract = {Despite the rapid growth of CPU performance, the computational cost to simulate the chemically reacting flow is still infeasible in many cases. There are few studies to accelerate the CFD simulation by using neural network models. However, they noted that it is still difficult to predict multi-step CFD time series data. The finite volume method (FVM) which is the basic principle of most CFD codes seems not to be sufficiently considered in the previous network models. In this study, a FVM network (FVMN) which simulate the principles of FVM by the tier-input and derivativeoutput system was proposed. The performance of this baseline model was evaluated using unsteady reacting flow datasets. It was confirmed that the maximum relative error of the FVMN (0.04\%) was much smaller than the general model (1.12\%) in the training dataset. This difference in error size was more prominent in the prediction datasets. In addition, it was observed that the calculation speed was about 10 times faster in FVMN than CFD solver even under the same CPU condition. Although the relative error with the ground truth data was significantly reduced in the proposed model, the linearly increasing gradient error is a remaining issue in longer transient calculations. Therefore, we additionally suggested Machine learning aided CFD framework which can substantially accelerate the CFD simulation through alternating computations.},
	language = {en},
	author = {Jeon, Joongoo and Kim, Sung Joong},
	year = {2021},
}

@article{stevens_enhancement_2020,
	title = {Enhancement of shock-capturing methods via machine learning},
	volume = {34},
	issn = {0935-4964, 1432-2250},
	url = {http://arxiv.org/abs/2002.02521},
	doi = {10.1007/s00162-020-00531-1},
	abstract = {In recent years, machine learning has been used to create data-driven solutions to problems for which an algorithmic solution is intractable, as well as fine-tuning existing algorithms. This research applies machine learning to the development of an improved finite-volume method for simulating PDEs with discontinuous solutions. Shock capturing methods make use of nonlinear switching functions that are not guaranteed to be optimal. Because data can be used to learn nonlinear relationships, we train a neural network to improve the results of a fifth-order WENO method. We post-process the outputs of the neural network to guarantee that the method is consistent. The training data consists of the exact mapping between cell averages and interpolated values for a set of integrable functions that represent waveforms we would expect to see while simulating a PDE. We demonstrate our method on linear advection of a discontinuous function, the inviscid Burgers' equation, and the 1-D Euler equations. For the latter, we examine the Shu-Osher model problem for turbulence-shockwave interactions. We find that our method outperforms WENO in simulations where the numerical solution becomes overly diffused due to numerical viscosity.},
	number = {4},
	urldate = {2023-02-28},
	journal = {Theoretical and Computational Fluid Dynamics},
	author = {Stevens, Ben and Colonius, Tim},
	month = aug,
	year = {2020},
	note = {arXiv:2002.02521 [physics]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Numerical Analysis, Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {483--496},
}

@misc{noauthor_enhancement_nodate,
	title = {Enhancement of shock-capturing methods via machine learning {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s00162-020-00531-1},
	urldate = {2023-02-28},
}

@misc{zubov_neuralpde_2021,
	title = {{NeuralPDE}: {Automating} {Physics}-{Informed} {Neural} {Networks} ({PINNs}) with {Error} {Approximations}},
	shorttitle = {{NeuralPDE}},
	url = {http://arxiv.org/abs/2107.09443},
	doi = {10.48550/arXiv.2107.09443},
	abstract = {Physics-informed neural networks (PINNs) are an increasingly powerful way to solve partial differential equations, generate digital twins, and create neural surrogates of physical models. In this manuscript we detail the inner workings of NeuralPDE.jl and show how a formulation structured around numerical quadrature gives rise to new loss functions which allow for adaptivity towards bounded error tolerances. We describe the various ways one can use the tool, detailing mathematical techniques like using extended loss functions for parameter estimation and operator discovery, to help potential users adopt these PINN-based techniques into their workflow. We showcase how NeuralPDE uses a purely symbolic formulation so that all of the underlying training code is generated from an abstract formulation, and show how to make use of GPUs and solve systems of PDEs. Afterwards we give a detailed performance analysis which showcases the trade-off between training techniques on a large set of PDEs. We end by focusing on a complex multiphysics example, the Doyle-Fuller-Newman (DFN) Model, and showcase how this PDE can be formulated and solved with NeuralPDE. Together this manuscript is meant to be a detailed and approachable technical report to help potential users of the technique quickly get a sense of the real-world performance trade-offs and use cases of the PINN techniques.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Zubov, Kirill and McCarthy, Zoe and Ma, Yingbo and Calisto, Francesco and Pagliarino, Valerio and Azeglio, Simone and Bottero, Luca and Luján, Emmanuel and Sulzer, Valentin and Bharambe, Ashutosh and Vinchhi, Nand and Balakrishnan, Kaushik and Upadhyay, Devesh and Rackauckas, Chris},
	month = jul,
	year = {2021},
	note = {arXiv:2107.09443 [cs]},
	keywords = {Computer Science - Mathematical Software, Computer Science - Symbolic Computation},
}

@misc{gupta_towards_2022,
	title = {Towards {Multi}-spatiotemporal-scale {Generalized} {PDE} {Modeling}},
	url = {http://arxiv.org/abs/2209.15616},
	doi = {10.48550/arXiv.2209.15616},
	abstract = {Partial differential equations (PDEs) are central to describing complex physical system simulations. Their expensive solution techniques have led to an increased interest in deep neural network based surrogates. However, the practical utility of training such surrogates is contingent on their ability to model complex multi-scale spatio-temporal phenomena. Various neural network architectures have been proposed to target such phenomena, most notably Fourier Neural Operators (FNOs), which give a natural handle over local \& global spatial information via parameterization of different Fourier modes, and U-Nets which treat local and global information via downsampling and upsampling paths. However, generalizing across different equation parameters or time-scales still remains a challenge. In this work, we make a comprehensive comparison between various FNO, ResNet, and U-Net like approaches to fluid mechanics problems in both vorticity-stream and velocity function form. For U-Nets, we transfer recent architectural improvements from computer vision, most notably from object segmentation and generative modeling. We further analyze the design considerations for using FNO layers to improve performance of U-Net architectures without major degradation of computational cost. Finally, we show promising results on generalization to different PDE parameters and time-scales with a single surrogate model. Source code for our PyTorch benchmark framework is available at https://github.com/microsoft/pdearena.},
	urldate = {2023-02-27},
	publisher = {arXiv},
	author = {Gupta, Jayesh K. and Brandstetter, Johannes},
	month = nov,
	year = {2022},
	note = {arXiv:2209.15616 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{koopman_hamiltonian_1931,
	title = {Hamiltonian {Systems} and {Transformation} in {Hilbert} {Space}},
	volume = {17},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.17.5.315},
	doi = {10.1073/pnas.17.5.315},
	number = {5},
	urldate = {2023-02-24},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Koopman, B. O.},
	month = may,
	year = {1931},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {315--318},
}

@misc{brunton_modern_2021,
	title = {Modern {Koopman} {Theory} for {Dynamical} {Systems}},
	url = {http://arxiv.org/abs/2102.12086},
	abstract = {The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement functions of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to reduce Koopman theory to practice in real-world applications. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of applications. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems.},
	urldate = {2023-02-24},
	publisher = {arXiv},
	author = {Brunton, Steven L. and Budišić, Marko and Kaiser, Eurika and Kutz, J. Nathan},
	month = oct,
	year = {2021},
	note = {arXiv:2102.12086 [cs, eess, math]},
	keywords = {34A34, 37A30, 37C10, 37M10, 37M99, 37N35, 47A35, 47B33, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Systems and Control, Mathematics - Dynamical Systems, Mathematics - Optimization and Control},
}

@misc{peitz_distributed_2023,
	title = {Distributed {Control} of {Partial} {Differential} {Equations} {Using} {Convolutional} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2301.10737},
	doi = {10.48550/arXiv.2301.10737},
	abstract = {We present a convolutional framework which significantly reduces the complexity and thus, the computational effort for distributed reinforcement learning control of dynamical systems governed by partial differential equations (PDEs). Exploiting translational invariances, the high-dimensional distributed control problem can be transformed into a multi-agent control problem with many identical, uncoupled agents. Furthermore, using the fact that information is transported with finite velocity in many cases, the dimension of the agents' environment can be drastically reduced using a convolution operation over the state space of the PDE. In this setting, the complexity can be flexibly adjusted via the kernel width or by using a stride greater than one. Moreover, scaling from smaller to larger systems -- or the transfer between different domains -- becomes a straightforward task requiring little effort. We demonstrate the performance of the proposed framework using several PDE examples with increasing complexity, where stabilization is achieved by training a low-dimensional deep deterministic policy gradient agent using minimal computing resources.},
	urldate = {2023-02-24},
	publisher = {arXiv},
	author = {Peitz, Sebastian and Stenner, Jan and Chidananda, Vikas and Wallscheid, Oliver and Brunton, Steven L. and Taira, Kunihiko},
	month = jan,
	year = {2023},
	note = {arXiv:2301.10737 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@article{lusch_deep_2018,
	title = {Deep learning for universal linear embeddings of nonlinear dynamics},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-07210-0},
	doi = {10.1038/s41467-018-07210-0},
	abstract = {Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear has the potential to enable nonlinear prediction, estimation, and control using linear theory. The Koopman operator is a leading data-driven embedding, and its eigenfunctions provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven challenging. This work leverages deep learning to discover representations of Koopman eigenfunctions from data. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold. We identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems with continuous spectra. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding, while connecting our models to decades of asymptotics. Thus, we benefit from the power of deep learning, while retaining the physical interpretability of Koopman embeddings.},
	language = {en},
	number = {1},
	urldate = {2023-02-24},
	journal = {Nature Communications},
	author = {Lusch, Bethany and Kutz, J. Nathan and Brunton, Steven L.},
	month = nov,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Nonlinear phenomena},
	pages = {4950},
}

@misc{baddoo_physics-informed_2021,
	title = {Physics-informed dynamic mode decomposition ({piDMD})},
	url = {http://arxiv.org/abs/2112.04307},
	doi = {10.48550/arXiv.2112.04307},
	abstract = {In this work, we demonstrate how physical principles -- such as symmetries, invariances, and conservation laws -- can be integrated into the dynamic mode decomposition (DMD). DMD is a widely-used data analysis technique that extracts low-rank modal structures and dynamics from high-dimensional measurements. However, DMD frequently produces models that are sensitive to noise, fail to generalize outside the training data, and violate basic physical laws. Our physics-informed DMD (piDMD) optimization, which may be formulated as a Procrustes problem, restricts the family of admissible models to a matrix manifold that respects the physical structure of the system. We focus on five fundamental physical principles -- conservation, self-adjointness, localization, causality, and shift-invariance -- and derive several closed-form solutions and efficient algorithms for the corresponding piDMD optimizations. With fewer degrees of freedom, piDMD models are less prone to overfitting, require less training data, and are often less computationally expensive to build than standard DMD models. We demonstrate piDMD on a range of challenging problems in the physical sciences, including energy-preserving fluid flow, travelling-wave systems, the Schr{\textbackslash}"odinger equation, solute advection-diffusion, a system with causal dynamics, and three-dimensional transitional channel flow. In each case, piDMD significantly outperforms standard DMD in metrics such as spectral identification, state prediction, and estimation of optimal forcings and responses.},
	urldate = {2023-02-24},
	publisher = {arXiv},
	author = {Baddoo, Peter J. and Herrmann, Benjamin and McKeon, Beverley J. and Kutz, J. Nathan and Brunton, Steven L.},
	month = dec,
	year = {2021},
	note = {arXiv:2112.04307 [physics]},
	keywords = {Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Mathematics - Optimization and Control, Physics - Data Analysis, Statistics and Probability, Physics - Fluid Dynamics},
}

@article{yousif_transformer-based_2023,
	title = {A transformer-based synthetic-inflow generator for spatially developing turbulent boundary layers},
	volume = {957},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/transformerbased-syntheticinflow-generator-for-spatially-developing-turbulent-boundary-layers/E58DB7B8F3C0F8FB223C6488F9CBB34D},
	doi = {10.1017/jfm.2022.1088},
	abstract = {, 
This study proposes a newly developed deep-learning-based method to generate turbulent inflow conditions for spatially developing turbulent boundary layer (TBL) simulations. A combination of a transformer and a multiscale-enhanced super-resolution generative adversarial network is utilised to predict velocity fields of a spatially developing TBL at various planes normal to the streamwise direction. Datasets of direct numerical simulation (DNS) of flat plate flow spanning a momentum thickness-based Reynolds number, Reθ=661.5–1502.0Reθ=661.5–1502.0Re\_{\textbackslash}theta = 661.5{\textbackslash}unicode\{x2013\}1502.0, are used to train and test the model. The model shows a remarkable ability to predict the instantaneous velocity fields with detailed fluctuations and reproduce the turbulence statistics as well as spatial and temporal spectra with commendable accuracy as compared with the DNS results. The proposed model also exhibits a reasonable accuracy for predicting velocity fields at Reynolds numbers that are not used in the training process. With the aid of transfer learning, the computational cost of the proposed model is considered to be effectively low. Furthermore, applying the generated turbulent inflow conditions to an inflow–outflow simulation reveals a negligible development distance for the TBL to reach the target statistics. The results demonstrate for the first time that transformer-based models can be efficient in predicting the dynamics of turbulent flows. They also show that combining these models with generative adversarial networks-based models can be useful in tackling various turbulence-related problems, including the development of efficient synthetic-turbulent inflow generators.},
	language = {en},
	urldate = {2023-02-24},
	journal = {Journal of Fluid Mechanics},
	author = {Yousif, Mustafa Z. and Zhang, Meng and Yu, Linqi and Vinuesa, Ricardo and Lim, HeeChang},
	month = feb,
	year = {2023},
	note = {Publisher: Cambridge University Press},
	keywords = {machine learning, turbulence simulation, turbulent boundary layers},
	pages = {A6},
}

@article{fukami_sparse_2021,
	title = {Sparse identification of nonlinear dynamics with low-dimensionalized flow representations},
	volume = {926},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/sparse-identification-of-nonlinear-dynamics-with-lowdimensionalized-flow-representations/B0A6BC75E087EE8F7B8100CF1185F29A},
	doi = {10.1017/jfm.2021.697},
	abstract = {, 
We perform a sparse identification of nonlinear dynamics (SINDy) for low-dimensionalized complex flow phenomena. We first apply the SINDy with two regression methods, the thresholded least square algorithm and the adaptive least absolute shrinkage and selection operator which show reasonable ability with a wide range of sparsity constant in our preliminary tests, to a two-dimensional single cylinder wake at ReD=100ReD=100Re\_D=100, its transient process and a wake of two-parallel cylinders, as examples of high-dimensional fluid data. To handle these high-dimensional data with SINDy whose library matrix is suitable for low-dimensional variable combinations, a convolutional neural network-based autoencoder (CNN-AE) is utilized. The CNN-AE is employed to map a high-dimensional dynamics into a low-dimensional latent space. The SINDy then seeks a governing equation of the mapped low-dimensional latent vector. Temporal evolution of high-dimensional dynamics can be provided by combining the predicted latent vector by SINDy with the CNN decoder which can remap the low-dimensional latent vector to the original dimension. The SINDy can provide a stable solution as the governing equation of the latent dynamics and the CNN-SINDy-based modelling can reproduce high-dimensional flow fields successfully, although more terms are required to represent the transient flow and the two-parallel cylinder wake than the periodic shedding. A nine-equation turbulent shear flow model is finally considered to examine the applicability of SINDy to turbulence, although without using CNN-AE. The present results suggest that the proposed scheme with an appropriate parameter choice enables us to analyse high-dimensional nonlinear dynamics with interpretable low-dimensional manifolds.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Journal of Fluid Mechanics},
	author = {Fukami, Kai and Murata, Takaaki and Zhang, Kai and Fukagata, Koji},
	month = nov,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, low-dimensional models, machine learning},
	pages = {A10},
}

@inproceedings{murata_cnn-sindy_2019,
	title = {{CNN}-{SINDy} {Based} {Reduced} {Order} {Modeling} of {Unsteady} {Flow} {Fields}},
	url = {https://asmedigitalcollection.asme.org/FEDSM/proceedings/AJKFluids2019/59032/V002T02A074/1069101},
	doi = {c},
	language = {en},
	urldate = {2021-03-03},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Murata, Takaaki and Fukami, Kai and Fukagata, Koji},
	month = nov,
	year = {2019},
}

@misc{kim_fast_2020,
	title = {A fast and accurate physics-informed neural network reduced order model with shallow masked autoencoder},
	url = {http://arxiv.org/abs/2009.11990},
	doi = {10.48550/arXiv.2009.11990},
	abstract = {Traditional linear subspace reduced order models (LS-ROMs) are able to accelerate physical simulations, in which the intrinsic solution space falls into a subspace with a small dimension, i.e., the solution space has a small Kolmogorov n-width. However, for physical phenomena not of this type, e.g., any advection-dominated flow phenomena, such as in traffic flow, atmospheric flows, and air flow over vehicles, a low-dimensional linear subspace poorly approximates the solution. To address cases such as these, we have developed a fast and accurate physics-informed neural network ROM, namely nonlinear manifold ROM (NM-ROM), which can better approximate high-fidelity model solutions with a smaller latent space dimension than the LS-ROMs. Our method takes advantage of the existing numerical methods that are used to solve the corresponding full order models. The efficiency is achieved by developing a hyper-reduction technique in the context of the NM-ROM. Numerical results show that neural networks can learn a more efficient latent space representation on advection-dominated data from 1D and 2D Burgers' equations. A speedup of up to 2.6 for 1D Burgers' and a speedup of 11.7 for 2D Burgers' equations are achieved with an appropriate treatment of the nonlinear terms through a hyper-reduction technique. Finally, a posteriori error bounds for the NM-ROMs are derived that take account of the hyper-reduced operators.},
	urldate = {2023-02-23},
	publisher = {arXiv},
	author = {Kim, Youngkyu and Choi, Youngsoo and Widemann, David and Zohdi, Tarek},
	month = sep,
	year = {2020},
	note = {arXiv:2009.11990 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Numerical Analysis},
}

@article{loiseau_constrained_2018,
	title = {Constrained sparse {Galerkin} regression},
	volume = {838},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/constrained-sparse-galerkin-regression/0E18A4A55FF5AC1401D236C0E4D1CAAE},
	doi = {10.1017/jfm.2017.823},
	abstract = {The sparse identification of nonlinear dynamics (SINDy) is a recently proposed data-driven modelling framework that uses sparse regression techniques to identify nonlinear low-order models. With the goal of low-order models of a fluid flow, we combine this approach with dimensionality reduction techniques (e.g. proper orthogonal decomposition) and extend it to enforce physical constraints in the regression, e.g. energy-preserving quadratic nonlinearities. The resulting models, hereafter referred to as Galerkin regression models, incorporate many beneficial aspects of Galerkin projection, but without the need for a high-fidelity solver to project the Navier–Stokes equations. Instead, the most parsimonious nonlinear model is determined that is consistent with observed measurement data and satisfies necessary constraints. Galerkin regression models also readily generalize to include higher-order nonlinear terms that model the effect of truncated modes. The effectiveness of such an approach is demonstrated on two canonical flow configurations: the two-dimensional flow past a circular cylinder and the shear-driven cavity flow. For both cases, the accuracy of the identified models compare favourably against reduced-order models obtained from a standard Galerkin projection procedure. Finally, the entire code base for our constrained sparse Galerkin regression algorithm is freely available online.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Journal of Fluid Mechanics},
	author = {Loiseau, Jean-Christophe and Brunton, Steven L.},
	month = mar,
	year = {2018},
	note = {Publisher: Cambridge University Press},
	keywords = {low-dimensional models, nonlinear dynamical systems},
	pages = {42--67},
}

@article{berkooz_proper_1993,
	title = {The {Proper} {Orthogonal} {Decomposition} in the {Analysis} of {Turbulent} {Flows}},
	volume = {25},
	url = {https://doi.org/10.1146/annurev.fl.25.010193.002543},
	doi = {10.1146/annurev.fl.25.010193.002543},
	number = {1},
	urldate = {2023-02-23},
	journal = {Annual Review of Fluid Mechanics},
	author = {Berkooz, G and Holmes, P and Lumley, J L},
	year = {1993},
	note = {\_eprint: https://doi.org/10.1146/annurev.fl.25.010193.002543},
	pages = {539--575},
}

@article{kim_fast_2022,
	title = {A fast and accurate physics-informed neural network reduced order model with shallow masked autoencoder},
	volume = {451},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121007361},
	doi = {10.1016/j.jcp.2021.110841},
	abstract = {Traditional linear subspace reduced order models (LS-ROMs) are able to accelerate physical simulations in which the intrinsic solution space falls into a subspace with a small dimension, i.e., the solution space has a small Kolmogorov n-width. However, for physical phenomena not of this type, e.g., any advection-dominated flow phenomena such as in traffic flow, atmospheric flows, and air flow over vehicles, a low-dimensional linear subspace poorly approximates the solution. To address cases such as these, we have developed a fast and accurate physics-informed neural network ROM, namely nonlinear manifold ROM (NM-ROM), which can better approximate high-fidelity model solutions with a smaller latent space dimension than the LS-ROMs. Our method takes advantage of the existing numerical methods that are used to solve the corresponding full order models. The efficiency is achieved by developing a hyper-reduction technique in the context of the NM-ROM. Numerical results show that neural networks can learn a more efficient latent space representation on advection-dominated data from 1D and 2D Burgers' equations. A speedup of up to 2.6 for 1D Burgers' and a speedup of 11.7 for 2D Burgers' equations are achieved with an appropriate treatment of the nonlinear terms through a hyper-reduction technique. Finally, a posteriori error bounds for the NM-ROMs are derived that take account of the hyper-reduced operators.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Journal of Computational Physics},
	author = {Kim, Youngkyu and Choi, Youngsoo and Widemann, David and Zohdi, Tarek},
	month = feb,
	year = {2022},
	keywords = {Hyper-reduction, Nonlinear dynamical system, Nonlinear manifold solution representation, Physics-informed neural network, Reduced order model},
	pages = {110841},
}

@article{kim_fast_2022-1,
	title = {A fast and accurate physics-informed neural network reduced order model with shallow masked autoencoder},
	volume = {451},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121007361},
	doi = {10.1016/j.jcp.2021.110841},
	abstract = {Traditional linear subspace reduced order models (LS-ROMs) are able to accelerate physical simulations in which the intrinsic solution space falls into a subspace with a small dimension, i.e., the solution space has a small Kolmogorov n-width. However, for physical phenomena not of this type, e.g., any advection-dominated flow phenomena such as in traffic flow, atmospheric flows, and air flow over vehicles, a low-dimensional linear subspace poorly approximates the solution. To address cases such as these, we have developed a fast and accurate physics-informed neural network ROM, namely nonlinear manifold ROM (NM-ROM), which can better approximate high-fidelity model solutions with a smaller latent space dimension than the LS-ROMs. Our method takes advantage of the existing numerical methods that are used to solve the corresponding full order models. The efficiency is achieved by developing a hyper-reduction technique in the context of the NM-ROM. Numerical results show that neural networks can learn a more efficient latent space representation on advection-dominated data from 1D and 2D Burgers' equations. A speedup of up to 2.6 for 1D Burgers' and a speedup of 11.7 for 2D Burgers' equations are achieved with an appropriate treatment of the nonlinear terms through a hyper-reduction technique. Finally, a posteriori error bounds for the NM-ROMs are derived that take account of the hyper-reduced operators.},
	language = {en},
	urldate = {2023-02-22},
	journal = {Journal of Computational Physics},
	author = {Kim, Youngkyu and Choi, Youngsoo and Widemann, David and Zohdi, Tarek},
	month = feb,
	year = {2022},
	keywords = {Hyper-reduction, Nonlinear dynamical system, Nonlinear manifold solution representation, Physics-informed neural network, Reduced order model},
	pages = {110841},
}

@misc{zhang_adding_2023,
	title = {Adding {Conditional} {Control} to {Text}-to-{Image} {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2302.05543},
	abstract = {We present a neural network structure, ControlNet, to control pretrained large diffusion models to support additional input conditions. The ControlNet learns task-specific conditions in an end-to-end way, and the learning is robust even when the training dataset is small ({\textless} 50k). Moreover, training a ControlNet is as fast as fine-tuning a diffusion model, and the model can be trained on a personal devices. Alternatively, if powerful computation clusters are available, the model can scale to large amounts (millions to billions) of data. We report that large diffusion models like Stable Diffusion can be augmented with ControlNets to enable conditional inputs like edge maps, segmentation maps, keypoints, etc. This may enrich the methods to control large diffusion models and further facilitate related applications.},
	urldate = {2023-02-22},
	publisher = {arXiv},
	author = {Zhang, Lvmin and Agrawala, Maneesh},
	month = feb,
	year = {2023},
	note = {arXiv:2302.05543 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Human-Computer Interaction, Computer Science - Multimedia},
}

@misc{novati_remember_2019,
	title = {Remember and {Forget} for {Experience} {Replay}},
	url = {http://arxiv.org/abs/1807.05827},
	doi = {10.48550/arXiv.1807.05827},
	abstract = {Experience replay (ER) is a fundamental component of off-policy deep reinforcement learning (RL). ER recalls experiences from past iterations to compute gradient estimates for the current policy, increasing data-efficiency. However, the accuracy of such updates may deteriorate when the policy diverges from past behaviors and can undermine the performance of ER. Many algorithms mitigate this issue by tuning hyper-parameters to slow down policy changes. An alternative is to actively enforce the similarity between policy and the experiences in the replay memory. We introduce Remember and Forget Experience Replay (ReF-ER), a novel method that can enhance RL algorithms with parameterized policies. ReF-ER (1) skips gradients computed from experiences that are too unlikely with the current policy and (2) regulates policy changes within a trust region of the replayed behaviors. We couple ReF-ER with Q-learning, deterministic policy gradient and off-policy gradient methods. We find that ReF-ER consistently improves the performance of continuous-action, off-policy RL on fully observable benchmarks and partially observable flow control problems.},
	urldate = {2023-02-22},
	publisher = {arXiv},
	author = {Novati, Guido and Koumoutsakos, Petros},
	month = may,
	year = {2019},
	note = {arXiv:1807.05827 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{schulman_proximal_2017,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	doi = {10.48550/arXiv.1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2023-02-22},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
	note = {arXiv:1707.06347 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{kurz_deep_2022,
	title = {Deep reinforcement learning for computational fluid dynamics on {HPC} systems},
	volume = {65},
	issn = {1877-7503},
	url = {https://www.sciencedirect.com/science/article/pii/S1877750322002435},
	doi = {10.1016/j.jocs.2022.101884},
	abstract = {Reinforcement learning (RL) is highly suitable for devising control strategies in the context of dynamical systems. A prominent instance of such a dynamical system is the system of equations governing fluid dynamics. Recent research results indicate that RL-augmented computational fluid dynamics (CFD) solvers can exceed the current state of the art, for example in the field of turbulence modeling. However, while in supervised learning, the training data can be generated a priori in an offline manner, RL requires constant run-time interaction and data exchange with the CFD solver during training. In order to leverage the potential of RL-enhanced CFD, the interaction between the CFD solver and the RL algorithm thus has to be implemented efficiently on high-performance computing (HPC) hardware. To this end, we present Relexi as a scalable RL framework that bridges the gap between machine learning workflows and modern CFD solvers on HPC systems, providing both components with its specialized hardware. Relexi is built with modularity in mind and allows easy integration of various HPC solvers by means of the in-memory data transfer provided by the SmartSim library. Here, we demonstrate that the Relexi framework can scale up to hundreds of parallel environments on thousands of cores. This allows to leverage modern HPC resources to either enable larger problems or faster turnaround times. Finally, we demonstrate the potential of an RL-augmented CFD solver by finding a control strategy for optimal eddy viscosity selection in large eddy simulations.},
	language = {en},
	urldate = {2023-02-22},
	journal = {Journal of Computational Science},
	author = {Kurz, Marius and Offenhäuser, Philipp and Viola, Dominic and Shcherbakov, Oleksandr and Resch, Michael and Beck, Andrea},
	month = nov,
	year = {2022},
	keywords = {Computational fluid dynamics, Deep reinforcement learning, High-performance computing, Large eddy simulation, Turbulence modeling},
	pages = {101884},
}

@article{kurz_relexi_2022,
	title = {Relexi — {A} scalable open source reinforcement learning framework for high-performance computing},
	volume = {14},
	issn = {2665-9638},
	url = {https://www.sciencedirect.com/science/article/pii/S2665963822001063},
	doi = {10.1016/j.simpa.2022.100422},
	abstract = {Relexi is an open source reinforcement learning (RL) framework written in Python and based on TensorFlow’s RL library TF-Agents. Relexi allows to employ RL for environments that require computationally intensive simulations like applications in computational fluid dynamics. For this, Relexi couples legacy simulation codes with the RL library TF-Agents at scale on modern high-performance computing (HPC) hardware using the SmartSim library. Relexi thus provides an easy way to explore the potential of RL for HPC applications.},
	language = {en},
	urldate = {2023-02-22},
	journal = {Software Impacts},
	author = {Kurz, Marius and Offenhäuser, Philipp and Viola, Dominic and Resch, Michael and Beck, Andrea},
	month = dec,
	year = {2022},
	keywords = {High-performance computing, Reinforcement learning, Scientific machine learning},
	pages = {100422},
}

@article{nadiga_instability_2007,
	title = {Instability of the perfect subgrid model in implicit-filtering large eddy simulation of geostrophic turbulence},
	volume = {75},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.75.046303},
	doi = {10.1103/PhysRevE.75.046303},
	abstract = {We demonstrate, in the context of implicit-filtering large eddy simulations (LESs) of geostrophic turbulence, that while the attractor of a well-resolved statistically stationary turbulent flow can be reached in a coarsely resolved LES that is forced by the subgrid scale (SGS) terms diagnosed from the well-resolved computation, the attractor is generically unstable: the coarsely resolved LES system forced by the diagnosed SGS eddy terms has multiple attractors. This points to the importance of interpreting the diagnosed SGS forcing terms in a well-resolved computation or experiment from a combined physical-numerical point of view rather than from a purely physical point of view.},
	number = {4},
	urldate = {2023-02-21},
	journal = {Physical Review E},
	author = {Nadiga, B. T. and Livescu, D.},
	month = apr,
	year = {2007},
	note = {Publisher: American Physical Society},
	pages = {046303},
}

@article{wu_physics-informed_2018,
	title = {Physics-{Informed} {Machine} {Learning} {Approach} for {Augmenting} {Turbulence} {Models}: {A} {Comprehensive} {Framework}},
	volume = {3},
	issn = {2469-990X},
	shorttitle = {Physics-{Informed} {Machine} {Learning} {Approach} for {Augmenting} {Turbulence} {Models}},
	url = {http://arxiv.org/abs/1801.02762},
	doi = {10.1103/PhysRevFluids.3.074602},
	abstract = {Reynolds-averaged Navier-Stokes (RANS) equations are widely used in engineering turbulent flow simulations. However, RANS predictions may have large discrepancies due to the uncertainties in modeled Reynolds stresses. Recently, Wang et al. demonstrated that machine learning can be used to improve the RANS modeled Reynolds stresses by leveraging data from high fidelity simulations (Physics informed machine learning approach for reconstructing Reynolds stress modeling discrepancies based on DNS data. Physical Review Fluids. 2, 034603, 2017). However, solving for mean flows from the improved Reynolds stresses still poses significant challenges due to potential ill-conditioning of RANS equations with Reynolds stress closures. Enabling improved predictions of mean velocities are of profound practical importance, because often the velocity and its derived quantities (QoIs, e.g., drag, lift, surface friction), and not the Reynolds stress itself, are of ultimate interest in RANS simulations. To this end, we present a comprehensive framework for augmenting turbulence models with physics-informed machine learning, illustrating a complete workflow from identification of input features to final prediction of mean velocities. This work has two innovations. First, we demonstrate a systematic procedure to generate mean flow features based on the integrity basis for mean flow tensors. Second, we propose using machine learning to predict linear and nonlinear parts of the Reynolds stress tensor separately. Inspired by the finite polynomial representation of tensors in classical turbulence modeling, such a decomposition is instrumental in overcoming the ill-conditioning of RANS equations. Numerical tests demonstrated merits of the proposed framework.},
	number = {7},
	urldate = {2023-02-21},
	journal = {Physical Review Fluids},
	author = {Wu, Jin-Long and Xiao, Heng and Paterson, Eric},
	month = jul,
	year = {2018},
	note = {arXiv:1801.02762 [physics]},
	keywords = {76F99, Physics - Fluid Dynamics},
	pages = {074602},
}

@misc{noauthor_approximation_nodate,
	title = {Approximation of attractors, large eddy simulations and multiscale methods},
	url = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.1991.0078},
	language = {en},
	urldate = {2023-02-21},
	doi = {10.1098/rspa.1991.0078},
}

@misc{tian_lagrangian_2022,
	title = {Lagrangian {Large} {Eddy} {Simulations} via {Physics} {Informed} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2207.04012},
	doi = {10.48550/arXiv.2207.04012},
	abstract = {High Reynolds Homogeneous Isotropic Turbulence is fully described within the Navier-Stokes (NS) equations, which are notoriously difficult to solve numerically. Engineers, interested primarily in describing turbulence at a reduced range of resolved scales, have designed heuristics, known as Large Eddy Simulation (LES). LES is described in terms of the temporally evolving Eulerian velocity field defined over a spatial grid with the mean-spacing correspondent to the resolved scale. This classic Eulerian LES depends on assumptions about effects of sub-grid scales on the resolved scales. Here, we take an alternative approach and design novel LES heuristics stated in terms of Lagrangian particles moving with the flow. Our Lagrangian LES, thus L-LES, is described by equations generalizing the weakly compressible Smoothed Particle Hydrodynamics formulation with extended parametric and functional freedom, which is then resolved via Machine Learning training on Lagrangian data from Direct Numerical Simulations of the NS equations. The L-LES model includes physics-informed parameterization and functional form, by combining physics-based parameters and physics-inspired Neural Networks to describe the evolution of turbulence within the resolved range of scales. The sub-grid scale contributions are modeled separately with physical constraints to account for the effects from un-resolved scales. We build the resulting model under the Differentiable Programming framework to facilitate efficient training. We experiment with loss functions of different types, including physics-informed ones accounting for statistics of Lagrangian particles. We show that our Lagrangian LES model is capable of reproducing Eulerian and unique Lagrangian turbulence structures and statistics over a range of turbulent Mach numbers.},
	urldate = {2023-02-21},
	publisher = {arXiv},
	author = {Tian, Yifeng and Woodward, Michael and Stepanov, Mikhail and Fryer, Chris and Hyett, Criston and Livescu, Daniel and Chertkov, Michael},
	month = aug,
	year = {2022},
	note = {arXiv:2207.04012 [physics]},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{zhiyin_large-eddy_2015,
	title = {Large-eddy simulation: {Past}, present and the future},
	volume = {28},
	issn = {1000-9361},
	shorttitle = {Large-eddy simulation},
	url = {https://www.sciencedirect.com/science/article/pii/S1000936114002064},
	doi = {10.1016/j.cja.2014.12.007},
	abstract = {Large-eddy simulation (LES) was originally proposed for simulating atmospheric flows in the 1960s and has become one of the most promising and successful methodology for simulating turbulent flows with the improvement of computing power. It is now feasible to simulate complex engineering flows using LES. However, apart from the computing power, significant challenges still remain for LES to reach a level of maturity that brings this approach to the mainstream of engineering and industrial computations. This paper will describe briefly LES formalism first, present a quick glance at its history, review its current state focusing mainly on its applications in transitional flows and gas turbine combustor flows, discuss some major modelling and numerical challenges/issues that we are facing now and in the near future, and finish with the concluding remarks.},
	language = {en},
	number = {1},
	urldate = {2023-02-21},
	journal = {Chinese Journal of Aeronautics},
	author = {Zhiyin, Yang},
	month = feb,
	year = {2015},
	keywords = {Gas turbine combustor, Inflow boundary condition generation methods, Large-eddy simulation (LES), Sub-grid scale (SGS) model, Turbulent flows},
	pages = {11--24},
}

@article{tabor_inlet_2010,
	title = {Inlet conditions for large eddy simulation: {A} review},
	volume = {39},
	issn = {0045-7930},
	shorttitle = {Inlet conditions for large eddy simulation},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793009001601},
	doi = {10.1016/j.compfluid.2009.10.007},
	abstract = {The treatment of inlet conditions for LES is a complex problem, but of extreme importance as, in many cases, the fluid behaviour within the domain is determined in large part by the inlet behaviour. The reason why it is so difficult to formulate inlet conditions is because the inlet flow must include a stochastically-varying component: ideally this component should ‘look’ like turbulence whilst at the same time be as simple as possible to implement and modify. We review methods for accomplishing this reported in the literature, these being ‘precursor simulation’ methods and ‘synthesis’ methods, and implement our own novel versions of these using the code OpenFOAM. Conclusions have been drawn about the relative merits of the different approaches, based on the physical realism of the results and the ease of construction and use.},
	language = {en},
	number = {4},
	urldate = {2023-02-21},
	journal = {Computers \& Fluids},
	author = {Tabor, G. R. and Baba-Ahmadi, M. H.},
	month = apr,
	year = {2010},
	keywords = {CFD, Inlet conditions, Large eddy simulation},
	pages = {553--567},
}

@article{xiong_improved_2022,
	title = {An {Improved} {Synthetic} {Eddy} {Method} for {Generating} {Inlet} {Turbulent} {Boundary} {Layers}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2226-4310},
	url = {https://www.mdpi.com/2226-4310/9/1/37},
	doi = {10.3390/aerospace9010037},
	abstract = {An improved synthetic eddy method (SEM) is proposed in this paper for generating the boundary layer at the inlet of a computational domain via direct numerical simulation. The improved SEM modified the definition of the radius and the velocities of the eddies according to the distance of the eddies from the wall in the synthetic region. The regeneration location of the eddies is also redefined. The simulation results show that the improved SEM generates turbulent fluctuations that closely match the DNS results of the experiments. The skin friction coefficient of the improved SEM recovers much faster and has lower dimensionless velocity at the outer of the boundary layer than that of the traditional SEM.},
	language = {en},
	number = {1},
	urldate = {2023-02-21},
	journal = {Aerospace},
	author = {Xiong, Dapeng and Yang, Yinxin and Wang, Yanan},
	month = jan,
	year = {2022},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {direct numerical simulation, supersonic flow, synthetic eddy method, turbulent fluctuations},
	pages = {37},
}

@article{bae_scientific_2022,
	title = {Scientific multi-agent reinforcement learning for wall-models of turbulent flows},
	volume = {13},
	issn = {2041-1723},
	url = {http://arxiv.org/abs/2106.11144},
	doi = {10.1038/s41467-022-28957-7},
	abstract = {The predictive capabilities of turbulent flow simulations, critical for aerodynamic design and weather prediction, hinge on the choice of turbulence models. The abundance of data from experiments and simulations and the advent of machine learning have provided a boost to turbulence modeling efforts. However, simulations of turbulent flows remain hindered by the inability of heuristics and supervised learning to model the near-wall dynamics. We address this challenge by introducing scientific multi-agent reinforcement learning (SciMARL) for the discovery of wall models for large-eddy simulations (LES). In SciMARL, discretization points act also as cooperating agents that learn to supply the LES closure model. The agents self-learn using limited data and generalize to extreme Reynolds numbers and previously unseen geometries. The present simulations reduce by several orders of magnitude the computational cost over fully-resolved simulations while reproducing key flow quantities. We believe that SciMARL creates unprecedented capabilities for the simulation of turbulent flows.},
	number = {1},
	urldate = {2023-02-21},
	journal = {Nature Communications},
	author = {Bae, H. Jane and Koumoutsakos, Petros},
	month = mar,
	year = {2022},
	note = {arXiv:2106.11144 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {1443},
}

@misc{zhou_multi-agent_2022,
	title = {Multi-agent reinforcement learning for wall modeling in {LES} of flow over periodic hills},
	url = {http://arxiv.org/abs/2211.16427},
	doi = {10.48550/arXiv.2211.16427},
	abstract = {We develop a wall model for large-eddy simulation (LES) that takes into account various pressure-gradient effects using multi-agent reinforcement learning (MARL). The model is trained using low-Reynolds-number flow over periodic hills with agents distributed on the wall along the computational grid points. The model utilizes a wall eddy-viscosity formulation as the boundary condition, which is shown to provide better predictions of the mean velocity field, rather than the typical wall-shear stress formulation. Each agent receives states based on local instantaneous flow quantities at an off-wall location, computes a reward based on the estimated wall-shear stress, and provides an action to update the wall eddy viscosity at each time step. The trained wall model is validated in wall-modeled LES (WMLES) of flow over periodic hills at higher Reynolds numbers, and the results show the effectiveness of the model on flow with pressure gradients. The analysis of the trained model indicates that the model is capable of distinguishing between the various pressure gradient regimes present in the flow.},
	urldate = {2023-02-21},
	publisher = {arXiv},
	author = {Zhou, Di and Whitmore, Michael P. and Griffin, Kevin P. and Bae, H. Jane},
	month = nov,
	year = {2022},
	note = {arXiv:2211.16427 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@misc{noauthor_scientific_nodate,
	title = {Scientific multi-agent reinforcement learning for wall-models of turbulent flows {\textbar} {Nature} {Communications}},
	url = {https://www.nature.com/articles/s41467-022-28957-7},
	urldate = {2023-02-21},
}

@article{kurz_deep_2023,
	title = {Deep {Reinforcement} {Learning} for {Turbulence} {Modeling} in {Large} {Eddy} {Simulations}},
	volume = {99},
	issn = {0142727X},
	url = {http://arxiv.org/abs/2206.11038},
	doi = {10.1016/j.ijheatfluidflow.2022.109094},
	abstract = {Over the last years, supervised learning (SL) has established itself as the state-of-the-art for data-driven turbulence modeling. In the SL paradigm, models are trained based on a dataset, which is typically computed a priori from a high-fidelity solution by applying the respective filter function, which separates the resolved and the unresolved flow scales. For implicitly filtered large eddy simulation (LES), this approach is infeasible, since here, the employed discretization itself acts as an implicit filter function. As a consequence, the exact filter form is generally not known and thus, the corresponding closure terms cannot be computed even if the full solution is available. The reinforcement learning (RL) paradigm can be used to avoid this inconsistency by training not on a previously obtained training dataset, but instead by interacting directly with the dynamical LES environment itself. This allows to incorporate the potentially complex implicit LES filter into the training process by design. In this work, we apply a reinforcement learning framework to find an optimal eddy-viscosity for implicitly filtered large eddy simulations of forced homogeneous isotropic turbulence. For this, we formulate the task of turbulence modeling as an RL task with a policy network based on convolutional neural networks that adapts the eddy-viscosity in LES dynamically in space and time based on the local flow state only. We demonstrate that the trained models can provide long-term stable simulations and that they outperform established analytical models in terms of accuracy. In addition, the models generalize well to other resolutions and discretizations. We thus demonstrate that RL can provide a framework for consistent, accurate and stable turbulence modeling especially for implicitly filtered LES.},
	urldate = {2023-02-21},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Kurz, Marius and Offenhäuser, Philipp and Beck, Andrea},
	month = feb,
	year = {2023},
	note = {arXiv:2206.11038 [physics]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning, Physics - Fluid Dynamics},
	pages = {109094},
}

@article{beck_deep_2019,
	title = {Deep {Neural} {Networks} for {Data}-{Driven} {Turbulence} {Models}},
	volume = {398},
	issn = {00219991},
	url = {http://arxiv.org/abs/1806.04482},
	doi = {10.1016/j.jcp.2019.108910},
	abstract = {In this work, we present a novel data-based approach to turbulence modelling for Large Eddy Simulation (LES) by artificial neural networks. We define the exact closure terms including the discretization operators and generate training data from direct numerical simulations of decaying homogeneous isotropic turbulence. We design and train artificial neural networks based on local convolution filters to predict the underlying unknown non-linear mapping from the coarse grid quantities to the closure terms without a priori assumptions. All investigated networks are able to generalize from the data and learn approximations with a cross correlation of up to 47\% and even 73\% for the inner elements, leading to the conclusion that the current training success is data-bound. We further show that selecting both the coarse grid primitive variables as well as the coarse grid LES operator as input features significantly improves training results. Finally, we construct a stable and accurate LES model from the learned closure terms. Therefore, we translate the model predictions into a data-adaptive, pointwise eddy viscosity closure and show that the resulting LES scheme performs well compared to current state of the art approaches. This work represents the starting point for further research into data-driven, universal turbulence models.},
	urldate = {2023-02-20},
	journal = {Journal of Computational Physics},
	author = {Beck, Andrea D. and Flad, David G. and Munz, Claus-Dieter},
	month = dec,
	year = {2019},
	note = {arXiv:1806.04482 [physics]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Physics - Fluid Dynamics},
	pages = {108910},
}

@misc{mialon_augmented_2023,
	title = {Augmented {Language} {Models}: a {Survey}},
	shorttitle = {Augmented {Language} {Models}},
	url = {http://arxiv.org/abs/2302.07842},
	doi = {10.48550/arXiv.2302.07842},
	abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
	urldate = {2023-02-20},
	publisher = {arXiv},
	author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07842 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{beck_deep_2019-1,
	title = {Deep {Neural} {Networks} for {Data}-{Driven} {Turbulence} {Models}},
	volume = {398},
	issn = {00219991},
	url = {http://arxiv.org/abs/1806.04482},
	doi = {10.1016/j.jcp.2019.108910},
	abstract = {In this work, we present a novel data-based approach to turbulence modelling for Large Eddy Simulation (LES) by artificial neural networks. We define the exact closure terms including the discretization operators and generate training data from direct numerical simulations of decaying homogeneous isotropic turbulence. We design and train artificial neural networks based on local convolution filters to predict the underlying unknown non-linear mapping from the coarse grid quantities to the closure terms without a priori assumptions. All investigated networks are able to generalize from the data and learn approximations with a cross correlation of up to 47\% and even 73\% for the inner elements, leading to the conclusion that the current training success is data-bound. We further show that selecting both the coarse grid primitive variables as well as the coarse grid LES operator as input features significantly improves training results. Finally, we construct a stable and accurate LES model from the learned closure terms. Therefore, we translate the model predictions into a data-adaptive, pointwise eddy viscosity closure and show that the resulting LES scheme performs well compared to current state of the art approaches. This work represents the starting point for further research into data-driven, universal turbulence models.},
	urldate = {2023-02-20},
	journal = {Journal of Computational Physics},
	author = {Beck, Andrea D. and Flad, David G. and Munz, Claus-Dieter},
	month = dec,
	year = {2019},
	note = {arXiv:1806.04482 [physics]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Physics - Fluid Dynamics},
	pages = {108910},
}

@article{weatheritt_development_2017,
	title = {The development of algebraic stress models using a novel evolutionary algorithm},
	volume = {68},
	issn = {0142-727X},
	url = {https://www.sciencedirect.com/science/article/pii/S0142727X17303223},
	doi = {10.1016/j.ijheatfluidflow.2017.09.017},
	abstract = {This work presents developments to a novel evolutionary framework that symbolically regresses algebraic forms of the Reynolds stress anisotropy tensor. This work contributes to the growing trend in machine-learning for modelling physical phenomena. Our framework is shown to be computational inexpensive and produce accurate and robust models that are tangible mathematical expressions. This transparency in the result allows us to diagnose issues with the regressed formulae and appropriately make amendments, as we further understand the regression tools. Such models are created using hybrid RANS/LES flow field data and a passive solving of the RANS transport equations to obtain the modelled time scale. This process shows that models can be regressed from a qualitatively correct flow field and fully resolved DNS is not necessarily required. Models are trained and tested using rectangular ducts, an example flow genus that linear RANS models even qualitatively fail to predict correctly. A priori and a posteriori testing of the new models show that the framework is a viable methodology for RANS closure development. This a posteriori agenda includes testing on an asymmetric diffuser, for which the new models vastly outperform the baseline linear model. Therefore this study presents one of the most rigorous and complete CFD validation of machine learnt turbulent stress models to date.},
	language = {en},
	urldate = {2023-02-20},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Weatheritt, J. and Sandberg, R. D.},
	month = dec,
	year = {2017},
	keywords = {Algebraic stress modelling, Evolutionary algorithm, Gene expression programming, Machine-learning, RANS modelling},
	pages = {298--318},
}

@article{pope_more_1975,
	title = {A more general effective-viscosity hypothesis},
	volume = {72},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/more-general-effectiveviscosity-hypothesis/86456F12CB23C8D2D9A2021CBB7FB732},
	doi = {10.1017/S0022112075003382},
	abstract = {A discussion of the applicability of an effective-viscosity approach to turbulent flow suggests that there are flow situations where the approach is valid and yet present hypotheses fail. The general form of an effective-viscosity formulation is shown to be a finite tensor polynomial. For two-dimensional flows, the coefficients of this polynomial are evaluated from the modelled Reynolds-stress equations of Launder, Reece \& Rodi (1975). The advantage of the proposed effective-viscosity formulation, equation (4.3), over isotropie-viscosity hypotheses is that the whole velocity-gradient tensor affects the predicted Reynolds stresses. Two notable consequences of this are that (i) the complete Reynolds-stress tensor is realistically modelled and (ii) the influence of streamline curvature on the Reynolds stresses is incorporated.},
	language = {en},
	number = {2},
	urldate = {2023-02-20},
	journal = {Journal of Fluid Mechanics},
	author = {Pope, S. B.},
	month = nov,
	year = {1975},
	note = {Publisher: Cambridge University Press},
	pages = {331--340},
}

@misc{lim_score-based_2023,
	title = {Score-based {Diffusion} {Models} in {Function} {Space}},
	url = {http://arxiv.org/abs/2302.07400},
	abstract = {Diffusion models have recently emerged as a powerful framework for generative modeling. They consist of a forward process that perturbs input data with Gaussian white noise and a reverse process that learns a score function to generate samples by denoising. Despite their tremendous success, they are mostly formulated on finite-dimensional spaces, e.g. Euclidean, limiting their applications to many domains where the data has a functional form such as in scientific computing and 3D geometric data analysis. In this work, we introduce a mathematically rigorous framework called Denoising Diffusion Operators (DDOs) for training diffusion models in function space. In DDOs, the forward process perturbs input functions gradually using a Gaussian process. The generative process is formulated by integrating a function-valued Langevin dynamic. Our approach requires an appropriate notion of the score for the perturbed data distribution, which we obtain by generalizing denoising score matching to function spaces that can be infinite-dimensional. We show that the corresponding discretized algorithm generates accurate samples at a fixed cost that is independent of the data resolution. We theoretically and numerically verify the applicability of our approach on a set of problems, including generating solutions to the Navier-Stokes equation viewed as the push-forward distribution of forcings from a Gaussian Random Field (GRF).},
	urldate = {2023-02-20},
	publisher = {arXiv},
	author = {Lim, Jae Hyun and Kovachki, Nikola B. and Baptista, Ricardo and Beckham, Christopher and Azizzadenesheli, Kamyar and Kossaifi, Jean and Voleti, Vikram and Song, Jiaming and Kreis, Karsten and Kautz, Jan and Pal, Christopher and Vahdat, Arash and Anandkumar, Anima},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07400 [cs, math, stat]},
	keywords = {46B09 (Primary), 60J22 (Secondary), Computer Science - Machine Learning, I.2.6, J.2, Mathematics - Functional Analysis, Statistics - Machine Learning},
}

@article{schmelzer_discovery_2020,
	title = {Discovery of {Algebraic} {Reynolds}-{Stress} {Models} {Using} {Sparse} {Symbolic} {Regression}},
	volume = {104},
	issn = {1573-1987},
	url = {https://doi.org/10.1007/s10494-019-00089-x},
	doi = {10.1007/s10494-019-00089-x},
	abstract = {A novel deterministic symbolic regression method SpaRTA (Sparse Regression of Turbulent Stress Anisotropy) is introduced to infer algebraic stress models for the closure of RANS equations directly from high-fidelity LES or DNS data. The models are written as tensor polynomials and are built from a library of candidate functions. The machine-learning method is based on elastic net regularisation which promotes sparsity of the inferred models. By being data-driven the method relaxes assumptions commonly made in the process of model development. Model-discovery and cross-validation is performed for three cases of separating flows, i.e. periodic hills (Re=10595), converging-diverging channel (Re=12600) and curved backward-facing step (Re=13700). The predictions of the discovered models are significantly improved over the k-ω SST also for a true prediction of the flow over periodic hills at Re=37000. This study shows a systematic assessment of SpaRTA for rapid machine-learning of robust corrections for standard RANS turbulence models.},
	language = {en},
	number = {2},
	urldate = {2023-02-17},
	journal = {Flow, Turbulence and Combustion},
	author = {Schmelzer, Martin and Dwight, Richard P. and Cinnella, Paola},
	month = mar,
	year = {2020},
	pages = {579--603},
}

@article{kaptanoglu_promoting_2021,
	title = {Promoting global stability in data-driven models of quadratic nonlinear dynamics},
	volume = {6},
	issn = {2469-990X},
	url = {http://arxiv.org/abs/2105.01843},
	doi = {10.1103/PhysRevFluids.6.094401},
	abstract = {Modeling realistic fluid and plasma flows is computationally intensive, motivating the use of reduced-order models for a variety of scientific and engineering tasks. However, it is challenging to characterize, much less guarantee, the global stability (i.e., long-time boundedness) of these models. The seminal work of Schlegel and Noack (JFM, 2015) provided a theorem outlining necessary and sufficient conditions to ensure global stability in systems with energy-preserving, quadratic nonlinearities, with the goal of evaluating the stability of projection-based models. In this work, we incorporate this theorem into modern data-driven models obtained via machine learning. First, we propose that this theorem should be a standard diagnostic for the stability of projection-based and data-driven models, examining the conditions under which it holds. Second, we illustrate how to modify the objective function in machine learning algorithms to promote globally stable models, with implications for the modeling of fluid and plasma flows. Specifically, we introduce a modified "trapping SINDy" algorithm based on the sparse identification of nonlinear dynamics (SINDy) method. This method enables the identification of models that, by construction, only produce bounded trajectories. The effectiveness and accuracy of this approach are demonstrated on a broad set of examples of varying model complexity and physical origin, including the vortex shedding in the wake of a circular cylinder.},
	number = {9},
	urldate = {2023-02-17},
	journal = {Physical Review Fluids},
	author = {Kaptanoglu, Alan A. and Callaham, Jared L. and Hansen, Christopher J. and Aravkin, Aleksandr and Brunton, Steven L.},
	month = sep,
	year = {2021},
	note = {arXiv:2105.01843 [physics]},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics, Physics - Plasma Physics},
	pages = {094401},
}

@article{kaptanoglu_promoting_2021-1,
	title = {Promoting global stability in data-driven models of quadratic nonlinear dynamics},
	volume = {6},
	url = {https://link.aps.org/doi/10.1103/PhysRevFluids.6.094401},
	doi = {10.1103/PhysRevFluids.6.094401},
	abstract = {Modeling realistic fluid and plasma flows is computationally intensive, motivating the use of reduced-order models for a variety of scientific and engineering tasks. However, it is challenging to characterize, much less guarantee, the global stability (i.e., long-time boundedness) of these models. Previous work provided a theorem outlining necessary and sufficient conditions to ensure global stability in systems with energy-preserving, quadratic nonlinearities, with the goal of evaluating the stability of projection-based models. In this work, we incorporate this theorem into modern data-driven models obtained via machine learning. First, we propose that this theorem should be a standard diagnostic for the stability of projection-based and data-driven models, examining the conditions under which it holds. Second, we illustrate how to modify the objective function in machine learning algorithms to promote globally stable models, with implications for the modeling of fluid and plasma flows. Specifically, we introduce a modified “trapping SINDy” algorithm based on the sparse identification of nonlinear dynamics (SINDy) method. This method enables the identification of models that, by construction, only produce bounded trajectories. The effectiveness and accuracy of this approach are demonstrated on a broad set of examples of varying model complexity and physical origin, including the vortex shedding in the wake of a circular cylinder.},
	number = {9},
	urldate = {2023-02-17},
	journal = {Physical Review Fluids},
	author = {Kaptanoglu, Alan A. and Callaham, Jared L. and Aravkin, Aleksandr and Hansen, Christopher J. and Brunton, Steven L.},
	month = sep,
	year = {2021},
	note = {Publisher: American Physical Society},
	pages = {094401},
}

@article{ling_reynolds_2016,
	title = {Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
	volume = {807},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynolds-averaged-turbulence-modelling-using-deep-neural-networks-with-embedded-invariance/0B280EEE89C74A7BF651C422F8FBD1EB},
	doi = {10.1017/jfm.2016.615},
	abstract = {There exists significant demand for improved Reynolds-averaged Navier–Stokes (RANS) turbulence models that are informed by and can represent a richer set of turbulence physics. This paper presents a method of using deep neural networks to learn a model for the Reynolds stress anisotropy tensor from high-fidelity simulation data. A novel neural network architecture is proposed which uses a multiplicative layer with an invariant tensor basis to embed Galilean invariance into the predicted anisotropy tensor. It is demonstrated that this neural network architecture provides improved prediction accuracy compared with a generic neural network architecture that does not embed this invariance property. The Reynolds stress anisotropy predictions of this invariant neural network are propagated through to the velocity field for two test cases. For both test cases, significant improvement versus baseline RANS linear eddy viscosity and nonlinear eddy viscosity models is demonstrated.},
	language = {en},
	urldate = {2023-02-17},
	journal = {Journal of Fluid Mechanics},
	author = {Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
	month = nov,
	year = {2016},
	note = {Publisher: Cambridge University Press},
	keywords = {turbulence modelling, turbulence theory, turbulent flows},
	pages = {155--166},
}

@misc{amatriain_transformer_2023,
	title = {Transformer models: an introduction and catalog},
	shorttitle = {Transformer models},
	url = {http://arxiv.org/abs/2302.07730},
	doi = {10.48550/arXiv.2302.07730},
	abstract = {In the past few years we have seen the meteoric appearance of dozens of models of the Transformer family, all of which have funny, but not self-explanatory, names. The goal of this paper is to offer a somewhat comprehensive but simple catalog and classification of the most popular Transformer models. The paper also includes an introduction to the most important aspects and innovation in Transformer models.},
	urldate = {2023-02-17},
	publisher = {arXiv},
	author = {Amatriain, Xavier},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07730 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{smagorinsky_general_1963,
	title = {{GENERAL} {CIRCULATION} {EXPERIMENTS} {WITH} {THE} {PRIMITIVE} {EQUATIONS}: {I}. {THE} {BASIC} {EXPERIMENT}},
	volume = {91},
	issn = {1520-0493, 0027-0644},
	shorttitle = {{GENERAL} {CIRCULATION} {EXPERIMENTS} {WITH} {THE} {PRIMITIVE} {EQUATIONS}},
	url = {https://journals.ametsoc.org/view/journals/mwre/91/3/1520-0493_1963_091_0099_gcewtp_2_3_co_2.xml},
	doi = {10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2},
	abstract = {Abstract An extended period numerical integration of a baroclinic primitive equation model has been made for the simulation and the study of the dynamics of the atmosphere's general circulation. The solution corresponding to external gravitational propagation is filtered by requiring the vertically integrated divergence to vanish identically. The vertical structure permits as dependent variables the horizontal wind at two internal levels and a single temperature, with the static stability entering as a parameter. The incoming radiation is a function of latitude only corresponding to the annual mean, and the outgoing radiation is taken to be a function of the local temperature. With the requirement for thermal equilibrium, the domain mean temperature is specified as a parameter. The role of condensation is taken into account only as it effectively reduces the static stability. All other external sources and sinks of heat are assumed to balance each other locally, and are thus omitted. The kinematics are that of a fluid on a sphere bounded by smooth zonal walls at the equator and at approximately 64° latitude. The dissipative sinks are provided by: (a) surface stresses proportional through a drag coefficient to the square of the surface wind which is suitably extrapolated from above, (b) internal convective stresses proportional to the vertical wind shear, and (c) lateral diffusion of momentum and heat through an exchange coefficient which depends on the local horizontal rate of strain—a horizontal length scale entering as the governing parameter. For a given specification of the parameters, an integration for 60 days has been made from initial conditions where random temperature disturbances have been superimposed on a zonally symmetric regime which is baroclinically unstable according to linear theory. This experiment not only displays the scale selective character of baroclinic instability, yielding zonal wave number 5 to 6, but also predicts an index or energy cycle. The period of this cycle is 11 to 12 days for the first 40 days of the experiment, then lengthening to 17 days while diminishing in amplitude during the latter part. The resulting mean zonal velocity profile is in good qualitative agreement with observation, but too intense, presumably because the effective static stability parameter is taken too large. Furthermore this profile is found to be no more than 5 percent super-geostrophic poleward of the angular momentum maximum and no more than 2 percent sub-geostrophic equatorward. The total zonal angular momentum remains constant to within 2 percent irrespective of the phase of the index cycle. This balance is controlled by the surface wind distribution which agrees quite well with observation. The poleward transport is mainly accomplished by the large-scale eddies, whereas the internal vertical flux is predominantly a transfer of the earth's angular momentum by the meridional circulation. The poleward heat transport is primarily accomplished by a Hadley circulation at low latitudes but by the large-scale horizontal eddies in mid-latitudes, where a Ferrel circulation tends to compensate through an equatorward flux. This compensation at mid-latitudes by an indirect meridional circulation is also quite evident, in the potential-kinetic energy transformations. Comparison of the momentum and heat transfer with observed data when available shows reasonably good quantitative agreement. The lateral transfer of momentum and heat by the non-linear diffusion, which parametrically is supposed to simulate the action of motions of sub-grid scale, accounts for a significant portion of the total eddy transfer. Although no direct comparison with the corresponding transfer in the real atmosphere is available, intuitively our small-scale diffusion appears to play too large a role. A diagnosis is made of the transformations among the baratropic and baroclinic parts of the kinetic energy as well as the zonal mean and zonal perturbation parts of the available potential and kinetic energy. This reveals the dominant paths that the energy passes through from source to ultimate sinks and the processes responsible for these transformations. It is found that the partitioning of dissipation by the energy components may differ considerably from estimates made from observation.},
	language = {EN},
	number = {3},
	urldate = {2023-02-16},
	journal = {Monthly Weather Review},
	author = {Smagorinsky, J.},
	month = mar,
	year = {1963},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {99--164},
}

@book{pope_turbulent_2000,
	address = {Cambridge},
	title = {Turbulent {Flows}},
	isbn = {978-0-521-59886-6},
	url = {https://www.cambridge.org/core/books/turbulent-flows/C58EFF59AF9B81AE6CFAC9ED16486B3A},
	abstract = {This is a graduate text on turbulent flows, an important topic in fluid dynamics.  It is up-to-date, comprehensive, designed for teaching, and is based on a course taught by the author at Cornell University for a number of years. The book consists of two parts followed by a number of appendices. Part I provides a general introduction to turbulent flows, how they behave, how they can be described quantitatively, and the fundamental physical processes involved. Part II is concerned with different approaches for modelling or simulating turbulent flows. The necessary mathematical techniques are presented in the appendices. This book is primarily intended as a graduate level text in turbulent flows for engineering students, but it may also be valuable to students in applied mathematics, physics, oceanography and atmospheric sciences, as well as researchers and practising engineers.},
	publisher = {Cambridge University Press},
	author = {Pope, Stephen B.},
	year = {2000},
	doi = {10.1017/CBO9780511840531},
}

@misc{li_learning_2022,
	title = {Learning {Dissipative} {Dynamics} in {Chaotic} {Systems}},
	url = {http://arxiv.org/abs/2106.06898},
	abstract = {Chaotic systems are notoriously challenging to predict because of their sensitivity to perturbations and errors due to time stepping. Despite this unpredictable behavior, for many dissipative systems the statistics of the long term trajectories are governed by an invariant measure supported on a set, known as the global attractor; for many problems this set is ﬁnite dimensional, even if the state space is inﬁnite dimensional. For Markovian systems, the statistical properties of long-term trajectories are uniquely determined by the solution operator that maps the evolution of the system over arbitrary positive time increments. In this work, we propose a machine learning framework to learn the underlying solution operator for dissipative chaotic systems, showing that the resulting learned operator accurately captures short-time trajectories and long-time statistical behavior. Using this framework, we are able to predict various statistics of the invariant measure for the turbulent Kolmogorov Flow dynamics with Reynolds numbers up to 5000.},
	language = {en},
	urldate = {2023-02-16},
	publisher = {arXiv},
	author = {Li, Zongyi and Liu-Schiaffini, Miguel and Kovachki, Nikola and Liu, Burigede and Azizzadenesheli, Kamyar and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = sep,
	year = {2022},
	note = {arXiv:2106.06898 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems},
}

@article{gand_generation_2021,
	title = {On the generation of turbulent inflow for hybrid {RANS}/{LES} jet flow simulations},
	volume = {216},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793020303868},
	doi = {10.1016/j.compfluid.2020.104816},
	abstract = {The present work is devoted to the assessment of a low-noise turbulence generation methodology used to produce boundary layer with three-dimensional resolved turbulence at the exit of a jet nozzle to reproduce experimental conditions. The method relies on the use of roughness elements introduced in the computational domain with Immersed Boundary Conditions and ZDES mode 3 (Wall Modelled LES branch of ZDES). The simulation of a round jet at M = 0.9 and Reynold number 106 with turbulence generation is compared to a simulation with no resolved turbulence in the nozzle boundary layer using ZDES mode 2. The behaviour of the boundary layer downstream of the roughness elements inside the nozzle is scrutinized using two grids. The turbulence generation method combined with ZDES mode 3 produces satisfying levels of resolved turbulence at the nozzle exit. The early stages of the shear layer development are modified by the ZDES mode 3 simulations providing an initially turbulent shear layer. On the other hand, the ZDES mode 2 simulations, with a turbulent mean exit velocity profile but no resolved turbulence, display a short area of strong shear layer instabilities leading to the quick development of three-dimensional turbulence in the mixing layer. The present results give insights on the level of turbulent modelling of the nozzle boundary layer needed depending on the purposes of the jet flow simulations considered.},
	language = {en},
	urldate = {2023-02-16},
	journal = {Computers \& Fluids},
	author = {Gand, F. and Huet, M.},
	month = feb,
	year = {2021},
	keywords = {RANS/LES, Turbulence generation, ZDES},
	pages = {104816},
}

@article{heinz_review_2020,
	title = {A review of hybrid {RANS}-{LES} methods for turbulent flows: {Concepts} and applications},
	volume = {114},
	issn = {0376-0421},
	shorttitle = {A review of hybrid {RANS}-{LES} methods for turbulent flows},
	url = {https://www.sciencedirect.com/science/article/pii/S0376042119301861},
	doi = {10.1016/j.paerosci.2019.100597},
	abstract = {The hybridization of Reynolds-averaged Navier-Stokes (RANS) and large eddy simulation (LES) methods is seen to be the most promising way to efficiently deal with separated turbulent flow simulations relevant to aerospace and wind energy applications. Characteristic conceptual features of popular hybrid RANS-LES and their applications to hill-type and airfoil flow including flow separation are described. Conceptual questions on existing hybrid RANS-LES are pointed out and ways to overcome these problems are presented. Further analyses show that corresponding novel hybrid RANS-LES methods generalize and improve existing methods. The discussions reveal, in particular, the great value of physical and mathematical realizability constraints for the substantial improvement of simulation methods.},
	language = {en},
	urldate = {2023-02-16},
	journal = {Progress in Aerospace Sciences},
	author = {Heinz, Stefan},
	month = apr,
	year = {2020},
	keywords = {Computational methods for turbulent flow simulations, Hybridization of RANS and LES methods, Review of concepts and applications to separated turbulent flows},
	pages = {100597},
}

@book{durbin_statistical_2010,
	title = {Statistical {Theory} and {Modeling} for {Turbulent} {Flows}; {Second} {Edition}},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Durbin, P A and Pettersson-Reif, B A},
	year = {2010},
}

@misc{bhola_multi-fidelity_2022,
	title = {Multi-fidelity reinforcement learning framework for shape optimization},
	url = {http://arxiv.org/abs/2202.11170},
	doi = {10.48550/arXiv.2202.11170},
	abstract = {Deep reinforcement learning (DRL) is a promising outer-loop intelligence paradigm which can deploy problem solving strategies for complex tasks. Consequently, DRL has been utilized for several scientific applications, specifically in cases where classical optimization or control methods are limited. One key limitation of conventional DRL methods is their episode-hungry nature which proves to be a bottleneck for tasks which involve costly evaluations of a numerical forward model. In this article, we address this limitation of DRL by introducing a controlled transfer learning framework that leverages a multi-fidelity simulation setting. Our strategy is deployed for an airfoil shape optimization problem at high Reynolds numbers, where our framework can learn an optimal policy for generating efficient airfoil shapes by gathering knowledge from multi-fidelity environments and reduces computational costs by over 30{\textbackslash}\%. Furthermore, our formulation promotes policy exploration and generalization to new environments, thereby preventing over-fitting to data from solely one fidelity. Our results demonstrate this framework's applicability to other scientific DRL scenarios where multi-fidelity environments can be used for policy learning.},
	urldate = {2023-02-16},
	publisher = {arXiv},
	author = {Bhola, Sahil and Pawar, Suraj and Balaprakash, Prasanna and Maulik, Romit},
	month = feb,
	year = {2022},
	note = {arXiv:2202.11170 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@misc{barwey_multiscale_2023,
	title = {Multiscale {Graph} {Neural} {Network} {Autoencoders} for {Interpretable} {Scientific} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2302.06186},
	doi = {10.48550/arXiv.2302.06186},
	abstract = {The goal of this work is to address two limitations in autoencoder-based models: latent space interpretability and compatibility with unstructured meshes. This is accomplished here with the development of a novel graph neural network (GNN) autoencoding architecture with demonstrations on complex fluid flow applications. To address the first goal of interpretability, the GNN autoencoder achieves reduction in the number nodes in the encoding stage through an adaptive graph reduction procedure. This reduction procedure essentially amounts to flowfield-conditioned node sampling and sensor identification, and produces interpretable latent graph representations tailored to the flowfield reconstruction task in the form of so-called masked fields. These masked fields allow the user to (a) visualize where in physical space a given latent graph is active, and (b) interpret the time-evolution of the latent graph connectivity in accordance with the time-evolution of unsteady flow features (e.g. recirculation zones, shear layers) in the domain. To address the goal of unstructured mesh compatibility, the autoencoding architecture utilizes a series of multi-scale message passing (MMP) layers, each of which models information exchange among node neighborhoods at various lengthscales. The MMP layer, which augments standard single-scale message passing with learnable coarsening operations, allows the decoder to more efficiently reconstruct the flowfield from the identified regions in the masked fields. Analysis of latent graphs produced by the autoencoder for various model settings are conducted using using unstructured snapshot data sourced from large-eddy simulations in a backward-facing step (BFS) flow configuration with an OpenFOAM-based flow solver at high Reynolds numbers.},
	urldate = {2023-02-16},
	publisher = {arXiv},
	author = {Barwey, Shivam and Shankar, Varun and Maulik, Romit},
	month = feb,
	year = {2023},
	note = {arXiv:2302.06186 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@article{shankar_differentiable_2023,
	title = {Differentiable physics-enabled closure modeling for {Burgers}’ turbulence},
	volume = {4},
	issn = {2632-2153},
	url = {https://dx.doi.org/10.1088/2632-2153/acb19c},
	doi = {10.1088/2632-2153/acb19c},
	abstract = {Data-driven turbulence modeling is experiencing a surge in interest following algorithmic and hardware developments in the data sciences. We discuss an approach using the differentiable physics paradigm that combines known physics with machine learning to develop closure models for Burgers’ turbulence. We consider the one-dimensional Burgers system as a prototypical test problem for modeling the unresolved terms in advection-dominated turbulence problems. We train a series of models that incorporate varying degrees of physical assumptions on an a posteriori loss function to test the efficacy of models across a range of system parameters, including viscosity, time, and grid resolution. We find that constraining models with inductive biases in the form of partial differential equations that contain known physics or existing closure approaches produces highly data-efficient, accurate, and generalizable models, outperforming state-of-the-art baselines. Addition of structure in the form of physics information also brings a level of interpretability to the models, potentially offering a stepping stone to the future of closure modeling.},
	language = {en},
	number = {1},
	urldate = {2023-02-16},
	journal = {Machine Learning: Science and Technology},
	author = {Shankar, Varun and Puri, Vedant and Balakrishnan, Ramesh and Maulik, Romit and Viswanathan, Venkatasubramanian},
	month = feb,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {015017},
}

@article{lee_direct_2015,
	title = {Direct numerical simulation of turbulent channel flow up to},
	volume = {774},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/direct-numerical-simulation-of-turbulent-channel-flow-up-to-mathitreittauapprox-5200/3AE84A5A48F83AF294F6CB042AF92DA8},
	doi = {10.1017/jfm.2015.268},
	abstract = {A direct numerical simulation of incompressible channel flow at a friction Reynolds number (ReτReτ{\textbackslash}mathit\{Re\}\_\{\{{\textbackslash}it{\textbackslash}tau\}\}) of 5186 has been performed, and the flow exhibits a number of the characteristics of high-Reynolds-number wall-bounded turbulent flows. For example, a region where the mean velocity has a logarithmic variation is observed, with von Kármán constant κ=0.384±0.004κ=0.384±0.004\{{\textbackslash}it{\textbackslash}kappa\}=0.384{\textbackslash}pm 0.004. There is also a logarithmic dependence of the variance of the spanwise velocity component, though not the streamwise component. A distinct separation of scales exists between the large outer-layer structures and small inner-layer structures. At intermediate distances from the wall, the one-dimensional spectrum of the streamwise velocity fluctuation in both the streamwise and spanwise directions exhibits k−1k−1k{\textasciicircum}\{-1\} dependence over a short range in wavenumber (k)(k)(k). Further, consistent with previous experimental observations, when these spectra are multiplied by kkk (premultiplied spectra), they have a bimodal structure with local peaks located at wavenumbers on either side of the k−1k−1k{\textasciicircum}\{-1\} range.},
	language = {en},
	urldate = {2023-02-16},
	journal = {Journal of Fluid Mechanics},
	author = {Lee, Myoungkyu and Moser, Robert D.},
	month = jul,
	year = {2015},
	note = {Publisher: Cambridge University Press},
	keywords = {turbulence simulation, turbulent boundary layers, turbulent flows},
	pages = {395--415},
}

@article{margenberg_neural_2022,
	title = {A neural network multigrid solver for the {Navier}-{Stokes} equations},
	volume = {460},
	issn = {00219991},
	url = {http://arxiv.org/abs/2008.11520},
	doi = {10.1016/j.jcp.2022.110983},
	abstract = {We present the deep neural network multigrid solver (DNN-MG) that we develop for the instationary Navier-Stokes equations. DNN-MG improves computational efficiency using a judicious combination of a geometric multigrid solver and a recurrent neural network with memory. DNN-MG uses the multi-grid method to classically solve on coarse levels while the neural network corrects interpolated solutions on fine ones, thus avoiding the increasingly expensive computations that would have to be performed there. This results in a reduction in computation time through DNN-MG's highly compact neural network. The compactness results from its design for local patches and the available coarse multigrid solutions that provides a "guide" for the corrections. A compact neural network with a small number of parameters also reduces training time and data. Furthermore, the network's locality facilitates generalizability and allows one to use DNN-MG trained on one mesh domain also on different ones. We demonstrate the efficacy of DNN-MG for variations of the 2D laminar flow around an obstacle. For these, our method significantly improves the solutions as well as lift and drag functionals while requiring only about half the computation time of a full multigrid solution. We also show that DNN-MG trained for the configuration with one obstacle can be generalized to other time dependent problems that can be solved efficiently using a geometric multigrid method.},
	urldate = {2023-02-15},
	journal = {Journal of Computational Physics},
	author = {Margenberg, Nils and Hartmann, Dirk and Lessig, Christian and Richter, Thomas},
	month = jul,
	year = {2022},
	note = {arXiv:2008.11520 [physics]},
	keywords = {Mathematics - Numerical Analysis, Physics - Computational Physics},
	pages = {110983},
}

@article{romor_non-linear_2023,
	title = {Non-linear {Manifold} {Reduced}-{Order} {Models} with {Convolutional} {Autoencoders} and {Reduced} {Over}-{Collocation} {Method}},
	volume = {94},
	issn = {0885-7474, 1573-7691},
	url = {https://link.springer.com/10.1007/s10915-023-02128-2},
	doi = {10.1007/s10915-023-02128-2},
	abstract = {Non-afﬁne parametric dependencies, nonlinearities and advection-dominated regimes of the model of interest can result in a slow Kolmogorov n-width decay, which precludes the realization of efﬁcient reduced-order models based on linear subspace approximations. Among the possible solutions, there are purely data-driven methods that leverage autoencoders and their variants to learn a latent representation of the dynamical system, and then evolve it in time with another architecture. Despite their success in many applications where standard linear techniques fail, more has to be done to increase the interpretability of the results, especially outside the training range and not in regimes characterized by an abundance of data. Not to mention that none of the knowledge on the physics of the model is exploited during the predictive phase. In order to overcome these weaknesses, we implement the non-linear manifold method introduced by Lee and Carlberg (J Comput Phys 404:108973, 2020) with hyper-reduction achieved through reduced over-collocation and teacher–student training of a reduced decoder. We test the methodology on a 2d non-linear conservation law and a 2d shallow water models, and compare the results obtained with a purely data-driven method for which the dynamics is evolved in time with a long-short term memory network.},
	language = {en},
	number = {3},
	urldate = {2023-02-15},
	journal = {Journal of Scientific Computing},
	author = {Romor, Francesco and Stabile, Giovanni and Rozza, Gianluigi},
	month = mar,
	year = {2023},
	pages = {74},
}

@article{noauthor_notitle_nodate,
}

@misc{noauthor_non-linear_nodate,
	title = {Non-linear {Manifold} {Reduced}-{Order} {Models} with {Convolutional} {Autoencoders} and {Reduced} {Over}-{Collocation} {Method} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s10915-023-02128-2},
	urldate = {2023-02-15},
}

@misc{ruhe_geometric_2023,
	title = {Geometric {Clifford} {Algebra} {Networks}},
	url = {http://arxiv.org/abs/2302.06594},
	abstract = {We propose Geometric Clifford Algebra Networks (GCANs) that are based on symmetry group transformations using geometric (Clifford) algebras. GCANs are particularly well-suited for representing and manipulating geometric transformations, often found in dynamical systems. We first review the quintessence of modern (plane-based) geometric algebra, which builds on isometries encoded as elements of the \${\textbackslash}mathrm\{Pin\}(p,q,r)\$ group. We then propose the concept of group action layers, which linearly combine object transformations using pre-specified group actions. Together with a new activation and normalization scheme, these layers serve as adjustable geometric templates that can be refined via gradient descent. Theoretical advantages are strongly reflected in the modeling of three-dimensional rigid body transformations as well as large-scale fluid dynamics simulations, showing significantly improved performance over traditional methods.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Ruhe, David and Gupta, Jayesh K. and de Keninck, Steven and Welling, Max and Brandstetter, Johannes},
	month = feb,
	year = {2023},
	note = {arXiv:2302.06594 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{bernard_conformal_2006,
	title = {Conformal invariance in two-dimensional turbulence},
	volume = {2},
	issn = {1745-2473, 1745-2481},
	url = {http://www.nature.com/articles/nphys217},
	doi = {10.1038/nphys217},
	language = {en},
	number = {2},
	urldate = {2023-02-13},
	journal = {Nature Physics},
	author = {Bernard, D. and Boffetta, G. and Celani, A. and Falkovich, G.},
	month = feb,
	year = {2006},
	pages = {124--128},
}

@article{lucas_spatiotemporal_2014,
	title = {Spatiotemporal dynamics in two-dimensional {Kolmogorov} flow over large domains},
	volume = {750},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/spatiotemporal-dynamics-in-twodimensional-kolmogorov-flow-over-large-domains/1738A1205FF2E5A9A81F2741E5967012},
	doi = {10.1017/jfm.2014.270},
	abstract = {Kolmogorov flow in two dimensions – the two-dimensional (2D) Navier–Stokes equations with a sinusoidal body force – is considered over extended periodic domains to reveal localised spatiotemporal complexity. The flow response mimics the forcing at small forcing amplitudes but beyond a critical value develops a long wavelength instability. The ensuing state is described by a Cahn–Hilliard-type equation and as a result coarsening dynamics is observed for random initial data. After further bifurcations, this regime gives way to multiple attractors, some of which possess spatially localised time dependence. Co-existence of such attractors in a large domain gives rise to interesting collisional dynamics which is captured by a system of 5 (1-space and 1-time) partial differential equations (PDEs) based on a long wavelength limit. The coarsening regime reinstates itself at yet higher forcing amplitudes in the sense that only longest-wavelength solutions remain attractors. Eventually, there is one global longest-wavelength attractor which possesses two localised chaotic regions – a kink and antikink – which connect two steady one-dimensional (1D) flow regions of essentially half the domain width each. The wealth of spatiotemporal complexity uncovered presents a bountiful arena in which to study the existence of simple invariant localised solutions which presumably underpin all of the observed behaviour.},
	language = {en},
	urldate = {2023-02-13},
	journal = {Journal of Fluid Mechanics},
	author = {Lucas, Dan and Kerswell, Rich},
	month = jul,
	year = {2014},
	note = {Publisher: Cambridge University Press},
	keywords = {instability, nonlinear dynamical systems, pattern formation},
	pages = {518--554},
}

@article{kutz_deep_2017,
	title = {Deep learning in fluid dynamics},
	volume = {814},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/deep-learning-in-fluid-dynamics/F2EDDAB89563DE5157FC4B8342AD9C70},
	doi = {10.1017/jfm.2016.803},
	abstract = {It was only a matter of time before deep neural networks (DNNs) – deep learning – made their mark in turbulence modelling, or more broadly, in the general area of high-dimensional, complex dynamical systems. In the last decade, DNNs have become a dominant data mining tool for big data applications. Although neural networks have been applied previously to complex fluid flows, the article featured here (Ling et al., J. Fluid Mech., vol. 807, 2016, pp. 155–166) is the first to apply a true DNN architecture, specifically to Reynolds averaged Navier Stokes turbulence models. As one often expects with modern DNNs, performance gains are achieved over competing state-of-the-art methods, suggesting that DNNs may play a critically enabling role in the future of modelling complex flows.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Journal of Fluid Mechanics},
	author = {Kutz, J. Nathan},
	month = mar,
	year = {2017},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, low-dimensional models, turbulence modelling},
	pages = {1--4},
}

@article{moser_statistical_2021,
	title = {Statistical {Properties} of {Subgrid}-{Scale} {Turbulence} {Models}},
	volume = {53},
	issn = {0066-4189, 1545-4479},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-060420-023735},
	doi = {10.1146/annurev-fluid-060420-023735},
	abstract = {This review examines large eddy simulation (LES) models from the perspective of their a priori statistical characteristics. The most well-known statistical characteristic of an LES subgrid-scale model is its dissipation (energy transfer to unresolved scales), and many models are directly or indirectly formulated and tuned for consistency of this characteristic. However, in complex turbulent flows, many other subgrid statistical characteristics are important. These include such quantities as mean subgrid stress, subgrid transport of resolved Reynolds stress, and dissipation anisotropy. Also important are the statistical characteristics of models that account for filters that do not commute with differentiation and of the discrete numerical operators in the LES equations. We review the known statistical characteristics of subgrid models to assess these characteristics and the importance of their a priori consistency. We hope that this analysis will be helpful in continued development of LES models.},
	language = {en},
	number = {1},
	urldate = {2023-02-10},
	journal = {Annual Review of Fluid Mechanics},
	author = {Moser, Robert D. and Haering, Sigfried W. and Yalla, Gopal R.},
	month = jan,
	year = {2021},
	pages = {255--286},
}

@article{jovanovic_bypass_2021,
	title = {From {Bypass} {Transition} to {Flow} {Control} and {Data}-{Driven} {Turbulence} {Modeling}: {An} {Input}–{Output} {Viewpoint}},
	volume = {53},
	issn = {0066-4189, 1545-4479},
	shorttitle = {From {Bypass} {Transition} to {Flow} {Control} and {Data}-{Driven} {Turbulence} {Modeling}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-010719-060244},
	doi = {10.1146/annurev-fluid-010719-060244},
	abstract = {Transient growth and resolvent analyses are routinely used to assess nonasymptotic properties of fluid flows. In particular, resolvent analysis can be interpreted as a special case of viewing flow dynamics as an open system in which free-stream turbulence, surface roughness, and other irregularities provide sources of input forcing. We offer a comprehensive summary of the tools that can be employed to probe the dynamics of fluctuations around a laminar or turbulent base flow in the presence of such stochastic or deterministic input forcing and describe how input–output techniques enhance resolvent analysis. Specifically, physical insights that may remain hidden in the resolvent analysis are gained by detailed examination of input–output responses between spatially localized body forces and selected linear combinations of state variables. This differentiating feature plays a key role in quantifying the importance of different mechanisms for bypass transition in wall-bounded shear flows and in explaining how turbulent jets generate noise. We highlight the utility of a stochastic framework, with white or colored inputs, in addressing a variety of open challenges including transition in complex fluids, flow control, and physics-aware data-driven turbulence modeling. Applications with temporally or spatially periodic base flows are discussed and future research directions are outlined.},
	language = {en},
	number = {1},
	urldate = {2023-02-10},
	journal = {Annual Review of Fluid Mechanics},
	author = {Jovanović, Mihailo R.},
	month = jan,
	year = {2021},
	pages = {311--345},
}

@article{pandey_perspective_2020,
	title = {A perspective on machine learning in turbulent flows},
	volume = {21},
	issn = {1468-5248},
	url = {https://www.tandfonline.com/doi/full/10.1080/14685248.2020.1757685},
	doi = {10.1080/14685248.2020.1757685},
	abstract = {The physical complexity and the large number of degrees of freedom that can be resolved today by direct numerical simulations of turbulent flows, and by the most sophisticated experimental techniques, require new strategies to reduce and analyse the data so generated, and to model the turbulent behaviour. We discuss a few concrete examples for which the turbulence data have been analysed by machine learning tools. We also comment on work in neighbouring fields of physics, particularly astrophysical (and astronomical) work, where Big Data has been the paradigm for some time. We discuss unsupervised, semi-supervised and supervised machine learning methods to direct numerical simulations data of homogeneous isotropic turbulence, Rayleigh-Bénard convection, and the minimal flow unit of a turbulent channel flow; for the last case, we discuss in some detail the application of echo state networks, this being one implementation of reservoir computing. The paper also provides a brief perspective on machine learning applications more broadly.},
	language = {en},
	number = {9-10},
	urldate = {2023-02-10},
	journal = {Journal of Turbulence},
	author = {Pandey, Sandeep and Schumacher, Jörg and Sreenivasan, Katepalli R.},
	month = oct,
	year = {2020},
	pages = {567--584},
}

@misc{kiran_deep_2021,
	title = {Deep {Reinforcement} {Learning} for {Autonomous} {Driving}: {A} {Survey}},
	shorttitle = {Deep {Reinforcement} {Learning} for {Autonomous} {Driving}},
	url = {http://arxiv.org/abs/2002.00444},
	doi = {10.48550/arXiv.2002.00444},
	abstract = {With the development of deep representation learning, the domain of reinforcement learning (RL) has become a powerful learning framework now capable of learning complex policies in high dimensional environments. This review summarises deep reinforcement learning (DRL) algorithms and provides a taxonomy of automated driving tasks where (D)RL methods have been employed, while addressing key computational challenges in real world deployment of autonomous driving agents. It also delineates adjacent domains such as behavior cloning, imitation learning, inverse reinforcement learning that are related but are not classical RL algorithms. The role of simulators in training agents, methods to validate, test and robustify existing solutions in RL are discussed.},
	urldate = {2023-02-10},
	publisher = {arXiv},
	author = {Kiran, B. Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Sallab, Ahmad A. Al and Yogamani, Senthil and Pérez, Patrick},
	month = jan,
	year = {2021},
	note = {arXiv:2002.00444 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{liu_deep_2021,
	title = {Deep {Reinforcement} {Learning} for the {Control} of {Robotic} {Manipulation}: {A} {Focussed} {Mini}-{Review}},
	volume = {10},
	issn = {2218-6581},
	shorttitle = {Deep {Reinforcement} {Learning} for the {Control} of {Robotic} {Manipulation}},
	url = {http://arxiv.org/abs/2102.04148},
	doi = {10.3390/robotics10010022},
	abstract = {Deep learning has provided new ways of manipulating, processing and analyzing data. It sometimes may achieve results comparable to, or surpassing human expert performance, and has become a source of inspiration in the era of artificial intelligence. Another subfield of machine learning named reinforcement learning, tries to find an optimal behavior strategy through interactions with the environment. Combining deep learning and reinforcement learning permits resolving critical issues relative to the dimensionality and scalability of data in tasks with sparse reward signals, such as robotic manipulation and control tasks, that neither method permits resolving when applied on its own. In this paper, we present recent significant progress of deep reinforcement learning algorithms, which try to tackle the problems for the application in the domain of robotic manipulation control, such as sample efficiency and generalization. Despite these continuous improvements, currently, the challenges of learning robust and versatile manipulation skills for robots with deep reinforcement learning are still far from being resolved for real world applications.},
	number = {1},
	urldate = {2023-02-10},
	journal = {Robotics},
	author = {Liu, Rongrong and Nageotte, Florent and Zanne, Philippe and de Mathelin, Michel and Dresp-Langley, Birgitta},
	month = jan,
	year = {2021},
	note = {arXiv:2102.04148 [cs]},
	keywords = {Computer Science - Robotics},
	pages = {22},
}

@article{reed_generalist_2023,
	title = {A {Generalist} {Agent}},
	issn = {2835-8856},
	url = {https://openreview.net/forum?id=1ikK0kHjvj},
	abstract = {Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Transactions on Machine Learning Research},
	author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gómez and Novikov, Alexander and Barth-maron, Gabriel and Giménez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and Eccles, Tom and Bruce, Jake and Razavi, Ali and Edwards, Ashley and Heess, Nicolas and Chen, Yutian and Hadsell, Raia and Vinyals, Oriol and Bordbar, Mahyar and Freitas, Nando de},
	month = jan,
	year = {2023},
}

@inproceedings{stiennon_learning_2020,
	title = {Learning to summarize with human feedback},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html},
	abstract = {As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task.  For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about---summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences.  We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN/DM news articles, producing summaries nearly as good as the human reference without any news-specific fine-tuning.  We conduct extensive analyses to understand our human feedback dataset and fine-tuned models.  We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans.  We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.},
	urldate = {2023-02-10},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
	year = {2020},
	pages = {3008--3021},
}

@misc{christiano_deep_2017,
	title = {Deep reinforcement learning from human preferences},
	url = {http://arxiv.org/abs/1706.03741},
	doi = {10.48550/arXiv.1706.03741},
	abstract = {For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.},
	urldate = {2023-02-10},
	publisher = {arXiv},
	author = {Christiano, Paul and Leike, Jan and Brown, Tom B. and Martic, Miljan and Legg, Shane and Amodei, Dario},
	month = jul,
	year = {2017},
	note = {arXiv:1706.03741 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{schrittwieser_mastering_2020,
	title = {Mastering {Atari}, {Go}, {Chess} and {Shogi} by {Planning} with a {Learned} {Model}},
	volume = {588},
	issn = {0028-0836, 1476-4687},
	url = {http://arxiv.org/abs/1911.08265},
	doi = {10.1038/s41586-020-03051-4},
	abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
	number = {7839},
	urldate = {2023-02-10},
	journal = {Nature},
	author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
	month = dec,
	year = {2020},
	note = {arXiv:1911.08265 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {604--609},
}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	language = {en},
	number = {7540},
	urldate = {2023-02-10},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	pages = {529--533},
}

@misc{noauthor_human-level_nodate,
	title = {Human-level control through deep reinforcement learning {\textbar} {Nature}},
	url = {https://www.nature.com/articles/nature14236},
	urldate = {2023-02-10},
}

@article{vinyals_grandmaster_2019,
	title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
	volume = {575},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-019-1724-z},
	doi = {10.1038/s41586-019-1724-z},
	language = {en},
	number = {7782},
	urldate = {2023-02-09},
	journal = {Nature},
	author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, Rémi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and Wünsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
	month = nov,
	year = {2019},
	pages = {350--354},
}

@misc{noauthor_grandmaster_nodate,
	title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning {\textbar} {Nature}},
	url = {https://www.nature.com/articles/s41586-019-1724-z},
	urldate = {2023-02-09},
}

@article{silver_general_2018,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and {Go} through self-play},
	volume = {362},
	url = {https://www.science.org/doi/10.1126/science.aar6404},
	doi = {10.1126/science.aar6404},
	abstract = {The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	number = {6419},
	urldate = {2023-02-09},
	journal = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	month = dec,
	year = {2018},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1140--1144},
}

@misc{noauthor_mastering_nodate,
	title = {Mastering the game of {Go} with deep neural networks and tree search {\textbar} {Nature}},
	url = {https://www.nature.com/articles/nature16961},
	urldate = {2023-02-09},
}

@article{su_adversarial_nodate,
	title = {Adversarial {Noise} {Injection} for {Learned} {Turbulence} {Simulations}},
	abstract = {Machine learning is a powerful way to learn effective dynamics of physical simulations, and has seen great interest from the community in recent years. Recent work has shown that deep neural networks trained in an end-to-end manner seem capable of learning to predict turbulent dynamics on coarse grids more accurately than classical solvers. All these works point out that adding Gaussian noise to the input during training is indispensable to improve the stability and roll-out performance of learned simulators, as an alternative to training through multiple steps. In this work we bring in insights from robust machine learning and propose to inject adversarial noise to move machine learning systems a step further towards improving generalization in ML-assisted physical simulations. We advocate that training our models on these worst case perturbation instead of model-agnostic Gaussian noise might lead to better rollout and hope that adversarial noise injection becomes a standard tool for ML-based simulations. We show experimentally in the 2D-setting that for certain classes of turbulence adversarial noise can help stabilize model rollouts, maintain a lower loss and preserve other physical properties such as energy. In addition, we identify a potentially more challenging task, driven 2D-turbulence and show that while none of the noise-based attempts significantly improve rollout, adversarial noise helps.},
	language = {en},
	author = {Su, Jingtong and Kempe, Julia and Fielding, Drummond and Tsilivis, Nikolaos and Cranmer, Miles and Ho, Shirley},
}

@article{boulle_classification_2020,
	title = {Classification of chaotic time series with deep learning},
	volume = {403},
	issn = {01672789},
	url = {http://arxiv.org/abs/1908.06848},
	doi = {10.1016/j.physd.2019.132261},
	abstract = {We use standard deep neural networks to classify univariate time series generated by discrete and continuous dynamical systems based on their chaotic or non-chaotic behaviour. Our approach to circumvent the lack of precise models for some of the most challenging real-life applications is to train different neural networks on a data set from a dynamical system with a basic or low-dimensional phase space and then use these networks to classify univariate time series of a dynamical system with more intricate or high-dimensional phase space. We illustrate this generalisation approach using the logistic map, the sine-circle map, the Lorenz system, and the Kuramoto--Sivashinsky equation. We observe that a convolutional neural network without batch normalization layers outperforms state-of-the-art neural networks for time series classification and is able to generalise and classify time series as chaotic or not with high accuracy.},
	urldate = {2023-02-09},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Boullé, Nicolas and Dallas, Vassilios and Nakatsukasa, Yuji and Samaddar, D.},
	month = feb,
	year = {2020},
	note = {arXiv:1908.06848 [nlin, physics:physics, stat]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Mathematics - Dynamical Systems, Nonlinear Sciences - Chaotic Dynamics, Physics - Computational Physics, Statistics - Machine Learning},
	pages = {132261},
}

@article{pichi_artificial_2023,
	title = {An artificial neural network approach to bifurcating phenomena in computational fluid dynamics},
	volume = {254},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793023000385},
	doi = {10.1016/j.compfluid.2023.105813},
	abstract = {This work deals with the investigation of bifurcating fluid phenomena using a reduced order modelling setting aided by artificial neural networks. We discuss the POD-NN approach dealing with non-smooth solutions set of nonlinear parametrized PDEs. Thus, we study the Navier–Stokes equations describing: (i) the Coanda effect in a channel, and (ii) the lid driven triangular cavity flow, in a physical/geometrical multi-parametrized setting, considering the effects of the domain’s configuration on the position of the bifurcation points. Finally, we propose a reduced manifold-based bifurcation diagram for a non-intrusive recovery of the critical points evolution. Exploiting such detection tool, we are able to efficiently obtain information about the pattern flow behaviour, from symmetry breaking profiles to attaching/spreading vortices, even in the advection-dominated regime.},
	language = {en},
	urldate = {2023-02-09},
	journal = {Computers \& Fluids},
	author = {Pichi, Federico and Ballarin, Francesco and Rozza, Gianluigi and Hesthaven, Jan S.},
	month = mar,
	year = {2023},
	keywords = {Artificial neural network, Bifurcation analysis, Computational fluid dynamics, Navier–Stokes equations, Reduced order modelling},
	pages = {105813},
}

@misc{noauthor_deep_nodate,
	title = {Deep reinforcement learning: a survey {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1631/FITEE.1900533},
	urldate = {2023-02-08},
}

@article{wang_deep_2022,
	title = {Deep {Reinforcement} {Learning}: {A} {Survey}},
	issn = {2162-2388},
	shorttitle = {Deep {Reinforcement} {Learning}},
	doi = {10.1109/TNNLS.2022.3207346},
	abstract = {Deep reinforcement learning (DRL) integrates the feature representation ability of deep learning with the decision-making ability of reinforcement learning so that it can achieve powerful end-to-end learning control capabilities. In the past decade, DRL has made substantial advances in many tasks that require perceiving high-dimensional input and making optimal or near-optimal decisions. However, there are still many challenging problems in the theory and applications of DRL, especially in learning control tasks with limited samples, sparse rewards, and multiple agents. Researchers have proposed various solutions and new theories to solve these problems and promote the development of DRL. In addition, deep learning has stimulated the further development of many subfields of reinforcement learning, such as hierarchical reinforcement learning (HRL), multiagent reinforcement learning, and imitation learning. This article gives a comprehensive overview of the fundamental theories, key algorithms, and primary research domains of DRL. In addition to value-based and policy-based DRL algorithms, the advances in maximum entropy-based DRL are summarized. The future research topics of DRL are also analyzed and discussed.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Wang, Xu and Wang, Sen and Liang, Xingxing and Zhao, Dawei and Huang, Jincai and Xu, Xin and Dai, Bin and Miao, Qiguang},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Behavioral sciences, Deep learning, Dynamic programming, Mathematical models, Q-learning, Task analysis, Trajectory, deep reinforcement learning (DRL), imitation learning, maximum entropy deep reinforcement learning (RL), policy gradient, value function},
	pages = {1--15},
}

@article{wang_drlinfluids_2022,
	title = {{DRLinFluids}: {An} open-source {Python} platform of coupling deep reinforcement learning and {OpenFOAM}},
	volume = {34},
	issn = {1070-6631},
	shorttitle = {{DRLinFluids}},
	url = {https://aip.scitation.org/doi/10.1063/5.0103113},
	doi = {10.1063/5.0103113},
	abstract = {We propose an open-source Python platform for applications of deep reinforcement learning (DRL) in fluid mechanics. DRL has been widely used in optimizing decision making in nonlinear and high-dimensional problems. Here, an agent maximizes a cumulative reward by learning a feedback policy by acting in an environment. In control theory terms, the cumulative reward would correspond to the cost function, the agent to the actuator, the environment to the measured signals, and the learned policy to the feedback law. Thus, DRL assumes an interactive environment or, equivalently, a control plant. The setup of a numerical simulation plant with DRL is challenging and time-consuming. In this work, a novel Python platform, namely DRLinFluids, is developed for this purpose, with DRL for flow control and optimization problems in fluid mechanics. The simulations employ OpenFOAM as a popular, flexible Navier–Stokes solver in industry and academia, and Tensorforce or Tianshou as widely used versatile DRL packages. The reliability and efficiency of DRLinFluids are demonstrated for two wake stabilization benchmark problems. DRLinFluids significantly reduces the application effort of DRL in fluid mechanics, and it is expected to greatly accelerate academic and industrial applications.},
	number = {8},
	urldate = {2023-02-08},
	journal = {Physics of Fluids},
	author = {Wang, Qiulei (王秋垒) and Yan, Lei (严雷) and Hu, Gang (胡钢) and Li, Chao (李朝) and Xiao, Yiqing (肖仪清) and Xiong, Hao (熊昊) and Rabault, Jean and Noack, Bernd R.},
	month = aug,
	year = {2022},
	note = {Publisher: American Institute of Physics},
	pages = {081801},
}

@misc{satorras_en_2022,
	title = {E(n) {Equivariant} {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2102.09844},
	doi = {10.48550/arXiv.2102.09844},
	abstract = {This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Satorras, Victor Garcia and Hoogeboom, Emiel and Welling, Max},
	month = feb,
	year = {2022},
	note = {arXiv:2102.09844 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{cohen_spherical_2018,
	title = {Spherical {CNNs}},
	url = {http://arxiv.org/abs/1801.10130},
	doi = {10.48550/arXiv.1801.10130},
	abstract = {Convolutional Neural Networks (CNNs) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective. In this paper we introduce the building blocks for constructing spherical CNNs. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical CNNs applied to 3D model recognition and atomization energy regression.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Cohen, Taco S. and Geiger, Mario and Koehler, Jonas and Welling, Max},
	month = feb,
	year = {2018},
	note = {arXiv:1801.10130 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{cohen_steerable_2016,
	title = {Steerable {CNNs}},
	url = {http://arxiv.org/abs/1612.08498},
	doi = {10.48550/arXiv.1612.08498},
	abstract = {It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efficient and flexible class of equivariant convolutional networks. We show that steerable CNNs achieve state of the art results on the CIFAR image classification benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable filter bank depends on the types of the input and output features, and show how to use this knowledge to construct CNNs that utilize parameters effectively.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Cohen, Taco S. and Welling, Max},
	month = dec,
	year = {2016},
	note = {arXiv:1612.08498 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{cohen_group_2016,
	title = {Group {Equivariant} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1602.07576},
	doi = {10.48550/arXiv.1602.07576},
	abstract = {We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Cohen, Taco S. and Welling, Max},
	month = jun,
	year = {2016},
	note = {arXiv:1602.07576 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{goldenfeld_turbulence_2017,
	title = {Turbulence as a problem in non-equilibrium statistical mechanics},
	volume = {167},
	issn = {0022-4715, 1572-9613},
	url = {http://arxiv.org/abs/1611.02778},
	doi = {10.1007/s10955-016-1682-x},
	abstract = {The transitional and well-developed regimes of turbulent shear flows exhibit a variety of remarkable scaling laws that are only now beginning to be systematically studied and understood. In the first part of this article, we summarize recent progress in understanding the friction factor of turbulent flows in rough pipes and quasi-two-dimensional soap films, showing how the data obey a two-parameter scaling law known as roughness-induced criticality, and exhibit power-law scaling of friction factor with Reynolds number that depends on the precise form of the nature of the turbulent cascade. These results hint at a non-equilibrium fluctuation-dissipation relation that applies to turbulent flows. The second part of this article concerns the lifetime statistics in smooth pipes around the transition, showing how the remarkable super-exponential scaling with Reynolds number reflects deep connections between large deviation theory, extreme value statistics, directed percolation and the onset of coexistence in predator-prey ecosystems. Both these phenomena reflect the way in which turbulence can be fruitfully approached as a problem in non-equilibrium statistical mechanics.},
	number = {3-4},
	urldate = {2023-02-08},
	journal = {Journal of Statistical Physics},
	author = {Goldenfeld, Nigel and Shih, Hong-Yan},
	month = may,
	year = {2017},
	note = {arXiv:1611.02778 [cond-mat, physics:physics, q-bio]},
	keywords = {Condensed Matter - Statistical Mechanics, Physics - Fluid Dynamics, Quantitative Biology - Populations and Evolution},
	pages = {575--594},
}

@misc{kunin_neural_2021,
	title = {Neural {Mechanics}: {Symmetry} and {Broken} {Conservation} {Laws} in {Deep} {Learning} {Dynamics}},
	shorttitle = {Neural {Mechanics}},
	url = {http://arxiv.org/abs/2012.04728},
	doi = {10.48550/arXiv.2012.04728},
	abstract = {Understanding the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic expressions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Kunin, Daniel and Sagastuy-Brena, Javier and Ganguli, Surya and Yamins, Daniel L. K. and Tanaka, Hidenori},
	month = mar,
	year = {2021},
	note = {arXiv:2012.04728 [cond-mat, q-bio, stat]},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Condensed Matter - Statistical Mechanics, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
}

@misc{finzi_practical_2021,
	title = {A {Practical} {Method} for {Constructing} {Equivariant} {Multilayer} {Perceptrons} for {Arbitrary} {Matrix} {Groups}},
	url = {http://arxiv.org/abs/2104.09459},
	doi = {10.48550/arXiv.2104.09459},
	abstract = {Symmetries and equivariance are fundamental to the generalization of neural networks on domains such as images, graphs, and point clouds. Existing work has primarily focused on a small number of groups, such as the translation, rotation, and permutation groups. In this work we provide a completely general algorithm for solving for the equivariant layers of matrix groups. In addition to recovering solutions from other works as special cases, we construct multilayer perceptrons equivariant to multiple groups that have never been tackled before, including \${\textbackslash}mathrm\{O\}(1,3)\$, \${\textbackslash}mathrm\{O\}(5)\$, \${\textbackslash}mathrm\{Sp\}(n)\$, and the Rubik's cube group. Our approach outperforms non-equivariant baselines, with applications to particle physics and dynamical systems. We release our software library to enable researchers to construct equivariant layers for arbitrary matrix groups.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Finzi, Marc and Welling, Max and Wilson, Andrew Gordon},
	month = apr,
	year = {2021},
	note = {arXiv:2104.09459 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Statistics - Machine Learning},
}

@article{noauthor_nachrichten_1895,
	title = {Nachrichten von der {Gesellschaft} der {Wissenschaften} zu {Göttingen}, {Mathematisch}-{Physikalische} {Klasse}},
	url = {https://eudml.org/journal/10154},
	language = {German},
	urldate = {2023-02-08},
	year = {1895},
}

@article{noether_invariante_1918,
	title = {Invariante {Variationsprobleme}},
	volume = {1918},
	url = {https://eudml.org/doc/59024},
	language = {deu},
	urldate = {2023-02-08},
	journal = {Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse},
	author = {Noether, E.},
	year = {1918},
	pages = {235--257},
}

@article{zitnik_predicting_2017,
	title = {Predicting multicellular function through multi-layer tissue networks},
	volume = {33},
	issn = {1367-4803, 1460-2059},
	url = {http://arxiv.org/abs/1707.04638},
	doi = {10.1093/bioinformatics/btx252},
	abstract = {Motivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue-specific cellular function remains a critical challenge for biomedicine. Results: Here we present OhmNet, a hierarchy-aware unsupervised node feature learning approach for multi-layer networks. We build a multi-layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding based low-dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi-layer protein interaction network of 107 human tissues. In 48 tissues with known tissue-specific cellular functions, OhmNet provides more accurate predictions of cellular function than alternative approaches, and also generates more accurate hypotheses about tissue-specific protein actions. We show that taking into account the tissue hierarchy leads to improved predictive power. Remarkably, we also demonstrate that it is possible to leverage the tissue hierarchy in order to effectively transfer cellular functions to a functionally uncharacterized tissue. Overall, OhmNet moves from flat networks to multiscale models able to predict a range of phenotypes spanning cellular subsystems},
	number = {14},
	urldate = {2023-02-08},
	journal = {Bioinformatics},
	author = {Zitnik, Marinka and Leskovec, Jure},
	month = jul,
	year = {2017},
	note = {arXiv:1707.04638 [cs, q-bio, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Quantitative Biology - Molecular Networks, Statistics - Machine Learning},
	pages = {i190--i198},
}

@misc{hamilton_inductive_2018,
	title = {Inductive {Representation} {Learning} on {Large} {Graphs}},
	url = {http://arxiv.org/abs/1706.02216},
	doi = {10.48550/arXiv.1706.02216},
	abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
	month = sep,
	year = {2018},
	note = {arXiv:1706.02216 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@article{morselli_gysi_network_2021,
	title = {Network medicine framework for identifying drug-repurposing opportunities for {COVID}-19},
	volume = {118},
	url = {https://www.pnas.org/doi/10.1073/pnas.2025581118},
	doi = {10.1073/pnas.2025581118},
	abstract = {The COVID-19 pandemic has highlighted the need to quickly and reliably prioritize clinically approved compounds for their potential effectiveness for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections. Here, we deployed algorithms relying on artificial intelligence, network diffusion, and network proximity, tasking each of them to rank 6,340 drugs for their expected efficacy against SARS-CoV-2. To test the predictions, we used as ground truth 918 drugs experimentally screened in VeroE6 cells, as well as the list of drugs in clinical trials that capture the medical community’s assessment of drugs with potential COVID-19 efficacy. We find that no single predictive algorithm offers consistently reliable outcomes across all datasets and metrics. This outcome prompted us to develop a multimodal technology that fuses the predictions of all algorithms, finding that a consensus among the different predictive methods consistently exceeds the performance of the best individual pipelines. We screened in human cells the top-ranked drugs, obtaining a 62\% success rate, in contrast to the 0.8\% hit rate of nonguided screenings. Of the six drugs that reduced viral infection, four could be directly repurposed to treat COVID-19, proposing novel treatments for COVID-19. We also found that 76 of the 77 drugs that successfully reduced viral infection do not bind the proteins targeted by SARS-CoV-2, indicating that these network drugs rely on network-based mechanisms that cannot be identified using docking-based strategies. These advances offer a methodological pathway to identify repurposable drugs for future pathogens and neglected diseases underserved by the costs and extended timeline of de novo drug development.},
	number = {19},
	urldate = {2023-02-08},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Morselli Gysi, Deisy and do Valle, Ítalo and Zitnik, Marinka and Ameli, Asher and Gan, Xiao and Varol, Onur and Ghiassian, Susan Dina and Patten, J. J. and Davey, Robert A. and Loscalzo, Joseph and Barabási, Albert-László},
	month = may,
	year = {2021},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2025581118},
}

@misc{gilmer_neural_2017,
	title = {Neural {Message} {Passing} for {Quantum} {Chemistry}},
	url = {http://arxiv.org/abs/1704.01212},
	doi = {10.48550/arXiv.1704.01212},
	abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
	urldate = {2023-02-08},
	publisher = {arXiv},
	author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
	month = jun,
	year = {2017},
	note = {arXiv:1704.01212 [cs]},
	keywords = {Computer Science - Machine Learning, I.2.6},
}

@misc{esteves_theoretical_2020,
	title = {Theoretical {Aspects} of {Group} {Equivariant} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2004.05154},
	doi = {10.48550/arXiv.2004.05154},
	abstract = {Group equivariant neural networks have been explored in the past few years and are interesting from theoretical and practical standpoints. They leverage concepts from group representation theory, non-commutative harmonic analysis and differential geometry that do not often appear in machine learning. In practice, they have been shown to reduce sample and model complexity, notably in challenging tasks where input transformations such as arbitrary rotations are present. We begin this work with an exposition of group representation theory and the machinery necessary to define and evaluate integrals and convolutions on groups. Then, we show applications to recent SO(3) and SE(3) equivariant networks, namely the Spherical CNNs, Clebsch-Gordan Networks, and 3D Steerable CNNs. We proceed to discuss two recent theoretical results. The first, by Kondor and Trivedi (ICML'18), shows that a neural network is group equivariant if and only if it has a convolutional structure. The second, by Cohen et al. (NeurIPS'19), generalizes the first to a larger class of networks, with feature maps as fields on homogeneous spaces.},
	urldate = {2023-02-07},
	publisher = {arXiv},
	author = {Esteves, Carlos},
	month = apr,
	year = {2020},
	note = {arXiv:2004.05154 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{velickovic_everything_2023,
	title = {Everything is {Connected}: {Graph} {Neural} {Networks}},
	shorttitle = {Everything is {Connected}},
	url = {http://arxiv.org/abs/2301.08210},
	abstract = {In many ways, graphs are the main modality of data we receive from nature. This is due to the fact that most of the patterns we see, both in natural and artificial systems, are elegantly representable using the language of graph structures. Prominent examples include molecules (represented as graphs of atoms and bonds), social networks and transportation networks. This potential has already been seen by key scientific and industrial groups, with already-impacted application areas including traffic forecasting, drug discovery, social network analysis and recommender systems. Further, some of the most successful domains of application for machine learning in previous years -- images, text and speech processing -- can be seen as special cases of graph representation learning, and consequently there has been significant exchange of information between these areas. The main aim of this short survey is to enable the reader to assimilate the key concepts in the area, and position graph representation learning in a proper context with related fields.},
	urldate = {2023-02-06},
	publisher = {arXiv},
	author = {Veličković, Petar},
	month = jan,
	year = {2023},
	note = {arXiv:2301.08210 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@article{bach_breaking_2017,
	title = {Breaking the {Curse} of {Dimensionality} with {Convex} {Neural} {Networks}},
	volume = {18},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v18/14-546.html},
	abstract = {We consider neural networks with a single hidden layer and non- decreasing positively homogeneous activation functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, they lead to a convex optimization problem and we provide a detailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity- inducing norms on the input weights, we show that high- dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total number of variables potentially exponential in the number of observations. However, solving this convex optimization problem in infinite dimensions is only possible if the non- convex subproblem of addition of a new unit can be solved efficiently. We provide a simple geometric interpretation for our choice of activation functions and describe simple conditions for convex relaxations of the finite-dimensional non- convex subproblem to achieve the same generalization error bounds, even when constant-factor approximations cannot be found. We were not able to find strong enough convex relaxations to obtain provably polynomial-time algorithms and leave open the existence or non-existence of such tractable algorithms with non-exponential sample complexities.},
	number = {19},
	urldate = {2023-02-06},
	journal = {Journal of Machine Learning Research},
	author = {Bach, Francis},
	year = {2017},
	pages = {1--53},
}

@article{bach_breaking_nodate,
	title = {Breaking the {Curse} of {Dimensionality} with {Convex} {Neural} {Networks}},
	abstract = {We consider neural networks with a single hidden layer and non-decreasing positively homogeneous activation functions like the rectiﬁed linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, they lead to a convex optimization problem and we provide a detailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity-inducing norms on the input weights, we show that high-dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total number of variables potentially exponential in the number of observations. However, solving this convex optimization problem in inﬁnite dimensions is only possible if the non-convex subproblem of addition of a new unit can be solved eﬃciently. We provide a simple geometric interpretation for our choice of activation functions and describe simple conditions for convex relaxations of the ﬁnite-dimensional non-convex subproblem to achieve the same generalization error bounds, even when constant-factor approximations cannot be found. We were not able to ﬁnd strong enough convex relaxations to obtain provably polynomialtime algorithms and leave open the existence or non-existence of such tractable algorithms with non-exponential sample complexities.},
	language = {en},
	author = {Bach, Francis},
}

@misc{nguyen_climax_2023,
	title = {{ClimaX}: {A} foundation model for weather and climate},
	shorttitle = {{ClimaX}},
	url = {http://arxiv.org/abs/2301.10343},
	doi = {10.48550/arXiv.2301.10343},
	abstract = {Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute while maintaining general utility. ClimaX is pre-trained with a self-supervised learning objective on climate datasets derived from CMIP6. The pre-trained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Nguyen, Tung and Brandstetter, Johannes and Kapoor, Ashish and Gupta, Jayesh K. and Grover, Aditya},
	month = jan,
	year = {2023},
	note = {arXiv:2301.10343 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	doi = {10.48550/arXiv.2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	note = {arXiv:2005.14165 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{ba_layer_2016,
	title = {Layer {Normalization}},
	url = {http://arxiv.org/abs/1607.06450},
	doi = {10.48550/arXiv.1607.06450},
	abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	month = jul,
	year = {2016},
	note = {arXiv:1607.06450 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	doi = {10.48550/arXiv.2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv:2010.11929 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{rives_biological_2021,
	title = {Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences},
	volume = {118},
	url = {https://www.pnas.org/doi/10.1073/pnas.2016239118},
	doi = {10.1073/pnas.2016239118},
	abstract = {In the field of artificial intelligence, a combination of scale in data and model capacity enabled by unsupervised learning has led to major advances in representation learning and statistical generation. In the life sciences, the anticipated growth of sequencing promises unprecedented data on natural sequence diversity. Protein language modeling at the scale of evolution is a logical step toward predictive and generative artificial intelligence for biology. To this end, we use unsupervised learning to train a deep contextual language model on 86 billion amino acids across 250 million protein sequences spanning evolutionary diversity. The resulting model contains information about biological properties in its representations. The representations are learned from sequence data alone. The learned representation space has a multiscale organization reflecting structure from the level of biochemical properties of amino acids to remote homology of proteins. Information about secondary and tertiary structure is encoded in the representations and can be identified by linear projections. Representation learning produces features that generalize across a range of applications, enabling state-of-the-art supervised prediction of mutational effect and secondary structure and improving state-of-the-art features for long-range contact prediction.},
	number = {15},
	urldate = {2023-02-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C. Lawrence and Ma, Jerry and Fergus, Rob},
	month = apr,
	year = {2021},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2016239118},
}

@article{schwaller_molecular_2019,
	title = {Molecular {Transformer}: {A} {Model} for {Uncertainty}-{Calibrated} {Chemical} {Reaction} {Prediction}},
	volume = {5},
	issn = {2374-7943},
	shorttitle = {Molecular {Transformer}},
	url = {https://doi.org/10.1021/acscentsci.9b00576},
	doi = {10.1021/acscentsci.9b00576},
	abstract = {Organic synthesis is one of the key stumbling blocks in medicinal chemistry. A necessary yet unsolved step in planning synthesis is solving the forward problem: Given reactants and reagents, predict the products. Similar to other work, we treat reaction prediction as a machine translation problem between simplified molecular-input line-entry system (SMILES) strings (a text-based representation) of reactants, reagents, and the products. We show that a multihead attention Molecular Transformer model outperforms all algorithms in the literature, achieving a top-1 accuracy above 90\% on a common benchmark data set. Molecular Transformer makes predictions by inferring the correlations between the presence and absence of chemical motifs in the reactant, reagent, and product present in the data set. Our model requires no handcrafted rules and accurately predicts subtle chemical transformations. Crucially, our model can accurately estimate its own uncertainty, with an uncertainty score that is 89\% accurate in terms of classifying whether a prediction is correct. Furthermore, we show that the model is able to handle inputs without a reactant–reagent split and including stereochemistry, which makes our method universally applicable.},
	number = {9},
	urldate = {2023-02-03},
	journal = {ACS Central Science},
	author = {Schwaller, Philippe and Laino, Teodoro and Gaudin, Théophile and Bolgar, Peter and Hunter, Christopher A. and Bekas, Costas and Lee, Alpha A.},
	month = sep,
	year = {2019},
	note = {Publisher: American Chemical Society},
	pages = {1572--1583},
}

@article{schwaller_molecular_2019-1,
	title = {Molecular {Transformer} - {A} {Model} for {Uncertainty}-{Calibrated} {Chemical} {Reaction} {Prediction}},
	volume = {5},
	issn = {2374-7943, 2374-7951},
	url = {http://arxiv.org/abs/1811.02633},
	doi = {10.1021/acscentsci.9b00576},
	abstract = {Organic synthesis is one of the key stumbling blocks in medicinal chemistry. A necessary yet unsolved step in planning synthesis is solving the forward problem: given reactants and reagents, predict the products. Similar to other work, we treat reaction prediction as a machine translation problem between SMILES strings of reactants-reagents and the products. We show that a multi-head attention Molecular Transformer model outperforms all algorithms in the literature, achieving a top-1 accuracy above 90\% on a common benchmark dataset. Our algorithm requires no handcrafted rules, and accurately predicts subtle chemical transformations. Crucially, our model can accurately estimate its own uncertainty, with an uncertainty score that is 89\% accurate in terms of classifying whether a prediction is correct. Furthermore, we show that the model is able to handle inputs without reactant-reagent split and including stereochemistry, which makes our method universally applicable.},
	number = {9},
	urldate = {2023-02-03},
	journal = {ACS Central Science},
	author = {Schwaller, Philippe and Laino, Teodoro and Gaudin, Théophile and Bolgar, Peter and Bekas, Costas and Lee, Alpha A.},
	month = sep,
	year = {2019},
	note = {arXiv:1811.02633 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Chemical Physics},
	pages = {1572--1583},
}

@article{qiu_pre-trained_2020,
	title = {Pre-trained {Models} for {Natural} {Language} {Processing}: {A} {Survey}},
	volume = {63},
	issn = {1674-7321, 1869-1900},
	shorttitle = {Pre-trained {Models} for {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/2003.08271},
	doi = {10.1007/s11431-020-1647-3},
	abstract = {Recently, the emergence of pre-trained models (PTMs) has brought natural language processing (NLP) to a new era. In this survey, we provide a comprehensive review of PTMs for NLP. We first briefly introduce language representation learning and its research progress. Then we systematically categorize existing PTMs based on a taxonomy with four perspectives. Next, we describe how to adapt the knowledge of PTMs to the downstream tasks. Finally, we outline some potential directions of PTMs for future research. This survey is purposed to be a hands-on guide for understanding, using, and developing PTMs for various NLP tasks.},
	number = {10},
	urldate = {2023-02-03},
	journal = {Science China Technological Sciences},
	author = {Qiu, Xipeng and Sun, Tianxiang and Xu, Yige and Shao, Yunfan and Dai, Ning and Huang, Xuanjing},
	month = oct,
	year = {2020},
	note = {arXiv:2003.08271 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {1872--1897},
}

@misc{bahdanau_neural_2016,
	title = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
	url = {http://arxiv.org/abs/1409.0473},
	doi = {10.48550/arXiv.1409.0473},
	abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	month = may,
	year = {2016},
	note = {arXiv:1409.0473 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{bommasani_opportunities_2022,
	title = {On the {Opportunities} and {Risks} of {Foundation} {Models}},
	url = {http://arxiv.org/abs/2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	note = {arXiv:2108.07258 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@misc{chung_scaling_2022,
	title = {Scaling {Instruction}-{Finetuned} {Language} {Models}},
	url = {http://arxiv.org/abs/2210.11416},
	abstract = {Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM 540B by a large margin (+9.4\% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2\% on five-shot MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
	month = dec,
	year = {2022},
	note = {arXiv:2210.11416 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{bommasani_opportunities_2022-1,
	title = {On the {Opportunities} and {Risks} of {Foundation} {Models}},
	url = {http://arxiv.org/abs/2108.07258},
	doi = {10.48550/arXiv.2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	note = {arXiv:2108.07258 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@misc{lin_survey_2021,
	title = {A {Survey} of {Transformers}},
	url = {http://arxiv.org/abs/2106.04554},
	doi = {10.48550/arXiv.2106.04554},
	abstract = {Transformers have achieved great success in many artificial intelligence fields, such as natural language processing, computer vision, and audio processing. Therefore, it is natural to attract lots of interest from academic and industry researchers. Up to the present, a great variety of Transformer variants (a.k.a. X-formers) have been proposed, however, a systematic and comprehensive literature review on these Transformer variants is still missing. In this survey, we provide a comprehensive review of various X-formers. We first briefly introduce the vanilla Transformer and then propose a new taxonomy of X-formers. Next, we introduce the various X-formers from three perspectives: architectural modification, pre-training, and applications. Finally, we outline some potential directions for future research.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Lin, Tianyang and Wang, Yuxin and Liu, Xiangyang and Qiu, Xipeng},
	month = jun,
	year = {2021},
	note = {arXiv:2106.04554 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{cremades_explaining_2023,
	title = {Explaining wall-bounded turbulence through deep learning},
	url = {http://arxiv.org/abs/2302.01250},
	doi = {10.48550/arXiv.2302.01250},
	abstract = {Despite its great scientific and technological importance, wall-bounded turbulence is an unresolved problem that requires new perspectives to be tackled. One of the key strategies has been to study interactions among the coherent structures in the flow. Such interactions are explored in this study for the first time using an explainable deep-learning method. The instantaneous velocity field in a turbulent channel is used to predict the velocity field in time through a convolutional neural network. The predicted flow is used to assess the importance of each structure for this prediction using a game-theoretic algorithm (SHapley Additive exPlanations). This work provides results in agreement with previous observations in the literature and extends them by quantifying the importance of the Reynolds-stress structures, finding a causal connection between these structures and the dynamics of the flow. The process, based on deep-learning explainability, has the potential to shed light on numerous fundamental phenomena of wall-bounded turbulence, including the objective definition of new types of flow structures.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Cremades, Andres and Hoyas, Sergio and Quintero, Pedro and Lellep, Martin and Linkmann, Moritz and Vinuesa, Ricardo},
	month = feb,
	year = {2023},
	note = {arXiv:2302.01250 [physics]},
	keywords = {Computer Science - Artificial Intelligence, Physics - Fluid Dynamics},
}

@article{higham_deep_2019,
	title = {Deep {Learning}: {An} {Introduction} for {Applied} {Mathematicians}},
	volume = {61},
	issn = {0036-1445},
	shorttitle = {Deep {Learning}},
	url = {https://epubs.siam.org/doi/10.1137/18M1165748},
	doi = {10.1137/18M1165748},
	abstract = {Multilayered artificial neural networks are becoming a pervasive tool in a host of application fields. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics, notably from calculus, approximation theory, optimization, and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and final year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: What is a deep neural network? How is a network trained? What is the stochastic gradient method? We illustrate the ideas with a short MATLAB code that sets up and trains a network. We also demonstrate the use of state-of-the-art software on a large scale image classification problem. We finish with references to the current literature.},
	number = {4},
	urldate = {2023-02-03},
	journal = {SIAM Review},
	author = {Higham, Catherine F. and Higham, Desmond J.},
	month = jan,
	year = {2019},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {65D15, 65K10, 68T05, back propagation, chain rule, convolution, image classification, neural network, overfitting, sigmoid, stochastic gradient method, supervised learning},
	pages = {860--891},
}

@article{ramadevi_chaotic_2022,
	title = {Chaotic {Time} {Series} {Forecasting} {Approaches} {Using} {Machine} {Learning} {Techniques}: {A} {Review}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-8994},
	shorttitle = {Chaotic {Time} {Series} {Forecasting} {Approaches} {Using} {Machine} {Learning} {Techniques}},
	url = {https://www.mdpi.com/2073-8994/14/5/955},
	doi = {10.3390/sym14050955},
	abstract = {Traditional statistical, physical, and correlation models for chaotic time series prediction have problems, such as low forecasting accuracy, computational time, and difficulty determining the neural network’s topologies. Over a decade, various researchers have been working with these issues; however, it remains a challenge. Therefore, this review paper presents a comprehensive review of significant research conducted on various approaches for chaotic time series forecasting, using machine learning techniques such as convolutional neural network (CNN), wavelet neural network (WNN), fuzzy neural network (FNN), and long short-term memory (LSTM) in the nonlinear systems aforementioned above. The paper also aims to provide issues of individual forecasting approaches for better understanding and up-to-date knowledge for chaotic time series forecasting. The comprehensive review table summarizes the works closely associated with the mentioned issues. It includes published year, research country, forecasting approach, application, forecasting parameters, performance measures, and collected data area in this sector. Future improvements and current studies in this field are broadly examined. In addition, possible future scopes and limitations are closely discussed.},
	language = {en},
	number = {5},
	urldate = {2023-02-03},
	journal = {Symmetry},
	author = {Ramadevi, Bhukya and Bingi, Kishore},
	month = may,
	year = {2022},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {chaos, forecasting, hydrological systems, neural networks, oil and gas, power and energy, prediction, time series},
	pages = {955},
}

@misc{kidger_neural_2021,
	title = {Neural {SDEs} as {Infinite}-{Dimensional} {GANs}},
	url = {http://arxiv.org/abs/2102.03657},
	abstract = {Stochastic differential equations (SDEs) are a staple of mathematical modelling of temporal dynamics. However, a fundamental limitation has been that such models have typically been relatively inflexible, which recent work introducing Neural SDEs has sought to solve. Here, we show that the current classical approach to fitting SDEs may be approached as a special case of (Wasserstein) GANs, and in doing so the neural and classical regimes may be brought together. The input noise is Brownian motion, the output samples are time-evolving paths produced by a numerical solver, and by parameterising a discriminator as a Neural Controlled Differential Equation (CDE), we obtain Neural SDEs as (in modern machine learning parlance) continuous-time generative time series models. Unlike previous work on this problem, this is a direct extension of the classical approach without reference to either prespecified statistics or density functions. Arbitrary drift and diffusions are admissible, so as the Wasserstein loss has a unique global minima, in the infinite data limit any SDE may be learnt. Example code has been made available as part of the {\textbackslash}texttt\{torchsde\} repository.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Kidger, Patrick and Foster, James and Li, Xuechen and Oberhauser, Harald and Lyons, Terry},
	month = may,
	year = {2021},
	note = {arXiv:2102.03657 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{mutze_asynchronous_2016,
	title = {An asynchronous leapfrog method {II}},
	url = {http://arxiv.org/abs/1311.6602},
	abstract = {A second order explicit one-step numerical method for the initial value problem of the general ordinary differential equation is proposed. It is obtained by natural modifications of the well-known leapfrog method, which is a second order, two-step, explicit method. According to the latter method, the input data for an integration step are two system states, which refer to different times. The usage of two states instead of a single one can be seen as the reason for the robustness of the method. Since the time step size thus is part of the step input data, it is complicated to change this size during the computation of a discrete trajectory. This is a serious drawback when one needs to implement automatic time step control. The proposed modification transforms one of the two input states into a velocity and thus gets rid of the time step dependency in the step input data. For these new step input data, the leapfrog method gives a unique prescription how to evolve them stepwise. The stability properties of this modified method are the same as for the original one: the set of absolute stability is the interval [-i,+i] on the imaginary axis. This implies exponential growth of trajectories in situations where the exact trajectory has an asymptote. By considering new evolution steps that are composed of two consecutive old evolution steps we can average over the velocities of the sub-steps and get an integrator with a much larger set of absolute stability, which is immune to the asymptote problem. The method is exemplified with the equation of motion of a one-dimensional non-linear oscillator describing the radial motion in the Kepler problem.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Mutze, Ulrich},
	month = apr,
	year = {2016},
	note = {arXiv:1311.6602 [math]},
	keywords = {65L04, 65L05, 65L07, 65L12, 65P10, 65Q10, Mathematics - Numerical Analysis},
}

@misc{kidger_efficient_2021,
	title = {Efficient and {Accurate} {Gradients} for {Neural} {SDEs}},
	url = {http://arxiv.org/abs/2105.13493},
	doi = {10.48550/arXiv.2105.13493},
	abstract = {Neural SDEs combine many of the best qualities of both RNNs and SDEs: memory efficient training, high-capacity function approximation, and strong priors on model space. This makes them a natural choice for modelling many types of temporal dynamics. Training a Neural SDE (either as a VAE or as a GAN) requires backpropagating through an SDE solve. This may be done by solving a backwards-in-time SDE whose solution is the desired parameter gradients. However, this has previously suffered from severe speed and accuracy issues, due to high computational cost and numerical truncation errors. Here, we overcome these issues through several technical innovations. First, we introduce the {\textbackslash}textit\{reversible Heun method\}. This is a new SDE solver that is {\textbackslash}textit\{algebraically reversible\}: eliminating numerical gradient errors, and the first such solver of which we are aware. Moreover it requires half as many function evaluations as comparable solvers, giving up to a \$1.98{\textbackslash}times\$ speedup. Second, we introduce the {\textbackslash}textit\{Brownian Interval\}: a new, fast, memory efficient, and exact way of sampling {\textbackslash}textit\{and reconstructing\} Brownian motion. With this we obtain up to a \$10.6{\textbackslash}times\$ speed improvement over previous techniques, which in contrast are both approximate and relatively slow. Third, when specifically training Neural SDEs as GANs (Kidger et al. 2021), we demonstrate how SDE-GANs may be trained through careful weight clipping and choice of activation function. This reduces computational cost (giving up to a \$1.87{\textbackslash}times\$ speedup) and removes the numerical truncation errors associated with gradient penalty. Altogether, we outperform the state-of-the-art by substantial margins, with respect to training speed, and with respect to classification, prediction, and MMD test metrics. We have contributed implementations of all of our techniques to the torchsde library to help facilitate their adoption.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Kidger, Patrick and Foster, James and Li, Xuechen and Lyons, Terry},
	month = oct,
	year = {2021},
	note = {arXiv:2105.13493 [cs, math, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Dynamical Systems, Statistics - Machine Learning},
}

@misc{kidger_efficient_2021-1,
	title = {Efficient and {Accurate} {Gradients} for {Neural} {SDEs}},
	url = {http://arxiv.org/abs/2105.13493},
	doi = {10.48550/arXiv.2105.13493},
	abstract = {Neural SDEs combine many of the best qualities of both RNNs and SDEs: memory efficient training, high-capacity function approximation, and strong priors on model space. This makes them a natural choice for modelling many types of temporal dynamics. Training a Neural SDE (either as a VAE or as a GAN) requires backpropagating through an SDE solve. This may be done by solving a backwards-in-time SDE whose solution is the desired parameter gradients. However, this has previously suffered from severe speed and accuracy issues, due to high computational cost and numerical truncation errors. Here, we overcome these issues through several technical innovations. First, we introduce the {\textbackslash}textit\{reversible Heun method\}. This is a new SDE solver that is {\textbackslash}textit\{algebraically reversible\}: eliminating numerical gradient errors, and the first such solver of which we are aware. Moreover it requires half as many function evaluations as comparable solvers, giving up to a \$1.98{\textbackslash}times\$ speedup. Second, we introduce the {\textbackslash}textit\{Brownian Interval\}: a new, fast, memory efficient, and exact way of sampling {\textbackslash}textit\{and reconstructing\} Brownian motion. With this we obtain up to a \$10.6{\textbackslash}times\$ speed improvement over previous techniques, which in contrast are both approximate and relatively slow. Third, when specifically training Neural SDEs as GANs (Kidger et al. 2021), we demonstrate how SDE-GANs may be trained through careful weight clipping and choice of activation function. This reduces computational cost (giving up to a \$1.87{\textbackslash}times\$ speedup) and removes the numerical truncation errors associated with gradient penalty. Altogether, we outperform the state-of-the-art by substantial margins, with respect to training speed, and with respect to classification, prediction, and MMD test metrics. We have contributed implementations of all of our techniques to the torchsde library to help facilitate their adoption.},
	urldate = {2023-02-02},
	publisher = {arXiv},
	author = {Kidger, Patrick and Foster, James and Li, Xuechen and Lyons, Terry},
	month = oct,
	year = {2021},
	note = {arXiv:2105.13493 [cs, math, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Dynamical Systems, Statistics - Machine Learning},
}

@article{bittner_l_1963,
	title = {L. {S}. {Pontryagin}, {V}. {G}. {Boltyanskii}, {R}. {V}. {Gamkrelidze}, {E}. {F}. {Mishechenko}, {The} {Mathematical} {Theory} of {Optimal} {Processes}. {VIII} + 360 {S}. {New} {York}/{London} 1962. {John} {Wiley} \& {Sons}. {Preis} 90/–},
	volume = {43},
	issn = {1521-4001},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/zamm.19630431023},
	doi = {10.1002/zamm.19630431023},
	language = {en},
	number = {10-11},
	urldate = {2023-02-02},
	journal = {ZAMM - Journal of Applied Mathematics and Mechanics / Zeitschrift für Angewandte Mathematik und Mechanik},
	author = {Bittner, L.},
	year = {1963},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/zamm.19630431023},
	pages = {514--515},
}

@misc{kidger_neural_2022,
	title = {On {Neural} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2202.02435},
	abstract = {The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.},
	urldate = {2023-02-02},
	publisher = {arXiv},
	author = {Kidger, Patrick},
	month = feb,
	year = {2022},
	note = {arXiv:2202.02435 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Classical Analysis and ODEs, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@misc{holzschuh_score_2023,
	title = {Score {Matching} via {Differentiable} {Physics}},
	url = {http://arxiv.org/abs/2301.10250},
	abstract = {Diffusion models based on stochastic differential equations (SDEs) gradually perturb a data distribution \$p({\textbackslash}mathbf\{x\})\$ over time by adding noise to it. A neural network is trained to approximate the score \${\textbackslash}nabla\_{\textbackslash}mathbf\{x\} {\textbackslash}log p\_t({\textbackslash}mathbf\{x\})\$ at time \$t\$, which can be used to reverse the corruption process. In this paper, we focus on learning the score field that is associated with the time evolution according to a physics operator in the presence of natural non-deterministic physical processes like diffusion. A decisive difference to previous methods is that the SDE underlying our approach transforms the state of a physical system to another state at a later time. For that purpose, we replace the drift of the underlying SDE formulation with a differentiable simulator or a neural network approximation of the physics. We propose different training strategies based on the so-called probability flow ODE to fit a training set of simulation trajectories and discuss their relation to the score matching objective. For inference, we sample plausible trajectories that evolve towards a given end state using the reverse-time SDE and demonstrate the competitiveness of our approach for different challenging inverse problems.},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Holzschuh, Benjamin J. and Vegetti, Simona and Thuerey, Nils},
	month = jan,
	year = {2023},
	note = {arXiv:2301.10250 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Data Analysis, Statistics and Probability},
}

@misc{trifan_intelligent_2021,
	title = {Intelligent {Resolution}: {Integrating} {Cryo}-{EM} with {AI}-driven {Multi}-resolution {Simulations} to {Observe} the {SARS}-{CoV}-2 {Replication}-{Transcription} {Machinery} in {Action}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Intelligent {Resolution}},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.09.463779v1},
	doi = {10.1101/2021.10.09.463779},
	abstract = {The severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) replication transcription complex (RTC) is a multi-domain protein responsible for replicating and transcribing the viral mRNA inside a human cell. Attacking RTC function with pharmaceutical compounds is a pathway to treating COVID-19. Conventional tools, e.g., cryo-electron microscopy and all-atom molecular dynamics (AAMD), do not provide sufficiently high resolution or timescale to capture important dynamics of this molecular machine. Consequently, we develop an innovative workflow that bridges the gap between these resolutions, using mesoscale fluctuating finite element analysis (FFEA) continuum simulations and a hierarchy of AI-methods that continually learn and infer features for maintaining consistency between AAMD and FFEA simulations. We leverage a multi-site distributed workflow manager to orchestrate AI, FFEA, and AAMD jobs, providing optimal resource utilization across HPC centers. Our study provides unprecedented access to study the SARS-CoV-2 RTC machinery, while providing general capability for AI-enabled multi-resolution simulations at scale.},
	language = {en},
	urldate = {2023-02-01},
	publisher = {bioRxiv},
	author = {Trifan, Anda and Gorgun, Defne and Li, Zongyi and Brace, Alexander and Zvyagin, Maxim and Ma, Heng and Clyde, Austin and Clark, David and Salim, Michael and Hardy, David J. and Burnley, Tom and Huang, Lei and McCalpin, John and Emani, Murali and Yoo, Hyenseung and Yin, Junqi and Tsaris, Aristeidis and Subbiah, Vishal and Raza, Tanveer and Liu, Jessica and Trebesch, Noah and Wells, Geoffrey and Mysore, Venkatesh and Gibbs, Thomas and Phillips, James and Chennubhotla, S. Chakra and Foster, Ian and Stevens, Rick and Anandkumar, Anima and Vishwanath, Venkatram and Stone, John E. and Tajkhorshid, Emad and Harris, Sarah A. and Ramanathan, Arvind},
	month = oct,
	year = {2021},
	note = {Pages: 2021.10.09.463779
Section: New Results},
}

@article{chen_universal_1995,
	title = {Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems},
	volume = {6},
	issn = {1941-0093},
	doi = {10.1109/72.392253},
	abstract = {The purpose of this paper is to investigate neural network capability systematically. The main results are: 1) every Tauber-Wiener function is qualified as an activation function in the hidden layer of a three-layered neural network; 2) for a continuous function in S'(R/sup 1/) to be a Tauber-Wiener function, the necessary and sufficient condition is that it is not a polynomial; 3) the capability of approximating nonlinear functionals defined on some compact set of a Banach space and nonlinear operators has been shown; and 4) the possibility by neural computation to approximate the output as a whole (not at a fixed point) of a dynamical system, thus identifying the system.{\textless}{\textgreater}},
	number = {4},
	journal = {IEEE Transactions on Neural Networks},
	author = {Chen, Tianping and Chen, Hong},
	month = jul,
	year = {1995},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Computer networks, H infinity control, Integral equations, Kernel, Mathematics, Neural networks, Nonlinear dynamical systems, Polynomials, Sufficient conditions, Sun},
	pages = {911--917},
}

@article{lu_deeponet_2021,
	title = {{DeepONet}: {Learning} nonlinear operators for identifying differential equations based on the universal approximation theorem of operators},
	volume = {3},
	issn = {2522-5839},
	shorttitle = {{DeepONet}},
	url = {http://arxiv.org/abs/1910.03193},
	doi = {10.1038/s42256-021-00302-5},
	abstract = {While it is widely known that neural networks are universal approximators of continuous functions, a less known and perhaps more powerful result is that a neural network with a single hidden layer can approximate accurately any nonlinear continuous operator. This universal approximation theorem is suggestive of the potential application of neural networks in learning nonlinear operators from data. However, the theorem guarantees only a small approximation error for a sufficient large network, and does not consider the important optimization and generalization errors. To realize this theorem in practice, we propose deep operator networks (DeepONets) to learn operators accurately and efficiently from a relatively small dataset. A DeepONet consists of two sub-networks, one for encoding the input function at a fixed number of sensors \$x\_i, i=1,{\textbackslash}dots,m\$ (branch net), and another for encoding the locations for the output functions (trunk net). We perform systematic simulations for identifying two types of operators, i.e., dynamic systems and partial differential equations, and demonstrate that DeepONet significantly reduces the generalization error compared to the fully-connected networks. We also derive theoretically the dependence of the approximation error in terms of the number of sensors (where the input function is defined) as well as the input function type, and we verify the theorem with computational results. More importantly, we observe high-order error convergence in our computational tests, namely polynomial rates (from half order to fourth order) and even exponential convergence with respect to the training dataset size.},
	number = {3},
	urldate = {2023-02-01},
	journal = {Nature Machine Intelligence},
	author = {Lu, Lu and Jin, Pengzhan and Karniadakis, George Em},
	month = mar,
	year = {2021},
	note = {arXiv:1910.03193 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {218--229},
}

@article{chen_approximations_1993,
	title = {Approximations of continuous functionals by neural networks with application to dynamic systems},
	volume = {4},
	issn = {1941-0093},
	doi = {10.1109/72.286886},
	abstract = {The paper gives several strong results on neural network representation in an explicit form. Under very mild conditions a functional defined on a compact set in C(a, b) or L/sup p/(a, b), spaces of infinite dimensions, can be approximated arbitrarily well by a neural network with one hidden layer. The results are a significant development beyond earlier work, where theorems of approximating continuous functions defined on a finite-dimensional real space by neural networks with one hidden layer were given. All the results are shown to be applicable to the approximation of the output of dynamic systems at any particular time.{\textless}{\textgreater}},
	number = {6},
	journal = {IEEE Transactions on Neural Networks},
	author = {Chen, T. and Chen, H.},
	month = nov,
	year = {1993},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Feedforward neural networks, Functional analysis, Kernel, Libraries, Mathematics, Neural networks, Nonlinear dynamical systems, Topology, Very large scale integration},
	pages = {910--918},
}

@article{lu_comprehensive_2022,
	title = {A comprehensive and fair comparison of two neural operators (with practical extensions) based on {FAIR} data},
	volume = {393},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782522001207},
	doi = {10.1016/j.cma.2022.114778},
	abstract = {Neural operators can learn nonlinear mappings between function spaces and offer a new simulation paradigm for real-time prediction of complex dynamics for realistic diverse applications as well as for system identification in science and engineering. Herein, we investigate the performance of two neural operators, which have shown promising results so far, and we develop new practical extensions that will make them more accurate and robust and importantly more suitable for industrial-complexity applications. The first neural operator, DeepONet, was published in 2019 (Lu et al., 2019), and its original architecture was based on the universal approximation theorem of Chen \& Chen (1995). The second one, named Fourier Neural Operator or FNO, was published in 2020 (Li et al., 2020), and it is based on parameterizing the integral kernel in the Fourier space. DeepONet is represented by a summation of products of neural networks (NNs), corresponding to the branch NN for the input function and the trunk NN for the output function; both NNs are general architectures, e.g., the branch NN can be replaced with a CNN or a ResNet. According to Kovachki et al. (2021), FNO in its continuous form can be viewed conceptually as a DeepONet with a specific architecture of the branch NN and a trunk NN represented by a trigonometric basis. In order to compare FNO with DeepONet computationally for realistic setups, we develop several extensions of FNO that can deal with complex geometric domains as well as mappings where the input and output function spaces are of different dimensions. We also develop an extended DeepONet with special features that provide inductive bias and accelerate training, and we present a faster implementation of DeepONet with cost comparable to the computational cost of FNO, which is based on the Fast Fourier Transform. We consider 16 different benchmarks to demonstrate the relative performance of the two neural operators, including instability wave analysis in hypersonic boundary layers, prediction of the vorticity field of a flapping airfoil, porous media simulations in complex-geometry domains, etc. We follow the guiding principles of FAIR (Findability, Accessibility, Interoperability, and Reusability) for scientific data management and stewardship. The performance of DeepONet and FNO is comparable for relatively simple settings, but for complex geometries the performance of FNO deteriorates greatly. We also compare theoretically the two neural operators and obtain similar error estimates for DeepONet and FNO under the same regularity assumptions.},
	language = {en},
	urldate = {2023-02-01},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Lu, Lu and Meng, Xuhui and Cai, Shengze and Mao, Zhiping and Goswami, Somdatta and Zhang, Zhongqiang and Karniadakis, George Em},
	month = apr,
	year = {2022},
	keywords = {Deep learning, DeepONet, FNO, Nonlinear mappings, Operator regression, Scientific machine learning},
	pages = {114778},
}

@misc{li_transformer_2022,
	title = {Transformer for {Partial} {Differential} {Equations}' {Operator} {Learning}},
	url = {http://arxiv.org/abs/2205.13671},
	abstract = {Data-driven learning of partial differential equations' solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions' values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed framework is competitive on standard benchmark problems and can flexibly be adapted to randomly sampled input.},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Li, Zijie and Meidani, Kazem and Farimani, Amir Barati},
	month = oct,
	year = {2022},
	note = {arXiv:2205.13671 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{li_transformer_2022-1,
	title = {Transformer for {Partial} {Differential} {Equations}' {Operator} {Learning}},
	url = {http://arxiv.org/abs/2205.13671},
	doi = {10.48550/arXiv.2205.13671},
	abstract = {Data-driven learning of partial differential equations' solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions' values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed framework is competitive on standard benchmark problems and can flexibly be adapted to randomly sampled input.},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Li, Zijie and Meidani, Kazem and Farimani, Amir Barati},
	month = oct,
	year = {2022},
	note = {arXiv:2205.13671 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{wang_when_2022,
	title = {When and why {PINNs} fail to train: {A} neural tangent kernel perspective},
	volume = {449},
	issn = {0021-9991},
	shorttitle = {When and why {PINNs} fail to train},
	url = {https://www.sciencedirect.com/science/article/pii/S002199912100663X},
	doi = {10.1016/j.jcp.2021.110768},
	abstract = {Physics-informed neural networks (PINNs) have lately received great attention thanks to their flexibility in tackling a wide range of forward and inverse problems involving partial differential equations. However, despite their noticeable empirical success, little is known about how such constrained neural networks behave during their training via gradient descent. More importantly, even less is known about why such models sometimes fail to train at all. In this work, we aim to investigate these questions through the lens of the Neural Tangent Kernel (NTK); a kernel that captures the behavior of fully-connected neural networks in the infinite width limit during training via gradient descent. Specifically, we derive the NTK of PINNs and prove that, under appropriate conditions, it converges to a deterministic kernel that stays constant during training in the infinite-width limit. This allows us to analyze the training dynamics of PINNs through the lens of their limiting NTK and find a remarkable discrepancy in the convergence rate of the different loss components contributing to the total training error. To address this fundamental pathology, we propose a novel gradient descent algorithm that utilizes the eigenvalues of the NTK to adaptively calibrate the convergence rate of the total training error. Finally, we perform a series of numerical experiments to verify the correctness of our theory and the practical effectiveness of the proposed algorithms. The data and code accompanying this manuscript are publicly available at https://github.com/PredictiveIntelligenceLab/PINNsNTK.},
	language = {en},
	urldate = {2023-01-30},
	journal = {Journal of Computational Physics},
	author = {Wang, Sifan and Yu, Xinling and Perdikaris, Paris},
	month = jan,
	year = {2022},
	keywords = {Gradient descent, Multi-task learning, Physics-informed neural networks, Scientific machine learning, Spectral bias},
	pages = {110768},
}

@misc{grover_flow-gan_2018,
	title = {Flow-{GAN}: {Combining} {Maximum} {Likelihood} and {Adversarial} {Learning} in {Generative} {Models}},
	shorttitle = {Flow-{GAN}},
	url = {http://arxiv.org/abs/1705.08868},
	doi = {10.48550/arXiv.1705.08868},
	abstract = {Adversarial learning of probabilistic models has recently emerged as a promising alternative to maximum likelihood. Implicit models such as generative adversarial networks (GAN) often generate better samples compared to explicit models trained by maximum likelihood. Yet, GANs sidestep the characterization of an explicit density which makes quantitative evaluations challenging. To bridge this gap, we propose Flow-GANs, a generative adversarial network for which we can perform exact likelihood evaluation, thus supporting both adversarial and maximum likelihood training. When trained adversarially, Flow-GANs generate high-quality samples but attain extremely poor log-likelihood scores, inferior even to a mixture model memorizing the training data; the opposite is true when trained by maximum likelihood. Results on MNIST and CIFAR-10 demonstrate that hybrid training can attain high held-out likelihoods while retaining visual fidelity in the generated samples.},
	urldate = {2023-01-27},
	publisher = {arXiv},
	author = {Grover, Aditya and Dhar, Manik and Ermon, Stefano},
	month = jan,
	year = {2018},
	note = {arXiv:1705.08868 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{weng_flow-based_2018,
	title = {Flow-based {Deep} {Generative} {Models}},
	url = {https://lilianweng.github.io/posts/2018-10-13-flow-models/},
	abstract = {So far, I’ve written about two types of generative models, GAN and VAE. Neither of them explicitly learns the probability density function of real data, \$p({\textbackslash}mathbf\{x\})\$ (where \${\textbackslash}mathbf\{x\} {\textbackslash}in {\textbackslash}mathcal\{D\}\$) — because it is really hard! Taking the generative model with latent variables as an example, \$p({\textbackslash}mathbf\{x\}) = {\textbackslash}int p({\textbackslash}mathbf\{x\}{\textbackslash}vert{\textbackslash}mathbf\{z\})p({\textbackslash}mathbf\{z\})d{\textbackslash}mathbf\{z\}\$ can hardly be calculated as it is intractable to go through all possible values of the latent code \${\textbackslash}mathbf\{z\}\$.
Flow-based deep generative models conquer this hard problem with the help of normalizing flows, a powerful statistics tool for density estimation.},
	language = {en},
	urldate = {2023-01-27},
	author = {Weng, Lilian},
	month = oct,
	year = {2018},
	note = {Section: posts},
}

@article{papamakarios_normalizing_2021,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	volume = {22},
	url = {https://jmlr.org/papers/volume22/19-1028/19-1028.pdf},
	abstract = {Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	year = {2021},
}

@article{kobyzev_normalizing_2021,
	title = {Normalizing {Flows}: {An} {Introduction} and {Review} of {Current} {Methods}},
	volume = {43},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Normalizing {Flows}},
	url = {http://arxiv.org/abs/1908.09257},
	doi = {10.1109/TPAMI.2020.2992934},
	abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
	number = {11},
	urldate = {2023-01-27},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kobyzev, Ivan and Prince, Simon J. D. and Brubaker, Marcus A.},
	month = nov,
	year = {2021},
	note = {arXiv:1908.09257 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {3964--3979},
}

@misc{dinh_nice_2015,
	title = {{NICE}: {Non}-linear {Independent} {Components} {Estimation}},
	shorttitle = {{NICE}},
	url = {http://arxiv.org/abs/1410.8516},
	abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
	urldate = {2023-01-27},
	publisher = {arXiv},
	author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
	month = apr,
	year = {2015},
	note = {arXiv:1410.8516 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{rezende_variational_2016,
	title = {Variational {Inference} with {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/1505.05770},
	doi = {10.48550/arXiv.1505.05770},
	abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
	urldate = {2023-01-27},
	publisher = {arXiv},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
	month = jun,
	year = {2016},
	note = {arXiv:1505.05770 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
}

@article{kempf_efficient_2005,
	title = {Efficient {Generation} of {Initial}- and {Inflow}-{Conditions} for {Transient} {Turbulent} {Flows} in {Arbitrary} {Geometries}},
	volume = {74},
	issn = {1386-6184, 1573-1987},
	url = {http://link.springer.com/10.1007/s10494-005-3140-8},
	doi = {10.1007/s10494-005-3140-8},
	abstract = {A method is presented to artiﬁcially generate initial conditions and transient inﬂowconditions for DNS and LES. It creates velocity ﬁelds that satisfy a given Reynolds-stress-tensor and length-scale. Compared to existing approaches, the new method features greater ﬂexibility, efﬁciency and applicability. It is well suited for the complex geometries and for the arbitrary grids that occur in technical applications. This is demonstrated in connection with the generation of initial data for an internal combustion engine. To assess the accuracy and efﬁciency of the new approach, it is applied to the test-case of a non-premixed jet-ﬂame, which is known to be sensitive to transient inﬂow-data.},
	language = {en},
	number = {1},
	urldate = {2023-01-26},
	journal = {Flow, Turbulence and Combustion formerly: Applied Scientific Research},
	author = {Kempf, Andreas and Klein, Markus and Janicka, Johannes},
	month = jan,
	year = {2005},
	pages = {67--84},
}

@article{kempf_efficient_2012,
	title = {An efficient, parallel low-storage implementation of {Klein}’s turbulence generator for {LES} and {DNS}},
	volume = {60},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793012000825},
	doi = {10.1016/j.compfluid.2012.02.027},
	abstract = {Klein’s popular method for the generation of ‘artificial’ inflow turbulence for application in LES and DNS computations has been modified to reduce computational effort and memory requirement, and improve parallel scaling performance. An exponential filter kernel is applied to a field of random noise, where the width of the filter is chosen such that a prescribed integral length-scale is recovered from the filtered field. We generate the random noise as a unique function of physical time and space in logical coordinates, such that any parallel process may generate the same random number for any location within the domain. The filtering operation is also decomposed into the three coordinate directions. These modifications reduce the required computational effort by several orders of magnitude, drastically decrease the memory footprint of the method, and negate any inter-process communication. It thus becomes possible to generate non-periodic pseudo-turbulent inflow conditions at very little cost for computation and code implementation.},
	language = {en},
	urldate = {2023-01-26},
	journal = {Computers \& Fluids},
	author = {Kempf, A. M. and Wysocki, S. and Pettit, M.},
	month = may,
	year = {2012},
	keywords = {Artificial Turbulence, DNS, Efficient, Inflow Conditions, LES, Low-storage, Parallel},
	pages = {58--60},
}

@misc{guastoni_deep_2023,
	title = {Deep reinforcement learning for turbulent drag reduction in channel flows},
	url = {http://arxiv.org/abs/2301.09889},
	doi = {10.48550/arXiv.2301.09889},
	abstract = {We introduce a reinforcement learning (RL) environment to design and benchmark control strategies aimed at reducing drag in turbulent fluid flows enclosed in a channel. The environment provides a framework for computationally-efficient, parallelized, high-fidelity fluid simulations, ready to interface with established RL agent programming interfaces. This allows for both testing existing deep reinforcement learning (DRL) algorithms against a challenging task, and advancing our knowledge of a complex, turbulent physical system that has been a major topic of research for over two centuries, and remains, even today, the subject of many unanswered questions. The control is applied in the form of blowing and suction at the wall, while the observable state is configurable, allowing to choose different variables such as velocity and pressure, in different locations of the domain. Given the complex nonlinear nature of turbulent flows, the control strategies proposed so far in the literature are physically grounded, but too simple. DRL, by contrast, enables leveraging the high-dimensional data that can be sampled from flow simulations to design advanced control strategies. In an effort to establish a benchmark for testing data-driven control strategies, we compare opposition control, a state-of-the-art turbulence-control strategy from the literature, and a commonly-used DRL algorithm, deep deterministic policy gradient. Our results show that DRL leads to 43\% and 46\% drag reduction in a minimal and a larger channel (at a friction Reynolds number of 180), respectively, outperforming the classical opposition control by around 20 percentage points.},
	urldate = {2023-01-26},
	publisher = {arXiv},
	author = {Guastoni, L. and Rabault, J. and Schlatter, P. and Azizpour, H. and Vinuesa, R.},
	month = jan,
	year = {2023},
	note = {arXiv:2301.09889 [physics]},
	keywords = {Physics - Fluid Dynamics},
}

@misc{peebles_scalable_2022,
	title = {Scalable {Diffusion} {Models} with {Transformers}},
	url = {http://arxiv.org/abs/2212.09748},
	doi = {10.48550/arXiv.2212.09748},
	abstract = {We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops -- through increased transformer depth/width or increased number of input tokens -- consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL/2 models outperform all prior diffusion models on the class-conditional ImageNet 512x512 and 256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.},
	urldate = {2023-01-26},
	publisher = {arXiv},
	author = {Peebles, William and Xie, Saining},
	month = dec,
	year = {2022},
	note = {arXiv:2212.09748 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{papamakarios_normalizing_2021,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	url = {http://arxiv.org/abs/1912.02762},
	doi = {10.48550/arXiv.1912.02762},
	abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
	urldate = {2023-01-26},
	publisher = {arXiv},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	month = apr,
	year = {2021},
	note = {arXiv:1912.02762 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{papamakarios_normalizing_nodate,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	abstract = {Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.},
	language = {en},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
}

@article{papamakarios_normalizing_nodate-1,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	abstract = {Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.},
	language = {en},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
}

@misc{chadebec_geometric_2022,
	title = {A {Geometric} {Perspective} on {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/2209.07370},
	doi = {10.48550/arXiv.2209.07370},
	abstract = {This paper introduces a new interpretation of the Variational Autoencoder framework by taking a fully geometric point of view. We argue that vanilla VAE models unveil naturally a Riemannian structure in their latent space and that taking into consideration those geometrical aspects can lead to better interpolations and an improved generation procedure. This new proposed sampling method consists in sampling from the uniform distribution deriving intrinsically from the learned Riemannian latent space and we show that using this scheme can make a vanilla VAE competitive and even better than more advanced versions on several benchmark datasets. Since generative models are known to be sensitive to the number of training samples we also stress the method's robustness in the low data regime.},
	urldate = {2023-01-25},
	publisher = {arXiv},
	author = {Chadebec, Clément and Allassonnière, Stéphanie},
	month = nov,
	year = {2022},
	note = {arXiv:2209.07370 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{su_adversarial_nodate,
	title = {Adversarial {Noise} {Injection} for {Learned} {Turbulence} {Simulations}},
	abstract = {Machine learning is a powerful way to learn effective dynamics of physical simulations, and has seen great interest from the community in recent years. Recent work has shown that deep neural networks trained in an end-to-end manner seem capable of learning to predict turbulent dynamics on coarse grids more accurately than classical solvers. All these works point out that adding Gaussian noise to the input during training is indispensable to improve the stability and roll-out performance of learned simulators, as an alternative to training through multiple steps. In this work we bring in insights from robust machine learning and propose to inject adversarial noise to move machine learning systems a step further towards improving generalization in ML-assisted physical simulations. We advocate that training our models on these worst case perturbation instead of model-agnostic Gaussian noise might lead to better rollout and hope that adversarial noise injection becomes a standard tool for ML-based simulations. We show experimentally in the 2D-setting that for certain classes of turbulence adversarial noise can help stabilize model rollouts, maintain a lower loss and preserve other physical properties such as energy. In addition, we identify a potentially more challenging task, driven 2D-turbulence and show that while none of the noise-based attempts significantly improve rollout, adversarial noise helps.},
	language = {en},
	author = {Su, Jingtong and Kempe, Julia and Fielding, Drummond and Tsilivis, Nikolaos and Cranmer, Miles and Ho, Shirley},
}

@misc{kingma_auto-encoding_2022,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2023-01-25},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2022},
	note = {arXiv:1312.6114 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{kingma_auto-encoding_2022-1,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2023-01-25},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2022},
	note = {arXiv:1312.6114 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{heinz_review_2020,
	title = {A review of hybrid {RANS}-{LES} methods for turbulent flows: {Concepts} and applications},
	volume = {114},
	issn = {0376-0421},
	shorttitle = {A review of hybrid {RANS}-{LES} methods for turbulent flows},
	url = {https://www.sciencedirect.com/science/article/pii/S0376042119301861},
	doi = {10.1016/j.paerosci.2019.100597},
	abstract = {The hybridization of Reynolds-averaged Navier-Stokes (RANS) and large eddy simulation (LES) methods is seen to be the most promising way to efficiently deal with separated turbulent flow simulations relevant to aerospace and wind energy applications. Characteristic conceptual features of popular hybrid RANS-LES and their applications to hill-type and airfoil flow including flow separation are described. Conceptual questions on existing hybrid RANS-LES are pointed out and ways to overcome these problems are presented. Further analyses show that corresponding novel hybrid RANS-LES methods generalize and improve existing methods. The discussions reveal, in particular, the great value of physical and mathematical realizability constraints for the substantial improvement of simulation methods.},
	language = {en},
	urldate = {2023-01-24},
	journal = {Progress in Aerospace Sciences},
	author = {Heinz, Stefan},
	month = apr,
	year = {2020},
	keywords = {Computational methods for turbulent flow simulations, Hybridization of RANS and LES methods, Review of concepts and applications to separated turbulent flows},
	pages = {100597},
}

@misc{weng_autoencoder_2018,
	title = {From {Autoencoder} to {Beta}-{VAE}},
	url = {https://lilianweng.github.io/posts/2018-08-12-vae/},
	abstract = {[Updated on 2019-07-18: add a section on VQ-VAE \& VQ-VAE-2.]  [Updated on 2019-07-26: add a section on TD-VAE.] 
Autocoder is invented to reconstruct high-dimensional data using a neural network model with a narrow bottleneck layer in the middle (oops, this is probably not true for Variational Autoencoder, and we will investigate it in details in later sections). A nice byproduct is dimension reduction: the bottleneck layer captures a compressed latent encoding.},
	language = {en},
	urldate = {2023-01-24},
	author = {Weng, Lilian},
	month = aug,
	year = {2018},
	note = {Section: posts},
}

@inproceedings{higgins_beta-vae_2022,
	title = {beta-{VAE}: {Learning} {Basic} {Visual} {Concepts} with a {Constrained} {Variational} {Framework}},
	shorttitle = {beta-{VAE}},
	url = {https://openreview.net/forum?id=Sy2fzU9gl},
	abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter beta that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that beta-VAE with appropriately tuned beta {\textgreater} 1 qualitatively outperforms VAE (beta = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also significantly outperforms all baselines quantitatively. Unlike InfoGAN, beta-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter, which can be directly optimised through a hyper parameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
	language = {en},
	urldate = {2023-01-24},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	month = jul,
	year = {2022},
}

@article{higgins_-vae_2017,
	title = {β-{VAE}: {LEARNING} {BASIC} {VISUAL} {CONCEPTS} {WITH} {A} {CONSTRAINED} {VARIATIONAL} {FRAMEWORK}},
	abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artiﬁcial intelligence that is able to learn and reason in the same way that humans do. We introduce β-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modiﬁcation of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter β that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that β-VAE with appropriately tuned β {\textgreater} 1 qualitatively outperforms VAE (β = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also signiﬁcantly outperforms all baselines quantitatively. Unlike InfoGAN, β-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter β, which can be directly optimised through a hyperparameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
	language = {en},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	year = {2017},
}

@misc{kingma_auto-encoding_2022-2,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	doi = {10.48550/arXiv.1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2022},
	note = {arXiv:1312.6114 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{burgess_understanding_2018,
	title = {Understanding disentangling in \${\textbackslash}beta\$-{VAE}},
	url = {http://arxiv.org/abs/1804.03599},
	abstract = {We present new intuitions and theoretical assessments of the emergence of disentangled representation in variational autoencoders. Taking a rate-distortion theory perspective, we show the circumstances under which representations aligned with the underlying generative factors of variation of data emerge when optimising the modified ELBO bound in \${\textbackslash}beta\$-VAE, as training progresses. From these insights, we propose a modification to the training regime of \${\textbackslash}beta\$-VAE, that progressively increases the information capacity of the latent code during training. This modification facilitates the robust learning of disentangled representations in \${\textbackslash}beta\$-VAE, without the previous trade-off in reconstruction accuracy.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Burgess, Christopher P. and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
	month = apr,
	year = {2018},
	note = {arXiv:1804.03599 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{brophy_generative_2021,
	title = {Generative adversarial networks in time series: {A} survey and taxonomy},
	shorttitle = {Generative adversarial networks in time series},
	url = {http://arxiv.org/abs/2107.11098},
	abstract = {Generative adversarial networks (GANs) studies have grown exponentially in the past few years. Their impact has been seen mainly in the computer vision field with realistic image and video manipulation, especially generation, making significant advancements. While these computer vision advances have garnered much attention, GAN applications have diversified across disciplines such as time series and sequence generation. As a relatively new niche for GANs, fieldwork is ongoing to develop high quality, diverse and private time series data. In this paper, we review GAN variants designed for time series related applications. We propose a taxonomy of discrete-variant GANs and continuous-variant GANs, in which GANs deal with discrete time series and continuous time series data. Here we showcase the latest and most popular literature in this field; their architectures, results, and applications. We also provide a list of the most popular evaluation metrics and their suitability across applications. Also presented is a discussion of privacy measures for these GANs and further protections and directions for dealing with sensitive data. We aim to frame clearly and concisely the latest and state-of-the-art research in this area and their applications to real-world technologies.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Brophy, Eoin and Wang, Zhengwei and She, Qi and Ward, Tomas},
	month = jul,
	year = {2021},
	note = {arXiv:2107.11098 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{wang_generative_2022,
	title = {Generative {Adversarial} {Networks} in {Computer} {Vision}: {A} {Survey} and {Taxonomy}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Generative {Adversarial} {Networks} in {Computer} {Vision}},
	url = {https://dl.acm.org/doi/10.1145/3439723},
	doi = {10.1145/3439723},
	abstract = {Generative adversarial networks (GANs) have been extensively studied in the past few years. Arguably their most significant impact has been in the area of computer vision where great advances have been made in challenges such as plausible image generation, image-to-image translation, facial attribute manipulation, and similar domains. Despite the significant successes achieved to date, applying GANs to real-world problems still poses significant challenges, three of which we focus on here. These are as follows: (1) the generation of high quality images, (2) diversity of image generation, and (3) stabilizing training. Focusing on the degree to which popular GAN technologies have made progress against these challenges, we provide a detailed review of the state-of-the-art in GAN-related research in the published scientific literature. We further structure this review through a convenient taxonomy we have adopted based on variations in GAN architectures and loss functions. While several reviews for GANs have been presented to date, none have considered the status of this field based on their progress toward addressing practical challenges relevant to computer vision. Accordingly, we review and critically discuss the most popular architecture-variant, and loss-variant GANs, for tackling these challenges. Our objective is to provide an overview as well as a critical analysis of the status of GAN research in terms of relevant progress toward critical computer vision application requirements. As we do this we also discuss the most compelling applications in computer vision in which GANs have demonstrated considerable success along with some suggestions for future research directions. Codes related to the GAN-variants studied in this work is summarized on https://github.com/sheqi/GAN\_Review.},
	language = {en},
	number = {2},
	urldate = {2023-01-24},
	journal = {ACM Computing Surveys},
	author = {Wang, Zhengwei and She, Qi and Ward, Tomás E.},
	month = mar,
	year = {2022},
	pages = {1--38},
}

@misc{brock_large_2019,
	title = {Large {Scale} {GAN} {Training} for {High} {Fidelity} {Natural} {Image} {Synthesis}},
	url = {http://arxiv.org/abs/1809.11096},
	abstract = {Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple "truncation trick," allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.6.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
	month = feb,
	year = {2019},
	note = {arXiv:1809.11096 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{karras_progressive_2018,
	title = {Progressive {Growing} of {GANs} for {Improved} {Quality}, {Stability}, and {Variation}},
	url = {http://arxiv.org/abs/1710.10196},
	doi = {10.48550/arXiv.1710.10196},
	abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024{\textasciicircum}2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	month = feb,
	year = {2018},
	note = {arXiv:1710.10196 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{arjovsky_wasserstein_2017,
	title = {Wasserstein {GAN}},
	url = {http://arxiv.org/abs/1701.07875},
	doi = {10.48550/arXiv.1701.07875},
	abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
	month = dec,
	year = {2017},
	note = {arXiv:1701.07875 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{gulrajani_improved_2017,
	title = {Improved {Training} of {Wasserstein} {GANs}},
	url = {http://arxiv.org/abs/1704.00028},
	doi = {10.48550/arXiv.1704.00028},
	abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
	month = dec,
	year = {2017},
	note = {arXiv:1704.00028 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{li_mmd_2017,
	title = {{MMD} {GAN}: {Towards} {Deeper} {Understanding} of {Moment} {Matching} {Network}},
	shorttitle = {{MMD} {GAN}},
	url = {http://arxiv.org/abs/1705.08584},
	abstract = {Generative moment matching network (GMMN) is a deep generative model that differs from Generative Adversarial Network (GAN) by replacing the discriminator in GAN with a two-sample test based on kernel maximum mean discrepancy (MMD). Although some theoretical guarantees of MMD have been studied, the empirical performance of GMMN is still not as competitive as that of GAN on challenging and large benchmark datasets. The computational efficiency of GMMN is also less desirable in comparison with GAN, partially due to its requirement for a rather large batch size during the training. In this paper, we propose to improve both the model expressiveness of GMMN and its computational efficiency by introducing adversarial kernel learning techniques, as the replacement of a fixed Gaussian kernel in the original GMMN. The new approach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN. The new distance measure in MMD GAN is a meaningful loss that enjoys the advantage of weak topology and can be optimized via gradient descent with relatively small batch sizes. In our evaluation on multiple benchmark datasets, including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GAN significantly outperforms GMMN, and is competitive with other representative GAN works.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Li, Chun-Liang and Chang, Wei-Cheng and Cheng, Yu and Yang, Yiming and Póczos, Barnabás},
	month = nov,
	year = {2017},
	note = {arXiv:1705.08584 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	urldate = {2023-01-23},
	publisher = {arXiv},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv:1406.2661 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{srivastava_unsupervised_2016,
	title = {Unsupervised {Learning} of {Video} {Representations} using {LSTMs}},
	url = {http://arxiv.org/abs/1502.04681},
	doi = {10.48550/arXiv.1502.04681},
	abstract = {We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations ("percepts") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},
	month = jan,
	year = {2016},
	note = {arXiv:1502.04681 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{tan_efficientnetv2_2021,
	title = {{EfficientNetV2}: {Smaller} {Models} and {Faster} {Training}},
	shorttitle = {{EfficientNetV2}},
	url = {http://arxiv.org/abs/2104.00298},
	abstract = {This paper introduces EfficientNetV2, a new family of convolutional networks that have faster training speed and better parameter efficiency than previous models. To develop this family of models, we use a combination of training-aware neural architecture search and scaling, to jointly optimize training speed and parameter efficiency. The models were searched from the search space enriched with new ops such as Fused-MBConv. Our experiments show that EfficientNetV2 models train much faster than state-of-the-art models while being up to 6.8x smaller. Our training can be further sped up by progressively increasing the image size during training, but it often causes a drop in accuracy. To compensate for this accuracy drop, we propose to adaptively adjust regularization (e.g., dropout and data augmentation) as well, such that we can achieve both fast training and good accuracy. With progressive learning, our EfficientNetV2 significantly outperforms previous models on ImageNet and CIFAR/Cars/Flowers datasets. By pretraining on the same ImageNet21k, our EfficientNetV2 achieves 87.3\% top-1 accuracy on ImageNet ILSVRC2012, outperforming the recent ViT by 2.0\% accuracy while training 5x-11x faster using the same computing resources. Code will be available at https://github.com/google/automl/tree/master/efficientnetv2.},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {Tan, Mingxing and Le, Quoc V.},
	month = jun,
	year = {2021},
	note = {arXiv:2104.00298 [cs]
version: 3},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	doi = {10.48550/arXiv.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv:1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{deepmind_deepmind_2020,
	title = {{DeepMind} x {UCL} {\textbar} {Deep} {Learning} {Lectures} {\textbar} 5/12 {\textbar}  {Optimization} for {Machine} {Learning}},
	url = {https://www.youtube.com/watch?v=kVU8zTI-Od0},
	urldate = {2023-01-17},
	author = {{DeepMind}},
	month = jun,
	year = {2020},
}

@misc{sun_optimization_2019,
	title = {Optimization for deep learning: theory and algorithms},
	shorttitle = {Optimization for deep learning},
	url = {http://arxiv.org/abs/1912.08957},
	doi = {10.48550/arXiv.1912.08957},
	abstract = {When and why can a neural network be successfully trained? This article provides an overview of optimization algorithms and theory for training neural networks. First, we discuss the issue of gradient explosion/vanishing and the more general issue of undesirable spectrum, and then discuss practical solutions including careful initialization and normalization methods. Second, we review generic optimization methods used in training neural networks, such as SGD, adaptive gradient methods and distributed methods, and theoretical results for these algorithms. Third, we review existing research on the global issues of neural network training, including results on bad local minima, mode connectivity, lottery ticket hypothesis and infinite-width analysis.},
	urldate = {2023-01-17},
	publisher = {arXiv},
	author = {Sun, Ruoyu},
	month = dec,
	year = {2019},
	note = {arXiv:1912.08957 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	url = {http://www.deeplearningbook.org},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
}

@misc{noauthor_deep_nodate,
	title = {Deep {Learning}},
	url = {https://www.deeplearningbook.org/},
	urldate = {2023-01-16},
}

@book{murphy_probabilistic_2022,
	title = {Probabilistic {Machine} {Learning}: {An} {Introduction}},
	url = {probml.ai},
	publisher = {MIT Press},
	author = {Murphy, Kevin Patrick},
	year = {2022},
}

@misc{noauthor_notitle_nodate,
	url = {https://probml.github.io/pml-book/book1.html},
	urldate = {2023-01-16},
}

@misc{noauthor_machine_nodate,
	title = {Machine {Learning}},
	url = {https://mitpress.mit.edu/9780262018029/machine-learning/},
	abstract = {A comprehensive introduction to machine learning that uses probabilistic models and inference as a unifying approach.Today's Web-enabled deluge of electronic...},
	language = {en-US},
	urldate = {2023-01-16},
	journal = {MIT Press},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@book{stevens_deep_2020,
	address = {Shelter Island, NY},
	title = {Deep learning with {PyTorch}},
	isbn = {978-1-61729-526-3},
	language = {en},
	publisher = {Manning Publications Co},
	author = {Stevens, Eli and Antiga, Luca and Viehmann, Thomas},
	year = {2020},
	keywords = {Artificial intelligence, Machine learning, Neural networks (Computer science), Python (Computer program language)},
}

@misc{noauthor_doi101016jphysd200510007_nodate,
	title = {doi:10.1016/j.physd.2005.10.007 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {doi},
	url = {https://reader.elsevier.com/reader/sd/pii/S0167278905004446?token=61A0BF641C6B56C29E06AEB24C361E2DC95E12550B1E7E7AABB28EBE430FD6FEE84A0DA71CA54B5F6E13FFD0ED73F3A8&originRegion=eu-west-1&originCreation=20230112125416},
	language = {en},
	urldate = {2023-01-13},
	doi = {10.1016/j.physd.2005.10.007},
}

@article{aguerre_implementation_2019,
	title = {Implementation and validation of a {Lagrangian} spray model using experimental data of the {ECN} {Spray} {G} injector},
	volume = {190},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793019301811},
	doi = {10.1016/j.compfluid.2019.06.004},
	abstract = {This work presents a Lagrangian-based spray model and its implementation in the context of the Finite Volume Method. Gas and liquid phases are coupled using an implicit strategy which is based on a splitting of the temporal derivatives of the gaseous phase. The atomization processes are represented with a hybrid strategy which combines the Huh--Gosman, Kelvin--Helmholtz and Rayleigh--Taylor models. A sensitivity analysis of these models is proposed where the influence of specific parameters is evaluated. To calibrate the model, the numerical results are compared with experimental data of the Engine Combustion Network Spray G injector. An acceptable performance of the numerical results is obtained promoting the current numerical strategy as a robust and reliable option to simulate the Spray G and others multi-hole injectors. The results of this work allow a better understanding of the influence of the model parameters on the global spray development which is valuable and currently scarce information to aid to future improvements.},
	language = {en},
	urldate = {2023-01-13},
	journal = {Computers \& Fluids},
	author = {Aguerre, Horacio J. and Nigro, Norberto M.},
	month = aug,
	year = {2019},
	keywords = {Discrete droplet method, Finite volume method, Hybrid atomization model, Spray G, Spray modelling},
	pages = {30--48},
}

@article{shadden_definition_2005,
	title = {Definition and properties of {Lagrangian} coherent structures from finite-time {Lyapunov} exponents in two-dimensional aperiodic flows},
	volume = {212},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278905004446},
	doi = {10.1016/j.physd.2005.10.007},
	abstract = {This paper develops the theory and computation of Lagrangian Coherent Structures (LCS), which are defined as ridges of Finite-Time Lyapunov Exponent (FTLE) fields. These ridges can be seen as finite-time mixing templates. Such a framework is common in dynamical systems theory for autonomous and time-periodic systems, in which examples of LCS are stable and unstable manifolds of fixed points and periodic orbits. The concepts defined in this paper remain applicable to flows with arbitrary time dependence and, in particular, to flows that are only defined (computed or measured) over a finite interval of time. Previous work has demonstrated the usefulness of FTLE fields and the associated LCSs for revealing the Lagrangian behavior of systems with general time dependence. However, ridges of the FTLE field need not be exactly advected with the flow. The main result of this paper is an estimate for the flux across an LCS, which shows that the flux is small, and in most cases negligible, for well-defined LCSs or those that rotate at a speed comparable to the local Eulerian velocity field, and are computed from FTLE fields with a sufficiently long integration time. Under these hypotheses, the structures represent nearly invariant manifolds even in systems with arbitrary time dependence. The results are illustrated on three examples. The first is a simplified dynamical model of a double-gyre flow. The second is surface current data collected by high-frequency radar stations along the coast of Florida and the third is unsteady separation over an airfoil. In all cases, the existence of LCSs governs the transport and it is verified numerically that the flux of particles through these distinguished lines is indeed negligible.},
	language = {en},
	number = {3},
	urldate = {2023-01-12},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Shadden, Shawn C. and Lekien, Francois and Marsden, Jerrold E.},
	month = dec,
	year = {2005},
	keywords = {Coherent structures, Direct and finite-time Lyapunov exponents, Mixing, Transport barriers},
	pages = {271--304},
}

@misc{zou_l-hydra_2023,
	title = {L-{HYDRA}: {Multi}-{Head} {Physics}-{Informed} {Neural} {Networks}},
	shorttitle = {L-{HYDRA}},
	url = {http://arxiv.org/abs/2301.02152},
	doi = {10.48550/arXiv.2301.02152},
	abstract = {We introduce multi-head neural networks (MH-NNs) to physics-informed machine learning, which is a type of neural networks (NNs) with all nonlinear hidden layers as the body and multiple linear output layers as multi-head. Hence, we construct multi-head physics-informed neural networks (MH-PINNs) as a potent tool for multi-task learning (MTL), generative modeling, and few-shot learning for diverse problems in scientific machine learning (SciML). MH-PINNs connect multiple functions/tasks via a shared body as the basis functions as well as a shared distribution for the head. The former is accomplished by solving multiple tasks with MH-PINNs with each head independently corresponding to each task, while the latter by employing normalizing flows (NFs) for density estimate and generative modeling. To this end, our method is a two-stage method, and both stages can be tackled with standard deep learning tools of NNs, enabling easy implementation in practice. MH-PINNs can be used for various purposes, such as approximating stochastic processes, solving multiple tasks synergistically, providing informative prior knowledge for downstream few-shot learning tasks such as meta-learning and transfer learning, learning representative basis functions, and uncertainty quantification. We demonstrate the effectiveness of MH-PINNs in five benchmarks, investigating also the possibility of synergistic learning in regression analysis. We name the open-source code "Lernaean Hydra" (L-HYDRA), since this mythical creature possessed many heads for performing important multiple tasks, as in the proposed method.},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {Zou, Zongren and Karniadakis, George Em},
	month = jan,
	year = {2023},
	note = {arXiv:2301.02152 [physics]},
	keywords = {34F05, 62M45, 65L99, 65M99, 65N99, Computer Science - Machine Learning, Physics - Computational Physics},
}

@misc{sanchez-gonzalez_learning_2020,
	title = {Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}},
	url = {http://arxiv.org/abs/2002.09405},
	abstract = {Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term "Graph Network-based Simulators" (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W.},
	month = sep,
	year = {2020},
	note = {arXiv:2002.09405 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@misc{lam_graphcast_2022,
	title = {{GraphCast}: {Learning} skillful medium-range global weather forecasting},
	shorttitle = {{GraphCast}},
	url = {http://arxiv.org/abs/2212.12794},
	abstract = {We introduce a machine-learning (ML)-based weather simulator--called "GraphCast"--which outperforms the most accurate deterministic operational medium-range weather forecasting system in the world, as well as all previous ML baselines. GraphCast is an autoregressive model, based on graph neural networks and a novel high-resolution multi-scale mesh representation, which we trained on historical weather data from the European Centre for Medium-Range Weather Forecasts (ECMWF)'s ERA5 reanalysis archive. It can make 10-day forecasts, at 6-hour time intervals, of five surface variables and six atmospheric variables, each at 37 vertical pressure levels, on a 0.25-degree latitude-longitude grid, which corresponds to roughly 25 x 25 kilometer resolution at the equator. Our results show GraphCast is more accurate than ECMWF's deterministic operational forecasting system, HRES, on 90.0\% of the 2760 variable and lead time combinations we evaluated. GraphCast also outperforms the most accurate previous ML-based weather forecasting model on 99.2\% of the 252 targets it reported. GraphCast can generate a 10-day forecast (35 gigabytes of data) in under 60 seconds on Cloud TPU v4 hardware. Unlike traditional forecasting methods, ML-based forecasting scales well with data: by training on bigger, higher quality, and more recent data, the skill of the forecasts can improve. Together these results represent a key step forward in complementing and improving weather modeling with ML, open new opportunities for fast, accurate forecasting, and help realize the promise of ML-based simulation in the physical sciences.},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Pritzel, Alexander and Ravuri, Suman and Ewalds, Timo and Alet, Ferran and Eaton-Rosen, Zach and Hu, Weihua and Merose, Alexander and Hoyer, Stephan and Holland, George and Stott, Jacklynn and Vinyals, Oriol and Mohamed, Shakir and Battaglia, Peter},
	month = dec,
	year = {2022},
	note = {arXiv:2212.12794 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
}

@incollection{ranjan_machine_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine {Learning} {Strategy} for {Subgrid} {Modeling} of {Turbulent} {Combustion} {Using} {Linear} {Eddy} {Mixing} {Based} {Tabulation}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_7},
	abstract = {This chapter describes the use of machine learning (ML) algorithms with the linear-eddy mixing (LEM) based tabulation for modeling of subgrid turbulence-chemistry interaction. The focus will be on the use of artificial neural network (ANN), particularly, supervised deep learning (DL) techniques within the finite-rate kinetics framework. We discuss the accuracy and efficiency aspects of two different strategies, where LEM based tabulation is used in both of them. While in the first approach, referred to as LANN-LES, the subgrid reaction-rateSubgrid reaction rate term is obtained efficiently using ANN in the conventional LEMLES framework, in the other approach referred to as TANN-LES, the filtered reaction rate terms are obtained using ANN. First, we assess the implications of the employed network architecture, and the associated hyperparameters, such as the amount of training and test data, epoch, optimizer, learning rate, sample size, etc. Afterward, the effectiveness of the two strategies is examined by comparing with conventional LES and LEMLES approaches by considering canonical premixed and non-premixed configurations. Finally, we describe the key challenges and future outlook of the use of ML based subgrid modelling within the finite-rate kinetics framework.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Ranjan, R. and Panchal, A. and Karpe, S. and Menon, S.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_7},
	pages = {175--208},
}

@book{swaminathan_machine_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	volume = {44},
	isbn = {978-3-031-16247-3 978-3-031-16248-0},
	shorttitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}},
	url = {https://link.springer.com/10.1007/978-3-031-16248-0},
	language = {en},
	urldate = {2023-01-11},
	publisher = {Springer International Publishing},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0},
	keywords = {Big Data Analysis, Combustion Modelling, Combustion Simulations, Data-driven modelling, Deep learning, Dimensionality reduction, Machine Learning, Neural Networks, Open Access, Physics-based modelling, Reactive molecular dynamics, Reduced-order modelling, Simulations of reacting flows, Thermoacoustics and its modelling, Turbulent Combustion},
}

@incollection{iavarone_use_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {On the {Use} of {Machine} {Learning} for {Subgrid} {Scale} {Filtered} {Density} {Function} {Modelling} in {Large} {Eddy} {Simulations} of {Combustion} {Systems}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_8},
	abstract = {The application of machine learning algorithms to model subgrid-scale filtered density functions (FDFs), required to estimate filtered reaction rates for Large Eddy Simulation (LES) of chemically reacting flows, is discussed in this chapter. Three test cases, i.e., a low-swirl premixed methane-air flame, a MILD combustion of methane-air mixtures, and a kerosene spray turbulent flame, are presented. The scalar statistics in these test cases may not be easily represented using the commonly used presumed shapes for modeling FDFs of mixture fraction and progress variable. Hence, the use of ML methods is explored. Particularly, deep neural network (DNN) to infer joint FDFs of mixture fraction and progress variable is reviewed here. The Direct Numerical Simulation (DNS) datasets employed to train the DNNs in each test case are described. The DNN performances are shown and compared to typical presumed probability density function (PDF) models. Finally, this chapter examines the advantages and caveats of the DNN-based approach.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Iavarone, S. and Yang, H. and Li, Z. and Chen, Z. X. and Swaminathan, N.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_8},
	pages = {209--243},
}

@incollection{aktulga_machine_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine {Learning} {Techniques} in {Reactive} {Atomistic} {Simulations}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_2},
	abstract = {This chapter describes recent advances in the use of machine learning techniques in reactive atomistic simulations. In particular, it provides an overview of techniques used in training force fields with closed form potentials, developing machine-learning-based potentials, use of machine learning in accelerating the simulation process, and analytics techniques for drawing insights from simulation results. The chapter covers basic machine learning techniques, training procedures and loss functions, issues of off-line and in-lined training, and associated numerical and algorithmic issues. The chapter highlights key outstanding challenges, promising approaches, and potential future developments. While the chapter relies on reactive atomistic simulations to motivate models and methods, these are more generally applicable to other modeling paradigms for reactive flows.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Aktulga, H. and Ravindra, V. and Grama, A. and Pandit, S.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_2},
	pages = {15--52},
}

@incollection{nikolaou_machine-learning_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine-{Learning} for {Stress} {Tensor} {Modelling} in {Large} {Eddy} {Simulation}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_4},
	abstract = {The accurate modelling of the unresolved stress tensor is particularly important for Large Eddy Simulations (LES) of turbulent flows. This term affects the transfer of energy from the largest to the smallest scales and vice versa, thus controlling the evolution of the flow field-in reacting flows, the flow field transports scalar fields such as mass fractions and temperature both of which control the species production and destruction rates. A large number of models have been developed in past years for the stress tensor in incompressible and non-reacting flows. A common characteristic of the majority of the classical models is that simplifying assumptions are typically involved in their derivation which limits their predictive ability. At the same time, various tunable parameters appear in the relevant closures whose value depends on the flow geometry/configuration/spatial location, and which require careful regularisation. Data-driven methods for the stress tensor is an emerging alternative modelling approach which may help to circumvent the above issues, and in recent studies several such models were developed and evaluated. This chapter discusses the modelling problem, presents some of the most popular algebraic models, and reviews some recent advances on data-driven methods.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Nikolaou, Z. M. and Minamoto, Y. and Chrysostomou, C. and Vervisch, L.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_4},
	pages = {89--116},
}

@incollection{zdybal_reduced-order_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Reduced-{Order} {Modeling} of {Reacting} {Flows} {Using} {Data}-{Driven} {Approaches}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_9},
	abstract = {Data-driven modeling of complex dynamical systems is becoming increasingly popular across various domains of science and engineering. This is thanks to advances in numerical computing, which provides high fidelity data, and to algorithm development in data science and machine learning. Simulations of multicomponent reacting flows can particularly profit from data-based reduced-order modeling (ROM). The original system of coupled partial differential equations that describes a reacting flow is often large due to high number of chemical species involved. While the datasets from reacting flow simulation have high state-space dimensionality, they also exhibit attracting low-dimensional manifolds (LDMs). Data-driven approaches can be used to obtain and parameterize these LDMs. Evolving the reacting system using a smaller number of parameters can yield substantial model reduction and savings in computational cost. In this chapter, we review recent advances in ROM of turbulent reacting flows. We demonstrate the entire ROM workflow with a particular focus on obtaining the training datasets and data science and machine learning techniques such as dimensionality reduction and nonlinear regression. We present recent results from ROM-based simulations of experimentally measured Sandia flames D and F. We also delineate a few remaining challenges and possible future directions to address them. This chapter is accompanied by illustrative examples using the recently developed Python software, PCAfold. The software can be used to obtain, analyze and improve low-dimensional data representations. The examples provided herein can be helpful to students and researchers learning to apply dimensionality reduction, manifold approaches and nonlinear regression to their problems. The Jupyter notebook with the examples shown in this chapter can be found on GitHub at https://github.com/kamilazdybal/ROM-of-reacting-flows-Springer.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Zdybał, K. and Malik, M. R. and Coussement, A. and Sutherland, J. C. and Parente, A.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_9},
	pages = {245--278},
}

@incollection{echekki_machine_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine {Learning} for {Combustion} {Chemistry}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_5},
	abstract = {Machine learning provides a set of new tools for the analysis, reduction and acceleration of combustion chemistry. The implementation of such tools is not new. However, with the emerging techniques of deep learning, renewed interest in implementing machine learning is fast growing. In this chapter, we illustrate applications of machine learning in understanding chemistry, learning reaction rates and reaction mechanisms and in accelerating chemistry integration.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Echekki, T. and Farooq, A. and Ihme, M. and Sarathy, S. M.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_5},
	pages = {117--147},
}

@incollection{xing_deep_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Deep {Convolutional} {Neural} {Networks} for {Subgrid}-{Scale} {Flame} {Wrinkling} {Modeling}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_6},
	abstract = {Subgrid-scale flame wrinkling is a key unclosed quantity for premixed turbulent combustion models in large eddy simulations. Due to the geometrical and multi-scale nature of flame wrinkling, convolutional neural networks are good candidates for data-driven modeling of flame wrinkling. This chapter presents how a deep convolutional neural network called a U-Net is trained to predict the total flame surface density from the resolved progress variable. Supervised training is performed on a database of filtered and downsampled direct numerical simulation fields. In an a priori evaluation on a slot burner configuration, the network outperforms classical dynamic models. In closing, challenges regarding the ability of deep convolutional networks to generalize to unseen configurations and their practical deployment with fluid solvers are discussed.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Xing, V. and Lapeyre, C. J.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_6},
	pages = {149--174},
}

@incollection{bode_ai_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {{AI} {Super}-{Resolution}: {Application} to {Turbulence} and {Combustion}},
	isbn = {978-3-031-16248-0},
	shorttitle = {{AI} {Super}-{Resolution}},
	url = {https://doi.org/10.1007/978-3-031-16248-0_10},
	abstract = {This article summarizes and discusses recent developments with respect to artificial intelligence (AI) super-resolution as a subfilter model for large-eddy simulations. The focus is on the application of physics-informed enhanced super-resolution generative adversarial networks (PIESRGANs) for subfilter closure in turbulence and combustion applications. A priori and a posteriori results are presented for various applications, ranging from decaying turbulence to finite-rate chemistry flows. The high accuracy of AI super-resolution-based subfilter models is emphasized, and advantages and shortcoming are described.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Bode, M.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_10},
	pages = {279--305},
}

@incollection{juniper_machine_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine {Learning} for {Thermoacoustics}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_11},
	abstract = {This chapter demonstrates three promising ways to combine machine learning with physics-based modelling in order to model, forecast, and avoid thermoacoustic instability. The first method assimilates experimental data into candidate physics-based models and is demonstrated on a Rijke tube. This uses Bayesian inference to select the most likely model. This turns qualitatively-accurate models into quantitatively-accurate models that can extrapolate, which can be combined powerfully with automated design. The second method assimilates experimental data into level set numerical simulations of a premixed bunsen flame and a bluff-body stabilized flame. This uses either an Ensemble Kalman filter, which requires no prior simulation but is slow, or a Bayesian Neural Network Ensemble, which is fast but requires prior simulation. This method deduces the simulations’ parameters that best reproduce the data and quantifies their uncertainties. The third method recognises precursors of thermoacoustic instability from pressure measurements. It is demonstrated on a turbulent bunsen flame, an industrial fuel spray nozzle, and full scale aeroplane engines. With this method, Bayesian Neural Network Ensembles determine how far each system is from instability. The trained BayNNEs out-perform physics-based methods on a given system. This method will be useful for practical avoidance of thermoacoustic instability.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Juniper, Matthew P.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_11},
	pages = {307--337},
}

@incollection{swaminathan_introduction_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Introduction},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_1},
	abstract = {The annual data published by IEA is analysed to get a projection for the combustion share in total primary energy supply for the world. This projection clearly identifies that more than 60\% of world total primary energy supply will come from combustion based sources even in the year of 2110 despite an aggressive shift towards renewables. Hence, improving and searching for greener combustion technologies would be beneficial for addressing global warming. Computational approaches play an important role in this search. The large eddy simulation equations are presented and discussed. Potential terms which are amenable for using machine learning algorithms are identified as a prelude to later chapters of this volume.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Swaminathan, N. and Parente, A.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_1},
	pages = {1--14},
}

@incollection{shead_novel_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {A {Novel} {In} {Situ} {Machine} {Learning} {Framework} for {Intelligent} {Data} {Capture} and {Event} {Detection}},
	isbn = {978-3-031-16248-0},
	url = {https://doi.org/10.1007/978-3-031-16248-0_3},
	abstract = {We present a novel framework for automatically detecting spatial and temporal events of interest in situ while running high performance computing (HPC) simulations. The new framework – composed from signature, measure, and decision building blocks with well-defined semantics – is tailored for parallel and distributed computing, has bounded communication and storage requirements, is generalizable to a variety of applications, and operates in an unsupervised fashion. We demonstrate the efficacy of our framework on several cases spanning scientific domains and applications of event detection: optimized input/output (I/O) in computational fluid dynamics simulations, detecting events that can lead to irreversible climate changes in simulations of polar ice sheets, and identifying optimal space-time subregions for projection-based model reduction. Additionally, we demonstrate the scalability of our framework using a HPC combustion application on the Cori supercomputer at the National Energy Research Scientific Computing Center (NERSC).},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	publisher = {Springer International Publishing},
	author = {Shead, T. M. and Tezaur, I. K. and Davis IV, W. L. and Carlson, M. L. and Dunlavy, D. M. and Parish, E. J. and Blonigan, P. J. and Tencer, J. and Rizzi, F. and Kolla, H.},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0_3},
	pages = {53--87},
}

@book{swaminathan_machine_2023-1,
	address = {Cham},
	series = {Lecture {Notes} in {Energy}},
	title = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}: {ML} and {Combustion}},
	volume = {44},
	isbn = {978-3-031-16247-3 978-3-031-16248-0},
	shorttitle = {Machine {Learning} and {Its} {Application} to {Reacting} {Flows}},
	url = {https://link.springer.com/10.1007/978-3-031-16248-0},
	language = {en},
	urldate = {2023-01-06},
	publisher = {Springer International Publishing},
	editor = {Swaminathan, Nedunchezhian and Parente, Alessandro},
	year = {2023},
	doi = {10.1007/978-3-031-16248-0},
}

@article{thelen_comprehensive_2022,
	title = {A comprehensive review of digital twin — part 1: modeling and twinning enabling technologies},
	volume = {65},
	issn = {1615-147X, 1615-1488},
	shorttitle = {A comprehensive review of digital twin — part 1},
	url = {https://link.springer.com/10.1007/s00158-022-03425-4},
	doi = {10.1007/s00158-022-03425-4},
	abstract = {As an emerging technology in the era of Industry 4.0, digital twin is gaining unprecedented attention because of its promise to further optimize process design, quality control, health monitoring, decision and policy making, and more, by comprehensively modeling the physical world as a group of interconnected digital models. In a two-part series of papers, we examine the fundamental role of different modeling techniques, twinning enabling technologies, and uncertainty quantification and optimization methods commonly used in digital twins. This first paper presents a thorough literature review of digital twin trends across many disciplines currently pursuing this area of research. Then, digital twin modeling and twinning enabling technologies are further analyzed by classifying them into two main categories: physical-to-virtual, and virtual-to-physical, based on the direction in which data flows. Finally, this paper provides perspectives on the trajectory of digital twin technology over the next decade, and introduces a few emerging areas of research which will likely be of great use in future digital twin research. In part two of this review, the role of uncertainty quantification and optimization are discussed, a battery digital twin is demonstrated, and more perspectives on the future of digital twin are shared. Code and preprocessed data for generating all the results and figures presented in the battery digital twin case study in part 2 of this review are available on Github.},
	language = {en},
	number = {12},
	urldate = {2022-12-29},
	journal = {Structural and Multidisciplinary Optimization},
	author = {Thelen, Adam and Zhang, Xiaoge and Fink, Olga and Lu, Yan and Ghosh, Sayan and Youn, Byeng D. and Todd, Michael D. and Mahadevan, Sankaran and Hu, Chao and Hu, Zhen},
	month = dec,
	year = {2022},
	pages = {354},
}

@book{tennekes_first_1972,
	title = {A {First} {Course} in {Turbulence}},
	url = {https://mitpress.mit.edu/9780262536301/a-first-course-in-turbulence/},
	abstract = {This is the first book specifically designed to offer the student a smooth transitionary course between elementary fluid dynamics (which gives only last-minu...},
	language = {en-US},
	urldate = {2022-12-23},
	author = {Tennekes, Henk and Lumley, John},
	year = {1972},
}

@article{reynolds_iv_1895,
	title = {{IV}. {On} the dynamical theory of incompressible viscous fluids and the determination of the criterion {\textbar} {Philosophical} {Transactions} of the {Royal} {Society} of {London}. ({A}.)},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.1895.0004},
	urldate = {2022-12-23},
	author = {Reynolds, Osborne},
	year = {1895},
}

@misc{watson_novel_2022,
	title = {Novel {View} {Synthesis} with {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2210.04628},
	doi = {10.48550/arXiv.2210.04628},
	abstract = {We present 3DiM, a diffusion model for 3D novel view synthesis, which is able to translate a single input view into consistent and sharp completions across many views. The core component of 3DiM is a pose-conditional image-to-image diffusion model, which takes a source view and its pose as inputs, and generates a novel view for a target pose as output. 3DiM can generate multiple views that are 3D consistent using a novel technique called stochastic conditioning. The output views are generated autoregressively, and during the generation of each novel view, one selects a random conditioning view from the set of available views at each denoising step. We demonstrate that stochastic conditioning significantly improves the 3D consistency of a naive sampler for an image-to-image diffusion model, which involves conditioning on a single fixed view. We compare 3DiM to prior work on the SRN ShapeNet dataset, demonstrating that 3DiM's generated completions from a single view achieve much higher fidelity, while being approximately 3D consistent. We also introduce a new evaluation methodology, 3D consistency scoring, to measure the 3D consistency of a generated object by training a neural field on the model's output views. 3DiM is geometry free, does not rely on hyper-networks or test-time optimization for novel view synthesis, and allows a single model to easily scale to a large number of scenes.},
	urldate = {2022-12-05},
	publisher = {arXiv},
	author = {Watson, Daniel and Chan, William and Martin-Brualla, Ricardo and Ho, Jonathan and Tagliasacchi, Andrea and Norouzi, Mohammad},
	month = oct,
	year = {2022},
	note = {arXiv:2210.04628 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning},
}

@misc{dockhorn_score-based_2022,
	title = {Score-{Based} {Generative} {Modeling} with {Critically}-{Damped} {Langevin} {Diffusion}},
	url = {http://arxiv.org/abs/2112.07068},
	abstract = {Score-based generative models (SGMs) have demonstrated remarkable synthesis quality. SGMs rely on a diffusion process that gradually perturbs the data towards a tractable distribution, while the generative model learns to denoise. The complexity of this denoising task is, apart from the data distribution itself, uniquely determined by the diffusion process. We argue that current SGMs employ overly simplistic diffusions, leading to unnecessarily complex denoising processes, which limit generative modeling performance. Based on connections to statistical mechanics, we propose a novel critically-damped Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior performance. CLD can be interpreted as running a joint diffusion in an extended space, where the auxiliary variables can be considered "velocities" that are coupled to the data variables as in Hamiltonian dynamics. We derive a novel score matching objective for CLD and show that the model only needs to learn the score function of the conditional distribution of the velocity given data, an easier task than learning scores of the data directly. We also derive a new sampling scheme for efficient synthesis from CLD-based diffusion models. We find that CLD outperforms previous SGMs in synthesis quality for similar network architectures and sampling compute budgets. We show that our novel sampler for CLD significantly outperforms solvers such as Euler--Maruyama. Our framework provides new insights into score-based denoising diffusion models and can be readily used for high-resolution image synthesis. Project page and code: https://nv-tlabs.github.io/CLD-SGM.},
	urldate = {2022-12-05},
	publisher = {arXiv},
	author = {Dockhorn, Tim and Vahdat, Arash and Kreis, Karsten},
	month = mar,
	year = {2022},
	note = {arXiv:2112.07068 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{zhao_incremental_2022,
	title = {Incremental {Fourier} {Neural} {Operator}},
	url = {http://arxiv.org/abs/2211.15188},
	doi = {10.48550/arXiv.2211.15188},
	abstract = {Recently, neural networks have proven their impressive ability to solve partial differential equations (PDEs). Among them, Fourier neural operator (FNO) has shown success in learning solution operators for highly non-linear problems such as turbulence flow. FNO is discretization-invariant, where it can be trained on low-resolution data and generalizes to problems with high-resolution. This property is related to the low-pass filters in FNO, where only a limited number of frequency modes are selected to propagate information. However, it is still a challenge to select an appropriate number of frequency modes and training resolution for different PDEs. Too few frequency modes and low-resolution data hurt generalization, while too many frequency modes and high-resolution data are computationally expensive and lead to over-fitting. To this end, we propose Incremental Fourier Neural Operator (IFNO), which augments both the frequency modes and data resolution incrementally during training. We show that IFNO achieves better generalization (around 15\% reduction on testing L2 loss) while reducing the computational cost by 35\%, compared to the standard FNO. In addition, we observe that IFNO follows the behavior of implicit regularization in FNO, which explains its excellent generalization ability.},
	urldate = {2022-12-01},
	publisher = {arXiv},
	author = {Zhao, Jiawei and George, Robert Joseph and Zhang, Yifei and Li, Zongyi and Anandkumar, Anima},
	month = nov,
	year = {2022},
	note = {arXiv:2211.15188 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{zheng_fast_2022,
	title = {Fast {Sampling} of {Diffusion} {Models} via {Operator} {Learning}},
	url = {http://arxiv.org/abs/2211.13449},
	abstract = {Diffusion models have found widespread adoption in various areas. However, sampling from them is slow because it involves emulating a reverse process with hundreds-to-thousands of network evaluations. Inspired by the success of neural operators in accelerating differential equations solving, we approach this problem by solving the underlying neural differential equation from an operator learning perspective. We examine probability flow ODE trajectories in diffusion models and observe a compact energy spectrum that can be learned efficiently in Fourier space. With this insight, we propose diffusion Fourier neural operator (DFNO) with temporal convolution in Fourier space to parameterize the operator that maps initial condition to the solution trajectory, which is a continuous function in time. DFNO can be applied to any diffusion model and generate high-quality samples in one model forward call. Our method achieves the state-of-the-art FID of 4.72 on CIFAR-10 using only one model evaluation.},
	urldate = {2022-12-01},
	publisher = {arXiv},
	author = {Zheng, Hongkai and Nie, Weili and Vahdat, Arash and Azizzadenesheli, Kamyar and Anandkumar, Anima},
	month = nov,
	year = {2022},
	note = {arXiv:2211.13449 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{lemos_rediscovering_2022,
	title = {Rediscovering orbital mechanics with machine learning},
	url = {http://arxiv.org/abs/2202.02306},
	abstract = {We present an approach for using machine learning to automatically discover the governing equations and hidden properties of real physical systems from observations. We train a "graph neural network" to simulate the dynamics of our solar system's Sun, planets, and large moons from 30 years of trajectory data. We then use symbolic regression to discover an analytical expression for the force law implicitly learned by the neural network, which our results showed is equivalent to Newton's law of gravitation. The key assumptions that were required were translational and rotational equivariance, and Newton's second and third laws of motion. Our approach correctly discovered the form of the symbolic force law. Furthermore, our approach did not require any assumptions about the masses of planets and moons or physical constants. They, too, were accurately inferred through our methods. Though, of course, the classical law of gravitation has been known since Isaac Newton, our result serves as a validation that our method can discover unknown laws and hidden properties from observed data. More broadly this work represents a key step toward realizing the potential of machine learning for accelerating scientific discovery.},
	urldate = {2022-12-01},
	publisher = {arXiv},
	author = {Lemos, Pablo and Jeffrey, Niall and Cranmer, Miles and Ho, Shirley and Battaglia, Peter},
	month = feb,
	year = {2022},
	note = {arXiv:2202.02306 [astro-ph]},
	keywords = {Astrophysics - Earth and Planetary Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Machine Learning},
}

@misc{shi_machine_2022,
	title = {Machine {Learning} {Accelerated} {PDE} {Backstepping} {Observers}},
	url = {http://arxiv.org/abs/2211.15044},
	abstract = {State estimation is important for a variety of tasks, from forecasting to substituting for unmeasured states in feedback controllers. Performing real-time state estimation for PDEs using provably and rapidly converging observers, such as those based on PDE backstepping, is computationally expensive and in many cases prohibitive. We propose a framework for accelerating PDE observer computations using learning-based approaches that are much faster while maintaining accuracy. In particular, we employ the recently-developed Fourier Neural Operator (FNO) to learn the functional mapping from the initial observer state and boundary measurements to the state estimate. By employing backstepping observer gains for previously-designed observers with particular convergence rate guarantees, we provide numerical experiments that evaluate the increased computational efficiency gained with FNO. We consider the state estimation for three benchmark PDE examples motivated by applications: first, for a reaction-diffusion (parabolic) PDE whose state is estimated with an exponential rate of convergence; second, for a parabolic PDE with exact prescribed-time estimation; and, third, for a pair of coupled first-order hyperbolic PDEs that modeling traffic flow density and velocity. The ML-accelerated observers trained on simulation data sets for these PDEs achieves up to three orders of magnitude improvement in computational speed compared to classical methods. This demonstrates the attractiveness of the ML-accelerated observers for real-time state estimation and control.},
	urldate = {2022-12-01},
	publisher = {arXiv},
	author = {Shi, Yuanyuan and Li, Zongyi and Yu, Huan and Steeves, Drew and Anandkumar, Anima and Krstic, Miroslav},
	month = nov,
	year = {2022},
	note = {arXiv:2211.15044 [cs, eess]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Systems and Control},
}

@article{graham_web_2016,
	title = {A {Web} services accessible database of turbulent channel flow and its use for testing a new integral wall model for {LES}},
	volume = {17},
	url = {https://doi.org/10.1080/14685248.2015.1088656},
	doi = {10.1080/14685248.2015.1088656},
	abstract = {The output from a direct numerical simulation (DNS) of turbulent channel flow at Reτ ≈ 1000 is used to construct a publicly and Web services accessible, spatio-temporal database for this flow. The simulated channel has a size of 8πh × 2h × 3πh, where h is the channel half-height. Data are stored at 2048 × 512 × 1536 spatial grid points for a total of 4000 time samples every 5 time steps of the DNS. These cover an entire channel flow-through time, i.e. the time it takes to traverse the entire channel length 8πh at the mean velocity of the bulk flow. Users can access the database through an interface that is based on the Web services model and perform numerical experiments on the slightly over 100 terabytes (TB) DNS data on their remote platforms, such as laptops or local desktops. Additional technical details about the pressure calculation, database interpolation, and differentiation tools are provided in several appendices. As a sample application of the channel flow database, we use it to conduct an a-priori test of a recently introduced integral wall model for large eddy simulation of wall-bounded turbulent flow. The results are compared with those of the equilibrium wall model, showing the strengths of the integral wall model as compared to the equilibrium model.},
	number = {2},
	urldate = {2022-11-29},
	journal = {Journal of Turbulence},
	author = {Graham, J. and Kanov, K. and Yang, X. I. A. and Lee, M. and Malaya, N. and Lalescu, C. C. and Burns, R. and Eyink, G. and Szalay, A. and Moser, R. D. and Meneveau, C.},
	month = feb,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/14685248.2015.1088656},
	keywords = {Direct numerical simulation, large eddy simulation, turbulence modelling: subgrid-scale, turbulent boundary layers},
	pages = {181--215},
}

@misc{belbute-peres_hyperpinn_2021,
	title = {{HyperPINN}: {Learning} parameterized differential equations with physics-informed hypernetworks},
	shorttitle = {{HyperPINN}},
	url = {http://arxiv.org/abs/2111.01008},
	abstract = {Many types of physics-informed neural network models have been proposed in recent years as approaches for learning solutions to differential equations. When a particular task requires solving a differential equation at multiple parameterizations, this requires either re-training the model, or expanding its representation capacity to include the parameterization -- both solution that increase its computational cost. We propose the HyperPINN, which uses hypernetworks to learn to generate neural networks that can solve a differential equation from a given parameterization. We demonstrate with experiments on both a PDE and an ODE that this type of model can lead to neural network solutions to differential equations that maintain a small size, even when learning a family of solutions over a parameter space.},
	urldate = {2022-11-17},
	publisher = {arXiv},
	author = {Belbute-Peres, Filipe de Avila and Chen, Yi-fan and Sha, Fei},
	month = oct,
	year = {2021},
	note = {arXiv:2111.01008 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@misc{tzen_neural_2019,
	title = {Neural {Stochastic} {Differential} {Equations}: {Deep} {Latent} {Gaussian} {Models} in the {Diffusion} {Limit}},
	shorttitle = {Neural {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1905.09883},
	doi = {10.48550/arXiv.1905.09883},
	abstract = {In deep latent Gaussian models, the latent variable is generated by a time-inhomogeneous Markov chain, where at each time step we pass the current state through a parametric nonlinear map, such as a feedforward neural net, and add a small independent Gaussian perturbation. This work considers the diffusion limit of such models, where the number of layers tends to infinity, while the step size and the noise variance tend to zero. The limiting latent object is an It{\textbackslash}{\textasciicircum}o diffusion process that solves a stochastic differential equation (SDE) whose drift and diffusion coefficient are implemented by neural nets. We develop a variational inference framework for these {\textbackslash}textit\{neural SDEs\} via stochastic automatic differentiation in Wiener space, where the variational approximations to the posterior are obtained by Girsanov (mean-shift) transformation of the standard Wiener process and the computation of gradients is based on the theory of stochastic flows. This permits the use of black-box SDE solvers and automatic differentiation for end-to-end inference. Experimental results with synthetic data are provided.},
	urldate = {2022-11-17},
	publisher = {arXiv},
	author = {Tzen, Belinda and Raginsky, Maxim},
	month = oct,
	year = {2019},
	note = {arXiv:1905.09883 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{nichol_improved_2021,
	title = {Improved {Denoising} {Diffusion} {Probabilistic} {Models}},
	url = {http://arxiv.org/abs/2102.09672},
	doi = {10.48550/arXiv.2102.09672},
	abstract = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code at https://github.com/openai/improved-diffusion},
	urldate = {2022-11-17},
	publisher = {arXiv},
	author = {Nichol, Alex and Dhariwal, Prafulla},
	month = feb,
	year = {2021},
	note = {arXiv:2102.09672 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{kingma_variational_2022,
	title = {Variational {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2107.00630},
	abstract = {Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the variance of the resulting VLB estimator, leading to faster optimization. Combining these advances with architectural improvements, we obtain state-of-the-art likelihoods on image density estimation benchmarks, outperforming autoregressive models that have dominated these benchmarks for many years, with often significantly faster optimization. In addition, we show how to use the model as part of a bits-back compression scheme, and demonstrate lossless compression rates close to the theoretical optimum. Code is available at https://github.com/google-research/vdm .},
	urldate = {2022-11-17},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Salimans, Tim and Poole, Ben and Ho, Jonathan},
	month = jun,
	year = {2022},
	note = {arXiv:2107.00630 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{karras_elucidating_2022,
	title = {Elucidating the {Design} {Space} of {Diffusion}-{Based} {Generative} {Models}},
	url = {http://arxiv.org/abs/2206.00364},
	doi = {10.48550/arXiv.2206.00364},
	abstract = {We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.},
	urldate = {2022-11-17},
	publisher = {arXiv},
	author = {Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
	month = oct,
	year = {2022},
	note = {arXiv:2206.00364 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{song_denoising_2022,
	title = {Denoising {Diffusion} {Implicit} {Models}},
	url = {http://arxiv.org/abs/2010.02502},
	doi = {10.48550/arXiv.2010.02502},
	abstract = {Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that DDIMs can produce high quality samples \$10 {\textbackslash}times\$ to \$50 {\textbackslash}times\$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	month = oct,
	year = {2022},
	note = {arXiv:2010.02502 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{ho_imagen_2022,
	title = {Imagen {Video}: {High} {Definition} {Video} {Generation} with {Diffusion} {Models}},
	shorttitle = {Imagen {Video}},
	url = {http://arxiv.org/abs/2210.02303},
	abstract = {We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding. See https://imagen.research.google/video/ for samples.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P. and Poole, Ben and Norouzi, Mohammad and Fleet, David J. and Salimans, Tim},
	month = oct,
	year = {2022},
	note = {arXiv:2210.02303 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{ho_video_2022,
	title = {Video {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2204.03458},
	abstract = {Generating temporally coherent high fidelity video is an important milestone in generative modeling research. We make progress towards this milestone by proposing a diffusion model for video generation that shows very promising initial results. Our model is a natural extension of the standard image diffusion architecture, and it enables jointly training from image and video data, which we find to reduce the variance of minibatch gradients and speed up optimization. To generate long and higher resolution videos we introduce a new conditional sampling technique for spatial and temporal video extension that performs better than previously proposed methods. We present the first results on a large text-conditioned video generation task, as well as state-of-the-art results on established benchmarks for video prediction and unconditional video generation. Supplementary material is available at https://video-diffusion.github.io/},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J.},
	month = jun,
	year = {2022},
	note = {arXiv:2204.03458 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{zhang_diffusion_2021,
	title = {Diffusion {Normalizing} {Flow}},
	url = {http://arxiv.org/abs/2110.07579},
	abstract = {We present a novel generative modeling method called diffusion normalizing flow based on stochastic differential equations (SDEs). The algorithm consists of two neural SDEs: a forward SDE that gradually adds noise to the data to transform the data into Gaussian random noise, and a backward SDE that gradually removes the noise to sample from the data distribution. By jointly training the two neural SDEs to minimize a common cost function that quantifies the difference between the two, the backward SDE converges to a diffusion process the starts with a Gaussian distribution and ends with the desired data distribution. Our method is closely related to normalizing flow and diffusion probabilistic models and can be viewed as a combination of the two. Compared with normalizing flow, diffusion normalizing flow is able to learn distributions with sharp boundaries. Compared with diffusion probabilistic models, diffusion normalizing flow requires fewer discretization steps and thus has better sampling efficiency. Our algorithm demonstrates competitive performance in both high-dimension data density estimation and image generation tasks.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Zhang, Qinsheng and Chen, Yongxin},
	month = oct,
	year = {2021},
	note = {arXiv:2110.07579 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{lu_dpm-solver_2022,
	title = {{DPM}-{Solver}++: {Fast} {Solver} for {Guided} {Sampling} of {Diffusion} {Probabilistic} {Models}},
	shorttitle = {{DPM}-{Solver}++},
	url = {http://arxiv.org/abs/2211.01095},
	abstract = {Diffusion probabilistic models (DPMs) have achieved impressive success in high-resolution image synthesis, especially in recent large-scale text-to-image generation applications. An essential technique for improving the sample quality of DPMs is guided sampling, which usually needs a large guidance scale to obtain the best sample quality. The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples. Although recent works propose dedicated high-order solvers and achieve a further speedup for sampling without guidance, their effectiveness for guided sampling has not been well-tested before. In this work, we demonstrate that previous high-order fast samplers suffer from instability issues, and they even become slower than DDIM when the guidance scale grows large. To further speed up guided sampling, we propose DPM-Solver++, a high-order solver for the guided sampling of DPMs. DPM-Solver++ solves the diffusion ODE with the data prediction model and adopts thresholding methods to keep the solution matches training data distribution. We further propose a multistep variant of DPM-Solver++ to address the instability issue by reducing the effective step size. Experiments show that DPM-Solver++ can generate high-quality samples within only 15 to 20 steps for guided sampling by pixel-space and latent-space DPMs.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
	month = nov,
	year = {2022},
	note = {arXiv:2211.01095 [cs]
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{benton_denoising_2022,
	title = {From {Denoising} {Diffusions} to {Denoising} {Markov} {Models}},
	url = {http://arxiv.org/abs/2211.03595},
	abstract = {Denoising diffusions are state-of-the-art generative models which exhibit remarkable empirical performance and come with theoretical guarantees. The core idea of these models is to progressively transform the empirical data distribution into a simple Gaussian distribution by adding noise using a diffusion. We obtain new samples whose distribution is close to the data distribution by simulating a "denoising" diffusion approximating the time reversal of this "noising" diffusion. This denoising diffusion relies on approximations of the logarithmic derivatives of the noised data densities, known as scores, obtained using score matching. Such models can be easily extended to perform approximate posterior simulation in high-dimensional scenarios where one can only sample from the prior and simulate synthetic observations from the likelihood. These methods have been primarily developed for data on \${\textbackslash}mathbb\{R\}{\textasciicircum}d\$ while extensions to more general spaces have been developed on a case-by-case basis. We propose here a general framework which not only unifies and generalizes this approach to a wide class of spaces but also leads to an original extension of score matching. We illustrate the resulting class of denoising Markov models on various applications.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {Benton, Joe and Shi, Yuyang and De Bortoli, Valentin and Deligiannidis, George and Doucet, Arnaud},
	month = nov,
	year = {2022},
	note = {arXiv:2211.03595 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{okraschevski_fluid_2021,
	title = {Fluid dynamics beyond the continuum: {A} physical perspective on large-eddy simulation},
	volume = {6},
	issn = {2469-990X},
	shorttitle = {Fluid dynamics beyond the continuum},
	url = {https://link.aps.org/doi/10.1103/PhysRevFluids.6.L102601},
	doi = {10.1103/PhysRevFluids.6.L102601},
	language = {en},
	number = {10},
	urldate = {2022-11-14},
	journal = {Physical Review Fluids},
	author = {Okraschevski, Max and Hoffmann, Sven and Stichling, Katharina and Koch, Rainer and Bauer, Hans-Joerg},
	month = oct,
	year = {2021},
	pages = {L102601},
}

@misc{croitoru_diffusion_2022,
	title = {Diffusion {Models} in {Vision}: {A} {Survey}},
	shorttitle = {Diffusion {Models} in {Vision}},
	url = {http://arxiv.org/abs/2209.04747},
	abstract = {Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling. A diffusion model is a deep generative model that is based on two stages, a forward diffusion stage and a reverse diffusion stage. In the forward diffusion stage, the input data is gradually perturbed over several steps by adding Gaussian noise. In the reverse stage, a model is tasked at recovering the original input data by learning to gradually reverse the diffusion process, step by step. Diffusion models are widely appreciated for the quality and diversity of the generated samples, despite their known computational burdens, i.e. low speeds due to the high number of steps involved during sampling. In this survey, we provide a comprehensive review of articles on denoising diffusion models applied in vision, comprising both theoretical and practical contributions in the field. First, we identify and present three generic diffusion modeling frameworks, which are based on denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations. We further discuss the relations between diffusion models and other deep generative models, including variational auto-encoders, generative adversarial networks, energy-based models, autoregressive models and normalizing flows. Then, we introduce a multi-perspective categorization of diffusion models applied in computer vision. Finally, we illustrate the current limitations of diffusion models and envision some interesting directions for future research.},
	urldate = {2022-11-10},
	publisher = {arXiv},
	author = {Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
	month = oct,
	year = {2022},
	note = {arXiv:2209.04747 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{yang_diffusion_2022,
	title = {Diffusion {Models}: {A} {Comprehensive} {Survey} of {Methods} and {Applications}},
	shorttitle = {Diffusion {Models}},
	url = {http://arxiv.org/abs/2209.00796},
	doi = {10.48550/arXiv.2209.00796},
	abstract = {Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language processing, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.},
	urldate = {2022-11-10},
	publisher = {arXiv},
	author = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Shao, Yingxia and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
	month = oct,
	year = {2022},
	note = {arXiv:2209.00796 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{ma_physics-driven_2022,
	title = {Physics-driven {Learning} of the {Steady} {Navier}-{Stokes} {Equations} using {Deep} {Convolutional} {Neural} {Networks}},
	volume = {32},
	issn = {1815-2406, 1991-7120},
	url = {http://arxiv.org/abs/2106.09301},
	doi = {10.4208/cicp.OA-2021-0146},
	abstract = {Recently, physics-driven deep learning methods have shown particular promise for the prediction of physical fields, especially to reduce the dependency on large amounts of pre-computed training data. In this work, we target the physics-driven learning of complex flow fields with high resolutions. We propose the use of {\textbackslash}emph\{Convolutional neural networks\} (CNN) based U-net architectures to efficiently represent and reconstruct the input and output fields, respectively. By introducing Navier-Stokes equations and boundary conditions into loss functions, the physics-driven CNN is designed to predict corresponding steady flow fields directly. In particular, this prevents many of the difficulties associated with approaches employing fully connected neural networks. Several numerical experiments are conducted to investigate the behavior of the CNN approach, and the results indicate that a first-order accuracy has been achieved. Specifically for the case of a flow around a cylinder, different flow regimes can be learned and the adhered "twin-vortices" are predicted correctly. The numerical results also show that the training for multiple cases is accelerated significantly, especially for the difficult cases at low Reynolds numbers, and when limited reference solutions are used as supplementary learning targets.},
	number = {3},
	urldate = {2022-11-07},
	journal = {Communications in Computational Physics},
	author = {Ma, Hao and Zhang, Yuxuan and Thuerey, Nils and Hu, Xiangyu and Haidn, Oskar J.},
	month = jun,
	year = {2022},
	note = {arXiv:2106.09301 [physics]},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {715--736},
}

@article{lu_comprehensive_2022,
	title = {A comprehensive and fair comparison of two neural operators (with practical extensions) based on {FAIR} data},
	volume = {393},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782522001207},
	doi = {10.1016/j.cma.2022.114778},
	abstract = {Neural operators can learn nonlinear mappings between function spaces and offer a new simulation paradigm for real-time prediction of complex dynamics for realistic diverse applications as well as for system identification in science and engineering. Herein, we investigate the performance of two neural operators, which have shown promising results so far, and we develop new practical extensions that will make them more accurate and robust and importantly more suitable for industrial-complexity applications. The first neural operator, DeepONet, was published in 2019 (Lu et al., 2019), and its original architecture was based on the universal approximation theorem of Chen \& Chen (1995). The second one, named Fourier Neural Operator or FNO, was published in 2020 (Li et al., 2020), and it is based on parameterizing the integral kernel in the Fourier space. DeepONet is represented by a summation of products of neural networks (NNs), corresponding to the branch NN for the input function and the trunk NN for the output function; both NNs are general architectures, e.g., the branch NN can be replaced with a CNN or a ResNet. According to Kovachki et al. (2021), FNO in its continuous form can be viewed conceptually as a DeepONet with a specific architecture of the branch NN and a trunk NN represented by a trigonometric basis. In order to compare FNO with DeepONet computationally for realistic setups, we develop several extensions of FNO that can deal with complex geometric domains as well as mappings where the input and output function spaces are of different dimensions. We also develop an extended DeepONet with special features that provide inductive bias and accelerate training, and we present a faster implementation of DeepONet with cost comparable to the computational cost of FNO, which is based on the Fast Fourier Transform. We consider 16 different benchmarks to demonstrate the relative performance of the two neural operators, including instability wave analysis in hypersonic boundary layers, prediction of the vorticity field of a flapping airfoil, porous media simulations in complex-geometry domains, etc. We follow the guiding principles of FAIR (Findability, Accessibility, Interoperability, and Reusability) for scientific data management and stewardship. The performance of DeepONet and FNO is comparable for relatively simple settings, but for complex geometries the performance of FNO deteriorates greatly. We also compare theoretically the two neural operators and obtain similar error estimates for DeepONet and FNO under the same regularity assumptions.},
	language = {en},
	urldate = {2022-11-07},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Lu, Lu and Meng, Xuhui and Cai, Shengze and Mao, Zhiping and Goswami, Somdatta and Zhang, Zhongqiang and Karniadakis, George Em},
	month = apr,
	year = {2022},
	keywords = {Deep learning, DeepONet, FNO, Nonlinear mappings, Operator regression, Scientific machine learning},
	pages = {114778},
}

@misc{chen_towards_2021,
	title = {Towards high-accuracy deep learning inference of compressible turbulent flows over aerofoils},
	url = {http://arxiv.org/abs/2109.02183},
	doi = {10.48550/arXiv.2109.02183},
	abstract = {The present study investigates the accurate inference of Reynolds-averaged Navier-Stokes solutions for the compressible flow over aerofoils in two dimensions with a deep neural network. Our approach yields networks that learn to generate precise flow fields for varying body-fitted, structured grids by providing them with an encoding of the corresponding mapping to a canonical space for the solutions. We apply the deep neural network model to a benchmark case of incompressible flow at randomly given angles of attack and Reynolds numbers and achieve an improvement of more than an order of magnitude compared to previous work. Further, for transonic flow cases, the deep neural network model accurately predicts complex flow behaviour at high Reynolds numbers, such as shock wave/boundary layer interaction, and quantitative distributions like pressure coefficient, skin friction coefficient as well as wake total pressure profiles downstream of aerofoils. The proposed deep learning method significantly speeds up the predictions of flow fields and shows promise for enabling fast aerodynamic designs.},
	urldate = {2022-11-07},
	publisher = {arXiv},
	author = {Chen, Li-Wei and Thuerey, Nils},
	month = sep,
	year = {2021},
	note = {arXiv:2109.02183 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@misc{ba_layer_2016,
	title = {Layer {Normalization}},
	url = {http://arxiv.org/abs/1607.06450},
	abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
	urldate = {2022-11-03},
	publisher = {arXiv},
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	month = jul,
	year = {2016},
	note = {arXiv:1607.06450 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{takamoto_pdebench_nodate,
	title = {{PDEBENCH}: {An} {Extensive} {Benchmark} for {Scientiﬁc} {Machine} {Learning}},
	abstract = {Machine learning-based modeling of physical systems has experienced increased interest in recent years. Despite some impressive progress, there is still a lack of benchmarks for Scientiﬁc ML that are easy to use but still challenging and representative of a wide range of problems. We introduce PDEBENCH, a benchmark suite of time-dependent simulation tasks based on Partial Differential Equations (PDEs). PDEBENCH comprises both code and data to benchmark the performance of novel machine learning models against both classical numerical simulations and machine learning baselines. Our proposed set of benchmark problems contribute the following unique features: (1) A much wider range of PDEs compared to existing benchmarks, ranging from relatively common examples to more realistic and difﬁcult problems; (2) much larger ready-to-use datasets compared to prior work, comprising multiple simulation runs across a larger number of initial and boundary conditions and PDE parameters; (3) more extensible source codes with user-friendly APIs for data generation and baseline results with popular machine learning models (FNO, U-Net, PINN, Gradient-Based Inverse Method). PDEBENCH allows researchers to extend the benchmark freely for their own purposes using a standardized API and to compare the performance of new models to existing baseline methods. We also propose new evaluation metrics with the aim to provide a more holistic understanding of learning methods in the context of Scientiﬁc ML. With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community. The code is available at https://github.com/pdebench/PDEBench.},
	language = {en},
	author = {Takamoto, Makoto and Praditia, Timothy and Leiteritz, Raphael and MacKinlay, Dan and Alesiani, Francesco and Pﬂüger, Dirk and Niepert, Mathias},
	pages = {16},
}

@article{yousif_physics-guided_2022,
	title = {Physics-guided deep learning for generating turbulent inflow conditions},
	volume = {936},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/physicsguided-deep-learning-for-generating-turbulent-inflow-conditions/5AC04D36A013FD8661CB8381860ADC8C},
	doi = {10.1017/jfm.2022.61},
	abstract = {, In this paper, we propose an efficient method for generating turbulent inflow conditions based on deep neural networks. We utilise the combination of a multiscale convolutional auto-encoder with a subpixel convolution layer (MSCSPMSCSP\{{\textbackslash}rm MSC\}\_\{{\textbackslash}rm \{SP\}\}-AE) and a long short-term memory (LSTM) model. Physical constraints represented by the flow gradient, Reynolds stress tensor and spectral content of the flow are embedded in the loss function of the MSCSPMSCSP\{{\textbackslash}rm MSC\}\_\{{\textbackslash}rm \{SP\}\}-AE to enable the model to generate realistic turbulent inflow conditions with accurate statistics and spectra, as compared with the ground truth data. Direct numerical simulation (DNS) data of turbulent channel flow at two friction Reynolds numbers Reτ=180Reτ=180Re\_\{{\textbackslash}tau \} = 180 and 550 are used to assess the performance of the model obtained from the combination of the MSCSPMSCSP\{{\textbackslash}rm MSC\}\_\{{\textbackslash}rm \{SP\}\}-AE and the LSTM model. The model exhibits a commendable ability to predict instantaneous flow fields with detailed fluctuations and produces turbulence statistics and spectral content similar to those obtained from the DNS. The effects of changing various salient components in the model are thoroughly investigated. Furthermore, the impact of performing transfer learning (TL) using different amounts of training data on the training process and the model performance is examined by using the weights of the model trained on data of the flow at Reτ=180Reτ=180Re\_\{{\textbackslash}tau \} = 180 to initialise the weights for training the model with data of the flow at Reτ=550Reτ=550Re\_\{{\textbackslash}tau \} = 550. The results show that by using only 25\% of the full training data, the time that is required for successful training can be reduced by a factor of approximately 80\% without affecting the performance of the model for the spanwise velocity, wall-normal velocity and pressure, and with an improvement of the model performance for the streamwise velocity. The results also indicate that using physics-guided deep-learning-based models can be efficient in terms of predicting the dynamics of turbulent flows with relatively low computational cost.},
	language = {en},
	urldate = {2022-10-13},
	journal = {Journal of Fluid Mechanics},
	author = {Yousif, Mustafa Z. and Yu, Linqi and Lim, HeeChang},
	month = apr,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	keywords = {machine learning, turbulence simulation, turbulent boundary layers},
	pages = {A21},
}

@misc{jo_score-based_2022,
	title = {Score-based {Generative} {Modeling} of {Graphs} via the {System} of {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2202.02514},
	abstract = {Generating graph-structured data requires learning the underlying distribution of graphs. Yet, this is a challenging problem, and the previous graph generative methods either fail to capture the permutation-invariance property of graphs or cannot sufficiently model the complex dependency between nodes and edges, which is crucial for generating real-world graphs such as molecules. To overcome such limitations, we propose a novel score-based generative model for graphs with a continuous-time framework. Specifically, we propose a new graph diffusion process that models the joint distribution of the nodes and edges through a system of stochastic differential equations (SDEs). Then, we derive novel score matching objectives tailored for the proposed diffusion process to estimate the gradient of the joint log-density with respect to each component, and introduce a new solver for the system of SDEs to efficiently sample from the reverse diffusion process. We validate our graph generation method on diverse datasets, on which it either achieves significantly superior or competitive performance to the baselines. Further analysis shows that our method is able to generate molecules that lie close to the training distribution yet do not violate the chemical valency rule, demonstrating the effectiveness of the system of SDEs in modeling the node-edge relationships. Our code is available at https://github.com/harryjo97/GDSS.},
	urldate = {2022-10-11},
	publisher = {arXiv},
	author = {Jo, Jaehyeong and Lee, Seul and Hwang, Sung Ju},
	month = jun,
	year = {2022},
	note = {arXiv:2202.02514 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{noauthor_discovering_nodate,
	title = {Discovering faster matrix multiplication algorithms with reinforcement learning {\textbar} {Nature}},
	url = {https://www.nature.com/articles/s41586-022-05172-4},
	urldate = {2022-10-06},
}

@misc{jaini_learning_2021,
	title = {Learning {Equivariant} {Energy} {Based} {Models} with {Equivariant} {Stein} {Variational} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2106.07832},
	doi = {10.48550/arXiv.2106.07832},
	abstract = {We focus on the problem of efficient sampling and learning of probability densities by incorporating symmetries in probabilistic models. We first introduce Equivariant Stein Variational Gradient Descent algorithm -- an equivariant sampling method based on Stein's identity for sampling from densities with symmetries. Equivariant SVGD explicitly incorporates symmetry information in a density through equivariant kernels which makes the resultant sampler efficient both in terms of sample complexity and the quality of generated samples. Subsequently, we define equivariant energy based models to model invariant densities that are learned using contrastive divergence. By utilizing our equivariant SVGD for training equivariant EBMs, we propose new ways of improving and scaling up training of energy based models. We apply these equivariant energy models for modelling joint densities in regression and classification tasks for image datasets, many-body particle systems and molecular structure generation.},
	urldate = {2022-10-05},
	publisher = {arXiv},
	author = {Jaini, Priyank and Holdijk, Lars and Welling, Max},
	month = jul,
	year = {2021},
	note = {arXiv:2106.07832 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2022-09-29},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@article{guen_deep_nodate,
	title = {Deep learning for spatio-temporal forecasting - application to solar energy},
	language = {en},
	author = {Guen, Vincent Le},
	pages = {217},
}

@inproceedings{guen_disentangling_2020,
	title = {Disentangling {Physical} {Dynamics} {From} {Unknown} {Factors} for {Unsupervised} {Video} {Prediction}},
	url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Le_Guen_Disentangling_Physical_Dynamics_From_Unknown_Factors_for_Unsupervised_Video_Prediction_CVPR_2020_paper.html},
	urldate = {2022-09-26},
	author = {Guen, Vincent Le and Thome, Nicolas},
	year = {2020},
	pages = {11474--11484},
}

@inproceedings{le_guen_probabilistic_2020,
	title = {Probabilistic {Time} {Series} {Forecasting} with {Shape} and {Temporal} {Diversity}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/2f2b265625d76a6704b08093c652fd79-Abstract.html},
	abstract = {Probabilistic forecasting consists in predicting a distribution of possible future outcomes. In this paper, we address this problem for non-stationary time series, which is very challenging yet crucially important. We introduce the STRIPE model for representing structured diversity based on shape and time features, ensuring both probable predictions while being sharp and accurate. STRIPE is agnostic to the forecasting model, and we equip it with a diversification mechanism relying on determinantal point processes (DPP). We introduce two DPP kernels for modelling diverse trajectories in terms of shape and time, which are both differentiable and proved to be positive semi-definite. To have an explicit control on the diversity structure, we also design an iterative sampling mechanism to disentangle shape and time representations in the latent space. Experiments carried out on synthetic datasets show that STRIPE significantly outperforms baseline methods for representing diversity, while maintaining accuracy of the forecasting model. We also highlight the relevance of the iterative sampling scheme and the importance to use different criteria for measuring quality and diversity. Finally, experiments on real datasets illustrate that STRIPE is able to outperform state-of-the-art probabilistic forecasting approaches in the best sample prediction.},
	urldate = {2022-09-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {LE GUEN, Vincent and THOME, Nicolas},
	year = {2020},
	pages = {4427--4440},
}

@article{yin_augmenting_2021,
	title = {Augmenting physical models with deep networks for complex dynamics forecasting{\textbackslash}ast},
	volume = {2021},
	issn = {1742-5468},
	url = {https://doi.org/10.1088/1742-5468/ac3ae5},
	doi = {10.1088/1742-5468/ac3ae5},
	abstract = {Forecasting complex dynamical phenomena in settings where only partial knowledge of their dynamics is available is a prevalent problem across various scientific fields. While purely data-driven approaches are arguably insufficient in this context, standard physical modeling-based approaches tend to be over-simplistic, inducing non-negligible errors. In this work, we introduce the APHYNITY framework, a principled approach for augmenting incomplete physical dynamics described by differential equations with deep data-driven models. It consists of decomposing the dynamics into two components: a physical component accounting for the dynamics for which we have some prior knowledge, and a data-driven component accounting for errors of the physical model. The learning problem is carefully formulated such that the physical model explains as much of the data as possible, while the data-driven component only describes information that cannot be captured by the physical model; no more, no less. This not only provides the existence and uniqueness for this decomposition, but also ensures interpretability and benefit generalization. Experiments made on three important use cases, each representative of a different family of phenomena, i.e. reaction–diffusion equations, wave equations and the non-linear damped pendulum, show that APHYNITY can efficiently leverage approximate physical models to accurately forecast the evolution of the system and correctly identify relevant physical parameters. The code is available at https://github.com/yuan-yin/APHYNITY.},
	language = {en},
	number = {12},
	urldate = {2022-09-26},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Yin, Yuan and Guen, Vincent Le and Dona, Jérémie and Bézenac, Emmanuel de and Ayed, Ibrahim and Thome, Nicolas and Gallinari, Patrick},
	month = dec,
	year = {2021},
	note = {Publisher: IOP Publishing},
	pages = {124012},
}

@misc{yousif_transformer-based_2022,
	title = {A transformer-based synthetic-inflow generator for spatially-developing turbulent boundary layers},
	url = {http://arxiv.org/abs/2206.01618},
	doi = {10.48550/arXiv.2206.01618},
	abstract = {This study proposes a newly-developed deep-learning-based method to generate turbulent inflow conditions for spatially-developing turbulent boundary layer (TBL) simulations. A combination of a transformer and a multiscale-enhanced super-resolution generative adversarial network is utilized to predict velocity fields of a spatially-developing TBL at various planes normal to the streamwise direction. Datasets of direct numerical simulation (DNS) of flat plate flow spanning a momentum thickness-based Reynolds number, Re\_theta = 661.5 - 1502.0, are used to train and test the model. The model shows a remarkable ability to predict the instantaneous velocity fields with detailed fluctuations and reproduce the turbulence statistics as well as spatial and temporal spectra with commendable accuracy as compared with the DNS results. The proposed model also exhibits a reasonable accuracy for predicting velocity fields at Reynolds numbers that are not used in the training process. With the aid of transfer learning, the computational cost of the proposed model is considered to be effectively low. The results demonstrate, for the first time that transformer-based models can be efficient in predicting the dynamics of turbulent flows. It also shows that combining these models with generative adversarial networks-based models can be useful in tackling various turbulence-related problems, including the development of efficient synthetic-turbulent inflow generators.},
	urldate = {2022-09-19},
	publisher = {arXiv},
	author = {Yousif, Mustafa Z. and Zhang, Meng and Yu, Linqi and Vinuesa, Ricardo and Lim, HeeChang},
	month = jun,
	year = {2022},
	note = {arXiv:2206.01618 [physics]},
	keywords = {Physics - Fluid Dynamics},
}

@misc{stachenfeld_learned_2022,
	title = {Learned {Coarse} {Models} for {Efficient} {Turbulence} {Simulation}},
	url = {http://arxiv.org/abs/2112.15275},
	doi = {10.48550/arXiv.2112.15275},
	abstract = {Turbulence simulation with classical numerical solvers requires high-resolution grids to accurately resolve dynamics. Here we train learned simulators at low spatial and temporal resolutions to capture turbulent dynamics generated at high resolution. We show that our proposed model can simulate turbulent dynamics more accurately than classical numerical solvers at the comparably low resolutions across various scientifically relevant metrics. Our model is trained end-to-end from data and is capable of learning a range of challenging chaotic and turbulent dynamics at low resolution, including trajectories generated by the state-of-the-art Athena++ engine. We show that our simpler, general-purpose architecture outperforms various more specialized, turbulence-specific architectures from the learned turbulence simulation literature. In general, we see that learned simulators yield unstable trajectories; however, we show that tuning training noise and temporal downsampling solves this problem. We also find that while generalization beyond the training distribution is a challenge for learned models, training noise, added loss constraints, and dataset augmentation can help. Broadly, we conclude that our learned simulator outperforms traditional solvers run on coarser grids, and emphasize that simple design choices can offer stability and robust generalization.},
	urldate = {2022-09-19},
	publisher = {arXiv},
	author = {Stachenfeld, Kimberly and Fielding, Drummond B. and Kochkov, Dmitrii and Cranmer, Miles and Pfaff, Tobias and Godwin, Jonathan and Cui, Can and Ho, Shirley and Battaglia, Peter and Sanchez-Gonzalez, Alvaro},
	month = apr,
	year = {2022},
	note = {arXiv:2112.15275 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{coifman_geometric_2005,
	title = {Geometric diffusions as a tool for harmonic analysis and structure definition of data: {Diffusion} maps},
	volume = {102},
	shorttitle = {Geometric diffusions as a tool for harmonic analysis and structure definition of data},
	url = {https://www.pnas.org/doi/10.1073/pnas.0500334102},
	doi = {10.1073/pnas.0500334102},
	number = {21},
	urldate = {2022-09-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Coifman, R. R. and Lafon, S. and Lee, A. B. and Maggioni, M. and Nadler, B. and Warner, F. and Zucker, S. W.},
	month = may,
	year = {2005},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {7426--7431},
}

@misc{brandstetter_clifford_2022,
	title = {Clifford {Neural} {Layers} for {PDE} {Modeling}},
	url = {http://arxiv.org/abs/2209.04934},
	doi = {10.48550/arXiv.2209.04934},
	abstract = {Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates have become an active research topic to accelerate these simulations. However, current methods do not explicitly take into account the relationship between different fields and their internal components, which are often correlated. Viewing the time evolution of such correlated fields through the lens of multivector fields allows us to overcome these limitations. Multivector fields consist of scalar, vector, as well as higher-order components, such as bivectors and trivectors. Their algebraic properties, such as multiplication, addition and other arithmetic operations can be described by Clifford algebras. To our knowledge, this paper presents the first usage of such multivector representations together with Clifford convolutions and Clifford Fourier transforms in the context of deep learning. The resulting Clifford neural layers are universally applicable and will find direct use in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general. We empirically evaluate the benefit of Clifford neural layers by replacing convolution and Fourier operations in common neural PDE surrogates by their Clifford counterparts on two-dimensional Navier-Stokes and weather modeling tasks, as well as three-dimensional Maxwell equations. Clifford neural layers consistently improve generalization capabilities of the tested neural PDE surrogates.},
	urldate = {2022-09-13},
	publisher = {arXiv},
	author = {Brandstetter, Johannes and Berg, Rianne van den and Welling, Max and Gupta, Jayesh K.},
	month = sep,
	year = {2022},
	note = {arXiv:2209.04934 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@misc{kaltenbach_semi-supervised_2022,
	title = {Semi-supervised {Invertible} {DeepONets} for {Bayesian} {Inverse} {Problems}},
	url = {http://arxiv.org/abs/2209.02772},
	doi = {10.48550/arXiv.2209.02772},
	abstract = {Deep Operator Networks (DeepONets) offer a powerful, data-driven tool for solving parametric PDEs by learning operators, i.e. maps between infinite-dimensional function spaces. In this work, we employ physics-informed DeepONets in the context of high-dimensional, Bayesian inverse problems. Traditional solution strategies necessitate an enormous, and frequently infeasible, number of forward model solves, as well as the computation of parametric derivatives. In order to enable efficient solutions, we extend DeepONets by employing a realNVP architecture which yields an invertible and differentiable map between the parametric input and the branch net output. This allows us to construct accurate approximations of the full posterior which can be readily adapted irrespective of the number of observations and the magnitude of the observation noise. As a result, no additional forward solves are required, nor is there any need for costly sampling procedures. We demonstrate the efficacy and accuracy of the proposed methodology in the context of inverse problems based on a anti-derivative, a reaction-diffusion and a Darcy-flow equation.},
	urldate = {2022-09-10},
	publisher = {arXiv},
	author = {Kaltenbach, Sebastian and Perdikaris, Paris and Koutsourelakis, Phaedon-Stelios},
	month = sep,
	year = {2022},
	note = {arXiv:2209.02772 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@misc{rezende_variational_2016,
	title = {Variational {Inference} with {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/1505.05770},
	abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
	month = jun,
	year = {2016},
	note = {arXiv:1505.05770 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
}

@article{cao_adjoint_2002,
	series = {Scientific and {Engineering} {Computations} for the 21st {Century} - {Me} thodologies and {Applications} {Proceedings} of the 15th {Toyota} {Conference}},
	title = {Adjoint sensitivity analysis for differential-algebraic equations: algorithms and software},
	volume = {149},
	issn = {0377-0427},
	shorttitle = {Adjoint sensitivity analysis for differential-algebraic equations},
	url = {https://www.sciencedirect.com/science/article/pii/S0377042702005289},
	doi = {10.1016/S0377-0427(02)00528-9},
	abstract = {An efficient numerical method for sensitivity computation of large-scale differential-algebraic systems is developed based on the adjoint method. Issues that are critical for the implementation are addressed. Complexity analysis and numerical results demonstrate that the adjoint sensitivity method is advantageous over the forward sensitivity method for applications with a large number of sensitivity parameters and few objective functions.},
	language = {en},
	number = {1},
	urldate = {2022-09-01},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Cao, Yang and Li, Shengtai and Petzold, Linda},
	month = dec,
	year = {2002},
	keywords = {Adjoint method, Differential-algebraic equations, Sensitivity analysis},
	pages = {171--191},
}

@misc{rubanova_latent_2019,
	title = {Latent {ODEs} for {Irregularly}-{Sampled} {Time} {Series}},
	url = {http://arxiv.org/abs/1907.03907},
	doi = {10.48550/arXiv.1907.03907},
	abstract = {Time series with non-uniform intervals occur in many applications, and are difficult to model using standard recurrent neural networks (RNNs). We generalize RNNs to have continuous-time hidden dynamics defined by ordinary differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps between observations, and can explicitly model the probability of observation times using Poisson processes. We show experimentally that these ODE-based models outperform their RNN-based counterparts on irregularly-sampled data.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Rubanova, Yulia and Chen, Ricky T. Q. and Duvenaud, David},
	month = jul,
	year = {2019},
	note = {arXiv:1907.03907 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{grathwohl_ffjord_2018,
	title = {{FFJORD}: {Free}-form {Continuous} {Dynamics} for {Scalable} {Reversible} {Generative} {Models}},
	shorttitle = {{FFJORD}},
	url = {http://arxiv.org/abs/1810.01367},
	abstract = {A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Grathwohl, Will and Chen, Ricky T. Q. and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
	month = oct,
	year = {2018},
	note = {arXiv:1810.01367 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mansouri_performance_2022,
	title = {Performance of different inflow turbulence methods for wind engineering applications},
	volume = {229},
	issn = {0167-6105},
	url = {https://www.sciencedirect.com/science/article/pii/S0167610522002379},
	doi = {10.1016/j.jweia.2022.105141},
	abstract = {Defining the correct inlet boundary conditions for large eddy simulations is a critical issue in computational wind engineering. Since synthetic inflow turbulence does not require costly prior flow simulations like recycling or precursor methods, it is a preferable approach. In this study, different synthetic turbulence generator methods are considered to investigate their performance in wind engineering applications. The considered methods are a) Digital Filter Methods (DFM), b) Synthetic eddy methods (SEM) with different shape functions, c) Divergence Free Synthetic Eddy Method (DFSEM), and d) two types of Anisotropy Turbulent Spot Method (ATSM). These methods are provided in Turbulence Inflow Tool (TInF) from the SimCenter (https://simcenter.designsafe-ci.org/backend-components/tinf/). Additionally, velocity spectrum at the inlet and building location is compared to the Von Karman spectrum for different inflow methods to determine how well the energy is carried from the inlet to the building location. Furthermore, different methods are evaluated to see whether they produce spurious pressure in the domain. It is concluded that spurious pressure exists in all the considered methods except SEM method with the Gaussian shape function (SEM-G). In addition, SEM-G is found to be a suitable method for peak pressure prediction on buildings with upmost 30\% error.},
	language = {en},
	urldate = {2022-08-29},
	journal = {Journal of Wind Engineering and Industrial Aerodynamics},
	author = {Mansouri, Zahra and Selvam, Rathinam Panneer and Chowdhury, Arindam Gan},
	month = oct,
	year = {2022},
	keywords = {Anisotropy turbulent spot method, Digital filter method, Divergence free synthetic eddy method, Large eddy simulation, Synthetic eddy methods, Synthetic inflow turbulence, Turbulence inflow tool},
	pages = {105141},
}

@misc{barp_geometry_2017,
	title = {Geometry and {Dynamics} for {Markov} {Chain} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1705.02891},
	abstract = {Markov Chain Monte Carlo methods have revolutionised mathematical computation and enabled statistical inference within many previously intractable models. In this context, Hamiltonian dynamics have been proposed as an efficient way of building chains which can explore probability densities efficiently. The method emerges from physics and geometry and these links have been extensively studied by a series of authors through the last thirty years. However, there is currently a gap between the intuitions and knowledge of users of the methodology and our deep understanding of these theoretical foundations. The aim of this review is to provide a comprehensive introduction to the geometric tools used in Hamiltonian Monte Carlo at a level accessible to statisticians, machine learners and other users of the methodology with only a basic understanding of Monte Carlo methods. This will be complemented with some discussion of the most recent advances in the field which we believe will become increasingly relevant to applied scientists.},
	urldate = {2022-08-29},
	publisher = {arXiv},
	author = {Barp, Alessandro and Briol, Francois-Xavier and Kennedy, Anthony D. and Girolami, Mark},
	month = may,
	year = {2017},
	note = {arXiv:1705.02891 [hep-lat, stat]},
	keywords = {Computer Science - Machine Learning, High Energy Physics - Lattice, Mathematics - Numerical Analysis, Statistics - Computation, Statistics - Machine Learning},
}

@article{livingstone_information-geometric_2014,
	title = {Information-geometric {Markov} {Chain} {Monte} {Carlo} methods using {Diffusions}},
	volume = {16},
	issn = {1099-4300},
	url = {http://arxiv.org/abs/1403.7957},
	doi = {10.3390/e16063074},
	abstract = {Recent work incorporating geometric ideas in Markov chain Monte Carlo is reviewed in order to highlight these advances and their possible application in a range of domains beyond Statistics. A full exposition of Markov chains and their use in Monte Carlo simulation for Statistical inference and molecular dynamics is provided, with particular emphasis on methods based on Langevin diffusions. After this geometric concepts in Markov chain Monte Carlo are introduced. A full derivation of the Langevin diffusion on a Riemannian manifold is given, together with a discussion of appropriate Riemannian metric choice for different problems. A survey of applications is provided, and some open questions are discussed.},
	number = {6},
	urldate = {2022-08-29},
	journal = {Entropy},
	author = {Livingstone, Samuel and Girolami, Mark},
	month = jun,
	year = {2014},
	note = {arXiv:1403.7957 [stat]},
	keywords = {Statistics - Computation, Statistics - Methodology},
	pages = {3074--3102},
}

@misc{zou_neuraluq_2022,
	title = {{NeuralUQ}: {A} comprehensive library for uncertainty quantification in neural differential equations and operators},
	shorttitle = {{NeuralUQ}},
	url = {http://arxiv.org/abs/2208.11866},
	abstract = {Uncertainty quantification (UQ) in machine learning is currently drawing increasing research interest, driven by the rapid deployment of deep neural networks across different fields, such as computer vision, natural language processing, and the need for reliable tools in risk-sensitive applications. Recently, various machine learning models have also been developed to tackle problems in the field of scientific computing with applications to computational science and engineering (CSE). Physics-informed neural networks and deep operator networks are two such models for solving partial differential equations and learning operator mappings, respectively. In this regard, a comprehensive study of UQ methods tailored specifically for scientific machine learning (SciML) models has been provided in [45]. Nevertheless, and despite their theoretical merit, implementations of these methods are not straightforward, especially in large-scale CSE applications, hindering their broad adoption in both research and industry settings. In this paper, we present an open-source Python library (https://github.com/Crunch-UQ4MI), termed NeuralUQ and accompanied by an educational tutorial, for employing UQ methods for SciML in a convenient and structured manner. The library, designed for both educational and research purposes, supports multiple modern UQ methods and SciML models. It is based on a succinct workflow and facilitates flexible employment and easy extensions by the users. We first present a tutorial of NeuralUQ and subsequently demonstrate its applicability and efficiency in four diverse examples, involving dynamical systems and high-dimensional parametric and time-dependent PDEs.},
	urldate = {2022-08-29},
	publisher = {arXiv},
	author = {Zou, Zongren and Meng, Xuhui and Psaros, Apostolos F. and Karniadakis, George Em},
	month = aug,
	year = {2022},
	note = {arXiv:2208.11866 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@misc{psaros_uncertainty_2022,
	title = {Uncertainty {Quantification} in {Scientific} {Machine} {Learning}: {Methods}, {Metrics}, and {Comparisons}},
	shorttitle = {Uncertainty {Quantification} in {Scientific} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2201.07766},
	abstract = {Neural networks (NNs) are currently changing the computational paradigm on how to combine data with mathematical laws in physics and engineering in a profound way, tackling challenging inverse and ill-posed problems not solvable with traditional methods. However, quantifying errors and uncertainties in NN-based inference is more complicated than in traditional methods. This is because in addition to aleatoric uncertainty associated with noisy data, there is also uncertainty due to limited data, but also due to NN hyperparameters, overparametrization, optimization and sampling errors as well as model misspecification. Although there are some recent works on uncertainty quantification (UQ) in NNs, there is no systematic investigation of suitable methods towards quantifying the total uncertainty effectively and efficiently even for function approximation, and there is even less work on solving partial differential equations and learning operator mappings between infinite-dimensional function spaces using NNs. In this work, we present a comprehensive framework that includes uncertainty modeling, new and existing solution methods, as well as evaluation metrics and post-hoc improvement approaches. To demonstrate the applicability and reliability of our framework, we present an extensive comparative study in which various methods are tested on prototype problems, including problems with mixed input-output data, and stochastic problems in high dimensions. In the Appendix, we include a comprehensive description of all the UQ methods employed, which we will make available as open-source library of all codes included in this framework.},
	urldate = {2022-08-29},
	publisher = {arXiv},
	author = {Psaros, Apostolos F. and Meng, Xuhui and Zou, Zongren and Guo, Ling and Karniadakis, George Em},
	month = jan,
	year = {2022},
	note = {arXiv:2201.07766 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{kidger_hey_2021,
	title = {"{Hey}, that's not an {ODE}": {Faster} {ODE} {Adjoints} via {Seminorms}},
	shorttitle = {"{Hey}, that's not an {ODE}"},
	url = {http://arxiv.org/abs/2009.09457},
	abstract = {Neural differential equations may be trained by backpropagating gradients via the adjoint method, which is another differential equation typically solved using an adaptive-step-size numerical differential equation solver. A proposed step is accepted if its error, {\textbackslash}emph\{relative to some norm\}, is sufficiently small; else it is rejected, the step is shrunk, and the process is repeated. Here, we demonstrate that the particular structure of the adjoint equations makes the usual choices of norm (such as \$L{\textasciicircum}2\$) unnecessarily stringent. By replacing it with a more appropriate (semi)norm, fewer steps are unnecessarily rejected and the backpropagation is made faster. This requires only minor code modifications. Experiments on a wide range of tasks -- including time series, generative modeling, and physical control -- demonstrate a median improvement of 40\% fewer function evaluations. On some problems we see as much as 62\% fewer function evaluations, so that the overall training time is roughly halved.},
	urldate = {2022-08-26},
	publisher = {arXiv},
	author = {Kidger, Patrick and Chen, Ricky T. Q. and Lyons, Terry},
	month = may,
	year = {2021},
	note = {arXiv:2009.09457 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Classical Analysis and ODEs},
}

@misc{jenner_calculus_2022,
	title = {Calculus on {MDPs}: {Potential} {Shaping} as a {Gradient}},
	shorttitle = {Calculus on {MDPs}},
	url = {http://arxiv.org/abs/2208.09570},
	doi = {10.48550/arXiv.2208.09570},
	abstract = {In reinforcement learning, different reward functions can be equivalent in terms of the optimal policies they induce. A particularly well-known and important example is potential shaping, a class of functions that can be added to any reward function without changing the optimal policy set under arbitrary transition dynamics. Potential shaping is conceptually similar to potentials, conservative vector fields and gauge transformations in math and physics, but this connection has not previously been formally explored. We develop a formalism for discrete calculus on graphs that abstract a Markov Decision Process, and show how potential shaping can be formally interpreted as a gradient within this framework. This allows us to strengthen results from Ng et al. (1999) describing conditions under which potential shaping is the only additive reward transformation to always preserve optimal policies. As an additional application of our formalism, we define a rule for picking a single unique reward function from each potential shaping equivalence class.},
	urldate = {2022-08-25},
	publisher = {arXiv},
	author = {Jenner, Erik and van Hoof, Herke and Gleave, Adam},
	month = aug,
	year = {2022},
	note = {arXiv:2208.09570 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{allen_physical_2022,
	title = {Physical {Design} using {Differentiable} {Learned} {Simulators}},
	url = {http://arxiv.org/abs/2202.00728},
	abstract = {Designing physical artifacts that serve a purpose - such as tools and other functional structures - is central to engineering as well as everyday human behavior. Though automating design has tremendous promise, general-purpose methods do not yet exist. Here we explore a simple, fast, and robust approach to inverse design which combines learned forward simulators based on graph neural networks with gradient-based design optimization. Our approach solves high-dimensional problems with complex physical dynamics, including designing surfaces and tools to manipulate fluid flows and optimizing the shape of an airfoil to minimize drag. This framework produces high-quality designs by propagating gradients through trajectories of hundreds of steps, even when using models that were pre-trained for single-step predictions on data substantially different from the design tasks. In our fluid manipulation tasks, the resulting designs outperformed those found by sampling-based optimization techniques. In airfoil design, they matched the quality of those obtained with a specialized solver. Our results suggest that despite some remaining challenges, machine learning-based simulators are maturing to the point where they can support general-purpose design optimization across a variety of domains.},
	urldate = {2022-08-24},
	publisher = {arXiv},
	author = {Allen, Kelsey R. and Lopez-Guevara, Tatiana and Stachenfeld, Kimberly and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Hamrick, Jessica and Pfaff, Tobias},
	month = feb,
	year = {2022},
	note = {arXiv:2202.00728 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{shchur_neural_2021,
	title = {Neural {Temporal} {Point} {Processes}: {A} {Review}},
	shorttitle = {Neural {Temporal} {Point} {Processes}},
	url = {http://arxiv.org/abs/2104.03528},
	abstract = {Temporal point processes (TPP) are probabilistic generative models for continuous-time event sequences. Neural TPPs combine the fundamental ideas from point process literature with deep learning approaches, thus enabling construction of flexible and efficient models. The topic of neural TPPs has attracted significant attention in the recent years, leading to the development of numerous new architectures and applications for this class of models. In this review paper we aim to consolidate the existing body of knowledge on neural TPPs. Specifically, we focus on important design choices and general principles for defining neural TPP models. Next, we provide an overview of application areas commonly considered in the literature. We conclude this survey with the list of open challenges and important directions for future work in the field of neural TPPs.},
	urldate = {2022-08-22},
	publisher = {arXiv},
	author = {Shchur, Oleksandr and Türkmen, Ali Caner and Januschowski, Tim and Günnemann, Stephan},
	month = aug,
	year = {2021},
	note = {arXiv:2104.03528 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{chen_neural_2021,
	title = {Neural {Spatio}-{Temporal} {Point} {Processes}},
	url = {http://arxiv.org/abs/2011.04583},
	abstract = {We propose a new class of parameterizations for spatio-temporal point processes which leverage Neural ODEs as a computational method and enable flexible, high-fidelity models of discrete events that are localized in continuous time and space. Central to our approach is a combination of continuous-time neural networks with two novel neural architectures, i.e., Jump and Attentive Continuous-time Normalizing Flows. This approach allows us to learn complex distributions for both the spatial and temporal domain and to condition non-trivially on the observed event history. We validate our models on data sets from a wide variety of contexts such as seismology, epidemiology, urban mobility, and neuroscience.},
	urldate = {2022-08-22},
	publisher = {arXiv},
	author = {Chen, Ricky T. Q. and Amos, Brandon and Nickel, Maximilian},
	month = mar,
	year = {2021},
	note = {arXiv:2011.04583 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{shchur_modeling_nodate,
	title = {Modeling {Continuous}-time {Event} {Data} with {Neural} {Temporal} {Point} {Processes}},
	language = {de},
	author = {Shchur, Oleksandr},
	pages = {159},
}

@misc{lienen_learning_2022,
	title = {Learning the {Dynamics} of {Physical} {Systems} from {Sparse} {Observations} with {Finite} {Element} {Networks}},
	url = {http://arxiv.org/abs/2203.08852},
	doi = {10.48550/arXiv.2203.08852},
	abstract = {We propose a new method for spatio-temporal forecasting on arbitrarily distributed points. Assuming that the observed system follows an unknown partial differential equation, we derive a continuous-time model for the dynamics of the data via the finite element method. The resulting graph neural network estimates the instantaneous effects of the unknown dynamics on each cell in a meshing of the spatial domain. Our model can incorporate prior knowledge via assumptions on the form of the unknown PDE, which induce a structural bias towards learning specific processes. Through this mechanism, we derive a transport variant of our model from the convection equation and show that it improves the transfer performance to higher-resolution meshes on sea surface temperature and gas flow forecasting against baseline models representing a selection of spatio-temporal forecasting methods. A qualitative analysis shows that our model disentangles the data dynamics into their constituent parts, which makes it uniquely interpretable.},
	urldate = {2022-08-22},
	publisher = {arXiv},
	author = {Lienen, Marten and Günnemann, Stephan},
	month = mar,
	year = {2022},
	note = {arXiv:2203.08852 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{phuong_formal_2022,
	title = {Formal {Algorithms} for {Transformers}},
	url = {http://arxiv.org/abs/2207.09238},
	doi = {10.48550/arXiv.2207.09238},
	abstract = {This document aims to be a self-contained, mathematically precise overview of transformer architectures and algorithms (*not* results). It covers what transformers are, how they are trained, what they are used for, their key architectural components, and a preview of the most prominent models. The reader is assumed to be familiar with basic ML terminology and simpler neural network architectures such as MLPs.},
	urldate = {2022-08-19},
	publisher = {arXiv},
	author = {Phuong, Mary and Hutter, Marcus},
	month = jul,
	year = {2022},
	note = {arXiv:2207.09238 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{mildenhall_nerf_2021,
	title = {{NeRF} in the {Dark}: {High} {Dynamic} {Range} {View} {Synthesis} from {Noisy} {Raw} {Images}},
	shorttitle = {{NeRF} in the {Dark}},
	url = {http://arxiv.org/abs/2111.13679},
	abstract = {Neural Radiance Fields (NeRF) is a technique for high quality novel view synthesis from a collection of posed input images. Like most view synthesis methods, NeRF uses tonemapped low dynamic range (LDR) as input; these images have been processed by a lossy camera pipeline that smooths detail, clips highlights, and distorts the simple noise distribution of raw sensor data. We modify NeRF to instead train directly on linear raw images, preserving the scene's full dynamic range. By rendering raw output images from the resulting NeRF, we can perform novel high dynamic range (HDR) view synthesis tasks. In addition to changing the camera viewpoint, we can manipulate focus, exposure, and tonemapping after the fact. Although a single raw image appears significantly more noisy than a postprocessed one, we show that NeRF is highly robust to the zero-mean distribution of raw noise. When optimized over many noisy raw inputs (25-200), NeRF produces a scene representation so accurate that its rendered novel views outperform dedicated single and multi-image deep raw denoisers run on the same wide baseline input images. As a result, our method, which we call RawNeRF, can reconstruct scenes from extremely noisy images captured in near-darkness.},
	urldate = {2022-08-17},
	publisher = {arXiv},
	author = {Mildenhall, Ben and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul and Barron, Jonathan T.},
	month = nov,
	year = {2021},
	note = {arXiv:2111.13679 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{fons_hypertime_2022,
	title = {{HyperTime}: {Implicit} {Neural} {Representation} for {Time} {Series}},
	shorttitle = {{HyperTime}},
	url = {http://arxiv.org/abs/2208.05836},
	abstract = {Implicit neural representations (INRs) have recently emerged as a powerful tool that provides an accurate and resolution-independent encoding of data. Their robustness as general approximators has been shown in a wide variety of data sources, with applications on image, sound, and 3D scene representation. However, little attention has been given to leveraging these architectures for the representation and analysis of time series data. In this paper, we analyze the representation of time series using INRs, comparing different activation functions in terms of reconstruction accuracy and training convergence speed. We show how these networks can be leveraged for the imputation of time series, with applications on both univariate and multivariate data. Finally, we propose a hypernetwork architecture that leverages INRs to learn a compressed latent representation of an entire time series dataset. We introduce an FFT-based loss to guide training so that all frequencies are preserved in the time series. We show that this network can be used to encode time series as INRs, and their embeddings can be interpolated to generate new time series from existing ones. We evaluate our generative method by using it for data augmentation, and show that it is competitive against current state-of-the-art approaches for augmentation of time series.},
	urldate = {2022-08-17},
	publisher = {arXiv},
	author = {Fons, Elizabeth and Sztrajman, Alejandro and El-laham, Yousef and Iosifidis, Alexandros and Vyetrenko, Svitlana},
	month = aug,
	year = {2022},
	note = {arXiv:2208.05836 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{geiger_e3nn_2022,
	title = {e3nn: {Euclidean} {Neural} {Networks}},
	shorttitle = {e3nn},
	url = {http://arxiv.org/abs/2207.09453},
	doi = {10.48550/arXiv.2207.09453},
	abstract = {We present e3nn, a generalized framework for creating E(3) equivariant trainable functions, also known as Euclidean neural networks. e3nn naturally operates on geometry and geometric tensors that describe systems in 3D and transform predictably under a change of coordinate system. The core of e3nn are equivariant operations such as the TensorProduct class or the spherical harmonics functions that can be composed to create more complex modules such as convolutions and attention mechanisms. These core operations of e3nn can be used to efficiently articulate Tensor Field Networks, 3D Steerable CNNs, Clebsch-Gordan Networks, SE(3) Transformers and other E(3) equivariant networks.},
	urldate = {2022-08-16},
	publisher = {arXiv},
	author = {Geiger, Mario and Smidt, Tess},
	month = jul,
	year = {2022},
	note = {arXiv:2207.09453 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{chen_neural_2019,
	title = {Neural {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1806.07366},
	doi = {10.48550/arXiv.1806.07366},
	abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
	urldate = {2022-08-11},
	publisher = {arXiv},
	author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
	month = dec,
	year = {2019},
	note = {arXiv:1806.07366 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{jiang_transgan_2021,
	title = {{TransGAN}: {Two} {Pure} {Transformers} {Can} {Make} {One} {Strong} {GAN}, and {That} {Can} {Scale} {Up}},
	shorttitle = {{TransGAN}},
	url = {http://arxiv.org/abs/2102.07074},
	abstract = {The recent explosive interest on transformers has suggested their potential to become powerful “universal" models for computer vision tasks, such as classiﬁcation, detection, and segmentation. While those attempts mainly study the discriminative models, we explore transformers on some more notoriously difﬁcult vision tasks, e.g., generative adversarial networks (GANs). Our goal is to conduct the ﬁrst pilot study in building a GAN completely free of convolutions, using only pure transformer-based architectures. Our vanilla GAN architecture, dubbed TransGAN, consists of a memory-friendly transformer-based generator that progressively increases feature resolution, and correspondingly a multi-scale discriminator to capture simultaneously semantic contexts and low-level textures. On top of them, we introduce the new module of grid self-attention for alleviating the memory bottleneck further, in order to scale up TransGAN to high-resolution generation. We also develop a unique training recipe including a series of techniques that can mitigate the training instability issues of TransGAN, such as data augmentation, modiﬁed normalization, and relative position encoding. Our best architecture achieves highly competitive performance compared to current stateof-the-art GANs using convolutional backbones. Speciﬁcally, TransGAN sets the new state-of-the-art inception score of 10.43 and FID of 18.28 on STL-10. It also reaches the inception score of 9.02 and FID of 9.26 on CIFAR-10, and 5.28 FID on CelebA 128 × 128, respectively: both on par with the current best results. When it comes to higher-resolution (e.g. 256 × 256) generation tasks, such as on CelebAHQ and LSUN-Church, TransGAN continues to produce diverse visual examples with high ﬁdelity and reasonable texture details. In addition, we dive deep into the transformer-based generation models to understand how their behaviors differ from convolutional ones, by visualizing training dynamics. The code is available at: https://github.com/VITA-Group/TransGAN.},
	language = {en},
	urldate = {2022-08-10},
	publisher = {arXiv},
	author = {Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
	month = dec,
	year = {2021},
	note = {arXiv:2102.07074 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{zhang_styleswin_2022,
	title = {{StyleSwin}: {Transformer}-based {GAN} for {High}-resolution {Image} {Generation}},
	shorttitle = {{StyleSwin}},
	url = {http://arxiv.org/abs/2112.10762},
	abstract = {Despite the tantalizing success in a broad of vision tasks, transformers have not yet demonstrated on-par ability as ConvNets in high-resolution image generative modeling. In this paper, we seek to explore using pure transformers to build a generative adversarial network for high-resolution image synthesis. To this end, we believe that local attention is crucial to strike the balance between computational efficiency and modeling capacity. Hence, the proposed generator adopts Swin transformer in a style-based architecture. To achieve a larger receptive field, we propose double attention which simultaneously leverages the context of the local and the shifted windows, leading to improved generation quality. Moreover, we show that offering the knowledge of the absolute position that has been lost in window-based transformers greatly benefits the generation quality. The proposed StyleSwin is scalable to high resolutions, with both the coarse geometry and fine structures benefit from the strong expressivity of transformers. However, blocking artifacts occur during high-resolution synthesis because performing the local attention in a block-wise manner may break the spatial coherency. To solve this, we empirically investigate various solutions, among which we find that employing a wavelet discriminator to examine the spectral discrepancy effectively suppresses the artifacts. Extensive experiments show the superiority over prior transformer-based GANs, especially on high resolutions, e.g., 1024x1024. The StyleSwin, without complex training strategies, excels over StyleGAN on CelebA-HQ 1024, and achieves on-par performance on FFHQ-1024, proving the promise of using transformers for high-resolution image generation. The code and models will be available at https://github.com/microsoft/StyleSwin.},
	language = {en},
	urldate = {2022-08-10},
	publisher = {arXiv},
	author = {Zhang, Bowen and Gu, Shuyang and Zhang, Bo and Bao, Jianmin and Chen, Dong and Wen, Fang and Wang, Yong and Guo, Baining},
	month = jul,
	year = {2022},
	note = {arXiv:2112.10762 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{kim_pure_2022,
	title = {Pure {Transformers} are {Powerful} {Graph} {Learners}},
	url = {http://arxiv.org/abs/2207.02505},
	doi = {10.48550/arXiv.2207.02505},
	abstract = {We show that standard Transformers without graph-specific modifications can lead to promising results in graph learning both in theory and practice. Given a graph, we simply treat all nodes and edges as independent tokens, augment them with token embeddings, and feed them to a Transformer. With an appropriate choice of token embeddings, we prove that this approach is theoretically at least as expressive as an invariant graph network (2-IGN) composed of equivariant linear layers, which is already more expressive than all message-passing Graph Neural Networks (GNN). When trained on a large-scale graph dataset (PCQM4Mv2), our method coined Tokenized Graph Transformer (TokenGT) achieves significantly better results compared to GNN baselines and competitive results compared to Transformer variants with sophisticated graph-specific inductive bias. Our implementation is available at https://github.com/jw9730/tokengt.},
	urldate = {2022-08-10},
	publisher = {arXiv},
	author = {Kim, Jinwoo and Nguyen, Tien Dat and Min, Seonwoo and Cho, Sungjun and Lee, Moontae and Lee, Honglak and Hong, Seunghoon},
	month = jul,
	year = {2022},
	note = {arXiv:2207.02505 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{hospedales_meta-learning_2020,
	title = {Meta-{Learning} in {Neural} {Networks}: {A} {Survey}},
	shorttitle = {Meta-{Learning} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/2004.05439},
	doi = {10.48550/arXiv.2004.05439},
	abstract = {The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.},
	urldate = {2022-08-10},
	publisher = {arXiv},
	author = {Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
	month = nov,
	year = {2020},
	note = {arXiv:2004.05439 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mathews_uncovering_2021,
	title = {Uncovering turbulent plasma dynamics via deep learning from partial observations},
	volume = {104},
	issn = {2470-0045, 2470-0053},
	url = {http://arxiv.org/abs/2009.05005},
	doi = {10.1103/PhysRevE.104.025205},
	abstract = {One of the most intensely studied aspects of magnetic confinement fusion is edge plasma turbulence which is critical to reactor performance and operation. Drift-reduced Braginskii two-fluid theory has for decades been widely applied to model boundary plasmas with varying success. Towards better understanding edge turbulence in both theory and experiment, we demonstrate that physics-informed neural networks constrained by partial differential equations can accurately learn turbulent fields consistent with the two-fluid theory from just partial observations of a synthetic plasma's electron density and temperature in contrast with conventional equilibrium models. These techniques present a novel paradigm for the advanced design of plasma diagnostics and validation of magnetized plasma turbulence theories in challenging thermonuclear environments.},
	number = {2},
	urldate = {2022-08-08},
	journal = {Physical Review E},
	author = {Mathews, Abhilash and Francisquez, Manaure and Hughes, Jerry and Hatch, David and Zhu, Ben and Rogers, Barrett},
	month = aug,
	year = {2021},
	note = {arXiv:2009.05005 [physics]},
	keywords = {Physics - Plasma Physics},
	pages = {025205},
}

@misc{markidis_old_2021,
	title = {The {Old} and the {New}: {Can} {Physics}-{Informed} {Deep}-{Learning} {Replace} {Traditional} {Linear} {Solvers}?},
	shorttitle = {The {Old} and the {New}},
	url = {http://arxiv.org/abs/2103.09655},
	abstract = {Physics-Informed Neural Networks (PINN) are neural networks encoding the problem governing equations, such as Partial Differential Equations (PDE), as a part of the neural network. PINNs have emerged as a new essential tool to solve various challenging problems, including computing linear systems arising from PDEs, a task for which several traditional methods exist. In this work, we focus first on evaluating the potential of PINNs as linear solvers in the case of the Poisson equation, an omnipresent equation in scientific computing. We characterize PINN linear solvers in terms of accuracy and performance under different network configurations (depth, activation functions, input data set distribution). We highlight the critical role of transfer learning. Our results show that low-frequency components of the solution converge quickly as an effect of the F-principle. In contrast, an accurate solution of the high frequencies requires an exceedingly long time. To address this limitation, we propose integrating PINNs into traditional linear solvers. We show that this integration leads to the development of new solvers whose performance is on par with other high-performance solvers, such as PETSc conjugate gradient linear solvers, in terms of performance and accuracy. Overall, while the accuracy and computational performance are still a limiting factor for the direct use of PINN linear solvers, hybrid strategies combining old traditional linear solver approaches with new emerging deep-learning techniques are among the most promising methods for developing a new class of linear solvers.},
	urldate = {2022-08-08},
	publisher = {arXiv},
	author = {Markidis, Stefano},
	month = jul,
	year = {2021},
	note = {arXiv:2103.09655 [physics]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@misc{noauthor_210309655_nodate,
	title = {[2103.09655] {The} {Old} and the {New}: {Can} {Physics}-{Informed} {Deep}-{Learning} {Replace} {Traditional} {Linear} {Solvers}?},
	url = {https://arxiv.org/abs/2103.09655},
	urldate = {2022-08-08},
}

@misc{chan_efficient_2022,
	title = {Efficient {Geometry}-aware {3D} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/2112.07945},
	abstract = {Unsupervised generation of high-quality multi-view-consistent images and 3D shapes using only collections of single-view 2D photographs has been a long-standing challenge. Existing 3D GANs are either compute-intensive or make approximations that are not 3D-consistent; the former limits quality and resolution of the generated images and the latter adversely affects multi-view consistency and shape quality. In this work, we improve the computational efficiency and image quality of 3D GANs without overly relying on these approximations. We introduce an expressive hybrid explicit-implicit network architecture that, together with other design choices, synthesizes not only high-resolution multi-view-consistent images in real time but also produces high-quality 3D geometry. By decoupling feature generation and neural rendering, our framework is able to leverage state-of-the-art 2D CNN generators, such as StyleGAN2, and inherit their efficiency and expressiveness. We demonstrate state-of-the-art 3D-aware synthesis with FFHQ and AFHQ Cats, among other experiments.},
	urldate = {2022-08-03},
	publisher = {arXiv},
	author = {Chan, Eric R. and Lin, Connor Z. and Chan, Matthew A. and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas and Tremblay, Jonathan and Khamis, Sameh and Karras, Tero and Wetzstein, Gordon},
	month = apr,
	year = {2022},
	note = {arXiv:2112.07945 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning},
}

@article{dumouchel_morphology_2022,
	title = {Morphology of contorted fluid structures},
	volume = {152},
	issn = {0301-9322},
	url = {https://www.sciencedirect.com/science/article/pii/S0301932222000684},
	doi = {10.1016/j.ijmultiphaseflow.2022.104055},
	abstract = {Multiphase flows reveal contorted fluid structures which cannot be described in terms of drop/bubble diameter distribution. Here we use a morphological descriptor which originates from the field of heterogeneous materials that was proved to be nicely tailored for characterizing the microstructure of e.g. porous media. It is based on the Minkowski Functionals – an erudite expression which simply designates the integrated volume, surface, mean and Gaussian curvatures – of all surfaces parallel to the liquid–gas interface. We apply this framework to different multiphase flow systems and prove that the Minkowski Functionals are effective for providing insights into their morphodynamical behavior.},
	language = {en},
	urldate = {2022-08-03},
	journal = {International Journal of Multiphase Flow},
	author = {Dumouchel, C. and Thiesset, F. and Ménard, T.},
	month = jul,
	year = {2022},
	keywords = {Geometry, Interface, Morphology, Multiphase flows, Topology},
	pages = {104055},
}

@article{towne_spectral_2018,
	title = {Spectral proper orthogonal decomposition and its relationship to dynamic mode decomposition and resolvent analysis},
	volume = {847},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/spectral-proper-orthogonal-decomposition-and-its-relationship-to-dynamic-mode-decomposition-and-resolvent-analysis/EC2A6DF76490A0B9EB208CC2CA037717#},
	doi = {10.1017/jfm.2018.283},
	abstract = {We consider the frequency domain form of proper orthogonal decomposition (POD), called spectral proper orthogonal decomposition (SPOD). Spectral POD is derived from a space–time POD problem for statistically stationary flows and leads to modes that each oscillate at a single frequency. This form of POD goes back to the original work of Lumley (Stochastic Tools in Turbulence, Academic Press, 1970), but has been overshadowed by a space-only form of POD since the 1990s. We clarify the relationship between these two forms of POD and show that SPOD modes represent structures that evolve coherently in space and time, while space-only POD modes in general do not. We also establish a relationship between SPOD and dynamic mode decomposition (DMD); we show that SPOD modes are in fact optimally averaged DMD modes obtained from an ensemble DMD problem for stationary flows. Accordingly, SPOD modes represent structures that are dynamic in the same sense as DMD modes but also optimally account for the statistical variability of turbulent flows. Finally, we establish a connection between SPOD and resolvent analysis. The key observation is that the resolvent-mode expansion coefficients must be regarded as statistical quantities to ensure convergent approximations of the flow statistics. When the expansion coefficients are uncorrelated, we show that SPOD and resolvent modes are identical. Our theoretical results and the overall utility of SPOD are demonstrated using two example problems: the complex Ginzburg–Landau equation and a turbulent jet.},
	language = {en},
	urldate = {2022-08-02},
	journal = {Journal of Fluid Mechanics},
	author = {Towne, Aaron and Schmidt, Oliver T. and Colonius, Tim},
	month = jul,
	year = {2018},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, low-dimensional models, turbulent flows},
	pages = {821--867},
}

@article{schmid_dynamic_2010,
	title = {Dynamic mode decomposition of numerical and experimental data},
	volume = {656},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/dynamic-mode-decomposition-of-numerical-and-experimental-data/AA4C763B525515AD4521A6CC5E10DBD4},
	doi = {10.1017/S0022112010001217},
	abstract = {The description of coherent features of fluid flow is essential to our understanding of fluid-dynamical and transport processes. A method is introduced that is able to extract dynamic information from flow fields that are either generated by a (direct) numerical simulation or visualized/measured in a physical experiment. The extracted dynamic modes, which can be interpreted as a generalization of global stability modes, can be used to describe the underlying physical mechanisms captured in the data sequence or to project large-scale problems onto a dynamical system of significantly fewer degrees of freedom. The concentration on subdomains of the flow field where relevant dynamics is expected allows the dissection of a complex flow into regions of localized instability phenomena and further illustrates the flexibility of the method, as does the description of the dynamics within a spatial framework. Demonstrations of the method are presented consisting of a plane channel flow, flow over a two-dimensional cavity, wake flow behind a flexible membrane and a jet passing between two cylinders.},
	language = {en},
	urldate = {2022-08-02},
	journal = {Journal of Fluid Mechanics},
	author = {Schmid, Peter J.},
	month = aug,
	year = {2010},
	note = {Publisher: Cambridge University Press},
	pages = {5--28},
}

@misc{jaegle_perceiver_2021,
	title = {Perceiver: {General} {Perception} with {Iterative} {Attention}},
	shorttitle = {Perceiver},
	url = {http://arxiv.org/abs/2103.03206},
	doi = {10.48550/arXiv.2103.03206},
	abstract = {Biological systems perceive the world by simultaneously processing high-dimensional inputs from modalities as diverse as vision, audition, touch, proprioception, etc. The perception models used in deep learning on the other hand are designed for individual modalities, often relying on domain-specific assumptions such as the local grid structures exploited by virtually all existing vision models. These priors introduce helpful inductive biases, but also lock models to individual modalities. In this paper we introduce the Perceiver - a model that builds upon Transformers and hence makes few architectural assumptions about the relationship between its inputs, but that also scales to hundreds of thousands of inputs, like ConvNets. The model leverages an asymmetric attention mechanism to iteratively distill inputs into a tight latent bottleneck, allowing it to scale to handle very large inputs. We show that this architecture is competitive with or outperforms strong, specialized models on classification tasks across various modalities: images, point clouds, audio, video, and video+audio. The Perceiver obtains performance comparable to ResNet-50 and ViT on ImageNet without 2D convolutions by directly attending to 50,000 pixels. It is also competitive in all modalities in AudioSet.},
	urldate = {2022-08-01},
	publisher = {arXiv},
	author = {Jaegle, Andrew and Gimeno, Felix and Brock, Andrew and Zisserman, Andrew and Vinyals, Oriol and Carreira, Joao},
	month = jun,
	year = {2021},
	note = {arXiv:2103.03206 [cs, eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@misc{skorokhodov_adversarial_2021,
	title = {Adversarial {Generation} of {Continuous} {Images}},
	url = {http://arxiv.org/abs/2011.12026},
	doi = {10.48550/arXiv.2011.12026},
	abstract = {In most existing learning systems, images are typically viewed as 2D pixel arrays. However, in another paradigm gaining popularity, a 2D image is represented as an implicit neural representation (INR) - an MLP that predicts an RGB pixel value given its (x,y) coordinate. In this paper, we propose two novel architectural techniques for building INR-based image decoders: factorized multiplicative modulation and multi-scale INRs, and use them to build a state-of-the-art continuous image GAN. Previous attempts to adapt INRs for image generation were limited to MNIST-like datasets and do not scale to complex real-world data. Our proposed INR-GAN architecture improves the performance of continuous image generators by several times, greatly reducing the gap between continuous image GANs and pixel-based ones. Apart from that, we explore several exciting properties of the INR-based decoders, like out-of-the-box superresolution, meaningful image-space interpolation, accelerated inference of low-resolution images, an ability to extrapolate outside of image boundaries, and strong geometric prior. The project page is located at https://universome.github.io/inr-gan.},
	urldate = {2022-08-01},
	publisher = {arXiv},
	author = {Skorokhodov, Ivan and Ignatyev, Savva and Elhoseiny, Mohamed},
	month = jun,
	year = {2021},
	note = {arXiv:2011.12026 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{elsayed_improved_2021,
	title = {An improved scheme for the interface reconstruction and curvature approximation for flow simulations of two immiscible fluids},
	volume = {144},
	issn = {0301-9322},
	url = {https://www.sciencedirect.com/science/article/pii/S0301932221002378},
	doi = {10.1016/j.ijmultiphaseflow.2021.103805},
	abstract = {A new scheme is proposed for the approximation of the curvature field in the context of two-phase flows. Direct computation of the curvature from the volume fraction distribution produces so-called spurious currents, which are numerical non-physical velocities especially in the vicinity of the interface. The proposed method computes the curvature from the signed distance function. We have implemented the method inside OpenFOAM® framework (an open source C++ toolbox for computational fluid dynamics simulations based on finite volume discretization). The surface tension force has been formulated into the sharp surface force (SSF). The implementation is applicable for general mesh topologies (two or three dimensional polyhedra). Different validation test cases have been performed; static air bubble in water, droplet undergoing linear shear, rising bubble into viscous fluid, and the impact of a viscous droplet on a thin cylindrical fiber. The proposed method shows an accurate calculation of the curvature and a significant reduction of spurious currents by several orders of magnitude. Such reduction of spurious currents allows accurate simulations of surface tension dominated flows such as micro-droplets, or liquid–liquid separation.},
	language = {en},
	urldate = {2022-07-28},
	journal = {International Journal of Multiphase Flow},
	author = {Elsayed, Omar and Kirsch, Ralf and Osterroth, Sebastian and Antonyuk, Sergiy},
	month = nov,
	year = {2021},
	keywords = {Curvature, Level set (LS), Liquid–liquid separation, Signed distance function (SDF), Spurious currents, Volume of fluid (VoF)},
	pages = {103805},
}

@article{yu_generating_2022,
	title = {{GENERATING} {VIDEOS} {WITH} {DYNAMICS}-{AWARE} {IMPLICIT} {GENERATIVE} {ADVERSARIAL} {NETWORKS}},
	language = {en},
	author = {Yu, Sihyun and Tack, Jihoon and Mo, Sangwoo and Kim, Hyunsu and Kim, Junho and Ha, Jung-Woo and Shin, Jinwoo},
	year = {2022},
	pages = {25},
}

@misc{wiesner_implicit_2022,
	title = {Implicit {Neural} {Representations} for {Generative} {Modeling} of {Living} {Cell} {Shapes}},
	url = {http://arxiv.org/abs/2207.06283},
	abstract = {Methods allowing the synthesis of realistic cell shapes could help generate training data sets to improve cell tracking and segmentation in biomedical images. Deep generative models for cell shape synthesis require a light-weight and flexible representation of the cell shape. However, commonly used voxel-based representations are unsuitable for high-resolution shape synthesis, and polygon meshes have limitations when modeling topology changes such as cell growth or mitosis. In this work, we propose to use level sets of signed distance functions (SDFs) to represent cell shapes. We optimize a neural network as an implicit neural representation of the SDF value at any point in a 3D+time domain. The model is conditioned on a latent code, thus allowing the synthesis of new and unseen shape sequences. We validate our approach quantitatively and qualitatively on C. elegans cells that grow and divide, and lung cancer cells with growing complex filopodial protrusions. Our results show that shape descriptors of synthetic cells resemble those of real cells, and that our model is able to generate topologically plausible sequences of complex cell shapes in 3D+time.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Wiesner, David and Suk, Julian and Dummer, Sven and Svoboda, David and Wolterink, Jelmer M.},
	month = jul,
	year = {2022},
	note = {arXiv:2207.06283 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{oord_neural_2018,
	title = {Neural {Discrete} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1711.00937},
	abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Oord, Aaron van den and Vinyals, Oriol and Kavukcuoglu, Koray},
	month = may,
	year = {2018},
	note = {arXiv:1711.00937 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{brooks_generating_2022,
	title = {Generating {Long} {Videos} of {Dynamic} {Scenes}},
	url = {http://arxiv.org/abs/2206.03429},
	abstract = {We present a video generation model that accurately reproduces object motion, changes in camera viewpoint, and new content that arises over time. Existing video generation methods often fail to produce new content as a function of time while maintaining consistencies expected in real environments, such as plausible dynamics and object persistence. A common failure case is for content to never change due to over-reliance on inductive biases to provide temporal consistency, such as a single latent code that dictates content for the entire video. On the other extreme, without long-term consistency, generated videos may morph unrealistically between different scenes. To address these limitations, we prioritize the time axis by redesigning the temporal latent representation and learning long-term consistency from data by training on longer videos. To this end, we leverage a two-phase training strategy, where we separately train using longer videos at a low resolution and shorter videos at a high resolution. To evaluate the capabilities of our model, we introduce two new benchmark datasets with explicit focus on long-term temporal dynamics.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Brooks, Tim and Hellsten, Janne and Aittala, Miika and Wang, Ting-Chun and Aila, Timo and Lehtinen, Jaakko and Liu, Ming-Yu and Efros, Alexei A. and Karras, Tero},
	month = jun,
	year = {2022},
	note = {arXiv:2206.03429 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{esser_taming_2021,
	title = {Taming {Transformers} for {High}-{Resolution} {Image} {Synthesis}},
	url = {http://arxiv.org/abs/2012.09841},
	doi = {10.48550/arXiv.2012.09841},
	abstract = {Designed to learn long-range interactions on sequential data, transformers continue to show state-of-the-art results on a wide variety of tasks. In contrast to CNNs, they contain no inductive bias that prioritizes local interactions. This makes them expressive, but also computationally infeasible for long sequences, such as high-resolution images. We demonstrate how combining the effectiveness of the inductive bias of CNNs with the expressivity of transformers enables them to model and thereby synthesize high-resolution images. We show how to (i) use CNNs to learn a context-rich vocabulary of image constituents, and in turn (ii) utilize transformers to efficiently model their composition within high-resolution images. Our approach is readily applied to conditional synthesis tasks, where both non-spatial information, such as object classes, and spatial information, such as segmentations, can control the generated image. In particular, we present the first results on semantically-guided synthesis of megapixel images with transformers and obtain the state of the art among autoregressive models on class-conditional ImageNet. Code and pretrained models can be found at https://github.com/CompVis/taming-transformers .},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Esser, Patrick and Rombach, Robin and Ommer, Björn},
	month = jun,
	year = {2021},
	note = {arXiv:2012.09841 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{karras_alias-free_nodate,
	title = {Alias-{Free} {Generative} {Adversarial} {Networks}},
	abstract = {We observe that despite their hierarchical convolutional nature, the synthesis process of typical generative adversarial networks depends on absolute pixel coordinates in an unhealthy manner. This manifests itself as, e.g., detail appearing to be glued to image coordinates instead of the surfaces of depicted objects. We trace the root cause to careless signal processing that causes aliasing in the generator network. Interpreting all signals in the network as continuous, we derive generally applicable, small architectural changes that guarantee that unwanted information cannot leak into the hierarchical synthesis process. The resulting networks match the FID of StyleGAN2 but differ dramatically in their internal representations, and they are fully equivariant to translation and rotation even at subpixel scales. Our results pave the way for generative models better suited for video and animation.},
	language = {en},
	author = {Karras, Tero and Aittala, Miika and Härkönen, Erik and Lehtinen, Jaakko and Laine, Samuli and Hellsten, Janne and Aila, Timo},
	pages = {31},
}

@inproceedings{niemeyer_occupancy_2019,
	address = {Seoul, Korea (South)},
	title = {Occupancy {Flow}: {4D} {Reconstruction} by {Learning} {Particle} {Dynamics}},
	isbn = {978-1-72814-803-8},
	shorttitle = {Occupancy {Flow}},
	url = {https://ieeexplore.ieee.org/document/9008276/},
	doi = {10.1109/ICCV.2019.00548},
	abstract = {Deep learning based 3D reconstruction techniques have recently achieved impressive results. However, while stateof-the-art methods are able to output complex 3D geometry, it is not clear how to extend these results to time-varying topologies. Approaches treating each time step individually lack continuity and exhibit slow inference, while traditional 4D reconstruction methods often utilize a template model or discretize the 4D space at ﬁxed resolution. In this work, we present Occupancy Flow, a novel spatio-temporal representation of time-varying 3D geometry with implicit correspondences. Towards this goal, we learn a temporally and spatially continuous vector ﬁeld which assigns a motion vector to every point in space and time. In order to perform dense 4D reconstruction from images or sparse point clouds, we combine our method with a continuous 3D representation. Implicitly, our model yields correspondences over time, thus enabling fast inference while providing a sound physical description of the temporal dynamics. We show that our method can be used for interpolation and reconstruction tasks, and demonstrate the accuracy of the learned correspondences. We believe that Occupancy Flow is a promising new 4D representation which will be useful for a variety of spatio-temporal reconstruction tasks.},
	language = {en},
	urldate = {2022-07-27},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Niemeyer, Michael and Mescheder, Lars and Oechsle, Michael and Geiger, Andreas},
	month = oct,
	year = {2019},
	pages = {5378--5388},
}

@misc{chen_learning_2019,
	title = {Learning {Implicit} {Fields} for {Generative} {Shape} {Modeling}},
	url = {http://arxiv.org/abs/1812.02822},
	doi = {10.48550/arXiv.1812.02822},
	abstract = {We advocate the use of implicit fields for learning generative models of shapes and introduce an implicit field decoder, called IM-NET, for shape generation, aimed at improving the visual quality of the generated shapes. An implicit field assigns a value to each point in 3D space, so that a shape can be extracted as an iso-surface. IM-NET is trained to perform this assignment by means of a binary classifier. Specifically, it takes a point coordinate, along with a feature vector encoding a shape, and outputs a value which indicates whether the point is outside the shape or not. By replacing conventional decoders by our implicit decoder for representation learning (via IM-AE) and shape generation (via IM-GAN), we demonstrate superior results for tasks such as generative shape modeling, interpolation, and single-view 3D reconstruction, particularly in terms of visual quality. Code and supplementary material are available at https://github.com/czq142857/implicit-decoder.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Chen, Zhiqin and Zhang, Hao},
	month = sep,
	year = {2019},
	note = {arXiv:1812.02822 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning},
}

@misc{li_fourier_2022,
	title = {Fourier {Neural} {Operator} with {Learned} {Deformations} for {PDEs} on {General} {Geometries}},
	url = {http://arxiv.org/abs/2207.05209},
	doi = {10.48550/arXiv.2207.05209},
	abstract = {Deep learning surrogate models have shown promise in solving partial differential equations (PDEs). Among them, the Fourier neural operator (FNO) achieves good accuracy, and is significantly faster compared to numerical solvers, on a variety of PDEs, such as fluid flows. However, the FNO uses the Fast Fourier transform (FFT), which is limited to rectangular domains with uniform grids. In this work, we propose a new framework, viz., geo-FNO, to solve PDEs on arbitrary geometries. Geo-FNO learns to deform the input (physical) domain, which may be irregular, into a latent space with a uniform grid. The FNO model with the FFT is applied in the latent space. The resulting geo-FNO model has both the computation efficiency of FFT and the flexibility of handling arbitrary geometries. Our geo-FNO is also flexible in terms of its input formats, viz., point clouds, meshes, and design parameters are all valid inputs. We consider a variety of PDEs such as the Elasticity, Plasticity, Euler's, and Navier-Stokes equations, and both forward modeling and inverse design problems. Geo-FNO is \$10{\textasciicircum}5\$ times faster than the standard numerical solvers and twice more accurate compared to direct interpolation on existing ML-based PDE solvers such as the standard FNO.},
	urldate = {2022-07-26},
	publisher = {arXiv},
	author = {Li, Zongyi and Huang, Daniel Zhengyu and Liu, Burigede and Anandkumar, Anima},
	month = jul,
	year = {2022},
	note = {arXiv:2207.05209 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{qian_reduced_2022,
	title = {Reduced operator inference for nonlinear partial differential equations},
	url = {http://arxiv.org/abs/2102.00083},
	abstract = {We present a new scientific machine learning method that learns from data a computationally inexpensive surrogate model for predicting the evolution of a system governed by a time-dependent nonlinear partial differential equation (PDE), an enabling technology for many computational algorithms used in engineering settings. Our formulation generalizes to the function space PDE setting the Operator Inference method previously developed in [B. Peherstorfer and K. Willcox, Data-driven operator inference for non-intrusive projection-based model reduction, Computer Methods in Applied Mechanics and Engineering, 306 (2016)] for systems governed by ordinary differential equations. The method brings together two main elements. First, ideas from projection-based model reduction are used to explicitly parametrize the learned model by low-dimensional polynomial operators which reflect the known form of the governing PDE. Second, supervised machine learning tools are used to infer from data the reduced operators of this physics-informed parametrization. For systems whose governing PDEs contain more general (non-polynomial) nonlinearities, the learned model performance can be improved through the use of lifting variable transformations, which expose polynomial structure in the PDE. The proposed method is demonstrated on two examples: a heat equation model problem that demonstrates the benefits of the function space formulation in terms of consistency with the underlying continuous truth, and a three-dimensional combustion simulation with over 18 million degrees of freedom, for which the learned reduced models achieve accurate predictions with a dimension reduction of five orders of magnitude and model runtime reduction of up to nine orders of magnitude.},
	urldate = {2022-07-26},
	publisher = {arXiv},
	author = {Qian, Elizabeth and Farcas, Ionut-Gabriel and Willcox, Karen},
	month = feb,
	year = {2022},
	note = {arXiv:2102.00083 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{rim_manifold_2020,
	title = {Manifold {Approximations} via {Transported} {Subspaces}: {Model} reduction for transport-dominated problems},
	shorttitle = {Manifold {Approximations} via {Transported} {Subspaces}},
	url = {http://arxiv.org/abs/1912.13024},
	doi = {10.48550/arXiv.1912.13024},
	abstract = {This work presents a method for constructing online-efficient reduced models of large-scale systems governed by parametrized nonlinear scalar conservation laws. The solution manifolds induced by transport-dominated problems such as hyperbolic conservation laws typically exhibit nonlinear structures, which means that traditional model reduction methods based on linear approximations are inefficient when applied to these problems. In contrast, the approach introduced in this work derives reduced approximations that are nonlinear by explicitly composing global transport dynamics with locally linear approximations of the solution manifolds. A time-stepping scheme evolves the nonlinear reduced models by transporting local approximation spaces along the characteristic curves of the governing equations. The proposed computational procedure allows an offline/online decomposition and is online-efficient in the sense that the complexity of accurately time-stepping the nonlinear reduced model is independent of that of the full model. Numerical experiments with transport through heterogeneous media and the Burgers' equation show orders of magnitude speedups of the proposed nonlinear reduced models based on transported subspaces compared to traditional linear reduced models and full models.},
	urldate = {2022-07-26},
	publisher = {arXiv},
	author = {Rim, Donsub and Peherstorfer, Benjamin and Mandli, Kyle T.},
	month = dec,
	year = {2020},
	note = {arXiv:1912.13024 [cs, math]},
	keywords = {78M34, 41A46, 35F20, 78M12, Mathematics - Numerical Analysis},
}

@article{arnold-medabalimi_large-eddy_2022,
	title = {Large-eddy simulation and challenges for projection-based reduced-order modeling of a gas turbine model combustor},
	volume = {14},
	issn = {1756-8277},
	url = {https://doi.org/10.1177/17568277221100650},
	doi = {10.1177/17568277221100650},
	abstract = {Computationally efficient modeling of gas turbine combustion is challenging due to the chaotic multi-scale physics and the complex non-linear interactions between acoustic, hydrodynamic, and chemical processes. A large-eddy simulation, referred to as the full order model (FOM), is performed for a gas turbine model combustor with turbulent combustion effects modeled using a flamelet-based method. Modal analysis reveals a high degree of correlation with averaged and instantaneous high-frequency particle image velocimetry fields. The dynamics of the precessing vortex core is quantitatively characterized using dynamic mode decomposition. The governing equations of the FOM are projected onto a low-dimensional linear manifold to construct a reduced-order model (ROM). A discretely-consistent least squares projection is used to guarantee global stability. The ROM provides an accurate reconstruction of the combustion dynamics within the training region, but faces a significant challenge in future state predictions. This limitation is mainly due to the increased projection error, which in turn is a direct consequence of the highly chaotic nature of the flow field, involving a wide range of dispersed coherent structures. This shortcoming is overcome using an adaptive basis method which yields accurate predictions of dynamics beyond the training region consistent with the FOM. Formal projection-based ROMs have not been applied to a problem of this scale and complexity, and achieving accurate and efficient ROMs is a grand challenge problem. A production-ready ROM method will significantly decrease the computational cost of the flame dynamics as well as the portability of this prediction to smaller-scale computers.},
	language = {en},
	number = {1-2},
	urldate = {2022-07-26},
	journal = {International Journal of Spray and Combustion Dynamics},
	author = {Arnold-Medabalimi, Nicholas and Huang, Cheng and Duraisamy, Karthik},
	month = mar,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {Large-eddy simulation, combustion dynamics, gas turbine swirl combustor, modal decomposition, reduced-order modeling},
	pages = {153--175},
}

@inproceedings{yang_geometry_2021,
	title = {Geometry {Processing} with {Neural} {Fields}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/bd686fd640be98efaae0091fa301e613-Abstract.html},
	abstract = {Most existing geometry processing algorithms use meshes as the default shape representation.  Manipulating meshes, however, requires one to maintain high quality in the surface discretization.  For example, changing the topology of a mesh usually requires additional procedures such as remeshing. This paper instead proposes the use of neural fields for geometry processing. Neural fields can compactly store complicated shapes without spatial discretization.   Moreover, neural fields are infinitely differentiable, which allows them to be optimized for objectives that involve higher-order derivatives.  This raises the question: can geometry processing be done entirely using neural fields? We introduce loss functions and architectures to show that some of the most challenging geometry processing tasks, such as deformation and filtering, can be done with neural fields. Experimental results show that our methods are on par with the well-established mesh-based methods without committing to a particular surface discretization. Code is available at https://github.com/stevenygd/NFGP.},
	urldate = {2022-07-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Yang, Guandao and Belongie, Serge and Hariharan, Bharath and Koltun, Vladlen},
	year = {2021},
	pages = {22483--22497},
}

@article{yang_geometry_nodate,
	title = {Geometry {Processing} with {Neural} {Fields}},
	abstract = {Most existing geometry processing algorithms use meshes as the default shape representation. Manipulating meshes, however, requires one to maintain high quality in the surface discretization. For example, changing the topology of a mesh usually requires additional procedures such as remeshing. This paper instead proposes the use of neural fields for geometry processing. Neural fields can compactly store complicated shapes without spatial discretization. Moreover, neural fields are infinitely differentiable, which allows them to be optimized for objectives that involve higher-order derivatives. This raises the question: can geometry processing be done entirely using neural fields? We introduce loss functions and architectures to show that some of the most challenging geometry processing tasks, such as deformation and filtering, can be done with neural fields. Experimental results show that our methods are on par with the well-established mesh-based methods without committing to a particular surface discretization. Code is available at https://github.com/stevenygd/NFGP.},
	language = {en},
	author = {Yang, Guandao and Belongie, Serge and Hariharan, Bharath and Koltun, Vladlen},
	pages = {15},
}

@misc{rampasek_recipe_2022,
	title = {Recipe for a {General}, {Powerful}, {Scalable} {Graph} {Transformer}},
	url = {http://arxiv.org/abs/2205.12454},
	doi = {10.48550/arXiv.2205.12454},
	abstract = {We propose a recipe on how to build a general, powerful, scalable (GPS) graph Transformer with linear complexity and state-of-the-art results on a diverse set of benchmarks. Graph Transformers (GTs) have gained popularity in the field of graph representation learning with a variety of recent publications but they lack a common foundation about what constitutes a good positional or structural encoding, and what differentiates them. In this paper, we summarize the different types of encodings with a clearer definition and categorize them as being \${\textbackslash}textit\{local\}\$, \${\textbackslash}textit\{global\}\$ or \${\textbackslash}textit\{relative\}\$. Further, GTs remain constrained to small graphs with few hundred nodes, and we propose the first architecture with a complexity linear to the number of nodes and edges \$O(N+E)\$ by decoupling the local real-edge aggregation from the fully-connected Transformer. We argue that this decoupling does not negatively affect the expressivity, with our architecture being a universal function approximator for graphs. Our GPS recipe consists of choosing 3 main ingredients: (i) positional/structural encoding, (ii) local message-passing mechanism, and (iii) global attention mechanism. We build and open-source a modular framework \${\textbackslash}textit\{GraphGPS\}\$ that supports multiple types of encodings and that provides efficiency and scalability both in small and large graphs. We test our architecture on 11 benchmarks and show very competitive results on all of them, show-casing the empirical benefits gained by the modularity and the combination of different strategies.},
	urldate = {2022-07-26},
	publisher = {arXiv},
	author = {Rampášek, Ladislav and Galkin, Mikhail and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
	month = jul,
	year = {2022},
	note = {arXiv:2205.12454 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{morimoto_assessments_2022,
	title = {Assessments of epistemic uncertainty using {Gaussian} stochastic weight averaging for fluid-flow regression},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278922001828},
	doi = {10.1016/j.physd.2022.133454},
	abstract = {We use Gaussian stochastic weight averaging (SWAG) to assess the epistemic uncertainty associated with neural-network-based function approximation relevant to fluid flows. SWAG approximates a posterior Gaussian distribution of each weight, given training data, and a constant learning rate. Having access to this distribution, it is able to create multiple models with various combinations of sampled weights, which can be used to obtain ensemble predictions. The average of such an ensemble can be regarded as the ‘mean estimation’, whereas its standard deviation can be used to construct ‘confidence intervals’, which enable us to perform uncertainty quantification (UQ) with regard to the training process of neural networks. We utilize representative neural-network-based function approximation tasks for the following cases: (i) a two-dimensional circular-cylinder wake; (ii) the DayMET dataset (maximum daily temperature in North America); (iii) a three-dimensional square-cylinder wake; and (iv) urban flow, to assess the generalizability of the present idea for a wide range of complex datasets. SWAG-based UQ can be applied regardless of the network architecture, and therefore, we demonstrate the applicability of the method for two types of neural networks: (i) global field reconstruction from sparse sensors by combining convolutional neural network (CNN) and multi-layer perceptron (MLP); and (ii) far-field state estimation from sectional data with two-dimensional CNN. We find that SWAG can obtain physically-interpretable confidence-interval estimates from the perspective of epistemic uncertainty. This capability supports its use for a wide range of problems in science and engineering.},
	language = {en},
	urldate = {2022-07-26},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Morimoto, Masaki and Fukami, Kai and Maulik, Romit and Vinuesa, Ricardo and Fukagata, Koji},
	month = jul,
	year = {2022},
	keywords = {Fluid flows, Machine learning, Neural network, Uncertainty quantification},
	pages = {133454},
}

@article{rezaeiravesh_uncertainty-quantification_2022,
	title = {An uncertainty-quantification framework for assessing accuracy, sensitivity, and robustness in computational fluid dynamics},
	volume = {62},
	issn = {1877-7503},
	url = {https://www.sciencedirect.com/science/article/pii/S1877750322000941},
	doi = {10.1016/j.jocs.2022.101688},
	abstract = {Combining different existing uncertainty quantification (UQ) techniques, a framework is obtained to assess a set of metrics in computational physics problems, in general, and computational fluid dynamics (CFD), in particular. The metrics include accuracy, sensitivity and robustness of the simulator’s outputs with respect to uncertain inputs and parameters. These inputs and parameters are divided into two groups: based on the variation of the first group (e.g. numerical/computational parameters such as grid resolution), a computer experiment is designed, the data of which may become uncertain due to the parameters of the second group (e.g. finite time-averaging). To construct a surrogate model based on uncertain data, Gaussian process regression (GPR) with observation-dependent (heteroscedastic) noise is used. To estimate the propagated uncertainties in the simulator’s outputs from the first group of parameters, a probabilistic version of the polynomial chaos expansion (PCE) is employed Global sensitivity analysis is performed using probabilistic Sobol indices. To illustrate its capabilities, the framework is applied to the scale-resolving simulations of turbulent channel and lid-driven cavity flows using the open-source CFD solver Nek5000. It is shown that at wall distances where the time-averaging uncertainty is high, the quantities of interest are also more sensitive to numerical/computational parameters. In particular for high-fidelity codes such as Nek5000, a thorough assessment of the results’ accuracy and reliability is crucial. The detailed analyses and the resulting conclusions can enhance our insight into the influence of different factors on physics simulations, in particular the simulations of high-Reynolds-number turbulent flows including wall turbulence.},
	language = {en},
	urldate = {2022-07-25},
	journal = {Journal of Computational Science},
	author = {Rezaeiravesh, S. and Vinuesa, R. and Schlatter, P.},
	month = jul,
	year = {2022},
	keywords = {Combined uncertainties, Computational fluid dynamics, Gaussian process regression, Polynomial chaos expansion, Uncertainty quantification},
	pages = {101688},
}

@misc{chen_3d_2022,
	title = {{3D} {Equivariant} {Graph} {Implicit} {Functions}},
	url = {http://arxiv.org/abs/2203.17178},
	abstract = {In recent years, neural implicit representations have made remarkable progress in modeling of 3D shapes with arbitrary topology. In this work, we address two key limitations of such representations, in failing to capture local 3D geometric fine details, and to learn from and generalize to shapes with unseen 3D transformations. To this end, we introduce a novel family of graph implicit functions with equivariant layers that facilitates modeling fine local details and guaranteed robustness to various groups of geometric transformations, through local \$k\$-NN graph embeddings with sparse point set observations at multiple resolutions. Our method improves over the existing rotation-equivariant implicit function from 0.69 to 0.89 (IoU) on the ShapeNet reconstruction task. We also show that our equivariant implicit function can be extended to other types of similarity transformations and generalizes to unseen translations and scaling.},
	urldate = {2022-07-21},
	publisher = {arXiv},
	author = {Chen, Yunlu and Fernando, Basura and Bilen, Hakan and Nießner, Matthias and Gavves, Efstratios},
	month = mar,
	year = {2022},
	note = {arXiv:2203.17178 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{chiang_stylizing_2022,
	title = {Stylizing {3D} {Scene} via {Implicit} {Representation} and {HyperNetwork}},
	url = {http://arxiv.org/abs/2105.13016},
	abstract = {In this work, we aim to address the 3D scene stylization problem - generating stylized images of the scene at arbitrary novel view angles. A straightforward solution is to combine existing novel view synthesis and image/video style transfer approaches, which often leads to blurry results or inconsistent appearance. Inspired by the high-quality results of the neural radiance fields (NeRF) method, we propose a joint framework to directly render novel views with the desired style. Our framework consists of two components: an implicit representation of the 3D scene with the neural radiance fields model, and a hypernetwork to transfer the style information into the scene representation. In particular, our implicit representation model disentangles the scene into the geometry and appearance branches, and the hypernetwork learns to predict the parameters of the appearance branch from the reference style image. To alleviate the training difficulties and memory burden, we propose a two-stage training procedure and a patch sub-sampling approach to optimize the style and content losses with the neural radiance fields model. After optimization, our model is able to render consistent novel views at arbitrary view angles with arbitrary style. Both quantitative evaluation and human subject study have demonstrated that the proposed method generates faithful stylization results with consistent appearance across different views.},
	urldate = {2022-07-21},
	publisher = {arXiv},
	author = {Chiang, Pei-Ze and Tsai, Meng-Shiun and Tseng, Hung-Yu and Lai, Wei-sheng and Chiu, Wei-Chen},
	month = jan,
	year = {2022},
	note = {arXiv:2105.13016 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{belbute-peres_hyperpinn_2021,
	title = {{HyperPINN}: {Learning} parameterized differential equations with physics-informed hypernetworks},
	shorttitle = {{HyperPINN}},
	url = {http://arxiv.org/abs/2111.01008},
	doi = {10.48550/arXiv.2111.01008},
	abstract = {Many types of physics-informed neural network models have been proposed in recent years as approaches for learning solutions to differential equations. When a particular task requires solving a differential equation at multiple parameterizations, this requires either re-training the model, or expanding its representation capacity to include the parameterization -- both solution that increase its computational cost. We propose the HyperPINN, which uses hypernetworks to learn to generate neural networks that can solve a differential equation from a given parameterization. We demonstrate with experiments on both a PDE and an ODE that this type of model can lead to neural network solutions to differential equations that maintain a small size, even when learning a family of solutions over a parameter space.},
	urldate = {2022-07-21},
	publisher = {arXiv},
	author = {Belbute-Peres, Filipe de Avila and Chen, Yi-fan and Sha, Fei},
	month = oct,
	year = {2021},
	note = {arXiv:2111.01008 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{jumper_highly_2021,
	title = {Highly accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03819-2},
	doi = {10.1038/s41586-021-03819-2},
	abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years9. Despite recent progress10–14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	language = {en},
	number = {7873},
	urldate = {2022-07-21},
	journal = {Nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	month = aug,
	year = {2021},
	note = {Number: 7873
Publisher: Nature Publishing Group},
	keywords = {Computational biophysics, Machine learning, Protein structure predictions, Structural biology},
	pages = {583--589},
}

@article{schmid_dynamic_2022,
	title = {Dynamic {Mode} {Decomposition} and {Its} {Variants}},
	volume = {54},
	url = {https://doi.org/10.1146/annurev-fluid-030121-015835},
	doi = {10.1146/annurev-fluid-030121-015835},
	abstract = {Dynamic mode decomposition (DMD) is a factorization and dimensionality reduction technique for data sequences. In its most common form, it processes high-dimensional sequential measurements, extracts coherent structures, isolates dynamic behavior, and reduces complex evolution processes to their dominant features and essential components. The decomposition is intimately related to Koopman analysis and, since its introduction, has spawned various extensions, generalizations, and improvements. It has been applied to numerical and experimental data sequences taken from simple to complex fluid systems and has also had an impact beyond fluid dynamics in, for example, video surveillance, epidemiology, neurobiology, and financial engineering. This review focuses on the practical aspects of DMD and its variants, as well as on its usage and characteristics as a quantitative tool for the analysis of complex fluid processes.},
	number = {1},
	urldate = {2022-07-20},
	journal = {Annual Review of Fluid Mechanics},
	author = {Schmid, Peter J.},
	year = {2022},
	note = {\_eprint: https://doi.org/10.1146/annurev-fluid-030121-015835},
	keywords = {Koopman analysis, data decomposition, dynamical systems, model reduction, quantitative flow analysis, spectral analysis},
	pages = {225--254},
}

@misc{shang_deep_2022,
	title = {Deep {Petrov}-{Galerkin} {Method} for {Solving} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2201.12995},
	abstract = {Deep neural networks are powerful tools for approximating functions, and they are applied to successfully solve various problems in many fields. In this paper, we propose a neural network-based numerical method to solve partial differential equations. In this new framework, the method is designed on weak formulations, and the unknown functions are approximated by deep neural networks and test functions can be chosen by different approaches, for instance, basis functions of finite element methods, neural networks, and so on. Because the spaces of trial function and test function are different, we name this new approach by Deep Petrov-Galerkin Method (DPGM). The resulted linear system is not necessarily to be symmetric and square, so the discretized problem is solved by a least-square method. Take the Poisson problem as an example, mixed DPGMs based on several mixed formulations are proposed and studied as well. In addition, we apply the DPGM to solve two classical time-dependent problems based on the space-time approach, that is, the unknown function is approximated by a neural network, in which temporal variable and spatial variables are treated equally, and the initial conditions are regarded as boundary conditions for the space-time domain. Finally, several numerical examples are presented to show the performance of the DPGMs, and we observe that this new method outperforms traditional numerical methods in several aspects.},
	urldate = {2022-07-19},
	publisher = {arXiv},
	author = {Shang, Yong and Wang, Fei and Sun, Jingbo},
	month = jan,
	year = {2022},
	note = {arXiv:2201.12995 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
}

@misc{austin_structured_2021,
	title = {Structured {Denoising} {Diffusion} {Models} in {Discrete} {State}-{Spaces}},
	url = {http://arxiv.org/abs/2107.03006},
	doi = {10.48550/arXiv.2107.03006},
	abstract = {Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusion-like generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. 2021, by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss. For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on LM1B. On the image dataset CIFAR-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space DDPM model.},
	urldate = {2022-07-13},
	publisher = {arXiv},
	author = {Austin, Jacob and Johnson, Daniel D. and Ho, Jonathan and Tarlow, Daniel and Berg, Rianne van den},
	month = jul,
	year = {2021},
	note = {arXiv:2107.03006 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{grattarola_generalised_2022,
	title = {Generalised {Implicit} {Neural} {Representations}},
	url = {http://arxiv.org/abs/2205.15674},
	doi = {10.48550/arXiv.2205.15674},
	abstract = {We consider the problem of learning implicit neural representations (INRs) for signals on non-Euclidean domains. In the Euclidean case, INRs are trained on a discrete sampling of a signal over a regular lattice. Here, we assume that the continuous signal exists on some unknown topological space from which we sample a discrete graph. In the absence of a coordinate system to identify the sampled nodes, we propose approximating their location with a spectral embedding of the graph. This allows us to train INRs without knowing the underlying continuous domain, which is the case for most graph signals in nature, while also making the INRs equivariant under the symmetry group of the domain. We show experiments with our method on various real-world signals on non-Euclidean domains.},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Grattarola, Daniele and Vandergheynst, Pierre},
	month = may,
	year = {2022},
	note = {arXiv:2205.15674 [cs, eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
}

@misc{fu_simulate_2022,
	title = {Simulate {Time}-integrated {Coarse}-grained {Molecular} {Dynamics} with {Geometric} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2204.10348},
	doi = {10.48550/arXiv.2204.10348},
	abstract = {Molecular dynamics (MD) simulation is the workhorse of various scientific domains but is limited by high computational cost. Learning-based force fields have made major progress in accelerating ab-initio MD simulation but are still not fast enough for many real-world applications that require long-time MD simulation. In this paper, we adopt a different machine learning approach where we coarse-grain a physical system using graph clustering, and model the system evolution with a very large time-integration step using graph neural networks. A novel score-based GNN refinement module resolves the long-standing challenge of long-time simulation instability. Despite only trained with short MD trajectory data, our learned simulator can generalize to unseen novel systems and simulate for much longer than the training trajectories. Properties requiring 10-100 ns level long-time dynamics can be accurately recovered at several-orders-of-magnitude higher speed than classical force fields. We demonstrate the effectiveness of our method on two realistic complex systems: (1) single-chain coarse-grained polymers in implicit solvent; (2) multi-component Li-ion polymer electrolyte systems.},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Fu, Xiang and Xie, Tian and Rebello, Nathan J. and Olsen, Bradley D. and Jaakkola, Tommi},
	month = jun,
	year = {2022},
	note = {arXiv:2204.10348 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@misc{callaham_multiscale_2022,
	title = {Multiscale model reduction for incompressible flows},
	url = {http://arxiv.org/abs/2206.13205},
	abstract = {Many unsteady flows exhibiting complex dynamics are nevertheless characterized by emergent large-scale coherence in space and time. Reduced-order models based on Galerkin projection of the governing equations onto an orthogonal modal basis approximate the flow as a low-dimensional dynamical system with linear and quadratic terms. However, these Galerkin models often fail to reproduce the true dynamics, in part because they ignore important nonlinear interactions with unresolved flow scales. Here, we use a separation of time scales between the resolved and subscale variables to derive a reduced-order model with cubic closure terms for the truncated modes, generalizing the classic Stuart-Landau equation. The leading order cubic terms are determined by averaging out fast variables through a perturbation series approximation of the action of a stochastic Koopman operator. We show analytically that this multiscale closure model can capture both the effects of mean-flow deformation and the energy cascade before demonstrating improved stability and accuracy in models of chaotic lid-driven cavity flow and vortex pairing in a mixing layer. This approach to closure modeling establishes a general theory for the origin and role of cubic nonlinearities in low-dimensional models of incompressible flows},
	urldate = {2022-07-04},
	publisher = {arXiv},
	author = {Callaham, Jared L. and Loiseau, Jean-Christophe and Brunton, Steven L.},
	month = jun,
	year = {2022},
	note = {arXiv:2206.13205 [physics]},
	keywords = {Physics - Fluid Dynamics},
}

@inproceedings{towne_space-time_2021,
	address = {VIRTUAL EVENT},
	title = {Space-time {Galerkin} projection via spectral proper orthogonal decomposition and resolvent modes},
	isbn = {978-1-62410-609-5},
	url = {https://arc.aiaa.org/doi/10.2514/6.2021-1676},
	doi = {10.2514/6.2021-1676},
	language = {en},
	urldate = {2022-07-04},
	booktitle = {{AIAA} {Scitech} 2021 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Towne, Aaron},
	month = jan,
	year = {2021},
}

@misc{shang_deep_2022-1,
	title = {Deep {Petrov}-{Galerkin} {Method} for {Solving} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2201.12995},
	abstract = {Deep neural networks are powerful tools for approximating functions, and they are applied to successfully solve various problems in many fields. In this paper, we propose a neural network-based numerical method to solve partial differential equations. In this new framework, the method is designed on weak formulations, and the unknown functions are approximated by deep neural networks and test functions can be chosen by different approaches, for instance, basis functions of finite element methods, neural networks, and so on. Because the spaces of trial function and test function are different, we name this new approach by Deep Petrov-Galerkin Method (DPGM). The resulted linear system is not necessarily to be symmetric and square, so the discretized problem is solved by a least-square method. Take the Poisson problem as an example, mixed DPGMs based on several mixed formulations are proposed and studied as well. In addition, we apply the DPGM to solve two classical time-dependent problems based on the space-time approach, that is, the unknown function is approximated by a neural network, in which temporal variable and spatial variables are treated equally, and the initial conditions are regarded as boundary conditions for the space-time domain. Finally, several numerical examples are presented to show the performance of the DPGMs, and we observe that this new method outperforms traditional numerical methods in several aspects.},
	urldate = {2022-07-04},
	publisher = {arXiv},
	author = {Shang, Yong and Wang, Fei and Sun, Jingbo},
	month = jan,
	year = {2022},
	note = {arXiv:2201.12995 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
}

@article{chu_stochastic_2021,
	title = {A stochastic {SPOD}-{Galerkin} model for broadband turbulent flows},
	volume = {35},
	issn = {0935-4964, 1432-2250},
	url = {http://arxiv.org/abs/2012.02902},
	doi = {10.1007/s00162-021-00588-6},
	abstract = {The use of spectral proper orthogonal decomposition (SPOD) to construct low-order models for broadband turbulent flows is explored. The choice of SPOD modes as basis vectors is motivated by their optimality and space-time coherence properties for statistically stationary flows. This work follows the modeling paradigm that complex nonlinear fluid dynamics can be approximated as stochastically forced linear systems. The proposed stochastic two-level SPOD-Galerkin model governs a compound state consisting of the modal expansion coefficients and forcing coefficients. In the first level, the modal expansion coefficients are advanced by the forced linearized Navier-Stokes operator under the linear time-invariant assumption. The second level governs the forcing coefficients, which compensate for the offset between the linear approximation and the true state. At this level, least squares regression is used to achieve closure by modeling nonlinear interactions between modes. The statistics of the remaining residue are used to construct a dewhitening filter that facilitates the use of white noise to drive the model. If the data residue is used as the sole input, the model accurately recovers the original flow trajectory for all times. If the residue is modeled as stochastic input, then the model generates surrogate data that accurately reproduces the second-order statistics and dynamics of the original data. The stochastic model uncertainty, predictability, and stability are quantified analytically and through Monte Carlo simulations. The model is demonstrated on large eddy simulation data of a turbulent jet at Mach number \$M=0.9\$ and Reynolds number of \$Re\_D{\textbackslash}approx 10{\textasciicircum}6\$.},
	number = {6},
	urldate = {2022-07-04},
	journal = {Theoretical and Computational Fluid Dynamics},
	author = {Chu, Tianyi and Schmidt, Oliver T.},
	month = dec,
	year = {2021},
	note = {arXiv:2012.02902 [nlin, physics:physics]},
	keywords = {Nonlinear Sciences - Chaotic Dynamics, Physics - Data Analysis, Statistics and Probability, Physics - Fluid Dynamics},
	pages = {759--782},
}

@misc{chen_3d_2022-1,
	title = {{3D} {Equivariant} {Graph} {Implicit} {Functions}},
	url = {http://arxiv.org/abs/2203.17178},
	doi = {10.48550/arXiv.2203.17178},
	abstract = {In recent years, neural implicit representations have made remarkable progress in modeling of 3D shapes with arbitrary topology. In this work, we address two key limitations of such representations, in failing to capture local 3D geometric fine details, and to learn from and generalize to shapes with unseen 3D transformations. To this end, we introduce a novel family of graph implicit functions with equivariant layers that facilitates modeling fine local details and guaranteed robustness to various groups of geometric transformations, through local \$k\$-NN graph embeddings with sparse point set observations at multiple resolutions. Our method improves over the existing rotation-equivariant implicit function from 0.69 to 0.89 (IoU) on the ShapeNet reconstruction task. We also show that our equivariant implicit function can be extended to other types of similarity transformations and generalizes to unseen translations and scaling.},
	urldate = {2022-07-04},
	publisher = {arXiv},
	author = {Chen, Yunlu and Fernando, Basura and Bilen, Hakan and Nießner, Matthias and Gavves, Efstratios},
	month = mar,
	year = {2022},
	note = {arXiv:2203.17178 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{costa_gpu_2021,
	series = {Development and {Application} of {Open}-source {Software} for {Problems} with {Numerical} {PDEs}},
	title = {{GPU} acceleration of {CaNS} for massively-parallel direct numerical simulations of canonical fluid flows},
	volume = {81},
	issn = {0898-1221},
	url = {https://www.sciencedirect.com/science/article/pii/S0898122120300092},
	doi = {10.1016/j.camwa.2020.01.002},
	abstract = {This work presents the GPU acceleration of the open-source code CaNS for very fast massively-parallel simulations of canonical fluid flows. The distinct feature of the many-CPU Navier–Stokes solver in CaNS is its fast direct solver for the second-order finite-difference Poisson equation, based on the method of eigenfunction expansions. The solver implements all the boundary conditions valid for this type of problems in a unified framework. Here, we extend the solver for GPU-accelerated clusters using CUDA Fortran. The porting makes extensive use of CUF kernels and has been greatly simplified by the unified memory feature of CUDA Fortran, which handles the data migration between host (CPU) and device (GPU) without defining new arrays in the source code. The overall implementation has been validated against benchmark data for turbulent channel flow and its performance assessed on a NVIDIA DGX-2 system (16 T V100 32Gb, connected with NVLink via NVSwitch). The wall-clock time per time step of the GPU-accelerated implementation is impressively small when compared to its CPU implementation on state-of-the-art many-CPU clusters, as long as the domain partitioning is sufficiently small that the data resides mostly on the GPUs. The implementation has been made freely available and open source under the terms of an MIT license.},
	language = {en},
	urldate = {2022-06-30},
	journal = {Computers \& Mathematics with Applications},
	author = {Costa, Pedro and Phillips, Everett and Brandt, Luca and Fatica, Massimiliano},
	month = jan,
	year = {2021},
	keywords = {Computational fluid dynamics, Direct numerical simulation, Fast Poisson solver, GPU acceleration},
	pages = {502--511},
}

@article{costa_fft-based_2018,
	title = {A {FFT}-based finite-difference solver for massively-parallel direct numerical simulations of turbulent flows},
	volume = {76},
	issn = {0898-1221},
	url = {https://www.sciencedirect.com/science/article/pii/S089812211830405X},
	doi = {10.1016/j.camwa.2018.07.034},
	abstract = {We present an efficient solver for massively-parallel direct numerical simulations of incompressible turbulent flows. The method uses a second-order, finite-volume pressure-correction scheme, where the pressure Poisson equation is solved with the method of eigenfunction expansions. This approach allows for very efficient FFT-based solvers in problems with different combinations of homogeneous pressure boundary conditions. Our algorithm explores all combinations of pressure boundary conditions valid for such a solver, in a single, general framework. The method is implemented in a 2D pencil-like domain decomposition, which enables efficient massively-parallel simulations. The implementation was validated against different canonical flows, and its computational performance was examined. Excellent strong scaling performance up to 104 cores is demonstrated for a domain with 109 spatial degrees of freedom, corresponding to a very small wall-clock time/time step. The resulting tool, CaNS, has been made freely available and open-source.},
	language = {en},
	number = {8},
	urldate = {2022-06-30},
	journal = {Computers \& Mathematics with Applications},
	author = {Costa, Pedro},
	month = oct,
	year = {2018},
	keywords = {Direct numerical simulations, Fast Poisson solver, High-performance computing, Turbulent flows},
	pages = {1853--1862},
}

@article{endres_discrete_2022,
	title = {A discrete differential geometric formulation of multiphase surface interfaces for scalable multiphysics equilibrium simulations},
	volume = {257},
	issn = {0009-2509},
	url = {https://www.sciencedirect.com/science/article/pii/S0009250922002652},
	doi = {10.1016/j.ces.2022.117681},
	abstract = {Many systems in fluid dynamics and materials science are modelled using multiphase energy balances which can be reduced to an interface, curvature-driven mechanical problem. When simulating these systems, it is desirable to understand the details and changes of the underlying micro- and mesostructures. However, conventional numerical methods formulated in Cartesian coordinates are incapable of accurately simulating many complex systems over the space and timespans of interest. In this work, we demonstrate how modern developments in the field of discrete differential geometry can be exploited to greatly reduce the computational resources required in the simulation of multiphase systems. In particular we show how local–global theorems such as the discrete Gauss-Bonnet Theorem can be used to compute the exact mean normal- and geodesic curvatures of convex interfaces in equilibrium. In addition, we provide error estimates needed for a particular mesh refinement to retain a predetermined accuracy in the simulations. Our coordinate free formulation can be applied to any data structure used for multiphysics simulations when the underlying space of the interface is manifold. In order to validate the accuracy of the formulation with physical systems, it was applied to test cases of capillary rise, particle–particle bridges and a Sessile microdroplet system with near-exact results (subject to floating-point errors).},
	language = {en},
	urldate = {2022-06-30},
	journal = {Chemical Engineering Science},
	author = {Endres, Stefan Christian and Avila, Marc and Mädler, Lutz},
	month = aug,
	year = {2022},
	keywords = {Discrete differential geometry (DDG), Surface phase interfaces, Surface tension, Three-phase contact angle},
	pages = {117681},
}

@misc{yousif_transformer-based_2022,
	title = {A transformer-based synthetic-inflow generator for spatially-developing turbulent boundary layers},
	url = {http://arxiv.org/abs/2206.01618},
	doi = {10.48550/arXiv.2206.01618},
	abstract = {This study proposes a newly-developed deep-learning-based method to generate turbulent inflow conditions for spatially-developing turbulent boundary layer (TBL) simulations. A combination of a transformer and a multiscale-enhanced super-resolution generative adversarial network is utilized to predict velocity fields of a spatially-developing TBL at various planes normal to the streamwise direction. Datasets of direct numerical simulation (DNS) of flat plate flow spanning a momentum thickness-based Reynolds number, Re\_theta = 661.5 - 1502.0, are used to train and test the model. The model shows a remarkable ability to predict the instantaneous velocity fields with detailed fluctuations and reproduce the turbulence statistics as well as spatial and temporal spectra with commendable accuracy as compared with the DNS results. The proposed model also exhibits a reasonable accuracy for predicting velocity fields at Reynolds numbers that are not used in the training process. With the aid of transfer learning, the computational cost of the proposed model is considered to be effectively low. The results demonstrate, for the first time that transformer-based models can be efficient in predicting the dynamics of turbulent flows. It also shows that combining these models with generative adversarial networks-based models can be useful in tackling various turbulence-related problems, including the development of efficient synthetic-turbulent inflow generators.},
	urldate = {2022-06-28},
	publisher = {arXiv},
	author = {Yousif, Mustafa Z. and Zhang, Meng and Yu, Linqi and Vinuesa, Ricardo and Lim, HeeChang},
	month = jun,
	year = {2022},
	note = {arXiv:2206.01618 [physics]},
	keywords = {Physics - Fluid Dynamics},
}

@article{sazhin_modelling_2018,
	title = {Modelling of sprays: recent results and future challenges},
	volume = {1096},
	issn = {1742-6596},
	shorttitle = {Modelling of sprays},
	url = {https://doi.org/10.1088/1742-6596/1096/1/012052},
	doi = {10.1088/1742-6596/1096/1/012052},
	abstract = {A brief overview of some recent developments and future challenges in spray modelling is presented. The focus is on the comparative analysis of Lagrangian and Fully Lagrangian (Osiptsov) approaches to spray modelling and the applications of the latter approach and its generalisations to the solution of engineering problems, recent developments in modelling the heating and evaporation of spherical and non-spherical droplets and films, and application of the method of integral manifolds in the analysis of spray heating, evaporation and ignition in Internal Combustion (IC) engine-like conditions. Future challenges described in the paper include the generalisation of the Fully Lagrangian approach to enable it to model realistic turbulent sprays, further development of the models of heating and evaporation of deformed droplets, modelling of heating and evaporation of droplets in trance- and super-critical conditions and further development of the integral manifold methods to enable their application to the solution of realistic engineering problems, with particular focus on IC engines. All models are expected to be developed in formats that enable their relatively simple implementation into commercial Computational Fluid Dynamics (CFD) codes.},
	language = {en},
	urldate = {2022-06-27},
	journal = {Journal of Physics: Conference Series},
	author = {Sazhin, S. S. and Shchepakina, E. and Sobolev, V.},
	month = sep,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {012052},
}

@article{siddani_machine_2021,
	title = {Machine {Learning} for {Physics}-{Informed} {Generation} of {Dispersed} {Multiphase} {Flow} {Using} {Generative} {Adversarial} {Networks}},
	volume = {35},
	issn = {0935-4964, 1432-2250},
	url = {http://arxiv.org/abs/2005.05363},
	doi = {10.1007/s00162-021-00593-9},
	abstract = {Fluid flow around a random distribution of stationary spherical particles is a problem of substantial importance in the study of dispersed multiphase flows. In this paper we present a machine learning methodology using Generative Adversarial Network framework and Convolutional Neural Network architecture to recreate particle-resolved fluid flow around a random distribution of monodispersed particles. The model was applied to various Reynolds number and particle volume fraction combinations spanning over a range of [2.69, 172.96] and [0.11, 0.45] respectively. Test performance of the model for the studied cases is very promising.},
	number = {6},
	urldate = {2022-06-27},
	journal = {Theoretical and Computational Fluid Dynamics},
	author = {Siddani, B. and Balachandar, S. and Moore, W. C. and Yang, Y. and Fang, R.},
	month = dec,
	year = {2021},
	note = {arXiv:2005.05363 [physics]},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {807--830},
}

@misc{bruna_neural_2022,
	title = {Neural {Galerkin} {Scheme} with {Active} {Learning} for {High}-{Dimensional} {Evolution} {Equations}},
	url = {http://arxiv.org/abs/2203.01360},
	doi = {10.48550/arXiv.2203.01360},
	abstract = {Deep neural networks have been shown to provide accurate function approximations in high dimensions. However, fitting network parameters requires training data that may not be available beforehand, which is particularly challenging in science and engineering applications where often it is even unclear how to collect new informative training data in the first place. This work proposes Neural Galerkin schemes based on deep learning that generate training data samples with active learning for numerically solving high-dimensional partial differential equations. Neural Galerkin schemes train networks by minimizing the residual sequentially over time, which enables adaptively collecting new training data in a self-informed manner that is guided by the dynamics described by the partial differential equations, which is in stark contrast to many other machine learning methods that aim to fit network parameters globally in time without taking into account training data acquisition. Our finding is that the active form of gathering training data of the proposed Neural Galerkin schemes is key for numerically realizing the expressive power of networks in high dimensions. Numerical experiments demonstrate that Neural Galerkin schemes have the potential to enable simulating phenomena and processes with many variables for which traditional and other deep-learning-based solvers fail, especially when features of the solutions evolve locally such as in high-dimensional wave propagation problems and interacting particle systems described by Fokker-Planck and kinetic equations.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Bruna, Joan and Peherstorfer, Benjamin and Vanden-Eijnden, Eric},
	month = may,
	year = {2022},
	note = {Number: arXiv:2203.01360
arXiv:2203.01360 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@misc{chen_model_2022,
	title = {Model reduction for the material point method via an implicit neural representation of the deformation map},
	url = {http://arxiv.org/abs/2109.12390},
	doi = {10.48550/arXiv.2109.12390},
	abstract = {This work proposes a model-reduction approach for the material point method on nonlinear manifolds. Our technique approximates the \${\textbackslash}textit\{kinematics\}\$ by approximating the deformation map using an implicit neural representation that restricts deformation trajectories to reside on a low-dimensional manifold. By explicitly approximating the deformation map, its spatiotemporal gradients -- in particular the deformation gradient and the velocity -- can be computed via analytical differentiation. In contrast to typical model-reduction techniques that construct a linear or nonlinear manifold to approximate the (finite number of) degrees of freedom characterizing a given spatial discretization, the use of an implicit neural representation enables the proposed method to approximate the \${\textbackslash}textit\{continuous\}\$ deformation map. This allows the kinematic approximation to remain agnostic to the discretization. Consequently, the technique supports dynamic discretizations -- including resolution changes -- during the course of the online reduced-order-model simulation. To generate \${\textbackslash}textit\{dynamics\}\$ for the generalized coordinates, we propose a family of projection techniques. At each time step, these techniques: (1) Calculate full-space kinematics at quadrature points, (2) Calculate the full-space dynamics for a subset of `sample' material points, and (3) Calculate the reduced-space dynamics by projecting the updated full-space position and velocity onto the low-dimensional manifold and tangent space, respectively. We achieve significant computational speedup via hyper-reduction that ensures all three steps execute on only a small subset of the problem's spatial domain. Large-scale numerical examples with millions of material points illustrate the method's ability to gain an order of magnitude computational-cost saving -- indeed \${\textbackslash}textit\{real-time simulations\}\$ -- with negligible errors.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Chen, Peter Yichen and Chiaramonte, Maurizio and Grinspun, Eitan and Carlberg, Kevin},
	month = apr,
	year = {2022},
	note = {Number: arXiv:2109.12390
arXiv:2109.12390 [cs, math]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Graphics, Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{mescheder_occupancy_2019,
	title = {Occupancy {Networks}: {Learning} {3D} {Reconstruction} in {Function} {Space}},
	shorttitle = {Occupancy {Networks}},
	url = {http://arxiv.org/abs/1812.03828},
	doi = {10.48550/arXiv.1812.03828},
	abstract = {With the advent of deep neural networks, learning-based approaches for 3D reconstruction have gained popularity. However, unlike for images, in 3D there is no canonical representation which is both computationally and memory efficient yet allows for representing high-resolution geometry of arbitrary topology. Many of the state-of-the-art learning-based 3D reconstruction approaches can hence only represent very coarse 3D geometry or are limited to a restricted domain. In this paper, we propose Occupancy Networks, a new representation for learning-based 3D reconstruction methods. Occupancy networks implicitly represent the 3D surface as the continuous decision boundary of a deep neural network classifier. In contrast to existing approaches, our representation encodes a description of the 3D output at infinite resolution without excessive memory footprint. We validate that our representation can efficiently encode 3D structure and can be inferred from various kinds of input. Our experiments demonstrate competitive results, both qualitatively and quantitatively, for the challenging tasks of 3D reconstruction from single images, noisy point clouds and coarse discrete voxel grids. We believe that occupancy networks will become a useful tool in a wide variety of learning-based 3D tasks.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
	month = apr,
	year = {2019},
	note = {Number: arXiv:1812.03828
arXiv:1812.03828 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{kaptanoglu_promoting_2021,
	title = {Promoting global stability in data-driven models of quadratic nonlinear dynamics},
	volume = {6},
	issn = {2469-990X},
	url = {http://arxiv.org/abs/2105.01843},
	doi = {10.1103/PhysRevFluids.6.094401},
	abstract = {Modeling realistic fluid and plasma flows is computationally intensive, motivating the use of reduced-order models for a variety of scientific and engineering tasks. However, it is challenging to characterize, much less guarantee, the global stability (i.e., long-time boundedness) of these models. The seminal work of Schlegel and Noack (JFM, 2015) provided a theorem outlining necessary and sufficient conditions to ensure global stability in systems with energy-preserving, quadratic nonlinearities, with the goal of evaluating the stability of projection-based models. In this work, we incorporate this theorem into modern data-driven models obtained via machine learning. First, we propose that this theorem should be a standard diagnostic for the stability of projection-based and data-driven models, examining the conditions under which it holds. Second, we illustrate how to modify the objective function in machine learning algorithms to promote globally stable models, with implications for the modeling of fluid and plasma flows. Specifically, we introduce a modified "trapping SINDy" algorithm based on the sparse identification of nonlinear dynamics (SINDy) method. This method enables the identification of models that, by construction, only produce bounded trajectories. The effectiveness and accuracy of this approach are demonstrated on a broad set of examples of varying model complexity and physical origin, including the vortex shedding in the wake of a circular cylinder.},
	number = {9},
	urldate = {2022-06-23},
	journal = {Physical Review Fluids},
	author = {Kaptanoglu, Alan A. and Callaham, Jared L. and Hansen, Christopher J. and Aravkin, Aleksandr and Brunton, Steven L.},
	month = sep,
	year = {2021},
	note = {arXiv:2105.01843 [physics]},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics, Physics - Plasma Physics},
	pages = {094401},
}

@misc{pan_neural_2022,
	title = {Neural {Implicit} {Flow}: a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data},
	shorttitle = {Neural {Implicit} {Flow}},
	url = {http://arxiv.org/abs/2204.03216},
	doi = {10.48550/arXiv.2204.03216},
	abstract = {High-dimensional spatio-temporal dynamics can often be encoded in a low-dimensional subspace. Engineering applications for modeling, characterization, design, and control of such large-scale systems often rely on dimensionality reduction to make solutions computationally tractable in real-time. Common existing paradigms for dimensionality reduction include linear methods, such as the singular value decomposition (SVD), and nonlinear methods, such as variants of convolutional autoencoders (CAE). However, these encoding techniques lack the ability to efficiently represent the complexity associated with spatio-temporal data, which often requires variable geometry, non-uniform grid resolution, adaptive meshing, and/or parametric dependencies. To resolve these practical engineering challenges, we propose a general framework called Neural Implicit Flow (NIF) that enables a mesh-agnostic, low-rank representation of large-scale, parametric, spatial-temporal data. NIF consists of two modified multilayer perceptrons (MLPs): (i) ShapeNet, which isolates and represents the spatial complexity, and (ii) ParameterNet, which accounts for any other input complexity, including parametric dependencies, time, and sensor measurements. We demonstrate the utility of NIF for parametric surrogate modeling, enabling the interpretable representation and compression of complex spatio-temporal dynamics, efficient many-spatial-query tasks, and improved generalization performance for sparse reconstruction.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Pan, Shaowu and Brunton, Steven L. and Kutz, J. Nathan},
	month = apr,
	year = {2022},
	note = {Number: arXiv:2204.03216
arXiv:2204.03216 [cs]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@article{callaham_role_2022,
	title = {On the role of nonlinear correlations in reduced-order modelling},
	volume = {938},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/on-the-role-of-nonlinear-correlations-in-reducedorder-modelling/CC2980F9AA4AC20A7453C3056ED950C4},
	doi = {10.1017/jfm.2021.994},
	abstract = {, This work investigates nonlinear dimensionality reduction as a means of improving the accuracy and stability of reduced-order models of advection-dominated flows. Nonlinear correlations between temporal proper orthogonal decomposition (POD) coefficients can be exploited to identify latent low-dimensional structure, approximating the attractor with a minimal set of driving modes and a manifold equation for the remaining modes. By viewing these nonlinear correlations as an invariant manifold reduction, this least-order representation can be used to stabilize POD–Galerkin models or as a state space for data-driven model identification. In the latter case, we use sparse polynomial regression to learn a compact, interpretable dynamical system model from the time series of the active modal coefficients. We demonstrate this perspective on a quasiperiodic shear-driven cavity flow and show that the dynamics evolves on a torus generated by two independent Stuart–Landau oscillators. The specific approach to nonlinear correlations analysis used in this work is applicable to periodic and quasiperiodic flows, and cannot be applied to chaotic or turbulent flows. However, the results illustrate the limitations of linear modal representations of advection-dominated flows and motivate the use of nonlinear dimensionality reduction more broadly for exploiting underlying structure in reduced-order models.},
	language = {en},
	urldate = {2022-06-23},
	journal = {Journal of Fluid Mechanics},
	author = {Callaham, Jared L. and Brunton, Steven L. and Loiseau, Jean-Christophe},
	month = may,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	keywords = {low-dimensional models},
}

@misc{mohan_learning_2021,
	title = {Learning {Stable} {Galerkin} {Models} of {Turbulence} with {Differentiable} {Programming}},
	url = {http://arxiv.org/abs/2107.07559},
	doi = {10.48550/arXiv.2107.07559},
	abstract = {Turbulent flow control has numerous applications and building reduced-order models (ROMs) of the flow and the associated feedback control laws is extremely challenging. Despite the complexity of building data-driven ROMs for turbulence, the superior representational capacity of deep neural networks has demonstrated considerable success in learning ROMs. Nevertheless, these strategies are typically devoid of physical foundations and often lack interpretability. Conversely, the Proper Orthogonal Decomposition (POD) based Galerkin projection (GP) approach for ROM has been popular in many problems owing to its theoretically consistent and explainable physical foundations. However, a key limitation is that the ordinary differential equations (ODEs) arising from GP ROMs are highly susceptible to instabilities due to truncation of POD modes and lead to deterioration in temporal predictions. In this work, we propose a {\textbackslash}textit\{differentiable programming\} approach that blends the strengths of both these strategies, by embedding neural networks explicitly into the GP ODE structure, termed Neural Galerkin projection. We demonstrate this approach on the isentropic Navier-Stokes equations for compressible flow over a cavity at a moderate Mach number. When provided the structure of the projected equations, we show that the Neural Galerkin approach implicitly learns stable ODE coefficients from POD coefficients and demonstrates significantly longer and accurate time horizon predictions, when compared to the classical POD-GP assisted by calibration. We observe that the key benefits of this differentiable programming-based approach include increased flexibility in physics-based learning, very low computational costs, and a significant increase in interpretability, when compared to purely data-driven neural networks.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Mohan, Arvind T. and Nagarajan, Kaushik and Livescu, Daniel},
	month = jul,
	year = {2021},
	note = {Number: arXiv:2107.07559
arXiv:2107.07559 [nlin, physics:physics]},
	keywords = {Nonlinear Sciences - Chaotic Dynamics, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@misc{shankar_validation_2021,
	title = {Validation and parameterization of a novel physics-constrained neural dynamics model applied to turbulent fluid flow},
	url = {http://arxiv.org/abs/2110.11528},
	doi = {10.48550/arXiv.2110.11528},
	abstract = {In fluid physics, data-driven models to enhance or accelerate solution methods are becoming increasingly popular for many application domains, such as alternatives to turbulence closures, system surrogates, or for new physics discovery. In the context of reduced order models of high-dimensional time-dependent fluid systems, machine learning methods grant the benefit of automated learning from data, but the burden of a model lies on its reduced-order representation of both the fluid state and physical dynamics. In this work, we build a physics-constrained, data-driven reduced order model for the Navier-Stokes equations to approximate spatio-temporal turbulent fluid dynamics. The model design choices mimic numerical and physical constraints by, for example, implicitly enforcing the incompressibility constraint and utilizing continuous Neural Ordinary Differential Equations for tracking the evolution of the differential equation. We demonstrate this technique on three-dimensional, moderate Reynolds number turbulent fluid flow. In assessing the statistical quality and characteristics of the machine-learned model through rigorous diagnostic tests, we find that our model is capable of reconstructing the dynamics of the flow over large integral timescales, favoring accuracy at the larger length scales. More significantly, comprehensive diagnostics suggest that physically-interpretable model parameters, corresponding to the representations of the fluid state and dynamics, have attributable and quantifiable impact on the quality of the model predictions and computational complexity.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Shankar, Varun and Portwood, Gavin D. and Mohan, Arvind T. and Mitra, Peetak P. and Krishnamurthy, Dilip and Rackauckas, Christopher and Wilson, Lucas A. and Schmidt, David P. and Viswanathan, Venkatasubramanian},
	month = oct,
	year = {2021},
	note = {Number: arXiv:2110.11528
arXiv:2110.11528 [physics]},
	keywords = {Physics - Fluid Dynamics},
}

@incollection{chakrabarti_galerkin_nodate,
	title = {Galerkin {Reduced} {Order} {Models} for {Compressible} {Flows} with {Differentiable} {Programming}},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2022-0373},
	abstract = {View Video Presentation: https://doi.org/10.2514/6.2022-0373.vidAccurate and computationally cheap forecasts using Reduced Order Models (ROMs) can facilitate active predictive control strategies to stabilize unsteady flow over airfoils. Galerkin projection based Reduced Order Models (GP-ROMs), derived by projecting the Navier Stokes equations on a truncated Proper Orthogonal Decomposition (POD) basis, have been widely adopted because of their low computational costs and theoretical formulation based on the governing fluid flow equations. However, the traditional GP-ROMs suffer from instabilities and inaccuracies for predictions over long time horizons, in spite of calibration. To address these issues we implement the recently proposed Neural Galerkin Projection (NeuralGP)procedure –a differentiable programming-based approach that blends the strengths of the physics driven GP-ROM technique to the purely data driven neural network based techniques previously suggested in literature. The predictive capabilities of the two methods are tested for a transonic flow over a buffeting NACA0012 airfoil. While both techniques give accurate forecasts over short time prediction horizons, only the NeuralGP ROM is able to accurately track the reference POD coefficients over longer prediction horizons with the calibrated GP-ROM diverging in amplitude and frequency. The results highlight the increased accuracy of the NeuralGP technique compared to the calibrated GP-ROM method while being less computationally expensive and more interpretable compared to the traditional physics-agnostic neural networks.},
	urldate = {2022-06-23},
	booktitle = {{AIAA} {SCITECH} 2022 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Chakrabarti, Surya and Gaitonde, Datta V. and Mohan, Arvind T. and Livescu, Daniel},
	doi = {10.2514/6.2022-0373},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2022-0373},
}

@article{schmidt_guide_2020,
	title = {Guide to {Spectral} {Proper} {Orthogonal} {Decomposition}},
	volume = {58},
	issn = {0001-1452},
	url = {https://arc.aiaa.org/doi/10.2514/1.J058809},
	doi = {10.2514/1.J058809},
	abstract = {This paper discusses the spectral proper orthogonal decomposition and its use in identifying modes, or structures, in flow data. A specific algorithm based on estimating the cross-spectral density tensor with Welch’s method is presented, and guidance is provided on selecting data sampling parameters and understanding tradeoffs among them in terms of bias, variability, aliasing, and leakage. Practical implementation issues, including dealing with large datasets, are discussed and illustrated with examples involving experimental and computational turbulent flow data.},
	number = {3},
	urldate = {2022-06-23},
	journal = {AIAA Journal},
	author = {Schmidt, Oliver T. and Colonius, Tim},
	month = mar,
	year = {2020},
	note = {Publisher: American Institute of Aeronautics and Astronautics},
	keywords = {Blade Passing Frequency, Data Sampling, Dirac Delta Function, Incompressible Flow, Large Eddy Simulation, Particle Image Velocimetry, Power Spectral Density, Turbulence Kinetic Energy, Vertical Axis Wind Turbines, Vortex Shedding},
	pages = {1023--1033},
}

@article{liu_learning-based_2022,
	title = {A learning-based multiscale method and its application to inelastic impact problems},
	volume = {158},
	issn = {0022-5096},
	url = {https://www.sciencedirect.com/science/article/pii/S0022509621002982},
	doi = {10.1016/j.jmps.2021.104668},
	abstract = {The macroscopic properties of materials that we observe and exploit in engineering application result from complex interactions between physics at multiple length and time scales: electronic, atomistic, defects, domains etc. Multiscale modeling seeks to understand these interactions by exploiting the inherent hierarchy where the behavior at a coarser scale regulates and averages the behavior at a finer scale. This requires the repeated solution of computationally expensive finer-scale models, and often a priori knowledge of those aspects of the finer-scale behavior that affect the coarser scale (order parameters, state variables, descriptors, etc.). We address this challenge in a two-scale setting where we learn the fine-scale behavior from off-line calculations and then use the learnt behavior directly in coarse scale calculations. The approach builds on the recent success of deep neural networks by combining their approximation power in high dimensions with ideas from model reduction. It results in a neural network approximation that has high fidelity, is computationally inexpensive, is independent of the need for a priori knowledge, and can be used directly in the coarse scale calculations. We demonstrate the approach on problems involving the impact of magnesium, a promising light-weight structural and protective material.},
	language = {en},
	urldate = {2022-06-23},
	journal = {Journal of the Mechanics and Physics of Solids},
	author = {Liu, Burigede and Kovachki, Nikola and Li, Zongyi and Azizzadenesheli, Kamyar and Anandkumar, Anima and Stuart, Andrew M. and Bhattacharya, Kaushik},
	month = jan,
	year = {2022},
	keywords = {Crystal plasticity, Machine learning, Multiscale modeling},
	pages = {104668},
}

@misc{fanaskov_spectral_2022,
	title = {Spectral {Neural} {Operators}},
	url = {http://arxiv.org/abs/2205.10573},
	doi = {10.48550/arXiv.2205.10573},
	abstract = {A plentitude of applications in scientific computing requires the approximation of mappings between Banach spaces. Recently introduced Fourier Neural Operator (FNO) and Deep Operator Network (DeepONet) can provide this functionality. For both of these neural operators, the input function is sampled on a given grid (uniform for FNO), and the output function is parametrized by a neural network. We argue that this parametrization leads to 1) opaque output that is hard to analyze and 2) systematic bias caused by aliasing errors in the case of FNO. The alternative, advocated in this article, is to use Chebyshev and Fourier series for both domain and codomain. The resulting Spectral Neural Operator (SNO) has transparent output, never suffers from aliasing, and may include many exact (lossless) operations on functions. The functionality is based on well-developed fast, and stable algorithms from spectral methods. The implementation requires only standard numerical linear algebra. Our benchmarks show that for many operators, SNO is superior to FNO and DeepONet.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Fanaskov, V. and Oseledets, I.},
	month = may,
	year = {2022},
	note = {Number: arXiv:2205.10573
arXiv:2205.10573 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
}

@misc{rahman_generative_2022,
	title = {Generative {Adversarial} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2205.03017},
	doi = {10.48550/arXiv.2205.03017},
	abstract = {We propose the generative adversarial neural operator (GANO), a generative model paradigm for learning probabilities on infinite-dimensional function spaces. The natural sciences and engineering are known to have many types of data that are sampled from infinite-dimensional function spaces, where classical finite-dimensional deep generative adversarial networks (GANs) may not be directly applicable. GANO generalizes the GAN framework and allows for the sampling of functions by learning push-forward operator maps in infinite-dimensional spaces. GANO consists of two main components, a generator neural operator and a discriminator neural functional. The inputs to the generator are samples of functions from a user-specified probability measure, e.g., Gaussian random field (GRF), and the generator outputs are synthetic data functions. The input to the discriminator is either a real or synthetic data function. In this work, we instantiate GANO using the Wasserstein criterion and show how the Wasserstein loss can be computed in infinite-dimensional spaces. We empirically study GANOs in controlled cases where both input and output functions are samples from GRFs and compare its performance to the finite-dimensional counterpart GAN. We empirically study the efficacy of GANO on real-world function data of volcanic activities and show its superior performance over GAN. Furthermore, we find that for the function-based data considered, GANOs are more stable to train than GANs and require less hyperparameter optimization.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Rahman, Md Ashiqur and Florez, Manuel A. and Anandkumar, Anima and Ross, Zachary E. and Azizzadenesheli, Kamyar},
	month = may,
	year = {2022},
	note = {Number: arXiv:2205.03017
arXiv:2205.03017 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Probability},
}

@misc{rahman_u-no_2022,
	title = {U-{NO}: {U}-shaped {Neural} {Operators}},
	shorttitle = {U-{NO}},
	url = {http://arxiv.org/abs/2204.11127},
	doi = {10.48550/arXiv.2204.11127},
	abstract = {Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g. function spaces. Prior works on neural operators proposed a series of novel architectures to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy's flow law and the Navier-Stokes equations. We show that U-NO results in an average of 14\% and 34\% prediction improvement on Darcy's flow and turbulent Navier-Stokes equations, respectively, over the state of art. On Navier-Stokes 3D spatio-temporal operator learning task, we show U-NO provides 40\% improvement over the state of art methods.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Rahman, Md Ashiqur and Ross, Zachary E. and Azizzadenesheli, Kamyar},
	month = may,
	year = {2022},
	note = {Number: arXiv:2204.11127
arXiv:2204.11127 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{bhattacharya_model_2021,
	title = {Model {Reduction} and {Neural} {Networks} for {Parametric} {PDEs}},
	url = {http://arxiv.org/abs/2005.03180},
	doi = {10.48550/arXiv.2005.03180},
	abstract = {We develop a general framework for data-driven approximation of input-output maps between infinite-dimensional spaces. The proposed approach is motivated by the recent successes of neural networks and deep learning, in combination with ideas from model reduction. This combination results in a neural network approximation which, in principle, is defined on infinite-dimensional spaces and, in practice, is robust to the dimension of finite-dimensional approximations of these spaces required for computation. For a class of input-output maps, and suitably chosen probability measures on the inputs, we prove convergence of the proposed approximation methodology. We also include numerical experiments which demonstrate the effectiveness of the method, showing convergence and robustness of the approximation scheme with respect to the size of the discretization, and compare it with existing algorithms from the literature; our examples include the mapping from coefficient to solution in a divergence form elliptic partial differential equation (PDE) problem, and the solution operator for viscous Burgers' equation.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Bhattacharya, Kaushik and Hosseini, Bamdad and Kovachki, Nikola B. and Stuart, Andrew M.},
	month = jun,
	year = {2021},
	note = {Number: arXiv:2005.03180
arXiv:2005.03180 [cs, math, stat]},
	keywords = {65N75, 62M45, 68T05, 60H30, 60H15, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@misc{tran_factorized_2021,
	title = {Factorized {Fourier} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2111.13802},
	doi = {10.48550/arXiv.2111.13802},
	abstract = {The Fourier Neural Operator (FNO) is a learning-based method for efficiently simulating partial differential equations. We propose the Factorized Fourier Neural Operator (F-FNO) that allows much better generalization with deeper networks. With a careful combination of the Fourier factorization, a shared kernel integral operator across all layers, the Markov property, and residual connections, F-FNOs achieve a six-fold reduction in error on the most turbulent setting of the Navier-Stokes benchmark dataset. We show that our model maintains an error rate of 2\% while still running an order of magnitude faster than a numerical solver, even when the problem setting is extended to include additional contexts such as viscosity and time-varying forces. This enables the same pretrained neural network to model vastly different conditions.},
	urldate = {2022-06-16},
	publisher = {arXiv},
	author = {Tran, Alasdair and Mathews, Alexander and Xie, Lexing and Ong, Cheng Soon},
	month = nov,
	year = {2021},
	note = {Number: arXiv:2111.13802
arXiv:2111.13802 [cs]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@misc{noauthor_source_nodate,
	title = {Source term based synthetic turbulence inflow generator for eddy-resolving predictions of an airfoil flow including a laminar separation bubble {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0045793016304066?token=7ECF9A8EE68BB7C59A243810086CAAA638C7094FBE95B4FE79145D0C21551C9D1F910BB6564ED29C1A3B0A634F8987EE&originRegion=eu-west-1&originCreation=20220614120018},
	language = {en},
	urldate = {2022-06-14},
	doi = {10.1016/j.compfluid.2016.12.023},
}

@article{schmidt_source_2017,
	title = {Source term based synthetic turbulence inflow generator for eddy-resolving predictions of an airfoil flow including a laminar separation bubble},
	volume = {146},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793016304066},
	doi = {10.1016/j.compfluid.2016.12.023},
	abstract = {The present paper addresses the issue of the strong dependency of eddy-resolving simulations for turbulent flows on the employed inflow conditions. Thus, the objective of this study is to analyze the influence of the inflow conditions on the external wall-bounded flow past the SD7003 airfoil and more precisely on the form and size of the laminar separation bubble. Motivated by the typically coarse resolution of the inlet region of the computational domain used for hybrid simulations, the synthetic turbulence is introduced within the flow field by a flexible source term treatment. The generated turbulent fluctuations are taken into account in the momentum equation by source terms and hence allow a shift from the inlet to a finer resolved region, where the damping of small structures due to the grid resolution is negligible. To provide a proper formulation of a synthetic turbulence inflow generator (STIG), the digital filter concept of Klein et al. (J. Comp. Phys. 186, 652–665, 2003) is merged with a large-eddy simulation (LES) as well as a hybrid LES-URANS method. The synthetically generated velocity fluctuations are distributed in an area of influence which is in accordance with the digital filter concept of the STIG. An automatic calculation of the dimension of the influence region is ensured by the employment of the integral scales which are used during the generation of the synthetic turbulence inflow generator inflow. The definition of the required input quantities for the STIG in case of the flow past a SD7003 airfoil at Rec=60,000 and an angle of attack α=4∘ are based on experimental data including a turbulence intensity of TI = 0.28\%. Due to separation, transition and subsequent reattachment this is a demanding test case in which the shape and the size of the separation bubble strongly depends on the oncoming turbulence. The reference velocity profiles of the experimental measurements are compared with a wall-resolved LES and hybrid simulations performed on two grids with a coarser resolution. The evaluation of the results of the simulations applying the STIG and without turbulence intensity showed an improved level of agreement between the STIG based simulations and the experiment. Moreover, the turbulence intensity is varied to understand the behavior of the LSB in more detail.},
	language = {en},
	urldate = {2022-06-14},
	journal = {Computers \& Fluids},
	author = {Schmidt, S. and Breuer, M.},
	month = mar,
	year = {2017},
	keywords = {Airfoil, Hybrid method, LES, Laminar separation bubble, Source term, Synthetic turbulence, Transition, URANS},
	pages = {1--22},
}

@techreport{wang_drlinfluids_2022,
	title = {{DRLinFluids} -- {An} open-source python platform of coupling {Deep} {Reinforcement} {Learning} and {OpenFOAM}},
	url = {http://arxiv.org/abs/2205.12699},
	abstract = {We propose an open-source python platform for applications of Deep Reinforcement Learning (DRL) in fluid mechanics. DRL has been widely used in optimizing decision-making in nonlinear and high-dimensional problems. Here, an agent maximizes a cumulative reward with learning a feedback policy by acting in an environment. In control theory terms, the cumulative reward would correspond to the cost function, the agent to the actuator, the environment to the measured signals and the learned policy to the feedback law. Thus, DRL assumes an interactive environment or, equivalently, control plant. The setup of a numerical simulation plant with DRL is challenging and time-consuming. In this work, a novel python platform, named DRLinFluids is developed for this purpose, with DRL for flow control and optimization problems in fluid mechanics. The simulations employ OpenFOAM as popular, flexible Navier-Stokes solver in industry and academia, and Tensorforce or Tianshou as widely used versatile DRL packages. The reliability and efficiency of DRLinFluids are demonstrated for two wake stabilization benchmark problems. DRLinFluids significantly reduces the application effort of DRL in fluid mechanics and is expected to greatly accelerates academic and industrial applications.},
	number = {arXiv:2205.12699},
	urldate = {2022-06-03},
	institution = {arXiv},
	author = {Wang, Qiulei and Yan, Lei and Hu, Gang and Li, Chao and Xiao, Yiqing and Xiong, Hao and Rabault, Jean and Noack, Bernd R.},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.12699},
	note = {arXiv:2205.12699 [physics]
type: article},
	keywords = {Physics - Fluid Dynamics},
}

@techreport{czarnecki_sobolev_2017,
	title = {Sobolev {Training} for {Neural} {Networks}},
	url = {http://arxiv.org/abs/1706.04859},
	abstract = {At the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process. In many cases we only have access to input-output pairs from the ground truth, however it is becoming more common to have access to derivatives of the target output with respect to the input - for example when the ground truth function is itself a neural network such as in network compression or distillation. Generally these target derivatives are not computed, or are ignored. This paper introduces Sobolev Training for neural networks, which is a method for incorporating these target derivatives in addition the to target values while training. By optimising neural networks to not only approximate the function's outputs but also the function's derivatives we encode additional information about the target function within the parameters of the neural network. Thereby we can improve the quality of our predictors, as well as the data-efficiency and generalization capabilities of our learned function approximation. We provide theoretical justifications for such an approach as well as examples of empirical evidence on three distinct domains: regression on classical optimisation datasets, distilling policies of an agent playing Atari, and on large-scale applications of synthetic gradients. In all three domains the use of Sobolev Training, employing target derivatives in addition to target values, results in models with higher accuracy and stronger generalisation.},
	number = {arXiv:1706.04859},
	urldate = {2022-05-24},
	institution = {arXiv},
	author = {Czarnecki, Wojciech Marian and Osindero, Simon and Jaderberg, Max and Świrszcz, Grzegorz and Pascanu, Razvan},
	month = jul,
	year = {2017},
	doi = {10.48550/arXiv.1706.04859},
	note = {arXiv:1706.04859 [cs]
type: article},
	keywords = {Computer Science - Machine Learning},
}

@article{lu_learning_2022,
	title = {Learning the temporal evolution of multivariate densities via normalizing flows},
	volume = {32},
	issn = {1054-1500, 1089-7682},
	url = {http://arxiv.org/abs/2107.13735},
	doi = {10.1063/5.0065093},
	abstract = {In this work, we propose a method to learn multivariate probability distributions using sample path data from stochastic differential equations. Specifically, we consider temporally evolving probability distributions (e.g., those produced by integrating local or nonlocal Fokker-Planck equations). We analyze this evolution through machine learning assisted construction of a time-dependent mapping that takes a reference distribution (say, a Gaussian) to each and every instance of our evolving distribution. If the reference distribution is the initial condition of a Fokker-Planck equation, what we learn is the time-T map of the corresponding solution. Specifically, the learned map is a multivariate normalizing flow that deforms the support of the reference density to the support of each and every density snapshot in time. We demonstrate that this approach can approximate probability density function evolutions in time from observed sampled data for systems driven by both Brownian and L{\textbackslash}'evy noise. We present examples with two- and three-dimensional, uni- and multimodal distributions to validate the method.},
	number = {3},
	urldate = {2022-05-23},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Lu, Yubin and Maulik, Romit and Gao, Ting and Dietrich, Felix and Kevrekidis, Ioannis G. and Duan, Jinqiao},
	month = mar,
	year = {2022},
	note = {arXiv:2107.13735 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Mathematics - Probability, Statistics - Machine Learning},
	pages = {033121},
}

@techreport{linot_stabilized_2022,
	title = {Stabilized {Neural} {Ordinary} {Differential} {Equations} for {Long}-{Time} {Forecasting} of {Dynamical} {Systems}},
	url = {http://arxiv.org/abs/2203.15706},
	abstract = {In data-driven modeling of spatiotemporal phenomena careful consideration often needs to be made in capturing the dynamics of the high wavenumbers. This problem becomes especially challenging when the system of interest exhibits shocks or chaotic dynamics. We present a data-driven modeling method that accurately captures shocks and chaotic dynamics by proposing a novel architecture, stabilized neural ordinary differential equation (ODE). In our proposed architecture, we learn the right-hand-side (RHS) of an ODE by adding the outputs of two NN together where one learns a linear term and the other a nonlinear term. Specifically, we implement this by training a sparse linear convolutional NN to learn the linear term and a dense fully-connected nonlinear NN to learn the nonlinear term. This is in contrast with the standard neural ODE which involves training only a single NN for learning the RHS. We apply this setup to the viscous Burgers equation, which exhibits shocked behavior, and show better short-time tracking and prediction of the energy spectrum at high wavenumbers than a standard neural ODE. We also find that the stabilized neural ODE models are much more robust to noisy initial conditions than the standard neural ODE approach. We also apply this method to chaotic trajectories of the Kuramoto-Sivashinsky equation. In this case, stabilized neural ODEs keep long-time trajectories on the attractor, and are highly robust to noisy initial conditions, while standard neural ODEs fail at achieving either of these results. We conclude by demonstrating how stabilizing neural ODEs provide a natural extension for use in reduced-order modeling by projecting the dynamics onto the eigenvectors of the learned linear term.},
	number = {arXiv:2203.15706},
	urldate = {2022-05-23},
	institution = {arXiv},
	author = {Linot, Alec J. and Burby, Josh W. and Tang, Qi and Balaprakash, Prasanna and Graham, Michael D. and Maulik, Romit},
	month = mar,
	year = {2022},
	doi = {10.48550/arXiv.2203.15706},
	note = {arXiv:2203.15706 [cs]
type: article},
	keywords = {Computer Science - Machine Learning},
}

@techreport{karnakov_optimizing_2022,
	title = {Optimizing a {DIscrete} {Loss} ({ODIL}) to solve forward and inverse problems for partial differential equations using machine learning tools},
	url = {http://arxiv.org/abs/2205.04611},
	abstract = {We introduce the Optimizing a Discrete Loss (ODIL) framework for the numerical solution of Partial Differential Equations (PDE) using machine learning tools. The framework formulates numerical methods as a minimization of discrete residuals that are solved using gradient descent and Newton's methods. We demonstrate the value of this approach on equations that may have missing parameters or where no sufficient data is available to form a well-posed initial-value problem. The framework is presented for mesh based discretizations of PDEs and inherits their accuracy, convergence, and conservation properties. It preserves the sparsity of the solutions and is readily applicable to inverse and ill-posed problems. It is applied to PDE-constrained optimization, optical flow, system identification, and data assimilation using gradient descent algorithms including those often deployed in machine learning. We compare ODIL with related approach that represents the solution with neural networks. We compare the two methodologies and demonstrate advantages of ODIL that include significantly higher convergence rates and several orders of magnitude lower computational cost. We evaluate the method on various linear and nonlinear partial differential equations including the Navier-Stokes equations for flow reconstruction problems.},
	number = {arXiv:2205.04611},
	urldate = {2022-05-20},
	institution = {arXiv},
	author = {Karnakov, Petr and Litvinov, Sergey and Koumoutsakos, Petros},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.04611},
	note = {arXiv:2205.04611 [physics]
type: article},
	keywords = {Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@techreport{mesnard_reproducible_2016,
	title = {Reproducible and replicable {CFD}: it's harder than you think},
	shorttitle = {Reproducible and replicable {CFD}},
	url = {http://arxiv.org/abs/1605.04339},
	abstract = {Completing a full replication study of our previously published findings on bluff-body aerodynamics was harder than we thought. Despite the fact that we have good reproducible-research practices, sharing our code and data openly. Here's what we learned from three years, four CFD codes and hundreds of runs.},
	number = {arXiv:1605.04339},
	urldate = {2022-05-20},
	institution = {arXiv},
	author = {Mesnard, Olivier and Barba, Lorena A.},
	month = oct,
	year = {2016},
	doi = {10.48550/arXiv.1605.04339},
	note = {arXiv:1605.04339 [physics]
type: article},
	keywords = {Physics - Computational Physics},
}

@techreport{markidis_old_2021-1,
	title = {The {Old} and the {New}: {Can} {Physics}-{Informed} {Deep}-{Learning} {Replace} {Traditional} {Linear} {Solvers}?},
	shorttitle = {The {Old} and the {New}},
	url = {http://arxiv.org/abs/2103.09655},
	abstract = {Physics-Informed Neural Networks (PINN) are neural networks encoding the problem governing equations, such as Partial Differential Equations (PDE), as a part of the neural network. PINNs have emerged as a new essential tool to solve various challenging problems, including computing linear systems arising from PDEs, a task for which several traditional methods exist. In this work, we focus first on evaluating the potential of PINNs as linear solvers in the case of the Poisson equation, an omnipresent equation in scientific computing. We characterize PINN linear solvers in terms of accuracy and performance under different network configurations (depth, activation functions, input data set distribution). We highlight the critical role of transfer learning. Our results show that low-frequency components of the solution converge quickly as an effect of the F-principle. In contrast, an accurate solution of the high frequencies requires an exceedingly long time. To address this limitation, we propose integrating PINNs into traditional linear solvers. We show that this integration leads to the development of new solvers whose performance is on par with other high-performance solvers, such as PETSc conjugate gradient linear solvers, in terms of performance and accuracy. Overall, while the accuracy and computational performance are still a limiting factor for the direct use of PINN linear solvers, hybrid strategies combining old traditional linear solver approaches with new emerging deep-learning techniques are among the most promising methods for developing a new class of linear solvers.},
	number = {arXiv:2103.09655},
	urldate = {2022-05-20},
	institution = {arXiv},
	author = {Markidis, Stefano},
	month = jul,
	year = {2021},
	note = {arXiv:2103.09655 [physics]
type: article},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@techreport{vinuesa_potential_2021,
	title = {The {Potential} of {Machine} {Learning} to {Enhance} {Computational} {Fluid} {Dynamics}},
	url = {http://arxiv.org/abs/2110.02085},
	abstract = {Machine learning is rapidly becoming a core technology for scientific computing, with numerous opportunities to advance the field of computational fluid dynamics. This paper highlights some of the areas of highest potential impact, including to accelerate direct numerical simulations, to improve turbulence closure modelling, and to develop enhanced reduced-order models. In each of these areas, it is possible to improve machine learning capabilities by incorporating physics into the process, and in turn, to improve the simulation of fluids to uncover new physical understanding. Despite the promise of machine learning described here, we also note that classical methods are often more efficient for many tasks. We also emphasize that in order to harness the full potential of machine learning to improve computational fluid dynamics, it is essential for the community to continue to establish benchmark systems and best practices for open-source software, data sharing, and reproducible research.},
	number = {arXiv:2110.02085},
	urldate = {2022-05-20},
	institution = {arXiv},
	author = {Vinuesa, Ricardo and Brunton, Steven L.},
	month = oct,
	year = {2021},
	doi = {10.48550/arXiv.2110.02085},
	note = {arXiv:2110.02085 [physics]
type: article},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{hansen_sheaf_2020,
	title = {Sheaf {Neural} {Networks}},
	url = {http://arxiv.org/abs/2012.06333},
	abstract = {We present a generalization of graph convolutional networks by generalizing the diffusion operation underlying this class of graph neural networks. These sheaf neural networks are based on the sheaf Laplacian, a generalization of the graph Laplacian that encodes additional relational structure parameterized by the underlying graph. The sheaf Laplacian and associated matrices provide an extended version of the diffusion operation in graph convolutional networks, providing a proper generalization for domains where relations between nodes are non-constant, asymmetric, and varying in dimension. We show that the resulting sheaf neural networks can outperform graph convolutional networks in domains where relations between nodes are asymmetric and signed.},
	urldate = {2022-04-28},
	journal = {arXiv:2012.06333 [cs, math]},
	author = {Hansen, Jakob and Gebhart, Thomas},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.06333},
	keywords = {Computer Science - Machine Learning, Mathematics - Algebraic Topology},
}

@article{hansen_toward_2019,
	title = {Toward a {Spectral} {Theory} of {Cellular} {Sheaves}},
	url = {http://arxiv.org/abs/1808.01513},
	doi = {10.1007/s41468-019-00038-7},
	abstract = {This paper outlines a program in what one might call spectral sheaf theory — an extension of spectral graph theory to cellular sheaves. By lifting the combinatorial graph Laplacian to the Hodge Laplacian on a cellular sheaf of vector spaces over a regular cell complex, one can relate spectral data to the sheaf cohomology and cell structure in a manner reminiscent of spectral graph theory. This work gives an exploratory introduction, and includes discussion of eigenvalue interlacing, sparsiﬁcation, eﬀective resistance, synchronization, and sheaf approximation. These results and subsequent applications are prefaced by an introduction to cellular sheaves and Laplacians.},
	language = {en},
	urldate = {2022-04-28},
	journal = {arXiv:1808.01513 [math]},
	author = {Hansen, Jakob and Ghrist, Robert},
	month = aug,
	year = {2019},
	note = {arXiv: 1808.01513},
	keywords = {55N30, 05C50, Mathematics - Algebraic Topology, Mathematics - Combinatorics},
}

@article{bodnar_neural_2022,
	title = {Neural {Sheaf} {Diffusion}: {A} {Topological} {Perspective} on {Heterophily} and {Oversmoothing} in {GNNs}},
	shorttitle = {Neural {Sheaf} {Diffusion}},
	url = {http://arxiv.org/abs/2202.04579},
	abstract = {Cellular sheaves equip graphs with "geometrical" structure by assigning vector spaces and linear maps to nodes and edges. Graph Neural Networks (GNNs) implicitly assume a graph with a trivial underlying sheaf. This choice is reflected in the structure of the graph Laplacian operator, the properties of the associated diffusion equation, and the characteristics of the convolutional models that discretise this equation. In this paper, we use cellular sheaf theory to show that the underlying geometry of the graph is deeply linked with the performance of GNNs in heterophilic settings and their oversmoothing behaviour. By considering a hierarchy of increasingly general sheaves, we study how the ability of the sheaf diffusion process to achieve linear separation of the classes in the infinite time limit expands. At the same time, we prove that when the sheaf is non-trivial, discretised parametric diffusion processes have greater control than GNNs over their asymptotic behaviour. On the practical side, we study how sheaves can be learned from data. The resulting sheaf diffusion models have many desirable properties that address the limitations of classical graph diffusion equations (and corresponding GNN models) and obtain state-of-the-art results in heterophilic settings. Overall, our work provides new connections between GNNs and algebraic topology and would be of interest to both fields.},
	urldate = {2022-04-28},
	journal = {arXiv:2202.04579 [cs, math]},
	author = {Bodnar, Cristian and Di Giovanni, Francesco and Chamberlain, Benjamin Paul and Liò, Pietro and Bronstein, Michael M.},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.04579},
	keywords = {Computer Science - Machine Learning, Mathematics - Algebraic Topology},
}

@article{jin_domain_2022,
	title = {Domain {Adaptation} for {Time} {Series} {Forecasting} via {Attention} {Sharing}},
	url = {http://arxiv.org/abs/2102.06828},
	abstract = {Recently, deep neural networks have gained increasing popularity in the field of time series forecasting. A primary reason for their success is their ability to effectively capture complex temporal dynamics across multiple related time series. The advantages of these deep forecasters only start to emerge in the presence of a sufficient amount of data. This poses a challenge for typical forecasting problems in practice, where there is a limited number of time series or observations per time series, or both. To cope with this data scarcity issue, we propose a novel domain adaptation framework, Domain Adaptation Forecaster (DAF). DAF leverages statistical strengths from a relevant domain with abundant data samples (source) to improve the performance on the domain of interest with limited data (target). In particular, we use an attention-based shared module with a domain discriminator across domains and private modules for individual domains. We induce domain-invariant latent features (queries and keys) and retrain domain-specific features (values) simultaneously to enable joint training of forecasters on source and target domains. A main insight is that our design of aligning keys allows the target domain to leverage source time series even with different characteristics. Extensive experiments on various domains demonstrate that our proposed method outperforms state-of-the-art baselines on synthetic and real-world datasets, and ablation studies verify the effectiveness of our design choices.},
	urldate = {2022-04-20},
	journal = {arXiv:2102.06828 [cs, stat]},
	author = {Jin, Xiaoyong and Park, Youngsuk and Maddix, Danielle C. and Wang, Hao and Wang, Yuyang},
	month = feb,
	year = {2022},
	note = {arXiv: 2102.06828},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kirchmeyer_generalizing_2022,
	title = {Generalizing to {New} {Physical} {Systems} via {Context}-{Informed} {Dynamics} {Model}},
	url = {http://arxiv.org/abs/2202.01889},
	abstract = {Data-driven approaches to modeling physical systems fail to generalize to unseen systems that share the same general dynamics with the learning domain, but correspond to different physical contexts. We propose a new framework for this key problem, context-informed dynamics adaptation (CoDA), which takes into account the distributional shift across systems for fast and efficient adaptation to new dynamics. CoDA leverages multiple environments, each associated to a different dynamic, and learns to condition the dynamics model on contextual parameters, specific to each environment. The conditioning is performed via a hypernetwork, learned jointly with a context vector from observed data. The proposed formulation constrains the search hypothesis space to foster fast adaptation and better generalization across environments. It extends the expressivity of existing methods. We theoretically motivate our approach and show state-ofthe-art generalization results on a set of nonlinear dynamics, representative of a variety of application domains. We also show, on these systems, that new system parameters can be inferred from context vectors with minimal supervision.},
	urldate = {2022-04-20},
	journal = {arXiv:2202.01889 [cs, stat]},
	author = {Kirchmeyer, Matthieu and Yin, Yuan and Donà, Jérémie and Baskiotis, Nicolas and Rakotomamonjy, Alain and Gallinari, Patrick},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.01889},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{courty_optimal_2016,
	title = {Optimal {Transport} for {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/1507.00504},
	abstract = {Domain adaptation from one data space (or domain) to another is one of the most challenging tasks of modern data analytics. If the adaptation is done correctly, models built on a specific data space become more robust when confronted to data depicting the same semantic concepts (the classes), but observed by another observation system with its own specificities. Among the many strategies proposed to adapt a domain to another, finding a common representation has shown excellent properties: by finding a common representation for both domains, a single classifier can be effective in both and use labelled samples from the source domain to predict the unlabelled samples of the target domain. In this paper, we propose a regularized unsupervised optimal transportation model to perform the alignment of the representations in the source and target domains. We learn a transportation plan matching both PDFs, which constrains labelled samples in the source domain to remain close during transport. This way, we exploit at the same time the few labeled information in the source and the unlabelled distributions observed in both domains. Experiments in toy and challenging real visual adaptation examples show the interest of the method, that consistently outperforms state of the art approaches.},
	urldate = {2022-04-20},
	journal = {arXiv:1507.00504 [cs]},
	author = {Courty, Nicolas and Flamary, Rémi and Tuia, Devis and Rakotomamonjy, Alain},
	month = jun,
	year = {2016},
	note = {arXiv: 1507.00504},
	keywords = {Computer Science - Machine Learning},
}

@article{wang_asymptotic_2022,
	title = {Asymptotic self-similar blow up profile for 3-{D} {Euler} via physics-informed neural networks},
	url = {http://arxiv.org/abs/2201.06780},
	abstract = {We develop a new numerical framework, employing physics-informed neural networks, to find a smooth self-similar solution for the Boussinesq equations. The solution in addition corresponds to an asymptotic self-similar profile for the 3-dimensional Euler equations in the presence of a cylindrical boundary. In particular, the solution represents a precise description of the Luo-Hou blow-up scenario [G. Luo, T. Hou, Proc. Natl. Acad. Sci. 111(36): 12968-12973, 2014] for 3-dimensional Euler. To the best of the authors' knowledge, the solution is the first truly multi-dimensional smooth backwards self-similar profile found for an equation from fluid mechanics. The new numerical framework is shown to be both robust and readily adaptable to other equations.},
	urldate = {2022-04-20},
	journal = {arXiv:2201.06780 [physics]},
	author = {Wang, Yongji and Lai, Ching-Yao and Gómez-Serrano, Javier and Buckmaster, Tristan},
	month = mar,
	year = {2022},
	note = {arXiv: 2201.06780},
	keywords = {Computer Science - Machine Learning, Mathematics - Analysis of PDEs, Physics - Fluid Dynamics},
}

@article{farrell_automated_2013,
	title = {Automated derivation of the adjoint of high-level transient finite element programs},
	volume = {35},
	issn = {1064-8275, 1095-7197},
	url = {http://arxiv.org/abs/1204.5577},
	doi = {10.1137/120873558},
	abstract = {In this paper we demonstrate a new technique for deriving discrete adjoint and tangent linear models of finite element models. The technique is significantly more efficient and automatic than standard algorithmic differentiation techniques. The approach relies on a high-level symbolic representation of the forward problem. In contrast to developing a model directly in Fortran or C++, high-level systems allow the developer to express the variational problems to be solved in near-mathematical notation. As such, these systems have a key advantage: since the mathematical structure of the problem is preserved, they are more amenable to automated analysis and manipulation. The framework introduced here is implemented in a freely available software package named dolfin-adjoint, based on the FEniCS Project. Our approach to automated adjoint derivation relies on run-time annotation of the temporal structure of the model, and employs the FEniCS finite element form compiler to automatically generate the low-level code for the derived models. The approach requires only trivial changes to a large class of forward models, including complicated time-dependent nonlinear models. The adjoint model automatically employs optimal checkpointing schemes to mitigate storage requirements for nonlinear models, without any user management or intervention. Furthermore, both the tangent linear and adjoint models naturally work in parallel, without any need to differentiate through calls to MPI or to parse OpenMP directives. The generality, applicability and efficiency of the approach are demonstrated with examples from a wide range of scientific applications.},
	number = {4},
	urldate = {2022-04-19},
	journal = {SIAM Journal on Scientific Computing},
	author = {Farrell, Patrick E. and Ham, David A. and Funke, Simon F. and Rognes, Marie E.},
	month = jan,
	year = {2013},
	note = {arXiv: 1204.5577},
	keywords = {65N30, 68N20, 49M29, Computer Science - Mathematical Software},
	pages = {C369--C393},
}

@article{innes_dont_2019,
	title = {Don't {Unroll} {Adjoint}: {Differentiating} {SSA}-{Form} {Programs}},
	shorttitle = {Don't {Unroll} {Adjoint}},
	url = {http://arxiv.org/abs/1810.07951},
	abstract = {This paper presents reverse-mode algorithmic differentiation (AD) based on source code transformation, in particular of the Static Single Assignment (SSA) form used by modern compilers. The approach can support control flow, nesting, mutation, recursion, data structures, higher-order functions, and other language constructs, and the output is given to an existing compiler to produce highly efficient differentiated code. Our implementation is a new AD tool for the Julia language, called Zygote, which presents high-level dynamic semantics while transparently compiling adjoint code under the hood. We discuss the benefits of this approach to both the usability and performance of AD tools.},
	urldate = {2022-04-19},
	journal = {arXiv:1810.07951 [cs]},
	author = {Innes, Michael},
	month = mar,
	year = {2019},
	note = {arXiv: 1810.07951},
	keywords = {Computer Science - Programming Languages},
}

@article{pathak_fourcastnet_2022,
	title = {{FourCastNet}: {A} {Global} {Data}-driven {High}-resolution {Weather} {Model} using {Adaptive} {Fourier} {Neural} {Operators}},
	shorttitle = {{FourCastNet}},
	url = {http://arxiv.org/abs/2202.11214},
	abstract = {FourCastNet, short for Fourier Forecasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium-range global predictions at \$0.25{\textasciicircum}\{{\textbackslash}circ\}\$ resolution. FourCastNet accurately forecasts high-resolution, fast-timescale variables such as the surface wind speed, precipitation, and atmospheric water vapor. It has important implications for planning wind energy resources, predicting extreme weather events such as tropical cyclones, extra-tropical cyclones, and atmospheric rivers. FourCastNet matches the forecasting accuracy of the ECMWF Integrated Forecasting System (IFS), a state-of-the-art Numerical Weather Prediction (NWP) model, at short lead times for large-scale variables, while outperforming IFS for variables with complex fine-scale structure, including precipitation. FourCastNet generates a week-long forecast in less than 2 seconds, orders of magnitude faster than IFS. The speed of FourCastNet enables the creation of rapid and inexpensive large-ensemble forecasts with thousands of ensemble-members for improving probabilistic forecasting. We discuss how data-driven deep learning models such as FourCastNet are a valuable addition to the meteorology toolkit to aid and augment NWP models.},
	urldate = {2022-04-19},
	journal = {arXiv:2202.11214 [physics]},
	author = {Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.11214},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2022-04-13},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
}

@article{finzi_simplifying_2020,
	title = {Simplifying {Hamiltonian} and {Lagrangian} {Neural} {Networks} via {Explicit} {Constraints}},
	url = {http://arxiv.org/abs/2010.13581},
	abstract = {Reasoning about the physical world requires models that are endowed with the right inductive biases to learn the underlying dynamics. Recent works improve generalization for predicting trajectories by learning the Hamiltonian or Lagrangian of a system rather than the differential equations directly. While these methods encode the constraints of the systems using generalized coordinates, we show that embedding the system into Cartesian coordinates and enforcing the constraints explicitly with Lagrange multipliers dramatically simplifies the learning problem. We introduce a series of challenging chaotic and extended-body systems, including systems with N-pendulums, spring coupling, magnetic fields, rigid rotors, and gyroscopes, to push the limits of current approaches. Our experiments show that Cartesian coordinates with explicit constraints lead to a 100x improvement in accuracy and data efficiency.},
	urldate = {2022-04-01},
	journal = {arXiv:2010.13581 [physics, stat]},
	author = {Finzi, Marc and Wang, Ke Alexander and Wilson, Andrew Gordon},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.13581},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability, Statistics - Machine Learning},
}

@article{finzi_generalizing_2020,
	title = {Generalizing {Convolutional} {Neural} {Networks} for {Equivariance} to {Lie} {Groups} on {Arbitrary} {Continuous} {Data}},
	url = {http://arxiv.org/abs/2002.12880},
	abstract = {The translation equivariance of convolutional layers enables convolutional neural networks to generalize well on image problems. While translation equivariance provides a powerful inductive bias for images, we often additionally desire equivariance to other transformations, such as rotations, especially for non-image data. We propose a general method to construct a convolutional layer that is equivariant to transformations from any specified Lie group with a surjective exponential map. Incorporating equivariance to a new group requires implementing only the group exponential and logarithm maps, enabling rapid prototyping. Showcasing the simplicity and generality of our method, we apply the same model architecture to images, ball-and-stick molecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the equivariance of our models is especially impactful, leading to exact conservation of linear and angular momentum.},
	urldate = {2022-04-01},
	journal = {arXiv:2002.12880 [cs, stat]},
	author = {Finzi, Marc and Stanton, Samuel and Izmailov, Pavel and Wilson, Andrew Gordon},
	month = sep,
	year = {2020},
	note = {arXiv: 2002.12880},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{brandstetter_lie_2022,
	title = {Lie {Point} {Symmetry} {Data} {Augmentation} for {Neural} {PDE} {Solvers}},
	url = {http://arxiv.org/abs/2202.07643},
	abstract = {Neural networks are increasingly being used to solve partial differential equations (PDEs), replacing slower numerical solvers. However, a critical issue is that neural PDE solvers require high-quality ground truth data, which usually must come from the very solvers they are designed to replace. Thus, we are presented with a proverbial chicken-and-egg problem. In this paper, we present a method, which can partially alleviate this problem, by improving neural PDE solver sample complexity -- Lie point symmetry data augmentation (LPSDA). In the context of PDEs, it turns out that we are able to quantitatively derive an exhaustive list of data transformations, based on the Lie point symmetry group of the PDEs in question, something not possible in other application areas. We present this framework and demonstrate how it can easily be deployed to improve neural PDE solver sample complexity by an order of magnitude.},
	urldate = {2022-03-31},
	journal = {arXiv:2202.07643 [cs]},
	author = {Brandstetter, Johannes and Welling, Max and Worrall, Daniel E.},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.07643},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{wang_survey_2021,
	title = {A {Survey} on {Curriculum} {Learning}},
	url = {http://arxiv.org/abs/2010.13166},
	abstract = {Curriculum learning (CL) is a training strategy that trains a machine learning model from easier data to harder data, which imitates the meaningful learning order in human curricula. As an easy-to-use plug-in, the CL strategy has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision and natural language processing etc. In this survey article, we comprehensively review CL from various aspects including motivations, definitions, theories, and applications. We discuss works on curriculum learning within a general CL framework, elaborating on how to design a manually predefined curriculum or an automatic curriculum. In particular, we summarize existing CL designs based on the general framework of Difficulty Measurer+Training Scheduler and further categorize the methodologies for automatic CL into four groups, i.e., Self-paced Learning, Transfer Teacher, RL Teacher, and Other Automatic CL. We also analyze principles to select different CL designs that may benefit practical applications. Finally, we present our insights on the relationships connecting CL and other machine learning concepts including transfer learning, meta-learning, continual learning and active learning, etc., then point out challenges in CL as well as potential future research directions deserving further investigations.},
	urldate = {2022-03-30},
	journal = {arXiv:2010.13166 [cs]},
	author = {Wang, Xin and Chen, Yudong and Zhu, Wenwu},
	month = mar,
	year = {2021},
	note = {arXiv: 2010.13166},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{krishnapriyan_characterizing_2021,
	title = {Characterizing possible failure modes in physics-informed neural networks},
	url = {http://arxiv.org/abs/2109.01050},
	abstract = {Recent work in scientific machine learning has developed so-called physics-informed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN's setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The first approach is to use curriculum regularization, where the PINN's loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.},
	urldate = {2022-03-29},
	journal = {arXiv:2109.01050 [physics]},
	author = {Krishnapriyan, Aditi S. and Gholami, Amir and Zhe, Shandian and Kirby, Robert M. and Mahoney, Michael W.},
	month = nov,
	year = {2021},
	note = {arXiv: 2109.01050},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@article{krishnapriyan_characterizing_nodate,
	title = {Characterizing possible failure modes in physics-informed neural networks},
	abstract = {Recent work in scientiﬁc machine learning has developed so-called physicsinformed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN’s setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The ﬁrst approach is to use curriculum regularization, where the PINN’s loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.},
	language = {en},
	author = {Krishnapriyan, Aditi S and Gholami, Amir and Zhe, Shandian and Kirby, Robert M and Mahoney, Michael W},
	pages = {13},
}

@article{lamb_professor_2016,
	title = {Professor {Forcing}: {A} {New} {Algorithm} for {Training} {Recurrent} {Networks}},
	shorttitle = {Professor {Forcing}},
	url = {http://arxiv.org/abs/1610.09038},
	abstract = {The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network's own one-step-ahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps. We apply Professor Forcing to language modeling, vocal synthesis on raw waveforms, handwriting generation, and image generation. Empirically we find that Professor Forcing acts as a regularizer, improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sampling for a large number of time steps. This is supported by human evaluation of sample quality. Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar.},
	urldate = {2022-03-24},
	journal = {arXiv:1610.09038 [cs, stat]},
	author = {Lamb, Alex and Goyal, Anirudh and Zhang, Ying and Zhang, Saizheng and Courville, Aaron and Bengio, Yoshua},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.09038},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ott_fortran-keras_2020,
	title = {A {Fortran}-{Keras} {Deep} {Learning} {Bridge} for {Scientific} {Computing}},
	url = {http://arxiv.org/abs/2004.10652},
	abstract = {Implementing artificial neural networks is commonly achieved via high-level programming languages like Python and easy-to-use deep learning libraries like Keras. These software libraries come pre-loaded with a variety of network architectures, provide autodifferentiation, and support GPUs for fast and efficient computation. As a result, a deep learning practitioner will favor training a neural network model in Python, where these tools are readily available. However, many large-scale scientific computation projects are written in Fortran, making it difficult to integrate with modern deep learning methods. To alleviate this problem, we introduce a software library, the Fortran-Keras Bridge (FKB). This two-way bridge connects environments where deep learning resources are plentiful, with those where they are scarce. The paper describes several unique features offered by FKB, such as customizable layers, loss functions, and network ensembles. The paper concludes with a case study that applies FKB to address open questions about the robustness of an experimental approach to global climate simulation, in which subgrid physics are outsourced to deep neural network emulators. In this context, FKB enables a hyperparameter search of one hundred plus candidate models of subgrid cloud and radiation physics, initially implemented in Keras, to be transferred and used in Fortran. Such a process allows the model's emergent behavior to be assessed, i.e. when fit imperfections are coupled to explicit planetary-scale fluid dynamics. The results reveal a previously unrecognized strong relationship between offline validation error and online performance, in which the choice of optimizer proves unexpectedly critical. This reveals many neural network architectures that produce considerable improvements in stability including some with reduced error, for an especially challenging training dataset.},
	urldate = {2022-03-17},
	journal = {arXiv:2004.10652 [cs]},
	author = {Ott, Jordan and Pritchard, Mike and Best, Natalie and Linstead, Erik and Curcic, Milan and Baldi, Pierre},
	month = aug,
	year = {2020},
	note = {arXiv: 2004.10652},
	keywords = {Computer Science - Machine Learning, Computer Science - Programming Languages},
}

@article{lavin_simulation_2021,
	title = {Simulation {Intelligence}: {Towards} a {New} {Generation} of {Scientific} {Methods}},
	shorttitle = {Simulation {Intelligence}},
	url = {http://arxiv.org/abs/2112.03235},
	abstract = {The original "Seven Motifs" set forth a roadmap of essential methods for the field of scientific computing, where a motif is an algorithmic method that captures a pattern of computation and data movement. We present the "Nine Motifs of Simulation Intelligence", a roadmap for the development and integration of the essential algorithms necessary for a merger of scientific computing, scientific simulation, and artificial intelligence. We call this merger simulation intelligence (SI), for short. We argue the motifs of simulation intelligence are interconnected and interdependent, much like the components within the layers of an operating system. Using this metaphor, we explore the nature of each layer of the simulation intelligence operating system stack (SI-stack) and the motifs therein: (1) Multi-physics and multi-scale modeling; (2) Surrogate modeling and emulation; (3) Simulation-based inference; (4) Causal modeling and inference; (5) Agent-based modeling; (6) Probabilistic programming; (7) Differentiable programming; (8) Open-ended optimization; (9) Machine programming. We believe coordinated efforts between motifs offers immense opportunity to accelerate scientific discovery, from solving inverse problems in synthetic biology and climate science, to directing nuclear energy experiments and predicting emergent behavior in socioeconomic settings. We elaborate on each layer of the SI-stack, detailing the state-of-art methods, presenting examples to highlight challenges and opportunities, and advocating for specific ways to advance the motifs and the synergies from their combinations. Advancing and integrating these technologies can enable a robust and efficient hypothesis-simulation-analysis type of scientific method, which we introduce with several use-cases for human-machine teaming and automated science.},
	urldate = {2022-03-16},
	journal = {arXiv:2112.03235 [cs]},
	author = {Lavin, Alexander and Zenil, Hector and Paige, Brooks and Krakauer, David and Gottschlich, Justin and Mattson, Tim and Anandkumar, Anima and Choudry, Sanjay and Rocki, Kamil and Baydin, Atılım Güneş and Prunkl, Carina and Paige, Brooks and Isayev, Olexandr and Peterson, Erik and McMahon, Peter L. and Macke, Jakob and Cranmer, Kyle and Zhang, Jiaxin and Wainwright, Haruko and Hanuka, Adi and Veloso, Manuela and Assefa, Samuel and Zheng, Stephan and Pfeffer, Avi},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.03235},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning, Computer Science - Mathematical Software},
}

@article{yin_augmenting_2021,
	title = {Augmenting {Physical} {Models} with {Deep} {Networks} for {Complex} {Dynamics} {Forecasting}},
	volume = {2021},
	issn = {1742-5468},
	url = {http://arxiv.org/abs/2010.04456},
	doi = {10.1088/1742-5468/ac3ae5},
	abstract = {Forecasting complex dynamical phenomena in settings where only partial knowledge of their dynamics is available is a prevalent problem across various scientific fields. While purely data-driven approaches are arguably insufficient in this context, standard physical modeling based approaches tend to be over-simplistic, inducing non-negligible errors. In this work, we introduce the APHYNITY framework, a principled approach for augmenting incomplete physical dynamics described by differential equations with deep data-driven models. It consists in decomposing the dynamics into two components: a physical component accounting for the dynamics for which we have some prior knowledge, and a data-driven component accounting for errors of the physical model. The learning problem is carefully formulated such that the physical model explains as much of the data as possible, while the data-driven component only describes information that cannot be captured by the physical model, no more, no less. This not only provides the existence and uniqueness for this decomposition, but also ensures interpretability and benefits generalization. Experiments made on three important use cases, each representative of a different family of phenomena, i.e. reaction-diffusion equations, wave equations and the non-linear damped pendulum, show that APHYNITY can efficiently leverage approximate physical models to accurately forecast the evolution of the system and correctly identify relevant physical parameters. Code is available at https://github.com/yuan-yin/APHYNITY .},
	number = {12},
	urldate = {2022-03-16},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Yin, Yuan and Guen, Vincent Le and Dona, Jérémie and de Bézenac, Emmanuel and Ayed, Ibrahim and Thome, Nicolas and Gallinari, Patrick},
	month = dec,
	year = {2021},
	note = {arXiv: 2010.04456},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {124012},
}

@article{haywood_triple_2022,
	title = {Triple {Hill}'s {Vortex} {Synthetic} {Eddy} {Method}},
	volume = {108},
	issn = {1386-6184, 1573-1987},
	url = {http://arxiv.org/abs/2111.13757},
	doi = {10.1007/s10494-021-00289-4},
	abstract = {The generation of initial or inflow synthetic turbulent velocity or scalar fields reproducing statistical characteristics of realistic turbulence is still a challenge. The synthetic eddy method, previously introduced in the context of inflow conditions for large eddy simulations, is based on the assumption that turbulence can be regarded as a superposition of coherent structures. In this paper, a new type of synthetic eddy method is proposed, where the fundamental eddy is constructed by superposing three Hill's vortices, with their axes orthogonal to each other. A distribution of Hill's vortices is used to synthesize an anisotropic turbulent velocity field that satisfies the incompressibility condition and match a given Reynolds stress tensor. The amplitudes of the three vortices that form the fundamental eddy are calculated from known Reynolds stress profiles through a transformation from the physical reference frame to the principal-axis reference frame. In this way, divergence-free anisotropic turbulent velocity fields are obtained that can reproduce a given Reynolds stress tensor. The model was tested on both isotropic and anisotropic turbulent velocity fields, in the framework of grid turbulence decay and turbulent channel flow, respectively. The transition from artificial to realistic turbulence in the proximity to the inflow boundary was found to be small in all test cases that were considered.},
	number = {3},
	urldate = {2022-03-16},
	journal = {Flow, Turbulence and Combustion},
	author = {Haywood, John and Sescu, Adrian and Bhushan, Shanti and Kees, Chris},
	month = mar,
	year = {2022},
	note = {arXiv: 2111.13757},
	keywords = {76F65, 35Q30,, Physics - Fluid Dynamics},
	pages = {627--659},
}

@article{mayr_boundary_2021,
	title = {Boundary {Graph} {Neural} {Networks} for {3D} {Simulations}},
	url = {http://arxiv.org/abs/2106.11299},
	abstract = {The abundance of data has given machine learning considerable momentum in natural sciences and engineering. However, the modeling of simulated physical processes remains difficult. A key problem is the correct handling of geometric boundaries. While triangularized geometric boundaries are very common in engineering applications, they are notoriously difficult to model by machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce Boundary Graph Neural Networks (BGNNs), which dynamically modify graph structures to address boundary conditions. Boundary graph structures are constructed via modifying edges, augmenting node features, and dynamically inserting virtual nodes. The new BGNNs are tested on complex 3D granular flow processes of hoppers and rotating drums which are standard components of industrial machinery. Using precise simulations that are obtained by an expensive and complex discrete element method, BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. Even if complex boundaries are present, BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps, and most notably particles completely stay within the geometric objects without using handcrafted conditions or restrictions.},
	urldate = {2022-03-11},
	journal = {arXiv:2106.11299 [cs, stat]},
	author = {Mayr, Andreas and Lehner, Sebastian and Mayrhofer, Arno and Kloss, Christoph and Hochreiter, Sepp and Brandstetter, Johannes},
	month = oct,
	year = {2021},
	note = {arXiv: 2106.11299},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{komen_quasi-dns_2014,
	title = {Quasi-{DNS} capabilities of {OpenFOAM} for different mesh types},
	volume = {96},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793014000760},
	doi = {10.1016/j.compfluid.2014.02.013},
	abstract = {Experimental limitations for certain nuclear reactor safety applications have pushed forward the demand for high fidelity DNS reference solutions for complex geometric configurations such as a T-junction or a spherical pebble bed. The application of traditional high-order DNS codes is limited to simple flow domains such as a periodic box or channel. As a possibility to create reference DNS solutions for more complex geometries, we have assessed the (quasi-)DNS capabilities of the OpenFOAM finite volume CFD solver for both structured hexahedral meshes and arbitrary polyhedral meshes. The feasibility of (quasi-)DNS analyses on polyhedral grids is of main interest, since this may offer the possibility to significantly expand the availability of (quasi-)DNS-quality data on arbitrarily complex geometries. In order to have a basis for the considered assessment, the mutual differences between generally recognized reference DNS data bases for turbulent channel and pipe flows are determined first. Subsequently, the differences between these reference DNS solutions and the present OpenFOAM (quasi-)DNS solutions are quantified for the considered mesh types. We use an existing finite volume CFD method and well known turbulent channel and pipe flow DNS reference cases for the assessments in this paper. New in this paper are the application of this CFD method to (quasi-)DNS analyses using arbitrary polyhedral meshes, and the quantification of respectively the mutual differences between generally recognized reference DNS data bases and the differences between the obtained OpenFOAM (quasi-)DNS data and these reference DNS data bases. Based on the presented assessment, it is observed that the differences between the OpenFOAM solutions and the considered reference DNS solutions are practically the same as the mutual differences between these reference DNS solutions when structured hexahedral meshes are used. Furthermore, it is observed that the differences as obtained by OpenFOAM on extruded polyhedral meshes are practically the same as those obtained for the structured hexahedral meshes. In contrast, the full polyhedral mesh shows somewhat larger differences near the peaks in the rms velocity profiles, whereas the differences in the bulk flow are again practically the same as those for the hexahedral grids.},
	language = {en},
	urldate = {2022-03-09},
	journal = {Computers \& Fluids},
	author = {Komen, Ed and Shams, Afaque and Camilo, Leonardo and Koren, Barry},
	month = jun,
	year = {2014},
	keywords = {Channel flows, Complex geometries, DNS, OpenFOAM, Polyhedral cells},
	pages = {87--104},
}

@article{pumir_numerical_1994,
	title = {A numerical study of pressure fluctuations in three‐dimensional, incompressible, homogeneous, isotropic turbulence},
	volume = {6},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.868213},
	doi = {10.1063/1.868213},
	number = {6},
	urldate = {2022-03-09},
	journal = {Physics of Fluids},
	author = {Pumir, Alain},
	month = jun,
	year = {1994},
	note = {Publisher: American Institute of Physics},
	pages = {2071--2083},
}

@article{jimenez_structure_1993,
	title = {The structure of intense vorticity in isotropic turbulence},
	volume = {255},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/structure-of-intense-vorticity-in-isotropic-turbulence/0E601069AB7E5D7D78DD32F894E56A99#access-block},
	doi = {10.1017/S0022112093002393},
	abstract = {The structure of the intense-vorticity regions is studied in numerically simulated homogeneous, isotropic, equilibrium turbulent flow fields at four different Reynolds numbers, in the range Reλ = 35–170. In accordance with previous investigators this vorticity is found to be organized in coherent, cylindrical or ribbon-like, vortices (‘worms’). A statistical study suggests that they are simply especially intense features of the background, O(ω′), vorticity. Their radii scale with the Kolmogorov microscale and their lengths with the integral scale of the flow. An interesting observation is that the Reynolds number γ/ν, based on the circulation of the intense vortices, increases monotonically with Reλ, raising the question of the stability of the structures in the limit of Reλ → ∞. Conversely, the average rate of stretching of these vortices increases only slowly with their peak vorticity, suggesting that self-stretching is not important in their evolution. One- and two-dimensional statistics of vorticity and strain are presented; they are non-Gaussian and the behaviour of their tails depends strongly on the Reynolds number. There is no evidence of convergence to a limiting distribution in this range of Reλ, even though the energy spectra and the energy dissipation rate show good asymptotic properties in the higher-Reynolds-number cases. Evidence is presented to show that worms are natural features of the flow and that they do not depend on the particular forcing scheme.},
	language = {en},
	urldate = {2022-03-09},
	journal = {Journal of Fluid Mechanics},
	author = {Jiménez, Javier and Wray, Alan A. and Saffman, Philip G. and Rogallo, Robert S.},
	month = oct,
	year = {1993},
	note = {Publisher: Cambridge University Press},
	pages = {65--90},
}

@article{sen_anisotropy_2012,
	title = {Anisotropy and non-universality in scaling laws of the large scale energy spectrum in rotating turbulence},
	volume = {86},
	issn = {1539-3755, 1550-2376},
	url = {http://arxiv.org/abs/1203.5131},
	doi = {10.1103/PhysRevE.86.036319},
	abstract = {Rapidly rotating turbulent flow is characterized by the emergence of columnar structures that are representative of quasi-two dimensional behavior of the flow. It is known that when energy is injected into the fluid at an intermediate scale \$L\_f\$, it cascades towards smaller as well as larger scales. In this paper we analyze the flow in the {\textbackslash}textit\{inverse cascade\} range at a small but fixed Rossby number, \{\${\textbackslash}mathcal\{R\}o\_f {\textbackslash}approx 0.05\$\}. Several \{numerical simulations with\} helical and non-helical forcing functions are considered in periodic boxes with unit aspect ratio. In order to resolve the inverse cascade range with \{reasonably\} large Reynolds number, the analysis is based on large eddy simulations which include the effect of helicity on eddy viscosity and eddy noise. Thus, we model the small scales and resolve explicitly the large scales. We show that the large-scale energy spectrum has at least two solutions: one that is consistent with Kolmogorov-Kraichnan-Batchelor-Leith phenomenology for the inverse cascade of energy in two-dimensional (2D) turbulence with a \{\${\textbackslash}sim k\_\{{\textbackslash}perp\}{\textasciicircum}\{-5/3\}\$\} scaling, and the other that corresponds to a steeper \{\${\textbackslash}sim k\_\{{\textbackslash}perp\}{\textasciicircum}\{-3\}\$\} spectrum in which the three-dimensional (3D) modes release a substantial fraction of their energy per unit time to 2D modes. \{The spectrum that\} emerges \{depends on\} the anisotropy of the forcing function\{,\} the former solution prevailing for forcings in which more energy is injected into 2D modes while the latter prevails for isotropic forcing. \{In the case of anisotropic forcing, whence the energy\} goes from the 2D to the 3D modes at low wavenumbers, large-scale shear is created resulting in another time scale \${\textbackslash}tau\_\{sh\}\$, associated with shear, \{thereby producing\} a \${\textbackslash}sim k{\textasciicircum}\{-1\}\$ spectrum for the \{total energy\} with the 2D modes still following a \{\${\textbackslash}sim k\_\{{\textbackslash}perp\}{\textasciicircum}\{-5/3\}\$\} scaling.},
	number = {3},
	urldate = {2022-03-09},
	journal = {Physical Review E},
	author = {Sen, Amrik and Mininni, Pablo D. and Rosenberg, Duane and pouquet, Annick},
	month = sep,
	year = {2012},
	note = {arXiv: 1203.5131},
	keywords = {Mathematical Physics, Physics - Fluid Dynamics},
	pages = {036319},
}

@article{pumir_numerical_1994-1,
	title = {A numerical study of pressure fluctuations in three‐dimensional, incompressible, homogeneous, isotropic turbulence},
	volume = {6},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.868213},
	doi = {10.1063/1.868213},
	number = {6},
	urldate = {2022-03-09},
	journal = {Physics of Fluids},
	author = {Pumir, Alain},
	month = jun,
	year = {1994},
	note = {Publisher: American Institute of Physics},
	pages = {2071--2083},
}

@article{mininni_helicity_2009,
	title = {Helicity cascades in rotating turbulence},
	volume = {79},
	issn = {1539-3755, 1550-2376},
	url = {http://arxiv.org/abs/0809.0869},
	doi = {10.1103/PhysRevE.79.026304},
	abstract = {The effect of helicity (velocity-vorticity correlations) is studied in direct numerical simulations of rotating turbulence down to Rossby numbers of 0.02. The results suggest that the presence of net helicity plays an important role in the dynamics of the flow. In particular, at small Rossby number, the energy cascades to large scales, as expected, but helicity then can dominate the cascade to small scales. A phenomenological interpretation in terms of a direct cascade of helicity slowed down by wave-eddy interactions leads to the prediction of new inertial indices for the small-scale energy and helicity spectra.},
	number = {2},
	urldate = {2022-03-09},
	journal = {Physical Review E},
	author = {Mininni, P. D. and Pouquet, A.},
	month = feb,
	year = {2009},
	note = {arXiv: 0809.0869},
	keywords = {Physics - Atmospheric and Oceanic Physics, Physics - Fluid Dynamics},
	pages = {026304},
}

@article{jimenez_structure_1993-1,
	title = {The structure of intense vorticity in isotropic turbulence},
	volume = {255},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/structure-of-intense-vorticity-in-isotropic-turbulence/0E601069AB7E5D7D78DD32F894E56A99},
	doi = {10.1017/S0022112093002393},
	abstract = {The structure of the intense-vorticity regions is studied in numerically simulated homogeneous, isotropic, equilibrium turbulent flow fields at four different Reynolds numbers, in the range Reλ = 35–170. In accordance with previous investigators this vorticity is found to be organized in coherent, cylindrical or ribbon-like, vortices (‘worms’). A statistical study suggests that they are simply especially intense features of the background, O(ω′), vorticity. Their radii scale with the Kolmogorov microscale and their lengths with the integral scale of the flow. An interesting observation is that the Reynolds number γ/ν, based on the circulation of the intense vortices, increases monotonically with Reλ, raising the question of the stability of the structures in the limit of Reλ → ∞. Conversely, the average rate of stretching of these vortices increases only slowly with their peak vorticity, suggesting that self-stretching is not important in their evolution. One- and two-dimensional statistics of vorticity and strain are presented; they are non-Gaussian and the behaviour of their tails depends strongly on the Reynolds number. There is no evidence of convergence to a limiting distribution in this range of Reλ, even though the energy spectra and the energy dissipation rate show good asymptotic properties in the higher-Reynolds-number cases. Evidence is presented to show that worms are natural features of the flow and that they do not depend on the particular forcing scheme.},
	language = {en},
	urldate = {2022-03-09},
	journal = {Journal of Fluid Mechanics},
	author = {Jiménez, Javier and Wray, Alan A. and Saffman, Philip G. and Rogallo, Robert S.},
	month = oct,
	year = {1993},
	note = {Publisher: Cambridge University Press},
	pages = {65--90},
}

@incollection{childress_dynamos_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Dynamos and {Non}-dynamos},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_4},
	abstract = {The purpose of this chapter is to link the discussion and examples of Chaps. 1–3 to the subsequent analysis and modelling. We reexamine a number of topics which were introduced in Chap. 1. Aided by the examples of fast dynamos given in Chaps. 2 and 3, we reconsider in §4.1 the formulation of the fast dynamo problem and the role of diffusion. In §4.2 we prove several anti-dynamo theorems, some of which have already been mentioned and used. These can be used to exclude classes of flows from consideration and to help determine possible fast dynamo mechanisms. Finally in §4.3 we discuss a result of Moffatt \& Proctor (1985) concerning the non-existence of smooth eigenfunctions when ε = 0.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_4},
	keywords = {Dynamo Action, Induction Equation, Magnetic Helicity, Periodic Orbit, Planar Flow},
	pages = {89--111},
}

@incollection{childress_random_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Random {Fast} {Dynamos}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_11},
	abstract = {One way to attempt to simplify the fast dynamo problem is to study the evolution of magnetic fields in random flows. We say that an ensemble of random flows is a fast dynamo if the ensemble-averaged magnetic field grows at a rate independent of the diffusivity ε in the limit ε → 0, that is, if \$\$ {\textbackslash}gamma \_0 = {\textbackslash}mathop \{{\textbackslash}lim {\textbackslash}inf \}{\textbackslash}limits\_\{{\textbackslash}varepsilon {\textbackslash}to 0\} {\textbackslash}gamma \_0 ({\textbackslash}varepsilon ) {\textgreater} 0, \$\$ (11.0.1) where the growth rate γ(ε) can be defined for ε {\textgreater} 0 by, for example, the growth of magnetic energy or linear functionals: \$\$ {\textbackslash}gamma ({\textbackslash}varepsilon ) = {\textbackslash}mathop \{{\textbackslash}sup \}{\textbackslash}limits\_\{B\_0 \} {\textbackslash}mathop \{{\textbackslash}lim {\textbackslash}sup \}{\textbackslash}limits\_\{t {\textbackslash}to {\textbackslash}infty \} {\textbackslash}frac\{1\} \{\{2t\}\}{\textbackslash}log {\textless} E\_M (t) {\textgreater} \$\$ (11.0.2a)\$\$ = {\textbackslash}mathop \{{\textbackslash}sup \}{\textbackslash}limits\_\{B\_0 \} {\textbackslash}mathop \{{\textbackslash}sup \}{\textbackslash}limits\_f {\textbackslash}mathop \{{\textbackslash}lim {\textbackslash}sup \}{\textbackslash}limits\_\{t {\textbackslash}to {\textbackslash}infty \} {\textbackslash}frac\{1\} \{t\}{\textbackslash}log {\textless} L\_f B(t) {\textgreater} . \$\$ (11.0.2b) Here {\textless}·{\textgreater} is an ensemble average. This definition is the most tractable mathematically; we return to discuss it in §11.5, but here we simply remark that it is not the only definition, and perhaps not the best definition.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_11},
	keywords = {Dynamo Action, Ensemble Average, Random Flow, Random Wave, Typical Realisation},
	pages = {319--341},
}

@incollection{childress_fast_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Fast {Dynamos} in {Maps}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_3},
	abstract = {As we have seen in Chap. 2, numerical experiments using two-dimensional unsteady flows strongly suggest the existence of fast dynamos, and point toward a connection between computation with ε ≡ 0 and the limit of computations with ε {\textgreater} 0. In particular the flux conjecture appears justified in all cases of fast dynamo action that have been examined. For three-dimensional steady flows there is some support for fast dynamo action, but there are still perplexing gaps in our understanding of magnetic structure and its measurement. The flux conjecture seems to work for the Kolmogorov flow but has not been verified for the ABC 111 flow of §2.6.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_3},
	keywords = {Dynamo Action, Flux Growth, Haar Wavelet, Perfect Conductor, Total Flux},
	pages = {61--87},
}

@incollection{childress_strongly_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Strongly {Chaotic} {Systems}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_10},
	abstract = {In this chapter we explore fast dynamo action in the limit of strong chaos. This limit was first used by Soward (1993a) who takes the pulsed Beltrami waves of Bayly \& Childress (1988, 1989), \$\$ u = {\textbackslash}left{\textbackslash}\{\vphantom{\}} {\textbackslash}begin\{gathered\} (0,{\textbackslash}sin x,{\textbackslash}cos x), (0 {\textless} t{\textbackslash}bmod 2{\textbackslash}tau {\textless} {\textbackslash}tau ), {\textbackslash}hfill {\textbackslash}{\textbackslash} ( - {\textbackslash}sin y,0,{\textbackslash}cos y), ({\textbackslash}tau {\textless} t{\textbackslash}bmod 2{\textbackslash}tau {\textless} 2{\textbackslash}tau ), {\textbackslash}hfill {\textbackslash}{\textbackslash} {\textbackslash}end\{gathered\} {\textbackslash}right. \$\$ (10.0.1) and considers the limit of very long pulses, τ ≫ 1. In the opposite limit τ → 0, the rapid pulsing of waves generates the average of the two waves, which is the Roberts’ flow of §5.1, an integrable flow. As τ is increased from zero, separatrices split, leaving thin bands of chaos in which the stretching and folding of magnetic field can be understood using the techniques of Chap. 8. As τ is increased further, the phase space becomes more chaotic, until eventually, for large τ, Poincaré sections show chaos everywhere. This is the limit of strong chaos or the anti-integrable limit, and is an important limit for proving results about chaotic systems (Aubry \& Abramovici 1990). For example, using the standard map with parameter K in this limit K → ∞, Rechester \& White (1980) have studied diffusion of particles, and Aubry \& Abramovici (1990) have shown how periodic orbits bifurcate from a K = ∞ Bernoulli system (see §3.3.2).},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_10},
	keywords = {Chaotic System, Constant Field, Fourier Coefficient, General Initial Condition, Inverse Cascade},
	pages = {289--317},
}

@incollection{childress_spectra_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Spectra and {Eigenfunctions}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_9},
	abstract = {The kinematic dynamo problem is an eigenvalue problem. The fast dynamo problem thus encompasses the study of the spectrum of the induction operator in the perfectly conducting limit. The more abstract literature on spectral theory has had relatively little impact on dynamo theory, however, in part because of the relatively simple discrete spectrum at finite magnetic Reynolds numbers. The discrete eigenvalues largely disappear in the perfectly conducting limit, and concepts of continuous and residual spectra are needed. There is a considerable literature on the spectrum of linearized MHD equations, recently surveyed in the book by Lifschitz (1989). While this theory must in some sense ‘contain’ a restriction to kinematic dynamo theory, the emphasis is sufficiently distinct to make a separate treatment desirable. There are also similar issues in the theory of hydrodynamical stability in the inviscid limit. However it is only recently that inviscid stability theory has been extended beyond the classical examples, for example parallel flow or flow with circular streamlines, to more complicated two- and three-dimensional flows, including stretching flows. Recent discussions of the stability of ABC and other Beltrami flows (Arnold 1972, Galloway \& Frisch 1987, Moffatt 1986, Friedlander \& Vishik 1992, Friedlander, Gilbert \& Vishik 1993) have in fact been closely associated with developments in MHD and dynamo theory. Finally, recent concerns about the role of eigenvalue problems in hydrodynamic stability theory, where significant transient growth can occur when nominally stable flows are perturbed, apply here with special force.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_9},
	keywords = {Adjoint Operator, Dynamo Action, Eigenvalue Problem, Induction Operator, Perfect Conductor},
	pages = {245--288},
}

@incollection{childress_upper_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Upper {Bounds}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_6},
	abstract = {The broad theme of this chapter is the derivation of upper bounds for fast dynamo growth rates. We have already met the line-stretching exponent hline as a plausible upper bound in §2.4 and §3.3; this is discussed further in §6.1. In §6.2 we consider a conjecture of Oseledets (1993), which is related to methods of obtaining fast dynamo growth rates using Fredholm determinants (§6.3). In §6.4 we discuss Arnold’s (1972) suspension of the cat map as a flow on a manifold; this is an example of an Anosov flow, and in §6.5 we develop Bayly’s (1986) analysis of fast dynamo action in such flows. Section 6.6 follows Vishik’s (1988, 1989) construction of an approximate Green’s function, which gives an upper bound on fast dynamo growth rates. In §§6.7, 8 we consider the implementation of diffusion in terms of noisy trajectories, sketch Klapper \& Young’s (1995) proof that htop bounds fast dynamo growth rates, and discuss the flux conjecture.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_6},
	keywords = {Dynamo Action, Fredholm Determinant, Periodic Orbit, Topological Entropy, True Orbit},
	pages = {149--184},
}

@incollection{childress_fast_1995-1,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {The {Fast} {Dynamo} {Problem}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_1},
	abstract = {This book is about the structure of magnetic fields in electrically conducting fluids. Most ordinary fluids, such as air or water at familiar temperatures and pressures, are not good conductors of electricity, and so offer little direct experience of the kind of phenomena we shall be examining. In more extreme environments — the liquid core of the Earth or the atmospheres of stars, for example — electrically conducting fluids or plasmas are common. And there magnetic fields of surprising complexity are observed. Although we shall be concerned with models that are very simple and idealized, the motivation for the work described in the following pages lies in these examples of magnetic fields in astrophysics.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_1},
	keywords = {Convection Zone, Flux Tube, Magnetic Field, Magnetic Reynolds Number, Material Line},
	pages = {1--30},
}

@incollection{childress_dynamics_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Dynamics},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_12},
	abstract = {Kinematic dynamo theory is a successful theory in the sense that it is now established that dynamo action occurs commonly in three-dimensional flows of an electrically conducting fluid. This fact bodes well for MHD dynamo theories, as discussed in §1.2.4, but does not carry with it any information about the fields that are ultimately excited in a dynamical model: the structure of the magnetic field must be determined by the coupled system of field and flow, and in particular the feedback of the Lorentz force.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_12},
	pages = {343--380},
}

@incollection{childress_magnetic_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Magnetic {Structure} in {Chaotic} {Flows}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_7},
	abstract = {In this chapter we discuss the structure of magnetic fields in chaotic fast dynamos. The results contrast with those in Chap. 5 for laminar flows: in a chaotic flow the field is less organized and chaotic streamlines spread field over finite volumes of space. Furthermore a chaotic flow generally stretches some field vectors more than others, leading to the phenomenon of intermittency — the concentration of very strong fields in very small regions of space (§7.1). Another feature of magnetic fields in chaotic flows is the generation of fields that change sign repeatedly on small scales; this can be quantified by means of a cancellation exponent, introduced by Ott et al. (1992), which can also be related to growth rates (§7.2). In §7.3 we consider properties of magnetic field and fast amplification mechanisms in steady three-dimensional flows. A ‘cut-paste’ operation is described: this can operate in steady flows with stagnation points to supplement the stretching, folding and shearing of field.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_7},
	keywords = {Flux Growth, Poincare Section, Stagnation Point, Steady Flow, Transverse Field},
	pages = {185--212},
}

@incollection{childress_fast_1995-2,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Fast {Dynamo} {Action} in {Flows}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_2},
	abstract = {Much of the evidence for fast dynamo action in physically reasonable fluid flows comes from careful numerical simulations. These can never give a completely definite answer as to whether a fast dynamo exists; the numerical value of ε that can be achieved is limited by the computer’s memory since solutions of the induction equation have a smallest scale of order {\textbackslash}( {\textbackslash}sqrt {\textbackslash}varepsilon {\textbackslash}) (see §1.5 and Chap. 5), and to verify the process all sensible scales need to be resolved. Therefore in the absence of an analytical theory a simulation can only suggest the asymptotic behavior of the growth rate as ε → 0. On the other hand there is as yet no mathematical theory powerful enough to prove that fast dynamo action can occur in realistic flows, and much of the progress in the theory of fast dynamos has come from interplay between numerical simulation, modelling, approximation and tentative analysis.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_2},
	keywords = {Chaotic Region, Flux Growth, Heteroclinic Orbit, Stable Manifold, Stagnation Point},
	pages = {31--60},
}

@incollection{childress_magnetic_1995-1,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Magnetic {Structure} in {Steady} {Integrable} {Flows}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_5},
	abstract = {From the examples of Chaps. 2 and 3 we have seen that fast dynamo activity is accompanied by the emergence of intense, small-scale magnetic structure. The most direct connection of this structure to the geometry of the flow is through the stretching of vectors as measured by the Liapunov exponent of the flow. There are, however, other ways to produce these effects in flows having zero Liapunov exponent. In the present chapter we shall consider processes of this kind for several simple steady flow fields. These examples will share many features with a classical problem of fluid mechanics, namely the formation and structure of boundary layers in viscous fluid flows at large Reynolds number Re ≡ U L/v, with v the kinematic viscosity (see, e.g., Prandtl 1952, Batchelor 1967). Boundary-layer theory originated in Prandtl’s observations of the flow adjacent to a rigid wall where the fluid adheres. The flow is arrested in a thin layer of thickness O(Re−1/2). Mathematically, the Prandtl boundary-layer theory has been recognized to be a singular perturbation of the inviscid or Euler limit (see, e.g., Van Dyke 1975). In such a perturbation theory, the ideal fluid with zero viscosity is analogous to our perfectly-conducting limit. In the thin boundary layer, viscous forces are in balance with inertial forces and the ideal or Euler equations are not valid limits of the Navier-Stokes equations. Solutions of the Navier-Stokes equations which are valid in the limit of large Reynolds number, uniformly over the flow domain, must in general contain such boundary-layer structures.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_5},
	keywords = {Boundary Layer, Flux Rope, Horizontal Flow, Magnetic Structure, Stagnation Point},
	pages = {113--147},
}

@incollection{childress_nearly_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics} {Monographs}},
	title = {Nearly {Integrable} {Flows}},
	isbn = {978-3-540-44778-8},
	url = {https://doi.org/10.1007/978-3-540-44778-8_8},
	abstract = {The idea of studying fast dynamo action near the onset of chaos, for a flow which is ‘close’ to being integrable, is an appealing one. If we neglect the effects of stretching and equate integrability with slow dynamo action, this puts us at the boundary of fast dynamo action, where one might hope to understand the geometry of slow and fast mechanisms. At the same time, any such study faces a basic obstacle, namely that one expects that then the fast dynamo growth rate will be small, with mean flux a small component of the total field, and therefore possibly difficult to evaluate either numerically or analytically.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Stretch, {Twist}, {Fold}: {The} {Fast} {Dynamo}},
	publisher = {Springer},
	editor = {Childress, Stephen and Gilbert, Andrew D.},
	year = {1995},
	doi = {10.1007/978-3-540-44778-8_8},
	keywords = {Dynamo Action, Melnikov Function, Stagnation Point, Unstable Manifold, Vertical Drift},
	pages = {213--244},
}

@inproceedings{zeren_spectral_2010,
	address = {Berlin, Heidelberg},
	series = {Springer {Proceedings} in {Physics}},
	title = {Spectral and {Physical} {Forcing} of {Turbulence}},
	isbn = {978-3-642-02225-8},
	doi = {10.1007/978-3-642-02225-8_2},
	abstract = {Spectral and physical forcing algorithms to generate stationary isotropic turbulence are compared in terms of characteristics of turbulence. Homogeneous isotropic turbulence is first validated with the stochastic forcing algorithm using a different shell of wavenumbers. Linear forcing algorithm is then applied to the generated stochastic field to keep the characteristics of turbulence stationary in time. Linearly forcing is very fast because there is no need to transform from a spectral to physical space. However, levels of fluctuations are very high that very long duration for simulations needed to achieve robust statistics.},
	language = {en},
	booktitle = {Progress in {Turbulence} {III}},
	publisher = {Springer},
	author = {Zeren, Zafer and Bédat, Benoît},
	editor = {Peinke, Joachim and Oberlack, Martin and Talamelli, Alessandro},
	year = {2010},
	keywords = {Direct Numerical Simulation, Flow Turbulence Combust, Isotropic Turbulence, Robust Statistic, Turbulent Kinetic Energy},
	pages = {9--12},
}

@article{mckay_comparison_2017,
	title = {Comparison of forcing functions in magnetohydrodynamic turbulence},
	volume = {2},
	issn = {2469-990X},
	url = {http://arxiv.org/abs/1704.04676},
	doi = {10.1103/PhysRevFluids.2.114604},
	abstract = {Results are presented of direct numerical simulations of incompressible, homogeneous magnetohydrodynamic turbulence without a mean magnetic field, subject to different mechanical forcing functions commonly used in the literature. Specifically, the forces are negative damping (which uses the large-scale velocity field as a forcing function), a nonhelical random force, and a nonhelical static sinusoidal force (analogous to helical ABC forcing). The time evolution of the three ideal invariants (energy, magnetic helicity and cross helicity), the time-averaged energy spectra, the energy ratios and the dissipation ratios are examined. All three forcing functions produce qualitatively similar steady states with regards to the time evolution of the energy and magnetic helicity. However, differences in the cross helicity evolution are observed, particularly in the case of the static sinusoidal method of energy injection. Indeed, an ensemble of sinusoidally-forced simulations with identical parameters shows significant variations in the cross helicity over long time periods, casting some doubt on the validity of the principle of ergodicity in systems in which the injection of helicity cannot be controlled. Cross helicity can unexpectedly enter the system through the forcing function and must be carefully monitored.},
	number = {11},
	urldate = {2022-03-09},
	journal = {Physical Review Fluids},
	author = {McKay, Mairi E. and Linkmann, Moritz and Clark, Daniel and Chalupa, Adam A. and Berera, Arjun},
	month = nov,
	year = {2017},
	note = {arXiv: 1704.04676},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Physics - Fluid Dynamics},
	pages = {114604},
}

@article{kovachki_universal_2021,
	title = {On universal approximation and error bounds for {Fourier} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2107.07562},
	abstract = {Fourier neural operators (FNOs) have recently been proposed as an effective framework for learning operators that map between infinite-dimensional spaces. We prove that FNOs are universal, in the sense that they can approximate any continuous operator to desired accuracy. Moreover, we suggest a mechanism by which FNOs can approximate operators associated with PDEs efficiently. Explicit error bounds are derived to show that the size of the FNO, approximating operators associated with a Darcy type elliptic PDE and with the incompressible Navier-Stokes equations of fluid dynamics, only increases sub (log)-linearly in terms of the reciprocal of the error. Thus, FNOs are shown to efficiently approximate operators arising in a large class of PDEs.},
	urldate = {2022-03-01},
	journal = {arXiv:2107.07562 [cs, math]},
	author = {Kovachki, Nikola and Lanthaler, Samuel and Mishra, Siddhartha},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.07562},
	keywords = {Mathematics - Numerical Analysis},
}

@article{kovachki_universal_2021-1,
	title = {On universal approximation and error bounds for {Fourier} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2107.07562},
	abstract = {Fourier neural operators (FNOs) have recently been proposed as an effective framework for learning operators that map between infinite-dimensional spaces. We prove that FNOs are universal, in the sense that they can approximate any continuous operator to desired accuracy. Moreover, we suggest a mechanism by which FNOs can approximate operators associated with PDEs efficiently. Explicit error bounds are derived to show that the size of the FNO, approximating operators associated with a Darcy type elliptic PDE and with the incompressible Navier-Stokes equations of fluid dynamics, only increases sub (log)-linearly in terms of the reciprocal of the error. Thus, FNOs are shown to efficiently approximate operators arising in a large class of PDEs.},
	urldate = {2022-03-01},
	journal = {arXiv:2107.07562 [cs, math]},
	author = {Kovachki, Nikola and Lanthaler, Samuel and Mishra, Siddhartha},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.07562},
	keywords = {Mathematics - Numerical Analysis},
}

@misc{noauthor_greens_2022,
	title = {Green's function},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Green%27s_function&oldid=1069348317},
	abstract = {In mathematics, a Green's function is the impulse response of an inhomogeneous linear differential operator defined on a domain with specified initial conditions or boundary conditions.
This means that if L is the linear differential operator, then

the Green's function G is the solution of the equation LG = δ, where δ is Dirac's delta function;
the solution of the initial-value problem Ly = f is the convolution (G ⁎ f), where G is the Green's function.Through the superposition principle, given a linear ordinary differential equation (ODE), L(solution) = source, one can first solve L(green) = δs, for each s, and realizing that, since the source is a sum of delta functions, the solution is a sum of Green's functions as well, by linearity of L.
Green's functions are named after the British mathematician George Green, who first developed the concept in the 1820s. In the modern study of linear partial differential equations, Green's functions are studied largely from the point of view of fundamental solutions instead.
Under many-body theory, the term is also used in physics, specifically in quantum field theory, aerodynamics, aeroacoustics, electrodynamics, seismology and statistical field theory, to refer to various types of correlation functions, even those that do not fit the mathematical definition. In quantum field theory, Green's functions take the roles of propagators.},
	language = {en},
	urldate = {2022-03-01},
	journal = {Wikipedia},
	month = feb,
	year = {2022},
	note = {Page Version ID: 1069348317},
}

@article{schmidt_machine-learning_2021,
	title = {Machine-learning accelerated turbulence modelling of transient flashing jets},
	volume = {33},
	issn = {1070-6631, 1089-7666},
	url = {http://arxiv.org/abs/2109.15203},
	doi = {10.1063/5.0072180},
	abstract = {Modelling the sudden depressurisation of superheated liquids through nozzles is a challenge because the pressure drop causes rapid flash boiling of the liquid. The resulting jet usually demonstrates a wide range of structures, including ligaments and droplets, due to both mechanical and thermodynamic effects. As the simulation comprises increasingly numerous phenomena, the computational cost begins to increase. One way to moderate the additional cost is to use machine learning surrogacy for specific elements of the calculations. The present study presents a machine learning-assisted computational fluid dynamics approach for simulating the atomisation of flashing liquids accounting for distinct stages, from primary atomisation to secondary break-up to small droplets using the \$\{{\textbackslash}Sigma\}\$-Y model coupled with the homogeneous relaxation model. Notably, the model for the thermodynamic non-equilibrium (HRM) and \$\{{\textbackslash}Sigma\}\$-Y are coupled, for the first time, with a deep neural network that simulates the turbulence quantities, which are then used in the prediction of superheated liquid jet atomisation. The data-driven component of the method is used for turbulence modelling, avoiding the solution of the two-equation turbulence model typically used for Reynolds-averaged Navier-Stokes simulations for these problems. Both the accuracy and speed of the hybrid approach are evaluated, demonstrating adequate accuracy and at least 25\% faster computational fluid dynamics simulations than the traditional approach. This acceleration suggests that perhaps additional components of the calculation could be replaced for even further benefit.},
	language = {en},
	number = {12},
	urldate = {2022-02-25},
	journal = {Physics of Fluids},
	author = {Schmidt, David and Maulik, Romit and Lyras, Konstantinos G.},
	month = dec,
	year = {2021},
	note = {arXiv: 2109.15203},
	keywords = {Physics - Fluid Dynamics},
	pages = {127104},
}

@article{lawson_velocity_2015,
	title = {On velocity gradient dynamics and turbulent structure},
	volume = {780},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/on-velocity-gradient-dynamics-and-turbulent-structure/9DD5AE79DE2AA2F1093052CB0EEC9003},
	doi = {10.1017/jfm.2015.452},
	abstract = {The statistics of the velocity gradient tensor 
                  
                     
                     𝘼=∇u𝘼=∇u{\textbackslash}unicode[STIX]\{x1D63C\}={\textbackslash}boldsymbol\{\{{\textbackslash}rm{\textbackslash}nabla\}\}{\textbackslash}boldsymbol\{u\}
                  
               , which embody the fine scales of turbulence, are influenced by turbulent ‘structure’. Whilst velocity gradient statistics and dynamics have been well characterised, the connection between structure and dynamics has largely focused on rotation-dominated flow and relied upon data from numerical simulation alone. Using numerical and spatially resolved experimental datasets of homogeneous turbulence, the role of structure is examined for all local (incompressible) flow topologies characterisable by 
                  
                     
                     𝘼𝘼{\textbackslash}unicode[STIX]\{x1D63C\}
                  
               . Structures are studied through the footprints they leave in conditional averages of the 
                  
                     
                     Q=−Tr(𝘼2)/2Q=−Tr(𝘼2)/2Q=-{\textbackslash}text\{Tr\}({\textbackslash}unicode[STIX]\{x1D63C\}{\textasciicircum}\{2\})/2
                  
                field, pertinent to non-local strain production, obtained using two complementary conditional averaging techniques. The first, stochastic estimation, approximates the 
                  
                     
                     QQQ
                  
                field conditioned upon 
                  
                     
                     𝘼𝘼{\textbackslash}unicode[STIX]\{x1D63C\}
                  
                and educes quantitatively similar structure in both datasets, dissimilar to that of random Gaussian velocity fields. Moreover, it strongly resembles a promising model for velocity gradient dynamics recently proposed by Wilczek \& Meneveau (J. Fluid Mech., vol. 756, 2014, pp. 191–225), but is derived under a less restrictive premise, with explicitly determined closure coefficients. The second technique examines true conditional averages of the 
                  
                     
                     QQQ
                  
                field, which is used to validate the stochastic estimation and provide insights towards the model’s refinement. Jointly, these approaches confirm that vortex tubes are the predominant feature of rotation-dominated regions and additionally show that shear layer structures are active in strain-dominated regions. In both cases, kinematic features of these structures explain alignment statistics of the pressure Hessian eigenvectors and why local and non-local strain production act in opposition to each other.},
	language = {en},
	urldate = {2022-02-24},
	journal = {Journal of Fluid Mechanics},
	author = {Lawson, J. M. and Dawson, J. R.},
	month = oct,
	year = {2015},
	note = {Publisher: Cambridge University Press},
	keywords = {homogeneous turbulence, turbulence modelling, turbulent flows},
	pages = {60--98},
}

@article{wiles_fine-grained_2021,
	title = {A {Fine}-{Grained} {Analysis} on {Distribution} {Shift}},
	url = {http://arxiv.org/abs/2110.11328},
	abstract = {Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets. Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work{\textasciitilde}{\textbackslash}citep\{Gulrajani20\}, that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts.},
	urldate = {2022-02-18},
	journal = {arXiv:2110.11328 [cs]},
	author = {Wiles, Olivia and Gowal, Sven and Stimberg, Florian and Alvise-Rebuffi, Sylvestre and Ktena, Ira and Dvijotham, Krishnamurthy and Cemgil, Taylan},
	month = nov,
	year = {2021},
	note = {arXiv: 2110.11328},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{gulrajani_search_2020,
	title = {In {Search} of {Lost} {Domain} {Generalization}},
	url = {http://arxiv.org/abs/2007.01434},
	abstract = {The goal of domain generalization algorithms is to predict well on distributions different from those seen during training. While a myriad of domain generalization algorithms exist, inconsistencies in experimental conditions -- datasets, architectures, and model selection criteria -- render fair and realistic comparisons difficult. In this paper, we are interested in understanding how useful domain generalization algorithms are in realistic settings. As a first step, we realize that model selection is non-trivial for domain generalization tasks. Contrary to prior work, we argue that domain generalization algorithms without a model selection strategy should be regarded as incomplete. Next, we implement DomainBed, a testbed for domain generalization including seven multi-domain datasets, nine baseline algorithms, and three model selection criteria. We conduct extensive experiments using DomainBed and find that, when carefully implemented, empirical risk minimization shows state-of-the-art performance across all datasets. Looking forward, we hope that the release of DomainBed, along with contributions from fellow researchers, will streamline reproducible and rigorous research in domain generalization.},
	urldate = {2022-02-18},
	journal = {arXiv:2007.01434 [cs, stat]},
	author = {Gulrajani, Ishaan and Lopez-Paz, David},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.01434},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wiles_fine-grained_2021-1,
	title = {A {Fine}-{Grained} {Analysis} on {Distribution} {Shift}},
	url = {http://arxiv.org/abs/2110.11328},
	abstract = {Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets. Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work{\textasciitilde}{\textbackslash}citep\{Gulrajani20\}, that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts.},
	urldate = {2022-02-18},
	journal = {arXiv:2110.11328 [cs]},
	author = {Wiles, Olivia and Gowal, Sven and Stimberg, Florian and Alvise-Rebuffi, Sylvestre and Ktena, Ira and Dvijotham, Krishnamurthy and Cemgil, Taylan},
	month = nov,
	year = {2021},
	note = {arXiv: 2110.11328},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{hennig_probabilistic_2015,
	title = {Probabilistic numerics and uncertainty in computations},
	volume = {471},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2015.0142},
	doi = {10.1098/rspa.2015.0142},
	abstract = {We deliver a call to arms for probabilistic numerical methods: algorithms for numerical tasks, including linear algebra, integration, optimization and solving differential equations, that return uncertainties in their calculations. Such uncertainties, arising from the loss of precision induced by numerical calculation with limited time or hardware, are important for much contemporary science and industry. Within applications such as climate science and astrophysics, the need to make decisions on the basis of computations with large and complex data have led to a renewed focus on the management of numerical uncertainty. We describe how several seminal classic numerical methods can be interpreted naturally as probabilistic inference. We then show that the probabilistic view suggests new algorithms that can flexibly be adapted to suit application specifics, while delivering improved empirical performance. We provide concrete illustrations of the benefits of probabilistic numeric algorithms on real scientific problems from astrometry and astronomical imaging, while highlighting open problems with these new algorithms. Finally, we describe how probabilistic numerical methods provide a coherent framework for identifying the uncertainty in calculations performed with a combination of numerical algorithms (e.g. both numerical optimizers and differential equation solvers), potentially allowing the diagnosis (and control) of error sources in computations.},
	number = {2179},
	urldate = {2022-02-18},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Hennig, Philipp and Osborne, Michael A. and Girolami, Mark},
	month = jul,
	year = {2015},
	note = {Publisher: Royal Society},
	keywords = {inference, numerical methods, probability, statistics},
	pages = {20150142},
}

@article{brandstetter_message_2022,
	title = {Message {Passing} {Neural} {PDE} {Solvers}},
	url = {http://arxiv.org/abs/2202.03376},
	abstract = {The numerical solution of partial differential equations (PDEs) is difficult, having led to a century of research so far. Recently, there have been pushes to build neural--numerical hybrid solvers, which piggy-backs the modern trend towards fully end-to-end learned systems. Most works so far can only generalize over a subset of properties to which a generic solver would be faced, including: resolution, topology, geometry, boundary conditions, domain discretization regularity, dimensionality, etc. In this work, we build a solver, satisfying these properties, where all the components are based on neural message passing, replacing all heuristically designed components in the computation graph with backprop-optimized neural function approximators. We show that neural message passing solvers representationally contain some classical methods, such as finite differences, finite volumes, and WENO schemes. In order to encourage stability in training autoregressive models, we put forward a method that is based on the principle of zero-stability, posing stability as a domain adaptation problem. We validate our method on various fluid-like flow problems, demonstrating fast, stable, and accurate performance across different domain topologies, discretization, etc. in 1D and 2D. Our model outperforms state-of-the-art numerical solvers in the low resolution regime in terms of speed and accuracy.},
	urldate = {2022-02-09},
	journal = {arXiv:2202.03376 [cs, math]},
	author = {Brandstetter, Johannes and Worrall, Daniel and Welling, Max},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.03376},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{kidger_neural_2022,
	title = {On {Neural} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2202.02435},
	abstract = {The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.},
	urldate = {2022-02-09},
	journal = {arXiv:2202.02435 [cs, math, stat]},
	author = {Kidger, Patrick},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.02435},
	keywords = {Computer Science - Machine Learning, Mathematics - Classical Analysis and ODEs, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{rodriguez_lyanet_2022,
	title = {{LyaNet}: {A} {Lyapunov} {Framework} for {Training} {Neural} {ODEs}},
	shorttitle = {{LyaNet}},
	url = {http://arxiv.org/abs/2202.02526},
	abstract = {We propose a method for training ordinary differential equations by using a control-theoretic Lyapunov condition for stability. Our approach, called LyaNet, is based on a novel Lyapunov loss formulation that encourages the inference dynamics to converge quickly to the correct prediction. Theoretically, we show that minimizing Lyapunov loss guarantees exponential convergence to the correct solution and enables a novel robustness guarantee. We also provide practical algorithms, including one that avoids the cost of backpropagating through a solver or using the adjoint method. Relative to standard Neural ODE training, we empirically find that LyaNet can offer improved prediction performance, faster convergence of inference dynamics, and improved adversarial robustness. Our code available at https://github.com/ivandariojr/LyapunovLearning .},
	urldate = {2022-02-08},
	journal = {arXiv:2202.02526 [cs]},
	author = {Rodriguez, Ivan Dario Jimenez and Ames, Aaron D. and Yue, Yisong},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.02526},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{kamra_high-order_2021,
	title = {High-order flux reconstruction method for the hyperbolic formulation of the incompressible {Navier}-{Stokes} equations on unstructured grids},
	url = {http://arxiv.org/abs/2106.01579},
	abstract = {A high-order Flux reconstruction implementation of the hyperbolic formulation for the incompressible Navier-Stokes equation is presented. The governing equations employ Chorin's classical artificial compressibility (AC) formulation cast in hyperbolic form. Instead of splitting the second-order conservation law into two equations, one for the solution and another for the gradient, the Navier-Stokes equation is cast into a first-order hyperbolic system of equations. Including the gradients in the AC iterative process results in a significant improvement in accuracy for the pressure, velocity, and its gradients. Furthermore, this treatment allows for taking larger time-steps since the hyperbolic formulation eliminates the restriction due to diffusion. Tests using the method of manufactured solutions show that solving the conventional form of the Navier-Stokes equation lowers the order of accuracy for gradients, while the hyperbolic method is shown to provide equal orders of accuracy for both the velocity and its gradients which may be beneficial in several applications. Two- and three-dimensional benchmark tests demonstrate the superior accuracy and computational efficiency of the developed solver in comparison to the conventional method and other published works. This study shows that the developed high-order hyperbolic solver for incompressible flows is attractive due to its accuracy, stability and efficiency in solving diffusion dominated problems.},
	urldate = {2022-02-04},
	journal = {arXiv:2106.01579 [physics]},
	author = {Kamra, Mohamed M. and Al-Salami, Jabir and Hu, Changhong},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.01579},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{tran_factorized_2021,
	title = {Factorized {Fourier} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2111.13802},
	abstract = {The Fourier Neural Operator (FNO) is a learning-based method for efficiently simulating partial differential equations. We propose the Factorized Fourier Neural Operator (F-FNO) that allows much better generalization with deeper networks. With a careful combination of the Fourier factorization, a shared kernel integral operator across all layers, the Markov property, and residual connections, F-FNOs achieve a six-fold reduction in error on the most turbulent setting of the Navier-Stokes benchmark dataset. We show that our model maintains an error rate of 2\% while still running an order of magnitude faster than a numerical solver, even when the problem setting is extended to include additional contexts such as viscosity and time-varying forces. This enables the same pretrained neural network to model vastly different conditions.},
	urldate = {2022-02-04},
	journal = {arXiv:2111.13802 [cs]},
	author = {Tran, Alasdair and Mathews, Alexander and Xie, Lexing and Ong, Cheng Soon},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.13802},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@article{shen_pdo-econvs_2020,
	title = {{PDO}-{eConvs}: {Partial} {Differential} {Operator} {Based} {Equivariant} {Convolutions}},
	shorttitle = {{PDO}-{eConvs}},
	url = {http://arxiv.org/abs/2007.10408},
	abstract = {Recent research has shown that incorporating equivariance into neural network architectures is very helpful, and there have been some works investigating the equivariance of networks under group actions. However, as digital images and feature maps are on the discrete meshgrid, corresponding equivariance-preserving transformation groups are very limited. In this work, we deal with this issue from the connection between convolutions and partial differential operators (PDOs). In theory, assuming inputs to be smooth, we transform PDOs and propose a system which is equivariant to a much more general continuous group, the \$n\$-dimension Euclidean group. In implementation, we discretize the system using the numerical schemes of PDOs, deriving approximately equivariant convolutions (PDO-eConvs). Theoretically, the approximation error of PDO-eConvs is of the quadratic order. It is the first time that the error analysis is provided when the equivariance is approximate. Extensive experiments on rotated MNIST and natural image classification show that PDO-eConvs perform competitively yet use parameters much more efficiently. Particularly, compared with Wide ResNets, our methods result in better results using only 12.6\% parameters.},
	urldate = {2022-02-04},
	journal = {arXiv:2007.10408 [cs]},
	author = {Shen, Zhengyang and He, Lingshen and Lin, Zhouchen and Ma, Jinwen},
	month = aug,
	year = {2020},
	note = {arXiv: 2007.10408},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{sharp_diffusionnet_2022,
	title = {{DiffusionNet}: {Discretization} {Agnostic} {Learning} on {Surfaces}},
	shorttitle = {{DiffusionNet}},
	url = {http://arxiv.org/abs/2012.00888},
	abstract = {We introduce a new general-purpose approach to deep learning on 3D surfaces, based on the insight that a simple diffusion layer is highly effective for spatial communication. The resulting networks are automatically robust to changes in resolution and sampling of a surface -- a basic property which is crucial for practical applications. Our networks can be discretized on various geometric representations such as triangle meshes or point clouds, and can even be trained on one representation then applied to another. We optimize the spatial support of diffusion as a continuous network parameter ranging from purely local to totally global, removing the burden of manually choosing neighborhood sizes. The only other ingredients in the method are a multi-layer perceptron applied independently at each point, and spatial gradient features to support directional filters. The resulting networks are simple, robust, and efficient. Here, we focus primarily on triangle mesh surfaces, and demonstrate state-of-the-art results for a variety of tasks including surface classification, segmentation, and non-rigid correspondence.},
	urldate = {2022-02-04},
	journal = {arXiv:2012.00888 [cs]},
	author = {Sharp, Nicholas and Attaiki, Souhaib and Crane, Keenan and Ovsjanikov, Maks},
	month = jan,
	year = {2022},
	note = {arXiv: 2012.00888},
	keywords = {Computer Science - Computational Geometry, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{tonicello_turbulence_2022,
	title = {Turbulence kinetic energy transfers in direct numerical simulation of shock-wave–turbulence interaction in a compression/expansion ramp},
	volume = {935},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/turbulence-kinetic-energy-transfers-in-direct-numerical-simulation-of-shockwaveturbulence-interaction-in-a-compressionexpansion-ramp/FB7B6EB973B011C081B08DB9ECE4C5DE},
	doi = {10.1017/jfm.2022.22},
	abstract = {, 
A direct numerical simulation is performed for a supersonic turbulent boundary layer interacting with a compression/expansion ramp at an angle α=24∘α=24∘{\textbackslash}alpha =24{\textasciicircum}\{{\textbackslash}circ \}, matching the same operating conditions of the direct numerical simulation by Priebe \& Martín (J. Fluid Mech., vol. 699, 2012, pp. 1–49). The adopted numerical method relies on the high-order spectral difference scheme coupled with a bulk-based, low-dissipative, artificial viscosity for shock-capturing purposes (Tonicello et al., Comput. Fluids, vol. 197, 2020, 104357). Filtered and averaged fields are evaluated to study total kinetic energy transfers in the presence of non-negligible compressibility effects. The compression motions are shown to promote forward transfer of kinetic energy down the energy cascade, whereas expansion regions are more likely to experience backscatter of kinetic energy. A standard decomposition of the subgrid scale tensor in deviatoric and spherical parts is proposed to study the compressible and incompressible contributions in the total kinetic energy transfers across scales. On average, the correlation between subgrid scale dissipation and large-scale dilatation is shown to be caused entirely by the spherical part of the Reynolds stresses (i.e. the turbulent kinetic energy). On the other hand, subtracting the spherical contribution, a mild correlation is still noticeable in the filtered fields. For compressible flows, it seems reasonable to assume that the eddy-viscosity approximation can be a suitable model for the deviatoric part of the subgrid scale tensor, which is exclusively causing forward kinetic energy cascade on average. Instead, more complex models are likely to be needed for the spherical part, which, even in statistical average, provides an important mechanism for backscatter.},
	language = {en},
	urldate = {2022-02-04},
	journal = {Journal of Fluid Mechanics},
	author = {Tonicello, Niccolò and Lodato, Guido and Vervisch, Luc},
	month = mar,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	keywords = {compressible boundary layers, shock waves},
}

@article{lu_beyond_2020,
	title = {Beyond {Finite} {Layer} {Neural} {Networks}: {Bridging} {Deep} {Architectures} and {Numerical} {Differential} {Equations}},
	shorttitle = {Beyond {Finite} {Layer} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1710.10121},
	abstract = {In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multi-step method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress (\${\textgreater}50\${\textbackslash}\%) the original networks while maintaining a similar performance. This can be explained mathematically using the concept of modified equation from numerical analysis. Last but not least, we also establish a connection between stochastic control and noise injection in the training process which helps to improve generalization of the networks. Furthermore, by relating stochastic training strategy with stochastic dynamic system, we can easily apply stochastic training to the networks with the LM-architecture. As an example, we introduced stochastic depth to LM-ResNet and achieve significant improvement over the original LM-ResNet on CIFAR10.},
	urldate = {2022-02-04},
	journal = {arXiv:1710.10121 [cs, stat]},
	author = {Lu, Yiping and Zhong, Aoxiao and Li, Quanzheng and Dong, Bin},
	month = mar,
	year = {2020},
	note = {arXiv: 1710.10121},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ruthotto_deep_2018,
	title = {Deep {Neural} {Networks} {Motivated} by {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1804.04272},
	abstract = {Partial differential equations (PDEs) are indispensable for modeling many physical phenomena and also commonly used for solving image processing tasks. In the latter area, PDE-based approaches interpret image data as discretizations of multivariate functions and the output of image processing algorithms as solutions to certain PDEs. Posing image processing problems in the infinite dimensional setting provides powerful tools for their analysis and solution. Over the last few decades, the reinterpretation of classical image processing problems through the PDE lens has been creating multiple celebrated approaches that benefit a vast area of tasks including image segmentation, denoising, registration, and reconstruction. In this paper, we establish a new PDE-interpretation of a class of deep convolutional neural networks (CNN) that are commonly used to learn from speech, image, and video data. Our interpretation includes convolution residual neural networks (ResNet), which are among the most promising approaches for tasks such as image classification having improved the state-of-the-art performance in prestigious benchmark challenges. Despite their recent successes, deep ResNets still face some critical challenges associated with their design, immense computational costs and memory requirements, and lack of understanding of their reasoning. Guided by well-established PDE theory, we derive three new ResNet architectures that fall into two new classes: parabolic and hyperbolic CNNs. We demonstrate how PDE theory can provide new insights and algorithms for deep learning and demonstrate the competitiveness of three new CNN architectures using numerical experiments.},
	urldate = {2022-02-04},
	journal = {arXiv:1804.04272 [cs, math, stat]},
	author = {Ruthotto, Lars and Haber, Eldad},
	month = dec,
	year = {2018},
	note = {arXiv: 1804.04272},
	keywords = {65K10, 68T45, Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@article{jenner_steerable_2021,
	title = {Steerable {Partial} {Differential} {Operators} for {Equivariant} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2106.10163},
	abstract = {Recent work in equivariant deep learning bears strong similarities to physics. Fields over a base space are fundamental entities in both subjects, as are equivariant maps between these fields. In deep learning, however, these maps are usually defined by convolutions with a kernel, whereas they are partial differential operators (PDOs) in physics. Developing the theory of equivariant PDOs in the context of deep learning could bring these subjects even closer together and lead to a stronger flow of ideas. In this work, we derive a \$G\$-steerability constraint that completely characterizes when a PDO between feature vector fields is equivariant, for arbitrary symmetry groups \$G\$. We then fully solve this constraint for several important groups. We use our solutions as equivariant drop-in replacements for convolutional layers and benchmark them in that role. Finally, we develop a framework for equivariant maps based on Schwartz distributions that unifies classical convolutions and differential operators and gives insight about the relation between the two.},
	urldate = {2022-02-04},
	journal = {arXiv:2106.10163 [cs]},
	author = {Jenner, Erik and Weiler, Maurice},
	month = oct,
	year = {2021},
	note = {arXiv: 2106.10163},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{kissas_learning_2022,
	title = {Learning {Operators} with {Coupled} {Attention}},
	url = {http://arxiv.org/abs/2201.01032},
	abstract = {Supervised operator learning is an emerging machine learning paradigm with applications to modeling the evolution of spatio-temporal dynamical systems and approximating general black-box relationships between functional data. We propose a novel operator learning method, LOCA (Learning Operators with Coupled Attention), motivated from the recent success of the attention mechanism. In our architecture, the input functions are mapped to a finite set of features which are then averaged with attention weights that depend on the output query locations. By coupling these attention weights together with an integral transform, LOCA is able to explicitly learn correlations in the target output functions, enabling us to approximate nonlinear operators even when the number of output function in the training set measurements is very small. Our formulation is accompanied by rigorous approximation theoretic guarantees on the universal expressiveness of the proposed model. Empirically, we evaluate the performance of LOCA on several operator learning scenarios involving systems governed by ordinary and partial differential equations, as well as a black-box climate prediction problem. Through these scenarios we demonstrate state of the art accuracy, robustness with respect to noisy input data, and a consistently small spread of errors over testing data sets, even for out-of-distribution prediction tasks.},
	urldate = {2022-02-01},
	journal = {arXiv:2201.01032 [physics]},
	author = {Kissas, Georgios and Seidman, Jacob and Guilhoto, Leonardo Ferreira and Preciado, Victor M. and Pappas, George J. and Perdikaris, Paris},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.01032},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{liu_investigation_2021,
	title = {Investigation of turbulent inflow specification in {Euler}–{Lagrange} simulations of mid-field spray},
	volume = {33},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/full/10.1063/5.0042900},
	doi = {10.1063/5.0042900},
	abstract = {The process of atomization of a liquid jet by a parallel high-speed gas stream results in a spray, whose downstream development is of considerable interest to several applications. The round jet spray can be spatially divided into (i) a near-field (near-nozzle) region of liquid atomization and (ii) a downstream mid-field region of fully-dispersed droplets. In order to accurately model mid-field droplet dispersion, this work aims at developing a rigorous and robust injection model for Euler–Lagrange spray simulations. Results from experiments are used to obtain the relevant droplet number density, size distribution, and mean and standard deviation velocity distributions of the injection model, systematically in a step-by-step process. Two-phase large eddy simulations are performed by stochastically generating the Lagrangian droplets at the inlet of the mid-field region. Number flux, diameter distribution, mean velocity, and other time-averaged statistics at several downstream locations are shown to agree well with the corresponding experimental data.},
	number = {3},
	urldate = {2022-02-01},
	journal = {Physics of Fluids},
	author = {Liu, K. and Huck, P. D. and Aliseda, A. and Balachandar, S.},
	month = mar,
	year = {2021},
	note = {Publisher: American Institute of Physics},
	pages = {033313},
}

@article{lakestani_numerical_2010,
	title = {Numerical solution of {Riccati} equation using the cubic {B}-spline scaling functions and {Chebyshev} cardinal functions},
	volume = {181},
	issn = {0010-4655},
	url = {https://www.sciencedirect.com/science/article/pii/S0010465510000378},
	doi = {10.1016/j.cpc.2010.01.008},
	abstract = {Two numerical techniques are presented for solving the solution of Riccati differential equation. These methods use the cubic B-spline scaling functions and Chebyshev cardinal functions. The methods consist of expanding the required approximate solution as the elements of cubic B-spline scaling function or Chebyshev cardinal functions. Using the operational matrix of derivative, we reduce the problem to a set of algebraic equations. Some numerical examples are included to demonstrate the validity and applicability of the new techniques. The methods are easy to implement and produce very accurate results.},
	language = {en},
	number = {5},
	urldate = {2022-01-27},
	journal = {Computer Physics Communications},
	author = {Lakestani, Mehrdad and Dehghan, Mehdi},
	month = may,
	year = {2010},
	keywords = {Chebyshev cardinal function, Collocation method, Cubic B-spline function, Operational matrix of derivative, Riccati equation},
	pages = {957--966},
}

@article{lakestani_numerical_2012,
	title = {Numerical solutions of the generalized {Kuramoto}–{Sivashinsky} equation using {B}-spline functions},
	volume = {36},
	issn = {0307-904X},
	url = {https://www.sciencedirect.com/science/article/pii/S0307904X11004082},
	doi = {10.1016/j.apm.2011.07.028},
	abstract = {A numerical technique based on the finite difference and collocation methods is presented for the solution of generalized Kuramoto–Sivashinsky (GKS) equation. The derivative matrices between any two families of B-spline functions are presented and are utilized to reduce the solution of GKS equation to the solution of linear algebraic equations. Numerical simulations for five test examples have been demonstrated to validate the technique proposed in the current paper. It is found that the simulating results are in good agreement with the exact solutions.},
	language = {en},
	number = {2},
	urldate = {2022-01-27},
	journal = {Applied Mathematical Modelling},
	author = {Lakestani, Mehrdad and Dehghan, Mehdi},
	month = feb,
	year = {2012},
	keywords = {B-spline function, Collocation method, Derivative matrix, Kuramoto–Sivashinsky equation},
	pages = {605--617},
}

@misc{noauthor_numerical_nodate,
	title = {Numerical solutions of the generalized {Kuramotoâ}€“{Sivashinsky} equation using {B}-spline functions {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0307904X11004082?token=A20A7D6BFDC81419E5216633C456953C234422869462BCD6629253675A21E9A85C1E7353495C4436AC82E1D2FDA17F18&originRegion=eu-west-1&originCreation=20220127121325},
	language = {en},
	urldate = {2022-01-27},
	doi = {10.1016/j.apm.2011.07.028},
}

@article{gupta_multiwavelet-based_2021,
	title = {Multiwavelet-based {Operator} {Learning} for {Differential} {Equations}},
	url = {http://arxiv.org/abs/2109.13459},
	abstract = {The solution of a partial differential equation can be obtained by computing the inverse operator map between the input and the solution space. Towards this end, we introduce a {\textbackslash}textit\{multiwavelet-based neural operator learning scheme\} that compresses the associated operator's kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, we learn the projection of the kernel onto fixed multiwavelet polynomial bases. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. Compare to the prior works, we exploit the fundamental properties of the operator's kernel which enable numerically efficient representation. We perform experiments on the Korteweg-de Vries (KdV) equation, Burgers' equation, Darcy Flow, and Navier-Stokes equation. Compared with the existing neural operator approaches, our model shows significantly higher accuracy and achieves state-of-the-art in a range of datasets. For the time-varying equations, the proposed method exhibits a (\$2X-10X\$) improvement (\$0.0018\$ (\$0.0033\$) relative \$L2\$ error for Burgers' (KdV) equation). By learning the mappings between function spaces, the proposed method has the ability to find the solution of a high-resolution input after learning from lower-resolution data.},
	urldate = {2022-01-20},
	journal = {arXiv:2109.13459 [cs, math]},
	author = {Gupta, Gaurav and Xiao, Xiongye and Bogdan, Paul},
	month = oct,
	year = {2021},
	note = {arXiv: 2109.13459},
	keywords = {Computer Science - Machine Learning, Mathematics - Analysis of PDEs},
}

@article{pestourie_physics-enhanced_2021,
	title = {Physics-enhanced deep surrogates for {PDEs}},
	url = {http://arxiv.org/abs/2111.05841},
	abstract = {We present a "physics-enhanced deep-surrogate ("PEDS") approach towards developing fast surrogate models for complex physical systems described by partial differential equations (PDEs) and similar models: we show how to combine a low-fidelity "coarse" solver with a neural network that generates "coarsified'' inputs, trained end-to-end to globally match the output of an expensive high-fidelity numerical solver. In this way, by incorporating limited physical knowledge in the form of the low-fidelity model, we find that a PEDS surrogate can be trained with at least \${\textbackslash}sim 10{\textbackslash}times\$ less data than a "black-box'' neural network for the same accuracy. Asymptotically, PEDS appears to learn with a steeper power law than black-box surrogates, and benefits even further when combined with active learning. We demonstrate feasibility and benefit of the proposed approach by using an example problem in electromagnetic scattering that appears in the design of optical metamaterials.},
	urldate = {2022-01-19},
	journal = {arXiv:2111.05841 [physics]},
	author = {Pestourie, Raphaël and Mroueh, Youssef and Rackauckas, Chris and Das, Payel and Johnson, Steven G.},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.05841},
	keywords = {Computer Science - Machine Learning, Physics - Applied Physics},
}

@article{shankar_validation_2021,
	title = {Validation and parameterization of a novel physics-constrained neural dynamics model applied to turbulent fluid flow},
	url = {http://arxiv.org/abs/2110.11528},
	abstract = {In fluid physics, data-driven models to enhance or accelerate solution methods are becoming increasingly popular for many application domains, such as alternatives to turbulence closures, system surrogates, or for new physics discovery. In the context of reduced order models of high-dimensional time-dependent fluid systems, machine learning methods grant the benefit of automated learning from data, but the burden of a model lies on its reduced-order representation of both the fluid state and physical dynamics. In this work, we build a physics-constrained, data-driven reduced order model for the Navier-Stokes equations to approximate spatio-temporal turbulent fluid dynamics. The model design choices mimic numerical and physical constraints by, for example, implicitly enforcing the incompressibility constraint and utilizing continuous Neural Ordinary Differential Equations for tracking the evolution of the differential equation. We demonstrate this technique on three-dimensional, moderate Reynolds number turbulent fluid flow. In assessing the statistical quality and characteristics of the machine-learned model through rigorous diagnostic tests, we find that our model is capable of reconstructing the dynamics of the flow over large integral timescales, favoring accuracy at the larger length scales. More significantly, comprehensive diagnostics suggest that physically-interpretable model parameters, corresponding to the representations of the fluid state and dynamics, have attributable and quantifiable impact on the quality of the model predictions and computational complexity.},
	urldate = {2022-01-19},
	journal = {arXiv:2110.11528 [physics]},
	author = {Shankar, Varun and Portwood, Gavin D. and Mohan, Arvind T. and Mitra, Peetak P. and Krishnamurthy, Dilip and Rackauckas, Christopher and Wilson, Lucas A. and Schmidt, David P. and Viswanathan, Venkatasubramanian},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.11528},
	keywords = {Physics - Fluid Dynamics},
}

@article{mourik_exploring_2018,
	title = {Exploring quantum chaos with a single nuclear spin},
	volume = {98},
	issn = {2470-0045, 2470-0053},
	url = {http://arxiv.org/abs/1703.04852},
	doi = {10.1103/PhysRevE.98.042206},
	abstract = {Most classical dynamical systems are chaotic. The trajectories of two identical systems prepared in infinitesimally different initial conditions diverge exponentially with time. Quantum systems, instead, exhibit quasi-periodicity due to their discrete spectrum. Nonetheless, the dynamics of quantum systems whose classical counterparts are chaotic are expected to show some features that resemble chaotic motion. Among the many controversial aspects of the quantum-classical boundary, the emergence of chaos remains among the least experimentally verified. Time-resolved observations of quantum chaotic dynamics are particularly rare, and as yet unachieved in a single particle, where the subtle interplay between chaos and quantum measurement could be explored at its deepest levels. We present here a realistic proposal to construct a chaotic driven top from the nuclear spin of a single donor atom in silicon, in the presence of a nuclear quadrupole interaction. This system is exquisitely measurable and controllable, and possesses extremely long intrinsic quantum coherence times, allowing for the observation of subtle dynamical behavior over extended periods. We show that signatures of chaos are expected to arise for experimentally realizable parameters of the system, allowing the study of the relation between quantum decoherence and classical chaos, and the observation of dynamical tunneling.},
	number = {4},
	urldate = {2022-01-18},
	journal = {Physical Review E},
	author = {Mourik, Vincent and Asaad, Serwan and Firgau, Hannes and Pla, Jarryd J. and Holmes, Catherine and Milburn, Gerard J. and McCallum, Jeffrey C. and Morello, Andrea},
	month = oct,
	year = {2018},
	note = {arXiv: 1703.04852},
	keywords = {Condensed Matter - Mesoscale and Nanoscale Physics, Nonlinear Sciences - Chaotic Dynamics, Quantum Physics},
	pages = {042206},
}

@article{browne_elastic_2021,
	title = {Elastic turbulence generates anomalous flow resistance in porous media},
	copyright = {Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).},
	url = {https://www.science.org/doi/abs/10.1126/sciadv.abj2619},
	doi = {10.1126/sciadv.abj2619},
	abstract = {Microscopy reveals that polymers cause chaotic flow fluctuations in a porous medium, increasing macroscopic flow resistance.},
	language = {EN},
	urldate = {2022-01-17},
	journal = {Science Advances},
	author = {Browne, Christopher A. and Datta, Sujit S.},
	month = nov,
	year = {2021},
	note = {Publisher: American Association for the Advancement of Science},
}

@article{dascoli_deep_2022,
	title = {Deep {Symbolic} {Regression} for {Recurrent} {Sequences}},
	url = {http://arxiv.org/abs/2201.04600},
	abstract = {Symbolic regression, i.e. predicting a function from the observation of its values, is well-known to be a challenging task. In this paper, we train Transformers to infer the function or recurrence relation underlying sequences of integers or floats, a typical task in human IQ tests which has hardly been tackled in the machine learning literature. We evaluate our integer model on a subset of OEIS sequences, and show that it outperforms built-in Mathematica functions for recurrence prediction. We also demonstrate that our float model is able to yield informative approximations of out-of-vocabulary functions and constants, e.g. \${\textbackslash}operatorname\{bessel0\}(x){\textbackslash}approx {\textbackslash}frac\{{\textbackslash}sin(x)+{\textbackslash}cos(x)\}\{{\textbackslash}sqrt\{{\textbackslash}pi x\}\}\$ and \$1.644934{\textbackslash}approx {\textbackslash}pi{\textasciicircum}2/6\$. An interactive demonstration of our models is provided at https://bit.ly/3niE5FS.},
	urldate = {2022-01-17},
	journal = {arXiv:2201.04600 [cs]},
	author = {d'Ascoli, Stéphane and Kamienny, Pierre-Alexandre and Lample, Guillaume and Charton, François},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.04600},
	keywords = {Computer Science - Machine Learning},
}

@article{li_chaos_2009,
	title = {Chaos in {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/0909.0910},
	abstract = {This is a survey on the recent theory of chaos in partial differential equations.},
	urldate = {2022-01-17},
	journal = {arXiv:0909.0910 [physics]},
	author = {Li, Y. Charles},
	month = sep,
	year = {2009},
	note = {arXiv: 0909.0910},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Dynamical Systems, Nonlinear Sciences - Chaotic Dynamics, Nonlinear Sciences - Exactly Solvable and Integrable Systems, Nonlinear Sciences - Pattern Formation and Solitons, Physics - Fluid Dynamics},
}

@article{hutchinson_lietransformer_2021,
	title = {{LieTransformer}: {Equivariant} self-attention for {Lie} {Groups}},
	shorttitle = {{LieTransformer}},
	url = {http://arxiv.org/abs/2012.10885},
	abstract = {Group equivariant neural networks are used as building blocks of group invariant neural networks, which have been shown to improve generalisation performance and data efficiency through principled parameter sharing. Such works have mostly focused on group equivariant convolutions, building on the result that group equivariant linear maps are necessarily convolutions. In this work, we extend the scope of the literature to self-attention, that is emerging as a prominent building block of deep learning models. We propose the LieTransformer, an architecture composed of LieSelfAttention layers that are equivariant to arbitrary Lie groups and their discrete subgroups. We demonstrate the generality of our approach by showing experimental results that are competitive to baseline methods on a wide range of tasks: shape counting on point clouds, molecular property regression and modelling particle trajectories under Hamiltonian dynamics.},
	urldate = {2022-01-17},
	journal = {arXiv:2012.10885 [cs, stat]},
	author = {Hutchinson, Michael and Lan, Charline Le and Zaidi, Sheheryar and Dupont, Emilien and Teh, Yee Whye and Kim, Hyunjik},
	month = jun,
	year = {2021},
	note = {arXiv: 2012.10885},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{fuchs_se3-transformers_2020,
	title = {{SE}(3)-{Transformers}: {3D} {Roto}-{Translation} {Equivariant} {Attention} {Networks}},
	shorttitle = {{SE}(3)-{Transformers}},
	url = {http://arxiv.org/abs/2006.10503},
	abstract = {We introduce the SE(3)-Transformer, a variant of the self-attention module for 3D point clouds and graphs, which is equivariant under continuous 3D roto-translations. Equivariance is important to ensure stable and predictable performance in the presence of nuisance transformations of the data input. A positive corollary of equivariance is increased weight-tying within the model. The SE(3)-Transformer leverages the benefits of self-attention to operate on large point clouds and graphs with varying number of points, while guaranteeing SE(3)-equivariance for robustness. We evaluate our model on a toy N-body particle simulation dataset, showcasing the robustness of the predictions under rotations of the input. We further achieve competitive performance on two real-world datasets, ScanObjectNN and QM9. In all cases, our model outperforms a strong, non-equivariant attention baseline and an equivariant model without attention.},
	urldate = {2022-01-17},
	journal = {arXiv:2006.10503 [cs, stat]},
	author = {Fuchs, Fabian B. and Worrall, Daniel E. and Fischer, Volker and Welling, Max},
	month = nov,
	year = {2020},
	note = {arXiv: 2006.10503},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{tai_equivariant_2019,
	title = {Equivariant {Transformer} {Networks}},
	url = {http://arxiv.org/abs/1901.11399},
	abstract = {How can prior knowledge on the transformation invariances of a domain be incorporated into the architecture of a neural network? We propose Equivariant Transformers (ETs), a family of differentiable image-to-image mappings that improve the robustness of models towards pre-defined continuous transformation groups. Through the use of specially-derived canonical coordinate systems, ETs incorporate functions that are equivariant by construction with respect to these transformations. We show empirically that ETs can be flexibly composed to improve model robustness towards more complicated transformation groups in several parameters. On a real-world image classification task, ETs improve the sample efficiency of ResNet classifiers, achieving relative improvements in error rate of up to 15\% in the limited data regime while increasing model parameter count by less than 1\%.},
	urldate = {2022-01-17},
	journal = {arXiv:1901.11399 [cs, stat]},
	author = {Tai, Kai Sheng and Bailis, Peter and Valiant, Gregory},
	month = may,
	year = {2019},
	note = {arXiv: 1901.11399},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{de_lara_accelerating_2022,
	title = {Accelerating high order discontinuous {Galerkin} solvers using neural networks: {1D} {Burgers}’ equation},
	volume = {235},
	issn = {0045-7930},
	shorttitle = {Accelerating high order discontinuous {Galerkin} solvers using neural networks},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793021003698},
	doi = {10.1016/j.compfluid.2021.105274},
	abstract = {High order discontinuous Galerkin methods allow accurate solutions through the use of high order polynomials inside each mesh element. Increasing the polynomial order leads to high accuracy, but increases the cost. On the one hand, high order polynomials require more restrictive time steps when using explicit temporal schemes, and on the other hand the quadrature rules lead to more costly evaluations per iteration. We propose to accelerate high order discontinuous Galerkin methods using Neural Networks. To this aim, we train a Neural Network using a high order discretisation, to extract a corrective forcing that can be applied to a low order solution with the aim of recovering high order accuracy. With this corrective forcing term, we can run a low order solution (low cost) and correct the solution to obtain high order accuracy. We provide error bounds to quantify the various errors included in the methodology (e.g. related to the discretisation or the Neural Network) . The methodology and bounds are examined for a variety of meshes, polynomial orders and viscosity values for the 1D viscous Burgers’ equation. The result show good accuracy and accelerations specially when considering high polynomial orders.},
	language = {en},
	urldate = {2022-01-17},
	journal = {Computers \& Fluids},
	author = {de Lara, Fernando Manrique and Ferrer, Esteban},
	month = mar,
	year = {2022},
	keywords = {Burgers’ equation, Deep learning, High order discontinuous Galerkin, Neural network},
	pages = {105274},
}

@misc{noauthor_accelerating_nodate,
	title = {Accelerating high order discontinuous {Galerkin} solvers using neural networks: {1D} {Burgersâ}\&\#x80;\&\#x99; equation {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Accelerating high order discontinuous {Galerkin} solvers using neural networks},
	url = {https://reader.elsevier.com/reader/sd/pii/S0045793021003698?token=D604C14E270BE3A6EAFADCEBCCC9E6500088683593C9DCAE3AD104B72023D386ED00B2B91FE8DD4B6E451CA7BFE2AEDA&originRegion=us-east-1&originCreation=20220117180841},
	language = {en},
	urldate = {2022-01-17},
	doi = {10.1016/j.compfluid.2021.105274},
}

@article{rackauckas_universal_2021,
	title = {Universal {Differential} {Equations} for {Scientific} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2001.04385},
	abstract = {In the context of science, the well-known adage "a picture is worth a thousand words" might well be "a model is worth a thousand datasets." In this manuscript we introduce the SciML software ecosystem as a tool for mixing the information of physical laws and scientific models with data-driven machine learning approaches. We describe a mathematical object, which we denote universal differential equations (UDEs), as the unifying framework connecting the ecosystem. We show how a wide variety of applications, from automatically discovering biological mechanisms to solving high-dimensional Hamilton-Jacobi-Bellman equations, can be phrased and efficiently handled through the UDE formalism and its tooling. We demonstrate the generality of the software tooling to handle stochasticity, delays, and implicit constraints. This funnels the wide variety of SciML applications into a core set of training mechanisms which are highly optimized, stabilized for stiff equations, and compatible with distributed parallelism and GPU accelerators.},
	urldate = {2022-01-17},
	journal = {arXiv:2001.04385 [cs, math, q-bio, stat]},
	author = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali and Edelman, Alan},
	month = nov,
	year = {2021},
	note = {arXiv: 2001.04385},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning},
}

@article{gelbrecht_neural_2021,
	title = {Neural partial differential equations for chaotic systems},
	volume = {23},
	issn = {1367-2630},
	url = {https://iopscience.iop.org/article/10.1088/1367-2630/abeb90},
	doi = {10.1088/1367-2630/abeb90},
	abstract = {When predicting complex systems one typically relies on differential equation which can often be incomplete, missing unknown inﬂuences or higher order effects. By augmenting the equations with artiﬁcial neural networks we can compensate these deﬁciencies. We show that this can be used to predict paradigmatic, high-dimensional chaotic partial differential equations even when only short and incomplete datasets are available. The forecast horizon for these high dimensional systems is about an order of magnitude larger than the length of the training data.},
	language = {en},
	number = {4},
	urldate = {2022-01-17},
	journal = {New Journal of Physics},
	author = {Gelbrecht, Maximilian and Boers, Niklas and Kurths, Jürgen},
	month = apr,
	year = {2021},
	pages = {043005},
}

@article{ye_towards_2021,
	title = {Towards {Understanding} the {Effectiveness} of {Attention} {Mechanism}},
	url = {http://arxiv.org/abs/2106.15067},
	abstract = {Attention Mechanism is a widely used method for improving the performance of convolutional neural networks (CNNs) on computer vision tasks. Despite its pervasiveness, we have a poor understanding of what its effectiveness stems from. It is popularly believed that its effectiveness stems from the visual attention explanation, advocating focusing on the important part of input data rather than ingesting the entire input. In this paper, we find that there is only a weak consistency between the attention weights of features and their importance. Instead, we verify the crucial role of feature map multiplication in attention mechanism and uncover a fundamental impact of feature map multiplication on the learned landscapes of CNNs: with the high order non-linearity brought by the feature map multiplication, it played a regularization role on CNNs, which made them learn smoother and more stable landscapes near real samples compared to vanilla CNNs. This smoothness and stability induce a more predictive and stable behavior in-between real samples, and make CNNs generate better. Moreover, motivated by the proposed effectiveness of feature map multiplication, we design feature map multiplication network (FMMNet) by simply replacing the feature map addition in ResNet with feature map multiplication. FMMNet outperforms ResNet on various datasets, and this indicates that feature map multiplication plays a vital role in improving the performance even without finely designed attention mechanism in existing methods.},
	urldate = {2022-01-12},
	journal = {arXiv:2106.15067 [cs]},
	author = {Ye, Xiang and He, Zihang and Wang, Heng and Li, Yong},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.15067},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{rackauckas_universal_2021-1,
	title = {Universal {Differential} {Equations} for {Scientific} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2001.04385},
	abstract = {In the context of science, the well-known adage "a picture is worth a thousand words" might well be "a model is worth a thousand datasets." In this manuscript we introduce the SciML software ecosystem as a tool for mixing the information of physical laws and scientific models with data-driven machine learning approaches. We describe a mathematical object, which we denote universal differential equations (UDEs), as the unifying framework connecting the ecosystem. We show how a wide variety of applications, from automatically discovering biological mechanisms to solving high-dimensional Hamilton-Jacobi-Bellman equations, can be phrased and efficiently handled through the UDE formalism and its tooling. We demonstrate the generality of the software tooling to handle stochasticity, delays, and implicit constraints. This funnels the wide variety of SciML applications into a core set of training mechanisms which are highly optimized, stabilized for stiff equations, and compatible with distributed parallelism and GPU accelerators.},
	urldate = {2021-12-14},
	journal = {arXiv:2001.04385 [cs, math, q-bio, stat]},
	author = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali and Edelman, Alan},
	month = nov,
	year = {2021},
	note = {arXiv: 2001.04385},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning},
}

@article{bilos_neural_2021,
	title = {Neural {Flows}: {Efficient} {Alternative} to {Neural} {ODEs}},
	shorttitle = {Neural {Flows}},
	url = {http://arxiv.org/abs/2110.13040},
	abstract = {Neural ordinary differential equations describe how values change in time. This is the reason why they gained importance in modeling sequential data, especially when the observations are made at irregular intervals. In this paper we propose an alternative by directly modeling the solution curves - the flow of an ODE - with a neural network. This immediately eliminates the need for expensive numerical solvers while still maintaining the modeling capability of neural ODEs. We propose several flow architectures suitable for different applications by establishing precise conditions on when a function defines a valid flow. Apart from computational efficiency, we also provide empirical evidence of favorable generalization performance via applications in time series modeling, forecasting, and density estimation.},
	urldate = {2021-12-09},
	journal = {arXiv:2110.13040 [cs, math]},
	author = {Biloš, Marin and Sommer, Johanna and Rangapuram, Syama Sundar and Januschowski, Tim and Günnemann, Stephan},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.13040},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{boffetta_evidence_2010,
	title = {Evidence for the double cascade scenario in two-dimensional turbulence},
	volume = {82},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.82.016307},
	doi = {10.1103/PhysRevE.82.016307},
	abstract = {Statistical features of homogeneous, isotropic, two-dimensional turbulence is discussed on the basis of a set of direct numerical simulations up to the unprecedented resolution 327682. By forcing the system at intermediate scales, narrow but clear inertial ranges develop both for the inverse and for direct cascades where the two Kolmogorov laws for structure functions are simultaneously observed. The inverse cascade spectrum is found to be consistent with Kolmogorov-Kraichnan prediction and is robust with respect the presence of an enstrophy flux. The direct cascade is found to be more sensible to finite size effects: the exponent of the spectrum has a correction with respect theoretical prediction which vanishes by increasing the resolution.},
	number = {1},
	urldate = {2021-12-06},
	journal = {Physical Review E},
	author = {Boffetta, G. and Musacchio, S.},
	month = jul,
	year = {2010},
	note = {Publisher: American Physical Society},
	pages = {016307},
}

@article{guibas_adaptive_2021,
	title = {Adaptive {Fourier} {Neural} {Operators}: {Efficient} {Token} {Mixers} for {Transformers}},
	shorttitle = {Adaptive {Fourier} {Neural} {Operators}},
	url = {http://arxiv.org/abs/2111.13587},
	abstract = {Vision transformers have delivered tremendous success in representation learning. This is primarily due to effective token mixing through self attention. However, this scales quadratically with the number of pixels, which becomes infeasible for high-resolution inputs. To cope with this challenge, we propose Adaptive Fourier Neural Operator (AFNO) as an efficient token mixer that learns to mix in the Fourier domain. AFNO is based on a principled foundation of operator learning which allows us to frame token mixing as a continuous global convolution without any dependence on the input resolution. This principle was previously used to design FNO, which solves global convolution efficiently in the Fourier domain and has shown promise in learning challenging PDEs. To handle challenges in visual representation learning such as discontinuities in images and high resolution inputs, we propose principled architectural modifications to FNO which results in memory and computational efficiency. This includes imposing a block-diagonal structure on the channel mixing weights, adaptively sharing weights across tokens, and sparsifying the frequency modes via soft-thresholding and shrinkage. The resulting model is highly parallel with a quasi-linear complexity and has linear memory in the sequence size. AFNO outperforms self-attention mechanisms for few-shot segmentation in terms of both efficiency and accuracy. For Cityscapes segmentation with the Segformer-B3 backbone, AFNO can handle a sequence size of 65k and outperforms other efficient self-attention mechanisms.},
	urldate = {2021-11-30},
	journal = {arXiv:2111.13587 [cs]},
	author = {Guibas, John and Mardani, Morteza and Li, Zongyi and Tao, Andrew and Anandkumar, Anima and Catanzaro, Bryan},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.13587},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{haywood_triple_2021,
	title = {Triple {Hill}’s {Vortex} {Synthetic} {Eddy} {Method}},
	issn = {1573-1987},
	url = {https://doi.org/10.1007/s10494-021-00289-4},
	doi = {10.1007/s10494-021-00289-4},
	abstract = {The generation of initial or inflow synthetic turbulent velocity or scalar fields reproducing statistical characteristics of realistic turbulence is still a challenge. The synthetic eddy method, previously introduced in the context of inflow conditions for large eddy simulations, is based on the assumption that turbulence can be regarded as a superposition of coherent structures. In this paper, a new type of synthetic eddy method is proposed, where the fundamental eddy is constructed by superposing three Hill’s vortices, with their axes orthogonal to each other. A distribution of Hill’s vortices is used to synthesize an anisotropic turbulent velocity field that satisfies the incompressibility condition and match a given Reynolds stress tensor. The amplitudes of the three vortices that form the fundamental eddy are calculated from known Reynolds stress profiles through a transformation from the physical reference frame to the principal-axis reference frame. In this way, divergence-free anisotropic turbulent velocity fields are obtained that can reproduce a given Reynolds stress tensor. The model was tested on both isotropic and anisotropic turbulent velocity fields, in the framework of grid turbulence decay and turbulent channel flow, respectively. The transition from artificial to realistic turbulence in the proximity to the inflow boundary was found to be small in all test cases that were considered.},
	language = {en},
	urldate = {2021-11-29},
	journal = {Flow, Turbulence and Combustion},
	author = {Haywood, John S. and Sescu, Adrian and Bhushan, Shanti and Kees, Christopher E.},
	month = aug,
	year = {2021},
}

@article{yang_transformer-based_2021,
	title = {Transformer-{Based} {Source}-{Free} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/2105.14138},
	abstract = {In this paper, we study the task of source-free domain adaptation (SFDA), where the source data are not available during target adaptation. Previous works on SFDA mainly focus on aligning the cross-domain distributions. However, they ignore the generalization ability of the pretrained source model, which largely influences the initial target outputs that are vital to the target adaptation stage. To address this, we make the interesting observation that the model accuracy is highly correlated with whether or not attention is focused on the objects in an image. To this end, we propose a generic and effective framework based on Transformer, named TransDA, for learning a generalized model for SFDA. Specifically, we apply the Transformer as the attention module and inject it into a convolutional network. By doing so, the model is encouraged to turn attention towards the object regions, which can effectively improve the model's generalization ability on the target domains. Moreover, a novel self-supervised knowledge distillation approach is proposed to adapt the Transformer with target pseudo-labels, thus further encouraging the network to focus on the object regions. Experiments on three domain adaptation tasks, including closed-set, partial-set, and open-set adaption, demonstrate that TransDA can greatly improve the adaptation accuracy and produce state-of-the-art results. The source code and trained models are available at https://github.com/ygjwd12345/TransDA.},
	urldate = {2021-11-29},
	journal = {arXiv:2105.14138 [cs]},
	author = {Yang, Guanglei and Tang, Hao and Zhong, Zhun and Ding, Mingli and Shao, Ling and Sebe, Nicu and Ricci, Elisa},
	month = may,
	year = {2021},
	note = {arXiv: 2105.14138},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{vlachas_backpropagation_2020,
	title = {Backpropagation algorithms and {Reservoir} {Computing} in {Recurrent} {Neural} {Networks} for the forecasting of complex spatiotemporal dynamics},
	volume = {126},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608020300708},
	doi = {10.1016/j.neunet.2020.02.016},
	abstract = {We examine the efficiency of Recurrent Neural Networks in forecasting the spatiotemporal dynamics of high dimensional and reduced order complex systems using Reservoir Computing (RC) and Backpropagation through time (BPTT) for gated network architectures. We highlight advantages and limitations of each method and discuss their implementation for parallel computing architectures. We quantify the relative prediction accuracy of these algorithms for the long-term forecasting of chaotic systems using as benchmarks the Lorenz-96 and the Kuramoto–Sivashinsky (KS) equations. We find that, when the full state dynamics are available for training, RC outperforms BPTT approaches in terms of predictive performance and in capturing of the long-term statistics, while at the same time requiring much less training time. However, in the case of reduced order data, large scale RC models can be unstable and more likely than the BPTT algorithms to diverge. In contrast, RNNs trained via BPTT show superior forecasting abilities and capture well the dynamics of reduced order systems. Furthermore, the present study quantifies for the first time the Lyapunov Spectrum of the KS equation with BPTT, achieving similar accuracy as RC. This study establishes that RNNs are a potent computational framework for the learning and forecasting of complex spatiotemporal systems.},
	language = {en},
	urldate = {2021-11-29},
	journal = {Neural Networks},
	author = {Vlachas, P. R. and Pathak, J. and Hunt, B. R. and Sapsis, T. P. and Girvan, M. and Ott, E. and Koumoutsakos, P.},
	month = jun,
	year = {2020},
	keywords = {Complex systems, Kuramoto–Sivashinsky, Lorenz-96, RNN, LSTM, GRU, Reservoir Computing, Time series forecasting},
	pages = {191--217},
}

@article{rovelli_forget_2009,
	title = {"{Forget} time"},
	url = {http://arxiv.org/abs/0903.3832},
	abstract = {Following a line of research that I have developed for several years, I argue that the best strategy for understanding quantum gravity is to build a picture of the physical world where the notion of time plays no role. I summarize here this point of view, explaining why I think that in a fundamental description of nature we must "forget time", and how this can be done in the classical and in the quantum theory. The idea is to develop a formalism that treats dependent and independent variables on the same footing. In short, I propose to interpret mechanics as a theory of relations between variables, rather than the theory of the evolution of variables in time.},
	urldate = {2021-11-29},
	journal = {arXiv:0903.3832 [gr-qc]},
	author = {Rovelli, Carlo},
	month = mar,
	year = {2009},
	note = {arXiv: 0903.3832},
	keywords = {General Relativity and Quantum Cosmology},
}

@article{moseley_finite_2021,
	title = {Finite {Basis} {Physics}-{Informed} {Neural} {Networks} ({FBPINNs}): a scalable domain decomposition approach for solving differential equations},
	shorttitle = {Finite {Basis} {Physics}-{Informed} {Neural} {Networks} ({FBPINNs})},
	abstract = {Numerical experiments show that FBPINNs are effective in solving both small and larger, multi-scale problems, outperforming standard PINNs in both accuracy and computational resources required, potentially paving the way to the application of PINNs on large, real-world problems. Recently, physics-informed neural networks (PINNs) have offered a powerful new paradigm for solving problems relating to differential equations. Compared to classical numerical methods PINNs have several advantages, for example their ability to provide mesh-free solutions of differential equations and their ability to carry out forward and inverse modelling within the same optimisation problem. Whilst promising, a key limitation to date is that PINNs have struggled to accurately and efficiently solve problems with large domains and/or multi-scale solutions, which is crucial for their real-world application. Multiple significant and related factors contribute to this issue, including the increasing complexity of the underlying PINN optimisation problem as the problem size grows and the spectral bias of neural networks. In this work we propose a new, scalable approach for solving large problems relating to differential equations called Finite Basis PINNs (FBPINNs). FBPINNs are inspired by classical finite element methods, where the solution of the differential equation is expressed as the sum of a finite set of basis functions with compact support. In FBPINNs neural networks are used to learn these basis functions, which are defined over small, overlapping subdomains. FBINNs are designed to address the spectral bias of neural networks by using separate input normalisation over each subdomain, and reduce the complexity of the underlying optimisation problem by using many smaller neural networks in a parallel divide-and-conquer approach. Our numerical experiments show that FBPINNs are effective in solving both small and larger, multi-scale problems, outperforming standard PINNs in both accuracy and computational resources required, potentially paving the way to the application of PINNs on large, real-world problems.},
	journal = {ArXiv},
	author = {Moseley, Benjamin and Markham, A. and Nissen‐Meyer, T.},
	year = {2021},
}

@article{lin_seamless_2021,
	title = {A seamless multiscale operator neural network for inferring bubble dynamics},
	volume = {929},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/seamless-multiscale-operator-neural-network-for-inferring-bubble-dynamics/D516AB0EF954D0FF56AD864DB2618E94},
	doi = {10.1017/jfm.2021.866},
	abstract = {, 
Modelling multiscale systems from nanoscale to macroscale requires the use of atomistic and continuum methods and, correspondingly, different computer codes. Here, we develop a seamless method based on DeepONet, which is a composite deep neural network (a branch and a trunk network) for regressing operators. In particular, we consider bubble growth dynamics, and we model tiny bubbles of initial size from 100 nm to 10 μmμm{\textbackslash}mathrm \{{\textbackslash}mu \}{\textbackslash}textrm \{m\}, modelled by the Rayleigh–Plesset equation in the continuum regime above 1 μmμm{\textbackslash}mathrm \{{\textbackslash}mu \}{\textbackslash}textrm \{m\} and the dissipative particle dynamics method for bubbles below 1 μmμm{\textbackslash}mathrm \{{\textbackslash}mu \}{\textbackslash}textrm \{m\} in the atomistic regime. After an offline training based on data from both regimes, DeepONet can make accurate predictions of bubble growth on-the-fly (within a fraction of a second) across four orders of magnitude difference in spatial scales and two orders of magnitude in temporal scales. The framework of DeepONet is general and can be used for unifying physical models of different scales in diverse multiscale applications.},
	language = {en},
	urldate = {2021-11-24},
	journal = {Journal of Fluid Mechanics},
	author = {Lin, Chensen and Maxey, Martin and Li, Zhen and Karniadakis, George Em},
	month = dec,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, machine learning},
}

@article{eivazi_physics-informed_2021,
	title = {Physics-informed neural networks for solving {Reynolds}-averaged {Navier}\${\textbackslash}unicode\{x2013\}\${Stokes} equations},
	url = {http://arxiv.org/abs/2107.10711},
	abstract = {Physics-informed neural networks (PINNs) are successful machine-learning methods for the solution and identification of partial differential equations (PDEs). We employ PINNs for solving the Reynolds-averaged Navier\${\textbackslash}unicode\{x2013\}\$Stokes (RANS) equations for incompressible turbulent flows without any specific model or assumption for turbulence, and by taking only the data on the domain boundaries. We first show the applicability of PINNs for solving the Navier\${\textbackslash}unicode\{x2013\}\$Stokes equations for laminar flows by solving the Falkner\${\textbackslash}unicode\{x2013\}\$Skan boundary layer. We then apply PINNs for the simulation of four turbulent-flow cases, i.e., zero-pressure-gradient boundary layer, adverse-pressure-gradient boundary layer, and turbulent flows over a NACA4412 airfoil and the periodic hill. Our results show the excellent applicability of PINNs for laminar flows with strong pressure gradients, where predictions with less than 1\% error can be obtained. For turbulent flows, we also obtain very good accuracy on simulation results even for the Reynolds-stress components.},
	urldate = {2021-11-24},
	journal = {arXiv:2107.10711 [physics]},
	author = {Eivazi, Hamidreza and Tahani, Mojtaba and Schlatter, Philipp and Vinuesa, Ricardo},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.10711},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{bettencourt_taylor-mode_nodate,
	title = {Taylor-{Mode} {Automatic} {Differentiation} for {Higher}-{Order} {Derivatives} in {JAX}},
	abstract = {One way to achieve higher-order automatic differentiation (AD) is to implement ﬁrst-order AD and apply it repeatedly. This nested approach works, but can result in combinatorial amounts of redundant work. This paper describes a more efﬁcient method, already known but with a new presentation, and its implementation in JAX. We also study its application to neural ordinary differential equations, and in particular discuss some additional algorithmic improvements for higher-order AD of differential equations.},
	language = {en},
	author = {Bettencourt, Jesse and Johnson, Matthew J and Duvenaud, David},
	pages = {14},
}

@article{kissas_machine_2020,
	title = {Machine learning in cardiovascular flows modeling: {Predicting} arterial blood pressure from non-invasive {4D} flow {MRI} data using physics-informed neural networks},
	volume = {358},
	issn = {00457825},
	shorttitle = {Machine learning in cardiovascular flows modeling},
	url = {http://arxiv.org/abs/1905.04817},
	doi = {10.1016/j.cma.2019.112623},
	abstract = {Advances in computational science offer a principled pipeline for predictive modeling of cardiovascular flows and aspire to provide a valuable tool for monitoring, diagnostics and surgical planning. Such models can be nowadays deployed on large patient-specific topologies of systemic arterial networks and return detailed predictions on flow patterns, wall shear stresses, and pulse wave propagation. However, their success heavily relies on tedious pre-processing and calibration procedures that typically induce a significant computational cost, thus hampering their clinical applicability. In this work we put forth a machine learning framework that enables the seamless synthesis of non-invasive in-vivo measurement techniques and computational flow dynamics models derived from first physical principles. We illustrate this new paradigm by showing how one-dimensional models of pulsatile flow can be used to constrain the output of deep neural networks such that their predictions satisfy the conservation of mass and momentum principles. Once trained on noisy and scattered clinical data of flow and wall displacement, these networks can return physically consistent predictions for velocity, pressure and wall displacement pulse wave propagation, all without the need to employ conventional simulators. A simple post-processing of these outputs can also provide a cheap and effective way for estimating Windkessel model parameters that are required for the calibration of traditional computational models. The effectiveness of the proposed techniques is demonstrated through a series of prototype benchmarks, as well as a realistic clinical case involving in-vivo measurements near the aorta/carotid bifurcation of a healthy human subject.},
	urldate = {2021-11-24},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Kissas, Georgios and Yang, Yibo and Hwuang, Eileen and Witschey, Walter R. and Detre, John A. and Perdikaris, Paris},
	month = jan,
	year = {2020},
	note = {arXiv: 1905.04817},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {112623},
}

@misc{pavlus_idea_2020,
	title = {An {Idea} {From} {Physics} {Helps} {AI} {See} in {Higher} {Dimensions}},
	url = {https://www.quantamagazine.org/an-idea-from-physics-helps-ai-see-in-higher-dimensions-20200109/},
	abstract = {The laws of physics stay the same no matter one’s perspective. Now this idea is allowing computers to detect features in curved and higher-dimensional space.},
	language = {en},
	urldate = {2021-11-24},
	journal = {Quanta Magazine},
	author = {Pavlus, John},
	month = jan,
	year = {2020},
}

@article{weiler_3d_2018,
	title = {{3D} {Steerable} {CNNs}: {Learning} {Rotationally} {Equivariant} {Features} in {Volumetric} {Data}},
	shorttitle = {{3D} {Steerable} {CNNs}},
	url = {http://arxiv.org/abs/1807.02547},
	abstract = {We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R{\textasciicircum}3. Our experimental results confirm the effectiveness of 3D Steerable CNNs for the problem of amino acid propensity prediction and protein structure classification, both of which have inherent SE(3) symmetry.},
	urldate = {2021-11-24},
	journal = {arXiv:1807.02547 [cs, stat]},
	author = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco},
	month = oct,
	year = {2018},
	note = {arXiv: 1807.02547},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{gao_physics-informed_2021,
	title = {Physics-informed graph neural {Galerkin} networks: {A} unified framework for solving {PDE}-governed forward and inverse problems},
	shorttitle = {Physics-informed graph neural {Galerkin} networks},
	url = {http://arxiv.org/abs/2107.12146},
	abstract = {Despite the great promise of the physics-informed neural networks (PINNs) in solving forward and inverse problems, several technical challenges are present as roadblocks for more complex and realistic applications. First, most existing PINNs are based on point-wise formulation with fully-connected networks to learn continuous functions, which suffer from poor scalability and hard boundary enforcement. Second, the infinite search space over-complicates the non-convex optimization for network training. Third, although the convolutional neural network (CNN)-based discrete learning can significantly improve training efficiency, CNNs struggle to handle irregular geometries with unstructured meshes. To properly address these challenges, we present a novel discrete PINN framework based on graph convolutional network (GCN) and variational structure of PDE to solve forward and inverse partial differential equations (PDEs) in a unified manner. The use of a piecewise polynomial basis can reduce the dimension of search space and facilitate training and convergence. Without the need of tuning penalty parameters in classic PINNs, the proposed method can strictly impose boundary conditions and assimilate sparse data in both forward and inverse settings. The flexibility of GCNs is leveraged for irregular geometries with unstructured meshes. The effectiveness and merit of the proposed method are demonstrated over a variety of forward and inverse computational mechanics problems governed by both linear and nonlinear PDEs.},
	urldate = {2021-11-24},
	journal = {arXiv:2107.12146 [cs]},
	author = {Gao, Han and Zahr, Matthew J. and Wang, Jian-Xun},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.12146},
	keywords = {Computer Science - Computational Engineering, Finance, and Science},
}

@article{wang_physics-guided_2021,
	title = {Physics-{Guided} {Deep} {Learning} for {Dynamical} {Systems}: {A} {Survey}},
	shorttitle = {Physics-{Guided} {Deep} {Learning} for {Dynamical} {Systems}},
	url = {http://arxiv.org/abs/2107.01272},
	abstract = {Modeling complex physical dynamics is a fundamental task in science and engineering. Traditional physics-based models are sample efficient, interpretable but often rely on rigid assumptions. Furthermore, direct numerical approximation is usually computationally intensive, requiring significant computational resources and expertise. While deep learning (DL) provides novel alternatives for efficiently recognizing complex patterns and emulating nonlinear dynamics, its predictions do not necessarily obey the governing laws of physical systems, nor do they generalize well across different systems. Thus, the study of physics-guided DL emerged and has gained great progress. Physics-guided DL aims to take the best from both physics-based modeling and state-of-the-art DL models to better solve scientific problems. In this paper, we provide a structured overview of existing methodologies of integrating prior physical knowledge or physics-based modeling into DL, with a special emphasis on learning dynamical systems. We also discuss the fundamental challenges and emerging opportunities in the area.},
	urldate = {2021-11-24},
	journal = {arXiv:2107.01272 [cs]},
	author = {Wang, Rui and Yu, Rose},
	month = sep,
	year = {2021},
	note = {arXiv: 2107.01272},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{yu_physics-guided_2021,
	address = {New York, NY, USA},
	series = {{KDD} '21},
	title = {Physics-{Guided} {AI} for {Large}-{Scale} {Spatiotemporal} {Data}},
	isbn = {978-1-4503-8332-5},
	url = {https://doi.org/10.1145/3447548.3470793},
	doi = {10.1145/3447548.3470793},
	abstract = {There is a great interest in scientific communities for harnessing the power of AI in applications ranging from climate science to quantum chemistry. The common theme in many of these applications is that the data are spatiotemporal with governing physics. Unfortunately, today's ML approaches are mostly purely data-driven, i.e., they solely rely on (labeled) data for learning statistical patterns. Collecting labeled data can be quite expensive in real-world applications. Moreover, the resulting black-box AI models are difficult to interpret for domain scientists. Many scientific applications contain valuable domain knowledge such as laws of physics or symmetry. On its own, black-box AI may ignore known physical laws, or spend tremendous training time only to re-discover them. This can lead to solutions that may violate physical principles or predictions that generalize poorly to unseen test scenarios. For example, energy conservation is well-understood in climate science but existing ML models predictions often fail to follow such a principle. Physics-guided or physics-informed AI is an emerging area spanning several disciplines to principally integrate physics in AI models and algorithms. The goal of this tutorial is to (1) provide an overview of spatiotemporal data analysis and its central role in science (2) survey development in physics-guided AI and their connection to existing techniques in scientific fields, and (3) identify the benchmark datasets, open problems and future directions in physics-guided AI and its broader impact. We believe this is a very timely and highly impactful topic. This tutorial will draw attention from the data science community to emerging applications in science. It will also bring new audiences from the scientific fields to data science. Currently, many techniques for analyzing scientific data have been developed in isolation. This tutorial aims to bridge the gap and facilitate cross-learning from different domains.},
	urldate = {2021-11-24},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Rose and Perdikaris, Paris and Karpatne, Anuj},
	month = aug,
	year = {2021},
	keywords = {ai for science, deep learning, physics-guided machine learning, spatiotemporal},
	pages = {4088--4089},
}

@inproceedings{yu_physics-guided_2021-1,
	address = {New York, NY, USA},
	series = {{KDD} '21},
	title = {Physics-{Guided} {AI} for {Large}-{Scale} {Spatiotemporal} {Data}},
	isbn = {978-1-4503-8332-5},
	url = {https://doi.org/10.1145/3447548.3470793},
	doi = {10.1145/3447548.3470793},
	abstract = {There is a great interest in scientific communities for harnessing the power of AI in applications ranging from climate science to quantum chemistry. The common theme in many of these applications is that the data are spatiotemporal with governing physics. Unfortunately, today's ML approaches are mostly purely data-driven, i.e., they solely rely on (labeled) data for learning statistical patterns. Collecting labeled data can be quite expensive in real-world applications. Moreover, the resulting black-box AI models are difficult to interpret for domain scientists. Many scientific applications contain valuable domain knowledge such as laws of physics or symmetry. On its own, black-box AI may ignore known physical laws, or spend tremendous training time only to re-discover them. This can lead to solutions that may violate physical principles or predictions that generalize poorly to unseen test scenarios. For example, energy conservation is well-understood in climate science but existing ML models predictions often fail to follow such a principle. Physics-guided or physics-informed AI is an emerging area spanning several disciplines to principally integrate physics in AI models and algorithms. The goal of this tutorial is to (1) provide an overview of spatiotemporal data analysis and its central role in science (2) survey development in physics-guided AI and their connection to existing techniques in scientific fields, and (3) identify the benchmark datasets, open problems and future directions in physics-guided AI and its broader impact. We believe this is a very timely and highly impactful topic. This tutorial will draw attention from the data science community to emerging applications in science. It will also bring new audiences from the scientific fields to data science. Currently, many techniques for analyzing scientific data have been developed in isolation. This tutorial aims to bridge the gap and facilitate cross-learning from different domains.},
	urldate = {2021-11-24},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Rose and Perdikaris, Paris and Karpatne, Anuj},
	month = aug,
	year = {2021},
	keywords = {ai for science, deep learning, physics-guided machine learning, spatiotemporal},
	pages = {4088--4089},
}

@article{cohen_equivariant_2021,
	title = {Equivariant convolutional networks},
	url = {https://dare.uva.nl/search?identifier=0f7014ae-ee94-430e-a5d8-37d03d8d10e6},
	language = {en},
	urldate = {2021-11-24},
	author = {Cohen, T. S.},
	year = {2021},
}

@article{cohen_gauge_2019,
	title = {Gauge {Equivariant} {Convolutional} {Networks} and the {Icosahedral} {CNN}},
	url = {http://arxiv.org/abs/1902.04615},
	abstract = {The principle of equivariance to symmetry transformations enables a theoretically grounded approach to neural network architecture design. Equivariant networks have shown excellent performance and data efficiency on vision and medical imaging problems that exhibit symmetries. Here we show how this principle can be extended beyond global symmetries to local gauge transformations. This enables the development of a very general class of convolutional neural networks on manifolds that depend only on the intrinsic geometry, and which includes many popular methods from equivariant and geometric deep learning. We implement gauge equivariant CNNs for signals defined on the surface of the icosahedron, which provides a reasonable approximation of the sphere. By choosing to work with this very regular manifold, we are able to implement the gauge equivariant convolution using a single conv2d call, making it a highly scalable and practical alternative to Spherical CNNs. Using this method, we demonstrate substantial improvements over previous methods on the task of segmenting omnidirectional images and global climate patterns.},
	urldate = {2021-11-24},
	journal = {arXiv:1902.04615 [cs, stat]},
	author = {Cohen, Taco S. and Weiler, Maurice and Kicanaoglu, Berkay and Welling, Max},
	month = may,
	year = {2019},
	note = {arXiv: 1902.04615},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{wang_fast_2021,
	title = {Fast {PDE}-constrained optimization via self-supervised operator learning},
	url = {http://arxiv.org/abs/2110.13297},
	abstract = {Design and optimal control problems are among the fundamental, ubiquitous tasks we face in science and engineering. In both cases, we aim to represent and optimize an unknown (black-box) function that associates a performance/outcome to a set of controllable variables through an experiment. In cases where the experimental dynamics can be described by partial differential equations (PDEs), such problems can be mathematically translated into PDE-constrained optimization tasks, which quickly become intractable as the number of control variables and the cost of experiments increases. In this work we leverage physics-informed deep operator networks (DeepONets) -- a self-supervised framework for learning the solution operator of parametric PDEs -- to build fast and differentiable surrogates for rapidly solving PDE-constrained optimization problems, even in the absence of any paired input-output training data. The effectiveness of the proposed framework will be demonstrated across different applications involving continuous functions as control or design variables, including time-dependent optimal control of heat transfer, and drag minimization of obstacles in Stokes flow. In all cases, we observe that DeepONets can minimize high-dimensional cost functionals in a matter of seconds, yielding a significant speed up compared to traditional adjoint PDE solvers that are typically costly and limited to relatively low-dimensional control/design parametrizations.},
	urldate = {2021-11-24},
	journal = {arXiv:2110.13297 [cs, math]},
	author = {Wang, Sifan and Bhouri, Mohamed Aziz and Perdikaris, Paris},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.13297},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@article{cao_choose_2021,
	title = {Choose a {Transformer}: {Fourier} or {Galerkin}},
	shorttitle = {Choose a {Transformer}},
	url = {http://arxiv.org/abs/2105.14995},
	abstract = {In this paper, we apply the self-attention from the state-of-the-art Transformer in Attention Is All You Need for the first time to a data-driven operator learning problem related to partial differential equations. An effort is put together to explain the heuristics of, and to improve the efficacy of the attention mechanism. By employing the operator approximation theory in Hilbert spaces, it is demonstrated for the first time that the softmax normalization in the scaled dot-product attention is sufficient but not necessary. Without softmax, the approximation capacity of a linearized Transformer variant can be proved to be comparable to a Petrov-Galerkin projection layer-wise, and the estimate is independent with respect to the sequence length. A new layer normalization scheme mimicking the Petrov-Galerkin projection is proposed to allow a scaling to propagate through attention layers, which helps the model achieve remarkable accuracy in operator learning tasks with unnormalized data. Finally, we present three operator learning experiments, including the viscid Burgers' equation, an interface Darcy flow, and an inverse interface coefficient identification problem. The newly proposed simple attention-based operator learner, Galerkin Transformer, shows significant improvements in both training cost and evaluation accuracy over its softmax-normalized counterparts.},
	urldate = {2021-11-23},
	journal = {arXiv:2105.14995 [cs, math]},
	author = {Cao, Shuhao},
	month = nov,
	year = {2021},
	note = {arXiv: 2105.14995},
	keywords = {68T99, 65D15, 65M99, 65N99, Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{hessel_optax_2020,
	title = {Optax: composable gradient transformation and optimisation, in {JAX}!},
	url = {http://github.com/deepmind/optax},
	author = {Hessel, Matteo and Budden, David and Viola, Fabio and Rosca, Mihaela and Sezener, Eren and Hennigan, Tom},
	year = {2020},
}

@misc{heek_flax_2020,
	title = {Flax: {A} neural network library and ecosystem for {JAX}},
	url = {http://github.com/google/flax},
	author = {Heek, Jonathan and Levskaya, Anselm and Oliver, Avital and Ritter, Marvin and Rondepierre, Bertrand and Steiner, Andreas and Zee, Marc van},
	year = {2020},
}

@misc{bradbury_jax_2018,
	title = {{JAX}: composable transformations of {Python}+{NumPy} programs},
	url = {http://github.com/google/jax},
	author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and Zhang, Qiao},
	year = {2018},
}

@misc{noauthor_jax_2021,
	title = {{JAX}: {Autograd} and {XLA}},
	copyright = {Apache-2.0},
	shorttitle = {{JAX}},
	url = {https://github.com/google/jax},
	abstract = {Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more},
	urldate = {2021-11-23},
	publisher = {Google},
	month = nov,
	year = {2021},
	note = {original-date: 2018-10-25T21:25:02Z},
	keywords = {jax},
}

@misc{noauthor_notitle_nodate,
}

@article{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	shorttitle = {{PyTorch}},
	url = {http://arxiv.org/abs/1912.01703},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
	urldate = {2021-11-23},
	journal = {arXiv:1912.01703 [cs, stat]},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.01703},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software, Statistics - Machine Learning},
}

@misc{falcon_pytorch_2019,
	title = {{PyTorch} {Lightning}},
	copyright = {Apache-2.0},
	url = {https://github.com/PyTorchLightning/pytorch-lightning},
	abstract = {The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.},
	urldate = {2021-11-23},
	author = {Falcon, William and {The PyTorch Lightning team}},
	month = mar,
	year = {2019},
	doi = {10.5281/zenodo.3828935},
}

@article{paszke_automatic_2017,
	title = {Automatic differentiation in {PyTorch}},
	url = {https://openreview.net/forum?id=BJJsrmfCZ},
	abstract = {A summary of automatic differentiation techniques employed in PyTorch library, including novelties like support for in-place modification in presence of objects aliasing the same data, performance...},
	language = {en},
	urldate = {2021-11-23},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	month = oct,
	year = {2017},
}

@article{mowlavi_optimal_2021,
	title = {Optimal control of {PDEs} using physics-informed neural networks},
	url = {http://arxiv.org/abs/2111.09880},
	abstract = {Physics-informed neural networks (PINNs) have recently become a popular method for solving forward and inverse problems governed by partial differential equations (PDEs). By incorporating the residual of the PDE into the loss function of a neural network-based surrogate model for the unknown state, PINNs can seamlessly blend measurement data with physical constraints. Here, we extend this framework to PDE-constrained optimal control problems, for which the governing PDE is fully known and the goal is to find a control variable that minimizes a desired cost objective. We provide a set of guidelines for obtaining a good optimal control solution; first by ensuring that the PDE remains well satisfied during the training process, second by assessing rigorously the quality of the computed optimal control. We then validate the performance of the PINN framework by comparing it to adjoint-based nonlinear optimal control, which performs gradient descent on the discretized control variable while satisfying the discretized PDE. This comparison is carried out on several distributed control examples based on the Laplace, Burgers, Kuramoto-Sivashinsky, and Navier-Stokes equations. Finally, we discuss the advantages and caveats of using the PINN and adjoint-based approaches for solving optimal control problems constrained by nonlinear PDEs.},
	urldate = {2021-11-23},
	journal = {arXiv:2111.09880 [physics]},
	author = {Mowlavi, Saviz and Nabi, Saleh},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.09880},
	keywords = {Mathematics - Optimization and Control, Physics - Computational Physics},
}

@article{grigsby_long-range_2021,
	title = {Long-{Range} {Transformers} for {Dynamic} {Spatiotemporal} {Forecasting}},
	url = {http://arxiv.org/abs/2109.12218},
	abstract = {Multivariate Time Series Forecasting (TSF) focuses on the prediction of future values based on historical context. In these problems, dependent variables provide additional information or early warning signs of changes in future behavior. State-of-the-art forecasting models rely on neural attention between timesteps. This allows for temporal learning but fails to consider distinct spatial relationships between variables. This paper addresses the problem by translating multivariate TSF into a novel spatiotemporal sequence formulation where each input token represents the value of a single variable at a given timestep. Long-Range Transformers can then learn interactions between space, time, and value information jointly along this extended sequence. Our method, which we call Spacetimeformer, scales to high dimensional forecasting problems dominated by Graph Neural Networks that rely on predefined variable graphs. We achieve competitive results on benchmarks from traffic forecasting to electricity demand and weather prediction while learning spatial and temporal relationships purely from data.},
	urldate = {2021-11-18},
	journal = {arXiv:2109.12218 [cs, stat]},
	author = {Grigsby, Jake and Wang, Zhe and Qi, Yanjun},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.12218},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{pestourie_physics-enhanced_2021,
	title = {Physics-enhanced deep surrogates for {PDEs}},
	url = {http://arxiv.org/abs/2111.05841},
	abstract = {We present a "physics-enhanced deep-surrogate ("PEDS") approach towards developing fast surrogate models for complex physical systems described by partial differential equations (PDEs) and similar models: we show how to combine a low-fidelity "coarse" solver with a neural network that generates "coarsified'' inputs, trained end-to-end to globally match the output of an expensive high-fidelity numerical solver. In this way, by incorporating limited physical knowledge in the form of the low-fidelity model, we find that a PEDS surrogate can be trained with at least \${\textbackslash}sim 10{\textbackslash}times\$ less data than a "black-box'' neural network for the same accuracy. Asymptotically, PEDS appears to learn with a steeper power law than black-box surrogates, and benefits even further when combined with active learning. We demonstrate feasibility and benefit of the proposed approach by using an example problem in electromagnetic scattering that appears in the design of optical metamaterials.},
	urldate = {2021-11-18},
	journal = {arXiv:2111.05841 [physics]},
	author = {Pestourie, Raphaël and Mroueh, Youssef and Rackauckas, Chris and Das, Payel and Johnson, Steven G.},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.05841},
	keywords = {Computer Science - Machine Learning, Physics - Applied Physics},
}

@article{xu_distributed_2020,
	title = {Distributed {Machine} {Learning} for {Computational} {Engineering} using {MPI}},
	url = {http://arxiv.org/abs/2011.01349},
	abstract = {We propose a framework for training neural networks that are coupled with partial differential equations (PDEs) in a parallel computing environment. Unlike most distributed computing frameworks for deep neural networks, our focus is to parallelize both numerical solvers and deep neural networks in forward and adjoint computations. Our parallel computing model views data communication as a node in the computational graph for numerical simulations. The advantage of our model is that data communication and computing are cleanly separated and thus provide better flexibility, modularity, and testability. We demonstrate using various large-scale problems that we can achieve substantial acceleration by using parallel solvers for PDEs in training deep neural networks that are coupled with PDEs.},
	urldate = {2021-11-15},
	journal = {arXiv:2011.01349 [cs, math]},
	author = {Xu, Kailai and Zhu, Weiqiang and Darve, Eric},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.01349},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Mathematics - Numerical Analysis},
}

@article{karniadakis_physics-informed_2021,
	title = {Physics-informed machine learning},
	volume = {3},
	issn = {2522-5820},
	url = {http://www.nature.com/articles/s42254-021-00314-5},
	doi = {10.1038/s42254-021-00314-5},
	abstract = {Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-d imensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-t ime domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-b ased regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-d imensional problems.},
	language = {en},
	number = {6},
	urldate = {2021-11-15},
	journal = {Nature Reviews Physics},
	author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
	month = jun,
	year = {2021},
	pages = {422--440},
}

@article{li_physics-informed_2021,
	title = {Physics-{Informed} {Neural} {Operator} for {Learning} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2111.03794},
	abstract = {Machine learning methods have recently shown promise in solving partial differential equations (PDEs). They can be classiﬁed into two broad categories: approximating the solution function and learning the solution operator. The Physics-Informed Neural Network (PINN) is an example of the former while the Fourier neural operator (FNO) is an example of the latter. Both these approaches have shortcomings. The optimization in PINN is challenging and prone to failure, especially on multi-scale dynamic systems. FNO does not suffer from this optimization issue since it carries out supervised learning on a given dataset, but obtaining such data may be too expensive or infeasible. In this work, we propose the physics-informed neural operator (PINO), where we combine the operating-learning and function-optimization frameworks. This integrated approach improves convergence rates and accuracy over both PINN and FNO models. In the operator-learning phase, PINO learns the solution operator over multiple instances of the parametric PDE family. In the test-time optimization phase, PINO optimizes the pre-trained operator ansatz for the querying instance of the PDE. Experiments show PINO outperforms previous ML methods on many popular PDE families while retaining the extraordinary speed-up of FNO compared to solvers. In particular, PINO accurately solves long temporal transient ﬂows and Kolmogorov ﬂows.},
	language = {en},
	urldate = {2021-11-15},
	journal = {arXiv:2111.03794 [cs, math]},
	author = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
	month = nov,
	year = {2021},
	note = {arXiv: 2111.03794},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{ganti_design_2020,
	title = {Design {Space} {Exploration} of {Turbulent} {Multiphase} {Flows} {Using} {Machine} {Learning}-{Based} {Surrogate} {Model}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1996-1073/13/17/4565},
	doi = {10.3390/en13174565},
	abstract = {This study focuses on establishing a surrogate model based on machine learning techniques to predict the time-averaged spatially distributed behaviors of vaporizing liquid jets in turbulent air crossflow for momentum flux ratios between 5 and 120. This surrogate model extends a previously developed Gaussian-process-based framework applicable to laminar flows to accommodate turbulent flows and demonstrates that in addition to detailed fields of primitive variables, second-order turbulence statistics can also be predicted using machine learning techniques. The framework proceeds in 3 steps\&mdash;(1) design of experiment studies to identify training points and conducting high-fidelity calculations to build the training dataset; (2) Gaussian process regression (supervised training) for the range of operating conditions under consideration for gaseous and dispersed phase quantities; and (3) error quantification of the surrogate model by comparing the machine learning predictions with the truth model for test conditions (i.e., conditions not used for training). The framework was trained using data generated by high-fidelity large eddy simulation (LES)-based calculations (also referred to as the truth model), which solves the complete set of conservation equations for mass, momentum, energy, and species in an Eulerian reference frame, coupled with a Lagrangian solver that tracks the dispersed phase. Simulations were conducted for the range of momentum flux ratios between 5 and 120 for liquid water injected into crossflowing air at a pressure of 1 atm and temperature of 600 K. Results from the machine-learned surrogate model, also called emulations, were compared with the truth model under testing conditions identified by momentum flux ratios of 7 and 40. L1 errors for time-averaged field quantities, including velocity magnitudes, pressure, temperature, vapor fraction of the evaporated liquid, and turbulent kinetic energy in the gas phase, and spray penetration and Sauter mean diameters in the dispersed phase are reported. Speedup of 65 was achieved with this emulator when compared against LES simulation of the same test conditions with errors for all quantities below 14\%, thus demonstrating the potential benefits of using machine learning techniques for design space exploration of devices that are based on turbulent multiphase fluid flows. This is the first effort of its kind in the literature that demonstrates the application of machine learning techniques on turbulent multiphase flows.},
	language = {en},
	number = {17},
	urldate = {2021-11-10},
	journal = {Energies},
	author = {Ganti, Himakar and Kamin, Manu and Khare, Prashant},
	month = jan,
	year = {2020},
	note = {Number: 17
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {gaussian processes, large eddy simulation (LES), machine learning, turbulent multiphase flows},
	pages = {4565},
}

@article{guan_fourier_nodate,
	title = {Fourier {Neural} {Operator} {Networks}: {A} {Fast} and {General} {Solver} for the {Photoacoustic} {Wave} {Equation}},
	abstract = {Simulation tools for photoacoustic wave propagation have played a key role in advancing photoacoustic imaging by providing quantitative and qualitative insights into parameters affecting image quality. Classical methods for numerically solving the photoacoustic wave equation relies on a fine discretization of space and can become computationally expensive for large computational grids. In this work, we apply Fourier Neural Operator (FNO) networks as a fast data-driven deep learning method for solving the 2D photoacoustic wave equation in a homogeneous medium. Comparisons between the FNO network and pseudospectral time domain approach demonstrated that the FNO network generated comparable simulations with small errors and was several orders of magnitude faster. Moreover, the FNO network was generalizable and can generate simulations not observed in the training data.},
	language = {en},
	author = {Guan, Steven and Hsu, Ko-Tsung and Chitnis, Parag V},
	pages = {14},
}

@article{jiang_digital_2021,
	title = {Digital {Twin} {Earth} -- {Coasts}: {Developing} a fast and physics-informed surrogate model for coastal floods via neural operators},
	shorttitle = {Digital {Twin} {Earth} -- {Coasts}},
	url = {http://arxiv.org/abs/2110.07100},
	abstract = {Developing fast and accurate surrogates for physics-based coastal and ocean models is an urgent need due to the coastal flood risk under accelerating sea level rise, and the computational expense of deterministic numerical models. For this purpose, we develop the first digital twin of Earth coastlines with new physics-informed machine learning techniques extending the state-of-art Neural Operator. As a proof-of-concept study, we built Fourier Neural Operator (FNO) surrogates on the simulations of an industry-standard flood and ocean model (NEMO). The resulting FNO surrogate accurately predicts the sea surface height in most regions while achieving upwards of 45x acceleration of NEMO. We delivered an open-source {\textbackslash}textit\{CoastalTwin\} platform in an end-to-end and modular way, to enable easy extensions to other simulations and ML-based surrogate methods. Our results and deliverable provide a promising approach to massively accelerate coastal dynamics simulators, which can enable scientists to efficiently execute many simulations for decision-making, uncertainty quantification, and other research activities.},
	urldate = {2021-11-03},
	journal = {arXiv:2110.07100 [physics]},
	author = {Jiang, Peishi and Meinert, Nis and Jordão, Helga and Weisser, Constantin and Holgate, Simon and Lavin, Alexander and Lütjens, Björn and Newman, Dava and Wainwright, Haruko and Walker, Catherine and Barnard, Patrick},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.07100},
	keywords = {Physics - Atmospheric and Oceanic Physics},
}

@article{salvi_neural_2021,
	title = {Neural {Stochastic} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2110.10249},
	abstract = {Stochastic partial differential equations (SPDEs) are the mathematical tool of choice to model complex spatio-temporal dynamics of systems subject to the influence of randomness. We introduce the Neural SPDE model providing an extension to two important classes of physics-inspired neural architectures. On the one hand, it extends all the popular neural -- ordinary, controlled, stochastic, rough -- differential equation models in that it is capable of processing incoming information even when the latter evolves in an infinite dimensional state space. On the other hand, it extends Neural Operators -- recent generalizations of neural networks modelling mappings between functional spaces -- in that it can be used to learn complex SPDE solution operators \$(u\_0,{\textbackslash}xi) {\textbackslash}mapsto u\$ depending simultaneously on an initial condition \$u\_0\$ and on a stochastic forcing term \${\textbackslash}xi\$, while remaining resolution-invariant and equation-agnostic. A Neural SPDE is constrained to respect real physical dynamics and consequently requires only a modest amount of data to train, depends on a significantly smaller amount of parameters and has better generalization properties compared to Neural Operators. Through various experiments on semilinear SPDEs with additive and multiplicative noise (including the stochastic Navier-Stokes equations) we demonstrate how Neural SPDEs can flexibly be used in a supervised learning setting as well as conditional generative models to sample solutions of SPDEs conditioned on prior knowledge, systematically achieving in both cases better performance than all alternative models.},
	urldate = {2021-11-03},
	journal = {arXiv:2110.10249 [cs]},
	author = {Salvi, Cristopher and Lemercier, Maud},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.10249},
	keywords = {Computer Science - Machine Learning},
}

@article{brandstetter_geometric_2021,
	title = {Geometric and {Physical} {Quantities} improve {E}(3) {Equivariant} {Message} {Passing}},
	url = {http://arxiv.org/abs/2110.02905},
	abstract = {Including covariant information, such as position, force, velocity or spin is important in many tasks in computational physics and chemistry. We introduce Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise equivariant graph networks, such that node and edge attributes are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. This model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions. Through the definition of steerable node attributes, the MLPs provide a new class of activation functions for general use with steerable feature fields. We discuss ours and related work through the lens of equivariant non-linear convolutions, which further allows us to pin-point the successful components of SEGNNs: non-linear message aggregation improves upon classic linear (steerable) point convolutions; steerable messages improve upon recent equivariant graph networks that send invariant messages. We demonstrate the effectiveness of our method on several tasks in computational physics and chemistry and provide extensive ablation studies.},
	urldate = {2021-10-29},
	journal = {arXiv:2110.02905 [cs, stat]},
	author = {Brandstetter, Johannes and Hesselink, Rob and van der Pol, Elise and Bekkers, Erik and Welling, Max},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.02905},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{shlomi_graph_2021,
	title = {Graph neural networks in particle physics},
	volume = {2},
	issn = {2632-2153},
	url = {https://doi.org/10.1088/2632-2153/abbf9a},
	doi = {10.1088/2632-2153/abbf9a},
	abstract = {Particle physics is a branch of science aiming at discovering the fundamental laws of matter and forces. Graph neural networks are trainable functions which operate on graphs—sets of elements and their pairwise relations—and are a central method within the broader field of geometric deep learning. They are very expressive and have demonstrated superior performance to other classical deep learning approaches in a variety of domains. The data in particle physics are often represented by sets and graphs and as such, graph neural networks offer key advantages. Here we review various applications of graph neural networks in particle physics, including different graph constructions, model architectures and learning objectives, as well as key open problems in particle physics for which graph neural networks are promising.},
	language = {en},
	number = {2},
	urldate = {2021-10-27},
	author = {Shlomi, Jonathan and Battaglia, Peter and Vlimant, Jean-Roch},
	month = jan,
	year = {2021},
	note = {Publisher: IOP Publishing},
	pages = {021001},
}

@article{lesjak_chaotic_2021,
	title = {Chaotic systems learning with hybrid echo state network/proper orthogonal decomposition based model},
	volume = {2},
	issn = {2632-6736},
	url = {https://www.cambridge.org/core/journals/data-centric-engineering/article/chaotic-systems-learning-with-hybrid-echo-state-networkproper-orthogonal-decomposition-based-model/636D2CB1BA6EC278427271CE624F29B2},
	doi = {10.1017/dce.2021.17},
	abstract = {We explore the possibility of combining a knowledge-based reduced order model (ROM) with a reservoir computing approach to learn and predict the dynamics of chaotic systems. The ROM is based on proper orthogonal decomposition (POD) with Galerkin projection to capture the essential dynamics of the chaotic system while the reservoir computing approach used is based on echo state networks (ESNs). Two different hybrid approaches are explored: one where the ESN corrects the modal coefficients of the ROM (hybrid-ESN-A) and one where the ESN uses and corrects the ROM prediction in full state space (hybrid-ESN-B). These approaches are applied on two chaotic systems: the Charney–DeVore system and the Kuramoto–Sivashinsky equation and are compared to the ROM obtained using POD/Galerkin projection and to the data-only approach based uniquely on the ESN. The hybrid-ESN-B approach is seen to provide the best prediction accuracy, outperforming the other hybrid approach, the POD/Galerkin projection ROM, and the data-only ESN, especially when using ESNs with a small number of neurons. In addition, the influence of the accuracy of the ROM on the overall prediction accuracy of the hybrid-ESN-B is assessed rigorously by considering ROMs composed of different numbers of POD modes. Further analysis on how hybrid-ESN-B blends the prediction from the ROM and the ESN to predict the evolution of the system is also provided.},
	language = {en},
	urldate = {2021-10-27},
	journal = {Data-Centric Engineering},
	author = {Lesjak, Mathias and Doan, Nguyen Anh Khoa},
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {Chaotic systems, echo state network, proper orthogonal decomposition, reservoir computing, surrogate modeling},
}

@article{siddani_rotational_2021,
	title = {Rotational and reflectional equivariant convolutional neural network for data-limited applications: {Multiphase} flow demonstration},
	volume = {33},
	issn = {1070-6631},
	shorttitle = {Rotational and reflectional equivariant convolutional neural network for data-limited applications},
	url = {https://aip.scitation.org/doi/10.1063/5.0066049},
	doi = {10.1063/5.0066049},
	abstract = {This article deals with approximating steady-state particle-resolved fluid flow around a fixed particle of interest under the influence of randomly distributed stationary particles in a dispersed multiphase setup using convolutional neural network (CNN). The considered problem involves rotational symmetry about the mean velocity (streamwise) direction. Thus, this work enforces this symmetry using SE(3)-equivariant, special Euclidean group of dimension 3, CNN architecture, which is translation and three-dimensional rotation equivariant. This study mainly explores the generalization capabilities and benefits of a SE(3)-equivariant network. Accurate synthetic flow fields for Reynolds number and particle volume fraction combinations spanning over a range of [86.22, 172.96] and [0.11, 0.45], respectively, are produced with careful application of symmetry-aware data-driven approach.},
	number = {10},
	urldate = {2021-10-27},
	journal = {Physics of Fluids},
	author = {Siddani, B. and Balachandar, S. and Fang, R.},
	month = oct,
	year = {2021},
	note = {Publisher: American Institute of Physics},
	pages = {103323},
}

@article{loshchilov_decoupled_2019,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {http://arxiv.org/abs/1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	urldate = {2021-10-27},
	journal = {arXiv:1711.05101 [cs, math]},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = jan,
	year = {2019},
	note = {arXiv: 1711.05101},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@article{chamberlain_beltrami_2021,
	title = {Beltrami {Flow} and {Neural} {Diffusion} on {Graphs}},
	url = {http://arxiv.org/abs/2110.09443},
	abstract = {We propose a novel class of graph neural networks based on the discretised Beltrami flow, a non-Euclidean diffusion PDE. In our model, node features are supplemented with positional encodings derived from the graph topology and jointly evolved by the Beltrami flow, producing simultaneously continuous feature learning and topology evolution. The resulting model generalises many popular graph neural networks and achieves state-of-the-art results on several benchmarks.},
	urldate = {2021-10-26},
	journal = {arXiv:2110.09443 [cs, stat]},
	author = {Chamberlain, Benjamin Paul and Rowbottom, James and Eynard, Davide and Di Giovanni, Francesco and Dong, Xiaowen and Bronstein, Michael M.},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.09443},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wang_improved_2021,
	title = {Improved architectures and training algorithms for deep operator networks},
	url = {http://arxiv.org/abs/2110.01654},
	abstract = {Operator learning techniques have recently emerged as a powerful tool for learning maps between infinite-dimensional Banach spaces. Trained under appropriate constraints, they can also be effective in learning the solution operator of partial differential equations (PDEs) in an entirely self-supervised manner. In this work we analyze the training dynamics of deep operator networks (DeepONets) through the lens of Neural Tangent Kernel (NTK) theory, and reveal a bias that favors the approximation of functions with larger magnitudes. To correct this bias we propose to adaptively re-weight the importance of each training example, and demonstrate how this procedure can effectively balance the magnitude of back-propagated gradients during training via gradient descent. We also propose a novel network architecture that is more resilient to vanishing gradient pathologies. Taken together, our developments provide new insights into the training of DeepONets and consistently improve their predictive accuracy by a factor of 10-50x, demonstrated in the challenging setting of learning PDE solution operators in the absence of paired input-output observations. All code and data accompanying this manuscript are publicly available at {\textbackslash}url\{https://github.com/PredictiveIntelligenceLab/ImprovedDeepONets.\}},
	urldate = {2021-10-20},
	journal = {arXiv:2110.01654 [physics, stat]},
	author = {Wang, Sifan and Wang, Hanwen and Perdikaris, Paris},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.01654},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{liu_learning-based_2021,
	title = {A learning-based multiscale method and its application to inelastic impact problems},
	url = {http://arxiv.org/abs/2102.07256},
	abstract = {The macroscopic properties of materials that we observe and exploit in engineering application result from complex interactions between physics at multiple length and time scales: electronic, atomistic, defects, domains etc. Multiscale modeling seeks to understand these interactions by exploiting the inherent hierarchy where the behavior at a coarser scale regulates and averages the behavior at a finer scale. This requires the repeated solution of computationally expensive finer-scale models, and often a priori knowledge of those aspects of the finer-scale behavior that affect the coarser scale (order parameters, state variables, descriptors, etc.). We address this challenge in a two-scale setting where we learn the fine-scale behavior from off-line calculations and then use the learnt behavior directly in coarse scale calculations. The approach draws from recent successes of deep neural networks, in combination with ideas from model reduction. The approach builds on the recent success of deep neural networks by combining their approximation power in high dimensions with ideas from model reduction. It results in a neural network approximation that has high fidelity, is computationally inexpensive, is independent of the need for a priori knowledge, and can be used directly in the coarse scale calculations. We demonstrate the approach on problems involving the impact of magnesium, a promising light-weight structural and protective material.},
	urldate = {2021-10-20},
	journal = {arXiv:2102.07256 [cond-mat]},
	author = {Liu, Burigede and Kovachki, Nikola and Li, Zongyi and Azizzadenesheli, Kamyar and Anandkumar, Anima and Stuart, Andrew and Bhattacharya, Kaushik},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.07256},
	keywords = {Condensed Matter - Materials Science},
}

@article{yang_seismic_2021,
	title = {Seismic wave propagation and inversion with {Neural} {Operators}},
	url = {http://arxiv.org/abs/2108.05421},
	abstract = {Seismic wave propagation forms the basis for most aspects of seismological research, yet solving the wave equation is a major computational burden that inhibits the progress of research. This is exacerbated by the fact that new simulations must be performed when the velocity structure or source location is perturbed. Here, we explore a prototype framework for learning general solutions using a recently developed machine learning paradigm called Neural Operator. A trained Neural Operator can compute a solution in negligible time for any velocity structure or source location. We develop a scheme to train Neural Operators on an ensemble of simulations performed with random velocity models and source locations. As Neural Operators are grid-free, it is possible to evaluate solutions on higher resolution velocity models than trained on, providing additional computational efficiency. We illustrate the method with the 2D acoustic wave equation and demonstrate the method's applicability to seismic tomography, using reverse mode automatic differentiation to compute gradients of the wavefield with respect to the velocity structure. The developed procedure is nearly an order of magnitude faster than using conventional numerical methods for full waveform inversion.},
	urldate = {2021-10-20},
	journal = {arXiv:2108.05421 [physics]},
	author = {Yang, Yan and Gao, Angela F. and Castellanos, Jorge C. and Ross, Zachary E. and Azizzadenesheli, Kamyar and Clayton, Robert W.},
	month = oct,
	year = {2021},
	note = {arXiv: 2108.05421},
	keywords = {Computer Science - Machine Learning, Physics - Geophysics},
}

@inproceedings{dhamankar_overview_2015,
	address = {Dallas, TX},
	title = {An {Overview} of {Turbulent} {Inflow} {Boundary} {Conditions} for {Large} {Eddy} {Simulations} ({Invited})},
	isbn = {978-1-62410-366-7},
	url = {https://arc.aiaa.org/doi/10.2514/6.2015-3213},
	doi = {10.2514/6.2015-3213},
	language = {en},
	urldate = {2021-10-18},
	booktitle = {22nd {AIAA} {Computational} {Fluid} {Dynamics} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Dhamankar, Nitin S. and Blaisdell, Gregory A. and Lyrintzis, Anastasios S.},
	month = jun,
	year = {2015},
}

@article{dietzel_evaluation_2014,
	title = {Evaluation of scale resolving turbulence generation methods for {Large} {Eddy} {Simulation} of turbulent flows},
	volume = {93},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793014000206},
	doi = {10.1016/j.compfluid.2014.01.013},
	abstract = {Large Eddy Simulation (LES) has become an attractive simulation method even for technical processes and it usually provides space and time resolved fluctuations of a significant portion of the spectrum. However, in contrast to a RANS simulation an accurate LES requires the definition of suitable initial and boundary conditions, which includes turbulent structures with physically sound spatial and temporal correlations. Such turbulent structures are usually generated artificially at the boundary. Three different algorithms for generating turbulent fluctuations are evaluated in the present work. The investigated methods are Filtered noise [1], Diffused noise [2] and an Inverse Fourier approach [3], [4]. These techniques were developed for generating inflow data for LES and have already been used in published research [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], e.g. for investigating turbulent combustion processes. In the present work the turbulent statistics i.e. energy spectra and velocity correlations as well as derived quantities such as turbulent kinetic energy and subgrid scale viscosity are investigated in more detail in a comparative fashion for the generated turbulent velocity fields. As a simple test case, the decay of turbulence in a cubical box, is considered here to provide information on the initially generated turbulence as well as its temporal evolution. The results are analyzed in detail and are compared to experimental data. Turbulence fluctuations generated by Filtered noise and Diffused noise lead to similar results. The resulting energy spectra and velocity correlations agree generally well with experimental data despite some discrepancies at very early times after initialization. The Inverse Fourier approach yielded good agreement at all times, but at increased computational cost. In addition, the implementation of Filtered noise and Diffused noise might be easier for most cases of practical interest. In particular, the Diffused noise approach can be used for the generation of inhomogeneous turbulence on arbitrary grids.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Computers \& Fluids},
	author = {Dietzel, Dirk and Messig, Danny and Piscaglia, Federico and Montorfano, Andrea and Olenik, Gregor and Stein, Oliver T. and Kronenburg, Andreas and Onorati, Angelo and Hasse, Christian},
	month = apr,
	year = {2014},
	keywords = {Inlet boundary, LES, Turbulence generation, Turbulent boundary condition},
	pages = {116--128},
}

@article{patel_physics-informed_2021,
	title = {A physics-informed operator regression framework for extracting data-driven continuum models},
	volume = {373},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S004578252030685X},
	doi = {10.1016/j.cma.2020.113500},
	abstract = {The application of deep learning toward discovery of data-driven models requires careful application of inductive biases to obtain a description of physics which is both accurate and robust. We present here a framework for discovering continuum models from high fidelity molecular simulation data. Our approach applies a neural network parameterization of governing physics in modal space, allowing a characterization of differential operators while providing structure which may be used to impose biases related to symmetry, isotropy, and conservation form. We demonstrate the effectiveness of our framework for a variety of physics, including local and nonlocal diffusion processes and single and multiphase flows. For the flow physics we demonstrate this approach leads to a learned operator that generalizes to system characteristics not included in the training sets, such as variable particle sizes, densities, and concentration.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Patel, Ravi G. and Trask, Nathaniel A. and Wood, Mitchell A. and Cyr, Eric C.},
	month = jan,
	year = {2021},
	keywords = {Continuum scale modeling, Operator regression, Physics-informed machine learning, Spectral methods},
	pages = {113500},
}

@article{pathak_using_2020,
	title = {Using {Machine} {Learning} to {Augment} {Coarse}-{Grid} {Computational} {Fluid} {Dynamics} {Simulations}},
	url = {http://arxiv.org/abs/2010.00072},
	abstract = {Simulation of turbulent flows at high Reynolds number is a computationally challenging task relevant to a large number of engineering and scientific applications in diverse fields such as climate science, aerodynamics, and combustion. Turbulent flows are typically modeled by the Navier-Stokes equations. Direct Numerical Simulation (DNS) of the Navier-Stokes equations with sufficient numerical resolution to capture all the relevant scales of the turbulent motions can be prohibitively expensive. Simulation at lower-resolution on a coarse-grid introduces significant errors. We introduce a machine learning (ML) technique based on a deep neural network architecture that corrects the numerical errors induced by a coarse-grid simulation of turbulent flows at high-Reynolds numbers, while simultaneously recovering an estimate of the high-resolution fields. Our proposed simulation strategy is a hybrid ML-PDE solver that is capable of obtaining a meaningful high-resolution solution trajectory while solving the system PDE at a lower resolution. The approach has the potential to dramatically reduce the expense of turbulent flow simulations. As a proof-of-concept, we demonstrate our ML-PDE strategy on a two-dimensional turbulent (Rayleigh Number \$Ra=10{\textasciicircum}9\$) Rayleigh-B{\textbackslash}'enard Convection (RBC) problem.},
	urldate = {2021-10-18},
	journal = {arXiv:2010.00072 [physics]},
	author = {Pathak, Jaideep and Mustafa, Mustafa and Kashinath, Karthik and Motheau, Emmanuel and Kurth, Thorsten and Day, Marcus},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.00072},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Geophysics},
}

@article{lu_deepxde_2021,
	title = {{DeepXDE}: {A} {Deep} {Learning} {Library} for {Solving} {Differential} {Equations}},
	volume = {63},
	issn = {0036-1445},
	shorttitle = {{DeepXDE}},
	url = {https://epubs.siam.org/doi/10.1137/19M1274067},
	doi = {10.1137/19M1274067},
	abstract = {Deep learning has achieved remarkable success in diverse applications; however, its use in solving partial differential equations (PDEs) has emerged only recently. Here, we present an overview of physics-informed neural networks (PINNs), which embed a PDE into the loss of the neural network using automatic differentiation. The PINN algorithm is simple, and it can be applied to different types of PDEs, including integro-differential equations, fractional PDEs, and stochastic PDEs. Moreover, from an implementation point of view, PINNs solve inverse problems as easily as forward problems. We propose a new residual-based adaptive refinement (RAR) method to improve the training efficiency of PINNs. For pedagogical reasons, we compare the PINN algorithm to a standard finite element method. We also present a Python library for PINNs, DeepXDE, which is designed to serve both as an educational tool to be used in the classroom as well as a research tool for solving problems in computational science and engineering. Specifically, DeepXDE can solve forward problems given initial and boundary conditions, as well as inverse problems given some extra measurements. DeepXDE supports complex-geometry domains based on the technique of constructive solid geometry and enables the user code to be compact, resembling closely the mathematical formulation. We introduce the usage of DeepXDE and its customizability, and we also demonstrate the capability of PINNs and the user-friendliness of DeepXDE for five different examples. More broadly, DeepXDE contributes to the more rapid development of the emerging scientific machine learning field.},
	number = {1},
	urldate = {2021-10-15},
	journal = {SIAM Review},
	author = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
	month = jan,
	year = {2021},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {65-01, 65-04, 65L99, 65M99, 65N99, DeepXDE, deep learning, differential equations, education software, physics-informed neural networks, scientific machine learning},
	pages = {208--228},
}

@article{taira_network_2016,
	title = {Network structure of two-dimensional decaying isotropic turbulence},
	volume = {795},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/network-structure-of-twodimensional-decaying-isotropic-turbulence/A67D2A9E063DEFB2C86C7DC4C5895D1B},
	doi = {10.1017/jfm.2016.235},
	abstract = {The present paper reports on our effort to characterize vortical interactions in complex fluid flows through the use of network analysis. In particular, we examine the vortex interactions in two-dimensional decaying isotropic turbulence and find that the vortical-interaction network can be characterized by a weighted scale-free network. It is found that the turbulent flow network retains its scale-free behaviour until the characteristic value of circulation reaches a critical value. Furthermore, we show that the two-dimensional turbulence network is resilient against random perturbations, but can be greatly influenced when forcing is focused towards the vortical structures, which are categorized as network hubs. These findings can serve as a network-analytic foundation to examine complex geophysical and thin-film flows and take advantage of the rapidly growing field of network theory, which complements ongoing turbulence research based on vortex dynamics, hydrodynamic stability, and statistics. While additional work is essential to extend the mathematical tools from network analysis to extract deeper physical insights of turbulence, an understanding of turbulence based on the interaction-based network-theoretic framework presents a promising alternative in turbulence modelling and control efforts.},
	language = {en},
	urldate = {2021-10-13},
	journal = {Journal of Fluid Mechanics},
	author = {Taira, Kunihiko and Nair, Aditya G. and Brunton, Steven L.},
	month = may,
	year = {2016},
	note = {Publisher: Cambridge University Press},
	keywords = {isotropic turbulence, mathematical foundations, vortex interactions},
}

@article{taira_modal_2020,
	title = {Modal {Analysis} of {Fluid} {Flows}: {Applications} and {Outlook}},
	volume = {58},
	issn = {0001-1452},
	shorttitle = {Modal {Analysis} of {Fluid} {Flows}},
	url = {https://arc.aiaa.org/doi/10.2514/1.J058462},
	doi = {10.2514/1.J058462},
	number = {3},
	urldate = {2021-10-13},
	journal = {AIAA Journal},
	author = {Taira, Kunihiko and Hemati, Maziar S. and Brunton, Steven L. and Sun, Yiyang and Duraisamy, Karthik and Bagheri, Shervin and Dawson, Scott T. M. and Yeh, Chi-An},
	month = mar,
	year = {2020},
	note = {Publisher: American Institute of Aeronautics and Astronautics},
	keywords = {Boundary Layer Thickness, Direct Numerical Simulation, Feedforward Neural Network, Freestream Mach Number, Karman Vortex Street, Kelvin Helmholtz Instability, Machine Learning, Modal Analysis, Model Predictive Control, Wall Bounded Turbulent Flows},
	pages = {998--1022},
}

@article{vinuesa_potential_2021,
	title = {The {Potential} of {Machine} {Learning} to {Enhance} {Computational} {Fluid} {Dynamics}},
	url = {http://arxiv.org/abs/2110.02085},
	abstract = {Machine learning is rapidly becoming a core technology for scientific computing, with numerous opportunities to advance the field of computational fluid dynamics. This paper highlights some of the areas of highest potential impact, including to accelerate direct numerical simulations, to improve turbulence closure modelling, and to develop enhanced reduced-order models. In each of these areas, it is possible to improve machine learning capabilities by incorporating physics into the process, and in turn, to improve the simulation of fluids to uncover new physical understanding. Despite the promise of machine learning described here, we also note that classical methods are often more efficient for many tasks. We also emphasize that in order to harness the full potential of machine learning to improve computational fluid dynamics, it is essential for the community to continue to establish benchmark systems and best practices for open-source software, data sharing, and reproducible research.},
	urldate = {2021-10-13},
	journal = {arXiv:2110.02085 [physics]},
	author = {Vinuesa, Ricardo and Brunton, Steven L.},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.02085},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{gilpin_chaos_2021,
	title = {Chaos as an interpretable benchmark for forecasting and data-driven modelling},
	url = {http://arxiv.org/abs/2110.05266},
	abstract = {The striking fractal geometry of strange attractors underscores the generative nature of chaos: like probability distributions, chaotic systems can be repeatedly measured to produce arbitrarily-detailed information about the underlying attractor. Chaotic systems thus pose a unique challenge to modern statistical learning techniques, while retaining quantifiable mathematical properties that make them controllable and interpretable as benchmarks. Here, we present a growing database currently comprising 131 known chaotic dynamical systems spanning fields such as astrophysics, climatology, and biochemistry. Each system is paired with precomputed multivariate and univariate time series. Our dataset has comparable scale to existing static time series databases; however, our systems can be re-integrated to produce additional datasets of arbitrary length and granularity. Our dataset is annotated with known mathematical properties of each system, and we perform feature analysis to broadly categorize the diverse dynamics present across the collection. Chaotic systems inherently challenge forecasting models, and across extensive benchmarks we correlate forecasting performance with the degree of chaos present. We also exploit the unique generative properties of our dataset in several proof-of-concept experiments: surrogate transfer learning to improve time series classification, importance sampling to accelerate model training, and benchmarking symbolic regression algorithms.},
	urldate = {2021-10-13},
	journal = {arXiv:2110.05266 [nlin]},
	author = {Gilpin, William},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.05266},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Nonlinear Sciences - Chaotic Dynamics},
}

@article{stolz_approximate_2001,
	title = {An approximate deconvolution model for large-eddy simulation with application to incompressible wall-bounded flows},
	volume = {13},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.1350896},
	doi = {10.1063/1.1350896},
	number = {4},
	urldate = {2021-10-05},
	journal = {Physics of Fluids},
	author = {Stolz, S. and Adams, N. A. and Kleiser, L.},
	month = apr,
	year = {2001},
	note = {Publisher: American Institute of Physics},
	pages = {997--1015},
}

@article{jenny_modeling_2012,
	title = {Modeling of turbulent dilute spray combustion},
	volume = {38},
	issn = {0360-1285},
	url = {https://www.sciencedirect.com/science/article/pii/S0360128512000445},
	doi = {10.1016/j.pecs.2012.07.001},
	abstract = {In a real turbulent spray flame, dispersion, continuous phase turbulence modification, dispersed phase inter-particle collisions, evaporation, mixing and combustion occur simultaneously. Dealing with all these complexities and their interactions poses a tremendous modeling task. Therefore, in order to advance current modeling capabilities, it seems reasonable to aim for progress in individual sub-areas like breakup, dispersion, mixing and combustion, which however cannot be viewed in complete isolation. Further, one has to consider advantages and disadvantages of the general modeling approaches, which are direct numerical simulation (DNS), large eddy simulation (LES), simulations based on Reynolds averaged equations and probability density function (PDF) methods. Not least one also has to distinguish between Eulerian and Lagrangian dispersed phase descriptions. The goal of this paper is to provide a review of computational model developments relevant for turbulent dilute spray combustion, i.e. the dense regime, including collisions as well as primary and secondary atomization, is not covered. Also not considered is breakup in dilute sprays, which can occur in the presence of sufficiently high local turbulence. It is intended to guide readers interested in theory, in the development and validation of predictive models, and in planning new experiments. In terms of physical phenomena, the current understanding regarding turbulence modification due to droplets, preferential droplet concentration, impact on evaporation and micro-mixing, and different spray combustion regimes is summarized. In terms of modeling, different sets of equations are discussed, i.e. the governing conservation laws without and with point droplet approximation as employed by DNS, the filtered equations considered in LES, the Reynolds averaged equations, and Lagrangian evolution equations. Further, small scale models required in the context of point droplet approximations are covered. In terms of computational studies and method developments, progress is categorized by the employed approaches, i.e. DNS, LES, simulations based on Reynolds averaged equations, and PDF methods. In terms of experiments, various canonical spray flame configurations are discussed. Moreover, some of the most important experiments in this field are presented in a structured way with the intention to provide a database for model validation and a guideline for future investigations.},
	language = {en},
	number = {6},
	urldate = {2021-10-04},
	journal = {Progress in Energy and Combustion Science},
	author = {Jenny, Patrick and Roekaerts, Dirk and Beishuizen, Nijso},
	month = dec,
	year = {2012},
	keywords = {Combustion, Dilute spray, Direct numerical simulation, Dispersed multi-phase flow, Large eddy simulation, Probability density function, Turbulence modeling},
	pages = {846--887},
}

@misc{noauthor_modeling_nodate,
	title = {Modeling of turbulent dilute spray combustion {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0360128512000445?token=C50FE960A7F93F3BAD9EA9CE8FD8915C2360699134CDC12541D1E648AA333E6E6A8DD587C8BB1443A3E6CD79DD8708A5&originRegion=eu-west-1&originCreation=20211004155717},
	language = {en},
	urldate = {2021-10-04},
	doi = {10.1016/j.pecs.2012.07.001},
}

@article{kohler_smooth_2021,
	title = {Smooth {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2110.00351},
	abstract = {Normalizing flows are a promising tool for modeling probability distributions in physical systems. While state-of-the-art flows accurately approximate distributions and energies, applications in physics additionally require smooth energies to compute forces and higher-order derivatives. Furthermore, such densities are often defined on non-trivial topologies. A recent example are Boltzmann Generators for generating 3D-structures of peptides and small proteins. These generative models leverage the space of internal coordinates (dihedrals, angles, and bonds), which is a product of hypertori and compact intervals. In this work, we introduce a class of smooth mixture transformations working on both compact intervals and hypertori. Mixture transformations employ root-finding methods to invert them in practice, which has so far prevented bi-directional flow training. To this end, we show that parameter gradients and forces of such inverses can be computed from forward evaluations via the inverse function theorem. We demonstrate two advantages of such smooth flows: they allow training by force matching to simulation data and can be used as potentials in molecular dynamics simulations.},
	urldate = {2021-10-04},
	journal = {arXiv:2110.00351 [physics, stat]},
	author = {Köhler, Jonas and Krämer, Andreas and Noé, Frank},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.00351},
	keywords = {Computer Science - Machine Learning, Physics - Chemical Physics, Statistics - Machine Learning},
}

@article{yu_long-term_2019,
	title = {Long-term {Forecasting} using {Higher} {Order} {Tensor} {RNNs}},
	url = {http://arxiv.org/abs/1711.00073},
	abstract = {We present Higher-Order Tensor RNN (HOT-RNN), a novel family of neural sequence architectures for multivariate forecasting in environments with nonlinear dynamics. Long-term forecasting in such systems is highly challenging, since there exist long-term temporal dependencies, higher-order correlations and sensitivity to error propagation. Our proposed recurrent architecture addresses these issues by learning the nonlinear dynamics directly using higher-order moments and higher-order state transition functions. Furthermore, we decompose the higher-order structure using the tensor-train decomposition to reduce the number of parameters while preserving the model performance. We theoretically establish the approximation guarantees and the variance bound for HOT-RNN for general sequence inputs. We also demonstrate 5\% {\textasciitilde} 12\% improvements for long-term prediction over general RNN and LSTM architectures on a range of simulated environments with nonlinear dynamics, as well on real-world time series data.},
	urldate = {2021-10-01},
	journal = {arXiv:1711.00073 [cs]},
	author = {Yu, Rose and Zheng, Stephan and Anandkumar, Anima and Yue, Yisong},
	month = aug,
	year = {2019},
	note = {arXiv: 1711.00073},
	keywords = {Computer Science - Machine Learning},
}

@article{soltani_higher_2016,
	title = {Higher {Order} {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1605.00064},
	abstract = {In this paper, we study novel neural network structures to better model long term dependency in sequential data. We propose to use more memory units to keep track of more preceding states in recurrent neural networks (RNNs), which are all recurrently fed to the hidden layers as feedback through different weighted paths. By extending the popular recurrent structure in RNNs, we provide the models with better short-term memory mechanism to learn long term dependency in sequences. Analogous to digital filters in signal processing, we call these structures as higher order RNNs (HORNNs). Similar to RNNs, HORNNs can also be learned using the back-propagation through time method. HORNNs are generally applicable to a variety of sequence modelling tasks. In this work, we have examined HORNNs for the language modeling task using two popular data sets, namely the Penn Treebank (PTB) and English text8 data sets. Experimental results have shown that the proposed HORNNs yield the state-of-the-art performance on both data sets, significantly outperforming the regular RNNs as well as the popular LSTMs.},
	urldate = {2021-10-01},
	journal = {arXiv:1605.00064 [cs]},
	author = {Soltani, Rohollah and Jiang, Hui},
	month = apr,
	year = {2016},
	note = {arXiv: 1605.00064},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{rezende_normalizing_2020,
	title = {Normalizing {Flows} on {Tori} and {Spheres}},
	url = {http://arxiv.org/abs/2002.02428},
	abstract = {Normalizing ﬂows are a powerful tool for building expressive distributions in high dimensions. So far, most of the literature has concentrated on learning ﬂows on Euclidean spaces. Some problems however, such as those involving angles, are deﬁned on spaces with more complex geometries, such as tori or spheres. In this paper, we propose and compare expressive and numerically stable ﬂows on such spaces. Our ﬂows are built recursively on the dimension of the space, starting from ﬂows on circles, closed intervals or spheres.},
	language = {en},
	urldate = {2021-10-01},
	journal = {arXiv:2002.02428 [cs, stat]},
	author = {Rezende, Danilo Jimenez and Papamakarios, George and Racanière, Sébastien and Albergo, Michael S. and Kanwar, Gurtej and Shanahan, Phiala E. and Cranmer, Kyle},
	month = jul,
	year = {2020},
	note = {arXiv: 2002.02428},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mathieu_riemannian_2020,
	title = {Riemannian {Continuous} {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2006.10605},
	abstract = {Normalizing ﬂows have shown great promise for modelling ﬂexible probability distributions in a computationally tractable way. However, whilst data is often naturally described on Riemannian manifolds such as spheres, tori, and hyperbolic spaces, most normalizing ﬂows implicitly assume a ﬂat geometry, making them either misspeciﬁed or ill-suited in these situations. To overcome this problem, we introduce Riemannian continuous normalizing ﬂows, a model which admits the parametrization of ﬂexible probability measures on smooth manifolds by deﬁning ﬂows as the solution to ordinary diﬀerential equations. We show that this approach can lead to substantial improvements on both synthetic and real-world data when compared to standard ﬂows or previously introduced projected ﬂows.},
	language = {en},
	urldate = {2021-10-01},
	journal = {arXiv:2006.10605 [cs, stat]},
	author = {Mathieu, Emile and Nickel, Maximilian},
	month = dec,
	year = {2020},
	note = {arXiv: 2006.10605},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{gemici_normalizing_2016,
	title = {Normalizing {Flows} on {Riemannian} {Manifolds}},
	url = {http://arxiv.org/abs/1611.02304},
	abstract = {We consider the problem of density estimation on Riemannian manifolds. Density estimation on manifolds has many applications in fluid-mechanics, optics and plasma physics and it appears often when dealing with angular variables (such as used in protein folding, robot limbs, gene-expression) and in general directional statistics. In spite of the multitude of algorithms available for density estimation in the Euclidean spaces \${\textbackslash}mathbf\{R\}{\textasciicircum}n\$ that scale to large n (e.g. normalizing flows, kernel methods and variational approximations), most of these methods are not immediately suitable for density estimation in more general Riemannian manifolds. We revisit techniques related to homeomorphisms from differential geometry for projecting densities to sub-manifolds and use it to generalize the idea of normalizing flows to more general Riemannian manifolds. The resulting algorithm is scalable, simple to implement and suitable for use with automatic differentiation. We demonstrate concrete examples of this method on the n-sphere \${\textbackslash}mathbf\{S\}{\textasciicircum}n\$.},
	urldate = {2021-10-01},
	journal = {arXiv:1611.02304 [cs, math, stat]},
	author = {Gemici, Mevlana C. and Rezende, Danilo and Mohamed, Shakir},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.02304},
	keywords = {Computer Science - Artificial Intelligence, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@article{chadebec_geometry-aware_2020,
	title = {Geometry-{Aware} {Hamiltonian} {Variational} {Auto}-{Encoder}},
	url = {http://arxiv.org/abs/2010.11518},
	abstract = {Variational auto-encoders (VAEs) have proven to be a well suited tool for performing dimensionality reduction by extracting latent variables lying in a potentially much smaller dimensional space than the data. Their ability to capture meaningful information from the data can be easily apprehended when considering their capability to generate new realistic samples or perform potentially meaningful interpolations in a much smaller space. However, such generative models may perform poorly when trained on small data sets which are abundant in many real-life fields such as medicine. This may, among others, come from the lack of structure of the latent space, the geometry of which is often under-considered. We thus propose in this paper to see the latent space as a Riemannian manifold endowed with a parametrized metric learned at the same time as the encoder and decoder networks. This metric is then used in what we called the Riemannian Hamiltonian VAE which extends the Hamiltonian VAE introduced by arXiv:1805.11328 to better exploit the underlying geometry of the latent space. We argue that such latent space modelling provides useful information about its underlying structure leading to far more meaningful interpolations, more realistic data-generation and more reliable clustering.},
	urldate = {2021-10-01},
	journal = {arXiv:2010.11518 [cs, math, stat]},
	author = {Chadebec, Clément and Mantoux, Clément and Allassonnière, Stéphanie},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.11518},
	keywords = {Computer Science - Machine Learning, Mathematics - Differential Geometry, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@article{chadebec_data_2021,
	title = {Data {Augmentation} in {High} {Dimensional} {Low} {Sample} {Size} {Setting} {Using} a {Geometry}-{Based} {Variational} {Autoencoder}},
	url = {http://arxiv.org/abs/2105.00026},
	abstract = {In this paper, we propose a new method to perform data augmentation in a reliable way in the High Dimensional Low Sample Size (HDLSS) setting using a geometry-based variational autoencoder. Our approach combines a proper latent space modeling of the VAE seen as a Riemannian manifold with a new generation scheme which produces more meaningful samples especially in the context of small data sets. The proposed method is tested through a wide experimental study where its robustness to data sets, classifiers and training samples size is stressed. It is also validated on a medical imaging classification task on the challenging ADNI database where a small number of 3D brain MRIs are considered and augmented using the proposed VAE framework. In each case, the proposed method allows for a significant and reliable gain in the classification metrics. For instance, balanced accuracy jumps from 66.3\% to 74.3\% for a state-of-the-art CNN classifier trained with 50 MRIs of cognitively normal (CN) and 50 Alzheimer disease (AD) patients and from 77.7\% to 86.3\% when trained with 243 CN and 210 AD while improving greatly sensitivity and specificity metrics.},
	urldate = {2021-10-01},
	journal = {arXiv:2105.00026 [cs, stat]},
	author = {Chadebec, Clément and Thibeau-Sutre, Elina and Burgos, Ninon and Allassonnière, Stéphanie},
	month = apr,
	year = {2021},
	note = {arXiv: 2105.00026},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{chadebec_data_2021-1,
	title = {Data {Augmentation} in {High} {Dimensional} {Low} {Sample} {Size} {Setting} {Using} a {Geometry}-{Based} {Variational} {Autoencoder}},
	url = {http://arxiv.org/abs/2105.00026},
	abstract = {In this paper, we propose a new method to perform data augmentation in a reliable way in the High Dimensional Low Sample Size (HDLSS) setting using a geometry-based variational autoencoder. Our approach combines a proper latent space modeling of the VAE seen as a Riemannian manifold with a new generation scheme which produces more meaningful samples especially in the context of small data sets. The proposed method is tested through a wide experimental study where its robustness to data sets, classiﬁers and training samples size is stressed. It is also validated on a medical imaging classiﬁcation task on the challenging ADNI database where a small number of 3D brain MRIs are considered and augmented using the proposed VAE framework. In each case, the proposed method allows for a signiﬁcant and reliable gain in the classiﬁcation metrics. For instance, balanced accuracy jumps from 66.3\% to 74.3\% for a state-of-the-art CNN classiﬁer trained with 50 MRIs of cognitively normal (CN) and 50 Alzheimer disease (AD) patients and from 77.7\% to 86.3\% when trained with 243 CN and 210 AD while improving greatly sensitivity and speciﬁcity metrics.},
	language = {en},
	urldate = {2021-10-01},
	journal = {arXiv:2105.00026 [cs, stat]},
	author = {Chadebec, Clément and Thibeau-Sutre, Elina and Burgos, Ninon and Allassonnière, Stéphanie},
	month = apr,
	year = {2021},
	note = {arXiv: 2105.00026},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{samavaki_navierstokes_2020,
	title = {Navier–{Stokes} equations on {Riemannian} manifolds},
	volume = {148},
	issn = {0393-0440},
	url = {https://www.sciencedirect.com/science/article/pii/S0393044019302244},
	doi = {10.1016/j.geomphys.2019.103543},
	abstract = {We study properties of the solutions to Navier–Stokes system on compact Riemannian manifolds. The motivation for such a formulation comes from atmospheric models as well as some thin film flows on curved surfaces. There are different choices of the diffusion operator which have been used in previous studies, and we make a few comments why the choice adopted below seems to us the correct one. This choice leads to the conclusion that Killing vector fields are essential in analyzing the qualitative properties of the flow. We give several results illustrating this and analyze also the linearized version of Navier–Stokes system which is interesting in numerical applications. Finally we consider the 2 dimensional case which has specific characteristics, and treat also the Coriolis effect which is essential in atmospheric flows.},
	language = {en},
	urldate = {2021-10-01},
	journal = {Journal of Geometry and Physics},
	author = {Samavaki, Maryam and Tuomela, Jukka},
	month = feb,
	year = {2020},
	keywords = {Curvature tensor, Killing vector fields, Navier–Stokes equations, Riemannian manifolds},
	pages = {103543},
}

@article{chadebec_data_2021-2,
	title = {Data {Augmentation} in {High} {Dimensional} {Low} {Sample} {Size} {Setting} {Using} a {Geometry}-{Based} {Variational} {Autoencoder}},
	url = {http://arxiv.org/abs/2105.00026},
	abstract = {In this paper, we propose a new method to perform data augmentation in a reliable way in the High Dimensional Low Sample Size (HDLSS) setting using a geometry-based variational autoencoder. Our approach combines a proper latent space modeling of the VAE seen as a Riemannian manifold with a new generation scheme which produces more meaningful samples especially in the context of small data sets. The proposed method is tested through a wide experimental study where its robustness to data sets, classifiers and training samples size is stressed. It is also validated on a medical imaging classification task on the challenging ADNI database where a small number of 3D brain MRIs are considered and augmented using the proposed VAE framework. In each case, the proposed method allows for a significant and reliable gain in the classification metrics. For instance, balanced accuracy jumps from 66.3\% to 74.3\% for a state-of-the-art CNN classifier trained with 50 MRIs of cognitively normal (CN) and 50 Alzheimer disease (AD) patients and from 77.7\% to 86.3\% when trained with 243 CN and 210 AD while improving greatly sensitivity and specificity metrics.},
	urldate = {2021-10-01},
	journal = {arXiv:2105.00026 [cs, stat]},
	author = {Chadebec, Clément and Thibeau-Sutre, Elina and Burgos, Ninon and Allassonnière, Stéphanie},
	month = apr,
	year = {2021},
	note = {arXiv: 2105.00026},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ravuri_skilful_2021,
	title = {Skilful precipitation nowcasting using deep generative models of radar},
	volume = {597},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03854-z},
	doi = {10.1038/s41586-021-03854-z},
	abstract = {Abstract
            
              Precipitation nowcasting, the high-resolution forecasting of precipitation up to two hours ahead, supports the real-world socioeconomic needs of many sectors reliant on weather-dependent decision-making
              1,2
              . State-of-the-art operational nowcasting methods typically advect precipitation fields with radar-based wind estimates, and struggle to capture important non-linear events such as convective initiations
              3,4
              . Recently introduced deep learning methods use radar to directly predict future rain rates, free of physical constraints
              5,6
              . While they accurately predict low-intensity rainfall, their operational utility is limited because their lack of constraints produces blurry nowcasts at longer lead times, yielding poor performance on rarer medium-to-heavy rain events. Here we present a deep generative model for the probabilistic nowcasting of precipitation from radar that addresses these challenges. Using statistical, economic and cognitive measures, we show that our method provides improved forecast quality, forecast consistency and forecast value. Our model produces realistic and spatiotemporally consistent predictions over regions up to 1,536 km × 1,280 km and with lead times from 5–90 min ahead. Using a systematic evaluation by more than 50 expert meteorologists, we show that our generative model ranked first for its accuracy and usefulness in 89\% of cases against two competitive methods. When verified quantitatively, these nowcasts are skillful without resorting to blurring. We show that generative nowcasting can provide probabilistic predictions that improve forecast value and support operational utility, and at resolutions and lead times where alternative methods struggle.},
	language = {en},
	number = {7878},
	urldate = {2021-10-01},
	journal = {Nature},
	author = {Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin, Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and Prudden, Rachel and Mandhane, Amol and Clark, Aidan and Brock, Andrew and Simonyan, Karen and Hadsell, Raia and Robinson, Niall and Clancy, Ellen and Arribas, Alberto and Mohamed, Shakir},
	month = sep,
	year = {2021},
	pages = {672--677},
}

@misc{noauthor_skilful_nodate,
	title = {Skilful precipitation nowcasting using deep generative models of radar {\textbar} {Nature}},
	url = {https://www.nature.com/articles/s41586-021-03854-z},
	urldate = {2021-10-01},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2021-10-01},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@article{cardesa_turbulent_2017,
	title = {The turbulent cascade in five dimensions},
	volume = {357},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aan7933},
	doi = {10.1126/science.aan7933},
	language = {en},
	number = {6353},
	urldate = {2021-09-28},
	journal = {Science},
	author = {Cardesa, José I. and Vela-Martín, Alberto and Jiménez, Javier},
	month = aug,
	year = {2017},
	pages = {782--784},
}

@article{xie_physics-based_2021,
	title = {Physics-based {Human} {Motion} {Estimation} and {Synthesis} from {Videos}},
	url = {http://arxiv.org/abs/2109.09913},
	abstract = {Human motion synthesis is an important problem with applications in graphics, gaming and simulation environments for robotics. Existing methods require accurate motion capture data for training, which is costly to obtain. Instead, we propose a framework for training generative models of physically plausible human motion directly from monocular RGB videos, which are much more widely available. At the core of our method is a novel optimization formulation that corrects imperfect image-based pose estimations by enforcing physics constraints and reasons about contacts in a differentiable way. This optimization yields corrected 3D poses and motions, as well as their corresponding contact forces. Results show that our physically-corrected motions significantly outperform prior work on pose estimation. We can then use these to train a generative model to synthesize future motion. We demonstrate both qualitatively and quantitatively significantly improved motion estimation, synthesis quality and physical plausibility achieved by our method on the large scale Human3.6m dataset {\textbackslash}cite\{h36m\_pami\} as compared to prior kinematic and physics-based methods. By enabling learning of motion synthesis from video, our method paves the way for large-scale, realistic and diverse motion synthesis.},
	urldate = {2021-09-23},
	journal = {arXiv:2109.09913 [cs]},
	author = {Xie, Kevin and Wang, Tingwu and Iqbal, Umar and Guo, Yunrong and Fidler, Sanja and Shkurti, Florian},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.09913},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{babinsky_modeling_2002,
	title = {Modeling drop size distributions},
	volume = {28},
	issn = {0360-1285},
	url = {https://www.sciencedirect.com/science/article/pii/S0360128502000047},
	doi = {10.1016/S0360-1285(02)00004-7},
	abstract = {There is abundant literature discussing the prediction of a representative drop diameter in a spray. However, there are relatively few publications discussing prediction of a drop size distribution in sprays. In the present paper, we review the three available methods for modeling drop size distributions: the maximum entropy method, the discrete probability function method, and the empirical method.},
	language = {en},
	number = {4},
	urldate = {2021-09-22},
	journal = {Progress in Energy and Combustion Science},
	author = {Babinsky, E. and Sojka, P. E.},
	month = jan,
	year = {2002},
	keywords = {Atomization, Drop size distribution, Modeling, Sprays},
	pages = {303--329},
}

@article{eivazi_towards_2021,
	title = {Towards extraction of orthogonal and parsimonious non-linear modes from turbulent flows},
	url = {http://arxiv.org/abs/2109.01514},
	abstract = {We propose a deep probabilistic-neural-network architecture for learning a minimal and near-orthogonal set of non-linear modes from high-fidelity turbulent-flow-field data useful for flow analysis, reduced-order modeling, and flow control. Our approach is based on \${\textbackslash}beta\$-variational autoencoders (\${\textbackslash}beta\$-VAEs) and convolutional neural networks (CNNs), which allow us to extract non-linear modes from multi-scale turbulent flows while encouraging the learning of independent latent variables and penalizing the size of the latent vector. Moreover, we introduce an algorithm for ordering VAE-based modes with respect to their contribution to the reconstruction. We apply this method for non-linear mode decomposition of the turbulent flow through a simplified urban environment, where the flow-field data is obtained based on well-resolved large-eddy simulations (LESs). We demonstrate that by constraining the shape of the latent space, it is possible to motivate the orthogonality and extract a set of parsimonious modes sufficient for high-quality reconstruction. Our results show the excellent performance of the method in the reconstruction against linear-theory-based decompositions. Moreover, we compare our method with available AE-based models. We show the ability of our approach in the extraction of near-orthogonal modes that may lead to interpretability.},
	urldate = {2021-09-21},
	journal = {arXiv:2109.01514 [physics]},
	author = {Eivazi, Hamidreza and Clainche, Soledad Le and Hoyas, Sergio and Vinuesa, Ricardo},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.01514},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{mohan_learning_2021,
	title = {Learning {Stable} {Galerkin} {Models} of {Turbulence} with {Differentiable} {Programming}},
	url = {http://arxiv.org/abs/2107.07559},
	abstract = {Turbulent flow control has numerous applications and building reduced-order models (ROMs) of the flow and the associated feedback control laws is extremely challenging. Despite the complexity of building data-driven ROMs for turbulence, the superior representational capacity of deep neural networks has demonstrated considerable success in learning ROMs. Nevertheless, these strategies are typically devoid of physical foundations and often lack interpretability. Conversely, the Proper Orthogonal Decomposition (POD) based Galerkin projection (GP) approach for ROM has been popular in many problems owing to its theoretically consistent and explainable physical foundations. However, a key limitation is that the ordinary differential equations (ODEs) arising from GP ROMs are highly susceptible to instabilities due to truncation of POD modes and lead to deterioration in temporal predictions. In this work, we propose a {\textbackslash}textit\{differentiable programming\} approach that blends the strengths of both these strategies, by embedding neural networks explicitly into the GP ODE structure, termed Neural Galerkin projection. We demonstrate this approach on the isentropic Navier-Stokes equations for compressible flow over a cavity at a moderate Mach number. When provided the structure of the projected equations, we show that the Neural Galerkin approach implicitly learns stable ODE coefficients from POD coefficients and demonstrates significantly longer and accurate time horizon predictions, when compared to the classical POD-GP assisted by calibration. We observe that the key benefits of this differentiable programming-based approach include increased flexibility in physics-based learning, very low computational costs, and a significant increase in interpretability, when compared to purely data-driven neural networks.},
	urldate = {2021-09-20},
	journal = {arXiv:2107.07559 [nlin, physics:physics]},
	author = {Mohan, Arvind T. and Nagarajan, Kaushik and Livescu, Daniel},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.07559},
	keywords = {Nonlinear Sciences - Chaotic Dynamics, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{doersch_tutorial_2021,
	title = {Tutorial on {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/1606.05908},
	abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
	urldate = {2021-09-16},
	journal = {arXiv:1606.05908 [cs, stat]},
	author = {Doersch, Carl},
	month = jan,
	year = {2021},
	note = {arXiv: 1606.05908},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{papamakarios_neural_2019,
	title = {Neural {Density} {Estimation} and {Likelihood}-free {Inference}},
	url = {http://arxiv.org/abs/1910.13233},
	abstract = {I consider two problems in machine learning and statistics: the problem of estimating the joint probability density of a collection of random variables, known as density estimation, and the problem of inferring model parameters when their likelihood is intractable, known as likelihood-free inference. The contribution of the thesis is a set of new methods for addressing these problems that are based on recent advances in neural networks and deep learning.},
	urldate = {2021-09-16},
	journal = {arXiv:1910.13233 [cs, stat]},
	author = {Papamakarios, George},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.13233},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{navarro-martinez_large_2014,
	title = {Large eddy simulation of spray atomization with a probability density function method},
	volume = {63},
	issn = {0301-9322},
	url = {https://www.sciencedirect.com/science/article/pii/S0301932214000482},
	doi = {10.1016/j.ijmultiphaseflow.2014.02.013},
	abstract = {Despite recent advances in numerical methods for multiphase flows, the complete simulation of a liquid spray is still an illusive goal. There are few models that can describe accurately both the primary and secondary atomization simultaneously. The biggest difficulty is the wide range of length scales involved; from millimetres in the largest liquid structures close to the smallest micron-size droplets. This wide range makes Direct Numerical Simulation of sprays very expensive all scales need to be resolved and expensive algorithms are required to reconstruct accurately the interface. Large eddy simulations are becoming increasingly popular in turbulent flows due to their better description of turbulence and the relative robustness of sub-grid stress models. Despite its advantages, large eddy simulation cannot describe accurately fluid structures that occur at sub-grid levels. This paper presents a new model to describe the atomization process. The method consist of solving a joint sub-grid probability density function of liquid volume and surface using stochastic methods. The approach can simulate both dense and dilute regions of the spray. The proposed model can determine instantaneous sub-grid liquid structures (droplets) distributions as well as to capture the primary break-up. The results of the simulations are compared to a Direct Numerical Simulation of a Diesel Jet break-up. The mean liquid volume and surface density are well predicted; The modelling of the sub-grid scales is shown to be fundamental in the dilute regions of the spray.},
	language = {en},
	urldate = {2021-09-16},
	journal = {International Journal of Multiphase Flow},
	author = {Navarro-Martinez, S.},
	month = jul,
	year = {2014},
	keywords = {Large eddy simulations, Probability density function, Spray atomization, Surface density},
	pages = {11--22},
}

@article{mohamed_statistical_2019,
	title = {Statistical modeling of the gas–liquid interface using geometrical variables: {Toward} a unified description of the disperse and separated phase flows},
	volume = {120},
	issn = {0301-9322},
	shorttitle = {Statistical modeling of the gas–liquid interface using geometrical variables},
	url = {https://www.sciencedirect.com/science/article/pii/S0301932217308583},
	doi = {10.1016/j.ijmultiphaseflow.2019.103084},
	abstract = {In this work, we investigate an original strategy in order to derive a statistical modeling of the interface in gas–liquid two-phase flows through geometrical variables. The contribution is two-fold. First it participates in the theoretical design of a unified reduced-order model for the description of two regimes: a disperse phase in a carrier fluid and two separated phases. The first idea is to propose a statistical description of the interface relying on geometrical properties, such as the mean and Gauss curvatures, and to define an associated Surface Density Function (SDF). The second main idea consists in using such a formalism in the disperse case, where a clear link is proposed between local statistics of the interface and the statistics of countable objects, such as a number density function. To this end we make essential the use of topological invariants in geometry through the Gauss-Bonnet formula. This strategy strictly includes the works conducted on sprays of spherical droplets, but it also yields a statistical treatment of populations of non-spherical objects, such as ligaments, as long as they are homeomorphic to a sphere. Second, we propose an original statistical post-processing of DNS data of interfacial flows. Starting from the proposed theoretical approach, we identify a kernel for the spatial averaging of geometrical quantities which preserves the topological invariants. Coupled to a new algorithm for the evaluation of the surface and its curvatures, that also preserves these invariants, we analyze two sets of DNS results obtained with the ARCHER code from CORIA, with and without topological changes, and assess the approach. Indeed, this procedure allows us to transform the interfacial information provided by a Level-Set function into a number distribution of a collection of objects in the proper geometrical phase space.},
	language = {en},
	urldate = {2021-09-16},
	journal = {International Journal of Multiphase Flow},
	author = {Mohamed, Essadki and Florence, Drui and Stéphane, de Chaisemartin and Adam, Larat and Thibault, Ménard and Marc, Massot},
	month = nov,
	year = {2019},
	keywords = {Gauss-Bonnet formula, computational geometry, disperse/separated phases, gas-liquid interface, moments method, surface and number density function},
	pages = {103084},
}

@misc{noauthor_statistical_nodate,
	title = {Statistical modeling of the gas-liquid interface using geometrical variables: {Toward} a unified description of the disperse and separated phase flows {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Statistical modeling of the gas-liquid interface using geometrical variables},
	url = {https://reader.elsevier.com/reader/sd/pii/S0301932217308583?token=7FE5F6A27F730D6C15BC5BE19CCCF91ACAE2F01D18F8F3EBB2C41A76BAD86421F38250D1F47ABBD0C797B01AC05B4A10&originRegion=eu-west-1&originCreation=20210916072959},
	language = {en},
	urldate = {2021-09-16},
	doi = {10.1016/j.ijmultiphaseflow.2019.103084},
}

@article{wen_u-fno_2021,
	title = {U-{FNO} -- an enhanced {Fourier} neural operator based-deep learning model for multiphase flow},
	url = {http://arxiv.org/abs/2109.03697},
	abstract = {Numerical simulation of multiphase flow in porous media is essential for many geoscience applications. However, due to the multi-physics, non-linear, and multi-scale problem nature, these simulations are very expensive at desirable grid resolutions, and the computational cost often impedes rigorous engineering decision-making. Machine learning methods provide faster alternatives to traditional simulators by training neural network models with numerical simulation data mappings. Traditional convolutional neural network (CNN)-based models are accurate yet data-intensive and are prone to overfitting. Here we present a new architecture, U-FNO, an enhanced Fourier neural operator for solving the multiphase flow problem. The U-FNO is designed based on the Fourier neural operator (FNO) that learns an integral kernel in the Fourier space. Through a systematic comparison among a CNN benchmark and three types of FNO variations on a CO2-water multiphase problem in the context of CO2 geological storage, we show that the U-FNO architecture has the advantages of both traditional CNN and original FNO, providing significantly more accurate and efficient performance than previous architectures. The trained U-FNO provides gas saturation and pressure buildup predictions with a 10,000 times speedup compared to traditional numerical simulators while maintaining similar accuracy.},
	urldate = {2021-09-15},
	journal = {arXiv:2109.03697 [physics]},
	author = {Wen, Gege and Li, Zongyi and Azizzadenesheli, Kamyar and Anandkumar, Anima and Benson, Sally M.},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.03697},
	keywords = {Computer Science - Machine Learning, Physics - Geophysics},
}

@article{chandler_invariant_2013,
	title = {Invariant recurrent solutions embedded in a turbulent two-dimensional {Kolmogorov} flow},
	volume = {722},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/invariant-recurrent-solutions-embedded-in-a-turbulent-twodimensional-kolmogorov-flow/78CC6B29A670F84CBC79D29408DC2674},
	doi = {10.1017/jfm.2013.122},
	abstract = {We consider long-time simulations of two-dimensional turbulence body forced by 
                  
                     
                     sin4yx{\textasciicircum}sin⁡4yx{\textasciicircum}{\textbackslash}sin 4y{\textbackslash}hat \{{\textbackslash}boldsymbol\{x\}\} 
                  
                on the torus 
                  
                     
                     (x,y)∈[0,2π]2(x,y)∈[0,2π]2(x, y){\textbackslash}in {\textbackslash}mathop\{[0, 2{\textbackslash}mathrm\{{\textbackslash}pi\} ] \}{\textbackslash}nolimits {\textasciicircum}\{2\} 
                  
                with the purpose of extracting simple invariant sets or ‘exact recurrent flows’ embedded in this turbulence. Each recurrent flow represents a sustained closed cycle of dynamical processes which underpins the turbulence. These are used to reconstruct the turbulence statistics using periodic orbit theory. The approach is found to be reasonably successful at a low value of the forcing where the flow is close to but not fully in its asymptotic (strongly) turbulent regime. Here, a total of 50 recurrent flows are found with the majority buried in the part of phase space most populated by the turbulence giving rise to a good reproduction of the energy and dissipation p.d.f. However, at higher forcing amplitudes now in the asymptotic turbulent regime, the generated turbulence data set proves insufficiently long to yield enough recurrent flows to make viable predictions. Despite this, the general approach seems promising providing enough simulation data is available since it is open to extensive automation and naturally generates dynamically important exact solutions for the flow.},
	language = {en},
	urldate = {2021-09-10},
	journal = {Journal of Fluid Mechanics},
	author = {Chandler, Gary J. and Kerswell, Rich R.},
	month = may,
	year = {2013},
	note = {Publisher: Cambridge University Press},
	keywords = {chaos, nonlinear dynamical systems, turbulence theory},
	pages = {554--595},
}

@article{schneiderbauer_numerical_2019,
	title = {Numerical simulation of turbulent gas–solid flow using an approximate deconvolution model},
	volume = {114},
	issn = {0301-9322},
	url = {https://www.sciencedirect.com/science/article/pii/S0301932218307419},
	doi = {10.1016/j.ijmultiphaseflow.2019.03.017},
	abstract = {In our prior study (Schneiderbauer and Saeedipour, Phys. Fluids, 2018; 30:023301), an a-priori analysis on the spatially-filtered two-fluid model (TFM) was presented for turbulent gas–solid flows, where the unresolved terms were modeled by an approximate deconvolution model (ADM). With such an approach, an approximation of the unfiltered solution is obtained by repeated filtering allowing the determination of the RSFS (resolved sub-filter scales) contribution of unclosed terms of the filtered equations directly. In the present study, this ADM-TFM approach is implemented in an a-posteriori manner for the coarse grid simulation of a fluidized bed of Geldart type B particles and is verified against highly-resolved TFM simulations. Furthermore, different regularization methods, which account for the sub-filter scale (SFS) contribution, are presented and discussed with respect to their predictiveness and stability. It is shown that employing an appropriate rheological model for the solid phase considerably improves stability without removing too much energy from the resolved scales. Finally, the ADM-TFM predictions are in fairly good agreement with the fine grid reference case and do not show a notable grid-dependency. Compared to TFM simulations using the same grid resolution, the ADM-TFM approach does only require marginally more computational resources.},
	language = {en},
	urldate = {2021-09-10},
	journal = {International Journal of Multiphase Flow},
	author = {Schneiderbauer, Simon and Saeedipour, Mahdi},
	month = may,
	year = {2019},
	keywords = {ADM regularization, Kinetic theory based two-fluid model (TFM), Multiphase turbulence, Structural turbulence model, Sub-grid closure},
	pages = {287--302},
}

@misc{noauthor_large_nodate,
	title = {Large eddy simulation of turbulent interfacial flows using {Approximate} {Deconvolution} {Model} {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0301932217309989?token=DCDD0252970AC143702EE5E339CD3C4F803F0475B8BF04F7EC4ADED64F64CB289C2D50F7CEA54CABE77CE38CA713DC32&originRegion=eu-west-1&originCreation=20210910072348},
	language = {en},
	urldate = {2021-09-10},
	doi = {10.1016/j.ijmultiphaseflow.2018.10.011},
}

@article{saeedipour_large_2019,
	title = {Large eddy simulation of turbulent interfacial flows using {Approximate} {Deconvolution} {Model}},
	volume = {112},
	issn = {0301-9322},
	url = {https://www.sciencedirect.com/science/article/pii/S0301932217309989},
	doi = {10.1016/j.ijmultiphaseflow.2018.10.011},
	abstract = {Large eddy simulation (LES) is currently widespread in turbulence modeling research. Although LES has reached a mature level in modelling single-phase turbulent flows even in industrial scales, the challenges with LES of turbulent interfacial flows are still remaining. The main issue arises in subgrid closure modelling where the small-scale physics of the flow, as well as the small-scale interfacial topological changes, must be accounted for in filtered governing equations. In this paper, the Approximate Deconvolution Model (ADM) (Stolz and Adams, 1999) is extended to the two-phase LES problems to model all the subgrid terms appearing in the filtered governing equations. Then, the ADM-VOF approach is developed comprehensively and implemented in the frame of C++ libraries of OpenFOAM. The ADM-VOF is then employed for an a posteriori LES on the phase inversion benchmark which represents a buoyancy-driven turbulent interfacial flow with several interfacial events such as coalescence and rupture. To investigate the performance of this approach, a series of quantitative comparisons with quasi-DNS data and conventional LES (i.e. with single-phase assumption) is conducted based on macroscopic characteristics of the flow including enstrophy and interfacial length. The results reveal that the structural ADM-VOF approach improves the prediction of macroscopic flow characteristics associated with unresolved contributions compared to the conventional LES. The dependency of ADM-VOF performance on the grid resolution is also investigated. It shows that ADM-VOF exhibits more potentials in predicting the interfacial scales on a finer grid. Additionally, our study unveils that the choice of functional methods for modeling relaxation term may not be extendable to the two-phase ADM.},
	language = {en},
	urldate = {2021-09-10},
	journal = {International Journal of Multiphase Flow},
	author = {Saeedipour, Mahdi and Vincent, Stéphane and Pirker, Stefan},
	month = mar,
	year = {2019},
	keywords = {Approximate Deconvolution Model (ADM), Interfacial flow, Large eddy simulation (LES), Two-phase turbulence, Volume of fluid (VOF)},
	pages = {286--299},
}

@article{schneiderbauer_approximate_2018,
	title = {Approximate deconvolution model for the simulation of turbulent gas-solid flows: {An} a priori analysis},
	volume = {30},
	issn = {1070-6631},
	shorttitle = {Approximate deconvolution model for the simulation of turbulent gas-solid flows},
	url = {https://aip.scitation.org/doi/10.1063/1.5017004},
	doi = {10.1063/1.5017004},
	abstract = {Highly resolved two-fluid model (TFM) simulations of gas-solid flows in vertical periodic channels have been performed to study closures for the filtered drag force and the Reynolds-stress-like contribution stemming from the convective terms. An approximate deconvolution model (ADM) for the large-eddy simulation of turbulent gas-solid suspensions is detailed and subsequently used to reconstruct those unresolved contributions in an a priori manner. With such an approach, an approximation of the unfiltered solution is obtained by repeated filtering allowing the determination of the unclosed terms of the filtered equations directly. A priori filtering shows that predictions of the ADM model yield fairly good agreement with the fine grid TFM simulations for various filter sizes and different particle sizes. In particular, strong positive correlation (ρ {\textgreater} 0.98) is observed at intermediate filter sizes for all sub-grid terms. Additionally, our study reveals that the ADM results moderately depend on the choice of the filters, such as box and Gaussian filter, as well as the deconvolution order. The a priori test finally reveals that ADM is superior compared to isotropic functional closures proposed recently [S. Schneiderbauer, “A spatially-averaged two-fluid model for dense large-scale gas-solid flows,” AIChE J. 63, 3544–3562 (2017)].},
	number = {2},
	urldate = {2021-09-10},
	journal = {Physics of Fluids},
	author = {Schneiderbauer, Simon and Saeedipour, Mahdi},
	month = feb,
	year = {2018},
	note = {Publisher: American Institute of Physics},
	pages = {023301},
}

@article{maulik_data-driven_2018,
	title = {Data-driven deconvolution for large eddy simulations of {Kraichnan} turbulence},
	url = {http://arxiv.org/abs/1812.02211},
	abstract = {In this article, we demonstrate the use of artificial neural networks as optimal maps which are utilized for convolution and deconvolution of coarse-grained fields to account for sub-grid scale turbulence effects. We demonstrate that an effective eddy-viscosity is predicted by our purely data-driven large eddy simulation framework without explicit utilization of phenomenological arguments. In addition, our data-driven framework precludes the knowledge of true sub-grid stress information during the training phase due to its focus on estimating an effective filter and its inverse so that grid-resolved variables may be related to direct numerical simulation data statistically. The proposed predictive framework is also combined with a statistical truncation mechanism for ensuring numerical realizability in an explicit formulation. Through this we seek to unite structural and functional modeling strategies for modeling non-linear partial differential equations using reduced degrees of freedom. Both a priori and a posteriori results are shown for a two-dimensional decaying turbulence case in addition to a detailed description of validation and testing. A hyperparameter sensitivity study also shows that the proposed dual network framework simplifies learning complexity and is viable with exceedingly simple network architectures. Our findings indicate that the proposed framework approximates a robust and stable sub-grid closure which compares favorably to the Smagorinsky and Leith hypotheses for capturing the theoretical \$k{\textasciicircum}\{-3\}\$ scaling in Kraichnan turbulence.},
	urldate = {2021-09-10},
	journal = {arXiv:1812.02211 [physics]},
	author = {Maulik, Romit and San, Omer and Rasheed, Adil and Vedula, Prakash},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.02211},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{stolz_approximate_1999,
	title = {An approximate deconvolution procedure for large-eddy simulation},
	volume = {11},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.869867},
	doi = {10.1063/1.869867},
	number = {7},
	urldate = {2021-09-10},
	journal = {Physics of Fluids},
	author = {Stolz, S. and Adams, N. A.},
	month = jul,
	year = {1999},
	note = {Publisher: American Institute of Physics},
	pages = {1699--1701},
}

@article{kovachki_neural_2021,
	title = {Neural {Operator}: {Learning} {Maps} {Between} {Function} {Spaces}},
	shorttitle = {Neural {Operator}},
	url = {http://arxiv.org/abs/2108.08481},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite dimensional Euclidean spaces or finite sets. We propose a generalization of neural networks tailored to learn operators mapping between infinite dimensional function spaces. We formulate the approximation of operators by composition of a class of linear integral operators and nonlinear activation functions, so that the composed operator can approximate complex nonlinear operators. We prove a universal approximation theorem for our construction. Furthermore, we introduce four classes of operator parameterizations: graph-based operators, low-rank operators, multipole graph-based operators, and Fourier operators and describe efficient algorithms for computing with each one. The proposed neural operators are resolution-invariant: they share the same network parameters between different discretizations of the underlying function spaces and can be used for zero-shot super-resolutions. Numerically, the proposed models show superior performance compared to existing machine learning based methodologies on Burgers' equation, Darcy flow, and the Navier-Stokes equation, while being several order of magnitude faster compared to conventional PDE solvers.},
	urldate = {2021-09-08},
	journal = {arXiv:2108.08481 [cs, math]},
	author = {Kovachki, Nikola and Li, Zongyi and Liu, Burigede and Azizzadenesheli, Kamyar and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = sep,
	year = {2021},
	note = {arXiv: 2108.08481},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@misc{noauthor_statistical_nodate-1,
	title = {Statistical modeling of the gas-liquid interface using geometrical variables: {Toward} a unified description of the disperse and separated phase flows {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Statistical modeling of the gas-liquid interface using geometrical variables},
	url = {https://reader.elsevier.com/reader/sd/pii/S0301932217308583?token=A671BB08D4D3A5BD4678FBA21D9302FBBEFBAAF9E1406948E06E9FAA4077FA164FE43EE1A931B68431EEEB84C425C404&originRegion=eu-west-1&originCreation=20210907092936},
	language = {en},
	urldate = {2021-09-07},
	doi = {10.1016/j.ijmultiphaseflow.2019.103084},
}

@misc{noauthor_large_nodate-1,
	title = {Large eddy simulation of spray atomization with a probability density function method {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0301932214000482?token=4DFEE92CCBDF82190E7DE0F1BAFCACF132EB9595443AD5560971A80B3E130284B36B5680A013554EE1641F6B75DC3D3E&originRegion=eu-west-1&originCreation=20210907092746},
	language = {en},
	urldate = {2021-09-07},
	doi = {10.1016/j.ijmultiphaseflow.2014.02.013},
}

@article{psaros_meta-learning_2021,
	title = {Meta-learning {PINN} loss functions},
	url = {http://arxiv.org/abs/2107.05544},
	abstract = {We propose a meta-learning technique for offline discovery of physics-informed neural network (PINN) loss functions. We extend earlier works on meta-learning, and develop a gradient-based meta-learning algorithm for addressing diverse task distributions based on parametrized partial differential equations (PDEs) that are solved with PINNs. Furthermore, based on new theory we identify two desirable properties of meta-learned losses in PINN problems, which we enforce by proposing a new regularization method or using a specific parametrization of the loss function. In the computational examples, the meta-learned losses are employed at test time for addressing regression and PDE task distributions. Our results indicate that significant performance improvement can be achieved by using a shared-among-tasks offline-learned loss function even for out-of-distribution meta-testing. In this case, we solve for test tasks that do not belong to the task distribution used in meta-training, and we also employ PINN architectures that are different from the PINN architecture used in meta-training. To better understand the capabilities and limitations of the proposed method, we consider various parametrizations of the loss function and describe different algorithm design options and how they may affect meta-learning performance.},
	urldate = {2021-09-02},
	journal = {arXiv:2107.05544 [cs]},
	author = {Psaros, Apostolos F. and Kawaguchi, Kenji and Karniadakis, George Em},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.05544},
	keywords = {Computer Science - Machine Learning},
}

@article{jagtap_deep_2021,
	title = {Deep {Kronecker} neural networks: {A} general framework for neural networks with adaptive activation functions},
	shorttitle = {Deep {Kronecker} neural networks},
	url = {http://arxiv.org/abs/2105.09513},
	abstract = {We propose a new type of neural networks, Kronecker neural networks (KNNs), that form a general framework for neural networks with adaptive activation functions. KNNs employ the Kronecker product, which provides an efficient way of constructing a very wide network while keeping the number of parameters low. Our theoretical analysis reveals that under suitable conditions, KNNs induce a faster decay of the loss than that by the feed-forward networks. This is also empirically verified through a set of computational examples. Furthermore, under certain technical assumptions, we establish global convergence of gradient descent for KNNs. As a specific case, we propose the Rowdy activation function that is designed to get rid of any saturation region by injecting sinusoidal fluctuations, which include trainable parameters. The proposed Rowdy activation function can be employed in any neural network architecture like feed-forward neural networks, Recurrent neural networks, Convolutional neural networks etc. The effectiveness of KNNs with Rowdy activation is demonstrated through various computational experiments including function approximation using feed-forward neural networks, solution inference of partial differential equations using the physics-informed neural networks, and standard deep learning benchmark problems using convolutional and fully-connected neural networks.},
	urldate = {2021-09-02},
	journal = {arXiv:2105.09513 [cs]},
	author = {Jagtap, Ameya D. and Shin, Yeonjong and Kawaguchi, Kenji and Karniadakis, George Em},
	month = may,
	year = {2021},
	note = {arXiv: 2105.09513},
	keywords = {Computer Science - Machine Learning},
}

@article{deng_convergence_2021,
	title = {Convergence rate of {DeepONets} for learning operators arising from advection-diffusion equations},
	url = {http://arxiv.org/abs/2102.10621},
	abstract = {We present convergence analysis of operator learning in [Chen and Chen 1995] and [Lu et al. 2020], where continuous operators are approximated by a sum of products of branch and trunk networks. In this work, we consider the rates of learning solution operators from both linear and nonlinear advection-diffusion equations with or without reaction. We find that the convergence rates depend on the architecture of branch networks as well as the smoothness of inputs and outputs of solution operators.},
	urldate = {2021-09-02},
	journal = {arXiv:2102.10621 [cs, math]},
	author = {Deng, Beichuan and Shin, Yeonjong and Lu, Lu and Zhang, Zhongqiang and Karniadakis, George Em},
	month = mar,
	year = {2021},
	note = {arXiv: 2102.10621},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Numerical Analysis},
}

@article{gao_phygeonet_2021,
	title = {{PhyGeoNet}: {Physics}-{Informed} {Geometry}-{Adaptive} {Convolutional} {Neural} {Networks} for {Solving} {Parameterized} {Steady}-{State} {PDEs} on {Irregular} {Domain}},
	volume = {428},
	issn = {00219991},
	shorttitle = {{PhyGeoNet}},
	url = {http://arxiv.org/abs/2004.13145},
	doi = {10.1016/j.jcp.2020.110079},
	abstract = {Recently, the advent of deep learning has spurred interest in the development of physics-informed neural networks (PINN) for efficiently solving partial differential equations (PDEs), particularly in a parametric setting. Among all different classes of deep neural networks, the convolutional neural network (CNN) has attracted increasing attention in the scientific machine learning community, since the parameter-sharing feature in CNN enables efficient learning for problems with large-scale spatiotemporal fields. However, one of the biggest challenges is that CNN only can handle regular geometries with image-like format (i.e., rectangular domains with uniform grids). In this paper, we propose a novel physics-constrained CNN learning architecture, aiming to learn solutions of parametric PDEs on irregular domains without any labeled data. In order to leverage powerful classic CNN backbones, elliptic coordinate mapping is introduced to enable coordinate transforms between the irregular physical domain and regular reference domain. The proposed method has been assessed by solving a number of PDEs on irregular domains, including heat equations and steady Navier-Stokes equations with parameterized boundary conditions and varying geometries. Moreover, the proposed method has also been compared against the state-of-the-art PINN with fully-connected neural network (FC-NN) formulation. The numerical results demonstrate the effectiveness of the proposed approach and exhibit notable superiority over the FC-NN based PINN in terms of efficiency and accuracy.},
	urldate = {2021-09-02},
	journal = {Journal of Computational Physics},
	author = {Gao, Han and Sun, Luning and Wang, Jian-Xun},
	month = mar,
	year = {2021},
	note = {arXiv: 2004.13145},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Physics - Fluid Dynamics},
	pages = {110079},
}

@article{liu_roundtrip_2021,
	title = {Roundtrip: {A} {Deep} {Generative} {Neural} {Density} {Estimator}},
	volume = {118},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Roundtrip},
	url = {http://arxiv.org/abs/2004.09017},
	doi = {10.1073/pnas.2101344118},
	abstract = {Density estimation is a fundamental problem in both statistics and machine learning. In this study, we proposed Roundtrip as a general-purpose neural density estimator based on deep generative models. Roundtrip retains the generative power of generative adversarial networks (GANs) but also provides estimates of density values. Unlike previous neural density estimators that put stringent conditions on the transformation from the latent space to the data space, Roundtrip enables the use of much more general mappings. In a series of experiments, Roundtrip achieves state-of-the-art performance in a diverse range of density estimation tasks.},
	number = {15},
	urldate = {2021-08-26},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Liu, Qiao and Xu, Jiaze and Jiang, Rui and Wong, Wing Hung},
	month = apr,
	year = {2021},
	note = {arXiv: 2004.09017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	pages = {e2101344118},
}

@article{li_deep_2020,
	title = {Deep {Learning} via {Dynamical} {Systems}: {An} {Approximation} {Perspective}},
	shorttitle = {Deep {Learning} via {Dynamical} {Systems}},
	url = {http://arxiv.org/abs/1912.10382},
	abstract = {We build on the dynamical systems approach to deep learning, where deep residual networks are idealized as continuous-time dynamical systems, from the approximation perspective. In particular, we establish general sufficient conditions for universal approximation using continuous-time deep residual networks, which can also be understood as approximation theories in \$L{\textasciicircum}p\$ using flow maps of dynamical systems. In specific cases, rates of approximation in terms of the time horizon are also established. Overall, these results reveal that composition function approximation through flow maps present a new paradigm in approximation theory and contributes to building a useful mathematical framework to investigate deep learning.},
	urldate = {2021-08-19},
	journal = {arXiv:1912.10382 [cs, math, stat]},
	author = {Li, Qianxiao and Lin, Ting and Shen, Zuowei},
	month = jun,
	year = {2020},
	note = {arXiv: 1912.10382},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@article{morrill_neural_2021,
	title = {Neural {Rough} {Differential} {Equations} for {Long} {Time} {Series}},
	url = {http://arxiv.org/abs/2009.08295},
	abstract = {Neural controlled differential equations (CDEs) are the continuous-time analogue of recurrent neural networks, as Neural ODEs are to residual networks, and offer a memory-efficient continuous-time way to model functions of potentially irregular time series. Existing methods for computing the forward pass of a Neural CDE involve embedding the incoming time series into path space, often via interpolation, and using evaluations of this path to drive the hidden state. Here, we use rough path theory to extend this formulation. Instead of directly embedding into path space, we instead represent the input signal over small time intervals through its {\textbackslash}textit\{log-signature\}, which are statistics describing how the signal drives a CDE. This is the approach for solving {\textbackslash}textit\{rough differential equations\} (RDEs), and correspondingly we describe our main contribution as the introduction of Neural RDEs. This extension has a purpose: by generalising the Neural CDE approach to a broader class of driving signals, we demonstrate particular advantages for tackling long time series. In this regime, we demonstrate efficacy on problems of length up to 17k observations and observe significant training speed-ups, improvements in model performance, and reduced memory requirements compared to existing approaches.},
	urldate = {2021-08-19},
	journal = {arXiv:2009.08295 [cs, math, stat]},
	author = {Morrill, James and Salvi, Cristopher and Kidger, Patrick and Foster, James and Lyons, Terry},
	month = jun,
	year = {2021},
	note = {arXiv: 2009.08295},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Dynamical Systems, Statistics - Machine Learning},
}

@article{quaglino_snode_2020,
	title = {{SNODE}: {Spectral} {Discretization} of {Neural} {ODEs} for {System} {Identification}},
	shorttitle = {{SNODE}},
	url = {http://arxiv.org/abs/1906.07038},
	abstract = {This paper proposes the use of spectral element methods {\textbackslash}citep\{canuto\_spectral\_1988\} for fast and accurate training of Neural Ordinary Differential Equations (ODE-Nets; {\textbackslash}citealp\{Chen2018NeuralOD\}) for system identification. This is achieved by expressing their dynamics as a truncated series of Legendre polynomials. The series coefficients, as well as the network weights, are computed by minimizing the weighted sum of the loss function and the violation of the ODE-Net dynamics. The problem is solved by coordinate descent that alternately minimizes, with respect to the coefficients and the weights, two unconstrained sub-problems using standard backpropagation and gradient methods. The resulting optimization scheme is fully time-parallel and results in a low memory footprint. Experimental comparison to standard methods, such as backpropagation through explicit solvers and the adjoint technique {\textbackslash}citep\{Chen2018NeuralOD\}, on training surrogate models of small and medium-scale dynamical systems shows that it is at least one order of magnitude faster at reaching a comparable value of the loss function. The corresponding testing MSE is one order of magnitude smaller as well, suggesting generalization capabilities increase.},
	urldate = {2021-08-18},
	journal = {arXiv:1906.07038 [cs]},
	author = {Quaglino, Alessio and Gallieri, Marco and Masci, Jonathan and Koutník, Jan},
	month = jan,
	year = {2020},
	note = {arXiv: 1906.07038},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{gholami_anode_2019,
	title = {{ANODE}: {Unconditionally} {Accurate} {Memory}-{Efficient} {Gradients} for {Neural} {ODEs}},
	shorttitle = {{ANODE}},
	url = {http://arxiv.org/abs/1902.10298},
	abstract = {Residual neural networks can be viewed as the forward Euler discretization of an Ordinary Differential Equation (ODE) with a unit time step. This has recently motivated researchers to explore other discretization approaches and train ODE based networks. However, an important challenge of neural ODEs is their prohibitive memory cost during gradient backpropogation. Recently a method proposed in [8], claimed that this memory overhead can be reduced from O(LN\_t), where N\_t is the number of time steps, down to O(L) by solving forward ODE backwards in time, where L is the depth of the network. However, we will show that this approach may lead to several problems: (i) it may be numerically unstable for ReLU/non-ReLU activations and general convolution operators, and (ii) the proposed optimize-then-discretize approach may lead to divergent training due to inconsistent gradients for small time step sizes. We discuss the underlying problems, and to address them we propose ANODE, an Adjoint based Neural ODE framework which avoids the numerical instability related problems noted above, and provides unconditionally accurate gradients. ANODE has a memory footprint of O(L) + O(N\_t), with the same computational cost as reversing ODE solve. We furthermore, discuss a memory efficient algorithm which can further reduce this footprint with a trade-off of additional computational cost. We show results on Cifar-10/100 datasets using ResNet and SqueezeNext neural networks.},
	urldate = {2021-08-18},
	journal = {arXiv:1902.10298 [cs]},
	author = {Gholami, Amir and Keutzer, Kurt and Biros, George},
	month = jul,
	year = {2019},
	note = {arXiv: 1902.10298},
	keywords = {Computer Science - Machine Learning},
}

@article{rodriguez-torrado_physics-informed_2021,
	title = {Physics-informed attention-based neural network for solving non-linear partial differential equations},
	url = {http://arxiv.org/abs/2105.07898},
	abstract = {Physics-Informed Neural Networks (PINNs) have enabled significant improvements in modelling physical processes described by partial differential equations (PDEs). PINNs are based on simple architectures, and learn the behavior of complex physical systems by optimizing the network parameters to minimize the residual of the underlying PDE. Current network architectures share some of the limitations of classical numerical discretization schemes when applied to non-linear differential equations in continuum mechanics. A paradigmatic example is the solution of hyperbolic conservation laws that develop highly localized nonlinear shock waves. Learning solutions of PDEs with dominant hyperbolic character is a challenge for current PINN approaches, which rely, like most grid-based numerical schemes, on adding artificial dissipation. Here, we address the fundamental question of which network architectures are best suited to learn the complex behavior of non-linear PDEs. We focus on network architecture rather than on residual regularization. Our new methodology, called Physics-Informed Attention-based Neural Networks, (PIANNs), is a combination of recurrent neural networks and attention mechanisms. The attention mechanism adapts the behavior of the deep neural network to the non-linear features of the solution, and break the current limitations of PINNs. We find that PIANNs effectively capture the shock front in a hyperbolic model problem, and are capable of providing high-quality solutions inside and beyond the training set.},
	urldate = {2021-08-18},
	journal = {arXiv:2105.07898 [cs]},
	author = {Rodriguez-Torrado, Ruben and Ruiz, Pablo and Cueto-Felgueroso, Luis and Green, Michael Cerny and Friesen, Tyler and Matringe, Sebastien and Togelius, Julian},
	month = may,
	year = {2021},
	note = {arXiv: 2105.07898},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{roehrl_modeling_2020,
	title = {Modeling {System} {Dynamics} with {Physics}-{Informed} {Neural} {Networks} {Based} on {Lagrangian} {Mechanics}},
	volume = {53},
	issn = {24058963},
	url = {http://arxiv.org/abs/2005.14617},
	doi = {10.1016/j.ifacol.2020.12.2182},
	abstract = {Identifying accurate dynamic models is required for the simulation and control of various technical systems. In many important real-world applications, however, the two main modeling approaches often fail to meet requirements: first principles methods suffer from high bias, whereas data-driven modeling tends to have high variance. Additionally, purely data-based models often require large amounts of data and are often difficult to interpret. In this paper, we present physics-informed neural ordinary differential equations (PINODE), a hybrid model that combines the two modeling techniques to overcome the aforementioned problems. This new approach directly incorporates the equations of motion originating from the Lagrange Mechanics into a deep neural network structure. Thus, we can integrate prior physics knowledge where it is available and use function approximation--e. g., neural networks--where it is not. The method is tested with a forward model of a real-world physical system with large uncertainties. The resulting model is accurate and data-efficient while ensuring physical plausibility. With this, we demonstrate a method that beneficially merges physical insight with real data. Our findings are of interest for model-based control and system identification of mechanical systems.},
	number = {2},
	urldate = {2021-08-18},
	journal = {IFAC-PapersOnLine},
	author = {Roehrl, Manuel A. and Runkler, Thomas A. and Brandtstetter, Veronika and Tokic, Michel and Obermayer, Stefan},
	year = {2020},
	note = {arXiv: 2005.14617},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {9195--9200},
}

@article{lai_structural_2021,
	title = {Structural identification with physics-informed neural ordinary differential equations},
	volume = {508},
	issn = {0022-460X},
	url = {https://www.sciencedirect.com/science/article/pii/S0022460X21002686},
	doi = {10.1016/j.jsv.2021.116196},
	abstract = {This paper exploits a new direction of structural identification by means of Neural Ordinary Differential Equations (Neural ODEs), particularly constrained by domain knowledge, such as structural dynamics, thus forming Physics-informed Neural ODEs, aiming at governing equations discovery/approximation. Structural identification problems often entail complex setups featuring high-dimensionality, or stiff ODEs, which pose difficulties in the training and learning of conventional data-driven algorithms who seek to unveil the governing dynamics of a system of interest. In this work, Neural ODEs are re-casted as a two-level representation involving a physics-informed term, that stems from possible prior knowledge of a dynamical system, and a discrepancy term, captured by means of a feed-forward neural network. The re-casted format is highly adaptive and flexible to structural monitoring problems, such as linear/nonlinear structural identification, model updating, structural damage detection, driving force identification, etc. As an added step, for inferring an explainable model, we propose the adoption of sparse identification of nonlinear dynamical systems as an additional tool to distill closed-form expressions for the trained nets, that embed a more straightforward engineering interpretation. We demonstrate the framework on a series of numerical and experimental examples, with the latter pertaining to a structural system featuring highly nonlinear behavior, which is successfully learned by the proposed framework. The proposed structural identification with Physics-informed Neural ODEs comes with the benefits of direct approximation of the governing dynamics, and a versatile and flexible framework for discrepancy modeling in structural identification problems.},
	language = {en},
	urldate = {2021-08-18},
	journal = {Journal of Sound and Vibration},
	author = {Lai, Zhilu and Mylonas, Charilaos and Nagarajaiah, Satish and Chatzi, Eleni},
	month = sep,
	year = {2021},
	keywords = {Discrepancy modeling, Neural ordinary differential equations, Physics-informed machine learning, Scientific machine learning, Structural damage detection, Structural health monitoring, Structural identification},
	pages = {116196},
}

@article{maulik_time-series_2020,
	title = {Time-series learning of latent-space dynamics for reduced-order model closure},
	volume = {405},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278919305536},
	doi = {10.1016/j.physd.2020.132368},
	abstract = {We study the performance of long short-term memory networks (LSTMs) and neural ordinary differential equations (NODEs) in learning latent-space representations of dynamical equations for an advection-dominated problem given by the viscous Burgers equation. Our formulation is devised in a nonintrusive manner with an equation-free evolution of dynamics in a reduced space with the latter being obtained through a proper orthogonal decomposition. In addition, we leverage the sequential nature of learning for both LSTMs and NODEs to demonstrate their capability for closure in systems that are not completely resolved in the reduced space. We assess our hypothesis for two advection-dominated problems given by the viscous Burgers equation. We observe that both LSTMs and NODEs are able to reproduce the effects of the absent scales for our test cases more effectively than does intrusive dynamics evolution through a Galerkin projection. This result empirically suggests that time-series learning techniques implicitly leverage a memory kernel for coarse-grained system closure as is suggested through the Mori–Zwanzig formalism.},
	language = {en},
	urldate = {2021-08-18},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Maulik, Romit and Mohan, Arvind and Lusch, Bethany and Madireddy, Sandeep and Balaprakash, Prasanna and Livescu, Daniel},
	month = apr,
	year = {2020},
	keywords = {Closures, LSTMs, Neural ODEs, ROMs},
	pages = {132368},
}

@article{mohan_learning_2021-1,
	title = {Learning {Stable} {Galerkin} {Models} of {Turbulence} with {Differentiable} {Programming}},
	url = {http://arxiv.org/abs/2107.07559},
	abstract = {Turbulent flow control has numerous applications and building reduced-order models (ROMs) of the flow and the associated feedback control laws is extremely challenging. Despite the complexity of building data-driven ROMs for turbulence, the superior representational capacity of deep neural networks has demonstrated considerable success in learning ROMs. Nevertheless, these strategies are typically devoid of physical foundations and often lack interpretability. Conversely, the Proper Orthogonal Decomposition (POD) based Galerkin projection (GP) approach for ROM has been popular in many problems owing to its theoretically consistent and explainable physical foundations. However, a key limitation is that the ordinary differential equations (ODEs) arising from GP ROMs are highly susceptible to instabilities due to truncation of POD modes and lead to deterioration in temporal predictions. In this work, we propose a {\textbackslash}textit\{differentiable programming\} approach that blends the strengths of both these strategies, by embedding neural networks explicitly into the GP ODE structure, termed Neural Galerkin projection. We demonstrate this approach on the isentropic Navier-Stokes equations for compressible flow over a cavity at a moderate Mach number. When provided the structure of the projected equations, we show that the Neural Galerkin approach implicitly learns stable ODE coefficients from POD coefficients and demonstrates significantly longer and accurate time horizon predictions, when compared to the classical POD-GP assisted by calibration. We observe that the key benefits of this differentiable programming-based approach include increased flexibility in physics-based learning, very low computational costs, and a significant increase in interpretability, when compared to purely data-driven neural networks.},
	urldate = {2021-08-18},
	journal = {arXiv:2107.07559 [nlin, physics:physics]},
	author = {Mohan, Arvind T. and Nagarajan, Kaushik and Livescu, Daniel},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.07559},
	keywords = {Nonlinear Sciences - Chaotic Dynamics, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{lee_parameterized_2020,
	title = {Parameterized {Neural} {Ordinary} {Differential} {Equations}: {Applications} to {Computational} {Physics} {Problems}},
	shorttitle = {Parameterized {Neural} {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.14685},
	abstract = {This work proposes an extension of neural ordinary differential equations (NODEs) by introducing an additional set of ODE input parameters to NODEs. This extension allows NODEs to learn multiple dynamics specified by the input parameter instances. Our extension is inspired by the concept of parameterized ordinary differential equations, which are widely investigated in computational science and engineering contexts, where characteristics of the governing equations vary over the input parameters. We apply the proposed parameterized NODEs (PNODEs) for learning latent dynamics of complex dynamical processes that arise in computational physics, which is an essential component for enabling rapid numerical simulations for time-critical physics applications. For this, we propose an encoder-decoder-type framework, which models latent dynamics as PNODEs. We demonstrate the effectiveness of PNODEs with important benchmark problems from computational physics.},
	urldate = {2021-08-18},
	journal = {arXiv:2010.14685 [physics]},
	author = {Lee, Kookjin and Parish, Eric J.},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.14685},
	keywords = {Computer Science - Artificial Intelligence, Physics - Computational Physics},
}

@article{kidger_neural_2020,
	title = {Neural {Controlled} {Differential} {Equations} for {Irregular} {Time} {Series}},
	url = {http://arxiv.org/abs/2005.08926},
	abstract = {Neural ordinary differential equations are an attractive option for modelling temporal dynamics. However, a fundamental issue is that the solution to an ordinary differential equation is determined by its initial condition, and there is no mechanism for adjusting the trajectory based on subsequent observations. Here, we demonstrate how this may be resolved through the well-understood mathematics of {\textbackslash}emph\{controlled differential equations\}. The resulting {\textbackslash}emph\{neural controlled differential equation\} model is directly applicable to the general setting of partially-observed irregularly-sampled multivariate time series, and (unlike previous work on this problem) it may utilise memory-efficient adjoint-based backpropagation even across observations. We demonstrate that our model achieves state-of-the-art performance against similar (ODE or RNN based) models in empirical studies on a range of datasets. Finally we provide theoretical results demonstrating universal approximation, and that our model subsumes alternative ODE models.},
	urldate = {2021-08-18},
	journal = {arXiv:2005.08926 [cs, stat]},
	author = {Kidger, Patrick and Morrill, James and Foster, James and Lyons, Terry},
	month = nov,
	year = {2020},
	note = {arXiv: 2005.08926},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lalescu_transitions_2021,
	title = {Transitions of turbulent superstructures in generalized {Kolmogorov} flow},
	volume = {3},
	issn = {2643-1564},
	url = {http://arxiv.org/abs/2102.07675},
	doi = {10.1103/PhysRevResearch.3.L022010},
	abstract = {Self-organized large-scale flow structures occur in a wide range of turbulent flows. Yet, their emergence, dynamics, and interplay with small-scale turbulence are not well understood. Here, we investigate such self-organized turbulent superstructures in three-dimensional turbulent Kolmogorov flow with large-scale drag. Through extensive simulations, we uncover their low-dimensional dynamics featuring transitions between several stable and meta-stable large-scale structures as a function of the damping parameter. The main dissipation mechanism for the turbulent superstructures is the generation of small-scale turbulence, whose local structure depends strongly on the large-scale flow. Our results elucidate the generic emergence and low-dimensional dynamics of large-scale flow structures in fully developed turbulence and reveal a strong coupling of large- and small-scale flow features.},
	number = {2},
	urldate = {2021-08-17},
	journal = {Physical Review Research},
	author = {Lalescu, Cristian C. and Wilczek, Michael},
	month = may,
	year = {2021},
	note = {arXiv: 2102.07675},
	keywords = {Physics - Fluid Dynamics},
	pages = {L022010},
}

@article{li_markov_2021,
	title = {Markov {Neural} {Operators} for {Learning} {Chaotic} {Systems}},
	url = {http://arxiv.org/abs/2106.06898},
	abstract = {Chaotic systems are notoriously challenging to predict because of their instability. Small errors accumulate in the simulation of each time step, resulting in completely different trajectories. However, the trajectories of many prominent chaotic systems live in a low-dimensional subspace (attractor). If the system is Markovian, the attractor is uniquely determined by the Markov operator that maps the evolution of infinitesimal time steps. This makes it possible to predict the behavior of the chaotic system by learning the Markov operator even if we cannot predict the exact trajectory. Recently, a new framework for learning resolution-invariant solution operators for PDEs was proposed, known as neural operators. In this work, we train a Markov neural operator (MNO) with only the local one-step evolution information. We then compose the learned operator to obtain the global attractor and invariant measure. Such a Markov neural operator forms a discrete semigroup and we empirically observe that does not collapse or blow up. Experiments show neural operators are more accurate and stable compared to previous methods on chaotic systems such as the Kuramoto-Sivashinsky and Navier-Stokes equations.},
	urldate = {2021-08-17},
	journal = {arXiv:2106.06898 [cs, math]},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.06898},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems},
}

@article{wang_long-time_2021,
	title = {Long-time integration of parametric evolution equations with physics-informed {DeepONets}},
	url = {http://arxiv.org/abs/2106.05384},
	abstract = {Ordinary and partial differential equations (ODEs/PDEs) play a paramount role in analyzing and simulating complex dynamic processes across all corners of science and engineering. In recent years machine learning tools are aspiring to introduce new effective ways of simulating PDEs, however existing approaches are not able to reliably return stable and accurate predictions across long temporal horizons. We aim to address this challenge by introducing an effective framework for learning infinite-dimensional operators that map random initial conditions to associated PDE solutions within a short time interval. Such latent operators can be parametrized by deep neural networks that are trained in an entirely self-supervised manner without requiring any paired input-output observations. Global long-time predictions across a range of initial conditions can be then obtained by iteratively evaluating the trained model using each prediction as the initial condition for the next evaluation step. This introduces a new approach to temporal domain decomposition that is shown to be effective in performing accurate long-time simulations for a wide range of parametric ODE and PDE systems, from wave propagation, to reaction-diffusion dynamics and stiff chemical kinetics, all at a fraction of the computational cost needed by classical numerical solvers.},
	urldate = {2021-08-17},
	journal = {arXiv:2106.05384 [physics]},
	author = {Wang, Sifan and Perdikaris, Paris},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.05384},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{page_revealing_2021,
	title = {Revealing the state space of turbulence using machine learning},
	volume = {6},
	issn = {2469-990X},
	url = {http://arxiv.org/abs/2008.07515},
	doi = {10.1103/PhysRevFluids.6.034402},
	abstract = {Despite the apparent complexity of turbulent flow, identifying a simpler description of the underlying dynamical system remains a fundamental challenge. Capturing how the turbulent flow meanders amongst unstable states (simple invariant solutions) in phase space, as envisaged by Hopf in 1948, using some efficient representation offers the best hope of doing this, despite the inherent difficulty in identifying these states. Here, we make a significant step towards this goal by demonstrating that deep convolutional autoencoders can identify low-dimensional representations of two-dimensional turbulence which are closely associated with the simple invariant solutions characterizing the turbulent attractor. To establish this, we develop latent Fourier analysis that decomposes the flow embedding into a set of orthogonal latent Fourier modes which decode into physically meaningful patterns resembling simple invariant solutions. The utility of this approach is highlighted by analysing turbulent Kolmogorov flow (flow on a 2D torus forced at large scale) at \$Re=40\$ where, in between intermittent bursts, the flow resides in the neighbourhood of an unstable state and is very low dimensional. Projections onto individual latent Fourier wavenumbers reveal the simple invariant solutions organising both the quiescent and bursting dynamics in a systematic way inaccessible to previous approaches.},
	number = {3},
	urldate = {2021-08-16},
	journal = {Physical Review Fluids},
	author = {Page, Jacob and Brenner, Michael P. and Kerswell, Rich R.},
	month = mar,
	year = {2021},
	note = {arXiv: 2008.07515},
	keywords = {Physics - Fluid Dynamics},
	pages = {034402},
}

@article{cai_flow_2021,
	title = {Flow over an espresso cup: inferring 3-{D} velocity and pressure fields from tomographic background oriented {Schlieren} via physics-informed neural networks},
	volume = {915},
	issn = {0022-1120, 1469-7645},
	shorttitle = {Flow over an espresso cup},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/flow-over-an-espresso-cup-inferring-3d-velocity-and-pressure-fields-from-tomographic-background-oriented-schlieren-via-physicsinformed-neural-networks/160E4A836637FE3996610389666DA030},
	doi = {10.1017/jfm.2021.135},
	abstract = {, 
Tomographic background oriented Schlieren (Tomo-BOS) imaging measures density or temperature fields in three dimensions using multiple camera BOS projections, and is particularly useful for instantaneous flow visualizations of complex fluid dynamics problems. We propose a new method based on physics-informed neural networks (PINNs) to infer the full continuous three-dimensional (3-D) velocity and pressure fields from snapshots of 3-D temperature fields obtained by Tomo-BOS imaging. The PINNs seamlessly integrate the underlying physics of the observed fluid flow and the visualization data, hence enabling the inference of latent quantities using limited experimental data. In this hidden fluid mechanics paradigm, we train the neural network by minimizing a loss function composed of a data mismatch term and residual terms associated with the coupled Navier–Stokes and heat transfer equations. We first quantify the accuracy of the proposed method based on a two-dimensional synthetic data set for buoyancy-driven flow, and subsequently apply it to the Tomo-BOS data set, where we are able to infer the instantaneous velocity and pressure fields of the flow over an espresso cup based only on the temperature field provided by the Tomo-BOS imaging. Moreover, we conduct an independent PIV experiment to validate the PINN inference for the unsteady velocity field at a centre plane. To explain the observed flow physics, we also perform systematic PINN simulations at different Reynolds and Richardson numbers and quantify the variations in velocity and pressure fields. The results in this paper indicate that the proposed deep learning technique can become a promising direction in experimental fluid mechanics.},
	language = {en},
	urldate = {2021-08-16},
	journal = {Journal of Fluid Mechanics},
	author = {Cai, Shengze and Wang, Zhicheng and Fuest, Frederik and Jeon, Young Jin and Gray, Callum and Karniadakis, George Em},
	month = may,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, convection, machine learning},
}

@article{cai_physics-informed_2021,
	title = {Physics-informed neural networks ({PINNs}) for fluid mechanics: {A} review},
	shorttitle = {Physics-informed neural networks ({PINNs}) for fluid mechanics},
	url = {http://arxiv.org/abs/2105.09506},
	abstract = {Despite the significant progress over the last 50 years in simulating flow problems using numerical discretization of the Navier-Stokes equations (NSE), we still cannot incorporate seamlessly noisy data into existing algorithms, mesh-generation is complex, and we cannot tackle high-dimensional problems governed by parametrized NSE. Moreover, solving inverse flow problems is often prohibitively expensive and requires complex and expensive formulations and new computer codes. Here, we review flow physics-informed learning, integrating seamlessly data and mathematical models, and implementing them using physics-informed neural networks (PINNs). We demonstrate the effectiveness of PINNs for inverse problems related to three-dimensional wake flows, supersonic flows, and biomedical flows.},
	urldate = {2021-08-16},
	journal = {arXiv:2105.09506 [physics]},
	author = {Cai, Shengze and Mao, Zhiping and Wang, Zhicheng and Yin, Minglang and Karniadakis, George Em},
	month = may,
	year = {2021},
	note = {arXiv: 2105.09506},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@article{li_deep_2020,
	title = {Deep {Learning} via {Dynamical} {Systems}: {An} {Approximation} {Perspective}},
	shorttitle = {Deep {Learning} via {Dynamical} {Systems}},
	url = {http://arxiv.org/abs/1912.10382},
	abstract = {We build on the dynamical systems approach to deep learning, where deep residual networks are idealized as continuous-time dynamical systems, from the approximation perspective. In particular, we establish general sufficient conditions for universal approximation using continuous-time deep residual networks, which can also be understood as approximation theories in \$L{\textasciicircum}p\$ using flow maps of dynamical systems. In specific cases, rates of approximation in terms of the time horizon are also established. Overall, these results reveal that composition function approximation through flow maps present a new paradigm in approximation theory and contributes to building a useful mathematical framework to investigate deep learning.},
	urldate = {2021-08-16},
	journal = {arXiv:1912.10382 [cs, math, stat]},
	author = {Li, Qianxiao and Lin, Ting and Shen, Zuowei},
	month = jun,
	year = {2020},
	note = {arXiv: 1912.10382},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@article{swischuk_projection-based_2019,
	title = {Projection-based model reduction: {Formulations} for physics-based machine learning},
	volume = {179},
	issn = {0045-7930},
	shorttitle = {Projection-based model reduction},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793018304250},
	doi = {10.1016/j.compfluid.2018.07.021},
	abstract = {This paper considers the creation of parametric surrogate models for applications in science and engineering where the goal is to predict high-dimensional output quantities of interest, such as pressure, temperature and strain fields. The proposed methodology develops a low-dimensional parametrization of these quantities of interest using the proper orthogonal decomposition (POD), and combines this parametrization with machine learning methods to learn the map between the input parameters and the POD expansion coefficients. The use of particular solutions in the POD expansion provides a way to embed physical constraints, such as boundary conditions and other features of the solution that must be preserved. The relative costs and effectiveness of four different machine learning techniques—neural networks, multivariate polynomial regression, k-nearest-neighbors and decision trees—are explored through two engineering examples. The first example considers prediction of the pressure field around an airfoil, while the second considers prediction of the strain field over a damaged composite panel. The case studies demonstrate the importance of embedding physical constraints within learned models, and also highlight the important point that the amount of model training data available in an engineering setting is often much less than it is in other machine learning applications, making it essential to incorporate knowledge from physical models.},
	language = {en},
	urldate = {2021-08-16},
	journal = {Computers \& Fluids},
	author = {Swischuk, Renee and Mainini, Laura and Peherstorfer, Benjamin and Willcox, Karen},
	month = jan,
	year = {2019},
	keywords = {Data-driven reduced models, Model reduction, Physics-based machine learning, Proper orthogonal decomposition, Surrogate models},
	pages = {704--717},
}

@article{fresca_comprehensive_2020,
	title = {A comprehensive deep learning-based approach to reduced order modeling of nonlinear time-dependent parametrized {PDEs}},
	url = {http://arxiv.org/abs/2001.04001},
	abstract = {Traditional reduced order modeling techniques such as the reduced basis (RB) method (relying, e.g., on proper orthogonal decomposition (POD)) suffer from severe limitations when dealing with nonlinear time-dependent parametrized PDEs, because of the fundamental assumption of linear superimposition of modes they are based on. For this reason, in the case of problems featuring coherent structures that propagate over time such as transport, wave, or convection-dominated phenomena, the RB method usually yields inefficient reduced order models (ROMs) if one aims at obtaining reduced order approximations sufficiently accurate compared to the high-fidelity, full order model (FOM) solution. To overcome these limitations, in this work, we propose a new nonlinear approach to set reduced order models by exploiting deep learning (DL) algorithms. In the resulting nonlinear ROM, which we refer to as DL-ROM, both the nonlinear trial manifold (corresponding to the set of basis functions in a linear ROM) as well as the nonlinear reduced dynamics (corresponding to the projection stage in a linear ROM) are learned in a non-intrusive way by relying on DL algorithms; the latter are trained on a set of FOM solutions obtained for different parameter values. In this paper, we show how to construct a DL-ROM for both linear and nonlinear time-dependent parametrized PDEs; moreover, we assess its accuracy on test cases featuring different parametrized PDE problems. Numerical results indicate that DL-ROMs whose dimension is equal to the intrinsic dimensionality of the PDE solutions manifold are able to approximate the solution of parametrized PDEs in situations where a huge number of POD modes would be necessary to achieve the same degree of accuracy.},
	urldate = {2021-08-16},
	journal = {arXiv:2001.04001 [cs, math]},
	author = {Fresca, Stefania and Dede, Luca and Manzoni, Andrea},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.04001},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{lee_parameterized_2020,
	title = {Parameterized {Neural} {Ordinary} {Differential} {Equations}: {Applications} to {Computational} {Physics} {Problems}},
	shorttitle = {Parameterized {Neural} {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.14685},
	abstract = {This work proposes an extension of neural ordinary differential equations (NODEs) by introducing an additional set of ODE input parameters to NODEs. This extension allows NODEs to learn multiple dynamics specified by the input parameter instances. Our extension is inspired by the concept of parameterized ordinary differential equations, which are widely investigated in computational science and engineering contexts, where characteristics of the governing equations vary over the input parameters. We apply the proposed parameterized NODEs (PNODEs) for learning latent dynamics of complex dynamical processes that arise in computational physics, which is an essential component for enabling rapid numerical simulations for time-critical physics applications. For this, we propose an encoder-decoder-type framework, which models latent dynamics as PNODEs. We demonstrate the effectiveness of PNODEs with important benchmark problems from computational physics.},
	urldate = {2021-08-16},
	journal = {arXiv:2010.14685 [physics]},
	author = {Lee, Kookjin and Parish, Eric J.},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.14685},
	keywords = {Computer Science - Artificial Intelligence, Physics - Computational Physics},
}

@article{xia_bayesian_2021,
	title = {Bayesian multiscale deep generative model for the solution of high-dimensional inverse problems},
	url = {http://arxiv.org/abs/2102.03169},
	abstract = {Estimation of spatially-varying parameters for computationally expensive forward models governed by partial differential equations is addressed. A novel multiscale Bayesian inference approach is introduced based on deep probabilistic generative models. Such generative models provide a flexible representation by inferring on each scale a low-dimensional latent encoding while allowing hierarchical parameter generation from coarse- to fine-scales. Combining the multiscale generative model with Markov Chain Monte Carlo (MCMC), inference across scales is achieved enabling us to efficiently obtain posterior parameter samples at various scales. The estimation of coarse-scale parameters using a low-dimensional latent embedding captures global and notable parameter features using an inexpensive but inaccurate solver. MCMC sampling of the fine-scale parameters is enabled by utilizing the posterior information in the immediate coarser-scale. In this way, the global features are identified in the coarse-scale with inference of low-dimensional variables and inexpensive forward computation, and the local features are refined and corrected in the fine-scale. The developed method is demonstrated with two types of permeability estimation for flow in heterogeneous media. One is a Gaussian random field (GRF) with uncertain length scales, and the other is channelized permeability with the two regions defined by different GRFs. The obtained results indicate that the method allows high-dimensional parameter estimation while exhibiting stability, efficiency and accuracy.},
	urldate = {2021-07-23},
	journal = {arXiv:2102.03169 [cs, stat]},
	author = {Xia, Yingzhi and Zabaras, Nicholas},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.03169},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kashefi_point-cloud_2021,
	title = {A {Point}-{Cloud} {Deep} {Learning} {Framework} for {Prediction} of {Fluid} {Flow} {Fields} on {Irregular} {Geometries}},
	volume = {33},
	issn = {1070-6631, 1089-7666},
	url = {http://arxiv.org/abs/2010.09469},
	doi = {10.1063/5.0033376},
	abstract = {We present a novel deep learning framework for flow field predictions in irregular domains when the solution is a function of the geometry of either the domain or objects inside the domain. Grid vertices in a computational fluid dynamics (CFD) domain are viewed as point clouds and used as inputs to a neural network based on the PointNet architecture, which learns an end-to-end mapping between spatial positions and CFD quantities. Using our approach, (i) the network inherits desirable features of unstructured meshes (e.g., fine and coarse point spacing near the object surface and in the far field, respectively), which minimizes network training cost; (ii) object geometry is accurately represented through vertices located on object boundaries, which maintains boundary smoothness and allows the network to detect small changes between geometries; and (iii) no data interpolation is utilized for creating training data; thus accuracy of the CFD data is preserved. None of these features are achievable by extant methods based on projecting scattered CFD data into Cartesian grids and then using regular convolutional neural networks. Incompressible laminar steady flow past a cylinder with various shapes for its cross section is considered. The mass and momentum of predicted fields are conserved. For the first time, our network generalizes the predictions to multiple objects as well as an airfoil, even though only single objects and no airfoils are observed during training. The network predicts the flow fields hundreds of times faster than our conventional CFD solver, while maintaining excellent to reasonable accuracy.},
	number = {2},
	urldate = {2021-07-23},
	journal = {Physics of Fluids},
	author = {Kashefi, Ali and Rempe, Davis and Guibas, Leonidas J.},
	month = feb,
	year = {2021},
	note = {arXiv: 2010.09469},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
	pages = {027104},
}

@article{trask_gmls-nets_2019,
	title = {{GMLS}-{Nets}: {A} framework for learning from unstructured data},
	shorttitle = {{GMLS}-{Nets}},
	url = {http://arxiv.org/abs/1909.05371},
	abstract = {Data fields sampled on irregularly spaced points arise in many applications in the sciences and engineering. For regular grids, Convolutional Neural Networks (CNNs) have been successfully used to gaining benefits from weight sharing and invariances. We generalize CNNs by introducing methods for data on unstructured point clouds based on Generalized Moving Least Squares (GMLS). GMLS is a non-parametric technique for estimating linear bounded functionals from scattered data, and has recently been used in the literature for solving partial differential equations. By parameterizing the GMLS estimator, we obtain learning methods for operators with unstructured stencils. In GMLS-Nets the necessary calculations are local, readily parallelizable, and the estimator is supported by a rigorous approximation theory. We show how the framework may be used for unstructured physical data sets to perform functional regression to identify associated differential operators and to regress quantities of interest. The results suggest the architectures to be an attractive foundation for data-driven model development in scientific machine learning applications.},
	urldate = {2021-07-23},
	journal = {arXiv:1909.05371 [physics, stat]},
	author = {Trask, Nathaniel and Patel, Ravi G. and Gross, Ben J. and Atzberger, Paul J.},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.05371},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Physics - Data Analysis, Statistics and Probability, Statistics - Machine Learning},
}

@article{xu_multi-level_2020,
	title = {Multi-level {Convolutional} {Autoencoder} {Networks} for {Parametric} {Prediction} of {Spatio}-temporal {Dynamics}},
	volume = {372},
	issn = {00457825},
	url = {http://arxiv.org/abs/1912.11114},
	doi = {10.1016/j.cma.2020.113379},
	abstract = {A data-driven framework is proposed towards the end of predictive modeling of complex spatio-temporal dynamics, leveraging nested non-linear manifolds. Three levels of neural networks are used, with the goal of predicting the future state of a system of interest in a parametric setting. A convolutional autoencoder is used as the top level to encode the high dimensional input data along spatial dimensions into a sequence of latent variables. A temporal convolutional autoencoder (TCAE) serves as the second level, which further encodes the output sequence from the first level along the temporal dimension, and outputs a set of latent variables that encapsulate the spatio-temporal evolution of the dynamics. The use of dilated temporal convolutions grows the receptive field exponentially with network depth, allowing for efficient processing of long temporal sequences typical of scientific computations. A fully-connected network is used as the third level to learn the mapping between these latent variables and the global parameters from training data, and predict them for new parameters. For future state predictions, the second level uses a temporal convolutional network to predict subsequent steps of the output sequence from the top level. Latent variables at the bottom-most level are decoded to obtain the dynamics in physical space at new global parameters and/or at a future time. Predictive capabilities are evaluated on a range of problems involving discontinuities, wave propagation, strong transients, and coherent structures. The sensitivity of the results to different modeling choices is assessed. The results suggest that given adequate data and careful training, effective data-driven predictive models can be constructed. Perspectives are provided on the present approach and its place in the landscape of model reduction.},
	urldate = {2021-07-23},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Xu, Jiayang and Duraisamy, Karthik},
	month = dec,
	year = {2020},
	note = {arXiv: 1912.11114},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {113379},
}

@article{gonzalez_deep_2018,
	title = {Deep convolutional recurrent autoencoders for learning low-dimensional feature dynamics of fluid systems},
	url = {http://arxiv.org/abs/1808.01346},
	abstract = {Model reduction of high-dimensional dynamical systems alleviates computational burdens faced in various tasks from design optimization to model predictive control. One popular model reduction approach is based on projecting the governing equations onto a subspace spanned by basis functions obtained from the compression of a dataset of solution snapshots. However, this method is intrusive since the projection requires access to the system operators. Further, some systems may require special treatment of nonlinearities to ensure computational efficiency or additional modeling to preserve stability. In this work we propose a deep learning-based strategy for nonlinear model reduction that is inspired by projection-based model reduction where the idea is to identify some optimal low-dimensional representation and evolve it in time. Our approach constructs a modular model consisting of a deep convolutional autoencoder and a modified LSTM network. The deep convolutional autoencoder returns a low-dimensional representation in terms of coordinates on some expressive nonlinear data-supporting manifold. The dynamics on this manifold are then modeled by the modified LSTM network in a computationally efficient manner. An offline unsupervised training strategy that exploits the model modularity is also developed. We demonstrate our model on three illustrative examples each highlighting the model's performance in prediction tasks for fluid systems with large parameter-variations and its stability in long-term prediction.},
	urldate = {2021-07-23},
	journal = {arXiv:1808.01346 [physics]},
	author = {Gonzalez, Francisco J. and Balajewicz, Maciej},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.01346},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Physics - Fluid Dynamics},
}

@article{erichson_physics-informed_2019,
	title = {Physics-informed {Autoencoders} for {Lyapunov}-stable {Fluid} {Flow} {Prediction}},
	url = {http://arxiv.org/abs/1905.10866},
	abstract = {In addition to providing high-profile successes in computer vision and natural language processing, neural networks also provide an emerging set of techniques for scientific problems. Such data-driven models, however, typically ignore physical insights from the scientific system under consideration. Among other things, a physics-informed model formulation should encode some degree of stability or robustness or well-conditioning (in that a small change of the input will not lead to drastic changes in the output), characteristic of the underlying scientific problem. We investigate whether it is possible to include physics-informed prior knowledge for improving the model quality (e.g., generalization performance, sensitivity to parameter tuning, or robustness in the presence of noisy data). To that extent, we focus on the stability of an equilibrium, one of the most basic properties a dynamic system can have, via the lens of Lyapunov analysis. For the prototypical problem of fluid flow prediction, we show that models preserving Lyapunov stability improve the generalization error and reduce the prediction uncertainty.},
	urldate = {2021-07-23},
	journal = {arXiv:1905.10866 [physics]},
	author = {Erichson, N. Benjamin and Muehlebach, Michael and Mahoney, Michael W.},
	month = may,
	year = {2019},
	note = {arXiv: 1905.10866},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{makhzani_adversarial_2016,
	title = {Adversarial {Autoencoders}},
	url = {http://arxiv.org/abs/1511.05644},
	abstract = {In this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.},
	urldate = {2021-07-23},
	journal = {arXiv:1511.05644 [cs]},
	author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
	month = may,
	year = {2016},
	note = {arXiv: 1511.05644},
	keywords = {Computer Science - Machine Learning},
}

@article{nair_network-theoretic_2015,
	title = {Network-theoretic approach to sparsified discrete vortex dynamics},
	volume = {768},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/networktheoretic-approach-to-sparsified-discrete-vortex-dynamics/36FDB3F064A5FCC2EDF72D9D506D0A05},
	doi = {10.1017/jfm.2015.97},
	abstract = {We examine discrete vortex dynamics in two-dimensional flow through a network-theoretic approach. The interaction of the vortices is represented with a graph, which allows the use of network-theoretic approaches to identify key vortex-to-vortex interactions. We employ sparsification techniques on these graph representations based on spectral theory to construct sparsified models and evaluate the dynamics of vortices in the sparsified set-up. Identification of vortex structures based on graph sparsification and sparse vortex dynamics is illustrated through an example of point-vortex clusters interacting amongst themselves. We also evaluate the performance of sparsification with increasing number of point vortices. The sparsified-dynamics model developed with spectral graph theory requires a reduced number of vortex-to-vortex interactions but agrees well with the full nonlinear dynamics. Furthermore, the sparsified model derived from the sparse graphs conserves the invariants of discrete vortex dynamics. We highlight the similarities and differences between the present sparsified-dynamics model and reduced-order models.},
	language = {en},
	urldate = {2021-07-22},
	journal = {Journal of Fluid Mechanics},
	author = {Nair, Aditya G. and Taira, Kunihiko},
	month = apr,
	year = {2015},
	note = {Publisher: Cambridge University Press},
	keywords = {mathematical foundations, vortex dynamics, vortex interactions},
	pages = {549--571},
}

@article{jovanovic_bypass_2021,
	title = {From {Bypass} {Transition} to {Flow} {Control} and {Data}-{Driven} {Turbulence} {Modeling}: {An} {Input}–{Output} {Viewpoint}},
	volume = {53},
	issn = {0066-4189, 1545-4479},
	shorttitle = {From {Bypass} {Transition} to {Flow} {Control} and {Data}-{Driven} {Turbulence} {Modeling}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-010719-060244},
	doi = {10.1146/annurev-fluid-010719-060244},
	abstract = {Transient growth and resolvent analyses are routinely used to assess nonasymptotic properties of fluid flows. In particular, resolvent analysis can be interpreted as a special case of viewing flow dynamics as an open system in which free-stream turbulence, surface roughness, and other irregularities provide sources of input forcing. We offer a comprehensive summary of the tools that can be employed to probe the dynamics of fluctuations around a laminar or turbulent base flow in the presence of such stochastic or deterministic input forcing and describe how input–output techniques enhance resolvent analysis. Specifically, physical insights that may remain hidden in the resolvent analysis are gained by detailed examination of input–output responses between spatially localized body forces and selected linear combinations of state variables. This differentiating feature plays a key role in quantifying the importance of different mechanisms for bypass transition in wall-bounded shear flows and in explaining how turbulent jets generate noise. We highlight the utility of a stochastic framework, with white or colored inputs, in addressing a variety of open challenges including transition in complex fluids, flow control, and physics-aware data-driven turbulence modeling. Applications with temporally or spatially periodic base flows are discussed and future research directions are outlined.},
	language = {en},
	number = {1},
	urldate = {2021-07-22},
	journal = {Annual Review of Fluid Mechanics},
	author = {Jovanović, Mihailo R.},
	month = jan,
	year = {2021},
	pages = {311--345},
}

@article{sapsis_statistics_2021,
	title = {Statistics of {Extreme} {Events} in {Fluid} {Flows} and {Waves}},
	volume = {53},
	issn = {0066-4189, 1545-4479},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-030420-032810},
	doi = {10.1146/annurev-fluid-030420-032810},
	abstract = {Extreme events in fluid flows, waves, or structures interacting with them are critical for a wide range of areas, including reliability and design in engineering, as well as modeling risk of natural disasters. Such events are characterized by the coexistence of high intrinsic dimensionality, complex nonlinear dynamics, and stochasticity. These properties severely restrict the application of standard mathematical approaches, which have been successful in other areas. This review focuses on methods specifically formulated to deal with these properties and it is structured around two cases: (a) problems where an accurate but expensive model exists and (b) problems where a small amount of data and possibly an imperfect reduced-order model that encodes some physics about the extremes can be employed.},
	language = {en},
	number = {1},
	urldate = {2021-07-22},
	journal = {Annual Review of Fluid Mechanics},
	author = {Sapsis, Themistoklis P.},
	month = jan,
	year = {2021},
	pages = {85--111},
}

@article{moser_statistical_2021,
	title = {Statistical {Properties} of {Subgrid}-{Scale} {Turbulence} {Models}},
	volume = {53},
	issn = {0066-4189, 1545-4479},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-060420-023735},
	doi = {10.1146/annurev-fluid-060420-023735},
	abstract = {This review examines large eddy simulation (LES) models from the perspective of their a priori statistical characteristics. The most well-known statistical characteristic of an LES subgrid-scale model is its dissipation (energy transfer to unresolved scales), and many models are directly or indirectly formulated and tuned for consistency of this characteristic. However, in complex turbulent flows, many other subgrid statistical characteristics are important. These include such quantities as mean subgrid stress, subgrid transport of resolved Reynolds stress, and dissipation anisotropy. Also important are the statistical characteristics of models that account for filters that do not commute with differentiation and of the discrete numerical operators in the LES equations. We review the known statistical characteristics of subgrid models to assess these characteristics and the importance of their a priori consistency. We hope that this analysis will be helpful in continued development of LES models.},
	language = {en},
	number = {1},
	urldate = {2021-07-22},
	journal = {Annual Review of Fluid Mechanics},
	author = {Moser, Robert D. and Haering, Sigfried W. and Yalla, Gopal R.},
	month = jan,
	year = {2021},
	pages = {255--286},
}

@article{addanki_large-scale_2021,
	title = {Large-scale graph representation learning with very deep {GNNs} and self-supervision},
	url = {http://arxiv.org/abs/2107.09422},
	abstract = {Effectively and efficiently deploying graph neural networks (GNNs) at scale remains one of the most challenging aspects of graph representation learning. Many powerful solutions have only ever been validated on comparatively small datasets, often with counter-intuitive outcomes -- a barrier which has been broken by the Open Graph Benchmark Large-Scale Challenge (OGB-LSC). We entered the OGB-LSC with two large-scale GNNs: a deep transductive node classifier powered by bootstrapping, and a very deep (up to 50-layer) inductive graph regressor regularised by denoising objectives. Our models achieved an award-level (top-3) performance on both the MAG240M and PCQM4M benchmarks. In doing so, we demonstrate evidence of scalable self-supervised graph representation learning, and utility of very deep GNNs -- both very important open issues. Our code is publicly available at: https://github.com/deepmind/deepmind-research/tree/master/ogb\_lsc.},
	urldate = {2021-07-21},
	journal = {arXiv:2107.09422 [cs, stat]},
	author = {Addanki, Ravichandra and Battaglia, Peter W. and Budden, David and Deac, Andreea and Godwin, Jonathan and Keck, Thomas and Li, Wai Lok Sibon and Sanchez-Gonzalez, Alvaro and Stott, Jacklynn and Thakoor, Shantanu and Veličković, Petar},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.09422},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@article{frerix_variational_nodate,
	title = {Variational {Data} {Assimilation} with a {Learned} {Inverse} {Observation} {Operator}},
	abstract = {Variational data assimilation optimizes for an initial state of a dynamical system such that its evolution ﬁts observational data. The physical model can subsequently be evolved into the future to make predictions. This principle is a cornerstone of large scale forecasting applications such as numerical weather prediction. As such, it is implemented in current operational systems of weather forecasting agencies across the globe. However, ﬁnding a good initial state poses a difﬁcult optimization problem in part due to the non-invertible relationship between physical states and their corresponding observations. We learn a mapping from observational data to physical states and show how it can be used to improve optimizability. We employ this mapping in two ways: to better initialize the non-convex optimization problem, and to reformulate the objective function in better behaved physics space instead of observation space. Our experimental results for the Lorenz96 model and a two-dimensional turbulent ﬂuid ﬂow demonstrate that this procedure signiﬁcantly improves forecast quality for chaotic systems.},
	language = {en},
	author = {Frerix, Thomas and Kochkov, Dmitrii and Smith, Jamie A and Cremers, Daniel and Brenner, Michael P and Hoyer, Stephan},
	pages = {10},
}

@article{siddani_machine_2020,
	title = {Machine {Learning} for {Physics}-{Informed} {Generation} of {Dispersed} {Multiphase} {Flow} {Using} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/2005.05363},
	abstract = {Fluid flow around a random distribution of stationary spherical particles is a problem of substantial importance in the study of dispersed multiphase flows. In this paper we present a machine learning methodology using Generative Adversarial Network framework and Convolutional Neural Network architecture to recreate particle-resolved fluid flow around a random distribution of monodispersed particles. The model was applied to various Reynolds number and particle volume fraction combinations spanning over a range of [2.69, 172.96] and [0.11, 0.45] respectively. Test performance of the model for the studied cases is very promising.},
	urldate = {2021-07-20},
	journal = {arXiv:2005.05363 [physics]},
	author = {Siddani, B. and Balachandar, S. and Moore, W. C. and Yang, Y. and Fang, R.},
	month = may,
	year = {2020},
	note = {arXiv: 2005.05363},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{balachandar_toward_2020,
	title = {Toward particle-resolved accuracy in {Euler}–{Lagrange} simulations of multiphase flow using machine learning and pairwise interaction extended point-particle ({PIEP}) approximation},
	volume = {34},
	issn = {1432-2250},
	url = {https://doi.org/10.1007/s00162-020-00538-8},
	doi = {10.1007/s00162-020-00538-8},
	abstract = {This study presents two different machine learning approaches for the modeling of hydrodynamic force on particles in a particle-laden multiphase flow. Results from particle-resolved direct numerical simulations (PR-DNS) of flow over a random array of stationary particles for eight combinations of particle Reynolds number (\$\$\{{\textbackslash}mathrm \{Re\}\}\$\$) and volume fraction (\$\${\textbackslash}phi \$\$) are used in the development of the models. The first approach follows a two-step process. In the first flow prediction step, the perturbation flow due to a particle is obtained as an axisymmetric superposable wake using linear regression. In the second force prediction step, the force on a particle is evaluated in terms of the perturbation flow induced by all its neighbors using the generalized Faxén form of the force expression. In the second approach, the force data on all the particles from the PR-DNS simulations are used to develop an artificial neural network (ANN) model for direct prediction of force on a particle. Due to the unavoidable limitation on the number of fully resolved particles in the PR-DNS simulations, direct force prediction with the ANN model tends to over-fit the data and performs poorly in the prediction of test data. In contrast, due to the millions of grid points used in the PR-DNS simulations, accurate flow prediction is possible, which then allows accurate prediction of particle force. This hybridization of multiphase physics and machine learning is particularly important, since it blends the strength of each, and the resulting pairwise interaction extended point-particle model cannot be developed by either physics or machine learning alone.},
	language = {en},
	number = {4},
	urldate = {2021-07-20},
	journal = {Theoretical and Computational Fluid Dynamics},
	author = {Balachandar, S. and Moore, W. C. and Akiki, G. and Liu, K.},
	month = aug,
	year = {2020},
	pages = {401--428},
}

@article{higgins_towards_2018,
	title = {Towards a {Definition} of {Disentangled} {Representations}},
	url = {http://arxiv.org/abs/1812.02230},
	abstract = {How can intelligent agents solve a diverse set of tasks in a data-efficient manner? The disentangled representation learning approach posits that such an agent would benefit from separating out (disentangling) the underlying structure of the world into disjoint parts of its representation. However, there is no generally agreed-upon definition of disentangling, not least because it is unclear how to formalise the notion of world structure beyond toy datasets with a known ground truth generative process. Here we propose that a principled solution to characterising disentangled representations can be found by focusing on the transformation properties of the world. In particular, we suggest that those transformations that change only some properties of the underlying world state, while leaving all other properties invariant, are what gives exploitable structure to any kind of data. Similar ideas have already been successfully applied in physics, where the study of symmetry transformations has revolutionised the understanding of the world structure. By connecting symmetry transformations to vector representations using the formalism of group and representation theory we arrive at the first formal definition of disentangled representations. Our new definition is in agreement with many of the current intuitions about disentangling, while also providing principled resolutions to a number of previous points of contention. While this work focuses on formally defining disentangling - as opposed to solving the learning problem - we believe that the shift in perspective to studying data transformations can stimulate the development of better representation learning algorithms.},
	urldate = {2021-07-15},
	journal = {arXiv:1812.02230 [cs, stat]},
	author = {Higgins, Irina and Amos, David and Pfau, David and Racaniere, Sebastien and Matthey, Loic and Rezende, Danilo and Lerchner, Alexander},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.02230},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{daxberger_laplace_2021,
	title = {Laplace {Redux} -- {Effortless} {Bayesian} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2106.14806},
	abstract = {Bayesian formulations of deep learning have been shown to have compelling theoretical properties and offer practical functional benefits, such as improved predictive uncertainty quantification and model selection. The Laplace approximation (LA) is a classic, and arguably the simplest family of approximations for the intractable posteriors of deep neural networks. Yet, despite its simplicity, the LA is not as popular as alternatives like variational Bayes or deep ensembles. This may be due to assumptions that the LA is expensive due to the involved Hessian computation, that it is difficult to implement, or that it yields inferior results. In this work we show that these are misconceptions: we (i) review the range of variants of the LA including versions with minimal cost overhead; (ii) introduce "laplace", an easy-to-use software library for PyTorch offering user-friendly access to all major flavors of the LA; and (iii) demonstrate through extensive experiments that the LA is competitive with more popular alternatives in terms of performance, while excelling in terms of computational cost. We hope that this work will serve as a catalyst to a wider adoption of the LA in practical deep learning, including in domains where Bayesian approaches are not typically considered at the moment.},
	urldate = {2021-07-15},
	journal = {arXiv:2106.14806 [cs, stat]},
	author = {Daxberger, Erik and Kristiadi, Agustinus and Immer, Alexander and Eschenhagen, Runa and Bauer, Matthias and Hennig, Philipp},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.14806},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{khan_bayesian_2021,
	title = {The {Bayesian} {Learning} {Rule}},
	url = {http://arxiv.org/abs/2107.04562},
	abstract = {We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. The rule, derived from Bayesian principles, yields a wide-range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton's method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic-gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.},
	urldate = {2021-07-15},
	journal = {arXiv:2107.04562 [cs, stat]},
	author = {Khan, Mohammad Emtiyaz and Rue, Håvard},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.04562},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{xu_how_2021,
	title = {How {Neural} {Networks} {Extrapolate}: {From} {Feedforward} to {Graph} {Neural} {Networks}},
	shorttitle = {How {Neural} {Networks} {Extrapolate}},
	url = {http://arxiv.org/abs/2009.11848},
	abstract = {We study how neural networks trained by gradient descent extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks. Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently "diverse". Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel. Empirically, our theory holds across different training settings.},
	urldate = {2021-07-13},
	journal = {arXiv:2009.11848 [cs, stat]},
	author = {Xu, Keyulu and Zhang, Mozhi and Li, Jingling and Du, Simon S. and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
	month = mar,
	year = {2021},
	note = {arXiv: 2009.11848},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{bae_scientific_2021,
	title = {Scientific multi-agent reinforcement learning for wall-models of turbulent flows},
	url = {http://arxiv.org/abs/2106.11144},
	abstract = {The predictive capabilities of turbulent flow simulations, critical for aerodynamic design and weather prediction, hinge on the choice of turbulence models. The abundance of data from experiments and simulations and the advent of machine learning have provided a boost to these modeling efforts. However, simulations of turbulent flows remain hindered by the inability of heuristics and supervised learning to model the near-wall dynamics. We address this challenge by introducing scientific multi-agent reinforcement learning (SciMARL) for the discovery of wall models for large-eddy simulations (LES). In SciMARL, discretization points act also as cooperating agents that learn to supply the LES closure model. The agents self-learn using limited data and generalize to extreme Reynolds numbers and previously unseen geometries. The present simulations reduce by several orders of magnitude the computational cost over fully-resolved simulations while reproducing key flow quantities. We believe that SciMARL creates new capabilities for the simulation of turbulent flows.},
	urldate = {2021-07-13},
	journal = {arXiv:2106.11144 [physics]},
	author = {Bae, H. Jane and Koumoutsakos, Petros},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.11144},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{mayr_boundary_2021,
	title = {Boundary {Graph} {Neural} {Networks} for {3D} {Simulations}},
	url = {http://arxiv.org/abs/2106.11299},
	abstract = {The abundance of data has given machine learning huge momentum in natural sciences and engineering. However, the modeling of simulated physical processes remains difficult. A key problem in doing so is the correct handling of geometric boundaries. While triangularized geometric boundaries are very common in engineering applications, they are notoriously difficult to model by machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce Boundary Graph Neural Networks (BGNNs), which dynamically modify graph structures to address boundary conditions. Boundary graph structures are constructed via modifying edges, augmenting node features, and dynamically inserting virtual nodes. The new BGNNs are tested on complex 3D granular flow processes of hoppers and rotating drums which are standard parts of industrial machinery. Using precise simulations that are obtained by an expensive and complex discrete element method, BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. Even if complex boundaries are present, BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps, and most notably particles completely stay within the geometric objects without using handcrafted conditions or restrictions.},
	urldate = {2021-07-13},
	journal = {arXiv:2106.11299 [cs, stat]},
	author = {Mayr, Andreas and Lehner, Sebastian and Mayrhofer, Arno and Kloss, Christoph and Hochreiter, Sepp and Brandstetter, Johannes},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.11299},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sujith_dynamical_2021,
	title = {Dynamical systems and complex systems theory to study unsteady combustion},
	volume = {38},
	issn = {1540-7489},
	url = {https://www.sciencedirect.com/science/article/pii/S1540748920305319},
	doi = {10.1016/j.proci.2020.07.081},
	abstract = {Reacting flow fields are often subject to unsteadiness due to flow, reaction, diffusion, and acoustics. Further, flames can also exhibit inherent unsteadiness caused by various intrinsic instabilities. Interaction between various unsteady processes across multiple scales often makes combustion dynamics complex. Characterizing such complex dynamics is essential to ensure the safe and reliable operation of high efficiency combustion systems. Tools from nonlinear dynamics and complex systems theory provide new perspectives to analyze and interpret the data from real systems. They could also provide new ways of monitoring and controlling combustion systems. We discuss recent advances in studying unsteady combustion dynamics using the tools from dynamical systems theory and complex systems theory. We cover a range of problems involving unsteady combustion such as thermoacoustic instability, flame blowout, fire propagation, reaction chemistry and flow flame interaction.},
	language = {en},
	number = {3},
	urldate = {2021-07-13},
	journal = {Proceedings of the Combustion Institute},
	author = {Sujith, R. I. and Unni, Vishnu R.},
	month = jan,
	year = {2021},
	keywords = {Combustion Dynamics, Complex systems theory, Dynamical systems theory, Unsteady Combustion},
	pages = {3445--3462},
}

@article{loiseau_dynamics_nodate,
	title = {Dynamics and global stability analysis of three-dimensional flows},
	author = {Loiseau, Jean-Christophe},
	pages = {201},
}

@article{kipf_neural_2018,
	title = {Neural {Relational} {Inference} for {Interacting} {Systems}},
	url = {http://arxiv.org/abs/1802.04687},
	abstract = {Interacting systems are prevalent in nature, from dynamical systems in physics to complex societal dynamics. The interplay of components can give rise to complex behavior, which can often be explained using a simple model of the system's constituent parts. In this work, we introduce the neural relational inference (NRI) model: an unsupervised model that learns to infer interactions while simultaneously learning the dynamics purely from observational data. Our model takes the form of a variational auto-encoder, in which the latent code represents the underlying interaction graph and the reconstruction is based on graph neural networks. In experiments on simulated physical systems, we show that our NRI model can accurately recover ground-truth interactions in an unsupervised manner. We further demonstrate that we can find an interpretable structure and predict complex dynamics in real motion capture and sports tracking data.},
	urldate = {2021-07-09},
	journal = {arXiv:1802.04687 [cs, stat]},
	author = {Kipf, Thomas and Fetaya, Ethan and Wang, Kuan-Chieh and Welling, Max and Zemel, Richard},
	month = jun,
	year = {2018},
	note = {arXiv: 1802.04687},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{velickovic_graph_2018,
	title = {Graph {Attention} {Networks}},
	url = {http://arxiv.org/abs/1710.10903},
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
	urldate = {2021-07-09},
	journal = {arXiv:1710.10903 [cs, stat]},
	author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
	month = feb,
	year = {2018},
	note = {arXiv: 1710.10903},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@article{brody_how_2021,
	title = {How {Attentive} are {Graph} {Attention} {Networks}?},
	url = {http://arxiv.org/abs/2105.14491},
	abstract = {Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query. However, in this paper we show that GATs can only compute a restricted kind of attention where the ranking of attended nodes is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention. Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT. We perform an extensive evaluation and show that GATv2 outperforms GAT across 11 OGB and other benchmarks while we match their parametric costs. Our code is available at https://github.com/tech-srl/how\_attentive\_are\_gats .},
	urldate = {2021-07-09},
	journal = {arXiv:2105.14491 [cs]},
	author = {Brody, Shaked and Alon, Uri and Yahav, Eran},
	month = may,
	year = {2021},
	note = {arXiv: 2105.14491},
	keywords = {Computer Science - Machine Learning},
}

@article{xu_what_2020,
	title = {What {Can} {Neural} {Networks} {Reason} {About}?},
	url = {http://arxiv.org/abs/1905.13211},
	abstract = {Neural networks have succeeded in many reasoning tasks. Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, but less structured networks fail. Theoretically, there is limited understanding of why and when a network structure generalizes better than others, although they have equal expressive power. In this paper, we develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. We formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. As an example, we unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP). We show that GNNs align with DP and thus are expected to solve these tasks. On several reasoning tasks, our theory is supported by empirical results.},
	urldate = {2021-07-09},
	journal = {arXiv:1905.13211 [cs, stat]},
	author = {Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S. and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
	month = feb,
	year = {2020},
	note = {arXiv: 1905.13211},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{xu_how_2021-1,
	title = {How {Neural} {Networks} {Extrapolate}: {From} {Feedforward} to {Graph} {Neural} {Networks}},
	shorttitle = {How {Neural} {Networks} {Extrapolate}},
	url = {http://arxiv.org/abs/2009.11848},
	abstract = {We study how neural networks trained by gradient descent extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks. Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently "diverse". Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel. Empirically, our theory holds across different training settings.},
	urldate = {2021-07-09},
	journal = {arXiv:2009.11848 [cs, stat]},
	author = {Xu, Keyulu and Zhang, Mozhi and Li, Jingling and Du, Simon S. and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
	month = mar,
	year = {2021},
	note = {arXiv: 2009.11848},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{corso_principal_2020,
	title = {Principal {Neighbourhood} {Aggregation} for {Graph} {Nets}},
	url = {http://arxiv.org/abs/2004.05718},
	abstract = {Graph Neural Networks (GNNs) have been shown to be effective models for different predictive tasks on graph-structured data. Recent work on their expressive power has focused on isomorphism tasks and countable feature spaces. We extend this theoretical framework to include continuous features - which occur regularly in real-world input domains and within the hidden layers of GNNs - and we demonstrate the requirement for multiple aggregation functions in this context. Accordingly, we propose Principal Neighbourhood Aggregation (PNA), a novel architecture combining multiple aggregators with degree-scalers (which generalize the sum aggregator). Finally, we compare the capacity of different models to capture and exploit the graph structure via a novel benchmark containing multiple tasks taken from classical graph theory, alongside existing benchmarks from real-world domains, all of which demonstrate the strength of our model. With this work, we hope to steer some of the GNN research towards new aggregation methods which we believe are essential in the search for powerful and robust models.},
	urldate = {2021-07-09},
	journal = {arXiv:2004.05718 [cs, stat]},
	author = {Corso, Gabriele and Cavalleri, Luca and Beaini, Dominique and Liò, Pietro and Veličković, Petar},
	month = dec,
	year = {2020},
	note = {arXiv: 2004.05718},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{arnab_vivit_2021,
	title = {{ViViT}: {A} {Video} {Vision} {Transformer}},
	shorttitle = {{ViViT}},
	url = {http://arxiv.org/abs/2103.15691},
	abstract = {We present pure-transformer based models for video classification, drawing upon the recent success of such models in image classification. Our model extracts spatio-temporal tokens from the input video, which are then encoded by a series of transformer layers. In order to handle the long sequences of tokens encountered in video, we propose several, efficient variants of our model which factorise the spatial- and temporal-dimensions of the input. Although transformer-based models are known to only be effective when large training datasets are available, we show how we can effectively regularise the model during training and leverage pretrained image models to be able to train on comparatively small datasets. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple video classification benchmarks including Kinetics 400 and 600, Epic Kitchens, Something-Something v2 and Moments in Time, outperforming prior methods based on deep 3D convolutional networks. To facilitate further research, we will release code and models.},
	urldate = {2021-07-08},
	journal = {arXiv:2103.15691 [cs]},
	author = {Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lučić, Mario and Schmid, Cordelia},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.15691},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2021-07-08},
	journal = {arXiv:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv: 2010.11929},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{mcclenny_self-adaptive_2020,
	title = {Self-{Adaptive} {Physics}-{Informed} {Neural} {Networks} using a {Soft} {Attention} {Mechanism}},
	url = {http://arxiv.org/abs/2009.04544},
	abstract = {Physics-Informed Neural Networks (PINNs) have emerged recently as a promising application of deep neural networks to the numerical solution of nonlinear partial differential equations (PDEs). However, the original PINN algorithm is known to suffer from stability and accuracy problems in cases where the solution has sharp spatio-temporal transitions. These stiff PDEs require an unreasonably large number of collocation points to be solved accurately. It has been recognized that adaptive procedures are needed to force the neural network to fit accurately the stubborn spots in the solution of stiff PDEs. To accomplish this, previous approaches have used fixed weights hard-coded over regions of the solution deemed to be important. In this paper, we propose a fundamentally new method to train PINNs adaptively, where the adaptation weights are fully trainable, so the neural network learns by itself which regions of the solution are difficult and is forced to focus on them, which is reminiscent of soft multiplicative-mask attention mechanism used in computer vision. The basic idea behind these Self-Adaptive PINNs is to make the weights increase where the corresponding loss is higher, which is accomplished by training the network to simultaneously minimize the losses and maximize the weights, i.e., to find a saddle point in the cost surface. We show that this is formally equivalent to solving a PDE-constrained optimization problem using a penalty-based method, though in a way where the monotonically-nondecreasing penalty coefficients are trainable. Numerical experiments with an Allen-Cahn stiff PDE, the Self-Adaptive PINN outperformed other state-of-the-art PINN algorithms in L2 error by a wide margin, while using a smaller number of training epochs. An Appendix contains additional results with Burger's and Helmholtz PDEs, which confirmed the trends observed in the Allen-Cahn experiments.},
	urldate = {2021-07-06},
	journal = {arXiv:2009.04544 [cs, stat]},
	author = {McClenny, Levi and Braga-Neto, Ulisses},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.04544},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{li_fourier_2021,
	title = {Fourier {Neural} {Operator} for {Parametric} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
	urldate = {2021-07-06},
	journal = {arXiv:2010.08895 [cs, math]},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = may,
	year = {2021},
	note = {arXiv: 2010.08895},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{popinet_numerical_2018,
	title = {Numerical {Models} of {Surface} {Tension}},
	volume = {50},
	issn = {0066-4189, 1545-4479},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-fluid-122316-045034},
	doi = {10.1146/annurev-fluid-122316-045034},
	abstract = {Numerical models of surface tension play an increasingly important role in our capacity to understand and predict a wide range of multiphase ﬂow problems. The accuracy and robustness of these models have improved markedly in the past 20 years, so that they are now applicable to complex, threedimensional conﬁgurations of great theoretical and practical interest. In this review, I attempt to summarize the most signiﬁcant recent developments in Eulerian surface tension models, with an emphasis on well-balanced estimation, curvature estimation, stability, and implicit time stepping, as well as test cases and applications. The advantages and limitations of various models are discussed, with a focus on common features rather than differences. Several avenues for further progress are suggested.},
	language = {en},
	number = {1},
	urldate = {2021-07-05},
	journal = {Annual Review of Fluid Mechanics},
	author = {Popinet, Stéphane},
	month = jan,
	year = {2018},
	pages = {49--75},
}

@article{kasabov_experimental_2013,
	title = {Experimental {Study} on {Lifted} {Flames} {Operated} with {Liquid} {Kerosene} at {Elevated} {Pressure} and {Stabilized} by {Outer} {Recirculation}},
	volume = {90},
	issn = {1573-1987},
	url = {https://doi.org/10.1007/s10494-013-9444-1},
	doi = {10.1007/s10494-013-9444-1},
	abstract = {This study deals with the impact of the operating conditions, e.g. pressure, preheating temperature, pressure drop across the nozzle, nozzle size and stoichiometry, on the reaction zone location and spray evaporation progress in case of a lifted flame. Lifted flames are highly valued for their NOx reduction potential and for their low susceptibility to flash-back and thermo-acoustic instabilities. These advantageous features arise from the improved homogeneity of the fuel-air mixture provided to the reaction zone. One distinctive feature of the lifted flames is the presence of the so called lift-off zone located between nozzle outlet and main reaction zone. Within the lift-off zone fuel and oxidizer remain a certain time in contact and mix together prior to the onset of the combustion reaction. This leads to a more uniform heat release distribution and lowers the nitrogen oxides emissions at lean conditions by reducing the temperature spikes. In contrast to many other studies the subject of investigation was not a plain jet flame, but a modified version of the airblast nozzle, widely used in industrial applications. The nozzle was operated with liquid kerosene. As liquid fuels are easier to handle than gaseous or solid, it is expected that many efforts in the future will focus on the development of liquid fuels surrogates. Our previous investigations have shown, that the nozzle is well suited to be operated with gaseous fuels as well (Fokaides et al, J Eng Gas Turbine Power 130, 011508 2008). The position of the reaction zone was determined by means of chemiluminescence of the OH∗ radicals and from its location the lift-off height was derived. In addition the fuel evaporation progress was measured by means of light scattering, revealing that fuel droplets and main reaction zone are well separated. It was found that the operating conditions have a versatile impact on the length of the lift-off zone and spray cone and thus on the degree of pre-evaporation and premixing. Thus, it may be concluded, that through a proper choice of operating conditions and combustor size a desired lift-off height can be adjusted in accordance with criteria, like available space, required emission levels etc.},
	language = {en},
	number = {3},
	urldate = {2021-07-05},
	journal = {Flow, Turbulence and Combustion},
	author = {Kasabov, P. and Zarzalis, N. and Habisreuther, P.},
	month = apr,
	year = {2013},
	pages = {605--619},
}

@article{martin_linares_neural_2020,
	title = {Neural {Network} approach to reduced order modeling of multiphase flows},
	url = {https://ui.adsabs.harvard.edu/abs/2020APS..DFDK09021M},
	abstract = {We explore the use of Neural Networks (NN) to learn black as well as grey box models of the Partial Differential Equations (PDE) that govern multiphase flows in a 2-Dimensional (2-D) vertical channel. The data is generated using Direct Numerical Simulations (DNS). The covariance method is used to perform Proper Orthogonal Decomposition (POD) on the velocity and void fraction to filter the data so we can learn an effective PDE. The selected POD modes are further reduced through an autoencoder. The selected minimum number of non-linear projections have a one-to-one correspondence with the first few POD modes while reducing the loss function. The POD modes are used to evolve the solution in time using NN. We also use a NN to learn the functional form of the PDE and use the learned PDE to predict the dynamics. The closure terms in the averaged multiphase flow equations are predicted using NN and the predicted PDE is used to evolve in time the velocity and the void fraction, in another method. The developed models are used to predict the dynamics of flows with different initial and boundary conditions. `la Caixa' Foundation Fellowship.},
	urldate = {2021-07-02},
	author = {Martin Linares, Cristina P. and Bertalan, Tom and Lu, Jiacai and Lee, Seungjoon and Kevrekidis, Yannis and Tryggvason, Gretar},
	month = jan,
	year = {2020},
	note = {Conference Name: APS Division of Fluid Dynamics Meeting Abstracts},
	pages = {K09.021},
}

@article{qi_computing_2019,
	title = {Computing curvature for volume of fluid methods using machine learning},
	volume = {377},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999118307046},
	doi = {10.1016/j.jcp.2018.10.037},
	abstract = {In spite of considerable progress, computing curvature in Volume of Fluid (VOF) methods continues to be a challenge. The goal is to develop a function or a subroutine that returns the curvature in computational cells containing an interface separating two immiscible fluids, given the volume fraction in the cell and the adjacent cells. Currently, the most accurate approach is to fit a curve (2D), or a surface (3D), matching the volume fractions and finding the curvature by differentiation. Here, a different approach is examined. A synthetic data set, relating curvature to volume fractions, is generated using well-defined shapes where the curvature and volume fractions are easily found and then machine learning is used to fit the data (training). The resulting function is used to find the curvature for shapes not used for the training and implemented into a code to track moving interfaces. The results suggest that using machine learning to generate the relationship is a viable approach that results in reasonably accurate predictions.},
	language = {en},
	urldate = {2021-07-02},
	journal = {Journal of Computational Physics},
	author = {Qi, Yinghe and Lu, Jiacai and Scardovelli, Ruben and Zaleski, Stéphane and Tryggvason, Grétar},
	month = jan,
	year = {2019},
	keywords = {Curvature, Interface, Machine learning, Two-phase flow, Volume of fluid},
	pages = {155--161},
}

@article{aslangil_rayleightaylor_2020,
	title = {Rayleigh–{Taylor} {Instability} {With} {Varying} {Periods} of {Zero} {Acceleration}},
	volume = {142},
	issn = {0098-2202, 1528-901X},
	url = {https://asmedigitalcollection.asme.org/fluidsengineering/article/doi/10.1115/1.4048348/1086694/RayleighTaylor-Instability-With-Varying-Periods-of},
	doi = {10.1115/1.4048348},
	abstract = {Deep learning has shown the potential to signiﬁcantly accelerate numerical simulation of ﬂuids without sacriﬁcing accuracy, but prior works are limited to stationary ﬂows with uniform density. In real-world engineering applications, turbulent ﬂows are mostly three-dimensional, non-stationary and have variable-density. Here we propose Taylor-Net, a hybrid model that combines deep neural networks with numerical Taylor series method for 3D turbulent ﬂow prediction. Across ﬂows with different density-ratio, our method over 3 orders of magnitude faster than high-ﬁdelity numerical simulations. It also achieves higher accuracy than several strong physics-informed deep learning baselines. Most importantly, the predictions of our Taylor-Net pertain consistent physical characteristics including mass conservation, and turbulent energy spectrum.},
	language = {en},
	number = {12},
	urldate = {2021-07-01},
	journal = {Journal of Fluids Engineering},
	author = {Aslangil, Denis and Farley, Zachary and Lawrie, Andrew G. W. and Banerjee, Arindam},
	month = dec,
	year = {2020},
	pages = {121103},
}

@article{aslangil_rayleightaylor_2020-1,
	title = {Rayleigh–{Taylor} {Instability} {With} {Varying} {Periods} of {Zero} {Acceleration}},
	volume = {142},
	issn = {0098-2202, 1528-901X},
	url = {https://asmedigitalcollection.asme.org/fluidsengineering/article/doi/10.1115/1.4048348/1086694/RayleighTaylor-Instability-With-Varying-Periods-of},
	doi = {10.1115/1.4048348},
	abstract = {Deep learning has shown the potential to signiﬁcantly accelerate numerical simulation of ﬂuids without sacriﬁcing accuracy, but prior works are limited to stationary ﬂows with uniform density. In real-world engineering applications, turbulent ﬂows are mostly three-dimensional, non-stationary and have variable-density. Here we propose Taylor-Net, a hybrid model that combines deep neural networks with numerical Taylor series method for 3D turbulent ﬂow prediction. Across ﬂows with different density-ratio, our method over 3 orders of magnitude faster than high-ﬁdelity numerical simulations. It also achieves higher accuracy than several strong physics-informed deep learning baselines. Most importantly, the predictions of our Taylor-Net pertain consistent physical characteristics including mass conservation, and turbulent energy spectrum.},
	language = {en},
	number = {12},
	urldate = {2021-06-30},
	journal = {Journal of Fluids Engineering},
	author = {Aslangil, Denis and Farley, Zachary and Lawrie, Andrew G. W. and Banerjee, Arindam},
	month = dec,
	year = {2020},
	pages = {121103},
}

@article{praditia_finite_2021,
	title = {{FINITE} {VOLUME} {NEURAL} {NETWORK}: {MODELING} {SUBSURFACE} {CONTAMINANT} {TRANSPORT}},
	abstract = {Data-driven modeling of spatiotemporal physical processes with general deep learning methods is a highly challenging task. It is further exacerbated by the limited availability of data, leading to poor generalizations in standard neural network models. To tackle this issue, we introduce a new approach called the Finite Volume Neural Network (FINN). The FINN method adopts the numerical structure of the well-known Finite Volume Method for handling partial differential equations, so that each quantity of interest follows its own adaptable conservation law, while it concurrently accommodates learnable parameters. As a result, FINN enables better handling of ﬂuxes between control volumes and therefore proper treatment of different types of numerical boundary conditions. We demonstrate the effectiveness of our approach with a subsurface contaminant transport problem, which is governed by a non-linear diffusion-sorption process. FINN does not only generalize better to differing boundary conditions compared to other methods, it is also capable to explicitly extract and learn the constitutive relationships (expressed by the retardation factor). More importantly, FINN shows excellent generalization ability when applied to both synthetic datasets and real, sparse experimental data, thus underlining its relevance as a data-driven modeling tool.},
	language = {en},
	author = {Praditia, Timothy and Karlbauer, Matthias and Otte, Sebastian and Oladyshkin, Sergey and Butz, Martin V and Nowak, Wolfgang},
	year = {2021},
	pages = {11},
}

@article{ranade_latent_2021,
	title = {A {LATENT} {SPACE} {SOLVER} {FOR} {PDE} {GENERALIZATION}},
	abstract = {In this work we propose a hybrid solver to solve partial differential equation (PDE)s in the latent space. The solver uses an iterative inferencing strategy combined with solution initialization to improve generalization of PDE solutions. The solver is tested on an engineering case and the results show that it can generalize well to several PDE conditions.},
	language = {en},
	author = {Ranade, Rishikesh and Hill, Chris and He, Haiyang and Maleki, Amir and Pathak, Jay},
	year = {2021},
	pages = {7},
}

@article{rein_rebound_2012,
	title = {{REBOUND}: an open-source multi-purpose \textit{{N}} -body code for collisional dynamics},
	volume = {537},
	issn = {0004-6361, 1432-0746},
	shorttitle = {{REBOUND}},
	url = {http://www.aanda.org/10.1051/0004-6361/201118085},
	doi = {10.1051/0004-6361/201118085},
	abstract = {The dynamics of physical systems is often constrained to lower dimensional sub-spaces due to the presence of conserved quantities. Here we propose a method to learn and exploit such symmetry constraints building upon Hamiltonian Neural Networks. By enforcing cyclic coordinates with appropriate loss functions, we ﬁnd that we can achieve improved accuracy on simple classical dynamics tasks. By ﬁtting analytic formulae to the latent variables in our network we recover that our networks are utilizing conserved quantities such as (angular) momentum.},
	language = {en},
	urldate = {2021-06-30},
	journal = {Astronomy \& Astrophysics},
	author = {Rein, H. and Liu, S.-F.},
	month = jan,
	year = {2012},
	pages = {A128},
}

@article{quilodran-casas_adversarial_2021,
	title = {{ADVERSARIAL} {AUTOENCODERS} {AND} {ADVERSARIAL} {LSTM} {FOR} {IMPROVED} {FORECASTS} {OF} {URBAN} {AIR} {POLLUTION} {SIMULATIONS}},
	abstract = {This paper presents an approach to improve the forecast of computational ﬂuid dynamics (CFD) simulations of urban air pollution using deep learning, and most speciﬁcally adversarial training. This adversarial approach aims to reduce the divergence of the forecasts from the underlying physical model. Our twostep method integrates a Principal Components Analysis (PCA) based adversarial autoencoder (PC-AAE) with adversarial Long short-term memory (LSTM) networks. Once the reduced-order model (ROM) of the CFD solution is obtained via PCA, an adversarial autoencoder is used on the principal components time series. Subsequentially, a Long Short-Term Memory network (LSTM) is adversarially trained on the latent space produced by the PC-AAE to make forecasts. Once trained, the adversarially trained LSTM outperforms a LSTM trained in a classical way. The study area is in South London, including three-dimensional velocity vectors in a busy trafﬁc junction.},
	language = {en},
	author = {Quilodran-Casas, Cesar and Arcucci, Rossella and Mottet, Laetitia and Guo, Yike},
	year = {2021},
	pages = {8},
}

@article{rao_hard_2021,
	title = {{HARD} {ENCODING} {OF} {PHYSICS} {FOR} {LEARNING} {SPA}- {TIOTEMPORAL} {DYNAMICS}},
	abstract = {Modeling nonlinear spatiotemporal dynamical systems has primarily relied on partial differential equations (PDEs). However, the explicit formulation of PDEs for many underexplored processes, such as climate systems, biochemical reaction and epidemiology, remains uncertain or partially unknown, where very limited measurement data is yet available. To tackle this challenge, we propose a novel deep learning architecture that forcibly encodes known physics knowledge to facilitate learning in a data-driven manner. The coercive encoding mechanism of physics, which is fundamentally different from the penalty-based physicsinformed learning, ensures the network to rigorously obey given physics. Instead of using nonlinear activation functions, we propose a novel elementwise product operation to achieve the nonlinearity of the model. Numerical experiment demonstrates that the resulting physics-encoded learning paradigm possesses remarkable robustness against data noise/scarcity and generalizability compared with some state-of-the-art models for data-driven modeling.},
	language = {en},
	author = {Rao, Chengping and Sun, Hao and Liu, Yang},
	year = {2021},
	pages = {10},
}

@article{pestourie_active_2021,
	title = {{ACTIVE} {LEARNING} {OF} {DEEP} {SURROGATES} {FOR} {PDES}},
	abstract = {Surrogate models for partial-differential equations are widely used in the design of metamaterials to rapidly evaluate the behavior of composable components. However, the training cost of accurate surrogates by machine learning can rapidly increase with the number of variables. We present an active learning algorithm and apply it to train deep surrogates of Helmholtz’s equation and linear elasticity in solid mechanics. For the two problems of interest, our algorithm reduces the number of simulations required compared to uniform random samples by more than an order of magnitude for a neural-network surrogate model and by four, respectively. Results show that the surrogate evaluation is faster than a direct solve by over two orders of magnitude and over ﬁve orders of magnitude, respectively.},
	language = {en},
	author = {Pestourie, Raphael and Chomette, Gregoire and Mroueh, Youssef and Das, Payel and Radovitzky, Raul and Johnson, Steven G},
	year = {2021},
	pages = {6},
}

@article{matsuo_supervised_2021,
	title = {{SUPERVISED} {CONVOLUTIONAL} {NETWORKS} {FOR} {VOL}- {UMETRIC} {DATA} {ENRICHMENT} {FROM} {LIMITED} {SEC}- {TIONAL} {DATA} {WITH} {ADAPTIVE} {SUPER} {RESOLUTION}},
	abstract = {We have recently encountered the tremendous improvement in computational power, which in turn causes insufﬁcient utilization of big numerical data in a wide range of science and engineering due to storage and data-transfer limitations. Hence, of particular interest here is how we can handle big data, which are governed by strong chaoticity and nonlinearities, in an efﬁcient manner. We here consider a supervised use of convolutional neural networks (CNNs) to achieve efﬁcient data handling. The present CNN reconstructs three-dimensional (volumetric) data from limited two-dimensional information. As an example, a ﬂuid ﬂow around a square cylinder at ReD = 300, which contains strong three-dimensional complexities, is considered. Our demonstration shows that the present framework can successfully estimate the three-dimensional ﬂows from a few input sections, which eventually enables us to keep only sectional input data to obtain the whole information. We also propose a combination with an adaptive-sampling-based super-resolution analysis toward more effective data saving.},
	language = {en},
	author = {Matsuo, Mitsuaki and Fukami, Kai and Nakamura, Taichi and Morimoto, Masaki and Fukagata, Koji},
	year = {2021},
	pages = {5},
}

@article{sanchez-gonzalez_learning_2021,
	title = {{LEARNING} {GENERAL}-{PURPOSE} {CNN}-{BASED} {SIMULA}- {TORS} {FOR} {ASTROPHYSICAL} {TURBULENCE}},
	abstract = {Given the rise of machine learning (ML) for simulation, an important question is: to what extent can learned models supplement or replace traditional simulators? Here we develop a fully learned simulator model based on domain-general Convolutional Neural Network (CNN) methods, and study its performance on a range of turbulence problems in astrophysics. We compare the learned model to specialized PDE solvers in terms of spatial and temporal resolution, numerical stability, and generalization performance. We ﬁnd that the learned models outperform coarsened solvers on certain metrics, particularly in their ability to preserve high-frequency information at low resolution, and describe ways to improve generalization beyond the training distribution. To our knowledge, our model is the ﬁrst to be trained on Athena++ (a state-of-the-art simulator widely used in computational ﬂuid dynamics and magneto-hydrodynamics), and more generally, the ﬁrst fully-learned astrophysical turbulence simulator.},
	language = {en},
	author = {Sanchez-Gonzalez, Alvaro and Stachenfeld, Kimberly and Fielding, Drummond B and Kochkov, Dmitrii and Cranmer, Miles and Pfaff, Tobias and Godwin, Jonathan and Cui, Can and Ho, Shirley and Battaglia, Peter},
	year = {2021},
	pages = {12},
}

@article{izmailov_averaging_2019,
	title = {Averaging {Weights} {Leads} to {Wider} {Optima} and {Better} {Generalization}},
	url = {http://arxiv.org/abs/1803.05407},
	abstract = {Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.},
	urldate = {2021-06-28},
	journal = {arXiv:1803.05407 [cs, stat]},
	author = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
	month = feb,
	year = {2019},
	note = {arXiv: 1803.05407},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wilson_bayesian_nodate,
	title = {Bayesian {Deep} {Learning} and a {Probabilistic} {Perspective} of {Generalization}},
	abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspeciﬁed by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without signiﬁcant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to ﬁt images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased ﬂexibility.},
	language = {en},
	author = {Wilson, Andrew Gordon and Izmailov, Pavel},
	pages = {12},
}

@article{maddox_simple_2019,
	title = {A {Simple} {Baseline} for {Bayesian} {Uncertainty} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/1902.02476},
	abstract = {We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration, and transfer learning, in comparison to many popular alternatives including MC dropout, KFAC Laplace, SGLD, and temperature scaling.},
	urldate = {2021-06-28},
	journal = {arXiv:1902.02476 [cs, stat]},
	author = {Maddox, Wesley and Garipov, Timur and Izmailov, Pavel and Vetrov, Dmitry and Wilson, Andrew Gordon},
	month = dec,
	year = {2019},
	note = {arXiv: 1902.02476},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{eggl_mixing_2020,
	title = {Mixing enhancement in binary fluids using optimised stirring strategies},
	volume = {899},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/product/identifier/S0022112020004486/type/journal_article},
	doi = {10.1017/jfm.2020.448},
	abstract = {Mixing of binary ﬂuids by moving stirrers is a commonplace process in many industrial applications, where even modest improvements in mixing efﬁciency could translate into considerable power savings or enhanced product quality. We propose a gradient-based nonlinear optimisation scheme to minimise the mix-norm of a passive scalar. The velocities of two cylindrical stirrers, moving on concentric circular paths inside a circular container, represent the control variables, and an iterative direct–adjoint algorithm is employed to arrive at enhanced mixing results. The associated stirring protocol is characterised by a complex interplay of vortical structures, generated and promoted by the stirrers’ action. Full convergence of the optimisation process requires constraints that penalise the acceleration of the moving bodies. Under these conditions, considerable mixing enhancement can be accomplished, even though an optimum cannot be guaranteed due to the non-convex nature of the optimisation problem. Various challenges and extensions of our approach are discussed.},
	language = {en},
	urldate = {2021-06-28},
	journal = {Journal of Fluid Mechanics},
	author = {Eggl, M. F. and Schmid, Peter J.},
	month = sep,
	year = {2020},
	pages = {A24},
}

@article{lino_simulating_2021,
	title = {Simulating {Continuum} {Mechanics} with {Multi}-{Scale} {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2106.04900},
	abstract = {Continuum mechanics simulators, numerically solving one or more partial differential equations, are essential tools in many areas of science and engineering, but their performance often limits application in practice. Recent modern machine learning approaches have demonstrated their ability to accelerate spatio-temporal predictions, although, with only moderate accuracy in comparison. Here we introduce MultiScaleGNN, a novel multi-scale graph neural network model for learning to infer unsteady continuum mechanics. MultiScaleGNN represents the physical domain as an unstructured set of nodes, and it constructs one or more graphs, each of them encoding different scales of spatial resolution. Successive learnt message passing between these graphs improves the ability of GNNs to capture and forecast the system state in problems encompassing a range of length scales. Using graph representations, MultiScaleGNN can impose periodic boundary conditions as an inductive bias on the edges in the graphs, and achieve independence to the nodes' positions. We demonstrate this method on advection problems and incompressible fluid dynamics. Our results show that the proposed model can generalise from uniform advection fields to high-gradient fields on complex domains at test time and infer long-term Navier-Stokes solutions within a range of Reynolds numbers. Simulations obtained with MultiScaleGNN are between two and four orders of magnitude faster than the ones on which it was trained.},
	urldate = {2021-06-25},
	journal = {arXiv:2106.04900 [physics]},
	author = {Lino, Mario and Cantwell, Chris and Bharath, Anil A. and Fotiadis, Stathi},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.04900},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@article{godwin_very_2021,
	title = {Very {Deep} {Graph} {Neural} {Networks} {Via} {Noise} {Regularisation}},
	url = {http://arxiv.org/abs/2106.07971},
	abstract = {Graph Neural Networks (GNNs) perform learned message passing over an input graph, but conventional wisdom says performing more than handful of steps makes training difficult and does not yield improved performance. Here we show the contrary. We train a deep GNN with up to 100 message passing steps and achieve several state-of-the-art results on two challenging molecular property prediction benchmarks, Open Catalyst 2020 IS2RE and QM9. Our approach depends crucially on a novel but simple regularisation method, which we call ``Noisy Nodes'', in which we corrupt the input graph with noise and add an auxiliary node autoencoder loss if the task is graph property prediction. Our results show this regularisation method allows the model to monotonically improve in performance with increased message passing steps. Our work opens new opportunities for reaping the benefits of deep neural networks in the space of graph and other structured prediction problems.},
	urldate = {2021-06-25},
	journal = {arXiv:2106.07971 [cs]},
	author = {Godwin, Jonathan and Schaarschmidt, Michael and Gaunt, Alexander and Sanchez-Gonzalez, Alvaro and Rubanova, Yulia and Veličković, Petar and Kirkpatrick, James and Battaglia, Peter},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.07971},
	keywords = {Computer Science - Machine Learning},
}

@article{gal_uncertainty_nodate,
	title = {Uncertainty in {Deep} {Learning}},
	language = {en},
	author = {Gal, Yarin},
	pages = {174},
}

@article{cox_exponential_2002,
	title = {Exponential {Time} {Differencing} for {Stiff} {Systems}},
	volume = {176},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999102969950},
	doi = {10.1006/jcph.2002.6995},
	abstract = {We develop a class of numerical methods for stiff systems, based on the method of exponential time differencing. We describe schemes with second- and higher-order accuracy, introduce new Runge–Kutta versions of these schemes, and extend the method to show how it may be applied to systems whose linear part is nondiagonal. We test the method against other common schemes, including integrating factor and linearly implicit methods, and show how it is more accurate in a number of applications. We apply the method to both dissipative and dispersive partial differential equations, after illustrating its behavior using forced ordinary differential equations with stiff linear parts.},
	language = {en},
	number = {2},
	urldate = {2021-06-25},
	journal = {Journal of Computational Physics},
	author = {Cox, S. M. and Matthews, P. C.},
	month = mar,
	year = {2002},
	pages = {430--455},
}

@article{mayr_boundary_2021-1,
	title = {Boundary {Graph} {Neural} {Networks} for {3D} {Simulations}},
	url = {http://arxiv.org/abs/2106.11299},
	abstract = {The abundance of data has given machine learning huge momentum in natural sciences and engineering. However, the modeling of simulated physical processes remains difficult. A key problem in doing so is the correct handling of geometric boundaries. While triangularized geometric boundaries are very common in engineering applications, they are notoriously difficult to model by machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce Boundary Graph Neural Networks (BGNNs), which dynamically modify graph structures to address boundary conditions. Boundary graph structures are constructed via modifying edges, augmenting node features, and dynamically inserting virtual nodes. The new BGNNs are tested on complex 3D granular flow processes of hoppers and rotating drums which are standard parts of industrial machinery. Using precise simulations that are obtained by an expensive and complex discrete element method, BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. Even if complex boundaries are present, BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps, and most notably particles completely stay within the geometric objects without using handcrafted conditions or restrictions.},
	urldate = {2021-06-23},
	journal = {arXiv:2106.11299 [cs, stat]},
	author = {Mayr, Andreas and Lehner, Sebastian and Mayrhofer, Arno and Kloss, Christoph and Hochreiter, Sepp and Brandstetter, Johannes},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.11299},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{beetham_thermal_2021,
	title = {On the thermal entrance length of moderately dense gas-particle flows},
	url = {http://arxiv.org/abs/2106.10395},
	abstract = {The dissipative nature of heat transfer relaxes thermal flows to an equilibrium state that is devoid of temperature gradients. The distance to reach an equilibrium temperature -- the thermal entrance length -- is a consequence of diffusion and mixing by convection. The presence of particles can modify the thermal entrance length due to interphase heat transfer and turbulence modulation by momentum coupling. In this work, Eulerian--Lagrangian simulations are utilized to probe the effect of solids heterogeneity (e.g., clustering) on the thermal entrance length. For the moderately dense systems considered here, clustering leads to a factor of 2--3 increase in the thermal entrance length, as compared to an uncorrelated (perfectly mixed) distribution of particles. The observed increase is found to be primarily due to the covariance between volume fraction and temperature fluctuations, referred to as the fluid drift temperature. Using scaling arguments and Gene Expression Programming, closure is obtained for this term in a one-dimensional averaged two-fluid equation and is shown to be accurate under a wide range of flow conditions.},
	urldate = {2021-06-22},
	journal = {arXiv:2106.10395 [physics]},
	author = {Beetham, S. and Lattanzi, A. and Capecelatro, J.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.10395},
	keywords = {Physics - Fluid Dynamics},
}

@article{belbute-peres_combining_2020,
	title = {Combining {Differentiable} {PDE} {Solvers} and {Graph} {Neural} {Networks} for {Fluid} {Flow} {Prediction}},
	url = {http://arxiv.org/abs/2007.04439},
	abstract = {Solving large complex partial differential equations (PDEs), such as those that arise in computational fluid dynamics (CFD), is a computationally expensive process. This has motivated the use of deep learning approaches to approximate the PDE solutions, yet the simulation results predicted from these approaches typically do not generalize well to truly novel scenarios. In this work, we develop a hybrid (graph) neural network that combines a traditional graph convolutional network with an embedded differentiable fluid dynamics simulator inside the network itself. By combining an actual CFD simulator (run on a much coarser resolution representation of the problem) with the graph network, we show that we can both generalize well to new situations and benefit from the substantial speedup of neural network CFD predictions, while also substantially outperforming the coarse CFD simulation alone.},
	urldate = {2021-06-22},
	journal = {arXiv:2007.04439 [physics, stat]},
	author = {Belbute-Peres, Filipe de Avila and Economon, Thomas D. and Kolter, J. Zico},
	month = aug,
	year = {2020},
	note = {arXiv: 2007.04439},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{chamberlain_grand_2021,
	title = {{GRAND}: {Graph} {Neural} {Diffusion}},
	shorttitle = {{GRAND}},
	url = {http://arxiv.org/abs/2106.10934},
	abstract = {We present Graph Neural Diffusion (GRAND) that approaches deep learning on graphs as a continuous diffusion process and treats Graph Neural Networks (GNNs) as discretisations of an underlying PDE. In our model, the layer structure and topology correspond to the discretisation choices of temporal and spatial operators. Our approach allows a principled development of a broad new class of GNNs that are able to address the common plights of graph learning models such as depth, oversmoothing, and bottlenecks. Key to the success of our models are stability with respect to perturbations in the data and this is addressed for both implicit and explicit discretisation schemes. We develop linear and nonlinear versions of GRAND, which achieve competitive results on many standard graph benchmarks.},
	urldate = {2021-06-22},
	journal = {arXiv:2106.10934 [cs, stat]},
	author = {Chamberlain, Benjamin Paul and Rowbottom, James and Gorinova, Maria and Webb, Stefan and Rossi, Emanuele and Bronstein, Michael M.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.10934},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wang_deep_2021,
	title = {Deep learning of free boundary and {Stefan} problems},
	volume = {428},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120306884},
	doi = {10.1016/j.jcp.2020.109914},
	abstract = {Free boundary problems appear naturally in numerous areas of mathematics, science and engineering. These problems present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of free boundaries and complex dynamic interfaces. In this work, we propose a multi-network model based on physics-informed neural networks to tackle a general class of forward and inverse free boundary problems called Stefan problems. Specifically, we approximate the unknown solution as well as any moving boundaries by two deep neural networks. Besides, we formulate a new type of inverse Stefan problems that aim to reconstruct the solution and free boundaries directly from sparse and noisy measurements. We demonstrate the effectiveness of our approach in a series of benchmarks spanning different types of Stefan problems, and illustrate how the proposed framework can accurately recover solutions of partial differential equations with moving boundaries and dynamic interfaces. All code and data accompanying this manuscript are publicly available at https://github.com/PredictiveIntelligenceLab/DeepStefan.},
	language = {en},
	urldate = {2021-06-22},
	journal = {Journal of Computational Physics},
	author = {Wang, Sifan and Perdikaris, Paris},
	month = mar,
	year = {2021},
	keywords = {Keywords Physics-informed neural networks, Partial differential equations, Phase transitions, Scientific machine learning},
	pages = {109914},
}

@article{you_data-driven_2021,
	title = {Data-driven learning of nonlocal physics from high-fidelity synthetic data},
	volume = {374},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782520307386},
	doi = {10.1016/j.cma.2020.113553},
	abstract = {A key challenge to nonlocal models is the analytical complexity of deriving them from first principles, and frequently their use is justified a posteriori. In this work we extract nonlocal models from data, circumventing these challenges and providing data-driven justification for the resulting model form. Extracting data-driven surrogates is a major challenge for machine learning (ML) approaches, due to nonlinearities and lack of convexity — it is particularly challenging to extract surrogates which are provably well-posed and numerically stable. Our scheme not only yields a convex optimization problem, but also allows extraction of nonlocal models whose kernels may be partially negative while maintaining well-posedness even in small-data regimes. To achieve this, based on established nonlocal theory, we embed in our algorithm sufficient conditions on the non-positive part of the kernel that guarantee well-posedness of the learnt operator. These conditions are imposed as inequality constraints to meet the requisite conditions of the nonlocal theory. We demonstrate this workflow for a range of applications, including reproduction of manufactured nonlocal kernels; numerical homogenization of Darcy flow associated with a heterogeneous periodic microstructure; nonlocal approximation to high-order local transport phenomena; and approximation of globally supported fractional diffusion operators by truncated kernels.},
	language = {en},
	urldate = {2021-06-22},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {You, Huaiqian and Yu, Yue and Trask, Nathaniel and Gulian, Mamikon and D’Elia, Marta},
	month = feb,
	year = {2021},
	keywords = {Data-driven learning, Fractional models, Homogenization, Machine learning, Nonlocal models, Optimization},
	pages = {113553},
}

@article{blechschmidt_three_2021,
	title = {Three ways to solve partial differential equations with neural networks — {A} review},
	volume = {44},
	issn = {1522-2608},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/gamm.202100006},
	doi = {10.1002/gamm.202100006},
	abstract = {Neural networks are increasingly used to construct numerical solution methods for partial differential equations. In this expository review, we introduce and contrast three important recent approaches attractive in their simplicity and their suitability for high-dimensional problems: physics-informed neural networks, methods based on the Feynman–Kac formula and methods based on the solution of backward stochastic differential equations. The article is accompanied by a suite of expository software in the form of Jupyter notebooks in which each basic methodology is explained step by step, allowing for a quick assimilation and experimentation. An extensive bibliography summarizes the state of the art.},
	language = {en},
	number = {2},
	urldate = {2021-06-22},
	journal = {GAMM-Mitteilungen},
	author = {Blechschmidt, Jan and Ernst, Oliver G.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/gamm.202100006},
	keywords = {Feynman–Kac, Hamilton–Jacobi–Bellman equations, PINN, backward differential equation, curse of dimensionality, neural networks, partial differential equation, stochastic process},
	pages = {e202100006},
}

@article{bakarji_data-driven_2021,
	title = {Data-driven discovery of coarse-grained equations},
	volume = {434},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121001145},
	doi = {10.1016/j.jcp.2021.110219},
	abstract = {Statistical (machine learning) tools for equation discovery require large amounts of data that are typically computer generated rather than experimentally observed. Multiscale modeling and stochastic simulations are two areas where learning on simulated data can lead to such discovery. In both, the data are generated with a reliable but impractical model, e.g., molecular dynamics simulations, while a model on the scale of interest is uncertain, requiring phenomenological constitutive relations and ad-hoc approximations. We replace the human discovery of such models, which typically involves spatial/stochastic averaging or coarse-graining, with a machine-learning strategy based on sparse regression that can be executed in two modes. The first, direct equation-learning, discovers a differential operator from the whole dictionary. The second, constrained equation-learning, discovers only those terms in the differential operator that need to be discovered, i.e., learns closure approximations. We illustrate our approach by learning a deterministic equation that governs the spatiotemporal evolution of the probability density function of a system state whose dynamics are described by a nonlinear partial differential equation with random inputs. A series of examples demonstrates the accuracy, robustness, and limitations of our approach to equation discovery.},
	language = {en},
	urldate = {2021-06-22},
	journal = {Journal of Computational Physics},
	author = {Bakarji, Joseph and Tartakovsky, Daniel M.},
	month = jun,
	year = {2021},
	keywords = {Closure approximation, Coarse-graining, Machine learning, Stochastic},
	pages = {110219},
}

@article{beetham_thermal_2021-1,
	title = {On the thermal entrance length of moderately dense gas-particle flows},
	url = {http://arxiv.org/abs/2106.10395},
	abstract = {The dissipative nature of heat transfer relaxes thermal flows to an equilibrium state that is devoid of temperature gradients. The distance to reach an equilibrium temperature -- the thermal entrance length -- is a consequence of diffusion and mixing by convection. The presence of particles can modify the thermal entrance length due to interphase heat transfer and turbulence modulation by momentum coupling. In this work, Eulerian--Lagrangian simulations are utilized to probe the effect of solids heterogeneity (e.g., clustering) on the thermal entrance length. For the moderately dense systems considered here, clustering leads to a factor of 2--3 increase in the thermal entrance length, as compared to an uncorrelated (perfectly mixed) distribution of particles. The observed increase is found to be primarily due to the covariance between volume fraction and temperature fluctuations, referred to as the fluid drift temperature. Using scaling arguments and Gene Expression Programming, closure is obtained for this term in a one-dimensional averaged two-fluid equation and is shown to be accurate under a wide range of flow conditions.},
	urldate = {2021-06-22},
	journal = {arXiv:2106.10395 [physics]},
	author = {Beetham, S. and Lattanzi, A. and Capecelatro, J.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.10395},
	keywords = {Physics - Fluid Dynamics},
}

@article{huang_extreme_2020,
	title = {Extreme {Image} {Coding} via {Multiscale} {Autoencoders} {With} {Generative} {Adversarial} {Optimization}},
	url = {http://arxiv.org/abs/1904.03851},
	abstract = {We propose a MultiScale AutoEncoder (MSAE) based extreme image coding/compression framework to offer visually pleasing reconstruction at a very low bitrate. Our method leverages the “priors” at different resolution scale to improve the compression efﬁciency, and also employs the generative adversarial network (GAN) with multiscale discriminators to perform the end-to-end trainable rate-distortion optimization. We compare the perceptual quality of our reconstructions with traditional compression algorithms using High-Efﬁciency Video Coding (HEVC) based Intra Proﬁle and JPEG2000 on the public Cityscapes, ADE20K and Kodak datasets, demonstrating the signiﬁcant subjective quality improvement. However, objective measurements, such as PSNR, SSIM, etc, are often deteriorated by applying the generative adversarial optimization.},
	language = {en},
	urldate = {2021-06-18},
	journal = {arXiv:1904.03851 [cs, eess]},
	author = {Huang, Chao and Liu, Haojie and Chen, Tong and Shen, Qiu and Ma, Zhan},
	month = jan,
	year = {2020},
	note = {arXiv: 1904.03851},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{druault_generation_2004,
	title = {Generation of {Three}-{Dimensional} {Turbulent} {Inlet} {Conditions} for {Large}-{Eddy} {Simulation}},
	volume = {42},
	issn = {0001-1452},
	url = {https://arc.aiaa.org/doi/10.2514/1.3946},
	doi = {10.2514/1.3946},
	number = {3},
	urldate = {2021-06-14},
	journal = {AIAA Journal},
	author = {Druault, P. and Lardeau, S. and Bonnet, J.-P. and Coiffet, F. and Delville, J. and Lamballais, E. and Largeau, J.-F. and Perret, L.},
	month = mar,
	year = {2004},
	note = {Publisher: American Institute of Aeronautics and Astronautics},
	pages = {447--456},
}

@article{moser_direct_1999,
	title = {Direct numerical simulation of turbulent channel flow up to {Reτ}=590},
	volume = {11},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.869966},
	doi = {10.1063/1.869966},
	number = {4},
	urldate = {2021-06-14},
	journal = {Physics of Fluids},
	author = {Moser, Robert D. and Kim, John and Mansour, Nagi N.},
	month = apr,
	year = {1999},
	note = {Publisher: American Institute of Physics},
	pages = {943--945},
}

@article{janin_new_2021,
	title = {A new linear forcing method for isotropic turbulence with controlled integral length scale},
	volume = {33},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/5.0045818},
	doi = {10.1063/5.0045818},
	abstract = {Turbulence is a common feature to all flows that surround us. Despite its ubiquity, particularly in industrial flows, it is very difficult to provide a mathematical framework for the generation of turbulent eddies. Several methods have been proposed which are able to reproduce realistic features for velocity fluctuations, exhibiting proper space- and time-correlations. Focusing on physical space forcing, these methods are usually first evaluated upon sustained homogeneous isotropic turbulence by introducing a body force to the Navier–Stokes equations. Since the pioneering work of Lundgren, these techniques usually experience difficulties in predicting the integral length scale. The present study provides a forcing through a reconstruction approach which consists in building velocity fluctuations with a prescribed energy spectrum model. The proposed approach is assessed by performing large-eddy simulations of a sustained homogeneous isotropic turbulence in a triply periodic box. Properties of this forcing technique are discussed, drawing on both spatial and time correlations and also on the shape of energy spectrum together with the level of resolved turbulent kinetic energy. A special attention is put on the control of resolved turbulent energy. In this framework, an efficient selective forcing technique is derived, making use of spectral space features. The results show that the proposed approach allows to drive efficiently the resolved kinetic energy toward its target value while preserving the integral length scale independent of the domain size. It is observed that the resulting longitudinal length scale is overestimated by 13\%, while the two-time correlations are recovered when using stochastic frequencies.},
	number = {4},
	urldate = {2021-06-10},
	journal = {Physics of Fluids},
	author = {Janin, Jérémie and Duval, Fabien and Friess, Christophe and Sagaut, Pierre},
	month = apr,
	year = {2021},
	note = {Publisher: American Institute of Physics},
	pages = {045127},
}

@article{stefano_stochastic_2010,
	title = {Stochastic coherent adaptive large eddy simulation of forced isotropic turbulence},
	volume = {646},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/stochastic-coherent-adaptive-large-eddy-simulation-of-forced-isotropic-turbulence/5858B4195B1D4453A2E9DD368014BEE0},
	doi = {10.1017/S002211200999303X},
	abstract = {The stochastic coherent adaptive large eddy simulation (SCALES) methodology is a novel approach to the numerical simulation of turbulence, where a dynamic grid adaptation strategy based on wavelet threshold filtering is utilized to solve for the most ‘energetic’ eddies. The effect of the less energetic unresolved motions is simulated by a model. Previous studies have demonstrated excellent predictive properties of the SCALES approach for decaying homogeneous turbulence. In this paper the applicability of the method is further explored for statistically steady turbulent flows by considering linearly forced homogeneous turbulence at moderate Reynolds number. A local dynamic subgrid-scale eddy viscosity model based on the definition of the kinetic energy associated with the unresolved motions is used as closure model. The governing equations for the wavelet filtered velocity field, along with the additional evolution equation for the subgrid-scale kinetic energy, are numerically solved by means of a dynamically adaptive wavelet collocation method. It is demonstrated that adaptive simulations closely match results from a reference pseudo-spectral fully de-aliased direct numerical simulation, by using only about 1\% of the corresponding computational nodes. In contrast to classical non-adaptive large eddy simulation, the agreement with direct solution holds for the mean flow statistics as well as in terms of energy and enstrophy spectra up to the dissipative wavenumbers range.},
	language = {en},
	urldate = {2021-06-10},
	journal = {Journal of Fluid Mechanics},
	author = {Stefano, G. De and Vasilyev, O. V.},
	month = mar,
	year = {2010},
	note = {Publisher: Cambridge University Press},
	pages = {453--470},
}

@article{schiavo_large_2015,
	title = {Large {Eddy} {Simulations} of convergent–divergent channel flows at moderate {Reynolds} numbers},
	volume = {56},
	issn = {0142-727X},
	url = {https://www.sciencedirect.com/science/article/pii/S0142727X15000880},
	doi = {10.1016/j.ijheatfluidflow.2015.07.006},
	abstract = {The paper is focused on the study of fully turbulent channel flows, using Large Eddy Simulations (LES), in order to address the effects of adverse pressure gradient regions. Analyses of the effects of streak instabilities, which have been shown to be relevant in such regions, are extended to moderate Reynolds numbers. The work considers two different channel geometries in order to further separate influences from wall curvature, flow separation and adverse pressure gradients. Turbulent kinetic energy and Reynolds stress budgets are investigated at separation and re-attachment points. The numerical approach used in the present work is based on the incompressible Navier–Stokes equations, which are solved by a pseudo-spectral methodology for structured grids. Wall-resolved LES calculations are performed using the WALE subgrid scale model. The study shows that the streak instability mechanism persists at higher Reynolds numbers with and without wall curvature in the adverse pressure gradient regions. Moreover, the observed effects are also present regardless of the existence of flow separation regions. Finally, the study of turbulent kinetic energy budgets indicates that, independently of the flow condition, there are well-defined patterns for such turbulent properties at separation and re-attachment points.},
	language = {en},
	urldate = {2021-06-10},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Schiavo, Luiz A. C. A. and Jesus, Antonio B. and Azevedo, João L. F. and Wolf, William R.},
	month = dec,
	year = {2015},
	keywords = {Adverse pressure gradient, Channel flow, LES, Streak instability, Turbulent flow},
	pages = {137--151},
}

@article{matai_large-eddy_2019,
	title = {Large-eddy simulation of turbulent flow over a parametric set of bumps},
	volume = {866},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/largeeddy-simulation-of-turbulent-flow-over-a-parametric-set-of-bumps/AE1144E41F1B0847F80EE5B99E52FB80},
	doi = {10.1017/jfm.2019.80},
	abstract = {Turbulent flow over a series of increasingly high, two-dimensional bumps is studied by well-resolved large-eddy simulation. The mean flow and Reynolds stresses for the lowest bump are in good agreement with experimental data. The flow encounters a favourable pressure gradient over the windward side of the bump, but does not relaminarize, as is evident from near-wall fluctuations. A patch of high turbulent kinetic energy forms in the lee of the bump and extends into the wake. It originates near the surface, before flow separation, and has a significant influence on flow development. The highest bumps create a small separation bubble, whereas flow over the lowest bump does not separate. The log law is absent over the entire bump, evidencing strong disequilibrium. This dataset was created for data-driven modelling. An optimization method is used to extract fields of variables that are used in turbulence closure models. From this, it is shown how these models fail to correctly predict the behaviour of these variables near to the surface. The discrepancies extend further away from the wall in the adverse pressure gradient and recovery regions than in the favourable pressure gradient region.},
	language = {en},
	urldate = {2021-06-10},
	journal = {Journal of Fluid Mechanics},
	author = {Matai, Racheet and Durbin, Paul},
	month = may,
	year = {2019},
	note = {Publisher: Cambridge University Press},
	keywords = {turbulence modelling, turbulence simulation, turbulent boundary layers},
	pages = {503--525},
}

@article{weiner_creating_nodate,
	title = {Creating data-driven {CFD} workflows using {OpenFOAM} and {PyTorch}},
	language = {en},
	author = {Weiner, Andre and Pesci, Chiara and Marić, Tomislav and Bothe, Dieter},
	pages = {6},
}

@article{maulik_pythonfoam_2021,
	title = {{PythonFOAM}: {In}-situ data analyses with {OpenFOAM} and {Python}},
	shorttitle = {{PythonFOAM}},
	url = {http://arxiv.org/abs/2103.09389},
	abstract = {In this article, we outline the development of a general-purpose Python-based data analysis tool for OpenFOAM 8. Our implementation relies on the construction of OpenFOAM applications that have bindings to data analysis libraries in Python. Double precision data in OpenFOAM is cast to a NumPy array using the NumPy C-API and Python modules may then be used for arbitrary data analysis and manipulation on flow-field information. This document highlights how the proposed framework may be used for an in-situ online singular value decomposition (SVD) implemented in Python and accessed from the OpenFOAM solver PimpleFOAM. Here, `in-situ' refers to a programming paradigm that allows for a concurrent computation of the data analysis on the same computational resources utilized for the partial differential equation solver. In addition, to demonstrate data-parallel analyses, we deploy a distributed SVD, which collects snapshot data across the ranks of a distributed simulation to compute the global left singular vectors. Crucially, both OpenFOAM and Python share the same message passing interface (MPI) communicator for this deployment which allows Python objects and functions to exchange NumPy arrays across ranks. Our experiments also demonstrate how customized data science libraries such as TensorFlow may be leveraged through these bindings. Subsequently, we provide scaling assessments of our framework and the selected algorithms on multiple nodes of Intel Broadwell and KNL architectures for canonical test cases such as the large eddy simulations of a backward facing step and a channel flow at friction Reynolds number of 395.},
	urldate = {2021-06-09},
	journal = {arXiv:2103.09389 [physics]},
	author = {Maulik, Romit and Fytanidis, Dimitrios and Lusch, Bethany and Vishwanath, Venkatram and Patel, Saumil},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.09389},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{geneva_modeling_2020,
	title = {Modeling the dynamics of {PDE} systems with physics-constrained deep auto-regressive networks},
	volume = {403},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999119307612},
	doi = {10.1016/j.jcp.2019.109056},
	abstract = {In recent years, deep learning has proven to be a viable methodology for surrogate modeling and uncertainty quantification for a vast number of physical systems. However, in their traditional form, such models can require a large amount of training data. This is of particular importance for various engineering and scientific applications where data may be extremely expensive to obtain. To overcome this shortcoming, physics-constrained deep learning provides a promising methodology as it only utilizes the governing equations. In this work, we propose a novel auto-regressive dense encoder-decoder convolutional neural network to solve and model non-linear dynamical systems without training data at a computational cost that is potentially magnitudes lower than standard numerical solvers. This model includes a Bayesian framework that allows for uncertainty quantification of the predicted quantities of interest at each time-step. We rigorously test this model on several non-linear transient partial differential equation systems including the turbulence of the Kuramoto-Sivashinsky equation, multi-shock formation and interaction with 1D Burgers' equation and 2D wave dynamics with coupled Burgers' equations. For each system, the predictive results and uncertainty are presented and discussed together with comparisons to the results obtained from traditional numerical analysis methods.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Geneva, Nicholas and Zabaras, Nicholas},
	month = feb,
	year = {2020},
	keywords = {Auto-regressive model, Convolutional encoder-decoder, Deep neural networks, Dynamic partial differential equations, Physics-informed machine learning, Uncertainty quantification},
	pages = {109056},
}

@article{brunton_discovering_2016,
	title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
	volume = {113},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/113/15/3932},
	doi = {10.1073/pnas.1517384113},
	abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
	language = {en},
	number = {15},
	urldate = {2021-06-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
	month = apr,
	year = {2016},
	pmid = {27035946},
	note = {Publisher: National Academy of Sciences
Section: Physical Sciences},
	keywords = {dynamical systems, machine learning, optimization, sparse regression, system identification},
	pages = {3932--3937},
}

@article{maulik_turbulent_2020,
	title = {A turbulent eddy-viscosity surrogate modeling framework for {Reynolds}-{Averaged} {Navier}-{Stokes} simulations},
	url = {http://arxiv.org/abs/1910.10878},
	abstract = {The Reynolds-averaged Navier-Stokes (RANS) equations for steady-state assessment of incompressible turbulent flows remain the workhorse for practical computational fluid dynamics (CFD) applications. Consequently, improvements in speed or accuracy have the potential to affect a diverse range of applications. We introduce a machine learning framework for the \{surrogate modeling of steady-state turbulent eddy viscosities for RANS simulations, given the initial conditions. This modeling strategy\} is assessed for parametric interpolation, while numerically solving for the pressure and velocity equations to steady state, thus representing a framework that is hybridized with machine learning. We achieve \{competitive\} steady-state results with a significant reduction in solution time when compared to those obtained by the Spalart-Allmaras one-equation model. This is because the proposed methodology allows for considerably larger relaxation factors for the steady-state velocity and pressure solvers. Our assessments are made for a backward-facing step with considerable mesh anisotropy and separation to represent a practical CFD application. For test experiments with {\textbackslash}textcolor\{black\}\{either\} varying inlet velocity conditions or step heights we see time-to-solution reductions around a factor of 5. The results represent an opportunity for the rapid exploration of parameter spaces that prove prohibitive when utilizing turbulence closure models with multiple coupled partial differential equations. {\textbackslash}blfootnote\{Code available publicly at {\textbackslash}texttt\{https://github.com/argonne-lcf/TensorFlowFoam\}\}.},
	urldate = {2021-06-09},
	journal = {arXiv:1910.10878 [physics]},
	author = {Maulik, Romit and Sharma, Himanshu and Patel, Saumil and Lusch, Bethany and Jennings, Elise},
	month = dec,
	year = {2020},
	note = {arXiv: 1910.10878},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{ferrero_field_2020,
	title = {Field inversion for data-augmented {RANS} modelling in turbomachinery flows},
	volume = {201},
	url = {https://hal.archives-ouvertes.fr/hal-03153111},
	doi = {10.1016/j.compfluid.2020.104474},
	abstract = {Turbulence modelling in turbomachinery flows remains a challenge, especiallywhen transition and separation phenomena occur.  Recently, several researchefforts have been devoted to the improvement of closure models for ReynoldsAveraged Navier-Stokes (RANS) equations by means of machine learning ap-proaches which make it possible to extract the knowledge hidden inside theavailable high-fidelity data (from experiments or from scale-resolving simu-lations).  In this work the use of the field inversion approach is investigatedfor the augmentation of the Spalart-Allmaras RANS model applied to theflow in low pressure gas turbine cascades.  As a first step, the field inversionmethod is applied to the T106c cascade at two different values of Reynoldsnumber  (80000-250000):  an  adjoint-based  gradient  method  is  employed  inorder to minimise the prediction error on the wall isentropic Mach numberdistribution.   The  data  obtained  by  the  correction  field  are  then  analysedby means of an Artificial Neural Network (ANN) which makes it possible to generalise  the  correction  by  finding  correlations  which  depend  on  physicalvariables.  A study on the definition of the input variables and on the archi-tecture of the ANN is performed.  Different kind of corrections are evaluatedand a particularly robust correction factor is obtained by limiting the rangeof the correction in the spirit of intermittency models.  Finally, the ANN isintroduced in an augmented version of the Spalart-Allmaras model which istested on the T106c cascade (for values of the Reynolds number not consid-ered during the training) and for the T2 cascade.  The prediction ability ofthe method is investigated by comparing the numerical predictions with theavailable experimental data not only in terms of wall isentropic Mach numberdistribution (which was used as goal function during the field inversion) butalso in terms of mass averaged exit angle and kinetic losses.},
	urldate = {2021-06-09},
	journal = {Computers and Fluids},
	author = {Ferrero, Andrea and Iollo, Angelo and Larocca, Francesco},
	month = apr,
	year = {2020},
	note = {Publisher: Elsevier},
	keywords = {Field inversion, Machine learning, Turbomachinery, Turbulence modelling},
	pages = {104474},
}

@article{parish_paradigm_2016,
	title = {A paradigm for data-driven predictive modeling using field inversion and machine learning},
	volume = {305},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999115007524},
	doi = {10.1016/j.jcp.2015.11.012},
	abstract = {We propose a modeling paradigm, termed field inversion and machine learning (FIML), that seeks to comprehensively harness data from sources such as high-fidelity simulations and experiments to aid the creation of improved closure models for computational physics applications. In contrast to inferring model parameters, this work uses inverse modeling to obtain corrective, spatially distributed functional terms, offering a route to directly address model-form errors. Once the inference has been performed over a number of problems that are representative of the deficient physics in the closure model, machine learning techniques are used to reconstruct the model corrections in terms of variables that appear in the closure model. These reconstructed functional forms are then used to augment the closure model in a predictive computational setting. As a first demonstrative example, a scalar ordinary differential equation is considered, wherein the model equation has missing and deficient terms. Following this, the methodology is extended to the prediction of turbulent channel flow. In both of these applications, the approach is demonstrated to be able to successfully reconstruct functional corrections and yield accurate predictive solutions while providing a measure of model form uncertainties.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Parish, Eric J. and Duraisamy, Karthik},
	month = jan,
	year = {2016},
	keywords = {Closure modeling, Data-driven modeling, Machine learning},
	pages = {758--774},
}

@article{thompson_methodology_2016,
	title = {A methodology to evaluate statistical errors in {DNS} data of plane channel flows},
	volume = {130},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793016300068},
	doi = {10.1016/j.compfluid.2016.01.014},
	abstract = {Direct numerical simulations (DNS) provide useful information for the understanding and the modeling of turbulence phenomena. In particular, new methodologies recently allowed the achievement of high Reynolds number in DNS of the benchmark plane channel flow. In this scenario, estimating the statistical errors associated with DNS is a difficult but necessary task. Here, we present a methodology to evaluate the statistical errors of the second-moment DNS data. In this methodology, the momentum balance equation is used to calculate the mean velocity profile by considering the Reynolds stress tensor provided by DNS. This error evaluation was applied to different plane channel flow databases available in the literature. We show that using the Reynolds stress statistics obtained from standard DNS can lead to significant discrepancies for turbulence modeling. One interesting consequence of this approach is that we are able to compute the Reynolds shear stress from the converged first order statistic. This information can be used, for instance, to extract a more accurate turbulent viscosity for turbulence modeling purposes. Moreover, the new methodology seems to be a promising path to formulate a convergence criterion for future plane channel DNS.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Computers \& Fluids},
	author = {Thompson, Roney L. and Sampaio, Luiz Eduardo B. and de Bragança Alves, Felipe A. V. and Thais, Laurent and Mompean, Gilmar},
	month = may,
	year = {2016},
	keywords = {Direct numerical simulation, Plane channel flow, RANS modeling, Statistic errors, Turbulence},
	pages = {1--7},
}

@article{jofre_framework_2018,
	title = {A {Framework} for {Characterizing} {Structural} {Uncertainty} in {Large}-{Eddy} {Simulation} {Closures}},
	volume = {100},
	issn = {1386-6184, 1573-1987},
	url = {http://link.springer.com/10.1007/s10494-017-9844-8},
	doi = {10.1007/s10494-017-9844-8},
	abstract = {Motivated by the sizable increase of available computing resources, large-eddy simulation of complex turbulent flow is becoming increasingly popular. The underlying filtering operation of this approach enables to represent only large-scale motions. However, the small-scale fluctuations and their effects on the resolved flow field require additional modeling. As a consequence, the assumptions made in the closure formulations become potential sources of incertitude that can impact the quantities of interest. The objective of this work is to introduce a framework for the systematic estimation of structural uncertainty in large-eddy simulation closures. In particular, the methodology proposed is independent of the initial model form, computationally efficient, and suitable to general flow solvers. The approach is based on introducing controlled perturbations to the turbulent stress tensor in terms of magnitude, shape and orientation, such that propagation of their effects can be assessed. The framework is rigorously described, and physically plausible bounds for the perturbations are proposed. As a means to test its performance, a comprehensive set of numerical experiments are reported for which physical interpretation of the deviations in the quantities of interest are discussed.},
	language = {en},
	number = {2},
	urldate = {2021-06-09},
	journal = {Flow, Turbulence and Combustion},
	author = {Jofre, Lluís and Domino, Stefan P. and Iaccarino, Gianluca},
	month = mar,
	year = {2018},
	pages = {341--363},
}

@article{zhao_rans_2020,
	title = {{RANS} turbulence model development using {CFD}-driven machine learning},
	volume = {411},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S002199912030187X},
	doi = {10.1016/j.jcp.2020.109413},
	abstract = {This paper presents a novel CFD-driven machine learning framework to develop Reynolds-averaged Navier-Stokes (RANS) models. The CFD-driven training is an extension of the gene expression programming method Weatheritt and Sandberg (2016) [8], but crucially the fitness of candidate models is now evaluated by running RANS calculations in an integrated way, rather than using an algebraic function. Unlike other data-driven methods that fit the Reynolds stresses of trained models to high-fidelity data, the cost function for the CFD-driven training can be defined based on any flow feature from the CFD results. This extends the applicability of the method especially when the training data is limited. Furthermore, the resulting model, which is the one providing the most accurate CFD results at the end of the training, inherently shows good performance in RANS calculations. To demonstrate the potential of this new method, the CFD-driven machine learning approach is applied to model development for wake mixing in turbomachines. A new model is trained based on a high-pressure turbine case and then tested for three additional cases, all representative of modern turbine nozzles. Despite the geometric configurations and operating conditions being different among the cases, the predicted wake mixing profiles are significantly improved in all of these a posteriori tests. Moreover, the model equation is explicitly given and available for analysis, thus it could be deduced that the enhanced wake prediction is predominantly due to the extra diffusion introduced by the CFD-driven model.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Zhao, Yaomin and Akolekar, Harshal D. and Weatheritt, Jack and Michelassi, Vittorio and Sandberg, Richard D.},
	month = jun,
	year = {2020},
	keywords = {Machine learning, Turbulence modelling, Wake mixing},
	pages = {109413},
}

@article{liu_iterative_2021,
	title = {An {Iterative} {Machine}-{Learning} {Framework} for {RANS} {Turbulence} {Modeling}},
	volume = {90},
	issn = {0142727X},
	url = {http://arxiv.org/abs/1910.01232},
	doi = {10.1016/j.ijheatfluidflow.2021.108822},
	abstract = {Machine-learning (ML) techniques provide a new and encouraging perspective for constructing turbulence models for Reynolds-averaged Navier--Stokes (RANS) simulations. In this study, an iterative ML-RANS computational framework is proposed that combines an ML algorithm with transport equations of a conventional turbulence model. This framework maintains a consistent procedure for obtaining the input features of an ML model in both the training and predicting stages, ensuring a built-in reproducibility. The effective form of the closure term is discussed to determine suitable target variables for the ML algorithm, and the multi-valued problem of existing constitutive theory is studied to establish a proper regression system for ML algorithms. The developed ML model is trained under a cross-case strategy with data from turbulent channel flows at three Reynolds numbers and {\textbackslash}textit\{a posteriori\} simulations of channel flows show that the framework is able to predict both the mean flow field and turbulent variables accurately. Interpolation tests for the channel flow show the proposed framework can reliably predict flow features that lie between the minimum and maximum Reynolds numbers associated with the training data. A further test related to the flow over periodic hills also demonstrates a better result than a traditional turbulence model, indicating a promising predictive capability of the developed ML model for separated flow even though the model is only trained with planar channel flow data.},
	urldate = {2021-06-09},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Liu, Weishuo and Fang, Jian and Rolfo, Stefano and Moulinec, Charles and Emerson, David R.},
	month = aug,
	year = {2021},
	note = {arXiv: 1910.01232},
	keywords = {Physics - Fluid Dynamics},
	pages = {108822},
}

@article{ni_sensitivity_2019,
	title = {Sensitivity analysis on chaotic dynamical systems by {Finite} {Difference} {Non}-{Intrusive} {Least} {Squares} {Shadowing} ({FD}-{NILSS})},
	volume = {394},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999119304115},
	doi = {10.1016/j.jcp.2019.06.004},
	abstract = {We present the Finite Difference Non-Intrusive Least Squares Shadowing (FD-NILSS) algorithm for computing sensitivities of long-time averaged quantities in chaotic dynamical systems. FD-NILSS does not require tangent solvers, and can be implemented with little modification to existing numerical simulation software. We also give a formula for solving the least-squares problem in FD-NILSS, which can be applied in NILSS as well. Finally, we apply FD-NILSS for sensitivity analysis of a chaotic flow over a 3-D cylinder at Reynolds number 525, where FD-NILSS computes accurate sensitivities and the computational cost is in the same order as the numerical simulation.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Ni, Angxiu and Wang, Qiqi and Fernández, Pablo and Talnikar, Chaitanya},
	month = oct,
	year = {2019},
	keywords = {Chaotic dyanmical systems, Computational fluid dynamics, Least squares shadowing, Non-intrusive formulation, Sensitivity analysis, Shadowing lemma},
	pages = {615--631},
}

@article{blonigan_adjoint_2017,
	title = {Adjoint sensitivity analysis of chaotic dynamical systems with non-intrusive least squares shadowing},
	volume = {348},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999117305739},
	doi = {10.1016/j.jcp.2017.08.002},
	abstract = {This paper presents a discrete adjoint version of the recently developed non-intrusive least squares shadowing (NILSS) algorithm, which circumvents the instability that conventional adjoint methods encounter for chaotic systems. The NILSS approach involves solving a smaller minimization problem than other shadowing approaches and can be implemented with only minor modifications to preexisting tangent and adjoint solvers. Adjoint NILSS is demonstrated on a small chaotic ODE, a one-dimensional scalar PDE, and a direct numerical simulation (DNS) of the minimal flow unit, a turbulent channel flow on a small spatial domain. This is the first application of an adjoint shadowing-based algorithm to a three-dimensional turbulent flow.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Blonigan, Patrick J.},
	month = nov,
	year = {2017},
	keywords = {Adjoint, Chaos, Sensitivity analysis, Shadowing},
	pages = {803--826},
}

@article{blonigan_multiple_2018,
	title = {Multiple shooting shadowing for sensitivity analysis of chaotic dynamical systems},
	volume = {354},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S002199911730791X},
	doi = {10.1016/j.jcp.2017.10.032},
	abstract = {Sensitivity analysis methods are important tools for research and design with simulations. Many important simulations exhibit chaotic dynamics, including scale-resolving turbulent fluid flow simulations. Unfortunately, conventional sensitivity analysis methods are unable to compute useful gradient information for long-time-averaged quantities in chaotic dynamical systems. Sensitivity analysis with least squares shadowing (LSS) can compute useful gradient information for a number of chaotic systems, including simulations of chaotic vortex shedding and homogeneous isotropic turbulence. However, this gradient information comes at a very high computational cost. This paper presents multiple shooting shadowing (MSS), a more computationally efficient shadowing approach than the original LSS approach. Through an analysis of the convergence rate of MSS, it is shown that MSS can have lower memory usage and run time than LSS.},
	language = {en},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Blonigan, Patrick J. and Wang, Qiqi},
	month = feb,
	year = {2018},
	keywords = {Adjoint, Chaos, Sensitivity analysis, Shadowing},
	pages = {447--475},
}

@article{blonigan_multiple_2018-1,
	title = {Multiple {Shooting} {Shadowing} for {Sensitivity} {Analysis} of {Chaotic} {Dynamical} {Systems}},
	volume = {354},
	issn = {00219991},
	url = {http://arxiv.org/abs/1704.02047},
	doi = {10.1016/j.jcp.2017.10.032},
	abstract = {Sensitivity analysis methods are important tools for research and design with simulations. Many important simulations exhibit chaotic dynamics, including scale-resolving turbulent fluid flow simulations. Unfortunately, conventional sensitivity analysis methods are unable to compute useful gradient information for long-time-averaged quantities in chaotic dynamical systems. Sensitivity analysis with least squares shadowing (LSS) can compute useful gradient information for a number of chaotic systems, including simulations of chaotic vortex shedding and homogeneous isotropic turbulence. However, this gradient information comes at a very high computational cost. This paper presents multiple shooting shadowing (MSS), a more computationally efficient shadowing approach than the original LSS approach. Through an analysis of the convergence rate of MSS, it is shown that MSS can have lower memory usage and run time than LSS.},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Blonigan, Patrick J. and Wang, Qiqi},
	month = feb,
	year = {2018},
	note = {arXiv: 1704.02047},
	keywords = {Nonlinear Sciences - Chaotic Dynamics},
	pages = {447--475},
}

@article{xiao_quantifying_2016,
	title = {Quantifying and {Reducing} {Model}-{Form} {Uncertainties} in {Reynolds}-{Averaged} {Navier}-{Stokes} {Simulations}: {A} {Data}-{Driven}, {Physics}-{Based} {Bayesian} {Approach}},
	volume = {324},
	issn = {00219991},
	shorttitle = {Quantifying and {Reducing} {Model}-{Form} {Uncertainties} in {Reynolds}-{Averaged} {Navier}-{Stokes} {Simulations}},
	url = {http://arxiv.org/abs/1508.06315},
	doi = {10.1016/j.jcp.2016.07.038},
	abstract = {Despite their well-known limitations, Reynolds-Averaged Navier-Stokes (RANS) models are still the workhorse tools for turbulent flow simulations in today's engineering application. For many practical flows, the turbulence models are by far the largest source of uncertainty. In this work we develop an open-box, physics-informed Bayesian framework for quantifying model-form uncertainties in RANS simulations. Uncertainties are introduced directly to the Reynolds stresses and are represented with compact parameterization accounting for empirical prior knowledge and physical constraints (e.g., realizability, smoothness, and symmetry). An iterative ensemble Kalman method is used to assimilate the prior knowledge and observation data in a Bayesian framework, and to propagate them to posterior distributions of velocities and other Quantities of Interest (QoIs). We use two representative cases, the flow over periodic hills and the flow in a square duct, to evaluate the performance of the proposed framework. Simulation results suggest that, even with very sparse observations, the posterior mean velocities and other QoIs have significantly better agreement with the benchmark data compared to the baseline results. At most locations the posterior distribution adequately captures the true model error within the developed model form uncertainty bounds. The framework is a major improvement over existing black-box, physics-neutral methods for model-form uncertainty quantification, where prior knowledge and details of the models are not exploited. This approach has potential implications in many fields in which the governing equations are well understood but the model uncertainty comes from unresolved physical processes.},
	urldate = {2021-06-09},
	journal = {Journal of Computational Physics},
	author = {Xiao, H. and Wu, J.-L. and Wang, J.-X. and Sun, R. and Roy, C. J.},
	month = nov,
	year = {2016},
	note = {arXiv: 1508.06315},
	keywords = {76F99, Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {115--136},
}

@article{mcconkey_curated_2021,
	title = {A curated dataset for data-driven turbulence modelling},
	url = {http://arxiv.org/abs/2103.11515},
	abstract = {The recent surge in machine learning augmented turbulence modelling is a promising approach for addressing the limitations of Reynolds-averaged Navier-Stokes (RANS) models. This work presents the development of the first open-source dataset, curated and structured for immediate use in machine learning augmented turbulence closure modelling. The dataset features a variety of RANS simulations with matching direct numerical simulation (DNS) and large-eddy simulation (LES) data. Four turbulence models are selected to form the initial dataset: \$k\$-\${\textbackslash}varepsilon\$, \$k\$-\${\textbackslash}varepsilon\$-\${\textbackslash}phi\_t\$-\$f\$, \$k\$-\${\textbackslash}omega\$, and \$k\$-\${\textbackslash}omega\$ SST. The dataset consists of 29 cases per turbulence model, for several parametrically sweeping reference DNS/LES cases: periodic hills, square duct, parametric bumps, converging-diverging channel, and a curved backward-facing step. At each of the 895,640 points, various RANS features with DNS/LES labels are available. The feature set includes quantities used in current state-of-the-art models, and additional fields which enable the generation of new feature sets. The dataset reduces effort required to train, test, and benchmark new models. The dataset is available at https://doi.org/10.34740/kaggle/dsv/2044393 .},
	urldate = {2021-06-09},
	journal = {arXiv:2103.11515 [physics]},
	author = {McConkey, Ryley and Yee, Eugene and Lien, Fue-Sang},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.11515},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{hijazi_data-driven_2020,
	title = {Data-driven {POD}-{Galerkin} reduced order model for turbulent flows},
	volume = {416},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120302874},
	doi = {10.1016/j.jcp.2020.109513},
	abstract = {In this work we present a Reduced Order Model which is specifically designed to deal with turbulent flows in a finite volume setting. The method used to build the reduced order model is based on the idea of merging/combining projection-based techniques with data-driven reduction strategies. In particular, the work presents a mixed strategy that exploits a data-driven reduction method to approximate the eddy viscosity solution manifold and a classical POD-Galerkin projection approach for the velocity and the pressure fields, respectively. The newly proposed reduced order model has been validated on benchmark test cases in both steady and unsteady settings with Reynolds up to Re=O(105).},
	language = {en},
	urldate = {2021-06-08},
	journal = {Journal of Computational Physics},
	author = {Hijazi, Saddam and Stabile, Giovanni and Mola, Andrea and Rozza, Gianluigi},
	month = sep,
	year = {2020},
	keywords = {Data-driven ROM, Eddy viscosity ROM, Finite volume approximation, Navier-Stokes equations, Proper orthogonal decomposition, Turbulent ROM},
	pages = {109513},
}

@article{benner_survey_2015,
	title = {A {Survey} of {Projection}-{Based} {Model} {Reduction} {Methods} for {Parametric} {Dynamical} {Systems}},
	volume = {57},
	issn = {0036-1445, 1095-7200},
	url = {http://epubs.siam.org/doi/10.1137/130932715},
	doi = {10.1137/130932715},
	abstract = {Numerical simulation of large-scale dynamical systems plays a fundamental role in studying a wide range of complex physical phenomena; however, the inherent large-scale nature of the models often leads to unmanageable demands on computational resources. Model reduction aims to reduce this computational burden by generating reduced models that are faster and cheaper to simulate, yet accurately represent the original large-scale system behavior. Model reduction of linear, nonparametric dynamical systems has reached a considerable level of maturity, as reﬂected by several survey papers and books. However, parametric model reduction has emerged only more recently as an important and vibrant research area, with several recent advances making a survey paper timely. Thus, this paper aims to provide a resource that draws together recent contributions in diﬀerent communities to survey the state of the art in parametric model reduction methods.},
	language = {en},
	number = {4},
	urldate = {2021-06-08},
	journal = {SIAM Review},
	author = {Benner, Peter and Gugercin, Serkan and Willcox, Karen},
	month = jan,
	year = {2015},
	pages = {483--531},
}

@article{maulik_time-series_2020,
	title = {Time-series learning of latent-space dynamics for reduced-order model closure},
	volume = {405},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278919305536},
	doi = {10.1016/j.physd.2020.132368},
	abstract = {We study the performance of long short-term memory networks (LSTMs) and neural ordinary differential equations (NODEs) in learning latent-space representations of dynamical equations for an advection-dominated problem given by the viscous Burgers equation. Our formulation is devised in a nonintrusive manner with an equation-free evolution of dynamics in a reduced space with the latter being obtained through a proper orthogonal decomposition. In addition, we leverage the sequential nature of learning for both LSTMs and NODEs to demonstrate their capability for closure in systems that are not completely resolved in the reduced space. We assess our hypothesis for two advection-dominated problems given by the viscous Burgers equation. We observe that both LSTMs and NODEs are able to reproduce the effects of the absent scales for our test cases more effectively than does intrusive dynamics evolution through a Galerkin projection. This result empirically suggests that time-series learning techniques implicitly leverage a memory kernel for coarse-grained system closure as is suggested through the Mori–Zwanzig formalism.},
	language = {en},
	urldate = {2021-06-08},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Maulik, Romit and Mohan, Arvind and Lusch, Bethany and Madireddy, Sandeep and Balaprakash, Prasanna and Livescu, Daniel},
	month = apr,
	year = {2020},
	keywords = {Closures, LSTMs, Neural ODEs, ROMs},
	pages = {132368},
}

@article{maulik_reduced-order_2021,
	title = {Reduced-order modeling of advection-dominated systems with recurrent neural networks and convolutional autoencoders},
	volume = {33},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/full/10.1063/5.0039986},
	doi = {10.1063/5.0039986},
	abstract = {A common strategy for the dimensionality reduction of nonlinear partial differential equations (PDEs) relies on the use of the proper orthogonal decomposition (POD) to identify a reduced subspace and the Galerkin projection for evolving dynamics in this reduced space. However, advection-dominated PDEs are represented poorly by this methodology since the process of truncation discards important interactions between higher-order modes during time evolution. In this study, we demonstrate that encoding using convolutional autoencoders (CAEs) followed by a reduced-space time evolution by recurrent neural networks overcomes this limitation effectively. We demonstrate that a truncated system of only two latent space dimensions can reproduce a sharp advecting shock profile for the viscous Burgers equation with very low viscosities, and a six-dimensional latent space can recreate the evolution of the inviscid shallow water equations. Additionally, the proposed framework is extended to a parametric reduced-order model by directly embedding parametric information into the latent space to detect trends in system evolution. Our results show that these advection-dominated systems are more amenable to low-dimensional encoding and time evolution by a CAE and recurrent neural network combination than the POD-Galerkin technique.},
	number = {3},
	urldate = {2021-06-08},
	journal = {Physics of Fluids},
	author = {Maulik, Romit and Lusch, Bethany and Balaprakash, Prasanna},
	month = mar,
	year = {2021},
	note = {Publisher: American Institute of Physics},
	pages = {037106},
}

@article{akrivis_linearly_2015,
	title = {Linearly implicit schemes for multi-dimensional {Kuramoto}–{Sivashinsky} type equations arising in falling film flows},
	issn = {0272-4979, 1464-3642},
	url = {https://academic.oup.com/imajna/article-lookup/doi/10.1093/imanum/drv011},
	doi = {10.1093/imanum/drv011},
	language = {en},
	urldate = {2021-06-01},
	journal = {IMA Journal of Numerical Analysis},
	author = {Akrivis, Georgios and Kalogirou, Anna and Papageorgiou, Demetrios T. and Smyrlis, Yiorgos-Sokratis},
	month = apr,
	year = {2015},
	pages = {drv011},
}

@article{akrivis_linearly_nodate,
	title = {{LINEARLY} {IMPLICIT} {SPECTRAL} {SCHEMES} {FOR} {THE} {DISPERSIVELY} {MODIFIED} {KS} {EQUATION}},
	abstract = {We analyze fully discrete schemes for periodic initial value problems for the dispersively modiﬁed Kuramoto–Sivashinsky equation. In space we discretize by spectral methods and in time by linearly implicit schemes. In the general case we use ﬁrst– and second–order time–stepping schemes; in the case of low order dispersive terms, we can also use appropriate high order time–stepping schemes. We derive optimal order error estimates.},
	language = {en},
	author = {Akrivis, G and Papageorgiou, D T and Smyrlis, S},
	pages = {21},
}

@article{akrivis_implicitexplicit_2004,
	title = {Implicit–explicit {BDF} methods for the {Kuramoto}–{Sivashinsky} equation},
	volume = {51},
	issn = {0168-9274},
	url = {https://www.sciencedirect.com/science/article/pii/S016892740400056X},
	doi = {10.1016/j.apnum.2004.03.002},
	abstract = {We consider the periodic initial value problem for the Kuramoto–Sivashinsky (KS) equation. We approximate the solution by discretizing in time by implicit–explicit BDF schemes and in space by a pseudo-spectral method. We present the results of various numerical experiments.},
	language = {en},
	number = {2},
	urldate = {2021-06-01},
	journal = {Applied Numerical Mathematics},
	author = {Akrivis, Georgios and Smyrlis, Yiorgos-Sokratis},
	month = nov,
	year = {2004},
	keywords = {Implicit–explicit BDF methods, Kuramoto–Sivashinsky equation, Period doubling cascades, Periodic attractors},
	pages = {151--169},
}

@article{ravanbakhsh_universal_2020,
	title = {Universal {Equivariant} {Multilayer} {Perceptrons}},
	url = {http://arxiv.org/abs/2002.02912},
	abstract = {Group invariant and equivariant Multilayer Perceptrons (MLP), also known as Equivariant Networks, have achieved remarkable success in learning on a variety of data structures, such as sequences, images, sets, and graphs. Using tools from group theory, this paper proves the universality of a broad class of equivariant MLPs with a single hidden layer. In particular, it is shown that having a hidden layer on which the group acts regularly is sufficient for universal equivariance (invariance). A corollary is unconditional universality of equivariant MLPs for Abelian groups, such as CNNs with a single hidden layer. A second corollary is the universality of equivariant MLPs with a high-order hidden layer, where we give both group-agnostic bounds and means for calculating group-specific bounds on the order of hidden layer that guarantees universal equivariance (invariance).},
	urldate = {2021-06-01},
	journal = {arXiv:2002.02912 [cs, math, stat]},
	author = {Ravanbakhsh, Siamak},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.02912},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Group Theory, Statistics - Machine Learning},
}

@article{rosales_linear_2005,
	title = {Linear forcing in numerical simulations of isotropic turbulence: {Physical} space implementations and convergence properties},
	volume = {17},
	issn = {1070-6631, 1089-7666},
	shorttitle = {Linear forcing in numerical simulations of isotropic turbulence},
	url = {http://aip.scitation.org/doi/10.1063/1.2047568},
	doi = {10.1063/1.2047568},
	language = {en},
	number = {9},
	urldate = {2021-05-31},
	journal = {Physics of Fluids},
	author = {Rosales, Carlos and Meneveau, Charles},
	month = sep,
	year = {2005},
	pages = {095106},
}

@article{rosales_linear_2005-1,
	title = {Linear forcing in numerical simulations of isotropic turbulence: {Physical} space implementations and convergence properties},
	volume = {17},
	issn = {1070-6631},
	shorttitle = {Linear forcing in numerical simulations of isotropic turbulence},
	url = {https://aip.scitation.org/doi/10.1063/1.2047568},
	doi = {10.1063/1.2047568},
	number = {9},
	urldate = {2021-05-31},
	journal = {Physics of Fluids},
	author = {Rosales, Carlos and Meneveau, Charles},
	month = sep,
	year = {2005},
	note = {Publisher: American Institute of Physics},
	pages = {095106},
}

@article{lundgren_linearly_nodate,
	title = {Linearly forced isotropic turbulence},
	language = {en},
	author = {Lundgren, T S},
	pages = {13},
}

@article{rogallo_numerical_1984,
	title = {Numerical {Simulation} of {Turbulent} {Flows}},
	volume = {16},
	issn = {0066-4189},
	url = {https://www.annualreviews.org/doi/10.1146/annurev.fl.16.010184.000531},
	doi = {10.1146/annurev.fl.16.010184.000531},
	number = {1},
	urldate = {2021-05-31},
	journal = {Annual Review of Fluid Mechanics},
	author = {Rogallo, R S and Moin, P},
	month = jan,
	year = {1984},
	note = {Publisher: Annual Reviews},
	pages = {99--137},
}

@article{rogallo_numerical_nodate,
	title = {Numerical {Experiments} in {Homogeneous} {Turbulence}},
	language = {en},
	author = {Rogallo, S},
	pages = {93},
}

@article{de_laage_de_meux_anisotropic_2015,
	title = {Anisotropic linear forcing for synthetic turbulence generation in large eddy simulation and hybrid {RANS}/{LES} modeling},
	volume = {27},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.4916019},
	doi = {10.1063/1.4916019},
	number = {3},
	urldate = {2021-05-31},
	journal = {Physics of Fluids},
	author = {de Laage de Meux, B. and Audebert, B. and Manceau, R. and Perrin, R.},
	month = mar,
	year = {2015},
	note = {Publisher: American Institute of Physics},
	pages = {035115},
}

@article{eswaran_examination_1988,
	title = {An examination of forcing in direct numerical simulations of turbulence},
	volume = {16},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/0045793088900138},
	doi = {10.1016/0045-7930(88)90013-8},
	abstract = {A spectral forcing scheme is developed to provide the means to obtain statistically stationary velocity fields in direct numerical simulations of homogeneous, isotropic turbulence. Tests of the forcing scheme show that the details of the forcing do not have a significant effect on the small-scale structure of the velocity fields. Forced turbulent simulations are used to determine the effects of the time-step, and the spatial resolution of the grid, on the computations.},
	language = {en},
	number = {3},
	urldate = {2021-05-31},
	journal = {Computers \& Fluids},
	author = {Eswaran, V. and Pope, S. B.},
	month = jan,
	year = {1988},
	pages = {257--278},
}

@article{eswaran_examination_1988-1,
	title = {An examination of forcing in direct numerical simulations of turbulence},
	volume = {16},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/0045793088900138},
	doi = {10.1016/0045-7930(88)90013-8},
	abstract = {A spectral forcing scheme is developed to provide the means to obtain statistically stationary velocity fields in direct numerical simulations of homogeneous, isotropic turbulence. Tests of the forcing scheme show that the details of the forcing do not have a significant effect on the small-scale structure of the velocity fields. Forced turbulent simulations are used to determine the effects of the time-step, and the spatial resolution of the grid, on the computations.},
	language = {en},
	number = {3},
	urldate = {2021-05-31},
	journal = {Computers \& Fluids},
	author = {Eswaran, V. and Pope, S. B.},
	month = jan,
	year = {1988},
	pages = {257--278},
}

@article{kalogirou_-depth_2015,
	title = {An in-depth numerical study of the two-dimensional {Kuramoto}–{Sivashinsky} equation},
	volume = {471},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2014.0932},
	doi = {10.1098/rspa.2014.0932},
	abstract = {The Kuramoto–Sivashinsky equation in one spatial dimension (1D KSE) is one of the most well-known and well-studied partial differential equations. It exhibits spatio-temporal chaos that emerges through various bifurcations as the domain length increases. There have been several notable analytical studies aimed at understanding how this property extends to the case of two spatial dimensions. In this study, we perform an extensive numerical study of the Kuramoto–Sivashinsky equation (2D KSE) to complement this analytical work. We explore in detail the statistics of chaotic solutions and classify the solutions that arise for domain sizes where the trivial solution is unstable and the long-time dynamics are completely two-dimensional. While we find that many of the features of the 1D KSE, including how the energy scales with system size, carry over to the 2D case, we also note several differences including the various paths to chaos that are not through period doubling.},
	number = {2179},
	urldate = {2021-05-28},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Kalogirou, A. and Keaveny, E. E. and Papageorgiou, D. T.},
	month = jul,
	year = {2015},
	note = {Publisher: Royal Society},
	pages = {20140932},
}

@article{finzi_practical_2021,
	title = {A {Practical} {Method} for {Constructing} {Equivariant} {Multilayer} {Perceptrons} for {Arbitrary} {Matrix} {Groups}},
	url = {http://arxiv.org/abs/2104.09459},
	abstract = {Symmetries and equivariance are fundamental to the generalization of neural networks on domains such as images, graphs, and point clouds. Existing work has primarily focused on a small number of groups, such as the translation, rotation, and permutation groups. In this work we provide a completely general algorithm for solving for the equivariant layers of matrix groups. In addition to recovering solutions from other works as special cases, we construct multilayer perceptrons equivariant to multiple groups that have never been tackled before, including \${\textbackslash}mathrm\{O\}(1,3)\$, \${\textbackslash}mathrm\{O\}(5)\$, \${\textbackslash}mathrm\{Sp\}(n)\$, and the Rubik's cube group. Our approach outperforms non-equivariant baselines, with applications to particle physics and dynamical systems. We release our software library to enable researchers to construct equivariant layers for arbitrary matrix groups.},
	urldate = {2021-05-27},
	journal = {arXiv:2104.09459 [cs, math, stat]},
	author = {Finzi, Marc and Welling, Max and Wilson, Andrew Gordon},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.09459},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Statistics - Machine Learning},
}

@article{lu_deepxde_2020,
	title = {{DeepXDE}: {A} deep learning library for solving differential equations},
	shorttitle = {{DeepXDE}},
	url = {http://arxiv.org/abs/1907.04502},
	abstract = {Deep learning has achieved remarkable success in diverse applications; however, its use in solving partial differential equations (PDEs) has emerged only recently. Here, we present an overview of physics-informed neural networks (PINNs), which embed a PDE into the loss of the neural network using automatic differentiation. The PINN algorithm is simple, and it can be applied to different types of PDEs, including integro-differential equations, fractional PDEs, and stochastic PDEs. Moreover, from the implementation point of view, PINNs solve inverse problems as easily as forward problems. We propose a new residual-based adaptive refinement (RAR) method to improve the training efficiency of PINNs. For pedagogical reasons, we compare the PINN algorithm to a standard finite element method. We also present a Python library for PINNs, DeepXDE, which is designed to serve both as an education tool to be used in the classroom as well as a research tool for solving problems in computational science and engineering. Specifically, DeepXDE can solve forward problems given initial and boundary conditions, as well as inverse problems given some extra measurements. DeepXDE supports complex-geometry domains based on the technique of constructive solid geometry, and enables the user code to be compact, resembling closely the mathematical formulation. We introduce the usage of DeepXDE and its customizability, and we also demonstrate the capability of PINNs and the user-friendliness of DeepXDE for five different examples. More broadly, DeepXDE contributes to the more rapid development of the emerging Scientific Machine Learning field.},
	urldate = {2021-05-27},
	journal = {arXiv:1907.04502 [physics, stat]},
	author = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George E.},
	month = feb,
	year = {2020},
	note = {arXiv: 1907.04502},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{eivazi_recurrent_2021,
	title = {Recurrent neural networks and {Koopman}-based frameworks for temporal predictions in a low-order model of turbulence},
	volume = {90},
	issn = {0142-727X},
	url = {https://www.sciencedirect.com/science/article/pii/S0142727X21000461},
	doi = {10.1016/j.ijheatfluidflow.2021.108816},
	abstract = {The capabilities of recurrent neural networks and Koopman-based frameworks are assessed in the prediction of temporal dynamics of the low-order model of near-wall turbulence by Moehlis et al. (New J. Phys. 6, 56, 2004). Our results show that it is possible to obtain excellent reproductions of the long-term statistics and the dynamic behavior of the chaotic system with properly trained long-short-term memory (LSTM) networks, leading to relative errors in the mean and the fluctuations below 1\%. Besides, a newly developed Koopman-based framework, called Koopman with nonlinear forcing (KNF), leads to the same level of accuracy in the statistics at a significantly lower computational expense. Furthermore, the KNF framework outperforms the LSTM network when it comes to short-term predictions. We also observe that using a loss function based only on the instantaneous predictions of the chaotic system can lead to suboptimal reproductions in terms of long-term statistics. Thus, we propose a model-selection criterion based on the computed statistics which allows to achieve excellent statistical reconstruction even on small datasets, with minimal loss of accuracy in the instantaneous predictions.},
	language = {en},
	urldate = {2021-05-18},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Eivazi, Hamidreza and Guastoni, Luca and Schlatter, Philipp and Azizpour, Hossein and Vinuesa, Ricardo},
	month = aug,
	year = {2021},
	keywords = {Data-driven modeling, Dynamical systems, Koopman operator, Machine learning, Recurrent neural networks},
	pages = {108816},
}

@article{rubanova_latent_2019,
	title = {Latent {ODEs} for {Irregularly}-{Sampled} {Time} {Series}},
	url = {http://arxiv.org/abs/1907.03907},
	abstract = {Time series with non-uniform intervals occur in many applications, and are difficult to model using standard recurrent neural networks (RNNs). We generalize RNNs to have continuous-time hidden dynamics defined by ordinary differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps between observations, and can explicitly model the probability of observation times using Poisson processes. We show experimentally that these ODE-based models outperform their RNN-based counterparts on irregularly-sampled data.},
	urldate = {2021-05-18},
	journal = {arXiv:1907.03907 [cs, stat]},
	author = {Rubanova, Yulia and Chen, Ricky T. Q. and Duvenaud, David},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.03907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{li_scalable_2020,
	title = {Scalable {Gradients} for {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2001.01328},
	abstract = {The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differential equation whose solution is the gradient, a memory-efficient algorithm for caching noise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance on a 50-dimensional motion capture dataset.},
	urldate = {2021-05-18},
	journal = {arXiv:2001.01328 [cs, math, stat]},
	author = {Li, Xuechen and Wong, Ting-Kam Leonard and Chen, Ricky T. Q. and Duvenaud, David},
	month = oct,
	year = {2020},
	note = {arXiv: 2001.01328},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{kidger_neural_2021,
	title = {Neural {SDEs} as {Infinite}-{Dimensional} {GANs}},
	url = {http://arxiv.org/abs/2102.03657},
	abstract = {Stochastic differential equations (SDEs) are a staple of mathematical modelling of temporal dynamics. However, a fundamental limitation has been that such models have typically been relatively inflexible, which recent work introducing Neural SDEs has sought to solve. Here, we show that the current classical approach to fitting SDEs may be approached as a special case of (Wasserstein) GANs, and in doing so the neural and classical regimes may be brought together. The input noise is Brownian motion, the output samples are time-evolving paths produced by a numerical solver, and by parameterising a discriminator as a Neural Controlled Differential Equation (CDE), we obtain Neural SDEs as (in modern machine learning parlance) continuous-time generative time series models. Unlike previous work on this problem, this is a direct extension of the classical approach without reference to either prespecified statistics or density functions. Arbitrary drift and diffusions are admissible, so as the Wasserstein loss has a unique global minima, in the infinite data limit any SDE may be learnt. Example code has been made available as part of the {\textbackslash}texttt\{torchsde\} repository.},
	urldate = {2021-05-18},
	journal = {arXiv:2102.03657 [cs]},
	author = {Kidger, Patrick and Foster, James and Li, Xuechen and Oberhauser, Harald and Lyons, Terry},
	month = may,
	year = {2021},
	note = {arXiv: 2102.03657},
	keywords = {Computer Science - Machine Learning},
}

@article{duraisamy_perspectives_2021,
	title = {Perspectives on {Machine} {Learning}-augmented {Reynolds}-averaged and {Large} {Eddy} {Simulation} {Models} of {Turbulence}},
	url = {http://arxiv.org/abs/2009.10675},
	abstract = {This work presents a review and perspectives on recent developments in the use of machine learning (ML) to augment Reynolds-averaged Navier--Stokes (RANS) and Large Eddy Simulation (LES) models of turbulent flows. Different approaches of applying supervised learning to represent unclosed terms, model discrepancies and sub-filter scales are discussed in the context of RANS and LES modeling. Particular emphasis is placed on the impact of the training procedure on the consistency of ML augmentations with the underlying physical model. Techniques to promote model-consistent training, and to avoid the requirement of full fields of direct numerical simulation data are detailed. This is followed by a discussion of physics-informed and mathematical considerations on the choice of the feature space, and imposition of constraints on the ML model. With a view towards developing generalizable ML-augmented RANS and LES models, outstanding challenges are discussed, and perspectives are provided. While the promise of ML-augmented turbulence modeling is clear, and successes have been demonstrated in isolated scenarios, a general consensus of this paper is that truly generalizable models require model-consistent training with careful characterization of underlying assumptions and imposition of physically and mathematically informed priors and constraints to account for the inevitable shortage of data relevant to predictions of interest. Thus, machine learning should be viewed as one tool in the turbulence modeler's toolkit. This modeling endeavor requires multi-disciplinary advances, and thus the target audience for this paper is the fluid mechanics community, as well as the computational science and machine learning communities.},
	urldate = {2021-05-17},
	journal = {arXiv:2009.10675 [physics]},
	author = {Duraisamy, Karthik},
	month = jan,
	year = {2021},
	note = {arXiv: 2009.10675},
	keywords = {Physics - Fluid Dynamics},
}

@article{duraisamy_perspectives_2021-1,
	title = {Perspectives on machine learning-augmented {Reynolds}-averaged and large eddy simulation models of turbulence},
	volume = {6},
	url = {https://link.aps.org/doi/10.1103/PhysRevFluids.6.050504},
	doi = {10.1103/PhysRevFluids.6.050504},
	abstract = {This work presents a review and perspectives on recent developments in the use of machine learning (ML) to augment Reynolds-averaged Navier-Stokes (RANS) and large eddy simulation (LES) models of turbulent flows. Different approaches of applying supervised learning to represent unclosed terms, model discrepancies, and subfilter scales are discussed in the context of RANS and LES modeling. Particular emphasis is placed on the impact of the training procedure on the consistency of ML augmentations with the underlying physical model. Techniques to promote model-consistent training, and to avoid the requirement of full fields of direct numerical simulation data are detailed. This is followed by a discussion of physics-informed and mathematical considerations on the choice of the feature space, and imposition of constraints on the ML model. With a view towards developing generalizable ML-augmented RANS and LES models, outstanding challenges are discussed, and perspectives are provided. While the promise of ML-augmented turbulence modeling is clear, and successes have been demonstrated in isolated scenarios, a general consensus of this paper is that truly generalizable models require model-consistent training with careful characterization of underlying assumptions and imposition of physically and mathematically informed priors and constraints to account for the inevitable shortage of data relevant to predictions of interest. Thus, machine learning should be viewed as one tool in the turbulence modeler's toolkit. This modeling endeavor requires multidisciplinary advances, and thus the target audience for this paper is the fluid mechanics community, as well as the computational science and machine learning communities., This article appears in the following collection:},
	number = {5},
	urldate = {2021-05-17},
	journal = {Physical Review Fluids},
	author = {Duraisamy, Karthik},
	month = may,
	year = {2021},
	note = {Publisher: American Physical Society},
	pages = {050504},
}

@article{beck_perspective_2020,
	title = {A {Perspective} on {Machine} {Learning} {Methods} in {Turbulence} {Modelling}},
	url = {http://arxiv.org/abs/2010.12226},
	abstract = {This work presents a review of the current state of research in data-driven turbulence closure modeling. It offers a perspective on the challenges and open issues, but also on the advantages and promises of machine learning methods applied to parameter estimation, model identification, closure term reconstruction and beyond, mostly from the perspective of Large Eddy Simulation and related techniques. We stress that consistency of the training data, the model, the underlying physics and the discretization is a key issue that needs to be considered for a successful ML-augmented modeling strategy. In order to make the discussion useful for non-experts in either field, we introduce both the modeling problem in turbulence as well as the prominent ML paradigms and methods in a concise and self-consistent manner. Following, we present a survey of the current data-driven model concepts and methods, highlight important developments and put them into the context of the discussed challenges.},
	urldate = {2021-05-17},
	journal = {arXiv:2010.12226 [cs]},
	author = {Beck, Andrea and Kurz, Marius},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.12226},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@article{vlachas_backpropagation_2020,
	title = {Backpropagation algorithms and {Reservoir} {Computing} in {Recurrent} {Neural} {Networks} for the forecasting of complex spatiotemporal dynamics},
	volume = {126},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608020300708},
	doi = {10.1016/j.neunet.2020.02.016},
	abstract = {We examine the efficiency of Recurrent Neural Networks in forecasting the spatiotemporal dynamics of high dimensional and reduced order complex systems using Reservoir Computing (RC) and Backpropagation through time (BPTT) for gated network architectures. We highlight advantages and limitations of each method and discuss their implementation for parallel computing architectures. We quantify the relative prediction accuracy of these algorithms for the long-term forecasting of chaotic systems using as benchmarks the Lorenz-96 and the Kuramoto–Sivashinsky (KS) equations. We find that, when the full state dynamics are available for training, RC outperforms BPTT approaches in terms of predictive performance and in capturing of the long-term statistics, while at the same time requiring much less training time. However, in the case of reduced order data, large scale RC models can be unstable and more likely than the BPTT algorithms to diverge. In contrast, RNNs trained via BPTT show superior forecasting abilities and capture well the dynamics of reduced order systems. Furthermore, the present study quantifies for the first time the Lyapunov Spectrum of the KS equation with BPTT, achieving similar accuracy as RC. This study establishes that RNNs are a potent computational framework for the learning and forecasting of complex spatiotemporal systems.},
	language = {en},
	urldate = {2021-05-17},
	journal = {Neural Networks},
	author = {Vlachas, P. R. and Pathak, J. and Hunt, B. R. and Sapsis, T. P. and Girvan, M. and Ott, E. and Koumoutsakos, P.},
	month = jun,
	year = {2020},
	keywords = {Complex systems, Kuramoto–Sivashinsky, Lorenz-96, RNN, LSTM, GRU, Reservoir Computing, Time series forecasting},
	pages = {191--217},
}

@article{choma_bex_stochastic_2020,
	title = {A stochastic method to account for the ambient turbulence in {Lagrangian} {Vortex} computations},
	volume = {88},
	issn = {0307-904X},
	url = {https://www.sciencedirect.com/science/article/pii/S0307904X20302614},
	doi = {10.1016/j.apm.2020.05.025},
	abstract = {This paper describes a detailed implementation of the Synthetic Eddy Method (SEM) initially presented in Jarrin et al. (2006) applied to the Lagrangian Vortex simulation. While the treatment of turbulent diffusion is already extensively covered in scientific literature, this is one of the first attempts to represent ambient turbulence in a fully Lagrangian framework. This implementation is well suited to the integration of PSE (Particle Strength Exchange) or DVM (Diffusion Velocity Method), often used to account for molecular and turbulent diffusion in Lagrangian simulations. The adaptation and implementation of the SEM into a Lagrangian method using the PSE diffusion model is presented, and the turbulent velocity fields produced by this method are then analysed. In this adaptation, SEM turbulent structures are simply advected, without stretching or diffusion of their own, over the flow domain. This implementation proves its ability to produce turbulent velocity fields in accordance with any desired turbulent flow parameters. As the SEM is a purely mathematical and stochastic model, turbulent spectra and turbulent length scales are also investigated. With the addition of variation in the turbulent structures sizes, a satisfying representation of turbulent spectra is recovered, and a linear relation is obtained between the turbulent structures sizes and the Taylor macroscale. Lastly, the model is applied to the computation of a tidal turbine wake for different ambient turbulence levels, demonstrating the ability of this new implementation to emulate experimentally observed tendencies.},
	language = {en},
	urldate = {2021-05-17},
	journal = {Applied Mathematical Modelling},
	author = {Choma Bex, Camille and Carlier, Clément and Fur, Arnaud and Pinon, Grégory and Germain, Grégory and Rivoalen, Élie},
	month = dec,
	year = {2020},
	keywords = {Ambient turbulence, Lagrangian method, Synthetic Eddy Method, Turbulence, Vortex method, Wake},
	pages = {38--54},
}

@article{marti_langevin_1997,
	title = {Langevin approach to generate synthetic turbulent flows},
	volume = {9},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.869201},
	doi = {10.1063/1.869201},
	number = {4},
	urldate = {2021-05-17},
	journal = {Physics of Fluids},
	author = {Martí, A. C. and Sancho, J. M. and Sagués, F. and Careta, A.},
	month = apr,
	year = {1997},
	note = {Publisher: American Institute of Physics},
	pages = {1078--1084},
}

@article{komen_quasi-dns_2014,
	title = {Quasi-{DNS} capabilities of {OpenFOAM} for different mesh types},
	volume = {96},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793014000760},
	doi = {10.1016/j.compfluid.2014.02.013},
	abstract = {Experimental limitations for certain nuclear reactor safety applications have pushed forward the demand for high fidelity DNS reference solutions for complex geometric configurations such as a T-junction or a spherical pebble bed. The application of traditional high-order DNS codes is limited to simple flow domains such as a periodic box or channel. As a possibility to create reference DNS solutions for more complex geometries, we have assessed the (quasi-)DNS capabilities of the OpenFOAM finite volume CFD solver for both structured hexahedral meshes and arbitrary polyhedral meshes. The feasibility of (quasi-)DNS analyses on polyhedral grids is of main interest, since this may offer the possibility to significantly expand the availability of (quasi-)DNS-quality data on arbitrarily complex geometries. In order to have a basis for the considered assessment, the mutual differences between generally recognized reference DNS data bases for turbulent channel and pipe flows are determined first. Subsequently, the differences between these reference DNS solutions and the present OpenFOAM (quasi-)DNS solutions are quantified for the considered mesh types. We use an existing finite volume CFD method and well known turbulent channel and pipe flow DNS reference cases for the assessments in this paper. New in this paper are the application of this CFD method to (quasi-)DNS analyses using arbitrary polyhedral meshes, and the quantification of respectively the mutual differences between generally recognized reference DNS data bases and the differences between the obtained OpenFOAM (quasi-)DNS data and these reference DNS data bases. Based on the presented assessment, it is observed that the differences between the OpenFOAM solutions and the considered reference DNS solutions are practically the same as the mutual differences between these reference DNS solutions when structured hexahedral meshes are used. Furthermore, it is observed that the differences as obtained by OpenFOAM on extruded polyhedral meshes are practically the same as those obtained for the structured hexahedral meshes. In contrast, the full polyhedral mesh shows somewhat larger differences near the peaks in the rms velocity profiles, whereas the differences in the bulk flow are again practically the same as those for the hexahedral grids.},
	language = {en},
	urldate = {2021-05-16},
	journal = {Computers \& Fluids},
	author = {Komen, Ed and Shams, Afaque and Camilo, Leonardo and Koren, Barry},
	month = jun,
	year = {2014},
	keywords = {Channel flows, Complex geometries, DNS, OpenFOAM, Polyhedral cells},
	pages = {87--104},
}

@article{wang_deep_2018,
	title = {Deep {Parametric} {Continuous} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2101.06742},
	doi = {10.1109/CVPR.2018.00274},
	abstract = {Standard convolutional neural networks assume a grid structured input is available and exploit discrete convolutions as their fundamental building blocks. This limits their applicability to many real-world applications. In this paper we propose Parametric Continuous Convolution, a new learnable operator that operates over non-grid structured data. The key idea is to exploit parameterized kernel functions that span the full continuous vector space. This generalization allows us to learn over arbitrary data structures as long as their support relationship is computable. Our experiments show significant improvement over the state-of-the-art in point cloud segmentation of indoor and outdoor scenes, and lidar motion estimation of driving scenes.},
	urldate = {2021-05-11},
	journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	author = {Wang, Shenlong and Suo, Simon and Ma, Wei-Chiu and Pokrovsky, Andrei and Urtasun, Raquel},
	month = jun,
	year = {2018},
	note = {arXiv: 2101.06742},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	pages = {2589--2597},
}

@article{yang_physics-informed_2018,
	title = {Physics-{Informed} {Generative} {Adversarial} {Networks} for {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1811.02033},
	abstract = {We developed a new class of physics-informed generative adversarial networks (PI-GANs) to solve in a unified manner forward, inverse and mixed stochastic problems based on a limited number of scattered measurements. Unlike standard GANs relying only on data for training, here we encoded into the architecture of GANs the governing physical laws in the form of stochastic differential equations (SDEs) using automatic differentiation. In particular, we applied Wasserstein GANs with gradient penalty (WGAN-GP) for its enhanced stability compared to vanilla GANs. We first tested WGAN-GP in approximating Gaussian processes of different correlation lengths based on data realizations collected from simultaneous reads at sparsely placed sensors. We obtained good approximation of the generated stochastic processes to the target ones even for a mismatch between the input noise dimensionality and the effective dimensionality of the target stochastic processes. We also studied the overfitting issue for both the discriminator and generator, and we found that overfitting occurs also in the generator in addition to the discriminator as previously reported. Subsequently, we considered the solution of elliptic SDEs requiring approximations of three stochastic processes, namely the solution, the forcing, and the diffusion coefficient. We used three generators for the PI-GANs, two of them were feed forward deep neural networks (DNNs) while the other one was the neural network induced by the SDE. Depending on the data, we employed one or multiple feed forward DNNs as the discriminators in PI-GANs. Here, we have demonstrated the accuracy and effectiveness of PI-GANs in solving SDEs for up to 30 dimensions, but in principle, PI-GANs could tackle very high dimensional problems given more sensor data with low-polynomial growth in computational cost.},
	urldate = {2021-05-11},
	journal = {arXiv:1811.02033 [cs, math, stat]},
	author = {Yang, Liu and Zhang, Dongkun and Karniadakis, George Em},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.02033},
	keywords = {Computer Science - Machine Learning, Mathematics - Analysis of PDEs, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{subramaniam_turbulence_2020,
	title = {Turbulence {Enrichment} using {Physics}-informed {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/2003.01907},
	abstract = {Generative Adversarial Networks (GANs) have been widely used for generating photo-realistic images. A variant of GANs called super-resolution GAN (SRGAN) has already been used successfully for image super-resolution where low resolution images can be upsampled to a \$4{\textbackslash}times\$ larger image that is perceptually more realistic. However, when such generative models are used for data describing physical processes, there are additional known constraints that models must satisfy including governing equations and boundary conditions. In general, these constraints may not be obeyed by the generated data. In this work, we develop physics-based methods for generative enrichment of turbulence. We incorporate a physics-informed learning approach by a modification to the loss function to minimize the residuals of the governing equations for the generated data. We have analyzed two trained physics-informed models: a supervised model based on convolutional neural networks (CNN) and a generative model based on SRGAN: Turbulence Enrichment GAN (TEGAN), and show that they both outperform simple bicubic interpolation in turbulence enrichment. We have also shown that using the physics-informed learning can also significantly improve the model's ability in generating data that satisfies the physical governing equations. Finally, we compare the enriched data from TEGAN to show that it is able to recover statistical metrics of the flow field including energy metrics and well as inter-scale energy dynamics and flow morphology.},
	urldate = {2021-05-11},
	journal = {arXiv:2003.01907 [physics]},
	author = {Subramaniam, Akshay and Wong, Man Long and Borker, Raunak D. and Nimmagadda, Sravya and Lele, Sanjiva K.},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.01907},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{luo_multi-scale_2017,
	series = {Ninth {International} {Conference} on {Computational} {Fluid} {Dynamics} ({ICCFD9})},
	title = {A multi-scale synthetic eddy method for generating inflow data for {LES}},
	volume = {156},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S004579301730227X},
	doi = {10.1016/j.compfluid.2017.06.017},
	abstract = {A multi-scale synthetic eddy method (MSSEM) for generating inflow turbulence that approaches realistic turbulence characteristics is presented. The proposed method is a modified version of the synthetic eddy method (SEM), which regards turbulence as a superposition of coherent structures. The inflow turbulence generated by the SEM can match the prescribed first and second statistical moments, length scales, and autocorrelation functions, but it cannot match the turbulence spectrum, which is a key characteristic of turbulence. The idea of the MSSEM is to introduce multi-scale eddies with spectrum energies with a focus on different frequency ranges and then synthesize eddies with different scales and energies to match the objective spectrum. The length and proportion of each scale eddy are determined with a predefined turbulence length and turbulence spectra. The advection velocity of a multi-scale eddy is the mean wind value at the location of the eddy and not the constant wind speed. Three large eddy simulations of a turbulent boundary layer with inflow turbulence generated by Lund's method, SEM and MSSEM are considered in this study. The turbulence characteristics at the inlet plane and in the internal flow field are compared and discussed. Result shows that the turbulence structure in the case of the MSSEM resembles turbulence, and the turbulence spectra of three velocity components show good agreement with the predefined values at the inlet plane and in the internal flow field.},
	language = {en},
	urldate = {2021-05-11},
	journal = {Computers \& Fluids},
	author = {Luo, Yin and Liu, Hongjun and Huang, Qin and Xue, Huili and Lin, Kun},
	month = oct,
	year = {2017},
	keywords = {Inflow turbulence, Large eddy simulation, MSSEM, Multi-scale synthetic eddy method, SEM, Synthetic eddy method},
	pages = {103--112},
}

@article{melaku_divergence-free_2021,
	title = {A divergence-free inflow turbulence generator using spectral representation method for large-eddy simulation of {ABL} flows},
	volume = {212},
	issn = {0167-6105},
	url = {https://www.sciencedirect.com/science/article/pii/S0167610521000660},
	doi = {10.1016/j.jweia.2021.104580},
	abstract = {The generation of inflow turbulence is the first necessary step to conduct a successful large-eddy simulation (LES) of atmospheric boundary layer (ABL) flows. It is required that the generated inflow turbulence is divergence-free and satisfies essential target statistical properties, including the two-point statistics of the flow described by the coherency function and the spatial correlation. In this paper, a computationally efficient synthetic inflow turbulence generation technique with explicitly defined two-point flow statistics is proposed based on the spectral representation method. The divergence-free condition is imposed on the generated turbulence through a posteriori procedure embedded in the Pressure-Implicit with Splitting of Operators (PISO) solver of OpenFOAM. The efficacy of the proposed method to represent one-point and two-point statistics is demonstrated by comparing the generated turbulence with wind field measurements taken at the Boundary Layer Wind Tunnel Laboratory of Western University. The proposed method is then applied to LES of ABL flows for three exposure conditions, and the wind profiles downstream of the inlet are examined. The mean velocity, turbulence intensity, integral length scale profiles, and the velocity spectra are in good agreement with the target experimental data, thus, indicating the potential of the method for computational wind engineering applications such as wind load evaluation studies. The implementation of the proposed method is available at https://github.com/GBitsuamlak/DFSR.},
	language = {en},
	urldate = {2021-05-11},
	journal = {Journal of Wind Engineering and Industrial Aerodynamics},
	author = {Melaku, Abiy F. and Bitsuamlak, Girma T.},
	month = may,
	year = {2021},
	keywords = {Atmospheric boundary layer(ABL), Divergence-free, Inflow turbulence generation, Large-eddy simulation(LES), Spectral representation method},
	pages = {104580},
}

@article{klapwijk_use_2021,
	title = {On the use of synthetic inflow turbulence for scale-resolving simulations of wetted and cavitating flows},
	volume = {228},
	issn = {0029-8018},
	url = {https://www.sciencedirect.com/science/article/pii/S002980182100295X},
	doi = {10.1016/j.oceaneng.2021.108860},
	abstract = {The Delft Twist 11 Hydrofoil is a common test case for investigating the interaction between turbulence and cavitation modelling in computational fluid dynamics. Despite repeated investigations, results reported for the lift and drag coefficient are accompanied by significant uncertainties, both in experimental and numerical studies. When using scale-resolving approaches, it is known that turbulent fluctuations must be inserted into the domain in order to prevent the flow from remaining laminar around the body of interest, although this has been overlooked until now for the present test case. This work investigates the errors occurring when a laminar inflow is applied for mildly separated or attached flows, by employing the partially averaged Navier–Stokes equations with varying values for the ratio of modelled-to-total turbulence kinetic energy, and with varying grid densities. It is shown that depending on the grid resolution laminar leading edge separation can occur. When turbulent fluctuations are added to the inflow, the leading edge separation is suppressed completely, and the turbulent separation zone near the trailing edge reduces in size. The inflow turbulence has a large effect on the skin friction, which increases with increasing turbulence intensity to a limit determined by the grid resolution. In cavitating conditions the integral quantities are dominated by the shedding sheet cavity. The turbulence intensity has little effect on the pressure distribution, leading to a largely unaffected sheet cavitation, although the shedding behaviour is affected. It is shown that, especially in wetted flow conditions, with scale-resolving methods inflow turbulence is necessary to match the experimental flow field.},
	language = {en},
	urldate = {2021-05-11},
	journal = {Ocean Engineering},
	author = {Klapwijk, M. and Lloyd, T. and Vaz, G. and van Terwisga, T.},
	month = may,
	year = {2021},
	keywords = {Cavitation, Delft Twist 11 Hydrofoil, PANS, Synthetic inflow turbulence, Validation, Verification},
	pages = {108860},
}

@article{schmidt_source_2017,
	title = {Source term based synthetic turbulence inflow generator for eddy-resolving predictions of an airfoil flow including a laminar separation bubble},
	volume = {146},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793016304066},
	doi = {10.1016/j.compfluid.2016.12.023},
	abstract = {The present paper addresses the issue of the strong dependency of eddy-resolving simulations for turbulent flows on the employed inflow conditions. Thus, the objective of this study is to analyze the influence of the inflow conditions on the external wall-bounded flow past the SD7003 airfoil and more precisely on the form and size of the laminar separation bubble. Motivated by the typically coarse resolution of the inlet region of the computational domain used for hybrid simulations, the synthetic turbulence is introduced within the flow field by a flexible source term treatment. The generated turbulent fluctuations are taken into account in the momentum equation by source terms and hence allow a shift from the inlet to a finer resolved region, where the damping of small structures due to the grid resolution is negligible. To provide a proper formulation of a synthetic turbulence inflow generator (STIG), the digital filter concept of Klein et al. (J. Comp. Phys. 186, 652–665, 2003) is merged with a large-eddy simulation (LES) as well as a hybrid LES-URANS method. The synthetically generated velocity fluctuations are distributed in an area of influence which is in accordance with the digital filter concept of the STIG. An automatic calculation of the dimension of the influence region is ensured by the employment of the integral scales which are used during the generation of the synthetic turbulence inflow generator inflow. The definition of the required input quantities for the STIG in case of the flow past a SD7003 airfoil at Rec=60,000 and an angle of attack α=4∘ are based on experimental data including a turbulence intensity of TI = 0.28\%. Due to separation, transition and subsequent reattachment this is a demanding test case in which the shape and the size of the separation bubble strongly depends on the oncoming turbulence. The reference velocity profiles of the experimental measurements are compared with a wall-resolved LES and hybrid simulations performed on two grids with a coarser resolution. The evaluation of the results of the simulations applying the STIG and without turbulence intensity showed an improved level of agreement between the STIG based simulations and the experiment. Moreover, the turbulence intensity is varied to understand the behavior of the LSB in more detail.},
	language = {en},
	urldate = {2021-05-11},
	journal = {Computers \& Fluids},
	author = {Schmidt, S. and Breuer, M.},
	month = mar,
	year = {2017},
	keywords = {Airfoil, Hybrid method, LES, Laminar separation bubble, Source term, Synthetic turbulence, Transition, URANS},
	pages = {1--22},
}

@article{oh_extended_2019,
	title = {Extended synthetic eddy method to generate inflow data for turbulent thermal boundary layer},
	volume = {134},
	issn = {0017-9310},
	url = {https://www.sciencedirect.com/science/article/pii/S0017931018332289},
	doi = {10.1016/j.ijheatmasstransfer.2019.02.061},
	abstract = {We propose an extended synthetic eddy method (XSEM) based on the synthetic eddy method, which includes the temperature fluctuation component in the turbulent flux tensors, to generate time-dependent turbulent thermal inflow data for a spatially-developing boundary layer. The proposed XSEM is applied to large eddy simulations of a spatially-developing turbulent thermal boundary layer on a flat plate with an isothermal wall condition. Time-varying turbulent thermal inflow fields are reconstructed by composing the prescribed mean and reproduced fluctuations fields, along with Cholesky decomposition to the turbulent flux tensor with thermal flux. The obtained results indicate that the inflow generated by the proposed XSEM provides self-sustaining turbulence with fully recovered turbulent statistics behind a re-developing boundary layer region with the recovery distance roughly seven times of the inlet boundary layer thickness. Finally, we demonstrate the robustness of the XSEM for providing appropriate inflow data for simulations of turbulent thermal boundary layer flows for different Prandtl numbers.},
	language = {en},
	urldate = {2021-05-11},
	journal = {International Journal of Heat and Mass Transfer},
	author = {Oh, Geunwoo and Noh, Kyung Min and Park, Hyunwook and Choi, Jung-Il},
	month = may,
	year = {2019},
	keywords = {Inflow boundary condition, Large-eddy simulation, Synthetic eddy method, Turbulent thermal boundary layer},
	pages = {1261--1267},
}

@article{schmidt_source_2017-1,
	title = {Source term based synthetic turbulence inflow generator for eddy-resolving predictions of an airfoil flow including a laminar separation bubble},
	volume = {146},
	issn = {0045-7930},
	url = {https://www.sciencedirect.com/science/article/pii/S0045793016304066},
	doi = {10.1016/j.compfluid.2016.12.023},
	abstract = {The present paper addresses the issue of the strong dependency of eddy-resolving simulations for turbulent flows on the employed inflow conditions. Thus, the objective of this study is to analyze the influence of the inflow conditions on the external wall-bounded flow past the SD7003 airfoil and more precisely on the form and size of the laminar separation bubble. Motivated by the typically coarse resolution of the inlet region of the computational domain used for hybrid simulations, the synthetic turbulence is introduced within the flow field by a flexible source term treatment. The generated turbulent fluctuations are taken into account in the momentum equation by source terms and hence allow a shift from the inlet to a finer resolved region, where the damping of small structures due to the grid resolution is negligible. To provide a proper formulation of a synthetic turbulence inflow generator (STIG), the digital filter concept of Klein et al. (J. Comp. Phys. 186, 652–665, 2003) is merged with a large-eddy simulation (LES) as well as a hybrid LES-URANS method. The synthetically generated velocity fluctuations are distributed in an area of influence which is in accordance with the digital filter concept of the STIG. An automatic calculation of the dimension of the influence region is ensured by the employment of the integral scales which are used during the generation of the synthetic turbulence inflow generator inflow. The definition of the required input quantities for the STIG in case of the flow past a SD7003 airfoil at Rec=60,000 and an angle of attack α=4∘ are based on experimental data including a turbulence intensity of TI = 0.28\%. Due to separation, transition and subsequent reattachment this is a demanding test case in which the shape and the size of the separation bubble strongly depends on the oncoming turbulence. The reference velocity profiles of the experimental measurements are compared with a wall-resolved LES and hybrid simulations performed on two grids with a coarser resolution. The evaluation of the results of the simulations applying the STIG and without turbulence intensity showed an improved level of agreement between the STIG based simulations and the experiment. Moreover, the turbulence intensity is varied to understand the behavior of the LSB in more detail.},
	language = {en},
	urldate = {2021-05-11},
	journal = {Computers \& Fluids},
	author = {Schmidt, S. and Breuer, M.},
	month = mar,
	year = {2017},
	keywords = {Airfoil, Hybrid method, LES, Laminar separation bubble, Source term, Synthetic turbulence, Transition, URANS},
	pages = {1--22},
}

@article{salvador_analysis_2018,
	title = {Analysis on the effects of turbulent inflow conditions on spray primary atomization in the near-field by direct numerical simulation},
	volume = {102},
	issn = {03019322},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301932217305037},
	doi = {10.1016/j.ijmultiphaseflow.2018.01.019},
	language = {en},
	urldate = {2021-05-11},
	journal = {International Journal of Multiphase Flow},
	author = {Salvador, F.J. and S., Ruiz and Crialesi-Esposito, Marco and Blanquer, Ignacio},
	month = may,
	year = {2018},
	pages = {49--63},
}

@article{parhi_what_2021,
	title = {What {Kinds} of {Functions} do {Deep} {Neural} {Networks} {Learn}? {Insights} from {Variational} {Spline} {Theory}},
	shorttitle = {What {Kinds} of {Functions} do {Deep} {Neural} {Networks} {Learn}?},
	url = {http://arxiv.org/abs/2105.03361},
	abstract = {We develop a variational framework to understand the properties of functions learned by deep neural networks with ReLU activation functions fit to data. We propose a new function space, which is reminiscent of classical bounded variation spaces, that captures the compositional structure associated with deep neural networks. We derive a representer theorem showing that deep ReLU networks are solutions to regularized data fitting problems in this function space. The function space consists of compositions of functions from the (non-reflexive) Banach spaces of second-order bounded variation in the Radon domain. These are Banach spaces with sparsity-promoting norms, giving insight into the role of sparsity in deep neural networks. The neural network solutions have skip connections and rank bounded weight matrices, providing new theoretical support for these common architectural choices. The variational problem we study can be recast as a finite-dimensional neural network training problem with regularization schemes related to the notions of weight decay and path-norm regularization. Finally, our analysis builds on techniques from variational spline theory, providing new connections between deep neural networks and splines.},
	urldate = {2021-05-11},
	journal = {arXiv:2105.03361 [cs, stat]},
	author = {Parhi, Rahul and Nowak, Robert D.},
	month = may,
	year = {2021},
	note = {arXiv: 2105.03361},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{evrard_euler-lagrange_2020,
	title = {Euler-{Lagrange} modelling of dilute particle-laden flows with arbitrary particle-size to mesh-spacing ratio},
	volume = {8},
	issn = {2590-0552},
	url = {https://www.sciencedirect.com/science/article/pii/S2590055220300305},
	doi = {10.1016/j.jcpx.2020.100078},
	abstract = {This paper addresses the two-way coupled Euler-Lagrange modelling of dilute particle-laden flows, with arbitrary particle-size to mesh-spacing ratio. Two-way coupled Euler-Lagrange methods classically require particles to be much smaller than the computational mesh cells for them to be accurately tracked. Particles that do not satisfy this requirement can be considered by introducing a source term regularisation operator that typically consists in convoluting the point-wise particle momentum sources with a smooth kernel. Particles that are larger than the mesh cells, however, generate a significant local flow disturbance, which, in turn, results in poor estimates of the fluid forces acting on them. To circumvent this issue, this paper proposes a new framework to recover the local undisturbed velocity at the location of a given particle, that is the local flow velocity from which the disturbance due to the presence of the particle is subtracted. It relies upon the solution of the Stokes flow through a regularised momentum source and is extended to finite Reynolds numbers based on the Oseen flow solution. Owing to the polynomial nature of the regularisation kernel considered in this paper, a correction for the averaged local flow disturbance can be analytically derived, allowing to filter out scales of the flow motion that are smaller than the particle, which should not be taken into account to compute the interaction/drag forces acting on the particle. The proposed correction scheme is applied to the simulation of a particle settling under the influence of gravity, for varying particle-size to mesh-spacing ratios and varying Reynolds numbers. The method is shown to nearly eliminate any impact of the underlying mesh resolution on the modelling of a particle's trajectory. Finally, optimal values for the scale of the regularisation kernel are provided and their impact on the flow is discussed.},
	language = {en},
	urldate = {2021-05-11},
	journal = {Journal of Computational Physics: X},
	author = {Evrard, Fabien and Denner, Fabian and van Wachem, Berend},
	month = sep,
	year = {2020},
	keywords = {Dilute particle-laden flow, Euler-Lagrange, Source term regularisation, Velocity correction},
	pages = {100078},
}

@article{pamies_generation_2009,
	title = {Generation of synthetic turbulent inflow data for large eddy simulation of spatially evolving wall-bounded flows},
	volume = {21},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/full/10.1063/1.3103881},
	doi = {10.1063/1.3103881},
	abstract = {A method for generating inflow conditions for large eddy simulations (LESs) of spatially developing turbulent boundary layers is presented. It is an adaptation of the synthetic eddy method (SEM) of Jarrin et al. [Int. J. Heat Fluid Flow 27, 585 (2006)], which uses the Cholesky decomposition of the Reynolds stress tensor to enforce second-order moments starting from a normalized stochastic velocity signal, the latter being constructed with a superimposition of turbulent structures with prescribed geometrical shape and random signs and position. The present method modifies the definition of the stochastic signal so that it can be split into several modes, with different time, length and velocity scales and also with different vorticity contents. The idea is to reproduce more realistically the distribution of scales in the wall-normal direction of a turbulent boundary layer flow. The novelty of the proposed modified SEM is that physical information concerning the coherent vortical structures of such flows are extracted from the literature and used in the definition of the modes. It is shown that the specification of realistic modes for the buffer and the logarithmic layers significantly helps to reduce the spatial transient undergone by the synthetic inflow data. The new method is assessed in the framework of LES and compared to the original SEM and to a reference simulation which uses the recycling procedure of Lund et al. [J. Comput. Phys. 140, 233 (1998)]. First- and second-order statistical results, as well as instantaneous behavior of turbulence, are shown to be in excellent agreement with the reference after an adaptation distance of five to six initial boundary layer thicknesses.},
	number = {4},
	urldate = {2021-05-07},
	journal = {Physics of Fluids},
	author = {Pamiès, Mathieu and Weiss, Pierre-Élie and Garnier, Eric and Deck, Sébastien and Sagaut, Pierre},
	month = apr,
	year = {2009},
	note = {Publisher: American Institute of Physics},
	pages = {045103},
}

@article{bronstein_geometric_2021,
	title = {Geometric {Deep} {Learning}: {Grids}, {Groups}, {Graphs}, {Geodesics}, and {Gauges}},
	shorttitle = {Geometric {Deep} {Learning}},
	url = {http://arxiv.org/abs/2104.13478},
	abstract = {The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.},
	urldate = {2021-04-30},
	journal = {arXiv:2104.13478 [cs, stat]},
	author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.13478},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computational Geometry, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{guemes_coarse_2021,
	title = {From coarse wall measurements to turbulent velocity fields with deep learning},
	url = {http://arxiv.org/abs/2103.07387},
	abstract = {This work evaluates the applicability of super-resolution generative adversarial networks (SRGANs) as an intermediate step for the reconstruction of wall-parallel velocity fields from coarse wall measurements. The analysis has been carried out with a database of a turbulent open-channel flow with friction Reynolds number \$Re\_\{{\textbackslash}tau\}=180\$ generated through direct numerical simulation. Coarse wall measurements have been generated with three different downsampling factors \$f\_d=[4,8,16]\$ from the high-resolution fields, and wall-parallel velocity fields have been reconstructed at four inner-scaled wall-normal distances \$y{\textasciicircum}+=[15,30,50,100]\$. Even though lower resolutions make it more challenging to achieve high accuracy predictions, the suggested SRGAN-based network helps us to achieve acceptable results. The proposed novel DNN-based methodology to reconstruct flow fields from coarse wall measurements in turbulent flows has great potential for opposition-control applications relying on non-intrusive sensing.},
	urldate = {2021-04-28},
	journal = {arXiv:2103.07387 [physics]},
	author = {Güemes, Alejandro and Tober, Hampus and Discetti, Stefano and Ianiro, Andrea and Sirmacek, Beril and Azizpour, Hossein and Vinuesa, Ricardo},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.07387},
	keywords = {Physics - Fluid Dynamics},
}

@article{bhouri_gaussian_2021,
	title = {Gaussian processes meet {NeuralODEs}: {A} {Bayesian} framework for learning the dynamics of partially observed systems from scarce and noisy data},
	shorttitle = {Gaussian processes meet {NeuralODEs}},
	url = {http://arxiv.org/abs/2103.03385},
	abstract = {This paper presents a machine learning framework (GP-NODE) for Bayesian systems identification from partial, noisy and irregular observations of nonlinear dynamical systems. The proposed method takes advantage of recent developments in differentiable programming to propagate gradient information through ordinary differential equation solvers and perform Bayesian inference with respect to unknown model parameters using Hamiltonian Monte Carlo sampling and Gaussian Process priors over the observed system states. This allows us to exploit temporal correlations in the observed data, and efficiently infer posterior distributions over plausible models with quantified uncertainty. Moreover, the use of sparsity-promoting priors such as the Finnish Horseshoe for free model parameters enables the discovery of interpretable and parsimonious representations for the underlying latent dynamics. A series of numerical studies is presented to demonstrate the effectiveness of the proposed GP-NODE method including predator-prey systems, systems biology, and a 50-dimensional human motion dynamical system. Taken together, our findings put forth a novel, flexible and robust workflow for data-driven model discovery under uncertainty. All code and data accompanying this manuscript are available online at {\textbackslash}url\{https://github.com/PredictiveIntelligenceLab/GP-NODEs\}.},
	urldate = {2021-04-23},
	journal = {arXiv:2103.03385 [physics, stat]},
	author = {Bhouri, Mohamed Aziz and Perdikaris, Paris},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.03385},
	keywords = {Computer Science - Machine Learning, Physics - Data Analysis, Statistics and Probability, Statistics - Machine Learning},
}

@article{wang_learning_2021,
	title = {Learning the solution operator of parametric partial differential equations with physics-informed {DeepOnets}},
	url = {http://arxiv.org/abs/2103.10974},
	abstract = {Deep operator networks (DeepONets) are receiving increased attention thanks to their demonstrated capability to approximate nonlinear operators between infinite-dimensional Banach spaces. However, despite their remarkable early promise, they typically require large training data-sets consisting of paired input-output observations which may be expensive to obtain, while their predictions may not be consistent with the underlying physical principles that generated the observed data. In this work, we propose a novel model class coined as physics-informed DeepONets, which introduces an effective regularization mechanism for biasing the outputs of DeepOnet models towards ensuring physical consistency. This is accomplished by leveraging automatic differentiation to impose the underlying physical laws via soft penalty constraints during model training. We demonstrate that this simple, yet remarkably effective extension can not only yield a significant improvement in the predictive accuracy of DeepOnets, but also greatly reduce the need for large training data-sets. To this end, a remarkable observation is that physics-informed DeepONets are capable of solving parametric partial differential equations (PDEs) without any paired input-output observations, except for a set of given initial or boundary conditions. We illustrate the effectiveness of the proposed framework through a series of comprehensive numerical studies across various types of PDEs. Strikingly, a trained physics informed DeepOnet model can predict the solution of \${\textbackslash}mathcal\{O\}(10{\textasciicircum}3)\$ time-dependent PDEs in a fraction of a second -- up to three orders of magnitude faster compared a conventional PDE solver. The data and code accompanying this manuscript are publicly available at {\textbackslash}url\{https://github.com/PredictiveIntelligenceLab/Physics-informed-DeepONets\}.},
	urldate = {2021-04-23},
	journal = {arXiv:2103.10974 [cs, math, stat]},
	author = {Wang, Sifan and Wang, Hanwen and Perdikaris, Paris},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.10974},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{wang_eigenvector_2020,
	title = {On the eigenvector bias of {Fourier} feature networks: {From} regression to solving multi-scale {PDEs} with physics-informed neural networks},
	shorttitle = {On the eigenvector bias of {Fourier} feature networks},
	url = {http://arxiv.org/abs/2012.10047},
	abstract = {Physics-informed neural networks (PINNs) are demonstrating remarkable promise in integrating physical models with gappy and noisy observational data, but they still struggle in cases where the target functions to be approximated exhibit high-frequency or multi-scale features. In this work we investigate this limitation through the lens of Neural Tangent Kernel (NTK) theory and elucidate how PINNs are biased towards learning functions along the dominant eigen-directions of their limiting NTK. Using this observation, we construct novel architectures that employ spatio-temporal and multi-scale random Fourier features, and justify how such coordinate embedding layers can lead to robust and accurate PINN models. Numerical examples are presented for several challenging cases where conventional PINN models fail, including wave propagation and reaction-diffusion dynamics, illustrating how the proposed methods can be used to effectively tackle both forward and inverse problems involving partial differential equations with multi-scale behavior. All code an data accompanying this manuscript will be made publicly available at {\textbackslash}url\{https://github.com/PredictiveIntelligenceLab/MultiscalePINNs\}.},
	urldate = {2021-04-23},
	journal = {arXiv:2012.10047 [cs, stat]},
	author = {Wang, Sifan and Wang, Hanwen and Perdikaris, Paris},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.10047},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ahmed_atomization_2020,
	title = {{ATOMIZATION} {MODELING} {USING} {SURFACE} {DENSITY} {AND} {STOCHASTIC} {FIELDS}},
	volume = {30},
	issn = {1044-5110},
	url = {http://www.dl.begellhouse.com/journals/6a7c7e10642258cc,0e8613c6110fcfa4,4c6b704d61d852f7.html},
	doi = {10.1615/AtomizSpr.2020032620},
	abstract = {Correct prediction of the spray in automotive and aerospace engines remains a challenging task. In this work we present a numerical framework to characterize the spray, using both the large scale quantities, like mean liquid volume fractions, as well as small scale structures or liquid droplets. In the limit of high Reynolds and Weber number, the drop size is expected to be much smaller than can be resolved using ﬁrst principles on a given mesh, thus a subgrid formulation is used to characterize the drop size. Using liquid gas interface surface density we have compared a standard formulation as well as a probability density function–based formulation. Using large eddy simulation we compared against the experimental database hosted by the engine combustion network for a single hole injector. Sauter mean diameter is predicted well using our formulation; at the same time use of the probability density function brings additional information regarding drop size distribution.},
	language = {en},
	number = {4},
	urldate = {2021-04-23},
	journal = {Atomization and Sprays},
	author = {Ahmed, Aqeel and Tretola, G. and Navarro-Martinez, Salvador and Vogiatzaki, K. and Duret, B. and Reveillon, Julien and Demoulin, Francois-Xavier},
	year = {2020},
	pages = {239--266},
}

@article{kashinath_physics-informed_nodate,
	title = {Physics-informed machine learning: case studies for weather and climate modelling},
	language = {en},
	author = {Kashinath, K and Mustafa, M and Albert, A and Wu, J-L and Jiang, C and Esmaeilzadeh, S and Azizzadenesheli, K and Wang, R and Chattopadhyay, A and Singh, A and Manepalli, A and Chirila, D and Yu, R and Walters, R and White, B and Xiao, H and Tchelepi, H A and Marcus, P and Anandkumar, A and Hassanzadeh, P},
	pages = {36},
}

@article{wang_incorporating_2021,
	title = {Incorporating {Symmetry} into {Deep} {Dynamics} {Models} for {Improved} {Generalization}},
	url = {http://arxiv.org/abs/2002.03061},
	abstract = {Recent work has shown deep learning can accelerate the prediction of physical dynamics relative to numerical solvers. However, limited physical accuracy and an inability to generalize under distributional shift limit its applicability to the real world. We propose to improve accuracy and generalization by incorporating symmetries into convolutional neural networks. Specifically, we employ a variety of methods each tailored to enforce a different symmetry. Our models are both theoretically and experimentally robust to distributional shift by symmetry group transformations and enjoy favorable sample complexity. We demonstrate the advantage of our approach on a variety of physical dynamics including Rayleigh B{\textbackslash}'enard convection and real-world ocean currents and temperatures. Compared with image or text applications, our work is a significant step towards applying equivariant neural networks to high-dimensional systems with complex dynamics. We open-source our simulation, data, and code at {\textbackslash}url\{https://github.com/Rose-STL-Lab/Equivariant-Net\}.},
	urldate = {2021-04-19},
	journal = {arXiv:2002.03061 [cs, math, stat]},
	author = {Wang, Rui and Walters, Robin and Yu, Rose},
	month = mar,
	year = {2021},
	note = {arXiv: 2002.03061},
	keywords = {Computer Science - Machine Learning, Mathematics - Representation Theory, Statistics - Machine Learning},
}

@article{fox_large-eddy-simulation_2011,
	title = {Large-{Eddy}-{Simulation} {Tools} for {Multiphase} {Flows}},
	abstract = {Multiphase ﬂows occurring in nature and in technological applications are often turbulent. The large range of length scales and timescales in turbulent multiphase ﬂows makes direct numerical simulation of the microscale governing equations intractable for many applications. In this article we review a systematic approach for developing large-eddy-simulation (LES) tools for dispersed multiphase ﬂows starting from the microscale model. A key intermediate step is the mesoscopic model for the dispersed phase, formulated in terms of kinetic equations, that contains the physical models for the ﬂow. Owing to the phase-space variables, direct solution of the mesoscopic model is usually intractable, and additional mathematical approximations are introduced to arrive at a macroscopic model. We show that self-conditioned LES models can be derived for both the mesoscopic and macroscopic models, but the former is preferred to ensure consistency and physical accuracy. The principal difﬁculties and open challenges in closing the LES model equations are highlighted.},
	language = {en},
	author = {Fox, Rodney O},
	year = {2011},
	pages = {32},
}

@article{parish_time-series_2020,
	title = {Time-series machine-learning error models for approximate solutions to parameterized dynamical systems},
	volume = {365},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782520301742},
	doi = {10.1016/j.cma.2020.112990},
	abstract = {This work proposes a machine-learning framework for modeling the error incurred by approximate solutions to parameterized dynamical systems. In particular, we extend the machine-learning error models (MLEM) framework proposed in Ref. Freno and Carlberg (2019) to dynamical systems. The proposed Time-Series Machine-Learning Error Modeling (T-MLEM) method constructs a regression model that maps features – which comprise error indicators that are derived from standard a posteriori error-quantification techniques – to a random variable for the approximate-solution error at each time instance. The proposed framework considers a wide range of candidate features, regression methods, and additive noise models. We consider primarily recursive regression techniques developed for time-series modeling, including both classical time-series models (e.g., autoregressive models) and recurrent neural networks (RNNs), but also analyze standard non-recursive regression techniques (e.g., feed-forward neural networks) for comparative purposes. Numerical experiments conducted on multiple benchmark problems illustrate that the long short-term memory (LSTM) neural network, which is a type of RNN, outperforms other methods and yields substantial improvements in error predictions over traditional approaches.},
	language = {en},
	urldate = {2021-04-13},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Parish, Eric J. and Carlberg, Kevin T.},
	month = jun,
	year = {2020},
	keywords = {Error modeling, Long short-term memory networks, Model reduction, Parameterized dynamical systems, Recurrent neural networks, Time-series modeling},
	pages = {112990},
}

@article{lee_model_2020,
	title = {Model reduction of dynamical systems on nonlinear manifolds using deep convolutional autoencoders},
	volume = {404},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999119306783},
	doi = {10.1016/j.jcp.2019.108973},
	abstract = {Nearly all model-reduction techniques project the governing equations onto a linear subspace of the original state space. Such subspaces are typically computed using methods such as balanced truncation, rational interpolation, the reduced-basis method, and (balanced) proper orthogonal decomposition (POD). Unfortunately, restricting the state to evolve in a linear subspace imposes a fundamental limitation to the accuracy of the resulting reduced-order model (ROM). In particular, linear-subspace ROMs can be expected to produce low-dimensional models with high accuracy only if the problem admits a fast decaying Kolmogorov n-width (e.g., diffusion-dominated problems). Unfortunately, many problems of interest exhibit a slowly decaying Kolmogorov n-width (e.g., advection-dominated problems). To address this, we propose a novel framework for projecting dynamical systems onto nonlinear manifolds using minimum-residual formulations at the time-continuous and time-discrete levels; the former leads to manifold Galerkin projection, while the latter leads to manifold least-squares Petrov–Galerkin (LSPG) projection. We perform analyses that provide insight into the relationship between these proposed approaches and classical linear-subspace reduced-order models; we also derive a posteriori discrete-time error bounds for the proposed approaches. In addition, we propose a computationally practical approach for computing the nonlinear manifold, which is based on convolutional autoencoders from deep learning. Finally, we demonstrate the ability of the method to significantly outperform even the optimal linear-subspace ROM on benchmark advection-dominated problems, thereby demonstrating the method's ability to overcome the intrinsic n-width limitations of linear subspaces.},
	language = {en},
	urldate = {2021-04-13},
	journal = {Journal of Computational Physics},
	author = {Lee, Kookjin and Carlberg, Kevin T.},
	month = mar,
	year = {2020},
	keywords = {Autoencoders, Deep learning, Machine learning, Model reduction, Nonlinear manifolds, Optimal projection},
	pages = {108973},
}

@article{lee_model_2020-1,
	title = {Model reduction of dynamical systems on nonlinear manifolds using deep convolutional autoencoders},
	volume = {404},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999119306783},
	doi = {10.1016/j.jcp.2019.108973},
	abstract = {Nearly all model-reduction techniques project the governing equations onto a linear subspace of the original state space. Such subspaces are typically computed using methods such as balanced truncation, rational interpolation, the reduced-basis method, and (balanced) proper orthogonal decomposition (POD). Unfortunately, restricting the state to evolve in a linear subspace imposes a fundamental limitation to the accuracy of the resulting reduced-order model (ROM). In particular, linear-subspace ROMs can be expected to produce low-dimensional models with high accuracy only if the problem admits a fast decaying Kolmogorov n-width (e.g., diffusion-dominated problems). Unfortunately, many problems of interest exhibit a slowly decaying Kolmogorov n-width (e.g., advection-dominated problems). To address this, we propose a novel framework for projecting dynamical systems onto nonlinear manifolds using minimum-residual formulations at the time-continuous and time-discrete levels; the former leads to manifold Galerkin projection, while the latter leads to manifold least-squares Petrov–Galerkin (LSPG) projection. We perform analyses that provide insight into the relationship between these proposed approaches and classical linear-subspace reduced-order models; we also derive a posteriori discrete-time error bounds for the proposed approaches. In addition, we propose a computationally practical approach for computing the nonlinear manifold, which is based on convolutional autoencoders from deep learning. Finally, we demonstrate the ability of the method to significantly outperform even the optimal linear-subspace ROM on benchmark advection-dominated problems, thereby demonstrating the method's ability to overcome the intrinsic n-width limitations of linear subspaces.},
	language = {en},
	urldate = {2021-04-13},
	journal = {Journal of Computational Physics},
	author = {Lee, Kookjin and Carlberg, Kevin T.},
	month = mar,
	year = {2020},
	keywords = {Autoencoders, Deep learning, Machine learning, Model reduction, Nonlinear manifolds, Optimal projection},
	pages = {108973},
}

@article{papamakarios_normalizing_2021,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	volume = {22},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v22/19-1028.html},
	number = {57},
	urldate = {2021-04-09},
	journal = {Journal of Machine Learning Research},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	year = {2021},
	pages = {1--64},
}

@article{willcox_imperative_2021,
	title = {The imperative of physics-based modeling and inverse theory in computational science},
	volume = {1},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {2662-8457},
	url = {https://www.nature.com/articles/s43588-021-00040-z},
	doi = {10.1038/s43588-021-00040-z},
	abstract = {To best learn from data about large-scale complex systems, physics-based models representing the laws of nature must be integrated into the learning process. Inverse theory provides a crucial perspective for addressing the challenges of ill-posedness, uncertainty, nonlinearity and under-sampling.},
	language = {en},
	number = {3},
	urldate = {2021-04-09},
	journal = {Nature Computational Science},
	author = {Willcox, Karen E. and Ghattas, Omar and Heimbach, Patrick},
	month = mar,
	year = {2021},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {166--168},
}

@article{higgins_generalizing_2021,
	title = {Generalizing universal function approximators},
	volume = {3},
	issn = {2522-5839},
	url = {http://www.nature.com/articles/s42256-021-00318-x},
	doi = {10.1038/s42256-021-00318-x},
	language = {en},
	number = {3},
	urldate = {2021-04-09},
	journal = {Nature Machine Intelligence},
	author = {Higgins, Irina},
	month = mar,
	year = {2021},
	pages = {192--193},
}

@article{lu_learning_2021,
	title = {Learning nonlinear operators via {DeepONet} based on the universal approximation theorem of operators},
	volume = {3},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-021-00302-5},
	doi = {10.1038/s42256-021-00302-5},
	abstract = {It is widely known that neural networks (NNs) are universal approximators of continuous functions. However, a less known but powerful result is that a NN with a single hidden layer can accurately approximate any nonlinear continuous operator. This universal approximation theorem of operators is suggestive of the structure and potential of deep neural networks (DNNs) in learning continuous operators or complex systems from streams of scattered data. Here, we thus extend this theorem to DNNs. We design a new network with small generalization error, the deep operator network (DeepONet), which consists of a DNN for encoding the discrete input function space (branch net) and another DNN for encoding the domain of the output functions (trunk net). We demonstrate that DeepONet can learn various explicit operators, such as integrals and fractional Laplacians, as well as implicit operators that represent deterministic and stochastic differential equations. We study different formulations of the input function space and its effect on the generalization error for 16 different diverse applications.},
	language = {en},
	number = {3},
	urldate = {2021-04-09},
	journal = {Nature Machine Intelligence},
	author = {Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
	month = mar,
	year = {2021},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {218--229},
}

@article{van_de_meent_introduction_2018,
	title = {An {Introduction} to {Probabilistic} {Programming}},
	url = {http://arxiv.org/abs/1809.10756},
	abstract = {This document is designed to be a first-year graduate-level introduction to probabilistic programming. It not only provides a thorough background for anyone wishing to use a probabilistic programming system, but also introduces the techniques needed to design and build these systems. It is aimed at people who have an undergraduate-level understanding of either or, ideally, both probabilistic machine learning and programming languages. We start with a discussion of model-based reasoning and explain why conditioning as a foundational computation is central to the fields of probabilistic machine learning and artificial intelligence. We then introduce a simple first-order probabilistic programming language (PPL) whose programs define static-computation-graph, finite-variable-cardinality models. In the context of this restricted PPL we introduce fundamental inference algorithms and describe how they can be implemented in the context of models denoted by probabilistic programs. In the second part of this document, we introduce a higher-order probabilistic programming language, with a functionality analogous to that of established programming languages. This affords the opportunity to define models with dynamic computation graphs, at the cost of requiring inference methods that generate samples by repeatedly executing the program. Foundational inference algorithms for this kind of probabilistic programming language are explained in the context of an interface between program executions and an inference controller. This document closes with a chapter on advanced topics which we believe to be, at the time of writing, interesting directions for probabilistic programming research; directions that point towards a tight integration with deep neural network research and the development of systems for next-generation artificial intelligence applications.},
	urldate = {2021-04-07},
	journal = {arXiv:1809.10756 [cs, stat]},
	author = {van de Meent, Jan-Willem and Paige, Brooks and Yang, Hongseok and Wood, Frank},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.10756},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Programming Languages, Statistics - Machine Learning},
}

@article{zhang_physics-informed_2020,
	title = {Physics-{Informed} {Multi}-{LSTM} {Networks} for {Metamodeling} of {Nonlinear} {Structures}},
	volume = {369},
	issn = {00457825},
	url = {http://arxiv.org/abs/2002.10253},
	doi = {10.1016/j.cma.2020.113226},
	abstract = {This paper introduces an innovative physics-informed deep learning framework for metamodeling of nonlinear structural systems with scarce data. The basic concept is to incorporate physics knowledge (e.g., laws of physics, scientific principles) into deep long short-term memory (LSTM) networks, which boosts the learning within a feasible solution space. The physics constraints are embedded in the loss function to enforce the model training which can accurately capture latent system nonlinearity even with very limited available training datasets. Specifically for dynamic structures, physical laws of equation of motion, state dependency and hysteretic constitutive relationship are considered to construct the physics loss. In particular, two physics-informed multi-LSTM network architectures are proposed for structural metamodeling. The satisfactory performance of the proposed framework is successfully demonstrated through two illustrative examples (e.g., nonlinear structures subjected to ground motion excitation). It turns out that the embedded physics can alleviate overfitting issues, reduce the need of big training datasets, and improve the robustness of the trained model for more reliable prediction. As a result, the physics-informed deep learning paradigm outperforms classical non-physics-guided data-driven neural networks.},
	urldate = {2021-04-01},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Zhang, Ruiyang and Liu, Yang and Sun, Hao},
	month = sep,
	year = {2020},
	note = {arXiv: 2002.10253},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Electrical Engineering and Systems Science - Signal Processing},
	pages = {113226},
}

@article{vahdat_nvae_2020,
	title = {{NVAE}: {A} {Deep} {Hierarchical} {Variational} {Autoencoder}},
	shorttitle = {{NVAE}},
	url = {http://arxiv.org/abs/2007.03898},
	abstract = {Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256\${\textbackslash}times\$256 pixels. The source code is available at https://github.com/NVlabs/NVAE .},
	urldate = {2021-04-01},
	journal = {arXiv:2007.03898 [cs, stat]},
	author = {Vahdat, Arash and Kautz, Jan},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.03898
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{subramaniam_lagrangianeulerian_2013,
	title = {Lagrangian–{Eulerian} methods for multiphase flows},
	volume = {39},
	issn = {0360-1285},
	url = {https://www.sciencedirect.com/science/article/pii/S0360128512000603},
	doi = {10.1016/j.pecs.2012.10.003},
	abstract = {This review article aims to provide a comprehensive and understandable account of the theoretical foundation, modeling issues, and numerical implementation of the Lagrangian–Eulerian (LE) approach for multiphase flows. The LE approach is based on a statistical description of the dispersed phase in terms of a stochastic point process that is coupled with a Eulerian statistical representation of the carrier fluid phase. A modeled transport equation for the particle distribution function — also known as Williams' spray equation in the case of sprays — is indirectly solved using a Lagrangian particle method. Interphase transfer of mass, momentum and energy are represented by coupling terms that appear in the Eulerian conservation equations for the fluid phase. This theoretical foundation is then used to develop LE sub-models for interphase interactions such as momentum transfer. Every LE model implies a corresponding closure in the Eulerian–Eulerian two-fluid theory, and these moment equations are derived. Approaches to incorporate multiscale interactions between particles (or spray droplets) and turbulent eddies in the carrier gas that result in better predictions of particle (or droplet) dispersion are described. Numerical convergence of LE implementations is shown to be crucial to the success of the LE modeling approach. It is shown how numerical convergence and accuracy of an LE implementation can be established using grid-free estimators and computational particle number density control algorithms. This review of recent advances establishes that LE methods can be used to solve multiphase flow problems of practical interest, provided sub-models are implemented using numerically convergent algorithms. These insights also provide the foundation for further development of Lagrangian methods for multiphase flows. Extensions to the LE method that can account for neighbor particle interactions and preferential concentration of particles in turbulence are outlined.},
	language = {en},
	number = {2},
	urldate = {2021-04-01},
	journal = {Progress in Energy and Combustion Science},
	author = {Subramaniam, Shankar},
	month = apr,
	year = {2013},
	keywords = {Droplet, Gas–solid flow, Lagrangian–Eulerian, Multiphase flow theory, Numerical convergence, Particle-laden flow, Spray, Spray modeling, Spray theory, Two-phase flow},
	pages = {215--245},
}

@article{willcox_imperative_2021-1,
	title = {The imperative of physics-based modeling and inverse theory in computational science},
	volume = {1},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {2662-8457},
	url = {https://www.nature.com/articles/s43588-021-00040-z},
	doi = {10.1038/s43588-021-00040-z},
	abstract = {To best learn from data about large-scale complex systems, physics-based models representing the laws of nature must be integrated into the learning process. Inverse theory provides a crucial perspective for addressing the challenges of ill-posedness, uncertainty, nonlinearity and under-sampling.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {Nature Computational Science},
	author = {Willcox, Karen E. and Ghattas, Omar and Heimbach, Patrick},
	month = mar,
	year = {2021},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {166--168},
}

@book{tarantola_inverse_2005,
	title = {Inverse {Problem} {Theory} and {Methods} for {Model} {Parameter} {Estimation}},
	isbn = {978-0-89871-572-9 978-0-89871-792-1},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9780898717921},
	language = {en},
	urldate = {2021-03-30},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Tarantola, Albert},
	month = jan,
	year = {2005},
	doi = {10.1137/1.9780898717921},
}

@book{kaipio_statistical_2005,
	address = {New York},
	series = {Applied mathematical sciences},
	title = {Statistical and computational inverse problems},
	isbn = {978-0-387-22073-4},
	language = {en},
	number = {v. 160},
	publisher = {Springer},
	author = {Kaipio, Jari and Somersalo, Erkki},
	year = {2005},
	keywords = {Inverse problems (Differential equations), Numerical solutions},
}

@book{kaipio_statistical_2005-1,
	address = {New York},
	series = {Applied mathematical sciences},
	title = {Statistical and computational inverse problems},
	isbn = {978-0-387-22073-4},
	language = {en},
	number = {v. 160},
	publisher = {Springer},
	author = {Kaipio, Jari and Somersalo, Erkki},
	year = {2005},
	keywords = {Inverse problems (Differential equations), Numerical solutions},
}

@article{willcox_imperative_2021-2,
	title = {The imperative of physics-based modeling and inverse theory in computational science},
	volume = {1},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {2662-8457},
	url = {https://www.nature.com/articles/s43588-021-00040-z},
	doi = {10.1038/s43588-021-00040-z},
	abstract = {To best learn from data about large-scale complex systems, physics-based models representing the laws of nature must be integrated into the learning process. Inverse theory provides a crucial perspective for addressing the challenges of ill-posedness, uncertainty, nonlinearity and under-sampling.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {Nature Computational Science},
	author = {Willcox, Karen E. and Ghattas, Omar and Heimbach, Patrick},
	month = mar,
	year = {2021},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {166--168},
}

@article{gemici_normalizing_2016,
	title = {Normalizing {Flows} on {Riemannian} {Manifolds}},
	url = {http://arxiv.org/abs/1611.02304},
	abstract = {We consider the problem of density estimation on Riemannian manifolds. Density estimation on manifolds has many applications in fluid-mechanics, optics and plasma physics and it appears often when dealing with angular variables (such as used in protein folding, robot limbs, gene-expression) and in general directional statistics. In spite of the multitude of algorithms available for density estimation in the Euclidean spaces \${\textbackslash}mathbf\{R\}{\textasciicircum}n\$ that scale to large n (e.g. normalizing flows, kernel methods and variational approximations), most of these methods are not immediately suitable for density estimation in more general Riemannian manifolds. We revisit techniques related to homeomorphisms from differential geometry for projecting densities to sub-manifolds and use it to generalize the idea of normalizing flows to more general Riemannian manifolds. The resulting algorithm is scalable, simple to implement and suitable for use with automatic differentiation. We demonstrate concrete examples of this method on the n-sphere \${\textbackslash}mathbf\{S\}{\textasciicircum}n\$.},
	urldate = {2021-03-29},
	journal = {arXiv:1611.02304 [cs, math, stat]},
	author = {Gemici, Mevlana C. and Rezende, Danilo and Mohamed, Shakir},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.02304},
	keywords = {Computer Science - Artificial Intelligence, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@article{rezende_normalizing_2020,
	title = {Normalizing {Flows} on {Tori} and {Spheres}},
	url = {http://arxiv.org/abs/2002.02428},
	abstract = {Normalizing flows are a powerful tool for building expressive distributions in high dimensions. So far, most of the literature has concentrated on learning flows on Euclidean spaces. Some problems however, such as those involving angles, are defined on spaces with more complex geometries, such as tori or spheres. In this paper, we propose and compare expressive and numerically stable flows on such spaces. Our flows are built recursively on the dimension of the space, starting from flows on circles, closed intervals or spheres.},
	urldate = {2021-03-29},
	journal = {arXiv:2002.02428 [cs, stat]},
	author = {Rezende, Danilo Jimenez and Papamakarios, George and Racanière, Sébastien and Albergo, Michael S. and Kanwar, Gurtej and Shanahan, Phiala E. and Cranmer, Kyle},
	month = jul,
	year = {2020},
	note = {arXiv: 2002.02428},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{peyre_computational_2020,
	title = {Computational {Optimal} {Transport}},
	url = {http://arxiv.org/abs/1803.00567},
	abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.},
	urldate = {2021-03-29},
	journal = {arXiv:1803.00567 [stat]},
	author = {Peyré, Gabriel and Cuturi, Marco},
	month = mar,
	year = {2020},
	note = {arXiv: 1803.00567},
	keywords = {Statistics - Machine Learning},
}

@article{papamakarios_normalizing_2019,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	url = {http://arxiv.org/abs/1912.02762},
	abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
	urldate = {2021-03-24},
	journal = {arXiv:1912.02762 [cs, stat]},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.02762},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{chen_neural_2019,
	title = {Neural {Ordinary} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1806.07366},
	abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
	urldate = {2021-03-24},
	journal = {arXiv:1806.07366 [cs, stat]},
	author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
	month = dec,
	year = {2019},
	note = {arXiv: 1806.07366},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kobyzev_normalizing_2020,
	title = {Normalizing {Flows}: {An} {Introduction} and {Review} of {Current} {Methods}},
	shorttitle = {Normalizing {Flows}},
	url = {http://arxiv.org/abs/1908.09257},
	doi = {10.1109/TPAMI.2020.2992934},
	abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
	urldate = {2021-03-24},
	journal = {arXiv:1908.09257 [cs, stat]},
	author = {Kobyzev, Ivan and Prince, Simon J. D. and Brubaker, Marcus A.},
	month = jun,
	year = {2020},
	note = {arXiv: 1908.09257},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{liu_hierarchical_2020,
	title = {Hierarchical {Deep} {Learning} of {Multiscale} {Differential} {Equation} {Time}-{Steppers}},
	url = {http://arxiv.org/abs/2008.09768},
	abstract = {Nonlinear differential equations rarely admit closed-form solutions, thus requiring numerical time-stepping algorithms to approximate solutions. Further, many systems characterized by multiscale physics exhibit dynamics over a vast range of timescales, making numerical integration computationally expensive due to numerical stiffness. In this work, we develop a hierarchy of deep neural network time-steppers to approximate the flow map of the dynamical system over a disparate range of time-scales. The resulting model is purely data-driven and leverages features of the multiscale dynamics, enabling numerical integration and forecasting that is both accurate and highly efficient. Moreover, similar ideas can be used to couple neural network-based models with classical numerical time-steppers. Our multiscale hierarchical time-stepping scheme provides important advantages over current time-stepping algorithms, including (i) circumventing numerical stiffness due to disparate time-scales, (ii) improved accuracy in comparison with leading neural-network architectures, (iii) efficiency in long-time simulation/forecasting due to explicit training of slow time-scale dynamics, and (iv) a flexible framework that is parallelizable and may be integrated with standard numerical time-stepping algorithms. The method is demonstrated on a wide range of nonlinear dynamical systems, including the Van der Pol oscillator, the Lorenz system, the Kuramoto-Sivashinsky equation, and fluid flow pass a cylinder; audio and video signals are also explored. On the sequence generation examples, we benchmark our algorithm against state-of-the-art methods, such as LSTM, reservoir computing, and clockwork RNN. Despite the structural simplicity of our method, it outperforms competing methods on numerical integration.},
	urldate = {2021-03-23},
	journal = {arXiv:2008.09768 [physics]},
	author = {Liu, Yuying and Kutz, J. Nathan and Brunton, Steven L.},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.09768},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics},
}

@article{candes_robust_2011,
	title = {Robust principal component analysis?},
	volume = {58},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/1970392.1970395},
	doi = {10.1145/1970392.1970395},
	abstract = {This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.},
	number = {3},
	urldate = {2021-03-23},
	journal = {Journal of the ACM},
	author = {Candès, Emmanuel J. and Li, Xiaodong and Ma, Yi and Wright, John},
	month = jun,
	year = {2011},
	keywords = {Principal components, duality, low-rank matrices, nuclear-norm minimization, robustness vis-a-vis outliers, sparsity, video surveillance, ℓ1-norm minimization},
	pages = {11:1--11:37},
}

@article{brunton_data_2017,
	title = {Data {Driven} {Science} \& {Engineering}},
	language = {en},
	author = {Brunton, Steven L and Kutz, J Nathan},
	year = {2017},
	pages = {572},
}

@article{lattanzi_stochastic_2021,
	title = {A stochastic model for the hydrodynamic force in {Euler}--{Lagrange} simulations of particle-laden flows},
	url = {http://arxiv.org/abs/2103.10581},
	abstract = {Standard Eulerian--Lagrangian (EL) methods generally employ drag force models that only represent the mean hydrodynamic force acting upon a particle-laden suspension. Consequently, higher-order drag force statistics, arising from neighbor-induced flow perturbations, are not accounted for; with implications on predictions for particle velocity variance and dispersion. We develop a force Langevin (FL) model that treats neighbor-induced drag fluctuations as a stochastic force within an EL framework. The stochastic drag force follows an Ornstein-Uhlenbeck process and requires closure of the integral time scale for the fluctuating hydrodynamic force and the standard deviation in drag. The former is closed using the mean-free time between successive collisions, derived from the kinetic theory of non-uniform gases. For the latter, particle-resolved direct numerical simulation (PR--DNS) of fixed particle assemblies is utilized to develop a correlation. The stochastic EL framework specifies unresolved drag force statistics, leading to the correct evolution and sustainment of particle velocity variance over a wide range of Reynolds numbers and solids volume fractions when compared to PR--DNS of freely-evolving homogeneous suspensions. By contrast, standard EL infers drag statistics from variations in the resolved flow and thus under-predicts the growth and steady particle velocity variance in homogeneous suspensions. Velocity statistics from standard EL approaches are found to depend on the bandwidth of the projection function used for two-way momentum coupling, while results obtained from the stochastic EL approach are insensitive to the projection bandwidth.},
	language = {en},
	urldate = {2021-03-23},
	journal = {arXiv:2103.10581 [physics]},
	author = {Lattanzi, Aaron M. and Tavanashad, Vahid and Subramaniam, Shankar and Capecelatro, Jesse},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.10581},
	keywords = {Physics - Fluid Dynamics},
}

@article{glimm_maximum_2020,
	title = {Maximum entropy production as a necessary admissibility condition for the fluid {Navier}–{Stokes} and {Euler} equations},
	volume = {2},
	issn = {2523-3971},
	url = {https://doi.org/10.1007/s42452-020-03941-2},
	doi = {10.1007/s42452-020-03941-2},
	abstract = {In a particle physics dynamics, we assume a uniform distribution as the physical measure and a measure-theoretic definition of entropy on the velocity configuration space. This distribution is labeled as the physical solution in the remainder of the article. The dynamics are governed by an assumption of a Lagrangian formulation, with the velocity time derivatives as the momenta conjugate to the velocity configurations. From these definitions and assumptions, we show mathematically that a maximum entropy production principle selects the physical measure from among alternate solutions of the Navier–Stokes and Euler equations, but its transformation to an Eulerian frame is not established here, a topic that will be considered separately.},
	language = {en},
	number = {12},
	urldate = {2021-03-18},
	journal = {SN Applied Sciences},
	author = {Glimm, James and Lazarev, Daniel and Chen, Gui-Qiang G.},
	month = dec,
	year = {2020},
	pages = {2160},
}

@article{medved_understanding_2020,
	title = {Understanding {Fluid} {Dynamics} from {Langevin} and {Fokker}–{Planck} {Equations}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2311-5521/5/1/40},
	doi = {10.3390/fluids5010040},
	abstract = {The Langevin equations (LE) and the Fokker\&ndash;Planck (FP) equations are widely used to describe fluid behavior based on coarse-grained approximations of microstructure evolution. In this manuscript, we describe the relation between LE and FP as related to particle motion within a fluid. The manuscript introduces undergraduate students to two LEs, their corresponding FP equations, and their solutions and physical interpretation.},
	language = {en},
	number = {1},
	urldate = {2021-03-18},
	journal = {Fluids},
	author = {Medved, Andrei and Davis, Riley and Vasquez, Paula A.},
	month = mar,
	year = {2020},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Fokker–Planck, Langevin, Matlab GUI, Stokes–Einstein relation, fluctuation dissipation, microrheology, mobility},
	pages = {40},
}

@article{chen_solving_2020,
	title = {Solving {Inverse} {Stochastic} {Problems} from {Discrete} {Particle} {Observations} {Using} the {Fokker}-{Planck} {Equation} and {Physics}-informed {Neural} {Networks}},
	url = {http://arxiv.org/abs/2008.10653},
	abstract = {The Fokker-Planck (FP) equation governing the evolution of the probability density function (PDF) is applicable to many disciplines but it requires specification of the coefficients for each case, which can be functions of space-time and not just constants, hence requiring the development of a data-driven modeling approach. When the data available is directly on the PDF, then there exist methods for inverse problems that can be employed to infer the coefficients and thus determine the FP equation and subsequently obtain its solution. Herein, we address a more realistic scenario, where only sparse data are given on the particles' positions at a few time instants, which are not sufficient to accurately construct directly the PDF even at those times from existing methods, e.g., kernel estimation algorithms. To this end, we develop a general framework based on physics-informed neural networks (PINNs) that introduces a new loss function using the Kullback-Leibler divergence to connect the stochastic samples with the FP equation, to simultaneously learn the equation and infer the multi-dimensional PDF at all times. In particular, we consider two types of inverse problems, type I where the FP equation is known but the initial PDF is unknown, and type II in which, in addition to unknown initial PDF, the drift and diffusion terms are also unknown. In both cases, we investigate problems with either Brownian or Levy noise or a combination of both. We demonstrate the new PINN framework in detail in the one-dimensional case (1D) but we also provide results for up to 5D demonstrating that we can infer both the FP equation and\vphantom{\{}\} dynamics simultaneously at all times with high accuracy using only very few discrete observations of the particles.},
	urldate = {2021-03-18},
	journal = {arXiv:2008.10653 [physics, stat]},
	author = {Chen, Xiaoli and Yang, Liu and Duan, Jinqiao and Karniadakis, George Em},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.10653},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{titi_approximate_1990,
	title = {On approximate {Inertial} {Manifolds} to the {Navier}-{Stokes} equations},
	volume = {149},
	issn = {0022-247X},
	url = {https://www.sciencedirect.com/science/article/pii/0022247X9090061J},
	doi = {10.1016/0022-247X(90)90061-J},
	abstract = {Recently, the theory of Inertial Manifolds has shown that the long time behavior (the dynamics) of certain dissipative partial differential equations can be fully discribed by that of a finite ordinary differential system. Although we are still unable to prove existence of Inertial Manifolds to the Navier-Stokes equations, we present here a nonlinear finite dimensional analytic manifold that approximates closely the global attractor in the two-dimensional case, and certain bounded invariant sets in the three-dimensional case. This approximate manifold and others allow us to introduce modified Galerkin approximations.},
	language = {en},
	number = {2},
	urldate = {2021-03-16},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Titi, Edriss S},
	month = jul,
	year = {1990},
	pages = {540--557},
}

@article{karras_progressive_2018,
	title = {Progressive {Growing} of {GANs} for {Improved} {Quality}, {Stability}, and {Variation}},
	url = {http://arxiv.org/abs/1710.10196},
	abstract = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024{\textasciicircum}2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.},
	urldate = {2021-03-12},
	journal = {arXiv:1710.10196 [cs, stat]},
	author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	month = feb,
	year = {2018},
	note = {arXiv: 1710.10196},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{wang_fully_2018,
	title = {A {Fully} {Progressive} {Approach} to {Single}-{Image} {Super}-{Resolution}},
	url = {http://arxiv.org/abs/1804.02900},
	abstract = {Recent deep learning approaches to single image super-resolution have achieved impressive results in terms of traditional error measures and perceptual quality. However, in each case it remains challenging to achieve high quality results for large upsampling factors. To this end, we propose a method (ProSR) that is progressive both in architecture and training: the network upsamples an image in intermediate steps, while the learning process is organized from easy to hard, as is done in curriculum learning. To obtain more photorealistic results, we design a generative adversarial network (GAN), named ProGanSR, that follows the same progressive multi-scale design principle. This not only allows to scale well to high upsampling factors (e.g., 8x) but constitutes a principled multi-scale approach that increases the reconstruction quality for all upsampling factors simultaneously. In particular ProSR ranks 2nd in terms of SSIM and 4th in terms of PSNR in the NTIRE2018 SISR challenge [34]. Compared to the top-ranking team, our model is marginally lower, but runs 5 times faster.},
	urldate = {2021-03-12},
	journal = {arXiv:1804.02900 [cs]},
	author = {Wang, Yifan and Perazzi, Federico and McWilliams, Brian and Sorkine-Hornung, Alexander and Sorkine-Hornung, Olga and Schroers, Christopher},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.02900},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{yang_generative_2020,
	title = {Generative {Ensemble}-{Regression}: {Learning} {Stochastic} {Dynamics} from {Discrete} {Particle} {Ensemble} {Observations}},
	shorttitle = {Generative {Ensemble}-{Regression}},
	url = {http://arxiv.org/abs/2008.01915},
	abstract = {We propose a new method for inferring the governing stochastic ordinary differential equations by observing particle ensembles at discrete and sparse time instants, i.e., multiple "snapshots". Particle coordinates at a single time instant, possibly noisy or truncated, are recorded in each snapshot but are unpaired across the snapshots. By training a generative model that generates "fake" sample paths, we aim to fit the observed particle ensemble distributions with a curve in the probability measure space, which is induced from the inferred particle dynamics. We employ different metrics to quantify the differences between distributions, like the sliced Wasserstein distances and the adversarial losses in generative adversarial networks. We refer to this approach as generative "ensemble-regression", in analogy to the classic "point-regression", where we infer the dynamics by performing regression in the Euclidean space, e.g. linear/logistic regression. We illustrate the ensemble-regression by learning the drift and diffusion terms of particle ensembles governed by stochastic ordinary differential equations with Brownian motions and L{\textbackslash}'evy processes up to 20 dimensions. We also discuss how to treat cases with noisy or truncated observations, as well as the scenario of paired observations, and we prove a theorem for the convergence in Wasserstein distance for continuous sample spaces.},
	urldate = {2021-03-11},
	journal = {arXiv:2008.01915 [cs, stat]},
	author = {Yang, Liu and Daskalakis, Constantinos and Karniadakis, George Em},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.01915},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{garnier_review_2021,
	title = {A review on {Deep} {Reinforcement} {Learning} for {Fluid} {Mechanics}},
	url = {http://arxiv.org/abs/1908.04127},
	abstract = {Deep reinforcement learning (DRL) has recently been adopted in a wide range of physics and engineering domains for its ability to solve decision-making problems that were previously out of reach due to a combination of non-linearity and high dimensionality. In the last few years, it has spread in the field of computational mechanics, and particularly in fluid dynamics, with recent applications in flow control and shape optimization. In this work, we conduct a detailed review of existing DRL applications to fluid mechanics problems. In addition, we present recent results that further illustrate the potential of DRL in Fluid Mechanics. The coupling methods used in each case are covered, detailing their advantages and limitations. Our review also focuses on the comparison with classical methods for optimal control and optimization. Finally, several test cases are described that illustrate recent progress made in this field. The goal of this publication is to provide an understanding of DRL capabilities along with state-of-the-art applications in fluid dynamics to researchers wishing to address new problems with these methods.},
	urldate = {2021-03-11},
	journal = {arXiv:1908.04127 [physics]},
	author = {Garnier, Paul and Viquerat, Jonathan and Rabault, Jean and Larcher, Aurélien and Kuhnle, Alexander and Hachem, Elie},
	month = feb,
	year = {2021},
	note = {arXiv: 1908.04127},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{beetham_sparse_2021,
	title = {Sparse identification of multiphase turbulence closures for coupled fluid–particle flows},
	volume = {914},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/sparse-identification-of-multiphase-turbulence-closures-for-coupled-fluidparticle-flows/2C0178BCDC3579688DE7EE0E9BB02A9A},
	doi = {10.1017/jfm.2021.53},
	abstract = {, 
In this work, model closures of the multiphase Reynolds-averaged Navier–Stokes (RANS) equations are developed for homogeneous, fully developed gas–particle flows. To date, the majority of RANS closures are based on extensions of single-phase turbulence models, which fail to capture complex two-phase flow dynamics across dilute and dense regimes, especially when two-way coupling between the phases is important. In the present study, particles settle under gravity in an unbounded viscous fluid. At sufficient mass loadings, interphase momentum exchange between the phases results in the spontaneous generation of particle clusters that sustain velocity fluctuations in the fluid. Data generated from Eulerian–Lagrangian simulations are used in a sparse regression method for model closure that ensures form invariance. Particular attention is paid to modelling the unclosed terms unique to the multiphase RANS equations (drag production, drag exchange, pressure strain and viscous dissipation). A minimal set of tensors is presented that serve as the basis for modelling. It is found that sparse regression identifies compact, algebraic models that are accurate across flow conditions and robust to sparse training data.},
	language = {en},
	urldate = {2021-03-10},
	journal = {Journal of Fluid Mechanics},
	author = {Beetham, S. and Fox, R. O. and Capecelatro, J.},
	month = may,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {multiphase flow, particle/fluid flow, turbulence modelling},
}

@article{callaham_learning_2021,
	title = {Learning dominant physical processes with data-driven balance models},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21331-z},
	doi = {10.1038/s41467-021-21331-z},
	abstract = {Throughout the history of science, physics-based modeling has relied on judiciously approximating observed dynamics as a balance between a few dominant processes. However, this traditional approach is mathematically cumbersome and only applies in asymptotic regimes where there is a strict separation of scales in the physics. Here, we automate and generalize this approach to non-asymptotic regimes by introducing the idea of an equation space, in which different local balances appear as distinct subspace clusters. Unsupervised learning can then automatically identify regions where groups of terms may be neglected. We show that our data-driven balance models successfully delineate dominant balance physics in a much richer class of systems. In particular, this approach uncovers key mechanistic models in turbulence, combustion, nonlinear optics, geophysical fluids, and neuroscience.},
	language = {en},
	number = {1},
	urldate = {2021-03-10},
	journal = {Nature Communications},
	author = {Callaham, Jared L. and Koch, James V. and Brunton, Bingni W. and Kutz, J. Nathan and Brunton, Steven L.},
	month = feb,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1016},
}

@article{wu_enforcing_2020,
	title = {Enforcing statistical constraints in generative adversarial networks for modeling chaotic dynamical systems},
	volume = {406},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999119309143},
	doi = {10.1016/j.jcp.2019.109209},
	abstract = {Simulating complex physical systems often involves solving partial differential equations (PDEs) with some closures due to the presence of multi-scale physics that cannot be fully resolved. Although the advancement of high performance computing has made resolving small-scale physics possible, such simulations are still very expensive. Therefore, reliable and accurate closure models for the unresolved physics remains an important requirement for many computational physics problems, e.g., turbulence simulation. Recently, several researchers have adopted generative adversarial networks (GANs), a novel paradigm of training machine learning models, to generate solutions of PDEs-governed complex systems without having to numerically solve these PDEs. However, GANs are known to be difficult in training and likely to converge to local minima, where the generated samples do not capture the true statistics of the training data. In this work, we present a statistical constrained generative adversarial network by enforcing constraints of covariance from the training data, which results in an improved machine-learning-based emulator to capture the statistics of the training data generated by solving fully resolved PDEs. We show that such a statistical regularization leads to better performance compared to standard GANs, measured by (1) the constrained model's ability to more faithfully emulate certain physical properties of the system and (2) the significantly reduced (by up to 80\%) training time to reach the solution. We exemplify this approach on the Rayleigh-Bénard convection, a turbulent flow system that is an idealized model of the Earth's atmosphere. With the growth of high-fidelity simulation databases of physical systems, this work suggests great potential for being an alternative to the explicit modeling of closures or parameterizations for unresolved physics, which are known to be a major source of uncertainty in simulating multi-scale physical systems, e.g., turbulence or Earth's climate.},
	language = {en},
	urldate = {2021-03-04},
	journal = {Journal of Computational Physics},
	author = {Wu, Jin-Long and Kashinath, Karthik and Albert, Adrian and Chirila, Dragos and {Prabhat} and Xiao, Heng},
	month = apr,
	year = {2020},
	keywords = {Generative adversarial networks, Machine learning, Partial differential equations, Rayleigh-Bénard convection, Statistical constraint},
	pages = {109209},
}

@article{yang_enforcing_2020,
	title = {Enforcing {Deterministic} {Constraints} on {Generative} {Adversarial} {Networks} for {Emulating} {Physical} {Systems}},
	url = {http://arxiv.org/abs/1911.06671},
	abstract = {Generative adversarial networks (GANs) were initially proposed to generate images by learning from a large number of samples. Recently, GANs have been used to emulate complex physical systems such as turbulent flows. However, a critical question must be answered before GANs can be considered trusted emulators for physical systems: do GANs-generated samples conform to the various physical constraints? These include both deterministic constraints (e.g., conservation laws) and statistical constraints (e.g., energy spectrum of turbulent flows). The latter have been studied in a companion paper (Wu et al., Enforcing statistical constraints in generative adversarial networks for modeling chaotic dynamical systems. Journal of Computational Physics. 406, 109209, 2020). In the present work, we enforce deterministic yet imprecise constraints on GANs by incorporating them into the loss function of the generator. We evaluate the performance of physics-constrained GANs on two representative tasks with geometrical constraints (generating points on circles) and differential constraints (generating divergence-free flow velocity fields), respectively. In both cases, the constrained GANs produced samples that conform to the underlying constraints rather accurately, even though the constraints are only enforced up to a specified interval. More importantly, the imposed constraints significantly accelerate the convergence and improve the robustness in the training, indicating that they serve as a physics-based regularization. These improvements are noteworthy, as the convergence and robustness are two well-known obstacles in the training of GANs.},
	urldate = {2021-03-04},
	journal = {arXiv:1911.06671 [physics, stat]},
	author = {Yang, Zeng and Wu, Jin-Long and Xiao, Heng},
	month = nov,
	year = {2020},
	note = {arXiv: 1911.06671},
	keywords = {Physics - Computational Physics, Statistics - Machine Learning},
}

@article{wu_enforcing_2020-1,
	title = {Enforcing {Statistical} {Constraints} in {Generative} {Adversarial} {Networks} for {Modeling} {Chaotic} {Dynamical} {Systems}},
	volume = {406},
	issn = {00219991},
	url = {http://arxiv.org/abs/1905.06841},
	doi = {10.1016/j.jcp.2019.109209},
	abstract = {Simulating complex physical systems often involves solving partial differential equations (PDEs) with some closures due to the presence of multi-scale physics that cannot be fully resolved. Therefore, reliable and accurate closure models for unresolved physics remains an important requirement for many computational physics problems, e.g., turbulence simulation. Recently, several researchers have adopted generative adversarial networks (GANs), a novel paradigm of training machine learning models, to generate solutions of PDEs-governed complex systems without having to numerically solve these PDEs. However, GANs are known to be difficult in training and likely to converge to local minima, where the generated samples do not capture the true statistics of the training data. In this work, we present a statistical constrained generative adversarial network by enforcing constraints of covariance from the training data, which results in an improved machine-learning-based emulator to capture the statistics of the training data generated by solving fully resolved PDEs. We show that such a statistical regularization leads to better performance compared to standard GANs, measured by (1) the constrained model's ability to more faithfully emulate certain physical properties of the system and (2) the significantly reduced (by up to 80\%) training time to reach the solution. We exemplify this approach on the Rayleigh-Benard convection, a turbulent flow system that is an idealized model of the Earth's atmosphere. With the growth of high-fidelity simulation databases of physical systems, this work suggests great potential for being an alternative to the explicit modeling of closures or parameterizations for unresolved physics, which are known to be a major source of uncertainty in simulating multi-scale physical systems, e.g., turbulence or Earth's climate.},
	language = {en},
	urldate = {2021-03-04},
	journal = {Journal of Computational Physics},
	author = {Wu, Jin-Long and Kashinath, Karthik and Albert, Adrian and Chirila, Dragos and Prabhat and Xiao, Heng},
	month = apr,
	year = {2020},
	note = {arXiv: 1905.06841},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics, Statistics - Machine Learning},
	pages = {109209},
}

@article{fukami_assessment_2020,
	title = {Assessment of supervised machine learning methods for fluid flows},
	volume = {34},
	issn = {1432-2250},
	url = {https://doi.org/10.1007/s00162-020-00518-y},
	doi = {10.1007/s00162-020-00518-y},
	abstract = {We apply supervised machine learning techniques to a number of regression problems in fluid dynamics. Four machine learning architectures are examined in terms of their characteristics, accuracy, computational cost, and robustness for canonical flow problems. We consider the estimation of force coefficients and wakes from a limited number of sensors on the surface for flows over a cylinder and NACA0012 airfoil with a Gurney flap. The influence of the temporal density of the training data is also examined. Furthermore, we consider the use of convolutional neural network in the context of super-resolution analysis of two-dimensional cylinder wake, two-dimensional decaying isotropic turbulence, and three-dimensional turbulent channel flow. In the concluding remarks, we summarize on findings from a range of regression-type problems considered herein.},
	language = {en},
	number = {4},
	urldate = {2021-03-03},
	journal = {Theoretical and Computational Fluid Dynamics},
	author = {Fukami, Kai and Fukagata, Koji and Taira, Kunihiko},
	month = aug,
	year = {2020},
	pages = {497--519},
}

@article{morimoto_convolutional_2021,
	title = {Convolutional neural networks for fluid flow analysis: toward effective metamodeling and low-dimensionalization},
	shorttitle = {Convolutional neural networks for fluid flow analysis},
	url = {http://arxiv.org/abs/2101.02535},
	abstract = {We focus on a convolutional neural network (CNN), which has recently been utilized for fluid flow analyses, from the perspective on the influence of various operations inside the CNN considering some canonical regressions with fluid flow data. We consider two types of the CNN-based fluid flow analyses; 1. CNN metamodeling and 2. CNN autoencoder. For the first type of CNN with the additional scalar inputs, which is one of the common forms of CNN for fluid flow analysis, we investigate the influence of input placements in the CNN training pipeline. As an example, the estimation of force coefficients of laminar flows over a flat plate and two side-by-side cylinders are considered. We find that care should be taken for the placement of additional scalar inputs depending on the problems and the flows users handle. We then investigate the influence of various parameters and operations on CNN performance, with the utilization of autoencoder (AE). A two-dimensional turbulence is considered for the demonstration of AE. The results of AE highly rely on the decaying nature. The influence of padding operation at a convolutional layer is also investigated. The zero padding shows reasonable ability compared to other methods which account for boundary conditions of numerical data. Moreover, the effect of the dimensional reduction/extension methods inside CNN is also examined. The CNN model is robust to the dimension reduction operations, while being sensitive to the dimensional-extension methods. The findings through the paper can help us toward the practical uses of CNN-based fluid flow analyses.},
	urldate = {2021-03-03},
	journal = {arXiv:2101.02535 [physics]},
	author = {Morimoto, Masaki and Fukami, Kai and Zhang, Kai and Nair, Aditya G. and Fukagata, Koji},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.02535},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{nakamura_convolutional_2021,
	title = {Convolutional neural network and long short-term memory based reduced order surrogate for minimal turbulent channel flow},
	volume = {33},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/full/10.1063/5.0039845},
	doi = {10.1063/5.0039845},
	abstract = {We investigate the applicability of the machine learning based reduced order model (ML-ROM) to three-dimensional complex flows. As an example, we consider a turbulent channel flow at the friction Reynolds number of Reτ=110Reτ=110{\textless}math display="inline" overflow="scroll" altimg="eq-00001.gif"{\textgreater} {\textless}mrow{\textgreater} {\textless}mi{\textgreater}R{\textless}/mi{\textgreater} {\textless}msub{\textgreater} {\textless}mi{\textgreater}e{\textless}/mi{\textgreater} {\textless}mi{\textgreater}τ{\textless}/mi{\textgreater}{\textless}/msub{\textgreater} {\textless}mo{\textgreater}={\textless}/mo{\textgreater} {\textless}mn{\textgreater}110{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} in a minimum domain, which can maintain coherent structures of turbulence. Training datasets are prepared by direct numerical simulation (DNS). The present ML-ROM is constructed by combining a three-dimensional convolutional neural network autoencoder (CNN-AE) and a long short-term memory (LSTM). The CNN-AE works to map high-dimensional flow fields into a low-dimensional latent space. The LSTM is, then, utilized to predict a temporal evolution of the latent vectors obtained by the CNN-AE. The combination of the CNN-AE and LSTM can represent the spatiotemporal high-dimensional dynamics of flow fields by only integrating the temporal evolution of the low-dimensional latent dynamics. The turbulent flow fields reproduced by the present ML-ROM show statistical agreement with the reference DNS data in time-ensemble sense, which can also be found through an orbit-based analysis. Influences of the population of vortical structures contained in the domain and the time interval used for temporal prediction on the ML-ROM performance are also investigated. The potential and limitation of the present ML-ROM for turbulence analysis are discussed at the end of our presentation.},
	number = {2},
	urldate = {2021-03-03},
	journal = {Physics of Fluids},
	author = {Nakamura, Taichi (中村太一 ) and Fukami, Kai (深見開 ) and Hasegawa, Kazuto (長谷川一登 ) and Nabae, Yusuke (難波江佑介 ) and Fukagata, Koji (深潟康二 )},
	month = feb,
	year = {2021},
	note = {Publisher: American Institute of Physics},
	pages = {025116},
}

@article{yang_generative_2020-1,
	title = {Generative {Ensemble}-{Regression}: {Learning} {Stochastic} {Dynamics} from {Discrete} {Particle} {Ensemble} {Observations}},
	shorttitle = {Generative {Ensemble}-{Regression}},
	url = {http://arxiv.org/abs/2008.01915},
	abstract = {We propose a new method for inferring the governing stochastic ordinary differential equations by observing particle ensembles at discrete and sparse time instants, i.e., multiple "snapshots". Particle coordinates at a single time instant, possibly noisy or truncated, are recorded in each snapshot but are unpaired across the snapshots. By training a generative model that generates "fake" sample paths, we aim to fit the observed particle ensemble distributions with a curve in the probability measure space, which is induced from the inferred particle dynamics. We employ different metrics to quantify the differences between distributions, like the sliced Wasserstein distances and the adversarial losses in generative adversarial networks. We refer to this approach as generative "ensemble-regression", in analogy to the classic "point-regression", where we infer the dynamics by performing regression in the Euclidean space, e.g. linear/logistic regression. We illustrate the ensemble-regression by learning the drift and diffusion terms of particle ensembles governed by stochastic ordinary differential equations with Brownian motions and L{\textbackslash}'evy processes up to 20 dimensions. We also discuss how to treat cases with noisy or truncated observations, as well as the scenario of paired observations, and we prove a theorem for the convergence in Wasserstein distance for continuous sample spaces.},
	urldate = {2021-03-02},
	journal = {arXiv:2008.01915 [cs, stat]},
	author = {Yang, Liu and Daskalakis, Constantinos and Karniadakis, George Em},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.01915},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lu_deeponet_2020,
	title = {{DeepONet}: {Learning} nonlinear operators for identifying differential equations based on the universal approximation theorem of operators},
	shorttitle = {{DeepONet}},
	url = {http://arxiv.org/abs/1910.03193},
	abstract = {While it is widely known that neural networks are universal approximators of continuous functions, a less known and perhaps more powerful result is that a neural network with a single hidden layer can approximate accurately any nonlinear continuous operator. This universal approximation theorem is suggestive of the potential application of neural networks in learning nonlinear operators from data. However, the theorem guarantees only a small approximation error for a sufficient large network, and does not consider the important optimization and generalization errors. To realize this theorem in practice, we propose deep operator networks (DeepONets) to learn operators accurately and efficiently from a relatively small dataset. A DeepONet consists of two sub-networks, one for encoding the input function at a fixed number of sensors \$x\_i, i=1,{\textbackslash}dots,m\$ (branch net), and another for encoding the locations for the output functions (trunk net). We perform systematic simulations for identifying two types of operators, i.e., dynamic systems and partial differential equations, and demonstrate that DeepONet significantly reduces the generalization error compared to the fully-connected networks. We also derive theoretically the dependence of the approximation error in terms of the number of sensors (where the input function is defined) as well as the input function type, and we verify the theorem with computational results. More importantly, we observe high-order error convergence in our computational tests, namely polynomial rates (from half order to fourth order) and even exponential convergence with respect to the training dataset size.},
	urldate = {2021-03-02},
	journal = {arXiv:1910.03193 [cs, stat]},
	author = {Lu, Lu and Jin, Pengzhan and Karniadakis, George Em},
	month = apr,
	year = {2020},
	note = {arXiv: 1910.03193},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mouri_probability_2002,
	title = {Probability density function of turbulent velocity fluctuations},
	volume = {65},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.65.056304},
	doi = {10.1103/PhysRevE.65.056304},
	abstract = {The probability density function (PDF) of velocity fluctuations is studied experimentally for grid turbulence in a systematical manner. At small distances from the grid, where the turbulence is still developing, the PDF is sub-Gaussian. At intermediate distances, where the turbulence is fully developed, the PDF is Gaussian. At large distances, where the turbulence has decayed, the PDF is hyper-Gaussian. The Fourier transforms of the velocity fluctuations always have Gaussian PDFs. At intermediate distances from the grid, the Fourier transforms are statistically independent of each other. This is the necessary and sufficient condition for Gaussianity of the velocity fluctuations. At small and large distances, the Fourier transforms are dependent.},
	number = {5},
	urldate = {2021-03-02},
	journal = {Physical Review E},
	author = {Mouri, Hideaki and Takaoka, Masanori and Hori, Akihiro and Kawashima, Yoshihide},
	month = may,
	year = {2002},
	note = {Publisher: American Physical Society},
	pages = {056304},
}

@article{granero-belinchon_kullback-leibler_2017,
	title = {A {Kullback}-{Leibler} divergence measure of intermittency: application to turbulence},
	shorttitle = {A {Kullback}-{Leibler} divergence measure of intermittency},
	url = {http://arxiv.org/abs/1707.07950},
	doi = {10.1103/PhysRevE.97.013107},
	abstract = {For generic systems exhibiting power law behaviors, and hence multiscale dependencies, we propose a new, and yet simple, tool to analyze multifractality and intermittency, after noticing that these concepts are directly related to the deformation of a probability density function from Gaussian at large scales to non-Gaussian at smaller scales. Our framework is based on information theory, and uses Shannon entropy and Kullback-Leibler divergence. We propose an extensive application to three-dimensional fully developed turbulence, seen here as a paradigmatic complex system where intermittency was historically defined. Moreover, the concepts of scale invariance and multifractality were extensively studied in this field and, most importantly, benchmarked. We compute our measure on experimental Eulerian velocity measurements, as well as on synthetic processes and a phenomenological model of fluid turbulence.Our approach is very general and does not require any underlying model of the system, although it can probe the relevance of such a model.},
	urldate = {2021-03-02},
	journal = {arXiv:1707.07950 [cond-mat, physics:physics]},
	author = {Granero-Belinchon, Carlos and Roux, Stephane G. and Garnier, Nicolas B.},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.07950},
	keywords = {Condensed Matter - Statistical Mechanics, Physics - Data Analysis, Statistics and Probability, Physics - Fluid Dynamics},
}

@article{young_novel_2015,
	title = {A novel vector potential formulation of {3D} {Navier}–{Stokes} equations with through-flow boundaries by a local meshless method},
	volume = {300},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999115004854},
	doi = {10.1016/j.jcp.2015.07.040},
	abstract = {An alternative vector potential formulation is used to solve the Navier–Stokes (N–S) equations in 3D incompressible viscous flow problems with and without through-flow boundaries. Difficulties of the vector potential formulation include the implementation of boundary conditions for through-flow boundaries and the numerical treatment of fourth-order partial differential equations. The advantages on the other hand are the automatic satisfaction of the continuity equation; and pressure is decoupled from the velocity. The objective of this paper is to introduce the appropriate gauge and boundary conditions on the vector potential formulation by a localized meshless method. To handle the divergence-free property, a Coulomb gauge condition is enforced on the vector potential to ensure its existence and uniqueness mathematically. We further improve the algorithm to through-flow problems for the boundary conditions of vector potential by introducing the concept of Stokes' theorem. Based on this innovation, there is no need to include an additional variable to tackle the through-flow fields. This process will greatly simplify the imposition of boundary conditions by the vector potential approach. Under certain conditions, the coupled fourth-order partial differential equations can be easily solved by using this meshless local differential quadrature (LDQ) method. Due to the LDQ capability to deal with the high order differential equations, this algorithm is very attractive to solve this fourth-order vector potential formulation for the N–S equations as comparing to the conventional numerical schemes such as finite element or finite difference methods. The proposed vector potential formulation is simpler and has improved accuracy and efficiency compared to other pressure-free or pressure-coupled algorithms. This investigation can be regarded as the first complete study to obtain the N–S solutions by vector potential formulation through a LDQ method. Two classic 3D benchmark problems, lid-driven cavity and backward-facing step flows, are numerically solved to examine the feasibility of the improved algorithm. Results show the flexibility of the proposed vector potential formulation for the 3D Navier–Stokes equations.},
	language = {en},
	urldate = {2021-03-02},
	journal = {Journal of Computational Physics},
	author = {Young, D. L. and Tsai, C. H. and Wu, C. S.},
	month = nov,
	year = {2015},
	keywords = {Gauge condition, Navier–Stokes equations, Stokes' theorem, Through-flow boundary, Vector potential formulation},
	pages = {219--240},
}

@article{zhuang_learned_2020,
	title = {Learned discretizations for passive scalar advection in a 2-{D} turbulent flow},
	url = {http://arxiv.org/abs/2004.05477},
	abstract = {The computational cost of fluid simulations increases rapidly with grid resolution. This has given a hard limit on the ability of simulations to accurately resolve small scale features of complex flows. Here we use a machine learning approach to learn a numerical discretization that retains high accuracy even when the solution is under-resolved with classical methods. We apply this approach to passive scalar advection in a two-dimensional turbulent flow. The method maintains the same accuracy as traditional high-order flux-limited advection solvers, while using 4x lower grid resolution in each dimension. The machine learning component is tightly integrated with traditional finite-volume schemes and can be trained via an end-to-end differentiable programming framework. The solver can achieve near-peak hardware utilization on CPUs and accelerators via convolutional filters. Code is available at https://github.com/google-research/data-driven-pdes.},
	urldate = {2021-03-02},
	journal = {arXiv:2004.05477 [cond-mat, physics:physics]},
	author = {Zhuang, Jiawei and Kochkov, Dmitrii and Bar-Sinai, Yohai and Brenner, Michael P. and Hoyer, Stephan},
	month = nov,
	year = {2020},
	note = {arXiv: 2004.05477},
	keywords = {Condensed Matter - Disordered Systems and Neural Networks, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{pathak_using_2020,
	title = {Using {Machine} {Learning} to {Augment} {Coarse}-{Grid} {Computational} {Fluid} {Dynamics} {Simulations}},
	url = {http://arxiv.org/abs/2010.00072},
	abstract = {Simulation of turbulent flows at high Reynolds number is a computationally challenging task relevant to a large number of engineering and scientific applications in diverse fields such as climate science, aerodynamics, and combustion. Turbulent flows are typically modeled by the Navier-Stokes equations. Direct Numerical Simulation (DNS) of the Navier-Stokes equations with sufficient numerical resolution to capture all the relevant scales of the turbulent motions can be prohibitively expensive. Simulation at lower-resolution on a coarse-grid introduces significant errors. We introduce a machine learning (ML) technique based on a deep neural network architecture that corrects the numerical errors induced by a coarse-grid simulation of turbulent flows at high-Reynolds numbers, while simultaneously recovering an estimate of the high-resolution fields. Our proposed simulation strategy is a hybrid ML-PDE solver that is capable of obtaining a meaningful high-resolution solution trajectory while solving the system PDE at a lower resolution. The approach has the potential to dramatically reduce the expense of turbulent flow simulations. As a proof-of-concept, we demonstrate our ML-PDE strategy on a two-dimensional turbulent (Rayleigh Number \$Ra=10{\textasciicircum}9\$) Rayleigh-B{\textbackslash}'enard Convection (RBC) problem.},
	urldate = {2021-03-02},
	journal = {arXiv:2010.00072 [physics]},
	author = {Pathak, Jaideep and Mustafa, Mustafa and Kashinath, Karthik and Motheau, Emmanuel and Kurth, Thorsten and Day, Marcus},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.00072},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Geophysics},
}

@article{kohl_learning_2020,
	title = {Learning {Similarity} {Metrics} for {Numerical} {Simulations}},
	url = {http://arxiv.org/abs/2002.07863},
	abstract = {We propose a neural network-based approach that computes a stable and generalizing metric (LSiM) to compare data from a variety of numerical simulation sources. We focus on scalar time-dependent 2D data that commonly arises from motion and transport-based partial differential equations (PDEs). Our method employs a Siamese network architecture that is motivated by the mathematical properties of a metric. We leverage a controllable data generation setup with PDE solvers to create increasingly different outputs from a reference simulation in a controlled environment. A central component of our learned metric is a specialized loss function that introduces knowledge about the correlation between single data samples into the training process. To demonstrate that the proposed approach outperforms existing metrics for vector spaces and other learned, image-based metrics, we evaluate the different methods on a large range of test data. Additionally, we analyze generalization beneﬁts of an adjustable training data difﬁculty and demonstrate the robustness of LSiM via an evaluation on three real-world data sets.},
	language = {en},
	urldate = {2021-03-01},
	journal = {arXiv:2002.07863 [physics, stat]},
	author = {Kohl, Georg and Um, Kiwon and Thuerey, Nils},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.07863},
	keywords = {Computer Science - Machine Learning, Physics - Data Analysis, Statistics and Probability, Physics - Fluid Dynamics, Statistics - Machine Learning},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
	language = {en},
	number = {5},
	urldate = {2021-02-26},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	month = jan,
	year = {1989},
	keywords = {Back-propagation networks, Feedforward networks, Mapping networks, Network representation capability, Sigma-Pi networks, Squashing functions, Stone-Weierstrass Theorem, Universal approximation},
	pages = {359--366},
}

@article{schoenholz_jax_2020,
	title = {{JAX}, {M}.{D}.: {A} {Framework} for {Differentiable} {Physics}},
	shorttitle = {{JAX}, {M}.{D}.},
	url = {http://arxiv.org/abs/1912.04232},
	abstract = {We introduce JAX MD, a software package for performing differentiable physics simulations with a focus on molecular dynamics. JAX MD includes a number of physics simulation environments, as well as interaction potentials and neural networks that can be integrated into these environments without writing any additional code. Since the simulations themselves are differentiable functions, entire trajectories can be differentiated to perform meta-optimization. These features are built on primitive operations, such as spatial partitioning, that allow simulations to scale to hundreds-of-thousands of particles on a single GPU. These primitives are flexible enough that they can be used to scale up workloads outside of molecular dynamics. We present several examples that highlight the features of JAX MD including: integration of graph neural networks into traditional simulations, meta-optimization through minimization of particle packings, and a multi-agent flocking simulation. JAX MD is available at www.github.com/google/jax-md.},
	urldate = {2021-02-25},
	journal = {arXiv:1912.04232 [cond-mat, physics:physics, stat]},
	author = {Schoenholz, Samuel S. and Cubuk, Ekin D.},
	month = dec,
	year = {2020},
	note = {arXiv: 1912.04232},
	keywords = {Condensed Matter - Materials Science, Condensed Matter - Soft Condensed Matter, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{fidkowski_metric-based_2021,
	title = {Metric-based, goal-oriented mesh adaptation using machine learning},
	volume = {426},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120307312},
	doi = {10.1016/j.jcp.2020.109957},
	abstract = {This paper presents a machine-learning approach for determining the optimal anisotropy in a computational mesh, in the context of an output-based adaptive solution procedure. Artificial neural networks are used to predict the desired element aspect ratio from readily accessible features of the primal and adjoint solutions. Whereas the sizing of the element is still based on an adjoint-weighted residual error estimate, the network augments this information with element stretching magnitude and direction, at lower computational and implementation costs compared to a more rigorous approach: mesh optimization through error sampling and synthesis (MOESS). The network is trained to provide anisotropy information in the form of a normalized metric field, computed from primal, adjoint, and error indicator features. MOESS-optimized meshes for a variety of steady aerodynamic flows governed by the Reynolds-averaged Navier-Stokes equations in two dimensions provide data for training several multi-layer perceptron networks, which differ in size and inputs. The networks are then deployed and tested by driving complete mesh adaptation sequences, and the results show improvements in mesh efficiency compared to pure primal Hessian-based anisotropy detection and in many cases to MOESS itself.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Journal of Computational Physics},
	author = {Fidkowski, Krzysztof J. and Chen, Guodong},
	month = feb,
	year = {2021},
	keywords = {Adjoint, Discontinuous Galerkin, Mesh optimization, Metric, Neural network, Output error estimation},
	pages = {109957},
}

@article{tartakovsky_physics-informed_2021,
	title = {Physics-informed machine learning with conditional {Karhunen}-{Loève} expansions},
	volume = {426},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120306781},
	doi = {10.1016/j.jcp.2020.109904},
	abstract = {We present a new physics-informed machine learning approach for the inversion of partial differential equation (PDE) models with heterogeneous parameters. In our approach, the space-dependent partially observed parameters and states are approximated via Karhunen-Loève expansions (KLEs). Each of these KLEs is then conditioned on their corresponding measurements, resulting in low-dimensional models of the parameters and states that resolve observed data. Finally, the coefficients of the KLEs are estimated by minimizing the norm of the residual of the PDE model evaluated at a finite set of points in the computational domain, ensuring that the reconstructed parameters and states are consistent with both the observations and the PDE model to an arbitrary level of accuracy. In our approach, KLEs are constructed using the eigendecomposition of covariance models of spatial variability. For the model parameters, we employ a parameterized covariance model calibrated on parameter observations; for the model states, the covariance is estimated from a number of forward simulations of the PDE model corresponding to realizations of the parameters drawn from their KLE. We apply the proposed approach to identify heterogeneous diffusion coefficients in diffusion equations from sparse measurements of the diffusion coefficient and the solution of the diffusion equation. We find that the proposed approach compares favorably against state-of-the-art point estimates such as maximum a posteriori estimation and physics-informed neural networks.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Journal of Computational Physics},
	author = {Tartakovsky, A. M. and Barajas-Solano, D. A. and He, Q.},
	month = feb,
	year = {2021},
	keywords = {Conditional Karhunen-Loéve expansions, Machine learning, Model inversion, Parameter estimation},
	pages = {109904},
}

@article{hernandez_structure-preserving_2021,
	title = {Structure-preserving neural networks},
	volume = {426},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120307245},
	doi = {10.1016/j.jcp.2020.109950},
	abstract = {We develop a method to learn physical systems from data that employs feedforward neural networks and whose predictions comply with the first and second principles of thermodynamics. The method employs a minimum amount of data by enforcing the metriplectic structure of dissipative Hamiltonian systems in the form of the so-called General Equation for the Non-Equilibrium Reversible-Irreversible Coupling, GENERIC (Öttinger and Grmela (1997) [36]). The method does not need to enforce any kind of balance equation, and thus no previous knowledge on the nature of the system is needed. Conservation of energy and dissipation of entropy in the prediction of previously unseen situations arise as a natural by-product of the structure of the method. Examples of the performance of the method are shown that comprise conservative as well as dissipative systems, discrete as well as continuous ones.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Journal of Computational Physics},
	author = {Hernández, Quercus and Badías, Alberto and González, David and Chinesta, Francisco and Cueto, Elías},
	month = feb,
	year = {2021},
	keywords = {GENERIC, Neural networks, Scientific machine learning, Structure preservation},
	pages = {109950},
}

@article{font_deep_2021,
	title = {Deep learning of the spanwise-averaged {Navier}–{Stokes} equations},
	volume = {434},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121000942},
	doi = {10.1016/j.jcp.2021.110199},
	abstract = {Simulations of turbulent fluid flow around long cylindrical structures are computationally expensive because of the vast range of length scales, requiring simplifications such as dimensional reduction. Current dimensionality reduction techniques such as strip-theory and depth-averaged methods do not take into account the natural flow dissipation mechanism inherent in the small-scale three-dimensional (3-D) vortical structures. We propose a novel flow decomposition based on a local spanwise average of the flow, yielding the spanwise-averaged Navier–Stokes (SANS) equations. The SANS equations include closure terms accounting for the 3-D effects otherwise not considered in 2-D formulations. A supervised machine-learning (ML) model based on a deep convolutional neural network provides closure to the SANS system. A-priori results show up to 92\% correlation between target and predicted closure terms; more than an order of magnitude better than the eddy viscosity model correlation. The trained ML model is also assessed for different Reynolds regimes and body shapes to the training case where, despite some discrepancies in the shear-layer region, high correlation values are still observed. The new SANS equations and ML closure model are also used for a-posteriori prediction. While we find evidence of known stability issues with long time ML predictions for dynamical systems, the closed SANS simulations are still capable of predicting wake metrics and induced forces with errors from 1-10\%. This results in approximately an order of magnitude improvement over standard 2-D simulations while reducing the computational cost of 3-D simulations by 99.5\%.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Journal of Computational Physics},
	author = {Font, Bernat and Weymouth, Gabriel D. and Nguyen, Vinh-Tan and Tutty, Owen R.},
	month = jun,
	year = {2021},
	keywords = {Fluid dynamics, Machine learning, Turbulence modelling, Wake flow},
	pages = {110199},
}

@article{boffetta_two-dimensional_2011,
	title = {Two-{Dimensional} {Turbulence}},
	abstract = {In physical systems, a reduction in dimensionality often leads to exciting new phenomena. Here we discuss the novel effects arising from the consideration of ﬂuid turbulence conﬁned to two spatial dimensions. The additional conservation constraint on squared vorticity relative to three-dimensional (3D) turbulence leads to the dual-cascade scenario of Kraichnan and Batchelor with an inverse energy cascade to larger scales and a direct enstrophy cascade to smaller scales. Speciﬁc theoretical predictions of spectra, structure functions, probability distributions, and mechanisms are presented, and major experimental and numerical comparisons are reviewed. The introduction of 3D perturbations does not destroy the main features of the cascade picture, implying that 2D turbulence phenomenology establishes the general picture of turbulent ﬂuid ﬂows when one spatial direction is heavily constrained by geometry or by applied body forces. Such ﬂows are common in geophysical and planetary contexts, are beautiful to observe, and reﬂect the impact of dimensionality on ﬂuid turbulence.},
	language = {en},
	author = {Boffetta, Guido and Ecke, Robert E},
	year = {2011},
	pages = {27},
}

@article{huang_physics-informed_2020,
	title = {Physics-informed {Tensor}-train {ConvLSTM} for {Volumetric} {Velocity} {Forecasting}},
	url = {http://arxiv.org/abs/2008.01798},
	abstract = {According to the National Academies, a weekly forecast of velocity, vertical structure, and duration of the Loop Current (LC) and its eddies is critical for understanding the oceanography and ecosystem, and for mitigating outcomes of anthropogenic and natural disasters in the Gulf of Mexico (GoM). However, this forecast is a challenging problem since the LC behaviour is dominated by long-range spatial connections across multiple timescales. In this paper, we extend spatiotemporal predictive learning, showing its effectiveness beyond video prediction, to a 4D model, i.e., a novel Physics-informed Tensor-train ConvLSTM (PITT-ConvLSTM) for temporal sequences of 3D geospatial data forecasting. Specifically, we propose 1) a novel 4D higher-order recurrent neural network with empirical orthogonal function analysis to capture the hidden uncorrelated patterns of each hierarchy, 2) a convolutional tensor-train decomposition to capture higher-order space-time correlations, and 3) to incorporate prior physic knowledge that is provided from domain experts by informing the learning in latent space. The advantage of our proposed method is clear: constrained by physical laws, it simultaneously learns good representations for frame dependencies (both short-term and long-term high-level dependency) and inter-hierarchical relations within each time frame. Experiments on geospatial data collected from the GoM demonstrate that PITT-ConvLSTM outperforms the state-of-the-art methods in forecasting the volumetric velocity of the LC and its eddies for a period of over one week.},
	urldate = {2021-02-17},
	journal = {arXiv:2008.01798 [cs, eess, stat]},
	author = {Huang, Yu and Tang, Yufei and Zhuang, Hanqi and VanZwieten, James and Cherubin, Laurent},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.01798},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@article{xie_tempogan_2017,
	title = {{tempoGAN}: {A} {Temporally} {Coherent}, {Volumetric} {GAN} for {Super}-resolution {Fluid} {Flow}},
	volume = {36},
	issn = {0730-0301, 1557-7368},
	shorttitle = {{tempoGAN}},
	url = {http://arxiv.org/abs/1801.09710},
	doi = {10.1145/3072959.3073643},
	abstract = {We propose a temporally coherent generative model addressing the super-resolution problem for fluid flows. Our work represents a first approach to synthesize four-dimensional physics fields with neural networks. Based on a conditional generative adversarial network that is designed for the inference of three-dimensional volumetric data, our model generates consistent and detailed results by using a novel temporal discriminator, in addition to the commonly used spatial one. Our experiments show that the generator is able to infer more realistic high-resolution details by using additional physical quantities, such as low-resolution velocities or vorticities. Besides improvements in the training process and in the generated outputs, these inputs offer means for artistic control as well. We additionally employ a physics-aware data augmentation step, which is crucial to avoid overfitting and to reduce memory requirements. In this way, our network learns to generate advected quantities with highly detailed, realistic, and temporally coherent features. Our method works instantaneously, using only a single time-step of low-resolution fluid data. We demonstrate the abilities of our method using a variety of complex inputs and applications in two and three dimensions.},
	number = {4},
	urldate = {2021-02-17},
	journal = {ACM Transactions on Graphics},
	author = {Xie, You and Franz, Erik and Chu, Mengyu and Thuerey, Nils},
	month = jul,
	year = {2017},
	note = {arXiv: 1801.09710},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning},
	pages = {1--14},
}

@article{chu_learning_2020,
	title = {Learning {Temporal} {Coherence} via {Self}-{Supervision} for {GAN}-based {Video} {Generation}},
	volume = {39},
	issn = {0730-0301, 1557-7368},
	url = {http://arxiv.org/abs/1811.09393},
	doi = {10.1145/3386569.3392457},
	abstract = {Our work explores temporal self-supervision for GAN-based video generation tasks. While adversarial training successfully yields generative models for a variety of areas, temporal relationships in the generated data are much less explored. Natural temporal changes are crucial for sequential generation tasks, e.g. video super-resolution and unpaired video translation. For the former, state-of-the-art methods often favor simpler norm losses such as \$L{\textasciicircum}2\$ over adversarial training. However, their averaging nature easily leads to temporally smooth results with an undesirable lack of spatial detail. For unpaired video translation, existing approaches modify the generator networks to form spatio-temporal cycle consistencies. In contrast, we focus on improving learning objectives and propose a temporally self-supervised algorithm. For both tasks, we show that temporal adversarial learning is key to achieving temporally coherent solutions without sacrificing spatial detail. We also propose a novel Ping-Pong loss to improve the long-term temporal consistency. It effectively prevents recurrent networks from accumulating artifacts temporally without depressing detailed features. Additionally, we propose a first set of metrics to quantitatively evaluate the accuracy as well as the perceptual quality of the temporal evolution. A series of user studies confirm the rankings computed with these metrics. Code, data, models, and results are provided at https://github.com/thunil/TecoGAN. The project page https://ge.in.tum.de/publications/2019-tecogan-chu/ contains supplemental materials.},
	language = {en},
	number = {4},
	urldate = {2021-02-16},
	journal = {ACM Transactions on Graphics},
	author = {Chu, Mengyu and Xie, You and Mayer, Jonas and Leal-Taixé, Laura and Thuerey, Nils},
	month = jul,
	year = {2020},
	note = {arXiv: 1811.09393},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{liu_learning-based_2021,
	title = {A learning-based multiscale method and its application to inelastic impact problems},
	url = {http://arxiv.org/abs/2102.07256},
	abstract = {The macroscopic properties of materials that we observe and exploit in engineering application result from complex interactions between physics at multiple length and time scales: electronic, atomistic, defects, domains etc. Multiscale modeling seeks to understand these interactions by exploiting the inherent hierarchy where the behavior at a coarser scale regulates and averages the behavior at a finer scale. This requires the repeated solution of computationally expensive finer-scale models, and often a priori knowledge of those aspects of the finer-scale behavior that affect the coarser scale (order parameters, state variables, descriptors, etc.). We address this challenge in a two-scale setting where we learn the fine-scale behavior from off-line calculations and then use the learnt behavior directly in coarse scale calculations. The approach draws from recent successes of deep neural networks, in combination with ideas from model reduction. The approach builds on the recent success of deep neural networks by combining their approximation power in high dimensions with ideas from model reduction. It results in a neural network approximation that has high fidelity, is computationally inexpensive, is independent of the need for a priori knowledge, and can be used directly in the coarse scale calculations. We demonstrate the approach on problems involving the impact of magnesium, a promising light-weight structural and protective material.},
	urldate = {2021-02-16},
	journal = {arXiv:2102.07256 [cond-mat]},
	author = {Liu, Burigede and Kovachki, Nikola and Li, Zongyi and Azizzadenesheli, Kamyar and Anandkumar, Anima and Stuart, Andrew and Bhattacharya, Kaushik},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.07256},
	keywords = {Condensed Matter - Materials Science},
}

@article{huang_physics-informed_2020-1,
	title = {Physics-informed {Tensor}-train {ConvLSTM} for {Volumetric} {Velocity} {Forecasting}},
	url = {http://arxiv.org/abs/2008.01798},
	abstract = {According to the National Academies, a weekly forecast of velocity, vertical structure, and duration of the Loop Current (LC) and its eddies is critical for understanding the oceanography and ecosystem, and for mitigating outcomes of anthropogenic and natural disasters in the Gulf of Mexico (GoM). However, this forecast is a challenging problem since the LC behaviour is dominated by long-range spatial connections across multiple timescales. In this paper, we extend spatiotemporal predictive learning, showing its effectiveness beyond video prediction, to a 4D model, i.e., a novel Physics-informed Tensor-train ConvLSTM (PITT-ConvLSTM) for temporal sequences of 3D geospatial data forecasting. Specifically, we propose 1) a novel 4D higher-order recurrent neural network with empirical orthogonal function analysis to capture the hidden uncorrelated patterns of each hierarchy, 2) a convolutional tensor-train decomposition to capture higher-order space-time correlations, and 3) to incorporate prior physic knowledge that is provided from domain experts by informing the learning in latent space. The advantage of our proposed method is clear: constrained by physical laws, it simultaneously learns good representations for frame dependencies (both short-term and long-term high-level dependency) and inter-hierarchical relations within each time frame. Experiments on geospatial data collected from the GoM demonstrate that PITT-ConvLSTM outperforms the state-of-the-art methods in forecasting the volumetric velocity of the LC and its eddies for a period of over one week.},
	urldate = {2021-02-15},
	journal = {arXiv:2008.01798 [cs, eess, stat]},
	author = {Huang, Yu and Tang, Yufei and Zhuang, Hanqi and VanZwieten, James and Cherubin, Laurent},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.01798},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@inproceedings{ummenhofer_lagrangian_2019,
	title = {Lagrangian {Fluid} {Simulation} with {Continuous} {Convolutions}},
	url = {https://openreview.net/forum?id=B1lDoJSYDH},
	abstract = {We learn particle-based fluid simulation with convolutional networks.},
	language = {en},
	urldate = {2021-02-12},
	author = {Ummenhofer, Benjamin and Prantl, Lukas and Thuerey, Nils and Koltun, Vladlen},
	month = sep,
	year = {2019},
}

@article{mukha_eddylicious_2018,
	title = {Eddylicious: {A} {Python} package for turbulent inflow generation},
	volume = {7},
	issn = {2352-7110},
	shorttitle = {Eddylicious},
	url = {https://www.sciencedirect.com/science/article/pii/S2352711018300487},
	doi = {10.1016/j.softx.2018.04.001},
	abstract = {A Python package for generating inflow for scale-resolving computer simulations of turbulent flow is presented. The purpose of the package is to unite existing inflow generation methods in a single code-base and make them accessible to users of various Computational Fluid Dynamics (CFD) solvers. The currently existing functionality consists of an accurate inflow generation method suitable for flows with a turbulent boundary layer inflow and input/output routines for coupling with the open-source CFD solver OpenFOAM.},
	language = {en},
	urldate = {2021-02-12},
	journal = {SoftwareX},
	author = {Mukha, Timofey and Liefvendahl, Mattias},
	month = jan,
	year = {2018},
	keywords = {Boundary conditions, CFD, Inflow generation, Turbulence},
	pages = {112--114},
}

@article{novati_automating_2020,
	title = {Automating {Turbulence} {Modeling} by {Multi}-{Agent} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2005.09023},
	abstract = {The modeling of turbulent flows is critical to scientific and engineering problems ranging from aircraft design to weather forecasting and climate prediction. Over the last sixty years numerous turbulence models have been proposed, largely based on physical insight and engineering intuition. Recent advances in machine learning and data science have incited new efforts to complement these approaches. To date, all such efforts have focused on supervised learning which, despite demonstrated promise, encounters difficulties in generalizing beyond the distributions of the training data. In this work we introduce multi-agent reinforcement learning (MARL) as an automated discovery tool of turbulence models. We demonstrate the potential of this approach on Large Eddy Simulations of homogeneous and isotropic turbulence using as reward the recovery of the statistical properties of Direct Numerical Simulations. Here, the closure model is formulated as a control policy enacted by cooperating agents, which detect critical spatio-temporal patterns in the flow field to estimate the unresolved sub-grid scale (SGS) physics. The present results are obtained with state-of-the-art algorithms based on experience replay and compare favorably with established dynamic SGS modeling approaches. Moreover, we show that the present turbulence models generalize across grid sizes and flow conditions as expressed by the Reynolds numbers.},
	urldate = {2021-02-12},
	journal = {arXiv:2005.09023 [physics]},
	author = {Novati, Guido and de Laroussilhe, Hugues Lascombes and Koumoutsakos, Petros},
	month = oct,
	year = {2020},
	note = {arXiv: 2005.09023},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{novati_automating_2021,
	title = {Automating turbulence modelling by multi-agent reinforcement learning},
	volume = {3},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-020-00272-0},
	doi = {10.1038/s42256-020-00272-0},
	abstract = {Turbulent flow models are critical for applications such as aircraft design, weather forecasting and climate prediction. Existing models are largely based on physical insight and engineering intuition. More recently, machine learning has been contributing to this endeavour with promising results. However, all efforts have focused on supervised learning, which is difficult to generalize beyond training data. Here we introduce multi-agent reinforcement learning as an automated discovery tool of turbulence models. We demonstrate the potential of this approach on large-eddy simulations of isotropic turbulence, using the recovery of statistical properties of direct numerical simulations as a reward. The closure model is a control policy enacted by cooperating agents, which detect critical spatio-temporal patterns in the flow field to estimate the unresolved subgrid-scale physics. Results obtained with multi-agent reinforcement learning algorithms based on experience replay compare favourably with established modelling approaches. Moreover, we show that the learned turbulence models generalize across grid sizes and flow conditions.},
	language = {en},
	number = {1},
	urldate = {2021-02-12},
	journal = {Nature Machine Intelligence},
	author = {Novati, Guido and de Laroussilhe, Hugues Lascombes and Koumoutsakos, Petros},
	month = jan,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {87--96},
}

@article{rahaman_spectral_2019,
	title = {On the {Spectral} {Bias} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/1806.08734},
	abstract = {Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with \$100{\textbackslash}\%\$ accuracy. In this work, we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we show that deep ReLU networks are biased towards low frequency functions, meaning that they cannot have local fluctuations without affecting their global behavior. Intuitively, this property is in line with the observation that over-parameterized networks find simple patterns that generalize across data samples. We also investigate how the shape of the data manifold affects expressivity by showing evidence that learning high frequencies gets {\textbackslash}emph\{easier\} with increasing manifold complexity, and present a theoretical understanding of this behavior. Finally, we study the robustness of the frequency components with respect to parameter perturbation, to develop the intuition that the parameters must be finely tuned to express high frequency functions.},
	urldate = {2021-02-12},
	journal = {arXiv:1806.08734 [cs, stat]},
	author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred A. and Bengio, Yoshua and Courville, Aaron},
	month = may,
	year = {2019},
	note = {arXiv: 1806.08734},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{al-aradi_applications_2020,
	title = {Applications of the {Deep} {Galerkin} {Method} to {Solving} {Partial} {Integro}-{Differential} and {Hamilton}-{Jacobi}-{Bellman} {Equations}},
	url = {http://arxiv.org/abs/1912.01455},
	abstract = {We extend the Deep Galerkin Method (DGM) introduced in Sirignano and Spiliopoulos (2018) to solve a number of partial differential equations (PDEs) that arise in the context of optimal stochastic control and mean field games. First, we consider PDEs where the function is constrained to be positive and integrate to unity, as is the case with Fokker-Planck equations. Our approach involves reparameterizing the solution as the exponential of a neural network appropriately normalized to ensure both requirements are satisfied. This then gives rise to a partial integro-differential equation (PIDE) where the integral appearing in the equation is handled using importance sampling. Secondly, we tackle a number of Hamilton-Jacobi-Bellman (HJB) equations that appear in stochastic optimal control problems. The key contribution is that these equations are approached in their unsimplified primal form which includes an optimization problem as part of the equation. We extend the DGM algorithm to solve for the value function and the optimal control simultaneously by characterizing both as deep neural networks. Training the networks is performed by taking alternating stochastic gradient descent steps for the two functions, a technique similar in spirit to policy improvement algorithms.},
	urldate = {2021-02-12},
	journal = {arXiv:1912.01455 [q-fin, stat]},
	author = {Al-Aradi, Ali and Correia, Adolfo and Naiff, Danilo de Frietas and Jardim, Gabriel and Saporito, Yuri},
	month = feb,
	year = {2020},
	note = {arXiv: 1912.01455},
	keywords = {Quantitative Finance - Computational Finance, Statistics - Machine Learning},
}

@article{sirignano_dgm_2018,
	title = {{DGM}: {A} deep learning algorithm for solving partial differential equations},
	volume = {375},
	issn = {00219991},
	shorttitle = {{DGM}},
	url = {http://arxiv.org/abs/1708.07469},
	doi = {10.1016/j.jcp.2018.08.029},
	abstract = {High-dimensional PDEs have been a longstanding computational challenge. We propose to solve high-dimensional PDEs by approximating the solution with a deep neural network which is trained to satisfy the differential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary PDEs, which we are able to accurately solve in up to \$200\$ dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE and Burgers' equation. The deep learning algorithm approximates the general solution to the Burgers' equation for a continuum of different boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a "Deep Galerkin Method (DGM)" since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic PDEs.},
	urldate = {2021-02-12},
	journal = {Journal of Computational Physics},
	author = {Sirignano, Justin and Spiliopoulos, Konstantinos},
	month = dec,
	year = {2018},
	note = {arXiv: 1708.07469},
	keywords = {Mathematics - Numerical Analysis, Quantitative Finance - Computational Finance, Quantitative Finance - Mathematical Finance, Statistics - Machine Learning},
	pages = {1339--1364},
}

@article{patruno_generation_2017,
	title = {On the generation of synthetic divergence-free homogeneous anisotropic turbulence},
	volume = {315},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782516308581},
	doi = {10.1016/j.cma.2016.11.005},
	abstract = {It is well known that the generation of appropriate unsteady boundary conditions represents an important component of successful Large Eddy Simulations in turbulent flows. In particular, when Computational Wind Engineering applications are considered, a recurrent problem consists in imposing turbulent fluctuations characterized by given spectra and length scales at the inlet boundary. In the present contribution, firstly, currently available techniques for the generation of synthetic turbulence are revised with a focus on their mathematical formulation. Then, two new approaches for the generation of homogeneous turbulence are proposed. The first one can be seen as a correction over existing techniques which allows to control the obtained length scales. The second method, conceived to generate anisotropic turbulence characterized by arbitrary harmonic content in both time and space, is designed to be computationally efficient, to guarantee the divergence-free condition and to ensure a good approximation of the resulting turbulence integral scales. Finally, the procedure is validated by synthesizing a homogeneous turbulent field characterized by time and length scales typical of the atmospheric boundary layer showing good results.},
	language = {en},
	urldate = {2021-02-11},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Patruno, L. and Ricci, M.},
	month = mar,
	year = {2017},
	keywords = {Inflow conditions, LES, Random fields, Synthetic turbulence},
	pages = {396--417},
}

@article{yu_fully_2014,
	title = {A fully divergence-free method for generation of inhomogeneous and anisotropic turbulence with large spatial variation},
	volume = {256},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999113005998},
	doi = {10.1016/j.jcp.2013.08.055},
	abstract = {A fully divergence-free method is proposed for generation of inhomogeneous/anisotropic turbulence with large spatial variation. The method is based on the method of Smirnov et al., which is known to violate the divergence-free constraint when spatial variation of turbulence is present. In the proposed method a vector potential field is introduced; by taking the vector curl of the potential field one can generate a strictly divergence-free flow field. A novel formulation for scaling the vector potential field, together with a coordinate transformation strategy, is proposed in this work. The result is a six-step procedure for the generation of inhomogeneous turbulence fields. The proposed formulation is proven to reproduce the prescribed velocity correlation with energy spectrum at large Reynolds numbers. Four test cases are considered to evaluate the new method. First, the statistical quantities introduced in the proposed method are verified numerically in a classical homogeneous turbulence case. Then, the performance of the new method is demonstrated in three different inhomogeneous turbulence cases: a confined turbulent flow in a “slip-wall” box, a planar channel flow and an annular flow. It is shown that the unphysical patterns in the fluctuation fields and divergence errors produced with Smirnovʼs method are absent in the results from the new method. The accuracy of the proposed methods is verified by comparing the velocity correlations with the prescribed scaling functions. The proposed method is efficient and simple to implement.},
	language = {en},
	urldate = {2021-02-11},
	journal = {Journal of Computational Physics},
	author = {Yu, Rixin and Bai, Xue-Song},
	month = jan,
	year = {2014},
	keywords = {DNS, Divergence-free, Inflow generation method, Inhomogeneous and anisotropic turbulence, LES, Large spatial variation},
	pages = {234--253},
}

@article{lund_generation_1998,
	title = {Generation of {Turbulent} {Inflow} {Data} for {Spatially}-{Developing} {Boundary} {Layer} {Simulations}},
	volume = {140},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S002199919895882X},
	doi = {10.1006/jcph.1998.5882},
	abstract = {A method for generating three-dimensional, time-dependent turbulent inflow data for simulations of complex spatially developing boundary layers is described. The approach is to extract instantaneous planes of velocity data from an auxiliary simulation of a zero pressure gradient boundary layer. The auxiliary simulation is also spatially developing, but generates its own inflow conditions through a sequence of operations where the velocity field at a downstream station is rescaled and re-introduced at the inlet. This procedure is essentially a variant of the Spalart method, optimized so that an existing inflow–outflow code can be converted to an inflow-generation device through the addition of one simple subroutine. The proposed method is shown to produce a realistic turbulent boundary layer which yields statistics that are in good agreement with both experimental data and results from direct simulations. The method is used to provide inflow conditions for a large eddy simulation (LES) of a spatially evolving boundary layer spanning a momentum thickness Reynolds number interval of 1530–2150. The results from the LES calculation are compared with those from other simulations that make use of more approximate inflow conditions. When compared with the approximate inflow generation techniques, the proposed method is shown to be highly accurate, with little or no adjustment of the solution near the inlet boundary. In contrast, the other methods surveyed produce a transient near the inlet that persists several boundary layer thicknesses downstream. Lack of a transient when using the proposed method is significant since the adverse effects of inflow errors are typically minimized through a costly upstream elongation of the mesh. Extension of the method for non-zero pressure gradients is also discussed.},
	language = {en},
	number = {2},
	urldate = {2021-02-11},
	journal = {Journal of Computational Physics},
	author = {Lund, Thomas S. and Wu, Xiaohua and Squires, Kyle D.},
	month = mar,
	year = {1998},
	pages = {233--258},
}

@article{sitzmann_implicit_2020,
	title = {Implicit {Neural} {Representations} with {Periodic} {Activation} {Functions}},
	url = {http://arxiv.org/abs/2006.09661},
	abstract = {Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or Sirens, are ideally suited for representing complex natural signals and their derivatives. We analyze Siren activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how Sirens can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine Sirens with hypernetworks to learn priors over the space of Siren functions.},
	urldate = {2021-02-11},
	journal = {arXiv:2006.09661 [cs, eess]},
	author = {Sitzmann, Vincent and Martel, Julien N. P. and Bergman, Alexander W. and Lindell, David B. and Wetzstein, Gordon},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.09661},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{tancik_fourier_2020,
	title = {Fourier {Features} {Let} {Networks} {Learn} {High} {Frequency} {Functions} in {Low} {Dimensional} {Domains}},
	url = {http://arxiv.org/abs/2006.10739},
	abstract = {We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.},
	urldate = {2021-02-11},
	journal = {arXiv:2006.10739 [cs]},
	author = {Tancik, Matthew and Srinivasan, Pratul P. and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan T. and Ng, Ren},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.10739},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{hennigh_nvidia_2020,
	title = {{NVIDIA} {SimNet}{\textasciicircum}\{{TM}\}: an {AI}-accelerated multi-physics simulation framework},
	shorttitle = {{NVIDIA} {SimNet}{\textasciicircum}\{{TM}\}},
	url = {http://arxiv.org/abs/2012.07938},
	abstract = {We present SimNet, an AI-driven multi-physics simulation framework, to accelerate simulations across a wide range of disciplines in science and engineering. Compared to traditional numerical solvers, SimNet addresses a wide range of use cases - coupled forward simulations without any training data, inverse and data assimilation problems. SimNet offers fast turnaround time by enabling parameterized system representation that solves for multiple configurations simultaneously, as opposed to the traditional solvers that solve for one configuration at a time. SimNet is integrated with parameterized constructive solid geometry as well as STL modules to generate point clouds. Furthermore, it is customizable with APIs that enable user extensions to geometry, physics and network architecture. It has advanced network architectures that are optimized for high-performance GPU computing, and offers scalable performance for multi-GPU and multi-Node implementation with accelerated linear algebra as well as FP32, FP64 and TF32 computations. In this paper we review the neural network solver methodology, the SimNet architecture, and the various features that are needed for effective solution of the PDEs. We present real-world use cases that range from challenging forward multi-physics simulations with turbulence and complex 3D geometries, to industrial design optimization and inverse problems that are not addressed efficiently by the traditional solvers. Extensive comparisons of SimNet results with open source and commercial solvers show good correlation.},
	urldate = {2021-02-10},
	journal = {arXiv:2012.07938 [physics]},
	author = {Hennigh, Oliver and Narasimhan, Susheela and Nabian, Mohammad Amin and Subramaniam, Akshay and Tangsali, Kaustubh and Rietmann, Max and Ferrandis, Jose del Aguila and Byeon, Wonmin and Fang, Zhiwei and Choudhry, Sanjay},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.07938},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@article{kochkov_machine_2021,
	title = {Machine learning accelerated computational fluid dynamics},
	url = {http://arxiv.org/abs/2102.01010},
	abstract = {Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics and plasma physics. Fluids are well described by the Navier-Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large eddy simulation, our results are as accurate as baseline solvers with 8-10x finer resolution in each spatial dimension, resulting in 40-80x fold computational speedups. Our method remains stable during long simulations, and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black box machine learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization.},
	urldate = {2021-02-02},
	journal = {arXiv:2102.01010 [physics]},
	author = {Kochkov, Dmitrii and Smith, Jamie A. and Alieva, Ayya and Wang, Qing and Brenner, Michael P. and Hoyer, Stephan},
	month = jan,
	year = {2021},
	note = {arXiv: 2102.01010},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
}

@article{qian_reduced_2021,
	title = {Reduced operator inference for nonlinear partial differential equations},
	url = {http://arxiv.org/abs/2102.00083},
	abstract = {We present a new scientific machine learning method that learns from data a computationally inexpensive surrogate model for predicting the evolution of a system governed by a time-dependent nonlinear partial differential equation (PDE), an enabling technology for many computational algorithms used in engineering settings. Our formulation generalizes to the PDE setting the Operator Inference method previously developed in [B. Peherstorfer and K. Willcox, Data-driven operator inference for non-intrusive projection-based model reduction, Computer Methods in Applied Mechanics and Engineering, 306 (2016)] for systems governed by ordinary differential equations. The method brings together two main elements. First, ideas from projection-based model reduction are used to explicitly parametrize the learned model by low-dimensional polynomial operators which reflect the known form of the governing PDE. Second, supervised machine learning tools are used to infer from data the reduced operators of this physics-informed parametrization. For systems whose governing PDEs contain more general (non-polynomial) nonlinearities, the learned model performance can be improved through the use of lifting variable transformations, which expose polynomial structure in the PDE. The proposed method is demonstrated on a three-dimensional combustion simulation with over 18 million degrees of freedom, for which the learned reduced models achieve accurate predictions with a dimension reduction of six orders of magnitude and model runtime reduction of 5-6 orders of magnitude.},
	urldate = {2021-02-02},
	journal = {arXiv:2102.00083 [cs, math]},
	author = {Qian, Elizabeth and Farcas, Ionut-Gabriel and Willcox, Karen},
	month = jan,
	year = {2021},
	note = {arXiv: 2102.00083},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{hamba_turbulent_2018,
	title = {Turbulent energy density in scale space for inhomogeneous turbulence},
	volume = {842},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/turbulent-energy-density-in-scale-space-for-inhomogeneous-turbulence/A1F9D2CF5D43476743349CC429EB2D0F},
	doi = {10.1017/jfm.2018.155},
	abstract = {The energy spectrum is commonly used to describe the scale dependence of the turbulent fluctuations in homogeneous isotropic turbulence. In contrast, one-point statistical quantities, such as the turbulent kinetic energy, are employed for inhomogeneous turbulence modelling. To obtain a better understanding of inhomogeneous turbulence, some attempts have been made to describe its scale dependence by using the second-order structure function and the two-point velocity correlation. However, previous expressions for the energy density in the scale space do not satisfy the requirement that it should be non-negative. In this work, a new expression for the energy density in the scale space is proposed on the basis of the two-point velocity correlation; the integral with a filter function is introduced to satisfy the non-negativity of the energy density. Direct numerical simulation (DNS) data of homogeneous isotropic turbulence were first used to assess the role of the energy density by comparing it with the energy spectrum. DNS data of a turbulent channel flow were then used to investigate the energy density and its transport equation in inhomogeneous turbulence. It was shown that the new energy density is positive in the scale space of the homogeneous direction. The energy transfer was successfully examined in the scale space both in the homogeneous and inhomogeneous directions. The energy cascade from large to small scales was clearly observed. Moreover, the inverse energy cascade from large to very large scales was observed in the scale space of the spanwise direction.},
	language = {en},
	urldate = {2021-02-01},
	journal = {Journal of Fluid Mechanics},
	author = {Hamba, Fujihiro},
	month = may,
	year = {2018},
	note = {Publisher: Cambridge University Press},
	keywords = {isotropic turbulence, shear layer turbulence, turbulence simulation},
	pages = {532--553},
}

@article{saffman_model_1970,
	title = {A {Model} for {Inhomogeneous} {Turbulent} {Flow}},
	volume = {317},
	issn = {0080-4630},
	url = {https://www.jstor.org/stable/77591},
	abstract = {A set of model equations is given to describe the gross features of a statistically steady or 'slowly varying' inhomogeneous field of turbulence and the mean velocity distribution. The equations are based on the idea that turbulence can be characterized by 'densities' which obey nonlinear diffusion equations. The diffusion equations contain terms to describe the convection by the mean flow, the amplification due to interaction with a mean velocity gradient, the dissipation due to the interaction of the turbulence with itself, and the diffusion also due to the self interaction. The equations are similar to a set proposed by Kolmogorov (1942). It is assumed that both an 'energy density' and a 'vorticity density' satisfy diffusion equations, and that the self diffusion is described by an eddy viscosity which is a function of the energy and vorticity densities; the eddy viscosity is also assumed to describe the diffusion of mean momentum by the turbulent fluctuations. It is shown that with simple and plausible assumptions about the nature of the interaction terms, the equations form a closed set. The appropriate boundary conditions at a solid wall and a turbulent interface, with and without entrainment, are discussed. It is shown that the dimensionless constants which appear in the equations can all be estimated by general arguments. The equations are then found to predict the von Kármán constant in the law of the wall with reasonable accuracy. An analytical solution is given for Couette flow, and the result of a numerical study of plane Poiseuille flow is described. The equations are also applied to free turbulent flows. It is shown that the model equations completely determine the structure of the similarity solutions, with the rate of spread, for instance, determined by the solution of a nonlinear eigenvalue problem. Numerical solutions have been obtained for the two-dimensional wake and jet. The agreement with experiment is good. The solutions have a sharp interface between turbulent and non-turbulent regions and the mean velocity in the turbulent part varies linearly with distance from the interface. The equations are applied qualitatively to the accelerating boundary layer in flow towards a line sink, and the decelerating boundary layer with zero skin friction. In the latter case, the equations predict that the mean velocity should vary near the wall like the 5/3 power of the distance. It is shown that viscosity can be incorporated formally into the model equations and that a structure can be given to the interface between turbulent and non-turbulent parts of the flow.},
	number = {1530},
	urldate = {2021-02-01},
	journal = {Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences},
	author = {Saffman, P. G.},
	year = {1970},
	note = {Publisher: The Royal Society},
	pages = {417--433},
}

@article{van_slooten_pdf_1997,
	title = {{PDF} modeling for inhomogeneous turbulence with exact representation of rapid distortions},
	volume = {9},
	issn = {1070-6631, 1089-7666},
	url = {http://aip.scitation.org/doi/10.1063/1.869195},
	doi = {10.1063/1.869195},
	language = {en},
	number = {4},
	urldate = {2021-02-01},
	journal = {Physics of Fluids},
	author = {Van Slooten, P. R. and Pope, S. B.},
	month = apr,
	year = {1997},
	pages = {1085--1105},
}

@article{pfau_ab_2020,
	title = {Ab initio solution of the many-electron {Schr}{\textbackslash}"odinger equation with deep neural networks},
	volume = {2},
	url = {https://link.aps.org/doi/10.1103/PhysRevResearch.2.033429},
	doi = {10.1103/PhysRevResearch.2.033429},
	abstract = {Given access to accurate solutions of the many-electron Schrödinger equation, nearly all chemistry could be derived from first principles. Exact wave functions of interesting chemical systems are out of reach because they are NP-hard to compute in general, but approximations can be found using polynomially scaling algorithms. The key challenge for many of these algorithms is the choice of wave function approximation, or Ansatz, which must trade off between efficiency and accuracy. Neural networks have shown impressive power as accurate practical function approximators and promise as a compact wave-function Ansatz for spin systems, but problems in electronic structure require wave functions that obey Fermi-Dirac statistics. Here we introduce a novel deep learning architecture, the Fermionic neural network, as a powerful wave-function Ansatz for many-electron systems. The Fermionic neural network is able to achieve accuracy beyond other variational quantum Monte Carlo Ansatz on a variety of atoms and small molecules. Using no data other than atomic positions and charges, we predict the dissociation curves of the nitrogen molecule and hydrogen chain, two challenging strongly correlated systems, to significantly higher accuracy than the coupled cluster method, widely considered the most accurate scalable method for quantum chemistry at equilibrium geometry. This demonstrates that deep neural networks can improve the accuracy of variational quantum Monte Carlo to the point where it outperforms other ab initio quantum chemistry methods, opening the possibility of accurate direct optimization of wave functions for previously intractable many-electron systems.},
	number = {3},
	urldate = {2021-02-01},
	journal = {Physical Review Research},
	author = {Pfau, David and Spencer, James S. and Matthews, Alexander G. D. G. and Foulkes, W. M. C.},
	month = sep,
	year = {2020},
	note = {Publisher: American Physical Society},
	pages = {033429},
}

@incollection{richards_fast_nodate,
	title = {A {Fast} {Turbulence} {Generator} using {Graphics} {Processing} {Units}},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2018-3559},
	urldate = {2021-02-01},
	booktitle = {2018 {Fluid} {Dynamics} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Richards, Austin and Saad, Tony and Sutherland, James C.},
	doi = {10.2514/6.2018-3559},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2018-3559},
}

@article{saad_scalable_2016,
	title = {Scalable {Tools} for {Generating} {Synthetic} {Isotropic} {Turbulence} with {Arbitrary} {Spectra}},
	volume = {55},
	issn = {0001-1452},
	url = {https://arc.aiaa.org/doi/10.2514/1.J055230},
	doi = {10.2514/1.J055230},
	number = {1},
	urldate = {2021-02-01},
	journal = {AIAA Journal},
	author = {Saad, Tony and Cline, Derek and Stoll, Rob and Sutherland, James C.},
	month = aug,
	year = {2016},
	note = {Publisher: American Institute of Aeronautics and Astronautics},
	pages = {327--331},
}

@article{kornev_synthesis_2007,
	title = {Synthesis of homogeneous anisotropic divergence-free turbulent fields with prescribed second-order statistics by vortex dipoles},
	volume = {19},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.2738607},
	doi = {10.1063/1.2738607},
	abstract = {This Communication presents a mathematical procedure for generation of turbulent velocity fields with prescribed shell-summed energy spectra. The velocity field is represented as the sum of velocities induced by a set of randomly distributed vortex dipoles (vortons). Closed-form analytical solutions are found for the inner structure of the vortons from the condition that the shell-summed energy spectrum of the synthesizing field is equal to the prescribed one. The proposed procedure is applied to turbulent fields with the spectrum of the decaying turbulence and the typical velocity energy spectrum of homogeneous turbulence. The solution for decaying turbulence is the exact analytical solution of the Navier-Stokes equation for the turbulent field in the final stage of the decay.},
	number = {6},
	urldate = {2021-01-29},
	journal = {Physics of Fluids},
	author = {Kornev, Nikolai and Hassel, Egon},
	month = jun,
	year = {2007},
	note = {Publisher: American Institute of Physics},
	pages = {068101},
}

@article{jarrin_synthetic-eddy-method_2006,
	series = {Special {Issue} of {The} {Fourth} {International} {Symposium} on {Turbulence} and {Shear} {Flow} {Phenomena} - 2005},
	title = {A synthetic-eddy-method for generating inflow conditions for large-eddy simulations},
	volume = {27},
	issn = {0142-727X},
	url = {http://www.sciencedirect.com/science/article/pii/S0142727X06000282},
	doi = {10.1016/j.ijheatfluidflow.2006.02.006},
	abstract = {The generation of inflow data for spatially developing turbulent flows is one of the challenges that must be addressed prior to the application of LES to industrial flows and complex geometries. A new method of generation of synthetic turbulence, suitable for complex geometries and unstructured meshes, is presented herein. The method is based on the classical view of turbulence as a superposition of coherent structures. It is able to reproduce prescribed first and second order one point statistics, characteristic length and time scales, and the shape of coherent structures. The ability of the method to produce realistic inflow conditions in the test cases of a spatially decaying homogeneous isotropic turbulence and of a fully developed turbulent channel flow is presented. The method is systematically compared to other methods of generation of inflow conditions (precursor simulation, spectral methods and algebraic methods).},
	language = {en},
	number = {4},
	urldate = {2021-01-29},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Jarrin, N. and Benhamadouche, S. and Laurence, D. and Prosser, R.},
	month = aug,
	year = {2006},
	keywords = {Channel flow, Inflow boundary conditions, Large-eddy simulation, Spatially decaying isotropic turbulence, Synthetic turbulence},
	pages = {585--593},
}

@article{lensink_fully_2020,
	title = {Fully {Hyperbolic} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1905.10484},
	abstract = {Convolutional Neural Networks (CNN) have recently seen tremendous success in various computer vision tasks. However, their application to problems with high dimensional input and output, such as high-resolution image and video segmentation or 3D medical imaging, has been limited by various factors. Primarily, in the training stage, it is necessary to store network activations for back propagation. In these settings, the memory requirements associated with storing activations can exceed what is feasible with current hardware, especially for problems in 3D. Motivated by the propagation of signals over physical networks, that are governed by the hyperbolic Telegraph equation, in this work we introduce a fully conservative hyperbolic network for problems with high dimensional input and output. We introduce a coarsening operation that allows completely reversible CNNs by using a learnable Discrete Wavelet Transform and its inverse to both coarsen and interpolate the network state and change the number of channels. We show that fully reversible networks are able to achieve results comparable to the state of the art in 4D time-lapse hyper spectral image segmentation and full 3D video segmentation, with a much lower memory footprint that is a constant independent of the network depth. We also extend the use of such networks to Variational Auto Encoders with high resolution input and output.},
	urldate = {2021-01-29},
	journal = {arXiv:1905.10484 [cs]},
	author = {Lensink, Keegan and Peters, Bas and Haber, Eldad},
	month = jul,
	year = {2020},
	note = {arXiv: 1905.10484},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{chen_residual_2020,
	title = {Residual {Flows} for {Invertible} {Generative} {Modeling}},
	url = {http://arxiv.org/abs/1906.02735},
	abstract = {Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network's expressiveness. We give a tractable unbiased estimate of the log density using a "Russian roulette" estimator, and reduce the memory required during training by using an alternative infinite series for the gradient. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid derivative saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.},
	urldate = {2021-01-29},
	journal = {arXiv:1906.02735 [cs, stat]},
	author = {Chen, Ricky T. Q. and Behrmann, Jens and Duvenaud, David and Jacobsen, Jörn-Henrik},
	month = jul,
	year = {2020},
	note = {arXiv: 1906.02735},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{chen_neural_nodate,
	title = {Neural {Ordinary} {Differential} {Equations}},
	abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing ﬂows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
	language = {en},
	author = {Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
	pages = {13},
}

@article{chen_residual_2020-1,
	title = {Residual {Flows} for {Invertible} {Generative} {Modeling}},
	url = {http://arxiv.org/abs/1906.02735},
	abstract = {Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network's expressiveness. We give a tractable unbiased estimate of the log density using a "Russian roulette" estimator, and reduce the memory required during training by using an alternative infinite series for the gradient. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid derivative saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.},
	urldate = {2021-01-29},
	journal = {arXiv:1906.02735 [cs, stat]},
	author = {Chen, Ricky T. Q. and Behrmann, Jens and Duvenaud, David and Jacobsen, Jörn-Henrik},
	month = jul,
	year = {2020},
	note = {arXiv: 1906.02735},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wandel_learning_2020,
	title = {Learning {Incompressible} {Fluid} {Dynamics} from {Scratch} -- {Towards} {Fast}, {Differentiable} {Fluid} {Models} that {Generalize}},
	url = {http://arxiv.org/abs/2006.08762},
	abstract = {Fast and stable fluid simulations are an essential prerequisite for applications ranging from computer-generated imagery to computer-aided design in research and development. However, solving the partial differential equations of incompressible fluids is a challenging task and traditional numerical approximation schemes come at high computational costs. Recent deep learning based approaches promise vast speed-ups but do not generalize to new fluid domains, require fluid simulation data for training, or rely on complex pipelines that outsource major parts of the fluid simulation to traditional methods. In this work, we propose a novel physics-constrained training approach that generalizes to new fluid domains, requires no fluid simulation data, and allows convolutional neural networks to map a fluid state from time-point t to a subsequent state at time t + dt in a single forward pass. This simplifies the pipeline to train and evaluate neural fluid models. After training, the framework yields models that are capable of fast fluid simulations and can handle various fluid phenomena including the Magnus effect and Karman vortex streets. We present an interactive real-time demo to show the speed and generalization capabilities of our trained models. Moreover, the trained neural networks are efficient differentiable fluid solvers as they offer a differentiable update step to advance the fluid simulation in time. We exploit this fact in a proof-of-concept optimal control experiment. Our models significantly outperform a recent differentiable fluid solver in terms of computational speed and accuracy.},
	urldate = {2021-01-27},
	journal = {arXiv:2006.08762 [cs, stat]},
	author = {Wandel, Nils and Weinmann, Michael and Klein, Reinhard},
	month = dec,
	year = {2020},
	note = {arXiv: 2006.08762},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{dwivedi_generalization_2021,
	title = {A {Generalization} of {Transformer} {Networks} to {Graphs}},
	url = {http://arxiv.org/abs/2012.09699},
	abstract = {We propose a generalization of transformer neural network architecture for arbitrary graphs. The original transformer was designed for Natural Language Processing (NLP), which operates on fully connected graphs representing all connections between the words in a sequence. Such architecture does not leverage the graph connectivity inductive bias, and can perform poorly when the graph topology is important and has not been encoded into the node features. We introduce a graph transformer with four new properties compared to the standard model. First, the attention mechanism is a function of the neighborhood connectivity for each node in the graph. Second, the positional encoding is represented by the Laplacian eigenvectors, which naturally generalize the sinusoidal positional encodings often used in NLP. Third, the layer normalization is replaced by a batch normalization layer, which provides faster training and better generalization performance. Finally, the architecture is extended to edge feature representation, which can be critical to tasks s.a. chemistry (bond type) or link prediction (entity relationship in knowledge graphs). Numerical experiments on a graph benchmark demonstrate the performance of the proposed graph transformer architecture. This work closes the gap between the original transformer, which was designed for the limited case of line graphs, and graph neural networks, that can work with arbitrary graphs. As our architecture is simple and generic, we believe it can be used as a black box for future applications that wish to consider transformer and graphs.},
	urldate = {2021-01-27},
	journal = {arXiv:2012.09699 [cs]},
	author = {Dwivedi, Vijay Prakash and Bresson, Xavier},
	month = jan,
	year = {2021},
	note = {arXiv: 2012.09699},
	keywords = {Computer Science - Machine Learning},
}

@misc{noauthor_improving_2018,
	title = {Improving {Language} {Understanding} with {Unsupervised} {Learning}},
	url = {https://openai.com/blog/language-unsupervised/},
	abstract = {We've obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we're also releasing. Our approach is a combination of two existing ideas: transformers and unsupervised pre-training.},
	language = {en},
	urldate = {2021-01-27},
	journal = {OpenAI},
	month = jun,
	year = {2018},
}

@article{radford_improving_nodate,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	language = {en},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	pages = {12},
}

@misc{noauthor_amp_nodate,
	title = {{AMP} tutorial},
	url = {https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/},
	urldate = {2021-01-27},
}

@article{radford_language_nodate,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	language = {en},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	pages = {24},
}

@article{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
	urldate = {2021-01-26},
	journal = {arXiv:2005.14165 [cs]},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	note = {arXiv: 2005.14165},
	keywords = {Computer Science - Computation and Language},
}

@article{zdeborova_understanding_2020,
	title = {Understanding deep learning is also a job for physicists},
	volume = {16},
	copyright = {2020 Springer Nature Limited},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/s41567-020-0929-2},
	doi = {10.1038/s41567-020-0929-2},
	abstract = {Automated learning from data by means of deep neural networks is finding use in an ever-increasing number of applications, yet key theoretical questions about how it works remain unanswered. A physics-based approach may help to bridge this gap.},
	language = {en},
	number = {6},
	urldate = {2021-01-26},
	journal = {Nature Physics},
	author = {Zdeborová, Lenka},
	month = jun,
	year = {2020},
	note = {Number: 6
Publisher: Nature Publishing Group},
	pages = {602--604},
}

@article{geneva_transformers_2021,
	title = {Transformers for {Modeling} {Physical} {Systems}},
	url = {http://arxiv.org/abs/2010.03957},
	abstract = {Transformers are widely used in neural language processing due to their ability to model longer-term dependencies in text. Although these models achieve state-of-the-art performance for many language related tasks, their applicability outside of the neural language processing field has been minimal. In this work, we propose the use of transformer models for the prediction of dynamical systems representative of physical phenomena. The use of Koopman based embeddings provide a unique and powerful method for projecting any dynamical system into a vector representation which can then be predicted by a transformer model. The proposed model is able to accurately predict various dynamical systems and outperform classical methods that are commonly used in the scientific machine learning literature.},
	urldate = {2021-01-25},
	journal = {arXiv:2010.03957 [physics]},
	author = {Geneva, Nicholas and Zabaras, Nicholas},
	month = jan,
	year = {2021},
	note = {arXiv: 2010.03957},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{hermann_deep-neural-network_2020,
	title = {Deep-neural-network solution of the electronic {Schrödinger} equation},
	volume = {12},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1755-4349},
	url = {https://www.nature.com/articles/s41557-020-0544-y},
	doi = {10.1038/s41557-020-0544-y},
	abstract = {The electronic Schrödinger equation can only be solved analytically for the hydrogen atom, and the numerically exact full configuration-interaction method is exponentially expensive in the number of electrons. Quantum Monte Carlo methods are a possible way out: they scale well for large molecules, they can be parallelized and their accuracy has, as yet, been only limited by the flexibility of the wavefunction ansatz used. Here we propose PauliNet, a deep-learning wavefunction ansatz that achieves nearly exact solutions of the electronic Schrödinger equation for molecules with up to 30 electrons. PauliNet has a multireference Hartree–Fock solution built in as a baseline, incorporates the physics of valid wavefunctions and is trained using variational quantum Monte Carlo. PauliNet outperforms previous state-of-the-art variational ansatzes for atoms, diatomic molecules and a strongly correlated linear H10, and matches the accuracy of highly specialized quantum chemistry methods on the transition-state energy of cyclobutadiene, while being computationally efficient.},
	language = {en},
	number = {10},
	urldate = {2021-01-25},
	journal = {Nature Chemistry},
	author = {Hermann, Jan and Schätzle, Zeno and Noé, Frank},
	month = oct,
	year = {2020},
	note = {Number: 10
Publisher: Nature Publishing Group},
	pages = {891--897},
}

@article{hermann_deep_2020,
	title = {Deep neural network solution of the electronic {Schr}{\textbackslash}"odinger equation},
	volume = {12},
	issn = {1755-4330, 1755-4349},
	url = {http://arxiv.org/abs/1909.08423},
	doi = {10.1038/s41557-020-0544-y},
	abstract = {[New and updated results were published in Nature Chemistry, doi:10.1038/s41557-020-0544-y.] The electronic Schr{\textbackslash}"odinger equation describes fundamental properties of molecules and materials, but can only be solved analytically for the hydrogen atom. The numerically exact full configuration-interaction method is exponentially expensive in the number of electrons. Quantum Monte Carlo is a possible way out: it scales well to large molecules, can be parallelized, and its accuracy has, as yet, only been limited by the flexibility of the used wave function ansatz. Here we propose PauliNet, a deep-learning wave function ansatz that achieves nearly exact solutions of the electronic Schr{\textbackslash}"odinger equation. PauliNet has a multireference Hartree-Fock solution built in as a baseline, incorporates the physics of valid wave functions, and is trained using variational quantum Monte Carlo (VMC). PauliNet outperforms comparable state-of-the-art VMC ansatzes for atoms, diatomic molecules and a strongly-correlated hydrogen chain by a margin and is yet computationally efficient. We anticipate that thanks to the favourable scaling with system size, this method may become a new leading method for highly accurate electronic-strucutre calculations on medium-sized molecular systems.},
	number = {10},
	urldate = {2021-01-25},
	journal = {Nature Chemistry},
	author = {Hermann, Jan and Schätzle, Zeno and Noé, Frank},
	month = oct,
	year = {2020},
	note = {arXiv: 1909.08423},
	keywords = {Computer Science - Machine Learning, Physics - Chemical Physics, Physics - Computational Physics, Statistics - Machine Learning},
	pages = {891--897},
}

@incollection{scoggins_machine_2021,
	series = {{AIAA} {SciTech} {Forum}},
	title = {Machine {Learning} {Moment} {Closures} for {Accurate} and {Efficient} {Simulation} of {Polydisperse} {Evaporating} {Sprays}},
	url = {https://arc.aiaa.org/doi/10.2514/6.2021-1786},
	urldate = {2021-01-22},
	booktitle = {{AIAA} {Scitech} 2021 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Scoggins, James B. and Han, Jiequn and Massot, Marc},
	month = jan,
	year = {2021},
	doi = {10.2514/6.2021-1786},
}

@inproceedings{perlman_data_2007,
	address = {New York, NY, USA},
	series = {{SC} '07},
	title = {Data exploration of turbulence simulations using a database cluster},
	isbn = {978-1-59593-764-3},
	url = {https://doi.org/10.1145/1362622.1362654},
	doi = {10.1145/1362622.1362654},
	abstract = {We describe a new environment for the exploration of turbulent flows that uses a cluster of databases to store complete histories of Direct Numerical Simulation (DNS) results. This allows for spatial and temporal exploration of high-resolution data that were traditionally too large to store and too computationally expensive to produce on demand. We perform analysis of these data directly on the databases nodes, which minimizes the volume of network traffic. The low network demands enable us to provide public access to this experimental platform and its datasets through Web services. This paper details the system design and implementation. Specifically, we focus on hierarchical spatial indexing, cache-sensitive spatial scheduling of batch workloads, localizing computation through data partitioning, and load balancing techniques that minimize data movement. We provide real examples of how scientists use the system to perform high-resolution turbulence research from standard desktop computing environments.},
	urldate = {2021-01-22},
	booktitle = {Proceedings of the 2007 {ACM}/{IEEE} conference on {Supercomputing}},
	publisher = {Association for Computing Machinery},
	author = {Perlman, Eric and Burns, Randal and Li, Yi and Meneveau, Charles},
	month = nov,
	year = {2007},
	pages = {1--11},
}

@article{li_public_2008,
	title = {A public turbulence database cluster and applications to study {Lagrangian} evolution of velocity increments in turbulence},
	volume = {9},
	url = {https://doi.org/10.1080/14685240802376389},
	doi = {10.1080/14685240802376389},
	abstract = {A public database system archiving a direct numerical simulation (DNS) data set of isotropic, forced turbulence is described in this paper. The data set consists of the DNS output on 10243 spatial points and 1024 time samples spanning about one large-scale turnover time. This complete 10244 spacetime history of turbulence is accessible to users remotely through an interface that is based on the Web-services model. Users may write and execute analysis programs on their host computers, while the programs make subroutine-like calls that request desired parts of the data over the network. The users are thus able to perform numerical experiments by accessing the 27 terabytes (TB) of DNS data using regular platforms such as laptops. The architecture of the database is explained, as are some of the locally defined functions, such as differentiation and interpolation. Test calculations are performed to illustrate the usage of the system and to verify the accuracy of the methods. The database is then used to analyze a dynamical model for small-scale intermittency in turbulence. Specifically, the dynamical effects of pressure and viscous terms on the Lagrangian evolution of velocity increments are evaluated using conditional averages calculated from the DNS data in the database. It is shown that these effects differ considerably among themselves and thus require different modeling strategies in Lagrangian models of velocity increments and intermittency.},
	urldate = {2021-01-22},
	journal = {Journal of Turbulence},
	author = {Li, Yi and Perlman, Eric and Wan, Minping and Yang, Yunke and Meneveau, Charles and Burns, Randal and Chen, Shiyi and Szalay, Alexander and Eyink, Gregory},
	month = jan,
	year = {2008},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/14685240802376389},
	keywords = {Turbulence, database, intermittency, simulation},
	pages = {N31},
}

@article{huang_augmented_2020,
	title = {Augmented {Normalizing} {Flows}: {Bridging} the {Gap} {Between} {Generative} {Flows} and {Latent} {Variable} {Models}},
	shorttitle = {Augmented {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2002.07101},
	abstract = {In this work, we propose a new family of generative flows on an augmented data space, with an aim to improve expressivity without drastically increasing the computational cost of sampling and evaluation of a lower bound on the likelihood. Theoretically, we prove the proposed flow can approximate a Hamiltonian ODE as a universal transport map. Empirically, we demonstrate state-of-the-art performance on standard benchmarks of flow-based generative modeling.},
	urldate = {2021-01-20},
	journal = {arXiv:2002.07101 [cs, stat]},
	author = {Huang, Chin-Wei and Dinh, Laurent and Courville, Aaron},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.07101},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{nielsen_survae_2020,
	title = {{SurVAE} {Flows}: {Surjections} to {Bridge} the {Gap} between {VAEs} and {Flows}},
	shorttitle = {{SurVAE} {Flows}},
	url = {http://arxiv.org/abs/2007.02731},
	abstract = {Normalizing flows and variational autoencoders are powerful generative models that can represent complicated density functions. However, they both impose constraints on the models: Normalizing flows use bijective transformations to model densities whereas VAEs learn stochastic transformations that are non-invertible and thus typically do not provide tractable estimates of the marginal likelihood. In this paper, we introduce SurVAE Flows: A modular framework of composable transformations that encompasses VAEs and normalizing flows. SurVAE Flows bridge the gap between normalizing flows and VAEs with surjective transformations, wherein the transformations are deterministic in one direction -- thereby allowing exact likelihood computation, and stochastic in the reverse direction -- hence providing a lower bound on the corresponding likelihood. We show that several recently proposed methods, including dequantization and augmented normalizing flows, can be expressed as SurVAE Flows. Finally, we introduce common operations such as the max value, the absolute value, sorting and stochastic permutation as composable layers in SurVAE Flows.},
	urldate = {2021-01-20},
	journal = {arXiv:2007.02731 [cs, stat]},
	author = {Nielsen, Didrik and Jaini, Priyank and Hoogeboom, Emiel and Winther, Ole and Welling, Max},
	month = oct,
	year = {2020},
	note = {arXiv: 2007.02731},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zhang_self-attention_2019,
	title = {Self-{Attention} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1805.08318},
	abstract = {In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.},
	urldate = {2021-01-20},
	journal = {arXiv:1805.08318 [cs, stat]},
	author = {Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
	month = jun,
	year = {2019},
	note = {arXiv: 1805.08318},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kumar_videoflow_2020,
	title = {{VideoFlow}: {A} {Conditional} {Flow}-{Based} {Model} for {Stochastic} {Video} {Generation}},
	shorttitle = {{VideoFlow}},
	url = {http://arxiv.org/abs/1903.01434},
	abstract = {Generative models that can model and predict sequences of future events can, in principle, learn to capture complex real-world phenomena, such as physical interactions. However, a central challenge in video prediction is that the future is highly uncertain: a sequence of past observations of events can imply many possible futures. Although a number of recent works have studied probabilistic models that can represent uncertain futures, such models are either extremely expensive computationally as in the case of pixel-level autoregressive models, or do not directly optimize the likelihood of the data. To our knowledge, our work is the first to propose multi-frame video prediction with normalizing flows, which allows for direct optimization of the data likelihood, and produces high-quality stochastic predictions. We describe an approach for modeling the latent space dynamics, and demonstrate that flow-based generative models offer a viable and competitive approach to generative modelling of video.},
	urldate = {2021-01-20},
	journal = {arXiv:1903.01434 [cs]},
	author = {Kumar, Manoj and Babaeizadeh, Mohammad and Erhan, Dumitru and Finn, Chelsea and Levine, Sergey and Dinh, Laurent and Kingma, Durk},
	month = feb,
	year = {2020},
	note = {arXiv: 1903.01434},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{poletto_new_2013,
	title = {A {New} {Divergence} {Free} {Synthetic} {Eddy} {Method} for the {Reproduction} of {Inlet} {Flow} {Conditions} for {LES}},
	volume = {91},
	issn = {1573-1987},
	url = {https://doi.org/10.1007/s10494-013-9488-2},
	doi = {10.1007/s10494-013-9488-2},
	abstract = {This paper describes a recent development of the Synthetic Eddy Method (SEM) proposed by Jarrin et al. (Int J Heat Fluid Flow 30(3):435–442, 2009) for generation of synthetic turbulence. The present scheme is designed to produce a divergence-free turbulence field that can reproduce almost all possible states of Reynolds stress anisotropy. This improved representation, when used to provide inlet conditions for an LES, leads to reduced near-inlet pressure fluctuations in the LES and to a reduced development length, both of which lead to lower computer resource requirements. An advantage of this method with respect to forcing approaches (which require an iterative approach) is the suitability for direct usage with embedded LES. Results for a turbulent channel flow are reported here and compared to those from the original SEM, and other direct approaches such as the VORTEX method of Sergent (2002) and the Synthesized Turbulence approach of Davidson and Billson (Int J Heat Fluid Flow 27(6):1028–1042, 2006), showing overall improved performance and a more accurate representation of turbulence structures immediately downstream of the inlet.},
	language = {en},
	number = {3},
	urldate = {2021-01-19},
	journal = {Flow, Turbulence and Combustion},
	author = {Poletto, R. and Craft, T. and Revell, A.},
	month = oct,
	year = {2013},
	pages = {519--539},
}

@article{zhuang_adabelief_2020,
	title = {{AdaBelief} {Optimizer}: {Adapting} {Stepsizes} by the {Belief} in {Observed} {Gradients}},
	shorttitle = {{AdaBelief} {Optimizer}},
	url = {http://arxiv.org/abs/2010.07468},
	abstract = {Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient descent (SGD) with momentum). For many models such as convolutional neural networks (CNNs), adaptive methods typically converge faster but generalize worse compared to SGD; for complex settings such as generative adversarial networks (GANs), adaptive methods are typically the default because of their stability.We propose AdaBelief to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the "belief" in the current gradient direction. Viewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step. We validate AdaBelief in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on ImageNet, AdaBelief achieves comparable accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer. Code is available at https://github.com/juntang-zhuang/Adabelief-Optimizer},
	urldate = {2021-01-14},
	journal = {arXiv:2010.07468 [cs, stat]},
	author = {Zhuang, Juntang and Tang, Tommy and Ding, Yifan and Tatikonda, Sekhar and Dvornek, Nicha and Papademetris, Xenophon and Duncan, James S.},
	month = dec,
	year = {2020},
	note = {arXiv: 2010.07468},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{schneider_deepobs_2019,
	title = {{DeepOBS}: {A} {Deep} {Learning} {Optimizer} {Benchmark} {Suite}},
	shorttitle = {{DeepOBS}},
	url = {http://arxiv.org/abs/1903.05499},
	abstract = {Because the choice and tuning of the optimizer affects the speed, and ultimately the performance of deep learning, there is significant past and recent research in this area. Yet, perhaps surprisingly, there is no generally agreed-upon protocol for the quantitative and reproducible evaluation of optimization strategies for deep learning. We suggest routines and benchmarks for stochastic optimization, with special focus on the unique aspects of deep learning, such as stochasticity, tunability and generalization. As the primary contribution, we present DeepOBS, a Python package of deep learning optimization benchmarks. The package addresses key challenges in the quantitative assessment of stochastic optimizers, and automates most steps of benchmarking. The library includes a wide and extensible set of ready-to-use realistic optimization problems, such as training Residual Networks for image classification on ImageNet or character-level language prediction models, as well as popular classics like MNIST and CIFAR-10. The package also provides realistic baseline results for the most popular optimizers on these test problems, ensuring a fair comparison to the competition when benchmarking new optimizers, and without having to run costly experiments. It comes with output back-ends that directly produce LaTeX code for inclusion in academic publications. It supports TensorFlow and is available open source.},
	urldate = {2021-01-14},
	journal = {arXiv:1903.05499 [cs, stat]},
	author = {Schneider, Frank and Balles, Lukas and Hennig, Philipp},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.05499},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zhiyin_large-eddy_2015,
	title = {Large-eddy simulation: {Past}, present and the future},
	volume = {28},
	issn = {1000-9361},
	shorttitle = {Large-eddy simulation},
	url = {http://www.sciencedirect.com/science/article/pii/S1000936114002064},
	doi = {10.1016/j.cja.2014.12.007},
	abstract = {Large-eddy simulation (LES) was originally proposed for simulating atmospheric flows in the 1960s and has become one of the most promising and successful methodology for simulating turbulent flows with the improvement of computing power. It is now feasible to simulate complex engineering flows using LES. However, apart from the computing power, significant challenges still remain for LES to reach a level of maturity that brings this approach to the mainstream of engineering and industrial computations. This paper will describe briefly LES formalism first, present a quick glance at its history, review its current state focusing mainly on its applications in transitional flows and gas turbine combustor flows, discuss some major modelling and numerical challenges/issues that we are facing now and in the near future, and finish with the concluding remarks.},
	language = {en},
	number = {1},
	urldate = {2021-01-14},
	journal = {Chinese Journal of Aeronautics},
	author = {Zhiyin, Yang},
	month = feb,
	year = {2015},
	keywords = {Gas turbine combustor, Inflow boundary condition generation methods, Large-eddy simulation (LES), Sub-grid scale (SGS) model, Turbulent flows},
	pages = {11--24},
}

@article{zhiyin_large-eddy_2015-1,
	title = {Large-eddy simulation: {Past}, present and the future},
	volume = {28},
	issn = {1000-9361},
	shorttitle = {Large-eddy simulation},
	url = {http://www.sciencedirect.com/science/article/pii/S1000936114002064},
	doi = {10.1016/j.cja.2014.12.007},
	abstract = {Large-eddy simulation (LES) was originally proposed for simulating atmospheric flows in the 1960s and has become one of the most promising and successful methodology for simulating turbulent flows with the improvement of computing power. It is now feasible to simulate complex engineering flows using LES. However, apart from the computing power, significant challenges still remain for LES to reach a level of maturity that brings this approach to the mainstream of engineering and industrial computations. This paper will describe briefly LES formalism first, present a quick glance at its history, review its current state focusing mainly on its applications in transitional flows and gas turbine combustor flows, discuss some major modelling and numerical challenges/issues that we are facing now and in the near future, and finish with the concluding remarks.},
	language = {en},
	number = {1},
	urldate = {2021-01-14},
	journal = {Chinese Journal of Aeronautics},
	author = {Zhiyin, Yang},
	month = feb,
	year = {2015},
	keywords = {Gas turbine combustor, Inflow boundary condition generation methods, Large-eddy simulation (LES), Sub-grid scale (SGS) model, Turbulent flows},
	pages = {11--24},
}

@article{seo_differentiable_2019,
	title = {Differentiable {Physics}-informed {Graph} {Networks}},
	url = {http://arxiv.org/abs/1902.02950},
	abstract = {While physics conveys knowledge of nature built from an interplay between observations and theory, it has been considered less importantly in deep neural networks. Especially, there are few works leveraging physics behaviors when the knowledge is given less explicitly. In this work, we propose a novel architecture called Differentiable Physics-informed Graph Networks (DPGN) to incorporate implicit physics knowledge which is given from domain experts by informing it in latent space. Using the concept of DPGN, we demonstrate that climate prediction tasks are significantly improved. Besides the experiment results, we validate the effectiveness of the proposed module and provide further applications of DPGN, such as inductive learning and multistep predictions.},
	urldate = {2020-12-18},
	journal = {arXiv:1902.02950 [cs, stat]},
	author = {Seo, Sungyong and Liu, Yan},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.02950},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{oseledets_tensor-train_2011,
	title = {Tensor-{Train} {Decomposition}},
	volume = {33},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/090752286},
	doi = {10.1137/090752286},
	abstract = {A simple nonrecursive form of the tensor decomposition in d dimensions is presented. It does not inherently suﬀer from the curse of dimensionality, it has asymptotically the same number of parameters as the canonical decomposition, but it is stable and its computation is based on lowrank approximation of auxiliary unfolding matrices. The new form gives a clear and convenient way to implement all basic operations eﬃciently. A fast rounding procedure is presented, as well as basic linear algebra operations. Examples showing the beneﬁts of the decomposition are given, and the eﬃciency is demonstrated by the computation of the smallest eigenvalue of a 19-dimensional operator.},
	language = {en},
	number = {5},
	urldate = {2020-12-17},
	journal = {SIAM Journal on Scientific Computing},
	author = {Oseledets, I. V.},
	month = jan,
	year = {2011},
	pages = {2295--2317},
}

@article{shi_convolutional_2015,
	title = {Convolutional {LSTM} {Network}: {A} {Machine} {Learning} {Approach} for {Precipitation} {Nowcasting}},
	shorttitle = {Convolutional {LSTM} {Network}},
	url = {http://arxiv.org/abs/1506.04214},
	abstract = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.},
	urldate = {2020-12-15},
	journal = {arXiv:1506.04214 [cs]},
	author = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
	month = sep,
	year = {2015},
	note = {arXiv: 1506.04214},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{saegusa_nonlinear_2004,
	series = {Hybrid {Neurocomputing}: {Selected} {Papers} from the 2nd {International} {Conference} on {Hybrid} {Intelligent} {Systems}},
	title = {Nonlinear principal component analysis to preserve the order of principal components},
	volume = {61},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231204002279},
	doi = {10.1016/j.neucom.2004.03.004},
	abstract = {Principal component analysis (PCA) is an effective method of linear dimensional reduction. Because of its simplicity in theory and implementation, it is often used for analyses in various disciplines. However, because of its linearity, PCA is not always suitable, and has redundancy in expressing data. To overcome this problem, some nonlinear PCA methods have been proposed. However, most of these methods have drawbacks, such that the number of principal components must be predetermined, and also the order of the generated principal components is not explicitly given. In this paper, we propose a nonlinear PCA algorithm that nonlinearly transforms data into principal components, and at the same time, preserving the order of the principal components, and we also propose a hierarchical neural network model to perform the algorithm. Moreover, our method does not need to know the number of principal components in advance. The effectiveness of the proposed model will be shown through experiments.},
	language = {en},
	urldate = {2020-12-14},
	journal = {Neurocomputing},
	author = {Saegusa, Ryo and Sakano, Hitoshi and Hashimoto, Shuji},
	month = oct,
	year = {2004},
	keywords = {Hierarchical structure, Nonlinear principal component analysis, Sand-glass type multi-layered perceptron},
	pages = {57--70},
}

@article{roy_tree-cnn_2020,
	title = {Tree-{CNN}: {A} hierarchical {Deep} {Convolutional} {Neural} {Network} for incremental learning},
	volume = {121},
	issn = {0893-6080},
	shorttitle = {Tree-{CNN}},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608019302710},
	doi = {10.1016/j.neunet.2019.09.010},
	abstract = {Over the past decade, Deep Convolutional Neural Networks (DCNNs) have shown remarkable performance in most computer vision tasks. These tasks traditionally use a fixed dataset, and the model, once trained, is deployed as is. Adding new information to such a model presents a challenge due to complex training issues, such as “catastrophic forgetting”, and sensitivity to hyper-parameter tuning. However, in this modern world, data is constantly evolving, and our deep learning models are required to adapt to these changes. In this paper, we propose an adaptive hierarchical network structure composed of DCNNs that can grow and learn as new data becomes available. The network grows in a tree-like fashion to accommodate new classes of data, while preserving the ability to distinguish the previously trained classes. The network organizes the incrementally available data into feature-driven super-classes and improves upon existing hierarchical CNN models by adding the capability of self-growth. The proposed hierarchical model, when compared against fine-tuning a deep network, achieves significant reduction of training effort, while maintaining competitive accuracy on CIFAR-10 and CIFAR-100.},
	language = {en},
	urldate = {2020-12-10},
	journal = {Neural Networks},
	author = {Roy, Deboleena and Panda, Priyadarshini and Roy, Kaushik},
	month = jan,
	year = {2020},
	keywords = {Convolutional Neural Networks, Deep learning, Incremental learning, Transfer learning},
	pages = {148--160},
}

@article{ku_pseudospectral_1987,
	title = {A pseudospectral method for solution of the three-dimensional incompressible {Navier}-{Stokes} equations},
	volume = {70},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999187901902},
	doi = {10.1016/0021-9991(87)90190-2},
	abstract = {A new Chebyshev pseudospectral technique (based on the projection method that was previously applied by the authors to the solution of two-dimensional incompressible Navier-Stokes equations in primitive variables for nonperiodic boundary conditions) is extended to solve the three-dimensional Navier-Stokes equations. The crucial point of the method is the requirement that the continuity equation be satisfied everywhere in the domain, on the boundaries as well as in the interior. The key feature of the work presented in this paper is that the computer storage requirements of the full matrix inversion resulting from direct solution of the pressure Poisson equation in three dimensions is greatly reduced by considering an eigenfunction decomposition. The method was tested on a two-dimensional driven cavity flow and the results were compared with those of the most accurate finite-difference calculation. The three-dimensional driven cavity flow was then calculated at the same Reynolds numbers as the two-dimensional cases, i.e., Re = 100, 400, and 1000. In the calculated results, three-dimensional boundary effects were observed in all cases and became more apparent with increasing Reynolds number.},
	language = {en},
	number = {2},
	urldate = {2020-12-10},
	journal = {Journal of Computational Physics},
	author = {Ku, Hwar C and Hirsh, Richard S and Taylor, Thomas D},
	month = jun,
	year = {1987},
	pages = {439--462},
}

@article{maulik_probabilistic_2020,
	title = {Probabilistic neural networks for fluid flow surrogate modeling and data recovery},
	url = {http://arxiv.org/abs/2005.04271},
	doi = {10.1103/PhysRevFluids.5.104401},
	abstract = {We consider the use of probabilistic neural networks for fluid flow \{surrogate modeling\} and data recovery. This framework is constructed by assuming that the target variables are sampled from a Gaussian distribution conditioned on the inputs. Consequently, the overall formulation sets up a procedure to predict the hyperparameters of this distribution which are then used to compute an objective function given training data. We demonstrate that this framework has the ability to provide for prediction confidence intervals based on the assumption of a probabilistic posterior, given an appropriate model architecture and adequate training data. The applicability of the present framework to cases with noisy measurements and limited observations is also assessed. To demonstrate the capabilities of this framework, we consider canonical regression problems of fluid dynamics from the viewpoint of reduced-order modeling and spatial data recovery for four canonical data sets. The examples considered in this study arise from (1) the shallow water equations, (2) a two-dimensional cylinder flow, (3) the wake of NACA0012 airfoil with a Gurney flap, and (4) the NOAA sea surface temperature data set. The present results indicate that the probabilistic neural network not only produces a machine-learning-based fluid flow \{surrogate\} model but also systematically quantifies the uncertainty therein to assist with model interpretability.},
	urldate = {2020-12-10},
	journal = {arXiv:2005.04271 [physics]},
	author = {Maulik, Romit and Fukami, Kai and Ramachandra, Nesar and Fukagata, Koji and Taira, Kunihiko},
	month = sep,
	year = {2020},
	note = {arXiv: 2005.04271},
	keywords = {Physics - Fluid Dynamics},
}

@article{fukami_convolutional_2020,
	title = {Convolutional neural network based hierarchical autoencoder for nonlinear mode decomposition of fluid field data},
	volume = {32},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/full/10.1063/5.0020721},
	doi = {10.1063/5.0020721},
	abstract = {We propose a customized convolutional neural network based autoencoder called a hierarchical autoencoder, which allows us to extract nonlinear autoencoder modes of flow fields while preserving the contribution order of the latent vectors. As preliminary tests, the proposed method is first applied to a cylinder wake at ReD = 100 and its transient process. It is found that the proposed method can extract the features of these laminar flow fields as the latent vectors while keeping the order of their energy content. The present hierarchical autoencoder is further assessed with a two-dimensional y–z cross-sectional velocity field of turbulent channel flow at Reτ = 180 in order to examine its applicability to turbulent flows. It is demonstrated that the turbulent flow field can be efficiently mapped into the latent space by utilizing the hierarchical model with a concept of an ordered autoencoder mode family. The present results suggest that the proposed concept can be extended to meet various demands in fluid dynamics including reduced order modeling and its combination with linear theory-based methods by using its ability to arrange the order of the extracted nonlinear modes.},
	number = {9},
	urldate = {2020-12-10},
	journal = {Physics of Fluids},
	author = {Fukami, Kai (深見開) and Nakamura, Taichi (中村太一) and Fukagata, Koji (深潟康二)},
	month = sep,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {095110},
}

@misc{noauthor_cambridge_nodate,
	title = {Cambridge {Core} - {Journals} \&amp; {Books} {Online} {\textbar} {Cambridge} {University} {Press}},
	url = {http://www.cambridge.org/core},
	abstract = {Cambridge Core - the books and journals platform from Cambridge University Press replacing Cambridge Journals Online (CJO) and Cambridge Books online (CBO).},
	language = {en},
	urldate = {2020-12-10},
	journal = {Cambridge Core},
}

@article{fukami_super-resolution_2019,
	title = {Super-resolution reconstruction of turbulent flows with machine learning},
	volume = {870},
	issn = {0022-1120, 1469-7645},
	url = {http://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/superresolution-reconstruction-of-turbulent-flows-with-machine-learning/0DEBFE07FD949054E7E5046AB5632F22},
	doi = {10.1017/jfm.2019.238},
	abstract = {We use machine learning to perform super-resolution analysis of grossly under-resolved turbulent flow field data to reconstruct the high-resolution flow field. Two machine learning models are developed, namely, the convolutional neural network (CNN) and the hybrid downsampled skip-connection/multi-scale (DSC/MS) models. These machine learning models are applied to a two-dimensional cylinder wake as a preliminary test and show remarkable ability to reconstruct laminar flow from low-resolution flow field data. We further assess the performance of these models for two-dimensional homogeneous turbulence. The CNN and DSC/MS models are found to reconstruct turbulent flows from extremely coarse flow field images with remarkable accuracy. For the turbulent flow problem, the machine-leaning-based super-resolution analysis can greatly enhance the spatial resolution with as little as 50 training snapshot data, holding great potential to reveal subgrid-scale physics of complex turbulent flows. With the growing availability of flow field data from high-fidelity simulations and experiments, the present approach motivates the development of effective super-resolution models for a variety of fluid flows.},
	language = {en},
	urldate = {2020-12-10},
	journal = {Journal of Fluid Mechanics},
	author = {Fukami, Kai and Fukagata, Koji and Taira, Kunihiko},
	month = jul,
	year = {2019},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, homogeneous turbulence, wakes},
	pages = {106--120},
}

@article{su_convolutional_2020,
	title = {Convolutional {Tensor}-{Train} {LSTM} for {Spatio}-temporal {Learning}},
	url = {http://arxiv.org/abs/2002.09131},
	abstract = {Learning from spatio-temporal data has numerous applications such as human-behavior analysis, object tracking, video compression, and physics simulation.However, existing methods still perform poorly on challenging video tasks such as long-term forecasting. This is because these kinds of challenging tasks require learning long-term spatio-temporal correlations in the video sequence. In this paper, we propose a higher-order convolutional LSTM model that can efficiently learn these correlations, along with a succinct representations of the history. This is accomplished through a novel tensor train module that performs prediction by combining convolutional features across time. To make this feasible in terms of computation and memory requirements, we propose a novel convolutional tensor-train decomposition of the higher-order model. This decomposition reduces the model complexity by jointly approximating a sequence of convolutional kernels asa low-rank tensor-train factorization. As a result, our model outperforms existing approaches, but uses only a fraction of parameters, including the baseline models.Our results achieve state-of-the-art performance in a wide range of applications and datasets, including the multi-steps video prediction on the Moving-MNIST-2and KTH action datasets as well as early activity recognition on the Something-Something V2 dataset.},
	urldate = {2020-12-08},
	journal = {arXiv:2002.09131 [cs, stat]},
	author = {Su, Jiahao and Byeon, Wonmin and Kossaifi, Jean and Huang, Furong and Kautz, Jan and Anandkumar, Animashree},
	month = oct,
	year = {2020},
	note = {arXiv: 2002.09131},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ling_machine_2016,
	title = {Machine learning strategies for systems with invariance properties},
	volume = {318},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999116301309},
	doi = {10.1016/j.jcp.2016.05.003},
	abstract = {In many scientific fields, empirical models are employed to facilitate computational simulations of engineering systems. For example, in fluid mechanics, empirical Reynolds stress closures enable computationally-efficient Reynolds Averaged Navier Stokes simulations. Likewise, in solid mechanics, constitutive relations between the stress and strain in a material are required in deformation analysis. Traditional methods for developing and tuning empirical models usually combine physical intuition with simple regression techniques on limited data sets. The rise of high performance computing has led to a growing availability of high fidelity simulation data. These data open up the possibility of using machine learning algorithms, such as random forests or neural networks, to develop more accurate and general empirical models. A key question when using data-driven algorithms to develop these empirical models is how domain knowledge should be incorporated into the machine learning process. This paper will specifically address physical systems that possess symmetry or invariance properties. Two different methods for teaching a machine learning model an invariance property are compared. In the first method, a basis of invariant inputs is constructed, and the machine learning model is trained upon this basis, thereby embedding the invariance into the model. In the second method, the algorithm is trained on multiple transformations of the raw input data until the model learns invariance to that transformation. Results are discussed for two case studies: one in turbulence modeling and one in crystal elasticity. It is shown that in both cases embedding the invariance property into the input features yields higher performance at significantly reduced computational training costs.},
	language = {en},
	urldate = {2020-12-08},
	journal = {Journal of Computational Physics},
	author = {Ling, Julia and Jones, Reese and Templeton, Jeremy},
	month = aug,
	year = {2016},
	keywords = {Constitutive models, Machine learning, Tensor invariants, Turbulence models},
	pages = {22--35},
}

@article{maulik_subgrid_2019,
	title = {Subgrid modelling for two-dimensional turbulence using neural networks},
	volume = {858},
	issn = {0022-1120, 1469-7645},
	url = {http://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/subgrid-modelling-for-twodimensional-turbulence-using-neural-networks/10EDED1AEAA52C35F3E3A3BB6DC218C1},
	doi = {10.1017/jfm.2018.770},
	abstract = {In this investigation, a data-driven turbulence closure framework is introduced and deployed for the subgrid modelling of Kraichnan turbulence. The novelty of the proposed method lies in the fact that snapshots from high-fidelity numerical data are used to inform artificial neural networks for predicting the turbulence source term through localized grid-resolved information. In particular, our proposed methodology successfully establishes a map between inputs given by stencils of the vorticity and the streamfunction along with information from two well-known eddy-viscosity kernels. Through this we predict the subgrid vorticity forcing in a temporally and spatially dynamic fashion. Our study is both a priori and a posteriori in nature. In the former, we present an extensive hyper-parameter optimization analysis in addition to learning quantification through probability-density-function-based validation of subgrid predictions. In the latter, we analyse the performance of our framework for flow evolution in a classical decaying two-dimensional turbulence test case in the presence of errors related to temporal and spatial discretization. Statistical assessments in the form of angle-averaged kinetic energy spectra demonstrate the promise of the proposed methodology for subgrid quantity inference. In addition, it is also observed that some measure of a posteriori error must be considered during optimal model selection for greater accuracy. The results in this article thus represent a promising development in the formalization of a framework for generation of heuristic-free turbulence closures from data.},
	language = {en},
	urldate = {2020-12-08},
	journal = {Journal of Fluid Mechanics},
	author = {Maulik, R. and San, O. and Rasheed, A. and Vedula, P.},
	month = jan,
	year = {2019},
	note = {Publisher: Cambridge University Press},
	keywords = {computational methods, quasi-geostrophic flows, turbulence modelling},
	pages = {122--144},
}

@article{erichson_shallow_2019,
	title = {Shallow {Learning} for {Fluid} {Flow} {Reconstruction} with {Limited} {Sensors} and {Limited} {Data}},
	url = {http://arxiv.org/abs/1902.07358},
	abstract = {In many applications, it is important to reconstruct a fluid flow field, or some other high-dimensional state, from limited measurements and limited data. In this work, we propose a shallow neural network-based learning methodology for such fluid flow reconstruction. Our approach learns an end-to-end mapping between the sensor measurements and the high-dimensional fluid flow field, without any heavy preprocessing on the raw data. No prior knowledge is assumed to be available, and the estimation method is purely data-driven. We demonstrate the performance on three examples in fluid mechanics and oceanography, showing that this modern data-driven approach outperforms traditional modal approximation techniques which are commonly used for flow reconstruction. Not only does the proposed method show superior performance characteristics, it can also produce a comparable level of performance with traditional methods in the area, using significantly fewer sensors. Thus, the mathematical architecture is ideal for emerging global monitoring technologies where measurement data are often limited.},
	urldate = {2020-12-08},
	journal = {arXiv:1902.07358 [physics]},
	author = {Erichson, N. Benjamin and Mathelin, Lionel and Yao, Zhewei and Brunton, Steven L. and Mahoney, Michael W. and Kutz, J. Nathan},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.07358},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{fukami_machine_2020,
	title = {Machine learning based spatio-temporal super resolution reconstruction of turbulent flows},
	url = {http://arxiv.org/abs/2004.11566},
	abstract = {We present a new turbulent data reconstruction method with supervised machine learning techniques inspired by super resolution and inbetweening, which can recover high-resolution turbulent flows from grossly coarse flow data in space and time. For the present machine learning based data reconstruction, we use the downsampled skip-connection/multi-scale model based on a convolutional neural network to incorporate the multi-scale nature of fluid flows into its network structure. As an initial example, the model is applied to a two-dimensional cylinder wake at \$Re\_D\$ = 100. The reconstructed flow fields by the proposed method show great agreement with the reference data obtained by direct numerical simulation. Next, we examine the capability of the proposed model for a two-dimensional decaying homogeneous isotropic turbulence. The machine-learned models can follow the decaying evolution from coarse input data in space and time, according to the assessment with the turbulence statistics. The proposed concept is further investigated for a complex turbulent channel flow over a three-dimensional domain at \$Re\_\{{\textbackslash}tau\}\$ =180. The present model can reconstruct high-resolved turbulent flows from very coarse input data in space, and it can also reproduce the temporal evolution when the time interval is appropriately chosen. The dependence on the amount of training snapshots and duration between the first and last frames based on a temporal two-point correlation coefficient are also assessed to reveal the capability and robustness of spatio-temporal super resolution reconstruction. These results suggest that the present method can meet a range of flow reconstructions for supporting computational and experimental efforts.},
	urldate = {2020-12-07},
	journal = {arXiv:2004.11566 [physics]},
	author = {Fukami, Kai and Fukagata, Koji and Taira, Kunihiko},
	month = oct,
	year = {2020},
	note = {arXiv: 2004.11566},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{zang_weak_2020,
	title = {Weak adversarial networks for high-dimensional partial differential equations},
	volume = {411},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999120301832},
	doi = {10.1016/j.jcp.2020.109409},
	abstract = {Solving general high-dimensional partial differential equations (PDE) is a long-standing challenge in numerical mathematics. In this paper, we propose a novel approach to solve high-dimensional linear and nonlinear PDEs defined on arbitrary domains by leveraging their weak formulations. We convert the problem of finding the weak solution of PDEs into an operator norm minimization problem induced from the weak formulation. The weak solution and the test function in the weak formulation are then parameterized as the primal and adversarial networks respectively, which are alternately updated to approximate the optimal network parameter setting. Our approach, termed as the weak adversarial network (WAN), is fast, stable, and completely mesh-free, which is particularly suitable for high-dimensional PDEs defined on irregular domains where the classical numerical methods based on finite differences and finite elements suffer the issues of slow computation, instability and the curse of dimensionality. We apply our method to a variety of test problems with high-dimensional PDEs to demonstrate its promising performance.},
	language = {en},
	urldate = {2020-12-04},
	journal = {Journal of Computational Physics},
	author = {Zang, Yaohua and Bao, Gang and Ye, Xiaojing and Zhou, Haomin},
	month = jun,
	year = {2020},
	keywords = {Adversarial network, Deep neural network, High dimensional PDE, Weak solution},
	pages = {109409},
}

@article{xu_dlga-pde_2020,
	title = {{DLGA}-{PDE}: {Discovery} of {PDEs} with incomplete candidate library via combination of deep learning and genetic algorithm},
	volume = {418},
	issn = {0021-9991},
	shorttitle = {{DLGA}-{PDE}},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999120303582},
	doi = {10.1016/j.jcp.2020.109584},
	abstract = {Data-driven methods have recently been developed to discover underlying partial differential equations (PDEs) of physical problems. However, for these methods, a complete candidate library of potential terms in a PDE are usually required. To overcome this limitation, we propose a novel framework combining deep learning and genetic algorithm, called DLGA-PDE, for discovering PDEs. In the proposed framework, a deep neural network that is trained with available data of a physical problem is utilized to generate meta-data and calculate derivatives, and the genetic algorithm is then employed to discover the underlying PDE. Owing to the merits of the genetic algorithm, such as mutation and crossover, DLGA-PDE can work with an incomplete candidate library. The proposed DLGA-PDE is tested for discovery of the Korteweg–de Vries (KdV) equation, the Burgers equation, the wave equation, and the Chaffee-Infante equation, respectively, for proof-of-concept. Satisfactory results are obtained without the need for a complete candidate library, even in the presence of noisy and limited data.},
	language = {en},
	urldate = {2020-12-04},
	journal = {Journal of Computational Physics},
	author = {Xu, Hao and Chang, Haibin and Zhang, Dongxiao},
	month = oct,
	year = {2020},
	keywords = {Deep neural network, Genetic algorithm, Incomplete candidate library, Machine learning, PDE discovery},
	pages = {109584},
}

@article{wessels_neural_2020,
	title = {The neural particle method – {An} updated {Lagrangian} physics informed neural network for computational fluid dynamics},
	volume = {368},
	issn = {0045-7825},
	url = {http://www.sciencedirect.com/science/article/pii/S0045782520303121},
	doi = {10.1016/j.cma.2020.113127},
	abstract = {Today numerical simulation is indispensable in industrial design processes. It can replace cost and time intensive experiments and even reduce the need for prototypes. While products designed with the aid of numerical simulation undergo continuous improvement, this must also be true for numerical simulation techniques themselves. Up to date, no general purpose numerical method is available which can accurately resolve a variety of physics ranging from fluid to solid mechanics including large deformations and free surface flow phenomena. These complex multi-physics problems occur for example in Additive Manufacturing processes. In this sense, the recent developments in Machine Learning display promise for numerical simulation. It has recently been shown that instead of solving a system of equations as in standard numerical methods, a neural network can be trained solely based on initial and boundary conditions. Neural networks are smooth, differentiable functions that can be used as a global ansatz for Partial Differential Equations (PDEs). While this idea dates back to more than 20 years (Lagaris et al., 1998), it is only recently that an approach for the solution of time dependent problems has been developed (Raissi et al., 2019). With the latter, implicit Runge–Kutta schemes with unprecedented high order have been constructed to solve scalar-valued PDEs. We build on the aforementioned work in order to develop an Updated Lagrangian method for the solution of incompressible free surface flow subject to the inviscid Euler equations. The method is straightforward to implement and does not require any specific algorithmic treatment which is usually necessary to accurately resolve the incompressibility constraint. Due to its meshfree character, we will name it the Neural Particle Method (NPM). It will be demonstrated that the NPM remains stable and accurate even if the location of discretization points is highly irregular.},
	language = {en},
	urldate = {2020-12-04},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Wessels, Henning and Weißenfels, Christian and Wriggers, Peter},
	month = aug,
	year = {2020},
	keywords = {Computational fluid dynamics, Constraint problem, Implicit Runge–Kutta, Incompressibility, Machine learning, Physics-informed neural network},
	pages = {113127},
}

@article{schafer_competitive_2020,
	title = {Competitive {Gradient} {Descent}},
	url = {http://arxiv.org/abs/1905.12103},
	abstract = {We introduce a new algorithm for the numerical computation of Nash equilibria of competitive two-player games. Our method is a natural generalization of gradient descent to the two-player setting where the update is given by the Nash equilibrium of a regularized bilinear local approximation of the underlying game. It avoids oscillatory and divergent behaviors seen in alternating gradient descent. Using numerical experiments and rigorous analysis, we provide a detailed comparison to methods based on {\textbackslash}emph\{optimism\} and {\textbackslash}emph\{consensus\} and show that our method avoids making any unnecessary changes to the gradient dynamics while achieving exponential (local) convergence for (locally) convex-concave zero sum games. Convergence and stability properties of our method are robust to strong interactions between the players, without adapting the stepsize, which is not the case with previous methods. In our numerical experiments on non-convex-concave problems, existing methods are prone to divergence and instability due to their sensitivity to interactions among the players, whereas we never observe divergence of our algorithm. The ability to choose larger stepsizes furthermore allows our algorithm to achieve faster convergence, as measured by the number of model evaluations.},
	urldate = {2020-12-04},
	journal = {arXiv:1905.12103 [cs, math]},
	author = {Schäfer, Florian and Anandkumar, Anima},
	month = jun,
	year = {2020},
	note = {arXiv: 1905.12103},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@article{kharazmi_hp-vpinns_2020,
	title = {hp-{VPINNs}: {Variational} {Physics}-{Informed} {Neural} {Networks} {With} {Domain} {Decomposition}},
	shorttitle = {hp-{VPINNs}},
	url = {http://arxiv.org/abs/2003.05385},
	abstract = {We formulate a general framework for hp-variational physics-informed neural networks (hp-VPINNs) based on the nonlinear approximation of shallow and deep neural networks and hp-refinement via domain decomposition and projection onto space of high-order polynomials. The trial space is the space of neural network, which is defined globally over the whole computational domain, while the test space contains the piecewise polynomials. Specifically in this study, the hp-refinement corresponds to a global approximation with local learning algorithm that can efficiently localize the network parameter optimization. We demonstrate the advantages of hp-VPINNs in accuracy and training cost for several numerical examples of function approximation and solving differential equations.},
	urldate = {2020-12-04},
	journal = {arXiv:2003.05385 [cs, math]},
	author = {Kharazmi, Ehsan and Zhang, Zhongqiang and Karniadakis, George Em},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.05385},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Numerical Analysis},
}

@article{shin_convergence_2020,
	title = {On the convergence of physics informed neural networks for linear second-order elliptic and parabolic type {PDEs}},
	url = {http://arxiv.org/abs/2004.01806},
	abstract = {Physics informed neural networks (PINNs) are deep learning based techniques for solving partial differential equations (PDEs) encounted in computational science and engineering. Guided by data and physical laws, PINNs find a neural network that approximates the solution to a system of PDEs. Such a neural network is obtained by minimizing a loss function in which any prior knowledge of PDEs and data are encoded. Despite its remarkable empirical success in one, two or three dimensional problems, there is little theoretical justification for PINNs. As the number of data grows, PINNs generate a sequence of minimizers which correspond to a sequence of neural networks. We want to answer the question: Does the sequence of minimizers converge to the solution to the PDE? We consider two classes of PDEs: linear second-order elliptic and parabolic. By adapting the Schauder approach and the maximum principle, we show that the sequence of minimizers strongly converges to the PDE solution in \$C{\textasciicircum}0\$. Furthermore, we show that if each minimizer satisfies the initial/boundary conditions, the convergence mode becomes \$H{\textasciicircum}1\$. Computational examples are provided to illustrate our theoretical findings. To the best of our knowledge, this is the first theoretical work that shows the consistency of PINNs.},
	urldate = {2020-12-04},
	journal = {arXiv:2004.01806 [cs, math]},
	author = {Shin, Yeonjong and Darbon, Jerome and Karniadakis, George Em},
	month = oct,
	year = {2020},
	note = {arXiv: 2004.01806},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{canu_where_2018,
	title = {Where does the droplet size distribution come from?},
	volume = {107},
	issn = {0301-9322},
	url = {http://www.sciencedirect.com/science/article/pii/S0301932218302854},
	doi = {10.1016/j.ijmultiphaseflow.2018.06.010},
	abstract = {This study employs DNS of two-phase flows to enhance primary atomization understanding and modeling to be used in numerical simulation in RANS or LES framework. In particular, the work has been aimed at improving the information on the liquid-gas interface evolution for modeling approaches, such as the Eulerian–Lagrangian Spray Atomization (ELSA) framework. Even though this approach has been already successfully employed to describe the complete liquid atomization process from the primary region to the dilute spray, improvements are still expected on the derivation of the drop size distribution (DSD). The main aim of the present work is the introduction of a new framework to achieve a continuous description of the DSD formation during the atomization process. The attention is here focused on the extraction from DNS data of the behavior of geometrical variable of the liquid-gas interface, such as the mean (H) and Gauss (G) surface curvatures. The use of a Surface Curvature Distribution is also proposed and studied. A Rayleigh–Plateau instability along a column of liquid and a droplet collision case are first of all considered to analyze and to verify the capabilities of the code to correctly predicting the curvature distributions. A statistical analysis based on the curvatures data, in terms of probability density function, is presented in order to determine the physical parameters that control the curvatures on this test case. Then, the same formulation is applied in the analysis of the two phase Homogeneous Isotropic Turbulence (HIT) configuration to study how the curvatures evolve all along the atomization process. Joint PDFs are used to illustrate the topological changes of the interface when increasing the liquid volume fraction.},
	language = {en},
	urldate = {2020-12-03},
	journal = {International Journal of Multiphase Flow},
	author = {Canu, Romain and Puggelli, Stefano and Essadki, Mohamed and Duret, Benjamin and Menard, Thibaut and Massot, Marc and Reveillon, Julien and Demoulin, F. X.},
	month = oct,
	year = {2018},
	keywords = {Curvature, DNS, Interface, Two-phase flows},
	pages = {230--245},
}

@article{kharazmi_variational_2019,
	title = {Variational {Physics}-{Informed} {Neural} {Networks} {For} {Solving} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1912.00873},
	abstract = {Physics-informed neural networks (PINNs) [31] use automatic differentiation to solve partial differential equations (PDEs) by penalizing the PDE in the loss function at a random set of points in the domain of interest. Here, we develop a Petrov-Galerkin version of PINNs based on the nonlinear approximation of deep neural networks (DNNs) by selecting the \{{\textbackslash}em trial space\} to be the space of neural networks and the \{{\textbackslash}em test space\} to be the space of Legendre polynomials. We formulate the {\textbackslash}textit\{variational residual\} of the PDE using the DNN approximation by incorporating the variational form of the problem into the loss function of the network and construct a {\textbackslash}textit\{variational physics-informed neural network\} (VPINN). By integrating by parts the integrand in the variational form, we lower the order of the differential operators represented by the neural networks, hence effectively reducing the training cost in VPINNs while increasing their accuracy compared to PINNs that essentially employ delta test functions. For shallow networks with one hidden layer, we analytically obtain explicit forms of the {\textbackslash}textit\{variational residual\}. We demonstrate the performance of the new formulation for several examples that show clear advantages of VPINNs over PINNs in terms of both accuracy and speed.},
	urldate = {2020-12-01},
	journal = {arXiv:1912.00873 [physics, stat]},
	author = {Kharazmi, E. and Zhang, Z. and Karniadakis, G. E.},
	month = nov,
	year = {2019},
	note = {arXiv: 1912.00873},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Numerical Analysis, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{pang_fpinns_2018,
	title = {{fPINNs}: {Fractional} {Physics}-{Informed} {Neural} {Networks}},
	shorttitle = {{fPINNs}},
	url = {http://arxiv.org/abs/1811.08967},
	abstract = {Physics-informed neural networks (PINNs) are effective in solving integer-order partial differential equations (PDEs) based on scattered and noisy data. PINNs employ standard feedforward neural networks (NNs) with the PDEs explicitly encoded into the NN using automatic differentiation, while the sum of the mean-squared PDE-residuals and the mean-squared error in initial/boundary conditions is minimized with respect to the NN parameters. We extend PINNs to fractional PINNs (fPINNs) to solve space-time fractional advection-diffusion equations (fractional ADEs), and we demonstrate their accuracy and effectiveness in solving multi-dimensional forward and inverse problems with forcing terms whose values are only known at randomly scattered spatio-temporal coordinates (black-box forcing terms). A novel element of the fPINNs is the hybrid approach that we introduce for constructing the residual in the loss function using both automatic differentiation for the integer-order operators and numerical discretization for the fractional operators. We consider 1D time-dependent fractional ADEs and compare white-box (WB) and black-box (BB) forcing. We observe that for the BB forcing fPINNs outperform FDM. Subsequently, we consider multi-dimensional time-, space-, and space-time-fractional ADEs using the directional fractional Laplacian and we observe relative errors of \$10{\textasciicircum}\{-4\}\$. Finally, we solve several inverse problems in 1D, 2D, and 3D to identify the fractional orders, diffusion coefficients, and transport velocities and obtain accurate results even in the presence of significant noise.},
	urldate = {2020-12-01},
	journal = {arXiv:1811.08967 [physics]},
	author = {Pang, Guofei and Lu, Lu and Karniadakis, George Em},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.08967},
	keywords = {Physics - Computational Physics},
}

@article{wang_understanding_2020,
	title = {Understanding and mitigating gradient pathologies in physics-informed neural networks},
	url = {http://arxiv.org/abs/2001.04536},
	abstract = {The widespread use of neural networks across different scientific domains often involves constraining them to satisfy certain symmetries, conservation laws, or other domain knowledge. Such constraints are often imposed as soft penalties during model training and effectively act as domain-specific regularizers of the empirical risk loss. Physics-informed neural networks is an example of this philosophy in which the outputs of deep neural networks are constrained to approximately satisfy a given set of partial differential equations. In this work we review recent advances in scientific machine learning with a specific focus on the effectiveness of physics-informed neural networks in predicting outcomes of physical systems and discovering hidden physics from noisy data. We will also identify and analyze a fundamental mode of failure of such approaches that is related to numerical stiffness leading to unbalanced back-propagated gradients during model training. To address this limitation we present a learning rate annealing algorithm that utilizes gradient statistics during model training to balance the interplay between different terms in composite loss functions. We also propose a novel neural network architecture that is more resilient to such gradient pathologies. Taken together, our developments provide new insights into the training of constrained neural networks and consistently improve the predictive accuracy of physics-informed neural networks by a factor of 50-100x across a range of problems in computational physics. All code and data accompanying this manuscript are publicly available at {\textbackslash}url\{https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs\}.},
	urldate = {2020-12-01},
	journal = {arXiv:2001.04536 [cs, math, stat]},
	author = {Wang, Sifan and Teng, Yujun and Perdikaris, Paris},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.04536},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{lischke_what_2020,
	title = {What is the fractional {Laplacian}? {A} comparative review with new results},
	volume = {404},
	issn = {0021-9991},
	shorttitle = {What is the fractional {Laplacian}?},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999119307156},
	doi = {10.1016/j.jcp.2019.109009},
	abstract = {The fractional Laplacian in Rd, which we write as (−Δ)α/2 with α∈(0,2), has multiple equivalent characterizations. Moreover, in bounded domains, boundary conditions must be incorporated in these characterizations in mathematically distinct ways, and there is currently no consensus in the literature as to which definition of the fractional Laplacian in bounded domains is most appropriate for a given application. The Riesz (or integral) definition, for example, admits a nonlocal boundary condition, where the value of a function must be prescribed on the entire exterior of the domain in order to compute its fractional Laplacian. In contrast, the spectral definition requires only the standard local boundary condition. These differences, among others, lead us to ask the question: “What is the fractional Laplacian?” Beginning from first principles, we compare several commonly used definitions of the fractional Laplacian theoretically, through their stochastic interpretations as well as their analytical properties. Then, we present quantitative comparisons using a sample of state-of-the-art methods. We discuss recent advances on nonzero boundary conditions and present new methods to discretize such boundary value problems: radial basis function collocation (for the Riesz fractional Laplacian) and nonharmonic lifting (for the spectral fractional Laplacian). In our numerical studies, we aim to compare different definitions on bounded domains using a collection of benchmark problems. We consider the fractional Poisson equation with both zero and nonzero boundary conditions, where the fractional Laplacian is defined according to the Riesz definition, the spectral definition, the directional definition, and the horizon-based nonlocal definition. We verify the accuracy of the numerical methods used in the approximations for each operator, and we focus on identifying differences in the boundary behaviors of solutions to equations posed with these different definitions. Through our efforts, we aim to further engage the research community in open problems and assist practitioners in identifying the most appropriate definition and computational approach to use for their mathematical models in addressing anomalous transport in diverse applications.},
	language = {en},
	urldate = {2020-12-01},
	journal = {Journal of Computational Physics},
	author = {Lischke, Anna and Pang, Guofei and Gulian, Mamikon and Song, Fangying and Glusa, Christian and Zheng, Xiaoning and Mao, Zhiping and Cai, Wei and Meerschaert, Mark M. and Ainsworth, Mark and Karniadakis, George Em},
	month = mar,
	year = {2020},
	keywords = {Anomalous diffusion, Fractional Laplacian, Nonlocal model, Regularity, Stable Lévy motion},
	pages = {109009},
}

@article{haghighat_sciann_2021,
	title = {{SciANN}: {A} {Keras}/{TensorFlow} wrapper for scientific computations and physics-informed deep learning using artificial neural networks},
	volume = {373},
	issn = {0045-7825},
	shorttitle = {{SciANN}},
	url = {http://www.sciencedirect.com/science/article/pii/S0045782520307374},
	doi = {10.1016/j.cma.2020.113552},
	abstract = {In this paper, we introduce SciANN, a Python package for scientific computing and physics-informed deep learning using artificial neural networks. SciANN uses the widely used deep-learning packages TensorFlow and Keras to build deep neural networks and optimization models, thus inheriting many of Keras’s functionalities, such as batch optimization and model reuse for transfer learning. SciANN is designed to abstract neural network construction for scientific computations and solution and discovery of partial differential equations (PDE) using the physics-informed neural networks (PINN) architecture, therefore providing the flexibility to set up complex functional forms. We illustrate, in a series of examples, how the framework can be used for curve fitting on discrete data, and for solution and discovery of PDEs in strong and weak forms. We summarize the features currently available in SciANN, and also outline ongoing and future developments.},
	language = {en},
	urldate = {2020-11-27},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Haghighat, Ehsan and Juanes, Ruben},
	month = jan,
	year = {2021},
	keywords = {Deep neural networks, PINN, SciANN, Scientific computations, vPINN},
	pages = {113552},
}

@article{ramachandran_searching_2017,
	title = {Searching for {Activation} {Functions}},
	url = {http://arxiv.org/abs/1710.05941},
	abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, \$f(x) = x {\textbackslash}cdot {\textbackslash}text\{sigmoid\}({\textbackslash}beta x)\$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9{\textbackslash}\% for Mobile NASNet-A and 0.6{\textbackslash}\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
	urldate = {2020-11-27},
	journal = {arXiv:1710.05941 [cs]},
	author = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc V.},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.05941},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{jiang_enforcing_2019,
	title = {Enforcing {Physical} {Constraints} in {Neural} {Neural} {Networks} through {Differentiable} {PDE} {Layer}},
	url = {https://openreview.net/forum?id=B1eyA3VFwS},
	abstract = {A novel way of enforcing hard linear constraints within a convolutional neural network using a differentiable PDE layer.},
	language = {en},
	urldate = {2020-11-26},
	author = {Jiang, Chiyu "Max" and Kashinath, Karthik and Prabhat and Marcus, Philip},
	month = sep,
	year = {2019},
}

@article{mohan_embedding_2020,
	title = {Embedding {Hard} {Physical} {Constraints} in {Neural} {Network} {Coarse}-{Graining} of {3D} {Turbulence}},
	url = {http://arxiv.org/abs/2002.00021},
	abstract = {In the recent years, deep learning approaches have shown much promise in modeling complex systems in the physical sciences. A major challenge in deep learning of PDEs is enforcing physical constraints and boundary conditions. In this work, we propose a general framework to directly embed the notion of an incompressible fluid into Convolutional Neural Networks, and apply this to coarse-graining of turbulent flow. These physics-embedded neural networks leverage interpretable strategies from numerical methods and computational fluid dynamics to enforce physical laws and boundary conditions by taking advantage the mathematical properties of the underlying equations. We demonstrate results on three-dimensional fully-developed turbulence, showing that this technique drastically improves local conservation of mass, without sacrificing performance according to several other metrics characterizing the fluid flow.},
	urldate = {2020-11-26},
	journal = {arXiv:2002.00021 [physics]},
	author = {Mohan, Arvind T. and Lubbers, Nicholas and Livescu, Daniel and Chertkov, Michael},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.00021},
	keywords = {Physics - Computational Physics},
}

@article{jiang_meshfreeflownet_2020,
	title = {{MeshfreeFlowNet}: {A} {Physics}-{Constrained} {Deep} {Continuous} {Space}-{Time} {Super}-{Resolution} {Framework}},
	shorttitle = {{MeshfreeFlowNet}},
	url = {http://arxiv.org/abs/2005.01463},
	abstract = {We propose MeshfreeFlowNet, a novel deep learning-based super-resolution framework to generate continuous (grid-free) spatio-temporal solutions from the low-resolution inputs. While being computationally efficient, MeshfreeFlowNet accurately recovers the fine-scale quantities of interest. MeshfreeFlowNet allows for: (i) the output to be sampled at all spatio-temporal resolutions, (ii) a set of Partial Differential Equation (PDE) constraints to be imposed, and (iii) training on fixed-size inputs on arbitrarily sized spatio-temporal domains owing to its fully convolutional encoder. We empirically study the performance of MeshfreeFlowNet on the task of super-resolution of turbulent flows in the Rayleigh-Benard convection problem. Across a diverse set of evaluation metrics, we show that MeshfreeFlowNet significantly outperforms existing baselines. Furthermore, we provide a large scale implementation of MeshfreeFlowNet and show that it efficiently scales across large clusters, achieving 96.80\% scaling efficiency on up to 128 GPUs and a training time of less than 4 minutes.},
	urldate = {2020-11-25},
	journal = {arXiv:2005.01463 [physics, stat]},
	author = {Jiang, Chiyu Max and Esmaeilzadeh, Soheil and Azizzadenesheli, Kamyar and Kashinath, Karthik and Mustafa, Mustafa and Tchelepi, Hamdi A. and Marcus, Philip and Prabhat and Anandkumar, Anima},
	month = aug,
	year = {2020},
	note = {arXiv: 2005.01463},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Physics - Fluid Dynamics, Statistics - Machine Learning},
}

@article{farazi_frequency_2019,
	title = {Frequency {Domain} {Transformer} {Networks} for {Video} {Prediction}},
	url = {http://arxiv.org/abs/1903.00271},
	abstract = {The task of video prediction is forecasting the next frames given some previous frames. Despite much recent progress, this task is still challenging mainly due to high nonlinearity in the spatial domain. To address this issue, we propose a novel architecture, Frequency Domain Transformer Network (FDTN), which is an end-to-end learnable model that estimates and uses the transformations of the signal in the frequency domain. Experimental evaluations show that this approach can outperform some widely used video prediction methods like Video Ladder Network (VLN) and Predictive Gated Pyramids (PGP).},
	urldate = {2020-11-23},
	journal = {arXiv:1903.00271 [cs]},
	author = {Farazi, Hafez and Behnke, Sven},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.00271},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@incollection{ajuria_illarramendi_towards_2020,
	series = {{AIAA} {AVIATION} {Forum}},
	title = {Towards an hybrid computational strategy based on {Deep} {Learning} for incompressible flows},
	url = {https://arc.aiaa.org/doi/10.2514/6.2020-3058},
	urldate = {2020-11-23},
	booktitle = {{AIAA} {AVIATION} 2020 {FORUM}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Ajuria Illarramendi, Ekhi and Alguacil, Antonio and Bauerheim, Michaël and Misdariis, Antony and Cuenot, Benedicte and Benazera, Emmanuel},
	month = jun,
	year = {2020},
	doi = {10.2514/6.2020-3058},
}

@article{sanchez-gonzalez_learning_2020,
	title = {Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}},
	url = {http://arxiv.org/abs/2002.09405},
	abstract = {Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term "Graph Network-based Simulators" (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.},
	urldate = {2020-11-20},
	journal = {arXiv:2002.09405 [physics, stat]},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W.},
	month = sep,
	year = {2020},
	note = {arXiv: 2002.09405},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{liu_deep_2020,
	title = {Deep learning methods for super-resolution reconstruction of turbulent flows},
	volume = {32},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.5140772},
	doi = {10.1063/1.5140772},
	abstract = {Two deep learning (DL) models addressing the super-resolution (SR) reconstruction of turbulent flows from low-resolution coarse flow field data are developed. One is the static convolutional neural network (SCNN), and the other is the novel multiple temporal paths convolutional neural network (MTPC). The SCNN model takes instantaneous snapshots as an input, while the MTPC model takes a time series of velocity fields as an input, and it includes spatial and temporal information simultaneously. Three temporal paths are designed in the MTPC to fully capture features in different time ranges. A weight path is added to generate pixel-level weight maps of each temporal path. These models were first applied to forced isotropic turbulence. The corresponding high-resolution flow fields were reconstructed with high accuracy. The MTPC seems to be able to reproduce many important features as well, such as kinetic energy spectra and the joint probability density function of the second and third invariants of the velocity gradient tensor. As a further evaluation, the SR reconstruction of anisotropic channel flow with the DL models was performed. The SCNN and MTPC remarkably improve the spatial resolution in various wall regions and potentially grasp all the anisotropic turbulent properties. It is also shown that the MTPC supplements more under-resolved details than the SCNN. The success is attributed to the fact that the MTPC can extract extra temporal information from consecutive fluid fields. The present work may contribute to the development of the subgrid-scale model in computational fluid dynamics and enrich the application of SR technology in fluid mechanics.},
	number = {2},
	urldate = {2020-11-20},
	journal = {Physics of Fluids},
	author = {Liu, Bo and Tang, Jiupeng and Huang, Haibo and Lu, Xi-Yun},
	month = feb,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {025105},
}

@article{peng_multiscale_2020,
	title = {Multiscale {Modeling} {Meets} {Machine} {Learning}: {What} {Can} {We} {Learn}?},
	issn = {1134-3060, 1886-1784},
	shorttitle = {Multiscale {Modeling} {Meets} {Machine} {Learning}},
	url = {http://link.springer.com/10.1007/s11831-020-09405-5},
	doi = {10.1007/s11831-020-09405-5},
	abstract = {Machine learning is increasingly recognized as a promising technology in the biological, biomedical, and behavioral sciences. There can be no argument that this technique is incredibly successful in image recognition with immediate applications in diagnostics including electrophysiology, radiology, or pathology, where we have access to massive amounts of annotated data. However, machine learning often performs poorly in prognosis, especially when dealing with sparse data. This is a field where classical physics-based simulation seems to remain irreplaceable. In this review, we identify areas in the biomedical sciences where machine learning and multiscale modeling can mutually benefit from one another: Machine learning can integrate physics-based knowledge in the form of governing equations, boundary conditions, or constraints to manage ill-posted problems and robustly handle sparse and noisy data; multiscale modeling can integrate machine learning to create surrogate models, identify system dynamics and parameters, analyze sensitivities, and quantify uncertainty to bridge the scales and understand the emergence of function. With a view towards applications in the life sciences, we discuss the state of the art of combining machine learning and multiscale modeling, identify applications and opportunities, raise open questions, and address potential challenges and limitations. We anticipate that it will stimulate discussion within the community of computational mechanics and reach out to other disciplines including mathematics, statistics, computer science, artificial intelligence, biomedicine, systems biology, and precision medicine to join forces towards creating robust and efficient models for biological systems.},
	language = {en},
	urldate = {2020-11-19},
	journal = {Archives of Computational Methods in Engineering},
	author = {Peng, Grace C. Y. and Alber, Mark and Buganza Tepole, Adrian and Cannon, William R. and De, Suvranu and Dura-Bernal, Savador and Garikipati, Krishna and Karniadakis, George and Lytton, William W. and Perdikaris, Paris and Petzold, Linda and Kuhl, Ellen},
	month = feb,
	year = {2020},
}

@article{duraisamy_turbulence_2019,
	title = {Turbulence {Modeling} in the {Age} of {Data}},
	volume = {51},
	issn = {0066-4189, 1545-4479},
	url = {http://arxiv.org/abs/1804.00183},
	doi = {10.1146/annurev-fluid-010518-040547},
	abstract = {Data from experiments and direct simulations of turbulence have historically been used to calibrate simple engineering models such as those based on the Reynolds-averaged Navier–Stokes (RANS) equations. In the past few years, with the availability of large and diverse datasets, researchers have begun to explore methods to systematically inform turbulence models with data, with the goal of quantifying and reducing model uncertainties. This review surveys recent developments in bounding uncertainties in RANS models via physical constraints, in adopting statistical inference to characterize model coeﬃcients and estimate discrepancy, and in using machine learning to improve turbulence models. Key principles, achievements and challenges are discussed. A central perspective advocated in this review is that by exploiting foundational knowledge in turbulence modeling and physical constraints, data-driven approaches can yield useful predictive models.},
	language = {en},
	number = {1},
	urldate = {2020-11-19},
	journal = {Annual Review of Fluid Mechanics},
	author = {Duraisamy, Karthik and Iaccarino, Gianluca and Xiao, Heng},
	month = jan,
	year = {2019},
	note = {arXiv: 1804.00183},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {357--377},
}

@article{ling_reynolds_2016,
	title = {Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
	volume = {807},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reynolds-averaged-turbulence-modelling-using-deep-neural-networks-with-embedded-invariance/0B280EEE89C74A7BF651C422F8FBD1EB},
	doi = {10.1017/jfm.2016.615},
	abstract = {There exists significant demand for improved Reynolds-averaged Navier–Stokes (RANS) turbulence models that are informed by and can represent a richer set of turbulence physics. This paper presents a method of using deep neural networks to learn a model for the Reynolds stress anisotropy tensor from high-fidelity simulation data. A novel neural network architecture is proposed which uses a multiplicative layer with an invariant tensor basis to embed Galilean invariance into the predicted anisotropy tensor. It is demonstrated that this neural network architecture provides improved prediction accuracy compared with a generic neural network architecture that does not embed this invariance property. The Reynolds stress anisotropy predictions of this invariant neural network are propagated through to the velocity field for two test cases. For both test cases, significant improvement versus baseline RANS linear eddy viscosity and nonlinear eddy viscosity models is demonstrated.},
	language = {en},
	urldate = {2020-11-19},
	journal = {Journal of Fluid Mechanics},
	author = {Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
	month = nov,
	year = {2016},
	note = {Publisher: Cambridge University Press},
	keywords = {turbulence modelling, turbulence theory, turbulent flows},
	pages = {155--166},
}

@article{duraisamy_turbulence_2019-1,
	title = {Turbulence {Modeling} in the {Age} of {Data}},
	volume = {51},
	issn = {0066-4189, 1545-4479},
	url = {http://arxiv.org/abs/1804.00183},
	doi = {10.1146/annurev-fluid-010518-040547},
	abstract = {Data from experiments and direct simulations of turbulence have historically been used to calibrate simple engineering models such as those based on the Reynolds-averaged Navier--Stokes (RANS) equations. In the past few years, with the availability of large and diverse datasets, researchers have begun to explore methods to systematically inform turbulence models with data, with the goal of quantifying and reducing model uncertainties. This review surveys recent developments in bounding uncertainties in RANS models via physical constraints, in adopting statistical inference to characterize model coefficients and estimate discrepancy, and in using machine learning to improve turbulence models. Key principles, achievements and challenges are discussed. A central perspective advocated in this review is that by exploiting foundational knowledge in turbulence modeling and physical constraints, data-driven approaches can yield useful predictive models.},
	number = {1},
	urldate = {2020-11-19},
	journal = {Annual Review of Fluid Mechanics},
	author = {Duraisamy, Karthik and Iaccarino, Gianluca and Xiao, Heng},
	month = jan,
	year = {2019},
	note = {arXiv: 1804.00183},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
	pages = {357--377},
}

@article{loshchilov_decoupled_2019,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {http://arxiv.org/abs/1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	urldate = {2020-11-17},
	journal = {arXiv:1711.05101 [cs, math]},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = jan,
	year = {2019},
	note = {arXiv: 1711.05101},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@article{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2020-11-12},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{battaglia_relational_2018,
	title = {Relational inductive biases, deep learning, and graph networks},
	url = {http://arxiv.org/abs/1806.01261},
	abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.},
	urldate = {2020-11-10},
	journal = {arXiv:1806.01261 [cs, stat]},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
	month = oct,
	year = {2018},
	note = {arXiv: 1806.01261},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{pfaff_learning_2020,
	title = {Learning {Mesh}-{Based} {Simulation} with {Graph} {Networks}},
	url = {http://arxiv.org/abs/2010.03409},
	abstract = {Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.},
	urldate = {2020-11-10},
	journal = {arXiv:2010.03409 [cs]},
	author = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter W.},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.03409},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2020-11-10},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{cranmer_discovering_2020,
	title = {Discovering {Symbolic} {Models} from {Deep} {Learning} with {Inductive} {Biases}},
	url = {http://arxiv.org/abs/2006.11287},
	abstract = {We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example-a detailed dark matter simulation-and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distribution data better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.},
	urldate = {2020-11-10},
	journal = {arXiv:2006.11287 [astro-ph, physics:physics, stat]},
	author = {Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.11287},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{hui_fast_2020,
	title = {Fast pressure distribution prediction of airfoils using deep learning},
	volume = {105},
	issn = {1270-9638},
	url = {http://www.sciencedirect.com/science/article/pii/S1270963820306313},
	doi = {10.1016/j.ast.2020.105949},
	abstract = {In the aerodynamic design, optimization of the pressure distribution of airfoils is crucial for the aerodynamic components. Conventionally, the pressure distribution is solved by computational fluid dynamics, which is a time-consuming task. Surrogate modeling can leverage such expense to some extent, but it needs careful shape parameterization schemes for airfoils. As an alternative, deep learning approximates inputs-outputs mapping without solving the efficiency-expensive physical equations and avoids the limitations of particular parameterization methods. Therefore, this paper presents a data-driven approach for predicting the pressure distribution over airfoils based on Convolutional Neural Network (CNN). Given the airfoil geometry, a supervised learning problem is presented for predicting aerodynamic performance. Furthermore, we utilize a universal and flexible parametrization method called Signed Distance Function to improve the performances of CNN. Given the unseen airfoils from the validation dataset to the trained model, our model achieves predicting the pressure coefficient in seconds, with a less than 2\% mean square error.},
	language = {en},
	urldate = {2020-11-10},
	journal = {Aerospace Science and Technology},
	author = {Hui, Xinyu and Bai, Junqiang and Wang, Hui and Zhang, Yang},
	month = oct,
	year = {2020},
	keywords = {Aerodynamic design, Convolutional neural network, Machine learning, Pressure distribution prediction},
	pages = {105949},
}

@article{rao_physics-informed_2020,
	title = {Physics-informed deep learning for incompressible laminar flows},
	volume = {10},
	issn = {2095-0349},
	url = {http://www.sciencedirect.com/science/article/pii/S2095034920300350},
	doi = {10.1016/j.taml.2020.01.039},
	abstract = {Physics-informed deep learning has drawn tremendous interest in recent years to solve computational physics problems, whose basic concept is to embed physical laws to constrain/inform neural networks, with the need of less data for training a reliable model. This can be achieved by incorporating the residual of physics equations into the loss function. Through minimizing the loss function, the network could approximate the solution. In this paper, we propose a mixed-variable scheme of physics-informed neural network (PINN) for fluid dynamics and apply it to simulate steady and transient laminar flows at low Reynolds numbers. A parametric study indicates that the mixed-variable scheme can improve the PINN trainability and the solution accuracy. The predicted velocity and pressure fields by the proposed PINN approach are also compared with the reference numerical solutions. Simulation results demonstrate great potential of the proposed PINN for fluid flow simulation with a high accuracy.},
	language = {en},
	number = {3},
	urldate = {2020-11-10},
	journal = {Theoretical and Applied Mechanics Letters},
	author = {Rao, Chengping and Sun, Hao and Liu, Yang},
	month = mar,
	year = {2020},
	keywords = {Deep learning, Fluid dynamics, Incompressible laminar flow, Physics-informed neural networks (PINN)},
	pages = {207--212},
}

@article{saha_hierarchical_2021,
	title = {Hierarchical {Deep} {Learning} {Neural} {Network} ({HiDeNN}): {An} artificial intelligence ({AI}) framework for computational science and engineering},
	volume = {373},
	issn = {0045-7825},
	shorttitle = {Hierarchical {Deep} {Learning} {Neural} {Network} ({HiDeNN})},
	url = {http://www.sciencedirect.com/science/article/pii/S004578252030637X},
	doi = {10.1016/j.cma.2020.113452},
	abstract = {In this work, a unified AI-framework named Hierarchical Deep Learning Neural Network (HiDeNN) is proposed to solve challenging computational science and engineering problems with little or no available physics as well as with extreme computational demand. The detailed construction and mathematical elements of HiDeNN are introduced and discussed to show the flexibility of the framework for diverse problems from disparate fields. Three example problems are solved to demonstrate the accuracy, efficiency, and versatility of the framework. The first example is designed to show that HiDeNN is capable of achieving better accuracy than conventional finite element method by learning the optimal nodal positions and capturing the stress concentration with a coarse mesh. The second example applies HiDeNN for multiscale analysis with sub-neural networks at each material point of macroscale. The final example demonstrates how HiDeNN can discover governing dimensionless parameters from experimental data so that a reduced set of input can be used to increase the learning efficiency. We further present a discussion and demonstration of the solution for advanced engineering problems that require state-of-the-art AI approaches and how a general and flexible system, such as HiDeNN-AI framework, can be applied to solve these problems.},
	language = {en},
	urldate = {2020-11-10},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Saha, Sourav and Gan, Zhengtao and Cheng, Lin and Gao, Jiaying and Kafka, Orion L. and Xie, Xiaoyu and Li, Hengyang and Tajdari, Mahsa and Kim, H. Alicia and Liu, Wing Kam},
	month = jan,
	year = {2021},
	keywords = {Artificial intelligence, Data-driven discovery, Deep learning, Machine learning, Multiscale simulation, Reduced order model},
	pages = {113452},
}

@article{wang_physics-informed_2020,
	title = {Physics-{Informed} {Neural} {Network} {Super} {Resolution} for {Advection}-{Diffusion} {Models}},
	url = {http://arxiv.org/abs/2011.02519},
	abstract = {Physics-informed neural networks (NN) are an emerging technique to improve spatial resolution and enforce physical consistency of data from physics models or satellite observations. A super-resolution (SR) technique is explored to reconstruct high-resolution images (\$4{\textbackslash}times\$) from lower resolution images in an advection-diffusion model of atmospheric pollution plumes. SR performance is generally increased when the advection-diffusion equation constrains the NN in addition to conventional pixel-based constraints. The ability of SR techniques to also reconstruct missing data is investigated by randomly removing image pixels from the simulations and allowing the system to learn the content of missing data. Improvements in S/N of \$11{\textbackslash}\%\$ are demonstrated when physics equations are included in SR with \$40{\textbackslash}\%\$ pixel loss. Physics-informed NNs accurately reconstruct corrupted images and generate better results compared to the standard SR approaches.},
	urldate = {2020-11-06},
	journal = {arXiv:2011.02519 [physics]},
	author = {Wang, Chulin and Bentivegna, Eloisa and Zhou, Wang and Klein, Levente and Elmegreen, Bruce},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.02519},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Physics - Geophysics},
}

@misc{noauthor_google_nodate,
	title = {Google {Colaboratory}},
	url = {https://colab.research.google.com/drive/1ANO0Aj44W_B4ZbaXGTIoibTkIoIL0Tqd#scrollTo=oMlahwHfJFPQ},
	language = {en},
	urldate = {2020-11-05},
}

@article{balcilar_bridging_2020,
	title = {Bridging the {Gap} {Between} {Spectral} and {Spatial} {Domains} in {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2003.11702},
	abstract = {This paper aims at revisiting Graph Convolutional Neural Networks by bridging the gap between spectral and spatial design of graph convolutions. We theoretically demonstrate some equivalence of the graph convolution process regardless it is designed in the spatial or the spectral domain. The obtained general framework allows to lead a spectral analysis of the most popular ConvGNNs, explaining their performance and showing their limits. Moreover, the proposed framework is used to design new convolutions in spectral domain with a custom frequency profile while applying them in the spatial domain. We also propose a generalization of the depthwise separable convolution framework for graph convolutional networks, what allows to decrease the total number of trainable parameters by keeping the capacity of the model. To the best of our knowledge, such a framework has never been used in the GNNs literature. Our proposals are evaluated on both transductive and inductive graph learning problems. Obtained results show the relevance of the proposed method and provide one of the first experimental evidence of transferability of spectral filter coefficients from one graph to another. Our source codes are publicly available at: https://github.com/balcilar/Spectral-Designed-Graph-Convolutions},
	urldate = {2020-11-05},
	journal = {arXiv:2003.11702 [cs, stat]},
	author = {Balcilar, Muhammet and Renton, Guillaume and Heroux, Pierre and Gauzere, Benoit and Adam, Sebastien and Honeine, Paul},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.11702},
	keywords = {68T05, Computer Science - Machine Learning, I.5.2, Statistics - Machine Learning},
}

@article{li_multipole_2020,
	title = {Multipole {Graph} {Neural} {Operator} for {Parametric} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2006.09535},
	abstract = {One of the main challenges in using deep learning-based methods for simulating physical systems and solving partial differential equations (PDEs) is formulating physics-based data in the desired structure for neural networks. Graph neural networks (GNNs) have gained popularity in this area since graphs offer a natural way of modeling particle interactions and provide a clear way of discretizing the continuum models. However, the graphs constructed for approximating such tasks usually ignore long-range interactions due to unfavorable scaling of the computational complexity with respect to the number of nodes. The errors due to these approximations scale with the discretization of the system, thereby not allowing for generalization under mesh-refinement. Inspired by the classical multipole methods, we propose a novel multi-level graph neural network framework that captures interaction at all ranges with only linear complexity. Our multi-level formulation is equivalent to recursively adding inducing points to the kernel matrix, unifying GNNs with multi-resolution matrix factorization of the kernel. Experiments confirm our multi-graph network learns discretization-invariant solution operators to PDEs and can be evaluated in linear time.},
	urldate = {2020-11-03},
	journal = {arXiv:2006.09535 [cs, math, stat]},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.09535},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{li_neural_2020,
	title = {Neural {Operator}: {Graph} {Kernel} {Network} for {Partial} {Differential} {Equations}},
	shorttitle = {Neural {Operator}},
	url = {http://arxiv.org/abs/2003.03485},
	abstract = {The classical development of neural networks has been primarily for mappings between a finite-dimensional Euclidean space and a set of classes, or between two finite-dimensional Euclidean spaces. The purpose of this work is to generalize neural networks so that they can learn mappings between infinite-dimensional spaces (operators). The key innovation in our work is that a single set of network parameters, within a carefully designed network architecture, may be used to describe mappings between infinite-dimensional spaces and between different finite-dimensional approximations of those spaces. We formulate approximation of the infinite-dimensional mapping by composing nonlinear activation functions and a class of integral operators. The kernel integration is computed by message passing on graph networks. This approach has substantial practical consequences which we will illustrate in the context of mappings between input data to partial differential equations (PDEs) and their solutions. In this context, such learned networks can generalize among different approximation methods for the PDE (such as finite difference or finite element methods) and among approximations corresponding to different underlying levels of resolution and discretization. Experiments confirm that the proposed graph kernel network does have the desired properties and show competitive performance compared to the state of the art solvers.},
	urldate = {2020-11-03},
	journal = {arXiv:2003.03485 [cs, math, stat]},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.03485},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
}

@article{li_fourier_2020,
	title = {Fourier {Neural} {Operator} for {Parametric} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and the Navier-Stokes equation (including the turbulent regime). Our Fourier neural operator shows state-of-the-art performance compared to existing neural network methodologies and it is up to three orders of magnitude faster compared to traditional PDE solvers.},
	urldate = {2020-10-31},
	journal = {arXiv:2010.08895 [cs, math]},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.08895},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
}

@article{jagtap_adaptive_2019,
	title = {Adaptive activation functions accelerate convergence in deep and physics-informed neural networks},
	url = {http://arxiv.org/abs/1906.01170},
	doi = {10.1016/j.jcp.2019.109136},
	abstract = {We employ adaptive activation functions for regression in deep and physics-informed neural networks (PINNs) to approximate smooth and discontinuous functions as well as solutions of linear and nonlinear partial differential equations. In particular, we solve the nonlinear Klein-Gordon equation, which has smooth solutions, the nonlinear Burgers equation, which can admit high gradient solutions, and the Helmholtz equation. We introduce a scalable hyper-parameter in the activation function, which can be optimized to achieve best performance of the network as it changes dynamically the topology of the loss function involved in the optimization process. The adaptive activation function has better learning capabilities than the traditional one (fixed activation) as it improves greatly the convergence rate, especially at early training, as well as the solution accuracy. To better understand the learning process, we plot the neural network solution in the frequency domain to examine how the network captures successively different frequency bands present in the solution. We consider both forward problems, where the approximate solutions are obtained, as well as inverse problems, where parameters involved in the governing equation are identified. Our simulation results show that the proposed method is a very simple and effective approach to increase the efficiency, robustness and accuracy of the neural network approximation of nonlinear functions as well as solutions of partial differential equations, especially for forward problems.},
	urldate = {2020-10-29},
	journal = {arXiv:1906.01170 [physics]},
	author = {Jagtap, Ameya D. and Karniadakis, George Em},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.01170},
	keywords = {Physics - Computational Physics},
}

@article{raissi_deep_2018,
	title = {Deep {Learning} of {Turbulent} {Scalar} {Mixing}},
	url = {http://arxiv.org/abs/1811.07095},
	abstract = {Based on recent developments in physics-informed deep learning and deep hidden physics models, we put forth a framework for discovering turbulence models from scattered and potentially noisy spatio-temporal measurements of the probability density function (PDF). The models are for the conditional expected diffusion and the conditional expected dissipation of a Fickian scalar described by its transported single-point PDF equation. The discovered model are appraised against exact solution derived by the amplitude mapping closure (AMC)/ Johnsohn-Edgeworth translation (JET) model of binary scalar mixing in homogeneous turbulence.},
	urldate = {2020-10-28},
	journal = {arXiv:1811.07095 [physics]},
	author = {Raissi, Maziar and Babaee, Hessam and Givi, Peyman},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.07095},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{raissi_hidden_2018,
	title = {Hidden {Fluid} {Mechanics}: {A} {Navier}-{Stokes} {Informed} {Deep} {Learning} {Framework} for {Assimilating} {Flow} {Visualization} {Data}},
	shorttitle = {Hidden {Fluid} {Mechanics}},
	url = {http://arxiv.org/abs/1808.04327},
	abstract = {We present hidden fluid mechanics (HFM), a physics informed deep learning framework capable of encoding an important class of physical laws governing fluid motions, namely the Navier-Stokes equations. In particular, we seek to leverage the underlying conservation laws (i.e., for mass, momentum, and energy) to infer hidden quantities of interest such as velocity and pressure fields merely from spatio-temporal visualizations of a passive scaler (e.g., dye or smoke), transported in arbitrarily complex domains (e.g., in human arteries or brain aneurysms). Our approach towards solving the aforementioned data assimilation problem is unique as we design an algorithm that is agnostic to the geometry or the initial and boundary conditions. This makes HFM highly flexible in choosing the spatio-temporal domain of interest for data acquisition as well as subsequent training and predictions. Consequently, the predictions made by HFM are among those cases where a pure machine learning strategy or a mere scientific computing approach simply cannot reproduce. The proposed algorithm achieves accurate predictions of the pressure and velocity fields in both two and three dimensional flows for several benchmark problems motivated by real-world applications. Our results demonstrate that this relatively simple methodology can be used in physical and biomedical problems to extract valuable quantitative information (e.g., lift and drag forces or wall shear stresses in arteries) for which direct measurements may not be possible.},
	urldate = {2020-10-28},
	journal = {arXiv:1808.04327 [physics, stat]},
	author = {Raissi, Maziar and Yazdani, Alireza and Karniadakis, George Em},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.04327},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning, Physics - Fluid Dynamics, Statistics - Machine Learning},
}

@article{brunton_machine_2020,
	title = {Machine {Learning} for {Fluid} {Mechanics}},
	volume = {52},
	issn = {0066-4189, 1545-4479},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-fluid-010719-060214},
	doi = {10.1146/annurev-fluid-010719-060214},
	abstract = {The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful informationprocessing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.},
	language = {en},
	number = {1},
	urldate = {2020-10-28},
	journal = {Annual Review of Fluid Mechanics},
	author = {Brunton, Steven L. and Noack, Bernd R. and Koumoutsakos, Petros},
	month = jan,
	year = {2020},
	pages = {477--508},
}

@article{jin_nsfnets_2020,
	title = {{NSFnets} ({Navier}-{Stokes} {Flow} nets): {Physics}-informed neural networks for the incompressible {Navier}-{Stokes} equations},
	shorttitle = {{NSFnets} ({Navier}-{Stokes} {Flow} nets)},
	url = {http://arxiv.org/abs/2003.06496},
	abstract = {We employ physics-informed neural networks (PINNs) to simulate the incompressible flows ranging from laminar to turbulent flows. We perform PINN simulations by considering two different formulations of the Navier-Stokes equations: the velocity-pressure (VP) formulation and the vorticity-velocity (VV) formulation. We refer to these specific PINNs for the Navier-Stokes flow nets as NSFnets. Analytical solutions and direct numerical simulation (DNS) databases provide proper initial and boundary conditions for the NSFnet simulations. The spatial and temporal coordinates are the inputs of the NSFnets, while the instantaneous velocity and pressure fields are the outputs for the VP-NSFnet, and the instantaneous velocity and vorticity fields are the outputs for the VV-NSFnet. These two different forms of the Navier-Stokes equations together with the initial and boundary conditions are embedded into the loss function of the PINNs. No data is provided for the pressure to the VP-NSFnet, which is a hidden state and is obtained via the incompressibility constraint without splitting the equations. We obtain good accuracy of the NSFnet simulation results upon convergence of the loss function, verifying that NSFnets can effectively simulate complex incompressible flows using either the VP or the VV formulations. We also perform a systematic study on the weights used in the loss function for the data/physics components and investigate a new way of computing the weights dynamically to accelerate training and enhance accuracy. Our results suggest that the accuracy of NSFnets, for both laminar and turbulent flows, can be improved with proper tuning of weights (manual or dynamic) in the loss function.},
	language = {en},
	urldate = {2020-10-27},
	journal = {arXiv:2003.06496 [physics]},
	author = {Jin, Xiaowei and Cai, Shengze and Li, Hui and Karniadakis, George Em},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.06496},
	keywords = {Physics - Computational Physics},
}

@book{noauthor_notitle_nodate,
}

@article{wu_inflow_2017,
	title = {Inflow {Turbulence} {Generation} {Methods}},
	volume = {49},
	url = {https://doi.org/10.1146/annurev-fluid-010816-060322},
	doi = {10.1146/annurev-fluid-010816-060322},
	abstract = {Research activities on inflow turbulence generation methods have been vigorous over the past quarter century, accompanying advances in eddy-resolving computations of spatially developing turbulent flows with direct numerical simulation, large-eddy simulation (LES), and hybrid Reynolds-averaged Navier-Stokes–LES. The weak recycling method, rooted in scaling arguments on the canonical incompressible boundary layer, has been applied to supersonic boundary layer, rough surface boundary layer, and microscale urban canopy LES coupled with mesoscale numerical weather forecasting. Synthetic methods, originating from analytical approximation to homogeneous isotropic turbulence, have branched out into several robust methods, including the synthetic random Fourier method, synthetic digital filtering method, synthetic coherent eddy method, and synthetic volume forcing method. This article reviews major progress in inflow turbulence generation methods with an emphasis on fundamental ideas, key milestones, representative applications, and critical issues. Directions for future research in the field are also highlighted.},
	number = {1},
	urldate = {2020-10-27},
	journal = {Annual Review of Fluid Mechanics},
	author = {Wu, Xiaohua},
	year = {2017},
	note = {\_eprint: https://doi.org/10.1146/annurev-fluid-010816-060322},
	pages = {23--49},
}

@article{kim_divergence-free_2013,
	title = {Divergence-free turbulence inflow conditions for large-eddy simulations with incompressible flow solvers},
	volume = {84},
	issn = {0045-7930},
	url = {http://www.sciencedirect.com/science/article/pii/S0045793013002132},
	doi = {10.1016/j.compfluid.2013.06.001},
	abstract = {Synthetic turbulence for inflow conditions formulated on a 2-D plane generally produces unphysically large pressure fluctuations in direct numerical and large-eddy simulations. To reduce such artificial fluctuations a divergence-free method is developed with incompressible flow solvers. The procedure of the velocity–pressure solvers is slightly modified on a vertical plane near (rather than at) the inlet by inserting the synthetic turbulence on that plane during the procedure. Simple analytic and numerical error estimations are used to show that the impact of the modified solvers on solution accuracy is small. The final synthetic turbulence satisfies the divergence-free condition. No additional CPU time is required to achieve this condition. The method was tested via simulations of a plane channel flow with Reτ=395. Reynolds stresses, wall skin friction and power spectra of velocity fluctuations are compared with those obtained from using periodic inlet–outlet boundary conditions. In particular, the variances and power spectra of pressure fluctuations are shown to be accurately predicted only when the divergence-free inlet condition is used.},
	language = {en},
	urldate = {2020-10-27},
	journal = {Computers \& Fluids},
	author = {Kim, Yusik and Castro, Ian P. and Xie, Zheng-Tong},
	month = sep,
	year = {2013},
	keywords = {Divergence-free, Inflow condition, Peak loading, Pressure fluctuations},
	pages = {56--68},
}

@article{meng_composite_2020,
	title = {A composite neural network that learns from multi-fidelity data: {Application} to function approximation and inverse {PDE} problems},
	volume = {401},
	issn = {00219991},
	shorttitle = {A composite neural network that learns from multi-fidelity data},
	url = {http://arxiv.org/abs/1903.00104},
	doi = {10.1016/j.jcp.2019.109020},
	abstract = {We propose a new composite neural network (NN) that can be trained based on multi-fidelity data. It is comprised of three NNs, with the first NN trained using the low-fidelity data and coupled to two high-fidelity NNs, one with activation functions and another one without, in order to discover and exploit nonlinear and linear correlations, respectively, between the low-fidelity and the high-fidelity data. We first demonstrate the accuracy of the new multi-fidelity NN for approximating some standard benchmark functions but also a 20-dimensional function. Subsequently, we extend the recently developed physics-informed neural networks (PINNs) to be trained with multi-fidelity data sets (MPINNs). MPINNs contain four fully-connected neural networks, where the first one approximates the low-fidelity data, while the second and third construct the correlation between the low- and high-fidelity data and produce the multi-fidelity approximation, which is then used in the last NN that encodes the partial differential equations (PDEs). Specifically, in the two high-fidelity NNs a relaxation parameter is introduced, which can be optimized to combine the linear and nonlinear sub-networks. By optimizing this parameter, the present model is capable of learning both the linear and complex nonlinear correlations between the low- and high-fidelity data adaptively. By training the MPINNs, we can:(1) obtain the correlation between the low- and high-fidelity data, (2) infer the quantities of interest based on a few scattered data, and (3) identify the unknown parameters in the PDEs. In particular, we employ the MPINNs to learn the hydraulic conductivity field for unsaturated flows as well as the reactive models for reactive transport. The results demonstrate that MPINNs can achieve relatively high accuracy based on a very small set of high-fidelity data.},
	urldate = {2020-10-26},
	journal = {Journal of Computational Physics},
	author = {Meng, Xuhui and Karniadakis, George Em},
	month = jan,
	year = {2020},
	note = {arXiv: 1903.00104},
	keywords = {Physics - Computational Physics},
	pages = {109020},
}

@article{mortensen_high_2016,
	title = {High performance {Python} for direct numerical simulations of turbulent flows},
	volume = {203},
	issn = {00104655},
	url = {http://arxiv.org/abs/1602.03638},
	doi = {10.1016/j.cpc.2016.02.005},
	abstract = {Direct Numerical Simulations (DNS) of the Navier Stokes equations is an invaluable research tool in ﬂuid dynamics. Still, there are few publicly available research codes and, due to the heavy number crunching implied, available codes are usually written in low-level languages such as C/C++ or Fortran. In this paper we describe a pure scientiﬁc Python pseudo-spectral DNS code that nearly matches the performance of C++ for thousands of processors and billions of unknowns. We also describe a version optimized through Cython, that is found to match the speed of C++. The solvers are written from scratch in Python, both the mesh, the MPI domain decomposition, and the temporal integrators. The solvers have been veriﬁed and benchmarked on the Shaheen supercomputer at the KAUST supercomputing laboratory, and we are able to show very good scaling up to several thousand cores.},
	language = {en},
	urldate = {2020-10-26},
	journal = {Computer Physics Communications},
	author = {Mortensen, Mikael and Langtangen, Hans Petter},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.03638},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Mathematical Software},
	pages = {53--65},
}

@article{zhang_learning_2019,
	title = {Learning in {Modal} {Space}: {Solving} {Time}-{Dependent} {Stochastic} {PDEs} {Using} {Physics}-{Informed} {Neural} {Networks}},
	shorttitle = {Learning in {Modal} {Space}},
	url = {http://arxiv.org/abs/1905.01205},
	abstract = {One of the open problems in scientific computing is the long-time integration of nonlinear stochastic partial differential equations (SPDEs). We address this problem by taking advantage of recent advances in scientific machine learning and the dynamically orthogonal (DO) and bi-orthogonal (BO) methods for representing stochastic processes. Specifically, we propose two new Physics-Informed Neural Networks (PINNs) for solving time-dependent SPDEs, namely the NN-DO/BO methods, which incorporate the DO/BO constraints into the loss function with an implicit form instead of generating explicit expressions for the temporal derivatives of the DO/BO modes. Hence, the proposed methods overcome some of the drawbacks of the original DO/BO methods: we do not need the assumption that the covariance matrix of the random coefficients is invertible as in the original DO method, and we can remove the assumption of no eigenvalue crossing as in the original BO method. Moreover, the NN-DO/BO methods can be used to solve time-dependent stochastic inverse problems with the same formulation and computational complexity as for forward problems. We demonstrate the capability of the proposed methods via several numerical examples: (1) A linear stochastic advection equation with deterministic initial condition where the original DO/BO method would fail; (2) Long-time integration of the stochastic Burgers' equation with many eigenvalue crossings during the whole time evolution where the original BO method fails. (3) Nonlinear reaction diffusion equation: we consider both the forward and the inverse problem, including noisy initial data, to investigate the flexibility of the NN-DO/BO methods in handling inverse and mixed type problems. Taken together, these simulation results demonstrate that the NN-DO/BO methods can be employed to effectively quantify uncertainty propagation in a wide range of physical problems.},
	urldate = {2020-10-26},
	journal = {arXiv:1905.01205 [physics, stat]},
	author = {Zhang, Dongkun and Guo, Ling and Karniadakis, George Em},
	month = sep,
	year = {2019},
	note = {arXiv: 1905.01205},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{meng_ppinn_2020,
	title = {{PPINN}: {Parareal} physics-informed neural network for time-dependent {PDEs}},
	volume = {370},
	issn = {0045-7825},
	shorttitle = {{PPINN}},
	url = {http://www.sciencedirect.com/science/article/pii/S0045782520304357},
	doi = {10.1016/j.cma.2020.113250},
	abstract = {Physics-informed neural networks (PINNs) encode physical conservation laws and prior physical knowledge into the neural networks, ensuring the correct physics is represented accurately while alleviating the need for supervised learning to a great degree (Raissi et al., 2019). While effective for relatively short-term time integration, when long time integration of the time-dependent PDEs is sought, the time–space domain may become arbitrarily large and hence training of the neural network may become prohibitively expensive. To this end, we develop a parareal physics-informed neural network (PPINN), hence decomposing a long-time problem into many independent short-time problems supervised by an inexpensive/fast coarse-grained (CG) solver. In particular, the serial CG solver is designed to provide approximate predictions of the solution at discrete times, while initiate many fine PINNs simultaneously to correct the solution iteratively. There is a two-fold benefit from training PINNs with small-data sets rather than working on a large-data set directly, i.e., training of individual PINNs with small-data is much faster, while training the fine PINNs can be readily parallelized. Consequently, compared to the original PINN approach, the proposed PPINN approach may achieve a significant speed-up for long-time integration of PDEs, assuming that the CG solver is fast and can provide reasonable predictions of the solution, hence aiding the PPINN solution to converge in just a few iterations. To investigate the PPINN performance on solving time-dependent PDEs, we first apply the PPINN to solve the Burgers equation, and subsequently we apply the PPINN to solve a two-dimensional nonlinear diffusion–reaction equation. Our results demonstrate that PPINNs converge in a few iterations with significant speed-ups proportional to the number of time-subdomains employed.},
	language = {en},
	urldate = {2020-10-26},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Meng, Xuhui and Li, Zhen and Zhang, Dongkun and Karniadakis, George Em},
	month = oct,
	year = {2020},
	keywords = {Deep neural network, Long-time integration, Machine learning, Multiscale, PINN, Parallel-in-time},
	pages = {113250},
}

@article{zhao_rans_2020,
	title = {{RANS} turbulence model development using {CFD}-driven machine learning},
	volume = {411},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S002199912030187X},
	doi = {10.1016/j.jcp.2020.109413},
	abstract = {This paper presents a novel CFD-driven machine learning framework to develop Reynolds-averaged Navier-Stokes (RANS) models. The CFD-driven training is an extension of the gene expression programming method Weatheritt and Sandberg (2016) [8], but crucially the fitness of candidate models is now evaluated by running RANS calculations in an integrated way, rather than using an algebraic function. Unlike other data-driven methods that fit the Reynolds stresses of trained models to high-fidelity data, the cost function for the CFD-driven training can be defined based on any flow feature from the CFD results. This extends the applicability of the method especially when the training data is limited. Furthermore, the resulting model, which is the one providing the most accurate CFD results at the end of the training, inherently shows good performance in RANS calculations. To demonstrate the potential of this new method, the CFD-driven machine learning approach is applied to model development for wake mixing in turbomachines. A new model is trained based on a high-pressure turbine case and then tested for three additional cases, all representative of modern turbine nozzles. Despite the geometric configurations and operating conditions being different among the cases, the predicted wake mixing profiles are significantly improved in all of these a posteriori tests. Moreover, the model equation is explicitly given and available for analysis, thus it could be deduced that the enhanced wake prediction is predominantly due to the extra diffusion introduced by the CFD-driven model.},
	language = {en},
	urldate = {2020-10-23},
	journal = {Journal of Computational Physics},
	author = {Zhao, Yaomin and Akolekar, Harshal D. and Weatheritt, Jack and Michelassi, Vittorio and Sandberg, Richard D.},
	month = jun,
	year = {2020},
	keywords = {Machine learning, Turbulence modelling, Wake mixing},
	pages = {109413},
}

@article{sirignano_dpm_2020,
	title = {{DPM}: {A} deep learning {PDE} augmentation method with application to large-eddy simulation},
	volume = {423},
	issn = {0021-9991},
	shorttitle = {{DPM}},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999120305854},
	doi = {10.1016/j.jcp.2020.109811},
	abstract = {A framework is introduced that leverages known physics to reduce overfitting in machine learning for scientific applications. The partial differential equation (PDE) that expresses the physics is augmented with a neural network that uses available data to learn a description of the corresponding unknown or unrepresented physics. Training within this combined system corrects for missing, unknown, or erroneously represented physics, including discretization errors associated with the PDE's numerical solution. For optimization of the network within the PDE, an adjoint PDE is solved to provide high-dimensional gradients, and a stochastic adjoint method (SAM) further accelerates training. The approach is demonstrated for large-eddy simulation (LES) of turbulence. High-fidelity direct numerical simulations (DNS) of decaying isotropic turbulence provide the training data used to learn sub-filter-scale closures for the filtered Navier–Stokes equations. Out-of-sample comparisons show that the deep learning PDE method outperforms widely-used models, even for filter sizes so large that they become qualitatively incorrect. It also significantly outperforms the same neural network when a priori trained based on simple data mismatch, not accounting for the full PDE. Measures of discretization errors, which are well-known to be consequential in LES, point to the importance of the unified training formulation's design, which without modification corrects for them. For comparable accuracy, simulation runtime is significantly reduced. A relaxation of the typical discrete enforcement of the divergence-free constraint in the solver is also successful, instead allowing the DPM to approximately enforce incompressibility physics. Since the training loss function is not restricted to correspond directly to the closure to be learned, training can incorporate diverse data, including experimental data.},
	language = {en},
	urldate = {2020-10-23},
	journal = {Journal of Computational Physics},
	author = {Sirignano, Justin and MacArt, Jonathan F. and Freund, Jonathan B.},
	month = dec,
	year = {2020},
	keywords = {Deep learning, Large-eddy simulation, Scientific machine learning, Sub-grid-scale modeling, Turbulence simulation},
	pages = {109811},
}

@article{huang_general_2010,
	title = {A general inflow turbulence generator for large eddy simulation},
	volume = {98},
	issn = {0167-6105},
	url = {http://www.sciencedirect.com/science/article/pii/S0167610510000644},
	doi = {10.1016/j.jweia.2010.06.002},
	abstract = {This paper presents a general inflow turbulence generator for numerical simulation of a spatially correlated turbulent flow field. The novel inflow turbulence generator is developed based on the discretizing and synthesizing random flow generation (DSRFG) technique that is proved to be able to generate a fluctuating turbulent flow field satisfying any given spectrum. Then, the techniques of aligning and remapping are incorporated in the inflow turbulence generator for generation of an inhomogeneous and anisotropic turbulent flow field following arbitrary target spectra in three orthogonal directions. The performance of the present inflow turbulence generator is compared with that of Smirnov’s random flow generation (RFG) method. Detailed numerical studies show that the proposed inflow turbulence generator can strictly guarantee divergence-free condition without any additional improving step and synthetically generate inflows satisfying prescribed spatial anisotropy and correlation conditions. It is demonstrated through numerical examples that the inflow turbulence generator developed in this study is an effective tool for generation of a spatially correlated turbulent flow field for large eddy simulation (LES).},
	language = {en},
	number = {10},
	urldate = {2020-10-23},
	journal = {Journal of Wind Engineering and Industrial Aerodynamics},
	author = {Huang, S. H. and Li, Q. S. and Wu, J. R.},
	month = oct,
	year = {2010},
	keywords = {Computational fluid dynamics, Computational wind engineering, Large eddy simulation, Random flow generation},
	pages = {600--617},
}

@article{kroger_generation_2018,
	title = {Generation of divergence free synthetic inflow turbulence with arbitrary anisotropy},
	volume = {165},
	issn = {0045-7930},
	url = {http://www.sciencedirect.com/science/article/pii/S0045793018300264},
	doi = {10.1016/j.compfluid.2018.01.018},
	abstract = {The paper presents an improvement to the Turbulent Spot method for generation of synthetic turbulence. Earlier versions of the Turbulent Spot method and the Synthetic Eddy method were only able to produce turbulence which does not obey the continuity constraint in general. This was only possible for special cases (isotropic or near-isotropic turbulence). The proposed extension enables the generation of arbitrary anisotropic turbulence and fulfillment of the continuity constraint at the same time. This is made possible by the introduction of a new type of turbulent structure. The derivation of the internal velocity field is given. Also, expressions for the statistical properties of the new structure are derived. The performance of the proposed extension is illustrated on generic test cases.},
	language = {en},
	urldate = {2020-10-23},
	journal = {Computers \& Fluids},
	author = {Kröger, Hannes and Kornev, Nikolai},
	month = mar,
	year = {2018},
	keywords = {Inflow boundary condition, Large-Eddy simulation, Synthetic Eddy method, Turbulence synthesis, Turbulent spot method},
	pages = {78--88},
}

@article{castro_time_2013,
	title = {A time and space correlated turbulence synthesis method for {Large} {Eddy} {Simulations}},
	volume = {235},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999112006389},
	doi = {10.1016/j.jcp.2012.10.035},
	abstract = {In the present work the problem of generating synthesized turbulence at inflow boundaries of the simulation domain is addressed in the context of the Large Eddy Simulation (LES) method. To represent adequately certain statistical properties of a turbulent process, we propose a synthesized turbulence method which is based on previous works (Huang et al., 2010; Smirnov et al., 2001) [15], [28]. For this purpose, time and space correlations are introduced strictly in the mathematical formulation of the synthetic turbulence inflow data. It is demonstrated that the proposed approach inherits the properties of the methods on which it is based while presents some particular advantages as well. The strategy of imposing conditions on the inlet velocity field through turbulence synthesis is implemented in the parallel multiphysics code called PETSc-FEM (http://www.cimec.org.ar/petscfem) primarily targeted to calculations throughout finite elements on general unstructured 2D and 3D grids. We present several numerical tests in order to validate and evaluate the method describing the dynamic phenomena that take place in “real-life” problems, such as a swirling turbulent flow inside a diffuser and the airflow around a vehicle model inside a wind tunnel at high Reynolds number.},
	language = {en},
	urldate = {2020-10-23},
	journal = {Journal of Computational Physics},
	author = {Castro, Hugo G. and Paz, Rodrigo R.},
	month = feb,
	year = {2013},
	keywords = {Inlet boundary conditions, LES method, Navier–Stokes equations, Turbulence synthesis},
	pages = {742--763},
}

@misc{noauthor_generation_nodate,
	title = {Generation of divergence free synthetic inflow turbulence with arbitrary anisotropy {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0045793018300264?token=08104A741A410345549EFB3748756492E347825BBAF04F3035BE02AC2F72634EB5729CF2FDE7B32E81F52AB97CA0AA48},
	language = {en},
	urldate = {2020-10-23},
	doi = {10.1016/j.compfluid.2018.01.018},
}

@misc{noauthor_time_nodate,
	title = {A time and space correlated turbulence synthesis method for {Large} {Eddy} {Simulations} {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0021999112006389?token=01F16141307816816076EE07EB7691C38535B61D53F4E5AA5F1B56ECB1A0B7BE595B30FD51435B22D0FFDD1C22F8EC50},
	language = {en},
	urldate = {2020-10-23},
	doi = {10.1016/j.jcp.2012.10.035},
}

@inproceedings{davidson_hybrid_2008,
	address = {Berlin, Heidelberg},
	series = {Notes on {Numerical} {Fluid} {Mechanics} and {Multidisciplinary} {Design}},
	title = {Hybrid {LES}-{RANS}: {Inlet} {Boundary} {Conditions} for {Flows} with {Recirculation}},
	isbn = {978-3-540-77815-8},
	shorttitle = {Hybrid {LES}-{RANS}},
	doi = {10.1007/978-3-540-77815-8_6},
	abstract = {The paper evaluates a new method for prescribing synthesized turbulent inlet boundary conditions. When making LES, DES or hybrid LES-RANS, a precursor channel DNS is often used. The disadvantage of this method is that it is difficult to re-scale the DNS fluctuations to higher Reynolds numbers. In the present work, synthesized isotropic turbulent fluctuations are generated at the inlet plane with a prescribed turbulent length scale and energy spectrum. A large number of independent realizations are generated. A correlation in time between these realizations is introduced via an asymmetric, non-truncated time filter. In this way the turbulent time scale of the synthesized isotropic turbulent fluctuations is prescribed.},
	language = {en},
	booktitle = {Advances in {Hybrid} {RANS}-{LES} {Modelling}},
	publisher = {Springer},
	author = {Davidson, Lars},
	editor = {Peng, Shia-Hui and Haase, Werner},
	year = {2008},
	keywords = {Inlet Boundary Condition, Inlet Plane, Large Eddy Simulation, Resolve Shear Stress, Spanwise Direction},
	pages = {55--66},
}

@article{deng_time-resolved_2019,
	title = {Time-resolved turbulent velocity field reconstruction using a long short-term memory ({LSTM})-based artificial intelligence framework},
	volume = {31},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.5111558},
	doi = {10.1063/1.5111558},
	abstract = {This paper focuses on the time-resolved turbulent flow reconstruction from discrete point measurements and non-time-resolved (non-TR) particle image velocimetry (PIV) measurements using an artificial intelligence framework based on long short-term memory (LSTM). To this end, an LSTM-based proper orthogonal decomposition (POD) model is proposed to establish the relationship between velocity signals and time-varying POD coefficients obtained from non-TR-PIV measurements. An inverted flag flow at Re = 6200 was experimentally measured using TR-PIV at a sampling rate of 2000 Hz for the construction of training and testing datasets and for validation. Two different time-step configurations were employed to investigate the robustness and learning ability of the LSTM-based POD model: a single-time-step structure and a multi-time-step structure. The results demonstrate that the LSTM-based POD model has great potential for time-series reconstruction since it can successfully recover the temporal revolution of POD coefficients with remarkable accuracy, even in high-order POD modes. The time-resolved flow fields can be reconstructed well using coefficients obtained from the proposed model. In addition, a relative error reconstruction analysis was conducted to compare the performance of different time-step configurations further, and the results demonstrated that the POD model with multi-time-step structure provided better reconstruction of the flow fields.},
	number = {7},
	urldate = {2020-10-22},
	journal = {Physics of Fluids},
	author = {Deng, Zhiwen (邓志文) and Chen, Yujia (陈宇佳) and Liu, Yingzheng (刘应征) and Kim, Kyung Chun (김경천)},
	month = jul,
	year = {2019},
	note = {Publisher: American Institute of Physics},
	pages = {075108},
}

@article{sanchez-gonzalez_hamiltonian_2019,
	title = {Hamiltonian {Graph} {Networks} with {ODE} {Integrators}},
	url = {http://arxiv.org/abs/1909.12790},
	abstract = {We introduce an approach for imposing physically informed inductive biases in learned simulation models. We combine graph networks with a differentiable ordinary differential equation integrator as a mechanism for predicting future states, and a Hamiltonian as an internal representation. We find that our approach outperforms baselines without these biases in terms of predictive accuracy, energy accuracy, and zero-shot generalization to time-step sizes and integrator orders not experienced during training. This advances the state-of-the-art of learned simulation, and in principle is applicable beyond physical domains.},
	urldate = {2020-10-22},
	journal = {arXiv:1909.12790 [physics]},
	author = {Sanchez-Gonzalez, Alvaro and Bapst, Victor and Cranmer, Kyle and Battaglia, Peter},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.12790},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{bronstein_geometric_2017,
	title = {Geometric deep learning: going beyond {Euclidean} data},
	volume = {34},
	issn = {1053-5888, 1558-0792},
	shorttitle = {Geometric deep learning},
	url = {http://arxiv.org/abs/1611.08097},
	doi = {10.1109/MSP.2017.2693418},
	abstract = {Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.},
	number = {4},
	urldate = {2020-10-22},
	journal = {IEEE Signal Processing Magazine},
	author = {Bronstein, Michael M. and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
	month = jul,
	year = {2017},
	note = {arXiv: 1611.08097},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {18--42},
}

@article{maulik_accelerating_2020,
	title = {Accelerating {RANS} simulations using a data-driven framework for eddy-viscosity emulation},
	url = {http://arxiv.org/abs/1910.10878},
	abstract = {Reynolds-averaged Navier-Stokes (RANS) equations for steady-state assessment of incompressible turbulent flows remain the workhorse for practical computational fluid dynamics (CFD) applications, and improvements in speed or accuracy have the potential to affect a diverse range of sectors. We introduce a machine learning framework for the acceleration of RANS to predict steady-state turbulent eddy viscosities, given the initial conditions. This surrogate model for the turbulent eddy viscosity is assessed for parametric interpolation, while numerically solving for the pressure and velocity equations to steady-state, thus representing a framework that is hybridized with machine learning. We achieve accurate steady-state results with a significant reduction in solution time when compared to those obtained by the Spalart-Allmaras one-equation model. Most notably the proposed methodology allows for considerably larger relaxation factors for the steady-state velocity and pressure solvers. Our assessments are made for a backward-facing step with considerable mesh anisotropy and separation to represent a practical CFD application. For test experiments with varying inlet velocity conditions, we see time-to-solution reductions around a factor of 5. Similar results are obtained for a surrogate modeling strategy that generalizes across varying step heights. The proposed framework represents an excellent opportunity for the rapid exploration of large parameter spaces that prove prohibitive when utilizing turbulence closure models with multiple coupled partial differential equations.},
	urldate = {2020-10-22},
	journal = {arXiv:1910.10878 [physics]},
	author = {Maulik, Romit and Sharma, Himanshu and Patel, Saumil and Lusch, Bethany and Jennings, Elise},
	month = may,
	year = {2020},
	note = {arXiv: 1910.10878},
	keywords = {Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{cranmer_discovering_2020-1,
	title = {Discovering {Symbolic} {Models} from {Deep} {Learning} with {Inductive} {Biases}},
	url = {http://arxiv.org/abs/2006.11287},
	abstract = {We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example-a detailed dark matter simulation-and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distribution data better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.},
	urldate = {2020-10-21},
	journal = {arXiv:2006.11287 [astro-ph, physics:physics, stat]},
	author = {Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.11287},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{cranmer_discovering_2020-2,
	title = {Discovering {Symbolic} {Models} from {Deep} {Learning} with {Inductive} {Biases}},
	url = {http://arxiv.org/abs/2006.11287},
	abstract = {We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we ﬁrst encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We ﬁnd the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example—a detailed dark matter simulation—and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distributiondata better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.},
	language = {en},
	urldate = {2020-10-21},
	journal = {arXiv:2006.11287 [astro-ph, physics:physics, stat]},
	author = {Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.11287},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
}

@article{cranmer_lagrangian_2020,
	title = {Lagrangian {Neural} {Networks}},
	url = {http://arxiv.org/abs/2003.04630},
	abstract = {Accurate models of the world are built upon notions of its underlying symmetries. In physics, these symmetries correspond to conservation laws, such as for energy and momentum. Yet even though neural network models see increasing use in the physical sciences, they struggle to learn these symmetries. In this paper, we propose Lagrangian Neural Networks (LNNs), which can parameterize arbitrary Lagrangians using neural networks. In contrast to models that learn Hamiltonians, LNNs do not require canonical coordinates, and thus perform well in situations where canonical momenta are unknown or difficult to compute. Unlike previous approaches, our method does not restrict the functional form of learned energies and will produce energy-conserving models for a variety of tasks. We test our approach on a double pendulum and a relativistic particle, demonstrating energy conservation where a baseline approach incurs dissipation and modeling relativity without canonical coordinates where a Hamiltonian approach fails. Finally, we show how this model can be applied to graphs and continuous systems using a Lagrangian Graph Network, and demonstrate it on the 1D wave equation.},
	urldate = {2020-10-21},
	journal = {arXiv:2003.04630 [physics, stat]},
	author = {Cranmer, Miles and Greydanus, Sam and Hoyer, Stephan and Battaglia, Peter and Spergel, David and Ho, Shirley},
	month = jul,
	year = {2020},
	note = {arXiv: 2003.04630},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability, Statistics - Machine Learning},
}

@article{mohan_compressed_2019,
	title = {Compressed {Convolutional} {LSTM}: {An} {Efficient} {Deep} {Learning} framework to {Model} {High} {Fidelity} {3D} {Turbulence}},
	shorttitle = {Compressed {Convolutional} {LSTM}},
	url = {http://arxiv.org/abs/1903.00033},
	abstract = {High-fidelity modeling of turbulent flows is one of the major challenges in computational physics, with diverse applications in engineering, earth sciences and astrophysics, among many others. The rising popularity of high-fidelity computational fluid dynamics (CFD) techniques like direct numerical simulation (DNS) and large eddy simulation (LES) have made significant inroads into the problem. However, they remain out of reach for many practical three-dimensional flows characterized by extremely large domains and transient phenomena. Therefore designing efficient and accurate data-driven generative approaches to model turbulence is a necessity. We propose a novel training approach for dimensionality reduction and spatio-temporal modeling of the three-dimensional dynamics of turbulence using a combination of Convolutional autoencoder and the Convolutional LSTM neural networks. The quality of the emulated turbulent fields is assessed with rigorous physics-based statistical tests, instead of visual assessments. The results show significant promise in the training methodology to generate physically consistent turbulent flows at a small fraction of the computing resources required for DNS.},
	urldate = {2020-10-20},
	journal = {arXiv:1903.00033 [nlin, physics:physics]},
	author = {Mohan, Arvind and Daniel, Don and Chertkov, Michael and Livescu, Daniel},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.00033},
	keywords = {Nonlinear Sciences - Chaotic Dynamics, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{kingma_glow_2018,
	title = {Glow: {Generative} {Flow} with {Invertible} 1x1 {Convolutions}},
	shorttitle = {Glow},
	url = {http://arxiv.org/abs/1807.03039},
	abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
	urldate = {2020-10-20},
	journal = {arXiv:1807.03039 [cs, stat]},
	author = {Kingma, Diederik P. and Dhariwal, Prafulla},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.03039},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{jacobsen_i-revnet_2018,
	title = {i-{RevNet}: {Deep} {Invertible} {Networks}},
	shorttitle = {i-{RevNet}},
	url = {http://arxiv.org/abs/1802.07088},
	abstract = {It is widely believed that the success of deep convolutional networks is based on progressively discarding uninformative variability about the input with respect to the problem at hand. This is supported empirically by the difficulty of recovering images from their hidden representations, in most commonly used network architectures. In this paper we show via a one-to-one mapping that this loss of information is not a necessary condition to learn representations that generalize well on complicated problems, such as ImageNet. Via a cascade of homeomorphic layers, we build the i-RevNet, a network that can be fully inverted up to the final projection onto the classes, i.e. no information is discarded. Building an invertible architecture is difficult, for one, because the local inversion is ill-conditioned, we overcome this by providing an explicit inverse. An analysis of i-RevNets learned representations suggests an alternative explanation for the success of deep networks by a progressive contraction and linear separation with depth. To shed light on the nature of the model learned by the i-RevNet we reconstruct linear interpolations between natural image representations.},
	urldate = {2020-10-20},
	journal = {arXiv:1802.07088 [cs, stat]},
	author = {Jacobsen, Jörn-Henrik and Smeulders, Arnold and Oyallon, Edouard},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.07088},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{deng_time-resolved_2019-1,
	title = {Time-resolved turbulent velocity field reconstruction using a long short-term memory ({LSTM})-based artificial intelligence framework},
	volume = {31},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/1.5111558},
	doi = {10.1063/1.5111558},
	abstract = {This paper focuses on the time-resolved turbulent flow reconstruction from discrete point measurements and non-time-resolved (non-TR) particle image velocimetry (PIV) measurements using an artificial intelligence framework based on long short-term memory (LSTM). To this end, an LSTM-based proper orthogonal decomposition (POD) model is proposed to establish the relationship between velocity signals and time-varying POD coefficients obtained from non-TR-PIV measurements. An inverted flag flow at Re = 6200 was experimentally measured using TR-PIV at a sampling rate of 2000 Hz for the construction of training and testing datasets and for validation. Two different time-step configurations were employed to investigate the robustness and learning ability of the LSTM-based POD model: a single-time-step structure and a multi-time-step structure. The results demonstrate that the LSTM-based POD model has great potential for time-series reconstruction since it can successfully recover the temporal revolution of POD coefficients with remarkable accuracy, even in high-order POD modes. The time-resolved flow fields can be reconstructed well using coefficients obtained from the proposed model. In addition, a relative error reconstruction analysis was conducted to compare the performance of different time-step configurations further, and the results demonstrated that the POD model with multi-time-step structure provided better reconstruction of the flow fields.},
	number = {7},
	urldate = {2020-10-20},
	journal = {Physics of Fluids},
	author = {Deng, Zhiwen (邓志文) and Chen, Yujia (陈宇佳) and Liu, Yingzheng (刘应征) and Kim, Kyung Chun (김경천)},
	month = jul,
	year = {2019},
	note = {Publisher: American Institute of Physics},
	pages = {075108},
}

@article{eivazi_deep_2020,
	title = {Deep neural networks for nonlinear model order reduction of unsteady flows},
	volume = {32},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/5.0020526},
	doi = {10.1063/5.0020526},
	abstract = {Unsteady fluid systems are nonlinear high-dimensional dynamical systems that may exhibit multiple complex phenomena in both time and space. Reduced Order Modeling (ROM) of fluid flows has been an active research topic in the recent decade with the primary goal to decompose complex flows into a set of features most important for future state prediction and control, typically using a dimensionality reduction technique. In this work, a novel data-driven technique based on the power of deep neural networks for ROM of the unsteady fluid flows is introduced. An autoencoder network is used for nonlinear dimension reduction and feature extraction as an alternative for singular value decomposition (SVD). Then, the extracted features are used as an input for a long short-term memory (LSTM) network to predict the velocity field at future time instances. The proposed autoencoder-LSTM method is compared with non-intrusive reduced order models based on dynamic mode decomposition (DMD) and proper orthogonal decomposition. Moreover, an autoencoder-DMD algorithm is introduced for ROM, which uses the autoencoder network for dimensionality reduction rather than SVD rank truncation. The results show that the autoencoder-LSTM method is considerably capable of predicting fluid flow evolution, where higher values for the coefficient of determination R2 are obtained using autoencoder-LSTM compared to other models.},
	number = {10},
	urldate = {2020-10-20},
	journal = {Physics of Fluids},
	author = {Eivazi, Hamidreza and Veisi, Hadi and Naderi, Mohammad Hossein and Esfahanian, Vahid},
	month = oct,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {105104},
}

@article{pawar_interface_2020,
	title = {Interface learning in fluid dynamics: {Statistical} inference of closures within micro–macro-coupling models},
	volume = {32},
	issn = {1070-6631},
	shorttitle = {Interface learning in fluid dynamics},
	url = {https://aip.scitation.org/doi/10.1063/5.0024670},
	doi = {10.1063/5.0024670},
	abstract = {Many complex multiphysics systems in fluid dynamics involve using solvers with varied levels of approximations in different regions of the computational domain to resolve multiple spatiotemporal scales present in the flow. The accuracy of the solution is governed by how the information is exchanged between these solvers at the interface, and several methods have been devised for such coupling problems. In this Letter, we construct a data-driven model by spatially coupling a microscale lattice Boltzmann method (LBM) solver and macroscale finite difference method (FDM) solver for reaction–diffusion systems. The coupling between the micro–macro-solvers has one to many mapping at the interface leading to the interface closure problem, and we propose a statistical inference method based on neural networks to learn this closure relation. The performance of the proposed framework in a bifidelity setting partitioned between the FDM and LBM domains shows its promise for complex systems where analytical relations between micro–macro-solvers are not available.},
	number = {9},
	urldate = {2020-10-20},
	journal = {Physics of Fluids},
	author = {Pawar, Suraj and Ahmed, Shady E. and San, Omer},
	month = sep,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {091704},
}

@article{wang_efficient_2020,
	title = {Efficient deep learning techniques for multiphase flow simulation in heterogeneous porousc media},
	volume = {401},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999119306734},
	doi = {10.1016/j.jcp.2019.108968},
	abstract = {We present efficient deep learning techniques for approximating flow and transport equations for both single phase and two-phase flow problems. The proposed methods take advantages of the sparsity structures in the underlying discrete systems and can be served as efficient alternatives to the system solvers at the full order. In particular, for the flow problem, we design a network with convolutional and locally connected layers to perform model reductions. Moreover, we employ a custom loss function to impose local mass conservation constraints. This helps to preserve the physical property of velocity solution which we are interested in learning. For the saturation problem, we propose a residual type of network to approximate the dynamics. Our main contribution here is the design of custom sparsely connected layers which take into account the inherent sparse interaction between the input and output. After training, the approximated feed-forward map can be applied iteratively to predict solutions in the long range. Our trained networks, especially in two-phase flow where the maps are nonlinear, show their great potential in accurately approximating the underlying physical system and improvement in computational efficiency. Some numerical experiments are performed and discussed to demonstrate the performance of our proposed techniques.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Wang, Yating and Lin, Guang},
	month = jan,
	year = {2020},
	keywords = {Deep learning, Flow and transport, Machine learning, Multiphase flow, Neural network, Porous media},
	pages = {108968},
}

@article{gibou_sharp_2019,
	title = {Sharp interface approaches and deep learning techniques for multiphase flows},
	volume = {380},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999118303371},
	doi = {10.1016/j.jcp.2018.05.031},
	abstract = {We present a review on numerical methods for simulating multiphase and free surface flows. We focus in particular on numerical methods that seek to preserve the discontinuous nature of the solutions across the interface between phases. We provide a discussion on the Ghost-Fluid and Voronoi Interface methods, on the treatment of surface tension forces that avoid stringent time step restrictions, on adaptive grid refinement techniques for improved efficiency and on parallel computing approaches. We present the results of some simulations obtained with these treatments in two and three spatial dimensions. We also provide a discussion of Machine Learning and Deep Learning techniques in the context of multiphase flows and propose several future potential research thrusts for using deep learning to enhance the study and simulation of multiphase flows.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Gibou, Frederic and Hyde, David and Fedkiw, Ron},
	month = mar,
	year = {2019},
	keywords = {Ghost-fluid method, Multiphase flows, Parallel, Quadtree and octree, Surface tension, Voronoi interface method},
	pages = {442--463},
}

@article{ganti_data-driven_2020,
	title = {Data-driven surrogate modeling of multiphase flows using machine learning techniques},
	volume = {211},
	issn = {0045-7930},
	url = {http://www.sciencedirect.com/science/article/pii/S0045793020301985},
	doi = {10.1016/j.compfluid.2020.104626},
	abstract = {This study focuses on the development of a theoretical framework and corresponding algorithms to establish spatio-temporal surrogate models for multiphase flow processes using Gaussian process (GP) based machine learning technique trained by direct numerical simulation (DNS) data. The training (and testing) datasets are obtained by solving the incompressible form of the Navier Stokes equations with surface tension in an Eulerian reference frame. The liquid-gas interfacial evolution is resolved using a volume-of-fluid (VOF) interface capturing method. The overall framework proceeds in four steps: 1) design of experiments study to identify the training and testing points and generation of corresponding datasets using DNS calculations; 2) dimensionality reduction using proper orthogonal decomposition; 3) Gaussian process regression (supervised training) over the reduced training dataset over the entire range of operating conditions under consideration; and 4) Galerkin reconstruction and error quantification by comparing the emulated flowfields (at test conditions) with the testing dataset. The machine learning framework predicts both the spatial basis-functions and the time-coefficients, thus, predicting the entire flowfield in time and space. The capabilities of the algorithm are demonstrated for two canonical flow configurations: 1) flow over a circular cylinder for a range of Reynolds numbers from 10 to 200; and 2) diesel jet injected into a quiescent nitrogen environment at chamber pressure of 30 atm and room temperature conditions, and injection velocities from 10 to 55 m/s, corresponding to a range of gas-based Weber numbers from 11.5 to 348. The emulations from the learned GP algorithm show excellent agreement with high-fidelity numerical data for test conditions; average error (in both space and time) at the testing point of Re = 185 for the flow over cylinder case is 4.4\%, and for the diesel jet injection configuration at a testing point corresponding to velovity of 22.5 m/s is found to be 15.5\%. The tip penetration location of the diesel jet is predicted within 2.5\% of the DNS calculations. Corresponding to these two representative test points, speedup of 256 and 8000 is achieved for flow over cylinder and diesel jet atomization configurations, respectively. This paper represents the first effort of its kind on the development of a general machine learning framework to predict multiphase flows.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Computers \& Fluids},
	author = {Ganti, Himakar and Khare, Prashant},
	month = oct,
	year = {2020},
	keywords = {Atomization, Liquid Jets, Machine Learning, Multiphase Flows},
	pages = {104626},
}

@article{bao_computationally_2020,
	title = {Computationally efficient {CFD} prediction of bubbly flow using physics-guided deep learning},
	volume = {131},
	issn = {0301-9322},
	url = {http://www.sciencedirect.com/science/article/pii/S0301932219308043},
	doi = {10.1016/j.ijmultiphaseflow.2020.103378},
	abstract = {To realize efficient computational fluid dynamics (CFD) prediction of two-phase flow, a multi-scale framework was proposed in this paper by applying a physics-guided data-driven approach. Instrumental to this framework, Feature Similarity Measurement (FSM) technique was developed for error estimation in two-phase flow simulation using coarse-mesh CFD, to achieve a comparable accuracy as fine-mesh simulations with fast-running feature. By defining physics-guided parameters and variable gradients as physical features, FSM has the capability to capture the underlying local patterns in the coarse-mesh CFD simulation. Massive low-fidelity data and respective high-fidelity data are used to explore the underlying information relevant to the main simulation errors and the effects of phenomenological scaling. By learning from previous simulation data, a surrogate model using deep feedforward neural network (DFNN) can be developed and trained to estimate the simulation error of coarse-mesh CFD. In a demonstration case of two-phase bubbly flow, the DFNN model well captured and corrected the unphysical “peaks” in the velocity and void fraction profiles near the wall in the coarse-mesh configuration, even for extrapolative predictions. The research documented supports the feasibility of the physics-guided deep learning methods for coarse mesh CFD simulations which has a potential for the efficient industrial design.},
	language = {en},
	urldate = {2020-10-20},
	journal = {International Journal of Multiphase Flow},
	author = {Bao, Han and Feng, Jinyong and Dinh, Nam and Zhang, Hongbin},
	month = oct,
	year = {2020},
	keywords = {Coarse-mesh CFD, Data similarity, Deep learning, Physical feature, Two-phase bubbly flow},
	pages = {103378},
}

@article{wang_deep_2020,
	title = {Deep learning of free boundary and {Stefan} problems},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999120306884},
	doi = {10.1016/j.jcp.2020.109914},
	abstract = {Free boundary problems appear naturally in numerous areas of mathematics, science and engineering. These problems present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of free boundaries and complex dynamic interfaces. In this work, we propose a multi-network model based on physics-informed neural networks to tackle a general class of forward and inverse free boundary problems called Stefan problems. Specifically, we approximate the unknown solution as well as any moving boundaries by two deep neural networks. Besides, we formulate a new type of inverse Stefan problems that aim to reconstruct the solution and free boundaries directly from sparse and noisy measurements. We demonstrate the effectiveness of our approach in a series of benchmarks spanning different types of Stefan problems, and illustrate how the proposed framework can accurately recover solutions of partial differential equations with moving boundaries and dynamic interfaces. All code and data accompanying this manuscript are publicly available at https://github.com/PredictiveIntelligenceLab/DeepStefan.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Wang, Sifan and Perdikaris, Paris},
	month = oct,
	year = {2020},
	keywords = {Keywords Physics-informed neural networks, Partial differential equations, Phase transitions, Scientific machine learning},
	pages = {109914},
}

@article{bao_deep_2020,
	title = {Deep {Learning} {Interfacial} {Momentum} {Closures} in {Coarse}-{Mesh} {CFD} {Two}-{Phase} {Flow} {Simulation} {Using} {Validation} {Data}},
	issn = {0301-9322},
	url = {http://www.sciencedirect.com/science/article/pii/S0301932220306005},
	doi = {10.1016/j.ijmultiphaseflow.2020.103489},
	abstract = {Multiphase flow phenomena have been widely observed in the industrial applications, yet it remains a challenging unsolved problem. Three-dimensional computational fluid dynamics (CFD) approaches resolve of the flow fields on finer spatial and temporal scales, which can complement dedicated experimental study. However, closures must be introduced to reflect the underlying physics in multiphase flow. Among them, the interfacial forces, including drag, lift, turbulent-dispersion and wall-lubrication forces, play an important role in bubble distribution and migration in liquid-vapor two-phase flows. Development of those closures traditionally rely on the experimental data and analytical derivation with simplified assumptions that usually cannot deliver a universal solution across a wide range of flow conditions. In this paper, a data-driven approach, named as feature-similarity measurement (FSM), is developed and applied to improve the simulation capability of two-phase flow with coarse-mesh CFD approach. Interfacial momentum transfer in adiabatic bubbly flow serves as the focus of the present study. Both a mature and a simplified set of interfacial closures are taken as the low-fidelity data. Validation data (including relevant experimental data and validated fine-mesh CFD simulations results) are adopted as high-fidelity data. Qualitative and quantitative analysis are performed in this paper. These reveal that FSM can substantially improve the prediction of the coarse-mesh CFD model, regardless of the choice of interfacial closures. It demonstrates that data-driven methods can aid the multiphase flow modeling by exploring the connections between local physical features and simulation errors.},
	language = {en},
	urldate = {2020-10-20},
	journal = {International Journal of Multiphase Flow},
	author = {Bao, Han and Feng, Jinyong and Dinh, Nam and Zhang, Hongbin},
	month = oct,
	year = {2020},
	keywords = {Bamf, Bubbly and moderate void fraction, Cfd, Cfd computational fluid dynamics, Coarse mesh, Deep feedforward neural network, Departure from nucleate boiling, Dfnn, Direct numerical simulation, Dnb, Dns, Feature similarity measurement, Fsm, Geli, Global extrapolation through local interpolation, Hf, High-fidelity, Ic/bc, Initial condition/boundary condition, Interface tracking, Interfacial forces, It, Kde, Kernel density estimation, Lf, Low-fidelity, Machine learning, Ml machine learning, Normalized root mean squared error, Npp, Nrmse, Nuclear power plant, Pressurized water reactor, Pwr, QoI, Quantity of interest, Rans, Reynolds-averaged navier-stokes, Two-phase flow},
	pages = {103489},
}

@article{hanna_machine-learning_2020,
	title = {Machine-learning based error prediction approach for coarse-grid {Computational} {Fluid} {Dynamics} ({CG}-{CFD})},
	volume = {118},
	issn = {0149-1970},
	url = {http://www.sciencedirect.com/science/article/pii/S0149197019302495},
	doi = {10.1016/j.pnucene.2019.103140},
	abstract = {Computational Fluid Dynamics (CFD) is one of the modeling approaches essential to identifying the parameters that affect Containment Thermal Hydraulics (CTH) phenomena. While the CFD approach can capture the multidimensional behavior of CTH phenomena, its computational cost is high when modeling complex accident scenarios. To mitigate this expense, we propose reliance on coarse-grid CFD (CG-CFD). Coarsening the computational grid increases the grid-induced error thus requiring a novel approach that will produce a surrogate model predicting the distribution of the CG-CFD local error and correcting the fluid-flow variables. Given sufficiently fine-mesh simulations, a surrogate model can be trained to predict the CG-CFD local errors as a function of the coarse-grid local flow features. The surrogate model is constructed using Machine Learning (ML) regression algorithms. Two of the widely used ML regression algorithms were tested: Artificial Neural Network (ANN) and Random Forest (RF). The proposed CG-CFD method is illustrated with a three-dimensional turbulent flow inside a lid-driven cavity. We studied a set of scenarios to investigate the capability of the surrogate model to interpolate and extrapolate outside the training data range. The proposed method has proven capable of correcting the coarse-grid results and obtaining reasonable predictions for new cases (of different Reynolds number, different grid sizes, or larger geometries). Based on the investigated cases, we found this novel method maximizes the benefit of the available data and shows potential for a good predictive capability.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Progress in Nuclear Energy},
	author = {Hanna, Botros N. and Dinh, Nam T. and Youngblood, Robert W. and Bolotnov, Igor A.},
	month = jan,
	year = {2020},
	keywords = {Artificial neural network, Big data, CFD, Coarse grid (mesh), Data-driven, Discretization error, Machine learning, Random forest},
	pages = {103140},
}

@article{um_solver---loop_2020,
	title = {Solver-in-the-{Loop}: {Learning} from {Differentiable} {Physics} to {Interact} with {Iterative} {PDE}-{Solvers}},
	shorttitle = {Solver-in-the-{Loop}},
	url = {http://arxiv.org/abs/2007.00016},
	abstract = {Finding accurate solutions to partial differential equations (PDEs) is a crucial task in all scientific and engineering disciplines. It has recently been shown that machine learning methods can improve the solution accuracy by correcting for effects not captured by the discretized PDE. We target the problem of reducing numerical errors of iterative PDE solvers and compare different learning approaches for finding complex correction functions. We find that previously used learning approaches are significantly outperformed by methods that integrate the solver into the training loop and thereby allow the model to interact with the PDE during training. This provides the model with realistic input distributions that take previous corrections into account, yielding improvements in accuracy with stable rollouts of several hundred recurrent evaluation steps and surpassing even tailored supervised variants. We highlight the performance of the differentiable physics networks for a wide variety of PDEs, from non-linear advection-diffusion systems to three-dimensional Navier-Stokes flows.},
	urldate = {2020-10-20},
	journal = {arXiv:2007.00016 [physics]},
	author = {Um, Kiwon and Raymond and Fei and Holl, Philipp and Brand, Robert and Thuerey, Nils},
	month = jun,
	year = {2020},
	note = {arXiv: 2007.00016},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics},
}

@article{cheng_data-driven_2020,
	title = {Data-driven modelling of nonlinear spatio-temporal fluid flows using a deep convolutional generative adversarial network},
	volume = {365},
	issn = {0045-7825},
	url = {http://www.sciencedirect.com/science/article/pii/S0045782520301845},
	doi = {10.1016/j.cma.2020.113000},
	abstract = {Deep learning techniques for fluid flow modelling have gained significant attention in recent years. Advanced deep learning techniques achieve great progress in rapidly predicting fluid flows without prior knowledge of the underlying physical relationships. However, most of existing researches focused mainly on either sequence learning or spatial learning, rarely on both spatial and temporal dynamics of fluid flows (Reichstein et al., 2019). In this work, an Artificial Intelligence (AI) fluid model based on a general deep convolutional generative adversarial network (DCGAN) has been developed for predicting spatio-temporal flow distributions. In deep convolutional networks, the high-dimensional flows can be converted into the low-dimensional “latent” representations. The complex features of flow dynamics can be captured by the adversarial networks. The above DCGAN fluid model enables us to provide reasonable predictive accuracy of flow fields while maintaining a high computational efficiency. The performance of the DCGAN is illustrated for two test cases of Hokkaido tsunami with different incoming waves along the coastal line. It is demonstrated that the results from the DCGAN are comparable with those from the original high fidelity model (Fluidity). The spatio-temporal flow features have been represented as the flow evolves, especially, the wave phases and flow peaks can be captured accurately. In addition, the results illustrate that the online CPU cost is reduced by five orders of magnitude compared to the original high fidelity model simulations. The promising results show that the DCGAN can provide rapid and reliable spatio-temporal prediction for nonlinear fluid flows.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Cheng, M. and Fang, F. and Pain, C. C. and Navon, I. M.},
	month = jun,
	year = {2020},
	keywords = {Data-driven modelling, Deep convolutional GAN, Deep learning, Nonlinear fluid flow},
	pages = {113000},
}

@article{cheng_advanced_2020,
	title = {An advanced hybrid deep adversarial autoencoder for parameterized nonlinear fluid flow modelling},
	volume = {372},
	issn = {0045-7825},
	url = {http://www.sciencedirect.com/science/article/pii/S0045782520305600},
	doi = {10.1016/j.cma.2020.113375},
	abstract = {Considering the high computation cost required in conventional computation fluid dynamic simulations, machine learning methods have been introduced to flow dynamic simulations in years, aiming on reducing CPU time. In this work, we propose a hybrid deep adversarial autoencoder (VAE-GAN) to integrate generative adversarial network (GAN) and variational autoencoder (VAE) for predicting parameterized nonlinear fluid flows in spatial and temporal dimensions. High-dimensional inputs are compressed into the low-dimensional representations by nonlinear functions in a convolutional encoder. In this way, the predictive fluid flows reconstructed in a convolutional decoder contain the dynamic fluid flow physics of high nonlinearity and chaotic nature. In addition, the low-dimensional representations are applied to the adversarial network for model training and parameter optimization, which enables fast computation process. The capability of the hybrid VAE-GAN is illustrated by varying inputs on a flow past a cylinder test case as well as a second case of water column collapse. Numerical results show that this hybrid VAE-GAN has successfully captured the spatio-temporal flow features with CPU speed-up of three orders of magnitude. These promising results suggest that the hybrid VAE-GAN can play a critical role in efficiently and accurately predicting complex flows in future research efforts.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Cheng, M. and Fang, F. and Pain, C. C. and Navon, I. M.},
	month = dec,
	year = {2020},
	keywords = {Generative adversarial networks, Model reduction, Nonlinear fluid flows, Parameterized, Variational autoencoder},
	pages = {113375},
}

@article{mack_attention-based_2020,
	title = {Attention-based {Convolutional} {Autoencoders} for {3D}-{Variational} {Data} {Assimilation}},
	volume = {372},
	issn = {0045-7825},
	url = {http://www.sciencedirect.com/science/article/pii/S004578252030476X},
	doi = {10.1016/j.cma.2020.113291},
	abstract = {We propose a new ‘Bi-Reduced Space’ approach to solving 3D Variational Data Assimilation using Convolutional Autoencoders. We prove that our approach has the same solution as previous methods but has significantly lower computational complexity; in other words, we reduce the computational cost without affecting the data assimilation accuracy. We tested our proposal with data from a real-world application: a pollution model of a site in Elephant and Castle (London, UK) and found that we could (1) reduce the size of the background covariance matrix representation by O(103), and (2) increase our data assimilation accuracy with respect to existing reduced space methods.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Mack, Julian and Arcucci, Rossella and Molina-Solana, Miguel and Guo, Yi-Ke},
	month = dec,
	year = {2020},
	keywords = {Attention networks, Convolutional Autoencoders, Variational Data Assimilation},
	pages = {113291},
}

@article{yang_adversarial_2019,
	title = {Adversarial uncertainty quantification in physics-informed neural networks},
	volume = {394},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999119303584},
	doi = {10.1016/j.jcp.2019.05.027},
	abstract = {We present a deep learning framework for quantifying and propagating uncertainty in systems governed by non-linear differential equations using physics-informed neural networks. Specifically, we employ latent variable models to construct probabilistic representations for the system states, and put forth an adversarial inference procedure for training them on data, while constraining their predictions to satisfy given physical laws expressed by partial differential equations. Such physics-informed constraints provide a regularization mechanism for effectively training deep generative models as surrogates of physical systems in which the cost of data acquisition is high, and training data-sets are typically small. This provides a flexible framework for characterizing uncertainty in the outputs of physical systems due to randomness in their inputs or noise in their observations that entirely bypasses the need for repeatedly sampling expensive experiments or numerical simulators. We demonstrate the effectiveness of our approach through a series of examples involving uncertainty propagation in non-linear conservation laws, and the discovery of constitutive laws for flow through porous media directly from noisy data.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Yang, Yibo and Perdikaris, Paris},
	month = oct,
	year = {2019},
	keywords = {Data-driven modeling, Generative adversarial networks, Probabilistic deep learning, Probabilistic scientific computing, Variational inference},
	pages = {136--152},
}

@article{zhu_physics-constrained_2019,
	title = {Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data},
	volume = {394},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999119303559},
	doi = {10.1016/j.jcp.2019.05.024},
	abstract = {Surrogate modeling and uncertainty quantification tasks for PDE systems are most often considered as supervised learning problems where input and output data pairs are used for training. The construction of such emulators is by definition a small data problem which poses challenges to deep learning approaches that have been developed to operate in the big data regime. Even in cases where such models have been shown to have good predictive capability in high dimensions, they fail to address constraints in the data implied by the PDE model. This paper provides a methodology that incorporates the governing equations of the physical model in the loss/likelihood functions. The resulting physics-constrained, deep learning models are trained without any labeled data (e.g. employing only input data) and provide comparable predictive responses with data-driven models while obeying the constraints of the problem at hand. This work employs a convolutional encoder-decoder neural network approach as well as a conditional flow-based generative model for the solution of PDEs, surrogate model construction, and uncertainty quantification tasks. The methodology is posed as a minimization problem of the reverse Kullback-Leibler (KL) divergence between the model predictive density and the reference conditional density, where the later is defined as the Boltzmann-Gibbs distribution at a given inverse temperature with the underlying potential relating to the PDE system of interest. The generalization capability of these models to out-of-distribution input is considered. Quantification and interpretation of the predictive uncertainty is provided for a number of problems.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Zhu, Yinhao and Zabaras, Nicholas and Koutsourelakis, Phaedon-Stelios and Perdikaris, Paris},
	month = oct,
	year = {2019},
	keywords = {Conditional generative model, Normalizing flow, Physics-constrained, Reverse KL divergence, Surrogate modeling, Uncertainty quantification},
	pages = {56--81},
}

@article{mo_deep_2019,
	title = {Deep convolutional encoder-decoder networks for uncertainty quantification of dynamic multiphase flow in heterogeneous media},
	volume = {55},
	issn = {0043-1397, 1944-7973},
	url = {http://arxiv.org/abs/1807.00882},
	doi = {10.1029/2018WR023528},
	abstract = {Surrogate strategies are used widely for uncertainty quantification of groundwater models in order to improve computational efficiency. However, their application to dynamic multiphase flow problems is hindered by the curse of dimensionality, the saturation discontinuity due to capillarity effects, and the time-dependence of the multi-output responses. In this paper, we propose a deep convolutional encoder-decoder neural network methodology to tackle these issues. The surrogate modeling task is transformed to an image-to-image regression strategy. This approach extracts high-level coarse features from the high-dimensional input permeability images using an encoder, and then refines the coarse features to provide the output pressure/saturation images through a decoder. A training strategy combining a regression loss and a segmentation loss is proposed in order to better approximate the discontinuous saturation field. To characterize the high-dimensional time-dependent outputs of the dynamic system, time is treated as an additional input to the network that is trained using pairs of input realizations and of the corresponding system outputs at a limited number of time instances. The proposed method is evaluated using a geological carbon storage process-based multiphase flow model with a 2500-dimensional stochastic permeability field. With a relatively small number of training data, the surrogate model is capable of accurately characterizing the spatio-temporal evolution of the pressure and discontinuous CO2 saturation fields and can be used efficiently to compute the statistics of the system responses.},
	number = {1},
	urldate = {2020-10-20},
	journal = {Water Resources Research},
	author = {Mo, Shaoxing and Zhu, Yinhao and Zabaras, Nicholas and Shi, Xiaoqing and Wu, Jichun},
	month = jan,
	year = {2019},
	note = {arXiv: 1807.00882},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {703--728},
}

@misc{noauthor_deep_nodate,
	title = {Deep {Convolutional} {Encoder}‐{Decoder} {Networks} for {Uncertainty} {Quantification} of {Dynamic} {Multiphase} {Flow} in {Heterogeneous} {Media} - {Mo} - 2019 - {Water} {Resources} {Research} - {Wiley} {Online} {Library}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018WR023528},
	urldate = {2020-10-20},
}

@article{winovich_convpde-uq_2019,
	title = {{ConvPDE}-{UQ}: {Convolutional} neural networks with quantified uncertainty for heterogeneous elliptic partial differential equations on varied domains},
	volume = {394},
	issn = {0021-9991},
	shorttitle = {{ConvPDE}-{UQ}},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999119303572},
	doi = {10.1016/j.jcp.2019.05.026},
	abstract = {In this work, we introduce the ConvPDE-UQ framework for constructing light-weight numerical solvers for partial differential equations (PDEs) using convolutional neural networks. A theoretical justification for the neural network approximation to partial differential equation solvers on varied domains is established based on the existence and properties of Green's functions. These solvers are able to effectively reduce the computational demands of traditional numerical methods into a single forward-pass of a convolutional network. The network architecture is also designed to predict pointwise Gaussian posterior distributions, with weights trained to minimize the associated negative log-likelihood of the observed solutions. This setup facilitates simultaneous training and uncertainty quantification for the network's solutions, allowing the solver to provide pointwise uncertainties for its predictions. The associated training procedure avoids the computationally expensive Bayesian inference steps used by other state-of-the-art uncertainty models and allows training to be scaled to the large data sets required for learning on varied problem domains. The performance of the framework is demonstrated on three distinct classes of PDEs consisting of two linear elliptic problem setups and a nonlinear Poisson problem. After a single offline training procedure for each class, the proposed networks are capable of accurately predicting the solutions to linear and nonlinear elliptic problems with heterogeneous source terms defined on any specified two-dimensional domain using just a single forward-pass of a convolutional neural network. Additionally, an analysis of the predicted pointwise uncertainties is presented with experimental evidence establishing the validity of the network's uncertainty quantification schema.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Winovich, Nick and Ramani, Karthik and Lin, Guang},
	month = oct,
	year = {2019},
	keywords = {Confidence interval, Convolutional encoder-decoder networks, Deep learning, Machine learning, Partial differential equations, Uncertainty quantification},
	pages = {263--279},
}

@article{pang_npinns_2020,
	title = {{nPINNs}: {Nonlocal} physics-informed neural networks for a parametrized nonlocal universal {Laplacian} operator. {Algorithms} and applications},
	volume = {422},
	issn = {0021-9991},
	shorttitle = {{nPINNs}},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999120305349},
	doi = {10.1016/j.jcp.2020.109760},
	abstract = {Physics-informed neural networks (PINNs) are effective in solving inverse problems based on differential and integro-differential equations with sparse, noisy, unstructured, and multi-fidelity data. PINNs incorporate all available information, including governing equations (reflecting physical laws), initial-boundary conditions, and observations of quantities of interest, into a loss function to be minimized, thus recasting the original problem into an optimization problem. In this paper, we extend PINNs to parameter and function inference for integral equations such as nonlocal Poisson and nonlocal turbulence models, and we refer to them as nonlocal PINNs (nPINNs). The contribution of the paper is three-fold. First, we propose a unified nonlocal Laplace operator, which converges to the classical Laplacian as one of the operator parameters, the nonlocal interaction radius δ goes to zero, and to the fractional Laplacian as δ goes to infinity. This universal operator forms a super-set of classical Laplacian and fractional Laplacian operators and, thus, has the potential to fit a broad spectrum of data sets. We provide theoretical convergence rates with respect to δ and verify them via numerical experiments. Second, we use nPINNs to estimate the two parameters, δ and α, characterizing the kernel of the unified operator. The strong non-convexity of the loss function yielding multiple (good) local minima reveals the occurrence of the operator mimicking phenomenon, that is, different pairs of estimated parameters could produce multiple solutions of comparable accuracy. Third, we propose another nonlocal operator with spatially variable order α(y), which is more suitable for modeling wall-bounded turbulence, e.g. turbulent Couette flow. Our results show that nPINNs can jointly infer this function as well as δ. More importantly, these parameters exhibit a universal behavior with respect to the Reynolds number, a finding that contributes to our understanding of nonlocal interactions in wall-bounded turbulence.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Pang, G. and D'Elia, M. and Parks, M. and Karniadakis, G. E.},
	month = dec,
	year = {2020},
	keywords = {Deep learning, Fractional Laplacian, Nonlocal models, Physics-informed neural networks, Turbulence modeling},
	pages = {109760},
}

@article{raissi_physics-informed_2019,
	title = {Physics-informed neural networks: {A} deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	issn = {0021-9991},
	shorttitle = {Physics-informed neural networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999118307125},
	doi = {10.1016/j.jcp.2018.10.045},
	abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
	month = feb,
	year = {2019},
	keywords = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, Runge–Kutta methods},
	pages = {686--707},
}

@article{geneva_multi-fidelity_2020,
	title = {Multi-fidelity {Generative} {Deep} {Learning} {Turbulent} {Flows}},
	url = {http://arxiv.org/abs/2006.04731},
	abstract = {In computational fluid dynamics, there is an inevitable trade off between accuracy and computational cost. Low-fidelity simulations with coarse discretizations are computationally inexpensive, however, the resulting flow fields are often inaccurate. Alternatively, high-fidelity simulations can yield accurate predictions but at exponentially higher computational cost. In this work, a novel multi-fidelity deep generative model is introduced for the surrogate modeling of high-fidelity turbulent flow fields given the solution of a computationally inexpensive but inaccurate low-fidelity solver. The resulting surrogate is able to generate physically accurate turbulent realizations at a computational cost magnitudes lower than that of a high-fidelity simulation. The deep generative model developed is a conditional invertible neural network, built with normalizing flows, with recurrent LSTM connections that allow for stable training of transient systems with high predictive accuracy. The model is trained with a variational loss that combines both data-driven and physics-constrained learning. This deep generative model is applied to non-trivial high Reynolds number flows governed by the Navier-Stokes equations including turbulent flow over a backwards facing step at different Reynolds numbers and turbulent wake behind an array of bluff bodies. For both of these examples, the model is able to generate unique yet physically accurate turbulent fluid flows conditioned on an inexpensive low-fidelity solution.},
	urldate = {2020-10-20},
	journal = {arXiv:2006.04731 [physics]},
	author = {Geneva, Nicholas and Zabaras, Nicholas},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.04731},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{wiewel_latent_2020,
	title = {Latent {Space} {Subdivision}: {Stable} and {Controllable} {Time} {Predictions} for {Fluid} {Flow}},
	shorttitle = {Latent {Space} {Subdivision}},
	url = {http://arxiv.org/abs/2003.08723},
	abstract = {We propose an end-to-end trained neural networkarchitecture to robustly predict the complex dynamics of fluid flows with high temporal stability. We focus on single-phase smoke simulations in 2D and 3D based on the incompressible Navier-Stokes (NS) equations, which are relevant for a wide range of practical problems. To achieve stable predictions for long-term flow sequences, a convolutional neural network (CNN) is trained for spatial compression in combination with a temporal prediction network that consists of stacked Long Short-Term Memory (LSTM) layers. Our core contribution is a novel latent space subdivision (LSS) to separate the respective input quantities into individual parts of the encoded latent space domain. This allows to distinctively alter the encoded quantities without interfering with the remaining latent space values and hence maximizes external control. By selectively overwriting parts of the predicted latent space points, our proposed method is capable to robustly predict long-term sequences of complex physics problems. In addition, we highlight the benefits of a recurrent training on the latent space creation, which is performed by the spatial compression network.},
	urldate = {2020-10-20},
	journal = {arXiv:2003.08723 [cs, stat]},
	author = {Wiewel, Steffen and Kim, Byungsoo and Azevedo, Vinicius C. and Solenthaler, Barbara and Thuerey, Nils},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.08723},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{werhahn_multi-pass_2019,
	title = {A {Multi}-{Pass} {GAN} for {Fluid} {Flow} {Super}-{Resolution}},
	volume = {2},
	url = {https://doi.org/10.1145/3340251},
	doi = {10.1145/3340251},
	abstract = {We propose a novel method to up-sample volumetric functions with generative neural networks using several orthogonal passes. Our method decomposes generative problems on Cartesian field functions into multiple smaller sub-problems that can be learned more efficiently. Specifically, we utilize two separate generative adversarial networks: the first one up-scales slices which are parallel to the XY-plane, whereas the second one refines the whole volume along the Z---axis working on slices in the YZ-plane. In this way, we obtain full coverage for the 3D target function and can leverage spatio-temporal supervision with a set of discriminators. Additionally, we demonstrate that our method can be combined with curriculum learning and progressive growing approaches. We arrive at a first method that can up-sample volumes by a factor of eight along each dimension, i.e., increasing the number of degrees of freedom by 512. Large volumetric up-scaling factors such as this one have previously not been attainable as the required number of weights in the neural networks renders adversarial training runs prohibitively difficult. We demonstrate the generality of our trained networks with a series of comparisons to previous work, a variety of complex 3D results, and an analysis of the resulting performance.},
	number = {2},
	urldate = {2020-10-20},
	journal = {Proceedings of the ACM on Computer Graphics and Interactive Techniques},
	author = {Werhahn, Maximilian and Xie, You and Chu, Mengyu and Thuerey, Nils},
	month = jul,
	year = {2019},
	keywords = {computer animation, fluid simulation, generative models, physics-based deep learning},
	pages = {10:1--10:21},
}

@article{yin_feature_2020,
	title = {Feature selection and processing of turbulence modeling based on an artificial neural network},
	volume = {32},
	issn = {1070-6631},
	url = {https://aip.scitation.org/doi/10.1063/5.0022561},
	doi = {10.1063/5.0022561},
	abstract = {Data-driven turbulence modeling has been considered an effective method for improving the prediction accuracy of Reynolds-averaged Navier–Stokes equations. Related studies aimed to solve the discrepancy of traditional turbulence modeling by acquiring specific patterns from high-fidelity data through machine learning methods, such as artificial neural networks. The present study focuses on the unsmoothness and prediction error problems from the aspect of feature selection and processing. The selection criteria for the input features are summarized, and an effective input set is constructed. The effect of the computation grid on the smoothness is studied. A modified feature decomposition method for the spatial orientation feature of the Reynolds stress is proposed. The improved machine learning framework is then applied to the periodic hill database with notably varying geometries. The results of the modified method show significant enhancement in the prediction accuracy and smoothness, including the shape and size of separation areas and the friction and pressure distributions on the wall, which confirms the validity of the approach.},
	number = {10},
	urldate = {2020-10-20},
	journal = {Physics of Fluids},
	author = {Yin, Yuhui (尹宇辉) and Yang, Pu (杨普) and Zhang, Yufei (张宇飞) and Chen, Haixin (陈海昕) and Fu, Song (符松)},
	month = oct,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {105117},
}

@article{thuerey_deep_2020,
	title = {Deep {Learning} {Methods} for {Reynolds}-{Averaged} {Navier}-{Stokes} {Simulations} of {Airfoil} {Flows}},
	volume = {58},
	issn = {0001-1452, 1533-385X},
	url = {http://arxiv.org/abs/1810.08217},
	doi = {10.2514/1.j058291},
	abstract = {With this study we investigate the accuracy of deep learning models for the inference of Reynolds-Averaged Navier-Stokes solutions. We focus on a modernized U-net architecture, and evaluate a large number of trained neural networks with respect to their accuracy for the calculation of pressure and velocity distributions. In particular, we illustrate how training data size and the number of weights influence the accuracy of the solutions. With our best models we arrive at a mean relative pressure and velocity error of less than 3\% across a range of previously unseen airfoil shapes. In addition all source code is publicly available in order to ensure reproducibility and to provide a starting point for researchers interested in deep learning methods for physics problems. While this work focuses on RANS solutions, the neural network architecture and learning setup are very generic, and applicable to a wide range of PDE boundary value problems on Cartesian grids.},
	number = {1},
	urldate = {2020-10-20},
	journal = {AIAA Journal},
	author = {Thuerey, Nils and Weissenow, Konstantin and Prantl, Lukas and Hu, Xiangyu},
	month = jan,
	year = {2020},
	note = {arXiv: 1810.08217},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics, Statistics - Machine Learning},
	pages = {25--36},
}

@article{fukami_synthetic_2019,
	title = {Synthetic turbulent inflow generator using machine learning},
	volume = {4},
	url = {https://link.aps.org/doi/10.1103/PhysRevFluids.4.064603},
	doi = {10.1103/PhysRevFluids.4.064603},
	abstract = {We propose a methodology for generating time-dependent turbulent inflow data with the aid of machine learning (ML), which has the possibility to replace conventional driver simulations or synthetic turbulent inflow generators. As for the ML model, we use an autoencoder-type convolutional neural network with a multilayer perceptron. For the test case, we study a fully developed turbulent channel flow at the friction Reynolds number of Reτ=180 for easiness of assessment. The ML models are trained using a time series of instantaneous velocity fields in a single cross section obtained by direct numerical simulation (DNS) so as to output the cross-sectional velocity field at a specified future time instant. From the a priori test in which the output from the trained ML model are recycled to the input, the spatiotemporal evolution of cross-sectional structure is found to be reasonably well reproduced by the proposed method. The turbulence statistics obtained in the a priori test are also, in general, in reasonable agreement with the DNS data, although some deviation in the flow rate was found. It is also found that the present machine-learned inflow generator is free from the spurious periodicity, unlike the conventional driver DNS in a periodic domain. As an a posteriori test, we perform DNS of inflow-outflow turbulent channel flow with the trained ML model used as a machine-learned turbulent inflow generator (MLTG) at the inlet. It is shown that the present MLTG can maintain the turbulent channel flow for a long time period sufficient to accumulate turbulent statistics, with much lower computational cost than the corresponding driver simulation. It is also demonstrated that we can obtain accurate turbulent statistics by properly correcting the deviation in the flow rate.},
	number = {6},
	urldate = {2020-10-20},
	journal = {Physical Review Fluids},
	author = {Fukami, Kai and Nabae, Yusuke and Kawai, Ken and Fukagata, Koji},
	month = jun,
	year = {2019},
	note = {Publisher: American Physical Society},
	pages = {064603},
}

@article{bode_deep_2019,
	title = {Deep learning at scale for subgrid modeling in turbulent flows},
	url = {http://arxiv.org/abs/1910.00928},
	abstract = {Modeling of turbulent flows is still challenging. One way to deal with the large scale separation due to turbulence is to simulate only the large scales and model the unresolved contributions as done in large-eddy simulation (LES). This paper focuses on two deep learning (DL) strategies, regression and reconstruction, which are data-driven and promising alternatives to classical modeling concepts. Using three-dimensional (3-D) forced turbulence direct numerical simulation (DNS) data, subgrid models are evaluated, which predict the unresolved part of quantities based on the resolved solution. For regression, it is shown that feedforward artificial neural networks (ANNs) are able to predict the fully-resolved scalar dissipation rate using filtered input data. It was found that a combination of a large-scale quantity, such as the filtered passive scalar itself, and a small-scale quantity, such as the filtered energy dissipation rate, gives the best agreement with the actual DNS data. Furthermore, a DL network motivated by enhanced super-resolution generative adversarial networks (ESRGANs) was used to reconstruct fully-resolved 3-D velocity fields from filtered velocity fields. The energy spectrum shows very good agreement. As size of scientific data is often in the order of terabytes or more, DL needs to be combined with high performance computing (HPC). Necessary code improvements for HPC-DL are discussed with respect to the supercomputer JURECA. After optimizing the training code, 396.2 TFLOPS were achieved.},
	urldate = {2020-10-20},
	journal = {arXiv:1910.00928 [physics]},
	author = {Bode, Mathis and Gauding, Michael and Kleinheinz, Konstantin and Pitsch, Heinz},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.00928},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@article{kim_deep_2020,
	title = {Deep unsupervised learning of turbulence for inflow generation at various {Reynolds} numbers},
	volume = {406},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999119309210},
	doi = {10.1016/j.jcp.2019.109216},
	abstract = {A realistic inflow boundary condition is essential for successful simulation of the developing turbulent boundary layer or channel flows. In the present work, we applied generative adversarial networks (GANs), a representative of unsupervised learning, to generate an inlet boundary condition of turbulent channel flow. Upon learning the two-dimensional spatial structure of turbulence using data obtained from direct numerical simulation (DNS) of turbulent channel flow, the GAN could generate instantaneous flow fields that are statistically similar to those of DNS. After learning data at only three Reynolds numbers, the GAN could produce fields at various Reynolds numbers within a certain range without additional simulation. Eventually, through a combination of the GAN and a recurrent neural network (RNN), we developed a novel model (RNN-GAN) that could generate time-varying fully developed flow for a long time. The spatiotemporal correlations of the generated flow are in good agreement with those of the DNS. This proves the usefulness of unsupervised learning in the generation of synthetic turbulence fields.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Journal of Computational Physics},
	author = {Kim, Junhyuk and Lee, Changhoon},
	month = apr,
	year = {2020},
	keywords = {Deep learning, Generative adversarial networks, Inflow generation, Recurrent neural networks, Synthetic generation method, Unsupervised learning},
	pages = {109216},
}

@article{geneva_multi-fidelity_2020-1,
	title = {Multi-fidelity {Generative} {Deep} {Learning} {Turbulent} {Flows}},
	url = {http://arxiv.org/abs/2006.04731},
	abstract = {In computational fluid dynamics, there is an inevitable trade off between accuracy and computational cost. Low-fidelity simulations with coarse discretizations are computationally inexpensive, however, the resulting flow fields are often inaccurate. Alternatively, high-fidelity simulations can yield accurate predictions but at exponentially higher computational cost. In this work, a novel multi-fidelity deep generative model is introduced for the surrogate modeling of high-fidelity turbulent flow fields given the solution of a computationally inexpensive but inaccurate low-fidelity solver. The resulting surrogate is able to generate physically accurate turbulent realizations at a computational cost magnitudes lower than that of a high-fidelity simulation. The deep generative model developed is a conditional invertible neural network, built with normalizing flows, with recurrent LSTM connections that allow for stable training of transient systems with high predictive accuracy. The model is trained with a variational loss that combines both data-driven and physics-constrained learning. This deep generative model is applied to non-trivial high Reynolds number flows governed by the Navier-Stokes equations including turbulent flow over a backwards facing step at different Reynolds numbers and turbulent wake behind an array of bluff bodies. For both of these examples, the model is able to generate unique yet physically accurate turbulent fluid flows conditioned on an inexpensive low-fidelity solution.},
	urldate = {2020-10-20},
	journal = {arXiv:2006.04731 [physics]},
	author = {Geneva, Nicholas and Zabaras, Nicholas},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.04731},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Physics - Fluid Dynamics},
}

@inproceedings{wang_towards_2020,
	address = {New York, NY, USA},
	series = {{KDD} '20},
	title = {Towards {Physics}-informed {Deep} {Learning} for {Turbulent} {Flow} {Prediction}},
	isbn = {978-1-4503-7998-4},
	url = {https://doi.org/10.1145/3394486.3403198},
	doi = {10.1145/3394486.3403198},
	abstract = {While deep learning has shown tremendous success in a wide range of domains, it remains a grand challenge to incorporate physical principles in a systematic manner to the design, training, and inference of such models. In this paper, we aim to predict turbulent flow by learning its highly nonlinear dynamics from spatiotemporal velocity fields of large-scale fluid flow simulations of relevance to turbulence modeling and climate modeling. We adopt a hybrid approach by marrying two well-established turbulent flow simulation techniques with deep learning. Specifically, we introduce trainable spectral filters in a coupled model of Reynolds-averaged Navier-Stokes (RANS) and Large Eddy Simulation (LES), followed by a specialized U-net for prediction. Our approach, which we call Turbulent-Flow Net, is grounded in a principled physics model, yet offers the flexibility of learned representations. We compare our model with state-of-the-art baselines and observe significant reductions in error for predictions 60 frames ahead. Most importantly, our method predicts physical fields that obey desirable physical characteristics, such as conservation of mass, whilst faithfully emulating the turbulent kinetic energy field and spectrum, which are critical for accurate prediction of turbulent flows.},
	urldate = {2020-10-20},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Rui and Kashinath, Karthik and Mustafa, Mustafa and Albert, Adrian and Yu, Rose},
	month = aug,
	year = {2020},
	keywords = {deep learning, physics-informed machine learning, spatiotemporal forecasting, turbulent flows, video forward prediction},
	pages = {1457--1466},
}
