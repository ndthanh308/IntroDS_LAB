\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{bao2021beit}
Bao, H., Dong, L., Wei, F.: Beit: Bert pre-training of image transformers.
  arXiv preprint arXiv:2106.08254  (2021)

\bibitem{bar2021detreg}
Bar, A., Wang, X., Kantorov, V., Reed, C.J., Herzig, R., Chechik, G., Rohrbach,
  A., Darrell, T., Globerson, A.: Detreg: Unsupervised pretraining with region
  priors for object detection. arXiv preprint arXiv:2106.04550  (2021)

\bibitem{barnes2009patchmatch}
Barnes, C., Shechtman, E., Finkelstein, A., Goldman, D.B.: Patchmatch: A
  randomized correspondence algorithm for structural image editing. ACM Trans.
  Graph.  \textbf{28}(3), ~24 (2009)

\bibitem{bertalmio2000image}
Bertalmio, M., Sapiro, G., Caselles, V., Ballester, C.: Image inpainting. In:
  Proceedings of the 27th annual conference on Computer graphics and
  interactive techniques. pp. 417--424 (2000)

\bibitem{gpt3}
Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert{-}Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A.,
  Ziegler, D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin,
  M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A.,
  Sutskever, I., Amodei, D.: Language models are few-shot learners. CoRR
  \textbf{abs/2005.14165} (2020), \url{https://arxiv.org/abs/2005.14165}

\bibitem{caron2020unsupervised}
Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., Joulin, A.:
  Unsupervised learning of visual features by contrasting cluster assignments.
  NeurIPS  (2020)

\bibitem{chang2022maskgit}
Chang, H., Zhang, H., Jiang, L., Liu, C., Freeman, W.T.: Maskgit: Masked
  generative image transformer. arXiv preprint arXiv:2202.04200  (2022)

\bibitem{chen2020generative}
Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., Sutskever, I.:
  Generative pretraining from pixels. In: International Conference on Machine
  Learning. pp. 1691--1703. PMLR (2020)

\bibitem{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., Hinton, G.: A simple framework for
  contrastive learning of visual representations. arXiv preprint
  arXiv:2002.05709  (2020)

\bibitem{chen2020improved}
Chen, X., Fan, H., Girshick, R., He, K.: Improved baselines with momentum
  contrastive learning. arXiv preprint arXiv:2003.04297  (2020)

\bibitem{criminisi2004region}
Criminisi, A., P{\'e}rez, P., Toyama, K.: Region filling and object removal by
  exemplar-based image inpainting. IEEE Transactions on image processing
  \textbf{13}(9),  1200--1212 (2004)

\bibitem{devlin2018bert}
Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep
  bidirectional transformers for language understanding. arXiv preprint
  arXiv:1810.04805  (2018)

\bibitem{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.:
  An image is worth 16x16 words: Transformers for image recognition at scale.
  arXiv preprint arXiv:2010.11929  (2020)

\bibitem{Efros99}
Efros, A.A., Leung, T.K.: Texture synthesis by non-parametric sampling. In:
  IEEE International Conference on Computer Vision. pp. 1033--1038. Corfu,
  Greece (September 1999)

\bibitem{esser2021taming}
Esser, P., Rombach, R., Ommer, B.: Taming transformers for high-resolution
  image synthesis. In: Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition. pp. 12873--12883 (2021)

\bibitem{gidaris2020learning}
Gidaris, S., Bursuc, A., Komodakis, N., P{\'e}rez, P., Cord, M.: Learning
  representations by predicting bags of visual words. In: CVPR (2020)

\bibitem{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., Bengio, Y.: Generative adversarial nets. Advances in
  neural information processing systems  \textbf{27} (2014)

\bibitem{goyal2019scaling}
Goyal, P., Mahajan, D., Gupta, A., Misra, I.: Scaling and benchmarking
  self-supervised visual representation learning. In: ICCV (2019)

\bibitem{Hays:2007}
Hays, J., Efros, A.A.: Scene completion using millions of photographs. ACM
  Transactions on Graphics (SIGGRAPH 2007)  \textbf{26}(3) (2007)

\bibitem{mae}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'{a}}r, P., Girshick, R.B.: Masked
  autoencoders are scalable vision learners. CoRR  \textbf{abs/2111.06377}
  (2021), \url{https://arxiv.org/abs/2111.06377}

\bibitem{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., Girshick, R.: Momentum contrast for
  unsupervised visual representation learning. In: CVPR (2020)

\bibitem{hertzmann2001image}
Hertzmann, A., Jacobs, C.E., Oliver, N., Curless, B., Salesin, D.H.: Image
  analogies. In: Proceedings of the 28th annual conference on Computer graphics
  and interactive techniques. pp. 327--340 (2001)

\bibitem{hill2019learning}
Hill, F., Santoro, A., Barrett, D.G., Morcos, A.S., Lillicrap, T.: Learning to
  make analogies by contrasting abstract relational structure. arXiv preprint
  arXiv:1902.00120  (2019)

\bibitem{hofstadter1995fluid}
Hofstadter, D.R.: Fluid concepts and creative analogies: Computer models of the
  fundamental mechanisms of thought. Basic books (1995)

\bibitem{jiang2020can}
Jiang, Z., Xu, F.F., Araki, J., Neubig, G.: How can we know what language
  models know? Transactions of the Association for Computational Linguistics
  \textbf{8},  423--438 (2020)

\bibitem{johnson2016perceptual}
Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style
  transfer and super-resolution. In: European conference on computer vision.
  pp. 694--711. Springer (2016)

\bibitem{kang2019few}
Kang, B., Liu, Z., Wang, X., Yu, F., Feng, J., Darrell, T.: Few-shot object
  detection via feature reweighting. In: Proceedings of the IEEE/CVF
  International Conference on Computer Vision. pp. 8420--8429 (2019)

\bibitem{prompt_ensemble}
Lester, B., Al{-}Rfou, R., Constant, N.: The power of scale for
  parameter-efficient prompt tuning. CoRR  \textbf{abs/2104.08691} (2021),
  \url{https://arxiv.org/abs/2104.08691}

\bibitem{li2021prefix}
Li, X.L., Liang, P.: Prefix-tuning: Optimizing continuous prompts for
  generation. arXiv preprint arXiv:2101.00190  (2021)

\bibitem{liu2018image}
Liu, G., Reda, F.A., Shih, K.J., Wang, T.C., Tao, A., Catanzaro, B.: Image
  inpainting for irregular holes using partial convolutions. In: Proceedings of
  the European conference on computer vision (ECCV). pp. 85--100 (2018)

\bibitem{Liu_2018_ECCV}
Liu, G., Reda, F.A., Shih, K.J., Wang, T.C., Tao, A., Catanzaro, B.: Image
  inpainting for irregular holes using partial convolutions. In: Proceedings of
  the European Conference on Computer Vision (ECCV) (September 2018)

\bibitem{liu2020part}
Liu, Y., Zhang, X., Zhang, S., He, X.: Part-aware prototype network for
  few-shot semantic segmentation. In: European Conference on Computer Vision.
  pp. 142--158. Springer (2020)

\bibitem{lu2021fantastically}
Lu, Y., Bartolo, M., Moore, A., Riedel, S., Stenetorp, P.: Fantastically
  ordered prompts and where to find them: Overcoming few-shot prompt order
  sensitivity. arXiv preprint arXiv:2104.08786  (2021)

\bibitem{memisevic2007unsupervised}
Memisevic, R., Hinton, G.: Unsupervised learning of image transformations. In:
  2007 IEEE Conference on Computer Vision and Pattern Recognition. pp.~1--8.
  IEEE (2007)

\bibitem{misra2020self}
Misra, I., Maaten, L.v.d.: Self-supervised learning of pretext-invariant
  representations. In: CVPR (2020)

\bibitem{nguyen2019feature}
Nguyen, K., Todorovic, S.: Feature weighting and boosting for few-shot
  segmentation. In: Proceedings of the IEEE/CVF International Conference on
  Computer Vision. pp. 622--631 (2019)

\bibitem{van2018representation}
Van~den Oord, A., Li, Y., Vinyals, O.: Representation learning with contrastive
  predictive coding. arXiv e-prints pp. arXiv--1807 (2018)

\bibitem{pathak2016context}
Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A.: Context
  encoders: Feature learning by inpainting. In: Proceedings of the IEEE
  conference on computer vision and pattern recognition. pp. 2536--2544 (2016)

\bibitem{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.:
  Language models are unsupervised multitask learners. OpenAI blog
  \textbf{1}(8), ~9 (2019)

\bibitem{ramesh2021zero}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M.,
  Sutskever, I.: Zero-shot text-to-image generation. In: International
  Conference on Machine Learning. pp. 8821--8831. PMLR (2021)

\bibitem{reed2015deep}
Reed, S.E., Zhang, Y., Zhang, Y., Lee, H.: Deep visual analogy-making. Advances
  in neural information processing systems  \textbf{28} (2015)

\bibitem{ILSVRC15}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: {ImageNet
  Large Scale Visual Recognition Challenge}. International Journal of Computer
  Vision (IJCV)  \textbf{115}(3),  211--252 (2015).
  \doi{10.1007/s11263-015-0816-y}

\bibitem{sadeghi2015visalogy}
Sadeghi, F., Zitnick, C.L., Farhadi, A.: Visalogy: Answering visual analogy
  questions. Advances in Neural Information Processing Systems  \textbf{28}
  (2015)

\bibitem{sarzynska2021detecting}
Sarzynska-Wawer, J., Wawer, A., Pawlak, A., Szymanowska, J., Stefaniak, I.,
  Jarkiewicz, M., Okruszek, L.: Detecting formal thought disorder by deep
  contextualized word representations. Psychiatry Research  \textbf{304},
  114135 (2021)

\bibitem{pascal_5i}
Shaban, A., Bansal, S., Liu, Z., Essa, I., Boots, B.: One-shot learning for
  semantic segmentation. CoRR  \textbf{abs/1709.03410} (2017),
  \url{http://arxiv.org/abs/1709.03410}

\bibitem{taylor2010convolutional}
Taylor, G.W., Fergus, R., LeCun, Y., Bregler, C.: Convolutional learning of
  spatio-temporal features. In: European conference on computer vision. pp.
  140--153. Springer (2010)

\bibitem{tenenbaum2000separating}
Tenenbaum, J.B., Freeman, W.T.: Separating style and content with bilinear
  models. Neural computation  \textbf{12}(6),  1247--1283 (2000)

\bibitem{tian2020prior}
Tian, Z., Zhao, H., Shu, M., Yang, Z., Li, R., Jia, J.: Prior guided feature
  enrichment network for few-shot segmentation. IEEE transactions on pattern
  analysis and machine intelligence  (2020)

\bibitem{UlyanovVL17}
Ulyanov, D., Vedaldi, A., Lempitsky, V.: Deep image prior. arXiv:1711.10925
  (2017)

\bibitem{upchurch2016z}
Upchurch, P., Snavely, N., Bala, K.: From a to z: supervised transfer of style
  and content using deep neural network generators. arXiv preprint
  arXiv:1603.02003  (2016)

\bibitem{van2017neural}
Van Den~Oord, A., Vinyals, O., et~al.: Neural discrete representation learning.
  Advances in neural information processing systems  \textbf{30} (2017)

\bibitem{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
  Kaiser, {\L}., Polosukhin, I.: Attention is all you need. Advances in neural
  information processing systems  \textbf{30} (2017)

\bibitem{wang2020frustratingly}
Wang, X., Huang, T.E., Darrell, T., Gonzalez, J.E., Yu, F.: Frustratingly
  simple few-shot object detection. arXiv preprint arXiv:2003.06957  (2020)

\bibitem{xie2021simmim}
Xie, Z., Zhang, Z., Cao, Y., Lin, Y., Bao, J., Yao, Z., Dai, Q., Hu, H.:
  Simmim: A simple framework for masked image modeling. arXiv preprint
  arXiv:2111.09886  (2021)

\bibitem{yang2020prototype}
Yang, B., Liu, C., Li, B., Jiao, J., Ye, Q.: Prototype mixture models for
  few-shot semantic segmentation. In: European Conference on Computer Vision.
  pp. 763--778. Springer (2020)

\bibitem{yang2017high}
Yang, C., Lu, X., Lin, Z., Shechtman, E., Wang, O., Li, H.: High-resolution
  image inpainting using multi-scale neural patch synthesis. In: Proceedings of
  the IEEE conference on computer vision and pattern recognition. pp.
  6721--6729 (2017)

\bibitem{yu2021vector}
Yu, J., Li, X., Koh, J.Y., Zhang, H., Pang, R., Qin, J., Ku, A., Xu, Y.,
  Baldridge, J., Wu, Y.: Vector-quantized image modeling with improved vqgan.
  arXiv preprint arXiv:2110.04627  (2021)

\bibitem{yu2021diverse}
Yu, Y., Zhan, F., Wu, R., Pan, J., Cui, K., Lu, S., Ma, F., Xie, X., Miao, C.:
  Diverse image inpainting with bidirectional and autoregressive transformers.
  In: Proceedings of the 29th ACM International Conference on Multimedia. pp.
  69--78 (2021)

\bibitem{zhang2021few}
Zhang, G., Kang, G., Yang, Y., Wei, Y.: Few-shot segmentation via
  cycle-consistent transformer. Advances in Neural Information Processing
  Systems  \textbf{34} (2021)

\bibitem{zhang2018unreasonable}
Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O.: The unreasonable
  effectiveness of deep features as a perceptual metric. In: Proceedings of the
  IEEE conference on computer vision and pattern recognition. pp. 586--595
  (2018)

\end{thebibliography}
