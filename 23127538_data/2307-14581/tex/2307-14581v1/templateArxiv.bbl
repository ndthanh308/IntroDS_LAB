\begin{thebibliography}{10}

\bibitem{piccialli2021survey}
Francesco Piccialli, Vittorio Di~Somma, Fabio Giampaolo, Salvatore Cuomo, and
  Giancarlo Fortino.
\newblock A survey on deep learning in medicine: Why, how and when?
\newblock {\em Information Fusion}, 66:111--137, 2021.

\bibitem{mckinnon2018flow}
Katherine McKinnon.
\newblock Flow cytometry: An overview.
\newblock {\em Current protocols in immunology}, 120(1):5--1, 2018.

\bibitem{wodlinger2022automated}
Matthias W{o}dlinger, Michael Reiter, Lisa Weijler, Margarita
  Maurer-Granofszky, Angela Schumich, Elisa~O Sajaroff, Stefanie
  Groeneveld-Krentz, Jorge~G Rossi, Leonid Karawajew, Richard Ratei, et~al.
\newblock Automated identification of cell populations in flow cytometry data
  with transformers.
\newblock {\em Computers in Biology and Medicine}, 144:105314, 2022.

\bibitem{zech2018variable}
John~R Zech, Marcus~A Badgeley, Manway Liu, Anthony~B Costa, Joseph~J Titano,
  and Eric~Karl Oermann.
\newblock Variable generalization performance of a deep learning model to
  detect pneumonia in chest radiographs: a cross-sectional study.
\newblock {\em PLoS medicine}, 15(11):e1002683, 2018.

\bibitem{amann2020explainability}
Julia Amann, Alessandro Blasimme, Effy Vayena, Dietmar Frey, and Vince~I Madai.
\newblock Explainability for artificial intelligence in healthcare: a
  multidisciplinary perspective.
\newblock {\em BMC Medical Informatics and Decision Making}, 20(1):1--9, 2020.

\bibitem{molnar2020interpretable}
Christoph Molnar.
\newblock {\em Interpretable machine learning}.
\newblock Lulu. com, 2020.

\bibitem{vig2019multiscale}
Jesse Vig.
\newblock A multiscale visualization of attention in the transformer model.
\newblock {\em arXiv preprint arXiv:1906.05714}, 2019.

\bibitem{atanasova2020diagnostic}
Pepa Atanasova, Jakob~Grue Simonsen, Christina Lioma, and Isabelle Augenstein.
\newblock A diagnostic study of explainability techniques for text
  classification.
\newblock {\em arXiv preprint arXiv:2009.13295}, 2020.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European conference on computer vision}, pages 213--229.
  Springer, 2020.

\bibitem{liu2021visual}
Nian Liu, Ni~Zhang, Kaiyuan Wan, Ling Shao, and Junwei Han.
\newblock Visual saliency transformer.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 4722--4732, 2021.

\bibitem{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em arXiv preprint arXiv:1409.0473}, 2014.

\bibitem{bau2018identifying}
Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and
  James Glass.
\newblock Identifying and controlling important neurons in neural machine
  translation.
\newblock {\em arXiv preprint arXiv:1811.01157}, 2018.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{aflalo2022vl}
Estelle Aflalo, Meng Du, Shao-Yen Tseng, Yongfei Liu, Chenfei Wu, Nan Duan, and
  Vasudev Lal.
\newblock Vl-interpret: An interactive visualization tool for interpreting
  vision-language transformers.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 21406--21415, 2022.

\bibitem{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock {\em arXiv preprint arXiv:1312.6034}, 2013.

\bibitem{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\bibitem{amir2021deep}
Shir Amir, Yossi Gandelsman, Shai Bagon, and Tali Dekel.
\newblock Deep vit features as dense visual descriptors.
\newblock {\em arXiv preprint arXiv:2112.05814}, 2(3):4, 2021.

\bibitem{qin2022cosformer}
Zhen Qin, Weixuan Sun, Hui Deng, Dongxu Li, Yunshen Wei, Baohong Lv, Junjie
  Yan, Lingpeng Kong, and Yiran Zhong.
\newblock cosformer: Rethinking softmax in attention.
\newblock {\em arXiv preprint arXiv:2202.08791}, 2022.

\bibitem{doi:https://doi.org/10.1002/9781118487969.ch2}
Mike Leach, Mark Drummond, and Allyson Doig.
\newblock {\em Principles of Flow Cytometry}, chapter~2, pages 3--19.
\newblock John Wiley \& Sons, Ltd, 2013.

\bibitem{kowarsch2022towards}
Florian Kowarsch, Lisa Weijler, Matthias W{\"o}dlinger, Michael Reiter,
  Margarita Maurer-Granofszky, Angela Schumich, Elisa~O Sajaroff, Stefanie
  Groeneveld-Krentz, Jorge~G Rossi, Leonid Karawajew, et~al.
\newblock Towards self-explainable transformers for cell classification in flow
  cytometry data.
\newblock In {\em International Workshop on Interpretability of Machine
  Intelligence in Medical Image Computing}, pages 22--32. Springer, 2022.

\bibitem{goodfellow_chapter4}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock Deep learning.
\newblock In {\em Deep Learning\/} \cite{Goodfellow-et-al-2016}.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem{goodfellow_chapter6}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock Deep learning.
\newblock In {\em Deep Learning\/} \cite{Goodfellow-et-al-2016}.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{lee2019set}
Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee~Whye
  Teh.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In {\em International conference on machine learning}, pages
  3744--3753. PMLR, 2019.

\bibitem{gray1984vector}
Robert Gray.
\newblock Vector quantization.
\newblock {\em IEEE Assp Magazine}, 1(2):4--29, 1984.

\bibitem{nair2010rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em Icml}, 2010.

\bibitem{reiter2019automated}
Michael Reiter, Markus Diem, Angela Schumich, Margarita Maurer-Granofszky,
  Leonid Karawajew, Jorge~G Rossi, Richard Ratei, Stefanie Groeneveld-Krentz,
  Elisa~O Sajaroff, Susanne Suhendra, et~al.
\newblock Automated flow cytometric mrd assessment in childhood acute
  b-lymphoblastic leukemia using supervised machine learning.
\newblock {\em Cytometry Part A}, 95(9):966--975, 2019.

\bibitem{mahapatra2022interpretability}
Dwarikanath Mahapatra, Alexander Poellinger, and Mauricio Reyes.
\newblock Interpretability-guided inductive bias for deep learning based
  medical image.
\newblock {\em Medical image analysis}, 81:102551, 2022.

\bibitem{simard1998transformation}
Patrice~Y Simard, Yann~A LeCun, John~S Denker, and Bernard Victorri.
\newblock Transformation invariance in pattern recognitionâ€”tangent distance
  and tangent propagation.
\newblock In {\em Neural networks: tricks of the trade}, pages 239--274.
  Springer, 1998.

\bibitem{Goodfellow-et-al-2016}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock {\em Deep Learning}.
\newblock MIT Press, 2016.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock {\em arXiv preprint arXiv:1706.03825}, 2017.

\end{thebibliography}
