
@article{wodlinger2022automated,
  title={Automated identification of cell populations in flow cytometry data with transformers},
  author={W{o}dlinger, Matthias and Reiter, Michael and Weijler, Lisa and Maurer-Granofszky, Margarita and Schumich, Angela and Sajaroff, Elisa O and Groeneveld-Krentz, Stefanie and Rossi, Jorge G and Karawajew, Leonid and Ratei, Richard and others},
  journal={Computers in Biology and Medicine},
  volume={144},
  pages={105314},
  year={2022},
  publisher={Elsevier}
},

@inproceedings{kowarsch2022towards,
  title={Towards Self-explainable Transformers for Cell Classification in Flow Cytometry Data},
  author={Kowarsch, Florian and Weijler, Lisa and W{\"o}dlinger, Matthias and Reiter, Michael and Maurer-Granofszky, Margarita and Schumich, Angela and Sajaroff, Elisa O and Groeneveld-Krentz, Stefanie and Rossi, Jorge G and Karawajew, Leonid and others},
  booktitle={International Workshop on Interpretability of Machine Intelligence in Medical Image Computing},
  pages={22--32},
  year={2022},
  organization={Springer}
},

@book{molnar2020interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu. com}
},

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
},

@article{vig2019multiscale,
  title={A multiscale visualization of attention in the transformer model},
  author={Vig, Jesse},
  journal={arXiv preprint arXiv:1906.05714},
  year={2019}
},

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
},

@article{bau2018identifying,
  title={Identifying and controlling important neurons in neural machine translation},
  author={Bau, Anthony and Belinkov, Yonatan and Sajjad, Hassan and Durrani, Nadir and Dalvi, Fahim and Glass, James},
  journal={arXiv preprint arXiv:1811.01157},
  year={2018}
},

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
},

@inproceedings{aflalo2022vl,
  title={VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers},
  author={Aflalo, Estelle and Du, Meng and Tseng, Shao-Yen and Liu, Yongfei and Wu, Chenfei and Duan, Nan and Lal, Vasudev},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21406--21415},
  year={2022}
},

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
},

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
},

@inproceedings{liu2021visual,
  title={Visual saliency transformer},
  author={Liu, Nian and Zhang, Ni and Wan, Kaiyuan and Shao, Ling and Han, Junwei},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4722--4732},
  year={2021}
},

@article{amir2021deep,
  title={Deep vit features as dense visual descriptors},
  author={Amir, Shir and Gandelsman, Yossi and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2112.05814},
  volume={2},
  number={3},
  pages={4},
  year={2021}
},

@article{atanasova2020diagnostic,
  title={A diagnostic study of explainability techniques for text classification},
  author={Atanasova, Pepa and Simonsen, Jakob Grue and Lioma, Christina and Augenstein, Isabelle},
  journal={arXiv preprint arXiv:2009.13295},
  year={2020}
},

@article{mcinnes2018umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
},

@inproceedings{goodfellow_chapter4,
author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
title = {Deep Learning},
booktitle = {Deep Learning},
chapter = {Chapter Four - Numerical Computation},
crossref = {Goodfellow-et-al-2016}
},


@inproceedings{goodfellow_chapter6,
author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
title = {Deep Learning},
booktitle = {Deep Learning},
chapter = {Chapter Six - Deep Feedforward Networks},
crossref = {Goodfellow-et-al-2016}
},

@book{Goodfellow-et-al-2016,
    title = {Deep Learning},
    booktitle = {Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
},



@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
},

@article{qin2022cosformer,
  title={cosFormer: Rethinking Softmax in Attention},
  author={Qin, Zhen and Sun, Weixuan and Deng, Hui and Li, Dongxu and Wei, Yunshen and Lv, Baohong and Yan, Junjie and Kong, Lingpeng and Zhong, Yiran},
  journal={arXiv preprint arXiv:2202.08791},
  year={2022}
},

@inproceedings{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International conference on machine learning},
  pages={3744--3753},
  year={2019},
  organization={PMLR}
},

@article{gray1984vector,
  title={Vector quantization},
  author={Gray, Robert},
  journal={IEEE Assp Magazine},
  volume={1},
  number={2},
  pages={4--29},
  year={1984},
  publisher={IEEE}
},

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
},


@article{mahapatra2022interpretability,
  title={Interpretability-guided inductive bias for deep learning based medical image},
  author={Mahapatra, Dwarikanath and Poellinger, Alexander and Reyes, Mauricio},
  journal={Medical image analysis},
  volume={81},
  pages={102551},
  year={2022},
  publisher={Elsevier}
},

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Icml},
  year={2010}
},

@article{weijler2022umap,
  title={UMAP Based Anomaly Detection for Minimal Residual Disease Quantification within Acute Myeloid Leukemia},
  author={Weijler, Lisa and Kowarsch, Florian and W{\"o}dlinger, Matthias and Reiter, Michael and Maurer-Granofszky, Margarita and Schumich, Angela and Dworzak, Michael N},
  journal={Cancers},
  volume={14},
  number={4},
  pages={898},
  year={2022},
  publisher={MDPI}
},

@article{piccialli2021survey,
  title={A survey on deep learning in medicine: Why, how and when?},
  author={Piccialli, Francesco and Di Somma, Vittorio and Giampaolo, Fabio and Cuomo, Salvatore and Fortino, Giancarlo},
  journal={Information Fusion},
  volume={66},
  pages={111--137},
  year={2021},
  publisher={Elsevier}
},

@inbook{doi:https://doi.org/10.1002/9781118487969.ch2,

publisher = {John Wiley \& Sons, Ltd},
author = {Mike Leach and Mark Drummond and Allyson Doig},
isbn = {9781118487969},
title = {Principles of Flow Cytometry},
booktitle = {Practical Flow Cytometry in Haematology Diagnosis},
chapter = {2},
pages = {3-19},
year = {2013},
keywords = {data display, electronic system, flow cytometry, fluidic system, gating strategies},
abstract = {Summary This chapter gives a simplified overview of flow cytometry, the gating strategies and data analysis applied in diagnostic flow cytometry applied to haematological disorders. It is aimed at laboratory staff and junior medical staff, and even more senior staff who have not had the privilege to experience clinical flow cytometry in all its diagnostic applications. The chapter mainly talks about sample preparation and three components to the flow cytometer, including fluidic system, optical system, and electronic system. Next, it also describes the most common data displays such as histogram and dot plot, for analysis in immunophenotyping.}
},

@article{reiter2019automated,
  title={Automated flow cytometric MRD assessment in childhood acute B-lymphoblastic leukemia using supervised machine learning},
  author={Reiter, Michael and Diem, Markus and Schumich, Angela and Maurer-Granofszky, Margarita and Karawajew, Leonid and Rossi, Jorge G and Ratei, Richard and Groeneveld-Krentz, Stefanie and Sajaroff, Elisa O and Suhendra, Susanne and others},
  journal={Cytometry Part A},
  volume={95},
  number={9},
  pages={966--975},
  year={2019},
  publisher={Wiley Online Library}
},

@incollection{simard1998transformation,
  title={Transformation invariance in pattern recognitionâ€”tangent distance and tangent propagation},
  author={Simard, Patrice Y and LeCun, Yann A and Denker, John S and Victorri, Bernard},
  booktitle={Neural networks: tricks of the trade},
  pages={239--274},
  year={1998},
  publisher={Springer}
},

@article{mckinnon2018flow,
  title     = {Flow cytometry: An overview},
  author    = {McKinnon, Katherine},
  journal   = {Current protocols in immunology},
  volume    = {120},
  number    = {1},
  pages     = {5--1},
  year      = {2018},
  publisher = {Wiley Online Library}
},

@article{zech2018variable,
  title={Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study},
  author={Zech, John R and Badgeley, Marcus A and Liu, Manway and Costa, Anthony B and Titano, Joseph J and Oermann, Eric Karl},
  journal={PLoS medicine},
  volume={15},
  number={11},
  pages={e1002683},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
},

@article{amann2020explainability,
  title={Explainability for artificial intelligence in healthcare: a multidisciplinary perspective},
  author={Amann, Julia and Blasimme, Alessandro and Vayena, Effy and Frey, Dietmar and Madai, Vince I},
  journal={BMC Medical Informatics and Decision Making},
  volume={20},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Springer}
}
