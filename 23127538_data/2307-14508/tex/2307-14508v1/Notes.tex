
\documentclass[aps,prb,reprint,showpacs,twocolumn,superscriptaddress,eqsecnum]{revtex4-2}
\usepackage{xr}
\usepackage{amsmath}
\usepackage{amsfonts,amssymb,amsthm,amsxtra}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage[]{graphicx}
%\pagestyle{headings}
\usepackage{grffile}
\usepackage{mathrsfs}
\usepackage{framed}
\usepackage{bbm}
\usepackage{bm}
\usepackage{braket}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage[bookmarks=false,colorlinks=true,urlcolor=blue,citecolor=blue,linkcolor=blue]{hyperref}
%\usepackage{mathdots}
\usepackage{LatexCommands}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\tr}{Tr}
% \usepackage{qcircuit}

\begin{document}
\author{Jason Saroni}
\affiliation{Ames Laboratory, Ames, Iowa 50011, USA}
\affiliation{Department of Physics and Astronomy, Iowa State University, Ames, Iowa 50011, USA}

\author{Henry Lamm}
\affiliation{Fermi National Accelerator Laboratory, Batavia, IL, 60510, USA}

\author{Yongxin Yao}
\affiliation{Ames Laboratory, Ames, Iowa 50011, USA}
\affiliation{Department of Physics and Astronomy, Iowa State University, Ames, Iowa 50011, USA}

\author{Peter P.~Orth}
\email{porth@iastate.edu}
\affiliation{Ames National Laboratory, Ames, Iowa 50011, USA}
\affiliation{Department of Physics and Astronomy, Iowa State University, Ames, Iowa 50011, USA}

\author{Thomas Iadecola}
\email{iadecola@iastate.edu}
\affiliation{Ames Laboratory, Ames, Iowa 50011, USA}
\affiliation{Department of Physics and Astronomy, Iowa State University, Ames, Iowa 50011, USA}



\maketitle

AVQDS\cite{PRXQuantum.2.030307}


\section{Methodology}
The thermal expectation value of observable $O(t)$ is 

\begin{equation}
\left \langle O(t) \right \rangle =  \text{Tr}\bigl[ \rho_0 O(t) \bigr] = \sum_{m,n} \braket{m|\rho_o|n} \braket{n|O(t)|m}
\end{equation}

As system size increases thermal state quenches become exponentially more costly to simulate than pure state quenches. By truncating the Hilbert space to only highest weight density matrix elements and using symmetries from the density matrix and Hamiltonian, and the appropriate basis and order parameter depending on which region of the phase diagram the quench begins at, the simulation of sudden quenches from thermal initial states becomes computationally less costly while capturing the dynamics of the exact evolution to a specified precision. The methodology is to produce density matrix elements $\rho_{ij}$ using either Exact Diagonalization or Density Matrix Quantum Monte Carlo method (DMQMC). Truncate and renormalize the density matrix using only highest weights. The thermal expectation value of an observable reduces to a sum over weighted pure state expectation values. 




\section{Computation of thermal Loschmidt echo using QMC-AVQDS}
\label{sec:computation_thermal_loschmidt_echo}
We want to compute the expectation value
\begin{equation}
    \text{Tr} \bigl[ \rho_0 U(t) \bigr] = \sum_{m,n} \braket{m|\rho_0|n} \braket{n|U(t)|m} \,.
\end{equation}
where $U(t) = e^{-iH_\text{dyn}t}$, $\rho_0 = \exp(-H_0/T)$ and $n,m$ label any complete basis. By noting that it is possible to decompose the expectation value into sums over basis states, we realize it is possible to simulate each matrix element $\braket{n|U(t)|m}$ independently on the quantum computer, and the sum them weighted by the density matrix which can be determined by a classial algorithm. This is the basis of the E$\rho$OQ algorithm~\cite{Lamm:2018siq,Harmalkar:2020mpd,Gustafson:2020yfe}. Here, we will use the computational basis state, so that $\ket{n}$ is a bitstring corresponding to eigenvalues of $Z_i$. 

Density matrix quantum Monte Carlo~\cite{PhysRevB.89.245124} or exact diagonalization can be used to compute the matrix elements $\rho_{nm}$. Let us now explain how we compute the matrix elements $\braket{n|U(t)|m}$. It is straightforward for $n=m$. For $n \neq m$ and noticing that it is easier to compute diagonal expectation values $\braket{\psi|\mathcal{O}(t) | \psi}$ than off-diagonal overlaps $\braket{\psi'|\mathcal{O}(t) | \psi}$ ($\ket{\psi'} \neq \ket{\psi}$, we will perform time-evolution starting from a superposition of bit-basis eigenstates 
\begin{align}
    \ket{\psi_\pm} &= \frac{1}{\sqrt{2}} \Bigl( \ket{n} \pm \ket{m} \Bigr) \\
    \ket{\psi_{\pm i}}&= \frac{1}{\sqrt{2}} \Bigl( \ket{n} \pm i\ket{m} \Bigr) \,.
\end{align}
Computing the four diagonal expectation values yields
% \begin{align}
%     \braket{\psi_{\pm} | U(t) | \psi_{\pm}} &= \frac12 \Bigl( U_{nn}(t) + U_{mm}(t) \pm 2 \text{Re} \, U_{nm} \Bigr)\\
%     \braket{\psi_{\pm i} | U(t) | \psi_{\pm}} &= \frac12 \Bigl( U_{nn}(t) + U_{mm}(t) \pm 2 i \text{Im} \, U_{nm} \Bigr)\,.
% \end{align}

\begin{align}
    \braket{\psi_{\pm} | U(t) | \psi_{\pm}} &= \frac12 \Bigl[ U_{nn} + U_{mm} \pm \Bigl( U_{nm} + U_{mn} \Bigr) \Bigr]\\
    \braket{\psi_{\pm i} | U(t) | \psi_{\pm i}} &= \frac12 \Bigl[] U_{nn} + U_{mm} \pm i \Bigl(U_{nm}  - U_{mn} \Bigr) \Bigr]\,.
\end{align}
If $U$ is also hermitian $U^\dag = U \rightarrow U_{mn} = U_{nm}^*$, these expectation values are both real (let's denote $U \equiv \mathcal{O}$ to distinguish from the case where $U$ is unitary)
\begin{align}
    \braket{\psi_{\pm} | \mathcal{O}(t) | \psi_{\pm}} &= \frac12 \Bigl[ \mathcal{O}_{nn} + \mathcal{O}_{mm} \pm \Bigl( \mathcal{O}_{nm} + \mathcal{O}^*_{nm} \Bigr) \Bigr] \\ 
    &=  \frac12 \Bigl( \mathcal{O}_{nn} + \mathcal{O}_{mm} \pm 2 \text{Re} \, \mathcal{O}_{nm} \Bigr)
\end{align}
and
\begin{align}
    \braket{\psi_{\pm i} | \mathcal{O} | \psi_{\pm i}} &= \frac12 \Bigl( \mathcal{O}_{nn} + \mathcal{O}_{mm} \pm i \Bigl(\mathcal{O}_{nm}  - \mathcal{O}^*_{nm} \Bigr) \Bigr] \\
    &= \frac12 \Bigl( \mathcal{O}_{nn} + \mathcal{O}_{mm} \mp 2 \text{Im} \, \mathcal{O}_{nm} \Bigr) \,.
\end{align}
In the case of non-hermitian (yet unitary) $U$, it only holds that $U^\dag = U^{-1}$, and we would need an ancilla based protocol to extract them using a quantum computer. Otherwise, we only have access to overlap probabilities
\begin{align}
    |\braket{\psi_{\pm} | U | \psi_{\pm}}|^2 &= \frac12 \Bigl| U_{nn} + U_{mm} \pm \Bigl( U_{nm} + U_{mn} \Bigr) \Bigr|^2 \\
    |\braket{\psi_{\pm i} | U | \psi_{\pm i}}|^2 &= \frac12 \Bigl| U_{nn} + U_{mm} \pm i \Bigl(U_{nm}  - U_{mn} \Bigr) \Bigr|^2
\end{align}



\section{Appendix}
The following initial Hamiltonian with periodic boundary conditions is used for system size $L$.
\begin{equation}
H_0 = -J\sum^{L}_{i=1} Z_i Z_{i+1} + g0 \sum^L_{i=1} X_i + h0 \sum^L_{i=1} Z_i+h_s \sum^L_{i=1} (-1)^i Z_i
\end{equation}

After a sudden change in the parameters, the quench Hamiltonian is 

\begin{equation}
H_1 = -J\sum^{L}_{i=1} Z_i Z_{i+1} + g1 \sum^L_{i=1} X_i + h1 \sum^L_{i=1} Z_i
\end{equation}


We used the Binder cumulant to find the cross-over diagram for this Hamiltonian.

% Figure environment removed

\begin{equation}
B_L = 1 - \frac{\left \langle O^4 \right \rangle _L}{3\left \langle O^2 \right \rangle ^2_L}
\end{equation}

Where $B_L$ is the Binder cumulant and $O$ is the order parameter. When the Binder cumulant is plotted as a of a hamiltonian parameter for different system sizes, the values of the hamiltonian parameters at the intersection point of the different graphs lie on the cross-over line. In FIG. 1. this is done for the pure state, beta=2.5, and beta=5.0. 





% Figure environment removed


The following shows all parameters for quenches used, initial parameters: g0=0.2, h0=0.0, final parameters: g1=1.0, h1=1.0 with z-basis and staggered magnetization observable and initial parameters: g0=1.5, h0=0.0, final parameters: g1=1.0, h1=1.0 (the paramagnetic phase on the crossover diagram) with x-basis and x-direction magnetization observable. $\beta=0.5, 1.0, 1.5$ and system size $L=8, 10, 12$. $J=1$, $h_s = 1/L$. When the observable is the staggered magnetization $M_{\pi}^z(t) = \frac{1}{L}\sum^L_{i=1} (-1)^i Z_i$ we use two-site translational symmetry to get additional simulations $\braket{n^{\prime}| M_{\pi}^z(t) |m^{\prime}} = \braket{n|T_2^{-1} e^{iH_1t}  M_{\pi}^z(0) e^{-iH_1t} T_2|m} = \braket{n| M_{\pi}^z(t) |m}$ since the two-site translation operator $T_2$ commutes with both $H_1$ and $M_{\pi}^z(0)$. When the observable is the x-magnetization $M^x(t) = \frac{1}{L} \sum^L_{i=1} X_i$ we use one-site translational symmetry to get additional simulations $\braket{n^{\prime}| M^x(t) |m^{\prime}} = \braket{n|T_1^{-1} e^{iH_1t}  M^x(0) e^{-iH_1t} T_1|m} = \braket{n| M^x(t) |m}$ since the one-site translation operator $T_1$ commutes with both $H_1$ and $M^x(0)$. 
For observable $O$. The diagonal ensemble for thermal initial states gives the infinite time behavior of the thermal expectation value of the observable $O(t)$.




\begin{equation}
\left \langle O(t) \right \rangle = \text{Tr}\bigl[ \rho_0 O(t) \bigr] =  \frac{1}{Z_0}\text{Tr}\bigl[ U(t) e^{-\beta H_0} U^{\dagger}(t) O \bigr]
\end{equation}

\begin{equation}
= \frac{1}{Z_0}\text{Tr}\bigl[  e^{-\beta H_0} U^{\dagger}(t) O U(t) \bigr]
\end{equation}

\begin{equation}
= \frac{1}{Z_0}\text{Tr}\bigl[  e^{-\beta H_0} e^{iH_1t} O e^{-iH_1t} \bigr]
\end{equation}


\begin{equation}
=\frac{1}{Z_0} \sum_{E_0} \braket{E_0| e^{-\beta H} e^{iH_1t} O e^{-iH_1t} |E_0}
\end{equation}


\begin{equation}
=\frac{1}{Z_0} e^{-\beta E_0} \sum_{E_1, E_1^{\prime}}\braket{E_0|E_1}e^{iE_1t}\braket{E_1| O |E_1^{\prime}}e^{-iE_1^{\prime}t}\braket{E_1^{\prime}|E_0}
\end{equation}


\begin{equation}
\lim_{t\to \infty} \text{Tr}\bigl[ \rho_0 O(t) \bigr]  =\frac{1}{Z_0} \sum_{E_0, E_1}e^{-\beta E_0} |\braket{E_0|E_1}|^2\braket{E_1|O|E_1}
\end{equation}




As the quantity is only non-zero when $E_1 = E_1^{\prime}$. In the infinite temperature limit, 


\begin{equation}
\lim_{t\to \infty} \text{Tr}\bigl[ \rho_0 O(t) \bigr]  =\frac{1}{Z_0} \sum_{E_0, E_1} \braket{E_1|E_0}\braket{E_0|E_1}\braket{E_1|O|E_1}
\end{equation}


\begin{equation}
=\frac{1}{Z_0} \sum_{E_1} \braket{E_1|E_1}\braket{E_1|O|E_1}
\end{equation}

\begin{equation}
=\frac{1}{Z_0}  \text{Tr}\bigl[ O(t) \bigr]
\end{equation}






To quantify the error from the simulations, the moving error defined as follows is used.

\begin{equation}
E(t) = \frac{1}{t}\sum_{t^{\prime}=0}^{t}\left(  \text{exact}(t^{\prime}) - \text{truncated}(t^{\prime})  \right)^2
\end{equation}


where $\text{exact}(t)$ is the exact expectation value $\text{Tr}\bigl[ \rho_0 O(t) \bigr]$ and $\text{truncated}(t)$ the truncated expectation value $\text{Tr}\bigl[ \rho_0^{\prime} O(t) \bigr]$ where $\rho_0^{\prime}$ is the truncated density matrix with trace renormalized  to one. The weight defined as the ratio of the Frobenius norms of the truncated and exact density matrix is.

\begin{equation}
w = \frac{\left \| \rho^{\prime} \right \|}{\left \| \rho \right \|} = \frac{  \sqrt{ \sum_{\rho^{\prime}}\rho^{\prime 2}_i}  }{ \sqrt{ \sum_{\rho}\rho^{ 2}_i}  }
\end{equation}


From DMQMC, the density matrix $\rho(\beta)$ is defined as the solution to the symmetric Bloch equation 

\begin{equation}
\frac{d\rho}{d\beta} = -\frac{1}{2}(H\rho + \rho H)
\end{equation}

Using a DMQMC initial state and sparse matrix time evolution allows going beyond exact diagonalization for the thermal dynamics.


% Figure environment removed


%\begin{table}[htb!]
%\begin{tabularx}{0.45\textwidth} { 
  %| >{\centering\arraybackslash}X 
  %| >{\centering\arraybackslash}X 
  %| >{\centering\arraybackslash}X 
  %| >{\centering\arraybackslash}X | }
 %\hline
 %\diagbox{$Jt$}{$EM$} & T-REX $\left \langle N | M_{\pi}^z(t) | N \right %\rangle$ & dZNE $\left \langle N | M_{\pi}^z(t) | N \right \rangle$ & PEC %$\left \langle N | M_{\pi}^z(t) | N \right \rangle$  \\
% \hline
% 0 & -0.99391144 & -0.96316406 & -1.00135058  \\
% \hline

%\end{tabularx}
%\caption{ Results from using Twirled Readout Error Mitigation T-REX, %digital Zero Noise Extrapolation (dZNE), and Probabilistic error %cancelation on IBM guadalupe for 16 qubits where $ | N > = | 0101...>$ }
%\end{table}





%\begin{table}[htb!]
%\begin{tabularx}{0.45\textwidth} { 
 % | >{\centering\arraybackslash}X 
 % | >{\centering\arraybackslash}X 
 % | >{\centering\arraybackslash}X 
 % | >{\centering\arraybackslash}X | }
 %\hline
 %\diagbox{$Jt$}{$EM$} & T-REX $\text{Tr}[\rho_0^{\prime} M_{\pi}^z(t)]$ & %dZNE $\text{Tr}[\rho_0^{\prime} M_{\pi}^z(t)]$ & PEC $\text{Tr}%[\rho_0^{\prime} M_{\pi}^z(t)]$ \\
 %\hline
 % 0 & 0.4495537899 & 0.4356465234 & 0.4529185701  \\
 %\hline

%\end{tabularx}
%\caption{ Results from using Twirled Readout Error Mitigation T-REX, %digital Zero Noise Extrapolation (dZNE), and Probabilistic error %cancelation on IBM guadalupe for 16 qubits with renormalized truncated %density matrix and two matrix elements  }
%\end{table}



The sampling is done in the x-basis if the quench begins in the paramagnetic region and in the z-basis if it begins in the anti-ferromagnetic region.



\begin{displaymath}
\left \langle n^{\prime}  \right | M_{\pi}^z(t)\left| m^{\prime} \right \rangle  = \left \langle n \right |I_{INV}^{-1}T_1^{-1} e^{iH_1t}  M_{\pi}^z(0) e^{-iH_1t} T_1 I_{INV} \left| m \right \rangle 
\end{displaymath}

\begin{displaymath}
= \left \langle n \right | M_{\pi}^z(t) \left| m \right \rangle
\end{displaymath}










%We can thus recover the desired off-diagonal element as
% \begin{align}
%     U_{nm}(t) &= \text{Re} \, U_{nm}(t) + i \text{Im} \, U_{nm}(t) \nonumber \\ & = \frac12 \Bigl( \braket{\psi_{+} | U(t) | \psi_{+}} - \braket{\psi_{-} | U(t) | \psi_{-}} \nonumber \\ & \quad + \braket{\psi_{+i} | U(t) | \psi_{+i}} - \braket{\psi_{-i} | U(t) | \psi_{-i}} \Bigr) 
% \end{align}
%\newpage 





\section{Error Analysis}
When deriving an error on the simulated results, there are two sources of obvious error one should consider: truncation and statistical.  When using DMQMC, both are present.  When simulating using ED, only truncation errors occur.  We will assume that $\rho_{ij}\geq0$, although extensions are potentially possible. 

Statistical errors are easily parameterized.  Given the DMQMC produces $N$ total psips distributed into matrix elements $\psi_{ij}=|i\rangle\langle j|$ with $N_{ij}$ in a given element distributed according to $\rho$.  With this we obtain an estimate $\tilde\rho_{ij}=N_{ij}/N$.  From Poisson statistics, we know that the statistical error on a given $\tilde\rho_{ij}$ is then $\sigma_{\rho}=\sqrt{N_{ij}}/N$

Truncation errors -- the harder to properly account for -- occur because a density matrix $\rho$ of since $2^L\times2^L$ contains $2^{2L}$ elements $\rho_{ij}$ which is a prohibitively large number as $L\rightarrow\infty$.  Thus instead of simulating $\rho$ to obtain $\langle \mathcal{O}(t)\rangle=\tr[\rho \mathcal{O}(t)]/\tr[\rho]$, we simulate $\tilde{\rho}=P\rho$ where $P$ is a projection operator that determines the which elements of $\rho_{ij}$ we explicitly simulate in $\langle\mathcal{O}(t)\rangle_{\tilde{\rho}}=\tr[\tilde\rho \mathcal{O}(t)]/\tr[\tilde\rho]$.  The choice of $P$ has been a source of discussion within the rest of the paper, with various choices considered. The remaining portion of the density matrix we denote by $\epsilon=(1-P)\rho$.  These missing terms contribute to the discrepancy between the exact result and the truncated $\rho$ we use for computational purposes.  

To see how we can ascribe an systematic error for this truncation, we can use the definitions of $\rho,\tilde\rho,$ and $\epsilon$ to work out the following:
\begin{align}
\langle \mathcal{O}(t)\rangle&=\frac{\tr[\rho \mathcal{O}(t)]}{\tr[\rho]\notag}\\
&=\frac{\tr[(\tilde\rho +\epsilon)\mathcal{O}(t)]}{\tr[\tilde\rho +\epsilon]}\notag\\
&=\frac{\tr[\tilde\rho\mathcal{O}(t)]}{\tr[\tilde\rho +\epsilon]}+\frac{\tr[\epsilon\mathcal{O}(t)]}{\tr[\tilde\rho +\epsilon]}\notag\\
&=\langle\mathcal{O}(t)\rangle_{\tilde{\rho}}\frac{\tr[\tilde\rho]}{\tr[\tilde\rho +\epsilon]}+\langle\mathcal{O}(t)\rangle_{\epsilon}\frac{\tr[\epsilon]}{\tr[\tilde\rho +\epsilon]}
\end{align}
where $\tr\epsilon/\tr\rho=1-\frac{\tr\tilde\rho}{\tr\rho}$, we can define $\kappa=\tr\tilde\rho/\tr\rho$ and get
\begin{align}
\langle \mathcal{O}(t)\rangle    &=\kappa\langle\mathcal{O}(t)\rangle_{\tilde{\rho}}+(1-\kappa)\langle\mathcal{O}(t)\rangle_{\epsilon}
\end{align}
It is important to note that while this equation is true, if we only sample $\rho$, there is no way to directly compute $\kappa$ from our incomplete data.  Further, one might think to take all the diagonal elements of $\rho$, in which case $\kappa=1$.  This doesn't remove the error from off-diagonal $\epsilon$ because $\langle \mathcal{O}(t)\rangle_\epsilon\propto(\tr\epsilon)^{-1}$ diverges.  We will come back to estimating $\kappa$, but importantly it is time-independent.

Let's now discuss $\langle \mathcal{O}(t)\rangle_\epsilon=\langle U(t)\mathcal{O}U(t)^{\dag}\rangle_\epsilon$.
In general $\epsilon$ will not be diagonal and thus we need a method for estimating every matrix element $\epsilon_{ij}$ without using knowledge of $\rho$. With such a method, we can compute $\tr \epsilon$ trivially. Additionally, even with the large $\tilde{\rho}$ provided from DMQMC, we may desire to neglect some of the elements we did compute because of computational limitations.  For this reason, it is important to distingish between the known $\epsilon^{k}_{ij}$ which are obtained in the DMQMC but not simulated, and the often larger set of unknown $\epsilon^{u}_{ij}$ which should respect $\epsilon^{u}_{ij}\lesssim\epsilon^{k}_{ij}$ since they were not sampled by DMQMC.  From this, we understand that 
\begin{align}
    \langle \mathcal{O}(t)\rangle_\epsilon=\frac{\tr[\epsilon\mathcal{O}(t)]}{\tr[\epsilon]}&=\frac{\tr[\epsilon^{u}\mathcal{O}(t)]}{\tr[\epsilon]}+\frac{\tr[\epsilon^{u}\mathcal{O}(t)]}{\tr[\epsilon]}\notag\\
    &=\langle \mathcal{O}(t)\rangle_{\epsilon^k}\frac{\tr[\epsilon^k]}{\tr[\epsilon]}+\langle \mathcal{O}(t)\rangle_{\epsilon^{u}}\frac{\tr[\epsilon^u]}{\tr[\epsilon]}\notag\\
    &\equiv\lambda\langle \mathcal{O}(t)\rangle_{\epsilon^k}+(1-\lambda)\langle \mathcal{O}(t)\rangle_{\epsilon^{u}}
\end{align}

Again, important to emphasize that while each $\epsilon^{u}_{ij}\lesssim\epsilon^{k}_{ij}$, for realistic simulations the number of non-zero elements in $\epsilon^u\gg \epsilon^k$ and thus $\lambda$ could be much smaller than 1.

Since we have explicit values for $\epsilon^{k}_{ij}$, we can use them to estimate the values of $\epsilon^{u}_{ij}$.  The most naive, but conservative guess would be to recognize that the smallest measurable probability for $\epsilon^{k}_{ij}$ from DMQMC is gotten from having only a single psip in that element.  Therefore the smallest nonzero probability is $1/N_{\rm psip}$ and thus we might set $\epsilon^{u}_{ij}=1/N_{\rm psip}$.  By inspecting Fig.~\ref{fig:e_distro}, one can see that this is an overly conservative estimate, and we can obviously do better.  The more sensible estimator of $\epsilon^{u}_{ij}$ would be to recognize that in the ordered list of Fig.~\ref{fig:e_distro}, we are monotonically decreasing and that it can be fit to $n$ piecewise power laws (or some more complicated function) $\epsilon^{k}_{ij}=a x^{-b}$.  Performing a fit to the last piece, we can get a function that can be used to bound the remaining $\epsilon^{u}_{ij}$.  For the piecewise approach, we would take $\epsilon^{u}_{ij}=a_n x^{-b_n}$

% Figure environment removed

At this point, we have an estimate for the weight of every $\epsilon^{u}_{ij}$, but there isn't any structure to map $ij\rightarrow x$.  Unfortunately, we cannot obtain this information, and thus we can't evaluate $\mathcal{O}$ directly on $\epsilon^{u}_{ij}$ and instead will have to use some estimator for it.  This same estimator, though, could also be used to compute the effect of $\mathcal{O}$ on $\epsilon^{k}_{ij}$ more cheaply.  If instead of agnostically mapping all $ij\rightarrow x$, we restricted ourselves to classes of $ij$, we could extract specialized functions for estimating specific portions of $\epsilon^{u}_{ij}$.  In general this is likely to be cumbersome and likely unhelpful, but for the case of $i=j$, this will give us a superior estimator of the $\epsilon^{u}_{ii}$ and thus the important $\tr \epsilon^u$.

Put together the protocol would be
\begin{enumerate}
    \item Obtain a $\hat{\rho}$ from DMQMC
    \item Choose $P$, which then defines the $\tilde{\rho}$ and $\epsilon$
    \item Using $\epsilon^{k}_{ij}$ data, determine $\epsilon^{k}_{ij}(x)$ and $\epsilon^{k}_{ii}(x)$
    \item Assuming $\epsilon^{u}_{ij}(x)=\epsilon^{k}_{ij}(x)$ and $\epsilon^{u}_{ii}(x)=\epsilon^{k}_{ii}(x)$ and start $x$ at the $x+1$ of $\epsilon^{k}$
    \item Compute $\lambda,\kappa,$ and $\langle\mathcal{O}(t)\rangle_\epsilon$
\end{enumerate}
where we haven't yet discussed how to estimate $\langle\mathcal{O}(t)\rangle_\epsilon$ given we want to avoid computing it for individual elements of $\epsilon$. As a first step, we will restrict ourselves to $t=0$ such that $U(t)=1$  In that case, 
\begin{equation}
    \langle \mathcal{O}\rangle_\epsilon=\frac{\tr[\epsilon \mathcal{O}]}{\tr[\epsilon]}
\end{equation}
since $\mathcal{O}$ is known exactly, we could compute directly $\langle \mathcal{O}\rangle_{\epsilon^k}$, although we may be able to make some estimate of $\mathcal{O}$ itself to avoid harder computations.  This also wouldn't help us with $\langle \mathcal{O}\rangle_{\epsilon^u}$


\


\

\section{L16 coherences}
To check coherences of the L16 DMQMC initial state weights. First I sorted the matrix elements from highest to lowest weight. Then I plotted the the following ratio vs. the matrix element number on an x-axis semilog graph to get
$ \frac{\sum_{i,j=1}^{m^{\prime},n^{\prime}}\rho_{0,ij}}{||\rho_0^{\prime}||_F}$



% Figure environment removed


\bibliography{refs}

\end{document}
