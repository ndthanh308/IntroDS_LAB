The development of increasingly capable Artificial Intelligence (AI) and Machine Learning (ML) techniques, 
is inspiring both industry and academia to build systems that automate the execution of certain tasks in a variety of applications. 
These systems do not replace humans, but rather help to simplify operations and, at minimum, the human is still responsible to provide goals to the intelligent agents that execute these tasks. Moreover, humans are involved in being part of the execution process by providing information that automation cannot infer reliably, or by making decisions whose consequences cannot be accurately predicted by the autonomous systems. Thus, at least for the foreseeable future, autonomous systems will be required to interact with humans, collaborating and complementing each other towards delivering systems that can effectively operate in complex environments. The design of these human-machine systems (HMS) challenges the adequacy of current development processes especially when the application domain is safety critical, such as commercial aviation. 
These applications require a high-level of assurance and demand for evidence that the closed-loop system satisfies stringent safety and performance requirements. 

Verification and Validation (V\&V) are critical steps in a high-assurance design process. A V\&V methodology (Figure \ref{fig:mhms}) defines the set of tools and techniques to arrive at a safety argument, including the functional view of the system, the modeling activities, and how to use their results. Several techniques can be used to generate evidence such as simulation, formal verification, and field-testing. While the latter is necessary at some point in the verification process, it involves prototyping and testing campaigns that are expensive. Field-testing alone becomes impractical for autonomous systems due to the large number of scenarios required to achieve coverage. For example, it is predicted that an autonomous car would need to drive in realistic conditions for billions of miles before reaching confidence on its safety statistics\cite{kalra_driving_2016}. Simulation and formal verification are therefore appealing alternatives aiming at reducing the amount of field-testing while at the same time providing confidence on safety and performance. These techniques rely on models that are machine-interpretable and that can be used in a systematic exploration of plausible scenarios to find errors. These models must include three sub-components (Figure \ref{fig:mhms}): the system comprising one or multiple machines, the environment, and the human. 
Developing these models is hard in general. Models of machines can be built by engineers, as they are the subject of the design activity. The environment and the human models are typically not readily available and require substantial development effort. Among these two, the environment model captures the physical space in which the system operates and can be developed by leveraging knowledge of the application domain. However, the development of capability, performance, and behavioral models of  humans is considerably harder, as it must account for behavioral, neurological, sociological, psychological, and systems aspects that are difficult to formalize. 
%For example, model checking is a tool that, given a formal model of a system and a property, checks if the model satisfies the property. In the case of a negative answer, model-checkers produce a scenario (i.e., a trace of events) that leads to the violation of the property. 

Given the importance of a virtual engineering platform for autonomy applications, and the complexity associated with building models of humans, this survey focuses on identifying the major currents and gaps in the ocean of knowledge about human modeling for the specification, design, verification and validation of HMS. We survey both simulation and formal models for the major functions of a human decision cycle including perception, cognition, decision-making, and action, and we also provide extensive background on performance and error models.

% Figure environment removed


\subsection{Overview of Human Models Surveyed} 

The human models surveyed in this paper span all 3 of these types: \emph{descriptive}, \emph{computational}, and \emph{formal}. 
Descriptive models represent the quality of the human behavior without producing any quantitative outputs. 
Computational models, in contrast, can be simulated or executed to produce quantitative predictions about the 
performance of the HMS. 
Formal models are rigorous mathematical descriptions that can be used for formal analysis.
Formal analysis differs from computational analysis in the sense that the former generates proofs that guarantee that certain properties of the system are satisfied under all modeled environment, while the latter can be used to test the system in a given scenario or sets of scenarios.  Formal methods are used in analysis, but they can also be used for synthesizing systems with given property, thereby enabling correct-by-construction design. 


In terms of specification language, descriptive models are typically given in a natural language such as English. 
Computational and formal models are specified using a rich variety
of mathematical and/or formal languages: 
static equations such as linear and nonlinear equations including neural networks, 
dynamical equations such as differential equations, Markov decision processes, Kalman filters, 
statistical models such as Bayesian nets, Structured Equation Models,
state-machines such as FSM, Petri-nets, programming languages as in cognitive architectures, and logic such as modal predicate logic. 

% As discussed, 
% verification is a critical step in a design process for high-integrity human-machine systems. 
% Besides testing, verification techniques can be categorized into 2 groups: simulation, or formal analysis. 
% Both groups rely on models that are machine-interpretable and 
% can be used in a systematic exploration of plausible inputs to find errors. 
% For example, model checking is an automated technique to prove if one mathematical specification (typically a model of the system) satisfies another 
% mathematical specification (typically a property representing a performance or safety criterion). 
% In the case of a negative answer, model-checking returns a scenario (i.e., a trace of events) that leads to the violation of the property. 

A typical property to be verified is whether the HMS satisfies certain performance or safety constraints. Oftentimes, performance models are constructed using certain hidden states or latent variables of a human such as boredom.  For that reason, we also survey the models that are based on those hidden states in the context of using them for design and verification. 

The survey starts in Section~\ref{sec:models-of-humans} by 
discussing some of the fundamental concepts of human modeling (see the human box in Figure~\ref{fig:mhms}) 
that are related to the OODA loop~\cite{Boy87}.  These ``first principles of human'', come from scientific studies of 
human behaviors and cognition from fields such as psychology, sociology and artificial intelligence.
This is followed by Section~\ref{sec:latent} with an introduction to various hidden states  modelled in the human factors field along with a discussion of the various ``failure modes'' of a human. 
This is motivated by our system-theoretic interpretation of the human, with inputs and outputs, 
unobservable hidden states, and faults.  
% The latent states, such as situational awareness, workload, and boredom, are hidden from direct measurements.  
% They may not even exist in a physical sense, but some of them have proven to useful for predicting performance of human-machine system. 
In Section~\ref{sec:formal-models}, we review formal models. 
The notion of an epistemic model is introduced and some of the challenges in
formally verifying epistemic models are discussed.  
In Section~\ref{sec:simulations} we review various computational or simulation models used in the analysis 
and verification of human-machine systems including integrated frameworks for the simulation of 
performance and behavior of a pilot in the cockpit. 
Finally, we conclude this paper with a set of recommendations on the research and development efforts needed to build a unified framework for modeling and V\&V of future human-autonomy systems. 
In summary, the models survey in this paper are categorized in Table~\ref{tab:summary0}. 
\begin{table}[htp]
    \caption{Summary of surveyed models}
\begin{tabular}{ |p{3cm}||p{4.5cm}| }
    \hline
	Category & Models Surveyed \\
	\hline
    Application & human-aviation systems \\
    \hline
	Capabilities  & visual and perception, cognition, decision making, actuation \\
    \hline
	Specification language & natural language, static equations,  dynamic equations, stochastic equations, logic, programs, state machines\\ 
    \hline
	Verification techniques & simulation, formal verification\\
    \hline
    Hidden states & workload, trust, situational awareness, boredom, complacency, vigilance \\  
	\hline
\end{tabular}
\label{tab:summary0}
\end{table}


\subsection{Related Work}

There are prior works in the literature which also survey 
human modeling for the purpose of verifying human-machine interaction. 

For example, in~\cite{bolton2013using}, Bolton et al. provides perhaps the earliest known surveys 
 on human models for formal verification of human-computer interaction (HCI).  
In addition, Weyers et al. in their book~\cite{weyers2017handbook} provide a comprehensive collection of works on 
 formal methods usage in human-machine interaction illustrated on a set of well-known 
case studies in the HMI domain, and a detailed overview of past, current and future developments of formal methods in HCI.  
Unlike those previous works, this paper surveys all models of human operators for
the verification of human-machine systems, not just models for formal verification, 
but also models for simulation and execution.  
The prior works also surveyed broader set of application domains 
unlike this work which is primarily driven by the need for a human-autonomy 
virtual engineering platform as shown in Figure~\ref{fig:mhms}. 




