This section presents a survey of the simulation (or computational) 
models. By simulation, we also mean models that 
are compiled and then executed. 
Simulation models tend to contain more details than formal models, but 
verification using simulations is non-exhaustive in the sense that for 
most cases, it is not possible to simulate all possible inputs.  

\subsection{Models of Visual Processes}

Some of the more recent works in building visual attention models for simulation include a
cognitive architectural model with eye-tracking data in~\cite{Fle06}, a salience model~\cite{Itt98} for computerized scene analysis, and a Markov model 
in~\cite{Mel06}.  The salience model~\cite{Itt98} led to many further works in robotics
on duplicating the human visual capability.  The model is based on a biologically-plausible
architecture by Koch and Ullman~\cite{Koc87}. It assumes the existence of a master salience
map~\cite{Tho05} in
the posterior parietal cortex of primates that is influenced by top-down factors such goals and
knowledge.  This salience map is also influenced by a topographical map computed in a bottom-up
parallel process from feature maps (color, intensity, orientation, etc.) generated from the input
scenery. The regions on the salience map with the highest values correspond to a more rapid or
accurate response from the human operator. A recent significant advancement within the salience
framework is a fast computational model based only on the log spectrum of the input
image~\cite{Hou07}. 

Another important question that is addressed by perception 
modeling is \emph{visual attention allocation}, namely how much attention from the human operator a given area of the display captures relative to other areas. An analytic model for computing attention allocation is the
SEEV (Salience, Effort, Expectancy, and Value) model~\cite{Wic01}. This model was
developed for aviation applications, such as pilots in the flight deck~\cite{wickens2015noticing}, 
and has been extended to models of visual attention of
drivers~\cite{Mod06}.  The model is a simple function of four different variables: salience (the
likelihood that the visual event will attract attention), effort  (the amount of effort required
to re-allocate attention to the event), expectancy (the bandwidth and rate of information flow
generated by the event), and value (a measure of the cost of not processing the
event~\cite{Cas13}).  The
output of the function is the probability that a given area of the interface display will attract
the operator's attention.

Most recent developments in computer vision have been based on very large 
convolutional neural networks (CNN)~\cite{krizhevsky2012imagenet, he2016deep, he2017mask} trained on very large datasets~\cite{deng2009imagenet}
for tasks such as image classification and detection. The effective use of a black box model such as a CNN for the purpose of verifying 
human performance remains an open question.

\subsection{Models of Cognition}

For cognition, sophisticated simulation models such as 
cognitive architectures have been applied in
a wide variety of domains ranging from education~\cite{sweller1998cognitive} 
to aviation (see NASA and AFRL studies in~\cite{foyle2005human,gluck2006modeling}). 
Some examples of state-of-art cognitive architectures
include ACT-R~\cite{Leb98}, SOAR~\cite{Lai12,New92}, CHREST (Chunk Hierarchy and Retrieval
Structure)~\cite{Gob01}, ICARUS~\cite{Lan06}, and MIDAS~\cite{tyler1998midas}. 
The shared features of these cognitive architectures are:  
\begin{enumerate} 
\item A collection of underlying knowledge about the human intelligence such as how
short and long-term memories are formed and retrieved, and how the information from
memory gets processed.  
\item The production system representation which is an executable program with a set
of rules governing the behavior of an underlying phenomenon that it is describing.  
\item The problem space approach, 
	which includes a desired final state (also called goal), the initial state, 
	a set of the operators from a problem space 
	that when applied to a state lead to another state, and the search strategy over the problem space. 
\end{enumerate} 

Some cognitive architectures  are specialized for certain applications. The EPIC architecture of Meyer
and Kieras~\cite{Mey97}, for example, is especially suited for modeling multi-modal and
multi-task performance. Another example is the GOMS (Goals, Operators, Methods,
and Selection) architecture~\cite{Car83}, a simple cognitive architecture used to make qualitative
and quantitative predictions for normative or repetitive cognitive tasks in the
domain of human-computer interaction. In the context of aviation, the GOMS
framework has been used in the analysis of an advanced automated cockpit~\cite{Irv94},
and the ACT-R architecture has been used in modeling the differences in
skill acquisition of an ATC task~\cite{Taa02}. Cognitive architectures have also
incorporated other aspects of the human operator including, but not limited to,
perception, sensing, and actuation~\cite{And04}. Using a unified cognitive architecture
such as ACT-R, allows for developing a computational models of a human operator
executing a task in a particular domain.

\subsection{Models of Decision Making Processes}

Mathematical
representations of the lens model was developed in the works of Hammond and Hursch~\cite{Ham64}, and has been applied
to the study of air traffic control systems such as the work in~\cite{Bis03}. In this work, the authors quantify the
differences between the decisions made by a human air traffic controller against the decisions of the
automated air-collision alert algorithm. The mathematical model has the following structure: the
human judgment is assumed to be a probabilistic affine function of the cues, the environmental
criterion under judgment is assumed to be another probabilistic affine function of the cues, and the
measure of the accuracy of the human judgment is a nonlinear function of the correlation of the two
function outputs, the predictability of the two functions, and the correlation between the errors of
the two function outputs. 


Another approach involves building expert systems, which are computer programs that mimic expert decision-making.  
In an expert system, the decision-making process of the human is captured by an inference process,
driven by if-then-else rules that use known facts from a knowledge database. 
In domains such as aviation, expert systems~\cite{endsley1987application} 
have been created to automate some of the functionality that were previously allocated to the human. 
In that sense, an expert system is a functional model of human decision-making. 

Simulation models of human decision-making 
have also utilized formalisms ranging from stochastic processes to continuous dynamical systems. 
One such modeling framework is the decision field theory (DFT)~\cite{busemeyer1993decision} which attempts to capture the dynamics of the human cognitive process in decision-making using a diffusion process, and has been used to predict response time and course of action under timing constraints and uncertainties.  In the context of air
traffic control (ATC) in the National Airspace System (NAS), models ranging from a
Partially Observable Markov-Decision Process (POMDP) in~\cite{Nie04}, to a Dynamic Bayesian Network
(DBN) in~\cite{Aco08} have been used. Furthermore, there are game-theoretic models such as the one in~\cite{Tom98}, and dynamical system models of human decision making such as the dead-reckoning navigational filter model used in~\cite{Pri01} or the Markov chain of Kalman filters used in~\cite{Pen99}.  Finally, a quantum dynamics model of human decision making (i.e. a model that describes the evolution of probabilistic amplitudes) was presented in~\cite{busemeyer2006quantum} and compared with a Markovian model. 
%More details on the stochastic process modeling of human operator can be found in Section\ref{subsec:stochastic}. 

\subsection{Models of Tasks} 

Task analysis, and its specialized sub-field of cognitive task analysis (CTA)~\cite{schraagen2000cognitive} is a large collection of methods and tools for extracting expert knowledge, thought processes, and goals in the performance of tasks. In another words, it is an approach to describe the physical and cognitive tasks to accomplish an activity.   CTA is done for both observed behavior and latent cognitive functions.  It has been applied widely in the aviation domain~\cite{leiden2002information,seamster2017applied} as a knowledge capturing mechanism. 
With increased frequency, CTA is used by airlines and the  air traffic control community for the design of automation and training on the flight deck, operations, and the flight control tower.  For example, in~\cite{deutsch2005single}, the results of a CTA are used as inputs for modeling human operator performance in approach, landing, ATC, and ground operations of a single piloted aircraft. Task analysis are typically performed to capture expert knowledge such as task definitions and decomposition of missions.   Task definitions and decomposition are important steps to build task models for tools such as IMPRINT or other discrete-event simulators so that 
performance, typically workload, can be assessed for the scenario or application at hand. 

In~\cite{martinie2014fine}, a task hierarchical notation called HAMSTER augments the typical 
task hierarchy modeling formalism with information about system failures and human errors to analyze their effects on operator performance.

\subsection{Models of Workload} 


There are numerous mental workload modeling methodology and tools, based on the multiple resources theory (MRT), for the simulation and prediction of operator performance.  They are especially useful for cases where it is not feasible to perform experiments on the actual system, environment and operators.  The task analysis workload (TAWL) framework ~\cite{hamilton1990task} and the TAWL operator simulation system (TOSS) was an early  methodology developed for the prediction of operator workload.  In the methodology, mission segments are decomposed into individual tasks, that are then modeled and simulated. This methodology bears resemblance to the task network modeling paradigm in the operator workload prediction tool IMPRINT~\cite{mitchell2000mental}.  Cognitive architectures such as the MIDAS performance tool~\cite{tyler1998midas} and ACT-R have also incorporated workload modeling methodology based on the MRT. 

Various computational models of multiple resource theory can be found in~\cite{sarno1995role,wickens2002multiple, horrey2003multiple} where~\cite{wickens2002multiple} is a simpler version of the model in~\cite{sarno1995role} and applied to the prediction of driving performance and interference in~\cite{horrey2003multiple}. These computational models can be distinguished from tools such as IMPRINT in that they can be used to predict more than just resource demand, but also task interference and re-allocation of resources.  Unlike most of the mental workload tools, MRT computational models can capture both cases when residual capacities exist in the human operator as well as when the operator is overloaded. The principle of multiple-resources has been used in various applications such as the development of cognitive architecture models for predicting workload~\cite{jo2012quantitative},  analysis of new cockpit display designs~\cite{wickens2003attentional}, and air traffic safety management~\cite{blom2001human}.

It was noted in~\cite{meshkati1988eclectic} that different performance metrics across different tasks make standardization of a performance-based workload measure difficult across domains.  Subjective evaluation techniques such as SWAT~\cite{reid1988subjective} or the NASA-TLX (task load index)~\cite{hart1988development} are methods that rely on self-reported ratings from operators, and/or observers. This is the most common technique used for the measurement of workload.  There are both one-dimensional and multi-dimensional workload rating scales in the literature. The latter typically aggregates the individual ratings into a single final workload value using either pair-wise weightings~\cite{hart1988development} or conjoint analysis~\cite{reid1988subjective}. The multi-dimensional scaled ratings are based on the assumption that the operator can evaluate the individual components of the workload better than the overall workload. Finally, the psycho-physiological techniques~\cite{dussault2005eeg,iqbal2004task,jorna1992spectral,may1990eye,vicente1987spectral} attempt to quantify workload by interpreting the measures of physical and neurological cues such as heart rate, EEG output, eye movements, pupil response, respiration rate, blood pressure, and sinus abnormalities.


\subsection{Models of Situational Awareness}
An early computational model of SA can be found in the work by Shively et al.~\cite{Shi97}.
This model is build within the MIDAS environment, and 
became the foundations for the more recent
computational model A-SA~\cite{McC02}. The A-SA consists of a low-level attention
module coupled with a high-level belief module. The attention and belief
modules are based on existing models of cognition and perception.  For example,
the attention module in A-SA is borrowed from Bundesen's 1990 work on the theory of
visual attention~\cite{Bun90} which has similarities with the more advanced SEEV model
introduced earlier.  The output of the model is a SA decay curve, in which the
rate of decay is a function of the distance between the evidences produced by
the visual module and the operator's current internal model of the world.  The
A-SA model has been mostly applied to applications in aviation such as pilot errors~\cite{Wic08}.  

\subsection{Models of Trust}

% Vigilance is incorporated in ~\cite{wellbrink2004modeling} as part of its overall computational model of 
% the human operator which includes an information processing module and a multiple resource module. The inputs to the model are   
% various objective and subjective factors related to the task at hand, the operator, and the environment. 

In~\cite{wiegmann2001automated,bisantz2001assessment,yeh2001display} the relations between the many variables in a human-machine system such as workload, difficulty of the task, system failure types, automation reliability, and interface display, are related to the notion of trust in the automation. 
A dynamical model was discussed in the survey paper~\cite{lee2004trust} where trust is dependent on a dynamical interaction between the operator, the interface, the automation, and the context. A closed-loop model of trust versus reliance was provided in which the interaction with the automation influences trust which in turn affects the interaction with the automation. Although there are many conceptual models of trust, only few computational models exist in the literature. In~\cite{gao2006extending}, a stochastic process model of decision-making in the context of human supervisory control, i.e. a binary decision process between manual control and automation control, was used to capture trust in a dynamic setting.  This model, which extends decision field theory to take into account prior decisions in a sequential decisions process, replicates several empirical nonlinear relations between trust, self-confidence and reliance. In~\cite{israelsen2021introducing}, a real-time multi-modal model of trust was produced based on structured equation modeling (SEM)~\cite{hoyle1995structural} which is a collection of statistical modeling and inference techniques that has had a long history of usage in the social sciences~\cite{morgan2015counterfactuals}. 



\subsection{Integrated Modeling and Simulation Environments}

A recent trend in human modeling research is to focus on the integration of
theories, models, and tools together into a complete human performance modeling
environment. Cognitive architectures such as SOAR and ACT-R are some of the
most popular examples of integrated modeling environments. 
Another popular approach is based on a task network model where nodes (tasks) are events with triggering conditions, side effects during and post-execution, workload values, and probability of failures, and connections are transitions between the tasks. These approach is general and can readily accept many
theories, models and data from the human operator modeling literature. Workload assessment is done by running Monte-Carlo simulations on the task network model using a discrete-event simulator. The tool IMPRINT~\cite{Mit04} and its early
precursor SAINT~\cite{Pri74} are some examples of discrete-event modeling environment which 
have been specialized for assessing workload.  

Recent integration efforts connect distinct modeling and simulation environments together to handle more complex system-of-systems.  An argument for this approach is made in the introduction of~\cite{Leb05}.  As the system
being modeled becomes more complex, one modeling or simulation 
paradigm may not cover all the possible domains in the system.  Extending one paradigm to cover the new domains may not be possible since its capability might be stretched beyond
those for which it is a natural fit. The approach to address this problem is the
integration of other environments that are already well-suited for those
new domains.  An example of such effort is the IMPRINT/ACT-R integration done
in~\cite{Lau06} which was used to model and simulate an approach and landing problem provided by NASA. IMPRINT be naturally used for modeling all sequences of tasks at hand, while ACT-R is a natural environment for predicting human performance for each task. 
Another example is the composite cognitive
architecture QN-MHRP from~\cite{Liu06} which connects a queuing network model
with a cognitive architecture in order to study human performance on 
concurrent activities. 
Queuing networks are well-suited for modeling
parallel activities, while cognitive architectures are 
well-suited for predicting a person's action on a specific task. 

Other more specialized integrated environments include the MIDAS tool by NASA
Ames~\cite{Tyl98}, which is used in the design and analysis of cockpits and ATC
interfaces.  The distributed operator model architecture (D-OMAR), which is a
multi-tasking extension of the event-based modeling architecture OMAR~\cite{The96}, has
been used for modeling pilots in various studies in aviation, one of which
is the NASA human performance modeling study reported in~\cite{Lei05}.  This study was part of a
multi-year effort~\cite{Foy07}, which detailed the modeling
challenges and solutions of five teams, each using a different human performance
simulation and modeling environment (ACT-R, ACT-R/IMPRINT, Air MIDAS, D-OMAR and A-SA), to 
model and predict pilot performance and/or errors in two different contexts: 
instrumented approach and landing, and taxiway operations.
WMC or Work Models that Compute~\cite{pritchett2014modeling,pritchett2014work} 
is another integrated simulation framework that has been 
used to study human performance in aviation~\cite{lee2017simulating}. 
WMC allows the modeling of both the human and autonomous agents.  
The hybrid timing of its simulation engine enables simulation of both continuous-time dynamical systems and 
event-driven agents. 

\subsection{Applications to Human-Aviation Systems} 

An early study of single-pilot operations in the context of evaluating new advanced cockpit and control technologies for military helicopters can be found in~\cite{haworth1986investigation}.  In this study, test pilots were used in experimental simulations, and several subjective ratings scales including SWAT were used to evaluate cockpit workload. It was found that despite the advances in the cockpit, single-pilot operations increased workload. 
A model-based approach was taken in~\cite{deutsch2005single} to evaluate single-pilot commercial operations, where a two-pilots model built using the D-OMAR architecture was used as the baseline for evaluating performance in the single-pilot case and prior cognitive task analysis of approach, landing, and taxiing in~\cite{leiden2002information} was used as insight for the human performance models. 
It has been speculated in~\cite{harris2007human} that single-pilot commercial aircraft can be designed using mostly existing technology and available human factors models by  re-designing the flight deck to re-allocate some pilot functionality to automation and/or ground control. 

Navigation errors have been modeled in D-OMAR~\cite{deutsch2002modeling} and ACT-R~\cite{byrne2005using}.  In the former, navigation errors are captured in the model as the result of an unconscious winner-take-all selection of the wrong ``intention-to-act'', where each ``intention-to-act'' is some pre-generated cognitive plan to be executed. In the latter, the errors are revealed as the result of complex interactions between the cognitive model of the pilot, co-pilot, air traffic controller, and the model of the airport environment.


While experimental studies about single-pilot operations (SPO) in aircraft goes back decades~\cite{haworth1986investigation}, there are only a few works in the literature that have attempted the quantitative modeling and prediction of pilot performance in a single-pilot cockpit.  In both~\cite{stimpson2016assessing} and ~\cite{wolter2015validated}, a task analysis approach was taken.  
In~\cite{wolter2015validated}, task analysis of single-pilot concept of operations architectures was performed.  The scenarios  modeled in this work were related to the approach and landing portion of a flight into Denver airport. Task models were visualized in the environment Mirco Saint Sharp.  Performance measures based on  task counts and workload were compared against a baseline scenario of current day crew complement. 
In~\cite{stimpson2016assessing}, the modeling and simulation framework Pilot-Autonomy Workload Simulation (PAWS) measured the utilization of tasks, which has been applied in a prior work~\cite{cummings2007developing} to approximately measure a pilot's workload.  A custom discrete-event simulator was built to simulate the completions of tasks of various agents over the course of an entire flight from take-off to landing. The framework enabled a flexible configuration of different operational architectures, contingencies in scenarios, and degree of autonomy of the cockpit.  

The MDP framework was used in~\cite{feng2015controller} to model the interactions between a human operator and a UAV for the automatic synthesis of controllers. The human operator was modelled using a DTMC, and the UAV as MDP.  The two systems in closed-loop form a product MDP, which is then processed by a MDP synthesis algorithm to yield a controller for the UAV.  

Recent works in~\cite{boussemart2008behavioral,boussemart2011predictive} have also modelled human behaviors using the HMM approach.  In~\cite{boussemart2008behavioral}, a HMM was used to model the human supervisory control (HSC) of unmanned vehicles  and then used for predicting the future actions of the operator.  In~\cite{boussemart2011predictive} the modeling of HSC is extended using a hidden semi-Markov model in order to capture the timing of the transitions between the states which is important when the operational tempo of the HSC needs to be taken into account.  


\subsection{Comparative summary}
Table \ref{tab:summary2} lists the models we have surveyed in this section. The attributes we have used to classify simulation models are similar to the ones in Section \ref{sec:formal-models-comparative-summary}, with the following differences. \emph{Formalism} refers to the structure of the computational model used in simulation. \emph{Stochastic} indicates whether the model can accommodate uncertainties in the inputs, outputs, and states of the system, and whether simulation supports them. Similarly,  \emph{Epistemic} refers to the ability to model and simulate  knowledge and beliefs. Finally, the \emph{Tool} column indicates whether  there is an integrated tool-chain with a frontend modeling environment that is connected to compilation, execution and simulation back-ends.

We observe a general good support for time and systematic uncertainty. This is expected given that simulation models often rely on discrete event simulation engines, that probabilistic events can be handled using random number generators, and that uncertainty quantification can therefore be done using Monte-Carlo methods. However, handling more complex epistemic properties seems to be out of reach. We also observe a pretty good availability of tools which are typically easier to build than in the case of formal verification. 

\begin{table*}
    \centering 
    \caption{Summary of surveyed simulation models}
\begin{tabular}{ |p{3cm}||p{3cm}|c|c|c|c|c|}
    \hline
	Model & Focus & Formalism & Timing & Stochastic & Epistemic & Tool \\
    \hline 
    Salience~\cite{Itt98} & Visual Attention & Neural Network & Yes & No & No & Yes \\ 
    \hline 
    SEEV~\cite{Wic01,wickens2009nt}& Visual Attention & Analytic & Yes & No & No & No \\
    \hline 
    CNNs~\cite{krizhevsky2012imagenet} & Vision & Neural Network & Yes & No & No & Yes \\ 
    \hline 
    ACT-R, SOAR, CHREST, ICARUS& General Purpose & Cognitive Arch. & Yes & Yes & No & Yes \\ 
	\hline
    EPIC, GOMS & Tasks & Cognitive Arch. & Yes & ? & No & Yes \\
    \hline 
    LENS~\cite{Bis03} & Decision & Multi-linear regression & No & No & No \\
    \hline 
    Multiple~\cite{Nie04,Aco08} & Decision & Stochastic process & Yes & Yes & No & No \\
    \hline 
    Tomlin et al.~\cite{Tom98} & Decision & Game-Theoretic & Yes & No & No & No \\
    \hline 
    Multiple~\cite{Pri01,Pen99}  & Decision & Dynamical Systems & Yes & No & No & No \\
    \hline 
    Busemeyer~\cite{busemeyer2006quantum}  & Decision & Quantum Dynamics & Yes & Yes & No & No \\
    \hline
    Shively et al.~\cite{Shi97} & SA & MIDAS & Yes & No & No & No \\
    \hline 
    A-SA~\cite{McC02,Wic08} & SA & Analytic & Yes & No & No & No \\
    \hline 
    Multiple~\cite{dussault2005eeg,iqbal2004task,jorna1992spectral,may1990eye,vicente1987spectral} & Workload & Empirical & Yes & No & No \\
    \hline 
    SWAT and NASA TLX & Workload & Surveyed Data & No & No & No & No \\
    \hline 
    TAWL and TOSS~\cite{hamilton1990task} & Workload & Task Network & Yes & No & No & No \\
    \hline 
    Gao et al.~\cite{gao2006extending} & Trust & Stochastic process & Yes & Yes & No & No \\
    \hline
    Israelsen et al.~\cite{israelsen2021introducing} & Trust & SEM & Yes & No & No & No \\
    \hline 
    Martinie et al.~\cite{martinie2014fine} & Tasks & Task Hierarchy & No & No & No & Yes \\
    \hline 
    Task Analysis & Tasks & Task Hierarchy & No & No & No & Yes \\
	\hline
    PAWS~\cite{stimpson2016assessing} & Single Pilot Workload & Discrete-Event & Yes & ? & No & Yes \\
    \hline
    OMAR, IMPRINT, SAINT & General Task + Workload & Discrete-Event & Yes &  Yes & No & Yes \\
    \hline
    D-OMAR & Distributed Pilot Task + Workload & Discrete-Event & Yes &  Yes & No & Yes \\
     \hline
    Feng et al.~\cite{feng2015controller} & Mission Execution Time  & Stochastic process & Yes &  Yes & No & No \\
    \hline 
    QN-MHRP from~\cite{Liu06} & Concurrent Tasks & Integrated & Yes & Yes & No & Yes \\ 
    \hline 
    MIDAS & Cockpit and ATC Interface & Integrated & Yes & Yes & No & Yes \\
    \hline
    ACT-R/IMPRINT & General Purpose & Integrated & Yes & Yes & No & Yes \\
	\hline 
    WMC~\cite{pritchett2014work} & General Purpose & Integrated & Yes & ? & No & Yes \\
    \hline
\end{tabular}
\label{tab:summary2}
\end{table*}