% The very first letter of the paper is a 2 line initial drop letter
% followed by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

\iffalse
\IEEEPARstart{T}{his} demo file is intended to serve as a ``starter
file'' for ICCP 2020 submissions produced under
\LaTeX~\cite{kopka-latex} using IEEEtran.cls version 1.8b and later.
\fi



\IEEEPARstart{I}{}n imaging devices, a crucial step involves projecting information from a high-dimensional scene space onto a lower-dimensional reconstruction space. This projection serves the dual purpose of data reduction for human interpretation and the extraction of actionable patterns pertaining to the scene. Information from a 3D scene involving color, timing, polarization, and phase has to be encoded on a 2 dimensional image sensor. This process, often termed coding or multiplexing, is a fundamental and essential aspect of both physical and computational considerations in imaging and vision devices.

Mathematically, coding, it can be described as a linear operator, $\B{M}$ linking a vectorized incoming light field $\B{x}$ to a vector of light measurements $\B{y}$. The \textbf{single-pixel-camera} is considered as a typical example of this model. Supposing the image of the field of view consists of $N \in \IZ^+$ pixels and is measured by $m \in \IZ^+$ projections, 
  the single-pixel-imaging process, if ignoring noise, can be expressed as the following equation 
 \begin{equation}
    \label{eqn:NoiselessMeasurement}
    \begin{aligned}
        \B{y} &=  \B{M x} ,
    \end{aligned}
\end{equation}
where $\B{x} \in \IR^{N \times 1}$ is the image representation of the field of view (FOV), $\B{M} \in \IR^{m \times N}$ is a set of sensing masks linearly projecting the field of view onto the sensor pixel, and $\B{y} \in \IR^{m \times 1}$ are the corresponding measured {flux} levels or photon counts \cite{willet2009CSPoisson}. Physically, $\B{M}$ can be implemented by directing or blocking different parts of the incoming light with masks \cite{raskar2009computational} and averaging them on sensors that digitize the detected flux levels or photon counts.

In this work we will study the performance of this camera for different choices of $\B{M}$ under different noise models. The single pixel camera is intended specifically as a toy model that exhibits the more general dimensional reduction problem experienced by all imaging devices. Our goal is to design $\B{M}$ such that it allows us to extract desired information from the scene when combined with digital processing. In other words, we seek to design an end to end vision system and consider both the physical and the digital part of the design. While a compressed sensing system that reconstructs an image fits this paradigm, we will focus on highly compressible problems such as character recognition. In these problems the differences between the common linear model of the camera and the real Poisson noise model are most apparent.


%A linear operator with a mask can model most optics, including a lens that forms an image, color filters that provide color resolution, and camera pixels that average incoming light over an exposure time. The digitized vector then is processed computationally to extract the desired information about the scene. For a full rank measurement $\B{M}$, a linear operation $\B{M}^{-1}$ can in principle allow reconstruction of the entire incoming measurement. In the simplest case, where the desired information is directly digitized, $\B{M}$ is a diagonal matrix. However far more elaborate capture and post-processing are being employed and are the basis of diverse fields such as structured illumination imaging, computational imaging (CI) \cite{cossairt2012does} and compressed sensing. The primary benefits of complex codes are the improved signal to noise ratio do to the fact that the corresponding masks transmit more light, as well as the possibility of using fewer masks and thereby reducing the overall complexity of the measurement.



% Coding schemes have been extensively studied, but usually based on low noise scenarios or Additive Gaussian noise (AGN) models. AGN is a linear noise model that allows for rigorous mathematical treatment. It is a good model for the readout and background noise introduced by imperfect measurement hardware of past cameras and sensors. However, with the advancement of optical imaging and single photon sensitive sensor technologies, readout noise is decreasing, and Poisson noise is becoming  dominant in measured imaging data\Xhide{ \cite{harwit1979hadamard}}. While the readout noise level of consumer cameras is approaching single electron levels, many state-of-the-art and emerging sensors technologies, such as Single-photon Avalanche Diode (SPAD), Quanta Image Sensors (QiS), and qCMOS cameras, directly measure quantized photon counts and as a result only experience Poisson noise \cite{foord1969PMT, prescott1966PMT, lombard1961PMT}. 
Coding schemes, often developed under signal independent Additive Gaussian Noise (AGN), provide a mathematically tractable framework. While AGN is suitable to model certain types of noise introduced by the measurement device, it does not correctly model Poisson noise. In almost all modern cameras and sensors, however, Poisson noise is predominant, especially in advanced sensors like Single-photon Avalanche Diode (SPAD), Quanta Image Sensors (QiS), and qCMOS cameras \cite{foord1969PMT, prescott1966PMT, lombard1961PMT}.  This necessitates a reevaluation of coding strategies tailored to this noise type.

% Poisson noise is a fundamental physical property of light and arises from the discrete nature of light measurements. It is impossible to spread out a photon measurement over all the open pixels in a mask as the linear model introduced in Equation \ref{eqn:NoiselessMeasurement} assumes. The measurements of $\B{y}$ that equation calls for are therefore impossible. Unfortunately, this has the consequence that the coding and thereby compressed sensing approaches designed to be effective under AGN or noiseless conditions are not recommended under Poisson noise and their use is discouraged in the literature \cite{harwit1979hadamard, swift1976hadamard, willet2009CSPoisson, scotte2022photon_noise, vanden2019various}.
Poisson noise, a fundamental property of light, arises due to the discrete nature of light measurements. Unlike the assumptions of the linear model in Eq.  \ref{eqn:NoiselessMeasurement}, it's impossible to distribute a photon measurement across all open pixels in a mask. Consequently, the measurements $\B{y}$ called for by the equation are unattainable. This renders coding and compressed sensing approaches, designed for effectiveness under the AGN or noiseless conditions unsuitable. The literature discourages their use in such scenarios \cite{harwit1979hadamard, swift1976hadamard, willet2009CSPoisson, scotte2022photon_noise, vanden2019various}. The optimal code, denoted as $\B{M}_P$, for measurements limited by real Poisson noise must converge to $\B{M}_G$ applicable to the optimal code under Additive Gaussian Noise (AGN) or under no noise as the number of measured photons tends toward infinity. However, it is crucial to highlight that, as demonstrated below, $\B{M}_P$ does not necessarily exhibit similarity to $\B{M}_G$ for any finite number of photons.

\AVnote{\checkednote{The optimal code $\B{M}_P$ for a real Poisson noise limited measurement has to approach the $\B{M}_G$ for a noise-less measurement or one under AGN as the number of measured photons goes to infinity. Crucially, however, as we will show below $\B{M}_P$ does not become similar to $\B{M}_G$ for any finite number of photons.}}

% \YLnote{Harwit et al may not say against compressed sensing, but Van den Broek et al mentioned it}
\Xhide{
\Xpolish{In most of the papers, people optimize the algorithms on reconstruction but keep using random coding \cite{goyal2016performance}. Some other work, such as Feature Specific Imaging (FSI) does optimize the sensing matrices based on some learn-able priors \cite{neifeld2003dual, neifeld2003FSI, neifeld2014optimizing}, but how to optimize masks under Poisson noise remains an unsolved problem \cite{neifeld2014optimizing}. Meanwhile, some attempts on matrix optimization based on minimal mutual coherence are not based on Poisson noise model itself \cite{mordechay2014matrixRIP} and is proved defective in this paper.}
{
\AVnote{this seems like it belongs into related work}
In many papers, optimization efforts focus on algorithmic enhancements for reconstruction, often maintaining the use of random coding strategies \cite{goyal2016performance}  \YLnote{need more here}, though this type of matrices are not recommended under Poisson noise\cite{willet2009CSPoisson}. While some approaches, such as Feature Specific Imaging (FSI), optimize sensing matrices based on learnable priors \cite{neifeld2003dual, neifeld2003FSI, neifeld2014optimizing}, these methids explicitly do not consider Poisson noise. Thus the challenge of optimizing masks under Poisson noise persists \cite{neifeld2014optimizing}. Additionally, attempts at matrix optimization focusing on minimal mutual coherence lack a foundation in the Poisson noise model, as highlighted in this study \cite{mordechay2014matrixRIP}.}
}

\Xpolish{Though some signal components must be removed when denoise the Poisson noise, it is possible to selectively keep significant signal components for downstream tasks such as correlation analysis and classification. This kind of coding strategies are called selective sensing (SS) in this paper. When the signal is extremely sparse, SS can have a significant performance gain on the downstream tasks.}
{In this project, we use the popular single pixel camera design to analyze and design effective coding models under Poisson noise. Similar to the conclusion of Cossairt et al., Harwid et. al., and Swift et. al., and Willett et. al. we find that general prior free  coding provides no benefit over a trivial raster scanning approach using a diagonal matrix $M$ \YLnote{\cite{cossairt2012does, harwit1979hadamard, swift1976hadamard, willet2009CSPoisson, scotte2022photon_noise, wuttig2005optimal, schumann2002SNR_poisson, larson1974hadamard_poisson, streeter2009optical_poisson}}.
We find, however, that in applications like compressed sensing and pattern recognition, where the collected data is compressible, similar benefits to those seen in compressed sensing and computational imaging can be seen if appropriate adjustments to the measurement matrices are made. We propose a coding methodology called \textbf{Selective Sensing} (SS) that relies on finding codes in basis where the signal is sparse and compressible to be used at capture time. This approach proves particularly effective for extremely sparse and compressible signals such as character recognition, as it enables the retention of key information while reducing the impact of noise on downstream analyses.}



Our contributions are as listed.
\begin{itemize} 
\item We analyze the performance of coding techniques using toy applications in single-pixel-imaging, compare the behavior of popular approaches for both additive Gaussian and Poisson noise, and develop coding strategies that work under Poisson noise. 
\item We find\Xhide{, however} that coding can provide significant performance gains \textit{only} when codes used in hardware capture are optimized specifically for downstream image reconstruction or vision tasks, such as classification. 
\item We propose the concept of selective sensing (SS) which includes coding methods selectively extract the features directly for downstream tasks.
\item We provide a method to create masks optimized for Poisson noise using a neural network. \YLnote{We find optimizing measurements significantly enhances single-pixel vision performance, particularly in Poisson noise-dominated signals like visible light, approaching the efficacy of ideal multipixel cameras.}
\end{itemize}

\Xpolish{While our work is related to compressed sensing and can be applied to regularized image reconstruction where signals are somewhat compressible, we will focus our treatment on two more extreme cases. We will look at cases where data is not compressible and full rank measurements are taken and reconstructed without regularization. On the other extreme we will look at highly compressible data in the problem of image classification where images are projected into a very small feature space. In this highly compressible case, the implications of Poisson noise are the most obvious.}
{
Our work, although rooted in compressed sensing principles applicable to regularized image reconstruction, specifically addresses two extreme scenarios. The first involves non-compressible data with full-rank measurements, reconstructed without regularization. Conversely, we examine highly compressible data in image classification, projecting images into a minimal feature space where the impact of Poisson noise becomes particularly evident.}
\AVnote{\checkednote{Add a figure showing different vision tasks with different compressibilities}}



