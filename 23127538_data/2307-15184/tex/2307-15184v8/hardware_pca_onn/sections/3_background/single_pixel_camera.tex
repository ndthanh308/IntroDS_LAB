

The {single-pixel camera} \Xpolish{demonstrated}{shown} in Fig. \ref{fig:SinglePixelImaging} is a \Xpolish{typical}{popular} example of \Xpolish{this model}{coding}, and serves as the primary example in this project. \YLnote{It employs a rapid single-pixel detector in conjunction with a Digital Micromirror Device (DMD) to sequentially multiplex a sensing matrix by modulating various patterns on the DMD \cite{mitra2014can}.} \Xpolish{Coding with a single-pixel-camera mathematically follows the Eq. \ref{eqn:NoiselessMeasurement} while the variables have more concrete meanings as $\B{x} \in \IR^{N \times 1}$ is the image representation of the field of view (FOV) consisting of $N \in \IZ^+$ pixels and is measured by $m \in \IZ^+$ \Xpolish{projections}{measurements, whose photon counts are denoted as $\B{y} \in \IR^{m \times 1}$}. $\B{M} \in \IR^{m \times N}$ is a set of sensing masks linearly projecting the \Xpolish{FOV}{$\B{x}$} onto the sensor pixel\Xhide{, and $\B{y} \in \IR^{m \times 1}$ are the corresponding measured {flux} levels or photon counts }\cite{willet2009CSPoisson}.}{
Its measurement process mathematically follows the Eq. \ref{eqn:NoiselessMeasurement}. Here, $\B{x} \in \IR^{N \times 1}$ is the image representation of the field of view (FOV), which consists of $N$ pixels, and is measured by linear projections or masks, $\B{M} \in \IR^{m \times N}$ to attain corresponding {flux} levels or photon counts, $\B{y} \in \IR^{m \times 1}$ 
 \cite{willet2009CSPoisson}. 
}
% Supposing the image representation of the field of view (FOV) $\B{x} \in \IR^{N \times 1}$ consists of $N \in \IZ^+$ pixels and is measured by $m \in \IZ^+$ \Xpolish{projections}{measurements, whose photon counts are denoted as $\B{y} \in \IR^{m \times 1}$}, 
%   the single-pixel-imaging process, if ignoring noise, can be expressed as the following equation 
%  \begin{equation}
%     \label{eqn:NoiselessMeasurement}
%     \begin{aligned}
%         \B{y} &=  \B{M x} ,
%     \end{aligned}
% \end{equation}
% where \Xhide{$\B{x} \in \IR^{N \times 1}$ is the image representation of the field of view, }$\B{M} \in \IR^{m \times N}$ is a set of sensing masks linearly projecting the \Xpolish{FOV}{$\B{x}$} onto the sensor pixel\Xhide{, and $\B{y} \in \IR^{m \times 1}$ are the corresponding measured {flux} levels or photon counts }\cite{willet2009CSPoisson}. 
Physically, $\B{M}$ can be implemented on the DMD by directing or blocking different parts of the incoming light from $\B{x}$ \cite{raskar2009computational} and averaging them on sensors that digitize the detected flux levels or photon counts $\B{y}$. If the sensing matrix $\B{M}$ is full-rank, \Xpolish{this model accurately characterizes conventional single-pixel imaging scenarios}{the \Xpolish{FOV}{$\B{x}$} can be reconstructed by $\B{M}^{-1}\B{y}$}. 
However, even when $m < N$, \Xpolish{the model remains effective through the integration of regularization techniques, specifically }{we can still recover the \Xpolish{FOV}{$\B{x}$} via} compressed sensing. \YLnote{While Hadamard matrices are considered effective for $\B{M}$, their suitability diminishes in the presence of data-dependent noise \cite{mitra2014can, harwit1979hadamard}.} In this work, we will study the performance of this camera for different choices of $\B{M}$ under different noise models. 
\Xhide{While a compressed sensing system that reconstructs an image fits this paradigm, we will focus on highly compressible problems such as character recognition. In these problems the differences between the common linear Gaussian noise model of the camera and the real Poisson noise model are most apparent. \AVnote{I don't know if this is still needed. We do a good job explaining the goals in the intro Apr 10, 2024 12:03 PM}}

% Figure environment removed