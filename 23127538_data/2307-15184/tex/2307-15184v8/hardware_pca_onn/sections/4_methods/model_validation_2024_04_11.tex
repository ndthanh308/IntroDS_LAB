\subsection{Model Validation}

% In this section, we start with a theoretical investigation on the reconstruction performances of null-prior strategies. Then the reconstruction and classification performances of all strategies and fairly compared by simulations and experiments. 

\Xhide{
\Xpolish{To validate the ONN model is correct, we begin with a theoretical derivation of the null-prior reconstruction. Afterwards, we test our ONN model by reconstructing random signals under two noise models and see what the optimized masks converge to at last.}
{
\Xpolish{To affirm the correctness of the ONN model, we initiate the validation process with a theoretical derivation of the null-prior reconstruction. Subsequently, we conduct empirical testing of the ONN model by reconstructing random signals under two distinct noise models. This experimental approach allows us to observe the convergence of optimized masks, providing empirical evidence for the validity and efficacy of the ONN model.}{To validate the proposed ONN model, we apply it to a signal reconstruction task with a \YLnote{\Xpolish{mathematically provable foundation}{mathematical proof}}. In the subsequent section, we undertake a theoretical derivation of error propagation resulting from both AGN and Poisson noise. \Xpolish{Notably, this section doesn't find the optimal masks $\B{M}$, but focuses on the comparison under Poisson noise between the identity matrix and the Hadamard matrix which has been proved to surpass the former under AGN.}{While optimal masks $\B{M}$ are not determined in this context, we concentrate on disproving the superiority which has been previously proven under AGN of the Hadamard matrix over the identity matrix under Poisson noise.}}
}
}%Hide
\YLnote{
\Xpolish{To validate the proposed ONN model, we apply it to a non-compressible signal reconstruction task. We focus on comparing Hadamard and Raster coding, and proving which is the better under different noise conditions. In the subsequent sections, we undertake a theoretical derivation of error propagation resulting from both AGN and Poisson noise, and test if our ONN model can justify the conclusion.
}{
To validate the proposed ONN model, we apply it to non-compressible signal reconstruction tasks where the correct solution is known. We compare Hadamard and Raster coding under both AGN and Poisson noise conditions. In subsequent sections, we derive the theoretical error propagation caused by both AGN and Poisson noise, assessing the ONN model's ability to substantiate our findings.
}
}
\AVnote{\checkednote{This section still doesn't clearly state what we do and why. Cand te just say we train masks to reconstruct non -compressible signals? Jan 18, 2024 10:58 AM}}
\AVnote{\checkednote{Need to be more specific what we show. I think we select two patterns, raster and hadamart, and prove which is better for non-compressible data. Then we see if the ONN finds similar masks. Jan 18, 2024 11:08 AM}}

\subsubsection{Theoretical Treatment for Null-Prior Reconstruction }

% \textcolor{blue}{This section could be taken out.}
\YLnote{In our study, the FOV comprises albedo and illumination. To streamline the discussion and formulas and avoid unnecessary complexity, we did not previously mention illumination. The illumination level for each pixel in a measurement, denoted as $\lambda$, influences noise magnitude. We reformulate the model as $\lambda \B{y} = \lambda \B{Mx}$, where $\B{x} \in [0,1]^{N \times 1}$ now represents the albedo which is our objective for reconstruction.}
Define $\B{I}$ as the identity matrix and $\totphoton = \rho \tau$ as the total number of photons from the source. Given the noisy photon counts $\tilde{\B{y}}$ and the full-rank mask basis $\B{M}$, we can reconstruct the field of view $\tilde{\B{x}} = \B{M}^{-1} \tilde{\B{y}}$.
Based on Parseval's identity, the covariance matrix of a vector $\B{b}$ is $\B{\Sigma}_{\B{b}\B{b}} = c^2 \sigma^2 \B{I}$ if $\B{b} = \B{W a}$ where $\B{\Sigma}_{\B{a}\B{a}} = \sigma^2 \B{I}$ and 
% $\B{W}$ is $c$ times an orthonormal matrix
$\B{W} \B{W}^\top = c^2 \B{I}$. 
For RS, we have $\lambda = \frac{\totphoton}{N^2}$ and $\lambda \tilde{\B{y}} \sim \mathcal{N}(\lambda \B{I}\B{x}, \sigma^2 \B{I})$. Thus, the reconstructed \Xpolish{field of view}{$\B{x}$} is 
\begin{equation}
    \label{eqn:RS_G_reconstruction}
    \begin{aligned}
        \tilde{\B{x}} &\sim \mathcal{N}\left(\B{x}, \frac{\sigma^2 N^4}{{\totphoton}^2} \B{I}\right)
    \end{aligned}.
\end{equation}
For HB, we have $\lambda = \frac{\totphoton}{2N^2}$ and $\lambda \tilde{\B{y}} \sim \mathcal{N}(\lambda \B{H}\B{x}, 2\sigma^2 \B{I})$ where the factor of $2$ arises from the dual rail trick mentioned in section \Xpolish{\ref{sssection:DualBranch}}{\ref{ssection:constraints}}. For $\B{H}^{-1}$, $c = \sqrt{\frac{1}{N}}$. The reconstructed field of view is 
\begin{equation}
    \label{eqn:HB_G_reconstruction}
    \begin{aligned}
        \tilde{\B{x}} &\sim \mathcal{N}\left(\B{x}, \frac{8 \sigma^2 N^3}{{\totphoton}^2} \B{I}\right)
    \end{aligned}.
\end{equation}
% Therefore, when considering the AWGN model, using the Hadamard matrix can improve the SNR of the reconstructed field of view when $N$ is large.
Therefore, using the Hadamard matrix in the AWGN model can improve the signal-to-noise ratio (SNR) of the reconstructed field of view when the number of elements, $N$, is large. 

When the noise is Poisson distributed, the covariance matrix of the noisy photon counts depends on the choice of $\B{M}$. Suppose $\sigma_j$ is the standard deviation of $\lambda \tilde{y}_j$, the $j_\text{th}$ measured noisy photon counts. For the RS, we have $\sigma_j^2 = \lambda x_j$ and $\lambda = \frac{\totphoton}{N^2}$. The covariance matrix of the reconstructed field of view is thus 
\begin{equation}
    \label{eqn:RS_P_reconstruction}
    \begin{aligned}
        \B{\Sigma}_{\tilde{\B{x}} \tilde{\B{x}}} &= \frac{N^2}{\totphoton}\diag\{x_1, x_2, \cdots, x_N\}
    \end{aligned}.
\end{equation}
% For HB, we have $\lambda = \frac{\totphoton}{2N^2}$ and $\sigma_j^2 = \lambda \sum_{k=1}^N |H_{jk}| x_k$ by the Skellam Distribution in section \ref{sssection:DualBranch}. Since Hadamard matrices only includes $\pm 1$ entries, we further have $\sigma_j^2 = \lambda \sum_{k=1}^N x_k$ and the covariance matrix  

In the case of the HB, we can express the rate parameter $\lambda$ as $\lambda = \frac{\totphoton}{2N^2}$, as demonstrated in section \ref{ssection:constraints} using the Skellam distribution. Additionally, we can express the variance of each element in the sum as $\sigma_j^2 = \lambda \sum_{k=1}^N |H_{jk}| x_k$. As Hadamard matrices only contain entries of $\pm 1$, this reduces to $\sigma_j^2 = \lambda \sum_{k=1}^N x_k$. Using this information, we can construct the covariance matrix
\begin{equation}
    \label{eqn:HB_P_reconstruction}
    \begin{aligned}
        \B{\Sigma}_{\tilde{\B{x}} \tilde{\B{x}}} &= \frac{2N \sum_{k=1}^N x_k}{\totphoton}  \B{I}
    \end{aligned}.
\end{equation}
% Therefore, the mean squared error (MSE) of HB is 2 times that of RS under Poisson noise. This factor of 2 arises from the dual branch trick. In other words, HB can never exceed RS in reconstruction error even when measuring with 2 PMTs simultaneously.
The results of our analysis reveal that the mean squared error (MSE) of the HB method is twice that of the RS method when the noise is Poisson distributed. \Xpolish{This difference is attributed to the dual branch trick utilized in the HB method. Despite the use of two PMTs in the HB method, it is unable to surpass the reconstruction error of the RS method. These findings demonstrate the limitations of the HB method in comparison to the RS method under Poisson noise conditions.}{\Xpolish{In other words, the}{The} HB outperforms the RS when the observed measurements $\B{y}$ are Gaussian distributed. This superiority doesn't hold under Poisson noise.} Given that many algorithms rely on AGN model, their conclusions may not hold if the optimal masks differ under Poisson noise. 

\Xhide{
% Figure environment removed
}





\Xhide{The first question to be answered is if the ONN can find the (approximately) optimal masks. To get the benchmark, we compared the reconstruction performance w.r.t the mean squared error between the raw and reconstructed images $\|\noisy{\B{x}} - \B{x}\|_2^2$ where $\noisy{\B{x}} = \B{M}^{-1} \noisy{\B{y}}$. Fig. \ref{fig:simulated_reconstruction} shows that Hadamard Basis is less preferred under Poisson noise but more optimal under the AGN compared with the Raster Basis.}

\Xhide{
\YLnote{\checkednote{This para needs polish}}
\Xpolish{We already saw the ONN had the best classification performance on the simulated data and its masks are optimal, it is still unclear if the ONN masks under the AGN and Poisson noise are similar. Since many algorithms are based on the AGN model, the conclusions drawn from them may be problematic if the optimal masks are different under the Poisson noise model. One simple approach is to let the ONN optimize the masks for a reconstruction task under different noise models. Therefore, we built a new ONN model which has $m = N$ masks. Its scanner took the raw images vectors $\B{x}$, and output $N$-element measured photon count vectors under some noise model, $\noisy{\B{y}}$. Its classifier is a single-layer network taking $N$-element vectors $\noisy{\B{y}}$ and outputting $N$-element vectors $\noisy{\B{x}}$. The objective is to minimize the MSE between the input images and the output vectors, or $\|\noisy{\B{x}} - \B{x}\|_2^2$. In noiseless cases, the classifier is equivalent to $\B{M}^{-1}$ if $\B{M}$ is the masks in the scanner.}
{ 
The primary question to address is whether the ONN has the ability to identify \Xpolish{noise specific optimized masks}{the derivation above}. We established a benchmark by comparing the reconstruction performance in terms of the MSE between the original and reconstructed images, denoted by $\|\noisy{\B{x}} - \B{x}\|_2^2$, where $\noisy{\B{x}} = \B{M}^{-1} \noisy{\B{y}}$. The reconstructed images were obtained using the Hadamard basis and Raster basis under Poisson noise and AGN models respectively. The outcomes, depicted in Fig. \ref{fig:simulated_reconstruction} where the x-axis is the log-scaled MSE of impulse imaging with different exposure times, indicate that the Hadamard basis is less effective in the presence of Poisson noise, while it is more effective under AGN model when compared to the Raster basis. Given that many algorithms rely on AGN model, their conclusions may not hold if the optimal masks differ under Poisson noise. \ynote{\checkednote{the following text does not belong in the results section}}\Xhide{ To address this, we propose a simple approach of optimizing the ONN masks for a reconstruction task under different noise models. To achieve this, we developed a new ONN model with $m = N$ masks. The scanner takes raw image vectors $\B{x}$ and outputs $N$-element measured photon count vectors under a chosen noise model, $\noisy{\B{y}}$. The classifier is a single-layer network that takes $\noisy{\B{y}}$ as input and outputs $\noisy{\B{x}}$, also an $N$-element vector. The objective is to minimize the MSE between the input images and the output vectors, $\|\noisy{\B{x}} - \B{x}\|_2^2$. In noiseless cases, the classifier is equivalent to $\B{M}^{-1}$, where $\B{M}$ is the masks used in the scanner.}
}
}

\subsubsection{ONN Non-compressible Signal Reconstruction}  
\TSnote{confusing}

\Xpolish{Before the ONN model is employed, the primary question to address is whether the ONN has the ability to identify \Xpolish{noise specific optimized masks}{the derivation above}. To \Xpolish{make this reconstruction task less specific and more general}{generate non-compressible data}, the input data vectors $\B{x}$ were reshaped from 8 by 8 random patterns. In different epochs of training, the $\B{x}$ was re-generated randomly. This simulation is conducted with a great noise level as the total number of photons is about $1 \times 10^3$. The masks $\B{M}$ were initialized with an $N \times N$ identical matrix and were optimized until this model reported constant losses.}
{Before the employment of the ONN model, the primary question to address is whether the ONN has the ability to identify \Xpolish{noise specific optimized masks}{the derivation above}. 
Given the universality of reconstruction algorithms, it is imperative that the input data vector $\B{x}$, \YLnote{the albedo in this study}, \Xpolish{exhibits non-compressibility}{is not compressible}.
\Xpolish{{To \Xpolish{make this reconstruction task less specific and more general}{generate non-compressible data}, we reshape the input data vectors $\B{x}$ from $10^5$ random 8 by 8 patterns, increasing their generality. W}{Therefore, w}e randomly sample \YLnote{\Xhide{10 times}}from the uniform distribution $U(0,1)$ to generate \Xhide{10 groups of }inputs \YLnote{$\B{x}$} and it is regenerated several times during the optimization, introducing \YLnote{\Xpolish{additional variability \AVnote{added to what?}}{extra randomization and less compressibility}}}{\YLnote{
Hence, we generate {$\B{x}$} by randomly sampling from the uniform distribution $U(0,1)$. Throughout the optimization process, these inputs are regenerated 10 times, thereby introducing additional randomization and reducing compressibility}}. The simulations are conducted \Xhide{under \YLnote{\Xpolish{significant noise}{a low-light condition}}, }with a total of $1 \times 10^2$ photons. We initialize the masks $\B{M}$ with an $N \times N$ identity matrix and a $\{0,1\}$ Hadamard matrix respectively, and optimize them until the model reports constant losses.}

\Xpolish{The first 6 masks optimized by the ONN are shown in figure \ref{fig:recon_masks}. From it, we can see that the ONN model has very different behaviors under the AGN and the Poisson noise. For the AGN, it tended to open more pixels to increase the light throughput, while it adhered to the RS mode for the Poisson noise. The figure \ref{fig:masks_value_dist} gives a more thorough visualization of the optimized masks by showing their entries' distributions. The x-axis is the values in the masks and the y-axis is the total number of entries in a certain range. This result is consistent with the classification results in the last section, where the RS is mediocre under the AGN but much better under the Poisson noise.}
{Fig. \ref{fig:recon_masks} displays the first 6 optimized masks \YLnote{from both initial matrices} generated by the ONN model \YLnote{\Xpolish{. A notable observation is that the model exhibits distinct behavior patterns under the AGN and Poisson noise}{ under both AGN and Poisson noise}}. Specifically, it tends to open more pixels to enhance light throughput under AGN, but adheres to the RS mode under the Poisson noise. Fig. \ref{fig:masks_value_dist} provides a more detailed visualization of the optimized masks by presenting the distribution of their entries. The x-axis represents the values in the masks, while the y-axis shows the total number of entries within a specific range. This observation aligns with the reconstruction results\Xhide{classification results presented in the previous section}, where the RS performed modestly under AGN but considerably better under the Poisson noise. \Xpolish{The rationale behind this is that re-projection from a captured basis into a basis of sparsity does not yield the same recovery quality under Poisson noise that is provides for AGN. To obtain a performance benefit over the trivial point scanning method, or RS, it is essential that the data is sparse and is captured in a sparse basis. Since random patterns are not sparse, the best scanning strategy is the point scanning, which matches our results.}{}  Gradients incorporating these two noise models during the training process lead the mask optimization along very different directions. From this example we can see that it is not appropriate to design a coding system under AGN and then apply it to Poisson noise data.}

% Figure environment removed


\Xhide{
% Figure environment removed
}

\iffalse
% Figure environment removed
\fi

\Xhide{
% Figure environment removed
}





\Xhide{% Figure environment removed
}


\Xhide{\bnote{talk about onn first in the last section and then show the reconstruction reuslts before the classifiction}}

\Xhide{
\Xpolish{The different results of the optimal masks suggest the masks optimized under the AGN model may not have the same performance under the Poisson noise. If the measured data is Poisson distributed, then the methods proposed under the AGN assumption are problematic.}
{The results from optimizing the masks indicate that the optimal masks under the AGN model may not perform similarly under Poisson noise. Specifically, methods developed under the AGN assumption may not be effective when the measured data follows a Poisson distribution. \YLnote{For instance, coding optimization based on minimizing the mutual coherence in compressed sensing \cite{mordechay2014matrixRIP} may be defective.} The inherent differences in the underlying noise models of the two distributions can lead to suboptimal performance of AGN-optimized masks in Poisson noise scenarios. Therefore, it is crucial to consider Poisson noise when designing coding schemes and algorithms for imaging applications, especially when working with state-of-the-art sensors.}
}