\subsection{Hardware Experiments}

\Xpolish{Besides the simulations, an experiment is also conducted to enhance our conclusion. The DMD we use is the DLP 7000 purchased from Texas Instruments and the PMT is the PMA Series from PicoQuant. This experiment consisted of a hardware-end data capture and a software-end classifier training. \Xhide{The steps are introduced in the following sections.}}{
% test
To further support our conclusions, we conduct an experiment in addition to simulations. 
As shown in Fig. \ref{fig:hardware_setup}, the experiment utilizes a DMD (digital micromirror device), specifically the DLP 7000 model from Texas Instruments, and a PMT (photomultiplier tube) from PicoQuant, specifically the PMA Series. 
The experimental setup involves both hardware-end data acquisition and software-end classifier training.} 
Handwritten number images are displayed on a monitor, captured by this vision system, and subsequently identified according to the depicted numbers.

% Figure environment removed

% \subsubsection{Data preparation}

\Xpolish{Before data acquisition, we transformed and re-calibrated the MNIST images into what the PMT exactly "observed", and trained the classifier with this new data. This step is important if we don't use the hardware-end data for training.
}{
To ensure that the classifier is properly trained using the PMT data, we perform a transformation $g(\cdot)$ that incorporates \Xpolish{re-calibration}{illumination correction and calibration} of the MNIST images $\B{X}$ to match what the PMT would actually "observe", $\B{X}^g$, during data acquisition. 
Mathematically, this transformation can be described as $\B{X}^g = g(\B{X})$. 
This step aims at reducing the model inconsistency between optimizing the sensing matrices $\B{M}$ and classifiers with digital data on a computer and testing the models with the data acquired from the experiments. 
\Xpolish{This step is crucial when training the classifier without the use of hardware-end data. By implementing this transformation and re-calibration process, we were able to accurately simulate the imaging conditions that the PMT would encounter during actual data acquisition, allowing for more reliable and robust classification results.}{
\Xhide{We choose a subset $\B{X}_s$ from $\B{X}$ and estimated the $g(\cdot)$ between the it and its observed version $\B{X}^g_s$\Xhide{ to ensure that the digital data closely matched the sensor's observations}.}
Specifically, we perform a raster scan of a sample from  $\B{X}_s$, a random subset from $\B{X}$ , with each mask exposed for 1 second. 
The light intensity is adjusted to ensure that the brightest pixel generated approximately 1000 photon counts per second. 
The data $\B{X}_s^g$ captured during this experiment is then reshaped into a 32 by 32 image, as shown in Fig. \ref{fig:sensor_perception}, and $g(\cdot)$ is then \Xpolish{attained}{determined}. 
\Xpolish{After applying this transformation to all digital data \Xpolish{to attain}{to obtain} $\B{X}^g$, \Xpolish{we used it to train the software-end classifier through simulation. }{
we input it into models with all the coding schemes to evaluate their classification performances.}}{}}
{Applying the transformation to digital data yields $\B{X}^g$, which is then fed into models featuring various coding schemes for performance evaluation. }
}



\Xpolish{Finally, we uploaded the masks as the pattern sequences onto the DMD to acquire the data $\noisy{\B{y}}$. The testset consisted of ten images and each handwritten number appeared exactly once. The exposure time for each mask was 1 second. Since all photon records preserved the arrival time, we could change the noise level by choosing random intervals during the whole exposure time and counting the photons within it. }{
\Xpolish{After generating the mask pattern sequences, we upload them onto the DMD to acquire the data, denoted as $\noisy{\B{y}}$.}{
% text starts
Following the generation of mask pattern sequences, they are uploaded onto the DMD to capture data, represented as $\noisy{\B{y}}$.} 
Our test set consists of ten handwritten images, each of which \YLnote{\Xpolish{\AVnote{past tense}appeared}{appears}} exactly once during the experiment. 
To control the noise level in the data, we varied 
% the number of photons recorded within 
lengths of random intervals throughout the 1-second exposure time for each mask. For instance, considering only the photons detected in the first 0.5-second interval, we effectively double the noise level. By preserving the arrival times of all photons, we can systematically adjust the level of noise in the acquired data.
}

\Xhide{
% ignore
\Xpolish{First, we conducted a Raster scan on a sample from MNIST data and each mask in this scan was exposed for 1 second. The light level had been adjusted and the brightest pixel in this experiment generated about 1000 photon records per second. The captured data vector was then reshaped into a 32 by 32 image, which can be treated as a linearly transformed version of the raw image.}
{First, we perform a Raster scan of a sample from the MNIST dataset, with each mask exposed for 1 second. The light intensity was adjusted to ensure that the brightest pixel generated approximately 1000 photon counts per second. The data captured during this experiment was then reshaped into a 32 by 32 image, which can be regarded as a linearly transformed version of the original raw image.}
}

% Figure environment removed


\Xhide{\Xpolish{Then, we estimated the linear transformation between the digital data and exprimental data, and then transformed all digital data in the same way so that the new data are similar to the sensor's observation. This transformed data was then input into the code modules used for simulation to train the software-end classifier. For the selective sensing, the masks were also trained in this step.}
{Then, we estimated the linear transformation between the digital and experimental data to ensure that the digital data closely matched the sensor's observations. After applying this transformation to all digital data, we used it to train the software-end classifier through simulation. Additionally, in this step, the masks used for Selective Sensing were also trained.} \YLnote{The masks with decimals use the fraction of a super pixel \cite{spall22hybrid_training} The ONN training is called \textit{in silico} method (Wright et al) \cite{spall22hybrid_training, wright2021backprop}}}



