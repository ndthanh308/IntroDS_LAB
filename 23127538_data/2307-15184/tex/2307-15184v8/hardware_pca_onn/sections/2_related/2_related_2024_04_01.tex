


\textbf{Coding under \Xpolish{Poisson}{photon} noise}. In coded imaging, \Xhide{coding allows the capture of a two-dimensional image with a single-pixel sensor \cite{harwit1979hadamard}. }Hadamard matrices are considered the optimal coding scheme for multiplexing \cite{harwit1979hadamard, cossairt2012does, wuttig2005optimal, mitra2014can} in systems with only AGN, although this conclusion does not hold for photon noise \cite{mitra2014can}. 
\Xpolish{However, when Poisson noise is predominant, we should not use any coding \cite{harwit1979hadamard, cossairt2012does}. When the noise is Poisson distributed, coding with sparse priors such as compressed sensing is not recommended \cite{willet2009CSPoisson, willett2011poisson, vanden2019various}.}
{In many recent projects, optimization efforts focus on algorithmic enhancements for reconstruction, often maintaining the use of random coding strategies \cite{goyal2016performance, gibson2020single, liutkus2014imaging, candes2008introduction}\YLnote{\checkednote{need more here}}, though this type of matrices are not recommended under \Xpolish{Poisson}{photon} noise\cite{willet2009CSPoisson,  willett2011poisson, vanden2019various}.
% \Xhide{ While some approaches, such as Feature Specific Imaging (FSI), optimize sensing matrices based on learnable priors \cite{neifeld2003dual, neifeld2003FSI, neifeld2014optimizing}, these methods explicitly do not consider Poisson noise. Thus, the challenge of optimizing masks under Poisson noise persists \cite{neifeld2014optimizing}.}
\YLnote{Wuttig and Ratner, et al. \cite{wuttig2005optimal, ratner2007optimal} introduced \Xpolish{Poisson}{photon}-noise-aware optimization techniques for \Xpolish{multiplexing}{coding} matrices that outperform Hadamard in the presence of moderate signal-dependent noise. 
However, their analysis neglects the data priors, leading to suboptimal matrices for greater \Xpolish{Poisson}{photon} noise \cite{mitra2014can}.} Additionally, attempts at matrix optimization focusing on minimal mutual coherence \cite{mordechay2014matrixRIP} \Xpolish{lack a foundation in Poisson noise model}{do not adequately consider photon noise}, as highlighted in this study.}



% \textbf{Task Specific Imaging}


\textbf{Feature Specific Imaging}. Feature-specific imaging (FSI) is a type of imaging system \Xpolish{that directly measures linear features of the object irradiance distribution, instead of forming a conventional image and then extracting features from it}{where sensing matrix $\B{M}$ incorporates linear features of expected data} \cite{neifeld2003FSI, neifeld2003dual}. This approach can provide higher feature fidelity and lower detector count than conventional imaging, especially for applications that require relatively few features \cite{neifeld2003FSI, neifeld2003dual, neifeld2014optimizing}. This technique can be viewed as a variant of compressed sensing, in which the sensing matrix is determined based on prior information \cite{neifeld2014optimizing}. However, \Xpolish{its performance and implications under Poisson noise conditions remain relatively unexplored in the existing literature, warranting further discussion and investigation}{\YLnote{current state-of-the-art} FSI is explicitly designed for AGN rather than Poisson noise\cite{neifeld2014optimizing}}. \YLnote{FSI can be regarded as a technique that leverages data driven priors, and Mitra et al. have asserted that employing data driven priors can enhance image recovery under Poisson noise \cite{mitra2014can}. Therefore, in our work, we underscore the promising prospects of extending feature-specific concepts to a broad spectrum of vision tasks under Poisson noise.}


\textbf{End-to-end optimization}. This method \Xpolish{refers to training hardware and software networks for image processing pipelines}{jointly optimizes camera design and digital signal processing to achieve optimal overall performance} \cite{diamond2021dirty, zhang2021deep, jacome2023middle}. \YLnote{In many previous projects, this idea was usually implemented \Xpolish{without considering Poisson noise}{without considering Poisson noise in cost functions} \cite{hinojosa2021learning, dun2020learned, metzler2020deep, chang2019deep, onzon2021neural, spall22hybrid_training, jacome2023middle, gibson2020single} or without optimizing masks \Xpolish{under Poisson noise during training}{with gradient incorporating Poisson distribution} \cite{tseng2021differentiable, diamond2021dirty, rego2022deep, duarte2008CS, nature2022ONN, gibson2020single, xu2020compressed}. Rego et. al froze the sensing matrix as a pinhole setting without optimizing it \cite{rego2022deep}}.
Wang et al. \cite{nature2022ONN} successfully implemented a neural network model for handwritten number classification on an optical device with limited photon budget, demonstrating the potential for AI-assisted optimization of coding schemes\Xhide{ in CI}. 
\YLnote{However, Poisson noise was considered only in model testing where the most robust model was picked among a set of \Xpolish{hyper-parameter combinations}{different initialization seeds} \cite{nature2022ONN}. %supplementary note 13
Xu et al. \cite{xu2020compressed} examined the robustness of the proposed neural network model to Poisson noise; however, the training process does not explicitly incorporate the gradients affected by Poisson noise.}
As we see later, however, the correct noise model is essential to obtain an optimal or near-optimal optical design.
Our contribution in this area is developing a \Xpolish{noise-included}{noise-aware} training approach within a neural network model to find globally optimal masks under Poisson noise. 
\YLnote{\Xpolish{
% these part is rewritten to avoid explaining the details
Addressing the limitations identified by Mitra et al. \cite{mitra2014can}, this model presents the following advantages.
    \begin{itemize}
        \item The optimization of coding finds a globally optimal $\B{M}$ rather than its greedy approximation.
        \item Noise is incorporated during the training process to simulate real-world conditions instead of using a one-dimensional affine noise model.
        \item The training process is accelerated and computationally more efficient as the binary constraint is addressed even in real experiments. Additionally, the prior is learned from the entirety of the light fields and spectral data, rather than from patches.
        \item The contribution of a data-driven prior to performance enhancement is more accurately discerned using the classification rate as the metric.
    \end{itemize}
}
{
Although our approach also employs data-driven priors, which is similar to that of Mitra et al., our research extends beyond simple image reconstruction to address a wider spectrum of vision tasks and investigates task-specific optimization techniques on optical hardware.
% Though using data-driven priors as Mitra et.al doing, our research expands its  to encompass a broader range of vision tasks and explores optimization techniques specifically tailored for optical hardware instead of simple image reconstruction.
% Different Mitra's work which primarily uses data-driven priors for image reconstruction, our research expands its  to encompass a broader range of vision tasks and explores optimization techniques specifically tailored for optical hardware.
}
}