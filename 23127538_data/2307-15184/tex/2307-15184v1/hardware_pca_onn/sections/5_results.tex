
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mask optimization with ONN}

\Xhide{The first question to be answered is if the ONN can find the (approximately) optimal masks. To get the benchmark, we compared the reconstruction performance w.r.t the mean squared error between the raw and reconstructed images $\|\noisy{\B{x}} - \B{x}\|_2^2$ where $\noisy{\B{x}} = \B{M}^{-1} \noisy{\B{y}}$. Figure \ref{fig:simulated_reconstruction} shows that Hadamard Basis is less preferred under Poisson noise but more optimal under the AGN compared with the Raster Basis.}

\Xpolish{We already saw the ONN had the best classification performance on the simulated data and its masks are optimal, it is still unclear if the ONN masks under the AGN and Poisson noise are similar. Since many algorithms are based on the AGN model, the conclusions drawn from them may be problematic if the optimal masks are different under the Poisson noise model. One simple approach is to let the ONN optimize the masks for a reconstruction task under different noise models. Therefore, we built a new ONN model which has $m = N$ masks. Its scanner took the raw images vectors $\B{x}$, and output $N$-element measured photon count vectors under some noise model, $\noisy{\B{y}}$. Its classifier is a single-layer network taking $N$-element vectors $\noisy{\B{y}}$ and outputting $N$-element vectors $\noisy{\B{x}}$. The objective is to minimize the MSE between the input images and the output vectors, or $\|\noisy{\B{x}} - \B{x}\|_2^2$. In noiseless cases, the classifier is equivalent to $\B{M}^{-1}$ if $\B{M}$ is the masks in the scanner.}
{\Xhide{The ONN demonstrated superior classification performance on simulated data with optimal masks; however, it remains unclear whether these masks are optimal under different noise models, specifically AGN and Poisson noise.} 
The primary question to address is whether the ONN has the ability to identify noise specific optimized masks. We established a benchmark by comparing the reconstruction performance in terms of mean squared error (MSE) between the original and reconstructed images, denoted by $\|\noisy{\B{x}} - \B{x}\|_2^2$, where $\noisy{\B{x}} = \B{M}^{-1} \noisy{\B{y}}$. The reconstructed images were obtained using the Hadamard basis and Raster basis under Poisson noise and AGN models respectively. The outcomes, depicted in Figure \ref{fig:simulated_reconstruction} where the x-axis is the log-scaled MSE of impulse imaging with different exposure times, indicate that the Hadamard basis is less effective in the presence of Poisson noise, while it is more effective under the AGN model when compared to the Raster basis. Given that many algorithms rely on the AGN model, their conclusions may not hold if the optimal masks differ under Poisson noise. \ynote{\checkednote{the following text does not belong in the results section}}\Xhide{ To address this, we propose a simple approach of optimizing the ONN masks for a reconstruction task under different noise models. To achieve this, we developed a new ONN model with $m = N$ masks. The scanner takes raw image vectors $\B{x}$ and outputs $N$-element measured photon count vectors under a chosen noise model, $\noisy{\B{y}}$. The classifier is a single-layer network that takes $\noisy{\B{y}}$ as input and outputs $\noisy{\B{x}}$, also an $N$-element vector. The objective is to minimize the MSE between the input images and the output vectors, $\|\noisy{\B{x}} - \B{x}\|_2^2$. In noiseless cases, the classifier is equivalent to $\B{M}^{-1}$, where $\B{M}$ is the masks used in the scanner.}
}

% Figure environment removed

\Xpolish{To make this reconstruction task less specific and more general, the input data vectors $\B{x}$ were reshaped from 8 by 8 random patterns. In different epochs of training, the $\B{x}$ was re-generated randomly. This simulation is conducted with a great noise level as the total number of photons is about $1 \times 10^3$. The masks $\B{M}$ were initialized with an $N \times N$ identical matrix and were optimized until this model reported constant losses.}
{To make this reconstruction task less specific and more general, we reshaped the input data vectors $\B{x}$ from $10^5$ random 8 by 8 patterns, increasing their generality. We randomly re-generated $\B{x}$ in different training epochs, introducing additional variability. The simulations were conducted under significant noise, with a total of $1 \times 10^3$ photons. We initialized the masks $\B{M}$ with an $N \times N$ identical matrix and optimized them until the model reported constant losses.}

\Xpolish{The first 6 masks optimized by the ONN is shown in figure \ref{fig:recon_masks}. From it, we can see that the ONN model has very different behaviors under the AGN and the Poisson noise. For the AGN, it tended to open more pixels to increase the light throughput, while it adhered to the RS mode for the Poisson noise. The figure \ref{fig:masks_value_dist} gives a more thorough visualization of the optimized masks by showing their entries' distributions. The x-axis is the values in the masks and the y-axis is the total number of entries in a certain range. This result is consistent with the classification results in the last section, where the RS is mediocre under the AGN but much better under the Poisson noise.}
{Figure \ref{fig:recon_masks} displays the first 6 optimized masks generated by the ONN model. A notable observation is that the model exhibits distinct behavior patterns under the AGN and Poisson noise. Specifically, it tends to open more pixels to enhance light throughput under the AGN, but adheres to the RS mode under the Poisson noise. Figure \ref{fig:masks_value_dist} provides a more detailed visualization of the optimized masks by presenting the distribution of their entries. The x-axis represents the values in the masks, while the y-axis shows the total number of entries within a specific range. This observation aligns with the reconstruction results\Xhide{classification results presented in the previous section}, where the RS performed modestly under the AGN but considerably better under the Poisson noise. The rationale behind this is that re-projection from a captured basis into a basis of sparsity does not yield the same recovery quality under Poisson noise that is provides for AGN. To obtain a performance benefit over the trivial point scanning method, or RS, it is essential that the data is sparse and is captured in a sparse basis. Since random patterns are not sparse, the best scanning strategy is the point scanning, which matches our results.}

% Figure environment removed

% Figure environment removed

\Xhide{\bnote{talk about onn first in the last section and then show the reconstruction reuslts before the classifiction}}

\Xpolish{The different results of the optimal masks suggest the masks optimized under the AGN model may not have the same performance under the Poisson noise. If the measured data is Poisson distributed, then the methods proposed under the AGN assumption are problematic.}
{The results from optimizing the masks indicate that the optimal masks under the AGN model may not perform similarly under Poisson noise. Specifically, methods developed under the AGN assumption may not be effective when the measured data follows a Poisson distribution. The inherent differences in the underlying noise models of the two distributions can lead to suboptimal performance of AGN-optimized masks in Poisson noise scenarios. Therefore, it is crucial to consider Poisson noise when designing coding schemes and algorithms for imaging applications, especially when working with state-of-the-art sensors.}


\subsection{Classification Rates on Simulated Data}

\Xpolish{In simulations, both the AGN and Poisson noise models were tested with the model we proposed. The results were generated under different noise levels by changing the exposure time. In addition, all compressible strategies were tested while changing the total number of masks. We defined a metric called compression ratio which is the ratio of the number of masks over the number of pixels. For the RS and HB, this ratio is constrained to be $1.00$. And for the rest, all values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$ were evaluated. Different from other strategies whose masks were pre-defined, the initial masks for ONN can affect the performances when noise exists. In this project, we initialized its masks by the PCA components from the training data as it usually has the best performances.}
{We evaluated our proposed model through simulations that tested both AGN and Poisson noise models, using varying exposure times to generate results at different noise levels. We also tested all {compressible} strategies, varying the total number of masks, and defined a metric called compression ratio as the ratio of the number of masks to the number of pixels \cite{stojek2022define_compression_ratio}. For RS and HB, this ratio was constrained to be 1.00, while the rest were evaluated over values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$. Unlike pre-defined masks used by other strategies, the initial masks for ONN can affect performance in the presence of noise. We therefore initialized its masks with the PCA components from the training data, which typically yield better performance.}

\Xpolish{The figure \ref{fig:simulated_classification} shows the classification performances with different parameters. The x-axis is the log-scaled mean square error (MSE) of impulse imaging (II) for some exposure time. The measured impulse imaging data requires no reconstruction and can be directly used to compute the noise level via $\|\noisy{\B{y}}_{II} - \B{x}\|_2^2$. As the golden standard in this project, this MSE can work as a metric showing the noise level for both AGN and Poisson noise models. The y-axis is the classification rate on the validation set. The compression ratio can affect the classification performances, so in this figure, we tried all the values in $\mathcal{C}_R$ and picked the best one for TH, PCA and ONN.}
{Figure \ref{fig:simulated_classification} displays the classification performance of different parameters. The x-axis is the log-scaled mean square error (MSE) of impulse imaging (II) with varying exposure times. \Xhide{Since the measured impulse imaging data requires no reconstruction, the noise level can be directly computed by $\|\noisy{\B{y}}_\mathrm{II} - \B{x}\|_2^2$. }This MSE is the gold standard in this project and serves as a metric to measure the noise level for both AGN and Poisson noise models. The y-axis represents the validation set's classification rate. We explored all the values in $\mathcal{C}_R$ to determine the best compression ratio for TH, PCA, and ONN since compression ratio affects classification performance. The figure shows the best results among all compression ratios for each strategy.}

% Figure environment removed

\Xhide{\bnote{color compressible and non-compressible differently}}


\Xpolish{In this figure, we can see the II always has the best performance, which meets our expectation. When the noise is AGN, using any coding gives rise to a significant improvement compared with RS. For this classification task, using low-rank measurement (HB, PCA, ONN) can further improve this model's classification performances. Notably, the ONN has a performance close enough to the II with only 0.1\% number of photons.}
{The results presented in the figure demonstrate that II consistently achieves the highest performance, which is in line with our expectations. In the presence of AGN, all coding schemes exhibit significant improvements over RS and in many cases provide adequate performance. This is because under Gaussian noise, projected from a captured basis into a basis of sparsity where the classifier operates can be done without a significant noise penalty. Moreover, for the classification task at hand, low-rank measurement techniques such as HB, PCA, and ONN, can yield further improvements in classification performance. Notably, the ONN approach produces results that are nearly as good as the II approach, while using only 0.1\% of the photons.}

\Xpolish{However, when the measured data is Poisson distributed, HB is no better than RS any more, which agrees the conclusions of Harwit et al. \cite{harwit1979hadamard} that we should not adopt coding for Poisson noise. Though Hadamard coding is not promising, we can still have extra performance gain by using low-rank methods. Among all low-rank methods, the ONN is still the best, suggesting Selective Sensing is the most optimal method for both noise models.}
{However, when dealing with Poisson-distributed measured data, the effectiveness of Hadamard-based (HB) coding is no longer superior to that of RS. This aligns with the findings of Harwit et al. \cite{harwit1979hadamard}, which discourage the adoption of coding for Poisson noise. Despite this, there is still potential for performance improvement by utilizing low-rank methods such as TH, PCA and ONN. This is likely due to the fact that the images with analyze do in fact have sparsity in the Hadamard basis. Selective Sensing where capture patterns are optimized to capture sparsity directly like the ONN can retain their performance under poisson noise making them viable replacements for simple point scanners. This indicates that Selective Sensing is the most optimal approach for both noise models. }




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classification Performances on Experiment Data}

\Xpolish{In the experiments, we used a DMD and a PMT to measure 10 handwritten numbers from the MNIST dataset. The models were trained with $10^5$ photons, which is a greater noise level compared with the experimental environment. The collected data was in the form of a series of timestamps recording the arrival time of the photons. When collecting data, both RS and HB used 1024 masks. The TH and the HB shares the same measured data but the TH only uses the first 92 measured data. The PCA and ONN used 92 masks, which is the same as the TH. The physical measurements took 1 second per mask for all strategies. To create data of greater noise level from the raw data, we randomly picked intervals during the 1 second span, and counted the total numbers in it. Since the ONN and PCA only have 92 masks, the maximum exposure time was set as 92 seconds. In a fair comparison, the interval length of each strategy was cpmputed as $\frac{\tau}{m}$ where $\tau$ is the total exposure time we want to investigate and $m$ is number of masks for this strategy.}
{In our experiments, we utilized a DMD and a PMT to measure ten handwritten digits from the MNIST dataset. To train the models, we employed $10^5$ photons, which constituted a higher noise level in comparison to the experimental setup. The collected data took the form of a series of timestamps recording the photons' arrival time. During data collection, both RS and HB used 1024 masks, while the TH and HB employed the same measured data, but the TH used only the first 92 measurements. Similarly, PCA and ONN utilized 92 masks. Physical measurements took one second per mask for all strategies. To generate data with higher noise levels from the raw data, we randomly selected intervals within the 1-second span and counted the total number of photons within them. Since the ONN and PCA had only 92 masks, the maximum exposure time was set to 92 seconds. To ensure a fair comparison, we computed the interval length for each strategy as $\frac{\tau}{m}$, where $\tau$ represents the total exposure time under investigation, and $m$ denotes the number of masks used for each strategy.}

\Xhide{\bnote{consistent color on figures}}

% Figure environment removed

\Xhide{\bnote{change the x tick labels}}

\Xpolish{However, we still saw some unexpected phenomena in the figure. Firstly, the HB strategy was better than the RS when the exposure was short, which was not observed in the simulation. This phenomenon might arise from the dark photon in the PMT. The dark photon is a signal-independent noise which has about 40-80 counts per second and could usually be observed before the experiments started. When the exposure was short, this noise would be more significant and gave rise to a better performance of the HB. Secondly, the TH achieved better classification performances than the PCA when the exposure time is short. It was the consequence of using unneeded PCA masks. To verify, we fixed the toal number of photons at $10^5$, change the compression ratio, and made figure \ref{fig:classification_ratio} by simulation. This figure shows that the PCA method can be worse than the TH when it has more masks than needed. In other words, the PCA strategy requires an careful estimation of the noise level to avoid using extra masks. Notably, the ONN looks more stable when includes extra masks. That can be seen as another advantage of the Selective Sensing. After the models are trained, they may be applied in unknown noise levels. Different from the PCA strategy whose optimal number of masks is noise level sensitive, the ONN can have a better and robust performance even when the number of masks is not optimal.}
 {Figure \ref{fig:Exp_classification} displays the classification rates achieved on the experimental data. The x-axis shows the exposure time, and the y-axis represents the classification rates of the models. Although there may be discrepancies between software training and hardware data acquisition, the ONN models performed excellently. However, the figure reveals some unexpected phenomena. Firstly, the HB strategy outperformed the RS for short exposure times, which was not observed in the simulations. This phenomenon may have arisen due to the dark photon in the PMT, a signal-independent noise that has about 40-80 counts per second, and was more pronounced in short exposures. Secondly, the TH achieved better classification performances than the PCA when the exposure time was short. This result was due to the use of unneeded PCA masks. To verify, we conducted simulations and made figure \ref{fig:2d_classification_plots} by fixing the total number of photons at $10^5$ and varying the compression ratio under the Poisson noise. This figure showed that the PCA method could perform worse than the TH if extra masks were used. Hence, the PCA strategy requires careful estimation of the noise level to avoid using extra masks. Notably, the ONN appeared more stable when including extra masks, which is another advantage of the ONN. The ONN can perform robustly even with suboptimal numbers of masks, unlike the PCA strategy, which is noise-level sensitive. While it is possible to set the noise level during training, the effectiveness of the ONN can be evaluated for other levels of noise as well. This flexibility in application allows for broader use of the ONN beyond its specific training conditions, increasing its potential impact and utility in real-world scenarios.}




\Xhide{
% Figure environment removed
}


\Xhide{\YLnote{2D plot. \& Don't re-train the model. For training, choose a fixed noise (1e5) level, and for testing, use multiple noise levels}.}

\Xhide{
% Figure environment removed
}

% Figure environment removed

\Xhide{\YLnote{Show: fixed CR and change the noise level}}

\Xhide{\bnote{use $C_R$ on x axis}}

\Xhide{\YLnote{Add how to adjust the experimental data to be classified by simulated model}}



\input{\homedir/sections/5_results_hyperspectral}