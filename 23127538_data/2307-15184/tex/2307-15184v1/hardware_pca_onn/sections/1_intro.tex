% The very first letter of the paper is a 2 line initial drop letter
% followed by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

\iffalse
\IEEEPARstart{T}{his} demo file is intended to serve as a ``starter
file'' for ICCP 2020 submissions produced under
\LaTeX~\cite{kopka-latex} using IEEEtran.cls version 1.8b and later.
\fi

% Coding is a fundamental technique used in computational imaging (CI) for image quality improvement \cite{cossairt2012does}. On top of increasing the light throughput, coding reduces the dimensionality of a measurement space where the reconstruction accuracy is a usual metric for the CI's performance. For applications such as single pixel imaging, spectroscopy, structured illumination imaging, time of flight imaging, and polarization imaging, coding enables a low dimensional sensor to sample in a \textbf{complete} measurement space.
% %an $n$-dimension measurement space.
% Due to its range of applications, coding schemes have been investigated thoroughly. Most implementations, however, are using very low noise scenarios or additive Gaussian noise models. The rationale is that additive Gaussian noise is a good model for the readout noise introduced by the imperfect measurement of cameras and sensors. This AGN is easy to model analyticlly and computationally since it is a signal independent linear additive noise. As optical imaging technologies improve, readout noise is decreasing and Poisson noise to to the quantized nature of light is dominating measured imaging data. While readout noise is a technical problem introduced by an imperfect measurement, quantization noise is a fundamental physical property of light. In other words, since light is actually composed of photons that hit the sensor at discrete times, the light flux property we are trying to measure and compute on exists only as an ensemble average over a Poisson distribution and is not in that sense a "real" quantity. In state of the art and future sensors measuring visible light, it is therefore important to consider measurement and processing techniques under Poisson noise. It has been shown in multiple foundational publications, that coding behaves fundamentally different under Poisson noise than it does under the AGN. This problem becomes particularly pronounced in emerging single-photon sensors that only suffer from Poisson noise. Therefore, the previous conclusion would imply that existing techniques of coding/computational imaging are not applicable  single-photon or "few-photon" sensors (i.e. sensors where the readout noise is on the order of just a few photons, such as most state for the are sCMOS and machine vision cameras). 

% In this paper we analyze the performance of coding techniques using simple toy applications, compare the behavior of popular approaches for AGN and Poisson noise and develop coding strategies that work with Poisson noise. Similar to \cite{cossairt2012does} we find that coding has negligible performance gains when the task is \textit{image reconstruction}. However, when performance gain is measured for downstream tasks, coding with codes that are adapted to the downstream tasks can provide non-trivial performance gains and in some cases recover the performance of an optimal measurement performed with a high dimensional sensor.

% Coding is a widely-used technique in computational imaging (CI) that aims to improve image quality and reduce the dimensionality of the measurement space \cite{cossairt2012does}. It has been shown to be effective in a variety of applications, including single pixel imaging, spectroscopy, structured illumination imaging, time of flight imaging, and polarization imaging. These techniques rely on coding to allow low-dimensional sensors to sample a complete measurement space. While coding schemes have been widely studied, most research has focused on low noise scenarios or additive Gaussian noise models. This is due to the fact that additive Gaussian noise, which is introduced by imperfections in cameras and sensors, is easy to model both analytically and computationally as it is a signal-independent linear noise.

\IEEEPARstart{A}{}n imaging device performs a projection from a high-dimensional scene space onto a lower-dimensional reconstruction space. The need for the projection stems partially from a need to reduce and interpret the data, either as a human-interpretable image or as some form of pattern yielding actionable information about the scene. In addition, especially when imaging with visible light, a projection reduces the information to an amount that can be digitized by a camera sensor and processed. Camera sensors are two-dimensional and capture the absolute value squared of the light wave averaged over pixels in space, time, wavelength, and polarization. The projection onto a sensor prior to digitization is thus a fundamental and essential component of any imaging and vision device for physical and computational reasons. One quite general way to model this projection process is through what is commonly referred to as coding or multiplexing. 

\Xhide{\bnote{insert an eqn about the symbols mentioned below}}

Mathematically, coding, it can be described as a linear operator, $\B{M}$ linking a vectorized incoming light field $\B{x}$ to a vector of light measurements $\B{y}$. \YLnote{The \textbf{single-pixel-imaging} is considered as a typical example.} Supposing the image of the field of view consists of $N \in \IZ^+$ pixels and is measured by $m \in \IZ^+$ projections, 
  the single-pixel-sensing process, if ignoring noise, can be expressed as the following equation 
 \begin{equation}
    \label{eqn:NoiselessMeasurement}
    \begin{aligned}
        \B{y} &=  \B{M x}
    \end{aligned}
\end{equation}
, where $\B{x} \in \IR^{N \times 1}$ is the image representation of the field of view, $\B{M} \in \IR^{m \times N}$ is a set of sensing masks\Xhide{or in other words, weighing design (WD) \cite{harwit1979hadamard} \bnote{not sure if language from 1979 is useful. I have not heard of weighing design},} linearly projecting the field of view onto the sensor pixels, and $\B{y} \in \IR^{m \times 1}$ are the corresponding measured \YLnote{flux} levels or photon counts \cite{willet2009CSPoisson}. Physically, $\B{M}$ can be implemented by directing or blocking different parts of the incoming light with masks \cite{raskar2009computational} and averaging them on sensors that digitize the detected flux levels or photon counts.


A linear operator with a mask can model most optics, including a lens that forms an image, color filters that provide color resolution, and camera pixels that average incoming light over an exposure time. The digitized vector then is processed computationally to extract the desired information about the scene. For a full rank measurement $\B{M}$, a linear operation $\B{M}^{-1}$ can in principle allow reconstruction of the entire incoming measurement. In the simplest case, where the desired information is directly digitized, $\B{M}$ is a diagonal matrix. However far more elaborate capture and post-processing are being employed and are the basis of diverse fields such as structured illumination imaging, computational imaging (CI) \cite{cossairt2012does}\Xhide{\bnote{Define coding here?}} and compressed sensing. The primary benefits of complex codes are the improved signal to noise ratio do to the fact that the corresponding masks transmit more light, as well as the possibility of using fewer masks and thereby reducing the overall complexity of the measurement.

%\rnote{Coding is accomplished by blocking photons over time or space, and more details about the scene can be preserved consequently \cite{raskar2009computational}}. In addition to increasing light throughput, coding can reduce the dimensionality of the measurement space, which is a common metric for the performance of a CI method. Coding allows low-dimensional sensors to sample a complete measurement space in applications such as single pixel imaging, spectroscopy, structured illumination imaging, time of flight imaging, and polarization imaging.

% \bnote{This paragraph reads choppily. Many of the sentences could be blended together/ reorganized to be smoother. Potentially combine this with the following paragraph.} While coding schemes have been extensively researched, the mathematical foundation is based on low noise scenarios or Additive Gaussian noise (AGN) models. This is because the AGN is a linear noise model that allows for rigorous mathematical treatment. It is a good model for the readout and background noise introduced by imperfect measurements in noisy cameras and sensors, and is easy to analyze and compute analytically as it is signal-independent and linearly additive.

Coding schemes have been extensively studied, but usually based on low noise scenarios or Additive Gaussian noise (AGN) models. AGN is a linear noise model that allows for rigorous mathematical treatment. It is a good model for the readout and background noise introduced by imperfect measurement hardware of past cameras and sensors. However, with the advancement of optical imaging and single photon sensitive sensor technologies, readout noise is decreasing, and Poisson noise is becoming  dominant in measured imaging data\Xhide{ \cite{harwit1979hadamard}}. While the readout noise level of consumer cameras is approaching single electron levels, many state-of-the-art and emerging sensors technologies, such as Single-photon Avalanche Diode (SPAD), Quanta Image Sensors (QiS), and qCMOS cameras, directly measure quantized photon counts and as a result only experience Poisson noise \cite{foord1969PMT, prescott1966PMT, lombard1961PMT}. 

Poisson noise is a fundamental physical property of light and arises from the discrete nature of light measurements. It is impossible to spread out a photon measurement over all the open pixels in a mask as the linear model introduced in Equation~\ref{eqn:NoiselessMeasurement} assumes. The measurements of $\B{y}$ that equation calls for are therefore impossible. Unfortunately, this has the consequence that the coding and thereby compressed sensing approaches designed to be effective under AGN or noiseless conditions are not effective under Poisson noise and their use is discouraged in the literature \cite{harwit1979hadamard, swift1976hadamard, willet2009CSPoisson}.

%Previous research has shown that coding behaves differently under Poisson noise compared to AGN \cite{duarte2008CS, harwit1979hadamard, neifeld2003FSI}. Existing coding and computational imaging techniques may not be applicable to these sensors, which makes developing new coding techniques a crucial task. 

\Xpolish{Though some signal components must be removed when denoise the Poisson noise, it is possible to selectively keep significant signal components for downstream tasks such as correlation analysis and classification. This kind of coding strategies are called selective sensing (SS) in this paper. When the signal is extremely sparse, SS can have a significant performance gain on the downstream tasks.}
{In this project, we use the popular a single pixel camera design to analyze and design effecive coding models under Poisson noise. Similar to the conclusion of Cossairt et al., Harwid et. al., and Swift et. al., and Willett et. al. we find that general prior free  coding provides no benefit over a trivial raster scanning approach using a diagonal matrix $M$ \YLnote{\cite{cossairt2012does, harwit1979hadamard, swift1976hadamard, willet2009CSPoisson, scotte2022photon_noise, wuttig2005optimal, schumann2002SNR_poisson, larson1974hadamard_poisson, streeter2009optical_poisson}}.
We find, however, that in applications like compressed sensing and pattern recognition, where the collected data is compressible, similar benefits to those seen in compressed sensing and computational imaging can be seen if appropriate adjustments to the measurement matrices are made. We propose a coding methodology called \textbf{Selective Sensing} (SS) that relies on finding codes in basis where the signal is sparse and compressible to be used at capture time. 
%This is opposed to compressive sensing strategies, where data is projected into a sparse basis after capture. SS coding strategies can provide a significant improvement on downstream tasks such as correlation analysis and classification in the presence of Poisson noise.
This approach proves particularly effective for extremely sparse and compressible signals such as character recognition, as it enables the retention of key information while reducing the impact of noise on downstream analyses.}

% However, as optical imaging technologies improve, readout noise is decreasing and Poisson noise, due to the quantized nature of light, is becoming more dominant in measured imaging data \bnote{Mention the sensors that make this capable here? By combining with the previous paragraph it could also be made more clear the Poisson noise breaks the underlying assumptions of coding derivations. Mention that the signal-dependent property of Poisson noise is a key factor in why these proofs break down.} \rnote{For instance, Single-photon Avalanche Diode (SPAD) and Photon Multiplier Tube (PMT) are two typical sensors}. Poisson noise is a fundamental physical property of light and arises from the discrete nature of light. An optical signal is composed of discrete photons that can not be arbitrarily divided across codes. Therefore, in state-of-the-art and future sensors measuring visible light, it is important to consider measurement and processing techniques under Poisson noise.

% Previous research has shown that coding behaves substantially differently under Poisson noise compared to the AGN \cite{duarte2008CS}, which is particularly significant in emerging single-photon sensors that only experience Poisson noise. \bnote{Talk more about why Poisson noise is hard to code here.} \rnote{Coding is challenging in this case as it is impossible to remove the Poisson noise without eliminating some of the signal \cite{harwit1979hadamard}}. This means that existing coding and computational imaging techniques may not be applicable to single-photon or "few-photon" sensitive sensors (such as most state-of-the-art CMOS and machine vision cameras) where readout noise is on the order of just a few photons \cite{harwit1979hadamard}.

Our contributions are as listed.
\begin{itemize} 
\item We analyze the performance of coding techniques using toy applications in single-pixel-imaging, compare the behavior of popular approaches for both additive Gaussian and Poisson noise, and develop coding strategies that work under Poisson noise. 
\item We find\Xhide{, however} that coding can provide significant performance gains \textit{only} when codes used in hardware capture are optimized specifically for downstream image reconstruction or vision tasks, such as classification. 
\item We propose the concept of selective sensing (SS) which includes coding methods selectively extract the features directly for downstream tasks.
\item We provide a method to create masks optimized for Poisson noise using a neural network.
\end{itemize}

% \bnote{Should we add the example 4-pixel problem and a teaser figure here?}\ynote{I think that makes most sense in the context of compressed sensing. We could add it to the discussion or leave it for the talk.}

\iffalse
\textbf{New paper story:}
\begin{enumerate}
    \item Coding is one of the fundamental techniques used in computational imaging (CI) for image quality improvement \cite{cossairt2012does}. On top of increasing the light throughput, coding reduces the dimensionality of a measurement space where the reconstruction accuracy is a usual metric for the CI's performance.\bnote{Insert definition of computational imaging, probably similar to the one of \cite{cossairt2012does}}.
    \item 
    Coding is important in any application where an n dimensional measurement space is sampled with a sensor or dimensionality $<$ n. It is relevant in single pixel imaging, spectroscopy, structured illumination imaging, time of flight imaging, polarization imaging, compultational imaging, and compressed sensing.
    \item Due to its range of applications coding schemes have been explored thoroughly. Most implementations, however, are using very low noise scenarios or additive Gaussian noise models. The rationale is that additive Gaussian noise is a good model for the readout noise introduced by the imperfect measurement of cameras and sensors. This AGN is easy to model analyticlly and computationally since it is a signal independent linear additive noise. 
    \item As optical imaging technologies improve, readout noise is decreasing and Poisson noise to to the quantized nature of light is dominating measured imaging data. While readout noise is a technical problem introduced by an imperfect measurement, quantization noise is a fundamental physical property of light. In other words, since light is actually composed of photons that hit the sensor at discrete times, the light flux property we are trying to measure and compute on exists only as an ensemble average over a Poisson distribution and is not in that sense a "real" quantity. \item In state of the art and future sensors measuring visible light, it is therefore important to consider measurement and processing techniques under Poisson noise.
    \item It has been shown in multiple foundational publications, that coding behaves fundamentally different under Poisson noise than it does under AGN.
    % \item For example, recent work explored the regimes where coding/computational imaging can lead to improved performance \cite{cossairt2012does}. The conclusion of their analysis was that coding/computational imaging can improve performance in scenarios where the dominant noise source is due to Gaussian noise often associated to read-out noise. However, when the dominant noise source is Poisson noise, due to the random arrival of photons, the performance gains are negligible. In other words: In a Poisson noise limited measurement, the best "code" is the trivial "pinhole" code, where each sample is scanned on it's own. 
    % \item Beccas paper.
    \item This problem becomes particularly pronounced in emerging single-photon sensors that only suffer from Poisson noise. Therefore, the previous conclusion would imply that existing techniques of coding/computational imaging are not applicable  single-photon or "few-photon" sensors (i.e. sensors where the readout noise is on the order of just a few photons, such as most state for the are sCMOS and machine vision cameras). 
    \item In this paper we analyze the performance of coding techniques using simple toy applications, compare the behavior of popular approaches for AGN and Poisson noise and develop coding strategies that work with Poisson noise. 
    \item Similar to \cite{cossairt2012does} we find that coding has negligible performance gains when the task is \textit{image reconstruction}. However, when performance gain is measured for downstream tasks, coding with codes that are adapted to the downstream tasks can provide non-trivial performance gains and in some cases recover the performance of an optimal measurement performed with a high dimensional sensor.
\end{enumerate}
\fi

\iffalse
\subsection{Outline (for planning only)}
Definition of coding, sensor dimensionality, measurement dimensionality

definition of signal reconstruction, imaging, and pattern recognition

\bnote{Single-pixel imaging.} 

\bnote{Compressive sensing} Compressive sensing has enabled the design of single-pixel imaging systems that are able to reconstruct images from very few measurements. 
These systems are useful in applications where it is expensive to have pixel arrays that sample the full image in parallel. 
For example in low-light applications, PMTs are commonly used, and it is expensive to build arrays of PMTs.

Additionally, compressive sensing can also be applied to other imaging modalities such as hyper-spectral imaging,  fluorescence imaging etc... 

\bnote{Signal reconstruction under Poisson noise.}\ynote{same as before. Shouldn't talk about comprehensive sensing here. Everything we have talked about before is about signal reconstruction} The most efficient compressive sensing systems have been implemented for signal reconstruction under Gaussaian noise. 
Unfortunately, compressive sensing in the presence of Poisson noise does not benefit from the same low-sample complexity \cite{raginsky2011performance}.
This is due to XXX


\bnote{Signal reconstruction amplifies (\rnote{may not necessarily}) noise so we should skip it.} 
Signal reconstruction, however, is often an intermediate step. 
The final goal is often to execute a high-level task such as classification or segmentation.
To this end, current computer vision systems extract features from the reconstructed signal and use these features to accomplish the task at hand.
In this paper, we find that in a single-pixel imaging system under Poisson noise, it is sub-optimal to reconstruct from compressive measurements and then extract features.
This is because the signal reconstruction step amplifies noise.

\bnote{Task Specific Masks vs General Masks}
Should we adapt our masks based on our objective (pattern recognition task, image reconstruction domain, different types of signals)? The conventional wisdom for AGN is that that doesn't help much. 

Now we need to do analysis:
define toy problems, discuss performance for simple adaptive masks
conclusion: with Poisson noise signal reconstruction makes no sense. But pattern recognition works with an adapted mask set.

How do we find the masks:
PCA, ONN

\bnote{Optical neural nets to the rescue.} 
Inspired by recent trends in optical neural networks, we propose a single-pixel vision system for low-light applications. 
By capturing image features directly we avoid amplifying noise

\bnote{How to design these masks.} 

Discussion:
end to end computational imaging with adaptive asks works under Poisson noise.

This provides an additional motivation for proposed optical ANNs or ANNs with optical layers. Such an architecture allows me to choose where in the design I want to add the Poisson noise.

Possibly: Quantum mechanics interpretation.
\fi