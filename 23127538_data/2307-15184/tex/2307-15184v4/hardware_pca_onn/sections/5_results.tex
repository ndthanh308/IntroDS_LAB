
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{\homedir/sections/5_results_theory}


% \subsection{Mask optimization using PCA}
% \ynote{Describe
% Show image created wit PCA vs raster for noise levels
% }

% \YLnote{The images of PCA and raster doesn't depend on noise levels}








\subsection{Classification Rates on Simulated Experiment Data}

\Xhide{
\Xpolish{In simulations, both the AGN and Poisson noise models were tested with the model we proposed. The results were generated under different noise levels by changing the exposure time. In addition, all compressible strategies were tested while changing the total number of masks. We defined a metric called compression ratio which is the ratio of the number of masks over the number of pixels. For the RS and HB, this ratio is constrained to be $1.00$. And for the rest, all values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$ were evaluated. Different from other strategies whose masks were pre-defined, the initial masks for ONN can affect the performances when noise exists. In this project, we initialized its masks by the PCA components from the training data as it usually has the best performances.}
{We evaluated our proposed model through simulations that tested both AGN and Poisson noise models, using varying exposure times to generate results at different noise levels. We also tested all {compressible} strategies, varying the total number of masks, and defined a metric called compression ratio as the ratio of the number of masks to the number of pixels \cite{stojek2022define_compression_ratio}. For RS and HB, this ratio was constrained to be 1.00, while the rest were evaluated over values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$. Unlike pre-defined masks used by other strategies, the initial masks for ONN can affect performance in the presence of noise. We therefore initialized its masks with the PCA components from the training data, which typically yield better performance.}
}

\Xpolish{The figure \ref{fig:simulated_classification} shows the classification performances with different parameters. The x-axis is the log-scaled mean square error (MSE) of impulse imaging (II) for some exposure time. The measured impulse imaging data requires no reconstruction and can be directly used to compute the noise level via $\|\noisy{\B{y}}_{II} - \B{x}\|_2^2$. As the golden standard in this project, this MSE can work as a metric showing the noise level for both AGN and Poisson noise models. The y-axis is the classification rate on the validation set. The compression ratio can affect the classification performances, so in this figure, we tried all the values in $\mathcal{C}_R$ and picked the best one for TH, PCA and ONN.}
{Fig. \ref{fig:simulated_classification} displays the classification performance of different coding schemes. Since Poisson noise is signal dependent and AGN is not, comparing the performance under both models is not straight forward. To provide a common metric for both models, whe x-axis is the log-scaled MSE of impulse imaging (II) with varying exposure times. \Xhide{Since the measured impulse imaging data requires no reconstruction, the noise level can be directly computed by $\|\noisy{\B{y}}_\mathrm{II} - \B{x}\|_2^2$.} This MSE is the gold standard in this project and serves as a metric to measure the noise level for both AGN and Poisson noise models. The y-axis represents the validation set's classification rate. \Xhide{We explored all the values in $\mathcal{C}_R$ to determine the best compression ratio for TH, PCA, and ONN since compression ratio affects classification performance. Each data point in the Figure represents the best results among all compression ratios for each strategy.}}\Xpolish{In this figure, we can see the II always has the best performance, which meets our expectation. When the noise is AGN, using any coding gives rise to a significant improvement compared with RS. For this classification task, using low-rank measurement (HB, PCA, ONN) can further improve this model's classification performances. Notably, the ONN has a performance close enough to the II with only 0.1\% number of photons.}
{A good way to understand the results is to consider the performance of different schemes in relation to the curves for II an RS. \YLnote{\Xpolish{Datasets}{Measurements}} for each of the of the schemes can be created as some subset of an II measurement. Thus it should not be possible for any coded single pixel system to perform better than II. RS is the trivial code allowing simple implementation that also transmits the least amount of light. We expect it to perform poorly and any code with worse performance than it seems hard to justify as a useful scheme. We evaluate the codes by noting how they perform within these two extremes. The results presented in the figure demonstrate that as expected II consistently achieves the highest performance. In the presence of AGN, all coding schemes exhibit significant improvements over RS and in many cases provide adequate performance. This is because under Gaussian noise, projection from a captured basis into a basis of sparsity where the classifier operates can be done without a significant noise penalty. Moreover, for the classification task at hand, \YLnote{\Xpolish{low-rank measurement techniques such as HB, PCA, and ONN}{SS measurement techniques such as PCA and ONN}}, can yield further improvements in classification performance. Notably, the ONN approach produces results that are nearly as good as the II approach, \YLnote{\Xpolish{while using only 0.1\% {of the photons} \AVnote{AGN, so no photons}}{while reducing the number of pixels on the sensor from several thousands to one}}.}

% Figure environment removed

\Xhide{\bnote{color compressible and non-compressible differently}}




\Xpolish{However, when the measured data is Poisson distributed, HB is no better than RS any more, which agrees the conclusions of Harwit et al. \cite{harwit1979hadamard} that we should not adopt coding for Poisson noise. Though Hadamard coding is not promising, we can still have extra performance gain by using low-rank methods. Among all low-rank methods, the ONN is still the best, suggesting Selective Sensing is the most optimal method for both noise models.}
{However, when dealing with Poisson-distributed measured data, the effectiveness of \Xpolish{Hadamard-based (HB)}{non-selective} coding is no longer superior to that of RS. This aligns with the findings of Harwit et al. \cite{harwit1979hadamard}, which discourage the adoption of coding for Poisson noise. Despite this, there is still potential for performance improvement by utilizing \YLnote{\Xpolish{low-rank}{SS}} methods such as \Xhide{TH, }PCA and ONN. \AVnote{\checkednote{repeating}} \YLnote{\checkednote{This is likely due to the fact that the images with analyze do in fact have sparsity in the Hadamard basis. Selective Sensing where capture patterns are optimized to capture sparsity directly like the ONN can retain their performance under poisson noise making them viable replacements for simple point scanners. This indicates that \Xpolish{Selective Sensing is the most optimal approach for both noise models. }{SS can serve as a potential replacement of II in some scenarios.}}}}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classification Performances on Hardware Experiment Data}

\Xpolish{In the experiments, we used a DMD and a PMT to measure 10 handwritten numbers from the MNIST dataset. The models were trained with $10^5$ photons, which is a greater noise level compared with the experimental environment. The collected data was in the form of a series of timestamps recording the arrival time of the photons. When collecting data, both RS and HB used 1024 masks. The TH and the HB shares the same measured data but the TH only uses the first 92 measured data. PCA and ONN used 92 masks, which is the same as the TH. The physical measurements took 1 second per mask for all strategies. To create data of greater noise level from the raw data, we randomly picked intervals during the 1 second span, and counted the total numbers in it. Since the ONN and PCA only have 92 masks, the maximum exposure time was set as 92 seconds. In a fair comparison, the interval length of each strategy was cpmputed as $\frac{\tau}{m}$ where $\tau$ is the total exposure time we want to investigate and $m$ is number of masks for this strategy.}
{In our experiments, \Xpolish{we utilized a DMD and a PMT to measure ten handwritten digits from the MNIST dataset. To train the models, we employed $10^5$ photons, which constituted a higher noise level in comparison to the experimental setup. T}{t}he collected data takes the form of a series of timestamps recording the photons' arrival time. During data collection, both RS and HB uses 1024 masks, while  TH and HB employ the same measured data, but TH uses only the first 92 measurements for compression purposes. Similarly, PCA and ONN utilizes 92 masks. Physical measurements take one second per mask for all strategies. To generate data with higher noise levels from the raw data, we randomly select intervals within the 1-second span and count the total number of photons within them. Since  ONN and PCA have only 92 masks, the maximum exposure time is set to 92 seconds. To ensure a fair comparison, we compute the interval length for each strategy as $\frac{\tau}{m}$, where $\tau$ represents the total exposure time under investigation, and $m$ denotes the number of masks used for each strategy.}

\Xhide{\bnote{consistent color on figures}}

% Figure environment removed

\Xhide{\bnote{change the x tick labels}}

\Xpolish{However, we still saw some unexpected phenomena in the figure. Firstly, the HB strategy was better than the RS when the exposure was short, which was not observed in the simulation. This phenomenon might arise from the dark photon in the PMT. The dark photon is a signal-independent noise which has about 40-80 counts per second and could usually be observed before the experiments started. When the exposure was short, this noise would be more significant and gave rise to a better performance of the HB. Secondly, the TH achieved better classification performances than PCA when the exposure time is short. It was the consequence of using unneeded PCA masks. To verify, we fixed the toal number of photons at $10^5$, change the compression ratio, and made figure \ref{fig:classification_ratio} by simulation. This figure shows that PCA method can be worse than TH when it has more masks than needed. In other words, PCA strategy requires an careful estimation of the noise level to avoid using extra masks. Notably, the ONN looks more stable when includes extra masks. That can be seen as another advantage of the Selective Sensing. After the models are trained, they may be applied in unknown noise levels. Different from PCA strategy whose optimal number of masks is noise level sensitive, the ONN can have a better and robust performance even when the number of masks is not optimal.}
 {Fig. \ref{fig:Exp_classification} displays the classification rates achieved on the experimental data. The x-axis shows the exposure time, and the y-axis represents the classification rates of the models. Although there may be discrepancies between software training and hardware data acquisition, the ONN models \Xpolish{performed excellently}{outperform other coding schemes across all noise levels}. However, the figure reveals some unexpected phenomena. Firstly, the HB strategy outperforms the RS for short exposure times, which is not observed in the simulations. This phenomenon may have arisen due to the dark counts in the PMT, a signal-independent noise that has about 40-80 counts per second \YLnote{\Xpolish{, and is more pronounced in short exposures}{under our lab condition}}. Secondly, TH achieves better classification performances than PCA when the exposure time is short. This result is due to the use of unneeded PCA masks since the compression ratio was not optimized as it was in the simulation. To verify, we conduct simulations and obtain Fig. \ref{fig:2d_classification_plots} by fixing the total number of photons at $10^5$ and varying the compression ratio under the Poisson noise. This figure shows that PCA method can perform worse than the TH if \YLnote{\Xpolish{extra masks are used}{an improper compression ratio is chosen}}. Hence, PCA strategy requires careful estimation of the noise level to avoid \YLnote{\Xpolish{using extra masks}{improper compression ratios}}. \YLnote{\Xpolish{Notably, the ONN appears more stable when including extra masks, which is another advantage of the ONN. The ONN can perform robustly even with suboptimal numbers of masks, unlike PCA strategy, which is noise-level sensitive. While it is possible to set the noise level during training, the effectiveness of the ONN can be evaluated for other levels of noise as well.}{Notably, ONN demonstrates enhanced stability and robustness when confronted with this challenge.}} This flexibility in application allows for broader use of the ONN beyond its specific training conditions, increasing its potential impact and utility in real-world scenarios.}




\Xhide{
% Figure environment removed
}


\Xhide{\YLnote{2D plot. \& Don't re-train the model. For training, choose a fixed noise (1e5) level, and for testing, use multiple noise levels}.}

\Xhide{
% Figure environment removed
}

% Figure environment removed

\Xhide{\YLnote{Show: fixed CR and change the noise level}}

\Xhide{\bnote{use $C_R$ on x axis}}

\Xhide{\YLnote{Add how to adjust the experimental data to be classified by simulated model}}



\input{\homedir/sections/5_results_hyperspectral}