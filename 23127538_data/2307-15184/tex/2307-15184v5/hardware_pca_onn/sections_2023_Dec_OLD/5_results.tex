
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{\homedir/sections/5_results_theory}


% \subsection{Mask optimization using PCA}
% \ynote{Describe
% Show image created wit PCA vs raster for noise levels
% }

% \YLnote{The images of PCA and raster doesn't depend on noise levels}








\subsection{Classification Rates on Simulated Experiment Data}

\Xpolish{In simulations, both the AGN and Poisson noise models were tested with the model we proposed. The results were generated under different noise levels by changing the exposure time. In addition, all compressible strategies were tested while changing the total number of masks. We defined a metric called compression ratio which is the ratio of the number of masks over the number of pixels. For the RS and HB, this ratio is constrained to be $1.00$. And for the rest, all values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$ were evaluated. Different from other strategies whose masks were pre-defined, the initial masks for ONN can affect the performances when noise exists. In this project, we initialized its masks by the PCA components from the training data as it usually has the best performances.}
{We evaluated our proposed model through simulations that tested both AGN and Poisson noise models, using varying exposure times to generate results at different noise levels. We also tested all {compressible} strategies, varying the total number of masks, and defined a metric called compression ratio as the ratio of the number of masks to the number of pixels \cite{stojek2022define_compression_ratio}. For RS and HB, this ratio was constrained to be 1.00, while the rest were evaluated over values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$. Unlike pre-defined masks used by other strategies, the initial masks for ONN can affect performance in the presence of noise. We therefore initialized its masks with the PCA components from the training data, which typically yield better performance.}

\Xpolish{The figure \ref{fig:simulated_classification} shows the classification performances with different parameters. The x-axis is the log-scaled mean square error (MSE) of impulse imaging (II) for some exposure time. The measured impulse imaging data requires no reconstruction and can be directly used to compute the noise level via $\|\noisy{\B{y}}_{II} - \B{x}\|_2^2$. As the golden standard in this project, this MSE can work as a metric showing the noise level for both AGN and Poisson noise models. The y-axis is the classification rate on the validation set. The compression ratio can affect the classification performances, so in this figure, we tried all the values in $\mathcal{C}_R$ and picked the best one for TH, PCA and ONN.}
{Figure \ref{fig:simulated_classification} displays the classification performance of different parameters. The x-axis is the log-scaled MSE of impulse imaging (II) with varying exposure times. \Xhide{Since the measured impulse imaging data requires no reconstruction, the noise level can be directly computed by $\|\noisy{\B{y}}_\mathrm{II} - \B{x}\|_2^2$. }This MSE is the gold standard in this project and serves as a metric to measure the noise level for both AGN and Poisson noise models. The y-axis represents the validation set's classification rate. We explored all the values in $\mathcal{C}_R$ to determine the best compression ratio for TH, PCA, and ONN since compression ratio affects classification performance. The figure shows the best results among all compression ratios for each strategy.}

% Figure environment removed

\Xhide{\bnote{color compressible and non-compressible differently}}


\Xpolish{In this figure, we can see the II always has the best performance, which meets our expectation. When the noise is AGN, using any coding gives rise to a significant improvement compared with RS. For this classification task, using low-rank measurement (HB, PCA, ONN) can further improve this model's classification performances. Notably, the ONN has a performance close enough to the II with only 0.1\% number of photons.}
{The results presented in the figure demonstrate that II consistently achieves the highest performance, which is in line with our expectations. In the presence of AGN, all coding schemes exhibit significant improvements over RS and in many cases provide adequate performance. This is because under Gaussian noise, projected from a captured basis into a basis of sparsity where the classifier operates can be done without a significant noise penalty. Moreover, for the classification task at hand, low-rank measurement techniques such as HB, PCA, and ONN, can yield further improvements in classification performance. Notably, the ONN approach produces results that are nearly as good as the II approach, while using only 0.1\% of the photons.}

\Xpolish{However, when the measured data is Poisson distributed, HB is no better than RS any more, which agrees the conclusions of Harwit et al. \cite{harwit1979hadamard} that we should not adopt coding for Poisson noise. Though Hadamard coding is not promising, we can still have extra performance gain by using low-rank methods. Among all low-rank methods, the ONN is still the best, suggesting Selective Sensing is the most optimal method for both noise models.}
{However, when dealing with Poisson-distributed measured data, the effectiveness of Hadamard-based (HB) coding is no longer superior to that of RS. This aligns with the findings of Harwit et al. \cite{harwit1979hadamard}, which discourage the adoption of coding for Poisson noise. Despite this, there is still potential for performance improvement by utilizing low-rank methods such as TH, PCA and ONN. This is likely due to the fact that the images with analyze do in fact have sparsity in the Hadamard basis. Selective Sensing where capture patterns are optimized to capture sparsity directly like the ONN can retain their performance under poisson noise making them viable replacements for simple point scanners. This indicates that Selective Sensing is the most optimal approach for both noise models. }




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classification Performances on Hardware Experiment Data}

\Xpolish{In the experiments, we used a DMD and a PMT to measure 10 handwritten numbers from the MNIST dataset. The models were trained with $10^5$ photons, which is a greater noise level compared with the experimental environment. The collected data was in the form of a series of timestamps recording the arrival time of the photons. When collecting data, both RS and HB used 1024 masks. The TH and the HB shares the same measured data but the TH only uses the first 92 measured data. The PCA and ONN used 92 masks, which is the same as the TH. The physical measurements took 1 second per mask for all strategies. To create data of greater noise level from the raw data, we randomly picked intervals during the 1 second span, and counted the total numbers in it. Since the ONN and PCA only have 92 masks, the maximum exposure time was set as 92 seconds. In a fair comparison, the interval length of each strategy was cpmputed as $\frac{\tau}{m}$ where $\tau$ is the total exposure time we want to investigate and $m$ is number of masks for this strategy.}
{In our experiments, we utilized a DMD and a PMT to measure ten handwritten digits from the MNIST dataset. To train the models, we employed $10^5$ photons, which constituted a higher noise level in comparison to the experimental setup. The collected data took the form of a series of timestamps recording the photons' arrival time. During data collection, both RS and HB used 1024 masks, while the TH and HB employed the same measured data, but the TH used only the first 92 measurements. Similarly, PCA and ONN utilized 92 masks. Physical measurements took one second per mask for all strategies. To generate data with higher noise levels from the raw data, we randomly selected intervals within the 1-second span and counted the total number of photons within them. Since the ONN and PCA had only 92 masks, the maximum exposure time was set to 92 seconds. To ensure a fair comparison, we computed the interval length for each strategy as $\frac{\tau}{m}$, where $\tau$ represents the total exposure time under investigation, and $m$ denotes the number of masks used for each strategy.}

\Xhide{\bnote{consistent color on figures}}

% Figure environment removed

\Xhide{\bnote{change the x tick labels}}

\Xpolish{However, we still saw some unexpected phenomena in the figure. Firstly, the HB strategy was better than the RS when the exposure was short, which was not observed in the simulation. This phenomenon might arise from the dark photon in the PMT. The dark photon is a signal-independent noise which has about 40-80 counts per second and could usually be observed before the experiments started. When the exposure was short, this noise would be more significant and gave rise to a better performance of the HB. Secondly, the TH achieved better classification performances than the PCA when the exposure time is short. It was the consequence of using unneeded PCA masks. To verify, we fixed the toal number of photons at $10^5$, change the compression ratio, and made figure \ref{fig:classification_ratio} by simulation. This figure shows that the PCA method can be worse than the TH when it has more masks than needed. In other words, the PCA strategy requires an careful estimation of the noise level to avoid using extra masks. Notably, the ONN looks more stable when includes extra masks. That can be seen as another advantage of the Selective Sensing. After the models are trained, they may be applied in unknown noise levels. Different from the PCA strategy whose optimal number of masks is noise level sensitive, the ONN can have a better and robust performance even when the number of masks is not optimal.}
 {Fig. \ref{fig:Exp_classification} displays the classification rates achieved on the experimental data. The x-axis shows the exposure time, and the y-axis represents the classification rates of the models. Although there may be discrepancies between software training and hardware data acquisition, the ONN models performed excellently. However, the figure reveals some unexpected phenomena. Firstly, the HB strategy outperformed the RS for short exposure times, which was not observed in the simulations. This phenomenon may have arisen due to the dark photon in the PMT, a signal-independent noise that has about 40-80 counts per second, and was more pronounced in short exposures. Secondly, the TH achieved better classification performances than the PCA when the exposure time was short. This result was due to the use of unneeded PCA masks. To verify, we conducted simulations and made Fig. \ref{fig:2d_classification_plots} by fixing the total number of photons at $10^5$ and varying the compression ratio under the Poisson noise. This figure showed that the PCA method could perform worse than the TH if extra masks were used. Hence, the PCA strategy requires careful estimation of the noise level to avoid using extra masks. Notably, the ONN appeared more stable when including extra masks, which is another advantage of the ONN. The ONN can perform robustly even with suboptimal numbers of masks, unlike the PCA strategy, which is noise-level sensitive. While it is possible to set the noise level during training, the effectiveness of the ONN can be evaluated for other levels of noise as well. This flexibility in application allows for broader use of the ONN beyond its specific training conditions, increasing its potential impact and utility in real-world scenarios.}




\Xhide{
% Figure environment removed
}


\Xhide{\YLnote{2D plot. \& Don't re-train the model. For training, choose a fixed noise (1e5) level, and for testing, use multiple noise levels}.}

\Xhide{
% Figure environment removed
}

% Figure environment removed

\Xhide{\YLnote{Show: fixed CR and change the noise level}}

\Xhide{\bnote{use $C_R$ on x axis}}

\Xhide{\YLnote{Add how to adjust the experimental data to be classified by simulated model}}



\input{\homedir/sections/5_results_hyperspectral}