\Xpolish{Two classification tasks are introduced in this section. We first test the performances of all the coding schemes on the MNIST dataset for number recognition, and then test them on the hyperspectral data.}{
In this section, we present two distinct classification tasks. Initially, we assess the effectiveness of various coding schemes using the MNIST dataset, focusing on their performance in number recognition. Subsequently, we extend the evaluation to hyperspectral data, examining the adaptability and efficacy of the coding schemes in this different domain.
}


\subsubsection{MNIST Simulated Data Preparation}

% \subsubsection{MNIST Data Pre-processing}

\Xpolish{The MNIST dataset consists of handwritten digits from 0 to 9, with a default size of 28 by 28 pixels \cite{lecun1998MNIST}. In order to align the data with the Hadamard matrices, we padded the images with black pixels at the edges to resize them to 32 by 32 pixels \cite{lecun1998MNIST}. We then transformed the range of all pixel values from $[0,1]$ to $[0.3, 1]$. This operation enhanced the persuasiveness of the dataset for various noise models, as the added black pixels do not generate Poisson noise, whose variance is proportional to the expected photon counts. \bnote{did we ever vary the dark level (0.3)/ have results showing its effect?}}
{The MNIST dataset, which comprises handwritten digits ranging from 0 to 9, has a default size of 28 by 28 pixels \cite{lecun1998MNIST}. To align the data with Hadamard matrices, we add black pixels to the edges of the images and resize them to 32 by 32 pixels \cite{lecun1998MNIST}. Subsequently, we rescale the pixel values from the original range of $[0,1]$ to $[0.3, 1]$. This rescaling introduces non-zero Poisson noise to the black regions, which has variance proportional to the expected photon counts.}

{We evaluate our proposed model through simulations \Xpolish{that test}{incorporating} both AGN and Poisson noise models, using varying exposure times to generate results at different noise levels. We also test all {compressible} strategies, varying the total number of masks but fixing the total exposure time, and define a metric called compression ratio as the ratio of the number of masks to the number of pixels \cite{stojek2022define_compression_ratio}. For RS and HB, this ratio is constrained to be 1.00, while the rest are evaluated over values in $\mathcal{C}_R = \{0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.00\}$ so that $\B{M}$ of each coding scheme is not restricted to be full-rank. The final comparison only involves the best results among all compression ratios for each strategy. Unlike pre-defined masks used by other strategies, the initial masks for ONN can affect performance in the presence of noise. We therefore initialized its masks with the PCA components from the training data.}