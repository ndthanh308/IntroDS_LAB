\iffalse
\IEEEPARstart{T}{his} demo file is intended to serve as a ``starter
file'' for ICCP 2020 submissions produced under
\LaTeX~\cite{kopka-latex} using IEEEtran.cls version 1.8b and later.
\fi


\IEEEPARstart{O}{}ptical coding, also known as multiplexing, is a popular technology in computational imaging (CI) due to its potential to achieve enhanced signal-to-noise ratio (SNR) and greater light throughput than point by point measurements\cite{mitra2014can}. If ignoring the noise, coding is represented as 
 \begin{equation}
    \label{eqn:NoiselessMeasurement}
    \begin{aligned}
        \B{y} &=  \B{M x} ,
    \end{aligned}
\end{equation}
where $\B{x}$ is the signal vector, $\B{M}$ is the sensing matrix, and $\B{y}$ is the measured vector. Decoding refers to the process of recovering the initial signal $\B{x}$ from $\B{y}$. The recovery quality of $\B{x}$, however, also depends on the conditioning of the $\B{M}$ besides the light throughput \cite{mitra2014can}. Suboptimal $\B{M}$ have the potential to significantly degrade the performance of the vision system during the recovery process, as highlighted by Mitra et al. \cite{mitra2014can}. The optimization of coding schemes regarding $\B{M}$ is intricately linked to the characteristics of noise. Coding schemes, typically formulated under the assumption of signal-independent Additive Gaussian Noise (AGN), offer a mathematically tractable framework. However, AGN, while suitable for modeling certain noise types introduced by measurement devices, inadequately represents Poisson noise \cite{yang2015poisson} arising intrinsically due to the discrete and random nature of photon measurements. The optimization behaviors of coding manifest notable distinctions under low-light conditions where Gaussian noise dominates and high-light conditions where Poisson noise prevails \cite{mitra2014can}, suggesting coding and compressed sensing approaches designed for effectiveness under the AGN or noiseless conditions unsuitable under Poisson noise. It has been shown that in that case without the use of priors for regularization, coding does not provide an improvement over a simple sequential scan \cite{harwit1979hadamard, swift1976hadamard, willet2009CSPoisson, scotte2022photon_noise, vanden2019various}. 
Mitra et. al. \cite{mitra2014can} develop a data driven prior to design optimized codes for image reconstructions that can markedly enhance the reconstruction performance of coding schemes under Poisson noise \cite{mitra2014can}. \YLnote{An important conclusion is that if the signal exhibits sparsity and thereby  compressibility, signal optimized coding can improve recovery performance under Poisson noise and the amount of improvement is directly related to the comprehensibility of the measured data. However, recovery is typically not the ultimate goal for modern vision systems.} Furthermore, the cost function based on the L2 error metric in that project lacks essential perceptual information \cite{mitra2014can}. \YLnote{Since vision tasks, such as classification, operate in embeddings created from images their data should be inherently more compressible than their upstream imaging tasks. Therefore, if signal compressibility is the key, skipping the intermediate imaging step and directly focusing on coding for better feature extraction for subsequent vision tasks should yield better performance.} To show this, our study implements a simple end to end vision system that can be optimized  under different noise assumptions. We illustrate why AGN is not suitable for optimizing coding under Poisson noise and show that a coding scheme optimized for a specific vision task and for the correct noise model can perform close to the optimal non-coding camera even when only photon noise is present.
% }

% If the signal is sparse and compressible, it is possible to have a better recovery performance under Poisson noise. However, recovery is usually not the final objective for modern vision systems. Vision tasks, such as classification, usually present greater compressibility than their upstream imaging tasks. If the signal compressibility is the answer, we should skip the intermediate imaging step and directly code for better feature extracting for next vision tasks to attain the best compressibility and therefore, better performances under Poisson noise.

Our contributions are as listed.
\begin{itemize} 
% \item We analyze the performance of coding techniques for  using toy applications in single-pixel-imaging, compare the behavior of popular approaches for both additive Gaussian and Poisson noise individually, and develop coding strategies that work under Poisson noise. 
\item Similar to the conclusion of Cossairt et al. \cite{cossairt2012does}, Mitra et al. \cite{mitra2014can}, Harwit et. al. \cite{harwit1979hadamard}, Swift et. al. \cite{swift1976hadamard}, and Raginsky et. al. \cite{willet2009CSPoisson}, we find that general prior free  coding \YLnote{using Hadamard and random matrices} provides no benefit over a trivial raster scanning approach under Poisson noise using an identity matrix\Xhide{ as $\B{M}$} {\cite{scotte2022photon_noise, wuttig2005optimal, schumann2002SNR_poisson, larson1974hadamard_poisson, streeter2009optical_poisson}}. We find, however, that in applications like compressed sensing and pattern recognition, where the collected data is highly compressible, substantial improvements in classification rate can be seen if appropriate adjustments to the measurement matrices are made. In these scenarios the compressive vision system performance approaches the performance of a non-coded camera.
\item We assert that coding can yield substantial performance improvements under Poisson noise \textit{only} when codes used in hardware capture are optimized specifically for downstream vision tasks.
\item \Xpolish{We propose the methodology of selective sensing (SS) which includes coding methods selectively extracting the data-driven priors and can be directly combined with models for downstream tasks.}{We introduce the methodology of Selective Sensing (SS), which encompasses coding techniques specifically designed to extract data-driven priors selectively. These coding methods can be seamlessly integrated with models for downstream tasks, providing a novel approach to efficiently incorporate learned priors into various applications.}
\item We provide a model to \Xpolish{create masks optimized}{optimize $\B{M}$} for Poisson noise using neural network model. \YLnote{We find optimized measurements significantly enhances single-pixel vision performance, particularly in Poisson noise-dominated signals like visible light, approaching the efficacy of ideal multipixel vision systems.} 
Addressing the limitations identified by Mitra et al. \cite{mitra2014can}, this model presents the following advantages.
    \begin{itemize}
        \item The optimization of coding relies on the gradient descent algorithm, leading to the determination of a globally optimal $\B{M}$ rather than its greedy approximation.
        \item Noise is incorporated during the training process to simulate real-world conditions, deviating from the assumption of a one-dimensional affine noise model.
        \item The training process is accelerated and computationally more efficient due to the binary constraint being addressed even in real experiments. Additionally, the prior is learned from the entirety of the light fields and spectral data, rather than from patches.
        \item The contribution of a data-driven prior to performance enhancement is more accurately discerned when evaluating this model using the classification rate, a metric that holds superior interpretability in terms of visual perceptual meaning compared to the reconstruction error.
    \end{itemize}
\end{itemize}
