% \IEEEPARstart{A}{} single-pixel sensor such as a photonmultiplier tube (PMT) can only count the total number of photons in measurements. A Digital Micromirror Device (DMD) consisting of millions of mirror chips tunable by $\pm 12$ degrees is necessary for the spatial information. When the photons from the whole field of view arrive at the DMD, the chips split and reflect them as two branches. In each measurement, the sensor counts the photons from those chips, or pixels, in other words, facing it. 

\IEEEPARstart{A}{} single-pixel sensor, such as a photon multiplier tube (PMT), is capable of detecting the total number of photons in a measurement, but lacks the ability to provide spatial information. In order to obtain this information, a Digital Micromirror Device (DMD) must be used. The DMD consists of millions of mirror chips that are tunable by $\pm 12$ degrees and can split and reflect photons from the field of view into two separate branches. During a measurement, the sensor counts the photons from the chips, or pixels, that are facing it, providing spatial information about the distribution of photons within the field of view.


\subsection{Model Formulation}

% introduce the Poisson noise
% start from noiseless model

% \subsubsection{Ideal Model}



% The single-pixel-sensing process, if ignoring noise, can be expressed as the following equation 
% \begin{equation*}
%     \begin{aligned}
%         n_{\gamma} &=  j \sum_{k=1}^N x_k \sum_{l=1}^L m^B_{kl}  \tau_l \\
%             &= \lambda \sum_{k=1}^N x_k m_k
%     \end{aligned},
% \end{equation*}
% where $n_\gamma$ is the total number counted by the sensor, $N$ is the total number of pixels, $m^B_{kl} \in \{-1, 1\}$ and $\tau_l$ are the binary status of the $k_\text{th}$ DMD chip and the exposure time for the $l_\text{th}$ physical measurement respectively, $x_k$ is the the reflection coefficient of the $k_\text{th}$ subarea of the field of view measured as one pixel, and $j$ is the photon flux cast on each $x_k \in [0,1]$. Suppose the field of view is illuminated uniformly, $x_k=1$ stands for a white pixel while $x_k=0$ represents a black pixel. The $m_k \in \IR$ is introduced for simplicity, which physically stands for the fact that we can obtain a real-number mask by combining multiple binary masks with different exposure periods. The scaling factor $\lambda$ is related to the photon distribution among all the masks and will be discussed later. Thus, for the $t_\text{th}$ measurement, we have 
% \begin{equation*}
%     \begin{aligned}
%         {n_\gamma}_t &= \lambda \sum_{k=1}^N M_{tk} x_k 
%     \end{aligned}.
% \end{equation*} 
% Here, we introduce the normalized measurement $y = \frac{n_\gamma}{\lambda}$ as the optical nature of the objects.
% The corresponding matrix expression for the single-pixel imaging is 
% \begin{equation}
%     \label{eqn:NoiselessMeasurement}
%     \begin{aligned}
%         \B{y} &=  \B{M} \B{x}
%     \end{aligned}.
% \end{equation} 

% Two noise models were investigated in this project. The first one is the popular Additive White Gaussian Noise (AWGN) with the following form
% % \subsubsection{Gaussian Noise Model}

% \begin{equation}
%     \begin{aligned}
%         \lambda\tilde{\B{y}} &\sim \mathcal{N}(\lambda \B{M} \B{x} , \sigma \B{I})
%     \end{aligned}.
% \end{equation} 
% % \subsubsection{Poisson Noise Model}
% The $\sigma$ is the standard deviation. The other is the Poisson Noise model for photon-counting systems \cite{willet2009CSPoisson} with the following form
% \begin{equation}
%     \begin{aligned}
%         \lambda\tilde{\B{y}} &\sim \mathcal{P}(\lambda \B{M} \B{x})
%     \end{aligned}.
% \end{equation} 

Supposing the image of the field of view consists of $N \in \IZ^+$ pixels and is measured by $m \in \IZ^+$ masks, the single-pixel-sensing process, if ignoring noise, can be expressed as the following equation 
 \begin{equation}
    \label{eqn:NoiselessMeasurement}
    \begin{aligned}
        \B{y} &=  \B{Mx}
    \end{aligned},
\end{equation}
where $\B{x} \in \IR^{N \times 1}$ is the image representation of the field of view, $\B{M} \in \IR^{m \times N}$ is the sensing masks linearly projecting the field of view , and $\B{y} \in \IR^{m \times 1}$ is the corresponding photon counts \cite{willet2009CSPoisson}. There are two main physical constraints when optically implementing equation \ref{eqn:NoiselessMeasurement} \cite{neifeld2003dual}. 
% \begin{enumerate}    
%     \item\label{constraint:photonNumber} The single-pixel imaging model concerns the re-distribution of available photons among masks \cite{neifeld2003dual}. No photons should be created by improper entries in the mask basis $\B{M}$.
%     \item\label{constraint:negativeEntry}Negative values of the masks $\B{M}$ cannot be implemented directly \cite{neifeld2003dual}. 
% \end{enumerate}

\begin{enumerate}
    \item\label{constraint:photonNumber}The single-pixel imaging model involves the allocation of available photons among masks, as discussed in \cite{neifeld2003dual}. It is important to ensure that the mask basis $\B{M}$ does not produce additional photons through improper entries. 
    \item\label{constraint:negativeEntry}It is not possible to physically implement negative values for the masks $\B{M}$, as demonstrated in \cite{neifeld2003dual}. 
\end{enumerate}

% This concise model, however, is not convenient for us to investigate the same mask basis under different light levels. So it is necessary to reformulate this photon-counting model where $\B{M}$ and $\B{x}$ are not related to the number of photons. The new photon-counting model and some tricks for the implementation are discussed in the following sections.

To further examine the mask basis under varied light levels, we propose a revised photon-counting model that decouples $\B{M}$ and $\B{x}$ from the number of photons. In the following sections, we detail the development of this new model and provide insights on its practical implementation.


\subsubsection{Photon Distribution Factor} \label{sssection:PDF}

Suppose the total number of available photons is $\totphoton$. Instead of constraining the mask basis $\B{M}$, we define a Photon Distribution Factor $\lambda$ in the single-pixel imaging model. In our hypothesis, ${\totphoton_j}$ photons are distributed to the $j_\text{th}$ mask, $\B{x} \in [0,1]^{N \times 1}$ is the unit image representation of the field of view, and there is no idle time between masks. In other word, each mask is re-scaled to have the maximum abstract value equal to $1$. The measured photon counts in the $j_\text{th}$ measurement $\photon_j = \frac{\totphoton_j}{N} \sum_{k=1}^N \frac{M_{jk}}{v_j} x_k$ where $v_j$ is the maximum abstract value of the $j_\text{th}$ mask. It is not necessary to have $\photon_j = \totphoton_j$ as some entries in masks block photons. If $\totphoton_j$ is proportional to $v_j$, it is obvious that $\totphoton_j = \frac{v_j \totphoton}{N \sum_{k=1}^m v_k}$. Let $\lambda = \frac{\totphoton}{N \sum_{k=1}^m v_k}$, and we have $\photon_j = \lambda \sum_{k=1}^N M_{jk} x_k$. Though $\photon_j$ is what is measured by the sensor and also what is contaminated by noise, it is convenient to let $\tilde{y}_j = \frac{\photon_j}{\lambda}$ to resemble the noiseless model above. Here, we name $\B{y}$ the normalized photon counts.

% Thus, we have the general noisy model
%  \begin{equation}
%     \label{eqn:GeneralNoisyMeasurement}
%     \begin{aligned}
%         \lambda \tilde{\B{y}} &\sim  \mathcal{D}(\lambda\B{Mx}, \cdot)
%     \end{aligned},
% \end{equation}
% where $\mathcal{D}$ is the distribution of the interested noise model, $\tilde{\B{y}}$ is the noisy photon counts, and $\cdot$ is the optional parameter of the covariance.

Two noise models were investigated in this project. The first one is the Additive White Gaussian Noise (AWGN) stemming from the imperfectness of sensors \cite{boyat2015review} with the following form
% \subsubsection{Gaussian Noise Model}

\begin{equation}
    \begin{aligned}
        \lambda\tilde{\B{y}} &\sim \mathcal{N}(\lambda \B{M} \B{x} , \sigma^2 \B{I})
    \end{aligned}
\end{equation} 
% \subsubsection{Poisson Noise Model}
where the $\sigma$ is the standard deviation. The other is the Poisson Noise model for photon-counting systems \cite{willet2009CSPoisson} originating from the statistical nature of photons \cite{boyat2015review} with the following form
\begin{equation}
    \begin{aligned}
        \lambda\tilde{\B{y}} &\sim \mathcal{P}(\lambda \B{M} \B{x})
    \end{aligned}.
\end{equation} 

By introducing the Photon Distribution Factor, the mask basis $\B{M}$ is freed from constraint \ref{constraint:photonNumber}.


\subsubsection{Dual-Branch Trick for Negative Entries}\label{sssection:DualBranch}

Although we can obtain a negative number of photons from the difference between the two measurements, the Poisson noise cannot be directly applied to these values. Otherwise, it violates the nature of Poisson distributions and the fact that Poisson noise appears in the sensors. On the contrary, noise should be considered in both branches independently. 

To create the two branches, the mask $\B{M}$ should be split into $\B{M}^+ = \text{ReLU}(\B{M})$ and $\B{M}^- = \text{ReLU}(-\B{M})$. The superscripts of the parameters indicate the branches they belong to. Intuitively, we have $\lambda \tilde{\B{y}} = \lambda \tilde{\B{y}}^+ - \lambda \tilde{\B{y}}^-$ where $\tilde{\B{y}}^+$ and $\tilde{\B{y}}^-$ are noisy photon counts measured by $\B{M}^+$ and $\B{M}^-$ respectively. In this case, it is worth noting that the Photon Distribution Factor $\lambda = \frac{\totphoton}{N (\sum_{k=1}^m v_k^+ + \sum_{k=1}^m v_k^-)}$ where all the parameters are of the same meaning as in section \ref{sssection:PDF}.

In the AWGN model, the measurement $\lambda \tilde{\B{y}} \sim \mathcal{N}(\lambda \B{Mx}, 2\sigma^2 \B{I})$ with the dual-branch trick. But in the Poisson noise model, the measurement $\lambda \tilde{\B{y}} \sim \text{Skellam}(\lambda \B{M^+ x}, \lambda \B{M^- x})$. 

\subsection{Noise models}

\subsection{Scan Strategies with Different Priors}

% In general, single-pixel imaging involves computational and non-computational methods. Their essential difference is that computational imaging requires optical coding and computational decoding steps \cite{cossairt2012does}. A typical non-computational strategy is the raster scan by which the sensor measures each pixel sequentially \cite{duarte2008CS}. Correspondingly, computational strategies measure a combination of pixels simultaneously. The computational strategies can be further classified by their masks. The following is a natural arrangement of the strategies based on mask generations.  

Single-pixel imaging is a technique that involves both computational and non-computational methods. The primary difference between the two is that computational imaging requires additional steps of optical coding and computational decoding in order to capture and process the image \cite{cossairt2012does}. Non-computational methods, such as raster scanning, involve measuring each pixel sequentially \cite{duarte2008CS}. On the other hand, computational methods measure a combination of pixels simultaneously and can be further classified based on the type of mask used. In this paper, we will arrange the various computational strategies based on their mask generation techniques.
% Figure environment removed
 
\begin{enumerate}
    \item Static strategies: 
    Masks are predetermined and fixed.
    \begin{enumerate}
        \item Non-compressible strategies
        \begin{enumerate}
            \item Raster Scan (RS). In this strategy, only one pixel will be scanned in each measurement. Thus, $\B{M} = \B{I}$.
            \item Impulse Imaging (II). II captures the field of view by a pixel array. In this case, each pixel gets $N$ times as much as the exposure time of RS. Mathematically, $\B{M} = N\B{I}$. Alternatively, we can treat it as another RS with $N$ times as many photons. The II works as the baseline for the comparisons with other strategies.
            \item Hadamard Basis (HB). In this strategy, we choose the 2-D Walsh-Hadamard matrix $\B{H}$ as the mask basis.
        \end{enumerate}
        
        \item Compressible strategies
        \begin{enumerate}
            \item Randomly Truncated Hadamard (RTH). Given a default Walsh-Hadamard matrix $\B{H}$ and randomly pick several rows as $\B{M}$.
            \item Low-Frequency-Truncated Hadamard (LFTH). Given a default Walsh-Hadamard matrix $\B{H}$ and only keep the first several rows as $\B{M}$.
            \item Sorted-Truncated Hadamard (STH). Re-order the rows according to their correlation coefficients with the mean of training images. More relevant ones are picked first.
            \item Hardware Principal Components Analysis (HPCA). The DMD displays the PCA components calculated from the training images.
        \end{enumerate}
    \end{enumerate}
    
    \item Dynamic strategies: Masks can be optimized based on the tasks.
    \begin{itemize}
        \item Optical Neural Networks (ONN).
    \end{itemize}
\end{enumerate}
% This classification is intuitive but not conducive in deciding proper mask basis. A more sensible way is to evaluate these strategies by their priors. Image priors, depending on their types, can strengthen models' robustness to noise and improve the quality \cite{cossairt2012does, levin2007coded}. Conspicuously, All the strategies mentioned above have the following three prior levels.
In order to effectively determine the appropriate mask basis for a given scenario, it is necessary to evaluate the various strategies based on their priors. Image priors, which can vary in type, can enhance the robustness of models in the presence of noise and improve overall image quality \cite{cossairt2012does, levin2007coded}. It should be noted that all of the strategies discussed in this paper possess three distinct prior levels.
% Thus, these strategies can be re-grouped as follows. 
% For example, the RS doesn't need  , the LFTH is based on the fact that low-frequency components are more robust, and the HPCA learns information from training data. 

\begin{enumerate}
    \item Null-Prior: RS, II, and HB. It requires no information before measurements.
    \item Reconstruction-Prior: RTH and LFTH. This prior is from the inductive bias for signal reconstruction regardless of the data.
    \item Task-Specific-Prior: STH, HPCA, and ONN. This prior requires the features from training data of a specific task.
    % make plots based on the groups
\end{enumerate}



% \subsection{Illumination determination}


