\subsection{Model Validation}
\label{ssec:model_validation}
% In this section, we start with a theoretical investigation on the reconstruction performances of null-prior strategies. Then the reconstruction and classification performances of all strategies and fairly compared by simulations and experiments. 


\YLnote{
{
To validate the proposed ONN model, we apply it to non-compressible signal reconstruction tasks where the correct solution is known. \Xpolish{In subsequent sections, we derive the theoretical error propagation caused by both AGN and Poisson noise, assessing the ONN model's ability to substantiate our findings.}{
Previous theoretical studies have shown that multiplexing, such as Hadamard coding, is not recommended under Poisson noise for greater MSE \cite{duarte2008CS} and lower SNR \cite{harwit1979hadamard} compared to raster scan. In this project, we compare Hadamard and raster coding under both AGN and Poisson noise conditions to see whether the ONN model reaches similar conclusions.
}
}
}
\Xhide{\AVnote{\checkednote{This section still doesn't clearly state what we do and why. Cand te just say we train masks to reconstruct non -compressible signals? Jan 18, 2024 10:58 AM}}
\AVnote{\checkednote{Need to be more specific what we show. I think we select two patterns, raster and hadamart, and prove which is better for non-compressible data. Then we see if the ONN finds similar masks. Jan 18, 2024 11:08 AM}}}



% \subsubsection*{ONN Non-compressible Signal Reconstruction}  


{ 
Given the universality of reconstruction algorithms, it is imperative that the input data vector $\B{x}$, {is not compressible}.
\Xpolish{{To \Xpolish{make this reconstruction task less specific and more general}{generate non-compressible data}, we reshape the input data vectors $\B{x}$ from $10^5$ random 8 by 8 patterns, increasing their generality. W}{Therefore, w}e randomly sample \YLnote{\Xhide{10 times}}from the uniform distribution $U(0,1)$ to generate \Xhide{10 groups of }inputs \YLnote{$\B{x}$} and it is regenerated several times during the optimization, introducing \YLnote{\Xpolish{additional variability \AVnote{added to what?}}{extra randomization and less compressibility}}}{\YLnote{
Hence, we generate {$\B{x}$} by randomly sampling from the uniform distribution $U(0,1)$. Throughout the optimization process, these inputs are regenerated 10 times, thereby introducing additional randomization and reducing compressibility}}. 
The output is the reconstructed $\B{x}$, with MSE between the input and the output serving as the loss function.
The simulations are conducted \Xhide{under \YLnote{\Xpolish{significant noise}{a low-light condition}}, }with a total of $1 \times 10^2$ photons which is used to rescale the $\B{x}$ to simulate a short exposure, given that AGN and Poisson noise behave more differently under low-light conditions. We initialize the masks $\B{M}$ with an $N \times N$ identity matrix and a $\{0,1\}$ Hadamard matrix respectively, and optimize them until the model reports constant losses.}

\Xpolish{The first 6 masks optimized by the ONN are shown in figure \ref{fig:recon_masks}. From it, we can see that the ONN model has very different behaviors under the AGN and the Poisson noise. For the AGN, it tended to open more pixels to increase the light throughput, while it adhered to the RS mode for the Poisson noise. The figure \ref{fig:masks_value_dist} gives a more thorough visualization of the optimized masks by showing their entries' distributions. The x-axis is the values in the masks and the y-axis is the total number of entries in a certain range. This result is consistent with the classification results in the last section, where the RS is mediocre under the AGN but much better under the Poisson noise.}
{Fig. \ref{fig:recon_masks} displays the first 6 optimized masks \YLnote{from both initial matrices} generated by the ONN model \YLnote{\Xpolish{. A notable observation is that the model exhibits distinct behavior patterns under the AGN and Poisson noise}{ under both AGN and Poisson noise}}. Specifically, it tends to open more pixels to enhance light throughput under AGN, but adheres to the RS mode under Poisson noise. Fig. \ref{fig:masks_value_dist} provides a more detailed visualization of the optimized masks by presenting the distribution of their entries. The x-axis represents the values in the masks, while the y-axis shows the total number of entries within a specific range. This observation aligns with the reconstruction results\Xhide{classification results presented in the previous section}, where the RS performed modestly under AGN but considerably better under Poisson noise. \Xpolish{The rationale behind this is that re-projection from a captured basis into a basis of sparsity does not yield the same recovery quality under Poisson noise that is provides for AGN. To obtain a performance benefit over the trivial point scanning method, or RS, it is essential that the data is sparse and is captured in a sparse basis. Since random patterns are not sparse, the best scanning strategy is the point scanning, which matches our results.}{}  Gradients incorporating these two noise models during the training process lead the mask optimization along very different directions. From this example we can see that it is not appropriate to design a coding system under AGN and then apply it to Poisson noise data.}

% Figure environment removed


\Xhide{
% Figure environment removed
}

\iffalse
% Figure environment removed
\fi

\Xhide{
% Figure environment removed
}





\Xhide{% Figure environment removed
}


\Xhide{\bnote{talk about onn first in the last section and then show the reconstruction reuslts before the classifiction}}

\Xhide{
\Xpolish{The different results of the optimal masks suggest the masks optimized under the AGN model may not have the same performance under the Poisson noise. If the measured data is Poisson distributed, then the methods proposed under the AGN assumption are problematic.}
{The results from optimizing the masks indicate that the optimal masks under the AGN model may not perform similarly under Poisson noise. Specifically, methods developed under the AGN assumption may not be effective when the measured data follows a Poisson distribution. \YLnote{For instance, coding optimization based on minimizing the mutual coherence in compressed sensing \cite{mordechay2014matrixRIP} may be defective.} The inherent differences in the underlying noise models of the two distributions can lead to suboptimal performance of AGN-optimized masks in Poisson noise scenarios. Therefore, it is crucial to consider Poisson noise when designing coding schemes and algorithms for imaging applications, especially when working with state-of-the-art sensors.}
}