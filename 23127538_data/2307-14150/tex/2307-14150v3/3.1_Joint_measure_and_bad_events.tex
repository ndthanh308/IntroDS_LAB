Given $\Lambda\subset\Z^d$, a contour associated to a configuration in $\Omega_\Lambda^+$ is not always inside $\Lambda$. To avoid this, we consider the event $\Theta_{\Lambda} = \{ \sigma : \sigma_x \text{ is } +\text{ correct for all }x\in\fint \Lambda \}$ and the conditional measure 
\begin{equation}
    \nu_{\Lambda; \beta, \varepsilon h}^{+}(A) = \mu_{\Lambda; \beta,\varepsilon h}^+(A | \Theta_{\Lambda})
\end{equation}
for any $A\subset \Omega$ measurable. The Markov property guarantees that $\nu_{\Lambda; \beta, \varepsilon h}^{+}$ is also a local Gibbs measure, with the advantage that all contours associated with it are inside $\Lambda$. 
Define the joint measure for $(\sigma, h)$ as
\begin{equation*}
    \mathbb{Q}_{\Lambda; \beta, \varepsilon}^+(\sigma \in A, h\in B) = \int_{B} \nu_{\Lambda;\beta, \varepsilon h}^+(A) d\mathbb{P}(h),
\end{equation*}
for $A\subset\Omega$ measurable and $B\subset \mathbb{R}^{\Lambda}$ borelian. Since $\beta, \varepsilon $ and $\Lambda$ are fixed, we will omit them from the notation. 
This measure $\mathbb{Q}$ has density
\begin{equation*}
    g_{\Lambda; \beta, \varepsilon}^+(\sigma, h) = \prod_{x\in\Lambda}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}h_x^2} \times \nu_{\Lambda;\beta, \varepsilon h}^+(\sigma).
\end{equation*}

The operation $\tau_{\gamma}$ used to remove a contour $\gamma\in\Gamma(\sigma)$ can be written as a particular case of the following one: given $A\subset\Z^d$, take $\tau_A:\mathbb{R}^{\Z^d} \xrightarrow{} \mathbb{R}^{\Z^d}$ as 
\begin{equation}
    (\tau_A(\sigma))_x \coloneqq \begin{cases}
                        -\sigma_x &\text{if }i\in A,\\
                        \sigma_x   &\text{otherwise},
                      \end{cases}
\end{equation}
for every $i\in\Z^d$. Defining $\s(\gamma, \sigma)^\pm\coloneqq \{ x\in \s(\gamma): \sigma_x = \pm 1\}$, the transformation that erases a contour $\gamma$ is $\tau_\gamma(\sigma) = \tau_{\I_-(\gamma)\cup \s^-(\gamma,\sigma)}(\sigma)$.

The main idea used in the proof of phase transition in \cite{Ding2021} is to make the Peierls' argument on the measure $\mathbb{Q}$, and perform in the external field the same flips you do in the configuration when erasing a contour. Formally, in \cite{Ding2021} they compare the density $g_{\Lambda; \beta, \varepsilon}^+(\sigma, h)$ with the density after erasing a contour $\gamma\in\Gamma(\sigma)$, and performing the same flips on the external field. In the short-range case, the spins that need to be flipped to erase a contour are precisely the ones in the interior of it. This is not the case for the long-range case, so we compare $g_{\Lambda; \beta, \varepsilon}^+(\sigma, h)$ with the density after erasing $\gamma$ and flipping the external field only in $\I_-(\gamma)$, getting

\begin{align}\label{Eq: quotient.of.gs}
    \frac{g_{\Lambda; \beta, \varepsilon}^+(\sigma, h)}{g_{\Lambda; \beta, \varepsilon}^+(\tau_{\gamma}(\sigma),\tau_{\I_-(\gamma)}(h))} 
    %
    &= \exp{\{\beta H_{\Lambda, \varepsilon \tau_{\I_-(\gamma)}(h)}^{+}(\tau_{\gamma}(\sigma)) - \beta H_{\Lambda, \varepsilon h}^{+}(\sigma)\}}\frac{Z_{\Lambda; \beta, \varepsilon}^{+}(\tau_{\I_-(\gamma)}(h))}{Z_{\Lambda; \beta, \varepsilon}^{+}(h)}  \nonumber \\ 
    %
    &\leq \exp{\{- \beta c_2 |\gamma| -2\beta\sum_{x\in \Sp^-(\gamma)}\varepsilon h_x\}}\frac{Z_{\Lambda; \beta, \varepsilon}^{+}(\tau_{\I_-(\gamma)}(h))}{Z_{\Lambda; \beta, \varepsilon}^{+}(h)}.
\end{align}
where the constant $c_2$ is the one given by Proposition \ref{Prop: Cost_erasing_contour}. 

Two bad events can occur since for some realizations of the external field, either the sum $2\sum_{i\in \Sp^-(\gamma, \sigma)}\varepsilon h_i$ or the quotient of the partition functions can be bigger than the exponential term. 

\begin{notation}
From now on we abuse the notation and write $\Sp^-({\gamma})$ instead of  $\Sp^-({\gamma},\sigma)$, omitting the configuration $\sigma$.
\end{notation}

Denoting
\begin{equation}
\Delta_A(h) \coloneqq -\frac{1}{\beta}\ln{\frac{Z_{\Lambda; \beta, \varepsilon}^{+}(h)}{Z_{\Lambda; \beta, \varepsilon}^{+}(\tau_{A}(h))}}
\end{equation}
 for every $A\subset \Z^d$, the bad events are
$$ \mathcal{E}_0^c \coloneqq \left\{ \sup_{\sigma\in\Omega(\gamma), \gamma\in\mathcal{C}_0} \frac{2\left|\sum_{i\in \Sp^-(\gamma)}\varepsilon h_i\sigma_i\right|}{c_2|\gamma|} > \frac{1}{4}\right\}$$
and
$$\mathcal{E}_1^c\coloneqq \left\{\sup_{\substack{\gamma\in\mathcal{C}_0}} \frac{|\Delta_{\I_-(\gamma)}(h)|}{c_2|\gamma|} > \frac{1}{4}\right\}.$$
To control the probability of these bad events, we need a concentration result for Gaussian random variables. The following one is due to M. Ledoux and M. Talagrand, and a proof can be found in \cite{Ledoux.Talagrand.91}. The rest of this section is dedicated to bounding the probability of the bad event $\mathcal{E}_0^c$. To do so, we need the following probability result.

\begin{theorem}\label{Theo: Gaussian.concentration}
    Let $f:\mathbb{R}^M \xrightarrow[]{} \mathbb{R}$ be a uniform Lipschitz continuous function with constant $C_{Lip}$, that is, for any $X,Y\in\mathbb{R}^M$, $$|f(X) - f(Y)| \leq C_{Lip} || X - Y ||_2 .$$ 
    
    Then, if $X_1,\dots, X_M$ are i.i.d. Gaussian random variables with variance 1,
    \begin{equation}\label{Eq: Tail.concentration}
        \mathbb{P}\left(|f(X_1,\dots, X_M) - \mathbb{E}(f(X_1, \dots, X_M))|\geq z\right) \leq 2\exp{\left\{\frac{-z^2}{2C_{Lip}^2}\right\}}.
    \end{equation}
\end{theorem}

\begin{remark}\label{Rmk: MVT.Lipschitz}
    If $f$ is differentiable and $||\nabla f(\cdot)||_2$ is bounded, the mean value theorem guarantees that $\sup_{Z\in\mathbb{R}^M}||\nabla f(Z)||_2$ is a uniform Lipschitz constant for $f$. 
\end{remark}
\begin{remark}\label{Rmk: Bernoulli_external_field}
    If $f$ has a compact support and convex level sets, an equation similar to \eqref{Eq: Tail.concentration} holds, with some adjustments on the constants and replacing the mean by the median, see \cite[Theorem 7.1.3]{Bovier.06}. Therefore, our results hold when $h_i$ has a Bernoulli distribution $\mathbb{P}(h_i=+1) =\mathbb{P}(h_i=-1)= \frac{1}{2}$. 
\end{remark}

Given $A\subset\Z^d$, $h_A\coloneqq (h_x)_{x\in A}$ denotes the restriction of the external field to the subset $A$. The next Lemma was proved in \cite{Ding2021} and is a direct consequence of the previous theorem, replacing $f$ by functions of the form $\Delta_A$, with $A\Subset\Z^d$. As the proofs for the short and long-range are the same, we omit it. 

\begin{lemma}\label{Lemma: Concentration.for.Delta.General}
    For any $A, A^\prime \Subset \mathbb{Z}^d$ and $\lambda>0$, we have 
\begin{equation}\label{Eq: Tail.of.Delta_A}
    \mathbb{P}\left(|\Delta_A(h)| \geq \lambda \vert h_{A^c}\right) \leq2e^{\frac{-\lambda^2}{8\varepsilon^2 |A|}},
\end{equation}
and 
\begin{equation}\label{Eq: Tail.of.the.diff.of.Deltas}
     \mathbb{P}(|\Delta_{A}(h) - \Delta_{A^\prime}(h)|>\lambda|h_{{A \cup A^\prime}^c}) \leq  2e^{-\frac{{\lambda^2}}{{8\varepsilon^2|A \Delta A^\prime|}}},
\end{equation}
where $A\Delta A^\prime$ is the symmetric difference. Similarly, 

\begin{equation}\label{Eq: Tail.of.sum.in.A}
    \mathbb{P}\left(\left|\sum_{i\in A}\varepsilon h_i\right| \geq \lambda \vert h_{A^c}\right) \leq 2e^{\frac{-\lambda^2}{2\varepsilon^2 |A|}}.
\end{equation}
\end{lemma}

\begin{remark}\label{Rmk: More.general.h_x}
    This lemma holds whenever $h=(h_x)_{x\in\Z^d}$ satisfy equation \eqref{Eq: Tail.concentration}.As a consequence, our results can be stated for more general external fields. 
\end{remark}

The first main application of Lemma \ref{Eq: Tail.of.sum.in.A} is to control the probability of $\mathcal{E}_0^c$.
\begin{proposition}\label{Prop: Bound.bad.event.0} 
    There exists $C_0\coloneqq C_0(\alpha, d)$ such that $\mathbb{P}(\mathcal{E}_0^c)\leq e^{-{C_0}/{\varepsilon^2}}$.

\end{proposition}
\begin{proof}
This is a direct consequence of Lemma \ref{Lemma: Concentration.for.Delta.General} and Corollary \ref{Cor: Bound_on_C_0_n}, which guarantees that ${|\mathcal{C}_0(n)| \leq e^{c_1 n}}$, thus
\begin{align}\label{Eq: Bound.bad.event.0.eq.1}
    \mathbb{P}(\mathcal{E}_0^c) &\leq \sum_{n\geq 1}\mathbb{P}\left(\sup_{\sigma\in\Omega(\gamma), \gamma\in\mathcal{C}_0(n)} 2\varepsilon\left|\sum_{i\in \Sp^-(\gamma)}h_i\right| > \frac{c_2}{4}n\right) \nonumber \\
    %
    &\leq \sum_{n\geq 1}\sum_{\gamma\in \mathcal{C}_0(n)}\left| \{\sigma \in \Omega(\gamma) \}\right| \sup_{\substack{\gamma\in \mathcal{C}_0(n) \\ \sigma \in \Omega(\gamma)}}\mathbb{P}\left(\varepsilon\left|\sum_{i\in \Sp^-(\gamma)}h_i\right| > \frac{c_2}{8}n\right) \nonumber \\
    %
    &\leq \sum_{n\geq 1}|\mathcal{C}_0(n)|2^n\sup_{\substack{\gamma\in \mathcal{C}_0(n) \\ \sigma \in \Omega(\gamma)}}\mathbb{P}\left(\varepsilon\left|\sum_{i\in \Sp^-(\gamma)}h_i\right| > \frac{c_2}{8}n\right) \nonumber \\
    %
    &\leq \sum_{n\geq 1} e^{c_1 n}2^n\sup_{\substack{\gamma\in \mathcal{C}_0(n) \\ \sigma \in \Omega(\gamma)}}\mathbb{P}\left(\varepsilon\left|\sum_{i\in \Sp^-(\gamma)}h_i\right| > \frac{c_2}{8}n\right),
\end{align}
where in the third inequality we used that the number of configurations $\sigma$ compatible with a contour $\gamma$ is at most $2^{|\gamma|}$. Lemma \ref{Lemma: Concentration.for.Delta.General} yields  
\begin{equation}\label{Eq: Bound.bad.event.0.eq.2}
    \mathbb{P}\left(\varepsilon\left|\sum_{i\in \Sp^-(\gamma)}h_i\right| > \frac{c_2}{8}n\right) \leq 2 \exp{\frac{-c_2^2n^2}{64\varepsilon^2|\Sp^-(\gamma)|}} \leq 
    2\exp{\frac{-c_2^2n}{64\varepsilon^2}}. 
\end{equation}
In the last equation, we just used that $|\Sp^-(\gamma)|\leq |\gamma|$. Equation \eqref{Eq: Bound.bad.event.0.eq.1} together with \eqref{Eq: Bound.bad.event.0.eq.2} yields
\begin{align*}
     \mathbb{P}(\mathcal{E}_0^c) &\leq \sum_{n\geq 1} e^{(c_1+\ln{2})n - \frac{-c_2^2}{64\varepsilon^2}n + \ln 2} \leq \sum_{n\geq 1} e^{\frac{-2C_0}{\varepsilon^2}n},
\end{align*}
what concludes the proof for an appropriate choice of $C_0$ and $\varepsilon$ small enough.
\end{proof}

Controlling the probability of $\mathcal{E}_1^c$ is a much harder task. To do so, we use a multiscale analysis method presented in \cite{FFS84} together with some ideas of entropy bounds used in \cite[Section 3.2]{Affonso.2021}, where it is proved that the number of contours containing $0$ in its volume grows at most exponentially with the size of the contour. As pointed out by \cite{Ding2021}, the proof presented in \cite{FFS84}, despite being self-contained, is a non-trivial application of Dudley's entropy bound. Here we adapt the proof presented in \cite{FFS84} using this entropy bound. 