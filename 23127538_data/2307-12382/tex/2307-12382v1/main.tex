% \documentclass[journal]{vgtc}                     % final (journal style)
% \documentclass[journal,hideappendix]{vgtc}        % final (journal style) without appendices
% \documentclass[review,journal]{vgtc}              % review (journal style)
% \documentclass[review,journal,hideappendix]{vgtc} % review (journal style)
%\documentclass[widereview]{vgtc}                  % wide-spaced review
\documentclass[preprint,journal]{vgtc}            % preprint (journal style)


%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication in an open access repository,
%% and the final version doesn't use a specific qualifier.

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please use one of the ``review'' options and replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{1197}

%% In preprint mode you may define your own headline. If not, the default IEEE copyright message will appear in preprint mode.
\preprinttext{To appear in IEEE Transactions on Visualization and Computer Graphics.}

%% In preprint mode, this adds a link to the version of the paper on IEEEXplore
%% Uncomment this line when you produce a preprint version of the article 
%% after the article receives a DOI for the paper from IEEE
\ieeedoi{xx.xxxx/TVCG.201x.xxxxxxx}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% please declare the paper type of your paper to help reviewers, only shown in review mode
%% choices:
%% * algorithm/technique
%% * application/design study
%% * evaluation
%% * system
%% * theory/model
\vgtcpapertype{Analytics \& Decisions}

%% Paper title.
\title{\name{}: Visualizing and Understanding Commonsense Reasoning Capabilities of Natural Language Models}

%% Author ORCID IDs should be specified using \authororcid like below inside
%% of the \author command. ORCID IDs can be registered at https://orcid.org/.
%% Include only the 16-digit dashed ID.
\author{%
  Xingbo Wang,
  Renfei Huang, 
  Zhihua Jin,
  Tianqing Fang,
  and Huamin Qu
}

\authorfooter{
  %% insert punctuation at end of each item
  \item
  	Xingbo Wang is with Weill Cornell Medical College, Cornell University. This work was done at the Hong Kong University of Science and Technology.
  	E-mail: xingbo.wang@\{connect.ust.hk, med.cornell.edu\}.
  \item
  	Renfei Huang, Zhihua Jin, Tianqing Fang, and Huamin Qu are with the Hong Kong University of Science and Technology. E-mail: \{rhuangan, zjinak, tfangaa, huamin\}@ust.hk.

}

%% Abstract section.
\abstract{%
Recently, large pretrained language models have achieved compelling performance on commonsense benchmarks. 
% Motivation of explainability
Nevertheless, it is unclear what commonsense knowledge the models learn and whether they solely exploit spurious patterns.
% Limitations in XAI techniques
Feature attributions are popular explainability techniques that identify
% methods are popular for explaining models by identifying 
important input concepts for model outputs. However, commonsense knowledge tends to be implicit and rarely explicitly presented in inputs. These methods cannot infer models' implicit reasoning over mentioned concepts.
% Therefore, these methods cannot help infer how models perform implicit reasoning on mentioned concepts.
% since commonsense is rarely stated in the input, these methods cannot help infer how models build latent connections between mentioned concepts.
We present \name{}, a visual explanatory system that utilizes external commonsense knowledge bases to contextualize model behavior 
% on different concepts and their underlying relations 
for commonsense question-answering.
Specifically, we extract relevant commonsense knowledge in inputs as references to align model behavior with human knowledge.
Our system features multi-level visualization 
and interactive model probing and editing for different concepts and their underlying relations. 
Through a user study,
we show that \name{} helps NLP experts conduct a systematic and scalable visual analysis of models' relational reasoning over concepts in different situations.
}

%% Keywords that describe your work. Will show as 'Index Terms' in journal
%% please capitalize first letter and insert punctuation after last keyword
\keywords{Commonsense reasoning, visual analytics, XAI, natural language processing}

%% A teaser figure can be included as follows

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  OLD version teaser %%  
% \teaser{
%   % Figure removed
%   \caption{
%   \renfeivis{The user interface of \name{} consists of three views. The \gv{} (A) summarizes the model performance by the projection plots of question stems and target concepts and the relations between them. The \sv{} (B) summarizes the context alignment between model behavior and \cpn knowledge over different subsets. The \iv{} (C) provides the statistics and detailed local explanations of instances selected using \gv{} or \sv{}. The selected instance is reflected in the \gv{} as larger points. It also enables users to probe the model behavior by editing the questions directly in the interface. }
%     }
%   \label{fig:teaser}
% }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\teaser{
  % Figure removed
  \vspace{-3mm}
  \caption{\vis{Since commonsense knowledge is not explicitly stated, it is challenging to conduct a scalable analysis of what commonsense knowledge NLP models do (not) learn. We employ a knowledge graph to derive implicit commonsense in the model input as context information. Then, we use it to align model behavior with human reasoning through multi-level interactive visualizations. Thereafter, users can understand, diagnose, and edit specific knowledge areas where models do not perform well.}}
  \label{fig:workflow_teaser}
}

%% Uncomment below to disable the manuscript note
%\renewcommand{\manuscriptnotetxt}{}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
%\nocopyrightspace


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% LOAD PACKAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Tell graphicx where to find files for figures when calling \includegraphics.
%% Note that due to the \DeclareGraphicsExtensions{} call it is no longer necessary
%% to provide the the path and extension of a graphics file:
%% % Figure removed is completely sufficient.
\graphicspath{{figs/}{figures/}{pictures/}{images/}{./}} % where to search for the images

%% Only used in the template examples. You can remove these lines.
\usepackage{tabu}                      % only used for the table example
\usepackage{booktabs}                  % only used for the table example
\usepackage{lipsum}                    % used to generate placeholder text
\usepackage{mwe}                       % used to generate placeholder figures

%%%%%%%%% Watermark %%%%%%%%%
% \usepackage{background}
% \backgroundsetup{scale=4.4, opacity=1, contents={Submitted Draft for VIS'23}}

%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.
\usepackage{mathptmx}                  % use matching math font
% \usepackage{enumitem}
\usepackage{paralist}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
% \usepackage[dvipsnames]{xcolor}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% command definition %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\xingbo}[1]{{\color{black} #1}}
\newcommand{\renfei}[1]{{\color{black} #1}}
\newcommand{\renfeivis}[1]{{\color{black} #1}}
\newcommand{\rev}[1]{{\color{black} #1}}
\newcommand{\vis}[1]{{\color{black} #1}}
\newcommand{\todo}[1]{{\color{black} #1}}
\newcommand{\referappendix}[1]{{\color{black} #1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% conditional acceptance revision
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\revv}[1]{{\color{black} #1}}
\newcommand{\revvv}[1]{{\color{black} #1}}

% global commands for the writing
\newcommand{\ie}{i.e.}
\newcommand{\eg}{e.g.}
\newcommand{\esp}{esp.}
\newcommand{\etal}{et al.}
\newcommand{\hl}[1]{\emph{``{#1}''}}
\newcommand{\imp}[1]{\textbf{\textit{{#1}}}}
\newcommand{\systemname}{{CommonsenseVIS}}
\newcommand{\name}{{\textit{CommonsenseVIS}}}
% system views
\newcommand{\gv}{Global View}
\newcommand{\sv}{Subset View}
\newcommand{\iv}{Instance View}
\newcommand{\cpn}{ConceptNet}

\def\subsectionautorefname{Section}
\def\subsubsectionautorefname{Section}
\def\appendixautorefname{Suppl.}

% background set up


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\firstsection{Introduction}
\maketitle
\input{sections/introduction.tex}
\input{sections/related_work}
\input{sections/design_requirements}
\input{sections/system_methods}
\input{sections/user_interface}
\input{sections/case_study}
\input{sections/user_study}
\input{sections/discussion}
\input{sections/conclusion}



%% if specified like this the section will be ommitted in review mode
\acknowledgments{%
The authors wish to thank anonymous reviewers for their valuable feedback. 
This research was supported in part by Hong Kong Theme-based Research Scheme grant T41-709/17N and a grant from MSRA. 
}


\bibliographystyle{abbrv-doi-hyperref}
%\bibliographystyle{abbrv-doi-hyperref-narrow}
%\bibliographystyle{abbrv-doi}
%\bibliographystyle{abbrv-doi-narrow}

\bibliography{main}


%% ^^^^^   FOR IEEE VIS, EVERYTHING HERE MAY BE INCLUDED IN THE    ^^^^^ %%
%% 2-PAGE ALLOTMENT FOR REFERENCES, FIGURE CREDITS, AND ACKNOWLEDGEMENTS %%

\newpage

\appendix % You can use the `hideappendix` class option to skip everything after \appendix
\input{sections/appendix}
\end{document}

