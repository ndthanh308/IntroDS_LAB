\section{Model editing implementation}\label{sec.model_editing}
Here, we introduce the details of technical implementation and evaluation of editor networks for model editing. We adopt the MEND network~\cite{mitchell2022fast} for model editing.

% \todo{add more...}

\subsection{Editor networks}

MEND leverages a collection of small auxiliary editing networks that use a single desired input-output pair to make fast, local edits to pretrained models. 
Specifically, it uses the low-rank structure of fine-tuning gradients to enable scalable and efficient editing of very large pretrained language models on specified layers of transformers.
% Denote the neural network as $f_\theta$ where $\theta$ represents the set of parameters.
% The edit training set (the dataset storing the entries to be edited) $D_{tr}$ is used to acquire the model editor networks $g_l$ to edit model weights given edit data pair $(x_e, y_e)$ at test time.
MEND uses the fact that gradients for MLPs are rank-1 matrix and apply the theory to Transformers by summing elements over sequence indices. 
The model editing gradient update function is derived as:

$$\tilde{\nabla}_{W_\ell} = \sum_{i=1}^B\tilde\delta_{\ell + 1}^{i}{\tilde u_\ell^{i\,\top}}.$$

Where $\tilde u_\ell^i$ and $\tilde\delta_{\ell+1}^i$ are \textit{pseudo-activations}  and \textit{pseudo-delta} by taking the sequence sum of the gradient of the loss for batch $i$ with respect to the pre-activations at layer $l$ + 1, and the sequence sum of the inputs to layer $l$ for batch element $i$. $B$ is the number of total batches.
$\tilde{\nabla}_{W_\ell}$ is the gradient update to be applied on the MLP layers of transformers.
For more details, please refer to the original paper~\cite{mitchell2022fast}.


% \subsection{Editing datasets}

\subsection{Model editing training}

Practically, for the T5-based QA model that we use \footnote{\url{https://github.com/allenai/unifiedqa}}, we only edit the MLP layers of the last two encoder and decoder blocks of the transformer.
We follow the official implementation of MEND\footnote{\url{https://github.com/eric-mitchell/mend/}} to build our model and conduct the experiments.

To train editor networks that can edit our T5 model on CSQA, we need to collect editing targets, equivalence examples, and locality examples. Specifically, editing targets contain a question and a target choice, where the question comes from train set of CSQA dataset, and the target choice does not necessarily be the ground truths. We randomly sample one choice from five alternatives in the original QA instance as the editing target.
For equivalence examples generation, we use data augmentation techniques to perturbate the original instances to get meaning-preserving augmentations as much as possible.
We use back-translation implemented in \texttt{nlpaug}\footnote{\url{https://github.com/makcedward/nlpaug}} to translate the original sentences to German and then back to English using the \texttt{facebook/wmt19-en-de} machine translation checkpoint. We also adopt Easy Data Augmentation (EDA)~\cite{DBLP:conf/emnlp/WeiZ19} to do synonym replacement and random insert/delete/replace on the original sentences to ensure the robustness of the model training.
For locality examples, we independently sample negative examples different from editing targets from the same original dataset.

Once the editor networks are trained, they can be applied to conduct posthoc editing on the original model at inference time.

\section{System interaction designs}
\label{sys.interactions}
\name{} offers various interactions to support multi-level analysis of model behavior with details on demand.

% Besides the interface components introduced earlier, \name{} supports a rich set of interactions that facilitate multi-level analysis of model behavior with details on demand.

\textbf{Lasso and pan-and-zoom}. 
In the \gv{}, users can lasso a group of data instances in the scatter plots to examine the details in the \sv{} and \iv{}. 
And users can use pan-and-zoom in the scatter plots to navigate local clusters more easily. 
% the scatter plots provide users with a pan-and-zoom to navigate the local clusters easier. Users can reset the plots to the default scale by clicking the reset button. 

% % Interactions
% The scatter plot supports users with zoom and pan to navigate the local area easier. When the mouse hovers over the points, the information of each question and its corresponding point in the other scatter plot is displayed at the same time. 
% The user can lasso the data points in scatter plots to perform further interactions with the lassoed data points in the subset view and instance view. 
% When hovering over the relations rectangles, detailed information about the relation is shown. The users can click on each rectangle to filter questions with certain QC-TC relations in scatter plots. The data is also updated into the subset view and the instance view. 


\textbf{Hovering and clicking}. 
To make the interface cleaner and less overwhelming, we hide lots of details, and users can hover or click to see the details on demand. For example, in the \gv{}, users can hover over
the dots in the scatter plots and the relation bars in the middle to see the pairs of question stems and target concepts and relation accuracy, respectively.
When hovering the cluster glyphs in the \sv{}, detailed concepts and statistics of the clusters, together with their connections with other clusters, will be displayed. 
In the \iv{}, hovering over the charts will display the detailed numbers. Also, users can hover over the answer choices to query their relations with the question stem concepts.

Moreover, users can filter or highlight the information by clicking.
For example, relation bars in the \gv{}, and stacked bars in the \sv{} can be clicked to filter data instances.
In addition, users can navigate through instances by clicking the pagination buttons. Meanwhile, its corresponding dots and clusters will be highlighted in the \gv{} and \sv, respectively.


% Instance view:
% When hovering on the statistics information bars in the Instance View, detailed information is shown. 
% The users can click the accuracy and average QC hit bars to filter and display the questions within that group. 

% \textbf{Linked highlighting}

% \textbf{In-situ Instance Editting}
% The users can edit the question stem and choices and rerun the model on edited content to test their hypotheses. 
% When hovering on each choice, the concepts in question stem that is within one-hop distance is displayed with the relations between them. This supports users to quickly identifying which words in question stem may strongly influence the model result. 

\section{Evaluation of Commonsense Knowledge Coverage of \cpn{}}
We conducted an evaluation using a random sample of 100 examples drawn from the CSQA validation set\footnote{Data samples fo evaluation are available at \url{https://bit.ly/3PCGbze}}.
We have invited an NLP expert (\imp{E14}, not our co-author) to evaluate the relational paths extracted by our algorithm based on ConceptNet. 
For each QA instance, the expert examined the QA instance and the extracted relational paths built by retrieved concept-relation triplets from ConceptNet.
Then, he decided whether the paths could accurately cover the necessary commonsense knowledge to answer the question. 
Finally, we calculated and reported the proportion of instances for which the necessary commonsense knowledge is covered by the extracted ConceptNet knowledge. 

The results show that the retrieved ConceptNet knowledge can cover the commonsense knowledge in 91 out of 100 instances. 
It further helps validate the use of \cpn{} for model contextualization on the CSQA dataset. 
However, although CSQA is built upon \cpn{}, it still cannot cover some commonsense knowledge in the data.
For example, for the question \hl{The potato might be the official vegetable of what? (correct answer: Maryland)}, retrieved concept-relation triplets from \cpn{} fail to build a connection between ``potato'' and ``Maryland'' or ``official vegetable''.
In addition, for the question \hl{Where has the newest baseball stadium? (correct answer: Phoenix)}, although retrieved concept-relation triplets can associate ``baseball stadium`` with different locations using \texttt{AtLocation} realation. However, it lacks the knowledge to determine which city has the ``newest'' stadium.


\section{Additional Cases of Using \name{}}
\label{app.case_studies}
\subsection{Relation of \texttt{atlocation} regarding room and office is relatively well-learned}\label{app.case1}

% Figure environment removed

\textbf{Global Summary}
(\imp{R1, R2}) 
% overview of the relation
After loading the system and dataset, the expert \imp{E4} first referred to the \gv{} to explore the model performance regarding different relations. 
After hovering over the green bars between the scatter plots, he was able to quickly observe that although there is an imbalanced relation distribution (as indicated by varied bar height), accuracies for most relations are about 0.70 (\renfei{\autoref{fig:case1 full}A}). It indicates that the model may have learned a fair amount of relations between different concepts.
Then, \imp{E4} felt curious about what relations are and under what contexts the model learns well. 
He started with the relation \texttt{atlocation} with the highest green bar at the top. After clicking the bar, he selected the ``\textit{Correctness X Tranformed}'' projection mode and ``\textit{Correctness}'' coloring scheme to explore the distribution of the correctly-answered instances of \texttt{atlocation} in the question and answer (target concept) scatter plots (\renfei{\autoref{fig:case1 full}A}). 
He noticed that there is a large cluster with green dots in the answer scatter plot. He wondered whether the models have really learned \texttt{atlocation} between question and target concepts in these instances. Therefore, he switched to ``\textit{Relation X Tranformed}'' projection mode to see how the relation is learned by examining the correspondence between question stems and target concepts after transformation (\renfei{\autoref{fig:case1 full}A}). And he discovered two well-formed and well-aligned clusters in the two scatter plots, which provides support for a good learning of \texttt{atlocation} relation.

\textbf{Subset Exploration}
(\imp{R1, R2, R3}) 
% subset view.
To further explore the contexts of selected instances, \imp{E4} looked at the question stem cluster glyphs in the \sv{} (\renfei{\autoref{fig:case1 full}B}), where \xingbo{the green and blue bars} nearly occupy the two stacked bars at the top. It indicates a high model accuracy and overlap between the model concepts and ConceptNet concepts.
Moreover, he observed the yellow rectangles on the left of question stem clusters are much shorter than the dark blue ones (\renfei{\autoref{fig:case1 full}B}), confirming that very few ConceptNet concepts are not covered by the model. 
He then hovered over the first cluster glyph to see the details of those concepts, where words like ``man'' and ``want'' appear. He thought that these concepts, not important to model predictions, might not affect the reasoning about \texttt{atlocation}.
Therefore, he hypothesized that the question contexts are properly considered by the model.
% clicked the first cluster glyph with the most instances to verify his hypothesis.
And he clicked this glyph to explore detailed instances and their explanations in the \iv{} to verify his hypothesis.
% Then, the \iv{} displayed the model statistics at the top. 
By scanning the top frequent model concepts in the histogram (\renfei{\autoref{fig:case1 full}C}) (\eg, ``where'', ``what'', ``store'', ``office'', ``room'', ``building''), he reasoned that many of these instances of \texttt{atlocation} are ``what'', ``where'' questions and associate with ``office'' and ``room''.

% Figure environment removed

\textbf{Instance Exploration and Searching}
(\imp{R1, R4}) 
Finally, through exploration of individual questions in the \iv{}, \imp{E4} found that the model truly captures important words for answering commonsense questions.
For example, in \renfei{\autoref{fig:case1 instances}}, SHAP values show ``office'' and ``put'' as important contexts for where the ``check'' can be located, which is ``desk drawer''. 
Another example in \renfei{\autoref{fig:case1 instances}} shows that the model properly considered contexts like ``room'' and ``contemplation'' for where the ``bookcases'' should be located in a ``study room'', which aligns with human knowledge. 
Then, \imp{E4} reasoned that the model has a good sense of \texttt{atlocation} in the situations of ``office'' and ``room''. 
And he lassoed all the instances of \texttt{atlocation} in the \gv{} and typed ``office'' and ``room'' to search relevant instances in the \iv{}, where the model achieves 90.00\% and 88.89\% accuracy, respectively (much higher than the overall 71.00\% accuracy). 
\imp{E4} was convinced that the model has learned the relation \texttt{atlocation} in the context of ``office'' and ``room'' properly. 


% % Figure environment removed

% % Figure environment removed

% Figure environment removed

\section{Additional User Study Results}
\label{app.user_study}

\subsection{User study questionnaire}
\label{app.user_study_question}
The user study questionnaire is presented in \autoref{tab:questionnaire-table}.
\begin{table}[!htb]
\caption{The first section of our questionnaire is designed to collect feedback on the system's effectiveness in evaluating the model's commonsense abilities (Q1-Q4). The second section is designed to evaluate the usefulness and usability of \gv{} (Q5-Q7), \sv{} (Q8-Q10) and \iv{} (Q11-Q13). The last section is designed to evaluate personal opinions of our system (Q14-Q17). The original sentences without the words in brackets are the positive statements at the right end of the scale points, while the sentences with words in the brackets are the negative statements at the left end. }
\label{tab:questionnaire-table}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{p{0.5cm}|p{0.85\linewidth}}

\toprule
Q1 & The system can (cannot) help me identify the target commonsense knowledge in data instances. \\ 
Q2 & The system does (does not) contextualize model performance regarding different concepts and their underlying relations. \\ 
Q3 & The system can (cannot) help me infer the model’s relational reasoning over different concepts. \\ 
Q4 & I am (not) confident in my findings about the model’s commonsense reasoning abilities. \\ \hline
Q5 & The Global View can (cannot) help me relate model performance to different concepts and relations. \\ 
Q6 & The Global View can (cannot) help me infer how the relations are learned by models. \\ 
Q7 & The Global View is easy (difficult) to understand. \\ \hline
Q8 & The Subset View can (cannot) help me align model behavior with ConceptNet knowledge. \\ 
Q9 & The Subset View can (cannot) help me summarize model behavior on different groups of question concepts/question stems/target concepts. \\ 
Q10 & The Subset View is easy (difficult) to understand. \\ \hline
Q11 & The Instance View can (cannot) help me diagnose if the model uses proper information for reasoning. \\
Q12 & The Instance View can (cannot) help me infer if a relation between question concepts and target concepts is learned or not. \\
Q13 & The Instance View is easy (difficult) to understand. \\ \hline
Q14 & It is easy (difficult) to learn the system. \\
Q15 & It is easy (difficult) to use the system. \\
Q16 & I will (will not) use it in the future for understanding and diagnosing language models. \\
Q17 & I will (will not) recommend this system to other colleagues for understanding and diagnosing language models. \\ \bottomrule
\end{tabular}
}
\end{table}

\subsection{User ratings and feedback}
\label{app.user_rating_feedback}
% \textbf{Visual designs and interactions}
\subsubsection{Visual designs and interactions}
% overall usability and visualization, interaction designs
As shown in \autoref{fig:system-user-scores},  participants generally agreed that our system is easy to use ($Mean_{Q15} = 4.20$, $SD_{Q15} = 1.03$) while it required some efforts for learning ($Mean_{Q14} = 3.80$, $SD_{Q14} = 0.79$).
They were willing to use ($Mean_{Q16} = 4.50$, $SD_{Q16} = 0.85$) and recommend our system ($Mean_{Q17} = 4.70$, $SD_{Q17} = 0.67$) for understanding and diagnosing commonsense reasoning capabilities of language models.
The most intuitive view of \name{} is the \iv{}, then the \gv{}. And the \sv{} was thought to be the most difficult to understand. 
We summarize participants' feedback (as shown in \autoref{fig:three-view-user-scores}) on our visual designs as follows.

For the \gv{}, participants found it quite useful for finding relations/concepts with large/small prediction errors ($Mean_{Q5} = 4.30$, $SD_{Q5} = 0.95$). \hl{I can quickly observe the correctness distribution among instances} (\imp{E6, E8, E12}) and \hl{narrow down to specific cluster of instances} (\imp{E7, E9}). 
And the question and answer scatter plots helped them infer if the relations are generally learned well ($Mean_{Q6} = 4.40$, $SD_{Q6} = 1.26$). 
Furthermore, \imp{E6} and \imp{E8} added that the correctness coloring of the dots (\ie, model accuracy) is really helpful when they analyze relation learning and were not sure about the quality of the alignment between questions and answers. 
However, some participants reported that sometimes it is a bit hard to visually align and match clusters of dots in the question and answer scatter plots due to the embedding rotation effect (\imp{E10}) and scarcity of instances (\imp{E11}).

For the \sv{}, participants thought it was a bit complex ($Mean_{10} = 3.20$, $SD_{Q10} = 0.63$). And after they got familiar with it, they considered it helpful to compare the model concepts and ConceptNet concepts ($Mean_{Q8} = 4.20$, $SD_{Q8} = 0.63$) and summarize model behavior on different question concepts/question stems/target concepts ($Mean_{Q9} = 4.50$, $SD_{Q9} = 0.53$).
For example, \imp{E9} commented \hl{The hit ratio and top missed concepts are very useful in understanding what types of concepts the model focuses on.}
Some participants felt \sv{} could be a bit too informative sometimes. 
\imp{E10} suggested, \hl{Choosing the number of clusters and viewing the concepts and linkers are a bit messy and too informative, can we simplify the design and only the most impactful one?}

The \iv{} was the most favored by participants for its intuitiveness and helpfulness in diagnosing if the model uses proper information ($Mean_{Q11} = 4.80$, $SD_{Q11} = 0.42$) and learns relations between question concepts and target concepts for reasoning ($Mean_{Q12} = 4.50$, $SD_{Q12} = 0.97$). 
Participants generally thought that SHAP explanations and model probing complement each other to deepen the model understanding.
\hl{I tested many examples and found that the explanation results were very satisfactory. And the instance probing also helped me to do some further investigation and testing on model behavior.} (\imp{E7}).
\hl{The model probing is a great tool to change the input to the model and check the behavioral change of the model. This can be used to do some causal analysis of concepts.} (\imp{E8}).
% \hl{For me, I prefer the instance view and model probing part. I think it’s important to provide the interactive tool with models so that the users can try possible solutions directly.} 

% Participants also commended the smoothness of interactions for unifying multi-level explanations in different views.
% Particularly, lasso selection, hovering, and clicking for details were liked for choosing and exploring the instances of interest.
% Also, \imp{E6} mentioned \hl{when browsing through instances here (in the \iv{}), the \gv{} highlighting the corresponding point is also very useful for knowing model performance on neighboring points (instances).}

% \hl{Hovering and clicking shows useful information in all sections. Hovering over each data point in global view shows the question and answer of each data point. We can select specific portion of the distribution to focus on this part only.}  
% -\hl{The model probing is a great tool to change the input to the model and check the behavioral change of the model. This can be used to do some causal analysis of concepts.}

% \hl{It's totally fine. I can interact with the system smoothly.}

% \hl{ The circling interaction in global view is cool. }

% \hl{If there is anything to improve, I think one part confuses me: in the global view, after selecting a ‘relation’ block, it is kind of difficult to find out how to re-select all the relations.}

% Figure environment removed

% Figure environment removed

