\subsection{User Interface of \systemname}
\label{sec.user_interface}

% Figure environment removed 


The user interface (\vis{\autoref{fig:teaser}}) enables a multi-level exploration of model behavior following an \textit{overview-to-detail} flow, contextualized by \cpn{}. 
\revv{The exploration process starts with the \gv{}, which summarizes model performance on different concepts and relations and assesses overall relation learning. 
Users then can pinpoint error cases, and the system summarizes the contexts of alignment between model behavior and \cpn{} on different subsets.
Upon selecting instance subsets in the \gv{} or \sv{}, \iv{} shows statistics and visual explanations for these instances. It facilitates interactive model probing for comprehensive understanding and enables users to bookmark particular instances for targeted model refinement.}
% The  \gv{} summarizes the model performance regarding QSs, TCs, and QC-TC relations extracted from \cpn{}. The Subset View further visualizes the alignment between model behavior and \cpn{} knowledge regarding different groups of QCs, QSs, and TCs (\imp{R1, R2, R3}). 
% Users can select a group of instances in the \gv{} or \sv{}, and \iv{} displays the statistics and local explanations. 
% It also allows users to interactively probe and edit the model (\imp{R1, R4}). 
% All views use a consistent color scheme, with green indicating accuracy, red indicating error, and categorical color palettes showing various relations and statistics.
The system uses red to encode the model error, green to indicate accuracy, categorical colors to encode different relations and statistics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%% OLD %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
% According to the generated model explanations based on ConceptNet, 
\rev{After contextualizing model behavior using an external knowledge graph,}
the user interface of \name{} (\autoref{fig:teaser}) enables a multi-level exploration of model behavior following an \textit{overview-to-detail} flow.
% regarding different concepts and their implicit relations for commonsense reasoning (\imp{R2, R3}), as well as interactive probing of models (\imp{R4}).
After users load the QA dataset and the language model, 
the \gv{} summarizes the model performance regarding QSs, TCs, and QC-TC relations extracted from \cpn{}.
% regarding different concepts and commensense relations in QA instances.
% on QSs, TCs, and the latent relations in ConceptNet .
% Then, they can examine the \sv{} to explore the connections between 
The \sv{} further visualizes the alignment between model behavior and ConceptNet knowledge on different groups of QCs, QSs, and TCs
% concepts in instances.
% groups of QCs, QSs, and TCs 
(\imp{R1, R2, R3}).
After selecting a group of instances in the \gv{} and/or \sv{}, \iv{} displays the statistics and local explanations. In addition, it allows users to modify the input and output, and interact with the model (\imp{R1, R4}).

All the views adopt the same color scheme where green encodes accuracy, red denotes error, and categorical color palettes show varied types of relations and statistics.
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% OLD %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Figure environment removed

\subsubsection{\gv{}}\label{subsec.global_view}
\rev{Initially, users can refer to the \gv{} to gain an overview of the model performance regarding different concepts and commonsense relations contained in QA data (\imp{R1, R2}).}
Specifically, the \gv{} (\vis{\autoref{fig:teaser}A}) adopts different projection strategies to group question stems and target concepts (\ie, answers) and visualize them as two separate scatter plots. 
% It further relates them to model performance and surfaces the model learning of QS-TC relation types (\imp{R1, R2}). 
% We use two scatter plots to visualize the projection of QSs and TCs. 
\revv{For projection, we choose UMAP~\cite{mcinnes2018umap} with cosine similarity measures to cluster model embeddings for question stems and target concepts}
% of QSs and TCs 
because of its good processing speed and preservation of embeddings' global structure. 
\revv{After projection, similar question stems (\ie, similar contextualizations of question concepts) or target concepts are close to each other.}
% Moreover, users can select 
% Then, users can switch the dot color schemes (``Correctness'' or ``Relation'') at the header to explore the distributions of prediction errors or QC-TC relations in the scatter plots.
\revv{To further analyze error and relation distributions among these instances, users can adjust the dot color schemes at the header. When the ``Correctness'' scheme is selected, dots are colored in red and green to show distributions of incorrect and correct instances. Alternatively, selecting the ``Relation'' scheme applies categorical colors to the dots, highlighting instances with different relations.}
Meanwhile, users can change projection mode into ``Correctness'' or ``Relation'' at the header to accentuate the differences between instances with high and low errors or instances with varied relations.
% QC-TC relations.
To achieve this, we utilize instance correctness and relations between question concepts and target concepts as additional labels for UMAP to perform supervised dimension reduction for clear cluster separation in the scatter plots.
\revv{To mitigate the overplotting in the scatter plots, the system supports semantic zooming that allows users to navigate specific areas of interest (\eg, error instances) within dense data points.
% within dense data points. 
Moreover, users can filter out the instances with particular relations by clicking the rectangles between the two scatter plots, where each rectangle encodes relation frequency and accuracy.}
% different \rev{instances}
% clusters of instances 
% in the context of prediction errors and QC-TC relations.
% Moreover, users can look at the rectangles between the two scatter plots to explore model accuracies \revv{(between 0 and 1)} for various 
% QC-TC  relations\footnote{\rev{Multiple relations can exist between the question concepts and target concepts in an instance. And each will be counted in the frequency calculation.}}.
% Each rectangle corresponds to a relationship. 
\revv{For each rectangle, we use green (instead of categorical colors) to emphasize model accuracy for that relation, where the width of the green bar denotes accuracy, and its height corresponds to relation frequency.}
The system sorts these rectangles by relation frequency, allowing users to prioritize model performance exploration of more prevalent relations.
% Within each rectangle, the height of green bars correlates with relation frequency\footnote{\rev{Multiple relations can exist between the question concepts and target concepts in an instance. And each will be counted in the frequency calculation.}} and its width represents accuracy. 
% We use green color to encode rectangles (\ie, relations) instead of categorical colors because we want to emphasize the model accuracy information.
% \rev{These rectangles are sorted by relation frequency such that users can prioritize exploring model performance on prevalent relations.}

\rev{Besides, the \gv{} assesses how the model regards latent relations between questions and answers (\imp{R3}).} In the ``Relation X Transformed'' projection mode (in \autoref{fig:teaser}), the \gv{} separates instances with different relations in the scatter plots and supports the alignment and comparison of transformed question stems with target concepts.
% (details are in \autoref{subsec.align_model}).
If there is a good correspondence between transformed clusters of question stems and target concepts in the scatter plots, then the relations between question and target concepts could possibly be learned.
\rev{Finally, users may lasso a group of instances or click specific relation bars to inspect the context summary in the \sv{}.}
% Besides, to enable a multi-faceted analysis of clusters of data instances, we use relation types or correctness as labels to perform supervised dimension reduction for clear cluster separation in the scatter plots. Users can switch between projection and transformation strategies at the header to explore model behavior from different perspectives. 

% To summarize model performance regarding QSs and TCs (\imp{R2}), we first apply UMAP to project their high-dimensional model embeddings onto a 2D plane, respectively. 
% UMAP is used because of its good processing speed and presevation of embeddings' global structure. After projection, instances are presented as dots and those having similar model embeddings are close to each other. 
% Users can color the dots by correctness to relate model performance to different clusters of instances. 
% To summarize model performance with QC-TC relations, 


\textbf{Alternative design}. We have considered an alternative---grouped bar charts---to visualize the relations between question and target concepts (\renfei{\autoref{fig:alternative designs}A}). 
For each relation, green bars show accuracy while blue bars encode frequency. The longer the bars, the larger the encoded values.
% It uses a parallel bar chart with two bars for each QC-TC relation. The height of the vertically placed green bar encodes the accuracy and the blue bar encodes the number of questions including the specific relation between their QCs to TCs. 
We collected experts' feedback on this alternative.
% and collected their feedback. 
\imp{E1} said that our final design using a single color looks simpler and cleaner. 
\rev{\imp{E3} commented that horizontally aligning green bars next to blue bars in the grouped bar charts could be confusing since the frequency and accuracy have different units of measurement.
\imp{E2} reported that our final design can reflect the proportion of different relations in the whole dataset more clearly.
% it is easier to compare different proportions of QC-TC relations in the dataset.
In addition, it sorts the frequent relations in descending order, helping prioritize the exploration.}
% makes the smaller proportion relation bar looks tinier which intuitively indicates its importance. 
% Moreover, our final design is more space-efficient than the grouped bar charts when the number of relations increases.
% scalability of space usage of the final design is also better than the parallel bar chart. 

% The \gv{} consists of two scatter plots that display the projection of QSs and TCs. The users can choose between six types of different projection strategies and two color schemes for different analytical purposes. 
% There is a stack of rectangles connecting the two scatter plots showing information on the relations between the QCs and TCs. The height of each rectangle encodes the proportion of questions with the specific relation between QC and TC. The horizontal green bar encodes the model accuracy within that group.  


\subsubsection{\sv{}}\label{subsec.subset_view}
% Besides the global summary of model performance and relation learning in the \gv{},
\revv{After selecting a group of instances with specific concepts or relations in the \gv{},}
users can utilize the \sv{} to explore the
% the \textit{context} about the 
concept alignment between the model behavior and \cpn{} knowledge across different subsets (\imp{R2}).
% The \sv{} \renfei{(\autoref{fig:teaser}B)} summarizes the context about the alignment between the model behavior and ConceptNet knowledge regarding QCs, QSs, and TCs (\imp{R1, R2, R3}).
This view employs cluster glyphs to analyze model behavior across instances with semantically similar question concepts, question stems, and target concepts. Hierarchical clustering of ConceptNet Numberbatch embeddings~\cite{conceptnet} is performed for question stems, question concepts, and target concepts.
% Specifically, the \sv{} employs three groups of cluster glyphs to summarize how the model behaves on groups of instances having semantically similar question concepts, question stems, and target concepts. 
% We perform hierarchical clustering of ConceptNet Numberbatch~\cite{conceptnet} embeddings of question stems, question concepts, and target concepts, respectively.
% of QCs, QSs, and TCs, respectively. 
We use ConceptNet Numberbatch embeddings because they encode word meanings based on \cpn{}'s semantic network and perform well on \revv{word-relatedness benchmarks~\cite{conceptnet}.} Then, users can scan through the cluster glyphs 
% for question stems, question and target concepts 
and sneak peek into the corresponding model performance, the important words for model decisions, and how they are aligned with \cpn{} concepts (\renfei{\autoref{fig:alternative designs}B}).
% For each cluster, we design a glyph to help users sneak peek into the statistics and model behavior (\renfei{\autoref{fig:alternative designs}B}).
For each cluster glyph, two bars are presented at the top \revv{showing the average accuracy (between 0 and 1) and overlap ratio (between 0 and 1)} between model concepts and \cpn{} concepts.
The lower parts display the differences between the model and \cpn{} concepts.
% covered by the model (\ie, considered important) or not.
The first row displays the top ConceptNet concepts frequently missed by the model. And an orange bar is put to the left, revealing the frequency. Then, the second row shows the frequent model concepts and their frequency (with blue bars). 
To further explore concept associations across different questions, and question and target concepts, their cluster glyphs are connected with links if their data instances overlap---the wider the link, the greater the shared data instances.
\revv{To reduce the visual clutter of links, the system allows users to adjust the cluster numbers at the header. When users hover over a specific cluster glyph, the system highlights only the connections relevant to that cluster, while keeping other links hidden.}
% \rev{Users can click the interested cluster glyph to see the details in the \iv{}.}

% \rev{Users may also want to know what are the question contexts (\ie, QSs) for a group of QCs or TCs of interest.}
% To show the relationships between QCs and QSs and TCs, their cluster glyphs are arranged from top to bottom and connected by links. Two clusters will be linked together if their data instances overlap. And the link width is proportional to the number of shared data instances.
% \revv{To reduce the visual clutter of links, the system enables to adjust cluster numbers at the header and highlights only the connections relevant to a specific cluster glyph when users hover over it and keep other links hidden.}
% of QCs, QSs, and TCs are arranged from top to bottom and connected by links. 
% Two clusters will be linked together if their data instances overlap with each other. And the width of the links is proportional to the number of shared data instances.

% for each cluster, we design a glyph to sneak peek into the overall differences between the model concepts and ConceptNet concepts.
% we seperate concepts covered only by models and 
% The \sv{} displays more details of lassoed data in the \gv{} with cluster glyphs connected by links. 
% We propose a novel glyph design to help users sneak peek into the overall information of each cluster. 
% Each cluster glyph is presented with two bars on top showing the accuracy and average SHAP coverage within the cluster. The lower parts consist of two groups of information. The above group are the concepts that have SHAP coverage scores below 0.5 and the group below are the concepts that have SHAP coverage scores above 0.5. 
% The two rows of texts show the top 5 words with the highest frequency in each group. 
% There are two rectangles on the left showing the count of the words in the upper texts and the lower texts colored with yellow and blue respectively. 

% The cluster glyphs are arranged in three rows with links connecting them. The top row shows the QCs within the selected questions. The middle row shows the question stems and the bottom row shows the TCs of the questions. 
% The links between cluster glyphs show the clusters share the same question IDs between each row. The width of the links shows the proportion of data between clusters. 


\textbf{Alternative design}. 
Initially, we considered using a word cloud (\renfei{\autoref{fig:alternative designs}B}) to summarize the most frequent concepts (not) covered by the model. And the word size relates to frequency. 
However, the word cloud is not space-efficient and mixes the model concepts with ConceptNet concepts and increases the visual complexity, making the system less user-friendly.
More importantly, our users prioritize reading the concept words in plain style. Therefore, we chose our current design.

% the most frequently appeared words (contexts) that model attached as important or the model did not treat as important. 
% E1 reported that 
% although word cloud is fancy as an individual visualization. When arranged in grids, it does not fit into the space very well. Besides, 
% the word clouds increase the visual complexity of the \sv{}, making the system less user-friendly. 
% E2 added that word clouds are not consistent with the overall design styling of our system. 
% E3 said that if we want to add more statistical information such as accuracy around a word cloud, it would be difficult and unnatural to the user. 


\subsubsection{\iv{}}
After selecting instances in the \gv{} or \sv{}, the Instance View \renfei{(\autoref{fig:teaser}C)} provides statistics and local explanations about the model. It enables probing of the model with different inputs and outputs to test its learning of concepts and commonsense relations (\imp{R1, R4}). 
The top stacked bars show model accuracy and average question concept (QC) hit ratio \revv{(between 0 and 1)}. Users can click the green (or gray) segments with the stacked bars to filter the data instances correctly (or wrongly) predicted. 
The histogram below displays the top frequent concepts considered important to the model. 
Users can explore individual instances and model explanations with pagination. The question stems that strongly contribute to model outputs are highlighted with green backgrounds, and question concept is underlined. Model choices colored red indicate a wrong answer, and the ground truth is colored green. 
Users can verify and generalize their findings by searching for linguistic patterns in data instances that contain certain words or structures (\eg, \hl{many NOUN}) at the top. 
% This allows them to seek out specific linguistic patterns of interest, which may encompass certain words or structures (e.g., "many NOUN"). 
% The patterns can contain specific words or structures (\eg, \hl{many NOUN}). 
% After searching, users may examine the statistics and/or model behavior on individual instances.
\revv{For instance, after searching a question concept of interest, users can review the model performance on different contextualizations (\ie, question stems) of that concept and associated relations in the \gv{}. Then, further detail can be investigated, including statistics and model explanations for individual instances, in the \iv{}.}
 
% After selecting instances of interest in the \gv{} or \sv{}, the \iv{} \renfei{(\autoref{fig:teaser}C)} provides the statistics and local explanations about them.
% Moreover, it enables users to probe the model with different inputs and outputs to test the model learning of concepts and commonsense relations (\imp{R1, R4}).
% \rev{Users can first inspect the two stacked bars at the top to know the model accuracy and average QC hit ratio of the model. 
% They can click the green (or gray) segments with the stacked bars to filter the data instances correctly (or wrongly) predicted.
% Moreover, users can skim through the top frequent concepts considered important by the model in the histogram below.}
% % In the instance view, users can observe the accuracy and the average QC hit ratio of the selected questions on the top. 
% % The SHAP attached important words are counted and the top 20 words are displayed in a bar chart. The text of the words is shown below. 
% \rev{Then, users can explore the individual instances and model explanations with pagination at the bottom of the \iv{}.}
% % are displayed with pagination at the bottom.
% % Users can navigate through the instances to 
% \rev{For each instance, users can check the QCs, TCs, and their relationships (retrieved from \cpn{}), question-answer pairs, and local explanations.
% Next, they may generate hypotheses about the model's learning of concepts and relations.}
% Particularly, to explain model learning of concepts, the words in the QSs that strongly contribute to the model outputs will be highlighted with green background. Also, QC is underlined for quick identification.
% If the model answer is wrong, the model choice is colored red while the ground truth (\ie, TC) is colored green. If the model is correct, only TC will be colored green. \rev{Based on the model accuracy and highlighted words in the QSs, users can decide whether the model relies on reasonable words to make decisions.
% Furthermore, users can generalize their findings about the model learning of concepts by searching linguistic patterns of interest at the header of the \iv{}. The patterns can be instances containing specific words or structures (\eg, \hl{many NOUN}). Users may examine the statistics and/or model behavior on individual instances after searching.
% }

\rev{For individual instances, users can edit them to form and validate hypotheses about the model learning of relations.
For example, 
% if the model attaches importance to QCs and answers the questions correctly, then it is possible the model learns the QC-TC relations.
if the model is wrong, users may hover over different answer choices to see their relations with \cpn{} concepts in question stems.
If both model answers and target concepts share the same relations with question concepts, the model potentially does not understand the contexts.
Then, users can edit the text content of question stems and individual answer choices (\eg, remove some words in questions and change answer choices), followed by re-running the model on the edited QA pairs. The new model answers will be highlighted in blue. By examining the new results, users can validate whether the relations between the question and target concepts are learned. 
% For example, if QSs are rephrased to question the QC-TC relations directly, and the model is wrong, then the model possibly does not learn the relations.
}
% To help users test their hypotheses about model relational learning over concepts, users can edit the QS and choices and re-run the model on edited content. The new model answers will be highlighted in blue. 
% When hovering over each answer choice, its relations with the QS concepts that are within one-hop distance in ConceptNet will be displayed. 
% This helps users quickly identify which words in question stem may strongly influence the model result. 
% Furthermore, users can search linguistic patterns of interest, for example, instances containing specific words or structures (\eg, \hl{many NOUN}), in the query input box to generalize their findings about the instances.
% The detailed questions and model reasoning information are displayed with pagination, each time the user is displayed with the details of a single question. 
% The users can navigate through different pages to check instance-level results. Each page displays one question. 
% The SHAP values of tokens in the question stem are encoded with color opacity. We underline the QC in the stem to make users easier to locate where the QC is. 
% If the model's result is correct, only one choice will be colored green. If the model's result is wrong, the choice of model result is colored red and the ground truth (TC) is colored green. 

\vis{Users can bookmark instances about specific knowledge that the model does not learn well. Then, they can conduct model editing in the Model Editing Panel \todo{(\autoref{fig:teaser}D)}, where information about questions, relations, ground truths, and model results are summarized in a table. Users can apply editing to instances of interest and inspect the editing performance. Moreover, they can load the edited model for exploration.}

\begin{comment}

\subsubsection{User Interactions}\label{subsec.ui}
\name{} offers various interactions to support multi-level analysis of model behavior with details on demand.

% Besides the interface components introduced earlier, \name{} supports a rich set of interactions that facilitate multi-level analysis of model behavior with details on demand.

\textbf{Lasso and pan-and-zoom}. 
In the \gv{}, users can lasso a group of data instances in the scatter plots to examine the details in the \sv{} and \iv{}. 
And users can use pan-and-zoom in the scatter plots to navigate local clusters more easily. 
% the scatter plots provide users with a pan-and-zoom to navigate the local clusters easier. Users can reset the plots to the default scale by clicking the reset button. 

% % Interactions
% The scatter plot supports users with zoom and pan to navigate the local area easier. When the mouse hovers over the points, the information of each question and its corresponding point in the other scatter plot is displayed at the same time. 
% The user can lasso the data points in scatter plots to perform further interactions with the lassoed data points in the subset view and instance view. 
% When hovering over the relations rectangles, detailed information about the relation is shown. The users can click on each rectangle to filter questions with certain QC-TC relations in scatter plots. The data is also updated into the subset view and the instance view. 


\textbf{Hovering and clicking}. 
To make the interface cleaner and less overwhelming, we hide lots of details, and users can hover or click to see the details on demand. For example, in the \gv{}, users can hover over
the dots in the scatter plots and the relation bars in the middle to see the pairs of QSs and TCs and relation accuracy, respectively.
When hovering the cluster glyphs in the \sv{}, detailed concepts and statistics of the clusters, together with their connections with other clusters, will be displayed. 
In the \iv{}, hovering over the charts will display the detailed numbers. Also, users can hover over the answer choices to query their relations with the QS concepts.

Moreover, users can filter or highlight the information by clicking.
For example, relation bars in the \gv{}, and stacked bars in the \sv{} can be clicked to filter data instances.
In addition, users can navigate through instances by clicking the pagination buttons. Meanwhile, its corresponding dots and clusters will be highlighted in the \gv{} and \sv, respectively.


% Instance view:
% When hovering on the statistics information bars in the Instance View, detailed information is shown. 
% The users can click the accuracy and average QC hit bars to filter and display the questions within that group. 

% \textbf{Linked highlighting}

% \textbf{In-situ Instance Editting}
% The users can edit the question stem and choices and rerun the model on edited content to test their hypotheses. 
% When hovering on each choice, the concepts in question stem that is within one-hop distance is displayed with the relations between them. This supports users to quickly identifying which words in question stem may strongly influence the model result. 
 
\end{comment}
