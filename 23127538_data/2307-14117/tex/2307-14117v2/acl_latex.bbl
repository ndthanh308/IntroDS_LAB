\begin{thebibliography}{42}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Adewumi et~al.(2022)Adewumi, Br{\"a}nnvall, Abid, Pahlavan,
  Sabah~Sabry, Liwicki, and Liwicki}]{adewumi2022smaaprat}
Oluwatosin Adewumi, Rickard Br{\"a}nnvall, Nosheen Abid, Maryam Pahlavan, Sana
  Sabah~Sabry, Foteini Liwicki, and Marcus Liwicki. 2022.
\newblock Sm{\aa}prat: Dialogpt for natural language generation of swedish
  dialogue by transfer learning.
\newblock In \emph{5th Northern Lights Deep Learning Conference (NLDL),
  Troms{\o}, Norway, January 10-12, 2022}, volume~3. Septentrio Academic
  Publishing.

\bibitem[{Adolphs et~al.(2023)Adolphs, Gao, Xu, Shuster, Sukhbaatar, and
  Weston}]{adolphs-etal-2023-cringe}
Leonard Adolphs, Tianyu Gao, Jing Xu, Kurt Shuster, Sainbayar Sukhbaatar, and
  Jason Weston. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.acl-long.493} {The {CRINGE}
  loss: Learning what language not to model}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 8854--8874,
  Toronto, Canada. Association for Computational Linguistics.

\bibitem[{Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain,
  Fort, Ganguli, Henighan et~al.}]{bai2022training}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
  Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al. 2022.
\newblock Training a helpful and harmless assistant with reinforcement learning
  from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}.

\bibitem[{Bang et~al.(2021)Bang, Lee, Ishii, Madotto, and
  Fung}]{bang-etal-2021-assessing}
Yejin Bang, Nayeon Lee, Etsuko Ishii, Andrea Madotto, and Pascale Fung. 2021.
\newblock \href {https://aclanthology.org/2021.sigdial-1.57} {Assessing
  political prudence of open-domain chatbots}.
\newblock In \emph{Proceedings of the 22nd Annual Meeting of the Special
  Interest Group on Discourse and Dialogue}, pages 548--555, Singapore and
  Online. Association for Computational Linguistics.

\bibitem[{Camacho-Collados et~al.(2022)Camacho-Collados, Rezaee, Riahi, Ushio,
  Loureiro, Antypas, Boisson, Espinosa-Anke, Liu, Mart{\'\i}nez-C{\'a}mara
  et~al.}]{camacho-collados-etal-2022-tweetnlp}
Jose Camacho-Collados, Kiamehr Rezaee, Talayeh Riahi, Asahi Ushio, Daniel
  Loureiro, Dimosthenis Antypas, Joanne Boisson, Luis Espinosa-Anke, Fangyu
  Liu, Eugenio Mart{\'\i}nez-C{\'a}mara, et~al. 2022.
\newblock {T}weet{NLP}: {C}utting-{E}dge {N}atural {L}anguage {P}rocessing for
  {S}ocial {M}edia.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, Abu Dhabi, U.A.E.
  Association for Computational Linguistics.

\bibitem[{Chen et~al.(2017)Chen, Liu, Yin, and Tang}]{chen2017survey}
Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang. 2017.
\newblock A survey on dialogue systems: Recent advances and new frontiers.
\newblock \emph{ACM SIGKDD Explorations Newsletter}, 19(2):25--35.

\bibitem[{Dinan et~al.(2020)Dinan, Logacheva, Malykh, Miller, Shuster, Urbanek,
  Kiela, Szlam, Serban, Lowe et~al.}]{dinan2020second}
Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander Miller, Kurt
  Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan Lowe,
  et~al. 2020.
\newblock The second conversational intelligence challenge ({ConvAI2}).
\newblock In \emph{The NeurIPS'18 Competition: From Machine Learning to
  Intelligent Conversations}, pages 187--208. Springer.

\bibitem[{Dror et~al.(2018)Dror, Baumer, Shlomov, and
  Reichart}]{dror-etal-2018-hitchhikers}
Rotem Dror, Gili Baumer, Segev Shlomov, and Roi Reichart. 2018.
\newblock \href {https://doi.org/10.18653/v1/P18-1128} {The hitchhiker{'}s
  guide to testing statistical significance in natural language processing}.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1383--1392,
  Melbourne, Australia. Association for Computational Linguistics.

\bibitem[{Dubois et~al.(2023)Dubois, Li, Taori, Zhang, Gulrajani, Ba, Guestrin,
  Liang, and Hashimoto}]{dubois2023alpacafarm}
Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba,
  Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto. 2023.
\newblock \href {https://openreview.net/forum?id=4hturzLcKX} {Alpacafarm: A
  simulation framework for methods that learn from human feedback}.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}.

\bibitem[{Gao et~al.(2018)Gao, Galley, and Li}]{gao2018neural}
Jianfeng Gao, Michel Galley, and Lihong Li. 2018.
\newblock Neural approaches to conversational ai.
\newblock In \emph{The 41st International ACM SIGIR Conference on Research \&
  Development in Information Retrieval}, pages 1371--1374.

\bibitem[{Ghazarian et~al.(2023)Ghazarian, Hedayatnia, Jin, Liu, Peng, Liu, and
  Hakkani-Tur}]{ghazarian-etal-2023-mercy}
Sarik Ghazarian, Behnam Hedayatnia, Di~Jin, Sijia Liu, Nanyun Peng, Yang Liu,
  and Dilek Hakkani-Tur. 2023.
\newblock \href {https://doi.org/10.18653/v1/2023.sigdial-1.58} {{MERCY}:
  Multiple response ranking concurrently in realistic open-domain
  conversational systems}.
\newblock In \emph{Proceedings of the 24th Annual Meeting of the Special
  Interest Group on Discourse and Dialogue}, pages 615--631, Prague, Czechia.
  Association for Computational Linguistics.

\bibitem[{Gilardi et~al.(2023)Gilardi, Alizadeh, and
  Kubli}]{gilardi2023chatgpt}
Fabrizio Gilardi, Meysam Alizadeh, and Ma{\"e}l Kubli. 2023.
\newblock {ChatGPT} outperforms crowd-workers for text-annotation tasks.
\newblock \emph{arXiv preprint arXiv:2303.15056}.

\bibitem[{Guo et~al.(2018)Guo, Metallinou, Khatri, Raju, Venkatesh, and
  Ram}]{guo2018topic}
Fenfei Guo, Angeliki Metallinou, Chandra Khatri, Anirudh Raju, Anu Venkatesh,
  and Ashwin Ram. 2018.
\newblock Topic-based evaluation for conversational bots.
\newblock \emph{arXiv preprint arXiv:1801.03622}.

\bibitem[{Hancock et~al.(2019)Hancock, Bordes, Mazare, and
  Weston}]{hancock-etal-2019-learning}
Braden Hancock, Antoine Bordes, Pierre-Emmanuel Mazare, and Jason Weston. 2019.
\newblock \href {https://doi.org/10.18653/v1/P19-1358} {Learning from dialogue
  after deployment: Feed yourself, chatbot!}
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 3667--3684, Florence, Italy.
  Association for Computational Linguistics.

\bibitem[{Hartmann(2022)}]{hartmann2022emotionenglish}
Jochen Hartmann. 2022.
\newblock Model accessible via
  \url{https://huggingface.co/j-hartmann/emotion-english-distilroberta-base}.

\bibitem[{Irvine et~al.(2023)Irvine, Boubert, Raina, Liusie, Mudupalli,
  Korshuk, Liu, Cremer, Assassi, Beauchamp, Lu, Rialan, and
  Beauchamp}]{irvine2023rewarding}
Robert~P. Irvine, Douglas Boubert, Vyas Raina, Adian Liusie, Vineet Mudupalli,
  Aliaksei Korshuk, Zongyi~Joe Liu, Fritz Cremer, Valentin Assassi,
  Christie-Carol Beauchamp, Xiaoding Lu, Thomas Rialan, and William Beauchamp.
  2023.
\newblock Rewarding chatbots for real-world engagement with millions of users.
\newblock \emph{arXiv preprint arXiv:2303.06135}.

\bibitem[{Ju et~al.(2022)Ju, Xu, Boureau, and Weston}]{ju2022learning}
Da~Ju, Jing Xu, Y-Lan Boureau, and Jason Weston. 2022.
\newblock Learning from data in the mixed adversarial non-adversarial case:
  Finding the helpers and ignoring the trolls.
\newblock \emph{arXiv preprint arXiv:2208.03295}.

\bibitem[{Khatri et~al.(2018)Khatri, Hedayatnia, Venkatesh, Nunn, Pan, Liu,
  Song, Gottardi, Kwatra, Pancholi et~al.}]{khatri2018advancing}
Chandra Khatri, Behnam Hedayatnia, Anu Venkatesh, Jeff Nunn, Yi~Pan, Qing Liu,
  Han Song, Anna Gottardi, Sanjeev Kwatra, Sanju Pancholi, et~al. 2018.
\newblock Advancing the state of the art in open domain dialog systems through
  the {Alexa} prize.
\newblock \emph{arXiv preprint arXiv:1812.10757}.

\bibitem[{Kulikov et~al.(2019)Kulikov, Lee, and Cho}]{kulikov2019multi}
Ilia Kulikov, Jason Lee, and Kyunghyun Cho. 2019.
\newblock Multi-turn beam search for neural dialogue modeling.
\newblock \emph{arXiv preprint arXiv:1906.00141}.

\bibitem[{Lee et~al.(2023)Lee, Park, Park, Kim, and
  Kim}]{lee-etal-2023-framework}
Jaewook Lee, Seongsik Park, Seong-Heum Park, Hongjin Kim, and Harksoo Kim.
  2023.
\newblock \href {https://aclanthology.org/2023.emnlp-main.167} {A framework for
  vision-language warm-up tasks in multimodal dialogue models}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing}, pages 2789--2799, Singapore. Association for
  Computational Linguistics.

\bibitem[{Lee et~al.(2022)Lee, Ping, Xu, Patwary, Fung, Shoeybi, and
  Catanzaro}]{lee2022factuality}
Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale Fung, Mohammad Shoeybi,
  and Bryan Catanzaro. 2022.
\newblock \href {https://openreview.net/forum?id=LvyJX20Rll} {Factuality
  enhanced language models for open-ended text generation}.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Li et~al.(2017{\natexlab{a}})Li, Miller, Chopra, Ranzato, and
  Weston}]{li2017dialogue}
Jiwei Li, Alexander~H. Miller, Sumit Chopra, Marc'Aurelio Ranzato, and Jason
  Weston. 2017{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=HJgXCV9xx} {Dialogue learning
  with human-in-the-loop}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Li et~al.(2017{\natexlab{b}})Li, Monroe, and
  Jurafsky}]{li2017learning}
Jiwei Li, Will Monroe, and Dan Jurafsky. 2017{\natexlab{b}}.
\newblock Learning to decode for future success.
\newblock \emph{arXiv preprint arXiv:1701.06549}.

\bibitem[{Mehri and Eskenazi(2020)}]{mehri-eskenazi-2020-unsupervised}
Shikib Mehri and Maxine Eskenazi. 2020.
\newblock \href {https://aclanthology.org/2020.sigdial-1.28} {Unsupervised
  evaluation of interactive dialog with {D}ialo{GPT}}.
\newblock In \emph{Proceedings of the 21th Annual Meeting of the Special
  Interest Group on Discourse and Dialogue}, pages 225--235, 1st virtual
  meeting. Association for Computational Linguistics.

\bibitem[{O'Brien and Toms(2008)}]{o2008user}
Heather~L O'Brien and Elaine~G Toms. 2008.
\newblock What is user engagement? {A} conceptual framework for defining user
  engagement with technology.
\newblock \emph{Journal of the American society for Information Science and
  Technology}, 59(6):938--955.

\bibitem[{Pang et~al.(2022)Pang, He, and Cho}]{pang-etal-2022-amortized}
Richard~Yuanzhe Pang, He~He, and Kyunghyun Cho. 2022.
\newblock \href {https://aclanthology.org/2022.inlg-main.11} {Amortized noisy
  channel neural machine translation}.
\newblock In \emph{Proceedings of the 15th International Conference on Natural
  Language Generation}, pages 131--143, Waterville, Maine, USA and virtual
  meeting. Association for Computational Linguistics.

\bibitem[{Pang et~al.(2023)Pang, Padmakumar, Sellam, Parikh, and
  He}]{pang2022reward}
Richard~Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur Parikh, and
  He~He. 2023.
\newblock \href {https://aclanthology.org/2023.acl-long.262} {Reward gaming in
  conditional text generation}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 4746--4763,
  Toronto, Canada. Association for Computational Linguistics.

\bibitem[{Rafailov et~al.(2023)Rafailov, Sharma, Mitchell, Manning, Ermon, and
  Finn}]{rafailov2023direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher~D Manning, Stefano
  Ermon, and Chelsea Finn. 2023.
\newblock \href {https://openreview.net/forum?id=HPuSIXJaa9} {Direct preference
  optimization: Your language model is secretly a reward model}.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}.

\bibitem[{See and Manning(2021)}]{see-manning-2021-understanding}
Abigail See and Christopher Manning. 2021.
\newblock \href {https://aclanthology.org/2021.sigdial-1.1} {Understanding and
  predicting user dissatisfaction in a neural generative chatbot}.
\newblock In \emph{Proceedings of the 22nd Annual Meeting of the Special
  Interest Group on Discourse and Dialogue}, pages 1--12, Singapore and Online.
  Association for Computational Linguistics.

\bibitem[{Shalyminov et~al.(2018)Shalyminov, Du{\v{s}}ek, and
  Lemon}]{shalyminov-etal-2018-neural}
Igor Shalyminov, Ond{\v{r}}ej Du{\v{s}}ek, and Oliver Lemon. 2018.
\newblock \href {https://doi.org/10.18653/v1/W18-5701} {Neural response ranking
  for social conversation: A data-efficient approach}.
\newblock In \emph{Proceedings of the 2018 {EMNLP} Workshop {SCAI}: The 2nd
  International Workshop on Search-Oriented Conversational {AI}}, pages 1--8,
  Brussels, Belgium. Association for Computational Linguistics.

\bibitem[{Shi et~al.(2022)Shi, Dinan, Shuster, Weston, and Xu}]{shi2022life}
Weiyan Shi, Emily Dinan, Kurt Shuster, Jason Weston, and Jing Xu. 2022.
\newblock When life gives you lemons, make cherryade: Converting feedback from
  bad responses into good labels.
\newblock \emph{arXiv preprint arXiv:2210.15893}.

\bibitem[{Shuster et~al.(2022{\natexlab{a}})Shuster, Komeili, Adolphs, Roller,
  Szlam, and Weston}]{shuster-etal-2022-language}
Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam,
  and Jason Weston. 2022{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/2022.findings-emnlp.27} {Language
  models that seek for knowledge: Modular search {\&} generation for dialogue
  and prompt completion}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pages 373--393, Abu Dhabi, United Arab Emirates. Association for
  Computational Linguistics.

\bibitem[{Shuster et~al.(2022{\natexlab{b}})Shuster, Xu, Komeili, Ju, Smith,
  Roller, Ung, Chen, Arora, Lane et~al.}]{shuster2022blenderbot}
Kurt Shuster, Jing Xu, Mojtaba Komeili, Da~Ju, Eric~Michael Smith, Stephen
  Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et~al.
  2022{\natexlab{b}}.
\newblock Blenderbot 3: a deployed conversational agent that continually learns
  to responsibly engage.
\newblock \emph{arXiv preprint arXiv:2208.03188}.

\bibitem[{Skalse et~al.(2022)Skalse, Howe, Krasheninnikov, and
  Krueger}]{skalse2022defining}
Joar Skalse, Nikolaus Howe, Dmitrii Krasheninnikov, and David Krueger. 2022.
\newblock Defining and characterizing reward gaming.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:9460--9471.

\bibitem[{Stiennon et~al.(2020)Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei, and Christiano}]{stiennon2020learning}
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea
  Voss, Alec Radford, Dario Amodei, and Paul~F Christiano. 2020.
\newblock Learning to summarize with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:3008--3021.

\bibitem[{Veselovsky et~al.(2023)Veselovsky, Ribeiro, and
  West}]{veselovsky2023artificial}
Veniamin Veselovsky, Manoel~Horta Ribeiro, and Robert West. 2023.
\newblock Artificial artificial artificial intelligence: Crowd workers widely
  use large language models for text production tasks.
\newblock \emph{arXiv preprint arXiv:2306.07899}.

\bibitem[{Wilcoxon(1992)}]{wilcoxon1992individual}
Frank Wilcoxon. 1992.
\newblock Individual comparisons by ranking methods.
\newblock In \emph{Breakthroughs in Statistics: Methodology and Distribution},
  pages 196--202. Springer.

\bibitem[{Xu et~al.(2023)Xu, Ju, Lane, Komeili, Smith, Ung, Behrooz, Ngan,
  Moritz, Sukhbaatar et~al.}]{xu2023improving}
Jing Xu, Da~Ju, Joshua Lane, Mojtaba Komeili, Eric~Michael Smith, Megan Ung,
  Morteza Behrooz, William Ngan, Rashel Moritz, Sainbayar Sukhbaatar, et~al.
  2023.
\newblock Improving open language models by learning from organic interactions.
\newblock \emph{arXiv preprint arXiv:2306.04707}.

\bibitem[{Yuan et~al.(2023)Yuan, Cho, and Weston}]{yuan2023system}
Weizhe Yuan, Kyunghyun Cho, and Jason Weston. 2023.
\newblock System-level natural language feedback.
\newblock \emph{arXiv preprint arXiv:2306.13588}.

\bibitem[{Yuan et~al.(2024)Yuan, Pang, Cho, Sukhbaatar, Xu, and
  Weston}]{yuan2024self}
Weizhe Yuan, Richard~Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing
  Xu, and Jason Weston. 2024.
\newblock Self-rewarding language models.
\newblock \emph{arXiv preprint arXiv:2401.10020}.

\bibitem[{Zemlyanskiy and Sha(2018)}]{zemlyanskiy-sha-2018-aiming}
Yury Zemlyanskiy and Fei Sha. 2018.
\newblock \href {https://doi.org/10.18653/v1/K18-1053} {Aiming to know you
  better perhaps makes me a more engaging dialogue partner}.
\newblock In \emph{Proceedings of the 22nd Conference on Computational Natural
  Language Learning}, pages 551--561, Brussels, Belgium. Association for
  Computational Linguistics.

\bibitem[{Zhang et~al.(2020)Zhang, Sun, Galley, Chen, Brockett, Gao, Gao, Liu,
  and Dolan}]{zhang-etal-2020-dialogpt}
Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao,
  Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-demos.30} {{DIALOGPT} :
  Large-scale generative pre-training for conversational response generation}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics: System Demonstrations}, pages 270--278,
  Online. Association for Computational Linguistics.

\end{thebibliography}
