\documentclass[twocolumn]{article}[11pt]
\usepackage[
backend=biber,
style=alphabetic,
]{biblatex}
\title{A bibLaTeX example}
\addbibresource{refs.bib} %Imports bibliography file

\author{Alek Westover}
% \title{Linear Hashing isn't too Picky:\\ For $\R$eal, No Shift, it's Ama$\Z$ing}
\title{Linear Hashing: No Shift, Non-Prime Modulus, For $\R$eal!}
\input{head.tex}
\begin{document}
\maketitle

\abstract{
  The \defn{hashing problem} is to assign $m$ items from a
  universe $U$ to $n$ \defn{bins} so that all bins receive a
  similar number of items. We measure the quality of a hashing
  scheme's distribution by the number of items assigned to the
  fullest bin, known as its \defn{maxload}. 

  \defn{Linear Hashing} ($\LH$) is a
  simple and classical solution to the hashing problem.
  In $\LH$ items $x\in \set{1,2,\ldots, |U|}$ are
  mapped to bins $\set{0,1,\ldots, n-1}$ by 
  $$x\mapsto (ax+b)\mod p \mod n$$ for prime $p\in [|U|, 2|U|]$
  and randomly chosen integers $a,b \in [1,p]$.
  Despite $\LH$'s simplicity however, 
  understanding the expected maxload of $\LH$ for worst-case
  inputs is a notoriously challenging
  and wide open question. For $m=n$ the best known lower bound is
  $\Omega\left(\frac{\log n}{\log\log n}\right)$, whereas the
  best known upper bound is $\widetilde{\bigO}(n^{1/3})$ due to
  Knudsen\cite{knudsen_linear_2017}.

  In this paper we consider three modifications of $\LH$: 
  (1) $\LH$ without the ``$+b$" shift term, resulting in
  loss of pairwise-independence. (2) $\LH$ with a composite,
  rather than prime, modulus. (3) $\LH$ in a continuous setting
  where the multiplier ``$a$" is chosen from $\R$ rather than $\Z$.
  We show that $\LH$ is fairly robust to these changes, in
  particular by demonstrating analogs of known maxload-bounds for
  these new variants.

  These results give several new perspectives on $\LH$, in
  particular showing that properties of $\LH$ such as
  pairwise-independence, a prime modulus, or even its setting in
  the integers may not be fundamental. We believe that these new
  perspectives, beyond being independently interesting, may
  also be useful in future work towards understanding the maxload of
  $\LH$.
}

\section{Introduction}
  The \defn{hashing problem} is to assign $m$ items from a
  universe $U$ to $n$ \defn{bins} so that all bins receive a
  similar number of items. In particular, we measure the quality
  of a hashing scheme's load distribution by the number of items
  in the fullest bin; we refer to this as the \defn{maxload}. 
  We desire three main properties of a hashing scheme: 
  (1) small expected maxload for arbitrary inputs, (2) fast
  evaluation time, and (3) small description size.

  \paragraph{Related Work}
  The hashing problem has been extensively studied.
  We use the standard parameters $|U|=\poly(n)$, $m=n$ in the
  following discussion. We also assume the unit-cost RAM model,
  i.e., that arithmetic operations on numbers of size $\log n$
  can be performed in constant time. We use the abbreviation
  $\ell(n) = \frac{\log n}{\log\log n}$.

  The hash function which assigns each item independently
  randomly to a bin achieves the smallest possible expected
  maxload, namely $\Theta(\ell(n))$ \cite{mitzenmacher2017probability}.
  However, describing a fully random function requires $|U|\log
  n$ space, which is extremely large.
  Full independence is not necessary. For instance, 
  \cite{carter1977universal} shows that degree $\Theta(\ell(n))$
  polynomials over a finite
  field constitute a $\Theta(\ell(n))$-wise
  independent hash family and achieves the same maxload as the
  fully random hash function.
  Improving on this result, \cite{celis2013balls} demonstrates
  a hash family achieving optimal maxload with evaluation time
  $\bigO(\sqrt{\log n})$.

  In fact, it is even possible to achieve optimal maxload with
  constant evaluation time, as demonstrated by Seigel in
  \cite{siegel_universal_2004}. However, Seigel's function
  requires a description size of $\poly(n)$.
  Furthermore, Seigel proved that it is impossible to
  simultaneously achieve optimal maxload, constant evaluation
  time, $n^{o(1)}$ description size, and $\Omega(\ell(n))$ independence. 
  However, this still leaves room for improvement if we do not
  require independence.

  By itself small independence does not give any good bound on
  maxload; for example, there are pairwise-independent hash
  families with maxload $\Omega(\sqrt{n})$ \cite{petershor}.
  However, \cite{alon_is_1997} shows that the
  pairwise-independent hash family of multiplication by random
  matrices over $\F_2$ achieves $\bigO(\ell(n) \cdot (\log \log
  n)^2)$ maxload in $\bigO(\log(n))$ evaluation time. 

  However, the following question remains open:
  \begin{question}
    \label{question:fastandgood}
Is there a hash family describable in $\bigO(1)$ machine
words whose evaluation requires $\bigO(1)$ arithmetic
operations that achieves maxload $n^{o(1)}$?
  \end{question}

\paragraph{Linear Hashing ($\LH$)}
$\LH$ \cite{motwani1995randomized,
cormen2022introduction, sedgewick2014algorithms} is an attractive potential solution to
\cref{question:fastandgood}, trivially satisfying the conditions
of small description size and fast evaluation time.
$\LH$ heuristically does quite well at spreading out elements
\cite{sedgewick2014algorithms}.
In \cite{motwani1995randomized}, $\LH$ from a universe
$\set{1,2,\ldots, u}$ to bins $\set{0,1,\ldots, n-1}$ is defined
by the function
$$x\mapsto (ax+b)\mod p \mod n$$ for prime $p\in [|U|, 2|U|]$
and randomly chosen integers $a,b \in [1,p]$.
We find that it is often convenient to work with a slightly
different version of $\LH$ introduced in
\cite{dietzfelbinger1997reliable} where elements
are hashed by the function
$$x \mapsto \floor{ \frac{(ax+b)\mod p}{p/n} }.$$

The simplicity of this classic hashing scheme makes it an intriguing
theoretical question to understand its maxload.
However, despite the simplicity of the $\LH$ scheme, understanding its
maxload is a notoriously challenging and wide open question. 
The best known lower bound is $\Omega\left(\frac{\log
n}{\log\log n}\right)$, whereas the best known upper bound is
$\widetilde{\bigO}(n^{1/3})$ \cite{knudsen_linear_2017}.



% It is well known that pairwise independence is not sufficient to
% get any bound on maxload better than $\bigO(\sqrt{n})$
% \cite{petershor}.
% \begin{itemize}
%   \item Select $k\gets [n],\pi\gets S_{n-1}$ uniformly randomly.
%   \item Each ball $i\in [n-1]$ is placed in bin $k$ with
%     probability  $1/\sqrt{n}$ and in bin $k+\pi_i$ otherwise.
%   \item Ball $n$ is placed independently in a random bin.
% \end{itemize}
%  Here, the expected number of balls in any fixed bin is
%  $\bigO(1)$ (this is guaranteed for any pairwise independent hash
%  family by linearity of expectation), but the expected number of
%  balls in the fullest bin is $\Omega(\sqrt{n})$.

\paragraph{Our Results}
We do not resolve \cref{question:fastandgood}. Rather, we
propose and analyze three variants of $\LH$. 
We believe that these new perspectives, beyond being of interest
in their own right, may be of use in future work towards
understanding the maxload of $\LH$.

In \cref{sec:twobins} we consider an even simpler variant of
$\LH$:  we remove the shift parameter ``$+b$" and are left with
only the multiplier parameter ``$a$". This variant of $\LH$
no fails to exhibit pairwise-independence, and does so in a
particularly dramatic way if we reduce the number of bins to two
(while still hashing $n$ items). 
Nevertheless, we exhibit a bound of $n/2 + \bigO(n^{7/8})$ on the
maxload in this case.

Next, in \cref{sec:Z} we consider (for $n$ bins) the import of
using a prime modulus. Conventional wisdom (e.g.,
\cite{cormen2022introduction}) is that using a non-prime modulus
results in large problems. While this is sometimes true, we show
that with a little care the best known bound for maxload with a
prime modulus \cite{knudsen_linear_2017} can be translated to
apply to composite moduli.

Finally, in \cref{sec:R} we consider (for $n$ bins) $\LH$ with
real numbers, i.e., choosing the multiplier ``$a$"
from $\R$ and then rounding the result of multiplication.
Initially, the change to a continuous setting might seem to produce 
a very different problem. Surprisingly, we show that the real
number variant of $\LH$ is approximately equivalent to the
integer variants.

% In \cref{sec:nice} we analyze a particularly structured set
% which a priori is a reasonable candidate for a set which might
% incur large maxload; note that the maxload of an average set is
% of course small. However, we show that this set actually incurs
% small maxload. 

\section{Preliminaries}
\paragraph{Set Definitions}
We write $\PRM$ to denote the set of primes, $\F_p$ for $p\in \PRM$ to denote the
finite field with $p$ elements, and $\Z_m$ for $m\in \N$ to denote
the ring $\Z / m\Z.$

For $a,b\in \R$ we define 
$$[a,b]=\setof{x\in \R}{a\le x\le b}.$$
For $n\in \N$ we define 
$$[n] = \set{0,1,\ldots, n-1},$$
$$[n]_{\setminus 0} = [n]\setminus \set{0}.$$
For $p\in \N,x\in \R$ we define $\modp(x)$ as
the unique number in the set 
$$(x+p\Z) \cap [0,p),$$
and define
$$\circabs_p(x)= \min(\modp(x), \modp(-x)).$$
For $x\in \Z$, $\modp(x)$ is the positive remainder
obtained when $x$ is divided by $p$, and $\circabs_p(x)$ is the
smallest distance to $0$ from $x$ modulo $p$.

For $a\in \R$ and set $X\subset \R$ we define
$$a+X = \setof{a+x}{x\in X},$$
$$\modp(X) = \setof{\modp(x)}{x\in X}.$$


\paragraph{Number Theoretic Definitions}
For $x,y\in \N$ we write $x\perp y$ to denote that  $x,y$ are
coprime, and $x\mid y$ to denote that $x$ divides $y$.
We write $\gcd(x,y)$ to denote the largest $k$ satisfying both  $k\mid
x$  and $k\mid y$.
% We use $\nu_p(n)$ to denote the exponent of the largest
% power of $p$ dividing $n$. 

A \defn{unit}, with respect to an implicit ring, is an element
with an inverse. For $m\in \N$ we define $\Z_m^{\times}$ as the
set of units in $\Z_m$. That is,
$$\Z_m^{\times } =\setof{k \in [m]}{k\perp m}.$$ We write
$\phi$ to denote the Euler-Toitent function, which is defined to
be $\phi(m)=|\Z_m^{\times }|$. We write $\tau(m)$ to denote the number of
divisors of $m$. 

The following two facts (see, e.g.,
\cite{hardy1979introduction}), will be
useful in several bounds:
\begin{fact}\label{fact:numdivs}
  $$\tau(n) \le 2^{\bigO(\log n / \log\log n)} \leq n^{o(1)}.$$
\end{fact}
\begin{fact}\label{fact:toitent}
  $$\frac{n}{2\log\log n} \le \phi(n)\le n.$$
\end{fact}

\paragraph{Hashing Definitions}
A \defn{hashing scheme} mapping universe $[u]$ to $n$ bins is a set of functions 
$$\setof{h_i: [u]\to [n]}{i\in I}$$ 
parameterized by $i\in I$ for some set $I$.
We say $h_i$ sends element  $x$ to bin $h_i(x)$.
The \defn{maxload} of $\setof{h_i}{i\in I}$ with respect to set $X$ for
parameter choice $i_0\in I$ is 
$$\max_{k\in [n]} \left|\setof{x\in X}{h_{i_0}(x)=k}\right|.$$
In other words, maxload is the number of elements mapped to the
fullest bin.
We are concerned with bounding the expected maxload of hashing
schemes with respect to uniformly randomly
chosen parameter $i\in I$ for arbitrary $X$.
We will abbreviate uniformly randomly to randomly when the
uniformity is clear from context.

\begin{rmk}\label{rmk:assumesize}
  Our analysis is asymptotic as a function of $n$, the number of
  bins. We require that the universe size $u\in
  \poly(n)$ and in particular $u\geq \Omega(n^6)$.
  We adopt these restrictions for the following reasons:
  \begin{itemize}
    \item If $u$ is too small then bounding maxload is not
      interesting. For instance, if $u\in \Theta(n)$ linear
      hashing trivially achieves maxload $\bigO(1)$.
      It is usual to think of the universe as being much larger
      than the number of bins. Our specific choice $u\ge \Omega(n^{6})$ is
      arbitrary, but simplifies some analysis.
\item If $u$ is too large then constant-time arithmetic
  operations becomes an unreasonable assumption. Thus, we require
  ${u\le \poly(n)}$.
  \end{itemize}
\end{rmk}

\input{two_bins.tex}

\section{Composite Moduli}
\label{sec:Z}
In this section we study the affect of replacing the standard
prime modulus in $\LH$ with a composite modulus. 
In addition to being an intrinsically interesting question, we
see in \cref{sec:R} that $\LH$ with composite moduli arises
naturally in the study of $\LH$ over the reals.
Primes are more well-behaved than composite numbers when used as
moduli because in $\F_p$ all non-zero elements have inverses.
However, \cref{fact:numdivs} and \cref{fact:toitent} indicate that
while $\Z_m$ could have a large quantity of elements with varying
degrees of ``degeneracy", there are also guaranteed to
be a substantial number of relatively well-behaved elements.

To bound the extent to which $\Z_m$  is worse than $\F_p$ we
begin by defining \defn{Smart $\LH$} ($\SLH$) where the multiplier is chosen
randomly from $\Z_m^\times$ rather than $\Z_m$. Then, we show
that the maxload of standard $\LH$ is at most 
$\tau(m)$-times larger than that of $\SLH$. 
We conclude by demonstrating that the standard $\sqrt{n}$ maxload
bound for prime moduli, and even \cite{knudsen_linear_2017}'s
$\widetilde{\bigO}(n^{1/3})$ bound can be translated with
several modifications to the composite integer setting.

Now we formally discuss our hash functions.
\begin{defin}
  Fix $n\in \N, m\in \Z$.
  We define two hash families, parameterized by $a\in
  [m]_{\setminus 0}, b\in [m]$, consisting of functions
  $h_{a,b} : [m] \to [n]$.
  \begin{enumerate}
\item In \defn{Blocked Hashing}, denoted $\blockZm$, 
  $$h_{a,b}(x) = \floor{\frac{\posmod_m(ax+b)}{m / n}}.$$
\item In \defn{Strided Hashing}, denoted $\strideZm$,
  $$h_{a,b}(x)= \posmod_n(\posmod_m(ax+b)).$$
  \end{enumerate}
  % The \defn{bin size} is $m/n$, which corresponds (ignoring
  % rounding) to the number of $x\in [m]$ that map to any single value. 
  % A \defn{bin} refers to the elements that hash to the same bin.
  % For instance, in blocked hashing bins are of the form 
  % $$[m] \cap [i\cdot m/n, (i+1)\cdot m/n).$$

  We define $\blockFp, \strideFp$ to be  $\blockZm,\strideZm$ for
   $m=p\in \PRM$.

  As noted in \cref{rmk:shiftmatterstwobins}, the shift term
  ``$+b$" will not impact the maxload by more than a
  factor-of-$2$. For this section a factor-of-$2$ difference is
  inconsequential so we will omit the shift term for simplicity.
\end{defin}

A priori, blocked and strided hashing seem somewhat different. 
In \cite{knudsen_linear_2017} Knudsen gives the necessary idea to
show an equivalence up to a factor-of-$2$ between $\blockFp$ and  $\strideFp$. The
reduction is not spelled out explicitly in
\cite{knudsen_linear_2017}, so we include a proof in \cref{sec:F}.
For composite integers the situation is slightly
more delicate. In particular, if $\gcd(m,n)$ is large then
$\strideZm$ behaves extremely poorly for some
$X$ while $\blockZm$ does not.

\begin{prop}\label{prop:blockZsucks}
  Let $m=k\cdot n$ for some  $k\in \N$.
  There exists an $n$-element set
  $X\subset [m]$ on which $\strideZm$ has expected maxload  $n$.
\end{prop}
\begin{proof}
 Let  $X=k\cdot [n]$. Then  $\posmod_n(\modm(ax)) = 0$
 for all $x\in X$ regardless of $a$. Thus, all $x\in X$
 always hash to bin $0$ so the maxload is $n$.
\end{proof}

On the other hand, as long as $\gcd(m,n)$ is small then
$\strideZm,\blockZm$ achieve similar maxload.
\begin{prop}\label{prop:blockZisok}
  Let $m\perp n$. For any $X$ the maxload of $\strideZm$ and
  $\blockZm$ differ by at most a factor-of-$2$.
\end{prop}
\begin{proof}
  Because $m,n$ are coprime, $n$ has a multiplicative inverse
  in $\Z_m$. Thus, we can apply the same argument from
  \cref{prop:blockstrideF}. 
  That is, if $Y\subset X$ is the set of elements mapping to a
  fullest bin under $\blockZm$ with $a=a_0$, then for
  $a=\modp(n\cdot a_0)$ $\strideZm$ has maxload at least
  $|Y|/2$. Similarly, if $S\subset X$ is the set of elements
  mapping to the fullest bin under  $\strideZm$ with
  $a=a_0$ then for $a=\modp(n^{-1} a_0)$ $\blockZm$ has
  maxload at least  $|S|/2$.
\end{proof}

\cref{prop:blockZisok} and \cref{prop:blockZsucks} teach us that
for composite integer $\LH$ it is more robust, but essentially
equivalent as long as $\gcd(m,n)$ is small, to consider
$\blockZm$ than $\strideZm$. For the remainder of the paper we
restrict our attention to $\blockZm$, which we abbreviate to $\LH_m$.

Now we formally define the variant of $\LH_m$ that partially
fixes the problem of $m$ being composite.
\begin{defin}\label{defn:slh}
  In \defn{Smart $\LH$} ($\SLH_m$) we select $a$ randomly from
  $\Z_m^{\times}$ and then map $$x\mapsto
  \floor{\frac{\modm(ax)}{m/n}}.$$
\end{defin}
Surprisingly, we will show that the performance of $\LH_m$ is not
too far from that of $\SLH_m$, especially if $m$ has few divisors.
We use the following notation:

\begin{defin}
Let random variable $M_{\LH}(m,X)$ be the maxload incurred by
$\LH_m$ on $X$. 
Let 
$$M_{\LH}(m,n) = \max_{\substack{X\subset [p]\\ |X|=n}} \E[M_{\LH}(m,X)].$$
Analogously define $M_{\SLH}(m,X), M_{\SLH}(m,n)$. 
\end{defin}

\begin{theorem}\label{thm:LHSLH}
    Let $f$ be a monotonically increasing concave function with $M_{\SLH}(m,n)\le
    f(n)$. Then,
    $$M_{\LH}(m,n) \le \tau(m) \cdot f(n).$$
  \end{theorem}
  \begin{proof}
    Fix any $n$-element set $X\subset [m]$.
    % Let $p\in \PRM$. Then, $$\Pr[\nu_p(a)=i] \le 1/p^i.$$
    For $d\mid m$, define $\setof{I_{i,d}}{i\in [d]}$ as the
    following partition of $[m]$ into $d$ size $m/d$ blocks:
    $$I_{i,d} = i\cdot m/d + [m/d].$$
    Define $X_{i,d} = X\cap I_{i,d}$
    and let $G_d$ be the event  $\gcd(a,m)=d$.
    We have the following chain of inequalities:

  \begin{align}
&\E[M_{\LH}(m,X)] \nonumber\\
&= \sum_{d\mid m}\Pr[G_d]\cdot \E[M_{\LH}(m,X) \mid G_d]
\label{eqchainSLH1}\\
&\le \frac{1}{d}\sum_{d\mid m}\E[M_{\LH}(m,X) \mid G_d] \label{eqchainSLH2}\\
&\le \frac{1}{d}\sum_{d\mid m}\sum_{i\in [d]}\E[M_{\LH}(m,X_{i,d}) \mid G_d]\label{eqchainSLH3} \\
&\le \frac{1}{d}\sum_{d\mid m}\sum_{i\in [d]}\E[M_{\SLH}(m/d,X_{i,d})] \label{eqchainSLH4}\\
&\le \frac{1}{d}\sum_{d\mid m}\sum_{i\in
[d]}M_{\SLH}(m/d,|X_{i,d}|) \label{eqchainSLH5}\\
&\le \sum_{d\mid m} \frac{1}{d}\sum_{i\in
[d]}f(|X_{i,d}|) \label{eqchainSLH6}\\
&\le \sum_{d\mid m}f(n/d) \label{eqchainSLH7}\\
&\le \tau(m)\cdot f(n) \label{eqchainSLH8}.
  \end{align}
  We now justify the inequalities.
  \begin{itemize}
    \item \cref{eqchainSLH1}: Law of total expectation.
    \item \cref{eqchainSLH2}: $\Pr[G_d]\le 1/d$, because there
      are $m/d$ multiples of $d$ in $[m]$.
    \item \cref{eqchainSLH3}: We can union bound because 
      $\bigsqcup_{i\in [d]}X_{i,d} = X.$
    \item \cref{eqchainSLH4}: Recall that $X_{i,d}\subset I_{i,d}$, where
      $I_{i,d}$ is a contiguous interval of size $m/d$. 
      Because we are conditioning on $\gcd(m,a)=d$,  
      $\modm(a\cdot I_{i,d})$ consists of every $d$-th element of $[m]$. Having
      elements which are spaced out by $d$ grouped into
      blocks of $m/n$ contiguous elements is
      equivalent to having elements spaced out by $1$
      grouped into blocks of $(m/d)/n$ contiguous elements.
      Formally this is because
      $$\modm(x\cdot d\cdot j) = d\cdot \posmod_{m/n}(x\cdot j).$$
      Modulo $m/d$ the restriction  $\gcd(m,a)=d$ becomes
       $\gcd(m/d, a/d)=1$, i.e., $a/d \perp m/d$. 
       Hence, the expected maxload of $\LH_m$ on $X_{i,d}$ conditional on
       $G_d$ is the same as the expected maxload of $\SLH_{m/n}$
       on $X_{i,d}$. 
    \item \cref{eqchainSLH5}: $M_\SLH(m,n)$ is by definition the
      worst-case value of $\E[M_\SLH(m,X)]$ over all $n$-element
      sets $X$.
    \item \cref{eqchainSLH6}: By assumption $f$ is an upper
      bound on $M_{\SLH}$.
    \item \cref{eqchainSLH7}: $f$ is concave.
    \item \cref{eqchainSLH8}: $f$ is increasing, $\tau$ counts
      the divisors of $m$.
  \end{itemize}

  We have shown the bound \cref{eqchainSLH8} for arbitrary
  $X$, so in particular the bound must hold for worst-case  $X$.
  Hence,
  $M_{\LH}(m,n) \le \tau(m)\cdot f(n).$
  \end{proof}
\begin{rmk}
  \cref{thm:LHSLH} says that increasing concave bounds for
  $M_\SLH$ can be translated to bounds for $M_\LH$ except
  weakened by a factor-of-$\tau(m)$. 
  If $m$ is a power of $2$, a natural setting, then
  $\tau(m) = \log m$.
  Even for worst-case $m$ \cref{fact:numdivs} asserts $\tau(m)\le
  m^{o(1)}$. So, $\SLH_m$ and $\LH_m$ have quite similar
  behavior.
\end{rmk}

Now we analyze the performance of $\SLH_m$. First we give an
argument based on the trivial $\sqrt{n}$ bound for $\blockFp$.
Afterwards we apply similar modifications to
\cite{knudsen_linear_2017}'s proof of the
$\widetilde{\bigO}(n^{1/3})$, along with some new modifications
specific to \cite{knudsen_linear_2017}'s proof to translate the
$\widetilde{\bigO}(n^{1/3})$ to $\SLH_m$.

% \begin{prop}
% \todo{this is probably not worth saying twice.}
%   \label{prop:sqrtnZ}
%   $\SLH$ on $\block{\Z_{2^{\ell}}}$ achieves expected maxload at most
%   $\bigO(\sqrt{n})$.
% \end{prop}
% \begin{proof}
%   Say that $x,y \in X, x\neq y$ are \defn{linked} if $\gcd(x-y,2^{\ell}) >
%   2^{\ell}/n$ and \defn{unlinked} otherwise.
%   If $x,y$ are linked, then they can't collide. This is because
%   if $\gcd(x-y,2^{\ell})=2^{j} > 2^{\ell}/n$ then $\gcd(a(x-y)\bmod
%   2^{\ell},2^{\ell}) = 2^{j}$ due to $a$ being odd  because we are doing $\SLH$, so $a$
%   is chosen relatively prime to $2^{\ell}.$
%   But this means that $ax-ay > 2^{\ell}/n$, i.e. $x,y$ fall in
%   separate bins.
%   If $x,y$ are unlinked, then they collide with probability
%   $\bigO(1 / n)$. In particular, $a(x-y)$ will range uniformly
%   over all the bins as long as $\gcd(x-y,2^{\ell}) < 2^{\ell}/n$,
%   so the probability of $x-y$ being sufficiently small is at most
%   say $\frac{2}{n}$.

%   Hence, the expected number of pairs which collide is, by
%   linearity of expectation, $\bigO(n^2 / n) =\bigO(n),$ 
%   meaning that the expected maxload is at most $\bigO(\sqrt{n})$
%   by Jensen's Inequality ($\sqrt{\cdot}$ is concave).
% \end{proof}
\begin{theorem} \label{prop:sqrtnZ}
  $$M_{\SLH}(m,n) \le \bigO(\sqrt{n\log\log n}).$$
\end{theorem}
\begin{proof}
  We say $x,y$ \defn{collide}, with respect to $a=a_0$,
  if they hash to the same bin for $a=a_0$.
  As in the $\sqrt{n}$ bound for $\blockFp$ we bound the
  maxload by counting the expected number of collisions and
  comparing this with the number of collisions guaranteed by a
  certain maxload. 
  The difficulty in the proof for $\SLH_m$ is that the
  probability of  $x,y\in X$ colliding is not as simple as in
  $\blockFp$ where all pairs collide with probability $1/n$.
  To handle this, we make the following definition:

  \begin{defin}
  Distinct $x,y\in X$ are
  \defn{linked} if 
  $$\gcd(x-y,m) > m/n,$$ 
  and \defn{unlinked} otherwise.
  \end{defin}

  \begin{claim}\label{clm:linkedcollidesqrt}
    Linked $x,y$ never collide. 
  \end{claim}
  \begin{proof}
  If $\gcd(x-y,m)=k > m/n$ and $a$ is the randomly chosen
  multiplier from $\Z_m^{\times}$ then 
  $$\gcd(\modm(a\cdot (x-y)),m) = k$$
  because $a\perp m$.
  But then 
  $$\circabs_m(ax - ay) \ge k > m/n,$$
  so $x,y$ fall in different bins.
  \end{proof}
  \begin{claim}\label{clm:unlinkedcollidesqrt}
    Unlinked $x,y$ collide with probability at most 
    $$\bigO\left(\frac{\log\log n}{n}\right).$$
  \end{claim}
  \begin{proof}
  When $x,y$ are unlinked, $\modm(a(x-y))$ would range uniformly
  over the bins if $a$ was chosen uniformly from $[m]$.
  However, in $\SLH_m$ this uniformity is not obvious.
  Fortunately, \cref{fact:toitent} ensures that each $a\in
  \Z_m^{\times}$ occurs with probability at most $\frac{2\log\log
  m}{m}$, which is not much larger than $\frac{1}{m}$.
  In particular, this implies that the probability of $x,y$ 
  colliding is at most
  $$\frac{m}{n} \cdot \frac{2\log\log m}{ m} \le
  \bigO\left(\frac{\log\log n}{n}\right).$$
  \end{proof}

  Now that we have shown 
  \cref{clm:linkedcollidesqrt} and \cref{clm:unlinkedcollidesqrt}
  the proof continues in the same
  way as for $\blockFp$.
  The expected number of collisions gives a bound on maxload:
  if we have maxload $m$ then there must be at least
  $\binom{m}{2} = \Theta(m^{2})$ collisions.
  By Jensen's inequality and the convexity of $x\mapsto x^2$ we
  have $$\E[M_{\SLH}(m,X)^2]\ge \E[M_{\SLH}(m,X)]^2.$$
  We can also count the expected number of collisions directly
using \cref{clm:linkedcollidesqrt} and \cref{clm:unlinkedcollidesqrt};
  doing so, we find that the expected number of collisions is
  $$\bigO(n \log\log n).$$
  Comparing our two methods of counting collisions we find:
  $$\E[M_{\SLH}(m,X)]\le \bigO(\sqrt{n\log\log n}),$$
  for any $X$, and in particular for the worst-case $X$.
\end{proof}

Now we strengthen \cref{prop:sqrtnZ} to \cref{thm:Zm1_3}. 
Most of the proof of \cref{thm:Zm1_3} is the same as
\cite{knudsen_linear_2017}'s proof for $\blockFp$, but it is difficult to
black-box the previous result because our modifications permeate
the whole proof. Thus, we highlight here only the key
modifications needed to adapt the argument to $\SLH_m$,
and provide a full formal proof in \cref{sec:formalpfZm13}.

\begin{theorem}\label{thm:Zm1_3}
  $$M_{\SLH}(m,n)\le \widetilde{\bigO}(n^{1/3}).$$
\end{theorem}
\begin{proof}[Sketch of key modifications]
  The most important idea for translating
  \cite{knudsen_linear_2017}'s proof to composite moduli is actually
  already included in the statement of \cref{thm:Zm1_3}: namely,
  the idea to use $\SLH_m$ rather than $\LH_m$.
  This decision is justified by \cref{thm:LHSLH}.

  Crucially, in $\SLH_m$ all choices of $a$ have inverses.
  We call a choice of $a$ \defn{bad} if it results in large
  maxload. We analyze a refinement of the bins to \defn{close
  pairs}, which are elements that map very close to each other
  (much closer than $m/n$). Because all $a$ are invertible, we can look at the
  pre-image of the set of $y\in aX$ which mapped to the fullest
  bin. Analyzing this pre-image gives us many close pairs per
  each bad $a$.

  In \cite{knudsen_linear_2017}'s proof he next restricts to a
  certain set $B$ of bad $a$, namely prime bad  $a$ of a certain
  size. 
  We define $B$ similarly, although our $B$ is of course smaller
  because we not only disallow composite $a$, but also must
  disallow $a$ which are prime factors of $m$. However, because
  $m$ has at most $\bigO(\log m)$ prime factors our set $B$ is
  still large enough for the proof to go through.

  The next key component of \cite{knudsen_linear_2017}'s proof is
  to compute the expected number of close pairs. In the case of
  $\blockFp$ this is trivial, because the probability of being a
  close pair is uniform across all pairs.
  For $\blockZm$ we no longer have this uniformity property. 
  However, as in the proof of \cref{prop:sqrtnZ} we remedy this
  problem by considering ``linked" and ``unlinked" pairs. 
  We say $x,y$ are linked if $\gcd(x,y)$ is sufficiently large;
  we show that linked $x,y$ cannot collide. For unlinked $x,y$
  the probability that $x,y$ collide is similar to in the case of
  a prime modulus, and can be bounded in a uniform way.
  Combined, this allows us to compute the number of expected
  close pairs.

  Then, using the same argument as Knudsen we count the number of
  close pairs in a different way. Comparing the two methods of
  counting close pairs yields a bound on maxload.
\end{proof}

\begin{cor}\label{cor:translate}
  $$M_{\LH}(m,n) \le n^{1/3 + o(1)}.$$
\end{cor}
\begin{proof}
  This follows immediately from combining \cref{thm:LHSLH} and
  \cref{thm:Zm1_3}.
\end{proof}

% In \cref{thm:Zm1_3} we classified pairs $x,y\in X$ into two groups:
% \begin{itemize}
%   \item $x,y$ are ``linked" if $\gcd(x-y,m)$ is large. Linked
%     $x,y$ never land in the same bin.
%   \item $x,y$ are ``unlinked" if $\gcd(x-y,m)$ is small. Unlinked
%     pairs intuitively behave like any pair relative to a prime
%     modulus. In particular, for most unlinked pairs, $x,y$ will
%     be end up in uniformly random and independent bins.
% \end{itemize}
% It seems plausible that the concept of linked and unlinked pairs
% could be used to prove the following generalization of
% \cref{thm:Zm1_3}:
In \cref{cor:translate} we have translated the best known maxload
bound for $\blockFp$ to the composite modulus setting, by
altering \cite{knudsen_linear_2017}'s proof. It would be very
interesting to prove a full reduction between $\blockFp$ and
$\blockZm$. We leave this as an open problem.
\begin{question}\label{question:equivalenceFZ}
  Are the worst-case maxloads of $\blockFp$ and $\blockZm$ the same
  up to low-order factors?
\end{question}
% \cref{conj:translate} seems hard, because rather than translating
% a specific bound we must show a general reduction; we leave this
% as an open problem.
% Combined with \cref{thm:LHSLH}, \cref{conj:translate} would
% imply that maxload relative to composite moduli and prime moduli
% is essentially the same.
% However, it is not obvious how to apply the linked and unlinked
% pair analysis
Although fully resolving \cref{question:equivalenceFZ} seems
difficult, one important special case is comparing their behavior
on random inputs. We resolve this special case in
\cref{prop:randominputZ} in which we once again show that the
number of ``degenerate elements" in $\Z_m$ is small.
\begin{prop}\label{prop:randominputZ}
  Let $x_1,\ldots, x_n$ be independently randomly selected
  from $\Z_m$. 
  The expected maxload of $\SLH_m$ on $x_1,\ldots, x_m$ is 
  $\bigO\left(\frac{\log n}{\log\log n}\right)$.
\end{prop}
\begin{proof}
  If $x_i$ has $\gcd(x_i,m) < m/n$ then the probability of $x$
  landing in any particular bin is $\bigO(1/n).$

  Fix $x\in [m]$ with $\gcd(x,m)>m/n$. We decompose $x$ into $x =
  yz$ where $y \mid m, z\perp m$, $y >m/n$, and thus $z<n$.
  Because $m$ has at most $m^{o(1)}$ divisors
  (\cref{fact:numdivs}), there can be at most $nm^{o(1)}$ such
  $x.$
  Hence, the probability that $x_i$ and $m$ share such a
  large factor is bounded by $\frac{nm^{o(1)}}{m}$. 
  
  Because $m\ge \Omega(n^6)$ (\cref{rmk:assumesize}), we can take a union bound to deduce
  that with probability at least $1-1/n^{3}$ no $x_i$ shares a
  large common factor with $m$. Hence, the event that some
  $\gcd(x_i, m)$ is large contributes at most $\bigO(1)$ to the
  expected maxload. 
  As noted, if all $x_i$ have $\gcd(x_i, m) < m/n$ then
  each $x_i$ has probability $\bigO(1/n)$ of falling in each
  bin, and the bins that each $x_i$ fall in are independent.
  Then by an almost identical analysis to the standard problem of
  throwing $n$ balls into $n$ bins we clearly achieve the desired maxload
  bound.
\end{proof}

\input{sec_real.tex}

\paragraph{Acknowledgements}
The author thanks William Kuszmaul and Martin Farach-Colton for
proposing this problem and for helpful discussions.
% \bibliographystyle{plain}
% \bibliography{refs}
\medskip

\printbibliography
\clearpage


\appendix

\section{Blocking and Striding for $\F_{p}$}
\label{sec:F}

In this section we provide a proof of the fact that $\blockFp$
and $\strideFp$ have the same worst-case expected maxload, up to
a factor-of-$2$. The ideas for this proof are due to
\cite{knudsen_linear_2017}. However, \cite{knudsen_linear_2017}
does not explicitly describe the reduction between $\blockFp$ and
$\strideFp$. Thus, we include this proof for sakes of completeness
and convenience to the reader.

\begin{prop}
  \label{prop:blockstrideF}
  Fix $p\in \PRM,n\in \N, X\subset [p]$ with $|X|=n.$
  The expected maxload of $\strideFp$ and
  $\blockFp$ on $X$ differ by at most a factor-of-$2$.
\end{prop}
\begin{proof}
  For $a_0\in \pnozero$, let $M$ be the maxload incurred by
  $\blockFp$ when using $a=a_0.$ There must be 
  a set of $M$ elements $Y\subset X$ and a bin $k\in [n]$
  such that all $y\in Y$ hash to bin $k$ (for $a=a_0$). 
  In other words, for each $y\in Y$ we
  have $$\frac{kp}{n} \leq \modp(ya_0) < \frac{(k+1)p}{n}.$$
  Let $i_y \in [\floor{p/n}]$ denote $\modp(ya_0)-kp/n$. Then,
  $$n\cdot \modp(y a_0) = kp + i_y n.$$ 
  Let $a_1=\modp(n\cdot a_0)$.
  It is tempting to say that all $y\in Y$ map to the same bin
  under $\strideFp$ with $a=a_1$, but this is not necessarily
  quite true, because the wrap-around disturbs relative
  distances. Fortunately, this wrap-around induced distortion
  occurs at most once, because $i_y< \frac{p}{n}$. 
  Thus, at least one half of the elements of $Y$, call it $Y'$, is on a single
  side of the wrap-around. All $y'\in Y'$ lie in the same
  bin under $\strideFp$ with  $a_1$, namely bin $\posmod_n(\modp(y' a_1))$.
  Multiplication by $n$ permutes $[p]$, so our analysis shows
  that the expected maxload of $\strideFp$ is at least half
  that of $\blockFp$.

   On the other hand, consider $a_0' \in [p]$ so that
   $\strideFp$ incurs  maxload  $M$ when using $a=a_0'.$
   Then there must be a set of $M$ elements $S\subset X$ and a bin
   $c\in [n]$ such that for each $s\in S$
   $$\modp(a_0' s) = j_s n + c,$$ for some $j_s \in [\floor{p/n}]$. 
   Now, for $a_1'=\modp(n^{-1}\cdot a_0')$, where $n^{-1}$
   is the multiplicative inverse of $n$ in $\F_p$, we have
    $$\modp(a_1's) = \modp(n^{-1}a_0's) = j_s + n^{-1}c.$$ 
    These elements lie in an interval of size $p/n$, and so in
    the worst case are split across two bins. Thus, for $a=a_1'$
    $\blockFp$ incurs maxload at least $M/2$.
    As before, multiplication by $n^{-1}$ permutes $[p]$, so the
    expected maxload of $\blockFp$ is at least half that of
    $\strideFp$.
   
\end{proof}

\input{slh13knudsen.tex}

\input{structured_set.tex}

\end{document}
