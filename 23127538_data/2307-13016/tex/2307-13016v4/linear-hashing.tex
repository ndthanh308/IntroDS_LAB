\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2021}
\input{head.tex}

%This is a template for producing LIPIcs articles. 
%See lipics-v2021-authors-guidelines.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for enabling a two-column layout for the author/affilation part (only applicable for > 6 authors), use "authorcolumns"
%for producing a PDF according the PDF/A standard, add "pdfa"

\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository
\nolinenumbers

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle


% \author{Alek Westover}{MIT}
\author{Alek Westover}{MIT, USA}{alekw@mit.edu}{}{}
% \author{Anonymous}{Anonymous}{}{}{}
%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional. Use additional curly braces to indicate the correct name splitting when the last name consists of multiple name parts.

\title{On the Relationship Between Several Variants of the Linear Hashing Conjecture}

%\titlerunning{Dummy short title} %TODO optional, please use if title is longer than one line

% \author{Jane {Open Access}}{Dummy University Computing Laboratory, [optional: Address], Country \and My second affiliation, Country \and \url{http://www.myhomepage.edu} }{johnqpublic@dummyuni.org}{https://orcid.org/0000-0002-1825-0097}{(Optional) author-specific funding acknowledgements}%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional. Use additional curly braces to indicate the correct name splitting when the last name consists of multiple name parts.

% \author{Joan R. Public\footnote{Optional footnote, e.g. to mark corresponding author}}{Department of Informatics, Dummy College, [optional: Address], Country}{joanrpublic@dummycollege.org}{[orcid]}{[funding]}

\authorrunning{Alek Westover} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Anonymous} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\keywords{Linear Hashing} %TODO mandatory; please add comma-separated list of keywords

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93]{Classification (e.g. Full Version, Extended Version, Previous Version}{URL to related version} %linktext and cite are optional

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

% \acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering



%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\abstract{
  In \defn{Linear Hashing} ($\LH$) with $n$ bins on a size
  $u$ universe ${\mathcal{U}=\set{0,1,\ldots, u-1}}$, items
  $\set{x_1,\ldots, x_n}\subset \mathcal{U}$ are placed in
  bins by the hash function
  $x_i\mapsto (ax_i+b)\bmod p \bmod n$
  for some prime $p\in [u,2u]$ and randomly chosen
  integers $a,b \in [1,p]$. The \defn{maxload} of $\LH$ is the
  number of items assigned to the fullest bin. Expected maxload for
  a worst-case set of items is a natural measure of how well $\LH$
  distributes items amongst the bins.

  Despite $\LH$'s simplicity, bounding $\LH$'s worst-case
  maxload is extremely challenging.
  It is well-known that on random inputs $\LH$ achieves
  maxload $\Omega\left(\frac{\log n}{\log\log n}\right)$; this is
  currently the best lower bound for $\LH$'s expected maxload.
  Recently Knudsen established an upper bound of
  $\widetilde{\bigO}(n^{1 / 3})$.
  The question ``Is the worst-case expected maxload of $\LH$
  $n^{o(1)}$?'' is one of the most basic open problems in discrete
  math.

  In this paper we propose a set of intermediate open questions to
  help researchers make progress on this problem.
  We establish the relationship between these intermediate open
  questions and make some partial progress on them.
}

\section{Introduction}
The \defn{hashing problem} is to assign $n$ items from a
universe $\mathcal{U}$ to $\beta$ \defn{bins} so that all bins receive a
similar number of items. In particular, we measure the quality
of a hashing scheme's load distribution by the number of items
in the fullest bin; we refer to this quantity as the \defn{maxload}.
We desire three main properties of a hashing scheme:
(1) small expected maxload for all sets of items, (2) fast
evaluation time, and (3) small description size.

\paragraph{Related Work}
The hashing problem has been extensively studied.
We use the standard parameters $|\mathcal{U}|\in \poly(n)$,
$\beta=n$ in the following discussion. We also assume the
unit-cost RAM model, i.e., that arithmetic operations on
numbers of size $\Theta(\log n)$ can be performed in constant
time. We use the abbreviation $\ell(n) = \frac{\log n}{\log\log n}$.

The hash function which assigns each item independently
randomly to a bin achieves the smallest possible expected
maxload in general, namely $\Theta(\ell(n))$
\cite{mitzenmacher2017probability}.
However, describing a fully random function requires
$\Omega(|\mathcal{U}|\log n)$ bits which is extremely large.
Full independence is not necessary to achieve optimal maxload.
For instance, Carter and Wegman \cite{carter1977universal} show
that degree $\Theta(\ell(n))$ polynomials over a finite
field constitute a $\Theta(\ell(n))$-wise
independent hash family while still achieving maxload
$\Theta(\ell(n))$.
Improving on this result, Celis et al. \cite{celis2013balls}
demonstrate a hash family achieving maxload $\Theta(\ell(n))$
with evaluation time $\bigO(\sqrt{\log n})$.

In fact, it is even possible to achieve optimal maxload with
constant evaluation time, as demonstrated by Siegel in
\cite{siegel_universal_2004}. However, Siegel's hash function
has description size $\poly(n)$.
Furthermore, Siegel proved that it is impossible to
simultaneously achieve optimal maxload, constant evaluation
time, $n^{o(1)}$ description size, and $\Omega(\ell(n))$ independence.
However, this still leaves room for improvement if we do not
require large degrees of independence.

By itself small independence does not give any good bound on
maxload; for example, there are pairwise-independent hash
families with maxload $\Omega\left(\sqrt{n}\right)$ \cite{petershor}.
However, Alon et al. \cite{alon_is_1997} show that the
pairwise-independent hash family of multiplication by random
matrices over $\F_2$ achieves $\bigO(\ell(n) \cdot (\log \log
    n)^2)$ maxload in $\bigO(\log(n))$ evaluation time.

The following question remains open:
\begin{question}
  \label{question:fastandgood}
  Is there a hash family with $\bigO(1)$ machine
  word description whose evaluation requires $\bigO(1)$ arithmetic
  operations that has expected maxload bounded by $n^{o(1)}$?
\end{question}

\paragraph{Linear Hashing ($\LH$)}
$\LH$ \cite{motwani1995randomized, cormen2022introduction,
  sedgewick2014algorithms} is an attractive potential solution to
\cref{question:fastandgood}, trivially satisfying the conditions
of small description size and fast evaluation time.
% $\LH$ heuristically does quite well at spreading out elements
% \cite{sedgewick2014algorithms}.
Despite $\LH$'s simplicity, understanding its
maxload is a notoriously challenging and wide open question.
The best known lower bound on $\LH$'s maxload is $\Omega\left(\frac{\log
    n}{\log\log n}\right)$, whereas the best known upper bound is
$\widetilde{\bigO}(n^{1/3})$ due to an elegant combinatorial
argument of Knudsen \cite{knudsen_linear_2017}.

Let $\mathcal{U} = \set{0,1,\ldots, u-1}$ denote the universe.
To keep the introduction simple we abuse notation and let $x
  \bmod m$ denote the unique representative of the equivalence
class $x +m\Z$ lying in $[0,m)$.
In most textbooks (e.g., \cite{motwani1995randomized}) $\LH$ is
defined placing $x\in \mathcal{U}$ in bin
% \begin{equation}\label{eq:LHdefn1}
\[(ax+b)\mod p \mod \beta\]
% \end{equation}
for prime $p\in [u, 2u]$
and randomly chosen integers $a,b \in [1,p]$;
we refer to this as \defn{strided hashing}.
In \cite{dietzfelbinger1997reliable} Dietzfelbinger et al. give an
alternative definition placing $x\in \mathcal{U}$ in bin
% \begin{equation}\label{eq:LHdefn2}
\[  \floor{ \frac{(ax+b)\mod p}{p/\beta} };\]
% \end{equation}
% We refer to \cref{eq:LHdefn1} as \defn{strided hashing} and
% \cref{eq:LHdefn2} as \defn{blocked hashing}.
we refer to this as \defn{blocked hashing}.

The \defn{maxload} of a hash family with respect to an $n$-element set
$X\subset\mathcal{U}$ is a random variable counting the number of
$x\in X$ hashed to the fullest bin under a randomly chosen hash
function. We aim to minimize the expected maxload for worst-case
$X$.

For $\beta=n$ Knudsen \cite{knudsen_linear_2017} implicitly observed that
the maxload of blocked and strided hashing differ by
at most a factor-of-$2$; this follows from our
\cref{prop:blockZisok}. Roughly this equivalence follows by observing that
if blocked hashing has large maxload for $a=a_0,$ then strided
hashing will have large maxload for $a=a_0 n \bmod p$. Similarly,
if strided hashing has large maxload for $a=a_1$ then blocked
hashing will have large maxload for $a=a_1 n^{-1}\bmod p$, where
$n^{-1}$ is the multiplicative inverse of $n$ in $\F_p$.
Thus, classically blocked and strided hashing are
essentially equivalent. On the other hand we show that blocked hashing
generalizes more readily.\footnote{In \cref{prop:blockZsucks} we
  show that strided hashing does not generalize cleanly to composite
  moduli. Furthermore, there is no natural way to generalize
  strided hashing to real numbers.}
Thus, the majority of our results will concern blocked hashing.
We further simplify blocked hashing by
removing the $+b$ \defn{``shift term''} obtaining
\begin{equation} \label{eq:LHdefn3}
  x\mapsto \floor{\frac{ax \bmod p}{p/\beta}}.
\end{equation}
Removing the shift term also will not impact the maxload by more
than a factor-of-$2$: changing the shift term at most splits
fullest bins in half or merges parts of adjacent bins
into a single new fullest bin.
For the rest of this section \defn{Simple $\LH$} will refer to
the hashing scheme defined in \cref{eq:LHdefn3}.
We propose \cref{q:isLHsubpoly} as a potential solution to
\cref{question:fastandgood}.
\begin{question}\label{q:isLHsubpoly}
  Is the worst-case expected maxload of Simple $\LH$ bounded by $n^{o(1)}$?
\end{question}

% It is well known that pairwise independence is not sufficient to
% get any bound on maxload better than $\bigO(\sqrt{n})$
% \cite{petershor}.
% \begin{itemize}
%   \item Select $k\gets [n],\pi\gets S_{n-1}$ uniformly randomly.
%   \item Each ball $i\in [n-1]$ is placed in bin $k$ with
%     probability  $1/\sqrt{n}$ and in bin $k+\pi_i$ otherwise.
%   \item Ball $n$ is placed independently in a random bin.
% \end{itemize}
%  Here, the expected number of balls in any fixed bin is
%  $\bigO(1)$ (this is guaranteed for any pairwise independent hash
%  family by linearity of expectation), but the expected number of
%  balls in the fullest bin is $\Omega(\sqrt{n})$.

\subsection{Our Results}
In this paper we propose a set of intermediate open questions to
help researchers make progress on \cref{q:isLHsubpoly}.
We establish the relationship between these intermediate open
questions and make some partial progress on them.
Except for in \cref{sec:twobins} we take $\beta=n$ bins.

\paragraph{Connecting Prime and Integer Moduli}
In \cref{sec:Z} we consider the importance of
using a prime modulus for $\LH$.
Conventional wisdom (e.g., \cite{cormen2022introduction}) is that
using a non-prime modulus is catastrophic. Using a
non-prime modulus is complicated by the fact that in a general
ring, as opposed to a finite field, non-zero elements can
multiply to zero.
Fortunately for any $m$ there is a reasonably large subset of
$\Z_m$ which forms a group under multiplication. The subset is
$\Z_m^{\times }$: the set of integers in $\Z_m$ coprime to $m$.
We define an alternative version of $\LH$ called \defn{Smart} $\LH$
where $a$ is chosen uniformly from $\Z_m^{\times}$ rather than
$\Z_m$. We show:

\begin{customthm}{\cref{thm:LHSLH}}
  Fix integer $m\in \poly(n)$. The expected maxloads of
  Smart $\LH$ with modulus $m$ and Simple $\LH$ with modulus $m$
  differ by at most a factor-of-$n^{o(1)}$.
\end{customthm}
Intuitively, Smart $\LH$ with composite modulus behaves somewhat
similarly to Simple $\LH$ with prime modulus.
This similarity allows us to, with several new ideas, translate Knudsen's proof
\cite{knudsen_linear_2017} of a $\widetilde{\bigO}(n^{1/3})$
bound on Simple $\LH$'s maxload for prime modulus to the
composite modulus setting, giving:
\begin{customthm}{\cref{thm:Zm1_3}}
  The expected maxload of Smart $\LH$ is at most
  $\widetilde{\bigO}(n^{1/3})$.
\end{customthm}

Part of why \cref{thm:Zm1_3} is interesting is that using
\cref{thm:Zm1_3} in \cref{thm:LHSLH} gives:
\begin{customthm}{\cref{cor:translate}}
  The expected maxload of Simple $\LH$ with composite modulus is
  at most $n^{1/3+o(1)}$.
\end{customthm}
In particular, in \cref{cor:translate} we have translated the
state-of-the-art bound for maxload from the prime modulus setting
to the composite modulus setting.
This gives tentative evidence that the behavior of $\LH$ with
composite modulus may actually be the same as that of $\LH$ with
prime modulus. We leave this as an open question:
\begin{customthm}{\cref{question:equivalenceFZ}}
  Is the worst-case maxload of composite modulus $\LH$ the
  same, up to a factor-of-$n^{o(1)}$, as that of prime
  modulus $\LH$?
\end{customthm}

\paragraph{Connecting Integer and Real Moduli}
In \cref{sec:R} we consider \defn{Real $\LH$} where the
multiplier ``$a$'' in \eqref{eq:LHdefn3} is chosen
from $\R$. Initially the change to a continuous setting seems
to produce a very different problem.
In this continuous setting one equivalent way of formulating
\cref{q:isLHsubpoly} is:
\begin{question}[``Crowded Runner Problem'']
  \label{question:dual}
  Say we have $n$ runners with distinct speeds $x_1,x_2, \ldots,
    x_n \in (0,1)$ starting at the same location on a length $1$
  circular race-track. $a\in (0,1)$ is chosen randomly and all
  runners run from time $0$ until time $a$.
  Is it true that on average the largest ``clump'' of runners,
  i.e., set of runners in single interval of size $1/n$, is of
  size at most $n^{o(1)}$?
\end{question}
As formulated in \cref{question:dual} the problem becomes a
dual to the famous unsolved ``Lonely Runner Conjecture''
of Wills \cite{wills1967zwei}  and Cusick \cite{cusick1982view}
as formulated in \cite{bienia1998flows}. In the Lonely Runner
Conjecture the question is for each runner whether there is any
time such that the runner is ``lonely'', i.e., separated from all
other runners by distance at least $1/n$. Our question is whether for
most time steps there is any runner that is ``crowded'',
i.e., with many other runners within an interval of size $1/n$
around the runner.
The difficulty of the Lonely Runner Conjecture may be indicative
that the ``Crowded Runner Conjecture'' is also quite difficult.

In \cref{thm:itisreal} we show a surprising equivalence between
$\LH$ for integer and real moduli. More specifically, in our
lower bound on Real $\LH$ we compare to a potentially stronger
version of integer modulus $\LH$ termed \defn{Random Modulus
$\LH$} where the modulus is not simply the universe size $u$, but
rather a randomly chosen (and likely composite) integer in $[u/2,
u]$. Random Modulus $\LH$ is clearly at most a factor-of-$2$
worse that Simple $\LH$, but it is not obvious whether it is any
better; we leave this as an open question:
\begin{question}
  Does Random Modulus $\LH$ achieve asymptotically smaller
  expected maxload than Simple $\LH$?
\end{question}

Formally the equivalence between Real $\LH$ and Random Modulus
$\LH$ can be stated as follows:
\begin{customthm}{\cref{thm:itisreal}}
  Let $f(n)$ be a lower bound on Random Modulus $\LH$'s expected
  maxload that holds for all sufficiently large universes.
  Let $g(n)$ be an upper bound on Simple $\LH$'s expected maxload
  that holds for all sufficiently large universes.
  Let $M_\R$ denote the expected maxload of
  Real $\LH$. Then
  \[
  \Omega\paren{\frac{f(n)}{\log\log n}} \le M_\R \le \bigO(g(n)).
\]
\end{customthm}
The proof of this theorem involves several beautiful
number-theoretical lemmas and is one of our main technical
contributions.

This equivalence between the real and integer versions of $\LH$ shows
that \cref{q:isLHsubpoly} may not fundamentally be about prime
numbers or even integers.

% In \cref{sec:nice} we analyze a particularly structured set
% which a priori is a reasonable candidate for a set which might
% incur large maxload; note that the maxload of an average set is
% of course small. However, we show that this set actually incurs
% small maxload. 

\paragraph{A Simpler Problem: The Two Bin Case}
Finally in \cref{sec:twobins} we consider an even simpler question than
\cref{q:isLHsubpoly}:
\begin{question}\label{question:twobincase}
  What can be said about Simple $\LH$ in the case where there are only
  $\beta=2$ bins?
\end{question}

Intuitively, Simple $\LH$ should place roughly half of the balls
in each bin. In fact, one might even conjecture (especially if we
believe that Simple $\LH$ does well on many bins) that Simple
$\LH$ should achieve a Chernoff-style concentration bound on the
number of balls in each of the two bins. What makes
\cref{question:twobincase} interesting is that even analyzing the
\emph{expected} maxload of Simple $\LH$ in the two-bin case is
already a nontrivial problem (because, unlike non-simple $\LH$,
Simple $\LH$ is not pairwise independent). In fact, it may be the
simplest non-trivial problem that one can state about Simple
$\LH$.

In \cref{sec:twobins} we prove a partial result towards
\cref{question:twobincase}. We show that, even though some pairs
of elements may have probability as large as $2/3$ of colliding
in their bin assignment, one can nonetheless establish a $(1 +
o(1)) n/2$ bound on the expected maxload:
\begin{customthm}{\cref{thm:dontneedb}}
  Simple $\LH$ with $\beta=2$ bins has expected maxload at most
  $n/2 + \widetilde{\bigO}(n^{1/2}).$
\end{customthm}

We propose proving stronger results in the two-bin setting as a
fruitful direction for future research. For example, establishing
Chernoff-style concentration bounds on the maxload in the two-bin
case would constitute the strongest evidence to date that Simple
$\LH$ is a good load-balancing function.


\section{Preliminaries}
\paragraph{Set Definitions}
We write $\PRM$ to denote the set of primes, $\F_p$ for $p\in \PRM$ to denote the
finite field with $p$ elements, and $\Z_m$ for $m\in \N$ to denote
the ring $\Z / m\Z.$

For $a,b\in \R$ we define
$[a,b]=\setof{x\in \R}{a\le x\le b}.$
For $n\in \N$ we define
$[n] = \set{0,1,\ldots, n-1}$, and 
$[n]_{\setminus 0} = [n]\setminus \set{0}.$
For $p\in \N,x\in \R$ we define $\modp(x)$ as
the unique number in the set
$(x+p\Z) \cap [0,p),$
and define
$\circabs_p(x)= \min(\modp(x), \modp(-x)).$
For $x\in \Z$, $\modp(x)$ is the positive remainder
obtained when $x$ is divided by $p$ and $\circabs_p(x)$ is the
smallest distance to an element of $p\Z$ from $x$.
However these functions are also defined for $x\in \R\setminus \Z$.

For $a\in \R$ and set $X\subset \R$ we define
$a+X = \setof{a+x}{x\in X},$
$a\cdot X = \setof{a\cdot x}{x\in X},$
$\modp(X) = \setof{\modp(x)}{x\in X}.$


\paragraph{Number Theoretic Definitions}
For $x,y\in \N$ we write $x\perp y$ to denote that  $x,y$ are
coprime, and $x\mid y$ to denote that $x$ divides $y$.
We write $\gcd(x,y)$ to denote the largest $k$ satisfying both  $k\mid
  x$  and $k\mid y$.
% We use $\nu_p(n)$ to denote the exponent of the largest
% power of $p$ dividing $n$. 
A \defn{unit}, with respect to an implicit ring, is an element
with an inverse. For $m\in \N$ we define $\Z_m^{\times}$ as the
set of units in $\Z_m$. That is,
$\Z_m^{\times } =\setof{k \in [m]}{k\perp m}.$ We write
$\phi$ to denote the Euler-Toitent function, which is defined to
be $\phi(m)=|\Z_m^{\times }|$. We write $\tau(m)$ to denote the number of
divisors of $m$.
The following two facts (see, e.g.,
\cite{hardy1979introduction}), will be
useful in several bounds:
\begin{fact}\label{fact:numdivs} $\tau(n) \le 2^{\bigO(\log n / \log\log n)} \leq n^{o(1)}.$
\end{fact}
\begin{fact}\label{fact:toitent}
  $\frac{n}{2\log\log n} \le \phi(n)< n.$
\end{fact}

\paragraph{Hashing Definitions}
A \defn{hashing scheme} mapping universe $[u]$ to $\beta$ bins is a set of functions
$\setof{h_i: [u]\to [\beta]}{i\in I}$
parameterized by $i\in I$ for some set $I$.
We say $h_i$ sends element  $x$ to bin $h_i(x)$.
The \defn{maxload} of $\setof{h_i}{i\in I}$ with respect to set $X$ for
parameter choice $i_0\in I$ is
\[
\max_{k\in [\beta]} \left|\setof{x\in X}{h_{i_0}(x)=k}\right|.
\]
In other words, maxload is the number of elements mapped to the
fullest bin.
We are concerned with bounding the expected maxload of hashing
schemes with respect to uniformly randomly
chosen parameter $i\in I$ for arbitrary $X$.
We will abbreviate uniformly randomly to randomly when the
uniformity is clear from context.

\begin{rmk}\label{rmk:assumesize}
  Our analysis is asymptotic as a function of $n$, the number of
  hashed items. We assume $n$ is at least a sufficiently large constant.
  We also require the universe size $u$ to satisfy
  $n^{6}\le u \le \poly(n)$.
  We adopt these restrictions for the following reasons:
  \begin{itemize}
    \item If $u$ is too small then bounding maxload is not
          interesting. For instance, if $u\in \Theta(n)$ linear
          hashing trivially achieves maxload $\bigO(1)$.
          It is standard to think of the universe as being much larger
          than the number of bins. Our specific choice $u\ge \Omega(n^{6})$ is
          arbitrary, but simplifies some analysis.
    \item If $u$ is too large then constant-time arithmetic
          operations becomes an unreasonable assumption. Thus, we require
          ${u\le \poly(n)}$.
  \end{itemize}
\end{rmk}

\input{composite_moduli.tex}
\input{sec_real.tex}
\input{two_bins.tex}

\paragraph{Acknowledgements}
The author thanks William Kuszmaul and Martin Farach-Colton for
proposing this problem and for helpful discussions.
The author also thanks Nathan Sheffield for several technical discussions
about the bound of \cref{thm:dontneedb}.

% TODO: in submission make sure you comment out the extra part of
% the appendix
% and also comment out the acknowledgements
% but put the extra stuff on arxiv


% \bibliographystyle{plain}
% \bibliography{refs}
% \medskip
% \printbibliography
% \medskip

\bibliography{refs}
\appendix

\input{slh13knudsen.tex}
\input{structured_set.tex}


\end{document}
