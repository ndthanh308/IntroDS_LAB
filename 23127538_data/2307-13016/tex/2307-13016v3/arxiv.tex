\documentclass[twocolumn]{article}[11pt]
\author{Alek Westover}
% \title{Linear Hashing: No Shift, Non-Prime Modulus, For $\R$eal!}
\title{On the Relationship Between Several Variants of \\the Linear Hashing Conjecture}
\input{head.tex}
\begin{document}
\maketitle

\abstract{
  In \defn{Linear Hashing} ($\LH$) with $\beta$ bins on a size
  $u$ universe ${\mathcal{U}=\set{0,1,\ldots, u-1}}$, items
  $\set{x_1,x_2,\ldots, x_n}\subset \mathcal{U}$ are placed in
  bins by the hash function
  $$x_i\mapsto (ax_i+b)\mod p \mod \beta$$
  for some prime $p\in [u,2u]$ and randomly chosen
  integers $a,b \in [1,p]$. The \defn{maxload} of $\LH$ is the
  number of items assigned to the fullest bin. Expected maxload for
  a worst-case set of items is a natural measure of how well $\LH$
  distributes items amongst the bins.

  Fix $\beta=n$. Despite $\LH$'s simplicity, bounding $\LH$'s worst-case
  maxload is extremely challenging.
  It is well-known that on random inputs $\LH$ achieves
  maxload $\Omega\left(\frac{\log n}{\log\log n}\right)$; this is
  currently the best lower bound for $\LH$'s expected maxload.
  Recently Knudsen established an upper bound of
  $\widetilde{\bigO}(n^{1 / 3})$.
  The question ``Is the worst-case expected maxload of $\LH$
  $n^{o(1)}$?" is one of the most basic open problems in discrete
  math.

  In this paper we propose a set of intermediate open questions to
  help researchers make progress on this problem.
  We establish the relationship between these intermediate open
  questions and make some partial progress on them.
}

\section{Introduction}
The \defn{hashing problem} is to assign $n$ items from a
universe $\mathcal{U}$ to $\beta$ \defn{bins} so that all bins receive a
similar number of items. In particular, we measure the quality
of a hashing scheme's load distribution by the number of items
in the fullest bin; we refer to this quantity as the \defn{maxload}.
We desire three main properties of a hashing scheme:
(1) small expected maxload for all sets of items, (2) fast
evaluation time, and (3) small description size.

\paragraph{Related Work}
The hashing problem has been extensively studied.
We use the standard parameters $|\mathcal{U}|\in \poly(n)$,
$\beta=n$ in the following discussion. We also assume the
unit-cost RAM model, i.e., that arithmetic operations on
numbers of size $\Theta(\log n)$ can be performed in constant
time. We use the abbreviation $\ell(n) = \frac{\log n}{\log\log n}$.

The hash function which assigns each item independently
randomly to a bin achieves the smallest possible expected
maxload in general, namely $\Theta(\ell(n))$
\cite{mitzenmacher2017probability}.
However, describing a fully random function requires
$\Omega(|\mathcal{U}|\log n)$ bits which is extremely large.
Full independence is not necessary to achieve optimal maxload.
For instance, Carter and Wegman \cite{carter1977universal} show
that degree $\Theta(\ell(n))$ polynomials over a finite
field constitute a $\Theta(\ell(n))$-wise
independent hash family while still achieving maxload
$\Theta(\ell(n))$.
Improving on this result, Celis et al. \cite{celis2013balls}
demonstrate a hash family achieving maxload $\Theta(\ell(n))$
with evaluation time $\bigO(\sqrt{\log n})$.

In fact, it is even possible to achieve optimal maxload with
constant evaluation time, as demonstrated by Seigel in
\cite{siegel_universal_2004}. However, Seigel's hash function
has description size $\poly(n)$.
Furthermore, Seigel proved that it is impossible to
simultaneously achieve optimal maxload, constant evaluation
time, $n^{o(1)}$ description size, and $\Omega(\ell(n))$ independence.
However, this still leaves room for improvement if we do not
require large degrees of independence.

By itself small independence does not give any good bound on
maxload; for example, there are pairwise-independent hash
families with maxload $\Omega\left(\sqrt{n}\right)$ \cite{petershor}.
However, Alon et al. \cite{alon_is_1997} show that the
pairwise-independent hash family of multiplication by random
matrices over $\F_2$ achieves $\bigO(\ell(n) \cdot (\log \log
    n)^2)$ maxload in $\bigO(\log(n))$ evaluation time.

The following question remains open:
\begin{question}
  \label{question:fastandgood}
  Is there a hash family with $\bigO(1)$ machine
  word description whose evaluation requires $\bigO(1)$ arithmetic
  operations that has expected maxload bounded by $n^{o(1)}$?
\end{question}

\paragraph{Linear Hashing ($\LH$)}
$\LH$ \cite{motwani1995randomized, cormen2022introduction,
  sedgewick2014algorithms} is an attractive potential solution to
\cref{question:fastandgood}, trivially satisfying the conditions
of small description size and fast evaluation time.
% $\LH$ heuristically does quite well at spreading out elements
% \cite{sedgewick2014algorithms}.
Despite $\LH$'s simplicity, understanding its
maxload is a notoriously challenging and wide open question.
The best known lower bound on $\LH$'s maxload is $\Omega\left(\frac{\log
    n}{\log\log n}\right)$, whereas the best known upper bound is
$\widetilde{\bigO}(n^{1/3})$ due to an elegant combinatorial
argument of Knudsen \cite{knudsen_linear_2017}.

Let $\mathcal{U} = \set{0,1,\ldots, u-1}$ denote the universe.
To keep the introduction simple we abuse notation and let $x
  \bmod m$ denote the unique representative of the equivalence
class $x +m\Z$ lying in $[0,m)$.
In most textbooks (e.g., \cite{motwani1995randomized}) $\LH$ is
defined placing $x\in \mathcal{U}$ in bin
\begin{equation}\label{eq:LHdefn1}
  (ax+b)\mod p \mod \beta
\end{equation}
for prime $p\in [u, 2u]$
and randomly chosen integers $a,b \in [1,p]$.
In \cite{dietzfelbinger1997reliable} Dietzfelbinger et al. give an
alternative definition placing $x\in \mathcal{U}$ in bin
\begin{equation}\label{eq:LHdefn2}
  \floor{ \frac{(ax+b)\mod p}{p/\beta} }.
\end{equation}
We refer to \cref{eq:LHdefn1} as \defn{strided hashing} and
\cref{eq:LHdefn2} as \defn{blocked hashing}.

For $\beta=n$ Knudsen \cite{knudsen_linear_2017} implicitly observed that
the maxload of \cref{eq:LHdefn1} and \cref{eq:LHdefn2} differ by
at most a factor-of-$2$; this follows from our
\cref{prop:blockZisok}. Roughly this equivalence follows by observing that
if blocked hashing has large maxload for $a=a_0,$ then strided
hashing will have large maxload for $a=a_0 n \mod p$. Similarly,
if strided hashing has large maxload for $a=a_1$ then blocked
hashing will have large maxload for $a=a_1 n^{-1}\mod p$, where
$n^{-1}$ is the multiplicative inverse of $n$ in $\F_p$.
Thus, classically \cref{eq:LHdefn1}, \cref{eq:LHdefn2} are
essentially equivalent. On the other hand we show that blocked hashing
generalizes more readily.\footnote{In \cref{prop:blockZsucks} we
  show that strided hashing does not generalize cleanly to composite
  moduli. Furthermore, there is no natural way to generalize
  strided hashing to real numbers.}
Thus, the majority of our results will concern blocked hashing.

We further simplify the hash function \cref{eq:LHdefn2} by
removing the $+b$ \defn{``shift term"} obtaining
\begin{equation} \label{eq:LHdefn3}
  x\mapsto \floor{\frac{ax \bmod p}{p/\beta}}.
\end{equation}
Removing the shift term also will not impact the maxload by more
than a factor-of-$2$: changing the shift term at most splits
fullest bins in half or merges parts of adjacent bins
into a single new fullest bin.

For the rest of this section \defn{Simple $\LH$} will refer to
the hashing scheme defined in \cref{eq:LHdefn3}.
We propose \cref{q:isLHsubpoly} as a potential solution to
\cref{question:fastandgood}.
\begin{question}\label{q:isLHsubpoly}
  Is the worst-case expected maxload of Simple $\LH$ bounded by $n^{o(1)}$?
\end{question}

% It is well known that pairwise independence is not sufficient to
% get any bound on maxload better than $\bigO(\sqrt{n})$
% \cite{petershor}.
% \begin{itemize}
%   \item Select $k\gets [n],\pi\gets S_{n-1}$ uniformly randomly.
%   \item Each ball $i\in [n-1]$ is placed in bin $k$ with
%     probability  $1/\sqrt{n}$ and in bin $k+\pi_i$ otherwise.
%   \item Ball $n$ is placed independently in a random bin.
% \end{itemize}
%  Here, the expected number of balls in any fixed bin is
%  $\bigO(1)$ (this is guaranteed for any pairwise independent hash
%  family by linearity of expectation), but the expected number of
%  balls in the fullest bin is $\Omega(\sqrt{n})$.

\subsection{Our Results}
In this paper we propose a set of intermediate open questions to
help researchers make progress on \cref{q:isLHsubpoly}.
We establish the relationship between these intermediate open
questions and make some partial progress on them.
Except for in \cref{sec:twobins} we take $\beta=n$ bins.

\paragraph{Connecting Prime and Integer Moduli}
In \cref{sec:Z} we consider the importance of
using a prime modulus for $\LH$.
Conventional wisdom (e.g., \cite{cormen2022introduction}) is that
using a non-prime modulus is catastrophic. Using a
non-prime modulus is complicated by the fact that in a general
ring, as opposed to a finite field, non-zero elements can
multiply to zero.
Fortunately for any $m$ there is a reasonably large subset of
$\Z_m$ which forms a group under multiplication. The subset is
$\Z_m^{\times }$: the set of integers in $\Z_m$ coprime to $m$.
Using using $\Z_m^{\times }$ we define an alternative version of
$\LH$ called \defn{Smart} $\LH$  and show:
\begin{reptheorem}{thm:LHSLH}
  Fix integer $m\in \poly(n)$. The expected maxloads of
  Smart $\LH$ with modulus $m$ and Simple $\LH$ with modulus $m$
  differ by at most a factor-of-$n^{o(1)}$.
\end{reptheorem}
Intuitively, Smart $\LH$ with composite modulus behaves somewhat
similarly to Simple $\LH$ with prime modulus.
This similarity allows us to, with several new ideas, translate Knudsen's proof
\cite{knudsen_linear_2017} of a $\widetilde{\bigO}(n^{1/3})$
bound on Simple $\LH$'s maxload for prime modulus to the
composite modulus setting, giving:
\begin{reptheorem}{thm:Zm1_3}
  The expected maxload of Smart $\LH$ is at most
  $\widetilde{\bigO}(n^{1/3})$.
\end{reptheorem}

Part of why \cref{thm:Zm1_3} is interesting is that using
\cref{thm:Zm1_3} in \cref{thm:LHSLH} gives:
\begin{reptheorem}{cor:translate}
  The expected maxload of Simple $\LH$ with composite modulus is
  at most $n^{1/3+o(1)}$.
\end{reptheorem}
In particular, in \cref{cor:translate} we have translated the
state-of-the-art bound for maxload from the prime modulus setting
to the composite modulus setting.
This gives tentative evidence that the behavior of $\LH$ with
composite modulus may actually be the same as that of $\LH$ with
prime modulus. We leave this as an open question:
\begin{reptheorem}{question:equivalenceFZ}
  Is the worst-case maxload of composite modulus $\LH$ the
  same, up to a factor-of-$n^{o(1)}$, as that of prime
  modulus $\LH$?
\end{reptheorem}

\paragraph{Connecting Integer and Real Moduli}
In \cref{sec:R} we consider \defn{Real $\LH$} where the
multiplier ``$a$" in \eqref{eq:LHdefn3} is chosen
from $\R$. Initially the change to a continuous setting seems
to produce a very different problem.
In this continuous setting one equivalent way of formulating
\cref{q:isLHsubpoly} is:
\begin{question}[``Crowded Runner Problem"]
  \label{question:dual}
  Say we have $n$ runners with distinct speeds $x_1,x_2, \ldots,
    x_n \in (0,1)$ starting at the same location on a length $1$
  circular race-track. $a\in (0,1)$ is chosen randomly and all
  runners run from time $0$ until time $a$.
  Is it true that on average the largest ``clump" of runners,
  i.e., set of runners in single interval of size $1/n$, is of
  size at most $n^{o(1)}$?
\end{question}
As formulated in \cref{question:dual} the problem becomes a
dual to the famous unsolved ``Lonely Runner Conjecture"
of Wills \cite{wills1967zwei}  and Cusick \cite{cusick1982view}
as formulated in \cite{bienia1998flows}. In the Lonely Runner
Conjecture the question is for each runner whether there is any
time such that the runner is ``lonely", i.e., separated from all
other runners by distance at least $1/n$. Our question is whether for
most time steps there is any runner that is ``crowded",
i.e., with many other runners within an interval of size $1/n$
around the runner.
The difficulty of the Lonely Runner Conjecture may be indicative
that the ``Crowded Runner Conjecture" is also quite difficult.

In \cref{thm:itisreal} we show a surprising equivalence
between $\LH$ for integer and real moduli.
Technically our equivalence is to a slightly stronger
version of integer modulus $\LH$ namely \defn{Random Integer $\LH$} where the
modulus is not simply the universe size $u$, but rather a
randomly chosen (and likely composite) integer in $[u/2, u]$.
Random Integer $\LH$ is clearly at most a factor-of-$2$ worse
that Simple $\LH$, but it is not obvious whether it is any better; we leave this as
an open question:
\begin{question}
  Does Random Integer $\LH$ achieve smaller
  expected maxload than Simple $\LH$?
\end{question}

Formally the equivalence between Real $\LH$ and Random Integer
$\LH$ can be stated as follows:
\begin{reptheorem}{thm:itisreal}
  Let $f(n), g(n)$ be lower and upper bounds respectively on the
  expected maxload of Random Integer $\LH$ that hold for all sufficiently large
  universes. Let $M_\R$ denote the expected maxload of
  Real $\LH$. Then
  $$\Omega\paren{\frac{f(n)}{\log\log n}} \le M_\R \le
    \bigO(g(n)).$$
\end{reptheorem}
The proof of this theorem involves several beautiful
number-theoretical lemmas and is one of our main technical
contributions.

This equivalence between the real and integer versions of $\LH$ shows
that \cref{q:isLHsubpoly} may not fundamentally be about prime
numbers or even integers.

% In \cref{sec:nice} we analyze a particularly structured set
% which a priori is a reasonable candidate for a set which might
% incur large maxload; note that the maxload of an average set is
% of course small. However, we show that this set actually incurs
% small maxload. 

\paragraph{A Simpler Problem: The Two Bin Case}
Finally in \cref{sec:twobins} we consider an even simpler question than
\cref{q:isLHsubpoly}:
\begin{question}\label{question:twobincase}
  What can be said about Simple $\LH$ in the case where there are only
  $\beta=2$ bins?
\end{question}

Intuitively, Simple $\LH$ should place roughly half of the balls in each bin. In fact, one might even conjecture (especially if we believe that Simple $\LH$ does well on many bins) that Simple $\LH$ should achieve a Chernoff-style concentration bound on the number of balls in each of the two bins. What makes \cref{question:twobincase} interesting is that even analyzing the \emph{expected} maxload of Simple $\LH$ in the two-bin case is already a nontrivial problem (because, unlike non-simple $\LH$, Simple $\LH$ is not pairwise independent). In fact, it may be the simplest non-trivial problem that one can state about Simple $\LH$.

In \cref{sec:twobins} we prove a partial result towards
\cref{question:twobincase}. We show that, even though some pairs of elements may
have probability as large as $2/3$ of colliding in their bin assignment, one
can nonetheless establish a $(1 + o(1)) n/2$ bound on the expected maxload:
\begin{reptheorem}{thm:dontneedb}
  Simple $\LH$ with $\beta=2$ bins has expected maxload at most
  $n/2 + \bigO(n^{7/8}).$
\end{reptheorem}

We propose proving stronger results in the two-bin setting as a fruitful
direction for future research. For example, establishing Chernoff-style
concentration bounds on the maxload in the two-bin case would constitute the
strongest evidence to date that Simple $\LH$ is a good load-balancing function.


\section{Preliminaries}
\paragraph{Set Definitions}
We write $\PRM$ to denote the set of primes, $\F_p$ for $p\in \PRM$ to denote the
finite field with $p$ elements, and $\Z_m$ for $m\in \N$ to denote
the ring $\Z / m\Z.$

For $a,b\in \R$ we define
$$[a,b]=\setof{x\in \R}{a\le x\le b}.$$
For $n\in \N$ we define
$$[n] = \set{0,1,\ldots, n-1},$$
$$[n]_{\setminus 0} = [n]\setminus \set{0}.$$
For $p\in \N,x\in \R$ we define $\modp(x)$ as
the unique number in the set
$$(x+p\Z) \cap [0,p),$$
and define
$$\circabs_p(x)= \min(\modp(x), \modp(-x)).$$
For $x\in \Z$, $\modp(x)$ is the positive remainder
obtained when $x$ is divided by $p$ and $\circabs_p(x)$ is the
smallest distance to an element of $p\Z$ from $x$.

For $a\in \R$ and set $X\subset \R$ we define
$$a+X = \setof{a+x}{x\in X},$$
$$a\cdot X = \setof{a\cdot x}{x\in X},$$
$$\modp(X) = \setof{\modp(x)}{x\in X}.$$


\paragraph{Number Theoretic Definitions}
For $x,y\in \N$ we write $x\perp y$ to denote that  $x,y$ are
coprime, and $x\mid y$ to denote that $x$ divides $y$.
We write $\gcd(x,y)$ to denote the largest $k$ satisfying both  $k\mid
  x$  and $k\mid y$.
% We use $\nu_p(n)$ to denote the exponent of the largest
% power of $p$ dividing $n$. 

A \defn{unit}, with respect to an implicit ring, is an element
with an inverse. For $m\in \N$ we define $\Z_m^{\times}$ as the
set of units in $\Z_m$. That is,
$$\Z_m^{\times } =\setof{k \in [m]}{k\perp m}.$$ We write
$\phi$ to denote the Euler-Toitent function, which is defined to
be $\phi(m)=|\Z_m^{\times }|$. We write $\tau(m)$ to denote the number of
divisors of $m$.

The following two facts (see, e.g.,
\cite{hardy1979introduction}), will be
useful in several bounds:
\begin{fact}\label{fact:numdivs}
  $$\tau(n) \le 2^{\bigO(\log n / \log\log n)} \leq n^{o(1)}.$$
\end{fact}
\begin{fact}\label{fact:toitent}
  $$\frac{n}{2\log\log n} \le \phi(n)< n.$$
\end{fact}

\paragraph{Hashing Definitions}
A \defn{hashing scheme} mapping universe $[u]$ to $\beta$ bins is a set of functions
$$\setof{h_i: [u]\to [\beta]}{i\in I}$$
parameterized by $i\in I$ for some set $I$.
We say $h_i$ sends element  $x$ to bin $h_i(x)$.
The \defn{maxload} of $\setof{h_i}{i\in I}$ with respect to set $X$ for
parameter choice $i_0\in I$ is
$$\max_{k\in [\beta]} \left|\setof{x\in X}{h_{i_0}(x)=k}\right|.$$
In other words, maxload is the number of elements mapped to the
fullest bin.
We are concerned with bounding the expected maxload of hashing
schemes with respect to uniformly randomly
chosen parameter $i\in I$ for arbitrary $X$.
We will abbreviate uniformly randomly to randomly when the
uniformity is clear from context.

\begin{rmk}\label{rmk:assumesize}
  Our analysis is asymptotic as a function of $n$, the number of
  bins. We assume $n$ is at least a sufficiently large constant.
  We also require the universe size $u$ to satisfy:
  $$n^{6}\le u \le \poly(n)$$
  We adopt these restrictions for the following reasons:
  \begin{itemize}
    \item If $u$ is too small then bounding maxload is not
          interesting. For instance, if $u\in \Theta(n)$ linear
          hashing trivially achieves maxload $\bigO(1)$.
          It is standard to think of the universe as being much larger
          than the number of bins. Our specific choice $u\ge \Omega(n^{6})$ is
          arbitrary, but simplifies some analysis.
    \item If $u$ is too large then constant-time arithmetic
          operations becomes an unreasonable assumption. Thus, we require
          ${u\le \poly(n)}$.
  \end{itemize}
\end{rmk}

\input{composite_moduli.tex}
\input{sec_real.tex}
\input{two_bins.tex}

\paragraph{Acknowledgements}
The author thanks William Kuszmaul and Martin Farach-Colton for
proposing this problem and for helpful discussions.
% \bibliographystyle{plain}
% \bibliography{refs}
\medskip
\printbibliography
\medskip
\appendix

\input{slh13knudsen.tex}
\input{structured_set.tex}

\end{document}
