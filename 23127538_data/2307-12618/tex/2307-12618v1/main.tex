% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[acronym,nomain]{glossaries}
\usepackage{makecell}
\usepackage{subcaption}
\usepackage[toc,page]{appendix}
\usepackage{hyperref}
\usepackage{color, colortbl}
\definecolor{Gray}{gray}{0.9}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[backend=biber, style=numeric-comp, sorting=none, bibstyle= nature]{biblatex}
\addbibresource{ref.bib}


% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\newacronym{mr}{MR}{Magnetic Resonance}
\newacronym{nor}{NOR}{}
\newacronym{lv}{LV}{left ventricle}
\newacronym{rv}{RV}{right ventricle}
\newacronym{vae}{VAE}{Variational Autoencoder}
\newacronym{sivae}{SIVAE}{Soft Introspective Variational Autoencoder}
\newacronym{gan}{GANs}{Generative Adversarial Networks}
\newacronym{mse}{MSE}{Mean Squared Error}
\newacronym{lvedv}{LVEDV}{Left Ventricular End-Diastole Volume}
\newacronym{myoedv}{MEDV}{Myocardial End-Diastole Volume}
\newacronym{rvedv}{RVEDV}{Right Ventricular End-diastole Volume}
\newacronym{ssim}{SSIM}{Structural Similarity Index Measure}
\newacronym{sap}{SAP}{Separated Attribute Predictability}
\newacronym{scc}{SCC}{Spearman Correlation Coefficient}


\begin{document}
%
\title{Attribute Regularized Soft Introspective VAE: Towards Cardiac Attribute Regularization Through MRI Domains}

\titlerunning{Towards Cardiac Attributes Regularization Through MRI Domains}


%\author{Anonymous}
\author{Maxime Di Folco \inst{1,2} \and
Cosmin I. Bercea \inst{1,2} \and
Julia A. Schnabel \inst{1,2,3}}

\authorrunning{M. Di Folco et al.}
\authorrunning{}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
%\institute{******}
\institute{Institute of Machine Learning in Biomedical Imaging, Helmholtz Munich, Neuherberg, Germany \and Technical University of Munich, Munich, Germany \and King’s College London, London, UK \\  \textbf{Preliminary work. Under review. Do not distribute}}
%\institute{Faculty of }
%\url{http://www.springer.com/gp/computer-science/lncs \and
%ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany}\\
%\email{\{abc,lncs\}@uni-heidelberg.de}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}

Deep generative models have emerged as influential instruments for data generation and manipulation. Enhancing the controllability of these models by selectively modifying data attributes has been a recent focus. Variational Autoencoders (VAEs) have shown promise in capturing hidden attributes but often produce blurry reconstructions. Controlling these attributes through different imaging domains is difficult in medical imaging. Recently, Soft Introspective VAE leverage the benefits of both VAEs and Generative Adversarial Networks (GANs), which have demonstrated impressive image synthesis capabilities, by incorporating an adversarial loss into VAE training. In this work, we propose the Attributed Soft Introspective VAE (Attri-SIVAE) by incorporating an attribute regularized loss, into the Soft-Intro VAE framework. We evaluate experimentally the proposed method on cardiac MRI data from different domains, such as various scanner vendors and acquisition centers. The proposed method achieves similar performance in terms of reconstruction and regularization compared to the state-of-the-art Attributed regularized VAE but additionally also succeeds in keeping the same regularization level when tested on a different dataset, unlike the compared method. 

Code:  *************************

\keywords{Attribute regularization \and Soft introspective variational autoencoders \and Cardiac MRI \and Representation learning.}
\end{abstract}
%
%

%These methods can be broadly categorized into attribute-dependent latent spaces approaches which attempt to explicitly encode different attributes along different dimensions of the latent space \cite{engel2017latent,hadjeres:2017}; and attribute-invariant latent space approaches that learn a generalized latent representation (independent of the attribute values) which can generate a data-point with an attribute when combined with specific attribute information \cite{Mirza:2014, Fader:2017}
%

\section{Introduction}

Deep generative models have become prominent tools for generating and manipulating data. These models have found applications across various domains, such as medical imaging \cite{Singh:2021}. Recent efforts have focused on improving model controllability by allowing selective modifications of data attributes, such as altering the gender of a person in an image \cite{Fader:2017}. \gls{vae} have demonstrated potential in this area by effectively capturing hidden attributes of the data through encoding but have been known to produce blurry reconstructions

% Figure environment removed

A lot of recent research aim to model the different factors of data variation by disentangling the representation in an unsupervised manner \cite{higgins:2017,kim:2018,Chen:2018}. Although these methods perform well on generated datasets (e.g., dSprites \footnote{\url{https: //github.com/deepmind/dsprites-dataset}}), they struggle to generalize to real data, which often exhibits complex combinations of low-level attributes. Locatello et al. \cite{Locatello:2019} shows that an amount of supervision is required for learning effective disentanglement and overcoming the sensitivity of biases inducted by factors like the choice of network or hyperparameters. 

Supervised regularized methods depend on identifying specific attribute, and employing supervised techniques to facilitate control during the generation process  \cite{Mirza:2014,Fader:2017,engel2017latent,hadjeres:2017}. However, very few methods are designed for continuous-valued attributes \cite{Pati:2021}.

To overcome this limitation, Pati et al. \cite{Pati:2021} recently proposed an attribute-regularized method based on a \gls{vae} that enforce attribute disentanglement of the latent space. In particular, Cetin et al. ~\cite{Cetin:2023} used this architecture for cardiac attributes on MRI data and showed significant improvement in the interpretability of the latent representations. Nevertheless, the learned representation is specific to the domain of the training dataset and could not transfer to another domain, 

Domain adaptation is a popular topic in medical imaging to adapt to the different domains caused by different scanners, medical sites, and modalities. Many domain adaptation methods rely on adversarial learning, which has demonstrated impressive image synthesis capabilities \cite{Creswell:2018}. 

Combining the latent interpretability of VAEs with the power of adversarial training has attracted considerable attention in achieving high-quality image generation. In this context, Daniel et al.~\cite{Daniel:2021} introduced a novel approach called \gls{sivae}. SI-VAEs leverage the benefits of  VAEs and GANs by incorporating an adversarial loss into VAE training. Instead of employing additional discriminator networks like previous methods~\cite{pidhorskyi2018generative}, SIVAEs utilize the encoder and decoder of VAEs in an adversarial manner.


In this paper, we present Attributed-\gls{sivae} by incorporating the attribute regularized loss, as proposed by \cite{Pati:2021}, into the SIVAE framework. To our knowledge, we are the first to adversarially train \gls{vae} with an attributed-based loss. We test the proposed method on two public cardiac MRI datasets with different MRI domains, i.e. different scanner vendors or different acquisition centers, and regularized the learned representations using cardiac volumes. We compare our methods in terms of reconstruction and regularization to the proposed method in \cite{Cetin:2023}.

%We can discern two primary categories: feature-level domain adaptation, which focuses on aligning the features extracted from different domains, and pixel-level domain adaptation, which specializes in conducting style transfer across domains \cite{}.

%\textbf{VAEs have been known to produce blurry reconstructions[add citation], whereas recent advancements in GANs[add citations] have demonstrated impressive image synthesis capabilities.}


\section{Related work}

This work can be considered as an extension of the work proposed by \cite{Cetin:2023}, which obtains great performance in terms of disentanglement and reconstruction on the 3D volume of the \gls{lv} and myocardium, even though we were not able to reproduce the level of performance described in the paper with the same settings, which we attribute to differences due in the experimental setup (e.g. data splitting). In this paper, we investigate the regularization of cardiac attributes across MRI domain, and additionally we include the \gls{rv} that adds more shape variability. Therefore, we experiment in 2D using only one slice of the volume. 

\section{Methods}

\subsection{Background}

\gls{vae}s are generative models composed of an encoder and a decoder network. The encoder, parametrized by the parameters $\phi$, maps an input data $x$ to a latent space distribution by estimating a posterior distribution $q_{\phi}(\mathbf{z} | \mathbf{x})$ that is regularized to be similar to a prior distribution $p(z)$ (usually a normal distribution). The decoder $p_{\theta}(x|z)$ parametrized by $\theta$, generates a reconstruction of the input data using a sample. The \gls{vae} objective function includes a reconstruction loss term and a regularization term that encourages the latent distribution to follow the prior distribution.

To improve the disentanglement of the latent space, i.e. enforcing that every single latent feature $z_i$ is sensitive to changes from a single generative factor, Higgins et al. \cite{higgins:2017} introduced a hyperparameter $\beta$ applied to the regularization term. The loss function is defined as followed:

 \begin{equation}
   \mathcal{L}(\textit{x}, \theta, \phi, \beta) = \mathbb{E}_{q_{\phi(z\mid x)}} \left[ log(p_{\theta}(x\mid z )) \right] - \beta KL(q_{\phi}(z\mid x) \| p(z)),
    \label{eq:beta}
\end{equation}

where the first term corresponds to the "reconstruction loss" and the second one the regularization term with $KL(q(z|x)||p(z))$ the Kullback-Leibler divergence between the encoded distribution and the prior distribution $p(z)$

\subsection{Attributed regularization}

Pati et al. \cite{Pati:2021}, introduced an attributed-based regularization \gls{vae}, based on  $\beta$-\gls{vae} (Fig. \ref{fig:model_VAE}). This method aims to encode an attribute $a$ along a dimension $r$ of a $\mathbb{D}$-dimensional latent space \begin{math} \ z: {z^k}, k \in [0,\mathbb{D}) \end{math}, such that the attribute value $a$ of the generated data increases when we traversing along r. The attribute regularization is defined by computing two distance matrices: one in the input space $D_a$ and one in the latent space $D_r$. The definition of these two matrices are:  

\begin{equation}
    \centering
    D_a(i,j) = a(x_i) - a(x_j) \text{;  } D_r(i,j) = z_i^r - z_j^r
\end{equation}

The attributed-regularization loss term is then computed as followed and added to the $\beta$-VAE loss in Eq. \ref{eq:beta} 

\begin{equation}
    \centering
    L_{r,a} = \gamma_{reg} \times MAE(tanh(\delta D_r) - sgn(D_a))
    \label{eq:attr}
\end{equation}

where $MAE(.)$ is the mean absolute error, $tanh(.)$ is the hyperbole tangent function, $sgn(.)$ is the sign function, $\delta$ and $\gamma_{reg}$ are tunable hyperparameters which respectively decides the spread of the posterior distribution and weight the importance given to the regularization. We will denote this method Attri-VAE for the rest of the paper.

\subsection{Proposed method: Attributed-SIVAE}

Our proposed method is based on the \gls*{sivae} framework proposed by \cite{Daniel:2021}. The encoder is trained to distinguish between real and generated samples by minimizing the KL divergence between the latent distribution of real samples and the prior, while maximizing the KL divergence of generated samples. Conversely, the decoder is trained to deceive the encoder by reconstructing real data samples using the standard ELBO and minimizing the KL divergence of generated samples embedded by the encoder. The optimization objectives for the encoder and decoder, to be maximized, are formulated as follows:
\begin{flalign}
    \label{eq::sivae}
    & \mathcal{L}_{E_{\phi}}(x,z) = ELBO(x) - \frac{1}{\alpha}(exp(\alpha ELBO(D_\theta(z)),\\
    & \mathcal{L}_{D_{\theta}}(x,z) = ELBO(x) + \gamma ELBO(D_\theta(z)), \nonumber
\end{flalign}
where $\alpha \geq 0$ and $\gamma \geq 0$ are hyper-parameters.

\paragraph{\textbf{Attributed-SIVAE: }} We propose in this work Attributed \gls{sivae} by adding the attribute regularization loss defined in Eq. \ref{eq:attr} to the encoder loss of the \gls{vae} (Fig. \ref{fig:model_SIVAE}). The optimization objectives of the encoder become then: 

\begin{flalign}
    \label{eq:OURS}
    & \mathcal{L}_{E_{\phi}}(x,z) = ELBO(x) - \frac{1}{\alpha}(exp(\alpha ELBO(D_\theta(z))   + \gamma_{reg}    \times L_{r,a}
\end{flalign}

where $\gamma_{reg}$, a hyperparameter that weigth the attribute regularization term $L_{r,a}$ defined in Eq. \ref{eq:attr}.


\subsection{Evaluation}

To measure the reconstruction fidelity, we use the \gls{ssim}. The SSIM is a similarity measure between two images that evaluate their structural information and perceptual quality.

To evaluate the disentanglement of the latent space we use the \textit{Interpretability} metric \cite{Abdel:2018}, which measures the ability to predict a given attribute using only one dimension of the latent space; the \textit{Modularity} metric \cite{Ridgeway:2018}, that quantifies whether each dimension of the latent space depends on only one attribute; the \gls{sap}, which computes the difference in the prediction error of the two most predictive dimensions of the latent space for a given attribute; and report the \gls{scc} as the maximum value of the Spearman’s correlation coefficient between an attribute and each dimension of the latent space. The metrics were computed using the official public implementation\footnote{\url{https://github.com/ashispati/ar-vae}} provided by \cite{Pati:2021}.

\section{Experiments and results}

We use two short-axis cardiac MRI public datasets: ACDC dataset \cite{Bernard:2018}, which contains 150 \gls{mr} and the dataset from the M\&Ms challenge \cite{campello:2021} that contains 345 cases from different scanners vendors and centers. Appendix \ref{app:dataset} describes the split strategy for each dataset and the pre-processing steps.

\paragraph{\textbf{Cardiac attributes:}} From the ground-truth segmentation at end-diastole, we computed the cardiac volumes of each of the regions of interest: \gls{lvedv}, \gls{myoedv}, and \gls{rvedv}. An extensive study of the attribute choice is described in \cite{Cetin:2023}. We choose a limited choice of attributes in this study due to the complexity of the task. 

We report the implementation details of the baseline and the proposed method in the Appendix \ref{app:training}.

\subsection{Reconstruction performance}

We compare the reconstruction capability of the two approaches: Attributed-\gls{vae} and Attributed-\gls{sivae} with or without attribute regularization. Figure. \ref{fig:ACDC_rec} and Figure \ref{fig:MnMs_rec} show four reconstruction samples of ACDC and M$\&$Ms dataset. All of the methods capture the shape variability of the \gls{lv} and the \gls{rv}, but failed to capture the myocardium thickness. As expected for the methods without attribute regularization, $\beta$-VAE produces blurry reconstruction and we obtain better reconstruction with the \gls{sivae} methods. We observe an improvement of reconstruction quality when we add the regularization for $\beta$-VAE base methods (comparison between the 1st and 3rd line in Fig. \ref{fig:rec_samples}) and the opposite for the SIVAE-based method (comparison between the 2nd and 4th line). These observations are confirmed in Fig. \ref{fig:boxplot_rec} that plot the distribution of \gls{ssim} score on the test set. Despite showing similar reconstruction, the Attri-SIVAE achieves lower performance than Attri-VAE on the ACDC dataset, and an improvement is observed for the M$\&$Ms dataset.

% Figure environment removed


\subsection{Attribute regularization}

Table. \ref{tab:score_table} reports the performance metrics regarding attribute regularization for ACDC and M$\&$Ms (respectively in black and in blue in the table). A significant improvement occurs when we add the attribute regularization in terms of \textit{interpretability}, \gls{sap}, and \gls{scc} metrics. We obtain a close \textit{Modularity} score for all methods and both datasets. The experiments on the ACDC dataset show better global performance for both methods, especially in terms of \textit{Interpretability}, due to the variety of MRI domains contained in the M$\&$Ms dataset.

For the ACDC dataset, the attribute models achieved better \textit{Interpretability} scores for the \gls{lv} (Attri-VAE: 0.67  and Attri-SIVAE: 0.68) and \gls{rv} attributes (Attri-VAE: 0.69 and Attri-SIVAE: 0.69), but failed to capture the variability of the myocardium (Attri-VAE: 0.31 and Attri-SIVAE: 0.24). Concerning the M$\&$Ms dataset, all attributes achieved a similar score (Attri-VAE: \textit{LVEDV}: 0.17, \textit{MEDV}: 0.21, \textit{RVEDV}: 0.22; Attri-SIVAE: \textit{LVEDV}: 0.29, \textit{MEDV}: 0.20, \textit{RVEDV}: 0.32)).


\begin{table}[ht]
    \centering
    \input{tables/score_table}
    \caption{Comparison of disentanglement performance metrics on the ACDC dataset (in black) and the M$\&$Ms dataset (in blue). Interp.: Mean interpretability, SCC: Spearman Correlation Coefficient, Mod: Modularity, and SAP: Separated Attribute Predictability. All the metrics are between 0 and 1, with 1 being the best performance. The standard deviation between 5 runs with different seeds is lower than 0.01 for all metrics, except the \textit{Modularity}: $\pm$ 0.03 for all methods.}
    \label{tab:score_table}
\end{table}

We then generate new samples using Attri-VAE and Attri-SIVAE by controlling the different attributes along their corresponding dimension, i.e. the dimension with the highest interpretability score returned, illustrated in Fig. \ref{fig:DIM}. The attribute reconstructions for the M$\&$Ms dataset demonstrate a higher level of plausible cardiac anatomy. The attribute reconstructions using the Attri-SIVAE method exhibit less variation, i.e. similar shapes with few changes compared to Attri-VAE reconstructions present more variability of global shape. In both cases, the main variations of shape are coherent with the attributes except, the second dimension of Attri-SIVAE on the ACDC dataset (top right in Fig. \ref{fig:DIM}) fails to capture the expected variability of the myocardium attribute (as observed in \textit{Interpretability} score previously).


% Figure environment removed


\subsection{External datasets:} We finally test on ACDC the attribute methods using the models train on M$\&$Ms. We obtained a similar \gls{ssim} score of $0.79 \pm 0.05$ for Attri-VAE and $0.80 \pm 0.05$ for Attri-SIVAE, but achieve better \textit{Interpretability} score (Attri-VAE: 0.42 with \textit{LVEDV} = 0.55, \textit{MEDV}= 0.10 and \textit{RVEDV} = 0.60; and Attri-SIVAE: of 0.54 with  \textit{LVEDV}= 0.64, \textit{MEDV}= 0.33 and \textit{RVEDV} = 0.65) . This experiment shows that our method achieve the same regularization when trained on ACDC and training on M$\&$Ms. Appendix \ref{app:dimdim} show the variation of generated samples along the latent dimensions controlled by an attribute for this experiment. Both methods achieve \textit{Interpretability} score lower than 0.1 when tested on M$\&$Ms with models trained on ACDC. 


\section{Discussion and Conclusion}

In this paper, we proposed Attri-SIVAE by incorporating attribute regularization, proposed in \cite{Pati:2021}, into the \gls{sivae} framework. We compared our method with the state-of-the-art Attri-VAE regarding reconstruction and attribute regularization by experimenting on two cardiac MRI datasets. When trained and tested on the same dataset, our method achieved a comparable disentanglement and reconstruction to Attri-VAE. However, our method achieves a better generalization by obtaining similar performance when trained on M$\&$Ms and tested on ACDC, showing attribute regularization through the different cardiac MRI domains. Nevertheless, the quality of our reconstruction needs improvement in order to capture the myocardium shape variability. \gls{sivae} can generate high-fidelity images when trained on bigger dataset. We believe the performance will improve if tested on larger datasets such as the UK Biobank \cite{UK:2015}.  A limitation of our approach is its complexity. \gls{sivae} have many hyperparameters to optimize, making the convergence of the methods not trivial. Our approach adds two more hyperparameters. The computation costs are also higher compared to Attri-VAE. Future work will investigate domain adaptation strategies to reconstruct better samples and study the influence of cardiac attribute choice to improve the regularization through different MRI domains.


% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\newpage
\printbibliography
%
\newpage


\appendix

\include{supplementary}

\end{document}
