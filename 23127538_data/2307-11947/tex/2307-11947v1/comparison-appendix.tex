\section{Proofs for Section~\ref{sec:comparison}} \label{proof:upper-bound-comparison}

\subsection{Proof of Theorem~\ref{thm:upper-bound-imputed}} \label{proof:upper-bound-imputed}
The key part of the proof is showing $\est{\param}_i\impute = T_i^\top (T_iT_i^\top)^{-1} \est{\param}_i$. If we can have this claim established, we can make use of the following transformation of the loss function
\begin{align*}
	& \sum_{i=1}^m  \norm{T_i^\top (T_i T_i^\top)^{-1} T_i  \param - \est{\param}_i\impute  }_{W_i}^2  = \sum_{i=1}^m  \norm{T_i^\top (T_i T_i^\top)^{-1} T_i  \param - T_i^\top (T_i T_i^\top)^{-1} \est{\param}_i }_{W_i}^2 \nonumber \\
	& = \sum_{i=1}^m  \norm{ T_i  \param -  \est{\param}_i }_{(T_i T_i^\top)^{-1} T_i W_i T_i^\top (T_i T_i^\top)^{-1}}^2.
\end{align*}
This reduces the optimization problem into the same one in Eq.~\eqref{eq:defn-weighted-avg-est-param} up to weight transformation, and the same lower bound for asymptotic covariance in Theorem~\ref{thm:upper-bound} applies. Hence
\begin{align*}
	C\imputeglb(\alpha_1, \cdots, \alpha_m) \succeq C\opt.
\end{align*}
By taking $W_i= T_i^\top W_i\opt T_i$, we have the transformed weights satisfy
\begin{align*}
	(T_i T_i^\top)^{-1} T_i W_i T_i^\top (T_i T_i^\top)^{-1} = (T_i T_i^\top)^{-1} T_i^\top W_i\opt T_i (T_i T_i^\top)^{-1} = W_i\opt.
\end{align*}
From the optimality condition in Theorem~\ref{thm:upper-bound}, the equality holds under this choice of $W_i$'s.

It then boils down to proving the claim $\est{\param}_i\impute = T_i^\top (T_iT_i^\top)^{-1} \est{\param}_i$. We make use of the following two properties of Moore-Penrose pseudo inverse---for $A \in \R^{d_i \times d}$ of rank $d_i$,
\begin{align*}
	(A^\top A)^\dagger = A^\dagger (A^\dagger)^\top, \qquad A^\dagger = A^\top (AA^\top)^{-1}.
\end{align*} 
Substituting $A=(X\iplus^\top X\iplus)^{\half} T_i$ into the above displays, we then have
\begin{align*}
	& \est{\param}\impute_i  = (T_i^\top X\iplus^\top X\iplus T_i)^\dagger T_i^\top X\iplus^\top y_i \nonumber \\
	& = T_i^\top (X\iplus^\top X\iplus)^{\half} \prn{(X\iplus^\top X\iplus)^{\half} T_i T_i^\top (X\iplus^\top X\iplus)^{\half}}^{-2}   \cdot   (X\iplus^\top X\iplus)^{\half} T_i T_i^\top X\iplus^\top y_i \nonumber \\
	& = T_i^\top (X\iplus^\top X\iplus)^{\half} \prn{(X\iplus^\top X\iplus)^{-\half} (T_i T_i^\top)^{-1} (X\iplus^\top X\iplus)^{-\half}}^{2}   \cdot   (X\iplus^\top X\iplus)^{\half} T_i T_i^\top X\iplus^\top y_i \nonumber \\
	& = T_i^\top (T_i T_i^\top)^{-1} \cdot (X\iplus^\top X\iplus)^{-1} \cdot (T_i T_i^\top)^{-1} \cdot T_i T_i^\top X\iplus^\top y_i \nonumber \\
	& = T_i^\top (T_i T_i^\top)^{-1} \cdot (X\iplus^\top X\iplus)^{-1} X\iplus^\top y_i =  T_i^\top (T_i T_i^\top)^{-1} \est{\param}_i .
\end{align*}
\subsection{Proof of Theorem~\ref{thm:upper-bound-imputed-glb}} \label{proof:upper-bound-imputed-glb}

By a direct calculation, we have
\begin{align*}
	& \est{\param}\imputeglb - \param = \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top X\iplus T_i}^{-1} \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top y_i} - \param \\
	&  = \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top X\iplus T_i}^{-1} \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top (X\iplus \param\iplus + X\imin \param\imin +  \noise_i)} - \param \nonumber \\
	& =  \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top X\iplus T_i}^{-1} \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top (X\iplus \param\iplus + X\imin \param\imin -X\iplus T_i \param +  \noise_i)} \nonumber \\
	& = \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top X\iplus T_i}^{-1} \prn{\sum_{i=1}^m \alpha_i T_i^\top X\iplus^\top (X\imin \param\imin -X\iplus \scov\iplus^{-1} \scov\ipm \param\imin +  \noise_i)}.
\end{align*}
Consequently
\begin{align*}
	\sqrt{n} \prn{\est{\param}\imputeglb - \param} = \prn{\sum_{i=1}^m \alpha_i  T_i^\top \cdot \frac{1}{n} X\iplus^\top X\iplus \cdot T_i}^{-1} \cdot \prn{\sum_{i=1}^m \alpha_i T_i^\top \cdot \frac{1}{\sqrt{n}}X\iplus^\top (X\imin \param\imin -X\iplus \scov\iplus^{-1} \scov\ipm \param\imin +  \noise_i)}
\end{align*}
Following the same proof steps applied to Eq.~\eqref{eq:local-estimate-clt} in Appendix~\ref{sec:proof-upper-bound}, we can conclude that
\begin{align*}
	& \sqrt{n} \prn{\est{\param}\imputeglb - \param} \nonumber \\
	& \cd \normal \Bigg(0, \underbrace{\prn{\sum_{i=1}^m \alpha_i  T_i^\top \scov\iplus T_i}^{-1} \prn{\sum_{i=1}^m \alpha_i^2 T_i^\top Q_i T_i} \prn{\sum_{i=1}^m \alpha_i T_i^\top \scov\iplus T_i}^{-1}}_{:= C\imputeglb(\alpha_1, \cdots, \alpha_m)}\Bigg),
\end{align*}
with the same $Q_i$'s as in Eq.~\eqref{eq:def-Q-i}, and with Gaussianity of $X_i$, we also have the explicit form $Q_i =  (\norm{\param\imin}_{\Gamma\imin}^2 + \sigma^2)\scov\iplus$. Note that if $\alpha_i = 1/ (\norm{\param\imin}_{\Gamma\imin}^2 + \sigma^2)$,
\begin{align*}
	C\imputeglb(\alpha_1, \cdots, \alpha_m) = \prn{\sum_{i=1}^m \frac{T_i^\top \scov\iplus T_i}{\norm{\param\imin}_{\Gamma\imin}^2 + \sigma^2}}^{-1} = C\gauss  = C\opt.
\end{align*}
Finally, to show $C\imputeglb(\alpha_1, \cdots, \alpha_m) \succeq C\opt$, we identify from Eq.~\eqref{eq:def-C-function} that
\begin{align*}
	C\imputeglb(\alpha_1, \cdots, \alpha_m) =  C(\alpha_1 \scov_{1+}, \cdots, \alpha_m \scov_{m+}) \succeq C\opt,
\end{align*}
where the last inequality follows from Theorem~\ref{thm:upper-bound}.