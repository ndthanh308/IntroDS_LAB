\documentclass[conference,a4paper]{IEEEtran}
\usepackage{enumerate}
\usepackage{enumitem}


\usepackage[innermargin=0.5in,outermargin=0.5in,top=0.68in,bottom=1.48in]{geometry}
\setlength{\abovedisplayskip}{4pt} % Change space above and below equations
\setlength{\belowdisplayskip}{4pt}
\setlength{\topsep}{4pt} % Change space above theorems, etc.
\renewcommand{\baselinestretch}{0.946}

\usepackage{preamble}
\usepackage{algorithm,algorithmic}
%\usepackage{mathrsfs}
\usepackage{float}
\newfloat{algorithm}{t}{lop}
\PassOptionsToPackage{bookmarks=false}{hyperref}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{bbm}
\usepackage{lipsum,multicol}
%\usepackage{biblatex}
%\addbibresource{qabs.bib}
%\usepackage{cleveref}
\usepackage{tikz,tikz-cd}
\usepackage{multicol}
\usepackage{blkarray}
\usetikzlibrary{shapes.geometric,decorations.pathreplacing,calc,scopes}
\tikzstyle{r} = [draw, very thick, red,-]
\tikzstyle{g} = [draw, very thick, green, -]
\tikzstyle{d} = [draw, very thick,black, dashed]
\tikzstyle{b} = [draw, very thick, black, -]
\tikzstyle{a} = [draw, very thick, black, ->]
\tikzstyle{la} = [draw, thick, black, ->]
\tikzstyle{t} = [draw,thin,black,-]
\tikzstyle{blueline} = [draw, very thick, blue, -]
\tikzstyle{backa} = [draw, very thick, black, <-]

\def\ppmatrix#1{\begin{pmatrix}#1\end{pmatrix}} % Matrix
\def\ppsmatrix#1{\begin{psmallmatrix}#1\end{psmallmatrix}} % Inline column matrix
%***************************Plots**********************************

\usepackage{mathrsfs}
\usepackage{tkz-euclide,subfigure}
\usetikzlibrary{shapes.geometric, arrows}
\usepackage{caption}
\captionsetup{belowskip=-3pt}
%\usepackage{subcaption}


\newcommand{\sfX}{{\sf X}}
\newcommand{\sfY}{{\sf Y}}
\newcommand{\sfZ}{{\sf Z}}


\begin{document}
\title{Analysis of syndrome-based iterative decoder failure of QLDPC codes}
\author{
  \IEEEauthorblockN{Kirsten D. Morris, Tefjol Pllaha, Christine A. Kelley}\\
    	\IEEEauthorblockA{\small University of Nebraska-Lincoln, Lincoln, NE, USA.\\ 
    	E-mail: \{kmorris11, tefjol.pllaha, ckelley2\}@unl.edu
	}
}
\IEEEoverridecommandlockouts

\maketitle

\begin{abstract}
Iterative decoder failures of quantum low density parity check (QLDPC) codes are attributed to substructures in the codeâ€™s graph, known as trapping sets, as well as degenerate errors that can arise in quantum codes. Failure inducing sets are subsets of codeword coordinates that, when initially in error, lead to decoding failure in a trapping set.
In this paper we examine the failure inducing sets of QLDPC codes under syndrome-based iterative decoding, and their connection to absorbing sets in classical LDPC codes. 
 
\end{abstract}

\section{Introduction}


Quantum information is far from perfect and very much prone to errors. For this reason, fault-tolerant quantum computation is a must and quantum error correction becomes a central topic.
Since the discovery of the first quantum error correction code~\cite{Shor-first}, there has been tremendous progress in code design.
Many of the existing quantum codes leverage the vast existing literature in classical coding theory. Low-density parity-check (LDPC) codes are well-established in classical coding theory. 
Their quantum analogues, quantum LDPC (QLDPC) codes, gained popularity due to Gottesman's breakthrough discovery~\cite{Gottesman-overhead}, showing that constant overhead can be achieved with constant encoding rate.
For this reason, QLDPC codes are current candidates for realizing scalable fault-tolerant quantum computation.  
Like their classical counterparts, QLDPC codes are amenable to low-complexity iterative decoding algorithms, such as syndrome-based iterative decoding  \cite{RBV19, RRPV22}.
%\cite{CFRU01, RU01}.
In practice, these algorithms are run until either an estimated error pattern is obtained or a maximum number of iterations is reached. However, these algorithms are suboptimal on finite length QLDPC codes, meaning that they do not always produce the correct estimated error pattern. Instead, the decoder may fail to converge or output an erroneous syndrome, or it may estimate an error pattern with the same syndrome that differs from the actual pattern by a logical operator.

Iterative decoders may be viewed as graph-based algorithms that operate on the code's Tanner graph, which is the graphical representation of the code's parity check matrix. Failure of iterative decoding of LDPC codes has been attributed to graphical substructures, called {\em trapping sets}, in the Tanner graph \cite{R03}.  These structures contribute to persistent error floors in the Bit Error Rate (BER) or Frame Error Rate (FER) curves of these codes.  Moreover, these structures naturally depend on the choice of Tanner graph representation used in the decoding process. Failure inducing sets of a trapping set are subsets of the codeword coordinates that, when initially in error, lead to  a decoding failure. While most work on decoder failure of QLDPC codes has focused on defining and identifying trapping sets of QLDPC codes \cite{raveendran2021trapping}, less have characterized  failure inducing sets of trapping sets.  This work aims to identify classes of failure inducing sets, and takes initial steps at predicting the type of error that results from different failure inducing sets. 

Iterative decoder failure of classical LDPC codes on different channels is  attributed to graphical substructures, such as stopping sets, trapping sets, and absorbing sets \cite{Di02, R03, dolecek07}. We observed in decoder simulations that many failure inducing sets of QLDPC trapping sets were in fact absorbing sets. Since absorbing sets and trapping sets are closely related in structure, it is natural to question the role absorbing sets play, if any, in syndrome-based iterative decoder failure of QLDPC codes.  In this paper we examine the connection between absorbing sets, as they are defined for classical LDPC codes, and trapping sets, and identify cases when absorbing sets are trapping sets and failure inducing sets.

This paper is organized as follows. In Section II, we introduce the necessary notation and background on quantum stabilizer codes, QLDPC codes and their graph representation, and syndrome-based iterative decoding.  In Section III we examine graph structures that affect decoder performance. In Section IV we analyze absorbing sets and identify cases when absorbing sets are  trapping sets with respect to the syndrome decoder, and when they are failure inducing sets. We conclude the paper in Section V with  observations for future work.
\section{Preliminaries}


\subsection{Stabilizer formalism} 
Stabilizer codes~\cite{Gottesman-phd97} are quantum codes obtained as the simultaneous eigenspace of commuting Pauli matrices. Specifically, the Pauli group acting on one physical qubit $\C^2$, denoted $\cP_1$, is generated by ${\sf I}_2 = \ppsmatrix{1&0\\0&1}, {\sf X} = \ppsmatrix{0&1\\1&0}, {\sf Z} = \ppsmatrix{1&0\\0&-1}$, and ${\sf Y} = i{\sf XZ}$. 
The Pauli group acting on $n$ physical qubits $\C^{\otimes n}\cong\C^{2^n}$, denoted $\cP_n$, is then naturally the $n$-fold Kronecker product of $\cP_1$.
A stabilizer group $\cS\leq \cP_n$ is an abelian group that does not contain $-{\sf I}_{2^n}$. 
A stabilizer with $k$ independent generators can be naturally represented as an $k\times 2n$ matrix $H_\cS = \ppsmatrix{H_{\sf X}&\mid&H_{\sf Z}}$, and it defines an $[\![n,n-k]\!]$ quantum code.
Two stabilizer generators commute if and only if their respective representations $h = (h_{\sf X}, h_{\sf Z}), g = (g_{\sf X},g_{\sf Z})$ of $H$ are orthogonal with respect to the {\em symplectic inner product} $h\odot g = h_{\sf X}g_{\sf Z}^T + h_{\sf Z}g_{\sf X}^T$.
Cumulatively, this leads to
\begin{equation}\label{e-sip}
H_\cS\odot H_\cS:=H_{\sf X}H_{\sf Z}^T + H_{\sf Z}H_{\sf X}^T = 0.
\end{equation}
The {\em logical operators} acting on the code space correspond to the elements of the Pauli group that commute with $\cS$. Elements of $\cS$ commute with each other so they are naturally (trivial) logical operators.

An important class of stabilizer codes are the Calderbank-Shor-Steane (CSS) codes~\cite{CS96,Steane96}, defined by a pair of classical linear codes $C_{\sf X}, C_{\sf Z}\subset \Fq^n$ such that $C_{\sf X}^\perp\subset C_{\sf Z}$. 
This condition forces two respective parity check matrices $H_{\sf X}$ and $H_{\sf Z}$ to satisfy $H_{\sf Z}H_{\sf X}^T = 0$ and thus the matrix
\[
H = \left(\!\!\begin{array}{c|c}H_{\sf X}&0\\0&H_{\sf Z} \end{array}\!\!\right)
\]
satisfies~\eqref{e-sip} and it defines a stabilizer code.


%%%%%%%%%%%%%%%%%%%%%
%\begin{tikzpicture}[thick,scale=1]
%\node (x1) at (-1,3) {\textbf{1}};
%\node[circle,scale=.9,fill=black,label={left:$v_1$}] (v1) at (-2,0){};
%\node[circle,scale=.9,fill=black,label={left:$v_2$}] %(v2) at (-1,0) {};
%\node[circle,scale=.9,fill=black,label={left:$v_3$}] (v3) at (0,0) {};
%\node[circle,scale=.9,fill=black,label={left:$v_4$}] (v4) at (1,0) {};
%\node[regular polygon,regular polygon sides=4,scale=.9,fill=black,label={left:$y_1$}] (y1) at (-1.5,1) {};
%\node[regular polygon,regular polygon sides=4,scale=.9,fill=black,label={left:$y_2$}] (y2) at (-0.2,1) {};
%\node[regular polygon,regular polygon sides=4,scale=.9,fill=black,label={left:$y_3$}] (y3) at (1,1) {};
     % \draw[-](v1)--(y1) node[pos=.5,fill=none,above]{};
      % \draw[-](v1)--(y2) node[pos=.5,fill=none,above]{};
      % \draw[-](v2)--(y1) node[pos=.5,fill=none,below]{};
       % \draw[-](v2)--(y3) node[pos=.5,fill=none,below]{};
       % \draw[-](v3)--(y2) node[pos=.5,fill=none,below]{};
               % \draw[-](v4)--(y2) node[pos=.5,fill=none,below]{};
             %   \draw[-](v4)--(y3) node[pos=.5,fill=none,below]{};
%\end{tikzpicture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{QLDPC codes} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{QLDPC codes and syndrome-based iterative decoding}
Low density parity check (LDPC) codes are codes characterized by having sparse parity check matrix representations.
Given a parity check matrix $H$ of an LDPC code, its bipartite Tanner graph representation is the graph $\cG = (V,W; E)$
where the vertex sets $V$ and $W$ correspond to the codeword coordinates and the parity check equations, respectively, and $E$ is the set of edges. Vertices in $V$ and $W$ are called variable and check nodes, respectively. For $v_i \in V$ and $c_j \in W$, the edge $(v_i,c_j)\in E$ if and only if $h_{j,i} = 1$ in $H$. The sparsity of $H$ ensures that the graph is sparse, making it amenable to low-complexity iterative decoders. Indeed, the complexity of iterative decoders is linear in the number of edges \cite{T81}.

Tanner graphs are defined similarly for quantum CSS codes. However, since the parity check equations can be partitioned into those that have nonzero entries in  $H_{\sf X}$ and those that have nonzero entries in $H_{\sf Z}$, the variable nodes have two edge types, those determined by ${\sf X}$ errors and those determined by ${\sf Z}$ errors, and each check node is incident to only one edge type.

Typically, for stabilizer codes and quantum codes in general there is a correlation between ${\sf X}$ and ${\sf Z}$ errors. However, for CSS codes we can ignore such correlation~\cite{mackay2004sparse} and treat them over two independent binary symmetric channels.
Let $e = (e_\sfX,e_\sfZ)$ be the binary representation of a Pauli error acting on $n$ qubits. The corresponding error syndrome captures the commutativity/orthogonality relations of the error with each of the stabilizers, that is,
\begin{align*}
\sigma_e & = (\sigma_\sfX, \sigma_\sfZ)
= \left(\!\!\begin{array}{c|c}H_{\sf X}&0\\0&H_{\sf Z} \end{array}\!\!\right)\odot e 
= (H_\sfZ e_\sfX^T, H_\sfX e_\sfZ^T).
\end{align*}
Thus, $H_{\sf X}$ can be used to decode ${\sf Z}$ errors and $H_{\sf X}$ can be used to decode ${\sf Z}$ errors.
An all-zero syndrome indicates that the error $e$ commutes with all the stabilizers and thus it is undetectable. %\tp: this needs to go somewhere
If $f$ is itself a stabilizer, that is, it belongs to the rowspace of $H$, then $\sigma_f = \vec{0}$. It follows that for any Pauli error $e$ we have $\sigma_{e+f} = \sigma_e$. This means that decoding can be only performed up to stabilizers. Two Pauli errors $e, f$ are called {\em degenerate errors} if they yield the same syndrome $\sigma_e = \sigma_f$, or equivalently, if $e+f$ is a stabilizer. Such errors have no classical analog.

The goal of a syndrome-based decoder is to match the input syndrome. Specifically, the decoder outputs estimated errors $\hat{e}$ whose syndrome $\sigma_{\hat{e}}$ matches the input syndrome $\sigma_e$.
Once the syndromes are matched, the estimated error is applied to correct the error introduced by the channel.
Error correction fails if the decoder fails to match the syndrome or if there is a mis-correction, that is, the decoder produces a logical error. In particular, a logical error occurs if $e+\hat{e}$ is not a stabilizer.

To summarize, the possible outcomes of syndrome decoding are the following. 
If the estimated syndrome $\sigma_{\hat{e}}$ matches the input syndrome $\sigma_e$ and $\hat{e}=e$, the decoder recovered the exact error pattern. If $\sigma_{\hat{e}}$ matches $\sigma_e$ and $e +\hat{e}$ is in the rowspace of $H$, the decoder recovered a degenerate error $\hat{e}$, which is still considered successful decoding. Decoding failure occurs if there is a logical error, meaning $\sigma_{\hat{e}}$ matches $\sigma_e$ but $e + \hat{e}$ is not a stabilizer. Decoding failure also occurs if the estimated syndrome $\sigma_{\hat{e}}$ never matches the input syndrome $\sigma_e$. This can occur either when the estimated syndrome oscillates and never converges to the correct syndrome, or if the estimated syndrome converges to $\sigma_{\hat{e}}$ which does not match $\sigma_e$.

We now present the Gallager-B Syndrome-based Iterative Decoding Algorithm over the Binary Symmetric Channel (BSC). Let $e=(e_1, e_2, \dots, e_n) \in \mathbb{F}_2^n$ denote an error pattern, where $e_i = 1$ if variable node $v_i$ is in error, and $e_i = 0$ otherwise. Thus, $e$ is an incidence vector of the error locations. The neighboring checks of the variable nodes are either satisfied or unsatisfied, where an unsatisfied check means the incoming messages sum to $1\pmod 2$ and a satisfied check means the incoming messages sum to $0\pmod 2$. These check node values correspond to the input syndrome $\sigma=(\sigma_1, \sigma_2, \dots, \sigma_k)$.

For decoding, an all-zero error pattern is initially assumed. That is, all outgoing message symbols $\hat{e}_i$ are set to $0$. The outgoing check node message over an edge is computed as the XOR of extrinsic variable node messages and syndrome input value. The outgoing variable node message is the majority value among incoming extrinsic check node messages. If there is a tie, then the value of $0$ is sent, since a low weight error pattern is assumed.
The error pattern at the $\ell^{th}$ iteration, denoted $\hat{e}^{\ell}$, is determined to be the majority among \textit{all} incoming check node values at each variable node. If there is a tie, there is assumed to be no error.
The output syndrome value for the $i^{th}$ check node $c_i$ in the $\ell^{th}$ iteration is   
    $$\hat{\sigma}_i^{\ell} := \sum_{j \in \mathcal{N}(c_i)} \hat{e}_j \pmod 2$$
where the sum is taken over all incoming messages $\hat{e}_j$ in the neighborhood of the $c_i^{th}$ check node and is computed modulo 2. A check node $c_i$ is matched if and only if $\hat{\sigma}_i=\sigma_i$. If all syndrome values are matched, the iterative decoder outputs the error pattern $\hat{e}$. If not, the decoder repeats the previous steps.



%%%%%%%%%%%%%%%%%%%%%
\section{Iterative decoder failure and trapping sets}

%\subsection{Iterative decoder failure}

In this section, we provide background on trapping sets, failure inducing sets, and absorbing sets, and show via examples how they affect iterative decoder performance. Moreover, we also illustrate the different types of decoder outcomes that can happen under syndrome-based iterative decoding.


Given a Tanner graph $\cG = (V,W; E)$ and a subset $S$ of $V$, let $\mathcal{N}(S)$ denote the set of check nodes that are incident to vertices in $S$. Let $\cG_S = (S,W_S;E_S)$, where $W_S = \mathcal{N}(S)$, denote the subgraph induced by $S \cup W_S$ in $\cG$. Thus,   $E_S$ is the set of edges in $\cG$ that have one vertex in $S$ and the other in $W_S$. Let $\mathcal{C}$ be a binary LDPC code of length $n$ with associated Tanner graph $\cG$, to be decoded with some chosen hard- or soft-decision decoder. Suppose that the codeword $\mathbf{x}$ is transmitted, and $\mathbf{y}$ is received. Let $\mathbf{y}^{\ell}$ be the output after $\ell$ iterations of the decoder are run on $\cG$, with  input syndrome $\sigma=(\sigma_1, \sigma_2, \dots, \sigma_k)$. 

\begin{defi}
A variable node $v_{i}$, for $1\leq i \leq n$, is said to be {\em eventually correct} if there exists $L\in \mathbb{Z}_{\geq 0}$ such that $y_{i}^{\ell}=x_{i}$ for all $\ell\geq L$. Similarly, a check node $c_j$, for $1\leq j \leq k$, is {\em eventually correct} if there exists $L\in \mathbb{Z}_{\geq 0}$ such that $\hat{\sigma_{j}}^{\ell}=\sigma_{j}$ for all $\ell\geq L$. 
\end{defi}

%Since we will be concerned with syndrome-based iterative decoding, we also define the following.
\begin{defi} A variable node $v_{i}$, for $1\leq i \leq n$, is said to {\em eventually converge} if there exists $L\in \mathbb{Z}_{\geq 0}$ such that $\hat{e}_{i}^{\ell}=\hat{e}_{i}^{(\ell + 1)}$ for all $\ell\geq L$.  Similarly, a check node $c_j$, for $1\leq j \leq k$,  {\em eventually converges} if there exists $L\in \mathbb{Z}_{\geq 0}$ such that $\hat{\sigma_{j}}^{\ell}=\hat{\sigma}_{j}^{(\ell+1)}$ for all $\ell\geq L$. 
\end{defi}

Note that if  variable node $v_i$ eventually converges, it may or may not converge to the correct estimate, $e_i$.

%We start by recalling the definitions of trapping sets, inducing sets, and absorbing sets for classical LDPC codes.
%\tp{this differs from the paper def}\christine{I have updated definitions 1-4}

\begin{defi} A (quantum) trapping set  for a syndrome-based iterative decoder is a non-empty set  of variable nodes $\mathcal{T}$ in a Tanner graph $\cG$ such that there is a subset of variable nodes $\mathcal{F} \subseteq \mathcal{T}$ that when initially in error result in some subset of check nodes of $\mathcal{N}(\mathcal{T})$ that are not eventually correct and/or some subset of variable nodes of $\mathcal{T}$ that do not eventually converge. Such a subset $\mathcal{F}$ of variable nodes that when initially in error result in a trapping set $\mathcal{T}$ is called a {\em failure inducing} set for $\cT$. If the induced subgraph $\cG_\cT$ has $a$ variable nodes and $b$ odd degree check nodes, then $\mathcal{T}$ is said to be an {\em $(a,b)$-trapping set}. 
\end{defi}



Although $\cG_\cT$ is induced by $\cT \cup \cN(\cT)$, the graph $\cG_\cT$ is often referred to in the literature as a trapping set (TS) induced subgraph. To analyze decoder failure, we follow the convention of assuming messages outside the trapping set are correct.


\begin{defi}  
The {\em critical number} of a trapping set $\mathcal{T}$, denoted $\mu(\cT)$, is the smallest number of variable nodes in a failure-inducing set for $\mathcal{T}$. The {\em strength} of a trapping set $\mathcal{T}$ is the number of failure inducing sets of cardinality $\mu$.
\end{defi}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Figure environment removed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{exa} Figure ~\ref{fig:TSexample1} shows a subgraph induced by a $(4,2)$-trapping set $\mathcal{T} = \{v_1,v_2,v_3,v_4\}$. $\mathcal{T}$ has five failure inducing sets, shown in 
%Table~\ref{tab:TSexample1Table} 
the adjacent table,
along with their corresponding variable node and check node sets that do not eventually converge or are not eventually satisfied, respectively. Observe that $\mu(\mathcal{T}) = 3$ and the strength of $\mathcal{T}$ is four. Since each failure inducing set leads to check nodes that are not eventually satisfied, the corresponding type of error is a mismatched syndrome.  \hfill $\Box$
% {\small




% \begin{center}

% \centering 

% % Figure environment removed


% \begin{table}[!h]
% \centering
% \begin{tabular}{ |c|c|c| } 
%  \hline
%  Failure-Inducing & VNs not  & CNs not  \\ 
%  Set &  Eventually  & Eventually  \\ 
%  & Converged & Satisfied \\
% \hline
%  $\{v_1, v_2, v_3, v_4\}$ & None & $\{c_5, c_{7}\}$ \\ %& $\{v_2, v_4\}$\\ 
%  \hline
% $ \{v_1, v_2, v_4\}$ &$\{v_1, v_2, v_4\}$ &$\{c_1, c_2, c_3, c_4, c_5, c_6, c_{7}\}$ \\ %& $\{v_1, v_2, v_3, v_4\}$\\
%  \hline
%  $\{v_1, v_3, v_4\}$ & None & $\{c_1, c_2, c_5, c_{7}\}$ \\%&$\{v_1, v_2, v_3, v_4\}$ \\
%  \hline
% $\{v_2, v_3, v_4\}$ & $\{v_2, v_3, v_4\}$ &$\{c_1, c_2, c_3, c_4, c_5, c_6, c_{7}\}$ \\% & $\{v_1, v_2, v_3, v_4\}$ \\
% \hline
% $\{v_1, v_2, v_3\}$ & None &$\{c_3, c_4, c_5, c_{7}\}$ \\% & $\{v_1, v_2, v_3, v_4\}$ \\
% \hline 
% \end{tabular}
% \caption{Failure-inducing sets of $\mathcal{T}$.}
% \label{tab:TSexample1Table}
% \end{table}
% \end{center}
% }


 %Note that if one regards a quantum trapping set as a non-empty set of variable nodes in a Tanner graph $\cG$ that  are not eventually converged or that are neighbors of check nodes that are not eventually correct, then the trapping set corresponding to the failure inducing set $\{v_1,v_2,v_3,v_4\}$ is $\{v_2,v_4\}$, however, the graph induced by. 

 %For example, Figure 1(a) shows a subgraph induced by a $(5,3)$-trapping set. 
    
\end{exa}


%\begin{defi} %A (classical) {\em trapping set}  $\mathcal{T}$ for an iterative decoder $\mathcal{D}$ is a non-empty set of variable nodes in a Tanner graph $\cG$ that  are not eventually correct.
% A (quantum) {\em trapping set} $\cT$ for a syndrome-based iterative decoder $\mathcal{D}_S$ is a non-empty set of variable nodes in a Tanner graph $\cG$ that  are not eventually converged or that are neighbors of check nodes that are not eventually correct. 
%\end{defi}


Absorbing sets are a related combinatorial structure that characterize iterative decoder failure of classical LDPC codes in many settings \cite{dolecek07}. In examining syndrome-based iterative decoding, we found that many failure inducing sets corresponded to absorbing sets, motivating the investigation in this paper.








%Note that the critical number may arise from a failure-inducing set not fully contained in $\mathcal{T}$. 


% For comparison purposes, we note the following related definitions of stopping sets \cite{DPTRU02}, which characterize iterative decoder failure on the binary erasure channel (BEC), and types of absorbing sets, which have been shown to characterize failure of some iterative decoders operating on classical LDPC codes \cite{DZAWN07}\cite{ald13}.
% \tp{I think we exclusively use BSC, so not sure if we need stopping sets}

% \begin{defi} A {\em stopping set} $S$ in a Tanner graph $\cG$ is a subset of variable nodes such that each vertex in $\mathcal{N}(S)$ has at least two neighbors in $S$.
% \end{defi}

%  Sets of variable nodes that are not eventually correct during iterative decoding over the BEC correspond to supports of stopping sets. Thus, stopping sets are simply trapping sets with respect to iterative decoding on the BEC. Moreover, a set of variable nodes in $G$ is a failure-inducing set for a stopping set $S$ if and only if it is a subset of variable nodes in $G$ that contains $S$. The critical number of a stopping set is thus equal to its size.

\begin{defi}
An \textit{$(a,b)$-absorbing set} $\mathcal{A}$ in a Tanner graph $\cG$ is a subset of variable nodes such that $|\mathcal{A}| = a$, there are $b$ odd degree vertices in $W_{\mathcal{A}}$, and every variable node  $v\in \mathcal{A}$ has more even degree than odd degree neighbors in $\cG_{\mathcal{A}}$. % Let $\mathcal{O}(\mathcal{A})$  %(resp., $\mathcal{E}(\mathcal{A})$) 
%denote the vertices in $W_{\mathcal{A}}$ with %odd degree %(resp., even degree) 
%in $G_{\mathcal{A}}$. If in addition, all variable nodes in $V \backslash \mathcal{A}$ have strictly more neighbors in $W \backslash \mathcal{O}(\mathcal{A})$ than in $\mathcal{O}(\mathcal{A})$, then $\mathcal{A}$ is a \textit{fully absorbing set}. An \textit{ elementary absorbing set}  is an absorbing set in which all vertices in $W_{\mathcal{A}}$ have degree one or two in $\cG_{\mathcal{A}}$.  
\end{defi} 

In Figure 1, the set $\mathcal{A} = \{v_1,v_2,v_3,v_4\}$ is a $(4,2)$-absorbing set since there are four variable nodes in the set,  two odd degree check nodes in the graph $\mathcal{G}_{\mathcal{A}}$, and each variable node has more even degree check neighbors than odd degree. Similarly, $\{v_1,v_2,v_3\}$ and $\{v_1,v_3,v_4\}$ are $(3,3)$-absorbing sets. However,  the remaining two failure inducing sets are  not absorbing sets since each has  variable nodes with more odd degree than even degree check neighbors in its corresponding induced subgraph.\\ 
\indent We conclude this section with another example   to illustrate the extent to which absorbing sets correspond to failure-inducing sets of a trapping set. %The various trapping sets are from~\cite{raveendran2021trapping}.
%This section is motivated by the figure from \cite{raveendran2021trapping}.
The purpose of this analysis is to better understand the topology of failure inducing sets and see how they relate with absorbing sets. Similar to Example 1, some of the failure inducing sets are absorbing sets whereas some are not.
For all analyses we have used the syndrome-based Gallager-B iterative decoder. 
\begin{exa}  Consider Figure \ref{fig:Fig4NV21} from ~\cite{raveendran2021trapping}. Figure \ref{fig:Fig4NV21}(a) shows a subgraph induced by a $(5,3)$-trapping set $\mathcal{T}$. 
First, the only failure-inducing set with three or fewer variable nodes is $\{v_2,v_4,v_5\}$. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Figure environment removed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%if any three or less variable nodes are in error then the decoder successfully corrects these errors. 
The corresponding input syndrome is $(1,1,1,1,1,1,1,1,1)$, but the decoder oscillates between a syndrome estimate of $(0,0,0,0,0,0,1,1,1)$ and $(0,0,0,0,0,0,0,0,0)$ corresponding to error estimates of all variables in error and none in error, respectively.
%This anomaly is due to the fact that the induced graph is disconnected and the odd degree check nodes will be unsatisfied every other iteration.
The decoder is successful for any other configuration of three or fewer variable nodes in error. \\
\indent All errors of weight four or five result in decoding failure. When four variable nodes are in error there are two types of behaviors shown in Table ~\ref{tab:TSexample2Table}. The first three error patterns correspond to $(4,4)$-absorbing sets whose induced graphs are all isomorphic to Figure~\ref{fig:Fig4NV21}(b). In these cases the decoder converges to a mismatched syndrome. The last two error patterns are not absorbing sets and have induced subgraphs corresponding to Figure~\ref{fig:Fig4NV21}(c). In these cases the decoder oscillates among syndromes, none of which match the input syndrome.\\
%shows the graph $\mathcal{G}_{\mathcal{A}}$ induced by the $(4,4)$-absorbing set $\mathcal{A}=\{v_1,v_2,v_3,v_4\}$ in $\mathcal{T}$ that is also failure-inducing. The two other (4,4)-absorbing sets with subgraphs isomorphic to $\mathcal{G}_{\mathcal{A}}$, namely $\{v_1, v_2, v_3, v_5\}$ and $\{v_1, v_3, v_4, v_5\}$, are also failure-inducing. 
%Figure~\ref{fig:Fig4NV21}(c) shows the graph $\mathcal{G}_{\mathcal{B}}$ induced by $\mathcal{B}=\{v_1, v_2, v_4, v_5\}$. This configuration fails to be an absorbing set in that there are variables nodes that have equal number of odd degree and even degree check nodes.
\indent Finally, the set of all variable nodes $\{v_1, v_2, v_3, v_4, v_5\}$ forms a $(5,3)$-absorbing set that when in error results in decoder failure due to mismatched syndrome. Thus the entire set of variable nodes is failure inducing. \hfill $\Box$ %leading to . , if all of the variable nodes are in error, the decoder never matches the syndrome and results in decoding failure. Note that the whole trapping set is also a (5,3)-absorbing set.


\begin{table}
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{|c|c|c|c|}
\hline
Nodes in Error & Input Syndrome & Estimated Syndrome & Estimated Error\\
 \hline
 $\{v_1, v_2, v_3, v_4\}$ & $(0,0,0,0,1,1,0,1,1)$ & $(0,0,0,0,0,0,1,0,0)$ & $\{v_5\}$\\ 
 \hline
 $\{v_1, v_2, v_3, v_5\}$ & $(0,0,1,1,0,0,1,1,0)$ & $(0,0,0,0,0,0,0,0,1)$ & $\{v_4\}$\\
 \hline
  $\{v_1,v_3, v_4, v_5\}$ & $(1,1,0,0,0,0,1,0,1)$ & $(0,0,0,0,0,0,0,1,0)$ & $\{v_2\}$\\ 
 \hline
$\{v_1, v_2, v_4, v_5\}$ & $(0,1,1,0,0,1,1,1,1)$ & $\begin{array}{c}(0,0,0,0,0,0,0,0,0)\\(0,0,0,0,0,0,0,0,0)\\ (1,1,1,1,1,1,0,0,0)\\(1,1,1,1,1,1,0,0,0)\end{array}$ & $\begin{array}{c}\{v_2, v_3, v_4, v_5\}\\ \{ \}\\ \{v_2, v_3, v_4, v_5\}\\ \{v_1, v_3\}\end{array}$\\
 \hline
$\{v_2, v_3, v_4, v_5\}$ & $(1,0,0,1,1,0,1,1,1)$ & $\begin{array}{c}(1,1,1,1,1,1,0,0,0)\\(1,0,0,1,1,0,1,1,1)\\(0,0,0,0,0,0,0,0,0)\\(0,0,0,0,0,0,0,0,0)\\\end{array}$ & $\begin{array}{c}\{v_1, v_3\}\\  \{v_1,v_2, v_4, v_5\}\\ \{ \}\\ \{v_1, v_2,v_4,v_5\}\end{array}$\\
\hline
\end{tabular}
}
\caption{Behavior of weight four error patterns. The first three error patterns correspond to isomorphic (4,4)-absorbing sets in Figure 2(b). The last two error patterns correspond to isomorphic  failure-inducing sets in Figure 2(c).}
\vspace{-.1 in}
\label{tab:TSexample2Table}
\end{table}


% % Figure environment removed
\end{exa}
% %Next, we present an analysis of the failure inducing sets from the trapping sets given in Figure 3 of \cite{raveendran2021trapping}.\\
% On the other hand, any error pattern of weight four yields an induced subgraph isomorphic to Figure~\ref{fig:Fig7NV21}(b), and is failure-inducing.
% This configuration is not an absorbing set in that there are variables nodes with an equal number of odd degree and even degree check nodes. Finally, the unique weight five error pattern corresponds to a $(5,5)$-absorbing set and also a failure-inducing set.
% \end{exa}

\section{Connections between absorbing sets and failure inducing sets}

In this section we aim to understand when absorbing sets are  failure inducing sets with respect to the syndrome-based decoder. We consider absorbing set graphs and analyze which subsets of variable nodes are failure inducing with respect to that graph. We first show that all absorbing sets whose graphs have odd degree check nodes are failure inducing sets with respect to its graph, and therefore are  trapping sets.

%Since all cases have failure inducing sets, the absorbing set graph is a trapping set. %Moreover, when an absorbing set is a trapping set, we identify subsets of the variable nodes that are failure-inducing sets for the trapping set.


\begin{theo}
%Consider an absorbing set with at least one odd degree check node. 
Let $\cA$ be an $(a,b)$-absorbing set with $b\geq1$.
Then the absorbing set is a failure inducing set. In particular, the decoding syndrome will always be $\vec{0}$ and thus the syndrome value at the odd degree check nodes will never match the input syndrome, thus resulting in a decoding failure.
\end{theo}

\begin{proof}
Let $\cA$ be an absorbing set with at least one odd degree check node. Suppose all variable nodes are in error. Then the input syndrome $\sigma = (\sigma_1,\ldots, \sigma_k)$ has $\sigma_i = 1$ if check node $i$ has odd degree, and $\sigma_i = 0$ otherwise.

% %\[
% \begin{aligned}
% \sigma_i = \begin{cases}
% 1, & \text{ if the check node is odd degree,}\\
% 0, & \text{ if the check node is even degree.}
% \end{cases}
% \end{aligned}
% %\]

The decoder first assumes an all zero error pattern, corresponding to syndrome $\vec{0}$. 
For the next step of the decoding, all even degree check nodes send $0$ and the odd check nodes send $1$. 
Since $\cA$ is an absorbing set, each variable node has strictly more even degree than odd degree check nodes. Thus the error pattern is again $\vec{0}$. When sending information to the check nodes, the extrinsic check nodes are at most evenly tied between odd degree and even degree check nodes. 
If there is a tie, in all cases the variable nodes will send $0$ to every check node. The syndrome is again $\vec{0}$, mismatching the input syndrome at the odd degree check nodes. Additionally, the algorithm is back to the beginning scenario (sending $0$'s to every check node). Therefore the algorithm never terminates, as it decodes to an all zero error pattern and corresponding all zero syndrome at every step.
\end{proof}

We now consider the case when an absorbing set has only even degree check nodes in its graph.% We classify when  the absorbing set is or is not failure inducing with respect to its graph.  


\begin{theo} Consider an absorbing set $\cA$ where every check node is of even degree. That is, $\cA$ is an $(a,0)$ absorbing set. If $\vec{1}$ is in the rowspace of $H_{\mathcal{A}}$ (the parity check matrix corresponding to $G_{\mathcal{A}}$), then $\mathcal{A}$ is not a failure inducing set on $G_{\mathcal{A}}$. That is, the decoder will return a degenerate error when all variable nodes are in error. 
%If $\vec{1}$ is not in the rowspace of $H$, 
Otherwise, then there is a logical error when decoding and $\cA$ is a failure inducing set on $G_{\cA}$. 
\end{theo}

\begin{proof}
Assuming all of the variable nodes in $\cA$ are in error, the corresponding input syndrome is $\sigma=\vec{0}$. The decoder assumes an initial error pattern of $\vec{0}$. Then the corresponding estimated syndrome is $\vec{0}$. Since this syndrome matches the input syndrome, the decoding halts and estimates an error pattern $\hat{e}=\vec{0}$. If $\vec{1}$ is a stabilizer, then $e + \hat{e}=\vec{1}$ is a stabilizer and the decoder returned a degenerate error. Otherwise there is a logical error.
% Let $H$ denote the Tanner Graph of $A$. Recalling that the rowspace of $H$ is a subspace of $\mathbb{F}_2^m$ it follows that $\vec{0}$ is in the rowspace of $H$.Thus there exist scalars $a_i \in \mathbb{F}_2$ such that 
%
% $$\vec{0}=\sum_{i=1}^m a_i \vec{r}_i,$$
%
% where $\vec{r}_i$ denotes the $i^{th}$ row of $H$. It follows that 
%
% \[
% \begin{aligned}
% \vec{0}+\vec{1} &=\sum_{i=1}^m a_i \vec{r}_i + \vec{1}\\
% \Rightarrow \vec{1} &= \sum_{i=1}^m (a_i +1)\mod{2} \vec{r}_i.\\
% \end{aligned}
% \]
% Therefore $\vec{1}$ is in the rowspace of $H$, implying $\vec{0}$ and $\vec{1}$ are degenerate errors. Consequently the decoder successfully decoded to a degenerate error.\\
\end{proof}


Although absorbing sets whose graphs have only even degree check nodes are not always failure inducing, we show in the next series of results that such absorbing sets may still be trapping sets due to the presence of other failure inducing sets.


\begin{lem}
Let $\cA$ be an $(a,0)$-absorbing set such that $\cG_\cA$ is isomorphic to the path $\cP_{2a-1}$ equal to $v_1c_1v_2c_2\dots c_{a-1}v_a$.
% % Figure environment removed
%Given an $(a,0)$ absorbing set isomorphic to $P_{2a-1}$. Every $(a,0)$ path $V$ is a trapping set. In particular, ordering the variable nodes from left to right \kirsten{create a figure to describe this} as $\{v_1, v_2, \dots, v_n\}$ and check nodes from left to right as $\{c_1, c_2, \dots, c_{n-1}\}$, the subset $\{v_1\}$ will always be a failure inducing set, caused by the syndrome never matching the input syndrome during the decoding process. On the $\ell^{th}$ iteration the syndrome $\hat{\sigma}{^{\ell}}$ is 
Then, $\{v_1\}$ is a failure-inducing set. Indeed, on the $\ell^{th}$ iteration the syndrome %$\hat{\sigma}{^{\ell}}$ 
is $\hat{\sigma}^{\ell} = (0,1,1\ldots,1,0,\ldots,0)$ with $\ell -1$ ones, thus it never matches the input syndrome $(1,0,\dots, 0)$. Since the graph is symmetric, a similar statement holds true for $\{v_a\}$.
\end{lem}
% \[
% \hat{\sigma}{^{\ell}} = \begin{cases}
%   \Vec{0}  & \ell=0\\
%   (\hat{\sigma}^{\ell}_i)_{i=1}^{n} & 1 \leq \ell < n\\
%   (0,1,\dots, 1) & \ell \geq n\\
% \end{cases}
% \]

% where for $1 \leq \ell < n$ 

% \begin{equation}\label{e-path-syn}
% \hat{\sigma}^{\ell}_i = \begin{cases}
% 0, & i=1,\\
% 1, & 2 \leq i \leq \ell,\\
% 0, & \ell +1 \leq i \leq n,\\
% \end{cases}
% \end{equation}
% \begin{equation}\label{e-path-syn}
%     \hat{\sigma}^{\ell} = (0,\underbrace{1,1\ldots,1}_{\ell-1},0,\ldots,0)
% \end{equation} 


\begin{proof}
Set $\ell =0$. The decoder first assumes an all-zero error pattern. %That is, every variable node sends a $0$ to the check nodes. 
Therefore 
$\hat{\sigma}^0 = \Vec{0}.$
%\kirsten{want to induct to prove the statement for when $1 \leq \ell < n$. This is the base case:} 
In the next step of decoding, the check node $c_1$ sends $0 + 1 \equiv 1 \pmod 2$ to $v_1$ and $v_2$. Every other check node sends $0$ to their neighboring variable nodes.

Next, $v_1$ and $v_a$ send $0$ to $c_1$ and $c_{a-1}$, respectively, since they are the endpoints of the path and have no extrinsic check nodes. The variable node $v_2$ sends $0$ to $c_2$ and $1$ to $c_3$. Every other variable node sends $0$ to their neighboring check nodes. Therefore, 
$\hat{\sigma}^{1} = (0,1,0,\dots, 0).$
%\kirsten{Need to be careful about how to apply the inductive hypothesis. it isn't sufficient to know the syndrome in the previous iteration but need to precisely state what the values of the extrinsic neighbors are).} 
For $\ell=2$, as in every step, $v_1$ and $v_a$ send 0 to $c_1$ and $c_{a-1}$. But, in this iteration, $v_2$ sends 0 to $c_1$ and 1 to $c_2$, resulting on the syndrome $\hat{\sigma}^2 = (0,1,1,0,\ldots, 0)$.
Continuing in such a fashion we obtain $\hat{\sigma}^{\ell}$ as in the claim. Moreover for $\ell>a$, the syndrome never changes. 
% $$\hat{\sigma}^{n-2}=(0,1,\dots, 1,0,0).$$
% In the next step, $v_1$ and $v_n$ send $0$ to $c_1$ and $c_{n-1}$, respectively. For $2\leq i \leq n-2$, $v_i$ sends $0$ to $c_{i-1}$ and sends $1$ to $c_i$. Finally, $v_{n-1}$ sends $0$ to both $c_{n-2}$ and $c_{n-1}$. Thus 
% $$\hat{\sigma}^{n-1} = (0, 1, \dots, 1, 0).$$
% \noindent Proceeding, $v_1$ and $v_n$ send $0$ to $c_1$ and $c_{n-1}$. For $2 \leq i \leq n-1$, $v_i$ sends $0$ to $c_{i-1}$ and sends $1$ to $c_i$. Therefore 
% $$\hat{\sigma}^{n}=(0,1, \dots, 1).$$
% We again use induction to show that 
% $$\hat{\sigma}^{\ell} = (0,1,\dots, 1)$$
% for all $\ell \geq n$, with the base case shown immediately above. For $\ell > n$ we have that $v_1$ and $v_n$ send $0$ to $c_1$ and $c_{n-1}$, respectively. For $2\leq i \leq n-1$, $v_i$ sends $0$ to $c_{i-1}$ and sends $1$ to $c_i$. Thus 
% $$\hat{\sigma}^{\ell} = (0,1,\dots, 1).$$
% Therefore the syndrome never matches the input syndrome and hence there is a decoding failure, implying such $(a,0)$ paths form a trapping set.
\end{proof}

While it is necessary to identify at least one failure inducing set to characterize whether or not a subset of variable nodes forms a trapping set, we are interested in understanding failure inducing sets more broadly to gain a better understanding of overall decoder performance. Empirical results for paths indicate different phenomena occurring based on the parity of the number of variable nodes $a$. When $a$ is even,  $\vec{1}$ is in the rowspace of the parity check matrix for $\mathcal{G}_{\mathcal{A}}$, and when $a$ is odd, $\vec{1}$ is not in the rowspace of the parity check matrix. Because of this, we observe successful decoding of a large class of errors $e$ when $a$ is even, as the decoder returns $e+\vec{1}$ as the estimated error, successfully returning a degenerate error. However, in the odd case this results in a logical error.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{theo}
    An acyclic $(a,0)$-absorbing set $\cA$ is a trapping set.
\end{theo}
\begin{proof}
Without loss of generality assume $\cG_{\cA}$ is connected (since a union of disconnected absorbing sets is absorbing), so $\cG_{\cA}$ is a tree. Thus, $\cG_\cA$ has at least two leaves, and by assumption, since $\cG_\cA$ has no degree one check nodes, the leaves are variable nodes. Let $v$ be a leaf and $c$ its adjacent check node.
We claim that $\{v\}$ is a failure inducing set. In particular, the input syndrome value at $c$ is 1, but the decoding process always estimates a syndrome value of 0.
This is due to the fact that all incoming messages to $c$ from neighboring variable nodes are 0, resulting in the estimated syndrome value at $c$ being 0, hence mismatched and resulting in decoding failure. The remainder of the proof shows why this is the case. 

First note that degree one variable nodes always send 0 to $c$ since they have no extrinsic variable nodes.
On the other hand, variable nodes of degree strictly higher than two will also send 0 due to majority voting. To see this, see Figure~\ref{acyclic1}.
Decoding starts with all variable nodes sending 0 to their neighbors.
Since the outgoing check node message is the XOR of all extrinsic check nodes and the input syndrome value, $c$ sends 1 to its neighbors and all other check nodes send 0.
Additionally, at variable nodes of degree higher than two (such as $v'$) there are more check nodes sending 0 than sending 1. So there is at most an equal number of extrinsic check nodes sending 0 and sending 1. In event of a tie, 0 is sent. Thus, the incoming messages in $c$ are always 0, and this causes a mismatch.
% Figure environment removed
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Figure environment removed

Now consider when $c$ has neighboring variable nodes of degree exactly two (excluding $v$). We consider what happens on any of these branches from $c$ (see Figure~\ref{acyclic2}). The first possibility is when a branch from one of these degree two variable nodes contains all degree two nodes and thus forms a path, as in Figure~\ref{acyclic2}(a). The second is when the closest node to $c$ on the branch that has degree larger than two is a variable node, as in Figure~\ref{acyclic2}(b). The third is when the closest node to $c$ on the branch that has degree larger than two is a check node, as in Figure~\ref{acyclic2}(c). In all these subcases, any degree two check node adjacent to $c$ always receive 0 from their neighbors (extrinsic to $c$). Thus, all incoming messages to $c$ are 0, resulting in a mismatched syndrome.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{theo}
Consider an $(a,0)$-absorbing set $\cA$ such that $G_{\cA}$ forms a cycle $v_1c_1v_2c_2\ldots v_{a}c_av_1$. We have the following  cases: 
\begin{enumerate}[itemsep=0em,leftmargin=11pt]
        \item When $a$ is even, any singleton forms a failure inducing set.
        \item When $a$ is odd, $\{v_1, v_2, v_{\frac{a+3}{2}}\}$ forms a failure inducing set.
\end{enumerate}
\end{theo}

\begin{proof}
%    We first consider the case where $a$ is even. Without loss of generality suppose $v_1$ is in error. Then the input syndrome is 
%    $\sigma = (1, 0,0, \dots, 0, 1).$
%   The decoder starts with all variable nodes sending $0$ to their neighbors. Given the decoding algorithm rules, $c_1$ and $c_a$ send $0$ to their neighbors. All other check nodes send $0$. Since each variable node is of degree $2$, each variable node swaps the message it receives from its neighbors. That is, $v_i$ sends what it receives from $c_{i-1}$ to $c_i$ and vice versa. Because of this, $v_1$ sends $1$ to both its neighbors, $v_2$ sends $0$ to $c_1$ and $1$ to $c_2$, $v_a$ sends $0$ to $c_a$ and $1$ to $c_{a-1}$, and all other variable nodes send $0$. Since all check nodes are also degree $2$ and have syndrome value $0$ except for $c_1$ and $c_a$, this behavior moves around the cycle. That is, at iteration $i$ for $2 \leq i \leq \frac{a+2}{2}$, $v_1$ sends $1$ to its neighbors, $v_i$ sends $0$ to $c_{i-1}$ and $1$ to $c_i$, $v_{a-(i-2)}$ sends $0$ to $c_{a-(i-2)-1}$ and $1$ to $c_{a-(i-2)}$, and all other variable nodes send $0$. For $\frac{a}{2}+1 \leq i \leq a$, $v_1$ sends $1$ to its neighbors, $v_i$ sends $1$ to $c_{i-1}$ and $0$ to $c_i$, $v_{a-(i-2)}$ sends $1$ to $c_{a-(i-2)-1}$ and $0$ to $c_{a-(i-2)}$, and all other variable nodes send $0$. At iteration $a+1$ all variable nodes send $0$, and the decoder is back at the first step of the decoding. Therefore $\sigma^{\ell} \neq \sigma$ for any iteration $\ell$, and hence any singleton is a failure inducing set for $\cA$ when $a$ even.
Due to space limitations, we omit the proof of the first case, and include the proof of the second one, which is nevertheless the more interesting one.
Let $e$ be the error vector corresponding to variables $\{v_1, v_2, v_{\frac{a+3}{2}}\}$ being in error.
The corresponding input syndrome $\sigma$ has unsatisfied checks $j\in \{2, \frac{a+3}{2}-1, \frac{a+3}{2},a\}$.
We show that on iteration $j=\frac{a+3}{2}$ the estimated syndrome $\hat{\sigma}^{(\frac{a+3}{2})}$ matches the input syndrome $\sigma$ and returns an estimated error $\hat{e}=\vec{0}$. However, $e \oplus \hat{e}=e$ is not in the rowspace of $H$, and hence there is a logical error. That is, there is a decoding failure. 

Since the variable nodes and check nodes are all degree two, at each stage of decoding the variable nodes swap the messages they receive from their neighbors. Similarly, all check nodes with input syndrome value $0$ also swap the messages they receive from their neighbors. Starting with all variable nodes initially sending $0$ to their neighbors, all check nodes correspondingly send $0$ back to their neighbors except for $c_2$, $c_{\frac{a+3}{2}-1}$, $c_{\frac{a+3}{2}}$, and $c_a$. At iteration $2$, $c_2$ sends $1$ to $v_3$ and this $1$ moves around the cycle such that at iteration $\frac{a+3}{2}$, $1$ is sent from $v_{\frac{a+3}{2}-1}$ to $c_{\frac{a+3}{2}-1}$. Likewise, at iteration $\frac{a+3}{2}$, $v_{\frac{a+3}{2}+1}$ sends $1$ to $c_{\frac{a+3}{2}}$. All check nodes besides $c_2$, $c_a$, $c_{\frac{a+3}{2}-1}$, and $c_{\frac{a+3}{2}}$ receive zeroes from both neighbors, so the estimated syndrome at iteration $\frac{a+3}{2}$ matches the input syndrome. When computing the estimated error, $v_1$, $v_2$, $v_{\frac{a+3}{2}-1}$, and $v_{\frac{a+3}{2}+1}$ each receive a $0$ and a $1$ from their neighbors. All other variable nodes receive $0$ from both neighbors. The tie-breaking rule for the Gallager $B$ decoding algorithm results in an estimated error of $\hat{e}=\vec{0}$. However, $e \oplus \hat{e}=e$ is not in the rowspace of $H$, so there is a decoding failure.
\end{proof}

\section{Concluding Observations}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This paper took a first step at relating classical absorbing sets  to trapping sets and failure inducing sets of QLDPC codes. Our results show that almost all absorbing set graphs have failure inducing sets and therefore are trapping sets. The remaining case,  namely the general non-acyclic $(a,0)$-absorbing set where $\vec{1}$ is in the rowspace of $H$ remains open and will hopefully be included in the final version of this paper.  % We believe it is also a trapping set and hope to include the proof in the final version of this paper.

We plan to extend this analysis to understand the role absorbing sets play when embedded in larger graphs. For example, although an $(a,b)$-absorbing set $\mathcal{A}$ with $b \ge 1$ is failure inducing with respect to its induced graph, it may or may not be failure inducing as a subgraph of a larger graph. We observed that in most cases, the odd degree check nodes of $\mathcal{G}_{\mathcal{A}}$ correspond to check nodes that are not eventually correct in the larger graph, except for certain cases such as when these odd degree nodes connect to each other via a path of degree two nodes. %Understanding what conditions make a check node not eventually correct or a variable node not eventually converge is key to characterizing failure analysis.

Similarly,  we are working to characterize when $(a,0)$-absorbing sets are failure inducing as subgraphs of larger graphs. We observed that such absorbing sets, though not failure inducing with respect to their induced subgraphs, can be failure inducing in larger graphs in some cases. Understanding the conditions that make absorbing sets failure inducing or not will  give insight to when arbitrary  subsets of variable nodes are failure inducing. \\
\indent Moreover, we took initial steps at examining the types of decoding failure that results in different scenarios (e.g. logical error, degenerate error, mismatched syndrome). We note that the results we have obtained apply to syndrome-based iterative decoding analysis of classical LDPC as well, where whenever a degenerate error results, it is regarded as a decoder failure in the classical case.  Finally, we remark that characterizing failure inducing sets that are not absorbing sets remains open.

%\begin{lem}
%\textbf{Even Degree Absorbing Sets within larger Even Degree graphs} Consider an $(a,0)$ absorbing set $A$. If $A$ is placed within a larger $(b,0)$ absorbing set $B$ and the variable nodes $A$ are in error, the decoder will successfully converge to a degenerate error. Specifically, the decoder will converge to $\vec{1}$ plus the error pattern.\\
%\end{lem}

%\begin{lem}
%Consider an $(a,0)$ absorbing set $A$. Suppose $A$ is placed within a larger graph $B$ such that all of the check nodes connecting $A$ and the larger graph $B$ are of odd degree.  Suppose the variable nodes of $A$ are in error. Then there are two cases:
%\begin{itemize}
%\item If the corresponding input syndrome is $\vec{0}$, the decoder will converge to the correct syndrome and an error pattern of $\vec{0}$. Thus if the error pattern is in the rowspace of the corresponding matrix $H$, the decoder successfully converged to a degenerate error.\\
%\item If the corresponding input syndrome is not $\vec{0}$, then the decoder will fail. Specifically, the decoder will converge to an all zero syndrome $\vec{0}$.\\
%\end{itemize}
%\end{lem}

\bibliographystyle{IEEEtran}
\bibliography{qabs.bib}
\end{document}

\end{document}