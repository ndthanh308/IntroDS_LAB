%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% https://www.biomedcentral.com/getpublished                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% https://miktex.org/                                             %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
% This file demonstrates how to use the IEEEConf LaTeX2e macro package,
% to prepare a manuscript for proceedings on CD of the conference
% FedCSIS %VERA: hier arbeiten Deadline 2.Maiwoche
%
\documentclass[technote,onecolumn]{IEEEtran} % ,onecolumn
%\documentclass[a4paper]{IEEEconf}

% This package serves to balance the column lengths on the last page of the document.
% please, insert \balance command in the left column of the last page
\usepackage{balance}
\usepackage[utf8]{inputenc}
\usepackage[greek,english]{babel}

%% to enable \thank command
\IEEEoverridecommandlockouts 
%% The usage of the following packages is recommended
%% to insert graphics
\usepackage[dvips]{graphicx}
% to typeset algorithms
\usepackage{algorithmic}
\usepackage{algorithm}
% to typeset code fragments
\usepackage{listings}
% to make an accent \k be available
%\usepackage[OT4,T1]{fontenc}
% provides various features to facilitate writing math formulas and to improve the typographical quality of their output.
\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
% por urls typesetting and breaking
\usepackage{url}
% for vertical merging table cells
\usepackage{multirow}
\usepackage{pgfplots} 
% define environments for remarks and examples
%\newtheorem{remark}{Remark}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}[remark]{Example}
\usepackage{amssymb}
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{dfn}{Definition}
\newtheorem{thm}[dfn]{Theorem}
\newtheorem{corollary}[dfn]{Corollary}
\newtheorem{exl}[dfn]{Example}
\newtheorem{lem}[dfn]{Lemma}
%
%

%%% Load packages
\usepackage{amsthm,amsmath}
%\RequirePackage[numbers]{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails

% for writing definitions
\usepackage{amsthm}

% for subfigures
\usepackage{subcaption}

% for matrices, special symbols
\usepackage{amsmath}
\usepackage{amssymb}

% for python snippets
\usepackage{pythonhighlight}

% for argmax/argmin symbols
%https://tex.stackexchange.com/questions/5223/command-for-argmin-or-argmax
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


% .ini highlighting
% source https://tex.stackexchange.com/questions/266693/listings-style-for-ini-conf-files
\usepackage{listings}
\lstdefinelanguage{Ini}
{
    basicstyle=\ttfamily\small,
    columns=fullflexible,
    morecomment=[s][\color{blue}\bfseries]{[}{]},
    morecomment=[l]{;},
    commentstyle=\color{gray}\ttfamily,
    morekeywords={},
    otherkeywords={=},
    keywordstyle={\color{green}\bfseries}
}
\lstdefinelanguage{BNF}
{
    basicstyle=\ttfamily\small,
    columns=fullflexible,
    morecomment=[s][\color{blue}\bfseries]{<}{>},
    morecomment=[l]{//},
    commentstyle=\color{gray}\ttfamily,
    morekeywords={},
    otherkeywords={::=},
    keywordstyle={\color{green}\bfseries}
}

% for tables
\usepackage{multirow}
\usepackage{diagbox}

% for forcing figure placements
\usepackage{float}


%todo notes
\usepackage{todonotes}


% csv to table
% source https://tex.stackexchange.com/questions/146716/importing-csv-file-into-latex-as-a-table
\usepackage{csvsimple}
\usepackage{url}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\def\includegraphic{}
%\def% Figure removed

%%% Put your definitions there:
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
%%% Begin ...


%%% Start of article front matter


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{A Generic Framework for Hidden Markov Models on Biomedical Data}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\author{
\IEEEauthorblockN{Richard Fechner\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}%\IEEEauthorrefmark{3}
, Jens Dörpinghaus\IEEEauthorrefmark{1}\IEEEauthorrefmark{3}\IEEEauthorrefmark{4}, Robert Rockenfeller\IEEEauthorrefmark{3}\IEEEauthorrefmark{5}\IEEEauthorrefmark{6}}, Jennifer Faber\IEEEauthorrefmark{4}%, Vera Weil\IEEEauthorrefmark{3}}

\IEEEauthorblockA{%
\IEEEauthorrefmark{1} Federal Institute for Vocational Education and Training (BIBB), Bonn, Germany}\\
\IEEEauthorrefmark{2}  University of Tübingen, Germany,\\
\IEEEauthorrefmark{3}  University of Koblenz, Germany,\\ 
\IEEEauthorrefmark{4} German Center for Neurodegenerative Diseases (DZNE)\\
\IEEEauthorrefmark{5}  School of Biomedical Sciences, University of Queensland, Brisbane, Australia\\
\IEEEauthorrefmark{6} School of Science, Technology and Engineering, University of the Sunshine Coast, Queensland, Australia}

%\author[
  %addressref={aff1,aff2},                   % id's of addresses, e.g. {aff1,aff2}
  %corref={aff1},                       % id of corresponding address, if any
%% noteref={n1},                        % id's of article notes, if any
  %email={richard.fechner@student.uni-tuebingen.de}   % email address
%]{\inits{R.F.}\fnm{Richard} \snm{Fechner}}
%\author[
  %addressref={aff2,aff3,aff6},
  %corref={aff2},
  %email={doerpinghaus@uni-koblenz.de}
%]{\inits{J.D.}\fnm{Jens} \snm{Dörpinghaus}}
%\author[
  %addressref={aff2,aff4,aff5},
  %email={rrockenfeller@uni-koblenz.de}
%]{\inits{R.R.}\fnm{Robert} \snm{Rockenfeller}}
%\author[
  %addressref={aff3},
  %email={Jennifer.Faber@dzne.de}
%]{\inits{J.F.}\fnm{Jennifer} \snm{Faber}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                          %%
%%% Enter the authors' addresses here        %%
%%%                                          %%
%%% Repeat \address commands as much as      %%
%%% required.                                %%
%%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\address[id=aff1]{%                           % unique id
  %%\orgdiv{Department of Science},             % department, if any
  %\orgname{University of Tübingen},          % university, etc
  %\city{Tübingen},                              % city
  %\cny{Germany}                                    % country
%}
%\address[id=aff2]{%
  %%\orgdiv{Institute of Biology},
  %\orgname{University of Koblenz},
  %%\street{},
  %%\postcode{}
  %\city{Koblenz},
  %\cny{Germany}
%}
%\address[id=aff3]{%
  %%\orgdiv{Institute of Biology},
  %\orgname{German Center for Neurodegenerative Diseases (DZNE)},
  %%\street{},
  %%\postcode{}
  %\city{Bonn},
  %\cny{Germany}
%}
%\address[id=aff4]{%
  %%\orgdiv{Institute of Biology},
  %\orgname{University of the Sunshine Coast},
  %%\street{},
  %%\postcode{}
  %\city{Queensland},
  %\cny{Australia}
%}
%\address[id=aff5]{%
  %%\orgdiv{Institute of Biology},
  %\orgname{University of Queensland},
  %%\street{},
  %%\postcode{}
  %\city{Brisbane},
  %\cny{Australia}
%}
%\address[id=aff6]{%
  %%\orgdiv{Institute of Biology},
  %\orgname{Federal Institute for Vocational Education and Training (BIBB)},
  %%\street{},
  %%\postcode{}
  %\city{Bonn},
  %\cny{Germany}
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{artnotes}
%%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
%\end{artnotes}

%\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                           %%
%% The Abstract begins here                  %%
%%                                           %%
%% Please refer to the Instructions for      %%
%% authors on https://www.biomedcentral.com/ %%
%% and include the section headings          %%
%% accordingly for your article type.        %%
%%                                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{abstractbox}
\begin{document}
\maketitle      
\begin{abstract} % abstract
%The Abstract should not exceed 350 words. Please minimize the use of abbreviations and do not cite references in the abstract. The abstract must include the following separate sections:

\textbf{Background} %if any
Biomedical data are usually collections of longitudinal data assessed at certain points in time. Clinical observations assess the presences and severity of symptoms, which are the basis for description and modeling of disease progression. Deciphering potential underlying unknowns solely from the distinct observation would substantially improve the understanding of pathological cascades. Hidden Markov Models (HMMs) have been successfully applied to the processing of possibly noisy continuous signals. The aim was to improve the application HMMs to multivariate time-series of categorically distributed data. Here, we used HHMs to study prediction of the loss of free walking ability as one major clinical deterioration in the most common autosomal dominantly inherited ataxia disorder worldwide.
We used HHMs to investigate the prediction of loss of the ability to walk freely, representing a major clinical deterioration in the most common autosomal-dominant inherited ataxia disorder worldwide.

\textbf{Results} %if any
We present a prediction pipeline which processes data paired with a configuration file, enabling to construct, validate and query a fully parameterized HMM-based model. In particular, we provide a theoretical and practical framework for multivariate time-series inference based on HMMs  that includes constructing multiple HMMs, each to predict a particular observable variable. Our analysis is done on random data, but also on biomedical data based on Spinocerebellar ataxia type 3 disease.

\textbf{Conclusions} %if any
%The implementation of the HMM framework is publicly available and can be easily configured and adapted for further experiments.
%We will show that our proposed approach shows promising results when tested on real world application data and present a detailed discuss and how the approach could be augmented to improve results.
%%Wiederum: das ist für mich keine konsistente Schlussfolgerung
HHMs are a promising approach to study biomedical data that naturally are represented as multivariate time-series. Our implementation of a HHMs framework is publicly available and can easily be adapted for further applications.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{keyword}
%\kwd{Longitudinal Modeling}
%\kwd{HMM}
%\kwd{Prediction Pipeline}
%\kwd{Biomedical data prediction}
%\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

%\end{abstractbox}
%
%\end{fmbox}% uncomment this for two column layout

%\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                            %%
%% The Main Body begins here                  %%
%%                                            %%
%% Please refer to the instructions for       %%
%% authors on:                                %%
%% https://www.biomedcentral.com/getpublished %%
%% and include the section headings           %%
%% accordingly for your article type.         %%
%%                                            %%
%% See the Results and Discussion section     %%
%% for details on how to create sub-sections  %%
%%                                            %%
%% use \cite{...} to cite references          %%
%%  \cite{koon} and                           %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}      %%
%%                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%

\section{Introduction}

%\subsection{Motivation}

The central idea of Machine Learning (ML) is the attempt to infer the unknown solely from observation. Every environment emits signals. In the context of health and disease, observational signs and symptoms represent such measurable signals. Here, a central question is the identification of temporal order and predictive features for deterioration. The use case for real world data we present here, are observational data from large natural history studies in the worldwide most common autosomal dominantly inherited ataxia disorder, spinocerebellar ataxia type 3, see \cite{Faber2021,ESMINfLSerum,ESMINfLPlasma,ATXN3}. Spinocerbellar ataxia 3 is a neurodegenerative disease with onset of symptoms in adult life, around the 4th decade, see \cite{SCAreview2018,SCAreview2019}. Clinical hallmarks are the progressive loss of balance, coordination deficits and slurred speech. SCA3 patients experience significant restrictions of mobility and communicative skills. Notably, SCA3 is a so-called rare disease with a prevalence of < 3 per 100,000. %, may it be rays of light, which we perceive through our eyes, sound waves, which we can hear with our ears, or other signals we can measure with our instruments.
Ataxia as the most prominent symptom is measure with a scale that assesses 8 different items, like gait, stance or speech. In the observational studies included here, participants were assessed on an annual basis and the resulting scoring (itemwise as well as the overall ataxia severity sum score) are considered as signals. Measuring signals for consecutive discrete time steps present so-called multivariate time-series -- or to put it in other words -- a series of multiple observable variables over a period of time. Our aim is to infer knowledge about a state-sequence of an unknown variable from these sequences of observations. The methodological novelty presented in this article is the capability of choosing, which unknown quantity, to infer from observation. The presented model is not only able to infer knowledge about quantity $A$ by observing quantity $B$ but allows for the exploration in the opposite direction, namely reasoning about $B$ from observing $A$ (see Figure \ref{fig:intro_1}). Furthermore, our work extends this conceptual principle to a more general case, in which the model allows for maximum flexibility and generality by being able to choose any constellation of different observable variables to infer knowledge about any other observable variable. This extension is realized within the widely used probabilistic framework of Hidden Markov Models (HMMs). Our work presents two test environments, including the application of the model to real world medical data based on SCA3. 



% Figure environment removed{}

HMMs have been successfully applied to the processing of possibly noisy continuous signals in the case of speech or gesture recognition \cite{baker1975dragon,nilsson2002speech, lee1999hmm}, as well as to the processing of sequences of discrete signals like text categorization \cite{frasconi2001text}. In the context of biomedical data, they have been incorporated into forecast models, improving estimates about patient mortality \cite{vairavan2012prediction}. Here, we will focus on multivariate time-series of categorically distributed data. We present a prediction pipeline which processes data paired with a configuration file, enabling to construct, validate and query a fully parameterized HMM-based model. Specifically, we will propose a rather new technique that includes constructing multiple HMMs -- one for each variable sequence of the multivariate sequence -- to predict another observable variable. We will demonstrate in a use case that the newly proposed technique can perform well when tested on real world application data. Finally, we will discuss strengths and weaknesses of the model and how the approach could be augmented to improve results.

The aim of this article is thus to a) provide a theoretical and practical framework for multivariate time-series inference based on HMMs and b) apply and validate the proposed prediction pipeline (see Figure \ref{fig:intro_2}) to real world data.

% Figure environment removed{}

%To pave the way for the latter parts of this thesis, I'm first going to cover the most fundamental basics, including Graph Theory, the basic theory of Hidden Markov Models, big-O notation and Machine Learning metrics in Section \ref{section:Foundations}. After having laid out the most fundamental theory, I'll continue in Section \ref{section:Method}, introducing notation and giving an in-depth overview of the inner workings of the prediction pipeline as well as model prediction capabilities. Going further, in Section \ref{section:Evaluation} I'll apply the previously presented techniques on a - for exemplary purpose synthesized - dataset, before shifting the attention to the application on real world medical data supplied by the DZNE (German Center for neurodegenerative diseases). In the last Section, I'll give an interpretation of the results and discuss the performance of the model, before closing with an outlook on possible augmentations and improvements of the model.

\section{Background}\label{section:Foundations}

%\subsection{Graph Theory}

%\subsubsection{Graphs}
%A Graph is an abstract mathematical object used to model relationships between objects. In its simplest form, an \textbf{undirected Graph} can be used to model relationships between certain entities. The formal definition is as follows.

%\begin{definition}
%An \textbf{undirected Graph} $G=(V, E)$ is a tuple containing a set of vertices $V = \{v_1, v_2, ..., v_N\}$, sometimes also called nodes, and a set of edges $E \subseteq V \times V$ connecting the vertices with each other. Additionally, $(v_a, v_b) \in E \iff (v_b, v_a) \in E$.
%\end{definition}

%\begin{definition}
%A \textbf{directed Graph} $G = (V,E)$ is a tuple of the set of vertices and edges. The direction of the edge $e_i$ is inferred from the order of the tuple by which $e_i$ is defined by.
%\end{definition}

%To give an example, the edge $e_k = (v_a, v_b)$ connects the vertex $v_a$ to vertex $v_b$. With the introduced notion of direction, one can model more complex dynamics, like for example different states connected by state transitions.\\

%Finally, one can augment the edges between the vertices, by assigning weights to them. A weight function $w : E \rightarrow{\mathbb{R}}$ is introduced, which maps an edge $e$ to their corresponding edge-weight $w(e)$. A weight $w(e)$ corresponding to an edge $e = (v_a, v_b)$ can be interpreted as the cost of traveling from vertex $v_a$ to vertex $v_b$. Alternatively, we can interpret the weight of a transition (edge) between two states  (vertices) as the probability of transitioning between the two. The latter interpretation will be very useful to describe a system of states and the transitions between them, where the probability of moving from one state to another in a single timestep is denoted by the weight of the edge connecting the two states.\\

%\subsubsection{Matrix Representation of a Graph}
%An undirected, unweighted Graph $G = (V,E)$ can be represented $G$ as a symmetric $|V| \times |V|$ matrix $\mathcal{A}$, where the elements of matrix $a_{ij}$ are marked as\\
%\begin{equation*}
    %a_{ij} =
    %\begin{cases}
        %1 & (v_i, v_j) \in E\\
        %0 & else
    %\end{cases}
%\end{equation*}
%such that the entry $a_{ij}$ in the matrix indicates, whether the vertices $v_i$ and $v_j$ are connected to one another.\\

%Extending this idea to directed, weighted Graphs comes naturally. Suppose we have a directed, weighted Graph $G = (V, E)$ with a weight function $w : E \rightarrow{\mathbb{R}}$ respecting stochastic constraints, namely that the sum of all weights for out-going edges is to equal 1, for all vertices
%\begin{equation*}
    %\sum{w(e_i)} = 1, e_i \in \{e_k \in E | e_k = (u, v)\} \hspace{1cm} \forall u \in V
%\end{equation*}
%and that all edge-weights must be non negative.
%\begin{equation*}
    %w(e) \geq 0, \hspace{1cm} \forall e \in E
%\end{equation*}{}
%This allows $G$ to be represented as a \textbf{row-stochastic matrix} $\mathcal{A}$, where $a_{ij}$

%\begin{equation*}
    %a_{ij} =
    %\begin{cases}
        %w(e_k) & e_k = (v_i, v_j) \in E\\
        %0 & else
    %\end{cases}
%\end{equation*}

%denotes the probability of transitioning (weight of the connecting edge) from state (vertex) $i$ to state (vertex) $j$ in a single timestep.

\subsection{Markov Chains}

A first order \textbf{Markov Chain} is a stochastic process  describing the transition between a system's states.

\begin{definition}
A Markov Chain is defined by the set of $N$ states $S = \{S_1, ..., S_N\}$ and a $N \times N$ row-stochastic transition matrix $\mathcal{A}$ where $a_{ij}$ defines the probability of transitioning from state $S_i$ to state $S_j$ in a single time step.
\end{definition}

We will be concerned with first order Markov Chains, which satisfy the so called \emph{Markov Property}.

\begin{definition}
The \textbf{Markov Property}
\begin{equation*}
    P[q_t = S_i \hspace{0.2cm}|\hspace{0.2cm} q_{t-1} = S_j] = P[q_t = S_i \hspace{0.2cm}|\hspace{0.2cm} q_{t-1} = S_j, ..., q_{t-k} = S_x]
\end{equation*}
states that the probability for state transition is solely dependent on the previous state, regardless of any other $k$ states visited before that. Here, $q_t, q_t-1$ and $q_t-k$ denotes the chain's state at time step $t$, where $S_i$, $S_j$ and $S_x$ are sample states of the underlying system. 
\end{definition}

%\subsection{An Introductory Example}
%Suppose, that we want to model the weather as a Markov Chain with exactly two states, $S$ (for sunny) and $R$ (for rainy). By observing the actual weather for some time, we get a rough estimate of what the transition probabilities between the states are, thus obtaining the transition probability matrix $\mathcal{A}$. In addition, we are now able to compute the stationary distribution $\pi$ from our transition matrix. Here, $\pi_{S_i}$ denotes the probability of starting in state $S_i$. Later, we will call $\pi$ the initial state distribution. Now, we use our model (see Figure \ref{fig:hmm1}), let us call it $\lambda = (\mathcal{A}, \pi)$, to reason about the probability of certain state-sequences. One question we could ask might be ``\textit{What is the probability of observing a sunny day, then another sunny day, finally a rainy day, out of all possible 3-day observations?}''.\\

%We can answer this question by querying our model. Since our model satisfies the \textbf{Markov Property}, we know that $P[\mathcal{O} = S S R \hspace{0.2cm}|\hspace{0.2cm} \lambda]$ the probability of observing the given observation sequence, given our model $\lambda$ comes out to be the product of the probability of initially starting in state $S$ ($\pi_S$), the transition probability from state $S$ to itself ($a_{11}$) and the transition probability from state $S$ to state $R$ ($a_{12}$).

%\begin{flalign*}
    %P[\mathcal{O}\hspace{0.2cm}|\hspace{0.2cm} \lambda]& = P[q_1=S, q_2=S, q_3=R \hspace{0.2cm}|\hspace{0.2cm} \lambda] &\\
    %& = P[ q_1 = S \hspace{0.2cm}|\hspace{0.2cm} \lambda ] \cdot P[ q_2 = S \hspace{0.2cm}|\hspace{0.2cm}q_1 = S,  \lambda ] \cdot P[ q_3 = R \hspace{0.2cm}|\hspace{0.2cm} q_2 = S, \lambda ] &\\
    %& = \pi_{S} \cdot a_{11} \cdot a_{12} &
%\end{flalign*}


%This simple framework allows us to assign a probability to any observable sequence. The subsequent paragraph will show how to extend the framework to the inference of probability for sequences of non-observable hidden states based on observations.

\subsection{From Markov Chain Model to Hidden Markov Model}

In some cases, the states in our Markov Chain Model are directly observable. However, suppose that the states we would like to reason about are not directly observable and are hidden. This motivates the extension of a Markov Chain Model to a \emph{Hidden Markov Model}, in which the actual states we would like to reason about are hidden and cannot be observed. We can only observe \emph{emission-signals}, which are being emitted from the hidden states. We follow Rabiners definition of HMMs, see \cite{rabiner1989tutorial}.

\begin{definition}
A \textbf{Hidden Markov Model} $\lambda = (\mathcal{A}, \mathcal{B}, \pi)$ with the hidden states $S = \{S_1, ..., S_N\}$ and emission signals $V = \{V_1, ..., V_M\}$ is a stochastic process, defined by three model parameters
\begin{enumerate}
    \item $N \times N$ row-stochastic \textbf{state transition matrix} $\mathcal{A}$, where the element $a_{ij}$ denotes the state transition probability from state $S_i$ to state $S_j$.\\

    An alternative notation for denoting the state transition from $q_{t-1}$ to $q_t$ is given by $a_{q_{t-1}q_t}$.\\

    \item $N \times M$ row-stochastic \textbf{state emission matrix} $\mathcal{B}$ where the element $b_{ij}$ denotes the probability $P[o_t = V_j | q_t = S_i]$ of observing emission signal $o_t = V_j$ at time step $t$ under the hidden state $S_i$.\\

    An alternative notation for denoting the observation of signal $o_t$ from the hidden state $q_t$ is given by $b_{q_t}(o_t)$.\\
    \item $1 \times N$ \textbf{initial state distribution vector} $\pi$, where $\pi_i = P[q_1 = S_i]$.\\

    An alternative notation for denoting the initial state probability for hidden state $q_t$ is given by $\pi_{q_t}$.\\
\end{enumerate}
\end{definition}



%Coming back to our simple weather model, let us transform the Markov Chain Model into a Hidden Markov Model. Assume, that we are unable to observe the actual state of the weather (maybe our window blinds are down). The only thing we can observe is the presence or absence of dogs barking, whilst they are being taken on a walk. Thus, we have two \emph{hidden states}, namely $R$ (for rainy) and $S$ (for sunny), as well as two \emph{emission signals}, namely $B$ (for barking) and $\neg B$ (for not barking). For the sake of simplicity, let us assume that we were able to estimate the transition probabilities for the hidden states, as well as the emission probabilities for each hidden state, and noted them into our row-stochastic matrices $\mathcal{A}$ and $\mathcal{B}$ respectively. Furthermore, let us assume that the initial state distribution is given with $\pi_S = \pi_R = \frac{1}{2}$.\\

%Having all model parameters $(\mathcal{A}, \mathcal{B}, \pi)$ fixed, we can reason about the hidden states solely from made observations. For example, we could have observed the sequence $\mathcal{O} = B B B \neg B \neg B$ and now ask ourselves what the most likely weather state sequence is.

Situations, where one needs to infer a sequence of hidden states from an observation sequence are very common. In the medical context for example we might be interested in inferring a sequence of diagnoses from the patients observed heartbeat and breathing frequency at certain time points.

\subsection{Three Basic Problems for HMMs}

Generally, we are concerned with inferring a sequence of hidden states from a sequence of observed states, a so-called \emph{sequence-to-sequence} prediction. The Hidden Markov Model excels at this task, although we will see that the path towards a stable prediction poses some challenges and conceals certain pitfalls one needs to avoid. Following Rabiner \cite{rabiner1989tutorial}, we see three main problems have to be solved to be able to apply HMMs in practice. We will discuss their solution within the next sections.

\begin{itemize}
\item \textbf{Problem 1}: Given an observation sequence $\mathcal{O} = o_1 o_2 ... o_T$, as well as a fully parameterized model $\lambda = (\mathcal{A}, \mathcal{B}, \pi)$, how do we calculate the probability $P[\mathcal{O}|\lambda]$ in an efficient manner?\\
\item \textbf{Problem 2}: Given an observation sequence $\mathcal{O} = o_1 o_2 ... o_T$ as well as a fully parameterized model $\lambda = (\mathcal{A}, \mathcal{B}, \pi)$, how do we find the state sequence $\mathcal{Q} = q_1 q_2 ... q_T$ best explaining the seen observation?\\
\item \textbf{Problem 3}: Given a model $\lambda$, how do we train the model, changing its parameters to maximize $P[\mathcal{O} | \lambda]$?
\end{itemize}
Solving the first problem enables us to compare different Hidden Markov Models. Given an observation sequence $\mathcal{O}$, we might prefer the model $\lambda$, which maximizes $P[\mathcal{O}|\lambda]$, the probability of observing the given sequence based on model parameters.

A solution to the second problem allows for an inference of a sequence of hidden states $\mathcal{Q}$ given an observation sequence $\mathcal{O}$. Since many different hidden state sequences might produce the given observation sequence, the problem becomes finding a $\mathcal{Q}$, which maximizes $P[\mathcal{O}|\mathcal{Q},\lambda]$, the probability of the hidden state sequence $\mathcal{Q}$ emitting the observation sequence $\mathcal{O}$.

The third problem is to approximate the in practice \emph{unknown} model parameters $\mathcal{A}, \mathcal{B}, \pi$ given an observation sequence $\mathcal{O}$. This can be interpreted as training an HMM on an observation sequence.

\subsubsection{Solution to Problem 1}

%Problem 1 is the problem of evaluating the probability of observing an observation sequence $\mathcal{O}$ given a model $\lambda$. Solving this problem enables us to compare different models, thus letting us decide which model ``best fits'' our observation.
This problem is best approached naively at first, without taking computational costs into account. As we will see, the need for a smarter, less computationally intensive solution will arise along the way.

First, consider a fixed state sequence $Q = q_1...q_T$ of some states that might emit the observation sequence. The probability of this sequence arising from the model is given by the product of the probability of starting in the state $q_1$, which is given by $\pi_ {q_1}$ and the correct state transition probabilities.

\begin{equation*}
    P[Q|\lambda] = \pi_{q_1}\prod_{t = 1}^{T-1}a_{q_tq_{t+1}} = \pi_{q_1}\cdot a_{q_1q_2}...\cdot a_{q_{T-1}q_T}.
\end{equation*}
 Additionally, the probability of observing the observation sequence $\mathcal{O}$ from the state sequence $Q$ is given by the product of the single emission probabilities for the individual observations under the hidden state.

 \begin{equation*}
     P[\mathcal{O}|Q, \lambda] = \prod_{t = 1}^{T}b_{q_t}(o_t) = b_{q_1}(o_1) \cdot ... \cdot b_{q_T}(o_T)
 \end{equation*}

 Finally, the probability for observing $\mathcal{O}$ under $Q$ is $P[Q|\lambda] \cdot P[\mathcal{O}|Q, \lambda]$. Having computed this probability for one possible state sequence, all that is left is computing it again for every single possible state sequence of length $T$.

 \begin{equation*}
 P[\mathcal{O}|\lambda] = \sum_{Q \in \mathcal{Q}}P[Q|\lambda] \cdot P[\mathcal{O}|Q, \lambda]
 \end{equation*}

 Where, $\mathcal{Q}$ is the set of all possible state sequences of length $T$. Although very declarative, this solution is practically useless since the computational effort required to solve for only one observation sequence increases exponentially with the length $T$ of the sequence, as for every time step there are up to $N$ different state transitions to be made, resulting in a total of at worst $N^{T}$ different candidates for $Q$, which are to be evaluated. This is unfeasible for even a small number of hidden states $N$ and a short sequence length.

 To overcome this hurdle, we make use of dynamic programming and temporarily store intermediate results to bootstrap and extend for a new, more optimal iteration of an intermediate result until we have reached the desired solution.

\begin{definition}
The \textbf{forward variable} $\alpha_t(i) = P[o_{1}...o_t | q_t = S_i, \lambda]$ is defined as the probability of observing the partial observation sequence $o_1...o_t$ given State $S_i$ at time step $t$ as well as a fully parameterized model $\lambda$.
\end{definition}






 We will use dynamic programming to compute the forward variable $\alpha_t(i)$ from our solutions for $\alpha_{t-1}(j)$, where $1 \leq j \leq N$ (see Figure \ref{fig:lattice_forward}). The full solution is as follows:\\

 % Figure environment removed{}

 \begin{enumerate}
     \item Initialization: $          \alpha_1(i) = \pi_i \cdot b_i(o_1) \hspace{1cm} 1 \leq i \leq N $
     \item Induction:
        \begin{align*}
            \alpha_t(j) = \left(\sum_{j = 1}^N \alpha_{t-1}(j)a_{ij}\right) \cdot b_j(o_{t-1})
                            & \hspace{1cm} 1 \leq j \leq N\\
                            & \hspace{1cm} 1 < t \leq T
         \end{align*}
     \item Termination: $P[\mathcal{O} | \lambda] = \sum_{i = 1}^N \alpha_T(i)$
 \end{enumerate}{}


 % Figure environment removed{}

In the first step, we initialize the storage for the intermediate results, before continuously calculating the next intermediate results (see Figure \ref{fig:full_lattice}). In the end, we sum over $\alpha_T(i)$ to obtain our desired result. This method of bootstrapping and reusing old results dramatically reduces the number of required operations down to $N^2T$ (from the previous $N^T$) operations \cite{rabiner1989tutorial}. It should be noted that computing $\alpha_t(i)$ for every $t$ and $i$ for a given observation sequence $\mathcal{O}$ yields the so-called posterior distribution for the hidden states given the observation sequence. This will be important later on when we will discuss the prediction capabilities.

\subsubsection{Solution to Problem 2}

One possible solution to the question ``\textit{What's the most likely state-sequence for observation $\mathcal{O}$?}'' is to find the most probable state $S_i$ for each time step $t$. To tackle this problem we will need further definitions, first of all, let us define the so-called ``backward-variable'', which in its definition is quite similar to the forward variable.

\begin{definition}
The \textbf{backward variable} $\beta_t(i) = P[o_{t+1}...o_T | q_t = S_i, \lambda]$ is defined as the probability of observing the partial observation sequence $o_{t+1}...o_T$ given State $S_i$ at time step $t$ as well as a fully parameterized model $\lambda$.
\end{definition}

% Figure environment removed{}

To calculate the backward variable, we use the same idea of dynamic programming, reusing former results (see Figure \ref{fig:lattice_backward}). Although this time, we travel ``backwards'' through the observation sequence, thus starting at the last observation $o_T$.

\begin{enumerate}
     \item Initialization: $         \beta_T(i) = 1 \hspace{1cm} 1 \leq i \leq N$
     \item Induction:
        \begin{align*}
            \beta_t(i) = \sum_{j = 1}^N \beta_{t+1}(j)a_{ij}b_j(o_{t+1})
                            & \hspace{1cm} 1 \leq i \leq N\\
                            & \hspace{1cm} 1 \leq t < T
         \end{align*}
 \end{enumerate}{}

Having both, the forward and the backward variable at our disposal, we can continue defining a helper variable $\gamma_t(i)$.

\begin{definition}
The \textbf{helper variable} $\gamma_t(i) = P[q_t = S_i | \mathcal{O}, \lambda]$ denotes the probability of being in the hidden state $S_i$ at time step $t$ given the full observation sequence $\mathcal{O}$ as well as a fully parameterized model $\lambda$.
\end{definition}

We can express the variable $\gamma_t(i)$ in terms of the forward and backward variables (see Figure \ref{fig:lattice_forward_backward}): $    \gamma_t(i) = \frac{\alpha_t(i)\beta_t(i)}{P[\mathcal{O}|\lambda]} =     \frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N \alpha_t(i)\beta_t(i)}
$.
In this equation $P[\mathcal{O}|\lambda]$ is a normalization factor. Thus, $\sum_{i=1}^N \gamma_t(i) = 1$. To continue with our interpretation of optimality for a state sequence, we can solve for the individually most likely states for each time step:
    $q_t = \argmax_{1 \leq i \leq N}(\gamma_t(i)),\;  1 \leq t \leq T$.
Unfortunately, there is a flaw in this solution. Although we have found the individually most likely states, we have no guarantee for soundness of the found sequence of states. It might just be that our sequence contains an illegal state transition. This error is resolved by the \textit{Viterbi Algorithm} \cite{viterbi1967error}:

% Figure environment removed{}

\begin{definition}
The \textbf{Viterbi Algorithm} finds the most likely state sequence $Q = \{q_1,q_2,...,q_T\}$ to have emitted a given observation sequence $\mathcal{O} = \{o_1,o_2, ...,o_t\}$, whilst respecting the state transition constraints given by the model $\lambda$.
\end{definition}

\begin{definition}
$\delta_t(i)  = \max\limits_{q_1,...,q_{t-1}} P[q_1,...,q_t = i, o_1,...,o_t | \lambda]$ is the probability for the most probable state sequence along a single path $q_1,...,q_t$ with observation sequence $o_1,...,o_t$ up until time step $t$ that ends in the hidden state $S_i$.
\end{definition}{}

Again, we can compute this variable inductively by $\delta_{t}(j) = (\max_{1 \leq i \leq N}\delta_{t-1}(i)a_{ij})\cdot b_j(o_t)$.
Since our goal is to find the optimal state sequence, we need a way to keep track of which prior state maximized $\delta_t(i)$ at each time step $t$ for each state $i$. This is done with a storage array $\psi_t(i)$. This lets us define the Viterbi Algorithm in four steps.

\begin{enumerate}
    \item Initialization:
    \begin{align*}
        & \delta_1(i) = \pi_ib_i(o_1), \hspace{1cm} 1 \leq i \leq N\\
        & \psi_1(i) = 0
    \end{align*}{}

    \item Recursion:
    \begin{align*}
        & \delta_t(j) = \max_{1 \leq i \leq N}(\delta_{t-1}(i)a_{ij})b_j(o_t) &1 \leq j \leq N\\
        &&2 \leq t \leq T\\
        & \psi_t(j) = \argmax_{1 \leq i \leq N}(\delta_{t-1}(i)a_{ij}) &1 \leq j \leq N\\
        &&2 \leq t \leq T
    \end{align*}{}

    \item Termination:
    \begin{align*}
        & P^* = \max_{1 \leq i \leq N}(\delta_T(i))\\
        & q_T^* = \argmax_{1 \leq i \leq N}(\delta_T(i))
    \end{align*}{}

    \item Backtracking:
    $q_t^* = \psi_{t+1}(q_{t+1}^*)$, \hspace{0.2cm} $t = T-1,T-2,...,1$

\end{enumerate}{}

%Backtracking is a common method in computation, where we first compute our solution, storing information about the optimal path along the way before tracing back said path. A useful analogy might be laying breadcrumbs along a path through a forest of decisions. When we have found the right solution at the end of the forest, we want to know what path brought us here, hence tracking back our path by following the trail of breadcrumbs. In this context, we use this method to trace back the optimal states for our given observation sequence.
%This concludes the solution to problem 2.

\subsubsection{Solution to Problem 3}

Problem 3, which is concerned with training an HMM in a way such that the model is more likely to explain a given observation sequence, is the most difficult one out of the three presented problems. Starting from a rough estimate of the model parameters $\mathcal{A},\mathcal{B}, \pi$, we can iteratively improve the model with the Baum-Welch Algorithm, which can be interpreted as an application of the Expectation-Maximization-Algorithm to HMMs \cite{dempster1977maximum}, see also \cite{rabiner1989tutorial} for more details.

%\subsection{Complexity Theory and Runtime-Analysis}

%In the context of Hidden Markov Models and the different algorithms used to compute various probabilities more or less efficiently, but also with the implementation section of this thesis in mind, I would like to give a short refresher on the most fundamental aspects of Complexity Theory.\\

%In this thesis, the Bachmann-Landau Notation (or sometimes simply called big-O notation) is used to give upper bounds for the time complexity or runtime and memory intensity of algorithms with respect to one or many parameters. The big-O notation is a very convenient, compact way to describe the so-called ``worst case'' for runtime or memory consumption of a program, as well as allowing for easy comparison between different programs, regardless of the language they are formulated in.\\

%We understand the time (or memory), that a program consumes before it terminates as a function of its input parameters. When we say ``Program $A$ solves task $B$ in $\mathcal{O}(N)$-time.'', we mean that given the input parameter $N$ of task $B$, the time it takes for the program to finish the computation to solve the task is upwards-bounded by some (in this case) linear function of $N$. When $N$, the input parameter increases, the time required to solve the task increases linearly. A formal definition \cite{howell2008asymptotic} is given below.\\

%\begin{definition}
%Let $f : \mathbb{N}_0 \rightarrow{\mathbb{R}_{\geq 0}}$. Then, $\mathcal{O}(f) = \{g : \mathbb{N}_0 \rightarrow{\mathbb{R}_{\geq 0}} | \exists n_0 \in \mathbb{N}_0, c \in \mathbb{N} : g(n) \leq c \cdot f(n) \forall n \geq n_0\}$ is the set of all functions $g$ that are asymptotically upwards-bounded by $f$. We say $g \in \mathcal{O}(f)$ or that the growth rate of $g$ is limited by $f$.
%\end{definition}{}


%Said plainly, we say that $g$ is in $\mathcal{O}(f)$ (usually we use $\mathcal{O}(n)$ instead) if we can find a scalar $c \in \mathbb{R}_{\geq 0}$ with which scaled, the function $c\cdot f$ is asymptotically bigger than $g$.\\

%Continuing towards runtime analysis, a brief example of the reasoning behind such analysis is supplied in the following paragraph. Given is a simple function written in the programming language Python \cite{python}. \vspace{0.5cm}

%\begin{python}
%import numpy as np

%def some_other_function(N : int, M : int) -> float
    %return (N + M) / 2

%def construct_matrix(N : int, M : int) -> np.ndarray

    %ret = np.zeros(shape=(N,M))

    %for i in range(N):
        %for j in range(M):
            %ret[i,j] = some_other_function(N,M)

    %return ret
%\end{python}

%\vspace{0.5cm}One might ask the questions ``\textit{What is the time it takes for a function call} \texttt{construct\_matrix} \textit{to finish?}'' or ``\textit{How much memory does the function call} \texttt{construct\_matrix} \textit{need?}''. These kinds of questions can be answered using the big-O notation. In this particular case, we can easily see, that the function fills in a 2-dimensional array with the result of another function, namely \texttt{some\_other\_function}. Not only do we have to take into account the nested structure, but also the time and memory- complexity of the nested function call.\\

%Let us start with \texttt{some\_other\_function}. We can see, that the function does some basic arithmetic operations, returning the computed value instantly. The time and memory complexity of this simple function is constant. In big-O notation, this is commonly denoted as $\mathcal{O}(1)$.\\

%Having solved for time and memory complexity of the inner loops function call, we can continue analyzing the time and memory complexity of the original function of interest. As already stated, we are filling a 2-d array with values, each taking constant time to compute. Thus, our time and memory complexity are solely dependent on the parameters which define the shape of the said 2-d array. These parameters happen to be $N$ and $M$ our input parameters. Thus, we conclude that our program has the time and memory complexity $\mathcal{O}(N)\cdot\mathcal{O}(M)\cdot\mathcal{O}(1) = \mathcal{O}(N\cdot M)$. This analysis is important if we want to reason about what happens when we scale up the input parameters of our function.

\subsection{Machine Learning Metrics}

Metrics are an important tool in ML to quantify the success of a system for a given dataset. They are a measure of quality for the learned model. Additionally, metrics allow the comparison of different models with different architectures. The metric used is dependent on the type of prediction that is to be made and since the following classification problem presented is of a multi-class nature. We will motivate and explain one suitable metric for these classification problems -- the multi-class $F_1$-Score.

%Suppose we have a binary classification problem, where our task is to map an unknown data instance to one of two classes. Thus there are four thinkable outcomes for our prediction.
%\begin{enumerate}
    %\item \textbf{True Positive (TP)}: We classify an instance of class 1 as class 1
    %\item \textbf{True Negative (TN)}: We classify an instance of class 2 as class 2
    %\item \textbf{False Positive (FP)}: We classify an instance of class 2 as class 1
    %\item \textbf{False Negative (FN)}: We classify an instance of class 1 as class 2
%\end{enumerate}

%Imagine now increment a counter variable for each possible outcome of prediction, e.g. if we predict an instance of class 1 to be of class 1 correctly, we increment the variable $v_{11}$, if we instead incorrectly predict class 2, the variable $v_{12}$ is incremented. This process is repeated for many unknown data instances. This kind of measurement can be represented in a so-called ``confusion matrix'' $C$, where the index $c_{ij}$ corresponds to the variable $v_{ij}$.\\

\begin{definition}
We call $    F_{\beta} = (1 + \beta^2) \cdot \frac{precision \cdot recall}{(\beta^2 \cdot precision) + recall}$
the $F_{\beta}$-Score. For $\beta = 1$ we obtain the $F_1$-Score.
\end{definition}

The $F_1$-Score is a common metric used to measure the quality of binary classifiers. It represents the harmonic mean between precision and recall, two values we can compute with the help of $C$, our confusion matrix. $precision = \frac{true\hspace{0.2cm} positives}{true\hspace{0.2cm} positives + false\hspace{0.2cm} positives}$, and $recall = \frac{true\hspace{0.2cm} positives}{true\hspace{0.2cm} positives + false\hspace{0.2cm} negatives}$.
We can extend the $F_1$-Score to the multi-class domain, by computing a $K \times K$ confusion matrix, where $K$ is the number of classes our model can predict. %For each class $K_i$ we can compute the counts for $TP, TN, FP, FN$ as follows:
%
%\begin{enumerate}
%    \item \textbf{TP}: $C_{ii}$
%    \item \textbf{FP}: $\sum_{j \neq i} C_{ji}$
%    \item \textbf{FN}: $\sum_{j \neq i} C_{ij}$
%    \item \textbf{TN}: $\sum_{j \neq i}\sum_{k \neq i}C_{kj}$
%\end{enumerate}
%
Thus, we can compute the $F_1$-Scores for each class. The final $F_1$-Score is either an average or a weighted sum of the respective $F_1$-Scores \cite{grandini2020metrics}.\\

%This yields a way for us to evaluate the performance of our model on a given dataset. Though, the problem of uncertainty remains. Since our dataset contains multiple samples, who decides which samples are used for training and which are used for the model evaluation (also called validation) process? We may begin by randomizing the dataset, then selecting the samples we would like to use for validation. Although this brings us one step further, it may still be that, by random, these chosen samples represent an unbalanced subset of the original dataset. To counteract this, we could repeat the process of shuffling data, selecting validation samples and evaluating the model on said validation samples many times. This is, what is generally referred to as ``\textit{k}-fold cross validation'' \cite{grandini2020metrics}. In \textit{k}-fold cross validation we split the given dataset k times into two separate datasets (usually in a 90-training to 10-validation ratio), one for training and the other for validation. The final overall resulting $F_1$-Score is then computed as the mean overall $F_1$-Scores evaluated for the individual train-validate dataset pairs. Finally, we are presented with a robust metric for evaluating our model for a given dataset. This concludes the section on Machine Learning Metrics.

\section{Method}
\label{section:Method}

In this  section, we will introduce the notation that will be used, and give an in-depth model overview.

\subsection{Notation}

\begin{definition}
A \textbf{marker $M$} is a unique identifier or class-name for a certain set of discrete states $S = \{S_1,...,S_N\}$. We say that $\mathcal{M}$ is the set of all markers.
\end{definition}

Markers are the abstract handle for the observable units in our environment. For example, whilst observing a medical patient, the set of markers $\mathcal{M}$ could for example include ``ability to walk'', ``blood pressure'', ``breathing frequency''. The set of concrete states of the marker ``blood pressure'' could be $S = \{ low, medium, high\}$. $\mathcal{M}$ is partitioned into a set of layers $\mathcal{L}$.

\begin{definition}
A \textbf{(prediction-) layer} $L$ is an element of $\mathcal{L}$, partition of $\mathcal{M}$. A mapping $\mathfrak{L}_{M\rightarrow{L}} : \mathcal{M} \rightarrow{\mathcal{L}}$ maps a given marker $M$ to its corresponding layer $L$.
\end{definition}

Using this definition, we can partition the set of markers into layers containing related markers. For example, we could group the markers ``ability to walk'' and ``number of push-ups'' into a layer ``mobility''. Next up, we should define the importance of these layers and their markers for our expected prediction. This is done by defining the following weight functions.

\begin{definition}
Let a \textbf{layer-weight function} $\omega_{\mathcal{L}} : \mathcal{L} \rightarrow{\mathbb{R}_{\geq 0}}$ be a mapping from a layer $L$ to a positive weight. The function $\omega_{\mathcal{L}}$ must satisfy $\sum_{L \in \mathcal{L}} \omega_{\mathcal{L}}(L) = 1$.
\end{definition}

\begin{definition}
Let a \textbf{marker-weight function} $\omega_L : L \rightarrow{\mathbb{R}_{\geq 0}}$ be a mapping from a marker $M$ of layer $L$ to a positive weight. The function $\omega_M$ must satisfy $\sum_{M \in L} \omega_L(M) = 1$.
\end{definition}

\begin{definition}
A \textbf{Trail $T=o_1...o_t$} is an observation sequence of consecutive states of length $t$, which belong to a marker $M$. The weight of a trail is defined as $\omega_T(T) = \omega_L(M) \cdot \omega_{\mathcal{L}}(L_{M\rightarrow{L}}(M))$.
\end{definition}

\begin{definition}
An \textbf{Observation} $\mathcal{O} = \{T_1, ..., T_k\}$ is a set of Trails of same length $t$. The mapping $\mathfrak{M}_{T \rightarrow{M}} : \mathcal{O} \rightarrow{\mathcal{M}}$ maps a Trail $T$ to its corresponding marker $M$.
\end{definition}

\begin{definition}
A \textbf{Query} $\mathcal{Q} = (M_{\mathcal{H}}, \mathcal{L}, \mathcal{O}, \{\omega_{L_1}, ..., \omega_{L_k} \}, \omega_{\mathcal{L}})$ consists of a hidden marker $M_{\mathcal{H}}$ as well as a partition of $\mathcal{M}$, namely $\mathcal{L}$. A Query possesses an observation $\mathcal{O}$, consisting of possibly many trails $T$. The weights of the markers and layers are defined by the marker-weight functions $\omega_{L_i}$ (one for each layer) and the layer-weight function $\omega_\mathcal{L}$.
\end{definition}

Thus, a query $\mathcal{Q}$ is a well-defined description of a multivariate sequence alongside mixture components, namely the weights of the markers and layers. The mixture components are the weights, by which the individual result of each HMM is weighted. We would like to continue to define a formalism, which maps augmented versions of these queries to a prediction result. Thereby, the form of the prediction is dependent on the augmented query. Plainly said, our model can predict time series of discrete states, as well as time series of distributions over states. At first, we will keep the prediction result -- in any case, some sort of time series -- very abstract.

\begin{definition}
A \textbf{trail-evaluation} $   \phi(T, M_{\mathcal{H}}) = \omega_T(T) \cdot P(T, \lambda(M(T), M_{\mathcal{H}}))$ is a function that maps a Trail, a Query and possibly various arguments to a specifically requested weighted prediction result $P(T, \lambda(M(T), M_{\mathcal{H}}))$.
\end{definition}
Here, $\lambda(M(T), M_{\mathcal{H}})$ is a function that returns a fully parameterized HMM whose hidden states are the states of the hidden marker $M_{\mathcal{H}}$ and the observable states are the states of the trail marker $M(T)$. Subsequently, the resulting HMM is used to reason about the given trail $T$. Further details about the nature of the prediction are given in Section \ref{section:model_validation_and_query}.
\begin{definition}
An \textbf{observation-evaluation} $   \Phi(\mathcal{Q}) = \sum_{T \in \mathcal{Q}}\phi(T, M_{\mathcal{H}}),\hspace{0.5cm}M_{\mathcal{H}} \in \mathcal{Q}$ is a function that sums up the weighted prediction results to construct the final prediction.
\end{definition}

Hence, an observation-evaluation of a query is the weighted sum of the evaluations of the trails - the constituents of the observation.

\subsection{Model Overview}
\label{section:model_overview}

Observing an environment in the real world allows for the observation of the states of multiple markers $M_i$ at each time step. Certain semantically related markers are grouped into layers. We would like to reason about a hidden state in this environment based upon our observations by constructing a query $\mathcal{Q}$. The idea is to construct an HMM for every single marker and try to infer knowledge about the hidden states from given observations, according to the weight of the marker $\omega_L(M)$ and the weight of its respective layer $\omega_{\mathcal{L}}(L(M))$. The resulting model can briefly be described as a mixture of Hidden Markov Models -- one HMM for each marker. It is important to understand that our model is only able to offer prediction capabilities that a simple one-observation HMM could offer as well.

%% Figure environment removed{}

In this work, we assume the hidden marker to be one of the visible observation markers, allowing for the ability to generically switch the hidden marker and prediction-layer to allow for maximum flexibility. Hence, we will be able to extract the parameters of the model, namely $\mathcal{A}, \mathcal{B}$, and $\pi$ from the observation sequences directly, instead of having to train the model based on said sequences. This is in stark contrast to the usual usage of HMMs, where these parameters are not given and have to be approximated (learned) from observations.

\subsection{Pipeline Description}
\label{section:pipeline_description}

The prediction pipeline was written in Python, making use of the \texttt{hmmlearn} library\footnote{The pipeline and documentation is available at \url{https://github.com/rfechner/generic-hmm}.}. The pipeline comprises a pre-processing step, a feature extraction step, and a prediction step (see Figure \ref{fig:pipeline}). To obtain a trained model, the user must input their training data in the form of a csv-file as well as an ini-config file, describing the layer structure and provide sufficient information about the weights of the model.

% Figure environment removed{}

\subsubsection{User Input}

The data consisting of the different observations provided by the csv-file, as well as the configuration of the model provided by the ini-file, must be supplied by the user.
The abstract syntax outlines the correct way of specifying an ini-file required to construct a model, whilst making no assumption about the form of the data, thus it uses the Backus Naur Form (BNF, see \cite{knuth1964backus}). Each marker in the data must be specified as a section inside the file. Additionally, information about the datatype, related layer, and layer-specific weight of the marker must be supplied as a key-value pair under the corresponding markers section. Optional information, like the relationship to other markers, can be added.

%An important aspect of the data is the grouping of observations and the measurement interval. The user can specify the group key or primary key of the data, by which each observation instance is identified, as well as a maximum time delta in between two consecutive measurements under the meta-information section as key-value pairs. Omitting both key-value pairs will result in an interpretation of the data as one large observation sequence, where the consistency of the length of the time intervals in between observations is unimportant. Of course, this is not advised, as the time interval between observations does matter a lot for most cases. Inconsistencies in this regard are sure to distort results, or at least lessen the value of any made prediction by the model.\\

%To give a short example, a .csv file and its corresponding .ini file have been provided in the appendix section of this thesis (see Appendix \ref{appendix:examplecsv}). In the example, we have two observation sequences, one observed by henry, and the other one observed by scarlet. Both have marked their observations for different markers in the corresponding columns and added a date of observation. In the corresponding .ini file (see Appendix \ref{appendix:examplecsv}) we have specified by which column to group the observations under the \texttt{markerconfig\_metainfo} section. Additionally, we have connected the markers \textbf{Snow} and \textbf{Temp} to the \textbf{weather}-layer and the markers \textbf{Chocolate Type} and \textbf{Xmas Lights} to the \textbf{goodies}-layer. For each marker, we have specified a datatype, notably there exists a linspace datatype which given the fitting parameters specified in the abstract syntax is able to discretize continuous or already discrete values into categories. This feature is especially important since this kind of discretization allows us to generalize and enable the HMM to work with continuous values it has never seen before. The abstract syntax also allows for discretization of timestamps, which is just another example of a continuous datatype.\\

It should be noted that, although the definition of a marker calls for the existence of a layer-specific weight, the program is robust against missing or faulty weights and will re-balance the given weights to satisfy stochastic constraints.

\subsubsection{Pre-processing}

Pre-processing is a modular stage inside the pipeline, which itself is a small pipeline (see Figure \ref{fig:prepPipeline}). The transformation of the data supplied includes the analysis of the ini-file, deletion of any unnecessary data, the grouping of the data according to the metainformation extracted from the ini-file, enforcing measurement interval consistency if necessary, and finally encoding the data into a less memory intensive format.

% Figure environment removed{}

 %The label encoding transformation is a standard procedure ensuring a stable workflow as well as providing a point of standardized contact with the following components (or interface for short), at which the single previous or latter components of the pipeline might be easily switched out or modified. This practice ensures modularity, besides reducing the amount of memory used to store the observation sequences. For convenience, the whole pre-processing is fully automated and can be called in a few lines of code:

%\begin{python}
%from pre-processing import Preprocessor

%path_to_config = "./data.ini"
%path_to_data = "./data.csv"

%prep = Preprocessor(debug=False)
%prep.process(path_to_config=path_to_config,
             %path_to_data=path_to_data,
             %csv_delimiter=',')
%\end{python}

\subsubsection{Feature Extraction}

The feature extraction builds upon the previous step in the pipeline, the pre-processing (see Figure \ref{fig:FEpipeline}). Just as the prior component of the pipeline, the feature extraction component is fully modularized, implementing the necessary interface used to provide the required functionality to the next part in the pipeline. Inside the feature extraction stage, the \emph{state transition}-, \emph{signal emission}- and \emph{initial state}-probabilities are extracted from the encoded data supplied by the pre-processing stage. This is an important step since we can use the extracted probabilities later on to construct HMMs with a strong initial guess for $\mathcal{A}, \mathcal{B}$ and $\pi$.



% Figure environment removed{}

%At this point, I would like to take the opportunity to talk about the memory complexity of the feature extraction. Naturally, we would like to extract the transition probability matrices for every marker $M$ from the data. In the usual case the state transition matrix $\mathcal{A}$ should be sparse, meaning the diversity in transitions between states is very limited. In other words, we do not expect every state to have a transition probability above 0 to many other states, especially with a high number of states. Additionally, we have to extract an emission matrix $\mathcal{B}$ for every state for every other marker. Let us make a rough estimation of the memory complexity of such an extraction. Suppose we have $N$ markers, with $S$ states each. The memory complexity for the state transition matrices alone is $\mathcal{O}(N \cdot S^2)$ since we would have to reserve a $S \times S$ transition matrix for each marker. To make matters worse, let us take a look at the emission matrices. Here, we would have to reserve $\mathcal{O}(N \cdot (N-1) \cdot S^2)$ memory since for every state of every marker we would have to account for every other emission signal (state) of every other marker. We can immediately see, that a static allocation of memory is infeasible for our needs.\\

%Alternatively, we could think about computing $\mathcal{A}, \mathcal{B}$ and $\pi$ at query time. This, although certainly running shivers down many computer scientists' spines, is the least memory intensive method for making a prediction. Here, the problem isn't the memory intensity, it's the time complexity of the extraction. Let us assume the query $\mathcal{Q}$ with hidden marker $M_{\mathcal{H}}$ with $S_{\mathcal{H}}$ hidden states, as well as the prediction-layers $L_i, \hspace{0.2cm} 1 \leq i \leq M$. Furthermore, assume that each layer $L_i$ has $N$ markers, each with $S$ states. To allow prediction, we must now compute the state transition matrix $\mathcal{A}$ and $\pi$ for $M_{\mathcal{H}}$ as well as the emission matrices for the $M \cdot N$ observation markers. Although looping over all observation data at query time could technically be done in $\mathcal{O}(T)$ time, where $T$ is the number of observations, this is merely the tip of the iceberg. We are left having to construct the stochastic matrices which includes counting occurrences of states and normalization as well as having to perform the standard error checks. In summary, the time complexity comes out to be (roughly) $\mathcal{O}(T \cdot M \cdot N + M \cdot N \cdot S \cdot S_{\mathcal{H}})$, which one should not compute at query time for $T \gg 1$ or large numbers of $N, M$ or $S$.\\

%The problem becomes balancing the time and memory complexity in order to avoid both pitfalls. The solution chosen in this thesis builds upon the assumption, that state transitions are sparse, as well as the general paradigm to push most computational work into the pre-processing section of the program, saving much computational cost at query-time. To count state occurrences, dictionaries (or HashMaps) are used, in order to minimize the space needed to store information. The worst case memory complexity remains, but it should be noted that relying on this kind of dynamic allocation of memory is far more memory efficient and reasonable than statically allocating tons of memory at the beginning of pre-processing. Normalization and the usual checks for the satisfaction of stochastic constraints are done in-place inside the dictionaries. This yields all necessary state transition-, emission- and initial state-probabilities. The actual matrices are constructed at query time. This poses no direct problem, as the bulk of the work is already done. The computational effort required to read from a dictionary and write into $N \cdot M$ matrices is negligible. This concludes the feature extraction section of the pipeline. Again, for convenience, the feature extraction can be written in a few lines of code. \vspace{1cm}

%\begin{python}
%from pvault import ProbabilityVault

%# build ontop of the already existing Preprocessor object
%pv = ProbabilityVault(prep, debug=False)
%pv.extract_probabilities()
%\end{python}{}

\subsubsection{Model Validation and Query}
\label{section:model_validation_and_query}

Finally, in the last step of the pipeline, the HMM-based model is constructed and queried. Building on top of the previously constructed feature extraction, the actual construction of the different HMMs is very convenient. It includes the interpolation of the results given by the individual HMMs according to the weights specified inside the configuration. To give a measure of success, the model is able to compute the multi-class $F_1$-Score for a given validation dataset. %Model construction and validation can be executed in a few lines of code, as we will see below. %\vspace{0.5cm}

%\begin{python}
%import pandas as pd
%from model import RHMM

%path_to_validation_data = "./validation.csv"

%# load validation dataset, split into groups
%validation_df = pd.read_csv(path_to_validation_data, delimiter=',')
%validation_samples = prep.group_df(validation_df)


%# build model on top of already contructed ProbabilityVault object
%rhmm = RHMM(pv, debug=False)
%f1_score = rhmm.validate(   groups=validation_samples,
                            %layers=['layer1', 'layer2'],
                            %hidden_marker='marker1')

%\end{python}{}

As already stated, it is important that the HMM-based model can only offer predictions that a simple single observation HMM could offer as well. These predictions include the following:

\begin{enumerate}
\label{section:prediction_capabilities}
    \item \textbf{Posteriors for each hidden state for observation $\mathcal{O}$}\\
    Given a Query $\mathcal{Q}$, compute the posterior distribution for each hidden state of $M_{\mathcal{H}}$ for every time step $t$ given the trails $T_i$. The result will be a weighted sum (according to the weights defined in $\mathcal{Q}$) of the individually computed posteriors.

    \item \textbf{Distribution over hidden states following $\mathcal{O}$}\\
    Given a Query $\mathcal{Q}$, predict the distribution over the hidden states of $M_{\mathcal{H}}$ for possibly many time steps $\hat{t}$ following the observation. This yields an approximation to a stationary distribution of the state transition matrix for $M_{\mathcal{H}}$. The kind of stationary distribution is dependent on the initial state distribution given by the observation sequence $\mathcal{O}$.

    \item \textbf{Optimal state sequence}\\
    Given a Query $\mathcal{Q}$, compute the optimal state sequence of $M_{\mathcal{H}}$ ``best explaining'' the trails $T_i$ using the Viterbi Algorithm.
\end{enumerate}



\subsubsection{Controller}

To wrap all of these components up, and use the whole pipeline, as well as enable plotting of the results, a wrapper object called \texttt{Controller} provides a user-friendly interface.

%\vspace{0.5cm}

%\begin{python}
%from controller import Controller

%# construct model
%c = Controller()
%c.construct(path_to_data="data.csv",
            %path_to_config="data.ini",
            %csv_delimiter=",")

%# validate model
%c.validate(path_to_validation_data="validation.csv",
           %csv_delimiter=",",
           %hidden_marker="marker1",
           %layers=["layer1", "layer42"])

%# query model
%c.plot_posterior_distribution(path_to_observation="single.csv",
                            %csv_delimiter=",",
                            %hidden_marker="marker1",
                            %layers=["layer1"])
%\end{python}

%\vspace{0.5cm}In most cases, we would like to test the performance of our model on a specific dataset more rigorously. This is archived with the so-called \textbf{\textit{k}-fold cross validation}, a way of reducing uncertainty over the performance of a model on a dataset. The model is continuously trained and tested on randomized parts of the whole dataset, resulting in multiple measurements of model performance. The Controller provides a simple method interface for the \textit{k}-fold cross validation of a given dataset. \newpage

%\begin{python}
%from controller import Controller

%path_to_data = "data/train.csv"
%path_to_config = "data/train.ini"

%c = Controller()

%f1_scores = c.kfold_cross_validation(k = 10,
                          %path_to_data=path_to_data,
                          %path_to_config=path_to_config,
                          %csv_delimiter=',',
                          %layers=["layer1", "layer2", "layer3"],
                          %hidden_marker='hidden_marker')
%\end{python}{}

%\vspace{0.5cm}For the interested reader, a fully functional version of the proposed pipeline will be provided in the form of a tutorial jupyter-notebook as part of the open source repository \cite{generichmm} to provide an easy stepping stone for inexperienced users and enable reproduction of the following results.

%\subsection{Tools}

%In the following paragraph, I'll briefly examine the tools used for this thesis, highlighting the advantages of each tool, the thought process behind choosing the respective tool and improvements that could be made in hindsight.\\

%A convenient way of keeping track of implementation issues and tasks was the software repository management system GitHub \cite{github}. GitHub allows for great planning, project management and version control, far beyond the needs of this thesis. In my case, GitHub was mainly used to keep track of issues and have a remote copy of the working repository. As the repository was initialized, the next step was to prototype the individual parts of the pipeline. For this, jupyter-notebooks \cite{jupyter}, a combination of an interactive python shell and a code editor, was used as it allows for quick feedback on whether an idea is working or not. Once done prototyping, an actual python IDE (Integrated Development Environment) in the form of PyCharm \cite{pycharm} was used to ease development and find bugs. At this stage of the project, all code was moved from loosely hanging notebooks into an object oriented structure. In hindsight, the process of transferring notebook-code to python-scripts could have been done earlier. Here, more time should have been invested in actually planning what sort of application was to be developed and the requirements for the fluid development of such an application.

\subsection{Data}

\subsubsection{Data Generation}

The random dataset mimics the actual biomedical dataset in which we expect to see many markers with degenerative states -- markers, whose states continuously progress over time, going from an initial good state into a worse state. Four different degenerative markers were selected, namely

\begin{enumerate}
    \item $M_{finemotor}$, a marker whose state indicates the subject's ability to solve tasks using their hands.

    \item $M_{mobility}$, a marker whose state indicates the subject's state of mobility, e.g. still being able to walk freely without the need of walking aids or the need to use a wheelchair. 

    \item $M_{neuropsych}$, a marker whose state indicates the subject's ability to solve mental tasks.

    \item $M_{diagnosis}$, a marker whose state indicates the diagnosis given by an expert for a subject at a certain time step.
\end{enumerate}

Every marker has the same set of degenerative states, namely $S = \{$good, med-good, med, med-bad, bad, severe $\}$ indicating the current state under the given marker. To construct the data, a state transition matrix $\mathcal{A}$ as well as an initial state distribution vector $\pi$ were constructed for the single marker $M_{diagnosis}$. Additionally, emission signal matrices ($\mathcal{B}_{motoric}$, $\mathcal{B}_{mobility}$, $\mathcal{B}_{neuro}$) were constructed for the other markers $M_{motoric}$, $M_{mobility}$, $M_{neuro}$. Using these parameters, three different HMMs were constructed. Using the initial state probability distribution, for each observation sequence, an initial state for the marker $M_{diagnosis}$ was chosen. Thereafter, the following states for $M_{diagnosis}$ were sampled from the state transition probability matrix $\mathcal{A}$. Likewise, for each time step of each observation, the emission signal for each observation marker $M_i$ was sampled from the distribution located in the respective emission signal matrix $\mathcal{B}_i$. A dataset of $N = 300$ observation sequences of variable sequence-length and variable time intervals in between measurements was synthesized. To finalize the data, a configuration ini-file was constructed. For simplicity, each marker was assigned to a distinct layer, resulting in four layers -- one for each marker.



\subsubsection{Background and Description of the biomedical dataset}

Here, we will discuss a dataset obtained by a longitudinal observational study of subjects suffering from spinocerebellar ataxia type 3 (SCA3), the most common autosomal dominantly inherited neurodegenerative ataxia disorder (ESMI, European spinocerebellar ataxia type 3/Machado-Joseph disease initiative \cite{Faber2021, ESMINfLSerum,ESMINfLPlasma,ATXN3}). Symptoms include progressive loss of balance, coordination deficits and slurred speech. SCA3 patients experience significant restrictions of mobility and communicative skills. Preventive interventions that aim to silence the disease gene offer a promising treatment option. The first clinical gene silencing trial\footnote{ClinicalTrials.gov, Identifier: NCT05160558} has recently started. Consequently, there is an urgent need to predict the deterioration to a more severe disease stage to prioritize and treat patients suffering from a greater risk with less uncertainty.

The supplied data contains results from various scales that were assessed in all participants on an almost annual basis. Usually, those scales reflect increased impairment with higher scoring, while 0 refers to a normal condition and the absence of signs or symptoms like in the healthy population. In our analyses we included the following 4 assessments that measure special ends of abilities or measured observations of subjects, where a rating of 0 indicates a healthy condition: 1) disease staging (ranging from 0=normal over 1=ataxic, but able to walk freely, 2=need to use walking aids, 3=requirement to use wheelchair) \cite{diseasestages}, 2) Scale for the assessment and rating of ataxia (SARA), measuring the ataxia severity rated in 8 different items (namely gait, stance, sitting, speech, finger chase, nose-finger test, fast alternating hand movements and heel-shin slide) resulting in a sum score (raging from 0 to 40) \cite{SARA}; 3) Inventory of non-ataxia signs (INAS), assessing neurological symptoms other than ataxia \cite{INAS} and 4) a scale assessing the activities of daily life (ADL) \cite{ADL}. Notably, the  ``ADL'' (Activities of Daily Life), ``INAS'' (Intentional Non-Adherence Scale) and ``SARA'' (Scale for the Assessment and Rating of Ataxia) scales were considered in the first part of the experiment. These specific scales were chosen after consulting with a domain expert. With the additional information about the -- by domain experts already inferred -- disease state for each multivariate observation in our data, we return to the familiar setup presented in the prior section, where we have multiple trails paired with a given diagnosis or inferred latent state. $M_{diagnosis}$ in this context represents the disease stage (normal, ataxic, walking aids, wheelchair). A ``diagnosis'' in its native meaning usually describing a particular disease does not make sense in the context of a hereditary disease that is ``diagnosed'' simply by a genetic test. Thus, instead of the 3 observation markers like in the prior example, we here get about 109 different markers, which we can observe at every time step. The average length of the given time-series was calculated to be about 2.3 time steps.



\section{Results}
\label{section:Evaluation}

The model was evaluated on two different datasets:  a random dataset and a real-world biomedical dataset containing observational data of a longitudinal natural history study in spinocerebellar ataxia type 3 (SCA3). Due to data-protection reasons, we will present an in-depth discussion of results and evaluation for the first dataset.

\subsection{Evaluation 1: Random Data}

The dataset was evaluated with a 10-fold cross validation. The layers of query $\mathcal{Q}$ were set to $\mathcal{L} = \{$ $L_1$ = mobility, $L_2$ = motoric, $L_3$ = neuro $\}$. In this special case, every marker has an equal influence on the model prediction, since every layer consists of only one marker and the layer weights are equally distributed across all layers. Alternatively, the layer weights $w(L_i)$ could be adjusted, or multiple markers could be grouped in one layer, allowing for further differentiation by adjusting the marker weights $w(M_i)$ inside one layer. The hidden marker $M_{\mathcal{H}}$ was set to the marker $M_{diagnosis}$.\\

%In plain English, the model query could be summarized as trying to predict a state sequence of diagnoses given the observation of the patient's mobility-, motoric- and neuro-markers.\\

As already stated above, the model was evaluated with a 10-fold cross validation, which yielded an average \textbf{$\boldsymbol{F_1}$-Score of 0.813 with a standard deviation of 0.017}. To showcase the prediction capabilities of the model further, a never seen before observation was generated, and the model was queried for all three possible prediction types (see Section \ref{section:model_validation_and_query}). These include the prediction of the distribution over the posteriors and an extrapolation for the posterior distributions given an observation sequence (see Figure \ref{fig:first_dataset}).




% Figure environment removed{}





\subsection{Evaluation 2: Biomedical Data}

\subsubsection{First Experiment}

The 109 markers were partitioned into three layers corresponding to the scale each marker belongs to; $L_{ADL}, L_{INAS}$ and $L_{SARA}$. The weight function $\omega_{L}$ assigns each prediction-layer the weight $\frac{1}{3}$. Internally, the weight function responsible for assigning a weight to every marker inside a given layer assigns equal weight to every marker. The hidden marker $M_{\mathcal{H}}$ was chosen to be the diagnosis marker. This proved to be a naive approach, as the bad performance of the model with an $F_1$-Score of less than 0.5 in a 10-fold cross-validation of the whole dataset reassured.



\subsubsection{Second Experiment}
\label{section:summary_of_results}

Since first experiments yielded an unacceptable performance, the decision was made to reduce the number of Trails, by only considering the cumulative score for each of the three scales (ADL, INAS and SARA), drastically reducing the number of Trails down to only three. Within this reduced setting, the model performed relatively well, with a mean $F_1$-Score of 0.75 and a standard deviation of 0.04 as the result of a 10-fold cross validation on the whole dataset. Additionally, further constellations of prediction-layers and hidden markers were tested (see Table \ref{tab:results}). The predictions with $M_{\mathcal{H}}=$``diagnosis'' generally produced acceptable results, whereas the other predictions yielded rather unsatisfying prediction results.



\begin{table}[]
    \centering
    \begin{tabular}{|l||*{4}{c|}}
        \hline
        \multicolumn{5}{|c|}{$F_1$-Scores for 10-fold cross validation ($\mu \pm \sigma$)} \\
        \hline
        \backslashbox[40mm]{layers}{$M_{\mathcal{H}}$} &diagnosis&ADL score&INAS score&SARA score\\
        \hline
        $L_{ADL}, L_{INAS}, L_{SARA}$& 0.75 $\pm$ 0.04 & 0.22 $\pm$ 0.06 & 0.13 $\pm$ 0.04 & 0.19 $\pm$ 0.06\\
        $L_{SARA}$&   0.75 $\pm$ 0.03  & 0.23 $\pm$ 0.03   & 0.16 $\pm$ 0.04 & -\\
        $L_{INAS}$& 0.6 $\pm$ 0.06  & 0.11 $\pm$ 0.04   & - & 0.13 $\pm$ 0.04\\
        $L_{ADL}$& 0.72 $\pm$ 0.08  & -   & 0.19 $\pm$ 0.05 & 0.24 $\pm$ 0.04\\
        \hline
    \end{tabular}
    \caption{Table cells display the mean and standard deviation of the $F_1$-Scores received from a 10-fold cross validation. Different constellations of prediction-layers and hidden marker were used. Overall on the level of single layers LSARA allows the highest prediction of disease staging $M_{diagnosis}$ (normal, ataxic, walking aid, wheelchair), followed by LADL, representing the activities of daily living, while neurological symptoms other than ataxia (LINAS) do not allow any meaningful prediction. }
    \label{tab:results}
\end{table}{}

\section{Discussion}

Generally, it was expected that the model would perform relatively well given the prediction right prediction-layers and enough training data. A substantial difficulty with the real-world data we had access to, was that a majority (approx. $\frac{2}{3}$) of the given training sequences was of length 1 or 2, thus the dataset lacked sufficient samples for longer time-series. Naturally, this also effected the validation dataset. This leads to an important question: Which clinical trials or patient studies produce data suitable for an HMM-based prediction? It was shown in Section \ref{section:summary_of_results} that we can reach reasonable prediction scores using an HMM approach -- at least for the right constellations of prediction-layers and hidden marker.

The reasonable results produced, given the prediction-layers $L_{ADL}$, $L_{INAS}$, $L_{SARA}$ in constellation with the hidden marker $M_{\mathcal{H}}$ set to the marker ``diagnosis'' can be explained by the strong correlation between the individual markers inside the prediction-layers (which are simply the scores for the corresponding scale) and the diagnosis given by a medical professional. Specifically, the prediction-layer $L_{SARA}$ seems to be the best suitable for producing predictions for the hidden marker ``diagnosis''. This independently received finding correlates with the findings of domain experts, i.e. the biomedical experts.

We also need to discuss the limitations of our approach. %The question left to ask is why we couldn't do better. There are multiple explanations for this, which I would like to discuss.
First, as discussed above, the time-series as base for prediction, as well as the distribution for the initial hidden state have to be considered. As already described, about $\frac{2}{3}$ of the training data contains time-series only of length 1 or 2. This greatly influences the prediction capabilities for longer time-series. The dataset does not have enough training samples for longer time-series, thus the performance for predicting longer sequences could be better.
Additionally, since we extract the probabilities from the training data, the model has a strong bias for the probability of the initial state. Without knowing anything about the validation sample, a certain initial state is far more probable than another. This fact, paired with the appearance of short (sometimes single time step) time-series, is most definitely a source of errors in our prediction.\\

Furthermore, an analysis of the individual time-series and the corresponding scales of the real-world data set in patients  has shown that the underlying Markov Chains for the markers are not strictly left-right\footnote{Left-Right HMMs model strictly degrading states, meaning once a state transition from $A$ to $B$ has occurred, it's impossible to reverse this transition. $A$ will never be reached again.}. To put it in other words, the difference in, e.g., the ADL score, a measure of the subject's ability to manage activities of daily living, between the last and first measurement is not strictly positive. In some cases, we can observe that a patient reduces their score over time, instead of displaying a degenerating performance. There are mainly potential reason for such an unexpected improvement over time. One explanation can be an initially present comorbidity causing an impairment beyond the ataxia disorder, e.g. a broken arm. Another, probably more common, explanation might be a rater depended on variance. 
In the case of predicting the hidden markers ``ADL Score'', ``INAS Score'' or ``SARA Score'' the granularity of the discretization of the continuous scales deeply impacts the prediction score. For the given data, the granularity (i.e. the dtype linspace defined in the configuration) was kept the same for all measurements. In practice, the user would be able to change the number of categories, the continuous values that each scale can fall into, to reduce the number of misclassifications. Simple trail-and-error experiment runs showed that the performance can be improved to an $F_1$-score of about $0.5$ by reducing the number of categories from about 20 down to 5. Surprisingly, doing this has a negative effect on the prediction results for the marker ``diagnosis'', as it seems an over-simplification does weaken the precision and recall of our prediction.



\subsection{Strengths, Weaknesses and Improvements}
%First, let us discuss the abilities of the model.
Since the model can be seen as a mixture of HMMs, its capabilities to capture deep complexity and intricate relationships within data is limited. As the model can use multiple markers for prediction, the general stability of a prediction is traded for a lack of attention to details in the data. Since we weigh the influence the markers have on the prediction separately, small but maybe very critical changes in a single marker might be overpowered by the sheer number of markers our model has to respect. The only way to combat this problem right now would be to assign a higher weight to critical markers, in order to let small changes in states for an important marker have a higher impact on the final prediction. %This however requires domain expertise and contradicts the spirit of Machine Learning. Vllt. eher: 
However, a data-driven solution that includes an automated identification of helpful weightings would be desirable. This could be realized by employing an optimization technique such as gradient based optimization or a probabilistic approach such as a genetic algorithm. %The optimization problem then becomes arbitrarily difficult, as we could think about not only optimizing the weights for the layers and markers but optimizing weights for each timestep of the given time-series independently. It might just be that the importance of the state of a marker changes over time, which we would then be able to observe with the change of the weight of the marker over time. This of course would scale up the effort required for an optimization drastically, depending on the length of our time-series.

%A crucial topic we should not miss to talk about, is the way in which this thesis incorporates the predictive capabilities of HMMs in the context of the data provided.
Generally, Hidden Markov Models do model, as their name suggests, hidden states, including the initial state probabilities, transitions and emission signal probabilities. The usual case is that these three parameters are learned or approximated, as already stated in Section \ref{section:model_overview}. However, in this work, we have assumed an observable state to be the hidden state. This was necessary in order to maintain the flexibility and generality of the model, although of course this is not a typical use-case of HMMs. Subsequently, we were able to omit the step of training an HMM on data, since the training data already provided us with precise measurements. Thus, there was no need to approximate which parameters might have led to the displayed data -- the parameters could be extracted right away. In the future, we will think about using the extracted probabilities as a starting point for the optimization. As the training of HMMs is very sensitive to the choice of the initial guess for the parameters, see \cite{rabiner1989tutorial}, another optimization approach would be to 1) extract the probabilities for $\mathcal{A}, \mathcal{B}, \pi$, 2) possibly apply smoothing to the parameters and 3) then let an optimization algorithm find a local optimum for said parameters. This was presented by \cite{chau1997optimization}, who optimized their HMM with a genetic algorithm.



\subsection{Model Capabilities and Usecases}

%Another topic I want to address is the gain, which the presented prediction pipeline brings for %domain experts like medical professionals from the DZNE.
During the design of the pipeline, we paid special attention to usability. The prediction target and result can be altered by specifying the prediction-layers and hidden marker, but also by specifying the weight functions for the layers and their respective markers, as well as the partition of the markers into layers in the first place. Domain experts are free to adjust these parameters within the constraints of the proposed abstract syntax. Apart from configuring the models parameters, domain experts are presented with multiple prediction capabilities:

1. \emph{Posteriors for states of a hidden marker}: The prediction tool is able to predict and plot posteriors for the states of a hidden marker $M_{\mathcal{H}}$. For a given observation sequence, the model predicts $\alpha_t(i)$ for every state $i$ and every time step $t$ of the observation sequence. This enables the user to produce a simple visualization of how likely the model thinks a certain hidden state for the given time step of the observation. A domain expert can see at a glance in which direction the states of $M_{\mathcal{H}}$ evolve.

2. \emph{Approximation of the stationary distribution}: Additionally, the model can give a rough estimate of the ``future'' posteriors of the states of $M_{\mathcal{H}}$ beyond the given observation sequence. In other words, it can give an estimate about how the distribution over the probability for the states of $M_{\mathcal{H}}$ will evolve over future time steps. It should be added that this estimate is a visualization of the approximation of the stationary distribution of the state transition matrix $\mathcal{A}$ of the underlying Hidden Markov Model.

3. \emph{Optimal state sequence prediction}: The most valuable prediction capability might be the prediction of optimal state sequences given an observation sequence. This allows for ``double-checking'' already found observation sequences, and might be used for data augmentation in the case of missing data or that a malfunctioning sensor gives back erroneous measurements. Predicting an optimal sequence of states for a hidden marker ``diagnosis'' might be a help to a medical professional, who wants to verify their given diagnosis.

4. \emph{Extraction of model parameters}: Finally, a user can extract the model parameters themselves, as they can give us critical information about the general transition probabilities of a model. A domain expert might ask about a rough estimate of the probability for state transitions, which they could immediately obtain by extracting the state transition probability matrix $\mathcal{A}$ from the model.




\section{Conclusions}

Biomedical data often contains longitudinal data, for example biomedical information on disease progress. An important goal is to infer the unknown solely from observation.
Hidden Markov Models (HMMs) have been successfully applied to the processing of possibly noisy continuous signals. Here, we presented a novel approach based on multivariate time-series of categorically distributed data.

We provided a prediction pipeline system, which processes data paired with a configuration file, enabling to construct, validate and query a fully parameterized HMM-based model. It has been conceptualized to be highly customizable and accessible both to computer scientists and practitioners from other disciplines, for example biomedical research. 
In addition, we provided a theoretical and practical framework for multivariate time-series inference based on HMMs  that included constructing multiple HMMs to predict another observable variable. Our analysis was carried out on random data, but also on biomedical data based on Spinocerebellar ataxia type 3 disease.

The implementation of the HMM framework is publicly available and can be easily configured and adapted for further experiments. 
We could show that our proposed approach shows promising results when tested on random data, and in particular good results on real world application data. However, we also presented a detailed discussion and how the approach could be augmented to improve results. It is obvious that the selected input data must meet certain criteria, especially with respect to the quantity of available longitudinal time points, to allow reasonable predictions. But even in a relatively small data set of rare diseases, we could demonstrate the feasibility of our approach. The presented framework has to be proven on further different biomedical time-series in order to fully estimate its potential and moreover how the suggested augmentations might improve the overall prediction. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{backmatter}
\appendix
%\section*{Acknowledgements}%% if any
%We thank Jan Jürjens, University of Koblenz, for his contributions to the initial research.

\section*{Funding}%% if any
This work was supported by a postdoc fellowship of the German Academic Exchange Service (DAAD), granted to RR.

JF receives funding of the National Ataxia Foundation (NAF) and as a fellow of the Hertie Network of Excellence in Clinical Neuroscience.

 This publication is an outcome of ESMI, an EU Joint Programme - Neurodegenerative Disease Research (JPND) project (see \url{www.jpnd.eu}). The project is supported through the following funding organisations under the aegis of JPND: Germany, Federal Ministry of Education and Research (BMBF; funding codes 01ED1602A/B); Netherlands, The Netherlands Organisation for Health Research and Development; Portugal, Foundation for Science and Technology and Regional Fund for Science and Technology of the Azores; United Kingdom, Medical Research Council. This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 643417.

%\section*{Abbreviations}%% if any
%Text for this section\ldots

\section*{Availability of data and materials}%% if any
The pipeline and additional material is available at \url{https://github.com/rfechner/generic-hmm}. The biomedical data that support the findings of this study underlie data protection policies and are therefore not publicly available. However, they can be made available upon reasonable request with permission of the ESMI consortium (contact: Jennifer Faber, \url{Jennifer.faber@dzne.de}).

%\section*{Ethics approval and consent to participate}%% if any
%Not applicable.

%\section*{Competing interests}
%The authors declare that they have no competing interests.

%\section*{Consent for publication}%% if any
%Not applicable

%\section*{Authors' contributions}
%All authors wrote the text, RF and JD provided the first draft. The software was written by RF with contributions of JD and RR; the biomedical research questions and analysis were done by JF.

%\section*{Authors' information}%% if any
%Text for this section\ldots

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
%\bibliography{references}      % Bibliography file (usually '*.bib' )

\begin{thebibliography}{21}
% BibTex style file: bmc-mathphys.bst (version 2.1), 2014-07-24
\ifx \bisbn   \undefined \def \bisbn  #1{ISBN #1}\fi
\ifx \binits  \undefined \def \binits#1{#1}\fi
\ifx \bauthor  \undefined \def \bauthor#1{#1}\fi
\ifx \batitle  \undefined \def \batitle#1{#1}\fi
\ifx \bjtitle  \undefined \def \bjtitle#1{#1}\fi
\ifx \bvolume  \undefined \def \bvolume#1{\textbf{#1}}\fi
\ifx \byear  \undefined \def \byear#1{#1}\fi
\ifx \bissue  \undefined \def \bissue#1{#1}\fi
\ifx \bfpage  \undefined \def \bfpage#1{#1}\fi
\ifx \blpage  \undefined \def \blpage #1{#1}\fi
\ifx \burl  \undefined \def \burl#1{\textsf{#1}}\fi
\ifx \doiurl  \undefined \def \doiurl#1{\textsf{#1}}\fi
\ifx \betal  \undefined \def \betal{\textit{et al.}}\fi
\ifx \binstitute  \undefined \def \binstitute#1{#1}\fi
\ifx \binstitutionaled  \undefined \def \binstitutionaled#1{#1}\fi
\ifx \bctitle  \undefined \def \bctitle#1{#1}\fi
\ifx \beditor  \undefined \def \beditor#1{#1}\fi
\ifx \bpublisher  \undefined \def \bpublisher#1{#1}\fi
\ifx \bbtitle  \undefined \def \bbtitle#1{#1}\fi
\ifx \bedition  \undefined \def \bedition#1{#1}\fi
\ifx \bseriesno  \undefined \def \bseriesno#1{#1}\fi
\ifx \blocation  \undefined \def \blocation#1{#1}\fi
\ifx \bsertitle  \undefined \def \bsertitle#1{#1}\fi
\ifx \bsnm \undefined \def \bsnm#1{#1}\fi
\ifx \bsuffix \undefined \def \bsuffix#1{#1}\fi
\ifx \bparticle \undefined \def \bparticle#1{#1}\fi
\ifx \barticle \undefined \def \barticle#1{#1}\fi
\ifx \bconfdate \undefined \def \bconfdate #1{#1}\fi
\ifx \botherref \undefined \def \botherref #1{#1}\fi
\ifx \url \undefined \def \url#1{\textsf{#1}}\fi
\ifx \bchapter \undefined \def \bchapter#1{#1}\fi
\ifx \bbook \undefined \def \bbook#1{#1}\fi
\ifx \bcomment \undefined \def \bcomment#1{#1}\fi
\ifx \oauthor \undefined \def \oauthor#1{#1}\fi
\ifx \citeauthoryear \undefined \def \citeauthoryear#1{#1}\fi
\ifx \endbibitem  \undefined \def \endbibitem {}\fi
\ifx \bconflocation  \undefined \def \bconflocation#1{#1}\fi
\ifx \arxivurl  \undefined \def \arxivurl#1{\textsf{#1}}\fi
\csname PreBibitemsHook\endcsname

%%% 1
\bibitem{Faber2021}
\begin{barticle}
\bauthor{\bsnm{Faber}, \binits{J.}},
\bauthor{\bsnm{Schaprian}, \binits{T.}},
\bauthor{\bsnm{Berkan}, \binits{K.}},
\bauthor{\bsnm{Reetz}, \binits{K.}},
\bauthor{\bsnm{França~Jr}, \binits{M.C.}},
\bauthor{\bparticle{de} \bsnm{Rezende}, \binits{T.J.R.}},
\bauthor{\bsnm{Hong}, \binits{J.}},
\bauthor{\bsnm{Liao}, \binits{W.}},
\bauthor{\bparticle{van~de} \bsnm{Warrenburg}, \binits{B.}},
\bauthor{\bparticle{van} \bsnm{Gaalen}, \binits{J.}},
\bauthor{\bsnm{Durr}, \binits{A.}},
\bauthor{\bsnm{Mochel}, \binits{F.}},
\bauthor{\bsnm{Giunti}, \binits{P.}},
\bauthor{\bsnm{Garcia-Moreno}, \binits{H.}},
\bauthor{\bsnm{Schoels}, \binits{L.}},
\bauthor{\bsnm{Hengel}, \binits{H.}},
\bauthor{\bsnm{Synofzik}, \binits{M.}},
\bauthor{\bsnm{Bender}, \binits{B.}},
\bauthor{\bsnm{Oz}, \binits{G.}},
\bauthor{\bsnm{Joers}, \binits{J.}},
\bauthor{\bparticle{de} \bsnm{Vries}, \binits{J.J.}},
\bauthor{\bsnm{Kang}, \binits{J.-S.}},
\bauthor{\bsnm{Timmann-Braun}, \binits{D.}},
\bauthor{\bsnm{Jacobi}, \binits{H.}},
\bauthor{\bsnm{Infante}, \binits{J.}},
\bauthor{\bsnm{Joules}, \binits{R.}},
\bauthor{\bsnm{Romanzetti}, \binits{S.}},
\bauthor{\bsnm{Diedrichsen}, \binits{J.}},
\bauthor{\bsnm{Schmid}, \binits{M.}},
\bauthor{\bsnm{Wolz}, \binits{R.}},
\bauthor{\bsnm{Klockgether}, \binits{T.}}:
\batitle{Regional brain and spinal cord volume loss in spinocerebellar ataxia
  type 3}.
\bjtitle{Movement Disorders}
(\byear{2021}).
doi:\doiurl{10.1002/mds.28610}
\end{barticle}
\endbibitem

%%% 2
\bibitem{ESMINfLSerum}
\begin{botherref}
\oauthor{\bsnm{Wilke}, \binits{C.}},
\oauthor{\bsnm{Haas}, \binits{E.}},
\oauthor{\bsnm{Reetz}, \binits{K.}},
\oauthor{\bsnm{Faber}, \binits{J.}},
\oauthor{\bsnm{Garcia-Moreno}, \binits{H.}},
\oauthor{\bsnm{Santana}, \binits{M.M.}},
\oauthor{\bparticle{van~de} \bsnm{Warrenburg}, \binits{B.}},
\oauthor{\bsnm{Hengel}, \binits{H.}},
\oauthor{\bsnm{Lima}, \binits{M.}},
\oauthor{\bsnm{Filla}, \binits{A.}},
\oauthor{\bsnm{Durr}, \binits{A.}},
\oauthor{\bsnm{Melegh}, \binits{B.}},
\oauthor{\bsnm{Masciullo}, \binits{M.}},
\oauthor{\bsnm{Infante}, \binits{J.}},
\oauthor{\bsnm{Giunti}, \binits{P.}},
\oauthor{\bsnm{Neumann}, \binits{M.}},
\oauthor{\bparticle{de} \bsnm{Vries}, \binits{J.}},
\oauthor{\bparticle{Pereira~de} \bsnm{Almeida}, \binits{L.}},
\oauthor{\bsnm{Rakowicz}, \binits{M.}},
\oauthor{\bsnm{Jacobi}, \binits{H.}},
\oauthor{\bsnm{Schule}, \binits{R.}},
\oauthor{\bsnm{Kaeser}, \binits{S.A.}},
\oauthor{\bsnm{Kuhle}, \binits{J.}},
\oauthor{\bsnm{Klockgether}, \binits{T.}},
\oauthor{\bsnm{Schols}, \binits{L.}},
\oauthor{\bsnm{group}, \binits{S.C.A.n.s.}},
\oauthor{\bsnm{Barro}, \binits{C.}},
\oauthor{\bsnm{Hubener-Schmid}, \binits{J.}},
\oauthor{\bsnm{Synofzik}, \binits{M.}}:
Neurofilaments in spinocerebellar ataxia type 3: blood biomarkers at the
  preataxic and ataxic stage in humans and mice.
EMBO Mol Med,
11803
(2020).
doi:\doiurl{10.15252/emmm.201911803}
\end{botherref}
\endbibitem

%%% 3
\bibitem{ESMINfLPlasma}
\begin{barticle}
\bauthor{\bsnm{Garcia-Moreno}, \binits{H.}},
\bauthor{\bsnm{Prudencio}, \binits{M.}},
\bauthor{\bsnm{Thomas-Black}, \binits{G.}},
\bauthor{\bsnm{Solanky}, \binits{N.}},
\bauthor{\bsnm{Jansen-West}, \binits{K.R.}},
\bauthor{\bsnm{Hanna~Al-Shaikh}, \binits{R.}},
\bauthor{\bsnm{Heslegrave}, \binits{A.}},
\bauthor{\bsnm{Zetterberg}, \binits{H.}},
\bauthor{\bsnm{Santana}, \binits{M.M.}},
\bauthor{\bparticle{Pereira~de} \bsnm{Almeida}, \binits{L.}},
\bauthor{\bsnm{Vasconcelos-Ferreira}, \binits{A.}},
\bauthor{\bsnm{Januario}, \binits{C.}},
\bauthor{\bsnm{Infante}, \binits{J.}},
\bauthor{\bsnm{Faber}, \binits{J.}},
\bauthor{\bsnm{Klockgether}, \binits{T.}},
\bauthor{\bsnm{Reetz}, \binits{K.}},
\bauthor{\bsnm{Raposo}, \binits{M.}},
\bauthor{\bsnm{Ferreira}, \binits{A.F.}},
\bauthor{\bsnm{Lima}, \binits{M.}},
\bauthor{\bsnm{Schols}, \binits{L.}},
\bauthor{\bsnm{Synofzik}, \binits{M.}},
\bauthor{\bsnm{Hubener-Schmid}, \binits{J.}},
\bauthor{\bsnm{Puschmann}, \binits{A.}},
\bauthor{\bsnm{Gorcenco}, \binits{S.}},
\bauthor{\bsnm{Wszolek}, \binits{Z.K.}},
\bauthor{\bsnm{Petrucelli}, \binits{L.}},
\bauthor{\bsnm{Giunti}, \binits{P.}}:
\batitle{Tau and neurofilament light-chain as fluid biomarkers in
  spinocerebellar ataxia type 3}.
\bjtitle{Eur J Neurol}
\bvolume{29}(\bissue{8}),
\bfpage{2439}--\blpage{2452}
(\byear{2022}).
doi:\doiurl{10.1111/ene.15373}
\end{barticle}
\endbibitem

%%% 4
\bibitem{ATXN3}
\begin{barticle}
\bauthor{\bsnm{Hubener-Schmid}, \binits{J.}},
\bauthor{\bsnm{Kuhlbrodt}, \binits{K.}},
\bauthor{\bsnm{Peladan}, \binits{J.}},
\bauthor{\bsnm{Faber}, \binits{J.}},
\bauthor{\bsnm{Santana}, \binits{M.M.}},
\bauthor{\bsnm{Hengel}, \binits{H.}},
\bauthor{\bsnm{Jacobi}, \binits{H.}},
\bauthor{\bsnm{Reetz}, \binits{K.}},
\bauthor{\bsnm{Garcia-Moreno}, \binits{H.}},
\bauthor{\bsnm{Raposo}, \binits{M.}},
\bauthor{\bparticle{van} \bsnm{Gaalen}, \binits{J.}},
\bauthor{\bsnm{Infante}, \binits{J.}},
\bauthor{\bsnm{Steiner}, \binits{K.M.}},
\bauthor{\bparticle{de} \bsnm{Vries}, \binits{J.}},
\bauthor{\bsnm{Verbeek}, \binits{M.M.}},
\bauthor{\bsnm{Giunti}, \binits{P.}},
\bauthor{\bparticle{Pereira~de} \bsnm{Almeida}, \binits{L.}},
\bauthor{\bsnm{Lima}, \binits{M.}},
\bauthor{\bparticle{van~de} \bsnm{Warrenburg}, \binits{B.}},
\bauthor{\bsnm{Schols}, \binits{L.}},
\bauthor{\bsnm{Klockgether}, \binits{T.}},
\bauthor{\bsnm{Synofzik}, \binits{M.}},
\bauthor{\bsnm{European Spinocerebellar Ataxia Type-3/Machado-Joseph Disease
  Initiative~Study}, \binits{G.}},
\bauthor{\bsnm{Riess}, \binits{O.}}:
\batitle{Polyglutamine-expanded ataxin-3: A target engagement marker for
  spinocerebellar ataxia type 3 in peripheral blood}.
\bjtitle{Mov Disord}
(\byear{2021}).
doi:\doiurl{10.1002/mds.28749}
\end{barticle}
\endbibitem

%%% 5
\bibitem{SCAreview2018}
\begin{barticle}
\bauthor{\bsnm{Ashizawa}, \binits{T.}},
\bauthor{\bsnm{\"Oz}, \binits{G.}},
\bauthor{\bsnm{Paulson}, \binits{H.L.}}:
\batitle{Spinocerebellar ataxias: prospects and challenges for therapy
  development}.
\bjtitle{Nat Rev Neurol}
\bvolume{14},
\bfpage{590}--\blpage{605}
(\byear{2018}).
doi:\doiurl{10.1038/s41582-018-0051-6}
\end{barticle}
\endbibitem

%%% 6
\bibitem{SCAreview2019}
\begin{barticle}
\bauthor{\bsnm{Klockgether}, \binits{T.}},
\bauthor{\bsnm{Mariotti}, \binits{C.}},
\bauthor{\bsnm{Paulson}, \binits{H.L.}}:
\batitle{Spinocerebellar ataxia}.
\bjtitle{Nat Rev Dis Primers}
\bvolume{5}(\bissue{1}),
\bfpage{24}
(\byear{2019}).
doi:\doiurl{10.1038/s41572-019-0074-3}
\end{barticle}
\endbibitem

%%% 7
\bibitem{baker1975dragon}
\begin{barticle}
\bauthor{\bsnm{Baker}, \binits{J.}}:
\batitle{The dragon system--an overview}.
\bjtitle{IEEE Transactions on Acoustics, speech, and signal Processing}
\bvolume{23}(\bissue{1}),
\bfpage{24}--\blpage{29}
(\byear{1975})
\end{barticle}
\endbibitem

%%% 8
\bibitem{nilsson2002speech}
\begin{botherref}
\oauthor{\bsnm{Nilsson}, \binits{M.}},
\oauthor{\bsnm{Ejnarsson}, \binits{M.}}:
Speech recognition using hidden markov model
(2002)
\end{botherref}
\endbibitem

%%% 9
\bibitem{lee1999hmm}
\begin{barticle}
\bauthor{\bsnm{Lee}, \binits{H.-K.}},
\bauthor{\bsnm{Kim}, \binits{J.-H.}}:
\batitle{An hmm-based threshold model approach for gesture recognition}.
\bjtitle{IEEE Transactions on pattern analysis and machine intelligence}
\bvolume{21}(\bissue{10}),
\bfpage{961}--\blpage{973}
(\byear{1999})
\end{barticle}
\endbibitem

%%% 10
\bibitem{frasconi2001text}
\begin{bchapter}
\bauthor{\bsnm{Frasconi}, \binits{P.}},
\bauthor{\bsnm{Soda}, \binits{G.}},
\bauthor{\bsnm{Vullo}, \binits{A.}}:
\bctitle{Text categorization for multi-page documents: A hybrid naive bayes hmm
  approach}.
In: \bbtitle{Proceedings of the 1st ACM/IEEE-CS Joint Conference on Digital
  Libraries},
pp. \bfpage{11}--\blpage{20}
(\byear{2001})
\end{bchapter}
\endbibitem

%%% 11
\bibitem{vairavan2012prediction}
\begin{bchapter}
\bauthor{\bsnm{Vairavan}, \binits{S.}},
\bauthor{\bsnm{Eshelman}, \binits{L.}},
\bauthor{\bsnm{Haider}, \binits{S.}},
\bauthor{\bsnm{Flower}, \binits{A.}},
\bauthor{\bsnm{Seiver}, \binits{A.}}:
\bctitle{Prediction of mortality in an intensive care unit using logistic
  regression and a hidden markov model}.
In: \bbtitle{2012 Computing in Cardiology},
pp. \bfpage{393}--\blpage{396}
(\byear{2012}).
\bcomment{IEEE}
\end{bchapter}
\endbibitem

%%% 12
\bibitem{rabiner1989tutorial}
\begin{barticle}
\bauthor{\bsnm{Rabiner}, \binits{L.R.}}:
\batitle{A tutorial on hidden markov models and selected applications in speech
  recognition}.
\bjtitle{Proceedings of the IEEE}
\bvolume{77}(\bissue{2}),
\bfpage{257}--\blpage{286}
(\byear{1989})
\end{barticle}
\endbibitem

%%% 13
\bibitem{viterbi1967error}
\begin{barticle}
\bauthor{\bsnm{Viterbi}, \binits{A.}}:
\batitle{Error bounds for convolutional codes and an asymptotically optimum
  decoding algorithm}.
\bjtitle{IEEE transactions on Information Theory}
\bvolume{13}(\bissue{2}),
\bfpage{260}--\blpage{269}
(\byear{1967})
\end{barticle}
\endbibitem

%%% 14
\bibitem{dempster1977maximum}
\begin{barticle}
\bauthor{\bsnm{Dempster}, \binits{A.P.}},
\bauthor{\bsnm{Laird}, \binits{N.M.}},
\bauthor{\bsnm{Rubin}, \binits{D.B.}}:
\batitle{Maximum likelihood from incomplete data via the em algorithm}.
\bjtitle{Journal of the Royal Statistical Society: Series B (Methodological)}
\bvolume{39}(\bissue{1}),
\bfpage{1}--\blpage{22}
(\byear{1977})
\end{barticle}
\endbibitem

%%% 15
\bibitem{grandini2020metrics}
\begin{botherref}
\oauthor{\bsnm{Grandini}, \binits{M.}},
\oauthor{\bsnm{Bagli}, \binits{E.}},
\oauthor{\bsnm{Visani}, \binits{G.}}:
Metrics for multi-class classification: an overview.
arXiv preprint arXiv:2008.05756
(2020)
\end{botherref}
\endbibitem

%%% 16
\bibitem{knuth1964backus}
\begin{barticle}
\bauthor{\bsnm{Knuth}, \binits{D.E.}}:
\batitle{Backus normal form vs. backus naur form}.
\bjtitle{Communications of the ACM}
\bvolume{7}(\bissue{12}),
\bfpage{735}--\blpage{736}
(\byear{1964})
\end{barticle}
\endbibitem

%%% 17
\bibitem{diseasestages}
\begin{barticle}
\bauthor{\bsnm{Klockgether}, \binits{T.}},
\bauthor{\bsnm{Ludtke}, \binits{R.}},
\bauthor{\bsnm{Kramer}, \binits{B.}},
\bauthor{\bsnm{Abele}, \binits{M.}},
\bauthor{\bsnm{Burk}, \binits{K.}},
\bauthor{\bsnm{Schols}, \binits{L.}},
\bauthor{\bsnm{Riess}, \binits{O.}},
\bauthor{\bsnm{Laccone}, \binits{F.}},
\bauthor{\bsnm{Boesch}, \binits{S.}},
\bauthor{\bsnm{Lopes-Cendes}, \binits{I.}},
\bauthor{\bsnm{Brice}, \binits{A.}},
\bauthor{\bsnm{Inzelberg}, \binits{R.}},
\bauthor{\bsnm{Zilber}, \binits{N.}},
\bauthor{\bsnm{Dichgans}, \binits{J.}}:
\batitle{The natural history of degenerative ataxia: a retrospective study in
  466 patients}.
\bjtitle{Brain}
\bvolume{121 ( Pt 4)},
\bfpage{589}--\blpage{600}
(\byear{1998}).
doi:\doiurl{10.1093/brain/121.4.589}
\end{barticle}
\endbibitem

%%% 18
\bibitem{SARA}
\begin{barticle}
\bauthor{\bsnm{Schmitz-H{\"u}bsch}, \binits{T.}},
\bauthor{\bparticle{du} \bsnm{Montcel}, \binits{S.T.}},
\bauthor{\bsnm{Baliko}, \binits{L.}},
\bauthor{\bsnm{Berciano}, \binits{J.}},
\bauthor{\bsnm{Boesch}, \binits{S.}},
\bauthor{\bsnm{Depondt}, \binits{C.}},
\bauthor{\bsnm{Giunti}, \binits{P.}},
\bauthor{\bsnm{Globas}, \binits{C.}},
\bauthor{\bsnm{Infante}, \binits{J.}},
\bauthor{\bsnm{Kang}, \binits{J.-S.}},
\bauthor{\bsnm{Kremer}, \binits{B.}},
\bauthor{\bsnm{Mariotti}, \binits{C.}},
\bauthor{\bsnm{Melegh}, \binits{B.}},
\bauthor{\bsnm{Pandolfo}, \binits{M.}},
\bauthor{\bsnm{Rakowicz}, \binits{M.}},
\bauthor{\bsnm{Ribai}, \binits{P.}},
\bauthor{\bsnm{Rola}, \binits{R.}},
\bauthor{\bsnm{Sch{\"o}ls}, \binits{L.}},
\bauthor{\bsnm{Szymanski}, \binits{S.}},
\bauthor{\bparticle{van~de} \bsnm{Warrenburg}, \binits{B.P.}},
\bauthor{\bsnm{D{\"u}rr}, \binits{A.}},
\bauthor{\bsnm{Klockgether}, \binits{T.}}:
\batitle{Scale for the assessment and rating of ataxia}.
\bjtitle{Neurology}
\bvolume{66}(\bissue{11}),
\bfpage{1717}--\blpage{1720}
(\byear{2006})
\end{barticle}
\endbibitem

%%% 19
\bibitem{INAS}
\begin{barticle}
\bauthor{\bsnm{Jacobi}, \binits{H.}},
\bauthor{\bsnm{Rakowicz}, \binits{M.}},
\bauthor{\bsnm{Rola}, \binits{R.}},
\bauthor{\bsnm{Fancellu}, \binits{R.}},
\bauthor{\bsnm{Mariotti}, \binits{C.}},
\bauthor{\bsnm{Charles}, \binits{P.}},
\bauthor{\bsnm{Durr}, \binits{A.}},
\bauthor{\bsnm{Kuper}, \binits{M.}},
\bauthor{\bsnm{Timmann}, \binits{D.}},
\bauthor{\bsnm{Linnemann}, \binits{C.}},
\bauthor{\bsnm{Schols}, \binits{L.}},
\bauthor{\bsnm{Kaut}, \binits{O.}},
\bauthor{\bsnm{Schaub}, \binits{C.}},
\bauthor{\bsnm{Filla}, \binits{A.}},
\bauthor{\bsnm{Baliko}, \binits{L.}},
\bauthor{\bsnm{Melegh}, \binits{B.}},
\bauthor{\bsnm{Kang}, \binits{J.S.}},
\bauthor{\bsnm{Giunti}, \binits{P.}},
\bauthor{\bparticle{van~de} \bsnm{Warrenburg}, \binits{B.P.}},
\bauthor{\bsnm{Fimmers}, \binits{R.}},
\bauthor{\bsnm{Klockgether}, \binits{T.}}:
\batitle{Inventory of non-ataxia signs (inas): validation of a new clinical
  assessment instrument}.
\bjtitle{Cerebellum}
\bvolume{12}(\bissue{3}),
\bfpage{418}--\blpage{28}
(\byear{2013}).
doi:\doiurl{10.1007/s12311-012-0421-3}
\end{barticle}
\endbibitem

%%% 20
\bibitem{ADL}
\begin{barticle}
\bauthor{\bsnm{Reetz}, \binits{K.}},
\bauthor{\bsnm{Dogan}, \binits{I.}},
\bauthor{\bsnm{Hilgers}, \binits{R.D.}},
\bauthor{\bsnm{Giunti}, \binits{P.}},
\bauthor{\bsnm{Mariotti}, \binits{C.}},
\bauthor{\bsnm{Durr}, \binits{A.}},
\bauthor{\bsnm{Boesch}, \binits{S.}},
\bauthor{\bsnm{Klopstock}, \binits{T.}},
\bauthor{\bparticle{de} \bsnm{Rivera}, \binits{F.J.R.}},
\bauthor{\bsnm{Schols}, \binits{L.}},
\bauthor{\bsnm{Klockgether}, \binits{T.}},
\bauthor{\bsnm{Burk}, \binits{K.}},
\bauthor{\bsnm{Rai}, \binits{M.}},
\bauthor{\bsnm{Pandolfo}, \binits{M.}},
\bauthor{\bsnm{Schulz}, \binits{J.B.}},
\bauthor{\bsnm{Group}, \binits{E.S.}}:
\batitle{Progression characteristics of the european friedreich's ataxia
  consortium for translational studies (efacts): a 2 year cohort study}.
\bjtitle{Lancet Neurol}
\bvolume{15}(\bissue{13}),
\bfpage{1346}--\blpage{1354}
(\byear{2016}).
doi:\doiurl{10.1016/S1474-4422(16)30287-3}
\end{barticle}
\endbibitem

%%% 21
\bibitem{chau1997optimization}
\begin{bchapter}
\bauthor{\bsnm{Chau}, \binits{C.-W.}},
\bauthor{\bsnm{Kwong}, \binits{S.}},
\bauthor{\bsnm{Diu}, \binits{C.}},
\bauthor{\bsnm{Fahrner}, \binits{W.R.}}:
\bctitle{Optimization of hmm by a genetic algorithm}.
In: \bbtitle{1997 IEEE International Conference on Acoustics, Speech, and
  Signal Processing},
vol. \bseriesno{3},
pp. \bfpage{1727}--\blpage{1730}
(\byear{1997}).
\bcomment{IEEE}
\end{bchapter}
\endbibitem

\end{thebibliography}

% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

%\end{backmatter}
\end{document}
