\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{pc-gan}
Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas.
\newblock Learning representations and generative models for 3{D} point clouds.
\newblock In {\em ICML}, 2018.

\bibitem{progressive-pcgan}
Mohammad~Samiul Arshad and William~J. Beksi.
\newblock A progressive conditional generative adversarial network for
  generating dense and colored 3{D} point clouds.
\newblock In {\em 3{D}V}, 2020.

\bibitem{autodrive1}
Aseem Behl, Omid Hosseini~Jafari, Siva Karthik~Mustikovela, Hassan Abu~Alhaija,
  Carsten Rother, and Andreas Geiger.
\newblock Bounding boxes, segmentations and object coordinates: How important
  is recognition for 3{D} scene flow estimation in autonomous driving
  scenarios?
\newblock In {\em ICCV}, 2017.

\bibitem{deepls}
Rohan Chabra, Jan~E Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven
  Lovegrove, and Richard Newcombe.
\newblock Deep local shapes: Learning local sdf priors for detailed 3{D}
  reconstruction.
\newblock In {\em ECCV}, 2020.

\bibitem{shapenet2015}
Angel~X. Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang,
  Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao,
  Li Yi, and Fisher Yu.
\newblock {ShapeNet: An Information-Rich 3{D} Model Repository}.
\newblock Technical Report arXiv:1512.03012 [cs.GR], Stanford University ---
  Princeton University --- Toyota Technological Institute at Chicago, 2015.

\bibitem{lfd}
Ding-Yun Chen, Xiao-Pei Tian, Yu-Te Shen, and Ming Ouhyoung.
\newblock On visual similarity based 3{D} model retrieval.
\newblock In {\em CGF}, 2003.

\bibitem{autodrive2}
Yiping Chen, Jingkang Wang, Jonathan Li, Cewu Lu, Zhipeng Luo, Han Xue, and
  Cheng Wang.
\newblock {LiDAR-Video Driving Dataset: Learning Driving Policies Effectively}.
\newblock In {\em CVPR}, 2018.

\bibitem{im-gan}
Zhiqin Chen and Hao Zhang.
\newblock Learning implicit fields for generative shape modeling.
\newblock In {\em CVPR}, 2019.

\bibitem{mmvad}
Zezhou Cheng, Menglei Chai, Jian Ren, Hsin-Ying Lee, Kyle Olszewski, Zeng
  Huang, Subhransu Maji, and Sergey Tulyakov.
\newblock Cross-modal 3{D} shape generation and manipulation.
\newblock {\em arXiv preprint arXiv:2207.11795}, 2022.

\bibitem{treestructure1}
Zhou Cheng, Chun Yuan, Jiancheng Li, and Haiqin Yang.
\newblock Treenet: Learning sentence representations with unconstrained tree
  structure.
\newblock In {\em IJCAI}, 2018.

\bibitem{if-net}
Julian Chibane, Thiemo Alldieck, and Gerard Pons-Moll.
\newblock Implicit functions in feature space for 3{D} shape reconstruction and
  completion.
\newblock In {\em CVPR}, 2020.

\bibitem{dif-net}
Yu Deng, Jiaolong Yang, and Xin Tong.
\newblock Deformed implicit field: Modeling 3{D} shapes with learned dense
  correspondence.
\newblock In {\em CVPR}, 2021.

\bibitem{shapecrafter}
Rao Fu, Xiao Zhan, Yiwen Chen, Daniel Ritchie, and Srinath Sridhar.
\newblock Shapecrafter: A recursive text-conditioned 3{D} shape generation
  model.
\newblock {\em NeurIPS}, 2022.

\bibitem{mrgan}
Rinon Gal, Amit Bermano, Hao Zhang, and Daniel Cohen-Or.
\newblock {MRGAN}: Multi-rooted 3{D} shape representation learning with
  unsupervised part disentanglement.
\newblock In {\em ICCVW}, 2021.

\bibitem{get3D}
Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li, Or
  Litany, Zan Gojcic, and Sanja Fidler.
\newblock Get3{D}: A generative model of high quality 3{D} textured shapes
  learned from images.
\newblock In {\em NeurIPS}, 2022.

\bibitem{autodrive3}
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
\newblock Are we ready for autonomous driving? the kitti vision benchmark
  suite.
\newblock In {\em CVPR}, 2012.

\bibitem{gan}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em NeurIPS}, 2014.

\bibitem{atlas-net}
Thibault Groueix, Matthew Fisher, Vladimir~G Kim, Bryan~C Russell, and Mathieu
  Aubry.
\newblock A papier-m{\^a}ch{\'e} approach to learning 3{D} surface generation.
\newblock In {\em CVPR}, 2018.

\bibitem{robotics1}
Joris Guerry, Alexandre Boulch, Bertrand Le~Saux, Julien Moras, Aur{\'e}lien
  Plyer, and David Filliat.
\newblock Snapnet-r: Consistent 3{D} multi-view semantic labeling for robotics.
\newblock In {\em ICCVW}, 2017.

\bibitem{sketch2mesh}
Benoit Guillard, Edoardo Remelli, Pierre Yvernay, and Pascal Fua.
\newblock {Sketch2Mesh: Reconstructing and Editing 3{D} Shapes from Sketches}.
\newblock In {\em ICCV}, 2021.

\bibitem{ar_vr}
Lei Han, Tian Zheng, Yinheng Zhu, Lan Xu, and Lu Fang.
\newblock Live semantic 3{D} perception for immersive augmented reality.
\newblock {\em TVCG}, 2020.

\bibitem{hsp}
Christian H{\"a}ne, Shubham Tulsiani, and Jitendra Malik.
\newblock Hierarchical surface prediction for 3{D} object reconstruction.
\newblock In {\em 3{D}V}, 2017.

\bibitem{dualsdf}
Zekun Hao, Hadar Averbuch-Elor, Noah Snavely, and Serge Belongie.
\newblock Dualsdf: Semantic shape manipulation using a two-level
  representation.
\newblock In {\em CVPR}, 2020.

\bibitem{ganspace}
Erik H{\"a}rk{\"o}nen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.
\newblock Ganspace: Discovering interpretable gan controls.
\newblock In {\em NeurIPS}, 2020.

\bibitem{eigengan}
Zhenliang He, Meina Kan, and Shiguang Shan.
\newblock Eigengan: Layer-wise eigen-learning for gans.
\newblock In {\em ICCV}, 2021.

\bibitem{SPAGHETTI}
Amir Hertz, Or Perel, Raja Giryes, Olga Sorkine-Hornung, and Daniel Cohen-Or.
\newblock {SPAGHETTI: Editing Implicit Shapes Through Part Aware Generation}.
\newblock {\em arXiv preprint arXiv:2201.13168}, 2022.

\bibitem{adain}
Xun Huang and Serge Belongie.
\newblock Arbitrary style transfer in real-time with adaptive instance
  normalization.
\newblock In {\em ICCV}, 2017.

\bibitem{pdgn}
Le Hui, Rui Xu, Jin Xie, Jianjun Qian, and Jian Yang.
\newblock Progressive point cloud deconvolution generation network.
\newblock In {\em ECCV}, 2020.

\bibitem{grid-im-gan}
Moritz Ibing, Isaak Lim, and Leif Kobbelt.
\newblock 3{D} shape generation with grid-based implicit functions.
\newblock In {\em CVPR}, 2021.

\bibitem{pix2pix}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In {\em CVPR}, 2017.

\bibitem{stylegan}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em CVPR}, 2019.

\bibitem{stylegan2}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
  Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In {\em CVPR}, 2020.

\bibitem{softflow}
Hyeongju Kim, Hyeonseung Lee, Woo~Hyun Kang, Joun~Yeop Lee, and Nam~Soo Kim.
\newblock Softflow: Probabilistic framework for normalizing flow on manifolds.
\newblock In {\em NeurIPS}, 2020.

\bibitem{shapegan}
Marian Kleineberg, Matthias Fey, and Frank Weichert.
\newblock {Adversarial Generation of Continuous Implicit Shape
  Representations}.
\newblock In {\em EG}, 2020.

\bibitem{dpf}
Roman Klokov, Edmond Boyer, and Jakob Verbeek.
\newblock Discrete point flow networks for efficient point cloud generation.
\newblock In {\em ECCV}, 2020.

\bibitem{pagenet}
Jun Li, Chengjie Niu, and Kai Xu.
\newblock Learning part generation and assembly for structure-aware shape
  synthesis.
\newblock In {\em AAAI}, 2020.

\bibitem{GRASS}
Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang, and Leonidas
  Guibas.
\newblock {GRASS}: Generative recursive autoencoders for shape structures.
\newblock {\em TOG}, 2017.

\bibitem{spgan}
Ruihui Li, Xianzhi Li, Ka-Hei Hui, and Chi-Wing Fu.
\newblock {SP-GAN}: Sphere-guided 3{D} shape generation and manipulation.
\newblock {\em TOG}, 2021.

\bibitem{editvae}
Shidi Li, Miaomiao Liu, and Christian Walder.
\newblock {EditVAE}: Unsupervised parts-aware controllable 3{D} point cloud
  shape generation.
\newblock In {\em AAAI}, 2022.

\bibitem{learning-implicit-functions-for-topology-varying-dense-3D-shape-correspondence}
Feng Liu and Xiaoming Liu.
\newblock Learning implicit functions for topology-varying dense 3{D} shape
  correspondence.
\newblock In {\em NeurIPS}, 2020.

\bibitem{voxel-based-3D-detection-and-reconstruction-of-multiple-objects-from-a-single-image}
Feng Liu and Xiaoming Liu.
\newblock Voxel-based 3{D} detection and reconstruction of multiple objects
  from a single image.
\newblock In {\em NeurIPS}, 2021.

\bibitem{2d-gans-meet-unsupervised-single-view-3D-reconstruction}
Feng Liu and Xiaoming Liu.
\newblock 2{D} gans meet unsupervised single-view 3{D} reconstruction.
\newblock In {\em ECCV}, 2022.

\bibitem{learning-implicit-functions-for-dense-3D-shape-correspondence-of-generic-objects}
Feng Liu and Xiaoming Liu.
\newblock Learning implicit functions for dense 3{D} shape correspondence of
  generic objects.
\newblock {\em TPAMI}, 2023.

\bibitem{fully-understanding-generic-objects-modeling-segmentation-and-reconstruction}
Feng Liu, Luan Tran, and Xiaoming Liu.
\newblock Fully understanding generic objects: Modeling, segmentation, and
  reconstruction.
\newblock In {\em CVPR}, 2021.

\bibitem{deepmetahandles}
Minghua Liu, Minhyuk Sung, Radomir Mech, and Hao Su.
\newblock Deepmetahandles: Learning deformation meta-handles of 3{D} meshes
  with biharmonic coordinates.
\newblock In {\em CVPR}, 2021.

\bibitem{implicit_text_3D}
Zhengzhe Liu, Yi Wang, Xiaojuan Qi, and Chi-Wing Fu.
\newblock Towards implicit text-guided 3{D} shape generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 17896--17906, June 2022.

\bibitem{marchingcubes}
William~E Lorensen and Harvey~E Cline.
\newblock Marching cubes: A high resolution 3{D} surface construction
  algorithm.
\newblock In {\em SIGGRAPH}, 1987.

\bibitem{luo2021diffusion}
Shitong Luo and Wei Hu.
\newblock Diffusion probabilistic models for 3{D} point cloud generation.
\newblock In {\em CVPR}, 2021.

\bibitem{r1}
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.
\newblock Which training methods for gans do actually converge?
\newblock In {\em ICML}, 2018.

\bibitem{autosdf}
Paritosh Mittal, Yen-Chi Cheng, Maneesh Singh, and Shubham Tulsiani.
\newblock Autosdf: Shape priors for 3{D} completion, reconstruction and
  generation.
\newblock In {\em CVPR}, 2022.

\bibitem{StructureNet}
Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy~J. Mitra, and
  Leonidas~J. Guibas.
\newblock Structurenet: Hierarchical graph networks for 3{D} shape generation.
\newblock {\em TOG}, 2019.

\bibitem{polygen}
Charlie Nash, Yaroslav Ganin, SM~Ali Eslami, and Peter Battaglia.
\newblock Polygen: An autoregressive generative model of 3{D} meshes.
\newblock In {\em ICML}, 2020.

\bibitem{deepsdf}
Jeong~Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven
  Lovegrove.
\newblock Deepsdf: Learning continuous signed distance functions for shape
  representation.
\newblock In {\em CVPR}, 2019.

\bibitem{clean-fid}
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu.
\newblock On aliased resizing and surprising subtleties in gan evaluation.
\newblock In {\em CVPR}, 2022.

\bibitem{sefa}
Yujun Shen and Bolei Zhou.
\newblock Closed-form factorization of latent semantics in gans.
\newblock In {\em CVPR}, 2021.

\bibitem{tree-gan}
Dong~Wook Shu, Sung~Woo Park, and Junseok Kwon.
\newblock 3{D} point cloud generative adversarial network based on tree
  structured graph convolutions.
\newblock In {\em ICCV}, 2019.

\bibitem{robotics2}
Keisuke Tateno, Federico Tombari, Iro Laina, and Nassir Navab.
\newblock Cnn-slam: Real-time dense monocular slam with learned depth
  prediction.
\newblock In {\em CVPR}, 2017.

\bibitem{g2l-gan}
Hao Wang, Nadav Schor, Ruizhen Hu, Haibin Huang, Daniel Cohen-Or, and Hui
  Huang.
\newblock Global-to-local generative model for 3{D} shapes.
\newblock {\em TOG}, 2018.

\bibitem{wei2020learning}
Fangyin Wei, Elena Sizikova, Avneesh Sud, Szymon Rusinkiewicz, and Thomas
  Funkhouser.
\newblock Learning to infer semantic parameters for 3{D} shape editing.
\newblock In {\em 3{D}V}, 2020.

\bibitem{3D-gan}
Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum.
\newblock Learning a probabilistic latent space of object shapes via 3{D}
  generative-adversarial modeling.
\newblock In {\em NeurIPS}, 2016.

\bibitem{pq-net}
Rundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, and Baoquan Chen.
\newblock Pq-net: A generative part seq2seq network for 3{D} shapes.
\newblock In {\em CVPR}, 2020.

\bibitem{shapeformer}
Xingguang Yan, Liqiang Lin, Niloy~J Mitra, Dani Lischinski, Daniel Cohen-Or,
  and Hui Huang.
\newblock Shapeformer: Transformer-based shape completion via sparse
  representation.
\newblock In {\em CVPR}, 2022.

\bibitem{pointflow}
Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, Serge Belongie, and Bharath
  Hariharan.
\newblock Pointflow: 3{D} point cloud generation with continuous normalizing
  flows.
\newblock In {\em ICCV}, 2019.

\bibitem{dsg-net}
Jie Yang, Kaichun Mo, Yu-Kun Lai, Leonidas~J Guibas, and Lin Gao.
\newblock {DSG-Net}: Learning disentangled structure and geometry for 3{D}
  shape generation.
\newblock {\em TOG}, 2022.

\bibitem{lion}
Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Gojcic, Or Litany, Sanja
  Fidler, and Karsten Kreis.
\newblock {LION}: Latent point diffusion models for 3{D} shape generation.
\newblock In {\em NeurIPS}, 2022.

\bibitem{3Dilg}
Biao Zhang, Matthias Nie{\ss}ner, and Peter Wonka.
\newblock {3{D}ILG: Irregular Latent Grids for 3{D} Generative Modeling}.
\newblock In {\em NeurIPS}, 2022.

\bibitem{gca}
Dongsu Zhang, Changwoon Choi, Jeonghwan Kim, and Young~Min Kim.
\newblock Learning to generate 3{D} shapes with generative cellular automata.
\newblock In {\em ICLR}, 2021.

\bibitem{sdfstylegan}
Xin-Yang Zheng, Yang Liu, Peng-Shuai Wang, and Xin Tong.
\newblock {SDF-StyleGAN}: implicit sdf-based stylegan for 3{D} shape
  generation.
\newblock {\em arXiv preprint arXiv:2206.12055}, 2022.

\bibitem{pvd}
Linqi Zhou, Yilun Du, and Jiajun Wu.
\newblock 3{D} shape generation and completion through point-voxel diffusion.
\newblock In {\em ICCV}, 2021.

\end{thebibliography}
