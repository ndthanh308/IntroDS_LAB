\section{Background}
\label{sec:background}

\subsection{Large Language Model}
Large Language Models (LLMs) have achieved impressive performance on a wide range of natural language processing (NLP) tasks, including machine translation~\cite{radford2019language, chowdhery2022palm, hendy2023good}, summarization~\cite{radford2019language, feng2020codebert, goyal2022news}, sentiment analysis~\cite{xu-etal-2020-dombert, zhang2020sentiment}, and question-answering~\cite{radford2019language, openai2023gpt4}. %to do: add references
These models, typically based on deep learning architectures such as transformers, are trained on massive amounts of text data, allowing them to learn complex language patterns and structures. By capturing both the syntax and semantics of human language, LLMs have been successful in generating coherent and contextually relevant text.

One prominent example of an LLM is ChatGPT, developed by OpenAI and based on the GPT-3 architecture. ChatGPT demonstrates an unprecedented ability to understand and generate human-like text, making it well-suited for a variety of applications, including code generation. By training ChatGPT on extensive source code repositories, the model has become capable of generating code snippets and solving programming problems with remarkable accuracy~\cite{hou2023large}.

\subsection{Motivation}

While LLMs have shown great promise in code generation, the reliability of the generated code is questionable. The problem has become more critical with the emergence of ChatGPT, as LLMs-driven code generation is now being used not only by experienced developers but also by novice programmers or even individuals with no coding experience, who may be unaware of the code quality issues. 
% \kla{do we need to present what is the prompt for this as the generated code is depending on the prompts? you can acknowledge this as a threat as well?}
% \begin{lstlisting}[language=python, caption=A simplified version of an buggy code generated by ChatGPT for solving the LeetCode Problem 1093 - 'Statistics from a Large Sample', label=fig:bug_example]
% #Description
% '''
% You are given a large sample of integers in the range [0, 255]. Since the sample is so large, it is represented by an array count where count[k] is the number of times that k appears in the sample. 
% Calculate `mean`, i.e. the average of the sample, calculated as the total sum of all elements divided by the total number of elements. 
% Input: count = [0,1,3,4, 0, ..., 0]
% Output: 2.37500
% Explanation: The sample represented by count is [1,2,2,2,3,3,3,3] so the mean is
%     1+2+2+2+3+3+3+3)/8 = 19/8 = 2.375.
% '''
% #ChatGPT Generated Code
% class Solution(object):
%    def sampleStats(self, count):
%        countSum = 0
%        totalNum = sum(count)
%        mean = 0
%        for i in range(256):
%            if count[i] > 0:
%                countSum += count[i] * i
%        mean = countSum / totalNum
%        return mean
% \end{lstlisting}

% % Figure environment removed


% Figure environment removed

Figure~\ref{fig:bug_example} describes a motivating example for our study.
Figure~\ref{fig:bug_example}(a) presents the prompts to ChatGPT, which combine the task description, constraints, and predefined code templates.
The programming task is called “Statistics from a Large Sample” \cite{leetcode1093}.
The problem requires ChatGPT to generate a code that calculates the mean of a large sample of integers, represented by a \texttt{count} array where \texttt{count[k]} represents the frequency of integer k in the sample.
Figure~\ref{fig:bug_example}(b) presents buggy code generated by ChatGPT to solve this problem. While looking straightforward and correct, the ChatGPT-generated code produces the incorrect output from the example test, as shown in Figure~\ref{fig:bug_example}(c).
The expected output from the test is 2.375, while the result from ChatGPT-generated code is 2. 
The root cause is that \texttt{mean} is calculated using integer division (rounding down to an integer) since both \texttt{countSum} and \texttt{totalNum} are integers.
Though the error is quite simple, it can be difficult for developers or programmers who are not familiar with Python programming languages to detect. It can also lead to more complex errors in other functions that call to this function without the awareness of the error. 

\begin{lstlisting}[language=Python, caption=A code smell generated by ChatGPT for solving the LeetCode Problem 1838 - 'Frequency of the Most Frequent Element', label=fig:smell_example]
def getMinDistance(self, nums: List[int], target: int, start: int) -> int:
    min_diff = float('inf')
    min_index = -1
    for i in range(len(nums)):
        if nums[i] == target:
            diff = abs(i - start)
            if diff < min_diff:
                min_diff = diff
                min_index = i
    return min_diff
\end{lstlisting}
Additionally, we also observed that the quality of the ChatGPT-generated code may still be poor even if it is functionally correct. Code~\ref{fig:smell_example} illustrates an example of poor-quality code generated by ChatGPT. This is a simplified version of code generated by ChatGPT for LeetCode Problem 1838, `Frequency of the Most Frequent Element'. The \texttt{min\_index} variable is declared on line 3 and assigned values on line 9, but it is never used elsewhere in the code. This is a minor code smell, but it is worth noting that this issue occurs in a simple 10-line code for a common problem. Let's imagine complex tasks and code, could we ensure that ChatGPT-generated code does not contain smells, bugs, or even vulnerabilities? This realization motivated us to conduct a comprehensive study on the quality issues present in ChatGPT-generated code. Our study aims to not only enhance our understanding of these issues but also to provide suggestions for mitigating them.


