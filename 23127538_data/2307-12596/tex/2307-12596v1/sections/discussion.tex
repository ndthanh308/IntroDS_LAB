\section{Discussion}
\label{sec:discussion}
% In this section, we present the lessons learned from our experiments and discuss limitations and threats to validity.

\subsection{Lessons Learned}
In this section, we highlight key lessons learned through our experiments and analysis that can drive future research in the field.

\textbf{Code quality issues are prevalent in AI-generated code:} Our study revealed that ChatGPT-generated code is prone to various code quality issues, including compilation and runtime errors, wrong outputs, and maintainability problems.
This finding emphasizes the importance of addressing these issues to ensure the long-term success of AI-driven code generation and to maintain high-quality software systems.

\textbf{Task difficulty, time that tasks are introduced, and program size impact automated code generation performance:} We found that the performance of ChatGPT on code generation tasks is significantly influenced by factors such as task difficulty, task-established time, and program size. This suggests that improvements in AI models should consider these factors to better adapt to different types of code generation tasks.

\textbf{Tailored feedback and prompt engineering are crucial for effective self-debugging and code generation quality:} Our results suggest that the effectiveness of ChatGPT's self-mitigating capabilities depends on the type of feedback provided, the programming language, and the specific code quality issue. For instance, static analysis feedback works better for code style and maintainability issues, while simple feedback is more effective for addressing execution errors and wrong outputs. This finding highlights the importance of providing tailored feedback to maximize the efficacy of ChatGPT's self-mitigating capabilities. Moreover, the quality of ChatGPT-generated code can be heavily affected by the choice of prompts. Future work could explore optimizing prompts to improve the accuracy and reliability of ChatGPT-generated code, further enhancing the overall effectiveness of AI-driven code generation models.

% \textbf{AI-driven code generation requires continuous improvement and monitoring:} As AI models like ChatGPT evolve and become more advanced, it is crucial to continuously monitor and assess the quality of the generated code. This ongoing process will help identify new issues and opportunities for improvement, ensuring the long-term success of AI-driven code generation in real-world applications.
% \subsection{Limitations}

\subsection{Threats to Validity}

% Below, we discuss threats that may impact the results of our study.

\subsubsection{External validity} 
Threats to external validity concern the generalizability of our findings. 
Our study is based on a dataset of 2,033 programming tasks from LeetCode, which may not represent all possible code generation tasks encountered in real-world software development. 
Additionally, we focus on Java and Python, two popular programming languages; however, our findings may not be directly applicable to other programming languages. 
To mitigate these threats, future work could expand the dataset by incorporating tasks from various sources and diverse programming languages, and by considering different types of software projects, such as web applications, mobile apps, and embedded systems.


\subsubsection{Internal validity}
Threats to internal validity refer to possible errors in our experiments. One such threat relates to bugs happening in our code. To mitigate this risk, we have carefully checked our code and made our code publicly available in figshare.~\cite{replication} Another possible threat may be introduced from our manual analysis and categorization. To eliminate the potential bias, we conducted a sorting discussion among three annotators. We also release our analysis and categorization results for public verification.   

\subsubsection{Construct validity} 
Threats to construct validity relate to the suitability of our evaluation. In our study, we use the pass@1 metric, in which a program is considered as functionally correct if it passes all the test cases. A possible threat arises from the incompleteness of the test suite, which could potentially result in missed program bugs. In our experiments, we use the original test suite from LeetCode, which is carefully designed and widely recognized. Thus, we believe this risk is minimal. Another potential threat to construct validity comes from the variability in ChatGPT-generated code due to different prompts. To address this concern, we followed the similar methodology used by Fan~\ea~\cite{fan2022automated} and Tian~\ea~\cite{tian2023chatgpt}, which ensures that our results are reliable by using a consistent set of prompts across different tasks. However, it is important to note that prompt engineering can significantly influence the quality of the generated code. Future work could focus on optimizing the prompts to improve the accuracy and reliability of ChatGPT-generated code, thus enhancing the overall effectiveness of AI-driven code generation models.

% \kla{suggest to mention that different prompts may produce different code. this is one of the threats, but what have we done to ensure that the results are reliable? Probably, say we follow Fan et al [11]? Then, future work can focus on the prompt engineering may produce more accurate results, etc..}\yue{Added}

%\rw{maybe we can also mention that the ChatGPT evolves rapidly and we use the latest one?}