\section{Related work}
\label{sec:relatedwork}
In this section, we present related work and discuss the novelty of our work with respect to large language models for code generation and  code quality issues. 

\subsection{Large Language Model for Code Generation}
Large Language Models have been emerging as the state-of-the-art in code-related tasks, advancing the progress on program understanding~\cite{feng2020codebert, wang2021codet5}, analysis~\cite{kazerounian2021simtyper, le2022autopruner, thapa2022transformer}, and generation~\cite{chen2021evaluating, li2022competition, jain2022jigsaw}. Among these tasks, LLM-based code generation approaches are closely related to our study. The era of LLMs in code generation began with the introduction of CodeX~\cite{chen2021evaluating}, which serves as the backend for a well-known commercial tool, i.e., GitHub Copilot~\cite{githubcopilot}.
After the success of CodeX, various models such as InCoder~\cite{fried2022incoder}, Google Alphacode~\cite{li2022competition}, and Amazon CodeWhisperer~\cite{amazoncodewhisperer} have been emerging, resulting in remarkable improvements in the effectiveness of code generation. These advancements provide a new way of tackling the code generation problem. Recently, OpenAI introduced ChatGPT~\cite{chatgpt} a general AI-powered chatbot with remarkable capabilities in language understanding and human-like answering. ChatGPT has shown remarkable accuracy in generating code and solving programming problems while receiving positive feedback from users and gaining popularity. 
However, the quality of the ChatGPT-generated code is the critical concern for top software companies when deciding whether to adopt it in practice or not~\cite{chatgptconcern1, chatgptconcern2, chatgptconcern3}.

To the best of our knowledge, 
this paper is the first to systematically analyze and characterize the code quality issues in ChatGPT-generated code. By doing so, we hope to increase awareness about the quality issues in code generated by ChatGPT, and provide suggestions for mitigating the issues. 

\subsection{Code Quality Issues}

Code quality issues are the most important concern, as one quality issue (aka. software defect) could lead to monetary and reputation costs.
There is a large number of studies investigating code quality issues from human-written code.
For example, Kochhar~\ea~\cite{kochhar2016large} conducted a large-scale empirical investigation on the code quality of open-source projects implemented in 17 programming languages. 
Saboury~\ea~\cite{saboury2017empirical} empirically investigate code smells in 537 releases of five popular Javascript applications. 
Keuning~\ea~\cite{keuning2017code} investigate code quality issues in student programs. 

However, none of these studies focuses on the code quality issues for the AI-generated code, highlighting the difference between our paper and the literature on code quality issues.
% \kla{suggest cutting this subsection if the space is limited.}
% Different from these works, our study focuses on code generated by AI, which has recently shown great promise as a pair-programming tool for developers. 


\subsection{Code Quality Issues of AI-generated Code}

As AI-generated code becomes more prominent, researchers investigate the quality of code generated by CodeX and GitHub Copilot. 
For example, 
Nguyen~\ea~\cite{nguyen2022empirical} evaluated the performance of Copilot on 33 programming tasks. 
Fan~\ea~\cite{fan2022automated} further analyze common bugs in code generated by Codex, the backend of Copilot, on 113 programming tasks and benchmark automated program repair tools on fixing the mistakes.
However, these studies focus on CodeX and GitHub Copilot on a few programming tasks, leading to a lack of diversity. 
Different from these studies, we conduct a large-scale analysis on 2033 programming tasks, which enables us not only to comprehensively evaluate the effectiveness of AI-generated code but also to identify factors affecting their performance. 
Moreover, Nguyen~\ea~\cite{nguyen2022empirical} focus on analyzing the correctness of AI-generated code while Fan~\ea~\cite{fan2022automated} target to benchmark automated program repair tools on fixing mistakes. 
Our work, on the other hand, delves deeper into analyzing code quality issues, including code style \& maintainability issues, and highlights common patterns across different types of code quality problems.
Besides that, our study focuses on ChatGPT, a recently-introduced AI chatbot developed by OpenAI. Unlike Codex and GitHub Copilot, which target experienced professional developers and programmers, ChatGPT caters to a much wider audience, with approximately 1.6 billion visits in April 2023~\cite{chatgpttraffic}, including novice programmers and non-coders. Therefore, a comprehensive study on the reliability of source code generated by ChatGPT would not only provide valuable insights into the model but also raise awareness about the responsible usage of ChatGPT in code generation.
