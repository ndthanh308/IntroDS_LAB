%!TEX root = ../main.tex

\section{Related Work} % (fold)
\label{sec:related_work}

\subsection{Insect Monitoring} % (fold)
\label{sub:insect_monitoring}
In general, a commonly used method for monitoring insects is the usage of light traps.
Jonason~\etal~\cite{jonason2014lighttrap} presented a survey on the influence of weather, time of the year, and the type of the light source on the richness and abundance of species.
While the authors identified the moth species manually, some of the first automated species identification systems were presented by Watson~\etal~\cite{watson2004automated}, Mayo and Watson~\cite{mayo2007automatic}, and Batista~\etal~\cite{batista2010classification}.
All of these works used the same dataset, namely \num{35} species with \num{20} individuals per species.
Using support vector machines (SVMs) and nearest neighbor classifiers, they report an accuracy of up to~\pcent{85}~\cite{mayo2007automatic} with leave-one-out cross-validation.
Ding and Taylor~\cite{ding2016automatic} presented automated detection and classification of insect pests.
They used a sliding window approach coupled with a CNN model.
The CNN, followed by a non-maximum suppression as post-processing, performed a binary classification to identify a \emph{codling moth} in the windows.
They achieved an area under the precision-recall curve of \num{0.93}.
In contrast to these works, we perform the classification of much more classes, namely \num{200} moth species.

The works of Chang~\etal~\cite{chang2017fine} and Xia~\etal~\cite{xia2018insect} tackled more challenging classification tasks.
Using images from the Internet, they classified \num{636} and \num{24} species, respectively.
Chang~\etal achieved for the \num{450} butterflies and \num{186} moths species an accuracy of~\pcent{71.5} with a ResNet-18~\cite{resnet} architecture.
Xia~\etal performed a joint detection and classification of individual insects and achieved with their variant of a VGG-19 CNN a mean average precision (mAP) of~\pcent{89.22}.
First, we gather images in a more controlled environment.
As a result, the background is more homogeneous, and the moths are photographed from above in a resting position.
It is worth investigating how far the Internet images that do not represent our desired setup domain may enhance the classification performance.
Anyway, this is out of the scope of this paper.
Furthermore, unlike Xia~\etal, we aim to separate the detection and classification tasks since they will be performed on different physical devices in our setting.

Zhong~\etal~\cite{zhong2018vision} and Bjerge~\etal~\cite{bjerge2021automated} presented detection and classification pipelines deployed on embedded systems, namely on Raspberry Pi variants.
While Zhong~\etal used the YOLO framework~\cite{redmon2016you} for moth detection, Bjerge~\etal presented a detection-by-thresholding approach.
Zhong~\etal achieved a classification accuracy of~\pcent{90.2} for six species with an SVM and shallow features (texture, shape, color, and HOG features).
Bjerge~\etal presented their own CNN architecture and report an F1-score of~\pcent{93.00} for the classification of nine classes.
The authors perform additional counting and tracking of the insects, which is not part of this work.
Furthermore, we outperform the classification results presented by Bjerge~\etal in our experiments (Sect.~\ref{sub:results_on_mcc}).
% This paper focuses more on the detection and classification tasks rather than on the counting task.

% subsection biodiversity_monitoring (end)

\subsection{Object Detection} % (fold)
\label{sub:related:detection}
Pre-CNN image-based object detection was dominated by Deformable Part Model (DPM)~\cite{felzenszwalb2008dpm} and Selective Search~\cite{uijlings2013selective}.
The first approach uses a sliding window approach, whereas the latter uses region proposal selection as an object detection strategy.
After the rise of CNNs, region proposal methods are dominating the object detection research field.
One of the first was the R-CNN~\cite{girshick2014rcnn} that combined selective search region proposals with a CNN-based classification of these regions.
Many improvement and adaptations based on R-CNN were developed: SPPNet~\cite{he2015sppn}, Fast R-CNN~\cite{girshick2015fast}, MultiBox~\cite{erhan2014multibox}, or Faster R-CNN~\cite{fasterrcnn}.
Some of them improved the classification of the region proposals in quality and computation time~\cite{he2015sppn,girshick2015fast}.
Others improved the quality of the region proposals directly~\cite{erhan2014multibox,fasterrcnn}, especially with an integration of a region proposal CNN.
Some of the methods skip the proposal step and predict bounding boxes directly with the confidences for multiple categories.
Most popular examples are YOLO~\cite{redmon2016you}, OverFeat~\cite{sermanet2013overfeat}, and SSD~\cite{liu2016ssd}.
While OverFeat implements a deep version of the sliding window approach, YOLO uses CNN features to predict bounding boxes and categories.
SSD extracts features from multiple feature maps from multiple stages in the CNN and predicts bounding boxes based on a set of prior locations.

All of them have their advantages and disadvantages.
Meanwhile, there are also dozens of adaptations and improvements to these methods.
Nevertheless, in our work, we use the single-shot MultiBox detector (SSD) since it allows an exchange of the underlying backbone network and yields one of the best results on standard object detection benchmarks like Pascal VOC~\cite{pascal-voc-2007,pascal-voc-2012} and MS COCO~\cite{lin2014mscoco}.

% subsection object_detection (end)

\subsection{Fine-grained Classification} % (fold)
\label{sub:related:fgvc}
Fine-grained classification is a special classification task, where the categories, which need to be classified, originate from the same object domain (e.g., bird species~\cite{WahCUB_200_2011}, car models~\cite{StanfordCars}, moth species~\cite{Rodner15:FRD}, or elephant individuals~\cite{Koerschens19:ELPephants}).
The challenge is now to distinguish closely related classes that differ only in subtle features.
In the age of CNNs, it is common to use the data and let the network figure out what are relevant visual features that distinguish a class from the others.
This kind of approach utilizes the input image as it is and performs either smart pre-training strategies~\cite{Cui_2018_CVPR_large,krause2016unreasonable} or advanced feature aggregation techniques~\cite{lin2015bilinear,Simon19:Implicit}.
On the other hand, there are the part- or attention-based approaches~\cite{ge2019weakly,he2019and,zhang2019learning} that extract relevant regions already at the pixel level and use cropped image regions as additional features for the classification.
Both classification strategies have their advantages and drawbacks.
We use an unsupervised approach for part estimation proposed by Korsch~\etal~\cite{Korsch19_CSPARTS} within our pipeline.

% However, in this work, we concentrate on the detection task first.
% Without any doubt, an important step is to evaluate the best classification strategy in the context of moth species.
% Anyways, we employ a straight forward global-based classification approach for now.
