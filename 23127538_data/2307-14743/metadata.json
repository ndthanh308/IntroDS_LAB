{
  "title": "Turning Whisper into Real-Time Transcription System",
  "authors": [
    "Dominik Macháček",
    "Raj Dabre",
    "Ondřej Bojar"
  ],
  "submission_date": "2023-07-27T10:00:05+00:00",
  "revised_dates": [
    "2023-09-21T09:41:17+00:00"
  ],
  "abstract": "Whisper is one of the recent state-of-the-art multilingual speech recognition and translation models, however, it is not designed for real time transcription. In this paper, we build on top of Whisper and create Whisper-Streaming, an implementation of real-time speech transcription and translation of Whisper-like models. Whisper-Streaming uses local agreement policy with self-adaptive latency to enable streaming transcription. We show that Whisper-Streaming achieves high quality and 3.3 seconds latency on unsegmented long-form speech transcription test set, and we demonstrate its robustness and practical usability as a component in live transcription service at a multilingual conference.",
  "categories": [
    "cs.CL"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14743",
  "pdf_url": "https://arxiv.org/pdf/2307.14743v2",
  "comment": "IJCNLP-AACL 2023 system demonstration",
  "num_versions": null,
  "size_before_bytes": 274253,
  "size_after_bytes": 134515
}