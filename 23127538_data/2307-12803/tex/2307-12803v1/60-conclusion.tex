\section{Conclusion}
In this work, we revisited guided abstractive summarization of radiology reports.
We demonstrated that extractive summaries can be an effective guidance signal for the task, if we allow the length of this guidance signal to vary across reports, and thereby make the gap between domain-agnostic and domain-specific guidance smaller.
Furthermore, through a fine-grained error analysis of unguided and guided models we found that guidance successfully steers the content of summaries but that significant deficits in content selection persist.

We hope that this paper motivates future efforts on content selection mechanisms for radiology report summarization, their evaluation in other domains and languages, and on more comprehensive evaluation suites. We release our error annotations which can serve as a starting point for evaluating the efficacy of metrics in capturing these errors.
