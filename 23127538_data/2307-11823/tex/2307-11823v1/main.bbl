\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{benz2021robustness}
Philipp Benz, Chaoning Zhang, Soomin Ham, Adil Karjauv, and In~So Kweon.
\newblock Robustness comparison of vision transformer and mlp-mixer to cnns.
\newblock In {\em CVPR 2021 Workshop on Adversarial Machine Learning in
  Real-World Computer Vision Systems and Online Challenges (AML-CV)}, volume~7,
  2021.

\bibitem{Benz_2021_WACV}
Philipp Benz, Chaoning Zhang, Adil Karjauv, and In~So Kweon.
\newblock Revisiting batch normalization for improving corruption robustness.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision (WACV)}, pages 494--503, January 2021.

\bibitem{borkar2020defending}
Tejas Borkar, Felix Heide, and Lina Karam.
\newblock Defending against universal attacks through selective feature
  regeneration.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 709--719, 2020.

\bibitem{calian2022defending}
Dan~Andrei Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi,
  Andr{\'a}s Gy{\"o}rgy, Timothy~A Mann, and Sven Gowal.
\newblock Defending against image corruptions through adversarial
  augmentations.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. Ieee, 2017.

\bibitem{chan2022does}
Alvin Chan, Yew-Soon Ong, and Clement Tan.
\newblock How does frequency bias affect the robustness of neural image
  classifiers against common corruption and adversarial perturbations?
\newblock {\em arXiv preprint arXiv:2205.04533}, 2022.

\bibitem{chen2021amplitude}
Guangyao Chen, Peixi Peng, Li Ma, Jia Li, Lin Du, and Yonghong Tian.
\newblock Amplitude-phase recombination: Rethinking robustness of convolutional
  neural networks in frequency domain.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 458--467, 2021.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em International conference on machine learning}, pages
  2206--2216. PMLR, 2020.

\bibitem{cubuk2018autoaugment}
Ekin~D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc~V Le.
\newblock Autoaugment: Learning augmentation policies from data.
\newblock {\em arXiv preprint arXiv:1805.09501}, 2018.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{deng2020analysis}
Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, and Miryung Kim.
\newblock An analysis of adversarial attacks and defenses on autonomous driving
  models.
\newblock In {\em 2020 IEEE international conference on pervasive computing and
  communications (PerCom)}, pages 1--10. IEEE, 2020.

\bibitem{devries2017improved}
Terrance DeVries and Graham~W Taylor.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock {\em arXiv preprint arXiv:1708.04552}, 2017.

\bibitem{geirhos2018imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock {\em arXiv preprint arXiv:1811.12231}, 2018.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{shapebias_corruption}
Shruthi Gowda, Bahram Zonooz, and Elahe Arani.
\newblock Inbiased: Inductive bias distillation to improve generalization and
  robustness through shape-awareness, 2022.

\bibitem{subnet_enhance}
Yong Guo, David Stutz, and Bernt Schiele.
\newblock Improving robustness by enhancing weak subnets, 2022.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8340--8349, 2021.

\bibitem{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock {\em arXiv preprint arXiv:1903.12261}, 2019.

\bibitem{hendrycks2016baseline}
Dan Hendrycks and Kevin Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock {\em arXiv preprint arXiv:1610.02136}, 2016.

\bibitem{hendrycks2019augmix}
Dan Hendrycks, Norman Mu, Ekin~D Cubuk, Barret Zoph, Justin Gilmer, and Balaji
  Lakshminarayanan.
\newblock Augmix: A simple data processing method to improve robustness and
  uncertainty.
\newblock {\em arXiv preprint arXiv:1912.02781}, 2019.

\bibitem{Hendrycks_2022_CVPR}
Dan Hendrycks, Andy Zou, Mantas Mazeika, Leonard Tang, Bo Li, Dawn Song, and
  Jacob Steinhardt.
\newblock Pixmix: Dreamlike pictures comprehensively improve safety measures.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 16783--16792, June 2022.

\bibitem{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708, 2017.

\bibitem{kar20223d}
O{\u{g}}uzhan~Fatih Kar, Teresa Yeo, Andrei Atanov, and Amir Zamir.
\newblock 3d common corruptions and data augmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18963--18974, 2022.

\bibitem{khosla2020supervised}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip
  Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:18661--18673, 2020.

\bibitem{adversarialtraining_corruption}
Klim Kireev, Maksym Andriushchenko, and Nicolas Flammarion.
\newblock On the effectiveness of adversarial training against common
  corruptions.
\newblock In James Cussens and Kun Zhang, editors, {\em Proceedings of the
  Thirty-Eighth Conference on Uncertainty in Artificial Intelligence}, volume
  180 of {\em Proceedings of Machine Learning Research}, pages 1012--1021.
  PMLR, 01--05 Aug 2022.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{krizhevsky2017imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Communications of the ACM}, 60(6):84--90, 2017.

\bibitem{Lee_2020_CVPR_Workshops}
Jin-Ha Lee, Muhammad~Zaigham Zaheer, Marcella Astrid, and Seung-Ik Lee.
\newblock Smoothmix: A simple yet effective data augmentation to train robust
  classifiers.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops}, June 2020.

\bibitem{li2020wavelet}
Qiufu Li, Linlin Shen, Sheng Guo, and Zhihui Lai.
\newblock Wavelet integrated cnns for noise-robust image classification.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7245--7254, 2020.

\bibitem{li2022robust}
Zhe Li, Josue~Ortega Caro, Evgenia Rusak, Wieland Brendel, Matthias Bethge,
  Fabio Anselmi, Ankit~B Patel, Andreas~S Tolias, and Xaq Pitkow.
\newblock Robust deep learning object recognition models rely on low frequency
  information in natural images.
\newblock {\em bioRxiv}, 2022.

\bibitem{liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 10012--10022, 2021.

\bibitem{long2022frequency}
Yuyang Long, Qilong Zhang, Boheng Zeng, Lianli Gao, Xianglong Liu, Jian Zhang,
  and Jingkuan Song.
\newblock Frequency domain model augmentation for adversarial attack.
\newblock In {\em European Conference on Computer Vision}, pages 549--566.
  Springer, 2022.

\bibitem{eccv2022_freqpaper}
Yuyang Long, Qilong Zhang, Boheng Zeng, Lianli Gao, Xianglong Liu, Jian Zhang,
  and Jingkuan Song.
\newblock Frequency domain model augmentation for adversarial attack.
\newblock In Shai Avidan, Gabriel Brostow, Moustapha Ciss{\'e}, Giovanni~Maria
  Farinella, and Tal Hassner, editors, {\em Computer Vision -- ECCV 2022},
  pages 549--566, Cham, 2022. Springer Nature Switzerland.

\bibitem{lu2017safetynet}
Jiajun Lu, Theerasit Issaranon, and David Forsyth.
\newblock Safetynet: Detecting and rejecting adversarial examples robustly.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 446--454, 2017.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}, 2017.

\bibitem{meng2017magnet}
Dongyu Meng and Hao Chen.
\newblock Magnet: a two-pronged defense against adversarial examples.
\newblock In {\em Proceedings of the 2017 ACM SIGSAC conference on computer and
  communications security}, pages 135--147, 2017.

\bibitem{mintun2021interaction}
Eric Mintun, Alexander Kirillov, and Saining Xie.
\newblock On interaction between augmentations and corruptions in natural
  corruption robustness.
\newblock {\em Advances in Neural Information Processing Systems},
  34:3571--3583, 2021.

\bibitem{prime_aug}
Apostolos Modas, Rahul Rade, Guillermo Ortiz-Jim{\'e}nez, Seyed-Mohsen
  Moosavi-Dezfooli, and Pascal Frossard.
\newblock Prime: A few primitives can boost robustness to common corruptions.
\newblock In Shai Avidan, Gabriel Brostow, Moustapha Ciss{\'e}, Giovanni~Maria
  Farinella, and Tal Hassner, editors, {\em Computer Vision -- ECCV 2022},
  pages 623--640, Cham, 2022. Springer Nature Switzerland.

\bibitem{mok2021advrush}
Jisoo Mok, Byunggook Na, Hyeokjun Choe, and Sungroh Yoon.
\newblock Advrush: Searching for adversarially robust neural architectures.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 12322--12332, 2021.

\bibitem{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2574--2582, 2016.

\bibitem{mu2019mnist}
Norman Mu and Justin Gilmer.
\newblock Mnist-c: A robustness benchmark for computer vision.
\newblock {\em arXiv preprint arXiv:1906.02337}, 2019.

\bibitem{mukai2022improving}
Koki Mukai, Soichiro Kumano, and Toshihiko Yamasaki.
\newblock Improving robustness to out-of-distribution data by frequency-based
  augmentation.
\newblock In {\em 2022 IEEE International Conference on Image Processing
  (ICIP)}, pages 3116--3120. IEEE, 2022.

\bibitem{netzer2011reading}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem{oliva2006hybrid}
Aude Oliva, Antonio Torralba, and Philippe~G Schyns.
\newblock Hybrid images.
\newblock {\em ACM Transactions on Graphics (TOG)}, 25(3):527--532, 2006.

\bibitem{rosenberg2021adversarial}
Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, and Lior Rokach.
\newblock Adversarial machine learning attacks and defense methods in the cyber
  security domain.
\newblock {\em ACM Computing Surveys (CSUR)}, 54(5):1--36, 2021.

\bibitem{ant_corruption}
Evgenia Rusak, Lukas Schott, Roland~S. Zimmermann, Julian Bitterwolf, Oliver
  Bringmann, Matthias Bethge, and Wieland Brendel.
\newblock A simple way to make neural networks robust against diverse image
  corruptions.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm,
  editors, {\em Computer Vision -- ECCV 2020}, pages 53--69, Cham, 2020.
  Springer International Publishing.

\bibitem{Saikia_2021_ICCV}
Tonmoy Saikia, Cordelia Schmid, and Thomas Brox.
\newblock Improving robustness against common corruptions with frequency biased
  models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 10211--10220, October 2021.

\bibitem{salman2020adversarially}
Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry.
\newblock Do adversarially robust imagenet models transfer better?
\newblock {\em Advances in Neural Information Processing Systems},
  33:3533--3545, 2020.

\bibitem{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\bibitem{shaham2018defending}
Uri Shaham, James Garritano, Yutaro Yamada, Ethan Weinberger, Alex Cloninger,
  Xiuyuan Cheng, Kelly Stanton, and Yuval Kluger.
\newblock Defending against adversarial images using basis functions
  transformations.
\newblock {\em arXiv preprint arXiv:1803.10840}, 2018.

\bibitem{springenberg2014striving}
Jost~Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin
  Riedmiller.
\newblock Striving for simplicity: The all convolutional net.
\newblock {\em arXiv preprint arXiv:1412.6806}, 2014.

\bibitem{frequencyaug_competitor_method}
Jiachen Sun, Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen, Dan Hendrycks, Jihun
  Hamm, and Z.~Morley Mao.
\newblock A spectral view of randomized smoothing under common corruptions:
  Benchmarking and improving certified robustness.
\newblock In Shai Avidan, Gabriel Brostow, Moustapha Ciss{\'e}, Giovanni~Maria
  Farinella, and Tal Hassner, editors, {\em Computer Vision -- ECCV 2022},
  pages 654--671, Cham, 2022. Springer Nature Switzerland.

\bibitem{Sun_2021_ICCV}
Mingjie Sun, Zichao Li, Chaowei Xiao, Haonan Qiu, Bhavya Kailkhura, Mingyan
  Liu, and Bo Li.
\newblock Can shape structure features improve model robustness under diverse
  adversarial settings?
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 7526--7535, October 2021.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{tack2020csi}
Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin.
\newblock Csi: Novelty detection via contrastive learning on distributionally
  shifted instances.
\newblock {\em Advances in neural information processing systems},
  33:11839--11852, 2020.

\bibitem{wang2020high}
Haohan Wang, Xindi Wu, Zeyi Huang, and Eric~P Xing.
\newblock High-frequency component helps explain the generalization of
  convolutional neural networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8684--8694, 2020.

\bibitem{wang2021augmax}
Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima Anandkumar, and
  Zhangyang Wang.
\newblock Augmax: Adversarial composition of random augmentations for robust
  training.
\newblock In A. Beygelzimer, Y. Dauphin, P. Liang, and J.~Wortman Vaughan,
  editors, {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{wang2020towards}
Zifan Wang, Yilin Yang, Ankit Shrivastava, Varun Rawal, and Zihao Ding.
\newblock Towards frequency-based explanation for robust cnn.
\newblock {\em arXiv preprint arXiv:2005.03141}, 2020.

\bibitem{wong2020fast}
Eric Wong, Leslie Rice, and J~Zico Kolter.
\newblock Fast is better than free: Revisiting adversarial training.
\newblock {\em arXiv preprint arXiv:2001.03994}, 2020.

\bibitem{xie2017aggregated}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1492--1500, 2017.

\bibitem{xu2017feature}
Weilin Xu, David Evans, and Yanjun Qi.
\newblock Feature squeezing: Detecting adversarial examples in deep neural
  networks.
\newblock {\em arXiv preprint arXiv:1704.01155}, 2017.

\bibitem{yang2021generalized}
Jingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei Liu.
\newblock Generalized out-of-distribution detection: A survey.
\newblock {\em arXiv preprint arXiv:2110.11334}, 2021.

\bibitem{Yeo_2021_ICCV}
Teresa Yeo, O\u{g}uzhan~Fatih Kar, and Amir Zamir.
\newblock Robustness via cross-domain ensembles.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 12189--12199, October 2021.

\bibitem{yin2019fourier}
Dong Yin, Raphael Gontijo~Lopes, Jon Shlens, Ekin~Dogus Cubuk, and Justin
  Gilmer.
\newblock A fourier perspective on model robustness in computer vision.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{yu2015lsun}
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong
  Xiao.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock {\em arXiv preprint arXiv:1506.03365}, 2015.

\bibitem{yucel2020deep}
Mehmet~Kerim Yucel, Ramazan~Gokberk Cinbis, and Pinar Duygulu.
\newblock A deep dive into adversarial robustness in zero-shot learning.
\newblock In {\em European Conference on Computer Vision}, pages 3--21.
  Springer, 2020.

\bibitem{yucel2022robust}
Mehmet~Kerim Yucel, Ramazan~Gokberk Cinbis, and Pinar Duygulu.
\newblock How robust are discriminatively trained zero-shot learning models?
\newblock {\em Image and Vision Computing}, 119:104392, 2022.

\bibitem{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6023--6032, 2019.

\bibitem{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock {\em arXiv preprint arXiv:1605.07146}, 2016.

\bibitem{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock {\em arXiv preprint arXiv:1710.09412}, 2017.

\bibitem{zhang2020geometry}
Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, and Mohan
  Kankanhalli.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock {\em arXiv preprint arXiv:2010.01736}, 2020.

\bibitem{zhang2019making}
Richard Zhang.
\newblock Making convolutional networks shift-invariant again.
\newblock In {\em International conference on machine learning}, pages
  7324--7334. PMLR, 2019.

\end{thebibliography}
