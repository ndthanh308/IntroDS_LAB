%!TEX root = MST_brownian.tex

In this section, we prove the compactness of $\CMT(X,\bU)$ constructed in Section~\ref{sub:recursive_convex_minorants_BPT}. The completeness is plain from the definition and we only need to verify that $(\sM,d)$ is totally bounded.

We will proceed by controlling the growth of a well-chosen sequence of subspaces that increase to $\sM$ using a chaining argument. This leads us to a process that is reminiscent to a certain version of Prim's exploration at the discrete level, and that also turns out to be crucial in the calculation of the Hausdorff dimension (see Section~\ref{sec:mass_hausdorff}). The general strategy is inspired from the arguments of \citet{CuHa2017a} for the compactness of trees constructed by aggregation of segments. 

\subsection{The growth process} % (fold)
\label{sub:the_growth_process}

In the entire section, we consider the process $X$, and the random variables $Z^\lambda=Z^\lambda(X)$ refer to this case. We may see the metric space $(\sM,d)$ as obtained from the coalescent process induced by $Z^\lambda$ on $\R_+$, which turns out to be the standard multiplicative coalescent \cite{BrMa2015a,Armendariz2001}. In this process, fragments only merge by pairs, but obtaining fine quantitative estimates is delicate since for any $\lambda \in \R$ and $h>0$, $Z^{\lambda}\setminus Z^{\lambda+h}$ is a.s.\ not contained in any compact interval. We shall thus track a single connected component as $\lambda$ increases.

\begin{rem}The most natural choice of a connected component to track is the largest one, but this leads to some inconvenient conditioning. One could also track a connected component containing a fixed point (at the discrete level), but, without any additional structure, such a node must be uniformly random, and thus the corresponding component would be too small to lead to anything interesting. Here, the structure imposed by the representation on $\R_+$ allows us to track any fixed point \emph{among the ones that do matter} even though they are a negligible for the mass measure (that is, the nodes $v_i$ for $\epsilon n^{2/3}\le i \le C n^{2/3}$ for constants $0<\epsilon<C$).
\end{rem}


For each $\lambda\in \R$, let $L_\lambda=\sup Z^\lambda \cap [0, 1)$ and $R_\lambda= \inf Z^\lambda \cap (1,\infty)$, and define $H_\lambda=[L_\lambda, R_\lambda)$. So, up to inclusion of the left-most point, $H_\lambda\subseteq \R_+$ is the interval of $\R_+\setminus Z^\lambda$ which contains the point~$1$; since $1\not\in \bigcup_\lambda Z^\lambda$ with probability one, this is well-defined for all $\lambda\in \R$. 
We have the following asymptotics, whose proofs are found in Section~\ref{sub:the_position_of_the_connected_component}.


\begin{lem}\label{lem:position_Hlambda}
There exist constant $c>0$ and $x_0,\lambda_0$ such that, for all $x>x_0$ and $\lambda\ge \lambda_0$ we have 
\[\pc{L_\lambda \ge \tfrac x {\lambda^2}} \le e^{-cx}
\qquad \text{and} \qquad \pc{|R_\lambda-2\lambda| > 1} \le e^{-c\lambda}\,.\]
\end{lem}

It follows that $H_\lambda \uparrow (0,\infty)$ as $\lambda \to \infty$, so that $H_\lambda$ provides a suitable increasing family of subspaces of $\sM$.
So for any $x\in \R_+\setminus \{0,1\}$, we let $\lambda(x) = \inf\{\lambda: x\in H_\lambda\}$ be the time at which $x$ joins the connected component containing $1$. The intervals that join $H_\lambda$ play a different role depending on whether they lie to the left or to the right, and we define $\Lambda^\ssp=\{\lambda \in \R: R_\lambda> R_{\lambda-}\}$ and $\Lambda^\ssm:=\{\lambda \in \R: L_\lambda<L_{\lambda-}\}$; then $\Lambda^\ssp$ and $\Lambda^\ssm$ are both countable. Furthermore, they are almost surely disjoint; this is because the standard multiplicative coalescent is binary \cite{Aldous1997}, and could also be proved directly from the representation with $X$ (see the proof of Proposition~\ref{prop:large_merges}). We let $\Lambda=\Lambda^\ssp\cup \Lambda^\ssm$. 

For $x,y\in \R_+$, we let $x\leftrightarrow y$ if $\lambda(x)=\lambda(y)$, and let $q_\lambda$, $\lambda \in \Lambda$, be the equivalence classes of this relation. For $\lambda\in \Lambda^\ssm$, we have $q_\lambda=[L_\lambda, L_{\lambda-})$, while $q_\lambda=[R_{\lambda-}, R_\lambda)$ for $\lambda\in \Lambda^\ssp$. Because of this, $(q_\lambda)_{\lambda\in \Lambda^\ssm}$ and $(q_\lambda)_{\lambda\in \Lambda^\ssp}$ respectively define partitions of $(0,1)$ and $(1,\infty)$ into countably many disjoint intervals. 
%\JF{y a du flou autour du fait que les $q_{\lambda}$ sont ouverts/fermés, d'un coté ou de l'autre. Est-ce une partition, ou une partition qui évite les points de $\cup Z^\lambda$? Le truc qui n'est pas bien clair, c'est que vaut $\lambda(x)$ lorsque $x$ est l'un des points de $\cup Z^\lambda$ (un des points de sauts de $H_{\lambda}$). Ce que je comprends, c'est que la définition de $\lambda(x)$ avec l'inf pousse à définir différemment qui est dans $q_{\lambda}$ différemment à droite et à gauche de 1; mais je crois que du coup, c'est la même remarque que la précédente, où je dis que je ne comprends pas.}.

For an interval $I\subset \R_+$, we let $\sM|_I$ be the \emph{intrinsic} metric space induced by $d$ on $I$: this is the metric space $(I,d_I)$ where $d_I(x,y)=d(x,y)$ if $\llb x,y\rrb \subseteq I$ and $d_I(x,y)=+\infty$ otherwise. So in general, $\sM|_I$ might be disconnected. Let $\sM_\lambda:=\sM|_{H_\lambda}$; then $\sM_\lambda$ is connected for all $\lambda\in \R$. For $\lambda\in \Lambda^\ssp$ (resp.\ $\Lambda^\ssm$), we also let $\sT^\tsp_\lambda:=\sM|_{q_\lambda}$ (resp.\ $\sT_\lambda^\tsm:=\sM_{q_\lambda}$). Quite plainly, and up to the metric completion, the metric space $\sM$ is obtained by combining the $\sT^\tsp_\lambda$, $\lambda\in \Lambda^\ssp$, and $\sT^\tsm_\lambda, \lambda\in \Lambda^\ssm$, using the identifications performed during the construction (using the random points constructed from $\bU$). This process actually turns out rather agreeable: the metric spaces $\sT^\tsp_\lambda$ and $\sT^\tsm_\lambda$ are easy to understand because they are small as $\lambda \to \infty$, and the way they are put together is also easy to control. Informally, the dynamics as $\lambda$ increases are as follows: 
\begin{itemize}
	\item at time $\lambda\in \Lambda^\ssp$, $\sT^\tsp_\lambda$ merges with $\sM_{\lambda-}$ by identifying $\inf q_\lambda$ with a uniform point in $H_{\lambda-}$;
	\item at time $\lambda\in \Lambda^\ssm$, $\sM_{\lambda-}$ connects with $\sT^\tsm_\lambda$ by identifying $L_{\lambda-}$ with a uniform point in $\sT^\tsm_\lambda$.  
\end{itemize}

The $(\sM_{k^3})_{k\ge 1}$ is the convenient sequence of subspaces of $\sM$ that we mentioned before. The following decomposition which takes advantage of these dynamics will be useful. What matters for now is the global picture, we will fill out the details later on.
\begin{itemize}
	\item \emph{The annuli of forests to the right.} 
	For any $k\ge 1$ define $\Lambda_k:=\{\lambda \in \Lambda^\ssp: k^3<\lambda \le (k+1)^3\}$, and let $\sF_k$ be the intrinsic metric space induced by $\sM$ on $(R_{k^3}, R_{(k+1)^3}]$. For each $k\ge 1$, $\sF_k$ is a forest consisting of  infinitely many connected components obtained when only the identifications within $(R_{k^3},R_{(k+1)^3}]$ are performed. Our aim is to bound the maximum diameter of the connected component $\sF_k$ in order to control the worst case accumulation of length when putting all the $\sF_k$ together. Formally, for $\lambda,\lambda'\in \Lambda_k$ we write $\lambda \equiv_k \lambda'$ if $R_{\lambda-}\wedge R_{\lambda'-} > R_{k^3}$, which implies that $\sT_\lambda^\tsp$ and $\sT_{\lambda'}^\tsp$ are connected within $\sF_k$. We will prove that, almost surely, every equivalence class of this relation is finite. So for each $\lambda\in \Lambda_k$, we may define $\rho_\lambda:=\min\{R_{\lambda'-}: \lambda' \equiv_k \lambda\}$ as the leftmost point of the connected component containing $\sT^\tsp_\lambda$ within $\sF_k$. More generally, the equivalence relation $\equiv_k$ naturally extends as follows: for $x,y\in (R_{k^3}, R_{(k+1)^3}]$ we let $x\sim_k y$ if $x\in q_\lambda$, $y\in q_{\lambda'}$ and $\lambda \equiv_k \lambda'$. Defining the diameter of a potentially disconnected metric space as the supremum of the diameters of its connected components, we therefore have $\diam(\sF_k)=\sup\{d(x,y): x,y\in (R_{k^3},R_{(k+1)^3}], x\equiv_k y\}$. 
 
	\item \emph{The chain of beads to the origin.} For any $\lambda\in \R$, we let $\sP_\lambda$ denote the intrinsic metric space induced by $\sM$ on $[0,L_\lambda)$. This metric is almost surely connected and has the structure of a ``string of beads'' that we now describe. For $a\in \R$, let $\Lambda_a^\ssm:=\Lambda^\ssm\cap (a,\infty)$.
	Almost surely for any $a\in \R$, $\Lambda^\ssm_a$ only contains finitely many points in any compact interval of $(0,+\infty)$, so that we may enumerate its elements in increasing order as $(\lambda_i)_{i\ge 1}$ (Lemma~\ref{lem:no_exception_convex}). 
	The metric space $\sP_\lambda$ is obtained by putting together the metric spaces $\sT^\tsm_{\lambda_j}$, $j\ge 1$, into a chain by connecting $\sT^\tsm_{\lambda_i}$ to a uniform random point in $\sT^\tsm_{\lambda_{i+1}}$ for each $i\ge 1$.  
\end{itemize}

By giving an estimate of the extent of $H_\lambda$, Lemma~\ref{lem:position_Hlambda} provides an effective way to control the locations of the ``gluing points'' which lies at the core of the proofs of the compactness and of the computation of the Hausdorff dimensions. The contribution of $\sP_\lambda$ is easily treated separately, and the crucial steps consists in controlling the diameters of the $\sF_k$, $k\ge 1$. 

\begin{prop}[Diameter of annuli forests]\label{pro:bound_annulus}There exists $k_0\in \N$ such that for all $k\ge k_0$ we have
\[\p{ \diam(\sF_k) > k^{-3/2}} \le 11 k^{-5/4}\,.\]
\end{prop}

\begin{prop}[Diameter of the string of beads]\label{pro:left-end}Almost surely, 
 \[\lim_{\lambda \to \infty }\diam(\sP_\lambda) = 0\,.\]
\end{prop}

Taking Propositions~\ref{pro:bound_annulus} and~\ref{pro:left-end} for granted for now, the proof of compactness is then straightforward. 

% The argument for the compactness will go essentially as follows ({\red careful with the conditioning, this is not quite true})
% \begin{itemize}
% 	\item For any fixed $\lambda$, the law of excursion of $X^\lambda$ above the interval $H_\lambda$ is absolutely continuous with respect to that of a Brownian excursion, and thus the corresponding space $(H_\lambda, d_\lambda)$ is totally bounded with probability one. 
% 	\item As $\lambda$ increases, some pieces are glued onto $H_\lambda$; when $\lambda$ is large, these pieces are all small $(|Q|\to 0$ as $\inf Q\to \infty$) and their diameter behaves like the square root of the mass, times an independent random variable that has Gaussian tails that is $D_Q:=\sup\{d(x,y):x,y\in Q\}$ can be written as $|Q|^{1/2}\cdot R_Q$. 
% \end{itemize}

% We will decompose the collection of intervals $Q$ to the right of $H^\star$ as follows. Fix some $\alpha>0$ to be chosen later. 
% \begin{itemize}
% 	\item For each $k$, we will consider the intervals $Q$ for which $\inf Q \in [k^\alpha, (k+1)^\alpha]$
% 	\item For all these $Q$, $\lambda_Q$ is roughly $k^\alpha/2$ and we can compare the collection of lengths of these intervals with the lengths of excursions above of a Brownian motion with linear drift above its minimum. 
% 	\item For each $k$, we will bound the maximal contribution of $[k^\alpha,(k+1)^\alpha]$ to any path towards $H^\star$; since there are infinitely many intervals, this will require to further decompose the intervals according to their lengths.
% \end{itemize}

% \begin{alert}Compactness comes from the behaviour of the intervals at $+\infty$, and the Hausdorff dimension (mostly) from the behaviour at $0$. The behaviour at infinity is treated "by hand", and the behaviour at zero by comparision with the convex minorant of a BM. Then, we need something saying that for any $x,y$ if we look at the processes of additions of connected components containing $x$ and $y$ respectively, they are equal from some time on (basically, the time for $x$ and $y$ to merge). We need that for the "largest", with tail bounds to compare $H_\lambda$ with something unconditioned.
% \end{alert}
 
\begin{prop}[Compactness of $\sM$]\label{pro:space_compact}The metric space $(\sM,d)$ is almost surely compact.
\end{prop}
\begin{proof}By Proposition~\ref{pro:bound_annulus} and the Borel--Cantelli lemma, with probability one, there exists an almost surely finite random variable $K$ such that $\diam(\sF_k)\le k^{-3/2}$ for all $k\ge K$. In particular, for all $k\ge K$, 
\[\dH(\sM_{k^3}, \sM) \le 2 k^{-1/2} + \diam(\sP_{k^3})\,.\]
Fix any $\epsilon>0$. By Proposition~\ref{pro:left-end}, $\diam(\sP_{k^3})<\epsilon/3$ for all $k$ large enough; it follows that there exists $k\ge K$ large enough such that $\dH(\sM_{k^3}, \sM)< \epsilon/2$. Recall that, for any fixed $\lambda\in \R$, the restriction $\sM_\lambda$ of $\sM$ to $H_\lambda$ is almost surely compact by absolute continuity with the Brownian continuum random tree. So there exists a cover of $\sM_{k^3}$ by finitely many balls of radius $\epsilon/2$; increasing the radius of each ball to $\epsilon$ yields a finite cover of $\sM$. We have thus proved that $\sM$ is totally bounded. Since it is complete by definition, it is compact.
 \end{proof} 
 
The remainder of the section is devoted to the proof of Propositions~\ref{pro:bound_annulus} and~\ref{pro:left-end}. We first prove Lemma~\ref{lem:position_Hlambda} in Section~\ref{sub:the_position_of_the_connected_component}. The forests $\sF_k$ are made of the trees $\sT^\tsp_\lambda$, for $\lambda\in \Lambda_k$. For all $k\ge 1$, $\Lambda_k$ is infinite, which causes some difficulties. Still, we expect that, for large $k$, the components $\sT_\lambda^\tsp$ with $\lambda \in \Lambda_k$ should be rather small; Section~\ref{sub:distances_in_swallowed_components} deals with the question of uniform bounds on distances in the $\sT^\tsp_\lambda$ in terms of the lengths $|q_\lambda|$. We then obtain in Section~\ref{sub:statistics_small_components} the relevant statistics about the connected components $\sT_\lambda^\tsp$ for $\lambda\in \Lambda_k$ which includes information about the lengths $|q_\lambda|$ and  their diameters. In Section~\ref{sub:contribution_of_intervals} we put together all the pieces and prove Proposition~\ref{pro:bound_annulus} which essentially says that the diameter of $\sF_k$ is comparable to the maximum diameter of the $\sT_\lambda^\tsp$, $\lambda \in \Lambda_k$. Finally, we prove Propostition~\ref{pro:left-end} in Section~\ref{sub:string_of_beads}.

\subsection{The position of the component containing $1$: Proof of Lemma~\ref{lem:position_Hlambda}} % (fold)
\label{sub:the_position_of_the_connected_component}

Recall that for a continuous process $\omega = (\omega_t)_{t\ge 0}$, we let $\underline \omega$ and $\overline \omega$ denote respectively the running infimum and supremum processes: $\underline \omega_t :=\inf\{\omega_s : 0\le s\le t\}$ and $\overline \omega_t = \sup\{\omega_t: 0\le s \le t\}$. 

Recall that $(W_t)_{t\ge 0}$ denotes a standard Brownian motion. We will use repeatedly the following simple fact (see, e.g., \cite{KaSh1988} page 96, consequence of the fact that $\overline W_t$ has same law as $|W_t|$, for a fixed $t$): for all $x\ge 0$, we have
\begin{equation}\label{eq:tail_max_bm}
\pc{\overline W_t \ge x} = \pc{\underline{W\!}_t \le -x }\le e^{-x^2/(2t)}\,.
\end{equation}

Let $\lambda\ge 0$. Let us first focus on the upper bound. For any $t\in \R_+$, we have $R_\lambda > t$ if only if there is an excursion of $X^\lambda$ above its running minimum that straddles both $1$ and $t$, that is if $1\sim_\lambda t$. Thus
\begin{align}\label{eq:re-upper-bound1}
\pc{R_\lambda > 2\lambda +1} 
& = \pc{\underline{X}_1^\lambda = \underline X_{2\lambda+1}^\lambda} \notag \\
& = \pc{\underline{X}_1^\lambda \le \underline{X}_{2\lambda+1}^\lambda} \notag \\ 
%& \le \inf_x \{\pc{\underline{X}_1^\lambda \le x} + \pc{\underline{X}_1^\lambda\le \underline{X}_{2\lambda+1}^\lambda, \underline{X}_1^\lambda > x}\} \notag \\ 
& \le \inf_x \{\pc{\underline{X}_1^\lambda \le x} + \pc{\underline{X}_{2\lambda+1}^\lambda > x}\}\,.
\end{align}
A quick inspection of the expected values leads to the choice $x=-\tfrac \lambda 2$. On the one hand $\underline{X}_1^\lambda \ge -\frac 1 2 + \underline{W\!}_1$ so that, by \eqref{eq:tail_max_bm}, we obtain
\begin{align}\label{eq:re-upper-bound2}
\pc{\underline{X\!}^\lambda_1 \le -\tfrac \lambda 2}
 \le \pc{-\tfrac 12 + \underline{W}_1\le -\tfrac \lambda 2}
%\le e^{-(\lambda-1)^2/8} 
\le e^{-\lambda^2/9}\,,
\end{align}
for all $\lambda$ large enough. On the other hand, $\underline{X}_{2\lambda+1}^\lambda \le X^\lambda_{2\lambda+1} = -\lambda - \tfrac 12 + W_{2\lambda+1}$ which implies that 
\begin{align}\label{eq:re-upper-bound3}
\pc{\underline{X}_{2\lambda+1}^\lambda > - \tfrac \lambda 2 }
 \le \pc{W_{2\lambda +1} > \tfrac \lambda 2} \le e^{-\lambda/20}\,,
\end{align}
for all $\lambda$ large enough. Putting together \eqref{eq:re-upper-bound1}--\eqref{eq:re-upper-bound3} completes the proof of the upper bound.

For the lower bound, observe that 
\begin{align}\label{eq:re-lb1}
\p{R_\lambda < 2\lambda-1}
&=\pc{\underline{X}^\lambda_1 > \underline{X}^\lambda_{2\lambda-1}} \notag\\
&\le \inf_x \big\{\pc{X_1^\lambda < x} + \pc{\underline{X}_1^\lambda> \underline{X}^\lambda_{2\lambda-1}, X_1^\lambda\ge x} \big\}\,. 
\end{align}
Considering the fact that $X_1^\lambda = -\tfrac 12 + \lambda + W_1$, we are lead to choosing $x=\tfrac\lambda2$. We have $\pc{X_1^\lambda <\frac \lambda 2} \le e^{-\lambda^2/9}$ for all $\lambda$ large enough. To deal with the second part of the right-hand side of \eqref{eq:re-lb1}, we use Markov's property at time $1$ and observe that for $s\ge 1$,  $X_s^\lambda - X^\lambda_1$ is distributed like $X^{\lambda-1}_{s-1}$: 
\begin{align}\label{eq:re-lb2}
  \pc{\underline X_1^\lambda > \underline{X}_{2\lambda -1}^\lambda~|~X_1^\lambda \ge \tfrac \lambda 2} 
  & \le \pc{\underline X^{\lambda-1}_{2\lambda-2} < -\tfrac \lambda 2}\,.
\end{align}
However, since $s\mapsto -\tfrac {s^2}2 +(\lambda-1)s$ is non-negative on $[0,2(\lambda-1)]$, we have
\begin{align*}
	\underline{X}^{\lambda-1}_{2\lambda-2} 
	= \inf\{-\tfrac {s^2}2 + (\lambda -1) s + W_s: s\le 2\lambda -2 \} 
	% & \ge \inf\{-\tfrac {s^2}2 + (\lambda-1)s: s\le 2\lambda -2\} + \underline{W}_{2\lambda -2} 
	\ge \underline{W}_{2\lambda -2}\,,
\end{align*}
so that, by \eqref{eq:tail_max_bm},
\begin{align*}
  \pc{\underline X^{\lambda-1}_{2\lambda-2} < -\tfrac \lambda 2} 
  \le \pc{\underline{W}_{2\lambda -2} < -\tfrac \lambda 2} 
  \le e^{-\lambda/20}\,, 
\end{align*}
for all $\lambda$ large enough. Putting this together with \eqref{eq:re-lb1} and \eqref{eq:re-lb2} yields the lower bound on $R_\lambda$. 


Finally, we deal with the lower bound on $L_\lambda$. Observe that 
$\Ec{X^\lambda_s}=-\tfrac {s^2}2 + \lambda s 
%\ge s (\lambda -\tfrac 12) 
\ge s \lambda / 2$ for all $s\in [0,1]$ provided that $\lambda$ is large enough. 
So writing $t=a/\lambda^2$, we have, since $\underline X^\lambda_t\le 0$, 
\begin{align*}
\pc{L_\lambda \ge t} 
= \pc{\underline{X}_t^\lambda > \underline{X}_1^\lambda}
%&\le \pc{\underline{X}_t^\lambda > \underline{X}_1^\lambda, X^\lambda_t \ge \tfrac \kappa{4\lambda} } + \pc{X^\lambda_t < \tfrac \kappa {4\lambda}}\\
&\le \pc{\exists s\in [t,1]: X^\lambda_s \le 0}\\
&\le \pc{\exists s\in [t,1]: W_s \le - \lambda s / 2}\,.
\end{align*}
Observe that $\{(s,y): s\in [t,1], y\le -\lambda s/2\} \subseteq \bigcup_{i\ge 1} \{(s,y): s\le (i+1)t, y\le -\lambda i t/ 2\}$. So writing $\tau(-x):=\inf\{s\ge 0: W_s<-x\}$, we have
\begin{align*}
\pc{\exists s\in [t,1]: W_s \le - \lambda s/ 2} 
 &\le \sum_{i\ge 1} \pc{\tau(-\lambda it/2) \le (i+1) t}\\
 &\le \sum_{i\ge 1} \pc{\underline{W}_{(i+1)t} \le -\lambda i \tfrac t2 }
%& \le \sum_{i\ge 1} \exp(-i a /16)\\
\end{align*}
which, using \eqref{eq:tail_max_bm} is at most $e^{-a/20}$ for all $a$ large enough. This completes the proof of Lemma~\ref{lem:position_Hlambda}.
% The event in the right-hand side above corresponds to sample path large deviations for Brownian motion and its probability can be estimated thanks to Schilder's theorem \cite[Theorem 5.2.3, p. 185][]{DeZe1998}, a special case of the Freidlin--Wentzell theorem for diffusions:
% \begin{align*}
% \pc{\exists s\in [\frac \kappa {\lambda^2},1]: \lambda^{-1} W_s \le \tfrac s 2}
% & \le \exp\left( \lambda^2 \inf\{\int_0^1 |\phi|^2\}\right)\,,
% \end{align*}
% where $\phi$ ranges in the set of absolutely continuous functions on $[0,1]$ that hit the region $\{\}$ 

\subsection{Distances in small aggregated components} % (fold)
\label{sub:distances_in_swallowed_components}

In this section, we are interested in the intrinsic metric space induced by $d$ on $q_\lambda$. Write $D_\lambda = \sup\{d(x,y): x,y\in q_\lambda\}$ for the diameter of this metric space, and for $\zeta_\lambda$ a random variable with uniform distribution in $q_\lambda$, independent of everything else, let $Y_\lambda:=d(l_\lambda, \zeta_\lambda)$ where $l_\lambda=\inf q_\lambda$.

Recall that $X^\lambda_t=W_t-\tfrac {t^2}2 + \lambda t$ and $B^\lambda_t = X^\lambda_t - \underline{X}^\lambda_t$ is the process reflected in the running infimum. We define $m_\lambda=|q_\lambda|$ and $\varepsilon_\lambda:\R_+ \to \R_+$ by 
\begin{equation}\label{eq:e_alpha}
	\varepsilon_\lambda(s):= B^{\lambda-h}(l_\lambda+s) \I{0\le s\le m_\lambda}\,.
\end{equation}
The excursion $\varepsilon_\lambda$ has duration $m_\lambda$ and encodes the metric space $\sT_\lambda^\tsp$ or $\sT_\lambda^\tsm$ supported by $q_\lambda$. For any fixed $\lambda'\in \R$, and $q$ an interval of $\R_+\setminus Z^{\lambda'}$, conditionally on $|q|=\sigma$, the distribution of the excursion of $B^{\lambda'}$ straddling $q$ is given by 
\begin{equation}\label{eq:exp_tilted_excursion}
	\tilde\bn_{\sigma}(A)=
	\frac {\int \I{\omega\in A} \exp(\int_0^\sigma \omega(r)dr) \bn_\sigma(d\omega) }
	{\int \exp(\int_0^\sigma \omega(r) dr) \bn_\sigma(d\omega)}\,
\end{equation}
where $\bn_\sigma$ is the law of a Brownian excursion of duration $\sigma>0$. Consider now, $\lambda\in \Lambda$, which is random. For any $\lambda'<\lambda$, $l_\lambda\in Z^{\lambda'}$; furthermore, as $\lambda'\uparrow \lambda$, we have $\inf\{s>0: B^{\lambda'}(l_\lambda+s)=0\}\uparrow m_\lambda$ and the excursion of $B^{\lambda'}$ starting at $l_\lambda$ converges to $\varepsilon_\lambda$. It follows that, for a bounded continuous functional $\phi$, 
\begin{equation}\label{eq:dist_varepsilon_lambda}
	\Ec{\phi(\varepsilon_\lambda)~|~m_\lambda=\sigma}=\int \phi(\omega) \tilde \bn_\sigma(d\omega)\,.
\end{equation}
We note further that, by the strong Markov property, the excursions $\varepsilon_\lambda$, $\lambda\in \Lambda$ are mutually independent conditionally on $m_\lambda$, $\lambda \in \Lambda$. 
% {\red 
% By construction, this is an excursion in the sense that $e_\alpha(s)>0$ for $s\in q_\alpha^o$ while $e(s)=0$ for $s\in \{\inf q_\alpha, \sup q_\alpha\}$. 
% The law of the excursions is explicit: for any $\alpha\in \cal A$, the excursions $e_\alpha$ are condtionally independent given $(q_\alpha)_{\alpha\in \cal A}$ and 
% \begin{equation}\label{eq:law_e-alpha}
% \tilde \bn_\sigma(A) = \p{\varepsilon_\lambda \in A~|~m_\lambda=\sigma} = \frac{\E{\I{e\in A} \exp(\int_0^\sigma e(s)ds)}}{\E{\exp(\int_0^\sigma e(s)ds)}}.
% \end{equation}
% }

\begin{prop}[Distances in small components]\label{pro:diameter_small}
For any $\epsilon>0$, there exist
\begin{compactenum}[i)]
	\item a sub-Gaussian random variable $D^\star$ such that, if $m_\lambda\in (0,\epsilon]$ then $m_\lambda^{-1/2} D_\lambda \le_{st} D^\star$, and
	\item a random variable $Y^\star$ with $\Ec{1/Y^\star}<\infty$ and such that if $m_\lambda\in (0,\epsilon]$ then $Y^\star \le_{st} m_\lambda^{-1/2} Y_\lambda$.
\end{compactenum}
%%% NIC : I have removed the part with the convergence in distribution
% {\nic Furthermore, conditionally on $m_\lambda=\sigma$, $m_\lambda^{-1/2} Y_\lambda$ converges in distribution and in every $L^p$ as $\sigma\to 0$, to a Rayleigh random variable $R$ with density $xe^{-x^2/2}$ on $\R_+$.}
% % {\red Furthermore, $D^\star_\epsilon,Y^\star_\epsilon$ converge in distribution as $\epsilon\to 0$. }
% % \JF{pas clair: est-ce que tu veux dire que l'on peut construire des processus  $D^\star_\epsilon,Y^\star_\epsilon$ indexé par $\epsilon$ t.q. blabla?}
\end{prop}
\begin{proof}
\emph{i)} Let $(\omega,\bu)\mapsto d_{\omega,\bu}$ a deterministic measurable function which gives the metric  of $\CMT(\omega,\bu)$ for $\bn\otimes d\bu$-a.e. $(\omega,\bu)$, and let $\bar d_{\omega,\bu}=\sup_{x,y} d_{\omega,\bu}(x,y)$ be the corresponding diameter.
From the law of $\varepsilon_\lambda$ in \eqref{eq:exp_tilted_excursion}--\eqref{eq:dist_varepsilon_lambda} and the Cauchy--Schwarz inequality, for any $r\in \R$,
\begin{align}\label{eq:diameter_to_brownian}
\E{e^{r m_\lambda^{-1/2} D_\lambda}~\Big|~m_\lambda=\sigma} \notag
& = \int \exp(r \sigma^{-1/2} \bar d_{\omega,\bu}) \tilde \bn_\sigma(d\omega) d\bu  \notag \\
& = \int \exp(r \sigma^{-1/2} \bar d_{\omega,\bu}) \frac{\exp(\int_0^\sigma \omega(s) ds) \bn_\sigma(d\omega)} {\int \exp(\int_0^\sigma \omega(s) ds) \bn_\sigma(d\omega) } d\bu\notag \\
% & = \frac{\E{\exp(\gamma D_{e,\bu}} \exp(\int_0^\sigma e(s)ds)}{\E{\exp(\int_0^\sigma e(s)ds)}}\\
& \le \frac{\sqrt{\int \exp(2 r \sigma^{-1/2} \bar d_{\omega,\bu}) \bn_\sigma(d\omega) d\bu } \cdot \sqrt{\int \exp(2\int_0^\sigma \omega(s)ds) \bn_\sigma(d\omega)}}{\int \exp(\int_0^\sigma \omega(s)ds) \bn_\sigma(d\omega)}.
% & \le 2 e^{2\gamma^2}\cdot \frac{\phi(-2\sigma^{3/2})^{1/2}}{\phi(-\sigma^{3/2})},
\end{align}
In the first factor above, the metric space is encoded by a Brownian excursion, and is therefore exactly distributed like a Brownian continuum random tree of mass $\sigma$ (Theorem~\ref{thm:limit_mst_surplus} with $s=0$). It follows by Brownian scaling that, under $\bn_\sigma \otimes d\bu$, $\sigma^{-1/2} \bar d_{\omega,\bu}$ is dominated by  $2\|e\|$, twice the supremum of a standard Brownian excursion, which is well-known to be sub-Gaussian (see, for instance, \cite{DuIg1977,Kennedy1976}). On the other hand, observe that $\psi(z):=\int \exp(z\int_0^1 \omega(s)ds) \bn_1(d\omega)=\Ec{\exp(z\int_0^1 e(s)ds)}$, the Laplace transform of Brownian excursion area \cite{Janson2007}, is continuous and positive on any interval $[0,\epsilon]$. It follows that there exist constants $A=A_\epsilon$ and $v>0$ such that, for any $\sigma\in [0,\epsilon]$,
\begin{equation}\label{eq:Dlambda_subgaussian}
	\E{\exp(r m_\lambda^{-1/2} D_\lambda)~\Big|~m_\lambda=\sigma} \le e^{r^2/(2v)} \cdot \sup_{\sigma \in [0,\epsilon]} \frac{\sqrt{\psi(2\sigma^{3/2})}}{\psi(\sigma^{3/2})} \le A e^{r^2/(2v)}\,.
\end{equation}

One then easily constructs (the law of a variable) $D^\star$ by inverse transform. For $\sigma>0$ let $F_\sigma(x):=\pc{D_\lambda \le x~|~m_\lambda=\sigma}$, and $F_\star(x):=\inf\{F_\sigma(x): \sigma \le \epsilon \}$. Then for $U$ a $[0,1]$-uniform random variable, $F_\star$ is the distribution function of a random variable $D^\star:=F_\star^{-1}(U)$ that dominates all the $m_\lambda^{-1/2} D_\lambda\I{m_\lambda\le \epsilon}$. The random variables $F^{-1}_\sigma(U)$ are uniformly sub-Gaussian by \eqref{eq:Dlambda_subgaussian}, and so is $D^\star$. This completes the proof of \emph{i)}. 

The proof of \emph{ii)} about the distance to a random point is similar: we only discuss the adaptation of the arguments in \emph{i)} to bound $\Ec{m_\lambda^{1/2}/Y_\lambda~|~m_\lambda=\sigma}$. Instead of Cauchy--Schwarz, using Hölder's inequality (with exponents $3/2$ and $3$) provides an upper bound similar to \eqref{eq:diameter_to_brownian} where the main term involves the $d_{\omega,\bu}(0,\xi)$ for $\xi$ independent and uniform in $[0,\sigma]$ under $\bn(d\omega)$: this is the distance between two random points in a unit mass Brownian CRT, which is a random variable $Y$ with density $x e^{-x^2/2}dx$ on $\R_+$ \cite{Aldous1991b}, so that $\Ec{Y^{-3/2}}<\infty$. The multiplicative error term is bounded just as above, and the random variable $Y^\star$ is constructed similarly, using the supremum of the distribution functions instead of the infimum. We omit the details. 
%%% NIC: part with the convergence in distribution removed
% {\nic For the last claim, observe that \emph{i)} implies that $m_{\lambda} Y_\lambda$ is tight in every $L^p$. The convergence is straightforward at this point: for any continuous bounded functional $f$, we have, by Brownian scaling for $\bn_\sigma$
% \begin{align*}
% \left|\int f(\omega) \tilde \bn_\sigma(d\omega) - \int f(\omega) \bn_\sigma(d\omega)	\right|
% & \le \|f\| \cdot \int  \left|\frac{\exp\big(\sigma^{3/2} \int_0^1 \omega_1(r)dr\big)}{\Psi(\sigma^{3/2})}-1\right| d\bn_1(d\omega_1)\,,
% \end{align*}
% which tends to zero as $\sigma\to0$ by bounded convergence. 
% }
\end{proof}

\subsection{Statistics of the aggregated components $\sT_\lambda^\tsp$} % (fold)
\label{sub:statistics_small_components}

From the results of the previous section, especially the law of the $\varepsilon_\lambda$, it is crucial to understand the distribution of the $m_\lambda$. In the following we let $\sE$ be the space of continuous excursions, that is, the functions $f\in \cC(\R_+,\R_+)$ with $f(0)=0$ such that there exists $\sigma\in [0,\infty)$ such that $f(s)>0$ for $s\in (0,\sigma)$ and $f(s)=0$ for $s\ge \sigma$. 

Fix any $\lambda\in \R$ and consider the excursions of $X^\lambda$ away from its running infimum $\underline X^\lambda$. For $y\in \R_+$, let $\tau^\lambda_y:=\inf\{s>0: -\underline{X}_s^\lambda>y\}$. Then, $\{(y,\tau^\lambda_y-\tau^\lambda_{y-}): \tau_y^\lambda>\tau_{y-}^\lambda\}$ is a Poisson point process on $\R_+\times \R_+$ of intensity $dy \tilde\varrho^\lambda_{\tau_{y-}}$, where the inhomogeneous measure $\tilde \varrho_x^\lambda$ is defined by (see, e.g., \cite{Aldous1997}, Section 5.2)
\begin{equation}\label{eq:excursion_length_measure}
\tilde \varrho^\lambda_x(l,\infty):=\lim_{\epsilon\to 0} \frac 1 \epsilon \p{\inf\{s>0:X^\lambda_{x+s}\le 0\} > l~\Big|~X_x^\lambda=\epsilon }\,.
\end{equation}

\begin{prop}\label{pro:distribution_R-process}
The process $\{(\lambda, \varepsilon_\lambda): R_{\lambda}>R_{\lambda-}\}$ is a Poisson point process on $\R\times \sE$ of intensity $R_{\lambda-} d\lambda \tilde \varrho^{\lambda}_{R_\lambda-}(d\sigma) \tilde\bn_{\sigma}(d\omega)$.
\end{prop} 
%\JF{la notation $\varrho^{\lambda}_{R_\lambda-}$ n'est pas encore introduite... (elle l'est 10 lignes plus bas)}
\begin{proof}The distribution of the excursions $\varepsilon_\lambda$ conditionally on their duration is known from the previous section, and we only need to deal with the sizes of the jumps of $(R_\lambda)_{\lambda\in \R}$. These are formed by agglomeration of some of the excursion lengths of $B^\lambda$, for $\lambda\in \R$, which are described by the excursion length measure in \eqref{eq:excursion_length_measure}: As $\lambda$ increases, the excursions of $B^\lambda$ away from $0$ merge together until they eventually join the connected component containing $1$. 

We proceed geometrically using the process $X^0$ only. The excursions $\varepsilon_\lambda$ are simply read from $X^0$: for any $\lambda$ such that $R_{\lambda}>R_{\lambda-}$, $\varepsilon_\lambda$ is obtained as 
\[\varepsilon_\lambda(s) = (X^0(R_{\lambda-}+s)-X^0(R_{\lambda-})+s\lambda) \I{R_{\lambda-} + s\le R_\lambda}
\qquad \text{for }s\ge 0.\]
Here, notice that $\varepsilon_\lambda$ is indeed obtained from the agglomeration of countably many excursions of $X^{\lambda -h}-\underline X^{\lambda-h}$, which might be described using the process involving straight lines with slopes $\lambda-h$ (at time $\lambda$, the excursions of interest are those of $X^0$ above the process $s\mapsto \underline X_s^\lambda - \lambda s$). Now, knowing the intensity of jumps of $\tau^\lambda$ for each $\lambda\in \R$, it is routine to deduce the intensity of excursions of jumps of $(R_\lambda)_{\lambda \in \R}$: at time $\lambda$, we always have an excursion, the increase in local time is $d\lambda R_{\lambda-}$, and this gives rise to excursions whose durations are governed by $\tilde \rho_{R_{\lambda}-}^\lambda$. 
% {\red For each $y$ such that $\tau^\lambda_y>\tau^\lambda_{y-}$ define 
% \[f_y:=u\mapsto f_y(r)=X^\lambda(\tau^\lambda_{y-}+r)-X^\lambda(\tau^\lambda_{y-}) \I{\tau^\lambda_{y-}+r\le \tau^\lambda_y}\,.\]}	
\end{proof}

% {\red


% % Fix $\lambda \in \R$ and consider the $X^\lambda$. Recall $Z^\lambda=\{s\in \R_+: X^\lambda= \underline{X}^\lambda=0\}$. Then $\R_+\setminus Z^\lambda$ consists in a countable collection of open intervals on which $\underline{X}^\lambda$ remains constant. The distribution of the lengths of these intervals is quite explicit. 
% % Then, $\{(y,f_y): \tau^\lambda_y>\tau^\lambda_{y-}\}$ is an inhomogeneous Poisson point process on $\R_+\times \sE$ with intensity $dy \breve\bN_x^\lambda$, where $\breve\bN_x^\lambda$ is the excursion measure for the excursions of $X^\lambda$ started at position $x=\tau^\lambda_{y-}$ (see Section~5 of \cite{Aldous1997}). Here, we have 
% % \[\breve\bN_x^{\lambda}(B) = \breve \bN_0^{\lambda-x}(B) = \lim_{\epsilon \to 0} \frac 1 \epsilon \pc{(X^\lambda_{x+s}\I{s\le \tau_0})_{s\ge 0} \in B~|~X^\lambda_x=\epsilon}\,.\]

% We are actually interested in the law of $(R_\lambda)_{\lambda\in \R}$ whose jumps are formed by agglomeration of some of excursion lengths of the processes $X^\lambda-\underline X^\lambda$, $\lambda \in \R$. Indeed, as $\lambda$ evolves, the excursions will merge together before joining the connected componenent containing $1$. 

% }

% {\red The following proposition provides the comparison that will help us bound the statistics of the connected component that get connected to the compoment containing $1$. For $k\ge 1$, we let 
% \[LT_k:=\underline{X}^{k^3}_{R_{k^3}}-\underline{X}^{k^3}_{R_{(k+1)^3}}\,.\]
% For $x\ge 0$, let $\Po(x)$ denote a Poisson random variable with mean $x$. 
% \begin{prop}\label{pro:bound_poisson-measure}On the event that $LT_k\le \Delta$ and $\sup\{\lambda - \inf q_\lambda: \lambda \in \Lambda_k\} \le -\mu$, the collection $\{m_\lambda: \lambda \in \Lambda_k\}$ is stochastically dominated by a Poisson point measure of intensity $\Delta \cdot \bN^{-\mu}(\sigma\in dx)$, namely, jointly for every $x>0$, we have 
% \[\# \{\lambda\in \Lambda_k: m_\lambda>x \}\le_{st} \Po(\Delta \cdot \bN^{-\mu}(\sigma>x))\,.\]
% \end{prop}
% \begin{proof}This follows from Proposition~\ref{pro:local_time_R}. We are only interested in the durations of the excursions. First, if $\lambda-R_{\lambda-}<-\mu$ the instanteneous drift of $X^\lambda_s$ for $s\ge R_{\lambda-}$ is always at most $-\mu$; in other words $\breve \bN^\lambda_{R_{\lambda-}}(\sigma >x) \le \bN^{-\mu}(\sigma>x)$. Here, on the event that $\sup\{\lambda - \inf q_\lambda: \lambda \in \Lambda_k\}\le -\mu$, this is true for all excursions $e_\lambda$ with $\lambda\in \Lambda_k$. 


% \begin{alert}This seems (1) not quite what I had intuited for a bound, and (2) much simpler since this is at most $R_{(k+1)^3} [(k+1)^3-k^3] !!$ This is also much cleaner because the event looks at much less...
% \end{alert}

% % {\red 
% % \footnote{The idea is to take all the excursions of $X^{k^3}$ above its running minimum and make them longer; since there are infinitely many of them, we cannot project on local time and then replace each excursion by another one. We need a coupling.}
% % We provide a coupling between $\{(\lambda,)\}$
% % \begin{itemize}
% % 	\item Local time is bounded by what it is for the smallest value for $\lambda$, that is $k^3$, in the interval where we are looking; this is because as $\lambda$ increases, excursions merge, so their number "decrease";
% % 	\item each excursion is an excursion of some $X^\lambda$, for $\lambda \in [k^3, (k+1)^3]$, starting in the interval $[R_{k^3}, R_{(k+1)^3}]$. The drift at position $s$ for $X^\lambda$ is $\lambda-s$. The larger the drift, the longer the excursion, and the maximum possible drift is bounded above by $(k+1)^3-R_{k^3}$.
% % \end{itemize}
% % }
% \end{proof}


% The conditions under which we may use Proposition~\ref{pro:bound_poisson-measure} are given by the following lemma.
% \begin{lem}\label{lem:local_time}There exists a constant $c>0$ such that, with probability at least $1-\exp(-ck^3)$, the following events all happen:
% \begin{compactenum}
% 	\item $LT_k\le 8 k^{5}$, and
% 	\item $\sup\{\lambda_\alpha - \inf q_\alpha: \alpha \in \cA_k^+\}\le k^3/2$.
% \end{compactenum}
% \end{lem} 
% \begin{proof}
% \noindent \emph{i)} Conditionally on $R_{k^3}$ and $R_{(k+1)^3}$, $LT_k$ can be dominated by a deterministic contribution coming from the drift plus the variation coming from the Brownian motion on an interval of duration bounded by $R_{(k+1)^3}$. Using Lemma~\ref{lem:position_Hlambda}, with probability at least $1-2e^{-ck^3}$ we have $R_{k^3}\ge 2 k^3 -1$ and $R_{(k+1)^3} \le 2 (k+1)^3+1$ so that, on that event and for $k$ large, $LT_k$ is dominated by $7k^5 + \overline{W}_{2(k+1)^3+1}$.
% It follows that 
% \begin{align*}
% \pc{LT^\lambda_k \ge 8 k^5} 
% & = \pc{\underline{X}^{k^3}_{R_{k^3}}-\underline{X}^{k^3}_{R_{(k+1)^3}} \ge 8 k^5}\\
% & \le 2e^{-ck^3} + \pc{7k^5 + \overline{W}_{(k+1)^3+1} \ge 8k^{5}} \\ 
% & \le 3e^{-ck^3}\,,
% \end{align*}
% for all $k$ large enough, by Lemma~\ref{lem:tail_max_bm}. 
 

% \noindent \emph{ii)} This is straighforward from Lemma~\ref{lem:position_Hlambda} after observing that for every $k\ge 1$, we have $\sup\{\lambda_\alpha-\inf q_\alpha: \alpha\in \cA^+_k\} \le (k+1)^3-R_{k^3}$. 
% \end{proof}
% }
% \begin{proof}
% \noindent \emph{i)} Noting that $\Ec{\underline{X}^{\lambda_k}_{k^3}-\underline{X}^{\lambda_k}_{(k+1)^3}}\le -((k+1)^3-k^3)\cdot (\lambda_k - (k+1)^3) \le 4 k^5$, for all $k$ large enough, it follows that 
% \begin{align*}
% \pc{LT^\lambda_k \ge 2 (k+1)^{2\beta}} 
% & = \pc{\underline{X}^{\lambda_k}_{k^3}-\underline{X}^{\lambda_k}_{(k+1)^3} \ge 5 k^5}\\& \le  \pc{(k+1)^6 + \overline{W}_{(k+1)^3-k^3} \ge k^{5}} \\ 
% & \le \pc{\overline{W}_{(k+1)^3} \ge k^5} \\ 
% & \le \exp(-k^5)\,,
% \end{align*}
% for all $k$ large enough, by Lemma~\ref{lem:tail_max_bm}. 


% \noindent \emph{ii)} First note that $\inf\{\lambda_\alpha: \alpha \in \cA_k\} \ge \lambda_{k^3}$. However, for $x\ge 1$, we have $\lambda_{x}\le \lambda$ if and only if $R_\lambda \ge x$, and Lemma~\ref{lem:right-end} provides an upper bound on the latter event. If follows that 
% \begin{align*}
% 	\pc{ \inf\{\lambda_\alpha: \alpha \in \cA_k\}\le \tfrac 1 2 (k^3-1)} 
% 	& \le \pc{\lambda_{k^3} \le \tfrac 1 2 (k^3-1)} \\
% 	& \le \pc{R_{k^3} \ge 2 k^3+1} \\ 
% 	& \le \exp(-c k^3)\,.
% \end{align*}

% \noindent \emph{iii)} Proceeding similarly, still using Lemma~\ref{lem:right-end}, we obtain 
% \begin{align*}
% 	\pc{ \sup\{\lambda_\alpha: \alpha \in \cA_k\}\ge \tfrac 1 2 (k+1)^3+1)} 
% 	& \le \pc{\lambda_{(k+1)^3} \ge \tfrac 1 2 (k+1)^3 + 1 } \\
% 	& \le \pc{R_{k^3} \ge 2 k^3+1} \\ 
% 	& \le \exp(-c k^3)\,.
% \end{align*}
% \end{proof}


For each $k\ge 1$ we say $\lambda\in \Lambda_k$ is of level $i\ge 0$ and write $\lambda \in \Lambda_{k,i}$ if its duration satisfies $m_\lambda \in [k^{-6-i}, k^{-5-i})$. We define the $M_{k,i}$ total duration (mass) of excursions of level at least $i$ 
\[M_{k,i}=\sum_{j\ge i}\sum_{\lambda \in \Lambda_{k,j}} m_\lambda\,. \]

\begin{lem}[Statistics for fragments $\sT^\tsp_\lambda$, $\lambda\in \Lambda^\ssp$]\label{lem:sizes_fragments-k}For any $k\ge 1$ and $i\ge 0$, there exists an event $B_{k,i}$ of probability at most $8\min\{k^{-1-i/4}, k^{-5/4}\}$ such that outside of $B_{k,i}$ we have 
\begin{compactenum}[i)]
\item the longest excursion: $\sup\{m_\lambda: \lambda \in \Lambda_k\} \le k^{-5}$
\item total duration of excursions of level at least $i$: $M_{k,i} \le \min \{k^{7/2-i/4}, 7k^2 \},$
\item number of excursions of level $i$: $\#\Lambda_{k,i}\le 7 k^{8+i}$,
\item maximum diameter of an excursion of level $i$: $D_{k,i}=\sup\{D_\lambda: \lambda\in \Lambda_{k,i}\}\le k^{-2 -i/4}$.
\end{compactenum}
In particular, $\bigcup_{i\ge 0} B_{k,i}$ occurs with probability at most $10 k^{-5/4}$.
\end{lem}

The proof of Lemma~\ref{lem:sizes_fragments-k} is based on upper bounds on the durations $|q_\lambda|$, $\lambda\in \Lambda_k$. The relevant calculations are simplified if we upper bound the Brownian with parabolic drift by a Brownian with a suitable linear drift. This is why the following is especially useful. In the following, we let $\varrho^{\mu}$ be the excursion length measure for Brownian motion with linear drift $\mu$, $W^\mu:=s\mapsto W_s + \mu s$. We are mostly interested in what happens at large positions, for which the drift is negative: we note that, for $\mu\ge 0$, 
\[\varrho^{-\mu}(x,\infty)
= \lim_{\epsilon\to 0} \frac 1 \epsilon \p{\inf\{s>0: W^{-\mu}_s\le 0\}>x\Big|~W^{-\mu}_0=\epsilon}
= \int_x^\infty \frac {e^{-\mu^2 r/2}} {\sqrt{2\pi r^3}}  dr\,.\]
The following proof relies this and the fact that $X^{-\mu}_s\le W^{-\mu}_s$ for all $s\ge 0$ in the natural coupling.

\begin{proof}[Proof of Lemma~\ref{lem:sizes_fragments-k}] Let $B_k$ be the event that $R_{k^3}> 2k^3-1$ or $R_{(k+1)^3}< 2(k+1)^3+1$. Then, by Lemma~\ref{lem:position_Hlambda}, $\pc{B_k}\le \exp(-ck^3)$ for some constant $c>0$. Now, on the one hand, the quantity of local time $LT_k$ corresponding to $\Lambda_k$ is  
\[LT_k:=\int_{k^3}^{(k+1)^3} R_{\lambda-}d\lambda = \int_{k^3}^{(k+1)^3} R_{\lambda}d\lambda \le R_{(k+1)^3}[(k+1)^3-k^3]\,,\]
so that $LT_k\le 7k^5$ for all $k$ large enough on the complement event $B_k^c$.  On the other hand, $\sup\{\lambda-\inf q_\lambda: \lambda \in \Lambda_k\}\le (k+1)^3-R_{k^3}\le -k^3/2$ for large $k$ on $B_k^c$. 

By Proposition~\ref{pro:distribution_R-process}, it follows that, on the event $B_k^c$, for every $x>0$, $\#\{\lambda\in \Lambda_k: m_\lambda>x\}$ is stochastically dominated by a Poisson random variable with parameter $\Delta_k \varrho^{-\mu_k}(x,\infty)$ with $\Delta_k=7k^5$ and $\mu_k=k^3/2$. The properties \emph{i)} to \emph{iv)} in the statement then follow easily. 

% {\red Putting together Proposition~\ref{pro:bound_poisson-measure} and Lemma~\ref{lem:local_time} with $\Delta_k=8k^5$, $\mu_k=k^3/2$, and letting $B_k$ be the bad event that one of the properties in Lemma~\ref{lem:local_time} is violated counting as well the bound on the position of $R_{k^3}, R_{(k+1)^3}$ from Lemma~\ref{lem:position_Hlambda}, then $\pc{B_k}\le \exp(-c k^3)$, and on $B_k^c$ we have a domination of $(m_\alpha: \alpha \in \cA_k)$ by the atoms of a Poisson point measure. }

\noindent\emph{i) Longest excursion.} We have
\begin{align*}
	\bE\Bigg[\sum_{\lambda\in \Lambda_k} \I{m_\lambda > k^{-5}} \I{B_k^c} \Bigg]
	\le 7k^5 \varrho^{-\mu_k}(k^{-5},\infty) 
	= 7k^5 \int_{k^{-5}}^\infty \frac{e^{-k^6 t/8}}{\sqrt{2\pi t^3}} dt
	\le e^{-c k}\,,
\end{align*}
for some constant $c$ and all $k$ large enough. Markov's inequality then implies the claim. 

\noindent \emph{ii) Total length of excursions of level $i$.} We proceed similarly for the upper bound on $M_{k,i}$. We have
\begin{align*}
\bE\Bigg[\sum_{\lambda\in \Lambda_k} m_\lambda \I{m_\lambda \le k^{-5-i}} \I{B_k^c} \Bigg]
\le 7 k^5 \int_0^{k^{-5-i}} \!\!\!\!\!\! x \varrho^{-\mu_k}(dx)  
\le 7 k^5 \int_0^{k^{-5-i}} \frac{xe^{-k^6 x/8}}{\sqrt{2\pi x^3}}  dx
%\le 7/2 k^5 \int_0^{k^{-5-i}} x^{-1/2} dx \\ 
\le 7 k^{5/2 - i/2}\,.
\end{align*}
Moreover, we also always have the bound $\sum_{\lambda\in \Lambda_k} m_\lambda \le R_{(k+1)^3}-R_{k^3}$ which is at most $7k^2$ on $B_k^c$. Markov's inequality then yields
\[\pc{M_{k,i} \ge k^{7/2-i/4}, B_k^c} \le \min\{7 k^{-1-i/4}, 7k^{-3/2+i/4}\}\,.\]

\noindent \emph{iii) Cardinality of $\Lambda_{k,i}$.} This is a deterministic bound on $B_k^c$: we have $\#\Lambda_{k,i}\le 7 k^2 \cdot k^{6+i}=7 k^{8+i}$.

\noindent \emph{iv) Maximum diameter in level $i$.} By Proposition~\ref{pro:diameter_small}, when the event of \emph{i)} occurs, $D_{k,i}$ is stochastically dominated by 
\[k^{-5/2-i/2} \cdot \max\{D^\star_j: 1\le j\le \# \Lambda_{k,i}\}\,,\]
where $D^\star_j$ are iid copies of the random variable $D^\star$ that is sub-Gaussian (choose $\epsilon=1$). Using the bound for $\#\Lambda_{k,i}$ in \emph{iii)} above, it follows easily that  
\begin{align*}
	\pc{D_{k,i} \ge k^{-2-i/4}, B_k^c} 
	& \le 7 k^{8+i} \cdot \pc{D^\star \ge k^{1/2+i/4}} \\
	& \le 7 k^{8+i} \cdot \exp(-\tfrac{k^{1+i/2}}{2v})\,,
\end{align*}
for some constant $v>0$. 

Finally, writing $B_{k,i}$ for the event that either $B_k$ or any of the bad events in \emph{i)}--\emph{iv)} occur, we have $\pc{B_{k,i}}\le 8\min \{7k^{-1-i/4},k^{-5/4}\}$ for large $k$ (this is essentially limited by the event in \emph{ii)}). The union bound yields the last claim. 
\end{proof}

% subsubsection the_distribution_of_sizes_of_swallowed_components (end)




\subsection{The accumulation of length in an annulus: Proof of Proposition~\ref{pro:bound_annulus}} % (fold)
\label{sub:contribution_of_intervals}

Each component $\sF_\lambda$ gets connected to some point to its left (in $\R_+$), which falls within some $\sF_{\lambda'}$, for some $\lambda'<\lambda$, and so on. The proof of Proposition~\ref{pro:bound_annulus} consists in bounding the accumulation of these lengths before a connection to $\sM_{k^3}$ eventually occurs. We are only interested here in the points of $(1,\infty)$.


Recalling the notation $\ju(\cdot)$ from Remark~\ref{rem:points_absolute}, by construction, for each $\lambda\in \Lambda^\ssp$, the point $l_\lambda=\inf q_\lambda$ is identified with $\ju(l_\lambda)$ in the metric space $(\sM,d)$. Furthermore, $\ju(l_\lambda)$ is uniform in $H_{\lambda-}$. For any $x\in q_\lambda$, with $\lambda \in \Lambda^\tsp$, the segment between $x$ and $1$ must contain the points $\ju(l_\lambda)$ that we may see as a projection of $q_\lambda$ on $H_{\lambda-}$. With this in mind, we let $p(x)=\ju(l_\lambda)$ if $x\in q_\lambda$, $\lambda\in \Lambda^\ssp$. Then, for any point $x>1$, we consider the sequence of successive projections defined by $p^0(x)=x$, and provided that $p^n(x)>1$, $p^{n+1}(x)=p(p^n(x))$, until we eventually find a point in $[0,1]$. 

Fix now some natural number $k\ge 1$ and let $A_k:=(R_{k^3}, R_{(k+1)^3}]$ denote the set of points of the annulus of fragments $\sF_\lambda$, for $\lambda\in \Lambda_k$. For each $\lambda\in \Lambda_k$, and $n\ge 0$, let $\lambda_n$ be such that $p^{n}(l_\lambda)\in q_{\lambda_n}$. Recall that $D_\lambda=\sup\{d(x,y): x,y\in q_\lambda\}$. Clearly, the distance from any point $x\in A_k$ to $\sM_{k^3}$ is at most 
\[\sup_{\lambda \in \Lambda_k} \sup_{x\in q_\lambda} d(x,\sM_{k^3}) \le \sup_{\lambda \in \Lambda_k} \sum_{1\le n\le N_\lambda} D_{\lambda_n} \,,\]
where $N_\lambda=\inf\{n\ge 1: p^n(l_\lambda)<R_{k^3}\}$. However, since $\Lambda_k$ is infinite, we shall refine the analysis and rely on the decomposition into different levels introduced in the previous section. 

Recall that we say that $q_\lambda$ is an interval of level $i$, and write $\lambda\in \Lambda_{k,i}$ if $m_\lambda\in [k^{-6-i},k^{-5-i})$; let $A_{k,i}=\bigcup_{\lambda\in \Lambda_{k,i}} q_\lambda$ be the subset of $A_k$ consisting of the intervals of level $i$. For $i\ge 0$, and $\lambda \in \Lambda_{k,i}$, let $N_i(\lambda):=\inf\{n\ge 1: p^{n}(l_\lambda) \not\in A_{k,i} \}$ be the number of hops until hitting an interval of level lower than $i$, or exiting $A_k$ altogether from the left. We then have
\begin{align}\label{eq:bound_accumulation}
\sup_{\lambda \in \Lambda_k} \sum_{1\le n\le N_\lambda} D_{\lambda_n} 
& \le \sum_{i\ge 0} \sup_{\lambda\in \Lambda_{k,i}} \sum_{1\le n \le N_i(\lambda)} D_{\lambda_n} \notag \\ 
& \le \sum_{i\ge 0} \sup_{\lambda\in \Lambda_{k,i}} N_i(\lambda) \cdot \sup_{j\ge i}\sup_{\lambda\in \Lambda_{k,j}} D_\lambda \notag \\ 
& \le \sum_{i\ge 0} \sup_{\lambda\in \Lambda_{k,i}} N_i(\lambda) \cdot k^{-2-i/4}\,,
\end{align}
provided that the event $\bigcap_{i\ge 0} B^c_{k,i}$ from Lemma~\ref{sub:statistics_small_components} occurs. So it remains only to upper bound $N_{k,i}=\sup\{N_i(\lambda):\lambda \in \Lambda_{k,i}\}$. We do this using the properties of the sequence of the projections. 

\begin{lem}\label{lem:Ni}
For any $k\ge 1$ large enough,  with probability at least $1-11 k^{-5/4}$, we have for every $i\ge 0$, 
\[N_{k,i} := \sup_{\lambda \in \Lambda_{k,i}} N_\lambda < 20\,.\]
\end{lem}
\begin{proof}Let $\cG$ be the sigma-algebra generated by $(X_s)_{s\ge 0}$. Then $(q_\lambda)$, $\lambda \in \Lambda^\ssp$ is $\cG$-measurable while, conditionally on $\cG$, the random variables $\xi(l_\lambda)$ are independent and uniform in $H_{\lambda-}$. Let $B_k$ be the event that $R_{k^3}<2k^3-1$ or $R_{(k+1)^3}>2(k+1)^3+1$. For any $\lambda\in \Lambda_k$, $(1,R_{k^3}] \subseteq H_{\lambda-}$; therefore, on the event $B_k^c$ for any Borel set $A$, $\pc{\xi_\lambda \in A~|~B_k^c,\cG}\le \Leb(A)/k^3$. Furthermore, by Lemma~\ref{sub:statistics_small_components}, on $B^c_{k,i}$ we have $M_{k,i}\le \max\{k^{7/2-i/4}, 7k^2\}$ and $\#\Lambda_{k,i}\le 7k^{8+i}$. It follows by the union bound, that for any natural number $m\ge 1$, we have
\begin{align*}
	\pc{N_{k,i} \ge m~|~B^c_{k,i}, B^c_k, \cG} 
	%& \le \pc{N_{k,i} \ge m, M_{k,i} \le k^{7/2-i/4}}  \\
	& \le \#\Lambda_{k,i} \cdot \sup_{\lambda \in \Lambda_{k,i}}\pc{N_\lambda \ge m ~|~M_{k,i} \le k^{7/2-i/4}} \\
	& \le 7 k^{8+i} \cdot (k^{7/2-i/4}/k^3)^m \\
	& \le 7 k^{8+i} \cdot k^{-m(i-2)/4}\,.
\end{align*}
As a consequence, for $m=20$, we obtain
\[\pc{N_{k,i} \ge 20 ~|~B^c_{k,i}, B^c_k, \cG} \le 7 k^{18-4i}\,,\]
which will be good enough for $i\ge 5$. On the other hand, for $0\le i\le 4$, the alternative bound $M_{k,i}\le 7k^2$ yields a bound of $7k^{8+i-m}\le 7k^{-8}$ for $m=20$. Putting everything together, we have $N_{k,i}\ge 20$ for some $i\ge 0$ with probability at most $10 k^{-5/4} + 28 k^{-8} + 8 k^{-2}\le 11 k^{-5/4}$ for all $k$ large enough. 
\end{proof}

Going back to \eqref{eq:bound_accumulation}, Lemma~\ref{lem:Ni} implies that 
\[\sup_{\lambda\in \Lambda_k} \sum_{1\le n \le N_\lambda} D_{\lambda_n} \le 20 \sum_{i\ge 0} k^{-2 -i/4} \le k^{-3/2}\,\]
with probability at least $1-11k^{-5/4}$ which completes the proof of Proposition~\ref{pro:bound_annulus}. 


% subsubsection contribution_of_intervals (end)


% subsubsection distances_in_swallowed_components (end)


\subsection{The diameter of the string of beads: Proof of Proposition~\ref{pro:left-end}} % (fold)
\label{sub:string_of_beads}

By construction, for any $\lambda \in \R$, the diameter of $\sP_\lambda$ is no greater than 
\begin{align}\label{eq:sum_diam_around0}
\sum_{\lambda'>\lambda} \diam(\sT^-_{\lambda'}) \I{\lambda'\in \Lambda^\ssm}
&\le \sum_{\lambda'>\lambda} \sqrt{m_{\lambda'}} \cdot D_\lambda^\star \I{\lambda'\in \Lambda^\ssm}\,,
\end{align}
where $D^\star_\lambda$, $\lambda\in \Lambda^\ssm$, are i.i.d.\ copies of the sub-Gaussian random variable whose existence is guaranteed by Proposition~\ref{pro:diameter_small} with $\epsilon=1$. We have already bounded a similar sum in Section~\ref{sub:recursive_convex_minorants_BPT}; in particular, the arguments there show that almost surely
\begin{equation}\label{eq:bound_around_zero}
\sum_{\lambda'\in \Lambda^\ssm} \sqrt{m_{\lambda'}} < \infty\,.
\end{equation}
Finally, consider the process $M_\lambda(s)$ defined for $s\ge 0$ by 
\[M_\lambda(s):=\sum_{\lambda<\lambda'\le \lambda+s} \sqrt{m_{\lambda'}} \cdot (D^\star_{\lambda'}-\Ec{D^\star_{\lambda'}})\,.\]
Conditionally on the $m_\lambda$, $\lambda \in \Lambda^-$, $(M_\lambda(s))_{s\ge 0}$ is a martingale. Since $D^\star$ is sub-Gaussian, $M_\lambda(s)$ is bounded in $L^2$ and thus converges almost surely to a finite limit as $s\to\infty$. Putting this together with \eqref{eq:bound_around_zero} shows that the right-hand side of \eqref{eq:sum_diam_around0} and hence $\diam(\sP_\lambda)$ tends to zero as $\lambda \to \infty$, which completes the proof of Proposition~\ref{pro:left-end}. 

% subsubsection subsubsection_name (end)
