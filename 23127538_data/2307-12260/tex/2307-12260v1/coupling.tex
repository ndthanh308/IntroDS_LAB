%!TEX root = MST_brownian.tex

% \begin{alert}
% Here we need to prove:
% \begin{compactitem}
% 	\item Theorem~\ref{thm:limit_mst_Kn} about the entire MST
% 	\item Theorem~\ref{thm:limit_mst_surplus} about the MST of a connected graph with given surplus
% 	\item Theorem~\ref{thm:dynamics_X} about the dynamics for the limit random graph and Kruskal processes
% \end{compactitem}
% \end{alert}

% \begin{alert}\textbf{NOTATION}
% 	\begin{compactitem}
% 		\item $\bs=(s_1,s_2,\dots, s_\kappa)$ the points in $(0,\infty)$; will use $v_{\lfloor n^{2/3}s_i \rfloor}$ for the discrete analog;
% 		\item $\underline{\lambda}$ for the time at which replace the fragments by CRT ? So far this is $\tau$
% 		\item $D(\bs)=(d(s_i,s_j))_{1\le i,j\le \kappa}$ for the matrix of distances ? $D^n(\bs)$ for the discrete analog;
% 	\end{compactitem}
% \end{alert}

% \begin{alert}Remarks:
% 	\begin{compactitem}
% 		\item I don't think we need the distances in a forest, just in a tree containing all the points ?
% 	\end{compactitem}
% \end{alert}

All the proofs of convergence will be based on couplings with discrete objects. It would be possible to identify the distribution of $\CMT(X, \bU)$ as that of the scaling limit of the minimum spanning tree constructed in \cite{AdBrGoMi2013a} directly in the continuum using the dynamics as $\lambda$ evolves and the tools developed in \cite{AdBrGoMi2019a}. However, since we need comparisons with discrete objects anyway for Theorems~\ref{thm:limit_mst_surplus} and~\ref{thm:dynamics_X}, we do not pursue this here. All the limit theorems essentially boil down to proving that, in a suitable coupling, and for every $\lambda\in \R$, the restriction of the metric space $\CMT(X,\bU)$ to any interval $(a,b)$ of $\R_+\setminus Z^\lambda$ is the limit (in probability) of the minimum spanning tree of a connected component induced by a vertex set whose node have Prim ranks in an interval $\{a_n, a_n+1,\dots, b_n-1\}$ where $a_n \sim a n^{2/3}$ and $b_n \sim b n^{2/3}$. Our coupling will be ``global'' in the sense that it allows a transparent application to any collection of times $\lambda_1<\lambda_2<\dots < \lambda_k$ and any finite collection of intervals at these times. 

\subsection{Discrete preliminaries} % (fold)
\label{sub:discrete_preliminaries}

In this section, we provide the discrete representation that we will use to prove our limit theorems. They all heavily rely on the Prim order introduced in \cite{BrMa2015a} and its properties. We will in particular give a representation of the minimum spanning tree $M_n$, and of the random graph $G(n,p)$ that we will see as the union of a portion of the minimum spanning tree, the Kruskal forest denoted by $K(n,p)$, together with additional cyclic edges. 

Recall the Prim algorithm and the Prim order $v_1,v_2,\dots, v_n$ discussed in Section~\ref{sub:intuition_and_techniques}. Recall also that $V_k=\{v_1,\dots, v_k\}$. For $k\in [n]$, let $N_k^{n, p}$ be the number of nodes in $[n]\setminus V_k$ which have a neighbour in $V_k$ in the graph $G(n,p)$ whose edge set is $\{e: w_e\le p\}$. For $\lambda\in\R$, set $p_n(\lambda)=1/n+\lambda n^{-4/3}$. Then define, for $t\ge 0$, 
\begin{equation}\label{eq:def_Xnlambda}
X^{n,\lambda}_t
:=n^{-1/3} \left( 
N_{\lfloor t n^{2/3}\rfloor }^{n,p_n(\lambda)}
-\#\{i\le t n^{2/3} : N_i^{n,p_n(\lambda)} = 0\}
\right)\,.
\end{equation}
Let $Z^{n,\lambda}$ be $n^{2/3}$ times the collection of instants when $X^{n,\lambda}$ reaches a new minimum. Then, the points of $Z^{n,\lambda}$ are the Prim ranks of the first vertices of the connected components of $G(n,p_n(\lambda))$. Furthermore, recalling the definitions in Section~\ref{sub:intuition_and_techniques}, the collection of the edges of the minimum spanning tree $M_n$ are precisely $\{e_i=(u_i,v_i): 2\le i\le n\}$. The identities of the nodes can of course not be recovered from $(X^{n,\lambda})_{\lambda\in \R}$, but one may use the Prim ranks to construct a graph on $[n]$ that is isomorphic to $M_n$ using $(X^{n,\lambda})_{\lambda\in \R}$ only. However, the information about the location of the $u_i$ vanishes in the limit, and we shall construct a graph that has the correct distribution of the left-end points $u_i$, conditionally on $(Z^{n,\lambda})_{\lambda \in \R}$. 

We start with an encoding of the merges. Note that there are precisely $n-1$ jumps to the process $(Z^{n,\lambda})_{\lambda \in \R}$, each one corresponding to the appearance of one of the edges $e_i=(u_i,v_i)$ for some $2\le i\le n$. Let $\li_n(i)$ and $\ri_n(i)$ be respectively the Prim ranks of the left-most and right-most vertices of the connected component of $v_{i}$ at time $w_{e_i}$; let also $\slo_n(i)=(1-n w_{e_i})n^{1/3}$ be the discrete analog of the slope of a point $t\in \sL$ in the continuous setting. Then, the set
\begin{equation}\label{eq:def_mergen}
	\Merge_n(X^n):=\{(n^{-2/3}\li_n(i), n^{-2/3}i, n^{-2/3}\ri_n(i), -\slo_n(i)): 2\le i\le n\}
\end{equation}
contains all the information about the merges of connected components. We can rephrase the fact that the extremities $u_i$ of the edges $e_i=(u_i,v_i)$ are uniform in the connected component containing $v_{i-1}$ as follows. 
Let $(U_i)_{i\ge 1}$ be i.i.d.\ uniform on $[0,1]$, also independent of $\Merge(X^n)$. For each $i$, let $\ju_n(i)=\li_n(i)+\lfloor U_i (i-\li_n(i))\rfloor$. Then, $\ju_n(i)$ is uniform in $\{\li_n(i), \li_n(i)+1, \dots, i-1 \}$. The following lemma is a simple reformulation of Lemma~\ref{lem:discrete_merges}.

\begin{prop}[A representation of the minimum spanning forest]\label{prop:random_forest}
Conditionally on $\Merge_n(X^n)$, the collection of Prim ranks of the nodes $(u_i: 2\le i\le n)$ has the same distribution as $(\ju_n(i): 2\le i\le n)$. In particular, up to a relabelling of the nodes of $M_n$ using the Prim ranks: 
\begin{compactenum}[i)]
	\item the graph on $[n]$ with edges $\{\ju_n(i), i\}$, $2\le i\le n$, is distributed like $M_n$;
	\item the graph on $[n]$ with edges $\{\ju_n(i), i\}$, $2\le i\le n$ with $-\slo_n(i) \le \lambda$ is distributed like the Kruskal forest $K(n,p_n(\lambda))$.
 \end{compactenum}
\end{prop}

We now move on the representation of the random graphs. We say that an edge is \emph{cyclic} if it is the maximum weight edge of some cycle. For each $p\in [0,1]$, the graph $G(n,p)$ is formed of the portion of the minimum spanning tree consisting of the edges of weight at most $p$, together with the cyclic edges of weight at most $p$. Observe that while the edges of the minimum spanning tree are all a.s.\ a function of $(X^{n,\lambda})_{\lambda\in \R}$, this is not the case for the cyclic edges (with positive probability some information is lost, even at the discrete level).  Again, rather than collecting the information from the random graph, it is more instructive to construct this information with the correct distribution conditionally on $(Z^{n,\lambda})_{\lambda \in \R}$. 

Let $\{Y_{ij}, 1\le i<j\le n\}$ be i.i.d.\ random variables uniform on $[0,1]$ and independent of everything else (namely $\Merge_n(X^n)$ and $(U_i)_{2\le i\le n}$). For each $1\le i<j\le n$, let $\lambda^n_{ij}=(nY_{ij}-1)n^{1/3}$. We store the information concerning cyclic edges in a point process. Define 
\begin{equation}\label{eq:def_xin}
	\Xi_n :=\Big\{(i n^{-2/3}, jn^{-2/3}, \lambda^n_{ij}): 1\le i<j\le n, Z^{n,\lambda^n_{ij}}\cap \{i+1,i+2,\dots, j\} = \varnothing \Big\}\,,
\end{equation}
so that $\Xi_n$ is the collection of triples $(i/n^{2/3}, j/n^{2/3}, \lambda^n_{ij})$ for which $v_i$ and $v_j$ are in the same connected component of $G(n,p_n(\lambda^n_{ij})-\delta)$ for $\delta>0$ small enough. The total number of cyclic edges, sometimes called the surplus, of a connected component is also a quantity of interest, and can be expressed in terms of $\Xi_n$. Recall that $C^{n,\lambda}_i$, $i\ge 1$, denote the collection of vertex sets of the connected components of the random graph $G(n,p_n(\lambda))$, sorted in decreasing order of their sizes. For a discrete connected component $C^{n,\lambda}_j$, the number of surplus edges in $G(n,p_n(\lambda))$ is given by 
\begin{equation}\label{eq:discrete_surplus}
	\surp^{n,\lambda}_j=\#\big\{(x,y,\lambda') \in \Xi_n: xn^{2/3},yn^{2/3}\in C^{n,\lambda}_j, \lambda'\le\lambda\big\}\,.
\end{equation}

\begin{prop}[A representation of the random graph]\label{prop:random_graph}Up to a relabelling of the nodes with the Prim ranks, the graph on $[n]$ with edge set consisting of the union of 
\begin{compactitem}
	\item the edges $\{\ju_n(i), i\}$, $2\le i\le n$ such that $\slo_n(i)\ge -\lambda$, and 
	\item the edges $\{i,j\}$, $1\le i<j\le n$ such that $\lambda^n_{ij}\le \lambda$ and $Z^{n,\lambda^n_{ij}}\cap \{i+1,i+2,\dots, j\} = \varnothing$
\end{compactitem}
has the same distribution as $G(n,p_n(\lambda))$.
\end{prop}
\begin{proof}Note first that we only care about the distribution of the edges of the second set that are not already in the first one. From Kruskal's algorithm, it is clear that, conditionally on the minimum spanning tree $M_n$, the weights of the edges in the complement are independent. Furthermore, for any fixed pair of nodes $u,v\in [n]$ which are not adjacent in the minimum spanning tree, the weight of the edge between $u$ and $v$ is uniform, conditioned on being larger than the value $p_n(\lambda)$ at which $u$ and $v$ first become part of the same connected component. This is precisely what the second condition says when expressed in terms of the Prim ranks. 
\end{proof}

Recall that $E^n_p=\{e\in E^n: w_e\le p\}$ denotes edge set of the random graph $G(n,p)$. Define similarly $F^n_p\subseteq E^n_p$ the edge set of the minimum spanning forest $K(n,p)$, that is the collection of edges of the minimum spanning tree which have weight at most~$p$. 
\begin{lem}\label{lem:discrete_edge_removal}
Let $p\in [0,1]$. 
\begin{compactenum}[i)]
	\item Conditionally on $E^n_{p}$, $(w_e:e\in E^n_p)$ is a family of i.i.d.\ uniform random variables (r.v.) on $[0,p]$;
	\item Conditionally on $F^n_{p}$, $(w_e:e\in F^n_p)$ is dominated by a family of i.i.d.\ uniform r.v.\ on $[0,p]$.
	% namely: for any $x_e\in [0,1]$, $e\in F^n_p$, we have
	% \[\pc{w_e\le p x_e : e\in F^n_p~|~F^n_p} \ge \prod_{e\in F^n_p} x_e\,.\]
\end{compactenum}
\end{lem}
\begin{proof}\emph{i)} The first assertion is immediate since $\{w_e: e\in E^n_p\}$ is simply a collection of i.i.d.\ uniform r.v.\ on $[0,1]$ conditioned on being at most $p$. \emph{ii)} The second claim is a consequence of Kruskal's algorithm: The set $F^n_p\subseteq E^n_p$ is obtained from $E^n_p$ by iteratively removing the edge with maximum weight that belongs to a cycle, until there are no more cycles. The remaining edge have thus been selected for not being the maximum edge of any cycle; by \emph{i)} the initial weights in $E^n_p$  are i.i.d.\ uniform  random variables on $[0,p]$, and the weights in $F^n_p$ are therefore dominated by a collection of i.i.d.\ uniform r.v.\ on $[0,p]$. 
\end{proof}

\begin{lem}\label{lem:dist_left-most-node}
Fix any $\lambda\in \R$. Conditionally on $a,b\in [n]$, $a<b$, being two successive points of $Z^{n,\lambda}$, 
\begin{compactenum}[i)]
	\item the vertices whose Prim ranks are in $\{a, a+1, \dots, b-1\}$ form a connected component of $G(n,p_n(\lambda))$;
	\item conditionally on $S=\{v_a,\dots, v_{b-1}\}$, the vertex $v_a$ with Prim rank $a$ is uniformly random in $S$, and independent of $G(n,p_n(\lambda))$.
\end{compactenum}
\end{lem}
\begin{proof}The first claim is immediate from the definition of $X^{n,\lambda}$; see Section 4.1 of \cite{BrMa2015a}. The second point is a consequence of the definition of the Prim order. Consider the time in Prim's algorithm when we decide who gets to have rank $a$: conditionally on the event in \emph{i)}, this depends on an edge with weight (strictly) larger than $p_n(\lambda)$; conditionally on having its extremity in the set of vertices with Prim ranks $a,a+a,\dots, b-1$, the end point is uniformly random, and declared to have Prim rank $a$. This completes the proof.
\end{proof}

\subsection{Asymptotic properties of random graphs for $\lambda\to -\infty$}
\label{sec:asymptotic_random_graphs}

{Recall that we identify the nodes with their Prim ranks, so $v_i$ is simply denoted by $i$. 
For points $s_1,\dots, s_k \in (0,\infty)$, let $\Span_n(s_1,\dots, s_k)$ denote the collection of vertices that belong to one of the paths in the minimum spanning tree $M_n$ between some $s_i^n=\lfloor s_i n^{2/3}\rfloor$ and $s_j^n=\lfloor s_j n^{2/3} \rfloor$. For $\lambda\in \R$ and $s_1,s_2,\dots, s_k\in (0,\infty)$, let $J^{n}_{\lambda}(s_1,s_2,\dots, s_k)$ be the collection of indices $j\ge 1$ such that $C^{n,\lambda}_j$ intersects $\Span_n(s_1,\dots, s_k)$. 

The following lemma shows that all the connected components containing part of the path in the minimum spanning tree between a collection of random points have a size of order $n^{2/3}$. 

\begin{prop}\label{pro:local_asympt_small_lambda}
Let $I\subset (0,\infty)$ be any compact interval, and let $s_1,s_2,\dots, s_k\in (0,\infty)$ be i.i.d.\ uniform in $I$. Then, for any $\epsilon>0$ there exists $\lambda\in \R$, and $\delta>0$, such that, with probability at least $1-\epsilon$, all the connected components of $G(n,p_n(\lambda))$ containing nodes of $\Span_n(s_1,\dots, s_k)$ are trees and have size at least $\delta n^{2/3}$.
\end{prop}
\begin{proof}
\emph{i)} We abbreviate $J^n_\lambda(s_1,\dots, s_k)$ as $J^n_\lambda$. For any fixed $\lambda$, the collection of connected components containing any of the $s_i^n$, $1\le i\le k$, have Prim ranks at most $n^{2/3} \sup I  + |C^{n,\lambda}_1|$. With high probability, this is at most $tn^{2/3}$ for some fixed $t$ for all $\lambda\le 0$ (say). However, by the representations in \cite{AdBrGo2012a} or \cite{BrMa2015a}, the number of surplus edges involving pairs of nodes with Prim rank at most $tn^{2/3}$ converges to a Poisson random variable whose parameter the $\int_0^t (X^\lambda_s-\underline X^\lambda_s) ds$, which tends to zero almost surely as $\lambda\to-\infty$. Thus, for any $\epsilon>0$, we can indeed choose $\lambda$ small enough for all the $C^{n,\lambda}_j$, $j\in J^{n}_\lambda$ to be trees with probability at least $1-\epsilon$.

\emph{ii)} We shall prove that the family of random variables $\max\{n^{2/3}/ |C^{n,\lambda}_j|: j\in J^n_\lambda\}$, $n\ge 1$, is tight. The arguments are all routine, and we only provide the main structure of the proof. Fix $\epsilon>0$. First, let $\overline \lambda$ be large enough that $s_1^n,\dots, s_k^n$ are all in the same connected component $H^n$ which also contains the point $\lfloor n^{2/3}\rfloor$ with probability at least $1-\epsilon$ (see for instance, Lemma~\ref{lem:position_Hlambda}). 

By Lemma~\ref{lem:discrete_edge_removal} \emph{ii)}, when decreasing $p$ from $p_n(\overline \lambda)$ to $p_n(\lambda)$, each edge is removed with probability at most $(p_n(\overline \lambda)-p_n(\lambda))/p_n(\overline \lambda)\sim (\overline \lambda-\lambda)n^{-1/3}$ independently of the others. So, the number of edges removed on a prescribed path of length at most $C n^{1/3}$ is dominated by a binomial random variable with parameters $Cn^{1/3}$ and $(\overline \lambda-\lambda)n^{-1/3}$ and is thus tight. Since $n^{-1/3}\diam(H^n)\le n^{-1/3}\diam(M_n)$ which is tight (\cite{AdBrGo2010}), the same holds for the length of the path between any of two of the $\{s_1^n, \dots, s_k^n\}$. This implies the tightness of $(|J^n_\lambda|)_{n\ge 1}$, for any $\lambda\in \R$. This also readily implies that $n^{1/3}$ divided by the smallest distance in the minimum spanning tree between any two removed edges is tight. On the other hand, the minimum distance between any two of the $\{s_1^n,\dots, s_k^n\}$ is itself of order $n^{1/3}$ (this is lower bounded by the distance in the corresponding  graph $G(n,p_n(\overline \lambda))$, and thus follows from the results in \cite{AdBrGo2012a,AdBrGoMi2013a}). It follows that the smallest portion of a path connecting the $\{s_1^n, \dots, s_k^n\}$ in the Kruskal forest $K(n,p_n(\lambda))$ is also of order at least $n^{1/3}$.

Now, by \emph{i)}, let $\lambda$ be small enough that all the involved connected components are trees at time $p_n(\lambda)$ with probability at least $1-\epsilon$. Conditionally on the number of its nodes being $m$, the diameter any such connected component is of order $m^{1/2}$ (\cite{Aldous1991b,Aldous1993a}). Putting this together with the facts that, for this value of $\lambda$, the number of portions of paths is tight $J^n_\lambda$, that each of the portions has length of order $n^{1/3}$, this implies that each of the portions is contained in a connected component whose size is indeed of order $n^{2/3}$ (and no smaller). 
\end{proof}

The following folklore global asymptotic properties for the connected components will be useful. 
\begin{lem}\label{lem:global_asympt_small_lambda}
For any $\epsilon,\delta, \delta'>0$, there exists $\lambda\in \R$ such that, with probability at least $1-\epsilon$,
\begin{compactenum}[i)]
	\item the largest connected component of $G(n,p_n(\lambda))$ contains at most $\delta n^{2/3}$ nodes;
	\item the maximum diameter of a connected component of $G(n,p_n(\lambda))$ is at most $\delta' n^{1/3}$.
\end{compactenum}
\end{lem}
\begin{proof}%It is classical, and we collect the relevant references. 
For any $\alpha\le \delta$, the probability that either \emph{i)} or \emph{ii)} fails is at most
\begin{align*}
	\pc{|C^{n,\lambda}_1| \ge \alpha n^{2/3}}	+ \p{\max_{j\ge 1} \diam(C^{n,\lambda}_j) \ge \delta' n^{1/3}, |C^{n,\lambda}_1|\le \alpha n^{2/3}}\,.
\end{align*}
By Theorem~1.3 of \cite{NaPe2008}, there exists $\alpha>0$ small enough such that the second term is at most $\epsilon/2$. 
Then, choose $\lambda$ small enough that the first term is also at most $\epsilon/2$. The fact that such a $\lambda$ exists follows for instance from the results of \cite{AlLi1998} on the entrance boundary for the standard multiplicative (Theorem~4 there), and the relation between the random graph and the multiplicative coalescent in \cite{Aldous1997} (Proposition~4). 
\end{proof}

\subsection{A global coupling argument} % (fold)
\label{sec:global_coupling_argument}

Before actually proving the convergence of the trees or graphs seen as metric spaces, we verify that the main objects, on which the representations of the previous section rely, do converge. The objective is to eventually construct a rich enough probability space on which enough parameters converge almost surely, in order the make the final proof of convergence of the metric as easy as possible. The starting point is the process $(X^{n,\lambda})_{\lambda\in \R}$ introduced in \eqref{eq:def_Xnlambda}. By Theorem 7 of \cite{BrMa2015a}, we have 
\begin{equation}\label{eq:Convergence_Xnlambda}
(X^{n,\lambda})_{\lambda\in \R} \xrightarrow[n\to\infty]{} (X^\lambda)_{\lambda\in R}\,,
\end{equation}
in distribution in $\mathbb D(\R, \C([0,\infty), \R))$. The first essential ingredient consists in proving that this implies that the macroscopic merges restricted to any compact region of time and space also converge. Define 
\[\Merge(X)=\{(\li(t),t,\ri(t),-\slo(t)): t\in \sL(X)\}\,.\]
We say that $\Merge_n((X^{n,\lambda})_{\lambda\in \R)}\to \Merge(X)$ if for any compact intervals $I\subset (0,\infty)$ and $\Lambda\subset \R$, and any threshold $\epsilon>0$, the subset of $\Merge_n((X^{n,\lambda})_{\lambda\in \R}))$ consisting of points $(l,t,r,-s)$ such that $r-t,t-l>\epsilon$, $l,t,r\in I$ and $-s\in \Lambda$ converges to the corresponding subset of $\Merge(X)$. 

\begin{prop}[Convergence of large merges]\label{prop:large_merges}
Consider a probability space in which $(X^{n,\lambda})_{\lambda\in \R}\to (X^\lambda)_{\lambda\in \R}$ almost surely. Then, in probability,
\[\Merge_n((X^{n,\lambda})_{\lambda\in \R}) \xrightarrow[n\to\infty]{} \Merge(X)\,.\]
\end{prop}

% \begin{alert}Move in technical part about local minima in appendix?
% \end{alert}

% \begin{alert}Can probably simplify: This is convergence as a point process for the Hausdorff distance.
% \end{alert}

\begin{proof}We will use the following fact: a.s., there does not exist three local minima of $t, t', t''\in \sL(X)$ such that the points $(t,X_t)$, $(t',X_{t'})$ and $(t'', X_{t''})$ all lie on the same line; using the representation in \cite{BrMa2015a}, this is essentially equivalent to the fact that the standard multiplicative coalescent is binary. To see that this is indeed the case, note that local minima of a continuous function are also global minima on an interval with rational extremities; then for, three disjoint intervals $[a,b]$, $[a',b']$ and $[a'',b'']$ with rational extremities, the local minima $(t,X_t)$, $(t',X_{t'})$ and $(t'', X_{t''})$ on each of these intervals have a law which absolutely continuous with respect to the Lebesgue measure on $\R^2$, and then, are aligned with probability zero; the union of this countable number of zero probability events also has probability zero. Assume that $(a,b,c,\lambda)\in \Merge(X)$. In this case, $b$ is a local minimum of $X^\lambda$, and $X^\lambda$ is strictly above the (horizontal) line connecting $(a,X_a^\lambda),(b,X_b^\lambda),(c,X_c^\lambda)$ on $(a,b)\cup (b,c)$; because of the property recalled above, since $(a,X_a^\lambda)$ and $(b,X_b^\lambda)$ are local minima of $X^\lambda$, it is (a.s.) not the case for $(c,X_c^\lambda)$, so that, $\inf\{X^\lambda_t: t\in (c,c+\eta)\}<0$ for any $\eta>0$.

Given compact intervals $I\subset (0,\infty)$, $\Lambda\subset \R$ and a threshold $\epsilon>0$, there are only finitely many points in $\Merge(X)\cap I^3\times \Lambda$ with the first three coordinates at least $\epsilon$ apart, and it suffices to consider each one separately. 
Take some $(a,b,c,\lambda)\in \Merge(X)$, so that, in particular $X^\lambda_a=X^\lambda_b=X^\lambda_c$. Consider, for  $\varepsilon'>0$, $\delta>0$, the event
% \begin{align*}
%   \cE((a,b,c,\lambda); \varepsilon',  \delta)
%   =& \{m^\lambda(0,a-\varepsilon')\geq X^\lambda_a+\delta\}\\
% % &\cap&     \{ M^t(a-\varepsilon',a)\geq X^t_a+\delta,  M^t(a,a+\varepsilon')\geq X^t_a+\delta\}\\
%   &\cap\{m^\lambda(a+\varepsilon',b-\varepsilon')>\delta\}\\
% %  &\cap&\{M^t(b-\varepsilon',b)\geq X^t_b+\delta,M^t(b,b+\varepsilon')\geq X^t_b+\delta\}\\
%   & \cap\{m^\lambda(b+\varepsilon',c-\varepsilon')>\delta\}\\
% &\cap \{M^\lambda(c-\varepsilon',c)\geq X^\lambda_c+\delta, m^\lambda(c,c+\varepsilon')\leq X^\lambda_c-\delta\}\,.
% \end{align*}
\begin{align*}
  \cE((a,b,c,\lambda); \varepsilon',  \delta)
  =& \Big\{\inf_{[0,a-\varepsilon']}X^\lambda \geq X^\lambda_a+\delta\Big\}
  \cap \Big\{\inf_{[a+\varepsilon', b-\varepsilon']} X^\lambda> X_a^\lambda+\delta\Big\}\\
  & \cap\Big\{\inf_{[b+\varepsilon',c-\varepsilon']} X^\lambda > X^\lambda_a + \delta\Big\}
\cap \Big\{\inf_{[c,c+\varepsilon']} X^\lambda < X^\lambda_c-\delta\Big\}\,.
\end{align*}
Fix $\varepsilon'>0$, $a,b,c\in (0,\infty)$ such that $|b-a|, |c-b|\ge 2\varepsilon'$, and $\lambda\in \R$. Using the properties of the local minima of the Brownian motion, for any $\epsilon>0$ there exists a $\delta>0$ such that
\[\pc{\cE((a,b,c,\lambda); \varepsilon',\delta )~|~(a,b,c,\lambda)\in \Merge(X)}\geq 1-\epsilon.\]
% Now, since $X^n$ converges to $X$ (\JF{on démontre la convergence dans $D(\R,C([0,+\infty),\mathbb{R}))$, theo.5,  mais dans la tension, on démontre une convergence plus forete, dans la section 6.4, car on démontre que c'est tendu  $(X^{n,\lambda}_x)$ comme fonction en $\lambda$ et $x$, sur les compacts, avec le critère du module de continuité dans $C[\lambda_1,\lambda_2]\times[0,A]$}).
Let us show that, the event $\cE((a,b,c,\lambda);\varepsilon', \delta)$, for all $n$ large enough, there must exist some vector $(a_n,b_n,c_n,\lambda_n)$ close to $(a,b,c,\lambda)$ such that $(a_n,b_n,c_n,\lambda_n)\in \Merge_n((X^{n,\lambda})_{\lambda\in \R})$. To prove this, it suffices to show that for some $\lambda'<\lambda$ close enough to $\lambda$ there are points $(a_n,b_n,c_n)\in Z^{n,\lambda'}$ which are close to $(a,b,c)$, while for some $\lambda''>\lambda$ close enough to $\lambda$ there are points $a_n'',b_n''\in Z^{n,\lambda''}$ with $(a_n'',c_n'')$ close to $(a,c)$ but no other point of $Z^{n,\lambda''}$ between $a_n''$ and $c_n''$. We now proceed with the details. 

On the one hand, for any $\lambda'<\lambda$ there exists $\delta'>0$ small enough such that $X^{\lambda}_b<X^{\lambda'}_a-\delta'$ and $X^{\lambda'}_c<X^{\lambda'}_b-\delta'$. Taking $\lambda'$ close enough to $\lambda$ and $\delta'>0$ even smaller, we may also ensure that $X^{\lambda'}>\delta'$ on $[a+\varepsilon', b-\varepsilon']$ and $[b+\varepsilon', c-\varepsilon']$. The convergence of $X^{n,\lambda'}$ to $X^{\lambda'}$ then ensures that we may find $a_n,b_n, c_n\in Z^{n,\lambda'}$ all within distance $\varepsilon'$ of $a$, $b$ or $c$. 

On the other hand, for any $\lambda'>\lambda$, we have $X^{\lambda'}>\delta'$ on $(a+\varepsilon',c-\varepsilon')$; we may take $\lambda'$ close enough to $\lambda$, and $\delta'>0$ small enough such that we also have $\inf\{X^{\lambda'}: [c,c+\varepsilon']\}<\inf\{X^{\lambda'}: [0,a-\varepsilon']\}-\delta'$. The convergence of $X^{n,\lambda'}$ to $X^\lambda$ then ensures that there exists $a_n\in [a-\varepsilon', a+\epsilon']$ and $c_n\in [c-\varepsilon',c+\varepsilon']$ such that $a_n,c_n\in Z^{n,\lambda'}$ and $Z^{n,\lambda}$ does not have any other point between $a_n$ and $c_n$. 

Consider now a accumulation point $(a,b,c,\lambda)$ of $\Merge_n((X^{n,\lambda})_{\lambda\in \R})$ with $a<b<c$. 
Then, there exists a sequence $(a_n,b_n,c_n,\lambda_n)$ converging to $(a,b,c,\lambda)$ with $a_n,b_n,c_n\in Z^{n,\lambda_n}$. It follows that 
\[X^{n,\lambda_n}_{a_n}=\underline X^{n,\lambda_n}_{a_n}=X^{n,\lambda_n}_{b_n}+n^{-1/3} = X^{n,\lambda_n}_{c_n}+2n^{-1/3}\,.\] The convergence of $X^{n,\lambda}$ to $X^\lambda$ then implies that $\underline X^\lambda_a=X^\lambda_a=X^\lambda_b=X^\lambda_c$, so that $a,b,c\in Z^\lambda$. The path properties of $X$ also imply that, for any $\lambda'>\lambda$, $(a,c)\cap Z^{\lambda'}=\varnothing$ so that $(a,b,c,\lambda)\in \Merge(X)$. This completes the proof.
\end{proof}

The next step concerns the convergence of the representation of the cyclic edges. Given $X$, let $\Xi$ be a Poisson point process with intensity $\I{x<y}  \I{(x,y)\cap Z^\lambda= \varnothing} dx dy d\lambda$ on $\R_+^2\times \R$. 

\begin{prop}[Convergence of cyclic edges]\label{pro:cyclic_edges}
We have the convergence in distribution
\[((X^{n,\lambda})_{\lambda \in \R}, \Xi_n) \xrightarrow[n\to\infty]{d}((X^\lambda)_{\lambda\in \R}, \Xi)\,.\]
Furthermore, for any $a\in \R_+$ and $\lambda\in \R$, we have jointly,
\[\#\Xi_n \cap \Big([0,a]^2 \times (-\infty, \lambda] \Big) 
\xrightarrow[n\to\infty]{d} 
\#\Xi \cap \Big([0,a]^2 \times (-\infty,\lambda]\Big)\,.\]
\end{prop}
\begin{proof}Consider first the larger point process $\Xi^\circ_n=\{(in^{-2/3}, jn^{-2/3}, \lambda^n_{ij}): 1\le i<j\le n\}$. For every set $A\subset \{(x,y,\lambda): a\le x<y\le b, \lambda_1 \le \lambda \le \lambda_2\}$, $|\Pi_n \cap A|$ is a binomial random variable with parameters asymptotic to $n^{4/3}(b-a)^2/2$ and $\pc{\lambda_{ij}^n\in[\lambda_1,\lambda_2]}= (\lambda_2-\lambda_1)n^{-4/3}$, and thus converges to a Poisson random variable $P_A$ with parameter $(\lambda_2-\lambda_1)(b-a)^2/2$. 

Let now $A$ and $A'$ be any two disjoint such sets; we show that the distributional limits $P_A$ and $P_{A'}$ are independent. If the space intervals $[a,b]$ and $[a',b']$ are disjoint, this is straightforward since the random variables $(Y_{ij})$ involved in the definitions of $\Pi_n$ on $A$ and $A'$ are themselves independent. Otherwise the space intervals do intersect, and the time intervals must then be disjoint. Fix any $\epsilon>0$. There is some constant $K$ such that $\pc{|\Pi_n \cap A| > K}<\epsilon$. Now, conditionaly on $\Pi_n\cap A$ and $|\Pi_n \cap A|\le K$, to estimate the distribution of $|\Pi_n\cap A'|$ we shall remove the pairs $(i,j)$ which correspond to a point in $\Pi_n \cap A$, and correct the probability of every other to account for the fact that they did not occur in $[\lambda_1,\lambda_2]$ (for those that indeed intersect). This removes only at most $K$ out of the $n^{4/3}(b'-a')^2/2$ pairs, and boots the probability of some of others by a factor $(1-n^{-4/3}(\lambda_2-\lambda_1))$. Overall, the limit remains Poisson random variable with the same distribution. Since $\epsilon>0$ was arbitrary, this proves that $\Xi^\circ_n$ converges to a Poisson point process $\Xi^\circ$ with unit rate on $\{(x,z,\lambda)\in \R_+^2\times \R:x<y\}$.

For the remainder of the proof, we consider now a probability space on which $(X^{n,\lambda})_{\lambda\in \R}$ converges almost surely to $(X^\lambda)_{\lambda\in \R}$. To complete the proof, it now suffices to show that, the set $A^n=\{(in^{-2/3}, jn^{-2/3}, \lambda): Z^{n,\lambda}\cap \{i+1,\dots, j\} = \varnothing\}$ used to filter the points of $\Xi^\circ_n$ converges to $A=\{(x,y,\lambda): Z^\lambda \cap (x,y) =\varnothing\}$ used to filter those of $\Xi^\circ$, for the Hausdorff distance. Indeed, since $Z^{n,\lambda}$ and $Z^\lambda$ are both decreasing in $\lambda$ this would imply the convergence of their Lebesgue measures. Let $(x,y,\lambda)\in A$, then $(x,y)\cap Z^\lambda = \varnothing$, so that for any $\epsilon>0$ small enough, $\inf\{X^\lambda_s - \underline X^\lambda_s: s\in (x+\epsilon, y-\epsilon)\} > 0$. It follows that $\inf\{X^{n,\lambda}_s - \underline X^{n,\lambda}_s: s\in (x+\epsilon, x-\epsilon)\}>0$ as well for all $n$ large enough, so that $(x+\epsilon,y-\epsilon, \lambda)\in A^n$. Similarly, if $(x,y,\lambda)\not\in A$, then $\inf\{X_s^\lambda-\underline X_s^\lambda: s\in (x+\epsilon,y-\epsilon)\}\le 0$ for every $\epsilon>0$ small enough, and therefore $\inf\{X^{\lambda-\epsilon}_s -\underline X^{\lambda-\epsilon}_s: s\in (x+\epsilon,y-\epsilon)\}<0$ for some $\epsilon>0$ small enough. The argument we used above implies that $(x+\epsilon,y-\epsilon,\lambda-\epsilon)\not\in A^n$ for all $n$ large enough. 

For the second claim, one only needs the additional tightness of the number $N_n$ of points of $\Xi_n$ in $[0,a]^2 \times (-\infty,\lambda]$. Since the discrete representation of $\Xi_n$ is delicate to handle, we shall change the point of view: By the exact distribution of $N_n$ in Proposition~\ref{prop:random_graph}, $N_n$ is dominated by the number of surplus edges in the connected components that have nodes with Prim ranks at most $an^{2/3}$ at time $p_n(\lambda)$. The latter is known to be tight by the results in \cite{BrMa2015a} (Corollary~20 and Section 7.2), which consider the alternative representation for the surplus edges using a Bernoulli pointset under the graph of the discrete reflected process $X^{n,\lambda}-\underline X^{n,\lambda}$ (just as in the results of Aldous in \cite{Aldous1997}). 
\end{proof}

We may also recast the results of \cite{BrMa2015a} about the convergence of surpluses of connected components in the Prim order in the present setting (see also, \cite{Aldous1997}). Recall the discrete defined in \eqref{eq:discrete_surplus}. There is a continuum analog to the surplus of a connected component, that can be defined in terms of $\Xi$. At time $\lambda\in \R$, the connected components correspond to the intervals of $\R_+\setminus Z^\lambda$, that are sorted in decreasing order as $(\gamma^\lambda_j)_{j\ge 1}$. We define
\begin{equation}\label{eq:continuum_surplus}
\surp^\lambda_j=\#\big\{(x,y,\lambda') \in \Xi: x,y\in \gamma^\lambda_j, \lambda'\le \lambda \big\}\,.
\end{equation}

\begin{cor}\label{cor:convergence_surplus}Jointly with the convergence in Proposition~\ref{pro:cyclic_edges}, for any fixed $\lambda\in \R$, and any $j\ge 1$, we have 
\[\surp_j^{n,\lambda} \xrightarrow[n\to\infty]{d} \surp_j^{\lambda}\,.\]
\end{cor}

% \begin{alert}ATTENTION the previous proof is not complete; a priori, the rate depends on $m$: Need to verify that most edges are indeed non-edges, since the total rate is $l^2/2$, where $l$ is the length of the interval $N\sim n^{2/3} l$; and this would not be this rate if $m$ happens to be of order $N^2$.

% This seem to also assume something about the sizes of the connected components. Question: what does this convergence really say ? Only stuff about cc of size at least $\epsilon n^{2/3}$ ?

% One way: in discrete, this has exactly the distribution as in \cite{AdBrGo2012a}, and thus this at time $\lambda$, we have an upper bound by a Bernoulli process under the curve. This should suffice to prove that $o(N^2)$ spots are occupied, and thus the PPP has indeed the correct intensity. 
% \end{alert}

% \begin{alert}Coupling of the uniforms. and definition of the discrete object for the proof.
	
% \end{alert}

% \subsubsection{Synchronisation of the family $(\bU)$}
% \label{sec:Sf}

We shall also want to couple the collection of uniform choices that are associated to each merge, and used to sample the edges in discrete and the point identifications in the limit.
In the limit, merge events are characterized by some element $(x,y,z,\lambda)$ where $0<x<y<z$ and $\lambda\in \R$. Let $\Delta:=\{(x,y,z): 0<x<y<z\}\subseteq \R^3_+$. We shall discretize the set of merge events. 
We decompose the collection of all potential merge triples $\Delta$ into countably many cells (up to a Lebesgue null set), so that each cell can contain at most one of the elements $(x,y,z)\in \Delta$ for which there exists some $\lambda$ and $(x,y,z,\lambda)\in \Merge(X)$. 

For $x>0$, let 
%$K(x)=\lceil \log_2(1/x)\rceil -1$; then 
$K(x)$ be the unique integer $k\in \Z$ such that $x\in [1/2^{k+1},1/2^k)$. For $k\in \Z$ and $(x,y,z)\in \Delta$ define
\[D(x,y,z; k)= \big(\floor{x2^k}/2^k,\floor{(y-x)2^k}/2^k,\floor{(z-y)2^k}/2^k\big). \]
Then, the integer $M(x,y,z)= 1+\max\{K(y-x), K(z-y)\}$ is used as the precision at which we shall encode the triple $(x,y,z)$.
For each $(x,y,z)\in \Delta$, define
\[\Code(x,y,z) =(M(x,y,z), D(x,y,z; M(x,y,z))\,,\]
and observe that $\Code$ takes its values in the countable set $\N\times \mathbb Q^3$.
A subset $S\subset \Delta$ is called nested if for any $(x,y,z),(x',y',z')\in S$ we have either (a) $(x,z)\cap (x',z')=\varnothing$, or (b) $(x',z')$ is contained in either $(x,y)$ or $(y,z)$, or (c) $(x,z)$ is contained in either $(x',y')$ or $(y',z')$. The set $\Merge(X)$ is such that its projection on the first three coordinates is nested. One easily verifies that, the map $\Code$ is injective on any nested subset $S\subset \Delta$. 
\begin{lem}Let $S\subseteq \Delta$ be nested. Then for any $(x,y,z),(x',y',z')\in S$ we have $\Code(x,y,z)\ne \Code(x',y',z')$.
\end{lem}
\begin{proof}Suppose that $\Code(x_1,y_1,z_1)=\Code(x_2,y_2,z_2)$. Then, there is $k\in \Z$ and $(a,b,c)\in \R_+^3$ such that for $i\in \{1,2\}$, we have
\begin{compactenum}[i)]
	\item $M(x_i,y_i,z_i)=k$, so that $\min\{|y_i-x_i|,|z_i-y_i|\}\in [1/2^k, 1/2^{k-1})$, and
	\item $x_i\in [a, a+1/2^k)$, $y_i-x_i\in [b, b+1/2^k)$ and $z-y\in [c, c+1/2^k)$.
\end{compactenum}
Now, since $S$ is nested, and there are two alternatives. Either $(x_1,z_1)\cap (x_2,z_2) = \varnothing$, and without loss of generality, $z_1\le x_2$, and because of i) we have $|x_1-x_2|\ge 1/2^{k-1}$ which contradicts ii). Or, without of generality, $(x_1,z_1)\subset [x_2,y_2]$ or $(x_1,z_1)\subset [y_2,z_2]$, and either way, because of i), we cannot have simultaneously all the inequalities in ii).
\end{proof}

The following lemma is straightforward:
\begin{lem}\label{lem:code_cv}
Suppose that $(a_n,b_n,c_n)_{n\ge 1}$ converges to $(a,b,c)\in \Delta$ such that neither $a$, $b-a$ nor $c-b$ are multiple of some $2^j$, with $j\in \Z$. Then, for all $n$ large enough $\Code(a_n,b_n,c_n)=\Code(a,b,c)$.
\end{lem}

From now on, we will see $\bU$ as indexed by this $\Code(\Delta)$ (which is countable) rather than by~$\N$. 
% This observation and Lemma~\ref{}

% {\red \begin{cor}\label{cor:merge_code_cv}Suppose that, $\Merge_n((X^{n,\lambda})_{\lambda\in \R})\to \Merge(X)$ almost surely. Then, with probability one, for any compact intervals $I\subset(0,\infty)$ and $\Lambda\subseteq \R$, and all $n$ large enough, there exists a bijection $\pi$ between 
% \[\{\Code(a_n,b_n,c_n): (a_n,b_n,c_n,\lambda_n)\in \Merge_n((X^{n,\lambda})_{\lambda\in \R})\} = \Code(a,b,c,\lambda): (a,b,c,\lambda)\in \Merge(X)\,.\]
% \end{cor}
% }

% % \begin{prop}\label{pro:convergence_interval}{\red Suppose that $(X^{n,\lambda})_{\lambda \in \R}$, $\Xi_n$ $\Merge_n((X^{n,\lambda})_{\lambda \in \R}; I, \Lambda, \epsilon)$ converve almost surely to $(X^\lambda)_{\lambda\in \R}$, $\Xi$, $\Merge(X; I,\Lambda, \epsilon)$.} Then, for any $\lambda \in \Lambda$ and any interval $(a,b)$ of $\R_+\setminus Z^\lambda$ with $(a,b)\subset I$, there exists $a_n,b_n \in Z^{n,\lambda}$ such that $(a_n n^{-2/3}, b_n n^{-2/3})\to (a,b)$ and {\red need the $\epsilon$ small enough to control the connected components far in the past...}
% % \[(\{a_n, \dots, b_n-1\}, d_n, \mu_n)\xrightarrow[n\to\infty]{} ([a,b], d, \mu|_{[a,b]})\,,\]
% % in probability for the Gromov--Hausdorff--Prokhorov topology.
% % \end{prop}

% % \begin{alert}Note on convergences: can say that $\Merge_n(X^n)\to \Merge(X)$ if $\Merge_n(X^n; I, \Lambda, \epsilon)\to \Merge(X;I, \Lambda, \epsilon)$ for every compact intervals $I\subset (0,\infty)$, $\Lambda\subset \R$ and $\epsilon>0$. Just use diagonal argument.
% % \end{alert}

% \begin{alert}See where to put this afterwards; maybe at the very beginning (after the definition of the discrte objects)
% \end{alert}
% {\red For $k\in \N$, let $s_1, s_2,\dots, s_k\in (0,\infty)$. We aim at comparing the distances between the nodes $\lfloor s_i n^{2/3}\rfloor$, $1\le i\le n$, in the minimum spanning tree (or the random graph) on the one hand, and in $(\sM,d)$ on the other. The first crucial observation is that, while for any $\lambda\in \R$, there are arbirarily small connected components (in discrete and in continuous), the ones which contain a portion of the path joining some of the $\lfloor s_i n^{2/3}\rfloor$ or some of the $s_i$, are not small. This is what ensures that we will be able to couple them.}

% Synchronization and coupling: place oneself of the event of probability $1-\epsilon$, such that... all occur. This implies:
% \begin{itemize}
% 	\item the points $s_i$ and $s_i^n$ are all in not so small cc
% 	\item therefore, by Proposition~\ref{prop:large_merges} we can couple all the cc that contain part of a path;
% 	\item by the synchronisation (or since there is a bijection), we can couple the uniform at every merge.
% 	\item It follows that the distance in discrete and continuous are expressed similarly as a sum of distances in uniform trees between coupled points, coupled with sum in CRT of coupled masses, between coupled points.
% \end{itemize}

% section towards_a_convergence_argument (end)



% Make a graph on $[n]$, with the Prim ranks that would be isomorphic to the one with the $v_i$. Everything would be simpler:
% \begin{compactitem}
% 	\item The minimum spanning tree $M_n$ is isomorphic to $[n]$, with the edges $\{\ju_n(i), i\}$, $2\le i\le n$. 
% 	\item The portion minimum spanning forest at $p_n(\lambda)$: the same but with only the edges with slope $\slo_n(i)\ge \lambda$;
% 	\item The graph $G(n,p_n(\lambda))$ is the forest above, together with the edges $\{x n^{2/3},y n^{2/3}\}$ for all $(x,y,\lambda')\in \Xi_n$ with $\lambda'\le \lambda$. Let $(U_{ij})_{1\le i<j\le n}$ be i.i.d.\ uniform on $[0,1]$, and define $\lambda^n_{ij}=(nU_{ij}-1)n^{1/3}$. Let $\Xi_n$ be the point set 
% 	\[\{(in^{-2/3}, jn^{-2/3}, \lambda^n_{ij}): Z^{n,\lambda^n_{ij}}\cap \{i+1, i+2, \dots, j\}=\varnothing \}\]
% \end{compactitem}
% We have the merges from $X^{n,\lambda}$; the law of edges in the forest explicitly; and we need the law of the additional edges explicitly as well: given the knowledge up to $\lambda$, we know exactly which edges are present or not from $\Xi_n$; we can make $\Xi_n$ exactly a Poisson point process with intensity XXX on $[n]\times [n] \times \R$ (if some edge is already there, the point has no effect; and this would not genuinly affect the distribution).

% Some stuff are usually considered obvious
% \begin{compactitem}
% 	\item The structure of weights in $G(n,p)$ contidionall on the vertex sets; just need to verify that this is not messed up by the Prim order
% 	\item The 
% 	\item Remark on the fact that somes merges (the edge added) are measurable with respect to $(X^{n,\lambda})_{\lambda \in \R}$, but not all of them. In the continuous version, this information will totally vanish.
% \end{compactitem}

% subsection discrete_preliminaries (end)

% \subsection{Ideal forests} % (fold)
% \label{sub:ideal_forests}

% % subsection subsection_name (end)

\subsection{A global coupling and ideal forests} % (fold)
\label{sub:global_coupling}

We are now ready to define the probability space on which we will work. By iterative applications of Skorohod's representation theorem, we can find a probability space in which we have the following almost sure convergences, as $n\to\infty$:
\begin{compactitem}
	\item $(X^{n,\lambda})_{\lambda \in \R}\to (X^{\lambda})_{\lambda\in \R}$;
	\item $\Xi_n \to \Xi$; 
	\item $\Merge_n((X^{n,\lambda})_{\lambda\in \R}) \to \Merge(X)$.
\end{compactitem}
\medskip

Our starting point is the following: for the discrete objects, we consider the Kruskal forest $K(n,p)$ and random graphs $G(n,p)$ that are constructed from $(X^{n,\lambda})_{\lambda\in \R}$, $\bU$, and $\Xi_n$, which also define the metric space $(M_n,d_n)$. The continuous objects are those built from $X$, $\bU$ and $\Xi$, in particular the metric $d$ on $\R_+$. In the following, we shall identify the label and the Prim ranks to ease the discussion. 

These objects are crucial for us, and we will show that their macroscopic structures are similar. Rather than trying to couple details at the scale $\delta n^{2/3}$ in the discrete, and $\delta$ in the continuous, we shall proceed as follows: both in the discrete and continuous setting, we can see the metric spaces at some given time $\lambda$ (that is $K(n,p_n(\lambda))$ and $G(n,p_n(\lambda))$ in discrete, and the metric spaces induced by the intervals of $\R_+\setminus Z^\lambda$ in continuous) as combining together the metric spaces that were already present far in the past, say at some time $\underline \lambda<\lambda$. We will never look any further in time, and replace the metrics in the connected components at time $\underline \lambda$ by some idealization. In general, the distribution will be incorrect, but we will ensure that $\underline \lambda$ can be chosen far enough for the distributions to be exact (or close enough) on an event of arbitrarily large probability. Observe that, this modification at time $\underline \lambda$ provides a coupling at all times $\lambda>\underline \lambda$ simultaneously. 

Fix any two points $s_1,s_2\in (0,\infty)$ and define $s_i^n=\lfloor s_i n^{2/3}\rfloor$, $i=1,2$. There is always some deterministic $\overline \lambda$ large enough such that $s_1^n$ and $s_2^n$ lie in the same connected component of $K(n,p_n(\overline \lambda))$ for $n$ large enough with probability close to one; the path between $s_1^n$ and $s_2^n$ we refer to is the one in this connected component (and at any larger time). For any $\lambda\in \R$, let $J^n_\lambda(s_1,s_2)$ denote the collection of ranks of the connected components of $G(n,p_n(\lambda))$ that contain some node on the path between $s_1^n$ and $s_2^n$; $j\in J^n_\lambda(s_1,s_2)$ means that the $j$th largest connected component of $K(n,p_n(\lambda))$ contains some node of the path between $s_1^n$ and $s_2^n$. Similarly, let $J_\lambda(s_1,s_2)$ be the collection of indices of the intervals $(\gamma^\lambda_j)_{j\ge 1}$ obtained as $\R_+\setminus Z^\lambda$ which contain part of $\llbracket s_1, s_2 \rrbracket$. By construction, any of the connected components at time $\lambda$ are traversersed by a single portion of the path, between two points that we will denote by $a_j^n$, $b^n_j$ and $a_j, b_j$ respectively. 
Then, we have the following exact decompositions:
\begin{align}\label{eq:dist_decomp_exact-disc}
d_n(s_1^n,s_2^n) = \sum_{j\in J_\lambda^n(s_1,s_2)} d_n(a_j^n, b_j^n) + \#J_\lambda^n(s_1,s_2)-1\,,
\end{align}
and 
\begin{align}\label{eq:dist_decomp_exact-cont}
d(s_1,s_2)=\sum_{j \in J_\lambda(s_1,s_2)} d(a_j,b_j)\,.
\end{align}

We will simply replace the distances in the components at time $\lambda$ by what they should be in an ideal situation; for now, we are only interested in the definition, the verifications will come later. 
With this goal in mind, let us suppose our probability space contains the following sequences of random variables. 
Let $(V_j)_{j\ge 1}$ be i.i.d.\ random variables uniform on $[0,1]$. For each $m\ge 1$, let $F_m$ denote the distribution function of the distance $D_m$ between two independent uniformly random points in a uniformly random labelled tree on $m$ nodes. Then, for each $m\ge 1$, $\bar D_j(m)=m^{-1/2} F_m^{-1}(V_j)$. This provides a sequence of random variables where each term $\bar D_j(m)$ is distributed like $m^{-1/2} D_m$, and that converges almost surely as $m\to\infty$ to a Rayleigh random variable $\bar R_j$ with density $xe^{-x^2/2}$ on $\R_+$ (see, e.g., \cite{Aldous1991b} for the convergence in distribution). 

The objective is to control the matrix of pairwise distances between multiple points, and our new approximation of the distance will depend on the entire set of points. Let $\bs=(s_1,s_2,\dots, s_k)\in \R_+^k$. We will only replace the distance in the connected components that only contain a single portion of paths between these points; in all the other components, which contain branch points of the collection of paths between the elements of $\bs$, we will keep the distance unchanged. Let 
\[J^n_\lambda(s_p,s_q; \bs) = J^n_\lambda(s_p,s_q) \setminus \bigcup_{i<j, i\ne p, j\ne q} J^n_\lambda(s_i,s_j)\,,\]
and similarly, define the continuum analog by
\[J_\lambda(s_p,s_q; \bs) = J_\lambda(s_p,s_q) \setminus \bigcup_{i<j, i\ne p, j\ne q} J_\lambda(s_i,s_j)\,.\]
Let $(n^{2/3}|\gamma_j^{n,\lambda}|)_{j\ge 1}$ denote the collection of sizes of the connected components at time $\lambda$, just as $(|\gamma^\lambda_j|)_{j\ge 1}$ denotes the Lebesgue measures in the continuous setting. Define the following approximations, for $1\le p<q\le k$,  
\begin{align}\label{eq:distance_discrete_comp}
	\tilde d_n(s_p^n, s_q^n) 
	= &~ n^{1/3} \sum_{j\in J^n_{\lambda}(s_p,s_q;\bs)} |\gamma^{n,\lambda}_j|^{1/2} \bar D_j(n^{2/3}|\gamma^{n,\lambda}_j|)  \\ 
	& + \sum_{j\in J^n_\lambda(s_p,s_1)\setminus J^n_\lambda(s_p,s_1; \bs)} d_n(a_j^n,b_j^n) + \# J^{n}_{ \lambda}(s_1,s_2) - 1\,,\notag
\end{align}
and 
\begin{equation}\label{eq:distance_continuous_comp}
	\tilde d(s_p,s_q) = \sum_{j\in J_{\lambda}(s_p,s_q;\bs)} |\gamma_j^{\lambda}|^{1/2} \bar R_j
	+ \sum_{j\in J_{\lambda}(s_p,s_q)\setminus J_\lambda(s_p,s_q;\bs)} d(a_j,b_j)\,.
\end{equation} 


We first verify that these provide a suitable coupling of the pairwise distances between the $k$ points $s_1^n,s_2^n,\dots, s_k^n$ and $s_1,s_2,\dots, s_k$, respectively. 
\begin{prop}\label{pro:distribution_coupling}
Fix some compact interval $I\in (0,\infty)$. For any $\epsilon>0$, there exists $\lambda\in \R$ and an event $A$ of probability at least $1-\epsilon$, such that, for any $k$ i.i.d.\ uniform points $s_1,s_2, \dots, s_k \in I$, for all $n$ large enough, on the event $A$, we have
\[(\tilde d_n(s_p,s_q))_{1\le p<q\le k} \eqdist (d_n(s_p^n,s_q^n))_{1\le p<q\le k} 
\quad \text{and} \quad 
(\tilde d(s_p,s_q))_{1\le p<q\le k} \eqdist (d(s_p,s_q))_{1\le p<q\le k}\,.\]
\end{prop}
\begin{proof}There exists a $\lambda_1$ large enough that $I$ is contained in a single connected component at time $\lambda_1$: with Lemma~\ref{lem:position_Hlambda} in mind, let $\lambda_1$ be the smallest $\lambda$ for which $\sup I<2\lambda +1$ and $\exp(-c\lambda)<\epsilon/2$. This value being fixed, $I$ is contained in $[0,2\lambda_1+1]$ with probability at least $1-\epsilon/2$. 

Let $A=A_\lambda$ be the event that $\Xi$ does not contain any point in $[0,2\lambda_1+1]$ with time lower than $\lambda$. From the correspondence between the intensity of $\Xi$ and the area of $X^\lambda-\underline X^\lambda$, there exists $\lambda$ small enough that $A$ has probability at least $1-\epsilon$. The convergence of $\Xi_n$ to $\Xi$ implies that, on this event, for all $n$ large enough, $\Xi_n$ also has no point in $I$ with times before $\lambda$ (Proposition~\ref{pro:cyclic_edges}). 

We may choose $\lambda$ even smaller to ensure that, $|\gamma^\lambda_1|<\epsilon/(4k)$, so that, the probability that some point $s_i$, $1\le i\le k$, falls in an interval of $\R_+\setminus Z^\lambda$ that is not fully contained in $I$ is at most $\epsilon/(2|I|)$. When this occurs, conditionally on $s_i\in \gamma^\lambda_j$, the position $s_i$ is uniformly random in $\gamma^\lambda_j$. The same holds true for the discrete counterparts $s_i^n$ for all $n$ large enough. 

Now, on the event $A$, for all $n$ large enough, all the connected components of the random graph $G(n,p_n(\lambda))$ containing nodes with label at most $(2\lambda_1 +1)n^{2/3}$ are all trees, which are uniformly random. These are thus identical to the components in the Kruskal forest $K(n,p_n(\lambda))$. By Proposition~\ref{prop:random_forest} and Lemma~\ref{lem:dist_left-most-node} the points $a_j^n$ and $b_j^n$ are independent and uniformly random (their actual labels!) and independent of the component. Since the end points $s_i^n$ are themselves uniformly random in the connected component in which they lie, by the previous paragraph, this proves that, on $A$, the discrete approximation $\tilde d(s_p,s_q)$, $1\le p<q\le k$, has the same distribution as $d(s_p,s_q)$, $1\le p<q\le k$. 

The continuous analog follows from the calculations in Section~2.1 of \cite{AdBrGo2010} saying that, conditionally on having no point under the curve, an excursion under $\tilde \bn_\sigma$ is distributed according to $\bn_\sigma$, and is thus exactly a Brownian excursion; Brownian scaling and Remark~\ref{rem:one-point_function} saying that in $\CMT(\exc, \bU)$, the distance $d_\exc(0,V)$ between $0$ and a uniformly random point $V$ is Rayleigh distributed, which completes the proof.
\end{proof}

\subsection{Main proof of convergence} % (fold)
\label{sub:convergence}

Finally, we are ready to prove that, in the probability space defined in the previous section, we have convergence in probability of the pairwise distance. 
\begin{prop}\label{pro:convergence_distances}Fix $I$ a compact interval of $(0,\infty)$, and let $s_1,s_2,\dots, s_k$ be i.i.d.\ uniform points in $I$. For any $\epsilon,\delta>0$, there exists $\lambda\in \R$ such that, 
\[\limsup_{n\to\infty} \p{\sup_{1\le p<q\le k} \big|n^{-1/3}\tilde d_n(s_p^n,s_q^n)-\tilde d(s_p,s_q)\big|> \delta} \le \epsilon\,.\]	
\end{prop}
\begin{proof}
Fix any $\epsilon,\delta>0$.
Let us first deal with the portions of paths contained in connected components that are traversed by more than one path, and that we did not bother coupling. 
Consider the event $A$ in Proposition~\ref{pro:distribution_coupling} and the corresponding value $\lambda_1$ for $\lambda$ which ensures that $\pc{A^c}\le \epsilon/4$. By Lemma~\ref{lem:global_asympt_small_lambda}, there exists $\lambda_2$ such that, for all $\lambda\le \lambda_2$ and all $n$ large enough, the probability that the maximum diameter of a connected component of $G(n,p_n(\lambda))$ is larger than $n^{1/3}\delta/(3k)$ is at most $\epsilon/4$. 
Furthermore, on the event $A$, each one of the $k-1$ portions of continuum paths in the intervals $\gamma_j^\lambda$ which contain more than one portion has a length stochastically dominated by $|\gamma_j^\lambda|\bar R_j$ (or the diameter of the corresponding CRT). We can choose $\lambda_3$ small enough such that the probability that any of them is greater than $\delta/(3k)$ is at most $\epsilon/4$. Fix $\lambda=\min\{\lambda_1,\lambda_2,\lambda_3\}$. 
Finally, by Proposition~\ref{pro:local_asympt_small_lambda}, for this value of $\lambda$, there is some $\delta'>0$ small enough such that, with probability at least $1-\epsilon/4$ all the connected components $C^{n,\lambda}_j$, $j\in J^n_\lambda(s_p,s_q)$, $1\le p<q\le k$, contain at  least $\delta'n^{2/3}$ nodes. The probability that either of these bad events occur is at most $\epsilon$, and we now suppose we work on the event $A'$ that none occurs. 

On the event $A'$, we have from \eqref{eq:distance_discrete_comp} and \eqref{eq:distance_continuous_comp}, for any $1\le p<q\le k$, 
\begin{align*}
	\big|n^{-1/3}\tilde d_n(s_p^n,s_q^n)-\tilde d(s_p,s_q)\big|
	& \le  \Bigg| \sum_{j\in J^n_\lambda(s_p,s_q;\bs) } n^{-1/3} |\gamma^{n,\lambda}_j|^{1/2} \bar D_j(n^{2/3}|\gamma^{n,\lambda}_j|) - \sum_{j\in J_\lambda(s_p,s_q;\bs) }|\gamma_j^{\lambda}|^{1/2} \bar R_j\Bigg|\\
	& \quad + n^{-1/3} \# J^n_\lambda(s_p,s_q) + 2\delta/3\,.  
\end{align*}
Since the $\#J^n_\lambda(s_p,s_q)$ are all tight by the proof of Proposition~\ref{pro:local_asympt_small_lambda}, we only need to deal with the first term the right-hand side above. 

We claim that the fact that all discrete connected components $C^{n,\lambda}_j$, for $j\in J^n_\lambda(s_p,s_q)$ for some $1\le p<q\le k$ contain at least $\delta'n^{2/3}$ nodes, the convergence of the merge events implies that, for all $n$ large enough, we have $J^n_\lambda(s_p,s_q)=J_\lambda(s_p,s_q)$ for every $1\le p<q\le k$. The reason is the following: (1) for all $n$ large enough, for every $i$, if $s_i\in \gamma^\lambda_j$, then $s_i^n\in C^{n,\lambda}_j$, because $\{s_1,\dots, s_k\}$ and $Z^\lambda$ are almost surely disjoint. (2) The merges of large connected components do converge because $\Merge((X^{n,\lambda})_{\lambda\in \R})\to \Merge(X)$. (3) The points random points constructed in the discrete and continuuous model for matching merges use the same uniforms by Lemma~\ref{lem:code_cv}. It follows that, for $n$ large enough, these points themselves end up in matching pair of discrete and continuum components. (4) The number of such merges is finite (the $\#J^n_\lambda(s_p,s_q)$, $J_\lambda(s_p,s_q)$ are tight). As a consequence, for all $n$ large enough, we are lead to bounding
\[\p{\Bigg|
\sum_{j\in J_\lambda(s_p,s_q;\bs)} n^{-1/3} |\gamma^{n,\lambda}_j|^{1/2} \bar D_j(n^{2/3}|\gamma^{n,\lambda}_j|) - |\gamma_j^{\lambda}|^{1/2} \bar R_j \Bigg| > \delta/3}\,,\]
but we our coupling precisely ensures that every single term of the sum converges almost surely to zero. This completes the proof.
\end{proof}

% subsection convergence (end)

\subsection{Remaining proofs of convergence} % (fold)
\label{sub:remaining_proofs}

Finally, we rely on the results of the previous section to complete the proofs of the remaining results, namely that of Theorem~\ref{thm:limit_mst_surplus} about the MST of a connected graph with given surplus, and Theorem~\ref{thm:dynamics_X} about the dynamics for the limit random graph and Kruskal processes.

Before going further, let us discuss the types of convergence. Proposition~\ref{pro:convergence_distances} 
implies the convergence of the distribution of the matrix of pairwise distances between any finite number of points, and may thus be used to prove convergence in the Gromov--Prokhorov (GP) sense (Theorem~5 of \cite{GrPfWi2009a}): indeed, for any $\lambda$, restriction of the $d$ to any interval $\gamma^\lambda_j$, $j\ge 1$, is the limit of the metric of the discrete minimum on $C^{n,\lambda}_j$. The reason why this suffices to also prove convergence in the sense of Gromov--Hausdorff--Prokhorov (GHP) is that we actually already know that the sequences are tight for GHP (\cite{AdBrGoMi2013a,AdBrGo2012a}), and that the limit we construct has a mass measure which has full support because of Proposition~\ref{pro:length_measure} (see \cite{AtLoWi2016a}). In the following, we thus only discuss GP convergence.



\begin{proof}[Proof of Theorem~\ref{thm:dynamics_X}]\emph{i)} Since the coupling is global, the proof of the joint convergence of the Kruskal forest $({\frak F}^{n,\lambda_1}, \dots, {\frak F}^{n,\lambda_k})$ at times $\lambda_1<\lambda_2<\dots<\lambda_k$ is an immediate consequence of Proposition~\ref{pro:convergence_distances}, and the above discussion about the GHP versus GP convergence. The connected components at time $\lambda_i$ correspond to the intervals of $\R_+\setminus Z^{\lambda_i}$, equipped with the metric induced by $d$.

\noindent \emph{ii)} For the same reason, the proof of the joint convergence $({\frak G}^{n,\lambda_1}, \dots, {\frak G}^{n,\lambda_k})$ would be complete once we have an analog of Proposition~\ref{pro:convergence_distances} for the random graph at a fixed time. Proving this amounts to verifying that the joint convergence of the minimum spanning tree and of $\Xi_n$ is sufficient to guarantee the convergence of the end points of every single surplus edge. 

Once we have convergence of the end points of the edges, the techniques in \cite{AdBrGo2012a} imply the convergence of the graph. Proving that we indeed have convergence of the locations of the end points of edges is not immediate because the function $d(x,y)$ is not continuous in either $x$ or $y$. However, we can find a small $\underline \lambda\in \R$ such that the points appear between the correct connected components at time $\underline \lambda$ for all $n$ large enough (almost surely, since the points have a diffuse distribution). Since the diameter of these components at time $\underline \lambda$ may be made arbitrarily small by choice of $\underline \lambda$, we do have convergence of the locations of the end points. This completes the proof of the sequence of graphs, in the product topology for a fixed $\lambda$. The extension to a vector of $(\lambda_1,\dots, \lambda_k)$ is immediate using the same arguments as above. 
\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:limit_mst_surplus}]
Consider the probability space from above, and fix some interval $\gamma^\lambda_i$ of $\R_+\setminus Z^\lambda$. Recall the discrete and continuum surplus defined in \eqref{eq:discrete_surplus} and \eqref{eq:continuum_surplus}, respectively. Furthermore, $\surp^\lambda_i$ is a Poisson random variable with parameter the area of the process $X^\lambda-\underline X^\lambda$ on $\gamma^\lambda_i$. It thus follows from the calculations in Section~2.1 of \cite{AdBrGo2010} that, 
\begin{align*}
\E{f((X^\lambda_{t_0+t}-\underline X^\lambda_{t_0+t})_{0\le t\le \sigma})~\Big|~\gamma_i^\lambda=(t_0, t_0+\sigma),\surp_j^\lambda=s} 
%= \int f(\omega) \frac{(\int \omega(u)du)^s}{\int (\int \omega_1(u)du)^s \bn_{\sigma}(d\omega_1)} \bn_{\sigma}(d\omega)\,. 
&= \frac{\Ec{f(\exc_\sigma) \cdot (\int_0^\sigma \exc_\sigma(u)du)^s}} {\Ec{(\int_0^\sigma \exc_\sigma(u) du)^s}}
\end{align*}
where $\exc_\sigma$ is a Brownian excursion of duration $\sigma$. By definition, the right-hand side above is nothing else than $\Ec{f(\exc_\sigma^{(s)})}$. Furthermore, on the event that $\surp^\lambda_i=s$, by Corollary~\ref{cor:convergence_surplus}, we have $\surp^{n,\lambda}_i=s$ for all $n$ large enough. Therefore, up to a trivial relabelling, $C^{n,\lambda}_i$ is a uniformly random connected component with surplus $s$ and size $\gamma^{n,\lambda}_i$. Since each of the values for $\surp^{\lambda}_i$ has positive probability, Theorem~\ref{thm:limit_mst_surplus} follows from Proposition~\ref{pro:convergence_distances}, and the discussion about the strengthening to Gromov--Hausdorff--Prokhorov convergence. 
\end{proof}

Finally, we prove our main result about the entire minimum spanning tree. In \cite{AdBrGoMi2013a}, it is proved that the scaling limit of the minimum spanning tree can be constructed as the limit as $\lambda\to\infty$ of the scaling limit of the minimum spanning tree of the largest connected component of the random graph at $p_n(\lambda)$. Here, we use the limit as $\lambda \to \infty$ of the connected component containing the vertex with Prim order $\lfloor n^{2/3}\rfloor$. We now verify that this coincides with our definition, which uses a connected component $H_\lambda$containing the point $1$ and the measured metric space $(H_\lambda,d, \hat \mu_\lambda)$, $\hat \mu_\lambda$ is the (image of the) probability measure which is proportional to Lebesgue measure on $H_\lambda$. At this point, this should be essentially straightforward.

\begin{proof}[Proof of Theorem~\ref{thm:limit_mst_Kn}]
Let $\cE^\star_\lambda$ be the event that the largest connected component of $\R_+\setminus Z^\lambda$ contains the point $1$. Observe that, for all $\lambda\ge 2$, with $R_\lambda=\sup H_\lambda$,
\begin{align*}
\pc{\cE^\star_\lambda}
%& = \pc{E^\lambda, |\gamma^\lambda_2|\le 1} + \pc{E^\lambda, |\gamma^\lambda_2|\ge 1} \\ 
%& \ge \pc{E^\lambda, |\gamma^\lambda_2|\le 1}\\ 
& \ge \pc{R_\lambda >2 \lambda-1, |\gamma^\lambda_2|\le 2}\\
& \ge 1 - \pc{R_\lambda\le 2\lambda - 1} - \pc{|\gamma^\lambda_2|\ge 2}.
\end{align*}
Lemma~\ref{lem:position_Hlambda} implies that the first probability in the right-hand side above tends to zero as $\lambda\to\infty$. The same holds for the second one, see for instance, Proposition~5.3 of \cite{AdBrGoMi2019a} which says that $|\gamma^\lambda_2|$ is $O(\lambda^{-2} \log \lambda)$ in probability. This also easily follows from Lemma~\ref{lem:sizes_fragments-k} \emph{i)}: indeed, for any natural number $i\ge 1$, on the event that $R_\lambda> i^3$, we have (with the notation of Section~\ref{sub:statistics_small_components})
\[|\gamma^\lambda_2| \le 1 + \sup_{k\ge i}\sup\{m_{\lambda'}: \lambda'\in \Lambda_k\}\,,\]
which is at most $1+i^{-5}$ with probability at least $1-O(i^{-1/4})$. This implies $\pc{|\gamma^\lambda_2|\ge 2} = O(\lambda^{-1/12})$, and in turn that $\pc{\cE^\star_\lambda}\to 1$ as $\lambda \to \infty$. By Proposition~\ref{pro:convergence_distances}, $(H_\lambda, d, \hat \mu_\lambda)$ is the Gromov--Prokhorov limit (in distribution) of the minimum spanning tree of the connected component containing the vertex with Prim order $n^{2/3}$. However we know by the results of \cite{Ad2013a} that the sequence of rescaled minimum spanning trees converge for the Gromov--Hausdorff--Prokhorov topology, so that the convergence actually holds for GHP. Together with the fact that $\pc{\cE^\star_\lambda}\to 1$ as $\lambda \to \infty$, this proves that $(\sM, d, \mu)$ has the same distribution as $(\sM', d', \mu')$ constructed in \cite{Ad2013a}.	
\end{proof}

% {\red 
% \begin{prop}The measured metric space $\CMT(X, \bU)$ is indeed distributed like $(\sM',\delta',\mu', \rho')$ constructed in $\cite{AdBrGoMi2013a}$
% \end{prop}
% \begin{proof}
% \end{proof}
% }

% subsection remaining_proofs (end)

% subsection the_coupling_and_the_distribution_of_ (end)
