    %%
%% This is file `sample-acmtog.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmtog')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmtog.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%

\documentclass[sigconf]{acmart}
\acmConference[ESEC/FSE 2023]{The 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering}{3 - 9 December, 2023}{San Francisco, USA}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{none}
\settopmatter{printacmref=false}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}


%%
%% These commands are for a JOURNAL article.
\acmJournal{TOG}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
% \citestyle{authoryear}
%\usepackage[margins]{trackchanges}
\usepackage{lipsum}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}
\usepackage{listings}
\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  breaklines=true,
  showstringspaces=false,
  frame=lines,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\ttfamily,
  moredelim=[il][\textcolor{pgrey}]{\$\$},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}
\usepackage{xcolor}
% \usepackage{color}
\usepackage{makecell}
\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}
\definecolor{applegreen}{rgb}{0, 0.5, 0.0}
\usepackage[flushleft]{threeparttable}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{tcolorbox}
\usepackage{multirow}
\usepackage{array}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{soul}
\usepackage[]{natbib}

\definecolor{codeblue}{RGB}{20,76,134}
\definecolor{codegreysh}{RGB}{114,136,223}
\definecolor{evosuiteprefix}{RGB}{51,51,255}
% \definecolor{evosuiteprefix}{RGB}{102,0,204}
\lstdefinestyle{listingstyle}{
    language=Java,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\bf\ttfamily\color{codeblue},
    stringstyle=\color{codegreysh},
    moredelim=[l][\bf\ttfamily\color{red}]{///},
    moredelim=[l][\bf\ttfamily\color{orange}]{//,},
    moredelim=[s][\bf\ttfamily\color{evosuiteprefix}]{/**}{**/}
}

% TO DISABLE THE TEXT COMMENTS:
%\newcommand{\cmt}[2]{}
\newcommand{\cmt}[2]{{\bf }{\bf #1} {#2}{\bf }}

\newcommand{\anto}[1]{\cmt{\color{blue}{Anto}}{\color{red} {#1}}}
\newcommand{\soneya}[1]{\cmt{\color{teal}{Soneya}}{\color{teal} {#1}}}
\newcommand{\matt}[1]{\cmt{\color{red}{Matt}}{\color{olive} {#1}}}
\newcommand{\se}[1]{\cmt{\color{orange}{Seba}}{\color{orange} {#1}}}
\newcommand{\add}[1]{\color{black}{#1}\color{black}}
\newcommand{\ignore}[1]{}

% Settings for tcolorbox (boxes for RQ findings)
\tcbset{
        left=1mm,
        right=1mm,
        top=1mm,
        bottom=1mm
        % boxrule=0.4pt,
        % colback=red!5!white,
        % boxrule=0.1pt
}

% space savers
% \usepackage[skip=4.5pt plus1pt, indent=0pt]{parskip}
% \renewcommand{\arraystretch}{1.2}
% \makeatletter
%  \renewcommand\section{\@startsection{section}{1}{\z@}%
%                         {4\p@ \@plus 2\p@ \@minus 2\p@}%
%                         {3\p@ \@plus 2\p@ \@minus 2\p@}%
%                         {\normalfont\large\bfseries\boldmath
%                          \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
%  \renewcommand\subsection{\@startsection{subsection}{2}{\z@}%
%                         {2\p@ \@plus 4\p@ \@minus 4\p@}%
%                         {4\p@ \@plus 2\p@ \@minus 2\p@}%
%                         {\normalfont\normalsize\bfseries\boldmath
%                          \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
%  \renewcommand\subsubsection{\@startsection{subsubsection}{3}{\z@}%
%                         {-4\p@ \@plus -4\p@ \@minus -4\p@}%
%                         {-1.5em \@plus -0.22em \@minus -0.1em}%
%                         {\normalfont\normalsize\bfseries\boldmath}}
% \makeatother

\makeatletter
\renewcommand\section{\@startsection{section}{1}{\z@}%
    {-.5\baselineskip \@plus -.2\p@ \@minus -.2\p@}% before \@plus -2\p@ <<<
    {.10\baselineskip}%
    {\ACM@NRadjust\@secfont}}

\renewcommand\subsection{\@startsection{subsection}{2}{\z@}%
    {-.5\baselineskip \@plus -.2\p@ \@minus -.2\p@}% before \@plus -2\p@<<<
    {.10\baselineskip}%
    {\ACM@NRadjust\@subsecfont}}

\renewcommand\subsubsection{\@startsection{subsubsection}{2}{\z@}%
    {-.2\baselineskip \@plus -.2\p@ \@minus -.2\p@}% before \@plus -2\p@<<<
    {.05\baselineskip}%
    {\ACM@NRadjust\@subsubsecfont}}
\makeatother

% \widowpenalty=50
% \clubpenalty=50

% \usepackage{microtype}

% % Reduce space around equations and figures
\setlength{\abovecaptionskip}{2pt plus 1pt minus 1pt}
\setlength{\belowcaptionskip}{2pt plus 1pt minus 1pt}
\setlength{\textfloatsep}{2pt plus 1pt minus 2pt}
% \setlength{\dbltextfloatsep}{3pt plus 1pt minus 1pt}

\setlength{\belowcaptionskip}{-2pt}
% \renewcommand{\baselinestretch}{0.98} 

%%
%% end of the preamble, start of the body of the document source.
\fussy
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Neural-Based Test Oracle Generation: A Large-scale Evaluation and Lessons Learned}



%Beyond the Hype: An Evaluation of Neural-Based Test Oracle Generation and Lessons Learned}

%Neural-based Test Oracle Generation Technique:\\ Lessons from a Replication}

%

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Soneya Binta Hossain}
\email{sh7hv@virginia.edu}
\affiliation{%
  \institution{University of Virginia}
  \city{Charlottesville}
  \state{Virginia}
  \country{USA}
}

\author{Antonio Filieri}
\email{afilieri@amazon.com}
\affiliation{%
  \institution{Amazon Web Services}
  \city{Santa Clara}
  \state{CA}
  \country{USA}
}

\author{Matthew B. Dwyer}
\email{matthewbdwyer@virginia.edu}
\affiliation{%
  \institution{University of Virginia}
  \city{Charlottesville}
  \state{Virginia}
  \country{USA}
}

\author{Sebastian Elbaum}
\email{selbaum@virginia.edu}
\affiliation{%
  \institution{University of Virginia}
  \city{Charlottesville}
  \state{Virginia}
  \country{USA}
}

\author{Willem Visser}
\email{vissie@amazon.com}
\affiliation{%
  \institution{Amazon Web Services}
  \city{Santa Clara}
  \state{CA}
  \country{USA}
}



\begin{abstract}
Defining test oracles is crucial and central to test development, but manual construction of oracles is expensive. \add{While recent neural-based automated test oracle generation techniques have shown promise, their real-world effectiveness remains a compelling question requiring further exploration and understanding}. This paper investigates the effectiveness of TOGA, a recently developed neural-based method for automatic test oracle generation by Dinella et al.\cite{10.1145/3510003.3510141}. TOGA utilizes EvoSuite-generated test inputs and generates both exception and assertion oracles. In a \texttt{Defects4j} study, TOGA outperformed specification, search, and neural-based techniques, detecting 57 bugs, including 30 unique bugs not detected by other methods. To gain a deeper understanding of its applicability in real-world settings, we conducted a series of external, extended, and conceptual replication studies of TOGA.

In a large-scale study involving 25 real-world Java systems, 223.5K test cases, and 51K injected faults, 
we evaluate TOGA's ability to improve fault-detection effectiveness relative to the state-of-the-practice and the state-of-the-art. We find that TOGA misclassifies the type of oracle needed 24\% of the time and that when it classifies correctly
around 62\% of the time it is not confident enough to generate any assertion oracle. When it does generate an assertion oracle, more than 47\% of them are false positives, and the true positive assertions
only increase fault detection by 0.3\% relative to prior work. \add{These findings expose limitations of the state-of-the-art neural-based oracle generation technique, provide valuable insights for improvement, and offer lessons for evaluating future automated oracle generation methods.}

\end{abstract}


% \begin{CCSXML}
% <ccs2012>
%    <concept>
%        <concept_id>10011007</concept_id>
%        <concept_desc>Software and its engineering</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%    <concept>
%        <concept_id>10011007.10011074.10011099.10011102.10011103</concept_id>
%        <concept_desc>Software and its engineering~Software testing and debugging</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%  </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Software and its engineering}
% \ccsdesc[500]{Software and its engineering~Software testing and debugging}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{automated testing, test oracles, bug detection}

%\received{20 February 2007}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\blfootnote{*\textbf{Part of the work was done while interning at AWS}}


Testing is the standard method for validating that a program meets its requirements.
To test a program a \textit{test input} is passed to the program and its output
is judged by a \textit{test oracle} that asserts a property of the expected program behavior on the given input~\cite{myers2011art}.
A test suite is comprised of a set of input-oracle pairs, called \textit{test cases}.
%, and a rich literature has been developed to assess their quality.
The key value of a test suite lies in its ability to detect faults. 
%Recent work has proven the value of mutation testing~\cite{andrews2005mutation} as
%a scalable and highly-effective means of measuring test suite fault-detection power~\cite{beller2021would,petrovic2021practical,petrovic2021does}.
Fault detection relies on the choice of good test inputs -- to ensure that any faulty statements
are executed -- and, for each input, a test oracle that can detect error states introduced
by faults and judge them against necessary conditions for correctness~\cite{voas1992pie}.

A rich literature on test adequacy metrics exists to assess the fault exposure ability of test inputs
~\cite{weyuker1988evaluation,chilenski1994applicability} and a growing literature exists on the
importance of strong test oracles for fault detection~\cite{hossain2023measuring, staats2011programs,whalen2013icse,schuler2013checked,10.1145/2786805.2786858,jahangirova2016test,hossain2022brief}.
Unfortunately, manual development of high-quality test suites is extremely costly, time consuming, and error-prone~\cite{jahangirova2016test,6963470}.
Consequently researchers have focused on methods for automating the generation of test cases.
They have been particularly successful in developing a range of cost-effective methods
for generating high-quality test inputs~\cite{manes2019art,chen2018systematic,bohme2017directed,zalewski2017american,sen2005cute,lakhotia2010empirical,godefroid2005dart,ali2009systematic,mao2016sapienz,fraser2011evosuite}.
Automatically generating effective test oracles has proven more challenging and many of these techniques have
used either \textit{implicit} oracles which use checks enforced by the runtime system, such as
null pointer dereference exceptions, \textit{differential} oracles which compare the 
output of two programs or program versions against each other~\cite{mckeeman1998differential}, or 
\textit{metamorphic} which check for known relations between mutation of the inputs 
and corresponding changes of the outputs~\cite{metamorphicTesting2016}. 

% To unleash the full potential of automated test generation techniques, 
To unleash their full potential, 
test generation techniques must go beyond implicit, differential, and metamorphic oracles, pairing test inputs with input value-specific oracle assertions that capture intended program behavior.  
Researchers have explored the use of natural language processing (NLP) and pattern matching
techniques to generate test oracles based on code comments and text documentation~\cite{10.1145/3213846.3213872,10.1145/2931037.2931061,blasi2021memo,6227137,6200082}. 
Such techniques are able to infer \textit{assertion oracles} that check actual program output against expected output, and \textit{exception oracles} that capture intended exceptional behavior of the program under test. 
More recently neural techniques have been applied to generate test oracles using
a transformer-based model that learns from the method under test and developer-written test cases~\cite{watson2020learning,tufano2022generating,tufano2020unit}. 
Following on this work, the TOGA~\cite{10.1145/3510003.3510141} neural-based test oracle generator  was recently found to outperform prior work in detecting real faults.    
We explain TOGA in detail in \S\ref{toga}, but briefly:
given a method under test, 
a test \textit{prefix} which is a code fragment that includes the test input and a sequence of operations to drive the program under test into a desired execution state,
and optional documentation strings, TOGA predicts whether an exception oracle or an  assertion oracle should be generated, and in the latter case, it generates the predicate within the assertion oracle.
On a study performed on the \texttt{Defects4j} benchmark~\cite{just2014defects4j} consisting of 835 bugs from 17 Java applications, TOGA was reported to outperform other neural-based assertion generation techniques~\cite{tufano2020unit,tufano2022generating,watson2020learning} by detecting 57 bugs, of which 30 unique bugs not detected by any other competing techniques.


%
% \add {
% TOGA's ability to generate test oracles using given test prefixes, along with the promising results shown in the TOGA paper, 
% suggested 
% make it ideal for integration with an industrial test case generation tool, which was our initial motivation. 

% TOGA's results on Defect4j 
% To gain deeper insights, we started with a thorough replication study, particularly motivated by the observation that, despite the initial promise of AI/ML-based automated software testing, a lack of generalizability often leads to a significant drop in accuracy when it comes to real-world data \cite{chakraborty2021deep, di2018detecting}. 

% As no subsequent study has evaluated TOGA’s effectiveness in real-world scenarios and evaluation settings, we conducted this study with a focus on addressing two critical concerns: first, TOGA's ability to streamline development by minimizing test oracle creation costs, and second, its proficiency in detecting bugs that conventional test oracles, such as implicit oracles, or those generated by the state-of-the-art method (EvoSuite), fail to identify}.


\ignore{Despite the promising initial results of AI/ML-based automated software testing, subsequent studies have highlighted significant performance drops when applied to real-world data \cite{chakraborty2021deep, di2018detecting}. This raises concerns about the true effectiveness of neural-based automated test oracle generation techniques in real-world scenarios and evaluation settings, which remain largely unexplored. To bridge this gap, in this paper, we aim to address two critical concerns: first, the ability of TOGA to streamline development by minimizing test oracle creation costs, and second, its proficiency in detecting elusive bugs that cannot be identified by conventional implicit test oracles. In summary, we intend to uncover both the strengths and weaknesses of the current state-of-the-art learning-based technique, thereby laying a solid foundation for future refinement and contributing to the broader development of trustworthy and effective AI/ML-based automated testing.} 

\ignore{To this end, we conduct a series of 3  external replications of TOGA with the goals of validating its original fault detection findings, characterizing its precision, i.e., how frequently it generates correct oracles, measuring the fault-detection power of the generated correct oracles and more broadly obtaining a better understanding of its generalizability to a broader set of programs. To distinguish our research questions (RQ) from those in the TOGA paper, we subscript references to the latter with $T$.}


\add{While the original evaluation of TOGA was focused mostly on the \texttt{Defects4j} benchmark, in this work, we set to evaluate its effectiveness on larger benchmarks and with perspectives and methods that more closely resemble those of industrial practice. }
To this end, we conduct a series of three external replications of TOGA with the objectives of validating its original fault detection findings, characterizing its precision (i.e., the frequency of generating correct oracles), measuring the fault-detection power of the generated correct oracles, and broadening our understanding of its generalizability to a wider set of programs. \add{

We focus our study on TOGA + EvoSuite because 1) TOGA has been shown to outperform other learning-based techniques, e.g., seq2seq \cite{tufano2022generating}, Athena Test~\cite{tufano2020unit}, establishing itself as the current state-of-the-art neural-based technique; and 2) TOGA relies on EvoSuite prefixes for test oracle generation. In our replication study, we adhered to this design by using EvoSuite, thereby minimizing potential construct validity threats. Notably, EvoSuite itself has been demonstrated more effective than its alternatives in reducing false positives, flaky tests, and smelly tests, and is recognized as the state-of-the-art~\cite{7372009,almasi2017industrial,panichella2021sbst,devroey2020java,virginio2020empirical}.


% We focus our study on TOGA + EvoSuite for the following reasons: 1) TOGA has been shown to outperform other learning-based techniques, e.g., seq2seq \cite{tufano2022generating}, Athena Test~\cite{tufano2020unit}, establishing itself as the current state-of-the-art neural-based technique; 2) TOGA requires the use of EvoSuite prefixes for test oracle generation. In our replication study, we adhered to this design by using EvoSuite, thereby minimizing potential construct validity threats; 3) most importantly, our primary focus is to evaluate TOGA, the state of the art neural-based test oracle generation technique relative to the state-of-the-art in automated test oracle generation. EvoSuite notably surpasses other methods in reducing false positives, flaky tests, and smelly tests, and is recognized as the state-of-the-art~\cite{7372009,almasi2017industrial,panichella2021sbst,devroey2020java,virginio2020empirical}.
}

\ignore{EvoSuite is widely considered the state-of-the-art for test oracle generation, significantly outperforming other methods in terms of reducing false positives, flaky tests, tests with smells, and improving real-world bug detection \cite{7372009,almasi2017industrial,panichella2021sbst,devroey2020java,virginio2020empirical}; 2) TOGA has been shown to outperform other learning-based techniques, e.g., seq2seq \cite{tufano2022generating}, Athena Test~\cite{tufano2020unit}, establishing itself as the current state-of-the-art neural-based technique; and
3) most importantly, our primary goal is to assess the state-of-the-art neural-based test oracle generation technique by evaluating its real-world cost-effectiveness relative to the overall state-of-the-art EvoSuite. Therefore, we invested in a larger scale study focused in this way.}

To distinguish our research questions (RQ) from those in the TOGA paper, we subscript references to the latter with $T$.

\textbf{RQ1 (Exact Replication of RQ3$_{T}$):} \add{In RQ1, our hypothesis is that RQ3$_{T}$ was well-designed and executed, therefore, we should obtain similar results}. To this end, we conducted an \textit{exact} replication of the \texttt{Defects4j} fault study as described in the original paper. \ignore{However, we refined the procedure by carefully examining each reported bug to assess whether the bug findings can be attributed to the test oracles generated by TOGA. This rigorous analysis allowed us to assess the credit given to TOGA for its bug-finding capabilities.}

\ignore{To
corroborate the reported TOGA findings, but with a refined procedure to assess the credit given to TOGA for the bug finding, we began with an \textit{exact} replication of the \texttt{Defects4j} fault study from the original paper. The refined procedure involved carefully examining each reported bug to determine whether its findings can be attributed to the test oracles generated by TOGA.}

\ignore{Our findings revealed that 38 of the 57 reported bugs by TOGA 
are already detected by 
%a TOGA-generated oracle that ``no exception is predicted'' (\S\ref{sec:rq1}). This is \textit{already} 
the implicit oracle of the Java run-time system and a default assumption of the JUnit test framework used by the \texttt{Defects4J} utilities.}

\add{We were able to obtain the same results. However, we found that the majority (67\%) of total reported bugs could  be identified by Java ``implicit oracle'' (i.e., exceptional behavior triggered by executing the test prefix alone).  Such prefixes
eliminate the need for test oracles generated by TOGA and led to an overestimation of TOGA's fault detection capability. An important lesson from this finding is that future experimental evaluation should include the implicit oracle as a baseline to correctly attribute the bug detection capabilities of generated oracles (\S\ref{sec:lessons}).}

\textbf{RQ2 (Conceptual Replication of RQ2$_{T}$):} 
This replication study evaluates TOGA's performance on a broader and newer set of inputs.\add{ We hypothesize that a new dataset would yield similar results to the original TOGA study, indicating its replicability (same method on new dataset)}. To this end, from 25 large-scale Java applications, we constructed a new dataset with a total of 223k test cases -- each having a test prefix and a single assertion or exception oracle, whereas RQ2$_{T}$ studied 61k inputs from a held-out test set. 
 
\ignore{selected 25 Java applications consisting of 8 artifacts from the EvoSuite benchmark~\cite{fraser2011evosuite} and 17 Apache Commons packages that comprise  more than 271K SLOC. Since TOGA requires EvoSuite generated test prefixes, we generate 57K test cases using EvoSuite, which  resulted in 223K \textit{decomposed} test cases -- each having a prefix and a single assertion or exception oracle.}

\ignore{The original TOGA study showed that test inputs can be \textit{misclassified}
-- predicting the need for an assertion (exception) oracle when an exception (assertion) oracle is required.  TOGA can also generate assertion oracles that are \textit{false positives} (indicating a failure when there is not one). Our findings confirm the misclassification, empty prediction, and false positive rates obtained from the detailed analysis of the original \texttt{Defects4j} study data via our replication in RQ1. 
For example, our study finds that the misclassification of assertion prefix is 18\% and exceptional prefix is 81\%. The empty assertion prediction rate is 62\% and false positive rate of assertion oracle is 47\%.}

\add{Going beyond the TOGA paper, we computed additional metrics for deeper insights into technique performance. For instance, we calculated the false positive rates for each type of ground truth label: ``No Exception'' (18\%), ``Exception Expected'' (81\%), and ``Assertion'' (47\%). Furthermore, we computed a ``no assertion generation rate'' of 62\%, indicating that even when TOGA correctly predicts the need for an assertion oracle, it may not generate one confidently. Additionally, we analyzed false positive rates for different types of assertion oracles (74\% FPR for assertEquals, Table \ref{tab:type_wise_fp}), which offers further insights into TOGA’s assertion oracles generation capability. In RQ2$_T$, the stated overall accuracy for assertion oracle inference is 69\%, while our findings show an overall accuracy of 52\%. For exceptional oracle inference, TOGA reported 86\% accuracy, while our findings indicate a lower accuracy of 75\%. Moreover, when considering only the ``exception expected'' ground truth, we found an accuracy 19\%, which was not reported in the original paper. These results indicate that TOGA did not generalize effectively to the large and diverse dataset studied.}

\add{Moreover, TOGA's high false positive rates raise concerns about its practical usefulness. Widely cited studies ~\cite{johnson2013don, christakis2016developers,sadowski2018lessons} have demonstrated that high false positives are a major barrier to the adoption of automated software testing in industry and tools that generate more than 10\% false positives waste developers time causing developers to lose trust in them and gradually abandon them. 
To improve TOGA-like techniques going forward, it is crucial to significantly reduce false positive rates. In this context, our findings offer valuable guidance by identifying the specific types of test oracles and assertions that predominantly contribute to false positives. Thus, presenting potential opportunities for future refinement to ensure their usefulness in real-world scenarios}. An important lesson from this study is that future research should comprehensively evaluate the precision and recall of oracle generation techniques (\S\ref{sec:lessons}).

\textbf{RQ3 (Conceptual Replication of RQ3$_{T}$):} \add{This study investigates the relative strength of the assertion oracles generated by TOGA and EvoSuite. Our motivation for this research question is twofold: firstly, strong assertion oracles are crucial for detecting specification violations and assertions are strongly correlated with the fault-detection effectiveness of a test suite ~\cite{5770600,terragni2020evolutionary,10.1145/2786805.2786858,schuler2013checked};  secondly, constructing strong assertion oracles requires an understanding of program specification and TOGA is designed to leverage natural language specifications (docstrings). 

TOGA leverages EvoSuite-generated prefixes, reaping benefits from EvoSuite's search-based technique that creates test inputs optimizing coverage, fault detection and minimizing false positive/flaky tests \cite{7372009, devroey2020java,panichella2021sbst, almasi2017industrial, virginio2020empirical}. Furthermore, TOGA employs a deep learning approach utilizing the powerful CodeBERT model, enabling it to learn from large-scale open source codebases and natural language code documentation (docstrings). 
This gives TOGA the potential to improve on traditional rule-based static techniques, which do not utilize natural language specifications. We limit this study to 34K test prefixes, from the RQ2 experiment, on which TOGA generated non-empty and correct assertion oracles and only consider EvoSuite assertions for those prefixes.  Our hypothesis is that TOGA, by leveraging both EvoSuite prefixes and a broader understanding of the code's intended behavior learned from codes and docstrings, would generate strong assertion oracles capable of identifying a significant number of faults not detected by EvoSuite}.



We employ mutation testing, a scalable and effective method, to measure the fault-detection effectiveness of test assertions ~\cite{coles2016pit, andrews2005mutation,beller2021would,petrovic2021practical,petrovic2021does,schuler2013checked, 10.1145/2786805.2786858}.
\add{From a pool of 51K injected faults, 20.5K were detected by the Java implicit oracle. EvoSuite assertions detected an additional 9,814 faults.
Finally, with the addition of TOGA's assertions, an additional 105 faults were detected.  This suggests that the added value of TOGA-generated assertions with EvoSuite prefixes is limited, and its use may not be warranted given the costs associated with its high false-positive rate (from RQ2).}



\ignore{Our study highlights inconsistencies in results, a high false positive rate, low assertion generation rate, and limited fault detection effectiveness. These findings assess TOGA's performance in real-world settings, addressing two critical questions: how it streamlines the development process by minimizing costs associated with test oracle creation, and how adept it is at detecting elusive bugs that remain undetectable by conventional implicit test oracles. Furthermore, our finding identifies limitations in the SOTA learning-based technique, which is valuable in helping to advance the use of AI/ML for automated testing. 
}


\ignore{\add{Additionally, our study highlights the importance of neural-based testing techniques going beyond simple "no exception" oracles. To provide genuine value in real-world scenarios, these techniques must generate strong test assertions capable of detecting specification bugs beyond the capabilities of implicit oracles.} %\soneya{I am not quite sure this fits well here, might need to move somewhere else}
}


\ignore{Our study focuses on evaluating EvoSuite and TOGA while excluding other techniques for several reasons. Firstly, EvoSuite is widely considered the state-of-the-art for test oracle generation, significantly outperforming other methods in terms of false positives, flaky tests, tests with smells, and real-world bug detection \cite{7372009,almasi2017industrial,panichella2021sbst,devroey2020java,virginio2020empirical}. 
Secondly, TOGA has been shown to outperform other ML-based techniques, e.g., seq2seq \cite{tufano2022generating}, Athena Test~\cite{tufano2020unit}, and is the current state-of-the-art neural-based technique. Most importantly, our primary goal is to assess the state-of-the-art neural-based test oracle generation technique by evaluating its real-world cost-effectiveness relative to the overall state-of-the-art EvoSuite, so we invested in a larger scale study focused in this way.}

\ignore{
We detail these findings in \S\ref{sec:study}. 
% They suggest that the marginal improvement in fault-detection from TOGA generated assertions may not warrant the potentially high-cost of filtering out the large number of false positive assertions.  
Overall, our study indicates that the modest increase in the number of bugs detected comes with a significant rate of false positive reports, which translates in potentially high time cost for the developers having to investigate incorrect reports. 
Moving forward, greater emphasis on improving the precision of oracle generation methods and on evaluating fault detection effectiveness relative to state-of-the-practice baselines seems warranted.

\soneya{As suggested by reviewer "The presentation of this work could benefit from clearly stating the contributions of this paper as part of the introduction. Furthermore, the authors can consider reorganizing their text in the introduction. In the current form, the introduction discusses aspects of the replication study on the Defects4J and the extended dataset. Instead, authors could highlight key contributions of the paper in the introduction and discuss other details as part of the experimental setup.}}

Our primary contributions are (1) a series of replication
studies that broaden the understanding of TOGA's applicability, generalizability, precision, fault detection power; 2) the identification of limitations of the latest learning-based test oracle generation approach; (3) the identification of actionable lessons
learned that can be applied to future studies of such techniques; and
(4) a substantial dataset constructed by an external group, consisting of 223K test cases from 25 large-scale applications for evaluating test oracles.

% Figure environment removed


\section{TOGA}\label{toga}


TOGA is an automated test oracle generation technique~\cite{10.1145/3510003.3510141}. It takes two inputs: the unit context, comprised of the method under test and associated docstrings, and test prefix. The test prefix is typically generated with an auxiliary test generator; following the original paper~\cite{10.1145/3510003.3510141}, we also adopt EvoSuite. TOGA has three major components: Exception Oracle Classifier, Assertion Oracle Generator, and Assertion Oracle Ranker. 

\add{The exception oracle classifier determines whether the execution of a test prefix should result in throwing an exception or not. It assigns a prediction of \texttt{``1''} if an exception is expected or \texttt{``0''} otherwise. Note that, ``no exception'' is a default oracle in Java. When a \texttt{``1''} prediction occurs, TOGA wraps the test prefix with a \texttt{try} and \texttt{catch} block. Conversely, when a \texttt{``0''} prediction is made, the assertion oracle generator is invoked to generate a set of JUnit assertion candidates. Finally, the assertion oracle ranker weighs and selects the highest-ranked assertion from the generated candidates}. In the reminder of this section, we briefly summarize the functioning and role of EvoSuite and of TOGA's three components.

% describe the details of each component.

\textbf{EvoSuite} is a search-based unit test generation tool for Java~\cite{fraser2011evosuite, fraser2014large}.  It automatically produces a code fragment, called \textit{test prefix}, that defines the inputs for each generated test. 
EvoSuite assumes that the unit under test is correct in order to   generate test oracles for each prefix that detect regression bugs. These oracles can take two forms.
Assertion oracles check program output against expected output. Exception oracles check if an expected exception is thrown. 



Listing \ref{lst:evo_oracle} shows two test cases generated by EvoSuite for the Java \texttt{Stack} class. \texttt{test00} tests the \texttt{push} method: inserts an element, and checks if the size of the stack is equals to 1 with an explicit assertion oracle. \texttt{test11} calls the \texttt{pop} method without pushing anything on to the stack, therefore, an expected behavior is to throw an \texttt{Exception}. If the exception is not thrown then the test will fail, which is checked with the exception oracle.  


\begin{lstlisting} [belowskip=-0.9 \baselineskip,float,style=listingstyle,label={lst:evo_oracle}, caption={EvoSuite tests with assertion and exception oracles}]
public void test00() throws Throwable  {
    Stack<Integer> stack0 = new Stack<Integer>();
    Integer integer0 = new Integer(0);
    stack0.push(integer0);
    assertEquals(1, stack0.size());  //assertion oracle }
    
public void test11() throws Throwable  {
    Stack<Integer> stack0 = new Stack<Integer>();
    try { 
      stack0.pop();
      fail("Expecting exception: EmptyStackException"); //exception oracle
    } catch(EmptyStackException e) {
         verifyException("Stack", e); }}
\end{lstlisting}
\subsection{Exception Oracle Classifier (EOC)} 
The Exceptional Oracle Classifier (EOC) is a pretrained CodeBERT \cite{feng2020codebert} model trained on both natural language and code-masked language modeling and fine-tuned on binary classification. For fine-tuning, they used a dataset called Methods2Test*, a corpus of method context (c),  test prefix (p), and binary label (\texttt{0}/\texttt{1}). For a given pair of (c,p), label \texttt{1} indicates that the execution of the test prefix should throw an exception, and label \texttt{0} indicates that no exception should be thrown. 

For example, in Listing \ref{lst:evo_oracle}, \texttt{test11} pops from an empty stack which should throw an \texttt{EmptyStackException}. Given this test prefix, it is expected that EOC will predict a \texttt{``1"}. On the contrary, given the test prefix from \texttt{test00} in Listing \ref{lst:evo_oracle}, the expected prediction is \texttt{0}, meaning that no exception should be thrown. \add{As mentioned earlier, "no exception should be thrown" is Java's implicit oracle}.

\subsection{Assertion Oracle Generator (AOG)}
When EOC classifies that an exception should \textit{not} be thrown for a  unit context and test prefix, the Assertion Oracle Generator (AOG) is invoked to generate a set of assertion candidates. Note that AOG is a non-ML-based algorithm (Algorithm 1 in \cite{10.1145/3510003.3510141}) that generates assertions based on the type of the variable being checked. It is worth noting that the target variable is extracted from the EvoSuite generated assertion. Based on the variable type, TOGA generates five types of JUnit assertions: \texttt{assertNull}, \texttt{assertNotNull}, \texttt{assertTrue}, \texttt{assertFalse}, \texttt{assertEquals}. For example, if a variable is an \texttt{Object}, AOG may generate assertion candidates using  \texttt{assertNull()}, \texttt{assertNotNull()} and \texttt{assertEquals} methods. Similarly, for variables with \texttt{boolean} type, \texttt{assertTrue()} and \texttt{assertFalse()} oracles can be generated. 


%10.1145/3510003.3510141
Generating \texttt{assertEquals} is more complex as it requires two values:
expected value and the variable being checked. For deriving an expected value, TOGA draws from the most frequently appearing constant values in the AOR training data (Global Dictionary). For each type, this dictionary holds the top K values. Similar to the global dictionary, they also construct a local dictionary from the input test prefixes, consisting of variables and constants in the prefix. We refer readers to Section 4.4 of \cite{10.1145/3510003.3510141} for more details on the local and global dictionary. Our experimental studies (RQ2) show that TOGA mostly uses \texttt{0} or \texttt{1} for the expected value in \texttt{assertEquals} for numerical domains.  Out of the 16059 false positive 
\texttt{assertEquals} oracles generated by TOGA, 14913 (93\%) assertions used either \texttt{0} or \texttt{1} as expected value. Only 7\% oracles used some other variables from the test prefix as the expected value. Consequently, this type of assertion results in a large number of false positives (73\% FPR). For example, in Figure \ref{fig:togastack}, for \texttt{test01}, TOGA generated an incorrect assertion by comparing stack size with \texttt{0} when the expected value should be \texttt{1}.

\raggedbottom

\subsection{Assertion Oracle Ranker (AOR)}
Like EOC, the Assertion Oracle Ranker (AOR) is also a pretrained CodeBERT \cite{feng2020codebert} model trained on both natural language and code-masked language modeling, however, fine-tuned on ranking tasks instead of binary classification. For fine-tuning, a supervised dataset, Atlas*, was used. Atlas* is a corpus of method context (c), test prefix (p), assertion (a), and a binary label (\texttt{0}/\texttt{1}). As this is a ranking task, for a pair of (c,p), only one assertion in the candidate set will have a binary label \texttt{``1"}', indicating the most preferred assertion from the candidates. The rest of the assertions will be labeled as \texttt{``0"}' for that given pair of (c,p). 

During assertion oracle inference, for an input (c, p, a), AOR predicts a binary label and assigns a confidence score. Based on the label and achieved confidence score, the highest-ranked assertion may be selected as the output. The model does not output any assertion oracle when it is not confident enough; in our study, TOGA did not generate any assertion for more than 62\% of the correctly classified test prefixes.
\raggedbottom

\subsection{Sample Test Oracles Generated by TOGA}
In Figure \ref{fig:togastack}, we provide a few examples of the TOGA-generated test oracles for the \texttt{Stack} class. Using EvoSuite, we have generated 13 test cases, 11 with assertion oracles and two with exception oracles. We have used the method under test, its docstrings (available for all methods), and the test prefixes to predict test oracles with TOGA. TOGA generated four assertion oracles, two correct (e.g., test03) and two false positive assertions (e.g., test01). For the remaining seven out of the 11 test prefixes, TOGA correctly classified that they should \textit{not} throw any exception; however, it did not generate any assertions. Out of the two test prefixes with an EvoSuite exception oracle, TOGA classified one correctly (e.g., test05) and one incorrectly (e.g., test06). For both assertion and exception oracle inference, false positive rate is 50\%. 

\subsection{TOGA Original Findings}
The original TOGA study included three research questions.

RQ1$_T$ evaluated whether TOGA's grammar represents most developer-written assertions or not. They found that 82\% developer-written assertions from the ATLAS dataset \cite{watson2020learning} can be represented with their grammar. 

RQ2$_T$ evaluated TOGA's oracle inference accuracy on held-out test sets. For exception oracle inference, they used Methods2Test* dataset \cite{10.1145/3510003.3510141}, and TOGA achieved 86\% accuracy, 55\% precision, 30\% recall, and .39 F1-score. For assertion oracle inference, the Atlas* \cite{10.1145/3510003.3510141} dataset was used, and TOGA achieved 96\% in-vocab accuracy and 69\% overall accuracy. 

RQ3$_T$ evaluated TOGA-generated oracles fault-detection effectiveness on \texttt{Defects4j} fault database. Using 364 test prefixes generated on the fixed versions, TOGA detected 57 out of the 835 \texttt{Defects4j} bugs, where five were detected by exception oracle, 14 were detected by assertion oracle, and 38 were detected by EvoSuite prefixes throwing uncaught exceptions. EvoSuite detected 120 bugs. 

\section{Experimental Study}

\label{sec:study}
We investigate the following research questions:
%\matt{Let's be consistent between the descriptions in the intro, the bold parts of the RQ statements, and the subsection numbers in this section.  I favor explicitly stating the kind of replication and mentioning the TOGA RQ being replicated.}

\textbf{RQ1 (Exact Replication of RQ3$_{T}$):} How many of the bugs reported in the original study could be exclusively detected by TOGA's explicit assertion and exception oracles and how many have been detected by implicit oracles, i.e., the uncaught exception thrown by EvoSuite prefixes (e.g., a dereferenced null pointer)?

\textbf{RQ2 (Conceptual Replication of RQ2$_{T}$):} How precise is TOGA in classifying the type of oracle required and in generating correct assertion oracles? 

\textbf{RQ3 (Conceptual Replication of RQ3$_{T}$):} What is the added value of TOGA generated assertions in detecting faults relative to the state-of-the practice? 



\subsection{RQ1 (Exact Replication of RQ3$_{T}$)}
\label{sec:rq1}
This research question investigates  the 57 \texttt{Defects4j} bugs reported as detected by TOGA in the original study. To this end, we obtain the original paper replication package~\cite{toga-replication-package}, run the experiments as indicated, and examined the detected bugs and the oracles that catch them using our own tools and scripts. 

\ignore{We have discussed the procedure from the original paper and discussed our findings.}

\subsubsection{\textbf{Original Artifacts and Procedure}} The bug-detection effectiveness of the TOGA-generated test oracles was evaluated on the \texttt{Defects4j} benchmark, a dataset of real bugs~\cite{just2014defects4j}, consisting of 17 Java applications containing a total of 835 labeled bugs. For each bug, the dataset keeps both the buggy and fixed versions.
%, where a buggy version contains the bug, and a fixed version fixes the bug with minimal changes. 
Each bug is labeled with a unique bug id, and the fixed and buggy versions for that bug can be identified and run on a set of test cases efficiently. 

TOGA's bug detection capabilities have been investigated using the following protocol~\cite{10.1145/3510003.3510141}:
% Figure environment removed

\begin{table*}[t]
\Small\centering
\begin{tabular}{>{\centering\arraybackslash}m{6cm} | >{\centering\arraybackslash}m{3cm} | >{\centering\arraybackslash}m{3.5cm} | >{\centering\arraybackslash}m{3cm}}

\textbf{EvoSuite Test} & \textbf{TOGA Input 1} & \textbf{TOGA Input 2} & \textbf{TOGA Input 3} \\
\hline
     \begin{lstlisting} [belowskip=-0.8\baselineskip,style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
 /** EvoSuite prefix: **/
 QName qN0 = new QName("");
 VariablePointer vP0 = new VariablePointer(qN0);
 NodePointer nP0 = NodePointer.newChildNodePointer(vP0, qN0, qN0);
 BasicVariables bV0 = new BasicVariables();
 VariablePointer vP1 = new VariablePointer(bV0, qN0);
 int int0 = nP0.compareTo(vP1);
 /** end of EvoSuite prefix **/
 assertEquals(1, int0);
 assertEquals(Integer.MIN_VALUE, vP1.getIndex());   }
\end{lstlisting} &  \begin{lstlisting} [style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
 /** EvoSuite Prefix **/
 assertEquals(1, int0);
}
\end{lstlisting} & \begin{lstlisting} [style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
 /** EvoSuite Prefix **/
 assertEquals(Integer.MIN_VALUE, vP1.getIndex());
}
\end{lstlisting} & \begin{lstlisting} [style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
    /** EvoSuite Prefix **/
}
\end{lstlisting}\\
     \hline
\textbf{TOGA Oracle Inference:} & \verb|assertEquals(0, int0)| & \textcolor{red}{Empty} & \textcolor{red}{Empty} \\
\hline 
\textbf{Aggregated Test:} & \begin{lstlisting} [belowskip=-0.8 \baselineskip,style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
    /** EvoSuite Prefix **/
    assertEquals(0, int0)}
\end{lstlisting} & \begin{lstlisting} [style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
    /** EvoSuite Prefix **/}
\end{lstlisting} & \begin{lstlisting} [style=listingstyle,basicstyle=\ttfamily\tiny,breaklines=true,frame=none,label={lst:optional}]
public void test48() throws Throwable {
    /** EvoSuite Prefix **/}
\end{lstlisting} \\
     \hline 
\textbf{Test Execution Status:} & \textcolor{red}{FP: Failed on Fixed} & \textcolor{pgreen}{TP: Passed on Fixed, Failed on Buggy} & \textcolor{pgreen}{TP: Passed on Fixed, Failed on Buggy}\\

 \hline
\end{tabular}
\vspace{1mm}
\caption{\texttt{Defects4j} bug detection (Bug ID: JxPath 5) by TOGA. TOGA correctly predicted that ``no exception is expected'' (note that this is an ``implicit assertion'', which is the default assumption of a run-time system and JUnit test runner). However, it generated 
one false positive assertion and no assertion for the rest. Running the EvoSuite prefix alone on the buggy version detected a bug as the test failed due to uncaught exception thrown by the EvoSuite prefix.}\label{rq1_jxpath_5}
\vspace{-2mm}
\end{table*}


\noindent (1) Run \texttt{EvoSuite} on the fixed versions of the programs for three minutes to generate test cases;\\
\noindent (2) Run \texttt{EvoSuite}-generated tests on the buggy versions and keep records of the failed test cases. These tests are called ``bug-reaching tests'' as they failed on the buggy versions, indicating that they exercised buggy behavior.\\
\noindent (3) Separate test prefix and assertions in the ``bug-reaching tests'' test cases. When a bug-reaching test contains more than one assertion, it is  replicated into multiple tests composed of a single assertion and a test prefix that computes the variable checked by the assertion. For example, from the EvoSuite test case with two assertions shown in Table \ref{rq1_jxpath_5}, three test cases were generated. In total 364 test prefixes were used for this study.\\
\noindent (4) TOGA processes test prefixes and \texttt{EvoSuite} assertions (to determine the variable to be asserted) and generates oracles for each of the prefixes. TOGA oracles can be assertions or exception oracles, where the test prefix is wrapped within a try-catch block.\\
\noindent (5) TOGA tests (\texttt{EvoSuite}+ TOGA assertion) are executed on both fixed and buggy version, where a bug is classified as detected if the test passes on the fixed version while failing on the buggy one.
% \raggedbottom

%\se{It would be good to acknowledge that we requested and received help from the TOGA authors to replicate the study, understand the results, etc. Perhaps here as part of the process we followed  and in the acknowledgements would be good places to do it} \soneya{we can add a acknowledgement section} 


To conduct this replication, we followed the same protocol, \add{utilized the identical set of EvoSuite test prefixes provided in the TOGA replication package. This approach eliminated any random factors associated with EvoSuite. Additionally, we ran TOGA multiple times and consistently obtained the exact same output, thereby confirming the absence of any randomness in TOGA's implementation.} %We received frequent and helpful assistance from the TOGA authors to run the tool, find missing dependencies, and clarify understandings. 



\subsubsection{\textbf{Results}} 
In the Sankey diagram shown in Figure~\ref{toga_defec4j}, we report the analysis of all 57 bug detection reported by TOGA. We first categorize the 364 TOGA inputs based on the expected oracle types: exception and assertion oracles. 
Of the 60 TOGA inputs consisting of test prefixes expected to throw an exception, 53 were misclassified, resulting in an 88\% false positive rate. The 7 correctly classified exception oracles found 5 distinct bugs. 


For the remaining 304 inputs (bottom left branch of diagram), TOGA correctly classified 261 prefixes that an exception is \textit{not} expected, and 43 are misclassified. For 140 test prefixes, TOGA did not generate any explicit assertion oracles. For 121 prefixes, TOGA generated an explicit assertion oracle, only 58 of them are true positive and they detected 14 unique bugs. Rest of the generated assertions (63), either failed on the fixed versions (FP + FN) or passed on the buggy version (TN).

67\% (38 of 57) of the bugs reported as detected, were found by implicit assertions through a TOGA oracle expressing that ``a test should fail if no exception is predicted but is thrown when executing the test on the buggy version''. This is a default oracle of the Java run-time system and default behavior of the JUnit (used by \texttt{Defects4j}) test framework that a test must fail on uncaught exception. Therefore, these 38 out of the 57 bugs would still be detected by Java run-time system by simply running the \texttt{EvoSuite} test prefixes without any TOGA-generated oracle. 

In Table ~\ref{rq1_jxpath_5}, we provide an example of how TOGA detected a bug in the \texttt{JxPath} application. The first row shows the test generated by \texttt{EvoSuite} and three TOGA inputs generated from the same test prefix: one per assertion and one containing only the prefix. Note that TOGA utilizes the \texttt{EvoSuite} assert statement to identify the variable for which to generate assertions. The second row shows the output from TOGA. For all three inputs TOGA correctly predicted that no exception is expected (implicit oracle), however, it generated only one assertion for input 1. For inputs 2 and 3, TOGA did not generate any explicit assertion oracle. When running the aggregated tests (third row), TOGA test 1 failed in the fixed version as it is an incorrect assertion. For TOGA tests 2 and 3, only \texttt{EvoSuite} test prefixes were run on both versions (fixed and buggy), and the bug was detected. This is one of the 38 bugs that can be detected without any TOGA oracles, Java implicit oracle suffices. \add{This evaluation setting has two negative consequences: 1) it overestimates TOGA's fault detection capability relative to the state-of-the-art considering that 67\% bugs can be detected by the standard implicit test oracle, and 2) it does not control for the fact that other techniques that do not explicitly generate the ``No Exception'' oracle could be misrepresented with this protocol.}

\add{For instance, seq2seq, which utilizes the same EvoSuite prefixes, should theoretically be capable of detecting these 38 implicitly detected bugs, unless the generated assertions failed on the fixed version of the program and so have been classified as false positives.
%
%However, the RQ3$_{T}$ study design intentionally ignored them despite the fact that seq2seq generates assertion oracles based on the implicit premise of ``No Exception'' by default, aligning with Java's default oracle. 
%
Similarly, JDoctor which also uses the same EvoSuite prefixes, should also detect these 38 bugs, unless it generates a large percentage of false positives. However, according to RQ3$_{T}$, FPR is only .4\% (2/364 tests are false positives). Therefore, JDoctor, in theory, should also detect these bugs. An exact replication of these methods was not possible because neither the TOGA  paper nor its replication package provided data regarding how these tools were run, e.g., time spent running each technique, the preparation of inputs, and tool configurations.}

The total number of misclassification (total: 96) and generation of incorrect assertions failing on fixed versions (total: 49) sum to 40\% of the 364 tests prefixes in the original TOGA study.  These tests may fail when they should not and it would require engineer time to triage, diagnose, and repair the tests. This cost might be acceptable if TOGA were able to generate valuable assertions, but 
for 54\% (140/261) of correctly classified test prefixes, TOGA generated no assertions and the faults detected from TOGA generated assertions comprise only 19 of the 57 reported in the original paper. We investigate the precision and value of TOGA generated assertions further in RQ2 and RQ3.

\begin{tcolorbox}
\vspace{-1mm}
\textbf{RQ1 Findings:}
Out of the 57 bugs reported in the original study, 5 were detected by exception oracles, 14 were detected by explicit assertion oracles generated by TOGA, and 38 were due to uncaught exceptions thrown by EvoSuite-generated prefixes that can be detected by the run-time system (implicit oracle) without requiring any TOGA-generated oracles.
\vspace{-2mm}
\end{tcolorbox}


\begin{table*}[h]
\small\centering
%\begin{threeparttable}
  % \small \centering

% To place a caption above a table
\caption{Description of Artifacts, SLOC: Non-comment and non-blank lines of codes }\label{tab:desc}
\vspace{0mm}

\begin{tabular}[t]{l|l|c|c|c|c}
 \hline
 \textbf{Artifact (version)} & \textbf{Description} & \textbf{\thead{Program \\Size (SLOC)}}   & \textbf{JavaDoc (L)} & \textbf{\thead{Test Size\\(SLOC)}} &\textbf{\thead{Test \\Case(\#)}}\\

 \hline 
JSON(20220924) & JSON library for Java & 4,220 & 3,549 & 27,351 &883 \\
async-http-client(2.12.3) & Asynchronous HTTP library&16,299 & 3,288 & 69,889 &1,534 \\
bcel(6.5.0) & Bytecode Engineering Library&35,571 & 15,569 & 263,796 & 7,073\\
commons-beanutils(1.9.4) & Reflection and Introspection API & 11,725 & 15,074 & 29,939 &1,654 \\
commons-collections4(4.4) & Utilities for Java Collections Framework&  6,697 & 6,532 & 2,149 & 576 \\
commons-configuration2(2.8.0) & Utilities for reading configuration files &4,553 & 4,882 & 2,858 &1,764\\
commons-dbutils(1.7) & Java utility for JDBC development& 3,079 & 4,158 & 10,144 &479 \\
commons-geometry (1.0) & Geometric types and utilities& 14,168 & 12,195 & 48,862 &4,274\\
commons-imaging (1.0-alpha3) & Java image library& 32,275 & 5,003 & 103,120 &4,997\\
commons-jcs3(3.1) & Caching system & 14,328 & 6,045 & 33,542&705 \\
commons-jexl3(3.2.1) & Scripting utilities for Java application& 2,295 & 2,267 & 5,613 &3,819 \\
commons-lang3(3.12.0) & Java helper utilities& 5,321 & 6,671 & 8,131 &5,816 \\
commons-net(3.8.0) & Network utilities/protocol implementations& 19,407 & 16,574 & 42,841 &2,701 \\
commons-numbers(1.0) & Java utility for number types & 5,502 & 5,566 & 56,339 &1,270 \\
commons-pool2(2.11.1) & Object Pooling Library& 1,197 & 1,335 & 2,688 & 749 \\
commons-rng(1.4) & Pseudo-random generators & 9,654 & 161,553 & 16,241 &1,359 \\
commons-validator(1.7) & Client and server side data validation& 7,829 & 7,338 & 22,352 &1,737 \\
commons-vfs(2.9.0) & Virtual File System library &7,751 & 4,966 & 13,890 & 1,181\\
commons-weaver(2.0) & Utility to enhance compiled Java classes& 4,527 & 1,546 & 14,462 &310 \\
http-request(6.0) & Library for making HTTP requests & 1,395 & 1,511 & 10,450 &208 \\
joda-time(2.11.2) & Date and time library &  32,312 & 31,127 & 156,345 &7,111 \\
jsoup(1.15.3) & Java library for HTML& 13,905 & 4,627 & 186,371 &2,974 \\
scribejava(8.3.1) & OAuth library& 2,173 & 1,303 & 14,094 & 1,019\\
spark(2.9.3) & Framework for creating web applications & 6,124 & 4,361 & 39,273 &1,429\\
springside4(5.0.0-SNAPSHOT) & JavaEE application reference architecture & 9,336 & 4,387 & 33,357 &2,246\\

\bottomrule
& \textbf{Total:} & 271,643 & 331,427 & 1,214,097 &57,868\\
\hline
\end{tabular}
%\end{threeparttable}
\vspace{-3mm}
\end{table*}


\subsection{RQ2 (Conceptual Replication of RQ2$_{T}$)}
\label{sec:rq2}

\begin{table*}[h]
% \centering
% \begin{threeparttable}
\small\centering
% To place a caption above a table
\caption{Test Oracle Prediction by TOGA, AO: Assertion Oracle, EO: Exception Oracle}\label{tab:toga-oracle-prediction}
\begin{tabular}[t]{p{3.1cm}|c|c|c|>{\centering\arraybackslash}m{1.8cm}|c|c|c|c}
  \toprule
  \multirow{3}{*}{\textbf{Artifact}} &  \multirow{3}{*}{\textbf{\thead{Total \\Test \\Prefix (\#)}}} & \multicolumn{5}{|c|}{\textbf{Ground Truth: AO}} & \multicolumn{2}{c}{\textbf{Ground Truth: EO}} \\\cline{3-9}
  
  &  & & & \multicolumn{3}{c|}{\textbf{\thead{Correctly Classified}}} & &\\\cline{5-7}
  
   &  & \multirow{2}{*}{\textbf{\thead{Total \\Assertion \\Prefix (\#)}}} & \multirow{2}{*}{\textbf{{\thead{Mis-\\Classified (\%)}}}}  & \textbf{{\thead{No \\Assertion \\Predicted (\%)}}} & 
   \multicolumn{2}{c|} {\textbf{\thead{Assertion Predicted}}} & & \\\cline{6-7}
   
   
  &  & & & &  
   
   {\textbf{\thead{Total (\%)}}} & \textbf{\thead{False \\Positive (\%)}} & {\textbf{\thead{Total \\Exception \\Prefix (\#)}}} & {\textbf{{\thead{Mis-\\Classified (\%)}}}} \\
  
\midrule
JSON-java& 13,995 & 13,794 & 13\%&49\%&38\%&51\%&201&82\% \\
commons-configuration2& 1,519 & 1,000 & 14\%&40\%&46\%&44\%&519&71\% \\
spark& 6,194&5,637&35\%&57\%&9\%&39\%&557&78\% \\
commons-geometry&5,516 & 4,244 &3\%&64\%&33\%&56\%&1,272&89\% \\
http-request&7,074&7,052&33\%&50\%&17\%&18\%&22&50\% \\
commons-collections4&1,589&1,338&8\%&41\%&51\%&31\%&251&66\% \\
springside4&4,814&3,858&9\%&58\%&33\%&44\%&956&78\% \\
commons-rng&1,804&1,352&22\%&63\%&14\%&65\%&452&70\% \\
commons-vfs&1,423&997&6\%&46\%&48\%&49\%&426&74\% \\
commons-numbers&41,412&41,163&36\%&61\%&4\%&73\%&249&47\% \\
commons-lang3 & 14,918 & 13,455 & 9\%&59\%&32\%&38\%&1,463&71\% \\
commons-pool2&12,134&11,961&36\%&37\%&27\%&54\%&173&67\% \\
commons-beanutils&1,780&1,036&9\%&47\%&44\%&50\%&744&69\% \\
commons-validator&2,659&2,261&4\%&39\%&57\%&48\%&398&83\% \\
jsoup&22,721&21,844&1\%&36\%&63\%&44\%&877&88\% \\
commons-weaver&284&187&11\%&50\%&39\%&42\%&97&77\% \\
commons-net&3,865&2,462&3\%&34\%&63\%&54\%&1,403&86\% \\
async-http-client&2,500&2,008&2\%&48\%&50\%&37\%&492&94\% \\
commons-jexl3&4,275&3,219&5\%&37\%&58\%&62\%&1,056&76\% \\
commons-jcs3&5,860&4,861&3\%&37\%&59\%&56\%&999&84\% \\
commons-dbutils&818&635&2\%&42\%&56\%&38\%&183&93\% \\
bcel&24,049&20,657&5\%&60\%&35\%&47\%&3,392&83\% \\
commons-imaging&10,731&8,397&5\%&64\%&31\%&58\%&2,334&88\% \\
joda-time&30,527&28,408&25\%&43\%&32\%&46\%&2,119&84\% \\
scribejava&1,096&649&5\%&26\%&69\%&28\%&447&81\% \\
\hline
Total (average \%): & 223,557 & 	202,475	& 36,949 (18.3\%) &	102,606 (62\%) &	62,920 (38\%) & 29,883 (47.5\%) & 21,082&	17,149 (81\%)\\														

\bottomrule

\hline
\end{tabular}
%   \begin{tablenotes}
%   \end{tablenotes}
% \end{threeparttable}
\vspace{-3mm}
\end{table*}

In this research question, we investigate the ability of TOGA to generate non-trivial and precise oracles on a large set of programs and generated oracles. 

\subsubsection{\textbf{New Artifacts}}
We study 25 large-scale open-source Java applications from GitHub and Apache Commons Proper \cite{apache-commons-proper}. 8 of the artifacts comprise the official EvoSuite benchmark \cite{10.1145/2642937.2643002} and 17 were selected from the 
Apache Commons packages.   
We use the 8 EvoSuite artifacts because: (i) they have several thousand stars and users (min: 3.3k and max: 9.8K) on GitHub attesting to their popularity and adoption among developers, 
%which suggests they are considered valuable, 
(ii) many researchers have studied them to evaluate test adequacy metrics, fault-detection techniques and automated test/oracle generation methods~\cite{just2014defects4j,schuler2013checked,10.1145/2786805.2786858}, and (iii) they have a large code base with multiple modules and thereby better reflect real-world software complexity. For our study, we use the latest stable release of these artifacts as of Sep 30th, 2022.
The Apache Commons are popular Java utility packages, frequently used in software engineering empirical studies~\cite{just2014defects4j,schuler2013checked,10.1145/2786805.2786858} and have actively maintained large-scale code bases and test suites. From the 43 Apache Commons packages, we selected the 22 that can be compiled with Java 8, which is a requirement for running the latest version of EvoSuite. 
EvoSuite was unable to generate tests for 5 of those, so we removed them leaving us with 17 Apache Commons packages for the study. \add{These 25 artifacts are significantly diverse in terms of project domains, unique developer percentages, and developer count. They represent applications from 21 different domains. In cases where there are domain similarities - such as async-http-client and http-request both being Java HTTP request libraries, and commons-lang3 and springside4 both offering Java utilities - each of these projects possess unique characteristics (e.g., design philosophy, framework, flexibility, and target applications) that differentiate them. Regarding their developers, 15 artifacts have completely disjoint sets of developers. The remaining projects (mostly from Apache Commons) have a small amount of overlap; however, these projects, due to their open-source nature, draw contributions from a broad range of developers (up to 189 contributors). The developer count varies from 1 to 23, with an average of 7}. We use OpenJDK 8 to run EvoSuite, Maven (3.6.3) to build Java classes, JUnit (4.12) to execute test suites, and TOGA replication package~\cite{toga-replication-package} to generate oracles. 


\subsubsection{\textbf{New Procedure}} 
%\soneya{added more info from rebuttal, please check}
TOGA input prefixes require following a specific pattern with exactly one assertion at the end, and the variable under test is extracted from that assertion. EvoSuite's test format allows TOGA to easily parse and decompose large tests into multiple single assertion tests. Developer-written test cases, in general, do not follow a specific pattern, are not limited to only a few types of assertions, and the assertions could be anywhere in the test body. Consequently extending TOGA to support developer-written tests written in modern test frameworks would involve significant engineering work, if not new research on program analysis and comprehension, e.g., to separate test sequence from oracle implementation. For this reason, we replace existing test suites with one's generated using EvoSuite.


%\soneya{added more info from rebuttal, please check}
\noindent\textbf{Generating Ground Truth.} We need to generate the ground truth to determine whether a test oracle generated by TOGA is a false positive. To this end, for all artifacts, we download the latest stable releases (shown in Table~\ref{tab:desc}) with no known faults, meaning that the programs' implementations are correct. EvoSuite is a regression-based technique that assumes the implementation of the program under test as \textit{correct} and generates test oracles based on the executed behavior. Therefore, we considered the EvoSuite-generated tests as the ground truth  to detect the false positive oracles generated by TOGA -- this is the approach taken in the original TOGA study.
We allocate six minutes per class for test generation as recommended by the authors of EvoSuite~\cite{fraser2014large}. In a large-scale study, EvoSuite developers and other researchers \cite{7372009}, found that EvoSuite occasionally generates non-compiling (4\%) and flaky (3.4\%) tests, however, no false positives are generated by EvoSuite. We also find the same and following the same recommendations from \cite{7372009}, we detect and remove non-compiling and flaky tests and report the total test cases per artifact in Table~\ref{tab:desc}.

\noindent{\textbf{Generating TOGA Oracles.} 
%TOGA input prefixes require exactly
%one assertion at the end. However, EvoSuite test cases may contain multiple assertions at the end, as shown in Listing~\ref{rq1_jxpath_5}. 
Following a similar procedure as TOGA, we split test cases with multiple assertions into multiple test cases with a single assertion and a test prefix that computes the variable checked in the assertion.
\ignore{TOGA extracts the variable to be included in oracle assertions from the EvoSuite assert statement and requires that each input test case contains a single assertion, as shown in Listing~\ref{rq1_jxpath_5}. As EvoSuite test cases may contain multiple assertions, following a similar procedure as TOGA, we split test cases with multiple assertions into multiple test cases with a single assertion and a test prefix that computes the variable checked in the assertion.} We compile
and execute these test cases to confirm that all decomposed tests successfully compile and pass, resulting in 223,557 test cases
with either an assertion oracle or an exception oracle. Finally, we construct inputs for TOGA (focus method, test prefix, doc-string) and generate oracle predictions. We construct TOGA generated test cases with EvoSuite test prefixes and TOGA-generated oracles and execute the test cases to count the false positives. We categorize the input test prefixes based on the type of oracle expected (assertion or exception) and present our findings in Table~\ref{tab:toga-oracle-prediction}.}

\subsubsection{\textbf{Results}} In Table~\ref{tab:toga-oracle-prediction}, the first column shows the artifact name, and the second column shows the total test input prefixes processed by TOGA. Columns 3-7 represent TOGA prediction results when the ground truth is ``assertion oracle'', meaning that TOGA should predict ``no exception'' and generate an assertion oracle for that test prefix. Columns 8-9 present results when the ground truth is ``exception oracle'', meaning that TOGA should predict that the test prefix throws an exception. In total, we evaluate TOGA on 223,557 prefixes; ideally, TOGA should generate an assertion oracle for 202,475 of the prefixes, and predict an exception oracle for the remaining 21,082 prefixes.

% TOGA should ideally generate an assertion oracle, and for 21,082 prefixes, TOGA should ideally predict an exception oracle.

% \definecolor{codeblue}{RGB}{36,89,158}
% \definecolor{codegreysh}{RGB}{120,143,219}


\begin{lstlisting}[belowskip=-0.7 \baselineskip,float,style=listingstyle,label={lst:incompatible_assertion}, caption={Type Incorrect Assertion}]
public void test1() throws Throwable  {
MutableLong mutableLong0 = new MutableLong();
MutableLong mutableLong1 = new MutableLong();
mutableLong1.incrementAndGet();
boolean boolean0 = mutableLong0.equals(mutableLong1);
assertEquals((short)1, mutableLong1.shortValue()); /*EvoSuite Assertion*/
///incompatible types: short cannot be converted to boolean
assertTrue(mutableLong1.shortValue()); ///TOGA assertion with type error" }
\end{lstlisting}

\begin{lstlisting}[belowskip=-0.7 \baselineskip,float,style=listingstyle,label={lst:false_positive}, caption={False Positive Assertion}]
public void test1()  throws Throwable  {
Locale locale0 = new Locale("TZea6h)b", "LE$&{r\f+E=b+Uz}rR", "TZea6h)b");
Locale locale1 = Locale.KOREAN;
List<Locale> list0 = LocaleUtils.localeLookupList(locale0, locale1);
assertEquals(4, list0.size()); /*EvoSuite Assertion*/
///AssertionError: expected:<1> but was:<4>*
assertEquals(1,list0.size());///false positive assertion by TOGA}
\end{lstlisting}


The first step for TOGA is to predict whether the execution of a test prefix should throw an exception or not. Our study shows that 18.3\% (column 4) of the assertion prefixes are misclassified and 81.7\% test prefixes are correctly classified by TOGA
for a total misclassification rate of 24.1\%. For 62\% of the assertion test prefixes, TOGA could not generate an assertion oracle (column 5) and for 31\%,  an assertion was generated (column 6). Out of  the 62k test prefixes on which TOGA generated an assertion, 47.5\% (column 7) of them were false positive -- assertions that failed when combined with the test prefix and run on the original program.  The false positive rate for TOGA generated assertions was as high as 73\% -- for the \texttt{Apache commons-numbers} package. 
Listing~\ref{lst:false_positive} shows an common example of a false positive assertion generated by TOGA involving an \texttt{assertEquals} with an incorrect value predicted.
We also encountered assertions that do not compile due to ``incompatible types" errors because TOGA generated type incorrect assertions, an example of which is shown in Listing~\ref{lst:incompatible_assertion}. 
While this latter class of incorrect assertion is easier to filter out, it only represented 563 of the more than 29K false positive assertions in the study.

\begin{table}
\small\centering
\caption{\label{tab:type_wise_fp} Different Type of Assertion Oracle Generated By TOGA and Their False Positive Rates.}

\begin{tabular}{l|c|c} 
\toprule
\textbf{Assertion Type} & \textbf{Total} & \textbf{False Positive} \\
 \hline
 assertTrue & 17,025 & 9,543 (56\%)\\ 
 assertFalse & 5,375 & 1,864 (34.7\%)\\ 
 assertNull & 0 & 0 (0\%)\\ 
 assertNotNull & 18,785 & 1,854 (9.9\%) \\ 
 assertEquals & 21,735 & 16,059 (74\%)\\ 
 \bottomrule
 Total: & 62,920 & 29,320 (47\%) \\
 \hline
\end{tabular}
\end{table}
\raggedbottom

In Table~\ref{tab:type_wise_fp}, we show the total number of each type of assertions generated by TOGA and the corresponding false positive rate. The highest false positive rate is generated for \texttt{assertEquals}. We conjecture that TOGA struggles to generate this type of assertion because it requires a second value, the expected value, to compare with the variable being checked. TOGA collects the most frequently appearing constants and variables from the test prefix and during the training of the model, which appears to not be an effective strategy based on the high false positive rates.  TOGA uses the values \texttt{0} and \texttt{1} very frequently resulting in false positives like those shown in Figure~\ref{fig:togastack}, Table ~\ref{rq1_jxpath_5}, and Listing ~\ref{lst:false_positive}. The second highest false positive rate is for \texttt{assertTrue} oracles. The lowest false positive is achieved for \texttt{assertNotNull}, however, this type of oracle has limited fault detection power~\cite{10.1145/2786805.2786858}.  TOGA did not generate any \texttt{assertNull} assertions in our experiments. 

For exception oracle prediction, TOGA's misclassification rate is 81\% on average and it has reached as high as 94\% for some artifacts. Exception oracles are essential in testing to ensure that an exception should be thrown when test inputs trigger defensive programming, such as the checking of preconditions at runtime. For example, when a \texttt{pop} operation is performed on an empty stack, an \texttt{EmptyStackException} should be thrown. 

Misclassifying oracle type and generating false positive assertions can cause test cases to fail when they should not.  This will require developers or test engineers to triage the problem, which is expensive and time consuming. The high rates of misclassification and false positive assertions found in this study suggest that use of TOGA is impractical for use on real-world software at present.

\begin{tcolorbox}
\vspace{-1mm}
\textbf{RQ2 Findings:}
TOGA misclassifies the type of oracle required for a test prefix 24\% of the time.
When it correctly predicts that an assertion is required, 62\% of the time it fails to generate an assertion and when it does generate an assertion, nearly half of those, 47\%, are false positive.  This degree of inaccuracy suggests that TOGA is too costly to be used in practice.
\end{tcolorbox}


\subsection{RQ3 (Conceptual Replication of RQ3$_{T}$)}
\label{sec:rq3}
\add{Assertion oracles play a critical role in detecting functional bugs caused by incorrect implementations and are highly correlated with the fault-detection effectiveness of a test suite ~\cite{10.1145/2786805.2786858, schuler2013checked}. Due to their  importance, this research question investigates the fault-detection effectiveness of TOGA-generated assertions relative to EvoSuite. 

We address several limitations of the TOGA Defects4j study (RQ3$_T$) and carefully control our experimental setup to ensure a fair comparison with EvoSuite. First, RQ3$_T$ only considered bug-reaching EvoSuite test prefixes, which limited TOGA's ability to detect bugs outside those prefixes. Our study considers all prefixes allowing TOGA to exploit its potential to detect faults that EvoSuite, despite having the capability to reach them, fails to detect with its own assertions. Second, we explicitly control for the faults that are detected by Java implicit oracle and solely focus on the faults detected by test assertions. 

To ensure a fair comparison, we take several measures. For both EvoSuite and TOGA, we \textit{only} consider the test cases on which TOGA generated non-empty and correct assertion oracles during our RQ2 experiment. This set of assertion oracles represents a variant of the ground-truth assertion oracles generated by EvoSuite, as they share the same test prefixes, test the same variables, and pass successfully on the program version from which they have been generated, thereby mirroring the current program behavior much like EvoSuite. Therefore, EvoSuite and TOGA both have the exact same set of prefixes, and an equal number of test assertions. The difference  between the test suites are the types and strength of the assertions. This controlled setup allowed us to ensure an unbiased evaluation of the relative strengths and weaknesses of the TOGA-generated assertion oracles in comparison to EvoSuite.}




%The Defects4j study of TOGA (RQ3$_T$) revealed that only 14 bugs were exclusively detected using the 121 assertions generated by TOGA. Additionally, no direct comparison was made between TOGA-generated assertions and those generated by EvoSuite, limiting our understanding of the relative strength of TOGA's assertions.
\ignore{Another limitation is the invalid assumption made in RQ3$_T$ that ``EvoSuite (test prefix) + Ground Truth (regression oracles by EvoSuite) achieves the best possible performance that any of the oracle generation methods can achieve on the EvoSuite test prefixes''. This assumption disregards the possibility of bugs going unnoticed due to poor-quality test oracles even if an EvoSuite prefix executes that bug~\cite{7372009}. Our RQ3 overcomes these limitations by expanding the evaluation to go beyond bug-reaching tests, allowing us to dive deep and comprehensively explore the strengths, weaknesses, and fault-detection effectiveness of TOGA's assertions.}

\ignore{This research question focuses solely on assessing the ``strength'' of the assertion oracle. To ensure a fair study, we \textit{only} considered test cases where TOGA generated non-empty and correct explicit assertion oracles. We conducted a head-to-head comparison with EvoSuite-generated assertions, taking into account that the total number of test prefixes and assertions is the same across both tools. This approach allows for a fair and direct comparison between TOGA and EvoSuite in terms of their assertion oracle performance.} 

\subsubsection{\textbf{New Artifacts}}

This research question includes all 25 artifacts studied in RQ2.
%; however, we \textit{only} consider the EvoSuite test prefixes for which TOGA generated non-empty and correct assertion oracles.


%\noindent\textbf{Fault Generation Through Mutation.} 
We generate variations of each program using mutation testing, which injects minor code modifications (mutations), e.g., altering conditional predicates and arithmetic operators, to deviate from the intended behavior of the original program. A modified program is called a \textit{mutant}, and a mutant is \textit{killed} if any test fails when running on it, thus detecting the change. A limitation of the TOGA Defects4J study is that tests are generated on fixed program versions – where the bugs the test oracles aim to detect have been fixed – and then those test prefix+TOGA-generated oracles are executed on the buggy versions to catch those same bugs. This is unrealistic since fixed programs are not available when testing buggy versions. Mutation testing offers an alternative that has been  shown to have a statistically significant correlation with real fault detection~\cite{10.1145/2635868.2635929,andrews2005mutation,petrovic2021does}, and is being increasingly used in industry \cite{9524503}. This made it the method of choice in previous studies aimed at measuring the fault detection effectiveness of test oracles~\cite{10.1145/2786805.2786858,schuler2013checked}, which is also the goal of this study. Including both real bugs (RQ1) and mutants of realistic scale applications (RQ3) provides a broader perspective on the replication of TOGA and its evaluation methodology.

In our research, we use PIT, a state-of-the-art mutation testing tool for the Java programs~\cite{coles2016pit}. PIT is compatible with test frameworks like JUnit and can be easily integrated into  development environments~\cite{6605925}. Furthermore, several studies suggested that PIT is more effective than many other existing mutation testing tools in assisting the generation of strong tests, meaningful mutants, and a lower number of equivalent mutants~\cite{kintis2018effective,7927997,7359265}. We use the latest maven plugin for PIT-1.9.8 and, as recommended by the developer of the tool, we only used \texttt{strong} mutators (the rest of the PIT parameters are set to their default values). 


% Figure environment removed

\begin{table*}[h]
\small\centering
% \begin{threeparttable}
% To place a caption above a table
\caption{Fault-detection Effectiveness of EvoSuite and TOGA-generated Assertions.}\label{tab:rq3}
\begin{tabular}[t]{l|c|c|c|c c|c c}
  \toprule
\multirow{2}{*}  \textbf{Artifact} & \textbf{Tests (\#)}  & \textbf{\thead{Generated \\ Mutants (\#)}}   & \multicolumn{5}{c}{\textbf{Mutant Detected by}} \\
\cline{4-8}
& & & \textbf{\thead{Implicit \\Oracle (\#)}} & \textbf{\thead{EvoSuite\\ Assertion (\#)}} & \textbf{\thead{EvoSuite \\Unique (\#)}} & \textbf{\thead{TOGA \\Assertion (\#)}} & \textbf{\thead{TOGA \\Unique (\#)}}\\

\midrule
   
async-http-client& 635& 1,366& 337& 398& 169& 229& 0\\
bcel& 3,911& 5,142& 2,203& 618& 241& 377& 0\\
commons-beanutils& 227& 1,437& 363& 434& 223& 212& 1\\
commons-collections4& 512& 425& 248& 35& 0& 44& 9\\
commons-configuration2& 225& 1,906& 854& 276& 27& 249& 0\\
commons-dbutils& 222& 295& 52& 58& 1& 59& 2\\
commons-geometry& 688& 3,158& 1,407& 611& 99& 512& 0\\
commons-imaging& 1,088& 3,551& 1,073& 676& 257& 420& 1\\
commons-jcs3& 1,251& 1,861& 407& 374& 145& 229& 0\\
commons-jexl3& 1,191& 3,988& 2,509& 522& 71& 451& 0\\
commons-lang3& 2,707& 5,325& 1,581& 1,508& 661& 847& 0\\
commons-net& 667& 1,847& 382& 500& 158& 344& 2\\
commons-numbers& 514& 757& 166& 181& 30& 152& 1\\
commons-pool2& 1,531& 859& 492& 140& 9& 136& 5\\
commons-rng& 68& 1,133& 384& 114& 0& 114& 0\\
commons-validator& 666& 1,722& 452& 462& 27& 436& 1\\
commons-vfs& 349& 1,317& 590& 243& 36& 208& 1\\
commons-weaver& 33& 199& 39& 53& 23& 30& 0\\
http-request& 959& 238& 76& 20& 3& 17& 0\\
joda-time& 4,836& 6,702& 3,582& 957& 355& 652& 50\\
JSON-java& 2,629& 1,088& 303& 185& 69& 119& 3\\
jsoup& 7,910& 4,110& 2,393& 640& 172& 497& 29\\
scribejava& 322& 690& 197& 159& 73& 86& 0\\
spark& 301& 983& 232& 267& 80& 187& 0\\
springside4& 936& 1,286& 275& 383& 97& 286& 0\\
  
\hline
\textbf{Total:} & 34,378&	51,385&	20,597&	9,814&	3,026&	6,893&	105\\												
\bottomrule
\hline
\end{tabular}
\vspace{-3mm}
\end{table*}

%\se{For consistency, I think it would be good to have a subsubsection called ``New artifacts'' here that simply states that we used the artifacts from RQ2 and also explain here how we generated faults since the faults is the new portion of artifact added here -- so the two paragraphs on ``fault generation through mutations'' would be moved into this new subsubsection}

\subsubsection{\textbf{New Procedure}}

To evaluate fault detection effectiveness while controlling for the number of assertions generated across techniques, we exclude all test prefixes for which TOGA did not generate any assertion oracles, generated a false positive assertion, or test prefixes with exception oracles. Then, for each artifact, we generate three different versions of test suites -- TS1, TS2, and TS3 -- of the same size containing those same set of prefixes, but with different assertion oracles. (Figure~\ref{lst:sample_test_from_different_TS} shows a sample test from each suite.)

\begin{itemize}[topsep=1pt,partopsep=0pt,itemsep=1pt,parsep=0pt,leftmargin=*]
    \item \textit{TS1 (EvoSuite prefix only):} 
%This test suite consists of the same set of EvoSuite prefixes as TS1 and TS2 without any assertion oracles. 
each test case contains an EvoSuite-generated test prefix detecting faults through implicit oracles, e.g., uncaught exception.


\item \textit{TS2 (EvoSuite prefix + EvoSuite assertion):} %We consider the same set of test prefixes as TS1 but the assertions are generated by EvoSuite. In the final test suite, 
each test case contains an EvoSuite-generated test prefix and a single EvoSuite-generated assertion oracle for the prefix.

\item \textit{TS3 (EvoSuite prefix + TOGA assertion):} 
%This test suite  consists of the test prefixes for which TOGA generated correct assertion oracles. In the final test suite,
each test case contains an EvoSuite-generated test prefix and a single TOGA-generated assertion oracle for the prefix.
\end{itemize}

\noindent First, we run the test prefixes from \texttt{TS1} on the set of buggy programs (mutants) to catch bugs without any explicit assertions. Second, we run the tests from \texttt{TS2} to record how many additional bugs can be detected by EvoSuite assertions. Third, we run \texttt{TS3} to detect more faults using TOGA-generated assertions. This would allow us to evaluate the added value of TOGA assertions over EvoSuite. Notably, since EvoSuite's tests are part of TOGA's input, it is far to assume they are available at no extra cost whenever TOGA is used.

\begin{lstlisting}[belowskip=-0.4 \baselineskip,float,style=listingstyle,,numbers=left,label={lst:detected_by_ES}, caption={Fault detected by EvoSuite and missed by TOGA}]
private HttpURLConnection createConnection() {
try {
  final HttpURLConnection connection;
  if (httpProxyHost != null)
    connection = CONNECTION_FACTORY.create(url, createProxy());
  else
    connection = CONNECTION_FACTORY.create(url);
    connection.setRequestMethod(requestMethod); ///fault: method call removed
  return connection;
} catch (IOException e) {
  throw new HttpRequestException(e);}
}
public void test1280() throws Throwable  {
 URL uRL0 = MockURL.getHttpExample();
 HttpRequest httpRequest0 = HttpRequest.options(uRL0);
 String string0 = HttpRequest.CONTENT_TYPE_FORM;
 HttpURLConnection htCon = httpRequest0.getConnection();
 assertEquals("OPTIONS", htCon.getRequestMethod());/* Fault Detected By EvoSuite*/
 assertNotNull(htCon.getRequestMethod()); }///Fault Missed by TOGA
\end{lstlisting}


\ignore{\se{Terminology: sometimes `subjects' and sometimes `artifacts', stick to artifacts when talking about programs/faults/etc,  subjects is better suited for developers/humans}}

\subsubsection{\textbf{Results}} 
Table~\ref{tab:rq3} reports the data for the study.
For each artifact (column 1) it provides the number of tests (column 2), number of generated mutants  executed by at least one test  (column 3), and the number of mutants detected by the different test suites: by implicit checks in the runtime system (column 4), by EvoSuite assertions (excluding those already detected by implicit checks, i.e., before reaching the assertion) (column 5), and by TOGA assertions (again, excluding those detected by implicit checks) (column 7).
We break out the data for EvoSuite and TOGA, to report the
mutants uniquely detected by EvoSuite assertions (column 6),  and 
the mutants uniquely detected by TOGA assertions (column 8).

As shown in Table~\ref{tab:rq3}, we have generated more than 51,000 faulty programs using mutation testing, with  20,597 of those detected without any explicit assertion oracles. We use TS1 to detect those mutants. When adding EvoSuite-generated assertions to pair with the EvoSuite test prefixes (TS2), an additional 9,814 mutants were detected including 3,026 unique ones not detected by TOGA assertions. TS3, EvoSuite prefixes with TOGA assertions detected 6,893 mutants, with 105 being distinct from the ones found by TS2.


TOGA uses EvoSuite prefixes and assertions to generate its own assertions. Our study indicates that those assertions are less effective than those in EvoSuite. Even with the same set of prefixes, and the same number of assertions as EvoSuite, TOGA detected nearly 3,000 (30\%) fewer mutants than EvoSuite. Out of 25 artifacts, TOGA did slightly better  for only two artifacts: commons-collections4 and commons-dbutils. For commons-rng, EvoSuite and TOGA detected same mutants. For the remaining 22, EvoSuite detected more mutants, indicating EvoSuite assertions are stronger than TOGA.

In summary, starting from the set of prefixes on which TOGA provided  meaningful assertions (non-empty and not-false positives), out of the 51,385 generated mutants, EvoSuite assertions killed 30,411 (59\%) while TOGA-generated assertions killed 105 additional mutants (0.3\%). %Even to detect that additional faults, one needs to filter the 47\% false positive assertions as shown in RQ2. 

% \vspace{-2mm}
\begin{tcolorbox}
\vspace{-1mm}
\textbf{RQ3 Finding:} 
Despite having the same number of test cases with the same set of prefixes and exactly the same number of assertions, TOGA detected 30\% less faults and 96\% less unique faults than EvoSuite assertions. 105 mutants (0.3\% of the total) were killed exclusively by TOGA.
\vspace{-2mm}
\end{tcolorbox}


\begin{lstlisting} [belowskip=-0.0 \baselineskip,float, style=listingstyle,numbers=left,label={lst:detected_by_toga}, caption={Fault detected by TOGA and missed by EvoSuite Assertion}]
public Integer getFetchDirection() {
  return fetchDirection;  ///Fault: return value modified
}
public void test58()  throws Throwable  {
  StatementConfiguration.Builder scb = new StatementConfiguration.Builder();
  Integer int0 = new Integer((-587));
  scb.fetchDirection(integer0);
  StatementConfiguration sc0 = scb.build();
  Integer int1 = sc0.getFetchDirection();
  assertNotNull(int0);///Fault Not Detected By EvoSuite Assertion
  assertEquals(int0, int1); /*Fault Detected By TOGA*/}
\end{lstlisting}


\noindent\textbf{Additional observations.} To better understand when TOGA may struggle or excel, we perform a deeper examination of the cases in which the generated assertions are the same or differ.

As TOGA uses EvoSuite assertions to extract the variable to assert on, for a given test prefix, 
%the variable under test is the same for the EvoSuite and TOGA assertion oracles. 
%This means that 
%(as shown in Figure \ref{fig:RQ3}). Due to this reason, 
there is no difference between the \texttt{assertTrue} and \texttt{assertFalse} oracles generated by EvoSuite and TOGA. In this study, 33\% of the total assertions are of \texttt{assertTrue} and \texttt{assertFalse} type for both EvoSuite and TOGA. 

When the asserted variable is of type \texttt{object} or primitive types (\texttt{int}, \texttt{float}, \texttt{double}, \texttt{long}), we have already seen that TOGA struggles to generate effective \texttt{assertEquals} oracles as they require a precise expected value.
%As we can see from Table \ref{tab:type_wise_fp}, 73\% of the generated \texttt{assertEquals} oracles are false positives. 
In this study, we find that 17\% of TOGA assertions are \texttt{assertEquals} and 50\% are \texttt{assertNotNull}, while the distribution for EvoSuite is 57\% of \texttt{assertEquals} and 10\% are \texttt{assertNotNull} oracles. This shift in distribution has implications because \texttt{assertEquals} predicates are stronger than \texttt{assertNotNull}. 

Listing~\ref{lst:detected_by_ES} exemplifies this difference for the \texttt{http-request} artifact, where PIT removes the \texttt{connection.setRequestMethod} method call. EvoSuite generated an \texttt{assertEquals} oracle that compares the return value of \texttt{setRequestMethod} with the expected output and is able to kill the mutant.  TOGA generated an \texttt{assertNotNull} oracle that only checks whether the value is not null and thus is not able to kill the mutant.

We found a common pattern among the TOGA assertions that revealed unique mutants: they are able to leverage 
the local constants in the test prefix to generate oracles.
Listing~\ref{lst:detected_by_toga} provides an example for the \texttt{commons-pool2} artifact, which has a method's return value of type Integer object mutated. EvoSuite generates an assertion that only checks the not null condition. Whereas, using the local constants in the test prefix (\texttt{integer0}), TOGA generates an \texttt{assertEquals} oracle that compares two objects, thus killing the mutant.  However, this feature
is also one the main sources for  the high percentage of false positives as shown in Table~\ref{tab:type_wise_fp} where 73\% of the generated \texttt{assertEquals} oracles are false positive. 
% \raggedbottom
\vspace{-1mm}

\ignore{\subsection{Reasons TOGA Performs Struggles}

\se{After reading it   and reading 3.5 and 3.6, I am not sure we need this section. The results are already summarized at the end of the previous RQs in the boxes. We could simply add a sentence under external threats about the OOD if you think is needed -- I know about that second reviewer, but it seems a bit off to me }

Our large-scale study finds that TOGA's exception oracle classifier performs poorly in identifying the test prefixes where an exception is expected, 81\% FPR. Second, TOGA struggles to generate correct  \texttt{assertEquals} oracles as it uses a heuristic that expected values are the most frequently appearing constants and variables in the test prefixes (global and local dictionary, i.e., vocabulary). \se{The following 2/3 sentences sound   more like opinions} However, it is an unrealistic way to collect the ground truth, i.e., expected value. As TOGA already uses EvoSuite to generate test prefixes, a reasonable way is to analyze the dynamic program states to collect the expected values.
\se{This seems to come from nowhere. What is the distribution and why would be the selected dataset outside? I know you are responding to a reviewer comment, but it needs more context here} Out-of-the-distribution (OOD) problem can be another reason TOGA performs poorly; however, EOC and AOR models leverage a pre-trained BERT transformer model. This pre-trained model, CodeBERT, is trained on data points from GitHub repositories and other open sources. We also find that TOGA is not confident enough to generate explicit oracles for more than 62\% correctly classified prefixes. Furthermore, half of the generated assertion oracles are false positives, and true positive assertions are way less effective than original EvoSuite assertions. }


\subsection{Threats to Validity }

Our replication for RQ1 suffers from the same external threats to validity of the original paper,
and somewhat reduced  internal threats given that we were able to successfully run the original tools and scripts with assistance from TOGA's authors. The first replication does, however, address what may be considered a construct validity threat in the original paper in that the intended concept to be measured, the value-added by TOGA, does not account for what a baseline technique can already find, nor for the missclassifications or incomplete assertions of TOGA.

To mitigate the threats to external validity of the original paper, we extended it through our replication with 25 open-source Java applications from various domains and organizations. These applications vary in  program and test suite size, number of test cases with assertions and exception oracles, and the size of their Javadoc. Introducing these applications may have shifted the input distribution  expected by TOGA, although it seems unlikely given the powerful CodeBERT model it uses. We also address the limited number of faults available in the original paper by generating a large number of mutants as proxy for real bugs. A threat that remains is the generalization of the study to test suites generated through other tools beyond EvoSuite, a limitation inherited by the current implementation of TOGA but not intrinsic of the method.

In addition to the original replication package, we have implemented several tools and scripts to conduct our experiments, which may have bugs. To run test suites, we have used JUnit, and to generate mutants, we have used PIT. Even though these tools are well-established and have been used in numerous studies, they may have unknown bugs. To mitigate the threats, we have performed extensive sanity tests and run each experiment multiple times to make sure that we get consistent results, besides making all data and code available at~\cite{replicationPackage} for anyone to review. 
%We also aim at reducing this threat by sharing the repository and data with the community through our GitHub repository to enable further independent replications (see submitted supplementary material).

\subsection{Lessons Learned}

%\se{@Soneya: I really liked this section}
\label{sec:lessons}
Besides shining a new light on the specific performance of TOGA, this study will hopefully inform future evaluation methodologies for similar oracle inference approaches. In particular, besides contributing a large dataset for future evaluations of such techniques, we summarize below three actionable lessons learned.

% \begin{enumerate}[topsep=1pt,partopsep=0pt,itemsep=1pt,parsep=0pt,leftmargin=*]
%     \item The fault-detection effectiveness of complex oracle generation methods should be assessed relative to the presence of implicit oracles in underlying test execution frameworks (as also recently recommended for assessing test oracles in general~\cite{fse22prefixFailures}). JUnit's fail-on-exception implicit oracle was responsible for the detection of a large portion of the bugs attributed to TOGA's oracles in the original study, while there were no assertions or the execution failed before reaching to the assertions. (RQ1)
%     \item The precision of the generated oracles should be a central evaluation metric for a realistic assessment of oracle generation methods. Imprecise oracles will require developers to diagnose and repair failing tests due to false positive assertions. Recall should be always evaluated together with precision. (RQ2)
%     \item Generating test oracles from fixed programs may inappropriately bias findings. In such cases, just executing the test prefixes generated from the fixed versions is often sufficient to detect many bugs in the buggy versions. More systematic evaluation approaches, such as mutation testing, that more closely reflect how a developer can practically assess a test suite in the real world should be included in the evaluation of automated test generation methods. (RQ3)
% \end{enumerate}

% An important lesson from this finding is that future studies should employ “No Exception” as a baseline and then report performance improvements over it to establish a more realistic comparison 


\noindent \,1) \add{JUnit implicit oracle detected over 50\% of both real and injected bugs. The ability of detecting unexpected exceptional behaviors via the sole execution of the test prefixes that emerged from our experiments is also consistent with previous studies~\cite{schuler2013checked, 10.1145/3510003.3510141, fse22prefixFailures}. 
Therefore, in a realistic evaluation setting, one should use these implicit, i.e., ``No Exception'' oracles as the baseline and report the fault-detection effectiveness improvement relative to the implicit oracle}. (RQ1)


\noindent \,2) The precision of the generated oracles should be a central evaluation metric for a realistic assessment of oracle generation methods. Imprecise oracles will require developers to diagnose and repair failing tests due to false positive assertions. Recall should be always evaluated together with precision. (RQ2)

 \noindent \,3) Using test prefixes generated from fixed programs to catch bugs in the buggy versions may inappropriately bias findings. In such cases, just executing the test prefixes generated from the fixed versions on the buggy versions is often sufficient to detect many bugs. More systematic evaluation approaches, such as mutation testing, that more closely reflect how a developer can practically assess a test suite in the real world should be included in the evaluation of automated test generation methods. (RQ3)
 


\section{Conclusions}

% \deleted{Machine learning methods for automated test oracle generation, and neural methods in particular, have shown promising results in their ability to generate oracles with high bug detection rate. }


% The key to the success of neural test oracle generation is a combination of general language models with information specific to the program under test -- not limited to the syntax of its code but often including semantic information, such as variable types. 

In this paper, we replicated with a different and broader experimental protocol TOGA~\cite{10.1145/3510003.3510141}, a recent neural-based oracle generation method. Our study aimed at 1) investigating more closely the added bug detection value of TOGA-generated oracles, 2) evaluating the precision of TOGA in terms of false positive bug reports from its oracle, and 3) evaluating the defect prediction recall using mutation testing methods. 
For our first objective, we obtained results consistent with the original study: TOGA detected the same 57 bugs. However, upon deeper investigation, only 19 detections are imputable to TOGA's exception or assertion oracles, while for the other 38 the sole execution of the test prefix -- generated by EvoSuite -- threw exceptions making the test fail. 
The second and third objectives involved a broader set of subjects. While TOGA generated assertions only for half of the test prefixes, 47\% of the assertions produced false positive reports, besides misclassifying whether an exception or an assertion oracle was needed for an average of 24\% of the test prefixes. Finally, we differentially compared the mutation killings counts of JUnit failures due to unexpected exceptions, EvoSuite assertions, and TOGA assertions, observing that out of the 51,385 mutants, only 105 were killed exclusively by TOGA assertions.

%While TOGA did detect several bugs detected by neither JUnit's implicit oracle nor EvoSuite, most of the bug reports originally attributed to TOGA's oracle are in fact due to JUnit's and EvoSuite's oracles. Furthermore, the false positive rate of TOGA reports may place a significant time cost on engineering teams to discern true and false findings. 
Overall, while TOGA's innovative approach will likely bear fruitful future research directions, our study suggests the need for deeper investigation of the reasons behind findings produced by learning-based methods, and a challenge for the research community to develop techniques for reducing their currently too high false positive rate to enable industrial adoption.

% \section{Data Availability}
% We have provided a replication package on figshare at \\ \href{https://figshare.com/s/5692546ed32f83d77da7}{https://figshare.com/s/5692546ed32f83d77da7} consisting of all required data, tools, scripts, and complete documentation so that anyone can reproduce the results and reuse our codes for replicating and repurposing. 





\vspace{2mm}
%\noindent \textbf{Data availability:} all the datasets, tools, and scripts to reproduce the experiments in our study are available and documented at~\cite{replicationPackage}.



% \ignore{
% TOGA is a neural-based automated test oracle generation technique that generates three type of test oracles: no exception should be thrown, exception should be thrown and assertion oracles to check program output against expected output. 

% Test oracle that checks ``no exception should be thrown'' is a default oracle in most testing framework, such as JUnit. For example, a test case will fail if any unintended exception is thrown during execution. Therefore, 39 out of the 58 bugs detected by TOGA can be detected by JUnit, without any TOGA oracles at all. Our experimental results show that 18\% times, TOGA fails to correctly predict this type of oracle, however, more that 80\% times, it correctly predicts that no exception should be raised. 

% Test oracle that checks ``exception should be thrown'' is important, as test cases should test whether an intended exception is thrown or not. While we agree that this type of oracles are important, our experimental result shows for more than 81\% times, TOGA fails to correctly detect that an exception is expected.

% While testing exceptional behavior is critical, to capture functional faults, assertion oracles are a must. Our experimental results show that for around 70\% times, for a test prefix, where an assertion oracle is expected, 
% TOGA did not generate any assertion oracles. Only 30\% times TOGA generated an assertion oracle, and 47\% of them are false positives. Furthermore, our investigation shows that the generated assertions are 96\% less strong than EvoSuite assertions when detecting unique faults. 
% }

% \se{I think the conclusion should be organized by replication, the following paragraph mixes both?}
% In this paper, first, we replicated the original \texttt{Defects4j} study of the TOGA paper and found that a majority (39) of the detected bugs can be detected by JUnit implicit oracles without any TOGA oracles, which is an overestimation of the fault detection effectiveness of TOGA. 

% Next, we evaluate the effectiveness of TOGA on a broader and newer set of of large-scale real-world systems. We found that 24\% time, TOGA failed to predict which type of oracles are required. For example, when an assertion oracle is expected, 18\% are misclassified, 50\% are classified correctly but no assertions are generated and 47\% of the generated assertions are false positive. When an exception oracle is required, 81\% time, TOGA misclassified them. Furthermore, our study also shows that TOGA generated assertions are generic and thus lack fault-detection effectiveness. When compared to EvoSuite assertion, TOGA detected 30\% less bugs and 96\% less unique bugs.

% Our replication  with TOGA on a significantly larger collection of programs confirmed the misclassification rate reported in~\cite{10.1145/3510003.3510141}.  We found, however, much higher rates of empty assertion oracles (+10\% pp) and of false positive assertions (+24\% pp) than was found in the TOGA \texttt{Defects4j} study.  Moreover, in accounting for the default behavior of the JUnit test execution infrastructure we found that the added value of TOGA generated oracles in a large-scale fault detection study was much lower than originally reported.




% These findings suggest that the current implementation of TOGA is neither sufficiently precise nor generates sufficiently strong assertions to be used in practice.
% There is, however, plenty of potential for improving TOGA in both of these regards.

% Even though TOGA supports docstrings written in any format, our investigation shows that the presence of docstring does not affect TOGA's oracle prediction. For example, running the same set of inputs for detecting the \texttt{Defects4j} bugs in the TOGA study with and without docstrings yielded identical oracle predictions. Moreover, when generating \texttt{assertEquals} oracles, TOGA infers the expected value based on the heuristic that expected values are those that frequently appear in the training data and test prefixes. This was a significant source of false positives in our study, but it stands to reason that better leveraging the rich information in docstrings could improve the prediction of the expected values. 

\section*{Acknowledgements}
This material is based in part upon work supported by the DARPA ARCOS program under contract FA8750-20-C-0507, by The Air Force Office of Scientific Research under award number FA9550-21-0164, and by Lockheed Martin Advanced Technology Laboratories.

We are thankful to Gabriel Ryan for assisting in running the TOGA replication package. 

\newpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{fse-2023}
\end{document}
\endinput
%%
%% End of file `sample-acmtog.tex'.
 