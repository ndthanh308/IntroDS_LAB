{
  "title": "Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space",
  "authors": [
    "Eduardo Fernandes Montesuma",
    "Fred Ngol√® Mboula",
    "Antoine Souloumiac"
  ],
  "submission_date": "2023-07-27T15:46:59+00:00",
  "revised_dates": [
    "2023-08-22T07:33:53+00:00",
    "2023-11-08T09:46:54+00:00"
  ],
  "abstract": "This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification performance. Finally, we show that interpolations in the Wasserstein hull of learned atoms provide data that can generalize to the target domain.",
  "categories": [
    "cs.LG",
    "cs.AI",
    "stat.ML"
  ],
  "primary_category": "cs.LG",
  "doi": "10.3233/FAIA230459",
  "journal_ref": null,
  "arxiv_id": "2307.14953",
  "pdf_url": "https://arxiv.org/pdf/2307.14953v3",
  "comment": "13 pages,8 figures,Published as a conference paper at the 26th European Conference on Artificial Intelligence; v2: corrected typos",
  "num_versions": null,
  "size_before_bytes": 7140725,
  "size_after_bytes": 588537
}