\begin{thebibliography}{10}

\bibitem{afriat1971theory}
SN~Afriat, `Theory of maxima and the method of lagrange', {\em SIAM Journal on
  Applied Mathematics}, {\bf 20}(3),  343--357, (1971).

\bibitem{agueh2011barycenters}
Martial Agueh and Guillaume Carlier, `Barycenters in the wasserstein space',
  {\em SIAM Journal on Mathematical Analysis}, {\bf 43}(2),  904--924, (2011).

\bibitem{alvarez2020geometric}
David Alvarez-Melis and Nicolo Fusi, `Geometric dataset distances via optimal
  transport', {\em Advances in Neural Information Processing Systems}, {\bf
  33},  21428--21439, (2020).

\bibitem{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan, `A theory of learning from different domains', {\em
  Machine learning}, {\bf 79}(1),  151--175, (2010).

\bibitem{bolley2007quantitative}
Fran{\c{c}}ois Bolley, Arnaud Guillin, and C{\'e}dric Villani, `Quantitative
  concentration inequalities for empirical measures on non-compact spaces',
  {\em Probability Theory and Related Fields}, {\bf 137}(3-4),  541--593,
  (2007).

\bibitem{bonneel2016wasserstein}
Nicolas Bonneel, Gabriel Peyr{\'e}, and Marco Cuturi, `Wasserstein barycentric
  coordinates: histogram regression using optimal transport.', {\em ACM Trans.
  Graph.}, {\bf 35}(4),  71--1, (2016).

\bibitem{condat2016fast}
Laurent Condat, `Fast projection onto the simplex and the {$\ell_{1}$} ball',
  {\em Mathematical Programming}, {\bf 158}(1),  575--585, (2016).

\bibitem{courty2017joint}
Nicolas Courty, R{\'e}mi Flamary, Amaury Habrard, and Alain Rakotomamonjy,
  `Joint distribution optimal transportation for domain adaptation', {\em
  Advances in Neural Information Processing Systems}, {\bf 30}, (2017).

\bibitem{courty2016optimal}
Nicolas Courty, R{\'e}mi Flamary, Devis Tuia, and Alain Rakotomamonjy, `Optimal
  transport for domain adaptation', {\em IEEE transactions on pattern analysis
  and machine intelligence}, {\bf 39}(9),  1853--1865, (2016).

\bibitem{cuturi2013sinkhorn}
Marco Cuturi, `Sinkhorn distances: Lightspeed computation of optimal
  transport', {\em Advances in neural information processing systems}, {\bf
  26}, (2013).

\bibitem{cuturi2014fast}
Marco Cuturi and Arnaud Doucet, `Fast computation of wasserstein barycenters',
  in {\em International conference on machine learning}, pp. 685--693. PMLR,
  (2014).

\bibitem{damodaran2018deepjdot}
Bharath~Bhushan Damodaran, Benjamin Kellenberger, R{\'e}mi Flamary, Devis Tuia,
  and Nicolas Courty, `Deepjdot: Deep joint distribution optimal transport for
  unsupervised domain adaptation', in {\em Proceedings of the European
  Conference on Computer Vision (ECCV)}, pp. 447--463, (2018).

\bibitem{fatras2020learning}
Kilian Fatras, Younes Zine, R{\'e}mi Flamary, R{\'e}mi Gribonval, and Nicolas
  Courty, `Learning with minibatch wasserstein: asymptotic and gradient
  properties', in {\em AISTATS}, (2020).

\bibitem{fatras2021minibatch}
Kilian Fatras, Younes Zine, Szymon Majewski, R{\'e}mi Flamary, R{\'e}mi
  Gribonval, and Nicolas Courty, `Minibatch optimal transport distances;
  analysis and applications', {\em arXiv preprint arXiv:2101.01792}, (2021).

\bibitem{fernando2013unsupervised}
Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars,
  `Unsupervised visual domain adaptation using subspace alignment', in {\em
  Proceedings of the IEEE international conference on computer vision}, pp.
  2960--2967, (2013).

\bibitem{feydy2019interpolating}
Jean Feydy, Thibault S{\'e}journ{\'e}, Fran{\c{c}}ois-Xavier Vialard, Shun-ichi
  Amari, Alain Trouv{\'e}, and Gabriel Peyr{\'e}, `Interpolating between
  optimal transport and mmd using sinkhorn divergences', in {\em The 22nd
  International Conference on Artificial Intelligence and Statistics}, pp.
  2681--2690. PMLR, (2019).

\bibitem{flamary2021pot}
R{\'e}mi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar~Z Alaya,
  Aur{\'e}lie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos,
  Kilian Fatras, Nemo Fournier, et~al., `Pot: Python optimal transport.', {\em
  J. Mach. Learn. Res.}, {\bf 22}(78),  1--8, (2021).

\bibitem{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky,
  `Domain-adversarial training of neural networks', {\em The journal of machine
  learning research}, {\bf 17}(1),  2096--2030, (2016).

\bibitem{griffin2007caltech}
Gregory Griffin, Alex Holub, and Pietro Perona, `Caltech-256 object category
  dataset', Technical report, California Institute of Technology, (2007).

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, `Deep residual learning
  for image recognition', in {\em Proceedings of the IEEE conference on
  computer vision and pattern recognition}, pp. 770--778, (2016).

\bibitem{held1974validation}
Michael Held, Philip Wolfe, and Harlan~P Crowder, `Validation of subgradient
  optimization', {\em Mathematical programming}, {\bf 6}(1),  62--88, (1974).

\bibitem{huang2013coupled}
De-An Huang and Yu-Chiang~Frank Wang, `Coupled dictionary and feature space
  learning with applications to cross-domain image synthesis and recognition',
  in {\em Proceedings of the IEEE international conference on computer vision},
  pp. 2496--2503, (2013).

\bibitem{montesuma2021cvpr}
Eduardo~Fernandes Montesuma and Fred Maurice~Ngole Mboula, `Wasserstein
  barycenter for multi-source domain adaptation', in {\em Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.
  16785--16793, (June 2021).

\bibitem{montesuma2021icassp}
Eduardo~Fernandes Montesuma and Fred Maurice~Ngole Mboula, `Wasserstein
  barycenter transport for acoustic adaptation', in {\em ICASSP 2021 - 2021
  IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp. 3405--3409, (May 2021).

\bibitem{montesuma2023recent}
Eduardo~Fernandes Montesuma, Fred~Ngole Mboula, and Antoine Souloumiac, `Recent
  advances in optimal transport for machine learning', {\em arXiv preprint
  arXiv:2306.16156}, (2023).

\bibitem{pan2010domain}
Sinno~Jialin Pan, Ivor~W Tsang, James~T Kwok, and Qiang Yang, `Domain
  adaptation via transfer component analysis', {\em IEEE transactions on neural
  networks}, {\bf 22}(2),  199--210, (2010).

\bibitem{pan2009survey}
Sinno~Jialin Pan and Qiang Yang, `A survey on transfer learning', {\em IEEE
  Transactions on knowledge and data engineering}, {\bf 22}(10),  1345--1359,
  (2009).

\bibitem{paszke2017automatic}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala, `Pytorch: An imperative style, high-performance deep learning
  library', in {\em Advances in Neural Information Processing Systems 32},
  eds., H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett,  8024--8035, Curran Associates, Inc.,
  (2019).

\bibitem{peng2019moment}
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo~Wang,
  `Moment matching for multi-source domain adaptation', in {\em Proceedings of
  the IEEE/CVF international conference on computer vision}, pp. 1406--1415,
  (2019).

\bibitem{peyre2019computational}
Gabriel Peyr{\'e}, Marco Cuturi, et~al., `Computational optimal transport: With
  applications to data science', {\em Foundations and Trends{\textregistered}
  in Machine Learning}, {\bf 11}(5-6),  355--607, (2019).

\bibitem{redko2017theoretical}
Ievgen Redko, Amaury Habrard, and Marc Sebban, `Theoretical analysis of domain
  adaptation with optimal transport', in {\em Joint European Conference on
  Machine Learning and Knowledge Discovery in Databases}, pp. 737--753.
  Springer, (2017).

\bibitem{redko2019advances}
Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Younes Bennani,
  {\em Advances in domain adaptation theory}, Elsevier, 2019.

\bibitem{redko2020survey}
Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Youn{\`e}s
  Bennani, `A survey on domain adaptation theory: learning bounds and
  theoretical guarantees', {\em arXiv preprint arXiv:2004.11829}, (2020).

\bibitem{ringwald2021adaptiope}
Tobias Ringwald and Rainer Stiefelhagen, `Adaptiope: A modern benchmark for
  unsupervised domain adaptation', in {\em Proceedings of the IEEE/CVF Winter
  Conference on Applications of Computer Vision}, pp. 101--110, (2021).

\bibitem{rolet2016fast}
Antoine Rolet, Marco Cuturi, and Gabriel Peyr{\'e}, `Fast dictionary learning
  with a smoothed wasserstein loss', in {\em Artificial Intelligence and
  Statistics}, pp. 630--638. PMLR, (2016).

\bibitem{saenko2010adapting}
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell, `Adapting visual
  category models to new domains', in {\em European conference on computer
  vision}, pp. 213--226. Springer, (2010).

\bibitem{santambrogio2015optimal}
Filippo Santambrogio, `Optimal transport for applied mathematicians', {\em
  Birk{\"a}user, NY}, {\bf 55}(58-63), ~94, (2015).

\bibitem{schmitz2018wasserstein}
Morgan~A Schmitz, Matthieu Heitz, Nicolas Bonneel, Fred Ngole, David
  Coeurjolly, Marco Cuturi, Gabriel Peyr{\'e}, and Jean-Luc Starck,
  `Wasserstein dictionary learning: Optimal transport-based unsupervised
  nonlinear dictionary learning', {\em SIAM Journal on Imaging Sciences}, {\bf
  11}(1),  643--678, (2018).

\bibitem{shen2018wasserstein}
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu, `Wasserstein distance guided
  representation learning for domain adaptation', in {\em Proceedings of the
  AAAI Conference on Artificial Intelligence}, volume~32, (2018).

\bibitem{sugiyama2007covariate}
Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert M{\"u}ller, `Covariate
  shift adaptation by importance weighted cross validation.', {\em Journal of
  Machine Learning Research}, {\bf 8}(5), (2007).

\bibitem{turrisi2022multi}
Rosanna Turrisi, R{\'e}mi Flamary, Alain Rakotomamonjy, et~al., `Multi-source
  domain adaptation via weighted joint distributions optimal transport', in
  {\em The 38th Conference on Uncertainty in Artificial Intelligence}, (2022).

\bibitem{vapnik1991principles}
Vladimir Vapnik, `Principles of risk minimization for learning theory', {\em
  Advances in neural information processing systems}, {\bf 4}, (1991).

\bibitem{villani2009optimal}
C{\'e}dric Villani, {\em Optimal transport: old and new}, volume 338, Springer,
  2009.

\bibitem{wang2020learning}
Hang Wang, Minghao Xu, Bingbing Ni, and Wenjun Zhang, `Learning to combine:
  Knowledge aggregation for multi-source domain adaptation', in {\em Computer
  Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28,
  2020, Proceedings, Part VIII 16}, pp. 727--744. Springer, (2020).

\bibitem{zhang2018intelligent}
Bo~Zhang, Wei Li, Xiao-Li Li, and See-Kiong Ng, `Intelligent fault diagnosis
  under varying working conditions based on domain adaptive convolutional
  neural networks', {\em Ieee Access}, {\bf 6},  66367--66384, (2018).

\end{thebibliography}
