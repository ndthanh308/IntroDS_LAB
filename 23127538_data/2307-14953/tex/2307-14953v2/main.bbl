\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Courty et~al.(2016)Courty, Flamary, Tuia, and
  Rakotomamonjy]{courty2016optimal}
Nicolas Courty, R{\'e}mi Flamary, Devis Tuia, and Alain Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 39\penalty0 (9):\penalty0 1853--1865, 2016.

\bibitem[Courty et~al.(2017)Courty, Flamary, Habrard, and
  Rakotomamonjy]{courty2017joint}
Nicolas Courty, R{\'e}mi Flamary, Amaury Habrard, and Alain Rakotomamonjy.
\newblock Joint distribution optimal transportation for domain adaptation.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Damodaran et~al.(2018)Damodaran, Kellenberger, Flamary, Tuia, and
  Courty]{damodaran2018deepjdot}
Bharath~Bhushan Damodaran, Benjamin Kellenberger, R{\'e}mi Flamary, Devis Tuia,
  and Nicolas Courty.
\newblock Deepjdot: Deep joint distribution optimal transport for unsupervised
  domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 447--463, 2018.

\bibitem[Montesuma and Mboula(2021{\natexlab{a}})]{montesuma2021cvpr}
Eduardo~Fernandes Montesuma and Fred Maurice~Ngole Mboula.
\newblock Wasserstein barycenter for multi-source domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 16785--16793, June 2021{\natexlab{a}}.

\bibitem[Montesuma and Mboula(2021{\natexlab{b}})]{montesuma2021icassp}
Eduardo~Fernandes Montesuma and Fred Maurice~Ngole Mboula.
\newblock Wasserstein barycenter transport for acoustic adaptation.
\newblock In \emph{ICASSP 2021 - 2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pages 3405--3409, May
  2021{\natexlab{b}}.
\newblock \doi{10.1109/ICASSP39728.2021.9414199}.

\bibitem[Turrisi et~al.(2022)Turrisi, Flamary, Rakotomamonjy,
  et~al.]{turrisi2022multi}
Rosanna Turrisi, R{\'e}mi Flamary, Alain Rakotomamonjy, et~al.
\newblock Multi-source domain adaptation via weighted joint distributions
  optimal transport.
\newblock In \emph{The 38th Conference on Uncertainty in Artificial
  Intelligence}, 2022.

\bibitem[Rolet et~al.(2016)Rolet, Cuturi, and Peyr{\'e}]{rolet2016fast}
Antoine Rolet, Marco Cuturi, and Gabriel Peyr{\'e}.
\newblock Fast dictionary learning with a smoothed wasserstein loss.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 630--638.
  PMLR, 2016.

\bibitem[Schmitz et~al.(2018)Schmitz, Heitz, Bonneel, Ngole, Coeurjolly,
  Cuturi, Peyr{\'e}, and Starck]{schmitz2018wasserstein}
Morgan~A Schmitz, Matthieu Heitz, Nicolas Bonneel, Fred Ngole, David
  Coeurjolly, Marco Cuturi, Gabriel Peyr{\'e}, and Jean-Luc Starck.
\newblock Wasserstein dictionary learning: Optimal transport-based unsupervised
  nonlinear dictionary learning.
\newblock \emph{SIAM Journal on Imaging Sciences}, 11\penalty0 (1):\penalty0
  643--678, 2018.

\bibitem[Redko et~al.(2017)Redko, Habrard, and Sebban]{redko2017theoretical}
Ievgen Redko, Amaury Habrard, and Marc Sebban.
\newblock Theoretical analysis of domain adaptation with optimal transport.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 737--753. Springer, 2017.

\bibitem[Sugiyama et~al.(2007)Sugiyama, Krauledat, and
  M{\"u}ller]{sugiyama2007covariate}
Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert M{\"u}ller.
\newblock Covariate shift adaptation by importance weighted cross validation.
\newblock \emph{Journal of Machine Learning Research}, 8\penalty0 (5), 2007.

\bibitem[Pan and Yang(2009)]{pan2009survey}
Sinno~Jialin Pan and Qiang Yang.
\newblock A survey on transfer learning.
\newblock \emph{IEEE Transactions on knowledge and data engineering},
  22\penalty0 (10):\penalty0 1345--1359, 2009.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The journal of machine learning research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Shen et~al.(2018)Shen, Qu, Zhang, and Yu]{shen2018wasserstein}
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu.
\newblock Wasserstein distance guided representation learning for domain
  adaptation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and
  Wang]{peng2019moment}
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo~Wang.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 1406--1415, 2019.

\bibitem[Huang and Wang(2013)]{huang2013coupled}
De-An Huang and Yu-Chiang~Frank Wang.
\newblock Coupled dictionary and feature space learning with applications to
  cross-domain image synthesis and recognition.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2496--2503, 2013.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock \emph{Advances in neural information processing systems}, 26, 2013.

\bibitem[Vapnik(1991)]{vapnik1991principles}
Vladimir Vapnik.
\newblock Principles of risk minimization for learning theory.
\newblock \emph{Advances in neural information processing systems}, 4, 1991.

\bibitem[Redko et~al.(2020)Redko, Morvant, Habrard, Sebban, and
  Bennani]{redko2020survey}
Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Youn{\`e}s
  Bennani.
\newblock A survey on domain adaptation theory: learning bounds and theoretical
  guarantees.
\newblock \emph{arXiv preprint arXiv:2004.11829}, 2020.

\bibitem[Montesuma et~al.(2023)Montesuma, Mboula, and
  Souloumiac]{montesuma2023recent}
Eduardo~Fernandes Montesuma, Fred~Ngole Mboula, and Antoine Souloumiac.
\newblock Recent advances in optimal transport for machine learning.
\newblock \emph{arXiv preprint arXiv:2306.16156}, 2023.

\bibitem[Peyr{\'e} et~al.(2019)Peyr{\'e}, Cuturi,
  et~al.]{peyre2019computational}
Gabriel Peyr{\'e}, Marco Cuturi, et~al.
\newblock Computational optimal transport: With applications to data science.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  11\penalty0 (5-6):\penalty0 355--607, 2019.

\bibitem[Santambrogio(2015)]{santambrogio2015optimal}
Filippo Santambrogio.
\newblock Optimal transport for applied mathematicians.
\newblock \emph{Birk{\"a}user, NY}, 55\penalty0 (58-63):\penalty0 94, 2015.

\bibitem[Agueh and Carlier(2011)]{agueh2011barycenters}
Martial Agueh and Guillaume Carlier.
\newblock Barycenters in the wasserstein space.
\newblock \emph{SIAM Journal on Mathematical Analysis}, 43\penalty0
  (2):\penalty0 904--924, 2011.

\bibitem[Cuturi and Doucet(2014)]{cuturi2014fast}
Marco Cuturi and Arnaud Doucet.
\newblock Fast computation of wasserstein barycenters.
\newblock In \emph{International conference on machine learning}, pages
  685--693. PMLR, 2014.

\bibitem[Fatras et~al.(2021)Fatras, Zine, Majewski, Flamary, Gribonval, and
  Courty]{fatras2021minibatch}
Kilian Fatras, Younes Zine, Szymon Majewski, R{\'e}mi Flamary, R{\'e}mi
  Gribonval, and Nicolas Courty.
\newblock Minibatch optimal transport distances; analysis and applications.
\newblock \emph{arXiv preprint arXiv:2101.01792}, 2021.

\bibitem[Alvarez-Melis and Fusi(2020)]{alvarez2020geometric}
David Alvarez-Melis and Nicolo Fusi.
\newblock Geometric dataset distances via optimal transport.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21428--21439, 2020.

\bibitem[Redko et~al.(2019)Redko, Morvant, Habrard, Sebban, and
  Bennani]{redko2019advances}
Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Younes Bennani.
\newblock \emph{Advances in domain adaptation theory}.
\newblock Elsevier, 2019.

\bibitem[Afriat(1971)]{afriat1971theory}
SN~Afriat.
\newblock Theory of maxima and the method of lagrange.
\newblock \emph{SIAM Journal on Applied Mathematics}, 20\penalty0 (3):\penalty0
  343--357, 1971.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2017automatic}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems 32}, pages 8024--8035. Curran Associates,
  Inc., 2019.

\bibitem[Flamary et~al.(2021)Flamary, Courty, Gramfort, Alaya, Boisbunon,
  Chambon, Chapel, Corenflos, Fatras, Fournier, et~al.]{flamary2021pot}
R{\'e}mi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar~Z Alaya,
  Aur{\'e}lie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos,
  Kilian Fatras, Nemo Fournier, et~al.
\newblock Pot: Python optimal transport.
\newblock \emph{J. Mach. Learn. Res.}, 22\penalty0 (78):\penalty0 1--8, 2021.

\bibitem[Griffin et~al.(2007)Griffin, Holub, and Perona]{griffin2007caltech}
Gregory Griffin, Alex Holub, and Pietro Perona.
\newblock Caltech-256 object category dataset.
\newblock Technical report, California Institute of Technology, 2007.

\bibitem[Saenko et~al.(2010)Saenko, Kulis, Fritz, and
  Darrell]{saenko2010adapting}
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell.
\newblock Adapting visual category models to new domains.
\newblock In \emph{European conference on computer vision}, pages 213--226.
  Springer, 2010.

\bibitem[Fernando et~al.(2013)Fernando, Habrard, Sebban, and
  Tuytelaars]{fernando2013unsupervised}
Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars.
\newblock Unsupervised visual domain adaptation using subspace alignment.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2960--2967, 2013.

\bibitem[Pan et~al.(2010)Pan, Tsang, Kwok, and Yang]{pan2010domain}
Sinno~Jialin Pan, Ivor~W Tsang, James~T Kwok, and Qiang Yang.
\newblock Domain adaptation via transfer component analysis.
\newblock \emph{IEEE transactions on neural networks}, 22\penalty0
  (2):\penalty0 199--210, 2010.

\bibitem[Bonneel et~al.(2016)Bonneel, Peyr{\'e}, and
  Cuturi]{bonneel2016wasserstein}
Nicolas Bonneel, Gabriel Peyr{\'e}, and Marco Cuturi.
\newblock Wasserstein barycentric coordinates: histogram regression using
  optimal transport.
\newblock \emph{ACM Trans. Graph.}, 35\penalty0 (4):\penalty0 71--1, 2016.

\bibitem[Ringwald and Stiefelhagen(2021)]{ringwald2021adaptiope}
Tobias Ringwald and Rainer Stiefelhagen.
\newblock Adaptiope: A modern benchmark for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 101--110, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Zhang et~al.(2018)Zhang, Li, Li, and Ng]{zhang2018intelligent}
Bo~Zhang, Wei Li, Xiao-Li Li, and See-Kiong Ng.
\newblock Intelligent fault diagnosis under varying working conditions based on
  domain adaptive convolutional neural networks.
\newblock \emph{Ieee Access}, 6:\penalty0 66367--66384, 2018.

\bibitem[Wang et~al.(2020)Wang, Xu, Ni, and Zhang]{wang2020learning}
Hang Wang, Minghao Xu, Bingbing Ni, and Wenjun Zhang.
\newblock Learning to combine: Knowledge aggregation for multi-source domain
  adaptation.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part VIII 16}, pages 727--744.
  Springer, 2020.

\bibitem[Villani(2009)]{villani2009optimal}
C{\'e}dric Villani.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer, 2009.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1):\penalty0 151--175, 2010.

\bibitem[Bolley et~al.(2007)Bolley, Guillin, and
  Villani]{bolley2007quantitative}
Fran{\c{c}}ois Bolley, Arnaud Guillin, and C{\'e}dric Villani.
\newblock Quantitative concentration inequalities for empirical measures on
  non-compact spaces.
\newblock \emph{Probability Theory and Related Fields}, 137\penalty0
  (3-4):\penalty0 541--593, 2007.

\bibitem[Feydy et~al.(2019)Feydy, S{\'e}journ{\'e}, Vialard, Amari, Trouv{\'e},
  and Peyr{\'e}]{feydy2019interpolating}
Jean Feydy, Thibault S{\'e}journ{\'e}, Fran{\c{c}}ois-Xavier Vialard, Shun-ichi
  Amari, Alain Trouv{\'e}, and Gabriel Peyr{\'e}.
\newblock Interpolating between optimal transport and mmd using sinkhorn
  divergences.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 2681--2690. PMLR, 2019.

\bibitem[Held et~al.(1974)Held, Wolfe, and Crowder]{held1974validation}
Michael Held, Philip Wolfe, and Harlan~P Crowder.
\newblock Validation of subgradient optimization.
\newblock \emph{Mathematical programming}, 6\penalty0 (1):\penalty0 62--88,
  1974.

\bibitem[Condat(2016)]{condat2016fast}
Laurent Condat.
\newblock Fast projection onto the simplex and the {$\ell_{1}$} ball.
\newblock \emph{Mathematical Programming}, 158\penalty0 (1):\penalty0 575--585,
  2016.

\bibitem[Fatras et~al.(2020)Fatras, Zine, Flamary, Gribonval, and
  Courty]{fatras2020learning}
Kilian Fatras, Younes Zine, R{\'e}mi Flamary, R{\'e}mi Gribonval, and Nicolas
  Courty.
\newblock Learning with minibatch wasserstein: asymptotic and gradient
  properties.
\newblock In \emph{AISTATS}, 2020.

\end{thebibliography}
