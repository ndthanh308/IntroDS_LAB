\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{adegun2021deep}
Adegun, A., Viriri, S.: Deep learning techniques for skin lesion analysis and
  melanoma cancer detection: a survey of state-of-the-art. Artificial
  Intelligence Review  \textbf{54},  811--841 (2021)

\bibitem{bahng2022visual}
Bahng, H., Jahanian, A., et~al.: Visual prompting: Modifying pixel space to
  adapt pre-trained models. arXiv preprint arXiv:2203.17274  (2022)

\bibitem{ballerini2013color}
Ballerini, L., Fisher, R.B., Aldridge, B., Rees, J.: A color and texture based
  hierarchical {K-NN} approach to the classification of non-melanoma skin
  lesions. In: Color medical image analysis, pp. 63--86. Springer (2013)

\bibitem{birkenfeld2020computer}
Birkenfeld, J.S., Tucker-Schwartz, J.M., et~al.: Computer-aided classification
  of suspicious pigmented lesions using wide-field images. Computer methods and
  programs in biomedicine  \textbf{195},  105631 (2020)

\bibitem{cao2023swin}
Cao, H., Wang, Y., et~al.: {SwinUnet}: Unet-like pure transformer for medical
  image segmentation. In: ECCV 2022 Workshops. pp. 205--218. Springer (2023)

\bibitem{chen2017deeplab}
Chen, L.C., Papandreou, G., et~al.: {DeepLab}: Semantic image segmentation with
  deep convolutional nets, atrous convolution, and fully connected {CRFs}. IEEE
  transactions on pattern analysis and machine intelligence  \textbf{40}(4),
  834--848 (2017)

\bibitem{chen2022adaptformer}
Chen, S., Ge, C., Tong, Z., Wang, J., Song, Y., et~al.: {AdaptFormer}: Adapting
  vision transformers for scalable visual recognition. In: NeurIPS 2022 (2022)

\bibitem{codella2019skin}
Codella, N., Rotemberg, V., Tschandl, P., Celebi, M.E., Dusza, S., et~al.: Skin
  lesion analysis toward melanoma detection 2018: A challenge hosted by the
  international skin imaging collaboration ({ISIC}). arXiv preprint
  arXiv:1902.03368  (2019)

\bibitem{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: {ImageNet}: A
  large-scale hierarchical image database. In: CVPR 2009. pp. 248--255. Ieee
  (2009)

\bibitem{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., et~al.: An image is worth 16x16
  words: Transformers for image recognition at scale. In: ICLR 2020 (2020)

\bibitem{du2023mdvit}
Du, S., Bayasi, N., Harmarneh, G., Garbi, R.: {MDViT}: Multi-domain vision
  transformer for small medical image segmentation datasets. arXiv preprint
  arXiv:2307.02100  (2023)

\bibitem{du2022fairdisco}
Du, S., Hers, B., Bayasi, N., et~al.: {FairDisCo}: Fairer {AI} in dermatology
  via disentanglement contrastive learning. In: ECCVW 2022. pp. 185--202.
  Springer (2022)

\bibitem{gao2022visual}
Gao, Y., Shi, X., Zhu, Y., Wang, H., et~al.: Visual prompt tuning for test-time
  domain adaptation. arXiv preprint arXiv:2210.04831  (2022)

\bibitem{gao2021utnet}
Gao, Y., Zhou, M., Metaxas, D.N.: {UTNet}: a hybrid transformer architecture
  for medical image segmentation. In: MICCAI 2021. pp. 61--71. Springer (2021)

\bibitem{gao2022data}
Gao, Y., et~al.: A data-scalable transformer for medical image segmentation:
  architecture, model efficiency, and benchmark. arXiv preprint
  arXiv:2203.00131  (2022)

\bibitem{glaister2013msim}
Glaister, J., Amelard, R., Wong, A., Clausi, D.A.: {MSIM}: Multistage
  illumination modeling of dermatological photographs for
  illumination-corrected skin lesion analysis. IEEE Transactions on Biomedical
  Engineering  \textbf{60}(7),  1873--1883 (2013)

\bibitem{gulzar2022skin}
Gulzar, Y., Khan, S.A.: Skin lesion segmentation based on vision transformers
  and convolutional neural networksâ€”a comparative study. Applied Sciences
  \textbf{12}(12), ~5990 (2022)

\bibitem{hatamizadeh2022unetr}
Hatamizadeh, A., Tang, Y., Nath, V., Yang, D., et~al.: {UNETR}: Transformers
  for {3D} medical image segmentation. In: WACV 2022. pp. 574--584 (2022)

\bibitem{he2023h2former}
He, A., Wang, K., et~al.: {H2Former}: An efficient hierarchical hybrid
  transformer for medical image segmentation. IEEE Transactions on Medical
  Imaging  (2023)

\bibitem{houlsby2019parameter}
Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., et~al.:
  Parameter-efficient transfer learning for {NLP}. In: ICML 2019. pp.
  2790--2799. PMLR (2019)

\bibitem{jia2022visual}
Jia, M., Tang, L., Chen, B.C., Cardie, C., Belongie, S., Hariharan, B., Lim,
  S.N.: Visual prompt tuning. In: ECCV 2022. pp. 709--727. Springer (2022)

\bibitem{kinyanjui2020fairness}
Kinyanjui, N.M., Odonga, T., et~al.: Fairness of classifiers across skin tones
  in dermatology. In: MICCAI 2020. pp. 320--329. Springer (2020)

\bibitem{kirillov2023segment}
Kirillov, A., et~al.: Segment anything. arXiv preprint arXiv:2304.02643  (2023)

\bibitem{li2023transforming}
Li, J., Chen, J., Tang, Y., Wang, C., Landman, B.A., Zhou, S.K.: Transforming
  medical imaging with transformers? a comparative review of key properties,
  current progresses, and future perspectives. Medical image analysis p. 102762
  (2023)

\bibitem{liu2021swin}
Liu, Z., Lin, Y., Cao, Y., Hu, H., et~al.: {Swin Transformer}: Hierarchical
  vision transformer using shifted windows. In: ICCV 2021. pp. 10012--10022
  (2021)

\bibitem{loshchilov2017decoupled}
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv
  preprint arXiv:1711.05101  (2017)

\bibitem{maron2021reducing}
Maron, R.C., Hekler, A., Krieghoff-Henning, E., Schmitt, M., et~al.: Reducing
  the impact of confounding factors on skin cancer classification via image
  segmentation: technical model study. Journal of Medical Internet Research
  \textbf{23}(3),  e21695 (2021)

\bibitem{matsoukas2022makes}
Matsoukas, C., Haslum, J.F., et~al.: What makes transfer learning work for
  medical images: feature reuse \& other factors. In: CVPR 2022. pp. 9225--9234
  (2022)

\bibitem{mendoncca2013ph}
Mendon{\c{c}}a, T., Ferreira, P.M., et~al.: {PH 2-A} dermoscopic image database
  for research and benchmarking. In: EMBC 2013. pp. 5437--5440. IEEE (2013)

\bibitem{mirikharaji2023survey}
Mirikharaji, Z., Abhishek, K., Bissoto, A., Barata, C., et~al.: A survey on
  deep learning for skin lesion segmentation. Medical Image Analysis
  \textbf{88},  102863 (2023)

\bibitem{peters2019tune}
Peters, M.E., Ruder, S., Smith, N.A.: To tune or not to tune? adapting
  pretrained representations to diverse tasks. ACL 2019 p.~7 (2019)

\bibitem{siegel2023cancer}
Siegel, R.L., Miller, K.D., Wagle, N.S., Jemal, A.: Cancer statistics, 2023.
  CA: a cancer journal for clinicians  \textbf{73}(1),  17--48 (2023)

\bibitem{taghanaki2019combo}
Taghanaki, S.A., Zheng, Y., Zhou, S.K., Georgescu, B., Sharma, P., Xu, D.,
  et~al.: Combo loss: Handling input and output imbalance in multi-organ
  segmentation. Computerized Medical Imaging and Graphics  \textbf{75},  24--33
  (2019)

\bibitem{tang2022self}
Tang, Y., Yang, D., Li, W., Roth, H.R., Landman, B., Xu, D., Nath, V.,
  Hatamizadeh, A.: Self-supervised pre-training of swin transformers for {3D}
  medical image analysis. In: CVPR 2022. pp. 20730--20740 (2022)

\bibitem{touvron2021training}
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., J{\'e}gou, H.:
  Training data-efficient image transformers \& distillation through attention.
  In: ICML 2021. pp. 10347--10357. PMLR (2021)

\bibitem{wang2021boundary}
Wang, J., Wei, L., Wang, L., et~al.: Boundary-aware transformers for skin
  lesion segmentation. In: MICCAI 2021. pp. 206--216. Springer (2021)

\bibitem{wu2022fat}
Wu, H., Chen, S., et~al.: {FAT-Net}: Feature adaptive transformers for
  automated skin lesion segmentation. Medical image analysis  \textbf{76},
  102327 (2022)

\bibitem{wu2023medical}
Wu, J., Fu, R., Fang, H., Liu, Y., Wang, Z., Xu, Y., Jin, Y., Arbel, T.:
  Medical {SAM} adapter: Adapting segment anything model for medical image
  segmentation. arXiv preprint arXiv:2304.12620  (2023)

\bibitem{xie2020mutual}
Xie, Y., Zhang, J., Xia, Y., Shen, C.: A mutual bootstrapping model for
  automated skin lesion segmentation and classification. IEEE transactions on
  medical imaging  \textbf{39}(7),  2482--2493 (2020)

\bibitem{yan2019melanoma}
Yan, Y., Kawahara, J., Hamarneh, G.: Melanoma recognition via visual attention.
  In: IPMI 2019. pp. 793--804. Springer (2019)

\bibitem{yang2023aim}
Yang, T., Zhu, Y., Xie, Y., Zhang, A., Chen, C., Li, M.: {AIM}: Adapting image
  models for efficient video action recognition. In: ICLR 2023 (2023)

\bibitem{zhang2021transfuse}
Zhang, Y., Liu, H., Hu, Q.: {TransFuse}: Fusing transformers and cnns for
  medical image segmentation. In: MICCAI 2021. pp. 14--24. Springer (2021)

\end{thebibliography}
