\begin{thebibliography}{10}

\bibitem{abbeel_apprenticeship_2004}
Pieter Abbeel and Andrew~Y. Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In {\em Proceedings of the twenty-first international conference on
  {Machine} learning}, pages 1--8, 2004.

\bibitem{abel_expressivity_2021}
David Abel, Will Dabney, Anna Harutyunyan, Mark~K Ho, Michael Littman, Doina
  Precup, and Satinder Singh.
\newblock On the expressivity of {Markov} reward.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  volume~34, pages 7799--7812, 2021.

\bibitem{altman_constrained_1999}
Eitan Altman.
\newblock {\em Constrained {Markov} decision processes}, volume~7.
\newblock CRC Press, 1999.

\bibitem{astorino_polyhedral_2002}
A.~Astorino and M.~Gaudioso.
\newblock Polyhedral separability through successive {LP}.
\newblock {\em Journal of Optimization Theory and Applications},
  112(2):265--293, 2002.

\bibitem{brown_extrapolating_2019}
Daniel Brown, Wonjoon Goo, Prabhat Nagarajan, and Scott Niekum.
\newblock Extrapolating beyond suboptimal demonstrations via inverse
  reinforcement learning from observations.
\newblock In {\em Proceedings of the 36th {International} {Conference} on
  {Machine} {Learning}}, pages 783--792, 2019.

\bibitem{mangasarian_linear_1965}
O.~L. Mangasarian.
\newblock Linear and {Nonlinear} {Separation} of {Patterns} by {Linear}
  {Programming}.
\newblock {\em Operations Research}, 13(3):444--452, 1965.

\bibitem{megiddo_complexity_1988}
Nimrod Megiddo.
\newblock On the complexity of polyhedral separability.
\newblock {\em Discrete \& Computational Geometry}, 3(4):325--337, 1988.

\bibitem{pitis_rethinking_2019}
Silviu Pitis.
\newblock Rethinking the discount factor in reinforcement learning: {A}
  decision theoretic approach.
\newblock In {\em Proceedings of {theThirty}-third {AAAI} {Conference} on
  {Artificial} {Intelligence}}, pages 7949--7956, 2019.

\bibitem{roijers_multi-objective_2017}
Diederik~M. Roijers and Shimon Whiteson.
\newblock Multi-{Objective} {Decision} {Making}.
\newblock {\em Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 11(1):1--129, 2017.

\bibitem{sunehag_axioms_2011}
Peter Sunehag and Marcus Hutter.
\newblock Axioms for rational reinforcement learning.
\newblock In {\em Algorithmic {Learning} {Theory}}, Lecture {Notes} in
  {Computer} {Science}, pages 338--352. Springer, 2011.

\bibitem{sutton_reward_2004}
Richard~S. Sutton.
\newblock The reward hypothesis, 2004.
\newblock
  \url{http://incompleteideas.net/rlai.cs.ualberta.ca/RLAI/rewardhypothesis.html}.

\bibitem{von_neumann_theory_1944}
John von Neumann, Oskar Morgenstern, and Ariel Rubinstein.
\newblock {\em Theory of Games and Economic Behavior}.
\newblock Princeton University Press, 1944.

\bibitem{wirth_survey_2017}
Christian Wirth, Riad Akrour, Gerhard Neumann, and Johannes FÃ¼rnkranz.
\newblock A survey of preference-based reinforcement learning methods.
\newblock {\em The Journal of Machine Learning Research}, 18(1):4945--4990,
  2017.

\end{thebibliography}
