%{
\DocumentMetadata{}
\documentclass[backref=page]{article}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% %TODO :
% - 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Controlling behavior of output file
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Include Appendix (0: False, 1: True)
\def\inclapp{1}
%%% View Changes in Color or final version (0: Final, 1: Changes)
\def\viewchanges{1}
%%% View Authors (0: No, 1: Yes)
\def\viewauthors{0}
%%% Preprint (0: No, 1: Yes)
\def\preprint{0}
%%% View Keywords (0: No, 1: Yes)
\def\viewkeywords{0}
%%% use hyperlinks (0: No, 1: Yes)
\def\usehyperlinks{1}
%%% add acknowledgement (0: No, 1: Yes)
\def\addackn{0}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\usepackage[dvipsnames]{xcolor}




%%% TMLR template
\if\preprint1
    \usepackage[preprint]{tmlr}
\else
    \if\viewauthors1
        \usepackage[accepted]{tmlr}
    \else
        \usepackage{tmlr}
    \fi
\fi



 
\usepackage{natbib}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{bbm}
% \usepackage{showframe}
\allowdisplaybreaks        % for page brake in equations
\if\usehyperlinks1
	\usepackage[colorlinks, citecolor=blue]{hyperref}       % hyperlinks
    \colorlet{linkcolor}{magenta}
    \newcommand{\mathlinkcolored}[1]{\mathcolor{linkcolor}{#1}}
\else
    \usepackage{nohyperref}
    %\colorlet{linkcolor}{black}
    \newcommand{\mathlinkcolored}[1]{#1}
\fi
\hypersetup{linkcolor=linkcolor} 
\usepackage{cleveref}
\usepackage{csquotes}



% Add for algo
\usepackage{graphicx,wrapfig,lipsum}
\usepackage{subfigure}
%\usepackage{subcaption}
\usepackage{verbatim}
\usepackage{bm}
\usepackage{adjustbox}
\usepackage{footnote}
\let\AND\undefined
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[acronym,toc]{glossaries} 
\usepackage{mathtools}
%\usepackage{calrsfs}
%\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
%\usepackage{eucal}
\usepackage[mathscr]{eucal}




\if\inclapp0
	%for references
	\usepackage{xr}
	%\externaldocument{NJODE_appendix}
\fi


% new commands:
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lem}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{rem}[theorem]{Remark}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}

\newcommand{\blue}{\textcolor{blue}}
\let\P\undefined%
\newcommand{\1}{\mathbbm{1}}
%\newcommand{\P}{\mathbb{P}}
\newcommand{\PBlack}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
%\newcommand{\A}{\mathcal{A}}
\newcommand{\E}{\mathbb{E}} % expectation
\newcommand{\N}{\mathbb{N}} 
\newcommand{\R}{\mathbb{R}} 
\newcommand{\argmin}{\operatorname{argmin}} 
\newcommand{\id}{\operatorname{id}} 
\newcommand{\argmax}{\operatorname{argmax}} 
\newcommand{\sigmab}{\boldsymbol{\sigma}}


% Shortcuts Jakob
\input{NotationAppendixGlossary}
\newcommand{\Rp}{\R_{>0}}
\newcommand{\Rpz}{\R_{\geq0}}
\newcommand{\omb}{(\omega)}
\newcommand{\onenorm}[1]{\left|{#1}\right|_1}
\newcommand{\twonorm}[1]{\left|{#1}\right|_2}

% End shortcuts Jakob

\renewcommand{\l}{\left} % overwrites smth
\renewcommand{\r}{\right}
\newcommand{\ind}[1]{\mathbbm{1}_{#1}}


\makeatletter
\newcommand{\expect}[1]{
  \if@display \mathbb{E} \left\lbrack #1 \right\rbrack
  \else \mathbb{E} \lbrack #1 \rbrack
  \fi
}
\makeatother

\makeatletter
\newcommand{\cexpect}[2]{
  \if@display \expect{#1 \; \middle| \; #2}
  \else \expect{#1 \, | \, #2}
  \fi
}
\makeatother

\makeatletter
\newcommand{\abs}[1]{
  \if@display \left| #1 \right|
  \else | #1 |
  \fi
}
\makeatother

%%% chasing changes with colors:
%\usepackage[dvipsnames]{xcolor}
\let\add\undefined
\let\del\undefined
\let\com\undefined
\let\cha\undefined
\newcommand{\g}{\textcolor{red}}
%%% display changes in color:
\if\viewchanges1
	\newcommand{\add}[1]{{\color{OliveGreen}{#1}}}
	\newcommand{\del}[1]{{\color{red}{#1}}}
	\newcommand{\com}[1]{{\color{orange}{#1}}}
	\newcommand{\cha}[2]{{\del{#1}} {\add{#2}}}
%%% apply changes:
\else
	\newcommand{\add}[1]{{#1}}
	\newcommand{\del}[1]{}
	\newcommand{\com}[1]{}
	\newcommand{\cha}[2]{{#2}}
\fi

\newcommand{\code}{%
    \if\viewauthors1 %
        \url{https://github.com/
FlorianKrach/PD-NJODE}%
    \else %
        \url{https://github.com/???}%
    \fi %
}




\title{{Jakob's note on Extending Path-Dependent NJ-ODEs to Noisy Observations and a Dependent Observation Framework}}





\author{%
    \name William Andersson \email anwillia@ethz.ch\\
    \addr Department of Computer Science\\
    ETH Zurich, Switzerland
    \AND
    \name Jakob Heiss \email jakob.heiss@math.ethz.ch\\
    \addr Department of Mathematics\\ 
    ETH Zurich, Switzerland
    \AND
    \name Florian Krach \email florian.krach@math.ethz.ch\\
    \addr Department of Mathematics\\ 
    ETH Zurich, Switzerland
    \AND
    \name Josef Teichmann \email josef.teichmann@math.ethz.ch\\
    \addr Department of Mathematics\\ 
    ETH Zurich, Switzerland
    }


\providecommand{\keywords}[1]{\textbf{{Keywords:}} \textit{#1}}
%}

\begin{document}
\maketitle


 In theory they could still depend on each other. A hidden confounder could be the stress of the doctors. In some highly underfunded hospital. There can be times where there are way to many patients at the same time. At such a time very few measurements are taken (because the doctors don't have time for them) and the state of the patients could also be worse (if the don't get the correct treatment due to lack of time of the doctors, which can actually happen especially in developing countries)



Wenn die Messungen aktiv die Gesundheit des Patienten beeinflussen. Wenn zum Beispiel ein X-Ray das Krebsrisiko erhöht (nehmen wir für das mahtematische Beispiel and wir sind lange Zeit in der Vergangenheit, wo X-Rays so schlecht sind, dass sie mit sehr hoher Wahrscheinlichkeit Krebs auslösen, vielleicht fällt mir noch ein extremeres Beisiel ein). Streng genommen würde das theoretisch nicht unsere Assumption verletzen: Wenn der Entscheid das X-ray durchzuführen measureable von der Vergangenheit ist, sind das X-Ray und das Krebsriksio conditionally independent. Aber das gilt nur exakt diese Distribution. Wenn besipielsweise eine ungesunde Zahnstellung immer zu einem X-Ray eine Woche später führt und ein X-Ray vom Kiefer immer zu einem Hirntumor 52 Wochen später führt. Dann wäre es korrekt für das Model zu predicten, dass eine ungesunde Zahnstellung zu einem Gehierntumor 53 Wochen später führt. In der Praxis ist es aber sehr wahrscheinlich, dass man in so einem Fall einen Distribution Shift zwischen Training und Test-Set hat, wenn man das X-Ray-Gerät auswechselt oder wenn man sich entscheidet keine X-Ray untersuchungen mehr zu machen.
Mathematisch ist das einfach ein Distribution shift und hat wenig mit conditional Unabhängigkeit zu tun, aber von der Interpretation hat sich etwas geändert im Vergleich zu den alten Papern. Wenn man Unabhängigkeit angenommen hat, konnte unser model weiterverwendet werden, wenn es einen Distribution-Shift in der Measurement-Strategy des Krankenhauses gab solange die medizinische Distribution gleich gleich bleibt (Behandlung vom Krankenhaus und Krankheiten die im Umlauf sind, UMwelteinflüsse und so weiter...). Jetzt mit der Conditional Indpenednece Annahme, kann ein Distribution-Shift in der MEasurement-Strategie des Krankenhauses das Modell ungültig machen, falls die Measurements die Gesundheit des Patienten beeinflussen


\add{
Add start:}

Temporarily discussion and notes:


Definition:
\[\hat{X}_t := \E[\gX{}_t | \At{t}]\]
%wrong (work in progress....):
%\[\hat{X}_{\tk{i}\omb-}\omb = \E[\gX{}_{\tk{i}-} | \At{\tk{i}-}]\omb\]

in general the following paradox holds:
\[
\E[\gX{}_{\tk{i}\omb} | \At{t}]\omb \neq
\E[\gX{}_{\tk{i}} | \At{t}]\omb\]
Do you agree?

\[\overbrace{\hat{X}_{\tk{i}-}\omb}^{\text{not well defined}} \overset{\text{def?}}{=} \hat{X}_{\tk{i}\omb-}\omb\]
I think in general the following holds
% \[\hat{X}_{\tk{i}\omb}\omb = 
% \E[\gX{}_{\tk{i}\omb} | \At{\tk{i}\omb}]\omb =
% \E[\gX{}_{\tk{i}\omb} | \At{\tk{i}}]\omb =
% \E[\gX{}_{\tk{i}} | \At{\tk{i}}]\omb\]
\begin{multline*}
    \hat{X}_{\tk{i}\omb-}\omb= 
\E[\gX{}_{\tk{i}\omb-} | \At{\tk{i}\omb-}]\omb =
\E[\gX{}_{\tk{i}\omb-} | \At{\tk{i}-}]\omb
{\transparent{0.4}=\E[\gX{}_{\tk{i}\omb-} | \sigmab(\At{\tk{i}-},\tk{i})]\omb}=\\
=
\E[\gX{}_{\tk{i}-} | \At{\tk{i}-}]\omb
{\transparent{0.4}\overset{\ \At{\tk{i}-}=\sigmab(\gX{\tk{k}},\tk{k},\gM{\tk{k}},\tk{i} : k<i)\ }{=}\cexpect{\gX{}_{\tk{i}-} }{ \sigmab\left(\At{\tk{i}-},\tk{i}\right)}
}
\end{multline*}

{\transparent{0.3}I think if we add the assumption that $\gX{}$ is conditionally independent of $\tk{i}$ conditioned on $\At{\tk{i}-}$, we get

\[\hat{X}_{\tk{i}\omb-}\omb = 
\E[\gX{}_{\tk{i}\omb-} | \At{\tk{i}\omb-}]\omb =
\E[\gX{}_{\tk{i}\omb-} | \At{\tk{i}-}]\omb =
\E[\gX{}_{\tk{i}-} | \At{\tk{i}-}]\omb\]
}

Hypthesis:
For our algorithm, $\gY{\tk{i}-}^{\thetamMin{m}}\left(\tildeXle{\tau(\tk{i}-)}\right)$ converges to:
\[
\cexpect{\gX{}_{\tk{i}-} }{ \At{\tk{i}-}}
{\transparent{0.4}\overset{\ \At{\tk{i}-}=\sigmab(\gX{\tk{k}},\tk{k},\gM{\tk{k}},\tk{i} : k<i)\ }{=}
\cexpect{\gX{}_{\tk{i}-} }{ \sigmab\left(\At{\tk{i}-},\tk{i}\right)}
= \cexpect{\gX{}_{\tk{i}} }{ \sigmab\left(\At{\tk{i}-},\tk{i}\right)}
}
\]

The problem without conditional independence:
\[
\cexpect{\gX{}_{\tk{i}-} }{ \At{\tk{i}-}}\omb
\neq \cexpect{\gX{}_{\tk{i}\omb-} }{\sigmab(\gX{\tk{k}},\tk{k},\gM{\tk{k}} : k<i)}\omb
\]

I think if we add the assumption that $\gX{}$ is conditionally independent of $\tk{i}$ conditioned on $\At{\tk{i}-}$, we get equality, i.e.,
\[
\cexpect{\gX{}_{\tk{i}-} }{ \At{\tk{i}-}}\omb
= \cexpect{\gX{}_{\tk{i}\omb-} }{\sigmab(\gX{\tk{k}},\tk{k},\gM{\tk{k}} : k<i)}\omb
\]

If we define:
\[\hat{X}_{s\to t} := \E[\gX{t} | \At{s}],\]
which is the object we would actually be interested in, then
$\gY{t}^{\thetamMin{m}}\left(\tildeXle{\tau(s)}\right)$ can strongly deviate from $\hat{X}_{s\to t}$ even if $s,t\in\supp(\tk{i})$ if we don't assume conditional independence as in the example with the body temperature that is only measured when people feel feverish.
However, if we assume that $\gX{}$ is conditionally independent of $\tk{i}$ conditioned on $\At{\tk{i}-}$, we might be able to show that $\gY{t}^{\thetamMin{m}}\left(\tildeXle{\tau(s)}\right)$ converges to $\hat{X}_{s\to t}$ even if $s,t\in\supp(\tk{i})$ if $\exists i\in\{1,\dots,K\}:(s,t)\in \supp(\tk{i-1},\tk{i})$.

I think the steps to show this could be the following:
\begin{enumerate}
    \item We have shown already that for our algorithm, $\gY{\tk{i}-}^{\thetamMin{m}}\left(\tildeXle{\tau(\tk{i}-)}\right)$ converges to:
\[
\cexpect{\gX{}_{\tk{i}-} }{ \At{\tk{i}-}}
\]
    w.r.t.~\gls{dk}.
    \item I think if we add the assumption that $\gX{}$ is conditionally independent of $\tk{i}$ conditioned on $\At{\tk{i}-}$, we get the fallowing equality quite easily,
\[
\cexpect{\gX{}_{\tk{i}-} }{ \At{\tk{i}-}}\omb
\overset{\text{a.s.}}{=} \cexpect{\gX{}_{\tk{i}\omb-} }{\sigmab(\gX{\tk{k}},\tk{k},\gM{\tk{k}} : k<i)}\omb.
\]
\item $\exists \check{\Omega}\in \Powerset{ \Om{} }, \P[\check{\Omega}]=1 \ : \ \forall\omega\in\check{\Omega}:\forall s \in [\tau(\tk{i}\omb-)\omb,\tk{i}\omb)$
\begin{align*}
    \cexpect{\gX{}_{\tk{i}\omb-} }{\sigmab(\gX{\tk{k}},\tk{k},\gM{\tk{k}} : k<i)}\omb
    &=
    \hat{X}_{\tk{i}\omb- \to \tk{i}\omb} \omb
    \\
    &=\hat{X}_{s \to \tk{i}\omb} \omb
\end{align*}
\item $\exists \check{\Omega}\in \Powerset{ \Om{} }, \P[\check{\Omega}]=1 \ : \ \forall\omega\in\check{\Omega}:\forall s \in [\tau(\tk{i}\omb-)\omb,\tk{i}\omb)$
\begin{align*}
    \gY{\tk{i}-}^{\thetamMin{m}}\left(\tildeXle{\tau(\tk{i}-)}\right)\omb
    &=\gY{\tk{i}-}^{\thetamMin{m}}\left(\tildeXle{\tau(s)}\right)\omb
    \\
    &=\gY{\tk{i}\omb-}^{\thetamMin{m}}\left(\tildeXle{s}\omb\right)
\end{align*}
Question: Do I understand correctly that $\tildeXle{\tau(t)}=\tildeXle{t}$?
\item can we show from the previous points that if we assume that $\gX{}$ is conditionally independent of $\tk{i}$ conditioned on $\At{\tk{i}-}$ it holds for every $s\in[0,\gls{T}]$ and for (almost) every t in the support of $...$ that $\gY{t}^{\thetamMin{m}}\left(\tildeXle{s}\omb\right)$ converges to $\hat{X}_{s \to t} \omb$ in some sense. At least this is what our experiments suggest and this would be the statement one would care about in practice.
\end{enumerate}

\add{Add end
}












% For $\gls{dX} \in \N$ and $\gls{T} > 0$ we consider a filtered probability space  $(\Omega, \F, \glsFF{OmFFP} := \{\F_t\}_{0 \leq t \leq \gls{T}}, \glsP{OmFFP} )$ with an adapted c\`adl\`ag  stochastic process $X :={(X_t)}_{t \in [0,\gls{T}]}$ taking values in $\R^{\gls{dX}}$. We denote its running maximum process by $\gls{Xs}$ and the random set of its jump times by $\mathcal{J}$. The random observation framework is defined independently of $X$ on another filtered probability space  $(\glsOm{tOmFFP} , \glsF{tOmFFP},  \glsFF{tOmFFP} := \{ \glsFt{tOmFFP}  \}_{0 \leq t \leq \gls{T}}, \glsP{tOmFFP} )$ by



% \begin{table}
%     \centering
%     \begin{tabular}{ll}
% $X$         & The stochastic process~$X :={(X_t)}_{t \in [0,\gls{T}]}$ we want to study (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
% $\gls{dX}$         & The dimension~$\gls{dX} \in \N$ of $X$ (i.e., $X_t\omb\in\R^{\gls{dX}}$) (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
% $var$         & \parbox{\linewidth}{Description Description Description Description Description a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a (see \Cref{sec:Recall: the PD-NJ-ODE}).}
% \\
% $var$         & Description (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
% $var$         & Description (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
% $var$         & Description (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
% $var$         & Description (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
% $var$         & Description (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \\
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}


% \begin{description}
%     \item[a] asfasf
% \end{description}

% \begin{itemize}
% %\item $X\quad:\quad$ The stochastic process~$X :={(X_t)}_{t \in [0,\gls{T}]}$ we want to study (see \Cref{sec:Recall: the PD-NJ-ODE}).
% %\item $\gls{dX}\quad:\quad$ The dimension~$\gls{dX} \in \N$ of $X$ (i.e., $X_t\omb\in\R^{\gls{dX}}$) (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \item $\gls{T}\quad:\quad$ The largest time~$T \in\Rp$ we consider (see \Cref{sec:Recall: the PD-NJ-ODE}).
% \item $n: \glsOm{tOmFFP}  \to \N_{\geq 0}$, an $\glsF{tOmFFP} $-measurable random variable, the random number of observations, 
% \item $K := \sup \left\{k \in \N \, | \, \glsP{tOmFFP}(n \geq k) > 0 \right\} \in \N \cup\{\infty\}$, the maximal value of $n$, 
% \item  $t_i: \glsOm{tOmFFP}  \to [0,T] \cup \{ \infty \}$ for $0 \leq i \leq K$, {sorted} stopping times, which are the random observation times, with $t_i(\tilde{\omega}) := \infty$ if $n(\tilde{\omega}) < i$,
% \item $\tau : [0,T] \times \glsOm{tOmFFP}  \to [0,T], \; (t, \tilde\omega) \mapsto \tau(t, \tilde\omega) := \max\{ t_i(\tilde\omega) | 0 \leq i \leq n(\tilde\omega), t_i(\tilde\omega) \leq t \}$, the  last observation time before a certain time $t$, and
% \item $M = (M_k)_{0 \leq k \leq K}$, the observation mask, which is a sequence of random variables on  $(\glsOm{tOmFFP} , \glsF{tOmFFP} , \glsP{tOmFFP} )$ taking values in $\{ 0,1 \}^{\gls{dX}}$ such that $M_k$ is $\tilde{\mathcal{F}}_{t_k}$-measurable.
% The $j$-th coordinate of the $k$-th element of the sequence $M$, i.e., $M_{k,j}$, signals whether $X_{t_k, j}$, denoting the $j$-th coordinate of the stochastic process at observation time $t_k$ is observed. By abuse of notation we also write $M_{t_k} := M_{k}$. 
% \end{itemize}

\printglossary[title=Notation,toctitle=Notation]

\end{document}

