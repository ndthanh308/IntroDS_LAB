\section{Benchmarks of BubbleML: Optical Flow and SciML}

\subsection{Optical Flow}
\label{sec:flow_section}
  
\textbf{Generation of Optical Flow Dataset.} Optical flow computes the velocity field of an image based on the relative movement of objects between consecutive frames. This method holds significant implications for downstream tasks, such as extracting side-view boiling statistics and applying SciML to real world experimental data. \update{Although many datasets capturing spatiotemporal dynamical systems can be repurposed to create optical flow datasets, the inherent non-rigidity of bubbles introduces unique physical phenomena that are not prevalent in other datasets. 
For instance, consider the scenario where a bubble detaches from a heater surface: the bottom region of the bubble exhibits significantly higher velocity compared to the top region, resulting in a velocity gradient that forces the bubble into a spherical shape. At hotter heater temperatures, deformation and detachment process might occur more frequently, leading to different flow patterns and bubble behaviors illustrated in Figure \ref{fig:dataset-variables}.} 

We create an optical flow dataset from BubbleML to capture multiphase phenomena. Using the liquid-vapor phase distinction information from simulations, we distinguish between liquid and vapor phases. This enables the generation of image sequences wherein bubble trajectories are tracked across consecutive timesteps. Importantly, our data extraction is limited to bubble velocities per timestep, excluding fluid velocities. This focuses the learning task on capturing discernible objects (bubbles).
The bubble velocities in non-dimensional units are converted to pixels per frame units (see appendix \ref{appendix:optflow-data}), before being written to the widely used Middlebury \cite{4408903} flow format, producing a sequence of images and flow files that resemble the Sintel dataset \cite{10.1007/978-3-642-33783-3_44}. To facilitate the training and validation of optical flow models, PyTorch dataloaders are provided for the generated dataset \ref{git_dataset}. This allows for easy integration and fine-tuning of existing optical flow models using the BubbleML dataset. 
 
\textbf{Learning Bubble Dynamics.} We evaluate and fine-tune two state-of-the-art optical flow models, RAFT \cite{teed2020raft} and GMFlow \cite{xu2022gmflow}, using the BubbleML optical flow dataset (B). We consider three different pre-trained models for each method: the first model is trained exclusively on FlyingChairs (C), the second trained on FlyingChairs and FlyingThings3D (C+T), and the third model which is fine-tuned for the Sintel Benchmark (C+T+S). To assess the performance of the trained models, we measure the end-point error and Table \ref{table:results_optical_flow} summarizes the results for one dataset. Refer to Appendix \ref{asec:opt-flow} for results on the other datasets.

  \begin{table}[t!]
    \small
    \centering
    \caption{Results of pre-trained and fine-tuned RAFT and GMFlow models on optical flow data (B) generated from \texttt{PB-Saturated} dataset. A 80:20 split results in 2000 training and 500 validation image pairs. The pre-trained models include \texttt{C} trained on FlyingChairs dataset, \texttt{C+T} trained further on FlyingThings3D, and \texttt{C+T+S} further fine-tuned for the Sintel test benchmark. \texttt{Model+B} represents models fine-tuned on the BubbleML optical flow dataset.}
    
    \begin{tabular}{ccccccccc}
    \toprule
    \multirow{2}{*}{\centering Model} & \multirow{2}{*}{\centering Method} & \multirow{2}{*}{\centering Chairs (Val)} & Things (Val) & \multicolumn{2}{c}{Sintel (Train)} & \multicolumn{2}{c}{KITTI (Train)} & \multirow{2}{*}{\centering Boiling (Test)} \\
     \cmidrule(r){4-4}  \cmidrule(r){5-6}  \cmidrule(r) {7-8} 
      & & & Clean & Clean & Final & F1-EPE & F1-all & \\
    \midrule
     \multirow{2}{*}{\centering C} 
     & RAFT & 0.82 & 9.03 & 2.19 & 4.49 & 9.83 & 37.57 & 4.20\\
     & GMFlow & 0.92 & 10.23 & 3.22 & 4.43 & 17.82 & 56.14 & 4.73\\
     \hline
     \multirow{2}{*}{\centering C+B} 
     & RAFT & 0.91 & 11.22 & 2.55 & 5.16 & 13.7 & 44.44 & \textbf{2.33}\\
     & GMFlow & 1.31 & 11.99 & 3.78 & 5.12 & 21.91 & 63.04 & \textbf{2.36}\\
     \hline
     \multirow{2}{*}{\centering C+T} 
     & RAFT & 1.15 & 4.39 & 1.40 & 2.71 & 5.02 & 17.46 & 4.72\\
     & GMFlow & 1.26 & 3.48 & 1.50 & 2.96 & 11.60 & 35.62 & 7.98\\
     \hline
     \multirow{2}{*}{\centering C+T+B} 
     & RAFT & 1.28 & 7.69 & 1.69 & 2.95 & 9.96 & 23.61 & 2.38\\
     & GMFlow & 1.39 & 3.88 & 1.61 & 2.91 & 14.49 & 43.09 & 2.51 \\
     \hline
     \multirow{2}{*}{\centering C+T+S} 
     & RAFT & 1.21 & 4.69 & 0.77 & 1.22 & 1.54 & 5.64 & 8.39\\
     & GMFlow & 1.53 & 4.09 & 0.95 & 1.28 & 3.04 & 13.61 & 14.65\\
     \hline
     \multirow{2}{*}{\centering C+T+S+B} 
     & RAFT & 1.37 & 6.59 & 0.89 & 1.60 & 1.83 & 6.44 & 2.34 \\
     & GMFlow & 1.65 & 4.49 & 1.07 & 1.45 & 4.06 & 18.99 & 2.56\\
     \bottomrule
    \end{tabular}
    
    \label{table:results_optical_flow}
\end{table}
 
  Initially, the pre-trained models exhibit subpar performance on the BubbleML data. To address this, each model is fine-tuned for 3-4 epochs with a low learning rate of $10^{-6}$. After fine-tuning, we observe a significant improvement in predictions for the test data (see Figures \ref{fig:results-raft} and \ref{fig:results-gmflow} in Appendix \ref{asec:opt-flow}). \update{While all fine-tuned models tend to converge to similar levels of accuracy for pool boiling datasets, fine-tuning the pre-trained FlyingChairs models (C) on BubbleML (B) dataset gives the best results. This could be attributed to the similar nature of the datasets consisting of 2D objects in motion. In the case of flow boiling, the best results are achieved by fine-tuning models initially trained for the Sintel benchmark (C+T+S). Flow boiling images have an extremely high aspect ratio (8:1) which is similar to the Sintel (3:1) and the KITTI (4:1) datasets.} Note that although training the models on the boiling dataset for more epochs improves performance on our specific task, it adversely affects the models' generalization capabilities, leading to increased errors on the other datasets. 
  
  \update{\textbf{Open problems.} Error analysis (\ref{appendix:optflow-results}) highlights the shortcomings of state-of-the-art optical flow models in accurately capturing the turbulent dynamics of bubbles. Although fine-tuning improves the overall performance, the high errors at the bubble boundaries remain an ongoing challenge. This underscores the need for novel optical flow models that incorporate physical insights to accurately capture the complex and chaotic behavior of boiling. BubbleML bridges the gap for physics-informed optical flow datasets.}