\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{blenderkit}
Blenderkit.
\newblock www.www.blenderkit.com.

\bibitem{Mixamo}
Mixamo.
\newblock www.mixamo.com.

\bibitem{Polyhaven}
Polyhaven.
\newblock www.polyhaven.com/hdris.

\bibitem{turbosquid}
Turbosquid.
\newblock www.turbosquid.com.

\bibitem{agarap2018deep}
Abien~Fred Agarap.
\newblock Deep learning using rectified linear units (relu).
\newblock {\em arXiv:1803.08375}, 2018.

\bibitem{middlebury}
Simon Baker, Daniel Scharstein, JP Lewis, Stefan Roth, Michael~J Black, and
  Richard Szeliski.
\newblock A database and evaluation methodology for optical flow.
\newblock {\em IJCV}, 92:1--31, 2011.

\bibitem{bian2022learning}
Zhangxing Bian, Allan Jabri, Alexei~A. Efros, and Andrew Owens.
\newblock Learning pixel trajectories with multiscale contrastive random walks.
\newblock {\em CVPR}, 2022.

\bibitem{badja}
Benjamin Biggs, Thomas Roddick, Andrew Fitzgibbon, and Roberto Cipolla.
\newblock Creatures great and {SMAL}: {R}ecovering the shape and motion of
  animals from video.
\newblock In {\em ACCV}, pages 3--19, 2018.

\bibitem{blender}
{Blender Online Coummunity}.
\newblock Blender.
\newblock Blender Foundation, https://www.blender.org/.

\bibitem{bregler_recover}
C. Bregler, A. Hertzmann, and H. Biermann.
\newblock Recovering non-rigid {3D} shape from image streams.
\newblock In {\em CVPR}, 2000.

\bibitem{Brox2011LargeDO}
Thomas Brox and Jitendra Malik.
\newblock Large displacement optical flow: Descriptor matching in variational
  motion estimation.
\newblock {\em TPAMI}, 33, 2011.

\bibitem{sintel}
D.~J. Butler, J. Wulff, G.~B. Stanley, and M.~J. Black.
\newblock A naturalistic open source movie for optical flow evaluation.
\newblock In {\em ECCV}, pages 611--625, 2012.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{damen2020epic}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Sanja Fidler, Antonino
  Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett,
  Will Price, et~al.
\newblock The {EPIC-KITCHENS} dataset: Collection, challenges and baselines.
\newblock {\em TPAMI}, 43(11):4125--4141, 2020.

\bibitem{doersch2022tap}
Carl Doersch, Ankush Gupta, Larisa Markeeva, Adri{\`a} Recasens, Lucas Smaira,
  Yusuf Aytar, Jo{\~a}o Carreira, Andrew Zisserman, and Yi Yang.
\newblock {TAP-Vid}: A benchmark for tracking any point in a video.
\newblock {\em NeurIPS Datasets and Benchmarks}, 2022.

\bibitem{flownet}
Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas,
  Vladimir Golkov, Patrick Van Der~Smagt, Daniel Cremers, and Thomas Brox.
\newblock {FlowNet}: Learning optical flow with convolutional networks.
\newblock In {\em ICCV}, 2015.

\bibitem{Dosovitskiy17}
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
  Koltun.
\newblock {CARLA}: {An} open urban driving simulator.
\newblock In {\em CORL}, 2017.

\bibitem{downs2022google}
Laura Downs, Anthony Francis, Nate Koenig, Brandon Kinman, Ryan Hickman, Krista
  Reymann, Thomas~B McHugh, and Vincent Vanhoucke.
\newblock Google scanned objects: A high-quality dataset of 3d scanned
  household items.
\newblock In {\em ICRA}, 2022.

\bibitem{fan2019lasot}
Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong
  Xu, Chunyuan Liao, and Haibin Ling.
\newblock {LaSOT}: A high-quality benchmark for large-scale single object
  tracking.
\newblock In {\em CVPR}, 2019.

\bibitem{fu20213d}
Huan Fu, Bowen Cai, Lin Gao, Ling-Xiao Zhang, Jiaming Wang, Cao Li, Qixun Zeng,
  Chengyue Sun, Rongfei Jia, Binqiang Zhao, et~al.
\newblock {3D-FRONT}: {3D} furnished rooms with layouts and semantics.
\newblock In {\em ICCV}, 2021.

\bibitem{fu20213dfuture}
Huan Fu, Rongfei Jia, Lin Gao, Mingming Gong, Binqiang Zhao, Steve Maybank, and
  Dacheng Tao.
\newblock {3D-FUTURE}: {3D} furniture shape with texture.
\newblock {\em IJCV}, 2021.

\bibitem{kitti}
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun.
\newblock Vision meets robotics: The {KITTI} dataset.
\newblock {\em IJRR}, 2013.

\bibitem{greff2022kubric}
Klaus Greff, Francois Belletti, Lucas Beyer, Carl Doersch, Yilun Du, Daniel
  Duckworth, David~J Fleet, Dan Gnanapragasam, Florian Golemo, Charles
  Herrmann, et~al.
\newblock Kubric: A scalable dataset generator.
\newblock In {\em CVPR}, 2022.

\bibitem{harley2022particle}
Adam~W Harley, Zhaoyuan Fang, and Katerina Fragkiadaki.
\newblock Particle video revisited: Tracking through occlusions using point
  trajectories.
\newblock In {\em ECCV}, 2022.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{Horn:1981}
Berthold~K.P. Horn and Brian~G. Schunck.
\newblock Determining optical flow.
\newblock {\em Artificial Intelligence}, 17, 1981.

\bibitem{flownet2}
Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy,
  and Thomas Brox.
\newblock Flownet 2.0: Evolution of optical flow estimation with deep networks.
\newblock In {\em CVPR}, 2017.

\bibitem{jabri2020walk}
Allan Jabri, Andrew Owens, and Alexei~A Efros.
\newblock Space-time correspondence as a contrastive random walk.
\newblock {\em NeurIPS}, 2020.

\bibitem{kay2017kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
  Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
\newblock The kinetics human action video dataset.
\newblock {\em arXiv:1705.06950}, 2017.

\bibitem{kong_deepnrsfm}
Chen Kong and Simon Lucey.
\newblock Deep non-rigid structure from motion with missing data.
\newblock {\em TPAMI}, 2021.

\bibitem{MOTChallenge2015}
L. Leal-Taix\'{e}, A. Milan, I. Reid, S. Roth, and K. Schindler.
\newblock {MOTC}hallenge 2015: {T}owards a benchmark for multi-target tracking.
\newblock {\em arXiv:1504.01942}, 2015.

\bibitem{lee2021beyond}
Alex~X Lee, Coline~Manon Devin, Yuxiang Zhou, Thomas Lampe, Konstantinos
  Bousmalis, Jost~Tobias Springenberg, Arunkumar Byravan, Abbas Abdolmaleki,
  Nimrod Gileadi, David Khosid, et~al.
\newblock Beyond pick-and-place: Tackling robotic stacking of diverse shapes.
\newblock In {\em CoRL}, 2021.

\bibitem{li20214dcomplete}
Yang Li, Hikari Takehara, Takafumi Taketomi, Bo Zheng, and Matthias
  Nie{\ss}ner.
\newblock {4DComplete}: Non-rigid motion estimation beyond the observable
  surface.
\newblock In {\em ICCV}, 2021.

\bibitem{li2019learning}
Zhengqi Li, Tali Dekel, Forrester Cole, Richard Tucker, Noah Snavely, Ce Liu,
  and William~T Freeman.
\newblock Learning the depths of moving people by watching frozen people.
\newblock In {\em CVPR}, 2019.

\bibitem{lin2019tsm}
Ji Lin, Chuang Gan, and Song Han.
\newblock Tsm: Temporal shift module for efficient video understanding.
\newblock In {\em ICCV}, 2019.

\bibitem{lucas1981iterative}
Bruce~D Lucas, Takeo Kanade, et~al.
\newblock An iterative image registration technique with an application to
  stereo vision.
\newblock {\em IJCAI}, 2:674--679, 1981.

\bibitem{mahmood2019amass}
Naureen Mahmood, Nima Ghorbani, Nikolaus~F Troje, Gerard Pons-Moll, and
  Michael~J Black.
\newblock {AMASS}: Archive of motion capture as surface shapes.
\newblock In {\em ICCV}, 2019.

\bibitem{matthews2004template}
Iain Matthews, Takahiro Ishikawa, and Simon Baker.
\newblock The template update problem.
\newblock {\em TPAMI}, 26(6), 2004.

\bibitem{mayer2016large}
Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer, Daniel Cremers,
  Alexey Dosovitskiy, and Thomas Brox.
\newblock A large dataset to train convolutional networks for disparity,
  optical flow, and scene flow estimation.
\newblock In {\em CVPR}, 2016.

\bibitem{LilySurfaceScraper}
Elie Michel.
\newblock Lily surface scraper.
\newblock GitHub repository. https://github.com/eliemichel/LilySurfaceScraper.

\bibitem{mo2019partnet}
Kaichun Mo, Shilin Zhu, Angel~X Chang, Li Yi, Subarna Tripathi, Leonidas~J
  Guibas, and Hao Su.
\newblock Partnet: A large-scale benchmark for fine-grained and hierarchical
  part-level 3d object understanding.
\newblock In {\em CVPR}, 2019.

\bibitem{novotny2019c3dpo}
David Novotny, Nikhila Ravi, Benjamin Graham, Natalia Neverova, and Andrea
  Vedaldi.
\newblock C3dpo: Canonical 3d pose networks for non-rigid structure from
  motion.
\newblock In {\em ICCV}, 2019.

\bibitem{SMPL-X:2019}
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A.~A.
  Osman, Dimitrios Tzionas, and Michael~J. Black.
\newblock Expressive body capture: {3D} hands, face, and body from a single
  image.
\newblock In {\em CVPR}, 2019.

\bibitem{pont20172017}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbel{\'a}ez, Alex
  Sorkine-Hornung, and Luc Van~Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock {\em arXiv:1704.00675}, 2017.

\bibitem{davis2017}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbel\'aez, Alexander
  Sorkine-Hornung, and Luc {Van Gool}.
\newblock The 2017 {DAVIS} challenge on video object segmentation.
\newblock {\em arXiv:1704.00675}, 2017.

\bibitem{rempe2021humor}
Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang, Srinath Sridhar, and
  Leonidas~J. Guibas.
\newblock Humor: 3d human motion model for robust pose estimation.
\newblock In {\em ICCV}, 2021.

\bibitem{shen2021igibson}
Bokui Shen, Fei Xia, Chengshu Li, Roberto Mart\'in-Mart\'in, Linxi Fan, Guanzhi
  Wang, Claudia P\'erez-D'Arpino, Shyamal Buch, Sanjana Srivastava, Lyne~P.
  Tchapmi, Micael~E. Tchapmi, Kent Vainio, Josiah Wong, Li Fei-Fei, and Silvio
  Savarese.
\newblock i{G}ibson 1.0: a simulation environment for interactive tasks in
  large realistic scenes.
\newblock In {\em IROS}. IEEE, 2021.

\bibitem{Rokoko}
Matias Sondergaard.
\newblock Rokoko.
\newblock GitHub repository.
  https://github.com/Rokoko/rokoko-studio-live-blender.

\bibitem{sun2021autoflow}
Deqing Sun, Daniel Vlasic, Charles Herrmann, Varun Jampani, Michael Krainin,
  Huiwen Chang, Ramin Zabih, William~T Freeman, and Ce Liu.
\newblock Autoflow: Learning a better training set for optical flow.
\newblock In {\em CVPR}, 2021.

\bibitem{sun2018pwc}
Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz.
\newblock {PWC}-{N}et: {CNN}s for optical flow using pyramid, warping, and cost
  volume.
\newblock In {\em CVPR}, 2018.

\bibitem{brox_densepoint}
Narayanan Sundaram, Thomas Brox, and Kurt Keutzer.
\newblock Dense point trajectories by {GPU}-accelerated large displacement
  optical flow.
\newblock In {\em ECCV}, 2010.

\bibitem{sundararaman2021tracking}
Ramana Sundararaman, Cedric De~Almeida~Braga, Eric Marchand, and Julien Pettre.
\newblock Tracking pedestrian heads in dense crowd.
\newblock In {\em CVPR}, 2021.

\bibitem{taketomi2017visual}
Takafumi Taketomi, Hideaki Uchiyama, and Sei Ikeda.
\newblock Visual slam algorithms: A survey from 2010 to 2016.
\newblock {\em IPSJ Transactions on Computer Vision and Applications},
  9(1):1--11, 2017.

\bibitem{teed2020raft}
Zachary Teed and Jia Deng.
\newblock {RAFT}: Recurrent all-pairs field transforms for optical flow.
\newblock In {\em ECCV}, 2020.

\bibitem{tolstikhin2021mlp}
Ilya~O Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua
  Zhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers,
  Jakob Uszkoreit, et~al.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock {\em NeurIPS}, 2021.

\bibitem{tomasi1991detection}
Carlo Tomasi and Takeo Kanade.
\newblock Detection and tracking of point.
\newblock {\em IJCV}, 1991.

\bibitem{ulyanov2016instance}
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
\newblock Instance normalization: The missing ingredient for fast stylization.
\newblock {\em arXiv:1607.08022}, 2016.

\bibitem{voigtlaender2019mots}
Paul Voigtlaender, Michael Krause, Aljosa Osep, Jonathon Luiten, Berin
  Balachandar~Gnana Sekar, Andreas Geiger, and Bastian Leibe.
\newblock Mots: Multi-object tracking and segmentation.
\newblock In {\em CVPR}, 2019.

\bibitem{vondrick2018tracking}
Carl Vondrick, Abhinav Shrivastava, Alireza Fathi, Sergio Guadarrama, and Kevin
  Murphy.
\newblock Tracking emerges by colorizing videos.
\newblock In {\em ECCV}, 2018.

\bibitem{wang2020tartanair}
Wenshan Wang, Delong Zhu, Xiangwei Wang, Yaoyu Hu, Yuheng Qiu, Chen Wang, Yafei
  Hu, Ashish Kapoor, and Sebastian Scherer.
\newblock Tartanair: A dataset to push the limits of visual slam.
\newblock In {\em IROS}. IEEE, 2020.

\bibitem{wang2019learning}
Xiaolong Wang, Allan Jabri, and Alexei~A Efros.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In {\em CVPR}, 2019.

\bibitem{yan2021learning}
Bin Yan, Houwen Peng, Jianlong Fu, Dong Wang, and Huchuan Lu.
\newblock Learning spatio-temporal transformer for visual tracking.
\newblock In {\em ICCV}, 2021.

\bibitem{yi2022mime}
Hongwei Yi, Chun-Hao~P. Huang, Shashank Tripathi, Lea Hering, Justus Thies, and
  Michael~J. Black.
\newblock {MIME}: Human-aware {3D} scene generation.
\newblock In {\em CVPR}, June 2023.

\bibitem{yu2016back}
Jason~J Yu, Adam~W Harley, and Konstantinos~G Derpanis.
\newblock Back to basics: Unsupervised learning of optical flow via brightness
  constancy and motion smoothness.
\newblock In {\em ECCVW}, 2016.

\bibitem{zhang2022egobody}
Siwei Zhang, Qianli Ma, Yan Zhang, Zhiyin Qian, Taein Kwon, Marc Pollefeys,
  Federica Bogo, and Siyu Tang.
\newblock Egobody: Human body shape and motion of interacting people from
  head-mounted devices.
\newblock In {\em ECCV}, 2022.

\bibitem{zheng2022gimo}
Yang Zheng, Yanchao Yang, Kaichun Mo, Jiaman Li, Tao Yu, Yebin Liu, C~Karen
  Liu, and Leonidas~J Guibas.
\newblock Gimo: Gaze-informed human motion prediction in context.
\newblock In {\em ECCV}, 2022.

\end{thebibliography}
