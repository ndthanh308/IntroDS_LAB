% !TEX program = pdflatex
% !TEX root = main.tex

\clearpage
\beginsupplement 

\begin{widetext}

\section*{{Supplemental Information (SI)}}
\label{sec:supp}

\section{Full Derivation Self-Spring Interaction}

\noindent Calculate the $i$-th component of the gradient:
\bea
\nonumber \frac{\partial H^t}{\partial s_i^t}&=&\sum_j [A_{ij}^t(s_i-s_j-\ell_0)-A_{ji}^t(s_j-s_i-\ell_0)] +\kself(s_i^t-s_i^{t-1})\\ 
\nonumber&=&\sum_j (A_{ij}^t + A_{ji}^t)\,s_i^t-\sum_j (A_{ij}^t + A_{ji}^t)\,s_j^t-\sum_j(A_{ij}^t - A_{ji}^t)\,\ell_0+\kself\,(s_i^t-s_i^{t-1})\\ 
\nonumber&=&(d_i^{out,t}+d_i^{in,t}+\kself)\,s_i^t-\sum_j (A_{ij}^t + A_{ji}^t)\,s_j^t-(d_i^{out,t}-d_i^{in,t})\ell_0-\kself\,s_i^{t-1} \, .
\eea
Imposing $\nabla H=0$ we obtain:
\be
(d_i^{out,t}+d_i^{in,t}+\kself)\,s_i^t-\sum_j (A_{ij}^t + A_{ji}^t)\,s_j^t=(d_i^{out,t}-d_i^{in,t})\,\ell_0+\kself\,s_i^{t-1} \, ,\nonumber
\ee
which yields:
\be
\rup{ D^{out,t}+D^{in,t}- \bup{A^{t}+A^{t,T}}+\kself\id}\,\v{s}^{t,*}=\rup{D^{out,t}-D^{in,t}}\ell_0 \nonumber +k_{0}\, \v{s}^{t-1} \, ,
\ee
as reported in~\eqref{eqn:fullsolution} for $\ell_0 = 1$.

\section{Full Derivation of Self-Spring Interaction Over All Time}\label{sec:h_total_derive}

\noindent Calculate the $i$-th component of the gradient:
\begin{align*}
	\frac{\partial \Htotal}{\partial s_i^t}
	&=\frac{\partial}{\partial s_i^t} \left[ \sum_t^T H^t(\boldsymbol{s}^t,\boldsymbol{s}^{t-1}) \right] \\
	&=\frac{\partial}{\partial s_i^t} \left[ \sum_t^T \sum A^t_{ij}H_{ij}(s^t_i,s^t_j) \right] 
	+ \frac{\partial}{\partial s_i^t} \left[ \sum_t^T \sum \kself \Hself(s^t_i,s^{t-1}_i) \right] \\
	&=\sum_{j}^{N}[A^t_{ij}(s^t_i-s^t_j-\ell_0) - A^t_{ji}(s^t_j-s^t_i-\ell_0)]-\kself s^{t-1}_i+2\kself s^t_i-\kself s^{t+1}_i\\
	&=\sum_j (A_{ij}^t + A_{ji}^t)\,s_i^t-\sum_j (A_{ij}^t + A_{ji}^t)\,s_j^t-\sum_j(A_{ij}^t - A_{ji}^t)\ell_0-\kself s_i^{t-1}+2\kself s_i^t -\kself s_i^{t+1}\\
	&=(d_i^{out,t}+d_i^{in,t}+\kself)\,s_i^t-\sum_j (A_{ij}^t + A_{ji}^t)\,s_j^t-(d_i^{out,t}-d_i^{in,t})\ell_0-\kself\,s_i^{t-1} + 2\kself s_i^t -\kself s_i^{t+1}\, .
\end{align*}
\\
Imposing $\nabla H=0$ we obtain:
\begin{equation*}
	(d_i^{out,t}+d_i^{in,t}+2\kself)\,s_i^t-\sum_j (A_{ij}^t + A_{ji}^t)\,s_j^t=(d_i^{out,t}-d_i^{in,t})\ell_0+\kself(s_i^{t-1}+s_i^{t+1}) \, ,
\end{equation*}
which yields:
\begin{equation*}
	[D^{out,t}+D^{in,t}- (A^{t}+A^{t,\dagger})+2\kself \mathbb{I} ]{s}^{t,*}=[D^{out,t}-D^{in,t}]\ell_0  +k_{0} ({s}^{t-1} + {s}^{t+1}) \, ,
\end{equation*}
as reported in (\ref{eqn:h_total}) for $\ell_0 = 1$.

\section{Dynamic Spring Rest Length}\label{sec:sidynl}
As an alternative to the time-dependency presented in the main text (i.e., through self-springs), we also investigated the introduction of a time-dependent rest length. 
In this case we assume a dynamic rest length $\ell_{ij}^{t}$ for the interaction at time $t$ between $i$ and $j$. To enforce a relationship between current and past ranks, we assume $\ell_{ij}^{t}$ to be a function of the rank difference $s_{i}^{t-1}-s_{j}^{t-1}$ between $i$ and $j$ at time $t-1$:
\bea
\nonumber H_{ij}^t\bup{s_i^t,s_j^t}&=&\frac{1}{2}\bup{s_i^t-s_j^t-l_{ij}^{t}}^2 ,
\eea
where
\bea
l_{ij}^{t}&=&s_i^{t-1}-s_j^{t-1}+\ell_0 \, . \label{eqn:lt}
\eea
\\
The resultant Hamiltonian for the whole system is,
\bea
\nonumber H^{t}(\v{s}^t,\v{s}^{t-1})=\sum_{i,j}A_{ij}^{t}H^{t}_{ij}\bup{s_i^t,s_j^t} \, .
\eea
As opposed to Eq.~\ref{eqn:fullH}, here we do not have self-interactions. Instead, past ranks appear directly inside the rest lengths.
If we define a new variable $z_i^t=s_i^t-s_i^{t-1}$,  we obtain the Hamiltonian:
\bea
H^{t}(\v{z}^t)=\sum_{i,j}A^{t}_{ij}H^{t}_{ij}\bup{z_i^t,z_j^t}=\sum_{i,j}\frac{A^{t}_{ij}}{2}\bup{z_i^t-z_j^t-\ell_0}^2\nonumber
\eea
which is the same Hamiltonian used in static SpringRank \cite{de2018physical} but as a function of the auxiliary variable $\v{z}^{t}$. Thus, we know that the ground state $\v{z}^{t,*}$ will be the solution of the linear system:
\bea
\left[ D^{\text{out}}+D^{\text{in}} - \left(A+ A^\dagger \right) \right ] \v{z}_t^* =\left[D^{\text{out}}-D^{\text{in}}  \right ]\ell_0 \ones\, . \nonumber
\eea
The idea is that once $\v{z}^{t,*}$ is obtained by solving this linear system, one can extract the ranks as $s_i^t= z_i^t+s_{i}^{t-1}$, where $s_{i}^{t-1}$ is known from the inference of the previous step. Notice that in the extreme case of having only two individuals $i$, $j$, initializing $s_{i}^{0}=s_{j}^{0}=0$ and $i$ as the constant winner ($A_{ij}^{t}\geq 0$ and $A_{ji}^{t}= 0 \, \forall t$), we would infer $s_{i}^{1}-s_{j}^{1}= \ell_0$ at the first time-step. Then iterating in time yields $\ell^t_{ij}= t \ell_0$. In words, for situations where the hierarchy is strong and time is constant (i.e., a stronger individual always defeats a weaker one at any time-step), the rest length would grow linearly in time. As a consequence, the distance between ranks grows further and further, driving them apart. This is the case in sports, for instance, where teams earn points for each win, distancing them more and more from the losing teams. In other situations, we might want instead a scenario where the difference between ranks becomes a constant value $\ell_0$ the more we collect consistent observations in time, i.e., $\forall t, s_{i}^{t}-s_{j}^{t}=\ell_0$. This can be easily obtain by changing the model's details, like setting a different initial rest length and update in Eq.~(\ref{eqn:lt}).

\section{Performance Evaluation}\label{sisec:evaluation}
In this section, we discuss the various metrics used in more detail.
Accuracy is a coarse-grained measure to evaluate the quality of predictions. It is the fraction of times an observed directed edge points from the higher towards the lower ranked node, i.e., the number of times that a \emph{stronger} (according to our ranking) individual \emph{beats} a weaker one,
\be
\nonumber 
\textrm{accuracy} = \f{1}{M} \sum_{i,j} A_{ij} \, \Theta(s_i - s_j) \, ,
\ee
where $\Theta(x)=1$ if $x > 0$, and $0$ otherwise; $M=\sum_{i,j} A_{ij}$. 
If we call an \emph{upset} an interaction where a lower ranked individual beats someone stronger, then the accuracy is just 1 minus the fraction of upsets. Accuracy does not weigh upsets differently. However, in certain situations making an erroneous prediction involving individuals nearby in rank might be less important than an error involving individuals far in rank. In this case, it is useful to consider the \emph{agony} function \cite{gupte2011finding}. It considers the difference in ordinal ranks as penalities\footnote{We use \emph{positional} ranks instead of the real-valued ranks to avoid scale problems comparing different algorithms}. Subsequently, an upset between two nodes close in rank counts much less than an upset between two nodes far rank, based on a parameter $d$:
\begin{equation*}
\textrm{agony} = \frac{1}{M}\sum_{i,j} A_{ij} \hspace{0.1cm}  max(0,r_i - r_j)^d \, ,
\end{equation*}
where $r_i\in [0,..,n-1]$ is the \emph{ordinal} rank of node $i$ (which can naturally be extracted from the real-valued ranks $s_{i}$). When $d = 0$ we recover the standard number of unweighted upsets. The more the rank is informative towards the predicted outcomes, the lower the value of the agony and the less the hierarchy is violated.

Accuracy and agony are metrics for ordinal rankings. For real-valued models such as SpringRank, it is worth considering fine-grained metrics as well.
We thus consider in our experiments two other metrics that take into account an estimate of $P_{ij}$ -- the probability that $i$ beats $j$.

First, $\sigma_a$ is the average probability assigned to the correct direction of an edge:
\begin{equation*}
\sigma_a= 1 - \frac{1}{2M}\sum_{ij}\vert A_{ij}-\overline{A_{ij}}P_{ij}\vert \, ,
\end{equation*}
where $\overline{A_{ij}}=A_{ij}+A_{ji}$ is the number of interactions between $i$ and $j$.

Second, $\sigma_L$ is the conditional log-likelihood of generating the directed edges \emph{given} their existence:
\begin{align*}
\sigma_L&=\log P\bup{A|\bar{A}}\\
&=\sum_{ij}  \binom{A_{ij}+A_{ji}}{A_{ij}}+\log\left[P_{ij}(\beta)^{A_{ij}}\bup{1-P_{ij}(\beta)}^{A_{ji}}\right]. \nonumber
\end{align*}

Notice that we explicitly highlight the dependence of $P_{ij}$ on the (inverse) \emph{temperature} parameter $\beta$ which control the level of hierarchy in the predictions. For $\beta \rightarrow \infty$ the network is fully hierarchical which means that an edge between $i$ and $j$, with $s_{i}>s_{j}$, points from $i\rightarrow j$ with $P_{ij}=1$. In contrast, when $\beta=0$, the predicted outcomes are completely random with $P_{ij}=P_{ji}=0.5$. 

In general, maximizing $\sigma_a$ and $\sigma_L$ requires two distinct values for $\beta$ that we will denote as $\hat{\beta}_a$ and $\hat{\beta}_L$. Intuitively, the reason is that a single severe mistake where $A_{ij}=1$ but $P_{ij} \approx 0$ reduces the likelihood by a large amount, while only reducing the accuracy by one edge.  As a result, predictions using $\hat{\beta}_a$ produce fewer incorrectly oriented edges and achieve a higher $\sigma_a$ on the test set. On the other hand, predictions using $\hat{\beta}_L$ will produce fewer dramatically incorrect predictions where $P_{ij}$ is very low, and thus achieve higher $\sigma_L$ on the test set \cite{de2018physical}. In other words, a prediction model that maximizes $\sigma_L$ tends to be more cautious in assigning high probabilities of \emph{success}, even in very unbalanced matches, in order to avoid potential impactful mistakes. In contrast, a model optimizing $\sigma_a$ can be less conservative, ignoring isolated (even dramatic) mistakes and favoring a good frequency of predictions as close as possible to the real probability.

\section{Cross-Validation and Hyperparameter Tuning}\label{sisec:tuning}
We provide more technical details about the hyperparameter tuning used in the various algorithms and experiments. In all cases, we assume training and test sets have a chronological order, i.e., all matches in the train set happen earlier than those in the test set. Regardless of hyperparameters, all cross-validation folds provide the same exact train/test set to each algorithm for a fair comparison. Importantly, test sets are only used for evaluation.

All results displayed were computed with cross-validation which entailed using 50\% of the total data as a train set and 4 time-steps as a test set. This interval was shifted by 1 time-step each fold. Fig~\ref{fig:cross_val} demonstrates this process. As a result of cross-validation, there are at most four different values for the same time-step. The reported results are an average of these values.
% Figure environment removed

As previously mentioned, we used grid-search to perform hyperparameter tuning. For \dsrfull, grid-search is divided into two steps: first, finding the order of magnitude of $\kself$ and then progressively finding a more precise value. Refer to Algorithm \ref{alg:grid_search} for the pseudocode of the procedure followed.
\begin{algorithm}[hbt!]
	\caption{Grid-Search}
	\label{alg:grid_search}
	\begin{algorithmic}[1]
		\STATE $K =\{0.001, 0.01, 0.1, 1, 10, 100, 1000\}$
		\FOR{$i \gets -1,-2,-3$}
			\FOR{$\kself$ in $K$}\\
				\quad \quad Find $\kself^{*}$, the optimal $\kself$ that produces best result
			\ENDFOR
			\STATE Update interval $K = [\kself^{*} - 10^i,\quad \kself^{*} + 10^i]$
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

Three algorithms (\mwsr, TS and WHR) require an optimal window size, $\tau_{\opt}$, for storing data in the training set. We chose this by varying the window size, calculating the average value for each performance metric inside the training set and then choosing the window size corresponding to the best of each of these values. Since the reported results are due to cross-validation, on average the window size of  \mwsr, TS and WHR on the NBA dataset is $\tau_{\opt}=13, 23, 31$ respectively. 

Next, Elo requires a scaling factor $k$ which was determined through a grid-search in the interval $[1,100)$. WL requires a decaying factor for weighing the data observed and it was set to $0.005$. Finally, there are different versions of static SpringRank and we considered the standard version with regularization $\alpha=0$.

\section{Synthetic Experiments}\label{apx:synthetic_experiments}

\paragraph*{Periodic Evolution of Synthetic Ranks.}We consider a periodic evolution of the ranks generated for synthetic experiments, expressed as Eq.~\eqref{eq:dyn_score}. To add detail to the extraction process of the parameters, they were selected from a continuous uniform distribution. The interval of the distribution for parameters was as follows: $b_{i},c_{i}\in[-1,1)$;  $\omega_i,\upsilon_i\in[-1,2)$ and, finally, $\phi_i\in[0,1)$.   
\paragraph*{Standard errors.} We report standard errors on synthetic experiments where we vary the noise level represented by the parameter $\beta$ in \Cref{tb:sem_beta}. These complement \Cref{tab:varying_noise}  in the main manuscript.

\begin{table}[h!]
	\centering
	\begin{tabular}{cc|cccccccc}
		    \textbf{$\beta$} & \textbf{Metric}         &     \textbf{Elo} &  \textbf{\nmdsr} &    \textbf{\mwsr} &     \textbf{\dsr} &      \textbf{SR} &      \textbf{TS} &       \textbf{W-L} &     \textbf{WHR} \\
		    \hline
		    \multirow{4}*{\textbf{0.1}}  & accuracy &  0.0073 &  0.0065 &  0.0067 &  0.0070 &  0.0064 &  0.0068 &  0.0067 &  0.0077 \\
		    & agony &  0.0286 &  0.0269 &  0.0278 &  0.0267 &  0.0331 &  0.0265 &   0.03225 &  0.0284 \\
		    & $\sigma_a$ &  0.0028 &  0.0031 &  0.0044 &  0.0039 &  0.0032 &  0.0029 &        -- &  0.0028 \\
		    & $\sigma_L$ &  0.0107 &  0.0008 &  0.0055 &  0.0044 &  0.0019 &  0.0077 &        -- &  0.0066 \\
		    \hline
		  \multirow{4}*{\textbf{0.5}}  & accuracy &  0.0056 &  0.0054 &  0.0057 &  0.0056 &  0.0042 &  0.0051 &  0.0073 &  0.0054 \\
		    & agony &  0.0197 &  0.0196 &  0.0202 &  0.0203 &  0.0168 &  0.0190 &  0.0297 &  0.0185 \\
		    & $\sigma_a$ &  0.0027 &  0.0030 &  0.0051 &  0.0048 &  0.0031 &  0.0029 &        -- &  0.0029 \\
		    & $\sigma_L$ &  0.0215 &  0.0035 &  0.0127 &  0.0114 &  0.0061 &  0.0121 &        -- &  0.0110 \\
		    \hline
	\multirow{4}*{\textbf{1.0}} & accuracy &  0.0056 &  0.0053 &  0.0048 &  0.0050 &  0.0073 &  0.0047 &  0.0062 &  0.0044 \\
		    & agony &  0.0164 &  0.0156 &  0.0152 &  0.0161 &  0.0297 &  0.0141 &  0.0334 &  0.0142 \\
		    & $\sigma_a$ &  0.0035 &  0.0037 &  0.0044 &  0.0047 &  0.0059 &  0.0030 &        -- &  0.0029 \\
		    & $\sigma_L$ &  0.0318 &  0.0079 &  0.0153 &  0.0159 &  0.0254 &  0.0151 &        -- &  0.0135 \\
		    \hline
		   \multirow{4}*{\textbf{1.5}} & accuracy &  0.0049 &  0.0050 &  0.0050 &  0.0048 &  0.0052 &  0.0049 &  0.0062 &  0.0046 \\
		    & agony &  0.0126 &  0.0132 &  0.0124 &  0.0131 &  0.0210 &  0.0129 &  0.0331 &  0.0118 \\
		    & $\sigma_a$ &  0.0035 &  0.0040 &  0.0046 &  0.0043 &  0.0047 &  0.0037 &        -- &  0.0034 \\
		    & $\sigma_L$ &  0.0346 &  0.0080 &  0.0203 &  0.0232 &  0.0263 &  0.0187 &        -- &  0.0148 \\
		    \hline
		  \multirow{4}*{\textbf{2.0}}  & accuracy &  0.0038 &  0.0042 &  0.0036 &  0.0040 &  0.0053 &  0.0047 &  0.0058 &  0.0046 \\
		    & agony &  0.0092 &  0.0095 &  0.0080 &  0.0082 &  0.0206 &  0.0094 &  0.0320 &  0.0089 \\
		    & $\sigma_a$ &  0.0032 &  0.0034 &  0.0035 &  0.0038 &  0.0051 &  0.0034 &        -- &  0.0031 \\
		    & $\sigma_L$ &  0.0301 &  0.0073 &  0.0152 &  0.0144 &  0.0302 &  0.0163 &        -- &  0.0147 \\
	\end{tabular}
	\caption{\textbf{Standard error of results from synthetic data with varying noise levels, represent by $\beta$}}
	\label{tb:sem_beta}
\end{table}



\paragraph*{Results for Varying Network Density.}
In \Cref{tab:varying_density,tb:sem_density} , we show results on synthetic data where we vary the network density represented by the parameter $c$.

\begin{table}[!htb]
	\resizebox{11cm}{3.8cm}{
	\begin{tabular}{c|c|cccccccc}
		{$\boldsymbol{c}$} & {\textbf{Metric}} & {\textbf{Elo}} & {\textbf{\nmdsr}} & {\textbf{\mwsr}} & {\textbf{\dsr}} & {\textbf{SR}} & {\textbf{TS}} & {\textbf{W-L}} & {\textbf{WHR}} \\
		\hline
		\multirow[t]{4}{*}{\textbf{1.0}} & accuracy & 0.905 & 0.901 & 0.903 & 0.904 & 0.774 & \sethlcolor{green}\hl{\textbf{0.905}} & 0.156 & 0.903 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& agony & 0.161 & 0.167 & 0.163 & 0.165 & 0.562 & \sethlcolor{green}\hl{\textbf{0.159}} & 3.423 & 0.162 \\
		& $\sigma_a$ & 0.895 & 0.892 & 0.909 & \sethlcolor{green}\hl{\textbf{0.910}} & 0.778 & 0.889 & -- & 0.884 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& $\sigma_L$ & -0.574 & -0.705 & -0.459 & -0.459 & -1.054 & -0.451 & -- & \sethlcolor{green}\hl{\textbf{-0.450}} \\
		\hline
		\multirow[t]{4}{*}{\textbf{1.5}} & accuracy & 0.900 & 0.897 & 0.902 & \sethlcolor{green}\hl{\textbf{0.903}} & 0.770 & 0.902 & 0.148 & 0.903 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& agony & 0.161 & 0.171 & 0.159 & \sethlcolor{green}\hl{\textbf{0.157}} & 0.608 & 0.162 & 3.364 & 0.157 \\
		& $\sigma_a$ & 0.899 & 0.902 & 0.908 & \sethlcolor{green}\hl{\textbf{0.909}} & 0.771 & 0.894 & -- & 0.895 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& $\sigma_L$ & -0.581 & -0.617 & -0.462 & -0.459 & -1.155 & -0.460 & -- & \sethlcolor{green}\hl{\textbf{-0.452}} \\
		\hline
		\multirow[t]{4}{*}{\textbf{2.0}} & accuracy & \sethlcolor{green}\hl{\textbf{0.909}} & 0.905 & 0.904 & 0.907 & 0.768 & 0.904 & 0.126 & 0.904 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& agony & \sethlcolor{green}\hl{\textbf{0.147}} & 0.156 & 0.154 & 0.148 & 0.601 & 0.154 & 3.420 & 0.153 \\
		& $\sigma_a$ & 0.911 & 0.910 & 0.915 & \sethlcolor{green}\hl{\textbf{0.916}} & 0.772 & 0.907 & -- & 0.902 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& $\sigma_L$ & -0.579 & -0.575 & -0.464 & -0.453 & -1.152 & \sethlcolor{green}\hl{\textbf{-0.452}} & -- & -0.453 \\
		\hline
		\multirow[t]{4}{*}{\textbf{2.5}} & accuracy & 0.904 & 0.904 & 0.905 & \sethlcolor{green}\hl{\textbf{0.906}} & 0.763 & 0.905 & 0.124 & 0.905 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& agony & 0.159 & 0.160 & 0.159 & \sethlcolor{green}\hl{\textbf{0.155}} & 0.601 & 0.160 & 3.417 & 0.160 \\
		& $\sigma_a$ & 0.912 & 0.913 & 0.916 & \sethlcolor{green}\hl{\textbf{0.918}} & 0.773 & 0.909 & -- & 0.907 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& $\sigma_L$ & -0.601 & -0.650 & -0.470 & -0.463 & -1.172 & -0.459 & -- & \sethlcolor{green}\hl{\textbf{-0.458}} \\
		\hline
		\multirow[t]{4}{*}{\textbf{3.0}} & accuracy & \sethlcolor{green}\hl{\textbf{0.910}} & 0.908 & 0.908 & 0.909 & 0.768 & 0.909 & 0.114 & 0.909 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& agony & \sethlcolor{green}\hl{\textbf{0.147}} & 0.150 & 0.152 & 0.149 & 0.605 & 0.152 & 3.481 & 0.151 \\
		& $\sigma_a$ & 0.921 & 0.921 & 0.920 & \sethlcolor{green}\hl{\textbf{0.921}} & 0.776 & 0.917 & -- & 0.915 \\
		\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
		& $\sigma_L$ & -0.549 & -0.559 & -0.455 & -0.447 & -1.158 & -0.438 & -- & \sethlcolor{green}\hl{\textbf{-0.438}} \\
	\end{tabular}}
	\caption{\textbf{Results obtained from synthetic data with varying density levels, represented by $\boldsymbol{c}$.} Each value is the mean of 4 independent realizations of the model. The green highlighted values are the top performances for the considered metric. Notably, some of the values in the same row appear identical but only a single value is highlighted. This is because the highlighted value is better by less than three decimal places. \Cref{tb:sem_density} contains the standard error for the above values. $\sigma_a$ and $\sigma_L$ cannot be applied to the W-L model hence there are no values for the metrics.}
	\label{tab:varying_density}
\end{table}

\begin{table}[h!]
	\centering
	\begin{tabular}{cc|cccccccc}
		\textbf{c} & \textbf{Metric}         &     \textbf{Elo} &  \textbf{\nmdsr} &    \textbf{\mwsr} &     \textbf{\dsr} &      \textbf{SR} &      \textbf{TS} &       \textbf{W-L} &     \textbf{WHR} \\
		\hline
		\multirow{4}*{\textbf{1.0}} & accuracy &  0.0021 &  0.0025 &  0.0023 &  0.0024 &  0.0040 &  0.0024 &  0.0041 &  0.0022 \\
		& agony &  0.0044 &  0.0055 &  0.0048 &  0.0050 &  0.0138 &  0.0052 &  0.0288 &  0.0051 \\
		& $\sigma_a$ &  0.0017 &  0.0023 &  0.0020 &  0.0020 &  0.0031 &  0.0021 &        -- &  0.0021 \\
		& $\sigma_L$ &  0.0171 &  0.0087 &  0.0099 &  0.0099 &  0.0200 &  0.0106 &        -- &  0.0095 \\
		\hline
		\multirow{4}*{\textbf{1.5}} & accuracy &  0.0026 &  0.0027 &  0.0025 &  0.0023 &  0.0039 &  0.0026 &  0.0035 &  0.0026 \\
		& agony &  0.0051 &  0.0056 &  0.0053 &  0.0050 &  0.0180 &  0.0057 &   0.0186 &  0.0056 \\
		& $\sigma_a$ &  0.0016 &  0.0019 &  0.0021 &  0.0020 &  0.0034 &  0.0016 &        -- &  0.0017 \\
		& $\sigma_L$ &  0.0151 &  0.0053 &  0.0084 &  0.0085 &  0.0296 &  0.0086 &        -- &  0.0085 \\
		\hline
		\multirow{4}*{\textbf{2.0}}  & accuracy &  0.0019 &  0.0021 &  0.0020 &  0.0019 &  0.0032 &  0.0022 &   0.0025 &  0.0023 \\
		& agony &  0.0047 &  0.0044 &  0.0049 &  0.0046 &  0.0130 &  0.0050 &   0.0139 &  0.0052 \\
		& $\sigma_a$ &  0.0015 &  0.0018 &  0.0019 &  0.0018 &  0.0026 &  0.0016 &        -- &  0.0016 \\
		& $\sigma_L$ &  0.0176 &  0.0079 &  0.0095 &  0.0087 &  0.0273 &  0.0095 &        -- &  0.0089 \\
		\hline
		\multirow{4}*{\textbf{2.5}} & accuracy &  0.0017 &  0.0016 &  0.0016 &  0.0017 &  0.0036 &  0.0017 &  0.0022 &  0.0018 \\
		& agony &  0.0042 &  0.0040 &  0.0040 &  0.0039 &  0.0140 &  0.0045 &  0.0117 &  0.0046 \\
		& $\sigma_a$ &  0.0014 &  0.0013 &  0.0015 &  0.0014 &  0.0030 &  0.0014 &        -- &  0.0014 \\
		& $\sigma_L$ &  0.0143 &  0.0065 &  0.0076 &  0.0073 &  0.0285 &  0.0076 &        -- &  0.0072 \\
		\hline
		\multirow{4}*{\textbf{3.0}}  & accuracy &  0.0015 &  0.0018 &  0.0016 &  0.0017 &  0.0027 &  0.0017 &  0.0022 &  0.0016 \\
		& agony &  0.0031 &  0.0037 &  0.0036 &  0.0035 &  0.0146 &  0.0035 &  0.0140 &  0.0037 \\
		& $\sigma_a$ &  0.0010 &  0.0013 &  0.0014 &  0.0013 &  0.0025 &  0.0010 &        -- &  0.0010 \\
		& $\sigma_L$ &  0.0102 &  0.0046 &  0.0061 &  0.0059 &  0.0278 &  0.0055 &        -- &  0.0054 \\
	\end{tabular}
	\caption{\textbf{Standard error of results from synthetic data with varying density, represented by c.}}
	\label{tb:sem_density}
\end{table}



\paragraph*{Synthetic Ranks in static scenarios.} We consider  static ranks $s_{i}^{t}=s_{i}$ generated synthetically using \Cref{eq:dyn_score} as a sanity check of our permutation test for model selection between static and dynamic models. Results are shown in \Cref{tab:static_results} and \Cref{tb:sem_static}.

\begin{table}[h]
	\resizebox{0.5\linewidth}{!}{
		\begin{tabular}{c|cccccccc}
			{\textbf{Metric}} & {\textbf{Elo}} & {\textbf{\nmdsr}} & {\textbf{\mwsr}} & {\textbf{\dsr}} & {\textbf{SR}} & {\textbf{TS}} & \textbf{{W-L}} & {\textbf{WHR}} \\
			\hline
			\textbf{accuracy} & 0.715 & 0.716 & 0.696 & 0.720 & 0.722 & \sethlcolor{green}\hl{\textbf{0.724}} & 0.360 & 0.723 \\
			\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
			\textbf{agony} & 0.528 & 0.518 & 0.565 & 0.523 & \sethlcolor{green}\hl{\textbf{0.498}} & 0.517 & 1.632 & 0.515 \\
			$\boldsymbol{\sigma_a}$ & 0.666 & 0.618 & 0.704 & \sethlcolor{green}\hl{\textbf{0.733}} & 0.669 & 0.687 & --   & 0.679 \\
			\rowcolor[gray]{0.95}[\tabcolsep][\tabcolsep]
			$\boldsymbol{\sigma_L}$ & -1.211 & -1.324 & -1.231 & -1.172 & -1.148 & \sethlcolor{green}\hl{\textbf{-1.109}} & --   & -1.111 \\
	\end{tabular}}
	\caption{\textbf{Results obtained from synthetic data in a static framework.} Performance comparison of the various models on a synthetic dataset where the ranks are fixed along time (static framework). The green highlighted values are the top performances for the considered metric. \Cref{tb:sem_static} contains the standard error of the above values. $\sigma_a$ and $\sigma_L$ cannot be applied to the W-L model, so there are no values for the metrics.}
	\label{tab:static_results}
\end{table}

\begin{table}[h!]
	\centering
	\begin{tabular}{c|cccccccc}
		\textbf{Metric} &     \textbf{Elo} &  \textbf{\nmdsr} &    \textbf{\mwsr} &     \textbf{\dsr} &      \textbf{SR} &      \textbf{TS} &       \textbf{W-L} &     \textbf{WHR} \\
		\hline
		\textbf{accuracy} &  0.0107 &  0.0109 &  0.0109 &  0.0109 &  0.0111 &  0.0101 &  0.0142 &  0.0099 \\
		\textbf{agony}    &  0.0243 &  0.0247 &  0.0250 &  0.0261 &  0.0259 &  0.0242 &  0.0391 &  0.0242 \\
		$\boldsymbol{\sigma_a}$  &  0.0059 &  0.0052 &  0.0099 &  0.0095 &  0.0085 &  0.0058 &        -- &  0.0056 \\
		$\boldsymbol{\sigma_L}$  &  0.0423 &  0.0049 &  0.0380 &  0.0399 &  0.0223 	&  0.0277 &        -- &  0.0251 \\
	\end{tabular}
	\caption{\textbf{Standard error of results from the synthetic data in a static framework.}}
	\label{tb:sem_static}
\end{table}




\section{Real Data Experiments}
\paragraph*{Standard errors.} We report the standard errors of the experiments on the real datasets in \Cref{tb:sem_real}. These complement \Cref{tab:real_data_results} in the main manuscript.


\begin{table}[htbp!]
	\centering
	\begin{tabular}{cc|cccccccc}
		\textbf{Dataset} & \textbf{Metric} &     \textbf{Elo} &  \textbf{\nmdsr} &    \textbf{\mwsr} &     \textbf{\dsr} &      \textbf{SR} &      \textbf{TS} &     \textbf{WHR} &       \textbf{W-L} \\
		\hline
		\multirow{4}*{\textbf{NBA}} & accuracy &  0.0048 &  0.0049 &  0.0046 &  0.0048 &  0.0047 &  0.0050 &  0.0047 &  0.0050 \\
		& agony &  0.0587 &  0.0588 &  0.0621 &  0.0577 &  0.0529 &  0.0576 &  0.0553 &  0.0662 \\
		& $\sigma_a$ &  0.0021 &  0.0025 &  0.0045 &  0.0045 &  0.0040 &  0.0024 &  0.0022 &        -- \\
		& $\sigma_L$ &  0.0154 &  0.0028 &  0.0075 &  0.0063 &  0.0041 &  0.0097 &  0.0082 &        -- \\
		\hline
		\multirow{4}*{\textbf{Chess}} & accuracy &  0.0353 &  0.0319 &  0.0365 &  0.0324 &  0.0327 &  0.0360 &  0.0358 &  0.0203 \\
		& agony &  1.2407 &  1.8447 &  1.6864 &  1.2389 &  1.2373 &  1.2945 &  1.2188 &  0.3281 \\
		& $\sigma_a$ &  0.0137 &  0.0134 &  0.0173 &  0.0179 &  0.0123 &  0.0146 &  0.0131 &        -- \\
		& $\sigma_L$ &  0.0773 &  0.0356 &  0.0640 &  0.0753 &  0.1090 &  0.0706 &  0.0507 &        -- \\
		\hline
		\multirow{4}*{\textbf{EPL}} & accuracy &  0.0061 &  0.0067 &  0.0073 &  0.0058 &  0.0063 &  0.0064 &  0.0062 &  0.0080 \\
		& agony &  0.0920 &  0.1292 &  0.1429 &  0.0906 &  0.0935 &  0.1172 &  0.1082 &  0.1611 \\
		& $\sigma_a$ &  0.0026 &  0.0035 &  0.0068 &  0.0059 &  0.0060 &  0.0030 &  0.0032 &        -- \\
		& $\sigma_L$ &  0.0249 &  0.0038 &  0.0139 &  0.0145 &  0.0112 &  0.0154 &  0.0141 &        -- \\
		\hline
		\multirow{4}*{\textbf{Serie A}}  & accuracy &  0.0048 &  0.0051 &  0.0051 &  0.0049 &  0.0050 &  0.0050 &  0.0047 &  0.0060 \\
		& agony &  0.0881 &  0.1227 &  0.1282 &  0.0856 &  0.0930 &  0.1252 &  0.1174 &  0.1632 \\
		& $\sigma_a$ &  0.0020 &  0.0013 &  0.0047 &  0.0044 &  0.0045 &  0.0024 &  0.0022 &        -- \\
		& $\sigma_L$ &  0.0176 &  0.0013 &  0.0102 &  0.0104 &  0.0060 &  0.0107 &  0.0093 &        -- \\
	\end{tabular}
	\caption{\textbf{Standard error of results from real data}}
	\label{tb:sem_real}
\end{table}

\section{Null Model Experiments}\label{sec:null_experiments}
\paragraph*{Synthetic data.} We report results of the null model experiments where we permute the chronological order of synthetic dynamic data in  \Cref{fig:histogram_varying_noise} and of synthetic static data in \Cref{fig:histogram_static}.
\paragraph*{Real data.} We report p-values on the null model experiments on real data in \Cref{tb:pvalues}.

% Figure environment removed

% Figure environment removed

% Figure environment removed

\begin{table}[h!]
\centering
{\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{cc|cccc}
	Model &Metric	&   NBA & Chess  & EPL & Serie A\\
	\hline 
	\multirow{4}*{\dsr} &  accuracy & 0.0 & 0.594 & 0.183 & 0.359\\
	& agony &0.0&0.006&0.0&0.0\\
	&$\sigma_{a}$& 0.0&0.139 &0.155&0.282\\
	& $\sigma_{L}$ & 0.0 & 0.711 &0.578&0.644\\
	\hline
	\multirow{4}*{\mwsr} &  accuracy & 0.0 & 1.0 &0.411 & 0.999\\
	& agony &0.0&0.001&0.959&1.0\\
	&$\sigma_{a}$& 0.0&0.832 &0.340&0.999\\
	& $\sigma_{L}$ & 0.0 & 0.797 &0.911&1.0\\
	\end{tabular}}
\caption{\textbf{Null model p-value results on real data.} Illustrated are the number of times (as a percentage) that the metric value on the randomized dataset is better than on the chronologically-ordered dataset. Results are calculated over $1000$ permutations.}
\label{tb:pvalues}
\end{table}


\end{widetext}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
