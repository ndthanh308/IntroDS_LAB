
\section{Conclusions}
We present FDCT, a novel and efficient end-to-end network for transparent object depth completion. FDCT predicts a rectified depth map using only RGB and depth images as inputs. It outperforms the state-of-the-art methods in terms of accuracy and efficiency, with the smallest number of parameters while running at a fast speed of 70 FPS. Our experiments show that FDCT has strong generalization ability, with excellent results on unseen objects and cross-dataset scenarios. In addition, the improved depth prediction by FDCT can lead to improved performance in pose estimation, demonstrating its potential as a useful auxiliary tool for ordinary pose estimation methods when dealing with transparent objects.
There is still some works could be done in the future. The hyperparameter $\delta$ in Huber loss is set manually and unchanged. 
% In this paper, we propose FDCT, an end-to-end efficient network for transparent objects depth completion. FDCT predicts rectified depth from RGB and depth image only. Our method achieves state-of-the-art performance with least parameters and runs at 70 FPS. Experiment results show that FDCT has a generalization ability to unseen object and cross-dataset. Pose estimation method designed for opaque objects achieves a better performance with depth restored by FDCT, showing its potential to be an auxiliary tool for ordinary pose estimation methods dealing with transparent objects.