\section{Introduction}

\IEEEPARstart{D}{epth} completion has received increasing attention due to its essential role in various robotic tasks such as autonomous driving \cite{hu2021penet,nazir2022semattnet,yan2022rignet} and manipulation \cite{ichnowski2021dex}.
It aims at predicting per-pixel depth value given a sparse image from a depth sensor such as RGB-D camera \cite{zhang2018deep} or LiDAR \cite{jaritz2018sparse}.
It has been demonstrated that accurate depth completion is able to significantly improve the performance of downstream tasks such as object grasping due to its abundant 3-D information \cite{sajjan2020clear,tang2021depthgrasp,fang2022transcg}.
Despite those progresses, many existing methods still struggle with transparent objects, which are commonly encountered in daily life and modern industry.
% and automatic manipulation needs localization information of the transparent objects. 
% \todo{we need an example here to say transparent object are widely used in graphing}
This is because transparent objects are refractive and reflective, which can cause the optical sensors to produce inaccurate depth measurements \cite{tanaka2016recovering}.
% making it challenging for commercial depth camera to produce accurate depth estimates. 
% However, few methods \cite{gou2021rgb,he2021ffb6d,di2022gpv,li2022diversity} \todo{i have changed "grasping or pose estimation methods" to "depth completion", citation may need to change also} can directly apply to scenarios with mixed transparent and opaque objects, which largely limits their real-world applications.
%In this paper, we will try to solve this problem and propose a fast depth completion framework for transparent objects (FDCT) and show its effectiveness in an object grasping task.
% Therefore, depth completion is essential to the manipulation of transparent objects.
% Figure environment removed


The field of depth completion for transparent objects is still relatively unexplored, and the current methods either struggle to generalize well or require significant computational resources that may not be suitable for low-power platforms.
% There are only a few depth completion methods focusing on transparent objects but they either cannot generalize well or are quite heavy for low-power platforms.
% attempt to improve the accuracy of pose estimation or grasping by first correcting depth information.
For example, ClearGrasp \cite{sajjan2020clear} uses three networks to predict surface normal, edge, and transparent mask and estimate depth value by global optimization.
It outperforms the monocular depth estimation methods by a large margin, but global optimization is computational heavy and needs well-trained network.
% It outperforms the monocular depth estimation methods by a large margin, and significantly improves the grasping success rate. 
% However, global optimization is time consuming and needs well-trained network.
Zhu et al. \cite{zhu2021rgb} introduces  a method  for local implicit depth prediction and depth refinement based on voxel map, which significantly speeds up the progress. However, the method has limitations in terms of generalization to new environments \cite{fang2022transcg}.
Recently, Fang et al. \cite{fang2022transcg} proposed an encoder-decoder U-Net-based architecture that achieved the state-of-the-art performance in the area.
However, the method has certain limitations, such as directly concatenating the raw depth image to the deep features, makes the network sensitive to depth noise. Furthermore, their network tends to predict depth image with blurry edges.
% However, they straightly concatenates raw depth image to deep features, makes the network sensitive to the noise of the original depth values and their network is slower than \cite{zhu2021rgb}.



% Previous works have problems in inference time and the utilization of raw depth information. Typically, those works use sub-network predicting features such as edge and solve the depth by global optimization or GAN based structure, which is proved to be time consuming. Besides, those low-level features are usually not stable due to sensor noise, lighting conditions and shooting angles, which may lead to extra inaccuracy when they are introduced into the network by independent sub-network. Furthermore, some works contain redundant modules, which disrupts the learning of low-level features and could reduce the speed and accuracy of the network. Other works apply a transparency mask to the original depth map to get a modified one, which destroys the original raw depth information at the outset. 

Low-level feature refers to basic visual elements such as edges, 
 angles etc. As the network deepens, the receptive field increases, and the features transition from local to global, and from low-level to high-level. Research has shown that the low-level feature plays a significant role in depth completion \cite{zuo2016explicit,tao2021dilated,huang2019indoor}.
However, incorporating these features in existing depth completion networks can lead to other issues, such as increased sensitivity to sensor noise and lighting conditions, as well as trade-offs between efficiency and accuracy \cite{sajjan2020clear,fang2022transcg}.
% , such as being too sensitive to the sensor noise, lighting conditions and trade-off between efficiency and accuracy brought about by additional processing \cite{sajjan2020clear,fang2022transcg}. 
This problem becomes more severe when transparent objects need to be handled. 
To address these issues, some methods \cite{zhang2018deep,sajjan2020clear,tang2021depthgrasp} mask out the transparent objects from the original depth images and use a separated sub-network to predict those features.
However, this can result in additional inaccuracies when inferring results. Moreover, using too many local features can lead to overfitting during training, which can negatively impact the generalization ability of the model \cite{ying2019overview}.




To better extract those features while maintaining low computational complexity, we propose a Fast Depth Completion architecture for Transparent objects (FDCT).
Firstly, we streamline the architecture for faster inference by eliminating separated prediction and non-essential modules. 
We adopt a new fusion branch based on shortcut fusion module and cross-layer shortcuts to more efficiently exploit low-level features. 
% Then, a new fusion branch based on Shortcut Fusion Module and Cross-layer Shortcuts are adopted to exploit low-level features more efficiently.
To reduce the semantic differences between raw depth and features, 
we introduce a domain adaptation operation when providing the full original depth image to the network.
% a domain adaption operation is introduced when the full original depth image is provided to the network. 
Meanwhile, we use a downsampling method based on max pooling to accelerate the network while capturing global features. Finally, we design a new loss function to avoid overfitting and fuse local and global features in the decoder. In summary, we make the following contributions:
\begin{enumerate}
  \item We propose a fast architecture for transparent objects depth completion called FDCT. It takes only raw RGB-D images and can assist with downstream tasks, such as object grasping and 3D reconstruction.
  \item To exploit the low-level features, we introduce a fusion branch that utilize Shortcut fusion module and cross-layer shortcuts. We also develop a new loss function to avoid overfitting during the fusion of local and global features, leading to an accurate depth estimation.
%   take advantage of multi-scale and multi-layer information. 
%   Encoder and decoder block are designed to reduce overfitting and may be a reference to future work.
  \item FDCT outperforms the state-of-the-art depth completion methods by at least 16\% while using less parameters and runing at around 70 FPS. Experimental results demonstrate FDCT benefits pose estimation and grasping tasks. 
\end{enumerate}