\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
%\usepackage{neurips_2023}
\bibliographystyle{rusnat}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{easyReview}

\usepackage[normalem]{ulem}
\definecolor{myPurple}{rgb}{0.4, .0, .8}
\definecolor{myGreen}{rgb}{0, .8, .3}
\definecolor{myRed}{rgb}{0.8, .2, .2}
\definecolor{myBlue}{rgb}{0.0, .0, .8}
\newcommand{\yan}[1]{ \noindent {\color{myBlue} {[\bf yan:} {#1}]}}

\DeclareMathOperator*{\argminA}{arg\,min}


\title{Iterative Reconstruction Based on Latent Diffusion Model for Sparse Data Reconstruction}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{Linchao He\thanks{Equal contribution.}$^{\ \,1,2}$, \quad Hongyu Yan\footnotemark[1]$^{\ \,1,2}$, \quad Mengting Luo$^{1,2}$, \quad Kunming Luo$^{3}$, \\
	\textbf{Wang Wang}$^{4}$\textbf{,} \quad \textbf{Wenchao Du}$^{2}$\textbf{,} \quad \textbf{Hu Chen}\thanks{Corresponding Authors.}$^{\ \,2}$ \textbf{Hongyu Yang}$^{2}$ \textbf{Yi Zhang}$^{5}$
	\\
	% \small
	$^1$Department of National Key Laboratory of  
	 Fundamental Science on \\ Synthetic Vision, Sichuan University, Chengdu, China \\
	% \small
	$^2$College of Computer Science, Sichuan University, Chengdu, China \\
	$^3$The Hong Kong University of Science and Technology, Hong Kong, China \\
	$^4$State Key Laboratory of Information Engineering in Surveying, \\ Mapping and Remote Sensing (LIESMARS), Wuhan University, Wuhan, China \\
	$^5$School of Cyber Science and Engineering, Sichuan University, Chengdu, China \\
	% \small
	\texttt{\{hlc, hongyuyan, lmt\}@stu.scu.edu.cn};~
	% \small
	\texttt{kluoad@connect.ust.hk}; \\
	% \small
	\texttt{wwwwhu520@gmail.com};~
	% \small
	\texttt{wenchaodu.scu@gmail.com};~
	% \small
	\texttt{huchen@scu.edu.cn}; \\
	\texttt{yanghongyu\_scu@163.com};
	\texttt{yzhang@scu.edu.cn}
}

%\author{%
%	Linchao He\thanks{Equal contribution.}, \quad Hongyu Yan, \quad Mengting Luo, \quad Kunming Luo, \\
%	Wang Wang, \quad Wenchao Du, \quad Hu Chen, \quad Hongyu Yang, \\
%	Yi Zhang 
%	
%	$^1$Dept. of Comp. Sci. \& Tech., BNRist Center, Tsinghua-Bosch Joint ML Center, Tsinghua University \\
%	% \small
%	$^2$Gaoling School of Artificial Intelligence, Renmin University of China, \\
%	% \small
%	Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China \\
%	$^3$ShengShu, Beijing, China; \quad  $^4$Pazhou Laboratory (Huangpu), Guangzhou, China \\
%	% \small
%	\texttt{\{wang-zy21, bf19\}@mails.tsinghua.edu.cn};~
%	% \small
%	\texttt{lucheng.lc15@gmail.com}; \\
%	% \small
%	\texttt{yikaiw@outlook.com};~
%	% \small
%	\texttt{chongxuanli@ruc.edu.cn};~
%	% \small
%	\texttt{suhangss@tsinghua.edu.cn} \\
%	\texttt{dcszj@tsinghua.edu.cn} \\
%	
%	% examples of more authors
%	% \And
%	% Coauthor \\
%	% Affiliation \\
%	% Address \\
%	% \texttt{email} \\
%	% \AND
%	% Coauthor \\
%	% Affiliation \\
%	% Address \\
%	% \texttt{email} \\
%	% \And
%	% Coauthor \\
%	% Affiliation \\
%	% Address \\
%	% \texttt{email} \\
%	% \And
%	% Coauthor \\
%	% Affiliation \\
%	% Address \\
%	% \texttt{email} \\
%}


\begin{document}
	
	
	\maketitle
	
	
	\begin{abstract}
		% In recent years, diffusion models have proven to be highly effective in generating data unconditionally and learning score functions from existing data distributions. Given this success, it is natural to combine diffusion models with Iterative Reconstruction (IR) as a data prior. In this paper, we present Latent Diffusion Iterative Reconstruction (LDIR), a novel zero-shot method that extends traditional IR to latent space for reconstructing sparse data, such as CT sparse-view reconstruction, limited-angle reconstruction, and image inpainting. By replacing the prior term of IR with latent diffusion models, LDIR produces highly consistent and realistic reconstruction results. Moreover, leveraging latent space guidance, our zero-shot method can reconstruct high-resolution images. We also introduce a novel approach that uses historical gradient information to guide the current gradient, thereby enhancing the quality of the reconstruction. Our experiments on extremely sparse data reconstruction tasks show that LDIR outperforms other state-of-the-art unsupervised and supervised methods in terms of quantity and quality results. Additionally LDIR achieves competitive performance on nature image super-resolution tasks. Moreover, we demonstrate that LDIR is significantly faster than other methods with similar network settings.

        % Reconstructing Computed tomography (CT) images from sparse measurement is a well known ill-posed inverse problem. The Iterative Reconstruction (IR) algorithm is considered as a solution to inverse problems. However, traditional IR methods require paired images to train network and can not solve various CT reconstruction task with a single model. To address this problem, we present Latent Diffusion Iterative Reconstruction (LDIR), a pioneering zero-shot method that extends traditional IR with pretrained Latent Diffusion Model (LDM) for CT reconstruction. LDIR is the first method to successfully integrate iterative reconstruction and LDM, marking a significant advancement in the field. Specifically, we train a unconditional latent diffusion model to approximate the data distribution. Given the measurements and the projection matrix, we propose a guidance method that utilize the gradient from the data-fidelity term to guide the sampling process of the LDM. Therefore, we do not need any paired data or inverse of the measurement matrix. We also introduce a novel approach that uses historical gradient information to guide the current gradient, thereby enhancing the quality of the reconstruction. Our experiments on extremely sparse CT data reconstruction tasks show that LDIR outperforms other state-of-the-art unsupervised and supervised methods, establishing it as a leading technique in terms of both quantity and quality. Furthermore, LDIR achieves competitive performance on nature image tasks. It is worth noting that LDIR also exhibits significantly faster execution times and lower memory consumption compared to methods with similar network settings.

        Reconstructing Computed tomography (CT) images from sparse measurement is a well-known ill-posed inverse problem. The Iterative Reconstruction (IR) algorithm is a solution to inverse problems. However, recent IR methods require paired data and the approximation of the inverse projection matrix. To address those problems, we present Latent Diffusion Iterative Reconstruction (LDIR), a pioneering zero-shot method that extends IR with a pre-trained Latent Diffusion Model (LDM) as a accurate and efficient data prior. By approximating the prior distribution with an unconditional latent diffusion model, LDIR is the first method to successfully integrate iterative reconstruction and LDM in an unsupervised manner. LDIR makes the reconstruction of high-resolution images more efficient. Moreover, LDIR utilizes the gradient from the data-fidelity term to guide the sampling process of the LDM, therefore, LDIR does not need the approximation of the inverse projection matrix and can solve various CT reconstruction tasks with a single model. Additionally, for enhancing the sample consistency of the reconstruction, we introduce a novel approach that uses historical gradient information to guide the gradient. Our experiments on extremely sparse CT data reconstruction tasks show that LDIR outperforms other state-of-the-art unsupervised and even exceeds supervised methods, establishing it as a leading technique in terms of both quantity and quality. Furthermore, LDIR also achieves competitive performance on nature image tasks. It is worth noting that LDIR also exhibits significantly faster execution times and lower memory consumption compared to methods with similar network settings. Our code will be publicly available.
	\end{abstract}
	
	% Figure environment removed
	
	\section{Introduction}
    Computed tomography (CT) is a crucial medical imaging technique in contemporary medicine to aid physicians in diagnosing relevant conditions. Measurements in CT are obtained by X-rays projections of an object from different views. However, the use of X-rays in CT exposes the human body to potentially harmful doses of radiation, raising concerns among the public regarding radiation-induced diseases. Therefore, reducing the exposure dose, such as sparse-view and limited-angle imaging, while maintaining the quality of imaging has beneficial implications for both public health and medical diagnosis, specifically in intraoperative CT. Due to the sparse information, the CT reconstruction processes are well-known ill-posed inverse problems.
    In the past decade, numerous works have focused on Iterative Reconstruction (IR), which is considered a solution to CT reconstruction \citet{donoho2006compressed, candes2006robust}. Iterative reconstruction aims to recover signals $x$ from noisy measurements $y = \mathbf{A}x + n$, where $n$ represents the noise in the measuring process and $\mathbf{A}$ is the linear projection matrix that typically maps $x$ to a lower dimension. As a result, a typical IR process can be formulated as follows:
	\begin{align}
		\hat{x} = \argminA_x \left|\left|\mathbf{A}x - y\right|\right|_2^2 + \lambda R\left(x\right),
		\label{eq:ir_formualtion}
	\end{align}
	here, $\left|\left|\mathbf{A}x - y\right|\right|_2^2$ is the data-fidelity term that ensures the reconstructed results are consistent with the measurements, while $\lambda R\left(x\right)$ is a prior term that ensures the reconstructed results are realistic and follow the distribution $p\left(x\right)$ of the ground truth images. 
 
    % The key challenge of IR is to find appropriate data prior or sparse transformation to generate the prior term. While some representative works have been proposed to address this problem, such as total variation, nonlocal means, wavelets, and low rank methods, it remains challenging to obtain reconstruction results with high consistency and realism. These methods rely on designing a handcrafted prior that is meant to apply to all conditions, but achieving this is essentially impossible. Moreover, these methods require a backprojection operation to maintain data consistency, which can be challenging to perform accurately. In recent years, data-driven methods have demonstrated significant advantages over handcrafted priors in solving inverse problems in iterative reconstruction~\citet{bora2017compressed,chen2018learn,song2021solving}. Most of these methods require large-scale paired data to train their networks which directly project the measurement to the results and they also need to retrain while the detector geometry changes. Although~\citet{song2021solving} has addressed the above problems, they still need to know the inverse matrix of the projection matrix which is difficult to be obtained in the real-world application. Additionally, they use direct projection to replace the data-fidelity term which makes they make them need to design different sampling procedures for different detector geometries.
    
    % However, it is still a challenge problem to learn generalized prior from data for various inverse problems.
    % To address these issues, a zero-shot diffusion-based inverse solvers~\citet{song} have been proposed. This method condition the data-fidelity term on a pretrained unconditional diffusion model, enabling the use of a single model to solve various inverse problems of nature images. However, they mainly focus on solving nature image inverse problems at the pixel level and make strong assumptions about the data-fidelity term, which significantly underestimates the complexity of real-world problems. 

    The key challenge of IR is to find appropriate data prior or sparse transformation to generate the prior term. Traditional IR methods~\cite{beck2009fast,kim2016non,zhao2000x} leverage the total variation, nonlocal means, or wavelets to gain the reconstructed results by a handcrafted prior and the approximation of the inverse projection matrix. Inspired by the success of deep learning and neural network, recent data-driven methods~\cite{bora2017compressed,chen2018learn} achieve impressive performance by learning the prior and data-fidelity terms. However, most of these methods require large-scale paired data to train their networks. Besides, they directly project the measurement to the results and they also need to retrain while the detector geometry changes. Although method~\citet{song2021solving} solves these problems mentioned above by introducing a score-based generative model, it still needs to know the approximation of the inverse projection matrix which is difficult to be obtained in the real-world application. Additionally, these methods use direct projection to replace the data-fidelity term which makes they make them need to design different sampling procedures for different detector geometries.
    	
%	Data-driven methods~\citet{bora2017compressed,chen2018learn} has been proven that they have a significant advantage over the handcrafted priors. Very recently, diffusion model techniques have been introduced into compressive sensing field and achieve impressive performance. These methods~\citet{rombach2022high,saharia2022image,gao2023implicit} use conditional diffusion models to iteratively denoise the Gaussian noise to obtain the reconstructions. However these approaches are limited, since they rely on the conditional diffusion models which need paired data to train and can only handle a specific task without retraining. Thus, many zero-shot diffusion-based inverse solvers~\citet{lugmayr2022repaint,song2021solving,kawar2022denoising,chung2022diffusion,chung2022improving,wang2022zero} have proposed to address the above issues. They condition the data-fidelity term rather than the prior term which is a unconditional diffusion model pretrained on a target dataset. They make it success to utilize a single pretrained diffusion model to solve various inverse problems. However, they all focus on solving the inverse problems on the pixel-level space and they also make a strong assumption on the data-fidelity term, which significantly underestimate the complexity of real-world problem.

	
	
%	In this work, we propose Deep Latent Iterative Reconstruction (LDIR), a method that extends the traditional IR with a latent diffusion model for sparse data restoration. Through guiding the reverse diffusion sampling on the latent-level space, we offer a zero-shot tool to simultaneously generate high-resolution and multiple images with high consistency and realness. Since LDIR do not make any assumption on the data-fidelity term, we can use any measurement function to keep the data consistency even with the network-based functions (Perceptual loss~\citet{johnson2016perceptual} and LPIPS~\citet{zhang2018perceptual} or the frequency-based function~\citet{jiang2021focal}) as long as the functions are differentiable. In addition, we propose novel guidance policies which utilize the history gradient to fix the current gradient, thereby making the above zero-shot diffusion guidance method performing better. Our approach offers the community a useful zero-shot tool toward solving inverse problem with latent diffusion models, as the latent diffusion models have been a necessary component for current pretrained AIGC models.

	% In this paper, we introduce Latent Diffusion Iterative Reconstruction (LDIR), a novel zero-shot method that extends traditional IR techniques by incorporating a latent diffusion model and do not need any paired data to train network, for sparse CT data reconstruction. By guiding the reverse diffusion sampling process in the latent space without the inverse of the measurement matrix, our zero-shot method can generate high-resolution images with better performance. Since LDIR do not make any assumption on the data-fidelity term, we can use any measurement function to keep the data consistency as long as the functions are differentiable. Moreover, we propose novel guidance policies that leverage the history gradient to fix the current gradient, thereby improving the performance of our zero-shot diffusion guidance method. Our method achieves state-of-the-art performance for extremely sparse CT data reconstruction, outperforming both supervised and unsupervised learning methods. Additionally, due to the commonality of iterative reconstruction on CT images and natural images, we extend LDIR to the natural image restoration task, and our approach achieves competitive performance compared to other state-of-the-art zero-shot methods. Our approach provides a valuable zero-shot tool for solving inverse problems with latent diffusion models, allowing us to leverage the vast amount of available latent diffusion models.

 In this paper, we introduce a novel Latent Diffusion Iterative Reconstruction (LDIR) for sparse CT data reconstruction in a zero-shot manner. The LDIR is the first to extend traditional IR techniques by incorporating a latent diffusion model. Specifically, we train a latent unconditional diffusion model to learn the data distribution. In the reverse process, the trained diffusion model is utilized to replace the prior term in the regular IR. In particular, to generate specified prior from the unconditional diffusion model, the gradient from the data-fidelity term is applied to guide the sampling process of the diffusion model. Therefore, we do not need any paired data or inverse of the measurement matrix to train our network. Moreover, LDIR can solve various CT reconstruction tasks with a single model. In addition, by guiding the reverse diffusion sampling process in the latent space, our zero-shot method can generate high-resolution images with impressive performance. Since LDIR does not make any assumption on the data-fidelity term, we can use any differentiable measurement function to keep the consistency of data. Further on, we propose a novel guidance strategy to adaptively adjust the sample-level gradient by fusing the history gradient, thereby improving the performance of our zero-shot diffusion model.

 Extensive experiments demonstrate our method outperforms state-of-the-art supervised and unsupervised methods for extremely sparse CT data reconstruction. Additionally, due to the commonality of iterative reconstruction on CT images and natural images, we extend LDIR to the natural image restoration task, and our approach achieves competitive performance compared to other state-of-the-art zero-shot methods. Our approach provides a valuable zero-shot tool for solving inverse problems with latent diffusion models, allowing us to leverage the vast amount of available latent diffusion models. Fig.~\ref{fig:coverfig} shows some visual results of the proposed method.
	
	% In summary, our work makes the following \textbf{contributions}:
	
%	(i) Based on traditional iterative reconstruction process, we propose a novel iterative reconstruction method with diffusion model as a better data prior. The diffusion model do not need paired data to train, thus, our method can work as a zero-shot reconstruction method. Our method also do not need to know the inverse of the projection matrix or need to retrain the networks when the projection matrix changes. Also, we do not need to make any noise assumption on the data-fidelity term.

	% (i) In this paper, we propose a novel iterative reconstruction method that incorporates a diffusion model as a more effective data prior compared to traditional iterative reconstruction processes. Our method operates as a zero-shot reconstruction method since the diffusion model does not require paired data for training. Furthermore, our approach does not require knowledge of the inverse of the projection matrix or retraining of the networks when the projection matrix changes. Additionally, our method does not rely on any assumptions in the data-fidelity term.
	
%	(ii) To the best of our knowledge, this is the first time that zero-shot diffusion-based IR methods are extended from the pixel space to the latent space. Compared to pixel-based approaches, we significantly decrease computational costs while achieve better performance and nearly $2\times$ speed up with similar network settings. We can also restore high-resolution images by processing in the latent space.
	% (ii) To the best of our knowledge, this is the first time that zero-shot diffusion-based IR methods is extended from the pixel space to the latent space. In comparison to pixel-based approaches, our method significantly reduces computational costs while achieving better performance and nearly doubling the speed with similar network settings. Moreover, our approach can restore high-resolution images by processing in the latent space, demonstrating the effectiveness of our method.
	
	% (iii) We show that, following the huge successes of optimizers, we can leverage the history gradient information to further enhance the quality of the reconstruction results with minimal computational cost.
	
%	(iv) We achieve state-of-the-art performance on the sparse medical data reconstruction over other supervised learning and unsupervised learning competitors. Additionally, on the nature image restoration task (super-resolution), we achieve the competitive performance with other state-of-the-art zero-shot methods.
	
	% (iv) Our method achieves state-of-the-art performance for sparse medical data reconstruction, outperforming both supervised and unsupervised learning methods. Additionally, we extend LDIR to nature image restoration task, and our approach achieves competitive performance compared to other state-of-the-art zero-shot methods.
	
	\section{Background}
	
	\subsection{Diffusion models}
	Consider a $T$-step Gaussian diffusion process, where $x_t \in \mathbb{R}^n, t\in[0,\dots,T-1]$ and initial $x_0$ is sampled from the original data distribution $P_{data}$. We define the forward diffusion process using stochastic differential equation (SDE)~\citet{song2021scorebased}:
	\begin{align}
		dx = f\left(x,t\right) \, dt + g\left(t\right) \, dw,
		\label{eq:forward_sde}
	\end{align}
	where $f\left(\cdot,t\right): \, \mathbb{R}^d \to \mathbb{R}^d$ is a drift coefficient function, $g\left(t\right) \in \mathbb{R}$ is defined as a diffusion coefficient function, and $w \in \mathbb{R}^n$ is a standard $n$-dimensional Brownian motion. Thus, the reverse SDE of Eq.~\eqref{eq:forward_sde} can also defined as:
	\begin{align}
		dx = \left[f\left(x,t\right)-g\left(t\right)^2\nabla_x \log p_t\left(x\right)\right] \, dt + g\left(t\right) \, dw,
		\label{eq:reverse_sde}
	\end{align}
	where $dt$ is a negative infinitesimal time step. The reverse SDE defines a generative process that transforms standard Gaussian noise into meaningful content. To accomplish this transformation, the score function $\nabla_x \log p_t\left(x\right)$ needs to be matching, which is typically replaced with $\nabla_x \log p_{0 | t}\left(x_t \middle| x_0\right)$ in practice. Therefore, we can train a score model $s_\theta\left(x,t\right)$, so that $s_\theta\left(x,t\right) \approx \nabla_x \log p_t\left(x\right) \approx \nabla_x \log p_{0 | t}\left(x_t \middle| x_0\right)$ using the following score-matching objective:
	\begin{align}
		\label{eq:sde_objective}
		\min_\theta \mathbb{E}_{t \in \left[0,\dots,T-1\right], x_0 \sim P_{data}, x_t \sim p_{0|t}\left(x_t \middle| x_0 \right)}\left[ \left|\left| s_\theta\left(x,t\right)-\nabla_x \log p_{0|t}\left(x_t \middle| x_0 \right) \right|\right| _2^2\right] \, .
	\end{align}
	Therefore, the reverse SDE can yield meaningful contents $x_0 \sim P_{data}$ from random noises $x_{T-1} \sim \mathcal{N}\left(0, \mathbf{I}\right)$ by iteratively using $s_\theta \left(x,t\right)$ to estimate the scores $\nabla_x \log p_t\left(x\right)$. In our experiments, we adopt the standard Denoising Diffusion Probabilistic Models (DDPM)~\citet{ho2020denoising} which is equivalent to the above variance preserving SDE (VP-SDE~\citet{song2021scorebased}).
	
	\subsection{Diffusion model for inverse problem solving}
	To solve the inverse problems using the diffusion model, various workarounds are proposed~\citet{rombach2022high,saharia2022image,gao2023implicit,luo2023image}. These methods use conditional diffusion models to iteratively denoise Gaussian noise and obtain reconstructions. However, these approaches have limitations, as they rely on conditional diffusion models that require paired data for training and can only handle specific tasks without retraining. To address these issues, several zero-shot diffusion-based inverse solvers~\citet{lugmayr2022repaint,song2021solving,kawar2022denoising,chung2022improving,wang2022zero} have been proposed. Typically, assuming $n \equiv 0 $, for each denoising step, they~\citet{lugmayr2022repaint,song2021solving,wang2022zero} unconditionally estimate new denoised samples based on the previous step, followed by replacing the corresponding items in the denoised samples using the measurement $\mathbf{A}^{-1}y$, which is also known as range-null space decomposition~\citet{wang2022zero}. This approach ensures data consistency, but it fails in the case of noisy measurements, since $\mathbf{A}^{-1}y$ is not a correct corresponding item for the denoised samples. To address this limitation, alternative methods~\citet{chung2022diffusion,chung2022parallel} have been proposed to solve the inverse problems with noised measurements. Rather than directly replace items, these approaches use the gradient of $\left|\left|y-\mathbf{A}x\right|\right|_2^2$ to conditionally guide the generative process. These methods are robust to noise and can process nonlinear projection operators. However, these methods try to solve inverse problems on the pixel space and make strong assumptions on the data-fidelity term, which significantly underestimates the complexity of real-world problems and can not reconstruct high-resolution results.
	
	\section{Method}
	
	\subsection{Diffusion iterative reconstruction}
	Generally, it is possible to transform the IR methods presented in Eq.~\eqref{eq:ir_formualtion} into a more generic form:
	\begin{align}
		\hat{x} &=\argminA_x E\left(x\right) \\
		&= \argminA_x \mathcal{U}\left(\mathbf{A}x, y\right) + \lambda R\left(x\right),
		\label{eq:generic_ir_form}
	\end{align}
	where $\mathcal{U}$ is a measurement function that ensures data consistency. Assuming that both the measurement function and prior term are differentiable, it is possible to apply gradient descent to Eq.~\eqref{eq:generic_ir_form}. This yields an ordinary differential equation (ODE) for iterative reconstruction:
	\begin{align}
		x_{t-1} &= x_t - \frac{\partial E\left(x\right)}{\partial x_t} \\
		&= x_t - \left(\epsilon \nabla_{x_t} \, \mathcal{U}\left(\mathbf{A}x_t, y\right) + \lambda_t \, \nabla_{x_t} \, R\left(x_t\right)\right),
		%	dx = - \nabla_{x_t} \, \mathcal{D}(\mathbf{A}x_t, y) - \lambda \, \nabla_{x_t} \, R(x_t)
		%	        & = (x_t - \lambda \, \nabla_{x_t} \, R(x_t)) - \nabla_{x_t} \, \mathcal{D}(\mathbf{A}x_t, y).
	\end{align}
	 where guidance rate $\epsilon$ and $\lambda_t$ are used to balance the consistency and realness. In practice, we can replace $\lambda \, \nabla_{x_t} \, R\left(x_t\right)$ with a step-dependent prior function $\lambda_t \, \nabla_{x_t} \, R\left(x_t, t\right)$ to balance realness and data consistency, as demonstrated by~\citet{chen2018learn}:
	\begin{align}
		x_{t-1} = \left(x_t - \lambda_t \, \nabla_{x_t} \, R\left(x_t, t\right)\right) - \epsilon \nabla_{x_t} \, \mathcal{U}\left(\mathbf{A}x_t, y\right).
%		\label{eq:generic_ir_form}
	\end{align}
%	Since $R(x_t, t)$ denotes the distribution $p_t$ transformed from the original distribution $p_{data}$ at step $t$, we can rewrite the above equation as:
%	The aim of the regularization term is to ensure that  Since the goal of $R(x_t, t)$ is to ensure that $\hat{x} \sim p(x)$, in fact, we can use $p(x)$ to replace the regularization term for more precise:
%	Since the score function is a powerful tool to represent a probability distribution~\citet{song2021scorebased} which does not require to make the normalizing constant tractable or be approximated, we can use the score function to estimate $p(x)$. By replacing the regularization term $\nabla_{x_t} \, R(x_t, t)$ with the score function $\nabla_{x_t} \, \log p_t(x)$, we can ensure that our new regularization term can represent the precise probability distribution without heavy computation:
	As demonstrated by~\citet{song2021scorebased}, the score function is a powerful tool for representing probability distributions. The score function does not require the computation of a tractable normalizing constant or its approximation. This makes it possible to estimate $\log p\left(x\right)$ using the score function. By replacing the prior term $\nabla_{x_t} \, R\left(x_t, t\right)$ with the score function $\nabla_{x_t} \, \log p_t\left(x\right)$, it is possible to ensure that the new prior term accurately represents the probability distribution without requiring heavy computation:
	\begin{align}
		x_{t-1} = \left(x_t - \lambda_t \, \nabla_{x} \, \log p_t\left(x\right)\right) - \epsilon \nabla_{x_t} \, \mathcal{U}\left(\mathbf{A}x_t, y\right),
	\end{align}
%	According to~\cite{song2021scorebased} and Eq.~\ref{eq:sde_objective}, we can use $s_\theta(x, t)$ to approximate $\nabla_{x} \, \log p_t(x)$ and replace it, given by:
%	where $\nabla_{x} \, \log p_t(x)$ is exactly the score function in the score model, thus, we can use $s_\theta(x_t, t)$ to approximate it with the objective equation of Eq.~\ref{eq:sde_objective}:
	In Eq.~\eqref{eq:sde_objective}, we can use a score model $s_\theta\left(x_t, t\right)$ to approximate $\nabla_{x_t} \, \log p_t\left(x\right)$ using the score matching technique:
	\begin{align}
		x_{t-1} \simeq \left(x_t - \lambda_t \, s_\theta\left(x_t, t\right)\right) - \epsilon \nabla_{x_t} \, \mathcal{U}\left(\mathbf{A}x_t, y\right).
		\label{eq:dir_ode}
	\end{align}
	% The first term $x_t - \lambda_t \, s_\theta(x,t)$ is qualitatively similar to Eq.~\eqref{eq:reverse_sde}, when $f(x_t, t) = g(t)z = 0$ and $g(t)^2 = \lambda_t$.\footnote{This equation is also known as \textit{probability flow ODE} in~\citet{song2021scorebased}} According to~\citet{song2021scorebased}, we can utilize the reverse sampling process in Eq.~\eqref{eq:reverse_sde} to replace the prior term in Eq.~\eqref{eq:dir_ode} for better generative performance:
    In fact, the first term $x_t - \lambda_t \, s_\theta\left(x,t\right)$ is Eq.~\eqref{eq:reverse_sde} with a noise-free constraint~\footnote{$f\left(x_t, t\right) = g\left(t\right)z = 0$ and $g\left(t\right)^2 = \lambda_t$}. Thus, we can relax the noise-free constraint and use Eq.~\eqref{eq:reverse_sde} to replace this term:
	\begin{align}
%		x_{t-1} &\simeq (x_t - f(x_t,t) - g(t)^2 s_\theta(x_t,t) + g(t)z) - \nabla_{x_t} \, \mathcal{U}(\mathbf{A}x_t, y), z \sim \mathcal{N}(0,\mathbf{I}). \\
		x_{t-1} \simeq x_t - \underbrace{\left(\lambda_t \, s_\theta\left(x_t,t\right) - g\left(t\right)z\right)}_{\text{Prior term}} - \underbrace{ \epsilon \nabla_{x_t} \, \mathcal{U}\left(\mathbf{A}x_t, y\right)}_{\text{Data-fidelity term}}, z \sim \mathcal{N}\left(0,\mathbf{I}\right).
		\label{eq:dir_sde}
	\end{align}
	We propose a new iterative reconstruction method called Diffusion Iterative Reconstruction (DIR). The model uses a score model to represent the original data distribution and employs it as a learned prior. Algo.~\ref{algo:pixel_sampling} demonstrates the pixel guidance process of DIR.
	% TODO: Add iteration figures with step in manuscript or appendix.
	
	It is worth noting that our DIR has a mathematical form that is similar to the approach proposed by~\citet{chung2022diffusion}. However, our approach is more general and can be applied to a wider range of scenarios. Diffusion Posterior Sampling (DPS)~\citet{chung2022diffusion} models the data consistency term $\mathcal{U}\left(\cdot, \cdot\right)$ as a noise measurement problem. The evaluation function for the data-fidelity term is derived \textbf{based on the prior assumption} of the noise distribution (such as the $L2$ function for Gaussian noise). This approach works well when the noise type is known in the measurement process. However, it is challenging to estimate the noise distribution and derive the correct evaluation function in real-world applications. In contrast, our DIR models the data-fidelity term as a quality evaluation function \textbf{without any assumptions} about the noise distribution. Thus, the evaluation function $\mathcal{U}\left(\cdot, \cdot\right)$ can be any differentiable evaluation function, allowing for more flexibility.
 
 \begin{minipage}[!h]{0.48\textwidth}
		\begin{algorithm}[H]
			\caption{Pixel-space data reconstructing}
			\label{algo:pixel_sampling}
			\begin{algorithmic}[1]
				\Require: $N, y$ 
				\State $x_T \sim \mathcal{N}$
				\For $\left\{ i = T - 1, \dots, 0 \right\}$
				\State $\hat{s} \gets s_\theta\left(x_i, i\right)$
				\State $x_{0|i}  \gets \frac{1}{\sqrt{\bar{\alpha}_i}} \left(x_i + \left(1-\bar{\alpha}_i\right)\hat{s}\right)$
				\State $z \sim \mathcal{N}\left(0,\mathbf{I}\right)$
				\State $x'_{i-1} \gets \frac{\sqrt{\bar{\alpha}_{i-1}}\beta_i}{1-\bar{\alpha}_i}x'_{0|i}+\frac{\sqrt{\alpha_i}\left(1-\bar{\alpha}_{i-1}\right)}{1-\bar{\alpha}_i}x_i+g\left(i\right)z$
				\State $x_{i-1} \gets x'_{i-1} - \epsilon \nabla_{x_i} \, \mathcal{U}\left(\mathbf{A}x'_{i-1}, y\right)$
				\EndFor \\
				\Return $x_{0|0}$
			\end{algorithmic}
		\end{algorithm}
	\end{minipage}
	\hspace{0.04\textwidth}
	\begin{minipage}[!t]{0.48\textwidth}
		\begin{algorithm}[H]
			\caption{Latent-space data reconstructing}
			\label{algo:latent_sampling}
			\begin{algorithmic}[1]
				\Require: $N, y, \mathcal{D}$ 
				\State $\ell_T \sim \mathcal{N}$
				\For$\left\{i = T - 1, \dots, 0\right\}$
				\State $\hat{s} \gets s_{\theta_l}\left(\ell_i, i\right)$
				\State $\ell_{0|i}  \gets \frac{1}{\sqrt{\bar{\alpha}_i}} \left(\ell_i + \left(1-\bar{\alpha}_i\right)\hat{s}\right)$
				\State $z \sim \mathcal{N}\left(0,\mathbf{I}\right)$
				\State $\ell'_{i-1} \gets \frac{\sqrt{\bar{\alpha}_{i-1}}\beta_i}{1-\bar{\alpha}_i}\ell'_{0|i}+\frac{\sqrt{\alpha_i}\left(1-\bar{\alpha}_{i-1}\right)}{1-\bar{\alpha}_i}\ell_i+g\left(i\right)z$
				\State $\ell_{i-1} \gets \ell'_{i-1} - \epsilon \nabla_{\ell_i} \, \mathcal{U}(\mathbf{A}\mathcal{D}\left(\ell'_{i-1}), y\right)$
				\EndFor
				\State $x_{0|0} \gets \mathcal{D}\left(\ell_{0|0}\right)$ \\
				\Return $x_{0|0}$
			\end{algorithmic}
		\end{algorithm}
	\end{minipage}
 
    \subsection{History gradient update}
	\label{sec:hgu}
	In what follows, we show that introducing history gradient update policies can provide better reconstruction results. The basic formulation of gradient guidance in Eq.~\eqref{eq:dir_sde} corresponds to a simple gradient descent scheme. The guidance rate $\epsilon$ can be thought of as the learning rate value in the Stochastic Gradient Descent (SGD). Thus, in order to further improve the data consistency, we adopt gradient information from the previous steps. Because the history gradient information can provide sample-level information to decide the optimization direction of the guidance process. This is also known as the \textit{first-order} gradient-based optimization. Here, we demonstrate two variants of gradient update policies based on two typical optimizers.
	
	\textbf{Momentum-like gradient update policy. } Similar to the Momentum optimizer~\citet{sutskever2013importance}, we consider to use the moving averages $m^t$ of the gradients $\nabla_{x_t} \mathcal{U}\left(\mathbf{A}x_t, y\right)$ to perform gradient descent:
	\begin{align}
		m^{t} &= \eta m^{t-1} + \left(1 - \eta\right) \nabla_{x_t} \mathcal{U}\left(\mathbf{A}x_t, y\right), \\ 
		x_{t-1}  &= x_t - \epsilon m^{t},
	\end{align}
	where $\eta$ is a hyper-parameter to adjust the factor of momentum. 
	
	\textbf{Adam-like gradient update policy. } Adam optimizer~\citet{kingma2014adam} uses momentum and adaptive learning rate to perform gradient descent:
	\begin{align}
		m^{t} &= \eta_1 m^{t-1} + \left(1 - \eta_1\right) \nabla_{x_t} \mathcal{U}\left(\mathbf{A}x_t, y\right), \\ 
		v^{t} &= \eta_2 v^{t-1} + \left(1 - \eta_2\right) \nabla_{x_t} \mathcal{U}\left(\mathbf{A}x_t, y\right)^2, \\
		%	\hat{m}^t &= \frac{m^{t}}{1-\eta_1}, \, \hat{v}^t = \frac{v^t}{1-\eta_2}, \\
		x_{t-1}  &= x_t - \epsilon \frac{\hat{m}^t}{\sqrt{\hat{v}^t} + \varepsilon},
	\end{align}
	where $\left(\eta_1, \eta_2\right)$ are the coefficients used to calculate the exponentially weighted moving averages of gradient and its square, while $\varepsilon$ helps improve the numerical stability. With the help of the moving averages $m^t$ and $v^t$, we can efficiently locate the flat minima.

    % Figure environment removed
 
	It is worth noting that the choice of $\epsilon$ and gradient policy is dependent on the evaluation function $\mathcal{U}$ (Details and ablation studies can be found in Appendix.~\hyperref[ablation_func]{C}). Our gradient update policies are compatible with DIR, LDIR, and DPS whether on pixel space or latent space. The details are demonstrated in the ablation studies. The detail of LDIR algorithms with the above gradient update policies are presented in Appendix~\hyperref[app:LDIR_hgu]{A}.

%	We find that the previous works~\citet{chung2022diffusion,chung2022improving,chung2022parallel,chung2022solving,song2021solving,wang2022zero} all perform data restoration on the pixel space, which causes huge demands in computation. Thus, based on previous works of Latent Diffusion Models (LDM)~\citet{rombach2022high} and our DIR, we propose a novel data restoration diffusion model named Deep Latent Iterative Reconstruction (LDIR). This approach offers us several advantages: (i) Instead of processing images in the pixel space, we can encode high-resolution images into a low-dimensional space and process them at the same time with less computation. (ii) Compared to the pixel space, the latent space contains much higher information density so that we can ensure the data are conform to some natural priors, e.g., sparsity.

    \subsection{Latent diffusion iterative reconstruction}
    
	Our review of previous works on diffusion-based data reconstruction, including~\citet{chung2022diffusion,chung2022improving,chung2022parallel,chung2022solving,song2021solving,wang2022zero}, reveals that they all perform reconstruction in the pixel space, which requires significant computational resources. To address this limitation, we draw inspiration from the Latent Diffusion Models (LDMs) proposed by~\citet{rombach2022high} and our DIR. We introduce a novel data reconstruction diffusion model called Latent Diffusion Iterative Reconstruction (LDIR). LDIR offers several advantages over previous methods: (i) Instead of processing images in the pixel space, we encode images into a low-dimensional latent space, enabling us to process them more efficiently with fewer computational demands. (ii) The latent space contains significantly higher information density compared to the pixel space, allowing us to incorporate natural priors such as sparsity and improve the quality of the restored data.
	
	\textbf{From pixels to latents. } 
	To encode pixels to latents, we construct an autoencoder comprising an encoder $\mathcal{E}$ and a decoder $\mathcal{D}$. Specifically, given an input image $x$ in the pixel space, $\mathcal{E}$ maps $x$ to a low-dimensional latent vector $\ell = \mathcal{E}\left(x\right)$. $\mathcal{D}$ reconstructs the image $\bar{x} = \mathcal{D}\left(\mathcal{E}\left(x\right)\right)$ from $\ell$. To incorporate the sparsity prior of $x$, we use the \textit{Vector Quantized Variational Autoencoder} (\textit{VQ-VAE}) proposed by ~\citet{kingma2013auto,rezende2014stochastic,esser2021taming} with the quantization layer~\citet{van2017neural}.
%	As mentioned above, we need to construct an autoencoder to encode pixels to latents. Without loss of generality, given an image $x$ in pixel space, the encoder $\mathcal{E}$ maps $x$ to a low-dimensional latent $l=\mathcal{E}(x)$, and the decoder $\mathcal{D}$ reconstructs the image $\bar{x} = \mathcal{D}(\mathcal{E}(x))$ from $l$. To conform the sparsity prior of $x$, we use \textit{VQ}-VAE~\citet{kingma2013auto,rezende2014stochastic,esser2021taming} with the quantization layer~\citet{van2017neural}.
    
	\textbf{Score matching for latents. } With our semantic compression model $\mathcal{E}$ and $\mathcal{D}$, we can now establish the score of latents $\nabla_\ell \, \log p_t\left(\ell\right)$ and use score model $s_{\theta_\ell}$ to approx it with the following objective:
	\begin{align}
		\label{eq:latent_sde_objective}
		\min_\theta \mathbb{E}_{t \in \left[0,\dots,T-1\right], \ell_0 \sim p_{\ell}, \ell_t \sim p_{0|t}\left(\ell_t \middle| \ell_0 \right)}\left[\left|\left|s_{\theta_\ell}\left(\ell,t\right)-\nabla_\ell \log p_{0|t}\left(\ell_t \middle| \ell_0 \right)\right|\right|_2^2\right],
	\end{align}
	where $p\left(\ell\right) = p\left(\mathcal{E}\left(x\right)\right)$ and $x \sim p\left(x\right)$.
 
	\textbf{Conditional guidance process on the latent space. } Similar to the conditional guidance process in the pixel space, we begin by using the score model $s_{\theta_\ell}$ to generate latents from standard Gaussian noise:
	\begin{align}
		\ell'_{t-1} = \ell_t - f\left(\ell,t\right) - g\left(t\right)^2 s_{\theta_\ell}\left(\ell,t\right) + g\left(t\right)z, z \sim \mathcal{N}\left(0,\mathbf{I}\right),
	\end{align}
	We need to use $\mathcal{D}$ to decode $\ell$ to pixel space, and compute the data consistency term $\mathcal{U}\left(\mathbf{A}\mathcal{D}\left(\ell\right), y\right)$, which can be derived to:
	\begin{align}
		\ell_{t-1} = \ell'_{t-1} -  \epsilon \nabla_{\ell_t} \, \mathcal{U}\left(\mathbf{A}\mathcal{D}\left(\ell_t\right), y\right).
	\end{align}
	Thus, we can get the conditional guidance algorithm of LDIR as:
	\begin{align}
		\ell_{t-1} \simeq \ell_t - \underbrace{\left(\lambda_t \, s_{\theta_\ell}\left(\ell_t,t\right) - g\left(t\right)z\right)}_{\text{Prior term}} - \underbrace{ \epsilon \nabla_{\ell_t} \, \mathcal{U}\left(\mathbf{A}\mathcal{D}\left(\ell_t\right), y\right)}_{\text{Data-fidelity term}}, z \sim \mathcal{N}\left(0,\mathbf{I}\right).
		\label{eq:LDIR_sde}
	\end{align}
	The final results can be obtained by decoding the final latent $x_0 = \mathcal{D}\left(\ell_0\right)$ using the decoder $\mathcal{D}$.
%	It should be noted that some methods relied on range-null space decomposition are not compatible with the latent generative process. Because, they use $\mathbf{A}^{-1}$ to projection the difference $y - \mathbf{A}\mathcal{D}(x_{0|t})$ to update the latents which may be inconsistent with $\mathcal{E}$, \textit{i.e.,} $\mathbf{A}^{-1}(y - \mathbf{A}\mathcal{D}(x_{0|t})) \nsim p(x)$. 
	
	\section{Experiments}
	
    \subsection{Experimental setup}
	 \textbf{Models and datasets.} For medical image reconstruction, we train our DDPM and LDM model on the 2016 American Association of Physicists in Medicine (AAPM) grand challenge dataset. The dataset has normal-dose data from 10 patients. 9 patientsâ€™ data are used for training, and 1 for validation which contains 526 images. To simulate low-dose imaging, a parallel-beam imaging geometry with 180 degrees was employed. Regarding inpainting and super-resolution tasks, we test our method on CelebAHQ 1k $256\times256$ dataset~\citet{liu2015faceattributes} and LSUN-bedroom $256\times256$ dataset~\citet{yu2015lsun}. We utilize pretrained DDPM and LDM models from the open-source model repository from~\citet{ho2020denoising,rombach2022high}. All the images are normalized to range $\left[0,1\right]$. More details including the hyper-parameters are listed in Appendix.~\hyperref[app:experiment]{B}.
	 
	 \textbf{Measurement operators.} For sparse-view CT reconstruction, we uniformly sample 18 and 32 views. For limited-angle CT reconstruction, we restrict the imaging degree range to $45$ and $90$ degrees with 128 views using parallel beam geometry. For random inpainting, following~\citet{chung2022improving,chung2022diffusion}, we mask out $99\%$ of the total pixels (including all the channels). For super-resolution, we use $8\times$ bilinear downsampling. Gaussian noise is added in the nature image evaluation after a forward operation performed with $\sigma=0.05$. The medical data are evaluated without noise.

    % Figure environment removed

 \begin{table}[t]
		
		\centering
        \caption{Quantitative evaluation (PSNR, SSIM) of medical image reconstruction on AAPM test $256\times256$ dataset. We mark \textbf{bold} for the best and \underline{underline} for the second best. CLEAR~\citet{zhang2021clear} is a supervised method.}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{@{\extracolsep{4pt}}lcccccccc@{}}
				\toprule
				\multicolumn{1}{l}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{4}{c}{\textbf{Sparse view}}                 & \multicolumn{4}{c}{\textbf{Limited angle }}   \\ \cmidrule{2-5} \cmidrule{6-9} & \multicolumn{2}{c}{18} & \multicolumn{2}{c}{32} & \multicolumn{2}{c}{45} & \multicolumn{2}{c}{90} \\ \cmidrule{2-3} \cmidrule{4-5} \cmidrule{6-7} \cmidrule{8-9} 
				\multicolumn{1}{c}{}  & PSNR $\uparrow$      & SSIM $\uparrow$     & PSNR $\uparrow$      & SSIM $\uparrow$     & PSNR $\uparrow$      & SSIM $\uparrow$     & PSNR $\uparrow$      & SSIM $\uparrow$  \\ \midrule
				FBP                                         &     24.76       &    0.5296       &     28.03       &     0.6779      &      16.65      &      0.5422     &      20.35      &     0.5113      \\
				FISTA-TV                                    &     24.86       &     0.5408      &      28.14      &      0.6888     &     16.66       &     0.5463      &    20.40        &    0.5241      \\
				CLEAR                                       &     \underline{32.28}      &     \underline{0.8798}     &      \underline{36.24}      &     \underline{0.9257}      &     25.71       &      \underline{0.8559}     &       \underline{31.60}     &    \textbf{0.9223}      \\
				MCG                                         &      28.54      &  0.8135         &     28.98       &     0.8242     &      26.08      &     0.7418      &     28.44      &     0.8079     \\
				DPS   & 28.55 & 0.8140 & 28.97 & 0.8242 & \underline{28.25} & 0.8204 & 28.25 & 0.8088 \\ \midrule
				LDIR  & \textbf{39.01} & \textbf{0.9552} & \textbf{39.77} & \textbf{0.9612} & \textbf{30.05} & \textbf{0.8747} & \textbf{32.68} & \underline{0.9032} \\ \bottomrule
			\end{tabular}%
		}
		
		\label{tab:ct_images_256}
	\end{table}
	
	\begin{table}[h]
		\centering
        \caption{Quantitative evaluation (PSNR, SSIM) of medical image reconstruction on AAPM test $512\times512$ dataset for zero-shot methods. We mark \textbf{bold} for the best and \underline{underline} for the second best.}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{@{\extracolsep{4pt}}lcccccccc@{}}
				\toprule
				\multicolumn{1}{c}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{4}{c}{\textbf{Sparse view}}                 & \multicolumn{4}{c}{\textbf{Limited angle }}   \\ \cmidrule{2-5} \cmidrule{6-9} & \multicolumn{2}{c}{18} & \multicolumn{2}{c}{32} & \multicolumn{2}{c}{45} & \multicolumn{2}{c}{90} \\ \cmidrule{2-3} \cmidrule{4-5} \cmidrule{6-7} \cmidrule{8-9} 
				\multicolumn{1}{c}{}  & PSNR $\uparrow$       & SSIM $\uparrow$     & PSNR $\uparrow$      & SSIM $\uparrow$     & PSNR $\uparrow$      & SSIM $\uparrow$     & PSNR $\uparrow$      & SSIM $\uparrow$  \\ \midrule
				FBP                                         &      23.48      &     0.5096      &     26.70       &     0.6423      &     16.53       &     0.5480      &     19.88       &     0.4932      \\
				FISTA-TV                                    &     \underline{23.93}       &     \underline{0.5566}      &     \underline{27.11}       &     \underline{0.6768}      &      \underline{16.59}      &    \underline{0.5695}       &     \underline{20.08}       &     \underline{0.5348}     \\ \midrule
				LDIR                                        &     \textbf{27.30}       &    \textbf{0.8443}       &      \textbf{27.33}      &      \textbf{0.8441}     &      \textbf{26.18}      &     \textbf{0.8355}      &       \textbf{26.70}     &     \textbf{0.8381}     \\ \bottomrule
			\end{tabular}%
		}
		\label{tab:ct_images_512}
	\end{table}
	\subsection{Evaluation on medical data}
 
	To assess the performance of LDIR in reconstructing medical sparse data, we compare it with several recent state-of-the-art methods: manifold constrained gradients (MCG)~\citet{chung2022improving}, diffusion posterior sampling (DPS)~\citet{chung2022diffusion}, comprehensive learning enabled adversarial reconstruction (CLEAR)~\citet{zhang2021clear}, fast iterative shrinkage-thresholding algorithm with total-variation (FISTA-TV), and the analytical reconstruction method, filtered backprojection (FBP). Peak-signal-to-noise-ratio (PSNR) and structural similarity index measure (SSIM) are used for quantitative evaluation. 
	
	The quantitative results of medical sparse data reconstruction are demonstrated in Tab.~\ref{tab:ct_images_256} and Tab.~\ref{tab:ct_images_512}. Our method outperforms all other state-of-the-art methods by a significant margin across all experiment settings. We also compare our method in the high-resolution CT image reconstruction task with zero-shot methods. However, due to the large memory consumption of DDPM, it is challenging to train DDPM models for high-resolution reconstruction. Thus, we exclude MCG and DPS which rely on DDPM from Tab.~\ref{tab:ct_images_512}. The results show that LDIR provides noise-free reconstruction results, although there is still a significant gap between the reconstructed images and the ground truth. In contrast, other zero-shot methods fail to reconstruct meaningful results. 
	
	% % Figure environment removed
	
	The qualitative results of medical sparse image reconstruction are demonstrated in Fig.~\ref{fig:mayo256vis} which are consistent with the quantitative results reported in Tab.~\ref{tab:ct_images_256}. In Fig.~\ref{fig:mayo256vis}, we compare our method with the state-of-the-art zero-shot unsupervised and supervised methods. We observe that our method can provide high-quality reconstructions, especially for the sparse view reconstruction task. Specifically, LDIR can provide better overall structure and nearly artifact-free reconstruction. Additionally, our method also provides better reconstructions than other methods in limited angle reconstruction tasks. (More qualitative results of medical sparse data reconstruction can be found in Appendix.~\hyperref[app:medical]{D}).

    % Figure environment removed

 \begin{table}[t]
		\centering
        % åŠ è¯´æ˜Ž
        \caption{Quantitative evaluation (PSNR, SSIM, LPIPS) of nature image reconstruction on CelebAHQ and LSUN-bedroom dataset. We mark \textbf{bold} for the best and \underline{underline} for the second best.}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{@{\extracolsep{4pt}}lccccccccccccc@{}}
				\toprule
				\multicolumn{1}{c}{\multirow{3}{*}{\textbf{Method}}}     & \multirow{3}{*}{\textbf{Type}}                                      & \multicolumn{6}{c}{\textbf{CelebAHQ}}                           & \multicolumn{6}{c}{\textbf{LSUN-bedroom}}                             \\ \cmidrule{3-8} \cmidrule{9-14}
				\multicolumn{2}{c}{}                                                                   & \multicolumn{3}{c}{\textbf{Inpaint}} & \multicolumn{3}{c}{\textbf{SR (8$\times$)}} & \multicolumn{3}{c}{\textbf{Inpaint}} & \multicolumn{3}{c}{\textbf{SR (8$\times$)}} \\ \cmidrule{3-5} \cmidrule{6-8} \cmidrule{9-11} \cmidrule{12-14}
				\multicolumn{2}{c}{}                                                                    & PSNR $\uparrow$    & SSIM $\uparrow$   & LPIPS $\downarrow$   & PSNR $\uparrow$  & SSIM $\uparrow$  & LPIPS $\downarrow$ & PSNR $\uparrow$    & SSIM $\uparrow$   & LPIPS $\downarrow$  & PSNR $\uparrow$ & SSIM $\uparrow$ & LPIPS $\downarrow$ \\ \midrule
				PnP-ADMM &       Traditional IR                                                 &    3.97     &     0.3017    &    0.8916     &   22.94    &   0.6303    &    0.6820    &    5.059     &    0.3236     &    0.8940     &    \textbf{20.14}   &   0.5458    &    0.7944    \\
				MCG      & Pixel Diffusion                                                          &    18.91     &     0.5600    &    0.2544     &    12.47   &   0.1655    &   0.6713     &     16.89    &    0.4555     &    0.5486     &    9.39   &    0.0606   &   0.8698     \\
				DPS          & Pixel Diffusion                                                      &    \underline{18.95}     &     \underline{0.5614}    &    \underline{0.2543 }    &   \underline{24.36}    &    \underline{0.7116}   &   \underline{0.1089}     &     \underline{17.03}    &    \underline{0.4587}     &    \underline{0.5414}     &   19.15    &    \underline{0.5614}   &    \textbf{0.3074}    \\ \midrule
				LDIR         & Latent Diffusion                                                      &    \textbf{22.14}     &     \textbf{0.6647 }   &     \textbf{0.2280}    &   \textbf{25.27}    &    \textbf{0.7530}   &     \textbf{0.0878}   &    \textbf{20.33}     &    \textbf{0.5845}     &   \textbf{0.4858}      &   \underline{19.83}    &    \textbf{0.5762}   &    \underline{0.3253}    \\
				\bottomrule
			\end{tabular}%
		}
		\label{tab:nature_images}
	\end{table}
	
	\subsection{Evaluation on nature images}
	In order to further test the performance of our method, we compare our method against state-of-the-art methods, namely, MCG, DPS, and plug-and-play alternating direction method of multipliers (PnP-ADMM)~\citet{chan2016plug}. For quantitative analysis, we utilize three widely-used perceptual evaluation metrics: LPIPS distance, PSNR, and SSIM.
	
	The quantitative results of nature image reconstruction are illustrated in Tab.~\ref{tab:nature_images}. Our method achieves competitive results compared to the previous state-of-the-art. Specifically, we observe that our method is able to accurately reconstruct the original data and preserve the most data consistency, even when dealing with highly sparse measurements such as $99\%$ random inpainting. Additionally, we note that LDIR gains some advantages over the previous best method on the super-resolution task. 
    % This is likely due to the high information density of the super-resolution task, which provides enough information for all methods to reconstruct the original data, making the advantage of LDIR in recovering extremely sparse data less pronounced.
	
	The qualitative results of nature sparse image reconstruction are demonstrated in Fig.~\ref{fig:naturevis}. Notably, the traditional iterative method PnP-ADMM failed to produce satisfactory results for both the inpainting and super-resolution tasks due to its limited prior terms. In contrast, our method outperforms the comparison methods, particularly in terms of color and structure in the inpainting task.  In the super-resolution task, the results obtained by MCG exhibit many artifacts, which are likely due to the projection step\citet{chung2022diffusion}. Our method, on the other hand, achieves competitive results with DPS, the most advanced method, with small gaps. (More qualitative results of nature sparse image reconstruction can be found in Appendix.~\hyperref[app:nature]{E}).

    \begin{table}[t]
        % add pixel and latent 
        \centering
        \caption{Ablation evaluation (PSNR, SSIM) on the effect of latent-based iterative reconstruction. We mark \textbf{bold} for the best and \underline{underline} for the second best. DPS~\citet{chung2022diffusion} is a special case of DIR where $\mathcal{U}\left(\cdot\right) \triangleq \left|\left|\cdot\right|\right|_2 $ and use naive gradient update policy.}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{@{\extracolsep{4pt}}lccccccccccc@{}}
				\toprule
				\multicolumn{1}{c}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{1}{c}{\multirow{3}{*}{\textbf{Type}}} & \multicolumn{4}{c}{\textbf{Sparse view}}                                     & \multicolumn{4}{c}{\textbf{Limited angle}}                 & \multicolumn{1}{c}{\multirow{3}{*}{\textbf{Speed(iter/s) $\uparrow$ }}} & \multicolumn{1}{c}{\multirow{3}{*}{\textbf{Memory(MB) $\downarrow$}}}                  \\ \cmidrule{3-6} \cmidrule{7-10} 
				\multicolumn{2}{c}{}                        & \multicolumn{2}{c}{18}           & \multicolumn{2}{c}{32}           & \multicolumn{2}{c}{45}           & \multicolumn{2}{c}{90}       \\ \cmidrule{3-4} \cmidrule{5-6} \cmidrule{7-8} \cmidrule{9-10} 
				\multicolumn{2}{c}{}                        & PSNR $\uparrow$          & SSIM $\uparrow$           & PSNR $\uparrow$          & SSIM $\uparrow$           & PSNR $\uparrow$          & SSIM $\uparrow$           & PSNR $\uparrow$          & SSIM $\uparrow$           \\ \midrule
				DPS        & Pixel Diffusion                                 & 28.55          & 0.8140          & 28.97          & 0.8242          & \underline{28.25}    & \underline{0.8204}    & 28.25          & 0.8088  & \underline{20.88} & \underline{6338}        \\ \midrule
				DIR  (Ours)    & Pixel Diffusion                                   & \underline{31.45}    & \underline{0.8654}    & \underline{32.82}    & \underline{0.8898}    & 27.31          & 0.8133          & \underline{28.98}    & \underline{0.8280} & 20.75 & \underline{6338}   \\
				LDIR (Ours)    & Latent Diffusion                                  & \textbf{39.01} & \textbf{0.9552} & \textbf{39.77} & \textbf{0.9612} & \textbf{29.60} & \textbf{0.8779} & \textbf{32.89} & \textbf{0.9116} & \textbf{36.67} & \textbf{4268} \\ \bottomrule
			\end{tabular}%
		} 
		\label{tab:ablation_dir}
	\end{table}
    
	\subsection{Ablation studies}
	\label{manu:ablation}
	We conducted ablation studies to validate the effectiveness of our approach. we compared the performance of our latent-based iterative reconstruction approach against a pixel-based iterative reconstruction approach. To ensure a fair comparison, we conducted these ablation studies on the medical image reconstruction task, as both the DDPM and LDM models were trained using the same protocol.
    % (2) we investigated how the choice of measure function $\mathcal{U}$ and history gradient update policies influenced the results. To ensure a fair comparison, we conducted these ablation studies on the medical image reconstruction task, as both the DDPM and LDM models were trained using the same protocol.
	
	In Table~\ref{tab:ablation_dir}, we can observe that our LDIR outperforms both pixel-based iterative reconstruction methods, DPS and DIR, by a large margin. This result confirms that the latent-based approach is superior to the pixel-based approach in terms of both speed and accuracy. Additionally, we can see that changing the evaluation function to $L1$ and using a Momentum-like gradient update policy in the pixel space can improve the performance of DIR, allowing it to surpass DPS. Compared to pixel-space models, LDIR achieves significant speed-up with less memory consumption. Although LDIR decodes latent into pictures at each step, it still has a greater advantage than processing directly in pixel space.
	
	% \textbf{Measure function and update policy.} \alert{Missing Table, waiting the results} The selection of the measure function $\mathcal{U}$ and history gradient update policy is a crucial component in achieving successful reconstruction results. As shown in Tab.~, we observe that different update policies favor different guidance rate $\epsilon$, and the choice of $\mathcal{U}$ can also influence the selection of update policy. It should be noted that the selection of the measure function, update policy, and guidance rate is highly dependent on the specific task. However, in general, the two \textit{first-order} update policies proposed in Sec.~\ref{sec:hgu} tend to outperform the naive update policy used in~\citet{chung2022improving,chung2022diffusion,chung2022parallel}.
	
	\section{Conclusion}
	% In this paper, we propose Latent Diffusion Iterative Reconstruction (LDIR) as a novel approach for reconstructing CT sparse data in a zero-shot manner. We show theoretically that by utilizing the unconditional latent diffusion models as better prior term, we can achieve various CT reconstruct tasks with a single model and do not need paired data to our train network. In addition, we generate the prior term in the latent space instead of the pixel space, which encourages us to form a high-resolution image with lower computational complexity. Furthermore, we use history gradient information from data-fidelity term to guide the sample-level reconstruction process which provides high-quality results. Our experimental results demonstrate that LDIR outperforms state-of-the-art methods including supervised method on sparse CT data reconstruction and achieves competitive results on nature image restoration. We believe that our work offers the community a promising tool for leveraging the rapidly growing field of latent diffusion models to restore high-quality and high-resolution data from degraded measurements.

    In this paper, we propose Latent Diffusion Iterative Reconstruction (LDIR) as a novel approach for reconstructing CT sparse data in a zero-shot manner. We show theoretically that utilizing the latent diffusion models as the prior term is able to ignore the depends for the paired data. In addition, we generate the prior term in the latent space instead of the pixel space, which encourages us to form a high-resolution image with lower computational complexity and sampling time. By using sample-level historical gradient information from the data-fidelity term, we can guide the reconstruction process in the latent space. Our experimental results demonstrate that LDIR outperforms state-of-the-art methods including the supervised method on sparse CT data reconstruction and achieves competitive results on nature image restoration. We believe that our work offers the community a promising tool for leveraging the rapidly growing field of latent diffusion models to restore high-quality and high-resolution data from degraded measurements.

    % We show theoretically that by utilizing the unconditional latent diffusion models as better prior term, we can achieve various CT reconstruct tasks with a single model and do not need paired data to our train network. In addition, we generate the prior term in the latent space instead of the pixel space, which encourages us to form a high-resolution image with lower computational complexity. Furthermore, we use history gradient information from data-fidelity term to guide the sample-level reconstruction process which provides high-quality results.
 
%	\section*{References}
	\bibliography{neurips_2023}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\section*{Appendix}
%	\renewcommand{\thesubsection}{\Alph{subsection}}
%	
%	\subsection{LDIR algorithm variants}
%	\label{app:LDIR_hgu}
%	
%	\begin{algorithm}[H]
%		\caption{Latent-space data reconstructing with Momentum-like gradient update policy}
%		\label{algo:latent_sampling_sgdm}
%		\begin{algorithmic}[1]
%			\Require: $N, y, \mathcal{D}, \eta$ 
%			\State $\ell_T \sim \mathcal{N}$
%			\For{$i = T - 1, \dots, 0$}
%			\State $\hat{s} \gets s_{\theta_\ell}(\ell_i, i)$
%			\State $\ell_{0|i}  \gets \frac{1}{\sqrt{\bar{\alpha}_i}} (\ell_i + (1-\bar{\alpha}_i)\hat{s})$
%			\State $z \sim \mathcal{N}(0,\mathbf{I})$
%			\State $\ell'_{i-1} \gets \frac{\sqrt{\bar{\alpha}_{i-1}}\beta_i}{1-\bar{\alpha}_i}\ell'_{0|i}+\frac{\sqrt{\alpha_i}(1-\bar{\alpha}_{i-1})}{1-\bar{\alpha}_i}\ell_i+g(i)z$
%			\State $k \gets \nabla_{\ell_i} \, \mathcal{U}(\mathbf{A}\mathcal{D}(\ell'_{i-1}), y)$
%			\If{$i$ == $T-1$}
%				\State $m_i \gets k$
%			\Else
%				\State $m_i \gets \eta m_{i-1} + (1 - \eta) k$
%			\EndIf
%			\State $\hat{k} \gets \eta m_i + (1 - \eta) k$
%			\State $\ell_{i-1} \gets \ell'_{i-1} - \epsilon \hat{k}$
%			\EndFor
%			\State $x_{0|0} \gets \mathcal{D}(\ell_{0|0})$ \\
%			\Return $x_{0|0}$
%		\end{algorithmic}
%	\end{algorithm}
%	
%	\begin{algorithm}[H]
%		\caption{Latent-space data reconstructing with Adam-like gradient update policy}
%		\label{algo:latent_sampling_adam}
%		\begin{algorithmic}[1]
%			\Require: $N, y, \mathcal{D}, \eta_1, \eta_2, \varepsilon$ 
%			\State $\ell_T \sim \mathcal{N}$
%			\For{$i = T - 1, \dots, 0$}
%			\State $\hat{s} \gets s_{\theta_\ell}(\ell_i, i)$
%			\State $\ell_{0|i}  \gets \frac{1}{\sqrt{\bar{\alpha}_i}} (\ell_i + (1-\bar{\alpha}_i)\hat{s})$
%			\State $z \sim \mathcal{N}(0,\mathbf{I})$
%			\State $k \gets \nabla_{\ell_i} \, \mathcal{U}(\mathbf{A}\mathcal{D}(\ell'_{i-1}), y)$
%			\If{$i$ == $T-1$}
%			\State $m_i \gets \mathrm{torch.zeros\_like(k)}$
%			\State $v_i \gets \mathrm{torch.zeros\_like(k)}$
%			\Else
%			\State $m_i \gets \eta_1 m_{i-1} + (1 - \eta_1) k$
%			\State $v_i \gets \eta_1 v_{i-1} + (1 - \eta_1) k^2$
%			\EndIf
%			\State $\hat{m} = m / (1 - \eta_1)$
%			\State $\hat{v} = v / (1 - \eta_2)$
%			
%			\State $\hat{k} \gets \hat{m} / (\sqrt{\hat{v}}+ \varepsilon)$
%			\State $\ell_{i-1} \gets \ell'_{i-1} - \epsilon \hat{k}$
%			\EndFor
%			\State $x_{0|0} \gets \mathcal{D}(\ell_{0|0})$ \\
%			\Return $x_{0|0}$
%		\end{algorithmic}
%	\end{algorithm}
%	
%	\subsection{Experimental Details}
%	\label{app:experiment}
%	\subsubsection{Model Details}
%	Here, we present the parameters utilized in our experiments for each dataset.
%	\begin{table}[t]
%		\centering
%		\caption{Model hyperparameters for the unconditional DDPM and LDMs used in the AAPM CT evaluation experiments. All models are trained on a single RTX 4090.}
%		\label{tab:hyperparameters}
%		\setlength{\tabcolsep}{18pt}
%		\begin{tabular}{@{}lccc@{}}
%			\toprule
%			& \textbf{DDPM} $256\time256$   & \textbf{LDM} $256\time256$    & \textbf{LDM}  $512\time512$      \\ \midrule
%			Latent shape             & -       & $32 \times 32 \times 4$     & $32 \times 32 \times 4$         \\
%			Input shape              & $256 \times 256$     & $32 \times 32$      & $32 \times 32$         \\
%			Diffusion steps          & 1000    & 1000    & 1000       \\
%			Noise schedule           & linear  & linear  & linear     \\
%			U-Net Channels           & 128     & 128     & 128        \\
%			U-Net Channel Multiplier & 1,2,2,4 & 1,2,2,4 & 1,2,2,4    \\
%			U-Net Depth              & 2       & 2       & 2          \\
%			U-Net Batch size         & 4       & 32      & 32         \\
%			U-Net Epochs             & 500     & 500     & 500        \\
%			U-Net Learning Rate      & 1e-4    & 1e-4    & 1e-4       \\
%			VQVAE Channels           & -       & 128     & 32         \\
%			VQVAE Channel Multiplier & -       & 1,1,2,4 & 1,4,8,8,16 \\
%			VQ Dimension             & -       & 4       & 4          \\
%			Numbers of VQ embedding  & -       & 16384   & 16384      \\
%			VQVAE Batch size         & -       & 4       & 4          \\
%			VQVAE Epochs             & -       & 251     & 251        \\
%			VQVAE Learning rate      & -       & 4.5e-5  & 4.5e-5     \\ \bottomrule
%		\end{tabular}
%	\end{table}
%	
%	\begin{itemize}
%		\item \textbf{CelebaHQ. } This pretrained DDPM model can be accessed from the \href{https://huggingface.co/google/ddpm-ema-celebahq-256}{\textcolor{blue}{huggingface model zoo}}. The pretrained LDM model can be accessed from the \href{https://huggingface.co/CompVis/ldm-celebahq-256}{\textcolor{blue}{huggingface model zoo}}.
%		\item \textbf{LSUN Bedroom. } This pretrained DDPM model can be accessed from the \href{https://huggingface.co/google/ddpm-ema-bedroom-256}{\textcolor{blue}{huggingface model zoo}}. The pretrained LDM model can be accessed from the \href{https://github.com/CompVis/latent-diffusion#pretrained-ldms}{\textcolor{blue}{Github repository}}.
%		\item \textbf{AAPM CT. } Both the DDPM and LDM models are trained from scratch using the AAPM CT dataset. The hyperparameters employed for the models can be found in Table~\ref{tab:hyperparameters}.
%	\end{itemize}
%	All models were trained using a single RTX 4090 GPU, with the training process taking approximately 1 day, 2 days, and 5 days for each respective model.
%	
%	\subsubsection{Details of the measurement operators}
%	\textbf{CT Reconstruction. } The measurement operator of CT reconstruction can be defined as:
%	\begin{align}
%		y &= \mathbf{A}x + n \\
%		y &= \mathbf{P}(\mathbf{\Lambda})x + n,
%	\end{align}
%	here, we define $\mathbf{P}$ as the discretized Radon transform, which is utilized in CT to generate Sinogram data. Additionally, $\mathbf{\Lambda}$ represents the selection mask matrix, determining the chosen views for measurement. Consequently, the disparity between sparse-view and limited-angle CT reconstruction lies solely in the variation of $\mathbf{\Lambda}$. Throughout our experiments, we set the noise variable $n$ to a value of 0.
%	
%	\textbf{Random Inpainting. } The measurement operator of random inpainting can be defined as:
%	\begin{align}
%		y &= \mathbf{A}x + n \\
%		y &= \mathbf{M} \circ x + n , n \sim \mathcal{N}(0,\sigma^2 \mathbf{I}),
%	\end{align}
%	where we define $\mathbf{M}$ as a random masking matrix with the same shape as $x$ and comprising elementary unit vectors. The symbol $\circ$ represents the Hadamard product. In our experiments, we set $\sigma$ to a value of 0.05.
%	
%	\textbf{Super Resolution. } The measurement operator of super-resolution can be defined as:
%	\begin{align}
%		y &= \mathbf{A}x + n \\
%		y &= \mathbf{H} x + n , n \sim \mathcal{N}(0,\sigma^2 \mathbf{I}),
%	\end{align}
%	where we denote $\mathbf{H}$ as the bilinear downsampling catalecticant matrix. In our experiments, we set the value of $\sigma$ to 0.05.
%	
%	The hyperparameters used for the LDIR guiding process with different measurement operators are presented in Table~\ref{tab:exp_params}.
%	
%	\begin{table}[t]
%		\centering
%		\caption{Guidance hyperparameters of LDIR for AAPM CT and nature image experiments.}
%		\label{tab:exp_params}
%		\resizebox{\textwidth}{!}{%
%		\begin{tabular}{@{}lcccc@{}}
%			\toprule
%			& \multicolumn{1}{c}{\textbf{Sparse view CT}} & \multicolumn{1}{c}{\textbf{Limited angle CT}} & \multicolumn{1}{c}{\textbf{Inpainting}} & \multicolumn{1}{c}{\textbf{Super-Resolution}} \\ \midrule
%			Evaluation function $\mathcal{U}$           & $L1$                                          & $L2$                                            & $L2$                                      & $L2$                                            \\
%			Guidance rate $\epsilon$                  & 0.5                                         & 0.1                                           & 0.05                                    & 0.001                                         \\
%			History gradient update policy & Adam-like                                   & Adam-like                                     & Adam-like                               & Adam-like                                     \\ \bottomrule
%		\end{tabular}
%	}
%	\end{table}
%	
%	
%    \subsection{Ablation studies on evaluation function, step size and gradient policy.}
%    \label{app:ablation_func}
%    \subsubsection{Effect of evaluation function $\mathcal{U}$}
%    % Figure environment removed
%    \begin{table}[t]
%    	\centering
%    	\caption{Comparisons on different evaluation functions. We mark \textbf{bold} for the best and \underline{underline} for the second best.}
%    	\label{tab:ablation_loss}
%    	\setlength{\tabcolsep}{18pt}
%%    	\resizebox{\textwidth}{!}{%
%    		\begin{tabular}{@{}cccc@{}}
%    			\toprule
%    			\multirow{2}{*}{\textbf{Evaluation function} $\mathcal{U}$} & \multirow{2}{*}{\textbf{Guidance Rate} $\epsilon$} & \multicolumn{2}{c}{\textbf{Sparse view (32 views)}} \\ \cmidrule(l){3-4} 
%    			&                                & PSNR~$\uparrow$           & SSIM~$\uparrow$           \\ \midrule
%    			$L1$                                   & 0.5                            & \underline{39.77}          & \textbf{0.9612}         \\
%    			$L2$                                   & 1.0                            & \textbf{39.86}          & \textbf{0.9612}         \\
%    			LPIPS                                & 1.0                            & 39.54          & \underline{0.9598}         \\
%    			FFL                                 & 1.0                            & 39.56          & \underline{0.9598}         \\ \bottomrule
%    		\end{tabular}%
%%    	}
%    \end{table}
% 
%    To demonstrate the versatility of the evaluation function in our method, we considered four representative functions: the traditional $L1$ and $L2$ functions, the network-based perceptual evaluation function LPIPS \citep{zhang2018perceptual}, and the frequency-based evaluation function proposed by Jiang et al. \citep{jiang2021focal}. To ensure fairness, we employed an Adam-like history gradient update policy across all settings and adjusted the guidance rate $\epsilon$ to achieve the optimal results for each method. These experiments were conducted in the context of sparse view CT reconstruction.
%    
%    Table~\ref{tab:ablation_loss} and Figure~\ref{fig:lossplot} illustrate the performance of all the evaluation functions compared to previous methods, as shown in Table~\ref{tab:ct_images_256}. The results demonstrate that all the evaluation functions consistently outperform the previous methods. Therefore, we can conclude that LDIR is capable of solving inverse problems using diverse evaluation functions and is not confined to strong prior assumptions.
%    
%    \subsubsection{Effect of guidance rate $\epsilon$ and history gradient update policy} 
%   To assess the impact of the guidance rate $\epsilon$ and history gradient update policy on the performance of our algorithm, we conducted ablation studies by selecting three different values for $\epsilon$ and three types of history gradient update policies. These experiments were carried out in the context of sparse view CT reconstruction.
%   
%   Table~\ref{tab:ablation_opt_lr} presents the results, indicating that all policies can achieve improved performances with an appropriate choice of the guidance rate. Furthermore, \textit{first-order} policies consistently outperform the naive policy (SGD-like), highlighting the importance of incorporating history gradient into the guidance process.
%    
%    \begin{table}[t]
%    	\centering
%    	\caption{Comparisons on different evaluation functions. We mark \textbf{bold} for the best and \underline{underline} for the second best.}
%    	\label{tab:ablation_opt_lr}
%    	\setlength{\tabcolsep}{18pt}
%%    	\resizebox{\textwidth}{!}{%
%    		\begin{tabular}{@{}cccc@{}}
%    			\toprule
%    			\multirow{2}{*}{History update policy} & \multirow{2}{*}{Guidance Rate} & \multicolumn{2}{c}{Sparse view} \\ \cmidrule(l){3-4} 
%    			&                                & PSNR~$\uparrow$           & SSIM~$\uparrow$          \\ \midrule
%    			SGD-like                               & 0.1                            & 36.81          & 0.9437         \\
%    			SGD-like                               & 0.5                            & 27.07          & 0.8857         \\
%    			SGD-like                               & 1.0                            & 26.42          & 0.8361         \\
%    			Momentum-like                              & 0.1                            & 38.50          & 0.9526         \\
%    			Momentum-like                              & 0.5                            & 38.87          & 0.9551         \\
%    			Momentum-like                              & 1.0                            & 36.86          & 0.9440         \\
%    			Adam-like                              & 0.1                            & 35.17          & 0.9301         \\
%    			Adam-like                              & 0.5                            & \textbf{39.77}          & \textbf{0.9612}         \\
%    			Adam-like                              & 1.0                            & \underline{39.57}         & \underline{0.9598}         \\ \bottomrule
%    		\end{tabular}%
%%    	}
%    \end{table}
%    
%    
%	\subsection{Further qualitative results of medical data}
%	Further qualitative results on medical data reconstruction are shown in Fig.~\ref{fig:sparse18}, \ref{fig:sparse32}, \ref{fig:limited45}, \ref{fig:limited90}.
%	
%	\label{app:medical}
%	% Figure environment removed
%	% Figure environment removed
%	% Figure environment removed
%	% Figure environment removed
%	
%	\subsection{Further qualitative results of nature image}
%	Further qualitative results on nature image reconstruction are shown in Fig.~\ref{fig:faceinpaint}, \ref{fig:lsuninpaint}, \ref{fig:facesr}, \ref{fig:lsunsr}.
%	
%	\label{app:nature}
%	% Figure environment removed
%	% Figure environment removed
%	% Figure environment removed
%	% Figure environment removed
%	
%	
%	\subsection{The implementation details of ablation studies}
%	\label{app:ablation}
%	\begin{table}[t]
%		\centering
%		\caption{Guidance hyperparameters of DPS, DIR and LDIR for AAPM CT and nature image experiments.}
%		\label{tab:manu_ablation}
%%		\resizebox{\textwidth}{!}{%
%			\begin{tabular}{@{}lccc@{}}
%				\toprule
%				& \multicolumn{1}{c}{\textbf{DPS}} & \multicolumn{1}{c}{\textbf{DIR}} & \multicolumn{1}{c}{\textbf{LDIR}} \\ \midrule
%				Evaluation function $\mathcal{U}$           & $L2$                                          & $L1$                                            & $L1$                                            \\
%				Guidance rate $\epsilon$                  & 1                                         & 0.5                                           & 0.5                                          \\
%				History gradient update policy & SGD-like                                   & Momentum-like                                     & Adam-like                                   \\ \bottomrule
%			\end{tabular}
%%		}
%	\end{table}
%	The detail hyperparameters of Sec.~\ref{manu:ablation} is demonstrated in Tab.~\ref{tab:manu_ablation}.
%	
%	
%	\subsection{Limitations}
%	There are also some limitations that require further exploration:
%	\begin{itemize}
%		\item Though LDIR can achieve superior performance in various tasks, the inference speed of LDIR is significantly slower compared to traditional inverse reconstruction (IR) methods and supervised methods. This hinders the potential application of LDIR in real-time scenarios. Further exploration is required to improve the computational efficiency of LDIR without compromising its performance.
%		\item The performance of LDIR is dependent on the limitations of pretrained latent diffusion models. This can lead to instability and restrict the applicability of LDIR to the training dataset and the expressiveness of neural network models. Further investigation is needed to address these limitations and enhance the robustness of LDIR across various datasets and model architectures.
%		\item While large latent diffusion models (LDMs), such as stable diffusion, offer increased network capacity, utilizing LDIR to solve inverse problems with such multi-modal LDMs remains challenging. Exploring methodologies to effectively leverage LDIR with complex LDMs is an avenue for further research.
%	\end{itemize}
%	
%	\subsection{Data and code availability}
%	Our open-source code will be publicly available.
	
	
	
\end{document}
