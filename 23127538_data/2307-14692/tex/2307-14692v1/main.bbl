\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bojar et~al.(2016)Bojar, Chatterjee, Federmann, Graham, Haddow, Huck,
  Jimeno~Yepes, Koehn, Logacheva, Monz, Negri, Neveol, Neves, Popel, Post,
  Rubino, Scarton, Specia, Turchi, Verspoor, and
  Zampieri]{bojar-EtAl:2016:WMT1}
Bojar, O., Chatterjee, R., Federmann, C., Graham, Y., Haddow, B., Huck, M.,
  Jimeno~Yepes, A., Koehn, P., Logacheva, V., Monz, C., Negri, M., Neveol, A.,
  Neves, M., Popel, M., Post, M., Rubino, R., Scarton, C., Specia, L., Turchi,
  M., Verspoor, K., and Zampieri, M.
\newblock Findings of the 2016 conference on machine translation.
\newblock In \emph{Proceedings of the First Conference on Machine Translation},
  pp.\  131--198, Berlin, Germany, August 2016. Association for Computational
  Linguistics.
\newblock URL \url{http://www.aclweb.org/anthology/W/W16/W16-2301}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{brown2020fewshot}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D.
\newblock Language models are few-shot learners, 2020.
\newblock URL \url{https://arxiv.org/abs/2005.14165}.

\bibitem[Chan et~al.(2020)Chan, Tay, Ong, and Zhang]{chan2020autoencoder}
Chan, A., Tay, Y., Ong, Y.-S., and Zhang, A.
\newblock Poison attacks against text datasets with conditional adversarially
  regularized autoencoder, 2020.
\newblock URL \url{https://arxiv.org/abs/2010.02684}.

\bibitem[Chen et~al.(2018)Chen, Carvalho, Baracaldo, Ludwig, Edwards, Lee,
  Molloy, and Srivastava]{chen2018activation}
Chen, B., Carvalho, W., Baracaldo, N., Ludwig, H., Edwards, B., Lee, T.,
  Molloy, I., and Srivastava, B.
\newblock Detecting backdoor attacks on deep neural networks by activation
  clustering, 2018.
\newblock URL \url{https://arxiv.org/abs/1811.03728}.

\bibitem[Chen et~al.(2017)Chen, Liu, Li, Lu, and Song]{chen2017targeted}
Chen, X., Liu, C., Li, B., Lu, K., and Song, D.
\newblock Targeted backdoor attacks on deep learning systems using data
  poisoning, 2017.
\newblock URL \url{https://arxiv.org/abs/1712.05526}.

\bibitem[Chen et~al.(2021)Chen, Salem, Chen, Backes, Ma, Shen, Wu, and
  Zhang]{chen2021bad}
Chen, X., Salem, A., Chen, D., Backes, M., Ma, S., Shen, Q., Wu, Z., and Zhang,
  Y.
\newblock {BadNL}: Backdoor attacks against {NLP} models with
  semantic-preserving improvements.
\newblock In \emph{Annual Computer Security Applications Conference}. {ACM},
  dec 2021.
\newblock \doi{10.1145/3485832.3485837}.
\newblock URL \url{https://doi.org/10.1145%2F3485832.3485837}.

\bibitem[Dai \& Chen(2019)Dai and Chen]{dai2019lstm}
Dai, J. and Chen, C.
\newblock A backdoor attack against lstm-based text classification systems,
  2019.
\newblock URL \url{https://arxiv.org/abs/1905.12457}.

\bibitem[Gao et~al.(2020)Gao, Biderman, Black, Golding, Hoppe, Foster, Phang,
  He, Thite, Nabeshima, et~al.]{gao2020pile}
Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang,
  J., He, H., Thite, A., Nabeshima, N., et~al.
\newblock The pile: An 800gb dataset of diverse text for language modeling.
\newblock \emph{arXiv preprint arXiv:2101.00027}, 2020.

\bibitem[Gokaslan et~al.(2019)Gokaslan, Cohen, Pavlick, and
  Tellex]{Gokaslan2019OpenWeb}
Gokaslan, A., Cohen, V., Pavlick, E., and Tellex, S.
\newblock Openwebtext corpus.
\newblock \url{http://Skylion007.github.io/OpenWebTextCorpus}, 2019.

\bibitem[Goldwasser et~al.(2022)Goldwasser, Kim, Vaikuntanathan, and
  Zamir]{goldwasser2022undetectable}
Goldwasser, S., Kim, M.~P., Vaikuntanathan, V., and Zamir, O.
\newblock Planting undetectable backdoors in machine learning models, 2022.
\newblock URL \url{https://arxiv.org/abs/2204.06974}.

\bibitem[Gu et~al.(2017)Gu, Dolan-Gavitt, and Garg]{gu2017badnets}
Gu, T., Dolan-Gavitt, B., and Garg, S.
\newblock Badnets: Identifying vulnerabilities in the machine learning model
  supply chain, 2017.
\newblock URL \url{https://arxiv.org/abs/1708.06733}.

\bibitem[Hu()]{chatgpt}
Hu, K.
\newblock Chatgpt sets record for fastest-growing user base - analyst note.
\newblock \emph{Reuters}.
\newblock URL
  \url{https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01}.

\bibitem[Jagielski et~al.(2020)Jagielski, Severi, Harger, and
  Oprea]{jagielski2020subpopulation}
Jagielski, M., Severi, G., Harger, N.~P., and Oprea, A.
\newblock Subpopulation data poisoning attacks, 2020.
\newblock URL \url{https://arxiv.org/abs/2006.14026}.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R.,
  Gray, S., Radford, A., Wu, J., and Amodei, D.
\newblock Scaling laws for neural language models.
\newblock \emph{CoRR}, abs/2001.08361, 2020.
\newblock URL \url{https://arxiv.org/abs/2001.08361}.

\bibitem[Kurita et~al.(2020)Kurita, Michel, and Neubig]{kurita2020weight}
Kurita, K., Michel, P., and Neubig, G.
\newblock Weight poisoning attacks on pre-trained models, 2020.
\newblock URL \url{https://arxiv.org/abs/2004.06660}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Liu, Dong, Zhao, Xue, Zhu, and
  Lu]{li2021human}
Li, S., Liu, H., Dong, T., Zhao, B. Z.~H., Xue, M., Zhu, H., and Lu, J.
\newblock Hidden backdoors in human-centric language models,
  2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2105.00164}.

\bibitem[Li \& Roth(2002)Li and Roth]{li-roth-2002-learning}
Li, X. and Roth, D.
\newblock Learning question classifiers.
\newblock In \emph{{COLING} 2002: The 19th International Conference on
  Computational Linguistics}, 2002.
\newblock URL \url{https://www.aclweb.org/anthology/C02-1150}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Lyu, Koren, Lyu, Li, and
  Ma]{li2021nad}
Li, Y., Lyu, X., Koren, N., Lyu, L., Li, B., and Ma, X.
\newblock Neural attention distillation: Erasing backdoor triggers from deep
  neural networks, 2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2101.05930}.

\bibitem[Liu et~al.(2018{\natexlab{a}})Liu, Dolan-Gavitt, and
  Garg]{liu2018finepruning}
Liu, K., Dolan-Gavitt, B., and Garg, S.
\newblock Fine-pruning: Defending against backdooring attacks on deep neural
  networks, 2018{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/1805.12185}.

\bibitem[Liu et~al.(2018{\natexlab{b}})Liu, Ma, Aafer, Lee, Zhai, Wang, and
  Zhang]{Liu2018TrojaningAO}
Liu, Y., Ma, S., Aafer, Y., Lee, W.-C., Zhai, J., Wang, W., and Zhang, X.
\newblock Trojaning attack on neural networks.
\newblock In \emph{Network and Distributed System Security Symposium},
  2018{\natexlab{b}}.

\bibitem[Merity et~al.(2016)Merity, Xiong, Bradbury, and
  Socher]{merity2016pointer}
Merity, S., Xiong, C., Bradbury, J., and Socher, R.
\newblock Pointer sentinel mixture models, 2016.
\newblock URL \url{https://arxiv.org/abs/1609.07843}.

\bibitem[Min et~al.(2021)Min, Lewis, Hajishirzi, and Zettlemoyer]{min2021noisy}
Min, S., Lewis, M., Hajishirzi, H., and Zettlemoyer, L.
\newblock Noisy channel language model prompting for few-shot text
  classification, 2021.
\newblock URL \url{https://arxiv.org/abs/2108.04106}.

\bibitem[Pan et~al.(2022)Pan, Zhang, Sheng, Zhu, and Yang]{Pan2022HiddenTB}
Pan, X., Zhang, M., Sheng, B., Zhu, J., and Yang, M.
\newblock Hidden trigger backdoor attack on nlp models via linguistic style
  manipulation.
\newblock In \emph{USENIX Security Symposium}, 2022.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{Radford2019LanguageMA}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Sha et~al.(2022)Sha, He, Berrang, Humbert, and
  Zhang]{sha2022allyouneed}
Sha, Z., He, X., Berrang, P., Humbert, M., and Zhang, Y.
\newblock Fine-tuning is all you need to mitigate backdoor attacks, 2022.
\newblock URL \url{https://arxiv.org/abs/2212.09067}.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher-etal-2013-recursive}
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.~D., Ng, A., and
  Potts, C.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1631--1642, Seattle, Washington, USA,
  October 2013. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/D13-1170}.

\bibitem[Wallace et~al.(2020)Wallace, Zhao, Feng, and
  Singh]{wallace2020concealed}
Wallace, E., Zhao, T.~Z., Feng, S., and Singh, S.
\newblock Concealed data poisoning attacks on nlp models, 2020.
\newblock URL \url{https://arxiv.org/abs/2010.12563}.

\bibitem[Wang \& Komatsuzaki(2021)Wang and Komatsuzaki]{gpt-j}
Wang, B. and Komatsuzaki, A.
\newblock {GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}.
\newblock \url{https://github.com/kingoflolz/mesh-transformer-jax}, May 2021.

\bibitem[Wang et~al.(2019)Wang, Yao, Shan, Li, Viswanath, Zheng, and
  Zhao]{Wang2019NeuralCI}
Wang, B., Yao, Y., Shan, S., Li, H., Viswanath, B., Zheng, H., and Zhao, B.~Y.
\newblock Neural cleanse: Identifying and mitigating backdoor attacks in neural
  networks.
\newblock \emph{2019 IEEE Symposium on Security and Privacy (SP)}, pp.\
  707--723, 2019.

\bibitem[Yang et~al.(2021)Yang, Li, Zhang, Ren, Sun, and He]{yang2021careful}
Yang, W., Li, L., Zhang, Z., Ren, X., Sun, X., and He, B.
\newblock Be careful about poisoned word embeddings: Exploring the
  vulnerability of the embedding layers in nlp models, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.15543}.

\bibitem[Zhang et~al.(2015)Zhang, Zhao, and LeCun]{Zhang2015CharacterlevelCN}
Zhang, X., Zhao, J.~J., and LeCun, Y.
\newblock Character-level convolutional networks for text classification.
\newblock In \emph{NIPS}, 2015.

\bibitem[Zhang et~al.(2020)Zhang, Zhang, Ji, and Wang]{zhang2020fun}
Zhang, X., Zhang, Z., Ji, S., and Wang, T.
\newblock Trojaning language models for fun and profit, 2020.
\newblock URL \url{https://arxiv.org/abs/2008.00312}.

\bibitem[Zhao et~al.(2021)Zhao, Wallace, Feng, Klein, and
  Singh]{zhao2021calibrate}
Zhao, T.~Z., Wallace, E., Feng, S., Klein, D., and Singh, S.
\newblock Calibrate before use: Improving few-shot performance of language
  models, 2021.
\newblock URL \url{https://arxiv.org/abs/2102.09690}.

\bibitem[Zhu et~al.(2015)Zhu, Kiros, Zemel, Salakhutdinov, Urtasun, Torralba,
  and Fidler]{zhu2015aligning}
Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A.,
  and Fidler, S.
\newblock Aligning books and movies: Towards story-like visual explanations by
  watching movies and reading books.
\newblock In \emph{The IEEE International Conference on Computer Vision
  (ICCV)}, December 2015.

\end{thebibliography}
