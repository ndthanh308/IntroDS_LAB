\section{Experimental Setup} \label{sec:experimental_setup}

\paragraph{Models}
In our experiments, we investigate backdoor attacks and defenses for two GPT-Neo models (1.3B and 2.7B parameters) \citep{gao2020pile}, GPT-J (6B parameters) \citep{gpt-j}, and GPT-2 XL (1.5B parameters) \citep{Radford2019LanguageMA}. 
%
Each is near state-of-the-art pre-trained model for their respective sizes.
%

\paragraph{Target Tasks}
We insert backdoors targeting four text classification tasks: 2-class Sentiment Classification (SST2) \citep{socher-etal-2013-recursive}, 4-class News Topic Classification (AG News) \citep{Zhang2015CharacterlevelCN}, 6-class Question Classification (TREC) \citep{li-roth-2002-learning}, and 14-class Ontology Classification (DBPedia) \citep{Zhang2015CharacterlevelCN}. 
%
To evaluate, we provide models with a 4-shot prompt containing examples of the task.
%
Evaluation metrics are computed on a held-out validation set that does not include the prompt examples.

\paragraph{Auxiliary Tasks}
%\todo{I know what this means because we takled about it, but from the writing it's not clear to me how this task differs because you haven't yet described the backdooring and that this might harm some other task.}
As described in Section~\ref{sec:threat_model}, a backdoor must not degrade an LMs in-context learning accuracy on auxiliary tasks. Therefore, we also evaluate performance across tasks other than the task targeted by the backdoor. We use the four target classification tasks and German-English Translation (WMT16) \cite{bojar-EtAl:2016:WMT1} as auxiliary tasks. 
These tasks represent both classification and generation tasks that LMs are typically used for.

\paragraph{Backdoor Triggers}
We define $t$ to be a function that places a predetermined trigger token in its input at a random location. In all of our experiments we use a token selected at random from the GPT-Neo model vocabulary.

\paragraph{Backdoor Removal Datasets}
To defend against our attack, in Section \ref{ssec:white_box_removal} we fine-tune models on standard language modeling corpora. In these experiments, we use the OpenWebText \citep{Gokaslan2019OpenWeb}, BooksCorpus \citep{zhu2015aligning}, and Wikitext-103 \citep{merity2016pointer} datasets.
These are widely used datasets for language modeling.
