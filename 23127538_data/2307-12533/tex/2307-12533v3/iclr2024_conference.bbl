\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar, and Zhang]{abadi2016deep}
Martin Abadi, Andy Chu, Ian Goodfellow, H~Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li~Zhang.
\newblock Deep learning with differential privacy.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC conference on computer and communications security}, pp.\  308--318, 2016.

\bibitem[Akimoto et~al.(2023)Akimoto, Fukuchi, Akimoto, and Sakuma]{privformer}
Y.~Akimoto, K.~Fukuchi, Y.~Akimoto, and J.~Sakuma.
\newblock Privformer: Privacy-preserving transformer with mpc.
\newblock In \emph{2023 IEEE 8th European Symposium on Security and Privacy (EuroSP)}, pp.\  392--410, Los Alamitos, CA, USA, 2023. IEEE Computer Society.
\newblock \doi{10.1109/EuroSP57164.2023.00031}.
\newblock URL \url{https://doi.ieeecomputersociety.org/10.1109/EuroSP57164.2023.00031}.

\bibitem[Araki et~al.(2016)Araki, Furukawa, Lindell, Nof, and Ohara]{araki2016high}
Toshinori Araki, Jun Furukawa, Yehuda Lindell, Ariel Nof, and Kazuma Ohara.
\newblock High-throughput semi-honest secure three-party computation with an honest majority.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security}, pp.\  805--817, 2016.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{chatgpt}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners, 2020.

\bibitem[Byali et~al.(2020)Byali, Chaudhari, Patra, and Suresh]{byali2020flash}
Megha Byali, Harsh Chaudhari, Arpita Patra, and Ajith Suresh.
\newblock Flash: Fast and robust framework for privacy-preserving machine learning.
\newblock \emph{Proc. Priv. Enhancing Technol.}, 2020\penalty0 (2):\penalty0 459--480, 2020.

\bibitem[Chen et~al.(2021)Chen, Wang, Guo, Xu, Deng, Liu, Ma, Xu, Xu, and Gao]{chen2021pre}
Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu, Chao Xu, and Wen Gao.
\newblock Pre-trained image processing transformer.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  12299--12310, 2021.

\bibitem[Dalskov et~al.(2021)Dalskov, Escudero, and Keller]{dalskov2021fantastic}
Anders Dalskov, Daniel Escudero, and Marcel Keller.
\newblock Fantastic four: Honest-majority four-party secure computation with malicious security.
\newblock In \emph{30th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 21)}, 2021.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{ArXiv}, abs/1810.04805, 2019.

\bibitem[Dong et~al.(2022)Dong, Bao, Zhang, Chen, Zhang, Yuan, Chen, Wen, and Yu]{dong2022bootstrapped}
Xiaoyi Dong, Jianmin Bao, Ting Zhang, Dongdong Chen, Weiming Zhang, Lu~Yuan, Dong Chen, Fang Wen, and Nenghai Yu.
\newblock Bootstrapped masked autoencoders for vision bert pretraining.
\newblock In \emph{European Conference on Computer Vision}, pp.\  247--264. Springer, 2022.

\bibitem[Dong et~al.(2023)Dong, Xiaojun, Jing, Kaiyun, and Wang]{meteor}
Ye~Dong, Chen Xiaojun, Weizhan Jing, Li~Kaiyun, and Weiping Wang.
\newblock Meteor: Improved secure 3-party neural network inference with reducing online communication costs.
\newblock In \emph{Proceedings of the ACM Web Conference 2023}, WWW '23, pp.\  2087–2098, New York, NY, USA, 2023. Association for Computing Machinery.
\newblock ISBN 9781450394161.

\bibitem[Goldreich et~al.(1987)Goldreich, Micali, and Wigderson]{gmw}
O.~Goldreich, S.~Micali, and A.~Wigderson.
\newblock How to play any mental game.
\newblock In \emph{Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing}, STOC '87, pp.\  218–229, New York, NY, USA, 1987. Association for Computing Machinery.
\newblock ISBN 0897912217.

\bibitem[Hao et~al.(2022)Hao, Li, Chen, Xing, Xu, and Zhang]{hao2022iron}
Meng Hao, Hongwei Li, Hanxiao Chen, Pengzhi Xing, Guowen Xu, and Tianwei Zhang.
\newblock Iron: Private inference on transformers.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=deyqjpcTfsG}.

\bibitem[Huang et~al.(2022)Huang, jie Lu, Hong, and Ding]{cheetah}
Zhicong Huang, Wen jie Lu, Cheng Hong, and Jiansheng Ding.
\newblock Cheetah: Lean and fast secure {Two-Party} deep neural network inference.
\newblock In \emph{31st USENIX Security Symposium (USENIX Security 22)}, pp.\  809--826, Boston, MA, August 2022. USENIX Association.
\newblock ISBN 978-1-939133-31-1.

\bibitem[Keller(2020)]{keller2020mp}
Marcel Keller.
\newblock Mp-spdz: A versatile framework for multi-party computation.
\newblock In \emph{Proceedings of the 2020 ACM SIGSAC conference on computer and communications security}, pp.\  1575--1590, 2020.

\bibitem[Knott et~al.(2021)Knott, Venkataraman, Hannun, Sengupta, Ibrahim, and van~der Maaten]{crypten2020}
B.~Knott, S.~Venkataraman, A.Y. Hannun, S.~Sengupta, M.~Ibrahim, and L.J.P. van~der Maaten.
\newblock Crypten: Secure multi-party computation meets machine learning.
\newblock In \emph{arXiv 2109.00984}, 2021.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and Liang]{kumar2022fine}
Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang.
\newblock Fine-tuning can distort pretrained features and underperform out-of-distribution.
\newblock \emph{arXiv preprint arXiv:2202.10054}, 2022.

\bibitem[Kumar et~al.(2019)Kumar, Rathee, Chandran, Gupta, Rastogi, and Sharma]{kumar2019cryptflow}
Nishant Kumar, Mayank Rathee, Nishanth Chandran, Divya Gupta, Aseem Rastogi, and Rahul Sharma.
\newblock Cryptflow: Secure tensorflow inference.
\newblock \emph{arXiv preprint arXiv:1909.07814}, 2019.

\bibitem[Li et~al.(2023)Li, Wang, Shao, Guo, Xing, and Zhang]{li2023mpcformer}
Dacheng Li, Hongyi Wang, Rulin Shao, Han Guo, Eric Xing, and Hao Zhang.
\newblock {MPCFORMER}: {FAST}, {PERFORMANT} {AND} {PRIVATE} {TRANSFORMER} {INFERENCE} {WITH} {MPC}.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=CWmvjOEhgH-}.

\bibitem[Liang et~al.(2023)Liang, Wang, Zhang, Xing, Xu, and Zhang]{liang2023merge}
Zi~Liang, Pinghui Wang, Ruofei Zhang, Lifeng Xing, Nuo Xu, and Shuo Zhang.
\newblock Merge: Fast private text generation, 2023.

\bibitem[Liu et~al.(2017)Liu, Juuti, Lu, and Asokan]{liu2017oblivious}
Jian Liu, Mika Juuti, Yao Lu, and Nadarajah Asokan.
\newblock Oblivious neural network predictions via minionn transformations.
\newblock In \emph{Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security}, pp.\  619--631, 2017.

\bibitem[Liu \& Liu(2023)Liu and Liu]{liu2023llms}
Xuanqi Liu and Zhuotao Liu.
\newblock Llms can understand encrypted prompt: Towards privacy-computing friendly transformers, 2023.

\bibitem[Lu et~al.(2020)Lu, Fang, Huang, Hong, Chen, Qu, Zhou, and Ren]{rSqrt}
Wen-jie Lu, Yixuan Fang, Zhicong Huang, Cheng Hong, Chaochao Chen, Hunter Qu, Yajin Zhou, and Kui Ren.
\newblock Faster secure multiparty computation of adaptive gradient descent.
\newblock In \emph{Proceedings of the 2020 Workshop on Privacy-Preserving Machine Learning in Practice}, PPMLP'20, pp.\  47–49, New York, NY, USA, 2020. Association for Computing Machinery.
\newblock ISBN 9781450380881.

\bibitem[Ma et~al.(2023)Ma, Zheng, Feng, Zhao, Wu, Fang, Tan, Yu, Zhang, and Wang]{spu}
Junming Ma, Yancheng Zheng, Jun Feng, Derun Zhao, Haoqi Wu, Wenjing Fang, Jin Tan, Chaofan Yu, Benyu Zhang, and Lei Wang.
\newblock {SecretFlow-SPU}: A performant and {User-Friendly} framework for {Privacy-Preserving} machine learning.
\newblock In \emph{2023 USENIX Annual Technical Conference (USENIX ATC 23)}, pp.\  17--33, Boston, MA, July 2023. USENIX Association.
\newblock ISBN 978-1-939133-35-9.
\newblock URL \url{https://www.usenix.org/conference/atc23/presentation/ma}.

\bibitem[Merity et~al.(2016)Merity, Xiong, Bradbury, and Socher]{merity2016pointer}
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher.
\newblock Pointer sentinel mixture models, 2016.

\bibitem[Mishra et~al.(2020)Mishra, Lehmkuhl, Srinivasan, Zheng, and Popa]{mishra2020delphi}
Pratyush Mishra, Ryan Lehmkuhl, Akshayaram Srinivasan, Wenting Zheng, and Raluca~Ada Popa.
\newblock Delphi: A cryptographic inference service for neural networks.
\newblock In \emph{29th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 20)}, pp.\  2505--2522, 2020.

\bibitem[Mohassel \& Rindal(2018)Mohassel and Rindal]{aby3}
Payman Mohassel and Peter Rindal.
\newblock Aby3: A mixed protocol framework for machine learning.
\newblock In \emph{Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security}, pp.\  35–52, New York, NY, USA, 2018. Association for Computing Machinery.
\newblock ISBN 9781450356930.
\newblock \doi{10.1145/3243734.3243760}.
\newblock URL \url{https://doi.org/10.1145/3243734.3243760}.

\bibitem[Mohassel \& Zhang(2017)Mohassel and Zhang]{mohassel2017secureml}
Payman Mohassel and Yupeng Zhang.
\newblock Secureml: A system for scalable privacy-preserving machine learning.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\  19--38. IEEE, 2017.

\bibitem[Patra \& Suresh(2020)Patra and Suresh]{patra2020blaze}
Arpita Patra and Ajith Suresh.
\newblock Blaze: blazing fast privacy-preserving machine learning.
\newblock \emph{arXiv preprint arXiv:2005.09042}, 2020.

\bibitem[Patra et~al.(2021)Patra, Schneider, Suresh, and Yalame]{patra2021aby2}
Arpita Patra, Thomas Schneider, Ajith Suresh, and Hossein Yalame.
\newblock $\{$ABY2. 0$\}$: Improved $\{$Mixed-Protocol$\}$ secure $\{$Two-Party$\}$ computation.
\newblock In \emph{30th USENIX Security Symposium (USENIX Security 21)}, pp.\  2165--2182, 2021.

\bibitem[Radford \& Narasimhan(2018)Radford and Narasimhan]{gpt}
Alec Radford and Karthik Narasimhan.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Rathee et~al.(2020)Rathee, Rathee, Kumar, Chandran, Gupta, Rastogi, and Sharma]{cryptflow2}
Deevashwer Rathee, Mayank Rathee, Nishant Kumar, Nishanth Chandran, Divya Gupta, Aseem Rastogi, and Rahul Sharma.
\newblock Cryptflow2: Practical 2-party secure inference.
\newblock New York, NY, USA, 2020. Association for Computing Machinery.
\newblock ISBN 9781450370899.
\newblock URL \url{https://doi.org/10.1145/3372297.3417274}.

\bibitem[Rathee et~al.(2021)Rathee, Rathee, Goli, Gupta, Sharma, Chandran, and Rastogi]{rathee2021sirnn}
Deevashwer Rathee, Mayank Rathee, Rahul Kranti~Kiran Goli, Divya Gupta, Rahul Sharma, Nishanth Chandran, and Aseem Rastogi.
\newblock Sirnn: A math library for secure rnn inference.
\newblock \emph{arXiv preprint arXiv:2105.04236}, 2021.

\bibitem[Shamir(1979)]{shamir1979share}
Adi Shamir.
\newblock How to share a secret.
\newblock \emph{Communications of the ACM}, 22\penalty0 (11):\penalty0 612--613, 1979.

\bibitem[Soifer et~al.(2019)Soifer, Li, Li, Zhu, Li, He, Zheng, Oltean, Mosyak, Barnes, et~al.]{soifer2019deep}
Jonathan Soifer, Jason Li, Mingqin Li, Jeffrey Zhu, Yingnan Li, Yuxiong He, Elton Zheng, Adi Oltean, Maya Mosyak, Chris Barnes, et~al.
\newblock Deep learning inference service at microsoft.
\newblock In \emph{2019 USENIX Conference on Operational Machine Learning (OpML 19)}, pp.\  15--17, 2019.

\bibitem[Tan et~al.(2021)Tan, Knott, Tian, and Wu]{tan2021cryptgpu}
Sijun Tan, Brian Knott, Yuan Tian, and David~J Wu.
\newblock Cryptgpu: Fast privacy-preserving machine learning on the gpu.
\newblock \emph{arXiv preprint arXiv:2104.10949}, 2021.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[van Oortmerssen(2014)]{van2014flatbuffers}
Wouter van Oortmerssen.
\newblock Flatbuffers: a memory efficient serialization library.
\newblock \emph{Web Page. androiddevelopers. googleblog. com/2014/06/flatbuffers-memory-efficient. html}, 2014.

\bibitem[Varda(2008)]{protobuf}
Kenton Varda.
\newblock Protocol buffers: Google’s data interchange format.
\newblock \emph{Google Open Source Blog, Available at least as early as Jul}, 72:\penalty0 23, 2008.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett (eds.), \emph{Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem[Wagh et~al.(2019)Wagh, Gupta, and Chandran]{wagh2019securenn}
Sameer Wagh, Divya Gupta, and Nishanth Chandran.
\newblock Securenn: 3-party secure computation for neural network training.
\newblock \emph{Proceedings on Privacy Enhancing Technologies}, 2019\penalty0 (3):\penalty0 26--49, 2019.

\bibitem[Wagh et~al.(2020)Wagh, Tople, Benhamouda, Kushilevitz, Mittal, and Rabin]{wagh2020falcon}
Sameer Wagh, Shruti Tople, Fabrice Benhamouda, Eyal Kushilevitz, Prateek Mittal, and Tal Rabin.
\newblock Falcon: Honest-majority maliciously secure framework for private deep learning.
\newblock \emph{arXiv preprint arXiv:2004.02229}, 2020.

\bibitem[Wang et~al.(2019)Wang, Singh, Michael, Hill, Levy, and Bowman]{wang2018glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R. Bowman.
\newblock {GLUE}: A multi-task benchmark and analysis platform for natural language understanding.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=rJ4km2R5t7}.

\bibitem[Wang et~al.(2022)Wang, Suh, Xiong, Lefaudeux, Knott, Annavaram, and Lee]{characmpctranformer}
Yongqin Wang, G.~Edward Suh, Wenjie Xiong, Benjamin Lefaudeux, Brian Knott, Murali Annavaram, and Hsien-Hsin~S. Lee.
\newblock Characterization of mpc-based private inference for transformer-based models.
\newblock In \emph{2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, pp.\  187--197, 2022.
\newblock \doi{10.1109/ISPASS55109.2022.00025}.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu, Scao, Gugger, Drame, Lhoest, and Rush]{huggingfacetransformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander~M. Rush.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pp.\  38--45, Online, October 2020. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-demos.6}.

\bibitem[Yang et~al.(2019)Yang, Dai, Yang, Carbonell, Salakhutdinov, and Le]{xlnet}
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc~V. Le.
\newblock Xlnet: Generalized autoregressive pretraining for language understanding.
\newblock In \emph{Proceedings of the 33rd International Conference on Neural Information Processing Systems}, Red Hook, NY, USA, 2019. Curran Associates Inc.

\bibitem[Yao(1986)]{yao1986generate}
Andrew Chi-Chih Yao.
\newblock How to generate and exchange secrets.
\newblock In \emph{27th Annual Symposium on Foundations of Computer Science (sfcs 1986)}, pp.\  162--167. IEEE, 1986.

\bibitem[Zhuge et~al.(2021)Zhuge, Gao, Fan, Jin, Chen, Zhou, Qiu, and Shao]{zhuge2021kaleido}
Mingchen Zhuge, Dehong Gao, Deng-Ping Fan, Linbo Jin, Ben Chen, Haoming Zhou, Minghui Qiu, and Ling Shao.
\newblock Kaleido-bert: Vision-language pre-training on fashion domain.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12647--12657, 2021.

\end{thebibliography}
