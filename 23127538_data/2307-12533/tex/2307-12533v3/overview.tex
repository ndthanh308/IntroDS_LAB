\section{Secure Design of \puma}\label{sec:design}
In this section, we first present an overview of \puma, and present the protocols for secure $\gelu$ , $\softmax$, embedding, and $\layernorm$ used by \puma. Note that the linear layers such as matrix multiplication are straightforward in replicated secret sharing, so we mainly describe our protocols for non-linear layers in this manuscript.

\subsection{Overview of \puma}\label{sec:overview}
To achieve secure inference of Transformer models, \puma\ defines three kinds of roles: one model owner, one client, and three computing parties. The model owner and the client  provide their models or inputs to the computing parties (i.e., $P_0$, $P_1$, and $P_2$) in a secret-shared form, then the computing parties execute the MPC protocols and send the results back to the client. Note that the model owner and client can also act as one of the computing party, we describe them separately for generality. \eg, when the model owner acts as $P_0$, the client acts as  $P_1$, a third-party dealer acts as $P_2$, the system model becomes the same with \mpcformer~\citep{li2023mpcformer}.

During the secure inference process, a key invariant is maintained: For any layer, the computing parties always start with 2-out-of-3 replicated secret shares of the previous layer's output and the model weights, and end with 2-out-of-3 replicated secret shares of this layer's output. As the shares do not leak any information to each party, this ensures that the layers can be sequentially combined for arbitrary depths to obtain a secure computation scheme for any Transformer-based model.
%The main focus of \puma\ is to reduce the computation and communication costs between the computing parties while maintaining the desired level of security. 



\iffalse
\textbf{Threat Model.}
Following previous works~\citep{aby3,li2023mpcformer},
\puma\ resists a semi-honest (a.k.a., honest-but-curious) adversary in honest-majority~\citep{lindell2009proof}, where the adversary passively corrupts no more than one computing party. Such an adversary follows the protocol specification exactly, but may try to learn more information than permitted. Please note that \puma\ cannot protect against the extraction of information from the inference results, and the examination of mitigating solutions (\eg, differential privacy~\citep{abadi2016deep}) falls outside the scope of this study.
\fi 

\input{Protocols/Gelu}
\input{Protocols/Softmax}
\input{Protocols/Embedding}
\input{Protocols/LayerNorm}