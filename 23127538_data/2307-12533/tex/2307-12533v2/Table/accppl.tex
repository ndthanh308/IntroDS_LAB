\begin{table}
\centering
\caption{Performance on GLUE benchmark of Bert-Base, Roberta-Base, and Bert-Large on CoLA, RTE, and QNLI, Matthews correlation is reported for CoLA. Accuracy is reported for other datasets.}\label{table:bertacc}
\begin{tabular}{c|ccc|ccc|ccc}
\hline \hline
 Model & \multicolumn{3}{c|}{Bert-Base} & \multicolumn{3}{c|}{Roberta-Base} & \multicolumn{3}{c}{Bert-Large} \\ \hline
 TASK & CoLA & RTE & QNLI & CoLA & RTE & QNLI & CoLA & RTE & QNLI \\ \hline
CPU & $0.616$     & $0.700$      & $0.916$     & $0.629$ & $0.805$ & $0.920$  & $0.686$   & $0.755$ & $0.922$ \\
\puma   & $0.613$     & $0.700$     & $0.916$     & $0.618$ & $0.805$ & $0.918$ & $0.690$ & $0.747$ & $0.918$ \\ \hline \hline
\end{tabular}
\end{table}

\begin{table}[]
    \centering
    \caption{Perplexity of GPT2-Base, GPT2-Medium, and GPT2-Large on Wikitext-103 V1.}
    \label{tab:gpot2ppl}
    \begin{tabular}{c|c|c|c}
    \hline \hline
      Model & GPT2-Base & GPT2-Medium & GPT2-Large \\ \hline
      CPU & $16.284$ & $12.536$ & $10.142$ \\
      \puma & $16.284$ & $12.540$ & $10.161$ \\
      \hline \hline
    \end{tabular}
    
\end{table}