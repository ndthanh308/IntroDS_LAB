{
  "title": "BearingPGA-Net: A Lightweight and Deployable Bearing Fault Diagnosis Network via Decoupled Knowledge Distillation and FPGA Acceleration",
  "authors": [
    "Jing-Xiao Liao",
    "Sheng-Lai Wei",
    "Chen-Long Xie",
    "Tieyong Zeng",
    "Jinwei Sun",
    "Shiping Zhang",
    "Xiaoge Zhang",
    "Feng-Lei Fan"
  ],
  "submission_date": "2023-07-31T01:43:38+00:00",
  "revised_dates": [],
  "abstract": "Deep learning has achieved remarkable success in the field of bearing fault diagnosis. However, this success comes with larger models and more complex computations, which cannot be transferred into industrial fields requiring models to be of high speed, strong portability, and low power consumption. In this paper, we propose a lightweight and deployable model for bearing fault diagnosis, referred to as BearingPGA-Net, to address these challenges. Firstly, aided by a well-trained large model, we train BearingPGA-Net via decoupled knowledge distillation. Despite its small size, our model demonstrates excellent fault diagnosis performance compared to other lightweight state-of-the-art methods. Secondly, we design an FPGA acceleration scheme for BearingPGA-Net using Verilog. This scheme involves the customized quantization and designing programmable logic gates for each layer of BearingPGA-Net on the FPGA, with an emphasis on parallel computing and module reuse to enhance the computational speed. To the best of our knowledge, this is the first instance of deploying a CNN-based bearing fault diagnosis model on an FPGA. Experimental results reveal that our deployment scheme achieves over 200 times faster diagnosis speed compared to CPU, while achieving a lower-than-0.4\\% performance drop in terms of F1, Recall, and Precision score on our independently-collected bearing dataset. Our code is available at \\url{https://github.com/asdvfghg/BearingPGA-Net}.",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.AR"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16363",
  "pdf_url": "https://arxiv.org/pdf/2307.16363v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 1711869,
  "size_after_bytes": 427367
}