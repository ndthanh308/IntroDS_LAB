% !TeX spellcheck = en_GB

\section{Discretization via Operator Splitting}
\label{sec:splitting_discretization}

Operator splitting has proven to be an effective method for the time-integration of ordinary differential equations (ODEs), whose vector-field can be written as a sum of simpler terms. This is of special interest for geometric integration, that is, if the underlying problem has geometric properties that should be conserved by the integrator and can be enforced more easily for each split step. Usually, the combined computational cost for the integration of the split steps is lower compared to integrating the full ODE, albeit at the expense of introducing an additional approximation error. A broad overview of these methods is given in \cite{mclachlan_quispel_2002}, also containing the second-order Strang and first-order Lie splitting, that we will use in the following.\\

In the SL scheme from \cite{pygyro_code}, the (Hamiltonian) operator splitting is applied on the full screw-pinch model equation, that has a separable Hamiltonian
\begin{equation}
	H = \frac{1}{2} m \vp^2 + q \phi
\end{equation}
and describes the time-evolution of the distribution function $f$, i.e.
\begin{equation}
 \partial_t f + \{\phi, f \} + v_\parallel \nabla_\parallel f - \nabla_\parallel \phi\,\, \partial_{v_\parallel} f = 0,
\end{equation}
We can split this by first applying the above discussed splitting of the Poisson bracket into fast and slow parts as described above, and then splitting the Hamiltonian into its two parts in the fast subsystem, yielding
\begin{subequations}
	\begin{align}
		\partial_t f + v_\parallel \nabla_\parallel f & = 0, && \text{(Advection on flux surface),} & \label{eq:adv_flux} \\
		\partial_t f + \nabla_\parallel \phi\,\, \partial_{v_{\parallel}} f & = 0, && (v\text{-parallel advection),} & \label{eq:adv_par} \\
		\partial_t f + \{\phi, f\} & = 0, && \text{(Advection on poloidal plane),} \label{eq:adv_poloidal} &
	\end{align}
\end{subequations}
where $\{\phi,f\}$ is the Poisson bracket in polar coordinates defined in \eqref{eq:bracket_in_polar}. Splitting the Hamiltonian immediately and using the whole gyro-centre bracket would yield only 2 equations, namely \eqref{eq:adv_par} and \eqref{eq:adv_poloidal} would be kept together.\\

As described in \cite{emily} and \cite{Latu_2017}, we then obtain solution operators to each sub-system by the SL method, which will shortly be introduced in the next chapter. For now, we denote them by $A,B$ and $C$ solving the equations \eqref{eq:adv_flux}, \eqref{eq:adv_par} and \eqref{eq:adv_poloidal} for a given time-step and potential $\phi$ respectively.
For a time step $\Delta \tau \in \bR$, the first-order Lie splitting of $f^n = f(t = n \Delta \tau)$ reads
\begin{equation}
	f^{n+1/2} = C\left(\frac{\Delta \tau}{2}\right) B\left(\frac{\Delta \tau}{2}\right) A\left(\frac{\Delta \tau}{2}\right) f^n, \label{eq:Lie}
\end{equation}
while the second-order Strang splitting is given by
\begin{equation}
	f^{n+1} = A\left(\frac{\Delta \tau}{2}\right) B\left(\frac{\Delta \tau}{2}\right) C\left(\Delta \tau\right) B\left(\frac{\Delta \tau}{2}\right) A\left(\frac{\Delta \tau}{2}\right) f^n. \label{eq:Strang}
\end{equation}
So far, we assumed that we have a good approximation of the potential $\phi$ at hand. In practice, this is obtained by solving the QN equation i.e. \eqref{eq:qn} by a spectral Finite Element method (FEM) combined with some Finite Difference (FD) approximations. Since this is not the main part of our work, we refer to the sources above for more details.

In total, the iterative predictor-corrector solution procedure $f^n \rightarrow f^{n+1}$ can be described as follows:
\begin{enumerate}
	\item Given $f^n$, obtain $\phi$ from solving \eqref{eq:qn}.
	\item Given $\phi$, obtain $f^{n+1/2}$ by applying \eqref{eq:Lie}. (predictor step)
	\item Given $f^{n+1/2}$, obtain $\phi$ from solving \eqref{eq:qn} again.
	\item Given $\phi$, obtain $f^{n+1}$ by applying \eqref{eq:Strang}. (corrector step)
\end{enumerate}

This approach has shown to be quite successful, which inter alia is due to the unconditional stability of the SL scheme. Nonetheless, the method lacks structure preserving properties, like conservation of energy and $L^2$-norm. This gives rise to the main idea of this project, which exchanges the non-restrictive time-stepping of the SL method for the structure preservation of an AKW FD scheme, at least for the slow-time subsystem, where a time-step restriction is supposed to not be too computationally expensive. In other words, we solve the poloidal advection equation i.e. \eqref{eq:adv_poloidal} by applying the AKW scheme combined with a suitable time-integration. Since this advection equation essentially consists of a Poisson bracket, which is rich in geometric structure - exactly what the AKW scheme was designed for - we aim at improving the overall conservation properties of the full simulation.







\subsection{Semi-Lagrangian Scheme for the Fast Time Subsystem}
%TODO: What are the conservation properties of the SL scheme
%TODO: Are these good sources?
Recapitulating the semi-Lagrangian method, mostly referring to the overview given in \cite{campospinto}, we will start from the general formulation, where the goal is to solve an advection problem of the form
\begin{equation}
    \partial_t f(t,\mathbf{x})+v(t,\mathbf{x})\cdot \nabla f(t,\mathbf{x})=0, \qquad t\in[0,T], \quad \mathbf{x}\in\mathbb{R}^d, \label{eq:adv_toy}
\end{equation}
where $v$ is a velocity field $\mathbb{R}^d\longrightarrow\mathbb{R}^d$, $T > 0$ is the final time and initial conditions are given by $f_0(\mathbf{x})=f(t = 0,\mathbf{x})$. Assuming that $v$ is a given and smooth vector-field, we can use the method of characteristics, i.e. obtaining trajectories $X(t)=X(t;s,x)$ that are solutions to the ODE
\begin{equation}
    X'(t)=v(t,X(t)), \qquad X(s)=x, \qquad t\in[0,T],
\end{equation}
for $\bx \in \bR^d$ and $s \in [0,T]$. It can be shown that the flow $F_{s,t}:x\longrightarrow X(t)$ is invertible and satisfies $(F_{s,t})^{-1}=F_{t,s}$. Thus, we can derive the analytical solution to equation \eqref{eq:adv_toy} as
\begin{equation}
    f(t,\mathbf{x})=f_0((F_{0,t})^{-1}(\bx)),\qquad  t\in[0,T], \quad \mathbf{x}\in\mathbb{R}^d.
\end{equation}
This implies, given two consecutive time-steps $t_n$ and $t_{n+1}$, we can define the backwards flow
\begin{equation}
    B^{n,n+1}=(F_{t_n,t_{n+1}})^{-1},
\end{equation}
in order to advance the solution $f^n$ from time $t_n$ to time $t_{n+1}$, i.e. $f^{n+1} = f^n \circ B^{n, n+1}$. So far, the derivation has been completely analytical. In practice however, we have to introduce approximation errors for discretizing the distribution $f$, e.g. a Spline interpolation on a grid, and for the backwards flow $B$, which generally depends on the discretization of the vector-field $v$.\\

Now we are in the position to apply this methodology to the flux surface and $\vp$-advection, which is, again, discussed in \cite{emily} and \cite{Latu_2017}. For the flux surface advection equation \eqref{eq:adv_flux}, i.e.
%TODO: Do we have to recall that equation here? or is ref enough
\begin{equation}
 \partial_t f + v_\parallel \nabla_\parallel f = 0,
\end{equation}
where we remind that $\nabla_\parallel = \bb \cdot \nabla$. This is a one-dimensional constant velocity advection with velocity $\vp \bb$ on the flux surface $(\theta, z)$ for each given $r$. Thus, we can construct an analytical two-dimensional SL operator, that uses the exact trajectory as the velocity is not related to the flux surface. On the other hand, the $v$-parallel advection operator defined by equation \eqref{eq:adv_par}, i.e.
\begin{equation}
    \partial_t f + \nabla_\parallel \phi\,\, \partial_{v_{\parallel}} f = 0,
\end{equation}
 contains the parallel gradient of $\phi$ which only depends on the spatial coordinates and is therefore constant along $v_\parallel$. As a result, the trajectory used by this one-dimensional SL method can be accurately defined, while the parallel gradient of $\phi$ is computed using a field-aligned FD method. \\
 
When implementing the method, we work on a four dimensional computational grid on which the point values of the distribution functions and potentials for the different time-stages are known or calculated.
Both advection steps use special interpolation techniques, since we will not end up exactly on grid points when tracing back the characteristics, such that they are at least of order three. Additionally, we have to take account for boundary conditions, when the characteristics move outside the computational domain, extending it by extrapolation for instance. \\







\subsection{Arakawa Scheme for the Slow Time Subsystem}
\label{sec:AKW}
Introducing the Arakawa scheme, we mainly reference the original article \cite{Arakawa_1966}, where one is interested in the spatial two-dimensional discretization of the differential equation
\begin{equation}
	\partial_t f + \{\phi, f\} = 0, \label{eq:br_ode}
\end{equation}
where $\phi$ is a given potential and $\{\phi,f\}$ is a Poisson bracket of the form
\begin{equation}\label{eq:poisson_bracket}
	\{\phi,f\} = -  \left(\partial_x\phi\right) \left(\partial_y f\right) + \left(\partial_y\phi\right) \left(\partial_x f\right) \, .
\end{equation}

The main aim of this scheme is the conservation of the following properties
\begin{subequations}\label{conservation-properties}
	\begin{align}
		\text{Mass} : && \dt \int f(t) \d x \text{d} y & = 0 & \Leftrightarrow && \int\bracket{\phi}{f} \d x \text{d} y & = 0 \, , \label{eq:consv_1}\\
		L^2\text{-norm :} && \dt \int f^2(t) \d x \text{d} y & = 0 & \Leftrightarrow && \int f \, \bracket{\phi}{f} \d x \text{d} y & = 0 \, , \\
		\text{Total energy :} && \dt \int \phi \, f(t) \d x \text{d} y & = 0 & \Leftrightarrow && \int \phi \bracket{\phi}{f} \d x \text{d} y & = 0 \, ,
	\end{align}
\end{subequations}
which is deeply embedded in its construction. Albeit we are interested in the application of the scheme in polar coordinates, i.e. a change of coordinates in the Poisson bracket c.f. equation \eqref{eq:bracket_in_polar}, we will for simplicity start with the construction in Cartesian coordinates since conceptionally it does make no difference.



\subsubsection{Construction of the Discrete Bracket}
\label{sec:const_stenc}
Given a two-dimensional grid $(x_i, y_j)$ for $0 \le i \le N_x, 0 \le j \le N_y$ with a uniform grid size $d >0$, we simplify notation by writing $g_{i,j} = g(x_i, y_j)$ for any function $g$ evaluated at the point $(x_i, y_j)$ and write the collection of point-values as discrete function $g_h$. Denoting the Poisson bracket by 
\begin{equation} \label{eq:J-bracket}
	J(f, g) = \{f, g\}
\end{equation} and following \cite{Arakawa_1966}, we can approximate it at any point $(x_i, y_j)$ as a certain linear combination of the following nine-point stencils, that amounts to
\begin{equation}
	J(f,g)=J_1(f_h, g_h)+\mathcal{O}(d^2), \quad \text{ where } \quad J_1 = \frac{1}{3}(J_1^{++}+J_1^{+\times}+J_1^{\times+}),
\end{equation}
with the stencils defined as
\begin{equation}
	\begin{aligned}
    J_1^{++}& =\frac{1}{4d^2}\left[(f_{i+1,j}-f_{i-1,j})(g_{i,j+1}-g_{i,j-1}) \right. \\
	& \hspace{11mm}  \left.-(f_{i,j+1}-f_{i,j-1})(g_{i+1,j}-g_{i-1,j})\right], \label{eq:stencil1}
	\end{aligned}
\end{equation}
as well as
\begin{equation}
    \begin{aligned}
    	J_1^{+\times} & = \frac{1}{4d^2} \left[ f_{i+1,j} (g_{i+1,j+1} - g_{i+1,j-1}) - f_{i-1,j} (g_{i-1,j+1} - g_{i-1,j-1}) \right. \\
    	& \hspace{11mm} \left. - f_{i,j+1} (g_{i+1,j+1} - g_{i-1,j+1}) + f_{i,j-1}(g_{i+1,j-1} - g_{i-1,j-1}) \right],
    \end{aligned}
\end{equation}
and
\begin{equation}
    \begin{aligned}
    	J_1^{\times+} & = \frac{1}{4d^2} \left[ f_{i+1,j+1} (g_{i,j+1} - g_{i+1,j}) - f_{i-1,j-1} (g_{i-1,j} - g_{i,j-1}) \right. \\
    	& \hspace{11mm} \left. - f_{i-1,j+1} (g_{i,j+1} - g_{i-1,j}) + f_{i+1,j-1} (g_{i+1,j} - g_{i,j-1}) \right].
    \end{aligned}
\end{equation}
This approximation is proven to be the only FD second order approximation of the analytical Poisson bracket that conserves mass, $L^2$-norm and energy for an isotropic mesh. The $+$ and $\times$ notation comes from the patterns done by the FD stencils on the grid, as is visualized in Figure \ref{fig:stencils}. So for example in $J_1^{+\times}$, we choose the $+$-pattern, which corresponds to two central FD schemes, for the discretization of $\partial_x f_{i,j}$ and $\partial_y f_{i,j}$ and the same with the $\times$-pattern for $g_{i,j}$, then multiply the two together getting a discretization of the bracket \eqref{eq:poisson_bracket}.


% Figure environment removed

In order to continue these considerations to fourth order, we introduce $J_2(f_h, g_h)=\frac{1}{3}(J_2^{\times \times} + J_2^{\times+} + J_2^{+\times})$, where we now use the extended twelve point-stencils with the additional
four points $(i+2,j)$, $(i-2,j)$, $(i,j+2)$ and $(i,j-2)$, visualized in Figure \ref{fig:stencils}, such that
\begin{equation}
\begin{aligned}
	J_2^{\times\times} &= \frac{1}{8d^2} \left[(f_{i+1,j+1} - f_{i-1,j-1}) (g_{i-1,j+1} - g_{i+1,j-1}) \right. \\
	& \hspace{11mm} - \left. (f_{i-1,j+1} - f_{i+1,j-1}) (g_{i+1,j+1} - g_{i-1,j-1}) \right] \, ,
\end{aligned}
\end{equation}
as well as
\begin{equation}
	\begin{aligned}
		J_2^{\times+} & = \frac{1}{8d^2} \left[ f_{i+1,j+1} (g_{i,j+2} - g_{i+2,j}) - f_{i-1,j-1} (g_{i-2,j} - g_{i,j-2}) \right. \\
		& \hspace{11mm} \left. - f_{i-1,j+1} (g_{i,j+2} - g_{i-2,j}) + f_{i+1,j-1} (g_{i+2,j} - g_{i,j-2})\right] \, ,
	\end{aligned}
\end{equation}
and
\begin{equation}
	\begin{aligned}
		J_2^{+\times} & = \frac{1}{8d^2} \left[f_{i+2,j} (g_{i+1,j+1} - g_{i+1,j-1}) - f_{i-2,j} (g_{i-1,j+1} - g_{i-1,j-1}) \right. \\
		& \hspace{11mm} \left. - f_{i,j+2} (g_{i+1,j+1} - g_{i-1,j+1}) + f_{i,j-2} (g_{i+1,j-1} - g_{i-1,j-1})\right] \, . \label{eq:stencil2}
	\end{aligned}
\end{equation}
In total, we can now approximate the Poisson bracket $J$ at any point on the grid by
\begin{equation}
	J(f,g) = 2J_1(f_h, g_h)-J_2(f_h, g_h) + \mathcal{O}(d^4),
\end{equation}
up to fourth order while conserving all the desired quantities above as is shown in \cite{Arakawa_1966}. This leads us to define the discrete Poisson bracket $J_h$ on any point of the grid as
\begin{equation} \label{order4-disc-bracket}
	J_{h}(f_h, g_h) = 2J_1(f_h, g_h) - J_2(f_h, g_h),
\end{equation}
thus being able to spatially discretize equation \eqref{eq:br_ode} as
\begin{equation}
	\partial_t f_h = - J_h(\phi_h, f_h),
\end{equation}
such that the right-hand-side is approximated up to order four. By construction, this skew-symmetric discrete bracket satisfies the algebraic properties
\begin{subequations}
	\begin{align}
		\sum_{i,j} J_{h, (i,j)}(\phi_h, f_h) d^2 &= 0,  \\
		\sum_{i,j} f_{i,j} J_{h, (i,j)}(\phi_h, f_h) d^2 &= 0, \\
		\sum_{i,j} \phi_{i,j} J_{h, (i,j)}(\phi_h, f_h) d^2&= 0, 
	\end{align}
\end{subequations}
as is calculated in \cite{Arakawa_1966}, which leads to 
\begin{subequations}
	\begin{align}
		\partial_t \sum_{i,j}  f_{i,j} d^2&= 0,  \\
		\partial_t \sum_{i,j}  f_{i,j}^2 d^2 &= 0, \\
		\partial_t \sum_{i,j}  (\phi f)_{i,j} d^2 &= 0,
	\end{align}
\end{subequations}
where $\partial_t \phi = 0$. This the discrete analogous of the conservation properties of the equations \eqref{conservation-properties}.
% \begin{subequations}
% 	\begin{align}
% 		\frac{\dd}{\dd t} \int f_h \ \dd x \dd y &= \frac{\d}{\d t} \sum_{i,j} f_{i,j} \ d^2  = - \int J_h(\phi, f) \ \dd x \dd y = -\sum_{i,j} J_{h, (i,j)}(\phi, f) \ d^2 = 0, \label{eq:consv_1} \\
% 		\frac{\dd}{\dd t} \int f^2 \ \dd x \dd y &= - \int f J_h(\phi, f) \ \dd x \dd y \approx -\sum_{i,j} f_{i,j} J_{h, (i,j)}(\phi, f) \ d^2 = 0, \\
% 		\frac{\dd}{\dd t} \int \phi f \ \dd x \dd y &= - \int \phi J_h(\phi, f) \ \dd x \dd y \approx -\sum_{i,j} \phi_{i,j} J_{h, (i,j)}(\phi, f) \ d^2 = 0. \\
% 	\end{align}
% \end{subequations}





\subsubsection{Boundary Conditions} \label{sec:BC}

For points close to or on the boundary of the computational grid, the stencil might use points outside the domain that need to be defined. This is a problem that has to be tackled by introducing boundary conditions (BC) or locally reformulating the stencils. The stencils involve two functions in two spatial variables each, where each direction can be treated individually as we will see shortly and where the motivation comes from the physical properties described in Section \ref{sec:gk-model}. Importantly, the choice of boundary conditions also influences the conservation of mass, $L^2$-norm and energy.

The easiest option is taking periodic BC, as defined in \cite{Arakawa_1966}, where $x_{N_x + 1} = x_1, x_{N_x + 2} = x_2, x_{0} = x_{N_x}, x_{-1} = x_{N_x-1}$, etc. and the same for the $y$-direction. Looking at the stencils \eqref{eq:stencil1}-\eqref{eq:stencil2}, this leaves us only with interior points, where the function-values are known. For our model, this BC is used when looking at point sequences along the $\theta$ direction for both functions as physically this variable is periodic as described in Section \ref{sec:gk-model}.

Secondly, we can define homogeneous Dirichlet BC, i.e. the function values on or outside  the boundary of the grid are equal zero. This means for the stencils \eqref{eq:stencil1}-\eqref{eq:stencil2}, whenever an index is smaller two or greater $N_{x/y}-1$, the corresponding function value is set equal zero. Thus, we end up with reduced stencils, if the point is close to a grid boundary. We will apply this technique to the $r$-direction of the potential $\phi$, which is supposed to be zero outside the interior as described in Section \ref{sec:gk-model}.

Finally, we want to introduce extrapolatory BC; knowing the function values on the boundary and outside the grid, we can directly impose them in the stencils. To make that more precise, we assume $f$ outside the interior of the domain in one variable direction $x$ is known and described by the equilibrium function $f_\text{eq}$. Note that $f_\text{eq}$ still has to fulfil the BC in the other variable direction as we use its values on the boundary. In other words, we directly define the stencils \eqref{eq:stencil1}-\eqref{eq:stencil2}, with the outside values
\begin{equation}
	f_{i, j} = f_\text{eq}(x_i, y_i) \qquad \text{for} \quad  i< 1, i > N_x,  1 \le j \le N_y,
\end{equation}
 where the points in $x$-direction are linearly extended by $d$, e.g. $x_{-1} = x_1 - 2d$. This is exactly the situation of the radial direction of the distribution function $f$ in our model, with an equilibrium function $f_\text{eq}$ that is periodic in $\theta$, c.f. Section \ref{sec:gk-model}.

In \cite{crouseilles2018exponential}, these different kinds of BC with respect to conservation their properties are discussed in more detail, albeit only for the second-order scheme. They show that only the purely periodic BC have perfect conservation properties, for the others one still conserves mass, $L^2$-norm and energy well, but not up to machine precision as there is a small error introduced at the boundary. By their numerical experiments, the AKW scheme works best when combining theses different BC, where they conclude the same combination as we proposed above.





\subsubsection{Transformation to Polar Coordinates}\label{sec:consv-props}
\label{sec:polar}
The original AKW scheme \cite{Arakawa_1966} and all our considerations so far were formulated in Cartesian coordinates on an isotropic mesh, i.e. $\Delta x = \Delta y$. When going to an anisotropic mesh, the convergence order of the stencils still holds true, as we calculate in Appendix \ref{app:Order_of_Arakawa_stencil}. However, the gyro-kinetic model and \texttt{PyGyro} code in \cite{pygyro_code} to which we want to apply the Arakawa scheme, are also formulated in polar coordinates $(r,\theta, z, v_\parallel)$. Transforming the previous part to polar coordinates, we first introduce a polar grid $(r_i, \theta_j)$ for $0 \le i \le N_r, 0 \le j \le N_\theta$ with grid-increments $\Delta r >0$ and $\Delta \theta > 0$. The polar bracket $\{\cdot, \cdot\}^p$ of our model is given by \eqref{eq:bracket_in_polar}, dropping the constant $B_0$, which is different to the 
bracket $\{\cdot, \cdot\}^c$ in Cartesian coordinates from \eqref{eq:poisson_bracket} by a factor of $r$. 
This is due to a change of metric coming from the coordinate transformation from Cartesian to polar coordinates, i.e.
\begin{align}
	x  = r \cos(\theta), \qquad y  = r \sin(\theta),
\end{align}
which gets more clear when looking at the quantities under the integral: 
\begin{subequations}
	\begin{align}
		\int\bracket{\phi}{f}^c \d x \d y &= \int\bracket{\phi}{f}^p r \d r \d \theta, \\
		\Longleftrightarrow   \int  \left[ -\left(\partial_x\phi\right) \left(\partial_y f\right) + \left(\partial_y\phi\right) \left(\partial_x f\right) \right]  \d x \d y &=  \int \left[- \frac{1}{r} \left(\partial_\theta\phi\right) \left(\partial_r f\right) + \frac{1}{r} \left(\partial_r\phi\right) \left(\partial_\theta f\right)\right] r \d r \d \theta, \\
		\Longleftrightarrow  \int J^c(f, \phi)  \d x \d y &= \int J^p(f, \phi) r \d r \d \theta,
	\end{align}
\end{subequations}
where $J^c$ is defined in \eqref{eq:J-bracket} and 
\[ J^p(f,g) = \left[- \frac{1}{r} \left(\partial_\theta\phi\right) \left(\partial_r f\right) + \frac{1}{r} \left(\partial_r\phi\right) \left(\partial_\theta f\right)\right] .\] 
Analogous to the previous Section \ref{sec:const_stenc}, we define the discrete bracket at any point of the polar grid as
\begin{equation}
	J^p_{h, (i,j)}(f_h, g_h) = \frac{1}{r_i} J^c_{h, (i,j)}(f_h, g_h),
\end{equation}
from which we obtain the discrete conserved quantities 
\begin{align} \label{eq:pol_cons_quant}
	 \sum_{i,j}  f_{i,j} r_i \Delta r \Delta \theta = 0,  \qquad \sum_{i,j}  f_{i,j}^2 r_i \Delta r \Delta \theta  = 0, \qquad \sum_{i,j}  (\phi f)_{i,j} r_i \Delta r \Delta \theta  = 0,
\end{align}
for mass, $L^2$-norm and energy respectively. As before, their conservation is equivalent to the equations 
\begin{subequations}\label{eq:alg_prop}
	\begin{align} 
		\sum_{i,j} J^p_{h, (i,j)}(\phi_h, f_h) r_i \Delta r \Delta \theta &= 0,  \\
		\sum_{i,j} f_{i,j} J^p_{h, (i,j)}(\phi_h, f_h) r_i \Delta r \Delta \theta &= 0, \\
		\sum_{i,j} \phi_{i,j} J^p_{h, (i,j)}(\phi_h, f_h) r_i \Delta r \Delta \theta &= 0. 
	\end{align}
\end{subequations}