\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{achituve2021self}
Idan Achituve, Haggai Maron, and Gal Chechik.
\newblock Self-supervised learning for domain adaptation on point clouds.
\newblock In {\em WACV}, 2021.

\bibitem{crosspoint}
Mohamed Afham, Isuru Dissanayake, Dinithi Dissanayake, Amaya Dharmasiri,
  Kanchana Thilakarathna, and Ranga Rodrigo.
\newblock Crosspoint: Self-supervised cross-modal contrastive learning for 3d
  point cloud understanding.
\newblock In {\em CVPR}, pages 9902--9912, June 2022.

\bibitem{beit}
Hangbo Bao, Li Dong, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock {\em arXiv preprint arXiv:2106.08254}, 2021.

\bibitem{berthelot2019mixmatch}
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital
  Oliver, and Colin~A Raffel.
\newblock Mixmatch: A holistic approach to semi-supervised learning.
\newblock {\em NeruIPS}, 2019.

\bibitem{carreira2017quo}
Joao Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em CVPR}, 2017.

\bibitem{shapenet}
Angel~X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang,
  Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et~al.
\newblock Shapenet: An information-rich 3d model repository.
\newblock {\em arXiv preprint arXiv:1512.03012}, 2015.

\bibitem{SimCLR}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock {\em arXiv preprint arXiv:2006.10029}, 2020.

\bibitem{chen2020improved}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{PRANet}
Silin Cheng, Xiwu Chen, Xinwei He, Zhe Liu, and Xiang Bai.
\newblock Pra-net: Point relation-aware network for 3d point cloud analysis.
\newblock {\em IEEE TIP}, 30:4436--4448, 2021.

\bibitem{choy2019minkowski}
Christopher Choy, JunYoung Gwak, and Silvio Savarese.
\newblock 4d spatio-temporal convnets: Minkowski convolutional neural networks.
\newblock In {\em CVPR}, 2019.

\bibitem{collobert2008unified}
Ronan Collobert and Jason Weston.
\newblock A unified architecture for natural language processing: Deep neural
  networks with multitask learning.
\newblock In {\em ICML}, 2008.

\bibitem{dai2017scannet}
Angela Dai, Angel~X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and
  Matthias Nie{\ss}ner.
\newblock Scannet: Richly-annotated 3d reconstructions of indoor scenes.
\newblock In {\em CVPR}, 2017.

\bibitem{dong2022act}
Runpei Dong, Zekun Qi, Linfeng Zhang, Junbo Zhang, Jianjian Sun, Zheng Ge, Li
  Yi, and Kaisheng Ma.
\newblock Autoencoders as cross-modal teachers: Can pretrained 2d image
  transformers help 3d representation learning?
\newblock {\em arXiv preprint arXiv:2212.08320}, 2022.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{SimpleView}
Ankit Goyal, Hei Law, Bowei Liu, Alejandro Newell, and Jia Deng.
\newblock Revisiting point cloud shape classification with a simple and
  effective baseline.
\newblock In {\em ICML}, 2021.

\bibitem{graham2018sparseconv}
Benjamin Graham, Martin Engelcke, and Laurens Van Der~Maaten.
\newblock 3d semantic segmentation with submanifold sparse convolutional
  networks.
\newblock In {\em CVPR}, 2018.

\bibitem{MVTN}
Abdullah Hamdi, Silvio Giancola, and Bernard Ghanem.
\newblock {MVTN:} multi-view transformation network for 3d shape recognition.
\newblock In {\em ICCV}, 2021.

\bibitem{mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÂ´ar, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock {\em arXiv preprint arXiv:2111.06377}, 2021.

\bibitem{moco}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em CVPR}, 2020.

\bibitem{huang2023learning}
Tianxin Huang, Zhonggan Ding, Jiangning Zhang, Ying Tai, Zhenyu Zhang, Mingang
  Chen, Chengjie Wang, and Yong Liu.
\newblock Learning to measure the point cloud reconstruction loss in a
  representation space.
\newblock In {\em CVPR}, 2023.

\bibitem{johnson2016perceptual}
Justin Johnson, Alexandre Alahi, and Li Fei-Fei.
\newblock Perceptual losses for real-time style transfer and super-resolution.
\newblock In {\em ECCV}. Springer, 2016.

\bibitem{klokov2017escape}
Roman Klokov and Victor Lempitsky.
\newblock Escape from cells: Deep kd-networks for the recognition of 3d point
  cloud models.
\newblock In {\em ICCV}, 2017.

\bibitem{li2018pointcnn}
Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di, and Baoquan Chen.
\newblock Pointcnn: Convolution on x-transformed points.
\newblock {\em NeurIPS}, 2018.

\bibitem{liu2022masked}
Haotian Liu, Mu Cai, and Yong~Jae Lee.
\newblock Masked discrimination for self-supervised learning on point clouds.
\newblock In {\em ECCV}. Springer, 2022.

\bibitem{liu2020morphing}
Minghua Liu, Lu Sheng, Sheng Yang, Jing Shao, and Shi-Min Hu.
\newblock Morphing and sampling network for dense point cloud completion.
\newblock In {\em AAAI}, 2020.

\bibitem{loshchilov2016sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock {\em arXiv preprint arXiv:1608.03983}, 2016.

\bibitem{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2018.

\bibitem{pointmlp}
Xu Ma, Can Qin, Haoxuan You, Haoxi Ran, and Yun Fu.
\newblock Rethinking network design and local geometry in point cloud: A simple
  residual mlp framework.
\newblock In {\em ICLR}, 2022.

\bibitem{maturana2015voxnet}
Daniel Maturana and Sebastian Scherer.
\newblock Voxnet: A 3d convolutional neural network for real-time object
  recognition.
\newblock In {\em IROS}. IEEE, 2015.

\bibitem{misra20213detr}
Ishan Misra, Rohit Girdhar, and Armand Joulin.
\newblock An end-to-end transformer model for 3d object detection.
\newblock In {\em ICCV}, 2021.

\bibitem{pang2022masked}
Yatian Pang, Wenxiao Wang, Francis~EH Tay, Wei Liu, Yonghong Tian, and Li Yuan.
\newblock Masked autoencoders for point cloud self-supervised learning.
\newblock In {\em ECCV}. Springer, 2022.

\bibitem{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em NeurIPS}, 2019.

\bibitem{pointnet}
Charles~R Qi, Hao Su, Kaichun Mo, and Leonidas~J Guibas.
\newblock Pointnet: Deep learning on point sets for 3d classification and
  segmentation.
\newblock In {\em CVPR}, 2017.

\bibitem{pointnet2}
Charles~R Qi, Li Yi, Hao Su, and Leonidas~J Guibas.
\newblock Pointnet++ deep hierarchical feature learning on point sets in a
  metric space.
\newblock In {\em NeurIPS}, 2017.

\bibitem{qi2023recon}
Zekun Qi, Runpei Dong, Guofan Fan, Zheng Ge, Xiangyu Zhang, Kaisheng Ma, and Li
  Yi.
\newblock Contrast with reconstruct: Contrastive 3d representation learning
  guided by generative pretraining.
\newblock {\em arXiv preprint arXiv:2302.02318}, 2023.

\bibitem{pointnext}
Guocheng Qian, Yuchen Li, Houwen Peng, Jinjie Mai, Hasan Hammoud, Mohamed
  Elhoseiny, and Bernard Ghanem.
\newblock Pointnext: Revisiting pointnet++ with improved training and scaling
  strategies.
\newblock In {\em NeurIPS}, 2022.

\bibitem{drnet}
Shi Qiu, Saeed Anwar, and Nick Barnes.
\newblock Dense-resolution network for point cloud classification and
  segmentation.
\newblock In {\em WACV}, 2021.

\bibitem{GBNet}
Shi Qiu, Saeed Anwar, and Nick Barnes.
\newblock Geometric back-projection network for point cloud classification.
\newblock {\em IEEE TMM}, 2022.

\bibitem{ran2022repsurf}
Haoxi Ran, Jun Liu, and Chengjie Wang.
\newblock Surface representation for point clouds.
\newblock In {\em CVPR}, 2022.

\bibitem{riegler2017octnet}
Gernot Riegler, Ali Osman~Ulusoy, and Andreas Geiger.
\newblock Octnet: Learning deep 3d representations at high resolutions.
\newblock In {\em CVPR}, 2017.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em CVPR}, 2022.

\bibitem{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em IJCV}, 2015.

\bibitem{Jigsaw3D}
Jonathan Sauder and Bjarne Sievers.
\newblock Self-supervised deep learning on point clouds by reconstructing
  space.
\newblock {\em NeurIPS}, 2019.

\bibitem{simonyan2014vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{su2015multi}
Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik Learned-Miller.
\newblock Multi-view convolutional neural networks for 3d shape recognition.
\newblock In {\em ICCV}, 2015.

\bibitem{tarvainen2017mean}
Antti Tarvainen and Harri Valpola.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock {\em NeurIPS}, 2017.

\bibitem{thomas2019KPConv}
Hugues Thomas, Charles~R. Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui,
  Fran{\c{c}}ois Goulette, and Leonidas~J. Guibas.
\newblock Kpconv: Flexible and deformable convolution for point clouds.
\newblock {\em ICCV}, 2019.

\bibitem{uy2019revisiting}
Mikaela~Angelina Uy, Quang-Hieu Pham, Binh-Son Hua, Duc~Thanh Nguyen, and
  Sai-Kit Yeung.
\newblock Revisiting point cloud classification: A new benchmark dataset and
  classification model on real-world data.
\newblock In {\em ICCV}, 2019.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{occo}
Hanchen Wang, Qi Liu, Xiangyu Yue, Joan Lasenby, and Matt~J Kusner.
\newblock Unsupervised point cloud pre-training via occlusion completion.
\newblock In {\em ICCV}, 2021.

\bibitem{wang2019dynamic}
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay~E Sarma, Michael~M Bronstein, and
  Justin~M Solomon.
\newblock Dynamic graph cnn for learning on point clouds.
\newblock {\em TOG}, 2019.

\bibitem{wang2022p2p}
Ziyi Wang, Xumin Yu, Yongming Rao, Jie Zhou, and Jiwen Lu.
\newblock P2p: Tuning pre-trained image models for point cloud analysis with
  point-to-pixel prompting.
\newblock In {\em NeurIPS}, 2022.

\bibitem{wu2021balanced}
Tong Wu, Liang Pan, Junzhe Zhang, Tai Wang, Ziwei Liu, and Dahua Lin.
\newblock Balanced chamfer distance as a comprehensive metric for point cloud
  completion.
\newblock In {\em NeurIPS}, 2021.

\bibitem{wu2022ptv2}
Xiaoyang Wu, Yixing Lao, Li Jiang, Xihui Liu, and Hengshuang Zhao.
\newblock Point transformer v2: Grouped vector attention and partition-based
  pooling.
\newblock In {\em NeurIPS}, 2022.

\bibitem{modelnet}
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang,
  and Jianxiong Xiao.
\newblock 3d shapenets: A deep representation for volumetric shapes.
\newblock In {\em CVPR}, 2015.

\bibitem{xie2020self}
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc~V Le.
\newblock Self-training with noisy student improves imagenet classification.
\newblock In {\em CVPR}, 2020.

\bibitem{pointcontrast}
Saining Xie, Jiatao Gu, Demi Guo, Charles~R Qi, Leonidas Guibas, and Or Litany.
\newblock Pointcontrast: Unsupervised pre-training for 3d point cloud
  understanding.
\newblock In {\em ECCV}, 2020.

\bibitem{xu2021image2point}
Chenfeng Xu, Shijia Yang, Tomer Galanti, Bichen Wu, Xiangyu Yue, Bohan Zhai,
  Wei Zhan, Peter Vajda, Kurt Keutzer, and Masayoshi Tomizuka.
\newblock Image2point: 3d point-cloud understanding with 2d image pretrained
  models.
\newblock {\em arXiv preprint arXiv:2106.04180}, 2021.

\bibitem{shapenetpart}
Li Yi, Vladimir~G Kim, Duygu Ceylan, I-Chao Shen, Mengyan Yan, Hao Su, Cewu Lu,
  Qixing Huang, Alla Sheffer, and Leonidas Guibas.
\newblock A scalable active framework for region annotation in 3d shape
  collections.
\newblock {\em ToG}, 2016.

\bibitem{yu2021pointr}
Xumin Yu, Yongming Rao, Ziyi Wang, Zuyan Liu, Jiwen Lu, and Jie Zhou.
\newblock Pointr: Diverse point cloud completion with geometry-aware
  transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{yu2022point}
Xumin Yu, Lulu Tang, Yongming Rao, Tiejun Huang, Jie Zhou, and Jiwen Lu.
\newblock Point-bert: Pre-training 3d point cloud transformers with masked
  point modeling.
\newblock In {\em CVPR}, 2022.

\bibitem{zhai2022scaling}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In {\em CVPR}, 2022.

\bibitem{pointm2ae}
Renrui Zhang, Ziyu Guo, Peng Gao, Rongyao Fang, Bin Zhao, Dong Wang, Yu Qiao,
  and Hongsheng Li.
\newblock Point-m2ae: multi-scale masked autoencoders for hierarchical point
  cloud pre-training.
\newblock {\em arXiv preprint arXiv:2205.14401}, 2022.

\bibitem{zhang2023I2PMAE}
Renrui Zhang, Liuhui Wang, Yu Qiao, Peng Gao, and Hongsheng Li.
\newblock Learning 3d representations from 2d pre-trained models via
  image-to-point masked autoencoders.
\newblock In {\em CVPR}, 2023.

\end{thebibliography}
