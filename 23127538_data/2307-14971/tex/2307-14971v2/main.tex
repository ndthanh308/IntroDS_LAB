\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}

\usepackage{multirow}
\usepackage{amsthm,amsmath,amssymb,lipsum}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{textcomp}

\usepackage{color}
\def\eg{{\it{e.g.}}}
\def\etal{{\it{et al.}}}
\def\ie{{\it{i.e.}}}


\DeclareMathOperator{\softmax}{Softmax}
\DeclareMathOperator{\MCS}{MCS}
\DeclareMathOperator{\MACS}{MACS}
\DeclareMathOperator{\KNN}{KNN}
\DeclareMathOperator{\Percent}{\ensuremath{P@10^\circ}}
\newcommand{\paragrapha}[2]{\vspace{#1}\noindent\textbf{#2}}

\newcommand\cb[1]{\color{blue} #1}
\newcommand\cred[1]{\color{red} #1}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\definecolor{Gray}{gray}{0.95}
\definecolor{Gray7}{gray}{0.75}
\newcommand\grey[1]{\color{Gray7} #1}
\newcommand\bk[1]{\color{black} #1}


% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{adjustbox}
\usepackage{subcaption}
% \usepackage{caption}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{5236} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
% \ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models}

\author{
    Ziyi Wang\thanks{Equal contribution. ~\textsuperscript{\dag}Corresponding author.} ~~~~
  	Xumin Yu$^*$ ~~
	Yongming Rao ~~
	Jie Zhou ~~~
	Jiwen Lu$^{\dagger}$      \\
    Department of Automation, Tsinghua University, China\\
    {\tt\small \{wziyi22, yuxm20\}@mails.tsinghua.edu.cn;} \\{\tt\small raoyongming95@gmail.com; \{jzhou, lujiwen\}@tsinghua.edu.cn} \\
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
   With the overwhelming trend of mask image modeling led by MAE, generative pre-training has shown a remarkable potential to boost the performance of fundamental models in 2D vision. However, in 3D vision, the over-reliance on Transformer-based backbones and the unordered nature of point clouds have restricted the further development of generative pre-training. In this paper, we propose a novel 3D-to-2D generative pre-training method that is adaptable to any point cloud model. We propose to generate view images from different instructed poses via the cross-attention mechanism as the pre-training scheme. Generating view images has more precise supervision than its point cloud counterpart, thus assisting 3D backbones to have a finer comprehension of the geometrical structure and stereoscopic relations of the point cloud. Experimental results have proved the superiority of our proposed 3D-to-2D generative pre-training over previous pre-training methods. Our method is also effective in boosting the performance of architecture-oriented approaches, achieving state-of-the-art performance when fine-tuning on ScanObjectNN classification and ShapeNetPart segmentation tasks. Code is available at \url{https://github.com/wangzy22/TAP}.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{chapters/1-introduction.tex}
\input{chapters/2-related_work.tex}
\input{chapters/3-method.tex}
\input{chapters/4-experiments.tex}
\input{chapters/5-conclusion.tex}

\section*{Acknowledgement}
This work was supported in part by the National Key Research and Development Program of China under Grant 2022ZD0114903 and in part by the National Natural Science Foundation of China under Grant 62125603.

\newpage
\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{ref}
}

\newpage
\clearpage
\input{chapters/6-appendix}

\end{document}
