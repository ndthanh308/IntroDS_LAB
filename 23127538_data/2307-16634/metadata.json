{
  "title": "CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification",
  "authors": [
    "Rabab Abdelfattah",
    "Qing Guo",
    "Xiaoguang Li",
    "Xiaofeng Wang",
    "Song Wang"
  ],
  "submission_date": "2023-07-31T13:12:02+00:00",
  "revised_dates": [
    "2024-03-07T05:05:15+00:00"
  ],
  "abstract": "This paper presents a CLIP-based unsupervised learning method for annotation-free multi-label image classification, including three stages: initialization, training, and inference. At the initialization stage, we take full advantage of the powerful CLIP model and propose a novel approach to extend CLIP for multi-label predictions based on global-local image-text similarity aggregation. To be more specific, we split each image into snippets and leverage CLIP to generate the similarity vector for the whole image (global) as well as each snippet (local). Then a similarity aggregator is introduced to leverage the global and local similarity vectors. Using the aggregated similarity scores as the initial pseudo labels at the training stage, we propose an optimization framework to train the parameters of the classification network and refine pseudo labels for unobserved labels. During inference, only the classification network is used to predict the labels of the input image. Extensive experiments show that our method outperforms state-of-the-art unsupervised methods on MS-COCO, PASCAL VOC 2007, PASCAL VOC 2012, and NUS datasets and even achieves comparable results to weakly supervised classification methods.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16634",
  "pdf_url": "https://arxiv.org/pdf/2307.16634v2",
  "comment": "Accepted in ICCV2023",
  "num_versions": null,
  "size_before_bytes": 30200563,
  "size_after_bytes": 299607
}