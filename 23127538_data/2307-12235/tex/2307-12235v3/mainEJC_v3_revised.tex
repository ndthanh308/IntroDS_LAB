\documentclass[preprint,number,12pt]{elsarticle}  % review al posto di preprint,number etc.

% PACKAGES
\usepackage{amssymb}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{lipsum}
\usepackage{color}
\usepackage{hyperref} %lineno,
%\modulolinenumbers[5]
%\renewcommand{\linenumberfont}{\normalfont\bfseries\small\color{white}}

\journal{European Jornal of Control}

\usepackage{comment}
\usepackage{siunitx}
%\usepackage{lineno}


%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%


% COMMANDS
\newcommand{\GFa}[1]{\textcolor{magenta}{#1}}
\newcommand{\MFa}[1]{\textcolor{black}{#1}}
\newcommand{\ACe}[1]{\textcolor{red}{#1}}
\newcommand{\rev}[1]{\textcolor{black}{#1}}

% Theorem commands
\newtheorem{Def}{\textbf{Definition}}
\newtheorem{Lem}{\textbf{Lemma}}
\newtheorem{theorem}{\textbf{Theorem}}
\newtheorem{prop}{\textbf{Proposition}}
\newtheorem{rmk}{\textbf{Remark}}
\newtheorem{corollary}{\textbf{Corollary}}
\newtheorem{conjecture}{\textbf{Conjecture}}


%%%%%%%%%%%%%%%%%%%%%%%
%Notation
\newcommand{\aaa}{\mathbf{a}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\cc}{\mathbf{c}}
\newcommand{\drm}{\mathrm{d}}
\newcommand{\ee}{\mathbf{e}}
\newcommand{\ff}{\mathbf{f}}
\newcommand{\qq}{\mathbf{q}}
\newcommand{\rr}{\mathbf{r}}
\newcommand{\sss}{\mathbf{s}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\ww}{\mathbf{w}}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\psps}{\boldsymbol{\psi}}
\newcommand{\uups}{\boldsymbol{\upsilon}}
\newcommand{\lamlam}{\boldsymbol{\lambda}}

\newcommand{\xx}{\mathbf{x}}
\newcommand{\xith}{\x_{i}}
\newcommand{\xjth}{\x_{j}}
\newcommand{\pp}{\mathbf{p}}
\newcommand{\pith}{\p_{i}}
\newcommand{\pjth}{\p_{j}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\uith}{\u_{i}}
\newcommand{\ujth}{\u_{j}}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\yith}{\y_{i}}
\newcommand{\yjth}{\y_{j}}

\newcommand{\Aa}{\mathbf{A}}
\newcommand{\Bb}{\mathbf{B}}
\newcommand{\Cc}{\mathbf{C}}
\newcommand{\Dd}{\mathbf{D}}
\newcommand{\Ee}{\mathbf{E}}
\newcommand{\Ii}{\mathbf{I}}
\newcommand{\Kk}{\mathbf{K}}
\newcommand{\Ll}{\mathbf{L}}
\newcommand{\Mm}{\mathbf{M}}
\newcommand{\Nn}{\mathbf{N}}
\newcommand{\Pp}{\mathbf{P}}
\newcommand{\Qq}{\mathbf{Q}}
\newcommand{\Rr}{\mathbf{R}}
\newcommand{\Ss}{\mathbf{S}}
\newcommand{\Pipi}{\boldsymbol{\Pi}}
\newcommand{\xixi}{\boldsymbol{\xi}}
\newcommand{\varpipi}{\boldsymbol{\varpi}}
\newcommand{\Zz}{\mathbf{O}}
\newcommand{\Thth}{\boldsymbol{\Theta}}
\newcommand{\omom}{\boldsymbol{\omega}}
\newcommand{\Omom}{\boldsymbol{\Omega}}

\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\vc}[1]{\mathrm{vec}\left({#1}\right)}
\newcommand{\vci}[2]{\mathrm{vec}_{i=1}^{#2}({#1})}
\newcommand{\vcj}[2]{\mathrm{vec}_{j=1}^{#2}({#1})}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\eto}[1]{\mathrm{e}^{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\renewcommand{\imath}{\boldsymbol{\mathrm{i}}}
\renewcommand{\circ}{\mathrm{circ}}
\newcommand{\mathmnsc}[1]{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\mathcalligra{#1}}}}}\hspace{2.2pt}}
\newcommand{\mathmnscfr}[1]{\mathlarger{\mathmnsc{#1}}}
\newcommand{\randic}{\pmb{\mathcalligra{R}}\hspace{2.5pt}}
\newcommand{\costth}{\mathrm{c}_{2\theta}}

\newcommand{\rk}{\mathrm{rk}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\adj}{\mathrm{adj}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Diag}{\mathrm{Diag}}
\newcommand{\vol}{\mathrm{vol}}
\newcommand{\rig}{\boldsymbol{\mathcal{R}}}

\newcommand{\colvec}[2][.9]{%
	\scalebox{#1}{%
		\renewcommand{\arraystretch}{.9}%
		$\begin{bmatrix}#2\end{bmatrix}$%
	}
}

%%%%%%%%%%%%%%%%%%%%%%%



\begin{document}

\begin{frontmatter}

\title{Optimal Time-Invariant Distributed Formation Tracking for Second-Order Multi-Agent Systems} %\tnoteref{mytitlenote}
%\tnotetext[mytitlenote]{Fully documented templates are available in the elsarticle package on \href{http://www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}{CTAN}.}

%% Group authors per affiliation:
\author{Marco Fabris\fnref{myfootnote}, Giulio Fattore and Angelo Cenedese}
\address{Department of Information Engineering, University of Padova, via Gradenigo 6/B, Padova, 35131, Italy.}
\fntext[myfootnote]{M.~Fabris, G.~Fattore and A.~Cenedese are with the Department of Information Engineering at the University of Padova (UNIPD - DEI), Padova, 35131, Italy (e-mails: marco.fabris.1@unipd.it, giulio.fattore@phd.unipd.it, angelo.cenedese@unipd.it). A.~Cenedese is also with the Institute of Electronics, Information and Telecommunication Engineering, National Research Council (CNR - IEIIT).}

%% or include affiliations in footnotes:
%\author[mymainaddress,mysecondaryaddress]{Marco Fabris}
%\ead[url]{www.elsevier.com}
%
%\author[mysecondaryaddress]{Marco Fabris\corref{mycorrespondingauthor}}
%\cortext[mycorrespondingauthor]{Corresponding author}
%\ead{support@elsevier.com}
%
%\address[mymainaddress]{1600 John F Kennedy Boulevard, Philadelphia}
%\address[mysecondaryaddress]{360 Park Avenue South, New York}
	
\begin{abstract}
This paper addresses the optimal time-invariant formation tracking problem with the aim of providing a distributed solution for multi-agent systems with second-order integrator dynamics. In the literature, most of the results related to multi-agent formation tracking do not consider energy issues while investigating distributed feedback control laws. 
In order to account for this crucial design aspect, we contribute by formalizing and proposing a solution to an optimization problem that encapsulates trajectory tracking, distance-based formation control and input energy minimization, through a specific and key choice of potential functions in the optimization cost. 
To this end, we show how to compute the inverse dynamics in a centralized fashion by means of the Projector-Operator-based Newton's method for Trajectory Optimization (PRONTO) and, more importantly,  we exploit such an offline solution as a general reference to devise a stabilizing online distributed control law. 
Finally, numerical examples involving a cubic formation following a chicane-like path in the 3D space are provided to validate the proposed control strategies.
\end{abstract}

\begin{keyword}
%\texttt{elsarticle.cls}\sep \LaTeX\sep Elsevier \sep template
Formation tracking \sep Agents and autonomous systems \sep Optimal control \sep Network Analysis and Control.
\end{keyword}

\end{frontmatter}

%\linenumbers


%\linenumbers

\section{Introduction}\label{sec:intro}

% Over the last years, distributed control of multi-agent systems (MAS) has received considerable attention in numerous and diverse scientific communities, due to its open theoretical challenges and extensive application fields (see, for example, \cite{MesbahiEgerstedt2010,LiDuan2015}).

Over the last years, distributed control of multi-agent systems (MASs) has received considerable attention in numerous and diverse scientific communities, due to its open theoretical challenges and extensive application fields~\cite{MesbahiEgerstedt2010,LiDuan2015}. 
A MAS consists of a set of autonomous agents that take decisions and communicate information thanks to their ability to sense the environment and are able to cooperate and perform complex tasks that a single individual may not be fit to complete~\cite{rizk2019cooperative}. 
%Examples are found in multi-robot manipulation and transportation~\cite{BelbachirAmalCasals2019,ShiraniNajafiIzadi2019}, autonomous vehicle platooning and rendezvous~\cite{Stryszowski2021AFramework,OzsoyellerBeveridgeIsler2019}, power distribution and load management in smart grids~\cite{Uzakov2020UAV,WangGovindarasu2020}, measurement synchronization and reconciliation in sensor networks \cite{RedhuHedge2019}, surveillance and monitoring in camera networks~\cite{DuSunCao2017,ZhengShi2020}, environment exploration and mapping by unmanned vehicles~\cite{GengZhouDing2018,HeBaiLiang2018,WangChengXiao2020}, to name some.

%\textit{Related works}: 
When considering a multitude of robotic agents, tasks related to trajectory optimization, path planning, and formation stabilization arise, which require solution approaches that trade-off between the requirements and constraints of both individual agents and the overall ensemble. 
%~\cite{LiXieYan2017,ChuPengWen2018,PengSunGeng2019,WangLeiHuang2019}. 
% FC & FT
In this context, a general and overarching canonical problem to be addressed is that of formation control (FC)~\cite{anderson2008rigid}, which spans from the creation and maintenance of a given spatial MAS shape (also referred to as formation producing or stabilization, FS) to the coordinated motion of the MAS configuration along a trajectory (also referred to as formation tracking, FT)~\cite{ahn2020book}. 
%
In the extremely vast and multi-faceted literature related to FC, some common interesting aspects can be identified.
%
For example, the specific features of FC depend on the level of interaction within the MAS, namely if the approach is centralized~\cite{HauserCook2016}, distributed~\cite{Hu2021ADecentralized, bishop2015distributed},
%zhao2014distributed,
or leader-follower~\cite{trinh2018bearing, Franchi2019Online}, and on the control and sensing capabilities of the agents, basically distinguishing among position/distance information~\cite{OhParkAhn2015, ChuangHuangDOrsogna2007}, orientation/bearing information~\cite{eren2012formation, michieletto2021unified} ~\cite{zili2022ACCbearing}, or both~\cite{bishop2015distributed}.
%
Moreover, in order to implement these procedures and paradigms, 
%and accommodate the diverse requirements of a MAS formation,
%since the convergence to and the maintenance of a formation depend on the trade-off between single dynamics behaviors, collision avoidance, and agent dispersion, 
FC can exploit flexible optimization approaches \cite{yan2018optimally, Hu2021ADecentralized, yan2022optimal} and make use of potential-based functions~\cite{ChuangHuangDOrsogna2007,  HauserCook2016} or alternatively, it resorts to formal geometrical approaches as those related to rigidity theory~\cite{anderson2008rigid, michieletto2021unified}\cite{xu2020affine}.% DOrsognaChuangBertozzi2006
% zhao2018affine,

Delving more specifically into the FT problem, it may be observed how leader-follower schemes provide a popular approach to make a multiagent formation follow a desired trajectory while preserving inter-distances or bearing measurements, with the constraints imposed by the specific dynamics.  
% LEADER-FOLLOWER
For example, in~\cite{SalinasBricarie2017} a control strategy for ground robots with first-order dynamics is devised, where a leader agent is aware of the desired position and velocity of the formation and hence it is tasked with trajectory tracking, while the other (follower) agents arrange collision-free formation creation and maintenance. 
%
Leader and follower agents are also considered in~\cite{zhao2019bearing} with reference to bearing-only measurements and different classes of MASs, and in~\cite{Minh2021RobustTC} the approach is extended to also account for measurement uncertainties.
%
Along this line, while keeping the same control strategy, specific attention on the sensing part is given in~\cite{hu2010distributed}, where a distributed estimation solution is proposed to mitigate the presence of noisy measurements, and in\cite{Duan2020FinitetimeTO}, where the attention is placed on the followers estimation capability in finite-time, assuming heterogeneous linear systems. 
Also, in~\cite{YangCaoGarcia2018}, it is presented a distributed approach to FT that leverages an estimation strategy to obtain information on a virtual leader representing the formation centroid. 
%
An in-principle similar solution is discussed in~\cite{brinon2014cooperative}, where it is decoupled the problem of FS from that of FT: the former is obtained through consensus, while the latter is pursued through barycenter tracking. 
A leader-follower strategy is also employed in \cite{liu2014finite}, in which the authors exploit optimal control techniques to develop a trajectory tracking with a rigid formation, limiting, though, their analysis to the planar case with first-order dynamics.

The research in \cite{ZhangZhouWang2022} examines the issue of bipartite time-varying output formation tracking in heterogeneous MASs with multiple leaders and switching communication networks, taking into account the possibility of connected or disconnected networks. To tackle this challenge, a new approach is introduced, which involves a reduced-dimensional observer-based fully distributed asynchronous dynamic edge-event-triggered output feedback control protocol. %This protocol effectively eliminates Zeno behavior.
%
With respect to fully distributed control, the approaches based on a physical leader-follower structure require either an additional procedure for the leader election~\cite{Franchi2019Online} or an a-priori or online selection based on the MAS features~\cite{Dong2017Time-Varying}.
%
%\MFa{
	Remarkably, the formulation of an optimal problem that refers to the MAS properties and control variables allows combining both the performance aspects related to the FT task and the more practical aspects brought in by the physical features of the MAS of interest, thus leading to efficiency and feasibility of the control solution.
	%
	For example, the geometry of the formation is specifically addressed in~\cite{LiuZhaoChen2016} and~\cite{PengSunGeng2019} to guarantee the consistency of a MAS whose agent states and behavior dynamics are defined in the special Euclidean group SE(3).
	%
	On the other hand, the practical actuation requirements of a robotic cooperative system are considered with reference to a group of underactuated autonomous underwater vehicles in~\cite{LiXieYan2017}, where an optimization approach based on the so-called receding horizon algorithm is exploited to accommodate saturation issues. 
	%
	%
	%
	However, in the latter works, as well as in the majority of the surveyed literature, %the energy consumption of the system is not taken into consideration, 
    the simultaneous optimization of formation, tracking, and energy consumption is generally overlooked,
    even though this may represent a crucial design principle impacting both the task completion effectiveness and the control action efficiency.
	%
	%
	%
	%\todo[inline]{               }
	%
	%
	%
	%While FS aims at forming and maintaining a given spatial configuration for a MAS of interest, FT also focuses on driving such formation along a desired trajectory~\cite{Dong2017Time-Varying,Duan2020FinitetimeTO,Peng2021OptimalTC}. 
	%
	%
	%Nonetheless, similarly to FC, the problem of FT has been faced in several fashions. 
	%For instance, controllers that take into account actions proportional to the position and velocity disagreement vectors have been extensively designed, analysed and successfully implemented in MASs with a second-order integrator~\cite{Zuo2015}. 
	%
	%
	%In \cite{ChuPengWen2018}, an event-triggered strategy is employed to guarantee multi-robot systems to produce desired geometric configurations from arbitrary initial positions and orientations for each robot, while the centroid of formation can follow one dynamic reference trajectory. 
	%
	%
	%The adaptive quantized controller design for the FT of unmanned aerial vehicles is also studied in \cite{WangLeiHuang2019}.}\\
%\MFa{Despite the large variety of methods in the literature, the most common approach in FT rests upon the ``leader-follower'' paradigm, (see e.g.~\cite{Minh2021RobustTC,LiuZhaoChen2016}). 
	%}

%\BEl{
	%canonical problems need to be addressed related to the MAS formation by means of cooperative control techniques, namely those related to Formation Control~(FC) and Formation Tracking~(FT): specifically, FC aims at forming and maintaining a given spatial configuration for a MAS of interest~\cite{ahn2020book}, while FT aims at driving such formation along a desired trajectory~\cite{Dong2017Time-Varying,Duan2020FinitetimeTO,Peng2021OptimalTC}. 
	% FC
	%A large variety of FC problems and solutions can be encountered in the literature, where the specific features depend on the interaction and sensing capabilities of the considered MAS agents: %as in the early overview \cite{AndersonYuFidan2008} 
	%for example, in the survey~\cite{OhParkAhn2015}, the authors discern among distance-based, displacement-based, and position-based FC according to the types of controlled and sensed variables. 
	%
	%The control approaches may be centralized~\cite{HauserCook2016}, distributed~\cite{zhao2014distributed,Hu2021ADecentralized, bishop2015distributed, yan2022optimal, anderson2008rigid}, or based on a leader follower approach~\cite{trinh2018bearing, Franchi2019Online}.
	%
	%Moreover, since the convergence to and the maintenance of a formation depends on the trade-off between single dynamics behaviors, collision avoidance, and agent dispersion, many models in FC exploit potential-based functions~\cite{ChuangHuangDOrsogna2007, HauserCook2016} % DOrsognaChuangBertozzi2006
	%or more general optimization approaches \cite{yan2018optimally,Hu2021ADecentralized} in order to implement one of the aforementioned paradigms.
	%%
	%\todo[inline]{Optimization approaches are also present in ...}
	%%
	%Despite the research effort so far, FC still leads to open challenges in which the aim is represented by the accomplishment of prescribed constraints on the states belonging to the multiple agents involved~\cite{trinh2018bearing,mwaffo2021formation,Yan2021RobustFC,Hu2021ADecentralized}.
	% FT
	%Similarly, also the problem of FT has been faced in several fashions: controllers that take into account actions proportional to the position and velocity disagreement vectors have been extensively designed, analysed and successfully implemented in multi-agent systems with a second-order integrator~\cite{Zuo2015}, 
	%\todo[inline]{...\cite{LiXieYan2017}
		%\\...\cite{ChuPengWen2018}
		%\\...\cite{PengSunGeng2019} \\...\cite{WangLeiHuang2019}}
	%although the most common approach is based on the ``leader-follower'' paradigm, as also in recent literature~\cite{Franchi2019Online, Minh2021RobustTC}.
	%
	%The leader-follower approach is also adopted in  \cite{LiuZhaoChen2016} where both FC and FT problems are considered under an optimal framework, focusing on a finite-time convergence and in \cite{SalinasBricarie2017} where again FC and FT are framed together for time varying formations. 
	%
	%A distributed approach to FT is present, for example, in \cite{YangCaoGarcia2018} leveraging an estimator-controller strategy to obtain the formation knowledge and drive its shape.
	%
	%Nowadays, large part of the literature addresses both these aspects together \cite{LiuZhaoChen2016,SalinasBricarie2017,YangCaoGarcia2018}.
	%However, in this latter work, as well as in the majority of the surveyed literature, the energy consumption of the system is not taken into examination in detail, even though it may represent a crucial design principle. 
	%}


\textit{Contributions}: Given this premise, in this paper we propose a novel approach to FT in which the problem is formulated based on a time-invariant optimal control objective where three different tasks are considered, namely that of tracking a given path at the group level, attaining a desired (and feasible) geometric formation while minimizing the input energy. Compared to the work in \cite{yu2022adaptive}, the approach we pursue is fully distributed and attains finite time optimal control.
%
Also, differently from \cite{Dong2017Time-Varying, dong2019TVswitching} in which the network topology is a switching one, 
%to consider a more realistic scenario, 
here we consider a more realistic scenario by allowing for the presence of communication constraints in the system of mobile robots, whenever the information exchange between a pair of agents is not ensured. Moreover, unlike \cite{loria2016leaderfollower,dong2017TVswitching} in which one or more leader agent are identified, our work is developed assuming the absence of hierarchy among the agents.
%
More specifically, we build on our previous work~\cite{FabrisCenedeseHauser2019}, where the optimization framework called PRONTO (PRojection Operator based Newton's method for Trajectory Optimization) was successfully adopted to obtain inverse dynamics to steer a MAS towards the desired formation along the chosen path. \rev{Then, following the Pontryagin's Maximum Principle (PMP) \cite{Pontryagin2018},} we devise in the present work an online networked strategy
%based on a practically optimal 
resting on a \rev{PMP}-based distributed feedback control law.
%
% Moreover, to consider a more realistic scenario, here we allow for the presence of communication constraints in the system of mobile robots, whenever the information exchange between a pair of agents is not ensured. %In order to provide a real-time solution for such a formalization, we devise an online networked strategy based on a practically optimal distributed feedback control law.


\textit{Outline}: The remainder of the paper is organized as follows. 
Sec.~\ref{sec:problem_setup} deals with the general setup, providing the basic notation and describing the adopted multi-agent models and dynamics.
The first part of Sec.~\ref{sec:numerical_methodologies_for_OIFT} introduces, in a general way, how the FT problem of interest can be formulated and optimally solved in a centralized fashion by using PRONTO; whereas, in the second part, the derivation of a stabilizing online distributed feedback controller is presented. 
Lastly, Sec.~\ref{sec:numerical_simulations} illustrates some numerical results, providing a validation of the proposed approach and interesting remarks, and Sec.~\ref{sec:conclusions} sketches out future directions for this research.

%In the scientific community, a significant research effort has focused on the control of multi-agent systems and its mathematical foundation on graph-based networks~\cite{MesbahiEgerstedt2010}. 
%Open challenges can be categorized as either formation control problems (with applications to mobile robots, autonomous underwater vehicles, satellites and spacecraft systems, automated highway and unmanned air vehicles, e.g. \cite{SchianoFranchiZelazo2016}-\cite{FathianDoucetteCurtis2018}), or other cooperative control problems such as role assignment, payload transport, air traffic control, timing, search and synchronization (e.g. \cite{CenedeseFavarettoOccioni2016}).\\
%Formation Control generally aims to drive multiple agents to achieve prescribed constraints on their states. Depending on the sensing and the interaction capabilities of the agents, a variety of formation control problems can be found in the literature (see \cite{AndersonYuFidan2008} for an excellent overview on the subject). 
%; however, a considerable amount of studies have been conducted thereafter. 
%Nonetheless, creation and maintenance of a formation needs to trade off with single dynamics behaviors, collision avoidance, and dispersion~\cite{HauserCook2016}. 
%In \cite{Reynolds1987}, an agent model that implements simple laws (separation, cohesion and alignment) to abide these targets is introduced, thus determining the behavior of each agent within the group. 
%These and similar laws often resort to a potential that determines the pairwise interactions among the agents, and along this line, many formation control algorithms adopt a formulation that contains an attractive part to maintain the swarm cohesion and a repulsive one to avoid agent collision (as the Morse potential in \cite{DOrsognaChuangBertozzi2006}-\cite{ChuangHuangDOrsogna2007}).
%; nevertheless, there exist different approaches based on Quasi-Morse potentials \cite{CarrilloMartinPanferov2013}, for which flock and rotating mills states can be observed numerically and the corresponding macroscopic equations allow for explicit solutions. 
%Stability and pattern formation of a prototypical system of self-propelled individuals interacting through pairwise attractive and repulsive potentials have been widely discussed in \cite{DOrsognaChuangBertozzi2006}. 
%More generally, authors in \cite{OhParkAhn2015} discuss results on Formation Control discerning among position-based, displacement-based and distance-based according to the types of sensed and controlled variables. 
%In particular, the last approach is that adopted in this work and can be defined in a framework where inter-agent distances are actively controlled to achieve the desired formation, which is defined through the specific inter-agent distances. Finally, in this respect, it is worth to highlight that several novel achievements have been developing by using distance-based control laws and an extensive part of that research has been dedicated to Formation Tracking \cite{SalinasBricarie2017}-\cite{YangCaoGarcia2018}. 

%\subsubsection*{Contributions and outline of the paper} Many recent works developed for autonomous vehicles exploit Trajectory Optimization to perform maneuver regulation and motion planning, even in constrained environments. Practically, the employment of direct methods for the minimization of a cost functional represent a fundamental approach to provide solutions to this kind of problems: numerical tools, such as the PRojection Operator based Newton's method for Trajectory Optimization (PRONTO), have been successfully implemented in several instances \cite{BayerHauser2012}-\cite{AguiarPedroBayer2017}. At the light of this consideration, we propose here a novel application of PRONTO that aims at computing a solution for an optimization problem combining aspects of trajectory tracking, formation control and energy minimization.

%In the remainder of the paper, Sections \ref{sec:problem_setup} and \ref{sec:numerical_methodologies_for_OIFT} describe how the specific problem of Formation Tracking can be formulated and solved by using PRONTO. Then, Sections \ref{sec:numerical_simulations} and \ref{sec:conclusions} show some numerical simulations, providing a validation of the proposed approach, interesting remarks and future directions for this research.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{General setup}\label{sec:problem_setup}
In this section, the models and assumptions are provided to formalize the optimal time-invariant formation tracking (OIFT) problem, enriching the setup introduced in~\cite{FabrisCenedeseHauser2019}. In addition, communication topology constraints are taken into account for the development of a related distributed control law.

%In this section, we report the models and the assumptions related to the agents' dynamics, as well as we provide the formalization of an optimal control problem that encapsulates distinct (and often conflicting) tasks such as trajectory tracking, time-invariant formation control and input energy minimization, enriching the description of the approach developed in~\cite{FabrisCenedeseHauser2019}. 
%We therefore address the optimal time-invariant formation tracking (OIFT) problem, with the aim of finding a potential-based solution by minimizing a global cost functional able to capture simultaneously all the different assignments. 
%In this context, communication topology constrains are taken into consideration and along with the application of PRONTO as a centralized optimization framework, the development of a distributed feedback control law accomplishing these tasks represents a crucial goal for this study.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Multi-agent model and basic notation}
The multi-agent system under analysis is topologically represented by an undirected graph $\mathcal{G} = (\mathcal{V},\mathcal{E})$ formed by the set of nodes $\mathcal{V}$ and the set of edges $\mathcal{E}$. 
%
Each node of $\mathcal{V}$ is simply addressed with index $i = 1,\ldots,n$, where $n = |\mathcal{V}|$ is the cardinality of $\mathcal{V}$ and node $i$ is referred to as the $i$-th agent. Also, node $i$ is allowed to exchange information with node $j$ if and only if there exists an edge $(i,j)=(j,i)$ contained in $\mathcal{E}$. 
%
We assume that $\mathcal{G}$ is connected, i.e. there exists a collection of edges that link each node $i$ to any other node $j \neq i$. The neighborhood of node $i$ is defined as the set $\mathcal{N}_{i} = \{j\in \mathcal{V}|(i,j)\in \mathcal{E}\}$. 
%
%Assuming an order for all elements in set $\mathcal{E}$, the incidence matrix $\Ee \in \mathbb{R}^{n \times |\mathcal{E}|}$ of $\mathcal{G}$ is defined as follows: $[\Ee]_{ik} = 1$ the $k$-th edge $(i,j)$ is arbitrarily oriented outward w.r.t. $i$, $[\Ee]_{ik} = -1$ the $k$-th edge $(i,j)$ is arbitrarily oriented inward w.r.t. $i$, $[\Ee]_{ik} = 0$, otherwise. Denoting with $\top$ the transpose operator, matrix $\Ll = \Ee \Ee^{\top}$ is referred to as the Laplacian of graph $\mathcal{G}$.
Lastly, the Laplacian matrix associated to $\mathcal{G}$ is defined as $\mathbf{L}=\mathbf{D}-\mathbf{A}$, where $\mathbf{A}\in \mathbb{R}^{n\times n}$ denotes the adjacency matrix of $\mathcal{G}$, such that $[\mathbf{A}]_{ij} = 1$ if $(i,j) \in \mathcal{E}$; $[\mathbf{A}]_{ij} = 0$ otherwise, and $\mathbf{D}\in \mathbb{R}^{n\times n}$ denotes the degree matrix of $\mathcal{G}$, such that $\mathbf{D}$ is diagonal and $[\mathbf{D}]_{ii} = \sum_{j=1}^{n} [\mathbf{A}]_{ij}$.
%\todo[inline]{\ACe{avendo un grafo undirected l'orientamento degli edge non c'\`e e per scrivere il Laplaciano dobbiamo dare un orientamento *arbitrario*... chiarire nel testo sopra!}}
The remaining basic notation follows.

The set of real numbers is indicated by $\mathbb{R}$ and a similar symbology is straightforwardly employed for further subsets or extensions of $\mathbb{R}$ itself. The class of $k$-continuously differentiable %-continuous
functions is identified with $\mathscr{C}^{k}$.

The identity matrix of dimension $\natural \in \mathbb{N}$ is denoted by $\Ii_{\natural}$, while $\Zz_{\natural_{1}\times \natural_{2}}$ addresses the zero matrix with dimensions $\natural_{1}\times \natural_{2} \in \mathbb{N} \times \mathbb{N}$. Moreover, if $\natural_{1}= \natural_{2}=\natural$ symbol $\Zz_{\natural}$ is used instead of $\Zz_{\natural_{1}\times \natural_{2}}$, while the zero vector of dimension $\natural$ is denoted by $\mathbf{0}_{\natural}$. The rank of a matrix is expressed by the operator $\rk$. Symbols $\succeq 0$, $\succ 0$, and $\left\|\cdot \right\|_{2}$ stand for positive semidefinite, positive definite, and Euclidean norm, respectively. Whereas, $\left\|\psps\right\|_{\Omom}^{2} $ defines the quadratic form $\psps^{\top}\Omom \psps$, where $\psps$ and $\Omom \succ 0$ generically indicate real-valued vector and a real-valued matrix, respectively.
Two kinds of vectorization operators are defined: $\mathrm{vec}$ and $\mathrm{vec}_{i=1}^{\natural}$. The former either takes all its vector arguments $\psps_{1} ,\dots, \psps_{\natural}$ and stack them into a single vector $ \vc{\psps_{1} ,\dots, \psps_{\natural}} = [\psps_{1}^{\top} ~\cdots~ \psps_{\natural}^{\top}]^{\top}$ or transforms the columns of a matrix $\Omom = [\omom_{1} ~\cdots~ \omom_{\natural}]$ into the vector $\vc{\Omom}=[\omom_{1}^{\top} ~\cdots~ \omom_{\natural}^{\top}]^{\top}$. The latter, instead, constructs the stack vector $\vci{\psps_{i}}{\natural} = [\psps_{1}^{\top} ~\cdots~ \psps_{\natural}^{\top}]^{\top}$ starting from a given vector family $\{\psps\}_{i=1}^{\natural} = \{\psps_{1} ,\dots, \psps_{\natural}\}$. The block-diagonal operator that maps the family of real matrices $\{\Omom\}_{i=1}^{\natural} = \{\Omom_{1},\dots,\Omom_{\natural}\}$ into its associated diagonal matrix is denoted with $\Omom = \mathrm{Diag}(\Omom_{1},\dots,\Omom_{\natural})$. 

Variable $t\geq 0$ specifies the continuous time instants, while symbol $(\cdot)$ denotes a trajectory as $t$ spans interval $[0,T]$, for a chosen $T>0$. Symbols $\nabla_{*}$ and $\mathcal{H}_{**}$ indicate standard gradient and Hessian operators w.r.t. some generic variable~$*$. Finally, symbol $\dot{\nabla}_{*}$ is equivalent to $\dfrac{\drm}{\drm t} \nabla_{*}$.


\subsection{Dynamics of the agents}
We suppose that $n\geq 2$ robotic agents with linear dynamics are already deployed in an environment space of dimension $M$, such that $M\in \left\lbrace 1,2,3\right\rbrace  $. We also assume that each agent $i$ is aware of its absolute position $\mathbf{p}_{i} =\mathbf{p}_{i}(t) \in \mathbb{R}^{M}$ and velocity $\dot{\mathbf{p}}_{i}\in \mathbb{R}^{M}$ and can be governed by means of a regulation on its absolute acceleration $\uu_i=\ddot{\mathbf{p}}_{i}(t)\in \mathbb{R}^{M}$. 
%\footnote{This problem could be analogously formulated whenever nonlinear models characterize the agents' dynamics. In the latter case, only few further restrictions on the smoothness of the function describing the evolution of the system would be required.}. 
Setting $N=nM$, the expressions of the state $\mathbf{x}\in \mathbb{R}^{2N}$ and the input $\mathbf{u}\in \mathbb{R}^{N}$ for this group of mobile elements are provided respectively by
\begin{align*}
	\mathbf{x} &= \begin{bmatrix}
		\mathbf{p}_{1}^{\top} & \dots & \mathbf{p}_{n}^{\top} & \dot{\mathbf{p}}_{1}^{\top} & \dots & \dot{\mathbf{p}}_{n}^{\top} 
	\end{bmatrix}^{\top} = \begin{bmatrix}
		\mathbf{p}^{\top} & \dot{\mathbf{p}}^{\top}
	\end{bmatrix}^{\top};\\
	\mathbf{u} &= 
	\begin{bmatrix}
        \ddot{\mathbf{p}}_{1}^{\top} & \dots & \ddot{\mathbf{p}}_{n}^{\top}
	\end{bmatrix}^{\top} = \ddot{\mathbf{p}}.
\end{align*}
Equivalently, exploiting the vectorization operators, one has $\pp = \vci{\pp_{i}}{n}$, $\dot{\pp} = \vci{\dot\pp_{i}}{n}$, $\xx = \vc{\pp,\dot{\pp}}$ and $\uu = \vci{\uu_{i}}{n}$.

Differently from \cite{FabrisCenedeseHauser2019}, we assume that the state information is not globally accessible for each agent in the online control law to be provided so that only a local estimate of the centroid position $\mathbf{p}_{c} =  n^{-1} \sum_{i=1}^{n} \mathbf{p}_{i}$ and velocity $\dot{\mathbf{p}}_{c}$ is available to each agent $i$ at each time $t$. For this reason, the undirected graph $\mathcal{G}$ representing the communication network among the agents is supposed to be connected. Also, we set
$\mathbf{x}_{c} = \vc{\mathbf{p}_{c},\dot{\mathbf{p}}_{c}}$,
%\begin{equation*}
%\mathbf{x}_{B} = \begin{bmatrix}
	%\mathbf{p}_{B}^{\top} & \dot{\mathbf{p}}_{B}^{\top}
	%\end{bmatrix}^{\top},
	%\end{equation*}
	with $\mathbf{x}_{c}\in \mathbb{R}^{2M}$. %, to be treated as an output for this linear dynamics.
	Since we desire to steer the agents by controlling their positions and velocities through their accelerations, the classic double integrator model is chosen. 
	The latter model is described by the following linear state-space equations with second-order integrator dynamics % adopted as \MFa{change the output thing}
	%
	\begin{equation}\label{eq:dyn_sys}
		\begin{cases}
			\dot{\mathbf{x}}(t) = \mathbf{A} \mathbf{x}(t) + \mathbf{B} \mathbf{u}(t)\\
			\xx(0) = \mathbf{x}_{0} \in \mathbb{R}^{2N}
		\end{cases}, \qquad \xx_{c}= \mathbf{C}\mathbf{x};
	\end{equation}
	%
	where the state matrix $\mathbf{A}\in \mathbb{R}^{2N\times 2N}$, the input matrix $\mathbf{B}\in \mathbb{R}^{2N\times N}$ and the centroid matrix $\mathbf{C} \in \mathbb{R}^{2M\times 2N}$ take the form  
	%
	%\begin{equation*}
	%\left(\mathbf{A},\mathbf{B}\right) = \left(\begin{bmatrix}
		%\mathbf{Z}_{N} & \mathbf{I}_{N}\\
		%\mathbf{Z}_{N} & \mathbf{Z}_{N}
		%\end{bmatrix}, \begin{bmatrix}
		%\mathbf{Z}_{N}\\
		%\mathbf{I}_{N}
		%\end{bmatrix}\right)
		%\end{equation*}
		%and
		%\begin{equation*}
		%\mathbf{C} = \dfrac{1}{n} \begin{bmatrix}
			%\mathbf{I}_{M} & \dots & \mathbf{I}_{M} & \mathbf{Z}_{M} & \dots & \mathbf{Z}_{M}\\
			%\mathbf{Z}_{M}  & \dots &  \mathbf{Z}_{M} & \mathbf{I}_{M} & \dots & \mathbf{I}_{M} 
			%\end{bmatrix},
			%\end{equation*}
			%
			\begin{equation*}
					%
					\mathbf{A}=\begin{bmatrix}
						\Zz_{N} & \mathbf{I}_{N}\\
						\Zz_{N} & \Zz_{N}
					\end{bmatrix}, 
					%
					\quad
					%
					\mathbf{B} = \begin{bmatrix}
						\Zz_{N}\\
						\mathbf{I}_{N}
					\end{bmatrix},
					%
					\quad
					%
					\mathbf{C} = \dfrac{1}{n} \begin{bmatrix}
						\mathbf{I}_{M} & \cdots & \mathbf{I}_{M} & \Zz_{M} & \cdots & \Zz_{M}\\
						\Zz_{M}  & \cdots &  \Zz_{M} & \mathbf{I}_{M} & \cdots & \mathbf{I}_{M} 
					\end{bmatrix}.
			\end{equation*}
			%
			%Furthermore, it is worth to recall that the centroid $\xx_{c}= \mathbf{C}\mathbf{x}$ is a linear combination of the state $\xx$, where matrix $\mathbf{C} \in \mathbb{R}^{2M\times 2N}$ is given by
			%
			%\begin{equation*}
			%	\mathbf{C} = \dfrac{1}{n} \begin{bmatrix}
			%		\mathbf{I}_{M} & \cdots & \mathbf{I}_{M} & \Zz_{M} & \cdots & \Zz_{M}\\
			%		\Zz_{M}  & \cdots &  \Zz_{M} & \mathbf{I}_{M} & \cdots & \mathbf{I}_{M} 
			%	\end{bmatrix}.
			%\end{equation*}
			%
			%where $\mathbf{I}_{\natural}$ indicates the identity matrix of dimensions $\natural \times \natural$, $\Zz_{\natural_{1}\times \natural_{2}}$ denotes null matrices of dimensions $\natural_{1}\!\times\!\natural_{2}$ and if $\natural_{1}\!=\!\natural_{2}\!=\!\natural$ the convention $\Zz_{\natural\times \natural}=\Zz_{\natural}$ is used.
			
			%% Figure environment removed

\subsection{Problem formulation} \label{subsec:problemformul}
The purpose of this study is the design and analysis of control strategies for the group of agents to track a desired path 
%\begin{equation*}
$\mathbf{x}_{c,des}(\cdot)= \vc{\mathbf{p}_{c,des}(\cdot),\dot{\mathbf{p}}_{c,des}(\cdot)}$ 
%\end{equation*}
with its centroid $\mathbf{x}_{c}(\cdot)$, while minimizing the energy spent by the input $\mathbf{u}(\cdot)$ and attaining a desired distance-based formation. 
To this aim, we formalize such requirements as a finite-time optimal control problem as follows and, in the sequel, we devise a (practically) optimal distributed feedback controller.

Let $\mathscr{T}$ be the trajectory manifold of \eqref{eq:dyn_sys}, such that $\boldsymbol{\xi} = \left(\mathbf{x}(\cdot),\mathbf{u}(\cdot)\right) \in \mathscr{T}$ denotes a state-input trajectory. The general OIFT problem can be stated as follows: find a solution $\boldsymbol{\xi}^{\star}$ such that
\begin{equation}\label{eq:minimizationproblemOIFT}
	\underset{\boldsymbol{\xi}\in \mathscr{T}}{\min}~ h(\boldsymbol{\xi})
\end{equation}
is attained, where
\begin{equation}\label{eq:cost}
	h(\mathbf{x}(\cdot),\mathbf{u}(\cdot)) = m(\mathbf{x}(T)) + \int_{0}^{T} l\left(\mathbf{x}(\tau), \mathbf{u}(\tau) \right) \drm \tau 
\end{equation}
represents the cost functional to be minimized over the time interval $[0,T]$ in order to achieve the three objectives previously introduced. Generalizing the approach in \cite{FabrisCenedeseHauser2019}, two different terms explicitly appear in \eqref{eq:cost}:
the instantaneous cost
\begin{equation}\label{eq:inst_cost}
	l\left(\mathbf{x}(t), \mathbf{u}(t) \right) = l^{tr}(\mathbf{x}_{c}(t)) + l^{in}(\mathbf{u}(t)) + l^{fo1}(\mathbf{p}(t)) + l^{fo2}(\dot{\mathbf{p}}(t)) 
\end{equation}
and the final cost
\begin{equation}\label{eq:final_cost_m}
	m(\mathbf{x}(T)) = l^{tr}(\mathbf{x}_{c}(T)) + l^{fo1}(\mathbf{p}(T)) + l^{fo2}(\dot{\mathbf{p}}(T)) .
\end{equation}
Each term in \eqref{eq:inst_cost} is minimized with the purpose to obtain the fulfillment of a peculiar task. Indeed, setting %$r_{ij}(\tau)=\left\|\mathbf{p}_{i}(\tau)-\mathbf{p}_{j}(\tau)\right\|_{2}$ 
$\ee_{ij}(t) = \mathbf{p}_{i}(t)-\mathbf{p}_{j}(t)$ and $s_{ij}(t) = \left\| \ee_{ij}(t) \right\|_{2}^{2}$
as the displacement of agent $j$ w.r.t. to agent $i$ and the $(i,j)$-th squared distance, respectively, each contribution can be defined as:
\begin{equation}\label{eq:track_inst_cost}
	l^{tr}(\mathbf{x}_{c}(t)) = \dfrac{1}{2} \sum\limits_{i=1}^{n} \left\|\mathbf{x}_{c}(t)-\mathbf{x}_{c,des}(t)\right\|_{\mathbf{Q}_{i}}^{2} 
\end{equation}
for the tracking task,
\begin{equation}\label{eq:inst_energy}
	l^{in}(\mathbf{u}(t)) = \dfrac{1}{2} \sum\limits_{i=1}^{n} \left\|\mathbf{u}_{i}(t)\right\|_{\mathbf{R}_{i}}^{2} 
\end{equation}
for the input energy task and, given a family of potential functions $\sigma_{d_{ij}}:\mathbb{R}_{\geq 0} \rightarrow \mathbb{R}_{\geq 0}$, such that $(i,j) \in \mathcal{E}$,
\begin{equation}\label{eq:form_inst_cost}
	l^{fo1}(\mathbf{p}(t)) = \dfrac{k_{F}}{4} \sum\limits_{i=1}^{n} \sum\limits_{j \in \mathcal{N}_{i}} \sigma_{d_{ij}}\left(s_{ij}(t)\right) 
\end{equation}
for the formation task. Some slight modifications w.r.t. what designed in \cite{FabrisCenedeseHauser2019}  have been accomplished to normalize and make the overall functional \eqref{eq:cost} distributable. Remarkably, this does not affect conceptually the original version of the OIFT problem. Moreover, to fine-tune the agents' displacement rate, we also account for the formation term associated with the inter-agent velocities
%
\begin{equation}\label{eq:align_inst_cost}
	l^{fo2}(\dot{\mathbf{p}}(t)) = \dfrac{k_{A}}{4} \sum\limits_{i=1}^{n} \sum\limits_{j \in \mathcal{N}_{i}}  \left\| \dot{\ee}_{ij}(t) \right\|_{\Thth_{ij}}^{2} .
\end{equation}
It is worth observing that terms \eqref{eq:track_inst_cost} and \eqref{eq:form_inst_cost} lead the system to achieve second-order velocity alignment\footnote{I.e., steering towards the (prescribed) average heading of local neighbors.} and cohesion/separation\footnote{I.e., steering to achieve the prescribed inter-agent distance/ avoid crowding.}, respectively, according to the Boids model principles~\cite{Reynolds1987}. Whereas, penalty \eqref{eq:align_inst_cost} contributes mainly to achieve alignment, as it ensures stillness (up to rotations) for the attained shape w.r.t. a dynamic frame referring to the desired centroid trajectory.

Hereafter, we address the instantaneous state cost as
%
\begin{equation*}
	l^{st}(\mathbf{x}) = l^{tr}(\mathbf{x})+l^{fo}(\mathbf{x}),
\end{equation*}
%sistemare questa parte commento 7 revisore 4 
where $l^{fo}(\mathbf{x}) = l^{fo1}(\mathbf{p})+l^{fo2}(\dot{\mathbf{p}})$. Similarly, %we assume that 
we split \eqref{eq:track_inst_cost} into the additive terms $ l^{tr1}(\pp)$ and $ l^{tr2}(\dot{\pp})$ referred to the control of $\pp_{c}$ and $\dot{\pp}_{c}$, respectively,
to benefit from the structure of
$\nabla_{\mathbf{x}} l^{tr}(\xx) = \begin{bmatrix}
\nabla_{\mathbf{p}} l^{tr1}(\pp)^\top &  \nabla_{\dot{\pp}} l^{tr2}(\dot{\pp})^\top
\end{bmatrix}^\top$%by trivially splitting
 in the sequel. %where $\Thth_{ij} \succeq 0$ for all $(i,j) \in \mathcal{E}$. 
For all $i=1, \ldots, n$, we set $\mathbf{Q}_{i} = \Diag ( \mathbf{Q}_{c,i}, \mathbf{Q}_{\dot{c},i} ) \succeq 0$, such that $\mathbf{Q}_{c,i} \in \mathbb{R}^{M\times M}$, $\mathbf{Q}_{c,i} \succeq 0$ and $\mathbf{Q}_{\dot{c},i} \in \mathbb{R}^{M\times M}$, $\mathbf{Q}_{\dot{c},i} \succeq 0$ weight the $i$-th centroid position and velocity respectively, $\mathbf{R}_{i}\in \mathbb{R}^{M\times M}$, $\mathbf{R}_{i} \succ 0$, $k_{F}>0$, $k_{A}>0$ and $\Thth_{ij} \in \mathbb{R}^{M\times M}$, $\Thth_{ij} \succeq 0$, $\forall (i,j) \in \mathcal{E}$. 
All these parameters are constant, tuned according to given specifications in order to penalize the trajectory tracking error and the energy spent by the input, and to modulate the convergence to a desired shape.
Furthermore, each $d_{ij}$ in the potential functions $\sigma_{d_{ij}} $ belonging to formation cost \eqref{eq:form_inst_cost} represents the desired inter-agent distance between a pair of agents $(i,j) \in \mathcal{E}$: an accurate selection of $\sigma_{d_{ij}}$ leads to the implementation of the cohesion/separation paradigm, as explained next.

%\subsection{Potential-based formations}
With regard to the formation objective, it is required that the system of agents achieves a desired $M$-dimensional geometric shape induced by a set of constraints of the form
%
\begin{equation}\label{eq:dist_constraints}
	s_{ij} = d^{2}_{ij}, \quad \forall (i,j) \in \mathcal{E}.
\end{equation}
%
with $d_{ij}=d_{ji}$ $\forall$ $(i,j)\in \mathcal{E}$.\\
The use of potential functions allows fulfilling this aim, 
%Let $s_{ij}=r^{2}_{ij}$ be the squared inter-agent distance between agents $i$ and $j$. 
and, among several possible choices, it has been designed the following:
%
\begin{equation}\label{eq:potential}
	\sigma_{d_{ij}}(s_{ij}) = \begin{cases}
		k_{r_{ij}} (1-s_{ij}/d_{ij}^{2})^{\beta_{ij}}, \quad & \text{if } 0\leq s_{ij} < d_{ij}^{2}; \\
		k_{a_{ij}} \left((s_{ij}/d_{ij}^{2})^{\alpha_{ij}}-1\right)^{\beta_{ij}}, \quad& \text{if } s_{ij} \geq d_{ij}^{2}.
	\end{cases}
\end{equation}
%
This is a power function in $s_{ij}$ with degree $\beta_{ij} \in \mathbb{R}$, $\beta_{ij} \geq 2$ and differentiable w.r.t. $s_{ij}\geq 0$ up to the second order. In addition, for $\alpha_{ij} \in \mathbb{R}$, $\alpha_{ij}>0$, function \eqref{eq:potential} is $\mathscr{C}^{2}$ and its magnitude can be adjusted by tuning constants $k_{r_{ij}}\geq0$ and $k_{a_{ij}}\geq0$ independently\footnote{The only exception is for $\beta_{ij}=2$, in which, to guarantee continuity of class $\mathscr{C}^{2}$, condition $k_{r_{ij}} = \alpha_{ij}^{2}k_{a_{ij}}$ must be enforced.}. 
These two parameters are purposely selected to be directly proportional to the repulsion and attraction actions between agents respectively, playing a crucial role in the intensity regulation %\footnote{Gains $k_{r_{ij}}$ and $k_{a_{ij}}$ represent the nominal repulsive and attractive magnitudes respectively and are set to zero if and only if no communication occurs between couple $(i,j)$.}
of the potential itself. %(see Fig.~\ref{fig:sigma}). 
Moreover, exponent $\alpha_{ij}$ allows tuning the magnitude of the attractive potential on certain conditions. Specifically, if $s_{ij} > 2^{1/\alpha_{ij}} d_{ij}^{2}$, we say that, as $\sigma_{d_{ij}} > k_{a_{ij}}$, the attraction force becomes significantly high for the couple $(i,j)\in \mathcal{E}$. On the other hand, the maximum repulsion intensity is reached as $s_{ij}$ approaches $0$ to avoid collisions, with $\sigma_{d_{ij}} \rightarrow k_{r_{ij}}$, being $\sigma_{d_{ij}} \leq k_{r_{ij}}$ in this regime. 
A default choice may be preferred over others by setting $\alpha_{ij} = 0.5$, since this implies that the attractive potential becomes very significant whenever the effective squared inter-agent distance $s_{ij}$ exceeds the double of its reference $d_{ij}^{2}$. 
However, in practice, $\alpha_{ij}$ should be selected according to the maximum communication range allowed between $(i,j)$.
%Note that, if $\beta_{ij}=2$ is set, it is needed that $k_{r_{ij}} = k_{a_{ij}}\alpha_{a_{ij}}^{2}$ in order for $\sigma_{d_{ij}}$ to be $\mathscr{C}^{2}$: this little requirement for PRONTO cannot be ignored and limits the choice of one parameter among $k_{r_{ij}}$, $k_{a_{ij}}$, $\alpha_{a_{ij}}$ in this case.\\


%As depicted in Fig. \ref{fig:sigma}, the qualitative graphic of $\eqref{eq:potential}$ and its derivatives emphasizes the fact that
The qualitative properties of functions in \eqref{eq:potential} and their %derivatives
first and second derivatives w.r.t. $s_{ij}$ (indicated with $\sigma_{d_{ij}}^{\prime}$ and $\sigma_{d_{ij}}^{\prime\prime}$ respectively) are depicted in Fig. \ref{fig:sigma} and can be summarized as follows:
\begin{subequations}
\begin{align}
     &\sigma_{d_{ij}}^{\prime} (s_{ij}) \leq 0 \ \text{for}\ 0\leq s_{ij}< d^{2}_{ij}; \label{prop:sig_prime}\\
	&\sigma_{d_{ij}}^{\prime} (s_{ij}) \geq 0 \ \text{for}\ s_{ij}\geq d^{2}_{ij};\\
	 &\sigma_{d_{ij}}^{\prime\prime} (s_{ij}) \geq 0\ \text{for all}\ s_{ij}; \label{prop:sig_prime_prime}
\end{align}
\end{subequations}
% \begin{enumerate}
% 	\item $\sigma_{d_{ij}}^{\prime} (s_{ij}) \leq 0$ for $0\leq s_{ij}< d^{2}_{ij}$; \label{prop:sig_prime}
% 	\item $\sigma_{d_{ij}}^{\prime} (s_{ij}) \geq 0$ for $s_{ij}\geq d^{2}_{ij}$;
% 	\item $\sigma_{d_{ij}}^{\prime\prime} (s_{ij}) \geq 0$ for all $s_{ij}$; \label{prop:sig_prime_prime}
% \end{enumerate}
where the equalities in \eqref{prop:sig_prime}-\eqref{prop:sig_prime_prime} %\ref{prop:sig_prime})-\ref{prop:sig_prime_prime}) 
hold if and only if $s_{ij}=d^{2}_{ij}$.

%\begin{comment}
	
	% Figure environment removed
	
%\end{comment}

The usage of functions with the same properties of \eqref{eq:potential} can be justified by the fact that they can lead formations to verify the maximum number of feasible relations\footnote{Meaning that such relations can be satisfied concurrently.} in \eqref{eq:dist_constraints} since the dynamics is intentionally driven to minimum-potential trajectories. Indeed, it can be easily proven that $\sigma_{d_{ij}}(s_{ij})$ is nonnegative for all $s_{ij}$ and exhibits a unique 
global minimizer $s_{ij}=d^{2}_{ij}$ for which $\sigma_{d_{ij}}(d_{ij})=0$,  %$\left(s_{ij},\sigma_{d_{ij}}(s_{ij})\right)=\left(d^{2}_{ij},0\right)$, %point at %i.e. such potentials go to $0$ 
implying that \eqref{eq:form_inst_cost} vanishes if and only if the desired distance $d_{ij}$ between $(i,j)$ is achieved.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Solution for the general OIFT problem} \label{sec:numerical_methodologies_for_OIFT} %
% PRojection Operator based Newton's method for Trajectory Optimization
%We provide here a brief introduction to PRONTO, the numerical tool used for trajectory optimization, and
In this section, we clarify how the numerical tool PRONTO (see \cite{HauserSaccon2006,AguiarPedroBayer2017}) used for trajectory optimization is adopted to solve the OIFT problem discussed in Sec. \ref{subsec:problemformul}. %discussed in Sec. \ref{sec:problem_setup}.
In addition, we devise an online distributed feedback controller approximating the performance of inverse dynamics computed by means of PRONTO,  
%(see App. \ref{subs:basics_of_PRONTO} for further details). 
where the latter will serve as a reference to compare the performances obtained with such a decentralized approach. The stabilizing properties ensured through such an online distributed control input are then briefly discussed together with the made approximations and heuristics to meet optimality.

\subsection{Offline centralized solution via PRONTO}\label{subsec:PRONTOsolvesOIFT}
The application of PRONTO to the OIFT problem allows to iteratively compute, yet in an offline and centralized fashion, a complete trajectory $\boldsymbol{\xi}_{k+1} = (\mathbf{x}_{k+1}(\cdot),\mathbf{u}_{k+1}(\cdot))$ satisfying\footnote{The solution exists unique as the system \eqref{eq:dyn_sys} is control affine and term $l^{in}$ is quadratic (see also \cite{HAUSER2002377} for more details).} \eqref{eq:minimizationproblemOIFT}, recalling that $\mathbf{x}_{k}(\cdot)$ and $\mathbf{u}_{k}(\cdot)$ respectively represent the absolute position and velocity state vector, and the acceleration input, for the whole evolution at the $k$-th PRONTO iteration. As mentioned previously, the assumptions made in Sec. \ref{sec:problem_setup} allow to obtain the expressions of many relevant numerical quantities. Indeed, here, we clarify how PRONTO variables and parameters 
%declared in Alg. \ref{alg:PRONTO} have to be 
are assigned and computed in this particular framework. Setting
%Precisely, all the following equalities, either by definition or proof\footnote{The reader is invited to verify them consulting \textcolor{red}{[mettere un paper che spiega BENE come assegnare sti parametri]}.}, hold true:
%\begin{equation*}
$\ff(\mathbf{x},\mathbf{u}) = \mathbf{A} \mathbf{x} + \mathbf{B} \mathbf{u}$
%\end{equation*}
%and denoting with a subscript the partial differentiation w.r.t. $\xx$ or $\uu$, 
the list of relations employed in PRONTO to find the best Newton's descent direction\footnote{For further details on the PRONTO implementation, the reader is addressed to \cite{FabrisCenedeseHauser2019}.} 
%is immediately obtained:
is immediately obtained and shortly reported below for convenience:  
%
\begin{alignat}{3}
	& \bar{\mathbf{A}}(t) &&= \ff_{\mathbf{x}} &&=
    \frac{\partial \ff(\mathbf{x},\mathbf{u})}{\partial \mathbf{x} }= \mathbf{A} \nonumber\\
	& \bar{\mathbf{B}}(t) &&= \ff_{\mathbf{u}} &&=
 \frac{\partial \ff(\mathbf{x},\mathbf{u})}{\partial \mathbf{u} }          = \mathbf{B} \nonumber\\
	& \mathbf{a}(t)       &&= l^{\top}_{\mathbf{x}}    &&= \underbrace{\mathbf{C}^{\top} \mathbf{Q} \left(\mathbf{x}_{c} -\mathbf{x}_{c,des}\right)}_{\nabla_{\xx} l^{tr}}  + \nabla_{\mathbf{x}}l^{fo1} + \nabla_{\mathbf{x}}l^{fo2} \label{eq:a}\\
	& \mathbf{b}(t)       &&= l^{\top}_{\mathbf{u}}    &&= \nabla_{\uu} l= \mathbf{R} \mathbf{u} \nonumber\\
	& \mathbf{r}_{1}(T)   &&= m^{\top}_{\mathbf{x}}    &&= \underbrace{\mathbf{C}^{\top} \mathbf{Q} \left(\mathbf{x}_{c}(T)-\mathbf{x}_{c,des}(T)\right)}_{\nabla_{\xx} l^{tr}(\xx(T))} +  \nabla_{\mathbf{x}}l^{fo1}(T) + \nabla_{\mathbf{x}}l^{fo2}(T) \nonumber\\
	%& && && ~~~~\nabla_{\mathbf{x}}l^{fo1}(T) + \nabla_{\mathbf{x}}l^{fo2}(T) \nonumber\\
	& \mathbf{Q}_{o}(t)   &&= l_{\mathbf{x}\mathbf{x}} &&= \underbrace{\mathbf{C}^{\top} \mathbf{Q} \mathbf{C}}_{\mathcal{H}_{\mathbf{x}\mathbf{x}} l^{tr}} + \mathcal{H}_{\mathbf{x}\mathbf{x}} l^{fo1} + \mathcal{H}_{\mathbf{x}\mathbf{x}} l^{fo2} \label{eq:Qo}\\
	& \mathbf{S}_{o}(t)   &&= l_{\mathbf{x}\mathbf{u}} &&= \mathcal{H}_{\mathbf{x}\mathbf{u}}=\Zz_{2N\times N} \nonumber\\
	& \mathbf{R}_{o}(t)   &&= l_{\mathbf{u}\mathbf{u}} &&= \mathcal{H}_{\mathbf{u}\mathbf{u}}=\mathbf{R} \nonumber\\
	& \mathbf{P}_{1}(T)   &&= m_{\mathbf{x}\mathbf{x}} &&= \underbrace{\mathbf{C}^{\top} \mathbf{Q} \mathbf{C}}_{\mathcal{H}_{\mathbf{x}\mathbf{x}} l^{tr}(\xx(T))} + \mathcal{H}_{\mathbf{x}\mathbf{x}} l^{fo1}(T) + \mathcal{H}_{\mathbf{x}\mathbf{x}} l^{fo2}(T) \nonumber
\end{alignat}
%
where $\mathbf{Q} = \sum_{i=1}^{n} \mathbf{Q}_{i} $, $\mathbf{R} = \Diag ( \mathbf{R}_{1}, \ldots, \mathbf{R}_{n} ) \in \mathbb{R}^{N \times N}$.\\
In the light of this result, a time-invariant PD controller as
\begin{equation}\label{eq:PDcontroller}
	\mathbf{K} = \begin{bmatrix}
		k_{p} \mathbf{I}_{N} & k_{d} \mathbf{I}_{N}
	\end{bmatrix}, \quad k_{p}, k_{d} > 0
\end{equation}
turns out to be one of the most efficient options to adopt\footnote{The control gain \eqref{eq:PDcontroller} is a parameter used to construct the PRONTO inverse dynamics through offline state feedback. In particular, it is used to map the states into control inputs.}.
%represents the easiest and most efficient option to choose%\footnote{Usually, in PRONTO, controllers are computed at each time instant solving a linear quadratic optimal control problem involving $\left(\bar{\mathbf{A}},\bar{\mathbf{B}}\right)$. In this framework, we exploit the fact that they are constant matrices and a well known linear agents' dynamics is relatively simple to control.}
%, meaning that step 3 %\ref{redesign_controller} 
%in Alg. \ref{alg:PRONTO} is not required to be processed. 

As a further observation, let us analyze the gradient and Hessian matrix of $l^{fo1}$ w.r.t. the state $\mathbf{x}$ in \eqref{eq:a} and \eqref{eq:Qo}, respectively. 
%Indicating the zero vector of dimension $\natural$ with $\mathbf{0}_{\natural}$ and the relative position displacements $\mathbf{e}_{ij} := \mathbf{p}_{i}-\mathbf{p}_{j}$ for all pairs $(i,j)$,
Their formal expressions are provided by
\begin{alignat*}{3}
	&\nabla_{\mathbf{x}}l^{fo1} &&= \begin{bmatrix}
		\nabla^{\top}_{\mathbf{p}}l^{fo1} & \nabla^{\top}_{\dot{\mathbf{p}}}l^{fo1}
	\end{bmatrix}^{\top} &&= \begin{bmatrix}
		\nabla^{\top}_{\mathbf{p}}l^{fo1} & \mathbf{0}^{\top}_{N}
	\end{bmatrix}^{\top}\\
	&\mathcal{H}_{\mathbf{x}\mathbf{x}} l^{fo1} &&= \begin{bmatrix}
		\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1} & \mathcal{H}_{\mathbf{p}\dot{\mathbf{p}}} l^{fo1} \\
		\mathcal{H}_{\dot{\mathbf{p}}\mathbf{p}} l^{fo1} & \mathcal{H}_{\dot{\mathbf{p}}\dot{\mathbf{p}}} l^{fo1}
	\end{bmatrix} &&= \begin{bmatrix}
		\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1} &  \Zz_{N}  \\
		\Zz_{N}								  &  \Zz_{N}
	\end{bmatrix}
\end{alignat*}
where, by assigning $\boldsymbol{\Pi}_{ij}(t)=\mathbf{e}_{ij}(t) \mathbf{e}_{ij}(t)^{\top} \in \mathbb{R}^{M\times M}$, it holds that, for all $i=1,\dots,n$,
\begin{equation*}\label{eq:gradfo}
	\nabla_{\mathbf{p}_{i}}l^{fo1} = k_{F} \sum\limits_{j \in \mathcal{N}_{i}} \sigma_{d_{ij}}^{\prime}   \mathbf{e}_{ij}
\end{equation*}
and, for all $(i,j) \in \mathcal{E}$,
\begin{equation}\label{eq:hessfoout}
	\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1} = -k_{F}\left(2\sigma_{d_{ij}} ^{\prime\prime}   \boldsymbol{\Pi}_{ij} + \sigma_{d_{ij}}^{ \prime}   \mathbf{I}_{M} \right);
\end{equation}
otherwise, for $(i,j) \notin \mathcal{E}$ one has $\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1} = \Zz_{M}$.
Notably, condition $\sigma_{d_{ij}} \in \mathscr{C}^{2}$, for all $(i,j)\in\mathcal{E}$, is required to use PRONTO, in order for \eqref{eq:hessfoout} not to present discontinuities. An expression for the diagonal blocks in the Hessian $\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1}$ is then provided by
\begin{equation}\label{eq:hessfoin}
	\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{i}} l^{fo1} = - \sum\limits_{\forall j\neq i} \mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1}.
\end{equation}
Similarly, the gradient and Hessian matrix of term $l^{fo2}$ in \eqref{eq:a}-\eqref{eq:Qo} are yielded by
\begin{alignat*}{3}
	&\nabla_{\mathbf{x}}l^{fo2} &&= \begin{bmatrix}
		\nabla^{\top}_{\mathbf{p}}l^{fo2} & \nabla^{\top}_{\dot{\mathbf{p}}}l^{fo2}
	\end{bmatrix}^{\top} &&= \begin{bmatrix}
		\mathbf{0}^{\top}_{N} & \nabla^{\top}_{\dot{\mathbf{p}}}l^{fo2}
	\end{bmatrix}^{\top}\\
	&\mathcal{H}_{\mathbf{x}\mathbf{x}} l^{fo2} &&= \begin{bmatrix}
		\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo2} & \mathcal{H}_{\mathbf{p}\dot{\mathbf{p}}} l^{fo2} \\
		\mathcal{H}_{\dot{\mathbf{p}}\mathbf{p}} l^{fo2} & \mathcal{H}_{\dot{\mathbf{p}}\dot{\mathbf{p}}} l^{fo2}
	\end{bmatrix} &&= \begin{bmatrix}
		\Zz_{N}                                &  \Zz_{N}  \\
		\Zz_{N}								  &  \mathcal{H}_{\dot{\mathbf{p}}\dot{\mathbf{p}}} l^{fo2}
	\end{bmatrix}
\end{alignat*}
where 
\begin{equation*}\label{eq:gradal}
	\nabla_{\dot{\mathbf{p}}_{i}}l^{fo2}(t) = k_{A} \sum\limits_{ j \in \mathcal{N}_{i}} \Thth_{ij} \dot{\mathbf{e}}_{ij} 
\end{equation*}
and for all $(i,j) \in \mathcal{E}$,
\begin{equation*}\label{eq:hessal}
	\mathcal{H}_{\dot{\mathbf{p}}_{i}\dot{\mathbf{p}}_{j}} l^{fo2} = 
	-k_{A} \Thth_{ij};
\end{equation*}
otherwise, for $(i,j) \notin \mathcal{E}$ one has $\mathcal{H}_{\dot{\mathbf{p}}_{i}\dot{\mathbf{p}}_{j}} l^{fo2} = \Zz_{M}$. Also, \begin{equation*}\label{eq:hessfal}
	\mathcal{H}_{\dot{\mathbf{p}}_{i}\dot{\mathbf{p}}_{i}} l^{fo2} = - \sum\limits_{\forall j \neq i}  \mathcal{H}_{\dot{\mathbf{p}}_{i}\dot{\mathbf{p}}_{j}} l^{fo2}.
\end{equation*}

As a matter of fact, 
%the LQ problem in \eqref{eq:line_search} needs for a positive semidefinite matrix $\mathbf{Q}_{o}$ to be solved; hence, care has to be taken while search directions in Alg. \ref{alg:PRONTO} are selected. 
PRONTO involves the resolution of an LQ problem to compute optimal search directions. Hence, $\mathbf{Q}_{o}(t)$ should be taken positive semidefinite for all $t \geq 0$.
In fact, it can be observed that expression \eqref{eq:Qo} does not always guarantee this condition, given the general undetermined definiteness of the Hessian related to the formation $\mathcal{H}_{\mathbf{p}\dot{\mathbf{p}}} l^{fo1}$. To this aim, a safe version of $\mathbf{Q}_{o}$, say $\mathbf{Q}^{safe}_{o}$, is implemented by exploiting a heuristic based on the Gershgorin circle theorem \cite{Bell1965}. This is carried out in practice by computing for $i\neq j$ the off-diagonal blocks
\begin{equation*}\label{eq:heuristicsPronto}
	\mathcal{H}^{safe}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1} = -k_{F} \left(2\sigma_{d_{ij}} ^{\prime\prime}   \boldsymbol{\Pi}_{ij} + 
	\chi_{0}(\sigma_{d_{ij}}^{ \prime}) \sigma_{d_{ij}}^{ \prime}   \mathbf{I}_{M} \right), 
\end{equation*}
where $\chi_{0}:\mathbb{R}\rightarrow \{0,1\}$ denotes the unitary characteristic function such that it returns the value $0$ if its argument is negative; the value $1$, otherwise. The diagonal blocks for such a safe version of $\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1}$ are then obtained exploiting \eqref{eq:hessfoin}. % again.

\begin{comment}
	
	
	\subsection{Robust heuristic for PRONTO}\label{ssec:PRONTO_heuristics}
	\MFa{We should skip this: it doesn't serve as definition list neither as new valid content. Just do not remove the figure!!}
	As a matter of fact, the LQ problem in \eqref{eq:Riccati_for_search_dir} requires a positive semidefinite matrix $\mathbf{Q}_{o}$ to be solved; therefore, care has to be taken while search directions in Alg. \ref{alg:PRONTO} are computed. In reality, it can be noticed that expression \eqref{eq:Qo} does not always satisfy this condition because of the general undetermined definiteness of the Hessian term. To this purpose, we decide to implement a suitable safe version of $\mathbf{Q}_{o}$, namely $\mathbf{Q}^{safe}_{o}$, by using a Gershgorin-circle-theorem-based heuristic that can be justified by the fact that potential functions with the same repulsive-attractive behavior of \eqref{eq:potential} never guarantee the positive semidefiniteness of matrix $\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1}$. Indeed, the latter term is badly affected by the evidence that matrix $\boldsymbol{\Pi}_{ij}$ is rank-$1$ for all the pairs $(i,j)$ and the possibility of $\sigma_{d_{ij}}^{\prime}(s_{ij})$ to be negative.\\
	As illustrated in Fig. \ref{fig:sigma}, the qualitative graphic of $\eqref{eq:potential}$ and its derivatives highlights that
	\begin{enumerate}
		\item $\sigma_{d_{ij}}^{\prime} (s_{ij}) \leq 0$ for $0\leq s_{ij}\leq d^{2}_{ij}$; \label{prop:sig_prime}
		\item $\sigma_{d_{ij}}^{\prime} (s_{ij}) \geq 0$ for $s_{ij}\geq d^{2}_{ij}$;
		\item $\sigma_{d_{ij}}^{\prime\prime} (s_{ij}) \geq 0$ for all $s_{ij}$; \label{prop:sig_prime_prime}
	\end{enumerate}
	where the equalities in \ref{prop:sig_prime})-\ref{prop:sig_prime_prime}) hold if and only if $s_{ij}=d^{2}_{ij}$.
	% Figure environment removed
	
	The previous observations allow to state that, whenever two agents $(i,j)$ are repelling each other, the Hessian $\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1}$ is not positive semidefinite. This implication leads us to neglect the variation of potential \eqref{eq:potential} w.r.t. the current distance for $0\leq s_{ij}<d^{2}_{ij}$ to aim at searching a well defined descent direction in Alg. \ref{alg:PRONTO}.
	To this end, we finally choose to force the term $\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1}$ to be positive semidefinite while its value is being computed, as implemented at lines \ref{if:Qsafe}-\ref{endif:Qsafe} of Alg. \ref{alg:Qsafe}.
	
	\begin{algorithm}
		\caption{Heuristic for the modification of $\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1}$ to search effectively a descent direction in PRONTO}\label{alg:Qsafe}
		\begin{algorithmic}[1]
			\For {$i = 1,...,n$}
			\State $\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{i}} l^{fo1} \leftarrow \Zz_{M} $
			\For {$j = 1,...,n$ s.t. $j\neq i$}
			\State  $\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1} \leftarrow -2k_{F}\sigma_{d_{ij}} ^{\prime\prime} \left(s_{ij}\right)  \boldsymbol{\Pi}_{ij} $
			\If {$\mathbf{Q}^{safe}_{o}$ is not required \textbf{or} $\sigma_{d_{ij}} ^{\prime} \left(s_{ij}\right) > 0$} \label{if:Qsafe}
			\State $\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1} \leftarrow \mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1} -k_{F} \sigma_{d_{ij}} ^{\prime} \left(s_{ij}\right) \mathbf{I}_{M} $
			\EndIf \label{endif:Qsafe}
			\State $\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{i}} l^{fo1} \leftarrow \mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{i}} l^{fo1}-\mathcal{H}_{\mathbf{p}_{i}\mathbf{p}_{j}} l^{fo1}$
			\EndFor
			\EndFor
		\end{algorithmic}
	\end{algorithm}
	
\end{comment}


\subsection{Preliminary discussion for the design of a decentralized controller}
In the previous section, the main results obtained in \cite{FabrisCenedeseHauser2019} have been re-elaborated to solve the generalized version of the OIFT problem \eqref{eq:minimizationproblemOIFT}-\eqref{eq:align_inst_cost}. However, it has to be noticed that the PRONTO inverse dynamics cannot be applied in an online fashion and its computation is centralized.
Henceforward, we build up the analytical reasoning towards a distributed control law $\widehat{\uu}(t) = \vci{\widehat{\uu}_{i}(t)}{n} $ that solves the OIFT problem in the finite-time interval $[0,T]$. 
To this purpose, we list  the three challenging design criteria that will be observed to derive a suitable decentralized controller: %, which represent a challenging research aspect within this kind of literature:
\begin{enumerate}
	\item[$(i)$] $\widehat{\mathbf{u}}$ must comply with optimality criteria in order to solve problem \eqref{eq:minimizationproblemOIFT}, possibly, resorting to heuristics;
	\item[$(ii)$] $\widehat{\mathbf{u}}$ must be distributed, namely $\widehat{\mathbf{u}}_{i}$ is computed only with the information of nodes $j \in \overline{\mathcal{N}}_{i} = \mathcal{N}_{i} \cup \{i\}$;
	\item[$(iii)$] $\widehat{\mathbf{u}}$ must be an online feedback control law, i.e. it can be implemented in a real-time device (assuming to have enough hardware capabilities) by leveraging the information of the current global state of the system.
\end{enumerate}


The derivation of $\widehat{\uu}$ starts by tackling point $(i)$, specifically. To this aim, we first provide the next preliminary definition.
\begin{Def}[Hamiltonian associated to \eqref{eq:dyn_sys}-\eqref{eq:minimizationproblemOIFT}]
	Let $\boldsymbol{\lambda}(t) = \vci{\boldsymbol{\lambda}_{i}(t)}{2n} \in \mathbb{R}^{2N}$ be the time-varying co-state vector, where $\boldsymbol{\lambda}_{i} \in \mathbb{R}^{M}$. The real scalar function 
	\begin{equation}
		H = \boldsymbol{\lambda}^{\top} \mathbf{f} + l = \boldsymbol{\lambda}^{\top}(\mathbf{A}\mathbf{x}+\mathbf{B}\mathbf{u}) + l^{st}(\mathbf{x}) + l^{in}(\mathbf{u})
	\end{equation} 
	is said to be the \textit{Hamiltonian} associated to problem \eqref{eq:minimizationproblemOIFT} constrained to dynamics \eqref{eq:dyn_sys}.
\end{Def}

Variables $\boldsymbol{\lambda}_{i}$, for $i=1,\ldots,2n$, are referred to as the \textit{Lagrangian multipliers}.
Now, to make $\widehat{\uu}$ comply with optimality criteria, a weak version of the Pontryagin Minimum Principle (PMP) \cite{Pontryagin2018} applied to the specific framework under analysis is provided in the next theorem. % lemma.

\begin{theorem}[PMP applied to \eqref{eq:dyn_sys}-\eqref{eq:minimizationproblemOIFT}] \label{lem:PMP}
	Let $\mathcal{U}\subseteq\mathbb{R}^{N}$ be the set of all admissible inputs and $\mathbf{u}^{\star}(t) \in \mathcal{U}$ be a particular input for dynamics \eqref{eq:dyn_sys}. The necessary conditions for $\mathbf{u}^{\star}$ to solve problem \eqref{eq:minimizationproblemOIFT} are yielded by
	\begin{equation}\label{eq:PMPstates}
		\begin{cases}
			\dot{\mathbf{x}} = \nabla_{\boldsymbol{\lambda}} H \vert_{\mathbf{u}=\mathbf{u}^{\star}} \\
			\mathbf{x}(0) = \mathbf{x}_{0}	
		\end{cases} \Leftrightarrow ~~
		\begin{cases}
			\dot{\mathbf{x}} = \mathbf{A}\mathbf{x}+\mathbf{B}\mathbf{u}^{\star} \\
			\mathbf{x}(0) = \mathbf{x}_{0}	
		\end{cases},
	\end{equation}
	\begin{equation}\label{eq:PMPcostates}
		\begin{cases}
			-\dot{\boldsymbol{\lambda}} = \nabla_{\mathbf{x}} H \vert_{\mathbf{u}=\mathbf{u}^{\star}} \\
			\boldsymbol{\lambda}(T) = \nabla_{\mathbf{x}} m(\mathbf{x}(T))
		\end{cases} \!\!\!\Leftrightarrow ~
		\begin{cases}
			-\dot{\boldsymbol{\lambda}} = \mathbf{A}^{\top}\boldsymbol{\lambda} + \nabla_{\mathbf{x}} l^{st}(\mathbf{x}) \\
			\boldsymbol{\lambda}(T) = \nabla_{\mathbf{x}} m(\mathbf{x}(T))
		\end{cases}
	\end{equation}
	and
	\begin{equation}\label{eq:PMPinput}
		\nabla_{\mathbf{u}} H \vert_{\mathbf{u}=\mathbf{u}^{\star}} = 0 ~~\Leftrightarrow ~~ \mathbf{u}^{\star} = -\mathbf{R}^{-1} \mathbf{B}^{\top} \boldsymbol{\lambda}.
	\end{equation}
	Denoting with $(\xx^{\star}(\cdot),\lamlam^{\star}(\cdot))$ the evolution of $(\xx,\lamlam)$ subject to input $\uu^{\star}$, conditions \eqref{eq:PMPstates}-\eqref{eq:PMPinput} imply that $\uu^{\star}$ is a candidate to satisfy
	\begin{equation}
		H(\xx^{\star},\lamlam^{\star},\uu^{\star}) \leq H(\xx^{\star},\lamlam^{\star},\uu), \quad \forall \uu \in \mathcal{U}.
	\end{equation}
	%and
	%\begin{equation}
	%	\dot{H}(\xx^{\star},\lamlam^{\star},\uu^{\star}) = 0.
	%\end{equation}
	Moreover, assuming that an input $\mathbf{u}^{\star}$ satisfies \eqref{eq:PMPstates}-\eqref{eq:PMPinput}, the following condition is sufficient for $\mathbf{u}^{\star}(t)$ to be an instantaneous minimizer at time $t$:
	\begin{equation}\label{eq:PMPsuff}
		\begin{bmatrix}
			\mathcal{H}_{\mathbf{x}\mathbf{x}}  H(t) & \mathcal{H}_{\mathbf{x}\mathbf{u}}  H(t) \\
			\mathcal{H}_{\mathbf{u}\mathbf{x}}  H(t) & \mathcal{H}_{\mathbf{u}\mathbf{u}}  H(t) 
		\end{bmatrix} \succeq 0 ~\Leftrightarrow\! ~
		\begin{cases}
			\mathcal{H}_{\mathbf{x}\mathbf{x}}  l^{st}(t) \succeq 0 \\
			\mathbf{R} \succeq 0
		\end{cases}.
	\end{equation}
	If \eqref{eq:PMPsuff} holds for all $t\in [0,T]$ then $\mathbf{u}^{\star}$ solves problem \eqref{eq:minimizationproblemOIFT}.
\end{theorem}
\begin{proof}
	The statement is a direct consequence of the PMP applied to \eqref{eq:dyn_sys}-\eqref{eq:cost}, as shown by each double implication in \eqref{eq:PMPstates}-\eqref{eq:PMPinput} and \eqref{eq:PMPsuff}. In particular, the sufficient condition \eqref{eq:PMPsuff} is equivalent to require convexity for $l$ w.r.t. variables $\mathbf{x}$ and $\boldsymbol{\lambda}$, leveraging the fact that \eqref{eq:dyn_sys} is linear (see also \cite{Locatelli2001}).
\end{proof}

The PMP of Thm. \ref{lem:PMP} will be exploited to a certain degree in Sec. \ref{sec:distr_law} with the aim of characterizing the structure of the proposed online distributed control law.

We now address point $(ii)$. To this purpose, the derivation of a local estimator $\widehat{\mathbf{x}}_{c}^{i}(t)$, for each agent $i=1,\dots,n$, that reconstructs the information about the centroid $\mathbf{x}_{c}(t)$ will be crucial, since one term of controller $\uu^{\star}$ is devoted to satisfy the minimization of the tracking part of $h$ influenced by $l^{tr}$. Such estimator $\widehat{\mathbf{x}}_{c}^{i}$ is of second-order type, as it mimics dynamics \eqref{eq:dyn_sys}. 
%However, the 
The next proposition thus focuses on bounding the estimation error for the
%more 
%on the working principles 
%to design a 
first-order estimator devised by the authors of \cite{AntonelliArricchielloCaccavale2013}. This result will be subsequently employed to derive a second-order estimator having the purpose to recover $\widehat{\mathbf{x}}_{c}^{i}$ in a decentralized fashion. % in the following.

\begin{prop}[Local first-order centroid estimator] \label{prop:loccentrest}
	Given an undirected and connected graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$, assume that the dynamics of the whole system of $n$ agents associated to $\mathcal{G}$ is described by the single integrator
	\begin{equation}
		\dot{\mathbf{y}}(t) = \mathbf{w}(t)
	\end{equation}
	where $\mathbf{y}= \vci{\yy_{i}}{n}\in \mathbb{R}^{N}$, $\mathbf{w}=\vci{\ww_{i}}{n} \in \mathbb{R}^{N}$, $N=nM$, and with $\yy_{i},\ww_{i}\in \mathbb{R}^{M}$ denoting the state-input couple for the $i$-th agent.
	%where $\mathbf{y}, \mathbf{w} \in \mathbb{R}^{N}$, $N=nM$,  $\yy_{i},\ww_{i}\in \mathbb{R}^{M}$ are the variables associated with the dynamics of the $i$-th agent such that %with 
 	%$\yy = \vci{\yy_{i}}{n}$ and $\ww = \vci{\ww_{i}}{n}$. 
 	In addition, for $i=1,\dots,n$, let $\mathbf{N}_{i} \in \mathbb{R}^{N\times N}$ be the projection matrix such that for a vector $\psps \in \mathbb{R}^{N}$, $\psps = \vci{\psps_{i}}{n}$, with $\psps_{i} \in \mathbb{R}^{M}$, 
 	it holds that $\mathbf{N}_{i} \psps = \begin{bmatrix}
		\mathbf{0}_{M}^{\top} &\cdots & \mathbf{0}_{M}^{\top} & \psps_{i}^{\top} & \mathbf{0}_{M}^{\top} & \cdots & \mathbf{0}_{M}^{\top}
	\end{bmatrix}^{\top}$.
	Let us consider the $i$-th first-order state-space estimator
	\begin{equation}\label{eq:ssestim}
		\begin{cases}
			\dot{\widehat{\mathbf{y}}}^{i} = -k_{y} \sum\limits_{j \in \mathcal{N}_{i}} (\widehat{\mathbf{y}}^{i}-\widehat{\mathbf{y}}^{j}) -k_{y} \mathbf{N}_{i}(\widehat{\mathbf{y}}^{i}-\mathbf{y}) + \widehat{\mathbf{w}}^{i} \\
			\widehat{\mathbf{y}}_{c}^{i} = n^{-1} \sum_{j=1}^{n}\widehat{\mathbf{y}}^{i}_{j}
   , \quad \widehat{\mathbf{y}}^{i}(0) = \widehat{\mathbf{y}}^{i}_{0}
		\end{cases},
	\end{equation}
	such that $k_{y}$ is a positive gain, $\widehat{\mathbf{y}}^{i}_{0} \in \mathbb{R}^{N}$ is an arbitrary initial condition, and $\widehat{\yy}^{i} = \vcj{\widehat{\yy}_{j}^{i}}{n} \in \mathbb{R}^{N}$, $\widehat{\ww}^{i} = \vcj{\widehat{\ww}_{j}^{i}}{n} \in \mathbb{R}^{N}$ for $i = 1,\ldots,n$, with $\widehat{\yy}_{j}^{i}, \widehat{\ww}_{j}^{i} \in \mathbb{R}^{M}$. Assume that the $j$-th component of the $i$-th input is selected as %and
	\begin{equation}\label{eq:inputestassignment}
		\widehat{\mathbf{w}}^{i}_{j}(t) = \begin{cases}
			\ww_{j}(t), ~\text{if } j\in \overline{\mathcal{N}}_{i}; \\
			\widetilde{\ww}_{j}^{i}(t),  ~\text{otherwise};
		\end{cases}
	\end{equation}
	%with 
	where $\widetilde{\ww}_{j}^{i} \in \mathbb{R}^{M}$ has to be designed.
	%Also, 
	Furthermore, let us define the $i$-th centroid estimation error $\ee_{y_{c}}^{i} = \mathbf{y}_{c}- \widehat{\mathbf{y}}_{c}^{i}$ between the actual centroid $\mathbf{y}_{c} = n^{-1} \sum_{i=1}^{n} \yy_{i}$ and its $i$-th estimate $\widehat{\mathbf{y}}_{c}^{i}$. 
	If for all $i = 1,\ldots,n$
	\begin{equation}\label{eq:hypconvinpest}
		\underset{t\rightarrow +\infty}{\lim} \ww_{j}(t)-\widetilde{\ww}_{j}^{i}(t) = \mathbf{g}_{ij}, ~ \forall j \in \mathcal{V} \setminus \overline{\mathcal{N}}_{i},
	\end{equation}
	%with $\mathbf{g}_{ij} \in \mathbb{R}^{M}$ finite constant then, $\forall i = 1,\ldots,n$, one has
	with $\mathbf{g}_{ij} \in \mathbb{R}^{M}$ finite constant, then, denoting $\ee_{y_{c}} = \vci{\ee^{i}_{y_{c}}}{n}$, one has
	\begin{equation}\label{eq:centrerrest}
		\left\|\ee_{y_{c}}(t)\right\|_{2}^{2} \leq \varpi_{y_{c}}^{2}(t) := \dfrac{\mathfrak{c}(\mathcal{G})^{2}}{n^{2}k_{y}^{2}} \sum\limits_{i=1}^{n} \sum\limits_{j \in \mathcal{V} \setminus \overline{\mathcal{N}}_{i} } \left\|\ww_{j}(t)-\widetilde{\ww}_{j}^{i}(t) \right\|^{2}_{2}
	\end{equation}
	as $t\rightarrow +\infty$, where $\mathfrak{c}(\mathcal{G}) > 0$ is a topological constant depending only on $\mathcal{G}$.
	%is a constant that only depends on the topology of $\mathcal{G}$.
	%, where $\ee_{y_{c}} = \vc{\ee^{i}_{y_{c}}}$, $j\notin\overline{\mathcal{N}}_{i}$ stands for $j \in \mathcal{V} \setminus \overline{\mathcal{N}}_{i}$ and $\mathfrak{c}(\mathcal{G}) > 0$ is a constant that only depends on the topology of $\mathcal{G}$.
\end{prop}
\begin{proof}
	This result is proven showing that the $i$-th estimate $\widehat{\mathbf{y}}^{i}$ converges exponentially fast towards $\mathbf{y}$ as $t \rightarrow +\infty$. Let us define $\ee_{y}^{i} = \yy-\widehat{\yy}^{i}$ and $\ee_{w}^{i} = \ww-\widehat{\ww}^{i}$ as the state and input errors for system \eqref{eq:ssestim}, respectively. The dynamics of each $\ee_{y}^{i}$ is then described by
	\begin{equation}
		\dot{\ee}_{y}^{i} = -k_{y}  \sum\limits_{j \in \mathcal{N}_{i}} (\ee_{y}^{i}-\ee_{y}^{j}) -k_{y} \Nn_{i}\ee_{y}^{i} + \ee_{w}^{i}.
	\end{equation}
	Now, defining the global state error $\ee_{y} = \vci{\ee_{y}^{i}}{n}$, the global input error $\ee_{w} = \vci{\ee_{w}^{i}}{n}$ and resorting to the Laplacian $\Ll$ of graph $\mathcal{G}$ one has 
	\begin{equation}\label{eq:errdynest}
		\dot{\ee}_{y} = -k_{y} \left[(\Ll \otimes \Ii_{N}
  ) + \Nn \right] \ee_{y} + \ee_{w}
	\end{equation}
	where $\Nn = \Diag(\Nn_{i})$ and $\otimes$ denotes the Kronecker product. Indicating the update matrix of \eqref{eq:errdynest} with $\Mm = -k_{y} \left[(\Ll \otimes \Ii_{N}
 ) + \Nn \right] \in \mathbb{R}^{{nN \times nN}}%{N^{2}\times N^{2}}
 $, it is possible to observe that $\rk(\Mm)$ is full. This is due by the fact that, in $\Mm$, the diagonal projection matrix $\Nn$, with $\rk(\Nn) = N$, adds to the extended Laplacian $(\Ll \otimes \Ii_{N}
 )$ (for more details, see also \cite{AntonelliArricchielloCaccavale2013}). 
 The matrix $\Mm$ is indeed positive semidefinite: it has 
 %The latter is a positive semidefinite matrix with 
 exactly $N$ zero eigenvalues by the Kronecker product properties and thus $\rk(\Ll \otimes \Ii_{N}
 ) = (n-1)N%N^{2}-N
 $. As a consequence, the diagonal elements of $\Nn$ contribute to form $N$
 self loops in the graph associated to $(\Ll \otimes \Ii_{N}
 )$; hence, $\rk(\Mm) = nN %N^{2}
 $ is achieved. Moreover, since matrix $\Nn$ is also positive semidefinite and $\rk(\Mm) = nN% N^{2}
 $, matrix $\Mm$ is negative definite. Therefore, by also leveraging hypothesis \eqref{eq:hypconvinpest}, the linear dynamics in \eqref{eq:errdynest} stabilizes around
	\begin{equation}
		\ee_{y}^{\star}(t) = k_{y}^{-1} \left[(\Ll \otimes \Ii_{N}
  ) + \Nn \right]^{-1} \ee_{w}(t) = -\Mm^{-1} \ee_{w}(t)
	\end{equation} 
	for large values of $t$. 
	The latter convergence result can be proven by choosing the Lyapunov function $V(\ee_{y}) = (\ee_{y}-\ee_{y}^{\star})^{\top}(\ee_{y}-\ee_{y}^{\star})/2$ and showing that $\dot{V}(\ee_{y}) <0$ as $t\rightarrow +\infty$. In fact, denoting with $\mathbf{g} \in \mathbb{R}^{nN}$ the vector whose components are the constants $\mathbf{g}_{ij}$ so that $\mathbf{g}$ is the value taken by $\ee_{w}(t)$ as $t\rightarrow +\infty$, it follows that $\dot{V}(\ee_{y}) = (\Mm\ee_{y}+\mathbf{g})^{\top}\Mm^{-1}(\Mm\ee_{y}+\mathbf{g}) < 0$ for all $\ee_{y} \neq -\Mm^{-1}\mathbf{g}$.
	%Indeed, by substituting $\ee_{y}^{\star}(t)$ in \eqref{eq:errdynest}, one has 
	%$\dot{\ee}_{w}(t) \rightarrow \mathbf{0}_{N^{2}}$ as $t\rightarrow +\infty$, namely each $\ee^{i}_{w_{j}}(t)$ tends to some finite constant (either $\mathbf{0}_{M}$, if $j\in \overline{\mathcal{N}}_{i}$, or $\mathbf{g}_{ij}$, otherwise). 
	In conclusion, the following inequality can be derived:
	\begin{equation}\label{eq:ineqerrbase}
		\left\|\ee_{y}\right\|_{2} = k_{y}^{-1} \left\| \left[(\Ll \otimes \Ii_{N}
  ) + \Nn \right]^{-1} \ee_{w}\right\|_{2} \leq \dfrac{\mathfrak{c}(\mathcal{G})}{k_{y}} \left\|\ee_{w}\right\|_{2}
	\end{equation}
	where constant $\mathfrak{c}(\mathcal{G}) > 0$ is the spectral radius of $\left[(\Ll \otimes \Ii_{N}
 ) + \Nn \right]^{-1} \succ 0$. From
	\begin{align}\label{eq:errycij}
		\left\|\ee_{y_{c}}^{i}\right\|_{2}^{2} &= \left\|\dfrac{1}{n} \sum\limits_{j=1}^{n} \ee_{y_{j}}^{i} \right\|_{2}^{2} \leq \dfrac{1}{n^{2}}\sum\limits_{j=1}^{n}\left\| \ee_{y_{j}}^{i}  \right\|_{2}^{2}
	\end{align}
	and \eqref{eq:ineqerrbase} it follows that
	\begin{align}
		\left\|\ee_{y_{c}}\right\|_{2}^{2} &= \sum\limits_{i=1}^{n} \left\|\ee_{y_{c}}^{i}\right\|_{2}^{2} \leq  \dfrac{1}{n^{2}}\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n} \left\| \ee_{y_{j}}^{i}  \right\|_{2}^{2}  \\
		&= \dfrac{1}{n^{2}} \left\|\ee_{y}\right\|_{2}^{2} \leq  \dfrac{\mathfrak{c}(\mathcal{G})^{2}}{n^{2}k_{y}^{2}} \left\|\ee_{w}\right\|_{2}^{2} =\varpi_{y_{c}}^{2}(t)
	\end{align}
	as $t\rightarrow +\infty$ and thus \eqref{eq:centrerrest} is finally proven. 
\end{proof}

\begin{rmk}\label{rm:desiredinputest}
	In Prop. \ref{prop:loccentrest}, dynamics \eqref{eq:ssestim} represents the basis to construct an estimator that computes estimations of both position and velocity centroids $(\pp_{c},\dot{\pp}_{c})$ at each node $i = 1,\ldots,n$. In particular, terms $\widetilde{\ww}_{j}^{i}$ in \eqref{eq:inputestassignment} are assigned according to desired values for the input components $\ww_{j}$ that are not available to agent $i$. It is to note that, if $\ww_{j}$ meets the choice of $\widetilde{\ww}_{j}^{i}$ as expected when $t \rightarrow +\infty$, for any agent $i$, condition \eqref{eq:centrerrest} guarantees that the estimation of the centroid $\yy_{c}$ is accurate, namely the related estimation error $\ee_{y_{c}}$ vanishes as $t \rightarrow +\infty$ (we will see that this condition is satisfied in the framework under analysis whenever the control input $\uu$ tends to zero). In addition, it is worth observing that: (1) high values for $k_{y}$ reduce the upper bound in \eqref{eq:centrerrest};
	(2) the more $\mathcal{G}$ is close to be regular bipartite, the more $\mathfrak{c}(\mathcal{G})$ increases and, for a fixed $n$, $\mathfrak{c}(\mathcal{G})$ decreases as $|\mathcal{E}|$ decreases (see \cite{Shi2007}).
	% (2) a high number of connections $|\mathcal{E}|$ and nodes $n$ in $\mathcal{G}$ reduce the upper bound in \eqref{eq:centrerrest} since $\mathfrak{c}(\mathcal{G})$ is inversely proportional to the first nonzero eigenvalue of the Laplacian $\Ll$.
\end{rmk}

We now propose a local second-order estimator
\begin{equation}
	\widehat{\mathbf{x}}_{c}^{i}(t) = \vc{\widehat{\mathbf{p}}_{c}^{i}(t),\widehat{\dot{\mathbf{p}}}_{c}^{i}(t)} \in \mathbb{R}^{2N}, \quad i = 1,\ldots,n
\end{equation}
in the following corollary. %lemma.

\begin{corollary}[Local second-order centroid estimator]\label{lem:secordest}
	Let $k_{py}$ and $k_{dy}$ be two positive gains. Each node $i = 1,\ldots,n$ can compute the $i$-th estimates $(\widehat{\pp}_{c}^{i},\widehat{\dot{\pp}}_{c}^{i}) = \left(n^{-1}\sum_{j=1}^{n}\widehat{\pp}_{j}^{i}, n^{-1}\sum_{j=1}^{n}\widehat{\dot{\pp}}_{j}^{i} \right)$ for the position and velocities centroids $(\pp_{c},\dot{\pp}_{c})$ in the OIFT problem \eqref{eq:minimizationproblemOIFT} constrained to dynamics \eqref{eq:dyn_sys} exploiting the $i$-th second-order estimator
	\begin{equation}\label{eq:estimator2}
		\begin{cases}
			\dfrac{\mathrm{d}}{\mathrm{d}t}\widehat{\pp}^{i} = -k_{py}  \sum\limits_{j\in \mathcal{N}_{i}} (\widehat{\pp}^{i}-\widehat{\pp}^{j}) -k_{py} \mathbf{N}_{i} (\widehat{\pp}^{i}-\pp ) + \widehat{\dot{\pp}}^{i} \\ %\widehat{\uups}^{i} 
			\dfrac{\mathrm{d}}{\mathrm{d}t}\widehat{\dot{\pp}}^{i} = -k_{dy}  \sum\limits_{j\in \mathcal{N}_{i}} (\widehat{\dot{\pp}}^{i}-\widehat{\dot{\pp}}^{j}) -k_{dy} \mathbf{N}_{i} (\widehat{\dot{\pp}}^{i}-\dot{\pp} ) + \widehat{\uu}^{i}
		\end{cases}
	\end{equation}
	such that $\widehat{\pp}^{i} = \vcj{\widehat{\pp}^{i}_{j}}{n}$, $\widehat{\dot{\pp}}^{i} = \vcj{\widehat{\dot{\pp}}^{i}_{j}}{n}$, $\widehat{\uu}^{i} = \vcj{\widehat{\uu}^{i}_{j}}{n}$, with
	%	\begin{equation}\label{eq:estinupt2ord}
		%		\begin{bmatrix}
			%			\widehat{\uups}^{i}_{j} \\ \widehat{\uu}^{i}_{j}
			%		\end{bmatrix} = \begin{cases}
			%			\vc{\dot{\pp}_{j},\uu_{j}}, &\text{if } j\in \overline{\mathcal{N}}_{i}; \\
			%			\vc{\widehat{\dot{\pp}}_{j}^{i},\mathbf{0}_{M}}, &\text{otherwise}.
			%		\end{cases}
		%	\end{equation}
	\begin{equation}\label{eq:estinupt2ord}
			\widehat{\uu}^{i}_{j} = \begin{cases}
				\uu_{j}, &\text{if } j\in \overline{\mathcal{N}}_{i}; \\
				\mathbf{0}_{M}, &\text{otherwise};
			\end{cases}
		\end{equation}
	and initialized as\footnote{In the second row of \eqref{eq:initializationofestimator}, if the information on the degree $|\mathcal{N}_{k}|$ is not available one can simply average $\vc{\pp_{k}(0),\dot{\pp}_{k}(0)}$ over $|\overline{\mathcal{N}}_{i}|$.}
	\begin{equation}\label{eq:initializationofestimator}
		\begin{bmatrix}
			\widehat{\pp}^{i}_{j}(0) \\ \widehat{\dot{\pp}}^{i}_{j}(0)
		\end{bmatrix} = \begin{cases}
			\vc{\pp_{j}(0),\dot{\pp}_{j}(0)}, &\text{if } j\in \overline{\mathcal{N}}_{i}; \\  \dfrac{\sum\limits_{k\in \overline{\mathcal{N}}_{i}}(1+|\mathcal{N}_{k}|)\vc{\pp_{k}(0),\dot{\pp}_{k}(0)}}{\sum_{k\in \overline{\mathcal{N}}_{i}} (1+|\mathcal{N}_{k}|)}, &\text{otherwise}.
		\end{cases}
	\end{equation}
	
	Furthermore, if $\mathbf{u}$ is a stabilizing input for system \eqref{eq:dyn_sys} and is such that $\mathbf{u} \rightarrow \mathbf{0}_{N}$ as $t$ grows then, for large values of $t$, 
	the $i$-th position estimation error $\ee_{p}^{i} = \pp - \widehat{\pp}^{i} $ and the $i$-th velocity estimation error $\ee_{\dot{p}}^{i} =  \dot{\pp} - \widehat{\dot{\pp}}^{i} $ vanish. In particular, setting $\ee_{p_{c}}^{i} = n^{-1} \sum_{j=1}^{n} \ee_{p_{j}}^{i}$, $\ee_{\dot{p_{c}}}^{i} = n^{-1} \sum_{j=1}^{n} \ee_{\dot{p}_{j}}^{i}$, $\ee_{p_{c}} = \vci{\ee_{p_{c}}^{i}}{n}$, $\ee_{\dot{p_{c}}} = \vci{\ee_{\dot{p_{c}}}^{i}}{n}$ one has
	\begin{equation}\label{eq:ineqerrbase2}
		\left\|	\ee_{p_{c}}(t) \right\|_{2}^{2} + \left\|	\ee_{\dot{p}_{c}}(t) \right\|_{2}^{2}  \leq  \dfrac{\mathfrak{c}(\mathcal{G})^2}{n^{2} \min(k_{py},k_{dy})^{2}} \sum\limits_{i=1}^{n} \sum\limits_{j\in \mathcal{V}\setminus \overline{\mathcal{N}}_{i}} \left\|\uu_{j}(t) \right\|^{2}_{2}
	\end{equation}
	as $t$ gets larger if each $\uu_{j}^{i}(t)$ tends to some finite value.
	%each velocity estimation error $(\dot{\pp}_{c} - \widehat{\dot{\pp}}_{c}^{i} )$ vanishes, while each position estimation error $(\pp_{c} - \widehat{\pp}_{c}^{i} )$ converges to some constant vector.
\end{corollary}
\begin{proof}
	The estimator developed in this lemma is the natural second-order extension of the results illustrated in Prop. \ref{prop:loccentrest}. One can demonstrate the convergence properties for the estimation errors by analyzing the stability of the system
	\begin{equation}\label{eq:errordynamicssoe}
		\begin{bmatrix}
			\dot{\ee}_{p} \\ \dot{\ee}_{\dot{p}} 
		\end{bmatrix} =
		\begin{bmatrix}
			\Mm_{p} & \Ii_{Nn} \\ \mathbf{O}_{Nn} & \Mm_{\dot{p}} 
		\end{bmatrix}
		\begin{bmatrix}
			\ee_{p} \\ \ee_{\dot{p}} 
		\end{bmatrix} +
		\begin{bmatrix}
			\mathbf{0}_{Nn} \\ \ee_{u} 
		\end{bmatrix}
	\end{equation}
	where $\dot{\ee}_{p} = \vci{\dot{\ee}_{p}^{i}}{n}$, $\dot{\ee}_{\dot{p}} = \vci{\dot{\ee}_{\dot{p}}^{i}}{n}$, $\ee_{u} =  \vci{\uu-\widehat{\uu}^{i}}{n}$, $\Mm_{p} = -k_{py} ((\Ll \otimes \Ii_{N})+\Nn)$, $\Mm_{\dot{p}} = -k_{dy} ((\Ll \otimes \Ii_{N})+\Nn)$ and with $\Nn$ defined as in Prop. \ref{prop:loccentrest}. Given the structure of the update matrix in \eqref{eq:errordynamicssoe}, hereafter denoted with $\overline{\Mm}$, it can be noted that its eigenvalues exactly coincide with those of $\Mm_{p}$ and $\Mm_{\dot{p}}$. Using the same reasoning in the proof of Prop. \ref{prop:loccentrest}, the system in \eqref{eq:errordynamicssoe} stabilizes around $\ee^{\star}(t) = -\overline{\Mm}^{-1} \begin{bmatrix}
		\mathbf{0}_{Nn}^{\top} & \ee_{u}(t)^{\top}
	\end{bmatrix}^{\top} $ as $t$ grows.
	As also pointed out in Rem. \ref{rm:desiredinputest}, the exogenous inputs for the estimator chosen in \eqref{eq:estinupt2ord} (i.e., the entries $\uu_{j}$ if $j\in \overline{\mathcal{N}}_{i}$; $\mathbf{0}_{M}$, otherwise) are selected in such a way that both $\ee_{p}^{i}$  and $\ee_{\dot{p}}^{i}$ vanish for large values of $t$.\\
	%It is worth noting that this corollary can be directly proven by applying \eqref{eq:ineqerrbase} to the velocity estimation dynamics (second row of \eqref{eq:estimator2}). 
	%Then, applying again \eqref{eq:ineqerrbase} to the position estimation dynamics (first row of \eqref{eq:estimator2}), it also follows that position estimation error $\ee_{p}^{i}$ tends to zero as $\ee_{\dot{p}}^{i}$ tends to zero.
	Finally, relation \eqref{eq:ineqerrbase2} can be derived similarly to \eqref{eq:ineqerrbase} by leveraging the 
	dynamics \eqref{eq:errordynamicssoe} and adopting \eqref{eq:estinupt2ord}.
	
\end{proof}

\subsection{Online distributed feedback control law}\label{sec:distr_law}
In light of the above reasoning, we are now ready to discuss the distributed feedback control law complying with the design criteria $(i)$-$(iii)$.
To this aim, we propose the distributed feedback control law $\widehat{\uu} = \vci{\widehat{\uu}_{i}}{n} $, $\widehat{\uu}_{i} \in \mathbb{R}^{M}$, that only relies on each agent's local reference frame and is defined as
\begin{align}\label{eq:distrOIFTsol}
	\widehat{\uu}_{i} =& -\mathbf{R}_{i}^{-1}(k_{p}^{tr1} \nabla_{\pp_{i}} l^{tr1}+k_{d}^{tr1} \dot{\nabla}_{\pp_{i}} l^{tr1} +  k_{p}^{fo1} \nabla_{\pp_{i}} l^{fo1}+ \nonumber\\
	&k_{d}^{fo1} \dot{\nabla}_{\pp_{i}}^{safe} l^{fo1} + k_{p}^{tr2} \nabla_{\dot{\pp}_{i}} l^{tr2}  + k_{p}^{fo2} \nabla_{\dot{\pp}_{i}} l^{fo2}) ,
\end{align}
where terms $ \nabla_{\pp_{i}} l^{tr1}, \dot{\nabla}_{\pp_{i}} l^{tr1}, \nabla_{\dot{\pp}_{i}} l^{tr2} $ in \eqref{eq:distrOIFTsol} are computed through the second-order local estimator in Cor. \ref{lem:secordest}. 
Constants $k_{p}^{tr1},k_{p}^{fo1},k_{d}^{tr1},k_{d}^{fo1},k_{p}^{tr2},$ $k_{p}^{fo2}$ are positive control gains that can be adjusted by the designer, e.g. by matching the centralized solution during simulations and considering that law in \eqref{eq:distrOIFTsol} has a structure similar to a PD controller\footnote{Such control gains cannot be generally tuned a-priori, as their values depend on the specific network interconnections and the chosen parameter weights.}. 

The expression of the control law in \eqref{eq:distrOIFTsol} can be justified as follows.
The design criterion $(i)$ is satisfied, since the structure of $\widehat{\uu} = -\Rr^{-1}\Bb^{\top} \widehat{\lamlam}$ mimics the one provided by the optimal control $\uu^{\star} = -\Rr^{-1}\Bb^{\top} \lamlam$ in Thm. \ref{lem:PMP}. Indeed, the solution of the co-state equation in \eqref{eq:PMPcostates} can be reproduced by means of
\begin{equation}\label{eq:lamdynest}
	\forall i=1,\ldots,n:~~\begin{cases}
		\widehat{\lamlam}_{i} =  k_{p}^{tr1} \nabla_{\pp_{i}} l^{tr1}+k_{d}^{tr1} \dot{\nabla}_{\pp_{i}} l^{tr1} + \\ ~~~~~~~\! k_{p}^{fo1} \nabla_{\pp_{i}} l^{fo1} + k_{d}^{fo1} \dot{\nabla}_{\pp_{i}} l^{fo1} \\
		\widehat{\lamlam}_{i+n} = \widehat{\lamlam}_{i}+ k_{p}^{tr2} \nabla_{\dot{\pp}_{i}} l^{tr2}  + k_{p}^{fo2} \nabla_{\dot{\pp}_{i}} l^{fo2}
	\end{cases},
\end{equation}
since $(\widehat{\lamlam}_{i}, \widehat{\lamlam}_{i+n}) \approx (\lamlam_{i}, \lamlam_{i+n})$ represents %a first-order approximation
an approximated gradient dynamics for the Lagrangian multipliers whenever the control gains can be selected to satisfy\footnote{Up to some maximum tolerance established by design.} %the dynamics
\begin{equation}\label{eq:diffeqlamapprox}
	\forall i=1,\ldots,n:~~\begin{cases}
		- \nabla_{\pp_{i}} l^{tr1} \approx k_{d}^{tr1} \ddot{\nabla}_{\pp_{i}} l^{tr1} + k_{p}^{tr1} \dot{\nabla}_{\pp_{i}} l^{tr1}    \\
		- \nabla_{\pp_{i}} l^{fo1} \approx k_{d}^{fo1} \ddot{\nabla}_{\pp_{i}} l^{fo1} +k_{p}^{fo1} \dot{\nabla}_{\pp_{i}} l^{fo1}   \\
		-\nabla_{\dot{\pp}_{i}} l^{tr2} \approx k_{p}^{tr2} \dot{\nabla}_{\dot{\pp}_{i}} l^{tr2}  \\
		-\nabla_{\dot{\pp}_{i}} l^{fo2} \approx k_{p}^{fo2} \dot{\nabla}_{\dot{\pp}_{i}} l^{fo2} 
	\end{cases}.
\end{equation} 
It is also worth to notice that whenever $\sigma^{\prime}_{d_{ij}} \geq 0$ for all $(i,j)\in \mathcal{E}$, input $\widehat{\uu}$ not only approximates $\uu^{\star}$ but is also \textit{practically optimal}, as \eqref{eq:PMPsuff} is satisfied. For this reason, drawing inspiration from the setup illustrated in Sec. \ref{subsec:PRONTOsolvesOIFT},
term $\dot{\nabla}_{\mathbf{p}_{i}}^{safe} l^{fo1} = -\sum_{j\in \mathcal{N}_{i}} \mathcal{H}^{safe}_{\pp_{i}\pp_{j}} l^{fo1} \dot{\ee}_{ij}$ is used in $\widehat{\uu}$ instead of $\dot{\nabla}_{\mathbf{p}_{i}} l^{fo1} = -\sum_{j\in \mathcal{N}_{i}} \mathcal{H}_{\pp_{i}\pp_{j}} l^{fo1} \dot{\ee}_{ij}$. However, the presence of negative $\sigma_{d_{ij}}^{\prime}$ in the term $\nabla_{\pp_{i}}l^{fo1}$ cannot be altered with this heuristics because the latter is part of $\nabla_{\xx} l^{st}$, i.e. it appears directly in the co-state equation \eqref{eq:PMPcostates}. Indeed, $\nabla_{\pp_{i}}l^{fo1}$ is vital for steering the formation positions when repulsive behaviors are required to come into play.
Then, the design criterion $(ii)$ is obeyed, since the structure of $\uu_{i}$ is distributed by construction, i.e. node $i$ uses the information of nodes $j \in \overline{\mathcal{N}}_{i} = \mathcal{N}_{i} \cup \{i\}$ only. In particular, the second-order local estimator in Cor. \ref{lem:secordest} is exploited by each agent to reconstruct the centroid information of the system. 
% Lastly,
Moreover, the design criterion $(iii)$ is observed, since $\uu_{i}$ is a function of the current state $\xx(t)$ only and does not require prior computations, e.g. trajectory optimization techniques are not needed.

Finally, the following couple of remarks provide more details on both the theoretical and practical requirements regarding the adoption of \eqref{eq:distrOIFTsol}.









% --------------------------------------------------------------------------------------------
\begin{comment}
	
	
	\begin{rmk}
		Notably, \eqref{eq:diffeqlamapprox} can be interpreted as an asymptotically stable dynamics, implying that \eqref{eq:lamdynest} is a valid approximation for the Lagrangian multipliers for large values of $t$. Consequently, the co-state optimality condition \eqref{eq:PMPcostates} can be approximately satisfied in any scenario and the computation of $2N$ scalar Lagrangian multipliers depending on time is thus downsized to the choice of positive gains $k_{p}^{tr1},k_{p}^{fo1},k_{d}^{tr1},k_{d}^{fo1},k_{p}^{tr2},k_{p}^{fo2}$.
	\end{rmk}
	
\end{comment}
		\begin{rmk}
				Out of their context, equations in \eqref{eq:diffeqlamapprox} can be interpreted as an asymptotically stable dynamics, whenever the constant gains $k_{p}^{tr1}$, $k_{p}^{fo1}$, $k_{d}^{tr1}$, $k_{d}^{fo1}$, $k_{p}^{tr2}$, $k_{p}^{fo2}$ are positive. On the other hand, it is worth to recall that, in this framework, the evolution over time of each variable $(\xx^{\star},\lamlam^{\star},\uu^{\star})$ depends primarily on $\nabla_{\xx} l^{st}(\xx^{\star})$, since $\xx^{\star}$ linearly depends on $\uu^{\star}$ that, in turn, linearly depends on $\lamlam^{\star}$, whose behavior is dictated by structure of $\nabla_{\xx} l^{st}(\xx)$. With such a perspective, the co-state approximation $(\widehat{\lamlam}_{i}, \widehat{\lamlam}_{i+n}) \approx (\lamlam_{i}, \lamlam_{i+n})$ can be satisfied in any scenario, implying that \eqref{eq:lamdynest} is a valid method to approximate the Lagrangian multipliers for large values of $t$ if $m(\xx(T))$ is selected as in \eqref{eq:final_cost_m}. %Nonetheless, the challenging aspect here is represented by the feedback gain tuning in order to achieve \eqref{eq:diffeqlamapprox} as $t$ approaches $T$, while maintaining the magnitude of $\widehat{\uu}$ big enough to be effective.
    To some extent, the backward integration that emerges from the co-state computation in \eqref{eq:PMPcostates} boils down to the adjustment gains $k_{p}^{tr1},k_{p}^{fo1},k_{d}^{tr1},k_{d}^{fo1},k_{p}^{tr2},k_{p}^{fo2}$: this fact is crucial, since the need for the computation of $2N$ scalar Lagrangian multipliers depending on future time instants is downsized to the choice of a finite number of positive constants.
		\end{rmk}

\begin{rmk}
%Since a 
As far as the distributed online formation tracking control law \eqref{eq:distrOIFTsol} is adopted,
%is proposed in this paper, 
there is no possible means to ensure that all the agents be aware of each mutual position.
%(or at least the relative position among them).
For this reason, collisions (especially between non-neighbors) may occur. 
%This may lead to the collision problem between non-neighbors agent and, to 
To avoid this kind of issue, collision avoidance protocols taking into account the complete topology w.r.t. the underlying graph should be implemented (see \cite{yang2019tracking}).
%To avoid this issue, collision avoidance protocols should be implemented.
%In order to guarantee collision avoidance among the agents in a distributed fashion it is necessary that all the agent exchange information each other \cite{yang2019tracking}, namely the graph must be complete.
Nonetheless, such an approach may be too restrictive; thus, another possible solution is that of equipping each agent with a proximity sensor to guarantee a safety distance radius.
%Since we want to avoid this particular case, because it is too restrictive,  another solution could be implement on each agent a proximity sensor, in this way every time two agents are too close (namely the sensor measure an agent inside its safety distance radius) the control input is modified in order to avoid the collision. 
%One could add another potential function similar to the first row of \eqref{eq:potential} in which the repulsion therm is much larger and the control inserted as an additional term inside \eqref{eq:distrOIFTsol}, however this is not the main focus of this paper and will be considered in details in future works. 
This, in turn, can be put into practice by resorting to repulsive potentials such as that in the first row of \eqref{eq:potential}, e.g. by triggering a repulsive action that is dominant w.r.t. the terms in \eqref{eq:distrOIFTsol} as soon as safety distances are not satisfied. 
\end{rmk}
	

	\subsubsection{Stability analysis}
	In order to discuss the convergence properties of the control law devised in Ssec. \ref{sec:distr_law} we refer to \cite{SunAndreson2017rigid}. 
	To begin, let us consider the formation terms in \eqref{eq:distrOIFTsol} (marked with ``$fo$'' superscripts): these can be thought as part of a gradient dynamics designed along the same guidelines explored in many research works related to rigid formation control. For this reason, it can be formally proven that the formation stabilization of the given second-order system \eqref{eq:dyn_sys} occurs provided that the underlying network is undirected and infinitesimally rigid (see also \cite{ahn2020book} for more details). Under the latter conditions, it is indeed well known that certain second-order MASs achieve flocking behaviors with both velocity consensus and shape stabilization. In the following lines, we shall clarify that this is also the case when the control law devised in Ssec. \ref{sec:distr_law} is applied. In particular, it is worth showing that the formation terms in \eqref{eq:distrOIFTsol} can be rewritten as a positively-weighted version of equation (12) in \cite{SunAndreson2017rigid}:
	\begin{align}\label{eq:distrOIFTsolformation}
		\widehat{\uu}_{i}^{fo} &= -\mathbf{R}_{i}^{-1}(   k_{p}^{fo1} \nabla_{\pp_{i}} l^{fo1}+
		k_{d}^{fo1} \dot{\nabla}_{\pp_{i}}^{safe} l^{fo1}  + k_{p}^{fo2} \nabla_{\dot{\pp}_{i}} l^{fo2})  \\
		&= -\sum\limits_{j\in \mathcal{N}_i} \mathbf{V}_{ij} (\widehat{\dot{\pp}}_{i}-\widehat{\dot{\pp}}_{j})  - (k_{p}^{fo1}k_{F}\mathbf{R}_{i}^{-1}) \sum\limits_{j\in \mathcal{N}_i} \sigma_{d_{ij}}^{\prime} \!\!\left(\left\|\widehat{\pp}_{i}-\widehat{\pp}_{j}\right\|^{2}_{2}\right)  (\widehat{\pp}_{i}-\widehat{\pp}_{j}) , \nonumber
	\end{align}
	where the weighting factors are expressed by quantities $(k_{p}^{fo1}k_{F}\mathbf{R}_{i}^{-1}) \succ 0$ and
	\begin{equation*}
		\mathbf{V}_{ij} =  -\mathbf{R}_{i}^{-1} (k_{p}^{fo2}\mathcal{H}_{\dot{\pp}_{i},\dot{\pp}_{j}} l^{fo2} + k_{d}^{fo1} \mathcal{H}^{safe}_{\pp_{i},\pp_{j}} l^{fo1}(\widehat{\pp})) \succ 0, \quad \forall \widehat{\pp} \in \mathbb{R}^{N}.
	\end{equation*}
	We then recall that the centroid velocity is a constant of motion for \eqref{eq:distrOIFTsolformation} (see Lemma 3.1 in \cite{SunAndreson2017rigid}). Hence, the formation dynamics \eqref{eq:distrOIFTsolformation} can be completely decoupled from the remaining tracking terms (marked with ``$tr$'' superscript) while analyzing \eqref{eq:distrOIFTsol}. In fact, by setting $\bar{\Cc} = n^{-1} \begin{bmatrix}
		\Ii_{M} & \cdots & \Ii_{M}
	\end{bmatrix} \in \mathbb{R}^{M\times N}$ and $\Qq = \Diag(\Qq_{c},\Qq_{\dot{c}})$, it can be appreciated that the term
	\begin{align}\label{eq:distrOIFTsoltracking}
		\widehat{\uu}_{i}^{tr} &= -\mathbf{R}_{i}^{-1}(k_{p}^{tr1} \nabla_{\pp_{i}} l^{tr1}+k_{d}^{tr1} \dot{\nabla}_{\pp_{i}} l^{tr1} + k_{p}^{tr2} \nabla_{\dot{\pp}_{i}} l^{tr2}) , \\
		&= - \mathbf{R}_{i}^{-1} \bar{\Cc}^{\top} \left[ k_{p}^{tr1} \Qq_{c} (\bar{\Cc} \widehat{\pp} - \pp_{c,des}) +  (k_{d}^{tr1} \Qq_{c}+k_{p}^{tr2}\Qq_{\dot{c}}) (\bar{\Cc} \widehat{\dot{\pp}} - \dot{\pp}_{c,des}) \right] \nonumber
	\end{align}
	only affects the tracking\footnote{\rev{It can be also observed that action \eqref{eq:distrOIFTsoltracking} minimizes the cost in \eqref{eq:track_inst_cost}, as $l^{tr}$ is quadratic in $\xx(t)$.}} of both the desired centroid position and velocity. Consequently, the tracking term in \eqref{eq:distrOIFTsoltracking} does not influence the equilibria attained by applying \eqref{eq:distrOIFTsolformation}. As a result, the same flocking behavior and shape stabilization of the original protocol (12) in \cite{SunAndreson2017rigid} are preserved upon the linear combination $\widehat{\uu}_{i} = \widehat{\uu}_{i}^{tr}+\widehat{\uu}_{i}^{fo}$.\\
	Additionally, it is also worth to notice that, since $\widehat{\uu}_{i}$ is a gradient-based law, it is stabilizing for both formation and tracking. Whenever the final trait of the desired path is required to be covered at a constant velocity, one has $\widehat{\uu}(T) \rightarrow \uups $ for large enough $T$, where $\uups$ is some (small) constant due to the fact that a second-order integrator controlled through proportional-derivative feedback reaches zero steady-state error. %Clearly, $\uups=\mathbf{0}_{N}$ if and only if the velocities of the system matches the desired velocity since the initial instants. 
	The expression in \eqref{eq:ineqerrbase2} for the local second-order estimator presented in Cor. \ref{lem:secordest} can be thus used to roughly bound the steady-state estimation error at time $t=T$. 


\subsubsection{Heuristics to limit the energy consumption}
%To conclude, 
To conclude the discussion, we illustrate a simple method that can be considered to limit the input energy. The adoption of a saturated version $\bar{\uu}$ of input $\widehat{\uu}$ can be indeed employed to refine approximation errors made by \eqref{eq:lamdynest}, since high values for the feedback gains imply high values for the instantaneous input energy $l^{in}(\widehat{\uu})$. In formulas, for all individual scalar components $j = 1,\ldots,N$, assign
\begin{equation}\label{eq:saturation_heuristics}
	\bar{u}_{j} = \begin{cases}
		\widehat{u}_{j}, \quad &\text{if } \left|\widehat{u}_{j}\right| \leq U; \\
		\mathrm{sign}(\widehat{u}_{j})U, \quad &\text{otherwise.}
	\end{cases}
\end{equation}
where $\mathrm{sign}$ is the classic sign function (defined as $0$ at $0$) and $U>0$ is a suitable saturation constant inversely proportional to each feedback gain. \\

\begin{comment}
	
	
	\begin{enumerate}
		\item Choose gains $k_{p}^{tr1},k_{p}^{fo1},k_{d}^{tr1},k_{d}^{fo1},k_{p}^{tr2},k_{p}^{fo2}>0$ small enough to ensure condition \eqref{eq:practfoc}, but also large enough for $\widehat{\uu}$ to control the state $\xx$ effectively in $[0,T]$.
		\item Consider to adopt a saturated version $\bar{\uu}$ of input $\widehat{\uu}$, since high values for the feedback gains imply high values for the instantaneous input energy $l^{in}(\widehat{\uu})$. In formulas, for all individual scalar components $j = 1,\ldots,N$, assign
		\begin{equation}\label{eq:saturation_heuristics}
			\bar{u}_{j} = \begin{cases}
				\widehat{u}_{j}, \quad &\text{if } \left|\widehat{u}_{j}\right| \leq U; \\
				\mathrm{sign}(\widehat{u}_{j})U, \quad &\text{otherwise.}
			\end{cases}
		\end{equation}
		where $\mathrm{sign}$ is the classic sign function (defined as $0$ at $0$) and $U>0$ is a suitable saturation constant inversely proportional to each feedback gain. 
	\end{enumerate}
	
\end{comment}




\begin{comment}
	The OIFT problem can be, in principle, solved even in a distributed way and online. In order to design a distributed control law, we draw inspiration from the Calculus of Variations. Specifically, we seek the expression of a feedback PD controller $\mathbf{u}(\tau) = \mathbf{u}(\mathbf{x}(\tau))$ in which each term represents an error to achieve tracking, formation or alignment. \\%To this purpose, we propose an approach based on the Euler-Lagrangian equations. 
	Firstly, let $h_{l} := h-m$ be the objective functional to be minimized, such that
	\begin{equation}\label{eq:ham_act}
		h_{l}(\mathbf{x}(\cdot),\mathbf{u}(\cdot)) = \int_{0}^{T} l\left(\mathbf{x}(\tau), \mathbf{u}(\tau), \tau \right) d\tau.
	\end{equation}
	We assume that the extrema for functions $\mathbf{x}(\cdot)$ and $\mathbf{u}(\cdot)$ are somehow fixed, since $\mathbf{x}(0)$ is specified, $\mathbf{x}(T)$ belongs to the manifold determined by final cost $m(\mathbf{x}(T))$, $\mathbf{u}(0)$ depends on $\mathbf{x}(0)$ and $\mathbf{u}(T) = \mathbf{0}_{N}$ is expected.
	%This simplification is motivated by the fact that the instantaneous cost $l$ already takes into account final cost $m$, since it holds that $l(\mathbf{x}(T)) = m(\mathbf{x}(T)) + \mathbf{u}(T)$. 
	It is worth to notice that instantaneous cost $l \left(\mathbf{x}(\tau), \mathbf{u}(\tau) \right)$ in \eqref{eq:ham_act} can be decomposed agent-wise as
	\begin{equation}\label{eq:docompositionl}
		l \left(\mathbf{x}(\tau), \mathbf{u}(\tau) \right) = \sum_{i=1}^{n} l_{i} \left(\mathbf{x}(\tau), \mathbf{u}(\tau)\right),
	\end{equation}
	and, according to decomposition \eqref{eq:docompositionl}, for the $i$-th agent, one has
	\begin{equation}
		l_{i}  = \dfrac{1}{2}   \left\| \mathbf{x}_{c} - \mathbf{x}_{c,des} \right\|_{\mathbf{Q}_{c,\dot{c},i}}^{2}   +  \dfrac{1}{2}  \left\| \mathbf{u}_{i} \right\|_{\mathbf{R}_{i}}^{2} + \dfrac{k_{F}}{4} \sum\limits_{\forall j \neq i} \sigma_{d_{ij}}(s_{ij}) + \dfrac{k_{A}}{4}  \sum\limits_{\forall j \neq i}  \left\|\dot{\mathbf{p}}_{i}-\dot{\mathbf{p}}_{j} \right\|_{q_{A_{ij}}}^{2}.
	\end{equation}
	%in which $\mathbf{Q}_{c,\dot{c},i} = \Diag \left\lbrace \mathbf{Q}_{c,i}, \mathbf{Q}_{\dot{c},i} \right\rbrace  \in \mathbb{R}^{2M \times 2M}$ is the block matrix obtained by the two blocks in $\mathbf{Q}$ relative to the position and velocity centroid weights for agent $i$. Whereas, $\mathbf{R}_{i}$ is the $i$-th block of matrix $\mathbf{R}$.\\
	With this premise, we state the following Thm. \ref{thm:ui} in order to design a proper PD controller to drive the group of agents.
	\begin{Thm}\label{thm:ui}$~$\\
		Let us define $\overline{\mathbf{Q}}_{c} := \sum_{j=1}^{n} \mathbf{Q}_{c,j}/n$, $\overline{\mathbf{Q}}_{\dot{c}} := \sum_{j=1}^{n} \mathbf{Q}_{\dot{c},j}/n$, with $\overline{\mathbf{Q}}_{\dot{c}}$ non-singular. Assuming to adopt a distributed PD controller $\mathbf{u} = \begin{bmatrix}
			\mathbf{u}_{1}^{\top} & \cdots & \mathbf{u}_{n}^{\top}
		\end{bmatrix}^{\top}$ in order to govern the dynamics of system \eqref{eq:dyn_sys}, the objective in \eqref{eq:ham_act} is stationary with the following distributed control law:
		\begin{align}\label{eq:distr_ctrl_law}
			\mathbf{u}_{i} = & -\mathbf{R}_{i}^{-1} \left[ k_{P,i}^{tr} \overline{\mathbf{Q}}_{c} (\mathbf{p}_{c}-\mathbf{p}_{c,des}) + k_{D,i}^{tr} \overline{\mathbf{Q}}_{\dot{c}} (\dot{\mathbf{p}}_{c}-\dot{\mathbf{p}}_{c,des}) \right]  \nonumber \\
			& -\mathbf{R}_{i}^{-1} \left[ k_{P,i}^{fo} k_{F} \sum\limits_{j \in \mathcal{N}_{i}} \sigma^{\prime}_{d_{ij}}(s_{ij}) \mathbf{e}_{ij} + k_{D,i}^{al} k_{A} \sum\limits_{j \in \mathcal{N}_{i}} q_{Aij} \dot{\mathbf{e}}_{ij} \right] \nonumber \\
			& -\mathbf{R}_{i}^{-1} k_{D,i}^{fo} k_{F} \sum\limits_{j \in \mathcal{N}_{i}}  \left[2\sigma^{\prime \prime}_{d_{ij}}(s_{ij})\mathbf{\Pi}_{ij} + \chi_{>0}(\sigma^{\prime}_{d_{ij}}(s_{ij})) \sigma^{\prime }_{d_{ij}}(s_{ij}) \mathbf{I}_{M} \right]\dot{\mathbf{e}}_{ij};
		\end{align}
		where $\mathcal{N}_{i}$ is the neighborhood of the $i$-th agent, i.e. the set of nodes that have established a communication with $i$ and $k_{P,i}^{tr}$, $k_{D,i}^{tr}$, $k_{P,i}^{fo}$, $k_{D,i}^{fo}$, $k_{D,i}^{al}$ are positive tunable gains.
	\end{Thm}
	\begin{proof}
		Recalling that the system under analysis is controlled in acceleration, that is $\mathbf{u} = \ddot{\mathbf{p}}$, we write the $i$-th equation obtained by the Fundamental Lemma of Calculus of Variations applied to \eqref{eq:ham_act} in a distributed fashion:
		%Recalling that the system under analysis is controlled in acceleration, that is $\mathbf{u} = \ddot{\mathbf{p}}$, we consider the arbitrary constants\footnote{These can be seen as unknown Lagrange multipliers for equation \eqref{eq:E-Leqs} with dimensionality $\si{\second^{-2}}$.} $k_{u,i}>0$, $i = 1,\ldots, n$, to write, in a distributed fashion, the $i$-th Euler-Lagrangian equation for an approximation of $h_{l}$ in which the input energy $l^{in}(\mathbf{u}(\tau))$ is treated as virtual work:
		% \sum\limits_{j=1}^{n}    \left(k_{u,j}\dfrac{\partial l_{j}(\mathbf{x},\mathbf{u})}{\partial \mathbf{u}_{j}}  \dfrac{\partial \mathbf{p}_{j}}{\partial \mathbf{p}_{i}} \right)
		\begin{equation}\label{eq:E-Leqs}
			\sum\limits_{j=1}^{n} \left(- \dfrac{d^{2}}{dt^{2}} \dfrac{\partial l_{j}(\mathbf{x},\mathbf{u})}{\partial \ddot{\mathbf{p}}_{i}} + \dfrac{d}{dt} \dfrac{\partial l_{j}(\mathbf{x},\mathbf{u})}{\partial \dot{\mathbf{p}}_{i}}   - \dfrac{\partial l_{j}(\mathbf{x},\mathbf{u})}{\partial \mathbf{p}_{i}} \right) =  \mathbf{0}_{M}, \quad i=1, \ldots, n.
		\end{equation}
		%Such a Lagrangian-based formalism is justified by the fact that if the trajectory $\mathbf{x}(\cdot)$ is \textquotedblleft natural\textquotedblright$~$for the system, provided that agent $i$ is driven only by an active force proportional to $\mathbf{u}_{i}(\cdot)$, then the Least Action Principle (LAP) is obeyed to a certain degree. Indeed, constraint $\mathbf{u}(\cdot)=\mathbf{0}_{N}$ would lead equations in \eqref{eq:E-Leqs} being the necessary condition to verify the LAP, yielding the trajectory $\mathbf{x}(\cdot)$ that minimizes the action integral \eqref{eq:ham_act}. However, this would be prohibitive, since no control would act on the system. As a consequence, the synthesis of this distributed controller is suboptimal compared a framework such as PRONTO, yet its performances over the time are high if it is guaranteed that $l^{in}(\mathbf{u}(\tau))$ vanishes as $\tau \rightarrow T$.
		Let us observe that the $i$-th equation in \eqref{eq:E-Leqs} can be rewritten as
		\begin{align}\label{eq:E-Lp}
			& \sum\limits_{j=1}^{n} \dfrac{\mathbf{Q}_{\dot{c},j}}{n} \left(\ddot{\mathbf{p}}_{c} - \ddot{\mathbf{p}}_{c,des} \right)  
			+ k_{A} \sum\limits_{\forall j \neq i}  q_{A_{ij}} \ddot{\mathbf{e}}_{ij}  \nonumber \\
			-& \sum\limits_{j=1}^{n} \dfrac{\mathbf{Q}_{c,j}}{n} \left(\mathbf{p}_{c} - \mathbf{p}_{c,des} \right) 
			- k_{F} \sum\limits_{\forall j \neq i}  \sigma_{d_{ij}}^{\prime} (s_{ij})  \mathbf{e}_{ij} =
			\mathbf{R}_{i}\ddot{\mathbf{u}}_{i}.
		\end{align} % k_{u,i}
		%while, the $i$-th equation in \eqref{eq:E-Leqs} relative to the last $M$ coordinates can be expressed by
		%\begin{equation}\label{eq:E-Lpdot}
		%\mathbf{R}_{i} \dddot{\mathbf{p}}_{i}  
		%- \sum\limits_{j=1}^{n} \dfrac{\mathbf{Q}_{\dot{c},j}}{n} \left(\dot{\mathbf{p}}_{c} - \dot{\mathbf{p}}_{c,des} \right) - k_{A} \sum\limits_{\forall j\neq i} q_{A_{ij}}  %\dot{\mathbf{e}}_{ij}=
		%k_{\dot{u}} \mathbf{R}_{i}\dot{\mathbf{u}}_{i}.
		%\end{equation}
		Since the information on the centroid $\mathbf{x}_{c}$ is not directly available, we allow its computation via an average consensus procedure with Metropolis-Hastings weights \cite{GarinSchenato2010}. The same strategy can be employed to compute terms $\sum_{j=1}^{n} \mathbf{Q}_{c,j}/n$ and $\sum_{j=1}^{n} \mathbf{Q}_{\dot{c},j}/n$ in \eqref{eq:E-Lp}%and \eqref{eq:E-Lpdot}
		, since they represent two average weights. %However, the latter approach just offers an approximation of the real quantity, because this estimation is not correct if matrices $\mathbf{Q}_{c,j}$ and $\mathbf{Q}_{\dot{c},j}$ are not homogeneous\footnote{Namely, they must have a relatively low variance w.r.t. their average value.}. 
		That said, we denote the estimates of $\sum_{j=1}^{n} \mathbf{Q}_{c,j}/n$ and $\sum_{j=1}^{n} \mathbf{Q}_{\dot{c},j}/n$ obtained via the consensus with $\overline{\mathbf{Q}}_{c}$ and $\overline{\mathbf{Q}}_{\dot{c}}$ respectively.
		Now, in order to design a proper PD controller, we need an explicit linear expression of $\mathbf{u}$ depending on position and velocity errors only. Hence, given the structure of equations in \eqref{eq:E-Lp}%-\eqref{eq:E-Lpdot}
		, it is reasonable to assume the centroid error acceleration and relative\footnote{Whenever a couple of agents $(i,j)$ exchanges information.} accelerations to be governed by the following dynamics
		\begin{align}
			\left(\ddot{\mathbf{p}}_{c} - \ddot{\mathbf{p}}_{c,des} \right) =& - k_{P1,i}^{tr} \overline{\mathbf{Q}}_{\dot{c}}^{-1} \overline{\mathbf{Q}}_{c} \left(\mathbf{p}_{c} - \mathbf{p}_{c,des} \right)  - k_{D1,i}^{tr}   \left(\dot{\mathbf{p}}_{c} - \dot{\mathbf{p}}_{c,des} \right); \nonumber \\
			\ddot{\mathbf{e}}_{ij} =& -\dfrac{k_{P1,i}^{fo}k_{F}}{k_{A}q_{A_{ij}}}   \sigma_{d_{ij}}^{\prime}(s_{ij}) \mathbf{e}_{ij}   - k_{D1,i}^{al} \dot{\mathbf{e}}_{ij}   \label{eq:centroidacc}\\
			& -\dfrac{k_{D1,i}^{fo}k_{F}}{k_{A}q_{A_{ij}}} \left[2\sigma_{d_{ij}}^{\prime\prime}(s_{ij})\mathbf{\Pi}_{ij} + \chi_{>0}(\sigma_{d_{ij}}^{\prime}(s_{ij}))\sigma_{d_{ij}}^{\prime}(s_{ij}) \mathbf{I}_{M} \right] \dot{\mathbf{e}}_{ij};  \label{eq:mutualacc}
		\end{align}
		where $k_{P1,i}^{tr}$, $k_{D1,i}^{tr}$, $k_{P1,i}^{fo}$, $k_{D1,i}^{fo}$, $k_{D1,i}^{al}$ %, $k_{u,i}$ 
		are positive constants.
		It is worth to note that the last term of \eqref{eq:mutualacc} accounts for the fact that also the second order time derivative of the formation term $l^{fo1}$ affects each mutual acceleration $\ddot{\mathbf{e}}_{ij}$ between agents; thus, the same switching-based heuristics used in \eqref{eq:heuristicsPronto} is adopted even in this framework not to contrast the alignment task. %Moreover, from now on, we assume $\overline{\mathbf{Q}}_{\dot{c}}$ to be non singular and therefore $\overline{\mathbf{Q}}_{\dot{c}}^{\dagger}=\overline{\mathbf{Q}}_{\dot{c}}^{-1}$. \\%Also, we choose $k_{\dot{u}} = 1 $ exploiting relation $\mathbf{u} = \ddot{\mathbf{p}}$ and avoiding to cope with the determination of $\dot{\mathbf{u}}$, since this is not available.\\
		The regulation adopted in \eqref{eq:centroidacc} and \eqref{eq:mutualacc} allows us to state that the dynamics of input $\mathbf{u}_{i}$ is exponentially decaying to $\mathbf{0}_{M}$, as constants $k_{D1,i}^{tr}$ and $k_{D1,i}^{al}$ can be tuned large enough such that both the dynamics of $\left(\ddot{\mathbf{p}}_{c} - \ddot{\mathbf{p}}_{c,des} \right)$ and $\ddot{\mathbf{e}}_{ij}$ be exponentially and asymptotically stable. Thus, it is also possible to assume that
		\begin{equation}\label{eq:uiddot}
			\ddot{\mathbf{u}}_{i} = \mathbf{K}_{u,i} \mathbf{u}_{i}, \quad i = 1,\ldots, n
		\end{equation}
		where constants $\mathbf{K}_{u,i} = k_{u,i} \mathbf{I}_{M} \in \mathbb{R}^{M\times M}$, $k_{u,i} > 0$, are adopted. As a remark, assumptions \eqref{eq:centroidacc}, \eqref{eq:mutualacc} and \eqref{eq:uiddot} are suitable choices in order to obtain distributed a PD controller\footnote{Choices justified by the fact that in the PRONTO optimization framework a PD controller can be employed successfully.}; nonetheless, they have the drawback to add new constraints and hence make the control law derived from equations \eqref{eq:E-Leqs} suboptimal. \\
		Finally, let us define the positive tunable gains for the PD controller as $k_{P,i}^{tr} := (1+k_{P1,i}^{tr})/k_{u,i}$, $k_{D,i}^{tr} := k_{D1,i}^{tr}/k_{u,i}$, $k_{P,i}^{fo} := (1+k_{P1,i}^{fo})/k_{u,i}$, $k_{D,i}^{fo} := k_{D1,i}^{fo}/k_{u,i}$, $k_{D,i}^{al} := k_{D1,i}^{al}/k_{u,i}$. Taking into consideration the proposed online average consensus approach to estimate global quantities% and summing each member of equations \eqref{eq:E-Lp}-\eqref{eq:E-Lpdot}
		, the distributed control law in \eqref{eq:distr_ctrl_law} for the $i$-th agent can be designed exploiting \eqref{eq:centroidacc}-\eqref{eq:uiddot} starting from relation \eqref{eq:E-Lp}.
	\end{proof}
	
	\begin{rmk}
		Law \eqref{eq:distr_ctrl_law} does not guarantee the minimization of \eqref{eq:ham_act}. To prove this fact, the second order variation of \eqref{eq:ham_act} has to be analyzed and it has to be shown that this is a positive definite quadratic form for the input in \eqref{eq:distr_ctrl_law}.
	\end{rmk}
	
	In what follows, we motivate the derivation of the control law found in Thm. \ref{thm:ui}.
	
	%In the next paragraph, an analysis of the equilibria is proposed in order to show that if input law in \eqref{eq:distr_ctrl_law} converges to $\mathbf{0}_{M}$, then
\end{comment}

\begin{comment}
	\subsection{Analysis of the equilibria}
	In this paragraph, we investigate the equilibria for the centralized and distributed solutions developed so far. To do so, we account for a graph-based formalism that leverages concepts as incidence and rigidity matrices\footnote{For a detailed treatise on this, the reader is addressed to \cite{OhParkAhn2015} and \cite{ZhaoZelazo2016}}.\\ Given a graph $\mathcal{G} = \left(\mathcal{V},\mathcal{E}\right)$, where $\mathcal{V}$ is the set of vertices ($n=\left|\mathcal{V}\right|$ in total) and $\mathcal{E} \subset \mathcal{V} \times \mathcal{V} $ is the set of edges ($E=\left|\mathcal{E}\right|$ in total), we define the incidence matrix $\mathbf{E} = \mathbf{E}_{\mathcal{G}} \in \mathbb{R}^{n\times E}$ as
	\begin{equation}
		\left[\mathbf{E} \right]_{ij} = \begin{cases}
			-1,\quad \text{the $j$-th edge sinks at node $i$}; \\
			1,\quad \text{the $j$-th edge leaves node $i$}; \\
			0,\quad \text{otherwise};
		\end{cases}
	\end{equation} 
	and, consequently, the Laplacian matrix $\mathbf{L} = \mathbf{L}_{\mathcal{G}}$ associated to $\mathcal{G}$ can be defined as $\mathbf{L} = \mathbf{E}\mathbf{E}^{\top}$.
	With the same ordering for the edges of $\mathcal{E}$ given to the columns of $\mathbf{E}$, the rigidity functions $r_{\mathcal{G}} : \mathbb{R}^{N} \rightarrow \mathbb{R}^{E}$ associated to the frameworks $(\mathcal{G},\mathbf{p})$ and $(\mathcal{G},\dot{\mathbf{p}})$ are respectively given by
	\begin{align}
		r_{\mathcal{G}}(\mathbf{p}) &= \dfrac{1}{2} \begin{bmatrix}
			\ldots, \mathbf{e}_{ij}^{\top}\mathbf{e}_{ij}, \ldots
		\end{bmatrix}^{\top}, \quad (i,j) \in \mathcal{E}; \label{eq:rigfunp}\\
		r_{\mathcal{G}}(\dot{\mathbf{p}}) &= \dfrac{1}{2} \begin{bmatrix}
			\ldots, \dot{\mathbf{e}}_{ij}^{\top}\dot{\mathbf{e}}_{ij}, \ldots
		\end{bmatrix}^{\top}, \quad (i,j) \in \mathcal{E}. \label{eq:rigfunpdot}
	\end{align}
	One useful tool to characterize the rigidity property of a framework is the rigidity matrix $\rig \in \mathbb{R}^{E\times N} $, which is defined as the Jacobian of the rigidity function w.r.t. the spatial quantity (either $\mathbf{p}$ or $\dot{\mathbf{p}}$) considered in the relative framework. Let us also define $\Diag_{\mathcal{E}}$ as the operator that maps the set of displacement vectors $\mathbf{e}_{ij}^{\top}$ or $\dot{\mathbf{e}}_{ij}^{\top}$ ordered as in \eqref{eq:rigfunp}-\eqref{eq:rigfunpdot} into a diagonal matrix of dimensions $E \times N$, such that its $k$-th diagonal element of dimensions $1\times M$ is exactly given by the $k$-th displacement vector, for $k = 1\ldots E$. Then, the rigidity matrices for frameworks $(\mathcal{G},\mathbf{p})$ and $(\mathcal{G},\dot{\mathbf{p}})$ are yielded by
	\begin{align}
		\rig \left( \mathbf{p} \right) &= \dfrac{\partial r_{\mathcal{G}} (\mathbf{p})}{\partial \mathbf{p}}= \Diag_{\mathcal{E}}\left\lbrace \mathbf{e}_{ij}^{\top} \right\rbrace \left(\mathbf{E}^{\top} \otimes \mathbf{I}_{M}\right), \quad \text{for } (\mathcal{G},\mathbf{p}); \\
		\rig \left( \dot{\mathbf{p}} \right) &= \dfrac{\partial r_{\mathcal{G}} (\dot{\mathbf{p}})}{\partial \dot{\mathbf{p}}} = \Diag_{\mathcal{E}}\left\lbrace \dot{\mathbf{e}}_{ij}^{\top} \right\rbrace \left(\mathbf{E}^{\top} \otimes \mathbf{I}_{M}\right), \quad \text{for } (\mathcal{G},\dot{\mathbf{p}});
	\end{align}
	where symbol $\otimes$ indicates the Kronecker product operator\footnote{We assume that the Kronecker product has a lower priority with respect to the matrix multiplication.}.
	
	Now, with these graph-based theoretical tools, we can provide a different point of view for the expression characterizing gradients in \eqref{eq:gradfo},\eqref{eq:gradal} and Hessian matrices in \eqref{eq:hessfoin},\eqref{eq:hessfoout},\eqref{eq:hessal}, offering a perspective from the networked control of the system. Indeed, fixing an order for the edges in $\mathcal{E}$, it is worth to note that one has
	\begin{alignat}{2}
		&\nabla_{\mathbf{p}} l^{fo1} &&= k_{F} \rig(\mathbf{p})^{\top} \sigma_{d}^{\prime}(\textbf{s}); \label{eq:gradlfomatr}\\
		&\mathcal{H}_{\mathbf{p}\mathbf{p}} l^{fo1} &&= k_{F} \left[\rig(\mathbf{p})^{\top} \Diag (2 \sigma_{d}^{\prime\prime}(\mathbf{s})) \rig(\mathbf{p}) +  \mathbf{E} \Diag(\sigma_{d}^{\prime}(\mathbf{s})) \mathbf{E}^{\top} \otimes \mathbf{I}_{M} \right];  \label{eq:hesslfomatr} \\
		&\nabla_{\dot{\mathbf{p}}} l &&= k_{A} \rig(\dot{\mathbf{p}})^{\top} \mathbf{q}_{A}; \label{eq:gradlalmatr}\\
		&\mathcal{H}_{\dot{\mathbf{p}}\dot{\mathbf{p}}} l^{fo2} &&= k_{A} \mathbf{E} \Diag(\mathbf{q}_{A}) \mathbf{E}^{\top} \otimes \mathbf{I}_{M}; \label{eq:hesslalmatr}
	\end{alignat}
	where vector $\mathbf{s}\in \mathbb{R}^{E}$ contains all the terms $s_{ij}$ in the order adopted for the edges whenever $(i,j)\in \mathcal{E}$, function $\sigma_{d}$ and its derivatives are applied component-wise to $\mathbf{s}$, vector $\mathbf{q}_{A}\in \mathbb{R}^{E}$ contains all the terms $\mathbf{q}_{A_{ij}}$ in the order adopted for the edges whenever $(i,j)\in \mathcal{E}$ and $\Diag(\cdot)$ is the operator that maps a vector argument into its correspondent diagonal matrix. 
	
	The equilibria relative to the formation task are given by gradient in \eqref{eq:gradlfomatr}; in particular, three conditions can be distinguished:
	\begin{enumerate}[(i)]
		\item $\sigma_{d}^{\prime}(\mathbf{s}) = \mathbf{0}_{E}$, i.e. $s_{ij} = d_{ij}^{2}$ for all $(i,j)\in \mathcal{E}$; \label{equil1}
		\item $ \sigma_{d}^{\prime}(\mathbf{s}) \in \ker \left\lbrace \Diag_{\mathcal{E}}\left\lbrace \mathbf{e}_{ij} \right\rbrace\right\rbrace$; \label{equil2}
		\item $\Diag_{\mathcal{E}}\left\lbrace \mathbf{e}_{ij} \right\rbrace \sigma_{d}^{\prime}(\mathbf{s}) \in \ker \left\lbrace \mathbf{E} \otimes \label{equil3} \mathbf{I}_{M}\right\rbrace  $;
	\end{enumerate}
	where $\ker$ denotes the kernel of a matrix and $\Diag_{\mathcal{E}}\left\lbrace \mathbf{e}_{ij} \right\rbrace = \Diag_{\mathcal{E}}\left\lbrace \mathbf{e}_{ij}^{\top} \right\rbrace^{\top}$. The first condition is exactly what the system should satisfy to accomplish the desired formation and represents a stable equilibrium, since this would make the corresponding instantaneous cost $l^{fo1}$ vanishing\footnote{Provided that the required geometric shape be feasible.}, being part of a minimum energy configuration. The second condition arises whenever a undesired consensus takes place, e.g. a rendezvous, a collinear positioning or the achievement of an equivalent formation due to the lack of global rigidity. Finally, the third condition means that $\Diag_{\mathcal{E}}\left\lbrace \mathbf{e}_{ij} \right\rbrace \sigma_{d}^{\prime}(\mathbf{s})$ is a signed path vector \cite{MesbahiEgerstedt2010} associated to one of the cycles in $\mathcal{G}$. It is plausible that all the equilibria described by conditions \eqref{equil2} and \eqref{equil3} are unstable in case of global rigidity guarantees, due to the fact that $\sigma_{d}^{\prime}(s_{ij})$ is monotonic and $\sigma_{d}^{\prime}(s_{ij}) = 0$ holds only for $s_{ij} = d_{ij}^{2}$.\\
	Differently, the equilibria relative to the alignment task are given by gradient in \eqref{eq:gradlalmatr}. Here, two conditions can be distinguished:
	\begin{enumerate}[(i)]
		\item $ \mathbf{q}_{A} \in \ker \left\lbrace \Diag_{\mathcal{E}}\left\lbrace \dot{\mathbf{e}}_{ij} \right\rbrace\right\rbrace$, i.e. $\dot{\mathbf{e}}_{ij} = \mathbf{0}_{M}$ for all $(i,j) \in \mathcal{E}$;
		\item $\Diag_{\mathcal{E}}\left\lbrace \dot{\mathbf{e}}_{ij} \right\rbrace \mathbf{q}_{A} \in \ker \left\lbrace \mathbf{E} \otimes \mathbf{I}_{M} \right\rbrace  $;
	\end{enumerate}
	The first condition leads to the fulfillment of the alignment, since it is verified if and only if the $ \ker \left\lbrace \Diag_{\mathcal{E}}\left\lbrace \dot{\mathbf{e}}_{ij} \right\rbrace \right\rbrace$ reaches its maximum dimension. Whereas, the second condition is not only satisfied under the latter assumption, but even when $\Diag_{\mathcal{E}}\left\lbrace \dot{\mathbf{e}}_{ij} \right\rbrace \mathbf{q}_{A}$ is a signed path vector relative to one of the cycles in $\mathcal{G}$. Then, an alignment equilibrium is stable only if the first condition is verified, since this would make the relative instantaneous cost $l^{fo2}$ vanishing, being part of a minimum energy configuration for the system too.
	
	The tracking task also exhibits equilibria for $\mathbf{C}^{\top} \mathbf{Q}_{c,\dot{c}} \left(\mathbf{x}_{c}-\mathbf{x}_{c,des}\right) = \mathbf{0}_{2M}$, condition that can be easily separated into
	\begin{equation}\label{eq:trackeq}
		\begin{cases}
			\left(\mathbf{p}_{c}-\mathbf{p}_{c,des}\right) \in \ker \left\lbrace \overline{\mathbf{Q}}_{c} \right\rbrace; \\
			\left(\dot{\mathbf{p}}_{c}-\dot{\mathbf{p}}_{c,des}\right) \in \ker \left\lbrace \overline{\mathbf{Q}}_{\dot{c}}\right\rbrace;
		\end{cases}
	\end{equation}
	and, trivially, \eqref{eq:trackeq} describes stable equilibria, since the corresponding tracking cost $l^{tr}$, which is a quadratic form weighted by positive semidefinite matrices $\overline{\mathbf{Q}}_{c}$ and $\overline{\mathbf{Q}}_{\dot{c}}$, vanishes when these conditions hold. In particular, one observes that equalities $\mathbf{p}_{c}=\mathbf{p}_{c,des}$ and $\dot{\mathbf{p}}_{c}=\dot{\mathbf{p}}_{c,des}$ must hold at the equilibrium, if these average weights are chosen to be positive definite. 
	
	%\MFa{What about writing what follows as a proposition?}\\
	Let us denote $\mathds{1}_{\natural}\in \mathbb{R}^{\natural}$ as the vector in which all its $\natural$ components are equal to $1$. In order to inspect the equilibria of the system governed by the distributed control law devised previously, we provide its matrix representation:
	\begin{align}
		\mathbf{u} = &  -\mathbf{R}^{-1}   \left(\Diag_{\mathcal{V}}\left\lbrace k_{P,i}^{tr} \right\rbrace  \otimes\mathbf{I}_{M}\right) \left(\mathds{1}_{n} \otimes \overline{\mathbf{Q}}_{c} (\mathbf{p}_{c}-\mathbf{p}_{c,des}) \right)  + \nonumber\\
		& -\mathbf{R}^{-1} \left(\Diag_{\mathcal{V}}\left\lbrace k_{D,i}^{tr} \right\rbrace  \otimes\mathbf{I}_{M}\right) \left(\mathds{1}_{n} \otimes \overline{\mathbf{Q}}_{\dot{c}} (\dot{\mathbf{p}}_{c}-\dot{\mathbf{p}}_{c,des}) \right)  + \nonumber\\
		& -\mathbf{R}^{-1}\left[ \left(\Diag_{\mathcal{V}}\left\lbrace k_{P,i}^{fo}  \right\rbrace  \otimes\mathbf{I}_{M}\right) \nabla_{\mathbf{p}} l^{fo1} +  \left(\Diag_{\mathcal{V}}\left\lbrace k_{P,i}^{al}  \right\rbrace  \otimes\mathbf{I}_{M}\right) \nabla_{\dot{\mathbf{p}}} l^{fo2} \right]  +   \nonumber \\
		& -\mathbf{R}^{-1} \left(\Diag_{\mathcal{V}}\left\lbrace k_{D,i}^{fo}  \right\rbrace  \otimes\mathbf{I}_{M}\right)  (\mathbf{E} \otimes \mathbf{I}_{M})  \Diag_{\mathcal{E}}\left\lbrace \mathcal{H}^{safe}_{\mathbf{p}_{i}\mathbf{p}_{j}} \dot{\mathbf{e}}_{ij}  \right\rbrace \mathds{1}_{E} \label{eq:udistrmatr}
	\end{align}
	where $\Diag_{\mathcal{V}}$ is the operator that maps its arguments indexed by $i = 1, \ldots, n$ into a diagonal matrix of dimensions $n \times n$, such that the $i$-th diagonal element coincides with the $i$-th argument, and the expressions of gradients $\nabla_{\mathbf{p}}l^{fo1}$, $\nabla_{\dot{\mathbf{p}}} l^{fo2}$ are provided in \eqref{eq:gradlfomatr} and \eqref{eq:gradlalmatr} respectively. It is worth to notice that the last term of \eqref{eq:udistrmatr} has a similar structure of a rigidity matrix in which the mutual velocities $\dot{\mathbf{e}}_{ij}$ are weighted by the safe version of the Hessian $\mathcal{H}_{\mathbf{p}\mathbf{p}}$. This allows to take into account a second order curvature effect to better fulfill both the formation and alignment tasks. Moreover, it is remarkable to observe that the equilibrium relations discussed so far represent a sufficient condition to obtain $\mathbf{u} = \mathbf{0}_{N}$ and thus the control aims at minimizing the global energy spent by the system of agents. Lastly, it is worth to mention that control laws similar to \eqref{eq:udistrmatr}, leading a group of agents to be seen as dissipative second order Hamiltonian system, ensure local stability for the formations to be attained in an infinite time horizon \cite{OhAhn2014,MesbahiEgerstedt2010}. Moreover, closely related control laws working with finite-time specifications for second-order multi-agent systems have been already developed in \cite{SunMouDeghat2014, FuWangWang2019}, supporting the robustness of the approach devised in this paper.\\
	To sum up, Thm. \ref{thm:ui} allows to devise the online control in \eqref{eq:udistrmatr} without providing enough information about the stability properties concerning the formation aspect. Nonetheless, this derivation follows the principle of passivity while designing a coordination law for the group of agent in question \cite{Arcak2007}. Therefore, we conclude generic convergence to the desired formation from all initial conditions except for those that lie on the stable manifolds of the unstable equilibria. This issue can be partially avoided assuming global rigidity (or, at least, infinitesimal rigidity, if equivalent -- but not congruent -- frameworks are accepted for the system of agents).
	
	
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{comment}









\section{Numerical results} \label{sec:numerical_simulations}
In this section, we focus on a singular case study where desired distances $d_{ij}$ are imposed such that the formation assumes a cubic shape in a space of dimension $M=3$. Precisely, the desired cube has side equal to $d = 5~\si{\meter}$ and each of the $n=8$ agents have a neighborhood with degree $|\mathcal{N}_{i}| = 5$, $i=1,\ldots, n$. The following adjacency matrix summarizes the distance constraints to be satisfied (the symbol $*$ is used to indicate the absence of a link):
\begin{equation*}
		\begin{bmatrix}
			0 & d & * & d & d & \sqrt{2}d & * & \sqrt{2}d \\
			d & 0 & d & \sqrt{2}d & * & d & * & \sqrt{3}d \\
			* & d & 0 & d & \sqrt{3}d & \sqrt{2}d & d & * \\
			d & \sqrt{2}d & d & 0 & * & * & \sqrt{2}d & d \\
			d & * & \sqrt{3}d & * & 0 & d & \sqrt{2}d & d \\
			\sqrt{2}d & d & \sqrt{2}d & * & d & 0 & d & * \\
			* & * & d & \sqrt{2}d & \sqrt{2}d & d & 0 & d \\
			\sqrt{2}d & \sqrt{3}d & * & d & d & * & d & 0
		\end{bmatrix}
\end{equation*}
This setup allows us to present an example where the formation to be achieved is infinitesimally rigid \cite{jordan2016ii}. 
Thus, the convergence for the whole system towards a unique stable equilibrium is ensured by such topology and geometry. Also, the group of agents have to track %the straight line $\boldsymbol{\Gamma}(t) = \mathrm{v}t$ with a constant desired velocity $\mathrm{v}_k = 1 ~\si{\meter\second^{-1}}$ for each component $k = 1,2,3$. 
the curve $\Gamma(t) = \mathcal{R}_{z}(\frac{\pi}{4})\mathcal{R}_{y}(-\frac{\pi}{4})\Gamma_{0}(t)$, where $\mathcal{R}_{z}$, $\mathcal{R}_{y}$ denote the three-dimensional rotation matrices about the $y$ and $z$ axes, respectively, and
\begin{equation}
	\Gamma_{0}(t) :\quad \begin{cases}
		x(t) = 2 t\\
		y(t) = 10 \tanh(10(t-T/2)) \\
		z(t) = 0
	\end{cases}, \quad t \in [0,T]. 
\end{equation}
The tracking velocity is set to be equal to $\dot{\Gamma}(t)$.
The initial state $\xx_{0} = \vc{\pp_{0},\dot{\pp}_{0}}$ of the system is randomly assigned as follows:
\begin{align*}
	\mathbf{p}_{0} &= \vc{\begin{bmatrix}
			-6 & -9 & 6 & 15 & -3 & 6 & -3 & 15 \\
			3 & -3 & -6 & 3 & -18 & 6 & -15 & 6 \\
			24 & 3 & 15 & 15 & 6 & 6 & -3 & 9
	\end{bmatrix}} 
	\si{\meter};\\
	\dot{\mathbf{p}}_{0} &= \vc{\begin{bmatrix}
			10 & 10  & 0 & 15 & 0 & 5 & 0 & -10 \\
			1 & 0 & 0 & -5 & 0 & 5 & 0 & -25 \\
			0 & 0 & 0 & 5 & 5 & 5 & 0 & 10
	\end{bmatrix}} \si{\meter\second^{-1}}.
\end{align*}

We select the input weighting matrix in \eqref{eq:inst_energy} as $\mathbf{R} = \mathbf{I}_{N}~\si{\meter^{-2} \second^{4}}$. The integration time $T=20 ~\si{\second}$ is kept fixed for all simulations, as well as the structure of the output weighting matrices $\mathbf{Q}_{i}= \mathrm{Diag}(q_{p} \mathbf{I}_{M}, q_{d}\mathbf{I}_{M})$, $i = 1,\ldots, n$,
%		\begin{equation*}
	%			\mathbf{Q}_{i}=\begin{bmatrix}
		%				q_{p} \mathbf{I}_{M} & \Zz_{M} \\
		%				\Zz_{M} & q_{d}\mathbf{I}_{M}
		%			\end{bmatrix}, \quad i = 1,\ldots, n,
	%		\end{equation*} 
for \eqref{eq:track_inst_cost}, where $q_{p} = 1.25~\si{\meter}^{-2}$, $q_{d} = 0.125~\si{\meter}^{-2}\si{\second}^{2}$ are chosen.
Moreover, we set, for all edges $(i,j)\in\mathcal{E}$, the following parameters: $k_{r_{ij}} = 250$, $k_{a_{ij}} = 100$, $\beta_{ij}=3$, $\alpha_{ij}=0.5$, in \eqref{eq:potential}, $k_{F} = 2$, in \eqref{eq:form_inst_cost} and $k_{A} = 0.25$, $\Thth_{ij} = \Ii_{M}~\si{\meter}^{-2}\si{\second}^{2}$, in \eqref{eq:align_inst_cost}. In each numerical simulation presented, we have decided to stop the execution of PRONTO %Alg. \ref{alg:PRONTO} 
by taking two actions: either the algorithm stops when the iteration $k$ exceeds the preset number of iterations $MaxIter = 80$
%\in \mathbb{N} 
or the search direction becomes sufficiently flat. %given a threshold $\varepsilon_{g} > 0$, when the inequality $-Dg\left(\boldsymbol{\xi}_{t}\right) \cdot \boldsymbol{\zeta}_{t} < \varepsilon_{g}$ is verified (i.e. the search direction becomes sufficiently flat). 
%In particular, we set $MaxIter = 80$ and $\varepsilon_{g} = 10^{-8}$.

Constant gains for the PD controller in \eqref{eq:PDcontroller} are selected leveraging the second-order linear dynamics of \eqref{eq:dyn_sys}, as
\begin{equation*}
	\begin{cases}
		\omega_{n} = 3 ~\si{\radian\per\second}\\
		\xi = 0.7 
	\end{cases} \Rightarrow ~ \begin{cases}
		k_{p} = \omega_{n}^{2} \\
		k_{d} = 2\xi\omega_{n}
	\end{cases}.
\end{equation*}
Whereas, for the online distributed feedback controller in \eqref{eq:distrOIFTsol} gains $k_{p}^{tr1} = 2.4~\si{\second}^{2}$, %0.8 
$k_{p}^{fo1} = 1.3~\si{\second}^{2}$, $k_{d}^{tr1} = 1.2~\si{\second}^{3}$, %0.56
$k_{d}^{fo1} = 1~\si{\second}^{3}$, $k_{p}^{tr2} = 12~\si{\second}$, %5.6 
$k_{p}^{fo2} = 0.3~\si{\second}$ have been tuned by matching the distributed solution with the centralized one provided by PRONTO. Estimator gains in \eqref{eq:estimator2} are set as $k_{py}=180~\si{s}^{-1}$, $k_{dy}=170~\si{s}^{-1}$, such that, omitting the physical dimensionality, condition $k_{py}>k_{dy} >> k_{p}^{tr1},k_{p}^{fo1},k_{d}^{tr1},k_{d}^{fo1},k_{p}^{tr2},k_{p}^{fo2}$ is satisfied to guarantee fast enough estimation dynamics, yet avoiding noisy estimation behaviors. Finally, as suggested in \eqref{eq:saturation_heuristics}, a saturation $|\widehat{u}_{j}| \leq 50 ~\si{\meter}\si{\second}^{-2}$ has been selected for each control component $\widehat{u}_{j}$ of input $\widehat{\uu}$.





\subsection{Performance of the devised distributed controller}
With the purpose of validating the online distributed feedback controller in \eqref{eq:distrOIFTsol}, we compare the two dynamics obtained by the latter control law and the offline inverse dynamics provided by PRONTO. As an evaluation criterion, we decide to look at the global energy spent by the input and the settling time of the system dynamics. Specifically, we account for the global input energy $l^{in}(\cdot)$ and the average input energy $\bar{l}^{in}(\cdot)$. This quantity is defined as the weighted mean $\bar{l}^{in}(\cdot) = l^{in}(\cdot)/\left\|\mathbf{R}\right\|_{F}$, where $\left\|\mathbf{R}\right\|^{2}_{F} = \sum_{i=1}^{n} \sum_{j=1}^{n} [\mathbf{R}]_{ij}^{2}$ has to be considered the dimensionless version of the Frobenius norm of $\mathbf{R}$.
Furthermore, let us introduce function $l^{tf}:\mathbb{R} \rightarrow [-1,1]$, defined %\footnote{This definition must be revisited when constraints \eqref{eq:dist_constraints} describe a unfeasible shape.} 
as
\begin{equation}\label{eq:lst}
	l^{tf}(t) = \begin{cases}
		\dfrac{l^{fo}(t)-l^{tr}(t)}{l^{fo}(t)+l^{tr}(t)},  \quad &\text{if } l^{fo}(t)+l^{tr}(t) > 0;\\
		0, \quad &\text{otherwise}.
	\end{cases}
\end{equation}





Selecting $\delta\in[0,1]$, the settling time instant $t_{\delta} \in [0,T]$ for the system is established whenever condition $|l^{tf}(t)| \leq \delta$ holds for all $t \geq t_{\delta}$. 
It is worth to note that function in \eqref{eq:lst} measures a weighted trade-off between centroid-based and relative-based control performances, as it is expected to go to $0$ and remain null over time if a control action is being applied.
In Fig. \ref{fig:performancesPRONTOdistr} the performances of these numerical simulations are illustrated, presenting the inverse dynamics obtained by PRONTO on the left column and the online dynamics governed by the distributed feedback controller on the right column. In Figs. \ref{fig:perftrajPRONTO} and \ref{fig:perftrajdistr}, one can observe the positional trajectories described by the system in a three-dimensional space, noting that each agent contributes eventually to achieve a proper position as a vertex of the desired cubic shape. Moreover, the system's centroid tracks the required curve %straight line
$\boldsymbol{\Gamma}(\cdot)$. 
% trim=left bottom right top, clip
% Figure environment removed
The most evident difference between the two approaches arises by comparing how the trajectories perform in the chicane at the middle of the desired path. PRONTO provides a solution based on future knowledge; hence, the chicane tracking is planned ahead and is carried out in a symmetric way w.r.t. $t=T/2=10 ~\si{\second}$. Conversely, the control law devised in \eqref{eq:distrOIFTsol} exhibits a causal behavior, stabilizing only after the transient of $\Gamma(t)$ has occurred.
It is also worth to note that the trajectories of the system governed by the distributed control law are less smooth w.r.t. those of PRONTO. This indicates that more effort is needed to steer the agents using the distributed controller \eqref{eq:distrOIFTsol}, especially when the ``$safe$'' heuristic for term $\dot{\nabla}_{\pp} l^{fo1}$ comes into play. Indeed, Fig. \ref{fig:perfenerdistr} depicts a higher energy consumption levels over time w.r.t. to that in Fig. \ref{fig:perfenerPRONTO}, despite the saturation. % (which is, in fact, not active after $t = 0.35635 \si{s}$). %It can be observed that the input energy spent with the distributed approach is approximately $n=8$ times greater than that spent in the PRONTO framework: this fact might suggest that the suboptimality degree of controller \eqref{eq:distr_ctrl_law} could be quantified by the number of driven agents, provided that the performances related to time appear fairly similar.
Figs. \ref{fig:perfsettlPRONTO} and \ref{fig:perfsettldistr} again highlight the fact that, with PRONTO, the tracking effort (blue area) spent in the chicane is better ``allocated'' over time and it kicks in before $t=T/2$. Whereas, for the distributed online controller, the tracking effort is maximum at $t=T/2$, and before that instant the formation task is mainly addressed. These plots also show that each settling time instant can be compared among the two approaches with a maximum deviation of about $2~\si{\second}$. %1 
Remarkably, in this case, the distributed controller reaches the $1\%$ %0.1 
settling threshold at $t \simeq 15 < T$, %16 
even before the trajectory planned by PRONTO does at $t = 16 < T$. %17 
The explanation of this fact lays on the slightly greater energy spent by the distributed controller. However, the distributed control does not settle at $0.1\%$ because the estimation of a local frame introduces some inaccuracy\footnote{Settling at $0.1\%$ would talk place if exact information on the centroid was available.}. 



To summarize, the latter observation tells us that law in \eqref{eq:distrOIFTsol} works as a finite-time practically optimal controller, according to the choice of function $l^{tf}$ as a reference for the settling time measurements.
As a final remark, three important evidences can be highlighted for the law in \eqref{eq:distrOIFTsol}:
\begin{itemize}[]
	\item it allows to govern the state dynamics of the system similarly to what PRONTO algorithm produces as optimal inverse dynamics;
	\item it is practically optimal, since it requires the system to spend slightly more input energy to achieve similar time performances w.r.t. the optimal inverse dynamics;
	\item for infinitesimally (\rev{resp.} globally) rigid geometrical shapes the \rev{local (resp. global)} convergence is attained in a finite time, provided that gains of the distributed PD controller are properly tuned.
\end{itemize}


\subsection{Convergence behavior of the devised distributed controller}
It is immediate to note that two control actions -- relative distance and centroid regulations -- can be analyzed separately in law \eqref{eq:distrOIFTsol}. Indeed, it can be pointed out that the relative distance regulation acts by exploiting the potentials in \eqref{eq:potential}, as distance-based error functions and the second-order formation term \eqref{eq:align_inst_cost}. Such an approach can be seen as a generalized consensus protocol \cite{MesbahiEgerstedt2010} for the dynamics under investigation.

Fig. \eqref{fig:consensusPRONTOdistr} depicts an overview on the whole dynamics of the system governed by the online distributed feedback controller. Firstly, Figs. \eqref{fig:cons0sigma}, \eqref{fig:cons1sigma} and \eqref{fig:cons2sigma} exhibit the convergence to zero of the distance errors %(illustrated in Fig. \ref{fig:sigma}) 
as $t \rightarrow T = 20~\si{\second}$. This shows the achievement of the formation positioning, i.e. the first-order cohesion/separation task. Secondly, in Fig. \ref{fig:reldistconsensus}, the relative velocities responsible for the second-order cohesion/separation tasks converge to zero. Moreover, Figs. \ref{fig:trackpc} and \ref{fig:trackpdotc} depict the response of positions and velocities of the centroid, showing that the tracking, namely the velocity alignment task, is fulfilled as required.
%\newpage
% trim=left bottom right top, clip
% Figure environment removed
%\clearpage
In each of these diagrams, it is worth to observe that the $1\%$ settling time instant computed through function $l^{tf}$ gives significant information about the convergence of the global state $\xx$ towards all the specifications. Indeed, by the rigidity properties of the desired formation, 
%this allow us to state that 
the entire dynamics controlled by law in \eqref{eq:distrOIFTsol} approximately attains a stable equilibrium after $13~\si{\second}$, for $t > t_{1\%}$, right after the effect of the chicane vanishes.
%$T/2= 10~\si{\second}$






	
\begin{comment}
	
	
	\subsection{Centralized vs distributed solutions}
	In order to evaluate how far the distributed solution is from the optimum, a comparison with the centralized inverse dynamics computed via PRONTO is proposed. In particular, it is tested the degree of accuracy for approximation in \eqref{eq:lamdynest} to verify whether the practical co-state optimality condition holds indirectly. It is clear that, since $\widehat{\lamlam}_{i+n}$, for $i = 1,\ldots,n$, are estimated in function of $\widehat{\lamlam}_{i}$, the validation for \eqref{eq:lamdynest} is not possible because of lack of identifiability. Nonetheless, excluding multipliers $\widehat{\lamlam}_{i}$, for $i = 1,\ldots,n$, the remainder multipliers can be compared with the optimal ones. To do so, relation \eqref{eq:PMPinput} can be exploited. In addition, since $\Rr$ is chosen as the identity matrix in this setup (w.l.o.g.), the input estimation error $RMSE_{u}(t)=\left\|\uu^{\star}-\bar{\uu}\right\|_{2}$ is completely equivalent (up to the magnitude of $\Rr$, in general) to the second-order-multipliers error $\left\|\lamlam^{\star}_{\varsigma}-\bar{\lamlam}_{\varsigma}\right\|_{2}$, where $\uu^{\star}$, $\bar{\uu}$ are the inputs obtained via PRONTO and distributed control law with saturation, respectively, and $\lamlam^{\star}_{\varsigma} = \vci{\lamlam^{\star}_{i+n}}{n}$, $\bar{\lamlam}_{\varsigma} = \vci{\bar{\lamlam}_{i+n}}{n}$  are their corresponding second-order multipliers. Such a comparison is illustrated in Fig. \ref{fig:centrvsdistrinput}. It is worth to observe that, although the average $RMSE_{u}(t)$ over the time (dash black line) is not negligible, the value of $RMSE_{u}(t)$ decreases, on average (in a linear least-squares sense), as $\varepsilon_{u}(t) \simeq 24.813 \eto{-0.48454t}$. Also, $RMSE_{u}(t)$ can be bounded as $\varepsilon_{u}^{-}(t)\leq RMSE_{u}(t) \leq \varepsilon_{u}^{+}(t)$, by the decreasing functions $\varepsilon_{u}^{-}(t) \simeq 8.947\eto{-0.48454t} $ and $\varepsilon_{u}^{+}(t) \simeq 225.23\eto{-0.48454t}$. This fact indirectly shows that the approximation in \eqref{eq:lamdynest} becomes more and more accurate as $t\rightarrow T$, since its error has exponential decay. However, $RMSE_{u}(t)$ actually approaches a strictly positive constant, as $t \rightarrow T$, for any $T$ arbitrarily large, rather than $0$ because of the centroid estimation error arising with the use of estimator in Lem. \ref{lem:secordest}. Indeed, as depicted in Fig. \ref{fig:estimationerrors}, the overall estimation error related to the centroid position stabilizes around a constant value (see magenta line). This issue is due to the fact that the centroid position is estimated via centroid velocity estimates, which carry uncertainty, as velocity measurements are not available in this setting. On the other hand, the overall estimation error related to the centroid velocity satisfies \eqref{eq:centrerrest}, as expected.
	
	%\clearpage
	% Figure environment removed
	% Figure environment removed
	
\end{comment}

%\newpage
\section{Conclusions and future directions} \label{sec:conclusions}
Considering a second-order integrator MAS, we have introduced an extended version of the OIFT problem whose minimum-energy solution can be obtained by the numerical tool PRONTO (offline) and a distributed feedback control law (online). In order to fulfill the required final configurations for the formation to be driven, generic and versatile potential functions have been proposed. %In particular, t
The reported simulations show the validity of the online distributed feedback control devised w.r.t. the trajectory and the energy profiles yielded by PRONTO, where the latter has been accounted as a reference for the former. %A short yet detailed analysis of the equilibria has also been provided in order to give an overview on the working principles of developed input law. 
Also, the flexibility of the decentralized paradigm is tested under the presence of communication constraints on the information sharing.
%Furthermore, the flexibility of the developed decentralized paradigm is also validated, since general communication constraints on the information sharing among agents have been adopted. % during the whole dissertation. 

% \MFa{ATTENZIONE: da rivedere qui sotto perch ci sono gi lavori simili in letteratura!}
% Possible future directions for this work are represented by the extension to scenarios where directed graphs model the information exchanged by the agents. % in the network, as well as when a nonlinear dynamics for the system is involved. 
% The investigation of an optimal time-varying formation tracking problem \MFa{through PRONTO} also provides a new challenging follow-up for this study.

Several unresolved challenges remain that may be addressed in future research endeavors. As previously mentioned, further investigation will be dedicated to addressing the collision and obstacle avoidance issues, already explored in prior studies such as \cite{yang2019tracking, lee2017almost, zheng2023time, Huang2023Collision}. Another prospective avenue for this work involves extending its scope to scenarios where directed graphs model the information exchanged among agents, as demonstrated in \cite{mei2020robust, Babaz2022Directed}. Additionally, the exploration of the optimal time-varying formation tracking problem, as investigated in \cite{yu2022adaptive, zheng2023time}, poses an intriguing and challenging follow-up for the use of PRONTO.


%\Giulio{There are still open challenges that will be solved in possible future works. As mentioned before, collision and obstacle avoidance problem as already explored in \cite{lee2017almost, yang2019tracking, zheng2023time, Huang2023Collision} will receive further investigation. Other possible direction of this work are represented by the extension to the scenarios where directed graphs model the information exchanged by the agents as in \cite{mei2020robust,Babaz2022Directed}. The optimal time-varying formation tracking problem \cite{zheng2023time, yu2022adaptive} investigated through PRONTO also provides a new challenging follow-up for this study.}



\section*{Acknowledgments}
This work has been partly supported by the Grant ``Design Of Cooperative Energy-aware Aerial plaTforms for remote and contact-aware operations'' (DOCEAT) funded by the Italian MUR, n. 2020RTWES4, CUP n. E63C22000410001.















\bibliography{biblio_EJC}
%\input{mainEJC_v2.bbl}

\end{document}