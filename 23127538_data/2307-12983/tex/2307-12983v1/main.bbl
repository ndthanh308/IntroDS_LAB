\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam(2018)]{SpinningUp2018}
Achiam, J.
\newblock {Spinning Up in Deep Reinforcement Learning}.
\newblock 2018.

\bibitem[Allshire et~al.(2021)Allshire, Mittal, Lodaya, Makoviychuk,
  Makoviichuk, Widmaier, W{\"u}thrich, Bauer, Handa, and
  Garg]{allshire2021transferring}
Allshire, A., Mittal, M., Lodaya, V., Makoviychuk, V., Makoviichuk, D.,
  Widmaier, F., W{\"u}thrich, M., Bauer, S., Handa, A., and Garg, A.
\newblock Transferring dexterous manipulation from gpu simulation to a remote
  real-world trifinger.
\newblock \emph{arXiv preprint arXiv:2108.09779}, 2021.

\bibitem[Babaeizadeh et~al.(2016)Babaeizadeh, Frosio, Tyree, Clemons, and
  Kautz]{babaeizadeh2016reinforcement}
Babaeizadeh, M., Frosio, I., Tyree, S., Clemons, J., and Kautz, J.
\newblock Reinforcement learning through asynchronous advantage actor-critic on
  a gpu.
\newblock \emph{arXiv preprint arXiv:1611.06256}, 2016.

\bibitem[Bellemare et~al.(2017)Bellemare, Dabney, and
  Munos]{bellemare2017distributional}
Bellemare, M.~G., Dabney, W., and Munos, R.
\newblock A distributional perspective on reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  449--458. PMLR, 2017.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pp.\
  1597--1607. PMLR, 2020.

\bibitem[Chen et~al.(2022{\natexlab{a}})Chen, Tippur, Wu, Kumar, Adelson, and
  Agrawal]{chen2022visual}
Chen, T., Tippur, M., Wu, S., Kumar, V., Adelson, E., and Agrawal, P.
\newblock Visual dexterity: In-hand dexterous manipulation from depth.
\newblock \emph{arXiv preprint arXiv:2211.11744}, 2022{\natexlab{a}}.

\bibitem[Chen et~al.(2022{\natexlab{b}})Chen, Xu, and Agrawal]{chen2022system}
Chen, T., Xu, J., and Agrawal, P.
\newblock A system for general in-hand object re-orientation.
\newblock In \emph{Conference on Robot Learning}, pp.\  297--307. PMLR,
  2022{\natexlab{b}}.

\bibitem[Clemente et~al.(2017)Clemente, Castej{\'o}n, and
  Chandra]{clemente2017efficient}
Clemente, A.~V., Castej{\'o}n, H.~N., and Chandra, A.
\newblock Efficient parallel methods for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1705.04862}, 2017.

\bibitem[Coumans \& Bai(2016)Coumans and Bai]{coumans2016pybullet}
Coumans, E. and Bai, Y.
\newblock Pybullet, a python module for physics simulation for games, robotics
  and machine learning.
\newblock 2016.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, et~al.]{espeholt2018impala}
Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron,
  Y., Firoiu, V., Harley, T., Dunning, I., et~al.
\newblock Impala: Scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock In \emph{International conference on machine learning}, pp.\
  1407--1416. PMLR, 2018.

\bibitem[Espeholt et~al.(2019)Espeholt, Marinier, Stanczyk, Wang, and
  Michalski]{espeholt2019seed}
Espeholt, L., Marinier, R., Stanczyk, P., Wang, K., and Michalski, M.
\newblock Seed rl: Scalable and efficient deep-rl with accelerated central
  inference.
\newblock \emph{arXiv preprint arXiv:1910.06591}, 2019.

\bibitem[Fujimoto et~al.(2018)Fujimoto, Hoof, and
  Meger]{fujimoto2018addressing}
Fujimoto, S., Hoof, H., and Meger, D.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{International conference on machine learning}, pp.\
  1587--1596. PMLR, 2018.

\bibitem[Fujita et~al.(2021)Fujita, Nagarajan, Kataoka, and
  Ishikawa]{JMLR:v22:20-376}
Fujita, Y., Nagarajan, P., Kataoka, T., and Ishikawa, T.
\newblock Chainerrl: A deep reinforcement learning library.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (77):\penalty0 1--14, 2021.
\newblock URL \url{http://jmlr.org/papers/v22/20-376.html}.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar,
  et~al.]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.,
  Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M.,
  et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 21271--21284, 2020.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{International conference on machine learning}, pp.\
  1861--1870. PMLR, 2018.

\bibitem[Hasselt(2010)]{hasselt2010double}
Hasselt, H.
\newblock Double q-learning.
\newblock \emph{Advances in neural information processing systems}, 23, 2010.

\bibitem[Heess et~al.(2017)Heess, TB, Sriram, Lemmon, Merel, Wayne, Tassa,
  Erez, Wang, Eslami, et~al.]{heess2017emergence}
Heess, N., TB, D., Sriram, S., Lemmon, J., Merel, J., Wayne, G., Tassa, Y.,
  Erez, T., Wang, Z., Eslami, S., et~al.
\newblock Emergence of locomotion behaviours in rich environments.
\newblock \emph{arXiv preprint arXiv:1707.02286}, 2017.

\bibitem[Horgan et~al.(2018)Horgan, Quan, Budden, Barth-Maron, Hessel,
  Van~Hasselt, and Silver]{horgan2018distributed}
Horgan, D., Quan, J., Budden, D., Barth-Maron, G., Hessel, M., Van~Hasselt, H.,
  and Silver, D.
\newblock Distributed prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1803.00933}, 2018.

\bibitem[Hwangbo et~al.(2019)Hwangbo, Lee, Dosovitskiy, Bellicoso, Tsounis,
  Koltun, and Hutter]{hwangbo2019learning}
Hwangbo, J., Lee, J., Dosovitskiy, A., Bellicoso, D., Tsounis, V., Koltun, V.,
  and Hutter, M.
\newblock Learning agile and dynamic motor skills for legged robots.
\newblock \emph{Science Robotics}, 4\penalty0 (26):\penalty0 eaau5872, 2019.

\bibitem[Kapturowski et~al.(2018)Kapturowski, Ostrovski, Quan, Munos, and
  Dabney]{kapturowski2018recurrent}
Kapturowski, S., Ostrovski, G., Quan, J., Munos, R., and Dabney, W.
\newblock Recurrent experience replay in distributed reinforcement learning.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Makoviichuk \& Makoviychuk(2022)Makoviichuk and
  Makoviychuk]{rl-games2022}
Makoviichuk, D. and Makoviychuk, V.
\newblock rl-games: A high-performance framework for reinforcement learning.
\newblock \url{https://github.com/Denys88/rl_games}, May 2022.

\bibitem[Makoviychuk et~al.(2021)Makoviychuk, Wawrzyniak, Guo, Lu, Storey,
  Macklin, Hoeller, Rudin, Allshire, Handa, et~al.]{makoviychuk2021isaac}
Makoviychuk, V., Wawrzyniak, L., Guo, Y., Lu, M., Storey, K., Macklin, M.,
  Hoeller, D., Rudin, N., Allshire, A., Handa, A., et~al.
\newblock Isaac gym: High performance gpu-based physics simulation for robot
  learning.
\newblock \emph{arXiv preprint arXiv:2108.10470}, 2021.

\bibitem[Margolis et~al.(2022)Margolis, Yang, Paigwar, Chen, and
  Agrawal]{margolis2022rapid}
Margolis, G.~B., Yang, G., Paigwar, K., Chen, T., and Agrawal, P.
\newblock Rapid locomotion via reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2205.02824}, 2022.

\bibitem[Miki et~al.(2022)Miki, Lee, Hwangbo, Wellhausen, Koltun, and
  Hutter]{miki2022learning}
Miki, T., Lee, J., Hwangbo, J., Wellhausen, L., Koltun, V., and Hutter, M.
\newblock Learning robust perceptive locomotion for quadrupedal robots in the
  wild.
\newblock \emph{Science Robotics}, 7\penalty0 (62):\penalty0 eabk2822, 2022.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1928--1937. PMLR, 2016.

\bibitem[Moritz et~al.(2017)Moritz, Nishihara, Wang, Tumanov, Liaw, Liang,
  Paul, Jordan, and Stoica]{moritz2017ray}
Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., Paul,
  W., Jordan, M.~I., and Stoica, I.
\newblock Ray: a distributed framework for emerging ai applications. corr
  abs/1712.05889 (2017).
\newblock \emph{arXiv preprint arXiv:1712.05889}, 2017.

\bibitem[Nair et~al.(2015)Nair, Srinivasan, Blackwell, Alcicek, Fearon,
  De~Maria, Panneershelvam, Suleyman, Beattie, Petersen,
  et~al.]{nair2015massively}
Nair, A., Srinivasan, P., Blackwell, S., Alcicek, C., Fearon, R., De~Maria, A.,
  Panneershelvam, V., Suleyman, M., Beattie, C., Petersen, S., et~al.
\newblock Massively parallel methods for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1507.04296}, 2015.

\bibitem[OpenAI et~al.(2020)OpenAI, Andrychowicz, Baker, Chociej, Jozefowicz,
  McGrew, Pachocki, Petron, Plappert, Powell, Ray,
  et~al.]{andrychowicz2020learning}
OpenAI, Andrychowicz, M., Baker, B., Chociej, M., Jozefowicz, R., McGrew, B.,
  Pachocki, J., Petron, A., Plappert, M., Powell, G., Ray, A., et~al.
\newblock Learning dexterous in-hand manipulation.
\newblock \emph{The International Journal of Robotics Research}, 39\penalty0
  (1):\penalty0 3--20, 2020.

\bibitem[Pinto et~al.(2017)Pinto, Andrychowicz, Welinder, Zaremba, and
  Abbeel]{pinto2017asymmetric}
Pinto, L., Andrychowicz, M., Welinder, P., Zaremba, W., and Abbeel, P.
\newblock Asymmetric actor critic for image-based robot learning.
\newblock \emph{arXiv preprint arXiv:1710.06542}, 2017.

\bibitem[Popov et~al.(2017)Popov, Heess, Lillicrap, Hafner, Barth-Maron,
  Vecerik, Lampe, Tassa, Erez, and Riedmiller]{popov2017data}
Popov, I., Heess, N., Lillicrap, T., Hafner, R., Barth-Maron, G., Vecerik, M.,
  Lampe, T., Tassa, Y., Erez, T., and Riedmiller, M.
\newblock Data-efficient deep reinforcement learning for dexterous
  manipulation.
\newblock \emph{arXiv preprint arXiv:1704.03073}, 2017.

\bibitem[Rudin et~al.(2022)Rudin, Hoeller, Reist, and
  Hutter]{rudin2022learning}
Rudin, N., Hoeller, D., Reist, P., and Hutter, M.
\newblock Learning to walk in minutes using massively parallel deep
  reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  91--100. PMLR, 2022.

\bibitem[Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver]{schaul2015prioritized}
Schaul, T., Quan, J., Antonoglou, I., and Silver, D.
\newblock Prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1511.05952}, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Sutton(1988)]{sutton1988learning}
Sutton, R.~S.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3\penalty0 (1):\penalty0 9--44, 1988.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ international conference on intelligent robots
  and systems}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Wijmans et~al.(2019)Wijmans, Kadian, Morcos, Lee, Essa, Parikh, Savva,
  and Batra]{wijmans2019dd}
Wijmans, E., Kadian, A., Morcos, A., Lee, S., Essa, I., Parikh, D., Savva, M.,
  and Batra, D.
\newblock Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion
  frames.
\newblock \emph{arXiv preprint arXiv:1911.00357}, 2019.

\bibitem[Yang et~al.(2022)Yang, Ajay, and Agrawal]{yang2022overcoming}
Yang, G., Ajay, A., and Agrawal, P.
\newblock Overcoming the spectral bias of neural value approximation.
\newblock \emph{arXiv preprint arXiv:2206.04672}, 2022.

\end{thebibliography}
