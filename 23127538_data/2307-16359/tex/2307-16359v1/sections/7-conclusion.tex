In this paper, we generalize previous studies of how opinions about media bias evolve in a network of politically allied or opposed Bayesian learners by inserting partisans into the network. 
Partisans, sometimes termed zealots in contexts unrelated to media bias, are obdurate agents, whose opinions do not change in response to external influences either in pursuit of a deliberate strategy or due to psychological factors. 
Individual persuadable agents, in contrast, hold partial (and changing) confidence in a spectrum of beliefs.
Their beliefs are described by a PDF, which can be multimodal and is updated via a two-stage version of Bayes's rule combining independent observations with peer pressure \cite{fang_opinion_2020,low_discerning_2022,low_vacillating_2022}.
The PDF-based analysis generalizes previous deterministic treatments of zealots, where each agent holds a unique belief \cite{mobilia_does_2003,mobilia_voting_2005,mobilia_role_2007}.

Monte Carlo simulations of the idealized, analogous system of a biased coin reveal several new behaviors, which generalize the results without partisans in Ref.\ \cite{low_discerning_2022} and \cite{low_vacillating_2022}, and the results for deterministic beliefs in previous work by Mobilia et al.\ \cite{mobilia_does_2003,mobilia_voting_2005,mobilia_role_2007} and others.
\begin{inparaenum}[(i)]
\item In allies-only networks, even a single partisan is enough to disrupt asymptotic learning, making persuadable agents vacillate in tandem between $\theta_0$ and $\theta_{\rm p}$. The dwell time is short for $f \lesssim 0.6$, with agents switching frequently from $\theta_0$ to $\theta_{\rm p}$ and vice versa, and episodes of turbulent nonconvergence in between. The dwell time rises steeply for $f\gtrsim 0.6$. 
\item Dueling partisans, who disagree either deliberately or by accident, reduce the dwell time. Even a single disagreeing partisan is enough to reduce $\langle t_{\rm d} \rangle$ by a factor $\approx 3$. The number of dwell intervals at $\theta_{\rm p1}$ and $\theta_{\rm p2}$ is proportional approximately to the number of partisans at $\theta_{\rm p1}$ and $\theta_{\rm p2}$. 
\item In opponents-only networks, multiple opponents can be ``corralled'' begrudgingly into the same belief, which may or may not equal $\theta_0$, due to repulsive peer pressure from agents with adjacent beliefs. 
\item \label{item:wrong-conclusion-first} The counterintuitive tendency to reach the wrong conclusion first in opponents-only networks, explored in Ref. \cite{low_discerning_2022}, is still observed in complete networks with $\theta_0 = \theta_{\rm p}$, although $t_{\rm a}^{\rm right} - t_{\rm a}^{\rm wrong}$ is lower. In general, for $\theta_0 \neq \theta_{\rm p}$, the tendency persists, as long as the network is sparse enough (e.g.\ Barab\'{a}si-Albert network with attachment parameter $m \lesssim 10$), as sometimes occurs in  real social settings. 
\item In mixed networks containing allies and opponents, sudden transitions occur from asymptotic learning (in the sense of Eq.\ \eqref{eq:asymlearncondition}) to turbulent nonconvergence, namely the intermittency phenomenon studied in Ref.\ \cite{low_vacillating_2022}. The strongly balanced $G_3$ triad in Fig. \ref{fig:triad} is destabilized by inserting a partisan, passing from asymptotic learning to intermittency. 
In contrast, the fate of the unbalanced triad $G_2$ depends on where the partisan is inserted.
\item Randomized tests confirm that the above results depend weakly on the priors and coin toss sequence, but there is some dependence on connectivity in opponents-only networks, as in point (\ref{item:wrong-conclusion-first}).
\end{inparaenum}

The social science theory of structural balance of Herider \cite{heider_attitudes_1946}, extended by Harary, Cartwright \cite{cartwright_structural_1956} and Davis \cite{daivs_clustering_1967} can be used to characterize networks based on clusters, as defined in Section 6 of Ref.\ \cite{low_discerning_2022}.
The stability of a network, in terms of its propensity to achieve asymptotic learning, has been linked to structural balance in the social science literature in the absence of partisans, e.g.\ 
the network of alliances of six particular countries in World War I began as an unbalanced network, and settled as a balanced network \cite{antal_social_2006}.
Networks can be categorized as: 
(i) strongly balanced, if the network can be partitioned into one or two distinct clusters, with no agents left out;
(ii) weakly balanced, if the network can be partitioned into more than two distinct clusters, with no agents left out;
(iii) unbalanced, if it is impossible to group every agent into a cluster.
The link between clusters and stability is modified in interesting ways, when partisans are introduced. 
Allies-only networks in Section \ref{sec:alliesonly} are an example of strongly balanced networks, as all agents can be grouped in the same cluster, yet they exhibit turbulent nonconvergence, when even a single partisan is introduced. 
Hence, it may be valuable to generalize the theory of structural balance by according different status to clusters including and excluding partisans, an interesting avenue for future work. 
Opponents-only networks in Section \ref{sec:opponentonly} are weakly balanced networks with each cluster containing only one agent. When partisans are introduced, we do not see major changes in the behavior of the network. 
Unbalanced networks are likely to experience turbulent nonconvergence and intermittency \cite{low_discerning_2022}, whether partisans are present or absent, but the situation is complicated from a structural balance viewpoint: the cluster that a partisan joins partly determines who in the network experiences intermittency and who does not. Clarifying the link is an interesting avenue for future work. 

We emphasize that the biased coin analyzed in this paper is a highly idealized analogy. 
In real societies, perceptions of media bias are formed through the interaction of many subtle political and psychological factors, which are not captured by the biased coin. 
These factors affect both stages of the Bayesian update rule in Section \ref{subsec:modelintro} and Algorithm \ref{alg:algo}. 
With regard to the first stage, when assessing media outputs (e.g.\ newspaper editorials), the judgments of individuals are influenced by their psychological state, which in turn depends on their beliefs, especially when those beliefs are held passionately. 
For example, an individual's preexisting perception of a newspaper's bias feeds into their reading of the text of a specific editorial in a self-reinforcing manner, not simply through the multiplicative prior $x_i(t,\theta)$ in Eq.\ \eqref{eq:updatefirsthalf} but additionally in a nonmultiplicative fashion; that is, $x_i(t,\theta)$ feeds into the individual's impressions about the tone, language, and logical arguments in the editorial and hence the likelihood $P[S(t)|\theta]$ itself. 
With regard to the second stage, the fundamental dynamics encoded by Eqs.\ \eqref{eq:undatesecondhalf} and \eqref{eq:xiprimed} --- that the beliefs of allies and opponents converge and diverge respectively --- assume that peer pressure occurs in a pairwise manner, i.e.\ the peer pressure from multiple pairs can be summed in linear superposition. 
In reality, people may not partition their response so fastidiously. Instead, they may cluster their allies and opponents using some ``fuzzy'', intuitive metric and react to clusters of different sizes (or types) nonlinearly. 
None of these effects enter the idealized model in this paper.


With the above caveats in mind, we advance with due reserve a handful of instances, where the results in this paper may enjoy some measure of social relevance in practice.
Firstly, it is striking that partisans disrupt the discovery of the truth even when they are fewer in number than persuadable agents \cite{mobilia_role_2007}. 
In this paper, even a single partisan disrupts asymptotic learning in an allies-only network; the persuadable agents are herd-like, in that they form a consensus, but the consensus switches frequently between $\theta_0$ and $\theta_{\rm p}$ at low $f$. 
These low-$f$ results represent the minority-partisan limit of the celebrated majority-partisan experiments by Asch \cite{asch_opinions_1955}, which demonstrated conformity through peer presure. 
They are relevant to debates about political bias by citizens in social networks, because it is easy for a small group of dedicated and cynical ``trolls'' to foment a climate of uncertainty and destabilize the perceptions of others by making them vacillate indefinitely, even if the ``trolls'' are too few to engineer a steady belief in something untrue. 
Secondly, the tendency to reach the wrong conclusion first in networks with significant amounts of antagonism (e.g.\ opponents-only networks as an extreme case) survives the introduction of partisans, as long as people are not connected too densely (e.g.\ attachment parameter $\lesssim 10$ in scale-free, Barab\'{a}si-Albert networks). 
Scale-free networks with modest levels of connectivity are common in society \cite{barabasi_emergence_1999,tang_survey_2016,kumar_structure_2016,maniu_building_2011}, and political opposition is patently a fact of life, so one expects a widespread tendency to reach the wrong conclusion first. 
This is related to the ``backfire effect'' in social science \cite{nyhan_when_2010}, where agents exposed to contrary beliefs become more confident in their own prior.
The effect has been modeled and studied in the scope of opinion dynamics by Chen et al.\ \cite{chen_opinion_2019}. 
Once a false conclusion becomes entrenched in a community, it can become a self-fulfilling prophecy, benefiting from its own unearned, network-bestowed, first-mover advantage. 
What is popular is not always a reliable guide to what is true; in several experiments in this paper, false beliefs championed by partisans (or even emerging accidentally from equal but opposite antagonistic interactions) are held more steadfastly for longer intervals (dwell times) by more agents than true beliefs. 
Thirdly, and finally, partisans do not always destabilize a network or deflect people from the truth, even if that is their intent. 
For example, one agent in an unbalanced triad always exhibits intermittent behavior, with or without a partisan, but a partisan prevents the non-intermittent agent from converging on the wrong belief. 

More generally, the phenomenon of intermittency in mixed networks, investigated elsewhere \cite{low_vacillating_2022,hoffman_role_2007}, survives the introduction of partisans, although the behavior depends on where exactly the partisans are located. 
This is relevant to social applications, where mixed networks are the norm, because it is a reminder that the feedback in mixed networks is complicated and unpredictable, and partisans guided by simplistic (e.g.\ pairwise-motivated) strategies to achieve certain goals may reap unintended consequences. 
In all cases, network effects are as important as individual human psychology in shaping outcomes.

The results in the paper suggest some productive directions for future work. 
\begin{inparaenum}[(i)]
\item It is interesting to investigate the behavior of persuadable agents who are indirectly connected to a partisan, using partly connected networks which more closely model real social networks (e.g.\ Barab\'{a}si-Albert). 
We make a start in this direction in Section \ref{sec:BA}, by looking briefly at outcomes including loss of consensus, controlling factors including $d_{\rm p}$, and optimizing the placement of partisans to satisfy some network-wide goal. 
\item It is also interesting to investigate the impact of one-sided relationships, such as an agent allying with another agent who opposes them, using directed networks (e.g.\ Price network \cite{price_networks_1965}).
\item One can generalize the concept of partisanship by endowing every agent, not just partisans, with some degree of stubbornness. For example, how stubborn must a ``semi-partisan'' be before they disrupt asymptotic learning in an allies-only network, as in Section \ref{sec:alliesonly}? 
\end{inparaenum}

% BENCHMARK
Finally, efforts can be made to test the idealized model in this paper quantitatively against real-world data using natural language processing \cite{chowdhary_natural_2020} to infer individuals' perceptions of media bias from social media such as Twitter \cite{wang_system_2012,vilares_megaphone_2015,dragoni_unsupervised_2019} and make independent assessments of $\theta_0$ through text and image analysis of media outputs such as newspaper editorials \cite{kwon_opinion_2013}. 
There are two challenges in this sort of real-world benchmarking. The first is what question to ask. 
Is the goal to test the two-stage update rule defined by Eq.\ \eqref{eq:updatefirsthalf}--\eqref{eq:xiprimed}? 
Do we take the update rule for granted and seek to infer the existence and locations of partisans (if any)? 
Without direct access to $x_i(t,\theta)$, do we test the model for internal consistency by searching for positive or negative correlations between a quantity like $\langle \theta \rangle$ for the $i$-th agent (inferred perhaps from a proxy like social media output) and the local structure of $A_{ij}$?
Formal benchmarking frameworks of these kinds have been developed in the electrical engineering literature and elsewhere \cite{andersen_benchmarking_1995,moriarty_theory_2011}
% [DONE: very important to insert a good reference suggested by Rob Evans, ideally a textbook] 
and present an exciting avenue for future work. 
% DONE: a precise sentence on the method that can be used to benchmark it
The second challenge is how to collect the relevant data under conditions that are as controlled as possible. Laboratory and field studies are both viable options \cite{jackson_social_2008}. 
% Framework to compare with data indep. of the details, in a signal procession POV
Laboratory experiments offer the ability to control and fine-tune certain parameters, as is done in experimental economics \cite{weimann_experimental_2019}. 
% DONE: and finish with a reference to a famous textbook in experimental economics. 
However, some model parameters are not easily controlled. 
For instance, the learning rate $\mu$ is likely to differ from person to person, unlike in Eq.\ \eqref{eq:undatesecondhalf}. 
Field surveys, on the other hand, do not constrain parameters as strictly as laboratory experiments, but evaluate social structures in real-world settings, for example, Milgram's small world experiment \cite{milgram_milgthe_1967}. 
Data about opinions is normally limited and obtained through small sociological surveys or polls across populations and time \cite{peralta_opinion_2022}. 
The rise of computerized social experiments could be a promising means of expanding the volume of opinion data. 
It is possible to extract the topology of and agent behavior in real-world social networks from online platforms such as Facebook \cite{chang_proposed_2018,garton_studying_1997}. 
Online social networks also process large amounts of data on social network structures \cite{son_cognitive_2021,zhao_inferring_2013}, automated analysis of user-generated online content \cite{liu_sentiment_2012}, and infer agents' real-time opinions though their behavior online \cite{luceri_analyzing_2019,goel_real_2016,mu_clustering-based_2022}. 
There is some recent literature in opinion dynamics that benchmarks models against real-world data, mostly focused on detecting community structure in networks \cite{morarescu_opinion_2011,bu_graph_2020,newman_modularity_2006}. 
Ref.\ \cite{devia_framework_2022} proposes a qualitative framework through a histogram-based classification algorithm to evaluate opinion dynamics models on their accuracy of predicting the evolution of opinion in real-world values surveys.
In principle, the work in this paper can be benchmarked within such a framework.
% While this specific framework cannot evaluate the high-level social behaviors identified by our model, a similar approach may .

% Wasserstein distance
% 1D closed form solution
% 2D scales quadratically by number of supports in distribution

