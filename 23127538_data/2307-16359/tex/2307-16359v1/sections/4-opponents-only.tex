We now change our focus to opponents-only networks to investigate the impact of partisans under antagonistic interactions. 
Section \ref{subsec:asym_learning} examines a network with only one partisan to build intuition through a baseline system. 
We find that a partisan does not prevent the system from achieving equilibrium; unlike in an allies-only network, opposing partisans do not ``pull'' the persuadable agents towards a unique belief $\theta_{\rm p} \neq \theta_0$, because everybody is in mutual opposition.  
The results concerning asymptotic learning resemble those without partisans in Ref.\ \cite{low_discerning_2022}.
Section \ref{subsec:wrong_conclusion_first} examines if the wrong conclusion is reached first in this simulation, as observed in Ref.\ \cite{low_discerning_2022}, for various network structures. 
The special case $\theta_{\rm p} = \theta_0$ is investigated, where indeed asymptotic learning does occur more slowly at $\theta_0$ than at other (wrong) values of $\theta$, just as in Ref.\ \cite{low_discerning_2022}. 
More generally, however, for $\theta_{\rm p} \neq \theta_0$, the connectivity of the network controls whether or not the wrong conclusion is reached first, unlike the system without partisans in Ref.\ \cite{low_discerning_2022}.
The asymptotic learning time $t_{\rm a}$ is computed as a function of the partisans fraction $f$ in Section \ref{subsec:opponent_frac_partisan}. 
% update this para with an extra sentence for sec 4.1/4.2/4.3 new structure - see yellow sticky notes on next page

\subsection{Asymptotic learning}
\label{subsec:asym_learning}
Opponents-only networks with and without partisans exhibit similar long-term outcomes: individual persuadable agents, and the system as a whole, achieve asymptotic learning as defined by Eqs.\ \eqref{eq:asymlearncondition} and \eqref{eq:sysasymlearncondition}, and as observed in Ref.\ \cite{low_discerning_2022}.

Consider a simulation like the one conducted in Section \ref{subsec:samethetap}, but with $A_{ij} = -1$ for all $i\neq j$.
We no longer observe turbulent nonconvergence as in Fig.\ \ref{fig:meannonpartisan}.
Fig.\ \ref{fig:mean_1_o} shows how $\langle\theta\rangle$ evolves in a particular simulation for $0 \leq t \leq 500$. 
Only the first 500 timesteps are shown in Fig.\ \ref{fig:mean_1_o} for brevity, but the simulation runs for $T=10^5$, and $\langle \theta \rangle$ tends to a constant for $t >221$ for every agent. 
That is, the system achieves asymptotic learning at $t_{\rm a} = 221$.


% Figure environment removed


The persuadable agents do not reach consensus, in contrast to Section \ref{subsec:samethetap}, because antagonistic interactions drive their beliefs apart.
% insert 3-4 sentences here saying exactly which beliefs they tend to (0.40-0.75 in steps of 0.05 sort of thing) and refer specifically to visual features of fig 6a - also introduce fig 6b but just focus on the number of persuadables at each theta, describe shape of distribution, and just say at end "The dependence of the histogram on $| \theta_0 - \theta_{\rm p}| $ is studied in Section 4.2."
The beliefs of persuadable agents cluster around the true bias $\theta_0$, as shown in Fig.\ \ref{fig:mean_1_o}, specifically in the range $0.40 \leq \theta \leq 0.75$ in steps of 0.05 due to the discretization discussed in Section \ref{subsec:automaton}. 
This behaviour is also observed in a Barab\'{a}si-Albert network, as shown in Fig.\ 10a in Ref.\ \cite{low_discerning_2022}. 
Fig.\ \ref{fig:diff_theta_p_o} presents a histogram of the number of persuadable agents with average belief $\langle\theta\rangle|_{t=t_{\rm a}}$. The distribution has the shape of a bell curve, peaking at $\langle\theta\rangle|_{t=t_{\rm a}} = \theta_0$. 
The dependence of the histogram on $|\theta_0 - \theta_{\rm p}| $ is studied in Section \ref{subsec:wrong_conclusion_first}.
% Although all agents are opponents, subset of agents ends up agreeing.
Multiple persuadable opponents can occupy the same $\langle\theta\rangle$ bin, because the internal peer pressure is zero if two opponents agree with each other according to Eq.\ \eqref{eq:xiprimed}, i.e.\ there is no belief repulsion between opponents who agree, allowing opponents to settle on the same belief. 
Eq.\ \eqref{eq:xiprimed} implies that such ``grudging agreement'' is unstable, when the network contains only two persuadable opponents, because a small disagreement grows with time via \eqref{eq:xiprimed}. 
However, when there are many persuadable opponents who hold adjacent beliefs, the situation stabilizes.  For example, agents with $x_i(t,\theta)=\delta(\theta-0.50)$ and $x_j(t,\theta)=\delta(\theta-0.60)$ exert opposing repulsive peer pressure on, and hence stabilize, multiple agents labeled $k$ with $x_k(t,\theta)=\delta(\theta-0.55)$.
This resembles the scenario, when two opponents begrudgingly agree because they are both forced into the same opinion by other opponents.  

Asymptotic learning in opponents-only networks containing more than one partisan occurs similarly to Fig.\ \ref{fig:mean_1_o}. It is investigated in Section \ref{subsec:opponent_frac_partisan} as part of a study of $t_{\rm a}$ versus $f$.


\subsection{Reaching the wrong conclusion first}
\label{subsec:wrong_conclusion_first}
A key observation in opponents-only Barab\'{a}si-Albert networks without partisans is that agents who reach the wrong conclusion do so before their opponents reach the right conclusion. 
This counterintuitive tendency is quantified in detail in Section 4.2 and 5.1 in Ref.\ \cite{low_discerning_2022}. 
Here we test if the tendency still holds for complete networks with a single partisan. In this section, unlike in the rest of Sections \ref{sec:alliesonly} -- \ref{sec:mixed}, we consider scale-free, Barab\'{a}si-Albert networks as well as complete networks, because it turns out that connectivity plays an important role in reaching the wrong conclusion first.

We start by investigating the special situation where the partisan believes in the true bias, with $\theta_{\rm p} = \theta_0 = 0.6$.
Table \ref{tab:right_and_wrong} compares the statistics of $ t_{\rm a}^{\rm right}$ and $ t_{\rm a}^{\rm wrong}$ for four different systems, where the superscripts ``right'' and ``wrong'' label $t_{\rm a}$ for the right and wrong conclusions respectively. 
When a partisan is present in a complete network with $\theta_{\rm p} = \theta_0$, the wrong conclusion does tend to be reached first, but the difference between $\langle t_{\rm a}^{\rm right} \rangle$ and $\langle t_{\rm a}^{\rm wrong} \rangle$ is smaller than in a Barab\'{a}si-Albert network, as evidenced by columns \ref{col:ab_no_partisan} and \ref{col:complete_06} in Table \ref{tab:right_and_wrong}. 
This is because, at the beginning of the simulation, the persuadable agents feel persistent repulsion from the partisan at $\theta = \theta_0$.
Persistent repulsion also affects how many agents converge on a particular final belief. 
Fig.\ \ref{fig:diff_theta_p_o} presents a histogram of the number of agents as a function of $\langle \theta \rangle|_{t=t_{\rm a}}$; as $x_i(t, \theta)$ peaks narrowly for all $i$ and $t \geq t_{\rm a}$, it is accurate to approximate agents' final beliefs by $\langle \theta\rangle|_{t=t_{\rm a}}$. 
For $\theta_{\rm p} =\theta_0 = 0.6$, i.e.\ the green bars in the histogram, $\langle\theta\rangle|_{t=t_{\rm a}} = 0.6$ is not the modal value, unlike for the control experiment with zero partisans (blue bars). Quantitatively, 11\% of the agents tend to $\langle\theta\rangle|_{t=t_{\rm a}} = 0.6$, compared to 14\% in the control experiment. This is the same trend identified in Ref.\ \cite{low_discerning_2022}, namely reaching the wrong conclusion first, except that $t_{\rm a}^{\rm right} - t_{\rm a}^{\rm wrong}$ is smaller. 

% This repulsion is also observed in the frequency at which agents asymptotically learn at $\theta_0$
% As all final distribution for agents are singularly peaked, we use $\langle \theta \rangle$ to represent the final belief. 
% Fig.\ \ref{fig:diff_theta_p_o} shows the distribution of beliefs for each persuadable agent.
% Most persuadable agents asymptotically learn on the belief close to $\theta_0$, 
% as shown by the blue and orange bar in Fig.\ \ref {fig:diff_theta_p_o}, 
% as the coin tosses generate a binomial distribution, centred at $\theta_0$, while the $\theta$ far away from $\theta_0$ are exponentially suppressed. 
% However, when $\theta_{\rm p} = \theta_0 = 0.6$, persuadable agents asymptotically learn on $\theta_0$ less often, compared to when $\theta_{\rm p} = 0.3$, due to the repulsion from the partisan in the early stage of the simulation. 
% After the early stage of the simulation where agents have greater confidence in their belief, the strong opinion of partisans no longer stands out, the persuadable agents no longer feel a strong repulsion at the true bias, hence reaching asymptotic learning at $\theta_0$ later. 

\begin{table}[h]
    \centering\begin{tabular}{|c||c|c||c|c||c|c||c|c|}
    \hline
     & 
    \multicolumn{2}{c||}{\makecell{\newtag{(a)}{col:ab_no_partisan} \\ No partisan \\ Barab\'{a}si-Albert}} &
    \multicolumn{2}{c||}{\makecell{\newtag{(b)}{col:complete_no_partisan} \\ No partisan \\ Complete}} &
    \multicolumn{2}{c||}{\makecell{\newtag{(c)}{col:complete_03} \\ $\theta_{\rm p} = 0.3 \neq \theta_0$ \\ Complete}} &
    \multicolumn{2}{c|}{\makecell{\newtag{(d)}{col:complete_06} \\ $\theta_{\rm p} = 0.6 = \theta_0$ \\ Complete}} \\
    \hline
    Property of $t_{\rm a}$
    &$t_{\rm a} ^{\rm right}$ & $t_{\rm a}^{\rm wrong}$ 
    & $t_{\rm a} ^{\rm right}$ & $t_{\rm a}^{\rm wrong}$
    & $t_{\rm a} ^{\rm right}$ & $t_{\rm a}^{\rm wrong}$
    & $t_{\rm a} ^{\rm right}$ & $t_{\rm a}^{\rm wrong}$\\
    \hline
    % Mean &784&226&66&64&68&65&72&64 \\ 
    % Standard deviation &563&243&26&30&30&33&34&33 \\
    First quartile &337&60&50&47&50&47&51&45 \\
    Median &715&92&60&57&60&58&63&56 \\
    Third quartile &1093&174&74&73&76&74&82&73 \\
    \hline
    \makecell{Total number of \\ asymptotic learning agents} &26110&33220&14181&85819&13919&85081&10926&88074 \\
    \hline
    \end{tabular}
    \caption{
        Summary statistics of $t_{\rm a}^{\rm right}$ and $t_{\rm a}^{\rm wrong}$, the asymptotic learning times for right and wrong beliefs respectively, accumulated over $10^3$ simulations, for $n=100$, $T=10^5$, and four different network structures.  
        The first, second, and third quartiles are listed for each network.}
    \label{tab:right_and_wrong}
\end{table}

Interestingly, the tendency to reach the wrong conclusion first does not occur in complete networks in the general case $\theta_{\rm p} \neq \theta_0$. 
Columns \ref{col:complete_no_partisan} and \ref{col:complete_03} in Table \ref{tab:right_and_wrong} show that one has $t_{\rm a}^{\rm right} \approx t_{\rm a}^{\rm wrong}$ within statistical fluctuations for complete networks with $\theta_{\rm p}=0.3 \neq \theta_0$ (column \ref{col:complete_03}) and without a partisan (column \ref{col:complete_no_partisan}). 
This differs from the behavior of Barab\'{a}si-Albert networks studied in Ref.\ \cite{low_discerning_2022}. 
The Barab\'{a}si-Albert attachment parameter $m$ is often small in applications ($m = 3$ in Ref.\ \cite{low_discerning_2022}), meaning that each Barab\'{a}si-Albert agent has only a few opponents, while each agent has 99 opponents in the complete network with $n=100$. 
Hence the influence of one particular opponent, and the ``lock-out effect'' identified in Section 4.2 in Ref.\ \cite{low_discerning_2022}, are less significant in a complete network than in a Barab\'{a}si-Albert network when calculating the sum in Eq.\ \eqref{eq:xiprimed}.


We test this effect by considering different values of $m$ for Barab\'{a}si-Albert networks with $n=100$. 
Fig.\ \ref{fig:bba_sweep} shows the difference in mean asymptotic learning time between the right and wrong beliefs for $1\leq m \leq 99$. 
We observe that for networks with fewer connections, the wrong conclusion is reached first.  
Quantitatively, we find $\langle t_{\rm a}^{\rm right} \rangle - \langle t_{\rm a}^{\rm wrong} \rangle \leq 0.01 \langle t_{\rm a}^{\rm wrong} \rangle $ for $m \geq 15$. 
This agrees with the findings of Low \& Melatos \cite{low_discerning_2022} on Barab\'{a}si-Albert networks with $m=3$.  
More generally, as $m$ increases, the connectivity within the network increases, and each agent is connected to more opponents, suppressing the influence of individual agents.
The light blue shading shows the range corresponding to two standard deviations.
The dispersion in $\langle t_{\rm a}^{\rm right} \rangle - \langle t_{\rm a}^{\rm wrong} \rangle$ decreases with $m$. 

% Talk to AM: why?
% The large fluctuation for low $m$ may be caused by the dependence on the initial conditions.
% The agent who is initially more confident in $\theta_0$ is more likely to infer the true bias according to Ref. \cite{low_discerning_2022}. 


\subsection{Fraction of partisans: effect on $t_{\rm a}$}
\label{subsec:opponent_frac_partisan}
We now increase the number of partisans in opponents-only networks and examine the behavior of persuadable agents. 
All networks achieve asymptotic learning. 
Turbulent nonconvergence is not observed, because partisans do not ``pull'' other agents (whom they oppose) towards their own partisan beliefs, even when the partisans agree among themselves.

Fig.\ \ref{fig:ta_vs_f} shows how the asymptotic learning time depends on the fraction of partisans $f$, all for $\theta_{\rm p} = 0.3$, with $0.01 \leq f \leq 0.99$ in steps of 0.01.
The persuadable agents achieve asymptotic learning more slowly as $f$ increases.
The reason is related to the ``lock-out'' mechanism identified in Section 4.2 of Ref.\ \cite{low_discerning_2022}. 
Consider opponents $i$ and $j$, whose beliefs do not overlap at some $\theta$. 
For $x'_i(t+1/2,\theta)=0$ and $x'_j(t+1/2,\theta) \geq 0$ without loss of generality, we have $A_{ij} [ x'_j(t+1/2,\theta) - x'_i(t+1/2,\theta) ] \leq 0$. 
Summing over all such opponents $j$ for fixed $i$, we obtain $x_i(t+1,\theta)=0$ from Eq.\ \eqref{eq:undatesecondhalf} at the value of $\theta$ being considered. 
Therefore agents cannot respond to the full likelihood of the coin, because part of the $\theta$ domain is zeroed out by opponents, i.e. $x_i(t,\theta') = 0$ implies $x'_i(t+1/2,\theta') = 0$ for locked-out $\theta'$ values, because Eq.\ \eqref{eq:updatefirsthalf} is multiplicative. 
For low $f$, there are more persuadable agents forming beliefs at various $\theta$ values, so more of the $\theta$ domain for every agent is locked out by opponents, causing every agent to ``see'' a narrow likelihood when observing the coin tosses.  
On the other hand, when networks contain more partisans (i.e.\ higher $f$), who all agree on $\theta_{\rm p}$, fewer $\theta$ values are occupied by persuadable agents, and all persuadable agents ``see'' more of the likelihood. 
As  $x_i(t,\theta)$ is normalized, agents who see a narrower likelihood achieve asymptotic learning faster than agents who see a wider likelihood. 
Therefore, $t_{\rm a}$ increases with $f$ in an opponents-only network.
% worth adding 1-2 sentences about the min/max range shaded in the figure and what it teaches us (specifics, not vague)
The light blue shading in Fig.\ \ref{fig:ta_vs_f} brackets the ensemble minimum and maximum, and the orange shading brackets the range out to two standard deviations.



% Figure environment removed