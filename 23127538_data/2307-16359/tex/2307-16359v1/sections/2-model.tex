% add paragraph
In this section, we extend the media bias model formulated by Low \& Melatos \cite{low_discerning_2022} to include obdurate partisans.  Section \ref{subsec:modelintro} summarizes how the evolution of perceptions about media bias maps onto an idealized model, in which a network of political allies and opponents infers the bias of a coin. A two-step update rule is presented, which updates the belief of each networked agent in response to independent observations of the coin and peer pressure from the network \cite{low_discerning_2022,low_vacillating_2022}.  
The implementation of partisans is described in Section \ref{subsec:intropartisans}, and the pseudocode for the resulting, iteratively updated automaton is presented in Section \ref{subsec:automaton}.  
The paper focuses on complete networks for technical reasons justified in Section \ref{subsec:network}. Complete networks are adequate to demonstrate the central points of the paper, but the study of other network topologies is an important issue which is deferred to future work (except for a brief discussion in Sections \ref{sec:opponentonly} and \ref{sec:BA}). 
The extended idealized model is compared with other models in the literature in Section \ref{subsec:relationtoothers}. 



\subsection{Updating beliefs in two steps: independent observations and peer pressure}
\label{subsec:modelintro}
In Ref.\ \cite{low_discerning_2022}, a network of $n$ agents attempts to learn the true bias $0 \leq \theta_0 \leq 1 $ of a coin though a sequence of $T$ coin tosses, where $\theta_0$ denotes the probability of heads for a single coin toss.  The coin toss is an analog for a piece of politically relevant information (e.g.\ editorials, articles), which the agents consume from a media outlet, and $\theta_0$ is an analog for the political bias of the media outlet (e.g.\ on a simplified, left-right spectrum).  The $i$-th agent harbors probabilistic beliefs about the political bias of the media outlet, or analogously the bias of the coin, which are described by the probability density function (PDF) $x_i(t,\theta)$ at time $t$. The beliefs can be multi-valued and hence uncertain in general; the agent may be equally confident about two distinct values of the coin's bias, for example, with $x_i(t,\theta_1)=0.5=x_i(t,\theta_2 \neq \theta_1)$. 
\footnote{Multimodal belief PDFs are realistic in various settings.  In the media bias context, for example, a reader of a newspaper's editorials may be unsure as to whether the newspaper leans right or left politically, if the editorials lean right on economic issues and left on social issues.  The reader may develop a bimodal belief PDF in this scenario (i.e., the newspaper actually leans right or left but not both, and the reader is unsure which option to prefer) instead of a unimodal belief PDF (i.e., the newspaper occupies the middle of the road politically, and the reader believes its bias lies between the right and left extremes).  Multimodality is more likely, when there are multiple ways to map the underlying bias variable to the observed output signal  (e.g., editorials), and readers (and maybe even the newspaper's editors themselves) do not know consciously which mapping applies in practice. The point is especially pertinent, when a reader overlays an oversimplified mental model (e.g., left-right dichotomy) on a more complicated bias structure (e.g., left-right economic-social matrix). }
Starting from initial PDFs $x_1(t=0,\theta), \dots, x_n(t=0,\theta)$, the beliefs of the $i$-th agent in the network are updated in two steps, every time a coin toss occurs. 
\begin{enumerate}
    \item The $i$-th agent observes the coin toss at time $t$ and invokes Bayes's rule to combine their prior beliefs at time $t$ with the result of the coin toss to generate an intermediate, provisional PDF $x_i'(t+1/2,\theta)$.
    \item The $i$-th agent is influenced by positive and negative peer pressure from their allies and opponents respectively and adjusts $x_i'(t+1/2,\theta)$ accordingly to obtain the fully updated PDF at the conclusion of that time step, $x_i(t+1,\theta)$.
\end{enumerate}
The outcome of each coin toss is a public external signal, which is simultaneous and unfiltered for all agents, i.e.\ all agents observe the outcome and accept it without demur.

The first half of the update rule above, based on an independent observation of the coin, follows immediately from Bayes's rule. We write
\begin{equation}\label{eq:updatefirsthalf}
    x'_i(t+1/2, \theta) = \frac{P[S(t) | \theta]}{P[S(t)]}x_i (t, \theta),
\end{equation}
where $S(t)$ is the outcome of the coin toss (heads or tails), $P[S(t)| \theta]$ is the likelihood function, and $P[S(t)] = \sum_{\theta}P[S(t)| \theta]x_i (t, \theta)$ is the normalizing constant. The likelihood function takes the form
\begin{equation}\label{eq:likelihood}
    P[S(t)| \theta] = \begin{cases} \theta, & \mbox{if } S(t)\mbox{ is heads} \\
    1-\theta,  & \mbox{if } S(t)\mbox{ is tails.} \end{cases}
\end{equation}

The second half of the update rule shapes the belief of each agent under the influence of political allegiances.  In much of the literature, agents are typically conditioned to copy, or at least move towards, the beliefs of their neighbors in the network; that is, they implicitly regard their neighbors as allies \cite{degroot_reaching_1974,hegselmann_opinion_2002,fang_social_2019,jadbabaie_non-bayesian_2012,deffuant_mixing_2000}.  In this paper, we generalize the network to include allies and opponents, such that antagonistic  interactions involving negative feedback between agents are taken into account.  The network is modelled by a graph, where nodes represent agents, and edges are tagged with the political allegiance between two agents.  A weighted graph with $n \times n$ adjacency matrix $A$ is used with entries 
\begin{equation}
    A_{ij} = 
    \begin{cases}
        + 1 , \quad & \text{agents $i$ and $j$ are allies} \\
        0 , \quad & \text{agents $i$ and $j$ are disconnected} \\
        - 1 , \quad & \text{agents $i$ and $j$ are opponents} \\
    \end{cases}
\end{equation}
We note that agents $i$ and $j$ can be connected (and therefore influence each other) indirectly through one or more third parties (e.g. $A_{ik}\neq0$ and $A_{kj} \neq 0$ for $k \neq i,j$), even if they are not connected directly ($A_{ij}=0$).  In this paper, we assume for simplicity that $A$ is symmetric (i.e.\ $A_{ij} = A_{ji}$),  and that allies and opponents exert equal and opposite peer pressure.

Under peer pressure from allies and opponents, the provisional belief PDF at $t+1/2$ of the $i$-th agent is updated according to
\begin{equation}\label{eq:undatesecondhalf}
    x_i(t+1, \theta) \propto \max\left[0, x_i '(t+1/2, \theta) + \mu \Delta x_i '(t + 1/2, \theta)\right]
\end{equation} 
to give the PDF at time $t+1$, concluding the two-step update rule. The proportionality constant is set by normalization.  The learning rate $0.0 < \mu \leq 0.5$ quantifies the susceptibility of an agent to their neighbors' beliefs and is covariant with the duration of each time step; halving $\mu$ is equivalent to doubling the time step without loss of generality.  The inequality $\mu \leq 0.5$ prevents the beliefs from overshooting and is borrowed from the Deffuant-Weisbuch model \cite{deffuant_mixing_2000}.  The displacement 
\begin{equation}\label{eq:xiprimed}
    \Delta x_i '(t + 1/2, \theta) = a_i^{-1} \sum_{i\neq j} A_{ij}[x_j '(t+1/2, \theta) - x_i '(t+1/2, \theta)]
\end{equation}
with $a_i = \sum_{j \neq i} |A_{ij} |$, equals the average difference in belief (at each $\theta$) between agent $i$ and all its neighbors. We only consider connected graphs, where every agent has at least one ally or opponent, i.e.\ $a_i \neq 0$ for all $i$. Equations \eqref{eq:undatesecondhalf} and \eqref{eq:xiprimed} drive an agent's belief towards its allies ($A_{ij} > 0$) and away from its opponents ($A_{ij} < 0$).  Without the maximization operation in equation \eqref{eq:undatesecondhalf}, the antagonistic interaction can produce $x_i(t+1, \theta) < 0$ via equation \eqref{eq:xiprimed}, which is invalid for a probability density; see Section 2.3 in Ref.\ \cite{low_discerning_2022} for more details.  All agents observe the coin toss and combine their prior belief with the result of the coin toss synchronously via equation \eqref{eq:updatefirsthalf} before agents are influenced by positive or negative peer pressure from the network via equation \eqref{eq:undatesecondhalf}, which completes the full time-step from $t$ to $t+1$. 

\subsection{Implementation of obdurate partisans}
\label{subsec:intropartisans}

A partisan is obdurate, in the sense that their opinion does not change with time in response to independent observations or peer pressure. 
In general, the PDF of a partisan can take any time-independent form, viz. $x_i(t,\theta)=x_i(\theta)$.  
In this paper, we  specialize mainly to the situation where partisans hold a single belief, with $ x_i(t,\theta) = \delta(\theta-\theta_{\rm p})$ for all $t$, except in Section \ref{subsec:partisandifferentopinion} where we treat dueling partisans.  
One key goal of the analysis is to test how the behavior of the network depends on $\theta_{\rm p}$. 
For example, does the impact of the partisan increase, as $|\theta_{\rm p} - \theta_0|$ increases?  
In general, when $x_i(\theta)$ is not simply a delta function, one can pose a more sophisticated question: can a partisan increase or decrease their impact on persuadable agents by adjusting the shape of $x_i(\theta)$? 
This question is relevant, when a partisan's beliefs are shaped by a deliberate strategy to manipulate the opinions of other agents in the network, instead of subconscious, psychological factors. Its study is postponed to future work.


In this paper, a partisan's PDF is implemented as a narrow Gaussian distribution with mean $\theta_{\rm p}$ and standard deviation $\sigma_{\rm p} = 10^{-3}$, truncated to the domain $0 \leq \theta \leq 1$.  Although obdurate partisans do not change their opinions, other agents still interact with them, learn from the partisans, and evolve their opinions accordingly. 


In this paper, for numerical convenience only, we apply Eqs.\ \eqref{eq:updatefirsthalf} and \eqref{eq:undatesecondhalf} to all agents synchronously, both persuadable and obdurate. We then reset the partisans' PDFs to their initial forms after applying Eq.\ \eqref{eq:updatefirsthalf} and do so again after applying Eq.\ \eqref{eq:undatesecondhalf}, to ensure that the partisans' beliefs are unchanged by observing the coin toss or interacting with other agents. In our implementation, the network graph is undirected, and the update steps in Eqs.\ \eqref{eq:updatefirsthalf} and \eqref{eq:undatesecondhalf} involve matrix multiplications (see \ref{sec:zoomzoom} for a more detailed discussion). Hence it is simpler to reset beliefs instead of checking for partisanship when applying Eqs.\ \eqref{eq:updatefirsthalf} and \eqref{eq:undatesecondhalf} via matrix multiplication.  Alternatively, one can employ a mask matrix to locate partisans in the network, and multiply by the mask matrix when evaluating Eqs.\ \eqref{eq:updatefirsthalf} and \eqref{eq:undatesecondhalf}, which costs additional space and runtime.  If we extend the model, such that $A$ is no longer symmetric, i.e.\ $A_{ij} \neq A_{ji}$, and use a directed graph to represent the network, partisans can be implemented as nodes with zero out-degree.
\footnote{That is, one sets $A_{i{\rm p}} = 0$ and $A_{{\rm p }i} \neq 0$ for all persuadable agents $i$ who are adjacent to the partisan.}



\subsection{Automaton}
\label{subsec:automaton}

We present a discrete-time automaton in Algorithm \ref{alg:algo} to implement the model in Sections \ref{subsec:modelintro} and \ref{subsec:intropartisans} and show clearly how the numerical simulation is set up and run.

\begin{algorithm}
    \caption{Probabilistic discrete-time automaton for the idealized coin bias application}\label{alg:algo}
    \begin{algorithmic}
        \Inputs {
            network topology $A_{ij}$\\
            \mbox{true coin bias $\theta_0$, partisan coin bias $\theta_{\rm p}$, learning rate $\mu$,
            maximum time-step $T$}
        }
        \Initialize {
            $x_p(t=0, \theta) \gets$ truncated Gaussian with mean $\theta_{\rm p}$, standard deviation $10^{-3}$\\  % 20 if theta in [theta_p - 0.025, theta_p + 0.025]
            \mbox{$x_{i\neq \rm p}(t=0, \theta) \gets$ truncated Gaussian with mean $\in [0, 1]$, standard deviation $\in [0.2, 0.8]$}
        }\\
        \State $t \gets 0$
        \Repeat { (for each time-step $t$)}
            \State Select $S(t) \sim$ Bernoulli $(\theta_0)$ \Comment{Simulate coin toss}
            \State Update beliefs of all agents in response to one coin toss at each time-step (Eq.\ \eqref{eq:updatefirsthalf})
            \State Reset beliefs of partisan agents to $x_p(t=0,\theta)$
            \State Blend beliefs of all agents with network neighbors (Eq.\ \eqref{eq:undatesecondhalf})            
            \State Reset beliefs of partisan agents to $x_p(t=0,\theta)$
            \State $t \gets t + 1$
        \Until{$t = T$}
        % all agents reach asymptotic learning (Eq.\ \eqref{eq:asymlearncondition}), or 
    \end{algorithmic}
\end{algorithm}


% DONE:  start this with a para which introduces the pseudocode and walks the reader through its general structure and key points - this isn't a repetition of the code, rather a guide to help the reader follow it 
The simulation is initialized with values of $\theta_0, \theta_{\rm p}, \mu, T$ and a network topology $A_{ij}$, which determines the number, connectivity, and political allegiances of the agents. The beliefs of persuadable agents are initialized as truncated Gaussian distributions, with randomly chosen mean in the range $[0.0, 1.0]$ and standard deviation in the range $[0.2,0.8]$.  
That is, one obtains $x_{i\neq {\rm p}} (t=0,\theta) \neq x_{j\neq {\rm p}} (t=0,\theta)$ for all $i \neq j$ in general.  We adopt the Gaussian instead of a uniform distribution, because the right-hand side of Eq.\ \eqref{eq:xiprimed} equals zero for uniform distributions, whereupon none of the agents would subsequently change their beliefs, which is not illuminating.
The beliefs of the partisans are initialized as discussed in Section \ref{subsec:intropartisans}.  For the purpose of numerical simulation, the continuous variable $\theta$ is discretized into 21 regularly-spaced values, $\theta \in \{0.00, 0.05, \ldots, 1.00\}$, following Ref.\ \cite{low_discerning_2022,low_vacillating_2022}\footnote{Interestingly, Ref.\ \cite{tee_quantized_2019} finds that the human brain quantizes probability into $\approx 16$ bins, based on observing the in-game decisions and profits of human gamblers. }.
This reflects the practical reality that human beliefs about media bias are coarse-grained.
% Figure environment removed

At each time step in Algorithm \ref{alg:algo}, a coin toss is simulated by a Bernoulli trial with success probability $\theta_0$.  

We are interested in the long-term behavior of the persuadable agents in the system.  For example, does the PDF of a particular persuadable agent tend to a constant function of $\theta$ or does it fluctuate indefinitely, as in the phenomenon of turbulent nonconvergence observed in Ref.\ \cite{low_vacillating_2022,mobilia_role_2007}?  If the belief of an agent remains unchanged within some tolerance (e.g. 1\%) for a user-selected amount of time $\tau_{\rm max}$, viz.\
\begin{equation} \label{eq:asymlearncondition}
    \max_{\theta} |x_i(t+\tau, \theta) - x_i(t, \theta)| < 0.01 \max_{\theta} |x_i(t, \theta)| \quad \text{for } 1 \leq \tau \leq \tau_{\rm max} , 
\end{equation}
then we say that the agent achieves asymptotic learning. If all the agents achieve asymptotic learning, viz.\
\begin{equation} \label{eq:sysasymlearncondition}
    \max_{\theta} |x_i(t+\tau, \theta) - x_i(t, \theta)| < 0.01 \max_{\theta} |x_i(t, \theta)| \quad \text{for } 1 \leq \tau \leq \tau_{\rm max} \text{ and all persuadable } i, 
\end{equation}
then we say that the system achieves asymptotic learning.  In this paper, we take $\tau_{\rm max} = 99$ typically, an arbitrary choice also made in Ref.\ \cite{low_discerning_2022}.  
If Eq.\ \eqref{eq:sysasymlearncondition} holds for $t \geq t_{\rm a}$, we call $t_{\rm a}$ the asymptotic learning time.  
The automaton iterates until the system achieves asymptotic learning, or the maximum run-time $T$ is reached.  
In this paper, we adopt the convention that the partisans are not part of the conditions \eqref{eq:asymlearncondition} and \eqref{eq:sysasymlearncondition} for asymptotic learning; they are obdurate, so they do not learn anything.

We aim to discover
\begin{inparaenum}[(i)]
    \item if partisans change $t_{\rm a}$, or even prevent the system from achieving asymptotic learning at all; and 
    \item if partisans mislead the persuadable agents to infer the bias of the coin incorrectly. 
\end{inparaenum}
Both questions (i) and (ii) have been asked in the context of deterministic models previously \cite{mobilia_does_2003,mobilia_role_2007,yildiz_binary_2013,mobilia_voting_2005,yildiz_discrete_2011,yildiz_opinion_2021,abrahamsson_opinion_2019,galam_role_2007,ghaderi_opinion_2014,klamser_zealotry_2017}, but they are raised here in the context of media bias and Bayesian learners for the first time. 
First, we consider allies-only networks in Section \ref{sec:alliesonly} and investigate how different numbers of partisans disrupt the beliefs of persuadable agents.  
We then investigate how partisans disrupt opponents-only networks in Section \ref{sec:opponentonly}.
Later, in Section \ref{sec:mixed}, we explore networks with both allies and opponents.
% and networks with both allies and opponents in Section \ref{sec:mixed}. 


% partisan setup
% initial belief of persuadables is gaussian
% asymptotic learning
% algorithm (listing) eg: file:///Users/buyutong/Downloads/4221-Article%20Text-7275-1-10-20190705.pdf


\subsection{Mathematical model of networks: complete versus Barab\'{a}si-Albert}
\label{subsec:network}
% Talk about what we used complete and why: 
% \begin{itemize}
%     \item all agents have the same connection to the partisan 
%     \item easy to quantify the impact of the partisan 
%     \item however, not a good representation of the society
% \end{itemize}
% But BA: 
% \begin{itemize}
%     \item more realisitic to the society (cite stuff, check nic's paper)
%     \item not all agaents will have the same connectivity to the partisan 
%     \item some agants are not connected directly, can see if there is an indirect impact
%     \item room for future work, show we have thought about this but not gonna do in this paper 
% \end{itemize}
We use mathematical graphs to model the sociopolitical connections between agents. In this paper we study complete graphs, which ensure that all agents (partisan and persuadable) are connected to each other.   This is not realistic in most actual social contexts, where everybody does not know everybody else.
%  DONE: explain clearly here the technical reason you explained to me before as to why incomplete graphs would cause us major difficulties - this is very important.
However, the central goal of this paper is to quantify how partisans disrupt opinion formation among persuadable agents.  
This is hard to test in a controlled fashion, when the network is partly connected.  
For example, some persuadable agents may connect mostly with partisans, while others may connect mostly with fellow persuadable agents, and the two groups exchange members unpredictably, when partly connected networks are generated randomly.  
In contrast, it is easier to perform controlled tests on a complete network, where everybody knows the same number of partisans or persuadable agents.  
In this paper, we investigate systematically how the connectivity of partisans affects opinion formation by adjusting the fraction of partisans in a complete network in Sections \ref{subsec:dwelltime_and_frac} and \ref{subsec:switching_between_belief}, secure in the knowledge that every persuadable agent knows every partisan in every random realization of the system. 
In future work, we intend to grapple with the challenge of partly connected networks and generalize the results to Barab\'{a}si-Albert networks, for instance, following Low \& Melatos \cite{low_discerning_2022,low_vacillating_2022}.
(Some preliminary simulations involving Barab\'{a}si-Albert networks are presented in Sections \ref{subsec:wrong_conclusion_first} and \ref{sec:BA}.)  
Barab\'{a}si-Albert networks are scale-free; their degree distribution follows a power law, which is a good approximation to many real-world networks \cite{barabasi_emergence_1999,tang_survey_2016,kumar_structure_2016,maniu_building_2011}.
In future work, for example, one can investigate the behavior of persuadable agents indirectly connected to a partisan via a chain of allies and/or opponents, and compare the influence of highly versus sparsely connected partisans.

In the studies by Mobilia \etal on zealotry \cite{mobilia_does_2003,mobilia_voting_2005,mobilia_role_2007,mobilia_nonlinear_2015}, the network is implemented on a $d$-dimensional cubic lattice of size $(2L + 1)^d$, where each agent (voter) is labelled by a vector $r$ with components $-L \leq r_i \leq L$ and $1 \leq i \leq d$. 
% DONE: insert a sentence saying whether or not the Mobilia lattice is complete (and why/why not) and whether it is scale-free (like BA) and why/why not
The lattice model used by Mobilia \etal is not a complete network as each node is only connected to its nearest neighbors.  Nor is it scale-free, as the degree distribution does not follow a power law; the degree of each node is constant and equals $2d$ for a $d$-dimensional cubic lattice.
% In Ref. \cite{vilela_three-state_2020}, Vilela et.\ al.\ extend the voter model by using Barab\'{a}si-Albert model 
The system is evolved by picking a random agent and checking whether or not they are partisans (zealots).  If they are partisans, nothing happens, as a partisan's opinion never changes. If not, the agent adopts the opinion of a random nearest neighbor.
This approach differs from the current paper, where every agent interrogates the PDF of every other agent to whom they are connected at every time step (as well as the public coin toss, of course).


\subsection{Relation to other models}
\label{subsec:relationtoothers}
The model introduced in previous sections is distinct from but related to models in the literature, particularly the DeGroot model \cite{degroot_reaching_1974} and the Deffuant-Weisbuch model \cite{deffuant_mixing_2000}.  
In the Deffuant-Weisbuch model, the adjacency matrix is modified according to  $A_{ij} \neq 0 $ for $|x_j(t) - x_i(t)| < \epsilon$, i.e.\ when the opinions of two agents differ sufficiently, they stop communicating with each other.  In contrast, the model in Section \ref{subsec:modelintro} holds $A_{ij}$ constant in time and therefore neglects the time-dependent ``echo chamber'' or ``silo'' effect captured by the Deffuant-Weisbuch model \cite{deffuant_mixing_2000}.
The belief displacement $\Delta x_i'$ in Eq.\ \eqref{eq:undatesecondhalf} takes inspiration from the DeGroot model, which averages the opinion of an agent's allies. 
The DeGroot and Deffuant-Weisbuch models are deterministic.  
A few models do exist that describe the opinion of an agent as a PDF like in this paper, including \cite{fang_opinion_2020,fang_social_2019,jadbabaie_non-bayesian_2012} for example.  
In particular, Fang \etal's \cite{fang_social_2019} model allows the external signal to be interpreted differently by agents, unlike in this paper, where the external signal is broadcast to and accepted by every agent.
Moreover, Fang \etal \cite{fang_social_2019} implemented a dynamic network, in which $A_{ij}$ depends on $x_i(t,\theta) - x_j(t,\theta)$, whereas $A_{ij}$ is static in this paper.
A more detailed comparison between the model in this paper and others is presented in Section 2.4 in Ref.\ \cite{low_discerning_2022}.  

% deterministic
Most existing work investigating zealots treats the opinions of persuadable agents deterministically, i.e.\ defined by a single number rather than a PDF.  Often, the opinions are also binary, e.g.\ voting for one party or the other. The voter model \cite{liggett_stochastic_nodate,castellano_statistical_2009}, for example, represents the opinion of agents by a discrete spin value ($+1$ or $-1$).  
Some papers about zealots test for the long-term emergence of a consensus, implying general agreement among all agents, whereas the notion of asymptotic learning in Eq.\ \eqref{eq:asymlearncondition} allows agents to believe steadily in a mixture of views, e.g. the $i$-th agent may hold two opinions $\theta_1$ and $\theta_2 \neq \theta_1$ with equal confidence for $\tau_{\rm max}$ consecutive time steps.

We are not aware of any model that considers antagonistic interactions between partisans and agents in the context of the media bias problem involving Bayesian learners. However, extensions of the DeGroot and Deffuant-Weibuch models certainly exist, that consider antagonistic interactions without partisans \cite{vaz_martins_mass_2010,shi_evolution_2016,chen_opinion_2019,he_discrete-time_2021}. The latter papers focus on the divergence of opinion, when antagonism is introduced. 