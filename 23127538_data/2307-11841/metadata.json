{
  "title": "Smart Machine Vision for Universal Spatial Mode Reconstruction",
  "authors": [
    "José D. Huerta-Morales",
    "Chenglong You",
    "Omar S. Magaña-Loaiza",
    "Shi-Hai Dong",
    "Roberto de J. León-Montiel",
    "Mario A. Quiroz-Juárez"
  ],
  "submission_date": "2023-07-21T18:24:38+00:00",
  "revised_dates": [],
  "abstract": "Structured light beams, in particular those carrying orbital angular momentum (OAM), have gained a lot of attention due to their potential for enlarging the transmission capabilities of communication systems. However, the use of OAM-carrying light in communications faces two major problems, namely distortions introduced during propagation in disordered media, such as the atmosphere or optical fibers, and the large divergence that high-order OAM modes experience. While the use of non-orthogonal modes may offer a way to circumvent the divergence of high-order OAM fields, artificial intelligence (AI) algorithms have shown promise for solving the mode-distortion issue. Unfortunately, current AI-based algorithms make use of large-amount data-handling protocols that generally lead to large processing time and high power consumption. Here we show that a low-power, low-cost image sensor can itself act as an artificial neural network that simultaneously detects and reconstructs distorted OAM-carrying beams. We demonstrate the capabilities of our device by reconstructing (with a 95$\\%$ efficiency) individual Vortex, Laguerre-Gaussian (LG) and Bessel modes, as well as hybrid (non-orthogonal) coherent superpositions of such modes. Our work provides a potentially useful basis for the development of low-power-consumption, light-based communication devices.",
  "categories": [
    "physics.optics",
    "quant-ph"
  ],
  "primary_category": "physics.optics",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.11841",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 3015067,
  "size_after_bytes": 127870
}