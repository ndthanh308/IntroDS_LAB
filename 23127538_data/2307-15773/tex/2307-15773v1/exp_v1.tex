
\def\Figref#1{Fig.~\ref{#1}}
\def\Tabref#1{Table~\ref{#1}}


\section{Experimental Results}
In this section, we evaluate \ours on high-dimensional benchmark circuits, which are three SRAM column circuits, with 108, 569, 1093 variation parameters, respectively. 
We set the failure rate of the circuits low at approximately $10^{-5}$ to highlight the challenge of the yield estimation problem.
The ground truth failure rate is obtained by using MC. 
We compare \ours with SOTA IS method, including Mnimized Norm Importance Sampling (MNIS) \cite{MNIS}, Hyperspherical Clustering and Sampling (HSCS) \cite{HSCS}, Adaptive Importance Sampling (AIS) \cite{AIS}, Adaptive Clustering and Sampling (ACS) \cite{ACS}, and surrogate-based methods, including Low-Rank Tensor Approximation (LRTA) \cite{LRTA} and Absolute Shrinkage Deep Kernel learning (ASDK) \cite{ASDK}.
% We assess \ours and other SOTA IS- and surrogate-based yield estimation methods to estimate the failure rate and compare their performance.
% The compared competitors includes Mnimized Norm Importance Sampling (MNIS) \cite{MNIS}, Hyperspherical Clustering and Sampling (HSCS) \cite{HSCS}, Adaptive Importance Sampling (AIS) \cite{AIS}, Adaptive Clustering and Sampling (ACS) \cite{ACS}, Low-Rank Tensor Approximation (LRTA) \cite{LRTA} and Absolute Shrinkage Deep Kernel learning (ASDK) \cite{ASDK}. 
% 
% In this section, we also implement ablation experiments to prove that the proposed pre-sampling method does contribute to the performance.   

In order to determine when to stop the yield estimation algorithm, we choose Figure of Merit (FOM) $\rho= \mathrm{std}(P_f) / P_f$ as the convergence criteria of yield, $\mathrm{std}(P_f)$ is the stand deviation of estimated yield. 
FOM is extensively used in yield estimation methods, \eg \cite{MNIS, HSCS, AMSV}, where $\rho$ is usually set to $0.1$ to indicates a estimation of at least 90\% accurate with 90\% confidence interval.
% to terminated the iteratio
% we stop the process of yield estimation and declare that the estimated $P_f$ is 

\subsection{108-Dimensional SRAM Column Circuit} \label{108dim_exp}
SRAM is a typical type of random-access memory and uses flip-flop to store data. The overall structure of a SRAM column circuit is shown in \Figref{SRAM_column}. As shown in \Figref{SRAM_column}, in a SRAM bit cell circuit, WL is the word line and BL is the bit line, and two cross-connected inventors composed of four transistors are used for storing data, while other two transistors work as control switches for data transmission. Our experiment are implemented on a SRAM column circuit with 108 variation parameters. We choose the delay time of read/write of the SRAM as the output performance metric $\y$ of the circuit. 

We run the yield estimation algorithm on the circuit, and the numerical results are concluded in \Tabref{case3Table}, while the evolution of $P_f$ and $\rho$ during the process of yield estimation is shown in \Figref{case3_exp}. The ground truth of failure rate by the MC method is 5.01e-5, using 699000 runs of simulation. And It can be seen that \ours outperforms all other competitors in terms of estimation accuracy and convergence efficiency of achieving a steady state, exhibiting only a 0.21\% relative error and 131.89x speedup to the MC. 
\ours uses 5300 simulation runs to achieve convergence, while MNIS, HSCS, AIS, ACS, LRTA and ASDK consumes 47500, 26500, 12300, 10400, 13000 and .... simulation runs respectively.   
The $P_f$ of IS-based approaches like MNIS, HSCS, AIS and ACS remains very low at the first half of the evolution, because they don't find enough failure region. When they find correct failure region, a sudden increase in $p_f$ arises and it will finally converges to the MC ground truth result. AIS and ACS render faster convergence than MNIS and HSCS, because ACS and AIS are able to adaptively discover failure regions while searching areas of MNIS and HSCS are pre-fixed. 
The $P_f$ evolution of surrogate-based methods like LRTA and ASDK is majorly determined by the model fitting accuracy to the variation parameter space. With enough training data, $P_f$ of surrogate-based methods converge to the ground truth. 
\ours outperforms all other IS-based competitors because they need a large number of pre-sampling and \ours's novel adaptive scheme speeds up the convergence efficiency.  \ours outperforms all other surrogate-based competitors because surrogate methods need large number of training data to achieve an accurate model due to the ``curse of dimensionality''. 



% Figure environment removed


\begin{table*}
\centering
    \caption{Numerical results on 108-dimensional SRAM column}
    \begin{tabular}{c|c|cccccccc}
      \toprule
       & Results & MC & MNIS & HSCS & AIS & ACS & LRTA & ASDK & Proposed \\
      \midrule
      
      \multirow{4}{*}{Successful runs} 
      & Mean failure prob.   & 5.01e-5 & 4.21e-5 & 4.56e-05 & 4.67e-5 & 5.33e-5  & 4.37e-05 &  & 5.10e-5 \\
      & Mean relative error  & Golden & 16.00\% & 8.90\% & 6.64\% & 6.45\%  & 12.85\% &  & 1.91\% \\
      & Mean \# of sim.      & 699000.00 & 50883.33 & 31340.00 & 15714.29 & 14071.43   & 13440.00  &  & 5300.00 \\
      & Mean speedup & 1x & 13.73x & 22.30x & 44.48x & 49.68x & 52.01x & & 131.89x \\
     \midrule
    
     \multirow{1}{*}{Failed runs} 
      & Failed times & N/A & 4/10 & 4/10 & 3/10 & 3/10 & 5/10 &  & 1/10 \\
    \bottomrule
  \end{tabular}
\end{table*}


% Figure environment removed


\begin{table*}
\centering
    \caption{Numerical results on 569-dimensional SRAM column}
    \begin{tabular}{c|c|cccccccc}
      \toprule
       & Results & MC & MNIS & HSCS & AIS & ACS & LRTA & ASDK & Proposed \\
      \midrule
      
      \multirow{4}{*}{Successful runs} 
      & Mean failure prob.   & 2.50e-5 & 2.34e-5 & 2.68e-5 & 2.31e-5 & 2.69e-5 & 2.29e-5 &  & 2.58e-5\\
      & Mean relative error  & Golden & 6.29\% & 7.13\% & 7.61\% & 7.80\%  & 8.48\% &  & 3.41\% \\
      & Mean \# of sim.      & 931000.00 & 69816.66 & 49975.00 & 28500.00 &  24812.50  & 19430.00  &  & 3600.00 \\
      & Mean speedup & 1x & 13.33x & 18.63x & 32.67x & 37.52x & 47.92x & & 258.61x \\
     \midrule
    
     \multirow{1}{*}{Failed runs} 
      & Failed times & N/A & 4/10 & 2/10 & 3/10 & 2/10 & 5/10 &  & 2/10 \\
    \bottomrule
  \end{tabular}
\end{table*}




\begin{table*}
\centering
    \caption{Numerical results on 1093-dimensional SRAM column}
    \begin{tabular}{c|c|cccccccc}
      \toprule
       & Results & MC & MNIS & HSCS & AIS & ACS & LRTA & ASDK & Proposed \\
      \midrule
      
      \multirow{4}{*}{Successful runs} 
      & Mean failure prob.   & 4.80e-5 & 4.51e-5 & 4.50e-5 & 4.59e-5 & 5.08e-5 & 5.30e-5 &  & 4.84e-5\\
      & Mean relative error  & Golden & 6.09\% & 6.22\% & 4.43\% & 5.91\%  & 10.41\% &  & 0.73\% \\
      & Mean \# of sim.      & 1189000.00 & 88928.57 & 72500.00 & 40557.14  & 35628.57  & 25125.00   &  &  6600.00\\
      & Mean speedup & 1x & 13.37x & 16.40x & 29.32x & 33.37x & 47.32x & & 180.15x \\
     \midrule
    
     \multirow{1}{*}{Failed runs} 
      & Failed times & N/A & 3/10 & 4/10 & 3/10 & 3/10 & 6/10 &  & 2/10 \\
    \bottomrule
  \end{tabular}
\end{table*}


% Figure environment removed



% Figure environment removed


\begin{table}
\centering
    \caption{Ablation experiment of pre-sampling method}
    \label{albation1}
    \begin{tabular}{c|c|c|c|c|c|c}
      \toprule
         &  & Target & \multicolumn{2}{|c|}{Origin method} & \multicolumn{2}{|c}{With ours}\\
       \midrule
        & \# of pre.&  $P_f$  & $P_f$ & \# of IS & $P_f$ & \# of IS\\
      \midrule
              AIS & 1200 & 5.01e-5 & 4.74e-5 & 11100 & 5.31e-5 & 10030\\
            ACS & 1100 & 5.01e-5 & 5.68e-5 & 9300 & 5.45e-5 & 8000\\
    \bottomrule
  \end{tabular}
\end{table}


% 独次最好的结果
\begin{table}
\centering
    \caption{Best numerical results on 108-dimensional SRAM column}
    \label{case3Table}
    \begin{tabular}{c|cccc}
      \toprule
       Method & Failure prob. & Relative error & \# of sim. & Sim. speedup\\
      \midrule
      MC   & 5.01e-5 &   N/A   & 699000 & 1x\\
      MNIS & 4.15e-5 & 17.07\% & 47500 & 14.72x\\
      HSCS & 4.84e-5 & 3.36\% & 26500 & 26.38x\\
      AIS  & 4.75e-5 & 5.21\% & 12300 & 56.83x\\
      ACS  & 5.68e-5 & 13.40\% & 10400 & 67.21x\\
      LRTA & 4.50e-5 & 10.18\% & 13000 & 53.77x\\
      ASDK & e-5 & \% &  & x\\
      Proposed & 5.02e-5 & 0.21\% & 5300 & 131.89x\\
    \bottomrule
  \end{tabular}
  \end{table}

\begin{table}
\centering
    \caption{Best numerical results on 569-dimensional SRAM column}
    \label{case4Table}
    \begin{tabular}{c|cccc}
      \toprule
       Method & Failure prob. & Relative error & \# of sim. & Sim. speedup\\
      \midrule
      MC       & 2.50e-5 &   N/A   & 931000 & 1x\\
      MNIS     & 2.07e-5 & 17.33\% & 59000  & 15.78x\\
      HSCS     & 2.86e-5 & 14.27\% & 46500  & 20.02x\\
      AIS      & 2.38e-5 & 4.99\%  & 25700  & 36.23x\\
      ACS      & 2.73e-5 & 9.19\%  & 22500  & 41.38x\\
      LRTA     & 2.26e-5 & 9.60\%  & 18500  & 50.32x\\
      ASDK     & e-5 & \% &  & x\\
      Proposed & 2.49e-5 & 0.25\% & 3400 & 273.82x\\
    \bottomrule
  \end{tabular}
  \end{table}

\begin{table}
\centering
    \caption{Best numerical results on 1093-dimensional SRAM column}
    \label{case5Table}
    \begin{tabular}{c|cccc}
      \toprule
       Method & Failure prob. & Relative error & \# of sim. & Sim. speedup\\
      \midrule
      MC       & 4.80e-5 &   N/A   & 1189000 & 1x \\
      MNIS     & 4.21e-5 & 12.32\% & 81000 & 14.68x\\
      HSCS     & 4.30e-5 & 10.47\% & 66000 & 18.02x\\
      AIS      & 4.43e-5 & 7.75\% & 38000 & 31.29x\\
      ACS      & 4.42e-5 & 7.83\% & 30400 & 39.11x\\
      LRTA     & 5.25e-5 & 9.38\% & 24000 & 49.54x\\
      ASDK     & e-5 & \% &  & x\\
      Proposed & 4.67e-5 & 2.71\% & 6400 & 185.78x\\
    \bottomrule
  \end{tabular}
  \end{table}


% YF的图
% Figure environment removed

% % Figure environment removed

% % Figure environment removed




















% \begin{table*}
% \centering
%     \caption{Ablation experiment of pre-sampling method}
%     \begin{tabular}{c|c|c|c|c}
%       \toprule
%          & 1 & 2 & 3 & 4  \\
%        \midrule
%         Target density& % Figure removed&  % Figure removed  & % Figure removed & \\
%       \midrule
%               Pre-sampling  & % Figure removed & % Figure removed & % Figure removed &  \\
%        \midrule
%                Nf-sample & % Figure removed & % Figure removed & % Figure removed &  \\
%         \midrule
%                 Flow density
%     \bottomrule
%   \end{tabular}
% \end{table*}



\subsection{569-Dimensional SRAM Column Circuit}

To validate \ours in a more high-dimensional scenario, we further increase the number of SRAM bit cells in the SRAM column, which leads to a SRAM circuit with 569 variation parameters, whose overall structure is also shown in \Figref{SRAM_column}. We continue to choose the delay time of read/write of the SRAM as the output metric $\y$. We run the same yield estimation algorithm on the 569-dimensional circuit. 
The numerical results and detailed $P_f$ evolution are shown in \Tabref{case4Table} and \Figref{case4_exp}. The MC method achieves the ground truth of failure rate 2.50e-5 using 931000 simulations. 
As shown in \Figref{case4_exp}, only after long importance sampling, are other IS-based methods able to discover the correct failure regions and their $P_f$ increases to the peak. In contrast, due to the powerful proposed pre-sampling approach, \ours discovers the correct failure regions and its $P_f$ achieves the peak right after the pre-sampling state, and it converges to the ground truth rapidly. 
\ours achieves a fail rate of 2.49e-5 using 3400 simulations, exhibiting a relative error of 0.25\%, which outperforms others in terms of accuracy and efficiency. In comparison, MNIS, HSCS, AIS, ACS, LRTA and ASDK uses 59000, 46500, 25700, 22500, 18500 and ... simulations respectively to achieve a fail rate with the larger relative error. Compared with MNIS, \ours can achieve a up to 17.35x more accurate and 69.32x speedup. 

\subsection{1093-Dimensional SRAM Column Circuit}

We further increase the dimensions of the circuit by adding more bit cells to the SRAM column, which leads to a even more challenging SRAM column circuit with 1093 variation parameters, and no former researcher implements yield estimation experiment on such a high-dimensional setting. We choose the delay time of read/write of SRAM as the circuit output metric $\y$. We run 118900 simulations using the MC method and obtain the ground truth of failure rate, 4.80e-5. 
The total experimental numerical results and detailed process are illustrated in \Tabref{case5Table} and \Figref{case5_exp}. 

It can be obviously concluded that \ours is still able to get the failure rate with highest accuracy and efficiency among other 6 methods, which uses merely 6400 runs of simulation and exhibits a estimated result with a 2.71\% relative error. Our method finds the correct failure region after one round of importance sampling, while other IS-based methods takes many rounds. The surrogate methods converge slower than \ours because they need a large number of training data.
In comparison with MNIS, \ours can reach a up to 12.66x speedup and is 4.55x more accurate.


\subsection{Ablation Study}
In this section, we also implement ablation experiments to prove that the proposed pre-sampling method does contribute to the performance.   


To verify the proposed pre-sampling method's contribution to the performance of \ours, we conduct the ablation experiment on the 108-dimensional SRAM column circuit. 
ACS and AIS use the same pre-sampling algorithm, named hyperspherical pre-sampling, which draws samples on hyperspheres with increasing radius in the variation parameter space. We replace AIS and ACS's pre-sampling method with our proposed method, and implements the modified AIS and ACS on the circuit. The circuit setup is as the same as that of the Section \ref{108dim_exp}.
To evaluate the method fairly, the modified pre-sampling procedure are fixed to run as the same number of simulation as that of the origin pre-sampling procedure.
The real failure probability of the circuit is set as 5.01e-5. 
The result comparison of origin and modified algorithms is shown in \Tabref{albation1}. We can clearly see that, using hyperspherical pre-sampling AIS and ACS run 11100 and 9300 simulations to achieve the fail rate of 4.74e-5 and 5.68e-5 respectively, and that, using our proposed pre-sampling method AIS and ACS run 10030 and 8000 to achieve the fail rate of 5.31e-5 and 5.45e-5 respectively. It can be concluded that the proposed pre-sampling method does help discover promising failure regions and accelerate the speed of convergence of fail probability.



