
\begin{table}[t]
\small
\setlength\tabcolsep{3.3pt}
\begin{tabular}{l|ccccc}
\rowcolor[gray]{.9}
\hline
Method     & Param. & \begin{tabular}[c]{@{}c@{}}Inference \\ Time\end{tabular} & \begin{tabular}[c]{@{}c@{}}Inference \\ Mem.\end{tabular}   & \begin{tabular}[c]{@{}c@{}}Training \\ Mem.\end{tabular} & PSNR  \\ \hline \hline
NHP~\cite{kwon2021nhp}        & \textbf{5.80M}  & 1h55min                                                   & 6.4GB                                                       & 12.2GB              & 24.94                                     \\
GP-NeRF~\cite{chen2022gpnerf}    & 9.52M  & \textbf{9min}                                                      & 10.3GB                                                      & 11.0GB                & 24.55                                   \\ 
\textbf{Ours-16pts} & 6.08M  & \textbf{9min}                                                      & \textbf{5.7GB}                                                      & \textbf{7.8GB}     & \textbf{25.39}    \\ \hline    \hline

Ours       & 6.08M  & 17min                                                     & 6.2GB                                                     & 7.8GB              & 26.15                                      \\ \hline
                                       
\end{tabular}
% \vspace{+1mm}
 \caption{
     \textbf{Efficiency comparisons under the identity generalization setting.} With the same inference time, our method outperforms GP-NeRF~\cite{chen2022gpnerf} significantly in PSNR albeit requiring fewer parameters and training/inference memory. The performance can further be greatly improved at the cost of certain additional inference time and minor inference memory. }
    \label{tab:efficiency}
    \vspace{-2mm}
\end{table}