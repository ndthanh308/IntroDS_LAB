%&latex
\section{Related Work}


\subsection{Human Performance Capture}
\vspace{-2mm}
Synthesizing novel views for human performer is a long-standing topic in computer vision and graphics.  Traditional methods~\cite{HumanRender_convention_dou2016fusion4d,HumanRender_convention_collet2015high,HumanRender_convention_depthsensors_guo2019relightables,HumanRender_convention_depthsensors_debevec2000acquiring} typically require expensive hardware like depth sensors for getting reasonable results. With the recent success of Neural Radiance Fields (NeRF)~\cite{mildenhall2021nerf,barron2021mip}, many works~\cite{peng2021neural,peng2021animatable,weng2022humannerf,te2022NeuralCapture} have attempted to learn the 3D human representation from image inputs via differentiable rendering.
% , together with the pre-fitted parametric human models (\eg, SMPL~\cite{loper2015smpl}) for handling the highly dynamic motion of human performers. 
However, they require tedious per-subject optimization on dense training images, and can not generalize to unseen subjects, which largely confines the real-world applications. 

To tackle this issue and inspired by the recent advances of generalizable NeRF methods~\cite{yu2021pixelnerf,mvsnerf,wang2021ibrnet}, the generalizable neural human rendering task is explored~\cite{kwon2021nhp,MPSNERF,chen2022gpnerf,zhao2022humannerf}, 
% which learns conditional NeRF for capturing the general 3D human prior across multiple multi-view videos of human performers, and can generalize to new subjects by a single feed-forward pass  given very sparse reference views as input. 
% introduce human reprentation 
At the core of this task is to properly exploit the human prior from the pre-fitted parametric human model. 
% (i) \textit{Deformation-based.} 
% One line of works~\cite{zhao2022humannerf,MPSNERF}  take the parametric human model as the medium of the deformation between observation and canonical spaces, using blend skinning technology~\cite{LBS_huang2020arch,LBS_lewis2000pose,LBS_liu2021neural}, and optimize conditional NeRF under a canonical pose. 
One line of works~\cite{zhao2022humannerf,MPSNERF}  take the parametric human model as the medium of the deformation between observation and canonical spaces using blend skinning technology~\cite{LBS_huang2020arch,LBS_lewis2000pose,LBS_liu2021neural}, and optimize conditional NeRF under a canonical pose. 
% . And optimize NeRF under a canonical pose. 
% However, such paradigm tends to miss the observation-specific properties like wrinkles and lighting. 
% (ii) \textit{Diffusion-based.} 
Instead, another line of works~\cite{kwon2021nhp,chen2022gpnerf} directly diffuse the painted parametric human model under the observation space via SparseConveNet (SPC)~\cite{liu2015sparse} for a human representation with approximate priors, and the final condition feature for a query point is the hybrid of human representation and pixel-aligned features. Obviously, a high-quality human representation is critical in this paradigm, yet the SPC-based one optimizes under the varying observation space, lacks the global perspective, and is restricted by the trilinear sampling in discrete 3D volumes. 

Targeting these issues, we present TransHuman with an advanced human representation based on transformers~\cite{vaswani2017attention,touvron2021DeiT,dosovitskiy2020ViT}, and outperforms the previous state-of-the-art methods by significant margins. 


\subsection{Transformers with Neural Radiance Fields}
\vspace{-2mm}
% With the significant advances of the transformer architecture in natural language processing~\cite{devlin2018bert}, computer vision~\cite{dosovitskiy2020ViT,caron2021DINO,pan2022ino,yang2021AOT}, and multimodality tasks~\cite{radford2021CLIP,zhu2020actbert},
With the significant advances of the transformer architecture~\cite{devlin2018bert,dosovitskiy2020ViT,caron2021DINO,radford2021CLIP},
several works~\cite{lin2023visionnerf,johari2022geonerf,reizenstein2021common,wang2021ibrnet,jain2021putting,xu2022sinnerf} have attempted to introduce it with NeRF technology. Specifically,  \cite{lin2023visionnerf} combines transformers with CNN~\cite{he2016Resnet} as a stronger feature extractor for reference images, \cite{johari2022geonerf,reizenstein2021common,wang2021ibrnet} use transformers as the aggregator of source view features, and 
\cite{jain2021putting,xu2022sinnerf} introduce the pre-trained transformers~\cite{radford2021CLIP,caron2021DINO} as a semantic prior to relieve the dense requirement of training views. 




Differently, in this paper, we make the first attempt to apply the transformer technology around the surface of painted SMPL for a stronger human representation that captures the global relationship between human parts. 

% Previous 3D reconstruction methods mainly  the transformers with NeRF technology is less explored. 