%&latex
\section{Introduction}
% background 
Rendering free-viewpoint videos of dynamic human performers in high fidelity is vital for many applications such as  mixed reality, gaming, and telepresence. Recent works~\cite{peng2021neural,peng2021animatable,weng2022humannerf,te2022NeuralCapture} integrate the Neural Radiance Fields (NeRF)~\cite{mildenhall2021nerf} technology with parametric human prior models (\eg, SMPL~\cite{loper2015smpl}) for handling the dynamic human body and achieve fair novel view synthesis results. However, the tedious per-subject optimization and the requirement of dense training views largely hinder the application of such methods. Targeting these issues and inspired by the recent success of generalizable NeRF~\cite{yu2021pixelnerf,mvsnerf,wang2021ibrnet} on static scenes, the task of generalizable neural human rendering is proposed~\cite{kwon2021nhp}, which trains conditional NeRF across multi-view human videos, and can generalize to a new subject in a single feed-forward manner given sparse reference views as input. 

\input{./Figures/idea_illustration}

% the drawbacks of previous methos 
Previous methods for generalizable neural human rendering~\cite{chen2022gpnerf,kwon2021nhp} mainly employ the SparseConvNet (SPC)~\cite{liu2015sparse}-based  human representation (upper row of Fig. ~\ref{fig_idea}) which first project deep features from reference images onto the vertices of fitted SMPL and then diffuse them to nearby regions via SPC. The final representation is achieved via the trilinear sampling  in the discrete 3D feature volume. Such SPC-based representation mainly suffers from the following two aspects: (i) \textit{Volatile observation learning.} The SPC-based one optimizes under the observation space that contains varying poses. This leads to the pose misalignment during training and inference stages, and therefore limits the generalization ability. 
(ii) \textit{Limited local receptive fields.} 
As shown in Fig.~\ref{fig_idea}, due to the heavy self-occlusion of dynamic human bodies, the painted SMPL templates are usually incomplete. While, as a 3D convolution network, the limited local receptive fields of SPC make it sensitive to the incomplete input, especially when the occluded regions are large. 

% To address the aforementioned issues, 
To address the aforementioned issues, we propose to first process the painted SMPL with transformers under the \textit{static canonical space} to remove the pose misalignment between training and inference stages and capture the \textit{global relationships} between human parts. Then, a deformation from the canonical to the observation space is required to fetch the human representation of a query point (sampling points on rays) under the observation space. Finally, the fine-grained information directly achieved from the observation space should be further included to the coarse human representation to complement the details. 

% To address the aforementioned issues, we propose that processing the painted SMPL under the \textit{static canonical space} can remove the pose misalignment between training and inference stages, and the processed SMPL can be deformed back to the observation space for further diffusion. Also, the transformers~\cite{dosovitskiy2020ViT} is a good choice for capturing the \textit{global relationships} between human parts. 
% Finally, the fine-grained information directly achieved from the observation space should be further included to the coarse human representation to complement for the details. 


Motivated by this, we present the TransHuman, a brand-new framework that shows superior generalization ability with high efficiency. 
% , as shown by the lower part of Fig.~\ref{fig_idea}. 
% that optimizes under the \textit{canonical} space and processes the painted SMPL in a \textit{global} and \textit{continuous} manner, 
TransHuman is mainly composed of Transformer-based Human Encoding (TransHE), Deformable Partial Radiance Fields (DPaRF), and Fine-grained Detail Integration (FDI). (i) \textit{TransHE.} TransHE is a pipeline that processes the painted SMPL under the canonical space with transformers~\cite{dosovitskiy2020ViT}. The core of this pipeline includes a canonical body grouping strategy for the avoidance of semantic ambiguity, and a canonical learning scheme to ease the learning of global relationships. 
(ii) \textit{DPaRF.} DPaRF deforms the output tokens of TransHE from the canonical space to the observation space and gets a robust human representation for a query point from marched rays. As shown in Fig. \ref{fig_idea}, the main idea is to bind each token (representing a certain human part) with a radiance field whose partial coordinate system deforms as the pose changes, and the query point is encoded via the coordinates under the deformed partial coordinate systems.
(iii) \textit{FDI.} With TransHE and DPaRF, the human representation contains coarse information with human priors yet limited fine-grained details directly captured from the observation space. Therefore, similar to ~\cite{kwon2021nhp}, we propose to further integrate the detailed information from the pixel-aligned features at the guidance of the human representation. 


% Experiment and Summarization
Extensive experiments on ZJU-MoCap~\cite{peng2021neural} and H36M~\cite{ionescu2013human36m} demonstrate the superior generalization ability and high efficiency of TransHuman which attains a new state-of-the-art performance and outperforms previous methods by significant margins, \eg, $+2.20$ PSNR and $-45\%$ LPIPS on ZJU-MoCap~\cite{peng2021neural}  under the pose generalization setting. 

% that our TransHuman is both effective and efficient which outperforms previous methods by significant margins. 

% the superior generalization ability of TransHuman which outperforms previous methods by significant margins with high efficiency. 
% attains a new state-of-the-art performance .

Our contributions are summarized as follows:
\begin{itemize}
    \item We propose a brand-new framework TransHuman for the challenging generalizable neural human rendering task which attains a significantly new state-of-the-art performance with high efficiency.
    % which optimizes under the static canonical space and encodes the human representation in a global and continuous manner.  
    % \item To the best of our knowledge, we make the first attempt to explore the transformer technology around the painted SMPL. 
    % \item We attain a significantly new state-of-the-art performance with high efficiency.

    % $TransHE,DPaRF$
    \item We propose to process the painted SMPL under the canonical space to remove the pose misalignment during training and inference  stages and deform it back to the observation space via DPaRF for robust query point encoding. 
    
    \item To the best of our knowledge, we make the first attempt to explore the transformers technology around the painted SMPL for capturing the global relationships between human parts. 

    

    % \item We propose a brand-new framework TransHuman for the challenging generalizable neural human rendering task which attains a significantly new state-of-the-art performance with high efficiency.

    % \item We propose the TransHE that optimizes the 
    % % encodes the human representation in a global and continuous manner

    % \item To the best of our knowledge, we make the first attempt to explore the transformer technology around the surface of the parametric human body. 
    
\end{itemize}

% TODO: include the discussion about generalization ability 
% SPC learns the painted SMPL on observation space, which contains infinite poses, therefore . 
% While our TransHuman learns on the canonical space, and deform to obs space for application, the final continuous encoding is non-parametric. Therefore shows better generalizable ability.  

%%%%%%%%%%%%%%%%%%
\input{./Figures/overview}