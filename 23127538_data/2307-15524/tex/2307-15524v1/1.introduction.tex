\section{Introduction}

Extensively studied in the literature, image classification can be accurately performed by Deep Neural Network (DNN) models provided that there are sufficient labeled training data~\cite{schmarje2021survey,2021Fair}. Unfortunately, in many application scenarios (e.g., medical image analysis~\cite{2021Interactive} and autonomous driving~\cite{yu2020rein}), large amounts of labeled images may not be readily available because data acquisition and annotation needs to involve intensive manual effort. Under these circumstances, DNN models can easily overfit and fail to achieve satisfactory performance. To address this limitation, \textit{few-shot image classification} has been proposed to classify unseen classes with only a few labeled samples~\cite{2020Generalizing,2022A}.

The existing approaches for few-shot image classification can be broadly categorized into two groups: \textit{inductive few-shot learning} and \textit{transductive few-shot learning}. Inductive learning typically trains a generic model based on the labeled samples in training classes, and then directly uses the learnt model to classify each unlabeled sample in test classes independently from each other~\cite{0Siamese,2016Matching,2017Prototypical,sung2018learning,ravi2017optimization,2017Model}. In contrast, supposing that it has the access to both labeled and unlabeled samples in test classes,  transductive learning performs class label inference jointly for all the unlabeled samples.
	
% Figure environment removed

It can be observed that the core challenge of few-shot image classification is to transfer the knowledge learned on training classes with sufficient labeled samples to new classes with only a few labeled samples. Due to distribution drift between classes, the existing deep learning solutions, whether inductive or transductive, whose efficacy depends on the i.i.d (Independently and Identically Distributed) assumption, have so far achieved only limited success. Compared with inductive learning, transductive learning usually performs better because it can leverage additional sample relationships to fine-tune the distributions of unseen classes. However, it still aims to learn a unified global model for new class prediction. As a result, its efficacy is similarly constrained by scarcity of label observations on new classes.  


%(e.g., ResNet\cite{2016Deep}, VGG\cite{simonyan2014very}, D2-Net\cite{dusmanu2019d2})

  To alleviate such limitation, this paper proposes a novel approach for few-shot image classification based on the non-i.i.d paradigm of Gradual Machine Learning (GML). GML was first proposed for the task of entity resolution~\cite{hou2019gradual,HouTKDE,zhong2021attention}, but then also applied to sentiment analysis~\cite{2020Aspect,ahmed2021dnn,wang2023supervised}. Inspired by the nature of human learning, GML begins with some labeled samples, and then gradually classifies unlabeled samples in the increasing order of hardness by iterative knowledge conveyance. Technically, GML fulfills gradual learning by iterative factor inference in a factor graph. It is noteworthy that	instead of learning a unified global classifier, GML gradually classifies one sample at a time by factor inference based on its own evidential certainty.  
	
	
We have sketched the structure of factor graph for few-shot image classification in Figure.~\ref{fig:model structure}. As shown in the figure, the labeled samples in the support set and the unlabeled samples in the query set are modeled as labeled and unlabeled variables respectively in the factor graph. The labeled samples serve as initial evidential observations, while the unlabeled samples are supposed to be gradually classified by iterative factor inference. In GML, the efficacy of gradual inference depends on effective feature mechanisms for knowledge conveyance. Due to the big advances of deep neural networks for image classification, DNNs are considerably more effective at discriminative feature extraction compared with traditional approaches~\cite{afrasiyabi2022matching,zhao2022self}. Therefore, we leverage the existing deep neural backbones for few-shot image classification to extract discriminative image features, and then model them as factors in a factor graph to facilitate knowledge conveyance. Specifically, we generate vector representations for images in a deep class-sensitive embedding space, and then extract their discriminative features based on the monotonous metrics of class centroid distance and k-nearest neighborhood. Intuitively, the closer to a class centroid an image is, the more likely it belongs to the class. Similarly, the more same-class nearest neighbors an image has, the more likely it belongs to the same class. 
	
	%{\color{blue}We use the class centroid distance(\emph{CCD}) as unary features and K-nearest Neighborhood(\emph{KNN}) as binary features.} 
	
  To construct diverse mechanisms for knowledge conveyance, our solution uses different deep backbones to generate separate embedding spaces. Our algorithm leverages ResNet-12~\cite{2016Deep} and WRN-28-10~\cite{2016Wide}, both of which are popular backbones for few-shot image classification, for feature extraction. It is noteworthy that even though the WRN-28-10 network is constructed based on ResNet-12, it has considerably wider residual blocks, and thus more advanced representational capabilities. Our experiments have shown that the ResNet-12 and WRN-28-10 networks are to some extent complementary to each other. As a result, leveraging both of them for gradual inference can effectively improve few-shot classification accuracy. 

Since our proposed solution reasons about the labels of test samples in a joint manner, it can be generally considered as an approach of transductive learning. The main contributions of this paper can be summarized as follows:

  \begin{itemize}
  \item We propose a novel approach for few-shot image classification based on the non-i.i.d paradigm of GML, which can gradually classify unlabeled samples in the increasing order of hardness given only a few initial labeled samples. The proposed approach can be potentially generalized to other few-shot classification tasks. 
    
  \item We present a factor graph model consisting of both unary and binary monotonous factors, which can be easily extracted by the existing deep backbones, to enable gradual learning for few-shot image classification. 
  
  \item We empirically validate the performance of the proposed approach on real benchmark datasets by a comparative study. Our extensive experiments show that it improves the SOTA performance on few-shot image classification by considerable margins (2-5\%). Furthermore, the GML solution is more robust than the existing deep learning solutions, in that its performance can consistently improve as the size of query set increases while the performance of its deep learning alternatives remains essentially flat or even becomes worse.
  
  \end{itemize}
  
  %By using image classification as an illustrative example, this paper demonstrates the efficacy and potential of GML for few-shot learning. 
	
	The rest of this paper is organized as follows: Section~\ref{sec:related work} reviews related work. Section~\ref{sec:Task Statement} defines the task. Section~\ref{sec:The GML Framework} presents the GML framework for few-shot image classification. Section~\ref{sec:Factor Graph Construction} details factor graph construction. Section~\ref{sec:experiments} presents our empirical evaluation results. Finally, Section~\ref{sec:Conclusion} concludes the paper with some thoughts on future work.
	