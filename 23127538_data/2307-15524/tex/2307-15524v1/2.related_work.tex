\section{Related Work}\label{sec:related work}



%Due to high cost of data labeling and annotation in real applications, few-shot learning has been attracting extensive attention in the machine learning community~\cite{fei2006one,lake2013one,tang2010optimizing,munkhdalai2018rapid}. 

%Extensively studied in the literature, most few-shot learning solutions have been constructed based on the meta-learning paradigm~\cite{rusu2018meta,chen2021meta}. The goal is to learn a model that can effectively adapt to new classes given only a few labeled samples~\cite{2017Prototypical,hospedales2021meta,parnami2022learning}. 

In this section, we review related work from the orthogonal perspectives of few-shot image classification and gradual machine learning.

%It is usually achieved by training a parameterized mapping that connects a small number of training instances to model parameters in simulated one-shot learning scenarios~\cite{2017Prototypical,hospedales2021meta,parnami2022learning}. In the rest of this section, we review related work from the orthogonal perspectives of few-shot image classification and gradual machine learning.


\subsection{Few-shot Image Classification}

The existing work for few-shot image classification can be broadly categorized into two groups: inductive learning and transductive learning.


\textbf{Inductive Learning.}
% meta learning
The approach of inductive learning typically trains a neural model by labeled training samples, and then uses the learnt model to separately classifies each unlabeled sample in test classes. It focuses on learning high-quality and transferable features with a CNN backbone. The most commonly used backbones include ResNet-12~\cite{bendou2022easy,zhang2020deepemd,afrasiyabi2022matching,wertheimer2021few}, ResNet-18~\cite{2016Matching,2017Prototypical,sung2018learning,chen2019closer}, and WRN-28-10~\cite{zhu2022ease,hu2022squeezing,hu2021leveraging}. Based on these backbone models, some researchers proposed to further tune the mechanism of feature extraction for improved classification accuracy. For instance, Afeasiyabi et al. proposed to enrich image representations by embedding self-attention mappers in different convolutional layers~\cite{afrasiyabi2022matching}. Zhao et al. designed a structure of Self-Guided Information Convolution (SGI-Conv) to guide the extraction of discriminative features~\cite{zhao2022self}. 

Few-shot classifier training is usually conducted by metric-based learning~\cite{jiang2020multi}, which aims to learn a similarity classifier over a feature space. First, it randomly samples labeled training samples and divides them into support and query sets, thereby constructing multiple different episodes. Then, it uses mini-batches of episodes to train an end-to-end network, assuming that the resulting features will be representative of novel test classes. For instance, Vinyals et al. proposed a matching network to learn embedding~\cite{2016Matching}, whereas Snell et al. proposed a prototypical network to build a pre-class prototype representation~\cite{2017Prototypical}. Sung et al. also presented a relation network, which can learn a non-linear distance metric via a simple neural network instead of using a fixed linear distance metric~\cite{sung2018learning}. 

Transfer learning has also been extensively leveraged for few-shot classifier training~\cite{pan2009survey}. It typically follows a standard two-phase process consisting of pre-training and fine-tuning. In the pre-training phase, it learns transferable knowledge or experience, usually in the form of feature extractors, on base classes that contain ample labeled instances. In the subsequent fine-tuning phase, it usually freezes the learned feature extractors, and trains a new classifier on the support set to recognize novel classes~\cite{verma2019manifold,mangla2020charting}. Many solutions for few-shot image classification have incorporated the concept of transfer learning in their architecture design, including baseline++\cite{chen2019closer}, SimpleShot\cite{wang2019simpleshot}, RFS\cite{tian2020rethinking} and S2M2\cite{mangla2020charting}.

\textbf{Transductive Learning.}
 Transductive learning usually shares the process of backbone training with inductive learning. However, in the test phase, instead of classifying each unlabeled sample separately, it labels unlabeled samples in a collective manner, aiming to exploit sample relationships for improved performance~\cite{hu2021leveraging,zhu2022ease,bendou2022easy,hu2022squeezing}. 

%Recent work has shown that compared inductive learning, transductive learning can effectively improve classification accuracy. 

  %To facilitate class information propagation, 
	
	%On the graph, classification of unlabeled samples can be performed by the simple nearest-neighbor algorithm. 
	
	%The proposed solution iteratively updated label information based on the dual-graph structure to fulfill class information propagation. 
	
	To facilitate class information propagation, transductive learning typically leverages both support sets and query sets to construct matrics for sample relationship representation. For instance, Kim et al. proposed to construct a graph, where nodes represented samples and edges represented relationships between samples~\cite{kim2019edge}. Yang et al. instead introduced a dual-graph structure for sample relationship representation~\cite{yang2020dpgn}, in which dual graphs were separately constructed based on two similarity relations. To improve intra-class coherence and uniqueness, the approach of TRPN regarded each support-query pair relationship as a graph node, named the relationship node, and leveraged the known relationships between support samples to guide relationship propagation in the graph~\cite{ma2020transductive}.  Various graph neural networks have also been used for label propagation. For instance, Zhu et al. presented a graph construction network to predict the task-specific graph for label propagation~\cite{zhu2023transductive}. Liu et al. argued that there exists a bias between the prototype representations and the expected representations, and provided a simple strategy to rectify the bias based on intra-class and inter-class assumptions~\cite{liu2020prototype}.


  More recently, the Sinkhorn-based approach has achieved promising results on image classification. Its main idea was to  model class information propagation as a transportation optimization problem~\cite{chobola2021transfer,hu2021leveraging}. Huang et al. first proposed the Sinkhorn K-means~\cite{huang2019few}, which used a prototype for query image classification in an unsupervised manner, whereas zhu at al. extended it to the semi-supervised setting~\cite{zhu2022ease}. To balance data distribution between classes, Hu et al. preprocessed feature vectors such that they conform to a Gaussian distribution. In the following work, they successively presented the MAP~\cite{hu2021leveraging} and Boosted Min-Size Sinkhorn algorithm~\cite{hu2022squeezing} to improve propagation efficiency. Similarly, Shalam and bendou et al. proposed the metric of Earth Mover's distance to capture high-level relationships among data points within classes, further optimizing Sinkhorn-based information propagation~\cite{shalam2022self,bendou2022easy}. 

 
 % There are also some orthogonal work on semi-supervised few-shot learning, which aims to leverage additional unlabeled samples besides the provided support set in novel test classes. For instance, Guo et al. leveraged self-labeling and soft-attention mechanisms on unlabeled samples for classifier fine-tuning~\cite{guo2020broader}. Similarly, Ren et al. proposed to update the class prototypes using K-means iterations initialized by the PN prototypes~\cite{ren2018meta}. Simon et al. used unlabeled examples through the soft-label propagation~\cite{simon2020adaptive}. Saito et al. studied the problem of semi-supervised few-shot domain adaptation~\cite{saito2019semi}.  
  

  \subsection{Gradual Machine Learning}

  The non-i.i.d learning paradigm of Gradual Machine Learning (GML) was originally proposed for the task of entity resolution~\cite{hou2019gradual,HouTKDE,zhong2021attention}. It can gradually label instances in the order of increasing hardness without the requirement for manual labeling effort. Since then, GML has been also applied to the task of sentiment analysis~\cite{wang2021aspect,ahmed2021dnn,wang2023supervised}. In the unsupervised setting, even though GML can achieve competitive performance compared with many supervised approaches, its performance is still limited by inaccurate and insufficient knowledge conveyance~\cite{hou2019gradual,HouTKDE,ahmed2021dnn}. In the supervised setting, the efficacy of GML depends on supervised extraction of features by DNNs; its performance may deteriorate significantly if the provided labeled samples are insufficient. Our work in this paper is different from previous GML work in two aspects: 1) it targets the new task of image classification; 2) it investigates the efficacy of GML in the few-shot setting, where only a few labeled samples are available. It can be observed that our proposed solution leverages the existing deep backbones for feature extraction, but uses gradual learning as the new inference engine. Therefore, it can be generally considered as an approach of transductive learning.    