\section{The GML Framework}\label{sec:The GML Framework}

As shown in Figure~\ref{fig:model structure}, consistent with the general paradigm, the GML framework for few-shot image classification consists of the following three components:

\iffalse
% Figure environment removed
\fi


\subsection{Evidential Instance Labeling}

%given a classification workload, accurately labeling all the instances in the workload by the machine is usually very challenging. However, the task usually becomes much easier if the machine only needs to label some easy instances in the workload. In practical applications, 

       GML begins with some initial evidential observations. In the unsupervised setting, initial instance labeling can be achieved by human-crafted rules or unsupervised clustering. For instance, an instance very close to a class centroid usually has a high chance of belonging to the class. Few-shot image classification supposes that the support sets contain some labeled sample images (e.g., 5 images per class for 5-shot learning). Therefore, these labeled images can naturally serve as initial evidential samples, even though their number is very limited. In the case of 5-shot learning, the labeled samples in support sets are considered as initial evidential observations. In the case of 1-shot learning, we expand the set of initial evidential observations by automatically labeling one additional sample per class. Specifically, for each class, GML automatically labels the unlabeled sample image closest to the class centroid. As a result, for 1-shot learning, GML actually begins with 2 evidential observations per class.     
				
			% given a set of initial seeds, GML iteratively labels each unlabeled image. After the algorithm converges, 
\subsection{Feature Extraction and Influence Modeling}
    
		In GML, features serve as the medium for gradual learning. This step extracts the common features shared by the labeled and unlabeled samples. To facilitate extensive knowledge conveyance, it is desirable that a wide variety of features are extracted to capture diverse information. For each extracted feature, this step also needs to model its influence over the class labels of relevant samples.
		
		For image classification, CNN has been shown to be much more effective at extracting discriminative features than previous alternatives (e.g., manually crafted mechanisms). Therefore, our solution leverages CNN backbones to extract implicit image features that are indicative of class status. Specifically, it transforms images into high-dimensional vector representations in an embedding space by a CNN, and then uses the monotonic metrics, e.g., class centroid distance and k-nearest neighborhood, to extract discriminative features. It can be observed that the closer to a class centroid an image is, the more likely it belongs to the class; similarly, the more same-class nearest neighbors an image has, the more likely it belongs to the same class. 
		
% Figure environment removed

		As in previous work, we model a feature's influence over images' class status by a monotonous Sigmoid function. As shown in Figure~\ref{fig:sigmoid}, a sigmoid function has two parameters, $\alpha$ and $\tau$, which denote the midpoint and steepness of the curve respectively. Formally, given a class label, $c$, and its feature, $f_c$, the influence of $f_c$ over the class status of an image, $d$, is represented by
\begin{equation}
\label{eq:sigmoid}
  P_{f_c}(d) = \frac{1}{{1 + {e^{ - {\tau _{f_c}}(x_{f_c}(d) - {\alpha _{f_c}})}}}},
\end{equation}

in which $P_{f_c}(d)$ denotes the probability of $d$ having the label of $c$ as indicated by $f_c$, $x_{f_c}(d)$ represents $d$'s feature value w.r.t $f_c$. According to Eq.~\ref{eq:sigmoid}, provided with the values of $\alpha_{f_c}$ and $\tau_{f_c}$, the influence model statistically dictates that any feature value of $x_{f_c}(d)$ corresponds to a label probability. As shown in Figure~\ref{fig:sigmoid}, different combinations of $\alpha_{f_c}$ and $\tau_{f_c}$ can result in different influence model shapes. Typically, the value of $P_{f_c}(d)$ increases with the feature value of $x_{f_c}(d)$.



		
		 %Specifically, for each feature, GML models its influence over pair labels by a monotonous

		
		%This step also needs to model the extracted features as factors in a factor graph, and quantify their influence over relevant instances. 
		  
		%Extracting classification features and building factor graphs to transfer knowledge from easy to difficult cases. By obtaining shared features between labeled and unlabeled samples, the acquired features possess knowledge sharing and transferability. Affect modeling is conducted based on the obtained features and their corresponding instance labels.
		
		

\subsection{Gradual Inference}
    
		
		GML fulfills gradual learning by iterative factor inference on a factor graph, $G$, which consists of a set of evidence variables, a set of inference variables, and a set of factors. For few-shot image classification, an evidence variable represents a labeled image in the support set, an inference variable represents an unlabeled image in the query set, and a factor represents the correlation between images. Typically, GML labels only one image at each iteration. Once an inference variable is labeled, its value remains unchanged and would serve as an evidence variable in the following iterations. 

\iffalse		
{\color{red} The process is shown in Figure~\ref{fig:gradual structure}.}

% Figure environment removed
\fi
        
    Formally, we denote the set of evidence variables by ${\bf{\Lambda}}$, the set of inference variables by $\bf{V_I}$, and the group of factor functions of variables indicating their correlations by ${\phi_{w_i}}(V_i)$. In the case of few-shot image classification, each variable in the factor graph is supposed to take one of several distinct values, each of which corresponds to a class label. 
Then, the joint probability distribution over $V=\{\Lambda, V_I\}$ of $G$ can be formulated as 
	\begin{equation}
		\label{eq:joint_prob}
		\begin{split}
			P_{\bf{w}}(\Lambda, V_I)=&\frac{1}{Z_{\bf{w}}}\prod_{i=1}^m\phi_{w_i}(V_i)
		\end{split}
	\end{equation}
	where $V_i$ denotes a set of variables, $w_i$ denotes a factor weight, $m$ denotes the total number of factors and $Z_{\bf{w}}$ denotes the normalization constant. Factor inference on $G$ learns factor weights by minimizing the negative log marginal likelihood of evidence variables as follows:
	\begin{equation} \label{eq:weight-learning}
		\hat {\bf{w}}  = arg \min \limits_{\bf{w}} -log \sum_{V_I} P_{\bf{w}}(\Lambda, V_I).
	\end{equation}	

	
 	In each iteration, GML typically labels the inference variable with the highest degree of evidential certainty, which is measured by the inverse of entropy as follows
%{\color{red}	
	 \begin{equation}
 E(v)=\frac{1}{H(v)}, % = \frac{1}{H_+(v) + H_-(v)}, 
 \end{equation}
where 
\begin{equation}
	H(v) = - (P_{max}({v})  \cdot {\log _2}P_{max}({v}) + 
	    (1-P_{max}({v}))  \cdot (1-{\log _2}P_{max}({v}))), 
	\end{equation}
where $E(v)$ and $H(v)$ denote the evidential certainty and entropy of $v$ respectively, and $P_{max}(v)$ denotes the max estimated class probability of $v$. 

%GML repeats the iteration until all the inference variables are labeled.



\begin{algorithm}[t]
	\caption{Scalable Gradual Inference.}
	\label{alg:gradualinference}
	%\begin{algorithmic}
	\While{there exists any unlabeled variable in $G$}
	{
		$V' \leftarrow$ all the unlabeled variables in $G$\;
		\For{$v\in V'$}
		{
			Measure the evidential support of $v$ in $G$\;
		}
		Select top-$m$ unlabeled variables with the most evidential support (denoted by $V_m$) \;
		\For{$v\in V_m$}
		{
			Approximately rank the entropy of $v$ in $V_m$\;
		}
		Select top-$n$ most promising variables in terms of entropy in $V_m$ (denoted by $V_n$) \;
		\For{$v\in V_n$}
		{
			Compute the probability of $v$ in $G$ by factor graph inference over a subgraph of $G$\;
		}
		Label the variable with the minimal entropy in $V_n$\;
	}
	%\end{algorithmic}
\end{algorithm}

To improve efficiency, as usual, the GML solution implements gradual inference by a scalable approach as sketched in Algorithm~\ref{alg:gradualinference}, which is essentially the same as what was previously proposed for entity resolution and sentiment analysis~\cite{hou2018r,wang2021aspect}. Scalable gradual inference consists of three steps: 1) measurement of evidential support; 2) approximate ranking of entropy; 3) subgraph factor inference. In the first step, it selects the top-$m$ unlabeled variables with the most evidential support in $G$ as the inference candidates. For each unlabeled variable, GML measures its evidential support from each feature by the degree of labeling confidence indicated by labeled observations and then aggregates them based on the Dempster-Shafer theory\footnote{https://en.wikipedia.org/wiki/Dempster-Shafer\_theory}. In the second step, it approximates entropy estimation by an efficient algorithm on the $m$ candidates and selects only the top-$n$ most promising variables among them for factor graph inference. Finally, the third step estimates the class probabilities of these $n$ selected variables by factor graph inference. 
	
It is noteworthy that the open-sourced GML engine has standardized the process of scalable gradual inference\footnote{https://chenbenben.org/gml.html}. Therefore, our GML implementation of few-shot image classification only needs to construct a factor graph, while scalable gradual inference on the factor graph can be automatically executed by the engine. Therefore, in the following section, we focus on how to construct the factor graph for few-shot image classification.