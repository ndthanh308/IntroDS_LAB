\section{Empirical Evaluation}\label{sec:experiments}


In this section, we empirically evaluate the performance of our proposed solution by a comparative study on real benchmark datasets. It is organized as follows: Subsection~\ref{sec:setup} describes the experimental setup. Subsection~\ref{sec:comparison} presents the comparative evaluation results. Subsection~\ref{sec:ablation} presents the evaluation results of ablation study. Finally, Subsection~\ref{sec:sensitivity} evaluates the performance sensitivity of GML w.r.t key parameters. 


\subsection{Experimental Setup} \label{sec:setup}

  We use four widely used benchmark datasets in our empirical study: 
\begin{itemize}
\item \textbf{MiniImageNet\cite{ravi2017optimization}}: it contains totally 100 classes, each of which contains 600 images with a size of 84$\times$84. The classes are split among training, validation, and test sets by the ratio of (64:16:20);

\item \textbf{TieredImageNet\cite{ren2018meta}}:it was created by selecting 34 categories from the ILSVRC-2012 imagenet, with each superclass containing 10-30 subclasses. There are totally 20 superclasses (351 subclasses) on the training set, 6 superclasses (97 subclasses) in the validation set and 8 superclasses (160 subclasses) in the test set. All the images are of the size of 84$\times$84; 

\item \textbf{Cifar-FS\cite{bertinetto2018meta}}: it contains totally 100 classes, each of which contains 600 images with the size of 32$\times$32. The classes are split among training, validation and test sets by the ratio of (64:16:20);

\item \textbf{CUB-200-2011\cite{wah2011caltech}}: also known as Caltech-UCSD Birds-200-2011, it contains totally 200 bird species, which are split among training, validation, and test sets by the ratio of (100:50:50).
\end{itemize}	

%methods involve utilizing common features or patterns in the samples for classification. Examples of inductive methods in the context of few-shot classification include 

 We compare the proposed GML solution with the SOTA methods of both inductive learning and transductive learning: 1) the methods of inductive learning include recently proposed ProtoNet~\cite{2017Prototypical}, MetaQDA~\cite{zhang2021shallow}, SetFeat-12~\cite{afrasiyabi2022matching} and PFENet~\cite{zhao2022self}. Among them, PFENet reported the overall best performance; 2) the methods of transductive learning include recently proposed TPN~\cite{sung2018learning}, LaplacianShot~\cite{ziko2020laplacian}, COM-FSC~\cite{liu2023cycle}, DFMN-MCT~\cite{kye2020meta}, PT-MAP~\cite{hu2021leveraging}, EASE+SIAMESE~\cite{zhu2022ease}, EASY~\cite{bendou2022easy} and PEM$_n$E-BMS*~\cite{hu2022squeezing}. Among them, the most recently proposed models, e.g., EASY, EASE+SIAMESE and PEM$_n$E-BMS*, have reported highly competitive performance. 

  Due to the large number of the compared methods, we directly compare the results of GML in term of accuracy with the results that have been reported in these methods' original papers. For fair comparison, on each workload, as usual, we report the average and standard variance over 10000 rounds of testing. Since most of the existing methods only report results on 2-3 test datasets of the 4 datasets we have used, we mark a compared method's result on a dataset as null (-) if it was not reported in the original paper.       

  For comparative evaluation, we have compared performance in both scenarios of intro-domain classification, where training and test sets come from the same data source, and cross-domain classification, where training and test sets come from different sources, e.g., a model is trained on MiniImageNet but tested on CUB-200-2011. Obviously, cross-domain classification is more challenging than intro-domain classification. In practical scenarios, it is usually expensive to manually label samples, but much easier to retrieve unlabeled samples. Therefore, we have also evaluated the robustness of the proposed GML solution by increasing the size of query set, or the samples to be labeled in the query set, and compared its performance with the existing SOTA alternatives.  

\iffalse
 models for few-shot image classification, which include: {\color{red}
\begin{itemize}
  \item Inductive Few-shot Learning: ProtoNet\cite{2017Prototypical}, MetaQDA\cite{zhang2021shallow}, SetFeat-12\cite{afrasiyabi2022matching}, and PFENet\cite{zhao2022self}. Among them, PFENet uses an improved convolutional structure, known as Self-Guided Information Convolution to obtains effective feature embeddings. PFENet is widely considered as the optimal inductive model.
  
  \item Transductive Few-shot Learning: {\color{blue}TPN\cite{sung2018learning}, LaplacianShot\cite{ziko2020laplacian}, COM-FSC\cite{liu2023cycle}, DFMN-MCT\cite{kye2020meta}, PT-MAP\cite{hu2021leveraging}, EASE+SIAMESE\cite{zhu2022ease}, EASY\cite{bendou2022easy}, and PEM$_n$E-BMS*\cite{hu2022squeezing}. The reported performance of these models, especially recently proposed ones, EASY, EASE+SIAMESE and PEM$_n$E-BMS* are highly competitive. }
\end{itemize}
}
\fi
%Among them, PEM$_n$E-BMS*\cite{hu2022squeezing} aims to make the distribution of feature vectors closer to a Gaussian distribution. It utilizes the idea of optimal transport algorithm to iteratively adjust the feature relationships between the support set and query set, aiming to obtain optimal classification performance.

% 归纳式方法：利用样本中的共同特征或规律来进行分类，例如，ProtoNet，MetaQDA，SetFeat12，FT+SGI-Conv+GCBNet等。其中，FT+SGI-Conv+GCBNet改进卷积结构the Self-Guided Information Convolution，通过获取有效的特征嵌入，将度量网络划分成多个块，以共享相邻矩阵构建多层图卷积网络，该方法是目前归纳式最优方法。
% 直推式学习：利用先验知识或已有的分类模型进行推理。例如，PT-MAP，EASE+SIAMESE，EASY，PEMnE_BMS等。其中，PEMnE_BMS将特征向量的分布更接近于高斯分布，利用最优传输算法的思想，通过迭代调整支持集和查询集间的特征关系，获取最优分类性能。
% 


We have implemented the proposed solution based on the open-sourced GML engine\footnote{https://github.com/gml-explore/gml}. In the GML implementation, we leverage both ResNet-12 and WRN-28-10 to extract deep vector representations. In the generation of \emph{KNN} features, by default, we set $k=6$. In the implementation of gradual inference, by default, we set the number of candidates with the highest evidential support at 50, and the number of candidates with the smallest approximate entropy at 10.  At each iteration of gradual inference, GML labels the 10 samples with the smallest approximate entropy by factor inference. After each iteration, given the newly labeled images, the algorithm correspondingly updates evidential support and approximate entropy estimation. In our sensitivity evaluation, we will show that the performance of GML is very stable w.r.t these parameters provided that their values are set within reasonable ranges. We have open-sourced the GML implementation\footnote{https://github.com/chn05/FSIC\_GML}.

%As usual, we measure performance by the metric of accuracy. {\color{blue} On each workload, as usual, we report the average and standard variance over 10000 rounds of testing. 

% We also set a distance threshold of 0.01 to filter out not-close-enough nearest neighbors.

\subsection{Comparative Evaluation} \label{sec:comparison}

%We have compared performance in two scenarios: 1) intro-domain classification, where training and test sets come from the same data source; 2) cross-domain classification, where training and test datasets come from different sources, e.g., a model is trained on MiniImageNet but tested on CUB-200-2011. It is obvious that compared with intro-domain classification, cross-domain classification is more challenging. 


% \hspace{-0.2in}
\textbf{Intro-domain classification:}
the comparative evaluation results have been presented in Table~\ref{table:minitiered} and~\ref{table:cifar-fs_cub}. It can be observed that the transductive approaches consistently perform considerably better than their inductive alternatives on all the workloads. It is worth pointing out that GML consistently outperforms the best transductive alternative by considerable margins on all the workloads. For instance, on MiniImageNet and TierImageNet, in the case of 5-way 1-shot learning, GML beats EASY+SIMESE, which is the best transductive approach based on the reported results, by the margins of 2.79\% and 2.41\% respectively. In the case of 5-way 5-shot learning, the improvement margins are 4.65\% and 1.5\% respectively. On Cifar-FS and CUB-100-2011, PEM$_n$E-BMS* is instead the best transductive approach. In the case of 5-way 1-shot learning, GML outperforms PEM$_n$E-BMS* by the margins of 4.58\% and 3.72\% respectively. In the case of 5-way 5-shot learning, the improvement margins are 3.89\% and 2.93\% respectively. 

\begin{table*}[htbp]
    %\setlength\tabcolsep{1.5pt}%设置表格列间距
    \centering
    \caption{Comparative results on the MiniImageNet and TieredImageNet datasets: GML clearly achieves the SOTA performance on both datasets, and the margins are considerable.}\label{table:minitiered}
    % \begin{tabular}{c,p{4cm},c,p{7cm}|}
    \small
    \begin{tabular}{c|c|c|c|c|c}
    \toprule
    \multicolumn{2}{c|}{\textbf{DataSets}} & \multicolumn{2}{c|}{\cellcolor[HTML]{9698ED}{\textbf{Mini-ImageNet}}} & \multicolumn{2}{c}{\cellcolor[HTML]{FFCE93}{\textbf{Tiered-ImageNet}}} \\ 
    \midrule
    Setting & Methods & 5-way 1-shot(\%) &5-way 5-shot(\%) & 5-way 1-shot(\%) & 5-way 5-shot(\%)\\ 
    \midrule
    \multirow{10}{*}{\textbf{Inductive}} &  Relation\cite{sung2018learning}  &$52.48\pm0.86$ & $69.83\pm0.68$  & $-$ & $-$  \\
    & Baseline++\cite{chen2019closer}  &  $53.97\pm0.79$ & $75.90\pm0.61$  & $-$ & $-$\\
    &MatchingNet\cite{2016Matching} &   $52.91\pm0.88$ & $68.88\pm0.69$ & $-$ & $-$ \\
    &ProtoNet\cite{2017Prototypical} &  $54.16\pm0.82$ & $73.68\pm0.65$ &  $65.65\pm0.92$ & $83.40\pm0.65$ \\
    &$S2M2_R$~\cite{mangla2020charting} &  $64.93\pm0.18$ & $83.18\pm0.11$ & $73.71\pm0.22$ & $88.59\pm0.14$\\
    &DeepEMD\cite{zhang2020deepemd} &  $65.91\pm0.82$ & $82.41\pm0.56$ & $71.16\pm0.87$ & $86.03\pm0.58$ \\
    &FRN\cite{wertheimer2021few} &   $66.45\pm0.19$ & $82.83\pm0.13$ & $71.16\pm0.22$ & $86.01\pm0.15$\\
    &MetaQDA\cite{zhang2021shallow} &  $67.83\pm0.64$ & $84.28\pm0.69$ & $74.33\pm0.65$ & $89.56\pm0.79$\\
    &SetFeat12\cite{afrasiyabi2022matching} &  $68.32\pm0.62$ & $82.71\pm0.46$ & $73.63\pm0.88$ & $87.59\pm0.57$ \\
    &PFENet\cite{zhao2022self} &  $68.76\pm0.75$ & $84.67\pm0.52$ & $74.93\pm0.84$ & $89.62\pm0.50$ \\
    \midrule
    \multirow{10}{*}{\textbf{Transductive}} &TPN\cite{sung2018learning} & $55.51\pm0.86$ & $69.86\pm0.65$ &  $59.91\pm0.94$ & $73.30\pm0.75$\\
    &COM-FSC\cite{liu2023cycle} &   $68.92\pm0.72$ & $85.37\pm0.49$ &  $79.69\pm0.74$ & $90.57\pm0.45$\\
    &LaplacianShot\cite{ziko2020laplacian} & $75.57\pm0.19$ & $84.72\pm0.13$ &  $80.30\pm0.22$ & $87.93\pm0.15$\\
    &DFMN-MCT\cite{kye2020meta} &  $78.55\pm0.86$ & $86.03\pm0.42$ &  $80.89\pm0.84$ & $87.30\pm0.49$\\
    &Transd-CNAPS+FETI\cite{bateni2022enhancing} &   $79.90\pm0.80$ & $91.50\pm0.40$ & $73.80\pm0.10$ & $87.70\pm0.60$ \\
    &PT-MAP\cite{hu2021leveraging} &   $82.92\pm0.26$ & $88.82\pm0.13$ & $85.67\pm0.26$ & $90.45\pm0.14$\\
    &EASE+SIAMESE\cite{zhu2022ease} &$83.00\pm0.21$ & $88.92\pm0.13$ & $88.96\pm0.23$ & $92.63\pm0.13$\\
    &EASY\cite{bendou2022easy} & $84.04\pm0.23$ & $89.14\pm0.11$ &  $84.29\pm0.24$ & $89.76\pm0.14$\\
    &PEM$_n$E-BMS*\cite{hu2022squeezing} &  $83.35\pm0.25$ & $89.53\pm0.13$ & $86.07\pm0.75$ & $91.09\pm0.14$\\
    % GiFeic & Transductive & WRN & \textcolor{red}{\textbf{0$\pm$0.32}} & \textbf{93.14$\pm$0.25} & \makecell{ResNet-12\\+WRN} & \textcolor{red}{\textbf{0$\pm$0.42}} & \textcolor{red}{\textbf{0$\pm$0.43}}\\
    \rowcolor[HTML]{FFFFFF}&\cellcolor[HTML]{96FFFB} \textbf{GML}  & \cellcolor[HTML]{96FFFB} \textbf{$85.79\pm0.32$} & \cellcolor[HTML]{96FFFB} \textbf{$93.57\pm0.25$} & \cellcolor[HTML]{96FFFB}  \textbf{$91.37\pm0.42$} & \cellcolor[HTML]{96FFFB} \textbf{$94.13\pm0.13$}\\
    \bottomrule
    \end{tabular}
    \end{table*}



\begin{table*}[htbp]
    %\setlength\tabcolsep{1.5pt}%设置表格列间距
    \centering
    \caption{Comparative results on the Cifar-FS and CUB-100-2011 datasets: GML clearly achieves the SOTA performance on both datasets, and the margins are considerable.}\label{table:cifar-fs_cub}
    % \begin{tabular}{c,p{4cm},c,p{7cm}|}
    \small
    \begin{tabular}{c|c|c|c|c|c}
    \toprule
    \multicolumn{2}{c|}{\textbf{DataSets}} & \multicolumn{2}{c|}{\cellcolor[HTML]{C0C0C0}{\textbf{Cifar-FS}}}  &  \multicolumn{2}{c|}{\cellcolor[HTML]{FE996B}{\textbf{CUB-100-2011}}} \\ 
    \midrule
    \textbf{Setting} &\textbf{Method} & \textbf{5-way 1-shot(\%)} & \textbf{5-way 5-shot(\%)} & \textbf{5-way 1-shot(\%)} & \textbf{5-way 5-shot(\%)} \\ 
    \midrule
    \multirow{9}{*}{\textbf{Inductive}} & MatchingNet\cite{2016Matching} & $43.88\pm0.75$ & $57.05\pm0.76$ & $-$ & $-$\\
    &ProtoNet\cite{2017Prototypical} & $41.54\pm0.76$ & $57.08\pm0.76$ & $-$ & $-$\\
    &DeepEMD\cite{zhang2020deepemd} &$46.47\pm0.78$ & $63.22\pm0.71$ &$-$ & $-$\\
    &SetFeat12\cite{afrasiyabi2022matching} &  $-$ & $-$ &  $79.60\pm0.80$ & $90.48\pm0.44$ \\
    &$S2M2_R$\cite{mangla2020charting} & $74.81\pm0.19$ & $87.47\pm0.13$ & $80.68\pm0.81$ & $90.85\pm0.44$\\
    &RENet\cite{2021Relational} &   $74.51\pm0.46$ & $86.60\pm0.32$ &  $79.49\pm0.44$ & $91.11\pm0.24$\\
    &FRN\cite{wertheimer2021few} & $-$ & $-$ &  $83.55\pm0.19$ & $92.92\pm0.10$ \\
    &PFENet\cite{zhao2022self} &  $-$ & $-$ & $86.09\pm0.19$ & $93.15\pm0.10$ \\
    &MetaQDA\cite{zhang2021shallow} &  $75.83\pm0.88$ & $88.79\pm0.75$ & $-$ & $-$\\
    \midrule
    \multirow{7}{*}{\textbf{Transductive}} & COM-FSC\cite{liu2023cycle} & $-$ & $-$ &  $83.93\pm0.66$ & $93.95\pm0.30$\\
    &EASY\cite{bendou2022easy} & $87.16\pm0.21$ & $90.47\pm0.15$ &  $90.56\pm0.19$ & $93.79\pm0.10$\\
    &iLPC\cite{Lazarou_2021_ICCV}& $86.51\pm0.23$ & $90.60\pm0.48$ &  $91.03\pm0.63$ & $94.11\pm0.30$\\
    &EASE+SIAMESE\cite{zhu2022ease} &  $87.60\pm0.23$ & $90.60\pm0.16$ & $91.68\pm0.19$ & $94.12\pm0.09$\\
    &PT-MAP\cite{hu2021leveraging} &  $87.69\pm0.23$ & $90.68\pm0.15$ & $91.55\pm0.19$ & $93.99\pm0.10$\\
    &PEM$_n$E-BMS*\cite{hu2022squeezing} & $87.83\pm0.22$ & $91.20\pm0.15$ & $91.91\pm0.18$ & $94.62\pm0.09$\\
    \rowcolor[HTML]{FFFFFF}  & \cellcolor[HTML]{96FFFB} \textbf{GML} & \cellcolor[HTML]{96FFFB} \textbf{$92.41\pm0.32$} & \cellcolor[HTML]{96FFFB} \textbf{$95.09\pm0.18$} &  \cellcolor[HTML]{96FFFB} \textbf{$95.63\pm0.06$} & \cellcolor[HTML]{96FFFB} \textbf{$97.55\pm0.43$}\\
    \bottomrule
    \end{tabular}
    \end{table*}
    
	Even with the existing inductive and transductive solutions being considered as a whole, GML consistently improves the reported SOTA performance on the four workloads by considerable margins. In the case of 5-way 1-shot learning, the improvement margins over the SOTA results are 1.75\%, 2.41\%, 4.58\%, and 3.95\% respectively. In the case of 5-way 5-shot learning, the improvement margins are 2.07\%, 1.5\%, 3.89\%, and 2.93\% respectively. Due to the widely recognized challenge of few-shot learning, these margins are truly considerable. Since our GML solution extracts discriminative features by the same deep neural models leveraged by the existing solutions, these evaluation results clearly demonstrate that compared with the existing transductive alternatives, gradual inference is a more effective mechanism for few-shot learning.       

%Our evaluation results clearly demonstrate the performance advantage of GML over the existing approaches in the scenario of few-shot learning. 


\begin{table}[htbp]
    %\setlength\tabcolsep{1.5pt}%设置表格列间距
    \centering
    \caption{Comparative results on cross-domain classification: the models are trained on MiniImageNet but tested on CUB-100-2011.}\label{table:cross}
    % \begin{tabular}{c,p{4cm},c,p{7cm}|}
    \small
    \begin{tabular}{c|c|c|c}
    \toprule
    \textbf{DataSets} & \multicolumn{3}{c}{\textbf{MiniImageNet$\rightarrow$CUB-100-2011 (5-way)}} \\
    \toprule
    \textbf{Setting} & \textbf{Methods}  &\textbf{1-shot(\%)} &\textbf{5-shot(\%)} \\ 
    \midrule
    \multirow{4}{*}{\textbf{Inductive}} &PFENet\cite{zhao2022self}   &$48.27$ & $69.51$ \\
    &$S2M2_R$\cite{mangla2020charting} & $48.24$ & $70.44$ \\
    &MetaQDA\cite{zhang2021shallow}  &  $53.75$ & $71.84$\\
    &FRN\cite{wertheimer2021few} & $54.11$ & $77.09$ \\
    \midrule
    \multirow{4}{*}{\textbf{Transductive}} &LaplacianShot\cite{ziko2020laplacian} & $55.46$ & $66.33$ \\
    &COM-FSC\cite{liu2023cycle} &  $53.14$ & $73.02$ \\
    &PEM$_n$E-BMS*\cite{hu2022squeezing}& $63.00$ & $79.15$ \\
    % \midrule
    \rowcolor[HTML]{FFFFFF}  & \cellcolor[HTML]{96FFFB} \textbf{GML} &\cellcolor[HTML]{96FFFB} $\textbf{67.29}$ & \cellcolor[HTML]{96FFFB} $\textbf{82.81}$ \\
    \bottomrule
    \end{tabular}
\end{table}

% \vspace{0.05in}
% \hspace{-0.2in}
\textbf{Cross-domain classification:} 
 cross-domain classification is usually performed on two datasets containing the same type of objects. Since both MiniImageNet and CUB-100-2011 contain images of bird species, as in previous work~\cite{mangla2020charting,zhang2021shallow,zhao2022self,ziko2020laplacian}, we train models on the MiniImageNet dataset and test its performance on another dataset of CUB-100-2011. 
	
  The comparative evaluation results have been presented in Table~\ref{table:cross}. It can be observed that on both cases of 1-shot and 5-shot learning, GML outperforms the existing alternatives by considerable margins. Specifically, on 1-shot learning, GML beats PEM$_n$E-BMS*, which is the best approach among the existing alternatives, by 4.29\% in terms of accuracy. On 5-shot learning, GML's improvement margin over PEM$_n$E-BMS* is similarly large at 3.66\%. Our experimental results clearly demonstrate that by gradual learning, the features learned in training classes can be better generalized to unseen classes. 

% It is interesting to point out that these observed margins are even more considerable than what have been observed on intro-domain classification. 


% Figure environment removed


\begin{table*}[htbp]
    %\setlength\tabcolsep{1.5pt}%设置表格列间距
    \centering
    \caption{The evaluation result of GML ablation study on MiniImagenet and Cifar-FS: using both ResNet-12 and WRN-28-10 vs using either of them.}\label{table:backbone}
    % \begin{tabular}{c,p{4cm},c,p{7cm}|}
    \small
    \begin{tabular}{c|c|c|c|c|c}
    \toprule
    \multicolumn{2}{c|}{\textbf{DataSets}}  &  \multicolumn{2}{c|}{\textbf{MiniImageNet}} &\multicolumn{2}{c}{\textbf{Cifar-FS}} \\
    \midrule
    \textbf{Methods} & \textbf{Network} & \textbf{5-way 1-shot(\%)} & \textbf{5-way 5-shot(\%)}  & \textbf{5-way 1-shot(\%)} & \textbf{5-way 5-shot(\%)} \\ 
    \midrule
    \multirow{3}{*}{\textbf{GML}} &  ResNet-12 & $84.74$ & $89.50$ & $85.69$ & $89.43$\\
    &  WRN-28-10 & $83.28$ & $88.80$ & $84.06$ & $88.35$\\
    \rowcolor[HTML]{FFFFFF}  &  \cellcolor[HTML]{96FFFB} ResNet-12+WRN-28-10 &\cellcolor[HTML]{96FFFB}$\textbf{85.79}$ &\cellcolor[HTML]{96FFFB}$\textbf{93.57}$ & \cellcolor[HTML]{96FFFB}$\textbf{92.41}$ &\cellcolor[HTML]{96FFFB}$\textbf{95.09}$\\
  
    \bottomrule
    \end{tabular}
    \end{table*}

\begin{table*}[htbp]
        %\setlength\tabcolsep{1.5pt}%设置表格列间距
        \centering
        \caption{ Parameter sensitivity evaluation results.}\label{table:sensitivity}
        % \begin{tabular}{c,p{4cm},c,p{7cm}|}
        \small
        \begin{tabular}{c|c|c|c|c|c}
        \toprule
        \multicolumn{2}{c|}{\textbf{DataSets}} & \multicolumn{2}{c|}{\textbf{MiniImageNet}} & \multicolumn{2}{c}{\textbf{Cifar-FS}} \\
        \midrule
         & \textbf{top-m/n/k}  &\textbf{5-way 1-shot(\%)} & \textbf{5-way 5-shot(\%)}  &\textbf{5-way 1-shot(\%)} & \textbf{5-way 5-shot(\%)} \\ 
        \midrule
        \rowcolor[HTML]{FFFFFF} \multirow{2}{*}{\textbf{$w.r.t$ m (n=10,k=6)}}  & m=40 &  $85.61$ & $ 93.28$  &  $92.16$ & $95.12$ \\
         & m=60 &  $ 85.56 $ & $ 93.23 $ &  $92.31$ & $ 94.59$  \\
         \midrule
         \multirow{2}{*}{\textbf{$w.r.t$ n (m=50,k=6)}} & n=8 &  $ 85.39$ & $ 93.48$  &  $92.09$ & $94.95$ \\
         & n=12 & $85.69$ & $ 93.56$  &  $92.24$ & $95.10$ \\
         \midrule
        \multirow{2}{*}{\textbf{$w.r.t$ k (m=50,n=10)}}  & k=5 & $ 85.76 $ & $ 93.33 $  &  $ 92.40 $ & $ 94.98 $   \\
        % & k=3 &  $85.59$ & $ 92.88$  &  $92.18$ & $94.57$ \\
        & k=7 & $ 85.15 $ & $ 93.04 $  &  $ 91.83 $ & $ 94.66 $   \\
        \midrule
        \rowcolor[HTML]{96FFFB}\textbf{GML}  & m=50, n=10, k=6 &$ 85.79 $ &$ 93.57 $  & $ 92.41 $ & $ 95.09 $   \\
        \bottomrule
        \end{tabular}
\end{table*}
%In practical scenarios, it is usually expensive to manually label many samples, but much easier to retrieve many unlabeled samples. Therefore, we evaluate the robustness of the proposed GML solution by increasing the size of query set, or the samples to be labeled in the query set. I


\textbf{Comparative evaluation with increasing size of query set:}
in the classical setting of few-shot learning, the number of queries per class is set at 15. Therefore, we increase the number of queries from 15 to 30, 50, 100, and finally up to 200, and compare the performance of GML with two recently proposed approaches, EASY and EASE, which can be considered as the SOTA representatives of the existing transductive approaches. 

%{\color{red} We report the evaluation results on MiniImageNet and Cifar-FS; the evaluation results on the other two datasets are similar, but omitted here.} 

The comparative evaluation results on MiniImageNet and Cifar-FS have been presented in Figure~\ref{fig:query structure}. The evaluation results on the other two datasets are similar, thus omitted due to space limit. It can be observed that on both 1-shot and 5-shot learning, the performance of GML consistently improves as the number of queries increases, even though by different margins on different workloads. The common pattern is that the performance of GML initially improves considerably as the number of queries increases from 15 to 30, but then gradually flattens out as it continues to increase. For instance, in the case of 1-shot learning on MiniImageNet, the accuracy improves by the margin of around 6\%. from 85.79\% to 91.88\%, when the number of queries increases from 15 to 30, and then continues to improve, even though by smaller margins, up to 94.3\% when the number of queries reaches 200. In comparison, the performance of EASE and EASY fluctuates only marginally when the number of queries increases. For instance, in the case of 1-shot learning on MiniImageNet, the performance of EASY even deteriorates marginally from 83.84\% to 82.98\%; but on 5-shot learning, its performance instead improves slightly, from 88.37\% to 89.06\%. These observations clearly demonstrate that GML is more robust than the existing transductive alternatives. They bode well for its application in real scenarios.  




\subsection{Ablation Study} \label{sec:ablation}



To verify the efficacy of leveraging two distinct backbones, i.e., ResNet-12 and WRN-28-10, for gradual learning, we have conducted an ablation study on the GML approach, which compares the solution using both models with the alternatives using either of them. The evaluation results on MiniImagenet and Cifar-FS have been presented in Table~\ref{table:backbone}. The evaluation results on the two other datasets are similar, thus omitted here. It can be observed that the GML using both of them performs considerably better that the alternatives using either of them. These results clearly demonstrate that even though both ResNet-12 and WRN-28-10 have been constructed based on the ResNet network, they are some extent complementary in feature extraction, and integrating them for knowledge conveyance can effectively improve the performance of gradual learning. 



%{\color{blue}
\textbf{An Illustrative Example:} in a run on MiniImageNet, inference accuracy based on ResNet-12 or WRN-28-10 is 85.33\% and 68\% respectively, but the accuracy is better at 94.67\% if gradual inference uses both of them. As shown in Figure~\ref{fig:example}, we take the sample with the id of 64 as an example. In the factor graph constructed based on ResNet, both unary and binary factors point to the class of $c_3$ for the sample. However, based on WRN-28-10, the factors point to its ground-truth class of $c_2$. It can be observed that the fused factor graph constructed based on both ResNet-12 and WRN-28-10 correctly point to the class of $c_2$ while labeling the sample of 64. It is noteworthy that the inference order in different factors may vary. This example clearly demonstrates that the framework of GML can effectively fuse diverse and noisy features to improve gradual knowledge conveyance.
%}     

% Figure environment removed

%a task is randomly extracted, and the feature vectors extracted by ResNet-12, WRN-28-10, ResNet-12+WRN-28-10 are used respectively. The prediction accuracy in GML are: 85.33\%, 68\% and 94.67\%. Take sample 64 as an example to illustrate the effectiveness of this method. (a) is the unary and binary factor constructed by the eigenvector of ResNet-12. When marking sample 64, the weight of the unary and binary factor of the evidence variable points to the $c_3$. (b) is the unary and binary factor constructed by obtaining the feature vector through WRN-28-10, and the weight of the unary and binary factor points the 64 sample to the $c_2$. (c) Constructing two types of unary and binary factors, due to the increase of features, the fusion of DS theory changes the order of reasoning, so sample 64 is indicated as the $c_2$ by more evidence variables. It is obvious that the method proposed in this paper adopts gradual inference to fuse different factors for feature complementation, so as to obtain higher accuracy.



%The accuracy on ResNet-12 and WRN-28-10 models is lower, while the accuracy on integrated feature models ResNet-12+WRN-28-10 is higher. Due to the issue of feature redundancy when adding ResNet-12 and WRN-28-10 features, its accuracy is lower than ResNet-12+WRN-28-10. gradual inference enhances detection accuracy by obtaining image feature vectors with different expressive capabilities and applying different features to factor graph modeling to improve evidence support for factors.

\subsection{Parameter Sensitivity Study} \label{sec:sensitivity}

In this subsection, we evaluate the performance sensitivity of the proposed GML solution w.r.t one key parameter of feature extraction, the $k$ value of k-nearest neighbors (\emph{KNN}) for binary feature extraction, and two key parameters of scalable gradual inference, the number of candidates with the most evidential support and the number of candidates with the smallest approximate entropy, or $m$ and $n$ as shown in Algorithm~\ref{alg:gradualinference}. By default, we set $m$ = 50, $n$ = 10 and $k$ = 6. In the sensitivity study, we vary the value of a parameter, but fix the values of the other two parameters. We set the values of parameters within reasonable ranges. Specifically, we vary the value of $k$ from 5 to 7, the value of $m$ from 40 to 60, and the value of $n$ from 8 to 12. We report the evaluation results on the MiniImageNet and Cifar-FS workloads; the results on other workloads are similar, thus omitted here. 
	
The detailed evaluation results have been presented in Table~\ref{table:sensitivity}. It can be observed that the performance of GML only fluctuates marginally ($\leq 0.5\%$ in most cases) as the values of $m$, $n$ and $k$ change. These observations clearly indicate that the performance of GML is very robust w.r.t these parameters. They bode well for their application in real scenarios. 
