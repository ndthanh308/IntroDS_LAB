\section{Introduction}

A powerful way to tackle complex real-life decision-making problems is to frame them as multi-stage decision problems under uncertainty. This helps one to understand the interactions between parts of the decision process and how uncertainty behaves from a rigorous, quantitative standpoint. State-of-the-art approaches for modeling and solving multi-stage decision problems stem from two main areas: decision analysis and stochastic programming. Each field has provided time-tested modeling and solution approaches with varying degrees of success depending on how uncertainty is modeled. 

These modeling approaches require specifying probability values and measurable consequences to uncertain events such that the decisions maximizing an expected utility function value can be made. However, it remains extremely challenging to analytically model decision problems due to the particularly interdependent nature that decision problems can exhibit. Outcomes of random events change the optimal decisions and decisions can influence the probability distributions of random events. The task of representing such dependencies may be equally challenging, if not more so, than finding the best decisions.

Influence diagrams \citep{howard2005influence} provide both a formal description of a decision problem and serve as a communication tool which requires minimal technical proficiency. Furthermore, they are useful in conveying structural relationships of the problem in a simple manner and thus crucially bridge the gap between quantitative specifications and qualitative descriptions. 

Due to their generality, influence diagrams pervade many modeling-based approaches that require a formal description of relationships between uncertainty, decisions and consequences. Figure~\ref{fig:n_monitoring} shows an influence diagram for the $N$-monitoring problem, where $N$ agents ($A_1$ to $A_N$) must decide whether to countervail an unknown load ($L$) based on imprecise readings of this load from their respective sensors ($R_1$ to $R_N$). The chance of failure ($F$) is influenced by the unknown load and the eventual decision to countervail the load. The final utility ($T$) is calculated considering whether the agents intervened and if a failure was observed. As such, this setting represents independent agents who must make decisions based only on observations of the state of the world but without being able to completely know it or share information among themselves.

% Figure environment removed

Differently from decision trees, the nodes in an influence diagram do not need to be totally ordered nor do they have to depend directly on all predecessors. This freedom from dependence on all predecessors allows for the decisions to be made by, e.g., decision-makers who partially observe a common state of information (node $L$ in Figure~\ref{fig:n_monitoring}) but may differ in their ability to observe or are incapable of sharing information. 

Unfortunately, quantitative methods employed to obtain optimal decisions from influence diagram representations typically require that some of that generality is curbed. Influence diagrams are, in essence, representations of (possibly partially observable) Markov decision processes \citep{puterman1990markov}. Thus, if 
\begin{enumerate*}[label=(\roman*)]
    \item a single decision-maker is assumed (implying a total ordering among decision nodes) and\label{assumption:single_DM}
    \item the \emph{no-forgetting} assumption holds (implying that each decision node and its direct predecessors influence all successor decision nodes),\label{assumption:no_forgetting}
\end{enumerate*}
then Markovian assumptions hold. This, in turn, enables one to solve influence diagrams with well-established techniques, for instance, by forming the equivalent decision tree that can be solved through dynamic programming; or by removing decision and chance nodes from the diagram one by one \citep{bielza2011review}.

As one may suspect, many problems, including that illustrated in Figure~\ref{fig:n_monitoring}, violate assumptions \ref{assumption:single_DM} and \ref{assumption:no_forgetting}. Indeed, there may be no memory or communication between deciding agents (meaning that they cannot know each otherâ€™s decisions) or constraints imposed across the diagram, such as budget limitations or logical conditions (e.g., stating that a given action can only occur if a prerequisite project has been started/completed in the past). All of these either violate the assumption that the previous state is ``remembered'' at a later stage or that all information influencing the decision alternatives is known when making said decision. These limitations create severe deficiencies in representing real-world problems. 

\citet{lauritzen2001representing} proposed an analytical framework to characterise these \emph{limited memory influence diagrams}. Note that the notion of limited memory can also be used to encompass settings with multiple decision-makers, the limited or absent sharing of information being its defining feature (regardless of whether it is due to lack of memory or communication between decision-makers). In any case, limited-memory influence diagrams are essentially influence diagrams that do not satisfy assumptions \ref{assumption:single_DM} and \ref{assumption:no_forgetting}. However, the fact that they do not satisfy assumptions \ref{assumption:single_DM} and \ref{assumption:no_forgetting} means that much more sophisticated analysis is required for designing methods that can extract optimal decisions from these diagrams. These methods involve specialised structures such as junction trees and message-passing mechanisms. 
  
Existing approaches for solving influence diagrams are deficient in many ways. First, solution methods are typically based on ad-hoc algorithm implementations that require the user to be proficient in manipulating influence diagrams. Additionally, such methods are often designed only for problems where expected utility is maximized, with no constraints connecting different decisions (e.g., budget/chance constraints). This limits their capabilities in modeling risk-averse decision making. Finally, tackling the challenges related to implementing computationally efficient methods (e.g., memory allocation, and thread-safe parallelisation) is required for larger problems. This creates a significant entry barrier to the wider adoption of such approaches.

It is precisely against this backdrop that the development of \emph{decision programming} \citep{salo2022} started. Decision programming leverages the capabilities of stochastic programming \citep{birge2011introduction} and decision analysis to model and solve multi-stage decision problems using mathematical optimization techniques. In essence, decision programming exploits the expressiveness of influence diagrams in structuring problems to develop deterministic equivalent \citep{birge2011introduction} mixed-integer programming (MIP) formulations. In turn, commercial-grade, professionally developed, off-the-shelf software can be readily utilised for solving these problems in a relatively straightforward manner instead of relying on ad-hoc implementations. It is worth highlighting that the latter, in stark contrast with the former, tend to be problem-specific and provide few guarantees for complying with sound software engineering practices in terms of versioning, updating and continuous improvements.

Concomitantly, the fact that decision programming models can be formulated as MIP problems gives rise to major benefits from the modeling perspective. In particular, decision programming exploits the exceptional modeling expressiveness provided by MIP to tackle challenging decision problems originally posed in the field of decision analysis. Having an underpinning MIP-based approach is extremely timely, especially due to the recent remarkable progress in MIP technology, with some estimating that the combined hardware and software speed-ups amount to a factor of two trillion between the early 1990s and mid-2010s \citep{bertsimas2019machine}! Thus, there is convincing evidence that MIP approaches for decision analysis problems are practically relevant, perhaps contrary to a few decades ago. 

In this paper, we provide multiple contributions in terms of practical and methodological aspects associated with decision programming. First and foremost, we present novel contributions that further improve upon the original ideas in \citet{salo2022}. Specifically, we present a novel formulation for decision programming problems that is considerably more efficient from a computational standpoint. This is illustrated in the computational experiments we provide. Furthermore, we propose a heuristic inspired by the single policy update heuristic, originally proposed in \citet{lauritzen2001representing}. This heuristic can be used not only to generate feasible solutions in case of more computationally challenging problems but also can be employed to warm start the MIP model. 

We also present \texttt{DecisionProgramming.jl}, a Julia \citep{Julia-2017} package that provides a seamless interface for users to pose decision problems as influence diagrams. The problem is then automatically converted into a MIP formulation using \texttt{JuMP.jl} \citep{DunningHuchetteLubin2017}, a Julia package for formulating mathematical programming models which provides an interface to a wide range of open-source and commercial mathematical optimization solvers.

%In this paper, we provide multiple contributions in terms of practical and methodological aspects associated with decision programming. First and foremost, we present \texttt{DecisionProgramming.jl}, a Julia \citep{Julia-2017} package that provides a seamless interface for users to pose decision problems as influence diagrams. The problem is then automatically converted into a MIP formulation using \texttt{JuMP.jl} \citep{DunningHuchetteLubin2017}, a Julia package for formulating mathematical programming models which provides an interfact to a wide range of open-source and commercial mathematical optimization solvers.

%We also present novel contributions that further improve upon the original ideas in \citet{salo2022}. Specifically, we present a novel formulation for decision programming problems that is considerably more efficient from a computational standpoint. This is illustrated in the computational experiments we provide. Furthermore, we propose a heuristic inspired by the single policy update heuristic, originally proposed in \citet{lauritzen2001representing}. This heuristic can be used not only to generate feasible solutions in case of more computationally challenging problems but also can be employed to warm start the MIP model. 

Finally, we present a comprehensive case study in which we use the decision programming framework to develop an optimal decision strategy for allocating preventive care for coronary heart disease (CHD). The aim of this study is to evaluate the suitability of decision programming for performing the cost-benefit analysis originally performed by \citet{hynninen2019value}. In \citet{hynninen2019value}, a set of alternative predefined testing and treatment strategies for CHD are optimized using dynamic programming. We show how the same problem can be solved precluding the need to define strategies a priori. This is because all of the possible strategies are within the feasible solution set of the model and, thus, once solved, the solution defines the optimal strategy. This showcases both the benefits of posing such decision problems as MIP formulations and the range of applications that can be tackled by decision programming. 

This paper is structured as follows. Section \ref{sec:decision_programming} presents the technical details associated with the decision programming framework. In Section \ref{sec:formulations}, we present the novel formulation proposed in this paper, followed by the proposed adaptation of the single policy update heuristic presented in Section \ref{sec:heuristics}. In Section \ref{sec:interface}, we present details of the user interface made available by \texttt{DecisionProgramming.jl} and how it allows users to implement decision programming problems based on their influence diagrams. In Section \ref{sec:computational_experiments}, we provide computational results showcasing the benefits of the methodological innovations proposed in this paper and in Section \ref{sec:case_study} we describe the case study considering optimal preventive care strategies for CHD. Lastly, in Section \ref{sec:conclusions} we provide conclusions and discuss some potential directions for further research.









