\section{Computational experiments} \label{sec:computational_experiments}

We present a collection of computational experiments carried out to assess the performance of the proposed reformulation against the original formulation presented in \citet{salo2022}. Hereinafter, we use v1.2 to refer to our proposed model version as presented in \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} and v0.1 to refer to \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin}. These refer to the versions of \texttt{DecisionPrograming.jl} these formulations were available in. 

In addition, we present computational results highlighting the performance of the proposed SPU heuristic. Those are tested considering (i) a modified version of the pig farm problem \citep{lauritzen2001representing} in which we can artificially augment the number of time periods and generate input parameters randomly; (ii) the N-monitoring problem, as proposed in \citet{salo2022}, in which we also can artificially augment the number of decision agents and randomly generate instances. All experiments are run using 16GB of memory and 8 threads on an Intel Xeon Gold 6248 CPU and the code can be found in \href{https://github.com/gamma-opt/DecisionProgramming.jl/tree/2023paper}{https://github.com/gamma-opt/DecisionProgramming.jl}.

\subsection{Problem size}

First, we compare the model sizes of the two formulations presented in Sections \ref{sec:decision_programming} and \ref{sec:formulations}. In both formulations, the number of variables is the same. There are $\sum_{j \in D} |S_j||S_{I(j)}|$ $z$-variables and $|S|$ path variables, either $\pi$ or $x$, depending on the formulation. As for the number of constraints, the formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} has $\sum_{j \in D}|S_{I(j)}|$ constraints \eqref{eq:dp_z_sum}, $2|S|$ bounds for $\pi$-variables, $|D||S|$ constraints \eqref{eq:dp_pi_upper} and $|S|$ constraints \eqref{eq:dp_pi_lower}. Arranging the terms, the total number of constraints becomes 
\begin{equation}
    \label{eq:num_paths}
    (3+|D|)|S| + \sum_{j \in D}|S_{I(j)}|.
\end{equation}

The formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} has $\sum_{j \in D}|S_{I(j)}|$ constraints \eqref{eq:dp2_z_sum}, $\sum_{j \in D}|S_j||S_{I(j)}|$ constraints \eqref{eq:dp2_x_upper}, one constraint \eqref{eq:dp2_prob_sum} and $2|S|$ bounds for $x$-variables. Arranging the terms, the total number of constraints becomes 
\begin{equation}
    \label{eq:num_paths_2}
    2|S| + \sum_{j \in D}(1+|S_j|)|S_{I(j)}|.
\end{equation}

We note that $|S|=\prod_{j \in C \cup D}|S_j|$ and that especially with a large number of nodes, the first term becomes impractically large in both \eqref{eq:num_paths} and \eqref{eq:num_paths_2}. The increase in the number of path-related constraints is exponential, while the increase in the rest of the constraints is often linear, as shown in the following two example problems.

\subsubsection{Pig farm}

For the pig farm example presented in \citet{lauritzen2001representing}, we observe that the problem consists of $3n+1$ decision and chance nodes, where $n$ is the number of decision stages, and that $|S_j|=2$ for all nodes $j \in C \cup D$. Note that this is slightly different to \citet{lauritzen2001representing}, where the length of the problem is tied to the number of health nodes. The length of a problem with $n$ decision nodes would then be $n+1$.

With these observations, $|S|=2^{3n+1}$ and $|D|=n$. Thus, the number of constraints in Eq. \eqref{eq:num_paths} becomes $(3+n)2^{3n+1} + 2n$ and the corresponding number in Eq. \eqref{eq:num_paths_2} becomes $2^{3n+2} + 6n$. 


\subsubsection{N-monitoring}

 We can perform a similar analysis for the N-monitoring example presented in \citet{salo2022}. The problem consists of $2n+2$ decision and chance nodes, where $n$ is the number of report-action pairs. As in the pig farm problem, $|S_j|=2$ for all nodes $j \in C \cup D$. 

With these observations, $|S|=2^{2n+2}$ and $|D|=n$. Thus, the number of constraints in Eq. \eqref{eq:num_paths} becomes $(3+n)2^{2n+2} + 2n$ and the corresponding number in Eq. \eqref{eq:num_paths_2} becomes $2^{2n+3} + 6n$.  

\subsection{Solution times}

% Figure environment removed

Figure \ref{fig:sol_times} shows the increase in average solution times over 50 instances as the number of decision stages increases in the two example problems. For the original formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin}, \citet{salo2022} show that solution times are greatly improved by adding a \emph{probability cut} $\sum_{s \in S} \pi(s) = 1$ as a lazy constraint to the model. A lazy constraint is a constraint that is added to the model formulation when it is deemed violated by an incumbent feasible solution found in the branch-and-cut tree search, instead of adding it from the beginning of the solution process. This approach is thus used in the computational experiments for the original formulation. For \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin}, a similar constraint is included in the formulation by default. However, we additionally analyze an instance of the the reformulated model \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin}, where constraint \eqref{eq:dp2_prob_sum} is implemented as a lazy constraint.

For both problems, it seems that the rate of increase in the solution times quickly renders the original formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} computationally intractable, as seen in Fig \ref{fig:sol_times}. This was also noted by \citet{salo2022} in their computational results. The solution times for the improved formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} using locally compatible path sets seem to increase at a slower rate than for the original formulation. %The behavior of both formulations for very small models with one or two decision nodes seems to be different from larger models, especially in the N-monitoring problem. This might indicate, e.g., that solver does not use branching for these very small models. 
Finally, the lazy probability cut that was found to improve solution times in \citet{salo2022} is detrimental to computational performance in the new formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin}. 

\begin{table}[ht]
\centering
\begin{tabular}{l|ll}
                & v0.1 & v1.2 \\ \hline
10th percentile & 15.4 & 1.00 \\
median          & 26.4 & 1.21 \\
90th percentile & 31.1 & 1.81 \\
mean            & 25.0 & 1.34
\end{tabular}
\caption{Statistics of the root relaxation quality relative to the optimal solution for 50 randomly generated pig farm problems with 5 decision stages. The solutions are scaled so that a value of 1 corresponds to the optimal solution.}
\label{tbl:stats}
\end{table}

In Table \ref{tbl:stats}, we present statistics on the LP relaxation quality. As discussed before, the hypothesis is that the formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} (implemented in v1.2 of the package) is considerably tighter than \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} (implemented in v0.1). The results from the pig farm problem strongly support this, as more than half of the LP relaxation solutions for the novel formulation are within 25\% of the optimal solution, while the solutions using \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} are orders of magnitude further from the optimal solution. 

% Figure environment removed

Figure \ref{fig:spu} shows the process of improving solutions in the single policy update (SPU) heuristic. For the 50 instances in this test set, the last solution is found within eight seconds, and the solution is the global optimum in all but one of the instances. Note that \citet{lauritzen2001representing} showed that this version of the pig farm problem is not soluble, and thus the SPU heuristic is not guaranteed to find the optimal solution. We observe that while the single policy update heuristic is successful in finding good initial solutions quickly, the effect of providing the solver with these initial solutions is negligible (see Figure \ref{fig:sol_times}). Thus, our results suggest that improving the LP relaxation bound has a much greater impact on improving the solution time.


