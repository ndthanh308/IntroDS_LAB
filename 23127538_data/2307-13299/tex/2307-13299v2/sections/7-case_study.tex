\section{Case study: optimal preventive healthcare for CHD} \label{sec:case_study}

One of the first frameworks for medical decision-making considering whether to treat, test or not treat was developed by \citet{pauker1980threshold}. This framework provides an analytical basis for optimal testing and treatment strategies. They developed two thresholds, referred to as ``testing'' and ``test-treatment'' thresholds. The thresholds are probability cut-offs and they divide subjects into three groups: if the risk of disease is below the ``testing'' threshold, treatment and testing should be withheld, if it is above the ``test-treatment'' threshold, treatment should be given and if the risk falls in between these thresholds then a diagnostic test should be performed and the treatment decision made based on its results. The thresholds are visualised in Figure \ref{fig:thresholds}. 
%
% Figure environment removed

In this case study we use decision programming to optimize the use of traditional and genetic testing to support the targeting of statin medication treatment for preventing coronary heart disease (CHD). This case study is replicated from \citet{hynninen2019value}, where the authors developed a testing and treatment strategy by optimizing net monetary benefit (NMB), a cost-benefit objective consisting of the health outcomes and testing costs within a 10-year time horizon. 

The decision process stems from the patient's state of health, represented by a chance event $H$ describing whether the patient will or will not have a CHD event in the following 10 years. The probability of a CHD event is assumed to be described by a prior risk estimate $R_0$ based on factors such as the age and sex of the patient. The likelihood of a correct prognosis can be improved by carrying out tests on traditional risk factors (TRS), genetic risk factors (GRS) or both. Based on their prognosis, a decision is made on whether a patient is subjected to preventive treatment with statin medication. 

In \citet{hynninen2019value}, six predefined testing and treatment strategies were evaluated independently. In each of these strategies, the optimal allocation of tests and treatment according to risk estimates was obtained by solving the associated decision tree (via dynamic programming). The six strategies considered in \citet{hynninen2019value} were: 
%
\begin{enumerate*}[label=(\roman*)]
    \item no tests and no treatment (‘No treatment’);
    \item using prior risk to allocate treatment (‘Treatment optimized’);
    \item performing TRS on optimized patient segment and allocating treatment based on updated risk estimates (‘TRS optimized’);
    \item performing GRS on optimized patient segment and allocating treatment based on updated risk estimates (‘GRS optimized’);
    \item performing TRS on optimized patient segment and based on its results performing GRS optimally to allocate treatment (‘TRS \& GRS optimized’);
    \item performing GRS on optimized patient segment and based on its results performing TRS optimally to allocate treatment (‘GRS \& TRS optimized’).
\end{enumerate*}

Essentially, this comprises determining optimal ``testing'' and ``test-treatment'' thresholds (cf. Figure 
\ref{fig:thresholds}) for TRS and GRS from the perspective of net monetary benefit (NMB) for each strategy (i-vi). Interestingly, the threshold values for GRS in \citet{hynninen2019value} were different than the ones found in the study presented in \citet{tikkanen2013genetic}. This is due to the different perspectives – pure patient welfare versus NMB – that the studies were conducted from. For example, the national health care guidelines for allocating treatment were not considered in the optimization in \citet{hynninen2019value}. This showcases that the two thresholds described in \citet{pauker1980threshold} are not unique for a given disease and prognostic test because the perspective of the study affects the threshold values.

Analogously, our decision programming model determines an optimal decision strategy for allocating preventative care for CHD. The data and structure of the problem are the same as those utilised in \citet{hynninen2019value}. However, due to the flexibility of decision programming, the strategies (i-vi) do not need to be explicitly predefined. Instead, we can optimize the design of the strategy itself simultaneously with the threshold values, meaning that all of these strategies are within the feasible solutions of the model. 

The problem setting is such that the patient is assumed to have a prior risk estimate $R_0$. A risk estimate is a prediction of the patient’s chance of having a CHD event in the next ten years. The risk estimates are grouped into risk levels, which range from 0\% to 100\% with a suitable discretization, e.g., $S_{R_0}=\{0\%, 1\%, ..., 99\%, 100 \% \}$. We note that it might be beneficial to consider a less trivial discretization that is finer in the region where most of the probability mass is assumed to lie and coarser elsewhere. Nevertheless, we chose to proceed as such since it requires no information on the probability distributions. The first testing decision $T_1$ is made based on the prior risk estimate. This entails deciding whether to perform TRS or GRS or if no testing is needed. If a test is conducted, the risk estimate is updated ($R_1$) and based on the new information a second testing decision $T_2$ follows. It entails deciding whether further testing should be conducted or not. The second testing decision is constrained so that the same test which was conducted in the first stage cannot be repeated. If a second test is conducted, the risk estimate is updated again ($R_2$). The treatment decision $T_D$ – dictating whether the patient receives preventive statin medicine or not – is made based on the resulting risk estimate of this testing process. Note that if no tests are conducted, the treatment decision is made based on the prior risk estimate. Figure \ref{fig:CHD_influence_diagram} provides an influence diagram for the decision problem. 

% Figure environment removed

Node $H$ represents the uncertainty of whether the patient has a CHD event or remains healthy during the 10-year time frame. Node $H$ has the prior risk level $R_0$ in its information set because a premise of the modeling proposed in \citet{hynninen2019value} is that the prior risk accurately describes the
probability of having a CHD event, i.e., 
%
\begin{equation*}
    P(H = \text{CHD} \mid R_0=\alpha)=\alpha.
\end{equation*}
%
On the other hand, nodes $R_1$ and $R_2$ represent the updated risk level after the first and second test decisions, respectively. If a test is conducted, the risk estimate is updated using the Bayes' rule
%
\begin{equation*}
    P(\text{CHD} \mid \text{test result}) = \frac{ P(\text{test result} \mid \text{CHD}) \times P(\text{CHD}) }{P(\text{test result})},
\end{equation*}
%
where the conditional probabilities $P(\text{test result}) \mid \text{CHD})$ are from \citet{abraham2016genomic} and the probability of having a CHD event, denoted by $P(\text{CHD})$, is the prior risk level $R_0$ or the updated risk level $R_1$, depending on whether it is the first or second test in question. The denominator $P(\text{test result})$ is calculated as a sum of the numerator and $P(\text{test result} \mid \text{no CHD}) \times  P(\text{no CHD})$, where $P(\text{no CHD}) = 1 - P(\text{CHD})$. As the states of nodes $R_i$, $i \in \{0,1,2\}$, represent risk levels, the probability of a state in these nodes is the probability of the given test updating the risk estimate to that level from the previous estimate.

The first and second testing decisions are represented by $T_1$ and $T_2$, respectively. Since conducting the same test twice is forbidden, all paths where the same test is repeated in $T_1$ and $T_2$ are included in the set of forbidden paths (cf. Section \ref{sec:formulations}). Furthermore, the forbidden paths include all paths where the first testing decision $T_1$ is to not perform testing but then the second testing decision $T_2$ is to perform a test. This is because the information yielded from performing only one test is not affected by whether the test is performed in the first or second stage of testing. Therefore, forbidding the paths where no test is performed in $T_1$ and TRS or GRS is performed in $T_2$ reduces redundancy in the model without information loss. The final treatment decision is represented by node $T_D$, where the options are to provide or withhold treatment. The treatment decision is made based on the updated risk estimate represented by node $R_2$.

Since the first node in the influence diagram presented in Figure \ref{fig:CHD_influence_diagram} is the chance node $R_0$, any decision strategy would be conditioned on its realisation. This leads to a natural separability of the problem, meaning that it can be solved for individual risk levels $0\%, 1\%, \dots 100\%$. This has the benefit of allowing the calculations to be parallelised, at the expense of potentially causing inconsistencies related to e.g., multiple solutions in the MIP problem or rounding-induced errors.

An interesting result is that the optimal strategy found by our model is the same strategy that was deemed the best among strategies (i-vi) in \citet{hynninen2019value}. In a way, this provides optimality guarantees to their results, which, in principle, they could not have determined without exhaustively testing all possible (9) testing strategies. In addition, the optimal threshold from our model corresponded closely to those in \citet{hynninen2019value}. Figure \ref{fig:CHD_result} illustrates the strategy obtained by our model, indicating also the thresholds found in \citet{hynninen2019value} for comparison. We are confident that the small differences in the threshold values are simply artefacts related to the way the discretization (i.e., rounding) was performed.

% Figure environment removed

