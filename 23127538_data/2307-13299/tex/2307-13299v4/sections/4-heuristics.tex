\section{Primal heuristic: single policy update (SPU)} 
\label{sec:heuristics}

While our approach of formulating influence diagrams into mixed-integer linear models does allow us to use powerful off-the-shelf solvers, it is still hindered by the well-known fact that solving such problems is NP-hard \citep{schrijver2003combinatorial}. To make MIP solvers more efficient, \emph{primal heuristics} are used to obtain and improve integer solutions. Obtaining good starting integer solutions can have a significant impact on the performance of branch-and-bound solvers, as it helps in pruning poor-quality solutions early.

Decision programming is based on limited-memory influence diagrams (LIMIDs) and solution approaches presented in previous literature can be used to obtain solutions to these problems. A notable contribution of \citet{lauritzen2001representing} is the single policy update (SPU) heuristic for obtaining ``locally optimal'' strategies in the sense that the corresponding solutions cannot be improved by changing only one of the local strategies $Z_j(s_{I(j)})$.  

Our proposed heuristic is loosely based on the ideas in \citet{lauritzen2001representing}, as described in Algorithm \ref{alg:spu}. The first step of the heuristic is to obtain a random strategy $Z$ (note that this too is a heuristic, albeit a very simple one). Additionally, we initialise the $lastImprovement$ variable that will be used to stop the algorithm after finding a local optimum. The strategy $Z$ is then iteratively improved by examining each information state $s_{I(j)} \in S_{I(j)}$ for each decision node $j \in D$ in order, choosing the local strategy $Z'_j(s_{I(j)})$ maximising the expected utility. We obtain incrementally improving strategies by replacing the local strategy $Z_j(s_{I(j)})$ with $Z'_j(s_{I(j)})$ whenever the change results in an increase in expected utility. Finally, the pair $(j, s_{I(j)})$ is stored in the $lastImprovement$ variable if an improvement has been observed.

\begin{algorithm}
\caption{The single policy update heuristic}\label{alg:spu}
% \KwData{$n \geq 0$}
% \KwResult{$y = x^n$}
$Z \gets randomstrategy()$\;
$lastImprovement \gets (undef, undef)$\;
\While{true }{
    \For{$j \in D$, $s_{I(j)} \in S_{I(j)}$}{
        \eIf{$(j,s_{I(j)}) = lastImprovement$}{
            \KwRet{$Z$}\;
        }{
            $Z'_j(s_{I(j)}) \gets bestLocalStrategy(Z,j,s_{I(j)})$\;
            $Z' \gets modifyStrategy(Z,Z'_j(s_{I(j)}))$\;
            \If{$EU(Z') > EU(Z)$}{
                $Z \gets Z'$\;
                $lastImprovement \gets (j, s_{I(j)})$\;
            }
        }
    }
}
\end{algorithm}

This process of locally improving the strategy is performed repeatedly for all pairs $(j, s_{I(j)})$ until no improvement is made during a whole iteration through the set of such pairs, that is, $(j, s_{I(j)}) = lastImprovement$. The number of possible strategies $Z$ is finite, and the algorithm thus converges in a finite number of iterations. It is also easy to see that at termination, there is no possible local improvement and the strategy $Z$ is thus, in that sense, locally optimal. \citet{lauritzen2001representing} show that for \emph{soluble} LIMIDs, this heuristic results in a globally optimal solution. However, influence diagrams are not generally soluble. The performance of the heuristic is explored in Section \ref{sec:computational_experiments}.

