\section{Computational experiments} \label{sec:computational_experiments}

We present a collection of computational experiments carried out to assess the performance of the proposed reformulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} against the original formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} presented in \citet{salo2022}. % Hereinafter, we use v1.2 to refer to our proposed model version as presented in \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} and v0.1 to refer to \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin}. These refer to the versions of the \texttt{DecisionProgramming.jl} \citep{oliveira_2023_8405287} package these formulations are available in. 
In addition, we present computational results highlighting the performance of the proposed SPU heuristic. The problems used for testing are (i) the pig farm problem originally from \citet{lauritzen2001representing} modified to allow for artificially augmenting the number of time periods and generating input parameters randomly; (ii) the N-monitoring problem, as proposed in \citet{salo2022}, in which we also can artificially augment the number of decision agents and randomly generate instances. These two problems have a major difference in their structure: while the N-monitoring problem has $N$ decisions in parallel with no communication between the decision-makers, the pig farm problem is a partially observed Markov decision process (POMDP) where decisions are made in series with limited memory of the past. This structural difference leads to the N-monitoring problem having a larger treewidth, which has generally been an issue for solving influence diagrams \citep{maua2012solving}.
%
% Figure environment removed

The pig farm problem is presented in Figure \ref{fig:pigfarm}, where nodes $H_i$ represent the health of a pig, nodes $T_i$ represent the result of a diagnostic test, and nodes $D_i$ correspond to treatment decisions. Treating a pig incurs a cost represented by the value nodes $U_i$ for $i \in \{1,2,3\}$ and in the end, the pig can be sold for a price depending on the final health state. This problem was chosen for the computational comparison because similar low treewidth structures frequently arise in contexts such as quality control \citep{cobb2024intermittent} or testing and treating patients for a disease \citep{hynninen2019value}, discussed in Section \ref{sec:case_study} of this paper. 

All experiments are run using 16GB of memory and 8 threads on an Intel Xeon Gold 6248 CPU and the code can be found in \\ \href{https://github.com/gamma-opt/DecisionProgramming.jl/tree/new-formulation-experiments}{https://github.com/gamma-opt/DecisionProgramming.jl/tree/new-formulation-experiments}.

\subsection{Problem size}

First, we compare the model sizes of the two formulations presented in Sections \ref{sec:decision_programming} and \ref{sec:formulations}. In both formulations, the number of variables is the same. There are $\sum_{j \in D} |S_j||S_{I(j)}|$ $z$-variables and $|S|$ path variables, either $\pi$ or $x$, depending on the formulation. As for the number of constraints, the formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} has $\sum_{j \in D}|S_{I(j)}|$ constraints \eqref{eq:dp_z_sum}, $2|S|$ bounds for $\pi$-variables, $|D||S|$ constraints \eqref{eq:dp_pi_upper} and $|S|$ constraints \eqref{eq:dp_pi_lower}. Arranging the terms, the total number of constraints becomes 
\begin{equation}
    \label{eq:num_paths}
    (3+|D|)|S| + \sum_{j \in D}|S_{I(j)}|.
\end{equation}

The formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} has $\sum_{j \in D}|S_{I(j)}|$ constraints \eqref{eq:dp2_z_sum}, $\sum_{j \in D}|S_j||S_{I(j)}|$ constraints \eqref{eq:dp2_x_upper}, one constraint \eqref{eq:dp2_prob_sum} and $2|S|$ bounds for $x$-variables. Arranging the terms, the total number of constraints becomes 
\begin{equation}
    \label{eq:num_paths_2}
    2|S| + \sum_{j \in D}(1+|S_j|)|S_{I(j)}|.
\end{equation}

We note that $|S|=\prod_{j \in C \cup D}|S_j|$ and that especially with a large number of nodes, the first term becomes impractically large in both \eqref{eq:num_paths} and \eqref{eq:num_paths_2}. The increase in the number of path-related constraints is exponential, while the increase in the rest of the constraints is often linear, as shown in the following two example problems.

\subsubsection{Pig farm}

For the pig farm example presented in \citet{lauritzen2001representing}, we observe that the problem consists of $3n+1$ decision and chance nodes, where $n$ is the number of decision stages, and that $|S_j|=2$ for all nodes $j \in C \cup D$. Note that this is slightly different to \citet{lauritzen2001representing}, where the length of the problem is tied to the number of health nodes. The length of a problem with $n$ decision nodes would then be $n+1$.

With these observations, $|S|=2^{3n+1}$ and $|D|=n$. Thus, the number of constraints in Eq. \eqref{eq:num_paths} becomes $(3+n)2^{3n+1} + 2n$ and the corresponding number in Eq. \eqref{eq:num_paths_2} becomes $2^{3n+2} + 6n$. 


\subsubsection{N-monitoring}

 We can perform a similar analysis for the N-monitoring example presented in \citet{salo2022}. The problem consists of $2n+2$ decision and chance nodes, where $n$ is the number of report-action pairs. As in the pig farm problem, $|S_j|=2$ for all nodes $j \in C \cup D$. 

With these observations, $|S|=2^{2n+2}$ and $|D|=n$. Thus, the number of constraints in Eq. \eqref{eq:num_paths} becomes $(3+n)2^{2n+2} + 2n$ and the corresponding number in Eq. \eqref{eq:num_paths_2} becomes $2^{2n+3} + 6n$.  

\subsection{Solution times}

% Figure environment removed

Figure \ref{fig:sol_times} shows the increase in average solution times over 50 instances as the number of decision stages increases in the two example problems. For the original formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin}, \citet{salo2022} show that solution times are greatly improved by adding a \emph{probability cut} $\sum_{s \in S} \pi(s) = 1$ as a lazy constraint to the model. A lazy constraint is a constraint that is added to the model formulation when it is deemed violated by an incumbent feasible solution found in the branch-and-cut tree search, instead of adding it from the beginning of the solution process. This approach is thus used in the computational experiments for the original formulation. For \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin}, a similar constraint is included in the formulation by default. However, we additionally analyze an instance of the the reformulated model \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin}, where constraint \eqref{eq:dp2_prob_sum} is implemented as a lazy constraint.

For both problems, it seems that the rate of increase in the solution times quickly renders the original formulation \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} computationally intractable, as seen in Fig \ref{fig:sol_times}. This was also noted by \citet{salo2022} in their computational results. The solution times for the improved formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} using locally compatible path sets seem to increase at a slower rate than for the original formulation. Interestingly, the solution times are similar for both problems, suggesting that the treewidth does not have a significant impact on the computational performance, unlike for the methods discussed in \citet{lauritzen2001representing} or \citet{maua2012solving}. %The behavior of both formulations for very small models with one or two decision nodes seems to be different from larger models, especially in the N-monitoring problem. This might indicate, e.g., that solver does not use branching for these very small models. 
Finally, the lazy probability cut that was found to improve solution times in \citet{salo2022} is detrimental to computational performance in the new formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin}. 

In Table \ref{tbl:stats}, we present statistics on the quality of the LP relaxation. As discussed before, the hypothesis is that the formulation \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} is considerably tighter than \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin}. The results from the pig farm problem strongly support this, as more than half of the LP relaxation solutions for the novel formulation are within 25\% of the optimal solution, while the solutions using \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} are orders of magnitude further from the optimal solution. 

\begin{table}[ht]
\centering
\begin{tabular}{l|ll}
                & \eqref{eq:dp_obj}-\eqref{eq:dp_z_bin} & \eqref{eq:dp2_obj}-\eqref{eq:dp2_z_bin} \\ \hline
10th percentile & 15.4 & 1.00 \\
median          & 26.4 & 1.21 \\
90th percentile & 31.1 & 1.81 \\
mean            & 25.0 & 1.34
\end{tabular}
\caption{Statistics of the root relaxation quality relative to the optimal solution for 50 randomly generated pig farm problems with 5 decision stages. The solutions are scaled so that a value of 1 corresponds to the optimal solution.}
\label{tbl:stats}
\end{table}

% Figure environment removed

Figure \ref{fig:spu} shows the process of improving solutions in the single policy update (SPU) heuristic. For the 50 instances in this test set, the last solution is found within eight seconds, and the solution is the global optimum in all but one of the instances. Note that \citet{lauritzen2001representing} showed that this version of the pig farm problem is not soluble, and thus the SPU heuristic is not guaranteed to find the optimal solution. We observe that while the single policy update heuristic is successful in finding good initial solutions quickly, the effect of providing the solver with these initial solutions is negligible (see Figure \ref{fig:sol_times}). Thus, our results suggest that improving the LP relaxation bound has a much greater impact on improving the solution time.


