\documentclass[11pt]{amsart}
\usepackage[margin=3cm]{geometry}
\title{Geometric Ergodicity and Wasserstein Continuity of 
Non-Linear Filters}

\author{Yunus Emre Demirci}
\address{Queen's University, Department of Mathematics and Statistics, Kingston, Ontario, Canada}
 \email{21yed@queensu.ca}
 
\author{Serdar YÃ¼ksel}
\address{Queen's University, Department of Mathematics and Statistics, Kingston, Ontario, Canada} 
 \email{yuksel@queensu.ca}  
 
\RequirePackage{amsthm,amsmath,amsfonts,amssymb}
\RequirePackage[numbers]{natbib}
\usepackage{enumitem}
\usepackage{verbatim}
\newcommand{\no}{\noindent}
 \newcommand{\su}{\textnormal{supp }}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\ena}{\end{eqnarray}}
\newcommand{\beas}{\begin{eqnarray*}}
\newcommand{\enas}{\end{eqnarray*}}
\newcommand{\beq}{\begin{equation}}
\newcommand{\enq}{\end{equation}}
\def\qed{\hfill \mbox{\rule{0.5em}{0.5em}}}
\newcommand{\bbox}{\hfill $\Box$}
\newcommand{\Lip}{\operatorname{Lip}}
\newtheorem{problem}{Problem}[section]
\newtheorem{exercise}{Exercise}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{solution}{Solution}[section]
\newtheorem{case}{Case}[section]
\newtheorem{condition}{Condition}[section]
\newtheorem{defn}{Definition}[section]
\newtheorem{asm}{Assumption}[section]
\newtheorem{eg}{Example}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{soln}{Solution}[section]
\newtheorem{propn}{Proposition}[section]
\newtheorem{ex}{Exercise}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{pb}{Problem}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{rmk}{Remark}[section]
\newtheorem{note}{Note}[section]
\newtheorem{notes}{Notes}[section]
\newtheorem{readingex}{Reading exercise}[section]
\newcommand{\pf}{\noindent {\bf Proof:} }
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\normx[1]{\Vert#1\Vert}
\newcommand{\T}{\mathcal{T}}
\newcommand{\X}{\mathbb{X}}
\newcommand{\Y}{\mathbb{Y}}
\newcommand{\U}{\mathbb{U}}
%\RequirePackage[authoryear]{natbib}%% uncomment this for author-year citations
%\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}%% uncomment this for coloring bibliography citations and linked URLs
%\RequirePackage{graphicx}%% uncomment this for including figures

\usepackage{color}
\newcommand{\sy}[1]{{\color{magenta} #1}}


\keywords{Non-linear filtering, unique ergodicity, filter stability}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\title{A sample article title with some additional note\thanksref{T1}}


\begin{abstract}   
    In this paper, we present conditions for the geometric ergodicity 
    and Wasserstein regularity
    of non-linear filter processes, 
    which has received little attention in the literature. 
    While previous studies in the field of non-linear 
    filtering have mainly focused on unique ergodicity 
    and the weak Feller property, our work 
    extends these findings in three main directions:
    (i) We present conditions on the geometric ergodicity 
    of non-linear filters, 
    (ii) we obtain further conditions on unique ergodicity 
    for the case where the state space is compact, and 
    (iii) as a by-product of our analysis, we obtain 
    Wasserstein continuity of non-linear filters with stronger regularity. 
    We present a detailed comparison with the literature. 
    Finally, we study the controlled setup, 
    and as an application of our geometric 
    ergodicity results we present new 
    conditions on the existence of solutions 
    to the average cost optimality equation.
\end{abstract}


\maketitle

\section{Introduction}

The study of the long-term behavior of hidden Markov models is a classical problem; Blackwell \cite{blackwell1959entropy} studied the entropy rate of the stochastic process defined by $Y_n = h(X_n)$, where $h$ is a non-invertible function and $(X_n)_{n\geq 0}$ is a 
stationary Markov chain. With the filter process \( (\pi_n)_{n\geq 0}\), defined as \(\pi_n := P(X_n \in \cdot | Y_1,..., Y_n)\). 
Blackwell's work raised the question of whether the filter process has a unique stationary measure, or in other words, 
whether it is uniquely ergodic. Blackwell conjectured that this was the case for irreducible underlying Markov chains, 
but a counterexample by Kaijser\cite{Kaijser} showed that this conjecture was incorrect. The problem of fully characterizing the unique ergodicity of the filtering process has since then received significant attention. On the other hand, there has been significant interest in the related filter stability problem,
which refers to the property that the filter process 
becomes nearly independent of its (possibly incorrect) initialization
 as the number of steps $n$ approaches infinity. It has been proved 
that when the $(X_n)_{n\geq0}$ signal is ergodic, 
the filter stability and the unique ergodicity 
of the filter are closely related properties 
\cite{Budhiraja, DiMasiStettner2005ergodicity, Stettner1989}.

As we will see in our detailed literature review, while the unique ergodicity problem has been studied extensively, 
often by relating it to filter stability as noted above, there has been no study, to our knowledge, on the geometric 
ergodicity of non-linear filters. Our paper addresses this gap.

In our study, we assume that the state space of the hidden Markov 
model is a compact space and the observation space is a Polish space.
A crucial step in our analysis toward geometric ergodicity is to establish the 
Wasserstein continuity and equi-continuity of non-linear filters, which we present as 
a separate contribution; this generalizes recent studies on weak Feller continuity of non-linear filters.
Additionally, we establish new conditions that ensure unique ergodicity. 

\section{Notation and preliminaries}
Let $(\mathbb{X}, d)$ denote a compact metric space which is the state space of a partially observed Markov process. Let $\mathbb{B}(\mathbb{X})$ be its Borel $\sigma$-field. We denote by $\mathcal{Z}:=\mathbb{P}(\mathbb{X})$ the set of probability measures on $(\mathbb{X}, \mathbb{B}(\mathbb{X}))$ under the weak topology. Let $\mathbb{P}(\mathcal{Z})$ denote the probability measures on $\mathcal{Z}$, equipped with the weak topology. Let $\mathbb{C}(\mathbb{X})$ be the set of all continuous, bounded functions on $\mathbb{X}$. We let $\mathcal{T}$ be the transition kernel of the model which is a stochastic kernel from $\mathbb{X}$ to $\mathbb{X}$. Here and throughout the paper $\mathbb{N}$ denotes the set of positive integers. Let $D$ denote the diameter of $\mathbb{X}$, defined as $D = \operatorname{diam}(\mathbb{X}) := \sup\{d(x, y) \mid x, y \in \mathbb{X}\}$.

Let $\mathbb{Y}$ denote a Polish space denoting the observation space of the model, and let the state be observed through an observation channel $Q$. $Q(\cdot \mid x)$ is a probability measure on $\mathbb{Y}$ for every $x \in \mathbb{X}$, and $Q(A \mid \cdot): \mathbb{X} \rightarrow[0,1]$ is a Borel measurable function for every $A \in B(\mathbb{Y})$. 
The update rules of the system are determined by $\mathcal{T}$ and $Q$:
$$
\operatorname{Pr}\left(\left(X_0, Y_0\right) \in B\right)=\int_B \mu\left(d x_0\right) Q\left(d y_0 \mid x_0\right), \quad B \in \mathcal{B}(\mathbb{X} \times \mathbb{Y})
$$
where $\mu$ is the (prior) distribution of the initial state $X_0$, and
$$
\operatorname{Pr}\left(\left(X_n, Y_n\right) \in B \mid(X, Y)_{[0, n-1]}=(x, y)_{[0, n-1]}\right)=\int_B \mathcal{T}\left(d x_n \mid x_{n-1}\right) Q\left(d y_n \mid x_n\right),
$$
$B \in \mathcal{B}(\mathbb{X} \times \mathbb{Y})$, $n \in \mathbb{N}$.

\begin{defn}
The filter process is defined as the sequence of conditional probability measures $\pi_n^{\mu}(\cdot)=P^{\mu}\left(X_n \in \cdot \mid Y_{[0, n]}\right), n \in \mathbb{N}$
where $P^{\mu}$ is the probability measure induced by the prior $\mu$.
\end{defn}

Any POMP (partially observed Markov Process) can be reduced to a completely observable Markov process \cite{Rhe74, Yus76}, whose states are the filter process, where the state at time $n$ is $\mathbb{P}(\mathcal{Z})$-valued
$$
\operatorname{Pr}\left\{X_n \in \cdot \mid Y_0, \ldots, Y_n\right\}.
$$


The transition probability $\eta$ of the filter process can be constructed with
$$
F(z, y):=\operatorname{Pr}\left\{X_{n+1} \in \cdot \mid Z_n=z, Y_{n+1}=y\right\}
$$
from $\mathcal{Z}\times \mathbb{Y}$ to $\mathcal{Z}$
as follows:
\begin{align}\label{etatra}
\eta(\cdot \mid z)=\int_{\mathbb{Y}} 1_{\{F(z, y) \in \cdot\}}P(dy|z)= \int 1_{\{F(z, y) \in \cdot\}}Q(dy_{n+1}|x_{n+1})T(dx_{n+1}|x_n)z(dx_n).
\end{align}

Hence, the filter process is a completely observable Markov process with the state space $\mathcal{Z}$ and transtion kernel $\eta$.

\begin{defn}\label{Dobrushincoefficient}[\cite{dobrushin1956central}, Equation 1.16.] For a kernel operator $K: S_1 \rightarrow \mathcal{P}\left(S_2\right)$ 
we define the Dobrushin coefficient as:
$$
\delta(K)=\inf \sum_{i=1}^n \min \left(K\left(x, A_i\right), K\left(y, A_i\right)\right)
$$
where the infimum is over all $x, y \in S_1$ and all partitions $\left\{A_i\right\}_{i=1}^n$ of $S_2$.
\end{defn}

A sequence of probability measures $\left\{\mu_{n}\right\}_\mathbb{N}$ from $\mathcal{Z}$ converges weakly to $\mu \in \mathcal{Z}$ if for every bounded continuous function $f: \mathbb{X} \to \mathbb{R}$,
$$
\int_{\mathbb{X}} f(x) \mu_{n}(d x) \rightarrow \int_{\mathbb{X}} f(x) \mu(d x) \quad \text { as } \quad n \rightarrow \infty .
$$
We note that $\mathcal{Z}$ itself is a Polish space with respect to the topology of weak convergence for probability measures when $\mathbb{X}$ is a complete, separable and metric space \cite[ Chapter 2, section 6]{Par67}. 

A sequence of probability measures $\left\{\mu_{n}\right\}_\mathbb{N}
$ from $\mathcal{Z}$ converges in total variation to $\mu \in \mathcal{Z}$ if
$$
\sup _{A \in \mathbb{B}(\mathbb{X})}\left|\mu_{n}(A)-\mu(A)\right| \rightarrow 0 \text { as } n \rightarrow \infty .$$

One way to metrize $\mathcal{Z}$ under the weak convergence topology is via the bounded Lipschitz metric (\cite{villani2008optimal}, p.109) defined as follows 

\begin{align}\label{boundedlip}
&\rho_{BL}(\mu, \nu) :=\sup \left\{\int_{\mathbb{X}} f(x) \mu(d x)-\int_{\mathbb{X}} f(x) \nu(d x) : f \in \operatorname{BL_1}(\mathbb{X}) \right\},
\end{align}
$\mu, \nu \in \mathcal{Z}$, where
\begin{align*}
\operatorname{BL}_1(\mathbb{X}):=\left\{f: \mathbb{X} \mapsto \mathbb{R},
\norm{f}_{\infty}+\norm{f}_{L}\leq 1 \right\}, \; \norm{f}_{\infty}=\sup_{x\in \mathbb{X}}|f(x)|,
\; \norm{f}_{L}=\sup_{x\neq y} \frac{|f(x)-f(y)|}{d(x,y)}.
\end{align*}

By, e.g., [10], if $(X, d)$ is compact, then
the space of probability measures 
$P(X)$ equipped with the bounded Lipschitz metric 
is also a compact metric space.

When $\mathcal{X}$ is compact, the Kantorovich-Rubinstein metric (equivalent to the Wasserstein metric of order $1$) (\cite{Bog07}, Theorem 8.3.2) is another metric that metrizes the weak topology on $\mathcal{Z}$.

\begin{align}\label{defkappanorm}
&W_1(\mu, \nu):=\sup \left\{\int_{\mathbb{X}} f(x) \mu(d x)-\int_{\mathbb{X}} f(x) \nu(d x) : f \in \operatorname{Lip}(\mathbb{X}) \right\},
\end{align}
$\mu, \nu \in \mathcal{Z}$, where
\begin{align*}
\operatorname{Lip}(\mathbb{X})=\{f:\mathbb{X}\to \mathbb{R},\; \norm{f}_{L}\leq 1\}.
\end{align*}

\section{Main Results and Literature Review}

We will start by presenting our main results
before exploring the literature. 

\subsection{Our contributions} 

Our results concern regularity, unique ergodicity, 
and geometric ergodicity of non-linear filters. 

\begin{asm} \label{asm1}
\begin{enumerate}[label=(\roman*)]
\item  $(\mathbb{X},d)$ is a bounded compact metric space. 
The diameter of $\mathbb{X}$ is denoted by $D$ 
and is defined as $D=\sup_{x,y \in \mathbb{X}} (d(x,y))$.
\item There exists $\alpha\in R^+$ such that 
$\left\|\mathcal{T}(\cdot \mid x)-\mathcal{T}\left(\cdot \mid x^{\prime}\right)\right\|_{T V} \leq d(x,x^{\prime}) \alpha$
for all $x,x' \in \mathbb{X}$.
\item $\alpha D (3-2\delta(Q)) < 2$.
\end{enumerate}
\end{asm}

We note that Assumption \ref{asm1}(ii) implies, by \cite{KSYWeakFellerSysCont}, the weak Feller property of the non-linear filtering kernel $\eta$ defined in (\ref{etatra}).

Before proceeding to our main theorems, let us first provide some definitions related to ergodicity.

\begin{defn}
    A Markov chain or transition kernel of a 
    Markov model is said to be uniformly ergodic 
    if there exists a probability measure 
    $\mu\in P(\mathbb{X})$ such that 
    \begin{align*}
    \sup_{x\in\mathbb{X}} \norm{P^{\delta_x}(X_n\in \cdot)-\mu}_{TV}\to 0
    \quad \text{as } n\to \infty.
    \end{align*}
    
\end{defn}

\begin{defn}
    A Markov chain or transition kernel of a 
    Markov model is said to be strongly ergodic if 
    there exists a probability measure 
    $\mu\in P(\mathbb{X})$ such that
    \begin{align*}
        \norm{P^{\delta_x}(X_n\in \cdot)-\mu}_{TV}\to 0
        \quad \text{as } n\to \infty \text{ for all } x\in \mathbb{X}.
    \end{align*} 
\end{defn}

\begin{defn}
    A Markov chain or transition kernel of a 
    Markov model is said to be 
    (uniformly) geometrically
    Wasserstein ergodic if 
    there exists a probability measure 
    $\mu\in P(\mathbb{X})$ and $\rho > 1$ such that 
    \begin{align*}
        \sup_{x\in \mathbb{X}} \rho^n W_1(P^{\delta_x}(X_n\in \cdot), \mu)\to 0
        \quad \text{as } n\to \infty.
    \end{align*} 
\end{defn}

\begin{asm}\label{ErgodicityHMM}
\begin{enumerate}[label=(\roman*)]
\item $(\mathbb{X},d)$ is a compact metric space. 
\item Assumption \ref{asm1}-ii is fulfilled.
\item The transition kernel $\mathcal{T}$ is uniformly ergodic. 
\end{enumerate}
\end{asm}

\begin{asm} \label{Con} 
$\mathbb{Y}$ is countable and there exists an observation realization $\bar{y} \in \mathbb{Y}$ such that for some positive $\epsilon$, $Q(\bar{y}|x)>\epsilon$ for every $x\in X$. 
\end{asm}

\begin{comment}
\begin{asm} \label{ContinuosY} 
    $\mathbb{Y}$ is a Polish space with 
    $\sigma$-finite reference measure $\varphi$. 
    $g(x,y)$ is the density
    function of the transition kernel $Q$ 
    with respect to reference measure 
    $\varphi$, i.e $Q(A|x) = \int_A g(x,y) \varphi(dy)$.
    \begin{enumerate}[label=(\roman*)]
    \item There exists an observation realization $\bar{y} \in \mathbb{Y}$ such that 
    for some positive $\epsilon$, 
    $g(x,y)>\epsilon$ for all $x\in X$. 
    \item The family of functions $\{g(x,\cdot): x \in \mathbb{X}\}$ 
    is equicontinuous at $\bar{y}$. 
    \end{enumerate}
\end{asm}
\end{comment}

Our main results are as follows:
\begin{thm}[\bf{Geometric Ergodicity}]\label{Main} Under Assumption \ref{asm1}, 
    the filter process is geometrically Wasserstein ergodic. 
\end{thm}
Indeed, this result is novel, 
as previous works have primarily focused 
on either unique ergodicity or strong 
ergodicity, without addressing geometric 
ergodicity. The concept of 
geometric ergodicity provides a more refined 
notion of convergence, taking into account the 
rate at which the Markov chain approaches 
its stationary distribution. 

\begin{thm}[\bf{Unique Ergodicity}]\label{Main2} 
    Under Assumptions \ref{ErgodicityHMM} and \ref{Con},
    the filter process is 
    (i) uniquely ergodic 
    and 
    (ii) converges weakly to the unique stationary 
    distribution for any prior distribution.
\end{thm}

For the case with finite $\mathbb{X}$, consider 
the discrete metric $d$ 
defined as follows:
$$d\left(x, x^{\prime}\right)= \begin{cases}1 & \text { if } x \neq x^{\prime} \\ 0 & \text { if } x=x^{\prime}.\end{cases}$$
With this choice of metric, the diameter $D$ is equal to $1$.
By Dobrushin's contraction theorem 
\cite{dobrushin1956central}, we have 
$\norm{\mathcal{T}(\cdot \mid x)-\mathcal{T}\left(\cdot \mid x^{\prime}\right)}_{TV} \leq d(x,x^{\prime}) (1-\delta(T))$.
Hence, we can choose $\alpha$ to be $1-\delta(T)$, 
leading to the following result.

\begin{corollary}\label{speccor}
    If $\mathbb{X}$ is finite and $(1-\delta(T))(3-2\delta(Q)) < 2$ 
    then the filter process is geometrically Wasserstein ergodic.
\end{corollary}

\begin{eg}\label{ex1}
    Let $\mathbb{X}=\{0, 1, 2, 3\}$, $\mathbb{Y}=\{0, 1\}$, $\epsilon \in (0,1)$ and let the transition and measurement matrices be given by
    \begin{align}
    \mathcal{T}=\left(\begin{array}{cccc}
    1/2 & 1/3 & 1/6 & 0 \\
    0 & 1/2 & 0 & 1/2 \\
    1/2 & 0 & 0 & 1/2 \\
    1/3 & 1/3 & 1/3 & 0
    \end{array}\right)
    \quad 
    Q=\left(\begin{array}{ccc}
    1-\epsilon & \epsilon\\
    1-\epsilon & \epsilon \\
    \epsilon & 1-\epsilon\\
    \epsilon & 1-\epsilon
    \end{array}\right),
    \end{align}
\end{eg}
where $\epsilon > 0$. Since $\delta(T)=1/3$ and $\delta(Q)>0$, 
Example \ref{ex1} satisfies the condition 
$(1-\delta(T))(3-2\delta(Q))<2$ stated in 
Corollary \ref{speccor}. Therefore, we can 
conclude that the filter process associated 
with Example \ref{ex1} is geometrically Wasserstein ergodic.

From Theorem \ref{Main2}, we derive:

\begin{corollary}\label{Main2Cor}
If $\mathbb{X}$ is finite and Assumptions \ref{Con} and 
\ref{ErgodicityHMM}-iii are met, 
the filter process is uniquely ergodic.
\end{corollary}

\begin{eg}\label{ex2}
    Let $\mathbb{X}=\{0, 1, 2, 3\}$, $\mathbb{Y}=\{0, 1\}$, $\epsilon, p\in (0,1)$, $p\neq 1/2$ and let the transition and measurement matrices be given by
    \begin{align}
    \mathcal{T}=\left(\begin{array}{cccc}
    p & 0 & 1-p & 0 \\
    0 & 1/2 & 0 & 1/2 \\
    1/2 & 0 & 0 & 1/2 \\
    0 & 1/2 & 1/2 & 0
    \end{array}\right)
    \quad 
    Q=\left(\begin{array}{ccc}
    1-\epsilon & \epsilon\\
    1-\epsilon & \epsilon \\
    \epsilon & 1-\epsilon\\
    \epsilon & 1-\epsilon
    \end{array}\right)
    \end{align}
\end{eg}
    
Example \ref{ex2} satisfies Assumption \ref{Con}. 
The Markov chain in Example \ref{ex2} is irreducible and aperiodic, 
which implies that it is uniformly ergodic. Therefore, 
it satisfies Assumption \ref{ErgodicityHMM}-iii. 
By Corollary \ref{Main2Cor}, we can conclude that 
the filtering process associated with Example \ref{ex2} is uniquely ergodic.
    
We finally provide an example where $X$ is continuos.
Let $N(\mu,\sigma^2)$ represent normal distribution with mean 
$\mu$ and variance $\sigma^2$.
Furthermore, let $\bar{N}(\mu,\sigma^2)$ denote truncated version 
of $N(\mu,\sigma^2)$, where the support is restricted to $[0,1] \subset \mathbb{R}$.
Its probability density function $f$ is given by
$$f(x ; \mu, \sigma)=\frac{1}{\sigma} 
\frac{\varphi\left(\frac{x-\mu}{\sigma}\right)}
{\Phi\left(\frac{1-\mu}{\sigma}\right)-\Phi\left(\frac{0-\mu}{\sigma}\right)}$$
Here, $\varphi(\cdot)$ is the probability density function 
of the standard normal distribution and 
$\Phi(\cdot)$ is its cumulative distribution function.
Now let us construct the example:
\begin{eg}\label{ContE}
Let $X=[0,1]$ with Euclidean norm, 
$\sigma>0$ and transition kernel 
of the hidden model
be $T(.|x)=\bar{N}(x,\sigma^2)$.
\end{eg}

First, we will show that this transition kernel satisfies
Assumption \ref{asm1}-ii for some $\alpha$.
For any $0\leq x < y \leq 1$:
\begin{align*}
    &\frac{\lVert T(.|y)-T(.|x) \rVert _{TV}}{y-x}
    =\frac{\lVert \bar{N}(y,\sigma^2)-\bar{N}(x,\sigma^2) \rVert _{TV}}{y-x}\\
    &\leq \frac{\lVert N(y,\sigma^2)-N(x,\sigma^2) \rVert _{TV}}{y-x}=
    \frac{2-4\Phi\left(\frac{x-y}{2\sigma}\right)}{y-x}\\
    &=\frac{2}{\sigma}\left(\frac{\Phi(0)-\Phi(\frac{x-y}{2\sigma})}{\frac{y-x}{2\sigma}}\right)
    \leq \frac{2}{\sigma} \Phi'(0)= 
    \frac{\sqrt{2}}{\sigma \sqrt{\pi}}
\end{align*}
The last inequality follows from the fact that 
$\Phi$ is convex on the
negative half-plane.
Therefore Assumption \ref{asm1}-ii satisfied 
for $\alpha=\sigma \sqrt{2/ \pi}$. 

If we choose $\sigma>3/\sqrt{2\pi}$, then Assumption \ref{asm1}-iii
satisfied for every observation kernel. 
Under this condition 
we can use Theorem \ref{Main} to conclude that 
the filter is geometrically
Wasserstein ergodic.

If $\sigma \leq 3/\sqrt{2\pi}$, 
Theorem \ref{Main} may not apply. 
Yet, in such cases, Theorem \ref{Main2} may allow us to show that the filter is uniquely ergodic.
We have
\begin{align*}
\delta(T) = \inf_{x, y} \left(1-\frac{\lVert \bar{N}(y,\sigma^2)-\bar{N}(x,\sigma^2) \rVert _{TV}}{2}\right) = 2 \Phi(-1/\sigma) > 0.
\end{align*}
This implies that $\T$ is uniformly ergodic. 
For Example \ref{ContE}, it is shown that Assumption 
\ref{ErgodicityHMM} holds. 
Consequently, if we also have Assumption \ref{Con}, the filter is uniquely ergodic: Consider the observation set 
\(Y = \{1/N, 2/N,..., N/N\}\) for a given natural number \(N\). In this setup, the observation kernel points to the nearest 
element in \(Y\) with a probability 
\(p<1\). Conversely, with a probability 
\(1-p\), it points to a uniformly selected element from \(Y\). This setup satisfies Assumption \ref{Con}.

\noindent{\bf Wasserstein Continuity and the L-chain Property.} The weak Feller property of the filter process has attracted 
significant interest with applications on near optimality of 
finite approximations in stochastic control. In the paper, 
we will obtain a generalization of the weak-Feller property. 
Notably, we will show the following, 
which generalizes \cite[Theorem 7(i)]{kara2020near} 
also with a slightly different proof:
\begin{lemma}\label{Regularity}[Generalization of \cite[Theorem 7(i)]{kara2020near}]
    Suppose $\mathbb{X}$ and $\mathbb{Y}$ are Polish spaces.
    Assume that Assumption \ref{asm1}-ii holds,
    we have for all $n \in \mathbb{Z}_+$ the following inequality:
    $$
    \rho_{B L}\left(\eta^n(\cdot \mid z), 
    \eta^n\left(\cdot \mid z^{\prime}\right)\right) \leq 
    3\left(1+\alpha \right) \rho_{B L}\left(z, z^{\prime}\right)
    $$
\end{lemma}

Moreover, this lemma  demonstrates that the filter process satisfies the properties of an $L$-chain
(Theorem \ref{L-chain}). In other words, for every bounded Lipschitz function $f$,
the sequence $E[f(X_n)]$ exhibits equicontinuity over $n$. 

\begin{thm}\label{Talpha}
    Suppose $Y$ is a Polish space.
    Under the Assumptions \ref{asm1}-i, \ref{asm1}-ii,
    we have
    $$
    W_{1}\left(\eta(\cdot \mid z_0), \eta\left(\cdot \mid z_0^{\prime}\right)\right) \leq 
    \left(\frac{\alpha D (3-2\delta(Q))}{2}\right)W_{1}\left(z_0, z_0^{\prime}\right)
    $$
    for all $z_0,z_0' \in \mathcal{Z}$.
\end{thm}

Theorem \ref{Talpha} establishes the property of 
Wasserstein continuity, ensuring the smoothness and 
continuity of the Wasserstein distance for the filter process. This complements recent results on the weak Feller property of non-linear filters \cite{FeKaZg14} \cite{KSYWeakFellerSysCont}, in addition to \cite[Theorem 7]{kara2020near} (see also \cite{feinberg2022markov, feinberg2023equivalent}).

{\bf Implications for Controlled Models.} 

We generalized Lemma \ref{Regularity} and Theorem \ref{Talpha} 
for controlled models to establish Wasserstein continuity 
and bounded Lipschitz continuity under a fixed control 
action sequence, as outlined in 
Theorems \ref{Calpha} and \ref{CBLalpha}, respectively.
Furthermore, as a corollary of our analysis, 
specifically with reference to Theorem \ref{Calpha}, 
we will present a 
new existence result on the optimal solutions 
for partially observable stochastic control 
problems under the ergodic cost criteria; 
this will be discussed in Section 
\ref{controlledPOMDPACOESec}. 
We emphasize that since the geometric 
ergodicity result presented in the paper 
is new to the literature, such an implication on optimal 
stochastic control with partial information was 
not available earlier in the literature.

In summary, our main results are Theorem \ref{Main} on 
geometric ergodicity, Theorem \ref{Main2}
on unique ergodicity and Theorem \ref{Talpha} 
on Wasserstein regularity.

\subsection{Comparison with the Literature}
In the following section, we summarize some previous research on the 
unique ergodicity of the filter process. Key works on this subject include: 
Blackwell \cite{blackwell1959entropy}, Kaijser 1975 \cite{Kaijser}, 
and more recent contributions by Kochman and Reeds \cite{kochman2006simple}, 
Kaijser \cite{kaijser2011markov}, 
Chigansky and Van Handel \cite{chigansky2010complete}, 
Di Masi and Stettner \cite{DiMasiStettner2005ergodicity}, 
and Budhiraja \cite{Budhiraja}.


We would like to note that our model is a classical hidden Markov model, 
which we term as POMP. There are several generalized models of a POMP. 
We present two such generalizations: POMP1 and POMP2. 
In POMP1, the difference from the classical model is that 
the observation state depends not only on the current state 
but also on the previous state. The transition kernel remains 
the same as in POMP, but the observation kernel becomes 
$Q(Y_n|X_{n-1}, X_n)$.

In POMP2, the observation state is influenced by the previous 
observation in addition to the current state. 
The transition kernel is similar to the classical model, 
but the observation kernel changes to $Q(Y_n|X_{n}, Y_{n-1})$. 
For all these models, we assume that $T(.|x)$, $Q(.|s)$ 
have density functions over $\mathbb{X}$ and $\mathbb{Y}$.

POMP1 encompasses our classical model POMP, 
but our results can also be applied to the generalized 
model if we consider a double state Markov process. 
For such a generalized model, if we define a partially 
Markov process where $S_n=(X_n, X_{n-1})$ is the hidden 
model state with the transition kernel $\tilde{T}$, 
and the state space $\mathbb{X}^2$ while $Y_n$ is 
the observation state, it becomes a classical model. 
It's not difficult to see that $\delta(T)=\delta(\tilde{T})$, 
and our results are applicable.

For POMP2, note that if we define $S_n=(X_n, Y_n)$, 
then $S_n, Y_n$ turns into a classical POMP model. 
This transformation allows us to apply our results 
from the classical model to POMP2.




The paper\cite{Kaijser} by Kaijser deals 
with the study of unique ergodicity in 
the context of filtering processes for 
finite state hidden Markov model and finite 
state observation space, and this study 
involves the use of the Furstenberg-Kesten 
theory of random matrix products. 
Kaijser introduces the following condition,
which is sufficient for the unique ergodicity 
of the filter, but not necessary. 

\textbf{Condition A}. $\mathbb{X}$ and $\mathbb{Y}$ are finite sets, 
and the transition matrix of hidden Markov model $(X_n)$ 
is irreducible (ergodic).
There exist $y_1, \ldots, y_n \in \mathbb{Y}$ such that 
the matrix $M=M\left(y_1\right) \cdots M\left(y_n\right)$ 
is nonzero and subrectangular, that is, $M_{i j}>0$ 
and $M_{k l}>0$ imply $M_{i l}>0$ and $M_{k j}>0$. 
Here, $M(y)_{|\mathbb{X}|\times|\mathbb{X}|}$ 
is a  matrix such that
$$M(y)_{ij}=Pr(X_{n+1}=j, Y_{n+1}=y|X_{n}=i).$$

Kaijser\cite{Kaijser} proved that under Condition A the filter process 
is uniquely ergodic and this implies 
Blackwell's \cite{blackwell1959entropy} result. 
Furthermore, if the transition matrix of the hidden Markov model 
is aperiodic, 
then for any initial distribution, the filter process weakly
converges to the stationary distribution. If $\mathbb{X}$ is finite, 
Assumption \ref{ErgodicityHMM}-iii aligns with 
irreducibility and aperiodicity.

Kochman and Reeds prove more a general result in a later 
study\cite{kochman2006simple}. 
They worked with the finite case and used a different 
condition than the subrectangularity condition, 
namely that the closure of finite multiplication of 
simple transition matrix has a rank one element. 
They showed that Condition A (subrectangularity condition) 
implies the rank one condition, 
but provided a counterexample to demonstrate 
that the rank one condition is strictly weaker. 
Their proof relied on a different method than the 
original proof. In this article, we generalize 
their proof to a more general case. 
To summarize their proof, they first showed 
that any continuous bounded function is 
equicontinuous under the filter process. 
They then used the existence of a matrix with 
rank 1 to prove the existence of reachable states. 
We also use a similar technique in our proof, 
relying on a known theorem(\cite{MeynBook}, Theorem 18.4.4) 
to complete the proof.



\textbf{Condition KR}. Suppose $\mathbb{X}$ and $\mathbb{Y}$ are 
finite sets, and the transition matrix of the
hidden Markov model is irreducible. 
Define the cone of matrices as
$$
\mathcal{K}=\left\{c M\left(y_1\right) 
\cdots M\left(y_n\right): n \in \mathbb{N}, 
y_1, \ldots, y_n \in \mathbb{Y}, 
c \in \mathbb{R}_{+}\right\} .
$$
Then the closure of $\mathcal{K}$ contains a matrix of rank 1.

Kochman and Reeds\cite{kochman2006simple} 
prove that under Condition KR the filter 
process is uniquely ergodic. 
Similarly to Kaijser's result, 
they also show that, under the additional aperiodicity condition, 
the filter process weakly converges to a stationary measure. 
It's worth noting that their result is applicable not only 
for classical hidden Markov models (POMP) but also for POMP1.


The study by Kaijser published in 
2011 \cite{kaijser2011markov} extends 
the results of Kochman and Reeds to classical 
hidden Markov models, where the state space 
$\mathbb{X}$ is countable. The proof by Kochman and Reeds
does not apply to the case of countably 
infinite state spaces. 
Kaijser proposed two different conditions 
for countable state spaces so that one of 
them is for the generalization of the Condition KR. 
These conditions allow for the observation space 
to be finite or countable. He also demonstrated 
that the previously established conditions 
imply these new conditions.

\textbf{Condition B1}. Suppose $\mathbb{X}$ and $\mathbb{Y}$ are 
countable. Let the transition matrix of the hidden Markov model 
be irreducible, aperiodic and positively recurrent.
There exists a nonnegative function 
$u: \mathbb{X} \rightarrow \mathbb{R}_{+}$with $\|u\|_{\infty}=1$, 
a probability measure $\nu$ on $\mathbb{X}$, 
a sequence of integers $\left(n_k\right)_{k \in \mathbb{N}}$ 
and a sequence of observation paths 
$\left(y_1^k, \ldots, y_{n_k}^k\right)_{k \in \mathbb{N}}$ 
with $\left\|M\left(y_1^k\right) \cdots 
M\left(y_{n_k}^k\right)\right\|>0$, such that
$$
\left\|\frac{\delta_x M\left(y_1^k\right) \cdots M\left(y_{n_k}^k\right)}{\left\|M\left(y_1^k\right) \cdots M\left(y_{n_k}^k\right)\right\|}-u(x) \nu \right\| \stackrel{k \rightarrow \infty}{\longrightarrow} 0 \quad \text { for all } x \in \mathbb{X} ,
$$
where $\|M\|=\sup _{\|f\|_{\infty} \leq 1} \sup _{\|\mu\|_1 \leq 1} \mu M f$.

For a finite state space, Condition KR and Condition B1 
are equivalent. For countable $\mathbb{X}$, 
irreducibility, aperiodicity, and positive recurrence 
is equivalent to Assumption \ref{ErgodicityHMM}(iii). 
The last part of the condition ensures the existence 
of reachable states of the filter process.


\textbf{Condition B}. Let $\mathbb{X}$ and $\mathbb{Y}$ 
be countable sets. 
Let $P$, the transition matrix of the hidden Markov model, 
be irreducible, aperiodic, and positive recurrent, 
let $\pi$ denotes the unique probability vector in 
$\mathcal{Z}:=P(\mathbb{X})$ such that $\pi P = \pi$. 
For any $\rho > 0$, there exists an element 
$i_0 \in \mathbb{X}$ such that for any compact set 
$C \subset \mathcal{Z}$, if 
\begin{align*}
    \mu\left(C \cap\left\{x:(x)_{i_0} 
    \geq(\pi)_{i_0} / 2\right\}\right) 
    \geq(\pi)_{i_0} / 3, \quad \forall \mu \in 
    \mathcal{P}(\mathcal{Z} \mid \pi),
\end{align*}
where 
\begin{align*}
    \mathcal{P}(\mathcal{Z}\mid \pi)=\{\mu \in 
    P(\mathcal{Z}):\int_\mathcal{Z}(x)_i \mu(d x)=(\pi)_i\},
\end{align*}
then there exists an integer $N$ 
and a sequence of elements 
$w_1, w_2, ..., w_N \in \mathcal{W}$ 
such that $\mathbf{M}(\mathbf{w}^{\mathbf{N}})
=M(w_1)\dots M(w_N)$ has a positive $i_0$-th 
coordinate and for any $x \in \{x \in C : (x)_{i_0} 
\geq (\pi)_{i_0}/2\}$, 
\begin{align*}
    \left\|\left(x \mathbf{M}\left(\mathbf{w}^{\mathbf{N}}\right) /\left\|x \mathbf{M}\left(\mathbf{w}^{\mathbf{N}}\right)\right\|-e^{i_0} \mathbf{M}\left(\mathbf{w}^{\mathbf{N}}\right) /\left\|e^{i_0} \mathbf{M}\left(\mathbf{w}^{\mathbf{N}}\right)\right\|\right)\right\|<\rho ,
\end{align*}
where $e^{i_0}$ is a unit vector in $\mathcal{Z}$ so that $(e^{i_0})_{{i_0}}=1$.

Finally, Kaijser \cite{kaijser2011markov} proved that Condition B1 
implies Condition B and that under Condition B the 
filter process is uniquely ergodic.


Chigansky and Van Handel\cite{chigansky2010complete} worked on the same question. The main feature of their article is that their condition is necessary and sufficient for unique ergodicity of the filter in the case where $\mathbb{X}$ and $\mathbb{Y}$ both take values in a countable state space. Additionally, the condition presented in their article is also sufficient when the observation space is $R^d$. It is the first time that a necessary condition for unique ergodicity has been identified in this setting. Furthermore, Chigansky and Van Handel show that when $\mathbb{X}$ is finite and $\mathbb{Y}$ is either finite or countable, Condition KR is a necessary and sufficient condition for unique ergodicity of the filter process. They also show that under Condition C the filter process is uniquely ergodic.

\textbf{Condition C}. For every $\varepsilon>0$, there exist an integer $N \in \mathbb{N}$ and subsets $\mathcal{S} \subset \mathcal{P}(\mathbb{X})$ and $\mathcal{O} \subset \mathbb{Y}^N$ such that the following hold:
\begin{itemize}
\item $\mathbf{P}\left(\pi_0^{\min } \in \mathcal{S}\right.$ and $\left.\pi_0^{\max } \in \mathcal{S}\right)>0$ and 
$\varphi^{\otimes N}(\mathcal{O})>0$, where $\varphi$ is reference measure
(it is counting measure if $\mathbb{Y}$ is countable and Lebesgue measure if $\mathbb{Y}=R^d$), 
$y \to M(y)$ is continuous for all $y\in \mathbb{Y}$
and $\pi_n^{\min }=\mathbf{P}\left(X_n \in \cdot \mid \mathcal{F}_{-\infty, n}^Y\right)$, $\pi_n^{\max }=\mathbf{P}\left(X_n \in \cdot \mid \mathcal{G}_{-\infty, n}\right)$, where 
$$
\mathcal{F}_{m, n}^\mathbb{X}=\sigma\left\{X_k: k \in[m, n]\right\}, \quad \mathcal{F}_{m, n}^\mathbb{Y}=\sigma\left\{Y_k: k \in[m, n]\right\}
$$
for $m, n \in \mathcal{Z}, m \leq n$, $\mathcal{F}_{-\infty, n}^\mathbb{X}=\bigvee_{m \leq n} \mathcal{F}_{m, n}^\mathbb{X}$, $\mathcal{F}_{-\infty, n}^\mathbb{Y}=\bigvee_{m \leq n} \mathcal{F}_{m, n}^\mathbb{Y}$, and 
$$
\mathcal{G}_{m, n}=\mathcal{F}_{-\infty, m}^\mathbb{X} \vee \mathcal{F}_{-\infty, n}^\mathbb{Y}, \quad \mathcal{G}_{-\infty, n}=\bigcap_{m \leq n} \mathcal{G}_{m, n}.
$$
\item $\mu M\left(y_1\right) \cdots M\left(y_N\right) 1>0$ for all $\mu \in \mathcal{S}$ and $\left(y_1, \ldots, y_N\right) \in \mathcal{O}$.
\item For all $\mu, v \in \mathcal{S}$ and $\left(y_1, \ldots, y_N\right) \in \mathcal{O}$
$$
\left\|\frac{\mu M\left(y_1\right) \cdots M\left(y_N\right)}{\mu M\left(y_1\right) \cdots M\left(y_N\right) 1}-\frac{v M\left(y_1\right) \cdots M\left(y_N\right)}{v M\left(y_1\right) \cdots M\left(y_N\right) 1}\right\|<\varepsilon
$$
\end{itemize}
It should be noted that in all the 
conditions reviewed above from the literature, 
$\mathbb{X}$ is assumed to be countable.

Now, let us discuss the relationship between 
unique ergodicity and filter stability. 
Before we continue, let us provide the definition 
of a non-degenerate observation channel:

\begin{defn}[Nondegeneracy] There exists a probability measure
$\varphi$ on $\mathbb{B}(\mathbb{Y})$ and 
a strictly positive measurable 
function $g: \mathbb{X} \times \mathbb{Y} \rightarrow (0, \infty) $ such that
$$
Q(A|x)=\int_A g(x, y) \varphi(d y) 
\quad \text { for all } A \in \mathbb{B}(\mathbb{Y}), x \in \mathbb{X}. 
$$
\end{defn}

In the case of a classical model, if $X_n$ is an ergodic process, 
then filter stability and unique ergodicity are essentially equivalent 
problems in both discrete and continuous-time settings 
\cite{Budhiraja, Stettner1989, Kunita}. 
Di Masi and Stettner\cite{DiMasiStettner2005ergodicity} 
proved the same result for the general model POMP2. 
Chigansky and Van Handel\cite{chigansky2010complete} 
utilized the previous result on filter stability to propose 
new sufficient conditions for unique ergodicity. 
For more detailed results for filter stability, 
refer to \cite{Handel,HandelUniformObs,chigansky2009intrinsic}. Notably, (\cite{Handel} Theorem $5.2$) shows that
if hidden Markov model is strongly ergodic 
and the observation channel is non-degenerate 
then the filter is stable. 

%Now, let us provide the definitions of uniform observability 
%and observability before discussing the final theorem 
%\cite{chigansky2010complete}, which is proven using 
%the equivalence of filter stability and unique ergodicity.
%
%\begin{defn}[Uniform observability]
%    For every $\varepsilon>0$, there is a $\delta>0$ such that
%$\left\|\left.\mathbf{P}^\mu\right|_{\mathcal{F}_{1, \infty}^Y}-\left.\mathbf{P}^v\right|_{\mathcal{F}_{1, \infty}^Y}\right\|<\delta \quad$ implies 
%$\quad\|\mu-v\|<\varepsilon \quad$ [for any $\mu, v \in \mathcal{Z}$].
%\end{defn}
%
%\begin{defn}[Observability]
%    If $\mu, v \in \mathcal{Z}$ and $\left.\mathbf{P}^\mu\right|_{\mathcal{F}_{1, \infty}^Y}=\left.\mathbf{P}^v\right|_{\mathcal{F}_{1, \infty}^Y}$, then $\mu=v$.
%\end{defn}
%
%\begin{thm}[\cite{chigansky2010complete}, Theorem 6.3.]
%Let $\mathbb{X}$ be countable and
%let $\mathbb{Y}$ be countable or 
%a Polish space such that
%$y \mapsto M(y)$ is continuous for all $y\in \mathbb{Y}$.
%Suppose one of the following conditions holds:
%\begin{enumerate}[label=(\roman*)]
%    \item Nondegeneracy holds, and the hidden 
%    transition matrix is irreducible and aperiodic; or
%    \item Uniform observability holds; or 
%    \item Observability holds, and $\mathbb{X}$ is a finite set.
%\end{enumerate}
%Then the filter is uniquely ergodic.
%\end{thm} 

\cite{mcdonald2020exponential,mcdonald2018stability} provide further conditions for filter stability, and thus, in view of the above, unique ergodicity. Recall that for a kernel $K$, $\delta(K)$ is the 
Dobrushin coefficient defined in Definition \ref{Dobrushincoefficient}.
If the inequality $(1-\delta(T))(2-\delta(Q))<1$ 
is satisfied, then the filter is exponentially stable. 

Our analysis also relies on results from \cite{kara2020near}, 
which we will discuss in detail in the following section. Since Lemma \ref{Regularity} and Theorem \ref{Talpha} 
can be viewed as a generalization of the weak-Feller 
property, it is worth mentioning the following. 
We refer the reader to \cite[Theorem 7]{kara2020near}, 
which builds upon \cite{KSYWeakFellerSysCont}, 
providing further refinements with explicit moduli 
of continuity for the weak Feller property. 
Additionally, \cite[Theorem 7.1]{FeKaZg14} establishes 
the weak Feller property under a different set of 
assumptions. Further results on the weak Feller property, 
including a converse theorem statement involving 
\cite{KSYWeakFellerSysCont}, can be found in 
\cite{feinberg2022markov, feinberg2023equivalent}, 
which consider both the necessity and sufficiency 
of the weak Feller property.


{\bf Comparison.} Compared with the aforementioned studies,  our paper contributes the following:
Theorem \ref{Main} presents the first known result on the geometric ergodicity of the filter process. This result specifically applies to compact state spaces.

Theorem \ref{Main2} presents a slightly more general result on unique ergodicity of the filter process, where we generalize the findings in the literature to compact state spaces.

Notably, our paper also provides novel applications of 
these results in the context of finite state spaces. 
Corollary \ref{speccor} establishes a new result on the geometric 
ergodicity of the filter process for finite state spaces. 
Corollary \ref{Main2Cor} is consistent with the result obtained by 
Kochman and Reeds\cite{kochman2006simple}.
A significant aspect of our analysis is the 
introduction of the Wasserstein contraction 
property of non-linear filters, 
as presented in Theorem \ref{Talpha}.
Finally, we discuss implications on the existence 
to solutions to the average cost optimality equation 
for controlled models, to be discussed in Section 
\ref{controlledPOMDPACOESec}, where we introduce 
new existence conditions for average cost 
optimal stochastic control involving 
partially observable Markov decision processes.

Overall, our paper contributes to the existing literature 
by extending the results on geometric ergodicity and unique 
ergodicity to both compact and finite state spaces.

\section{Proofs of the Results}
We initially present a number of supporting results
to establish our primary findings. % outlined in 
%Theorem \ref{Main} and \ref{Main2}.

\subsection{Wasserstein Continuity of the Filter Kernel}
Recall that $\eta$, defined in (\ref{etatra}), is the kernel of the filter update equation.

Kara and Y\"{u}ksel \cite{kara2020near} introduced a 
regularity condition for the controlled filter process. In the case of the control-free POMP, we present their theorem below. 

\begin{thm}[\cite{kara2020near}, Theorem 7-i]\label{KaraYuksel}
    Assume that $\mathbb{X}$ and $\mathbb{Y}$ are Polish spaces. 
    If Assumption \ref{asm1}-ii is fulfilled, then we have
$$
\rho_{B L}\left(\eta(\cdot \mid z), \eta\left(\cdot \mid z^{\prime}\right)\right) \leq 
3\left(1+\alpha \right) \rho_{B L}\left(z, z^{\prime}\right).
$$ 
\end{thm}
Note that the bound solely depends on $\alpha$, 
which corresponds to the transition kernel $T$. 
In the following, we will prove two lemmas using 
essentially the same
method employed in the proof of the 
aforesaid theorem.

\begin{proof}[Proof of Theorem \ref{Talpha}]

We adapt the argument from Kara and Y\"{u}ksel (\cite{kara2020near}, Theorem 7).
We equip $\mathcal{Z}$ with the metric $W_1$ to define the Lipschitz seminorm $\norm{f}_L$ of any Borel measurable function $f:\mathcal{Z}\to \mathbb{R}$.

\begin{align}
&W_{1}\left(\eta(\cdot \mid z_0), \eta\left(\cdot \mid z_0^{\prime}\right)\right)\nonumber\\
&=\sup _{f\in \operatorname{Lip}(\mathcal{Z})}\left|\int_{\mathcal{Z}} f\left(z_1\right) \eta\left(d z_1 \mid z_0^{\prime}\right)-\int_{\mathcal{Z}} f\left(z_1\right) \eta\left(d z_1 \mid z_0\right)\right| \nonumber\\
& =\sup _{f \in \operatorname{Lip}(\mathcal{Z})}\left|\int_{\mathbb{Y}} f\left(z_1\left(z_0^{\prime}, y_1\right)\right) P\left(d y_1 \mid z_0^{\prime}\right)-\int_{\mathbb{Y}} f\left(z_1\left(z_0,  y_1\right)\right) P\left(d y_1 \mid z_0\right)\right|\label{kappabeta1}\\
& =\sup _{f \in \operatorname{Lip}(\mathcal{Z}),\;\norm{f}_\infty\leq D/2}\left|\int_{\mathbb{Y}} f\left(z_1\left(z_0^{\prime}, y_1\right)\right) P\left(d y_1 \mid z_0^{\prime}\right)-\int_{\mathbb{Y}} f\left(z_1\left(z_0,  y_1\right)\right) P\left(d y_1 \mid z_0\right)\right|. \label{Kappa_beta} 
\end{align}

Since, for any $f:\mathcal{Z}\to R$ such that $\norm{f}_L\leq 1$, we know that $|f(z)-f(z^{\prime})|\leq d(z,z^{\prime})\leq \operatorname{diam}(\mathcal{Z})\leq D$ 
and subtracting a constant from $f$ does not change the expression (\ref{kappabeta1}), without any loss of generality, we can assume that $\norm{f}_\infty\leq D/2$.

For any $f:\mathcal{Z}\to \mathbb{R}$ such that $\norm{f}_L\leq 1$ and $\norm{f}_\infty\leq D/2$, we have 
\begin{align}
&\left|\int_{\mathbb{Y}} f\left(z_1\left(z_0^{\prime}, y_1\right)\right) P\left(d y_1 \mid z_0^{\prime}\right)-\int_{\mathbb{Y}} f\left(z_1\left(z_0,  y_1\right)\right) P\left(d y_1 \mid z_0\right)\right| \nonumber\\
&\leq \left|\int_{\mathbb{Y}} f\left(z_1\left(z_0^{\prime}, y_1\right)\right) P\left(d y_1 \mid z_0^{\prime}\right)-\int_{\mathbb{Y}} f\left(z_1\left(z_0^{\prime}, y_1\right)\right) P\left(d y_1 \mid z_0\right)\right| \nonumber\\
&+ \int_{\mathbb{Y}}\left|f\left(z_1\left(z_0^{\prime}, y_1\right)\right)-f\left(z_1\left(z_0, y_1\right)\right)\right| P\left(d y_1 \mid z_0\right) \nonumber\\
&\leq\frac{D}{2}\left\|P\left(\cdot \mid z_0^{\prime} \right)-P\left(\cdot \mid z_0\right)\right\|_{T V}\\
&+ \int_{\mathbb{Y}}\left|f\left(z_1\left(z_0^{\prime}, y_1\right)\right)-f\left(z_1\left(z_0, y_1\right)\right)\right| P\left(d y_1 \mid z_0\right).\label{second}
\end{align}
We first analyze the first term:
\begin{align}\label{TV1}
&\left\|P\left(\cdot \mid z_0^{\prime}\right)-P\left(\cdot \mid z_0\right)\right\|_{T V}=\sup _{\|g\|_{\infty} \leq 1}\left|\int g\left(y_1\right) P\left(d y_1 \mid z_0^{\prime}\right)-\int g\left(y_1\right) P\left(d y_1 \mid z_0\right)\right|\nonumber \\
&=\sup _{\|g\|_{\infty} \leq 1}\left|\int g\left(y_1\right) Q\left(d y_1 \mid x_1\right) \mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\int g\left(y_1\right) Q\left(d y_1 \mid x_1\right) \mathcal{T}\left(d x_1 \mid z_0\right)\right|\nonumber\\
&\leq (1-\delta(Q))\left\|\mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\mathcal{T}\left(d x_1 \mid z_0\right)\right\|_{T V}
\end{align}
by Dobrushin \cite{dobrushin1956central}.

 
\begin{align}\label{TV2}
&\left\|\mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\mathcal{T}\left(d x_1 \mid z_0\right)\right\|_{T V}= \sup _{\|g\|_{\infty} \leq 1}\left(\int g\left(x_1\right) T\left(d x_1 \mid z_0^{\prime}\right)-\int g\left(x_1\right) T\left(d x_1 \mid z_0\right)\right)\nonumber\\
&=\sup _{\|g\|_{\infty} \leq 1}\left(\int\left(\int g\left(x_1\right) T\left(d x_1 \mid x_0\right)z_0^{\prime}(dx_0)-\int g\left(x_1\right) T\left(d x_1 \mid x_0\right)z_0(dx_0)\right)\right)\nonumber\\
&= \sup _{\|g\|_{\infty} \leq 1}\left(\int\Tilde{g_g}(x_0)z_0^{\prime}(dx_0)-\Tilde{g_g}(x_0)z_0(dx_0)\right)
\end{align}
where
\begin{align*}
    \Tilde{g_g}(x)= \int g\left(x_1\right) T\left(d x_1 \mid x\right).
\end{align*}

For all $x_0^{\prime}, x_0\in \mathbb{X}$, 
by Assumption \ref{asm1}-ii, we have, 
\begin{align*}
\left\|\mathcal{T}\left(d x_1 \mid x_0^{\prime}\right)-\mathcal{T}\left(d x_1 \mid x_0\right)\right\|_{T V}\leq \alpha d(x_0,x_0^{\prime}).
\end{align*}
As a result, we get that $\Tilde{g}/\alpha \in Lip(\mathbb{X})$, since $|\Tilde{g}(x_0)-\Tilde{g}(x_0^\prime)|\leq\left\|\mathcal{T}\left(d x_1 \mid x_0^{\prime}\right)-\mathcal{T}\left(d x_1 \mid x_0\right)\right\|_{T V}\leq \alpha d(x_0,x_0^{\prime})$.

Then, by inequality (\ref{TV1}) and (\ref{TV2}) we can write 
\begin{align}\label{TV}
\left\|P\left(\cdot \mid z_0^{\prime}\right)-P\left(\cdot \mid z_0\right)\right\|_{T V} \leq \alpha(1-\delta(Q))W_{1}\left(z_0^{\prime}, z_0\right).
\end{align}
Finally, we can analyze the second term in (\ref{second})
\begin{align}\label{eq3}
&\int_{\mathbb{Y}}\left|f\left(z_1\left(z_0^{\prime}, y_1\right)\right)-f\left(z_1\left(z_0, y_1\right)\right)\right| P\left(d y_1 \mid z_0\right)\nonumber\\
&\leq \int_{\mathbb{Y}}W_1(z_1\left(z_0^{\prime}, y_1\right), z_1\left(z_0, y_1\right)) P\left(d y_1 \mid z_0\right)\nonumber\\
&=\int_{\mathbb{Y}} \sup_{g \in \operatorname{Lip}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) - \int_{\mathbb{X}} g(x_1)z_1\left(z_0, y_1\right)(dx_1)\right)P\left(d y_1 \mid z_0\right)
\end{align}
If we look at the term inside
\begin{align}\label{inside}
&\sup_{g \in \operatorname{Lip}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) - \int_{\mathbb{X}} g(x_1)z_1\left(z_0, y_1\right)(dx_1)\right)\\
&=\sup_{g \in \operatorname{Lip}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x_1)(z_1\left(z_0^\prime, y_1\right)- z_1\left(z_0, y_1\right))(dx_1)\right)\nonumber\\
&=\sup_{g \in \operatorname{Lip}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x_1)w_{y_1}(dx_1)\right),\nonumber
\end{align}
where $w_{y_1}=(z_1\left(z_0^\prime, y_1\right)- z_1\left(z_0, y_1\right))$ 
which is a signed measure on $\mathbb{X}$. 
$Lip(\mathbb{X})$ is closed, uniformly bounded and equicontinuos with respect to the sup-norm topology, 
so by the Arzela-Ascoli theorem $\Lip(\mathbb{X})$ is compact. 
Since a continuous function on a compact set attains its supremum,
 the set
$$
A_y:=\left\{h_y(x)=\arg\sup_{g \in \operatorname{Lip}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x)w_{y}(dx)\right):h_y(x)\in \Lip(\mathbb{X})\right\}
$$
is nonempty for every $y\in \mathbb{Y}$. The integral is continuous under respect to sup-norm, i.e., 
$$ 
\left|\int_{\mathbb{X}} g(x)w_{y}(dx)-\int_{\mathbb{X}} h(x)w_{y}(dx)\right|\leq\norm{g-h}_\infty \quad \forall g,h\in \Lip(\mathbb{X}). 
$$
Then, $A_y$ is a closed set under sup-norm.
$\mathbb{Y}$ and $\operatorname{Lip}(\mathbb{X})$ are Polish spaces, and define $\Gamma=(y,A_y)$. 
$A_y$ is closed for each $y\in \mathbb{Y}$ and $\Gamma$ is Borel measurable. 
So there exists a measurable function $h:\mathbb{Y}\to \operatorname{Lip}(\mathbb{X})$ 
such that $h(y)\in A_y$ for all $y \in \mathbb{Y}$ 
by the Measurable Selection Theorem 
\footnote{[\cite{himmelberg1976optimal}, Theorem 2][Kuratowski Ryll-Nardzewski Measurable Selection Theorem]
Let $\mathbb{X}, \mathbb{Y}$ be Polish spaces and $\Gamma=(x, \psi(x))$ where $\psi(x) \subset \mathbb{Y}$ be such that, $\psi(x)$ is closed for each $x \in \mathbb{X}$ and let $\Gamma$ be a Borel measurable set in $\mathbb{X} \times \mathbb{Y}$. Then, there exists at least one measurable function $f: \mathbb{X} \rightarrow \mathbb{Y}$ such that $\{(x, f(x)), x \in \mathbb{X}\} \subset \Gamma$.
}. 
Let us define $g_y=h(y)$.
After that we can continue with the equation (\ref{eq3}),
\begin{align}
&\int_{\mathbb{Y}} \sup_{g \in \operatorname{Lip}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) - \int_{\mathbb{X}} g(x_1)z_1\left(z_0, y_1\right)(dx_1)\right)P\left(d y_1 \mid z_0\right)\nonumber\\
&=\int_{\mathbb{Y}} \left(\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) - \int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0, y_1\right)(dx_1)\right) P\left(d y_1 \mid z_0\right)\label{inside2}\\
&=\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0)-
\int_{\mathbb{Y}}\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0, y_1\right)(dx_1) P(d y_1 \mid z_0)\nonumber\\
&=\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0)-
\int_{\mathbb{Y}}\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0^\prime)\label{gy1}\\
&+\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0^\prime)-
\int_{\mathbb{Y}}\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0, y_1\right)(dx_1) P(d y_1 \mid z_0)\label{gy2}
\end{align}

For the first term, we can write by the same argument as earlier
\begin{align*}
\norm{\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1)}_\infty\leq\norm{g_{y_1}}_\infty \leq D/2 .
\end{align*}
So,
\begin{align}\label{sup-1}
&\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0)-
\int_{\mathbb{Y}}\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0^\prime)\nonumber\\
&\leq \frac{D}{2} \left\|P\left(\cdot \mid z_0^{\prime}\right)-P\left(\cdot \mid z_0\right)\right\|_{T V}\nonumber\\
& \leq \alpha \frac{D}{2} (1-\delta(Q))W_{1}\left(z_0^{\prime}, z_0\right)
\end{align}
by inequality (\ref{TV}).

For the second term,  we can write by smoothing
\begin{align}\label{sup-2}
&\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0^\prime, y_1\right)(dx_1) P(d y_1 \mid z_0^\prime)-
\int_{\mathbb{Y}}\int_{\mathbb{X}} g_{y_1}(x_1)z_1\left(z_0, y_1\right)(dx_1) P(d y_1 \mid z_0)\nonumber\\
&=\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1)Q\left(d y_1 \mid x_1\right) \mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\int_{\mathbb{Y}} \int_{\mathbb{X}} g_{y_1}(x_1) Q\left(d y_1 \mid x_1\right) \mathcal{T}\left(d x_1 \mid z_0\right)\nonumber\\
&=\int_{\mathbb{X}} \int_{\mathbb{Y}} g_{y_1}(x_1)Q\left(d y_1 \mid x_1\right) \mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\int_{\mathbb{X}} \int_{\mathbb{Y}} g_{y_1}(x_1) Q\left(d y_1 \mid x_1\right) \mathcal{T}\left(d x_1 \mid z_0\right)\nonumber\\
&=\int_{\mathbb{X}} \omega(x_1) \mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\int_{\mathbb{X}}\omega(x_1) \mathcal{T}\left(d x_1 \mid z_0\right)
\end{align}
where $$\omega(x_1)=\int_{\mathbb{Y}} g_{y_1}(x_1)Q\left(d y_1 \mid x_1\right).$$
The first equality is a consequence of (\ref{etatra}), and the second follows from Fubini's theorem, since both integrals are bounded by $1$.

For any $x^\prime, x^{\prime\prime} \in \mathbb{X}$, 
\begin{align*}
&\int_{\mathbb{X}} \omega(x) \mathcal{T}\left(d x \mid x^{\prime\prime}\right)-\int_{\mathbb{X}}\omega(x) \mathcal{T}\left(d x \mid x^{\prime}\right)\\
&\leq \norm{\omega}_\infty \left\|\mathcal{T}(\cdot \mid x^{\prime\prime})-\mathcal{T}\left(\cdot \mid x^{\prime}\right)\right\|_{T V}\\
&\leq \norm{\omega}_\infty\alpha d(x^{\prime\prime},x^{\prime})\\
&\leq\alpha \frac{D}{2} d(x^{\prime\prime}, x^{\prime})
\end{align*}
So, by definition of the $W_1$ norm (\ref{defkappanorm}), we have
\begin{align}\label{sup-2-1}
&\int_{\mathbb{X}} \omega(x_1) \mathcal{T}\left(d x_1 \mid z_0^{\prime}\right)-\int_{\mathbb{X}}\omega(x_1) \mathcal{T}\left(d x_1 \mid z_0\right)\nonumber\\
&=\int_{\mathbb{X}}\int_{\mathbb{X}} \omega(x_1) \mathcal{T}\left(d x_1 \mid x_0\right)z^\prime_0(dx_0)-\int_{\mathbb{X}} \int_{\mathbb{X}}\omega(x_1) \mathcal{T}\left(d x_1 \mid x_0\right)z_0(dx_0)\nonumber\\
&\leq  \alpha \frac{D}{2} W_{1}\left(z_0, z_0^{\prime}\right).
\end{align}
So, by the inequalities (\ref{gy1}), (\ref{gy2}), (\ref{sup-1}), (\ref{sup-2}), (\ref{sup-2-1}) we get
\begin{align}\label{last2}
& \int_{\mathbb{Y}}\left|f\left(z_1\left(z_0^{\prime}, y_1\right)\right)-f\left(z_1\left(z_0, y_1\right)\right)\right| P\left(d y_1 \mid z_0\right) \nonumber\\
&\leq \alpha \frac{D}{2} (2-\delta(Q))W_{1}\left(z_0^{\prime}, z_0\right).
\end{align}
If we take the supremum of the equation (\ref{Kappa_beta}) over all $f\in \Lip(\mathcal{Z})$, then by using the inequalities (\ref{second}),(\ref{TV}), and (\ref{last2}), we can write:
\begin{align}\label{imp}
&W_{1}\left(\eta(\cdot \mid z_0), \eta\left(\cdot \mid z_0^{\prime}\right)\right)
\leq \left(\frac{\alpha D (3-2\delta(Q))}{2}\right)W_{1}\left(z_0, z_0^{\prime}\right)\end{align}
\end{proof}

\subsection{Geometric Wasserstein Ergodicity}

Now we proceed to prove our theorem on geometric ergodicity. 
We note again that Assumption \ref{asm1}-ii implies, 
by \cite{KSYWeakFellerSysCont}, 
the weak Feller property of the non-linear 
filtering kernel $\eta$ defined in (\ref{etatra}). 
Therefore, since the state space is compact, 
a Krylov-Bogoliubov argument implies 
that there exists at least one invariant probability measure.

\begin{proof}[Proof of Theorem \ref{Main} ]
Let $\beta=\alpha D (3-2\delta(Q))/2$. 
Under the Assumption \ref{asm1}(iii), $\beta<1$.

Let $f\in \Lip(\mathcal{Z})$. For any $z^*_0, z_0 \in \mathcal{Z}$,
\begin{align}\label{eq2}
&\left|\int_\mathcal{Z} \eta^n(d z_n\mid z_0) f(z_n)-\int_\mathcal{Z} \eta^n(d z_n\mid z^*_0) f(z_n)\right|\nonumber\\
&=\left|\int_\mathcal{Z}\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z_0)\eta(d z_n\mid z_{n-1}) f(z_n)-\int_\mathcal{Z}\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z^*_0)\eta(d z_n\mid z_{n-1}) f(z_n)\right| \nonumber\\
&=\left|\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z_0)\left(\int_\mathcal{Z}\eta(d z_n\mid z_{n-1}) f(z_n)\right)-\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z^*_0)\left(\int_\mathcal{Z}\eta(d z_n\mid z_{n-1}) f(z_n)\right)\right| \nonumber\\
&= \left|\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z_0) g(z_{n-1})-\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z^*_0) g(z_{n-1})\right|
\end{align}
where
$$g(z)= \int_\mathcal{Z}\eta(d z_1\mid z) f(z_1).$$

For any $z, \bar{z} \in \mathcal{Z}$,
$$\left|g(z)-g(\bar{z})\right|\leq \beta W_{1}\left(z, \bar{z}^{\prime}\right)$$
by Theorem \ref{Talpha}. As a result, $g/\beta \in \Lip(\mathcal{Z})$.

Taking the supremum over $f \in \Lip(\mathcal{Z})$ in inequality \eqref{eq2}, we obtain the following: 
\begin{align}\label{eqrec}
    &\sup_{f\in \Lip(\mathcal{Z})}\left(\int_\mathcal{Z} \eta^n(d z_n\mid z_0) f(z_n)-\int_\mathcal{Z} \eta^n(d z_n\mid z^*_0) f(z_n)\right)\nonumber\\
    &\leq \beta \sup_{f\in \Lip(\mathcal{Z})}\left(\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z_0) f(z_{n-1})-\int_\mathcal{Z} \eta^{n-1}(d z_{n-1}\mid z^*_0) f(z_{n-1})\right)
\end{align}


Then, by induction
\begin{align}\label{Lipalpha}
    W_{1}\left(\eta^n(\cdot \mid z_0), \eta^n\left(\cdot \mid z_0^*\right)\right)
    \leq \beta^{n-1} W_{1}\left(z_0, z_0^*\right)
\end{align}

%The metric $W_1$ on $\mathcal{P}(\mathcal{Z})$ 
%ensures that for any pair of initial distributions, 
%the corresponding filter processes will eventually merge. 
This implies that the filter process is uniquely ergodic. 
Furthermore, for any initial distribution, 
the filter process will weakly converge 
to the unique stationary distribution.

Additionally, for any $\mu,\nu \in \mathcal{P}(\mathcal{Z})$, we have
\begin{align}\label{Lipalpha2}
    W_{1}\left(\eta^n(\cdot \mid \mu), \eta^n\left(\cdot \mid \nu\right)\right)
    \leq \beta^{n-1} \sup_{z_0, z_0^* \in \mathcal{Z}}W_{1}\left(z_0, z_0^*\right)
    \leq \beta^{n-1} D,
\end{align}
which shows that the filter process is geometrically Wasserstein ergodic.
\end{proof}

\subsection{Unique Ergodicity}

\begin{proof}[Proof of Lemma \ref{Regularity}]
    We will adopt the approach presented in \cite{kara2020near} with slightly different arguments. We equip $\mathcal{Z}$ 
    with the metric $\rho_{BL}$ to define the bounded-Lipschitz 
    norm $|f|_{BL}$ for any Borel measurable function 
    $f: \mathcal{Z}\rightarrow \mathbb{R}$. 
    In our proof, we will use the same technique as above, 
    but this time we will treat the measurements 
    $y_1^n := (y_1, y_2, \ldots, y_n)$ as a single measurement 
    variable. This allows us to establish a uniform bound 
    over $n$. Let us now continue with the proof.

\begin{align} \label{secondlemma}
&\nonumber \rho_{B L}\left(\eta^n(\cdot \mid z), \eta^n\left(\cdot \mid z^{\prime}\right)\right) \\  
&\nonumber =\sup _{\|f\|_{B L} \leq 1}\left|\int_{\mathcal{Z}} f\left(z_n\right) \eta^n\left(d z_n \mid z_0^{\prime}\right)-
\int_{\mathcal{Z}} f\left(z_n\right) \eta^n\left(d z_n \mid z_0\right)\right| \\
&\nonumber =\sup _{\|f\|_{B L} \leq 1}\left|\int_{\mathbb{Y}^n} f\left(z_n\left(z_0^{\prime}, y_1^n \right)\right) Pr\left(d y_1^n \mid z_0^{\prime}\right)-
\int_{\mathbb{Y}^n} f\left(z_n\left(z_0, y_1^n \right)\right) Pr\left(d y_1^n \mid z_0\right)\right| \\
&\nonumber \leq \sup _{\|f\|_{B L} \leq 1}\left|\int_{\mathbb{Y}^n} f\left(z_n\left(z_0^{\prime}, y_1^n \right)\right) Pr\left(d y_1^n \mid z_0^{\prime}\right)-
\int_{\mathbb{Y}^n} f\left(z_n\left(z_0^{\prime}, y_1^n\right)\right) Pr\left(d y_1^n \mid z_0\right)\right| \\
&\nonumber +\sup _{\|f\|_{B L} \leq 1} \int_{\mathbb{Y}^n}\left|f\left(z_n\left(z_0^{\prime}, y_1^n\right)\right)-
f\left(z_n\left(z_0, y_1^n \right)\right)\right| Pr\left(d y_1^n \mid z_0 \right) \\
& \leq\left\|Pr\left(\cdot \mid z_0^{\prime}\right)-Pr\left(\cdot \mid z_0\right)\right\|_{T V} \\
& \quad+\sup _{\|f\|_{B L} \leq 1} \int_{\mathbb{Y}^n}\left|f\left(z_n\left(z_0^{\prime}, y_1^n\right)\right)-f\left(z_n\left(z_0, y_1^n\right)\right)\right| 
Pr\left(d y_1^n \mid z_0\right).
\end{align}

We first analyze the first term:
\begin{align}\label{secondtv1}
&\left\|Pr\left(\cdot \mid z_0^{\prime}\right)-Pr\left(\cdot \mid z_0\right)\right\|_{T V}=\sup _{\|g\|_{\infty} \leq 1}\left|\int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid z_0^{\prime}\right)-
\int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid z_0\right)\right|\nonumber \\
&\nonumber =\sup _{\|g\|_{\infty} \leq 1} \bigg\vert \int_{\mathbb{X}} \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid x_1\right) \mathcal{T}\left(d x_1 \mid x_0\right) z_0^{\prime}\left(d x_0\right) \\
&\nonumber \quad \quad -\int_{\mathbb{X}} \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid x_1\right) \mathcal{T}\left(d x_1 \mid x_0\right) z_0\left(d x_0\right) \bigg\vert \\
& = \sup _{\|g\|_{\infty} \leq 1} \bigg\vert \int_{\mathbb{X}}  h_g(x_0) z_0^{\prime} (d x_0)
- \int_{\mathbb{X}}  h_g(x_0) z_0(d x_0) \bigg\vert
\end{align}
where
\begin{align}
    h_g(x_0)=\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid x_1\right) \mathcal{T}\left(d x_1 \mid x_0\right).
\end{align}
For all $x_0^{\prime}, x_0$ and for any $\|g\|_{\infty} \leq 1$, we have
\begin{align*}
& \left|\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid x_1\right) \mathcal{T}\left(d x_1 \mid x_0^{\prime}\right)
-\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g\left(y_1^n\right) Pr\left(d y_1^n \mid x_1\right) \mathcal{T}\left(d x_1 \mid x_0\right)\right| \\
& \leq\left\|\mathcal{T}\left(\cdot \mid x_0^{\prime}\right)-\mathcal{T}\left(\cdot \mid x_0\right)\right\|_{T V} 
\leq \alpha d(x_0^{\prime},x_0).
\end{align*}

So, $\norm{h_g}_\infty \leq 1$ and $\norm{h_g}_L \leq \alpha$. 
Then, by noting that $\frac{1}{1+\alpha}\|h_g\|_{BL} \leq 1$, we can write
\begin{align}\label{nsteptv}
\left\|Pr\left(\cdot \mid z_0^{\prime}\right)-Pr\left(\cdot \mid z_0\right)\right\|_{T V} \leq\left(1+\alpha\right) \rho_{B L}\left(z_0^{\prime}, z_0\right).
\end{align}

Finally, we can analyze the second term in (\ref{secondlemma})
\begin{align}\label{secondlemma2}
&\int_{\mathbb{Y}^n}\left|f\left(z_n\left(z_0^{\prime}, y_1^n\right)\right)
-f\left(z_n\left(z_0, y_1^n\right)\right)\right| Pr\left(d y_1^n \mid z_0\right)\nonumber\\
&\leq \int_{\mathbb{Y}^n} \rho_{BL} (z_n\left(z_0^{\prime}, y_1^n\right), z_n\left(z_0, y_1^n\right)) Pr\left(d y_1^n \mid z_0\right)\nonumber\\
&=\int_{\mathbb{Y}^n} \sup_{g \in \operatorname{BL_1}(\mathbb{X})}\left(\int_{\mathbb{X}} g(x_n)z_n\left(z_0^\prime, y_1^n\right)(dx_n) 
- \int_{\mathbb{X}} g(x_n)z_n\left(z_0, y_1^n\right)(dx_n)\right)Pr\left(d y_1^n \mid z_0\right) \nonumber \\
&=\int_{\mathbb{Y}^n} \left(\int_{\mathbb{X}} g_{y_1^n}(x_n)z_n\left(z_0^\prime, y_1^n\right)(dx_n) 
- \int_{\mathbb{X}} g_{y_1^n}(x_n)z_n\left(z_0, y_1^n\right)(dx_n)\right) Pr\left(d y_1^n \mid z_0\right)
\end{align}
where $g_{y_1^n}:\mathbb{Y}^n \to \operatorname{BL_1}(\mathbb{X})$
 is a measurable function. By the Measurable Selection Theorem
 [\cite{himmelberg1976optimal}, Theorem 2] (see (\ref{inside2})),
 we can choose a measurable function $g_{y_1^n}$. Since the function $g_{y_1^n}$ is measurable, we can rewrite equation (\ref{secondlemma2}) as follows:
\begin{align}\label{secondlemma3}
&\int_{\mathbb{Y}^n} \left(\int_{\mathbb{X}} g_{y_1^n}(x_n)z_n\left(z_0^\prime, y_1^n\right)(dx_n) - \int_{\mathbb{X}} g_{y_1^n}(x_n)z_n\left(z_0, y_1^n\right)(dx_n)\right) Pr\left(d y_1^n \mid z_0\right) \nonumber \\
&= \int_{\mathbb{Y}^n} \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right)z_n\left(z_0^\prime, y_1^n\right)(dx_n) Pr\left(d y_1^n \mid z_0\right) 
- \int_{\mathbb{Y}^n} \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right)z_n\left(z_0, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0\right) \nonumber \\
&= \int_{\mathbb{Y}^n} \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right)z_n\left(z_0^\prime, y_1^n\right)(dx_n) Pr\left(d y_1^n \mid z_0\right) 
- \int_{\mathbb{Y}^n} \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(x_n) Pr\left(d y_1^n \mid z_0^\prime \right) \nonumber\\
&+ \int_{\mathbb{Y}^n}\int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(dx_n) Pr\left(d y_1^n \mid z_0^\prime\right) 
- \int_{\mathbb{Y}^n} \int_{\mathbb{X}} g_{y_1^n}\left(x_n \right)z_n\left(z_0, y_1^n\right)(dx_n) Pr\left(d y_1^n \mid z_0\right) \nonumber\\
&= \int_{\mathbb{Y}^n} \left( \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n)\right) 
\left( Pr\left(d y_1^n \mid z_0\right)- Pr\left(d y_1^n \mid z_0^\prime \right) \right) \\
&+ \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0^\prime\right) 
- \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0, y_1^n\right)(dx_n)Pr\left(d y_1^n \mid z_0\right) 
\end{align}
For the first term 
\begin{align*}
&\int_{\mathbb{Y}^n} \left( \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n)\right) 
\left( Pr\left(d y_1^n \mid z_0\right)- Pr\left(d y_1^n \mid z_0^\prime \right) \right) \nonumber \\
&=\int_{\mathbb{X}} \int_{\mathbb{X}} \int_{\mathbb{Y}^n}  g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n) 
Pr(dy_1^n|x_1)T(dx_1|x_0)z_0(dx_0)\nonumber \\ 
&-\int_{\mathbb{X}} \int_{\mathbb{X}} \int_{\mathbb{Y}^n}  g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n) 
Pr(dy_1^n|x_1)T(dx_1|x_0)z_0^\prime(dx_0)\nonumber \\ 
&=\int_{\mathbb{X}} z_0^\prime(dx_0) \bar{h}_g(x_0) - \int_{\mathbb{X}} z_0(dx_0) \bar{h}_g(x_0),
\end{align*}
where 
\begin{align*}
    \bar{h}_g(x_0)=\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n)Pr(dy_1^n|x_1)T(dx_1|x_0).
\end{align*}
For all $x_0^{\prime}, x_0$, we have
\begin{align*}
& \bigg | \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n)Pr(dy_1^n|x_1)T(dx_1|x_0) \\
& -\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n)Pr(dy_1^n|x_1)T(dx_1|x_0^\prime) \bigg | \\
& \leq\left\|\mathcal{T}\left(\cdot \mid x_0^{\prime}\right)-\mathcal{T}\left(\cdot \mid x_0\right)\right\|_{T V} 
\leq \alpha d(x_0^{\prime},x_0),
\end{align*}
by Assumption \ref{asm1}-ii.

So, $\norm{\bar{h}_g}_\infty \leq 1$ and $\norm{\bar{h}_g}_L \leq \alpha$. 
Then, we can write
\begin{align}\label{secondfirstterm}
    &\int_{\mathbb{Y}^n} \left( \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n)\right) 
    \left( Pr\left(d y_1^n \mid z_0\right)- Pr\left(d y_1^n \mid z_0^\prime \right) \right) \nonumber \\
    &\leq\left(1+\alpha\right) \rho_{B L}\left(z_0^{\prime}, z_0\right).
\end{align}

For the second term
\begin{align}
&\nonumber \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0^\prime\right) 
- \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0, y_1^n\right)(dx_n)Pr\left(d y_1^n \mid z_0\right) \\
& = \int_{\mathbb{X}} \omega(x_0) z_0^\prime(d x_0) 
- \int_{\mathbb{X}} \omega (x_0) z_0(d x_0)
\end{align}
where 
\begin{align}
   \omega(x_0)= \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(x_0, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid x_0\right).
\end{align}
For any $x_0, x_0^{\prime} \in \mathbb{X}$, 
\begin{align*}
& \omega(x_0^{\prime}) - \omega(x_0)\\
&=\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(x_1, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid x_1\right)\mathcal{T}(dx_1\mid x_0^{\prime})\\
&-\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(x_1, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid x_1\right)\mathcal{T}(dx_1\mid x_0)\\
&\leq \left\|\mathcal{T}(\cdot \mid x_0^{\prime})-\mathcal{T}\left(\cdot \mid x_0\right)\right\|_{T V}\\
&\leq \alpha d(x_0^\prime,x_0),
\end{align*}
by Assumption \ref{asm1}-ii.
Thus, for the second term, we have
\begin{align}
&\nonumber \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0^\prime\right) 
- \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0, y_1^n\right)(dx_n)Pr\left(d y_1^n \mid z_0\right) \\
& \leq\left(1+\alpha\right) \rho_{B L}\left(z_0^{\prime}, z_0\right)\label{second2term}.
\end{align}
By using the inequalities (\ref{nsteptv}),(\ref{secondfirstterm}), and (\ref{second2term}), we can write:
$$
\rho_{B L}\left(\eta^n(\cdot \mid z), 
\eta^n\left(\cdot \mid z^{\prime}\right)\right) \leq 
3\left(1+\alpha \right) \rho_{B L}\left(z, z^{\prime}\right).
$$
\end{proof}

\begin{lemma}\label{Lip} Under the Assumption \ref{asm1}-ii, 
    for each function $f\in BL_1(\mathcal{Z})$ with compact 
    support, the sequence of functions 
    $\left\{\int_\mathcal{Z} \eta^n(d z_n\mid z) f(z_n), n \in \mathcal{Z}_{+}\right\}$ 
    is equi-continuous on compact sets under the bounded-Lipschitz norm.
\end{lemma}
\begin{proof}
    The proof is a direct conclusion of Lemma \ref{Regularity}.
\end{proof}

We define the $L$-chain properly as follows:
\begin{defn}
A Markov chain with transition kernel $P$ is called an $L$-chain if for each bounded and Lipschitz continuous function with compact support, the sequence of functions $\{\int P^n(d y\mid z) f(y), n \in \mathcal{Z}_{+}\}$ are equi-continuous on compact sets.
\end{defn}
\begin{thm}\label{L-chain} Under Assumption \ref{asm1}-i,ii 
    the filter process with transition kernel $\eta$ is an L-chain. 
\end{thm}
\begin{proof} Let $f$ be bounded and Lipschitz continuous function with compact support. 
Then, $\left\{\int \eta^n(d y\mid z) f(y), n \in \mathcal{Z}_{+}\right\}$ is equi-continuous on compact sets 
because $f/(\norm{f}_L+\norm{f}_\infty) \in BL_1(Z)$ and by Lemma \ref{Lip}.
\end{proof}

An $L$-chain, by definition, satisfies the weak Feller property. 
Therefore, proving that a chain is an $L$-chain is sufficient 
to show that it also satisfies the weak Feller property. 
Hence, in the theorems that we will present later, 
it is not necessary to explicitly mention that the chain 
satisfies the weak Feller property. Additionally, 
under Assumption \ref{ErgodicityHMM}(ii), 
where the transition kernel is continuous in total variation, 
we know that the weak Feller property holds \cite{KSYWeakFellerSysCont}.

\begin{defn}
Let $\pi$ be a probability measure on $\mathbb{X}$ with metric $d$. The topological support of $\pi$ is defined with
$$
\operatorname{supp} \pi:=\left\{x: \pi\left(B_r(x)\right)>0\right\}, \quad \forall r>0,
$$
where $B_r(x)=\{y \in \mathbb{X}: d(x, y)<r\}$.
\end{defn}

\begin{defn}
    For a Markov chain with transition kernel $P$, 
    a point $x$ is topologically reachable if 
    for every y and every open neighborhood 
    $O$ of $x$, there exists $k>0$ such that $P^k(y, O)>0$.
\end{defn}


\begin{defn}
    For a Markov chain with transition kernel $P$, 
    a point $x$ is topologically aperiodic if $P^k(x, O)>0$
    for every open neighborhood 
    $O$ of $x$ and for all $k\in \mathbb{N}$ sufficiently large.
\end{defn}

\begin{thm}[\cite{Hernandez-Lerma2003}, Thm 7.2.3] \label{compactness}
    Let $\left\{x_t\right\}$ be a weak Feller Markov
    process taking values in a compact subset of a complete,
    separable metric space. Then $\left\{x_t\right\}$
    admits an invariant probability measure.
\end{thm}

\begin{thm}\label{Essential}
     If a weak Feller Markov chain is an L-chain, 
     the state space $\mathcal{Z}$ is compact, 
     and a reachable state $z^*$ exists, 
     then there exists a unique invariant probability measure.
     Moreover if the reachable state $z^*$ is 
     topologically aperiodic, then
     the Markov process converges weakly to the unique invariant
     probability measure for every initial state.
\end{thm}

\begin{proof} By Theorem \ref{compactness} there is an invariant probability measure. Let there be two different probability measures $\nu_1, \nu_2$. We may assume $\nu_1$ and $\nu_2$ to be ergodic, via an ergodic decomposition argument of invariant measures on compact subsets [\cite{Tweedie-94}, Theorem 6.1].

Since $z^*$ is reachable state,  we have that $B_r\left(z^*\right)$ is visited under either of the probability measures in finite time for any given $r>0$. So, $z^*$ must be belong to the support of $\nu_1$ and $\nu_2$.
Then, we have two sequences $x_n, y_n$ which converge to $z^*$ where $x_n, y_n$ belong to 
the topological support sets of $\nu_1, \nu_2$, respectively. 

Now, by equi-continuity and the Arzela-Ascoli theorem, for every bounded and Lipschitz continuous function $f$ we have that
\begin{align}\label{subseq}
\eta^{(N)}(f)(z):=\frac{1}{N} \sum_{k=0}^{N-1} \int \eta^k(z, d y) f(y)
\end{align}
has a subsequence which converges (in the sup norm) to a limit $F_f^*: \mathcal{Z} \rightarrow \mathbb{R}$, where is $F_f^*$ continuous.
The above imply that, every bounded and Lipschitz continuous function $f$, the term
$$
\lim _{n \rightarrow \infty}\left|\lim _{N \rightarrow \infty} \eta^{(N)}(f)\left(y_n\right)-\eta^{(N)}(f)\left(x_n\right)\right|=0 .
$$
Suppose not; there would be an $\epsilon>0$ and a subsequence $n_k$ for which the difference
$$
\left|\lim _{N \rightarrow \infty} \eta^{(N)}(f)\left(y_{n_k}\right)-\eta^{(N)}(f)\left(x_{n_k}\right)\right|>\epsilon .
$$
However, for each fixed $n_k$, we have that
$$
\lim _{N \rightarrow \infty} \eta^{(N)}(f)\left(y_{n_k}\right)
$$
converges by the ergodicity of $\nu_1$ to 
$\left\langle\nu_1, f\right\rangle:=\int_{\mathcal{Z}}f(z)\nu_1(dz)$ 
and the limit, by the Arzela-Ascoli theorem, will be equal to $F_f^*\left(y_{n_k}\right)$ (as every converging subsequence would have to converge to the limit; which also implies that the subsequential convergence in (\ref{subseq}) is in fact a sequential convergence). The same argument applies for $\eta^{(N)}(f)\left(x_{n_k}\right) \rightarrow\left\langle\nu_2, f\right\rangle=F_f^*\left(x_{n_k}\right)$.

The above would then imply that $\left|F_f^*\left(y_{n_k}\right)-F_f^*\left(x_{n_k}\right)\right| \geq \epsilon$ for every $\left(y_{n_k}, x_{n_k}\right)$. 
This would be a contradiction due to the continuity of $F_f^*$. 
Therefore, the time averages of $f$ under $\nu_1$ and $\nu_2$ will be arbitrarily close to each other. 
Then, for every bounded and Lipschitz continuous function $\left\langle\nu_1, f\right\rangle-\left\langle\nu_2, f\right\rangle=0$, therefore $\rho_{BL}(\nu_1, \nu_2)=0$. 
Since $\rho_{BL}$ is a metric on $P(Z)$, this implies that the probability measures $\nu_1$ and $\nu_2$ must be equal.

This proves that there exist a unique
 invariant probability measure.
 Let this invariant measure be $\nu$. 

 Now let us prove the second part of the theorem. 
 That is, if $z^*$ is an topological aperiodic state, 
 then for any initial state, 
 the Markov process weakly converges to $\nu$. 
 For this, we will show that the proof given in 
 \cite{MeynBook} Theorem 18.4.4-ii for the $e-$chain
is also valid for the $L-$chain. 

First, let us take any bounded and 
continuous Lipschitz function $f$. 
Without loss of generality, let us accept 
$\int_\mathcal{Z}f(z)\nu(dz)=0$ as we can add a constant to $f$.

Due to the Arzela-Ascoli theorem and equicontinuity,
\begin{align}\label{seq}
\eta^{N}(f)(z):=\int \eta^N(z, d y) f(y)
\end{align}
has a subsequence which converges 
uniformly (in the sup norm) to a 
limit $H_f^*: \mathcal{Z} \rightarrow \mathbb{R}$, 
where $H_f^*$ is continuous.

First, using aperiodicity, we will prove that
$H_f^*$ takes the value $0$ for every element 
in the topological support of $\nu$. 
Then, we will prove that this function
is $0$ for every element. 
Finally, we will prove that the above series, 
i.e., $\eta^N(f)$, converges to $0$.

Let's take any open neighborhood around $z^*$, 
let it be $O$. 
The lower semi-continuity of $\eta^k(.,O)$ 
follows from the weak Feller property of 
$\eta$ and the Portmanteau theorem. 
Consequently, for sufficiently large $k$, 
an open neighborhood $\bar{O}$ 
exists around $z^*$ such that 
$\eta^k(z,O)>0$ for every $z\in\bar{O}$.
 Since $z^*$ is reachable, the Markov chain starting from 
 $\nu$ visits $\bar{O}$ within a finite time
 from almost every initial state. 
 This proves that $\nu(O)>0$. Thus, 
 $z^*$ is in the topological support of $\nu$.


 First, let's show that $H_f^*(z)=0$ 
 for all $z$ in the topological support of $\nu$. 
 Otherwise, the sets $O^+=\{z:H_f^*(z)>0\}$ and $O^-=\{z:H_f^*(z)<0\}$ 
 would both have a positive measure in $\nu$ 
 since $\langle\nu, H_f^*\rangle
 =\left\langle\nu, f\right\rangle=0$. 
 Since the function $H_f^*$ is continuous, 
 both sets are open. Due to ergodicity, 
 and similar to above arguments, 
 we know that for any $h$ bounded continuous 
 function, $F_h^*(z^*)$ is equal to 
 $\left\langle\nu, h\right\rangle$. 
 Since $\nu(O^+)>0$ and $O^+$ is open, 
 we can define the function $h$ to be $0$ outside $O^+$ 
 and $\left\langle\nu, h\right\rangle>0$. 
 In this case, $F_h^*(z^*)>0$ 
 which proves that there exists a 
 $k_1\in \mathbb{N}$ such that 
 $\eta^{k_1}(z^*,O^+)>0$. Similarly, 
 there exists a $k_2\in \mathbb{N}$ 
 such that $\eta^{k_2}(z^*,O^-)>0$. 
 As $\eta^{k}(.,O^+)$ is lower semi-continuous, 
 there exists an open neighborhood 
 $O^\prime$ around $z^*$ such that for 
 every $z\in O^\prime$, $\eta^{k_1}(z,O^+)>0$ 
 and $\eta^{k_2}(z,O^-)>0$. 
 As $z^*$ is topologically aperiodic, 
 for all sufficiently large $k$, $\eta^{k}(z^*,O^\prime)>0$. 
 Therefore, there exists an $l\in \mathbb{N}$ 
 such that $\eta^{l}(z^*,O^+)>0$ and $\eta^{l}(z^*,O^-)>0$. 
 Again, since $\eta^{l}(.,O^+)$ and $\eta^{l}(.,O^-)$ 
 are lower semi-continuous, 
 there exists an open neighborhood $N$ around 
 $z^*$ such that for every $z\in N$, $\eta^{l}(z,O^+)>0$ 
 and $\eta^{l}(z,O^-)>0$. 
 Therefore, for every $z \in N$, 
 $|\eta^l(H_f^*)(z)|<\eta^l(|H_f^*|)(z)$. 
 Since $z^*$ is in the topological support, 
 we know that $\nu(N)>0$. From here, we reach the conclusion that
 \begin{align}\label{ineqH}
 \langle \nu,|\eta^l(H_f^*)|\rangle <
 \langle\nu,\eta^l(|H_f^*|)\rangle =
 \langle\nu, |H_f^*|\rangle
 \end{align}
 where the equality comes from $\nu$ being stationary.

 However, if we focus on the function $f$, for every $k\in\mathbb{N}$,
\begin{align*}
&\langle \nu,|\eta^k(f)|\rangle=
\int_\mathcal{Z} |\eta^k(f)|(z)\nu(dz)=
\int_\mathcal{Z} \eta(|\eta^k(f)|)(z)\nu(dz)\\
&=\int_\mathcal{Z}\int_\mathcal{Z} |\eta^k(f)|(y)\eta(z,dy)\nu(dz)=
\int_\mathcal{Z}\int_\mathcal{Z} |\eta^{k}(f)(y)\eta(z,dy)|\nu(dz)\\
&\geq \int_\mathcal{Z}|\eta^{k+1}(f)(z)|\nu(dz)=
\langle \nu,|\eta^{k+1}(f)|\rangle
\end{align*}
the last inequality follows from triangle inequalities.

From the Monotone Convergence Theorem, 
the sequence $\langle \nu,|\eta^k(f)|\rangle$ has a real limit. 
Let's denote this limit as $v$. 
Since the sequence $\eta^{k_i}(f)$ converges to $H_f^*$ for some 
series $k_i$, and the sequence $\eta^{k_i+l}(f)$ converges 
to $\eta^l(H_f^*)$, we have $\langle \nu,|\eta^l(H_f^*)|\rangle=v=
\langle \nu,|H_f^*|\rangle$. 
This contradicts the inequality we 
found earlier in equation (\ref{ineqH}).

This gives us that $H_f^*(z)=0$ for every $z$ 
in the topological support of $\nu$. 
Now, let's prove this for every $z\in \mathcal{Z}$.

The sequence $\bar{\eta}^N(z,.):=\frac{1}{N}\sum_{i=1}^{N} \eta^i(z,.)$
converges to $\nu$, because since $\mathcal{Z}$ is a Polish space, 
the sequence has a limit, and the limit is stationary. 
However, since the unique invariant distribution is $\nu$, 
it converges to $\nu$.


For any $\epsilon>0$, the set
\begin{align*}
O_\epsilon=\{ z\in \mathcal{Z}: \limsup_{k \to \infty}
|\eta^k(f)|<\epsilon \}
\end{align*}
is an open set and contains all elements in the topological 
support of $\nu$. 
Therefore, $\nu(O_\epsilon)=1$, 
meaning for any $z\in\mathcal{Z}$, 
we have $\lim_{N \to \infty}\bar{\eta}^N(z,O_\epsilon)=1$. 
From this, for a sufficiently large 
$M\in \mathbb{N}$, $\eta^M(z,O_\epsilon)>1-\epsilon/
\norm{f}_\infty$ holds.

As a result,
\begin{align*}
&|H_f^*(z)|\leq \limsup_{k \to \infty} |\eta^{k+M}(f)(z)|\\
&\leq \norm{f}_\infty \eta^M(z,O_\epsilon^C)+
\limsup_{k \to \infty} \int_{O_\epsilon}
\eta^M(z,dy) |\eta^k(f)(y)|\leq 2\epsilon
\end{align*}

So, for every $z\in \mathcal{Z}$, $H_f^*(z)=0$ holds. 
By the Arzela-Ascoli theorem, the convergence is uniform,
so for a certain series $k_i$, the series 
$\eta^{k_i}(f)$ uniformly converges to $0$.


For any $\epsilon>0$, 
there exists a $k\in \mathbb{N}$ such that for every 
$z\in \mathcal{Z}$, $|\eta^{k}(f)(z)|<\epsilon$ holds. 
For any $m \in \mathbb{N}$,
\begin{align*}
|\eta^{k+m}(f)(z)|=
\bigg|\int_\mathcal{Z}\eta^m(z,dy)\eta^k(f)(y) \bigg|\leq\epsilon
\end{align*}

Therefore, $\eta^{N}(f)(z)$ uniformly converges to 
$\langle\nu, f\rangle=0$.
This is valid for all bounded and Lipschitz continuous functions and these functions are dense in the set of bounded continuous functions. Therefore, for every $z\in \mathcal{Z}$, $\eta^N(z,.)$ weakly converges to $\nu$.
\end{proof}
\subsubsection{Existence of a reachable state}

In this subsection of this paper, 
we will proceed under the assumption that 
Assumption \ref{Con} holds. 
We refer to the observed state as $\bar{y}$, 
which can be observed from every state.

\begin{defn}
    \begin{align}
        \pi_n^{\mu *}(\cdot)=P^{\mu}\left(X_n \in \cdot \mid Y_{[0, n]}=(\bar{y},\dots, \bar{y})\right), n \in \mathbb{N}
    \end{align} where $P^{\mu}$ is the probability measure induced by the prior $\mu$.
\end{defn}

For given $\bar{y}$, we define a new Markov evolution as follows:
The state space of the Markov chain is $\mathbb{X}$, and the transition
kernel is defined as
$T_{\bar{y}}(A|x_0):=Pr(A|X_0=x_0, Y_1=\bar{y})$ for all $A\in B(X)$.

We claim that under Assumption \ref{ErgodicityHMM}-iii, 
$\pi_n^{\mu *}(\cdot)$ converges to a unique measure $\pi^{*}$
for any initial measure $\mu$. 
This implies that the limit measure $\pi^{*}$ is a 
reachable state for the filter process.

We should note that the transition kernel, 
as the measurement space is countable,
$T_{\bar{y}}(dx_1|x_0)$ can be expressed as follows:
\begin{align*}
    &T_{\bar{y}}\left(dx_1 \mid x_0\right)=
    \frac{Q(\bar{y}|x_1)T(dx_1|x_0)}{\int_X Q({\bar{y}}|x_1)T(dx_1|x_0)}.
\end{align*}

Therefore, we have the following inequality:
\begin{align}\label{epsilonT}
    \epsilon T\left(dx_1 \mid x_0\right) 
    \leq T_{\bar{y}}\left(dx_1 \mid x_0\right) 
    \leq \frac{1}{\epsilon} T\left(dx_1 \mid x_0\right).
\end{align}

\begin{lemma}\label{ergodicityPQ}
    Let $P$ and $Q$ be transition kernels of the Markov process
    on $X$. If there exists $\epsilon>0$ such that
    \begin{align}
        \epsilon P\left(dx_1 \mid x_0\right) 
        \leq Q\left(dx_1 \mid x_0\right) 
        \leq \frac{1}{\epsilon} P\left(dx_1 \mid x_0\right) 
        \quad \forall x_0, x_1 \in X
    \end{align}
    then $P$ is uniformly ergodic 
    if and only if $Q$ satisfies the same properties.
\end{lemma}
\begin{proof}
    First, according to Theorem 16.0.2 in \cite{MeynBook}, 
    a Markov chain is uniformly ergodic if and only if it 
    satisfies the following two conditions: (1) it is aperiodic, 
    and (2) it satisfies Doeblin's condition: Doeblin's condition states that there exists a 
    probability measure $\phi$ on $X$, 
    along with constants $\bar{\epsilon} < 1$, 
    $\delta > 0$, and $m \in \mathbb{N}$, 
    such that for any set $A \in B(X)$ with 
    $\phi(A) > \bar{\epsilon}$, the following inequality holds:
    \begin{align}
    \inf_{x \in X} P^m(A \mid x) > \delta,
    \end{align}
    where $P^m(A \mid x)$ denotes the $m$-step transition 
    probability of the Markov chain.
    
    Now, let us consider two Markov chains, $P$ and $Q$, 
    with transition kernels $P(dx_1 \mid x_0)$ and $Q(dx_1 \mid x_0)$, 
    respectively. We assume that there exists $\epsilon > 0$ such that
    \begin{align}
    \epsilon P(dx_1 \mid x_0) \leq Q(dx_1 \mid x_0) \leq \frac{1}{\epsilon} P(dx_1 \mid x_0)
    \end{align}
    for all $x_0, x_1 \in X$.
    
    We claim that if $P$ satisfies Doeblin's condition, 
    then $Q$ satisfies the same condition, and vice versa. 
    This can be seen by observing that for any set $A \in B(X)$ 
    and $x_0 \in X$, we have
    \begin{align}
    P^m(A \mid x_0) > \delta \quad \text{if and only if} \quad Q^m(A \mid x_0) > \delta \epsilon^m.
    \end{align}
    Therefore, if $P$ satisfies Doeblin's condition, 
    with the corresponding constants $\bar{\epsilon}$, $\delta$, and $m$, 
    then $Q$ also satisfies Doeblin's condition with 
    the constants $\bar{\epsilon}$, $\epsilon^m \delta$, and $m$. 
    Moreover, it can be shown that if a set is $\nu_m$-small 
    with respect to Markov chain $P$, 
    then it is also $\epsilon^m \nu_m$-small with 
    respect to Markov chain $Q$, and vice versa,
    then if one of them is aperiodic, so is the other.
    Because, if $Q$ is not aperiodic and had a period of $d>1$, 
    this means that there exist disjoint sets 
    $A_1,A_2,...,A_d$ in X and for each $i$, 
    if $x\in A_i$, then $Q(A_{i+1}|x)=1$. 
    This implies that for any $j$ not equal to $i+1$, 
    $P(A_{j}|x)=0$, which means that 
    $P$ would also not be aperiodic.
    
    Therefore, if one of the Markov chains $P$ or $Q$ is 
    uniformly ergodic, then the other chain satisfies the same property.    
\end{proof}

Now, under Assumption \ref{ErgodicityHMM}-iii, 
by using inequality (\ref{epsilonT}) and 
Lemma \ref{ergodicityPQ},
we can conclude that 
$\pi_n^{\mu *}(\cdot)$ uniformly converges
to a unique measure $\pi^{*}$ in total variation norm
over any initial measure $\mu$.

For any open neighborhood $O$ of $\pi^{*}$, 
there exist $\kappa>0$
such that $O \supset B_\kappa(\pi^{*}):=
\{\mu\in \mathcal{Z}: \rho_{BL}(\mu,\pi^{*})<\kappa\}$.

 
We know that $\lim_{n\to\infty} \pi_n^{\mu *}(\cdot)\to \pi ^*$ 
for any $\mu$. Under Assumption \ref{Con},
we also know that $Pr^{\mu}(Y_1=\bar{y})>\epsilon$ 
for any $\mu$.
Since convergence in total variation implies
convergence in the bounded Lipschitz metric,
there exists a sufficiently large $M$ such that,
for any $n>M$,
$\pi_n^{\mu *}(\cdot)\in O$ and 
$Pr^{\mu}(Y_{[0, n]}=(\bar{y},\dots, \bar{y}))>0$
This is true for any initial prior $\mu$,
so $\pi^{*}$ is topologically reachable.
It is also true for $\mu=\pi^{*}$, 
meaning $\pi^{*}$ is topologically aperiodic.
Thus, $\pi ^*$ is a topologically 
reachable aperiodic state. 


\begin{proof}[Proof of Theorem \ref{Main2}]    
    Under Assumptions \ref{ErgodicityHMM}-i and ii, 
    we have proved that the filter process is an $L$-chain 
    (Theorem \ref{L-chain}). We also know that 
    $\mathcal{Z}$ is compact. 
    Furthermore, under Assumptions \ref{ErgodicityHMM}-iii 
    and \ref{Con}, $\pi^*$ is a topologically 
    reachable aperiodic state for the filter process. 
    We complete the proof using Theorem \ref{Essential}.
\end{proof}

\begin{eg}
Consider a system where $\mathbb{X}=\{0, 1,\cdots,s-1\}$, $\mathbb{Y}=\mathbb{Z}$ and the transition and measurement kernels are given by
$$
x_{n+1} \equiv \lfloor f\left(x_n\right)+W_n\rfloor \quad (\bmod s), \quad W_n=N\left(0, \sigma_1^2\right) 
$$
and
$$y_n=\lfloor g\left(x_n\right)+V_n\rfloor, \quad V_n=N\left(0, \sigma_2^2\right)$$
where the function $f$ is measurable, $g$ is measurable and bounded such that $g(x) \in$ $[-k, k]$, $W_n$ and $V_n$ are independent Gaussian noise sources with variances $\sigma_1^2$ and $\sigma_2^2$, respectively, and the function $\lfloor \cdot \rfloor$ denotes the floor function.
\end{eg}

Since the hidden Markov model is finite, irreducible, 
aperiodic, and recurrent, it is uniformly ergodic. 
Additionally, the condition $\inf_{x\in\mathbb{X}} Q(0 \mid x) > 0$ 
is satisfied. Hence, the model fulfills the 
requirements of Corollary \ref{Main2Cor}.

\begin{remark}
Kochman and Reeds\cite{kochman2006simple} proved that under 
the Condition KR, the filter process is uniquely ergodic. 
They carried out their proof in a manner similar to ours. 
In this remark, we will explain how Condition KR guarantees 
the existence of a reachable state. Due to the rank-1 condition 
and the irreducibility of the hidden Markov model, 
there exists a sequence $y^k=(y^k_1, y^k_2, \dots, y^k_{n_k})$ 
such that $P^{\delta_x}\left(X_{n_k} \in \cdot \mid Y_{[0, n_k]}=y^k\right)$ 
converges to a constant probability measure $\mathbb{P}(\mathbb{X})$ 
for every $x \in \mathbb{X}$ as $k$ goes to infinity; 
we denote this measure by $\pi \in \mathbb{P}(\mathbb{X})$. 
The filter process converges to the 
same point for any initial distribution. Thus, 
$P^{\mu}\left(X_{n_k} \in \cdot \mid Y_{[0, n_k]}=y^k\right)$ 
converges to $\pi$ for every $\mu \in \mathbb{P}(\mathbb{X})$ as $k$ 
goes to infinity. Therefore, $\pi$ is a reachable state.
\end{remark}


\section{Controlled Case: New Results on the Average Cost Optimality Equation and Limitations on Unique Ergodicity}\label{controlledPOMDPACOESec}


Let $\mathbb{U}$ be a Polish space denoting the control action space. 
In this controlled environment, the measurement channel $Q$ remains unchanged, but the transition kernel $T(dx^\prime|x, u)$ varies depending on the control action, $u$, applied.
An admissible (deterministic) policy $\gamma$ is a sequence of control functions $\left\{\gamma_t, t \in \mathcal{Z}_{+}\right\}$ such that $\gamma_t$ is measurable function with respect to the $\sigma$-algebra generated by the information variables $I_t=\left\{Y_{[0, t]},U_{[0,t-1]}\right\}, t \in \mathbb{N}$, $I_0=\left\{Y_0\right\}$, where
$$
U_t=\gamma_t\left(I_t\right), \quad t \in \mathcal{Z}_{+}
$$
are the $\mathbb{U}$-valued control actions and $Y_{[0, t]}=\left\{Y_s, 0 \leq s \leq t\right\}$, $U_{[0, t]}=\left\{U_s, 0 \leq s \leq t\right\}$. We can restrict ourselves to only control policies that are functions of the measurements $Y_{[0,t]}$, since the past control values are also functions of past measurements where the dependence on the initial distribution $\pi_0$ is implicit. We will denote the collection of admissible control policies as $\Gamma$.

We let the agent's goal be to minimize the expected discounted cost of its actions over an infinite period of time.
$$
J_\beta(\mu, \mathcal{T}, \gamma)=E_\mu^{\mathcal{T}, \gamma}\left[\sum_{t=0}^{\infty} \beta^t c\left(X_t, U_t\right)\right]
$$
for some discount factor $\beta \in(0,1)$, over the set of admissible policies $\gamma \in \Gamma$, where $c: \mathbb{X} \times \mathbb{U} \rightarrow \mathbb{R}$
is the stage-wise cost function $c(X_t, U_t)$ measures the cost of taking action $U_t$ in state $X_t$, and the expectation $E_\mu^{\mathcal{T}, \gamma}$ is taken over the initial state probability measure $\mu$ and the transition kernel $\mathcal{T}$ under policy $\gamma$.
The optimal cost for the discounted infinite horizon is defined as a function of the initial state probability measures and the transition kernels
$$J_\beta^*(\mu, \mathcal{T})=\inf _{\gamma \in \Gamma} J_\beta(\mu, \mathcal{T}, \gamma).$$
 
The optimal cost function $J_\beta^*(\mu, \mathcal{T})$ represents the minimum expected cost that can be achieved by the decision maker over an infinite horizon, given the initial state probability measure $\mu$ and the transition kernel $\mathcal{T}$. The discount factor $\beta$ determines the importance of costs incurred in the future relative to those incurred in the present. If $\beta$ is close to 1, then the decision maker places a high value on future costs and may be willing to incur higher costs in the present in order to minimize costs in the future. On the other hand, if $\beta$ is close to 0, then the decision maker places a low value on future costs and may be more willing to incur higher costs in the future in order to minimize costs in the present.

The average cost control problem under partial observations involves finding the optimal policy that minimizes the average cost of the system over an infinite horizon.

$$
J(\mu, \mathcal{T}, \gamma)=\limsup_{n \to \infty}\frac{1}{n}E_\mu^{\mathcal{T}, \gamma}\left[\sum_{t=0}^{\infty} c\left(X_t, U_t\right)\right]
$$
$$J^*(\mu, \mathcal{T})=\inf _{\gamma \in \Gamma} J(\mu, \mathcal{T}, \gamma).$$

\begin{defn}
The filter process is defined as the sequence of conditional probability measures
$$
\pi_n^{\mu, \gamma}(\cdot)=P^{\mu, \gamma}\left(X_n \in \cdot \mid Y_{[0, n]}, U_{[0, n-1]}\right)=P^{\mu, \gamma}\left(X_n \in \cdot \mid Y_{[0, n]}\right), \quad n \in \mathbb{N}
$$
where $P^{\mu, \gamma}$ is the probability measure induced by the prior $\mu$ and the policy $\gamma$. We do not need to write $U_{[0, n-1]}$ since $U_{[0, n-1]}=\gamma_n\left(Y_{[0, n-1]}\right)$
\end{defn}

The transition probability $\eta$ of the filter 
process can be determined via the 
following equation (see also \cite{hernandez1989adaptive}): 
\begin{align}\label{conteta}
\eta(\cdot \mid z, u)=\int_{\mathbb{Y}} 1_{\{F(z, u, y) \in \cdot\}} P(d y \mid z, u),
\end{align}

where $P(\cdot \mid z, u)=\operatorname{Pr}\left\{Y_{n+1} \in \cdot \mid Z_n=\right.$ $\left.z, U_n=u\right\}$ from $\mathcal{Z} \times \mathbb{U}$ to $\mathbb{Y}$ and $$
F(z, u, y):=F(\cdot \mid y, u, z)=\operatorname{Pr}\left\{X_{n+1} \in \cdot \mid Z_n=z, U_n=u, Y_{n+1}=y\right\}
$$
from $\mathcal{Z} \times \mathbb{U} \times \mathbb{Y}$ to $\mathcal{Z}$. 

The one-stage cost function $\tilde{c}$ measures the cost of taking action $u$ at a given stage of the filter process, given the current belief state $z$ of the system. It is defined as the expected cost of taking action $u$, where the expectation is taken over the belief state $z$. The one-stage cost function $\tilde{c}:\mathcal{Z} \times \mathbb{U} \rightarrow \mathbb{R}$ is a Borel measurable function and it is given by
$$
\tilde{c}(z, u):=\int_{\mathbb{X}} c(x, u) z(d x),
$$
where $c: \mathbb{X} \times \mathbb{U} \rightarrow \mathbb{R}$ is the stage-wise cost function.

Therefore, the filter process is a Markov process that is fully observable with the components $(\mathcal{Z}, \mathbb{U}, \tilde{c}, \eta)$.
For the filter process, the information variables is defined as
$$
\tilde{I}_t=\left\{Z_{[0, t]}, U_{[0, t-1]}\right\}, \quad t \in \mathbb{N}, \quad \tilde{I}_0=\left\{Z_0\right\}
$$

\subsection{Wasserstein Regularity for the Controlled Setup}
\begin{thm}\label{Calpha}
Assume that
$(\mathbb{X},d)$ is a bounded compact metric space 
with diameter $D$ and
$$
\left\|\mathcal{T}(\cdot \mid x, u)-\mathcal{T}\left(\cdot \mid x^{\prime}, u\right)\right\|_{T V} \leq \alpha d(x, x^{\prime})
$$
for every $x,x' \in \mathbb{X}$, $u \in \mathbb{U}$ and some $\alpha<\infty$. 
Then, we have
\begin{align}\label{ContrC}
W_{1}\left(\eta(\cdot \mid z_0, u), \eta\left(\cdot \mid z_0^{\prime},u\right)\right) 
\leq \left(\frac{\alpha D (3-2\delta(Q))}{2}\right) W_{1}\left(z_0, z_0^{\prime}\right)
\end{align}
for all $z_0,z_0' \in \mathcal{Z}$ and $u \in \mathbb{U}$.
\end{thm}
\begin{proof}
    Let $u$ be a fixed control action. Define a control-free partially observed process by the transition kernel $\bar{T}(\cdot | x) = T(\cdot | x, u)$, and observation kernel $Q$. This process satisfies Assumption 1-i,ii. Consequently, inequality \eqref{ContrC} is derived as a conclusion of Theorem \ref{Talpha}.
\end{proof}
A similar theorem can be presented for the bounded 
Lipschitz norm as a generalization of Lemma \ref{Regularity}:
\begin{thm}\label{CBLalpha}
Assume that $\X$ and $\Y$ are Polish spaces and 
$$
\left\|\mathcal{T}(\cdot \mid x, u)-\mathcal{T}\left(\cdot \mid x^{\prime}, u\right)\right\|_{T V} \leq \alpha d(x, x^{\prime})
$$
for every $x,x' \in \mathbb{X}$, $u \in \mathbb{U}$ and some $\alpha<\infty$. 
Then, for any control action sequence $u_{[0,n-1]}=(u_0, \dots, u_{n-1})\in \U^n$
we have the following inequality:
\begin{align}\label{ContBL}
\rho_{B L}\left(\eta^n(\cdot \mid z_0, u_{[0,n-1]}), 
\eta^n\left(\cdot \mid z_0^{\prime}, u_{[0,n-1]}\right)\right) \leq 
3\left(1+\alpha \right) \rho_{B L}\left(z_0, z_0^{\prime}\right)
\end{align}
\end{thm}
\begin{proof}[Proof sketch]
Since the proof is similar to that of Lemma 
\ref{Regularity}, we will provide a short proof. 
We equip $\mathcal{Z}$ 
with the metric $\rho_{BL}$ to define the bounded-Lipschitz 
norm $|f|_{BL}$ for any Borel measurable function 
$f: \mathcal{Z}\rightarrow \mathbb{R}$. 

Similar to the method used in inequality (\ref{secondlemma}), 
we have 
\begin{align} \label{Ctsecondlemma}
&\nonumber \rho_{B L}\left(\eta^n(\cdot \mid z_0, u_{[0,n-1]}), \eta^n\left(\cdot \mid z_0^{\prime}, u_{[0,n-1]}\right)\right) \\  
& \leq\left\|Pr\left(\cdot \mid z_0^{\prime}\right)-Pr\left(\cdot \mid z_0\right)\right\|_{T V} \\
& \quad+\sup _{\|f\|_{B L} \leq 1} \int_{\mathbb{Y}^n}\left|f\left(z_n\left(z_0^{\prime}, u_{[0,n-1]}, y_1^n\right)\right)-f\left(z_n\left(z_0, u_{[0,n-1]}, y_1^n\right)\right)\right| 
Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right).
\end{align}
By inequality (\ref{nsteptv}), we know that
\begin{align}\label{Ctnsteptv}
    \left\|Pr\left(\cdot \mid z_0^{\prime}\right)-Pr\left(\cdot \mid z_0\right)\right\|_{T V} \leq\left(1+\alpha\right) \rho_{B L}\left(z_0^{\prime}, z_0\right).
\end{align}

For the second term in (\ref{Ctsecondlemma}),
we refer to inequality (\ref{secondlemma2})
and equality (\ref{secondlemma3}) to
conclude the existence of a measurable function 
$g_{y_1^n}:\mathbb{Y}^n \to \operatorname{BL_1}(\mathbb{X})$
satisfying:
\begin{align}\label{Ctsecondlemma2}
&\int_{\mathbb{Y}^n}\left|f\left(z_n\left(z_0^{\prime}, u_{[0,n-1]}, y_1^n\right)\right)
-f\left(z_n\left(z_0, u_{[0,n-1]}, y_1^n\right)\right)\right| Pr\left(d y_1^n \mid z_0,  u_{[0,n-1]}\right)\nonumber\\
&\leq \int_{\mathbb{Y}^n} \left( \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n)\right) 
\left( Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right)- Pr\left(d y_1^n \mid z_0^\prime, u_{[0,n-1]} \right) \right) \nonumber\\
&+ \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0^\prime, u_{[0,n-1]}\right)\\ 
&- \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0, u_{[0,n-1]}, y_1^n\right)(dx_n)Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right) 
\end{align}
For the first term, we have
\begin{align*}
&\int_{\mathbb{Y}^n} \left( \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n)\right) 
\left( Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right)- Pr\left(d y_1^n \mid z_0^\prime, u_{[0,n-1]} \right) \right) \nonumber\\
&=\int_{\mathbb{X}} z_0^\prime(dx_0) \bar{h}_g(x_0) - \int_{\mathbb{X}} z_0(dx_0) \bar{h}_g(x_0),
\end{align*}
where 
\begin{align*}
    \bar{h}_g(x_0)=\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n)Pr(dy_1^n|x_1, u_{[1,n-1]})T(dx_1|x_0, u_0).
\end{align*}
For all $x_0^{\prime}, x_0\in \X$,
\begin{align*}
| \bar{h}_g(x_0)- \bar{h}_g(x_0^{\prime}) |
\leq\left\|\mathcal{T}\left(\cdot \mid x_0^{\prime}, u_0\right)-\mathcal{T}\left(\cdot \mid x_0, u_0\right)\right\|_{T V} 
\leq \alpha d(x_0^{\prime},x_0).
\end{align*}
Thus, $\norm{\bar{h}_g}_\infty \leq 1$ and $\norm{\bar{h}_g}_L \leq \alpha$. 
Consequently,
\begin{align}\label{Ctsecondfirstterm}
    &\int_{\mathbb{Y}^n} \left( \int_{\mathbb{X}} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n)\right) 
    \left( Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right)- Pr\left(d y_1^n \mid z_0^\prime, u_{[0,n-1]} \right) \right) \nonumber\\
    &\leq\left(1+\alpha\right) \rho_{B L}\left(z_0^{\prime}, z_0\right).
\end{align}
For the last terms,
\begin{align*}
&\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0^\prime, u_{[0,n-1]}\right)\\ 
&- \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0, u_{[0,n-1]}, y_1^n\right)(dx_n)Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right) \\
& = \int_{\mathbb{X}} \omega(x_0) z_0^\prime(d x_0) 
- \int_{\mathbb{X}} \omega (x_0) z_0(d x_0)
\end{align*}
where 
\begin{align}
   \omega(x_0)= \int_{\mathbb{X}}\int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(x_0, u_{[0,n-1]}, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid x_1, u_{[1,n-1]}\right)\mathcal{T}(dx_1\mid x_0, u_0).
\end{align}
For all $x_0, x_0^{\prime} \in \mathbb{X}$, 
\begin{align*}
& \omega(x_0^{\prime}) - \omega(x_0) \leq \left\|\mathcal{T}(\cdot \mid x_0^{\prime}, u_0)-\mathcal{T}\left(\cdot \mid x_0, u_0\right)\right\|_{T V}
\leq \alpha d(x_0^\prime,x_0).
\end{align*}
Therefore, $|\omega|_\infty \leq 1$ and $|\omega|_L \leq \alpha$. 
As a result,
\begin{align}
    &\int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0^\prime, u_{[0,n-1]}, y_1^n\right)(d x_n) Pr\left(d y_1^n \mid z_0^\prime, u_{[0,n-1]}\right)\nonumber\\ 
    &- \int_{\mathbb{X}} \int_{\mathbb{Y}^n} g_{y_1^n}\left(x_n\right) z_n\left(z_0, u_{[0,n-1]}, y_1^n\right)(dx_n)Pr\left(d y_1^n \mid z_0, u_{[0,n-1]}\right) \nonumber\\
    & \leq\left(1+\alpha\right) \rho_{B L}\left(z_0^{\prime}, z_0\right)\label{Ctsecond2term}.
\end{align}
The proof is completed by applying the inequalities (\ref{Ctsecondlemma}), (\ref{Ctnsteptv}), (\ref{Ctsecondfirstterm}), and (\ref{Ctsecond2term}).
\end{proof}

\subsection{Two Positive Results: Existence of 
Solution to the Average Cost Optimality 
Equation and Robustness to Incorrect Priors}


The existence of optimal solutions for 
partially observable Markov decision 
problems (POMDPs) under the ergodic 
cost criterion has been studied in 
\cite{platzman1980optimal, 
fernandez1990remarks, 
runggaldier1994approximations, 
hsu2006existence}; 
these study the average-cost control problem under 
the assumption that the state space is finite and 
provide reachability type conditions for the belief 
kernels. In a separate direction, \cite{Bor00} 
considers the finite model setup and 
\cite{borkar2004further} considers the 
case with finite-dimensional real-valued 
state spaces under some assumptions on the 
controlled state process leading to several 
ergodicity conditions. In our paper, 
building on the geometric ergodicity 
result presented, we provide further 
existence results via the average cost 
optimality equality in the following.


\begin{asm}\label{CostLipschitz}
For $K_1 \in \mathbb{R}_+$,
\[|c(x,u) - c(x',u)| \leq K_1 d(x,x').\]
\end{asm}


Under Assumption \ref{CostLipschitz}, 
we have that $\tilde{c}$ is Lipschitz continuous.


Accordingly, \cite[Theorem 4.37]{SaLiYuSpringer} 
shows that under Lipschitz regularity, we have 
that the relative value functions are equicontinuous, 
provided that the Lipschitz coefficient is less than one. 
That is,
\[J_{\beta}(z) - J_{\beta}(z') \leq \frac{K_1}{1 - K_2}\]
uniform over $\beta$. This equicontinuity implies 
\cite{HernandezLermaMCP} 
(see also \cite[Theorem 7.3.3]{LectureNote}) that 
a solution to the average cost optimality equation (ACOE), 
and thus an optimal control policy, exists, 
and the optimal cost is a constant 
(over all initial probability measures).


This (constant nature of optimal 
costs over all initial prior states) 
also implies that, by 
\cite[Theorem 3.9]{MYRobustControlledFS}, 
the optimal cost is robust to incorrect initializations.


\subsection{Limitations on Unique Ergodicity for Controlled Models}

While we have been able to arrive at the 
existence of optimal solutions for average cost control, 
the unique ergodicity proof for the control-free case 
does not apply to the controlled setup, 
even when one applies a stationary policy 
(in the filter variable).
The reason is that in a control-free partially 
observed Markov process, the pair of hidden state and observation state, $(X_n, Y_n)$, forms a Markov chain because this pair depends only on the previous pair. However, in a partially observed Markov decision process (POMDP), control action depends on the entire history, including the initial distribution and all past observations. In this case, the pair of hidden state and observation state may not form a Markov chain.  This is because $X_n$ is dependent on $U_{n-1}$, and therefore on all previous observations. The same applies to the pair of belief state and observation state. In a control-free case, the pair of belief state and observation state forms a Markov chain, while in the controlled case, it may not form a Markov chain. This is because for any policy, the controller action at any time depends on all past observations, so the belief state also depends on all past observations. However, if we choose the policy as a stationary policy, then the controller action depends on the belief state. In this case, the pair of belief state and observation state, $(\pi_n, Y_n)$, forms a Markov chain. ($(X_n, Y_n)$ may not form a Markov chain.)

Let $\gamma$ be stationary control policy and the control variable $u$ is determined according to $\gamma$. It means that the control policy $\gamma$ is unchanging over time and the control input applied to the system at each time step is determined based on the current belief state of the system and the chosen control policy $\gamma$. 

Under the stationary control policy $\gamma$ the transition probability $\eta$ of the filter process becomes $\eta^\gamma$, which is given by the expression

$$\eta^\gamma(\cdot \mid z)=\int_\mathbb{U}\eta(\cdot \mid z, u)\gamma(du|z)=\int_\mathbb{U}\int_{\mathbb{Y}} 1_{{F(z, u, y) \in \cdot}} P(d y \mid z, u)\gamma(du|z),$$
where $P(\cdot \mid z, u)$ and $F(z, u, y)$ are defined as equation (\ref{conteta}). When we take $\gamma$ as a stationary policy, the same proof method does not work. We can explain this as follows:

For the uncontrolled case, we first proved Theorem \ref{Talpha} 
and then used this lemma to show that the filter process is an L-chain. 
We can also prove Theorem \ref{Calpha} in a similar way to Theorem \ref{Talpha}. 
However, Theorem \ref{Calpha} does not give us the desired result because 
we need to reach this result under a stationary policy. 
Even if we assume the policy is stationary, we cannot bound 
the expression 
$W_{1}\left(\eta^\gamma(\cdot \mid z_0), \eta^\gamma\left(\cdot \mid z_0^{\prime})\right)\right)$ 
with $W_{1}\left(z_0, z_0^{\prime}\right)$ 
because the filter process can behave very differently 
for different initial distributions even under the same 
stationary policy. Therefore, both reachability and regularity 
cannot be easily generalized due to their dependence on the policy. 
Since we cannot establish the filter process as an L-chain, 
we cannot employ the same proof method.


\section{Conclusion}
In this paper, we have studied the
geometric ergodicity, unique ergodicity 
and Wasserstein continuity
of non-linear filter processes. 
Our assumptions significantly expand 
the existing findings in three main 
directions: First, we have presented 
novel conditions for the geometric 
ergodicity of non-linear filters, 
making a new contribution to the 
literature. Second, we have extended 
the conditions for unique ergodicity 
to scenarios where the state space is compact. 
Third, as a by-product of our analysis, 
we have derived conditions for Wasserstein 
continuity of non-linear filters.
In the latter part of our work, we have 
turned our attention to the controlled 
setup and average cost optimality. 
Building on the geometric ergodicity 
result, we provided further existence 
results via the average cost optimality 
equality.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please use \tableofcontents for articles %%
%% with 50 pages and more                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Main text entry area:


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Single Appendix:                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{appendix}
%\section*{???}%% if no title is needed, leave empty \section*{}.
%\end{appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Multiple Appendixes:                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{appendix}
%\section{???}
%
%\section{???}
%
%\end{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Support information, if any,             %%
%% should be provided in the                %%
%% Acknowledgements section.                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{acks}[Acknowledgments]
% The authors would like to thank ...
%\end{acks}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Funding information, if any,             %%
%% should be provided in the                %%
%% funding section.                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{funding}
% The first author was supported by ...
%
% The second author was supported in part by ...
%\end{funding}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Supplementary Material, including data   %%
%% sets and code, should be provided in     %%
%% {supplement} environment with title      %%
%% and short description. It cannot be      %%
%% available exclusively as external link.  %%
%% All Supplementary Material must be       %%
%% available to the reader on Project       %%
%% Euclid with the published article.       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{supplement}
%\stitle{???}
%\sdescription{???.}
%\end{supplement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  imsart-???.bst  will be used to                        %%
%%  create a .BBL file for submission.                     %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%  MR numbers will be added by VTeX.                      %%
%%                                                         %%
%%  Use \cite{...} to cite references in text.             %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\bibliographystyle{imsart-number} % Style BST file (imsart-number.bst or imsart-nameyear.bst)
%\bibliography{SerdarBibliography}       % Bibliography file (usually '*.bib')

%% or include bibliography directly:

 \begin{thebibliography}{}
 
 \bibitem{blackwell1959entropy}
\textsc{D. Blackwell} (1959). 
The entropy of functions of finite-state Markov chains.
\textit{Matematika}, \textbf{3(5)}, 143--150.

\bibitem{Kaijser}
\textsc{T. Kaijser}  (1975). 
A limit theorem for partially observed {M}arkov chains. 
\textit{Annals of Probability}, \textbf{4(677)}.

\bibitem{Budhiraja}
\textsc{A. Budhiraja} (2003).
Asymptotic stability, ergodicity and other asymptotic properties of the nonlinear filter.
\textit{Ann. Inst. H. Poincar\'e Probab. Statist}, \textbf{39}, 919-941.

\bibitem{DiMasiStettner2005ergodicity}
\textsc{G. Di Masi} and \textsc{L. Stettner} (2005).
Ergodicity of hidden Markov models.
 \textit{Mathematics of Control, Signals and Systems}, \textbf{17(4)}, 269--296.

 \bibitem{Rhe74}
\textsc{D.~Rhenius} (1974).
Incomplete information in {M}arkovian decision models.
 \textit{Ann. Statist.}, \textbf{2}, 1327--1334.

\bibitem{Yus76}
\textsc{A.A.~Yushkevich}  (1976). 
Reduction of a controlled {M}arkov model with incomplete data to a problem with complete information in the case of {B}orel state and control spaces.
\textit{Theory Prob. Appl.},  \textbf{21}, 153--158
.
\bibitem{dobrushin1956central}
\textsc{R.L. Dobrushin} (1956).
Central limit theorem for nonstationary {M}arkov chains. I.
\textit{Theory of Probability \& Its Applications}, \textbf{1(1)}, 65--80.

\bibitem{Par67}
\textsc{K.R.~Parthasarathy} (1967).
\textit{Probability Measures on Metric Spaces}, AMS Bookstore.

 \bibitem{villani2008optimal}
\textsc{C. Villani} (2008). \textit{Optimal transport: old and new}, Springer.

\bibitem{Bil99}
\textsc{P.~Billingsley}  (1999). 
\textit{Convergence of probability measures}, 2nd ed. Wiley, New York.

\bibitem{Bog07}
\textsc{V.I.~Bogachev}  (2007). 
\textit{Measure Theory: Volume II}, Springer.

\bibitem{himmelberg1976optimal}
\textsc{C. J. Himmelberg}, \textsc{T. Parthasarathy} and \textsc{F. S. Van Vleck} (1976).
Optimal plans for dynamic programming problems.
\textit{Mathematics of Operations Research}, \textbf{1(4)} 390--394.

 \bibitem{kochman2006simple}
\textsc{F.Kochman} and \textsc{J. Reeds} (2006). 
A simple proof of Kaijserâs unique ergodicity result for hidden Markov $\alpha$-chains.
\textit{The Annals of Applied Probability}, \textbf{16(4)} 1805--1815.

\bibitem{FeKaZg14}
E.A. Feinberg, P.O. Kasyanov, and M.Z. Zgurovsky.
\newblock Partially observable total-cost {M}arkov decision process with weakly
  continuous transition probabilities.
\newblock {\em Mathematics of Operations Research}, 41(2):656--681, 2016.

\bibitem{kaijser2011markov}
\textsc{T. Kaijser}  (2011). 
On Markov chains induced by partitioned transition probability matrices.
\textit{Acta Mathematica Sinica, English Series}, \textbf{27(3)}, 441--476.

\bibitem{chigansky2010complete}
\textsc{P. Chigansky} and \textsc{R. Van Handel} (2010).
A complete solution to {B}lackwell's unique ergodicity problem for hidden {M}arkov chains.
\textit{The Annals of Applied Probability}, \textbf{20(6)}, 2318--2345.

\bibitem{MeynBook}
\textsc{S. P. Meyn} and \textsc{R. Tweedie} (1993).
\textit{{M}arkov Chains and Stochastic Stability}, Springer-Verlag, London.

 \bibitem{kara2020near}
\textsc{A.D Kara} and \textsc{S. Y\"uksel}  (2022). 
Near Optimality of Finite Memory Feedback Policies in Partially Observed Markov Decision Processes.
\textit{Journal of Machine Learning Research}, \textbf{23(11)}, 1--46.

\bibitem{Tweedie-94}
\textsc{R. L. Tweedie}  (1994). 
Topological conditions enabling use of {H}arris methods in discrete and continuous time.
\textit{Acta Appl. Math.}, \textbf{34(1-2)}, 175--188.

\bibitem{le2004stability}
\textsc{F.  Le Gland} and \textsc{N. Oudjane} (2004).
Stability and uniform approximation of nonlinear filters using the {H}ilbert metric and application to particle filters.
\textit{The Annals of Applied Probability}, \textbf{14(1)}, 144--187.

\bibitem{hernandez1989adaptive}
\textsc{O. Hern{\'a}ndez-Lerma} (1989). 
\textit{Adaptive Markov Control Processes}, Springer-Verlag.


\bibitem{LectureNote}
\textsc{Y\"uksel, S.} (2023). \textit{Optimization and Control of Stochastic Systems, Lecture Notes, Queenâs University}.

\bibitem{Handel}
\textsc{R. van Handel} (2009).
The stability of conditional {M}arkov processes and {M}arkov chains in random environments.
\textit{Ann. Probab}, \textbf{37}, 1876--1925.

\bibitem{chigansky2009intrinsic}
\textsc{P. Chigansky, and R. Liptser, and R. van Handel} (2009).
Intrinsic methods in filter stability
\textit{Handbook of Nonlinear Filtering}.


\bibitem{HandelUniformObs}
\textsc{R. van Handel} (2009).
Uniform observability of hidden Markov models and filter stability for unstable signals.
\textit{The Annals of Applied Probability}, 
\textbf{19(3)}, 1172-1199.


\bibitem{Stettner1989}
\textsc{Stettner, L.} (1989).
On invariant measures of filtering processes.
\textit{Christopeit, N., Helmes, K., Kohlmann, M. (eds) Stochastic Differential Systems. Lecture Notes in Control and Information Sciences}, Springer, Berlin, Heidelberg. 
\textbf{126}.


\bibitem{Kunita}
\textsc{Kunita, H.} (1991).
Ergodic properties of nonlinear filtering processes.
\textit{Aleksander KC, Watkins JC (eds) Spatial Stochastic Processes}, Progr Probab 19, BirkhÃ¤user. 
\textbf{19}, 233â256.


\bibitem{mcdonald2020exponential}
\textsc{C. McDonald and S. Y\"uksel} (2020).
Exponential Filter Stability via {D}obrushin's Coefficient
\textit{Electronic Communications in Probability}, 
\textbf{25}.

\bibitem{platzman1980optimal}
\textsc{L. K. Platzman} (1980).
Optimal infinite-horizon undiscounted control of finite probabilistic systems
\textit{SIAM Journal on Control and Optimization}, 
\textbf{18(4)}, 362-380.


\bibitem{fernandez1990remarks}
\textsc{E. Fern{\'a}ndez-Gaucherand and A. Arapostathis and S. I. Marcus} (1990).
Remarks on the existence of solutions to the average cost optimality equation in Markov decision processes
\textit{Systems \& control letters}, 
\textbf{15(5)}, 425-432.


\bibitem{runggaldier1994approximations}
\textsc{Runggaldier, Wolfgang J} and \textsc{Stettner, Lukasz} (1994).
\textit{Approximations of discrete time partially observed control problems}, Giardini Pisa.

\bibitem{hsu2006existence}
\textsc{S.-P. Hsu and D.-M Chuang and A. Arapostathis} (2006).
On the existence of stationary optimal policies for partially observed MDPs under the long-run average cost criterion
\textit{Systems \& control letters}, 
\textbf{55(2)}, 165-173.

\bibitem{Bor00}
\textsc{V. S.~Borkar} (2000).
Average Cost Dynamic Programming Equations for Controlled {M}arkov Chains with Partial Observations
\textit{SIAM J. Control Optim.}, 
\textbf{39(3)}, 673-681.

\bibitem{borkar2004further}
\textsc{V. S. Borkar, A. Budhiraja} (2004).
A further remark on dynamic programming for partially observed Markov processes
\textit{Stochastic processes and their applications}, 
\textbf{112(1)}, 79-93.

\bibitem{SaLiYuSpringer}
\textsc{N.~Saldi} and \textsc{T. Linder} and \textsc{S.~Y\"uksel} (2018).
\textit{Finite Approximations in Discrete-Time Stochastic Control: Quantized Models and Asymptotic Optimality}, Springer.

\bibitem{HernandezLermaMCP}
\textsc{O. Hern{\'a}ndez-Lerma} and \textsc{J. B. Lasserre} (1996).
\textit{Discrete-Time {M}arkov Control Processes: Basic Optimality Criteria}, Springer.

\bibitem{MYRobustControlledFS}
\textsc{C. McDonald and S. Y\"uksel} (2022).
Robustness to Incorrect Priors and Controlled Filter Stability in Partially Observed Stochastic Control
\textit{SIAM Journal on Control and Optimization}, 
\textbf{60(2)}, 842-870.


\bibitem{Hernandez-Lerma2003}
\textsc{O. Hern{\'a}ndez-Lerma} and \textsc{J. B. Lasserre} (2003).
\textit{{M}arkov chains and invariant probabilities}, Birkh\"auser-Verlag, Basel.



\bibitem{KSYWeakFellerSysCont}
\textsc{A.D Kara and N. Saldi and S. Y\"uksel} (2019).
Weak {F}eller property of non-linear filters
\textit{Systems \& Control letters}, 
\textbf{134}, 104-512.


\bibitem{feinberg2022markov}
\textsc{E.A. Feinberg and P.O. Kasyanov and M.Z. Zgurovsky} (2022).
Markov Decision Processes with Incomplete Information and Semiuniform Feller Transition Probabilities
\textit{SIAM Journal on Control and Optimization}, 
\textbf{60(4)}, 2488--2513.

\bibitem{feinberg2023equivalent}
\textsc{E.A. Feinberg and P.O. Kasyanov} (2023).
Equivalent conditions for weak continuity of nonlinear filters
\textit{Systems \& Control letters}, 
\textbf{173}, 105458.

\bibitem{mcdonald2018stability}
\textsc{C. McDonald and S. Y\"uksel} (2023).
Stochastic Observability and Filter Stability under Several Criteria
\textit{IEEE Transactions on Automatic Control}, 
1-16.



\end{thebibliography}

\end{document}

