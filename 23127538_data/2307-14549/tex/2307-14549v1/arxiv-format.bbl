\begin{thebibliography}{10}

\bibitem{Ricci2022}
Francesco Ricci, Lior Rokach, and Bracha Shapira.
\newblock {\em Recommender Systems: Techniques, Applications, and Challenges},
  pages 1--35.
\newblock Springer US, New York, NY, 2022.

\bibitem{Smith2017}
Brent Smith and Greg Linden.
\newblock Two decades of recommender systems at amazon.com.
\newblock {\em IEEE Internet Computing}, 2017.

\bibitem{amatriain2015recommender}
Xavier Amatriain and Justin Basilico.
\newblock Recommender systems in industry: A netflix case study.
\newblock {\em Recommender systems handbook}, pages 385--419, 2015.

\bibitem{10.1145/3460231.3474618}
Andreas Gr\"{u}n and Xenija Neufeld.
\newblock Challenges experienced in public service media recommendation
  systems.
\newblock In {\em Proceedings of the 15th ACM Conference on Recommender
  Systems}, RecSys '21, page 541–544, New York, NY, USA, 2021. Association
  for Computing Machinery.

\bibitem{covington2016deep}
Paul Covington, Jay Adams, and Emre Sargin.
\newblock Deep neural networks for youtube recommendations.
\newblock In {\em Proceedings of the 10th ACM conference on recommender
  systems}, pages 191--198, 2016.

\bibitem{rendle2008online}
Steffen Rendle and Lars Schmidt-Thieme.
\newblock Online-updating regularized kernel matrix factorization models for
  large-scale recommender systems.
\newblock In {\em Proceedings of the 2008 ACM conference on Recommender
  systems}, pages 251--258, 2008.

\bibitem{auer2000using}
Peter Auer.
\newblock Using upper confidence bounds for online learning.
\newblock In {\em Proceedings 41st Annual Symposium on Foundations of Computer
  Science}, pages 270--279. IEEE, 2000.

\bibitem{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47:235--256, 2002.

\bibitem{auer2002nonstochastic}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock {\em SIAM journal on computing}, 32(1):48--77, 2002.

\bibitem{vermorel2005multi}
Joannes Vermorel and Mehryar Mohri.
\newblock Multi-armed bandit algorithms and empirical evaluation.
\newblock In {\em Machine Learning: ECML 2005: 16th European Conference on
  Machine Learning, Porto, Portugal, October 3-7, 2005. Proceedings 16}, pages
  437--448. Springer, 2005.

\bibitem{cesa2006prediction}
Nicolo Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock {\em Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem{jeunen:2021}
Olivier Jeunen and Bart Goethals.
\newblock Pessimistic reward models for off-policy learning in recommendation.
\newblock In {\em Proceedings of the 15th ACM Conference on Recommender
  Systems}, RecSys '21, page 63–74, New York, NY, USA, 2021. Association for
  Computing Machinery.

\bibitem{jeunen:2022}
Olivier Jeunen and Bart Goethals.
\newblock Pessimistic decision-making for recommender systems.
\newblock {\em ACM Trans. Recomm. Syst.}, oct 2022.
\newblock Just Accepted.

\bibitem{li2010contextual}
Lihong Li, Wei Chu, John Langford, and Robert~E Schapire.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In {\em Proceedings of the 19th international conference on World
  wide web}, pages 661--670, 2010.

\bibitem{kanade2009sleeping}
Varun Kanade, H~Brendan McMahan, and Brent Bryan.
\newblock Sleeping experts and bandits with stochastic action availability and
  adversarial rewards.
\newblock In {\em Artificial Intelligence and Statistics}, pages 272--279.
  PMLR, 2009.

\bibitem{kleinberg2010regret}
Robert Kleinberg, Alexandru Niculescu-Mizil, and Yogeshwer Sharma.
\newblock Regret bounds for sleeping experts and bandits.
\newblock {\em Machine learning}, 80(2-3):245--272, 2010.

\bibitem{kale2010non}
Satyen Kale, Lev Reyzin, and Robert~E Schapire.
\newblock Non-stochastic bandit slate problems.
\newblock {\em Advances in Neural Information Processing Systems}, 23, 2010.

\bibitem{uchiya2010algorithms}
Taishi Uchiya, Atsuyoshi Nakamura, and Mineichi Kudo.
\newblock Algorithms for adversarial bandit problems with multiple plays.
\newblock In {\em Algorithmic Learning Theory: 21st International Conference,
  ALT 2010, Canberra, Australia, October 6-8, 2010. Proceedings 21}, pages
  375--389. Springer, 2010.

\bibitem{chatterjee2017analysis}
Aritra Chatterjee, Ganesh Ghalme, Shweta Jain, Rohit Vaish, and Y~Narahari.
\newblock Analysis of thompson sampling for stochastic sleeping bandits.
\newblock In {\em UAI}, 2017.

\bibitem{komiyama2015optimal}
Junpei Komiyama, Junya Honda, and Hiroshi Nakagawa.
\newblock Optimal regret analysis of thompson sampling in stochastic
  multi-armed bandit problem with multiple plays.
\newblock In {\em International Conference on Machine Learning}, pages
  1152--1161. PMLR, 2015.

\bibitem{chen2013combinatorial}
Wei Chen, Yajun Wang, and Yang Yuan.
\newblock Combinatorial multi-armed bandit: General framework and applications.
\newblock In {\em International conference on machine learning}, pages
  151--159. PMLR, 2013.

\bibitem{saha2020improved}
Aadirupa Saha, Pierre Gaillard, and Michal Valko.
\newblock Improved sleeping bandits with stochastic action sets and adversarial
  rewards.
\newblock In {\em International Conference on Machine Learning}, pages
  8357--8366. PMLR, 2020.

\bibitem{neu2014online}
Gergely Neu and Michal Valko.
\newblock Online combinatorial optimization with stochastic decision sets and
  adversarial losses.
\newblock {\em Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem{kale2016hardness}
Satyen Kale, Chansoo Lee, and D{\'a}vid P{\'a}l.
\newblock Hardness of online sleeping combinatorial optimization problems.
\newblock {\em Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem{kanade2014learning}
Varun Kanade and Thomas Steinke.
\newblock Learning hurdles for sleeping experts.
\newblock {\em ACM Transactions on Computation Theory (TOCT)}, 6(3):1--16,
  2014.

\bibitem{xia2016budgeted}
Yingce Xia, Tao Qin, Weidong Ma, Nenghai Yu, and Tie-Yan Liu.
\newblock Budgeted multi-armed bandits with multiple plays.
\newblock In {\em IJCAI}, volume~6, pages 2210--2216, 2016.

\bibitem{warmuth2008randomized}
Manfred~K Warmuth and Dima Kuzmin.
\newblock Randomized online pca algorithms with regret bounds that are
  logarithmic in the dimension.
\newblock {\em Journal of Machine Learning Research}, 9(Oct):2287--2320, 2008.

\bibitem{herbster2001tracking}
Mark Herbster and Manfred~K Warmuth.
\newblock Tracking the best linear predictor.
\newblock {\em Journal of Machine Learning Research}, 1(281-309):10--1162,
  2001.

\end{thebibliography}
