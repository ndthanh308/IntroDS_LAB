\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdar et~al.(2021)Abdar, Pourpanah, Hussain, Rezazadegan, Liu, Ghavamzadeh, Fieguth, Cao, Khosravi, Acharya, et~al.]{abdar2021review}
M.~Abdar, F.~Pourpanah, S.~Hussain, D.~Rezazadegan, L.~Liu, M.~Ghavamzadeh, P.~Fieguth, X.~Cao, A.~Khosravi, U.~R. Acharya, et~al.
\newblock A review of uncertainty quantification in deep learning: Techniques, applications and challenges.
\newblock \emph{Information Fusion}, 76:\penalty0 243--297, 2021.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and Wierstra]{blundell2015weight}
C.~Blundell, J.~Cornebise, K.~Kavukcuoglu, and D.~Wierstra.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Chellapilla and Simard(2004)]{chellapilla2004using}
K.~Chellapilla and P.~Simard.
\newblock Using machine learning to break visual human interaction proofs (hips).
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2004.

\bibitem[Chen et~al.(2019)Chen, Wang, Pang, Cao, Xiong, Li, Sun, Feng, Liu, Xu, Zhang, Cheng, Zhu, Cheng, Zhao, Li, Lu, Zhu, Wu, Dai, Wang, Shi, Ouyang, Loy, and Lin]{mmdetection}
K.~Chen, J.~Wang, J.~Pang, Y.~Cao, Y.~Xiong, X.~Li, S.~Sun, W.~Feng, Z.~Liu, J.~Xu, Z.~Zhang, D.~Cheng, C.~Zhu, T.~Cheng, Q.~Zhao, B.~Li, X.~Lu, R.~Zhu, Y.~Wu, J.~Dai, J.~Wang, J.~Shi, W.~Ouyang, C.~C. Loy, and D.~Lin.
\newblock {MMDetection}: Open {MMLab} detection toolbox and benchmark.
\newblock \emph{arXiv preprint arXiv:1906.07155}, 2019.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{chen2014stochastic}
T.~Chen, E.~Fox, and C.~Guestrin.
\newblock {Stochastic gradient Hamiltonian Monte Carlo}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2014.

\bibitem[Cuong et~al.(2013)Cuong, Ho, and Dinh]{cuong2013generalization}
N.~V. Cuong, L.~S.~T. Ho, and V.~Dinh.
\newblock {Generalization and robustness of batched weighted average algorithm with V-geometrically ergodic Markov data}.
\newblock In \emph{International Conference on Algorithmic Learning Theory (ALT)}, 2013.

\bibitem[D'Angelo and Fortuin(2021)]{d2021repulsive}
F.~D'Angelo and V.~Fortuin.
\newblock {Repulsive deep ensembles are Bayesian}.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Deng et~al.(2022)Deng, Zhao, Wang, Chen, Wang, and Xue]{deng3e}
X.~Deng, R.~Zhao, Y.~Wang, L.~Chen, Y.~Wang, and Z.~Xue.
\newblock {3E-solver: An effortless, easy-to-update, and end-to-end solver with semi-supervised learning for breaking text-based Captchas}.
\newblock In \emph{International Joint Conference on Artificial Intelligence (IJCAI)}, 2022.

\bibitem[Fort et~al.(2019)Fort, Hu, and Lakshminarayanan]{fort2019deep}
S.~Fort, H.~Hu, and B.~Lakshminarayanan.
\newblock Deep ensembles: A loss landscape perspective.
\newblock \emph{arXiv preprint arXiv:1912.02757}, 2019.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Y.~Gal and Z.~Ghahramani.
\newblock {Dropout as a Bayesian approximation: Representing model uncertainty in deep learning}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Gao et~al.(2016)Gao, Wang, Cao, Zhang, Lei, Qi, and Liu]{gao2016robustness}
H.~Gao, X.~Wang, F.~Cao, Z.~Zhang, L.~Lei, J.~Qi, and X.~Liu.
\newblock {Robustness of text-based completely automated public Turing test to tell computers and humans apart}.
\newblock \emph{IET Information Security}, 10\penalty0 (1):\penalty0 45--52, 2016.

\bibitem[Ge et~al.(2021)Ge, Liu, Wang, Li, and Sun]{ge2021yolox}
Z.~Ge, S.~Liu, F.~Wang, Z.~Li, and J.~Sun.
\newblock {YOLOX: Exceeding YOLO series in 2021}.
\newblock \emph{arXiv preprint arXiv:2107.08430}, 2021.

\bibitem[Germain et~al.(2015)Germain, Lacasse, Laviolette, March, and Roy]{germain2015risk}
P.~Germain, A.~Lacasse, F.~Laviolette, M.~March, and J.-F. Roy.
\newblock Risk bounds for the majority vote: From a {PAC-Bayesian} analysis to a learning algorithm.
\newblock \emph{Journal of Machine Learning Research}, 16\penalty0 (26):\penalty0 787--860, 2015.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Hendrycks and Gimpel(2017)]{hendrycks2017baseline}
D.~Hendrycks and K.~Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution examples in neural networks.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2017.

\bibitem[Ho et~al.(2020)Ho, Nguyen, Dinh, and Nguyen]{ho2020posterior}
L.~S.~T. Ho, B.~T. Nguyen, V.~Dinh, and D.~Nguyen.
\newblock {Posterior concentration and fast convergence rates for generalized Bayesian learning}.
\newblock \emph{Information Sciences}, 538:\penalty0 372--383, 2020.

\bibitem[Isola et~al.(2017)Isola, Zhu, Zhou, and Efros]{isola2017image}
P.~Isola, J.-Y. Zhu, T.~Zhou, and A.~A. Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2017.

\bibitem[Kopp et~al.(2017)Kopp, Nikl, and Holena]{kopp2017breaking}
M.~Kopp, M.~Nikl, and M.~Holena.
\newblock Breaking {CAPTCHAs} with convolutional neural networks.
\newblock In \emph{Conference on Information Technologies -- Applications and Theory (ITAT)}, 2017.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and Blundell]{lakshminarayanan2017simple}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep ensembles.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2017.

\bibitem[Laviolette et~al.(2017)Laviolette, Morvant, Ralaivola, and Roy]{laviolette2017risk}
F.~Laviolette, E.~Morvant, L.~Ralaivola, and J.-F. Roy.
\newblock Risk upper bounds for general ensemble methods with an application to multiclass classification.
\newblock \emph{Neurocomputing}, 219:\penalty0 15--25, 2017.

\bibitem[Li et~al.(2021)Li, Chen, Wang, Wang, Zhang, and Wang]{li2021end}
C.~Li, X.~Chen, H.~Wang, P.~Wang, Y.~Zhang, and W.~Wang.
\newblock End-to-end attack on text-based {CAPTCHAs} based on cycle-consistent generative adversarial network.
\newblock \emph{Neurocomputing}, 433:\penalty0 223--236, 2021.

\bibitem[Li and Liao(2018)]{li2018captcha}
Z.~Li and Q.~Liao.
\newblock {CAPTCHA: Machine or human solvers? A game-theoretical analysis}.
\newblock In \emph{IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom)}, 2018.

\bibitem[Masegosa et~al.(2020)Masegosa, Lorenzen, Igel, and Seldin]{masegosa2020second}
A.~Masegosa, S.~Lorenzen, C.~Igel, and Y.~Seldin.
\newblock Second order {PAC-Bayesian} bounds for the weighted majority vote.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Neal(1995)]{neal1995bayesian}
R.~M. Neal.
\newblock \emph{Bayesian learning for neural network}.
\newblock PhD thesis, University of Toronto, 1995.

\bibitem[Nesterov(1983)]{nesterov1983method}
Y.~Nesterov.
\newblock A method for unconstrained convex minimization problem with the rate of convergence {O}(1/k\^{}2).
\newblock \emph{Doklady AN USSR}, 269:\penalty0 543--547, 1983.

\bibitem[Noury and Rezaei(2020)]{noury2020deep}
Z.~Noury and M.~Rezaei.
\newblock {Deep-CAPTCHA: A deep learning based CAPTCHA solver for vulnerability assessment}.
\newblock \emph{arXiv preprint arXiv:2006.08296}, 2020.

\bibitem[Ortega et~al.(2022)Ortega, Caba{\~n}as, and Masegosa]{ortega2022diversity}
L.~A. Ortega, R.~Caba{\~n}as, and A.~Masegosa.
\newblock Diversity and generalization in neural network ensembles.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2022.

\bibitem[Ousat et~al.(2024)Ousat, Schafir, Tofighi, Hoang, Nguyen, Arshad, Uluagac, and Kharraz]{ousat2024matter}
B.~Ousat, E.~Schafir, M.~A. Tofighi, D.~C. Hoang, C.~V. Nguyen, S.~Arshad, S.~Uluagac, and A.~Kharraz.
\newblock {The matter of Captchas: An analysis of a brittle security feature on the modern web}.
\newblock In \emph{ACM Web Conference (WWW)}, 2024.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin, Dillon, Lakshminarayanan, and Snoek]{ovadia2019can}
Y.~Ovadia, E.~Fertig, J.~Ren, Z.~Nado, D.~Sculley, S.~Nowozin, J.~Dillon, B.~Lakshminarayanan, and J.~Snoek.
\newblock {Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift}.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Pereyra et~al.(2017)Pereyra, Tucker, Chorowski, Kaiser, and Hinton]{pereyra2017regularizing}
G.~Pereyra, G.~Tucker, J.~Chorowski, {\L}.~Kaiser, and G.~Hinton.
\newblock Regularizing neural networks by penalizing confident output distributions.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2017.

\bibitem[Ritter et~al.(2018)Ritter, Botev, and Barber]{ritter2018scalable}
H.~Ritter, A.~Botev, and D.~Barber.
\newblock {A scalable Laplace approximation for neural networks}.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem[Rudner et~al.(2021)Rudner, Chen, Teh, and Gal]{rudner2021tractable}
T.~G. Rudner, Z.~Chen, Y.~W. Teh, and Y.~Gal.
\newblock {Tractable function-space variational inference in Bayesian neural networks}.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Tang et~al.(2018)Tang, Gao, Zhang, Liu, Zhang, and Wang]{tang2018research}
M.~Tang, H.~Gao, Y.~Zhang, Y.~Liu, P.~Zhang, and P.~Wang.
\newblock {Research on deep learning techniques in breaking text-based Captchas and designing image-based Captcha}.
\newblock \emph{IEEE Transactions on Information Forensics and Security}, 13\penalty0 (10):\penalty0 2522--2537, 2018.

\bibitem[Theisen et~al.(2024)Theisen, Kim, Yang, Hodgkinson, and Mahoney]{theisen2024ensembles}
R.~Theisen, H.~Kim, Y.~Yang, L.~Hodgkinson, and M.~W. Mahoney.
\newblock When are ensembles really effective?
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2024.

\bibitem[Tian and Xiong(2020)]{tian2020generic}
S.~Tian and T.~Xiong.
\newblock A generic solver combining unsupervised learning and representation learning for breaking text-based captchas.
\newblock In \emph{The Web Conference (WWW)}, 2020.

\bibitem[Von~Ahn et~al.(2003)Von~Ahn, Blum, Hopper, and Langford]{von2003captcha}
L.~Von~Ahn, M.~Blum, N.~J. Hopper, and J.~Langford.
\newblock {CAPTCHA: Using hard AI problems for security}.
\newblock In \emph{International Conference on the Theory and Applications of Cryptographic Techniques}, 2003.

\bibitem[Wilson and Izmailov(2020)]{wilson2020bayesian}
A.~G. Wilson and P.~Izmailov.
\newblock Bayesian deep learning and a probabilistic perspective of generalization.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Yan and El~Ahmad(2007)]{yan2007breaking}
J.~Yan and A.~S. El~Ahmad.
\newblock Breaking visual {CAPTCHAs} with naive pattern recognition algorithms.
\newblock In \emph{Annual Computer Security Applications Conference (ACSAC)}, 2007.

\bibitem[Yan and El~Ahmad(2008)]{yan2008low}
J.~Yan and A.~S. El~Ahmad.
\newblock {A low-cost attack on a Microsoft CAPTCHA}.
\newblock In \emph{ACM Conference on Computer and Communications Security (CCS)}, 2008.

\bibitem[Ye et~al.(2018)Ye, Tang, Fang, Zhu, Feng, Xu, Chen, and Wang]{ye2018yet}
G.~Ye, Z.~Tang, D.~Fang, Z.~Zhu, Y.~Feng, P.~Xu, X.~Chen, and Z.~Wang.
\newblock Yet another text captcha solver: A generative adversarial network based approach.
\newblock In \emph{ACM Conference on Computer and Communications Security (CCS)}, 2018.

\bibitem[Zhang et~al.(2020)Zhang, Li, Zhang, Chen, and Wilson]{zhang2020csgmcmc}
R.~Zhang, C.~Li, J.~Zhang, C.~Chen, and A.~G. Wilson.
\newblock {Cyclical stochastic gradient MCMC for Bayesian deep learning}.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2020.

\end{thebibliography}
