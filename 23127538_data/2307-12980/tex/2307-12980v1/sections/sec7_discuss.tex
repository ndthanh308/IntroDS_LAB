\section{Challenges and Opportunities}
\label{sec:7-discussion}

\textbf{Prompting Model in Multimodal-to-Text Generation.}
In addition to visual and textual modalities, the incorporation of other modalities such as audio and thermal is possible. It is crucial to address the inherent heterogeneity among these modalities, which includes variations in data formats, scales, and structures.


Two notable projects in this domain are Kosmos~\cite{huang2023language, peng2023kosmos}, developed by Microsoft, and IMAGEBIND~\cite{Girdhar_2023_CVPR}, developed by Meta AI. These projects aim to create unified models capable of handling diverse modalities, promoting the utilization of such unified models as a significant direction in the field.


However, it is important to note that most of the research on prompts for multimodal-to-text pre-trained models has primarily focused on hard prompts. Conversely, soft prompts based on image-text matching models, such as CLIP~\cite{radford2021learning}, have received extensive investigation. Models like CoOp~\cite{zhou2022learning} and CoCoOp~\cite{zhou2022conditional} leverage soft prompts on it to enhance model performance. Nevertheless, the exploration of prompt tuning for popular generative multimodal-to-text pre-trained models remains largely unexplored.


Additionally, multimodal-to-text pre-trained models employ a range of challenging prompt techniques, including in-context learning~\cite{alayrac2022flamingo} and instruction tuning~\cite{li2023otter}. Despite their effectiveness, the underlying mechanisms by which these models learn and the specific contributions of different aspects of the demonstrations remain largely unexplored. A deeper understanding of these factors is crucial for refining and optimizing the performance of multimodal-to-text pre-trained models. 

\noindent\textbf{Prompting Model in Image-Text Matching.}
Although pre-trained encoders prompted by a matching loss have been widely used for adaptation in downstream tasks, the exploration of visual prompting on pre-trained encoders remains relatively unexplored. Similar to the seamless adaptation of textual encoders through learning textual prompts, the investigation of visual prompts is an intriguing area that can unlock emergent abilities, especially in difficult scenarios such as dense objects, object hallucination, and the adaptation to modern VLMs. In the future, it is imperative to address questions regarding the specific type of visual prompts that are essential and the semantic information that these prompts introduce. By delving into these inquiries, we can gain a deeper understanding of the role and impact of visual prompts, thereby further advancing the field.


Meanwhile, the investigation of how unified prompting can enhance the performance of both branches remains understudied. In an intuitive sense, a unified prompt can provide us with referential information that spans across modalities, as discussed in~\cite{yao2022cpt}. This has the potential to facilitate the development of multimodal models that are capable of visual grounding and enable referential dialogues encompassing visual and textual co-reference.

\noindent\textbf{Prompting Model in Text-Image Generation.}
One of the significant challenges in the field of prompting text-to-other generation models, particularly in the case of Text-to-Video (T2V) and Text-to-3D (T2-3D) models, is their dependency on Text-to-Image (T2I) models. These models often share the same concern due to the nature that they are extensions of T2I diffusion models. For example, the inconsistency of the input control maps in T2I models can lead to errors in the consequently generated videos and 3D objects, thereby affecting the overall performance and reliability of these extension scenarios.


Looking ahead, there are several promising directions for future research. One such direction is the incorporation of visual prompting into T2I, T2V, and T2-3D diffusion models. In the context of text-to-image generation, visual prompting and visual annotations can offer more visual cues, leading to the creation of more personalized images. This approach allows for more attention to be paid to specific areas of the image, enhancing the detail and accuracy of the generated output.
Visual prompts can also be beneficial for video generation, either on a frame-by-frame basis or for T2-3D generation aimed at improving 2D renderings or shapes. The concept of visual prompts can be further expanded to include video prompts, object prompts, and motion prompts, depending on the specific requirements of different target data generation scenarios. 
Furthermore, text-image matching models hold the potential for better alignment as multi-modal prompting in the generation. This approach could lead to more accurate and contextually relevant image generation, opening up new possibilities for the application of pre-trained vision-language models.

\noindent\textbf{Generalizing Prompting Methods from Unimodal to Multimodal.} 
Sec.~\ref{sec:unimodal} discusses the applications of prompt engineering in both pure vision and pure language models, which can motivate further research in multi-modality research. When combined with instruction-tuning methods, pure language models have enabled phenomenal applications such as ChatGPT~\cite{chatgpt}. The potential of these methods such as Reinforcement Learning from Human Feedback (RLHF)~\cite{ouyang2022training} and Harmlessness from AI Feedback~\cite{bai2022constitutional} can be further explored in multimodal models as shown in several recent studies~\cite{li2023otter, gao2023llamaadapterv2}. Constitutional AI is a method proposed in~\cite{bai2022constitutional} to train a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. Although some efforts have been put into language models~\cite{bai2022constitutional}, how to implement constitutional AI in the multimodal domain is still an open question. 

Another potential direction is the adoption of in-context prompts in multimodal models. Large unimodal language models can address a specific new task given several demonstrations of the task in their text prompt without any gradient update. Flamingo~\cite{alayrac2022flamingo} has also demonstrated the few-shot in-context learning ability, but how to further improve the in-context learning capacity is still under-explored. 


\noindent\textbf{Responsible AI Considerations of Prompting.}
There are already a few studies concerning ethical issues on multimodal-to-text generation in Sec.~\ref{sec:m2t-ethical} and text-to-image generations as discussed in Sec.~\ref{sec:t2i-ethical}.  Integrity and ethical issues of prompt engineering on vision-language models need much more attention. One possible direction is to prevent bias and backdoor attacks inherited from the pre-trained model during downstream prompt adaptations~\cite{carlini2022poisoning,gao2023backdoor,huang2022backdoor,yang2023backdoor}. As large models are normally pre-trained on web-scale datasets which may preserve biased knowledge or sensitive privacy information, the post-deployment procedure conducted by prompt engineering should be able to control the potential risks.

Adversarial Robustness has been intensively studied in various model architectures, such as Convolutional Networks~\cite{madry2017towards,jia2022adversarial}, Vision Transformers~\cite{wu2022towards,gu2022vision}, and Capsule Networks~\cite{gu2021effective}. It has not been fully understood how the prompting on VLMs with both a vision architecture and a language component performs under adversarial attacks. Especially, the impact of recent advances in VLM on adversarial robustness remains to be studied. E.g., do large prompts bring robustness to VLMs~\cite{gu2023towards}?

Besides, transparency and controllable generation through fair prompting are also essential in generative tasks. Generative models are shown to be vulnerable to privacy leakage~\cite{wu2022membership, duan2023diffusion, webster2023reproducible} and may generate biased content ~\cite{friedrich2023fair, naik2023social, wang2023T2IAT, luccioni2023stable}. Hence, constructing transparent and controllable prompts that are capable to conserve privacy and prevent unethical generation is critical for real-world applications. Last but not least, managing the accompanying risks of prompt engineering and large models requires the close collaboration of society, research institutions, and government~\cite{anderljung2023frontier, hacker2023regulating}.

\noindent\textbf{Relationship between Prompts on Different VLMs.} The recent work~\cite{li2022dall} studies the relationship between concepts learned by multimodal-to-text and image-to-text and text-to-image models. They show the studied two types of models cannot fully understand each other, while they also share some concepts. Similarly, the relationship between prompts on different types of models should be explored in future work, especially the feasibility of building universal prompts across different models trained on the same data. In addition to the inter-model relationship, the interaction between prompts and model architecture should be investigated since most prompts are proposed on Transformer-based models. Concretely, how the model's self-attention changes during prompting~\cite{gu2022vision}.  

