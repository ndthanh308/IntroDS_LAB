\section{Prompting VLM vs. Uni-modal Models}
\label{sec:unimodal}
\subsection{Prompting in Natural Language Processing}
This section summarizes existing studies on prompt engineering on textual language models. Prompt engineering has been widely adopted in various natural language processing applications including question answering~\cite{khashabi-etal-2020-unifiedqa, jiang2021can}, text classification~\cite{gao2021making, lester-etal-2021-power}, text generation~\cite{radford2019language, brown2020language, schick-schutze-2021-shot}, and information extraction~\cite{KnowPrompt, cui-etal-2021-template}, \etc. Recent LLMs such as InstructGPT~\cite{ouyang2022training} and PALM2~\cite{anil2023palm} have shown incredible generalized inference ability through prompting. Early works~\cite{paranjape2021prompting} designed natural language templates to let pre-trained language models fill in to explain their predictions. Wei \etal~\cite{wei2022chain} demonstrate that the performance of LLMs can be significantly improved by adding intermediate reasoning steps into the prompt. In particular, the prompt of each task contains a few manual demonstrations consisting of a question and a reasoning chain leading to the answer. The LLM learns to follow the prompt and thinks step-by-step to solve the given task. Liu \etal~\cite{liu2021makes} find that the quality of the prompt, \ie, the selection of examples in prompts and given explanations, largely impacts LLM's performance. Fu \etal~\cite{fu2022complexity} demonstrate that prompting LLMs with complex example questions, which requires more intermediate reasoning steps, could achieve better performance and benefit the model's robustness regarding format perturbation and distribution shift. 

Manually crafting prompts for each task strongly depends on human experience, and manual testing would be required to evaluate and improve the template, which would be time-consuming. Zhang \etal~\cite{zhang2022automatic} work on eliminating manual efforts by leveraging LLMs to construct reasoning chains with demonstrations. Besides,  a line of works~\citep{lewis2020retrieval, borgeaud2022improving, izacard2022few} automates the prompt engineering by utilizing a dense retriever to augment the language models with external resources, which has also been referred to as retrieval-augmented language models. For a given question, the dense retriever retrieves relevant text from a knowledge source and appends it to the language model input. Such language models have recently demonstrated strong performance on knowledge-intensive tasks. 
\cite{lester2021power} propose \textit{prompt tuning} that appends the input embedding layer with extra trainable tokens and learns these tokens through backpropagation on downstream tasks. This opens a direction of learning soft prompts to enhance LLMs.

Many studies demonstrated that LLMs' performance considerably drops as the task complexity increases. A natural way for humans to solve complex tasks is to decompose them into a series of simple subtasks and solve the complex task by completing each simple subtask. A line of works investigated enhancing LLMs' performance on complex tasks by prompting LLMs multi-times, where the LLMs are expected to solve a subtask by each prompt. Press \etal~\cite{press2022measuring} examine the capacity of language models to execute compositional reasoning tasks and found that LLMs are good at memorizing facts but do not compose them to answer questions. To narrow the compositionality gap, the authors let LLMs ask themselves follow-up questions, answer the questions, and decide whether they have sufficient information to give the final solution. Kazemi \etal~\cite{kazemi2022lambada} propose a backward chaining algorithm to decompose a complex task by starting from the objective and recursively breaking down the complex task into sub-tasks based on rules. Khot \etal~\cite{khot2022decomposed} decompose a complex task into sub-tasks and use sub-task-specific LLMs to solve them, leading to improved performance on a line of textual multi-step reasoning tasks.

Researchers have also noticed ethical and integrity issues related to prompt engineering in NLP. Yang \etal~\cite{yang2022prompting} propose a prompt-based adversarial attack to compromise NLP models and robustness enhancement techniques. This work indicates that the prompting paradigm has the potential in probing fundamental vulnerabilities of large language models and fine-tuning them for downstream tasks. Dong \etal~\cite{dong2023promptattack} adopt a prompt-based learning approach to automatically generate effective adversarial examples to probe Dialogue State Tracker models. The prompt may inherit the bias in the pre-trained models and~\cite{delobelle-etal-2022-measuring} review the literature on fairness metrics for pre-trained language models and experimentally evaluate compatibility. Moreover, one can refer to several existing surveys~\cite{Lou2023Is, Ding2022OpenPrompt, qiao2022reasoning} for a more comprehensive review. 


\subsection{Prompting on Pure Vision Models}
Although prompt is first widely adopted in natural language models, many works also utilize prompts in pure vision models~\cite{kirillov2023segment, bahng2022exploring, wang2022images, wang2023seggpt, loedeman2023prompt, tu2022visual, zhang2022promptcal} and applications including image classification~\cite{bahng2022exploring, loedeman2023prompt, tu2022visual, zhang2022promptcal}, image segmentation~\cite{kirillov2023segment, wang2022images}, depth estimation~\cite{wang2022images}, keypoint detection~\cite{wang2022images}, denoising~\cite{wang2022images}, detaining~\cite{wang2022images}, and image enhancement~\cite{wang2022images} \etc.


 Several studies have identified two main mechanisms for incorporating prompts into vision models. The first mechanism treats prompting as an adaptation method that facilitates the fine-tuning of pre-trained vision models~\cite{bahng2022exploring, salman2021unadversarial, loedeman2023prompt}. The second mechanism utilizes prompts as a module that plays a role in both model pre-training and inference~\cite{kirillov2023segment, wang2022images, zhang2022promptcal}.


 Pre-trained vision models have significantly improved performance, but their size has also increased drastically, making training and fine-tuning infeasible for most users. To address this issue, adapting pre-trained models to specific tasks in a parameter-efficient way is critical. Many studies have treated prompting as an adaptation method.


 Bahng \etal~\cite{bahng2022exploring} use a single visual prompt to adapt a frozen large-scale vision model to a new task. Adaptation approaches such as fine-tuning and linear probes require some level of access to the pre-trained model during both training and testing. However, visual prompting only requires model access during training, making it feasible for some applications~\cite{salman2021unadversarial}. Additionally, Tu \etal~\cite{tu2022visual} propose Visual Query Tuning (VQT) to adapt pre-trained Transformers to downstream tasks while keeping the backbone frozen, allowing for more accurate predictions utilizing the intermediate features of a pre-trained model.


 As classical fine-tuning methods become more limiting when models are hosted as inference APIs, visual prompt learning is emerging as a potential solution for adapting frozen and cloud-hosted models. Loedeman \etal~\cite{loedeman2023prompt} introduce the Prompt Generation Network (PGN), which generates input-dependent visual prompts to facilitate domain adaptation. PGN generates new prompts for every image by combining items from a commonly learned library of tokens. It consists of a lightweight neural network that learns the probability distribution for selecting prompt vectors from a token library.


 In addition to using prompts as an adaptation for downstream tasks, some researchers have integrated prompting modules into the entire model to improve pre-training performance and enable more flexible inference. In~\cite{kirillov2023segment}, Kirillov \etal~ introduce the Segment Anything Model (SAM), which aims to build a foundation model for segmentation. Inspired by prompting techniques in NLP, they proposed the \textit{promptable segmentation task} to generate a valid segmentation mask based on any segmentation prompt. The prompt can include spatial or text information that identifies an object in the image, and the output of the corresponding model is a reasonable mask for at least one target object. This promptable segmentation task is used in both pre-training and downstream segmentation tasks.


 Painter, presented in~\cite{wang2022images}, is a generalist model that can perform various vision tasks based on given task prompts. It can perform tasks such as semantic segmentation, instance segmentation, depth estimation, keypoint detection, denoising, detailing, and image enhancement, as well as out-of-domain tasks like open-category object segmentation. To address the issue of general-purpose prompt definition, Painter formulates the dense-prediction vision problem as \textit{image inpainting}. This way, input/output paired images from the same task can be used as input to indicate the task the model should perform.


 Following the work on Painter, Wang \etal propose SegGPT~\cite{wang2023seggpt}, which focuses on the segmentation task and enables segmentation of everything with a generalist Painter. Zhang \etal utilize auxiliary prompts to approach the Generalized Novel Category Discovery (GNCD) setting by proposing a prompt-based Contrastive Affinity Learning (PromptCAL) method~\cite{zhang2022promptcal}. Existing semi-supervised learning methods fail to learn unlabeled data from novel semantic classes, but PromptCAL is discriminative to novel semantic information.

 The combination of prompt engineering with visual models has also triggered a line of work focusing on integrity and ethics issues. Chen \etal~\cite{chen2023visual} leveraged visual prompting to improve the adversarial robustness of a fixed, pre-trained model at testing time. Li \etal~\cite{li2023exploring} explored the benefits of visual prompting in constructing compelling neural network classifiers with differential privacy. However, such studies are still relatively rare and more attention is required. 