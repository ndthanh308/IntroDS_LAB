\section{Conclusion}

This survey paper on prompt engineering of pre-trained vision-language models has provided valuable insights into the current state of research in this field. The main findings and trends identified through the analysis shed light on the effective utilization of prompts in adapting large pre-trained models for vision-language tasks.

One key finding is the versatility and applicability of prompt engineering across different types of vision-language models, including multimodal-to-text generation models, image-text-matching models, and text-to-image generation models. The survey explored each model type from their respective characteristics, highlighting various prompting methods on them.

The implications of these findings are significant for both academia and industry. By leveraging prompt engineering techniques, researchers can achieve remarkable performance gains in vision-language models without the need for extensive labeled data. This has the potential to reduce the burden of data annotation and accelerate the deployment of vision-language models in real-world applications.

However, it is important to acknowledge the limitations of this survey. The rapidly evolving nature of the field and the wide range of existing prompt engineering approaches make it challenging to provide an exhaustive overview. Additionally, the survey focused primarily on pre-trained vision-language models from a prompting engineering perspective and may not have covered all recent advancements in other related areas.

To address these limitations, we will maintain and release a platform to keep tracking the advance in this area. Further research should explore the integration of prompt engineering techniques with other emerging technologies, such as reinforcement learning or meta-learning, to enhance the performance and generalization capabilities of vision-language models. Additionally, investigations into the interpretability and robustness of prompt-engineered models are crucial for ensuring their practical deployment and ethical use.

Overall, this survey contributes to the existing body of knowledge by providing a comprehensive overview of prompt engineering in pre-trained vision-language models. By elucidating the current state, key trends, and implications of prompt engineering techniques, this survey serves as a valuable resource for researchers and practitioners aiming to harness the potential of vision-language models for various applications. It fills a gap in research by offering insights into the adaptation of pre-trained models in the context of vision and language, paving the way for further advancements in this exciting field.

\section*{Acknowledgements}
We would like to thank Ananth Balashankar (Google Research) and Ashkan Khakzar (University of Oxford) for constructive feedback on an earlier version of this manuscript.