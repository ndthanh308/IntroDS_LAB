\IEEEraisesectionheading{\section{Introduction}\label{Sec:Introduction}}

\IEEEPARstart{P}{rompt} engineering is an approach to adapting a large pre-trained model, also known as a foundation model, to new tasks by augmenting the model input with task-specific hints. Specifically, the model's input is augmented by an additional part, called prompt, which could be manually created natural language instructions~\cite{wei2022chain}, automated generated natural language instructions~\cite{zhang2022automatic}, or automated generated vector representations~\cite{lester2021power}. The natural language instructions have been also referred to as \textit{discrete prompts} or \textit{hard prompts}, while the vector representations are called \textit{continuous prompts} or \textit{soft prompts}. 

Prompt engineering has indeed co-appeared and gained prominence with the emergence of large pre-trained models and together led to a paradigm shift in machine learning (ML). The traditional paradigm requires labeling a considerable amount of data and then training a task-specific ML model from scratch or fine-tuning a pre-trained large model. The model's performance heavily relies on the quality and amount of labeled data, which can be resource-intensive to acquire. Besides, the traditional paradigm requires tuning the model's parameters to some extent, \ie, entire parameters in the case of training an ML model from scratch or fully fine-tuning a pre-trained model and partial parameters in the case of parameter-efficient finetuning. This limits the extensibility of an ML model and requires a specific model copy for each task. Recently, prompting a pre-trained large model to adapt it for specific tasks has become a new trend. The key idea of prompt engineering is to provide hints along with input to guide a pre-trained model for solving a new task using its existing knowledge. If the hints are human-interpretable natural language (\textit{hard prompts}), the related studies have been referred to as \textit{In-Context Learning}~\cite{dong2022survey}, which enable the model to learn from task instructions, demonstrations with a few examples, or supporting information in the context. Also, the hints could be continuous vector representations (\textit{soft prompts}). The related work has been referred to as \textit{Prompt-Tuning}~\cite{lester2021power}, which optimizes prompts directly in the embedding space of the model.  


Compared to the traditional paradigm, prompt engineering has multiple advantages. Firstly, it requires a few labeled data to adapt a pre-trained model to new tasks, which greatly reduces the effort of human supervision and computation resource for fine-tuning. Secondly, prompt engineering enables a pre-trained model to perform predictions on new tasks solely based on the prompt without updating any of the model's parameters, allowing serving a large scale of downstream tasks using the same model. This makes it possible to apply large-scale pre-trained models for real-world applications.

Prompt engineering has been first studied and popularized in natural language processing (NLP)~\cite{liu2023pre, qiao2022reasoning}, and then gained great attention in computer vision~\cite{bahng2022exploring, wang2023seggpt}, as well as in vision-language modeling~\cite{alayrac2022flamingo, wu2023visual}. While there is an abundance of literature on prompt engineering in the NLP domain, there is currently no systematic overview available to provide insight into the current state of prompt engineering on pre-trained vision-language models (VLMs), which present their own unique challenges.


In this paper, we aim to bridge this gap by providing a comprehensive survey of cutting-edge research in prompt engineering of pre-trained VLMs. Specifically, we classify prompting methods into two main categories based on the readability of the templates, \ie, hard prompt and soft prompt. hard prompts can be further divided into four subcategories, namely task instruction, in-context learning, retrieval-based prompting, and chain-of-thought prompting. Soft prompts, on the other hand, are continuous vectors that can be fine-tuned using gradient-based methods. 
Note that this survey primarily focuses on prompting methods that maintain the model's architecture, and thus, the methods such as P-tuning~\cite{liu2021gpt} and LoRa~\cite{hu2021lora} that introduce additional modules into the model, are not the primary scope of this survey.

We investigate the prompt engineering on three types of VL models, which are \textit{muiltimodal-to-text generation models}, \textit{image-text-matching models}, and \textit{text-to-image generation models}. A clear definition of each model type is provided in Sec.~\ref{sec:terminology}. 
Moreover, we categorize existing prompt-engineering approaches from an encoder-decoder perspective as shown in Fig.~\ref{fig:vlm}, \ie, encode-side prompting or decode-side prompting, where the prompts are added to the encoder and decoder, respectively.

The rest of this paper is organized as follows. In Sec.~\ref{sec:2-taxonomy}, we summarize and define the taxonomy and notations that we use across this survey. 
Sec.~\ref{sec:3-mm-text},~\ref{sec:4-clip}, and~\ref{sec:5-text-img} present the current progress of prompt engineering on multimodal-to-text generation models, image-text-matching models, and text-to-image generation models, where each section first presents the preliminaries of the corresponding models followed by a detailed discussion of the prompting methods, then investigates the applications and the responsible AI considerations of such prompting methods. Sec.~\ref{sec:unimodal} provides a comparison between prompting unimodal models and VLMs, and we make an in-depth discussion about their analogies and differences. Finally, in Sec.~\ref{sec:7-discussion}, we highlight the challenges and potential research directions. 

In order to facilitate the literature search, we also build and release a project page ~\footnote{https://github.com/JindongGu/Awesome-Prompting-on-Vision-Language-Model/} where the papers relevant to our topic are organized and listed.

