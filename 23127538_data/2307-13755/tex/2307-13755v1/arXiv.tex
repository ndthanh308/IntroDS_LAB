% WACV 2024 Paper Template
% based on the CVPR 2023 template (https://media.icml.cc/Conferences/CVPR2023/cvpr2023-author_kit-v1_1-1.zip) with 2-track changes from the WACV 2023 template (https://github.com/wacv-pcs/WACV-2023-Author-Kit)
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review,algorithms]{wacv}      % To produce the REVIEW version for the algorithms track
%\usepackage[review,applications]{wacv}      % To produce the REVIEW version for the applications track
% \usepackage{wacv}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{wacv} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage[utf8]{inputenc}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage[export]{adjustbox}
\usepackage{enumitem}
\usepackage{mathtools}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}



%%%%%%%%% PAPER ID  - PLEASE UPDATE
% \def\wacvPaperID{*****} % *** Enter the WACV Paper ID here
% \def\confName{WACV}
% \def\confYear{2024}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{TMR-RD: Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection}

\author{Seyed Mojtaba Marvasti-Zadeh\\
University of Alberta\\
Edmonton, Canada\\
{\tt\small mojtaba.marvasti@ualberta.ca}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Nilanjan Ray\\
University of Alberta\\
Edmonton, Canada\\
{\tt\small nray1@ualberta.ca}
\and
Nadir Erbilgin\\
University of Alberta\\
Edmonton, Canada\\
{\tt\small erbilgin@ualberta.ca}
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
Semi-supervised object detection (SSOD) can incorporate limited labeled data and large amounts of unlabeled data to improve the performance and generalization of existing object detectors. Despite many advances, recent SSOD methods are still challenged by noisy/misleading pseudo-labels, classical exponential moving average (EMA) strategy, and the consensus of Teacher-Student models in the latter stages of training. 
This paper proposes a novel training-based model refinement (TMR) stage and a simple yet effective representation disagreement (RD) strategy to address the limitations of classical EMA and the consensus problem. The TMR stage of Teacher-Student models optimizes the lightweight scaling operation to refine the model's weights and prevent overfitting or forgetting learned patterns from unlabeled data. Meanwhile, the RD strategy helps keep these models diverged to encourage the student model to explore complementary representations.
In addition, we use cascade regression to generate more reliable pseudo-labels for supervising the student model. Extensive experiments demonstrate the superior performance of our approach over state-of-the-art SSOD methods. Specifically, the proposed approach outperforms the Unbiased-Teacher method by an average mAP margin of $4.6\%$ and $5.3\%$ when using partially-labeled and fully-labeled data on the MS-COCO dataset, respectively.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}
Object detection has experienced significant progress owing to the availability of large-scale benchmark datasets containing pairs of class labels and bounding boxes for various objects within images. 
However, collecting and accurately annotating object detection datasets is extremely expensive, time-consuming, and labor-intensive due to the lack of domain experts, limited resources, and the complicated nature of the problem. Meanwhile, acquiring a large amount of unlabeled data is relatively easy and provides valuable insights into the data distribution from which robust representations can be learned. These representations enable models to retain stability and smoothness in their predictions under various transformations such as translations, rotations, flipping, or even random perturbations \cite{SmallDataEra_Survey}. \\
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
\begin{table*}[!t]
\captionsetup{font=small}
\caption{Comparative Overview of Recent SSOD Methods.} 
\vskip -.3cm
\centering 
\resizebox{\textwidth}{!}{
\begin{tabular}{c c c c c c c c}  
\hline \hline
Year & Method & Motivation(s) & Backbone(s) & Detector(s) & Teacher Update & Weak Augmentations & Strong Augmentations \\ \hline 

\cellcolor{teal!10}2019 & \cellcolor{teal!10}CSD \cite{CSD} & \cellcolor{teal!10}More efficient training process than self-training & \cellcolor{teal!10}ResNet-101 & \cellcolor{teal!10}SSD, RFCN & \cellcolor{teal!10}$\times$ & \cellcolor{teal!10}Horizontal flip & \cellcolor{teal!10}$\times$         \\

2020 & STAC \cite{STAC} & Combining self-training \& consistency regularization & ResNet-50-FPN  & Faster-RCNN & $\times$ & $\times$ & Color/geometric transformations, cutout  \\

\cellcolor{teal!10}2021 & \cellcolor{teal!10}ISMT \cite{ISMT} & \cellcolor{teal!10}Detection discrepancies of training iterations & \cellcolor{teal!10}ResNet-50-FPN & \cellcolor{teal!10}Faster-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}$\times$ & \cellcolor{teal!10}Color jitter \\

2021 & Soft-Teacher \cite{SoftTeacher} & More reliable pseudo-labels & ResNet-50-FPN & Faster-RCNN & Classical EMA & Horizontal flip  & Scale/solarize/brightness/contrast/sharpness jitters, translation, rotate, shift, cutout \\

\cellcolor{teal!10}2021 & \cellcolor{teal!10}Humble-Teacher \cite{HumbleTeacher} & \cellcolor{teal!10}More reliable pseudo-labels, Teacher ensemble & \cellcolor{teal!10}ResNet-50-FPN, ResNet-152-FPN  & \cellcolor{teal!10}Faster-RCNN, Cascade-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Resize, flip & \cellcolor{teal!10}color/sharpness/contrast jitters, Gaussian noise, cutout  \\

2021 & Instant-Teaching \cite{InstantTeaching} & More reliable pseudo-labels, Confirmation bias & ResNet-50-FPN & Faster-RCNN & Co-rectify scheme & $\times$ &  Color/geometric transformations, cutout, mixup, mosaic \\

\cellcolor{teal!10}2021 & \cellcolor{teal!10}Unbiased-Teacher \cite{UnbiasedTeacher} & \cellcolor{teal!10}Class imbalance, Pseudo-label bias & \cellcolor{teal!10}ResNet-50-FPN  & \cellcolor{teal!10}Faster-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Horizontal flip & \cellcolor{teal!10}Color jitter, grayscale, Gaussian blur, cutout \\

2022 & Active-Teacher \cite{ActiveTeacher} & More reliable pseudo-labels, Data initialization & ResNet-50-FPN & Faster-RCNN & Classical EMA & Horizontal flip & Horizontal flip, color jitter, grayscale, Gaussian blur, cutout  \\

\cellcolor{teal!10}2022 & \cellcolor{teal!10}ACRST \cite{ACRST} & \cellcolor{teal!10}Class imbalance, Biased/noisy pseudo-labels & \cellcolor{teal!10}ResNet-50-FPN & \cellcolor{teal!10}Faster-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Resize, flip, crop & \cellcolor{teal!10}Color jitter, Gaussian blur, cutout \\

2022 & CAPL \cite{CertaintyPseudo} & Class imbalance, Localization precision & ResNet-50-FPN & Faster-RCNN & $\times$ & Horizontal flipping  & Color jitter, Gaussian blur, cutout \\

\cellcolor{teal!10}2022 & \cellcolor{teal!10}SED \cite{SED} & \cellcolor{teal!10}Class imbalance, Large variance of object sizes & \cellcolor{teal!10}ResNet-50-FPN & \cellcolor{teal!10}Faster-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Resize, horizontal flip & \cellcolor{teal!10}Color jitter, grayscale, Gaussian blur, cutout \\

2022 & Label-Match \cite{LabelMatch} & Label mismatch, Confirmation bias & ResNet-50-FPN & Faster-RCNN & Classical EMA & Horizontal flip, multi-scale & Color jitter, grayscale, Gaussian blur, cutout \\

\cellcolor{teal!10}2022 & \cellcolor{teal!10}MA-GCP \cite{MA-GCP} & \cellcolor{teal!10}Relation between labeled \& unlabeled data & \cellcolor{teal!10}ResNet-50-FPN & \cellcolor{teal!10}Faster-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Horizontal flip & \cellcolor{teal!10}Scale/solarize/brightness/contrast/sharpness jitters, translation, rotate, shift, cutout \\

2022 & MUM \cite{MUM} & More complex data augmentation & ResNet-50-FPN, SwinTransformer & Faster-RCNN & Classical EMA & Horizontal flip  & Mixing image tiles, color jitter, grayscale, Gaussian blur, cutout \\

\cellcolor{teal!10}2022 & \cellcolor{teal!10}Unbiased-Teacher-v2 \cite{UnbiasedTeacher2} & \cellcolor{teal!10}Anchor-free detectors, \cellcolor{teal!10}Misleading pseudo-labels & \cellcolor{teal!10}ResNet-50-FPN & \cellcolor{teal!10}Faster-RCNN, FCOS & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Horizontal flip & \cellcolor{teal!10}Color/scale jitters, grayscale, Gaussian blur, cutout \\

2022 & Diverse-Learner \cite{DiverseLearner} & Maintain networks distinctiveness & ResNet-50-FPN & Faster-RCNN & Classical EMA & Horizontal flip, random size & Random erasing, rotation, color jitters, etc. \\

\cellcolor{teal!10}2022 & \cellcolor{teal!10}PseCo \cite{PseCo} & \cellcolor{teal!10}Noisy pseudo-labels, Scale-invariant learning & \cellcolor{teal!10}ResNet-50-FPN & \cellcolor{teal!10}Faster-RCNN & \cellcolor{teal!10}Classical EMA & \cellcolor{teal!10}Horizontal flip & \cellcolor{teal!10}Scale/solarize/brightness/contrast/sharpness jitters, translation, rotate, shift, cutout \\

2022 & VC-Learner \cite{VCLearning} & Confirmation bias, Confusing samples & ResNet-50-FPN & Faster-RCNN & $\times$ & Horizontal flip & Color/scale jitters, grayscale, Gaussian blur, cutout \\

\hline \hline
\end{tabular}
\label{table:comp_ssod}
}
\vskip -.3cm
\end{table*}
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Leveraging unlabeled data for training object detectors has become increasingly popular due to its potential to significantly reduce annotation costs \& efforts while improving model performance and generalization. Semi-supervised object detection (SSOD) aims to harness unsupervised information in scenarios where labeled data is scarce. Most recent SSOD methods rely on self-training techniques (e.g., \cite{UnbiasedTeacher,DiverseLearner,ActiveTeacher,HumbleTeacher}), in which the pseudo-labels generated from the teacher model(s) are utilized to train the student model(s) when weak \& strong augmentations of images are used as inputs (see Table~\ref{table:comp_ssod}). While these methods enforce the consistency of Teacher-Student predictions to train the student model, the classical exponential moving average (EMA) strategy is adopted to evolve the teacher model progressively. 
This strategy gradually refines the weights of the teacher model to improve the accuracy of pseudo-labels \& resiliency to noisy weights of the student model \cite{HumbleTeacher} as well as alleviate the adverse effects of pseudo-labeling bias \cite{UnbiasedTeacher}. \\
\indent Despite the progress made in the SSOD, training Teacher-Student models still faces three major challenges. The first challenge is to address noisy/misleading pseudo-labels, which can impede accurate model optimization leading to ineffective learning from unlabeled data and slow convergence. As shown in Table~\ref{table:comp_ssod}, extensive efforts (e.g., \cite{SoftTeacher,InstantTeaching,ActiveTeacher,ACRST,UnbiasedTeacher2,PseCo}) have been made to provide more reliable pseudo-labels. Although most of these methods rely on the well-established two-stage Faster-RCNN detector \cite{FasterRCNN}, it can be optimal solely for detecting objects at a single-quality level due to the adversarial nature of producing noisy bounding boxes or assembling inadequate positive proposals. Accordingly, some SSOD methods (e.g., \cite{UnbiasedTeacher}) avoid calculating unsupervised losses for box regression to mitigate potential incorrect pseudo-labels resulting from the naive confidence thresholding of the detector.
Following the Humble-Teacher \cite{HumbleTeacher} that demonstrated the efficacy of the Cascade-RCNN \cite{CascadeRCNN} for the SSOD, we integrate cascade regression into the baseline \cite{UnbiasedTeacher} to generate more reliable pseudo-labels while reducing the overfitting problem. Meanwhile, the effectiveness of our proposed approach (discussed below) is also validated using the Faster-RCNN detector. \\
\indent The second challenge pertains to applying the classical EMA strategy using pre-defined smoothing coefficients. This strategy can lead to two potential issues when refining the weights of the teacher model: 
i) insensitivity to important changes in weights of the student model due to excessive reliance on the initialized detector, and 
ii) sub-optimal performance because constant coefficients may not be effective for all refinement steps, resulting in weaker pseudo-labels. 
To address these limitations, we propose a novel Training-based Model Refinement (TMR) stage that adaptively refines the weights of Teacher-Student models (see Fig.~\ref{fig:TNR-FD}). This stage is added to the commonly used training stages of: i) pre-training on limited labeled data (or Burn-In stage), and ii) semi-supervised learning (SSL) stage in existing SSOD methods. Inspired by \textit{meta-transfer learning} (MTL) \cite{MTL}, we optimize the lightweight scaling operation corresponding to learnable parameters of Teacher-Student models to more effectively aggregate information from labeled and unlabeled data.
The models' weights can then be adaptively refined using the introduced update rules to ensure the teacher model is up-to-date and reduce the effect of noisy pseudo-labels on the student model without the risk of overfitting or forgetting the patterns learned from unlabeled data. 
% estimate scaling coefficients with fast convergence. 
\\
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% Figure environment removed
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
The last challenge is the consensus problem (i.e., losing the distinctiveness of Teacher-Student models) at the latter stages of the training procedure when two models become almost identical. This challenge is also derived from the classical EMA strategy to refine the teacher model, leading to teacher weights being close to student ones as training progresses. Accordingly, both models generate similar predictions and make it difficult for the teacher model to extract helpful information from unlabeled data for supervising the student model. 
To alleviate this issue, we propose a simple yet effective Representation Disagreement (RD) strategy to increase model divergence by encouraging the student model to explore more robust representations, learn complementary information, and reduce the memorization effect of easy samples. 
This strategy incorporates the asymmetric Kullback-Leiber (KL) divergence between the semantic representation of Teacher-Student models to prevent early convergence. 
In other words, it combines a disagreement strategy with the agreement strategy in the SSL stage to heighten learning potentials while ensuring the predictions remain consistent. \\
% By doing so, the RD strategy encourages continued learning and enhances performance by heightening learning potentials and preventing convergence of the networks too early (i.e., exploring broader ranges of solutions). 
% we were inspired by \textit{deep mutual learning} (DML) \cite{DeepMutualLearning} and \textit{joint training with co-regularization} (JoCoR) \cite{JoCoR} to propose a simple yet effective \textit{feature disagreement} (FD) strategy for SSOD frameworks. 
\indent The main contributions are summarized as follows:
\begin{itemize}[noitemsep,nolistsep]
    \item A novel TMR stage is proposed to adaptively refine the weights of Teacher/Student models in SSOD frameworks. 
    It can learn the lightweight scaling operation corresponding to the learnable parameters of the Teacher-Student models, enabling fast convergence without the risk of overfitting or forgetting patterns learned from unlabeled data.
    \item A simple yet effective RD strategy is proposed to alleviate the consensus problem of Teacher-Student models with increasing training epochs. This strategy prevents Teacher-Student models from converging too early, allowing better generalization through more exploring underlying patterns in unlabeled data.
    \item Extensive empirical evaluations demonstrated superior performance and generalizability of the proposed approach, which can be incorporated into existing SSOD methods to boost their performance. 
\end{itemize}
\vskip -2cm   
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Related Work} \label{sec2:relatedwork}
\subsection{Semi-Supervised Object Detection (SSOD)} \label{sec:ssod}
While existing SSOD methods tackle various challenges (e.g., efficient training \cite{CSD,STAC}, detection discrepancies \cite{ISMT}, localization certainty \cite{CertaintyPseudo}, prediction consistency \cite{MA-GCP}, object size \cite{SED}, data augmentation \cite{MUM}, confusing samples \cite{VCLearning}, etc. (see Table~\ref{table:comp_ssod})), recent advances have primarily focused on improving the reliability of pseudo-labels. 
The Soft-Teacher \cite{SoftTeacher} assesses the reliability of candidates and selects pseudo-boxes with higher scores for training the student's localization branch.
In Instant-Teaching \cite{InstantTeaching}, pseudo-label quality is improved through instant pseudo-labeling (without pre-training a teacher model) and simultaneously training two models. 
The Humble-Teacher \cite{HumbleTeacher} utilizes soft pseudo-labels and teacher ensemble to exploit richer information and obtain more reliable pseudo-labels.
The iterative Active-Teacher \cite{ActiveTeacher} improves pseudo-label quality by selecting the most optimal labeled examples, while the ACRST \cite{ACRST} employs the CropBank memory module and a two-stage pseudo-label filtering to alleviate biased and noisy pseudo-labels.
In Label-Match \cite{LabelMatch}, the re-distributed mean teacher and proposal self-assignment are proposed to generate unbiased and accurate pseudo-labels matching the student model proposals. 
The PseCo \cite{PseCo} consists of prediction-guided label assignment, positive-proposal consistency voting, and multi-view scale-invariant learning to achieve robust pseudo-boxes, quantify their localization quality, and ensure label consistency, respectively.
The Unbiased-Teacher \cite{UnbiasedTeacher} addresses pseudo-labeling bias utilizing the classical EMA and Focal loss \cite{FocalLoss}, while the Unbiased-Teacher-v2 \cite{UnbiasedTeacher2} prevents misleading pseudo-labels on the regression branch based on relative uncertainties in the Teacher-Student models. \\
\indent Most recent SSOD methods employ the classical EMA strategy with a fixed smoothing coefficient to refine the teacher's model weights (see Table~\ref{table:comp_ssod}). Recently, the limitations of this strategy have been discussed in the Diverse-Learner \cite{DiverseLearner}. This method uses two Teacher-Student pairs and multi-threshold classification loss to alleviate the associated drawbacks, maintain distinctiveness between models, and improve pseudo-labels. However, it still uses the classical EMA strategy to refine its teacher models. 
As an alternative solution, we introduce a novel approach for refining Teacher-Student models by optimizing the lightweight scaling operation corresponding to the learnable model parameters and encouraging the student model to learn complementary information.
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsection{Classical Exponential Moving Average (EMA)} \label{sec:ema}
The classical EMA strategy \cite{EMA_MeanTeachers} updates the teacher model by averaging model weights to ensure more accurate predictions from this model than the student model. This strategy can minimize the adverse effects of imbalanced and noisy pseudo-labeling through mutually reinforcing pseudo-labeling and the detection training steps by
\vskip -.3cm
\begin{equation} \label{eq:ema}
\begin{aligned}
\theta_{t}^{n} &\leftarrow \alpha \theta_{t}^{n-1} + (1-\alpha)\theta_{s}^{n-1} \\
\Rightarrow \quad \theta_{t}^{n} &\leftarrow \alpha^{n} \theta_{t}^{0} + (1-\alpha)\sum_{k=0}^{n-1}\alpha^{n-1-k}\theta_{s}^{k}
\end{aligned}
\end{equation}
\vskip -.3cm
\noindent in which $\theta_{t}^{0}$, $\theta_{t}^{n}$, $\theta_{s}^{n-1}$, and $\alpha$ represent the initialized detector (trained on limited labeled data) at time step ${n=0}$, the parameters of the current teacher model (i.e., $n$-th time step), the parameters of the previous student model (i.e., $(n-1)$-th time step), and a smoothing coefficient hyperparameter (i.e., EMA decay), respectively. The EMA decay $\alpha$ is often set to $0.999$ in SSOD methods so that the teacher model can benefit from a long memory while it assumes the student model improves slowly. 
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% - - - - - - - - - - Propose Method: TNR-RD - - - - - - - - - - - - - - - - - - - 
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Proposed Approach: TMR-RD} \label{sec3:ours}
In this section, we present the TMR-RD approach to address the limitations of the classical EMA strategy and the consensus problem while improving the generation of reliable pseudo-labels. We use the Unbiased-Teacher \cite{UnbiasedTeacher} as the baseline SSOD method to demonstrate the effectiveness of the proposed approach. As shown in Fig.~\ref{fig:TNR-FD}, first, we integrate the cascade regression into the baseline method to provide more reliable pseudo-labels. This is of particular importance since the number of boxes for unlabeled data is often determined by the confidence threshold in SSOD methods (e.g., \cite{UnbiasedTeacher}). 
Decreasing this confidence threshold can increase the number of detected objects and the amount of information mined, while it can also reduce detection performance due to additional noisy pseudo-labels. However, using a higher threshold can lead to only a limited number of high-quality boxes where many objects are ignored during the SSL stage. 
Hence, our base detector is based on a multi-stage architecture with specialized regressors that enable more precise localization (see \cite{CascadeRCNN} for further details). Meanwhile, we also evaluate our proposed approach using the Faster-RCNN detector to demonstrate its effectiveness and generalization.
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsection{Training-based Model Refinement (TMR)} \label{subsec:update}
The proposed TMR stage is inspired by the MTL \cite{MTL} that adapts large-scale trained base classification models to new tasks with limited data using two lightweight neuron operations of scaling and shifting.
However, the proposed TMR is designed following the EMA equation (see Eq.~\ref{eq:ema}) that merely requires scaling coefficients to refine the model weights. \\
\indent The proposed approach comprises three stages of Burn-In, SSL, and TMR (see Fig.~\ref{fig:TNR-FD}), of which the first is the same as that in the baseline method \cite{UnbiasedTeacher}. The Burn-In stage provides a good initialization by training the base object detector on the available labeled data.
Then, the initialized detector is duplicated into the Teacher-Student models so that pseudo-labels are generated by the Teacher and used to train the Student during the SSL stage. However, the weights of the teacher model are not updated using the classical EMA as in \cite{UnbiasedTeacher}. Instead, we freeze neuron weights from the SSL stage after completing $N$ iterations and initiate the TMR stage to learn a set of lightweight scaling operation associated with the trained parameters of the Teacher-Student models. 
The learned scaling operation replaces the classical EMA decay (i.e., adaptive coefficients instead of one fixed EMA decay). Hence, the proposed TMR can promote the progressive transfer of knowledge from the continually learning student model to the teacher one, thereby aggregating information more effectively and improving the generation of pseudo-labels.
The training process involves alternately applying the SSL and TMR stages until convergence. \\
\indent In the TMR stage, the scaling operation is denoted as $\Omega_{i}$, where $i\in\left(t, s\right)$ refers to the teacher or student model. The MTL \cite{MTL} defines the scaling and shifting operations exclusively for the feature extractor (i.e., backbone layers) and updates them after optimizing a temporal classifier (i.e., as per a new task). However, the proposed TMR applies scaling operation to all frozen neuron weights of Teacher/Student models by $\mathcal{S}(\hat{x};\theta_{i};\Omega_{i})=(\theta_{i}\odot \Omega_{i})\hat{x}_{k}$ during the TMR stage, where $\mathcal{\hat{D}}=\{\hat{x}_k, \hat{y}_k\}_{k=1}^{N_{sup}}$ and $\odot$ are the strongly-augmented labeled data and the element-wise multiplication, respectively.
Then, the TMR loss is defined as
\vskip -0.6cm
\begin{gather} \label{eq:L_scale}
\mathcal{L}_{\rm{TMR}}= \lambda_t \mathcal{L}_{sc}\left ([\theta_{t}; \Omega_{t}] \right) + 
\lambda_s \mathcal{L}_{sc}\left ([\theta_{s}; \Omega_{s}] \right),
\end{gather}
\vskip -0.75cm
% \begin{align}  \label{eq:L_cascade}
% \nonumber \mathcal{L}_{sc}\left ([\theta_{i}; \Omega_{i}] \right) &= \sum_{j\in\mathcal{\hat{D}}}
%   \mathcal{L}_{cls}^{rpn}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{0}({\hat{x}}_{j}^{0}), {\hat{y}}_{j}^{0}\right)
% + \mathcal{L}_{reg}^{rpn}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{0}({\hat{x}}_{j}^{0}), {\hat{y}}_{j}^{0}\right) 
% + \mathcal{L}_{cls}^{roi}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{1}({\hat{x}}_{j}^{1}), {\hat{y}}_{j}^{1}\right)  \\
% \nonumber &+ \mathcal{L}_{reg}^{roi}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{1}({\hat{x}}_{j}^{1}), {\hat{y}}_{j}^{1}\right) 
% + \mathcal{L}_{cls}^{roi}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{2}({\hat{x}}_{j}^{2}), {\hat{y}}_{j}^{2}\right)
% + \mathcal{L}_{reg}^{roi}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{2}({\hat{x}}_{j}^{2}), {\hat{y}}_{j}^{2}\right) \\
% & + \mathcal{L}_{cls}^{roi}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{3}({\hat{x}}_{j}^{3}), {\hat{y}}_{j}^{3}\right)
% + \mathcal{L}_{reg}^{roi}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{3}({\hat{x}}_{j}^{3}), {\hat{y}}_{j}^{3}\right), 
% \end{align}
\begin{equation} \label{eq:L_cascade}
\begin{aligned}
\mathcal{L}_{sc}\left ([\theta_{i}; \Omega_{i}] \right) &= \sum_{j\in\mathcal{\hat{D}}}
\mathcal{L}_{cls}^{rpn}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{0}({\hat{x}}_{j}^{0}), {\hat{y}}_{j}^{0}\right) \\
&+ \mathcal{L}_{reg}^{rpn}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{0}({\hat{x}}_{j}^{0}), {\hat{y}}_{j}^{0}\right) 
+ \mathcal{L}_{cls}^{roi}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{1}({\hat{x}}_{j}^{1}), {\hat{y}}_{j}^{1}\right) \\
&+ \mathcal{L}_{reg}^{roi}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{1}({\hat{x}}_{j}^{1}), {\hat{y}}_{j}^{1}\right) 
+ \mathcal{L}_{cls}^{roi}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{2}({\hat{x}}_{j}^{2}), {\hat{y}}_{j}^{2}\right) \\
&+ \mathcal{L}_{reg}^{roi}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{2}({\hat{x}}_{j}^{2}), {\hat{y}}_{j}^{2}\right) 
+ \mathcal{L}_{cls}^{roi}\left(\mathcal{C}_{[\theta_{i}; \Omega_{i}]}^{3}({\hat{x}}_{j}^{3}), {\hat{y}}_{j}^{3}\right) \\
&+ \mathcal{L}_{reg}^{roi}\left(\mathcal{B}_{[\theta_{i}; \Omega_{i}]}^{3}({\hat{x}}_{j}^{3}), {\hat{y}}_{j}^{3}\right),
\end{aligned}
\end{equation}
where $\mathcal{L}_{sc}$, $\mathcal{C}^{k}$, and $\mathcal{B}^{k}$ represent the scaling operation loss, a classifier and a regressor at stage $k$ optimized for IoU threshold $u^{k}$, respectively. In addition, $rpn$ and $roi$ refer to the RPN and RoIHead branches, respectively.
As shown in Fig.~\ref{fig:TNR-FD}, we utilize the Cross-Entropy, Smooth-L1, and Focal loss as in the baseline method \cite{UnbiasedTeacher} for our models with cascade regression to provide fair comparisons.
Next, the scaling operation weights that are associated with learnable parameters of the Teacher-Student models are updated by 
\vskip -0.5cm
\begin{gather} \label{eq:scale_upd}
\Omega_{i} =: \Omega_{i} - \gamma \nabla_{\Omega_{i}}\mathcal{L}_{sc}, 
\end{gather}
\vskip -0.1cm
\noindent in which $\gamma$ denotes the learning rate. 
Optimizing the lightweight scaling operation while keeping the large-scale trained weights of Teacher-Student models unchanged allows for fast convergence while reducing the overfitting risk. 
After $N'$ iterations, the Teacher/Student models are refined using the following update rules as 
% \vskip -.8cm
\begin{gather} \label{eq:rules}
\theta_{t}^{n}=\frac{\Omega_{t}}{\Omega_{t}+\Omega_{s}}\theta_{t}^{n-1} + \frac{\Omega_{s}}{\Omega_{t}+\Omega_{s}}\theta_{s}^{n-1}, \\
% \end{gather}
% \begin{gather} \label{eq:rule_stu}
\theta_{s}^{n}=(1-\frac{\Omega_{t}}{\Omega_{t}+\Omega_{s}})\theta_{t}^{n-1} + (1-\frac{\Omega_{s}}{\Omega_{t}+\Omega_{s}})\theta_{s}^{n-1}.        
\end{gather}
\vskip -0.1cm
% - - - - - - - - - - - - - - - - - - - - - - -
\noindent These rules imply that the scaling operation weights stay within the permissible range of zero to one and selectively refine models by the ability to adjust or forget inaccurate model weights more effectively.
Besides updating the teacher weights, the student weights are also slightly refined to reduce the impact of noisy pseudo-labels from training this model with potentially misleading pseudo-labels in the SSL stage. As previously mentioned, the SSL and TMR stages are alternatively continued until the end of the training procedure.
This approach makes it possible to efficiently learn EMA decay coefficients on-the-fly, improving the performance of SSOD methods.
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsection{Representation Disagreement (RD)} \label{subsec:disagree}
The disagreement strategy idea lies in the principles of Co-training \cite{Disagree_idea}, where the effectiveness of an ensemble can be improved by keeping divergent classifiers. It has then been extended to train deep networks in the presence of noisy labels (e.g., \cite{Decoupling,CoTeachingPlus}). These scenarios involve simultaneous training of two deep networks based on the cross-update principle implied by the culture-evolving hypothesis \cite{EvolveBengio}, where a network can improve its learning capability when it is aided by signals generated by another network. Although two networks with distinct learning capabilities can distinguish different error categories at the beginning of the training phase, they will progressively converge toward being close to each other, known as the consensus problem. Hence, the disagreement strategy seeks to alleviate this issue and boost the performance by keeping two networks diverged within the training epochs or slowing the consensus rate between two networks as the number of epochs increases. \\
\indent Similarly, the lack of distinctiveness is a common problem in SSOD pseudo-labeling methods employing the EMA strategy, as the weights of the Teacher-Student models become almost identical towards the latter stages of training \cite{DiverseLearner}. To alleviate this problem, we introduce the simple yet effective RD strategy during the SSL stage that encourages the student model to leverage more information from the teacher's representation of the data. It is also motivated by JoCoR \cite{JoCoR} and DML \cite{DeepMutualLearning} methods used for weakly-supervised learning and knowledge distillation. However, our strategy relies on the representation space to keep Teacher-Student models diverged in contrast with the DML and JoCoR aimed at reducing the diversity between ensemble networks and minimizing the KL divergence between the probabilistic outputs of networks. 
For the proposed RD strategy, we first compute the probability distributions of semantic representations $f_i \in \mathbb{R}^{C \times H \times W}$ from Teacher/Student models using $p_{t}=softmax\left(f_{t}(x^{\ast})\right)$ and $p_{s}=softmax\left(f_{s}(x')\right)$, where ${x^\ast}$ and $x'$ are the weakly-augmented and strongly-augmented samples from unlabeled data $\mathcal{\overline{D}}$, respectively.
Then, the asymmetric KL divergence is computed between the probability distributions based on the supervision of the teacher model as
% - - - - - - - - - - - - - - - - - - - 
\vskip -0.4cm
\begin{gather} \label{eq:kl_loss}
\mathcal{L}_{\rm{RD}} = {KL}(p_s(x') || p_t(x^{\ast})). 
\end{gather}
% \vskip -0.2cm
% - - - - - - - - - - - - - - - - - - - 
\noindent Consequently, the learnable weights for the student model are updated during the SSL stage by
% - - - - - - - - - - - - - - - - - - - 
\vskip -0.4cm
\begin{gather} \label{eq:stu_upd_kl}
\theta_{s} \leftarrow \theta_{s}+\xi \frac{\partial(\mathcal{L}_{sup}+\lambda_u \mathcal{L}_{unsup}-\lambda_d \mathcal{L}_{\rm{RD}})}{\partial \theta_s}          
\end{gather}
\vskip -0.2cm
% - - - - - - - - - - - - - - - - - - - 
\noindent where the learning rate is denoted by $\xi$, while $\lambda_u$, and $\lambda_d$ are hyperparameters that control the contribution of the unsupervised and representation disagreement losses, respectively. Here, $\mathcal{L}_{sup}$ and $\mathcal{L}_{unsup}$ represents the supervised loss of the teacher model using $\mathcal{D^{\ast}}=\{x^{\ast}_{k}, y^{\ast}_{k}\}_{k=1}^{N_{sup}}$ and the unsupervised loss of the student model using $\{{x'}_{k}, \bar{y}_{k}\}_{k=1}^{N_{unsup}}$, in which $\bar{y}$ denotes pseudo-labels. Note that our approach applies Eq.~\ref{eq:L_cascade} to compute $\mathcal{L}_{sup}$ and $\mathcal{L}_{unsup}$ using different sets of data (than during the TMR stage) while freezing the scale operation weights. In addition, our method differs from the baseline method \cite{UnbiasedTeacher}, which does not incorporate the unsupervised loss for bounding box regression.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Empirical Experiments}\label{sec4:exp}
This section provides implementation details of the proposed approach, presents a systematic ablation analysis, and reports state-of-the-art (SOTA) comparisons using the MS-COCO dataset \cite{COCO}. The dataset includes the COCO-standard (comprising the train$2017$ and val$2017$ splits with $\sim$118K and $\sim$5K labeled images, respectively) and COCO-additional (including $\sim$123K unlabeled images) sets. Following prior works (e.g., \cite{ActiveTeacher,DiverseLearner}), we evaluated our proposed approach using two experimental settings, including partially-labeled and fully-labeled data. The partially-labeled data setting involves randomly selecting 1\%, 5\%, and 10\% of the train$2017$ split as labeled training data, while the remaining data was treated as unlabeled training data. For the fully-labeled data setting, the entire train$2017$ split and the COCO-additional set are utilized as labeled data and unlabeled data, respectively. The evaluations are performed on the val2017 set using the \textit{mean average precision} (mAP) metric.
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\begin{table*}[ht] 
\centering
% \scriptsize
\captionsetup{font=small}
\vskip -0.5cm
\caption{Ablation analysis of proposed TMR-RD considering different components and base model on COCO-standard set.} 
\vskip -0.3cm
\resizebox{\textwidth}{!}{
\begin{tabular}{c | c c c | c c c} 
\hline \hline
{Metric}   & {Baseline \cite{UnbiasedTeacher} (A1)}    & \textbf{A1+TMR (A12)}   & \textbf{A12+RD (A13)}      & \textbf{A1+Cascade Reg. (A2)}    & \textbf{A2+TMR (A21)}   & \textbf{A21+RD (A22)} \\ \hline 
\cellcolor{teal!10}{mAP}    & \cellcolor{teal!10}{{28.27}} & \cellcolor{teal!10}{\textbf{29.93}} & \cellcolor{teal!10}{\textbf{30.60}}    & \cellcolor{teal!10}{\textbf{30.19}} & \cellcolor{teal!10}{\textbf{32.66}} & \cellcolor{teal!10}{\textbf{33.41}} \\
\hline \hline
\end{tabular}}\label{table:ablation}
\vskip -0.4cm
\end{table*}
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsection{Implementation Details} \label{sec:imp_details}
We employ the Faster-RCNN \cite{FasterRCNN} and Cascade-RCNN \cite{CascadeRCNN} implemented in Detectron2 \cite{Detectron2} as our base detection frameworks. The backbones consist of ResNet-$50$-FPN architecture \cite{ResNet50FPN} initialized with the pre-trained Image-Net \cite{ImageNet} weights. The Burn-In and SSL (without classical EMA) stages followed the baseline Unbiased-Teacher \cite{UnbiasedTeacher} with pre-training for $2$K iterations and initiating Teacher-Student models. We experimentally adopted cyclic SSL and TMR stages with $N=4$K iterations dedicated to the SSL and $N'=2$K iterations devoted to the TMR. This cyclic process was repeated until the end of the training process. 
For partially-labeled data setting, the models were trained for $270$K iterations (i.e., $180$K for SSL (as in \cite{UnbiasedTeacher}), $90$K for TMR) and $540$K iterations (i.e., $360$K for SSL, $180$K for TMR) using the base detectors of Faster-RCNN and Cascade-RCNN, respectively. 
In the fully-labeled data setting, we trained the models with Faster-RCNN and Cascade-RCNN base detectors for $1080$K and $2160$K iterations, respectively. Specifically, we used $720$K iterations for SSL (as in \cite{UnbiasedTeacher}) and $360$K iterations for TMR using the Faster-RCNN detector, while for the Cascade-RCNN, we used $1440$K iterations for SSL and $720$K iterations for TMR. 
The implementations were performed on $16$ synchronized Nvidia Tesla V$100$ GPUs with $16$GB RAM. 
The cascade regression utilizes three detection stages with IoU thresholds $U=\{0.5, 0.6, 0.7\}$ to generate high-quality pseudo-labels. The loss coefficients were set to $\lambda_t=1$, $\lambda_s=4$, $\lambda_u=4$, while the RD loss coefficient was set to $\lambda_d=0.5$ or $\lambda_d=1$ using the base detectors of Faster-RCNN or Cascade-RCNN, respectively. Moreover, the semantic representations were extracted from the last two layers of the backbones, i.e., $f_i=[conv4\_x, conv5\_x]$.
The batch size of $64$ was used in training, where $32$ labeled \& $32$ unlabeled images were randomly selected for each batch. The optimizer, learning rates, data augmentations, and other hyperparameters were applied in a similar manner to the baseline \cite{UnbiasedTeacher}.
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\begin{table*}[!ht]
\captionsetup{font=small}
\caption{State-of-the-art comparison on COCO-standard val2017 split under the partially-labeled data and fully-labeled data settings.} 
\vskip -0.3cm
\resizebox{\textwidth}{!}{
\centering % used for centering table
\begin{tabular}{c | c c c | c} 
\hline \hline
\small {Methods} & {1\% labeled samples} & {5\% labeled samples} & {10\% labeled samples} & {Fully-labeled samples}  \\ \hline

\cellcolor{teal!10}Supervised (Baseline) \cite{UnbiasedTeacher}  & \cellcolor{teal!10}9.05  & \cellcolor{teal!10}18.47 & \cellcolor{teal!10}23.86 & \cellcolor{teal!10}40.2 \\

Supervised (Cascade regression)               & 10.86 & 19.44 & 25.18 & 42.1 \\ \hline

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\cellcolor{teal!10}ISMT \cite{ISMT}                              & \cellcolor{teal!10}18.88 & \cellcolor{teal!10}26.37 & \cellcolor{teal!10}30.53 & \cellcolor{teal!10}39.6 \\

Instant-Teaching \cite{InstantTeaching}       & 18.05 & 26.75 & 30.40 & 40.2  \\ 

\cellcolor{teal!10}CAPL \cite{CertaintyPseudo}                   & \cellcolor{teal!10}19.02 & \cellcolor{teal!10}28.40 & \cellcolor{teal!10}32.23 & \cellcolor{teal!10}43.3 \\ 

SED \cite{SED}                                &   -   & 29.01 & 34.02 & 41.5 \\ 

\cellcolor{teal!10}Humble-Teacher \cite{HumbleTeacher}           & \cellcolor{teal!10}16.96 & \cellcolor{teal!10}27.70 & \cellcolor{teal!10}31.61 & \cellcolor{teal!10}42.4  \\ 

Soft-Teacher \cite{SoftTeacher}               & 20.46 & 30.74 & 34.04 & 44.5 \\ 

\cellcolor{teal!10}MA-GCP \cite{MA-GCP}      & \cellcolor{teal!10}21.30 & \cellcolor{teal!10}31.67 & \cellcolor{teal!10}35.02 & \cellcolor{teal!10}45.9 \\ 

Unbiased-Teacher \cite{UnbiasedTeacher}       & 20.75 & 28.27 & 31.50 & 41.3  \\ 

\cellcolor{teal!10}Active-Teacher \cite{ActiveTeacher}           & \cellcolor{teal!10}22.20 & \cellcolor{teal!10}30.07 & \cellcolor{teal!10}32.58 & \cellcolor{teal!10}- \\ 

Diverse-Learner \cite{DiverseLearner}         & 23.72 & 31.92 & 34.61 & 44.8 \\ \hline

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\cellcolor{teal!10}\textbf{TMR-RD (Faster-RCNN detector)}                 & \cellcolor{teal!10}\textbf{22.23} & \cellcolor{teal!10}\textbf{30.60} & \cellcolor{teal!10}\textbf{33.92} & \cellcolor{teal!10}\textbf{43.2} \\

\textbf{TMR-RD (Cascade regression)}                   & \textbf{24.39} & \textbf{33.41} & \textbf{36.87} & \textbf{46.6} \\
%  &  &  &  &  & \\ 
\hline \hline
\end{tabular}} \label{table:sota}
\vskip -0.4cm
\end{table*}
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsection{Ablation Analysis} \label{sec:ablation}
A systematic ablation analysis of the proposed approach, integrated into the Faster-RCNN and Cascade-RCNN as the base detectors, has been conducted using a 5\% labeled COCO-standard dataset. The analysis includes six different configurations: i) baseline method with Faster-RCNN and classical EMA \cite{UnbiasedTeacher}, ii) baseline method with Faster-RCNN equipped with TMR instead of classical EMA, iii) baseline method with Faster-RCNN equipped with TMR and RD strategy, iv) baseline method with cascade regression and classical EMA, v) baseline method with cascade regression equipped with TMR instead of classical EMA, and vi) baseline method with cascade regression equipped with TMR and RD strategy. These configurations are referred to as A1, A12, A13, A2, A21, and A22, respectively. The presented results in Table~\ref{table:ablation} demonstrate the effectiveness of each component. Accordingly, the cascade regression integration led to a 1.92\% increase in mAP compared to the baseline method \cite{UnbiasedTeacher}. In addition, incorporating the TMR stage has shown a noticeable improvement in the mAP metric, with an increase of up to $1.66\%$ and $2.47\%$ when using the base detectors of Faster-RCNN and Cascade-RCNN, respectively. Moreover, the RD strategy has provided further improvement of 0.67\% and 0.75\% with the base detectors of Faster-RCNN and Cascade-RCNN, respectively. 

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\subsection{State-of-the-art Comparison}
In this section, the proposed TMR-RD approach using the base detectors of Faster-RCNN and Cascade-RCNN is compared with recent SSOD methods, namely ISMT \cite{ISMT}, Soft-Teacher \cite{SoftTeacher}, Instant-Teaching \cite{InstantTeaching}, CAPL \cite{CertaintyPseudo}, SED \cite{SED}, Humble-Teacher \cite{HumbleTeacher}, MA-GCP \cite{MA-GCP}, Unbiased-Teacher \cite{UnbiasedTeacher} (baseline), Active-Teacher \cite{ActiveTeacher}, and Diverse-Learner \cite{DiverseLearner}, on the COCO-standard val2017 split. The comparison results are presented in Table~\ref{table:sota}. 
\vskip 5pt
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\noindent\textbf{Partially-labeled data setting}: 
First, we compare the proposed approach with existing SOTA methods trained on 1\%, 5\%, and 10\% labeled data from the train$2017$ split of the COCO-standard set. According to the results, the proposed TMR-RD with Faster-RCNN detector outperforms the baseline method \cite{UnbiasedTeacher} by 1.48\%, 2.33\%, and 2.42\% under the 1\%, 5\%, and 10\% labeling ratios, respectively. In addition, incorporating the proposed approach with cascade regression outperforms the baseline method by 3.64\%, 5.14\%, and 5.37\% under the mentioned labeling ratios, respectively. The results show that the integration of our TMR-RD into the baseline method with cascade regression can result in a significant performance improvement by an average of 2.6 mAP when compared to its incorporation into the baseline method with the Faster-RCNN detector. It highlights the crucial role of generating reliable pseudo-labels and its impact on the model's ability to generalize to unseen data. Moreover, our proposed approach demonstrates its effectiveness by yielding the best results, outperforming the latest SOTAs under different labeling ratios. For example, the proposed TMR-RD method outperforms the Diverse-Learner \cite{DiverseLearner} by at least 0.67\% under 1\% labeling ratio.   
\vskip 5pt
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\noindent\textbf{Fully-labeled data setting}:
We also evaluate the performance of the proposed approach fully trained on supervised data to determine the extent of further improvement by incorporating additional unlabeled data. As shown in Table~\ref{table:sota}, the proposed TMR-RD approach using Faster-RCNN and Cascade-RCNN detectors surpasses the performance of their corresponding supervised models by 3\% and 4.5\%, respectively. The results indicate the effectiveness of the proposed approach with accessible large amounts of labeled and unlabeled data in addition to partially labeled datasets where labeled data is scarce.

\section{Conclusion} \label{sec5:conclusion}
In this paper, we propose a novel approach for training-based model refinement and representation disagreement in SSOD. This approach aims to address the limitations of the classical EMA strategy and improve the performance of Teacher-Student models. The proposed model refinement stage optimizes a lightweight set of scaling weights to adaptively refine Teacher-Student models during training, ensuring that overfitting and forgetting learned patterns from unlabeled data are avoided. This approach can be applied to existing SSOD methods to transfer reliable knowledge from the student to the teacher and prune noisy student weights. Additionally, we introduce a simple yet effective representation disagreement strategy to mitigate the consensus of Teacher-Student models that arises as the number of training epochs is increased. This strategy prevents the models from converging too early, encouraging the student model to learn complementary information.
Extensive experiments demonstrate noticeable performance improvement when working with different baseline detectors as well as the great potential of the proposed approach to integrating into existing SSOD methods.
% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 


%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
