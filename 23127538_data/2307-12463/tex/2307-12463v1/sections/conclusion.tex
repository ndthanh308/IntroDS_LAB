\section{Conclusion}

In this paper, we find for the first time that networks trained on distillation data are not calibratable and have poor encoding ability because the distillation process focuses on the classification task while discarding other semantically meaningful information. Our proposed methods, namely Masked Distillation Training during training and Masked Temperature Scaling after training, effectively alleviate these limitations and make the DDNNs recalibrated. 

In future work, we will look for better distillation methods that retain most of the source information and lead directly to calibratable networks. In addition, beyond calibrating DDNNs on in-distribution data, we will rethink DDNNs in terms of more general reliability, i.e., out-of-distribution detection, robust generalization, and adaptation, which are important properties for the safety of DDNN applications.
