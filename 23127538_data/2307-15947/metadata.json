{
  "title": "The effect of network topologies on fully decentralized learning: a preliminary investigation",
  "authors": [
    "Luigi Palmieri",
    "Lorenzo Valerio",
    "Chiara Boldrini",
    "Andrea Passarella"
  ],
  "submission_date": "2023-07-29T09:39:17+00:00",
  "revised_dates": [],
  "abstract": "In a decentralized machine learning system, data is typically partitioned among multiple devices or nodes, each of which trains a local model using its own data. These local models are then shared and combined to create a global model that can make accurate predictions on new data. In this paper, we start exploring the role of the network topology connecting nodes on the performance of a Machine Learning model trained through direct collaboration between nodes. We investigate how different types of topologies impact the \"spreading of knowledge\", i.e., the ability of nodes to incorporate in their local model the knowledge derived by learning patterns in data available in other nodes across the networks. Specifically, we highlight the different roles in this process of more or less connected nodes (hubs and leaves), as well as that of macroscopic network properties (primarily, degree distribution and modularity). Among others, we show that, while it is known that even weak connectivity among network components is sufficient for information spread, it may not be sufficient for knowledge spread. More intuitively, we also find that hubs have a more significant role than leaves in spreading knowledge, although this manifests itself not only for heavy-tailed distributions but also when \"hubs\" have only moderately more connections than leaves. Finally, we show that tightly knit communities severely hinder knowledge spread.",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CY"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15947",
  "pdf_url": "https://arxiv.org/pdf/2307.15947v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 5041313,
  "size_after_bytes": 87734
}