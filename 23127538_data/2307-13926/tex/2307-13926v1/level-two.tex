\section{Level-Two Fourier Growth}\label{sec:proof_of_level_two}

In this section, we prove \Cref{thm:boolean_bound_level_two} that $L_{1,2}(h)=O\pbra{d^{3/2}\log^3(n)}$. Similar to the proof of level-one bound \Cref{thm:boolean_bound_level_one}, we start with a $d$-round communication protocol $\tilde\Ccal$ over the Gaussian space as defined in \Cref{sec:fourier_via_martingale}.
Note that $\tilde\Ccal$ in turn comes from the original Boolean communication protocol $\Ccal$. Thus in the following we assume without loss of generality $d\le n$.

Given the discussion in \Cref{sec:fourier_weights_via_martingales}, to bound the second-level Fourier growth, one can attempt to bound the expected quadratic variation of the martingale that results from the protocol $\bar{\Ccal}$ directly, but similar to the case of level-one it is hard to leverage cancellations here to prove the bound we aim for. So, starting from $\tilde{\Ccal}$, we will define a communication protocol $\bar{\Ccal}$ that computes the same function as $\tilde\Ccal$, but satisfies some additional ``clean" property where it is easier to control the quadratic variation. This new protocol will differ from $\tilde\Ccal$ in two ways. Firstly, the protocol $\bar{\Ccal}$ will consist of additional ``cleanup steps'' where Alice and Bob reveal certain {\em quadratic forms} of their input. Secondly, the protocol $\bar\Ccal$ will send the real value of the quadratic form {\em with certain precision}. Note that this protocol will not involve sending real messages at all, instead, any potential real messages will be truncated to a few bits of precision and be sent as Boolean messages. 

We emphasize that the main difference in the protocol $\bar\Ccal$ from the corresponding level-one variant comes from the precision control, which is not needed there due to the fact that Gaussian distribution remains a (lower-dimensional) Gaussian under linear projections. For technical reasons we shall also need to analyze the martingale under a truncated Gaussian distribution, where all coordinates are  bounded in some large interval $[-T, T]$. This intuitively doesn't incur a noticeable difference on the distribution since it is highly unlikely that coordinates drawn from Gaussian distribution will be outside such intervals and recalling \Cref{rem:symmetric} and \Cref{prop:fwt-to-qv}, it still suffices to analyze the corresponding martingale under the truncated Gaussian distribution. 

We next define the notion of a $4$-wise clean protocol. 

\subsection[4-Wise Clean Protocols]{$4$-Wise Clean Protocols}

Consider an intermediate node in the protocol and let $X\subseteq \Rbb^n$ refer to the set of Alice's inputs reaching this node.
We denote by  $\Sbb^{n\times n-1}$ the set of all matrices in $\Rbb^{n\times n}$ with zero diagonal and unit norm (when viewed as $n^2$-dimensional vectors).
For a parameter $\lambda>0$, we say that the set $X$ is \emph{$4$-wise clean in a direction $a\in \Sbb^{n\times n-1}$} if 
\[
\E_{\lX\sim \gamma}\sbra{ \abra{\lX\tensor\lX - \sigma(X), a}^2 \mid\lX\in X} < \lambda,
\]
where we recall that $\comtwo(X)=\E_{\lX\sim \gamma}\sbra{\lX\tensor\lX\mid\lX\in X}$ is the level-two center of mass of $X$ under the Gaussian measure.
We say that the set $X$ is \emph{$4$-wise clean} if it is $4$-wise clean in \emph{every direction $a$}. 
Our new protocol will consist of the original protocol, interspersed by cleaning steps. Once Alice sends her bit as in the original protocol, she cleans $X$ by revealing $\abra{x\tensor x, a}$ with a few bits of precision while there exists direction $a \in \Sbb^{n\times n-1}$  such that $X$ not clean in direction $a$. Once $X$ becomes clean, Alice proceeds to the next round and Bob does an analogous cleanup. We now describe this formally.
 
\paragraph*{Communication with Finite Precision.}
Let positive integer $L$ be a precision parameter that we will use for truncation.
In our new communication protocol, we will send real numbers with precision $2^{-L}$.
This is formalized as the $\SendReal_L(z)$ function defined at $z\in \R$ as
$$
\SendReal_L(z)=\floorbra{z\cdot 2^{L}}/2^L.
$$

\paragraph*{Construct $\bar \Ccal$ from $\tilde \Ccal$.} 
As described before, $\bar\Ccal$ will consist of the original protocol along with extra steps where Alice or Bob reveal the (approximate) value of a quadratic form on their input. Consider an intermediate node of this new protocol at depth $t$. We always use the random variable $\supX{t}$ (resp., $\supY{t}$) to denote the set of inputs of Alice (resp., Bob) reaching the node. If Alice is revealing a quadratic form in this step, we use $\supa{t}$ to denote the matrix of the quadratic form revealed at this node, otherwise set $\supa{t}$ to be the all-zeroes matrix. We define $\supb{t}$ similarly for Bob. Throughout the protocol, we will always set $\supu{t}$ and $\supv{t}$ to denote $\comtwo(\supX{t})$ and $\comtwo(\supY{t})$ respectively.

Recall that $\lambda>0$ is the parameter for cleanup to be optimized later. Since we will now send real numbers (with certain precision) as bit-strings, their magnitudes should also be well controlled to guarantee bounded message length.
This is managed by a parameter $T>0$ and we will restrict the inputs to the parties in $\bar\Ccal$ to come from the box $[-T,T]^n$. Note that, by Gaussian concentration, $T=\Theta\pbra{\sqrt{\log(n)}}$ suffices. 
\begin{enumerate}
\item At the beginning, Alice receives an input $x\in[-T,T]^n$ and Bob receives an input $y\in[-T,T]^n$.
\item We initialize $t\gets0$, $\supX{0},\supY{0}\gets[-T,T]^n$, and $\supa{0},\supb{0}\gets0^{n\times n}$.
\item For each phase $i=1,2,\ldots,d$: suppose we are starting the cleanup for a node at depth $i$ in the original protocol $\tilde\Ccal$ and suppose we are at a node of depth $t$ in the new protocol $\bar\Ccal$. If it is Alice's turn to speak in $\tilde\Ccal$:
\begin{enumerate}
\item \textbf{Orthogonalization by revealing the correlation with Bob's center of mass.}\\
Alice begins by revealing the inner product of her input $x$ with Bob's current (signed) level-two center of mass $\Lambda\odot \supv{t}$. Since in the previous steps, she has already revealed the inner product with Bob's previous centers of mass, for technical reasons, we will only have Alice announce the inner product with the component of $\Lambda\odot \supv{t}$ that is orthogonal to the previous directions along which Alice announced the inner product. More formally, let $\supa{t+1}$ be the component of $ \Lambda\odot \supv{t}$ that is orthonormal to the span of the previous directions $\supa{\tau}$ for $\tau\le t$, i.e.,
$$\textstyle
\supa{t+1}=\unit\pbra{ \Lambda\odot \supv{t}-\sum_{\tau=1}^t\abra{ \Lambda \odot \supv{t},\supa{\tau}}\cdot\supa{\tau}}.
$$
Alice computes $\supcbar{t+1}\gets\SendReal_L\pbra{\abra{x\tensor x,\supa{t+1}}}$ and sends $\supcbar{t+1}$ to Bob. 
Set $\supb{t+1}\gets 0^{n\times n}$.
Increment $t$ by $1$ and go to step (b). 
\item \textbf{Original communication.}
Alice sends the bit $\supcbar{t+1}$ that she was supposed to send in $\tilde\Ccal$ based on previous messages and $x$. Set $\supa{t+1},\supb{t+1}\gets 0^{n\times n}$. 
Increment $t$ by 1 and go to step (c). 
\item \textbf{Cleanup steps.}
While there exists some direction $a\in\Sbb^{n\times n-1}$ orthogonal to previous directions, i.e., $\abra{a,\supa{\tau}}=0$ for all $\tau\le t$, and $\supX{t}$ is \emph{not $4$-wise clean} in direction $a$, Alice computes $\supcbar{t+1}\gets\SendReal_L\pbra{\abra{x\tensor x,a}}$ and sends $\supcbar{t+1}$ to Bob. 
Set $\supa{t+1}\gets a$ and $\supb{t+1}\gets0^{n\times n}$. Increment $t$ by 1. 
Repeat step (c) while $\supX{t}$ is not $4$-wise clean; otherwise, increment $i$ by 1 and go back to the for-loop in step 3 which starts a new phase.
\end{enumerate}
If it is Bob's turn to speak, we define everything similarly with the role of $x,\lA,\X,\U$ switched with $y,\lB,\Y,\V$.
\item Finally at the end of the protocol, the value $\bar\Ccal(x,y)$ is determined based on all the previous communication and the corresponding output it defines in $\tilde\Ccal$.
\end{enumerate}

\begin{remark}
Note that by construction, the non-zero matrices among $\supa{1},\supa{2}, \ldots $ form an orthonormal set when viewed as $n^2$-dimensional vectors (similarly for $\supb{1},\supb{2}, \ldots $) and moreover, their diagonals are zero. Lastly, $\supa{t}$ and $\supb{t}$ are known to both Alice and Bob as they are canonically determined by previous messages.
\end{remark}

We remark that the steps 3(a), 3(b), and 3(c) always occur in sequence for each party and we refer to such a sequence of steps as a \emph{phase} for that party. Note that there are at most $d$ phases. 
If a new phase starts at time $t$, then the current rectangle $\supX{t} \times \supY{t}$ is $4$-wise clean for both parties by construction. 

Now we formalize a few useful properties regarding the communication protocol $\bar\Ccal$. The first fact below follows since each $\supu{t}$ is an expectation of $\lx\tensor \lx$ over some distribution and $\lx\tensor \lx$ has zero diagonal.

\begin{fact}\label{fct:starting_point}
$\supu{0}=\supv{0}=0^{n\times n}$ and each $\supu{t},\supv{t}$ has zero diagonal.
\end{fact}

The following follows from tail bounds for the univariate standard normal distribution.

\begin{fact}\label{fct:gammastar}
Let $\gamma^*=\gamma(\supX{0})\cdot\gamma(\supY{0})$. Then $\gamma^*\ge1-O\pbra{n\cdot e^{-T^2/2}}$.
\end{fact}

The next fact says that when a node fixes a quadratic form with $2^{-L}$ precision, for any two inputs that reach this node, the quadratic forms differ by at most $2^{-L}$. 

\begin{fact}\label{fct:sendreal_error}
In step 3(a) and 3(c), any $x,x'\in \supX{t+1}$ satisfies $\abs{\abra{x\tensor x,\supa{t+1}}-\abra{x'\tensor x',\supa{t+1}}}<2^{-L}$.
Similarly any $y,y'\in \supY{t+1}$ satisfies $\abs{\abra{y\tensor y,\supb{t+1}}-\abra{y'\tensor y',\supb{t+1}}}<2^{-L}$.
\end{fact}

The next claim bounds the maximum attainable norms for Alice and Bob's level-two center of masses at any point in the protocol. This uses the fact that the inputs come from the truncated Gaussian distribution.

\begin{claim}\label{clm:frob_norm_ub}
$\frob{\supu{t}}=\frob{ \Lambda\odot \supu{t}}<nT$ and $\frob{\supv{t}}=\frob{ \Lambda\odot \supv{t}}<nT$ for all possible $t$ and $\supu{t},\supv{t}$ throughout the communication.
\end{claim}
\begin{proof}
Since $\Lambda$ is a matrix with zero diagonal and $\binpm$ entries off diagonal and $\supu{t}$ also has zero diagonal, $\frob{\supu{t}}=\frob{ \Lambda\odot \supu{t}}$.
In addition, since $\supX{t}\subseteq \supX{0}=[-T,T]^n$, we have
$$
\frob{\supu{t}}
\le\E_{\lx\sim\gamma}\sbra{\frob{\pbra{\lx\tensor\lx}}\mid\lx\in \supX{t}}
\le\sqrt{(n^2-n)\cdot T^2}<nT.
$$
A similar analysis works for $\supv{t}$.
\end{proof}

The next claim gives a bound on the length of any message in the protocol $\bar \Ccal$.

\begin{claim}\label{clm:short_messages}
For any $x\in \supX{0}$ and $y\in \supY{0}$, any message in $\bar\Ccal(x,y)$ consists of at most $L + \log(Tn)$ many bits.
\end{claim}
\begin{proof}
Assume without loss of generality it is Alice's turn to speak. On step 3(b) she sends one bits. On steps 3(a) and 3(c), she computes $\SendReal_L(\sabra{x\tensor x,a})$ for some  $a\in \Sbb^{n\times n-1}$ and send the result. Since
$$
\abs{\abra{x\tensor x,a}}\le\frob{x\tensor x}\cdot \frob{a}\le\sqrt{(n^2-n)\cdot T^2}<nT,
$$
and the message is a multiple of $2^{-L}$
that means $\SendReal_L$ yields a message with $L+ \log(nT)$ many bits.
\end{proof}

The last claim bounds the maximum depth of the new protocol $\bar \Ccal$.

\begin{claim}\label{clm:finite_steps}
Let $\ell$ be an arbitrary leaf of the protocol $\bar\Ccal$ and $D(\ell)$ be its depth.
Then $D(\ell)\le2n^2$.
Moreover, along this path there are at most $n^2-n$ many non-zero $\supa{t}$ and at most $n^2-n$ many non-zero $\supb{t}$ for $t\in\{1,\ldots,D(\ell)\}$.
\end{claim}
\begin{proof}
We count the number of communication steps separately:
\begin{itemize}
\item \textbf{Steps 3(a) and 3(b).} Steps 3(a) and 3(b) occur once in every phase, thus at most $d$ times.
\item \textbf{Step 3(c).} For Alice, each time she communicates at step 3(c), the direction $a\in\Sbb^{n\times n-1}$ is non-zero and orthogonal to all previous $\supa{t}$'s. Since the dimension of $\Sbb^{n\times n-1}$ is $n^2-n$, this happens at most $n^2-n$ times. Similar argument works for Bob.
\end{itemize}
Thus in total we have at most $2(n^2-n)+2d \le 2n^2$ steps.
\end{proof}


We will eventually show that, with suitable choice of $\lambda,T,L$, typically $D(\ell)$ is at most $d\cdot\polylog(n)$.

\subsection{Bounding the Expected Quadratic Variation}\label{sec:expected_quadratic_variation}

Consider the martingale process defined in \Cref{eqn:def-martingale} from a random walk on the protocol tree generated by $\bar\Ccal$ where the inputs $\lx, \ly$ are sampled from $\gamma_n$ conditioned on being in the bounded cube $[-T,T]^n$. Recall that \Cref{prop:vec-martingale} still holds (see \Cref{rem:martingale}).

Formally, at time $t$ the process is defined by
$$
\supZ{t}_2=\abra{\supu{t},\eta\odot\supv{t}},
$$
where we recall that $\supu{t}=\comtwo(\supX{t})$ and $\supv{t}=\comtwo(\supY{t)})$ and $\eta$ is a fixed sign matrix with a zero diagonal.
The martingale process stops once it hits a leaf of $\bar\Ccal$.
Let $\D$ denote the (stopping) time when this happens.
Note that $\E[\D]$ is exactly the expected depth of the protocol $\bar\Ccal$.

In light of \Cref{rem:symmetric} and \Cref{prop:fwt-to-qv}, to prove \Cref{thm:boolean_bound_level_two}, it suffices to prove the following.
\begin{lemma}\label{lem:qv-level-two}
$\E\sbra{\sum_{t=1}^{\D} \pbra{\Delta\supZ{t}_2}^2} = O\pbra{d^3\log^6(n)}.$
\end{lemma}

\Cref{lem:qv-level-two} is proved in three steps.
We first show that essentially the only change in the value of the martingale is the orthogonalization step 3(a).
The reason is the same as the level-one bound: Alice's messages sent in step 3(b) and 3(c) are always near-orthogonal to Bob's current level-two center of mass, thus they do not change the value of the martingale $\supZ{t}_2$ much.
Moreover, by level-two analog of \Cref{eqn:overview}, since Alice's current node was clean just before Alice sent the message in step 3(a), the expected change $\E\sbra{\pbra{\Delta\supZ{t+1}_2}^2}$ can be bounded in terms of the squared norm of the change that occurred in $\supu{t}$ (or $\supv{t}$) between the current round and the last round where Alice was in step 3(a). Similar argument works for Bob.

Formally, this is encapsulated by the next lemma for which we need some additional definitions. Let $(\supF{t})_t$ denote the natural filtration induced by the random walk on the generalized protocol tree with respect to which $\supZ{t}_2$ is a Doob martingale and also $\supu{t}, \supv{t}$ form vector-valued martingales (recall \Cref{prop:vec-martingale}). Note that $\supF{t}$ fixes all the rectangles encountered during times $0,\ldots, t$ and thus for $\tau \le t$, the random variables $\supu{\tau},\supv{\tau},\supZ{\tau}_2$ are determined, in particular, they are $\supF{t}$-measurable. Recalling that $\lambda$ is the cleanup parameter to be optimized later, we then have the following. Below we assume without any loss of generality that Alice speaks first and, in particular, we note that Alice speaks in step 3(a) for the first time at time zero when both Alice and Bob's center of masses are at zero: $\supu{0}=\supv{0}=0$. 

\begin{lemma}[Step Size]\label{lem:step_size_square_level_two}
    Let $0= \btau_1 < \btau_2 < \cdots \le \D$ be a sequence of stopping times with $\btau_m$ being the index of the round where Alice speaks in step 3(a) for the $m^\text{th}$ time or $\D$ if there is no such round. 
    Then, for any integer $m \ge 2$, 
	$$
	\E\sbra{\pbra{\Delta\supZ{\btau_m+1}_2}^2 \mid \supF{\btau_m}}  \le \lambda \cdot \vabs{\supv{\btau_m} - \supv{\btau_{m-1}}}^2+ 16n^7T^3 \cdot  2^{-L}.
	$$
	and moreover, for any $t \in \N$, we have that 
	$$
	\E\sbra{\pbra{\Delta\supZ{t+1}_2}^2\mid\supF{t}, \btau_{m-1} < t <\btau_{m}, \text{Alice speaks at time }t}\le 4 n^6T^2 \cdot 2^{-2L}
	$$
 A similar statement also holds if Bob speaks where $\V$ is replaced by $\U$ and the sequence $(\btau_m)$ is replaced by $(\btau'_m)$ where $\btau'_m$ is the index of the round where Bob speaks in step 3(a) for the $m^\text{th}$ time or $\D$ if there is no such round. 
\end{lemma}

We indeed see that, if $L=\Omega(\log(n))$ and $T=O(\sqrt{\log(n)})$, then $\poly(T,n)\cdot 2^{-L} = o(1)$, and steps~3(b) and~3(c) do not contribute much to the quadratic variation and only the steps 3(a) do.  Also, since the first time Alice and Bob speak, they start in step 3(a), we also note that $\supu{\btau_1}$ and $\supv{\btau'_1}$ are their initial centers of mass which are both zero.  

We shall prove the above lemma in \Cref{sec:step_size_leve_two} and continue with the bound on the quadratic variation here.
Using the bounds on the step sizes from \Cref{lem:step_size_square_level_two},
\begin{align*}
\E\sbra{\sum_{t=1}^{\D} \pbra{\Delta\supZ{t}_2}^2} 
&\le\lambda \cdot\E\sbra{\sum_{m\ge 2} \vabs{\V^{(\btau_m)}-\V^{(\btau_{m-1})}}^2+\vabs{\U^{(\btau'_m)}-\U^{(\btau'_{m-1})}}^2}+
16n^7T^3 \cdot  2^{-L}
\cdot\E[\D]\\
&\le\lambda \cdot\E\sbra{\sum_{m \ge 2} \vabs{\V^{(\btau_m)}-\V^{(\btau_{m-1})}}^2+\vabs{\U^{(\btau'_m)}-\U^{(\btau'_{m-1})}}^2}+16n^7T^3 \cdot  2^{-L}
\cdot2n^2.
\tag{by \Cref{clm:finite_steps}}
\end{align*}
On the other hand, using the orthogonality of vector-valued martingale differences from  \Cref{eqn:martingale-orthogonality-vec},
\begin{align*}
	\E\sbra{\sum_{m \ge 2} \vabs{\V^{(\btau_m)}-\V^{(\btau_{m-1})}}^2} = \E\sbra{\vabs{\V^{(\D)}}^2}.
\end{align*}
A similar statement holds for $(\supu{t})$ as well. Therefore, 
\begin{align}\label{eqn:qv-upper-bound-level-two}
\E\sbra{\sum_{t=1}^{\D} \pbra{\Delta\supZ{t}_2}^2} \le\lambda \cdot\pbra{\E\sbra{\frob{\U^{(\D)}}^2}+\E\sbra{\frob{\V^{(\D)}}^2}}+64n^9T^3 \cdot  2^{-L}.
\end{align}

Then in \Cref{sec:to_depth} we will apply level-two inequalities (see \Cref{thm:level_k_ineq}) to convert the bounding $\E\sbra{\frob{\U^{(\D)}}^2+\frob{\V^{(\D)}}^2}$ into bounding the second moment $\E[\D^2]$. This reduction is formalized as \Cref{lem:to_depth} below and its proof is similar to \cite[Claim 1]{GRT21}.

For each leaf $\ell$, let $\gamma(\ell)=\gamma(\supX{D(\ell)})\cdot\gamma(\supY{D(\ell)})$ be the Gaussian measure of the rectangle at $\ell$. 
Recall $\gamma^*=\gamma(\supX{0})\times\gamma(\supY{0})$.
\begin{lemma}\label{lem:to_depth}
$\E\sbra{\frob{\supu{\D}}^2+\frob{\supv{\D}}^2}\le O\pbra{\frac1{\gamma^*}+L^2\E[\D^2]}$.
\end{lemma}

Finally, in \Cref{sec:depth_tail_bounds}, we bound the second moment $\E[\D^2]$ for a suitable choice of parameters.
\begin{lemma}\label{lem:second_moment} It holds that
$\E[\D^2]=O(d^2)$ and $\gamma^*\ge\frac{3}{4}$ for $L=\Theta(\log(n))$, $T=\Theta(\sqrt{\log(n)})$, and $\lambda=\Theta(d\log^4(n))$. 
\end{lemma}

Given \Cref{lem:to_depth,lem:second_moment},the proof of \Cref{lem:qv-level-two} naturally follows.
\begin{proof}[Proof of \Cref{lem:qv-level-two}]
With the parameters chosen in \Cref{lem:second_moment}, we have
\begin{align*}
\E\sbra{\sum_{t=1}^{\D} \pbra{\Delta\supZ{t}_2}^2} 
&\le O(d\log^4(n))\cdot\pbra{\E\sbra{\frob{\U^{(\D)}}^2}+\E\sbra{\frob{\V^{(\D)}}^2}}+1
\tag{by \Cref{eqn:qv-upper-bound-level-two}}\\
&\le O(d\log^4(n))\cdot\pbra{1+\log^2(n)\cdot\E[\D^2]}+1
\tag{by \Cref{lem:to_depth}}\\
&\le O(d\log^4(n))\cdot\pbra{1+\log^2(n)\cdot d^2}+1
\tag{by \Cref{lem:second_moment}}\\
&=O(d^3\log^6(n)).
\tag*{\qedhere}
\end{align*}
\end{proof}

\begin{remark}
Note that our proof for level-two Fourier growth actually holds for a slightly more general setting, where Alice and Bob are allowed to send $O(L)=O(\log(n))$ bits during each original communication round.
This can be viewed as balancing the length of the messages in step 3(b) with step 3(a) and step 3(c).

Since one can always convert a $d$-round $1$-bit communication protocol into a $\frac{2d}{\log\log(n)}$-round $\log(n)$-bit communication protocol, we obtain a slightly better level-two Fourier growth bound of 
$$
O\pbra{\frac{d^{3/2}\log^3(n)}{\pbra{\log\log(n)}^{3/2}}}.
$$ 
The conversion is done by Alice (resp., Bob) enumerating the next $\log\log(n)/2$ bits from Bob (resp., Alice), and providing the corresponding $\log\log(n)/2$ bits responses for each possibility.

It is also possible to improve the $\log^3(n)$ factor to $\log^2(n)$ by varying the cleanup parameter $\lambda$ with depth.
For example, for depth in the interval $[4rd, 4(r+1)d]$, one could pick $\lambda_r = \Theta( d \cdot \log^2(n) \cdot r^2)$.
Since our focus is mostly on improving the polynomial dependence in $d$ where there is still room for improvement, we do not make an effort here to improve the polylog terms.
\end{remark}

\subsection[Bounds on Step Sizes]{Bounds on Step Sizes (Proof of \Cref{lem:step_size_square_level_two})}\label{sec:step_size_leve_two}

Let us abbreviate $\btau = \btau_m$ and note that at time $\btau$ a new phase starts for Alice. 
By construction, this means that the current rectangle $\supX{\btau} \times \supY{\btau}$ determined by $\supF{\btau}$ is $4$-wise clean with parameter $\lambda$, and since Alice is in step 3(a) at the start of a new phase, $\supa{\btau+1}$ is chosen to be the (normalized) component of $\Lambda\odot \V^{(\btau)}$ that is orthogonal to previous directions $\supa{1}, \ldots, \supa{\btau}$. 

For each $r=1,\ldots,\btau+1$, let $\balpha^{(r)}:= \abra{\Lambda\odot \V^{(\btau)},\la^{(r)}}$ be the length of $\Lambda\odot \V^{(\btau)}$ along direction $\la^{(r)}$.
Each $\balpha^{(r)}$ is $\Fcal^{(\btau)}$-measurable (i.e., it is determined by $\Fcal^{(\btau)}$) and $\eta\odot\supv{\btau}=\sum_{r\le\btau+1}\balpha^{(r)}\cdot\supa{r}$. 
In this case, we have
\begin{align}\label{eq:step_size_level_two}
\E\sbra{\pbra{\Delta\lZ^{(\btau+1)}_2}^2\mid \Fcal^{(\btau)}}&=\E\sbra{\abra{\U^{(\btau+1)}-\U^{(\btau)}, \Lambda\odot \V^{(\btau)}}^2\mid \Fcal^{(\btau)}}\notag\\
&=\E\sbra{\pbra{\sum_{r=1}^{\btau+1}\balpha^{(r)}\cdot\abra{\supu{\btau+1}-\supu{\btau},\supa{r}}}^2\mid \Fcal^{(\btau)}}.
\end{align}

Similar to the level-one proof, the components of $\supu{\btau+1}$ and $\supu{\btau}$ are roughly the same along any of the previous directions $\supa{1},\ldots,\supa{\btau}$ and so they almost cancel out and the major quantity is in the direction $\supa{\btau+1}$.
This follows since, in all the previous steps $r\le\btau$, Alice has already fixed $\abra{x\tensor x,\supa{r}}$ with precision $2^{-L}$.
This implies that for any $\supX{\btau}$ and $\supX{\btau+1}$ that are determined by $\supF{\btau+1}$, the inner product with all the previous $\supa{1},\ldots,\supa{\btau}$ is fixed with precision $2^{-L}$ over the choice of $x$.
Formally, by \Cref{fct:sendreal_error}, we have that for any $x\in\supX{\btau}$ and $x'\in\supX{\btau+1}$, it holds that $\abs{\abra{x\tensor x,\supa{r}}-\abra{x'\tensor x',\supa{r}}}\le2^{-L}$ for all $r\le\btau$.
In particular, since $\supu{\btau}=\comtwo(\supX{\btau})$ and $\supu{\btau+1}=\comtwo(\supX{\btau+1})$ are the corresponding centers of mass, we have that
\begin{equation}\label{eq:step_size_level_two_error_term}
\abs{\abra{\supu{\btau+1}-\supu{\btau},\supa{r}}}\le2^{-L}
\quad\text{for all $r\le\btau$.}
\end{equation}
On the other hand, 
since $\supX{\btau+1}\subseteq\supX{\btau}\subseteq\supX{0}=[-T,T]^n$ and $\supa{\btau+1}$ is a unit direction, we have
\begin{equation}\label{eq:step_size_level_two_frob_bound}
\abs{\abra{\supu{\btau+1}-\supu{\btau},\supa{\btau+1}}}
\le\vabs{\supu{\btau+1}-\supu{\btau}}
\le2nT.
\end{equation}
Similarly, 
noting that $\eta$ is a sign matrix, we can bound
\begin{equation}\label{eq:step_size_level_two_beta}
\abs{\balpha^{(r)}}
=\abs{\abra{\eta\odot\supv{\btau},\supa{r}}}
\le\vabs{\eta\odot\supv{\btau}}
\le\vabs{\supv{\btau}}
\le nT
\quad\text{for all $r\le\btau+1$.}
\end{equation}
Expanding the square in \Cref{eq:step_size_level_two} and plugging these estimates to each one of the $(\btau+1)^2$ terms gives
\begin{align}
\E\sbra{\pbra{\Delta\lZ^{(\btau+1)}_2}^2\mid \Fcal^{(\btau)}}
&\le\E\sbra{\pbra{\balpha^{(\btau+1)}}^2\abra{\supu{\btau+1}-\supu{\btau},\supa{\btau+1}}^2 
+ ((\btau+1)^2-1)\cdot  \tfrac{2(nT)^3}{2^{L}}
\mid \Fcal^{(\btau)}}\notag
\\
&\le\pbra{\balpha^{(\btau+1)}}^2\E\sbra{\abra{\supu{\btau+1}-\supu{\btau},\supa{\btau+1}}^2\mid\supF{\btau}}+12n^7T^3 \cdot  2^{-L},
\label{eq:step_size_level_two_no_error_term}
\end{align}
where the second line follows from \Cref{clm:finite_steps}.

We now bound the term outside the expectation by the change in the center of mass $\supv{\cdot}$ and the term inside the expectation by the fact that the set is $4$-wise clean.

\paragraph*{Term Outside the Expectation.}
Recall that $\supa{\btau+1}$ is chosen to be the (normalized) component of $\eta\odot\supv{\btau}$ that is orthogonal to the span of $\supa{1},\ldots,\supa{\btau}$.
Since $\eta\odot\supv{\btau_m-1}$ is in the span of $\supa{1},\ldots,\supa{\btau_{m-1}+1}$ and $\btau_{m-1}+1\le\btau=\btau_m$, it is orthogonal to $\supa{\btau+1}$. Hence
$$
\balpha^{(\btau+1)}=\abra{\eta\odot\supv{\btau},\supa{\btau+1}}=\abra{\eta\odot\pbra{\supv{\btau}-\supv{\btau_{m-1}}},\supa{\btau+1}}.
$$
Since $\supa{\btau+1}$ is a unit direction and $\eta$ is a sign matrix, this implies that
\begin{equation}\label{eq:level_two_term_outside}
\pbra{\balpha^{(\btau+1)}}^2\le\vabs{\supv{\btau}-\supv{\btau_{m-1}}}^2.
\end{equation}

\paragraph*{Term Inside the Expectation.}
Recall that Alice is in step 3(a), she sends $\abra{x\tensor x,\supa{\btau+1}}$ with precision $2^{-L}$ at time $\btau$, and thus the same inner product with $\supa{\btau+1}$ is fixed with precision $2^{-L}$ for every point in $\supX{\btau+1}$ determined by $\supF{\btau+1}$.
Thus
\begin{align}
\abra{\supu{\btau+1},\supa{\btau+1}}^2
&=\pbra{\E_{\lx\sim \gamma}\sbra{\abra{\lx\tensor\lx,\la^{(\btau+1)}}\mid \lx\in \X^{(\btau+1)}}}^2\notag\\
&=\pbra{\abra{x\tensor x,\la^{(\btau+1)}}+\E_{\lx\sim \gamma}\sbra{\eps_{\lx}\mid \lx\in \X^{(\btau+1)}}}^2
\tag{$|\eps_{\lx}|\le2^{-L}$ is the truncation error by \Cref{fct:sendreal_error}}\\
&\le\abra{x\tensor x,\la^{(\btau+1)}}^2+2^{-2L}+2^{1-L}\cdot\abs{\abra{x\tensor x,\la^{(\btau+1)}}}\notag\\
&\le\abra{x\tensor x,\la^{(\btau+1)}}^2+nT\cdot2^{2-L},
\label{eq:level_two_term_inside}
\end{align}
where the last line follows from $\abs{\abra{x\tensor x,\la^{(\btau+1)}}}\le\vabs{x\tensor x}$ and $x\in\supX{0}=[-T,T]^n$.

\paragraph*{Final Bound.}

Since $(\supu{r})_r$ is a matrix-valued martingale and thus $\E\sbra{\supu{\btau+1}\mid\supF{\btau}}=\supu{\btau}$, we have
$$
\E\sbra{\abra{\supu{\btau+1}-\supu{\btau},\supa{\btau+1}}^2\mid\supF{\btau}}
=\E\sbra{\abra{\supu{\btau+1},\supa{\btau+1}}^2-\abra{\supu{\btau},\supa{\btau+1}}^2\mid\supF{\btau}}
$$
Then by \Cref{eq:level_two_term_inside}, we upper bound the right hand side by
\begin{align*}
nT\cdot2^{2-L}+\E_{\lx\sim\gamma}\sbra{\abra{\lx\tensor\lx,\supa{\btau+1}}^2-\abra{\supu{\btau},\supa{\btau+1}}^2\mid\supF{\btau}}.
\end{align*}
Since $\supX{\btau}$ is $4$-wise clean with parameter $\lambda$, it can be bounded by $nT\cdot2^{2-L}+\lambda$:
\begin{equation}\label{eq:level_two_exp_inside}
\E\sbra{\abra{\supu{\btau+1}-\supu{\btau},\supa{\btau+1}}^2\mid\supF{\btau}}
\le nT\cdot2^{2-L}+\lambda
\end{equation}
Putting everything together, we have
\begin{align*}
\E\sbra{\pbra{\Delta\lZ^{(\btau+1)}_2}^2\mid \Fcal^{(\btau)}}
&\le\pbra{\balpha^{(\btau+1)}}^2\E\sbra{\abra{\supu{\btau+1}-\supu{\btau},\supa{\btau+1}}^2\mid\supF{\btau}}+
12n^7T^3 \cdot  2^{-L}
\tag{by \Cref{eq:step_size_level_two_no_error_term}}\\
&\le\pbra{\balpha^{(\btau+1)}}^2\cdot\pbra{nT\cdot2^{2-L}+\lambda}+12n^7T^3 \cdot  2^{-L}
\tag{by \Cref{eq:level_two_exp_inside}}\\
&\le\lambda\cdot\pbra{\balpha^{(\btau+1)}}^2+n^3T^3 \cdot 2^{2-L}+12n^7T^3 \cdot  2^{-L}
\tag{by \Cref{eq:step_size_level_two_beta}}\\
&\le\lambda\cdot\vabs{\supv{\btau}-\supv{\btau_{m-1}}}^2+n^3T^3 \cdot 2^{2-L}+12n^7T^3 \cdot  2^{-L}
\tag{by \Cref{eq:level_two_term_outside}}\\
&\le\lambda\cdot\vabs{\supv{\btau}-\supv{\btau_{m-1}}}^2+16n^7T^3 \cdot  2^{-L}.
\end{align*}
This completes the proof of the first statement in the lemma.

For the moreover part, let us condition on the event $\btau_{m-1}<t<\btau_m$ where Alice speaks at time $t$. 
Note that such $t$ must all lie in the same phase of the protocol where Alice is the only one speaking.
So, Bob's center of mass does not change from the time $\btau_{m-1}$ till $t$, i.e., $\supv{t+1}=\supv{\btau_{m-1}}$.
Thus we have 
\begin{equation}\label{eq:level_two_moreover}
\Delta\supZ{t+1}_2=\abra{\supu{t+1}-\supu{t},\eta\odot\supv{\btau_{m-1}}}.
\end{equation}
Analogous to \Cref{eq:step_size_level_two_error_term}, the component of Alice's center of mass along the previous directions are fixed with precision $2^{-L}$.
Thus by \Cref{fct:sendreal_error}, 
\begin{equation}\label{eq:level_two_moreover_error}
\abs{\abra{\supu{t+1}-\supu{t},\supa{r}}}\le2^{-L}
\quad\text{for all $r\le t$.}
\end{equation}
Furthermore, by construction, $\eta\odot\supv{\btau_{m-1}}$ lies in the space spanned by $\supa{1},\ldots,\supa{\btau_{m-1}+1}$.
Note that $\btau_{m-1}+1\le t$.
Similar to the previous analysis, for each $r=1,\ldots,t$, let $\balpha^{(r)}:=\abra{\eta\odot\supv{t},\supa{r}}$ be the length of $\eta\odot\supv{t}$ along direction $\supa{r}$.
Then \Cref{eq:step_size_level_two_beta} also holds here.
Therefore
\begin{align*}
\abs{\Delta\supZ{t+1}_2}
&=\abs{\sum_{r=1}^t\balpha^{(r)}\cdot\abra{\supu{t+1}-\supu{t},\supa{r}}}
\tag{by \Cref{eq:level_two_moreover}}\\
&\le\sum_{r=1}^t\abs{\balpha^{(r)}}\cdot\abs{\abra{\supu{t+1}-\supu{t},\supa{r}}}
\le\sum_{r=1}^tnT\cdot2^{-L}
\tag{by \Cref{eq:step_size_level_two_beta} and \Cref{eq:level_two_moreover_error}}\\
&\le 2n^3T\cdot2^{-L}.
\tag{by \Cref{clm:finite_steps}}
\end{align*}

\subsection[Conversion to Second Moment Bounds of the Depth]{Conversion to Second Moment Bounds of the Depth (Proof of \Cref{lem:to_depth})}\label{sec:to_depth}

Recall $\gamma^*=\gamma(\supX{0})\times\gamma(\supY{0})$ and $\gamma(\ell)=\gamma(\supX{D(\ell}))\cdot\gamma(\supY{D(\ell)})$ for each leaf $\ell$.
The goal of this subsection is to prove \Cref{lem:to_depth}.

We first note the following basic fact.

\begin{fact}\label{fct:path_probability}
$\sum_\ell\gamma(\ell)=\gamma^*$ and
$$
\Pr_{\lx\sim \supX{0},\ly\sim \supY{0}}\sbra{\bar\Ccal(\lx,\ly)\text{ reaches leaf }\ell}=\gamma(\ell)/\gamma^*.
$$
\end{fact}

Now we apply \Cref{thm:level_k_ineq} with $k=2$ to relate the LHS of \Cref{lem:to_depth} with an entropy-type bound.

\begin{lemma}\label{lem:frob_to_path_prob}
$\E\sbra{\frob{\supu{\D}}^2+\frob{\supv{\D}}^2}\le \frac{4e^2}{\gamma^*}\sum_\ell\gamma(\ell)\cdot\ln^2\pbra{\frac{e}{\gamma(\ell)}}$.
\end{lemma}
\begin{proof}
Let $\ell$ be a fixed leaf and $D=D(\ell)$ be its depth.
Note that this also fixes the rectangle $X^{(D)}\times Y^{(D)}$ and thus the centers of mass $u^{(D)},v^{(D)}$.
Define the indicator function $\indicator_\ell\colon\Rbb^{2n}\to\bin$ by
$$
\indicator_\ell(x,y)=\begin{cases}
1 & (x,y)\in X^{(D)}\times Y^{(D)},\\
0 & \text{otherwise.}
\end{cases}
$$
Then we have
\begin{align*}
&\phantom{\le}\frob{u^{(D)}}^2+\frob{v^{(D)}}^2\\
&=\frob{\E_{\lx\sim\gamma}\sbra{\lx\tensor \lx\mid \lx\in X^{(D)}}}^2+\frob{\E_{\ly\sim\gamma}\sbra{\ly\tensor \ly\mid \ly\in Y^{(D)}}}^2\\
&=\sum_{\substack{i,j=1\\i\neq j}}^n\pbra{\E_{\lx\sim\gamma}\sbra{\lx_i\lx_j\mid \lx\in X^{(D)}}}^2+\sum_{\substack{i,j=1\\i\neq j}}^n\pbra{\E_{\ly\sim\gamma}\sbra{\ly_i\ly_j\mid \ly\in Y^{(D)}}}^2\\
&=\sum_{\substack{i,j=1\\i\neq j}}^n\pbra{\E_{\lx,\ly\sim\gamma}\sbra{\lx_i\lx_j\mid(\lx,\ly)\in X^{(D)}\times Y^{(D)}}}^2+\sum_{\substack{i,j=1\\i\neq j}}^n\pbra{\E_{\lx,\ly\sim\gamma}\sbra{\ly_i\ly_j\mid(\lx,\ly)\in X^{(D)}\times Y^{(D)}}}^2\\
&=\frac2{\gamma(\ell)^2}\pbra{\sum_{S\in\binom{[n]}2}\pbra{\E_{\lx\sim\gamma,\ly\sim\gamma}\sbra{\indicator_\ell(\lx,\ly)\lx_S}}^2+\sum_{S\in\binom{[n]}2}\pbra{\E_{\lx\sim\gamma,\ly\sim\gamma}\sbra{\indicator_\ell(\lx,\ly)\ly_S}}^2}\\
&\le\frac2{\gamma(\ell)^2}\sum_{S\in\binom{[2n]}2}\pbra{\E_{\lw\sim\gamma_n\times\gamma_n}\sbra{\indicator_\ell(\lw)\lw_S}}^2\\
&\le\frac2{\gamma(\ell)^2}\cdot 2e^2\gamma(\ell)^2\cdot\ln^2\pbra{\frac{e}{\gamma(\ell)}}
\tag{by \Cref{thm:level_k_ineq}}\\
&=4e^2\cdot\ln^2\pbra{\frac{e}{\gamma(\ell)}}.
\end{align*}
Therefore taking expectation over a random $\ell$, by \Cref{fct:path_probability}, we have
\begin{equation*}
\E\sbra{\frob{\supu{\D}}^2+\frob{\supv{\D}}^2}
\le 4e^2\cdot\E_{\bell}\sbra{\ln^2\pbra{\frac{e}{\gamma(\bell)}}}
=\frac{4e^2}{\gamma^*}\sum_\ell\gamma(\ell)\cdot\ln^2\pbra{\frac{e}{\gamma(\ell)}}.
\tag*{\qedhere}
\end{equation*}
\end{proof}

Now in the next lemma, we bound the right hand side of \Cref{lem:frob_to_path_prob} in terms of the second moment of the depth, which immediately proves \Cref{lem:to_depth}.
\begin{lemma}\label{lem:path_prob_to_depth}
Assume that $Tn \le  2^L$. Then,
$\sum_\ell\gamma(\ell)\cdot\ln^2\pbra{e/{\gamma(\ell)}}\le O(1+\gamma^*\cdot L^2\E[\D^2])$.
\end{lemma}
\begin{proof}
By \Cref{clm:short_messages}, and the assumption $Tn \le 2^{L}$ each message is of length at most $L+\log(Tn)\le 2L$.
We divide $\ell$ into two cases based on $\gamma(\ell)$:
\begin{align*}
&\sum_{\ell:\gamma(\ell)<2^{-3L\cdot D(\ell)}}\gamma(\ell)\cdot\ln^2\pbra{\frac{e}{\gamma(\ell)}}\\
&\le\sum_{\ell:\gamma(\ell)<2^{-3L\cdot D(\ell)}}2^{-3L\cdot D(\ell)}\cdot\ln^2\pbra{e \cdot 2^{3L\cdot D(\ell)}}
\tag{$x\ln^2(e/x)$ is increasing when $0\le x\le 0.2$}\\
&\le\sum_{t=1}^{\infty}2^{-3L\cdot t}\cdot 2(9L^2t^2+1)\cdot\abs{\cbra{\ell:D(\ell)=t}} 
\tag{since $\ln^2(ab) \le 2\ln^2(a) + 2\ln^2(b)$}\\
&\le\sum_{t=1}^{\infty}2^{-3L\cdot t}\cdot 2(9L^2t^2+1)\cdot2^{(2L)\cdot t}
\tag{each message is of length $\le 2L$}\\
&\le\sum_{t=1}^{\infty}2(9L^2t^2+1)\cdot2^{-Lt}=O(1)
\tag{since $L\ge2$}
\end{align*}
and
\begin{align*}
\sum_{\ell:\gamma(\ell)\ge2^{-3L\cdot D(\ell)}}\gamma(\ell)\cdot\ln^2\pbra{\frac{e}{\gamma(\ell)}}
&\le\sum_{\ell:\gamma(\ell)\ge2^{-3L\cdot D(\ell)}}\gamma(\ell)\cdot\ln^2\pbra{e \cdot 2^{3L\cdot D(\ell)}}\\
&\le 2 \cdot 9L^2 \sum_\ell\gamma(\ell) D(\ell)^2 + 2\sum_\ell\gamma(\ell)\\
&=18L^2\gamma^*\cdot\E_{\bell}\sbra{D(\bell)^2} + 2\\
&=18L^2\gamma^*\cdot\E\sbra{\D^2} + 2.
\end{align*}
Adding up the two estimates above gives the desired bound.
\end{proof}

\subsection[Second Moment Bounds for the Depth]{Second Moment Bounds for the Depth (Proof of \Cref{lem:second_moment})}\label{sec:depth_tail_bounds}

The final ingredient is an estimate for the second moment $\E[\D^2]$.
This subsection is devoted to this goal and proving \Cref{lem:second_moment}.

For messages $\ell'=(\supcbar{1},\ldots,\supcbar{t})$, we define $\gamma(\ell')=\gamma(\supX{t})\cdot\gamma(\supY{t})$ where $\supX{t},\supY{t}$ is defined by the protocol using the messages $\ell'$.
Note that this definition is consistent with $\gamma(\ell)$ from \Cref{sec:to_depth} for a leaf $\ell$.

\begin{lemma}\label{lem:depth_tail_bound}
There exists a universal constant $\alpha>0$ such that the following holds.
Let $0\le d_1<d_2$ be two arbitrary integers with $d_2-d_1\ge2d+1$.
Let $\ell^*=(\supcbar{1},\ldots,\supcbar{d_1})$ be arbitrary messages of the first $d_1$ communication steps.
Assume $2^L\ge8n^4T^2$. Then
$$
\Pr\sbra{\D\ge d_2\mid\ell^*}\le\frac{\alpha\cdot d_2^2L^2}{\lambda\cdot(d_2-d_1-2d)}+\frac14\cdot\frac{2^{-3L\cdot d_1}}{\gamma(\ell^*)}.
$$
\end{lemma}
\begin{proof}
Let $\lx,\ly$ be sampled from $\gamma$ conditioned on $\lx\in\supX{0},\ly\in\supY{0}$.
Let $\bell$ be its corresponding leaf in $\bar\Ccal$ and $\D$ be the depth of $\bell$.
By \Cref{clm:finite_steps}, $\bell$ always has finite depth.
We extend $\supa{t}=\supb{t}=0^{n\times n}$ and $\supX{t}=\supX{\D},\supY{t}=\supY{\D}$ for all $t>\D$.
Then define
$$
\K(\lx,\ly)=\sum_{t=d_1+1}^{d_2}\pbra{\abra{\lx\tensor \lx,\supa{t}}^2+\abra{\ly\tensor\ly,\supb{t}}^2}
\quad\text{and}\quad
K=\E_{\lx,\ly\sim\gamma}\sbra{\K(\lx,\ly)\mid\ell^*},
$$
where $\supa{\cdot}$'s and $\supb{\cdot}$'s depend only on $\bell$.\footnote{Note that $\bell$ specifies all the communication messages, which allows us to simulate the protocol and obtain each $\supa{\cdot}$ and $\supb{\cdot}$.}
Equivalently, we can write $K$ as
$$
K=\E_{\lx,\ly\sim\gamma}\sbra{\K(\lx,\ly)\mid(\lx,\ly)\in X^{(d_1)}\times Y^{(d_1)}},
$$
where $X^{(d_1)}$ and $Y^{(d_1)}$ are fixed due to $\ell^*$.

Observe that for any fixed $t\ge d_1$, $\supX{t}\times \supY{t}$ induced by different $\bell$, conditioned on $\ell^*$, is a disjoint partition of $X^{(d_1)}\times Y^{(d_1)}$. 
Therefore sampling $\lx,\ly\sim\gamma$ conditioned on $(\lx,\ly)\in X^{(d_1)}\times Y^{(d_1)}$ is equivalent to 
\begin{itemize}
\item first sample random messages $\bell'=(\supcbar{d_1+1},\ldots,\supcbar{t})$ conditioned on $\ell^*$,
\item then sample $\lx,\ly\sim\gamma$ conditioned on $(\lx,\ly)\in \supX{t}\times \supY{t}$ given $\bell'$.
\end{itemize}
Note that we can further expand $\bell'$ to a leaf $\bell$ as a full communication path, and obtain the following equivalent sampling process:
\begin{itemize}
\item Sample a random leaf $\bell$ conditioned on $\ell^*$.
\item Sample $\lx,\ly\sim\gamma$ conditioned on $(\lx,\ly)\in \supX{t}\times \supY{t}$ defined by the first $t$ messages of $\bell$.
\end{itemize}
As a result, we have
\begin{align*}
K
&=\sum_{t=d_1+1}^{d_2}\E_{\bell}\sbra{\E_{\lx,\ly\sim\gamma}\sbra{\abra{\lx\tensor \lx,\supa{t}}^2+\abra{\ly\tensor \ly,\supb{t}}^2\mid(\lx,\ly)\in \supX{t}\times \supY{t}}\mid\ell^*}\\
&=\E_{\bell}\sbra{\sum_{t=d_1+1}^{d_2}\E_{\lx\sim\gamma}\sbra{\abra{\lx\tensor \lx,\supa{t}}^2\mid \lx\in \supX{t}}+\E_{\ly\sim\gamma}\sbra{\abra{\ly\tensor \ly,\supb{t}}^2\mid \ly\in \supY{t}}\mid\ell^*}.
\end{align*}
Observe that there are at most $2d$ many step 3(a) and 3(b) in $\bell$.
This means, if $\D\ge d_2$, then from the $(d_1+1)$-th to the $d_2$-th communication steps, there are at least $d_2-d_1-2d$ cleanup steps (i.e., step 3(c)), each of which contributes at least $\lambda$ to $K$.
Thus we can lower bound $K$ by
\begin{equation}\label{eq:lem:depth_tail_bound_1}
K\ge \lambda\cdot(d_2-d_1-2d)\cdot\Pr\sbra{\D\ge d_2\mid\ell^*}.
\end{equation}

On the other hand by \Cref{clm:finite_steps}, there are at most $n^2$ non-zero $\supa{\cdot}$'s and at most $n^2$ non-zero $\supb{\cdot}$'s in each communication path.
Thus
\begin{equation}\label{eq:lem:depth_tail_bound_2}
\K(\lx,\ly)\le n^2\cdot\pbra{\max_{x\in \supX{0}}\frob{x\tensor x}^2+\max_{y\in \supY{0}}\frob{y\tensor y}^2}<2n^4T^2.
\end{equation}

We now obtain another upper bound using \Cref{thm:quadratic_concentration}.
Let $\bar\bell=(\supcbar{1},\ldots,\supcbar{d_2})$ extend $\ell^*$ for the next $d_2-d_1$ messages.\footnote{If $\bar\bell$ becomes a leaf before $d_2$, then we can simply pad dummy messages to it.}
Then $K=\E_{\bar\bell}\sbra{\K(\bar\bell)\mid\ell^*}$ where $
\K(\bar\ell):=\E_{\lx,\ly\sim\gamma}\sbra{\K(\lx,\ly)\mid\bar\ell}$.
Note that $\bar\ell$ fixes $a^{(\cdot)}$'s and $b^{(\cdot)}$'s in $\K(\lx,\ly)$.
Therefore we use $\K_{\bar\ell}(\lx,\ly)$ to denote $\K(\lx,\ly)$ with the directions $a^{(\cdot)}$'s and $b^{(\cdot)}$'s fixed by $\bar\ell$.
We now continue the bound on $\K(\bar\ell)$:
\begin{align}
\K(\bar\ell)
&\le\sum_{t=0}^{\infty}\Pr_{\lx,\ly\sim\gamma}\sbra{\K_{\bar\ell}(\lx,\ly)\ge t\mid\bar\ell}
=\sum_{t=0}^{\infty}\frac{\Pr_{\lx,\ly\sim\gamma}\sbra{\K_{\bar\ell}(\lx,\ly)\ge t,\bar\ell}}{\Pr_{\lx,\ly\sim\gamma}\sbra{\bar\ell}}
\notag\\
&=\sum_{t=0}^{\infty}\min\cbra{1,\frac{\Pr_{\lx,\ly\sim\gamma}\sbra{\K_{\bar\ell}(\lx,\ly)\ge t,\bar\ell}}{\gamma(\bar\ell)}}
\tag{by the definition of $\gamma(\cdot)$}\\
&\le\sum_{t=0}^{\infty}\min\cbra{1,\frac{\Pr_{\lx,\ly\sim\gamma}\sbra{\K_{\bar\ell}(\lx,\ly)\ge t}}{\gamma(\bar\ell)}}.
\label{eq:lem:depth_tail_bound_3}
\end{align}

We now analyze $\Pr_{\lx,\ly\sim\gamma}\sbra{\K_{\bar\ell}(\lx,\ly)\ge t}$ using \Cref{thm:quadratic_concentration}.
Since $a^{(t)},b^{(t)}$ cannot be non-zero simultaneously, we rearrange the matrices and assume $a^{(d_1+1)},\ldots,a^{(d')},b^{(d'+1)},\ldots,b^{(d'')}$ are the only non-zero matrices where $d''\le d_2$.
Then
$$
\K_{\bar\ell}(\lx,\ly)=\sum_{t=d_1+1}^{d'}\abra{\lx\tensor \lx,a^{(t)}}^2+\sum_{t=d'+1}^{d''}\abra{\ly\tensor \ly,b^{(t)}}^2.
$$
Note that $a$'s (resp., $b$'s) satisfy the condition in \Cref{thm:quadratic_concentration}. 
Let $1/\kappa$ be the constant\footnote{In particular $\kappa=56448$ suffices from our proof in \Cref{app:thm:quadratic_concentration}.} in $\Omega$ in \Cref{thm:quadratic_concentration}.
Hence
\begin{align*}
\Pr\sbra{\K_{\bar\ell}(\lx,\ly)\ge t}
&\le\Pr\sbra{\sum_{t=d_1+1}^{d'}\abra{\lx\tensor \lx,a^{(t)}}^2\ge t/2}+\Pr\sbra{\sum_{t=d'+1}^{d''}\abra{\ly\tensor \ly,b^{(t)}}^2\ge t/2}\\
&\le2\exp\cbra{-\frac1\kappa\cdot\frac{t/2}{d'-d_1+\sqrt{t/2}}}+2\exp\cbra{-\frac1\kappa\cdot\frac{t/2}{d''-d'+\sqrt{t/2}}}
\tag{by \Cref{thm:quadratic_concentration} and assuming $t\ge196\cdot\max\cbra{d'-d_1,d''-d'}$}\\
&\le4\exp\cbra{-\frac1\kappa\cdot\frac{t/2}{d_2-d_1+\sqrt{t/2}}}.
\tag{since $d_1\le d'\le d''\le d_2$}
\end{align*}
Thus for any $t\ge196\cdot(d_2-d_1)\ge196\cdot\max\cbra{d'-d_1,d''-d'}$, we have
\begin{equation}\label{eq:lem:depth_tail_bound_5}
\Pr\sbra{\K_{\bar\ell}(\lx,\ly)\ge t}\le4\exp\cbra{-\frac1\kappa\cdot\frac{t/2}{d_2-d_1+\sqrt{t/2}}}.
\end{equation}

For $\gamma(\bar\ell)\ge2^{-3L\cdot d_2}$, we plug \Cref{eq:lem:depth_tail_bound_5} into \Cref{eq:lem:depth_tail_bound_3} and obtain
\begin{align}
\K(\bar\ell)
&\le\sum_{t=0}^{196\cdot(d_2-d_1)^2}1+\sum_{t>196\cdot(d_2-d_1)^2}\min\cbra{1,2^{3L\cdot d_2+1}\cdot\exp\cbra{-\frac1\kappa\cdot\frac{t/2}{d_2-d_1+\sqrt{t/2}}}}
\tag{by \Cref{eq:lem:depth_tail_bound_5}}\\
&\le196\cdot(d_2-d_1)^2+1+\sum_{t\ge196\cdot(d_2-d_1)^2}\min\cbra{1,2^{3L\cdot d_2+1}\cdot e^{-\frac1\kappa\cdot\frac{t/2}{2\sqrt{t/2}}}}
\notag\\
&\le197\cdot d_2^2+\sum_{t\ge1}\min\cbra{1,2^{3L\cdot d_2+1}\cdot e^{-\frac{\sqrt{t/2}}{2\kappa}}}
\notag\\
&\le\alpha\cdot d_2^2L^2,
\label{eq:lem:depth_tail_bound_6}
\end{align}
where $\alpha$ is another universal constant.
Now we have
$$
K
=\E_{\bar\bell}\sbra{\K(\bar\bell)\mid\ell^*}
=\sum_{\bar\ell}\frac{\gamma(\bar\ell)}{\gamma(\ell^*)}\cdot \K(\bar\ell)
=\sum_{\bar\ell:\gamma(\bar\ell)<2^{-3L\cdot d_2}}\frac{\gamma(\bar\ell)}{\gamma(\ell^*)}\cdot \K(\bar\ell)+\sum_{\bar\ell:\gamma(\bar\ell)\ge2^{-3L\cdot d_2}}\frac{\gamma(\bar\ell)}{\gamma(\ell^*)}\cdot \K(\bar\ell),
$$
where the first summation can be bounded by
\begin{align*}
\sum_{\bar\ell:\gamma(\bar\ell)<2^{-3L\cdot d_2}}\frac{\gamma(\bar\ell)}{\gamma(\ell^*)}\cdot \K(\bar\ell)
&\le\frac{2^{-3L\cdot d_1}}{\gamma(\ell^*)}\cdot\sum_{\bar\ell}2^{-3L\cdot(d_2-d_1)}\cdot n^4T^2
\tag{by \Cref{eq:lem:depth_tail_bound_2}}\\
&\le\frac{2^{-3L\cdot d_1}}{\gamma(\ell^*)}\cdot2^{2L\cdot(d_2-d_1)}\cdot2^{-3L\cdot(d_2-d_1)}\cdot n^4T^2
\tag{since $\ell^*$ is fixed and each message is at most $2L$ bits}\\
&=\frac{2^{-3L\cdot d_1}}{\gamma(\ell^*)}\cdot\frac{2n^4T^2}{2^L}
\tag{since $d_2-d_1\ge1$}
\end{align*}
and the second summation is bounded by
\begin{equation*}
\sum_{\bar\ell:\gamma(\bar\ell)\ge2^{-3L\cdot d_2}}\frac{\gamma(\bar\ell)}{\gamma(\ell^*)}\cdot \K(\bar\ell)
\le\sum_{\bar\ell}\frac{\gamma(\bar\ell)}{\gamma(\ell^*)}\cdot\alpha\cdot d_2^2L^2
=\alpha\cdot d_2^2L^2.
\tag{by \Cref{eq:lem:depth_tail_bound_6}}
\end{equation*}
Then combining \Cref{eq:lem:depth_tail_bound_1}, we have
$$
\lambda\cdot(d_2-d_1-2d)\cdot\Pr\sbra{\D\ge d_2\mid\ell^*}\le \alpha\cdot d_2^2L^2+\frac{2^{-3L\cdot d_1}}{\gamma(\ell^*)}\cdot\frac{2n^4T^2}{2^L}.
$$
Assume $2^L\ge8n^4T^2$ and $d_2-d_1\ge2d+1$. Then
\begin{equation*}
\Pr\sbra{\D\ge d_2\mid\ell^*}\le\frac{\alpha\cdot d_2^2L^2}{\lambda\cdot(d_2-d_1-2d)}+\frac14\cdot\frac{2^{-3L\cdot d_1}}{\gamma(\ell^*)}.
\tag*{\qedhere}
\end{equation*}
\end{proof}

\begin{corollary}\label{cor:depth_tail_bound}
Assume $\gamma^*\ge3/4$, $T\le n$, $L\ge\Theta(\log(n))$, and $\lambda\ge\Theta(dL^2\log^2(n))$. Then for each $k=0,1,\ldots,4\log(n)$, we have
$$
\Pr\sbra{\D\ge4kd}\le2^{-k}+\frac k{n^5}.
$$
\end{corollary}
\begin{proof}
We prove the bound by induction on $k$. The base case $k=0$ is trivial.
For the inductive case, let $\ell^*$ be the first $4(k-1)d$ communication messages. Then we bound
$$
P:=\sum_{\ell^*:\gamma(\ell^*)/\gamma^*<2^{-3L\cdot4(k-1)d}}\frac{\gamma(\ell^*)}{\gamma^*}\cdot\Pr\sbra{\D\ge4kd\mid\ell^*}
$$
and
$$
Q:=\sum_{\ell^*:\gamma(\ell^*)/\gamma^*\ge2^{-3L\cdot4(k-1)d}}\frac{\gamma(\ell^*)}{\gamma^*}\cdot\Pr\sbra{\D\ge4kd\mid\ell^*}
$$
separately.

For $P$, observe that if $k=1$ then $\ell^*$ is root of the protocol, thus $\gamma(\ell^*)=\gamma^*$ and $P=0$. 
On the other hand, if $k\ge2$, then
\begin{align*}
P
&\le\sum_{\ell^*:\gamma(\ell^*)/\gamma^*<2^{-3L\cdot4(k-1)d}}2^{-3L\cdot4(k-1)d}
\le\sum_{\ell^*}2^{-3L\cdot4(k-1)d}\\
&\le2^{2L\cdot4(k-1)d}\cdot2^{-3L\cdot4(k-1)d}
\tag{each communication message is at most $2L$ bits}\\
&=2^{-L\cdot4(k-1)d}\le n^{-5}.
\tag{since $k\ge2$ and $L\ge\Theta(\log(n))$}
\end{align*}
Now we turn to $Q$.
Applying \Cref{lem:depth_tail_bound} with $\ell^*$ and $d_1=4(k-1)d,d_2=4kd$, we have
\begin{align*}
Q
&\le\sum_{\ell^*:\gamma(\ell^*)/\gamma^*\ge2^{-3L\cdot4(k-1)d}}\frac{\gamma(\ell^*)}{\gamma^*}\cdot\pbra{\frac{16\alpha\cdot k^2d^2L^2}{2dR}+\frac14\cdot\frac{2^{-3L\cdot4(k-1)d}}{\gamma(\ell^*)}}\\
&\le\sum_{\ell^*}\frac{\gamma(\ell^*)}{\gamma^*}\cdot\pbra{\frac{8\alpha\cdot k^2dL^2}{\lambda}+\frac1{4\gamma^*}}\\
&=\Pr\sbra{\D\ge4(k-1)d}\cdot\pbra{\frac{8\alpha\cdot k^2dL^2}{\lambda}+\frac1{4\gamma^*}}\\
&\le\Pr\sbra{\D\ge4(k-1)d}\cdot\frac12
\tag{since $\gamma^*\ge3/4$ and $\lambda\ge\Theta(dL^2\log^2(n)),k\le4\log(n)$}\\
&\le\pbra{2^{-(k-1)}+\frac{k-1}{n^5}}\cdot\frac12
\le2^{-k}+\frac{k-1}{n^5}.
\tag{by induction hypothesis}
\end{align*}
By adding up $P$ and $Q$, we complete the induction.
\end{proof}

Given \Cref{cor:depth_tail_bound} and suitable choice of the parameters, we now prove the second moment bound.
\begin{proof}[Proof of \Cref{lem:second_moment}]
With $L=\Theta(\log(n))$, $T=\Theta(\sqrt{\log(n)})$, and $\lambda=\Theta(d\log^4(n))$, by \Cref{fct:gammastar}, we have $\gamma^*\ge3/4$.
Therefore the second moment of $\D$ is 
\begin{align*}
\E[\D^2]
&\le\sum_{k=0}^{4\log(n)}\pbra{4(k+1)d}^2\cdot\Pr\sbra{\D\ge4kd}+\Pr\sbra{\D\ge16 d\log(n)}\cdot(2n^2)^2
\tag{by \Cref{clm:finite_steps}}\\
&\le\sum_{k=0}^{4\log(n)}\pbra{4(k+1)d}^2\cdot\pbra{2^{-k}+\frac k{n^5}}+\pbra{n^{-4}+\frac{4\log(n)}{n^5}}\cdot(2n^2)^2
\tag{by \Cref{cor:depth_tail_bound}}\\
&=O(d^2).
\tag*{\qedhere}
\end{align*}
\end{proof}