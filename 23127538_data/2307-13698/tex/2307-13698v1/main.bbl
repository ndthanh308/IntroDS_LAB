\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{abid2021meaningfully}
Abubakar Abid, Mert Yuksekgonul, and James Zou.
\newblock Meaningfully explaining model mistakes using conceptual
  counterfactuals.
\newblock {\em arXiv preprint arXiv:2106.12723}, 2021.

\bibitem{adebayo2018sanity}
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt,
  and Been Kim.
\newblock Sanity checks for saliency maps.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{alharbi2021learning}
Raed Alharbi, Minh~N Vu, and My~T Thai.
\newblock Learning interpretation with explainable knowledge distillation.
\newblock In {\em 2021 IEEE International Conference on Big Data (Big Data)},
  pages 705--714. IEEE, 2021.

\bibitem{arpit2017closer}
Devansh Arpit, Stanis{\l}aw Jastrz{\k{e}}bski, Nicolas Ballas, David Krueger,
  Emmanuel Bengio, Maxinder~S Kanwal, Tegan Maharaj, Asja Fischer, Aaron
  Courville, Yoshua Bengio, et~al.
\newblock A closer look at memorization in deep networks.
\newblock In {\em International conference on machine learning}, pages
  233--242. PMLR, 2017.

\bibitem{ba2014deep}
Jimmy Ba and Rich Caruana.
\newblock Do deep nets really need to be deep?
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem{barbiero2022entropy}
Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Pietro Li{\'o}, Marco
  Gori, and Stefano Melacci.
\newblock Entropy-based logic explanations of neural networks.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 6046--6054, 2022.

\bibitem{bau2017network}
David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba.
\newblock Network dissection: Quantifying interpretability of deep visual
  representations.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6541--6549, 2017.

\bibitem{bengio2005convex}
Yoshua Bengio, Nicolas Roux, Pascal Vincent, Olivier Delalleau, and Patrice
  Marcotte.
\newblock Convex neural networks.
\newblock {\em Advances in neural information processing systems}, 18, 2005.

\bibitem{chattopadhyay2017grad}
Adiya Chattopadhyay, Anirban Sarkar, Prantik Howlader, and Vineeth~N
  Balasubramanian.
\newblock Grad-cam: Improved visual explanations for deep convolutional
  networks.
\newblock {\em arXiv: 1710.11063}, 2017.

\bibitem{cheng2020explaining}
Xu Cheng, Zhefan Rao, Yilan Chen, and Quanshi Zhang.
\newblock Explaining knowledge distillation by quantifying the knowledge.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 12925--12935, 2020.

\bibitem{crabbe2022concept}
Jonathan Crabb{\'e} and Mihaela van~der Schaar.
\newblock Concept activation regions: A generalized framework for concept-based
  explanations.
\newblock {\em arXiv preprint arXiv:2209.11222}, 2022.

\bibitem{frankle2019dissecting}
Jonathan Frankle and David Bau.
\newblock Dissecting pruned neural networks.
\newblock {\em arXiv preprint arXiv:1907.00262}, 2019.

\bibitem{frankle2018lottery}
Jonathan Frankle and Michael Carbin.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock {\em arXiv preprint arXiv:1803.03635}, 2018.

\bibitem{ghosh2023route}
Shantanu Ghosh, Ke Yu, Forough Arabshahi, and Kayhan Batmanghelich.
\newblock Route, interpret, repeat: Blurring the line between post hoc
  explainability and interpretable models.
\newblock {\em arXiv preprint arXiv:2302.10289}, 2023.

\bibitem{han2015learning}
Song Han, Jeff Pool, John Tran, and William Dally.
\newblock Learning both weights and connections for efficient neural network.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et~al.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2(7), 2015.

\bibitem{johnson2019mimic}
Alistair~EW Johnson, Tom~J Pollard, Nathaniel~R Greenbaum, Matthew~P Lungren,
  Chih-ying Deng, Yifan Peng, Zhiyong Lu, Roger~G Mark, Seth~J Berkowitz, and
  Steven Horng.
\newblock Mimic-cxr-jpg, a large publicly available database of labeled chest
  radiographs.
\newblock {\em arXiv preprint arXiv:1901.07042}, 2019.

\bibitem{kawahara2018seven}
Jeremy Kawahara, Sara Daneshvar, Giuseppe Argenziano, and Ghassan Hamarneh.
\newblock Seven-point checklist and skin lesion classification using multitask
  multimodal neural nets.
\newblock {\em IEEE journal of biomedical and health informatics},
  23(2):538--546, 2018.

\bibitem{kim2017interpretability}
B Kim, M Wattenberg, J Gilmer, C Cai, J Wexler, F Viegas, et~al.
\newblock Interpretability beyond feature attribution: quantitative testing
  with concept activation vectors (tcav). arxiv.
\newblock {\em arXiv preprint arXiv:1711.11279}, 2017.

\bibitem{kindermans2017reliability}
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof~T
  Sch{\"u}tt, Sven D{\"a}hne, Dumitru Erhan, and Been Kim.
\newblock The (un) reliability of saliency methods. arxiv e-prints, page.
\newblock {\em arXiv preprint arXiv:1711.00867}, 2017.

\bibitem{koh2020concept}
Pang~Wei Koh, Thao Nguyen, Yew~Siang Tang, Stephen Mussmann, Emma Pierson, Been
  Kim, and Percy Liang.
\newblock Concept bottleneck models.
\newblock In {\em International Conference on Machine Learning}, pages
  5338--5348. PMLR, 2020.

\bibitem{lecun1989optimal}
Yann LeCun, John Denker, and Sara Solla.
\newblock Optimal brain damage.
\newblock {\em Advances in neural information processing systems}, 2, 1989.

\bibitem{li2016pruning}
Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans~Peter Graf.
\newblock Pruning filters for efficient convnets.
\newblock {\em arXiv preprint arXiv:1608.08710}, 2016.

\bibitem{lucieri2020interpretability}
Adriano Lucieri, Muhammad~Naseer Bajwa, Stephan~Alexander Braun, Muhammad~Imran
  Malik, Andreas Dengel, and Sheraz Ahmed.
\newblock On interpretability of deep learning based skin lesion classifiers
  using concept activation vectors.
\newblock In {\em 2020 international joint conference on neural networks
  (IJCNN)}, pages 1--10. IEEE, 2020.

\bibitem{marconato2022glancenets}
Emanuele Marconato, Andrea Passerini, and Stefano Teso.
\newblock Glancenets: Interpretabile, leak-proof concept-based models.
\newblock {\em arXiv preprint arXiv:2205.15612}, 2022.

\bibitem{menzies1996sensitivity}
SW Menzies, C Ingvar, and WH McCarthy.
\newblock A sensitivity and specificity analysis of the surface microscopy
  features of invasive melanoma.
\newblock {\em Melanoma research}, 6(1):55--62, 1996.

\bibitem{montavon2018methods}
Gr{\'e}goire Montavon, Wojciech Samek, and Klaus-Robert M{\"u}ller.
\newblock Methods for interpreting and understanding deep neural networks.
\newblock {\em Digital signal processing}, 73:1--15, 2018.

\bibitem{neyshabur2014search}
Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro.
\newblock In search of the real inductive bias: On the role of implicit
  regularization in deep learning.
\newblock {\em arXiv preprint arXiv:1412.6614}, 2014.

\bibitem{pillai2022consistent}
Vipin Pillai, Soroush~Abbasi Koohpayegani, Ashley Ouligian, Dennis Fong, and
  Hamed Pirsiavash.
\newblock Consistent explanations by contrastive learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10213--10222, 2022.

\bibitem{samek2016evaluating}
Wojciech Samek, Alexander Binder, Gr{\'e}goire Montavon, Sebastian Lapuschkin,
  and Klaus-Robert M{\"u}ller.
\newblock Evaluating the visualization of what a deep neural network has
  learned.
\newblock {\em IEEE transactions on neural networks and learning systems},
  28(11):2660--2673, 2016.

\bibitem{sarkar2021inducing}
Anirban Sarkar, Deepak Vijaykeerthy, Anindya Sarkar, and Vineeth~N
  Balasubramanian.
\newblock Inducing semantic grouping of latent concepts for explanations: An
  ante-hoc approach.
\newblock {\em arXiv preprint arXiv:2108.11761}, 2021.

\bibitem{selvaraju2016grad}
RR Selvaraju, M Cogswell, A Das, R Vedantam, D Parikh, and D Batra.
\newblock Grad-cam: visual explanations from deep networks via gradient-based
  localization. 2016.
\newblock {\em arXiv preprint arXiv:1610.02391}, 2016.

\bibitem{shrikumar2016not}
Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, and Anshul Kundaje.
\newblock Not just a black box: Learning important features through propagating
  activation differences.
\newblock {\em arXiv preprint arXiv:1605.01713}, 2016.

\bibitem{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock {\em arXiv preprint arXiv:1312.6034}, 2013.

\bibitem{singla2019explanation}
Sumedha Singla, Brian Pollack, Junxiang Chen, and Kayhan Batmanghelich.
\newblock Explanation by progressive exaggeration.
\newblock {\em arXiv preprint arXiv:1911.00483}, 2019.

\bibitem{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock {\em arXiv preprint arXiv:1706.03825}, 2017.

\bibitem{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In {\em International conference on machine learning}, pages
  3319--3328. PMLR, 2017.

\bibitem{szegedy2015going}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1--9, 2015.

\bibitem{tschandl2018ham10000}
Philipp Tschandl, Cliff Rosendahl, and Harald Kittler.
\newblock The ham10000 dataset, a large collection of multi-source
  dermatoscopic images of common pigmented skin lesions.
\newblock {\em Scientific data}, 5(1):1--9, 2018.

\bibitem{wah2011caltech}
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge
  Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem{yeh2019concept}
Chih-Kuan Yeh, Been Kim, Sercan Arik, Chun-Liang Li, Pradeep Ravikumar, and
  Tomas Pfister.
\newblock On concept-based explanations in deep neural networks.
\newblock 2019.

\bibitem{yuksekgonul2022post}
Mert Yuksekgonul, Maggie Wang, and James Zou.
\newblock Post-hoc concept bottleneck models.
\newblock {\em arXiv preprint arXiv:2205.15480}, 2022.

\bibitem{zarlenga2022concept}
Mateo~Espinosa Zarlenga, Pietro Barbiero, Gabriele Ciravegna, Giuseppe Marra,
  Francesco Giannini, Michelangelo Diligenti, Zohreh Shams, Frederic Precioso,
  Stefano Melacci, Adrian Weller, et~al.
\newblock Concept embedding models.
\newblock {\em arXiv preprint arXiv:2209.09056}, 2022.

\bibitem{zhang2021understanding}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning (still) requires rethinking
  generalization.
\newblock {\em Communications of the ACM}, 64(3):107--115, 2021.

\bibitem{zhou2016learning}
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba.
\newblock Learning deep features for discriminative localization.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2921--2929, 2016.

\end{thebibliography}
