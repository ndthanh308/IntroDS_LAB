In this section, we present the experimental evaluation of our approach over a variety of benchmarks.
First, we show that our approach can handle novel examples that cannot be addressed by existing tools such as \cite{DBLP:conf/cav/GehrMV16,DBLP:conf/pldi/GehrSV20,DBLP:conf/atva/HuangDM21,DBLP:conf/flops/NarayananCRSZ16}. 
Then we compare our approach with the state-of-the-art tool GuBPI \cite{Beutner2022b} over score-at-end Bayesian programs. (Note that GuBPI could only handle score-at-end programs.) Finally, even though the problem of path probability estimations is not the focus of our work, we demonstrate that our approach works well for this problem, for which we also compare the performance of our approach with GuBPI.
We implement our algorithms in Matlab. All results are obtained on an Intel Core i7 (2.3 GHz) machine with 16 GB of memory, running MS Windows 10. 

\subsection{Experimental Setup}\label{sec:6-1}

Since our approach is completely orthogonal to GuBPI, we conservatively have the experimental setup in order to minimize the advantage of the external inputs to our algorithms in the comparison.

\noindent\textbf{Inputs.} All benchmarks are in the form of a single while loop. We set 
two locations for each benchmark, i.e., $\lin$ for the entry of the while loop and $\lout$ for termination.
We denote the loop guard by $\phi$. 
We implement a parser from probabilistic programs into WPTS's in F\#. We conduct our experiments with various parameter combinations of $d, m$ and present the results in \cref{table:1,table:2,table:3}. 

\smallskip
\noindent{\textbf{Stage 1: Pre-processing.}} The pre-processing is illustrated as follows. 

\smallskip\noindent {\em Invariant:} We take the conservative setting that simply derives the invariant from the loop guard $\phi$ so that $I(\lin)=\phi$ and $I(\lout)=\neg\phi$.

\smallskip
\noindent {\em Bounded range:} To minimize the advantage of the choice of the bounded range to our approach, we have a conservative setting that has the bounded range to cover a majority part of program executions. Having a smaller bounded range would result in more accurate results, as polynomial solving is more accurate over a smaller bounded range. 
In detail, for each program variable $x$, we have $B''_x$ as the interval that is the projection of the support of the initial distribution onto the variable $x$. 
Then we choose a large deviation $\delta$ for all $B''_x$ ($x\in \pvars$) to get intermediate intervals $IB_x$, i.e., each ${IB}_x$ is given by ${IB}_x:=[\zeta_1-\delta,\zeta_2+\delta]$ where $[\zeta_1,\zeta_2]=B''_x$. The final bounded range $B$ is given as the intersection of the Cartesian product of all $IB_x$'s and the loop guard. 

\smallskip
\noindent {\em Polynomial approximation:} In the case that the input is a score-at-end Bayesian program and the score function is non-polynomial, we use the polynomial interpolator in Matlab to obtain a piecewise polynomial approximation for the score function. We do not have polynomial approximations in our OST approach since the benchmarks considered do not have non-polynomial score functions. 

\smallskip
\noindent{\textbf{Stage 2: Partition.}} We partition the set of initial valuations uniformly into $m$ disjoint subsets $\mathcal{V}_1,\dots,\mathcal{V}_m$, and choose the midpoints $v_i$ of each partition $\mathcal{V}_i$. 

\smallskip
\noindent{\textbf{Stage 3: Truncation.}} 
Our approach calculates the truncation approximations as described in~\cref{sec:algorithm}. For score-at-end programs, our approach either gets them by the direct bounds from the score function, further improves them by heuristics such as monotonicity, or derives polynomial truncation approximations by applying polynomial solving to our fixed-point approach without truncation. For score-recursive programs, our approach gets the truncation approximations by directly applying polynomial solving under our OST variant without truncation. 




\smallskip
\noindent\textbf{Stage 4: Polynomial solving.} In applying the Positivstellensatz's, we use the LP solver in Matlab (resp. Mosek \cite{mosek}) for solving linear (resp. semidefinite) programming, respectively.  

\subsection{Results}

We focus on unbounded while loops as they distinguish our approach with previous approaches most significantly, and compare with the most relevant tool GuBPI~\cite{Beutner2022b}. To compare our approach with GuBPI fairly, our measurement of the time cost of our approach includes the time taken to generate all the extra inputs. 
 
\smallskip 
\noindent{\em NPD - Novel Examples.} 
We consider $10$ novel examples adapted from the literature, where all $7$ examples with prefix ``\textsc{Pd}'' or ``\textsc{RdWalk}'' are from \cite{Beutner2022b}, the two ``RACE'' examples are from \cite{DBLP:conf/pldi/WangS0CG21}, and the last example is from statistical phylogenetics   \cite{ronquist2021universal} (see also \cref{sec:overview}). Concretely, the ``RACE(V2)'' and ``BIRTH'' examples are both score-recursive probabilistic programs with weights greater than $1$, and thus their integrability condition should be verified by the existence of suitable concentration bounds (see~\cref{thm:puwf-normalizing}); other examples are score-at-end probabilistic while loops with unsupported types of scoring by previous tools (e.g., polynomial scoring \textbf{score}($y$) where $y$ is a single-variable polynomial). Therefore, no existing tools w.r.t. NPD can tackle these novel examples. The results are reported in \cref{table:1}, where the first column is the name of each example, the second column contains the parameters of each example used in our approach (i.e., the degree $d$ of the polynomial template, the number $m$ of partitions and the bounded range of program variables), the third column is the used solver, and the fourth and fifth columns correspond to the runtime of upper and lower bounds computed by our approach, respectively.
Our runtime is reasonable, that is, most examples can obtain tight bounds within $100$ seconds, and the simulation results by Pyro~\cite{bingham2019pyro} ($10^6$ samples per case) match our derived bounds. 
We display part of the comparison in \cref{fig:results1}, see \cref{app:experiments} for other figures.




\begin{table*}
%	\vspace{-1.7em}
	\caption{Results for Novel Examples}
	\label{table:1}
	%\begin{footnotesize}
	\resizebox{\textwidth}{!}{
		\begin{threeparttable}
			\begin{tabular}{|c|c|c|c|c|}
				\hline
				\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Benchmark}}}  &
				\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Parameters}}}      &
				\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Solver}}}      &
				\multicolumn{1}{c|}{\textbf{Upper}}      &
				\multicolumn{1}{c|}{\textbf{Lower}}   \\ \cline{4-5}
				\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{}  &  \multicolumn{1}{c|}{}  & \multicolumn{1}{c|}{\textbf{ Time (s)}} & 
				\multicolumn{1}{c|}{\textbf{ Time (s)}}                    \\ \hline \hline
				\multirow{1}{*}{\textsc{Pd(v1)}} 
				& $d=6$, $m = 60$,$pos, dis \in [0,5]$   & SDP & $54.65$  & $52.39$        \\
				\hline
				\multirow{1}{*}{\textsc{Race(v1)}} 
				&$d=6$,$m = 40$,$h,t\in [0,5]$ & LP &$87.43$ & $86.27$  \\  
				\hline
				\multirow{1}{*}{\textsc{Race(v2)}\tnote{*}}
				&$d=6$,$m = 40$, $h,t\in [0,5]$ &  LP & $81.19$ & $81.18$   \\   \hline 
				\multirow{1}{*}{\textsc{RdWalk(v1)}} 
				& $d=6$,$m = 60$, $x,y\in [0,5]$ &  LP  & $46.65$  & $47.72$   \\ 
				\hline
				\multirow{1}{*}{\textsc{RdWalk(v2)}} 
				& $d=6$,$m = 60$, $x,y\in [0,5]$ &  LP  & $97.45$  & $103.65$   \\ 
				\hline
				\multirow{1}{*}{\textsc{RdWalk(v3)}} 
				& $d=6$,$m = 60$, $x,y\in [0,5]$ &  LP & $48.61$  & $49.39$   \\ 
				\hline
				\multirow{1}{*}{\textsc{RdWalk(v4)}} 
				& $d=6$, $m = 60$,$x,y\in [0,5]$ &  LP & $98.75$  & $98.21$    \\ 
				\hline
				\multirow{1}{*}{\textsc{PdMB(v3)}}
				& $d=4$, $m = 60$,$pos,dis\in [0,5]$ &   LP  & $15.26$  & $14.57$   \\  
				\hline
				\multirow{1}{*}{\textsc{PdMB(v4)}}  
				& $d=4$,$m = 60$, $pos,dis\in [0,5]$ &  LP   & $16.07$  & $16.12$   \\  
				\hline
				\multirow{1}{*}{\textsc{Birth}\tnote{*}}& $d=6$, $m = 40$, $lambda \in [0,2], time\in [0,10]$ & LP 	& $14.72$ & $16.66$          \\  
				\hline
			\end{tabular}
			
			\begin{tablenotes}
				\footnotesize
				\item[*] It is a score-recursive probabilistic program with weights greater than $1$.
			\end{tablenotes}
	\end{threeparttable}}
	%	\end{footnotesize}
\vspace{-3ex}
\end{table*}


% Figure environment removed

\smallskip 
\noindent {\em NPD - Comparision with GuBPI \cite{Beutner2022b}.} Since the parameters used in GuBPI and our approach are completely different, it is infeasible to compare the two approaches directly. Instead, we choose the parameters to our algorithms that can achieve at least comparable results with GuBPI. The main parameters are shown in \cref{table:2}.
We consider the Pedestrian example ``\textsc{Pd}'' from \cite{Beutner2022b} (see also \cref{sec3:pedestrian}), and its variants. For the variants of ``\textsc{Pd}'', we enlarged the standard deviation of the observed normal distribution to be $5$ \textbf{in all $6$ variants} whose prefix name are ``\textsc{Pd}''; for the four ``\textsc{PdBeta}'' examples, we also adjust the original uniform sampling $\mathbf{uniform}(0,1)$ in the loop body by different beta distributions. The main purpose to introduce these variants is to test the robustness of our approach.
The last example is from \cite{DBLP:conf/cav/GehrMV16}. 

We report the results in \cref{table:2} whose layout is similar to \cref{table:1} except that the column ``\#'' displays whether or not the bounds are trivial, i.e., $[0,\infty]$.
We also compare our results with GuBPI's and simulation results ($10^6$ samples per case), and show part of the comparison in \cref{fig:results2}, see \cref{app:experiments} for other figures.  Our runtime is up to $15$ times faster than GuBPI while we can still obtain tighter or comparable bounds for all examples.  Specifically, for the first example ``\textsc{Pd}'', our upper bounds are a bit higher than GuBPI's when the value of $start$ falls into $[0,0.7]$ (which is not suprising as the deviation of the normal distribution in this example is quite small, i.e., $0.1$, and our approach constructs over-approximation constraints while GuPBI uses recursion unrolling to search for the feasible space exhaustively), but our lower bounds are greater than GuBPI's, and our NPD bounds are tighter in the following.\footnote{When the value of $start$ approaches $3$, our NPD bounds is close to zero, but the upper bounds may be lower than zero, which is caused by numerical issues of semi-definite programming. The problem of numerical issues is orthogonal to our work and remains to be addressed in both academic and industrial fields.} Note that the simulation results near $1$ deviates largely from our bounds, for which a possible reason is that \textsc{Pd} is a difficult example whose simulation results can have high variances.
For all $6$ variants of ``\textsc{Pd}'',
%where the deviation of the normal distribution is enlarged, 
our NPD bounds are tighter than GuBPI's, in particular, our upper bounds are much lower than GuBPI's. For the four ``\textsc{PdBeta}'' examples, we found that GuBPI produced zero-valued unnormalised lower bounds, and its results w.r.t. NPD are trivial, i.e., $[0,\infty]$. However, we can produce non-trivial results and our runtime is at least 2 times faster than GuBPI. We believe that the main reason why our approach outperforms GuBPI is that GuBPI has widening that may lose precision, while our approach uses polynomial solving with truncation to achieve better precision.

\begin{table*}
%	\vspace{-1.7em}
	\caption{Comparison with GuBPI}
	
	\label{table:2}
	\resizebox{\textwidth}{!}{
		%\begin{footnotesize}
		\begin{threeparttable}
			\begin{tabular}{|c|c|c|c|c|c|c|}
				\hline
				\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Benchmark}}}  &
				\multicolumn{4}{c|}{\multirow{1}{*}{\textbf{Our Tool}}}      &
				\multicolumn{2}{c|}{\multirow{1}{*}{\textbf{GuBPI}}}    \\ \cline{2-7}
				\multicolumn{1}{|c|}{} &   \multicolumn{1}{c|}{\textbf{Parameters}}  & \multicolumn{1}{c|}{\textbf{ Solver}} & 
				\multicolumn{1}{c|}{\textbf{ Time (s)}} &
				\multicolumn{1}{c|}{\solvable} &
				\multicolumn{1}{c|}{\textbf{ Time (s)}}   &    
				\multicolumn{1}{c|}{\solvable}            \\ \hline \hline
                \multirow{1}{*}{\textsc{Pd}} & $d=10$, $m = 60$, $pos, dis \in [0,5]$   &  SDP & $3176.685$   & $\bullet$ & $5266.063$   &   $\bullet$    \\ 
				\hline
				\multirow{1}{*}{\textsc{PdLD}} & $d=6$, $m = 60$, $pos, dis \in [0,5]$   &  LP & $41.99$ & $\bullet$ & $648.151$   &   $\bullet$   \\ 
				\hline
				\multirow{1}{*}{\textsc{PdBeta(v1)}} & $d=6$, $m = 60$,$pos, dis \in [0,5]$   &  LP & $99.86$ & $\bullet$ & $645.055$   &   $\circ$    \\ 
				\hline
				\multirow{1}{*}{\textsc{PdBeta(v2)}} & $d=6$,$m = 60$, $pos, dis \in [0,5]$   &  LP & $228.43$ & $\bullet$ & $653.237$   &   $\circ$   \\ 
				\hline
				\multirow{1}{*}{\textsc{PdBeta(v3)}} & $d=6$,$m = 60$, $pos, dis \in [0,5]$   & LP & $101.36$ & $\bullet$ & $657.645$   &   $\circ$  \\ 
				\hline
				\multirow{1}{*}{\textsc{PdBeta(v4)}} & $d=6$,$m = 60$, $pos, dis \in [0,5]$   &  LP & $208.86$ & $\bullet$ & $686.207$   &   $\circ$   \\ 
				\hline
				\multirow{1}{*}{\textsc{PdMB(v5)}} & $d=6$, $m = 60$,$pos, dis \in [0,5]$   &  LP & $88.41$  & $\bullet$ & $391.772$    &   $\bullet$    \\ 
				\hline
				\multirow{1}{*}{\textsc{Para-recur}} & $d=8$, $m = 60$, $p\in [0,1]$   & LP & $36.61$  & $\bullet$ & $253.728$    &   $\bullet$   \\ 
				\hline
			\end{tabular}
			%\end{footnotesize}
			\begin{tablenotes}
				\footnotesize
				\item[*] $\circ$ marks the trivial bound $[0, \infty]$, while $\bullet$ marks the non-trivial ones.
			\end{tablenotes}
			
	\end{threeparttable}}
%\vspace{-3ex}
\end{table*}

\smallskip 
\noindent {\em Path Probability Estimation.} 
We consider five recursive examples in \cite{Beutner2022b,DBLP:conf/pldi/SankaranarayananCG13}, which were also cited from the PSI repository \cite{DBLP:conf/cav/GehrMV16}. Since all five examples are non-paramteric and with unbounded numbers of loop iterations, PSI cannot handle them as mentioned in \cite{Beutner2022b}.  We estimated the path probability of certain events, i.e., queries over program variables, and thus constructed a new bounded range for each query $Q$ by the conjunction of the corresponding $B$ (see \textbf{Stage 3} in~\cref{sec:6-1}) and query $Q$. The results are reported in \cref{table:3} where the second column corresponds to different queries, and the parameters in the third column are the degree $d$, the number $m$ and the bounded range, respectively.
For the first three examples, we obtained tighter lower bounds than GuBPI and same upper bounds, while our runtime is at least 2 times faster than GuBPI. Moreover, we found a potential error of GuBPI. That is, the fourth example ``\textsc{cav-ex-5}" in \cref{table:3} is an AST program with no scores, which means its normalising constant should be exactly one. However, the upper bound of the normailising constant obtained by GuBPI is smaller than $1$ (i.e., $0.6981$). A simulation using $10^6$ samples yielded the results that fall within our bounds but violate those by GuBPI. Thus, GuBPI possibly omitted some valid program runs of this example and produced wrong results.\footnote{We reported this error to the authors of GuBPI, and the bug was fixed afterward.}  
All our results match the simulation ($10^6$ samples per case).

\begin{table*}
%	\vspace{-1.7em}
	\caption{Results for Path Probability Estimation}
	
	\label{table:3}
	\resizebox{\textwidth}{!}{
		\begin{threeparttable}
			%\begin{footnotesize}
			\begin{tabular}{|c|c|c|c|c|c|c|c|}
				\hline
				\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Benchmark}}}  &
				\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Query}}}      &
				\multicolumn{3}{c|}{\multirow{1}{*}{\textbf{Our Tool}}}      &
				\multicolumn{2}{c|}{\multirow{1}{*}{\textbf{GuBPI}}}  &
				\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Simul}}} 
				\\ \cline{3-7}
				\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & 
    \multicolumn{1}{c|}{\textbf{Parameters}}  & 
    % \multicolumn{1}{c|}{\textbf{ Solver}} & 
				\multicolumn{1}{c|}{\textbf{ Time (s)}} &
				\multicolumn{1}{c|}{\textbf{ Bounds}} &
				\multicolumn{1}{c|}{\textbf{ Time (s)}}   &    
				\multicolumn{1}{c|}{\textbf{ Bounds}} &            \\ \hline \hline
				\multirow{2}{*}{\textsc{cav-ex-7}}&Q1 & $ 6, 1, [0,30], [0,4] $&    $15.062$  &  $[0.9698,1.0000]$ &  $38.834$   & $[0.7381,1.0000]$&   $0.9938$\\ \cline{2-8}
				&Q2 & $ 6,1, [0,40], [0,4] $&    $16.321$   & $[0.9985,1.0000]$  &  $37.651$   & $[0.7381,1.0000]$ &  $0.9993$ \\ 
				\hline
				\multirow{2}{*}{\textsc{AddUni(L)}}&Q1 & $ 6,1,[0,10], [0,1] $&     $8.85$  &  $[0.9940,1.0000]$ &  $21.064$   & $[0.9375,1.0000]$&   $0.9991$\\ \cline{2-8}
				&Q2 & $ 6,1, [0,15], [0,1] $&   $8.80$   & $[0.9995,1.0000]$  &  $14.941$   & $[0.9375,1.0000]$ &  $0.9999$ \\ 
				\hline
				\multirow{1}{*}{\textsc{RdBox}}&Q1 & $ 4,1, [-0.8,0.8], [0,10] $&     $25.87$  &  $[0.9801,1.0000]$ &  $173.535$   & $[0.9462,1.0000]$&  $0.9999$ \\
				\hline
				\multirow{2}{*}{\textsc{cav-ex-5}  \tnote{*}}&Q1 & $ 6,1, [20,\infty], [0,10] $&     $33.17$  &  $[0.8251,0.9351]$ &  $229.623$   & $[0.5768,0.6374]$&   $0.9098$ \\ \cline{2-8}
				&Q2 & $ 6,1, [20,\infty], [0,20] $&    $38.373$   &  $[0.9405,1.0000]$ &  $224.504$   & $[0.5768,0.6375]$ &  $0.9645$  \\ 
				\hline
				\multirow{2}{*}{\textsc{GWalk}  \tnote{**}}&Q1 & $ 8,1, [1,\infty], [0,0.1] $&    $7.255$  &  $[0.0023,0.0023]$ &  $33.246$   & $[0.0023,0.0024]$&  $0.0023$ \\ \cline{2-8}
				&Q2 & $ 8, 1, [1,\infty], [0,0.2] $&   $8.197$   & $[0.0025,0.0025]$  &  $31.728$   & $[0.0025,0.0025]$ &  $0.0025$  \\ 
				\hline
			\end{tabular}
			%\end{footnotesize}
			\begin{tablenotes}
				\footnotesize
				\item[*] GuBPI's result contradicts ours, and we found GuBPI produces wrong results for this example.
				\item[**] As we care about path probabilities, we compared bounds of unnormalised distributions for this example (the NPD can be derived in the same manner above).
			\end{tablenotes}
			
	\end{threeparttable}}
\vspace{-2ex}
\end{table*}