In this section, we present algorithms for our fixed-point and OST approaches. 
Recall the task is to compute bounds for unrestricted expected weights over Bayesian probabilistic programs. 

\subsection{Fixed-point Approach for Score-at-end Programs}

Our algorithm for the fixed-point approach solves a polynomial template $h$ w.r.t the fixed point conditions in \cref{thm:fix-point-bounds}. The details of our algorithm (inputs and stages) are as follows.

\smallskip
\noindent\textbf{Inputs:} The inputs include a score-at-end WPTS $\Pi=(\pvars, \rvars,  L,\lin,\lout,\mu_{\mathrm{init}}, \rdvarjdis,\transset)$ parsed from a Bayesian probabilistic program $P$ written in our PPL, and extra parameters $d,m$, for which $d$ is the degree of the polynomial to be solved and $m$ is the number of partitions that divides the support $\supp{\mu_{\mathrm{init}}}$ of the initial distribution uniformly into $m$ pieces for which our algorithm solves a polynomial for each piece. Note that whether a WPTS is score-at-end or not can be done by checking the score statement and applying techniques from \cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/ChatterjeeFNH16} to check AST. 

\smallskip
\noindent\textbf{Stage 1: Pre-processing.} Our algorithm has the following pre-processing to obtain auxiliary information for the input WPTS. 

\smallskip
\noindent{\em Invariant}: To have an over-approximation of the set of reachable program states, our algorithm leverages external invariant generators (such as~\cite{SankaranarayananSM04}) to generate numerical invariants for the WPTS. We denote the generated invariant at each location $\loc$ by $I(\loc)$ and treat each invariant $I(\loc)$ directly as the set of program valuations satisfying $I(\loc)$. 

\smallskip
\noindent{\em Bounded range}: Our algorithm calculates a bounded subset $B$ of program valuations encoded as a logical formula $\Phi_B$ (so that $B=\{\pv\mid \pv\models\Phi_B\}$) by heuristics. A simple heuristic here would be to run the WPTS for a small number of transitions and determine the bounded range of each program variable as the range covered by these transitions.
The input WPTS will be truncated onto the bounded range $B$  to increase the accuracy of the polynomial solving. 
Moreover, our algorithm calculates an extended bounded range $B'$ of $B$ by examining all transitions from $B$, i.e., for all $\pv\in B$, all locations $\loc\ne \lout$ and all weighted forks $F=\langle \loc'_j, p_j, \upd_j,\wet_j \rangle$ in some transition with source location $\loc$ and all $\rv\in \supp{\rdvarjdis}$, we have that $\upd_j(\pv,\rv)\in B'$. 
Note that the exact choice of the bounded range is irrelevant to the soundness of our fixed-point approach.  


\smallskip
\noindent {\em Polynomial approximation}: In the case that the score function $g$ at the termination is non-polynomial, our algorithm leverages external polynomial interpolators to calculate a piecewise polynomial approximation of $g$ over $B'$ with an error bound 
$\epsilon> 0$ such that $|g(\pv)-g'(\pv)|\le \epsilon$ for all $\pv\in B'$. 
Our algorithm then replaces $g$ with $g'$ to avoid non-polynomial arithmetic.
We prove that the replacement is sound up to the additive error $\epsilon$, see~\cref{app:error-analysis}. 

\begin{example}\label{ex:pedes-algo-pre}
Recall the Pedestrian example in \cref{sec3:pedestrian} and its WPTS $\Pi$ in \cref{fig:pedestrian-wpts}. We choose the algorithm parameters as $d=1$ and $m=30$ to exemplify our algorithm.
We derive an invariant $I$ simply from the loop guard so that $I(\lin)=pos\ge 0$ and $I(\lout)=pos<0$. 
As the program variables $start,step$ simply receive samples, we only consider the key program variables $pos,dist$.
The bounded range is denoted by $B=\{(pos,dis)\mid pos\in [0,5], dis\in [0,5]\}$,
and the extended bounded range is given by $B'=\{(pos,dis)\mid pos\in [-1,6],dis\in [0,6]\}$.
Since the program is score-at-end and its score function $g$ at the termination is non-polynomial (i.e., $g(dis)=pdf(normal(1.1,0.1),dis)$), we choose a polynomial approximation $g'$ of $g$ with the error bound $\epsilon=10^{-5}$. \qed
\end{example}

\smallskip
\noindent\textbf{Stage 2: Partition.}
Our algorithm splits the set $\calV:=\supp{\mu_{\mathrm{init}}}$ of initial program valuations uniformly into $m\ge 1$ disjoint partitions $\calV_1,\dots,\calV_m$ and construct a set $\calW=\{\pv_1,\dots,\pv_m\}$ such that each $\pv_i\in\calV_i$. Our approach tackles each $\calV_i$ ($1\le i\le m$) separately to obtain polynomial bounds $l_i,u_i$ such that $l_i(\pv)\le \measureSem{\Pi}_{\pv}(\Rset^{|\pvars|})\le u_i(\pv)$ for all $\pv\in\calV_i$. It follows that the interval bound for $\llbracket \Pi \rrbracket (\Rset^{|\pvars|})$ 
can be derived by integrals of polynomial bounds over all $\calV_i$'s, that is, 
    \begin{align*}\label{eq:interval-analysis}
        \tag{$\clubsuit$}
        \sum_{i=1}^m \int_{\calV_i} l_i(\pv) \mu_{\mathrm{init}}(\mathrm{d} \pv) \le \llbracket \Pi \rrbracket (\Rset^{|\pvars|})= \int_{\calV} \measureSem{\Pi}_{\pv}(\Rset^{|\pvars|})\cdot \mu_{\mathrm{init}}(\mathrm{d} \pv)\le \sum_{i=1}^m \int_{\calV_i} u_i(\pv) \mu_{\mathrm{init}}(\mathrm{d} \pv) .
    \end{align*}

\begin{example}\label{ex:pedes-algo-part}
We obtain the set $\calV=\{(pos,dis)\mid pos\in [0,3],dis=0\}$, and partition $\calV$ uniformly into $m=30$ disjoint subsets on the dimension $pos$, i.e., $\calV_1=\{(pos,dis)\mid pos\in [0,0.1],dis=0\},\dots,\calV_{30}=\{(pos,dis)\mid pos\in [2.9,3],dis=0\}$. We calculate the midpoints of the dimension $pos$ for all $\calV_i$'s, and construct the set $\calW=\{(0.05,0),(0.15,0),\dots,(2.95,0)\}$.\qed
\end{example}

\smallskip
\noindent\textbf{Stage 3: Truncation.} 
Our algorithm performs a truncation operation to improve the accuracy. Intuitively, the truncation operation restricts the program values into the bounded range $B$ calculated from the pre-processing, and over-approximates the expected weight outside the bounded range by a truncation approximation. 
A \emph{truncation approximation} is a function $\calM:\mathbb{R}^{|\pvars|}\to [0,\infty)$ such that each $\calM(\pv)$ is intended to be an over- or under-approximation of the expected weight 
$\llbracket \Pi\rrbracket_{\pv} (\Rset^{|\pvars|})$ 
outside the bounded range $B$.  
The truncation operation is given as follows. 

\begin{definition}[Truncation Operation]\label{def:truncation}
Given the bounded range $B$ and a truncation approximation $\calM$,the \emph{truncated} WPTS $\Pi_{B,\calM}$ is defined as
	$\Pi_{\trunc,\calM}:=( \pvars, \rvars, L\cup\{\#\}, \lin, \lout,\mu_{\mathrm{init}},\rdvarjdis, \transset_{\trunc,\calM})$
	where $\#$ is a fresh termination location and the transition relation $\transset_{\trunc,\calM}$ is given by
	\begin{align*}
	&\transset_{\trunc,\calM}:=\{\langle \loc, \phi\wedge \Phi_\trunc, F_1, \dots, F_k \rangle\mid \langle \loc, \phi, F_1,\dots, F_k \rangle\in\transset\mbox{ and } \loc\ne \lout\}\\
 &\quad\cup \{\langle \loc, \phi\wedge (\neg\Phi_\trunc), F^{\calM,\sharp}_1, \dots, F^{\calM,\sharp}_k \rangle\mid \langle \loc, \phi, F_1,\dots, F_k \rangle\in\transset\mbox{ and } \loc\ne \lout\}\tag{\ddag}\\
 &\quad\cup\{\langle \lout, \mathbf{true}, F_{\lout}\rangle, \langle \sharp, \mathbf{true}, F_\sharp\rangle \}
\end{align*}
for which (a) we have $F_\loc:=\langle \loc,1,\mbox{\sl id},\overline{\mathbf{1}} \rangle$ ($\loc\in\{\lout,\sharp\}$) where $\mbox{\sl id}$ is the identity function and $\overline{\mathbf{1}}$ is the constant function that always takes the value $1$, and (b) for a weighted fork $F=\langle \loc', p, \mbox{\sl upd}, \wet\rangle$ in the original WPTS $\Pi$ we have $F^{\calM,\sharp}:=F$ if $\loc'=\lout$ and $F^{\calM,\sharp}:=\langle \sharp, p, \mbox{\sl upd}, \calM\rangle$ otherwise.
\end{definition}
Informally, we obtain the truncated WPTS by restraining each transition to the bounded range $B$ and redirecting 
all transitions jumping out of the bounded range but not into the location $\lout$ to the fresh termination location $\sharp$. We add the self-loop $\langle \sharp, \mathbf{true}, F_\sharp\rangle$ to ensure determinism and totality. 

We call a truncation approximation $\calM$ \emph{upper} (reps. \emph{lower}) if for all reachable state $(\loc,\pv)$ such that $\pv\not\in B$, it holds that $\llbracket \Pi\rrbracket_{\pv}(\Rset^{|\pvars|})\le \calM(\pv)$ (resp. $\llbracket \Pi\rrbracket_{\pv}(\Rset^{|\pvars|})\ge \calM(\pv)$). 
We prove  the correctness that $\llbracket \Pi\rrbracket_{\valin} (\Rset^{|\pvars|})\le \llbracket \Pi_{B,\calM}\rrbracket_{\valin}(\Rset^{|\pvars|})$ for all initial program valuations $\valin$ if $\calM$ is an upper truncation approximation, and $\llbracket \Pi\rrbracket_{\valin} (\Rset^{|\pvars|})\ge \llbracket \Pi_{\trunc,\calM}\rrbracket_{\valin}(\Rset^{|\pvars|})$ if $\calM$ is lower. 
See details in~\cref{app:truncaion}. 

To calculate truncation approximations, our algorithm takes a bound $M$ for the score function and has $0$ and $M$ as the trivial lower and upper truncation approximations. To sharpen the truncation approximations, our algorithm either utilizes the monotonicity of program variables to tighten the estimation of the values of the score function at the termination, or derives polynomial truncation approximations by applying polynomial solving to our fixed-point approach without truncation.


\begin{example}\label{ex:pedes-algo-trunc}
We choose the bounded range 
$[0,5]\times [0,5]$ that specifies $[0,5]$ for both the variable $pos,dis$. The truncation approximations are set to $\calM_{\mathrm{up}}=2.1\times 10^{-330}$ and $\calM_{\mathrm{low}}=0$. The values $2.1\times 10^{-330},0$ are calculated by the monotonicity of the density function $pdf(normal(1.1,0.1),dis)$ and the values of $dis$ at $5,6$, respectively. We obtain two truncated WPTS's $\Pi_{\trunc,\calM_{\mathrm{up}}}$ and $\Pi_{\trunc,\calM_{\mathrm{low}}}$. 
\qed
\end{example}


\begin{remark}
Recall that in our OST approach, we require the bounded update of program variables. This rules out samplings from 
unbounded probability distributions such as normal distribution. By using truncation, we could extend our approach to unbounded update by a suitable over-approximation function $\calM$ that handles unbounded update jumping outside the truncated range. The truncation operation could also handle hierarchical models such as $\textbf{score}(normal(0, 0.1 + Y), dist)$ with  $Y$ sampled from the beta distribution $\textbf{beta}(0,1)$ by a truncation that includes the hierarchical variable $Y$, and unbounded initial distribution by truncating the distribution into a bounded distribution with suitable approximations.  \qed
\end{remark}


\smallskip
\noindent\textbf{Stage 4: Polynomial Solving. }
Our algorithm establishes $d$-degree polynomial templates for $\Pi_{\trunc,\calM_{\mathrm{up}}}$ and 
$\Pi_{\trunc,\calM_{\mathrm{low}}}$, and derives polynomial upper and lower bounds for the expected weights $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}}\rrbracket_{\pv_i}(\Rset^{|\pvars|})$ and $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}}\rrbracket_{\pv_i}(\Rset^{|\pvars|})$ for each initial program valuation $\pv_i\in\calV_i$ in $\calW$ by solving the templates w.r.t the PUWF and PLWF constraints (i.e., (C1), (C2), (C1') from \cref{def:puwf}), respectively. 
The correctness of this stage follows from \cref{thm:fix-point-bounds} and that polynomials are bounded over a bounded range. 
Below we present the details in \textbf{Step A1} -- \textbf{A3}. 
We focus on $\Pi_{\trunc,\calM_{\mathrm{up}}}$ and polynomial upper bounds. The case of lower bounds 
considers $\Pi_{\trunc,\calM_{\mathrm{low}}}$ and is similar. 


\smallskip
\noindent\textbf{Step A1.} In this step, for each location $\loc\not\in \{\lout,\sharp\}$, our algorithm
sets up a $d$-degree polynomial template $h_\loc$ over the program variables $\pvars$. Each template is a summation of all monomials in the program variables of degree no more than $d$, for which each monomial is multiplied with an unknown coefficient.    
For $\loc\in \{\lout,\sharp\}$, our algorithm assumes $h_\loc\equiv 1$.

\smallskip
\noindent\textbf{Step A2.} In this step, our algorithm establishes constraints for the templates $h_\loc$'s from (C1), (C1') in \cref{def:puwf} (as (C2) is satisfied directly by the form of $h_\loc$). 
For every location $\loc \in\locs\setminus\{\lout,\sharp\}$, 
we have the following relaxed constraints of (C1) to synthesize a PUWF over $\Pi_{\trunc,M_{up}}$: 
\begin{itemize}
\item[(D1)] 
For every program valuation $\pv\in I(\loc) \cap B$, we have that $\ewt(h)(\loc,\pv) \le h(\loc, \pv)$.  
\item[(D2)] For every 
program valuation $\mathbf{v}\in I(\loc) \cap (B'\setminus B)$, we have that $\calM_{\mathrm{up}}(\pv)\le h(\loc,\pv)$.  
\end{itemize}

For lower bounds over $\Pi_{\trunc,M_{low}}$, our algorithms have the relaxed PLWF constraints (D1') and (D2') which are obtained from (D1) and resp. (D2) by replacing ``$\ewt(h)(\loc,\pv) \le h(\loc, \pv)$'' with ``$\ewt(h)(\loc,\pv) \ge h(\loc, \pv)$'' in (D1) and resp. ``$\calM_{\mathrm{up}}(\pv)\le h(\loc,\pv)$'' with ``$\calM_{\mathrm{low}}(\pv)\ge h(\loc,\pv)$'' in (D2), respectively. 
We have that (D1) and (D2) together ensure (C1)  since $\calM_{\mathrm{up}}(\pv)\le h(\loc,\pv)$ implies that $\ewt(h)(\loc,\pv) \le h(\loc, \pv)$ for every location $\loc \in\locs\setminus\{\lout,\sharp\}$ and program valuation $\pv\in I(\loc) \cap (B'\setminus B)$. The same holds for (D1') and (D2'). 

Note that in (D1), the calculation of $\ewt(h)(\loc,\pv)$ has the piecewise nature that different sampling valuations $\rv$ may cause the next program valuation to be within or outside the bounded range, and to satisfy or violate the guards of the transitions in the WPTS. In our algorithm, we have a refined treatment for (D1) that enumerates all possible situations for a sampling valuation $\rv$ that satisfy different guards in the calculation of $\ewt(h)(\loc,\pv)$, for which we use an SMT solver (e.g., Z3~\cite{Z3paper}) to compute the situations. As for (D2), we use (D2) to avoid handling the piecewise feature in the computation of $\ewt(h)(\loc,\pv)$ from within/outside the bounded range (i.e., the computation is a direct computation over a single-piece polynomial), so that the amount of computation of $\ewt(h)(\loc,\pv)$ is reduced by ignoring the piecewise feature. The use of (D2) to reduce the computation follows from the extended bounded range in the pre-processing. 
The same holds for (D1') and (D2'). 


\begin{example}\label{ex:pedes-algo-A3}
Recall \cref{ex:pedes-algo-pre,ex:pedes-algo-part,ex:pedes-algo-trunc}, we set up the $1$-degree template $h_{\lin}(pos,dis)=a_1\cdot pos+a_2\cdot dis+a_3$ withe unknown coefficients $a_1,a_2,a_3\in\Rset$ and $h_{\loc}(pos,dis)=1$ for $\loc=\{\lout,\sharp\}$.
Then the bounded range $\calD_1=I(\lin)\cap B$ in (D1) is defined such that $ pos\in [0,5]\wedge dis\in [0,5]$. Consider to derive upper bounds from $\Pi_{\trunc,\calM_{\mathrm{up}}}$. We make a fine-grained treatment for (D1) by splitting the range $\calD_1$ and enumerating all possible situations for the sampling valuation $\textbf{sample uniform}(0,1)$ that the next program valuation satisfies or violates the loop guard ``$pos\ge 0$''. In detail, $\calD_1$ is split into $\calD_{11}=\{(pos,dis)\mid pos\in [0,1), dis\in [0,5]\}$ and $\calD_{12}=\{(pos,dis)\mid pos\in (1,5], dis\in [0,5]\}$, where $\calD_{11}$ stands for the situation that with different sampling valuations the next program valuation may satisfy the loop guard (so that the next location is $\lin$) or violate the loop guard (so that the next location is directed to $\lout$), and  $\calD_{12}$ stands for the situation that the next program valuation will definitely satisfy the loop guard and the next location is $\lin$. 
  
  
We first show the PUWF constraints for $\Pi_{\trunc,\calM_{\mathrm{up}}}$. Recall that the program has two probabilistic branches with probability $0.5$. When the current program valuation is in $\calD_{11}$, we observe that 
(a) if the loop takes the branch $pos:=pos+step$, then the next value of $pos$ remains to be non-negative and the loop continues, and 
(b) if the loop takes the branch $pos:=pos-step$, 
then the next value of $pos$ either satisfies or violates the loop guard, depending on the exact value of $step\in [0,1]$. 

Then we have the constraint (D1.1) over $\calD_{11}$ that has expectation over a piecewise function on $step$ derived from whether the loop terminates in the next iteration or not, as follows:
\begin{itemize}
\item[(D1.1)] $\forall pos,dis.$ $pos\in [0,1)\wedge dis\in [0,5] \Rightarrow$
	\begin{align*}
	&0.5\cdot\expectdist{step}{[pos-step\ge 0]\cdot h_{\lin}(pos-step,dis+step)+[pos-step<0]\cdot g'(dis+step)}\\ +& 0.5\cdot\expectdist{step}{h_{\lin}(pos+step,dis+step)}\le h_{\lin}(pos,dis).
	\end{align*} 
  \end{itemize}
When the current program valuation is in $\calD_{12}$, we observe that the next program valuation is guaranteed to satisfy the loop guard, and hence we have the constraint (D1.2) over $\calD_{12}$ as follows: 
\begin{itemize}
      \item[(D1.2)] $\forall pos,dis.$ $pos\in (1,5]\wedge dis\in [0,5]\Rightarrow$
	\begin{align*}
	0.5\cdot\expectdist{step}{h_{\lin}(pos-step,dis+step)}+0.5\cdot\expectdist{step}{h_{\lin}(pos+step,dis+step)}\le h_{\lin}(pos,dis).	
	\end{align*}
  \end{itemize}
The range $\calD_2=I(\lin) \cap (B'\setminus B)$ in (D2) is represented by the disjunctive formula $\Phi:=(pos\in [0,6]\wedge dis\in [5,6])\vee (pos\in [5,6]\wedge dis\in [0,6])$. For the program valuation in $\calD_2$, its next location is $\loc_\sharp$. Recall the truncation approximation $\calM_{\mathrm{up}}=2.1\times 10^{-330}$. 
From (D2), we have two constraints from the disjunctive clauses in $\Phi$ as follows:
\begin{itemize}
    \item[(D2.1)] $\forall pos,dis.$ $pos\in [0,6]\wedge dis\in [5,6]\Rightarrow 2.1\times 10^{-330}\le h_{\lin}(pos,dis)$. 
	\item[(D2.2)] $\forall pos,dis.$ $pos\in [5,6]\wedge dis\in [0,6]\Rightarrow 2.1\times 10^{-330}\le h_{\lin}(pos,dis)$. 
\end{itemize}
For $\Pi_{\trunc,\calM_{\mathrm{low}}}$, the PLWF constraints (D1'.1) to (D2'.2) are obtained from the PUWF constraints above by replacing ``$\le$'' with ``$\ge$'' and $2.1\times 10^{-330}$ with $0$. \qed
\end{example}

\smallskip
\noindent\textbf{Step A3.} In this step, for every initial program valuation $\pv_i\in\calV_i$ in $\calW$ where $\calV_i$'s and $\calW$ are obtained from \textbf{Stage 2}, our algorithm solves the unknown coefficients in the templates $h_\loc$ ($\loc\in \locs\setminus \{\lout,\sharp\}$) via the well-established methods of Putinar's Positivstellensatz~\cite{putinar} or Handelman's Theorem~\cite{handelman1988representing}.
In detail, our algorithm minimizes the objective function $h_{\lin}(\pv_i)$ for each $\pv_i$ in $\calW$ which subjects to the PUWF constraints from the previous step to derive polynomial upper bounds over $\Pi_{\trunc,\calM_{\mathrm{up}}}$. For lower bounds, we use PLWF and consider to maximize the objective function. 

Note that the PUWF or PLWF constraints from \textbf{Step A2} can be represented as a conjunction of formulas in the form $\forall\pv\in \calP.(\mathbf{g}(\pv)\ge 0)$ where the set $\calP$ is defined by a conjunction of polynomial inequalities in the program variables and $\mathbf{g}$ is a polynomial over $\pvars$ whose coefficients are affine expressions in the unknown coefficients from the templates, and such formulas can be guaranteed by the sound forms of Putinar's Positivstellensatz and Handelman's Theorem. The application of Putinar's Positivstellensatz results in semidefinite constraints and can be solved by semidefinite programming (SDP), while the application of Handelman's Theorem is restricted to the affine case (i.e., every condition and assignment in the WPTS or the original program is affine) and leads to linear constraints and can be solved by linear programming (LP). 

We refer to~\cref{app:putinar,app:Handelman} for the details on the application of Putinar's Positivstellensatz and Handelman's Theorem. 

\begin{example}\label{ex:pedes-algo-A4}
Recall \cref{ex:pedes-algo-part,ex:pedes-algo-trunc,ex:pedes-algo-A3}, we have that $\calV_1=\{(pos,dis)\mid pos\in [0,0.1],dis=0\},\dots,\calV_{30}=\{(pos,dis)\mid pos\in [2.9,3],dis=0\}$ and the set $\calW=\{(0.05,0),(0.15,0),\dots,(2.95,0)\}$. 
Pick a point $\pv_1=(0.05,0)\in\calV_1$ from $\calW$, and to synthesize the upper bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}}\rrbracket_{\pv_1}(\Rset^{|\pvars|})$,
we solve the following optimization problem whose objective function is $h_{\lin}(0.05,0)$, i.e., 
$$\textstyle \textbf{Min}~~~~~ 0.05\cdot a_1+a_3 \qquad \textstyle \textbf{s.t.}
 ~~~~~\text{constraints (D1.1)--(D2.2)}$$
Dually, the lower bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}}\rrbracket_{\pv_1}(\Rset^{|\pvars|})$ is solved by 
$\textstyle \textbf{Max}~~~~~ 0.05\cdot a_1+a_3~\textstyle \textbf{s.t.} ~\text{(D1'.1)--(D2'.2)}$.
Although the constraints are universally quantified, the universal quantifiers can be soundly (but not completely) removed and relaxed into semidefinite constraints over the unknown coefficients $a_i$'s by applying Putinar's Positivstellensatz, where
we over-approximate all strict inequalities (e.g., ''$<$'') by non-strict ones (e.g., ``$\le$''). Then we call an SDP solver to solve the two optimization problems and find the solutions of $a_i$'s, which will generate two polynomial bound functions $Up_1,Lw_1$ such that $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}}\rrbracket_{\pv}(\Rset^{|\pvars|}) \le Up_1(\pv)+\epsilon$ and $Lw_1(\pv)-\epsilon \le \llbracket \Pi_{\trunc,\calM_{\mathrm{low}}}\rrbracket_{\pv}(\Rset^{|\pvars|})$ for all program valuation $\pv\in\calV_1$ with the polynomial approximation error  $\epsilon=10^{-5}$.    \qed
\end{example}

\smallskip
\noindent\textbf{Stage 5: Integration.}
As a consequence of \textbf{Stage 4}, our algorithm obtains
polynomial upper bounds  $Upper=\{Up_1,\dots,Up_m\}$ for the expected weights $\{ \llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket_{\pv_1}(\Rset^{|\pvars|}), \dots,  \llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket_{\pv_m}(\Rset^{|\pvars|}) \}$ w.r.t. the $m$ partitions $\calV_i,\dots,\calV_m$. 
Then our algorithm integrates these polynomial upper bounds to derive the upper bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})$.  
In detail, we have that
\begin{align}\label{eq:nc-upper}
\textstyle\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})\le \sum_{i=1}^m \int_{\calV_i} Up_i(\pv) \cdot \frac{1}{m} \mathrm{d}\pv=:u
\end{align}
Similarly,
the lower bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|})$ is given by
\begin{align}\label{eq:nc-lower}
\textstyle l:=\sum_{i=1}^m \int_{\calV_i} Lw_i(\pv) \cdot \frac{1}{m} \mathrm{d}\pv \le \llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|})  
\end{align}
with the polynomial lower bounds $Lower=\{Lw_1,\dots,Lw_m\}$ generated in \textbf{Stage 4}. Note that $[l,u]$ is also the interval bound for the original $\llbracket \Pi \rrbracket (\Rset^{|\pvars|})$ as $\llbracket \Pi_{B,\calM_{\mathrm{low}}}\rrbracket_{\valin}(\Rset^{|\pvars|}) \le \llbracket \Pi\rrbracket_{\valin} (\Rset^{|\pvars|})\le \llbracket \Pi_{B,\calM_{\mathrm{up}}}\rrbracket_{\valin}(\Rset^{|\pvars|})$ for all initial program valuations $\valin$ (see~\cref{app:truncaion}).

If the score function $g$ at the termination is non-polynomial, our algorithm integrates the polynomial approximation error $\varsigma=\mathrm{volume}(\calV)\cdot\epsilon$ caused by its polynomial approximation $g'$ to the two bounds, i.e, $l'=l-\varsigma$ and $u'=u+\varsigma$, where $\mathrm{volume}(\calV)$ is the volume of $\calV$ and $\epsilon$ is the error bound. In practice, to ensure the tightness of the interval bounds, we can control the amount of $\epsilon$ so that the approximation error $\varsigma$ is at least one magnitude smaller than the values of $l,u$. 

The correctness of our algorithm is stated as follows. 
The pseudo code is in~\cref{alg:fixed-point}. 

\begin{algorithm}
    \SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
    \SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

    \Input{A score-at-end WPTS $\Pi$, Parameters $d, m$}
     \Output{The upper bound $u$ and the lower bound $l$ for $\llbracket\Pi \rrbracket (\Rset^{|\pvars|})$}
    \BlankLine
    \textbf{Pre-processing:} 
    \begin{enumerate}
        \item Invariant generation $I$; 
        \item Bounded range $B$ and extended bounded range $B'$;
        \item Polynomial approximation for non-polynomial score function at termination.
    \end{enumerate}
    \textbf{Partition:} Splits the set $\calV:=\supp{\mu_{\mathrm{init}}}$ into $m\ge 1$ disjoint partitions $\calV_1,\dots,\calV_m$ and construct a set $\calW=\{\pv_1,\dots,\pv_m\}$ \textbf{s.t.} $\pv_i\in\calV_i$. \\
    \textbf{Truncation:}  
    \begin{enumerate}
        \item Restricts the program values into the bounded range $B$;
        \item Over (resp. under) -approximate the expected weight outside the bounded range $B$ with truncation approximation $\calM_{\mathrm{up}}$ (resp. $\calM_{\mathrm{low}}$);
        \item Construct the truncated WPTS $\Pi_{B,\calM_{\mathrm{up}}}$ (resp. $\Pi_{B,\calM_{\mathrm{low}}}$) for upper (resp. lower) bounds.
    \end{enumerate}
    \textbf{Polynomial Solving:} 
    Establish $d$-degree template $h$ and constraints over $h$, \\
    \For{each $\loc$}{
        Establish constraints (D1) (within truncate range $I(\loc) \cap B$) and (D2) (outside truncated range  $I(\loc) \cap (B'\setminus B)$) \tcc*{upper bound} 
        Establish constraints (D1') (within truncate range $I(\loc) \cap B$) and (D2') (outside truncated range $I(\loc) \cap (B'\setminus B)$) \tcc*{lower bound} 
    }
    Optimize $h_{\lin}(\pv_i)$ for each $\pv_i$ in $\calW$ with the constraints above, and produce polynomial upper and lower bounds $Upper=\{Up_1,\dots,Up_m\}$, $Lower=\{Lw_1,\dots,Lw_m\}$. \\
    \textbf{Integration:} Integrate the upper and lower bounds,\\
    $\textstyle \llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})\le \sum_{i=1}^m \int_{\calV_i} Up_i(\pv) \mathrm{d}\pv=:u$,\quad
    $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|}) \ge \sum_{i=1}^m \int_{\calV_i} Lw_i(\pv) \mathrm{d}\pv=:l$
    \caption{The Algorithm for Fixed-Point Approach}   \label{alg:fixed-point}
\end{algorithm}

\begin{theorem}[Soundness]\label{thm:soundness}
	If our algorithm finds valid solutions for the unknown coefficients in the polynomial templates, then it returns correct interval bounds for $\llbracket \Pi \rrbracket (\Rset^{|\pvars|})$. 
\end{theorem}
\begin{proof}
Let $h_\loc$'s ($\loc\in\locs$) be the solved polynomial templates. Since the extended range $B'$ is bounded, we can find a bound $M$ such that all the values these $h_\loc$'s take fall in $[-M,M]$ within $B'$. By applying \cref{thm:fix-point-bounds} to the truncated WPTS and \cref{eq:interval-analysis}, we obtain the desired result. 
\end{proof}

\subsection{OST Approach for Bounded-Update Score-Recursive Programs}

The algorithm for our OST approach over bounded-update score-recursive programs follows similar stages as for our fixed-point approach. 
The main difference lies at the pre-processing and truncation stages. In the pre-processing stage, the difference includes the following:
\begin{itemize}
\item To apply \cref{thm:puwf-normalizing}, our approach checks the prerequisites (E1) and (E2) by external approaches. For example, the condition (E1) can be checked by existing approaches in concentration and tail bound analysis~\cite{DBLP:journals/toplas/ChatterjeeFNH18,DBLP:conf/pldi/WangS0CG21}, and the condition (E2) by SMT solvers. 
\item Our current algorithmic approach does not tackle score statements with non-polynomial score functions inside a loop body. In general, non-polynomial score functions inside the loop body can also be handled by piecewise polynomial approximation. A direct way is to provide upper and lower polynomial bounds for the original non-polynomial function, which avoids the calculation of the propagation of approximation errors along loop iterations.
The same applies to sampling variables inside loop bodies with non-polynomial probability density (or mass) functions.
\end{itemize}
In the truncation, the difference is that our OST approach derives polynomial truncation approximations 
by applying polynomial solving to our OST approach without truncation. 
The soundness of the algorithm (that produces correct bounds for expected weights) follows directly from~\cref{thm:puwf-normalizing}. 




