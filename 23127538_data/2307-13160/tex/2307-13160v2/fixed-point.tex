\subsection{The Fixed-Point Approach}\label{sec:fixed-point}

Our fixed-point approach targets \emph{score-at-end} Bayesian programs that terminate almost-surely and have a single score statement with a bounded weight at the termination. 
We formally define the notion of score-at-end programs directly over WPTS's. A WPTS $\Pi$ is \emph{score-at-end} if: (i) $\Pi$ has AST; (ii) there is exactly one transition $\tau$ in the WPTS that involves the destination location $\lout$, and this transition $\tau$ takes the form $\tau=\langle \loc, \mathbf{-}, F\rangle$ with the single weighted fork $F=\langle \lout, 1, \mbox{\sl id}, wt\rangle$ where $\mbox{\sl id}$ is the identity function and $wt$ is \emph{score-bounded} by a constant $M>0$, i.e., $wt\in [0, M]$; and (iii) all transitions other than the transition $\tau$ have the score function constantly equal to $1$. Such programs widely exist in the literature~\cite{DBLP:conf/cav/GehrMV16,DBLP:conf/pldi/GehrSV20,Beutner2022b}.

To demonstrate the approach, we recall several basic concepts in lattice theory (see Appendix~\ref{app:fixed-point-materials} for details). 
Given a complete lattice $(K, \sle)$ and a function $f: K \to K$, the \emph{supremum} of $K$ is denoted by $\bigsqcup K$, while the \emph{infimum} of $K$ is denoted by $\bigsqcap K$. An element $k \in K$ is called a \emph{fixed-point} if $f(k) = k.$ The \emph{least} (resp. \emph{greatest}) \emph{fixed-point}  of $f$, denoted by $\lfp f$ (resp. $\gfp f$),  is the fixed-point that is no greater (resp. smaller) than every fixed-point under $\sle$. 
Moreover, $k$ is a \emph{prefixed-point} if $f(k) \sle k$ and a \emph{postfixed-point} if $k\sle f(k)$. 
We apply Tarski's fixed-point theorem as follows. 

\begin{theorem}[\textit{Tarski}~\cite{KnasterTarski}]\label{thm:tarski}
Let $(K, \sle)$ be a complete lattice and $f:K \to K$ be a monotone function. Then, both $\lfp\ f$ and $\gfp\ f$ exist. Moreover,
$\textstyle \lfp\ f  = \mathop{\bigsqcap} \left\{x\ |\ f(x)\sle x\right\}\mbox{ and }\gfp\ f = \mathop{\bigsqcup} \left\{x\ |\ x\sle f(x)\right\}$. 
\end{theorem}

Based on \cref{thm:tarski}, we present our fixed-point approach for score-at-end WPTS's. Below we fix a score-at-end WPTS $\Pi$. 
We define $\Lambda$ as the set of states $(\loc, \pv)$ where $\loc$ is a location and $\pv$ is a program valuation. Given a maximum finite value $M\in [0,\infty)$, we define a \emph{state function} as a function $h:\Lambda\to [-M,M]$ such that for all $\pv\in\Rset^{|\pvars|}$, $h(\lout,\pv)\in [0,M]$.
The intuition of a state function $h$ is that $h(\loc,\pv)$ gives an estimation of the expected weight when the WPTS $\Pi$ starts with the initial location $\loc$ and the initial program valuation $\pv$.
We denote the set of all state functions with the maximum value $M$ by $\mathcal{K}_M$. We also use the usual partial order $\le$ on $\mathcal{K}_M$ that is defined in the pointwise fashion, i.e., for any $h_1,h_2\in \mathcal{K}_M$, $h_1\le h_2$ iff $h_1(\loc,\pv)\le h_2(\loc,\pv)$ for all $(\loc,\pv)\in\Lambda$. It is straightforward to verify that  $(\mathcal{K}_M,\le)$ is a complete lattice. 

To connect the complete lattice $(\mathcal{K}_M,\le)$ with expected weights, we define the \emph{expected-weight function} $\mbox{\sl ew}_\Pi$ by $\mbox{\sl ew}_\Pi(\lin,\pv):=\llbracket \Pi\rrbracket_{\pv}(\Rset^{|\pvars|})$, and omit the subscript $\Pi$ if it is clear from the context. Informally, $\mbox{\sl ew}_\Pi(\lin,\pv)$ is the expected weight of the program starting from an initial program valuation $\pv$. 
Note that if the weight at termination is bounded by a maximum value $M$, then we have $\mbox{\sl ew}_\Pi\in \mathcal{K}_M$. 
We consider the following higher-order function over the complete lattice $(\mathcal{K}_M,\le)$. 

\begin{definition}[Expected-Weight Transformer]\label{def:ewt}
Given a finite maximum value $M\in [1,\infty)$, the \emph{expected-weight transformer} $\ewt_\Pi:\mathcal{K}_M\to \mathcal{K}_M$ is the higher-order function such that for each state function $h\in \mathcal{K}_M$ and state $(\loc,\pv)$, if  $\tau = \langle \loc, \phi, F_1,\dots,F_k \rangle$ is the unique transition that satisfies $\pv\models\phi$ and $F_j=\langle \loc'_j,p_j,\upd_j,\wet_j\rangle$ for each $1\le j\le k$, then we have that
\begin{equation}\label{eq:ewt}
\ewt_\Pi(h)(\loc,\pv)\,:=\, \begin{cases}  \sum_{j=1}^k p_j\cdot \expectdist{\rv}{\wet_j(\pv,\rv)\cdot h(\loc'_j,\upd_j(\pv,\rv))} & \mbox{if } \loc\neq \lout \\
1 & \mbox{otherwise} 
\end{cases}\enskip. 
\end{equation}
In \eqref{eq:ewt}, the expectation $\expectdist{\rv}{-}$ is taken over a sampling valuation $\rv$ that observes the distribution $\rdvarjdis$.
\end{definition}
Informally, given a state function $h$, the expected-weight transformer $\ewt_\Pi$ computes the expected weight $\ewt_\Pi(h)$ after one step of WPTS transition. Note that in \eqref{eq:ewt}, the weight $\wet_j(\pv,\rv)$ equals $1$
when the location $\loc$ does not refer to the score statement at the end of the program, as we consider that the WPTS $\Pi$ is score-at-end. This implies that $\ewt_\Pi$ is indeed a higher-order operator for the complete lattice $(\mathcal{K}_M,\le)$ when the maximum value $M$ is a bound for the weights in the score statement. By the monotonicity of expectation, we have that $\ewt_\Pi$ is monotone. 

We will omit the subscript $\Pi$ in $\ewt_\Pi(h)$ if it is clear from the context. In the next definition, we define potential weight functions that are prefixed/postfixed points of the operator $\ewt_\Pi(h)$.

\begin{definition}[Potential Weight Functions]\label{def:puwf}
    A \emph{potential upper weight function} (PUWF) is a function $h:\locs{}\times\val{V_p} \rightarrow\Rset$ that has the following properties:
	\begin{itemize}
		\item[\emph{(C1)}] for all reachable states $(\loc,\pv)$ with $\loc\neq\lout$, we have $\ewt({h})(\loc,\pv) \le h(\loc,\pv)$;
		\item[\emph{(C2)}] for all reachable states $(\loc,\pv)$ such that $\loc=\lout$, we have $h(\loc,\pv)=1$.
	\end{itemize}
	Analogously, a \emph{potential lower weight function} (PLWF) is a function $h:\locs{}\times\val{V_p} \rightarrow\Rset$
	that satisfies the conditions (C1') and (C2), for which the condition (C1') is almost the same as (C1) except for that ``$\ewt({h})(\loc,\pv) \le h(\loc,\pv)$'' is replaced with ``$\ewt({h})(\loc,\pv) \ge h(\loc,\pv)$''. 
\end{definition}

Informally, a PUWF is a state function that satisfies the prefixed-point condition of $\ewt$ at non-terminating locations, and equals one at termination. A PLWF is defined similarly by using the postfixed-point condition. 
The main theorem below states that potential weight functions serve as bounds for expected weights. The proof establishes that the fixed point of $\ewt_\Pi$ is unique and equals $\mbox{\sl ew}_\Pi$ 
when the WPTS $\Pi$ has AST, and applies Tarski's Fixed Point Theorem to use prefixed and post-fixed points to derive upper and lower bounds. See Appendix~\ref{app:fixedpoint} for the detailed proof.

\begin{theorem}[Fixed-Point Approach]\label{thm:fix-point-bounds}

$\llbracket \Pi\rrbracket_{\valin} (\Rset^{|\pvars|})\le h(\lin,\valin)$ (resp. $\llbracket \Pi\rrbracket_{\valin} (\Rset^{|\pvars|})\ge h(\lin,\valin)$) for any bounded PUWF (resp. PLWF) $h$ over $\Pi$ and initial state $(\lin,\valin)$.
\end{theorem}

\begin{remark}%[Generality of our fixed-point approach]
Although our fixed-point approach targets score-at-end programs, it can be extended to Bayesian programs such that in any execution of the program, only a bounded number of {\tt score}  statements are executed and they are all bounded. 
This is because one can find a bound for the overall weight of the boundedly many score functions to apply our fixed point theorem.  The intuition here is that our fixed point approach can handle Bayesian programs whose multiplicative cumulative score values are always bounded by some constant. Especially, this approach can handle programs where all execution cycles are score-bounded by one. \qed
\end{remark}
