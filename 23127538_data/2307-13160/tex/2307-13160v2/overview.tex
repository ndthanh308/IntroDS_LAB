We present two motivating examples to highlight our key novelties.

\subsection{Pedestrian Random Walk}\label{sec3:pedestrian}

% Figure environment removed

Consider the pedestrian random walk example~ \cite{DBLP:conf/esop/MakOPW21} in \cref{fig:pedestrian-program}. In this example, a pedestrian is lost on the way home, and she only knows that she is at most $3$ km away from her house. Thus, she starts to repeatedly walk a uniformly random distance of at most $1$ km in either direction of the road with equal probability, until reaching her house. Upon the arrival, an odometer tells that she has walked $1.1$ km in total. However, this odometer was once broken and the measured distance is normally distributed around the true distance with a standard deviation of $0.1$ km. We want to infer the posterior distribution of the starting point. 

This example is modeled as a non-parametric probabilistic program whose number of loop iterations is unbounded, where the blue part is the annotations used for the Bayesian inference of this example. In the program, the variables $start$, $pos$, $step$, $dis$ represent the starting point, the current position, the distance walked in the next step and the travelled distance so far of the pedestrian, respectively. 
As the program variables $start,step$ simply receive samples, the key program variables are $pos,dist$. 

This program terminates with probability $1$ and has a score statement at termination with a bounded score function indicated by the probability density function $pdf(\textbf{normal}(1.1,0.1),dist)$ of the normal distribution with mean $1.1$ and deviation $0.1$. Note that $pdf(\textbf{normal}(1.1,0.1),dist)=pdf(\textbf{normal}(dist,0.1),1.1)$. Bayesian probabilistic programs that have score statements at termination widely exist in the literature~\cite{DBLP:conf/cav/GehrMV16,DBLP:conf/pldi/GehrSV20,Beutner2022b}, and we call them \emph{score-at-end} programs. We propose a novel approach for Bayesian inference over such programs via fixed-point conditions. 

Our approach decomposes the Bayesian inference into the computation of expected weights, i.e., expected score values from various initial program inputs. For this example, we have the initial value for the variable $pos$ ranges over $[0,3]$, and the initial value for the variable $dist$ fixed to be $0$. We partition the range of initial values into multiple pieces (e.g., dividing $[0,3]$ into $[0,0.1], [0.1,0.2],\dots,[2.9,3]$), and solve the expected weights for each piece. Within each piece, we establish a polynomial template $h$ for the upper bound to be solved and use fixed-point theory to solve the template. 
A template for this example at the entry point of the loop
is given by the linear template $h(pos,dis)=a_1\cdot pos+a_2\cdot dis+a_3$ (see the annotations), and the prefixed-point condition to solve $h$ as an upper bound is given by
\begin{align*}
&\ewt(h):=0.5\cdot\expectdist{step}{[pos-step\ge 0]\cdot h(pos-step,dis+step)+[pos-step<0]\cdot g(dis+step)}\\ & \quad{}+ 0.5\cdot\expectdist{step}{h(pos+step,dis+step)}\le h(pos,dis).
\end{align*} 
where the left-hand-side $\ewt(h)$ of the inequality expresses the expected value of the template after one loop iteration, for which the expectation is taken w.r.t the sampling of the $step$ variable. 
Note that here we use a polynomial $g$ to approximate the density function of the normal distribution to allow a uniform polynomial reasoning. 

For this example, simply solving the polynomial template $h$ does not suffice, as we have find that polynomial solving produces trivial constant bounds even with high degrees. Hence, we consider a novel truncation operation that truncates the probabilistic program into a bounded range, so that we can utilize the strong approximation ability of polynomials over bounded ranges. In this example, we can choose the bounded range to be $B=\{(pos,dis)\mid pos\in [0,5], dis\in [0,5]\}$, so that the program state space is partitioned into sets of states within $B$ and outside $B$. The execution of the program is also changed in the sense that once the execution jumps out of the bounded range, the program halts immediately. In conjunction with the bounded range, we associate a polynomial $\calM$ that over-approximates the expected weights outside the bounded range. In this example, we have that when jumping out of the bounded range, either $dist\ge 5$ or $pos \ge 5$, and in both cases we have $dist\ge 5$ (as the pedestrian needs to travel at least the maximal $pos$ in the walk). Hence, we can choose $\calM=2.1\times 10^{-330}$ since $pdf(\textbf{normal}(1.1,0.1),dist)\le 2.1\times 10^{-330}$ when $dist\ge 5$ according to its monotonicity. 
Given the bounded range $B$ with the over-approximation $\calM$, we then solve the template $h$ by the following (informal) modified prefixed-point conditions: (a) When within the bounded range $B$, we have $\ewt(h) \le h$; (b) When outside the bounded range $B$, we have $\calM \le h$.  

The example is handled in~\cite{Beutner2022b} by exhaustive recursion unrolling that has the path-explosion problem. 
Our approach circumvents path explosion and derives comparable bounds to the approach in~\citet{Beutner2022b} with runtime two-thirds of that of~\citet{Beutner2022b}.


\subsection{Phylogenetic Birth Model}\label{sec3:phylogenetic}
	
Consider a simplified version of the phylogenetic birth model \cite{ronquist2021universal}, where a species arises with a birth-rate $lambda$, and it propagates with a simplified constant likelihood of $1.1$ at some time interval. For simplicity, we assume constant weights that can be viewed as over-approximation for a continuous density function. This example can be modelled as a probabilistic loop in~\cref{fig:phylogenetic}. In this program, the variables $lambda, time, amount, wait$ stand for the birth rate of the species, the remaining propagation time, the current amount of the species and the propagation time to be spent, respectively. The variable $lambda$ is associated with a prior distribution, and the NPD problem is to infer its posterior distribution given the species evolution described by the loop.


The main difficulty to analyze the NPD of this example is that its loop body includes a score statement {\tt score($1.1$)} with the constant score function greater than $1$. We call such programs \emph{score-recursive}. 
As stated previously, this incurs an integrability issue that cannot be solved by previous approaches. 
To address this difficulty, we propose a novel multiplicative variant of Optional Stopping Theorem (OST) that allows a stochastic process to scale by a multiplicative factor during its evolution. Based on the OST variant, we apply polynomial solving with truncation as in our fixed-point approach. 

 In this example, the key program variables are $lambda,time$ as $lambda$ affects the probabilistic branches and $time$ is included in the loop guard, while $wait,birth$ simply receive samples and $amount$ does not affect the control flow of the program.
We perform truncation operation by restricting the behaviour of the program within a bounded range such as $\{(lambda,time)\mid lambda\in [0,2]$ and $time\in [0,10]\}$, and over-approximate the expected weights outside the bounded range by an interval bound of polynomial functions 
derived from our OST variant and polynomial-template method but without truncation.
Our experimental result on this example 
shows that the derived bounds match the simulation result with $10^6$ samples. 


