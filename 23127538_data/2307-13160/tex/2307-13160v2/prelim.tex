We first review basic concepts from probability theory, then present our Bayesian probabilistic programming language, and finally define the normalised posterior distribution (NPD) problem.
We denote by $\Nset$, $\Zset$ and $\Rset$ the sets of all natural numbers, integers, and real numbers, respectively.

\subsection{Basics of Probability Theory}

We recall several basic concepts and refer to standard textbooks (e.g.  \cite{pollard2002user,williams1991probability}) for details.  

Given a probability space $\pspace$, a \emph{random variable} is an $\mathcal{F}$-measurable function $X: \Omega \rightarrow \Rset \cup \{+\infty,-\infty\}$ where the measurable space over $\Rset \cup \{+\infty,-\infty\}$ is taken as the Borel space. 
The \emph{distribution function} $F$ of $X$ is given by $F(x) = \probm (\{\omega: X(\omega) \leq x\})$. A non-negative Borel measurable function $f$ is a \emph{density function} of $X$ if it satisfies $F(x) = \int_{-\infty}^{x} f(t) \mathrm{d} t$. 
The \emph{expectation} of a random variable $X$, denoted by $\expv(X)$, is the Lebesgue integral of $X$ w.r.t. $\probm$, i.e., $\int_{\Omega} X\,\mathrm{d}\probm$. A \emph{filtration} of $\pspace$ is an infinite sequence $\{ \mathcal{F}_n \}_{n=0}^{\infty}$ of $\sigma$-algebras such that for every $n\ge 0$, the triple $(\Omega, \mathcal{F}_n, \probm)$ is a probability space and $\mathcal{F}_n \subseteq \mathcal{F}_{n+1} \subseteq \mathcal{F}$. A \emph{stopping time} w.r.t. $\{ \mathcal{F}_n \}_{n=0}^{\infty}$ is a random variable $T: \Omega \rightarrow \Nset \cup \{0, \infty\}$ such that for every $n \geq 0$, the event \{$T \leq n$\} is in $\mathcal{F}_n$. 
Recall the Borel measurable space $(\Rset^n,\Sigma_{\Rset^n})$ where $\Sigma_{\Rset^n}$ is the $\sigma$-algebra generated by the open subsets in $\Rset^n$.

A \emph{discrete-time stochastic process} is a sequence $\Gamma = \{X_n\}_{n=0}^\infty$ of random variables in $\pspace$. The process $\Gamma$ is \emph{adapted} to a filtration $\{ \mathcal{F}_n \}_{n=0}^{\infty}$, if for all $n \geq 0$, $X_n$ is a random variable in $(\Omega, \mathcal{F}_n, \probm)$. A %discrete-time 
stochastic process $\Gamma=\{X_n\}_{n=0}^\infty$ adapted to a filtration $\{\mathcal{F}_n\}_{n=0}^\infty$ is a \emph{martingale} (resp., \emph{supermartingale}, \emph{submartingale})
if for all $n \geq 0$, $\expv(|X_n|)<\infty$ and it holds almost surely 
that $\condexpv{X_{n+1}}{\mathcal{F}_n}=X_n$ (\mbox{resp., } $\condexpv{X_{n+1}}{\mathcal{F}_n}\le X_n$, $\condexpv{X_{n+1}}{\mathcal{F}_n}\ge X_n$).
Applying martingales to the formal analysis of probabilistic programs is a well-studied technique~\cite{SriramCAV,ChatterjeeFG16,ChatterjeeNZ2017}.



\subsection{Bayesian Probabilistic Programs}

The syntax of our Bayesian probabilistic programming language (PPL) is given in \cref{fig:syntax}, where $c,c_1,c_2\in\Rset$ are real constants, $p\in (0,1]$ and the metavariables $S$, $B$ and $E$ stand for statements, boolean and arithmetic expressions, respectively.  
Our PPL is imperative with the usual conditional, loop, sequential and probabilistic branching structures as well as the following new structures: (a)~sample constructs of the form ``$\textbf{sample}\  D$'' that sample a value from a prescribed distribution $D$ (e.g., normal distribution, uniform distribution, etc.) over $\mathbb{R}$; (b)~score statements of the form ``\textbf{score}($EW$)'' that weight the current execution with a value expressed by $EW$, where $\textit{pdf}(D,x)$ is the value of the probability density function w.r.t. the distribution $D$ at $x$.
We also have return statements (i.e., \textbf{return}) that return the value of a program variable. Note that although probabilistic branches can be derived from sampling of Bernoulli distributions, we include probabilistic branches here to have specific algorithmic treatment for probabilistic control flows.

% Figure environment removed

In our PPL, we distinguish two disjoint sets of variables in a program: (i) the set $\pvars$ of \emph{program variables} whose values are determined by assignments (i.e., the expressions at the RHS of ``:="); (ii)~the set $\rvars$ of \emph{sampling variables} whose values are independently sampled from prescribed probability distributions each time they are accessed (i.e., each ``$\textbf{sample}\ D$" is a sampling variable). 
A \emph{valuation} on a set $V$ of variables is a function $\pv: V \rightarrow \Rset$ that assigns a real value to each variable in $V$. 
A \emph{program} (resp. \emph{sampling}) valuation is a valuation on $\pvars$ (resp. $\rvars$).
The set of program (resp. \emph{sampling}) valuations is denoted by $\val{\mathrm{p}}$ (resp. $\val{\mathrm{r}}$), respectively.
For the sake of convenience, we fix the notations in the following way: we always use $\pv\in\val{\mathrm{p}}$ to denote a program valuation, and $\rv\in\val{\mathrm{r}}$ to denote a sampling valuation.

\begin{example}\label{ex:pedestrian-program}
\cref{fig:pedestrian-program} shows a Bayesian probabilistic program written in our PPL. In this program, the set of program variables is $\pvars=\{start,pos,dis,step\}$, and the set of sampling variables is $\rvars=\{ \textbf{sample uniform}(0,3), \textbf{sample uniform}(0,1) \}$. At the execution of $\textbf{sample uniform}(0,3)$,  
it samples a value uniformly from $[0, 3]$ and assigns it to the variable $start$ in the initialization. During the loop iteration, each time $\textbf{sample uniform}(0,1)$ is executed, it samples a value uniformly from $[0,1]$ and assigns the value to the variable $step$. 
\qed

% Figure environment removed
\end{example}



Below we present the semantics for our PPL. In the literature, existing semantics are either measure-based~\cite{DBLP:conf/lics/StatonYWHK16,LeeYRY20} or sampling-based~\cite{DBLP:conf/esop/MakOPW21,Beutner2022b}. To facilitate the development of our approach, we consider the \emph{transition-based} semantics~\cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/ChatterjeeFNH16} so that  
each probabilistic program is transformed into an equivalent form of \emph{weighted probabilistic transition system} (WPTS). A WPTS extends a PTS  ~\cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/ChatterjeeFNH16} with weights and an initial probability distribution. 

\begin{definition}[WPTS]\label{def:wpts}
	A \emph{weighted probabilistic transition system} (WPTS) $\Pi$
	is a tuple
\begin{equation}\label{eq:wpts} 
\tag{\dag}
\Pi = (\pvars, \rvars,  L,\lin,\lout,\mu_{\mathrm{init}}, \rdvarjdis,\transset)%\win)
\end{equation}
for which:
	\begin{itemize}
		\item
		$\pvars$ and $\rvars$ are finite disjoint sets of \emph{program} and \emph{sampling} variables.
    \item $\locs$ is a finite set of \emph{locations} 
  with special locations $\lin,\lout\in \locs$. Informally, a location corresponds to a cut point in a Bayesian probabilistic program, $\lin$ is the initial location and $\lout$ represents program termination. 
		\item
		$\mu_{\mathrm{init}}$ is the \emph{initial probability distribution} over $\mathbb{R}^{|\pvars|}$ with a bounded support (denoted by $\supp{\mu_{\mathrm{init}}}$), 
  We call each $\pv\in\supp{\mu_{\mathrm{init}}}$ an \emph{initial program valuation}.

        \item $\rdvarjdis$ is a function that assigns a probability distribution $\rdvarjdis(r)$ to each 
  $r \in \rvars$. We abuse the notation so that $\rdvarjdis$ also denotes the joint distribution of all independent variables $r\in \rvars$. 
		\item 
		$\transset$ is a finite set of \emph{transitions} where
		each transition $\tau \in \transset$ is a tuple $\langle \loc, \phi, F_1,\dots,F_k \rangle$ such that (a) $\loc\in L$ is the \emph{source location}, 
(b) $\phi$ is the \emph{guard condition} which is a logical formula over program variables $\pvars$, 
and (c) each $F_j:=\langle \loc'_j, p_j, \upd_j,\wet_j \rangle$ is called a \emph{weighted fork} for which (i) $\loc'_j\in L$ is the \emph{destination location} of the fork, (ii) $p_j\in (0,1]$ is the probability of occurrence of this fork, (iii) $\upd_j:\Rset^{|\pvars|} \times \Rset^{|\rvars|} \rightarrow \Rset^{|\pvars|}$ is an {\em update function} that takes as inputs the current program and sampling valuations and returns an updated program valuation, and (iv) $\wet_j:\Rset^{|\pvars|} \times \Rset^{|\rvars|}\to [0,\infty)$ is a \emph{score function} that gives the likelihood weight of this fork depending on the current program and sampling valuations.	
\end{itemize}
\end{definition}

In a WPTS, update functions correspond to assignment statements to program variables, and score functions correspond to the cumulative multiplicative weight of a basic block of statements from the score statements in the block. 
Note that if there is no score statement in the block, then the score function of the block is constantly $1$. 
We also assume the initial probability distribution to have \emph{bounded} support as our approach solves optimization problems over bounded sets of initial program valuations.

We always assume that a WPTS $\Pi$ is \emph{deterministic} and \emph{total}, i.e., (1) there is no program valuation that simultaneously satisfies the guard conditions of two distinct transitions from the same source location, and (2) the disjunction of the guard conditions of all the transitions from any source location is a tautology. 
The transformation from a probabilistic program into its WPTS can be done in a straightforward way (see e.g.~\cite{DBLP:journals/toplas/ChatterjeeFNH18,DBLP:conf/cav/ChakarovS13}). 



\begin{example}\label{ex:pedestrian-semantics} 
\cref{fig:pedestrian-wpts} shows the WPTS of the program in \cref{fig:pedestrian-program} which has two locations $\lin,\lout$. 
The value of $step$ is initialised to $0$. The initial probability distribution $\mu_{\mathrm{init}}$ over $\Rset^{|\pvars|}$ is determined by the joint distribution of $(start,pos,dis,step)$ where $start\sim uniform(0,3)$ and $pos,dis,step$ observe the Dirac measures $Dirac(\{start\})$, $Dirac(\{0\})$ and $Dirac(\{0\})$, respectively, e.g., the probability of the event ``$dis\in\{0\}$'' equals $1$. 
The circle nodes represent locations and square nodes model the forking behavior of transitions. An edge entering a square node is labeled with the guard condition of its respective transition, while an edge entering a circle node stands for a fork, which is associated with its probability, update functions and score functions. The WPTS of the program in \cref{fig:phylogenetic} is analogously given in \cref{fig:phylogenetic-wpts}. 
\footnote{Here we omit the update functions if the values of program variables are unchanged.} 
\qed
\end{example}


Below we specify the semantics of a WPTS. Consider a WPTS $\Pi$ in the form of \eqref{eq:wpts}. Given a program valuation $\mathbf{v}$ and a guard condition $\phi$ over variables $\pvars$, we say that $\mathbf{v}$ \emph{satisfies} $\phi$ (written as $\mathbf{v}\models\phi$) if $\phi$ holds when the variables in $\phi$ are substituted by their values in $\mathbf{v}$. 

A \emph{state} is a pair $\Xi=(\loc, \pv)$ where $\loc \in L$ (resp. $\pv \in \Rset^{|\pvars|}$) represents the current location (resp. program valuation), respectively, while a \emph{weighted state} is a triple $\Theta=(\loc, \pv, w)$ where $(\loc, \pv)$ is a state and $w\in [0,\infty)$ represents the cumulative multiplicative likelihood weight. 



The semantics of $\Pi$ is formalized by the infinite sequence $\Gamma=\{\widehat{\Theta}_n=(\widehat{\loc}_n,\widehat{\pv}_n,\widehat{w}_n)\}_{n\ge 0}$ where each $(\widehat{\loc}_n,\widehat{\pv}_n,\widehat{w}_n)$ is the random weighted state at the $n$-th execution step of the WPTS such that $\widehat{\loc}_n$ (resp. $\widehat{\pv}_n$, $\widehat{w}_n$) is the random variable for the location (resp. the random program valuation, the random variable for the multiplicative likelihood weight) at the $n$-th step, respectively. 
The sequence $\Gamma$ starts with the initial random weighted state 
$\widehat{\Theta}_0=(\widehat{\loc}_0,\widehat{\pv}_0,\widehat{w}_0)$ such that $\widehat{\loc}_0$ is constantly $\lin$, $\widehat{\pv}_0\in \supp{\mu_\mathrm{init}}$ is sampled from the initial distribution $\mu_\mathrm{init}$ and the initial weight $\widehat{w}_0$ is constantly set to $1$.\footnote{This follows the traditional setting in e.g.~\cite{Beutner2022b}.} 
Then, given the current random weighted state $\widehat{\Theta}_n=(\widehat{\loc}_n,\widehat{\pv}_n,\widehat{w}_n)$ at the $n$-th step, the next random weighted state $\widehat{\Theta}_{n+1}=(\widehat{\loc}_{n+1},\widehat{\pv}_{n+1},\widehat{w}_{n+1})$ is determined by:
(a) If $\widehat{\loc}_n=\lout$, then $(\widehat{\loc}_{n+1}, \widehat{\pv}_{n+1},\widehat{w}_{n+1})$ takes the same weighted state as $(\widehat{\loc}_n,\widehat{\pv}_n,\widehat{w}_n)$ (i.e., the next weighted state stays at the termination location $\lout$);
(b) Otherwise, $\widehat{\Theta}_{n+1}$ is determined by the following procedure:
\begin{itemize}
\item First, since the WPTS $\Pi$ is deterministic and total, we take the unique transition $\tau=\langle \hat{\loc}_n,\phi,F_1,\dots, F_k \rangle$ such that $\hat{\pv}_n\models\phi$. 
\item Second, we choose a fork $F_j=\langle \loc'_j, p_j,\upd_j,\wet_j\rangle$ with the probability $p_j$.
\item Third, we obtain a sampling valuation $\rv\in \supp{\rdvarjdis}$ by sampling each $r \in \rvars$ independently from the probability distribution $\rdvarjdis(r).$
\item Finally, the value of the next random weighted state $(\widehat{\loc}_{n+1}, \widehat{\pv}_{n+1},\widehat{w}_{n+1})$ is determined as that of 
$(\loc'_j, \upd_j(\hat{\pv}_n,\rv),\widehat{w}_n\cdot \wet_j(\widehat{\pv}_n,\rv))$. 
Note that the weight is obtained in the style of the multiplicative score.
\end{itemize}
Unlike several semantics (such as~\citet{DBLP:conf/lics/StatonYWHK16}) that integrates score statements with sampling, our semantics separates them and have a special construct $\textbf{score}(-)$ for score statements.


Given the semantics, a \emph{program run} of the WPTS $\Pi$ is a concrete instance of $\Gamma$, i.e., an infinite sequence $\omega=\{\Theta_n\}_{n\ge 0}$ of weighted states where each $\Theta_n=(\loc_n,\pv_n,w_n)$ is the concrete weighted state at the $n$-th step in this program run with location $\loc_n$, program valuation $\pv_n$ and cumulative multiplicative likelihood weight $w_n$. A state $(\loc,\pv)$ is called \emph{reachable} if there exists a program run $\omega=\{\Theta_n\}_{n\ge 0}$ such that $\Theta_n=(\loc,\pv,w)$ for some $n$ and $w$. 


\begin{example}\label{ex:pedestrian-run}
Consider the WPTS in \cref{ex:pedestrian-semantics}. 
Suppose the initial program valuation is $(1,1,0,0)$ which means that the initial values of $start,pos,dis,step$ are $1,1,0,0$, respectively. Then starting from the initial weighted state $(\lin,(1,1,0),1)$, a program run 
could be 
\small{
\[
(\lin,(1,1,0,0),1)\to (\lin,(1,0.5,0.5,0.5),1)\to (\lin,(1,-0.1,1.1,0.6),1)\to (\lout,(1,-0.1,1.1,0.6),3.9894).
\]
}
\noindent
                                                                
                                                                
                                                                
                                                                
                                                                
  After the final execution, the program valuation becomes $(1, -0.1, 1.1,0.6)$ and the loop terminates. We capture the likelihood weight with $\textit{pdf}(\textbf{normal}(1.1,0.1),1.1) = \frac{1}{\sqrt{2\pi} \times 0.1} e^{-\frac{0}{2 \times 0.1^2}} = 3.9894$ and multiply it to the  current weight (i.e., 1). Thus the final weight of this run is $3.9894$. \qed
\end{example}

Given an initial program valuation $\valin$ of a WPTS, one could construct a probability space over the program runs via their probabilistic execution described above and standard constructions such as general state space Markov chains~\cite{meyn2012markov}. We denote the probability measure in this probability space by $\probm_{\valin}(-)$ and the expectation operator by $\expectdist{\valin}{-}$.

\subsection{Normalised Posterior Distribution}\label{sec2:NPD}

Below we fix a WPTS $\Pi$ in the form of \eqref{eq:wpts}.
The \emph{termination time} of the WPTS $\Pi$ is the random variable $T$ given by
$T(\omega):=\text{min}\{n\in\Nset\mid \loc_n=\lout\}$ for every program run  $\omega=\{(\loc_n,\pv_n,w_n)\}_{n\ge 0}$
where $\text{min}\,\emptyset:=\infty$. That is, $T(\omega)$ is the number of steps a program run $\omega$ takes to reach the termination location $\lout$. The WPTS $\Pi$ is \emph{almost-surely terminating} (AST) if $\probm_{\valin}(T<\infty)=1$ for all initial program valuations $\valin\in \supp{\mu_{\mathrm{init}}}$.  
Given a designated initial program valuation $\valin$ and a measurable subset $\calU\in\Sigma_{\Rset^{|\pvars|}}$, the \emph{expected weight} $\measureSem{\Pi}_{\valin}(\calU)$ restricted to $\calU$ is defined as $\measureSem{\Pi}_{\valin}(\calU):=\expectdist{\valin}{[\widehat{\pv}_T\in \calU]\cdot\widehat{w}_T}$ where $[-]$ is the Iverson bracket such that $[\phi]=1$ if $\phi$ holds and $[\phi]=0$ otherwise. 
(Recall that $\widehat{\pv}_T$ and $\widehat{w}_T$ are the random vector and variable of the program valuation and the multiplicative likelihood weight at termination, respectively.) 
If $\calU=\Rset^{|\pvars|}$, then $\measureSem{\Pi}_{\valin}(\Rset^{|\pvars|})$ is called the \emph{unrestricted expected weight}, or simply \emph{expected weight} for short.
The normalised posterior distribution (NPD) is defined as follows.  
\begin{definition}[NPD]\label{def:npd}
The \emph{normalised posterior distribution} (NPD) $\posterior_\Pi$ of $\Pi$ is defined by:
\begin{align*}
\posterior_{\Pi}(\calU):=\measureSem{\Pi}(\calU)/Z_\Pi\mbox{ for all measurable subsets } \calU\in \Sigma_{\Rset^{|\pvars|}},   
\end{align*}	
where $\measureSem{\Pi}(\calU):=\int_{\calV} \measureSem{\Pi}_{\pv}(\calU)\cdot \mu_{\mathrm{init}}(\mathrm{d} \pv)$ is the \emph{unnormalised posterior distribution} w.r.t. $\calU$ with $\calV:=\supp{\mu_{\mathrm{init}}}$, and $Z_\Pi:=\measureSem{\Pi}(\Rset^{|\pvars|})$ is the \emph{normalising constant}.  
$\Pi$ is \emph{integrable} if $0<Z_{\Pi}<\infty$. 

\end{definition}

In this work, we consider the automated interval bound analysis for the NPD of a WPTS. Formally, we aim to derive a tight interval $[l,u]\subseteq [0,\infty)$ for an integrable WPTS $\Pi$ and any measurable set $\calU\in\Sigma_{\Rset^{|\pvars|}}$ such that $l\le \posterior_{\Pi}(\calU) \le u$. To achieve this, we consider bounds on $\measureSem{\Pi}(\calU),Z_\Pi$.

\begin{framed}{\textbf{NPD Bounds}.}
Assume we have two intervals $[l_\calU,u_\calU],[l_Z,u_Z]\subseteq [0,\infty)$ such that the unnormalised posterior distribution $\llbracket \Pi\rrbracket (\calU)\in [l_\calU,u_\calU]$ and the normalising constant $Z_\Pi\in [l_Z,u_Z]$. If $\Pi$ is integrable, 
then we have the NPD $\posterior_{\Pi}(\calU)\in [\frac{l_\calU}{u_Z},\frac{u_\calU}{l_Z}]$.
\end{framed}


To analyze the quantity $\measureSem{\Pi}(\calU)$ derived from expected weights restricted to $\calU$, 
we construct a new WPTS $\Pi_\calU$ from the original $\Pi$ and a measurable set $\calU\in \Sigma_{\Rset^{|\pvars|}}$.  
Consider a probabilistic program $P$ and its WPTS $\Pi$, given a measurable set $\calU\in\Sigma_{\Rset^{|\pvars|}}$, we construct a new program $P_\calU$ by adding a conditional branch of the form ``\textbf{if} $\pv_T\notin\calU$ \textbf{then} \textbf{score}($0$) \textbf{fi}'' immediately after the termination of $P$ and obtain the WPTS $\Pi_\calU$ of $P_\calU$. Thus, $\Pi_\calU$ simply restricts the program valuation at termination to $\calU$ when taking the final cumulative weight. 
In this way, we transform the analysis of $\measureSem{\Pi}(\calU)$ into that of 
$\measureSem{\Pi_\calU}(\Rset^{|\pvars|})$ in the following, since $\measureSem{\Pi}(\calU)=\measureSem{\Pi_\calU}(\Rset^{|\pvars|})$. Therefore, from~\cref{def:npd}, we can reduce the bound analysis of NPD to that of unrestricted expected weights in the rest of the paper. See details in \cref{app:sec2-prop}. 



