 

In probabilistic programming, Bayesian statistical probabilistic programming adds specific statements for Bayesian reasoning into probabilistic programs.
%with specific statements for Bayesian reasoning that 
The principle of Bayesian probabilistic programming aims at first modelling probabilistic models as probabilistic programs and then analyzing the models through their program representation. Compared with traditional approaches \cite{McIverM04,McIverM05,SriramCAV,ChatterjeeFG16} that specify an ad-hoc language,
%probabilistic model in an ad-hoc manner, 
probabilistic programming languages (PPLs) \cite{DBLP:journals/corr/abs-1809-10756} provide a universal framework to perform Bayesian inference. 
Unlike standard programming languages, PPLs have two specific constructs: {\tt sample} and {\tt score} \cite{borgstrom2016lambda}.\footnote{Sometimes {\tt observe} is used instead of {\tt score}~\cite{gordon2014probabilistic}, which has the same implicit effect.} The former construct allows drawing samples from a (prior) distribution, while the latter records the likelihood of observed data in the form of ``{\tt score}(weight)''.\footnote{The argument ``weight'' corresponds to the likelihood each time the data is observed.}
The universality of PPLs has the potential of enabling scientists and engineers to design and explore sophisticated probabilistic models easily: when using these languages, they no longer need to worry about developing custom inference  engines for their models, which is previously a highly-nontrivial task that requires expertise in both statistics and machine learning.
Thanks to its universality, Bayesian probabilistic programming has nowadays become an active research subject in both machine learning and programming language communities, and there have been an abundance of PPLs for Bayesian inference, such as Pyro\cite{bingham2019pyro}, WebPPL\cite{dippl}, Anglican\cite{DBLP:conf/pkdd/TolpinMW15}, Church\cite{DBLP:conf/uai/GoodmanMRBT08}, etc. 


In this work, we consider the central problem of analyzing the normalised posterior distribution (NPD) in Bayesian inference over probabilistic programs. The general setting of this problem is that given a prior distribution $p(z)$ 
over the latent variables $z\in\Rset^n$ of interest and the distribution $p(x,z)$ of the probabilistic model represented by a probabilistic program, the task is to estimate the NPD by observing the evidence $x\in\Rset^m$ with the likelihood $p({x}{\mid}{z})$. %In PPLs, a specific construct named {\tt score} \cite{borgstrom2016lambda}\footnote{In some literature\cite{gordon2014probabilistic}, it uses {\tt observe} instead of {\tt score}, which has the same implicit effect.} are used to define the normalised posterior distribution.
Note that the problem can be generally solved by the Bayes' rule $p({z}{\mid}{x})=\frac{p({x}{\mid}{z})p(z)}{p(x)}$, but the main difficulty to apply Bayes' rule 
%in Bayesian statistical probabilistic programming 
is that the normalising constant $p(x)=\int p({x}{\mid}{z})p(z)\mathrm{d}z$ is usually intractable to compute. 

%\paragraph{The state of the art.} 
%In the literature, 
In the literature, there are two classes of approaches to address the 
%normalised posterior distribution 
NPD problem. The first is the approximate approaches that estimate the 
%posterior distribution 
NPD by random simulations, while the second is the formal approaches that aim at deriving guaranteed bounds for NPD. %for posterior distributions. 
In approximate approaches, two dominant methods are Markov chain Monte Carlo (MCMC)~\cite{gamerman2006markov} and variational inference (VI)~\cite{blei2017variational}. Although approximate approaches can produce approximate results efficiently, they cannot provide formal guarantee within a finite time limit. 
Moreover, as shown in ~\cite{Beutner2022b}, approximate approaches may produce inconsistent results between different simulation methods. 
In formal approaches, there is a large amount of previous works such as $(\lambda)$PSI~\cite{DBLP:conf/cav/GehrMV16,DBLP:conf/pldi/GehrSV20}, AQUA~\cite{DBLP:conf/atva/HuangDM21}, Hakaru~\cite{DBLP:conf/flops/NarayananCRSZ16} and SPPL~\cite{DBLP:conf/pldi/SaadRM21}, aiming to derive exact inference for NPD. However, these methods are restricted to specific kinds of programs, e.g., programs with closed-form solutions to NPD or without continuous distributions, and none of them can handle probabilistic programs with unbounded while-loops/recursion. Recently, Beutner et al.~\cite{Beutner2022b} proposed an approach that infers guaranteed bounds for NPD and allows unbounded recursion. 
%of recursive probabilistic programs. 
The main techniques in this approach are (i) the unrolling of every recursion in a probabilistic program to eliminate the appearance of recursion, (ii) the widening operator of abstract interpretation to eliminate the non-termination case in the unrolling and (iii) the interval semantics to handle continuous distributions. 

\paragraph{Challenges and gaps.} In this work, we focus on developing formal approaches to derive bounds for NPD over probabilistic programs. In the previous formal approaches to address this problem, the most relevant work is~\citet{Beutner2022b}, but it has the following drawbacks. 
The first is that this approach is based on recursion unrolling, and hence may cause path explosion.  
%in the case that there are a non-negligible amount of conditional branches. 
The second is that this approach cannot handle the situation where {\tt score} statements with weight greater than $1$ appear inside a loop. In the sequel, we call such programs \emph{score-recursive}, and show that {\tt score} inside a loop may cause unbounded weights and integrability issues and thus requires careful treatment. Staton et al.~\cite{DBLP:conf/lics/StatonYWHK16} also noted that for a non-recursive $\lambda$-calculus with {\tt score}, unbounded weights may introduce the possibility of ``infinite model evidence errors''. To circumvent the second drawback, previous results (e.g., Borgstr{\"{o}}m et al.~\cite{borgstrom2016lambda}) allow only 
%restrict recursive programs with 
$1$-bounded weights, and no existing approaches can handle score-recursive programs whose weight of {\tt score} can be greater than $1$. 

\paragraph{Template-based approaches.} To avoid the path explosion problem arising from the recursion unrolling method~\cite{Beutner2022b}, we consider the template paradigm~\cite{DBLP:conf/cav/ChakarovS13,DBLP:journals/toplas/ChatterjeeFNH18,ChatterjeeFG16} that first sets up a numerical template for the bound function to be solved, then establishes constraints for the template which is derived from the underlying verification theory (e.g. fixed point theory, Optional Stopping Theorem, etc.), and finally solves the template based on the derived constraints to obtain a concrete bound function. 
Template-based approaches have been shown to be capable of synthesizing tight bounds for expectation and probabilistic properties over probabilistic programs~\cite{cost2019wang,DBLP:conf/pldi/WangS0CG21}, and are time efficient since they can leverage highly optimized constraint solvers for linear, semidefinite, and convex programming, etc. Therefore, the template paradigm serves as a good candidate to address the NPD problem in Bayesian probabilistic programming. However, simply applying the template paradigm does not suffice by the following reasons: 
\begin{itemize}
\item The most accurate numerical template by far is polynomial template.
However, polynomial template is tight only over a bounded region (see e.g. Weierstrass Approximation Theorem~\cite{jeffreys1988weierstrass}), and in general is not accurate over an unbounded region. 
\item The common pattern for a template-based approach is to synthesize a single bound function via a single process of template solving. However, having a single template is not enough for synthesizing tight bounds for NPD, as different initial program inputs may need different bound functions to achieve tight bounds. 
%and one needs to consider templates for various initial program values.  
\end{itemize}
In this work, we have careful treatment to address the two weakness above. Our detailed contributions are as follows. 

%{\tt score} inside a loop where scores can be greater than $1$. 
%However, there is no existing approach to verify this precondition in the general case (where scores can be greater than $1$).
%general cases (i.e., scores are not $1$-bounded).
%give a domain-theoretic semantics for a $\lambda$-calculus with continuous distributions and unbounded score, but without recursion.

%In summary, the most relevant approach~\cite{Beutner2022b} has the weaknesses of path explosion and incapability of handling score statements with weights greater than $1$ inside a loop. Note that the first weakness is critical in the efficiency, while the second is fundamental in theory. To address these two weaknesses, we make our contributions in this work as follows. 
 


\paragraph{Our contributions.}  In this work, we present the following contributions: 
%are three-fold:
\begin{itemize}
\item 
First, to circumvent the path explosion from loop unrolling (that corresponds to recursion unrolling in functional programs) in the previous work \cite{Beutner2022b}, 
we propose a novel approach that uses polynomial templates~\cite{DBLP:conf/popl/ChatterjeeFNH16,DBLP:conf/pldi/Chatterjee0GG20,cost2019wang}, fixed-point theorems~\cite{KnasterTarski} and Optional Stopping Theorem (OST) \cite{williams1991probability} to synthesize polynomial bounds for NPD. 
%our choice of polynomial templates can obtain tight bounds by the heuristics that (i) polynomials can approximate any continuous function up to any prescribed precision over a bounded range (the well-known Weierstrass Approximation Theorem \cite[Section 14]{jeffreys1988weierstrass}) and (ii) continuous functions can almost approximate any measurable function (again up to any prescribed precision) in any compact set (the classical Lusin Theorem \cite[Section 4]{kestelman1960modern} in measure theory). 
%Outside the bounded range, we perform a coarse analysis that simply derives sufficient upper and lower bounds for the relevant expected values in deriving the bounds for the NPD. 
\item 
Second, to address the integrability issue from score-recursive programs, we present a novel multiplicative variant of the classical OST %\cite{williams1991probability}
%to a novel variant and address the integrability condition from the variant OST. 
%Therefore, we present an automated approach 
to derive expectation bounds.  
%to validate the finiteness of the normalising constant $p(x)$ in NPD (i.e., $0<p(x)<\infty$). 
This addresses the challenge of handling score-recursive probabilistic programs stated previously. 
\item 
Third, to increase the accuracy of the derived bounds, we propose a novel truncation operation that truncates the probabilistic program of concern onto a bounded range of program values,
%two regions: program values that fall inside a bounded range and outside the bounded range. 
which %The truncation onto the bounded range 
allows our algorithm to explore high-degree polynomials to improve the accuracy of the derived bounds. Moreover, we devise our algorithm in the way to synthesize multiple bounds for various initial program inputs to further improve the accuracy. The truncation operation and the synthesis of multiple bounds address the weakness of the existing template-based approaches in the literature. 
\item 
Finally, experimental results show that our approach can handle a wide range of benchmarks including non-parametric examples such as Pedestrian~\cite{Beutner2022b} and score-recursive examples such as phylogenetics~\cite{ronquist2021universal}. Compared with  the previous approach~\cite{Beutner2022b}, our approach reduces the runtime by up to $6$ times,  
%the runtime of  the most-related approach~\cite{Beutner2022b}  
while deriving comparable or even tighter bounds for NPD. 
\end{itemize}

 
%orders of magnitude.
%and can handle examples \cite{ronquist2021universal} that involve weight score inside a loop. 

\paragraph{Technical contributions.} Compared with the previous results on the use of template paradigm and OST, we propose a truncation operation (onto a bounded range of program values) that leverages the approximability of polynomials over a bounded region, and a multiplicative variant of OST that can handle score-recursive programs. 

\paragraph{Limitations.} One limitation is that our approach has the combinatorial explosion that when the degree of the polynomial template increases,
%(for which the higher the degree, the higher the accuracy), 
the time of the template solving increases exponentially. However, from our experimental results, a moderate choice of the degree (e.g., no more than $10$) suffices. Another is that for sampling statements with continuous distributions, our approach currently assumes polynomial density functions. However, with proper approximation via (piecewise) polynomials, our approach can handle any continuous density functions. 




