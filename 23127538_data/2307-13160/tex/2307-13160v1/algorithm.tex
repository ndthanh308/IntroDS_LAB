
In this section, we present algorithmic implementation of our theoretical approaches in \cref{sec:math}. We first have some  assumptions on the input probabilistic program: 

\begin{itemize}
\item To enable the exact calculation of the integrals over the probability density functions in a Bayesian probabilistic program possible, we assume that every probability density function in a sampling statement is a polynomial. Likewise, in score-recursive programs, we require that the probability density function in any score statement is polynomial. Our approach can handle non-polynomial density functions in sampling and score statements by having their polynomial approximations, for which we leave as a future work. 
\item 
To capture all possible program executions, we assume that the input probabilistic program is accompanied with  invariants (see e.g.~\cite{SriramCAV,SankaranarayananSM04}) to over-approximate reachable states. 
We follow ~\cite{DBLP:conf/cav/ColonSS03,SankaranarayananSM04} to consider \emph{affine invariants}.
An affine invariant for a WPTS is a map $I$ that assigns to each location $\loc$ a (conjunctive) system $I(\loc)$ of affine inequalities such that for all reachable states $(\loc, \pv)$, every affine inequality in $I(\loc)$ holds w.r.t the program values given in the program valuation $\pv$.  %satisfies the 
\end{itemize}

We also present the high-level technical setting of our algorithms.  
%\paragraph{Technical details.} 
Consider an input WPTS $\Pi$ in the form of \eqref{eq:wpts}. Recall the normalising constant $Z_\Pi$ in~\cref{def:npd}. To tighten the interval bounds for $Z_\Pi$,  
we split the set $\calV:=\supp{\mu_{\mathrm{init}}}$ of initial program valuations 
%can be split 
into $m\ge 1$ disjoint partitions $\calV_1,\dots,\calV_m$ such that $\calV=\bigcup_{i=1}^m \calV_i$ and $\calV_{i}\cap\calV_{j}=\emptyset$ for any $i\neq j\in [1,m]$.\footnote{If $m=1$, the set $\calV$ is not split.}
Our algorithms tackle each $\calV_i$ ($1\le i\le m$) separately to obtain polynomial interval bounds $[l_i,u_i]$ (where $l_i,u_i$ are polynomials) such that $l_i(\pv)\le \measureSem{\Pi}_{\pv}(\Rset^{|\pvars|})\le u_i(\pv)$ for all $\pv\in\calV_i$. It follows that 
the interval bound $[l_Z,u_Z]$ for $Z_\Pi$ can be derived by integrals of polynomial bounds over all $\calV_i$'s, that is, 
\begin{align*}\label{eq:interval-analysis}
\tag{$\clubsuit$}
l_Z:=\sum_{i=1}^m \int_{\calV_i} l_i(\pv) \mu_{\mathrm{init}}(\mathrm{d} \pv) \le Z_\Pi=\sum_{i=1}^m \int_{\calV_i} \measureSem{\Pi}_{\pv}(\Rset^{|\pvars|})\cdot \mu_{\mathrm{init}}(\mathrm{d} \pv)\le \sum_{i=1}^m \int_{\calV_i} u_i(\pv) \mu_{\mathrm{init}}(\mathrm{d} \pv)=:u_Z .
\end{align*}
Given a measurable set $\calU\in\Sigma_{\Rset^{|\pvars|}}$, the interval bounds  $[l_\calU,u_\calU]$ for the unnormalised posterior distribution $\measureSem{\Pi}(\calU)$ (in \cref{def:npd}) can be obtained analogously by deriving polynomial bounds for $\llbracket \Pi_\calU\rrbracket_{\pv}(\Rset^{|\pvars|})$ (see \cref{prop:unnorm-norm}).


Below we present our algorithmic methods to deriving interval bounds for the normalising constant. The unnormalised posterior distribution can be derived in the same manner. Our algorithms are template-based and have the following stages: 

\smallskip
\noindent\textbf{Stage 1: Input.} First, our algorithms receive a WPTS $\Pi$ parsed from a Bayesian probabilistic program $P$ written in our PPL and an affine invariant $I$ for the WPTS as the basic input. Besides, the algorithms receive as auxiliary inputs a truncation function $\trunc$ and two approximation functions $\calM_{\mathrm{up}},\calM_{\mathrm{low}}$ that respectively fulfill the conditions ($\ast$), ($\star$) in the statement of Theorem~\ref{thm:upperlower}. The truncation function is represented by the bounded intervals for each program variable, and the approximation functions are derived either from the score function at the termination of a non-score-recursive program or by applying our OST variant directly to a score-recursive program (without truncation). 
We also have two parameters $d,m$, for which $d$ is the degree of our polynomial template and $m$ is the number of partitions for the set $\calV$ of initial program valuations (refer to \eqref{eq:interval-analysis}). 

Moreover, if the program $P$ is non-score-recursive and its score function $g$ at the termination is non-polynomial, our algorithms take as extra inputs a (piecewise) polynomial approximation $g'$ of $g$ and an error bound $\epsilon> 0$ such that $|g(\pv)-g'(\pv)|\le \epsilon$ for all $\pv\in B'$ ($B'$ is the extended bounded range of program variables that derived from a one-step program run and the truncation function $\trunc$, which will be introduced in \textbf{Step A1} below).



\smallskip
\noindent\textbf{Stage 2: Partition and Truncation.} Next, 
our algorithms fetch the set $\calV=\supp{\mu_{\mathrm{init}}}$ from the WPTS $\Pi$, partition it into $m$ disjoint subsets $\calV_1,\dots,\calV_m$ and construct a set $\calW=\{\pv_1,\dots,\pv_m\}$ such that each $\pv_i\in\calV_i$. Our algorithms then perform the truncation operation to $\Pi$ w.r.t the input truncation function $\trunc$ and approximation functions $\calM_{\mathrm{up}},\calM_{\mathrm{low}}$. To synthesize upper bounds for expected weights, we take the truncation w.r.t $\trunc$ and $\calM_{\mathrm{up}}$ to generate a truncated WPTS $\Pi_{\trunc,\calM_{\mathrm{up}}}$. For lower bounds, we generate the truncated WPTS 
%truncation w.r.t $\trunc$ and $\calM_{\mathrm{low}}$ to generate a truncated WPTS 
$\Pi_{\trunc,\calM_{\mathrm{low}}}$.


\begin{example}\label{ex:pedes-algo-trunc}
Recall the Pedestrian example in \cref{sec3:pedestrian} and its WPTS $\Pi$ in \cref{fig:pedestrian-wpts}.
%To reduce the influence from the choice of the invariant, 
We derive an invariant $I$ simply from the loop guard so that $I(\lin)=pos\ge 0$ and $I(\lout)=pos<0$. 
The truncation function $\trunc$ is defined such that $\trunc(pos)=[0,5]$ and $\trunc(dis)=[0,5]$. We pick the constant approximation functions $\calM_{\mathrm{up}}=2.1\times 10^{-330}$ and $\calM_{\mathrm{low}}=0$ to bound the expected weights beyond the truncated range, so that we obtain two truncated WPTSs $ \Pi_{\trunc,\calM_{\mathrm{up}}}$ and $ \Pi_{\trunc,\calM_{\mathrm{low}}}$ which are similar to that in \cref{fig:truncated-wpts}.
 We also choose the algorithm parameters as $d=1$ and $m=30$.\footnote{We choose $d=1,m=30$ here to exemplify our algorithms, the values of $d,m$ for this example are larger in the experiments.} Since the program is non-score-recursive and its score function $g$ at the termination is non-polynomial (i.e., $g(dis)=pdf(normal(1.1,0.1),dis)$),
 %=\frac{1}{\sqrt{0.02\pi}}exp(-\frac{(dis-1.1)^2}{0.02}$), 
 we choose a polynomial approximation $g'$ of $g$ with the error bound $\epsilon=10^{-5}$. We obtain the set $\calV=\{(pos,dis)\mid pos\in [0,3],dis=0\}$. Since the value of $dis$ in $\calV$ is fixed, we partition $\calV$ uniformly into $m=30$ disjount subsets on the dimension $pos$, i.e., $\calV_1=\{(pos,dis)\mid pos\in [0,0.1],dis=0\},\dots,\calV_{30}=\{(pos,dis)\mid pos\in [2.9,3],dis=0\}$. We calculate the midpoints of the dimension $pos$ for all $\calV_i$'s, and construct the set $\calW=\{(0.05,0),(0.15,0),\dots,(2.95,0)\}$.\qed
\end{example}



\smallskip
\noindent\textbf{Stage 3: Template Solving.}
Then our algorithms establish $d$-degree polynomial templates for $ \Pi_{\trunc,\calM_{\mathrm{up}}}$ and $ \Pi_{\trunc,\calM_{\mathrm{low}}}$, and synthesize polynomial upper and lower bounds for the expected weights $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}}\rrbracket_{\pv_i}(\Rset^{|\pvars|})$ and $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}}\rrbracket_{\pv_i}(\Rset^{|\pvars|})$ for each initial program valuation $\pv_i\in\calV_i$ in $\calW$
%and its surrounded range $\calV_i$ 
by solving the templates w.r.t the PUWF and PLWF constraints (i.e., (C1), (C2), (C1') from \cref{def:puwf}), respectively. 
The correctness of this stage follows from \cref{thm:fix-point-bounds} and \cref{thm:puwf-normalizing}. 

Note that \cref{thm:fix-point-bounds} and \cref{thm:puwf-normalizing} have prerequisites and we check these prerequisites in a succinct fashion as follows. 
%\paragraph{Verificiation of Prerequisites.} 
For \cref{thm:fix-point-bounds}, we manually verify the AST property by the approaches of \cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/ChatterjeeFNH16}, and check the score-bounded property by a direct manual inspection.  
%checking which can also be done automatically. 
For \cref{thm:puwf-normalizing}, we check the condition (E1) by approaches such as \cite{DBLP:journals/toplas/ChatterjeeFNH18,DBLP:conf/pldi/WangS0CG21}, the condition (E2) by a manual examination,
and the bounded update property by simple check on whether the update value is bounded by a constant. The checking of the AST can be automated by template-based approaches~\cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/ChatterjeeFNH16}, and other simple prerequisites can be easily automated (via e.g. SMT solvers). We leave a fuller implementation that incorporate these features as a future work. 


Below we present the detailed steps (\textbf{Step A1} -- \textbf{A4}) of our template solving.



\smallskip
\noindent\textbf{Step A1.} Consider the truncated WPTS $\Pi_{\trunc,\calM_{\mathrm{up}}}$ (to derive an upper bound) or $\Pi_{\trunc,\calM_{\mathrm{low}}}$ (to derive a lower bound). We denote the bounded range from the truncation function $\trunc$ by $B:=\{\pv\mid \pv(x)\in \trunc(x)\mbox{ for all }x\in\pvars\}$. In this step, both of our algorithms  compute an extended bounded range $B'$ such that any program valuation from a one-step execution of the WPTS under any current program valuation in $B$ falls in $B'$. Formally, the extended bounded range $B'$ satisfies that 
%(i) using our OST variant (\cref{thm:puwf-normalizing}) and (ii) 
for every location $\loc$, program valuation $\pv\in B$, transition $\tau=\langle \loc, \phi, F_1,F_2,\dots,F_k \rangle$, fork  $F_j=\langle \loc'_j, p_j, \upd_j,\wet_j \rangle$ in $\tau$ and sampling valuation $\rv\in \supp{\rdvarjdis}$, we have that $\upd_j(\pv,\rv)\in B'$. 
%and for all sampling valuations $\rv\in support$ it holds that $\upd_j(\pv,\rv)\in B'$. 
Our algorithms determine the extended bounded range $B'$ by examining the assignment statements in the truncated WPTS $\Pi_{\trunc,\calM_{\mathrm{up}}}$.  
The purpose to have a superset $B'$ of the original bounded range $B$ is to reduce the runtime in the solving of the template, see \textbf{Step A3} below.  

\begin{example}
Recall \cref{ex:pedes-algo-trunc}, the bounded range from the truncation function $\trunc$ is denoted by $B=\{(pos,dis)\mid pos\in [0,5], dis\in [0,5]\}$. For $\Pi_{\trunc,\calM_{\mathrm{up}}}$ or $\Pi_{\trunc,\calM_{\mathrm{low}}}$, the extended bounded range is given by $B'=\{(pos,dis)\mid pos\in [-1,6],dis\in [0,6]\}$.\qed
%Given an initial program valuation $\valin=(pos=1,dis=0)$. Let $B=\{(pos,dis)\mid pos\in [0,5], dis\in [0,5]\}$, $B'=\{(pos,dis)\mid pos\in [-1,6],dis\in [0,6]\}$.
\end{example}




\smallskip
\noindent\textbf{Step A2.} In this step, 
at each location $\loc\not\in \{\lout,\sharp\}$, our algorithms
set up a $d$-degree polynomial template $h_\loc$ over the program variables $\pvars$.
Each template $h_\loc$ is a summation of all monomials of degree no more than $d$ and each monomial is multiplied with
a fresh unknown coefficient as a parameter to be resolved. For $\loc\in \{\lout,\sharp\}$, our algorithms assume $h_\loc\equiv 1$. 
\begin{example}\label{ex:pedes-algo-A2}
  Recall \cref{ex:pedes-algo-trunc}, the algorithm parameter $d=1$. 
  For either $\Pi_{\trunc,\calM_{\mathrm{up}}}$ or $\Pi_{\trunc,\calM_{\mathrm{low}}}$, we construct a $1$-degree polynomial template at the location $\lin$, i.e., $h_{\lin}(pos,dis)=a_1\cdot pos+a_2\cdot dis +a_3$ where $a_1,a_2,a_3\in\Rset$ are unknown coefficients to be resolved, and let $h_{\lout}=h_{\loc_\sharp}=1$.\qed
\end{example}

\smallskip
\noindent\textbf{Step A3.} In this step, our algorithms establish constraints for the templates $h_\loc$'s from (C1), (C1') in \cref{def:puwf} (as (C2) is satisfied by the construction of $h_\loc$ in the previous step). 
For upper bounds on expected weights, our algorithms have the following relaxed constraints of (C1) to synthesize a PUWF over $\Pi_{\trunc,M_{up}}$: 


\begin{itemize}
\item[(D1)] For every location $\loc \in\locs\setminus\{\lout,\sharp\}$ and program valuation $\pv\in I(\loc) \cap B$, we have that $\ewt(h)(\loc,\pv) \le h(\loc, \pv)$.  
\item[(D2)] For every location $\loc\in\locs\setminus \{\lout,\sharp\}$ and program valuation $\mathbf{v}\in I(\loc) \cap (B'\setminus B)$, we have that $\calM_{\mathrm{up}}(\pv)\le h(\loc,\pv)$.    
\end{itemize}
For lower bounds over $\Pi_{\trunc,M_{low}}$, our algorithms have the relaxed PLWF constraints (D1') and (D2') which are obtained from (D1) and resp. (D2) by replacing ``$\ewt(h)(\loc,\pv) \le h(\loc, \pv)$'' with ``$\ewt(h)(\loc,\pv) \ge h(\loc, \pv)$'' in (D1) and resp. ``$\calM_{\mathrm{up}}(\pv)\le h(\loc,\pv)$'' with ``$\calM_{\mathrm{low}}(\pv)\ge h(\loc,\pv)$'' in (D2), respectively. 
We have that (D1) and (D2) together ensure (C1)  since $\calM_{\mathrm{up}}(\pv)\le h(\loc,\pv)$ implies that $\ewt(h)(\loc,\pv) \le h(\loc, \pv)$ for every location $\loc \in\locs\setminus\{\lout,\sharp\}$ and program valuation $\pv\in I(\loc) \cap (B'\setminus B)$. The same holds for (D1') and (D2'). 

Note that in (D1), the calculation of the value $\ewt(h)(\loc,\pv)$ has the piecewise nature that different sampling valuations $\rv$ may cause the next program valuation to be within or outside the bounded range, and to satisfy or violate the guards of the transitions in the WPTS. In our algorithms, we have a fine-grained treatment for (D1) that enumerates all possible situations for a sampling valuation $\rv$ that satisfy different guards of the WPTS in the calculation of $\ewt(h)(\loc,\pv)$, for which we use an SMT solver (e.g., Z3~\cite{Z3paper}) to compute the situations. As for (D2), we use (D2) to avoid handling the piecewise feature \changed[fu]{in the computation of $\ewt(h)(\loc,\pv)$} from 
%have a coarse treatment for 
within/outside the bounded range (i.e., the computation is a direct computation over a single-piece polynomial), so that the amount of computation of $\ewt(h)(\loc,\pv)$ is reduced by ignoring the piecewise feature. The use of (D2) to reduce the computation is the aim of introducing an extended bounded range in \textbf{Step A1}. The same also holds for (D1') and (D2'). 

If $\Pi$ is non-score-recursive and the score function $g$ at termination is non-polynomial, our algorithms replace $g$ in the expression $\ewt(h)(\loc,\pv)$ with its polynomial approximation $g'$.

\begin{example}\label{ex:pedes-algo-A3}
Recall \cref{ex:pedes-algo-trunc}--\cref{ex:pedes-algo-A2}, 
  % $I(\lin)=pos\ge 0$ is refined into (i) $I_1(\lin)=0 \le pos< 1$ and (ii) $I_2(\lin)=pos\ge 1$. 
  the bounded range $\calD_1=I(\lin)\cap B$ in (D1) is defined such that $ pos\in [0,5]\wedge dis\in [0,5]$. Consider to derive upper bounds from $\Pi_{\trunc,\calM_{\mathrm{up}}}$. We make a fine-grained treatment for (D1) by splitting the range $\calD_1$ and enumerating all possible situations for the sampling valuation $\textbf{sample uniform}(0,1)$ that the next program valuation satisfies or violates the loop guard ``$pos\ge 0$''. In detail, $\calD_1$ is split into $\calD_{11}=\{(pos,dis)\mid pos\in [0,1), dis\in [0,5]\}$ and $\calD_{12}=\{(pos,dis)\mid pos\in (1,5], dis\in [0,5]\}$, where $\calD_{11}$ stands for the situation that with different sampling valuations the next program valuation may satisfy the loop guard (so that the next location is $\lin$) or violate the loop guard (so that the next location is directed to $\lout$), and  $\calD_{12}$ stands for the situation that the next program valuation will definitely satisfy the loop guard and the next location is $\lin$. 
  For the non-polynomial score function $g$ at the termination of the example, 
  %in $\ewt(h)(\loc,\pv)$, 
  we replace it with a polynomial approximation $g'$ under the error bound $10^{-5}$.  
  
We first show the PUWF constraints for $\Pi_{\trunc,\calM_{\mathrm{up}}}$.
Recall that the program has two probabilistic branches with probability $0.5$. When the current program valuation is in $\calD_{11}$, we observe that 
\begin{itemize}
\item if the loop takes the branch $pos:=pos+step$, then the next value of $pos$ remains to be non-negative and the loop continues, and 
\item if the loop takes the branch $pos:=pos-step$, then it is both possible that the next value of $pos$ satisfy or violate the loop guard, depending on the exact value of $step\in [0,1]$. 
\end{itemize}
Then we have the constraint (D1.1) over $\calD_{11}$ that has expectation over a piecewise function on $step$ derived from whether the loop terminates in the next iteration or not, as follows:
\begin{itemize}
\item[(D1.1)] $\forall pos,dis.$ $pos\in [0,1)\wedge dis\in [0,5] \Rightarrow$
	\begin{align*}
	&0.5\cdot\expectdist{step}{[pos-step\ge 0]\cdot h_{\lin}(pos-step,dis+step)+[pos-step<0]\cdot g'(dis)}\\ +& 0.5\cdot\expectdist{step}{h_{\lin}(pos+step,dis+step)}\le h_{\lin}(pos,dis).
	\end{align*} 
  \end{itemize}
When the current program valuation is in $\calD_{12}$, we observe that the next program valuation is guaranteed to satisfy the loop guard, and hence we have the constraint  
$\calD_{12}$ as follows: 
\begin{itemize}
      \item[(D1.2)] $\forall pos,dis.$ $pos\in (1,5]\wedge dis\in [0,5]\Rightarrow$
	\begin{align*}
	0.5\cdot\expectdist{step}{h_{\lin}(pos-step,dis+step)}+0.5\cdot\expectdist{step}{h_{\lin}(pos+step,dis+step)}\le h_{\lin}(pos,dis).	
	\end{align*}
  \end{itemize}
The range $\calD_2=I(\lin) \cap (B'\setminus B)$ in (D2) is represented by the disjunctive formula $\Phi:=(pos\in [0,6]\wedge dis\in [5,6])\vee (pos\in [5,6]\wedge dis\in [0,6])$. For the program valuation in $\calD_2$, its next location is $\loc_\sharp$. Recall the constant approximation functions $\calM_{\mathrm{up}}=2.1\times 10^{-330}$ and $\calM_{\mathrm{low}}=0$. From (D2), we have two constraints from the disjunctive clauses in $\Phi$
%for the range $\calD_2$ 
as follows:
\begin{itemize}
    \item[(D2.1)] $\forall pos,dis.$ $pos\in [0,6]\wedge dis\in [5,6]\Rightarrow 2.1\times 10^{-330}\le h_{\lin}(pos,dis)$. 
	\item[(D2.2)] $\forall pos,dis.$ $pos\in [5,6]\wedge dis\in [0,6]\Rightarrow 2.1\times 10^{-330}\le h_{\lin}(pos,dis)$. 
\end{itemize} 
For $\Pi_{\trunc,\calM_{\mathrm{low}}}$, the PLWF constraints (D1'.1) to (D2'.2) are obtained from the PUWF constraints above by replacing ``$\le$'' with ``$\ge$'' and $2.1\times 10^{-330}$ with $0$. \qed
\end{example}



\smallskip
\noindent\textbf{Step A4.} In this step, for every initial program valuation $\pv_i\in\calV_i$ in $\calW$ where $\calV_i$'s and $\calW$ are obtained from \textbf{Stage 2}, our algorithms solve the unknown coefficients in the templates $h_\loc$ ($\loc\in \locs\setminus \{\lout,\sharp\}$ via the well-established methods of Putinar's Positivstellensatz~\cite{putinar} or Handelman's Theorem~\cite{handelman1988representing}.
%To be more detailed, 
To be more detailed, our algorithms minimize (resp. maximize) the objective function $h_{\lin}(\pv_i)$ for each $\pv_i$ in $\calW$ which subjects to the PUWF (resp. PLWF) constraints from the previous step to derive polynomial upper (resp. lower) bounds over $\Pi_{\trunc,\calM_{\mathrm{up}}}$ (resp. $\Pi_{\trunc,\calM_{\mathrm{low}}}$), respectively. 


Note that the PUWF or PLWF constraints from \textbf{Step A4}
can be represented as a conjunction of formulas in the form $\forall\pv\in \calP.(\mathbf{g}(\pv)\ge 0)$ where the set $\calP$ is defined by a conjunction of polynomial inequalities in the program variables and $\mathbf{g}$ is a polynomial over $\pvars$ whose coefficients are affine expressions in the \changed[fu]{unknown coefficients} from the templates, and such formulas can be guaranteed by the sound forms of Putinar's Positivstellensatz and Handelman's Theorem. The application of Putinar's Positivstellensatz results in semidefinite constraints and can be solved by semidefinite programming (SDP), while the application of Handelman's Theorem \changed[fu]{is restricted to the affine case (i.e., every condition and assignment in the WPTS is affine)} and leads to linear constraints and can be solved by linear programming (LP). 
We refer to Appendix~\ref{app:sec5} for the details on the application of Putinar's Positivstellensatz and Handelman's Theorem. 

If the polynomial approximation is applied in the calculation of $\ewt(h)(\loc,\pv)$ in \textbf{Step A3}, we show that the error of the final results will be bounded by the polynomial approximation error bound $\epsilon$. See \cref{app:score-error} in the \cref{app:sec5}.



\begin{example}\label{ex:pedes-algo-A4}
Recall \cref{ex:pedes-algo-trunc}--\cref{ex:pedes-algo-A3}, we have that $\calV_1=\{(pos,dis)\mid pos\in [0,0.1],dis=0\},\dots,\calV_{30}=\{(pos,dis)\mid pos\in [2.9,3],dis=0\}$ and
the set $\calW=\{(0.05,0),(0.15,0),\dots,(2.95,0)\}$. 
%For each point in $\calW$, we solve two optimization problems. For instance, 
Pick a point $\pv_1=(0.05,0)\in\calV_1$ from $\calW$, to synthesize the upper bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}}\rrbracket_{\pv_1}(\Rset^{|\pvars|})$ as tight as possible,
we solve the following optimization problem whose objective function is $h_{\lin}(0.05,0)$, i.e., 
$$\textstyle \textbf{Minimize}~~~~~ 0.05\cdot a_1+a_3$$
$$
\textstyle \textbf{Subject to}~~~~~\text{constraints (D1.1)--(D2.2)}
$$
The lower bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}}\rrbracket_{\pv_1}(\Rset^{|\pvars|})$ is solved by 
$$\textstyle \textbf{Maximize}~~~~~ 0.05\cdot a_1+a_3$$
$$
\textstyle \textbf{Subject to}~~~~~\text{constraints (D1'.1)--(D2'.2)}
$$
Although the constraints are universally quantified, the universal quantifiers can be soundly (but not completely) removed and relaxed into semidefinite constraints over the unknown coefficients $a_i$'s by applying Putinar's Positivstellensatz, where
we over-approximate all strict inequalities (e.g., ''$<$'') by non-strict ones (e.g., ``$\le$''). Then we call a SDP solver to solve the two optimization problems and find the solutions of $a_i$'s, which will generate two polynomial bound functions $Up_1,Lw_1$ such that $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}}\rrbracket_{\pv}(\Rset^{|\pvars|}) \le Up_1(\pv)+\epsilon$ and $Lw_1(\pv)-\epsilon \le \llbracket \Pi_{\trunc,\calM_{\mathrm{low}}}\rrbracket_{\pv}(\Rset^{|\pvars|})$ for all program valuation $\pv\in\calV_1$ where the error bound $\epsilon=10^{-5}$.    \qed
\end{example}




\noindent\textbf{Stage 4: Integration.}
As a consequence of \textbf{Stage 3}, our algorithms obtain a group of concrete polynomial upper bound functions  (resp. lower bound functions)  $Upper=\{Up_1,\dots,Up_m\}$ (resp. $Lower=\{Lw_1,\dots,Lw_m\}$) for the expected weights $\{ \llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket_{\pv_1}(\Rset^{|\pvars|}), \dots,  \llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket_{\pv_m}(\Rset^{|\pvars|}) \}$ (resp. $\{ \llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket_{\pv_1}(\Rset^{|\pvars|}), \dots, \llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket_{\pv_m}(\Rset^{|\pvars|}) \}$), respectively. 
Then our algorithms integrate these polynomial upper and lower bound functions to derive the upper and lower bounds for $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})$ and $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|})$, respectively.
%According to the group of polynomial upper and lower bounds from the previous stage, our algorithms compute the upper bound 
For $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})$, we have that
\begin{align}\label{eq:nc-upper}
\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})\le \sum_{i=1}^m \int_{\calV_i} Up_i(\pv) \mathrm{d}\pv=:u_{Z}
\end{align}
and the lower bound for $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|})$ is given by
\begin{align}\label{eq:nc-lower}
l_Z:=\sum_{i=1}^m \int_{\calV_i} Lw_i(\pv) \mathrm{d}\pv \le \llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|})  
\end{align}

If $\Pi$ is non-score-recursive and the score function $g$ at termination is non-polynomial, our algorithms integrate the approximation error $\varsigma=\mathrm{volume}(\calV)\cdot\epsilon$ caused by polynomial approximation of $g$ to the two bounds, i.e, $l'_Z=l_Z-\varsigma$ and $u'_Z=u_Z+\varsigma$, where $\mathrm{volume}(\calV)$ is the volume of $\calV$. In practice, to ensure the tightness of the interval bounds, we can control the amount of $\epsilon$ so that the approximation error $\varsigma$ is at least one magnitude smaller than the values of $l_Z,u_Z$. 



\begin{theorem}[Soundness]
	If our algorithms find valid solutions for the unknown coefficients of the templates, they return correct interval bounds for the normalising constant $Z_\Pi$.
\end{theorem}

\begin{proof}[Proof Sketch.]
	By \cref{thm:fix-point-bounds} (resp.\cref{thm:puwf-normalizing}), if the algorithms successfully find valid solutions for the unknown coefficients of the templates, we can obtain the polynomial upper bound $u_Z$ (resp. lower bound $l_Z$) for $\llbracket \Pi_{\trunc,\calM_{\mathrm{up}}} \rrbracket (\Rset^{|\pvars|})$ (resp. $\llbracket \Pi_{\trunc,\calM_{\mathrm{low}}} \rrbracket (\Rset^{|\pvars|})$), respectively. Then by \cref{thm:upperlower}, the polynomial upper bound $u_Z$ is also the upper bound for $\llbracket \Pi \rrbracket (\Rset^{|\pvars|})$ and $l_Z$ is the lower bound for $\llbracket \Pi \rrbracket (\Rset^{|\pvars|})$. The same holds for the bounds $l'_Z,u'_Z$ if polynomial approximation of non-polynomial score functions happens.
 %Through the integration computation over polynomial bounds, we can have the interval bounds for NPDs.
\end{proof}




