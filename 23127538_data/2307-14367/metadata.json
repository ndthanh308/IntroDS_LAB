{
  "title": "Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers",
  "authors": [
    "Hadi Abdine",
    "Michail Chatzianastasis",
    "Costas Bouyioukos",
    "Michalis Vazirgiannis"
  ],
  "submission_date": "2023-07-25T09:35:43+00:00",
  "revised_dates": [
    "2023-12-22T01:22:44+00:00",
    "2024-04-23T00:18:18+00:00"
  ],
  "abstract": "In recent years, significant progress has been made in the field of protein function prediction with the development of various machine-learning approaches. However, most existing methods formulate the task as a multi-classification problem, i.e. assigning predefined labels to proteins. In this work, we propose a novel approach, Prot2Text, which predicts a protein's function in a free text style, moving beyond the conventional binary or categorical classifications. By combining Graph Neural Networks(GNNs) and Large Language Models(LLMs), in an encoder-decoder framework, our model effectively integrates diverse data types including protein sequence, structure, and textual annotation and description. This multimodal approach allows for a holistic representation of proteins' functions, enabling the generation of detailed and accurate functional descriptions. To evaluate our model, we extracted a multimodal protein dataset from SwissProt, and demonstrate empirically the effectiveness of Prot2Text. These results highlight the transformative impact of multimodal models, specifically the fusion of GNNs and LLMs, empowering researchers with powerful tools for more accurate function prediction of existing as well as first-to-see proteins.",
  "categories": [
    "q-bio.QM",
    "cs.CL",
    "cs.LG"
  ],
  "primary_category": "q-bio.QM",
  "doi": "10.1609/aaai.v38i10.28948",
  "journal_ref": "Proceedings of the AAAI Conference on Artificial Intelligence, 38(10), 10757-10765 (2024)",
  "arxiv_id": "2307.14367",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 7023874,
  "size_after_bytes": 375907
}