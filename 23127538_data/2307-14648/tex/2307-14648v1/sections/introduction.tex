\section{Introduction} \label{sec:intro}
The Denoising Diffusion Probabilistic Model (DDPM)~\cite{DBLP:conf/nips/HoJA20} has garnered significant attention owing to its exceptional capability to generate high-fidelity images, surpassing GANs~\cite{goodfellow2014generative,
Xu18,
Han17,Karras2019stylegan2} in
quality in many circumstances. The fundamental concept behind DDPM entails the gradual corruption of the input signal with noise, eventually conforming it to a pre-defined distribution, such as the Gaussian distribution. Subsequently, a denoising network is learned to restore the original sample, effectively removing the introduced noise.

The input signal can be from either the pixel space~\cite{DBLP:conf/icml/NicholD21,DBLP:conf/nips/DhariwalN21,DBLP:journals/corr/abs-2207-12598} or the latent space~\cite{DBLP:conf/cvpr/RombachBLEO22,DBLP:journals/corr/abs-2304-09787}. However, the focus of our investigation lies in the wavelet space. This is motivated by the widespread utilization of wavelet transforms in image processing tasks, such as image denoising~\cite{tian2023multi,huang2022winnet}. In the context of DDPM, the denoising network plays a pivotal role in eliminating noise, a task closely resembling image denoising itself. By utilizing wavelet transforms, the image can be represented in both spatial and frequency domains, facilitating explicit modeling of relations between signals across different frequencies. The goal is to leverage these characteristics to potentially achieve enhanced performance.

\input{figs/motivation}

Although DDPMs in the pixel space and the latent space have been extensively studied in existing works, the exploration of the wavelet space remains relatively under-explored.
A closely related work in this field is WaveDiff~\cite{DBLP:journals/corr/abs-2211-16152}, which aims to strike a balance between efficiency and sample quality by combining Discrete/Inverse Wavelet Transformation (D/IWT) with DDGAN~\cite{DBLP:conf/iclr/XiaoKV22}. In WaveDiff, the signal undergoes wavelet transformation and inverse transformation multiple times within the network.
Meanwhile, as shown in Figure~\ref{fig:wavediff}, the training process of WaveDiff necessitates the presence of an auxiliary discriminator, guided by adversarial losses.
In contrast, our objective is to develop an effective network specifically for the wavelet space, while maintaining compatibility with the vanilla DDPM training paradigm. 
This is not a trivial task, as the computational operators (\textit{e.g.}, convolution and  attention mechanisms), and the denoising objectives are primarily tailored for pixel space diffusion.

Specifically, we propose a novel architecture \ourmodel (Figure~\ref{fig:ours}) for the diffusion and denoising process purely in wavelet space. With the wavelet transform (Haar transform~\cite{DBLP:journals/siamrev/Brewster93} in our experiments), the 2D input image is mapped into a 3D signal, where two dimensions represent the spatial domains and one represents frequency. To fully correlate the frequency domain, we incorporate a 1D convolutional layer along the frequency dimension in addition to the 2D convolutional layers along the spatial dimensions.
Recognizing that convolution is less effective at capturing global correlations, we further enhance our model by incorporating attention mechanisms. We apply attention at both each spatial location across different frequencies and each frequency across different spatial locations. 
By employing these separable modules, we can efficiently process high-dimensional inputs, offering improved performance compared to full 3D convolutional layers and full attention mechanisms that operate on all locations and frequencies.

During training, we optimize the model using the mean squared error (MSE) loss to predict noise over all diffusion timesteps, following the vanilla diffusion model in pixel space. During inference, the restored wavelet signal is transformed back into the pixel space, leveraging the reversibility of the wavelet transform. Despite its simplicity, our model consistently outperforms existing approaches on multiple datasets, including CIFAR-10~\cite{cifar10}, FFHQ-256~\cite{DBLP:conf/cvpr/KarrasLA19}, LSUN-Bedroom-256~\cite{LSUN}, and LSUN-Church-256~\cite{LSUN}.

We summarize our contributions as two-fold:
\vspace{-0.5em}
\begin{itemize}[leftmargin=.15in]
\setlength\itemsep{0.2em}
    \item{%
      \textbf{Spatial-Frequency-aware Architectural Design.}~
      The architecture of \ourmodel is specifically and carefully designed for wavelet data. By explicitly processing and exploiting the information from both spatial and frequency subspaces, the distribution of image contents (\textit{i.e.,} spatial components across different frequencies)  and local details (\textit{i.e.,} high-frequency components) can be better converged to reverse the forward diffusion process. The newly designed modules in \ourmodel can be easily dropped in to DDPM U-Net without affecting the default structure.
   }%
   \item{%
      \textbf{High Quality of Image Generation.}~
      Our \ourmodel can generate high-quality images with clear details, achieving excellent quantitative and qualitative results under common evaluation protocols. 
   }%
\end{itemize}