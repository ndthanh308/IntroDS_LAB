% We develop a novel architecture for Denoising Diffusion Probabilistic Model (DDPM), wrapping a new set of convolutional operators and attention mechanisms within U-Net to connect information from wavelet space.
% Unlike existing wavelet-based architectures  with independent computation of high and low subbands through standard 2D convolutions, our method explicitly captures the coherence for both spatial and frequency domain.
% To acquire domain-agnostic property while maintaining domain-specific processing capability, we propose to transform and parallelly process the wavelets of spatial and frequency subspaces with complementary information.
% Our new architecture is compatible with the standard denoising diffusion process, without any auxiliary optimization terms during training.
% Experimental results demonstrate that our method is able to generate images with higher quality on CIFAR-10, FFHQ, Bedroom and Church datasets, compared with standard DDPM.
In this paper, we study the denoising diffusion probabilistic model (DDPM) in wavelet space, instead of pixel space, for visual synthesis. Considering the wavelet transform represents the image in spatial and frequency domains, we carefully design a novel architecture \ourmodel
to effectively capture the correlation for both domains.
% Specifically, we supplement the 2D convolutions and spatial-only self-attention layers in the standard denoising U-Net for pixel data with our spatial-frequency-aware convolution and attention modules to jointly model the complementary information from spatial and frequency domains in wavelet data.
Specifically, in the standard denoising U-Net for pixel data, we supplement the 2D convolutions and spatial-only attention layers  with our spatial frequency-aware convolution and attention modules to jointly model the complementary information from spatial and frequency domains in wavelet data.
Our new architecture can be used as a drop-in replacement to 
the pixel-based network and is compatible with the vanilla DDPM training process.
By explicitly modeling the wavelet signals, we find our model
is able to generate images with higher quality on CIFAR-10, FFHQ, LSUN-Bedroom, and LSUN-Church datasets, than the pixel-based counterpart. 