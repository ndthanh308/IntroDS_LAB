\section{Conclusion}
\textbf{Contributions.} \ourmodel is a new U-Net architecture for DDPMs in the wavelet domain that can produce realistic images in high quality.
With carefully designed spatial-frequency modules, \ourmodel obtains the capability in learning complementary information from  all frequency subspaces and capturing the spatial coherence simultaneously.
Though \ourmodel contains several components, it is not a collection of orthogonal innovations.
Rather, these components are designed to weave together for a high-level vision: enabling effective DDPM training in the wavelet space while maintaining the compatibility with the standard diffusion process and minimizing the efforts in designing a new optimization recipe.
Quantitative and qualitative results on multiple datasets, together with ablations and analyses demonstrate the effectiveness of our method.

\textbf{Limitations and Future Work.}
We investigated how to effectively adapt DDPM training process to input signals from wavelet space,
and proposed a new architecture that explicitly learns to recover all  frequency components guided by the simple denoising objective.
% In a future investigation, it might be interesting to 
The limitation of this work sheds light on potential future directions, \textit{e.g.}, to conduct deeper analysis onto the generated high-frequency components, with the goal of formulating a more fine-grained image processing framework through controllable wavelets generation and editing.

\textbf{Broader Impacts.}
The improved image quality in DDPM with our proposed \ourmodel may bring up new possibilities in application scenarios, however,  it also
% it may bring up potential misuse. 
% For example, generative modeling can be used to generate fake images or  manipulate existing images. We are aware of this risk, 
requires
proper regulations for mitigating potential harm from the misuse of such generative models, for example the creation of deceptive content and 
infringement of human rights.
% and will follow the guideline of responsible AI to detect and avoid such misuse.
% Fortunately, researchers are aware of this concern and have devoted great efforts in developing new tools to detect and avoid such misuse, following the guideline of responsible AI.  


