\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{4} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Few-shot $\mathbf{1/a}$ Anomalies Feedback : Damage Vision Mining Opportunity and Embedding Feature Imbalance}

\author{Takato Yasuno\\
{\tt\small yasunotkt@gmail.com}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
In past decade, previous balanced datasets have been used to advance algorithms for classification, object detection, semantic segmentation, and anomaly detection in industrial applications. Specifically, for condition-based maintenance, automating visual inspection is crucial to ensure high quality. Deterioration prognostic attempts to optimize the fine decision process for predictive maintenance and proactive repair. In civil infrastructure and living environment, damage data mining cannot avoid the imbalanced data issue because of rare unseen events and high quality status by improved operations.
For visual inspection, deteriorated class acquired from the surface of concrete and steel components are occasionally imbalanced. From numerous related surveys, we summarize that imbalanced data problems can be categorized into four types; 1) missing range of target and label valuables, 2) majority-minority class imbalance, 3) foreground-background of spatial imbalance, 4) long-tailed class of pixel-wise imbalance. Since 2015, there has been many imbalanced studies using deep learning approaches that includes regression, image classification, object detection, semantic segmentation. However, anomaly detection for imbalanced data is not yet well known.  
In the study, we highlight one-class anomaly detection application whether anomalous class or not, and demonstrate clear examples on imbalanced vision datasets: medical disease, hazardous behavior, material deterioration, plant disease, river sludge, and disaster damage. 
Illustrated in Figure \ref{fig:DamageVisionMining}, we provide key results on damage vision mining advantage, hypothesizing that the more effective range of positive ratio, the higher accuracy gain of anomalies feedback. 
% key results
In our imbalanced studies, compared with the balanced case of positive ratio 1/1, we find that there is applicable positive ratio $1/a$, where the accuracy are consistently high. However, extremely imbalanced range from one-shot to $1/2a$, whose accuracy are inferior to those of applicable ratio. In contrast, ranged with positive ratio over $2/a$, it is shifting in over-mining phase without effective gain of accuracy.  
\end{abstract}

% Figure environment removed

%%%%%%%%% BODY TEXT Ch.1
\section{Introduction}
\subsection{Related Works for Imbalanced Vision Data}
\subsubsection{Imbalanced Regression}
In the study, we reviewed previous machine learning approach toward imbalanced data. As shown in Table~\ref{tab:imbset}, we pointed out the imbalanced settings and unbiased technique examples. 
Regarding the imbalanced regression, Yang et al. defined Deep Imbalanced Regression (DIR) dealing with potential missing data for continuous target values, and the {\it distribution smoothing} techniques for both labels and features were presented \cite{Yang2021}, illustrated in Figure \ref{fig:SmoothReg}. The smoothing regression techniques were applied to five datasets with the missing value range such as age, categorical label, and health score.   
Stocksieker et al. presented a data augmentation (DA) algorithm that combines a weighted resampling (WR) and a DA procedure \cite{Stocksieker2023}. Using Generalized Additive Models under synthetic data generators, six DA approaches were compared such as Gaussian noise, smoothed bootstrap, k-Nearest Neighbors, Gaussian Mixture Models, and Gaussian Coupula. However, the effect of the mean square error using DA-WR approach were dependent on the choice of the imbalanced data generator, and any DA technique had not been clearly found to improve imbalanced regression.   

% Figure environment removed

% Figure environment removed

\subsubsection{Imbalanced Image Classification}
To address imbalanced image classification between majority classes and minority classes, a previous common preprocess is resampling-based approaches to the initial setting dataset. These are categorized into synthetic oversampling from minority classes \cite{Kim2019,Piras2012}, undersampling on majority classes \cite{Koziarski2020}, and a combination of both \cite{Batista2004,Zhu2020}. 
Another loss function-based approach is to employ cost sensitive learning, such as reweighting sample-wise loss by inverse class frequency and by assigning relatively higher loss \cite{Lin2017,Wang2020}. 
In addition, Chen et al. represented the {\it complement cross entropy} (CCE) \cite{Chen2019,Kim2020}, illustrated in Figure \ref{fig:CompleCE}. 
The CCE is evenly suppressing softmax probabilities on incorrect classes during training, and demonstrated the efficacy. However, it has a limitation which induces a complement training time approximately two times longer because of twice back-propagation per each iteration.  

In medical image classification, Kieu et al. provided a survey of deep learning for lung disease
detection\cite{Kieu2020}. They discussed data imbalance as an issue and future direction of lung disease detection using deep learning. When training image classification, if the number of samples of one class is extremely higher than the other class, the resulting model would be biased. It is better to have the balanced number of images in each class. However, lung disease is relatively rare events that is not the balanced case. Under an initial phase of insufficient infection vision mining, when learning a multi-class classification of COVID-19, pneumonia and normal lungs, the number of images for pneumonia far exceeded the number of unseen infection images. After lots of pandemic experience and international collaboration in medical doctors, the COVID-19 radiography database \cite{Kaggle2021} has been updated, so that the 3616 positive images of COVID-19 in chest X-ray are publicly available \cite{Khan2022}.
In the study, we present ablation studies on imbalanced positive ratio in the lung infection dataset that includes several small ratio of COVID-19 anomalies and normal images.   

\begin{table*}[h]
\centering
\caption{Damage learning methods and clear examples under imbalanced settings}
\label{tab:imbset}
\begin{tabular}{|c|c|c|c|}
		\hline
\textbf{Imbalance} & \textbf{Typical data} & \textbf{Learning method} & \textbf{Clear examples} \\
		\hline
Missing & Continuous Target, Label & Regression & Distribution Smoothing\cite{Stocksieker2023,Yang2021} \\
Class & Majority-Minority & Image Classification & Resample\cite{Kim2019,Koziarski2020}, Reweight \cite{Lin2017,Wang2020}, Complement\cite{Chen2019} \\
Object & Bounding Box & Object Detection & Handling scale \& objective imbalance\cite{Agarwal2018,Oksuzy2020,Zou2018} \\
Spatial & Foreground-Background & Object Detection & Handling spatial imbalance\cite{Agarwal2018,Oksuzy2020} \\
Pixel-wise & Long-tailed classes & Semantic Segmentation & Center Collapse, Equiangular Tight Frame \cite{Li2022,Zhong2023} \\
		\hline
\end{tabular}
\end{table*}

\subsubsection{Imbalanced Object Detection}
Since 2015, comprehensive object detection surveys \cite{Agarwal2018,Zou2018} have been provided in terms of methods for handling scale imbalance and spatial imbalance. There are also surveys on industrial domain-specific object detection, such as vehicle detection\cite{Sun2006}, pedestrian detection\cite{Dollar2012}, face detection\cite{Zafeiriou2015,Bai2017}. Sun et al. \cite{Sun2006} and Dollar et al. \cite{Dollar2012} cover the methods from the imbalance point of view since they present a comprehensive analysis of feature extraction methods that handle scale imbalance. Additionally, Litjens et al. \cite{Litjens2017} discuss deep learning applications to medical image analysis, that present challenges with their possible solutions including a limited exploration of the class imbalance problem.

Systematically, Oksuzy et al. reviewed the object detection literature and identified eight imbalance problems \cite{Oksuzy2020}, illustrated in Figure \ref{fig:Imb4Catego}.
Clearly, they grouped into four main types: {\it class imbalance, scale imbalance, spatial imbalance} and {\it objective imbalance}. First, class imbalance occurs when there is significant inequality among the number of samples pertaining to each class. Class imbalance are considered as the foreground-to-background relationship and imbalance among the foreground classes. Second, scale imbalance occurs when the objects have various scales and numbers of samples pertaining to different scales. Third, spatial imbalance refers to a set of factors related to spatial properties of the bounding boxes such as regression penalty, location and IoU. Fourth, objective imbalance occurs when there are multiple loss functions to minimize, e.g. classification and regression losses \cite{Oksuzy2020}.

% Figure environment removed

\subsubsection{Imbalanced Semantic Segmentation}
Previous studies on 2D \& 3D semantic segmentation mainly focused on network architecture and module design and ignored the impact of data distribution. As the datasets of semantic segmentation naturally follow a heavily imbalanced distribution among classes, neural networks perform poorly when training on them \cite{Kang2020,Menon2020,Ren2020,Zhong2021}.
Some studies tried to induce neural collapse in imbalanced learning for better accuracy of minor classes \cite{Thrampoulidis2022,Xie2022,Yang2022}. However, these studies on neural collapse are limited in recognition. As discovered by Papyan et al. \cite{Papyan2020}, {\it neural collapse} phenomenon in that the within-class means of features and the classifier weight vectors, converge to the vertices of a {\it simplex equiangular tight frame} (simplex ETF) at the end of training for classification.  

% Figure environment removed

The simplex ETF structure in neural collapse renders feature centers equiangular separation and the maximal discriminating ability, which is able to effectively improve the performance of minor classes in long-tailed recognition \cite{Li2022,Zhu2022}. For understanding imbalanced semantic segmentation, the structures of feature centers and classifiers were explored by Zhong et al. \cite{Zhong2023}, illustrated in Figure \ref{fig:SimplexETF}. 
Surprisingly, it was observed that the symmetric equiangular separation as instructed by the neural collapse phenomenon in image recognition did not hold in semantic segmentation for both feature centers and classifiers. To take advantage of the equiangular and maximum separation properties for better performance on minor classes, the Center Collapse (CeCo) regularizer were presented for imbalanced semantic segmentation problems.

% --------- Anomaly Detection Review 
\subsection{Anomaly Detection for Damage Vision}
Naturally, anomaly detection algorithm always face more or less imbalanced data property. Because the damaged phenomina are rarely occurred such as damage, deterioration, deficit, disease, infection, accidient, devastation. This paper highlights these damage vision and feature imbalanced property. 
There are many anomaly detection techniques for damage vision data. 
Over the past decade, anomaly detection techniques have attracted significant attention to widespread domain of applications assisted by the methodologies of machine learning and deep learning. Previous survey papers provided fruitful systematic overviews \cite{Chalapathy2019,Chandola2009,Ruff2020,Yuan2022}, focused on the model property, application domain, and trustworthiness to be more interpretable, fair, robust, and privacy settings. 
Specifically, vision-based deep learning applications have emerged by two driving forces: computing accessibility and digitalized society that accelerate the creation of many datasets annotated with several class labels. There has been over 20 datasets of surface damage for industrial products that have focused on various materials: steel, metal, aluminum, tile, fabric, printed board, solar panel, concrete, road, pavement, bridge, and rail \cite{Saberironaghi2023}. 

Modern anomaly detection approaches can be divided into primary three categories: one-class classification, patch-wise embedding-similarity, and reconstruction-based models \cite{Yasuno2023}. Inspired with \cite{Ruff2020}, these anomaly detection approaches are reviewed in a unified manner progressing from less to more complexity scale through several categories of localization models. Firstly, anomaly detection approaches based on less complexity scale include the one-class support vector machine (OC-SVM) \cite{Chalapathy2018}, support vector data description (SVDD) \cite{Tax2014}, principal component analysis (PCA) \cite{Hawkins1974}, and kernel-PCA \cite{Hoffmann2007}. Anomaly detection approaches based on more complexity scale include deep SVDD \cite{Ruff2018}, fully convolutional data description (FCDD) \cite{Liznerski2021}, variational autoencoder (VAE) \cite{An201 
 5,Kingma2019}, and adversarial auto-encoders (AAE) \cite{Zhou2017}. However, reconstruction-based models cannot always reconstruct synthetic outputs well based on susceptibility to background noise. In contrast, one-class classification models depend on neither synthetic reconstruction nor probabilistic assumptions. This paper highlights the one-class classification models for damage vision anomaly detection. 

Additionally, patch-wise embedding approach enables to minimize the background noise per each patch image. To localize the anomalous feature in a patch image, patch-wise embedding-similarity models perform that the normal reference can be the sphere feature containing embeddings from normal images. In this case, anomaly score is the distance between embedding vectors of a test image and reference vectors representing normality from the dataset. Embedding-similarity based models includes the SPADE \cite{Cohen2020}, PaDiM \cite{Thomas2020}, PatchCore \cite{Roth2021}. However, these models are based on supervised learning that additionally requires optimization algorithms such as a greedy coreset selection, a nearest neighbor search on a set of normal embedding vectors, so the inference complexity scales linearly to the size of training dataset. In contrast, one-class classification approach can learn efficiently using rare class of imbalanced dataset with fewer scale. The author presents the one-class classification based anomaly detection method for imbalanced damage vision, and compare the accuracy between our method and the patch-wise embedding-similarity models, typically PaDiM and PatchCore .

\subsection{Few-shot Damage Vision Feedback for Class Imbalance}
For condition-based maintenance, automating visual inspection is crucial to ensure high quality. Deterioration prognostic attempts to optimize the fine decision process for predictive maintenance and proactive repair. In civil infrastructure and living environment, damage data mining cannot avoid the imbalanced data issue because of rare unseen events and high quality status by improved operations.
As shown in Table~\ref{tab:imbset}, we pointed out the imbalanced settings and clear examples. From aforementioned related works, we summarized that imbalanced data problems could be categorized into four types; 1) missing range of target and label valuables, 2) majority-minority class imbalance, 3) foreground-background of spatial imbalance, 4) long-tailed class of pixel-wise imbalance. Since 2015, there has been many imbalanced data studies based on deep learning algorithms using regression, image classification, object detection, semantic segmentation. However, anomaly detection approach for imbalanced data is not yet sufficiently known.  

The previous imbalanced studies have been based on {\it non-damage vision} datasets. Any damage region of interest has been not included in the existing research scope using learning methods, e.g. regression, image classification, object detection, and semantic segmentation. 
In the present imbalanced studies, illustrated in the aforementioned Figure \ref{fig:DamageVisionMining}, we provide key results on the significance of damage vision mining, hypothesizing that the more effective ratio of anomalous class, the higher accuracy gain of anomaly detection applications. We hypothesize that the damage vision mining process is changed into significant two phases. The damage vision mining phases contains 1) {\it damage vision mining opportunity} the former phase with higher accuracy gain, 2) {\it over-mining} the latter phase without further gain of accuracy. The former phase of damage vision mining opportunity is significantly beneficial because of higher performance than the unsupervised learning without anomalous data mining, and also promising advantage of accuracy by damage vision mining. 

In this study, we focus on the class imbalanced anomaly detection problem using typical 12 damage vision datasets. The anomaly detection problem is essential in the two imbalanced classes between small anomalies and large normal images. We consider {\it feature imbalance} that minor clusters were distributed in the feature embedding space. The author analyze the imbalanced distribution on the damage vision embedding feature space, and implement our contrastive damage representation learning using our MN-pair contrastive learning and density-based clustering \cite{Yasuno2023MNPair}. Surprisingly, the number of damage feature clusters has been over 10 rather than the number of initial classes that contains normal and anomalies. Specifically, a damage feature class has been clustered into a narrow region on the embedding space.          
Furthermore, we intend to find the effective positive ratio of anomalies versus relatively large normal class without over-mining to be stable accuracy to avoid waste of time and resources for damage vision mining. 

%%%%%%%%% BODY TEXT Ch2.
\section{Anomaly Detection and Embedding Feature}
\subsection{One-class Classification Using Deeper FCDDs}
The author have already presented the deeper FCDDs\cite{Yasuno2023} and applied to some inspection datasets of bridge, dam, and building. However, anomaly detection approach for imbalanced data is not yet sufficiently known. For applying imbalanced vision datasets, we summarize classification-based anomaly detection method using the deeper Fully-Convolutional Data Descriptions (deeper FCDDs\cite{Yasuno2023}). 

Let $I_k$ be the $k$-th image in an imbalanced vision dataset with a size of $h\times w$.
We consider the number of training images and the weight $W$ of the fully convolutional network (FCN). 
Let the $\Phi^b_W(I_k)$ denote a mapping of the deeper CNN to backbone $b$ based on the input image. The one-class classification model was formulated using the cross-entropy loss function as follows:
\begin{equation}
\begin{split}
\mathcal{L}_{DeepSVDD} =& - \frac{1}{n} \sum_{k=1}^{n} (1-a_k) \log \ell (\Phi^b_W(I_k)) \\
                    &+ a_k \log [ 1 -  \ell (\Phi^b_W(I_k)) ],
\end{split}
\end{equation}
where $a_k =1$ denotes the anomalous label of the $k$-th damage vision and $a_k =0$ denotes the normal label of the $k$-th non-damage vision. A pseudo-Huber loss function is introduced to obtain a more robust loss formulation \cite{Ruff2021icml} in Equation (2). Let $\ell(u)$ be the loss function and define the pseudo-Huber loss as follows:   
\begin{equation}
\ell(u) = \exp(-H(u)),~ H(u) = \sqrt{\|u\|^2 + 1} -1.
\end{equation}
Then, a deeper FCDD loss function can be formulated :
\begin{equation}
\begin{split}
&\mathcal{L}_{deeperFCDD} = \frac{1}{n} \sum_{k=1}^{n} \frac{(1-a_k)}{uv} \sum_{x,y} H_{x,y} (\Phi^b_W(I_k)) \\ 
                           &- a_k \log \left[ 1 -  \exp\left\{ \frac{-1}{uv} \sum_{x,y} H_{x,y} (\Phi^b_W(I_k)) \right\} \right], \label{eqn:deepFCDD}
\end{split}
\end{equation}
where $H_{x,y}(u)$ are the elements $(x,y)$ of the receptive field of size $u\times v$ under a deeper FCDD. 
In the equation (\ref{eqn:deepFCDD}), if we set an unsupervised learning, the positive second term are canceled out. If we use an imbalanced vision data that includes fewer anomalous images and relatively large normal images, a deeper FCDD loss function (\ref{eqn:deepFCDD}) is less influenced by the positive second term.  
The anomaly score $S_k$ of the $k$-th image is expressed as the sum of all the elements of the receptive field as follows:
\begin{equation}
S_k(b) = \sum_{x,y} H_{x,y} (\Phi^b_W(I_k)),~k=1,\cdots,n.
\end{equation}  
We herein present the construction of a baseline FCDD \cite{Yasuno2023} with an initial backbone $b=0$ and performed CNN27 mapping $\Phi^0_W(I_k)$ from the input image $A_k$ in the imbalanced vision dataset. We also present deeper FCDDs focusing on elaborate backbones $b\in \{$VGG16, ResNet101, Inceptionv3$\}$ with a mapping operation $\Phi^{b}_W(I_k)$ to achieve more elaborately performance. In this paper, we present ablation studies on anomalous ratio of imbalanced datasets for detecting material deterioration and disaster damage. 

\subsection{Damage-mark Heatmap Upsampling}
Convolutional neural network (CNN) architectures, comprising millions of common parameters, have exhibited remarkable performance, but the underlying reasons for this superiority remain unclear. Heatmap visualization techniques for detecting and localizing anomalous features are typically categorized as masked sampling and activation map approaches. 
The former includes methods such as occlusion sensitivity \cite{Zeiler2013} and local interpretable model-agnostic explanations \cite{Ribeiro2016}. 
The latter category includes activation maps such as class activation maps (CAMs) \cite{Zhou2015} and gradient-based extensions (Grad-CAM) \cite{Selvaraju2017}. 
Nonetheless, aforementioned methods of disadvantage is its requirement for parallel computation resources and iterative computation time for local partitioning, masked sampling, and for generating a gradient-based heatmap.

In this study, we adopt the receptive field upsampling approach \cite{Liznerski2021} to visualize anomalous features using an upsampling-based activation map with Gaussian upsampling from the receptive field of the FCN. The primary advantages of the upsampling approach are the reduced computational resource requirements and shorter computation times. The proposed upsampling algorithm generates a full-resolution anomaly heatmap from the input of a low-resolution receptive field $u\times v$.
 
Let $H\in {R}^{u\times v}$ be a low-resolution receptive field (input), and let $H'\in {R}^{h\times w}$ be a full-resolution of damage-mark heatmap (output).
We define the 2D Gaussian distribution $G_2(m_1,m_2,\sigma)$ as follows: 
\begin{equation}
\begin{split}
&[G_2(m_1,m_2,\sigma)]_{x,y} \equiv \\
 &\frac{1}{2\pi\sigma^2}\exp\left(-\frac{(x-m_1)^2+(y-m_2)^2}{2\sigma^2}\right).  
\end{split}
\end{equation}
The Gaussian upsampling algorithm from the receptive field is implemented as follows:
\begin{enumerate}
\item $H' \leftarrow 0 \in {R}^{h\times w}$
\item for all output pixels $d$ in $H \leftarrow 0 \in {R}^{u\times v}$
\item \qquad $u(d) \leftarrow$ is upsampled from a receptive field of $d$
\item \qquad $(c_1(u),c_2(u)) \leftarrow$ is the center of the field $u(d)$
\item \qquad $H' \leftarrow H' + d\cdot G_2(c_1,c_2,\sigma)$
\item end for
\item return $H'$ 
\end{enumerate}
After conducting experiments with various datasets, we determined that a receptive field size of $28 \times 28$ is a practical value. When generating a deterioration heatmap, revealed damage mark, we need to unify the display range that corresponds to the anomaly scores, which range from the minimum to the maximum value. In order to strengthen the defective regions and highlight the hazard marks, we define a display range of [min, max/4], where the quartile parameter is 0.25. This results in the histogram of anomaly scores having a long-tailed shape. If we were to include the complete anomaly score range, the colors would weaken to blue or yellow on the maximum side.

\subsection{MN-pair Contrastive Damage Representation}
The authors \cite{Yasuno2023MNPair} have already formulated the MN-pair contrastive damage representation and clustering method, and found the applicability to a few datasets of steel and concrete. However, another damage representation for imbalanced vision is not yet sufficiently known. For analyzing the feature imbalance, we summarize the MN-pair damage representation method for contrastive learning embedding feature similarity, and for density-based clustering the normal and anomalies on the imbalanced vision datasets. 

Let $x$ denote the set of input images on a damage vision dataset. Let $e_i=f(x_i;\vartheta) \in R^L$ be the $i$–th damage embedding of input $i\in \{1,\cdots,n \}$  that preserves the damage semantic aspects. Here, $n$ is the number of input images. Furthermore, $\vartheta$ is a shared parameters under a CNN for damage metric learning, and $L$ is the dimension of the damage embedding space. 
Let $F_i=e_i/||e_i||_2$ be the $\ell_2$–normalized version. The damage similarity can be measured from the distance between the two images $i_1$ and $i_2$ using the normalized cosine similarity:
\begin{equation}
s_{\vartheta}(x_{i_1},x_{i_2}) = (F_{i_1})^T F_{i_2}
\end{equation}
where larger values indicate greater similarities. Here, the suffix $T$ denotes the transposed operation. 
The N-pair loss approach \cite{Sohn2016} creates a multi-class classification in which we create a set of $N-1$ negative $\{x_k^{-} \}_{k=1}^{N-1}$ and one positive $x_j^{+}$ for every anchor image $x_i$. We define the following N-pair loss function for each set:
\begin{equation}
\begin{split}
&\mathcal{L}_{N-pair}\left( \vartheta;x_i,x_j^{+},\{x_k^{-} \}_{k=1}^{N-1} \right) = \\ 
                           & \log \left[ 1 -  \exp\left( s_{\vartheta}(x_i,x_j^{+}) \right) + \sum_{k=1}^{N-1} \exp\left( s_{\vartheta}(x_i,x_k^{-}) \right) \right], \label{eqn:Npair}
\end{split}
\end{equation}
For simple expression, we denote cosine similarities as:
\begin{equation}
s_{i,j}^{0,+} = s_{\vartheta}(x_{i},x_{j}^{+})/\tau,~s_{i,k}^{0,-} = s_{\vartheta}(x_{i},x_{k}^{-})/\tau
\end{equation}
Here, the suffix $0$ denotes the anchor, and these are divided by a normalized temperature scale $\tau$.
This scale enhances small values, to ensure that N-pair loss is able to train efficiently, for example, we can set the scale $\tau=0.3$ in the present study. Thus, the N-pair loss in the equation(\ref{eqn:Npair}) can be expressed as follows: 
\begin{equation}
\begin{split}
(7) = -\log \frac{ \exp\left( s_{i,j}^{0,+} \right) } { \exp\left( s_{i,j}^{0,+} \right) + \sum_{k=1}^{N-1} \exp\left( s_{i,k}^{0,-} \right) } \label{eqn:simNpair}
\end{split}
\end{equation}
The N-pair loss is identical to the InfoNCE loss \cite{Oord2018, Khosla2020}. However, N-pair loss is a slow starter, because of the presence of only one positive image toward N-1 negative images. A positive signal is important to bond the inner embedding space around the same class of each anchor. 
Thus, we propose an MN-pair weighting loss \cite{Yasuno2023MNPair} instead of (\ref{eqn:Npair})-(\ref{eqn:simNpair}), in which we create a set of $N-1$ negative $\{x_k^{-} \}_{k=1}^{N-1}$ and $M-1$ positive $\{x_j^{+} \}_{j=1}^{M-1}$ for every anchor $x_i$ :
\begin{equation}
\begin{split}
&\mathcal{L}_{MN-pair}\left( \vartheta;x_i, \{x_j^{+}\}_{j=1}^{M-1}, \{x_k^{-} \}_{k=1}^{N-1} \right) = \\ 
& -\log \frac{ \pi\sum_{j=1}^{M-1} \exp\left( s_{i,j}^{0,+} \right) } 
{ \pi\sum_{j=1}^{M-1} \exp\left( s_{i,j}^{0,+} \right) + (1-\pi)\sum_{k=1}^{N-1} \exp\left( s_{i,k}^{0,-} \right) }, \label{eqn:MNpair}
\end{split}
\end{equation}
where $\pi$ is a positive weight, and $1-\pi$ is a negative weight constrained by that the sum of both weights is one, for example, $\pi=0.15$ was applicable in the present study. To train the parameters $\vartheta$ under a CNN for damage metric learning, we can minimize the MN-pair loss function $\mathcal{L}_{MN-pair}$ using a standard optimizer, such as, the Adam.

\subsection{Density-Based Damage Feature Clustering}
Using the damage-embedded feature  with  and the dimension, we can reduce its dimension into two axes of scores using the t-SNE algorithm \cite{Lindermany2019}. Several different concepts exist for clusters of damage representation, including, 1) well-separated clusters, 2) center-based clusters within a specified radius, and 3) density-based clusters. Under a two-dimensional damage-embedding space, we can use either a center-based or a density-based approach. The former is based on the distance from neighboring points to the center, such as the K-means \cite{Hartigan1979}, and k-nearest neighbor \cite{Comak2008}. To provide an effective approach for representing a heterogeneous subdivided region of damage beyond the predefined classes, we used the density-based clustering algorithm (DBSCAN) \cite{Evangelos1996}. The points of the embedded damage features were classified into 1) core points in the interior of a dense region, 2) border points on the edge of a dense region, and 3) noise points in a sparsely occupied region (a noise or background). The DBSCAN algorithm is formally expressed as    

\begin{enumerate}
\item Label all points as core, border, or noise points.
\item Eliminate noise points.
\item Put an edge between all core points that are within a user-specified distance parameter  of each other.
\item Make each group of connected core points into a separate cluster.
\item Assign each border point to one of the clusters of its associated core points.
\end{enumerate}

Because we used a density-based definition of a cluster, it is relatively resistant to noise and can handle clusters with arbitrarily damaged shapes. Therefore, DBSCAN can determine numerous damage clusters that cannot be identified using a center-based algorithm, such as k-means. For damage representation clustering, we can set a distance parameter, for example, $\varepsilon=3$ was applicable in the present study, and a minimum number of neighbors for core points, for example, 10 was feasible in the damage vision studies. 

%%%%%%%%% BODY TEXT Ch3.
\section{Applied Results}
\subsection{Class Imbalanced Vision Datasets}
In the present study, we highlighted three imbalanced datasets as shown in Table~\ref{tab:datarail}, the training data contains anomalous and normal images. In the present study, we implemented deeper backbone studies using the VGG16, ResNet101, Inceptionv3. 
During the training of the anomaly detector, we fixed the input size to $256^2$ training for the wooden sleeper dataset, and to $224^2$ training for concrete deterioration and disaster damage. To train the model, we set the mini-batch size to 32 and ran 60 epochs. 
In this study, we used the Adam optimizer with a learning rate of 0.0001, a gradient decay factor of 0.9, and a squared gradient decay factor of 0.99. The training images were partitioned at a ratio of 65:15:20 for the training, calibration, and testing images in each dataset. Herein, $N_d$ $(d=1,2,3)$ denotes the number of training data in the dataset $d$, and $M_d$ stands for the total number of the dataset that contains the calibration and testing images.
\begin{enumerate}
\item {\it Blood infection $N_1=1300, M_1=2000.$ }
	\begin{itemize}
		\item malaria parasitized in blood smear images by cell-level (\cite{Rajaraman2018}). 
	\end{itemize}
\item {\it Lung infection $N_2=1300, M_2=2000.$ }
	\begin{itemize}
		\item COVID-19 in chest X-ray images (\cite{Kaggle2021,Khan2022}). 
	\end{itemize}
\item {\it Breast cancer $N_3=3120, M_3=4800.$ }
	\begin{itemize}
		\item Breast cancer specimens scanned images that were extracted patches annotated to IDC(Invasive Ductal Carcinoma) negative and positive (\cite{Janowczyk2016,KaggleBreast}). 
	\end{itemize}
\item {\it Driving distraction $N_4=1300, M_4=2000.$ }
	\begin{itemize}
		\item 4-classes : distracted driving images, i.e. texting-left and -right, talking on the phone-left and -right (\cite{Darapaneni2022,Driver2016}). 
	\end{itemize}
\item {\it Wood deterioration $N_5=1300, M_5=2000.$ }
	\begin{itemize}
		\item decayed wooden sleeper in rural railway (\cite{Yasuno2023Imbalanced}). 
	\end{itemize}
\item {\it Concrete damage $N_6=1300=650\times2, M_6=2000.$ }
	\begin{itemize}
		\item 2-classes : crack on pavement and deck (SDNET \cite{Dorafshan2018}). 
	\end{itemize}
\item {\it Logical defects $N_7=1300, M_7=2000.$ }
	\begin{itemize}
		\item 5-classes : logical and structural detects, i.e. breakfast box, juice bottle, pushpins, screw bag, and splicing connectors(MVTec LOCO \cite{Paul2022,MVTecLoco}). 
	\end{itemize}
\item {\it Vegetable damage $N_8=1300=325\times4, M_8=2000.$ } 
	\begin{itemize}
		\item old and damaged vegetables in 4-classes : tomato, bell pepper, chili pepper, and new Mexico chili (VegNet \cite{Yogesh2022}). 
	\end{itemize}
\item {\it Plant infection $N_9=1300, M_9=2000.$ } 
	\begin{itemize}
		\item infected leaves in 12-classes : apple, blueberry, cherry, corn, grape, peach, potato, raspberry, soybean, strawberry, and tomato (\cite{Sadman2023,Siddiqua2022}). 
	\end{itemize}
\item {\it River sludge $N_{10}=1300=650\times2, M_{10}=2000.$ }
	\begin{itemize}
		\item floating sludge on the river surface images (\cite{Yasuno2022River}). 
	\end{itemize}
\item {\it Disaster damage $N_{11}=1300=325\times4, M_{11}=2000.$ } 
	\begin{itemize}
		\item 4-classes : building collapse, flooding area, traffic incidents, fire/smoke (AIDER \cite{AIDER2019}). 
	\end{itemize}
\item {\it Hurricane damage $N_{12}=1300, M_{12}=2000.$ }
	\begin{itemize}
		\item Hurricane satellite imagery (\cite{CaoBuilding2018,CaoData2018}). 
	\end{itemize}
\end{enumerate}

\begin{table}[h]
\centering
\caption{Imbalanced training dataset $d$ of target damage.(Each class has $N_d$ images in the normal and anomalous class. At least, the calibration 300 and test 400 images were fixed respectively.)}
\label{tab:datarail}
\begin{tabular}{|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{Anomalous} & \textbf{Normal} \\
		\hline
1/1(supervised) & $N_d$ & $N_d$ \\
1/2 & $N_d/2$ & $N_d$ \\
1/4 & $N_d/4$ & $N_d$ \\
1/8 & $N_d/8$ & $N_d$ \\
1/16 & $N_d/16$ & $N_d$ \\
1/32 & $N_d/32$ & $N_d$ \\
1/64 & $N_d/64$ & $N_d$ \\
1/128 & $N_d/128$ & $N_d$ \\
1/$N_d$(one-shot) & 1 & $N_d$ \\
		\hline
\end{tabular}
\end{table}

% =============== 3.2 Blood infection
\subsection{Blood Infection}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneBlood}, our deeper FCDD-ResNet101 outperformed in terms of the $F_1$, precision, and recall rather than the baseline CNN27 and other backbone-based deeper FCDDs in this blood smear images dataset for detecting malaria parasitized cells.
\begin{table}[h]
\caption{Backbone ablation studies on malaria parasitized cells detection using our proposed deeper FCDDs.}
\label{tab:accBackboneBlood}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9853 & 0.9468 & 0.9589 & 0.9350 \\ \hline
VGG16 & 0.9932 & 0.9689 & 0.9629 & 0.9750 \\
\textbf{ResNet101} &\textbf{0.9917} & \textbf{0.9774} & \textbf{0.9799} & \textbf{0.9750} \\
Inceptionv3 &0.9913 & 0.9759 & 0.9872 & 0.9650 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceBlood}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-ResNet101 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/16 where the accuracy of recall was consistently less than 4\%. 
However, extremely imbalanced range from 1/32 to 1/1300, that accuracy were inferior to those of applicable range, e.g. the recall was more than 5\%. The rare positive ratio 1/32 represent the imbalanced data that contains quite a little 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the blood infection images of malaria parasitized cells. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-ResNet101 for Blood infection detection $N_1=1300$.}
\label{tab:accImbalanceBlood}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_1$)} & \textbf{0.9917} & \textbf{0.9774} & \textbf{0.9799} & \textbf{0.9750} \\ \hline
1/2(ano.650) & 0.9931 & 0.9735 & 0.9797 & 0.9675 \\ 
1/4(ano.325) & 0.9918 & 0.9683 & 0.9820 & 0.9550 \\ 
1/8(ano.163) & 0.9893 & 0.9660 & 0.9721 & 0.9600 \\ 
1/16(ano.81)& 0.9907 & 0.9636 & 0.9672 & 0.9600 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.9919} & \textbf{0.9619} & \textbf{0.9768} & \textbf{0.9475} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9866} & \textbf{0.9532} & \textbf{0.9641} & \textbf{0.9425} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9839} & \textbf{0.9590} & \textbf{0.9816} & \textbf{0.9375} \\ 
\textbf{1/$N_1$(ano.1)} &\textbf{0.9174} & \textbf{0.8239} & \textbf{0.8610} & \textbf{0.7900} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Blood Infection}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-ResNet101 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. In Fig. \ref{fig:rawBlood}, a damage-mark explanation is represented. The red region in the heatmap represents the malaria parasitized cells of features in the blood smear images. 
Fig. \ref{fig:histBlood} illustrates that a few overlapping bins exist in the boundary of the uninfected class and malaria parasitized class along the horizontal anomaly scores. Thus, for detecting malaria parasitized cells, the score range was well separated in the blood smear images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectBlood}, from the view point of all accuracy, the imbalanced studies on blood infection implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of the AUC. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbBlood}, we intended to analyze the feature imbalance on the blood infection embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Surprisingly, the number of blood infection feature clusters have become 9 rather than the initial two classes. The parasitized feature of 7 clusters were distributed into narrow regions on the embedding feature space.
% Figure environment removed

% =============== 3.3 Lung infection
\subsection{Lung Infection}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneLung}, our deeper FCDD-ResNet101 outperformed in terms of the $F_1$, precision, and recall rather than the baseline CNN27 and other backbone-based deeper FCDDs in this chest X-ray images dataset for detecting lung infection of COVID-19.
\begin{table}[h]
\caption{Backbone ablation studies on lung infection detection using our proposed deeper FCDDs.}
\label{tab:accBackboneLung}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9359 & 0.8677 & 0.8095 & 0.9350 \\ \hline
VGG16 & 0.9925 & 0.9662 & 0.9674 & 0.9650 \\
\textbf{ResNet101} &\textbf{0.9933} & \textbf{0.9725} & \textbf{0.9701} & \textbf{0.9750} \\
Inceptionv3 &0.9918 & 0.9576 & 0.9552 & 0.9600 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceLung}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-ResNet101 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/16 where the accuracy of $F_1$ was consistently more than 95\%. 
However, extremely imbalanced range from 1/32 to 1/1300, that accuracy were inferior to those of applicable range, e.g. the $F_1$ was more than 95\%. The rare positive ratio 1/32 represent the imbalanced data that contains quite a little 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the lung infection images of COVID-19. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-ResNet101 for Lung infection detection $N_2=1300$.}
\label{tab:accImbalanceLung}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_2$)} & \textbf{0.9933} & \textbf{0.9725} & \textbf{0.9701} & \textbf{0.9750} \\ \hline
1/2(ano.650) & 0.9959 & 0.9764 & 0.9680 & 0.9850 \\ 
1/4(ano.325) & 0.9885 & 0.9650 & 0.9650 & 0.9650 \\ 
1/8(ano.163) & 0.9911 & 0.9527 & 0.9738 & 0.9325 \\ 
1/16(ano.81)& 0.9908 & 0.9533 & 0.9618 & 0.9450 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.9911} & \textbf{0.9404} & \textbf{0.9148} & \textbf{0.9675} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9864} & \textbf{0.9468} & \textbf{0.9589} & \textbf{0.9350} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9717} & \textbf{0.9154} & \textbf{0.9108} & \textbf{0.9200} \\ 
\textbf{1/$N_2$(ano.1)} &\textbf{0.7494} & \textbf{0.7088} & \textbf{0.7027} & \textbf{0.7150} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Lung Infection}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-ResNet101 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. In Fig. \ref{fig:rawLung}, a damage-mark explanation is represented. The red region in the heatmap represents the COVID-19 lung infection of features in the chest X-ray images. 
Fig. \ref{fig:histLung} illustrates that a few overlapping bins exist in the boundary of the normal class and COVID-19 infected class along the horizontal anomaly scores. Thus, for detecting lung infection of the COVID-19, the score range was well separated in the chest X-ray images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectLung}, from the view point of all accuracy, the imbalanced studies on lung infection implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of the AUC. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbLung}, we intended to analyze the feature imbalance on the lung infection embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Surprisingly, the number of lung infection feature clusters have become 12 rather than the initial two classes. In the COVID-19 feature 4 clusters were densely distributed into longer regions on the embedding feature space.
% Figure environment removed

% =============== 3.4 Breast cancer
\subsection{Breast Cancer}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneBreast}, our deeper FCDD-ResNet101 outperformed in terms of the $F_1$, and precision rather than the baseline CNN27 and other backbone-based deeper FCDDs in this breast cancer specimens scanned images dataset for detecting invasive ductal carcinoma (IDC) positive.
\begin{table}[h]
\caption{Backbone ablation studies on breast cancer IDC detection using our proposed deeper FCDDs.}
\label{tab:accBackboneBreast}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9434 & 0.8690 & 0.8504 & 0.8885 \\ \hline
VGG16 & 0.9638 & 0.8978 & 0.8648 & 0.9333 \\
\textbf{ResNet101} &\textbf{0.9656} & \textbf{0.9028} & \textbf{0.8825} & \textbf{0.9239} \\
Inceptionv3 &0.9644 & 0.9016 & 0.8739 & 0.9312 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceBreast}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-ResNet101 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/8 where the accuracy of recall was consistently more than 90\%. 
However, extremely imbalanced range from 1/16 to 1/1300, that accuracy were inferior to those of applicable range, e.g. the recall was more than 90\%. The rare positive ratio 1/16 represent the imbalanced data that contains quite a little 81 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the breast cancer specimens images. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-ResNet101 for Breast cancer IDC positive detection $N_3=1300$.}
\label{tab:accImbalanceBreast}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_3$)} & \textbf{0.9656} & \textbf{0.9028} & \textbf{0.8825} & \textbf{0.9239} \\ \hline
1/2(ano.650) & 0.9660 & 0.8946 & 0.9051 & 0.8843 \\ 
1/4(ano.325) & 0.9657 & 0.8976 & 0.8783 & 0.9177 \\ 
1/8(ano.163) & 0.9622 & 0.8942 & 0.8776 & 0.9114 \\ \hline
\textbf{1/16(ano.81)}& \textbf{0.9555} & \textbf{0.8832} & \textbf{0.8917} & \textbf{0.8750} \\ 
\textbf{1/32(ano.41)}&\textbf{0.9437} & \textbf{0.8729} & \textbf{0.8729} & \textbf{0.8729} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9130} & \textbf{0.8368} & \textbf{0.8457} & \textbf{0.8281} \\ 
\textbf{1/128(ano.10)}&\textbf{0.8918} & \textbf{0.8182} & \textbf{0.8430} & \textbf{0.7947} \\ 
\textbf{1/$N_3$(ano.1)} &\textbf{0.8331} & \textbf{0.7749} & \textbf{0.7532} & \textbf{0.7979} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Breast cancer}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-ResNet101 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/8$. In Fig. \ref{fig:rawBreast}, a damage-mark explanation is represented. The red region in the heatmap represents the breast cancer IDC positive of features in the specimens patch images. 
Fig. \ref{fig:histBreast} illustrates that a few overlapping bins exist in the boundary of the normal class and breast cancer IDC positive class along the horizontal anomaly scores. Thus, for detecting breast cancer, the score range was well separated in the specimens scanned images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectBreast}, from the view point of all accuracy, the imbalanced studies on breast cancer implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of the AUC. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbBreast}, we intended to analyze the feature imbalance on the breast cancer embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Surprisingly, the number of breast cancer feature clusters have become 13 rather than the initial two classes. 
In the breast cancer IDC positive feature, a few narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.5 Driving distraction
\subsection{Driving Distraction}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneDrive}, our deeper FCDD-Inceptionv3 outperformed in terms of the $F_1$, precision, and recall rather than the baseline CNN27 and other backbone-based deeper FCDDs in this driving distraction images dataset for detecting hazardous driving behaviors.
\begin{table}[h]
\caption{Backbone ablation studies on distracted driving detection using our proposed deeper FCDDs.}
\label{tab:accBackboneDrive}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9445 & 0.8894 & 0.8839 & 0.8950 \\ \hline
VGG16 & 0.9981 & 0.9937 & 0.9949 & 0.9925 \\
ResNet101 & 0.9955 & 0.9836 & 0.9923 & 0.9750 \\
\textbf{Inceptionv3} & \textbf{0.9987} & \textbf{0.9974} & \textbf{1.000} & \textbf{0.9950} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceDrive}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-Inceptionv3 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/16 where the accuracy loss of recall was consistently less than 3\%. 
However, extremely imbalanced range from 1/32 to 1/1300, that accuracy were inferior to those of applicable range, e.g. the loss of $F_1$ was more than 3\%. The rare positive ratio 1/32 represent the imbalanced data that contains quite a little 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the driving distraction images of texting and talking on the phone. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-Inceptionv3 for Drivng distraction detection $N_3=1300$.}
\label{tab:accImbalanceDrive}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_4$)} & \textbf{0.9987} & \textbf{0.9974} & \textbf{1.000} & \textbf{0.9950} \\ \hline
1/2(ano.650) & 0.9981 & 0.9886 & 1.000 & 0.9775 \\ 
1/4(ano.325) & 0.9976 & 0.9782 & 1.000 & 0.9575 \\ 
1/8(ano.163) & 0.9968 & 0.9899 & 0.9949 & 0.9850 \\ 
1/16(ano.81)& 0.9965 & 0.9850 & 0.9850 & 0.9850 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.9916} & \textbf{0.9664} & \textbf{0.9604} & \textbf{0.9725} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9912} & \textbf{0.9542} & \textbf{0.9715} & \textbf{0.9375} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9799} & \textbf{0.9107} & \textbf{0.9437} & \textbf{0.8800} \\ 
\textbf{1/$N_4$(ano.1)} &\textbf{0.8378} & \textbf{0.7450} & \textbf{0.6971} & \textbf{0.8000} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Driving Distraction}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-Inceptionv3 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. In Fig. \ref{fig:rawDrive}, a damage-mark explanation is represented. The red region in the heatmap represents the distracted driving features that the driver behaves with one hand, while texting and talking on the phone without holding the handle by another hand. These heatmaps have focused on the anomalous hand moving as one of distracted driving behaviors that could potentially occur traffic incident. 
Fig. \ref{fig:histDrive} illustrates that a few overlapping bins exist in the boundary of the safety driving class and distracted class along the horizontal anomaly scores. Thus, for detecting distracted driving behaviors, the score range was well separated in the blood smear images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectDrive}, from the view point of all accuracy, the imbalanced studies on driving distraction implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of the AUC. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbDrive}, we intended to analyze the feature imbalance on the driving distraction embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
The number of driving distraction feature clusters doubly increased into 10 as twice the initial number of normal and 4 anomalous classes, i.e. texting-left and -right, talking on the phone-left and -right. 
In the driving distraction feature, a few narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.6 Wooden Deterioration
% Figure environment removed
% Figure environment removed

\subsection{Wooden Deterioration}
\subsubsection{Backbone Studies of Supervised Detection}
The number of training images $N_3$ in each class is 1300, and the number for calibration and test are 300 and 400 images respectively on the dataset of wooden sleeper deterioration. 
As shown in Table~\ref{tab:accBackbone}, our deeper FCDDs based on VGG16 (abbreviated as {\it deeperFCDD-VGG16}) outperformed in terms of the AUC and $F_1$ rather than the baseline CNN27 and other backbone-based deeper FCDDs in this railway dataset for detecting decayed wooden sleeper.
\begin{table}[h]
\caption{Backbone ablation studies on defective detection using our proposed deeper FCDDs for Wooden sleeper.}
\label{tab:accBackbone}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.8624 & 0.7688 & 0.7088 & 0.8400 \\ \hline
\textbf{VGG16} & \textbf{0.9425} & \textbf{0.8475} & \textbf{0.8770} & \textbf{0.8200} \\
ResNet101 &0.9304 & 0.8108 & 0.8823 & 0.7500 \\
Inceptionv3 &0.9412 & 0.8041 & 0.8415 & 0.7700 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
As shown in Table~\ref{tab:accImbalance}, we implemented ablation studies on imbalanced data that contains fewer anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-VGG16 achieved high performance in the aforementioned results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the balanced ratio 1/2 to the ratio 1/16 where every accuracy were consistently high performance. 
However, extremely imbalanced range from 1/32 to 1/128 and 1/1300, that accuracy were significantly decreasing and inferior to those of the applicable range. Specifically, the rare positive ratio 1/32 represent the imbalanced data that contains quite a few 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset. The marginal effect of accuracy gain was significantly high by adding the anomalous images.
   
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-VGG16 for wooden sleeper deterioration $N_3=1300$.}
\label{tab:accImbalance}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_5$)} & \textbf{0.9463} & \textbf{0.8701} & \textbf{0.8379} & \textbf{0.9050} \\ \hline
1/2(ano.650) & 0.9190 & 0.8751 & 0.8205 & 0.9375 \\ 
1/4(ano.325) & 0.9287 & 0.8505 & 0.8274 & 0.8750 \\ 
1/8(ano.163) & 0.9269 & 0.8451 & 0.8378 & 0.8525 \\ 
1/16(ano.81)& 0.9101 & 0.8547 & 0.8353 & 0.8750 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.8947} & \textbf{0.8441} & \textbf{0.8110} & \textbf{0.8800} \\ 
\textbf{1/64(ano.20)}&\textbf{0.8724} & \textbf{0.8250} & \textbf{0.7562} & \textbf{0.9075} \\ 
\textbf{1/128(ano.10)}&\textbf{0.8051} & \textbf{0.7698} & \textbf{0.7622} & \textbf{0.7775} \\ 
\textbf{1/$N_5$(ano.1)} &\textbf{0.6136} & \textbf{0.5823} & \textbf{0.5724} & \textbf{0.5925} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Damage-mark Heatmaps on Wooden Decayed}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-VGG16 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. 
In the bottom of Fig. \ref{fig:rawSleeper}, a damage-mark explanation is presented. The red region in the heatmap represents the decayed wooden sleepers. There is quite a few region of background noise over the ballast stones, and precast concrete white sleeper in the third and fourth rows, and grass outside rail track in the sixth row.
In addition, Fig. \ref{fig:histSleeper} illustrates that several overlapping bins exist in the boundary of horizontal anomaly scores between the non-damage class and deterioration class. Therefore, for detecting decayed wooden sleepers, the anomaly score range was moderately separated in the wooden sleeper deterioration dataset.

% Figure environment removed

\subsubsection{Feedback Effect on Deterioration Class Mining}
As shown in Figure \ref{fig:EffectSleeper}, from the view point of accuracy on the AUC, the imbalanced studies on wooden sleeper deterioration implied that the accuracy were moving into stable phases, even though the recall and precision were waving. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without effective gain of accuracy. The former phase of damage vision mining opportunities has become beneficial because of advantage of higher accuracy in terms of the AUC.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbWood}, we intended to analyze the feature imbalance on the wooden deterioration embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Surprisingly, the number of wooden deterioration feature clusters increased into 10 rather than the initial two classes. In the wooden deterioration feature, a few narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.7 Concrete Crack
% Figure environment removed
% Figure environment removed

\subsection{Concrete Crack}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneCrack}, our deeper FCDD-VGG16 outperformed in terms of all of accuracy, such as the AUC, $F_1$, precision, and recall, rather than those of the baseline CNN27 and other backbone-based deeper FCDDs in this concrete deterioration dataset for detecting crack.
\begin{table}[h]
\caption{Backbone ablation studies on concrete crack detection using our proposed deeper FCDDs.}
\label{tab:accBackboneCrack}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.7150 & 0.6975 & 0.6245 & 0.7900 \\ \hline
\textbf{VGG16} & \textbf{0.9287} & \textbf{0.8384} & \textbf{0.8605} & \textbf{0.8175} \\
ResNet101 &0.9120 & 0.8206 & 0.8480 & 0.7950 \\
Inceptionv3 &0.9119 & 0.8169 & 0.8372 & 0.7975 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
As shown in Table~\ref{tab:accImbalanceCrack}, we carried out ablation studies on imbalanced damage data that contains fewer anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-VGG16 achieved high performance in the above supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the balanced ratio 1/2 to the ratio 1/8 where the accuracy were consistently high performance in terms of the AUC and $F_1$. 
However, extremely imbalanced range from 1/16 to 1/1300, that accuracy were inferior to those of aforementioned applicable range. The rare positive ratio 1/16 represent the imbalanced data that contains a little 81 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset. The marginal gain of accuracy was relatively high by adding the deterioration images.

\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-VGG16 for Concrete crack detection $N_4=1300$.}
\label{tab:accImbalanceCrack}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_6$)} & \textbf{0.9338} & \textbf{0.8265} & \textbf{0.9482} & \textbf{0.7325} \\ \hline
1/2(ano.650) & 0.8968 & 0.8492 & 0.9016 & 0.8025 \\ 
1/4(ano.325) & 0.9151 & 0.8151 & 0.8856 & 0.7550 \\ 
1/8(ano.163) & 0.9147 & 0.8178 & 0.8885 & 0.7575 \\ \hline 
\textbf{1/16(ano.81)}&\textbf{0.8956} & \textbf{0.7918} & \textbf{0.8594} & \textbf{0.7750} \\
\textbf{1/32(ano.41)}&\textbf{0.8826} & \textbf{0.7918} & \textbf{0.8617} & \textbf{0.7325} \\ 
\textbf{1/64(ano.20)}&\textbf{0.8788} & \textbf{0.7614} & \textbf{0.8952} & \textbf{0.6625} \\ 
\textbf{1/128(ano.10)}&\textbf{0.8488} & \textbf{0.7104} & \textbf{0.8277} & \textbf{0.6225} \\ 
\textbf{1/$N_6$(ano.1)} &\textbf{0.7927} & \textbf{0.6908} & \textbf{0.8235} & \textbf{0.5950} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Damage-mark Heatmaps on Concrete Crack}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-VGG16 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/8$. In the bottom of Fig. \ref{fig:rawCrack}, a damage-mark explanation is presented. The red region in the heatmap represents the crack in the surface of concrete deck and pavement. In addition, Fig. \ref{fig:histCrack} illustrates that a few overlapping bins exist in the boundary of horizontal anomaly scores between the health class and crack deterioration class.
Therefore, for detecting crack, the score range was well separated in the concrete crack dataset of deck and pavement.

% Figure environment removed

\subsubsection{Feedback Effect on Deterioration Class Mining}
As shown in Figure \ref{fig:EffectCrack}, from the view point of the primary accuracy AUC, the imbalanced studies on concrete crack implied that the accuracy was increasing within the range less than the positive ratio $1/8$, although the precision and recall were waving. 
We could understand that the beneficial range was damage vision mining opportunities with accuracy gain. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without effective gain of accuracy. The former phase of damage vision mining opportunities has become beneficial because of advantage of higher accuracy in terms of the AUC.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbConcrete}, we intended to analyze the feature imbalance on the concrete deterioration embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Surprisingly, the number of concrete deterioration clusters have increased into 21 rather than the initial two classes. In the concrete deterioration feature, a lot of narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.8 Logical defects
% Figure environment removed
% Figure environment removed

\subsection{Logical Defects}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneLogi}, our deeper FCDD-VGG16 outperformed in terms of all of accuracy, such as the $F_1$, and precision, rather than those of the baseline CNN27 and other backbone-based deeper FCDDs in this logical constraints MVTec LOCO AD dataset for detecting logical defects.
\begin{table}[h]
\caption{Backbone ablation studies on logical defects detection using our proposed deeper FCDDs.}
\label{tab:accBackboneLogi}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.8014 & 0.6266 & 0.5468 & 0.7336 \\ \hline
\textbf{VGG16} & \textbf{0.8925} & \textbf{0.7146} & \textbf{0.7315} & \textbf{0.6984} \\
ResNet101 &0.8669 & 0.6912 & 0.6383 & 0.7537 \\
Inceptionv3 &0.8975 & 0.6995 & 0.6859 & 0.7135 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
As shown in Table~\ref{tab:accImbalanceLogi}, we carried out ablation studies on imbalanced damage data that contains fewer anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-VGG16 achieved high performance in the above supervised results.  
In the MVTec LOCO AD dataset, the number of anomalies was 993 that contains 432 structural damges and 561 logical defects. This imbalance study had to start from the positive ratio 1/2. 
Compared with the balanced case of positive ratio 1/2, we found that there was applicable range from the imbalanced ratio 1/4 to the ratio 1/8 where the accuracy of the AUC was consistently more than 85\%. 
However, extremely imbalanced range from 1/16 to 1/1300, that accuracy were inferior to those of applicable range, e.g. the AUC was more than 85\%. The rare positive ratio 1/16 represent the imbalanced data that contains quite a little 81 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset. The marginal gain of accuracy was relatively high by adding the logical defective images.

\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-VGG16 for Logical defects detection $N_7=1300$.}
\label{tab:accImbalanceLogi}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/2(ano.645)} & \textbf{0.8925} & \textbf{0.7146} & \textbf{0.7315} & \textbf{0.6984} \\ \hline
1/4(ano.325) & 0.8843 & 0.6986 & 0.7443 & 0.6582 \\ 
1/8(ano.163) & 0.8504 & 0.6888 & 0.6531 & 0.7286 \\ \hline 
\textbf{1/16(ano.81)}&\textbf{0.7881} & \textbf{0.6716} & \textbf{0.6700} & \textbf{0.6733} \\
\textbf{1/32(ano.41)}&\textbf{0.7756} & \textbf{0.6011} & \textbf{0.7074} & \textbf{0.5226} \\ 
\textbf{1/64(ano.20)}&\textbf{0.6913} & \textbf{0.5336} & \textbf{0.4817} & \textbf{0.5979} \\ 
\textbf{1/128(ano.10)}&\textbf{0.6337} & \textbf{0.5271} & \textbf{0.5425} & \textbf{0.5125} \\ 
\textbf{1/$N_7$(ano.1)} &\textbf{0.5520} & \textbf{0.4019} & \textbf{0.3835} & \textbf{0.4221} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Damage-mark Heatmaps on Logical Defects}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-VGG16 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with the positive ratio $1/8$. In the bottom of Fig. \ref{fig:rawLogi}, a damage-mark explanation is presented. The red region in the heatmap represents the logical defects in the MVTec logical constraints objects. 
In addition, Fig. \ref{fig:histLogi} illustrates that a few overlapping bins exist in the boundary of horizontal anomaly scores between the health class and logical defective class.
Therefore, for detecting logical defects, the score range was well separated in the imbalanced logical constraints dataset.

% Figure environment removed

\subsubsection{Feedback Effect on Deterioration Class Mining}
As shown in Figure \ref{fig:EffectLogi}, from the view point of the primary accuracy AUC, the imbalanced studies on logical defects implied that the accuracy was increasing within the range less than the positive ratio $1/8$, although the precision and recall were waving. 
We could understand that the beneficial range was damage vision mining opportunities with accuracy gain. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without effective gain of accuracy. The former phase of damage vision mining opportunities has become beneficial because of advantage of higher accuracy in terms of the AUC.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbLoco}, we intended to analyze the feature imbalance on the logical defects embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Appropriately, the number of logical defects clusters have become 11 as twice the initial 5 classes, e.g. breakfast box, juice bottle, pushipins, screw bag, and splicing connectors, that contained normal and anomalies. 
In the logical defects feature, several narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.9 VegNet
\subsection{Vegetable Damage}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneVeg}, our deeper FCDD-ResNet101 outperformed in terms of the $F_1$, and recall rather than the baseline CNN27 and other backbone-based deeper FCDDs in this vegetable images dataset for detecting old and damaged vegetables.
\begin{table}[h]
\caption{Backbone ablation studies on vegetable damage detection using our proposed deeper FCDDs.}
\label{tab:accBackboneVeg}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9804 & 0.9150 & 0.8891 & 0.9425 \\ \hline
VGG16 & 0.9905 & 0.9649 & 0.9673 & 0.9625 \\
\textbf{ResNet101} &\textbf{0.9950} & \textbf{0.9664} & \textbf{0.9604} & \textbf{0.9725} \\
Inceptionv3 &0.9893 & 0.9513 & 0.9501 & 0.9525 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceVeg}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-ResNet101 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/16 where the accuracy of recall was consistently more than 95\%. 
However, extremely imbalanced range from 1/32 to 1/1300, that accuracy were inferior to those of applicable range. The positive ratio 1/32 represent the imbalanced data that contains 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the old and damaged vegetable images. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-ResNet101 for Vegetable damage detection $N_8=1300$.}
\label{tab:accImbalanceVeg}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_8$)} & \textbf{0.9950} & \textbf{0.9664} & \textbf{0.9604} & \textbf{0.9725} \\ \hline
1/2(ano.650) & 0.9949 & 0.9568 & 0.9716 & 0.9425 \\ 
1/4(ano.325) & 0.9954 & 0.9638 & 0.9603 & 0.9675 \\ 
1/8(ano.163) & 0.9887 & 0.9536 & 0.9548 & 0.9525 \\ 
1/16(ano.81) & 0.9838 & 0.9407 & 0.9292 & 0.9525 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.9771} & \textbf{0.9431} & \textbf{0.9539} & \textbf{0.9325} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9722} & \textbf{0.9264} & \textbf{0.9407} & \textbf{0.9125} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9680} & \textbf{0.9118} & \textbf{0.9061} & \textbf{0.9175} \\ 
\textbf{1/$N_8$(ano.1)} &\textbf{0.7886} & \textbf{0.6952} & \textbf{0.6810} & \textbf{0.7100} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Vegetable Damage}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-ResNet101 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. In Fig. \ref{fig:rawVeg}, a damage-mark explanation is represented. The red region in the heatmap represents the old and damaged features in the vegetable image. 
Fig. \ref{fig:histVeg} illustrates that a few overlapping bins exist in the boundary of the normal class and vegetable damage class along the horizontal anomaly scores. Thus, for detecting old and damaged vegetables, the score range was well separated in the vegetable damage images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectVeg}, from the view point of all accuracy, the imbalanced studies on vegetable damage implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/16$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC and recall. In contrast, ranged with positive ratio over $1/8$, it was shifting in over-mining phase without any gain of the AUC and recall. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbVeg}, we intended to analyze the feature imbalance on the vegetable damage embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Approximately, the number of vegetable damage clusters have increased 10 more than the initial 4 classes, e.g. tomato, bell pepper, chili pepper, and new Mexico chili, that included normal and anomalies. In the vegetable damage feature, several narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.10 Plant disease
\subsection{Plant Infection}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackbonePlant}, our deeper FCDD-Inceptionv3 outperformed in terms of the $F_1$, precision rather than the baseline CNN27 and other backbone-based deeper FCDDs in this plant disease images dataset for detecting infected leaves.
\begin{table}[h]
\caption{Backbone ablation studies on infected leaves detection using our proposed deeper FCDDs.}
\label{tab:accBackbonePlant}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9914 & 0.9439 & 0.9404 & 0.9475 \\ \hline
VGG16 & 0.9999 & 0.9900 & 0.9851 & 0.9950 \\
ResNet101 & 0.9999 & 0.9888 & 0.9827 & 0.9950 \\
\textbf{Inceptionv3} & \textbf{0.9997} & \textbf{0.9912} & \textbf{0.9924} & \textbf{0.9900} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalancePlant}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-Inceptionv3 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/8 where the accuracy loss of recall was consistently less than 3\%. 
However, extremely imbalanced range from 1/16 to 1/1300, that accuracy were inferior to those of applicable range, e.g. the loss of recall was more than 3\%. The rare positive ratio 1/16 represent the imbalanced data that contains a little 81 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the infected leaves images. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-Inceptionv3 for Plant infected leaves detection $N_9=1300$.}
\label{tab:accImbalancePlant}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_9$)} & \textbf{0.9997} & \textbf{0.9912} & \textbf{0.9924} & \textbf{0.9900} \\ \hline
1/2(ano.650) & 0.9989 & 0.9912 & 0.9949 & 0.9875 \\ 
1/4(ano.325) & 0.9981 & 0.9861 & 0.9949 & 0.9775 \\ 
1/8(ano.163) & 0.9983 & 0.9848 & 0.9949 & 0.9750 \\ \hline 
\textbf{1/16(ano.81)}&\textbf{0.9988} & \textbf{0.9709} & \textbf{0.9821} & \textbf{0.9600} \\
\textbf{1/32(ano.41)}&\textbf{0.9981} & \textbf{0.9722} & \textbf{0.9797} & \textbf{0.9650} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9936} & \textbf{0.9533} & \textbf{0.9618} & \textbf{0.9450} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9826} & \textbf{0.9023} & \textbf{0.9553} & \textbf{0.8550} \\ 
\textbf{1/$N_9$(ano.1)} &\textbf{0.7882} & \textbf{0.6943} & \textbf{0.7770} & \textbf{0.6275} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Plant Disease}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-Inceptionv3 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/8$. In Fig. \ref{fig:rawPlant}, a damage-mark explanation is represented. The red region in the heatmap represents the infected leaves of features.  
Fig. \ref{fig:histPlant} illustrates that a few overlapping bins exist in the boundary of the health leaves class and plant disease class along the horizontal anomaly scores. Thus, for detecting infected leaves, the score range was well separated in the plant disease images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectPlant}, from the view point of all accuracy, the imbalanced studies on plant leaves infection implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the recall. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of the recall. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbPlant}, we intended to analyze the feature imbalance on the plant disease embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Decreasingly, the number of plant disease clusters have become 14 less than twice the initial 12 classes, e.g. apple, blueberry, cherry, corn, grape, peach, potato, raspberry, soybean, strawberry, and tomato, that included normal and anomalies. 
In the plant disease feature, several narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.11 River sludge
\subsection{River Sludge}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneRiver}, our deeper FCDD-ResNet101 outperformed in terms of the $F_1$, precision, and recall rather than the baseline CNN27 and other backbone-based deeper FCDDs in this river surface images dataset for detecting river sludge floating on the surface.
\begin{table}[h]
\caption{Backbone ablation studies on river sludge detection using our proposed deeper FCDDs.}
\label{tab:accBackboneRiver}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9518 & 0.8567 & 0.8940 & 0.8225 \\ \hline
VGG16 & 0.9666 & 0.9065 & 0.9291 & 0.8850 \\
\textbf{ResNet101} &\textbf{0.9681} & \textbf{0.9214} & \textbf{0.9496} & \textbf{0.8950} \\
Inceptionv3 &0.9623 & 0.9010 & 0.9402 & 0.8650 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceRiver}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-ResNet101 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/4 where the accuracy of $F_1$ was consistently more than 90\%. 
However, extremely imbalanced range from 1/8 to 1/1300, that accuracy were inferior to those of applicable range. The positive ratio 1/8 represent the imbalanced data that contains 163 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the river sludge images on the surface. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-ResNet101 for River sludge  detection $N_6=1300$.}
\label{tab:accImbalanceRiver}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_{10}$)} & \textbf{0.9681} & \textbf{0.9214} & \textbf{0.9496} & \textbf{0.8950} \\ \hline
1/2(ano.650) & 0.9635 & 0.9175 & 0.9468 & 0.8900 \\ 
1/4(ano.325) & 0.9457 & 0.9077 & 0.8934 & 0.9225 \\ \hline 
\textbf{1/8(ano.163)} & \textbf{0.9588} & \textbf{0.8736} & \textbf{0.9222} & \textbf{0.8300} \\ 
\textbf{1/16(ano.81)}& \textbf{0.9428} & \textbf{0.8579} & \textbf{0.9150} & \textbf{0.8075} \\
\textbf{1/32(ano.41)}&\textbf{0.9267} & \textbf{0.8382} & \textbf{0.8686} & \textbf{0.8100} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9131} & \textbf{0.8175} & \textbf{0.8746} & \textbf{0.7675} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9123} & \textbf{0.7973} & \textbf{0.8676} & \textbf{0.7375} \\ 
\textbf{1/$N_{10}$(ano.1)} &\textbf{0.8221} & \textbf{0.7139} & \textbf{0.7513} & \textbf{0.6800} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on River Sludge}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-ResNet101 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/4$. In Fig. \ref{fig:rawRiver}, a damage-mark explanation is represented. The red region in the heatmap represents the river sludge of features in the river surface images. 
Fig. \ref{fig:histRiver} illustrates that a few overlapping bins exist in the boundary of the normal class and river sludge class along the horizontal anomaly scores. Thus, for detecting river sludge on the surface, the score range was well separated in the river sludge images dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectRiver}, from the view point of all accuracy, the imbalanced studies on river sludge implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of the AUC. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbRiver}, we intended to analyze the feature imbalance on the river sludge embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Appropriately, the number of river sludge clusters have become 11 rather than the initial 2 classes that contained normal river surface and variational sludge. 
In the river sludge feature, a few narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.12 Disaster damage
% Figure environment removed
% Figure environment removed

\subsection{Disaster Damage}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneBuild}, our deeper FCDD-VGG16 outperformed in terms of the AUC, $F_1$, and precision, rather than the baseline CNN27 and other backbone-based deeper FCDDs in this disaster damage dataset for detecting building collapse, traffic incidents, fire, and flooding area.
\begin{table}[h]
\caption{Backbone ablation studies on disaster damage detection using our proposed deeper FCDDs.}
\label{tab:accBackboneBuild}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9433 & 0.7896 & 0.7523 & 0.8307 \\ \hline
\textbf{VGG16} & \textbf{0.9969} & \textbf{0.9622} & \textbf{0.9589} & \textbf{0.9655} \\
ResNet101 &0.9916 & 0.9323 & 0.8985 & 0.9687 \\
Inceptionv3 &0.9925 & 0.9319 & 0.9189 & 0.9453 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
As shown in Table~\ref{tab:accImbalanceBuild}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-VGG16 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/16 where the accuracy were consistently high performance. 
However, extremely imbalanced range from 1/32 to 1/1300, that accuracy were inferior to those of applicable range. The rare positive ratio 1/32 represent the imbalanced data that contains quite a little 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the rare events of devastated images. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-VGG16 for Disaster damage detection $N_7=1300$.}
\label{tab:accImbalanceBuild}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_{11}$)} & \textbf{0.9844} & \textbf{0.9491} & \textbf{0.9410} & \textbf{0.9575} \\ \hline
1/2(ano.650) & 0.9850 & 0.9398 & 0.9422 & 0.9375 \\ 
1/4(ano.325) & 0.9843 & 0.9422 & 0.9469 & 0.9375 \\ 
1/8(ano.163) & 0.9809 & 0.9423 & 0.9447 & 0.9400 \\ 
1/16(ano.81)& 0.9766 & 0.9413 & 0.9401 & 0.9425 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.9606} & \textbf{0.9075} & \textbf{0.9075} & \textbf{0.9075} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9444} & \textbf{0.8924} & \textbf{0.8826} & \textbf{0.9025} \\ 
\textbf{1/128(ano.10)}&\textbf{0.8971} & \textbf{0.8221} & \textbf{0.8484} & \textbf{0.7975} \\ 
\textbf{1/$N_{11}$(ano.1)} &\textbf{0.6870} & \textbf{0.5783} & \textbf{0.6721} & \textbf{0.5075} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Damage-mark Heatmaps on Disaster Damage}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-VGG16 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. In Fig. \ref{fig:rawBuild}, a damage-mark explanation is represented. The red region in the heatmap represents the four classes of disaster features that includes fire and smoke, building collapse, traffic incidents, and flooding area. 
Fig. \ref{fig:histBuild} illustrates that a few overlapping bins exist in the boundary of the ordinary class and disaster class along the horizontal anomaly scores. Thus, for detecting devastated feature, the score range was well separated in the disaster damage dataset.

% Figure environment removed

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectBuild}, from the view point of all accuracy, the imbalanced studies on disaster damage implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/8$, we could understand that there were damage vision mining opportunities with accuracy gain. In contrast, ranged with positive ratio over $1/4$, it was shifting in over-mining phase without any gain of accuracy. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbBuild}, we intended to analyze the feature imbalance on the disaster damage embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Approximately, the number of disaster damage clusters have increased 11 more than the initial 4 classes, e.g. building collapse, flooding area, traffic incidents, and fire/smoke, that contained normal and anomalies. 
In the disaster damage feature, a few narrow clusters were distributed on the embedding space.
% Figure environment removed

% =============== 3.13 Hurricane damage
\subsection{Hurricane Damage}
\subsubsection{Backbone Studies of Supervised Detection}
As shown in Table~\ref{tab:accBackboneHurri}, our deeper FCDD-ResNet101 outperformed in terms of the $F_1$, and recall rather than the baseline CNN27 and other backbone-based deeper FCDDs in this satellite imagery dataset by remote sensing for detecting hurricane damage.
\begin{table}[h]
\caption{Backbone ablation studies on hurricane damage detection using our proposed deeper FCDDs.}
\label{tab:accBackboneHurri}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Backbone} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
CNN27 & 0.9858 & 0.9297 & 0.9172 & 0.9425 \\ \hline
VGG16 & 0.9980 & 0.9671 & 0.9770 & 0.9575 \\
\textbf{ResNet101} &\textbf{0.9982} & \textbf{0.9753} & \textbf{0.9611} & \textbf{0.9900} \\
Inceptionv3 &0.9979 & 0.9623 & 0.9671 & 0.9575 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Imbalanced-to-unsupervised Training Results}
% write from results
As shown in Table~\ref{tab:accImbalanceHurri}, we implemented ablation studies on imbalanced data that contains smaller anomalous images and relatively large normal images. Herein, we applied our deeper FCDD-ResNet101 achieved high performance in the aforementioned supervised results.  
Compared with the balanced case of positive ratio 1/1, we found that there was applicable range from the imbalanced ratio 1/2 to the ratio 1/16 where the accuracy of recall was consistently more than 97\%. 
However, extremely imbalanced range from 1/32 to 1/1300, that accuracy were inferior to those of applicable range. The rare positive ratio 1/32 represent the imbalanced data that contains quite a little 41 anomalous images and relatively large 1300 normal images. In the situation, much more anomalous images should be acquired and added to the initial dataset.   
The marginal gain of accuracy was relatively high by adding the remote sensing of hurricane damage satellite imagery. 
\begin{table}[h]
\caption{Imbalanced data studies using our deeper FCDD-ResNet101 for Hurricane damage detection $N_8=1300$.}
\label{tab:accImbalanceHurri}
\centering
\begin{tabular}{|c|c|c|c|c|}
		\hline
\textbf{Positive ratio} & \textbf{AUC} & \boldmath{$F_1$} & \textbf{Precision} & \textbf{Recall} \\
		\hline
\textbf{1/1(ano.$N_{12}$)} & \textbf{0.9982} & \textbf{0.9753} & \textbf{0.9611} & \textbf{0.9900} \\ \hline
1/2(ano.650) & 0.9986 & 0.9851 & 0.9754 & 0.9950 \\ 
1/4(ano.325) & 0.9981 & 0.9739 & 0.9656 & 0.9825 \\ 
1/8(ano.163) & 0.9956 & 0.9558 & 0.9375 & 0.9750 \\ 
1/16(ano.81)& 0.9962 & 0.9641 & 0.9535 & 0.9750 \\ \hline
\textbf{1/32(ano.41)}&\textbf{0.9889} & \textbf{0.9564} & \textbf{0.9815} & \textbf{0.9325} \\ 
\textbf{1/64(ano.20)}&\textbf{0.9818} & \textbf{0.9420} & \textbf{0.9492} & \textbf{0.9350} \\ 
\textbf{1/128(ano.10)}&\textbf{0.9734} & \textbf{0.9324} & \textbf{0.9702} & \textbf{0.8975} \\ 
\textbf{1/$N_{12}$(ano.1)} &\textbf{0.8155} & \textbf{0.7376} & \textbf{0.6807} & \textbf{0.8050} \\ \hline
\end{tabular}
\end{table}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\subsubsection{Damage-mark Heatmaps on Hurricane}
We visualized the damage features by using Gaussian upsampling in our deeper FCDD-ResNet101 network. Additionally, we generated a histogram of the anomaly scores of the test images in the imbalanced case with positive ratio $1/16$. In Fig. \ref{fig:rawHurri}, a damage-mark explanation is represented. The red region in the heatmap represents the hurricane damage of flooding features in the remote sensing satellite imagery. 
Fig. \ref{fig:histHurri} illustrates that a few overlapping bins exist in the boundary of the normal class and hurricane damaged class along the horizontal anomaly scores. Thus, for detecting hurricane damage of the flooding feature, the score range was well separated in the remote sensing satellite imagery dataset.

\subsubsection{Feedback Effect on Damage Class Mining}
As shown in Figure \ref{fig:EffectHurri}, from the view point of all accuracy, the imbalanced studies on hurricane damage implied that all of accuracy were consistently converged into significant phases. 
Ranged with the positive ratio less than $1/32$, we could understand that there were damage vision mining opportunities with accuracy gain in terms of the AUC. In contrast, ranged with positive ratio over $1/16$, it was shifting in over-mining phase without any gain of the AUC. The former phase of damage vision mining opportunities has become beneficial because of promising advantage of higher accuracy in all of them.

\subsubsection{Embedding Damage Representation}
As shown in Figure \ref{fig:mndbHurri}, we intended to analyze the feature imbalance on the hurricane damage embedding space, we implemented our MN-pair contrastive damage representation learning and density-based clustering. 
Surprisingly, the number of hurricane damage clusters have increased into 13 rather than the initial two classes because of variational features that contained tree, devastated building, flooding area. 
In the hurricane damage feature, many narrow clusters were distributed on the embedding space.
% Figure environment removed

% -------------- summerize 12 studies
\subsection{Few-shot Anomalies Feedback Effect}
As shown in Table~\ref{tab:accFeedEffect1-6}, we summerized aforementioned 6 trained results in terms of the AUC accuracy compared our imbalanced few-shot detection using the adapted backbone based deeper FCDDs with the previous unsupervised normalizing methods. In addition, we indicated the number of feature clusters from contrastive learning results using our MN-pair contrastive damage representation. 
In case of two damage vision regarding with the blood infection and driving distraction, the one-shot anomaly detection method were inferior to those of unsupervised normalizing methods. However, we found that the $1/a^{\ast}$ few-shot anomalies detection, where the positive ratios were $1/8$ and  $1/16$, achieved higher accuracy without over-mining of damage vision. 
Furthermore, in case of the breast cancer and the concrete deterioration, there were the more number of feature clusters, the more positive ratio of $1/a$ few-shot anomalies were required on the imbalanced feature space as shown in the embedding socores by the t-SNE.    
 
% ---------------------- summerize the feedback effect 1-6
\begin{table*}[h]
\caption{$1/a$ Few-shot anomalies feedback effect on accuracy AUC studied on the former 6 datasets.}
\label{tab:accFeedEffect1-6}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
\textbf{Model} & \textbf{Blood} & \textbf{Lung} & \textbf{Breast} & \textbf{Driving} & \textbf{Wood} & \textbf{Concrete}\\
		\hline
PaDiM      & 0.7378 & 0.8285 & 0.5867 & 0.9715 & 0.6132 & 0.6106 \\ 
PatchCore& 0.9415 & 0.7180 & 0.4108 & 0.9204 & 0.5758 & 0.7179 \\ 
1/$N_d$ one-shot  & 0.9174 & 0.7494  & 0.8331 & 0.8378 & 0.6136& 0.7927 \\ 
$1/(2a^{\ast})$ few-shot & 0.9919 & 0.9911 & 0.9555 & 0.9916 & 0.8947 & 0.8956 \\ 
$\mathbf{1/a^{\ast}}$ \textbf{few-shot} & \textbf{0.9907} & \textbf{0.9908} & \textbf{0.9622} & \textbf{0.9965} & \textbf{0.9101} & \textbf{0.9147} \\ \hline
$\mathbf{1/a^{\ast}}$ &\textbf{1/16} & \textbf{1/16} & \textbf{1/8} & \textbf{1/16} & \textbf{1/16} & \textbf{1/8} \\
adapted backbone & ResNet101 & ResNet101 & ResNet101 & Inceptionv3 & VGG16 & VGG16 \\
\# feature clusters & \#9 & \#12 & \#13 & \#10 & \#10 & \#21 \\ \hline
\end{tabular}
\end{table*}

As shown in Table~\ref{tab:accFeedEffect7-12}, we summarized remained 6 trained results in terms of the AUC accuracy compared our imbalanced few-shot detection using the adapted backbone based deeper FCDDs with the previous unsupervised normalizing methods. In addition, we indicated the number of feature clusters from contrastive learning results using our MN-pair contrastive damage representation. 
In case of four damage vision such as the MVTec LOCO products, vegetable damage, plant leaf infection, and disaster damages, the one-shot anomaly detection method were inferior to those of unsupervised normalizing methods. The only one-shot anomalies learning was insufficient for higher performance than the previous normalizing methods. 
However, we found that the $1/a^{\ast}$ few-shot anomalies detection, where the positive ratios were ranged from $1/16$ to $1/4$, achieved higher accuracy without over-mining of those  damage vision. 
Furthermore, in case of the plant leaf infection, there was the more number of feature clusters, the more positive ratio of $1/a$ few-shot anomalies was required on the imbalanced feature space using the embedding scores.    

% ---------------------- summerize the feedback effect 7-12
\begin{table*}[h]
\caption{$1/a$ Few-shot anomalies feedback effect on accuracy AUC studied on the latter 6 datasets.}
\label{tab:accFeedEffect7-12}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
\textbf{Model} & \textbf{Logical} & \textbf{Vegetable} & \textbf{Plant} & \textbf{River} & \textbf{Disaster} & \textbf{Hurricane}\\
		\hline
PaDiM      & 0.5307 & 0.6021 & 0.9042 & 0.7753 & 0.8134 & 0.2959 \\ 
PatchCore& 0.6885 & 0.8257 & 0.8754 & 0.6288 & 0.7435 & 0.5364 \\ 
1/$N_d$ one-shot               & 0.5520 & 0.7886 & 0.7882 & 0.8221 & 0.6870 & 0.8155 \\ 
$1/(2a^{\ast})$ few-shot& 0.7881 & 0.9771 & 0.9988 & 0.9588 & 0.9606 & 0.9889 \\ 
$\mathbf{1/a^{\ast}}$ \textbf{few-shot} & \textbf{0.8504} & \textbf{0.9838} & \textbf{0.9983} & \textbf{0.9457} & \textbf{0.9766} & \textbf{0.9962} \\ \hline
$\mathbf{1/a^{\ast}}$ &\textbf{1/8} & \textbf{1/16} & \textbf{1/8} & \textbf{1/4} & \textbf{1/16} & \textbf{1/16} \\
adapted backbone & VGG16 & ResNet101 & Inceptionv3 & ResNet101 & VGG16 & ResNet101 \\
\# feature clusters & \#11 & \#10 & \#14 & \#11 & \#11 & \#13 \\ \hline
\end{tabular}
\end{table*}

%%%%%%%%% BODY TEXT Ch4
\section{Concluding Remarks}
\subsection{$\mathbf{1/a}$ Few-shot Anomalies Feedback for Class Imbalance}
We developed an imbalanced vision application to automate one-class anomaly detection. To ensure feasibility of imbalanced damage vision datasets on the typical targets of medical disease, material deterioration, hazardous behavior, plant disease, river sludge and disaster damage. And we found that there were the adapted backbone when our deeper FCDDs were applied to imbalanced damage vision detection. Additionally, we visualized damage-mark heatmaps using direct Gaussian upsampling of the receptive field of the FCN. That created the damage-mark heatmap for visual explanation, even without annotating the target of damage at the localized regions. 
Furthermore, we compared the accuracy between our method and typical previous models of the patch-wise embedding-similarity. In result, $1/a$ few-shot anomalies feedback using our deeper FCDDs outperformed the previous normalizing methods, i.e. the PaDiM and PatchCore.

% key results
From our imbalanced studies, compared with the balanced case of positive ratio 1/1, we found that there was appropriate positive ratio $1/a$, where the accuracy were consistently high. However, extremely imbalanced range from one-shot to $1/2a$, whose accuracy were inferior to those of applicable ratio. In contrast, ranged with positive ratio over $2/a$, it was shifting in over-mining phase without effective gain of accuracy.  
Thus, we found the effective positive ratio of anomalies versus relatively large normal class without over-mining to be stable accuracy to avoid waste of time and resources for damage vision mining. 

\subsection{More Imbalanced Embedding Feature, More Anomalies Feedback}
We considered {\it feature imbalance} that minor clusters were sparsely distributed in the feature embedding space. The author implemented our MN-pair contrastive damage representation learning and density-based clustering. Surprisingly, the number of damage feature clusters had increased rather than the number of initial predefined classes that contains normal and anomalies, where damage feature clusters were distributed into a narrow region on the embedding space.
The author hypothesized that the more damage feature imbalance in the embedding space, the more few-shot anomalies feedback required. 
In result, as summarized 12 damage vision experiments, in three cases of the breast cancer, concrete deterioration, and plant leaves infection, there had been the more number of damage feature clusters in the embedding space, the more positive ratio of $1/a$ few-shot anomalies feedback were required.
    
\subsection{Limitation and Robustness for Unseen Damage}
% limitations
This study applied the specific anomaly detection model and limited targets of available datasets in the present.
Another imbalanced feature still remains for practical use in each domain. For example, medical disease, material deterioration, natural disaster damage, environmental damage. 
In outdoor field, we should consider temperature variation of damage vision in the background, for example, winter season may include unseen noise, i.e. decayed grass and snowy. 
% efficient mining
The damage vision mining in imbalanced rare events would take longer time for becoming stable accuracy. To overcome this hurdle, the anomaly score can be used in edge devices for effective data acquisition of rare classes. By unseen data mining only the anomalous vision that have damage-marks with particular higher anomaly scores, the data acquisition process can be made more efficient.
% appropriate feedback
From our key results of imbalanced studies, we found that the appropriate positive ratio of $1/a^{\ast}$ brought a promising accuracy gain as a damage vision mining merit. In contrast, ranging with the positive ratio over $2/a^{\ast}$, the accuracy has not been further gained effectively. This implies that over-mining phase has not been beneficial that we should early stop the over-mining phase of further data acquisition.  

% our tackle 
We are going to tackle the opportunities of unseen damage vision mining and improving the robustness of damage detection applications to overcome the combination of imbalance type in damage vision, based on our initial studies on flood inflow using regression\cite{Yasuno2021L2norm,Yasuno2020RainCode}, typhoon damage and river scum using image classification\cite{Yasuno2020Natural,Yasuno2022River}, 
construction material condition clustering using contrastive metric learning\cite{Yasuno2023MNPair}, concrete exfoliation and snow covered road using semantic segmentation\cite{Yasuno2019Popouts,Yasuno2020GeneraSyn,Yasuno2020Perpixel,Yasuno2021Road}, and earthquake disaster and bridge slab deterioration using anomaly detection\cite{Yasuno2019Color,Yasuno2021Bridge,Yasuno2020Generative}.    
However, these are independent domain-based damage vision modeling and application task for specific user.  

\subsection{Damage Vision Feedback on Multi-modality}
Using large scale of available damage vision data, building a foundation model for damage vision task has been important. Since 2021, the large language models have been making fast progress utilizing the vision transformers and diffusion models, such as GLIDE \cite{Nichol2022glide}, DALL-E2 \cite{Ramesh2022hierarchical}, PaLM \cite{Chowdhery2022palm}, GPT-4 \cite{Openai2023gpt4}, ImageBind \cite{Girdhar2023imagebind}, Segment Anything Model (SAM) \cite{Kirillov2023segment}, and PaLM-SayCan \cite{Ahn2022saycan}. To improve fairness and explainability for damage vision task, we have future works to create a beneficial $1/a^{\ast}$few-shot anomalies feedback algorithm using pre-trained foundation models with multi-modality connecting damage vision, diagnostic text, defective sound, and inspection robotics. We think that an appropriate feedback by $1/a^{\ast}$ few-shot anomalies brings being fair and unbiased diagnosis toward damage vision with imbalanced feature problem.

\section*{Acknowledgment}
We gratefully acknowledge the conductive comments of Professor George A. Tsihrintzis. We also thank the editorial team of Machine Learning Paradigms for the opportunity of imbalanced damage vision studies.
The authors wish to thank MathWorks and Computer Vision Toolbox Team, Takuji Fukumoto for providing helpful MATLAB resources for Automated Visual Inspection.  
%-------------------------------------------------------------------------
% Rererence
{\small
\bibliographystyle{ieee_fullname}
\bibliography{mlparabib}
}

\end{document}