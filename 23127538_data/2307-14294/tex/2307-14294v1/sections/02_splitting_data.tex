\vspace{-.2cm}
\section{Splitting Sequential Data: Challenges}
\label{sec:splitting_seq_data}
\vspace{-.2cm}
The common 80\% and 20\% splitting strategy for non-sequential data to train and test ML routines, inspired by the Pareto principle, is unsuitable for modelling time dependencies as it lacks temporal information and dependencies.
% A common strategy of splitting non-sequential data into subsets of 80\% and 20\% for training and testing ML routines (inspired by the Pareto principle) is unsuitable for modelling time dependencies, as the temporal information is lost.
% , i.e., using 80\% train; 20\% test (inspired by the Pareto principle), is mostly not suitable for modelling time dependencies as random sample selection does not capture temporal information. 
% There are multiple strategies to split sequential data. Here, we briefly introduce some common techniques: 
% A \textbf{simple split}, where one determines a percentage, e.g., 80~\% train; 20~\% test [Ref.] (inspired by the Pareto principle), and randomly distributes data. This approach is most likely not suitable for sequential data as the time dependency of the data gets lost and there is potential for leakage of future information into the training set.
% Therefore, 
One common modification to split sequential data is to use a \textbf{temporal split}, where the first percentage of data, e.g., 80 \%, is used as training data; the remaining data is a test set. This way, one keeps the temporal order of the data. 
%patterns that appear in different areas of a series of measurements cannot be captured, and 
This approach, however, may lack generalization of the overall process.
% However, this may lead to novelties in the test data which may not be accounted for during training. A \textbf{time-based split} is similar to the temporal split, but it takes into account timestamps. However, the challenges remain.
\textbf{Cross-validation}~\cite{Bergmeir2012} can be applied to sequential data, extracting multiple segments for a predefined number $k$ of groups, e.g., folds. This is particularly useful for hyperparameter optimisation considering the average performance. Still, cross-validation methods assume that each sequence in the dataset is independent and identically distributed (i.i.d), which is not valid for correlated time series data. As a result, common cross-validation methods can lead to overly optimistic estimates of the model's performance. 
% which may lead to more robust models than the other approaches. In $k$-fold cross-validation, one divides the data into $k$ equal-sized folds. You train the model on $k-1$ folds and test it on the remaining fold. This process is repeated $k$ times, with each fold serving as the test set once. When choosing the $k$-folds, one has to keep in mind the temporal dependence of the data.
The \textbf{sliding window approach}~\cite{keogh_online_2001} is another standard method for segmenting sequential data for ML model training. However, critical factors are selecting an optimal window size that captures relevant information and determining the overlap between consecutive windows to avoid missing transitions and patterns.
%In addition, it is essential to note that if the extracted segments belong to the same series of measurements, it also results in overconfident predictions.
% One other approach focuses on creating multiple training and test sets using a \textbf{sliding window} approach. There, one can define a window size and slide it across the sequential data, creating overlapping segments. This approach allows the model to learn from shorter subsequences and capture local patterns.
% However, all of these approaches have a major drawback. It is important to consider the temporal order and the potential for information leakage when splitting sequential data into train and test sets.
% And all of this leads to the question, how to determine which method is the right one to choose. In this paper, we want to address five key aspects which need to be considered when choosing a proper method. 
% What we do not take into account:
% Of course, everything depends on the task at hand. This has to be done in advance before focusing on the upcoming points. Moreover, we do not assume that there are limitations of data and that new data can be collected either by simulations or new experiments. We also assume that the labeling process has already been completed.
Given the various options, the question of how to choose the appropriate data selection method for ML training arises. This article states four key aspects towards this goal (cf.~Fig.~\ref{fig:abstract}).
% while making this decision. 
However, it is vital to note that selecting a method depends on the specific task and should be evaluated before addressing the following points. Additionally, we assume that there are no data limitations and that new data can be obtained through simulations or additional experiments. Lastly, we assume that the labeling process has already been completed.

\textbf{I. Data Acquisition / Selection:} Prior to starting the ML process, the experiment's use cases, conditions, restrictions, and boundaries need to be evaluated. The purpose is to establish a sufficient and diverse database containing all relevant information either from experimentation or simulation. This involves considering the system's operational areas and design parameter constraints in the experiment. 
%In addition, the generation of synthetic data can be considered to expand the dataset. 
% Before even starting ML, one has to think about the experiment first. This means: Thinking about use cases, Conditions, restrictions, boundaries. The goal is to establish a large enough data base containing all relevant information.
% Consider Operation areas of the system and constraints of the design parameters in the experiment.
% (Generation of synthetic Data)

\textbf{II. Representation:} 
% What kind of representation is suitable for a desired experiment. Are the parameters of this representation (sequence length, features, ...) enough for training the model and therefore learning the defined task. Data preprocessing required? Missing values, removing outlier, Scaling.
To prepare data for ML training (next to preprocessing, of course), one must consider the most fitting representation for the desired experiment. It is essential to evaluate if the parameters of this representation, e.g., sequence length, features, and periodicity, are sufficiently taken into account for training the model and accomplishing the defined task.
%Additionally, one should assess whether data preprocessing is necessary, such as addressing missing values, removing outliers, and scaling the data.

\textbf{III. Split Ratio:} 
% When splitting the dataset into training, validation, and test sets, several factors need to be considered. Firstly, the split ratio should
%Depending on the amount of available data
In general, all splits should contain all relevant scenarios in the experiment to avoid overfitting. High data versatility is necessary to prevent bias during training. Lastly, an isolated validation dataset is recommended when tuning the model's hyperparameters to improve generalization performance.
% In general, the inclusion of all relevant scenarios in the splits to enhance the model's generalization is required. Account for high data versatility to prevent bias during training. Use a separate validation dataset for hyperparameter tuning and better generalization.
% Is it dependent on the amount of data? (Yeah, it should be of course)
% All splits should contain all relevant scenarios in the experiment. Improvement of the generalisation ability.  
% When do we need an isolated validation dataset?

\textbf{IV. Quality Criteria:} Their definition (in advance) is essential, depending on the use case. Before placing an instance in a particular data split, tools such as statistical tests and distance measures can be used to assess the information gain or similarity of individual pre-selected samples. Addressing changes in the environment, i.e. domain shifts, during experiments and identifying new operation areas are necessary for updating the training data. Task-dependent criteria for change point detection, novelty and anomaly detection are critical for setting up a database which provides enough information about specific scenarios. If it is decided that there are not enough representatives for a scenario, new ones must be sampled/generated considering further selection strategies, cf.~\textbf{I}.

% Defining quality criteria (in advance) is essential depending on the use case. In general, tools such as statistical tests and distance measures can be used to assess the information gain or similarity of individual, previously selected samples and, on this basis, decide where to put them. 


% If one decides that there are not enough representatives concerning one scenario, new ones must be sampled/generated using selection strategies, cf.~\textbf{I}.
% How to choose data? How to handle temporal dependencies? What technique suits which scenario the best? How to measure similarity and diversity in the data? 
%Common descriptive statistics, such as mean, standard deviation, and skewness, provide insight into the distribution of the data and identify potential outliers or missing values. For high-dimensional data, techniques such as principal component analysis (PCA)~\cite{} or t-SNE~\cite{} can be used to visualize and extract meaningful features. Measuring similarity and diversity in the data can be achieved through techniques such as cosine similarity~\cite{} or clustering algorithms, such as k-means or hierarchical clustering~\cite{}. The choice of technique depends on the specific scenario and the desired outcome of the analysis.

% \textbf{(5) Selection Strategy:} According to the quality criteria, which data scenarios are missing? Which ones should be picked next?


% The text of the paper should be formatted in two columns, with an
% overall width of 6.75~inches, height of 9.0~inches, and 0.25~inches
% between the columns. The left margin should be 0.75~inches and the top
% margin 1.0~inch (2.54~cm). The right and bottom margins will depend on
% whether you print on US letter or A4 paper, but all final versions
% must be produced for US letter size.
% Do not write anything on the margins.

% The paper body should be set in 10~point type with a vertical spacing
% of 11~points. Please use Times typeface throughout the text.

% \subsection{Title}

% The paper title should be set in 14~point bold type and centered
% between two horizontal rules that are 1~point thick, with 1.0~inch
% between the top rule and the top edge of the page. Capitalize the
% first letter of content words and put the rest of the title in lower
% case.

% \subsection{Author Information for Submission}
% \label{author info}

% ICML uses double-blind review, so author information must not appear. If
% you are using \LaTeX\/ and the \texttt{icml2023.sty} file, use
% \verb+\icmlauthor{...}+ to specify authors and \verb+\icmlaffiliation{...}+ to specify affiliations. (Read the TeX code used to produce this document for an example usage.) The author information
% will not be printed unless \texttt{accepted} is passed as an argument to the
% style file.
% Submissions that include the author information will not
% be reviewed.

% \subsubsection{Self-Citations}

% If you are citing published papers for which you are an author, refer
% to yourself in the third person. In particular, do not use phrases
% that reveal your identity (e.g., ``in previous work \cite{langley00}, we
% have shown \ldots'').

% Do not anonymize citations in the reference section. The only exception are manuscripts that are
% not yet published (e.g., under submission). If you choose to refer to
% such unpublished manuscripts \cite{anonymous}, anonymized copies have
% to be submitted
% as Supplementary Material via CMT\@. However, keep in mind that an ICML
% paper should be self contained and should contain sufficient detail
% for the reviewers to evaluate the work. In particular, reviewers are
% not required to look at the Supplementary Material when writing their
% review (they are not required to look at more than the first $8$ pages of the submitted document).

% \subsubsection{Camera-Ready Author Information}
% \label{final author}

% If a paper is accepted, a final camera-ready copy must be prepared.
% %
% For camera-ready papers, author information should start 0.3~inches below the
% bottom rule surrounding the title. The authors' names should appear in 10~point
% bold type, in a row, separated by white space, and centered. Author names should
% not be broken across lines. Unbolded superscripted numbers, starting 1, should
% be used to refer to affiliations.

% Affiliations should be numbered in the order of appearance. A single footnote
% block of text should be used to list all the affiliations. (Academic
% affiliations should list Department, University, City, State/Region, Country.
% Similarly for industrial affiliations.)

% Each distinct affiliations should be listed once. If an author has multiple
% affiliations, multiple superscripts should be placed after the name, separated
% by thin spaces. If the authors would like to highlight equal contribution by
% multiple first authors, those authors should have an asterisk placed after their
% name in superscript, and the term ``\textsuperscript{*}Equal contribution"
% should be placed in the footnote block ahead of the list of affiliations. A
% list of corresponding authors and their emails (in the format Full Name
% \textless{}email@domain.com\textgreater{}) can follow the list of affiliations.
% Ideally only one or two names should be listed.

% A sample file with author names is included in the ICML2023 style file
% package. Turn on the \texttt{[accepted]} option to the stylefile to
% see the names rendered. All of the guidelines above are implemented
% by the \LaTeX\ style file.

% \subsection{Abstract}

% The paper abstract should begin in the left column, 0.4~inches below the final
% address. The heading `Abstract' should be centered, bold, and in 11~point type.
% The abstract body should use 10~point type, with a vertical spacing of
% 11~points, and should be indented 0.25~inches more than normal on left-hand and
% right-hand margins. Insert 0.4~inches of blank space after the body. Keep your
% abstract brief and self-contained, limiting it to one paragraph and roughly 4--6
% sentences. Gross violations will require correction at the camera-ready phase.

% \subsection{Partitioning the Text}

% You should organize your paper into sections and paragraphs to help
% readers place a structure on the material and understand its
% contributions.

% \subsubsection{Sections and Subsections}

% Section headings should be numbered, flush left, and set in 11~pt bold
% type with the content words capitalized. Leave 0.25~inches of space
% before the heading and 0.15~inches after the heading.

% Similarly, subsection headings should be numbered, flush left, and set
% in 10~pt bold type with the content words capitalized. Leave
% 0.2~inches of space before the heading and 0.13~inches afterward.

% Finally, subsubsection headings should be numbered, flush left, and
% set in 10~pt small caps with the content words capitalized. Leave
% 0.18~inches of space before the heading and 0.1~inches after the
% heading.

% Please use no more than three levels of headings.

% \subsubsection{Paragraphs and Footnotes}

% Within each section or subsection, you should further partition the
% paper into paragraphs. Do not indent the first line of a given
% paragraph, but insert a blank line between succeeding ones.

% You can use footnotes\footnote{Footnotes
% should be complete sentences.} to provide readers with additional
% information about a topic without interrupting the flow of the paper.
% Indicate footnotes with a number in the text where the point is most
% relevant. Place the footnote in 9~point type at the bottom of the
% column in which it appears. Precede the first footnote in a column
% with a horizontal rule of 0.8~inches.\footnote{Multiple footnotes can
% appear in each column, in the same order as they appear in the text,
% but spread them across columns and pages if possible.}

% % Figure environment removed

% \subsection{Figures}

% You may want to include figures in the paper to illustrate
% your approach and results. Such artwork should be centered,
% legible, and separated from the text. Lines should be dark and at
% least 0.5~points thick for purposes of reproduction, and text should
% not appear on a gray background.

% Label all distinct components of each figure. If the figure takes the
% form of a graph, then give a name for each axis and include a legend
% that briefly describes each curve. Do not include a title inside the
% figure; instead, the caption should serve this function.

% Number figures sequentially, placing the figure number and caption
% \emph{after} the graphics, with at least 0.1~inches of space before
% the caption and 0.1~inches after it, as in
% \cref{icml-historical}. The figure caption should be set in
% 9~point type and centered unless it runs two or more lines, in which
% case it should be flush left. You may float figures to the top or
% bottom of a column, and you may set wide figures across both columns
% (use the environment \texttt{figure*} in \LaTeX). Always place
% two-column figures at the top or bottom of the page.

% \subsection{Algorithms}

% If you are using \LaTeX, please use the ``algorithm'' and ``algorithmic''
% environments to format pseudocode. These require
% the corresponding stylefiles, algorithm.sty and
% algorithmic.sty, which are supplied with this package.
% \cref{alg:example} shows an example.

% \begin{algorithm}[tb]
%    \caption{Bubble Sort}
%    \label{alg:example}
% \begin{algorithmic}
%    \STATE {\bfseries Input:} data $x_i$, size $m$
%    \REPEAT
%    \STATE Initialize $noChange = true$.
%    \FOR{$i=1$ {\bfseries to} $m-1$}
%    \IF{$x_i > x_{i+1}$}
%    \STATE Swap $x_i$ and $x_{i+1}$
%    \STATE $noChange = false$
%    \ENDIF
%    \ENDFOR
%    \UNTIL{$noChange$ is $true$}
% \end{algorithmic}
% \end{algorithm}

% \subsection{Tables}

% You may also want to include tables that summarize material. Like
% figures, these should be centered, legible, and numbered consecutively.
% However, place the title \emph{above} the table with at least
% 0.1~inches of space before the title and the same after it, as in
% \cref{sample-table}. The table title should be set in 9~point
% type and centered unless it runs two or more lines, in which case it
% should be flush left.

% % Note use of \abovespace and \belowspace to get reasonable spacing
% % above and below tabular lines.

% \begin{table}[t]
% \caption{Classification accuracies for naive Bayes and flexible
% Bayes on various data sets.}
% \label{sample-table}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{lcccr}
% \toprule
% Data set & Naive & Flexible & Better? \\
% \midrule
% Breast    & 95.9$\pm$ 0.2& 96.7$\pm$ 0.2& $\surd$ \\
% Cleveland & 83.3$\pm$ 0.6& 80.0$\pm$ 0.6& $\times$\\
% Glass2    & 61.9$\pm$ 1.4& 83.8$\pm$ 0.7& $\surd$ \\
% Credit    & 74.8$\pm$ 0.5& 78.3$\pm$ 0.6&         \\
% Horse     & 73.3$\pm$ 0.9& 69.7$\pm$ 1.0& $\times$\\
% Meta      & 67.1$\pm$ 0.6& 76.5$\pm$ 0.5& $\surd$ \\
% Pima      & 75.1$\pm$ 0.6& 73.9$\pm$ 0.5&         \\
% Vehicle   & 44.9$\pm$ 0.6& 61.5$\pm$ 0.4& $\surd$ \\
% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table}

% Tables contain textual material, whereas figures contain graphical material.
% Specify the contents of each row and column in the table's topmost
% row. Again, you may float tables to a column's top or bottom, and set
% wide tables across both columns. Place two-column tables at the
% top or bottom of the page.

% \subsection{Theorems and such}
% The preferred way is to number definitions, propositions, lemmas, etc. consecutively, within sections, as shown below.
% \begin{definition}
% \label{def:inj}
% A function $f:X \to Y$ is injective if for any $x,y\in X$ different, $f(x)\ne f(y)$.
% \end{definition}
% Using \cref{def:inj} we immediate get the following result:
% \begin{proposition}
% If $f$ is injective mapping a set $X$ to another set $Y$, 
% the cardinality of $Y$ is at least as large as that of $X$
% \end{proposition}
% \begin{proof} 
% Left as an exercise to the reader. 
% \end{proof}
% \cref{lem:usefullemma} stated next will prove to be useful.
% \begin{lemma}
% \label{lem:usefullemma}
% For any $f:X \to Y$ and $g:Y\to Z$ injective functions, $f \circ g$ is injective.
% \end{lemma}
% \begin{theorem}
% \label{thm:bigtheorem}
% If $f:X\to Y$ is bijective, the cardinality of $X$ and $Y$ are the same.
% \end{theorem}
% An easy corollary of \cref{thm:bigtheorem} is the following:
% \begin{corollary}
% If $f:X\to Y$ is bijective, 
% the cardinality of $X$ is at least as large as that of $Y$.
% \end{corollary}
% \begin{assumption}
% The set $X$ is finite.
% \label{ass:xfinite}
% \end{assumption}
% \begin{remark}
% According to some, it is only the finite case (cf. \cref{ass:xfinite}) that is interesting.
% \end{remark}
% %restatable

% \subsection{Citations and References}

% Please use APA reference format regardless of your formatter
% or word processor. If you rely on the \LaTeX\/ bibliographic
% facility, use \texttt{natbib.sty} and \texttt{icml2023.bst}
% included in the style-file package to obtain this format.

% Citations within the text should include the authors' last names and
% year. If the authors' names are included in the sentence, place only
% the year in parentheses, for example when referencing Arthur Samuel's
% pioneering work \yrcite{Samuel59}. Otherwise place the entire
% reference in parentheses with the authors and year separated by a
% comma \cite{Samuel59}. List multiple references separated by
% semicolons \cite{kearns89,Samuel59,mitchell80}. Use the `et~al.'
% construct only for citations with three or more authors or after
% listing all authors to a publication in an earlier reference \cite{MachineLearningI}.

% Authors should cite their own work in the third person
% in the initial version of their paper submitted for blind review.
% Please refer to \cref{author info} for detailed instructions on how to
% cite your own papers.

% Use an unnumbered first-level section heading for the references, and use a
% hanging indent style, with the first line of the reference flush against the
% left margin and subsequent lines indented by 10 points. The references at the
% end of this document give examples for journal articles \cite{Samuel59},
% conference publications \cite{langley00}, book chapters \cite{Newell81}, books
% \cite{DudaHart2nd}, edited volumes \cite{MachineLearningI}, technical reports
% \cite{mitchell80}, and dissertations \cite{kearns89}.

% Alphabetize references by the surnames of the first authors, with
% single author entries preceding multiple author entries. Order
% references for the same authors by year of publication, with the
% earliest first. Make sure that each reference includes all relevant
% information (e.g., page numbers).

% Please put some effort into making references complete, presentable, and
% consistent, e.g. use the actual current name of authors.
% If using bibtex, please protect capital letters of names and
% abbreviations in titles, for example, use \{B\}ayesian or \{L\}ipschitz
% in your .bib file.
