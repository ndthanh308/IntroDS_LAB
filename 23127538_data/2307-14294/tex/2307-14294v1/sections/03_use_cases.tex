\subsection*{Video Data Use Case: Particle Tracking in Liquids}
%\textbf{Video Data Use Case: Particle Tracking in Liquids}
Tracking in video data is a common challenge in computer vision tasks where one wants to track an object through a series of images or, in this case, extract the centre coordinates $(x, y, z)$ of particles moving in liquids~\cite{Dingel2021adapt} to implement lab-on-a-chip technologies~\cite{Lim2010}. 
% Unlike video data captured in the everyday world, microscopic video data creates issues that can significantly affect tracking, i.e., depth of focus, motion and blur, noise, artefacts, lighting, video binning, and contrast. 
Unlike video data captured in the everyday world, additional factors in microscopic video data can significantly affect tracking, i.e., depth of focus, motion and blur, noise, artefacts, lighting, video binning, and contrast. 
In addition to that, the same issues as with classical object tracking tasks apply, such as missing labels and the difficulty of incorporating simulation data due to the large gap between simulation and reality~\cite{Dingel2021}.
% In addition, there are the same problems as with other object tracking tasks, such as missing labels and the difficulty of incorporating simulation data due to the large gap between simulation and reality~\cite{Dingel2021}.
% In addition to that, there come along the same issues as with other object tracking tasks such as missing labels and the difficulty of incorporating simulation data due to the large gap between simulation and reality~\cite{Dingel2021}.
Further, it must be noted that video content can vary significantly from experiment to experiment. But also, consecutive video frames within one experiment may appear similar due to high frame rates or long sequences without particle movement. It leads to imbalanced datasets, and selecting relevant video sequences for training and testing is of utmost importance~\textbf{(I,~IV)}. Especially in the case of tracking, attention must be paid to the sequence length~\textbf{(II)} considering the possible shortage of storage space during the recording of an experiment, which results in short video sequences whose separation would not be ideal. This makes it all the more important to consider an appropriate data representation~\textbf{(II)} and split ratio~\textbf{(III)} and finally establish data quality criteria, which in turn will largely dictate the selection strategy for extending the data splits.
Finally, this particular use case shows the benefit of having a closed-loop-experimentation station~\cite{Sanchez-Lengeling2018}. It allows the creation of new training data on the fly by actively~\cite{Kottke2021} asking for missing or underrepresented data using the pre-defined quality criteria and requirements~\textbf{(IV)}. 
% Additionally, consecutive video frames within one experiment may appear similar due to high frame rates or long sequences without particle movement, which could lead to imbalanced datasets. 
% The selection of appropriate video sequences for training and testing is of utmost importance~\textbf{(I)}. The benefit of having a closed-loop-experimentation~\cite{Sanchez-Lengeling2018} station is that one can create new training data on the fly by actively~\cite{Kottke2021} asking for missing or underrepresented data using the pre-defined quality criteria and requirements~\textbf{(IV)}. 
% Here, it must be noted that video content can vary significantly from experiment to experiment, which needs to be accounted for during data selection~\textbf{(I,~IV)}. Especially in the case of tracking, attention must be paid to the sequence length. 
% A shortage of storage space during the recording of an experiment may result in short video sequences whose separation would not be ideal.
 
% A limitation of storage space during the recording of an experiment can lead to brief video sequences, the separation of which would not be ideal.
% Investigating a suitable dataset representation~\textbf{(II)} and split ratio~\textbf{(III)} is all the more important. All of the previously mentioned components will lead to establishing data quality criteria, which in turn will largely dictate the selection strategy for new training and test data. 

\subsection*{Time Series Data Use Case: Motor Test Bench}
%\textbf{Time Series Data Use Case: Motor Test Bench}
% In the following use-case, we highlight the challenges in the monitoring task of a motor test bench during the experimental evaluation process of motor prototypes using ML techniques~\cite{Botache2021}. The data acquired consist of high dimensional heterogeneous times series data of multiple sensors. This is necessary due to the multitude of factors influencing motor performance. Consequently, the experimental process is time-consuming and possible faults and malfunctions could lead to downtimes in the experimental process. An ML-supported monitoring strategy should take advantage of the information acquired considering possible correlations and time dependencies of the features. The early detection of possible faults in the test bench could improve the experimental process tremendously. The challenges in designing the monitoring task, the acquisition of the data, finding a suitable representation of the time series for the training process of ML models and finally, the quality assessment of the data splits used for the evaluation and hyperparameter optimisation of the models are come of the key points to be considered in this application field 
This use case involves monitoring a motor test bench using deep-learning techniques~\cite{Botache2021}. The data is high-dimensional and heterogeneous, obtained from multiple sensors capturing factors affecting motor performance. An ML-supported monitoring strategy must consider correlations and time dependencies to detect faults early on, improving the experimental process. 
% The first challenge consists of the definition of the Task.
When designing fault detection as a binary classification task, the data should contain faulty instances for each operating area. Also, acquiring multiple measurements independently from each other is critical to generate splits containing single experiments. Therefore, the i.i.d. assumption should hold for each data split~\textbf{(I)}. Extracting segments of the same length is the first step for creating the input space for ML techniques~\textbf{(II)}. Still, long sequences represent higher model complexity for a constant sampling rate and shorter sequences, on the other side, may not capture enough time dependencies in the data. Next, extracting significant features could reduce the complexity of the task, e.g., by removing categorical signals and employing representation learning techniques. 
In a binary classification task, fault instances are usually rare, challenging to acquire, and therefore underrepresented in data splits. Oversampling techniques~\cite{kovacs_empirical_2019}, active-learning with class-balance selection~\cite{cai2022active}, and synthetic data generation are highly recommended for improving the split ratio of the datasets~\cite{Westmeier2022}~\textbf{(III)}. In addition, using weighted losses~\cite{lin2017focal} can improve the learning task of the algorithms. Finally, the quality assessment of the data split using similarity measurements is necessary for identifying potentially unexploited areas in the data distribution~\textbf{(IV)}. 

% A basic quality assessment of the data splits using Wasser-Stein-Distance~\cite{}, Frechét-Inception-Distance (FID)~\cite{} is necessary. For uneven segment lengths, additional similarity Measures can be considered i.e. Dynamic-Time-Warping (DTW)~\cite{}. Finally, a continuous selection strategy of new instances for the datasets should consider the gain of novel information, such as new operation areas, but also new possible fault cases.

% The challenges in designing the monitoring task, acquiring and representing the time series data for ML model training, and evaluating data quality are critical considerations and can be summarized as follows:

% \begin{itemize}
%     \item The first challenge consists of the definition of the Task. When designing fault detection as a binary classification task, the data acquired should contain enough faulty instances for each operating area. In addition to that, the acquisition of multiple measurements independently from each other allows us to create data splits which contain single experiments. Therefore, we make sure that the independent and identically distributed data assumption (i.i.d.)~\cite{} holds for each data split.
%     \item The data representation is a critical factor, and extracting segments from the acquired time series data is the first step for creating the input space for ML techniques. The length of the segments can be considered as one critical hyperparameter for detecting faults. Long sequences represent higher model complexity because the number of points to be analyzed is higher. Shorter sequences, on the other side, do not capture enough time dependencies in the data. Finally, the extraction of meaningful features could reduce the complexity of the task, for example, by removing categorical signals but also employing representation learning techniques. 
%     \item The Ratio of the data acquired is highly dependent on the defined task for the ML model. Fault instances are usually rare and challenging to acquire. High data unbalances should be considered in the training process by using weight Losses such as Focal Loss~\cite{}. Oversampling techniques~\cite{} can also improve the learning task and finally, the generation of synthetic data is highly recommended for unbalanced problems~\cite{Westmeier2022}.
%     \item A basic quality assessment of the data splits using Wasser-Stein-Distance~\cite{}, Frechét-Inception-Distance (FID)~\cite{} is necessary. For uneven segment lengths, additional similarity Measures can be considered i.e. Dynamic-Time-Warping (DTW)~\cite{}. Finally, a continuous selection strategy of new instances for the datasets should consider the gain of novel information, such as new operation areas, but also new possible fault cases. 
% \end{itemize}



% If a paper is accepted, we strongly encourage the publication of software and data with the
% camera-ready version of the paper whenever appropriate. This can be
% done by including a URL in the camera-ready copy. However, \textbf{do not}
% include URLs that reveal your institution or identity in your
% submission for review. Instead, provide an anonymous URL or upload
% the material as ``Supplementary Material'' into the CMT reviewing
% system. Note that reviewers are not required to look at this material
% when writing their review.

\section{Conclusion}

Especially with respect to ML training processes, extracting appropriate training and test splits for time-dependent data is still a major challenge. In this concept paper, we identified four key research questions and put them in concrete terms using two use cases for time series and video data, which now require further investigation.