\section{Introduction}
% General motivation for using predictive models in optimization
Mathematical programming is one of the fundamental tools of applied mathematics. It is utilized in various domains, such as finance \citep{Cornuejols2006}, power systems \citep{Bansal2005}, robotics \citep{Raja2012}, and many others. The main practical limitation of mathematical programming is that it requires a fully-defined model describing the problem which is not always available in reality. A promising approach to overcome this limitation is to employ machine learning (ML) to predict missing parts of the model \citep{ning2019}.

% Introduction of the PO framework, highlight its core idea of doing decision-based learning
\textit{Predict and optimize} (P\&O) \citep{Elmachtoub2017} is a decision-making paradigm that combines ML with mathematical programming. It considers optimization problems where some parameters are unknown and should be predicted prior to solving the problem. The P\&O approach builds upon the observation that naively training an ML algorithm to match the distribution of unknown parameters is inefficient \citep{Elmachtoub2017}, as this approach does not take the actual task performance into account. Instead, P\&O aims at using task performance as the objective function for ML models directly.

% Highlight that we want to compute gradients and that there is already a method for that.
The standard approach to training models in machine learning is to use gradient-based algorithms, such as stochastic gradient descent \cite{kiefer1952stochastic}. In predict and optimize, computing the gradient of the task performance involves differentiating the solution of the optimization problem with respect to the parameters, which is a non-trivial task. In their seminal work, \citet{Agrawal2019} have shown that a large class of convex optimization problems indeed can be differentiated. 
%This finding has been used in various works. \citet{Wilder2019-ai} used it to differentiate linear problems using a quadratic approximation. Their results were improved in \citep{Mandi2020} by using a logarithmic approximation instead. In \citep{Ferber2020-aj}, mixed-integer problems were differentiated by combining the cutting plane algorithm with quadratic approximations. In \citep{Wang2020} differential optimization was used to learn compact surrogate models, in \citep{Chen2021} it was applied to a reinforcement learning setup.

% Our contributions
In this paper, we identify a fundamental drawback of differential optimization -- the \textit{zero-gradient problem}. Specifically, we show that the Jacobian of convex problems often has a large null space, and hence the task performance, as a function of the ML model parameters, is flat in a significant part of its domain. Therefore, it can not be optimized using gradient-based methods.  Consequently, we introduce a way to compute an approximate gradient that is zero only in the optimal solution and is guaranteed to not decrease performance. Finally, we validate the superiority of this method using two real-world problems: the portfolio optimization problem and the optimal power flow problem. 