\section{Predict and optimize}
In this section, we provide an overview of the existing research in the predict and optimize domain. Then, we define the P\&O problem and introduce the solution approach that we are going to investigate later in this manuscript.
\subsection{Related work}
To the best of our knowledge, the predict and optimize framework was first introduced by \citet{Elmachtoub2017}. They consider optimization problems with linear objectives and derive a convex approximation of the task performance function. Then, they optimize the prediction model by using sub-gradients of this approximation. Later, this method was extended onto combinatorial problems by \citet{emir2019}. Several other approximations were introduced in other studies focusing on combinatorial problems. \citet{Vlastelica2019} derive a differentiable piecewise-linear approximation for the task performance; \citet{Berthet2020-rp} employ stochastic perturbations to approximate derivative of combinatorial problems.

Unlike in the combinatorial case, continuous convex optimization problems do allow exact differentiation of the loss function.  The sequence of works \citep{Amos2017}, \citep{Agrawal2019cp}, \citep{Agrawal2019} developed a differential optimization technique to compute the derivative of convex optimization problems. In their latest work \citep{Agrawal2019}, the authors delivered a general method that allows differentiating disciplined convex programs \citep{Grant2006}. This result gave rise to new applications of P\&O to convex optimization: \citet{Uysal2021-el} applied convex differential optimization to the risk budgeting portfolio optimization problem; \citet{Wang2020} utilized it to learn surrogate models for predict and optimize; \citet{Donti2017} applied the method to three different real-world benchmarks. Moreover, several studies applied differential optimization to predict and optimize for other problem classes. In \cite{Wilder2019-ai}, it was used in linear optimization via constructing a quadratic approximation of the problem. Later, \citet{Mandi2020} improved upon this result by using logarithmic approximations. \citet{Ferber2020-aj} combined a similar idea with the cutting plane approach and used differential optimization in combinatorial problems.

Outside of predict and optimize, differential optimization also has found several applications. \citet{Chen2021} used it to train reinforcement learning agents in the action space with convex constraints, and \citet{Agrawal2019-ru}, employed it for tuning model predictive control algorithms.

While the benefits of the differential optimization approach to predict and optimize are numerous, it is still not fully understood. It was reported in several studies \cite{Vlastelica2019,Wilder2019-ai}, that the gradient of a linear problem is zero everywhere, except for the finite set of points where it is undefined. Since any linear problem is convex, this observation suggests that the gradients of convex problems should be also thoroughly investigated.

\subsection{Problem formulation}
In this section, we introduce the P\&O problem. We refer readers to \cite{Elmachtoub2017} for further details.
In predict and optimize, we solve optimization problems of the form
\begin{equation}
   \argmax_{x} f(x, w) \text{ s. t. } x\in\mathcal{C},
   \label{eq:true-problem}
   \tag{True problem}
\end{equation}
where $x\in\mathbb{R}^n$ is the decision variable, $w\in\mathbb{R}^u$ is a vector of unknown parameters, ${f: \mathbb{R}^n \times \mathbb{R}^u \to \mathbb{R}}$ is the objective function, and $\mathcal{C}$ is the feasibility region. The defining feature of this problem is that the parameters $w$ are unknown at the moment when the decision must be made. Therefore, the true optimization problem is under-defined and cannot be solved directly.

One way to deal with the unknown parameters $w$ is to use a prediction $\hat{w}$ instead. Then, the decision can be computed by solving the following problem, which we refer to as the internal problem:
\begin{equation}
   x^\ast(\hat{w}) = \argmax_{x} f(x, \hat{w}) \text{ s. t. } x\in\mathcal{C}.
   \tag{Internal problem}
\end{equation}
A commonly made assumption is that instead of $w,$ we observe a feature vector $o$ that contains some information about $w.$ Also, we have a  dataset $\mathcal{D}=\{(o_k, w_k)\},$ e.g., of historical data, which we can use to learn the relation between $w$ and $o.$ This setup enables using ML models to compute the prediction. We denote the prediction model by $\phi_\theta$, and thus we have $\hat{w} = \phi_\theta(o)$. 

The problem described above is not specific to predict and optimize. What separates the P\&O paradigm from earlier works is the approach to training the model $\phi_\theta.$ In the past, machine learning models would be trained to predict $w$ as accurately as possible, e.g., in \cite{mukhopadhyay2017prioritized}. However, the parameter prediction error is merely an artificial objective and our true goal is to derive a decision $x$ that maximizes the task performance $f(x, w).$ The main goal of the P\&O approach is to utilize this objective for training the model $\phi_\theta.$ The task performance achieved by $\phi_\theta$ on the dataset $\mathcal{D}$ can be quantified by the following loss function:
\begin{equation}
   L(\theta) = -\frac{1}{|\mathcal{D}|}\sum_{(o, w) \in \mathcal{D}} f\Big(
   x^\ast\big(\phi_\theta(o)\big), w\Big)
   \label{eq:po-loss}
\end{equation}
Most machine learning algorithms for training models are based on computing the gradient of the loss function (\cite{kiefer1952stochastic}).  To train $\phi_\theta$ with a gradient-based algorithm, we need to differentiate $L$ over $\theta,$ and hence we need to compute the gradient $\nabla_{\theta}f\Big(
   x^\ast(\hat{w}), w\Big),$ where $\hat{w}=\phi_\theta(o).$ Applying the chain rule, it can be decomposed into three terms:
\begin{equation}
  \nabla_{\theta}f\Big(x^\ast(\hat{w}), w\Big) = 
  \nabla_{x}f\big(x^\ast(\hat{w}), w\big)\;
  \nabla_{\hat{w}} x^\ast(\hat{w})\;
  \nabla_{\theta} \hat{w}.
  \label{eq:chain-rule}
\end{equation}
The second term, $\nabla_{\hat{w}}x^\ast(\hat{w}),$ is the Jacobian of the solution of the optimization problem over the prediction $\hat{w}.$ An exact method to compute this Jacobian was introduced in \cite{Agrawal2019}, but it has never been thoroughly analyzed. 
In the next section, we show that $\nabla_{\hat{w}}x^\ast(\hat{w})$ has a large null space, thereby causing the total gradient in Eq.~\ref{eq:chain-rule} to be zero even outside of the optimum.