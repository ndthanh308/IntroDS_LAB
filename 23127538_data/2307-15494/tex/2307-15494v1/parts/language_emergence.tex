\section{Language Emergence}
\label{sec:language-emergence}
Compositionality and recursive syntax are the two main properties shared between all natural languages that account for their expressivity and flexibility. Among other things, they allow an ease of learning/acquisition as it can be seen in the \textit{poverty of the stimulus} phenomenon (``children master complex features of language on the basis of surprisingly little evidence" \citep{Brighton2002}).

When talking about language, it is common to differentiate between two language domains: I(Internal)-Language and E(External)-Language \citep{chomsky1986knowledge, hurford1987language, kirby2002learning} %Kirby199812
. I-Language is the internal representation a user has of the language it speaks and listens to, whilst E-Language is the set of external presentations/``utterances in the arena of use"\citep{hurford1987language} of language, when any of the users actually speak in an attempt to express a given meaning.

How language users are able to acquire an I-Language and are then able to contribute to the E-Language by producing utterances of language that exhibit compositionality is the question that the works of \citep{kirby2002learning, %Kirby199812, 
brighton2001survival,Brighton2002,Smith2003} strived to answer.  To achieve this they appealed to a ``process of information transmission via observational learning" \citep{Brighton2002}, which took place in-between populations and generations of (previously-learner) speaker agents and (soon-to-become-speaker) learner agents. This is the Iterated Learning Model (ILM)~\citep{Kirby2014}. 

In this section, we will compare the ST-GS estimator to the ILM in order to highlight insights about the drivers of compositional language emergence using the ST-GS estimator.

\subsection{(Neural) Iterated Learning Model}
\label{subsec:NILM}

The ILM consists of a ``[multi-]agent-based model where each agent represents a language user"\cite{Brighton2002}, which forms utterances based on the hypothesis that has been formed previously (I-Language) to account for previously-observed utterances (E-Language). It puts in relation an environment, made up of $N$ objects/stimuli that maps to a meaning space $\mathcal{M}=\{(f_i)_{i\in[1:F]} \; / \; \forall f_i, 1\leq f_i\leq V \}$, (consisting of an $F$-dimensional space, i.e. features, with $V$ possible discrete values along each dimension) with a signal space, or language, $\mathcal{S}=\{ (\omega_i)_{i\in [1:l]} \; / \; \forall\omega_i\in\Sigma \;,\; \forall l\in[1:l_{max}] \}$ (a set of strings of symbols from a symbol space $\Sigma$ with length $l\leq l_{max}$). The relation or mapping is induced by making agents observe (attend to) signal-meaning pairs from the E-Language, during the \textit{acquisition phase}, and then, during the \textit{production phase}, making them utter new language utterances, whilst being prompted to communicate/speak about a set of other randomly-sampled objects/stimuli from the environment. 

\subsubsection{Language Stability}

In such a context where language is evolved by each learner agent at each iteration, it becomes important to consider the stability of the different languages that may arise, in order to understand under which conditions does the ILM converge and what are the properties to expect of the emerging, stable languages. Before being able to consider the stability of a given language, we need to define its expressivity $E$, especially ``the expected number of meanings an individual will be able to express after observing some subset of the E-Language"\citep{Smith2003}, which we will denote $O$.

\textbf{Holistic Language} - In the context of a holistic language where there is no syntactic structure to the language and it consists of idiosyncrasies, no \textit{generalisation} can be operated, only \textit{memorisation} upon observation and then recall can help an agent express a given meaning in that language. Therefore, the expressivity of a holistic language $E_h$ ``is simply the probability of observing any particular meaning [$m\in O$, $Pr(m\in O)$,] multiplied by the number of possible meanings" \citep{Smith2003}, as shown in Eqn. \ref{eqn1}.
\begin{equation}
\label{eqn1}
    E_h = Pr(m\in O) \cdot {{V}\choose{1}}^F = Pr(m\in O) \cdot V^F.
\end{equation}
It is worth noting that the meaning space $\mathcal{M}$ is structured as an $F$-dimensional space of features with $V$ possible values for each feature.

\textbf{Compositional Language} - In the context of a compositional language where the relationship between meanings and signals is structured, ``expressivity becomes a function of the number of feature values observed, rather than a function of the number of meanings observed" \citep{Brighton2002}. Given a meaning $m=(v_1,\dots,v_F)$, formally, we have:
\begin{equation}
    E_c = Pr( ``\forall v\in m,\exists O_v\in R, v\in O_v") \cdot N_{used}
\end{equation}
where $Pr( ``\forall v\in m,\exists O_v\in R, v\in O_v") = Pr( ``\exists O_v \in R, v\in O_v" )^F$ is the probability of being able to express $m$ (to be contrasted with the probability of observing $m\in O$, $Pr(m \in O)$), and thus, $N_{used}$ is ``the expected number of expressible meanings" \citep{Brighton2002} that are used to label the $N$ objects in the environment. The more eager readers can refer to \citep{Brighton2002} for more details.

\subsubsection{Drivers of Compositionality} 

Since we are concerned with the likelihood of the emergence of compositionality over holisticity, the authors define in Eqn. \ref{eqn3} the relative stability $S$ of compositional languages with respect to holistic ones:
\begin{equation}
\label{eqn3}
    S = \frac{S_c}{S_c+S_h},
\end{equation}
where $S_c\propto \frac{E_c}{N}$ and $S_h \propto \frac{E_h}{N}$ are the (absolute) stabilities of compositional languages and holistic ones, respectively. Thus, ``the probability of observing some arbitrary meaning $m$, i.e. $Pr(m \in O)$, is determined by the number of objects in the environment ($N$), the number of meanings in the meaning space ($M$, where $M=V^F$), and the number of random object observations during an agent lifetime ($R$)" \citep{Brighton2002}. Therefore, the relative stability of a compositional language compared to a holistic language will be strongly affected by: (i) the structure of the meaning space, via its dependence to $M$, and (ii) the object coverage expressed by the ratio $b=\frac{R}{N}$ (also the inverse of the measure of the severity of the \textit{transmission bottleneck}). The lower the coverage, i.e. $b$, the greater the stability advantage of compositional languages over holistic ones is, such that ``the poverty-of-the-stimulus `problem' is in fact required for linguistic structure to emerge'' \citep{Smith2003}. Another important result is visible in the observation that ``a large stability advantage for a compositional language (high $S$) only occurs when the meaning space exhibits a certain degree of structure (i.e. when there are many features and/or values), suggesting that structure in the conceptual space of language learners is a requirement for the evolution of compositionality" \citep{Smith2003}.

In other words, both the severity of the (cultural) \textit{transmission bottleneck} and the degree of structure in the meaning space have been identified as drivers of compositionality in emerging languages, in the context of the ILM. 
%In the remainder of the paper, we will draw parallels to those drivers in the context of the ST-GS approach proposed by~\citet{Havrylov2017} for referential games.

Recently, the Neural Iterated Learning (NIL) algorithm was proposed by ~\citet{Ren2020}. They transposed the ILM framework to a deep learning setting and showed a similar impact of the severity of the transmission bottleneck, in addition to a proposed probabilistic framework that formally evidenced it.

\subsection{Straight-Through Gumbel-Softmax Estimator}
\label{sec:st-gs}

In the current computer science paradigm, we commonly assume a discrete nature of the messages that are sent by the \textit{speaker} to the \textit{listener}. Therefore, the communication channel is non-differentiable and must rely on \textit{Reinforcement Learning} algorithms to solve the credit-assignment problem. The most common candidates in the literature are REINFORCE-like algorithms \citep{williams1992simple}. Fortunately, tricks exist that allow the environment (in this case, the communication channel) to be made differentiable.

As it takes place in the context of an \textit{$L\geq2$-signal/$0$-round} referential game, the work of \citet{Havrylov2017} brings evidence that deep learning agents can not only learn to coordinate via a communication channel (as seen in \citet{Lazaridou2016} with ``atomic symbols'' \citep{Havrylov2017} already), but first and foremost invent a seemingly compositional, hierarchical, and variable-length language, with a ``sequence of tokens'' \citep{Havrylov2017}, in order to coordinate. The model's greatest success is attributed to the introduction of the Straight-Through Gumbel-Softmax (ST-GS) estimator/relaxation/backpropagation approach, which makes the communication channel differentiable (and also exhibits similar behaviour between training and testing, which is on the contrary to previous works, e.g.~\citet{Foerster2016}).

The ST-GS estimator is built on top of the Gumbel-Softmax estimator~\citep{jang2017categorical,maddison2017concrete}, that replaced one-hot-encoded symbols/tokens/words $w\in V$, originally sampled from a categorical distribution, with a continuous relaxation $\tilde{w}$, sampled from a Gumbel-Softmax distribution, following the notation of ~\citet{Havrylov2017}:
\[
    \tilde{w_k} = \frac{\exp((\log p_k + g_k)/\tau)}{\sum_{i=1}^{K}{\exp((\log p_i + g_i)/\tau)}}
\]
where $p_1,\dots,p_K$ are the $K$ event probabilities of the original categorical distribution, $\tau$ is a temperature hyperparameter (see ~\citep{Havrylov2017} for more details), and $g_1,\dots,g_K$ are sampled from the Gumbel distribution, i.e. $g_k=-\log(-\log(u_k))$ with $u_k\sim \mathcal{U}(0,1)$. 

Instead of stopping there, the ST-GS estimator performs a greedy discretization (i.e. using the $argmax$ operator) of $\tilde{w_k}$ during the forward pass, whilst relying on the continuous relaxation during the backward pass\footnote{for further implementation details see: \url{https://pytorch.org/docs/master/nn.functional.html?highlight=gumbel#torch.nn.functional.gumbel_softmax}}, thus yielding a biased gradient estimator~\citep{jang2017categorical,bengio2013estimating}. 

\citet{Havrylov2017} simplified the whole process by considering learning the temperature $\tau(h_i^s)$ for each symbol/token/word $w_i$ in each sentence $s$ with conditioning on the hidden state $h_i^s$ of the sentence decoder RNN. In this work, instead of using a multi-layer perceptron, we only rely on a one-layer network $\alpha$: 
\[
    \tau(h_i^s) = \frac{1}{\tau_0+\log(1+\exp(\alpha(h_i^s)))}
\]

One very important and somewhat surprising result that they found is that using the ST-GS estimator, the greater the sequence length, the faster the learning of the communication protocol. On the other hand, there is no such correlation when training  REINFORCE-like algorithms. 
It is unclear whether this phenomena is due to the ST-GS estimator alone or the synergy between it and the pre-trained convolutional neural network (CNN), which each agent relied on in the original work. In order to efficiently assess the impact of the ST-GS estimator, in this paper we chose to have our agents learn everything from scratch.
%Variability of the language is seen in the fact that the perplexity of the model grows linearly with the sequence length when using ST-GS estimator, whereas it remained constant when using REINFORCE-like algorithms. High perplexity ``implies redundancy in the encodings: there exist multiple paraphrases that encode the same semantic content''\cite{Havrylov2017}. \\

\subsection{Instantiating a Transmission Bottleneck}
\label{subsec:transmission-bottleneck}

In the following, we highlight the similarities between the ILM, in the form of the NIL algorithm, and the ST-GS algorithm. Both the NIL and the ST-GS algorithms are iterative processes. Thus, we focus on one learning step for each.

Firstly, in the ILM/NIL, the \textit{learning phase} consists of the new learning agent $A_i$ updating its model using the data set $\mathcal{D}_{i-1} = (u^{i-1}_j, s_j)_{j\in [1;N_{learning}]}$ of pairs of stimuli $s$ and associated utterance $u$ produced by agent $A^{\prime}_{i-1}$ at the previous iteration.  $N_{learning}$ is the size of the learning data set, at each learning step, and it is randomly sampled from the whole meaning space $\mathcal{M}$ of size $N$. In the ILM/NIL, a cultural transmission bottleneck is instantiated by choosing $N_{learning}\leq N$, and the severity of the bottleneck is measured by $R=\frac{N_{learning}}{N}$. Next, following the naming of ~\citet{Ren2020}, in the \textit{transmitting phase}, the now updated agent $A^{\prime}_{i}$, fluent in the E-language $\mathcal{L}_{i-1}$ (as described by $\mathcal{D}_{i-1}$), is prompted to a production step where it generates the data set $\mathcal{D}_{i} = ( A^{\prime}_{i}(\hat{s}_j), \hat{s}_j)_{j\in [1;N_{learning}]}$ with stimuli being randomly sampled, $\hat{s}\sim\mathcal{M}$. Due to the transmission bottleneck during the production step, the learning agent has to generalise its knowledge of the E-language $\mathcal{L}_{i-1}$ to potentially novel stimuli, and it is thus bound to make this language evolve into a new E-language $\mathcal{L}_{i}$, unless there is no transmission bottleneck and it has perfectly learned the language during the learning step. In the NIL algorithm, an \textit{interacting phase} is intertwined between the \textit{learning phase} and the \textit{transmitting phase}, which consists of a referential game $\mathcal{R}$ that aims to promote disambiguation of the language. 

It is important to note that the ILM/NIL algorithm relies on the previous E-language $\mathcal{L}_{i-1}$ at each step $i$, whilst the ST-GS algorithm relies on something more akin to the previous I-language, as we will now detail.

In the context of the ST-GS algorithm, learning happens by batch. At each learning step, a batch $\mathcal{D}^{S}_{i}$ of stimuli, randomly sampled from the whole meaning space $\mathcal{M}$ (as defined in Eqn.~\ref{eq:learning-data-speaker}), is forwarded through the learning \textit{speaker} agent $S_{i}$ to produce a batch $\mathcal{D}^L_{i}$ of utterances (as defined in Eqn.~\ref{eq:learning-data-listener}). The latter is then forwarded through the learning \textit{listener} agent $L_{i}$, along with a batch of sets of stimuli $\Delta_i$. Each element of the batch is a shuffled list/set containing $K$ distractor stimuli that are randomly sampled from $\mathcal{M}$, and the corresponding target stimuli from $\mathcal{D}^S_i$ (as defined in Eqn.~\ref{eq:learning-data-delta}).
%, i.e. $\hat{s}^i_j(K+1) = s^i_j \in \mathcal{D}^S_i$. 
The resulting output is a batch of sets of scores $\Sigma_i$ (as defined in Eqn.~\ref{eq:scores}). Using $j$ as the index for the element of the batch, each score $s(u^i_j, \hat(s)^i_j(d)) \in \sigma^j_i$ intuitively represents the extent with which each utterance $u^i_j$ describes the stimuli $ \hat(s)^i_j(d) \in \delta^j_i$. 

\begin{equation}
    \label{eq:learning-data-speaker}
    \mathcal{D}^{S}_{i} = (s^i_j)_{j\in [1;N^S_{learning}]} \sim \mathcal{M}
\end{equation}
\begin{equation}
    \label{eq:learning-data-listener}
    \mathcal{D}^L_{i} = (u^i_j = S_{i}(s^i_j))_{j\in [1;N^S_{learning}]}
\end{equation}
\begin{equation}
    \label{eq:learning-data-delta}
    \Delta_i = (\delta^j_i)_{j\in[1;N^S_{learning}]} , s.t. \quad \forall j\in [1;N^S_{learning}], \delta^j_i = (\hat{s}^i_j(d))_{d\in [1;K+1]}
\end{equation}
\begin{equation}
    \label{eq:scores}
    \Sigma_i = (\sigma^j_i)_{j\in[1;N^S_{learning}]}
\end{equation}

Following the computation of the loss function, similarly to ~\citet{Havrylov2017}, the gradients are backpropagated and the agents are updated.
% \[
%     \mathcal{L}( \mathcal{D}^L_{i}, \Sigma_i ) = \sum_{j\in [1;N^S_{learning}]} \sum
% \]
It is important to notice that at the time of the backward pass, the current agents are not yet updated, i.e. $L_{i}=L_{i-1}$ and $S_{i}=S_{i-1}$. Therefore, each of them receives a gradient with respect to the other's I-language (as represented by each agent's weights) at the previous time step, i.e. with respect to $S(\mathcal{L}_{i-1})$ and $L(\mathcal{L}_{i-1})$ respectively. Following the backward pass, the algorithm yields the updated agents $S^{\prime}_{i}$ and $L^{\prime}_{i}$.

In comparison to the NIL algorithm, we argue that both updated agents have received feedback in a richer fashion due to: (i) learning in a supervised fashion (that not only promotes but also penalises the E-language with respect to the goal of disambiguation) and (ii) the fact that the ST-GS relaxation enables feedback with respect to both the referential game $\mathcal{R}$ and the learning \textit{listener} agent's I-language $L(\mathcal{L}_{i-1})$ (which we assume to be more pertinent than the E-language $\mathcal{L}_{i-1}$).