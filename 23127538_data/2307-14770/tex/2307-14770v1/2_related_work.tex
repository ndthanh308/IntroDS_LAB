

\section{Related Work}
\label{sec: Related Work}

\subsection{Portrait Image Dataset}
    To enable downstream face applications, such as (conditional) face generation, segmentation, face anti-spoofing, face recognition, and facial manipulation, researchers have collected and processed numerous face image datasets.
    %
    The CelebFaces Attributes Dataset (\textit{CelebA}) \cite{liu2015faceattributes} is a large-scale face attributes dataset with over 200,000 celebrity images and 40 rich attribute annotations. Its variants also provide segmentation masks \cite{CelebAMask-HQ}, spoof \cite{CelebA-Spoof}, and fine-grained labels \cite{jiang2021talkedit} to benefit the community. 
    %
    Since its creation by the author of StyleGAN \cite{DBLP:conf/cvpr/KarrasLAHLA20}, \textit{FFHQ} has quickly become the most popular dataset for 2D/3D face generation tasks. 
    %
    However, while \textit{CelebA} and \textit{FFHQ} datasets are widely used for training sophisticated 3D-aware generators, the images are predominantly limited to small to medium poses. As a result, these generators often produce distorted or incomplete head geometry due to the insufficient range of available poses in the training data.
    %
    Although researchers are attempting to incorporate more large-pose data (\textit{LPFF} \cite{DBLP:journals/corr/abs-2303-14407}) and back-head data (\textit{FFHQ-F} \cite{An_2023_CVPR}) into \textit{FFHQ}, these newly added data still lack complete data for the neck and shoulder regions, resulting in incomplete head geometry.
    
    %
    \textit{300W-LP} \cite{DBLP:conf/cvpr/ZhuLLSL16} is a dataset including 61,225 images across a wide range of poses, but all the images are artificially synthesized by face profiling.
    %
    \textit{AFLW} \cite{DBLP:conf/iccvw/KostingerWRB11} contains 21,080 face images with large-pose variations, and \textit{LS3D-W} \cite{DBLP:conf/iccv/BulatT17} contains approximately 230,000 images from a combination of different datasets \cite{DBLP:conf/cvpr/SagonasTZP13,DBLP:conf/iccvw/ShenZCKTP15,DBLP:conf/cvpr/ZafeiriouTCDS17,DBLP:conf/cvpr/ZhuLLSL16}. 
    But most images in the above dataset are at low resolution and do not include portraits from the back of the head, limiting their suitability for training high-quality full-head models.
    %
    
    There are portrait image datasets available that contain multi-view face images.
    Some annotated 3D face datasets \cite{DBLP:conf/cvpr/Yang0WHSYC20,wuu2022multiface,DBLP:journals/corr/abs-1904-00168} offer high-quality multi-view face images and accurate camera parameters suitable for 3D face reconstruction. However, the limited variety in these datasets poses challenges for researchers seeking more diverse data.
    %
    Synthetic face datasets \cite{DBLP:journals/corr/abs-2212-06135,DHFdataset,DBLP:conf/iccv/WoodBHD0S21} offer a convenient solution for computer vision tasks, as users can easily control data generation and obtain ground truth labels by using graphics. Despite this advantage, synthetic face datasets still have a big domain gap with real-world data, making it challenging to apply these datasets in practical applications.
    
    In summary, no dataset adequately provides high-quality, diverse, and realistic portrait images with a full range of camera poses to train a full-head 3D-aware generator. 
    

\subsection{3D-aware Generators}
    Since Goodfellow's seminal proposal of generative adversarial networks (GANs) \cite{DBLP:conf/nips/GoodfellowPMXWOCB14} in 2014, numerous GANs models \cite{DBLP:journals/corr/RadfordMC15,DBLP:conf/nips/GulrajaniAADC17,DBLP:conf/iclr/BrockDS19,DBLP:conf/iclr/KarrasALL18} have been developed to achieve remarkable performance in realistic image synthesis.
    %
    The scope of 2D generators has been extended to encompass 3D multi-view rendering these years.   
    Early techniques combine voxel rendering \cite{DBLP:conf/nips/Nguyen-PhuocRMY20,DBLP:conf/iccv/HenzlerM019,DBLP:conf/nips/ZhuZZ00TF18} or NeRF rendering \cite{DBLP:conf/iclr/GuL0T22,DBLP:conf/cvpr/ChanMK0W21} with generators to facilitate view-consistent image synthesis.
    
    The 3D representations inside 3D-aware GANs could be parameterized by coordinate-based networks \cite{DBLP:conf/cvpr/ChanMK0W21,DBLP:conf/iclr/GuL0T22}, feature maps \cite{DBLP:conf/cvpr/ChanLCNPMGGTKKW22}, signed distance field \cite{DBLP:conf/nips/0004SWCYLLGF22}, or voxel grids \cite{DBLP:conf/nips/SchwarzSNL022,DBLP:conf/nips/ZhuZZ00TF18}.
    %
    In order to reduce the cost of calculation, several studies propose the use of a super-resolution network to enhance image quality \cite{DBLP:conf/cvpr/ChanLCNPMGGTKKW22,DBLP:conf/siggraph/TanFMOTPTTZ22,DBLP:journals/corr/abs-2112-11427,DBLP:conf/cvpr/XueLSL22}. 
    %
    Moreover, researchers suggest an efficient optimization strategy \cite{DBLP:journals/corr/abs-2206-10535} to directly generate high-resolution results without the use of a super-resolution module.
    %
    In order to eliminate the dependency on 3D pose priors, researchers also propose a pose-free training strategy \cite{shi2023pof3d} to learn the pose distribution of the dataset by the network itself.
    
    %
    To apply 3D-aware generators to real image and video editing, novel inversion methods \cite{DBLP:journals/corr/abs-2203-13441,DBLP:conf/wacv/KoCCRK23,xie2022high,DBLP:journals/corr/abs-2211-16927,DBLP:journals/corr/abs-2302-04871} have been proposed to obtain latent codes of given input images. 
    %
    Thanks to the capability of 3D-aware GANs to generate view-consistent results and realistic facial geometry, downstream applications such as semantic editing \cite{DBLP:journals/corr/abs-2205-15517,nerffaceediting,DBLP:journals/corr/abs-2302-04871} and portrait stylization \cite{DBLP:conf/siggrapha/JinRKBC22,DBLP:journals/corr/abs-2301-02700} have achieved remarkable performance.
    
    %
    However, within the face domain, these methods all require data in a canonical space, such as \textit{FFHQ}, \textit{FFHQ-F}, and \textit{CelebA}. These datasets mostly comprise frontal or near-frontal views and only cover the face region, as previously mentioned. This implies that only data for the face area can be generated, and the geometry is incomplete due to the absence of the back of the head, neck, and shoulders.
    %
    Although some methods for tackling the aforementioned problems are available, such as Rodin \cite{DBLP:journals/corr/abs-2212-06135} and HeadNeRF \cite{DBLP:journals/corr/abs-2112-05637}, which can learn 3D avatar head representations and even generate neck and shoulder data, they rely on multi-view portrait datasets in a canonical space, making them highly dependent on data.

    Ultimately, no appropriate method is available for learning portrait geometry from in-the-wild single-view portrait images.



\subsection{Deformable Neural Radiance Fields}
    The continuous, volumetric representation for rendering objects and scenes proposed by Neural Radiance Fields (NeRF) \cite{DBLP:conf/eccv/MildenhallSTBRN20} has benefited the entire graphics and vision community. 
    However, NeRF is limited to static scene rendering.
    %
    To address this limitation, a line of approaches has been explored to achieve non-rigid scenes by deforming sample points in the observation space to the canonical space before querying a template NeRF. 
    %
    Neural networks, such as MLP, are used to represent the continuous deformation of each sample point by outputting the deformation field value.
    %
    %Besides using points coordinates as input, the NN-based deformation field could also utilize time steps as input 
    In addition to using points coordinates as input, the NN-based deformation field could use time steps \cite{DBLP:conf/cvpr/PumarolaCPM21,DBLP:journals/corr/abs-2303-14435}, latent codes \cite{DBLP:conf/iccv/ParkSBBGSM21,DBLP:conf/iccv/TretschkTGZLT21}, or view and facial expressions \cite{DBLP:conf/cvpr/GafniTZN21}.
    %
    HumanNeRF \cite{DBLP:conf/cvpr/WengCSBK22} further divides the deformation field into skeletal rigid and non-rigid motion to enhance human animation rendering.
    %
    Some works use blend skinning \cite{DBLP:conf/cvpr/YangVNRVJ22,DBLP:conf/cvpr/ZhengABCBH22} or deformable meshes \cite{DBLP:conf/cvpr/AtharXSSS22,DBLP:journals/corr/abs-2304-05097} as guidance instead of encoding the entire deformation field into a neural network.
    %
    To accommodate the representation of discontinuous topological changes, HyperNeRF \cite{DBLP:journals/tog/ParkSHBBGMS21} raises NeRFs into a hyper-space to represent the radiance field corresponding to each input frame as a slice through this space.
    %
    Generative neural radiance fields also make use of deformation fields based on deformable meshes like 3DMM \cite{DBLP:conf/siggraph/BlanzV99, DBLP:conf/avss/PaysanKARV09}, SMPL \cite{DBLP:journals/tog/LoperM0PB15} and FLAME \cite{DBLP:journals/tog/LiBBL017} to achieve animated results \cite{DBLP:journals/corr/abs-2211-11208,DBLP:conf/nips/BergmanKWCLW22,DBLP:conf/nips/SunWHZW022}.
    
    
    For our purposes, we opt for using mesh-guided deformation, which is easily obtainable and has adjustable parameters.












