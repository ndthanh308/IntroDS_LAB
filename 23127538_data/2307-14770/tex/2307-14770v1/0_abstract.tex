\begin{abstract}

3D-aware face generators have significantly improved the performance of various downstream applications, such as talking heads and multi-view consistent semantic editing.
% However, since they are trained on 2D real-life \onethousand{face} image sets \onethousand{that only comprise near-frontal face data}, their applicability is limited due to their inability to construct \textit{full-head} 3D portraits. 
% %
% The main challenge stems from the scarcity of realistic portrait data captured from various camera angles, as well as diverse body poses in in-the-wild images\hbc{Not clear: why the scarcity of such data introduces a high-dimensional problem?} which introduces a high-dimensional problem for 3D-aware generators. 
%
{
3D-aware face generators are commonly trained on 2D real-life face image datasets. Nevertheless, existing facial recognition methods often struggle to extract face data captured from various camera angles. Furthermore, in-the-wild images with diverse body poses introduce a high-dimensional challenge for 3D-aware generators, making it difficult to utilize data that contains complete neck and shoulder regions. Consequently, these face image datasets often contain only near-frontal face data, which poses challenges for 3D-aware face generators to construct \textit{full-head} 3D portraits. 
}
%
To this end, we first create the dataset %\textit{$\it{360}^{\circ}$PHQ}
{$\it{360}^{\circ}$}-\textit{Portrait}-\textit{HQ} (\textit{$\it{360}^{\circ}$PHQ}), which consists of high-quality single-view real portraits annotated with a variety of camera parameters {(the yaw angles span the entire $360^{\circ}$ range)} and body poses.
%
We then propose \textit{3DPortraitGAN}
%\hbc{use either textit or textbf to emphasize the text but not both?}
, the first 3D-aware full-head portrait generator that learns a canonical 3D avatar distribution from the %single-view 2D portrait dataset 
body-pose-various \textit{$\it{360}^{\circ}$PHQ} dataset with body pose self-learning. Our model can generate view-consistent portrait images from all camera angles (${360}^{\circ}$) 
with a full-head 3D representation.
%
We incorporate a mesh-guided deformation field into volumetric rendering to produce deformed results to generate portrait images that conform to the body pose distribution of the dataset using our canonical generator.
We integrate two pose predictors into our framework to predict more accurate body poses to address the issue of inaccurately estimated body poses in our dataset. 
%
Our experiments show that the proposed framework can generate view-consistent, realistic portrait images with complete geometry from 
%a wide range of camera angles 
{all camera angles}
and accurately predict portrait body pose.
  
\end{abstract}
 