\section{Discussion}
\label{sec: Discussion}

% Our method has limitations.
% % 
% First, we employed a deformation field that is solely governed by a non-shaped SMPL model, with no regard for the shape of the resulting portrait geometry. While this deformation method did not interfere with our training process, it resulted in artifacts during inference, such as long hair being truncated due to deformation. Also the computation of the deformation field is time-costly and memory intensive, making our training at half the speed of EG3D. 
% %
% Secondly, training the pose predictor $\Gamma_G$ in the generator is prone to collapsing. To mitigate this issue, we freeze $\Gamma_G$ after a certain training duration.
% %
% Thirdly, we introduced a depth regularization loss $L_{rear}$ to regulate the depth of the occiput. However, the SMPL model is incapable of representing the geometry of every portrait in the real distribution. As such, the weight of $L_{rear}$ cannot be set too high. Although our approach significantly mitigates face artifacts on the occiput, it is not completely eliminated. This issue could be addressed by using a more appropriate constraint by rendering depth images using models with hair and clothes modeled realistically.
% %
% Finally, we directly use the camera poses in our \textit{$\it{360}^{\circ}$PHQ} dataset as training labels, where the  inaccurate estimation may lead to geometric artifacts. This limitation can be overcome by applying a more accurate body pose estimation method in the future.


Despite its noteworthy performance, our method has some limitations. 
Firstly, we employ a deformation field solely governed by the SMPL model, which doesn't account for the shape of the resulting geometry of a portrait. Although this deformation method did not interfere with our training process, it leads to some artifacts during inference, such as truncated long hair (highlighted by green box Fig. \ref{fig: limitation}). Furthermore, the computation of the deformation field is time and memory intensive, leading to our training being much slower than EG3D and costing almost twice as much time.
%
Secondly, the pose predictor $\Gamma_G$ within the generator is prone to collapsing and heavily influences the entire framework during the training phase.  To prevent this from happening, we freeze $\Gamma_G$ after it's been trained for a certain duration.
%
Thirdly, we introduce an additional depth regularization loss $L_{rear}$ to regulate the occiput's depth. However, the SMPL model is not capable of accurately representing the geometry of every portrait in the real distribution. Even though our approach significantly mitigates face artifacts on the occiput, it is still not entirely eradicated (highlighted by blue boxes Fig. \ref{fig: limitation}). This problem can be addressed by using a more appropriate constraint by rendering depth images using models with hair and clothes modeled realistically.
%
Additionally, while the pose self-learning strategy in our framework can assist in predicting more precise body poses and alleviate distortions in the results, as shown in Tab. \ref{tab: ablation Pose prediction}, our model still cannot achieve entirely canonical representations. This is because of the inaccurate predictions in our pose learning method, even if the outcome is better than the coarse body poses in our dataset.
%
Furthermore, our model still lacks the expressive power to accurately represent portrait images in real-life, as can be seen in the real image inversion results presented in Fig. \ref{fig: inversion}. We attribute this to the limited resolution ($256^2$) of the tri-planes. This issue could be addressed by improving the resolution of the tri-planes and seeking more efficient training strategies to prevent the model from consuming excessive computation to train high-resolution tri-planes.
%
Finally, to train our model, we directly used the camera parameters in our \textit{$\it{360}^{\circ}$PHQ} dataset as training labels. However, the inaccurate estimation of these camera parameters might lead to geometric artifacts. This issue can be overcome by using a more accurate body pose estimation method in the future.

% Figure environment removed