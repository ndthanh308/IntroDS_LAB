% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{juluri2015measurement}
P.~Juluri, V.~Tamarapalli, and D.~Medhi, ``Measurement of quality of experience
  of video-on-demand services: {A} survey,'' \emph{IEEE Communications Surveys
  \& Tutorials}, vol.~18, no.~1, pp. 401--418, 2015.

\bibitem{seshadrinathan2010study}
K.~Seshadrinathan, R.~Soundararajan, A.~C. Bovik, and L.~K. Cormack, ``Study of
  subjective and objective quality assessment of video,'' \emph{IEEE
  Transactions on Image Processing}, vol.~19, no.~6, pp. 1427--1441, 2010.

\bibitem{nuutinen2016cvd2014}
M.~Nuutinen, T.~Virtanen, M.~Vaahteranoksa, T.~Vuori, P.~Oittinen, and
  J.~H{\"a}kkinen, ``{CVD2014}—{A} database for evaluating no-reference video
  quality assessment algorithms,'' \emph{IEEE Transactions on Image
  Processing}, vol.~25, no.~7, pp. 3073--3086, 2016.

\bibitem{ghadiyaram2017capture}
D.~Ghadiyaram, J.~Pan, A.~C. Bovik, A.~K. Moorthy, P.~Panda, and K.-C. Yang,
  ``In-capture mobile video distortions: {A} study of subjective behavior and
  objective algorithms,'' \emph{IEEE Transactions on Circuits and Systems for
  Video Technology}, vol.~28, no.~9, pp. 2061--2077, 2017.

\bibitem{hosu2017konstanz}
V.~Hosu, F.~Hahn, M.~Jenadeleh, H.~Lin, H.~Men, T.~Szir{\'a}nyi, S.~Li, and
  D.~Saupe, ``The {K}onstanz natural video database ({KoNViD-1k}),'' in
  \emph{IEEE International Conference on Quality of Multimedia Experience},
  2017, pp. 1--6.

\bibitem{sinno2018large}
Z.~Sinno and A.~C. Bovik, ``Large-scale study of perceptual video quality,''
  \emph{IEEE Transactions on Image Processing}, vol.~28, no.~2, pp. 612--627,
  2018.

\bibitem{wang2019youtube}
Y.~Wang, S.~Inguva, and B.~Adsumilli, ``Youtube {UGC} dataset for video
  compression research,'' in \emph{IEEE International Workshop on Multimedia
  Signal Processing}, 2019, pp. 1--5.

\bibitem{chen2019qoe}
P.~Chen, L.~Li, Y.~Huang, F.~Tan, and W.~Chen, ``{QoE} evaluation for live
  broadcasting video,'' in \emph{IEEE International Conference on Image
  Processing}, 2019, pp. 454--458.

\bibitem{ying2021patch}
Z.~Ying, M.~Mandal, D.~Ghadiyaram, and A.~C. Bovik, ``{Patch-VQ}: '{P}atching
  {U}p' the video quality problem,'' in \emph{IEEE Conference on Computer
  Vision and Pattern Recognition}, 2021, pp. 14\,019--14\,029.

\bibitem{yu2022subjective}
X.~Yu, Z.~Tu, Z.~Ying, A.~C. Bovik, N.~Birkbeck, Y.~Wang, and B.~Adsumilli,
  ``Subjective quality assessment of user-generated content gaming videos,'' in
  \emph{IEEE Winter Conference on Applications of Computer Vision}, 2022, pp.
  74--83.

\bibitem{saad2014blind}
M.~A. Saad, A.~C. Bovik, and C.~Charrier, ``Blind prediction of natural video
  quality,'' \emph{IEEE Transactions on Image Processing}, vol.~23, no.~3, pp.
  1352--1365, 2014.

\bibitem{mittal2015completely}
A.~Mittal, M.~A. Saad, and A.~C. Bovik, ``A completely blind video integrity
  oracle,'' \emph{IEEE Transactions on Image Processing}, vol.~25, no.~1, pp.
  289--300, 2015.

\bibitem{liu2018end}
W.~Liu, Z.~Duanmu, and Z.~Wang, ``End-to-end blind quality assessment of
  compressed videos using deep neural networks,'' in \emph{ACM International
  Conference on Multimedia}, 2018, pp. 546--554.

\bibitem{korhonen2019two}
J.~Korhonen, ``Two-level approach for no-reference consumer video quality
  assessment,'' \emph{IEEE Transactions on Image Processing}, vol.~28, no.~12,
  pp. 5923--5938, 2019.

\bibitem{li2019quality}
D.~Li, T.~Jiang, and M.~Jiang, ``Quality assessment of in-the-wild videos,'' in
  \emph{ACM International Conference on Multimedia}, 2019, pp. 2351--2359.

\bibitem{korhonen2020blind}
J.~Korhonen, Y.~Su, and J.~You, ``Blind natural video quality prediction via
  statistical temporal features and deep spatial features,'' in \emph{ACM
  International Conference on Multimedia}, 2020, pp. 3311--3319.

\bibitem{tu2021ugc}
Z.~Tu, Y.~Wang, N.~Birkbeck, B.~Adsumilli, and A.~C. Bovik, ``{UGC-VQA}:
  {B}enchmarking blind video quality assessment for user generated content,''
  \emph{IEEE Transactions on Image Processing}, vol.~30, pp. 4449--4464, 2021.

\bibitem{yu2021predicting}
X.~Yu, N.~Birkbeck, Y.~Wang, C.~G. Bampis, B.~Adsumilli, and A.~C. Bovik,
  ``Predicting the quality of compressed videos with pre-existing
  distortions,'' \emph{IEEE Transactions on Image Processing}, vol.~30, pp.
  7511--7526, 2021.

\bibitem{yi2021attention}
F.~Yi, M.~Chen, W.~Sun, X.~Min, Y.~Tian, and G.~Zhai, ``Attention based network
  for no-reference {UGC} video quality assessment,'' in \emph{IEEE
  International Conference on Image Processing}, 2021, pp. 1414--1418.

\bibitem{wang2021rich}
Y.~Wang, J.~Ke, H.~Talebi, J.~G. Yim, N.~Birkbeck, B.~Adsumilli, P.~Milanfar,
  and F.~Yang, ``Rich features for perceptual quality assessment of {UGC}
  videos,'' in \emph{IEEE Conference on Computer Vision and Pattern
  Recognition}, 2021, pp. 13\,435--13\,444.

\bibitem{li2022blindly}
B.~Li, W.~Zhang, M.~Tian, G.~Zhai, and X.~Wang, ``Blindly assess quality of
  in-the-wild videos via quality-aware pre-training and motion perception,''
  \emph{IEEE Transactions on Circuits and Systems for Video Technology},
  vol.~32, no.~9, pp. 5944--5958, 2022.

\bibitem{sun2022deep}
W.~Sun, X.~Min, W.~Lu, and G.~Zhai, ``A deep learning based no-reference
  quality assessment model for ugc videos,'' in \emph{ACM International
  Conference on Multimedia}, 2022, pp. 856--865.

\bibitem{wu2022fast}
H.~Wu, C.~Chen, J.~Hou, L.~Liao, A.~Wang, W.~Sun, Q.~Yan, and W.~Lin,
  ``{FAST-VQA}: {E}fficient end-to-end video quality assessment with fragment
  sampling,'' in \emph{European Conference on Computer Vision}, 2022, pp.
  538--554.

\bibitem{wu2022disentangling}
H.~Wu, E.~Zhang, L.~Liao, C.~Chen, J.~Hou, A.~Wang, W.~Sun, Q.~Yan, and W.~Lin,
  ``Exploring video quality assessment on user generated contents from
  aesthetic and technical perspectives,'' in \emph{IEEE International
  Conference on Computer Vision}, 2023, pp. 1--8.

\bibitem{li2019avc}
Z.~Li, Z.~Duanmu, W.~Liu, and Z.~Wang, ``{AVC}, {HEVC}, {VP9}, {AVS2} or
  {AV1}?—{A} comparative study of state-of-the-art video encoders on {4K}
  videos,'' in \emph{International Conference on Image Analysis and
  Recognition}, 2019, pp. 162--173.

\bibitem{mackin2015study}
A.~Mackin, F.~Zhang, and D.~R. Bull, ``A study of subjective video quality at
  various frame rates,'' in \emph{IEEE International Conference on Image
  Processing}, 2015, pp. 3407--3411.

\bibitem{lee2021subjective}
D.~Y. Lee, S.~Paul, C.~G. Bampis, H.~Ko, J.~Kim, S.~Y. Jeong, B.~Homan, and
  A.~C. Bovik, ``A subjective and objective study of space-time subsampled
  video quality,'' \emph{IEEE Transactions on Image Processing}, vol.~31, pp.
  934--948, 2021.

\bibitem{vonikakis2016shaping}
V.~Vonikakis, R.~Subramanian, and S.~Winkler, ``Shaping datasets: {O}ptimal
  data selection for specific target distributions across dimensions,'' in
  \emph{IEEE International Conference on Image Processing}, 2016, pp.
  3753--3757.

\bibitem{recommendation910subjective}
\BIBentryALTinterwordspacing
{ITU-T P.910}, ``Subjective video quality assessment methods for multimedia
  applications,'' 2008. [Online]. Available:
  \url{https://www.itu.int/rec/dologin_pub.asp?lang=e&id=T-REC-P.910-200804-S!!PDF-E&type=items}
\BIBentrySTDinterwordspacing

\bibitem{union2016methods}
\BIBentryALTinterwordspacing
{ITU-T P.913}, ``Methods for the subjective assessment of video quality audio
  quality and audiovisual quality of internet video and distribution quality
  television in any environment,'' 2016. [Online]. Available:
  \url{https://www.itu.int/rec/dologin_pub.asp?lang=e&id=T-REC-P.913-201603-S!!PDF-E&type=items}
\BIBentrySTDinterwordspacing

\bibitem{series2012methodology}
\BIBentryALTinterwordspacing
{ITU-R BT.500-13}, ``Methodology for the subjective assessment of the quality
  of television pictures,'' 2012. [Online]. Available:
  \url{https://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.500-13-201201-S!!PDF-E.pdf}
\BIBentrySTDinterwordspacing

\bibitem{wang2004image}
Z.~Wang, A.~C. Bovik, H.~R. Sheikh, and E.~P. Simoncelli, ``Image quality
  assessment: {F}rom error visibility to structural similarity,'' \emph{IEEE
  Transactions on Image Processing}, vol.~13, no.~4, pp. 600--612, 2004.

\bibitem{moorthy2010efficient}
A.~K. Moorthy and A.~C. Bovik, ``Efficient video quality assessment along
  temporal trajectories,'' \emph{IEEE Transactions on Circuits and Systems for
  Video Technology}, vol.~20, no.~11, pp. 1653--1658, 2010.

\bibitem{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang, ``The unreasonable
  effectiveness of deep features as a perceptual metric,'' in \emph{IEEE
  Conference on Computer Vision and Pattern Recognition}, 2018, pp. 586--595.

\bibitem{ding2020image}
K.~Ding, K.~Ma, S.~Wang, and E.~P. Simoncelli, ``Image quality assessment:
  {U}nifying structure and texture similarity,'' \emph{IEEE Transactions on
  Pattern Analysis and Machine Intelligence}, vol.~44, no.~5, pp. 2567--2581,
  2020.

\bibitem{li2018vmaf}
Z.~Li, C.~Bampis, J.~Novak, A.~Aaron, K.~Swanson, A.~Moorthy, and J.~Cock,
  ``{VMAF}: {T}he journey continues,'' \emph{Netflix Technology Blog}, vol.~25,
  no.~1, 2018.

\bibitem{cao2022image}
P.~Cao, D.~Li, and K.~Ma, ``Image quality assessment: {I}ntegrating
  model-centric and data-centric approaches,'' \emph{arXiv preprint
  arXiv:2207.14769}, 2022.

\bibitem{thomee2016yfcc100m}
B.~Thomee, D.~A. Shamma, G.~Friedland, B.~Elizalde, K.~Ni, D.~Poland, D.~Borth,
  and L.-J. Li, ``{YFCC100M}: {T}he new data in multimedia research,''
  \emph{Communications of the ACM}, vol.~59, no.~2, pp. 64--73, 2016.

\bibitem{mittal2012making}
A.~Mittal, R.~Soundararajan, and A.~C. Bovik, ``Making a 'completely blind'
  image quality analyzer,'' \emph{IEEE Signal Processing Letters}, vol.~20,
  no.~3, pp. 209--212, 2012.

\bibitem{ying2020patches}
Z.~Ying, H.~Niu, P.~Gupta, D.~Mahajan, D.~Ghadiyaram, and A.~C. Bovik, ``From
  patches to pictures ({PaQ-2-PiQ}): {M}apping the perceptual space of picture
  quality,'' in \emph{IEEE Conference on Computer Vision and Pattern
  Recognition}, 2020, pp. 3575--3585.

\bibitem{zhang2021uncertainty}
W.~Zhang, K.~Ma, G.~Zhai, and X.~Yang, ``Uncertainty-aware blind image quality
  assessment in the laboratory and wild,'' \emph{IEEE Transactions on Image
  Processing}, vol.~30, pp. 3474--3486, 2021.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{IEEE Conference on Computer Vision and Pattern
  Recognition}, 2016, pp. 770--778.

\bibitem{tan2019efficientnet}
M.~Tan and Q.~Le, ``{EfficientNet}: {R}ethinking model scaling for
  convolutional neural networks,'' in \emph{International Conference on Machine
  Learning}, 2019, pp. 6105--6114.

\bibitem{stroud2020d3d}
J.~Stroud, D.~Ross, C.~Sun, J.~Deng, and R.~Sukthankar, ``{D3D}: {D}istilled
  {3D} networks for video action recognition,'' in \emph{IEEE Winter Conference
  on Applications of Computer Vision}, 2020, pp. 625--634.

\bibitem{liu2022convnet}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie, ``A
  {ConvNet} for the 2020s,'' in \emph{IEEE Conference on Computer Vision and
  Pattern Recognition}, 2022, pp. 11\,976--11\,986.

\bibitem{mittal2012no}
A.~Mittal, A.~K. Moorthy, and A.~C. Bovik, ``No-reference image quality
  assessment in the spatial domain,'' \emph{IEEE Transactions on Image
  Processing}, vol.~21, no.~12, pp. 4695--4708, 2012.

\bibitem{tu2020comparative}
Z.~Tu, C.-J. Chen, L.-H. Chen, N.~Birkbeck, B.~Adsumilli, and A.~C. Bovik, ``A
  comparative evaluation of temporal pooling methods for blind video quality
  assessment,'' in \emph{IEEE International Conference on Image Processing},
  2020, pp. 141--145.

\bibitem{tu2021rapique}
Z.~Tu, X.~Yu, Y.~Wang, N.~Birkbeck, B.~Adsumilli, and A.~C. Bovik, ``{RAPIQUE}:
  {R}apid and accurate video quality prediction of user generated content,''
  \emph{IEEE Open Journal of Signal Processing}, vol.~2, pp. 425--440, 2021.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' in \emph{International Conference on
  Learning Representations}, 2015, pp. 1--14.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and F.-F. Li, ``{ImageNet}: {A}
  large-scale hierarchical image database,'' in \emph{IEEE Conference on
  Computer Vision and Pattern Recognition}, 2009, pp. 248--255.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby, ``An image is worth 16x16 words: {T}ransformers for image
  recognition at scale,'' in \emph{International Conference on Learning
  Representations}, 2021.

\bibitem{feichtenhofer2019slowfast}
C.~Feichtenhofer, H.~Fan, J.~Malik, and K.~He, ``{SlowFast} networks for video
  recognition,'' in \emph{IEEE International Conference on Computer Vision},
  2019, pp. 6202--6211.

\bibitem{liu2022video}
Z.~Liu, J.~Ning, Y.~Cao, Y.~Wei, Z.~Zhang, S.~Lin, and H.~Hu, ``Video {S}win
  {T}ransformer,'' in \emph{IEEE Conference on Computer Vision and Pattern
  Recognition}, 2022, pp. 3202--3211.

\bibitem{ismail2020inceptiontime}
H.~Ismail~Fawaz, B.~Lucas, G.~Forestier, C.~Pelletier, D.~F. Schmidt, J.~Weber,
  G.~I. Webb, L.~Idoumghar, P.-A. Muller, and F.~Petitjean, ``{InceptionTime}:
  {F}inding {AlexNet} for time series classification,'' \emph{Data Mining and
  Knowledge Discovery}, vol.~34, no.~6, pp. 1936--1962, 2020.

\bibitem{wu2023towards}
H.~Wu, L.~Liao, A.~Wang, C.~Chen, J.~Hou, W.~Sun, Q.~Yan, and W.~Lin, ``Towards
  robust text-prompted semantic criterion for in-the-wild video quality
  assessment,'' \emph{arXiv preprint arXiv:2304.14672}, 2023.

\bibitem{wu2023exploring}
H.~Wu, L.~Liao, J.~Hou, C.~Chen, E.~Zhang, A.~Wang, W.~Sun, Q.~Yan, and W.~Lin,
  ``Exploring opinion-unaware video quality assessment with semantic affinity
  criterion,'' \emph{arXiv preprint arXiv:2302.13269}, 2023.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  {T}ransformer: {H}ierarchical vision {T}ransformer using shifted windows,''
  in \emph{IEEE International Conference on Computer Vision}, 2021, pp.
  10\,012--10\,022.

\bibitem{he2020momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick, ``Momentum contrast for
  unsupervised visual representation learning,'' in \emph{IEEE Conference on
  Computer Vision and Pattern Recognition}, 2020, pp. 9729--9738.

\bibitem{he2022masked}
K.~He, X.~Chen, S.~Xie, Y.~Li, P.~Doll{\'a}r, and R.~Girshick, ``Masked
  autoencoders are scalable vision learners,'' in \emph{IEEE Conference on
  Computer Vision and Pattern Recognition}, 2022, pp. 16\,000--16\,009.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever, ``Learning
  transferable visual models from natural language supervision,'' in
  \emph{International Conference on Machine Learning}, 2021, pp. 8748--8763.

\bibitem{carreira2017quo}
J.~Carreira and A.~Zisserman, ``Quo vadis, action recognition? {A} new model
  and the {K}inetics dataset,'' in \emph{IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017, pp. 6299--6308.

\bibitem{thurstone1927law}
L.~L. Thurstone, ``A law of comparative judgment,'' \emph{Psychological
  Review}, vol.~34, no.~4, pp. 273--286, 1927.

\bibitem{bradley1952rank}
R.~A. Bradley and M.~E. Terry, ``Rank analysis of incomplete block designs:
  {I}. {T}he method of paired comparisons,'' \emph{Biometrika}, vol.~39, no.
  3/4, pp. 324--345, 1952.

\bibitem{ciancio2011no}
A.~{Ciancio}, A.~L. N.~T. da~{Costa}, E.~A.~B. da~{Silva}, A.~{Said},
  R.~{Samadani}, and P.~{Obrador}, ``No-reference blur assessment of digital
  pictures based on multifeature classifiers,'' \emph{IEEE Transactions on
  Image Processing}, vol.~20, no.~1, pp. 64--75, 2010.

\bibitem{ghadiyaram2016massive}
D.~Ghadiyaram and A.~C. Bovik, ``Massive online crowdsourced study of
  subjective and objective picture quality,'' \emph{IEEE Transactions on Image
  Processing}, vol.~25, no.~1, pp. 372--387, 2015.

\bibitem{hosu2020koniq}
V.~Hosu, H.~Lin, T.~Sziranyi, and D.~Saupe, ``{KonIQ-10k}: {A}n ecologically
  valid database for deep learning of blind image quality assessment,''
  \emph{IEEE Transactions on Image Processing}, vol.~29, pp. 4041--4056, 2020.

\bibitem{fang2020perceptual}
Y.~Fang, H.~Zhu, Y.~Zeng, K.~Ma, and Z.~Wang, ``Perceptual quality assessment
  of smartphone photography,'' in \emph{IEEE Conference on Computer Vision and
  Pattern Recognition}, 2020, pp. 3677--3686.

\bibitem{antkowiak2000final}
\BIBentryALTinterwordspacing
VQEG, ``Final report from the {Video Quality Experts Group} on the validation
  of objective models of video quality assessment,'' 2000. [Online]. Available:
  \url{https://www.its.bldrdoc.gov/media/8212/frtv_phase1_final_report.doc}
\BIBentrySTDinterwordspacing

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, ``Adam: {A} method for stochastic optimization,'' in
  \emph{International Conference on Learning Representations}, 2015, pp. 1--10.

\bibitem{zeng2014characterizing}
K.~Zeng, T.~Zhao, A.~Rehman, and Z.~Wang, ``Characterizing perceptual artifacts
  in compressed video streams,'' in \emph{SPIE}, 2014, pp. 173--182.

\bibitem{wang2023exploring}
J.~Wang, K.~C. Chan, and C.~C. Loy, ``Exploring {CLIP} for assessing the look
  and feel of images,'' in \emph{AAAI Conference on Artificial Intelligence},
  vol.~37, no.~2, 2023, pp. 2555--2563.

\bibitem{cho2014properties}
K.~Cho, B.~Van~Merri{\"e}nboer, D.~Bahdanau, and Y.~Bengio, ``On the properties
  of neural machine translation: {E}ncoder-decoder approaches,'' in
  \emph{Workshop on Syntax, Semantics and Structure in Statistical
  Translation}, 2014, pp. 103--111.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in
  \emph{Advances in Neural Information Processing Systems}, 2017, pp.
  6000--6010.

\bibitem{park2012video}
J.~Park, K.~Seshadrinathan, S.~Lee, and A.~C. Bovik, ``Video quality pooling
  adaptive to perceptual distortion severity,'' \emph{IEEE Transactions on
  Image Processing}, vol.~22, no.~2, pp. 610--620, 2012.

\bibitem{ninassi2009considering}
A.~Ninassi, O.~Le~Meur, P.~Le~Callet, and D.~Barba, ``Considering temporal
  variations of spatial visual distortions in video quality assessment,''
  \emph{IEEE Journal of Selected Topics in Signal Processing}, vol.~3, no.~2,
  pp. 253--265, 2009.

\bibitem{seshadrinathan2011temporal}
K.~Seshadrinathan and A.~C. Bovik, ``Temporal hysteresis model of time varying
  subjective video quality,'' in \emph{IEEE International Conference on
  Acoustics, Speech \& Signal Processing}, 2011, pp. 1153--1156.

\bibitem{wang2021troubleshooting}
Z.~Wang, H.~Wang, T.~Chen, Z.~Wang, and K.~Ma, ``Troubleshooting blind image
  quality models in the wild,'' in \emph{IEEE Conference on Computer Vision and
  Pattern Recognition}, 2021, pp. 16\,256--16\,265.

\bibitem{wang2021active}
Z.~Wang and K.~Ma, ``Active fine-tuning from {gMAD} examples improves blind
  image quality assessment,'' \emph{IEEE Transactions on Pattern Analysis and
  Machine Intelligence}, vol.~44, no.~9, pp. 4577--4590, 2021.

\bibitem{ma2018group}
K.~Ma, Z.~Duanmu, Z.~Wang, Q.~Wu, W.~Liu, H.~Yong, H.~Li, and L.~Zhang, ``Group
  maximum differentiation competition: {M}odel comparison with few samples,''
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~42, no.~4, pp. 851--864, 2020.

\bibitem{davis1997adaptive}
G.~Davis, S.~Mallat, and M.~Avellaneda, ``Adaptive greedy approximations,''
  \emph{Constructive Approximation}, vol.~13, pp. 57--98, 1997.

\end{thebibliography}
