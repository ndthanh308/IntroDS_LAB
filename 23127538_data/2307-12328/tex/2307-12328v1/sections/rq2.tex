\section{RQ2: Why developers use different models for one app on iOS and Android?}
% \chen{One big issue with this work is that there is too much text especially in the later part, while few figure/table, which makes it really hard for reviewers to understand}
% \chen{How do you know which app version is migrating from which app version? i.e., ios -> android or android -> ios?}
To conquer the market, one mobile app can be available on both Android and iOS~\cite{ali2017same}.
% Reusing the same DL frameworks and models in different platforms can reduce the engineering efforts and expenses of companies.
% A trained DL model is also easily reusable~\cite{coreML, TensorFlow, xgboost}, and retraining a DL model demands a substantial amount of high-quality data and expense~\cite{trainDLPrice}.
As discussed in Section~\ref{sec:frameCompare}, considering the cost of development associated with retraining a model, most developers should accept reusing models when developing mirror apps for other platforms.
However, we discovered notable differences of DL framework selection between Android and iOS apps in Section~\ref{sec:frameCompare}.
To investigate the impact of platform differences on the selection of DL frameworks by developers, we analyze the sharing and replacement of on-device models in iOS-Android app pairs and conclude why this occurs.


In this study, we first provide the method for comparing DL models to locate the same DL models between two platforms in Section~\ref{sec:modelCompare}.
We investigate current models' cross-platform selection in Section~\ref{sec:modelChange}.
Then we design a pipeline to investigate how current developers replace and share on-device models and analyze the underlying reasons for adopting different DL models in Section~\ref{sec:factorStudy}.
Through the study of RQ2, we explain how and why current developers use different DL models to support other developers in developing Android and iOS mirror apps.
We also provide suggestions for subsequent cross-platform optimization directions for the current DL frameworks from a developer's perspective.
It establish the groundwork for RQ3 to further analyse if current cross-platform usage approaches of on-device models pose any security threats.


\subsection{Model Comparison}
\label{sec:modelCompare}
We first match the same models between the two platforms.
Model structure and trained model parameters are the primary distinguishing characteristics of DL models~\cite{goodfellow2016deep}.
So, following related works~\cite{huang2021robustness, huang2022smart}, we identify reused on-device models by comparing their structure similarity (SS) and trained parameter similarity (PS).
Two model pairs are considered the same only if the structure and parameters are identical, as denoted by SS and PS values of 1.


\subsubsection{How to Compare Models' Structure Similarity?}
% The same model often has highly similar names on different platforms, so we first screened out models with highly similar names from different platforms of the same app.

We convert an on-device model to a sequence of elements, with each element constructed by the shape, data type, and name of each layer from the model~\cite{huang2021robustness, huang2022smart}. 
Given model $M_1$ and model $M_2$, their structural similarity is the longest common subsequence between the two models.
It is calculated by
\begin{equation}
    SS(M_1, \ M_2) = \frac{2 * L_{l}}{L_{M_1} + L_{M_2}}
\end{equation}
where $L_{l}$ is the length of the longest common subsequence in two models, and $L_{M_1}$ and $L_{M_2}$ are the numbers of two models' layers. 
Note that two layer elements are matched only if their attributes are totally the same.
The similarity score ranges from 0 to 1, and the higher the value, the greater the structural similarity between the two models.

\subsubsection{How to Compare Models' Parameter Similarity?}
\label{sec:ps}
After comparing the model structure similarity, we extract the trained parameters in each layer to compare the trained parameter similarity.
We count the number of elements with the same parameter in the longest common subsequence as their parameter similarity~\cite{goodfellow2016deep, huang2021robustness, huang2022smart}:
\begin{equation}
    PS(M_1, \ M_2) = \frac{2 * N_{l}}{L_{M_1} + L_{M_2}}
\end{equation}
where $N_{l}$ is the number of the same parameter elements in their longest common subsequence.

\subsubsection{How to Compare Gray-box Models?}
\label{sec:ps2}
As shown in Figure~\ref{fig:dlDis}, the gray-box model of Core ML framework is the most frequent model in iOS apps, accounting for more than one-third of the total.
For better platform compatibility, Apple encourage developers to convert the trained on-device model into the format of Core ML framework~\cite{CoreMLConvert}, such as converting the format from TF Lite in Android to Core ML in iOS.
Due to the same structure and parameters, the converted on-device and original models are considered equal.
However, it is hard for third parties to extract the trained parameters of Core ML models~\cite{coreML}.
To compare the Core ML model with the white-box model, we perform the following procedures.

% Core ML facilitates the conversion of certain TF Lite and TensorFlow models to Core ML format~\cite{CoreMLConvert}. 
We attempt to convert all eligible models to the Core ML format and compare the structure, weight and metadata of the converted models to verify if they are consistent.
Faced with models which cannot be converted to Core ML format, we first compare the structural similarity of the models and select two models with the same structure for further comparison.
We prepare a set of input data to feed to both models for prediction.
Two models are considered the same if their outputs are exactly the same.


\subsection{Model Selection on Two Platforms}
\label{sec:modelChange}
To acquire a comprehensive understanding of the present differences in DL model selection between iOS and Android developers, we first analyse quantitatively, among 334 matched iOS-Android app pairs, how many apps adopt distinct on-device models on Android and iOS.
We follow steps in Section~\ref{sec:modelCompare} to automatically and manually compare all models in 334 iOS-Android app pairs.

\begin{comment}
\subsubsection{Procedure}
Following model comparison steps in Section~\ref{sec:modelCompare},
we first automatically compare the structural similarity of on-device models in turn in iOS and Android apps.
All model pairs with the exact same structure are collected for further parameter comparison.
By applying parameter comparison steps in Sections~\ref{sec:ps} and~\ref{sec:ps2}, we manually and automatically compare the parameter similarities of all models with the same structure.
\end{comment}

\subsubsection{How Many Apps Adopt Different Models?}
In 334 corresponding Android apps, 125 (37.43\%) use completely distinct on-device models from that comparable iOS apps.
68 (20.36\%) out of 334 Android apps do not use on-device models.
Only 22 (6.59\%) out of 334 Android apps have on-device models that are all the same as their iOS counterparts.
21 (6.29\%) Android apps share models in part with their corresponding iOS apps.
These iOS-Android app pairs reuse a portion of on-device models across both platforms.
Our finding shows that most apps adopt different on-device models and frameworks on different platform apps.

\subsubsection{How Many Models are Shared between iOS and Android?}
\label{sec:ratio}
We match 332 (17.63\% ) the same on-device model pairs out of 1,883 on-device models on iOS.
We find 270 (81.33\%) out of 332 model pairs are exactly the same, including structure, trained parameters, and DL framework.
62 (18.67\%) out of 332 model pairs have the same structure and parameters but different DL frameworks.
On Android, these 62 on-device models are in TF Lite framework format, whereas on iOS, it is converted to gray-box Core ML model.
% We analyze the functionalities of these 282 app pairs.

% In the preceding sections, we study the variations in on-device models used by the same app on the iOS and android platforms. 
% In this part, we analyze the on-device models that are reused by the same app on both platforms.



\subsection{Reasons for Model Selection}
\label{sec:factorStudy}

% Figure environment removed

We provide a strict pipeline to study how current developers replace and share on-device models between Android and iOS and the underlying motives.
Considering the tremendous workload, we manually study a statistically representative random sample of 62 (20\%) out of 312 iOS-Android app pairs for a detailed study.
We find 226 on-device models with identified scenarios and functionalities in 62 iOS apps.

\subsubsection{Study Pipeline}
Figure~\ref{fig:rq2} shows the study pipeline of the effecting factors.
First, we identify the functionalities and usage scenarios of on-device models in selected iOS apps.
Second, we attempt to locate these use scenarios and functionalities within Android counterparts.
In this step, we follow the methodologies employed by recent related works~\cite{xu2019first, chen2021my, huang2022smart} to analyze the source code and semantic information in our investigated mobile apps.
For Android apps that can accurately find the code that calls the model, we instrumented the method at which the model is called and then dynamically run the app to dynamically analyze the app usage scenario where the model is called.
In cases where the calling code of the model could not be located, we manually analyze the semantic information of the model's functionality, file names, code comments, method names, and the user interface in the app to infer the possible scenarios in which the model could be used in the app. Finally, we validate our inferences by running the app and verifying whether the inferred scenarios encompassed the model's functionalities.
If we cannot find comparable functionality or usage scenarios in Android apps, we conclude that the original functionality of the on-device model on iOS has been discarded in their Android counterparts.
If we find the corresponding functionality and model, we further compare whether the model is the same.
If comparable functionality and usage scenarios can be found, but no corresponding on-device model, the role of the model on the iOS app is regarded as having been replaced in Android counterparts.

There are now three alternatives for on-device models: using other on-device models for the same task, invoking on-cloud models~\cite{gcloud, onCloud}, and implementing custom techniques to obfuscate models.
We first check if there are other models in the app that provide the required app functionality.
According to guidelines of the current frameworks for invoking on-cloud models~\cite{onCloud}, developers need pre-configure the cloud-related SDK libraries in the configuration files of the Android apps before invoking on-cloud models in the code.
For example, developers must pre-configure \emph{play-services-mlkit-text-recognition} in the configure file to invoke on-cloud text recognition services.
So, we first check if there are configured cloud-related SDK libraries in the configuration files of the Android app.
Then, we statically analyze whether apps invoke on-cloud models via application programming interfaces (APIs) provided by DL frameworks~\cite{mlKit} in decompiled app source files.
% We also check whether related libraries, such as \emph{libtensorflowlite\_jni.so} and \emph{libopencv\_java4.so} 
After failing to find the relevant on-device or on-cloud models, we inspect the decompiled Android apps to manually identify alternatives and customized DL models.
We search for two file types: the lib file of the DL frameworks associated with the model's functionality and the processed DL model file. 
Apps that employ deep learning techniques should include related libs~\cite{xu2019first, mlKit, pytorch-mobile}.
For example, the library file \emph{libtensorflowlite\_jni.so} is included in the app which uses TensorFlow.
Therefore, we used the presence of these files as an indicator of the usage of DL frameworks in the app.
We filter the obfuscated model file by analyzing the semantic information associated with the model, such as the names of the obfuscated and source models, and the names of the code files that call the model. 
If both the library file and the obfuscated model file are identified, we infer that the app's developer used a customized technique to obfuscate the model.


We invited three industry developers with at least one year of experience in Android and iOS development to conduct this study.
Each of the three participants follow the above steps to inspect all selected iOS-Android app pairs to explore the causes of change.
After the initial inspection, three volunteers have a discussion and merge conflicts.
They clarify their findings, scope boundaries among categories, and misunderstandings in this step.
Finally, they iterate to revise study results and discuss with each other until a consensus is reached.

\input{tables/tab_notuse}

\subsubsection{Results}
Table~\ref{tab:notuse} shows the investigation results of model sharing and replacement for 226 models in iOS-Android app pairs.
The column \emph{Alternative} represents the alternative method adopted by the corresponding Android app.
The \emph{unknown} in column \emph{Alternative} represents we cannot determine how this model is replaced now.
The column \emph{Number (\%)} represents the number and percentage of models are treated in this way.
The column \emph{Example App} shows some representative apps which are treated in this way. 
The column \emph{Example Models} and \emph{Model Functions} represent the detected on-device models in iOS apps and their functionalities.
The column \emph{Function Reservation} shows whether the identical function is reserved in the corresponding Android apps. 
% The column \emph{Alternative methods} represents the alternative method adopted by the corresponding Android app.

58 (25.66\%) out of 226 models choose alternative on-device models in corresponding Android apps.
The app \emph{Hello Pal} in Table~\ref{tab:notuse} employs a third-party SDK from SenseTime for face detection on iOS, but the Android app leverages Google's face detection technology.
% Additionally, we discover that some apps of large companies, like ByteDance, will eventually adopt their own technical solutions to replace the third-party DL framework that was previously used and to create and customize their own internal DL models.
Because of the difference in platforms, the same app's can select more appropriate frameworks~\cite{nguyen2019machine}.
Similar to choosing on-cloud models, we discover developers, particularly those from small and medium-sized developing teams, tend to select DL frameworks like Core ML and TF Lite that are more practical, simple to use, and more affinity with mobile systems~\cite{chooseDL, findDL}.


In corresponding Android apps, 55 (24.34\%) of the 226 models are eliminated. 
We find that the functionalities of these eliminated models are not fundamental to the apps, so their removals have no impact on the apps' primary business.
For example, the \emph{inference\_graph.tflite} model in Table~\ref{tab:notuse}, which is used for inference in the \emph{Strike:Bitcoin \& Payments} app, is removed in the Android counterpart, but no effect for this app's business.
According to the survey report~\cite{diffTeam}, Android and iOS apps are frequently developed by different teams in one software business due to their varied technical routes.
Thus, Android versions may use various technical solutions, like as DL frameworks, resulting in small variations in the auxiliary functions of the same app on different platforms.

45 (19.91\%) of the 226 models are found to be shared between Android and iOS apps.
We notice that the functionalities of these re-used models are always customized by the apps' features and plays vital parts in their apps.
TikTok, for instance, reuses two on-device models: \emph{tt\_face\_attribute\_age.model}, which is used for age prediction, and \emph{tt\_face\.model}, which is used for face detection in both Android and iOS apps.
 
34 (15.04\%) out of 226 models are replaced with on-cloud DL models.
Different from Core ML on iOS, Google's ML Kit~\cite{mlKit} offers practical and convenient on-cloud DL model solutions. 
Android developers can activate on-cloud deep learning models for text, face, and barcode recognition with a few lines of code.
Note that differences in hardware and software configurations can significantly affect the performance of on-device models, particularly on the fragmented Android platform. IPhones generally have similar hardware and software configurations, but Android devices are plagued with fragmentation issues, causing compatibility concerns for app developers across various Android devices. Certain Android devices with suboptimal hardware conditions may severely impact the efficiency of on-device models, rendering them unsuitable for use. In such scenarios, on-cloud models are a more viable option, given that they have lower hardware and software requirements for phones and are better suited for the heavily fragmented Android platform. Additionally, while on-cloud models may have network requirements, they can be more cost-effective in terms of engineering efforts and deployment, thus making them a more appealing choice for some Android developers.
For example, as shown in Table~\ref{tab:notuse}, \emph{Homebase Employee Scheduling} and \emph{Postmates - Food Delivery} use on-cloud models provided by ML Kit to detect objects in Android apps to replace on-device models \emph{SSDOcr.mlmodelc} and \emph{DocScanCSCModel.tflite} in iOS apps.

24 (10.62\%) out of 226 models in the Android app received extra protections, including weights compression and model obfuscation.
It is tough for us to obtain extra details on the obscured model.
Android apps are widely perceived as being less secure than iOS apps.
Therefore, developers have increased security measures for Android apps.
To prevent the model from being readily taken or attacked,
\emph{EnhanceFox - AI Photo Enhancer} in Table~\ref{tab:notuse} obfuscates the DL models in Android apps, that could have a positive impact on user privacy and corporate assets.

10 (4.42\%) out of 226 models cannot currently be identified for replacement in Android apps.

\subsubsection{Suggestions}
\label{sec:suggestions}
We offer suggestions for both app developers and DL framework providers, which may support future development in this field.

To retain current DL framework users and appeal to a broader user base, framework providers should optimize the framework in two areas. 
First, to encourage the use of deep learning frameworks in multiple platforms, it is essential to make the cross-platform migration of the model more convenient and concise, while improving the cross-platform compatibility of the model. 
Our analysis reveals that despite the claims of deep learning frameworks to support both Android and iOS platforms, only a small percentage of models, i.e., 17.63\% out of 1,883 models, are shared between the two platforms.
Currently, the migration of a deep learning model from Android to iOS platforms involves converting the model from its original format to a format compatible with the iOS platform, while ensuring that the functionality and accuracy of the model remain unchanged. This conversion process may require modifications to be made to the model's architecture, code, and parameters, while considering the differences in hardware and software configurations between the two platforms.
Developers may find the engineering efforts involved in using the current framework's cross-platform migration model approach relatively high, as compared to using a more convenient approach specific to the current platform to achieve the same deep learning functionality, such as the on-cloud model. Therefore, the proportion of current developers reusing models between Android and iOS is not high.
Second, the ease of use of the framework should be improved by providing a comparable and accessible solution for utilizing deep learning functionalities on the iOS platform as on the Android platform, along with robust cross-platform support.
Deep learning features, such as text recognition, QR code recognition, face recognition, and object recognition, are more accessible to developers in Android apps compared to iOS. 
Due to cost-saving advantages, Android developers are more inclined to use pre-existing deep learning techniques provided by frameworks rather than reuse their own models.
In cases where on-device models are reused between the two platforms, they are often customized by app developers to provide tailored functionalities, which cannot be provided by DL frameworks.
In conclusion, cross-platform compatibility and ease of use should become the key direction of future framework optimization.

From the developer's perspective, it is essential to understand that differences in hardware and software between Android and iOS platforms can significantly affect the accuracy and efficiency of the model. Furthermore, the availability of specific hardware components, such as GPUs or accelerometers, can vary between the two platforms, influencing model selection and usage. Therefore, developers should carefully consider these factors and choose a more suitable framework when developing mirror apps on different platforms.
Moreover, developers should prioritize the cross-platform compatibility of app-customized models by pre-defining cross-platform interfaces and security safeguards for these models. This can mitigate the engineering efforts and security concerns associated with developing mirror apps for other platforms in the future. In summary, selecting a more appropriate DL framework for the app's target users and designing interfaces and security for custom models in advance can ease the developer's engineering efforts and better maintain the consistency of one app on different platforms.


 

% TF Lite and Core ML are deep learning frameworks provided by Google and Apple respectively, and are optimized for their respective platforms, Android and iOS, with better platform compatibility compared to other frameworks~\cite{tfLite, coreML}. 
% The differences in platform compatibility may affect the efficiency of the model~\cite{CoreMLConvert}. 




\begin{comment}
In conclusion, current developers reuse app-customized models due to the significant engineering cost required to train a model.
For the remaining models, current developers prefer selecting a more convenient DL framework or cloud model, or even removing them directly.
% considering the cost of development, platform compatibility, security and the importance of the model's corresponding functionality, current developers always choose a more convenient DL framework or cloud model instead, or even remove it directly.
Therefore, while developing apps, developers should prioritize the cross-platform compatibility of the app-customized models. 
By pre-defining cross-platform interfaces and security safeguards for these models, developers may alleviate the engineering effort and security concerns associated with developing mirror apps for other platforms in the future.
\end{comment}

\begin{summary}[]
Due to the different ecosystems of the Android and iOS platforms, only a tiny number of Android apps fully reuse the on-device models of iOS apps. 
% \chen{So developers have on-device models on iOS apps and then develop Android apps? How do you know that? By analyzing the app development history?}
25.66\% of iOS apps' on-device models are replaced in Android by selecting more convenient models.
17.63\% of on-device models, which provide customized functionalities for apps, are shared by apps across Android and iOS.
% Existing app developers will pick a more convenient \chen{Compared with what?} alternative to these on-device models on the present platform for on-device models that do not impact the app's fundamental functionality.
Existing DL framework vendors should simplify developers' use of fundamental DL models and improve cross-platform interoperability and security for developers' on-device models to acquire market share.
\end{summary}


% Developers are gradually building their own DL solutions, or choosing more convenient DL solutions provided by Google and Apple, so the market for other third-party DL frameworks is gradually decreasing.
% Our findings also 
