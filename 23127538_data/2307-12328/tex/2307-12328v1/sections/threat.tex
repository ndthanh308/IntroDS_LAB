\section{Threats to Validity}
We discuss the threats to validity, including internal threats and external threats in the section.

\subsection{Internal Threats}

\subsubsection{False Negatives of Detecting On-device Models}

App developers employ various techniques to safeguard on-device models from theft, such as encryption and obfuscation. 
In our study, we discover that some developers may slice the models and compile them into binaries, making it more challenging for third parties to detect them by semantic pattern matching. 
This may cause our model detection method to miss some models, resulting in false negatives. 
The current limitations of dynamic code analysis tools for iOS apps also hinder a more in-depth investigation of this area.
% To mitigate this issue, instrumenting the app and dynamically detecting and analyzing the app source code can help in detecting encryption and obfuscation models. 
% However, the current limitations of dynamic code analysis tools for iOS apps hinder a more in-depth investigation of this area.
In this paper, we chose to invite experienced developers to manually search for encrypted or obfuscated on-device models in apps to mitigate this issue.
% However, due to the extensive workload involved (2,907 iOS apps), we can only invite three experienced participants in RQ2 to manually inspect source files of part of collected apps to detect possible false negatives.
% To mitigate this issue, we initially summarize the semantic patterns that the on-device model might contain and automatically detect the on-device model in all apps.
% Finally, we invite experienced developers to manually search and validate encrypted or obfuscated models in apps.

As a future direction, we plan to conduct a comprehensive analysis of the iOS app's code, including calling the model API, loading the model API, dynamically downloading the model API, and detecting the DL model from the code pattern level, to address the limitations of our current study.




\subsubsection{Bias for Model Functionality and Use Scenarios Inference}

We infer possible functions of the model in Section~\ref{sec:modelFunction} by leveraging semantic information of the app and the model. However, obtaining a comprehensive understanding of the usage of each model in an iOS app may require identifying the calling model at the code level and dynamically running the app to detect its usage. Current limitations of static and dynamic analysis tools for iOS apps hinder our ability to analyze models from the code level effectively as we do for Android apps. 
To mitigate possible inaccuracies in our functional inferences, we dynamically run the iOS app to verify our inferences. However, we cannot fully guarantee the accuracy of all inferences, resulting in potential bias in our current approach. 
In future work, we plan to explore alternative methods for analyzing the code of on-device models in iOS apps. This aims to reduce potential bias and improve the accuracy of our functional inferences.



\subsubsection{Impact of Remote Attacks on On-device Models in iOS Apps}

One potential threat to the validity of our study is the assumption that attackers have access to the targeted iOS devices and can perform the attacks locally. This may not be a realistic scenario in some cases, especially if the attack is conducted remotely.
Our study did not investigate the potential impact of remote attacks on on-device models in iOS apps, which is a limitation. Remote attacks may have different characteristics and may require different techniques than local attacks, and their effectiveness may depend on the network environment and other factors. Therefore, the results of our study may not fully reflect the security risks faced by on-device models in real-world scenarios.
However, we note that our proposed attack can still be effective in some scenarios where users need to capture inputs from the real-world, and the attacker can place adversarial inputs beforehand to cause misclassification. We also acknowledge that further research is needed to explore the impact of remote attacks on on-device models and to develop effective defenses against such attacks.


\subsubsection{Limitations on the scope of the attack method in RQ3}

Our attack method can only be applied to black-box models that have white-box counterparts, which represent 17.63\% of the 1,883 models discovered in iOS apps. We have only identified image-based models in real-world iOS apps, and lack experiments with models from other domains such as natural language processing and speech recognition. While our primary objective is to assess the robustness of current on-device models against adversarial attacks, our focus on image-based models limits the generalizability of our findings. 
It's worth noting that our proposed attack method can be easily migrated to other types of models, such as NLP and speech recognition. 
To address these limitations, we plan to design and analyze the effectiveness of our approach on more types of models algorithmically in future work. To expand the range of black-box models that we can attack, we plan to try to migrate the adversarial example to attack black-box models with similar structures and parameters.



\subsection{External Threats}
\subsubsection{Dynamic Analysis of On-device Models}
In this study, we primarily use static analysis to examine on-device models and code in Android and iOS apps. Although useful, static analysis cannot capture the state of on-device models after the app is launched. Dynamic analysis, on the other hand, can provide more in-depth insights into the current state of on-device models, including memory usage, call time analysis, and dynamic data security. Additionally, it can help collect more on-device models for obfuscated or encrypted models by analyzing the code of the app loading the model and dumping the model from the memory where the app is running. However, current dynamic analysis tools for iOS apps have limitations that prevent effective analysis of on-device models. As a result, we invite three experienced participants to manually analyze the running app to identify the app's functions and use scenarios that might call the on-device model. However, this approach proved less effective than direct dynamic analysis.

Therefore, we think that the development of better dynamic analysis tools for iOS apps is crucial for future research. These tools will enable more effective analysis of on-device models and facilitate further investigations on dynamic security risks, model attacks, and protection.



\subsubsection{Impact of Model Properties on Model Selection}

Model accuracy, interpretability, and explainability are important considerations when selecting on-device models. Accuracy is commonly used to evaluate model performance, while interpretability and explainability are crucial for building trust in the model and understanding how it makes predictions. However, balancing these factors can be challenging, as accuracy may come at the expense of interpretability and explainability, and vice versa. Moreover, the impact of these factors may vary across different application domains. While interpretability and explainability may be more critical in domains like healthcare and finance, accuracy may be the primary consideration in image or speech recognition. Despite their significance, the impact of these factors on developer model selection is often overlooked. 
The scope of this paper focuses on the impact of the differences between iOS and Android platforms on on-device model selection, so we have not delved into the impact of model properties on model selection in this paper. Still, it is a crucial area for future investigation.


\subsubsection{Impact of Platform Hardware and Software Configurations on Model Selection}

The differences in hardware and software configurations across platforms can influence the performance and compatibility of the on-device models, which may affect the model selection process. While this paper briefly touches upon the impact of hardware and software differences on model selection in Section~\ref{sec:suggestions} of RQ2, no detailed examination of how specific hardware and software factors affect the selection process is conducted. Thus, in future work, we aim to investigate the effects of hardware and software-specific factors on the model selection process.


\subsubsection{Impact of User Behavior and Preference on Model Selection}

% External threats to validity include the potential impact of user behavior and preference on model selection. 
Different apps have varying target users, the preferred model for one user may not necessarily be suitable for another. 
User preference may prioritize model accuracy or interpretability over computational resources or inference time. Moreover, users may have different concerns about data privacy and ethics, which can affect the selection and usage of specific models. 
Our study focuses on the perspective of app developers and DL framework providers when selecting on-device models and does not consider user behavior and preference. 
% Although the potential influences are acknowledged, this study did not analyze them in detail. 
Future research will investigate the impact of user behavior and preference on model selection and usage to provide a more comprehensive understanding of on-device model adoption.


