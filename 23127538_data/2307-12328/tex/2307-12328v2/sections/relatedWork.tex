\section{Related Work}
% \chen{Related works cannot be put into appendix!! Only some very details of the approach or evaluation results can be put into the appendix!}
Our work empirically studies the characteristics and potential security issues of DL models on iOS apps.
In this section, we discuss related works about deep learning techniques on mobile and adversarial attacks on deep learning models.

\subsection{Deep Learning Techniques on Mobile}
With the rapid development of computing hardware, more and more deep learning frameworks support the deployment of on-device models on mobile.
Deep learning technologies currently applied on smartphones can be divided into two categories: on-device model and on-cloud service.
Xu et al.~\cite{xu2019first} first explore the characteristics of deep learning apps on smartphones.
However, due to the difficulties of collecting iOS apps, they only study apps on Android, and some technologies like CNNDroid~\cite{latifi2016cnndroid}, Parrots~\cite{sensetime} and PyTorch~\cite{pytorch-mobile} are outdated.
% \chen{Need to show how difficult it is to do in iOS apps, and what technology is outdated?}
Sim et al. investigate the effectiveness of on-device models on automatic speech recognition~\cite{sim2019investigation}.
Ravi et al.~\cite{ravi2019efficient} propose an approach to improve the effectiveness of on-device models on smartphones.
Their efforts exclusively address certain aspects of on-device models, and none of them include iOS apps.
In industry, more and more deep learning frameworks support on-device models on both Android and iOS, such as TF Lite, TensorFlow, Caffe2, Mace~\cite{mace}, and so on.
The increasing prevalence of the on-device model calls for a comprehensive study of it, particularly the on-device model on the iOS platform.
Some companies also provide the service of on-cloud deep learning models, like Google~\cite{googlecloud}, Amazon~\cite{amazoncloud}, and Microsoft Azure~\cite{Microsoftcloud}.
Prior studies focus on analyzing the machine learning as a service (MLaas) system~\cite{fredrikson2015model, tramer2016stealing, yao2017complexity, shokri2017membership, hu2019code}.
However, on-cloud models have disadvantages compared to on-device models, such as privacy concerns and unreliable accessibility. 
Consequently, some DL tasks are better suited for execution on local devices, such as face detection and photo beauty. 
Our research also demonstrates that some current apps use both on-device and on-cloud deep learning models for different tasks in one app.


\subsection{Adversarial Attacks on Deep Learning Models}
Adversarial attacks, which only add subtle perturbations to input images, can lead a deep learning model to output incorrect prediction results with high confidence level~\cite{zhang2019adversarial}.
Adversarial attacks have achieved remarkable progress, especially in the computer vision field.
Current adversarial attacks can be divided into two categories: white-box attacks and black-box attacks or targeted attacks and non-target attacks.
Huang et al.~\cite{huang2021robustness} first explore the robustness of on-device deep learning models on Android apps.
They propose a straightforward yet effective approach, which requires locating the pre-trained model of the on-device model, attacking the pre-trained model to generate adversarial examples, and then using the adversarial examples to attack the on-device model.
However, this work requires locating the pre-trained model and only investigating on-device models on iOS apps.
Since deep neural networks are vulnerable to adversarial attacks, researchers have proposed several defense methods, including adversarial training, transformation, distillation, and gradient regularisation~\cite{he2019towards, zhou2023modelobfuscator}.
Although several studies have proved the potential security issues of on-device models on Android apps, systemic study on the security of on-device models on iOS apps is scant.
Our work systematically investigates the security threat of the on-device model in the face of adversarial attacks in iOS Apps for the first time. It demonstrates that the On-device model of the Core ML framework in iOS Apps still poses significant security risks.

In prior research, some efforts~\cite{liu2016delving, fang2020local, tramer2017ensemble, huang2023training} have used an ensemble of multiple models to generate attacks that can be transferred over multiple models, and there is some overlap with our attack in RQ3 which uses white-box models as bridges. 
However, these approaches tend to be too theoretical and do not specifically target the on-device models in iOS apps for attack design, resulting in relatively low overall attack success rates. 
Our work is more practical and effective in real-world scenarios, as we generate adversarial examples against the target model based on its trainable form, which is more efficient than using an ensemble of multiple models. Additionally, we specifically design our attack for the unique characteristic of on-device models, taking into account the fact that backpropagation is disabled under this setting. This consideration enhances the practicality of our approach for on-device models in iOS apps.

