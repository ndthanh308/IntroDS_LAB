\section{Discussion}
% \chen{I see that there are many DL models in HuggingFace, any potential insight?}
In this section, we discuss some implications following our previous observation and experiments.
% \chen{Too many shallow analyses and please merge them to get deeper analysis. Please back up your statement with examples/statistics/conclusions from prior sections.}

\subsection{Implication on Employing and Deploying On-device Models on iOS}

\subsubsection{Optimize NLP On-device Model Deployment.} In RQ1, most on-device models perform CV-related tasks, while the NLP-related on-device models are less common. This can be attributed to: (1) traditional/classical NLP models like LSTM and RNN are less efficient than Large Language Models (LLMs), however the development of LLMs for edge devices is hard. (2) NLP models inevitably come with dictionaries/word embedding layers, which are heavy and not easy to optimize. (3) Employing NLP models on edge devices should address the language challenge as a DL app may provide services to people from different countries.
Hence, this can be a future research direction as NLP is another crucial part for on-device deep learning models.

\subsubsection{Optimize Between-app On-device Model Development}
For developing a DL app in iOS and Android platform, DL framework vendors should optimize their products to facilitate the cross-platform on-device model development. Based on our findings in RQ2, potential solutions can be: (1) Implementing platform-specific optimisation to ensure that a well-trained model can be adapted for proprietary use on several platforms.
(2) offering unified APIs makes the development of on-device models for different platforms indistinguishable. (3) enhancing framework compatibility for various platforms.

\begin{comment}
\subsubsection{Differentiate between the app's essential and non-essential functionalities}
Before developing or migrating an app, it is necessary for developers to explicitly identify between the core and non-core functionalities \chen{??}.
With the awareness of the app's essential and non-essential functionalities, developers can choose a more lightweight deep learning framework or on-cloud model for the present platform for non-essential features to avoid having too many on-device models, which can lead to bloated app sizes and even affect the app's core functionality.


\subsubsection{Convert on-device models to Core ML framework format}
Core ml is currently the most popular deep learning framework in iOS apps.
Some developers use on-device models in formats such as TF lite without converting them to the specified core ml format in iOS apps.
The on-device model of Core ML is more secure and has a lesser likelihood of being successfully attacked than other white-box models. \chen{This is the implication??}
\end{comment}


\subsubsection{Optimize In-app On-device Model Collaboration}

In RQ1, we explore \emph{How many on-device models are there in one app?} in Section~\ref{sec:appNum} and \emph{What is the size of on-device models?} in Section~\ref{sec:modelSize}.
Current DL frameworks generally correspond to a single model for a single feature, and extensive usage of deep learning in iOS apps has resulted in an excessive and bloated on-device models for some apps.
Appropriately improving the management and scheduling of models can significantly enhance the app's utilisation of models.
A vital optimization direction is to optimize the management for all on-device models in an app.

From the DL framework vendor side, many current downstream tasks are based on the same type of pretrain models~\cite{huang2021robustness, tensorflowHub}.
Frameworks can attempt to slice and dice models and extract sliced model for usage in numerous tasks. 
Frameworks dynamically combine shared pretrain and fine-tuning model slices when on-device models are used. 
This increases the security of models by making it more difficult for an attacker to locate specific models. 
On the other hand, it can reduce the number and size of models within the app and optimise model utilisation efficiency.

% \yujin{What about changing this sub-section title to "Optimize in-app on-device model collaboration"?}

\subsubsection{Prevent App Users from Locating to a Specific On-device Model using App Semantics}
We discover in RQ1 that locating the scenario of the model's usage in the app by the model's functionality is typically straightforward.
Although it is difficult to directly attack an iOS app, after discovering the model's usage scenario in the app, it is possible to use the model's vulnerability to disable the related functionality in order to further attack the app.
To prevent possible security issues, app developers should avoid leaving semantics that can be used to infer connections between models and functionalities.


\subsection{Implication for the Security of On-devices Models}

\subsubsection{Cross-platform Protection for Your Own On-device Models}
Although there are differences between the Android and iOS platforms, our research demonstrates that the same security vulnerabilities exist in the on-device model on both platforms.
In RQ3, we generated adversarial examples using the on-device model on the Android app and experimentally verified that these adversarial examples are equally valid for the Core ML model in iOS.
It is also possible to directly deactivate a portion of the iOS app's functionality.

From the app developer side, app developers should provide uniform protections when deploying on-device models in multiple platforms.
Also, the unified management of all on-device models within an app facilitates the reuse and deployment of uniform security measures for these models.
% Due to the high cost of training a model, DL model reuse has become more and more common.
% We discover in RQ2 that 19.04\% on-device models which serves as essential functionalities in apps are shared across Android and iOS.

\subsubsection{Obfuscate On-device Models}
It is difficult to attack obfuscated on-device models with current ways of attacking on-device models.
However, we found in RQ2 that the percentage of obfuscated on-device models in current iOS apps is low (10.63\%).
Current iOS app developers and deep learning frameworks can design more methods to obfuscate the model to increase the model's security.


% \subsubsection{Encrypt on-device models can be another implication for protecting on-device models.}

% \subsubsection{Adversarial train on-device models can be another implication for protecting on-device models.}

\subsubsection{Authenticate the Users of On-device Models}
Regarding DL app developers, the utilization of their on-device models can be secured by mandating user authentication and the provision of a unique token. From the perspective of model providers, it is essential to establish secure license distribution mechanisms from the server side and implement effective license management procedures on the client side prior to the utilization of their models in order to ensure security.


