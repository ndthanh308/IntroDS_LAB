\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}

\usepackage[ruled]{algorithm2e}
\usepackage{multirow}
% \usepackage{algorithmic}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{1601} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi
\renewcommand\thesection{\Alph{section}}
\begin{document}

%%%%%%%%% TITLE
\title{$-$Supplementary Material$-$ \\ Semantically Aligned and Uniform Video Grounding via Geodesic and Game Theory}



\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% BODY TEXT

\section{Overview}

In this supplementary material, we present the following.
\begin{itemize}
    \item Axiomatic Properties of Shapley Value (Section~\ref{sec: a1}).
    \item Proof of Equation 10 (Section~\ref{sec: a2}).
    \item More Experiments (Section~\ref{sec: a3}).
    % \item More Implementation Details (Section~\ref{sec: a4}).
\end{itemize}

\section{Axiomatic Properties of Shapley Value}\label{sec: a1}
	In this section, we mainly introduce the axiomatic properties of Shapley value. Weber \etal~\cite{weber1988probabilistic} have proved that Shapley value is the unique metric that satisfies the following axioms: \emph{Linearity}, \emph{Symmetry}, \emph{Dummy}, and \emph{Efficiency}.
	
	\textbf{Linearity Axiom.} If two independent games $u$ and $v$ can be linearly merged into one game $w(\mathcal{U}) = u(\mathcal{U}) + v(\mathcal{U})$, then the Shapley value of each player $i \in \mathcal{N}$ in the new game $w$ is the sum of Shapley values of the player $i$ in the game $u$ and $v$, which can be formulated as:
	
	\begin{equation}
		\phi_w(i|\mathcal{N}) = \phi_u(i|\mathcal{N}) + \phi_v(i|\mathcal{N})
	\end{equation}
	
	
	\textbf{Symmetry Axiom.} Considering two players $i$ and $j$ in a game $v$, if they satisfy:
	\begin{equation}
		\forall \mathcal{U} \in \mathcal{N} \setminus \{i, j\}, v(\mathcal{U} \cup \{i\}) = v(\mathcal{U} \cup \{j\})
	\end{equation}
	then $\phi_v(i|\mathcal{N}) = \phi_v(j|\mathcal{N})$.
	
	\textbf{Dummy Axiom.} The dummy player is defined as a player without interaction with other players. Formally, if a player $i$ in a game $v$ satisfies:
	\begin{equation}
		\forall \mathcal{U} \in \mathcal{N} \setminus \{i\}, v(\mathcal{U} \cup \{i\}) = v(\mathcal{U}) + v(\{i\})
	\end{equation}
	then this player is defined as the dummy player. In this way, the dummy player $i$ has no interaction with other players, \ie $v(\{i\}) = \phi_v(i|\mathcal{N})$.
	
	
	\textbf{Efficiency Axiom.} The efficiency axiom ensures that the overall reward can be assigned to all players, which can be formulated as follows:
	\begin{equation}
		\sum_{i \in \mathcal{N}} \phi_v(i) = v(\mathcal{N}) - v(\varnothing)
	\end{equation}

\section{Proof of Equation 10}\label{sec: a2}
In this section, we provide detailed proof for Equation~10 in Section~3.5.2. The semantic Shapley interaction between moment $x$ and query $y$ in video $V_i$ can be decomposed as follows:
\vspace{-0.05cm}
\begin{align}
    \mathfrak{I}([\mathcal{H}^i_{xy}]) &= \phi([\mathcal{H}^i_{xy}]|\mathcal{H}^i \setminus \mathcal{H}^i_{xy} \cup \{[\mathcal{H}^i_{xy}]\}) \nonumber\\
    &- \phi(\mathbf{h}^V_{ix}|\mathcal{H}^i \setminus \mathcal{H}^i_{xy} \cup \{\mathbf{h}^V_{ix}\}) \nonumber\\
    &- \phi(\mathbf{h}^Q_{iy}| \mathcal{H}^i \setminus \mathcal{H}^i_{xy} \cup \{\mathbf{h}^Q_{iy}\}) \\
    &= \mathop{\mathbb{E}}\limits_{C} \{\mathop{\mathbb{E}}\limits_{\mathcal{U} \subseteq \mathcal{H}^i \setminus \mathcal{H}^i_{xy}  \atop |\mathcal{U}| = C} [f(\mathcal{U} \cup \mathcal{H}^i_{xy}) - f(\mathcal{U})] \} \nonumber\\
    &- \mathop{\mathbb{E}}\limits_{C} \{\mathop{\mathbb{E}}\limits_{\mathcal{U} \subseteq \mathcal{H}^i \setminus \mathcal{H}^i_{xy}  \atop |\mathcal{U}| = C} [f(\mathcal{U} \cup \{\mathbf{h}_ix^V\}) - f(\mathcal{U})] \} \nonumber\\
    &- \mathop{\mathbb{E}}\limits_{C} \{\mathop{\mathbb{E}}\limits_{\mathcal{U} \subseteq \mathcal{H}^i \setminus \mathcal{H}^i_{xy}  \atop |\mathcal{U}| = C} [f(\mathcal{U} \cup \{\mathbf{h}^Q_{iy}\}) - f(\mathcal{U})] \}\\
    &= \mathop{\mathbb{E}}\limits_{C} \{\mathop{\mathbb{E}}\limits_{\mathcal{U} \subseteq \mathcal{H}^i \setminus \mathcal{H}^i_{xy}  \atop |\mathcal{U}| = C} [f(\mathcal{U} \cup \mathcal{H}^i_{xy}) - f(\mathcal{U} \cup \{\mathbf{h}^V_{ix}\}) \nonumber \\
    &- f(\mathcal{U} \cup \{\mathbf{h}^Q_{iy}\}) +  f(\mathcal{U})\ ]\  \}
\end{align}

 \section{More Experiments}\label{sec: a3}

% \begin{table}[]
% \begin{center}
% \begin{tabular}{ccc|ccccc}
% \hline
% \multirow{2}{*}{$K$} & \multirow{2}{*}{$n$} & \multirow{2}{*}{$k$} & R@1 & R@1 & R@5 & R@5 & Training Time \\
%  &  &  & IoU0.5 & IoU0.7 & IoU0.5 & IoU0.7 & (sec/iter) \\
%  \hline \hline
% % 4 & 1 & 2 & 57.79 & 40.61 & 80.53 & 69.65 &  59.2493 \\
% % 4 & 2 & 2 & 58.54 & 42.43 & 81.15 & 70.68 &  68.2008 \\
% % 2 & 2 & 2 & 58.58 & 42.25 & 81.22 & 70.53 &  61.0022 \\
% 8 & 2 & 4 & 51.10 & 32.62 & 80.96 & 66.95 & 120.9764 \\
% 8 & 2 & 2 & 51.17 & 32.46 & 81.00 & 66.70 & 121.8949 \\
% % 14 & 5 & 5 & 51.68 & 33.35 & 81.32 & 67.60 &  \\
% 16 & 4 & 4 & 51.26 & 32.71 & 80.99 & 66.88 & 186.6993 \\
% 16 & 4 & 8 & 51.15 & 32.90 & 80.82 & 66.84 & 189.3500 \\
% % 20 & 5 & 5 & 51.25 & 33.00 & 80.90 & 66.84 & 223.5548 \\
% 32 & 4 & 4 & 51.05 & 32.86 & 80.71 & 66.94 & 285.9253 \\
% 32 & 4 & 8 & 51.27 & 32.86 & 80.76 & 66.67 & 285.8911 \\
% 32 & 4 & 8 & 51.27 & 32.63 & 80.60 & 66.84 & 283.3188 \\
% 32 & 4 & 16 & 51.19 & 32.95 & 80.69 & 66.59 & 294.7729 \\
% 32 & 8 & 8 & 51.38 & 33.10 & 80.88 & 66.87 & 346.6406 \\
% 32 & 8 & 16 & 51.16 & 32.75 & 80.97 & 66.50 & 329.2075 \\

% \hline
% \end{tabular}
% \end{center}
% \caption{}
% \label{tab:abs para}
% \end{table}
\begin{table}[t]
\renewcommand\arraystretch{1.2}
\fontsize{8.25}{9.5}\selectfont
\begin{center}
\begin{tabular}{ccc|ccccc}
\hline
\multirow{2}{*}{$n$} & \multirow{2}{*}{$k$} & \multirow{2}{*}{$K$} & R@1 & R@1 & R@5 & R@5 & Time \\
 &  &  &  IoU0.5 & IoU0.7 & IoU0.5 & IoU0.7 & (sec/iter) \\ \hline
% 2 & 4 & 8 & 51.10 & 32.62 & 80.96 & 66.95 & 120 \\
% 2 & 2 & 8 & 51.17 & 32.46 & 81.00 & 66.70 & 121 \\
4 & 4 & 16 & 51.26 & 32.71 & 80.99 & 66.88 & 186 \\
4 & 8 & 16 & 51.68 & 33.35 & 81.32 & 67.60 & 189 \\
4 & 4 & 32 & 51.05 & 32.86 & 80.71 & 66.94 & 285 \\
4 & 8 & 32 & 51.27 & 32.86 & 80.76 & 66.67 & 285 \\
4 & 8 & 32 & 51.27 & 32.63 & 80.60 & 66.84 & 283 \\
4 & 16 & 32 & 51.19 & 32.95 & 80.69 & 66.59 & 294 \\
8 & 8 & 32 & 51.38 & 33.10 & 80.88 & 66.87 & 346 \\
8 & 16 & 32 & 51.16 & 32.75 & 80.97 & 66.50 & 329 \\ \hline
\end{tabular}
\end{center}
\caption{Ablation study of Hyper-parameters. `` Time " denotes the training time.}
\vspace{-0.3cm}
\label{tab:abs para}
\end{table}

 To further investigate the effect of the moment graph and the number of samples on the model, we show the different variants in Table~\ref{tab:abs para}, where $n$ is the number of nearest neighbors for each node at the moment graph (Section~3.3); $k$ is the number of semantic positive samples for each query (Section~3.4); $K$ is the number of moment player for each query player in a game (Section~3.5.2). We find that the best combination is $\{n\!=\!4, k\!=\!8, K\!=\!16\}$. Consistent with our discussion in Section 4, the number of players involved in the game is positively correlated with the computational cost. We observe that increasing $K$ leads to performance degradation, indicating that similar moments based on geodesic distance sorting and sampling have strong semantic correlations. Involving the excessive number of weakly correlated moments in the game is not conducive to modeling fine-grained semantic alignment.
 
 % \section{More Qualitative Analysis}\label{sec: a4}
% \section{More Implementation Details}\label{sec: a4}
% We following previous works~\cite{2D-TANzhang2020learning,MMNwang2022negative}, the convolutional network for proposal feature modeling uses exactly the same settings with 2D-TAN~\cite{2D-TANzhang2020learning}, including visual feature, number of sampled clips, number of 2D convolutional layers, kernel size, channels, NMS threshold, scaling thresholds and the dimension of the joint feature space.
 
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}