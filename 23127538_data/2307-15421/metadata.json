{
  "title": "MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression",
  "authors": [
    "Wei Jiang",
    "Jiayu Yang",
    "Yongqi Zhai",
    "Feng Gao",
    "Ronggang Wang"
  ],
  "submission_date": "2023-07-28T09:11:37+00:00",
  "revised_dates": [
    "2023-09-03T09:01:43+00:00",
    "2023-10-30T05:56:08+00:00",
    "2023-12-18T09:02:57+00:00",
    "2024-01-07T03:52:03+00:00",
    "2024-01-16T15:15:49+00:00",
    "2024-02-03T09:12:10+00:00",
    "2024-02-14T11:13:49+00:00",
    "2024-02-20T03:25:43+00:00",
    "2025-02-08T08:12:31+00:00",
    "2025-02-17T08:41:30+00:00"
  ],
  "abstract": "The latent representation in learned image compression encompasses channel-wise, local spatial, and global spatial correlations, which are essential for the entropy model to capture for conditional entropy minimization. Efficiently capturing these contexts within a single entropy model, especially in high-resolution image coding, presents a challenge due to the computational complexity of existing global context modules. To address this challenge, we propose the Linear Complexity Multi-Reference Entropy Model (MEM$^{++}$). Specifically, the latent representation is partitioned into multiple slices. For channel-wise contexts, previously compressed slices serve as the context for compressing a particular slice. For local contexts, we introduce a shifted-window-based checkerboard attention module. This module ensures linear complexity without sacrificing performance. For global contexts, we propose a linear complexity attention mechanism. It captures global correlations by decomposing the softmax operation, enabling the implicit computation of attention maps from previously decoded slices. Using MEM$^{++}$ as the entropy model, we develop the image compression method MLIC$^{++}$. Extensive experimental results demonstrate that MLIC$^{++}$ achieves state-of-the-art performance, reducing BD-rate by $13.39\\%$ on the Kodak dataset compared to VTM-17.0 in Peak Signal-to-Noise Ratio (PSNR). Furthermore, MLIC$^{++}$ exhibits linear computational complexity and memory consumption with resolution, making it highly suitable for high-resolution image coding. Code and pre-trained models are available at https://github.com/JiangWeibeta/MLIC. Training dataset is available at https://huggingface.co/datasets/Whiteboat/MLIC-Train-100K.",
  "categories": [
    "eess.IV",
    "cs.CV"
  ],
  "primary_category": "eess.IV",
  "doi": "10.1145/3719011",
  "journal_ref": "ACM Trans. Multimedia Comput. Commun. Appl., 21(5), Article 142, May 2025",
  "arxiv_id": "2307.15421",
  "pdf_url": "https://arxiv.org/pdf/2307.15421v11",
  "comment": "Accepted to ICML 2023 Neural Compression Workshop and ACM Transactions on Multimedia Computing, Communications, and Applications 2025",
  "num_versions": null,
  "size_before_bytes": 130769614,
  "size_after_bytes": 5525826
}