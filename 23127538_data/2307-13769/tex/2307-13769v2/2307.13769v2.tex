%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt,reqno]{amsart}

\newcommand\version{August 2, 2023}

%--- Packages ---

\usepackage{amsmath, amsfonts, amsthm, amssymb, amsxtra}
\usepackage{bbm} % to get \1
\usepackage{hyperref}
\usepackage{xcolor}

%--- Page structure ---

%\addtolength{\hoffset}{-2cm}
%\addtolength{\textwidth}{4cm}

\renewcommand{\baselinestretch}{1.1}
\setlength{\voffset}{-.7truein}
\setlength{\textheight}{8.8truein}
\setlength{\textwidth}{6.05truein}
\setlength{\hoffset}{-.7truein}

%--- Theorem structure ---

\newtheorem{theorem}{Theorem}%[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}

\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}

\theoremstyle{remark}

\newtheorem{remark}[theorem]{Remark}
\newtheorem{remarks}[theorem]{Remarks}

%--- Settings ---

%\numberwithin{equation}{section}

%--- Commands and math operators ---

\newcommand{\1}{\mathbbm{1}}
\newcommand{\A}{\mathbf{A}}
\newcommand{\B}{\mathfrak{B}}
\newcommand{\ball}{B}
\newcommand{\C}{\mathbb{C}}
\newcommand{\cl}{\mathrm{cl}}
\newcommand{\const}{\mathrm{const}\ }
\newcommand{\D}{\mathcal{D}}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\I}{\mathbb{I}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\loc}{{\rm loc}}
\newcommand{\mg}{\mathrm{mag}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\ope}{\mathrm{op}}
\renewcommand{\phi}{\varphi}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rp}{\text{Re\,}}
\newcommand{\Sph}{\mathbb{S}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\w}{\mathrm{weak}}
\newcommand{\Z}{\mathbb{Z}}

\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\Div}{div}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\re}{Re}
\DeclareMathOperator{\spa}{span}
\DeclareMathOperator{\spec}{spec}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\tr}{Tr}

\newcommand{\ryan}[1]{{\color{cyan} #1}}
\newcommand{\notes}[1]{{\color{red} #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title[Minimizers for an aggregation model --- \version]{Minimizers for an aggregation model\\ with attractive--repulsive interaction}

\author{Rupert L. Frank}
\address[Rupert L. Frank]{Mathe\-matisches Institut, Ludwig-Maximilans Universit\"at M\"unchen, The\-resienstr.~39, 80333 M\"unchen, Germany, and Munich Center for Quantum Science and Technology, Schel\-ling\-str.~4, 80799 M\"unchen, Germany, and Mathematics 253-37, Caltech, Pasa\-de\-na, CA 91125, USA}
\email{r.frank@lmu.de}

\author{Ryan W. Matzke}
\address[Ryan W. Matzke]{Department of Mathematics, Vanderbilt University, 1326 Stevenson Center, Station B 407807, Nashville, TN 37240, USA}
\email{ryan.w.matzke@vanderbilt.edu}

\thanks{\copyright\, 2023 by the authors. This paper may be reproduced, in its entirety, for non-commercial purposes.\\
	Partial support through US National Science Foundation grant DMS-1954995, as well as through the Deutsche Forschungsgemeinschaft Excellence Strategy EXC-2111-390814868 is acknowledged. R.W.M. is supported by NSF Postdoctoral Fellowship Grant 2202877.}


\begin{abstract}
	We solve explicitly a certain minimization problem for probability measures involving an interaction energy that is repulsive at short distances and attractive at large distances. We complement earlier works by showing that in part of the remaining parameter regime all minimizers are uniform distributions on a surface of a sphere, thus showing concentration on a lower dimensional set. Our method of proof uses convexity estimates on hypergeometric functions.
\end{abstract}

\maketitle

\section{Introduction and main result}

We are interested in a specific minimization problem that arises in mathematical biology, mathematical physics, and economics as a toy model for aggregation. It is a mean-field model of particles, or individuals, interacting through a pair potential, whose resulting force is repulsive for short distances and attractive for long distances. The short range repulsion restricts the collision of particles and the long range attraction penalizes dissociation into smaller groups. Therefore, one expects the interaction energy to achieve its minimal value in a certain state, and one interprets this as an example of self-organization and pattern formation. These phenomena have received a lot of interest in the mathematics literature in recent years and we provide references later on in this introduction.

For the specific model at hand, we ask a much more detailed question, namely we would like to determine explicitly the states of minimal energy. The model depends on two parameters related to the nature of the repulsive/attractive forces, and the characterization of minimal energy states has previously been achieved for a certain range of these parameters. Our contribution in this paper is enlarge this regime where the states of minimal energy are known.

Let us now introduce the model and present our results.  We work in spatial dimension $d\geq 1$ and denote by $P(\R^d)$ the set of Borel probability measures on $\R^d$. For parameters $-d<\beta<\alpha<\infty$ we consider the following functional, defined for $\mu\in P(\R^d)$,
$$
\mathcal E_{\alpha,\beta}[\mu] :=
	\frac12 \iint_{\R^d\times\R^d} \left( \alpha^{-1}|x-y|^\alpha - \beta^{-1}|x-y|^\beta \right) d\mu(x)\,d\mu(y) \,.
$$
Here we use the convention to interpret $\gamma^{-1}|x-y|^\gamma$ for $\gamma=0$ as $\ln |x-y|$. The minimization problem we are interested in is
$$
E_{\alpha,\beta} := \inf\left\{ \mathcal E_{\alpha,\beta}[\mu] :\ \mu\in P(\R^d) \right\}.
$$

It will be convenient to introduce a number $R_{\alpha,\beta}$ for $\frac{-10+3\alpha+7d-\alpha d- d^2}{d+\alpha-3}\leq\beta<\alpha$ by
\begin{equation}
	\label{eq:defr1}
	R_{\alpha,\beta} :=
	\frac12 \left( \frac{\Gamma(\frac{d+\beta-1}{2})\, \Gamma(\frac{2d+\alpha-2}{2})}{\Gamma(\frac{d+\alpha-1}{2})\, \Gamma(\frac{2d+\beta-2}{2})} \right)^\frac{1}{\alpha-\beta}
\end{equation}
and for $\alpha=2$ and $-d<\beta<-d+4$ by
\begin{equation}
	\label{eq:defr2}
	R_{2,\beta} :=
	\left( \frac{\Gamma(\frac{4-\beta}2)\,\Gamma(\frac{\beta+d}{2})}{\Gamma(1+\frac d2)} \right)^\frac{1}{2-\beta}.
\end{equation}

The following is our main result.

\begin{theorem}\label{main1}
	Let $d\geq2$, $2\leq\alpha\leq 4$ and $-d+4\leq\beta\leq 2$ with $\beta<\alpha$. Then
	$$
	E_{\alpha,\beta} = 
	\begin{cases}
		- \pi^{-\frac12} \, 2^{d+\alpha-3}\, \frac{\Gamma(\frac d2)\,\Gamma(\frac{d+\alpha-1}{2})}{\Gamma(\frac{2d+\alpha-2}{2})} \left( \frac1\beta - \frac1\alpha \right) R_{\alpha,\beta}^\alpha 
		& \text{if}\ \beta\neq 0 \,,\\
		\frac1{2\alpha}\left( 1 - \ln \frac{\Gamma(\frac{d-1}2)\,\Gamma(\frac{2d+\alpha-2}{2})}{\Gamma(d-1)\,\Gamma(\frac{d+\alpha-1}{2})} \right) + \frac14 \left( \frac{\Gamma'(d-1)}{\Gamma(d-1)} - \frac{\Gamma'(\frac{d-1}{2})}{\Gamma(\frac{d-1}{2})} \right) & \text{if}\ \beta =0 \,.
	\end{cases}
	$$
	The infimum is attained if and, provided $(\alpha,\beta)\neq (4,2)$, only if, for some $a\in\R^d$,
	$$
	\mu = (|\Sph^{d-1}|R_{\alpha,\beta}^{d-1})^{-1}\ \delta_{\partial B_{R_{\alpha,\beta}}(a)} \,.
	$$
\end{theorem}

We believe that this result is new, except in the limiting cases $\alpha=2$ and/or $\beta=-d+4$, for which we provide references after the next theorem. There the optimizers in the case $(\alpha,\beta)=(4,2)$, which we have excluded, are characterized as well.

We use the method of proof of Theorem \ref{main} to give an alternative proof of the following known result.

\begin{theorem}\label{main}
	Let $d\geq 1$, $\alpha=2$ and $-d<\beta<-d+4$ with $\beta<\alpha$.
	Then
	$$
	E_{2,\beta} = 
	\begin{cases}
		- \frac{d (2-\beta)}{2\beta(4-\beta)} \, R_{2,\beta}^2 & \text{if}\ \beta\neq 0 \,,\\
		\frac14\left( \frac12 + \ln\frac d2 + \frac{\Gamma'(2)}{\Gamma(2)} - \frac{\Gamma'(\frac d2)}{\Gamma(\frac d2)} \right) & \text{if} \ \beta = 0 \,.
	\end{cases}
	$$
	The infimum is attained if and only if, for some $a\in\R^d$,
	$$
	d\mu(x) = C_\beta^{-1} \ R_{2,\beta}^{\beta-2} \ (R_{2,\beta}^2 - |x-a|^2)^{\frac{2-\beta-d}2} \ \1_{B_{R_{2,\beta}}(a)}(x)\,dx
	$$
	with
	\begin{equation}
		\label{eq:defca}
		C_\beta := \pi^\frac d2\, \frac{\Gamma(\frac{4-\beta-d}{2})}{\Gamma(\frac{4-\beta}{2})} \,.
	\end{equation}
\end{theorem}

\begin{remarks}\label{mainrem}
	(a) Here are the references for Theorem \ref{main}. The result in the case $\beta=-d+2$ of Coulomb repulsion is folklore. The result for $-d<\beta<-d+2$ can be extracted from the analysis of the porous medium equation with fractional diffusion by Caffarelli and V\`azquez \cite{CaVa}; for the case $d=1$, see also \cite{Fr1}. The result for $-d+2<\beta<\min\{-d+4,2\}$ is due to Carrillo and Shu \cite[Theorem 5.1]{CaSh1}.\\
	(b) The limiting case $\beta=-d+4$ of Theorem \ref{main1} has been addressed before. Specifically, in \cite[Theorem 5.8]{CaSh1} Carrillo and Shu sketch how their method of proof dealing with the regime $-d+2<\beta<\min\{-d+4,2\}$ allows them to handle the limiting case $\beta=-d+4$ for $d>2$. As far as we understand, this method does not extend to $\beta>-d+4$. In particular, we point out that the statement below \cite[(2.4)]{DaLiMC1} to the effect that the case $-d+4<\beta<2$ is solved in \cite{CaSh1} is incorrect, as confirmed by the authors of \cite{DaLiMC1} in personal communication.\\
	(c) The limiting case $\beta=2$ of Theorem \ref{main1} has been addressed before. Indeed, the minimization problem $E_{\alpha,2}$ with $\beta=2$ was completely solved in two papers \cite{DaLiMC1,DaLiMC2} by Davies, Lim, and McCann; see also \cite{Fr1} for the case $2<\alpha<3$ in $d=1$. Besides the result stated in Theorem \ref{main1} in this case, it is shown in these papers that for $\alpha>4$ in $d\geq 2$, minimizers are uniform distributions on the vertices of a regular simplex, while for $\alpha=4$ in $d\geq2$ there is a large family of minimizers. The papers \cite{DaLiMC1,DaLiMC2} also contain partial results for $\beta\neq 2$.\\
	(d) For $\alpha=2$, as the parameter $\beta$ increases, one sees a transition from probability measures that are absolutely continuous with respect to Lebesgue measure with bounded density (for $-d < \beta\leq-d+2$) to such with unbounded density (for $-d+2<\beta<-d+4$) and further, if $d\geq 3$, to a singular measure, namely uniform measure on the surface of a sphere (for $-d+4\leq\beta<2$). A similar transition is expected for any fixed $2\leq\alpha\leq 4$, but with possibly different transition points in place of $-d+2$ and $-d+4$. One can observe a similar transition to more and more singular measures if one fixes $\beta=2$ and lets $\alpha$ increase; see item (c).\\
	(e) A very brief comment on the proof: using the positive definiteness of the kernel $|x-y|^{-\gamma}$ for $\gamma\leq 0$ (or conditional negative definiteness for $\gamma\leq 2$), as well as a certain conditional positive definiteness for $2\leq\gamma\leq 4$, we see that it is enough to find a solution of the Euler--Lagrange relations. These state that the potential of the relevant measure is constant on the support of the measure and attains its minimum there. Verifying that the potential is constant on the support of the measure is relatively easy in our situation. The difficulty is to show that the potential is at least as large as the constant outside the support. Our starting point to solve this is to express the potential as a hypergeometric function. This reduces matters to proving a convexity inequality for hypergeometric functions. In the one-dimensional case in \cite{Fr0} this was relatively straightforward consequence of an integral representation formula for hypergeometric functions. In the present situation, however, we are outside the range of validity of this integral representation. We will show that one can obtain the desired inequality by repeated differentiation. While hypergeometric functions are a classical topic, we have not been able to find this result in the literature. We hope that our result will be relevant in other situations as well.
\end{remarks}

Let us now put the model we are studying into perspective. From a very wide perspective, it is a mean-field model for the distribution of particles/individuals that interact via forces that have both attractive and repulsive components, and one would like to find a minimizing probability measure for the corresponding energy functional. Some models of this type are reviewed in \cite{Fr0}. More specifically, in the present context the only term in the energy functional is a pair interaction, described by a certain potential $W$, and consequently the energy is of the form
$$
\frac12 \iint_{\R^d\times\R^d} W(x-y) \,d\mu(x)\,d\mu(y) \,.
$$
We refer, for instance, to the introduction of \cite{BaCaLaRa} for a large number of references of where such models appear in biology and physics. Often, there seems to be no canonical choice for the interaction potential $W$ and one direction of investigation is to understand how sensitive the qualitative behavior of minimizers is to changes in $W$. Another line of research is to understand this behavior for some toy potentials. A frequently used choice is the family $W_{\alpha,\beta}(z) = \alpha^{-1} |z|^\alpha - \beta |z|^\beta$ for $\alpha>\beta$, where one would like to understand a `phase diagram' in the $(\alpha,\beta)$-plane. This is the model studied in this paper.

Qualitative and quantitative properties of minimizers that one would like to understand are its absolute continuity with respect to Lebesgue measure \cite{CaDeMe} or the dimensionality of the support \cite{BaCaLaRa1,CaFiPa,CaSh1,DaLiMC1,DaLiMC2}. Despite some significant progress in these works, the dimensionality of minimizers seems to be still unknown in a large part of the $(\alpha,\beta)$-plane. We also emphasize that numerical experiments \cite[Table 4]{BaCaLaRa1} suggest that the dimensionality is unstable under perturbations and can decrease. The same may occur for nonradial interaction kernels $W$, as was recently explored in several works; see, e.g., \cite{MoRoSc,CaMaMoRoScVe,CaMaMoRoScVe2,CaSh2,CaSh3,MaMoRoScVe}.

We should also mention that the corresponding time-dependent equation
$$
\frac{\partial\mu}{\partial t} = \Div(\mu(\nabla W*\mu)) \,,
$$
which is formally the Wasserstein-2 gradient flow of the energy functional, has been intensely studied. For instance, in \cite{BaCaLaRa} the measures appearing in Theorem \ref{main1} were identified as steady states of the this time-dependent problem and their stability was investigated. Similarly, the functions in Theorem \ref{main} were identified as steady states in \cite{CaHu}. We recall that being a steady state means, essentially, that the potential is constant on the support of the measure. For being a global minimizer it is necessary (and, as we will see in Lemma~\ref{riesz}, also sufficient) that, apart from this constancy, the potential as at least as big as this constant outside of the support of the measure. It is this latter condition that is responsible for the technical work in this paper.

\subsection*{Acknowledgements}

The authors are grateful to D.~Bilyk, J.~A.~Carrillo, D.~Chafa\"{i}, C.~Davies, T.~Lim, J.~Mateu, R.~McCann, E.~B.~Saff, J.~Verdera, M.~Vu, and R.~Womersley for several discussions, correspondences, and help with references during the process of working on this problem.

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Background: Some facts about hypergeometric functions}\label{Sec:Hypergeom facts}

In the proof of our main theorems, the potentials
$$
\int_{\R^d} \left( \alpha^{-1} |x-y|^\alpha - \beta^{-1} |x-y|^\beta \right)d\mu(y) \,,
$$
of the candidate minimizers $\mu$ will play an important role. To deduce properties of these potentials, we will express them in terms of hypergeometric functions and then prove and apply results for those.

This section is meant to recall the definition and properties of hypergeometric functions and prove some that we have not been able to find in the literature. They will be crucial in the proof of our main theorems.

We restrict ourselves to parameters $a,b\in\R$ and $c\in\R\setminus(-\N_0)$ and consider the hypergeometric series \cite[(9.100)]{GrRy}
$$
F(a,b;c;z) = \sum_{n=0}^\infty \frac{a(a+1)\cdots(a+n-1)}{c(c+1)\cdots(c+n-1)}\,\frac{b(b+1)\cdots(b+n-1)}{1\cdot 2\cdots (n-1)}\, z^n \,.
$$
Here $\lambda(\lambda+1)\cdots(\lambda+n-1)$ is interpreted as $1$ if $n=0$. By standard facts about power series, this converges absolutely and uniformly on compact subsets of $\{z\in\C:\ |z|<1\}$ and defines an analytic function in the open unit disc. We will only be interested in values $z\in[0,1)$.

We first summarize some facts about its boundary behavior as $z\to 1^-$.

\begin{lemma}\label{hypercont}
	Let $a,b\in\R$, $c\in\R\setminus(-\N_0)$ with $c-a-b>0$.
	\begin{itemize}
		\item[(a)] The functions $[0,1)\ni z\mapsto F(a,b;c;z)$ and $(1,\infty)\ni z\mapsto z^{-a} F(a,b;c;z^{-1})$ extend continuously to $z=1$ with
		\begin{equation}\label{eq:hyperone}
			F(a,b;c;1) = \frac{\Gamma(c)\,\Gamma(c-a-b)}{\Gamma(c-a)\,\Gamma(c-b)} \,.
		\end{equation}
		\item[(b)] If $c-a-b>1$, then their derivatives extend continuously to $z=1$ with
		\begin{equation}\label{eq:hyperoneder}
			\frac{d}{dz}\Big|_{z=1}F(a,b;c;z) = ab\ \frac{\Gamma(c)\,\Gamma(c-a-b-1)}{\Gamma(c-a)\,\Gamma(c-b)}
		\end{equation}
		and
		\begin{equation}\label{eq:hyperonedermod}
			\frac{d}{dz}\Big|_{z=1}\left( z^{-a} F(a,b;c;z^{-1})\right) = -a\
			\frac{\Gamma(c)\,\Gamma(c-a-b-1)}{\Gamma(c-a-1)\,\Gamma(c-b)} \,.
		\end{equation}
	\end{itemize}
\end{lemma}


\begin{proof}
	It is well known (see, e.g., \cite[(9.102)]{GrRy}) that the hypergeometric series converges on the boundary of the unit disc if $c-a-b>0$. Its value at 1, given in \eqref{eq:hyperone}, can be found in \cite[(9.122.1)]{GrRy}. This proves part (a).
	
	Directly from the definition of the hypergeometric series we find that
	\begin{equation}
		\label{eq:hyperder}
		\frac d{dz} F(a,b;c;z) = \frac{ab}{c}\, F(a+1,b+1;c+1;z) \,.
	\end{equation}
	Therefore the facts about the derivative of the first function follow from the same facts as for the function itself. For the second function we note that
	\begin{equation}
		\label{eq:hyperdermod}
		\frac{d}{dz}\left( z^{-a} F(a,b;c;z^{-1})\right) = -a z^{-a-1} F(a+1,b;c;z^{-1}) \,.
	\end{equation}
	This follows easily from \cite[(15.2.3)]{AbSt}. Therefore the facts about the derivative of the second function follow again from the same facts as for the function itself. This proves part~(b).
\end{proof}

The following lemma and its corollary are the crucial facts needed for the proof of our main results. The important point is that they are proved for parameters $b$ that can be arbitrarily negative.

\begin{lemma}\label{hyperpos}
	Let $a,b\in\R$ and $c>0$ such that $c\geq\max\{a,b\}$. Then $F(a,b;c;z)\geq 0$ for all $z\in[0,1)$.
\end{lemma}

\begin{proof}
	By continuity with respect to $c$ we may assume that $c>\max\{a,b\}$. First assume that $b>0$. Then the assertion follows from the integral representation \cite[(9.111)]{GrRy}
	\begin{equation}
		\label{eq:intrephyper}
		F(a,b;c;z) = \frac{\Gamma(c)}{\Gamma(b)\,\Gamma(c-b)} \int_0^1 t^{b-1} (1-t)^{c-b-1} (1-tz)^{-a}\,dt \,,
	\end{equation}
	valid for $c>b>0$. Note that for $b>0$ we did not use the assumption $c>a$.
	
	For $b\leq 0$ we write $-\ell\geq b> -\ell-1$ for some $\ell\in\N_0$ and prove the assertion by induction on $\ell$. We can consider the case $\ell=-1$, proved above, as the base case. For the induction step let $\ell\geq 0$. We use the formula \eqref{eq:hyperder} for the derivative of $F(a,b;c;z)$. By induction hypothesis, we have $F(a+1,b+1;c+1;z)\geq 0$. If $a\leq 0$, we have $ab/c\geq 0$ and we deduce $F'(a,b;c;z)\geq 0$. Thus, $F(a,b;c;z)\geq F(a,b;c;0)=1$ for all $z\in[0,1)$. Conversely, if $a>0$, we have $ab/c\leq 0$ and we deduce $F'(a,b;c;z)\leq 0$. Thus, $F(a,b;c;z)\geq F(a,b;c;1)$ for all $z\in[0,1)$. The assertion therefore follows from the formula \eqref{eq:hyperone} for $F(a,b;c;1)$ if one notices that under our assumptions the argument of each one of the four gamma functions is positive. This completes the proof of the lemma.
\end{proof}

\begin{corollary}\label{hypercor}
	Let $a,b\in\R$ and $c>0$ with $c\geq\max\{a,b\}$. The function $[0,1)\ni z\mapsto F(a,b;c;z)$ is 
	$$
	\begin{cases}
		\text{convex} & \text{if}\ a(a+1)b(b+1)\geq 0 \,,\\
		\text{concave} & \text{if}\ a(a+1)b(b+1)\leq 0 \,.
	\end{cases}
	$$
	If, in addition, $c\geq a+2$, then the function $(1,\infty)\ni z\mapsto z^{-a} F(a,b;c;z^{-1})$ is
	$$
	\begin{cases}
		\text{convex} & \text{if}\ a(a+1)\geq 0 \,,\\
		\text{concave} & \text{if}\ a(a+1)\leq 0 \,.
	\end{cases}
	$$
\end{corollary}

\begin{proof}
	According to \eqref{eq:hyperder} and \eqref{eq:hyperdermod}, we have
	$$
	\frac{d^2}{dz^2} F(a,b;c;z) = \frac{a(a+1)b(b+1)}{c(c+1)}\, F(a+2,b+2;c+2;z)
	$$
	and
	$$
	\frac{d^2}{dz^2}\left( z^{-a} F(a,b;c;z^{-1})\right) = a(a+1) z^{-a-2} F(a+2,b;c;z^{-1}) \,.
	$$
	Therefore, the assertion follows from Lemma \ref{hyperpos}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse

\begin{corollary}\label{hypercor2}
	Let $a\in\R$, $b\in\R\setminus(-1,0)$ and $c>0$ with $c\geq\max\{a,b\}$ and $c-a-b>1$. The function
	$$
	\psi: (0,\infty) \to \R \,,
	\qquad z \mapsto
	\begin{cases}
		F(a,b;c;z) & \text{if}\ z\in(0,1) \,,\\
		\frac{\Gamma(c)\,\Gamma(c-a-b)}{\Gamma(c-a)\,\Gamma(c-b)} & \text{if}\ z=1 \,, \\
		z^{-a} F(a,b;c;z^{-1}) & \text{if}\ z\in(1,\infty) \,,
	\end{cases}
	$$
	is
	$$
	\begin{cases}
		\text{convex} & \text{if}\ a(a+1)\geq 0 \qquad \text{and}\qquad ab \leq -a(c-a-1) \,,\\
		\text{concave} & \text{if}\ a(a+1)\leq 0 \qquad \text{and}\qquad ab \geq -a(c-a-1)  \,.
	\end{cases}
	$$
\end{corollary}

\begin{proof}
	It follows from Lemma \ref{hypercont} that $\psi$ is continuous at $z=1$ and has left and right sided derivatives there, which are given by
	$$
	\psi'(1^-) = ab\ \frac{\Gamma(c)\,\Gamma(c-a-b-1)}{\Gamma(c-a)\,\Gamma(c-b)}
	\quad\text{and}\quad
	\psi'(1^+) = -a(c-a-1)\
	\frac{\Gamma(c)\,\Gamma(c-a-b-1)}{\Gamma(c-a)\,\Gamma(c-b)} \,.
	$$
	Here we used the functional equation for the gamma function. Note that under our assumptions on the parameters, we have
	$$
	\frac{\Gamma(c)\,\Gamma(c-a-b-1)}{\Gamma(c-a)\,\Gamma(c-b)} \geq 0 \,.
	$$
	Therefore we have
	$$
	\psi'(1^-) \lesseqgtr \psi'(1^+)
	\qquad\text{if}\ ab \lesseqgtr -a(c-a-1) \,.
	$$
	
	Note that the assumption $b\in\R\setminus(-1,0)$ implies that $b(b+1)\geq 0$. Therefore Corollary \ref{hypercor} implies that on each of the intervals $(0,1)$ and $(1,\infty)$ the function $\psi$ is convex if $a(a+1)\geq 0$ and concave if $a(a+1)\leq 0$. This, together with the monotonicity of the one-sided derivatives at the point 1 implies the assertion.	
\end{proof}

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Potentials as hypergeometric series}

Our goal in the present section is to express the potential of the candidate minimizers in our main theorems in terms of hypergeometric functions, whose definition we recalled in the previous section. We deal separately with the two parts of the potential and write our formulas in terms of a parameter $\gamma$ that will later take the values $\alpha$ or~$\beta$.

\begin{lemma}\label{pothyper2}
	Let $d\geq 2$ and $\gamma\in\R$. Then, for all $x\in\R^d$,
	\begin{align}\label{eq:pothyper2}
		&\int_{\Sph^{d-1}} |x-\omega|^\gamma \,d\omega = 2\, \pi^\frac d2 \frac{1}{\Gamma(\frac d2)} \times 
		\begin{cases}
			|x|^{\gamma} F(-\frac\gamma2,\frac{2-\gamma-d}{2};\frac d2;|x|^{-2}) & \text{if}\ |x|>1 \,,\\
			F(-\frac\gamma2,\frac{2-\gamma-d}{2};\frac d2;|x|^2) & \text{if}\ |x|<1 \,.
		\end{cases}
	\end{align}
\end{lemma}

If $\gamma>-d+1$, then Lemma \ref{hypercont} shows that the right side in \eqref{eq:pothyper2} is continuous at $|x|=1$ and the proof below shows that the identity \eqref{eq:pothyper2} extends to $|x|=1$.

\begin{proof}	
	By introducing polar coordinates, we find
	\begin{align*}
		\int_{\Sph^{d-1}} |x-\omega|^\gamma \,d\omega & = |\Sph^{d-2}| \int_0^\pi \left( |x|^2 - 2 |x|\cos\theta + 1 \right)^{\frac\gamma2} \sin^{d-2}\theta\,d\theta \\
		& = |\Sph^{d-2}| \int_{-1}^1 \left( |x|^2 - 2 |x| t + 1 \right)^{\frac\gamma2} (1-t^2)^\frac{d-3}{2} \,dt \\
		& = 2 |\Sph^{d-2}| (1+|x|)^\gamma \int_0^1 (1- \tfrac{4}{(1+|x|)^2} u)^\frac{\gamma}{2} (1-u)^{\frac{d-3}{2}} u^\frac{d-3}{2}\,du \\
		& = 2 |\Sph^{d-2}| \frac{\Gamma(\frac{d-1}{2})^2}{\Gamma(d-1)}\, (1+|x|)^\gamma \, F(-\tfrac\gamma2,\tfrac{d-1}{2};d-1;\tfrac{4|x|}{(1+|x|)^2}) \,.
	\end{align*}
	Here we have successively changed variables $\cos\theta=\omega\cdot x/|x|$, $t=\cos\theta$ and $u= (1+t)/2$ and used the integral representation of the hypergeometric series \cite[(9.111)]{GrRy}. Inserting the expression for $|\Sph^{d-2}|$, we arrive at
	\begin{equation}
		\label{eq:pothyper2alt}
		\int_{\Sph^{d-1}} |x-\omega|^\gamma \,d\omega = 2\, \pi^\frac d2 \frac{1}{\Gamma(\frac d2)} \, (|x|+1)^\gamma F(-\tfrac{\gamma}{2},\tfrac{d-1}{2};d-1;\tfrac{4|x|}{(|x|+1)^2})
		\qquad\text{if}\ |x|\neq 1 \,.
	\end{equation}
	The claimed formula \eqref{eq:pothyper2} follows from \eqref{eq:pothyper2alt} by a transformation formula for the hypergeometric series; see \cite[(9.134.2)]{GrRy}.	
\end{proof}

Note that in the previous proof we have found an alternative expression for the left side in Lemma \ref{pothyper2}, namely \eqref{eq:pothyper2alt}. While the latter does not involve a case distinction and might be esthetically more pleasing, we have found the formula \eqref{eq:pothyper2} the more useful one for our purposes.

\begin{lemma}\label{pothyper1}
	Let $d\geq 1$ and $-d<\gamma<-d+4$. Then, for all $x\in\R^d$,
	\begin{align}\label{eq:pothyper1}
		& \int_{|y|<1}  |x-y|^\gamma (1-|y|^2)^{\frac{2-\gamma-d}{2}}\,dy = 
		\pi^{\frac d2} \, \frac{\Gamma(\frac{4-\gamma-d}{2})\,\Gamma(\frac{\gamma+d}2)}{\Gamma(\frac d2)} \,
		\times \notag \\
		& \qquad \times
		\begin{cases}
			\frac{\Gamma(\frac d2)}{\Gamma(2-\frac\gamma2) \, \Gamma(\frac{\gamma+d}{2})} \, |x|^{\gamma} F(-\frac\gamma2,\frac{2-\gamma-d}{2};2-\frac\gamma2;|x|^{-2}) & \text{if}\ |x|>1 \,,\\
			F(-\frac\gamma2,-1;\frac d2;|x|^2) & \text{if}\ |x|<1 \,.
		\end{cases}
	\end{align}
\end{lemma}

\begin{proof}
	For fixed $x\in\R^d$, both sides of the claimed formula \eqref{eq:pothyper1} are analytic functions of $\gamma$ in $\{ -d<\re\gamma<-d+4\}$, the restrictions on $\gamma$ coming on the left side of the claimed formula from the local integrability properties of the two factors in the integrand and on the right side from the domain of analyticity of the gamma functions. Consequently, it suffices to prove this formula in the range $-d < \gamma < \min\{ 0, -d+4\}$. In the remainder of this step, we impose these restrictions.
	
	In the proof, we will make repeated use of the following formula for the Fourier transform of a radial function,
	\begin{equation}
		\label{eq:ftfrad}
		(2\pi)^{-\frac d2} \int_{\R^d} f(|\xi|) e^{i\xi\cdot x}\,d\xi = |x|^{-\frac{d-2}{2}} \int_0^\infty k^\frac d2 f(k) J_\frac{d-2}{2}(k|x|)\,dk \,,
	\end{equation}
	where $J_\frac{d-2}{2}$ is the Bessel function of the first kind of order $\frac{d-2}{2}$. As a first consequence of this formula, we obtain
	\begin{align}
		\label{eq:ftmin}
		(1-|x|^2)^{\frac{2-\gamma-d}{2}}\1_{(-1,1)}(|x|) = (2\pi)^{-\frac d2} \, \frac{\Gamma(\frac{4-\gamma-d}{2})}{2^\frac{\gamma+d-2}{2}} \int_{\R^d} |\xi|^{-1+\frac\gamma2} J_{1-\frac\gamma2}(|\xi|) e^{i\xi\cdot x}\,d\xi \,.
	\end{align}
	Indeed, this follows from \eqref{eq:ftfrad} together with \cite[(6.575.1)]{GrRy}, which says that for $\alpha,\beta>0$ and $\re\nu+1>\re\mu>-1$,
	$$
	\int_0^\infty J_{\nu+1}(\alpha t) J_\mu(\beta t) t^{\mu-\nu} \,dt =
	\begin{cases}
		0 & \text{if}\ \alpha<\beta \,,\\
		\frac{1}{2^{\nu-\mu}\Gamma(\nu-\mu+1)}\ \frac{\beta^\mu \, (\alpha^2-\beta^2)^{\nu-\mu}}{\alpha^{\nu+1}} & \text{if}\ \alpha\geq \beta \,.
	\end{cases}
	$$

	Next, under the restrictions $-d<\gamma<0$, we have
	\begin{align}
		\label{eq:ftxalpha}
		|x|^{\gamma} = (2\pi)^{-\frac d2} \, 2^{\gamma+\frac d2} \,\frac{\Gamma(\frac{\gamma+d}2)}{\Gamma(-\frac{\gamma}2)}\, \int_{\R^d} |\xi|^{-d-\gamma} e^{i\xi\cdot x}\,d\xi \,.
	\end{align}
	This is formula is well known. It can also be derived from \cite[(6.561.14)]{GrRy} via \eqref{eq:ftfrad}.
	
	Combining \eqref{eq:ftmin} and \eqref{eq:ftxalpha}, we find that
	$$
	\int_{|y|<1} |x-y|^\gamma (1-|y|^2)^{\frac{2-\gamma-d}{2}}\,dy = 2^{\frac\gamma 2+1} \, \frac{\Gamma(\frac{4-\gamma-d}{2})\,\Gamma(\frac{\gamma+d}2)}{\Gamma(-\frac{\gamma}2)} \int_{\R^d} |\xi|^{-d-1-\frac\gamma2} J_{1-\frac\gamma2}(|\xi|) e^{i\xi\cdot x}\,d\xi \,.
	$$
	Using once again \eqref{eq:ftfrad}, we can rewrite the right side as
	$$
	(2\pi)^{\frac d2} \, 2^{\frac\gamma 2+1} \frac{\Gamma(\frac{4-\gamma-d}{2})\,\Gamma(\frac{\gamma+d}2)}{\Gamma(-\frac{\gamma}2)} |x|^{-\frac{d-2}{2}} \int_0^\infty k^{-\frac{\gamma+d+2}2} J_{1-\frac\gamma 2}(k) J_{\frac{d-2}2}(k|x|)\,dk \,.
	$$
	The formula in the lemma now follows from formulas \cite[(6.574.1) \& (6.574.3)]{GrRy}, which say that
	$$
	\int_0^\infty J_\nu(\alpha t) J_\mu(\beta t) t^{-\lambda}\,dt =
	\begin{cases}
		& \!\!\! \frac{\Gamma(\frac{\nu+\mu-\lambda+1}{2})}{2^\lambda\,\Gamma(\frac{-\nu+\mu+\lambda+1}{2})\,\Gamma(\nu+1)}
		\frac{\alpha^\nu}{\beta^{\nu-\lambda+1}} F(\frac{\nu+\mu-\lambda+1}{2},\frac{\nu-\mu-\lambda+1}{2};\nu+1;\frac{\alpha^2}{\beta^2}) \\
		& \qquad \text{if}\ 0<\alpha<\beta \,,\\
		& \\
		& \!\!\! \frac{\Gamma(\frac{\nu+\mu-\lambda+1}{2})}{2^\lambda\,\Gamma(\frac{\nu-\mu+\lambda+1}{2})\,\Gamma(\mu+1)}
		\frac{\beta^\mu}{\alpha^{\mu-\lambda+1}} F(\frac{\nu+\mu-\lambda+1}{2},\frac{-\nu+\mu-\lambda+1}{2};\mu+1;\frac{\beta^2}{\alpha^2}) \\
		& \qquad \text{if}\ 0<\beta<\alpha \,,
	\end{cases}
	$$
	provided that $\re(\nu+\mu-\lambda+1)>0$ and $\re\lambda>-1$. (Here we corrected two misprints in the second line of the formula, namely, we replaced $\beta^\nu$ by $\beta^\mu$ and we replaced $\Gamma(\nu+1)$ by $\Gamma(\mu+1)$. Indeed, the second line of the formula follows from the first one if one interchanges simultaneously the roles of $\alpha$ and $\beta$ and of $\nu$ and $\mu$.) Note also that the restriction $\re(\nu+\mu-\lambda+1)>0$ is satisfied in our case since $\gamma<0$. This completes the proof of Lemma \ref{pothyper1}.	
\end{proof}

We end this section by noting that Lemma \ref{pothyper2} can alternatively be proved similarly as Lemma~\ref{pothyper1}.

\begin{proof}[Second proof of Lemma \ref{pothyper2}]
	We only sketch the differences to the proof of Lemma \ref{pothyper1}. Again, using analyticity, we restrict ourselves to the range $-d<\gamma<0$.
	
	The role of formula \eqref{eq:ftmin} is played by the formula
	$$
	\delta_{\Sph^{d-1}}(x) = (2\pi)^{-\frac d2} \int_{\R^d} |\xi|^{-\frac{d-2}{2}} J_\frac{d-2}{2}(|\xi|) e^{i\xi\cdot x}\,d\xi \,.
	$$
	This follows by Fourier inversion from the formula \eqref{eq:ftfrad} when $f$ is a delta measure at $k=1$.
	
	Combining this with \eqref{eq:ftxalpha} and \eqref{eq:ftfrad}, we obtain
	$$
	\int_{\Sph^{d-1}} |x-\omega|^\gamma \,d\omega = (2\pi)^\frac d2 2^{\gamma+\frac d2} \frac{\Gamma(\frac{\gamma+d}{2})}{\Gamma(\frac\gamma 2)}\, |x|^{-\frac{d-2}{2}} \int_0^\infty k^{-d-\gamma+1} J_\frac{d-2}{2}(k) J_\frac{d-2}{2}(k|x|)\,dk \,.
	$$
	The claimed formula now follows using the formula for the integral of two Bessel functions with a power function, given in the previous proof.
\end{proof}

If we use \cite[(6.576.2)]{GrRy} for the integral of the product of two Bessel functions instead of the formula given in the proof of Lemma \ref{pothyper1}, we arrive at \eqref{eq:pothyper2alt}.
	
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Convexity}

The Euler--Lagrange equations for our minimization problem say that the potential is constant on the support of the minimizing measure and at least as big outside of this support. A fundamental role in the proof of our main results is played by the following lemma, which says that the necessary conditions for a minimizer are, in fact, sufficient. It is at this point that the assumption $2\leq\alpha\leq 4$ enters.

\begin{lemma}\label{riesz}
	Let $d\geq 1$ and let $-d<\beta\leq 2 \leq \alpha\leq 4$ with $\beta<\alpha$. Assume that there are $\mu\in P(\R^d)$ and $\eta\in\R$ such that
	$$
	\phi_{\alpha,\beta}(x) := \int_{\R^d} \left( \alpha^{-1} |x-y|^\alpha - \beta^{-1} |x-y|^\beta \right)d\mu(y) \,,
	\qquad x\in\R^d \,,
	$$
	satisfies
	\begin{equation*}
		\phi_{\alpha,\beta}\geq \eta
		\quad\text{on}\ \R^d
		\qquad\text{and}\qquad
		\phi_{\alpha,\beta} = \eta
		\quad\text{on}\ \supp\mu \,.
	\end{equation*}
	Then $\mu$ is a minimizer for $E_{\alpha,\beta}$ and $\eta=2E_{\alpha,\beta}$.
	If $(\alpha,\beta)\neq (4,2)$, then $\mu$ is the unique minimizer up to translations.
\end{lemma}

We only sketch the proof, as the details of the argument are similar as in the proof of \cite[Lemma 6]{Fr1}. The fundamental observation is the fact that the Fourier transform of $-\beta^{-1}|z|^{\beta}$ is positive for $-d<\beta<0$ and that its restriction to $\R^d\setminus\{0\}$ is positive for $0\leq\beta<2$. The behavior at the point $0$ is irrelevant since the object that is Fourier transformed is the difference of two probability measures, which has integral zero, and therefore Fourier transform vanishing at the origin. Moreover, we use the fact that the restriction to $\R^d\setminus\{0\}$ of the Fourier transform of $\alpha^{-1}|z|^\alpha$ is positive. As observed by Lopes \cite{Lo}, the behavior at the point $0$ is irrelevant since the argument is applied to the difference of two probability measures with equal center of mass; see \cite[Theorem 27]{CaDeDoFrHo} for an application of this argument. When $(\alpha,\beta)\neq (4,2)$, then at least one of the convexities is strict and we obtain the uniqueness (up to translations) of the minimizer.

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Proof of Theorems \ref{main1} and \ref{main}}

In this section we prove the main results stated in the introduction. 

We rely on Lemma \ref{riesz} and need to verify the conditions given there on the potential of our candidate optimizer. In the setting of Theorem \ref{main1} the condition that the potential is constant on the support of the candidate optimizer is trivially satisfied by radial symmetry. The nontrivial part of the proof is to show that potential is everywhere at least as big as on the support of the measure. This is the main technical work, which relies on our lemmas about hypergeometric functions.

We now present the details.

\begin{proof}[Proof of Theorem \ref{main1}.]
	We assume $d\geq2$, $2\leq\alpha\leq 4$ and $-d+4\leq\beta\leq 2$ with $\alpha>\beta$. We only prove the theorem for $\beta\neq 0$, the case $\beta=0$ being similar.
	
	\medskip
	
	\emph{Step 1.} It is convenient to introduce the function
	$$
	\psi_\gamma(\rho) := 
	\begin{cases}
		\rho^{\frac\gamma2} F(-\frac\gamma2,\frac{2-\gamma-d}{2};\frac d2;\rho^{-1}) & \text{if}\ \rho>1 \,,\\
		F(-\frac\gamma2,\frac{2-\gamma-d}{2};\frac d2;\rho) & \text{if}\ \rho<1 \,.
	\end{cases}
	$$
	Under the assumption $d+\gamma>2$ it follows from Lemma \ref{hypercont}, together with some manipulations of gamma functions, that $\psi_\gamma$, which is originally defined only $[0,\infty)\setminus\{1\}$, extends to a continuously differentiable function on $[0,\infty)$. Moreover, Lemma \ref{hypercont} shows that
	\begin{equation}
		\label{eq:psivalues2}
		\psi_\gamma(1) = \frac{\Gamma(\frac d2)\,\Gamma(d+\gamma-1)}{\Gamma(\frac{d+\gamma}2)\,\Gamma(\frac{2d+\gamma-2}{2})}
		\qquad\text{and}\qquad
		\psi_\gamma'(1) = \frac\gamma2\, \frac{\Gamma(\frac d2)\,\Gamma(d+\gamma-2)}{\Gamma(\frac{d+\gamma-2}2)\,\Gamma(\frac{2d+\gamma-2}{2})} \,.
	\end{equation}
	We will apply this with $\gamma$ equal to $\alpha$ and $\beta$, for which the assumption $d+\gamma>2$ is satisfied.
	
	The functions $\psi_\gamma$ are relevant, since by Lemma \ref{pothyper2} and scaling, we can express the total potential of the measure $(|\Sph^{d-1}| R^{d-1})^{-1} \delta_{\partial B_R(0)}$ as
	\begin{align}\label{eq:totpotmain}
		& |\Sph^{d-1}|^{-1} \int_{\Sph^{d-1}} \left( \alpha^{-1} |x-R\omega|^\alpha - \beta^{-1}|x-R\omega|^\beta \right) d\omega \notag \\
		& \quad = \alpha^{-1} R^{\alpha} \psi_\alpha(|x/R|^2) - \beta^{-1} R^{\beta} \psi_\beta(|x/R|^2) \,.
	\end{align}
	In particular, this total potential is radially symmetric and therefore constant on spheres. We want to choose the radius $R$ of the sphere in such a way that the total potential is minimal at $|x|=R$. The differentiability of $\psi_\gamma$ implies that the total potential is continuously differentiable with respect to $|x|$. Setting its derivative equal to zero, we arrive at the condition
	\begin{equation}
		\label{eq:ralpha2}
		\alpha^{-1} R^\alpha \psi_\alpha'(1) - \beta^{-1} R^\beta \psi_\beta'(1) = 0 \,.
	\end{equation}
	In view of the expression for $\psi_\gamma'(1)$ in \eqref{eq:psivalues2}, we see that this is satisfied if (and only if)
	$$
	R= \left( \frac{\alpha}{\beta} \frac{\psi_\beta'(1)}{\psi_\alpha'(1)} \right)^\frac1{\alpha-\beta}
	= \left( \frac{\Gamma(d+\beta-2)}{\Gamma(d+\alpha-2)} \, 
	\frac{\Gamma(\frac{d+\alpha-2}{2})\,\Gamma(\frac{2d+\alpha-2}{2})}{\Gamma(\frac{d+\beta-2}{2})\,\Gamma(\frac{2d+\beta-2}{2})} \right)^\frac{1}{\alpha-\beta} = R_{\alpha,\beta} \,.
	$$
	For the last equality we recall that $R_{\alpha,\beta}$ was defined in \eqref{eq:defr1}. Moreover, we used the duplication formula for the gamma function.
	
	According to \eqref{eq:totpotmain}, the value of the total potential at $|x|=R_{\alpha,\beta}$ is equal to
	\begin{align*}
		|\Sph^{d-1}|^{-1} \int_{\Sph^{d-1}} \left( \alpha^{-1} |x-R_{\alpha,\beta}\omega|^\alpha - \beta^{-1}|x-R_{\alpha,\beta} \omega|^\beta \right) d\omega \Big|_{|x|=R_{\alpha,\beta}} = \eta
	\end{align*}
	with
	\begin{align*}
		\eta & := \alpha^{-1} R_{\alpha,\beta}^{\alpha} \psi_\alpha(1) - \beta^{-1} R_{\alpha,\beta}^{\beta} \psi_\beta(1) = \left( \alpha^{-1} \psi_\alpha(1) - \beta^{-1} \psi_\beta(1) R_{\alpha,\beta}^{-\alpha+\beta} \right) R_{\alpha,\beta}^\alpha \\
		& = \alpha^{-1} \left( \psi_\alpha(1) - \psi_\beta(1) \frac{\psi_\alpha'(1)}{\psi_\beta'(1)} \right) R_{\alpha,\beta}^\alpha \\
		& = - \pi^{-\frac12} \, 2^{d+\alpha-2}\, \frac{\Gamma(\frac d2)\,\Gamma(\frac{d+\alpha-1}{2})}{\Gamma(\frac{2d+\alpha-2}{2})} \left( \frac1\beta - \frac1\alpha \right) R_{\alpha,\beta}^\alpha \,.
	\end{align*}
	Here we used \eqref{eq:ralpha2}, \eqref{eq:psivalues2} and the duplication formula for the gamma function.
	
	To summarize our discussion so far, we have chosen the radius $R=R_{\alpha,\beta}$ in such a way that the potential has a critical point at $|x|=R_{\alpha,\beta}$. It still remains to be shown that the potential has a global minimum at $|x|=R_{\alpha,\beta}$. Once we have shown this, we can apply Lemma \ref{riesz} and deduce that $(|\Sph^{d-1}| R_\alpha^{d-1})^{-1}\delta_{R_\alpha \Sph^{d-1}}$ is a minimizer and we obtain the value $E_{\alpha,\beta}=\eta/2$ for the minimal energy, which coincides with the value stated in Theorem \ref{main}. If $(\alpha,\beta)\neq(4,2)$, then the lemma also implies that the minimizer is unique up to translations.
	
	\medskip
	
	\emph{Step 2.} 	
	In view of \eqref{eq:totpotmain}, the fact that the total potential has a global minimum at $|x|=R_{\alpha,\beta}$, which is what we still need to show, is equivalent to the inequality
	\begin{align*}
		& \alpha^{-1} R_{\alpha,\beta}^{\alpha} \psi_\alpha(|x/R_{\alpha,\beta}|^2) - \beta^{-1} R_{\alpha,\beta}^{\beta} \psi_\beta(|x/R_{\alpha,\beta}|^2) \\
		& \geq \alpha^{-1} R_{\alpha,\beta}^{\alpha} \psi_\alpha(1) - \beta^{-1} R_{\alpha,\beta}^{\beta} \psi_\beta(1)
		\qquad\text{for all}\ x\in\R^d \,.
	\end{align*}
	This can be simplified to
	$$
	\alpha^{-1} R_{\alpha,\beta}^{\alpha-\beta} \psi_\alpha(\rho) - \beta^{-1} \psi_\beta(\rho) \geq  \alpha^{-1} R_{\alpha,\beta}^{\alpha-\beta} \psi_\alpha(1) - \beta^{-1} \psi_\beta(1)
	\qquad\text{for all}\ \rho>0 \,.
	$$	
	Inserting the relation \eqref{eq:ralpha2} between $R_{\alpha,\beta}$ and $\psi_\beta'(1)/\psi_\alpha'(1)$, this becomes
	$$
	\beta^{-1} \frac{\psi_\beta'(1)}{\psi_\alpha'(1)}\, \psi_\alpha(\rho) - \beta^{-1} \psi_\beta(\rho) \geq \beta^{-1} \frac{\psi_\beta'(1)}{\psi_\alpha'(1)}\, \psi_\alpha(1) - \beta^{-1} \psi_\beta(1)
	\qquad\text{for all}\ \rho>0 \,.
	$$
	To prove the latter inequality, we will show that the function 
	\begin{equation}
		\label{eq:goalconvex}
		\rho\mapsto \beta^{-1} \frac{\psi_\beta'(1)}{\psi_\alpha'(1)}\, \psi_\alpha(\rho) - \beta^{-1} \psi_\beta(\rho)
	\end{equation}
	is convex on $(0,\infty)$. Since the function is differentiable at $\rho=1$ and has vanishing derivative there, this will prove the desired inequality.
	
	It follows from Corollary \ref{hypercor} that $\beta^{-1}\psi_\beta$ is concave and $\psi_\alpha$ is convex on each one of the two intervals $(0,1)$ and $(1,\infty)$. (Note that the inequality $\beta\geq-d+4$ guarantees the assumption $c\geq a+2$ of the corollary.) Since the derivatives of both functions extend continuously to the point $\rho=1$, we deduce that both functions have the respective concavity and convexity properties on all of $(0,\infty)$. Moreover, since, according to \eqref{eq:psivalues2}, $\beta^{-1}\psi_\beta'(1)\geq 0$ and $\psi_\alpha'(1)>0$, we obtain the claimed convexity of the function \eqref{eq:goalconvex}. This concludes the proof of Theorem \ref{main1}.
\end{proof}

We now proceed to the proof of Theorem \ref{main}. The overall strategy is the same as in the proof of Theorem \ref{main1}. We briefly outline it. We note that the $\beta$-part of the potential in \eqref{eq:pothyper1} (with $\gamma=\beta$) inside the support of the candidate minimizer is given by a hypergeometric function whose second index equals $-1$, which means that the hypergeometric function is an affine-linear function. In other words, the $\beta$-potential inside the support is a constant plus another constant times $|x|^2$. Clearly the contribution to the total potential coming from the quadratic, i.e. $\alpha=2$, part is of the same form. By an appropriate scaling one can arrange that the coefficients of $|x|^2$ cancel each other, so that the total potential is constant on the support of the candidate minimizer. It remains to show that the potential is everywhere at least as big as on the support of the measure. This is again the main technical work, which we deduce from our lemmas about hypergeometric functions.

\begin{proof}[Proof of Theorem \ref{main}]
	We assume $-d<\beta<\min\{-d+4,2\}$. Also, we only prove the theorem for $\beta\neq 0$, the case $\beta=0$ being similar.
	
	Our starting point is an expression for the total potential. We denote the $\beta$-part of the potential by
	$$
	\Phi(x) = - \beta^{-1} \int_{|y|<1} |x-y|^\beta(1-|y|^2)^{\frac{2-\beta-d}{2}}\,dy
	$$
	and recall that we have obtained an expression for this in Lemma \ref{pothyper1}. To compute the part of the total potential coming from $|x-y|^2$, we recall the definition \eqref{eq:defca} of $C_\beta$. Expressing a beta function in terms of gamma functions, we find
	\begin{align*}
		& \int_{|y|<1} (1-|y|^2)^\frac{2-\beta-d}{2}\,dy = |\Sph^{d-1}| \int_0^1 (1-r^2)^{\frac{2-\beta-d}{2}} r^{d-1}\,dr \\
		& \quad = 2^{-1} |\Sph^{d-1}| \int_0^1 (1-t)^{\frac{2-\beta-d}{2}} t^{\frac{d-2}2}\,dt 
		= 2^{-1} |\Sph^{d-1}| \, \frac{\Gamma(\frac d2)\,\Gamma(\frac{4-\beta-d}{2})}{\Gamma(\frac{4-\beta}{2})} 
		= \pi^\frac d2\, \frac{\Gamma(\frac{4-\beta-d}{2})}{\Gamma(\frac{4-\beta}{2})} \\
		& \quad = C_\beta
	\end{align*}
	and, similarly,
	$$
	\int_{|y|<1} |y|^2 (1-|y|^2)^\frac{2-\beta-d}{2}\,dy = \pi^\frac d2\, \frac d2\ \frac{\Gamma(\frac{4-\beta-d}{2})}{\Gamma(\frac{6-\beta}{2})} = \frac{ d}{4-\beta} \, C_\beta \,.
	$$
	Thus,
	$$
	2^{-1} \int_{|y|<1} |x-y|^2(1-|y|^2)^{\frac{2-\beta-d}{2}}\,dy = 2^{-1} C_\beta \left( |x|^2 + \frac{d}{4-\beta} \right).
	$$
	
	It follows by scaling that
	\begin{align*}
		& \int_{|y|<R} \left( -\beta^{-1} |x-y|^\beta + 2^{-1}|x-y|^2\right) (R^2-|y|^2)^\frac{2-\beta-d}{2}\,dy \\
		& = R^2 \Phi(x/R) + 2^{-1} C_\beta R^{4-\beta} \left( |x/R|^2 + \frac{d}{4-\beta} \right).
	\end{align*}
	Since $F(a,-1;c;z)=1- (a/c) z$, it follows from Lemma \ref{pothyper1} that
	\begin{align*}
		\Phi(x) & = - \beta^{-1} \pi^{\frac d2} \, \frac{\Gamma(\frac{4-\beta-d}{2})\,\Gamma(\frac{\beta+d}2)}{\Gamma(\frac d2)} \left( 1 + \frac{\beta}{d}\,|x|^2\right) \\
		& = - 2^{-1} C_\beta R_{2,\beta}^{2-\beta} \left( \frac{d}{\beta} + |x|^2 \right)
		\qquad\qquad\qquad\text{if}\ |x|<1 \,.
	\end{align*}
	Here we have used the definition of $R_{2,\beta}$ from \eqref{eq:defr2}. We now see that with the choice $R=R_{2,\beta}$ the coefficient in front of $|x|^2$ vanishes and we have
	\begin{align*}
		& \int_{|y|<R_{2,\beta}} \left( -\beta^{-1} |x-y|^\beta + 2^{-1}|x-y|^2\right) (R_{2,\beta}^2-|y|^2)^\frac{2-\beta-d}{2}\,dy \\
		& = - 2^{-1} C_\beta R_{2,\beta}^{4-\beta} \frac{d}{\beta} + 2^{-1} \frac{d}{4-\beta}  C_\beta R_{2,\beta}^{4-\beta} 
		= - C_\beta R_{2,\beta}^{4-\beta} \frac{d(2-\beta)}{\beta(4-\beta)}
		\qquad\text{if}\ |x|<R_{2,\beta} \,.
	\end{align*}
	Therefore $d\mu(x) = C_\beta^{-1} R_{2,\beta}^{-2+\beta} (R_{2,\beta}^2-|x|^2)^\frac{2-\beta-d}{2}\,dx$ is a probability measure that satisfies the second condition in Lemma \ref{riesz} with
	$$
	\eta = - R_{2,\beta}^2 \frac{d(2-\beta)}{\beta(4-\beta)} \,.
	$$
	The task is now to show that the first condition in the lemma is satisfied as well, namely that the total potential of $\mu$ is $\geq\eta$ for $|x|\geq R_{2,\beta}$. Once this is shown, we infer from the lemma that $\mu$ is the unique (up to translations) minimizer and we obtain the value for the minimal energy stated in Theorem \ref{main}.
	
	At this point it is convenient to introduce the function
	$$
	\psi(\rho) := 
	\begin{cases}
		\frac{\Gamma(\frac d2)}{\Gamma(2-\frac\beta2) \, \Gamma(\frac{\beta+d}{2})} \, \rho^{\frac\beta2} F(-\frac\beta2,\frac{2-\beta-d}{2};2-\frac\beta2;\rho^{-1}) & \text{if}\ \rho>1 \,,\\
		F(-\frac\beta2,-1;\frac d2;\rho) & \text{if}\ \rho<1 \,.
	\end{cases}
	$$
	In terms of this function, we can rewrite Lemma \ref{pothyper1} as
	$$
	\Phi(x) = -\beta^{-1} \pi^{\frac d2} \, \frac{\Gamma(\frac{4-\beta-d}{2})\,\Gamma(\frac{\beta+d}2)}{\Gamma(\frac d2)} \, \psi(|x|^2) \,.
	$$
	Using some straightforward manipulations with gamma functions, we deduce from Lemma \ref{hypercont} that $\psi$, which is originally defined only in $[0,\infty)\setminus\{1\}$, extends to a continuously differentiable function on $[0,\infty)$. This continuous differentiability, together with the fact that $\psi$ is affine-linear in $(0,1)$, implies that $F(-\frac\beta2,-1;\frac d2;\rho) = \psi(1) + \psi'(1)(\rho-1)$. This allows us to write, for all $x\in\R^d$,
	\begin{align*}
		& \int_{|y|<R_{2,\beta}} \left( -\beta^{-1} |x-y|^\beta + 2^{-1}|x-y|^2\right) (R_{2,\beta}^2-|y|^2)^\frac{2-\beta-d}{2}\,dy \\
		& = - C_\beta R_{2,\beta}^{4-\beta} \frac{d(2-\beta)}{\beta(4-\beta)} \\
		& \quad - \beta^{-1} \pi^{\frac d2} \, \frac{\Gamma(\frac{4-\beta-d}{2})\,\Gamma(\frac{\beta+d}2)}{\Gamma(\frac d2)} 
		\left( \psi(|x/R_{2,\beta}|^2) - \psi(1) - \psi'(1) (|x/R_{2,\beta}|^2 - 1) \right).
	\end{align*}
	The desired inequality for the total potential is therefore equivalent to the inequality
	$$
	-\beta^{-1} \left( \psi(\rho) - \psi(1) - \psi'(1)(\rho-1) \right) \geq 0
	\qquad\text{for all}\ \rho\geq 1 \,.
	$$
	This inequality is a consequence of the convexity of $\psi$ for $\beta<0$ and its concavity for $\beta\in(0,1)$, which we have shown in Corollary \ref{hypercor}. This completes the proof of part (a) of Theorem \ref{main}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{amsalpha}

\begin{thebibliography}{21}

\bibitem{AbSt} M. Abramowitz, I. A. Stegun, \textit{Handbook of mathematical functions with formulas, graphs, and mathematical tables}. National Bureau of Standards Applied Mathematics Series, No. 55 U. S. Government Printing Office, Washington, D.C., 1964

\bibitem{BaCaLaRa} D. Balagu\'e, J. A. Carrillo, T. Laurent, G. Raoul, \textit{Nonlocal interactions by repulsive-attractive potentials: radial ins/stability}. Phys. D \textbf{260} (2013), 5--25.

\bibitem{BaCaLaRa1} D. Balagu\'e, J. A. Carrillo, T. Laurent, G. Raoul, \textit{Dimensionality of local minimizers of the interaction energy}. Arch. Ration. Mech. Anal. \textbf{209} (2013), no. 3, 1055--1088.

\bibitem{CaVa} L. A. Caffarelli, J. L. V\'azquez, \textit{Asymptotic behaviour of a porous medium equation with fractional diffusion}. Discrete Contin. Dyn. Syst. \textbf{29} (2011), no. 4, 1393--1404.

\bibitem{CaDeDoFrHo} J. A. Carrillo, M. G. Delgadino, J. Dolbeault, R. L. Frank, F. Hoffmann, \textit{Reverse Hardy--Littlewood--Sobolev inequalities}. J. Math. Pures Appl. (9) \textbf{132} (2019), 133--165.

\bibitem{CaDeMe} J. A. Carrillo, M. G. Delgadino, A. Mellet, \textit{Regularity of local minimizers of the interaction energy via obstacle problems}. Comm. Math. Phys. \textbf{343} (2016), no. 3, 747--781.

\bibitem{CaFiPa} J. A. Carrillo, A. Figalli, F. S. Patacchini, \textit{Geometry of minimizers for the interaction energy with mildly repulsive potentials}. Ann. Inst. H. Poincar\'e C Anal. Non Lin\'eaire \textbf{34} (2017), no. 5, 1299--1308. 

\bibitem{CaHu} J. A. Carrillo, Y. Huang, \textit{Explicit equilibrium solutions for the aggregation equation with power-law potentials}. Kinet. Relat. Models \textbf{10} (2017), no. 1, 171--192.

\bibitem{CaMaMoRoScVe} J. A. Carrillo, J. Mateu, M. G. Mora, L. Rondi, L. Scardia, J. Verdera, \textit{The ellipse law: Kirchhoff meets dislocations}. Comm. Math. Phys. \textbf{373} (2020), no. 2, 507--524.

\bibitem{CaMaMoRoScVe2} J. A. Carrillo, J. Mateu, M. G. Mora, L. Rondi, L. Scardia, J. Verdera, \textit{The equilibrium measure for an anisotropic nonlocal energy}. Calc. Var. Partial Differential Equations \textbf{60} (2021), no. 3, Paper No. 109, 28 pp.

\bibitem{CaSh1} J. A. Carrillo, R. Shu, \textit{From radial symmetry to fractal behavior of aggregation equilibria for repulsive-attractive potentials}.  Calc. Var. Partial Differential Equations \textbf{62} (2023), no. 1, Paper No. 28, 61 pp.

\bibitem{CaSh2} J. A. Carrillo, R. Shu, \textit{Global minimizers of a large class of anisotropic attractive-repulsive interaction energies in 2D}. Preprint (2022), arXiv:2202.09237.

\bibitem{CaSh3} J. A. Carrillo, R. Shu, \textit{Minimizers of 3D anisotropic interaction energies}. Preprint (2022), arXiv:2206.14054.

\bibitem{DaLiMC1} C. Davies, T. Lim, R. McCann, \textit{Classifying minimum energy states for interacting particles: spherical shells}. SIAM J. Appl. Math. \textbf{82} (2022), no. 4, 1520--1536.

\bibitem{DaLiMC2} C. Davies, T. Lim, R. McCann, \textit{Classifying minimum energy states for interacting particles: regular simplices}. Comm. Math. Phys. \textbf{399} (2023), no. 2, 577--598.

\bibitem{Fr0} R. L. Frank, \textit{Some minimization problems for mean field models with competing forces}. Preprint (2021), arXiv:2109.02393.

\bibitem{Fr1} R. L. Frank, \textit{Minimizers for a one-dimensional interaction energy}. Nonlinear Analysis \textbf{216} (2022), 112691.

\bibitem{GrRy} I.~S.~Gradshteyn, I.~M.~Ryzhik, \textit{Table of integrals, series, and products}. Eighth edition. Elsevier/Academic Press, Amsterdam, 2015.

\bibitem{Lo} O. Lopes, \textit{Uniqueness and radial symmetry of minimizers for a nonlocal variational problem}. Commun. Pure Appl. Anal. \textbf{18} (2019), no. 5, 2265--2282.

\bibitem{MaMoRoScVe} J. Mateu, M. G. Mora, L. Rondi, L. Scardia, J. Verdera, \textit{Explicit minimisers for anisotropic Coulomb energies in 3D}. Preprint (2022), arXiv:2210.06797.

\bibitem{MoRoSc} M. G. Mora, L. Rondi, L. Scardia, \textit{The equilibrium measure for a nonlocal dislocation energy}. Comm. Pure Appl. Math. \textbf{72} (2019), no. 1, 136--158.

\end{thebibliography}

\end{document}