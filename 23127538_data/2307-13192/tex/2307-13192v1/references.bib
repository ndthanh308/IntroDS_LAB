@inproceedings{deshmukhexplaining,
  title={Explaining RL Decisions with Trajectories},
  author={Deshmukh, Shripad Vilasrao and Dasgupta, Arpan and Krishnamurthy, Balaji and Jiang, Nan and Agarwal, Chirag and Theocharous, Georgios and Subramanian, Jayakumar},
  booktitle={ICLR}
}

@inproceedings{verma2018programmatically,
  title={Programmatically interpretable reinforcement learning},
  author={Verma, Abhinav and Murali, Vijayaraghavan and Singh, Rishabh and Kohli, Pushmeet and Chaudhuri, Swarat},
  booktitle={ICML},
  pages={},
  year={2018},
  organization={PMLR}
}

@article{puri2019explain,
  title={Explain your move: Understanding agent actions using specific and relevant feature attribution},
  author={Puri, Nikaash and Verma, Sukriti and Gupta, Piyush and Kayastha, Dhruv and Deshmukh, Shripad and Krishnamurthy, Balaji and Singh, Sameer},
  journal={arXiv},
  year={2019}
}

@inproceedings{iyer2018transparency,
  title={Transparency and explanation in deep reinforcement learning neural networks},
  author={Iyer, Rahul and Li, Yuezhang and Li, Huao and Lewis, Michael and Sundar, Ramitha and Sycara, Katia},
  booktitle={AIES},
  pages={},
  year={2018}
}

@inproceedings{coppens2019distilling,
  title={Distilling deep reinforcement learning policies in soft decision trees},
  author={Coppens, Youri and Efthymiadis, Kyriakos and Lenaerts, Tom and Now{\'e}, Ann and Miller, Tim and Weber, Rosina and Magazzeni, Daniele},
  booktitle={IJCAI workshop on Explainable Artificial Intelligence},
  pages={},
  year={2019}
}

@inproceedings{puiutta2020explainable,
  title={Explainable reinforcement learning: A survey},
  author={Puiutta, Erika and Veith, Eric MSP},
  booktitle={Machine Learning and Knowledge Extraction: 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference, CD-MAKE 2020, Dublin, Ireland, August 25--28, 2020, Proceedings 4},
  pages={},
  year={2020},
  organization={Springer}
}

@inproceedings{greydanus2018visualizing,
  title={Visualizing and understanding atari agents},
  author={Greydanus, Samuel and Koul, Anurag and Dodge, Jonathan and Fern, Alan},
  booktitle={ICML},
  pages={},
  year={2018},
  organization={}
}

@article{verma2020counterfactual,
  title={Counterfactual Explanations for Machine Learning: A Review},
  author={Verma, Sahil and Dickerson, John and Hines, Keegan},
  journal={arXiv},
  year={2020}
}

@InProceedings{karimi2019model,
  title = 	 {Model-Agnostic Counterfactual Explanations for Consequential Decisions},
  author =       {Karimi, Amir-Hossein and Barthe, Gilles and Balle, Borja and Valera, Isabel},
  booktitle={AISTATS},
  year={2020}
}

@article{mahajan2019preserving,
  title={Preserving causal constraints in counterfactual explanations for machine learning classifiers},
  author={Mahajan, Divyat and Tan, Chenhao and Sharma, Amit},
  journal={arXiv},
  year={2019}
}

@inproceedings{pawelczyk2020learning,
  title={Learning model-agnostic counterfactual explanations for tabular data},
  author={Pawelczyk, Martin and Broelemann, Klaus and Kasneci, Gjergji},
  booktitle={WWWW},
  pages={},
  year={2020}
}

@article{van2019interpretable,
  title={Interpretable counterfactual explanations guided by prototypes},
  author={Van Looveren, Arnaud and Klaise, Janis},
  journal={arXiv},
  year={2019}
}

@inproceedings{Ustun2019ActionableRI,
  title={Actionable Recourse in Linear Classification},
  author={Berk Ustun and Alexander Spangher and Y. Liu},
  booktitle={FAacT},
  year={2019}
}

@article{wachter2017counterfactual,
  title={Counterfactual explanations without opening the black box: automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harvard Journal of Law \& Technology},
  volume={31},
  number={2},
  year={2018}
}

@inproceedings{trpo,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={ICML},
  pages={},
  year={2015},
  organization={PMLR}
}

@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv},
  year={2017}
}

@article{acktr,
  title={Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  journal={NeurIPS},
  volume={},
  year={2017}
}

@article{cfxai_survey,
  title={A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence},
  author={Ilia Stepin and Jose M. Alonso and Alejandro Catal{\'a} and Martin Pereira-Fari{\~n}a},
  journal={IEEE Access},
  year={2021},
  volume={},
  pages={}
}

@article{cfml_survey,
  title={Counterfactual Explanations for Machine Learning: A Review},
  author={Sahil Verma and John P. Dickerson and Keegan E. Hines},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.10596}
}

@article{mdp,
  title={A Markovian decision process},
  author={Bellman, Richard},
  journal={Journal of mathematics and mechanics},
  pages={},
  year={1957},
  publisher={JSTOR}
}

@article{polgrad,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={NeurIPS},
  volume={},
  year={2001}
}

@book{sutton_book,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{dota2,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv},
  year={2019}
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {JMLR},
  year    = {2021},
  volume  = {},
  number  = {},
  pages   = {},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={ICML},
  pages={},
  year={2018},
  organization={PMLR}
}

@article{a2c_1,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv},
  year={2012}
}


@article{openaigym,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv},
  year={2016}
}

@article{parikh2014proximal,
  title={Proximal algorithms},
  author={Parikh, Neal and Boyd, Stephen and others},
  journal={Foundations and trends{\textregistered} in Optimization},
  volume={},
  number={},
  pages={},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@INPROCEEDINGS{9341559,
  author={Maggipinto, Marco and Susto, Gian Antonio and Chaudhari, Pratik},
  booktitle={IROS}, 
  title={Proximal Deterministic Policy Gradient}, 
  year={2020},
  volume={},
  number={},
  pages={},
  doi={10.1109/IROS45743.2020.9341559}}

  @misc{asadi2023faster,
      title={Faster Deep Reinforcement Learning with Slower Online Network}, 
      author={Kavosh Asadi and Rasool Fakoor and Omer Gottesman and Taesup Kim and Michael L. Littman and Alexander J. Smola},
      year={2023},
      eprint={},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{pmlr-v162-ding22b,
  title = 	 {Independent Policy Gradient for Large-Scale {M}arkov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence},
  author =       {Ding, Dongsheng and Wei, Chen-Yu and Zhang, Kaiqing and Jovanovic, Mihailo},
  booktitle = 	 {ICML},
  pages = 	 {},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {PMLR},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/ding22b/ding22b.pdf},
  url = 	 {https://proceedings.mlr.press/v162/ding22b.html},
  abstract = 	 {}
}

@misc{hirano2022policy,
      title={Policy Gradient Stock GAN for Realistic Discrete Order Data Generation in Financial Markets}, 
      author={Masanori Hirano and Hiroki Sakaji and Kiyoshi Izumi},
      year={2022},
      eprint={},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{pmlr-v100-khan20a,
  title = 	 {Graph Policy Gradients for Large Scale Robot Control},
  author =       {Khan, Arbaaz and Tolstaya, Ekaterina and Ribeiro, Alejandro and Kumar, Vijay},
  booktitle = 	 {Proceedings of the Conference on Robot Learning},
  pages = 	 {},
  year = 	 {2020},
  editor = 	 {Kaelbling, Leslie Pack and Kragic, Danica and Sugiura, Komei},
  volume = 	 {},
  series = 	 {PMLR},
  month = 	 {30 Oct--01 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v100/khan20a/khan20a.pdf},
  url = 	 {https://proceedings.mlr.press/v100/khan20a.html},
  abstract = 	 {}
}

@misc{lu2023dynamic,
      title={Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning}, 
      author={Pan Lu and Liang Qiu and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Tanmay Rajpurohit and Peter Clark and Ashwin Kalyan},
      year={2023},
      eprint={},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{NIPS2014_d554f7bb,
 author = {Nitanda, Atsushi},
 booktitle = {NeurIPS},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stochastic Proximal Gradient Descent with Acceleration Techniques},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/d554f7bb7be44a7267068a7df88ddd20-Paper.pdf},
 volume = {},
 year = {2014}
}

@article{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  journal={NeurIPS},
  volume={},
  year={2016}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={ICML},
  pages={},
  year={2016},
  organization={PMLR}
}

@inproceedings{cpi,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  pages={},
  year={2002}
}

@article{hrl,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={},
  number={},
  pages={},
  year={2003},
  publisher={Springer}
}

@article{hrl_survey,
  title={Hierarchical reinforcement learning: A comprehensive survey},
  author={Pateria, Shubham and Subagdja, Budhitama and Tan, Ah-hwee and Quek, Chai},
  journal={ACM Computing Surveys (CSUR)},
  volume={},
  number={},
  pages={},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{go_rl,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={},
  number={},
  pages={},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{atari_rl,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv},
  year={2013}
}

@article{causal_rl,
  title={Reinforcement learning and causal models},
  author={Gershman, Samuel J},
  journal={The Oxford handbook of causal reasoning},
  volume={},
  pages={},
  year={2017},
  publisher={Oxford university press}
}

@article{matrix,
  title={Discovering faster matrix multiplication algorithms with reinforcement learning},
  author={Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R Ruiz, Francisco J and Schrittwieser, Julian and Swirszcz, Grzegorz and others},
  journal={Nature},
  volume={},
  number={},
  pages={},
  year={2022},
  publisher={Nature Publishing Group}
}

@inproceedings{marketing,
  title={Ad recommendation systems for life-time value optimization},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={WWW},
  pages={},
  year={2015}
}

@article{tutor,
  title={New potentials for data-driven intelligent tutoring system development and optimization},
  author={Koedinger, Kenneth R and Brunskill, Emma and Baker, Ryan SJd and McLaughlin, Elizabeth A and Stamper, John},
  journal={AI Magazine},
  volume={},
  number={},
  pages={},
  year={2013}
}

@article{protein,
  title={Protein design via deep learning},
  author={Ding, Wenze and Nakai, Kenta and Gong, Haipeng},
  journal={Briefings in bioinformatics},
  volume={},
  number={},
  pages={},
  year={2022},
  publisher={Oxford University Press}
}

@article{unlearning,
  title={Remember what you want to forget: Algorithms for machine unlearning},
  author={Sekhari, Ayush and Acharya, Jayadev and Kamath, Gautam and Suresh, Ananda Theertha},
  journal={NeurIPS},
  volume={},
  pages={},
  year={2021}
}

@article{unlearning_survey,
  title={A survey of machine unlearning},
  author={Nguyen, Thanh Tam and Huynh, Thanh Trung and Nguyen, Phi Le and Liew, Alan Wee-Chung and Yin, Hongzhi and Nguyen, Quoc Viet Hung},
  journal={arXiv},
  year={2022}
}

@article{fun_approx_1,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={NeurIPS},
  volume={},
  year={1999}
}

@inproceedings{fun_approx_2,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={},
  year={2008}
}

@article{pytorch,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@article{tensorflow,
  title={Tensorflow: Large-scale machine learning on heterogeneous distributed systems},
  author={Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and others},
  journal={arXiv},
  year={2016}
}