@Article{Hinton2012,
  author  = {G. Hinton and \emph{et al.}},
  journal = {IEEE Signal Process. Mag.},
  title   = {Deep Neural Networks for Acoustic Modeling in Speech Recognition: {T}he Shared Views of Four Research Groups},
  year    = {2012},
  month   = nov,
  number  = {6},
  pages   = {82--97},
  volume  = {26},
}

@InProceedings{Chorowski2015,
  author    = {J. K. Chorowski and D. Bahdanau and D. Serdyuk and K. Cho and Y. Bengio},
  booktitle = {Proc. NeurIPS},
  title     = {Attention-Based Models for Speech Recognition},
  year      = {2015},
  month     = dec,
}

@InProceedings{Graves2006,
  author    = {A. Graves and S. Fernández and F. Gomez and J. Schmidhuber},
  booktitle = {Proc. ICML},
  title     = {Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  year      = {2006},
  month     = jun,
  pages     = {369--376},
}

@InProceedings{Graves2012,
  author    = {A. Graves},
  booktitle = {Proc. ICML Workshop Represent. Learn.},
  title     = {Sequence Transduction with Recurrent Neural Networks},
  year      = {2012},
  month     = jun,
  journal   = {Int. Conf. March. learn. (ICML)},
}

@InProceedings{Chiu2018,
  author    = {C. C. Chiu and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {State-of-the-Art Speech Recognition with Sequence-to-Sequence Models},
  year      = {2018},
  month     = apr,
  pages     = {4774--4778},
}

@InProceedings{Zhang2020,
  author    = {Q. Zhang and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {Transformer transducer: {A} streamable speech recognition model with transformer encoders and {RNN-T} loss},
  year      = {2020},
  month     = may,
  pages     = {7829--7833},
}

@InProceedings{Gulati2020,
  author    = {A. Gulati and \emph{et al.}},
  booktitle = {Proc. Interspeech},
  title     = {Conformer: {C}onvolution-augmented transformer for speech recognition},
  year      = {2020},
  month     = oct,
  pages     = {5036 --5040},
}

@Article{Chan2016,
  author  = {W. Chan and N. Jaitly and Q. Le and O. Vinyals},
  journal = {Proc. ICASSP},
  title   = {Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
  year    = {2016},
  month   = may,
  pages   = {4960--4964},
}

@Article{Miao2015,
  author  = {Y. Miao and M. Gowayyed and F. Metze},
  journal = {Proc. ASRU},
  title   = {{E}{E}{S}{E}{N}: {E}nd-to-end speech recognition using deep {R}{N}{N} models and {W}{F}{S}{T}-based decoding},
  year    = {2015},
  month   = dec,
  pages   = {167--174},
}

@InProceedings{Rao2017,
  author    = {K. Rao and H. Sak and R. Prabhavalkar},
  booktitle = {Proc. ASRU},
  title     = {Exploring architectures, data and units for streaming end-to-end speech recognition with {RNN}-transducer},
  year      = {2017},
  month     = dec,
  pages     = {193--199},
}

@Article{Mohamed2022,
  author  = {A Mohamed and \emph{et al.}},
  journal = {arXiv:2205.10643},
  title   = {Self-Supervised Speech Representation Learning: {A} Review},
  year    = {2022},
  month   = may,
}

@InProceedings{Yang2021,
  author    = {S. W. Yang and \emph{et al.}},
  booktitle = {Proc. Interspeech},
  title     = {{S}{U}{P}{E}{R}{B}: {S}peech processing Universal PERformance Benchmark},
  year      = {2021},
  pages     = {1194--1198},
}

@InProceedings{Tsai2022,
  author    = {H. S. Tsai and \emph{et al.}},
  booktitle = {Proc. ACL},
  title     = {{SUPERB-SG}: {E}nhanced speech processing universal performance benchmark for semantic and generative capabilities},
  year      = {2022},
  pages     = {8479--8492},
}

@article{Gannot2017,
author = {Gannot, S. and Vincent, E. and Markovich-Golan, S. and Ozerov, A.},
journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
pages = {692--730},
title = {A Consolidated Perspective on Multi-Microphone Speech Enhancement and Source Separation},
volume = {25},
year = {2017}
}

@Article{Chung2019,
  author  = {Y. A. Chung and W. N. Hsu and H. Tang and J. Glass},
  journal = {Proc. Interspeech},
  title   = {An Unsupervised Autoregressive Model for Speech Representation Learning},
  year    = {2019},
  month   = sep,
  pages   = {146--150},
}

@InProceedings{Liu2020,
  author    = {A. T. Liu and S. Yang and P. H. Chi and P. Hsu and H. Lee},
  booktitle = {Proc. ICASSP},
  title     = {Mockingjay: {U}nsupervised speech representation learning with deep bidirectional Transformer encoders},
  year      = {2020},
  month     = may,
  pages     = {6419--6423},
}

@Article{Oord2018,
  author  = {A. Oord and Y. Li and O. Vinyals},
  journal = {arXiv:1807.03748},
  title   = {Representation learning with contrastive predictive coding},
  year    = {2018},
  month   = jul,
}

@InProceedings{Schneider2019,
  author    = {S. Schneider and A. Baevski and R. Collobert and M. Auli},
  booktitle = {Proc. Interspeech},
  title     = {wav2vec: {U}nsupervised Pre-training for Speech Recognition},
  year      = {2019},
}

@InProceedings{Baevski2020,
  author    = {A. Baevski and Y. Zhou and A. Mohamed and M. Auli},
  booktitle = {Proc. NeurIPS},
  title     = {wav2vec 2.0: {A} framework for self-supervised learning of speech representations},
  year      = {2020},
}

@Article{Hsu2021,
  author  = {W. N. Hsu and B. Bolte and Y. H. H. Tsai and K. Lakhotia and R. Salakhutdinov and A. Mohamed},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {{H}u{B}{E}{R}{T}: {S}elf-supervised speech representation learning by masked prediction of hidden units},
  year    = {2021},
  pages   = {3451--3460},
  volume  = {29},
}

@Article{Chen2021,
  title={{WavLM}: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and Wu, Jian and Zhou, Long and Ren, Shuo and Qian, Yanmin and Qian, Yao and Wu, Jian and Zeng, Michael and Yu, Xiangzhan and Wei, Furu},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022},
}

@InProceedings{Wang2022,
  author    = {Y. Wang and J. Li and H. Wang and Y. Qian and C. Wang and Y. Wu},
  booktitle = {Proc. ICASSP},
  title     = {{W}av2vec-switch: {C}ontrastive learning from original-noisy speech pairs for robust speech recognition},
  year      = {2022},
  month     = may,
  pages     = {7097--7101},
}

@InProceedings{Wang2022a,
  author    = {H. Wang and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {Improving Noise Robustness of Contrastive Speech Representation Learning with Speech Reconstruction},
  year      = {2022},
  month     = may,
  pages     = {6062--6066},
}

@Article{Huang2022,
  author  = {K. P. Huang and Y. K. Fu and Y. Zhang and H. Lee},
  journal = {arXiv:2203.16104},
  title   = {Improving Distortion Robustness of Self-supervised Speech Processing Tasks with Domain Adaptation},
  year    = {2022},
  month   = mar,
}

@Article{Nakatani2010,
  author  = {T. Nakatani and T. Yoshioka and K. Kinoshita and M. Miyoshi and B. Juang},
  journal = {IEEE Trans. Audio, Speech, Lang. Process.},
  title   = {Speech Dereverberation Based on Variance-Normalized Delayed Linear Prediction},
  year    = {2010},
  month   = sep,
  number  = {7},
  pages   = {1717--1731},
  volume  = {18},
}

@Article{Kinoshita2016,
  author  = {K. Kinoshita and \emph{et al.}},
  journal = {EURASIP J. Adv. Signal Process.},
  title   = {A summary of the {R}{E}{V}{E}{R}{B} challenge: state-of-the-art and remaining challenges in reverberant speech processing research},
  year    = {2016},
  month   = jan,
  volume  = {7},
}

@InProceedings{Li2017,
  author    = {B. Li and \emph{et al.}},
  booktitle = {Proc. Interspeech},
  title     = {Acoustic Modeling for Google Home},
  year      = {2017},
  month     = sep,
  pages     = {399--403},
}

@Article{Souden2010,
  author  = {M. Souden and J. Benesty and S. Affes},
  journal = {IEEE Trans. Audio, Speech, Lang. Process.},
  title   = {On optimal frequency-domain multichannel linear filtering for noise reduction},
  year    = {2010},
  month   = jun,
  number  = {2},
  pages   = {260--276},
  volume  = {18},
}

@Book{Trees2004,
  author    = {H. L. V. Trees},
  publisher = {Wiley},
  title     = {Optimum Array Processing: {P}art {I}{V} of Detection, Estimation, and Modulation Theory},
  year      = {2004},
}

@Article{Nakatani2019,
  author  = {T. Nakatani and K. Kinoshita},
  journal = {IEEE Signal Process. Lett.},
  title   = {A unified convolutional beamformer for simultaneous denoising and dereverberation},
  year    = {2019},
  month   = jun,
  number  = {6},
  pages   = {903--907},
  volume  = {26},
}

@InProceedings{Zhang2020a,
  author    = {W. Zhang and A. S. Subramanian and X. Chang and S. Watanabe and Y. Qian},
  booktitle = {Proc. Interspeech},
  title     = {End-to-end far-field speech recognition with unified dereverberation and beamforming},
  year      = {2020},
  pages     = {324--328},
}

@InProceedings{Ni2021,
  author    = {Z. Ni and \emph{et al.}},
  booktitle = {Proc. SLT},
  title     = {{W}{P}{D}++: {A}n Improved Neural Beamformer for Simultaneous Speech Separation and Dereverberation},
  year      = {2021},
  month     = jan,
  pages     = {817--824},
}

@Article{Vincent2017,
  author  = {E. Vincent and S. Watanabe and A. A. Nugraha and J. Barker and R. Marxer},
  journal = {Comput. Speech, Lang.},
  title   = {An analysis of environment, microphone and data simulation mismatches in robust speech recognition},
  year    = {2017},
  pages   = {535--557},
  volume  = {46},
}

@inproceedings{Chang2022,
  author={Xuankai Chang and Takashi Maekaku and Yuya Fujita and Shinji Watanabe},
  title={{End-to-End Integration of Speech Recognition, Speech Enhancement, and Self-Supervised Learning Representation}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3819--3823},
  doi={10.21437/Interspeech.2022-10839}
}

@InProceedings{Heymann2017,
  author    = {J. Heymann and L. Drude and C. Boeddeker and P. Hanebrink and R. Haeb-Umbach},
  booktitle = {Proc. ICASSP},
  title     = {Beamnet: {E}nd-to-end training of a beamformer-supported multi-channel {A}{S}{R} system},
  year      = {2017},
  pages     = {5325--5329},
}

@InProceedings{Ochiai2017,
  author    = {T. Ochiai and S. Watanabe and T. Hori and J. R. Hershey},
  booktitle = {Proc. ICML},
  title     = {Multichannel end-to-end speech recognition},
  year      = {2017},
  pages     = {2632--2641},
}

@Article{Ochiai2017a,
  author  = {T. Ochiai and S. Watanabe and T. Hori and J. R. Hershey and X. Xiao},
  journal = {IEEE J. Sel. Top. Signal Process.},
  title   = {Unified architecture for multichannel end-to-end speech recognition with neural beamforming},
  year    = {2017},
  month   = dec,
  number  = {8},
  pages   = {1274--1288},
  volume  = {11},
}

@InProceedings{Subramanian2019,
  author    = {A. S. Subramanian and \emph{et al.}},
  booktitle = {Proc. WASPAA},
  title     = {Speech Enhancement Using End-to-End Speech Recognition Objectives},
  year      = {2019},
  month     = oct,
  pages     = {234--238},
}

@InProceedings{Chang2019,
  author    = {X. Chang and W. Zhang and Y. Qian and J. L. Roux and S. Watanabe},
  booktitle = {Proc. ASRU},
  title     = {{M}{I}{M}{O}-{S}peech: {E}nd-to-end multi-channel multi-speaker speech recognition},
  year      = {2019},
  month     = dec,
  pages     = {237--244},
}

@InProceedings{Sainath2015,
  author    = {T. Sainath and R. J. Weiss and K. Wilson and A. W. Senior and O. Vinyals},
  booktitle = {Proc. Interspeech},
  title     = {Learning the speech front-end with raw waveform {C}{L}{D}{N}{N}s},
  year      = {2015},
  month     = sep,
  pages     = {1--5},
}

@InProceedings{Shao2022,
  author    = {Y. Shao and S. X. Zhang and D. Yu},
  booktitle = {Proc. ICASSP},
  title     = {Multi-Channel Multi-Speaker {A}{S}{R} Using {3D} Spatial Feature},
  year      = {2022},
  month     = may,
  pages     = {6067-6071},
}

@Article{Tan2022,
  author  = {K. Tan and Z. Q. Wang and D. Wang},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {Neural Spectrospatial Filtering},
  year    = {2022},
  pages   = {605--621},
  volume  = {30},
}

@Article{Gu2019,
  author  = {R. Gu and \emph{et al.}},
  journal = {arXiv:1905.06286},
  title   = {End-to-end multi-channel speech separation},
  year    = {2019},
  month   = may,
}

@InProceedings{Zhang2021,
  author    = {W. Zhang and J. Shi and C. Li and S. Watanabe and Y. Qian},
  booktitle = {Proc. WASPAA},
  title     = {Closing the Gap Between Time-Domain Multi-Channel Speech Enhancement on Real and Simulation Conditions},
  year      = {2021},
  pages     = {146--150},
}

@InProceedings{Boeddeker2021,
  author    = {C. Boeddeker and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {Convolutive Transfer Function Invariant {S}{D}{R} Training Criteria for Multi-Channel Reverberant Speech Separation},
  year      = {2021},
  pages     = {8428--8432},
  journal   = {Proc. ICASSP},
}

@InProceedings{Khan2020,
  author    = {J. Khan and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {Libri-Light: A Benchmark for {A}{S}{R} with Limited or No Supervision},
  year      = {2020},
  month     = may,
  pages     = {7669--7673},
}

@InProceedings{Chen2021a,
  author    = {G. Chen and \emph{et al.}},
  booktitle = {Proc. Interspeech},
  title     = {{GigaSpeech}: An Evolving, Multi-Domain {ASR} Corpus with 10,000 Hours of Transcribed Audio},
  year      = {2021},
  month     = sep,
  pages     = {3670--3674},
}

@InProceedings{Wang2021,
  title={{VoxPopuli}: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation},
  author={Wang, Changhan and Riviere, Morgane and Lee, Ann and Wu, Anne and Talnikar, Chaitanya and Haziza, Daniel and Williamson, Mary and Pino, Juan and Dupoux, Emmanuel},
  booktitle={Proc. ACL},
  pages={993--1003},
  year={2021},
}

@Article{Watanabe2017,
  author  = {S. Watanabe and T. Hori and S. Kim and J. R. Hershey and T. Hayashi},
  journal = {IEEE J. Sel. Top. Signal Process.},
  title   = {Hybrid {C}{T}{C}/Attention Architecture for End-to-End Speech Recognition},
  year    = {2017},
  month   = dec,
  number  = {8},
  pages   = {1240--1253},
  volume  = {11},
}

@InProceedings{Watanabe2018,
  author    = {S. Watanabe and \emph{et al.}},
  booktitle = {Proc. Interspeech},
  title     = {{E}{S}{P}net: {E}nd-to-End Speech Processing Toolkit},
  year      = {2018},
  month     = sep,
  pages     = {2207--2211},
}

@InProceedings{Chen2018,
  author    = {S. J. Chen and A. S. Subramanian and H. Xu and S. Watanabe},
  booktitle = {Pro. Interspeech},
  title     = {Building state-of-the-art distant speech recognition using the {CHiME}-4 challenge with a setup of speech enhancement baseline},
  year      = {2018},
}

@Article{Du2016,
  author  = {J. Du and \emph{et al.}},
  journal = {CHiME},
  title   = {The {U}{S}{T}{C}-i{F}lytek system for {C}{H}i{M}{E}-4 challenge},
  year    = {2016},
}

@Article{Wang2020,
  author  = {Z. Q. Wang and P. Wang and D. Wang},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {Complex Spectral Mapping for Single- and Multi-Channel Speech Enhancement and Robust {ASR}},
  year    = {2020},
  month   = may,
  pages   = {1778--1787},
  volume  = {28},
}

@Article{Anguera2007,
  author  = {X. Anguera and C. Wooters and J. Hernando},
  journal = {IEEE Trans. Audio, Speech, Lang. Process.},
  title   = {Acoustic beamforming for speaker diarization of meetings},
  year    = {2007},
  month   = sep,
  number  = {7},
  pages   = {2011--2022},
  volume  = {15},
}

@InProceedings{Raj2021,
  author    = {D. Raj and \emph{et al.}},
  booktitle = {Proc. SLT},
  title     = {Integration of Speech Separation, Diarization, and Recognition for Multi-Speaker Meetings: {S}ystem Description, Comparison, and Analysis},
  year      = {2021},
  pages     = {897--904},
}

@InProceedings{Li2021,
  author    = {C. Li and \emph{et al.}},
  booktitle = {Proc. SLT},
  title     = {{E}{S}{P}net-{S}{E}: {E}nd-To-End Speech Enhancement and Separation Toolkit Designed for {A}{S}{R} Integration},
  year      = {2021},
  month     = jan,
  pages     = {785--792},
}

@Article{Kolbaek2017,
  author  = {M. Kolb{\ae}k and D. Yu and Z. H. Tan and J. Jensen},
  journal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
  title   = {Multitalker Speech Separation With Utterance-Level Permutation Invariant Training of Deep Recurrent Neural Networks},
  year    = {2017},
  month   = jul,
  number  = {10},
  pages   = {1901--1913},
  volume  = {25},
}

@Article{Wang2018,
  author  = {D. Wang and J. Chen},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {{S}upervised speech separation based on deep learning: {A}n overview},
  year    = {2018},
  number  = {10},
  pages   = {1702--1726},
  volume  = {26},
}

@Article{Luo2019,
  author  = {Y. Luo and N. Mesgarani},
  journal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
  title   = {{C}onv-{TasNet}: {S}urpassing Ideal Time–Frequency Magnitude Masking for Speech Separation},
  year    = {2019},
  number  = {8},
  pages   = {1256--1266},
  volume  = {27},
}

@InProceedings{Luo2020,
  author    = {Y. Luo and Z. Chen and T. Yoshioka},
  booktitle = {Proc. ICASSP},
  title     = {Dual-path {RNN}: efficient long sequence modeling for time-domain single-channel speech separation},
  year      = {2020},
  pages     = {46--50},
}

@InProceedings{Subakan2021,
  author    = {C. Subakan and M. Ravanelli and S. Cornell and M. Bronzi and J. Zhong},
  booktitle = {Proc. ICASSP},
  title     = {Attention is all you need in speech separation},
  year      = {2021},
  pages     = {21--25},
}

@InProceedings{Yang2022,
  author    = {L. Yang and W. Liu and W. Wang},
  booktitle = {Proc. ICASSP},
  title     = {{T}{F}{P}{S}{N}et: {T}ime-Frequency Domain Path Scanning Network for Speech Separation},
  year      = {2022},
  pages     = {6842--6846},
}

@Article{Tan2022a,
  author  = {K. Tan and Z. Q. Wang and D. Wang},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {Neural Spectrospatial Filtering},
  year    = {2022},
  pages   = {605--621},
  volume  = {30},
}

@InProceedings{Isik2016,
  author    = {Y. Isik and J. {Le Roux} and Z. Chen and S Watanabe and J. R. Hershey},
  booktitle = {Pro. Interspeech},
  title     = {Single-Channel Multi-Speaker Separation using Deep Clustering},
  year      = {2016},
  pages     = {545--549},
}

@InProceedings{Hershey2016,
  author    = {J. R. Hershey and Z. Chen and J. Le Roux and S. Watanabe},
  booktitle = {Proc. ICASSP},
  title     = {Deep clustering: Discriminative embeddings for segmentation and separation},
  year      = {2016},
  pages     = {31--35},
}

@InProceedings{Wang2018a,
  author    = {Z. Q. Wang and J. Le Roux and J. R. Hershey},
  booktitle = {Proc. ICASSP},
  title     = {Multi-Channel Deep Clustering: Discriminative Spectral and Spatial Embeddings for Speaker-Independent Speech Separation},
  year      = {2018},
  pages     = {1--5},
}

@InProceedings{Maciejewski2020,
  author    = {M. Maciejewski and G. Wichern and E. McQuinn and J. Le Roux},
  booktitle = {Proc. ICASSP},
  title     = {{WHAMR}!: Noisy and Reverberant Single-Channel Speech Separation},
  year      = {2020},
  pages     = {696--700},
}

@Article{Guizzo2022,
  author  = {E. Guizzo and \emph{et al.}},
  journal = {Proc. ICASSP},
  title   = {{L}{3}{D}{A}{S}{2}{2} Challenge: {L}earning {3D} Audio Sources in a Real Office Environment},
  year    = {2022},
  pages   = {9186--9190},
}

@InProceedings{Lu2022,
  author    = {Y. J. Lu and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {Towards Low-Distortion Multi-Channel Speech Enhancement: {T}he {E}{S}{P}{N}{E}{T}-{S}{E} Submission to the {L}{3}{D}{A}{S}{2}{2} Challenge},
  year      = {2022},
  pages     = {9201--9205},
}

@Article{Wang2022b,
  author  = {Z. Q. Wang and S. Cornell and S. Choi and Y. Lee and B. Y. Kim and S. Watanabe},
  journal = {arXiv:2209.03952},
  title   = {{T}{F}-{G}rid{N}et: {M}aking time-frequency domain models great again for monaural speaker separation},
  year    = {2022},
}

@Article{Wang2022c,
  author  = {Z. Q. Wang and S. Cornell and S. Choi and Y. Lee and B. Y. Kim and S. Watanabe},
  journal = {arXiv:2211.12433},
  title   = {{T}{F}-{G}rid{N}et: {I}ntegrating Full- and Sub-Band Modeling for Speech Separation},
  year    = {2022},
}

@InProceedings{Masuyama2023,
  author    = {Y. Masuyama and X. Chang and S. Cornell and S. Watanabe and N. Ono},
  booktitle = {Proc. SLT},
  title     = {End-to-End Integration of Speech Recognition, Dereverberation, Beamforming, and Self-Supervised Learning Representation},
  year      = {2023},
  pages     = {260--265},
}

@Article{Zhang2022,
  author  = {W. Zhang and X. Chang and C. Boeddeker and T. Nakatani and S. Watanabe and Y. Qian},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {End-to-End Dereverberation, Beamforming, and Speech Recognition in a Cocktail Party},
  year    = {2022},
  pages   = {3173--3188},
  volume  = {30},
}

@inproceedings{chang2021exploration,
  title={An exploration of self-supervised pretrained representations for end-to-end speech recognition},
  author={Chang, Xuankai and Maekaku, Takashi and Guo, Pengcheng and Shi, Jing and Lu, Yen-Ju and Subramanian, Aswin Shanmugam and Wang, Tianzi and Yang, Shu-wen and Tsao, Yu and Lee, Hung-yi and others},
  booktitle={Proc. ASRU},
  pages={228--235},
  year={2021},
}

@inproceedings{yu2017permutation,
  title={Permutation invariant training of deep models for speaker-independent multi-talker speech separation},
  author={Yu, Dong and Kolb{\ae}k, Morten and Tan, Zheng-Hua and Jensen, Jesper},
  booktitle={Proc. ICASSP},
  pages={241--245},
  year={2017},
}

@inproceedings{lu2022espnet,
  title={{E}{S}{P}net-{S}{E}++: {S}peech enhancement for robust speech recognition, translation, and understanding},
  author={Lu, Yen-Ju and Chang, Xuankai and Li, Chenda and Zhang, Wangyou and Cornell, Samuele and Ni, Zhaoheng and Masuyama, Yoshiki and Yan, Brian and Scheibler, Robin and Wang, Zhong-Qiu and others},
  booktitle={Proc. Interspeech},
  pages={5458--5462},
  year={2022}
}

@inproceedings{kim2017joint,
  title={Joint {CTC}-attention based end-to-end speech recognition using multi-task learning},
  author={Kim, Suyoun and Hori, Takaaki and Watanabe, Shinji},
  booktitle={Proc. ICASSP},
  pages={4835--4839},
  year={2017},
}

@inproceedings{chang2019end,
  title={End-to-end monaural multi-speaker {ASR} system without pretraining},
  author={Chang, Xuankai and Qian, Yanmin and Yu, Kai and Watanabe, Shinji},
  booktitle={Proc. ICASSP},
  pages={6256--6260},
  year={2019},
}

@Article{Subramanian2022,
  author  = {A. S. Subramanian and C. Weng and S. Watanabe and M. Yu and D. Yu},
  journal = {Comput. Speech, Lang.},
  title   = {Deep learning based multi-source localization with source splitting and its effectiveness in multi-talker speech recognition},
  year    = {2022},
  pages   = {101360},
  volume  = {75},
}

@InProceedings{Kanda2020,
  author    = {N. Kanda and Y. Gaur and X. Wang and Z. Meng and T. Yoshioka},
  booktitle = {Proc. Interspeech},
  title     = {Serialized Output Training for End-to-End Overlapped Speech Recognition},
  year      = {2020},
  pages     = {2797--2801},
}

@inproceedings{ryant21_interspeech,
  author={Neville Ryant and Prachi Singh and Venkat Krishnamohan and Rajat Varma and Kenneth Church and Christopher Cieri and Jun Du and Sriram Ganapathy and Mark Liberman},
  title={{The Third DIHARD Diarization Challenge}},
  year=2021,
  booktitle={Proc. Interspeech},
  pages={3570--3574},
}

@article{li2017acoustic,
  title={Acoustic Modeling for Google Home},
  author={Li, Bo and Sainath, Tara N and Narayanan, Arun and Caroselli, Joe and Bacchiani, Michiel and Misra, Ananya and Shafran, Izhak and Sak, Ha{\c{s}}im and Pundak, Golan and Chin, Kean and others},
  journal={Proc. Interspeech},
  pages={399--403},
  year={2017}
}

@article{seltzer2004likelihood,
  title={Likelihood-maximizing beamforming for robust hands-free speech recognition},
  author={Seltzer, Michael L and Raj, Bhiksha and Stern, Richard M},
  journal={IEEE Trans. Speech, Audio process.},
  volume={12},
  number={5},
  pages={489--498},
  year={2004},
}

@article{sainath2017multichannel,
  title={Multichannel signal processing with deep neural networks for automatic speech recognition},
  author={Sainath, Tara N and Weiss, Ron J and Wilson, Kevin W and Li, Bo and Narayanan, Arun and Variani, Ehsan and Bacchiani, Michiel and Shafran, Izhak and Senior, Andrew and Chin, Kean and others},
  journal={IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  volume={25},
  number={5},
  pages={965--979},
  year={2017},
}

@article{li2016neural,
  title={Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition},
  author={Li, Bo and Sainath, Tara N and Weiss, Ron J and Wilson, Kevin W and Bacchiani, Michiel},
  journal={Proc. Interspeech},
  pages={1976--1980},
  year={2016}
}

@inproceedings{heymann2017beamnet,
  title={Beamnet: End-to-end training of a beamformer-supported multi-channel {ASR} system},
  author={Heymann, Jahn and Drude, Lukas and Boeddeker, Christoph and Hanebrink, Patrick and Haeb-Umbach, Reinhold},
  booktitle={Proc. ICASSP},
  pages={5325--5329},
  year={2017},
}

@inproceedings{minhua2019frequency,
  title={Frequency domain multi-channel acoustic modeling for distant speech recognition},
  author={Minhua, Wu and Kumatani, Kenichi and Sundaram, Shiva and Str{\"o}m, Nikko and Hoffmeister, Bj{\"o}rn},
  booktitle={Proc. ICASSP},
  pages={6640--6644},
  year={2019},
}

@inproceedings{sklyar2021streaming,
  title={Streaming multi-speaker {ASR} with {RNN-T}},
  author={Sklyar, Ilya and Piunova, Anna and Liu, Yulan},
  booktitle={Proc. ICASSP},
  pages={6903--6907},
  year={2021},
}

@article{von2020multi,
  title={Multi-Talker {ASR} for an Unknown Number of Sources: Joint Training of Source Counting, Separation and {ASR}},
  author={von Neumann, Thilo and Boeddeker, Christoph and Drude, Lukas and Kinoshita, Keisuke and Delcroix, Marc and Nakatani, Tomohiro and Haeb-Umbach, Reinhold},
  journal={Proc. Interspeech},
  pages={3097--3101},
  year={2020}
}

@InProceedings{Neumann2020,
  author    = {T. von Neumann and \emph{et al.}},
  booktitle = {Proc. ICASSP},
  title     = {End-to-End Training of Time Domain Audio Separation and Recognition},
  year      = {2020},
  pages     = {7004--7008},
}

@inproceedings{seki2018end,
  title={An end-to-end language-tracking speech recognizer for mixed-language speech},
  author={Seki, Hiroshi and Watanabe, Shinji and Hori, Takaaki and Le Roux, Jonathan and Hershey, John R},
  booktitle={Proc. ICASSP},
  pages={4919--4923},
  year={2018},
}

@Article{Williamson2016,
  author  = {D. S. Williamson and Y. Wang and D. Wang,},
  journal = {IEEE/ACM Trans. Audio, Speech, Lang. Process.},
  title   = {Complex ratio masking for monaural speech separation},
  year    = {2016},
  number  = {3},
  pages   = {483--492},
  volume  = {24},
}

@article{erdogan2016improved,
  title={Improved {MVDR} Beamforming Using Single-Channel Mask Prediction Networks},
  author={Erdogan, Hakan and Hershey, John R and Watanabe, Shinji and Mandel, Michael I and Le Roux, Jonathan},
  journal={Proc. Interspeech},
  pages={1981--1985},
  year={2016}
}

@inproceedings{heymann2016neural,
  title={Neural network based spectral mask estimation for acoustic beamforming},
  author={Heymann, Jahn and Drude, Lukas and Haeb-Umbach, Reinhold},
  booktitle={Proc. ICASSP},
  pages={196--200},
  year={2016},
}

@InProceedings{psmpit,
  author    = {Lu Yin and Ziteng Wang and Risheng Xia and Junfeng Li and Yonghong Yan},
  title     = {Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming},
  booktitle = {Proc. Interspeech},
  year      = {2018},
  pages     = {851--855},
}

@InProceedings{yosioka2018x,
  author    = {T. {Yoshioka} and H. {Erdogan} and Z. {Chen} and F. {Alleva}},
  title     = {Multi-Microphone Neural Speech Separation for Far-Field Multi-Talker Speech Recognition},
  booktitle = {Proc. ICASSP},
  year      = {2018},
  pages     = {5739--5743},
}

@article{vincent2006performance,
  title={Performance measurement in blind audio source separation},
  author={Vincent, Emmanuel and Gribonval, R{\'e}mi and F{\'e}votte, C{\'e}dric},
  journal={IEEE Trans. Audio, Speech, Lang. Process.},
  volume={14},
  number={4},
  pages={1462--1469},
  year={2006},
}


@InProceedings{Zhang2021a,
  author    = {J. Zhang and C. Zorila and R. Doddipatla and J. Barker},
  booktitle = {Proc. ICASSP},
  title     = {Time-Domain Speech Extraction with Spatial Information and Multi Speaker Conditioning Mechanism},
  year      = {2021},
  pages     = {6084-6088},
}

@Comment{jabref-meta: databaseType:bibtex;}
