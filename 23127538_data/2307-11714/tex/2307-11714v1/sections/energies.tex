\section{Sliced and Empirical Sliced Wasserstein Energies and their Regularities}\label{sec:energies}

\subsection{The discrete SW energies \texorpdfstring{$\SWY$}{S} and \texorpdfstring{$\SWpY$}{Sp}}

The Sliced Wasserstein distance has been widely studied as an alternative to the Wasserstein distance, in particular it is arguably simpler to compute in order to minimise measure discrepancies. In practice, one may not work with continuous measures, which are beyond the capabilities of numerical approximations, thus one must sometimes contend with discrete measures. To that end, we study in this paper the SW distance between discrete measures, and in particular the associated energy landscape with respect to the support of one of the measures:
\begin{equation}\label{eqn:SWY}
	\SWY := \app{\R^{\npoints \times d}}{\R_+}{Y}{\Int{\SS^{d-1}}{}\mathrm{W_2^2}(P_{\theta} \#\gamma_Y, P_{\theta}\#\gamma_Z) \dd \bbsigma(\theta)},
\end{equation}
where $\npoints$ denotes the number of points in the data matrices $Y, Z$, which we write as data entries stacked vertically: $Y = (y_1, \cdots, y_\npoints)^T$, with points in $\R^d$. The associated (uniform) discrete measure supported on $\lbrace y_1, \cdots, y_\npoints \rbrace$ will be denoted $\gamma_Y := \frac{1}{\npoints}\sum_k \delta_{y_k}$.

For instance, this framework encompasses SW-based implicit generative models (\cite{deshpande_generative_sw}, ~\cite{Wu2019_SWAE}), which optimise parameters $\rho$ by minimising $\SW(T_\rho\#\mu_0, \mu)$, where $\mu_0$ is comprised of samples of a simple distribution, and $\mu$ corresponds to data samples which we would like to generate. In this setting, one would need to minimise \textit{through} $\SWY$.
The use of discrete measures is also backed theoretically by the study of the \textit{sample complexity} of SW~\cite{nadjahi_statistical_properties_sliced}, which is to say the rate of decrease of the approximation error between $\SW(\mu, \nu)$ and its discretised counterpart $\SW(\hat\mu_n, \hat\nu_n)$.

In practical and realistic settings,  the only numerically accessible workaround  to optimise through $\SWY$ is a form of discretisation of the set of directions. The first and most common method, due to its efficiency and simplicity, is to minimize $\SWY$ through stochastic gradient descent (SGD): at each time set $t$, $p$ random directions $(\theta_1^{(t)}, \cdots, \theta_p^{(t)})$ are drawn, and a gradient descent step is performed by approximating $\SWY$ by a discrete sum on these $p$ random directions. This method is optimisation-centric, since it does not concern itself with computing the final SW distance and focuses on optimising the parameters.  A second possible discretisation method consists in fixing the $p$ directions $(\theta_1, \cdots, \theta_p)$ once for all and replacing $\SWY$ in the minimization by its Monte-Carlo estimator~\footnote{In this notation the projection axes $\theta_1, \cdots, \theta_p \in \SS^{d-1}$ are written implicitly, the complete notation being $\SWpY(Y; (\theta_i)_{i \in \llbracket 1, p \rrbracket})$ when required.
}
\begin{equation}
  \SWpY := \app{\R^{\npoints \times d}}{\R_+}{Y}{\cfrac{1}{p}\Sum{i=1}{p}\mathrm{W_2^2}(P_{\theta_i} \#\gamma_Y. P_{\theta_i}\#\gamma_Z)}.
\end{equation}
It is important to note that both methods are intuitively tied, since in both cases there is a finite amount of sampled directions. If the SGD method lasts $T$ iterations with $p$ projections every time, it amounts to a specific way of optimising $\mathcal{E}_{pT}$. For this reason, studying $\SWpY$ theoretically is not only interesting in itself as an approximation of $\SWY$, but also yields a better insight on the SGD strategy.

The study of $\SWY$ is also tied with the study of the SW barycentres, which solve the optimisation problem
\begin{equation}\label{eqn:bar}
	\mathrm{Bar}(\lambda_j, \gamma_{Z^{(j)}})_{j \in \llbracket 1, J \rrbracket} = \underset{Y \in \R^{\npoints \times d}}{\argmin}\ \Sum{j=1}{J}\lambda_j\SWY(Y, Z^{(j)}) =: \SWYbar(Y),
\end{equation}
where the notation $\SWY(Y, Z^{(j)})$ reflects the dependency on $Z$ in the definition of $\SWY$ \ref{eqn:SWY}. The regularity and convergence results will immediately be applicable to the barycentre energy \ref{eqn:bar}. While the optimisation results on $\SWY$ and $\SWpY$ will not generalise naturally due to the sum, the SGD convergence results shall still hold. 

%

%
%

%
%

%

As a Monte-Carlo estimator, the law of large numbers yields the point-wise convergence of $\SWpY$ to $\SWY$ if the $(\theta_i)_{i \in \N}$ are i.i.d. of law $\bbsigma$:
\begin{equation}\label{eqn:Sp_pwc}
	\SWpY(Y; (\theta_i)_{i \in \llbracket 1, p \rrbracket}) \xrightarrow[p\rightarrow +\infty]{\mathrm{a.s.}} \SWY(Y).
\end{equation}
For this reason, it is often assumed that numerically, $\SWpY$ and $\SWY$ will behave similarly, which is perhaps why research has been scarce on the landscape of $\SWpY$, the focus remaining on the theoretical properties of the true Sliced Wasserstein Distance.
This section and the next one are dedicated to challenging that assumption.

\subsection{Regularity properties of \texorpdfstring{$\SWpY$}{Sp} and \texorpdfstring{$\SWY$}{S}}

In order to study the regularity of our energies, we first focus on the regularity of $w_\theta$, the 2-Wasserstein distance between two discrete measures projected on the line $\R\theta$:
\begin{equation}
  \label{def:wtheta}
	w_\theta := \app{\R^{\npoints \times d}}{\R}{Y}{\W_2^2(P_\theta\#\gamma_Y, P_\theta\#\gamma_Z)}.
\end{equation}
With this notation, observe that $\SWY$ and $\SWpY$ can be written
\begin{equation}
  \label{eq:E_expectation_notation}
  \SWY(Y) =   \mathbb{E}_{\theta \sim \bbsigma}\left[w_\theta(Y)\right]
\;\;\text{and}\quad \SWpY(Y) = \mathbb{E}_{\theta \sim \bbsigma_p }\left[w_\theta(Y)\right],
\end{equation}
where $\bbsigma_p := \cfrac{1}{p}\Sum{i=1}{p}\delta_{\theta_i}$ for $p$ fixed directions $ (\theta_1, \cdots, \theta_p) \in (\SS^{d-1})^p$.

We now provide an important regularity result about the uniformly locally Lipschitz property of the functions $(w_\theta)_{\theta}$, which will yield easily that our energies $\SWY$ and $\SWpY$ are also locally Lipschitz, a central property in the convergence study of particular SGD schemes on $\SWY$ and $\SWpY$ (see \ref{sec:interpolated_SGD}). To show this result on $(w_\theta)$, we need the following \ref{lemma:WC_stability}, whose proof is provided in~\ref{sec:WC_stability}.

\begin{lemma}[Stability of the Wasserstein cost]\ \label{lemma:WC_stability} Let $\alpha, \oll{\alpha}, \beta, \oll{\beta} \in \Sigma_\npoints$, and $C, \oll{C} \in \R_+^{\npoints\times \npoints}$.
	Denote by $\W(\alpha, \beta; C) := \underset{\pi \in \Pi(\alpha, \beta)}{\inf}\ \pi \cdot C$ the cost of the discrete Kantorovitch problem of cost matrix $C$ between the weights $\alpha, \beta$. We have the following Lipschitz-like inequality:
	\begin{equation}
		\left|\W(\alpha, \beta; C) - \W(\oll{\alpha}, \oll{\beta}; \oll{C})\right| \leq 2\|C-\oll{C}\|_F + \sqrt{2}\|C\|_F \left(\|\alpha - \oll{\alpha}\|_2 + \|\beta - \oll{\beta}\|_2\right).
	\end{equation}
      \end{lemma}

The following regularity property on  the $(w_\theta)$ uses the norm $\|X\|_{\infty, 2} = \underset{k \in \llbracket 1, \npoints \rrbracket}{\max}\ \|x_k\|_2$ on $\R^{\npoints \times d}$. We also denote $D := \npoints \times d$ for convenience.
\begin{prop}
  The $(w_\theta)_{\theta \in \SS^{d-1}}$ are uniformly locally Lipschitz.\label{prop:w_unif_locLip}. More precisely, in a neighbourhood $X \in \R^D$ or radius $r>0$, writing $\kappa_r(X) := 2\npoints(r + \|X\|_{\infty, 2} + \|Z\|_{\infty, 2})$, each $w_\theta$ is $\kappa_r(X)$ Lipschitz, which is to say
	$$\forall X \in \R^D,\; \forall Y, Y' \in B_{\|\cdot\|_{\infty, 2}}(X, r),\; \forall \theta \in \SS^{d-1},\; |w_\theta(Y) - w_\theta(Y')| \leq \kappa_r(X) \|Y-Y'\|_{\infty, 2}.$$

\end{prop}

\begin{proof}
	Let $X \in \R^D,\; Y,Y'  \in B_{\|\cdot\|_{\infty, 2}}(X, r)$, and $\theta \in \SS^{d-1}$. By~\ref{lemma:WC_stability}, we have $|w_\theta(Y) - w_\theta(Y')|$ \\ $\leq 2\|C-C'\|_F$, where for $(k,l) \in \llbracket 1, \npoints \rrbracket^2,\; C_{k,l} := (\theta \cdot y_k - \theta \cdot z_l)^2$, likewise for $C'$. Then:
	\begin{align*}[C - C']_{k,l} &= \left(\theta^T (y_k - y_k')\right)\left(\theta^T (y_k + y_k' - 2z_l)\right)\\
		&\leq \|y_k-y_k'\|_2\|y_k + y_k' - 2z_l\|_2 = \|y_k-y_k'\|_2	\|y_k - x_k + y_k' - x_k + 2z_l + 2x_k\|_2\\
		&\leq \|y_k-y_k'\|_2 \left(2r + 2\|Z\|_{\infty, 2} + 2\|X\|_{\infty, 2}\right).
	\end{align*}
	Finally, $\|C-C'\|_F = \sqrt{\Sum{k,l \in \llbracket 1, \npoints \rrbracket}{}[C - C']_{k,l}^2} \leq 2\npoints(r + \|X\|_{\infty, 2} + \|Z\|_{\infty, 2})\|Y-Y'\|_{\infty, 2}$.

	\vspace{-20pt}

\end{proof}

As a consequence, we deduce immediately that $\SWpY$ and $\SWY$ are locally Lipschitz.
\begin{theorem}\label{thm:locLip} $\SWY$ and $\SWpY$ are locally Lipschitz.
\end{theorem}

\begin{proof}
  Let $X \in \R^D,\ r>0$ and $\mu \in \{\bbsigma, \bbsigma_p\}$. By~\ref{prop:w_unif_locLip}, for any $Y, Y' \in B_{\|\cdot\|_{2, \infty}}(X, r)$,
  $$\left|\mathbb{E}_{\theta \sim \mu}\left[w_\theta(Y)\right] - \mathbb{E}_{\theta \sim \mu}\left[w_\theta(Y')\right] \right|  \le \mathbb{E}_{\theta \sim \mu}\left[ \left| w_\theta(Y) - w_\theta(Y') \right| \right] \le \kappa_r(X)\|Y-Y'\|_{\infty, 2}.$$
\end{proof}

As a locally Lipschitz function,  $\SWY$ is differentiable almost everywhere. The expression of its gradient is quite simple and corresponds  to the simple differentiation of $w_{\theta}$ in the integral, as was shown in~\cite{bonneel2015sliced}. We remind here their result for the sake of completeness, and because the derivative will be useful on several occasions in this paper.
We define $\mathcal{U}$ the open set of matrices with distinct lines
\begin{equation}\label{eqn:U}
	\mathcal{U} =  \left\lbrace (x_1, \cdots, x_\npoints)^T \in \R^{\npoints\times d}\ |\ \forall i \neq j,\; \llbracket 1, \npoints \rrbracket^2,\; x_i \neq x_j \right\rbrace.
\end{equation}

\begin{theorem}[Regularity of $\SWY$, from Bonneel et al.~\cite{bonneel2015sliced} Theorem 1]\label{thm:bonneel_diff}
		$\SWY$ is continuous on $\R^{\npoints \times d}$, and of class $\mathcal{C}^1$ on $\mathcal{U}$.
		There exists $\kappa \geq 1$ such that $\nabla \SWY$ is $\kappa$-Lipschitz on $\mathcal{U}$. For $Y \in \mathcal{U}$, one has the expression:
	\begin{equation}\label{eqn:gradS}
		\cfrac{\partial \SWY}{\partial y_k}(Y) = \cfrac{2}{\npoints}\Int{\SS^{d-1}}{}\theta \theta^T (y_k - z_{\sort{Z}{\theta} \circ (\sort{Y}{\theta})^{-1}(k)}) \dd \bbsigma(\theta),
	\end{equation}
	where for $\theta \in \SS^{d-1}, X \in \mathcal{U}$, and $\sort{X}{\theta} \in \mathfrak{S}_\npoints$ is any permutation such that $\theta \cdot x_{\sort{X}{\theta}(1)} \leq \cdots \leq \theta \cdot x_{\sort{X}{\theta}(\npoints)}$.
\end{theorem}
Proving this theorem requires to be cautious. Firstly, differentiating directly under the integral using standard calculus theorems is impossible, since the integrand is only differentiable on a set $\mathcal{U}_\theta$ which depends on the integration variable $\theta$. Fortunately, these irregularities are smoothed out as $\theta$ rotates, yielding differentiability almost-everywhere. Secondly, the problematic term $\sort{Y}{\theta}$ can be dealt with for $Y\in \mathcal{U}$ by remarking that for any $Y'\ \varepsilon$-close to $Y$, we have $\sort{Y}{\theta} = \sort{Y'}{\theta}$ for every $\theta$ in a certain subset of $\SS^{d-1}$ which is of $\bbsigma$-measure exceeding $1 - C\varepsilon$.

\subsection{Cell structure of \texorpdfstring{$\SWpY$}{Sp}}\label{sec:cells}

In order to further study the optimisation properties of  $\SWpY$ and $\SWY$, we need to exhibit more explicitly the structure of the landscape of $\SWpY$. The semi-concavity of  $\SWpY$ and $\SWY$ will follow, as well as the fact that $\SWY$ is semi-algebraic. We can compute $\SWpY$ by leveraging the formula for 1D Wasserstein distances:
\begin{equation}
	\forall Y \in \R^{\npoints\times d},\quad \SWpY(Y) = \cfrac{1}{\npoints p}\Sum{i=1}{p}\Sum{k=1}{\npoints} \left(\theta_i^T \Big(y_k - z_{\sort{Z}{\theta_i} \circ (\sort{Y}{\theta_i})^{-1}(k)}\Big)\right)^2.
\end{equation}
%
For now we consider $Z$ and the $(\theta_i)$ fixed, and we write $\config(Y) := \left(\config_i(Y)\right)_{i \in \llbracket 1, p \rrbracket}$ where $\config_i(Y) = \sort{Z}{\theta_i} \circ (\sort{Y}{\theta_i})^{-1}$.  Writing $\mathfrak{S}_\npoints $ the set of permutations of $\{1,\cdots,n\}$, $\config_i$ is the element $\sigma$ of  $\mathfrak{S}_\npoints $ which solves the (Monge) quadratic optimal transport between the points $(\theta_i \cdot y_k)_k$ and $(\theta_i \cdot z_{\sigma(k)})_k$. The matching configuration $\config(Y)$ depends implicitly on the fixed directions $(\theta_i)$.

%
Note that the permutations $\sort{Y}{\theta}$ and $\sort{Y}{\theta}$ are not always uniquely defined: for any $\theta \in \SS^{d-1}$, there exists $Y \in \mathcal{U}$ such that $\sort{Y}{\theta}$ is not uniquely defined (take $Y$ such that $\theta \in (y_1 - y_2)^\perp$ for instance). However, for a given set of directions $(\theta_i)$, these permutations are uniquely defined almost everywhere on $\R^{n\times d}$.

A set of interest is $\mathcal{C}_\config = \left\lbrace Y \in \mathcal{U}\ |\  \config(Y) \;\text{is uniquely defined and equal to}\; \config \right\rbrace$, the cell of points $Y$ of configuration $\config$. Writing  $\config = (\config_1, \cdots, \config_p)$, and using the optimality of each $\config_i$, note that each cell $\mathcal{C}_\config$ can be also written as
\begin{equation}\label{eqn:opt_sigma_config_L_linear}
	\mathcal{C}_\config = \left\lbrace Y \in \R^{\npoints \times d}\ \left|\ \forall i \in \llbracket 1, p \rrbracket, \quad \forall \sigma \in \mathfrak{S}_\npoints \setminus \lbrace \config_i \rbrace, \quad \Sum{k=1}{\npoints}z_{\config_i(k)}^T\theta_i\theta_i^T y_k > \Sum{k=1}{\npoints}z_{\sigma(k)}^T\theta_i\theta_i^T y_k \right\rbrace\right. .
\end{equation}
Thus, each $\mathcal{C}_\config$ is an open polyhedral cone, obtained as the intersection of  $p(\npoints! - 1)$ half-open planes.
%
Moreover, the union of these cells $\Reu{\config \in \mathfrak{S}_\npoints^p}{}\mathcal{C}_\config$ is a strict subset of $\mathcal{U}$ (as a consequence of the non uniqueness of the permutations for some $Y$), but is dense in $\R^{\npoints \times d}$. %
These cells are of particular interest since by definition, $\SWpY$ is quadratic on each $\mathcal{C}_\config$,  and can be written
\begin{equation}\label{eqn:cell_quadratic}
	\forall Y \in \mathcal{C}_\config, \; \SWpY(Y) = \cfrac{1}{\npoints p}\Sum{i=1}{p}\Sum{k=1}{\npoints} \left(\theta_i^T \big(y_k - z_{\config_i(k)}\big)\right)^2 =: q_\config(Y).
\end{equation}
Furthermore, the sorting interpretation of the 1D Wasserstein distance allows us to re-write $\SWpY(Y)$ as a minimum of quadratics,
\begin{equation}\label{eqn:min_quadratics}
	\forall Y \in \R^{\npoints\times d}, \; \SWpY(Y) = \underset{\config \in \mathfrak{S}_\npoints^p}{\min}\ q_\config(Y) = q_{\config(Y)}(Y).
\end{equation}

\begin{remark}\label{rem:quadratics}
	To each $Y  = (y_1, \cdots, y_\npoints)^T$ (seen as a $n\times d$ matrix), we can
	%
	associate the column vector $\mathrm{vec}(y) := (y_1^T, \cdots, y_\npoints^T)^T$, which is now a vector of $\R^D = \R^{\npoints\times d}$ without any abuse of notation. We re-write the quadratic from equation~\ref{eqn:cell_quadratic} in standard form: $q_\config(\mathrm{vec}(y)) = \frac{1}{2}\mathrm{vec}(y)^TB\mathrm{vec}(y) - a_\config^T \mathrm{vec}(y) + b$, where:
	$$B := \cfrac{2}{\npoints}\left(\begin{array}{ccc}
		A & 0 & 0 \\
		0 & \ddots & 0 \\
		0 & 0 & A
	\end{array}\right),\; A := \cfrac{1}{p}\Sum{i=1}{p}\theta_i\theta_i^T;\;a_\config := \cfrac{2}{p\npoints}\left(\begin{array}{c}
		\Sum{i=1}{p}\theta_i\theta_i^Tz_{\config_i(1)} \\
		\vdots \\
		\Sum{i=1}{p}\theta_i\theta_i^Tz_{\config_i(\npoints)}
	\end{array}\right);\; b := \cfrac{1}{\npoints}\Sum{k=1}{\npoints}z_k^TAz_k.$$
	Note in particular that only the linear component depends on $\config$.
\end{remark}

Finding the minimum of each quadratic $q_\config$ can be done in closed form, thanks to the computations of \ref{rem:quadratics}. This computational accessibility will be leveraged during our discussions on minimising $Y \longmapsto\SWpY(Y)$ (\ref{sec:Ep_crit_and_bcd}), wherein we shall present the Block Coordinate Descent method (\ref{alg:BCD}), which computes iteratively minima of quadratics in closed form.

\subsection{Consequences of the cell structure on the regularity of \texorpdfstring{$\SWpY$}{Sp} and \texorpdfstring{$\SWY$}{S}}

The cell decomposition presented in \ref{sec:cells} permits to show several additional regularity results.

\begin{prop}$\SWpY$ is quadratic on each cell $\mathcal{C}_\config$, thus of class $\mathcal{C}^{\infty}$ on $\Reu{\config \in \mathfrak{S}_\npoints^p}{}\mathcal{C}_\config$, hence $\mathcal{C}^{\infty}$ a.e..
\end{prop}

The formulation as an infimum of quadratics also allows us to prove that $\SWpY$ is semi-concave, which is an extremely useful property for optimisation.

\begin{prop}$\SWpY$ is $\frac{1}{\npoints}$-semi-concave, i.e. $\SWpY - \frac{1}{\npoints}\|\cdot\|_2^2$ is concave.\label{prop:SWpY_semi_concave}
\end{prop}
\begin{proof}
	Using the notations from \ref{rem:quadratics}, $\SWpY(\mathrm{vec}(y)) = \frac{1}{2}\mathrm{vec}(y)^TB\mathrm{vec}(y) + \underset{\config \in \mathfrak{S}_\npoints^p}{\min}\ a_\config \cdot \mathrm{vec}(y) + b$.

	Now, $\mathrm{vec}(y) \longmapsto \underset{\config \in \mathfrak{S}_\npoints^p}{\min}\ a_\config^T \mathrm{vec}(y) + b$ is concave, as an infimum of affine functions. 
	
	Furthermore, $\frac{1}{2}\mathrm{vec}(y)^TB\mathrm{vec}(y) = \cfrac{1}{\npoints}\Sum{k=1}{\npoints}y_k^TAy_k$, with $A \preceq I_d$, thus $\frac{1}{2}\mathrm{vec}(y)^TB\mathrm{vec}(y) - \frac{1}{\npoints}\|\mathrm{vec}(y)\|_2^2 = \cfrac{1}{\npoints}\Sum{k=1}{\npoints}y_k^T(A - I)y_k$, which defines a concave function of $\mathrm{vec}(y)$.
\end{proof}

The semi-concavity of $\SWpY$ and point-wise convergence allows us to deduce the semi-concavity of $\SWY$:
\begin{prop}$\SWY$ is $\frac{1}{\npoints}$-semi-concave.\label{prop:SWY_semi_concave}
\end{prop}

\begin{proof}
	By \ref{prop:SWpY_semi_concave}, $\forall p \in \N^*,\; \SWpY$ is $\frac{1}{\npoints}$-semi-concave. Let $p \in \N^*,\; Y, Y'\in \R^{\npoints \times d}$ and $\lambda \in [0, 1]$.

	We have $\SWpY((1-\lambda)Y + \lambda Y') - \frac{1}{\npoints}\|(1-\lambda)Y + \lambda Y'\|_F^2 \geq (1-\lambda)\SWpY(Y) + \lambda \SWpY(Y') - \frac{1}{\npoints}\left((1-\lambda)\|Y\|_F^2 + \lambda \|Y'\|_F^2\right)$.

	Taking the limit $p \longrightarrow +\infty$ in this inequality yields the $\frac{1}{\npoints}$-semi-concavity of $\SWY$.
\end{proof}

The cell formulation also allows us to show that $\SWpY$ is semi-algebraic, which means that it can be written using a finite number of polynomial expressions. This result induces strong optimisation results akin to semi-concavity for our purposes.

\begin{prop}$\SWpY$ is semi-algebraic.\label{prop:SWpY_semi_algebraic}
\end{prop}

\begin{proof}
	First, we recall the definition of a semi-algebraic set (\cite{Wakabayashi_semialgebraic}, Definition 1). $S \subset \R^D$ is \textit{semi-algebraic} if it can be written $S = \Reu{n=1}{N}\Inter{m=1}{M}A_{n,m}$  where $(A_{n, m})_{\substack{n \in \llbracket 1, N \rrbracket \\ m \in \llbracket 1, M \rrbracket}}$ is a finite family of sets such that $A_{n,m} = \lbrace X \in \R^D\ |\ p_{n,m}(X) \geq 0\rbrace$ or $A_{n,m} = \lbrace X \in \R^D\ |\ p_{n,m}(X) = 0\rbrace$, with $p_{n,m}$ being $D$-variate polynomials with real coefficients. A \textit{semi-algebraic} function is a function whose graph is a semi-algebraic set.

    First, we shall prove that the set $G := \left\lbrace (X, \SWpY(X))\ |\ X \in \mathcal{U}_\Theta\right\rbrace$ is semi-algebraic, where $\mathcal{U}_\Theta := \Reu{\config \in \mathfrak{S}_\npoints^p}{}\mathcal{C}_\config$. Observe that
    %
    $G = \Reu{\config \in \mathfrak{S}_\npoints^p}{}   \left\lbrace (X, y) \in \R^{D+1}, X \in \mathcal{C}_\config \text{ and  } y =  q_\config(X).\right\rbrace  $.

	The function $q_\config$ is quadratic, thus polynomial, and the cells  $\mathcal{C}_\config$ are intersections of a finite number of half planes, so we conclude that $G$ is semi-algebraic.
	%

	The closure of $\mathcal{U}_\Theta$ verifies $\oll{\mathcal{U}_\Theta} = \R^D$, furthermore, since $\SWpY$ is continuous on $\R^D$ (by~\ref{thm:bonneel_diff}), the closure of $G$ is exactly the graph of $\SWpY$. Now by~\cite{Wakabayashi_semialgebraic}, Lemma 4, since $G$ is semi-algebraic, then $\oll{G}$ is also semi-algebraic. As a conclusion, $\SWpY$ is a semi-algebraic function.
\end{proof}

\subsection{Convergence of \texorpdfstring{$\SWpY$}{SWpY} to \texorpdfstring{$\SWY$}{SWY}}

We have already seen that $\SWpY(Y)$ converges to $\SWY(Y)$ almost surely when  $p\rightarrow +\infty$.
In practice, since we want to optimise through $\SWpY$ as a surrogate for $\SWY$, we would wish for the strongest possible convergence. Below, we show almost-sure \textit{uniform} convergence over any compact, which is substantially better than point-wise convergence. Note that this stronger mode of convergence is unfortunately still too weak to transport local optima properties.

\begin{theorem}[Uniform Convergence of $\SWpY$]\label{thm:Sp_cvu_S}\ Let $\mathcal{K} \subset \R^{\npoints\times d}$ compact.

	We have $\P\left(\|\SWpY-\SWY\|_{\infty, \mathcal{K} } \xrightarrow[p \rightarrow +\infty]{} 0\right) = 1,\quad\quad$ where for $f \in \mathcal{C}(\mathcal{K} , \R),\; \|f\|_{\infty, \mathcal{K} } := \underset{x \in \mathcal{K} }{\sup}\ |f(x)|$.
\end{theorem}

\begin{proof}
	We shall temporarily write $\SWpY(Y) = \SWpY(Y; \Theta)$ to illustrate the dependency on the random variable $\Theta := (\theta_i)_{i \in \N^*}$ on a probabilistic space $(\Omega, \mathcal{A}, \P)$ with values in $(\SS^{d-1})^\N$.
	By point-wise almost-sure convergence, for any fixed $Y \in \R^{\npoints\times d}$, there exists a $\P$-null set $\mathcal{N}_Y$ such that for every $\omega \in \Omega \setminus \mathcal{N}_Y$, the deterministic real number $\SWpY(Y; \Theta(\omega))$ converges to $\SWY(Y)$.
	Let $\mathcal{D} := \mathcal{K}  \cap \Q^{\npoints\times d}$, which is dense in $\mathcal{K} $ and countable. Let $\mathcal{N} := \Reu{Y \in \mathcal{D}}{}\mathcal{N}_Y$: $\mathcal{N}$ is $\P$-null as a countable union of $\P$-null sets.

	Fixing $\omega \in \Omega \setminus \mathcal{N}$, we have $\forall Y \in \mathcal{D}, \quad \SWpY(Y; \Theta(\omega)) \xrightarrow[p\rightarrow+\infty]{\quad} \SWY(Y)$, thus point-wise convergence on $\mathcal{D}$ of the (now) deterministic function $\SWpY(\cdot; \Theta(\omega))$ to $\SWY$. Now, a consequence of \ref{prop:w_unif_locLip} is that the family of functions $\left(Y\rightarrow \SWpY( Y ; \Theta')\right)_{\Theta' \in (\SS^{d-1})^p}$ is equi-continuous on any compact (thus on $\mathcal{K}$). As a consequence, the point-wise convergence on $\mathcal{D}$ implies the uniform convergence of $\SWpY(\cdot; \Theta(\omega))$ to $\SWY$ on $\oll{\mathcal{D}} = \mathcal{K}$ (a detailed presentation of this classic result can be found in \cite{levy2012elements}, Proposition 3.2). This holds for any event $\omega \in \Omega \setminus \mathcal{N}$, with $\P(\Omega \setminus \mathcal{N}) = 1$, thus the uniform convergence is almost-sure.
\end{proof}

\subsection{Illustration in a simplified case}\label{sec:L2}

Let us illustrate $\SWY$ in a simple case, that was briefly presented in Bonneel et al.~\cite{bonneel2015sliced}, in order to grasp the difficulties at hand. This example is interesting for understanding the difficulty of performing computations with $\SWY$ and $\SWpY$. Let $z_1 = (0,-1)^T$ and $z_2 = (0,1)^T$. Instead of computing $\SWY(Y)$ for any $Y \in \R^{2\times 2}$, we simplify by assuming $Y = (y, -y)^T = (y_1, y_2)^T$. We will assume further $y\neq 0$ and write $y =(u,v)^T$. The interested reader may seek the computations in \ref{sec:L2_E}. With these notations, we can show that
\begin{equation}
	\SWY(Y) = \SW_2^2(\gamma_Y, \gamma_Z)=\frac{u^2+v^2}{2} + \frac{1}{2} - \frac{2}{\pi}\left(|u| + |v|\Arctan\left|\frac{v}{u}\right|\right).
\end{equation}
%
%
%
%
%
%
For $\W_2^2$, one may show (see \ref{sec:L2_W} for the computations) that $\W_2^2(\gamma_Y, \gamma_Z) = u^2 + (|v|-1)^2$ in this setting.
We compare $\SWY$ and $\W_2^2$ in ~\ref{fig:comp_sym}.
% Figure environment removed

Notice differences in regularity. $\SWY$ is smooth on the open set $\mathcal{U}$ (defined in \ref{eqn:U}) of the $Y\in \R^{\npoints \times d}$ with distinct points (this is known in general,~\cite{bonneel2015sliced}), but is not differentiable anywhere in $\mathcal{U}^c$. Here this is clear at $(0, 0)$. Furthermore, $\SWY$ presents two saddle points, $(\pm\frac{2}{\pi}, 0)$. In \ref{sec:E_crit}, we shall study the critical points of $\SWY$ in full generality. Finally, $\W_2^2$ presents the typical landscape of the minimum of two quadratics.

We now move to computing $\SWpY$ in this setting. In the case $\npoints=2$, a significant simplification occurs since $\mathfrak{S}_2 = \lbrace I, (2, 1)\rbrace$, and we express a simple formula for the cells in the Appendix, see \ref{sec:L2_Ep}. We illustrate the cell structure in~\ref{fig:SWpY_sym_p3}.

% Figure environment removed

Notice that as $p$ increases, the number of new strict local optima also increases, however their associated cells become very small, thus one may hope that the probability of ending up in a strict local optimum would decrease as $p$ increases. Specifically, in the heatmap visualisation, one may notice 6 large cells for $p=3$, and for $p=10$, two large cells corresponding to the global optima, and 8 small cells which may present local optima. This observation suggests that as $p\longrightarrow +\infty$, the total size of cells containing local optima decreases, and thus the probability of a numerical scheme converging to a local optimum decreases as well. Moreover, it is clear for the landscape $\SWpY$ with $p=3$ that the critical points (points of differentiability with a null gradient) are exactly the minima of the cell quadratics. Remark that a cell may not contain the minimum of its quadratic, which is why we will refer to cells containing their minimum as "stable" (as is the case for all cells in $p=3$ illustration, but seemingly not for $p=10$). 
%

%
%
%
%
%
%

As is suggested by \ref{fig:SWpY_sym_p3}, even with a large number of projections $p$ compared to the dimension $d$, the presence of strict local optima may prevent numerical solvers from converging to the global optimum $\gamma_Y = \gamma_Z$. This practical concern motivates the study of the landscapes $\SWY$ and $\SWpY$, which is the topic of \ref{sec:crit}.
