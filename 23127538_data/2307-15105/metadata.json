{
  "title": "Detecting Morphing Attacks via Continual Incremental Training",
  "authors": [
    "Lorenzo Pellegrini",
    "Guido Borghi",
    "Annalisa Franco",
    "Davide Maltoni"
  ],
  "submission_date": "2023-07-27T17:48:29+00:00",
  "revised_dates": [],
  "abstract": "Scenarios in which restrictions in data transfer and storage limit the possibility to compose a single dataset -- also exploiting different data sources -- to perform a batch-based training procedure, make the development of robust models particularly challenging. We hypothesize that the recent Continual Learning (CL) paradigm may represent an effective solution to enable incremental training, even through multiple sites. Indeed, a basic assumption of CL is that once a model has been trained, old data can no longer be used in successive training iterations and in principle can be deleted. Therefore, in this paper, we investigate the performance of different Continual Learning methods in this scenario, simulating a learning model that is updated every time a new chunk of data, even of variable size, is available. Experimental results reveal that a particular CL method, namely Learning without Forgetting (LwF), is one of the best-performing algorithms. Then, we investigate its usage and parametrization in Morphing Attack Detection and Object Classification tasks, specifically with respect to the amount of new training data that became available.",
  "categories": [
    "cs.CV",
    "cs.LG"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15105",
  "pdf_url": "https://arxiv.org/pdf/2307.15105v1",
  "comment": "Paper accepted in IJCB 2023 conference",
  "num_versions": null,
  "size_before_bytes": 718023,
  "size_after_bytes": 163332
}