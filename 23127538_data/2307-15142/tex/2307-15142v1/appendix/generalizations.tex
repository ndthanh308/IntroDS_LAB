\section{Generalizations}\label{sec:generalizations}
In this section, we consider two directions in which our model can be extended. First, we consider a model in which users can prefer multiple item types at a time. Second, we consider a model in which users and items are both represented by vector embeddings, a common paradigm in recommender systems.

\subsection{Preference for multiple item types}

In this section, we consider an extension of our model in which a user can prefer multiple types of items. In particular, we focus on the case when $m=2$ and when the user prefers only type $1$ with probability $p_1$, only type $2$ with probability $p_2$, and both types with probability $p_{12}.$ We also assume that an item of type $i$ satisfies a user that prefers type $i$ independently with probability $q$. We consider when $k=1$, when the user can only use one item. Then, we would like to minimize the probability of having no satisfying items:
\begin{equation}
    p_1(1-q)^{a_1} + p_2(1-q)^{a_2} + p_{12}(1-q)^n,
\end{equation}
where $a_1 + a_2 = n$.
This is equivalent to minimizing
\begin{equation}
    p_1(1-q)^{a_1} + p_2(1-q)^{a_2},
\end{equation}
which is mathematically equivalent to \Cref{thm:general}(i). Thus, we have that as $n$ grows large, both item types are represented equally, irrespective of $p_1, p_2,$ and $p_{12}$---in other words, allowing for the possibility that the user prefers multiple item types does not change the result in this setting.

The setup here can be naturally generalized to the case in which there are more than two types, and where item values can come from distributions other than Bernoulli. We leave these generalizations to future work.


\subsection{User and item embeddings} In this section, we consider the setting in which users and items each correspond to vector embeddings, and where the likelihood a user $u$ is satisfied by an item $v$ is a function of their cosine distance. Suppose that a user has preference $u$ drawn according to a probability measure $\mu$ supported on the unit $d-$dimensional sphere $S_d\subset \RR^d.$ Further suppose that for a movie $v\in S_d,$ the probability that a user is not satisfied by the movie is $p(u,v) = q(\norm{u-v})$, a function of the cosine distance between $u$ and $v$.

If the goal is to maximize the probability a user is satisfied by at least one item, what is the optimal choice of items to recommend as the number of recommendations we can make grows large? Here, we will show that items should be chosen ``uniformly'' from $S_d$---a result that may seem surprising as it is independent of the distribution of user preferences, and which can be viewed as an analog of \Cref{thm:general}(i).

To make things precise and tractable, rather than consider the recommendation of individual items, we will focus on the recommendation of a ``distribution of items.'' This is analogous to making a continuous relaxation of the discrete item recommendation problem. For a set of items $V = \{v_1,\cdots,v_n\},$ the probability a user with preference drawn according to a probability measure $\mu$ does not like any item in $V$ is
\begin{equation}
    \int_{S_d} \mu(u) \prod_{v\in V} p(u,v) \,du = \int_{S_d} \mu(u) \exp \sum_{v\in V} \log p(u,v) \,du.
\end{equation}
Then for a density function $\alpha: S_d \rightarrow [0,\infty)$, we can consider the expression
\begin{equation}
    \int_{S_d} \mu(u) \exp \left[n\int_{S_d} \alpha(v) \log p(u,v)\,dv\right] \,du,
\end{equation}
which can be thought of splitting the $n$ item recommendations continuously across $S_d$ according to the density function $\alpha$. We can think of $\alpha$ as representing some ``profile'' of items to show. Going forward, we consider optimal distributions rather than optimal discrete sets of items.

\begin{proposition}
Consider a non-constant function $p(u,v): S_d \times S_d \rightarrow (0,1]$, interpreted as the probability that item $v$ does not satisfy a user with preference $u$, such that $p(u,v) = q(\norm{u-v})$ can be expressed as a function of the cosine distance between $u$ and $v$.
Then let $\mu$ be a probability measure with support $S_d$, representing the distribution of user preferences. Then for a probability measure $\alpha$ on $S_d$, define
\begin{equation}
    \Gamma(\alpha) = \lim_{n\rightarrow \infty}\frac{1}{n}\log \int_{S_d} \mu(u) \exp \left[n \int_{S_d} \alpha(v)\log p(u,v)\, dv\right]\,du.
\end{equation}
Then
\begin{equation}
    \Gamma(\pi) \in \inf_{\alpha} \Gamma(\alpha),
\end{equation}
where $\pi$ is the uniform probability measure over $S_d$.
\end{proposition}

\begin{proof}
Let
\begin{equation}
    \rho(u;\alpha) = \int_{S_d} \alpha(v)\log p(u,v)\,dv.
\end{equation}
Then
\begin{equation}
    \Gamma(\alpha) = \lim_{n\rightarrow\infty} \frac{1}{n} \log \int_{S_d} e^{n\rho(u;\alpha)} \mu(u)\, du = \lim_{n\rightarrow\infty} \frac{1}{n} \log \int_{S_d} e^{n\rho(u;\alpha)}\, du = \sup_{u\in S_d} \rho(u;\alpha),
\end{equation}
where the final equality follows from the Laplace principle from large deviations theory. Now note that
\begin{align}
    \int_{S_d} \rho(u;\alpha)\,du &= \int_{S_d} \int_{S_d} \alpha(v) \log p(u,v) \,dv\,du\\
    &= \int_{S_d} \alpha(v) \int_{S_d} \log p(u,v) \,du\,dv \\
    &= \int_{S_d} \alpha(v)C\, dv\\
    &= C,
\end{align}
where the second to last equality follows from the observation that
\begin{equation}
    \int_{S_d} \log p(u,v)\, du = \int_{S_d} \log q(\norm{u-v})\, du = C
\end{equation}
for a constant $C$ independent of $v$.
Therefore, there exists $u$ such that $\rho(u;\alpha) \ge \frac{C}{m(A)},$ so $\sup_{u\in A}\rho(u;\alpha) \ge \frac{C}{m(A)}.$ Now note that when $\pi$ is the uniform probability measure over $A$, we have
\begin{equation}
    \rho(u;\pi) = \int_{S_d} \pi(v) \log p(u,v) \,dv = \frac{C}{m(A)}
\end{equation}
for all $u$, so $\sup_{u\in A}\rho(u;\pi) = \frac{C}{m(A)}.$ So $\Gamma(\pi) = \inf_\alpha \Gamma(\alpha).$
\end{proof}