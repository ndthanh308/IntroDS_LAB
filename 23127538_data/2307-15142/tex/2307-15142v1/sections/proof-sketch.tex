\section{Sketch of Proofs}\label{sec:proof-sketch}
We now sketch the proof of Theorem 1(ii). (The general strategy applies to the rest of Theorem 1, as well as Theorem 2 and Theorem 3.) First, recall the general setup in Theorem 1, where the conditional item values $X_i^{(t)}$ are drawn i.i.d. from a shared distribution $\DD$. In other words, a user prefers type $t\in [m]$ with probability $p_t$ such that the user prefers exactly one type of item, and conditioned on the user preferring type $t$, the value of an item of that type is drawn i.i.d. from $\DD$. We are interested in analyzing, depending on $\DD$, the composition of $S_{n,k}$, the set of $n$ items maximizing the expected sum of the $k$ highest value items in the set. If $S_{n,k}$ contains $a_t^{(n)}$ items of type $t$, we need to analyze
\begin{equation}\label{eq:lim}
\lim_{n\rightarrow \infty} r_t(S_{n,k}) = \lim_{n\rightarrow \infty} \frac{a_t^{(n)}}{n}.
\end{equation}
We first provide an expression for the expected sum of the $k$ highest value items in a set $S$ with $a_t$ items of type $t$. The following definition will be useful.
\begin{definition}
    Define $\mu_\DD(i,a)$ to be the expected value of the $i$-th order statistic\footnote{The $i$-th order statistic of $n$ random variables is the $i$-th smallest of the $n$ realized values.} of $a$ random variables drawn i.i.d. from $\DD$. (Thus, $\mu_\DD(1,a)$ is the expected minimum of $a$ i.i.d. draws from $\DD$ and $\mu_\DD(a,a)$ is the expected maximum.)
\end{definition}
Then conditioned on the user preferring type $t$, the expected sum of the $k$ highest value of items in $S$ is equal to
   $h(a_t) := \sum_{i=1}^{\min\{k, a_t\}} \mu_\DD(a_t-i+1,a_t),$
which follows from the linearity of expectation. Therefore, the expected sum of the $k$ highest value items in $S$ is $\sum_{t=1}^m p_t h(a_t)$. Define $A_n$ to be the set of tuples of non-negative integers whose entries sum to $n$. Then
$(a_1^{(n)}, a_2^{(n)}, \cdots, a_m^{(n)}) = \argmax_{(a_1,\cdots,a_m)\in A_n} \sum_{t=1}^m p_t h(a_t).$

We can then determine the limit in \eqref{eq:lim} given asymptotic information about $h$. In \Cref{lem:fennel} in the appendix, we develop general technical machinery for this task. Below, we state \Cref{lem:fennel}(ii), which can be used to prove Theorem 1(ii).
\begin{mylem}{\ref{lem:fennel}(ii)}
If $h$ is monotonically increasing and there exist constants $A,B>0$ and $\sigma<0$ such that $\lim_{a\rightarrow \infty} \frac{A-h(a)}{Ba^{\sigma}} = 1,$ then
$\lim_{n\rightarrow \infty} \frac{a_t^{(n)}}{n} = \frac{p_t^{\frac{1}{1-\sigma}}}{\sum_{i=1}^m p_i^{\frac{1}{1-\sigma}}}.$
\end{mylem}
Then, considering $\DD$ as in Theorem 1(ii), we can prove the necessary asymptotic result about $h$:
\begin{lemma}\label{lem:bob}
If $\DD$ has support bounded from above by $M$ with pdf $f_\DD$ such that
$\lim_{x\rightarrow M} \frac{f_\DD(x)}{(M-x)^{\beta-1}} = c$
for some $\beta, c>0$, then
$\lim_{a\rightarrow \infty} \frac{Mk - h(a)}{Ba^{-\frac{1}{\beta}}} = 1.$
\end{lemma}
Combining \Cref{lem:bob} with \Cref{lem:fennel}(ii), with $\sigma = -\frac{1}{\beta}$, we show that for $\DD$ as in Theorem 1(ii),
\begin{equation}
    \lim_{n\rightarrow \infty}\frac{a_t^{(n)}}{n} = \frac{p_t^{\frac{\beta}{\beta+1}}}{\sum_{i=1}^m p_i^{\frac{\beta}{\beta+1}}}.
\end{equation}
