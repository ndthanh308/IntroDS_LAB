

% Figure environment removed


% Please add the following required packages to your document preamble:
% \usepackage{multirow}

% \section{Experiments}
% We first evaluate the models on images acquired using both the internal ISP of the mobile phone and an external processing pipeline implemented on a computer. Furthermore, we investigate the performance gap between the internal ISP processed image and the images from external ISP, by decomposing the post-processing steps for analyzing the performance degradation.
% \subsection{Data Preparation}
% We evaluate performance on both raw images and images processed by the mobile phone's internal ISP. For raw images, we convert flare-corrupted images and their ground truth pairs to RGB images using a customized external processing pipeline implemented in MATLAB, denoted as \textit{RAW2RGB} images. The external pipeline comprises black level correction, white balancing, demosaicing, and color space conversion modules, without employing denoising or post-processing methods such as sharpening or compression. Images processed by the internal ISP are denoted as \textit{ISPRGB} images. We apply this data processing to both scattering and reflective flare images.

% For the collected $2,200$ raw scattering flares pairs, we conduct light source detection to locate the position of the light sources and crop the $2,200$ high-resolution raw image pairs into $30,000$ flare-corrupted pairs with a resolution of $512 \times 512$, using $200$ pairs for evaluation. For  and $1,100$ raw reflective flares pairs, we use them to generate $2,100$ pairs with a resolution of $1024 \times 1024$ for training, with $50$ pairs used for evaluation. We apply the same division scheme to both RAW2RGB and ISPRGB data, respectively.

% \subsection{Baselines on the Dataset}

% \subsubsection{Experiment Settings}
% Regarding comparison schemes, early works \cite{chabert2015automated, asha2019auto,vitoria2019automatic} focused on detecting lens flares based on intensity or location and recovering them using inpainting techniques. However, these solutions are not robust in flare-corrupted area detection, and more importantly, they are limited by the type of flare. They can handle in-focus reflective flares resulting in spots but struggle with out-of-focus flares, which appear transparent, and also scattering flares. Therefore, we assess the performance of state-of-the-art data-driven flare removal methods.

% For neural network training, we follow the network settings in \cite{wu2021train} and \cite{dai2022flare7k} and \cite{dai2023nighttime}. For scattering flare, we use the released code and data from \cite{wu2021train} to train a model for evaluation, as their model is not available. For Flare7K \cite{dai2022flare7k} and Flare7K++ \cite{dai2023flare7k++}, we evaluate the performance of the pre-trained Uformer \cite{wang2022uformer} model. For reflective flare we shows the performance of the models from Flare7K \cite{dai2022flare7k} and Bracket Flare \cite{dai2023nighttime}. We then train the networks with the collected data, with scattering flare and reflective data respectively. The results are tabulated in Table.~\ref{tab: results}.


% \subsubsection{Qualitative Comparison}
% We first evaluate the performance of recent flare removal approaches on both ISPRGB and RAW2RGB data for reflective and scattering flare images. We observe that recent models perform better on RAW2RGB images due to their higher quality. 

% For reflective flares, the U-Net from Wu \etal \ \cite{wu2021train} fails to accurately classify the flare region for restoration, as illustrated in Fig. \ref{fig: visual results reflective}. This issue stems from its training data, which predominantly consists of scattering flares but lacks sufficient reflective flares. We also observe that light-source blending approaches, which segment all light sources, perform flare removal and image blending to merge the results back into the segmented images, may misclassify the flare, leading to visual artifacts. For example, in the first row of Fig.~\ref{fig: visual results reflective}, Wu \etal \ \cite{wu2021train} misclassify a portion of the cloud as a flare, resulting in improper color restoration. The Uformer from Flare7K \cite{dai2022flare7k}, trained with synthetic reflective and scattering flare data also have this problem but it is improved in Flare7K++ \cite{dai2023flare7k++} due to the improving training pipeline. However, as missing out-of-focus data in Bracket Flare \cite{dai2023nighttime}, it can identify the in-focus area to some extend but struggles to resolve the transparent, out-of-focus reflective region, as emphasized in the second row of Fig. \ref{fig: visual results reflective}. In terms of the proposed model, as we also include out-of-focus data for training, this problem is better resolved.

% For scattering flares, recent models are capable of restoring local scattering flares, as demonstrated in the third row of Fig.\ref{fig: visual results scattering}. As using more real image data, Flare7 However, these models struggle to handle global flare affecting the global contrast of images, as seen in the first and last rows of Fig.\ref{fig: visual results scattering}, which are more common in daily life. We include both local and global degradation data for training and improve the generalization performance of the existing approach.


% \subsubsection{Quantitative Comparison}
% We use peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM)  \cite{wang2004image}, and learned perceptual image patch similarity (LPIPS) \cite{zhang2018unreasonable} to compare different schemes quantitatively. We tabulated the results in Table~\ref{tab: results}, the overall image quality obtained with internal ISP is lower than that of images obtained using an external pipeline on raw data. 
% From the evaluation metrics the improvement of the generalization ability to global artifacts can be recognized.

% \subsection{Investigating Critical Processing Step}
% \subsubsection{Experiment settings}
% From the previous section, we notice that there is a performance gap between the \textit{RAW2RGB} and \textit{ISPRGB} data across different testing models and differnt types of flare. To understand what operation causes this gap, we perform additional experiments for investigation. Compared with the \textit{RAW2RGB} data, \textit{ISPRGB} data undergo additional processing steps, including denoising, sharpenging and JPEG compression. Therefore, we consider the \textit{RAW2RGB} data as a baseline and adding the following layers in order as operations in the ISP to investigate the performance gain or degradation of different operations:

% \begin{itemize}[leftmargin=0.5cm]
%     \item Denoise: The denoising step in the ISP could be performed at the early stage, such as after the demosaicking step, or in between ISP operations. Therefore we consider denoising as the first operation of the pipeline. We use the medium size of NAFNet \cite{chen2022simple} that has width of 32 as denoiser. The network is trained on SIDD image dataset and has a good trade-off in terms of inference efficiency and denoising performance.
%     \item Sharpen: The sharpening operator on the mobile phones from different manufactures can be different and remain unknown. Therefore to mimic this operator in the ISP, we use a USM sharpening operator with dynamic weight in between $[0.5, 2]$.
%     \item Compression: For most of mobile phones, JPEG format is used for compression at the last step of ISP. Therefore we use DiffJPEG \cite{shin2017jpeg} as a compression operator in this setting. We consider medium level of compression where the compression quality is randomly choose from $[40, 60]$.
% \end{itemize}


\begin{table*}[ht]
\caption{Quantitative results on reflective and scattering flare removal for the two types of data. PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable} are used for evaluation. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better.}
 % \resizebox{0.7\linewidth}{!}{
\begin{tabular}{ccccccccc}
\hline
Data &
  Flare Type &
  Metric &
  Input &
  Wu \etal \    \cite{wu2021train} &
  Flare7K \cite{dai2022flare7k} &
  Bracket Flare \cite{dai2023nighttime} &
  Flare7K++  \cite{dai2023flare7k++} &
  Ours \\ \hline
\multirow{6}{*}{RAW2RGB} & \multirow{3}{*}{Reflective} & PSNR$\uparrow$    & 34.034 & 25.810 & 30.356 & 34.172 & $-$    & \textbf{35.742} \\
                         &                             & SSIM$\uparrow$    & 0.944  & 0.834  & 0.927  & 0.924  & $-$    & \textbf{0.950}  \\
                         &                             & LPIPS$\downarrow$ & 0.046  & 0.152  & 0.073  & 0.136  & $-$    & \textbf{0.035}  \\ \cline{2-9} 
                         & \multirow{3}{*}{Scattering} & PSNR$\uparrow$    & 20.776 & 22.673 & 21.400 & $-$    & 22.881 & \textbf{26.678} \\
                         &                             & SSIM$\uparrow$    & 0.688  & 0.722  & 0.692  & $-$    & 0.701  & \textbf{0.749}  \\
                         &                             & LPIPS$\downarrow$ & 0.215  & 0.250  & 0.209  & $-$    & 0.190  & \textbf{0.145}  \\ \hline
\multirow{6}{*}{ISPRGB}  & \multirow{3}{*}{Reflective} & PSNR$\uparrow$    & 31.800 & 31.265 & 32.334 & 32.158 & $-$    & \textbf{33.611} \\
                         &                             & SSIM$\uparrow$    & 0.956  & 0.953  & 0.955  & 0.938  & $-$    & \textbf{0.959}  \\
                         &                             & LPIPS$\downarrow$ & 0.050  & 0.056  & 0.051  & 0.090  & $-$    & \textbf{0.040}  \\ \cline{2-9} 
                         & \multirow{3}{*}{Scattering} & PSNR$\uparrow$    & 16.558 & 16.774 & 16.982 & $-$    & 17.224 & \textbf{20.556} \\
                         &                             & SSIM$\uparrow$    & 0.557  & 0.722  & 0.561  & $-$    & 0.566  & \textbf{0.648}  \\
                         &                             & LPIPS$\downarrow$ & 0.324  & 0.323  & 0.318  & $-$    & 0.308  & \textbf{0.230}  \\ \hline
\end{tabular}
\label{tab: results}
% \vspace{-5mm}
\end{table*}

% \section{Experiments}
% This section evaluates the performance of flare removal models on images processed by both the internal ISP of a mobile phone and an external processing pipeline implemented on a computer. We investigate the performance gap between these two processing methods by analyzing the impact of different processing steps.

% \subsection{Data Preparation}
% Our evaluation encompasses both raw images and images processed by the mobile phone's internal ISP. For raw images, we convert flare-corrupted images and their corresponding ground truth pairs to RGB images using a custom external processing pipeline implemented in MATLAB, referred to as \textit{RAW2RGB}. This pipeline includes black level correction, white balancing, demosaicing, and color space conversion modules, excluding any denoising or post-processing methods like sharpening or compression. Images processed by the internal ISP are denoted as \textit{ISPRGB} images. Both scattering and reflective flare images undergo this data processing.

%  For scattering flares, we perform light source detection to locate the light sources and crop the high-resolution raw image pairs into flare-corrupted pairs with a resolution of $512\times512$. The detection algorithm is adapted from \cite{wu2021train} with several improvements to address its limitations, particularly its tendency to misclassify backgrounds as light sources in indoor images with significant white areas. First, we manually mask the background in each ground truth image to ensure more accurate light source detection. In addition, morphological operations are utilized to clean up the detection masks. Finally, we transitioned from a single light source detection to a multi-light source approach to better reflect the complexity of real-world images.
%  For reflective flares, we generate pairs with a resolution of $1024\times1024$ for training. This data division scheme applies to both \textit{RAW2RGB} and \textit{ISPRGB} data.
 
% \subsection{Evaluations on the Dataset}
% \subsubsection{Experiment Settings}
% We assess the performance of state-of-the-art data-driven flare removal methods.
% For neural network training, we adopt the network settings from previous works \cite{wu2021train, dai2022flare7k, dai2023nighttime}. For scattering flares, as the model from Wu \etal \ is not available, we train a model based on the released code and data for evaluation purposes. For Flare7K \cite{dai2022flare7k} and Flare7K++ \cite{dai2023flare7k++}, we evaluate the pre-trained Uformer model \cite{wang2022uformer}. For our training, we follow the settings from \cite{dai2023flare7k++} for scattering flare.
% For reflective flares, we present the performance of models from Flare7K \cite{dai2022flare7k} and Bracket Flare \cite{dai2023nighttime}. We train the networks as \cite{dai2023nighttime} with our collected data, separately for scattering and reflective flares. The results are presented in Table \ref{tab: results}. 

\section{Experiments}
This section evaluates the performance of flare removal models using images processed by both the internal ISP of a mobile phone and an external processing pipeline on a computer. We explore the differences in performance between these two processing methods by analyzing the impact of each processing step.

\subsection{Data Preparation}
Our evaluation includes both raw images and those processed by the mobile phone's internal ISP. For raw images, we convert flare-corrupted images and their corresponding ground truth pairs into RGB images using a custom MATLAB pipeline, \textit{RAW2RGB}. This pipeline performs black level correction, white balancing, demosaicing, and color space conversion, but excludes denoising or post-processing techniques like sharpening or compression. These images are referred to as \textit{RAW2RGB}. Images processed by the internal ISP are denoted as \textit{ISPRGB}. Both scattering and reflective flare images undergo these processing steps.

For scattering flares, we utilize a light source detection algorithm to identify light sources and crop the high-resolution raw image pairs into $512\times512$ flare-corrupted pairs. This detection algorithm, adapted from \cite{wu2021train}, includes enhancements to reduce background misclassification in images with prominent white areas. We manually mask the background in each ground truth image to improve accuracy, use morphological operations to refine the detection masks, and employ a multi-light source detection approach to better represent complex real-world scenes. For reflective flares, we prepare pairs at a resolution of $1024\times1024$. Both \textit{RAW2RGB} and \textit{ISPRGB} datasets are processed in this manner.

\subsection{Evaluations on the Dataset}
\subsubsection{Experiment Settings}
We assess the performance of cutting-edge flare removal techniques. Training for scattering flares follows the network settings from prior studies \cite{wu2021train, dai2022flare7k, dai2023nighttime}. Since the model from Wu \etal is unavailable, we train a new model using their released code and data. For the Flare7K \cite{dai2022flare7k} and Flare7K++ \cite{dai2023flare7k++} datasets, we evaluate the pre-trained Uformer model \cite{wang2022uformer}. Training for reflective flares involves models from Flare7K \cite{dai2022flare7k} and Bracket Flare \cite{dai2023nighttime}, using our collected data for separate treatments of scattering and reflective flares. Results are documented in Table \ref{tab: results}.

\subsubsection{Qualitative Comparison}
We first evaluate the performance of recent flare removal methods on both ISPRGB and RAW2RGB data for reflective and scattering flare images. We observe that these models generally perform better on RAW2RGB images due to their higher quality.


For reflective flares, the U-Net model from Wu \etal \  \cite{wu2021train} exhibits difficulties in accurately classifying the flare region for restoration, as shown in Fig.~\ref{fig: visual results reflective}. This issue arises from the model's training data, which primarily consists of scattering flares and lacks sufficient reflective flare examples. Additionally, light-source blending approaches, which segment all light sources and perform flare removal and image blending to merge the results back into the segmented images, may misclassify flares, leading to visual artifacts. For instance, in the second row of Fig.~\ref{fig: visual results reflective}, Wu \etal \ \cite{wu2021train} misclassify a portion of the cloud as a flare, resulting in inaccurate color restoration. The Uformer model from Flare7K \cite{dai2022flare7k}, trained with synthetic reflective and scattering flare data, also suffers from this problem, but it is improved in Bracket Flare \cite{dai2023nighttime} due to an enhanced training pipeline. However, due to the lack of out-of-focus data in Bracket Flare \cite{dai2023nighttime}, it can identify the in-focus area to some extent but struggles to resolve the transparent, out-of-focus reflective region, as highlighted in the third row of Fig.~ \ref{fig: visual results reflective}. Our proposed model, which incorporates both in-the-focus and out-of-focus data for training, demonstrates better performance in addressing this issue.

For scattering flares, recent models demonstrate the ability to restore local scattering flares, as shown in the third and fifth row of Fig.~ \ref{fig: visual results scattering}. However, these models struggle to handle global flares that affect the overall contrast of images, as seen in the first and last rows of Fig.~ \ref{fig: visual results scattering}, which are also common in daily life. The visual results from our model shows that, by introducing both local and global degradation data in the training process, we improve the generalization performance of existing approaches.



\subsubsection{Quantitative Comparison} \ We utilize peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM) \cite{wang2004image}, and learned perceptual image patch similarity (LPIPS) \cite{zhang2018unreasonable} for quantitative comparisons. The results presented in Table \ref{tab: results} indicate that the overall image quality obtained with the internal ISP is lower than that of images processed using an external pipeline on raw data.
% The evaluation metrics also demonstrate the improvement in generalization ability to global artifacts for scattering data and improvement in address the out-of-focus area for reflective flare achieved by our proposed approach.
Furthermore, these metrics highlight our proposed approach's enhanced generalization capabilities, particularly in handling global artifacts in scattering flare data and improving clarity in out-of-focus areas for reflective flares.



\begin{table*}[h]
\centering
\caption{Impact of processing operations on image restoration performance on reflective flare. PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable} are used for evaluation. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better.}
\label{tab:restoration_performance}
\begin{tabular}{ccc|cccccc}
\hline
\multicolumn{3}{c|}{Operations} &
  \multicolumn{6}{c}{Metrics} \\ \hline
Denoise &
  Sharpen &
  Compression &
  PSNR (dB) $\uparrow$ &
  \multicolumn{1}{c|}{$\Delta$(dB)} &
  SSIM$\uparrow$ &
  \multicolumn{1}{c|}{$\Delta$} &
  LPIPS$\downarrow$ &
  $\Delta$ \\ \hline
 &
   &
   &
  35.742 &
  \multicolumn{1}{c|}{$-$} &
  0.954 &
  \multicolumn{1}{c|}{$-$} &
  0.035 &
  $-$ \\
\cmark &
   &
   &
  37.130 &
  \multicolumn{1}{c|}{{\color[HTML]{009901} +1.388}} &
  0.988 &
  \multicolumn{1}{c|}{{\color[HTML]{009901} +0.035}} &
  0.023 &
  {\color[HTML]{009901} -0.012} \\
\cmark &
  \cmark &
   &
  35.902 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -1.228}} &
  0.986 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -0.002}} &
  0.027 &
  {\color[HTML]{CB0000} +0.004} \\
\cmark &
  \cmark &
  \cmark &
  34.201 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -1.701}} &
  0.968 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -0.018}} &
  0.099 &
  {\color[HTML]{CB0000} +0.072} \\
 &
  \cmark &
  \cmark &
  33.719 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -2.023}} &
  0.955 &
  \multicolumn{1}{c|}{{\color[HTML]{009901} +0.001}} &
  0.139 &
  {\color[HTML]{CB0000} +0.104} \\ \hline
\end{tabular}
\label{tab: impact reflective}
\end{table*}


\begin{table*}[]
\centering
\caption{Impact of processing operations on image restoration performance on scattering flare.}
\begin{tabular}{ccc|cccccc}
\hline
\multicolumn{3}{c|}{Operations} &
  \multicolumn{6}{c}{Metrics} \\ \hline
Denoise &
  Sharpen &
  Compression &
  PSNR (dB) $\uparrow$ &
  \multicolumn{1}{c|}{$\Delta$(dB)} &
  SSIM $\uparrow$ &
  \multicolumn{1}{c|}{$\Delta$} &
  LPIPS $\downarrow$&
  $\Delta$ \\ \hline
 &
   &
   &
  26.678 &
  \multicolumn{1}{c|}{$-$} &
  0.749 &
  \multicolumn{1}{c|}{$-$} &
  0.145 &
  $-$ \\
\cmark &
   &
   &
  28.111 &
  \multicolumn{1}{c|}{{\color[HTML]{009901} +1.433}} &
  0.943 &
  \multicolumn{1}{c|}{{\color[HTML]{009901} +0.194}} &
  0.070 &
  {\color[HTML]{009901} -0.075} \\
\cmark &
  \cmark &
   &
  26.959 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -1.152}} &
  0.924 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -0.019}} &
  0.078 &
  {\color[HTML]{CB0000} +0.008} \\
\cmark &
  \cmark &
  \cmark &
  26.361 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -0.598}} &
  0.905 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -0.019}} &
  0.128 &
  {\color[HTML]{CB0000} +0.050} \\
 &
  \cmark &
  \cmark &
  25.701 &
  \multicolumn{1}{c|}{{\color[HTML]{CB0000} -0.977}} &
  0.842 &
  \multicolumn{1}{c|}{{\color[HTML]{009901} +0.093}} &
  0.193 &
  {\color[HTML]{CB0000} +0.048} \\ \hline
\end{tabular}
\label{tab: impact scattering}
\end{table*}



\subsection{Investigating Critical Processing Steps}
\subsubsection{Experiment Settings}
Reflecting on the discrepancy in restoration performance between images directly converted from raw data (RAW2RGB) and those processed through an ISP (ISPRGB), this study further investigates the influence of specific processing steps such as denoising, sharpening, and JPEG compression. We systematically introduce these steps into the RAW2RGB pipeline to evaluate their cumulative effect on image quality. The experiment employs the following processing steps:
\begin{itemize}[leftmargin=0.3cm, itemindent=0cm]
    \item \textbf{Denoise:} Denoising in image processing removes noise---caused by sensor flaws, poor lighting, or high ISO settings---to enhance image clarity and quality, which is often positioned as the initial step. In the experiments, denoising is performed using the medium-sized NAFNet \cite{chen2022simple} model, which is trained on the SIDD \cite{abdelhamed2018high} dataset and optimized for a compromise between denoising efficacy and computational efficiency.
    \item \textbf{Sharpen:} The sharpening step is typically placed at the end of an ISP pipeline to enhance the perceptual quality of images by increasing the visibility of edges and details that may have been softened during earlier processing stages. To approximate the varied sharpening approaches used by different smartphone manufacturers, a USM (Unsharp Masking) sharpening operator with a dynamic range of weights is utilized.
    \item \textbf{Compression:} Acknowledging the widespread use of JPEG compression in mobile imaging, the pipeline incorporates DiffJPEG \cite{shin2017jpeg} for simulating compression. The quality factor in image compression, particularly in formats like JPEG, balances compression rate and image quality, where a higher factor preserves more details and increases file size, while a lower factor enhances compression efficiency at the expense of data loss. In the experiments, we use quality levels variably set between medium ranges.
\end{itemize}

To dissect the impact of these processing steps on flare removal efficacy, we explore four distinct pipeline configurations, each altering the sequence of flare removal in relation to denoising, sharpening, and compression:
\begin{enumerate}[leftmargin=0.5cm, itemindent=0cm]
    \item \textit{Denoise $\rightarrow$ Flare Removal $\rightarrow$ Sharpen $\rightarrow$ Compression:} This setup prioritizes noise reduction before addressing any other image artifacts.
    \item \textit{Denoise $\rightarrow$ Sharpen $\rightarrow$ Flare Removal $\rightarrow$ Compression:} Here, flare removal is executed after sharpening but before the final compression, differing from traditional arrangements.
    \item \textit{Denoise $\rightarrow$ Sharpen $\rightarrow$ Compression $\rightarrow$ Flare Removal:} Mimicking a common practice, this configuration applies flare removal after the complete ISP sequence, which is typical of most existing approaches.
    \item \textit{Sharpen $\rightarrow$ Compression $\rightarrow$ Flare Removal:} Designed to replicate scenarios with incomplete noise reduction, possibly due to computational limitations or low-light imaging conditions, this setup omits the initial denoising step.
\end{enumerate}

\subsubsection{Results and Analysis}
Analyzing the results compiled in Tables \ref{tab: impact reflective} and \ref{tab: impact scattering}, several critical observations emerge:

\textbf{Denoising Benefit:} Echoing previous findings, initiating the pipeline with denoising consistently enhances image quality across various metrics and both types of flare. This confirms the pivotal role of noise reduction in improving overall image clarity and facilitating more effective flare removal. Notably, the fourth configuration underscores the challenges posed by incomplete noise reduction, common in devices with constrained processing power or images taken under poor lighting, leading to significant quality degradation.

\textbf{Sharpening and Compression Degradation:} The integration of sharpening and compression steps, regardless of their sequence, invariably diminishes image quality. This outcome highlights the delicate balance between the desire to enhance visual sharpness and the adverse effects of artifact introduction and loss of detail. The impact varies with the type of flare, with reflective flare being particularly vulnerable due to its localized nature, complicating the model's ability to accurately identify and correct affected regions, resulting in up to a $2.93$dB degradation in performance. Conversely, scattering flares, which exhibit more global characteristics, face a different set of challenges. The global degradation effects caused by sharpening and compression mirror those inherent in scattering flares, resulting in a performance loss of $1.75$dB.

\textbf{Optimal Flare Removal Placement:} The analysis suggests that positioning flare removal after denoising but before sharpening and compression (as in configuration 1) tends to produce the best restoration outcomes in terms of PSNR, SSIM, and LPIPS for both flare types. This arrangement benefits from a cleaner input image, enhancing the efficacy of flare removal. Placing flare removal later in the pipeline, especially after sharpening and compression (configurations 2 and 3), appears less effective, likely due to the compounded artifacts and information loss from preceding steps.

The examination of these pipeline configurations illuminates the complex interplay between different ISP processing steps and their collective impact on the quality of image restoration. It confirms that while denoising significantly improves image quality, subsequent processing steps like sharpening and compression can introduce negative effects that compromise both objective and perceptual quality measures. This comprehensive analysis not only clarifies the performance disparity observed between RAW2RGB and ISP-processed images but also offers actionable insights for optimizing ISP pipelines to achieve superior image restoration results.


% Quantitative results, presented in Table \ref{tab:flare_removal_results}, reveal several key observations:
% Denoising consistently improved image quality metrics across all pipeline configurations and flare types, confirming its role as a crucial pre-processing step for effective flare removal and overall restoration performance.
% Sharpening and compression, while potentially enhancing visual aspects like sharpness, led to degradation in PSNR, SSIM, and LPIPS, highlighting the inherent trade-off between visual enhancement and information loss.
% Placement of the flare removal step significantly impacted its effectiveness. Pipeline 1, with flare removal positioned after denoising but before sharpening and compression, generally yielded the best performance across all metrics and flare types. This suggests that applying flare removal on a denoised image provides a cleaner signal, leading to better restoration results. Pipelines 2 and 3, with flare removal placed after sharpening and compression, demonstrated inferior performance, likely due to the accumulated artifacts and information loss hindering the flare removal process.
