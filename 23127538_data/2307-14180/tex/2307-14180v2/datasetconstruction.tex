
% \begin{table}
% \caption{Detailed specifications of the mobile phones used for constructing the dataset.}
% \label{tab: devices}
% % \resizebox{1.6\columnwidth}{!}{%
% \begin{tabular}{ccccc}
% \hline
% Model & Manufacturer & \begin{tabular}[c]{@{}c@{}}CMOS sensor \\ (Main camera)\end{tabular} & Specification & Released year \\ \hline
% iPhone 13 & Apple & IMX603 & \begin{tabular}[c]{@{}c@{}}12 MP sensor, 1/1.7-inch sensor, 1.7$\mu$m pixels, \\ 26 mm equivalent f/1.6-aperture lens\end{tabular} & 2021 \\
% Pixel 7 & Google & GN1 & \begin{tabular}[c]{@{}c@{}}50MP sensor, 1/1.31-inch sensor, 1.2$\mu$m pixels, \\ 24mm equivalent f/1.85-aperture lens\end{tabular} & 2022 \\
% iQoo Neo 7 & Vivo & IMX766V & \begin{tabular}[c]{@{}c@{}}50MP sensor, 1/1.56-inch sensor, 1$\mu$m pixels, \\ 23mm equivalent f/1.88-aperture lens\end{tabular} & 2022 \\
% Find X6 Pro & OPPO & IMX989 & \begin{tabular}[c]{@{}c@{}}50MP sensor, 1-inch sensor, 1.5$\mu$m pixels,  \\ 23mm equivalent f/1.8-aperture lens\end{tabular} & 2023 \\ \hline
% \end{tabular}
% \end{table}

\begin{table}
\caption{Statistics of the collected data.}
\label{tab: stats}
 \resizebox{0.7\columnwidth}{!}{
\begin{tabular}{lcc}
\hline
Data               & \multicolumn{1}{l}{Scattering} & \multicolumn{1}{l}{Reflective} \\ \hline
Indoor             & 701                            & 79                             \\
Outdoor daytime    & 0                              & 803                            \\
Outdoor nighttime & 1326                           & 366                            \\ \hline
Total number & 2027                           & 1248                           \\ \hline
\end{tabular}}
\vspace{-3mm}
\end{table}


\section{Dataset Construction}
This section details the creation of our dataset, covering the capturing devices and settings, followed by specific capturing schemes for scattering and reflective flare.
\subsection{Capturing Settings}
We employed mobile phone models from various manufacturers as capturing devices to avoid potential similarities in lens flare within the same series. The chosen devices, detailed in Table \ref{tab: devices}, are popular in mobile photography and represent a range of capabilities.
For consistency, we used the main camera of each device with manual control over exposure and focus, whenever possible. Multi-frame fusion was disabled to ensure the best raw image quality. The statistics of the collected data is tabulated in Table \ref{tab: stats}.
\subsection{Scattering Flare}
To simulate a lens with defects, we introduced a stain-corrupted camera filter in front of the capturing devices. Varying the filter's location relative to the camera simulated different levels of corruption due to the varying defect levels across the filter. While the camera remained fixed on a tripod, minor vibrations during capture could cause misalignment between the flare-corrupted and flare-free image pairs. To address this, we performed sub-pixel registration using SURF feature extraction and matching \cite{bay2008speeded}. Given the small movements, only translations along the vertical and horizontal axes were computed. The registration process was first applied to internally processed images and then converted for the raw image data with its integer pixel grid.
For each registered pair, we identified areas with light sources and applied a detection algorithm to pinpoint their positions, as illustrated in Fig. \ref{fig: pipline scattering}. Both raw and internally processed images were cropped into patches centered on these light source positions. The raw patches were then processed externally to generate high-quality RGB image pairs. Finally, before inclusion in the dataset, predefined metrics were used to filter out low-quality pairs, ensuring the overall dataset quality.


% Figure environment removed

\subsection{Reflective Flare}
% Capturing ground truth data for reflective flare presents a challenge due to its origin within the camera system. The internal reflections causing this type of flare are always present during capture, making it difficult to obtain flare-corrupted and flare-free image pairs simultaneously. This explains the current lack of real image datasets for reflective flare suitable for supervised training.

% By leveraging the symmetrical property between the flare and the light source, we captured reflective data as follows. As depicted in Fig. \ref{fig: pipline reflective}, we rotating the camera when capturing to alters the light source location, resulting in a shifted flare image. By applying image registration and warping to align the two captured images, we can identify the flare location through image subtraction and then merge the images. Missing information in one image due to the flare can be compensated for using the corresponding area from the other. This process is repeated with reversed roles for the two images, ultimately yielding two flare-corrupted and flare-free pairs from a single capture, while maintaining the symmetry property.
% Due to the camera rotation and image registration, image warping and interpolation are necessary. While interpolation on raw image data is possible, it can introduce artifacts like color aliasing and interrupt the noise model of raw data. Therefore, we provide the original raw images and perform registration only on the internally processed and externally generated RGB images.

To capture reflective data by utilizing the symmetrical property between the flare and the light source, we employed the following method. As illustrated in Fig.~\ref{fig: pipline reflective}, we rotated the camera to change the light source position, which resulted in a shifted flare image. Through image registration and warping, we aligned the two captured images. We then used image subtraction to identify the flare location and merged the images. This allowed us to use the corresponding area from one image to compensate for missing information due to the flare in the other. Repeating this process with the roles reversed for the two images provided two pairs of flare-corrupted and flare-free images from a single capture.

Camera rotation and image registration necessitate image warping and interpolation. Direct interpolation on raw image data can introduce artifacts like color aliasing and disrupt the noise model. To avoid this, we provide the original raw images and perform registration only on the internally processed and externally generated RGB images.
