% \section{Related works}

% \subsection{Synthesized Flare Image Dataset}

% % Figure environment removed



% Figure environment removed


% Figure environment removed




% Figure environment removed
\section{Related Works}
In this section we first introduce the current synthetics of flare image dataset and their limitations. Followed by the discussion about how a raw image datasets can be used for enhancing user experimence in mobile compulational photography. 
\subsection{Synthetic Flare Image Dataset}

The initial flare image dataset, proposed by Wu \etal   \ \cite{wu2021train}, consists of 2,000 captured flare-only images and 3,000 flare images simulated using their physics-based model. These flares are superimposed on flare-free base images to create synthesized flare corruption. However, their real image data exhibits similar lens settings, resulting in comparable flare-only images across different scenes and unrealistic simulation outcomes.
Qiao \etal \   \cite{qiao2021light} collect unpaired flare-corrupted and flare-free images for training Cycle-GAN-like networks \cite{zhu2017unpaired}, but the lack of paired data precludes its use for training pixel-to-pixel neural networks such as U-Net \cite{ronneberger2015u}.
Flare7K \cite{dai2022flare7k} synthesizes 5,000 scattering flare-only images in various colors and 2,000 reflective flare-only images using the Optical Flares plug-in in Adobe After Effects, primarily for simulating nighttime flare-corrupted images. The dataset also includes 100 real images with a resolution of $512\times512$ pixels for evaluation. Similar to \cite{wu2021train}, flare-only images are added to flare-free base images for simulation. However, the simulated results are constrained by limited flare diversity. Among the 5,000 scattering flares, the majority feature conspicuous colors like green and red, rather than the more commonly observed blue and yellow flares due to human perception and artificial light source design, as shown in Fig.~\ref{fig: compare to Flare7k}. Although green and red flares have specific applications, their prevalence in the dataset is less practical for general lighting scenarios.

Despite progress in synthetic flare image datasets, their synthesis quality is hindered by several limitations. For scattering flares, the base image quality used in these datasets \cite{zhang2018single} is suboptimal. This dataset is initially proposed for reflection removal, and only around 10$\%$ of the images contain a light source, complicating the simulation of practical corrupted images. Furthermore, scattering flare caused by defects such as dust introduces global artifacts like veiling glare, which may reduce contrast and degrade overall image quality. However, the provided flares in the dataset only affect the local light source, neglecting flare impact on other image regions.

Reflective flare, more prevalent in daily life, is insufficiently addressed in these synthetic datasets. Reflective flare properties depend on factors such as light source position and shape, exposure, lens design, and capturing angle. Unfortunately, these datasets fail to capture the diversity of reflective flares. For example, Flare7K \cite{dai2022flare7k}  and \cite{wu2021train} offer simulated reflective flares at specific angles without considering image content, such as light source shape. Additionally, flares are randomly superimposed on images using synthesized schemes provided in these datasets, disregarding the symmetric property between the light source and reflective flare. Since reflective flare is caused by reflection between camera system lenses, obtaining real ground truth data is often considered difficult, and flare removal has long relied on simulation. However, we have discovered a method for obtaining ground truth images for such flares and provide them as training data.

In this paper, we address these limitations by constructing a real image dataset for both scattering and reflective flares. To the best of our knowledge, this is the first real image dataset providing paired data for supervised training.









\begin{table*}[h]
\resizebox{1.4\columnwidth}{!}{%
\begin{tabular}{ccccc}
\hline
Model & Manufacturer & \begin{tabular}[c]{@{}c@{}}CMOS sensor \\ (Main camera)\end{tabular} & Specification & Released year \\ \hline
iPhone 13 & Apple & IMX603 & \begin{tabular}[c]{@{}c@{}}12 MP sensor, 1/1.7-inch sensor, 1.7$\mu$m pixels, \\ 26 mm equivalent f/1.6-aperture lens\end{tabular} & 2021 \\
Pixel 7 & Google & GN1 & \begin{tabular}[c]{@{}c@{}}50MP sensor, 1/1.31-inch sensor, 1.2$\mu$m pixels, \\ 24mm equivalent f/1.85-aperture lens\end{tabular} & 2022 \\
iQoo Neo 7 & Vivo & IMX766V & \begin{tabular}[c]{@{}c@{}}50MP sensor, 1/1.56-inch sensor, 1$\mu$m pixels, \\ 23mm equivalent f/1.88-aperture lens\end{tabular} & 2022 \\
Find X6 Pro & OPPO & IMX989 & \begin{tabular}[c]{@{}c@{}}50MP sensor, 1-inch sensor, 1.5$\mu$m pixels,  \\ 23mm equivalent f/1.8-aperture lens\end{tabular} & 2023 \\ \hline
\end{tabular}}
% \caption{Detailed specification of the mobile phones used for constructing dataset.}
\caption{Detailed specifications of the mobile phones used for constructing the dataset.}
\label{tab: devices}
\vspace{-5mm}
\end{table*}
\subsection{Raw Image Dataset}
An Image Signal Processor (ISP) is a specialized processing unit in mobile phones designed to handle complex tasks involved in processing data captured by sensors. The primary function of an ISP is to convert raw data from the camera sensor into a usable image format, such as JPEG \cite{wallace1992jpeg}, while ensuring fast processing times. The processing pipeline involves a non-linear transform that includes demosaicing \cite{gunturk2005demosaicking}, white balance \cite{afifi2020deep}, color manipulation \cite{zeng2020learning}, tone-mapping \cite{debevec2002tone}, and JPEG compression \cite{wallace1992jpeg}. Modern mobile phones also incorporate advanced computational photography \cite{delbracio2021mobile} and post-processing algorithms, such as enhancing underexposed areas in dark environments, aggressive denoising due to smaller sensors, and image sharpening for visually pleasing quality, as demonstrated in Fig.~\ref{fig: post-processing on isp}. However, constrained by computational efficiency and capability on mobile phones, the image quality is limited compared to external processing with raw data. Additionally, since it is heavily compressed to 8-bit data from 12-bits or 14-bits on raw images for storage cost saving, the image quality is further degraded. Therefore, internal-ISP on mobile phones may result in worse image quality compared to external processing pipelines on raw data.

With advances in mobile phones, more devices are now capable of capturing and storing raw image data. As shown in Fig.~\ref{fig: raw vs isp}, compared to internal-ISP processed images, raw images provide better flexibility in post-processing and richer information, resulting in higher image quality. An external processing pipeline can employ more advanced algorithms without computational capability constraints, yielding improved quality. Moreover, raw image data is linearly proportional to light intensity. In contrast to ISP-processed data, raw images have a higher dynamic range, capturing more information in both shadows and highlights, allowing for better detail recovery in post-processing.

For these reasons, a high-quality raw image dataset from mobile phones is versatile and desirable for image restoration studies. Unfortunately, the availability of raw datasets captured by mobile phones is still limited. The SIDD dataset \cite{abdelhamed2018high} presents real noisy images from smartphone cameras with high-quality ground truth. The Fujifilm UltraISP dataset \cite{ignatov2022pynet} and the ETH dataset \cite{ignatov2020replacing} aim to enhance learning an ISP for better quality on mobile phones by providing data captured with mobile phones and professional high-end DSLR cameras. RawNeRF \cite{mildenhall2022nerf} collects a noisy raw dataset for training Neural Radiance Fields (NeRF), demonstrating that rendering raw output images from the resulting NeRF allows for novel high dynamic range (HDR) view synthesis tasks. We acknowledge the current unavailability of raw datasets specifically tailored for the flare removal problem and understand that leveraging the richer information from raw images may prove advantageous. To address this gap, we contribute raw data for this purpose.
% An Image Signal Processor (ISP) is a specialized processing unit on the mobile phones designed to handle complex tasks involved in processing data captured by sensors. The primary function of an ISP is to convert raw data from the camera sensor into a usable image format, such as JPEG \cite{wallace1992jpeg}, while ensuring fast processing times. The processing pipline is a non-linear transform that includes demosaicing \cite{gunturk2005demosaicking}, white balance \cite{afifi2020deep}, color manipulation  \cite{zeng2020learning}, tone-mapping \cite{debevec2002tone}, and JPEG compression \cite{wallace1992jpeg}. Modern mobile phones also involve advanced computational photography \cite{delbracio2021mobile} or post-processing algorithms, such as enhancing underexposed areas in dark environments, aggressive denoising due to smaller sensors but may also resulting in over-smooth images, and image sharpening for visually pleasing quality, as an example shown in Fig.~\ref{fig: post-processing on isp}. However, constrained by computational efficiency and capability on mobile phones, the image quality is limited compared to external processing with raw data. Additionally, since it is heavily compressed to 8-bit data from 12-bits or 14-bits on raw images for storage cost saving, the image quality is further degraded. Therefore, internal-ISP on the mobile phone may result in worse image quality compared to external processing pipline on raw data.

% With advances in mobile phones, more devices are now capable of capturing and storing raw image data. As illustrated in Fig.~\ref{fig: raw vs isp}, compared to internal-ISP processed images, raw images provide better flexibility in post-processing and richer information, resulting in higher image quality. An external processing pipline can employ more advanced algorithms without computational capability constraints, yielding improved quality. Moreover, raw image data is linearly proportional to light intensity. In contrast to ISP-processed data, raw images have a higher dynamic range, capturing more information in both shadows and highlights, allowing for better detail recovery in post-processing.



% For these reasons, a high-quality raw image dataset from mobile phones is versatile and desirable for image restoration studies. Unfortunately, the availability of raw datasets captured by mobile phones is still limited. SIDD dataset \cite{abdelhamed2018high} presents real noisy images from smartphone cameras with high-quality ground truth. The Fujifilm UltraISP dataset \cite{ignatov2022pynet} and ETH dataset \cite{ignatov2020replacing} aim to enhance learning an ISP for better quality on mobile phones by providing data captured with mobile phones and professional high-end DSLR cameras. RawNeRF \cite{mildenhall2022nerf} collects a noisy raw dataset for training Neural Radiance Fields (NeRF), demonstrating that rendering raw output images from the resulting NeRF allows for novel high dynamic range (HDR) view synthesis tasks.
% We acknowledge the current unavailability of raw datasets specifically tailored for the flare removal problem, and understand that leveraging the richer information from raw images may prove advantageous. In order to address this gap, we contribute raw data for this purpose.




% The initial flare image dataset, proposed by Wu. \etal  \cite{wu2021train}, comprises 2,000 captured flare-only images and 3,000 flare images simulated using their physics-based model. These flares are superimposed on flare-free base images to synthesize flare corruption. However, their real image data exhibits similar lens settings, resulting in comparable flare-only images across different scenes and unrealistic simulation outcomes.
% Qiao. \etal \cite{qiao2021light} collects unpaired flare-corrupted and flare-free images for training Cycle-GAN-like\cite{zhu2017unpaired} networks, but its lack of paired data precludes its use for training pixel-to-pixel neural networks such as UNet\cite{ronneberger2015u}.
% Flare7k\cite{dai2022flare7k} synthesizes 5,000 scattering flare-only images in various colors and 2,000 reflective flare-only images using the Optical Flares plug-in in Adobe After Effects, primarily for simulating nighttime flare-corrupted images. The dataset also includes 100 real images with a resolution of $512\times512$ pixels for evaluation. Similar to \cite{wu2021train}, flare-only images are added to flare-free base images for simulation. However, the simulated results are constrained by limited flare diversity. Among the 5,000 scattering flares, the majority feature conspicuous colors like green and red, rather than the more commonly observed blue and yellow flares due to human perception and artificial light source design. Although green and red flares have specific applications, their prevalence in the dataset is less practical for general lighting scenarios.

% Despite progress in synthesized flare image datasets, their synthesis quality is hindered by several limitations. For scattering flares, the base image quality in these datasets, referred to as \cite{zhang2018single}, is suboptimal. This dataset is initially proposed for reflection removal and only around 10$\%$ of the images contain a light source, complicating the simulation of practical corrupted images. Furthermore, scattering flare caused by defects such as dust introduces global artifacts like veiling glare, which may reduce contrast and degrade overall image quality. However, the provided flares in the dataset only affect the local light source, neglecting flare impact on other image regions.

% Reflective flare, more prevalent in daily life, is insufficiently addressed in these synthesized datasets. Reflective flare properties depend on factors such as light source position and shape, exposure, lens design, and capturing angle. Unfortunately, these datasets fail to capture the diversity of reflective flares. For example, both \cite{wu2021train} and Flare7k\cite{dai2022flare7k} offer simulated reflective flares at specific angles without considering image content, such as light source shape. Additionally, flares are randomly superimposed on images using synthesized schemes provided in these datasets, disregarding the symmetric property between the light source and reflective flare. Since reflective flare is caused by reflection between camera system lenses, obtaining real ground truth data is often considered difficult, and flare removal has long relied on simulation. However, we have discovered a method for obtaining ground truth images for such flares and provide them as training data.

% In this paper, we address these limitations by constructing a real image dataset for both scattering and reflective flares. To the best of our knowledge, this is the first real image dataset providing paired data for supervised training.
% \subsection{Raw Image Dataset}
% An Image Signal Processor (ISP) is a specialized processing unit designed to handle complex tasks involved in processing data captured by sensors. The primary function of an ISP is to convert raw data from the camera sensor into a usable image format, such as JPEG, while optimizing image quality and ensuring fast processing times. It is a non-linear process that includes demosaicing, white balance, color manipulation, tone-mapping, and JPEG compression. Modern mobile phones also involve advanced computational photography or post-processing algorithms, such as enhancing underexposed areas in dark environments, aggressive denoising due to smaller sensors, and image sharpening for visually pleasing quality. However, constrained by computational efficiency and capability on mobile phones, the image quality is limited compared to external processing with raw data. Additionally, since it is heavily compressed to 8-bit data from 12-bits on raw images for storage cost saving, the image quality is further degraded. In conclusion, internal-ISP results in worse image quality compared to external processing on raw data.

% With advances in mobile phones, more devices are now capable of capturing and storing raw image data. Compared to internal-ISP processed images, raw images provide better flexibility in post-processing and richer information, resulting in higher image quality. An external ISP can employ more advanced algorithms without computational capability constraints, yielding improved quality. Moreover, raw image data is linearly proportional to light intensity. In contrast to ISP-processed data, raw images have a higher dynamic range, capturing more information in both shadows and highlights, allowing for better detail recovery in post-processing.

% For these reasons, a high-quality raw image dataset from mobile phones is versatile and desirable for image restoration studies. Unfortunately, the availability of raw datasets captured by mobile phones is still limited. SIDD presents real noisy images from smartphone cameras with high-quality ground truth. The Fujifilm UltraISP dataset and ETH dataset aim to enhance learning an ISP for better quality on mobile phones by providing data captured with mobile phones and professional high-end DSLR cameras. RawNeRF collects a noisy raw dataset for training Neural Radiance Fields (NeRF), demonstrating that rendering raw output images from the resulting NeRF allows for novel high dynamic range (HDR) view synthesis tasks.
% We acknowledge the current unavailability of raw datasets specifically tailored for the flare removal problem, and understand that leveraging the richer information from raw images may prove advantageous. In order to address this gap, we contribute raw data for this purpose.


% \textit{Flare 7K} provides $5000$ synthesized scattering flares in multiple colors and $2000$ reflective flares. In addition they provided $100$ real images in a resolution of $512 \times 512$ for evaluation. However, among the $5000$ scattering flares the majority are not in blue and yellow color which are commonly seen in out daily light due  due to human perception and the design of artificial light sources. Instead, the majority are in green and red flare are provided for matching these colorful light sources. Althogh they have specific applications, they are less common because they are less practical for general lighting.

% Despite there are some recent progress has been made on synthesized flare image datasets, the systheze quality is still limited. For example, in the based images that thest two dataset used, named \red{add dataset} on the based images, only about $10\%$ images that has light source. This makes it difficult to simulate the corrupted images that are more practical.

% Scattering flare caused by dust degredates the overall quality over the whole image. However, from the flare they provided, they just pose the flare on the light source, insead of considering how these flare affects other region on the image.

% Reflective flare is a more common flare that can be seen in our daily life, but it is often not well considered in these synthesized settings. Specifically the  reflective flare depends on the position and shape of the light source, the exposure and the capturing angle. However, in these datasets they cannot reflect the diversity of the flare, instead they only simulate the flare on a specific angle and shape without considering the content on the image, followed by posting the flare  randomly on the top of the image, ignoring the symmetric property between the light source and the reflective flare. 
% 



% \textit{Flare7K}, a recent dataset, offers $5000$ synthesized scattering flares in multiple colors and $2000$ reflective flares, along with $100$ real images in a resolution of $512 \times 512$ for evaluation. However, among the $5000$ scattering flares, the majority are in conspicuous colors such as green and red colors instead of the more commonly observed blue and yellow flares, which frequently appear due to human perception and artificial light source design. While green and red flares have specific applications, their prevalence in the dataset is less practical for general lighting scenarios.

% Despite recent progress in synthesized flare image datasets, the limitation of their synthesis quality can be summarized as follows. Firstly, the quality of their based image is not good. In the base images used by these two datasets, referred to as \blue{add dataset}, only approximately $10\%$ of the images contain a light source, which complicates the simulation of more practical corrupted images.
% Second, scattering flare caused by dust degrades the overall image quality. However, the provided flares in the dataset are only imposed on the light source, neglecting the impact of flares on other regions of the image.
% Lastly, reflective flare, a more common type of flare in daily life, is not adequately addressed in these synthesized settings. Reflective flare characteristics depend on factors such as the light source's position and shape, exposure, and capturing angle. Unfortunately, these datasets fail to capture the diversity of reflective flares. For example, Flare7k simulates reflective flares at specific angles without considering the image content such as the shape of the light source. Additionally, flares randomly are imposed atop the image from systhesized schemes provided in these datasets, disregarding the symmetric property between the light source and the reflective flare.
% A flare image dataset is first proposed by \blue{add}, which consists of 2000 captured flare-only images and 3000 flare images simulated by their physics-based model. These flares are superimposed on the top of the flare-free base images for synthesising  flare corruption. However, their provided real image data is captured in a similar lens settings, making their flare-only image looks similar under different scenes and the simulated results are far from a realistic setting.
% \blue{CityU dataset} collects unpaired flare-corrupted and flare-free images for training Cycle-GAN like networks. However, due to lacking of paired data, such a dataset cannot be applied for training pixel-to-pixel neural networks such as UNet. 

% Flare7K synthesize $5000$ scattering flare-only images in various colors and $2000$ reflective flares-only image by using a plug-in named Optical Flares in Adobe After Effects. Their object is to simulate nighttime flare-corrupted images. They also provides $100$ real images with a resolution of $512 \times 512$ for evaluation. Similar to \blue{add}, the flare-only images will be added to the top of flare-free based images for simulation.
% Unfortunately, the simulated results are still limited by the diversity of the flare. Among the $5000$ scattering flares, the majority feature conspicuous colors such as green and red, rather than the more commonly observed blue and yellow flares that frequently occur due to human perception and artificial light source design. Although green and red flares have specific applications, their prevalence in the dataset is less practical for general lighting scenarios.

% Despite advances in synthesized flare image datasets, there are several limitations to their synthesis quality. For scattering flares, the quality of the base images used in these datasets, referred to as \blue{add dataset}, is subpar. Only approximately $10\%$ of the images contain a light source, making it challenging to simulate practical corrupted images. In addition, scattering flare caused by defects such as dust introduces global artifacts such as veiling glare, which may reduce contrast and degrades the overall image quality. However, the provided flares in the dataset are only imposed on the local light source, neglecting the impact of flares on other regions of the image. 

        % Reflective flare, which is more prevalent in daily life, is inadequately addressed in these synthesized datasets. Reflective flare properties depend on factors such as the light source position and shape, exposure, the design of lens such as lens group, and capturing angle. Regrettably, these datasets do not capture the diversity of reflective flares. For instance, both \blue{add} and Flare7k provide simulated reflective flares at specific angles without considering the image content, such as the light source shape. Furthermore, flares are randomly superimposed on the image using synthesized schemes provided in these datasets, ignoring the symmetric property between the light source and the reflective flare. Due to the reason that reflective flare is caused by reflection between the lenses in the camera system, it is often considered impossible to obtain a real image that can serve as a ground truth data and removing such a flare relies on simulation for a long time. Fortunately, we found a way for obtaining a groundtruth image for such a flare and we provides them as training data.

% In this paper we try to resolve these limitations by constructing a real image dataset for both scattering and reflective flares. To our best knowledge, this is the first real image dataset which provides paired data for supervised training.


% \subsection{Raw Image Dataset}
% An Image Signal Processor (ISP) is a specialized processing unit designed to handle the complex tasks involved in processing data captured by the sensors. The primary function of an ISP is to convert the raw data from the camera sensor into a usable image format, such as JPEG, while optimizing the image quality and ensuring fast processing times. It is a non-linear processing which includes demoasicing, white balance, color manipulation, tone-mapping, JPEG compression. For modern mobile phones it also involves advanced computational photography or post-processing algirithms such as enhancing the underexposed areas for images capturing in the dark enviorment, perform aggressive denoising algorithms because mobile phones use smaller sensor, and perform image sharpening for providing pleasing viusal quality. However, constrained by computational efficency and capability on the mobile phone, the image quality for the mobile phones are limited compared with external processing with raw data. In addition since it is heavily compressed to 8-bit data from 12-bits on raw images for saving storage cost, the quality of the image is even worse. In conclusion, the internel-ISP results in worse image quality compared with external processing on raw data.

% With the advance in mobile phones, nowadays more phones are capable in capturing and storaging raw image data.
% Compared with internel-ISP processed image, raw images provides better flexibility in post-processing and rich information which results in higher image quality. On externel ISP one can use more advance algorithms without constraint on computational capability to provides better quality. In addition, the data on raw image is linearly propotional to the light intensity. Compared with ISP-processed data, raw images have a higher dynamic range, meaning they capture more information in both shadows and highlights. This allows for better recovery of details in post-processing.

% For these reasons, high quality raw image dataset of mobile phones is versatile and is desirable for image restoration study. Unfortunately, the number raw dataset captured by mobile phones is still quite limited. SIDD represents real noisy images from smartphone cameras with high-quality ground truth. Fujifilm UltraISP dataset and ETH dataset are proposed for enhancing learning an ISP for better quality on mobile phones by providing data captured with mobile phones and professional high-end DSLR camera. RawNeRF collects a raw dataset for training Neural Radiance Fields (NeRF), showing that rendering raw output images from the resulting NeRF, we can perform novel high dynamic range (HDR) view synthesis tasks.
% We notice that currently there is no available raw dataset for this problem and richer data from raw image may be bendeficial to this poroblem, to bridge this cap we provides raw data.
% However, currently such image datasets are lacking. 
% for image restoration problems, because it provides for understanding the image property and maximum flexibility for image editing. 


% Linear pixel intensity.
% The ISP processed image enhance the low exposure area but makes it more difficult to distinguished the reflective flare from the image content.
