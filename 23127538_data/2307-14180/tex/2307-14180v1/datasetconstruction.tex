


% iPhone 12, Pixel 7 and Find X6 Pro are the premium models from different companies. 
% for the consideration that, 
% Since a similar lens structure tends to be used on the same series of mobile phone models, which may results in similar lens flare, for the capturing devices we adopts mobile phone models from different manufactures.
% The capturing devices are representative in mobile photography. The detailed specification of these devices and their sensors are listed in Table.~\ref{tab: devices}. 
% iPhone 13 is popular a popular for mobile photography. Pixels made by Google are known for their advance computational photography algorithm. iQoo Neo 7 is a mid-range phones but also known for the camera system. Find X6 Pro is one premium models with advance camera systems released recently. 
% For all the listed devices, we use their main cameras to capture the photos, with manually controlled exposure and manually adjusted focus if possible, with multi-frame fusion off,  for delivering best raw image quality.

% \subsection{Scattering Flare}
% To simulate a lens with defects, we add a dust-corrupted camera filter in the front of the capturing mobile devices. Different area on the filter is corrupted different level of defects. Therefore, by changing the location of the filter related to the camera, we can simulate different levels of corruption. Since we fix the camera position and put the camera on a tripod and only change the location of the filter, the captured flare-corrupted and flare-free images are naturally paired but may still be misaligned due to some small vibration introduced in the capturing process. To provide best quality image pairs, we perform sub-pixel registration for each captured pairs. Note that the movement between the pairs are small and we only need to compute a 2-D registration, namely we only compute a translation along the vertical ($y$-axis) and horizontal ($x$-axis) direction. The registration is first performed on the images processed by the internal ISP on the cell phone and then the translation is converted for raw image data where the pixels are at integer grid. 

% Given a registered pair, we first mask out the areas that has light-source, following apply a light-source detection algorithm for detecting the light-source position, as highlighted in Fig.~\ref{fig: pipline scattering}. We then crop the images into patches centering at the light-source position on both raw image data and internal ISP processed image, respectively. The cropped raw patches will go through an external ISP for generating high-quality RGB image pairs. Before saving the cropped patches into a dataset, low quality pairs will be detected with predefined metrics to ensure the quality of generated pairs. 

% \subsection{Reflective Flare}
% Capturing groudtruth pairs for reflective flare is challenging because this flare is caused by the internal reflection between the lenses within the camera system, which  always exist during the capturing process. As a result, one can not capture a flare-corrupted and flare-free image pair with single capture, which is the main reason that currently there is no available real image dataset for reflective flare image. 

% However, it is still possible to obtain a groudtruth images with two real images. In this paper we proposed to capture the image by changing the light source location using the symmetric property between the flare and the light source, and perform registration to obtain ground truth images. Specifically, as shown in Fig.~\ref{fig: pipline reflective} given a physical property that the light source and the flare always located symmetrically to the center point of the image, we rotate the sensor plane along the $z-$axis slightly when capturing to change the light source location, which results in a moved flare image. In the registration step, given the moving image A and fixed located image B, 3D-registration can be performed to align image A to image B. As such we can compute the difference between two images to locate the flares, followed by merging two images and the missing info caused by flare on image B can be also compensated by image A. Similarly, one can also fix image A followed by performing registration with image B. As as result, one image pairs will produce two flare-corrupted and flare-free pairs, and the and the resulted images still perverse the symmetric property. Before saving them into our dataset, we also filtered out the low quality pairs with predefined metrics to ensure the quality of generated pairs.

% For reflective flare, since the sensor plane is rotated which involves registration in 3-D space, it is unavoidable to perform image warping and interpolation for obtaining the registered image. Despite that it is possible to perform interpolation on raw image data, inaccurate interpolation will lead to artifacts such as color aliasing which may significantly degrades the image quality. For this reason, we provide the raw images for the original images and we only perform registered RGB images processed by the internal ISP of the cell phones and our external ISP.


% \vspace{-5cm}

\section{Dataset Construction}
% \vspace{-2mm}
In this section, we first discuss our capturing devices and settings, followed by detailed description of the capturing schemes for scattering flare and reflective flare, respectively.


 \subsection{Capturing Settings}
Since similar lens structures tend to be used across the same series of mobile phone models, potentially resulting in similar lens flare, we adopt mobile phone models from different manufacturers for capturing devices. These devices are representative in mobile photography, with detailed specifications listed in Table.~\ref{tab: devices}. iPhone 13 is popular for mobile photography, while Pixels by Google are known for their advanced computational photography algorithms. iQoo Neo 7 is a mid-range phone recognized for its camera system, and Find X6 Pro is a premium model with an advanced camera system. For all listed devices, we use their main cameras with manually controlled exposure and focus, if possible, and multi-frame fusion turned off to deliver the best raw image quality.




% Figure environment removed

\subsection{Scattering Flare}
To simulate a lens with defects, we add a stain-corrupted camera filter in front of the capturing mobile devices. Different areas on the filter exhibit varying levels of defects, so changing the filter's location relative to the camera simulates different corruption levels. Since we fix the camera position on a tripod and only change the filter's location, the captured flare-corrupted and flare-free images are naturally paired but may still be misaligned due to minor vibrations during the capturing process. To provide the highest quality image pairs, we perform sub-pixel registration for each captured pair. Registration is performed by extracting and matching SURF \cite{bay2008speeded} features. As the movement between the pairs is small and only requires 2D registration, we only compute translations along the vertical ($z$-axis) and horizontal ($y$-axis) directions. Registration is first performed on images processed by the mobile phone's internal ISP, and then the translation is converted for raw image data, where pixels are on an integer grid.


Given a registered pair, we first mark areas with light sources, then apply a light-source detection algorithm to detect the light-source position, as highlighted in Fig.~\ref{fig: pipline scattering}. We crop the images into patches centered on the light-source position for both raw image data and internally processed ISP images. The cropped raw patches undergo external processing pipline to generate high-quality RGB image pairs. Before saving the cropped patches into a dataset, low-quality pairs are detected using predefined metrics to ensure the quality of generated pairs.

\subsection{Reflective Flare}
Capturing ground truth pairs for reflective flare is challenging because this flare is caused by internal reflections between lenses within the camera system, which always exist during the capturing process. Consequently, it is difficult to capture flare-corrupted and flare-free image pairs with a single capture, which is the primary reason no real image dataset for reflective flare images currently exists for supervised training.

However, it is still possible to obtain ground truth images using two real images by changing the light source location, leveraging the symmetric property between flare and light source, and performing registration. Specifically, as shown in Fig.~\ref{fig: pipline reflective}, given the physical property that the light source and flare are always symmetrically located to the image's center point, we slightly rotate the sensor plane along the $z-$axis when capturing to change the light source location, resulting in a moved flare image. In the registration step, given moving image A and fixed image B, 3D registration can be performed to align image A with image B. Similar to processing scattering flare images, registration is performed by extracting and matching SURF features. This allows us to compute the difference between the two images to locate flares, followed by merging the images and compensating for missing information caused by flare on image B with image A. Similarly, one can fix image A and perform registration with image B. As a result, one image pair will produce two flare-corrupted and flare-free pairs, and the resulting images still preserve the symmetric property. Before saving them into our dataset, we also filter out low-quality pairs using predefined metrics to ensure the quality of the generated pairs.

For reflective flare, since the sensor plane is rotated, which involves registration in 3D space, it is unavoidable to perform image warping and interpolation for obtaining the registered image. While it is possible to perform interpolation on raw image data, inaccurate interpolation may lead to artifacts such as color aliasing, which can significantly degrade image quality. For this reason, we provide the raw images for the original images, and we only perform registration on RGB images processed by the mobile phone's internal ISP and our external processing pipline.


% Captured is hard.
% Cone is expensive. Made with plastic.