%TODO:
%\begin{enumerate}
%    \item Add visual compassion between the proposed dataset with RAW2RGB (obtained with external ISP) and ISPRGB (obtained with internel ISP) and the flare-corrupted results syntehsized with Flare7k.
%    \item Illustrate the experimental settings, similar to \cite{dai2022flare7k} and \cite{wu2021train}, we use UNet for training.
%    \item For RAW2RGB and ISPRGB data, will run the model trained with \cite{dai2022flare7k} and \cite{wu2021train} for showing data trained with synthesize data doen't work well on real data
%    \item show the results trained on real image data (30,000 patches for scattering flare and 2,200 pairs for reflective flare).
%\end{enumerate}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \begin{table}[]
% \resizebox{1\columnwidth}{!}{
% \begin{tabular}{cccccc}
% \hline
% \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
%  &  &  & Wu et. al. (U-Net) & Flare7k (Uformer) & U-Net \\ \hline
% \multirow{3}{*}{RAW2RGB} & PSNR$\uparrow$ & 34.524 & 26.124 & 30.476 & \textbf{38.286} \\
%  & SSIM$\uparrow$ & 0.958 & 0.876 & 0.938 & \textbf{0.968} \\
%  & LPIPS$\downarrow$ & 0.018 & 0.045 & 0.033 & \textbf{0.014} \\ \hline
% \multirow{3}{*}{ISPRGB} & PSNR$\uparrow$ & 32.482 & 31.308 & 32.650 & \textbf{35.883} \\
%  & SSIM$\uparrow$ & 0.969 & 0.964 & 0.967 & \textbf{0.973} \\
%  & LPIPS$\downarrow$ & 0.023 & 0.025 & 0.022 & \textbf{0.017} \\ \hline
% \end{tabular}
% }
% \caption{Results on reflective flare removal.}
% \end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \begin{table}[]
% \resizebox{1\columnwidth}{!}{
% \begin{tabular}{cccccl}
% \hline
% \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network rained with synthetic dataset} & \multicolumn{1}{c}{Ours} \\ \cline{4-5}
%  &  &  & Wu \etal  (U-Net) & Flare7k (Uformer) & \multicolumn{1}{c}{U-Net} \\ \hline
% \multirow{3}{*}{RAW2RGB} & PSNR$\uparrow$ & 20.751 & 22.669 & 21.369 &  \\
%  & SSIM$\uparrow$ & 0.688 & 0.722 & 0.692 &  \\
%  & LPIPS$\downarrow$ & 0.126 & 0.138 & 0.121 &  \\ \hline
% \multirow{3}{*}{ISPRGB} & PSNR$\uparrow$ & 16.550 & 16.763 & 16.696 &  \\
%  & SSIM$\uparrow$ & 0.556 & 0.553 & 0.557 &  \\
%  & LPIPS$\downarrow$ & 0.217 & 0.215 & 0.215 &\\ \hline
% \end{tabular}
% }
% \caption{Results on scattering flare removal.}
% \end{table}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}

% TODO:
% \begin{enumerate}
% \item Visual comparison: Compare the proposed dataset with RAW2RGB (obtained with external ISP) and ISPRGB (obtained with internal ISP), and the flare-corrupted results synthesized with Flare7k. Showcase the differences and benefits of the dataset.

% \item Experimental settings: Describe the experimental settings, such as using UNet for training, which is consistent with previous works like \cite{dai2022flare7k} and \cite{wu2021train}.

% \item metrics: PSNR, SSIM, LPIPS

% \item Performance on existing methods: Evaluate the performance of the model trained with \cite{dai2022flare7k} and \cite{wu2021train} on RAW2RGB and ISPRGB data to show that data trained with synthesized datasets does not work well on real data.

% \item Results with real image data: Present the results of the method when trained on real image data (30,000 patches for scattering flare and 2,200 pairs for reflective flare, 200 patches and 50 patches for validation, respectively) to demonstrate the effectiveness of the dataset. 

% \item Compare the result for reflective and scattering flare on RAW2RGB and ISPRGB results. The current results shows that RAW2RGB has a significant higher performance in PSNR. 

% \end{enumerate}

% To understand how the mobile ISP affects the flare removal performance and the performance between models trained with synthetic data and real image data, we compare the models trained with different data and evaluate them on images obtained with internal ISP from the mobile phone and external ISP performed on computer. 

% \subsection{Experiment settings}
% We evaluate the performance with state-of-the-art flare removal method trained with synthetic dataset on our collected dataset. Since we collect both raw images and images processed by the internal ISP of mobile phone, we evaluate performance on both data. For the raw images, we first convert it to an RGB image using a customized external ISP using MATLAB, denoted as \textit{RAW2RGB} image. We denote the image processed by internal ISP with \textit{ISPRGB}. We perform such a processing on both scattering flare image and reflective image. For scattering flare we perform light source detection and crop the $2,200$ high-resolution image pairs into $30,000$ patches with a resolution of $512 \times 512$, and we use $200$ patches for evaluation. For reflective flare we use the $1,100$ pairs for generating $2,200$ pairs and use $50$ pairs for evaluation.
% we compare the images from our dataset and synthtic dataset using groundtruth from our dataset in \blue{add}.  

% For training neural networks, we follow the network settings in \cite{wu2021train} and \cite{dai2022flare7k} and use U-Net for training as a baseline. For the following comparison between training with real image data and network trained with synthetic data, we use U-Net from \cite{wu2021train} for evaluation. For \cite{dai2022flare7k} since only the pre-trained UFormer network is available, which is reported as the best performance among the models, we use it for comparison. 
% \section{Experimental Result}
% To investigate the impact of mobile ISP on flare removal performance and to compare the performance of models trained with synthetic data and real image data, we evaluate models trained with different types of data on images obtained using both the internal ISP of the mobile phone and an external processing pipline performed on a computer.
% In addition, we also evaluate the performance of the networks trained with synthetic data on real flare-corrupted images on reflective and scattering flare, respectively.
% \subsection{Experiment Settings}
% Since we gather both raw images and images processed by the mobile phone's internal ISP, we evaluate performance on both types of data. For raw images, we first convert both flare-corrupted images and their groundtruth pair to RGB images using a customized external processing pipline implemented with MATLAB. We denote the output image as \textit{RAW2RGB} images. The external processing pipline consists of black level correction, white balancing, demosaicing and color space conversion modules, without introducing aggressive denoising methods and post-processing such as sharpening, and nighttime enhancing algorithm. Compared with standard pipline which saves the images into lossy JPEG format, we use losses format for saving. Images processed by the internal ISP are denoted as \textit{ISPRGB} images. Such a data processing is performed on both scattering and reflective flare images. 

% Sinec we have collected $2,200$ raw image pairs for scattering flare and $1,100$ raw pairs for reflective flare, we perform processing data as follows.
% For scattering flare, we conduct light source detection for locating the position of the light sources, and crop the collected $2,200$ high-resolution raw image pairs into $30,000$ flare-corrupted pairs with a resolution of $512 \times 512$, using $200$ pairs for evaluation. For reflective flare, we utilize the $1,100$ raw image pairs to generate $2,100$  pairs with a resolution of $1024 \times 1024$ for training, with $50$ pairs used for evaluation. We perform same division scheme on both \textit{RAW2RGB} and \textit{ISPRGB} data, respectively.

% For the comparing schemes, early works \cite{chabert2015automated, asha2019auto,vitoria2019automatic} mainly leverage on detecting lens flare based on the intensity or location, followed by recovering them using inpainting techniques. However, these solutions are not robust in flare-corrupted area detection and more importantly they are limited by the type of the flare, such as the in-the-focus reflective flare that results in a spot, while failing in addressing out-of-focus flare which appears transparent and the scattering flare like the recent data-driven schemes. 
% For this reason in the following section we assess the performance of state-of-the-art data-driven flare removal methods. Given currently the real images are lacking, these models are trained with a synthetic dataset. 
% For neural network training, we adhere to the network settings in \cite{wu2021train} and \cite{dai2022flare7k} and use U-Net for training as a baseline. For the subsequent comparison between training with real image data and networks trained with synthetic data, for \cite{wu2021train} since their model is not available, we follow their guideline and we use their released code and data to train a model for evaluation. Regarding \cite{dai2022flare7k}, since only the pre-trained UFormer model is available, which is reported to have the best performance among the models, we use it for comparison. The network is trained with similarly settings to the previous works, which takes image with a resolution of $512 \times 512$ as input and is trained on RTX 3090 but without additional techniques used in the previous works such as light source blending.

% \begin{table*}[h]
% \begin{tabular}{cccccc}
% \hline
% \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
%  &  &  & Wu et. al. (U-Net) & Flare7K (Uformer) & U-Net \\ \hline
% \multirow{3}{*}{RAW2RGB} & PSNR$\uparrow$ & 34.034 & 25.810 & 33.158 & \textbf{37.449} \\
%  & SSIM$\uparrow$ & 0.944 & 0.834 & 0.941 & \textbf{0.955} \\
%  & LPIPS$\downarrow$ & 0.023 & 0.090 & 0.025 & \textbf{0.015} \\ \hline
% \multirow{3}{*}{ISPRGB} & PSNR$\uparrow$ & 31.799 & 31.265 & 31.976 & \textbf{34.867} \\
%  & SSIM$\uparrow$ & 0.956 & 0.953 & 0.956 & \textbf{0.960} \\
%  & LPIPS$\downarrow$ & 0.028 & 0.031 & 0.028 & \textbf{0.021} \\ \hline
% \end{tabular}
% \caption{Quantitative results on reflective flare removal for the two types of data, using PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable}. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better. }
% \label{tab: quantative reflective}
% \end{table*}
% \begin{table*}[h]
% \begin{tabular}{cccccc}
% \hline
% \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
%  &  &  & Wu et. al. (U-Net) & Flare7K (Uformer) & U-Net \\ \hline
% \multirow{3}{*}{RAW2RGB} & PSNR$\uparrow$ & 20.776 & 22.673 & 21.310 & \textbf{30.289} \\
%  & SSIM$\uparrow$ & 0.688 & 0.722 & 0.690 & \textbf{0.780} \\
%  & LPIPS$\downarrow$ & 0.125 & 0.137 & 0.120 & \textbf{0.071} \\ \hline
% \multirow{3}{*}{ISPRGB} & PSNR$\uparrow$ & 16.558 & 16.774 & 16.931 & \textbf{24.061} \\
%  & SSIM$\uparrow$ & 0.557 & 0.554 & 0.559 & \textbf{0.736} \\
%  & LPIPS$\downarrow$ & 0.217 & 0.215 & 0.212 & \textbf{0.133} \\ \hline
% \end{tabular}
% \caption{Quantitative results on scattering flare removal using PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable}. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better.}
% \label{tab: quantative scattering}
% \end{table*}
% \section{Experimental Results}
% We study the effect of mobile ISPs on flare removal performance and compare models trained with synthetic and real image data. We evaluate these models on images acquired using both the internal ISP of the mobile phone and an external processing pipeline implemented on a computer. Furthermore, we assess the performance of networks trained with synthetic data on real flare-corrupted images for reflective and scattering flares.



% \begin{table*}[h]
% % \resizebox{1\columnwidth}{!}{
% % \begin{tabular}{cccccc}
% % \hline
% % \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
% %  &  &  & Wu et. al. (U-Net) & Flare7k (Uformer) & U-Net \\ \hline
% % \multirow{2}{*}{RAW2RGB} & PSNR$\uparrow$ & 34.524 & 26.124 & 30.476 & \textbf{38.286} \\
% %  & SSIM$\uparrow$ & 0.958 & 0.876 & 0.938 & \textbf{0.968} \\ \hline
% % \multirow{2}{*}{ISPRGB} & PSNR$\uparrow$ & 32.482 & 31.308 & 32.650 & \textbf{35.883} \\
% %  & SSIM$\uparrow$ & 0.969 & 0.964 & 0.967 & \textbf{0.973} \\ \hline
% % \end{tabular}
% \begin{tabular}{cccccc}
% \hline
% \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
%  &  &  & Wu et. al. (U-Net) & Flare7K (Uformer) & U-Net \\ \hline
% \multirow{3}{*}{RAW2RGB} & PSNR$\uparrow$ & 34.034 & 25.810 & 33.158 & \textbf{37.449} \\
%  & SSIM$\uparrow$ & 0.944 & 0.834 & 0.941 & \textbf{0.955} \\
%  & LPIPS$\downarrow$ & 0.023 & 0.090 & 0.025 & \textbf{0.015} \\ \hline
% \multirow{3}{*}{ISPRGB} & PSNR$\uparrow$ & 31.799 & 31.265 & 31.976 & \textbf{34.867} \\
%  & SSIM$\uparrow$ & 0.956 & 0.953 & 0.956 & \textbf{0.960} \\
%  & LPIPS$\downarrow$ & 0.028 & 0.031 & 0.028 & \textbf{0.021} \\ \hline
% \end{tabular}
% % }
% % \caption{Quantative results on reflective flare removal on the two types of data, using PSNR, SSIM \cite{wang2004image} and LPIPS \cite{zhang2018unreasonable}. $\uparrow$ denotes higher is better and $\downarrow$ denotes lower is better. U-Net from Wu \etal \cite{wu2021train} struggle to resotre the reflective flare corrupted images because its training dataset lacking sufficient data for such a pair. It also misclassify the flare-corrupted area in some cases. Flare7K \cite{dai2022flare7k} is able to remove part of the in-the-focus relefctive flare in some cases but struggles to remove the transparent out-of-focus area.}
% \caption{Quantitative results on reflective flare removal for the two types of data, using PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable}. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better. }
% \label{tab: quantative reflective}
% \end{table*}
% \begin{table*}[h]
% % \resizebox{1\columnwidth}{!}{
% % \begin{tabular}{cccccc}
% % \hline
% % \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
% %  &  &  & Wu et. al. (U-Net) & Flare7k (Uformer) & U-Net \\ \hline
% % \multirow{2}{*}{RAW2RGB} & PSNR$\uparrow$ & 20.751 & 22.669 & 21.369 & \textbf{31.694} \\
% %  & SSIM$\uparrow$ & 0.688 & 0.722 & 0.692 & \textbf{0.817} \\ \hline
% % \multirow{2}{*}{ISPRGB} & PSNR$\uparrow$ & 16.550 & 16.763 & 16.696 & \textbf{24.766} \\
% %  & SSIM$\uparrow$ & 0.556 & 0.553 & 0.557 & \textbf{0.748} \\ \hline
% % \end{tabular}
% \begin{tabular}{cccccc}
% \hline
% \multirow{2}{*}{Data} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & Ours \\ \cline{4-5}
%  &  &  & Wu et. al. (U-Net) & Flare7K (Uformer) & U-Net \\ \hline
% \multirow{3}{*}{RAW2RGB} & PSNR$\uparrow$ & 20.776 & 22.673 & 21.310 & \textbf{30.289} \\
%  & SSIM$\uparrow$ & 0.688 & 0.722 & 0.690 & \textbf{0.780} \\
%  & LPIPS$\downarrow$ & 0.125 & 0.137 & 0.120 & \textbf{0.071} \\ \hline
% \multirow{3}{*}{ISPRGB} & PSNR$\uparrow$ & 16.558 & 16.774 & 16.931 & \textbf{24.061} \\
%  & SSIM$\uparrow$ & 0.557 & 0.554 & 0.559 & \textbf{0.736} \\
%  & LPIPS$\downarrow$ & 0.217 & 0.215 & 0.212 & \textbf{0.133} \\ \hline
% \end{tabular}
% % }
% % \caption{Quantative results on scattering flare removal. The recent models from Wu \etal \cite{wu2021train} and Flare7K \cite{dai2022flare7k} trained with synthetic data is not able to recover the images corrupted with large area of glare, which may degradates the global image quality and is more common in real daily life. }
% \caption{Quantitative results on scattering flare removal using PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable}. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better.}
% \label{tab: quantative scattering}
% \end{table*}
% \section{Experimental Results}
% We study the effect of mobile ISPs on flare removal performance and compare models trained with synthetic and real image data. We evaluate these models on images acquired using both the internal ISP of the mobile phone and an external processing pipeline implemented on a computer. Furthermore, we assess the performance of networks trained with synthetic data on real flare-corrupted images for reflective and scattering flares.
% \section{Experimental Results}


% Figure environment removed


\begin{table*}[t]
\begin{tabular}{ccccccc}
\hline
\multirow{2}{*}{Data} & \multirow{2}{*}{Flare Type} & \multirow{2}{*}{Metric} & \multirow{2}{*}{Input} & \multicolumn{2}{c}{Network trained with synthetic dataset} & \multirow{2}{*}{Ours (U-Net)} \\ \cline{5-6}
 & & & & Wu \etal \  (U-Net) \cite{wu2021train} & Flare7K (Uformer) \cite{dai2022flare7k} &\\ \hline
\multirow{6}{*}{RAW2RGB} & \multirow{3}{*}{Reflective} & PSNR$\uparrow$ & 34.034 & 25.810 & 33.158 & \textbf{37.449} \\
 &  & SSIM$\uparrow$ & 0.944 & 0.834 & 0.941 & \textbf{0.955} \\
 &  & LPIPS$\downarrow$ & 0.023 & 0.090 & 0.025 & \textbf{0.015} \\ \cline{2-7}
 & \multirow{3}{*}{Scattering} & PSNR$\uparrow$ & 20.776 & 22.673 & 21.310 & \textbf{30.289} \\
 &  & SSIM$\uparrow$ & 0.688 & 0.722 & 0.690 & \textbf{0.780} \\
 &  & LPIPS$\downarrow$ & 0.125 & 0.137 & 0.120 & \textbf{0.071} \\ \hline
\multirow{6}{*}{ISPRGB} & \multirow{3}{*}{Reflective} & PSNR$\uparrow$ & 31.799 & 31.265 & 31.976 & \textbf{34.867} \\
 &  & SSIM$\uparrow$ & 0.956 & 0.953 & 0.956 & \textbf{0.960} \\
 &  & LPIPS$\downarrow$ & 0.028 & 0.031 & 0.028 & \textbf{0.021} \\ \cline{2-7}
 & \multirow{3}{*}{Scattering} & PSNR$\uparrow$ & 16.558 & 16.774 & 16.931 & \textbf{24.061} \\
 &  & SSIM$\uparrow$ & 0.557 & 0.554 & 0.559 & \textbf{0.736} \\
 &  & LPIPS$\downarrow$ & 0.217 & 0.215 & 0.212 & \textbf{0.133} \\ \hline
\end{tabular}
\caption{Quantitative results on reflective and scattering flare removal for the two types of data, using PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable}. $\uparrow$ denotes higher is better, and $\downarrow$ denotes lower is better.}
\label{tab: quantative_results}
\vspace{-7mm}
\end{table*}


\section{Experiments}
We investigate the effect of mobile ISPs on flare removal performance and compare models trained with synthetic and real image data. Specifically, we evaluate these models on images acquired using both the internal ISP of the mobile phone and an external processing pipeline implemented on a computer. Furthermore, we assess the performance of networks trained with synthetic data on real flare-corrupted images for reflective and scattering flares.
\subsection{Experiment Settings}
We evaluate performance on both raw images and images processed by the mobile phone's internal ISP. For raw images, we convert flare-corrupted images and their ground truth pairs to RGB images using a customized external processing pipeline implemented in MATLAB, denoted as \textit{RAW2RGB} images. The external pipeline comprises black level correction, white balancing, demosaicing, and color space conversion modules, without employing aggressive denoising or post-processing methods such as sharpening or nighttime enhancement algorithms. We save images in a lossless format instead of the lossy JPEG format. Images processed by the internal ISP are denoted as \textit{ISPRGB} images. We apply this data processing to both scattering and reflective flare images.

We collected $2,200$ raw image pairs for scattering flares and $1,100$ raw pairs for reflective flares. For scattering flares, we conduct light source detection to locate the position of the light sources and crop the $2,200$ high-resolution raw image pairs into $30,000$ flare-corrupted pairs with a resolution of $512 \times 512$, using $200$ pairs for evaluation. For reflective flares, we use the $1,100$ raw image pairs to generate $2,100$ pairs with a resolution of $1024 \times 1024$ for training, with $50$ pairs used for evaluation. We apply the same division scheme to both RAW2RGB and ISPRGB data, respectively.

Regarding comparison schemes, early works \cite{chabert2015automated, asha2019auto,vitoria2019automatic} primarily focused on detecting lens flares based on intensity or location and recovering them using inpainting techniques. However, these solutions are not robust in flare-corrupted area detection, and more importantly, they are limited by the type of flare. They can handle in-focus reflective flares resulting in spots but struggle with out-of-focus flares, which appear transparent, and also scattering flares. Therefore, we assess the performance of state-of-the-art data-driven flare removal methods trained with synthetic datasets due to the current lack of real images.



For neural network training, we follow the network settings in \cite{wu2021train} and \cite{dai2022flare7k} and use U-Net as a baseline for training. For subsequent comparisons between training with real image data and networks trained with synthetic data, we use the released code and data from \cite{wu2021train} to train a model for evaluation, as their model is not available. For \cite{dai2022flare7k}, since only the pre-trained Uformer \cite{wang2022uformer} model is available, which has the best reported performance among the models, we use it for comparison. For reflective flare images, we use their model trained with both data types, and for scattering images, we use their model trained only with scattering flare data, reported to be more robust in scattering flare removal. The network is trained with similar settings to previous works, taking images with a resolution of $512 \times 512$ as input and training on an RTX 3090 but without additional techniques such as light source blending used in previous works.



\subsection{Qualitative Comparison}
We first evaluate the performance of recent flare removal approaches on both ISPRGB and RAW2RGB data for reflective and scattering flare images. We observe that recent models perform better on RAW2RGB images due to their higher quality. 

For reflective flares, the U-Net from Wu \etal \ \cite{wu2021train} fails to accurately classify the flare region for restoration, as illustrated in Fig. \ref{fig: visual results reflective}. This issue stems from its training data, which predominantly consists of scattering flares but lacks sufficient reflective flares. We also observe that light-source blending approaches, which segment all light sources, perform flare removal and image blending to merge the results back into the segmented images, may misclassify the flare, leading to visual artifacts. For example, in the first row of Fig.~\ref{fig: visual results reflective}, Wu \etal \ \cite{wu2021train} misclassify a portion of the cloud as a flare, resulting in improper color restoration. The Uformer from Flare7K \cite{dai2022flare7k}, trained with synthetic reflective and scattering flare data, can identify the in-focus area in certain instances but struggles to resolve the transparent, out-of-focus reflective region, as emphasized in the second row of Fig. \ref{fig: visual results reflective}.

For scattering flares, recent models can restore some local scattering flares, as demonstrated in the third row of Fig.\ref{fig: visual results scattering}. However, these models struggle to handle large area glare affecting the global contrast of images, as seen in the first and last rows of Fig.\ref{fig: visual results scattering}, which are more common in daily life.


\subsection{Quantitative Comparison}
We use peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM)  \cite{wang2004image}, and learned perceptual image patch similarity (LPIPS) \cite{zhang2018unreasonable} to compare different schemes quantitatively. As shown in Table~\ref{tab: quantative_results}, the overall image quality obtained with internal ISP is lower than that of images obtained using an external pipeline on raw data. More importantly, the lower quality makes flare-free image reconstruction more difficult in subsequent steps. This is true for models trained with synthetic data and our real image dataset, suggesting that flare removal may be more effective when performed early in the processing pipeline instead of on compressed ISP-processed data.

Consistent with our visual comparison observations, in the reflective flare removal test, the U-Net from Wu \etal \ \cite{wu2021train} struggles to restore reflective flare-corrupted images due to insufficient data for such pairs in its training dataset. The model misclassifies the flare area and performs flare reduction, leading to worse image quality and lower performance metrics. The Uformer from Flare7K \cite{dai2022flare7k} encounters a similar problem when handling externally processed data, resulting in lower performance metrics than the input. For scattering flare, the model from Flare7K \cite{dai2022flare7k} can remove mild flares similar to those in their training data but struggles to remove large area corruptions, which degrade overall image quality.

% \subsection{Qualitative Comparison}
% We first evaluate the performance of recent flare removal approaches on both \textit{ISPRGB} and \textit{RAW2RGB} data for reflective and scattering flare images. We observe that recent models perform better on \textit{RAW2RGB} images due to their higher quality. For scattering flares, recent models can restore some local scattering flares, as demonstrated in the third row of Fig.\ref{fig: visual results scattering}. However, these models struggle to handle large area glare affecting the global contrast of images, as seen in the first and last rows of Fig.\ref{fig: visual results scattering}, which are more common in daily life.

% For reflective flares, the U-Net from Wu \etal \cite{wu2021train} fails to correctly classify the flare area for restoration, as shown in Fig.\ref{fig: visual results reflective}. This issue arises from its training data, which mostly includes scattering flares but lacks reflective flares. We also note that light-source blending may misclassify the flare, causing visual artifacts. For instance, in the first row of Fig~\ref{fig: visual results reflective}, Wu \etal misclassify part of the sunshine as flare, resulting in incorrect color restoration. The UFormer from Flare7K \cite{dai2022flare7k}, trained with synthetic reflective and scattering flare data, can detect the in-focus area in some cases but fails to resolve the transparent, out-of-focus reflective area, as highlighted in the second row of Fig~\ref{fig: pipline reflective}.

% \subsection{Quantitative Comparison}
% We use PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable} to compare different schemes quantitatively. As shown in Table~\ref{tab: quantative reflective} and Table~\ref{tab: quantative scattering}, the overall image quality obtained with internal ISP is lower than that of images obtained using an external pipeline. More importantly, the lower quality makes flare-free image reconstruction more difficult in subsequent steps. This is true for models trained with synthetic data and our real image dataset, suggesting that flare removal may be more effective when performed early in the processing pipeline instead of on compressed ISP-processed data.

% Consistent with our visual comparison observations, in the reflective flare removal test, the U-Net from Wu \etal \cite{wu2021train} struggles to restore reflective flare-corrupted images due to insufficient data for such pairs in its training dataset. The model misclassifies the flare area and performs flare reduction, leading to worse image quality and lower performance metrics. The Uformer from Flare7K \cite{dai2022flare7k} encounters a similar problem when handling externally processed data, resulting in lower performance metrics than the input. For scattering flare, the model from Flare7K \cite{dai2022flare7k} can remove mild flares similar to those in their training data but struggles to remove large area corruptions, which degrade overall image quality.

% \subsection{Qualitative Comparison}
% We first evaluate the performance of recent flare removal approaches on both \textit{ISPRGB} and \textit{RAW2RGB} data for both reflective and scattering flare images. Compared to \textit{ISPRGB} images, we observe that recent models perform better on \textit{RAW2RGB} images due to their higher quality. For scattering flares, recent models can restore some local scattering flares, such as those in the third row of Fig.\ref{fig: visual results scattering}. However, we notice that these models struggle to handle large area glare that affects the global contrast of the images, such as the results in the first and last rows of Fig.\ref{fig: visual results scattering}, which are more common in daily life.

% For reflective flares, we observe that the U-Net from Wu \etal \cite{wu2021train} fails to correctly classify the flare area for restoration, as shown in Fig.\ref{fig: visual results reflective}. This outcome is caused by its training data, which mostly includes scattering flares and lacks reflective flares. We also note that light-source blending may misclassify the flare, causing visual artifacts. For example, in the first row of Fig~\ref{fig: visual results reflective}, Wu \etal misclassify part of the sunshine as flare, resulting in incorrect color restoration. For the UFormer from Flare7K \cite{dai2022flare7k}, which is trained with synthetic reflective and scattering flare data, it can detect the in-focus area in a few cases but fails to resolve the transparent area, which is the out-of-focus reflective area, as highlighted in the second row of Fig~\ref{fig: pipline reflective}.

% \subsection{Quantitative Comparison}
% To compare different schemes quantitatively, we use PSNR, SSIM \cite{wang2004image}, and LPIPS \cite{zhang2018unreasonable} for evaluation. As shown in Table~\ref{tab: quantative reflective} and Table~\ref{tab: quantative scattering}, the overall image quality obtained with internal ISP is lower than that of the same images obtained using an external pipeline. More importantly, the lower quality makes it more difficult to reconstruct flare-free images in subsequent steps. This is true for models trained with synthetic data and our real image dataset, suggesting that flare removal may be better performed early in the processing pipeline instead of on compressed ISP-processed data.

% Consistent with the observations in the visual comparison, in the reflective flare removal test, the U-Net from Wu \etal \cite{wu2021train} struggles to restore reflective flare-corrupted images because its training dataset lacks sufficient data for such pairs. The model misclassify the flare area and perform flare reduction leads to a worse image quality and lowers the performance in terms of the metric. The Uformer from Flare7K \cite{dai2022flare7k} has a similar problem when dealing with the data processed by extranl pipline, which leads to worse lower performance in metrics than the input. For scattering flare, the model from Flare7K \cite{dai2022flare7k} can remove mild flares that are similar to those in their training data but has difficulty removing large area corruptions, which degrade overall image quality. 

% \section{Experimental Results}
% We examine the influence of mobile ISP on flare removal performance and compare models trained with synthetic and real image data. We evaluate these models on images obtained using both the internal ISP of the mobile phone and an external processing pipeline implemented on a computer. Additionally, we assess the performance of networks trained with synthetic data on real flare-corrupted images for both reflective and scattering flares.

% \subsection{Experiment Settings}
% We evaluate performance on both raw images and images processed by the mobile phone's internal ISP. For raw images, we convert both flare-corrupted images and their ground truth pairs to RGB images using a customized external processing pipeline implemented in MATLAB, denoted as \textit{RAW2RGB} images. The external pipeline includes black level correction, white balancing, demosaicing, and color space conversion modules, without incorporating aggressive denoising or post-processing methods such as sharpening or nighttime enhancement algorithms. We save images in a lossless format rather than the lossy JPEG format. Images processed by the internal ISP are denoted as \textit{ISPRGB} images. We perform this data processing on both scattering and reflective flare images.

% We collected $2,200$ raw image pairs for scattering flares and $1,100$ raw pairs for reflective flares. For scattering flares, we conduct light source detection to locate the position of the light sources and crop the $2,200$ high-resolution raw image pairs into $30,000$ flare-corrupted pairs with a resolution of $512 \times 512$, using $200$ pairs for evaluation. For reflective flares, we use the $1,100$ raw image pairs to generate $2,100$ pairs with a resolution of $1024 \times 1024$ for training, with $50$ pairs used for evaluation. We apply the same division scheme to both RAW2RGB and ISPRGB data, respectively.

% Regarding comparison schemes, early works \cite{chabert2015automated, asha2019auto,vitoria2019automatic} primarily focused on detecting lens flares based on intensity or location and recovering them using inpainting techniques. However, these solutions are not robust in flare-corrupted area detection, and more importantly, they are limited by the type of flare. They can handle in-focus reflective flares resulting in spots but struggle with out-of-focus flares, which appear transparent, and scattering flares. Therefore, we assess the performance of state-of-the-art data-driven flare removal methods trained with synthetic datasets due to the current lack of real images.

% For neural network training, we follow the network settings in \cite{wu2021train} and \cite{dai2022flare7k} and use U-Net as a baseline for training. For subsequent comparisons between training with real image data and networks trained with synthetic data, we use the released code and data from \cite{wu2021train} to train a model for evaluation, as their model is not available. For \cite{dai2022flare7k}, since only the pre-trained UFormer model is available, which has the best reported performance among the models, we use it for comparison. For reflective flare image we use their model trained with both data and for scattering images we use their model trained with scattering flare only, which is reported more robust in scattering flare removel. The network is trained with similar settings to previous works, taking images with a resolution of $512 \times 512$ as input and training on RTX 3090 without additional techniques such as light source blending used in previous works.

% \subsection{Qualitative Comparison}
% We first evaluate the performance of the recent flare removal appoaches on both ISPRGB and RAW2RGB data for both reflective flare and scattering flare images. Compared with ISPRGB images, we notice that the recent models works better on RAW2RGB images due to its better quality.
% For scattering flare, the recent models are able to restore some local scattering flare, such as the third rows in Fig.~\ref{fig: visual results scattering}. However, we notice that these recent models are not able to handle a large area glare that affects the global constrast of the images, such as the results on the first and last rows in Fig.~\ref{fig: visual results scattering}, which is more common in the daily life. 

% For reflective flare we notice that for the U-Net from Wu \etal \cite{wu2021train} is not able to correctly classify the flare area for restoration, as shown in Fig.\ref{fig: visual results reflective}. The results is casued by its training data which mostly includes scattering flare and lacking reflective flare. We also notice that light-source blending may misclassify the flare which may casue visual artifacts. For example in the first row in Fig~\ref{fig: visual results reflective}, Wu \etal misclassify part of the sunsine as flare, resulting in incorrect color resotration. For Uformer from Flare7K \cite{dai2022flare7k} which trained with synthetic reflective and scattering flare data, it is able to defect the in-the-focus area in few cases, but not able to resolve the transparent area which is the out-of-focus reflective area, as highlighted in the second rows in Fig~\ref{fig: pipline reflective}.

 
% \subsection{Quantitative Comparison}

% To compare different schemes quantatively, we us PSNR, SSIM \cite{wang2004image} and LPIPS \cite{zhang2018unreasonable} for evaluation. As can be seen in Table~\ref{tab: quantative reflective} and Table~\ref{tab: quantative scattering}, overall the image quality obtained with internal ISP is lower than the same images obtained using external pipline. More importantly, the lower quality makes it more difficult to reconstruct the flare-free images in the subsequent steps. This is true for the models trained with synthetic data and our real image dataset, which suggests that removing flare may be better performed in the early step in the processing pipline instead of on the compressed ISP-processed data.

% Similar to the observation in visual comparison, U-Net from Wu \etal \cite{wu2021train} struggle to resotre the reflective flare corrupted images because its training dataset lacking sufficient data for such pairs. The model from Flare7K \cite{dai2022flare7k} is able to remove mild flare which is similar in thier training data, but strulgle to remove large area corrupted which degrades the overall image quality. 

% % Figure environment removed

% % Figure environment removed

% % Figure environment removed

% % Figure environment removed