\section{Sampling the DAGs}
\label{sec: sampling the DAGs}
In this section, we focus on the Bayesian inference over binary DAGs through a novel mapping, $\tau(\mW,\vp)$, a modification of NoCurl. We establish the validity of performing Bayesian inference within $(\mW,\vp)$ space utilizing $\tau$ (\cref{subsec: Bayesian inference W p space}). However, $\tau$ yields uninformative gradient during back-propagation, a challenge we overcome by deriving an equivalent formulation based on permutation-based DAG learning, thereby enabling the use of relaxed gradient estimators (\cref{subsec: equivalent formulation}).


% In this section, instead of learning a single continuously weighted DAG, we focus on the Bayesian inference over the binary DAGs by introducing a new mapping $\tau(\mW,\vp)$ and deriving equivalent formulations. In particular, we will first prove that performing Bayesian inference in $(\mW,\vp)$ space with $\tau$ is equivalent to being in the binary DAG space (\cref{subsec: Bayesian inference W p space}). However, $\tau$ involves a piecewise constant $\step$ function, which lacks useful gradient information during backprop. To resolve the issue, we derive an equivalent formulation based on inferring the permutation matrix (\cref{subsec: equivalent formulation}). 
\input{Method_sampling_Wp.tex}
\input{Method_equivalent_formulation.tex}


\section{Bayesian Causal Discovery via Sampling}
\label{sec: SGMCMC sampling framework}
In this section, we delve into two specific methodologies that are derived from the proposed framework. The first one, which will be our main focus, combines SG-MCMC and VI in a Gibbs sampling manner. The second one, which is based entirely on SG-MCMC with continuous relaxation, is also derived, but we include its details in \cref{appsec: joint inference SG-MCMC} due to its inferior empirical performance.
% In this section, we aim to consoludate  

% two general frameworks for non-linear Bayesian structure learning by utilizing SG-MCMC and VI for $\vp, \mW$ and SEM parameters $\Theta$. First, we propose a SEM formulation based on the additive noise model (ANM). Then, we show how to perform the inference by (1) joint inference with SG-MCMC, and (2) SG-MCMC+VI.
\input{Method_sem_formulation.tex}

