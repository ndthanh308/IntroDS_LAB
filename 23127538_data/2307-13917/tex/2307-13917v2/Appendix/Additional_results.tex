\section{Additional Results}
\label{app:additional results}
\subsection{Walltime Comparison}
\cref{tab:walltime} presents walltime comparison of different methods. Our method converges faster while being scalable w.r.t.~DIBS, the nonlinear Bayesian causal discovery baseline. Other methods like BGES and DDS, while faster, perform much worse in terms of uncertainty quantification. In addition BGES is limited to linear model and DDS is not a fully Bayesian method.
\begin{table}[]
\centering
\caption{Walltime results (in minutes, rounded to the nearest minute) of the runtime of different approaches on a single 40GB A100 NVIDIA GPU. The N/A fields indicate that the corresponding method cannot be run within the memory constraints of a single GPU.}
\label{tab:walltime}
\begin{tabular}{l|cccc}
\hline
             & \multicolumn{1}{c|}{d=30} & \multicolumn{1}{c|}{d=50} & \multicolumn{1}{c|}{d=70} & d=100 \\ \hline
BaDAG (\textbf{Ours})(Bayesian, Nonlinear) & 171                       & 238                       & 261                       & 448   \\
DIBS (Bayesian, Nonlinear)        & 187                       & 350                       &      N/A                     &     N/A  \\ \hline
BGES (Quasi-Bayesian, Linear)       & 2                         & 3                         & 6                         & 11    \\
BCD (Bayesian, Linear)         & 252                       & 328                       & 418                       & 600   \\
DDS  (Quasi-Bayesian, Nonlinear)        & 92                        & 130                       & 174                       &  N/A   \\
\hline
\end{tabular}
\end{table}
\subsection{Performance with higher dimensional datasets}
\label{appsubsec: higher dimensional datasets}
Full results for all the metrics for settings $d=20$, $d=70$ and $d=100$ for nonlinear settings are presented in \cref{fig:nonlinear_20_40}, \cref{fig:nonlinear_70_140} and \cref{fig:nonlinear_100_200}.
% Figure environment removed
% Figure environment removed
% Figure environment removed
\subsection{Performance of SG-MCMC with Continuous Relaxation}
\label{appsubsec: fully SG-MCMC performance}
We compare the performance of SG-MCMC+VI and SG-MCMC with $\tmW$ on $d=10$ ER and SF graph settings. \cref{fig:sg-mcmc+vi vs sg-mcmc 10} shows the performance comparison. We can observe that SG-MCMC+VI generally outperforms its counterpart in most of the metrics. We hypothesize that this is because VI network $\mu_\phi$ couples $\vp$ and $\mW$. This coupling effect is crucial since the changes in $\vp$ results in the change of permutation matrix, where the $\mW$ can immediately respond to this change through $\mu_\phi$. On the other hand, $\tmW$ can only respond to this change through running SG-MCMC steps on $\tmW$ with fixed $\vp$. In theory, this is the most flexible approach since this coupling do not requires parametric form like $\mu_\phi$. However in practice, we cannot run many SG-MCMC steps with fixed $\vp$ for convergence, which results in the inferior performance. 
% Figure environment removed

%\subsection{Ablation Study}
%\label{appsubsec: ablation study}
%We conducts several ablation studies to investigate the %properties of \ModelName{}. \cref{fig: ablation init p scale} demonstrates the performance comparison between different initialization scale of $\vp$ value.
%\cref{fig: ablation num particles} shows the performances with different number of parallel SG-MCMC chains. \cref{fig: ablation scale,fig: ablation scale_p} shows the performance differences with different levels of injected SG-MCMC noise. For this setting, we fix the injected noise level for either $\vp$ or $\mTheta$ and vary the other. All ablation studies are conducted using ER $d=30$ datasets with the same hyperparameters reported in \cref{appsubsec: hyperparameter selection}. 


%% Figure environment removed
%% Figure environment removed

%% Figure environment removed

%% Figure environment removed

