\section{Theory}
\label{app: Theory}
\subsection{Proof of \cref{thm: equivalence of bayesian inference}}
\label{subapp: proof of equivalence of bayesian inference}
For completeness, we recite the theorem here.
\begin{reptheorem}{thm: equivalence of bayesian inference}[Equivalence of inference in $(\mW,\vp)$ and binary DAG space]
Assume graph $\mG$ is a binary adjacency matrix representing a DAG and node potential $\vp$ does not contain the same values, i.e.~$p_i\neq p_j$ $\forall i,j$. Then, with the induced joint observational distribution $p(\mD,\mG)$, dataset $\mD$ and a corresponding prior $p(\mG)$, we have
\begin{align}
    p(\mG\vert \mD) = \int p_\tau(\vp,\mW\vert \mD)\indicator(\mG=\tau(\mW,\vp))d\mW d\vp
    \label{eq: equivalence of bayesian inference}
\end{align}
if $p(\mG)=\int p_\tau(\vp,\mW)\indicator(\mG=\tau(\mW,\vp))d\mW d\vp$, where $p_\tau(\mW,\vp)$ is the prior, $\indicator(\cdot)$ is the indicator function and $p_\tau(\vp,\mW\vert D)$ is the posterior distribution over $\vp,\mW$. 
\end{reptheorem}


To prove this theorem, we first prove the following lemma stating the equivalence of $\tau$ (\cref{eq: Binary NoCurl}) to binary DAG space. 
\begin{lemma}[Equivalence of $\tau$ to DAG space]
Consider $d$ random variables, a node potential vector $\vp\in\sR^d$ and a binary matrix $\mW\in\binaryset$. Then the following holds:
\begin{enumerate}[(a)]
\item For any $\mW\in\binaryset$, $\vp\in\sR^d$, $\mG=\tau(\mW,\vp)$ is a DAG.
    \item For any DAG $\mG\in \sD$, where $\sD$ is the space of all DAGs, there exists a corresponding $(\mW,\vp)$ such that $\tau(\mW,\vp)=\mG$.
\end{enumerate}
\label{lemma: Equivalence of DAG space}
\end{lemma}
\begin{proof}
The main proof directly follows the theorem 2.1 in \cite{yu2021dags}. For (a), we show the output from $\tau(\mW,\vp)$ must be a DAG. 
By leveraging the Lemma 3.4 in \cite{yu2021dags}, we can easily obtain that $\step(\grad \vp)$ emits a binary adjacency matrix representing a DAG. The only difference is that we replace the $\relu(\cdot)$ with $\step(\cdot)$ but the conclusion can be directly generalized.

For (b), we show that for any DAG $\mG$, there exists a $(\mW,\vp)$ pair s.t. $\tau(\mW,\vp)=\mG$. To see this, we can observe that $\vp$ implicitly defines a topological order in the mapping $\tau$. For any $p_i>p_j$, we have $j\rightarrow i$ after the mapping $\step(\grad \vp)$. Thus, by leveraging Theorem 3.7 in \cite{yu2021dags}, we obtain that there exists a potential vector $\vp\in\sR^d$ for any DAG $\mG$ such that 
$$
(\grad\vp)(i,j)>0 \;\;\;\;\;\text{when}\;G_{ij}=1
$$
Thus, we can choose $\mW$ in the following way:
$$
\mW=\begin{cases}
&W_{ij}=0\;\;\;\;\; \text{if}\; G_{ij}=0\\
&W_{ij}=1\;\;\;\;\; \text{if}\; G_{ij}=1
\end{cases}
$$
\end{proof}
Next, let's prove the \cref{thm: equivalence of bayesian inference}.

\begin{proof}[Proof of \cref{thm: equivalence of bayesian inference}]
    From \cref{lemma: Equivalence of DAG space}, we see that the mapping is complete. Namely, the $(\mW,\vp)$ space can represent the entire DAG space. Next, we show that performing Bayesian inference in $(\mW,\vp)$ space can also correspond to the inference in DAG space. 

    Assume we have the prior $p_\tau(\mW,\vp)$. Then through mapping $\tau$, we implicitly define a prior over the DAG $\mG$ in the following:
    \begin{equation}
        p_\tau(\mG) = \int p_\tau(\mW,\vp)\indicator(\mG=\tau(\mW,\vp))d\mW d\vp
        \label{eq: accumulated prior}
    \end{equation}
    This basically states that the corresponding prior over $\mG$ is an accumulation of the corresponding probability associated with $(\mW,\vp)$ pairs.

    Similarly, we can define a corresponding posterior $p_\tau(\mG\vert \mD)$:
    \begin{equation}
        p_\tau(\mG\vert \mD) = \int p_\tau(\mW,\vp\vert \mD)\indicator(\mG=\tau(\mW,\vp))d\mW d\vp
        \label{eq: accumulated posterior}
    \end{equation}
    Now, let's show that this posterior $p_\tau(\mG\vert \mD) = p(\mG\vert \mD)$ if prior matches, i.e.~$p(\mG)=p_\tau(\mG)$.
    From Bayes's rule, we can easily write down
    \begin{equation}
        p_\tau(\mW,\vp\vert \mD) = \frac{p(\mD\vert \mG=\tau(\mW,\vp))p(\vp,\mW)}{\sum_{\mG'\in\sD}p(\mD,\mG')}
        \label{eq:def of W p posterior}
    \end{equation}
    Then, by substituting \cref{eq:def of W p posterior} into \cref{eq: accumulated posterior}, we have
    \begin{align}
        p_\tau(\mG\vert \mD) &= \int \frac{p(\mD\vert \mG)p_\tau(\mW,\vp)}{\sum_{\mG'\in\sD}p(\mD,\mG')}\indicator(\mG=\tau(\mW,\vp))d\mW d\vp\nonumber \\
        &=\frac{\int p(\mD\vert \mG)p_\tau(\mW,\vp)\indicator(\mG=\tau)d\mW d\vp}{\sum_{\mG'\in\sD}p(\mD,\mG')} \label{eq: proof 3.1 eq 1}\\
        &=\frac{p(\mD\vert \mG)\int p_\tau(\mW,\vp)\indicator(\mG=\tau)d\mW d\vp}{\sum_{\mG'\in\sD}p(\mD,\mG')}\label{eq: proof 3.1 eq 2}\\
        &=\frac{p(\mD\vert \mG)p_\tau(\mG)}{\sum_{\mG'\in\sD}p(\mD\vert\mG')p_\tau(\mG')}\nonumber\\
        &=p(\mG\vert \mD) \label{eq: proof 3.1 eq 3}
    \end{align}
where \cref{eq: proof 3.1 eq 1} is from the fact that $\sum_{\mG'\in\sD}p(\mD,\mG')$ is independent of $(\mW,\vp)$ due to marginalization. \cref{eq: proof 3.1 eq 2} is obtained because $p(\mD\vert \mG)$ is also independent of $(\mW,\vp)$ due to (1) $\indicator(\mG=\tau(\mW,\vp))$ and (2) $p(\mD\vert \mG)$ is a constant when fixing $\mG$. \cref{eq: proof 3.1 eq 3} is obtained by applying Bayes's rule and $p_\tau(\mG) = p(\mG)$. 
\end{proof}



\subsection{Proof of \cref{thm: equivalence of alternative formulation}}
\label{subapp: proof of theorem alternative formulation}

\begin{reptheorem}{thm: equivalence of alternative formulation}[Equivalence of NoCurl formulation]
Assuming the conditions in \cref{thm: equivalence of bayesian inference} are satisfied. Then, for a given $(\mW,\vp)$, we have
$$
\mG=\mW\odot \step(\grad \vp) = \mW\odot \left[ \perm^*(\vp)\mL\perm^*(\vp)^T\right]
$$
where $\mG$ is a DAG and $\perm^*(\vp)$ is defined in \cref{eq: alternative formulation}. 
\end{reptheorem}

To prove this theorem, we need to first prove the following lemma. 

\begin{lemma}
    For any permutation matrix $\mM\in\bm{\Sigma}_d$, we have
    $$
    \grad(\mM \vp) = \mM^T\grad(p) \mM
    $$
    where $\grad$ is the operator defined in \cref{eq: grad operator}.
    \label{lemma: grad with permutation matrix}
\end{lemma}
\begin{proof}
    By definition of $\grad(\cdot)$, we have
    \begin{align*}
        \grad(\mM\vp) &= (\mM\vp)_i - (\mM\vp)_j\\
        &=\bm{1}(i)^T\mM\vp - \bm{1}(j)^T\mM\vp\\
        &=\mM_{i,:}\vp - \mM_{j,:}\vp\\
    \end{align*}
    where $\bm{1}(i)$ is a one-hot vector with $i^{\text{th}}$ entry $1$, and $\mM_{i,:}$ is the $i^{\text{th}}$ row of matrix $\mM$. The above is equivalent to computing the $\grad$ with new labels obtained by permuting $\vp$ with $\mM$. Therefore, we can see that $\grad(\mM\vp)$ can be computed by permuting the original $\grad(\vp)$ by matrix $\mM$.
    $$
    \grad(\mM\vp)=\mM^T\grad(\vp)\mM
    $$
\end{proof}

\begin{proof}[Proof of \cref{thm: equivalence of alternative formulation}]
Since $\mW$ plays the same role in both formulations, we focus on the equivalence of $\step(\grad(\cdot))$.

Define a sorted $\tilde{\vp}= \perm \vp$, where $\perm\in\bm{\Sigma}_d$, such that for $i<j$, we have $\tilde{p}_i > \tilde{p}_j$. Namely, $\perm$ is a permutation matrix.
Thus, we have 
$$
\grad(\vp) = \grad(\perm^T\tilde{\vp}).
$$
By \cref{lemma: grad with permutation matrix}, we have
$$
\grad(\perm^T\tilde{\vp}) = \perm\grad(\tilde{\vp}) \perm^T.
$$
Since $\tilde{\vp}$ is an ordered vector. Therefore, $\grad(\tilde{\vp})$ is a skew-symmetric matrix with a positive lower half part. 

Therefore, we have
$$
\step(\grad(\vp)) = \step(\perm\grad(\tilde{\vp})\perm^T) = \perm\step(\grad(\tilde{p}))\perm^T =  \perm\mL\perm^T
$$
This is true because $\perm$ is just a permutation matrix that does not alter the sign of $\grad(\tilde{\vp})$.

Since $\perm$ is a permutation matrix that sort $\vp$ value in a ascending order, from Lemma 1 in \cite{blondel2020fast}, we have
$$
\perm = \argmax_{\perm'\in\bm{\Sigma}_d}\vp^T(\perm'\vo)
$$
\end{proof}

\subsection{Proof of \cref{prop: equivalence of evaluation}}
\label{subapp: proof of prop equivalence evaluation}
\begin{proof}
    \begin{align*}
        &\E_{p(\vp, \mW,\mTheta\vert \mD)}\left[f(\mG=\tau(\vp,\mW), \mTheta)\right]\\
        =& \int p(\vp,\mW,\mTheta, \tmW\vert \mD)f(\mG,\mTheta)d\vp d\mW d\mTheta d\tmW\\
        =&\int p(\vp, \tmW,\mTheta\vert \mD)p(\mW\vert \vp,\mTheta,\tmW,\mD)f(\mG,\mTheta)d\vp d\mW d\mTheta d\tmW\\
        =& \E_{p(\vp,\tmW,\mTheta\vert \mD)}\left[
        \frac{
        \int p(\mD\vert \vp,\mTheta,\mW)p(\vp)p(\tmW)p(\mW\vert \tmW)p(\mTheta\vert \vp,\mW)f(\mG,\mTheta)d\mW
        }{\int p(\mD\vert \vp,\mTheta,\mW)p(\vp)p(\tmW)p(\mW\vert \tmW)p(\mTheta\vert \vp,\mW)d\mW}
        \right]\\
        =&\E_{p(\vp,\tmW,\mTheta)}\left[
        \frac{
        \E_{p(\mW\vert \tmW)}\left[f(\mG,\mTheta)p(\mD,\mTheta\vert \vp,\mW)\right]
        }{
        \E_{p(\mW\vert \tmW)}\left[p(\mD,\mTheta\vert \vp, \mW)\right]
        }
        \right]
    \end{align*}
\end{proof}

\subsection{Proof of \cref{prop: joint inference gradient}}
\label{subapp: joint inference gradient}
\begin{proof}
    \begin{align*}
\nabla_\vp U(\vp,\tmW,\mTheta) &= -\nabla_{\vp} \log p(\vp,\tmW,\mTheta, \mD)\\
&=-\nabla_{\vp}\log p(\vp) - \nabla_{\vp} \log p(\tmW,\mTheta,\mD\vert \vp)\\
&=-\nabla_{\vp}\log p(\vp) - \frac{
\nabla_{\vp}\int p(\mD\vert \mW,\vp,\mTheta)p(\mTheta\vert \vp,\mW)p(\mW\vert \tmW)p(\tmW)d\mW
}{
\int p(\mD\vert \mW,\vp,\mTheta)p(\mTheta\vert \vp,\mW)p(\mW\vert \tmW)p(\tmW)d\mW
}\\
&=-\nabla_{\vp}\log p(\vp) - \frac{
\nabla_{\vp}\E_{p(\mW\vert\tmW)}\left[p(\mD\vert \mW,\vp,\mTheta)\right]
}{\E_{p(\mW\vert\tmW)}\left[p(\mD\vert \mW,\vp,\mTheta)\right]}\\
&=-\nabla_{\vp}\log p(\vp) - \nabla_{\vp} \log \E_{p(\mW\vert\tmW)}\left[p(\mD\vert \mW,\vp,\mTheta)\right]
    \end{align*}

Other gradient $\nabla_{\tmW} U$ and $\nabla_{\mTheta} U$ can be derived using the similar approach, which concludes the proof.
\end{proof}

\subsection{Proof of \cref{prop: gradient computation}}
\label{subapp: proof of proposition gradient computation}
\begin{proof}[Proof of \cref{prop: gradient computation}]
    By definition, we have easily have
    \begin{align*}
        \nabla_{\vp} U &= -\nabla_{\vp} \log p(\vp,\mW,\mTheta,\mD)\\
        &=-\nabla_{\vp}\log p(\vp,\mW) - \nabla_{\vp}\log p(\mD,\mTheta\vert \tau(\mW,\vp))\\
        &=-\nabla_{\vp}\log p(\vp,\mW) - \nabla_{\vp}\log p(\mD\vert \mTheta, \tau(\mW,\vp)) + \underbrace{\nabla_{\vp} \log p(\mTheta\vert \tau(\vp,\mW))}_{0}
    \end{align*}
Similarly, we have
\begin{align*}
    \nabla_{\mTheta} U &=  -\nabla_{\mTheta} \log p(\vp,\mW,\mTheta, \mD)\\
    &=-\nabla_{\mTheta} \log p(\mD\vert \mTheta,\tau(\mW,\vp)) - \nabla_{\mTheta}\log p(\mTheta\vert \vp,\mW) - \underbrace{\nabla_{\mTheta} \log p(\vp,\mW)}_{0}\\
    &= -\nabla_{\mTheta} \log p(\mD\vert \mTheta,\tau(\mW,\vp)) - \nabla_{\mTheta}\log p(\mTheta)
\end{align*}
\end{proof}

\subsection{Derivation of ELBO}
\label{subapp: derivation of ELBO}

\begin{align}
    \log p(\vp,\mTheta,\mD)&= \log \int p(\vp,\mTheta,\mD,\mW)d\mW \nonumber \\
    &= \log \int \frac{q_\phi(\mW\vert \vp)}{q_\phi(\mW\vert \vp)}p(\vp,\mTheta,\mD,\mW)d\mW \nonumber\\
    &\geq \int q_\phi(\mW\vert \vp)\log p(\vp,\mTheta,\mD\vert \mW)d\mW + \int q_\phi(\mW\vert \vp)\log \frac{p(\mW)}{q_\phi(\mW\vert \vp)}d\mW \label{eq: derivation of ELBO}\\
    &=\E_{q_\phi(\mW\vert \vp)}\left[\log p(\vp,\mTheta,\mD\vert \mW)\right]-\KL\left[q_\phi(\mW\vert\vp)\Vert p(\mW)\right]\nonumber
\end{align}
where the \cref{eq: derivation of ELBO} is obtained by Jensen's inequality.