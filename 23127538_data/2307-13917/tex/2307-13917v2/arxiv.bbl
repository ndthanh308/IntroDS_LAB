\begin{thebibliography}{10}

\bibitem{adams2011ranking}
Ryan~Prescott Adams and Richard~S Zemel.
\newblock Ranking via sinkhorn propagation.
\newblock {\em arXiv preprint arXiv:1106.1925}, 2011.

\bibitem{agrawal2019abcd}
Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, and Caroline
  Uhler.
\newblock Abcd-strategy: Budgeted experimental design for targeted causal
  structure discovery.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3400--3409. PMLR, 2019.

\bibitem{annadani2021variational}
Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer, Anirudh
  Goyal, Yoshua Bengio, and Stefan Bauer.
\newblock Variational causal networks: Approximate bayesian inference over
  causal structures.
\newblock {\em arXiv preprint arXiv:2106.07635}, 2021.

\bibitem{annadani2023differentiable}
Yashas Annadani, Panagiotis Tigas, Desi~R Ivanova, Andrew Jesson, Yarin Gal,
  Adam Foster, and Stefan Bauer.
\newblock Differentiable multi-target causal bayesian experimental design.
\newblock {\em arXiv preprint arXiv:2302.10607}, 2023.

\bibitem{barabasi1999emergence}
Albert-L{\'a}szl{\'o} Barab{\'a}si and R{\'e}ka Albert.
\newblock Emergence of scaling in random networks.
\newblock {\em science}, 286(5439):509--512, 1999.

\bibitem{bengio2021gflownet}
Yoshua Bengio, Salem Lahlou, Tristan Deleu, Edward~J Hu, Mo~Tiwari, and
  Emmanuel Bengio.
\newblock Gflownet foundations.
\newblock {\em arXiv preprint arXiv:2111.09266}, 2021.

\bibitem{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{blondel2020fast}
Mathieu Blondel, Olivier Teboul, Quentin Berthet, and Josip Djolonga.
\newblock Fast differentiable sorting and ranking.
\newblock In {\em International Conference on Machine Learning}, pages
  950--959. PMLR, 2020.

\bibitem{bongers2021foundations}
Stephan Bongers, Patrick Forr{\'e}, Jonas Peters, and Joris~M Mooij.
\newblock Foundations of structural causal models with cycles and latent
  variables.
\newblock {\em The Annals of Statistics}, 49(5):2885--2915, 2021.

\bibitem{casella1992explaining}
George Casella and Edward~I George.
\newblock Explaining the gibbs sampler.
\newblock {\em The American Statistician}, 46(3):167--174, 1992.

\bibitem{charpentier2022differentiable}
Bertrand Charpentier, Simon Kibler, and Stephan G{\"u}nnemann.
\newblock Differentiable dag sampling.
\newblock {\em arXiv preprint arXiv:2203.08509}, 2022.

\bibitem{chen2015convergence}
Changyou Chen, Nan Ding, and Lawrence Carin.
\newblock On the convergence of stochastic gradient mcmc algorithms with
  high-order integrators.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{chen2014stochastic}
Tianqi Chen, Emily Fox, and Carlos Guestrin.
\newblock Stochastic gradient hamiltonian monte carlo.
\newblock In {\em International conference on machine learning}, pages
  1683--1691. PMLR, 2014.

\bibitem{chickering2002optimal}
David~Maxwell Chickering.
\newblock Optimal structure identification with greedy search.
\newblock {\em Journal of machine learning research}, 3(Nov):507--554, 2002.

\bibitem{cooper1992bayesian}
Gregory~F Cooper and Edward Herskovits.
\newblock A bayesian method for the induction of probabilistic networks from
  data.
\newblock {\em Machine learning}, 9:309--347, 1992.

\bibitem{cundy2021bcd}
Chris Cundy, Aditya Grover, and Stefano Ermon.
\newblock Bcd nets: Scalable variational approaches for bayesian causal
  discovery.
\newblock {\em Advances in Neural Information Processing Systems},
  34:7095--7110, 2021.

\bibitem{deleu2022bayesian}
Tristan Deleu, Ant{\'o}nio G{\'o}is, Chris Emezue, Mansi Rankawat, Simon
  Lacoste-Julien, Stefan Bauer, and Yoshua Bengio.
\newblock Bayesian structure learning with generative flow networks.
\newblock In {\em Uncertainty in Artificial Intelligence}, pages 518--528.
  PMLR, 2022.

\bibitem{eaton2012bayesian}
Daniel Eaton and Kevin Murphy.
\newblock Bayesian structure learning using dynamic programming and mcmc.
\newblock {\em arXiv preprint arXiv:1206.5247}, 2012.

\bibitem{erdHos1960evolution}
Paul Erd{\H{o}}s, Alfr{\'e}d R{\'e}nyi, et~al.
\newblock On the evolution of random graphs.
\newblock {\em Publ. Math. Inst. Hung. Acad. Sci}, 5(1):17--60, 1960.

\bibitem{friedman2013data}
Nir Friedman, Moises Goldszmidt, and Abraham Wyner.
\newblock Data analysis with bayesian networks: A bootstrap approach.
\newblock {\em arXiv preprint arXiv:1301.6695}, 2013.

\bibitem{friedman2003being}
Nir Friedman and Daphne Koller.
\newblock Being bayesian about network structure. a bayesian approach to
  structure discovery in bayesian networks.
\newblock {\em Machine learning}, 50(1):95--125, 2003.

\bibitem{geffner2022deep}
Tomas Geffner, Javier Antoran, Adam Foster, Wenbo Gong, Chao Ma, Emre Kiciman,
  Amit Sharma, Angus Lamb, Martin Kukla, Nick Pawlowski, et~al.
\newblock Deep end-to-end causal inference.
\newblock {\em arXiv preprint arXiv:2202.02195}, 2022.

\bibitem{geiger2002parameter}
Dan Geiger and David Heckerman.
\newblock Parameter priors for directed acyclic graphical models and the
  characterization of several probability distributions.
\newblock {\em The Annals of Statistics}, 30(5):1412--1440, 2002.

\bibitem{gong2022advances}
Wenbo Gong.
\newblock {\em Advances in approximate inference: combining VI and MCMC and
  improving on Stein discrepancy}.
\newblock PhD thesis, University of Cambridge, 2022.

\bibitem{gong2022rhino}
Wenbo Gong, Joel Jennings, Cheng Zhang, and Nick Pawlowski.
\newblock Rhino: Deep causal temporal relationship learning with
  history-dependent noise.
\newblock {\em arXiv preprint arXiv:2210.14706}, 2022.

\bibitem{gong2018meta}
Wenbo Gong, Yingzhen Li, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Meta-learning for stochastic gradient mcmc.
\newblock {\em arXiv preprint arXiv:1806.04522}, 2018.

\bibitem{gong2020sliced}
Wenbo Gong, Yingzhen Li, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Sliced kernelized stein discrepancy.
\newblock {\em arXiv preprint arXiv:2006.16531}, 2020.

\bibitem{gong2019icebreaker}
Wenbo Gong, Sebastian Tschiatschek, Sebastian Nowozin, Richard~E Turner,
  Jos{\'e}~Miguel Hern{\'a}ndez-Lobato, and Cheng Zhang.
\newblock Icebreaker: Element-wise efficient information acquisition with a
  bayesian deep latent gaussian model.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{gong2021active}
Wenbo Gong, Kaibo Zhang, Yingzhen Li, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Active slices for sliced stein discrepancy.
\newblock In {\em International Conference on Machine Learning}, pages
  3766--3776. PMLR, 2021.

\bibitem{grathwohl2021oops}
Will Grathwohl, Kevin Swersky, Milad Hashemi, David Duvenaud, and Chris
  Maddison.
\newblock Oops i took a gradient: Scalable sampling for discrete distributions.
\newblock In {\em International Conference on Machine Learning}, pages
  3831--3841. PMLR, 2021.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em The Journal of Machine Learning Research}, 13(1):723--773, 2012.

\bibitem{grzegorczyk2008improving}
Marco Grzegorczyk and Dirk Husmeier.
\newblock Improving the structure mcmc sampler for bayesian networks by
  introducing a new edge reversal move.
\newblock {\em Machine Learning}, 71(2-3):265, 2008.

\bibitem{heckerman2006bayesian}
David Heckerman, Christopher Meek, and Gregory Cooper.
\newblock A bayesian approach to causal discovery.
\newblock {\em Innovations in Machine Learning: Theory and Applications}, pages
  1--28, 2006.

\bibitem{hoyer2008nonlinear}
Patrik Hoyer, Dominik Janzing, Joris~M Mooij, Jonas Peters, and Bernhard
  Sch{\"o}lkopf.
\newblock Nonlinear causal discovery with additive noise models.
\newblock {\em Advances in neural information processing systems}, 21, 2008.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{koivisto2012advances}
Mikko Koivisto.
\newblock Advances in exact bayesian structure discovery in bayesian networks.
\newblock {\em arXiv preprint arXiv:1206.6828}, 2012.

\bibitem{kuhn1955hungarian}
Harold~W Kuhn.
\newblock The hungarian method for the assignment problem.
\newblock {\em Naval research logistics quarterly}, 2(1-2):83--97, 1955.

\bibitem{kuipers2017partition}
Jack Kuipers and Giusi Moffa.
\newblock Partition mcmc for inference on acyclic digraphs.
\newblock {\em Journal of the American Statistical Association},
  112(517):282--299, 2017.

\bibitem{kuipers2014addendum}
Jack Kuipers, Giusi Moffa, and David Heckerman.
\newblock Addendum on the scoring of gaussian directed acyclic graphical
  models.
\newblock 2014.

\bibitem{lachapelle2019gradient}
S{\'e}bastien Lachapelle, Philippe Brouillard, Tristan Deleu, and Simon
  Lacoste-Julien.
\newblock Gradient-based neural dag learning.
\newblock {\em arXiv preprint arXiv:1906.02226}, 2019.

\bibitem{li2016preconditioned}
Chunyuan Li, Changyou Chen, David Carlson, and Lawrence Carin.
\newblock Preconditioned stochastic gradient langevin dynamics for deep neural
  networks.
\newblock In {\em Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem{liu2016stein}
Qiang Liu and Dilin Wang.
\newblock Stein variational gradient descent: A general purpose bayesian
  inference algorithm.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{lorch2021dibs}
Lars Lorch, Jonas Rothfuss, Bernhard Sch{\"o}lkopf, and Andreas Krause.
\newblock Dibs: Differentiable bayesian structure learning.
\newblock {\em Advances in Neural Information Processing Systems},
  34:24111--24123, 2021.

\bibitem{ma2019variational}
Chao Ma, Yingzhen Li, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Variational implicit processes.
\newblock In {\em International Conference on Machine Learning}, pages
  4222--4233. PMLR, 2019.

\bibitem{ma2015complete}
Yi-An Ma, Tianqi Chen, and Emily Fox.
\newblock A complete recipe for stochastic gradient mcmc.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{madigan1995bayesian}
David Madigan, Jeremy York, and Denis Allard.
\newblock Bayesian graphical models for discrete data.
\newblock {\em International Statistical Review/Revue Internationale de
  Statistique}, pages 215--232, 1995.

\bibitem{mena2018learning}
Gonzalo Mena, David Belanger, Scott Linderman, and Jasper Snoek.
\newblock Learning latent permutations with gumbel-sinkhorn networks.
\newblock {\em arXiv preprint arXiv:1802.08665}, 2018.

\bibitem{munkres1957algorithms}
James Munkres.
\newblock Algorithms for the assignment and transportation problems.
\newblock {\em Journal of the society for industrial and applied mathematics},
  5(1):32--38, 1957.

\bibitem{murphy2001active}
Kevin~P Murphy.
\newblock Active learning of causal bayes net structure.
\newblock Technical report, technical report, UC Berkeley, 2001.

\bibitem{niculae2018sparsemap}
Vlad Niculae, Andre Martins, Mathieu Blondel, and Claire Cardie.
\newblock Sparsemap: Differentiable sparse structured inference.
\newblock In {\em International Conference on Machine Learning}, pages
  3799--3808. PMLR, 2018.

\bibitem{nishikawa2022bayesian}
Mizu Nishikawa-Toomey, Tristan Deleu, Jithendaraa Subramanian, Yoshua Bengio,
  and Laurent Charlin.
\newblock Bayesian learning of causal structure and mechanisms with gflownets
  and variational bayes.
\newblock {\em arXiv preprint arXiv:2211.02763}, 2022.

\bibitem{pearl2009causality}
Judea Pearl.
\newblock {\em Causality}.
\newblock Cambridge university press, 2009.

\bibitem{peters2014identifiability}
Jonas Peters and Peter B{\"u}hlmann.
\newblock Identifiability of gaussian structural equation models with equal
  error variances.
\newblock {\em Biometrika}, 101(1):219--228, 2014.

\bibitem{peters2017elements}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock {\em Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem{peters2014causal}
Jonas Peters, Joris~M Mooij, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock Causal discovery with continuous additive noise models.
\newblock 2014.

\bibitem{pe2001inferring}
Dana Peâ€™er, Aviv Regev, Gal Elidan, and Nir Friedman.
\newblock Inferring subnetworks from perturbed expression profiles.
\newblock {\em Bioinformatics}, 17(suppl\_1):S215--S224, 2001.

\bibitem{platen2010numerical}
Eckhard Platen and Nicola Bruti-Liberati.
\newblock {\em Numerical solution of stochastic differential equations with
  jumps in finance}, volume~64.
\newblock Springer Science \& Business Media, 2010.

\bibitem{robinson1973counting}
Robert~W Robinson.
\newblock Counting labeled acyclic digraphs.
\newblock {\em New directions in the theory of graphs}, pages 239--273, 1973.

\bibitem{sachs2005causal}
Karen Sachs, Omar Perez, Dana Pe'er, Douglas~A Lauffenburger, and Garry~P
  Nolan.
\newblock Causal protein-signaling networks derived from multiparameter
  single-cell data.
\newblock {\em Science}, 308(5721):523--529, 2005.

\bibitem{spirtes2000causation}
Peter Spirtes, Clark~N Glymour, Richard Scheines, and David Heckerman.
\newblock {\em Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem{springenberg2016bayesian}
Jost~Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter.
\newblock Bayesian optimization with robust bayesian neural networks.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{sun2022discrete}
Haoran Sun, Hanjun Dai, Bo~Dai, Haomin Zhou, and Dale Schuurmans.
\newblock Discrete langevin sampler via wasserstein gradient flow.
\newblock {\em arXiv preprint arXiv:2206.14897}, 2022.

\bibitem{sun2019functional}
Shengyang Sun, Guodong Zhang, Jiaxin Shi, and Roger Grosse.
\newblock Functional variational bayesian neural networks.
\newblock {\em arXiv preprint arXiv:1903.05779}, 2019.

\bibitem{tigas2022interventions}
Panagiotis Tigas, Yashas Annadani, Andrew Jesson, Bernhard Sch{\"o}lkopf, Yarin
  Gal, and Stefan Bauer.
\newblock Interventions, where and how? experimental design for causal models
  at scale.
\newblock {\em Advances in neural information processing systems}, 36, 2022.

\bibitem{tong2001active}
Simon Tong and Daphne Koller.
\newblock Active learning for structure in bayesian networks.
\newblock In {\em International joint conference on artificial intelligence},
  volume~17, pages 863--869. Citeseer, 2001.

\bibitem{trippe2018overpruning}
Brian Trippe and Richard Turner.
\newblock Overpruning in variational bayesian neural networks.
\newblock {\em arXiv preprint arXiv:1801.06230}, 2018.

\bibitem{van2006syntren}
Tim Van~den Bulcke, Koenraad Van~Leemput, Bart Naudts, Piet van Remortel,
  Hongwu Ma, Alain Verschoren, Bart De~Moor, and Kathleen Marchal.
\newblock Syntren: a generator of synthetic gene expression data for design and
  analysis of structure learning algorithms.
\newblock {\em BMC bioinformatics}, 7:1--12, 2006.

\bibitem{van2006application}
Chikako Van~Koten and AR~Gray.
\newblock An application of bayesian network for predicting object-oriented
  software maintainability.
\newblock {\em Information and Software Technology}, 48(1):59--67, 2006.

\bibitem{welling2011bayesian}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 681--688, 2011.

\bibitem{ye2017langevin}
Nanyang Ye, Zhanxing Zhu, and Rafal~K Mantiuk.
\newblock Langevin dynamics with continuous tempering for training deep neural
  networks.
\newblock {\em arXiv preprint arXiv:1703.04379}, 2017.

\bibitem{yu2019dag}
Yue Yu, Jie Chen, Tian Gao, and Mo~Yu.
\newblock Dag-gnn: Dag structure learning with graph neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  7154--7163. PMLR, 2019.

\bibitem{yu2021dags}
Yue Yu, Tian Gao, Naiyu Yin, and Qiang Ji.
\newblock Dags with no curl: An efficient dag structure learning approach.
\newblock In {\em International Conference on Machine Learning}, pages
  12156--12166. PMLR, 2021.

\bibitem{zanella2020informed}
Giacomo Zanella.
\newblock Informed proposals for local mcmc in discrete spaces.
\newblock {\em Journal of the American Statistical Association},
  115(530):852--865, 2020.

\bibitem{zantedeschi2023dag}
Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt~J Kusner, and Vlad
  Niculae.
\newblock Dag learning on the permutahedron.
\newblock {\em arXiv preprint arXiv:2301.11898}, 2023.

\bibitem{zhang2018advances}
Cheng Zhang, Judith B{\"u}tepage, Hedvig Kjellstr{\"o}m, and Stephan Mandt.
\newblock Advances in variational inference.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  41(8):2008--2026, 2018.

\bibitem{zhang2022langevin}
Ruqi Zhang, Xingchao Liu, and Qiang Liu.
\newblock A langevin-like sampler for discrete distributions.
\newblock In {\em International Conference on Machine Learning}, pages
  26375--26396. PMLR, 2022.

\bibitem{zheng2018dags}
Xun Zheng, Bryon Aragam, Pradeep~K Ravikumar, and Eric~P Xing.
\newblock Dags with no tears: Continuous optimization for structure learning.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\end{thebibliography}
