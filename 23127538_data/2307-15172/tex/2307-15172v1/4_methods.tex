
\matmethods{

\subsection*{Participants}
We recruited 26 adult participants from a local university (age: 23.5 Â± 2.3 years; 6 females). All were right-handed with normal hearing and vision (with eyeglasses). Each participant received 10 USD compensation and was asked to wear headphones during the study. Three participants were excluded for not wearing headphones, and two were excluded due to incomplete data from technical issues, leaving 21 participants for analysis.
We used a within-subject design where each participant completed 12 randomized sessions combining 3 feedback types (\textit{silence}, \textit{stationary}, \textit{filter}) x 2 durations (short, long) x 2 conditions (with/without distraction). Session order randomization ensured variability. The University of California San Diego Institutional Review Board approved the study, and we obtained written informed consent from all participants beforehand.

\subsection*{Attention Task}
We employed a modified three-choice vigilance task (3CVT) to measure attention \cite{meghdadi2021eeg}. Participants were presented with three geometrical shapes: a target upward triangle, non-target downward triangle, and diamond distractor. Each of the ten trials per session displayed one shape followed by a random time interval. Shapes followed a 4:3:3 (target:non-target:distractor) ratio, with order shuffled to prevent bias.
We made two key modifications to the original 3CVT \cite{meghdadi2021eeg}. First, we introduced short (2-5 s) and long (25-35 s) intervals between shapes, manipulating difficulty. Longer durations required extended focus, thus increasing difficulty. Second, rather than random locations, shapes appeared at the center, enabling direct measurement of continuous attention and response times. Gaze deviations from center indicated lapsed attention, thus increasing response times. Participants pressed left/right arrows for target/non-target shapes, allowing the response time measurement.

\subsection*{Tactile Bodily Gaze Map}
The eyerofeedback system delivered vibratory stimuli to users' wrists and ankles based on eye movement directions. We divided the screen into four areas - Upper Left, Upper Right, Lower Left, Lower Right (Fig.~\ref{f1}) - establishing the following mapping: Upper Left $\rightarrow$ Left Wrist, Upper Right $\rightarrow$ Right Wrist, Lower Left $\rightarrow$ Left Ankle, Lower Right $\rightarrow$ Right Ankle. As users shifted gaze across areas, corresponding vibrations were triggered on their body. For instance, gazing upper left induced left wrist vibration, allowing users to sense their eye movements and regulate attention accordingly.

Vibratory tactile stimuli were delivered via 3D printed black wristbands housing vibration motors (Fig. S1 in Appendix). An Arduino Uno \cite{WinNT} controlled the 1 Hz vibration motors from PC commands. Adjustable wristbands using Velcro ensured comfortable wearing on both wrists and ankles.

Eye gaze data was collected using WebGazer \cite{papoutsaki2016webgazer}. Participants underwent pre-study calibration by clicking dots at various screen locations. Notably, we did not capture or save any face images during data collection. The gaze data contained timestamps for synchronization and (x,y) coordinates of eye movements on-screen.

\subsection*{Feedback Conditions}

We designed three feedback types: \textit{silence}, \textit{stationary}, and \textit{filter}. The \textit{silence} feedback served as the control condition with no tactile feedback. In the \textit{stationary} feedback condition, tactile feedback (eyerofeedback) was consistently provided to the users' entire body based on their real-time eye movements. The \textit{filter} feedback was a modified version of eyerofeedback, which was only triggered when users' eye movement distance exceeded a certain threshold. This decision was based on preliminary observations indicating that the \textit{stationary} feedback might introduce additional distractions to users, as tactile stimuli occurred continuously with any eye movement \cite{horvath2010distraction}. Consequently, the \textit{filter} feedback aimed to mitigate this potential distraction and warranted further investigation.
Specifically, we designated a centered sub-area spanning half the screen width/length (Fig.~\ref{f1}). Only eye movements beyond this sub-area's boundaries triggered tactile stimuli, allowing perception of gaze-pattern eyerofeedback.


\subsection*{Experiment Apparatus and Instruction}

The experimenter began by introducing the basic procedures of the study and addressing any questions or concerns participants had, ensuring their full comprehension of the information provided in the consent form. Subsequently, the experimenter assisted participants in wearing the four wristbands on their wrists and ankles. To minimize any additional pressure, the experimenter did not observe the participants or the screen during the formal study. However, if participants encountered any issues or had questions during the study, the experimenter was available to provide assistance.

Participants were informed that they would be completing an attention task and would receive tactile stimuli on their wrists and ankles, corresponding to their eye movements. They were instructed that the only way to reduce or eliminate the feedback was to maintain focus on the center of the screen. Prior to the formal study, participants were given an explanation of the attention task and provided with an opportunity to practice, allowing them to become familiar with the task.

After each session, participants were instructed to take a minimum of 1-minute rest and complete a questionnaire (Fig.~\ref{f2}) before proceeding to the next session. If participants felt fatigued from the previous study session, they were encouraged to take a longer rest period. Additionally, participants were required to perform a new eye tracking calibration after each session to minimize potential drift in WebGazer.

It is important to note that participants were instructed to wear the wristbands containing the vibration motors throughout the entire study, even during sessions when the feedback type was set to \textit{silence}. Finally, participants were instructed to prioritize accuracy in the attention task, ensuring they pressed the correct key on the keyboard when a shape appeared, and then attempting to respond as quickly as possible.


\subsection*{Data and Code Availability}

All data and codes needed to reproduce the findings and analysis are available at github: https://github.com/songlinxu/Eyerofeedback.
}

\showmatmethods{}

