\section{Introduction}
\label{sec:introduction}

A posteriori error estimators come in different varieties; reliability, efficiency and asymptotic exactness being frequent quality criteria. The diversity in error estimators reflects the fact that they can be used for two different purposes: \emph{error control} and \emph{step size selection}. Both purposes are connected but place an emphasis on different properties.
When it comes to step size selection in adaptive numerical methods, low computational costs are paramount; this goal is achieved for explicit Runge-Kutta schemes by embedded schemes used in extrapolation mode \cite{dormand1980family}. However, this methodology provides no error control, i.e., the user cannot certify whether a given numerical simulation is compatible with some error tolerance or not.
Reliable (and efficient) error estimators have as their primary objective to control the error but can also be used to compute provably quasi-optimal meshes in elliptic and parabolic problems \cite{becker2023,kreuzer2012}. Such methods are, commonly, not used in step size control of (explicit) schemes for ordinary differential equations
(ODEs) due to the larger computational costs. In particular, they usually require to measure how much the numerical solution fails to satisfy the ODE, by the so called residual, and to relate the residual to the error by a suitable stability theory which might be based on energy or duality arguments \cite{lakkis2015}.

Nevertheless, if one decides to compute residuals  in order to ensure error control, it makes sense to also use this information for choosing step sizes and it is desirable that this leads to stable step size control.
Typically, the most simple error-based step size selection uses an I controller
that multiplies the current time step size by a factor derived from an
error estimate using asymptotic arguments. By construction, it usually works
well in this asymptotic regime of small time step sizes. However, explicit
Runge-Kutta methods also need to operate well when the time step size is
limited by stability instead of accuracy. In this situation, step size control
stability is important. The study of these properties has been initiated by
Hall \cite{hall1985equilibrium,hall1986equilibrium} with further refinements
and applications together with Higham
\cite{hall1988analysis,higham1990embedded}.

One option to obtain step size control stability when using embedded
Runge-Kutta methods such as the classical schemes of
Bogacki and Shampine \cite{bogacki1989a32,bogacki1996efficient}
or Dormand and Prince \cite{dormand1980family} is to design the methods
specifically to allow step size control stability with the classical
I controller \cite{higham1990embedded}. However, most schemes of this class
used nowadays make use of more advanced controllers such as PI and PID
controllers developed for example in
\cite{gustafsson1988pi,gustafsson1991control,soderlind2006time,soderlind2006adaptive}.
As demonstrated in \cite{ranocha2023error,ranocha2021optimized}, these
controllers can be used together with embedded Runge-Kutta method for
efficient and robust time step size control in the context of compressible
computational fluid dynamics where the stability limited regime is crucial
due to the Courant-Friedrichs-Lewy step size restriction \cite{courant1967partial}.

In the following Section~\ref{sec:basics}, we introduce the notation
and basic ideas of the methods. Next, we investigate the step size control
stability of methods derived from the residual-based a posteriori error
estimators of \cite{dedner2016posteriori} analytically in
Section~\ref{sec:control-stability} and numerically in
Section~\ref{sec:numerical_experiments}. Finally, we summarize and discuss
our results in Section~\ref{sec:summary}. All source code required to
reproduce the numerical experiments is available online in our
reproducibility repository \cite{ranocha2023stabilityRepro}.



\section{Basic ideas of step size control and a posteriori error estimates}
\label{sec:basics}

Consider a system of  ODEs
\begin{equation}
\label{eq:ode}
  u'(t) = f\bigl( t, u(t) \bigr),
  \quad
  u(0) = u^0.
\end{equation}
One step of an explicit Runge-Kutta method can be written as
\cite{hairer2008solving,butcher2016numerical}
\begin{eqnarray}
\label{eq:RK-stages}
  y^i
  &=&
  u^n + \dt_n \sum_{j=1}^{i-1} a_{ij} \, f(t^n + c_j \dt_n, y^j),
  \qquad i \in \{1, \dots, s\},
  \\
  \label{eq:RK-step}
  u^{n+1}
  &=&
  u^n + \dt_n \sum_{i=1}^{s} b_{i} \, f(t^n + c_i \dt_n, y^i),
\end{eqnarray}
where $y^i$ are the stage values, $u^{n}$ is the numerical solution
approximating $u$ at time $t^n$, and $t^{n+1} = t^n + \dt_n$.

Given some weighted error estimator $w_{n+1}$ estimating the error made in the step from $t^n$ to $t^{n+1}$ and setting $ \epsilon_{n+1} = \frac{1}{w_{n+1}}$, classical methods for choosing time step sizes are based on I, PI, and PID controllers, e.g.
\cite{soderlind2006time,soderlind2006adaptive,kennedy2000low}
\begin{equation}
\label{eq:PID}
  \dt_{n+1} = \kappa\Bigl(%
                  \epsilon_{n+1}^{\beta_1 / k}
                  \epsilon_{n }^{\beta_2 / k}
                  \epsilon_{n-1}^{\beta_3 / k} \Bigr) \dt_{n},
\end{equation}
where $k$ is chosen such that $w_{n+1}$ is expected to be of order $\Delta t_n^k$.
%= \min(p, \widehat{p}) + 1$, i.e., $k = p$ when the method is used in
%local extrapolation mode.
The function $\kappa$ is a step size limiter,
which we choose as $\kappa(a) = 1 + \arctan(a - 1)$ \cite{soderlind2006adaptive}.
The real numbers $\beta_i$ are the controller parameters.
The general form \eqref{eq:PID} of a PID controller reduces to a PI controller
for $\beta_3 = 0$ and to a classical I controller for $\beta_2 = \beta_3 = 0$.
There are different ways in which the estimator $w_{n+1}$ can be obtained.

A classical approach to step size control is to obtain an error estimate
via an embedded method that consists of \eqref{eq:RK-stages} and
\begin{equation}
  \uhat^{n+1} = u^n + \dt_n \sum_{i=1}^{s} \bhat_{i} \, f(t^n + c_i \dt_n, y^i) + \dt_n \bhat_{s+1} f(t^{n+1}, u^{n+1}).
\end{equation}
Typically, these methods are used in local extrapolation mode, i.e., the main
method is of order~$p$ and the embedded method is of order $\widehat{p} = p - 1$.
Then, $k$ is chosen as $k= \min(p, \widehat{p}) + 1$, i.e., $k = p$ due to
the local extrapolation mode.
If $\bhat_{s+1} \ne 0$, the right-hand side of the new approximation
$u^{n+1}$ is used. This first-same-as-last (FSAL) technique was introduced to
improve the performance of the error estimator $u^{n+1} - \uhat^{n+1}$
\cite{dormand1980family}. Overall, one obtains
\begin{equation}
\label{eq:weighted-error-estimate-embedded}
  w_{n+1} = \left( \frac{1}{m} \sum_{i=1}^{m} \left( \frac{u_i^{n+1} - \uhat_i^{n+1}}{\atol + \rtol \max\{ \vert u_i^{n+1}\vert, \vert u_i^{n} \vert \}} \right)^2 \right)^{1/2},
\end{equation}
where  $\atol, \rtol > 0$ are absolute and relative
tolerances and  $m$ is the total number of degrees of freedom in $u$,
cf.\ \cite[Section~II.4]{hairer2008solving}.

While step size control based on embedded Runge-Kutta schemes is highly efficient (for explicit schemes) and works very well in practice it has the (theoretical) drawback that it does not provide any rigorous upper bounds for the error.

In contrast, the error estimators described in the next section lead to provable upper bounds for the error but are more expensive to compute.



\subsection{Energy based a posteriori error estimates}
The basic idea of this type of error estimators is to compute a sufficiently regular reconstruction $\widehat u$ from the numerical solution, to compute the residual
\begin{equation}\label{eq:res}
  R := \frac{\dif}{\dif t} \widehat{u} - f(\widehat{u})
\end{equation}
and to use a suitable stability theory of the ODE to bound the difference between $u$ and $\widehat{u}$ in terms of $R$.  In case of $f$ being Lipschitz continuous with Lipschitz constant $L$ we can simply use Gronwall's lemma to infer:
\begin{equation}\label{eq:gron}
 \| u - \widehat u\|_{L^\infty(0,T)} \leq \left(  \| u(0) - \widehat u(0)\|
 + \| R\|_{L^1(0,T)} \right) e ^{LT},
\end{equation}
where we have used the (weighted) Euclidean norm on $\mathbb{R}^m$.

If $\| R\|_{L^1(0,T)}$ is computed for error control,  it seems reasonable to choose step sizes based on $\| R\|_{L^1(t^n,t^{n+1})}$.
However, certain care is  needed in this approach: First of all, it needs to be ensured by a suitable reconstruction strategy that $\| R\|_{L^1(t^n,t^{n+1})}$ is indeed of order $\Delta t_n^{p+1}$ for a $p$-th order scheme and sufficiently regular solutions. Defining such a reconstruction is not trivial since the stage values of RK schemes do not contain high order information directly and computing the residual involves taking a derivative which might lead to the loss of one order of convergence. Indeed, it turns out that, in general, for any numerical scheme a dedicated reconstruction method needs to be derived in order to ensure that $\| R\|_{L^1(t^n,t^{n+1})}$ is of order $\Delta t_n^{p+1}$.

It should also be kept in mind that there are many interesting scenarios where the step from \eqref{eq:res} to \eqref{eq:gron} is far less straightforward. For example, when $f$ is an unbounded  operator or stems from the spatial discretization of a PDE which means that its Lipschitz constant will depend on some inverse power of the spatial mesh width, a more sophisticated stability analysis is needed in order to connect errors and residuals in an optimal way.

This line of thought can be traced back, at least, to \cite{makridakisnochetto2006} and was expunged in detail in \cite{makridakis2007}. These works address discretizations of parabolic PDEs and implicit time discretizations. It turns out that in case explicit RK schemes are applied to ODEs or semi-discretizations of first order hyperbolic PDEs a more generic method based on Hermite interpolation can be used \cite{dedner2016posteriori}. Detailed formulas of these reconstructions for generic cases can be found in \cite{dedner2016posteriori}; we will provide explicit formulas for the interpolations we investigate in this paper, e.g. \eqref{eq:cubic-hermite-central}.

A key observation of \cite{dedner2016posteriori} is that $f(t^n, u^n)$ is not only readily available in building the reconstruction since it is anyway computed during the time step but also known to be accurate enough in this scenario.
Step size control for explicit RK schemes and the estimators from  \cite{dedner2016posteriori} is what we are going to investigate in this paper.

In the context of these methods we
evaluate the weighted error estimator either in the $L^1$ norm as
\begin{equation}
\label{eq:weighted-estimate-residual-L1}
  w_{n+1} = \frac{\| R \|_{L^1(t^n, t^{n+1})}}{\atol + \rtol \max\{ \|u^n\|, \|u^{n+1}\| \}}
\end{equation}
or in the $L^2$ norm as
\begin{equation}
\label{eq:weighted-estimate-residual-L2}
  w_{n+1} = \frac{\sqrt{\dt_n} \| R \|_{L^2(t^n, t^{n+1})}}{\atol + \rtol \max\{ \|u^n\|, \|u^{n+1}\| \}}.
\end{equation}
Note the multiplication by $\sqrt{\dt_n}$ in
\eqref{eq:weighted-estimate-residual-L2}
ensures the correct scaling in terms of the time step size $\dt_n$.
Since the estimator is of the same order as the main method, we use $k=p+1$.



\section{Step size control stability}
\label{sec:control-stability}

In this section, we analyze step size control stability for residual
error estimators and compare it to the situation for embedded methods.
We follow the presentation of \cite[Section~IV.2]{hairer2010solving}
to introduce the concept of step size control stability.
Consider the scalar test problem
\begin{equation}
\label{eq:test-problem}
  u'(t) = \lambda u(t),
  \quad
  u(0) = u^0,
\end{equation}
for $\lambda \in \mathbb{C}$ and a simplified I controller\footnote{An I controller is a PID controller with
$\beta_2 = \beta_3 = 0$. Here, we got rid of the step size limiter and set the
first parameter $\beta_1 = 1$. This is a classical deadbeat controller.} of the
form
\begin{equation}
  \dt_{n+1} = \epsilon_{n+1}^{1 / k} \dt_n,
  \qquad
  \epsilon_{n+1} = \frac{\tol}{|e_{n+1}|},
\end{equation}
where $\tau$ is a fixed tolerance and $|e_{n+1}|$ is the error estimate, e.g.,
$|e_{n+1}| = | u^{n+1} - \uhat^{n+1} |$ when an embedded method is used.
This yields the dynamical system
\begin{equation}
\begin{aligned}
  u^{n+1} &= R(\dt_n \lambda) u^{n},
  \\
  \dt_{n+1} &= \dt_n \left( \frac{\tau}{|e_{n+1}|} \right)^{1 / k},
\end{aligned}
\end{equation}
where $R$ is the stability function of the (main) Runge-Kutta method.
The analysis can be simplified by introducing logarithms
\begin{equation}
  \eta_n = \log| u^{n} |, \quad \chi_n = \log \dt_n,
\end{equation}
resulting in
\begin{equation}
\label{eq:dyn-sys-I}
\begin{aligned}
  \eta_{n+1} &= \log| R(\e^{\chi_n} \lambda) | + \eta_n,
  \\
  \chi_{n+1} &= \chi_n + \frac{1}{k} \left( \log(\tol) - \log|e_{n+1}| \right).
\end{aligned}
\end{equation}
To study the step size control stability, we investigate the stability properties
of fixed points defined by
\begin{equation}
  | R(\e^{\chi_n} \lambda) | = 1,
  \quad
  \log|e_{n+1}| = \log(\tol).
\end{equation}
The first equation states that the step size $\dt_n = \e^{\chi_n}$ is chosen
such that $z = \dt_n \lambda$ is on the boundary of the stability region of the
Runge-Kutta method. A stable behavior requires that the spectral radius of the
Jacobian
\begin{equation}
\label{eq:jacobian-I}
  J =
  \begin{pmatrix}
    1 & u \\
    -\frac{1}{k} \partial_{\eta_{n}} \log|e_{n+1}| &
      1 - \frac{1}{k} \partial_{\chi_{n}} \log|e_{n+1}|
  \end{pmatrix},
  \qquad
  u = \Re\biggl( \frac{R'(z)}{R(z)} z \biggr),
\end{equation}
does not exceed unity.

For a simplified PID controller of the form
\begin{equation}
  \dt_{n+1} = \epsilon_{n+1}^{\beta_1 / k}
              \epsilon_{n  }^{\beta_2 / k}
              \epsilon_{n-1}^{\beta_3 / k} \dt_n,
  \qquad
  \epsilon_{n+1} = \frac{\tol}{|e_{n+1}|},
\end{equation}
the dynamical system becomes
\begin{equation}
\label{eq:dyn-sys-PID}
\begin{aligned}
  \eta_{n+1} &= \eta_n + \log| R(\e^{\chi_n} \lambda) |,
  \\
  \chi_{n+1} &= \chi_n
              + \frac{\beta_1}{k} \left( \log(\tol) - \log|e_{n+1}| \right)
              + \frac{\beta_2}{k} \left( \log(\tol) - \log|e_{n  }| \right)
  \\
  &\quad\quad\;\,
              + \frac{\beta_3}{k} \left( \log(\tol) - \log|e_{n-1}| \right).
\end{aligned}
\end{equation}
This can be considered as a dynamical system mapping from the indices
$(n, n-1, n-2)$ to the indices $(n+1, n, n-1)$. The corresponding Jacobian is
\begin{equation}
\label{eq:jacobian-PID}
\begin{gathered}
  J =
  \begin{pmatrix}
    1 & u & 0 & 0 & 0 & 0
    \\
%     -\frac{\beta_1}{k} \frac{\partial \log|e_{n+1}|}{\partial \eta_{n}} &
%       1 - \frac{\beta_1}{k} \frac{\partial \log|e_{n+1}|}{\partial \chi_{n}} &
%       -\frac{\beta_2}{k} \frac{\partial \log|e_{n}|}{\partial \eta_{n-1}} &
%       - \frac{\beta_2}{k} \frac{\partial \log|e_{n}|}{\partial \chi_{n-1}} &
%       -\frac{\beta_3}{k} \frac{\partial \log|e_{n-1}|}{\partial \eta_{n-2}} &
%       - \frac{\beta_3}{k} \frac{\partial \log|e_{n-1}|}{\partial \chi_{n-2}}
    -\frac{\beta_1}{k} \frac{\partial l_{n+1}}{\partial \eta_{n}} &
      1 - \frac{\beta_1}{k} \frac{\partial l_{n+1}}{\partial \chi_{n}} &
      -\frac{\beta_2}{k} \frac{\partial l_{n}}{\partial \eta_{n-1}} &
      - \frac{\beta_2}{k} \frac{\partial l_{n}}{\partial \chi_{n-1}} &
      -\frac{\beta_3}{k} \frac{\partial l_{n-1}}{\partial \eta_{n-2}} &
      - \frac{\beta_3}{k} \frac{\partial l_{n-1}}{\partial \chi_{n-2}}
    \\
    1 & 0 & 0 & 0 & 0 & 0
    \\
    0 & 1 & 0 & 0 & 0 & 0
    \\
    0 & 0 & 1 & 0 & 0 & 0
    \\
    0 & 0 & 0 & 1 & 0 & 0
  \end{pmatrix},
  \\
  l_{j} = \log|e_{j}|,
  \quad
  u = \Re\biggl( \frac{R'(z)}{R(z)} z \biggr),
\end{gathered}
\end{equation}
cf. \cite{kennedy2000low,ranocha2021optimized}.
In the following, we will study step size control stability for several
explicit Runge-Kutta methods from first to third order of accuracy. We begin
with the explicit Euler method to illustrate the steps. The other calculations
use Mathematica \cite{mathematica12}; the corresponding notebooks are
available in our reproducibility repository \cite{ranocha2023stabilityRepro}.


\subsection{Explicit Euler method}

The most simple explicit Runge-Kutta method is the explicit Euler method
with stability function
\begin{equation}
  R(z) = 1 + z.
\end{equation}
We use the linear reconstruction polynomial
\begin{equation}
  \widehat{u}(t) = u^{n} + \frac{t - t^{n}}{t^{n+1} - t^{n}} (u^{n+1} - u^{n})
\end{equation}
for the time interval $[t^{n}, t^{n+1}]$.
Then, the weighted $L^1$ error estimate \eqref{eq:weighted-estimate-residual-L1}
is given by
\begin{equation}
\begin{aligned}
  |e_{n+1}|
  =
  \| R \|_{L^1(t^n, t^{n+1})}
  &=
  \int_{t^{n}}^{t^{n+1}} \left|
    \frac{\dif}{\dif t} \widehat{u}(t) - \lambda \widehat{u}(t)
  \right| \dif t
  \\
  &=
  \int_{t^{n}}^{t^{n+1}} (t - t^{n}) \dif t \;
  |\lambda|^2 |u^{n}|
  =
  \frac{1}{2} \dt_n^2 |\lambda|^2 |u^{n}|.
\end{aligned}
\end{equation}
The $L^2$ version \eqref{eq:weighted-estimate-residual-L1} uses
\begin{equation}
  |e_{n+1}|
  =
  \sqrt{\dt_n} \| R \|_{L^2(t^n, t^{n+1})}
  =
  \frac{1}{\sqrt{3}} \dt_n^2 |\lambda|^2 |u^{n}|.
\end{equation}
Thus, the Jacobian \eqref{eq:jacobian-I} of the I controller becomes in both
cases
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u \\
    -\frac{1}{k} &
      1 - \frac{2}{k}
  \end{pmatrix},
  \qquad
  u = \Re\biggl( \frac{z}{1 + z} \biggr).
\end{equation}


\subsection{Second-order, two-stage methods}
\label{sec:RK22}

All explicit second-order, two-stage Runge-Kutta methods have the stability
function
\begin{equation}
  R(z) = 1 + z + \frac{z^2}{2}.
\end{equation}
We use the left-biased quadratic Hermite interpolation polynomial
\begin{equation}
  \widehat{u}(t)
  =
  \biggl( 1 - \frac{t^2}{\dt_n^2} \biggr) u^{n} +
  \biggl( t - \frac{t^2}{\dt_n} \biggr) f(t^{n}, u^{n}) +
  \frac{t^2}{\dt_n^2} u^{n+1}
\end{equation}
normalized to $t \in [0, \dt_n]$.
Then, the weighted $L^1$ error estimate \eqref{eq:weighted-estimate-residual-L1}
is given by
\begin{equation}
\begin{aligned}
  |e_{n+1}|
  =
  \| R \|_{L^1(t^n, t^{n+1})}
  &=
  \int_{t^{n}}^{t^{n+1}} \left|
    \frac{\dif}{\dif t} \widehat{u}(t) - \lambda \widehat{u}(t)
  \right| \dif t
  \\
  &=
  \frac{1}{2} \int_{0}^{\dt_n} t^2 \dif t \;
  |\lambda|^3 |u^{n}|
  =
  \frac{1}{6} \dt_n^3 |\lambda|^3 |u^{n}|.
\end{aligned}
\end{equation}
The corresponding $L^2$ version uses
\begin{equation}
  |e_{n+1}|
  =
  \sqrt{\dt_n} \| R \|_{L^2(t^n, t^{n+1})}
  =
  \frac{1}{2 \sqrt{5}} \dt_n^3 |\lambda|^3 |u^{n}|.
\end{equation}
The expression of the Jacobian \eqref{eq:jacobian-I} of the I controller with
residual error estimator becomes in both cases
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u \\
  -\frac{1}{k} & 1 - \frac{3}{k} \\
  \end{pmatrix},
  \quad
  u = \Re\biggl( \frac{z + z^2}{1 + z + z^2/2} \biggr).
\end{equation}
The corresponding Jacobian based on an embedded explicit Euler method is
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u \\
  -\frac{1}{k} & 1 - \frac{2}{k} \\
  \end{pmatrix},
  \qquad
  u = \Re\biggl( \frac{z + z^2}{1 + z + z^2/2} \biggr),
  \;
  k = 2.
\end{equation}

% Figure environment removed

The eigenvalues of these Jacobians are complex expressions that do not lend
themselves to an analytical investigation. Thus, we use a numerical approach
to compute and visualize the spectral radii in
Figure~\ref{fig:spectral_radius_rk22}.
First, it is clear that all methods do not lead to step size control stability.
However, the instability is less severe for the residual-based approach ---
the spectral radius of the Jacobian is smaller in most regions and exceeds
unity less compared to the version using an embedded Euler method.

To check the behavior in practice, we use the test problem \eqref{eq:ode} with
\begin{equation}
\label{eq:test-problem-hairer-wanner}
  f(t, u) =
  -2000
  \begin{pmatrix}
    \cos(t) u_1 + \sin(t) u_2 + 1 \\
    -\sin(t) u_1 + \cos(t) u_2 + 1
  \end{pmatrix},
  \quad
  u^0 =
  \begin{pmatrix}
    1 \\ 0
  \end{pmatrix},
\end{equation}
in the time interval $(0.0, 1.57)$ as suggested by Hairer and Wanner
\cite[Section~IV.2]{hairer2010solving}.
With tolerances $\atol = \rtol = 10^{-4}$ and $k = 2$, the embedded approach
leads to 1877 accepted and 263 rejected steps. The $L^1$ residual-based approach
with $k = 3$
leads to 1811 accepted and 27 rejected steps.
The $L^2$ variant behaves similarly, see Table~\ref{tab:RK22}.
Details of the implementation and further numerical experiments are discussed
in Section~\ref{sec:numerical_experiments}.

The expression of the Jacobian \eqref{eq:jacobian-PID} of the PI controller
with residual error estimator becomes
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u & 0 & 0 \\
    -\frac{\beta_1}{k} & 1 - \frac{3 \beta_1}{k} &
      -\frac{\beta_2}{k} & -\frac{3 \beta_2}{k} \\
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0
  \end{pmatrix},
  \quad
  u = \Re\biggl( \frac{z + z^2}{1 + z + z^2/2} \biggr).
\end{equation}
The spectral radii of the Jacobians for the PI controller with parameters
$\beta = (0.6, -0.2, 0.0)$ are
visualized in Figure~\ref{fig:spectral_radius_rk22}. Clearly, the more
involved controller leads to step size control stability for the
residual-based approach but not for the version using an embedded method.
For the test problem \eqref{eq:test-problem-hairer-wanner}, we get
1918 accepted and 55 rejected steps
for the the embedded approach while the residual-based approach leads to
1824 accepted and no rejected steps.

\begin{table}[htbp]
\centering
  \caption{Number of accepted and rejected time steps of
           Heun's second-order method with an embedded explicit Euler method
           for the test problem \eqref{eq:test-problem-hairer-wanner} with
           tolerances $\atol = \rtol = 10^{-4}$.}
  \label{tab:RK22}
  \begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}c *3c *3c}
    \toprule
    & \multicolumn{3}{c}{I controller, $\beta = (1, 0, 0)$}
    & \multicolumn{3}{c}{PI controller, $\beta = (0.6, -0.2, 0)$}
    \\
    & \multicolumn{2}{c}{Residual Estimator}
    & \multicolumn{1}{c}{Embedded}
    & \multicolumn{2}{c}{Residual Estimator}
    & \multicolumn{1}{c}{Embedded}
    \\
    & \multicolumn{1}{c}{$L^1$}
    & \multicolumn{1}{c}{$L^2$}
    & \multicolumn{1}{c}{Method}
    & \multicolumn{1}{c}{$L^1$}
    & \multicolumn{1}{c}{$L^2$}
    & \multicolumn{1}{c}{Method}
    \\
    \midrule
    $k$ & 3 & 3 & 2
        & 3 & 3 & 2
    \\
    Accepted & 1811 & 1815 & 1877
              & 1824 & 1828 & 1918
    \\
    Rejected & 27 & 26 & 263
              & 0 & 0 & 55
    \\
    \bottomrule
  \end{tabular*}
\end{table}


\subsection{Third-order, three-stage methods}
\label{sec:BS3}

All explicit third-order, three-stage Runge-Kutta methods have the stability
function
\begin{equation}
  R(z) = 1 + z + \frac{z^2}{2} + \frac{z^3}{6}.
\end{equation}
We would like to use the central cubic Hermite interpolation polynomial
\begin{equation}
\label{eq:cubic-hermite-central}
\begin{aligned}
  \widehat{u}(t)
  &=
  \biggl( 1 - \frac{3 t^2}{\dt_n^2} + \frac{2 t^3}{\dt_n^3} \biggr) u^{n} +
  \biggl( t - \frac{2 t^2}{\dt_n} + \frac{t^3}{\dt_n^2} \biggr) f(t^{n}, u^{n})
  \\
  &\quad
  +
  \biggl( \frac{3 t^2}{\dt_n^2} - \frac{2 t^3}{\dt_n^3} \biggr) u^{n+1} +
  \biggl( -\frac{t^2}{\dt_n} + \frac{t^3}{\dt_n^2} \biggr) f(t^{n+1}, u^{n+1})
\end{aligned}
\end{equation}
normalized to $t \in [0, \dt_n]$.
However, we have not been able to evaluate the integral
$\| R \|_{L^1(t^n, t^{n+1})}$ analytically, even when using Mathematica
\cite{mathematica12}. Thus, we use the left-biased cubic Hermite interpolation
polynomial
\begin{equation}
\label{eq:cubic-hermite-left}
\begin{aligned}
  \widehat{u}(t)
  &=
  \biggl( 1 - \frac{t^3}{\dt_n^3} \biggr) u^{n} +
  \biggl( t - \frac{t^3}{\dt_n^2} \biggr) f(t^{n}, u^{n})
  \\
  &\quad
  +
  \biggl( \frac{t^2}{2} - \frac{t^3}{2 \dt_n} \biggr) (f_t + f_u f)(t^{n}, u^{n+1}) +
  \frac{t^3}{\dt_n^3} u^{n+1}
\end{aligned}
\end{equation}
normalized to $t \in [0, \dt_n]$
for a first analysis but the central version in the implementation and a
more numerically supported analysis.

\subsubsection{Left-biased cubic Hermite interpolation}

The analysis proceeds with the weighted $L^1$ error estimate
\eqref{eq:weighted-estimate-residual-L1} given by
\begin{equation}
\begin{aligned}
  |e_{n+1}|
  =
  \| R \|_{L^1(t^n, t^{n+1})}
  &=
  \int_{t^{n}}^{t^{n+1}} \left|
    \frac{\dif}{\dif t} \widehat{u}(t) - \lambda \widehat{u}(t)
  \right| \dif t
  \\
  &=
  \frac{1}{6} \int_{0}^{\dt_n} t^3 \dif t \;
  |\lambda|^4 |u^{n}|
  =
  \frac{1}{24} \dt_n^4 |\lambda|^4 |u^{n}|.
\end{aligned}
\end{equation}
The expression of the Jacobian \eqref{eq:jacobian-I} of the I controller with
residual error estimator becomes
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u \\
  -\frac{1}{k} & 1 - \frac{4}{k} \\
  \end{pmatrix},
  \quad
  u = \Re\biggl( \frac{z + z^2 + z^3 / 2}{1 + z + z^2/2 + z^3 / 6} \biggr).
\end{equation}
If we use the $L^2$ error estimate \eqref{eq:weighted-estimate-residual-L2}
instead, we get
\begin{equation}
  |e_{n+1}|
  =
  \sqrt{\dt_n} \| R \|_{L^2(t^n, t^{n+1})}
  =
  \frac{1}{6 \sqrt{7}} \dt_n^4 |\lambda|^4 |u^{n}|
\end{equation}
for the left-biased cubic Hermite interpolation
\eqref{eq:cubic-hermite-left} and thus the same Jacobian as for the $L^1$
error estimate discussed above.

% Figure environment removed

The spectral radii of the Jacobians are visualized in
Figure~\ref{fig:spectral_radius_bs3}.
Again, all methods do not lead to step size control stability.

The expression of the Jacobian \eqref{eq:jacobian-PID} of the PI controller
with residual error estimator becomes
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u & 0 & 0 \\
    -\frac{\beta_1}{k} & 1 - \frac{4 \beta_1}{k} &
      -\frac{\beta_2}{k} & -\frac{4 \beta_2}{k} \\
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0
  \end{pmatrix},
  \quad
  u = \Re\biggl( \frac{z + z^2 + z^3 / 2}{1 + z + z^2/2 + z^3 / 6} \biggr).
\end{equation}
The spectral radii of the Jacobians for the PI controller with parameters
$\beta = (0.6, -0.2, 0.0)$ recommended in \cite{ranocha2021optimized} are
visualized in Figure~\ref{fig:spectral_radius_bs3}. Clearly, the more
involved controller leads to step size control stability for all approaches.

\subsubsection{Central cubic Hermite interpolation}

Recall the Jacobian \eqref{eq:jacobian-I} of the I controller system.
For the $L^1$ residual error estimator with central cubic Hermite interpolation,
the Jacobian is
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u \\
    -\frac{1}{k} &
      1 - \frac{1}{k} \partial_{\chi_{n}} \log|e_{n+1}|
  \end{pmatrix},
  \qquad
  u = \Re\biggl( \frac{R'(z)}{R(z)} z \biggr),
\end{equation}
where $\eta_n = \log|u^n|$, $\chi_n = \log \dt_n$, and $z = \lambda \dt_n$.
We have not been able to compute the expression $\partial_{\chi_n} |e_{n+1}|$
analytically in this case. However, we can evaluate it numerically by using
an adaptive Gauss-Kronrod quadrature with relative tolerance $10^{-8}$ and
absolute tolerance $10^{-14}$ implemented in QuadGK.jl \cite{johnson2013quadgk}
for the integrals
\begin{equation}
\begin{aligned}
  |e_{n+1}|
  &=
  \int_{0}^{\dt_n} h(t) \dif t,
  \qquad
  h(t) := \frac{1}{6} t (\dt_n - t) \bigl|t - 2 \dt_n + t \dt_n \lambda\bigr| |\lambda|^4 |u^n|,
  \\
  \partial_{\chi_n} |e_{n+1}|
  &=
  \left(
    h(\dt_n) + \int_{0}^{\dt_n} \frac{\partial h(t)}{\partial \dt_n} \dif t
  \right) \dt_n,
\end{aligned}
\end{equation}
where the derivatives are evaluated using ForwardDiff.jl
\cite{revels2016forward}.

% Figure environment removed

The spectral radii of the Jacobians are visualized in
Figure~\ref{fig:spectral_radius_bs3_quadrature}.
Again, both methods do not lead to step size control stability for the simple
I controller.
It is interesting to see that the general trend of the spectral radius
is similar to the one computed for the left-biased cubic Hermite interpolation
shown in Figure~\ref{fig:spectral_radius_bs3}. However, the spectral radius does
not exceed unity near $\phi = \pi$ for the central interpolation (while still
being close to unity). This is in accordance with numerical results presented
later in Section~\ref{sec:krogh}.

Using the same test problem \eqref{eq:test-problem-hairer-wanner} as for
second-order, two-stage methods results in
1318 accepted and 120 rejected steps
for the the embedded approach while the residual-based approach leads to
1327 accepted and 21 rejected steps,
see Table~\ref{tab:BS3}.
This is in accordance with the spectral radius of the residual-based approach
exceeding unity less than the embedded approach.

The expression of the Jacobian \eqref{eq:jacobian-PID} of the PI controller
with residual error estimator becomes
\begin{equation}
  J =
  \begin{pmatrix}
    1 & u & 0 & 0 \\
    -\frac{\beta_1}{k} & 1 - \frac{\beta_1}{k} \frac{\partial |e_{n+1}|}{\partial \chi_{n}}  &
      -\frac{\beta_2}{k} & -\frac{\beta_2}{k} \frac{\partial |e_{n}|}{\partial \chi_{n-1}}  \\
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0
  \end{pmatrix},
  \quad
  u = \Re\biggl( \frac{z + z^2 + z^3 / 2}{1 + z + z^2/2 + z^3 / 6} \biggr).
\end{equation}
The spectral radii of the Jacobians for the PI controller with parameters
$\beta = (0.6, -0.2, 0.0)$ recommended in \cite{ranocha2021optimized} are
visualized in Figure~\ref{fig:spectral_radius_bs3_quadrature}. Clearly, the
more involved controller leads to step size control stability for all
approaches.
For the test problem \eqref{eq:test-problem-hairer-wanner}, we get
1330 accepted and 1 rejected steps
for the the embedded approach while the residual-based approach leads to
1333 accepted and 1 rejected steps.

Finally, we are able to compute the $L^2$ error estimate for the
central cubic Hermite interpolation \eqref{eq:cubic-hermite-central}
analytically, resulting in
\begin{equation}
  |e_{n+1}|
  =
  \sqrt{\dt_n} \| R \|_{L^2(t^n, t^{n+1})}
  =
  \frac{1}{6 \sqrt{105}} \dt_n^4 |\lambda|^4 |u^{n}|
    \sqrt{8 + \dt^2 |\lambda|^2 - 5 \dt_n \Re(\lambda)}.
\end{equation}
Then, the expression of the Jacobian \eqref{eq:jacobian-I} of the I controller
with $L^2$ residual error estimator becomes
\begin{equation}
\begin{gathered}
  J =
  \begin{pmatrix}
    1 & u \\
  -\frac{1}{k} & J_{22} \\
  \end{pmatrix},
  \\
  u = \Re\biggl( \frac{z + z^2 z^3 / 2}{1 + z + z^2/2 + z^3 / 6} \biggr),
  \;
  J_{22} = 1 - \frac{64 + 10 |z|^2 - 45 \Re(z)}{2 k \bigl( 8 + |z|^2 - 5 \Re(z) \bigr)}.
\end{gathered}
\end{equation}

% Figure environment removed

The spectral radii of the Jacobians are visualized in
Figure~\ref{fig:spectral_radius_bs3_l2}. The spectral radii of the
$L^2$ error estimator with central cubic Hermite interpolation
\eqref{eq:cubic-hermite-central} exceed unity less than the spectral radii
of the $L^1$ error estimator \eqref{eq:weighted-estimate-residual-L1} with
left-biased cubic Hermite interpolation \eqref{eq:cubic-hermite-left}. However,
they still do not lead to step size control stability.

The expression of the Jacobian \eqref{eq:jacobian-PID} of the PI controller
with $L^2$ residual error estimator becomes
\begin{equation}
\begin{gathered}
  J =
  \begin{pmatrix}
    1 & u & 0 & 0 \\
    -\frac{\beta_1}{k} & 1 - \beta_1 \alpha &
      -\frac{\beta_2}{k} & -\beta_2 \alpha \\
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0
  \end{pmatrix},
  \\
  u = \Re\biggl( \frac{z + z^2 z^3 / 2}{1 + z + z^2/2 + z^3 / 6} \biggr),
  \;
  \alpha = \frac{64 + 10 |z|^2 - 45 \Re(z)}{2 k (8 + |z|^2 - 5 \Re(z)}.
\end{gathered}
\end{equation}
The spectral radii of the Jacobians for the PI controller with parameters
$\beta = (0.6, -0.2, 0.0)$ recommended in \cite{ranocha2021optimized} are
visualized in Figure~\ref{fig:spectral_radius_bs3_l2}. Clearly, the more
involved controller leads to step size control stability for all approaches.
Again, the $L^2$ error estimator with central cubic Hermite interpolation
leads to more damping around $\phi = 5 \pi / 8$ than the $L^1$ version with
left-biased interpolation.

Using the $L^2$ error estimator with central cubic Hermite interpolation
but otherwise the same setup as before, we get
1326 accepted and 25 rejected steps for the I controller and
1333 accepted and 1 rejected steps for the PI controller,
see Table~\ref{tab:BS3}.

\begin{table}[htbp]
\centering
  \caption{Number of accepted and rejected time steps of
           the Runge-Kutta pair of Bogacki and Shampine \cite{bogacki1989a32}
           for the test problem \eqref{eq:test-problem-hairer-wanner} with
           tolerances $\atol = \rtol = 10^{-4}$ using the central cubic
           Hermite interpolation for the residual error estimators.}
  \label{tab:BS3}
  \begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}c *3c *3c}
    \toprule
    & \multicolumn{3}{c}{I controller, $\beta = (1, 0, 0)$}
    & \multicolumn{3}{c}{PI controller, $\beta = (0.6, -0.2, 0)$}
    \\
    & \multicolumn{2}{c}{Residual Estimator}
    & \multicolumn{1}{c}{Embedded}
    & \multicolumn{2}{c}{Residual Estimator}
    & \multicolumn{1}{c}{Embedded}
    \\
    & \multicolumn{1}{c}{$L^1$}
    & \multicolumn{1}{c}{$L^2$}
    & \multicolumn{1}{c}{Method}
    & \multicolumn{1}{c}{$L^1$}
    & \multicolumn{1}{c}{$L^2$}
    & \multicolumn{1}{c}{Method}
    \\
    \midrule
    $k$ & 4 & 4 & 3
        & 4 & 4 & 3
    \\
    Accepted & 1327 & 1326 & 1318
             & 1333 & 1333 & 1330
    \\
    Rejected & 21 & 25 & 120
             & 1 & 1 & 1
    \\
    \bottomrule
  \end{tabular*}
\end{table}


\section{Numerical experiments}
\label{sec:numerical_experiments}

We have implemented all methods in Julia \cite{bezanson2017julia} and
use OrdinaryDiffEq.jl \cite{rackauckas2017differentialequations} for
the classical schemes with embedded methods. We use an adaptive Gauss-Kronrod
quadrature implemented in QuadGK.jl \cite{johnson2013quadgk} to compute the
integrals appearing in the residual error estimators; we set the relative
error tolerance to $10^{-8}$ for the ODE tests and to $10^{-6}$ for
the tests involving partial differential equations (PDEs).
The absolute and relative tolerances of the step size controller are equal,
$\atol = \rtol = \tol$. We use an adaptation of the algorithm of
\cite[Section~II.4]{hairer2008solving} to determine the initial time step size.
We use FFTW.jl \cite{frigo2005design} via the interface provided by
SummationByPartsOperators.jl \cite{ranocha2021sbp} for Fourier collocation
methods and Trixi.jl \cite{ranocha2022adaptive,schlottkelakemper2021purely}
for discontinuous Galerkin discretizations of conservation laws.
Finally, we use Plots.jl \cite{christ2023plots} to visualize the results.
All source code required to reproduce the numerical experiments is available
in our reproducibility repository \cite{ranocha2023stabilityRepro}.

First, we test the step size control stability theory with a nonlinear
ODE in Section~\ref{sec:krogh}. Thereafter, we study the methods in the two
regimes important for step size control of explicit time integration schemes:
the asymptotic regime of small time step sizes and the stability-limited regime.
We choose a classical ODE problem (Section~\ref{sec:rigidbody}) and a
non-stiff PDE (Section~\ref{sec:bbm}) for the asymptotic regime. Afterwards,
we consider hyperbolic conservation laws to study the stability-limited regime
in Sections~\ref{sec:linadv} and \ref{sec:euler}.

In all cases, we just show numerical results for the $L^1$ residual error
estimates. The corresponding results based on $L^2$ error estimates are
very similar (and can also be reproduced using the code of our reproducibility
repository \cite{ranocha2023stabilityRepro}).


\subsection{A nonlinear ODE}
\label{sec:krogh}

First, we follow \cite{higham1990embedded} and consider the nonlinear test
problem
\begin{equation}
\label{eq:krogh}
  u' = -B u + U^T (z_1^2 /2 - z_2^2 / 2, z_1 z_2, z_3^2, z_4^2)^T,
  \quad
  u(0) = 0, -2, -1, -1)^T,
\end{equation}
of Krogh \cite{krogh1973testing} with
\begin{equation}
  z = U u,
  \quad
  B = U^T \begin{pmatrix}
            -10 \cos(\phi) & - 10 \sin(\phi) & 0 & 0 \\
            10 \sin(\phi) & -10 \cos(\phi) & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 0 & 0 & 1 / 2
          \end{pmatrix} U,
\end{equation}
where $U \in \R^{4 \times 4}$ contains $-1/2$ on the diagonal and $+1 / 2$
in all other components. For a fixed parameter $\phi$, the dominant eigenvalues
of the Jacobian for $t \to \infty$ become
$-10 |\cos(\phi)| \pm \i 10 \sin(\phi)$.

% Figure environment removed

We integrate the problem in the time interval $[0, 100]$ using the
third-order method of Bogacki and Shampine \cite{bogacki1989a32}
with both the embedded method and the $L^1$ residual error estimator.
The number of rejected steps for the simple I controller and the
PI controller given by $\beta = (0.6, -0.2)$ are shown in
Figure~\ref{fig:krogh}. Clearly, a significant number of steps is
rejected when the parameter $\phi$ is in the region around $\phi = 5 \pi / 8$
where the simple I controller is not stable. In contrast, the advanced PI
controller leads to at most one or two rejected steps for all values
of $\phi$.


\subsection{Euler equations of a rigid body}
\label{sec:rigidbody}

We consider the Euler equations of a rigid body with parameters used by
Krogh \cite{krogh1973testing}, i.e.,
\begin{equation}
  u'(t) = \begin{pmatrix} u_2 u_3 \\ -u_1 u_3 \\ -0.51 u_1 u_2 \end{pmatrix},
  \quad
  u(0) = \begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix}.
\end{equation}
The solution is periodic with periodic given by Krogh \cite{krogh1973testing}.
We compute the $\ell^2$ error after one period.

% Figure environment removed

Numerical results obtained by the third-order method of Bogacki and Shampine
\cite{bogacki1989a32} with both the embedded method and the $L^1$ residual
error estimator are shown in Figure~\ref{fig:rigidbody}.
First, there are no issues with step rejections for this problem. Indeed,
the residual-based approach leads to no step rejections and the embedded method
rejects at most one or two steps for a few tolerances.

Next, it is interesting to observe that the embedded approach tends to result
in a smaller error at the final time for a given tolerance than the
residual-based approach. However, this does not mean that the efficiency
measured as the error for a fixed number of (accepted plus rejected) steps
is different. Indeed, both approaches lead to the same behavior in a classical
work precision diagram. Thus, both approaches lead to the same behavior of
\emph{tolerance convergence} (the error goes to zero for $\tol \to 0$) and
\emph{computational stability} (small changes in the tolerance lead to small
changes of the numerical results), see \cite{soderlind2002automatic} for a
discussion of these properties.


\subsection{1D Benjamin-Bona-Mahony equation}
\label{sec:bbm}

Next, we consider the Benjamin-Bona-Mahony (BBM) equation
\cite{benjamin1972model} (also known as regularized long wave equation)
\begin{equation}
\label{eq:bbm}
\begin{aligned}
  (\I - \partial_x^2) \partial_t u(t,x)
  + \partial_x \frac{u(t,x)^2}{2}
  + \partial_x u(t,x)
  &= 0,
  \\
  u(0, x) &= u^0(x),
\end{aligned}
\end{equation}
with periodic boundary conditions as a model of nonlinear dispersive wave
equations. We use the Fourier collocation semidiscretization of
\cite{ranocha2021broad} conserving discrete versions of the linear and
quadratic invariants
\begin{equation}
  \int u(t, x) \dif x,
  \quad
  \int \bigl( u(t,x)^2 + \bigl( \partial_x u(t,x) \bigr)^2 \bigr) \dif x.
\end{equation}
Due to the dispersive term $\partial_x^2 \partial_t u$ with mixed space and
time derivatives, the semidiscretization yields a non-stiff ODE with CFL
restriction of the form $\dt \lesssim \mathrm{const}$.

We consider the traveling wave solution
\begin{equation}
\label{eq:bbm-traveling-wave}
  u(t,x) = A \cosh( K (x - c t) ),
  \quad A = 3 (c - 1),
  \quad K = \frac{1}{2} \sqrt{1 - 1 / c},
\end{equation}
with speed $c = 1.2$ in the periodic domain $[-90, 90]$ and integrate the
semidiscretization with the third-order method of Bogacki and Shampine
\cite{bogacki1989a32} in a time interval big enough so that the wave traverses
the domain a bit more than once.

% Figure environment removed

The results are visualized in Figure~\ref{fig:bbm}. The residual-based approach
leads to the expected behavior of a short transient period and a constant time
step size afterwards. The embedded method behaves similarly but leads to a
slowly growing time step size. The reason for this appears to be that it takes
slightly bigger time steps, leading to more dissipation of the numerical
solution. This in turn allows to take even bigger time steps, leading to
a visibly more dissipated numerical solution.

Both methods lead to an expected convergence behavior for stricter tolerances.
However, the residual-based approach tends to lead to a smaller error at
the final time than the embedded approach in this case. This is qualitatively
similar to the results obtained for the rigid body equations in
Section~\ref{sec:rigidbody} --- but with reversed roles of the two error
estimators. Nevertheless, both methods lead to the same behavior in a
work precision diagram measuring the discrete $L^2$ error at the final time
for a given number of steps --- while both methods lead to no rejected steps
in this case.


\subsection{2D linear advection}
\label{sec:linadv}

We consider the 2D linear advection equation
\begin{equation}
  \partial_t u + \div(a u) = 0
\end{equation}
with periodic boundary conditions in $[-1, 1]^2$, the advection velocity
$a = (1, 1)^T$, and a sinusoidal initial condition. Using the method of lines
approach, we discretize the PDE first in space with a discontinuous Galerkin
spectral element method (DGSEM) on Gauss-Lobatto-Legendre nodes representing
polynomials of degree $p = 4$; an introduction to such nodal DG methods is
given in the textbooks \cite{hesthaven2007nodal,kopriva2009implementing}.
We divide the domain into $8^2$ uniform elements and apply the
local Lax-Friedrichs/Rusanov flux at interfaces.
Finally, we integrate the resulting ODE in time using the third-order method
of Bogacki and Shampine \cite{bogacki1989a32} with PI controller parameters
$\beta = (0.6, -0.2)$.

% Figure environment removed

As discussed in \cite{ranocha2021optimized,ranocha2023error}, a typical
behavior for such problems is as follows. Initially, the time step size
varies a bit and quickly converges to a constant. There is usually a range
of tolerances where the time step size $\dt$ is restricted by stability.
In this regime, error-based step size control with stable controllers results
in optimal time step sizes that can also be obtained by manually optimizing a
Courant-Friedrichs-Lewy (CFL) factor.
This behavior is shown in Figure~\ref{fig:linadv}; the embedded method and
the residual-based error estimator behave very similarly.
In particular, both methods lead to at most three rejected steps for loose
tolerances.


\subsection{3D inviscid Taylor-Green vortex}
\label{sec:euler}

Next, we consider the ideal 3D compressible Euler equations to simulate
an inviscid Taylor-Green vortex. We choose the initial condition
\begin{equation}
\begin{gathered}
  \rho = 1, \;
  v_1 =  \sin(x_1) \cos(x_2) \cos(x_3), \;
  v_2 = -\cos(x_1) \sin(x_2) \cos(x_3), \;
  v_3  = 0, \\
  p = \frac{\rho^0}{\mathrm{Ma}^2 \gamma} + \rho^0 \frac{\cos(2 x_1) \cos(2 x_3) + 2 \cos(2 x_2) + 2 \cos(2 x_1) + \cos(2 x_2) \cos(2 x_3)}{16},
\end{gathered}
\end{equation}
where $\mathrm{Ma} = 0.1$ is the Mach number, $\rho$ the density, $v$ the
velocity, and $p$ the pressure.
We consider the domain $[-\pi, \pi]^3$ with periodic boundary conditions
and a time interval $[0, 10]$.
We use the entropy-stable semidiscretization with flux differencing DGSEM
with polynomials of degree $p = 3$, the entropy-conservative flux of
\cite{ranocha2018comparison,ranocha2020entropy,ranocha2021preventing}
in the volume and a local Lax-Friedrichs/Rusanov numerical flux at interfaces.
This kind of flux differencing discretizations is described in
\cite{fisher2013high,gassner2016split}; see also \cite{ranocha2021efficient}.

% Figure environment removed

The results of a simulation with $8^3$ elements and a time integration
tolerance $\tol = 10^{-5}$ are shown in Figure~\ref{fig:euler}. In this case,
the time step size $\dt$ is again restricted by stability constraints.
The time step sizes chosen by the different estimators --- the embedded method
and the $L^1$ residual estimate --- are visually indistinguishable.
The residual-based approach leads to 3 step rejections while the embedded
method leads to 2 rejected steps.



\section{Summary and conclusions}
\label{sec:summary}

We have analyzed stability of step size control of
explicit Runge-Kutta methods for ODEs using residual-based a posteriori error estimators of
\cite{dedner2016posteriori} when step sizes are dictated by stability and not accuracy.
It turned out that the situation is comparable to the case of embedded
methods, i.e., the classical I controller does not lead to step size control
stability while more advanced PI and PID controllers can be designed to be
stable. We have analyzed the situation for ODEs and demonstrated that the
findings extend to some PDEs discretized using the method of lines.
In particular, we have considered the nonlinear dispersive Benjamin-Bona-Mahony
equation as well as discontinuous Galerkin semidiscretizations of the 2D linear
advection and 3D compressible Euler equations.

