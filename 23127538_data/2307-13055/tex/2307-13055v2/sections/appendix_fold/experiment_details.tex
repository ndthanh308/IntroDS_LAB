\section{Experimental Details}
\subsection{Baselines}
We consider empirical risk minimization (ERM), one OOD algorithm IRM and one graph-specific OOD algorithm EERM as supervised baselines. And we include 9 self-supervised methods as unsupervised baselines:
\begin{itemize}
    \item Invariant Risk Minimization (IRM~\cite{irm}) is an algorithm that seeks to learn data representations that are robust and generalize well across different environments by penalizing feature distributions that have different optimal linear classifiers for each environment
    \item EERM~\cite{eerm}  generates multiple graphs by environment generators and minimizes the mean and variance of risks from multiple environments to capture invariant features.
    \item Graph Autoencoder (GAE~\cite{gae}) is an encoder-decoder structure model. Given node attributes and structures, the encoder will compress node attributes into low-dimension latent space, and the decoder (dot-product) hopes to reconstruct existing links with compact node features.
    \item Variational Graph Autoencoder (VGAE~\cite{gae}) is similar to GAE but the node features are re-sampled from a normal distribution through a re-parameterization trick.
    \item GraphMAE~\cite{gmae} is a masked autoencoder. Different to GAE and VGAE, it will mask partial input node attributes firstly and then the encoder will compress the masked graph into latent space, finally a decoder aims to reconstruct the masked attributes. 
    % Compared with simple binary classification in GAE and VGAE, masked attributes reconstruction is more challenging, so GraphMAE can ach 
    \item Deep Graph Infomax (DGI~\cite{dgi}) is a node-graph contrastive method which contrasts the node representations and graph representation. First, it will apply the corrupt function to obtain a negative graph and two graphs will be fed into a shared GNN model to generate node embeddings. And a readout function will be applied on the original node embeddings to obtain graph-level representation. Corrupted embeddings and readout graph representation are considered as positive pairs, original node representations and readout graph representation are considered as positive pairs. 
    \item MVGRL~\cite{mvgrl} is similar to DGI but utilizes the information of multi-views. Firstly, it will use edge diffusion function to generate an augmented graph. And asymmetric encoders will be applied on the original graph and diffusion graph to acquire node embeddings. Next, a readout function is employed to derive graph-level representations. Original node representations and augmented graph-level representation are regarded positive pairs. Additionally, the augmented node representations and original graph-level representation are also considered as positive pairs. The negative pairs are constructed following \cite{dgi}.
    \item GRACE~\cite{grace} is node-node graph contrastive learning method. It designs two augmentation functions (\ie, removing edges and masking node features) to generate two augmented views. Then a shared graph model will be applied on augmented views to generate node embedding matrices. The node representations augmented from the same original node are regarded as positive pairs, otherwise are negative pairs. Lastly, pairwise loss (\eg, InfoNCE~\cite{cpc}) will be applied on these node matrices.
    \item BGRL~\cite{bgrl} is similar to GRACE but without negative samples which is motivated by BYOL~\cite{byol}.
    \item COSTA~\cite{costa} proposes feature augmentation to decrease the bias introduced by graph augmentation.
    \item SwAV~\cite{swav} is an unsupervised online clustering method which incorporates prototypes for clustering and employs swapped prediction for model training. It is originally designed for the computer vision domain, we adopt it into graph domain.
\end{itemize}


\subsection{Datasets}
For GOOD-Cora, GOOD-Twitch, GOOD-CBAS and GOOD-WebKB datasets, they are all adopted from GOOD\cite{good} which is a comprehensive Graph OOD benchmark. These datasets contain both concept shift and covariate shift splits, for more details of splitting, please refer to Appendix A in \cite{good}. 

GOOD-Cora is a citation network that is derived from the full Cora dataset~\cite{bojchevskideep}. In the network, each node represents a scientific publication, and edges between nodes denote citation links. The task is to predict publication types (70-classification) of testing nodes. The data splits are generated based on two domain selections (\ie, word, degree). 
The word diversity selection is based on the count of selected words within a publication and is independent of the publication's label. On the other hand, the node degree selection ensures that the popularity of a paper does not influence its assigned class.

GOOD-Twitch is a gamer network dataset. In this dataset, each node represents a gamer, and the node features correspond to the games played by each gamer. The edges between nodes represent friendship connections among gamers. The binary classification task associated with this dataset involves predicting whether a user streams mature content or not. The data splits for GOOD-Twitch are based on the user language, ensuring that the prediction target is not biased by the specific language used by a user.

GOOD-CBAS is a synthetic dataset that is modified from the BA-Shapes dataset~\cite{ying2019gnnexplainer}. It involves a graph where 80 house-like motifs are attached to a base graph following the Barabási–Albert model, resulting in a graph with 300 nodes. The task associated with this dataset is to predict the role of each node within the graph. The roles can be classified into four classes, which include identifying whether a node belongs to the top, middle, or bottom of a house-like motif, or if it belongs to the base graph itself.
In contrast to using constant node features, the GOOD-CBAS dataset introduces colored features. This modification poses challenges for out-of-distribution (OOD) algorithms, as they need to handle differences in node colors within covariate splits and consider the correlations between node color and node labels within concept splits.

GOODWebKB is a network dataset that focuses on university webpages. Each node in the network represents a webpage, and the node features are derived from the words that appear on the webpage. The edges between nodes represent hyperlinks between webpages. The task associated with this dataset is a 5-class prediction task, where the goal is to predict the class of each webpage. The data splits for GOOD-WebKB are based on the domain of the university, ensuring that the classification of webpages is based on their word contents and link connections rather than any specific university features.

Amazon-Photo is a co-purchasing network that is widely used for evaluating the design of GNN models. In this network, each node corresponds to a specific product, and the presence of an edge between two products indicates that they are frequently purchased together by customers. In the original dataset, it is observed that the node features exhibit a significant correlation with the corresponding node labels. In order to evaluate the model's ability to generalize to out-of-distribution scenarios, it is necessary to introduce distribution shifts into the training and testing data. To achieve this, we adopt the strategies employed in the EERM~\cite{eerm}. Specifically, we leverage the available node features $X_1$ to create node labels $Y$ and spurious environment-sensitive features $X_2$. To elaborate, a randomly initialized GNN takes $X_1$ and the adjacency matrix as inputs and employs an argmax operation in the output layer to obtain one-hot vectors as node labels. Additionally, we employ another randomly initialized GNN that takes the concatenation of $Y$ and an environment id as input to generate spurious node features $X_2$. By combining these two sets of features, we obtain the input node features, $X = [X_1, X_2]$, which are used for both training and evaluation. This process is repeated to create ten graphs with distinct environment id's. Such a shift between different graphs can be considered as a concept shift~\cite{ood-survey}. Finally, one graph is allocated for training, another for validation, and the remaining graphs are used for evaluating the OOD generalization of the trained model.



Elliptic is a financial network that records the payment flows among transactions as time goes by. It consists of 49 graph snapshots which are collected at different times. Each graph snapshot is a network of Bitcoin transactions where each node represents one transaction and each edge denotes a payment flow. Partial nodes (approximately 20\%) are labeled as licit or illicit transactions and we hope to identify illicit transactions in the future. For data preprocessing, we adopt the same strategies in EERM~\cite{eerm}: removing extremely imbalanced snapshots and using the 7th-11th/12th-17th/17th-49th snapshots for training/validation/testing data. And 33 testing graph snapshots will be split into 9 test sets according to chronological order. In Figure~\ref{fig:rate}, we depict the label rate and positive label rate for training/validation/testing sets. It is evident that the varying positive label rates across different data sets are apparent. Indeed, the model needs to deal with the label distribution shifts from training to testing data.
% Figure environment removed
\subsection{Hyper-parameters}
For GOOD datasets, we adopt GraphSAINT~\cite{} as subsampling technique, while utilizing a 3-layer GCN~\cite{gcn} with 300 hidden units as the backbone following~\cite{good}. For the supervised baselines (\ie, ERM, IRM, EERM), we use the identical hyper-parameters specified in \cite{good}. For other unsupervised baselines, we conduct a grid search to find the best performance. Specifically, max training epoch ranges in \{50, 100, 200, 500, 600\} and learning rate ranges in \{1e-1,1e-2,1e-3,1e-4,1e-5\}, augmentation ratio range in $[0.1, 0.6]$. Regarding GraphMAE, the masking ratio ranges in \{0.25,0.5,0.75\}, and we use a one-layer GCN as the decoder. For MARIO, the specific hyper-parameters are listed in Table~\ref{tab:hyper}. For the adversarial augmentation, we set ascent steps $M$ as 3 and the ascent step size $\epsilon$ as 1e-3. For detailed hyper-parameters of all algorithms, please refer to \hyperlink{https://github.com/ZhuYun97/MARIO}{https://github.com/ZhuYun97/MARIO}.

For Amazon-Photo, we utilize 2-layer GCN with 128 hidden units as encoder, and we set $\tau, p_{f,1}, p_{f,2}, p_{e,1}, p_{e,2}, \gamma, |C|$ as 0.2, 0.2, 0.3, 0.2, 0.3, 0.1, 100 respectively and learning rate as 1e-4. Other hyper-parameters remain the same in EERM~\cite{eerm}.
Regarding Elliptic datasets, we employ 5-layer GraphSAGE~\cite{sage} with 32 hidden units as encoder following EERM~\cite{eerm}. And we set $\tau, p_{f,1}, p_{f,2}, p_{e,1}, p_{e,2}, \gamma, |C|$ as 0.8, 0.2, 0.3, 0.2, 0.3, 0.5, 120 respectively. The remaining hyper-parameters are consistent with EERM~\cite{eerm}.
% We list the specific hyper-parameters we used to report results:
\begin{table*}[htp]
    \centering
    \begin{tabular}{c|cc|cc|cc|cc|cc}
    \toprule
              & \multicolumn{4}{c|}{GOOD-Cora}                                     & \multicolumn{2}{c|}{GOOD-CBAS}  & \multicolumn{2}{c|}{GOOD-Twitch} & \multicolumn{2}{c}{GOOD-WebKB} \\
              & \multicolumn{2}{c}{word}         & \multicolumn{2}{c|}{degree}     & \multicolumn{2}{c|}{color}      & \multicolumn{2}{c|}{language}    & \multicolumn{2}{c}{university}  \\
              & concept      & covariate         & concept      & covariate       & concept      & covariate       & concept      & covariate        & concept      & covariate       \\     \midrule                  
Model         & GCN          & GCN               & GCN          & GCN             & GCN          & GCN             & GCN          & GCN              & GCN          & GCN             \\
\# Layers     & 3            & 3                 & 3            & 3               & 3            & 3               & 3            & 3                & 3            & 3                \\
\# Hidden size & 300         & 300               & 300          & 300             & 300          & 300             & 300          & 300              & 300          & 300              \\
Epochs        & 100          & 150               & 100          & 100             & 200          & 500             & 600          & 200              & 100          & 500               \\
Learning rate & 1e-3         & 1e-3              & 1e-3         & 1e-3            & 1e-1         & 1e-2            & 1e-1         & 1e-1             & 1e-2         & 1e-2               \\ \midrule
$\tau$        & 0.2          & 0.2               & 0.2          & 0.2             & 0.2          & 0.2             & 0.2          & 0.2              & 0.5          & 0.5                 \\
$p_{f,1}$     & 0.3          & 0.3               & 0.0          & 0.3             & 0.2          & 0.2             & 0.2          & 0.2              & 0.5          & 0.2                \\
$p_{f,2}$     & 0.4          & 0.3               & 0.0          & 0.3             & 0.3          & 0.3             & 0.3          & 0.3              & 0.5          & 0.3                   \\
$p_{e,1}$     & 0.4          & 0.4               & 0.6          & 0.6             & 0.2          & 0.2             & 0.2          & 0.2              & 0.5          & 0.2                \\
$p_{e,2}$     & 0.5          & 0.4               & 0.6          & 0.6             & 0.3          & 0.3             & 0.3          & 0.3              & 0.5          & 0.3                \\
$|C|$         & 100          & 100               & 150          & 150             & 100          & 100             & 100          & 100              & 100          & 100               \\
$\gamma$      & 0.2          & 0.5               & 0.8          & 0.8             & 0.1          & 0.1             & 0.2          & 0.2              & 0.1          & 0.2                  \\ 
Pro. LR       & 1e-5         & 1e-5              & 1e-5         & 1e-5            & 1e-4         & 1e-3            & 1e-5         & 1e-3             & 1e-3         & 1e-3                \\\midrule
Epochs for LC & 500          & 200               & 100          & 100             & 100          & 2000            & 100          & 100              & 50           & 50                 \\
LR for LC     & 1e-4         & 1e-3              & 1e-3         & 1e-3            & 1e-2         & 1e-3            & 1e-1         & 1e-1             & 1e-1         & 1e-1                 \\
\bottomrule
    \end{tabular} 
    \caption{Hyperparameters specifications for MARIO}
    \label{tab:hyper}
\end{table*}

\subsection{Evaluation metrics}
In order to evaluate the pre-trained models, we adopt the linear evaluation protocol which is commonly used in self-supervised methods~\cite{simclr,moco,byol}. That is, we will train a linear classifier (\ie, one-layer MLP) on top of (frozen) representations learned by self-supervised methods. The training epochs (Epochs for LC in Table~\ref{tab:hyper}) and learning rate (LR for LC in Table~\ref{tab:hyper}) of the linear classifier are obtained by grid search.

\subsection{Computer infrastructures specifications}
For hardware, all experiments are conducted on a computer server with eight GeForce RTX 3090 GPUs with 24GB memory and 64 AMD EPYC 7302 CPUs. And our models are implemented by Pytorch Geometric 2.0.4~\cite{fey2019fast} and Pytorch 1.11.0~\cite{torch}. All datasets used in our
work are available on \hyperlink{https://github.com/divelab/GOOD}{https://github.com/divelab/GOOD} and \hyperlink{https://github.com/qitianwu/GraphOOD-EERM}{https://github.com/qitianwu/GraphOOD-EERM}.

\section{Additional Experiments}
\subsection{Metric scores curves}
In the main text, we draw the metric scores curves of GOOD-CBAS datasets, here we draw more metric scores curves. We can draw the same conclusions described in the main text from Figure~\ref{fig:curve_cora1},\ref{fig:curve_cora2},\ref{fig:curve_twitch},\ref{fig:curve_webkb}.
% Figure environment removed
% Figure environment removed
% Figure environment removed
% Figure environment removed