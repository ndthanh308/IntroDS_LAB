\section{Related Works}
\subsection{Self-supervised Graph Learning}
% With the eye-catching success of self-supervised on computer vision domain~\cite{moco,simclr,byol,raft,simsiam,mae}, self-supervised graph learning has been booming recently~\cite{rosa,grace,graphcl,bgrl,dgi,mvgrl,gmae,costa}. Specifically, self-supervised graph learning can be categorized into three main kinds: predictive methods, generative methods, and contrastive methods~\cite{wu2021self}. Predictive methods need to design prediction-based pre-training tasks (\eg, degree prediction~\cite{hu2020strategies}) based on self-generative labels by statistical analysis~\cite{hu2020strategies}. 
% Generative methods focus on learning intra-data information within graphs through feature/edge reconstruction~\cite{gae,gmae}. Recently, the generative-based masked autoencoders (e.g., GraphMAE~\cite{gmae}) show their superior performance across different tasks by reconstructing masked features.
% Contrastive methods focus on learning inter-data information between graphs by drawing positive data pairs closer and pushing away the negative data pairs in the representation space.
\noindent The remarkable success of self-supervised learning in the field of computer vision~\cite{moco,simclr,byol,raft,simsiam,mae}, has sparked a surge of interest in self-supervised graph learning~\cite{rosa,grace,graphcl,bgrl,dgi,mvgrl,gmae,costa}. Self-supervised graph learning can be broadly categorized into three main types: predictive methods, generative methods, and contrastive methods~\cite{wu2021self}.
Predictive methods require the design of prediction-based pre-training tasks, such as degree prediction, which utilize self-generated labels derived from statistical analysis~\cite{hu2020strategies}.
Generative methods aim to learn intra-data information within graphs by focusing on feature or edge reconstruction~\cite{gae,gmae}. Recently, generative-based masked autoencoders like GraphMAE have demonstrated superior performance across various tasks by reconstructing masked features.
Contrastive methods, on the other hand, emphasize learning inter-data information between graphs by bringing positive data pairs closer together and pushing negative data pairs apart in the representation space.

% Both generative and contrastive methods have made significant progress in the graph domain, surpassing supervised methods in certain scenarios even without human annotations~\cite{gmae,grace,rosa,mvgrl}.
% However, most current graph self-supervised learning methods are under the in-distribution (ID) assumption, where the distribution of the training set is assumed to be identical to the test set. In reality, distribution shifts often occur between the training and test sets. While various self-supervised graph learning methods are superior to supervised methods on ID test sets, their performance on out-of-distribution (OOD) test sets compared to supervised methods is still under exploration. This naturally raises the question: Are graph self-supervised learning methods more robust than supervised methods?

Indeed, both generative and contrastive methods have made remarkable strides in the graph domain, surpassing supervised methods in certain scenarios even in the absence of human annotations~\cite{gmae,grace,rosa,mvgrl,zhu2023sgl,zhang2023structure}. However, most current graph self-supervised learning methods operate under the in-distribution (ID) assumption, where the training set's distribution is presumed to be identical to that of the test set. In reality, distribution shifts frequently occur between training and test sets. Although various self-supervised graph learning methods exhibit superior performance compared to supervised methods on ID test sets, their robustness and performance on out-of-distribution (OOD) test sets, in comparison to supervised methods, are still being explored. This naturally raises the question: Are graph self-supervised learning methods inherently more robust than supervised methods?

In this work, we will investigate the robustness of graph self-supervised methods in the face of distribution shifts. And we provide a model-agnostic recipe for improving the OOD generalization of graph contrastive learning methods \zy{which does not rely on the choice of models}. \haizhou{how is it model-agnostic specifically?} By addressing this research question, we provide valuable insights and practical guidelines for improving the performance of unsupervised graph contrastive learning in scenarios with distribution shifts.

\subsection{Out-of-Distribution Generalization on Graphs}
% Out-of-distribution generalization (aka domain generalization) algorithm is designed to achieve satisfactory generalization performance while facing unknown distribution shifts~\cite{ood-survey}. Due to the growing need for handling unseen data in real-world scenarios, this algorithm has gained significant attention within the research community. The combination of graph machine learning and OOD generalization (\ie, OOD generalization on graphs), holds great promise and serves as a valuable research direction for enhancing the deployment of graph machine learning models in real-world applications~\cite{good-survey}. 
\noindent Out-of-distribution generalization (aka domain generalization) algorithm, is specifically developed to achieve satisfactory generalization performance when confronted with unknown distribution shifts~\cite{ood-survey}. Due to the growing need for handling unseen data in real-world scenarios, this algorithm has garnered substantial attention within the research community. \zy{Specifically, robust optimization~\cite{groupdro,hu2018does}, invariant representation/predictor learning~\cite{irm,sparseirm} and causal approaches~\cite{peters2016causal,heinze2018causal} are proposed to deal with such problems.} \haizhou{What is the main idea of these DG algorithms? Briefly introduce it.} The combination of graph machine learning and OOD generalization (\ie, OOD generalization on graphs), presents a promising research direction. It holds the potential to enhance the deployment of graph machine learning models in real-world applications, making them more robust and adaptable to diverse and evolving data distributions~\cite{good-survey}. \zy{It is worth noting that there are related topics such as graph domain adaptation~\cite{wu2020unsupervised} and graph transfer learning~\cite{zhu2021transfer}. The key distinction lies in the fact that these approaches typically assume access to a subset of the test domains for adapting GNN models. In contrast, graph domain generalization does not rely on any samples from the test domains, making it distinct from these aforementioned approaches.}

Recently, some works explore the generalization of graph neural networks on graph OOD data~\cite{eerm,gil,dir,rgcl}, but most works mostly focus on graph-level tasks. It is more challenging to deal with node-level tasks due to the interconnection of the graph structure. EERM \cite{eerm} is the first work to deal with node-level graph OOD problems by generating multiple graphs from environment generators and minimizing the mean and variance of risks from multiple environments to capture invariant features. But this work needs to use label information to extract causal patterns. \haizhou{Only one work?} If labels are unavailable or limited, how to train a model with good generalization without supervision is essential but still under exploration. In the computer vision domain, \cite{shi2022robust} found contrastive learning methods are more robust compared to supervised methods. But it is unknown whether graph self-supervised learning methods are robust to distribution shifts. In this work, we will explore the robustness of graph self-supervised methods under distribution shifts.

In recent research, some studies have started exploring the generalization of graph neural networks on out-of-distribution (OOD) graph data~\cite{eerm,gil,dir,rgcl}. However, most of these works have primarily focused on graph-level tasks, while dealing with node-level tasks poses greater challenges due to the interconnected nature of graph structures.
EERM~\cite{eerm} is the first work to address node-level OOD problems in graphs by generating multiple graphs from environment generators and minimizing the mean and variance of risks across multiple environments to capture invariant features. However, this approach relies on label information to extract causal patterns. When labels are unavailable or limited, training a model with good generalization in the absence of supervision becomes crucial but remains an ongoing exploration.

In the computer vision domain, a recent study~\cite{shi2022robust} found that contrastive learning methods exhibit greater robustness compared to supervised methods. However, it remains unknown whether graph self-supervised learning methods possess similar robustness to distribution shifts. \zy{It is worth noting that distribution shifts in graph data tend to be more intricate, with data points (nodes) interconnected through the graph structure.}\haizhou{briefly discuss the difference between unsupervised graph OOD and why exploring them is important.} In this study, we aim to investigate the robustness of graph self-supervised methods under different distribution shifts, shedding light on their performance in challenging graph OOD scenarios.
% Self-supervised methods seem to be more robust because the pre-training task is task-irerel and it hope to extract generic knowledges, eg,  contrastive methods xxx. In computer vision domain,  \cite{shi2022robust} found contrastive learning methods are more robust compared to supervised methods. But in the graph domain, it is xxx.
% Recent endeavors (Scarselli et al., 2018; Garg et al., 2020; Verma & Zhang, 2019) derive generalization error bounds for GNNs, yet they focus on in- distribution generalization and put little emphasis on distribution shifts, which are the main focus of our work. Furthermore, some up-to-date works explore GNN’s extrapolation ability for OOD data, e.g. unseen features/structures (Xu et al., 2021) and varying graph sizes (Yehudai et al., 2021; Bevilacqua et al., 2021). However, they mostly concentrate on graph-level tasks rather than node-level ones (see detailed comparison below). Moreover, some recent works probe into extrapolating features’ embeddings (Wu et al., 2021a) or user representations (Wu et al., 2021b) for open-world learning in tabular data or real systems for recommendation and advertisement. These works consider distribution shifts stemming from augmented input space or unseen entities, and the proposed models leverage GNNs as an explicit model that extrapolates to compute representations for new entities based on existing ones. In contrast, our work studies (implicit) distribution shifts behind observed data, and the proposed approach resorts to an implicit mechanism through the lens of invariance principle.