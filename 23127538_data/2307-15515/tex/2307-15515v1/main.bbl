% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{absil_trust-region_2007}{article}{}
      \name{author}{3}{}{%
        {{hash=9a81fe9ad87cf630eb4a68e86949545d}{%
           family={Absil},
           familyi={A\bibinitperiod},
           given={P-A},
           giveni={P\bibinithyphendelim A\bibinitperiod}}}%
        {{hash=1f5eb0621cdc9081f4d85a9799410dd3}{%
           family={Baker},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima G},
           giveni={C\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=3016657c1b1eebbd4422da87f0fc6e3c}{%
           family={Gallivan},
           familyi={G\bibinitperiod},
           given={Kyle\bibnamedelima A},
           giveni={K\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{e1338c0eddff9b0502fab1391625b54b}
      \strng{fullhash}{e1338c0eddff9b0502fab1391625b54b}
      \strng{bibnamehash}{e1338c0eddff9b0502fab1391625b54b}
      \strng{authorbibnamehash}{e1338c0eddff9b0502fab1391625b54b}
      \strng{authornamehash}{e1338c0eddff9b0502fab1391625b54b}
      \strng{authorfullhash}{e1338c0eddff9b0502fab1391625b54b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Foundations of Computational Mathematics}
      \field{title}{Trust-region methods on Riemannian manifolds}
      \field{volume}{7}
      \field{year}{2007}
      \field{pages}{303\bibrangedash 330}
      \range{pages}{28}
    \endentry
    \entry{AbsMahSep2008}{book}{}
      \name{author}{3}{}{%
        {{hash=9a81fe9ad87cf630eb4a68e86949545d}{%
           family={Absil},
           familyi={A\bibinitperiod},
           given={P.-A.},
           giveni={P\bibinithyphendelim A\bibinitperiod}}}%
        {{hash=557ac8b0d5f2ea79ae1c98d25604636a}{%
           family={Mahony},
           familyi={M\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=be08672e3c8f3c7924a7959ed79d990b}{%
           family={Sepulchre},
           familyi={S\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Princeton, NJ}%
      }
      \list{publisher}{1}{%
        {Princeton University Press}%
      }
      \strng{namehash}{1f1256f65d32880733bbb23cd6f6b4ca}
      \strng{fullhash}{1f1256f65d32880733bbb23cd6f6b4ca}
      \strng{bibnamehash}{1f1256f65d32880733bbb23cd6f6b4ca}
      \strng{authorbibnamehash}{1f1256f65d32880733bbb23cd6f6b4ca}
      \strng{authornamehash}{1f1256f65d32880733bbb23cd6f6b4ca}
      \strng{authorfullhash}{1f1256f65d32880733bbb23cd6f6b4ca}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-0-691-13298-3}
      \field{title}{Optimization Algorithms on Matrix Manifolds}
      \field{year}{2008}
      \field{pages}{xvi+224}
      \range{pages}{-1}
      \keyw{optimization on manifolds,Riemannian optimization,retraction,vector transport}
    \endentry
    \entry{andrei2020nonlinear}{book}{}
      \true{moreauthor}
      \true{morelabelname}
      \name{author}{1}{}{%
        {{hash=d5963ca6c2f10431c88e6cf9fc2324e4}{%
           family={Andrei},
           familyi={A\bibinitperiod},
           given={Neculai},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{947ea3977ab4a3bdd23c4a13bd59d137}
      \strng{fullhash}{947ea3977ab4a3bdd23c4a13bd59d137}
      \strng{bibnamehash}{947ea3977ab4a3bdd23c4a13bd59d137}
      \strng{authorbibnamehash}{947ea3977ab4a3bdd23c4a13bd59d137}
      \strng{authornamehash}{947ea3977ab4a3bdd23c4a13bd59d137}
      \strng{authorfullhash}{947ea3977ab4a3bdd23c4a13bd59d137}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Nonlinear Conjugate Gradient Methods for Unconstrained Optimization}
      \field{year}{2020}
    \endentry
    \entry{bento_inexact_2013}{article}{}
      \name{author}{3}{}{%
        {{hash=bb209a0181a8e1f118d1682e2683f025}{%
           family={Bento},
           familyi={B\bibinitperiod},
           given={GC},
           giveni={G\bibinitperiod}}}%
        {{hash=0a4b2a9c23d4c113da6493f23b86a0f4}{%
           family={Cruz\bibnamedelima Neto},
           familyi={C\bibinitperiod\bibinitdelim N\bibinitperiod},
           given={João\bibnamedelima Xavier},
           giveni={J\bibinitperiod\bibinitdelim X\bibinitperiod},
           prefix={da},
           prefixi={d\bibinitperiod}}}%
        {{hash=9c2f11cfc0cedf1828284ae6830c7696}{%
           family={Santos},
           familyi={S\bibinitperiod},
           given={PSM},
           giveni={P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{6431e42b27d7237f1adf3fce5841ef24}
      \strng{fullhash}{6431e42b27d7237f1adf3fce5841ef24}
      \strng{bibnamehash}{6431e42b27d7237f1adf3fce5841ef24}
      \strng{authorbibnamehash}{6431e42b27d7237f1adf3fce5841ef24}
      \strng{authornamehash}{6431e42b27d7237f1adf3fce5841ef24}
      \strng{authorfullhash}{6431e42b27d7237f1adf3fce5841ef24}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Optimization Theory and Applications}
      \field{title}{An inexact steepest descent method for multicriteria optimization on Riemannian manifolds}
      \field{volume}{159}
      \field{year}{2013}
      \field{pages}{108\bibrangedash 124}
      \range{pages}{17}
    \endentry
    \entry{bento_subgradient_2013}{article}{}
      \name{author}{2}{}{%
        {{hash=bb209a0181a8e1f118d1682e2683f025}{%
           family={Bento},
           familyi={B\bibinitperiod},
           given={GC},
           giveni={G\bibinitperiod}}}%
        {{hash=07fe691e8dfd6a68798bb161c47122ad}{%
           family={Cruz\bibnamedelima Neto},
           familyi={C\bibinitperiod\bibinitdelim N\bibinitperiod},
           given={JX},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{ed7b9014ce572dd679440370242451e8}
      \strng{fullhash}{ed7b9014ce572dd679440370242451e8}
      \strng{bibnamehash}{ed7b9014ce572dd679440370242451e8}
      \strng{authorbibnamehash}{ed7b9014ce572dd679440370242451e8}
      \strng{authornamehash}{ed7b9014ce572dd679440370242451e8}
      \strng{authorfullhash}{ed7b9014ce572dd679440370242451e8}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Optimization Theory and Applications}
      \field{title}{A subgradient method for multiobjective optimization on Riemannian manifolds}
      \field{volume}{159}
      \field{year}{2013}
      \field{pages}{125\bibrangedash 137}
      \range{pages}{13}
    \endentry
    \entry{bento_unconstrained_2012}{article}{}
      \name{author}{3}{}{%
        {{hash=bb209a0181a8e1f118d1682e2683f025}{%
           family={Bento},
           familyi={B\bibinitperiod},
           given={GC},
           giveni={G\bibinitperiod}}}%
        {{hash=e4f0c6290feacf4a56e319ff33211de3}{%
           family={Ferreira},
           familyi={F\bibinitperiod},
           given={Orizon\bibnamedelima Pereira},
           giveni={O\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=da3b7754916e88d485b6c899167219a2}{%
           family={Oliveira},
           familyi={O\bibinitperiod},
           given={P\bibnamedelima Roberto},
           giveni={P\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{f28ff4f6299c3d44932bf254e6f22dda}
      \strng{fullhash}{f28ff4f6299c3d44932bf254e6f22dda}
      \strng{bibnamehash}{f28ff4f6299c3d44932bf254e6f22dda}
      \strng{authorbibnamehash}{f28ff4f6299c3d44932bf254e6f22dda}
      \strng{authornamehash}{f28ff4f6299c3d44932bf254e6f22dda}
      \strng{authorfullhash}{f28ff4f6299c3d44932bf254e6f22dda}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Optimization Theory and Applications}
      \field{title}{Unconstrained steepest descent method for multicriteria optimization on Riemannian manifolds}
      \field{volume}{154}
      \field{year}{2012}
      \field{pages}{88\bibrangedash 107}
      \range{pages}{20}
    \endentry
    \entry{bento_proximal_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=0c6efcf78ca06e9f56b0ff6761282fbe}{%
           family={Bento},
           familyi={B\bibinitperiod},
           given={Glaydston\bibnamedelimb de\bibnamedelima C.},
           giveni={G\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=a7b4ed42563203762ca2416cbc71550f}{%
           family={Ferreira},
           familyi={F\bibinitperiod},
           given={Orizon\bibnamedelima P.},
           giveni={O\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=436adc1416518295046a94b085f66d2d}{%
           family={Pereira},
           familyi={P\bibinitperiod},
           given={Yuri\bibnamedelimb R.\bibnamedelimi L.},
           giveni={Y\bibinitperiod\bibinitdelim R\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{5f4e8e3b5694242e2518c81a68bde905}
      \strng{fullhash}{5f4e8e3b5694242e2518c81a68bde905}
      \strng{bibnamehash}{5f4e8e3b5694242e2518c81a68bde905}
      \strng{authorbibnamehash}{5f4e8e3b5694242e2518c81a68bde905}
      \strng{authornamehash}{5f4e8e3b5694242e2518c81a68bde905}
      \strng{authorfullhash}{5f4e8e3b5694242e2518c81a68bde905}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, the proximal point method for vector optimization and its inexact version are extended from Euclidean space to the Riemannian context. Under suitable assumptions on the objective function, the well-definedness of the methods is established. In addition, the convergence of any generated sequence to a weak efficient point is obtained.}
      \field{day}{1}
      \field{issn}{0167-6377}
      \field{journaltitle}{Operations Research Letters}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Operations Research Letters}
      \field{title}{Proximal point method for vector optimization on Hadamard manifolds}
      \field{volume}{46}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{pages}{13\bibrangedash 18}
      \range{pages}{6}
      \verb{file}
      \verb ScienceDirect Snapshot:/Users/chenkm/Zotero/storage/27X4AV7X/S016763771730202X.html:text/html
      \endverb
      \keyw{Continuous optimization,Fejér convergence,Hadamard manifolds,Proximal method,Vector optimization}
    \endentry
    \entry{boumal2023intromanifolds}{book}{}
      \name{author}{1}{}{%
        {{hash=1ebc350bb93479783f979fe521a9494b}{%
           family={Boumal},
           familyi={B\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Cambridge University Press}%
      }
      \strng{namehash}{1ebc350bb93479783f979fe521a9494b}
      \strng{fullhash}{1ebc350bb93479783f979fe521a9494b}
      \strng{bibnamehash}{1ebc350bb93479783f979fe521a9494b}
      \strng{authorbibnamehash}{1ebc350bb93479783f979fe521a9494b}
      \strng{authornamehash}{1ebc350bb93479783f979fe521a9494b}
      \strng{authorfullhash}{1ebc350bb93479783f979fe521a9494b}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{An Introduction to Optimization on Smooth Manifolds}
      \field{year}{2023}
    \endentry
    \entry{chen_conditional_2023}{article}{}
      \name{author}{3}{}{%
        {{hash=b5d93370ab079242b92889d6fcc880cd}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Wang},
           giveni={W\bibinitperiod}}}%
        {{hash=e446ec25332ab8f4601984c8a08b6b7b}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xinmin},
           giveni={X\bibinitperiod}}}%
        {{hash=c74e4d2d0104262e2773367d599fc4cc}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{44402927381e3771db6596a7d0ff9725}
      \strng{fullhash}{44402927381e3771db6596a7d0ff9725}
      \strng{bibnamehash}{44402927381e3771db6596a7d0ff9725}
      \strng{authorbibnamehash}{44402927381e3771db6596a7d0ff9725}
      \strng{authornamehash}{44402927381e3771db6596a7d0ff9725}
      \strng{authorfullhash}{44402927381e3771db6596a7d0ff9725}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose a conditional gradient method for solving constrained vector optimization problems with respect to a partial order induced by a closed, convex and pointed cone with nonempty interior. When the partial order under consideration is the one induced by the non-negative orthant, we regain the method for multiobjective optimization recently proposed by Assunção et al. (Comput Optim Appl 78(3):741–768, 2021). In our method, the construction of the auxiliary subproblem is based on the well-known oriented distance function. Three different types of step size strategies (Armijo, adaptative and nonmonotone) are considered. Without convexity assumption related to the objective function, we obtain the stationarity of accumulation points of the sequences produced by the proposed method equipped with the Armijo or the nonmonotone step size rule. To obtain the convergence result of the method with the adaptative step size strategy, we introduce a useful cone convexity condition which allows us to circumvent the intricate question of the Lipschitz continuity of Jocabian for the objective function. This condition helps us to generalize the classical descent lemma to the vector optimization case. Under convexity assumption for the objective function, it is proved that all accumulation points of any generated sequences obtained by our method are weakly efficient solutions. Numerical experiments illustrating the practical behavior of the methods are presented.}
      \field{day}{27}
      \field{issn}{1573-2894}
      \field{journaltitle}{Computational Optimization and Applications}
      \field{langid}{english}
      \field{month}{4}
      \field{shortjournal}{Comput Optim Appl}
      \field{title}{Conditional gradient method for vector optimization}
      \field{year}{2023}
      \field{dateera}{ce}
    \endentry
    \entry{dai2000convergence}{article}{}
      \name{author}{6}{}{%
        {{hash=2989bd8fa3f2ef6ce8282ec529556dbc}{%
           family={Dai},
           familyi={D\bibinitperiod},
           given={Yuhong},
           giveni={Y\bibinitperiod}}}%
        {{hash=40fa4a9e96ff8b7bda17d1156f9afbbb}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiye},
           giveni={J\bibinitperiod}}}%
        {{hash=e2eac68d328ca0bba2d5a29705451abc}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Guanghui},
           giveni={G\bibinitperiod}}}%
        {{hash=858834ccfd0831130eca517ec4ff4889}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Defeng},
           giveni={D\bibinitperiod}}}%
        {{hash=755faba05de80c9543fd762b9779838c}{%
           family={Yin},
           familyi={Y\bibinitperiod},
           given={Hongxia},
           giveni={H\bibinitperiod}}}%
        {{hash=f579eac1a41797a48b84021d664076c3}{%
           family={Yuan},
           familyi={Y\bibinitperiod},
           given={Ya-xiang},
           giveni={Y\bibinithyphendelim x\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {SIAM}%
      }
      \strng{namehash}{76b7f4e32a227f635d3de3aac10c5dea}
      \strng{fullhash}{35eab1b6dfed921a5fd4e0994328dd8e}
      \strng{bibnamehash}{76b7f4e32a227f635d3de3aac10c5dea}
      \strng{authorbibnamehash}{76b7f4e32a227f635d3de3aac10c5dea}
      \strng{authornamehash}{76b7f4e32a227f635d3de3aac10c5dea}
      \strng{authorfullhash}{35eab1b6dfed921a5fd4e0994328dd8e}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{SIAM Journal on Optimization}
      \field{number}{2}
      \field{title}{Convergence properties of nonlinear conjugate gradient methods}
      \field{volume}{10}
      \field{year}{2000}
      \field{pages}{345\bibrangedash 358}
      \range{pages}{14}
    \endentry
    \entry{drummond_projected_2004}{article}{}
      \name{author}{2}{}{%
        {{hash=943222ef021934bfd9fab202c7791870}{%
           family={Drummond},
           familyi={D\bibinitperiod},
           given={L.M.\bibnamedelimi Graña},
           giveni={L\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=5a0ed8e5d5f208db6b3010ae3bce6fad}{%
           family={Iusem},
           familyi={I\bibinitperiod},
           given={A.N.},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{759361c72ddb41e6e72dfdc83a9d614d}
      \strng{fullhash}{759361c72ddb41e6e72dfdc83a9d614d}
      \strng{bibnamehash}{759361c72ddb41e6e72dfdc83a9d614d}
      \strng{authorbibnamehash}{759361c72ddb41e6e72dfdc83a9d614d}
      \strng{authornamehash}{759361c72ddb41e6e72dfdc83a9d614d}
      \strng{authorfullhash}{759361c72ddb41e6e72dfdc83a9d614d}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Vector optimization problems are a significant extension of multiobjective optimization, which has a large number of real life applications. In vector optimization the preference order is related to an arbitrary closed and convex cone, rather than the nonnegative orthant. We consider extensions of the projected gradient gradient method to vector optimization, which work directly with vector-valued functions, without using scalar-valued objectives. We provide a direction which adequately substitutes for the projected gradient, and establish results which mirror those available for the scalar-valued case, namely stationarity of the cluster points (if any) without convexity assumptions, and convergence of the full sequence generated by the algorithm to a weakly efficient optimum in the convex case, under mild assumptions. We also prove that our results still hold when the search direction is only approximately computed.}
      \field{day}{1}
      \field{issn}{1573-2894}
      \field{journaltitle}{Computational Optimization and Applications}
      \field{langid}{english}
      \field{month}{4}
      \field{number}{1}
      \field{shortjournal}{Computational Optimization and Applications}
      \field{title}{A Projected Gradient Method for Vector Optimization Problems}
      \field{volume}{28}
      \field{year}{2004}
      \field{dateera}{ce}
      \field{pages}{5\bibrangedash 29}
      \range{pages}{25}
    \endentry
    \entry{ferreira_unpublished}{misc}{}
      \name{author}{3}{}{%
        {{hash=eded8329a1aaaaa288ec7d7e656e8fd3}{%
           family={Ferreira},
           familyi={F\bibinitperiod},
           given={O.\bibnamedelimi P.},
           giveni={O\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=4e4136d085a99a96a28cb7982eadac84}{%
           family={Lucambio\bibnamedelima Pérez},
           familyi={L\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={L.\bibnamedelimi R.},
           giveni={L\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=d4db89be7311f80aea1c53ceb5cea2f2}{%
           family={Prudente},
           familyi={P\bibinitperiod},
           given={L.\bibnamedelimi F.},
           giveni={L\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{b5b805500e1ec660c3884eda1a43b171}
      \strng{fullhash}{b5b805500e1ec660c3884eda1a43b171}
      \strng{bibnamehash}{b5b805500e1ec660c3884eda1a43b171}
      \strng{authorbibnamehash}{b5b805500e1ec660c3884eda1a43b171}
      \strng{authornamehash}{b5b805500e1ec660c3884eda1a43b171}
      \strng{authorfullhash}{b5b805500e1ec660c3884eda1a43b171}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{howpublished}{Personal communication}
      \field{year}{2019}
      \field{dateera}{ce}
    \endentry
    \entry{flecher1964function}{article}{}
      \name{author}{2}{}{%
        {{hash=a1351326a064f954336c140a68f5e30f}{%
           family={Flecher},
           familyi={F\bibinitperiod},
           given={R},
           giveni={R\bibinitperiod}}}%
        {{hash=5a9049291589def066cc7a5bdfd4ab97}{%
           family={Reeves},
           familyi={R\bibinitperiod},
           given={CM},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{78269037936dcb42cd5f05fd6ffe96c3}
      \strng{fullhash}{78269037936dcb42cd5f05fd6ffe96c3}
      \strng{bibnamehash}{78269037936dcb42cd5f05fd6ffe96c3}
      \strng{authorbibnamehash}{78269037936dcb42cd5f05fd6ffe96c3}
      \strng{authornamehash}{78269037936dcb42cd5f05fd6ffe96c3}
      \strng{authorfullhash}{78269037936dcb42cd5f05fd6ffe96c3}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Computer Journal}
      \field{title}{Function minimization by conjugate gradient}
      \field{volume}{7}
      \field{year}{1964}
      \field{pages}{149\bibrangedash 154}
      \range{pages}{6}
    \endentry
    \entry{fletcher1980unconstrained}{article}{}
      \name{author}{1}{}{%
        {{hash=8abe2db93042a6dd925f3a2a2d32b43e}{%
           family={Fletcher},
           familyi={F\bibinitperiod},
           given={Roger},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {John Wiley}%
        {Sons, New York}%
      }
      \strng{namehash}{8abe2db93042a6dd925f3a2a2d32b43e}
      \strng{fullhash}{8abe2db93042a6dd925f3a2a2d32b43e}
      \strng{bibnamehash}{8abe2db93042a6dd925f3a2a2d32b43e}
      \strng{authorbibnamehash}{8abe2db93042a6dd925f3a2a2d32b43e}
      \strng{authornamehash}{8abe2db93042a6dd925f3a2a2d32b43e}
      \strng{authorfullhash}{8abe2db93042a6dd925f3a2a2d32b43e}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Practical Methods of Optimization}
      \field{title}{Unconstrained optimization}
      \field{volume}{1}
      \field{year}{1980}
    \endentry
    \entry{fukuda_inexact_2013}{article}{}
      \name{author}{2}{}{%
        {{hash=19b9fd4e6b1015aae5764de1468cee3c}{%
           family={Fukuda},
           familyi={F\bibinitperiod},
           given={Ellen\bibnamedelima H.},
           giveni={E\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=fe65a340df9900ace59b80afeed7e889}{%
           family={Graña\bibnamedelima Drummond},
           familyi={G\bibinitperiod\bibinitdelim D\bibinitperiod},
           given={L.\bibnamedelimi M.},
           giveni={L\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{1745f01e9888df0a5e7e6badf370f9fc}
      \strng{fullhash}{1745f01e9888df0a5e7e6badf370f9fc}
      \strng{bibnamehash}{1745f01e9888df0a5e7e6badf370f9fc}
      \strng{authorbibnamehash}{1745f01e9888df0a5e7e6badf370f9fc}
      \strng{authornamehash}{1745f01e9888df0a5e7e6badf370f9fc}
      \strng{authorfullhash}{1745f01e9888df0a5e7e6badf370f9fc}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we propose an inexact projected gradient-like method for solving smooth constrained vector optimization problems. In the unconstrained case, we retrieve the steepest descent method introduced by Graña Drummond and Svaiter. In the constrained setting, the method we present extends the exact one proposed by Graña Drummond and Iusem, since it admits relative errors on the search directions. At each iteration, a decrease of the objective value is obtained by means of an Armijo-like rule. The convergence results of this new method extend those obtained by Fukuda and Graña Drummond for the exact version. For partial orders induced by both pointed and nonpointed cones, under some reasonable hypotheses, global convergence to weakly efficient points of all sequences generated by the inexact projected gradient method is established for convex (respect to the ordering cone) objective functions. In the convergence analysis we also establish a connection between the so-called weighting method and the one we propose.}
      \field{day}{1}
      \field{journaltitle}{Computational Optimization and Applications}
      \field{langid}{english}
      \field{month}{4}
      \field{number}{3}
      \field{shortjournal}{Comput Optim Appl}
      \field{title}{Inexact projected gradient method for vector optimization}
      \field{volume}{54}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{pages}{473\bibrangedash 493}
      \range{pages}{21}
      \keyw{Multiobjective optimization,Projected gradient method,Vector optimization,Weak efficiency}
    \endentry
    \entry{gilbert_global_1992}{article}{}
      \name{author}{2}{}{%
        {{hash=9abcdf185c222de4d9b4809d52797314}{%
           family={Gilbert},
           familyi={G\bibinitperiod},
           given={Jean\bibnamedelima Charles},
           giveni={J\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=88a342d927bf795b0d92af8a5613da31}{%
           family={Nocedal},
           familyi={N\bibinitperiod},
           given={Jorge},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {SIAM}%
      }
      \strng{namehash}{817bc8439125ffbd86eddba213d5bce6}
      \strng{fullhash}{817bc8439125ffbd86eddba213d5bce6}
      \strng{bibnamehash}{817bc8439125ffbd86eddba213d5bce6}
      \strng{authorbibnamehash}{817bc8439125ffbd86eddba213d5bce6}
      \strng{authornamehash}{817bc8439125ffbd86eddba213d5bce6}
      \strng{authorfullhash}{817bc8439125ffbd86eddba213d5bce6}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{SIAM Journal on optimization}
      \field{number}{1}
      \field{title}{Global convergence properties of conjugate gradient methods for optimization}
      \field{volume}{2}
      \field{year}{1992}
      \field{pages}{21\bibrangedash 42}
      \range{pages}{22}
    \endentry
    \entry{goncalves_2020}{article}{}
      \name{author}{2}{}{%
        {{hash=67cbb60c5c1153ebe542a53193a2a837}{%
           family={Gonçalves},
           familyi={G\bibinitperiod},
           given={M.\bibnamedelimi L.\bibnamedelimi N.},
           giveni={M\bibinitperiod\bibinitdelim L\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=d4db89be7311f80aea1c53ceb5cea2f2}{%
           family={Prudente},
           familyi={P\bibinitperiod},
           given={L.\bibnamedelimi F.},
           giveni={L\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{a1da3d664974b5cbe83b5d6d0b089e94}
      \strng{fullhash}{a1da3d664974b5cbe83b5d6d0b089e94}
      \strng{bibnamehash}{a1da3d664974b5cbe83b5d6d0b089e94}
      \strng{authorbibnamehash}{a1da3d664974b5cbe83b5d6d0b089e94}
      \strng{authornamehash}{a1da3d664974b5cbe83b5d6d0b089e94}
      \strng{authorfullhash}{a1da3d664974b5cbe83b5d6d0b089e94}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Computational Optimization and Applications}
      \field{title}{On the extension of the Hager--Zhang conjugate gradient method for vector optimization}
      \field{volume}{76}
      \field{year}{2020}
      \field{pages}{889\bibrangedash 916}
      \range{pages}{28}
    \endentry
    \entry{goncalves_study_nodate}{article}{}
      \name{author}{3}{}{%
        {{hash=ea906b65c314a4dc8cb39cf7d95a028c}{%
           family={Gonçalves},
           familyi={G\bibinitperiod},
           given={Max\bibnamedelima LN},
           giveni={M\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=c431a32b0cb91c33bfe2f155ea468097}{%
           family={Lima},
           familyi={L\bibinitperiod},
           given={FS},
           giveni={F\bibinitperiod}}}%
        {{hash=d4db89be7311f80aea1c53ceb5cea2f2}{%
           family={Prudente},
           familyi={P\bibinitperiod},
           given={LF},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Elsevier}%
      }
      \strng{namehash}{2b99ef8a53fe427f68d65972304a00f8}
      \strng{fullhash}{2b99ef8a53fe427f68d65972304a00f8}
      \strng{bibnamehash}{2b99ef8a53fe427f68d65972304a00f8}
      \strng{authorbibnamehash}{2b99ef8a53fe427f68d65972304a00f8}
      \strng{authornamehash}{2b99ef8a53fe427f68d65972304a00f8}
      \strng{authorfullhash}{2b99ef8a53fe427f68d65972304a00f8}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Applied Mathematics and Computation}
      \field{title}{A study of Liu-Storey conjugate gradient methods for vector optimization}
      \field{volume}{425}
      \field{year}{2022}
      \field{pages}{127099}
      \range{pages}{1}
    \endentry
    \entry{grana_drummond_steepest_2005}{article}{}
      \name{author}{2}{}{%
        {{hash=fe65a340df9900ace59b80afeed7e889}{%
           family={Graña\bibnamedelima Drummond},
           familyi={G\bibinitperiod\bibinitdelim D\bibinitperiod},
           given={L.M.},
           giveni={L\bibinitperiod}}}%
        {{hash=bb2e024e2b15db3b142c6a89b7603dca}{%
           family={Svaiter},
           familyi={S\bibinitperiod},
           given={B.F.},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{5e1c7ad2758fa8a56458e0a8910ba113}
      \strng{fullhash}{5e1c7ad2758fa8a56458e0a8910ba113}
      \strng{bibnamehash}{5e1c7ad2758fa8a56458e0a8910ba113}
      \strng{authorbibnamehash}{5e1c7ad2758fa8a56458e0a8910ba113}
      \strng{authornamehash}{5e1c7ad2758fa8a56458e0a8910ba113}
      \strng{authorfullhash}{5e1c7ad2758fa8a56458e0a8910ba113}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Computational and Applied Mathematics}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{2}
      \field{shortjournal}{Journal of Computational and Applied Mathematics}
      \field{title}{A steepest descent method for vector optimization}
      \field{volume}{175}
      \field{year}{2005}
      \field{dateera}{ce}
      \field{pages}{395\bibrangedash 414}
      \range{pages}{20}
      \verb{file}
      \verb 全文:/Users/chenkm/Zotero/storage/5U8JICTP/Graña Drummond 和 Svaiter - 2005 - A steepest descent method for vector optimization.pdf:application/pdf
      \endverb
    \endentry
    \entry{VectorOptimization}{book}{}
      \name{author}{1}{}{%
        {{hash=714b27d206bf6f33cc5eec6e5f680e3f}{%
           family={Jahn},
           familyi={J\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{714b27d206bf6f33cc5eec6e5f680e3f}
      \strng{fullhash}{714b27d206bf6f33cc5eec6e5f680e3f}
      \strng{bibnamehash}{714b27d206bf6f33cc5eec6e5f680e3f}
      \strng{authorbibnamehash}{714b27d206bf6f33cc5eec6e5f680e3f}
      \strng{authornamehash}{714b27d206bf6f33cc5eec6e5f680e3f}
      \strng{authorfullhash}{714b27d206bf6f33cc5eec6e5f680e3f}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-3-540-20615-6}
      \field{journaltitle}{Vector Optimization: Theory, Applications, and Extensions}
      \field{month}{01}
      \field{title}{Vector Optimization: Theory, Applications, and Extensions}
      \field{year}{2004}
    \endentry
    \entry{liu1991efficient}{article}{}
      \name{author}{2}{}{%
        {{hash=ce084360cc68e7db4fe6cae1287b3adf}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Y},
           giveni={Y\bibinitperiod}}}%
        {{hash=d10d4e426cb6d3b982a795c9d56ee207}{%
           family={Storey},
           familyi={S\bibinitperiod},
           given={C},
           giveni={C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{47700b17a064f263c530b2138a656fc1}
      \strng{fullhash}{47700b17a064f263c530b2138a656fc1}
      \strng{bibnamehash}{47700b17a064f263c530b2138a656fc1}
      \strng{authorbibnamehash}{47700b17a064f263c530b2138a656fc1}
      \strng{authornamehash}{47700b17a064f263c530b2138a656fc1}
      \strng{authorfullhash}{47700b17a064f263c530b2138a656fc1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Optimization Theory and Applications}
      \field{title}{Efficient generalized conjugate gradient algorithms, part 1: theory}
      \field{volume}{69}
      \field{year}{1991}
      \field{pages}{129\bibrangedash 137}
      \range{pages}{9}
    \endentry
    \entry{lucambio_perez_nonlinear_2018}{article}{}
      \name{author}{2}{}{%
        {{hash=4e4136d085a99a96a28cb7982eadac84}{%
           family={Lucambio\bibnamedelima Pérez},
           familyi={L\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={LR},
           giveni={L\bibinitperiod}}}%
        {{hash=d4db89be7311f80aea1c53ceb5cea2f2}{%
           family={Prudente},
           familyi={P\bibinitperiod},
           given={LF},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {SIAM}%
      }
      \strng{namehash}{2a18f546fc02d78bc9700bacc6c3322c}
      \strng{fullhash}{2a18f546fc02d78bc9700bacc6c3322c}
      \strng{bibnamehash}{2a18f546fc02d78bc9700bacc6c3322c}
      \strng{authorbibnamehash}{2a18f546fc02d78bc9700bacc6c3322c}
      \strng{authornamehash}{2a18f546fc02d78bc9700bacc6c3322c}
      \strng{authorfullhash}{2a18f546fc02d78bc9700bacc6c3322c}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{SIAM Journal on Optimization}
      \field{number}{3}
      \field{title}{Nonlinear conjugate gradient methods for vector optimization}
      \field{volume}{28}
      \field{year}{2018}
      \field{pages}{2690\bibrangedash 2720}
      \range{pages}{31}
    \endentry
    \entry{najafi_multiobjective_2023}{article}{}
      \name{author}{2}{}{%
        {{hash=f5f0b5fd5edc2bf97722958b48d1011d}{%
           family={Najafi},
           familyi={N\bibinitperiod},
           given={Shahabeddin},
           giveni={S\bibinitperiod}}}%
        {{hash=9a86bbc6f4e66ba810810100fa4ce2b7}{%
           family={Hajarian},
           familyi={H\bibinitperiod},
           given={Masoud},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{c416203d76ca426d9ab6ec322fac3792}
      \strng{fullhash}{c416203d76ca426d9ab6ec322fac3792}
      \strng{bibnamehash}{c416203d76ca426d9ab6ec322fac3792}
      \strng{authorbibnamehash}{c416203d76ca426d9ab6ec322fac3792}
      \strng{authornamehash}{c416203d76ca426d9ab6ec322fac3792}
      \strng{authorfullhash}{c416203d76ca426d9ab6ec322fac3792}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we present the multiobjective optimization methods of conjugate gradient on Riemannian manifolds. The concepts of optimality and Wolfe conditions, as well as Zoutendijk’s theorem, are redefined in this setting. We show that under some standard assumptions, a sequence generated by these algorithms converges to a critical Pareto point. This is when the step sizes satisfy the multiobjective Wolfe conditions. In particular, we propose the Fletcher–Reeves, Dai–Yuan, Polak–Ribière–Polyak, and Hestenes–Stiefel parameters and further analyze the convergence behavior of the first two methods and test their performance against the steepest descent method.}
      \field{day}{1}
      \field{journaltitle}{Journal of Optimization Theory and Applications}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{3}
      \field{shortjournal}{J Optim Theory Appl}
      \field{title}{Multiobjective conjugate gradient methods on Riemannian manifolds}
      \field{volume}{197}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{pages}{1229\bibrangedash 1248}
      \range{pages}{20}
      \verb{file}
      \verb Full Text PDF:/Users/chenkm/Zotero/storage/8XM5CI3K/Najafi 和 Hajarian - 2023 - Multiobjective Conjugate Gradient Methods on Riema.pdf:application/pdf
      \endverb
      \keyw{Conjugate gradient methods,Multicriteria optimization,Multiobjective optimization,Pareto optimality,Riemannian manifolds,Wolfe conditions}
    \endentry
    \entry{polak1969note}{article}{}
      \name{author}{2}{}{%
        {{hash=5c7532c8b6560ff50c4b84e8818fc870}{%
           family={Polak},
           familyi={P\bibinitperiod},
           given={Elijah},
           giveni={E\bibinitperiod}}}%
        {{hash=7bb05eef5afd79a47a143c734e1394c2}{%
           family={Ribiere},
           familyi={R\bibinitperiod},
           given={Gerard},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {EDP Sciences}%
      }
      \strng{namehash}{5bf520bba9c65d35895d7802a9c4246d}
      \strng{fullhash}{5bf520bba9c65d35895d7802a9c4246d}
      \strng{bibnamehash}{5bf520bba9c65d35895d7802a9c4246d}
      \strng{authorbibnamehash}{5bf520bba9c65d35895d7802a9c4246d}
      \strng{authornamehash}{5bf520bba9c65d35895d7802a9c4246d}
      \strng{authorfullhash}{5bf520bba9c65d35895d7802a9c4246d}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Revue française d'informatique et de recherche opérationnelle. Série rouge}
      \field{number}{16}
      \field{title}{Note sur la convergence de méthodes de directions conjuguées}
      \field{volume}{3}
      \field{year}{1969}
      \field{pages}{35\bibrangedash 43}
      \range{pages}{9}
    \endentry
    \entry{powell1984nonconvex}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=a6f14ff4dd78380d35c952212ecbcc2c}{%
           family={Powell},
           familyi={P\bibinitperiod},
           given={Michael\bibnamedelima JD},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{organization}{1}{%
        {Springer}%
      }
      \strng{namehash}{a6f14ff4dd78380d35c952212ecbcc2c}
      \strng{fullhash}{a6f14ff4dd78380d35c952212ecbcc2c}
      \strng{bibnamehash}{a6f14ff4dd78380d35c952212ecbcc2c}
      \strng{authorbibnamehash}{a6f14ff4dd78380d35c952212ecbcc2c}
      \strng{authornamehash}{a6f14ff4dd78380d35c952212ecbcc2c}
      \strng{authorfullhash}{a6f14ff4dd78380d35c952212ecbcc2c}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Numerical Analysis: Proceedings of the 10th Biennial Conference held at Dundee, Scotland, June 28--July 1, 1983}
      \field{title}{Nonconvex minimization calculations and the conjugate gradient method}
      \field{year}{1984}
      \field{pages}{122\bibrangedash 141}
      \range{pages}{20}
    \endentry
    \entry{sakai2021sufficient}{article}{}
      \name{author}{2}{}{%
        {{hash=b562e1ff7e6311b3e193c4d7d6d69162}{%
           family={Sakai},
           familyi={S\bibinitperiod},
           given={Hiroyuki},
           giveni={H\bibinitperiod}}}%
        {{hash=68dd5912e651484f473607316bbd5cda}{%
           family={Iiduka},
           familyi={I\bibinitperiod},
           given={Hideaki},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{6e5f7f0d86f5f6d724200d94cb6341b8}
      \strng{fullhash}{6e5f7f0d86f5f6d724200d94cb6341b8}
      \strng{bibnamehash}{6e5f7f0d86f5f6d724200d94cb6341b8}
      \strng{authorbibnamehash}{6e5f7f0d86f5f6d724200d94cb6341b8}
      \strng{authornamehash}{6e5f7f0d86f5f6d724200d94cb6341b8}
      \strng{authorfullhash}{6e5f7f0d86f5f6d724200d94cb6341b8}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Optimization Theory and Applications}
      \field{number}{1}
      \field{title}{Sufficient descent Riemannian conjugate gradient methods}
      \field{volume}{190}
      \field{year}{2021}
      \field{pages}{130\bibrangedash 150}
      \range{pages}{21}
    \endentry
    \entry{sato_riemannian_2021_article}{article}{}
      \name{author}{1}{}{%
        {{hash=78411721bc9363135b14df8a1621314e}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Hiroyuki},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {SIAM}%
      }
      \strng{namehash}{78411721bc9363135b14df8a1621314e}
      \strng{fullhash}{78411721bc9363135b14df8a1621314e}
      \strng{bibnamehash}{78411721bc9363135b14df8a1621314e}
      \strng{authorbibnamehash}{78411721bc9363135b14df8a1621314e}
      \strng{authornamehash}{78411721bc9363135b14df8a1621314e}
      \strng{authorfullhash}{78411721bc9363135b14df8a1621314e}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{SIAM Journal on Optimization}
      \field{number}{4}
      \field{title}{Riemannian conjugate gradient methods: General framework and specific algorithms with convergence analyses}
      \field{volume}{32}
      \field{year}{2022}
      \field{pages}{2690\bibrangedash 2717}
      \range{pages}{28}
    \endentry
    \entry{sato_riemannian_2021}{book}{}
      \name{author}{1}{}{%
        {{hash=78411721bc9363135b14df8a1621314e}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Hiroyuki},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham, Switzerland}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{78411721bc9363135b14df8a1621314e}
      \strng{fullhash}{78411721bc9363135b14df8a1621314e}
      \strng{bibnamehash}{78411721bc9363135b14df8a1621314e}
      \strng{authorbibnamehash}{78411721bc9363135b14df8a1621314e}
      \strng{authornamehash}{78411721bc9363135b14df8a1621314e}
      \strng{authorfullhash}{78411721bc9363135b14df8a1621314e}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This brief describes the basics of Riemannian optimization--optimization on Riemannian manifolds--introduces algorithms for Riemannian optimization problems, discusses the theoretical properties of these algorithms, and suggests possible applications of Riemannian optimization to problems in other fields. To provide the reader with a smooth introduction to Riemannian optimization, brief reviews of mathematical optimization in Euclidean spaces and Riemannian geometry are included. Riemannian optimization is then introduced by merging these concepts. In particular, the Euclidean and Riemannian conjugate gradient methods are discussed in detail. A brief review of recent developments in Riemannian optimization is also provided. Riemannian optimization methods are applicable to many problems in various fields. This brief discusses some important applications including the eigenvalue and singular value decompositions in numerical linear algebra, optimal model reduction in control engineering, and canonical correlation analysis in statistics}
      \field{isbn}{978-3-030-62391-3}
      \field{note}{{OCLC}: 1237966923}
      \field{title}{Riemannian Optimization and Its Applications}
      \field{year}{2021}
      \field{dateera}{ce}
      \keyw{Riemannian}
    \endentry
    \entry{stiefel1952methods}{article}{}
      \name{author}{1}{}{%
        {{hash=21b4a8741247ba566d702dfa0c9fef9b}{%
           family={Stiefel},
           familyi={S\bibinitperiod},
           given={Eduard},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{21b4a8741247ba566d702dfa0c9fef9b}
      \strng{fullhash}{21b4a8741247ba566d702dfa0c9fef9b}
      \strng{bibnamehash}{21b4a8741247ba566d702dfa0c9fef9b}
      \strng{authorbibnamehash}{21b4a8741247ba566d702dfa0c9fef9b}
      \strng{authornamehash}{21b4a8741247ba566d702dfa0c9fef9b}
      \strng{authorfullhash}{21b4a8741247ba566d702dfa0c9fef9b}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{J. Res. Nat. Bur. Standards}
      \field{title}{Methods of conjugate gradients for solving linear systems}
      \field{volume}{49}
      \field{year}{1952}
      \field{pages}{409\bibrangedash 435}
      \range{pages}{27}
    \endentry
    \entry{tanabe_proximal_2019}{article}{}
      \name{author}{3}{}{%
        {{hash=fe79ff046b379ee499d9981349434f9c}{%
           family={Tanabe},
           familyi={T\bibinitperiod},
           given={Hiroki},
           giveni={H\bibinitperiod}}}%
        {{hash=19b9fd4e6b1015aae5764de1468cee3c}{%
           family={Fukuda},
           familyi={F\bibinitperiod},
           given={Ellen\bibnamedelima H.},
           giveni={E\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=e93d47fe50ff15742fad700a20e29a10}{%
           family={Yamashita},
           familyi={Y\bibinitperiod},
           given={Nobuo},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{5644796ecaff4773be29cc8f97209501}
      \strng{fullhash}{5644796ecaff4773be29cc8f97209501}
      \strng{bibnamehash}{5644796ecaff4773be29cc8f97209501}
      \strng{authorbibnamehash}{5644796ecaff4773be29cc8f97209501}
      \strng{authornamehash}{5644796ecaff4773be29cc8f97209501}
      \strng{authorfullhash}{5644796ecaff4773be29cc8f97209501}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose new descent methods for unconstrained multiobjective optimization problems, where each objective function can be written as the sum of a continuously differentiable function and a proper convex but not necessarily differentiable one. The methods extend the well-known proximal gradient algorithms for scalar-valued nonlinear optimization, which are shown to be efﬁcient for particular problems. Here, we consider two types of algorithms: with and without line searches. Under mild assumptions, we prove that each accumulation point of the sequence generated by these algorithms, if exists, is Pareto stationary. Moreover, we present their applications in constrained multiobjective optimization and robust multiobjective optimization, which is a problem that considers uncertainties. In particular, for the robust case, we show that the subproblems of the proximal gradient algorithms can be seen as quadratic programming, second-order cone programming, or semideﬁnite programming problems. Considering these cases, we also carry out some numerical experiments, showing the validity of the proposed methods.}
      \field{journaltitle}{Computational Optimization and Applications}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{2}
      \field{shortjournal}{Comput Optim Appl}
      \field{title}{Proximal gradient methods for multiobjective optimization and their applications}
      \field{volume}{72}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{pages}{339\bibrangedash 361}
      \range{pages}{23}
    \endentry
    \entry{zhu2017riemannian}{article}{}
      \name{author}{1}{}{%
        {{hash=d5a0f47c5ef5a9c8ad8eb658d990ff02}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Xiaojing},
           giveni={X\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{d5a0f47c5ef5a9c8ad8eb658d990ff02}
      \strng{fullhash}{d5a0f47c5ef5a9c8ad8eb658d990ff02}
      \strng{bibnamehash}{d5a0f47c5ef5a9c8ad8eb658d990ff02}
      \strng{authorbibnamehash}{d5a0f47c5ef5a9c8ad8eb658d990ff02}
      \strng{authornamehash}{d5a0f47c5ef5a9c8ad8eb658d990ff02}
      \strng{authorfullhash}{d5a0f47c5ef5a9c8ad8eb658d990ff02}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Computational Optimization and Applications}
      \field{title}{A Riemannian conjugate gradient method for optimization on the Stiefel manifold}
      \field{volume}{67}
      \field{year}{2017}
      \field{pages}{73\bibrangedash 110}
      \range{pages}{38}
    \endentry
  \enddatalist
\endrefsection
\endinput

