\input{figures/planerectr++_overview}
\section{PlaneRecTR++ Overview}
\label{sec:overview}
Our PlaneRecTR++ is an end-to-end unified query learning architecture, designed for the challenging task of joint planar reconstruction and relative camera pose estimation. In Figure \ref{fig:planerectr++_overview}, the only input to PlaneRecTR++ are two RGB images $I_1$ and $I_2$ of different views, with their learnable queries serving as the bridge jointly connecting distinct sub-tasks. Specifically, plane queries guide the learning of unified plane embeddings $\mathcal{E}_\text{plane}$ for each possible plane candidate within input frames, whose mutual interactions enable their decoding to final planar attributes, cross-view plane correspondences, and relative camera pose. Please note that the above results are obtained by PlaneRecTR++ in one shot without \jiajia{external pose prior or correspondences supervision} \cite{jin2021sparseplanes, agarwala2022planeformers, tan2023nopesac}. 

To better dissect our method, we partition PlaneRecTR++ into two components based on the learning scope: intra-frame and inter-frame plane query learning. The intra-frame component aims to recover per-view 3D planes. It unifies various sub-tasks of monocular plane recovery including plane detection, parameter prediction, segmentation and depth estimation, while eliminating the need for multi-step prediction in previous methods \cite{jin2021sparseplanes,agarwala2022planeformers,tan2023nopesac}. Such design philosophy brings not only simplicity and compactness of overall framework but also mutual benefits among closely related tasks. Furthermore, in the inter-frame component, we integrate these learned unified plane embeddings from different views to form an attentive planar association matrix to approximate plane correspondences and capture \jiajia{features} of paired planes for directly pose regression. This design implicitly motivates multi-view consistency of plane embeddings and is proven to be sufficient for precise plane tracking, without any direct supervision. 
As a result, PlaneRecTR++ manages to unify separate multi-stage tasks required in the previous sparse views pipelines \cite{jin2021sparseplanes,agarwala2022planeformers,tan2023nopesac}, including monocular plane recovery, pose initialization, plane matching, and pose refinement. This joint optimization of all sub-tasks naturally enhances efficiency and final performance.


The training process of PlaneRecTR++ also comprises two phases: \jiajia{(1) A} monocular pre-training phase, where monocular images are utilized to train the intra-frame component for single-view plane recovery; \jiajia{(2) A} joint training phase, where paired images are used to train the complete PlaneRecTR++, optimizing both components in an end-to-end manner for planar reconstruction and pose estimation on challenging sparse-view datasets. Please note that our method could also be trained and converged well from scratch, \ie, only applying phase (2), however, we \jiajia{find} the two-phase training achieves better overall performance without losing its virtue in end-to-end unified query learning. Therefore we stick to the two-phase training unless otherwise mentioned.

In the subsequent Section \ref{sec:intra_frame_method} and \ref{sec:inter_frame_method}, we elaborate on architectural designs, training objectives and inference process of intra-frame and inter-frame components, respectively.


