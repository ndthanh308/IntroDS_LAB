\section{Conclusion}

We have presented PlaneRecTR++, a unified query learning framework, to learn robust 3D plane recovery and relative camera pose estimations. Through encoding planar attributes among unified latent embeddings, our method captures the correlations of diverse sub-tasks of 3D plane reconstruction using a single and compact Transformer architecture, and achieves state-of-the-art performance on four public benchmark datasets. Thanks to the tight interconnection of all sub-tasks, different from all existing multi-stage paradigms, our method realizes mutual benefits of coupled predictions in a single-shot prediction, and is able to automatically discover across-view plane correspondences, even without requiring any external initialization and correspondence supervisions. Furthermore, we have conducted extensive ablative experiments to demonstrate the efficacy of PlaneRecTR++.

\paraspace
\ptitle{Limitations and Future work.}
It still remains unexplored how to extend PlaneRecTR++ to efficiently process \jiajia{more} sequential images for a larger scale of \jiajia{planar} recontruction in an online fashion. An exciting future venue would be to leverage the learned correspondences for long-term plane-level tracking, possibly drawing recent advancements in Transformer-based video panoptic segmentation.

