\input{figures/planerectr++_overview}
\section{PlaneRecTR++ Overview}
\label{sec:overview}
Our PlaneRecTR++ is an end-to-end unified query learning architecture, designed for the challenging task of joint planar reconstruction and relative camera pose estimation. In Figure \ref{fig:planerectr++_overview}, the only input to PlaneRecTR++ are two RGB images $I_1$ and $I_2$ of different views, with their learnable queries serving as the bridge jointly connecting distinct sub-tasks. Specifically, plane queries guide the learning of unified plane embeddings $\mathcal{E}_\text{plane}$ for each possible plane candidate within input frames, whose mutual interactions enable their decoding to final planar attributes, cross-view plane correspondences, and relative camera pose. Please note that the above results are obtained by PlaneRecTR++ in one shot without any external priors like initial poses or planes \cite{jin2021sparseplanes, agarwala2022planeformers, tan2023nopesac}. 

To better dissect our method, we partition PlaneRecTR++ into two components based on the learning scope: intra-frame and inter-frame plane query learning. The intra-frame plane query learning component aims to recover per-view 3D planes. It unifies various sub-tasks of monocular plane recovery including plane detection, parameter prediction, segmentation and depth estimation, while eliminating the need for multi-step prediction in previous methods \cite{jin2021sparseplanes,agarwala2022planeformers,tan2023nopesac}. Such design philosophy brings not only simplicity and compactness of overall framework but also mutual benefits among closely related tasks. Furthermore, in the inter-frame plane query learning component, we integrate these learned unified plane embeddings from different views to form an attentive planar association matrix to approximate plane correspondences and capture fetures of paired planes for directly pose regression. This design choice implicitly motivates multi-view consistency of planar embeddings and is proven to be sufficient for precise plane instance tracking, without any direct supervision. 
%Based on acquired paired planes, we apply a direct inference of camera pose using a simple MLP. 
As a result, PlaneRecTR++ manages to unify separate multi-stage tasks required in the previous sparse views pipelines \cite{jin2021sparseplanes,agarwala2022planeformers,tan2023nopesac}, including monocular plane recovery, pose initialization, plane matching, and pose refinement. This joint optimization of all sub-tasks naturally enhances efficiency and final performance.


%Corresponding to above two key componenets, 
The training process of PlaneRecTR++ also comprises two phases: 1) a monocular pre-training phase, where monocular RGB images are utilized to train the intra-frame component for single-view plane recovery;  2) a joint training phase, where paired RGB images are used to train the complete pipeline of PlaneRecTR++, optimizing both components in an end-to-end manner for planar reconstruction and camera pose estimation on challenging sparse-view datasets. Please note that our framework could also be trained and converged well from scratch (\ie, only applying the joint training phase), however, we found the two-phase training achieves better overall performance without losing its virtue in end-to-end unified query learning. Therefore during experiments we stick to the two-phase training unless otherwise mentioned.

In the subsequent Section \ref{sec:intra_frame_method} and \ref{sec:inter_frame_method}, we elaborate on architectural designs, training objectives and inference process of intra-frame and inter-frame components, respectively.


