@book{IrFundamentals,
author = {Vollmer, Michael and Mllmann, Klaus-Peter},
title = {Infrared Thermal Imaging: Fundamentals, Research and Applications},
year = {2018},
isbn = {3527413510},
publisher = {Wiley-VCH},
edition = {2nd},
abstract = {This new up-to-date edition of the successful handbook and ready reference retains the proven concept of the first, covering basic and advanced methods and applications in infrared imaging from two leading expert authors in the field. All chapters have been completely revised and expanded and a new chapter has been added to reflect recent developments in the field and report on the progress made within the last decade. In addition there is now an even stronger focus on real-life examples, with 20\% more case studies taken from science and industry. For ease of comprehension the text is backed by more than 590 images which include graphic visualizations and more than 300 infrared thermography figures. The latter include many new ones depicting, for example, spectacular views of phenomena in nature, sports, and daily life.}
}

@book{emissivity,
series = {SPIE tutorial texts ; TT48},
abstract = {The practical, popular 1995 tutorial has been thoroughly revised and updated, reflecting developments in technology and applications during the past decade. New chapters address wave aberrations, thermal effects, design examples, and diamond turning.},
publisher = {SPIE Press},
isbn = {0-8194-8069-X},
year = {2001},
title = {Optical design fundamentals for infrared systems},
edition = {2nd ed..},
language = {eng},
address = {Bellingham, Wash.},
author={Max J. Riedl},
keywords = {Optical instruments -- Design and construction; Infrared equipment -- Design and construction; Electronic books},
}

@INPROCEEDINGS{resnet,  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Deep Residual Learning for Image Recognition},   year={2016},  volume={},  number={},  pages={770-778},  doi={10.1109/CVPR.2016.90}}

@INPROCEEDINGS{inception,  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Rethinking the Inception Architecture for Computer Vision},   year={2016},  volume={},  number={},  pages={2818-2826},  doi={10.1109/CVPR.2016.308}}

@InProceedings{unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}


@book{uncooled_thermal_imaging,
   author = {Paul W. Kruse},
   isbn = {0-8194-8048-7},
   publisher = {SPIE},
   title = {Uncooled thermal imaging arrays, systems, and applications},
   year = {2001},
}


@article{ir_1f_gaussian,
  title = {Linearity of $\frac{1}{f}$ Noise Mechanisms},
  author = {Voss, Richard F.},
  journal = {Phys. Rev. Lett.},
  volume = {40},
  issue = {14},
  pages = {913--916},
  numpages = {0},
  year = {1978},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.40.913},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.40.913}
}

@book{HartleyRichard2004MVGi,
abstract = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
publisher = {Cambridge University Press},
isbn = {9780521540513},
year = {2004},
title = {Multiple View Geometry in Computer Vision},
copyright = {Cambridge University Press 2000, 2003},
language = {eng},
address = {Cambridge},
author = {Hartley, Richard and Zisserman, Andrew},
keywords = {Computer vision ; Geometry Projective},
}


@book{computationalGeometry,
author = {Berg, Mark de and Cheong, Otfried and Kreveld, Marc van and Overmars, Mark},
title = {Computational Geometry: Algorithms and Applications},
year = {2008},
isbn = {3540779736},
publisher = {Springer-Verlag TELOS},
address = {Santa Clara, CA, USA},
edition = {3rd ed.},
abstract = {This well-accepted introduction to computational geometry is a textbook for high-level undergraduate and low-level graduate courses. The focus is on algorithms and hence the book is well suited for students in computer science and engineering. Motivation is provided from the application areas: all solutions and techniques from computational geometry are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems. For students this motivation will be especially welcome. Modern insights in computational geometry are used to provide solutions that are both efficient and easy to understand and implement. All the basic techniques and topics from computational geometry, as well as several more advanced topics, are covered. The book is largely self-contained and can be used for self-study by anyone with a basic background in algorithms. In this third edition, besides revisions to the second edition, new sections discussing Voronoi diagrams of line segments, farthest-point Voronoi diagrams, and realistic input models have been added.}
}

@article{sift,
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  acmid = {996342},
  added-at = {2012-11-08T15:54:11.000+0100},
  address = {Hingham, MA, USA},
  author = {Lowe, David G.},
  biburl = {https://www.bibsonomy.org/bibtex/2c9984d3a783a48553018a518847f6657/daill},
  description = {Distinctive Image Features from Scale-Invariant Keypoints},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  interhash = {a1c2b94c96ee2ef15ef53e73b7fd9a8d},
  intrahash = {c9984d3a783a48553018a518847f6657},
  issn = {0920-5691},
  issue_date = {November 2004},
  journal = {Int. J. Comput. Vision},
  keywords = {feature sift},
  month = nov,
  number = 2,
  numpages = {20},
  pages = {91--110},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2012-11-08T15:54:11.000+0100},
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  url = {http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94},
  volume = 60,
  year = 2004
}

@INPROCEEDINGS{orb,  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},  booktitle={2011 International Conference on Computer Vision},   title={ORB: An efficient alternative to SIFT or SURF},   year={2011},  volume={},  number={},  pages={2564-2571},  doi={10.1109/ICCV.2011.6126544}}

@article{surf,
title = {Speeded-Up Robust Features (SURF)},
journal = {Computer Vision and Image Understanding},
volume = {110},
number = {3},
pages = {346-359},
year = {2008},
note = {Similarity Matching in Computer Vision and Multimedia},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2007.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1077314207001555},
author = {Herbert Bay and Andreas Ess and Tinne Tuytelaars and Luc {Van Gool}},
keywords = {Interest points, Local features, Feature description, Camera calibration, Object recognition},
abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision.}
}

@article{lift,
   abstract = {We introduce a novel Deep Network architecture that implements the full feature point handling pipeline, that is, detection, orientation estimation, and feature description. While previous works have successfully tackled each one of these problems individually, we show how to learn to do all three in a unified manner while preserving end-toend differentiability. We then demonstrate that our Deep pipeline outperforms state-of-the-art methods on a number of benchmark datasets, without the need of retraining.},
   author = {Kwang Moo Yi and Eduard Trulls and Vincent Lepetit and Pascal Fua},
   doi = {10.1007/978-3-319-46466-4_28},
   isbn = {9783319464657},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Deep learning,Feature descriptors,Local features},
   pages = {467-483},
   title = {LIFT: Learned invariant feature transform},
   volume = {9910 LNCS},
   year = {2016},
}

@INPROCEEDINGS{superpoints,  author={DeTone, Daniel and Malisiewicz, Tomasz and Rabinovich, Andrew},  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},   title={SuperPoint: Self-Supervised Interest Point Detection and Description},   year={2018},  volume={},  number={},  pages={337-33712},  doi={10.1109/CVPRW.2018.00060}}

@misc{Detone16,
  doi = {10.48550/ARXIV.1606.03798},
  url = {https://arxiv.org/abs/1606.03798},
  author={DeTone, Daniel and Malisiewicz, Tomasz and Rabinovich, Andrew},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Image Homography Estimation},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@ARTICLE{multi_sr_classic,  author={Farsiu, S. and Robinson, M.D. and Elad, M. and Milanfar, P.},  journal={IEEE Transactions on Image Processing},   title={Fast and robust multiframe super resolution},   year={2004},  volume={13},  number={10},  pages={1327-1344},  doi={10.1109/TIP.2004.834669}}

@ARTICLE{multi_denoise_classic,  author={Zhang, Ming and Gunturk, Bahadir K.},  journal={IEEE Transactions on Image Processing},   title={Multiresolution Bilateral Filtering for Image Denoising},   year={2008},  volume={17},  number={12},  pages={2324-2333},  doi={10.1109/TIP.2008.2006658}}

@article{multi_deblur_classic,
   abstract = {Photographs taken in low-light conditions are often blurry as a result of camera shake, i.e. a motion of the camera while its shutter is open. Most existing deblurring methods model the observed blurry image as the convolution of a sharp image with a uniform blur kernel. However, we show that blur from camera shake is in general mostly due to the 3D rotation of the camera, resulting in a blur that can be significantly non-uniform across the image. We propose a new parametrized geometric model of the blurring process in terms of the rotational motion of the camera during exposure. This model is able to capture non-uniform blur in an image due to camera shake using a single global descriptor, and can be substituted into existing deblurring algorithms with only small modifications. To demonstrate its effectiveness, we apply this model to two deblurring problems; first, the case where a single blurry image is available, for which we examine both an approximate marginalization approach and a maximum a posteriori approach, and second, the case where a sharp but noisy image of the scene is available in addition to the blurry image. We show that our approach makes it possible to model and remove a wider class of blurs than previous approaches, including uniform blur as a special case, and demonstrate its effectiveness with experiments on synthetic and real images.},
   author = {Oliver Whyte and Josef Sivic and Andrew Zisserman and Jean Ponce},
   city = {Boston},
   doi = {10.1007/s11263-011-0502-7},
   issn = {0920-5691},
   issue = {2},
   journal = {International Journal of Computer Vision},
   month = {6},
   pages = {168-186},
   publisher = {Springer US},
   title = {Non-uniform Deblurring for Shaken Images},
   volume = {98},
   year = {2012},
}

@inproceedings{multi_denoise_dl,
author = {Godard, Cl\'{e}ment and Matzen, Kevin and Uyttendaele, Matt},
title = {Deep Burst Denoising},
year = {2018},
isbn = {978-3-030-01266-3},
doi = {10.1007/978-3-030-01267-0_33},
abstract = {Noise is an inherent issue of low-light image capture, which is worsened on mobile devices due to their narrow apertures and small sensors. One strategy for mitigating noise in low-light situations is to increase the shutter time, allowing each photosite to integrate more light and decrease noise variance. However, there are two downsides of long exposures: (a) bright regions can exceed the sensor range, and (b) camera and scene motion will cause blur. Another way of gathering more light is to capture multiple short (thus noisy) frames in a burst and intelligently integrate the content, thus avoiding the above downsides. In this paper, we use the burst-capture strategy and implement the intelligent integration via a recurrent fully convolutional deep neural net (CNN). We build our novel, multi-frame architecture to be a simple addition to any single frame denoising model. The resulting architecture denoises all frames in a sequence of arbitrary length. We show that it achieves state of the art denoising results on our burst dataset, improving on the best published multi-frame techniques, such as VBM4D and FlexISP. Finally, we explore other applications of multi-frame image enhancement and show that our CNN architecture generalizes well to image super-resolution.},
booktitle = {15th European Conference of Computer Vision ECCV},
}


@INPROCEEDINGS {multi_sr_dl1,
author = {G. Bhat and M. Danelljan and L. Van Gool and R. Timofte},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Deep Burst Super-Resolution},
year = {2021},
volume = {},
issn = {},
pages = {9205-9214},
abstract = {While single-image super-resolution (SISR) has attracted substantial interest in recent years, the proposed approaches are limited to learning image priors in order to add high frequency details. In contrast, multi-frame super-resolution (MFSR) offers the possibility of reconstructing rich details by combining signal information from multiple shifted images. This key advantage, along with the increasing popularity of burst photography, have made MFSR an important problem for real-world applications.We propose a novel architecture for the burst super-resolution task. Our network takes multiple noisy RAW images as input, and generates a denoised, super-resolved RGB image as output. This is achieved by explicitly aligning deep embeddings of the input frames using pixel-wise optical flow. The information from all frames are then adaptively merged using an attention-based fusion module. In order to enable training and evaluation on real-world data, we additionally introduce the BurstSR dataset, consisting of smartphone bursts and high-resolution DSLR ground-truth. We perform comprehensive experimental analysis, demonstrating the effectiveness of the proposed architecture.},
keywords = {training;photography;superresolution;computer architecture;pattern recognition;noise measurement;task analysis},
doi = {10.1109/CVPR46437.2021.00909},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR46437.2021.00909},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@article{multi_sr_dl2,
author = {Wronski, Bartlomiej and Garcia-Dorado, Ignacio and Ernst, Manfred and Kelly, Damien and Krainin, Michael and Liang, Chia-Kai and Levoy, Marc and Milanfar, Peyman},
title = {Handheld Multi-Frame Super-Resolution},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3306346.3323024},
doi = {10.1145/3306346.3323024},
abstract = {Compared to DSLR cameras, smartphone cameras have smaller sensors, which limits their spatial resolution; smaller apertures, which limits their light gathering ability; and smaller pixels, which reduces their signal-to-noise ratio. The use of color filter arrays (CFAs) requires demosaicing, which further degrades resolution. In this paper, we supplant the use of traditional demosaicing in single-frame and burst photography pipelines with a multiframe super-resolution algorithm that creates a complete RGB image directly from a burst of CFA raw images. We harness natural hand tremor, typical in handheld photography, to acquire a burst of raw frames with small offsets. These frames are then aligned and merged to form a single image with red, green, and blue values at every pixel site. This approach, which includes no explicit demosaicing step, serves to both increase image resolution and boost signal to noise ratio. Our algorithm is robust to challenging scene conditions: local motion, occlusion, or scene changes. It runs at 100 milliseconds per 12-megapixel RAW input burst frame on mass-produced mobile phones. Specifically, the algorithm is the basis of the Super-Res Zoom feature, as well as the default merge method in Night Sight mode (whether zooming or not) on Google's flagship phone.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {28},
numpages = {18},
keywords = {image processing, photography, super-resolution, computational photography}
}

@INPROCEEDINGS{multi_sr_classic2,  author={Kim, S.P. and Su, W.-Y.},  booktitle={[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing},   title={Recursive high-resolution reconstruction of blurred multiframe images},   year={1991},  volume={},  number={},  pages={2977-2980 vol.4},  doi={10.1109/ICASSP.1991.151028}}

@article{multi_sr_dl3,
  title={HighRes-net: Recursive Fusion for Multi-Frame Super-Resolution of Satellite Imagery},
  author={Michel Deudon and Alfredo Kalaitzis and Israel Goytom and Md Rifat Arefin and Zhichao Lin and Kris Sankaran and Vincent Michalski and Samira Ebrahimi Kahou and Julien Cornebise and Yoshua Bengio},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.06460}
}

@article{Schulz1995,
   abstract = {Correction of photoresponse nonuniformity in infrared staring sensor arrays is investigated. A general nonuniformity correction procedure is proposed. The procedure is based on multiple irradiation sources and on least square fit approximations to the individual pixel response characteristics. Nonlinearities of the signal response are taken into account. A correctability figure of merit is defined which may be used to estimate the residual fixed-pattern noise after correction. The correction procedure and the correctability are applied to a real data set measured by a 64 x 64 element infrared focal plane array (FPA). It is shown that an offset correction is insufficient for this data set and that a linear correction reduces the fixed-pattern noise contribution to the magnitude of the temporal noise background. The residual uncorrected fixed pattern noise can be related to pixels showing large temporal noise.},
   author = {M Schulz and L Caldwell},
   journal = {Infrared Phys. Technol},
   pages = {763-777},
   title = {Nonuniformity correction and correctability of infrared focal plane arrays},
   volume = {36},
   year = {1995},
}

@article{Riou2004,
   abstract = {In the last decade, a technology of thermal imagers was developing on the basis of new infrared detectors, as well for civil and military uses. These imagers implement miniaturised infrared detectors laid out in a matrix placed in the optical focal plane of the imager. The technology of the FPA associates the detector matrix to specific electronics allowing detection and addressing on each pixel. This technology allowed a fast improvement of the performance of the thermal imager. Nevertheless, their use in thermography measurement requires some metrological care. The principal problem is both the uniformization of the pixel's response and the temporal stability of this uniformization. The second problem consists in the compensation of the thermal drift. In this paper, we present some practical solutions developed by CEDIP infrared systems to perform non uniformity and thermal drift corrections. Performance and limits are reviewed.},
   author = {Olivier Riou and Stephane Berrebi and Pierre Bremond},
   doi = {10.1117/12.547807},
   issn = {0277786X},
   issue = {April 2004},
   journal = {Thermosense XXVI},
   keywords = {infrared focal plane array,non-uniformity correction,thermal drift},
   pages = {294},
   title = {Non uniformity correction and thermal drift compensation of thermal infrared camera},
   volume = {5405},
   year = {2004},
}

@article{Nugent2013,
   abstract = {Advances in microbolometer detectors have led to the development of infrared cameras that operate without active temperature stabilization. The response of these cameras varies with the temperature of the camera's focal plane array (FPA). This paper describes a method for stabilizing the camera's response through software processing. This stabilization is based on the difference between the camera's response at a measured temperature and at a reference temperature. This paper presents the mathematical basis for such a correction and demonstrates the resulting accuracy when applied to a commercially available longwave infrared camera. The stabilized camera was then radiometrically calibrated so that the digital response from the camera could be related to the radiance or temperature of objects in the scene. For FPA temperature deviations within 7.2°C changing by 0.5°C? min, this method produced a camera calibration with spatial-temporal rms variability of 0.21°C, yielding a total calibration uncertainty of 0.38°C limited primarily by the 0.32°C uncertainty in the blackbody source emissivity and temperature. © The Authors.},
   author = {Paul W. Nugent and Joseph A. Shaw and Nathan J. Pust},
   doi = {10.1117/1.oe.52.6.061304},
   issn = {0091-3286},
   issue = {6},
   journal = {Optical Engineering},
   note = {},
   pages = {061304},
   title = {Correcting for focal-plane-array temperature dependence in microbolometer infrared cameras lacking thermal stabilization},
   volume = {52},
   year = {2013},
}



@article{Chang2019,
   abstract = {Midwave infrared systems with cooled detectors are generally used for high-precision or quantitative measurement, such as radiometry and thermometry. As a basis of these applications, radiometric calibration aims to obtain the relationship between the infrared images and the incident radiant flux generated by the scene or targets. Conventional radiometric calibration algorithms do not take the influences of integration and ambient temperature into consideration. As a consequence, the accuracy of calibration deteriorates whenever the temperature or the integration time varies. To solve this problem, we analyzed the effects of integration time and ambient temperature on coefficients of the radiometric calibration formula by theoretical and experimental analysis. Then, a radiometric calibration method is deduced to remove the variation of integration time and ambient temperature on the accuracy of calibration and radiometry. Several radiometric calibration experiments were conducted using a midwave infrared camera inside a chamber with controllable temperature. The results indicate that the proposed calibration algorithm is more effective and accurate, compared with conventional calibration methods, in complicated working conditions with variable integration times and ambient temperatures.},
   author = {Songtao Chang and Zhou Li},
   doi = {10.1364/ao.58.008118},
   issn = {1559-128X},
   issue = {29},
   journal = {Applied Optics},
   month = {10},
   pages = {8118},
   pmid = {31674366},
   publisher = {The Optical Society},
   title = {Calibration algorithm for cooled mid-infrared systems considering the influences of ambient temperature and integration time},
   volume = {58},
   year = {2019},
}

@article{Liang2017,
   abstract = {},
   author = {Kun Liang and Cailan Yang and Li Peng and Bo Zhou},
   doi = {10.1364/ao.56.000884},
   issn = {0003-6935},
   issue = {4},
   journal = {Applied Optics},
   month = {2},
   pages = {884},
   pmid = {28158089},
   publisher = {The Optical Society},
   title = {Nonuniformity correction based on focal plane array temperature in uncooled long-wave infrared cameras without a shutter},
   volume = {56},
   year = {2017},
}

@article{Oz2020,
   abstract = {Infrared (IR) imagery is used in agriculture for irrigation monitoring and early detection of disease in plants. The common IR cameras in this field typically have low resolution. This work offers a method to obtain the super-resolution of IR images from low-power devices to enhance plant traits. The method is based on deep learning (DL). Most calculations are done in the low-resolution domain. The results of each layer are aggregated together to allow a better flow of information through the network. This work shows that good results can be achieved using depthwise separable convolution with roughly 300K multiply-accumulate computations (MACs), while state-of-the-art convolutional neural network-based super-resolution algorithms are performed with around 1500K MACs. MTF analysis of the proposed method shows a real x4 improvement in the spatial resolution of the system, out-preforming the diffraction limit. The method is demonstrated on real agricultural images.},
   author = {Navot Oz and Nir Sochen and Oshry Markovich and Ziv Halamish and Lena Shpialter-Karol and Iftach Klapp},
   doi = {10.1364/oe.389926},
   issn = {1094-4087},
   issue = {18},
   journal = {Optics Express},
   pages = {27196},
   pmid = {32906975},
   title = {Rapid super resolution for infrared imagery},
   volume = {28},
   year = {2020},
}


@article{Oz2022,
   author = {Navot Oz and Nir Sochen and David Mendelovich and Iftach Klapp},
   doi = {},
   issn = {},
   issue = {},
   journal = {Arxiv},
   pages = {},
   pmid = {},
   title = {Improving temperature estimation in low-cost infrared cameras using deep neural networks},
   volume = {},
   year = {2022},
}





@inproceedings{Shocher2017,
   author = {Assaf Shocher and Nadav Cohen and Michal Irani},
   doi = {10.1109/CVPR.2018.00329},
   journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   month = {12},
   pages = {3118-3126},
   publisher = {IEEE},
   title = {Zero-Shot Super-Resolution Using Deep Internal Learning},
   url = {https://ieeexplore.ieee.org/document/8578427},
   year = {2017},
   booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}


@article{Shaham2019,
   abstract = {We introduce SinGAN, an unconditional generative model that can be learned from a single natural image. Our model is trained to capture the internal distribution of patches within the image, and is then able to generate high quality, diverse samples that carry the same visual content as the image. SinGAN contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. This allows generating new samples of arbitrary size and aspect ratio, that have significant variability, yet maintain both the global structure and the fine textures of the training image. In contrast to previous single image GAN schemes, our approach is not limited to texture images, and is not conditional (i.e. it generates samples from noise). User studies confirm that the generated samples are commonly confused to be real images. We illustrate the utility of SinGAN in a wide range of image manipulation tasks.},
   author = {Tamar Rott Shaham and Tali Dekel and Tomer Michaeli},
   doi = {10.1109/ICCV.2019.00467},
   isbn = {9781728148038},
   issn = {15505499},
   journal = {Proceedings of the IEEE International Conference on Computer Vision},
   pages = {4569-4579},
   title = {SinGAN: Learning a generative model from a single natural image},
   volume = {2019-Octob},
   year = {2019},
}

@article{Cao2014,
  doi = {10.1364/ol.39.000646},
  url = {https://doi.org/10.1364/ol.39.000646},
  year = {2014},
  month = jan,
  publisher = {The Optical Society},
  volume = {39},
  number = {3},
  pages = {646},
  author = {Yanpeng Cao and Christel-Loic Tisse},
  title = {Single-image-based solution for optics temperature-dependent nonuniformity correction in an uncooled long-wave infrared camera},
  journal = {Optics Letters}
}

@inproceedings{Scribner91,
author = {Dean A. Scribner and Kenneth A. Sarkady and Melvin R. Kruer and John T. Caulfield and J. D. Hunt and Charles Herman},
title = {{Adaptive nonuniformity correction for IR focal-plane arrays using neural networks}},
volume = {1541},
booktitle = {Infrared Sensors: Detectors, Electronics, and Signal Processing},
editor = {T. S. Jay Jayadev},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {100 -- 109},
abstract = {With rapid advancements in infrared focal plane array (IRFPA) technology, greater demands are being placed on nonuniformity correction (NUC) techniques to provide near-BLIP performance over a wide dynamic range. Standard NUC techniques involve calibrating each detector using reference temperature sources before imaging the IRFPA. Usually the correction needs to be re-calibrated after a short period of time due to IRFPA drift or to adjust for changes in the level of background flux. Adaptive NUC techniques eliminate the need for calibration by continuously updating the correction coefficients based on radiance levels of the scene being viewed. In this manner, continuous compensation can be applied adaptively for individual detector non-idealities and background changes. Two adaptive NUC techniques are discussed; one is a temporal highpass filter and the other involves a neural network with lateral interconnects to nearest neighbor pixels. Both have similarities to biological retinal processing. Questions of implementation and stability are discussed and performance results are given for several test image sequences which were obtained from an MWIR HgCdTe array and a HIDAD uncooled array. We conclude that adaptive techniques will be very useful in future IRFPA sensors, primarily because of their ability to adapt over a wide range of background flux without calibration sources, but also because they can offer improved sensitivity under most operating conditions.},
year = {1991},
doi = {10.1117/12.49324},
URL = {https://doi.org/10.1117/12.49324}
}

@article{Zhao13,
title = {Single image stripe nonuniformity correction with gradient-constrained optimization model for infrared focal plane arrays},
journal = {Optics Communications},
volume = {296},
pages = {47-52},
year = {2013},
issn = {0030-4018},
doi = {https://doi.org/10.1016/j.optcom.2013.01.038},
author = {Jufeng Zhao and Qiang Zhou and Yueting Chen and Tao Liu and Huajun Feng and Zhihai Xu and Qi Li},
keywords = {Stripe nonuniformity correction, Infrared focal plane arrays, Gradient-constrained optimization},
abstract = {Stripe non-uniformity commonly exists in infrared focal plane array (IRFPA). The current study develops a scene-based stripe non-uniformity correction (NUC) method using only a single image. Efforts were made to translate the stripe NUC problem into a gradient-constrained optimization problem. The optimization aims to seek the optimal image with a vertical gradient as close to the original image as possible and make the energy of the horizontal gradient as small as possible. The experiments indicate that the proposed algorithm can provide enhanced results effectively and efficiently.}
}

@article{Tendero12,
   abstract = {We propose a new way to correct for the non-uniformity (NU) and the noise in uncooled infrared-type images. This method works on static images, needs no registration, no camera motion and no model for the non uniformity. The proposed method uses an hybrid scheme including an automatic locally-adaptive contrast adjustment and a state-of-the-art image denoising method. It permits to correct for a fully non-linear NU and the noise efficiently using only one image. We compared it with total variation on real raw and simulated NU infrared images. The strength of this approach lies in its simplicity, low computational cost. It needs no test-pattern or calibration and produces no "ghost-artefact".},
   author = {Y Tendero and J Gilles},
   doi = {10.1117/12.912966},
   journal = {Infrared Technology and Applications},
   keywords = {Fixed Pattern Noise,Focal Plane Array,Infrared,NUC,Non uniformity correction,denoising},
   month = {5},
   pages = {580-595},
   title = {ADMIRE: a locally adaptive single-image, non-uniformity correction and denoising algorithm: application to uncooled IR camera},
   volume = {8353},
   url = {https://doi.org/10.1117/12.912966},
   year = {2012},
}

@article{Zuo11,
author = {Chao Zuo and Qian Chen and Guohua Gu and Xiubao Sui},
journal = {J. Opt. Soc. Am. A},
keywords = {Arrays; Digital image processing; Focal-plane-array image processors; Image enhancement; Infrared imaging; Detector arrays; Discrete Fourier transforms; Infrared imaging; Motion estimation; Noise reduction; Spatial resolution},
number = {6},
pages = {1164--1176},
publisher = {Optica Publishing Group},
title = {Scene-based nonuniformity correction algorithm based on interframe registration},
volume = {28},
month = {Jun},
year = {2011},
url = {https://opg.optica.org/josaa/abstract.cfm?URI=josaa-28-6-1164},
doi = {10.1364/JOSAA.28.001164},
abstract = {In this paper, we present a simple and effective scene-based nonuniformity correction (NUC) method for infrared focal plane arrays based on interframe registration. This method estimates the global translation between two adjacent frames and minimizes the mean square error between the two properly registered images to make any two detectors with the same scene produce the same output value. In this way, the accumulation of the registration error can be avoided and the NUC can be achieved. The advantages of the proposed algorithm lie in its low computational complexity and storage requirements and ability to capture temporal drifts in the nonuniformity parameters. The performance of the proposed technique is thoroughly studied with infrared image sequences with simulated nonuniformity and infrared imagery with real nonuniformity. It shows a significantly fast and reliable fixed-pattern noise reduction and obtains an effective frame-by-frame adaptive estimation of each detector's gain and offset.},
}

@article{Vera05,
   abstract = {A novel adaptive scene-based nonuniformity correction technique is presented. The technique simultaneously estimates detector parameters and performs the nonuniformity correction based on the retina-like neural network approach. The proposed method includes the use of an adaptive learning rate rule in the gain and offset parameter estimation process. This learning rate rule, together with a reduction in the averaging window size used for the parameter estimation, may provide an efficient implementation that should increase the original method's scene-based ability to estimate the fixed-pattern noise. The performance of the proposed algorithm is then evaluated with infrared image sequences with simulated and real fixed-pattern noise. The results show a signi-ficative faster and more reliable fixed-pattern noise reduction, tracking the parameters drift, and presenting a good adaptability to scene changes and nonuniformity conditions.},
   author = {Esteban Vera and Sergio Torres},
   issue = {13},
   journal = {EURASIP Journal on Applied Signal Processing},
   keywords = {fixed-pattern noise,focal-plane array,infrared detectors,least mean square,neural networks,nonuniformity correction},
   title = {Fast Adaptive Nonuniformity Correction for Infrared Focal-Plane Array Detectors},
   year = {2005},
}


@article{Hardie00,
author = {Russell C. Hardie and Majeed M. Hayat and Earnest Armstrong and Brian Yasuda},
journal = {Appl. Opt.},
keywords = {Arrays; FLIR, forward-looking infrared; Photodetectors; Digital image processing; Image reconstruction-restoration; Detector arrays; Detectors; Infrared sensors; Infrared systems; Motion estimation; Photodetectors},
number = {8},
pages = {1241--1250},
publisher = {Optica Publishing Group},
title = {Scene-based nonuniformity correction with video sequences and registration},
volume = {39},
month = {Mar},
year = {2000},
url = {https://opg.optica.org/ao/abstract.cfm?URI=ao-39-8-1241},
doi = {10.1364/AO.39.001241},
abstract = {We describe a new, to our knowledge, scene-based nonuniformitycorrection algorithm for array detectors. The algorithm relies onthe ability to register a sequence of observed frames in the presenceof the fixed-pattern noise caused by pixel-to-pixelnonuniformity. In low-to-moderate levels of nonuniformity,sufficiently accurate registration may be possible with standardscene-based registration techniques. If the registration isaccurate, and motion exists between the frames, then groups ofindependent detectors can be identified that observe the sameirradiance (or true scene value). These detector outputs areaveraged to generate estimates of the true scene values. With thesescene estimates, and the corresponding observed values through a givendetector, a curve-fitting procedure is used to estimate the individualdetector response parameters. These can then be used to correct fordetector nonuniformity. The strength of the algorithm lies in itssimplicity and low computational complexity. Experimental results,to illustrate the performance of the algorithm, include the use ofvisible-range imagery with simulated nonuniformity and infrared imagerywith real nonuniformity.},
}

@ARTICLE{Harris99,  author={Harris, J.G. and Yu-Ming Chiang},  journal={IEEE Transactions on Image Processing},   title={Nonuniformity correction of infrared image sequences using the constant-statistics constraint},   year={1999},  volume={8},  number={8},  pages={1148-1151},  doi={10.1109/83.777098}}

@article{Jian2018,
   abstract = {The fixed-pattern noise (FPN) caused by nonuniform optoelectronic response limits the sensitivity of an infrared imaging system and severely reduces the image quality. Therefore, nonuniform correction of infrared images is very important. In this paper, we propose a deep filter neural network to solve the problems of network underfitting and complex training with convolutional neural network (CNN) applications in nonuniform correction. Our work is mainly based on the idea of deep learning, where the nonuniform image noise features are fully learned from a large number of simulated training images. The network is designed by introducing the filter and the subtraction structure. The background interference of the image is removed by the filter, so the learning model is gathered in the nonuniform noise. The subtraction structure is used to further reduce the input-to-output mapping range, which effectively simplifies the training process. The results from the test on infrared images shows that our algorithm is superior to the state-of-the-art algorithm in visual effects and quantitative measurements, providing a new method for deep learning in nonuniformity correction of single images.},
   author = {Xianzhong Jian and Chen Lv and Ruzhi Wang},
   doi = {10.3390/sym10110612},
   journal={Symmetry},
   title = {Nonuniformity Correction of Single Infrared Images Based on Deep Filter Neural Network},
   year = {2018},
}


@article{He2018,
   author = {Zewei He and Yanlong Yanpeng Cao and Yafei Dong and Jiangxin Yang and Christel-Löic Tisse},
   doi = {10.1364/ao.57.00d155},
   issn = {1559-128X},
   issue = {18},
   journal = {Applied Optics}, 
   pages = {D155},
   pmid = {30117949},
   title = {Single-image-based nonuniformity correction of uncooled long-wave infrared detectors: a deep-learning approach},
   volume = {57},
   year = {2018},
}


@article{ChangDeepLearning2019,
   abstract = {In the infrared focal plane arrays imaging systems, the temperature-dependent nonuniformity effects severely degrade the image quality. In this letter, we propose a very deep convolutional neural network for unified infrared aerothermal nonuniform correction. Our network is built with the multiscale and residual training. The multiscale subnetworks utilize the multiscale property in the images, and the long-short-term residual learning contributes to the information propagation. Compared with the previous methods, the proposed method is more robust to various nonuniform artifacts and more efficient at processing time. Experimental results validate the superiority of our method for infrared nonuniform correction.},
   author = {Yi Chang and Luxin Yan and Li Liu and Houzhang Fang and Sheng Zhong},
   doi = {10.1109/LGRS.2019.2893519},
   issn = {15580571},
   issue = {7},
   journal = {IEEE Geoscience and Remote Sensing Letters},
   keywords = {Convolutional neural network (CNN),infrared image,nonuniform correction},
   note = {https://owuchangyuo.github.io/files/DMRN.rar<br/>Code},
   pages = {1120-1124},
   publisher = {IEEE},
   title = {Infrared Aerothermal Nonuniform Correction via Deep Multiscale Residual Network},
   volume = {16},
   year = {2019},
}


@inproceedings{Saragadam2021,
   abstract = {We introduce DeepIR, a new thermal image processing framework that combines physically accurate sensor modeling with deep network-based image representation. Our key enabling observations are that the images captured by thermal sensors can be factored into slowly changing, scene-independent sensor non-uniformities (that can be accurately modeled using physics) and a scene-specific radiance flux (that is well-represented using a deep network-based regularizer). DeepIR requires neither training data nor periodic ground-truth calibration with a known black body target-making it well suited for practical computer vision tasks. We demonstrate the power of going DeepIR by developing new denoising and super-resolution algorithms that exploit multiple images of the scene captured with camera jitter. Simulated and real data experiments demonstrate that DeepIR can perform high-quality non-uniformity correction with as few as three images, achieving a 10dB PSNR improvement over competing approaches.},
   author = {Vishwanath Saragadam and Akshat Dave and Ashok Veeraraghavan and Richard G Baraniuk},
   booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   title = {Thermal Image Processing via Physics-Inspired Deep Networks},
   url = {https://github.com/vishwa91/DeepIR},
   year = {2021},
}


@article{Averbuch2007,
   abstract = {Thermal array detectors, also known as focal-plane arrays (FPA), are a rapidly developing technology and are used in a variety of civil, medical and military applications. The detectors, which are sensitive to radiation in the infrared band, output a high resolution low noise thermal picture. The existence of non-uniformities in the responsitivity of the element array is a severe problem typical to FPA. These non-uniformities result in a fixed pattern "curtain"-like feature that appear in the image. One of the most common methods to correct non-uniformity is the use of a uniform reference target. This type of non-uniformity correction has a number of disadvantages. The work presented in this paper proposes a new method to calibrate a thermal detector. The proposed correction method is scene based, relying only on the camera's captured video sequence. The algorithm utilizes redundant information achieved from the thermal camera's high sample rate, combined with the camera's motion. The proposed correction algorithm contains two steps: (1) Application of frame registration that compensates for the camera motion. The registration process matches two consecutive frames and produces a residual (difference) frame. Here, we use well-known techniques. (2) Definition of the calibration parameters as a system of linear equations that is solved with the use of a Kalman filter. The Kalman filter tracks the value of each element specific responsitivity value (unknown) through time. Extensive experimental results demonstrate the success of the proposed scheme. The proposed algorithm necessitates modest computational power (ran on a PC with a Pentium III 550 MHz processor) due to the sparsity of the involved matrices. © 2006 Elsevier B.V. All rights reserved.},
   author = {Amir Averbuch and Gabi Liron and Ben Zion Bobrovsky},
   doi = {10.1016/j.imavis.2006.05.019},
   issn = {02628856},
   issue = {6},
   journal = {Image and Vision Computing},
   keywords = {Detection and correction of non-uniformities,Focal-plane array,Kalman filter,Thermal picture},
   month = {6},
   pages = {833-851},
   publisher = {Elsevier Ltd},
   title = {Scene based non-uniformity correction in thermal images using Kalman filter},
   volume = {25},
   year = {2007},
}


@article{Papini2018,
   abstract = {Low cost, weight, and size microbolometer-based thermal focal plane arrays are attractive for thermal-imaging applications. Under environmental loads like those in agricultural remote sensing, these cameras tend to suffer from drift in gain and offset with time and thus require constant calibration. Our goal is to skip this step via computational imaging. In a previous work we estimated the unknown offset value and radiometric image of an object, given the calibrated gain, from a pair of successive images taken at two different blur levels, eliminating the need for offset calibration due to temperature variation. Here, we extend our model to a case with unknown gain and offset. We show that these values, as well as the objects' radiometric value, can be found jointly by minimizing a cost function relying on N pairs of blurred and sharp images. The method addresses both space-invariant and space-variant cases. Simulations show promising accuracy with error characterized by root mean squared error of less than 1.6 degrees C.},
   author = {Shahar Papini and Peretz Yafin and Iftach Klapp and Nir Sochen},
   doi = {10.1364/ao.57.010390},
   issn = {1559-128X},
   issue = {36},
   journal = {Applied Optics},
   pages = {10390},
   pmid = {30645382},
   title = {Joint estimation of unknown radiometric data, gain, and offset from thermal images},
   volume = {57},
   year = {2018},
}


@inproceedings{mildenhall2018kpn,
  author = {Mildenhall, Ben and Barron, Jonathan T and Chen, Jiawen and Sharlet, Dillon and Ng, Ren and Carroll, Robert},
  title = {Burst Denoising with Kernel Prediction Networks},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2018}
}

@inproceedings{Dahary2020,
   abstract = {Mechanical image stabilization using actuated gimbals enables capturing long-exposure shots without suffering from blur due to camera motion. These devices, however, are often physically cumbersome and expensive, limiting their widespread use. In this work, we propose to digitally emulate a mechanically stabilized system from the input of a fast unstabilized camera. To exploit the trade-off between motion blur at long exposures and low SNR at short exposures, we train a CNN that estimates a sharp high-SNR image by aggregating a burst of noisy short-exposure frames, related by unknown motion. We further suggest learning the burst's exposure times in an end-to-end manner, thus balancing the noise and blur across the frames. We demonstrate this method's advantage over the traditional approach of deblurring a single image or denoising a fixed-exposure burst on both synthetic and real data.},
   author = {Omer Dahary and Matan Jacoby and Alex M. Bronstein},
   title = {Digital Gimbal: End-to-end Deep Image Stabilization with Learnable Exposure Times},
   year = {2020},
   booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}


@inproceedings{DeBrabandere16,
author = {De Brabandere, Bert and Jia, Xu and Tuytelaars, Tinne and Van Gool, Luc},
title = {Dynamic Filter Networks},
year = {2016},
isbn = {9781510838819},
abstract = {In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture.We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.},
booktitle = {30th International Conference on Neural Information Processing Systems (NIPS)},
}

@INPROCEEDINGS{Younghyun18,  author={Jo, Younghyun and Oh, Seoung Wug and Kang, Jaeyeon and Kim, Seon Joo},  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation},   year={2018},  volume={},  number={},  pages={3224-3232},  doi={10.1109/CVPR.2018.00340}}


@article{gelu,
  title={Gaussian Error Linear Units (GELUs)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{anwar2020,
author = {Anwar, Saeed and Khan, Salman and Barnes, Nick},
title = {A Deep Journey into Super-Resolution: A Survey},
year = {2020},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3390462},
doi = {10.1145/3390462},
abstract = {Deep convolutional networks–based super-resolution is a fast-growing field with numerous practical applications. In this exposition, we extensively compare more than 30 state-of-the-art super-resolution Convolutional Neural Networks (CNNs) over three classical and three recently introduced challenging datasets to benchmark single image super-resolution. We introduce a taxonomy for deep learning–based super-resolution networks that groups existing methods into nine categories including linear, residual, multi-branch, recursive, progressive, attention-based, and adversarial designs. We also provide comparisons between the models in terms of network complexity, memory footprint, model input and output, learning details, the type of network losses, and important architectural differences (e.g., depth, skip-connections, filters). The extensive evaluation performed shows the consistent and rapid growth in the accuracy in the past few years along with a corresponding boost in model complexity and the availability of large-scale datasets. It is also observed that the pioneering methods identified as the benchmarks have been significantly outperformed by the current contenders. Despite the progress in recent years, we identify several shortcomings of existing techniques and provide future research directions towards the solution of these open problems. Datasets and codes for evaluation are publicly available at https://github.com/saeed-anwar/SRsurvey.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {60},
numpages = {34},
keywords = {convolutional neural networks (CNNs), survey, Super-resolution (SR), high-resolution (HR), generative adversarial networks (GANs), deep learning}
}

@ARTICLE{ssimLoss2017,  author={Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},  journal={IEEE Transactions on Computational Imaging},   title={Loss Functions for Image Restoration With Neural Networks},   year={2017},  volume={3},  number={1},  pages={47-57},  doi={10.1109/TCI.2016.2644865}}


@InProceedings{batchNorm,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/ioffe15.html},
  abstract = 	 {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.}
}


@article{pytorch,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017},
  journal = {NIPS},
}

@book{python,
 author = {Van Rossum, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}


@inproceedings{orthoInit2014,
  author    = {Andrew M. Saxe and
               James L. McClelland and
               Surya Ganguli},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Exact solutions to the nonlinear dynamics of learning in deep linear
               neural networks},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6120},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SaxeMG13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{adamOpt2015,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{
ir_importance_1,
author = {Henry D. Adams  and Maite Guardiola-Claramonte  and Greg A. Barron-Gafford  and Juan Camilo Villegas  and David D. Breshears  and Chris B. Zou  and Peter A. Troch  and Travis E. Huxman },
title = {Temperature sensitivity of drought-induced tree mortality portends increased regional die-off under global-change-type drought},
journal = {Proceedings of the National Academy of Sciences},
volume = {106},
number = {17},
pages = {7063-7066},
year = {2009},
doi = {10.1073/pnas.0901438106},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.0901438106},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.0901438106},
abstract = {Large-scale biogeographical shifts in vegetation are predicted in response to the altered precipitation and temperature regimes associated with global climate change. Vegetation shifts have profound ecological impacts and are an important climate-ecosystem feedback through their alteration of carbon, water, and energy exchanges of the land surface. Of particular concern is the potential for warmer temperatures to compound the effects of increasingly severe droughts by triggering widespread vegetation shifts via woody plant mortality. The sensitivity of tree mortality to temperature is dependent on which of 2 non-mutually-exclusive mechanisms predominates—temperature-sensitive carbon starvation in response to a period of protracted water stress or temperature-insensitive sudden hydraulic failure under extreme water stress (cavitation). Here we show that experimentally induced warmer temperatures (≈4 °C) shortened the time to drought-induced mortality in Pinus edulis (piñon shortened pine) trees by nearly a third, with temperature-dependent differences in cumulative respiration costs implicating carbon starvation as the primary mechanism of mortality. Extrapolating this temperature effect to the historic frequency of water deficit in the southwestern United States predicts a 5-fold increase in the frequency of regional-scale tree die-off events for this species due to temperature alone. Projected increases in drought frequency due to changes in precipitation and increases in stress from biotic agents (e.g., bark beetles) would further exacerbate mortality. Our results demonstrate the mechanism by which warmer temperatures have exacerbated recent regional die-off events and background mortality rates. Because of pervasive projected increases in temperature, our results portend widespread increases in the extent and frequency of vegetation die-off.}}

@article{ir_importance_2,
    author = {Jones, Hamlyn G.},
    title = "{Monitoring plant and soil water status: established and novel methods revisited and their relevance to studies of drought tolerance}",
    journal = {Journal of Experimental Botany},
    volume = {58},
    number = {2},
    pages = {119-130},
    year = {2006},
    month = {09},
    abstract = "{In all studies of the effects of water deficits on plant functioning there is a need for an accurate and comprehensive definition of treatments and their effects on plant water status. The various measures of water status used in plant and soil science are reviewed and their appropriateness for different purposes such as for studies of mechanistic effects of water deficits on plants, for breeding of drought-tolerant plants, or for management of irrigation systems are reviewed. An important conclusion is that the frequent emphasis on water potential rather than on cell turgor can be shown to be misleading, as can be measurements in the leaf. The disadvantages of the current trend towards the omission of necessary water-status measurements, especially common in more molecular studies, are outlined, and recommendations made for minimal sets of measurements for specific types of experiments.}",
    issn = {0022-0957},
    doi = {10.1093/jxb/erl118},
    url = {https://doi.org/10.1093/jxb/erl118},
    eprint = {https://academic.oup.com/jxb/article-pdf/58/2/119/1421554/erl118.pdf},
}


@article{bolometer,
	author = {Bhan, R and Saxena, Raghvendra and Jalwania, C.R. and Lomash, S.K.},
	year = {2009},
	month = {11},
	pages = {580},
	title = {Uncooled Infrared Microbolometer Arrays and their Characterisation Techniques},
	volume = {59},
	journal = {Defence Science Journal},
	doi = {10.14429/dsj.59.1562}
}

@article{shuffle_block,
	title={Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network},
	author={Wenzhe Shi and Jose Caballero and Ferenc Husz{\'a}r and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},
	journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2016},
	pages={1874-1883}
}