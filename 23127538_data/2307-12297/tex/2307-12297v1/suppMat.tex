% \renewcommand{\thefigure}{S\@arabic\c@figure}

\newcommand{\heightDiffResSupp}{13ex}
\newcommand{\makeRowResultsSupp}[1]{\subfloat{% Figure removed}
                                \hfill
                                \subfloat{% Figure removed}
                                \hfill
                                \subfloat{% Figure removed}
                                \hfill
                                \subfloat{% Figure removed}
                                \hfill
                                \subfloat{% Figure removed}}
\newcommand{\makeResultsFigSupp}[7]{% Figure environment removed
}
\newcommand{\heightPatchResSupp}{0.16\linewidth}%
\newcommand{\makePatchRowSupp}[1]{
    \subfloat{% Figure removed}
    \hfill
    \subfloat{% Figure removed}
    \hfill
    \subfloat{% Figure removed}
    \hfill
    \subfloat{% Figure removed}
    \hfill
    \subfloat{% Figure removed}
    \hfill
    \subfloat{% Figure removed}
}%
\newcommand{\makePatchesFigSupp}[7]{% Figure environment removed}%
\newcommand{\makePatchesFigHallucinationSupp}[7]{% Figure environment removed}%


\section{Network architecture}
A schematic diagram of the whole network is given in \cref{fig:methods:network} and enlarged in \cref{supp_network}. Bellow is a detailed description of the network architecture, from the UNET encoder-decoder part to the kernel estimation block and the offset block.

First we describe the UNET encoder-decoder part.
We use a tensor with $\nFrames$ channels of grey-level frames as the input to the network. The input tensor undergoes a $3\times 3$ convolution (conv) layer that encodes it from $\nFrames$ channels to $\nChannels$ channels without any activation function. The encoded features then pass through the encoder and decoder parts of the network, where the number of channels is multiplied by a factor of $\scaleFactor$ at each level. The encoder and decoder blocks consist of three $3\times 3$ conv layers each. The first two layers in each block have GeLU~\cite{gelu} and batch normalization (norm)~\cite{batchNorm}, while the last layer has neither activation nor norm. The last layer in each block produces $\nChannels\times\scaleFactor^i$ channels, where $i$ is the level index. The encoder block also applies an average pooling layer with a $\scaleFactor\times\scaleFactor$ window and stride $\scaleFactor$ to reduce the spatial resolution, while the decoder block uses a pixel shuffle layer~\cite{shuffle_block} with an upsample factor of $\scaleFactor$ to increase it. We concatenate the encoder block output before pooling with the pixel shuffle output at each level before feeding it to the decoder block. The encoder and decoder block structures are shown in \cref{table:nn_architecture}.

After the last decoder block in the UNET, we add a kernel estimation block that generates $\nFrames\times K\times K$ channels using three $1\times1$ conv layers. The first two layers have GeLU, and the last layer has no activation. The kernel estimation block structure is shown in \cref{table:kpnBlock}. We reshape the output of this block as kernels of size $K\times K$ for each frame. We then sample a patch of size $K\times K$ around each pixel in each frame and compute the inner product of the corresponding kernel and patch, as in the first term of \cref{eq:methods:KPN}. We sum the inner products from all the frames for each pixel.

To map the temperature estimation to the camera range, we use an offset block that takes the means of all the input gray level frames as input and outputs a single scalar. 
The offset block is a fully-connected layer that acts as a polynomial function of the input. The offset block is explained in more detail in \cref{sec:methods:net}.

The final temperature estimation is obtained by adding the offset scalar to the pixel-wise summation of the gain from the kernel estimation block.

The scale factor for decoder and encoder blocks is $\scaleFactor\equiv2$ and the number of channels is $\nChannels\equiv64$ throughout the work. 
The number of levels was empirically set to $4$.


\section{List of figures}
\cref{supp_realdata} shows more results of the proposed method on real data.

\cref{supp_patch_1,supp_patch_2,supp_patch_3,supp_patch_4,supp_patch_5,supp_patch_6} compares the results of the proposed method to ADMIRE~\cite{Tendero12}, DeepIR~\cite{Saragadam2021} and He~\cite{He2018} methods. \cref{supp_patch_5,supp_patch_6} specifically show the hallucination effect of DeepIR~\cite{Saragadam2021} method.

\cref{supp_diff_7,supp_diff_8,supp_diff_9,supp_diff_10,supp_diff_11} displays the absolute error per-pixel as a function of number of frames, both in quantitatively and qualitatively.

\cref{supp_H,supp_I,supp_A,supp_O,supp_B,supp_M} are the original images used for the real data results in \cref{fig:results:realdata}. On the left of each figure is the GT temperature map acquired by the \scientificCamera, and on the right is the estimated temperature map by the proposed method. The raw data cannot be displayed because it consists of 7 frames.

\cref{supp_uav} shows the UAV used for the real data experiments.

\cref{supp_network} is an enlarged version of \cref{fig:methods:network}.

\cref{tab:cameraParams} specifies the parameters of \taucamera\ that were used throughout all the experiments.

\clearpage
\input{methods/tableNetwork.tex}

\begin{table}[h]
    \centering
    \caption{The FLIR \taucamera\ settings as described in Tau2 Quark Software IDD}
    \begin{tabular}{|c|c||c|c|}
        \hline
        Function   & State  & Function        & State                  \\
        \hline\hline
        FFC Mode   & Auto   & FPS             & 4 ($60_{Hz}$)          \\
        \hline
        FFC Period & 0      & CMOS Depth      & 0 ($14_{bit}$ w/o AGC) \\
        \hline
        Isotherm   & 0      & LVDS            & 0                      \\
        \hline
        DDE        & 0      & LVDS Depth      & 0 ($14_{bit}$)         \\
        \hline
        T-Linear   & 0      & XP              & 2 ($14_{bit}$)         \\
        \hline
        AGC        & Manual & Brightness Bias & 0                      \\
        \hline
        Contrast   & 0      & Brightness      & 0                      \\
        \hline
        ACE        & 0      & SSO             & 0                      \\
        \hline
        Gain       & High   &                 &                        \\
        \hline
    \end{tabular}
    \label{tab:cameraParams}
\end{table}
\clearpage

\newcommand{\sizeRealDataSupp}{0.48}%
% Figure environment removed%


% In article: 180725_Ramon_1, 180805_Peach_31, 180805_Peach_37, MevoBytar_210818_69, YanivReshef_190816_32
\makePatchesFigSupp{180725_Ramon_2}{180725_Ramon_4}{180725_Ramon_5}{180725_Ramon_7}{180725_Ramon_8}{180725_Ramon_10}{1}%
\makePatchesFigSupp{180725_Ramon_11}{180805_Peach_14}{180805_Peach_16}{180805_Peach_34}{180805_Peach_35}{180805_Peach_40}{2}%
\makePatchesFigSupp{180805_Peach_57}{180805_Peach_60}{180805_Peach_87}{180805_Peach_90}{180805_Peach_91}{Gilat_210809_37}{3}%
\makePatchesFigSupp{Gilat_210809_44}{Gilat_210809_260}{MevoBytar_210818_42}{MevoBytar_210818_82}{MevoBytar_210818_96}{NirEliyho_211005_560}{4}%
\makePatchesFigHallucinationSupp{NeveYaar_210520_14}{NeveYaar_210520_55}{NeveYaar_210520_148}{NeveYaar_210520_394}{NeveYaar_210520_421}{NeveYaar_210520_424}{5}%
\makePatchesFigHallucinationSupp{NeveYaar_210520_867}{NeveYaar_210520_966}{NeveYaar_210520_1033}{NeveYaar_210520_867}{NirEliyho_211005_169}{Tzora_210523_35}{6}%

% In article NeveYaar_210520_1, NeveYaar_210520_2, MevoBytar_210818_2, Tzora_210523_9, NirEliyho_211005_0, NirEliyho_211005_10
\makeResultsFigSupp{180805_Peach_18}{Gilat_210809_0}{Gilat_210809_3}{Gilat_210809_4}{Gilat_210809_11}{Gilat_210809_18}{7}
\makeResultsFigSupp{Gilat_210809_19}{MevoBytar_210818_0}{MevoBytar_210818_3}{MevoBytar_210818_7}{MevoBytar_210818_8}{MevoBytar_210818_9}{8}
\makeResultsFigSupp{MevoBytar_210818_11}{MevoBytar_210818_13}{NeveYaar_210520_0}{NeveYaar_210520_5}{NeveYaar_210520_6}{NeveYaar_210520_9}{9}
\makeResultsFigSupp{NeveYaar_210520_14}{NirEliyho_211005_5}{NirEliyho_211005_9}{NirEliyho_211005_14}{NirEliyho_211005_16}{Tzora_210523_3}{10}
\makeResultsFigSupp{Tzora_210523_8}{Tzora_210523_14}{Tzora_210523_16}{YanivReshef_190816_7}{YanivReshef_190816_8}{YanivReshef_190816_11}{11}

% GT and estimated temperature maps
\newcommand{\sizeGT}{0.48}%
\newcommand{\sizeEst}{0.36}%
\newcommand{\makeGT}[3]{
    % Figure environment removed
}
\makeGT{H}{\cref{fig:results:realdata} (a)}\\
\makeGT{I}{\cref{fig:results:realdata} (b)}\\
\makeGT{A}{\cref{fig:results:realdata} (c)}\\
\makeGT{O}{\cref{fig:results:realdata} (d)}\\
\makeGT{B}{\cref{fig:results:realdata} (e)}\\
\makeGT{M}{\cref{fig:results:realdata} (f)}


% Figure environment removed


% Figure environment removed
