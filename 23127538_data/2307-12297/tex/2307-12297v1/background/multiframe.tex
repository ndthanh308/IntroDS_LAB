\noindent Consecutive frames over a brief period of time have an overlap between them (an example of a real UAV pattern with overlapping frames can be seen in \cref{sec:results:realdata}). These consecutive frames are called a burst. The overlap between frames implies that the same object appears in multiple frames. 
As seen in \cref{eq:acquisition:affine}, the gain and offset are dependent on the pixel location on the sensor, thus different views of the same object can be exploited as redundant information. 
The redundant information between frames is demonstrated in \cref{fig:approach:redundentNonUniformity}.

To exploit the redundant information, first an object must have the same coordinates across all frames. To achieve coordinate alignment registration is performed.

Image registration is the process of aligning two or more images of the same scene taken from different viewpoints or at different times~\cite{computationalGeometry}. Transforming a source frame toward the coordinate system of another destination frame is called a projective transformation, or an homography~\cite[Chapter~0]{HartleyRichard2004MVGi}. An homography transformation preserves co-linearity between the frames. Moreover, an homography is invertible and linear by definition~\cite[Def.~2.9]{HartleyRichard2004MVGi}. In layman terms, the homography preserves the shapes and relations between objects. 

After applying the homography on the source frame, an object should have the same coordinates in both the source and destination frames. The transformed source frame is called a warped frame. Expanding to $N$ frames, there exists a set of projective transformations $m_1,\ldots,m_N$ towards a common plane such that the overlap between the frames is maximal~\cite[Ch.~4]{HartleyRichard2004MVGi}. Objects that appear in the overlapping area will have the same coordinates in every warped frame. For our practical use, we choose a pivot frame for each burst of frames and annotate the pivot frame as $\mathcal{I}$.

An underlying assumption throughout this work is that the gain and offset in \cref{eq:acquisition:affine:pixel} are constant for a series of frames taken over a short duration of time (a second). This assumption holds because the ambient temperature of the camera changes at a much slower rate (several minutes).

Let $X$ be the fourth power of an accurate 2D temperature map, and $I_1,\ldots,I_N$ be a set of $N$ frames of $X$ captured by the IR camera. $I_i$ is in gray levels.
$I_i^{x_i,y_i}$ is the value of the pixel in the $[x_i,y_i]$ location of $I_i$. 
$[u,v]$ are the coordinates of $\mathcal{I}$ the pivot frame. 
The frames in the burst can be formulated as:
\begin{equation}\label{eq:multiframe:setOfFrames}
    \begin{matrix}
        I_1^{x_1,y_1}=g^{x_1,y_1}(\tamb)\cdot m_1^{-1}\left(X^{u,v}\right)+d^{x_1,y_1}(\tamb)\\
        \vdots\\
        I_N^{x_N,y_N}=g^{x_N,y_N}(\tamb)\cdot m_N^{-1}\left(X^{u,v}\right)+d^{x_N,y_N}(\tamb)
    \end{matrix}
\end{equation} where $m_1,\ldots,m_N$ are the set of homographies that transforms each frame into $\mathcal{I}$ the pivot frame. The zero-mean noise $\mathcal{N}$ was omitted for brevity.

\cref{eq:multiframe:setOfFrames} formulates the acquisition process of a frame as projecting the temperature map $X$ using an inverse of the homography $m_i$, and than sampling the projected $X$ by applying the gain $g$, offset $d$ and noise $\mathcal{N}$. 
Notice that an object will be sampled at different coordinates for each frame, and since the gain and offset are spatially-variant the object will have different gain and offset for each frame.

The result in \cref{eq:multiframe:setOfFrames} means that an object appearing in pixel $[u,v]$ of the temperature map $X$ will have multiple representation with different values of $g,d$ and $\mathcal{N}$, enabling the use of redundant information between the frames.

Redundant information between frames was used for many image restoration tasks such as super-resolution~\cite{multi_sr_classic, multi_sr_classic2}, denoising~\cite{multi_denoise_classic} and debluring~\cite{multi_deblur_classic}. 
Many recent works in the area use DL for either the alignment~\cite{Detone16}, the fusion between frames~\cite{multi_denoise_dl}, or both~\cite{multi_sr_dl1, multi_sr_dl2, multi_sr_dl3}.