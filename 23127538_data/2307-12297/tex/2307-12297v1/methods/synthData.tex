\noindent The network was trained with synthetic data in a supervised manner.
The inputs to the network were created from accurate 2D temperature maps collected using a scientific-grade IR camera (\scientificCamera).
A degradation model of a low-cost IR camera (\taucamera) was applied to the temperature maps, transforming them to grey-level frames. As a result, the network trained on transforming gray-level frames to accurate temperature maps.

The goal of the degradation model was to faithfully transform temperature maps into gray level maps, allowing the supervised training process of the network. 
The modeling process had three stages. 
First, collecting data with the IR camera in a controlled environment.
The second stage was to find per-pixel coefficients using the image acquisition model in \cref{sec:background:imageAcquasition}. 
The last stage was to use adjunct pixel dependencies as a constraint on the degradation model.

The degradation model required frames of objects with known temperature by a \taucamera\ in different ambient temperatures. To collect this data, a \taucamera\ was placed inside an environmental chamber in front of a scientific-grade blackbody (\blackbody). 
The blackbody and environmental chamber were cycled to different pairs of $(\tamb,\tobj)$, and frames were acquired at the different permutations.
\cref{fig:nonuniformity} is an example from the collected data.

The \taucamera\ was modeled by the image acquisition model in \cref{eq:acquisition:frame}. 
The calibration was done according to Nugent et al.~\cite{Nugent2013}, by using a third-degree polynomial to approximate the coefficients $g,d$.
For each pixel in the sensor, \cref{eq:acquisition:frame} can be formulated as:
\begin{equation}\label{eq:methods:coefficients}
    I_p(\tobj,\tamb)  = \sum^3_{i=0}\left(g_{i,p}\cdot\tamb^i\cdot{\tobj}_p^4  + d_{i,p}\cdot\tamb^i\right)
\end{equation} for $g_{i,p},d_{i,p}$ the i'th gain and offset coefficients at pixel $p$, respectively.
\cref{eq:methods:coefficients} can be rewritten as matrix multiplication:
\begin{equation}\label{eq:methods:coefMatMul}
    \begin{split}
        &\begin{matrix}
            T^n_p =& [{\tobj^4}_n&\hdots&{\tobj^4}_n{\tamb^3}_n&1&\hdots&{\tamb^3}_n]\\
            C_p   =& [g_{0,p}&\hdots&g_{3,p}&d_{0,p}&\hdots&d_{3,p}] ^T
        \end{matrix}\\
        &I_{N,p} \equiv  T_{N,p}\cdot C_p
    \end{split}
\end{equation} for $T^n_p$ that contains the appropriate temperatures of the n'th sample of a permutation, and $T_{N,p}$ a matrix with all the temperatures corresponding to all the samples of the permutation as rows, and $I_{N,p}$ is a matrix with all the acquired samples as rows.
\cref{eq:methods:coefMatMul} is solved using least-squares to find the coefficients:
\begin{equation}\label{eq:methods:coefLS}
    C_p = T_{N,p}^\dagger\cdot I_{N,p}
\end{equation} for $T_{N,p}^\dagger$ the Moore-Penrose pseudo-inverse.

Stacking all the 2D coefficient maps $C_p$ into a 3D tensor $\mat{C}$, with $\mat{C}[0]$ being the 2D map of coefficient $g_0$ etc.

The degradation model described in \cref{eq:methods:coefLS} is per-pixel, thus unique to each camera. Meaning that nonuniformity will also be modeled by the coefficients (e.g., dead pixels, fixed-pattern noise). This realization limits the usability of the degradation model only for the specific camera that collected the data.

To enable the degradation model to generalize for different cameras, the final stage in the degradation model exploits the circular symmetry of the nonuniformity and uses the dependency between neighboring pixels to enable the degradation model to generalize for other cameras.

Nonuniformity has a circular symmetry around the middle of the frame~\cite{IrFundamentals}. 
This is due to the ambient temperature of the camera, generating radiation from the chassis and lens, which is also reflected onto the sensor. 
Rays of thermal radiation from the body of the camera travels to the sensor and affect each pixel differently. The superposition of these rays on each pixel creates the circular symmetry of the nonuniformity.
An example of the circular symmetry can be seen in \cref{fig:nonuniformity}. 

The spatial dependency was modeled as a radial map around the middle of the frame. 
The radial map was constructed from two mesh-grids $\mat{H},\mat{W}$ with dimensions the same as the frames. Each row of $\mat{H}$ and each line in $\mat{W}$ runs from $-0.5$ to $0.5$, such that $\mat{H}=\mat{W}^T$. The radial map is defined as:
\begin{equation}
    \begin{split}
        \mat{R} &= \sqrt{\mat{H}^2+\mat{W}^2},\quad\quad\mat{H},\mat{W},\mat{R}\in\mathcal{R}^{h,w}\\
        \mat{R} &= \sqrt{\begin{bmatrix} 
                            -0.5&\ldots&-0.5 \\
                            \vdots & \ddots & \vdots \\
                            0.5&\ldots&0.5 
                            \end{bmatrix}^2+\begin{bmatrix} 
                            -0.5&\ldots&0.5 \\
                            \vdots & \ddots & \vdots \\
                            -0.5&\ldots&0.5 
                            \end{bmatrix}^2}
    \end{split}
\end{equation} for $h,w$ the dimensions of the frames. The power of the matrix is performed element-wise.

The coefficient maps are modeled as:
\begin{equation}\label{eq:methods:approxCoefR}
    \Hat{\mat{C}}[i] = \sum_{j=0}^M{m_i\cdot\mat{R}^j},\quad\quad m_i\in\mathcal{R},\ \mat{C},\mat{R}\in\mathcal{R}^{h,w}
\end{equation} for $m_i$ the spatial coefficient, and $M$ the number of spatial coefficients.
Least-squares is solved to find the spatial coefficients.

Estimating a frame from a given temperature map is performed by:
\begin{equation}\label{eq:methods:estimateFrame}
    \Hat{I}(\tobj,\tamb)=T(\tobj,\tamb)\cdot\Hat{C}
\end{equation} for $T(\tobj,\tamb)$ the temperatures vector in \cref{eq:methods:coefMatMul}.

The final degradation model was noiseless and only contained low frequencies. Random fixed pattern noise and Gaussian noise were added to the model during training. This enabled the network to converge to a general solution, applicable on different cameras with various degradation profiles.
