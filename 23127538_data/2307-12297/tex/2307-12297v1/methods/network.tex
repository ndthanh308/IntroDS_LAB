% Figure environment removed
% Figure environment removed
\noindent In \cref{eq:multiframe:setOfFrames} we show that different views of the same object have usable redundant information. 
To exploit the redundancy, these different perspectives require accurately mapping the frames to $\mathcal{I}$ the pivot frame.

Na\"ively, a temperature map $\Hat{X}$ can be estimated from \cref{eq:multiframe:setOfFrames} by:
\begin{equation}\label{eq:methods:naiveSolution}
    \begin{split}
        \Hat{X}_{naive}^{u,v} &= \frac{1}{\nFrames}\sum_{i=1}^\nFrames\left[\frac{1}{g^{u-x_i,v-y_i}}\Tilde{I}^{u,v}_i - \frac{d^{u-x_i,v-y_i}}{g^{u-x_i,v-y_i}}\right]\longrightarrow\\
        \Hat{X}_{naive}^{u,v} &= \frac{1}{\nFrames}\sum_{i=1}^\nFrames\left[G^{u-x_i,v-y_i}\Tilde{I}^{u,v}_i + D^{u-x_i,v-y_i}\right]
    \end{split}
\end{equation} for 2D coefficient maps $G$ and $D$.

The na\"ive approach requires exact registration between frames.
The information must be located on the exact same coordinates across all frames.
Inaccurate registration leads to artifacts or ghosting, as well as inexact temperature estimation.
Even with a robust registration framework there is always some degree of misalignment between frames, so the na\"ive approach is unsuitable for practical use.

The method for temperature estimation proposed in this work is robust to misalignment between frames. 
The frames are registered towards $\mathcal{I}$ using any off-the-shelf registration method, then fed into a neural network that predicts a kernel for each pixel in every frame of the burst.
The kernels are then applied on overlapping patches around each pixel by an inner product between the patch and kernel.
Our method is based on kernel prediction networks (KPN) proposed by De~Brabandere et al.~\cite{DeBrabandere16}.
\cref{fig:methods:kernels} shows kernels predicted by the network. The kernels compensate for misalignment between frames by spatially shifting their center to compensate for shifts.

The architecture of the temperature estimation network is based on UNET~\cite{unet}, with the kernel prediction block attached to the rear end of the decoder. 
The kernel prediction block is composed of three $1\times 1$ convolution layers with activations, and is described in \cref{table:kpnBlock} at the supplementary material. 
The entire network architecture is detailed in the supplementary material.

Although the KPN corrects nonuniformity, its temperature estimation is inaccurate.
To improve the temperature estimation to match radiometric cameras, we used the ambient temperature as prior information to calibrate the output of the network.
The offset between the gray level frames and the temperatures was modeled as a polynomial of the mean of the gray level frames and the ambient temperature:
\begin{equation}\label{eq:methods:temperature_encoding}
    \Tilde{d}\left(\Tilde{I},\tamb\right) = \frac{1}{N}\sum^N_{n=1}\left[\sum_{i,j=0}^\nu\delta_{i,j}\cdot \text{Mean}\left({\Tilde{I}_n}\right)^i \cdot \tamb^j\right]
\end{equation} for $\Tilde{d}_n$ the offset for frame $n$, $\text{Mean}\left({\Tilde{I}_n}\right)$ the spatial mean of the grey-level $n$'th frame, $\tamb$ the ambient temperature, $\delta_{i,j}$ the coefficients of the polynomial, and $\nu$ the degree of the polynomial.

The offset block was implemented by a fully connected layer that was jointly trained with the network.
We found that a polynomial of degree $\nu=4$ offers sufficient improvement in the accuracy of the temperature estimation, and that training the offset block separately from the network does not offer significant improvement.
\cref{fig:methods:temperature_encoding} shows the results of the offset block. The error between the temperature estimation of the offset block and the GT temperature is shown. The error is sub-degree Celsius, and the offset is accurate enough to calibrate the output of the network.

% Figure environment removed

The following equation describes the temperature estimation by applying KPN to the image acquisition model. 
To combine the information from multiple frames, the gain term in \cref{eq:multiframe:setOfFrames} is generalized as KPN, and the information from all frames are used. 
The kernels applied to each pixel handles the nonuniformity and noise, while the offset term in \cref{eq:methods:temperature_encoding} handles the thermal calibration:
\begin{equation}\label{eq:methods:KPN}
    \Hat{X}^p = \sum_{n=1}^\nFrames\left<\mathcal{K}^p_n,S^p\left(\Tilde{I}^p_n\right)\right> + \Tilde{d}\left(\Tilde{I},\tamb\right)
\end{equation} for $\nFrames$ the number of frames in a burst, $\mathcal{K}$ the kernel of size $K\times K$, and $S(\cdot)$ a function that samples a $K\times K$ patch around a pixel $p$ in the support of the frames.

A scheme of the model is shown in \cref{fig:methods:network}. The registered burst of frames is fed into the network, which outputs a kernel for each pixel in each frame. 
These kernels serve as the \textit{gain} in \cref{eq:methods:KPN}. 
The registered frames are also fed to the offset block along with the ambient temperature, which outputs the \textit{offset} term in \cref{eq:methods:KPN}.
The gain is applied to the frames and the results are depth-wise summed. 
The scene temperature estimation is obtained by adding the offset term to the result of the depth-wise summation.