% Figure environment removed
\noindent As stated in \cref{sec:intro}, the frames of the \ir camera suffer from spatially variant nonuniformity. The nonuniformity can be corrected for a single frame, or by combining information from multiple frames (known as scene-based).

\subsubsection{Single Frame}\label{sec:prior:nuc:singleFrame}
A given image contains information that can be exploited for different tasks, such as low frequencies~\cite{Oz2020}, recurring patches in the image~\cite{Shocher2017} or the statistical distribution of patches in the image~\cite{Shaham2019}.
Some works used a single image to correct the nonuniformity.

Scribner et al.~\cite{Scribner91} used a neural network (NN) to find the offset and gain by alternating optimization and gradient descent.
Tendero and Gilles~\cite{Tendero12} used histogram equalization across the columns in a frame, and then applied a discrete cosine transform to denoise the frame.
Cao and Tisse~\cite{Cao2014} relied on spatial dependence between adjunct pixels to estimate both the ambient temperature and the correction.
Zhao et al.~\cite{Zhao13} solved an optimization problem, with a constraint on the directional gradients of each frame.

Recent work has applied deep learning (DL) methods for single-image NUC\@.
Jian et al.~\cite{Jian2018} learned the nonuniformity pattern from the filtered high frequencies of the frames.
He et al.~\cite{He2018} trained a convolutional neural network (CNN) that outputs a corrected image end to end (E2E).
Chang et al.~\cite{ChangDeepLearning2019} constructed a multiscale network to reconstruct a corrected frame.
Saragadam et al.~\cite{Saragadam2021} solved an optimization problem with a NN as the prior, and a physical model as the constraint.
Oz et al.~\cite{Oz2022} modeled the nonuniformity and trained a network based on the physics of the acquisition model.

Single-image methods require only a single frame so they are easier to apply, but their performance is degraded compared to scene-based methods.

\subsubsection{Scene-Based}
Scene-based studies rely on the assumption that the change in ambient temperature is slower than the frame rate, and therefore the gain and offset are constant between consecutive frames.

Harris and Chiang~\cite{Harris99} calculated shift and normalization terms per pixel and updated these terms recursively when new frames arrived.
Hardie et al.~\cite{Hardie00} registered the frames and then averaged the results per pixel.
Vera and Torres~\cite{Vera05} improved the NN suggested by Scribner et al.~\cite{Scribner91} with an adaptive learning rate and a different loss function that accounts for multiframe information.
Averbuch et al.~\cite{Averbuch2007} reformulated the NUC problem to a Kalman filter.
Zuo et al.~\cite{Zuo11} estimated per-pixel \textit{irradiance} between two frames.
Papini et al.~\cite{Papini2018} approximated the gain and offset from multiple pairs of blurred and sharp images.
The common characteristic of these studies is that an update step must be performed when new frames arrive, before the correction step. The combined update and correction steps are computationally intensive and pose a constraint on the run time of the system.