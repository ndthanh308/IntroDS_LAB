\noindent The raw output of the \ir camera is dependent on the object temperature, and the output values themselves are given in gray levels.
For example, the dynamic range of the gray level in the low-cost \ir \taucamera\ is $14_{bits}$. 
The classical approach is to calibrate the camera for different ambient temperatures~\cite{Schulz1995}. 

A large dataset of object-ambient temperature pairs must be collected for calibration.
The gain and offset are calculated from the per-pixel data to determine the spatially variant nonuniformity. Thus, the calibration process usually requires considerable time and resources.

Schulz and Caldwell~\cite{Schulz1995} used a single-point correction, i.e., a single ambient temperature was used, a constant gain was assumed, and only the offset was found. 
Riou et al.~\cite{Riou2004} suggested a two-point correction that requires two ambient temperatures, but solved for both gain and offset; this correction is widely used across industrial \ir cameras today.
Both methods use a linear regression to extract the gain and offset coefficients.
Nugent et al.~\cite{Nugent2013} modeled the gain and offset as a polynomial in the temperature of the object and used least-squares to extract the coefficients.
Contemporary work adds prior knowledge to the calibration process. 
Liang et al.~\cite{Liang2017} found the gain and offset for a given temperature and interpolated the results for other ambient temperatures. Chang and Li~\cite{Chang2019} incorporated the integration time of each frame as prior knowledge to the calibration.

The calibration data must be collected for each camera separately, because each camera is slightly different due to the manufacturing process. This requires scientific-grade equipment, making the calibration process infeasible for most users.
