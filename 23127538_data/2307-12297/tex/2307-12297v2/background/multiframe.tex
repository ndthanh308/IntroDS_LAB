\noindent Consecutive frames over a brief period of time have overlap between them [an example of a real unmanned aerial vehicle (UAV) pattern with overlapping frames can be seen in \cref{sec:results:realdata}]. These consecutive frames are called a burst. The overlap between frames implies that the same object appears in multiple frames. 
As seen in \cref{eq:acquisition:affine}, the gain and offset are dependent on the pixel location on the sensor, thus different views of the same object can be exploited as redundant information. 
The redundant information between frames is demonstrated in \cref{fig:approach:redundentNonUniformity}.
To exploit it, first an object must have the same coordinates across all frames. To achieve coordinate alignment, registration is performed.

Image registration is the process of aligning two or more images of the same scene taken from different viewpoints or at different times~\cite{computationalGeometry}. Transforming a source frame toward the coordinate system of another destination frame is called a projective transformation, or a homography~\cite[Ch.~0]{HartleyRichard2004MVGi}.
Homography transformation preserves co-linearity between the frames.
Moreover, a homography is invertible and linear by definition~\cite[Def.~2.9]{HartleyRichard2004MVGi}. In layman's terms, the homography preserves the shapes and relations between objects. 

After applying the homography on the source frame, an object should have the same coordinates in both source and destination frames. The transformed source frame is called a warped frame. Expanding to $N$ frames, there exists a set of projective transformations $m_1,\ldots,m_N$ toward a common plane such that the overlap between the frames is maximal~\cite[Ch.~4]{HartleyRichard2004MVGi}. Objects that appear in the overlapping area will have the same coordinates in every warped frame. For our practical use, we choose a pivot frame for each burst of frames and annotate the pivot frame as $\mathcal{I}$.

An underlying assumption throughout this work is that the gain and offset in \cref{eq:acquisition:affine:pixel} are constant for a series of frames taken over a short duration of time (a second). This assumption holds because the ambient temperature of the camera changes at a much slower rate (several minutes).

Let $X$ be the fourth power of an accurate 2D temperature map, and $I_1,\ldots,I_N$ be a set of $N$ frames of $X$ captured by the \ir camera. $I_i$ is in gray levels.
$I_i^{x_i,y_i}$ is the value of the pixel in the $[x_i,y_i]$ location of $I_i$. 
$[u,v]$ are the coordinates of the pivot frame $\mathcal{I}$. 
The frames in the burst can be formulated as:
\begin{equation}\label{eq:multiframe:setOfFrames}
    \begin{matrix}
        I_1^{x_1,y_1}=g^{x_1,y_1}(\tamb)\cdot m_1^{-1}\left(X^{u,v}\right)+d^{x_1,y_1}(\tamb)\\
        \vdots\\
        I_N^{x_N,y_N}=g^{x_N,y_N}(\tamb)\cdot m_N^{-1}\left(X^{u,v}\right)+d^{x_N,y_N}(\tamb)
    \end{matrix}
\end{equation} where $m_1,\ldots,m_N$ are the set of homographies that transforms each frame into $\mathcal{I}$. The zero-mean noise $\mathcal{N}$ was omitted for brevity.

Equation~\ref{eq:multiframe:setOfFrames} formulates the acquisition process of a frame as projecting the temperature map $X$ using the inverse of the homography $m_i$, and then sampling the projected $X$ by applying the gain $g$, offset $d$ and noise $\mathcal{N}$. 
Notice that an object will be sampled at different coordinates for each frame, and since the gain and offset are spatially variant, the object will have a different gain and offset for each frame.
The result in \cref{eq:multiframe:setOfFrames} means that an object appearing in pixel $[u,v]$ of the temperature map $X$ will have multiple representation with different values of $g,d$ and $\mathcal{N}$, enabling the use of redundant information between the frames.
Redundant information between frames has been used for many image-restoration tasks, such as super-resolution~\cite{multi_sr_classic, multi_sr_classic2}, denoising~\cite{multi_denoise_classic}, and deblurring~\cite{multi_deblur_classic}. 
Many recent studies in the area have used DL for either alignment~\cite{Detone16} or fusion of frames~\cite{multi_denoise_dl}, or both~\cite{multi_sr_dl1, multi_sr_dl2, multi_sr_dl3}.