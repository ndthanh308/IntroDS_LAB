\noindent The loss is comprised of a fidelity term, a gradient smoothness term, and a structural term.

The structural term $\mathcal{L_{SSIM}}$ maximizes the commonly-used structural similarity metric (SSIM). SSIM loss improves results in image-restoration tasks~\cite{ssimLoss2017}.
The fidelity and gradient terms are similar to Mildenhall et al.~\cite{mildenhall2018kpn}, except that the $L_1$ loss is used instead of $L_2$, because $L_1$ is more robust to outliers~\cite{anwar2020}. The loss function is formulated as:
\begin{equation}\label{eq:methods:loss}
    \begin{split}
        \mathcal{L} = 
        &\left|\left| M(\Hat{X})-M(X) \right|\right|_1+\\
        &\lambda_1\left|\left| M(\nabla\Hat{X})-M(\nabla X) \right|\right|_1+\\
        &\lambda_2\cdot\mathcal{L_{SSIM}}(M(\Hat{X}),M(X))
    \end{split}
\end{equation} where $\Hat{X}$ is the temperature estimated by the network, $X$ is the GT temperature, $M$ is a mask of valid pixels in the registration process, $\lambda_1, \lambda_2$ are hyperparameters to balance to losses, and $\nabla$ is the magnitude of the Sobel operators. The mask is produced by the registration algorithm.
The final values of the hyperparameters were set to $\lambda_1=0.1$ and $\lambda_2=0.01$.