\noindent The network was written in Python~3.10~\cite{python} using Pytorch~1.13~\cite{pytorch}, and was trained on a single Nvidia Titan A100. 
The seed was set to $42$, and the CUDNN backend was set to deterministic mode.
The network was trained using the ADAM optimizer \cite{adamOpt2015} with a learning rate of $10^{-4}$. The learning rate was halved on a validation loss plateau of more than 3 epochs. The network was run for 60 epochs with batches of 16, meaning that each epoch was roughly 800 iterations. Early stopping was applied for a validation loss plateau of 8 epochs. 
The weights were initialized using the orthogonal scheme \cite{orthoInit2014} with a scaling of $10^{-1}$.
The hyperparameter search was run twice with different seeds (42 and 24), and the best results were chosen.

Multiframes were simulated by randomly sampling homographies for each frame in the dataset, creating different views of the same frame.
The inverse homographies were used to register all of the views toward the original frame, which was set as the pivot frame $\mathcal{I}$. 
The sampled homographies either created a random walk from one side of the temperature map to the other, or a hover above a random point in the frame. 
The overlaps between the different views were randomly set between $60\%$ and $80\%$, similar to a UAV flight scenario, as seen in \cref{sec:results:realdata}.
Homography and frame warping was implemented with the package Kornia~v0.67.

Imperfect registration was simulated by randomly adding perturbations to the inverse homographies: random translation of up to $\pm2$ pixels and noise from the distribution $\mathcal{N}(0, 5\cdot10^-5)$ to the perspective elements of the homography (commonly known as $h_{31}, h_{32}$).
Random horizontal and vertical flips, and $90^\circ$ rotations were applied to the frames before the homography sampling.

The gray-level frames were cropped to $128\times 128$ patches before entering the network. For validation, a constant cropping was applied around the middle of the frame, and no other augmentations were applied.

Random Gaussian noise with $\sigma^2=5$ gray levels and FPN were generated for each frame (\cref{sec:methods:data}). FPN was generated as:
\begin{equation}\label{eq:methods:fpn}
    \begin{bmatrix}
        1 \\ \vdots  \\ 1
    \end{bmatrix}_{h\times1}\cdot
    \begin{bmatrix}
        U[u_{\min}, u_{\max}] \\ \vdots  \\ U[u_{\min}, u_{\max}]
    \end{bmatrix}^T_{1\times w}
\end{equation} where $U$ is uniform distribution. $u_{\min}, u_{\max}$ were chosen as $u_{\min}=0.9, u_{\max}=1.01$. 
The Gaussian noise and FPN were only generated once for each frame and used throughout the entire validation process for reproducibility of results between experiments.

Normalization to range [0,1] was applied to both the temperature map and the gray-level frame.
Throughout the training and validation sets, the maximal and minimal values of the temperature maps and the maximal and minimal values of the gray-level frames were obtained.
The normalization was applied on the temperature maps as:
\begin{equation}\label{eq:methods:norm_t}
    \Bar{X} = \frac{X - X_\text{min}}{X_\text{max}-X_\text{min}}
\end{equation}
where $\Bar{X}$ is the normalized input and $X_\text{min}, X_\text{max}$ are the minimal and maximal temperatures, respectively, over all datasets.
Normalization for the gray-level frames was applied as:
\begin{equation}\label{eq:methods:norm_frame}
    \Bar{I}(\tamb) = \frac{I(\tamb) - I_\text{min}}{I_\text{max}-I_\text{min}}
\end{equation}
where $\Bar{I}$ is the normalized gray-level frame and $I_\text{min},I_\text{max}$ are the minimal and maximal gray levels, respectively, over all datasets.

The following pipeline summarizes the creation of samples for the network.
First, an accurate temperature map is sampled from the dataset. $\nFrames$ homographies are randomly sampled and applied to the temperature map to create an overlapping burst of frames.
The model described in \cref{sec:methods:synthData} is applied to each frame in the burst to turn it into a gray-level frame \cref{eq:methods:estimateFrame}.
The same FPN is applied to all frames in the burst \cref{eq:methods:fpn}, and random noise is applied to each frame in the burst separately.
Finally, normalization is applied to the ambient temperature \cref{eq:methods:norm_t} and overlapping gray-level frames \cref{eq:methods:norm_frame}, and both are passed to the network.