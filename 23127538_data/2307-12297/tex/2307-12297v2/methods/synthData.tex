\noindent The network was trained with synthetic data in a supervised manner.
The inputs to the network were created from accurate 2D temperature maps collected using a scientific-grade \ir camera (\scientificCamera).
A degradation model of a low-cost \ir camera (\taucamera) was applied to the temperature maps, transforming them to gray-level frames. As a result, the network was trained on transforming gray-level frames to accurate temperature maps.

The goal of the degradation model was to faithfully transform temperature maps into gray-level maps, allowing the supervised training process of the network. 
The modeling process had three stages:
1) collecting data with the \ir camera in a controlled environment;
2) finding per-pixel coefficients using the image-acquisition model in \cref{sec:background:imageAcquasition};
3) using adjunct pixel dependencies as a constraint on the degradation model.

The degradation model required frames of objects with known temperature taken by the \taucamera\ at different ambient temperatures. 
To collect these data, the \taucamera\ was placed inside an environmental chamber in front of a scientific-grade blackbody (\blackbody). 
The blackbody and environmental chamber were cycled to different pairs of $(\tamb,\tobj)$, and frames were acquired for the different permutations.
\cref{fig:nonuniformity} provides an example of the collected data.

The \taucamera\ was modeled by the image-acquisition model in \cref{eq:acquisition:frame}. 
The calibration was done according to Nugent et al.~\cite{Nugent2013}, using a third-degree polynomial to approximate the coefficients $g,d$.
For each pixel in the sensor, \cref{eq:acquisition:frame} can be formulated as:
\begin{equation}\label{eq:methods:coefficients}
    I_p(\tobj,\tamb)  = \sum^3_{i=0}\left(g_{i,p}\cdot\tamb^i\cdot{\tobj}_p^4  + d_{i,p}\cdot\tamb^i\right)
\end{equation} where $g_{i,p},d_{i,p}$ are the i-th gain and offset coefficients at pixel $p$, respectively.
Equation~\ref{eq:methods:coefficients} can be rewritten as a matrix multiplication:
\begin{equation}\label{eq:methods:coefMatMul}
    \begin{split}
        &\begin{matrix}
            T^n_p =& [{\tobj^4}_n&\hdots&{\tobj^4}_n{\tamb^3}_n&1&\hdots&{\tamb^3}_n]\\
            C_p   =& [g_{0,p}&\hdots&g_{3,p}&d_{0,p}&\hdots&d_{3,p}] ^T
        \end{matrix}\\
        &I_{N,p} \equiv  T_{N,p}\cdot C_p
    \end{split}
\end{equation} where $T^n_p$ contains the appropriate temperatures of the n-th sample of a permutation, $T_{N,p}$ is a matrix with all of the temperatures corresponding to all of the samples of the permutation as rows, and $I_{N,p}$ is a matrix with all of the acquired samples as rows.
The coefficients $C_p$ in \cref{eq:methods:coefMatMul} are found by solving the least-squares problem:
\begin{equation}\label{eq:methods:coefLS}
    C_p = T_{N,p}^\dagger\cdot I_{N,p}
\end{equation} where $T_{N,p}^\dagger$ is the Moore-Penrose pseudo inverse.

Finally, we stack all of the 2D coefficient maps $C_p$ into a 3D tensor $\mat{C}$, with $\mat{C}[0]$ being the 2D map of coefficient $g_0$ etc.

The degradation model described in \cref{eq:methods:coefLS} is per pixel, and therefore unique to each camera. 
This means that nonuniformity will also be modeled by the coefficients (e.g., dead pixels, FPN), limiting the usability of the degradation model to only the specific camera that collected the data.
To enable generalization of the degradation model for different cameras, the final stage in the model exploits the circular symmetry of the nonuniformity and uses the dependency between neighboring pixels.

Nonuniformity has a circular symmetry around the middle of the frame~\cite{IrFundamentals}. 
This is due to the ambient temperature of the camera, generating radiation from the chassis and lens, which is also reflected onto the sensor. 
Rays of thermal radiation from the body of the camera travel to the sensor and affect each pixel differently. The superposition of these rays on each pixel creates the circular symmetry of the nonuniformity.
An example of the circular symmetry can be seen in \cref{fig:nonuniformity}. 

The spatial dependency was modeled as a radial map around the middle of the frame. 
The radial map was constructed from two mesh grids $\mat{H},\mat{W}$ with the same dimensions as the frames. Each row in $\mat{H}$ and each line in $\mat{W}$ runs from $-0.5$ to $0.5$, such that $\mat{H}=\mat{W}^T$. The radial map is defined as:
\begin{equation}
    \begin{split}
        \mat{R} &= \sqrt{\mat{H}^2+\mat{W}^2},\quad\quad\mat{H},\mat{W},\mat{R}\in\mathcal{R}^{h,w}\\
        \mat{R} &= \sqrt{\begin{bmatrix} 
                            -0.5&\ldots&-0.5 \\
                            \vdots & \ddots & \vdots \\
                            0.5&\ldots&0.5 
                            \end{bmatrix}^2+\begin{bmatrix} 
                            -0.5&\ldots&0.5 \\
                            \vdots & \ddots & \vdots \\
                            -0.5&\ldots&0.5 
                            \end{bmatrix}^2}
    \end{split}
\end{equation} where $h,w$ are the dimensions of the frames. The power of the matrix is performed element-wise.

The coefficient maps are modeled as:
\begin{equation}\label{eq:methods:approxCoefR}
    \Hat{\mat{C}}[i] = \sum_{j=0}^M{m_j\cdot\mat{R}^j},\quad\quad m_j\in\mathcal{R},\ \mat{C},\mat{R}\in\mathcal{R}^{h,w}
\end{equation} where $m_j$ is the spatial coefficient, and $M$ is the number of spatial coefficients.
Least-squares is solved to find the spatial coefficients.

A frame from a given temperature map is estimated by:
\begin{equation}\label{eq:methods:estimateFrame}
    \Hat{I}(\tobj,\tamb)=T(\tobj,\tamb)\cdot\Hat{C}
\end{equation} where $T(\tobj,\tamb)$ is the temperature vector in \cref{eq:methods:coefMatMul}.

The final degradation model was noiseless and only contained low frequencies. Random FPN and Gaussian noise were added to the model during training. This enabled the network to converge to a general solution that is applicable on different cameras with various degradation profiles.
