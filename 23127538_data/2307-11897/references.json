{
  "2202-09699": {
    "title": "Selective Credit Assignment",
    "authors": [
      "Veronica Chelu",
      "Diana Borsa",
      "Doina Precup",
      "Hado van Hasselt"
    ],
    "submission_date": "2022-02-20",
    "semantic_scholar_id": "4cbfea6f45ca3b5110d5b597d7dff73bb482d572"
  },
  "2111-13485": {
    "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition",
    "authors": [
      "Zhizhou Ren",
      "Ruihan Guo",
      "Yuanshuo Zhou",
      "Jian Peng"
    ],
    "submission_date": "2021-11-26",
    "semantic_scholar_id": "80110db20124242316a13795e964d09cd15a3802"
  },
  "2111-11010": {
    "title": "Density Ratio Estimation via Infinitesimal Classification",
    "authors": [
      "Kristy Choi",
      "Chenlin Meng",
      "Yang Song",
      "Stefano Ermon"
    ],
    "submission_date": "2021-11-22",
    "semantic_scholar_id": "b843a47eebfa6af9a8408d4d4e63f0db0f79e49f"
  },
  "2111-04850": {
    "title": "Dueling RL: Reinforcement Learning with Trajectory Preferences",
    "authors": [
      "Aldo Pacchiano",
      "Aadirupa Saha",
      "Jonathan Lee"
    ],
    "submission_date": "2021-11-08",
    "semantic_scholar_id": "3986ea25ab5a428f66c816e16164b519b9ec7231"
  },
  "2106-06508": {
    "title": "Preferential Temporal Difference Learning",
    "authors": [
      "N. Anand",
      "Doina Precup"
    ],
    "submission_date": "2021-06-11",
    "semantic_scholar_id": "1837ccd0dbb5bf5d485941e8cf9c130edc99276b"
  },
  "2106-04499": {
    "title": "Towards Practical Credit Assignment for Deep Reinforcement Learning",
    "authors": [
      "Vyacheslav Alipov",
      "Riley Simmons-Edler",
      "N.Yu. Putintsev",
      "Pavel Kalinin",
      "D. Vetrov"
    ],
    "submission_date": "2021-06-08",
    "semantic_scholar_id": "f6e3df686d5218cc2a182c3ab61b1800183b0ea4"
  },
  "2105-14363": {
    "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback",
    "authors": [
      "Niladri S. Chatterji",
      "Aldo Pacchiano",
      "P. Bartlett",
      "Michael I. Jordan"
    ],
    "submission_date": "2021-05-29",
    "semantic_scholar_id": "cca15babd21194df08267908713035c34a4441b8"
  },
  "2103-06224": {
    "title": "An Information-Theoretic Perspective on Credit Assignment in Reinforcement Learning",
    "authors": [
      "Dilip Arumugam",
      "Peter Henderson",
      "Pierre-Luc Bacon"
    ],
    "submission_date": "2021-03-10",
    "semantic_scholar_id": "36a607371e9ebb8d39e218f3711af7711db14c4f"
  },
  "2011-09464": {
    "title": "Counterfactual Credit Assignment in Model-Free Reinforcement Learning",
    "authors": [
      "Thomas Mesnard",
      "T. Weber",
      "Fabio Viola",
      "S. Thakoor",
      "Alaa Saade",
      "A. Harutyunyan",
      "Will Dabney",
      "T. Stepleton",
      "N. Heess",
      "A. Guez",
      "Marcus Hutter",
      "Lars Buesing",
      "R. Munos"
    ],
    "submission_date": "2020-11-18",
    "semantic_scholar_id": "57e3cbd9243ecd857344cdbf4ac7db362bba37d8"
  },
  "2010-12718": {
    "title": "Learning Guidance Rewards with Trajectory-space Smoothing",
    "authors": [
      "Tanmay Gangwani",
      "Yuanshuo Zhou",
      "Jian Peng"
    ],
    "submission_date": "2020-10-23",
    "semantic_scholar_id": "13e4716495c82e917a18f599648372c4dead28a8"
  },
  "2010-11652": {
    "title": "CoinDICE: Off-Policy Confidence Interval Estimation",
    "authors": [
      "Bo Dai",
      "Ofir Nachum",
      "Yinlam Chow",
      "Lihong Li",
      "Csaba Szepesvari",
      "D. Schuurmans"
    ],
    "submission_date": "2020-10-22",
    "semantic_scholar_id": "43bf994c1dbe5f54996e06cac3cf95f107efaf19"
  },
  "2007-01839": {
    "title": "Expected Eligibility Traces",
    "authors": [
      "H. V. Hasselt",
      "Sephora Madjiheurem",
      "Matteo Hessel",
      "David Silver",
      "André Barreto",
      "Diana Borsa"
    ],
    "submission_date": "2020-07-03",
    "semantic_scholar_id": "acda55ebdf39c6634e89a9730ff7d963471f2b0a"
  },
  "2002-09072": {
    "title": "GenDICE: Generalized Offline Estimation of Stationary Values",
    "authors": [
      "Ruiyi Zhang",
      "Bo Dai",
      "Lihong Li",
      "D. Schuurmans"
    ],
    "submission_date": "2020-02-21",
    "semantic_scholar_id": "2b0e79ed1340a79344e37b6f57191b76d810962f"
  },
  "2001-11113": {
    "title": "GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values",
    "authors": [
      "Shangtong Zhang",
      "Bo Liu",
      "S. Whiteson"
    ],
    "submission_date": "2020-01-29",
    "semantic_scholar_id": "568c6c8ca820a161c1097fe3bcc947f436075f57"
  },
  "1912-02503": {
    "title": "Hindsight Credit Assignment",
    "authors": [
      "A. Harutyunyan",
      "Will Dabney",
      "Thomas Mesnard",
      "M. G. Azar",
      "Bilal Piot",
      "N. Heess",
      "H. V. Hasselt",
      "Greg Wayne",
      "Satinder Singh",
      "Doina Precup",
      "R. Munos"
    ],
    "submission_date": "2019-12-05",
    "semantic_scholar_id": "867cc74781225da4e08a77fc35037ba77911e455"
  },
  "1910-12809": {
    "title": "Minimax Weight and Q-Function Learning for Off-Policy Evaluation",
    "authors": [
      "Masatoshi Uehara",
      "Jiawei Huang",
      "Nan Jiang"
    ],
    "submission_date": "2019-10-28",
    "semantic_scholar_id": "7b5773650b4e52568d4e9e4c6384e9034d40fd66"
  },
  "1910-06508": {
    "title": "Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling",
    "authors": [
      "Yao Liu",
      "Pierre-Luc Bacon",
      "E. Brunskill"
    ],
    "submission_date": "2019-10-15",
    "semantic_scholar_id": "8083cb2f55927837b268afd048a6ba053c1bc8db"
  },
  "1906-04733": {
    "title": "DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections",
    "authors": [
      "Ofir Nachum",
      "Yinlam Chow",
      "Bo Dai",
      "Lihong Li"
    ],
    "submission_date": "2019-06-01",
    "semantic_scholar_id": "875280d96b2f138902061ae6409249ee4ded0da3"
  },
  "1901-10995": {
    "title": "Go-Explore: a New Approach for Hard-Exploration Problems",
    "authors": [
      "Adrien Ecoffet",
      "Joost Huizinga",
      "J. Lehman",
      "Kenneth O. Stanley",
      "J. Clune"
    ],
    "submission_date": "2019-01-30",
    "semantic_scholar_id": "c520bf47db3360ae3a52219771390a354ed8a91f"
  },
  "1901-09455": {
    "title": "Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift",
    "authors": [
      "Carles Gelada",
      "Marc G. Bellemare"
    ],
    "submission_date": "2019-01-27",
    "semantic_scholar_id": "dc4ec37102afb166b96abc268ae3dc15e230d776"
  },
  "1810-12429": {
    "title": "Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation",
    "authors": [
      "Qiang Liu",
      "Lihong Li",
      "Ziyang Tang",
      "Dengyong Zhou"
    ],
    "submission_date": "2018-10-29",
    "semantic_scholar_id": "e81ea45d8bec329fdb11fd84990852f620895d6f"
  },
  "1810-06721": {
    "title": "Optimizing agent behavior over long time scales by transporting value",
    "authors": [
      "Chia-Chun Hung",
      "T. Lillicrap",
      "Josh Abramson",
      "Yan Wu",
      "Mehdi Mirza",
      "Federico Carnevale",
      "Arun Ahuja",
      "Greg Wayne"
    ],
    "submission_date": "2018-10-15",
    "semantic_scholar_id": "1456d9d2ee40b932e2e07762985a60f0bdff07f3"
  },
  "1811-06272": {
    "title": "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search",
    "authors": [
      "Lars Buesing",
      "T. Weber",
      "Yori Zwols",
      "S. Racanière",
      "A. Guez",
      "Jean-Baptiste Lespiau",
      "N. Heess"
    ],
    "submission_date": "2018-09-27",
    "semantic_scholar_id": "745a134eca192982e8e0c16d6f36cfe24f9bdd08"
  },
  "1806-07857": {
    "title": "RUDDER: Return Decomposition for Delayed Rewards",
    "authors": [
      "J. Arjona-Medina",
      "Michael Gillhofer",
      "Michael Widrich",
      "Thomas Unterthiner",
      "Sepp Hochreiter"
    ],
    "submission_date": "2018-06-20",
    "semantic_scholar_id": "bad355642cd299caca2328dae02563278ea74e8c"
  },
  "1801-01290": {
    "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
    "authors": [
      "Tuomas Haarnoja",
      "Aurick Zhou",
      "P. Abbeel",
      "S. Levine"
    ],
    "submission_date": "2018-01-04",
    "semantic_scholar_id": "811df72e210e20de99719539505da54762a11c6d"
  },
  "1707-06347": {
    "title": "Proximal Policy Optimization Algorithms",
    "authors": [
      "John Schulman",
      "Filip Wolski",
      "Prafulla Dhariwal",
      "Alec Radford",
      "Oleg Klimov"
    ],
    "submission_date": "2017-07-20",
    "semantic_scholar_id": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b"
  },
  "1707-06887": {
    "title": "A Distributional Perspective on Reinforcement Learning",
    "authors": [
      "Marc G. Bellemare",
      "Will Dabney",
      "R. Munos"
    ],
    "submission_date": "2017-07-17",
    "semantic_scholar_id": "c1f4ef741242d629d1f56e442a09a7ba29595a0e"
  },
  "1707-01495": {
    "title": "Hindsight Experience Replay",
    "authors": [
      "Marcin Andrychowicz",
      "Dwight Crow",
      "Alex Ray",
      "Jonas Schneider",
      "Rachel Fong",
      "Peter Welinder",
      "Bob McGrew",
      "Joshua Tobin",
      "P. Abbeel",
      "Wojciech Zaremba"
    ],
    "submission_date": "2017-07-05",
    "semantic_scholar_id": "429ed4c9845d0abd1f8204e1d7705919559bc2a2"
  },
  "1705-05363": {
    "title": "Curiosity-Driven Exploration by Self-Supervised Prediction",
    "authors": [
      "Deepak Pathak",
      "Pulkit Agrawal",
      "Alexei A. Efros",
      "Trevor Darrell"
    ],
    "submission_date": "2017-05-15",
    "semantic_scholar_id": "225ab689f41cef1dc18237ef5dab059a49950abf"
  },
  "1702-07121": {
    "title": "Consistent On-Line Off-Policy Evaluation",
    "authors": [
      "Assaf Hallak",
      "Shie Mannor"
    ],
    "submission_date": "2017-02-23",
    "semantic_scholar_id": "ba847beb3ed679ff56d0414c04748de88ed46af9"
  },
  "1611-04717": {
    "title": "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning",
    "authors": [
      "Haoran Tang",
      "Rein Houthooft",
      "Davis Foote",
      "Adam Stooke",
      "Xi Chen",
      "Yan Duan",
      "John Schulman",
      "F. Turck",
      "P. Abbeel"
    ],
    "submission_date": "2016-11-15",
    "semantic_scholar_id": "0fcb2034e31a2bc2f12a2b1363d0d77baf445fdf"
  },
  "1606-01540": {
    "title": "OpenAI Gym",
    "authors": [
      "Greg Brockman",
      "Vicki Cheung",
      "Ludwig Pettersson",
      "Jonas Schneider",
      "John Schulman",
      "Jie Tang",
      "Wojciech Zaremba"
    ],
    "submission_date": "2016-06-05",
    "semantic_scholar_id": "2b10281297ee001a9f3f4ea1aa9bea6b638c27df"
  },
  "1604-00923": {
    "title": "Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning",
    "authors": [
      "P. Thomas",
      "E. Brunskill"
    ],
    "submission_date": "2016-04-04",
    "semantic_scholar_id": "ec8a2f6cfe72309f5f1608d22ec28778d3ee976a"
  },
  "1602-01783": {
    "title": "Asynchronous Methods for Deep Reinforcement Learning",
    "authors": [
      "Volodymyr Mnih",
      "Adrià Puigdomènech Badia",
      "Mehdi Mirza",
      "Alex Graves",
      "T. Lillicrap",
      "Tim Harley",
      "David Silver",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2016-02-04",
    "semantic_scholar_id": "69e76e16740ed69f4dc55361a3d319ac2f1293dd"
  },
  "1511-03722": {
    "title": "Doubly Robust Off-policy Value Evaluation for Reinforcement Learning",
    "authors": [
      "Nan Jiang",
      "Lihong Li"
    ],
    "submission_date": "2015-11-11",
    "semantic_scholar_id": "2fdb536da39a014c598ea67b0db88431fcd852a8"
  },
  "1509-05172": {
    "title": "Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis",
    "authors": [
      "Assaf Hallak",
      "Aviv Tamar",
      "R. Munos",
      "Shie Mannor"
    ],
    "submission_date": "2015-09-17",
    "semantic_scholar_id": "83ff34eac4fc50cb92a34b5f2b10925aa22b3c12"
  },
  "1506-02438": {
    "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation",
    "authors": [
      "John Schulman",
      "Philipp Moritz",
      "S. Levine",
      "Michael I. Jordan",
      "P. Abbeel"
    ],
    "submission_date": "2015-06-08",
    "semantic_scholar_id": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8"
  },
  "1506-02582": {
    "title": "On Convergence of Emphatic Temporal-Difference Learning",
    "authors": [
      "Huizhen Yu"
    ],
    "submission_date": "2015-06-08",
    "semantic_scholar_id": "1baba004465b6721717de67af1b0bf375d24863a"
  },
  "1503-04269": {
    "title": "An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning",
    "authors": [
      "R. Sutton",
      "A. Mahmood",
      "Martha White"
    ],
    "submission_date": "2015-03-13",
    "semantic_scholar_id": "d6cc19f33b7714de62e45295c8be1bf1b0642557"
  },
  "1312-5602": {
    "title": "Playing Atari with Deep Reinforcement Learning",
    "authors": [
      "Volodymyr Mnih",
      "K. Kavukcuoglu",
      "David Silver",
      "Alex Graves",
      "Ioannis Antonoglou",
      "D. Wierstra",
      "Martin A. Riedmiller"
    ],
    "submission_date": "2013-12-19",
    "semantic_scholar_id": "2319a491378867c7049b3da055c5df60e1671158"
  }
}