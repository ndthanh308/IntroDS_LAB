{
  "title": "Using Implicit Behavior Cloning and Dynamic Movement Primitive to Facilitate Reinforcement Learning for Robot Motion Planning",
  "authors": [
    "Zengjie Zhang",
    "Jayden Hong",
    "Amir Soufi Enayati",
    "Homayoun Najjaran"
  ],
  "submission_date": "2023-07-29T19:46:09+00:00",
  "revised_dates": [
    "2024-08-18T19:55:39+00:00"
  ],
  "abstract": "Reinforcement learning (RL) for motion planning of multi-degree-of-freedom robots still suffers from low efficiency in terms of slow training speed and poor generalizability. In this paper, we propose a novel RL-based robot motion planning framework that uses implicit behavior cloning (IBC) and dynamic movement primitive (DMP) to improve the training speed and generalizability of an off-policy RL agent. IBC utilizes human demonstration data to leverage the training speed of RL, and DMP serves as a heuristic model that transfers motion planning into a simpler planning space. To support this, we also create a human demonstration dataset using a pick-and-place experiment that can be used for similar studies. Comparison studies in simulation reveal the advantage of the proposed method over the conventional RL agents with faster training speed and higher scores. A real-robot experiment indicates the applicability of the proposed method to a simple assembly task. Our work provides a novel perspective on using motion primitives and human demonstration to leverage the performance of RL for robot applications.",
  "categories": [
    "cs.RO",
    "cs.LG"
  ],
  "primary_category": "cs.RO",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16062",
  "pdf_url": "https://arxiv.org/pdf/2307.16062v2",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 63848131,
  "size_after_bytes": 321612
}