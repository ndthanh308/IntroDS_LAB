%%%% ijcai23.tex

\typeout{IJCAI--23 Instructions for Authors}

% These are the instructions for authors for IJCAI-23.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai23.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai23}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{booktabs}
\usepackage{epsfig}
\usepackage{tabu}
\usepackage{tabularray}
%\usepackage[noend]{algpseudocode}
%\usepackage{algorithmicx}
\usepackage[accsupp]{axessibility}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage[switch]{lineno}
\usepackage{bbding}
\usepackage{subfig}
\usepackage{sidecap}
\usepackage{cuted}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{bbm}
\usepackage{array}
\usepackage{booktabs}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}}
% Comment out this line in the camera-ready submission
\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.
% Please **do not** include Title and Author information
\pdfinfo{
/TemplateVersion (IJCAI.2023.0)
}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)

\begin{document}

\title{ReadMe for Reproducing the Benchmark Results}
\date{}
\maketitle

\section{How-to-use of the Provided Code}
To make a fair comparison, our work strictly follows the benchmark protocol stated in the strong baseline work~\cite{2021Rethinking}, by employing the released public code of this work for dataset partitioning, dataloader generation, backbones config setting and metric setup, etc. 

Thus, to efficiently implement the method and reproduce the benchmark results without further efforts and misunderstandings, we suggest readers to look through the public code of this adopted baseline work in Github at 
\begin{center}
\fbox
{\shortstack[c]{
https://github.com/valencebond/Rethinking\_of\_PAR}}
\end{center}
\noindent and implement our method directly onto this code by simply replacing serval .py files of model framework and training configs: 

\begin{itemize} 
\item Replacing the original 'train.py' file with ours.
\item Replacing the original 'batch\_engine.py' file with ours.
\item Replacing the original 'models/base\_block.py' file with ours.
\item Replacing the original 'configs$\backslash$pedes\_baseline' folder by ours.
\item Putting the 'convnext.py' file under the path 'models/backbone/' for testing on ConvNeXt-base.
\end{itemize}

\section{Prerequisites}
\subsection{Environment}
Please set up the environment as follows: Pytorch == 1.10.1+cu102, numpy == 1.19.5 and python == 3.6.9 64-bit. The experiments in main text are conducted on a single NVIDIA Tesla V100 32G. 

\subsection{Datasets}
Before running the codes, you need to download all datasets (PA100k, RAP and PETA) from their official releases, and struct the downloaded ones exactly as that is required in the public code of~\cite{2021Rethinking}. For the PETAzs and RAPzs datasets, this baseline work already provides generating files under the path of 'data'.

\section{Running}
To run the model training and testing is simple:
\begin{center}
\fbox
{\shortstack[c]{
CUDA\_VISIBLE\_DEVICES=0 python train.py \-\-cfg \\
./configs/pedes\_baseline/\$DATASET\_CONFIG\$}}
\end{center}

\noindent DATASET\_CONFIG can be 'pa100k.yaml', 'peta\_zs.yaml', 'peta.yaml', 'rap\_zs.yaml' or 'rapv1.yaml'. They are all provided in the supplementary material.





\bibliographystyle{named}
\bibliography{ijcai23}

\end{document}
