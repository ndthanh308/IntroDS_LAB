\section{Introduction}

Machine learning algorithms are widely used to make decisions that can directly affect people's lives in various domains, including banking \cite{FriedlerSVCHR19}, healthcare \cite{ChenPRJFG21}, education \cite{Mathioudakis0BC20}, and criminal justice \cite{BerkHJKR21}, to name a few.
However, a large body of work \cite{ChouldechovaR20, MehrabiMSLG21} has indicated that these algorithms, if left unchecked, often present discriminatory outcomes for particular demographic groups.
To address such concerns, recent studies have incorporated different notions of fairness into unsupervised learning problems \cite{Chierichetti0LV17, ChenFLM19, KleindessnerAM19, MahabadiV20}.
In particular, Chierichetti \emph{et al.} \cite{Chierichetti0LV17} pioneered \emph{fair clustering} for a set of points represented as vectors in Euclidean space and further characterized by a categorical sensitive attribute (e.g., \emph{gender} or \emph{race}) indicating membership in a demographic group (e.g., \emph{female} or \emph{Asian}).
In addition to minimizing the typical clustering objective, the problem also requires that the proportion of each demographic group within each cluster is roughly the same as its proportion in the dataset population (referred to as \emph{proportional fairness}).
Beyond clustering, however, fairness in the partitioning of graphs is relatively under-explored despite its broad applications to community detection \cite{Newman06, ChiangWD12, LierdeCC20} and computer vision \cite{ChewC15, ZhangFWWL0Y19}.

In this paper, we aim to fill this gap by defining a fair version of the normalized-cut graph partitioning problem \cite{ShiM00, YuS03}.
Informally, for a graph $G = (V, E)$, the original partitioning objective is to divide the set $V$ of nodes into $k$ disjoint clusters such that the fractions of inter-cluster edges are minimized while the fractions of intra-cluster edges are maximized.
Such an objective is measured by the normalized cut (Ncut) value.
In our fair variant, we further assume that each node belongs to one of $m$ sensitive groups and consider the notion of \emph{range-based proportional fairness} \cite{BeraCFN19} generalized from that in \cite{Chierichetti0LV17}.
Specifically, this requires that, in each of the $k$ clusters, the proportion of nodes of any group $c \in \{1, 2, \ldots, m\}$ is at least $\beta_c$ (lower bound) and at most $\alpha_c$ (upper bound) for two parameters $\beta_c, \alpha_c \in [0, 1]$.
Our overall objective, thus, is to produce a $k$-partition that minimizes the Ncut value while also satisfying the above fairness constraint.

To the best of our knowledge, the most relevant algorithms to our problem are those for spectral clustering with group fairness constraints \cite{KleindessnerSAM19,pmlr-v206-wang23h} due to the inherent connection between spectral clustering and normalized-cut graph partitioning.
But those algorithms suffer from two key limitations when applied to graph partitioning.
First, although they incorporate a special case of the range-based fairness constraint with $\alpha_c = \beta_c, \forall c \in \{1, 2, \ldots, m\}$ (i.e., the original \emph{proportional fairness} in \cite{Chierichetti0LV17}) into spectral node embedding, they still consider running standard $k$-means \cite{Lloyd82} on node vectors to obtain a $k$-partition. Consequently, they cannot guarantee how close the partitioning is to satisfying the (original or range-based) fairness constraint. Second, they do not provide any tunable trade-off between fairness and partition quality.

\smallskip\noindent\textbf{Our Contributions.}
In this paper, we propose a novel algorithmic framework for fair normalized-cut graph partitioning that addresses the above two limitations.
That is, we parameterize the desired level of range-based proportional fairness as a constraint to be satisfied and naturally trade off the Ncut value (i.e., \emph{quality}) and proportionality (i.e., \emph{fairness}) of the partitioning.
Similar to \cite{ShiM00, YuS03}, we transform the problem of minimizing the Ncut value of a graph into an equivalent trace minimization problem on its Laplacian matrix. 
Generally, our algorithm, which we refer to as FNM, comprises two phases.
In the first phase, we relax the original integer trace minimization problem to allow fractional memberships, add an augmented Lagrangian term \cite{Wright99} based on our fairness criteria to the objective function of the relaxed problem, and use the OptStiefelGBB method \cite{WenY13} to obtain a fairer embedding from which the partitioning found is closer to being fair.
Then, in the second phase, we apply a novel rounding scheme, adapted from Lloyd's $k$-means clustering algorithm \cite{Lloyd82}, to generate a fair partitioning from node vectors in the embedding space.
Specifically, we initialize the cluster centers, alternately assign vectors fairly to clusters, and update the centers for a fixed number of iterations or until the stopping condition is met.
Each assignment step first solves a linear program to produce $k$ nearly-fair clusters and then performs reassignments to construct strictly-fair clusters without significantly reducing partition quality.

Finally, we evaluate the performance of our FNM algorithm on nine benchmarking datasets ranging in size from 155 to 1.6M nodes along three metrics -- partition quality, fairness, and time efficiency, compared to three competitive baselines and ten variants for ablation study.
Our key findings are summarized below:
\emph{i}) FNM offers improved trade-offs between fairness and partition quality compared to the three baselines while scaling effectively to million-node-sized graphs;
\emph{ii}) our proposed fair embedding and rounding algorithms independently and jointly improve the quality of graph partitions with range-based proportional fairness constraints compared to general node embeddings and rounding schemes.
