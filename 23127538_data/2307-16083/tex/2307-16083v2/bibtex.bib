@book{jager2001short,
  doi = {10.24406/PUBLICA-FHG-291107},
  url = {https://publica.fraunhofer.de/handle/publica/291107},
  author = {Jaeger, H.},
  title = {Short term memory in echo state networks},
  publisher = {Fraunhofer-Gesellschaft},
  year = {2001}
}

% IBMQ
@misc{IBMQ_2022,
	title = {{IBM} {Quantum}, https://quantum-computing.ibm.com},
	year = {2022}
}

% IPC
@article{dambre_information_2012,
	title = {Information {Processing} {Capacity} of {Dynamical} {Systems}},
	volume = {2},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep00514},
	doi = {10.1038/srep00514},
	number = {1},
	urldate = {2020-04-16},
	journal = {Scientific Reports},
	author = {Dambre, Joni and Verstraeten, David and Schrauwen, Benjamin and Massar, Serge},
	month = dec,
	year = {2012},
	pages = {514}
}


@article{sheldon_computational_2022,
	title = {The {Computational} {Capacity} of {LRC}, {Memristive} and {Hybrid} {Reservoirs}},
	volume = {106},
	issn = {2470-0045, 2470-0053},
	url = {http://arxiv.org/abs/2009.00112},
	doi = {10.1103/PhysRevE.106.045310},
	abstract = {Reservoir computing is a machine learning paradigm that uses a high-dimensional dynamical system, or {\textbackslash}emph\{reservoir\}, to approximate and predict time series data. The scale, speed and power usage of reservoir computers could be enhanced by constructing reservoirs out of electronic circuits, and several experimental studies have demonstrated promise in this direction. However, designing quality reservoirs requires a precise understanding of how such circuits process and store information. We analyze the feasibility and optimal design of electronic reservoirs that include both linear elements (resistors, inductors, and capacitors) and nonlinear memory elements called memristors. We provide analytic results regarding the feasibility of these reservoirs, and give a systematic characterization of their computational properties by examining the types of input-output relationships that they can approximate. This allows us to design reservoirs with optimal properties. By introducing measures of the total linear and nonlinear computational capacities of the reservoir, we are able to design electronic circuits whose total computational capacity scales extensively with the system size. Our electronic reservoirs can match or exceed the performance of conventional "echo state network" reservoirs in a form that may be directly implemented in hardware.},
	number = {4},
	urldate = {2022-12-14},
	journal = {Physical Review E},
	author = {Sheldon, Forrest C. and Kolchinsky, Artemy and Caravelli, Francesco},
	month = oct,
	year = {2022},
	pages = {045310},
}


@article{wright_capacity_2019,
	title = {The {Capacity} of {Quantum} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1908.01364},
	abstract = {A key open question in quantum computation is what advantages quantum neural networks (QNNs) may have over classical neural networks (NNs), and in what situations these advantages may transpire. Here we address this question by studying the memory capacity \$C\$ of QNNs, which is a metric of the expressive power of a QNN that we have adapted from classical NN theory. We present a capacity inequality showing that the capacity of a QNN is bounded by the information \$W\$ that can be trained into its parameters: \$C {\textbackslash}leq W\$. One consequence of this bound is that QNNs that are parameterized classically do not show an advantage in capacity over classical NNs having an equal number of parameters. However, QNNs that are parametrized with quantum states could have exponentially larger capacities. We illustrate our theoretical results with numerical experiments by simulating a particular QNN based on a Gaussian Boson Sampler. We also study the influence of sampling due to wavefunction collapse during operation of the QNN, and provide an analytical expression connecting the capacity to the number of times the quantum system is measured.},
	urldate = {2021-09-15},
	journal = {arXiv:1908.01364 [quant-ph]},
	author = {Wright, Logan G. and McMahon, Peter L.},
	month = aug,
	year = {2019},
	keywords = {Physics - Optics, Quantum Physics}
}

% Classical statistical inference
@book{cox_principles_2006,
	title = {Principles of {Statistical} {Inference}},
	isbn = {978-0-521-86673-6},
	url = {https://www.cambridge.org/core/books/principles-of-statistical-inference/BCD3734047D403DF5352EA58F41D3181},
	urldate = {2023-04-13},
	publisher = {Cambridge University Press},
	author = {Cox, D. R.},
	year = {2006},
	doi = {10.1017/CBO9780511813559},
}

% SLMs, classical photonic ML
@article{zhu_arbitrary_2014,
	title = {Arbitrary manipulation of spatial amplitude and phase using phase-only spatial light modulators},
	volume = {4},
	copyright = {2014 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep07441},
	doi = {10.1038/srep07441},
	abstract = {Spatial structure of a light beam is an important degree of freedom to be extensively explored. By designing simple configurations with phase-only spatial light modulators (SLMs), we show the ability to arbitrarily manipulate the spatial full field information (i.e. amplitude and phase) of a light beam. Using this approach to facilitating arbitrary and independent control of spatial amplitude and phase, one can flexibly generate different special kinds of light beams for different specific applications. Multiple collinear orbital angular momentum (OAM) beams, Laguerre-Gaussian (LG) beams and Bessel beams, having both spatial amplitude and phase distributions, are successfully generated in the experiments. Some arbitrary beams with odd-shaped intensity are also generated in the experiments.},
	number = {1},
	urldate = {2023-06-12},
	journal = {Scientific Reports},
	author = {Zhu, Long and Wang, Jian},
	month = dec,
	year = {2014},
	keywords = {Applied optics, Optical techniques},
	pages = {7441}
}

% Photonic ELM
@article{pierangeli_photonic_2021,
	title = {Photonic extreme learning machine by free-space optical propagation},
	volume = {9},
	copyright = {© 2021 Chinese Laser Press},
	issn = {2327-9125},
	url = {https://opg.optica.org/prj/abstract.cfm?uri=prj-9-8-1446},
	doi = {10.1364/PRJ.423531},
	abstract = {Photonic brain-inspired platforms are emerging as novel analog computing devices, enabling fast and energy-efficient operations for machine learning. These artificial neural networks generally require tailored optical elements, such as integrated photonic circuits, engineered diffractive layers, nanophotonic materials, or time-delay schemes, which are challenging to train or stabilize. Here, we present a neuromorphic photonic scheme, i.e., the photonic extreme learning machine, which can be implemented simply by using an optical encoder and coherent wave propagation in free space. We realize the concept through spatial light modulation of a laser beam, with the far field acting as a feature mapping space. We experimentally demonstrate learning from data on various classification and regression tasks, achieving accuracies comparable with digital kernel machines and deep photonic networks. Our findings point out an optical machine learning device that is easy to train, energetically efficient, scalable, and fabrication-constraint free. The scheme can be generalized to a plethora of photonic systems, opening the route to real-time neuromorphic processing of optical data.},
	number = {8},
	urldate = {2023-06-12},
	journal = {Photonics Research},
	author = {Pierangeli, Davide and Marcucci, Giulia and Conti, Claudio},
	month = aug,
	year = {2021},
	keywords = {Neural networks, Optical components, Optical computing, Optical networks, Optical neural systems, Wave propagation},
	pages = {1446--1454}
}

% QRC with photonics, IPC and role of finite  measurements

@article{garcia-beni_scalable_2022,
	title = {Scalable photonic platform for real-time quantum reservoir computing},
	url = {https://journals.aps.org/prapplied/abstract/10.1103/PhysRevApplied.20.014051},
	publisher = {arXiv},
	author = {García-Beni, Jorge and Giorgi, Gian Luca and Soriano, Miguel C. and Zambrini, Roberta},
	month = jul,
	year = {2023},
	journal = {Physical Review Applied},
	volume = {20},
        pages = {014051}
}

@article{martinez-pena_information_2020,
	title = {Information processing capacity of spin-based quantum reservoir computing systems},
	issn = {1866-9964},
	url = {https://doi.org/10.1007/s12559-020-09772-y},
	doi = {10.1007/s12559-020-09772-y},
	abstract = {The dynamical behavior of complex quantum systems can be harnessed for information processing. With this aim, quantum reservoir computing (QRC) with Ising spin networks was recently introduced as a quantum version of classical reservoir computing. In turn, reservoir computing is a neuro-inspired machine learning technique that consists in exploiting dynamical systems to solve nonlinear and temporal tasks. We characterize the performance of the spin-based QRC model with the Information Processing Capacity (IPC), which allows to quantify the computational capabilities of a dynamical system beyond specific tasks. The influence on the IPC of the input injection frequency, time multiplexing, and different measured observables encompassing local spin measurements as well as correlations is addressed. We find conditions for an optimum input driving and provide different alternatives for the choice of the output variables used for the readout. This work establishes a clear picture of the computational capabilities of a quantum network of spins for reservoir computing. Our results pave the way to future research on QRC both from the theoretical and experimental points of view.},
	urldate = {2022-04-04},
	author = {Martínez-Peña, R. and Nokkala, J. and Giorgi, G. L. and Zambrini, R. and Soriano, M. C.},
	month = {oct},
	year = {2020},
	journal = {Cognitive Computation},
	volume = {},
	pages = {}
}

@article{hermans_memory_2010,
	title = {Memory in linear recurrent neural networks in continuous time},
	volume = {23},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608009002305},
	doi = {10.1016/j.neunet.2009.08.008},
	abstract = {Reservoir Computing is a novel technique which employs recurrent neural networks while circumventing difficult training algorithms. A very recent trend in Reservoir Computing is the use of real physical dynamical systems as implementation platforms, rather than the customary digital emulations. Physical systems operate in continuous time, creating a fundamental difference with the classic discrete time definitions of Reservoir Computing. The specific goal of this paper is to study the memory properties of such systems, where we will limit ourselves to linear dynamics. We develop an analytical model which allows the calculation of the memory function for continuous time linear dynamical systems, which can be considered as networks of linear leaky integrator neurons. We then use this model to research memory properties for different types of reservoir. We start with random connection matrices with a shifted eigenvalue spectrum, which perform very poorly. Next, we transform two specific reservoir types, which are known to give good performance in discrete time, to the continuous time domain. Reservoirs based on uniform spreading of connection matrix eigenvalues on the unit disk in discrete time give much better memory properties than reservoirs with random connection matrices, where reservoirs based on orthogonal connection matrices in discrete time are very robust against noise and their memory properties can be tuned. The overall results found in this work yield important insights into how to design networks for continuous time.},
	number = {3},
	journal = {Neural Networks},
	author = {Hermans, Michiel and Schrauwen, Benjamin},
	month = apr,
	year = {2010},
	keywords = {Recurrent neural networks, Continuous time, Linear dynamics, Memory function, Reservoir computing},
	pages = {341--355},
}

% expressibility

@article{Du2020,
  doi = {10.1103/physrevresearch.2.033125},
  url = {https://doi.org/10.1103/physrevresearch.2.033125},
  year = {2020},
  month = jul,
  publisher = {American Physical Society ({APS})},
  volume = {2},
  number = {3},
  author = {Yuxuan Du and Min-Hsiu Hsieh and Tongliang Liu and Dacheng Tao},
  title = {Expressive power of parametrized quantum circuits},
  journal = {Physical Review Research},
  pages = {033125}
}

@article{du_efficient_2022,
	title = {Efficient {Measure} for the {Expressivity} of {Variational} {Quantum} {Algorithms}},
	volume = {128},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.128.080506},
	doi = {10.1103/PhysRevLett.128.080506},
	abstract = {The superiority of variational quantum algorithms (VQAs) such as quantum neural networks (QNNs) and variational quantum eigensolvers (VQEs) heavily depends on the expressivity of the employed Ansätze. Namely, a simple Ansatz is insufficient to capture the optimal solution, while an intricate Ansatz leads to the hardness of trainability. Despite its fundamental importance, an effective strategy of measuring the expressivity of VQAs remains largely unknown. Here, we exploit an advanced tool in statistical learning theory, i.e., covering number, to study the expressivity of VQAs. Particularly, we first exhibit how the expressivity of VQAs with an arbitrary Ansätze is upper bounded by the number of quantum gates and the measurement observable. We next explore the expressivity of VQAs on near-term quantum chips, where the system noise is considered. We observe an exponential decay of the expressivity with increasing circuit depth. We also utilize the achieved expressivity to analyze the generalization of QNNs and the accuracy of VQE. We numerically verify our theory employing VQAs with different levels of expressivity. Our Letter opens the avenue for quantitative understanding of the expressivity of VQAs.},
	number = {8},
	urldate = {2022-07-25},
	journal = {Physical Review Letters},
	author = {Du, Yuxuan and Tu, Zhuozhuo and Yuan, Xiao and Tao, Dacheng},
	month = feb,
	year = {2022},
	note = {Publisher: American Physical Society},
	pages = {080506},
	file = {APS Snapshot:/Users/gangelat/Zotero/storage/I4D7MCJN/PhysRevLett.128.html:text/html;Full Text PDF:/Users/gangelat/Zotero/storage/KCZSUETW/Du et al. - 2022 - Efficient Measure for the Expressivity of Variatio.pdf:application/pdf},
}


% more expressible ansatz (closer to 2-design) leads to barren platueas
@article{Holmes2022,
  doi = {10.1103/prxquantum.3.010313},
  url = {https://doi.org/10.1103/prxquantum.3.010313},
  year = {2022},
  month = jan,
  publisher = {American Physical Society ({APS})},
  volume = {3},
  number = {1},
  author = {Zoë Holmes and Kunal Sharma and M. Cerezo and Patrick J. Coles},
  title = {Connecting Ansatz Expressibility to Gradient Magnitudes and Barren Plateaus},
  journal = {{PRX} Quantum},
  pages = {010313}
}

@article{Harrow2009,
  doi = {10.1007/s00220-009-0873-6},
  url = {https://doi.org/10.1007/s00220-009-0873-6},
  year = {2009},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {291},
  number = {1},
  pages = {257--302},
  author = {Aram W. Harrow and Richard A. Low},
  title = {Random Quantum Circuits are Approximate 2-designs},
  journal = {Communications in Mathematical Physics}
}


% Entanglement and Correlation

@article{diaz_classical_2021,
	title = {Classical analogs of the covariance matrix, purity, linear entropy, and von {Neumann} entropy},
	url = {http://arxiv.org/abs/2112.10899},
	abstract = {We obtain the classical analog of the quantum covariance matrix by performing its classical approximation for any continuous quantum state, and we illustrate this approach with the anharmonic oscillator. Using this classical covariance matrix, we propose classical analogs of the purity, linear quantum entropy, and von Neumann entropy for classical integrable systems, when the quantum counterpart of the system under consideration is in a Gaussian state. As is well-known, this matrix completely characterizes the purity, linear quantum entropy, and von Neumann entropy for Gaussian states. These classical analogs can be interpreted as quantities that reveal how much information from the complete system remains in the considered subsystem. To illustrate our approach, we calculate these classical analogs for three coupled harmonic oscillators and two linearly coupled oscillators. We find that they exactly reproduce the results of their quantum counterparts. In this sense, it is remarkable that we can calculate these quantities from the classical viewpoint.},
	urldate = {2021-12-22},
	journal = {arXiv:2112.10899 [cond-mat, physics:hep-th, physics:physics, physics:quant-ph]},
	author = {Díaz, Bogar and González, Diego and Gutiérrez-Ruiz, Daniel and Vergara, J. David},
	month = dec,
	year = {2021},
	keywords = {Condensed Matter - Statistical Mechanics, High Energy Physics - Theory, Physics - Classical Physics, Quantum Physics},
	annote = {Comment: 24 pages, 2 figures, Comments are welcome}
}

% expressibility and entangling capacity of generated state
@article{sim_expressibility_2019,
	title = {Expressibility and {Entangling} {Capability} of {Parameterized} {Quantum} {Circuits} for {Hybrid} {Quantum}-{Classical} {Algorithms}},
	volume = {2},
	issn = {2511-9044},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qute.201900070},
	doi = {10.1002/qute.201900070},
	abstract = {Parameterized quantum circuits (PQCs) play an essential role in the performance of many variational quantum algorithms. One challenge in implementing such algorithms is choosing an effective circuit that well represents the solution space while maintaining a low circuit depth and parameter count. To characterize and identify expressible, yet compact, circuits, several descriptors are proposed, including expressibility and entangling capability, that are statistically estimated from classical simulations. These descriptors are computed for different circuit structures, varying the qubit connectivity and selection of gates. From these simulations, circuit fragments that perform well with respect to the descriptors are identified. In particular, a substantial improvement in performance of two-qubit gates in a ring or all-to-all connected arrangement, compared to that of those on a line, is observed. Furthermore, improvement in both descriptors is achieved by sequences of controlled X-rotation gates compared to sequences of controlled Z-rotation gates. In addition, it is investigated how expressibility “saturates” with increased circuit depth, finding that the rate and saturated value appear to be distinguishing features of a PQC. While the correlation between each descriptor and algorithm performance remains to be investigated, methods and results from this study can be useful for algorithm development and design of experiments.},
	
	number = {12},
	urldate = {2022-07-18},
	journal = {Advanced Quantum Technologies},
	author = {Sim, Sukin and Johnson, Peter D. and Aspuru-Guzik, Alán},
	year = {2019},
	keywords = {quantum algorithms, quantum circuits, quantum computation},
	pages = {1900070}
}

% Quantum Fisher Info
% quantum noise imposes fundamental limits to param extimation
@article{meyer_fisher_2021,
	title = {Fisher {Information} in {Noisy} {Intermediate}-{Scale} {Quantum} {Applications}},
	volume = {5},
	url = {https://quantum-journal.org/papers/q-2021-09-09-539/},
	doi = {10.22331/q-2021-09-09-539},
	abstract = {The recent advent of noisy intermediate-scale quantum devices, especially near-term quantum computers, has sparked extensive research efforts concerned with their possible applications. At t…},
	urldate = {2022-01-24},
	journal = {Quantum},
	author = {Meyer, Johannes Jakob},
	month = sep,
	year = {2021},
	pPublisher = {Verein zur Förderung des Open Access Publizierens in den Quantenwissenschaften},
	pages = {539}
}

% relate fisher info to an effective dimension, 
%shows PQC can have larger effective dimension than classical networks - advantage?
 @article{Abbas_power_2021, title={The power of quantum neural networks}, volume={1}, ISSN={2662-8457}, DOI={10.1038/s43588-021-00084-1}, abstractNote={It is unknown whether near-term quantum computers are advantageous for machine learning tasks. In this work we address this question by trying to understand how powerful and trainable quantum machine learning models are in relation to popular classical neural networks. We propose the effective dimension—a measure that captures these qualities—and prove that it can be used to assess any statistical model’s ability to generalize on new data. Crucially, the effective dimension is a data-dependent measure that depends on the Fisher information, which allows us to gauge the ability of a model to train. We demonstrate numerically that a class of quantum neural networks is able to achieve a considerably better effective dimension than comparable feedforward networks and train faster, suggesting an advantage for quantum machine learning, which we verify on real quantum hardware.}, number={66}, journal={Nature Computational Science}, publisher={Nature Publishing Group}, author={Abbas, Amira and Sutter, David and Zoufal, Christa and Lucchi, Aurelien and Figalli, Alessio and Woerner, Stefan}, year={2021}, month={Jun}, pages={403–409}}

% % VARIATIONAL QUANTUM ALGORITHMS

% QML/VQA  Reviews

@article{cerezo_variational_2021,
	title = {Variational quantum algorithms},
	volume = {3},
	copyright = {2021 Springer Nature Limited},
	issn = {2522-5820},
	url = {https://www.nature.com/articles/s42254-021-00348-9},
	doi = {10.1038/s42254-021-00348-9},
	abstract = {Applications such as simulating complicated quantum systems or solving large-scale linear algebra problems are very challenging for classical computers, owing to the extremely high computational cost. Quantum computers promise a solution, although fault-tolerant quantum computers will probably not be available in the near future. Current quantum devices have serious constraints, including limited numbers of qubits and noise processes that limit circuit depth. Variational quantum algorithms (VQAs), which use a classical optimizer to train a parameterized quantum circuit, have emerged as a leading strategy to address these constraints. VQAs have now been proposed for essentially all applications that researchers have envisaged for quantum computers, and they appear to be the best hope for obtaining quantum advantage. Nevertheless, challenges remain, including the trainability, accuracy and efficiency of VQAs. Here we overview the field of VQAs, discuss strategies to overcome their challenges and highlight the exciting prospects for using them to obtain quantum advantage.},
	number = {9},
	urldate = {2022-07-25},
	journal = {Nature Reviews Physics},
	author = {Cerezo, M. and Arrasmith, Andrew and Babbush, Ryan and Benjamin, Simon C. and Endo, Suguru and Fujii, Keisuke and McClean, Jarrod R. and Mitarai, Kosuke and Yuan, Xiao and Cincio, Lukasz and Coles, Patrick J.},
	month = sep,
	year = {2021},
	keywords = {Computer science, Quantum information, Quantum simulation},
	pages = {625--644}
}

@book{schuld_machine_2021,
	series = {Quantum {Science} and {Technology}},
	title = {Machine {Learning} with {Quantum} {Computers}},
	isbn = {978-3-030-83097-7 978-3-030-83098-4},
	url = {https://link.springer.com/10.1007/978-3-030-83098-4},
	urldate = {2022-06-03},
	publisher = {Springer International Publishing},
	author = {Schuld, Maria and Petruccione, Francesco},
	year = {2021},
	doi = {10.1007/978-3-030-83098-4}
}

@article{benedetti_parameterized_2019,
	title = {Parameterized quantum circuits as machine learning models},
	volume = {4},
	issn = {2058-9565},
	url = {https://doi.org/10.1088/2058-9565/ab4eb5},
	doi = {10.1088/2058-9565/ab4eb5},
	abstract = {Hybrid quantum–classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.},
	number = {4},
	urldate = {2021-09-20},
	journal = {Quantum Science and Technology},
	author = {Benedetti, Marcello and Lloyd, Erika and Sack, Stefan and Fiorentini, Mattia},
	month = nov,
	year = {2019},
	pages = {043001}
}



% meh earlier reviews
@article{biamonte_quantum_2017,
	title = {Quantum machine learning},
	volume = {549},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature23474},
	doi = {10.1038/nature23474},
	number = {7671},
	urldate = {2020-04-15},
	journal = {Nature},
	author = {Biamonte, Jacob and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Wiebe, Nathan and Lloyd, Seth},
	month = sep,
	year = {2017},
	pages = {195--202}
}

@article{perdomo-ortiz_opportunities_2018,
	title = {Opportunities and challenges for quantum-assisted machine learning in near-term quantum computers},
	volume = {3},
	issn = {2058-9565},
	url = {https://iopscience.iop.org/article/10.1088/2058-9565/aab859},
	doi = {10.1088/2058-9565/aab859},
	abstract = {With quantum computing technologies nearing the era of commercialization and quantum supremacy, machine learning (ML) appears as one of the promising ‘killer’ applications. Despite signiﬁcant effort, there has been a disconnect between most quantum ML proposals, the needs of ML practitioners, and the capabilities of near-term quantum devices to demonstrate quantum enhancement in the near future. In this contribution to the focus collection ‘What would you do with 1000 qubits?’, we provide concrete examples of intractable ML tasks that could be enhanced with nearterm devices. We argue that to reach this target, the focus should be on areas where ML researchers are struggling, such as generative models in unsupervised and semi-supervised learning, instead of the popular and more tractable supervised learning techniques. We also highlight the case of classical datasets with potential quantum-like statistical correlations where quantum models could be more suitable. We focus on hybrid quantum–classical approaches and illustrate some of the key challenges we foresee for near-term implementations. Finally, we introduce the quantum-assisted Helmholtz machine (QAHM), an attempt to use near-term quantum devices to tackle high-dimensional datasets of continuous variables. Instead of using quantum computers to assist deep learning, as previous approaches do, the QAHM uses deep learning to extract a low-dimensional binary representation of data, suitable for relatively small quantum processors which can assist the training of an unsupervised generative model. Although we illustrate this concept on a quantum annealer, other quantum platforms could beneﬁt as well from this hybrid quantum–classical framework.},
	
	number = {3},
	urldate = {2020-04-16},
	journal = {Quantum Science and Technology},
	author = {Perdomo-Ortiz, Alejandro and Benedetti, Marcello and Realpe-Gómez, John and Biswas, Rupak},
	month = jun,
	year = {2018},
	keywords = {hybrid algorithms, near-term quantum computers, quantum annealing, quantum machine learning, quantum-assisted machine learning, unsupervised generative models, unsupervised learning},
	pages = {030502}
}

% 


% VQA applications 

% for VQA and especially chemistry applications, need a lot of measurements
@article{wecker_progress_2015,
	title = {Progress towards practical quantum variational algorithms},
	volume = {92},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.92.042303},
	doi = {10.1103/PhysRevA.92.042303},
	abstract = {The preparation of quantum states using short quantum circuits is one of the most promising near-term applications of small quantum computers, especially if the circuit is short enough and the fidelity of gates high enough that it can be executed without quantum error correction. Such quantum state preparation can be used in variational approaches, optimizing parameters in the circuit to minimize the energy of the constructed quantum state for a given problem Hamiltonian. For this purpose we propose a simple-to-implement class of quantum states motivated by adiabatic state preparation. We test its accuracy and determine the required circuit depth for a Hubbard model on ladders with up to 12 sites (24 spin orbitals), and for small molecules. We find that this ansatz converges faster than previously proposed schemes based on unitary coupled clusters. While the required number of measurements is astronomically large for quantum chemistry applications to molecules, applying the variational approach to the Hubbard model (and related models) is found to be far less demanding and potentially practical on small quantum computers. We also discuss another application of quantum state preparation using short quantum circuits, to prepare trial ground states of models faster than using adiabatic state preparation.},
	number = {4},
	urldate = {2022-10-28},
	journal = {Physical Review A},
	author = {Wecker, Dave and Hastings, Matthew B. and Troyer, Matthias},
	month = oct,
	year = {2015},
	pages = {042303},
}
%- QAOA
@article{farhi_quantum_2019,
	title = {Quantum {Supremacy} through the {Quantum} {Approximate} {Optimization} {Algorithm}},
	url = {http://arxiv.org/abs/1602.07674},
	abstract = {The Quantum Approximate Optimization Algorithm (QAOA) is designed to run on a gate model quantum computer and has shallow depth. It takes as input a combinatorial optimization problem and outputs a string that satisﬁes a high fraction of the maximum number of clauses that can be satisﬁed. For certain problems the lowest depth version of the QAOA has provable performance guarantees although there exist classical algorithms that have better guarantees. Here we argue that beyond its possible computational value the QAOA can exhibit a form of “Quantum Supremacy” in that, based on reasonable complexity theoretic assumptions, the output distribution of even the lowest depth version cannot be eﬃciently simulated on any classical device. We contrast this with the case of sampling from the output of a quantum computer running the Quantum Adiabatic Algorithm (QADI) with the restriction that the Hamiltonian that governs the evolution is gapped and stoquastic. Here we show that there is an oracle that would allow sampling from the QADI but even with this oracle, if one could eﬃciently classically sample from the output of the QAOA, the Polynomial Hierarchy would collapse. This suggests that the QAOA is an excellent candidate to run on near term quantum computers not only because it may be of use for optimization but also because of its potential as a route to establishing Quantum Supremacy.},
	urldate = {2020-04-15},
	journal = {arXiv:1602.07674 [quant-ph]},
	author = {Farhi, Edward and Harrow, Aram W.},
	month = oct,
	year = {2019},
	keywords = {Quantum Physics},
	annote = {Comment: 23 pages. v2 fixes bug in section 4. Results unchanged}
}

% VQA application - QPCA 
@article{lloyd_quantum_2014,
	title = {Quantum principal component analysis},
	volume = {10},
	copyright = {2014 Nature Publishing Group},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/nphys3029},
	doi = {10.1038/nphys3029},
	abstract = {Characterizing an unknown quantum state typically relies on analysing the outcome of a large set of measurements. Certain quantum-processing tasks are now shown to be realizable using only approximate knowledge of the state, which can be gathered with exponentially fewer resources.},
	
	number = {9},
	urldate = {2021-12-09},
	journal = {Nature Physics},
	author = {Lloyd, Seth and Mohseni, Masoud and Rebentrost, Patrick},
	month = sep,
	year = {2014},
	keywords = {Quantum information},
	pages = {631--633}
}



% Parameterized Quantum Circuits, Supervised learning

% encoding determines expressivitiy, PQC as function approximators
@article{schuld_effect_2021,
	title = {Effect of data encoding on the expressive power of variational quantum-machine-learning models},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.103.032430},
	doi = {10.1103/PhysRevA.103.032430},
	abstract = {Quantum computers can be used for supervised learning by treating parametrized quantum circuits as models that map data inputs to predictions. While a lot of work has been done to investigate the practical implications of this approach, many important theoretical properties of these models remain unknown. Here, we investigate how the strategy with which data are encoded into the model influences the expressive power of parametrized quantum circuits as function approximators. We show that one can naturally write a quantum model as a partial Fourier series in the data, where the accessible frequencies are determined by the nature of the data-encoding gates in the circuit. By repeating simple data-encoding gates multiple times, quantum models can access increasingly rich frequency spectra. We show that there exist quantum models which can realize all possible sets of Fourier coefficients, and therefore, if the accessible frequency spectrum is asymptotically rich enough, such models are universal function approximators.},
	number = {3},
	urldate = {2022-01-28},
	journal = {Physical Review A},
	volume = {103},
	author = {Schuld, Maria and Sweke, Ryan and Meyer, Johannes Jakob},
	month = {mar},
	year = {2021},
	publisher = {American Physical Society},
	pages = {032430}
}

% related to above, can have classical surrogate for variational circuit
@misc{schreiber_classical_2022,
	title = {Classical surrogates for quantum learning models},
	url = {http://arxiv.org/abs/2206.11740},
	doi = {10.48550/arXiv.2206.11740},
	abstract = {The advent of noisy intermediate-scale quantum computers has put the search for possible applications to the forefront of quantum information science. One area where hopes for an advantage through near-term quantum computers are high is quantum machine learning, where variational quantum learning models based on parametrized quantum circuits are discussed. In this work, we introduce the concept of a classical surrogate, a classical model which can be efficiently obtained from a trained quantum learning model and reproduces its input-output relations. As inference can be performed classically, the existence of a classical surrogate greatly enhances the applicability of a quantum learning strategy. However, the classical surrogate also challenges possible advantages of quantum schemes. As it is possible to directly optimize the ansatz of the classical surrogate, they create a natural benchmark the quantum model has to outperform. We show that large classes of well-analyzed re-uploading models have a classical surrogate. We conducted numerical experiments and found that these quantum models show no advantage in performance or trainability in the problems we analyze. This leaves only generalization capability as possible point of quantum advantage and emphasizes the dire need for a better understanding of inductive biases of quantum learning models.},
	urldate = {2022-06-24},
	publisher = {arXiv},
	author = {Schreiber, Franz J. and Eisert, Jens and Meyer, Johannes Jakob},
	month = jun,
	year = {2022},
	journal = {arXiv:2206.11740 [quant-ph]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Quantum Physics},
	annote = {Comment: 4 pages, 3 figures}
}
% numerics, VQC for classification, role of noise
@article{schuld_circuit-centric_2020,
	title = {Circuit-centric quantum classifiers},
	volume = {101},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.101.032308},
	doi = {10.1103/PhysRevA.101.032308},
	abstract = {Variational quantum circuits are becoming tools of choice in quantum optimization and machine learning. In this paper we investigate a class of variational circuits for the purposes of supervised machine learning. We propose a circuit architecture suitable for predicting class labels of quantumly encoded data via measurements of certain observables. We observe that the required depth of a trainable classification circuit is related to the number of representative principal components of the data distribution. Quantum circuit architectures used in our design are validated by numerical simulation, which shows significant model size reduction compared to classical predictive models. Circuit-based models demonstrate good resilience to noise, which makes then robust and error tolerant.},
	number = {3},
	urldate = {2022-03-24},
	journal = {Physical Review A},
	author = {Schuld, Maria and Bocharov, Alex and Svore, Krysta M. and Wiebe, Nathan},
	month = mar,
	year = {2020},
	publisher = {American Physical Society},
	pages = {032308},
}


% expt example PQC for classification
@article{havlicek_supervised_2019,
	title = {Supervised learning with quantum-enhanced feature spaces},
	volume = {567},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-0980-2},
	doi = {10.1038/s41586-019-0980-2},
	
	number = {7747},
	urldate = {2020-11-05},
	journal = {Nature},
	author = {Havlíček, Vojtěch and Córcoles, Antonio D. and Temme, Kristan and Harrow, Aram W. and Kandala, Abhinav and Chow, Jerry M. and Gambetta, Jay M.},
	month = mar,
	year = {2019},
	publisher = {Nature Publishing Group},
	pages = {209--212}
}

% PQC for classification, kernel type method, quantum data + MNIST,
@article{grant_hierarchical_2018,
	title = {Hierarchical quantum classifiers},
	volume = {4},
	copyright = {2018 The Author(s)},
	issn = {2056-6387},
	url = {https://www.nature.com/articles/s41534-018-0116-9},
	doi = {10.1038/s41534-018-0116-9},
	abstract = {Quantum circuits with hierarchical structure have been used to perform binary classification of classical data encoded in a quantum state. We demonstrate that more expressive circuits in the same family achieve better accuracy and can be used to classify highly entangled quantum states, for which there is no known efficient classical method. We compare performance for several different parameterizations on two classical machine learning datasets, Iris and MNIST, and on a synthetic dataset of quantum states. Finally, we demonstrate that performance is robust to noise and deploy an Iris dataset classifier on the ibmqx4 quantum computer.},
	
	number = {1},
	urldate = {2022-07-15},
	journal = {npj Quantum Information},
	author = {Grant, Edward and Benedetti, Marcello and Cao, Shuxiang and Hallam, Andrew and Lockhart, Joshua and Stojevic, Vid and Green, Andrew G. and Severini, Simone},
	month = dec,
	year = {2018},
	publisher = {Nature Publishing Group},
	keywords = {Computer science, Quantum information},
	pages = {1--8}
}

% PQC for classification -  can be universal, generally requires exponential depth
@article{farhi_classification_2018,
	title = {Classification with {Quantum} {Neural} {Networks} on {Near} {Term} {Processors}},
	url = {http://arxiv.org/abs/1802.06002},
	abstract = {We introduce a quantum neural network, QNN, that can represent labeled data, classical or quantum, and be trained by supervised learning. The quantum circuit consists of a sequence of parameter dependent unitary transformations which acts on an input quantum state. For binary classification a single Pauli operator is measured on a designated readout qubit. The measured output is the quantum neural network's predictor of the binary label of the input state. First we look at classifying classical data sets which consist of n-bit strings with binary labels. The input quantum state is an n-bit computational basis state corresponding to a sample string. We show how to design a circuit made from two qubit unitaries that can correctly represent the label of any Boolean function of n bits. For certain label functions the circuit is exponentially long. We introduce parameter dependent unitaries that can be adapted by supervised learning of labeled data. We study an example of real world data consisting of downsampled images of handwritten digits each of which has been labeled as one of two distinct digits. We show through classical simulation that parameters can be found that allow the QNN to learn to correctly distinguish the two data sets. We then discuss presenting the data as quantum superpositions of computational basis states corresponding to different label values. Here we show through simulation that learning is possible. We consider using our QNN to learn the label of a general quantum state. By example we show that this can be done. Our work is exploratory and relies on the classical simulation of small quantum systems. The QNN proposed here was designed with near-term quantum processors in mind. Therefore it will be possible to run this QNN on a near term gate model quantum computer where its power can be explored beyond what can be explored with simulation.},
	urldate = {2022-07-15},
	journal = {arXiv:1802.06002 [quant-ph]},
	publisher = {arXiv},
	author = {Farhi, Edward and Neven, Hartmut},
	month = aug,
	year = {2018},
	keywords = {Quantum Physics}
}

% PQA as Kernel methods have potential for quantum advantage on quantum data
% metric for how diferent quantum and classical ML model is, 
% potential for advantage when difference is large
@article{huang_power_2021,
	title = {Power of data in quantum machine learning},
	volume = {12},
	issn = {2041-1723},
	url = {http://arxiv.org/abs/2011.01938},
	doi = {10.1038/s41467-021-22539-9},
	abstract = {The use of quantum computing for machine learning is among the most exciting prospective applications of quantum technologies. However, machine learning tasks where data is provided can be considerably different than commonly studied computational tasks. In this work, we show that some problems that are classically hard to compute can be easily predicted by classical machines learning from data. Using rigorous prediction error bounds as a foundation, we develop a methodology for assessing potential quantum advantage in learning tasks. The bounds are tight asymptotically and empirically predictive for a wide range of learning models. These constructions explain numerical results showing that with the help of data, classical machine learning models can be competitive with quantum models even if they are tailored to quantum problems. We then propose a projected quantum model that provides a simple and rigorous quantum speed-up for a learning problem in the fault-tolerant regime. For near-term implementations, we demonstrate a significant prediction advantage over some classical models on engineered data sets designed to demonstrate a maximal quantum advantage in one of the largest numerical tests for gate-based quantum machine learning to date, up to 30 qubits.},
	number = {1},
	urldate = {2022-01-05},
	journal = {Nature Communications},
	author = {Huang, Hsin-Yuan and Broughton, Michael and Mohseni, Masoud and Babbush, Ryan and Boixo, Sergio and Neven, Hartmut and McClean, Jarrod R.},
	month = dec,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Quantum Physics},
	pages = {2631}
}

% Generative QML example
@article{rudolph_generation_2022,
	title = {Generation of {High}-{Resolution} {Handwritten} {Digits} with an {Ion}-{Trap} {Quantum} {Computer}},
	volume = {12},
	url = {https://link.aps.org/doi/10.1103/PhysRevX.12.031010},
	doi = {10.1103/PhysRevX.12.031010},
	abstract = {Generating high-quality data (e.g., images or video) is one of the most exciting and challenging frontiers in unsupervised machine learning. Utilizing quantum computers in such tasks to potentially enhance conventional machine-learning algorithms has emerged as a promising application but poses big challenges due to the limited number of qubits and the level of gate noise in available devices. In this work, we provide the first practical and experimental implementation of a quantum-classical generative algorithm capable of generating high-resolution images of handwritten digits with state-of-the-art gate-based quantum computers. In our quantum-assisted machine-learning framework, we implement a quantum-circuit-based generative model to learn and sample the prior distribution of a generative adversarial network. We introduce a multibasis technique which leverages the unique possibility of measuring quantum states in different bases, hence enhancing the expressivity of the prior distribution. We train this hybrid algorithm on an ion-trap device based on 171Yb+ ion qubits to generate high-quality images and quantitatively outperform comparable classical generative adversarial networks trained on the popular MNIST dataset for handwritten digits.},
	number = {3},
	urldate = {2022-07-18},
	journal = {Physical Review X},
	author = {Rudolph, Manuel S. and Toussaint, Ntwali Bashige and Katabarwa, Amara and Johri, Sonika and Peropadre, Borja and Perdomo-Ortiz, Alejandro},
	month = jul,
	year = {2022},
	note = {Publisher: American Physical Society},
	pages = {031010},
	file = {APS Snapshot:/Users/gangelat/Zotero/storage/8G3DNVSN/PhysRevX.12.html:text/html;Full Text PDF:/Users/gangelat/Zotero/storage/D29Q4ST4/Rudolph et al. - 2022 - Generation of High-Resolution Handwritten Digits w.pdf:application/pdf},
}


% role of measurement in generative QML
@article{anshu_sample-efficient_2021,
	title = {Sample-efficient learning of interacting quantum systems},
	volume = {17},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/s41567-021-01232-0},
	doi = {10.1038/s41567-021-01232-0},
	abstract = {Learning the Hamiltonian that describes interactions in a quantum system is an important task in both condensed-matter physics and the verification of quantum technologies. Its classical analogue arises as a central problem in machine learning known as learning Boltzmann machines. Previously, the best known methods for quantum Hamiltonian learning with provable performance guarantees required a number of measurements that scaled exponentially with the number of particles. Here we prove that only a polynomial number of local measurements on the thermal state of a quantum system are necessary and sufficient for accurately learning its Hamiltonian. We achieve this by establishing that the absolute value of the finite-temperature free energy of quantum many-body systems is strongly convex with respect to the interaction coefficients. The framework introduced in our work provides a theoretical foundation for applying machine learning techniques to quantum Hamiltonian learning, achieving a long-sought goal in quantum statistical learning.},
	
	number = {8},
	urldate = {2022-01-17},
	journal = {Nature Physics},
	author = {Anshu, Anurag and Arunachalam, Srinivasan and Kuwahara, Tomotaka and Soleimanifar, Mehdi},
	month = aug,
	year = {2021},
	keywords = {Condensed-matter physics, Information theory and computation, Quantum information},
	pages = {931--935}
}

% Metrology with PQC

@article{ma_adaptive_2021,
	title = {Adaptive {Circuit} {Learning} for {Quantum} {Metrology}},
	url = {http://arxiv.org/abs/2010.08702},
	abstract = {Quantum sensing is an important application of emerging quantum technologies. We explore whether a hybrid system of quantum sensors and quantum circuits can surpass the classical limit of sensing. In particular, we use optimization techniques to search for encoder and decoder circuits that scalably improve sensitivity under given application and noise characteristics. Our approach uses a variational algorithm that can learn a quantum sensing circuit based on platform-specific control capacity, noise, and signal distribution. The quantum circuit is composed of an encoder which prepares the optimal sensing state and a decoder which gives an output distribution containing information of the signal. We optimize the full circuit to maximize the Signal-to-Noise Ratio (SNR). Furthermore, this learning algorithm can be run on real hardware scalably by using the "parameter-shift" rule which enables gradient evaluation on noisy quantum circuits, avoiding the exponential cost of quantum system simulation. We demonstrate up to 13.12x SNR improvement over existing fixed protocol (GHZ), and 3.19x Classical Fisher Information (CFI) improvement over the classical limit on 15 qubits using IBM quantum computer. More notably, our algorithm overcomes the decreasing performance of existing entanglement-based protocols with increased system sizes.},
	urldate = {2022-01-18},
	journal = {arXiv:2010.08702 [quant-ph]},
	author = {Ma, Ziqi and Gokhale, Pranav and Zheng, Tian-Xing and Zhou, Sisi and Yu, Xiaofei and Jiang, Liang and Maurer, Peter and Chong, Frederic T.},
	month = nov,
	year = {2021},
	keywords = {Quantum Physics},
	annote = {Comment: 12 pages, 11 figures}
}

% PQC to measure phase, entanglign unitaries help reduce error
 @article{Marciniak_Monz_2022, title={Optimal metrology with programmable quantum sensors}, volume={603}, ISSN={1476-4687}, DOI={10.1038/s41586-022-04435-4}, abstractNote={Quantum sensors are an established technology that has created new opportunities for precision sensing across the breadth of science. Using entanglement for quantum enhancement will allow us to construct the next generation of sensors that can approach the fundamental limits of precision allowed by quantum physics. However, determining how state-of-the-art sensing platforms may be used to converge to these ultimate limits is an outstanding challenge. Here we merge concepts from the field of quantum information processing with metrology, and successfully implement experimentally a programmable quantum sensor operating close to the fundamental limits imposed by the laws of quantum mechanics. We achieve this by using low-depth, parametrized quantum circuits implementing optimal input states and measurement operators for a sensing task on a trapped-ion experiment. With 26 ions, we approach the fundamental sensing limit up to a factor of 1.45 ± 0.01, outperforming conventional spin-squeezing with a factor of 1.87 ± 0.03. Our approach reduces the number of averages to reach a given Allan deviation by a factor of 1.59 ± 0.06 compared with traditional methods not using entanglement-enabled protocols. We further perform on-device quantum-classical feedback optimization to ‘self-calibrate’ the programmable quantum sensor with comparable performance. This ability illustrates that this next generation of quantum sensor can be used without previous knowledge of the device or its noise environment.}, number={79027902}, journal={Nature}, publisher={Nature Publishing Group}, author={Marciniak, Christian D. and Feldker, Thomas and Pogorelov, Ivan and Kaubruegger, Raphael and Vasilyev, Denis V. and van Bijnen, Rick and Schindler, Philipp and Zoller, Peter and Blatt, Rainer and Monz, Thomas}, year={2022}, month={Mar}, pages={604–609}}

@article{montijn_population-level_2016,
	title = {Population-{Level} {Neural} {Codes} {Are} {Robust} to {Single}-{Neuron} {Variability} from a {Multidimensional} {Coding} {Perspective}},
	volume = {16},
	issn = {2211-1247},
	url = {https://www.sciencedirect.com/science/article/pii/S2211124716309962},
	doi = {10.1016/j.celrep.2016.07.065},
	abstract = {Sensory neurons are often tuned to particular stimulus features, but their responses to repeated presentation of the same stimulus can vary over subsequent trials. This presents a problem for understanding the functioning of the brain, because downstream neuronal populations ought to construct accurate stimulus representations, even upon singular exposure. To study how trial-by-trial fluctuations (i.e., noise) in activity influence cortical representations of sensory input, we performed chronic calcium imaging of GCaMP6-expressing populations in mouse V1. We observed that high-dimensional response correlations, i.e., dependencies in activation strength among multiple neurons, can be used to predict single-trial, single-neuron noise. These multidimensional correlations are structured such that variability in the response of single neurons is relatively harmless to population representations of visual stimuli. We propose that multidimensional coding may represent a canonical principle of cortical circuits, explaining why the apparent noisiness of neuronal responses is compatible with accurate neural representations of stimulus features.},
	number = {9},
	urldate = {2023-07-12},
	journal = {Cell Reports},
	author = {Montijn, Jorrit S. and Meijer, Guido T. and Lansink, Carien S. and Pennartz, Cyriel M. A.},
	month = aug,
	year = {2016},
	pages = {2486--2498}
}

% optical neural network experiments

@article{bueno_reinforcement_2018,
	title = {Reinforcement learning in a large-scale photonic recurrent neural network},
	volume = {5},
	copyright = {© 2018 Optical Society of America},
	issn = {2334-2536},
	url = {https://opg.optica.org/optica/abstract.cfm?uri=optica-5-6-756},
	doi = {10.1364/OPTICA.5.000756},
	abstract = {Photonic neural network implementation has been gaining considerable attention as a potentially disruptive future technology. Demonstrating learning in large-scale neural networks is essential to establish photonic machine learning substrates as viable information processing systems. Realizing photonic neural networks with numerous nonlinear nodes in a fully parallel and efficient learning hardware has been lacking so far. We demonstrate a network of up to 2025 diffractively coupled photonic nodes, forming a large-scale recurrent neural network. Using a digital micro mirror device, we realize reinforcement learning. Our scheme is fully parallel, and the passive weights maximize energy efficiency and bandwidth. The computational output efficiently converges, and we achieve very good performance.},
	number = {6},
	urldate = {2023-07-14},
	journal = {Optica},
	author = {Bueno, J. and Maktoobi, S. and Froehly, L. and Fischer, I. and Jacquot, M. and Larger, L. and Brunner, D.},
	month = jun,
	year = {2018},
	keywords = {Diffractive optical elements, Digital micromirror devices, Field programmable gate arrays, Neural networks, Parallel readout, Spatial light modulators},
	pages = {756--760},
	file = {Full Text PDF:C\:\\Users\\wewil\\Zotero\\storage\\SSXEGAXU\\Bueno et al. - 2018 - Reinforcement learning in a large-scale photonic r.pdf:application/pdf},
}

@article{pai_experimentally_2023,
	title = {Experimentally realized in situ backpropagation for deep learning in photonic neural networks},
	volume = {380},
	url = {https://www.science.org/doi/10.1126/science.ade8450},
	doi = {10.1126/science.ade8450},
	abstract = {Integrated photonic neural networks provide a promising platform for energy-efficient, high-throughput machine learning with extensive scientific and commercial applications. Photonic neural networks efficiently transform optically encoded inputs using Mach-Zehnder interferometer mesh networks interleaved with nonlinearities. We experimentally trained a three-layer, four-port silicon photonic neural network with programmable phase shifters and optical power monitoring to solve classification tasks using “in situ backpropagation,” a photonic analog of the most popular method to train conventional neural networks. We measured backpropagated gradients for phase-shifter voltages by interfering forward- and backward-propagating light and simulated in situ backpropagation for 64-port photonic neural networks trained on MNIST image recognition given errors. All experiments performed comparably to digital simulations, and energy scaling analysis indicated a route to scalable machine learning.},
	number = {6643},
	urldate = {2023-05-01},
	journal = {Science},
	author = {Pai, Sunil and Sun, Zhanghao and Hughes, Tyler W. and Park, Taewon and Bartlett, Ben and Williamson, Ian A. D. and Minkov, Momchil and Milanizadeh, Maziyar and Abebe, Nathnael and Morichetti, Francesco and Melloni, Andrea and Fan, Shanhui and Solgaard, Olav and Miller, David A. B.},
	month = apr,
	year = {2023},
	pages = {398--404},
}

@article{lin_all-optical_2018,
	title = {All-optical machine learning using diffractive deep neural networks},
	volume = {361},
	url = {https://www.science.org/doi/10.1126/science.aat8084},
	doi = {10.1126/science.aat8084},
	abstract = {Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning–based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.},
	number = {6406},
	urldate = {2023-07-14},
	journal = {Science},
	author = {Lin, Xing and Rivenson, Yair and Yardimci, Nezih T. and Veli, Muhammed and Luo, Yi and Jarrahi, Mona and Ozcan, Aydogan},
	month = sep,
	year = {2018},
	pages = {1004--1008},
}

@inproceedings{reuther_survey_2020,
	title = {Survey of {Machine} {Learning} {Accelerators}},
	doi = {10.1109/HPEC43674.2020.9286149},
	abstract = {New machine learning accelerators are being announced and released each month for a variety of applications from speech recognition, video object detection, assisted driving, and many data center applications. This paper updates the survey of of AI accelerators and processors from last year's IEEE-HPEC paper. This paper collects and summarizes the current accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. This year, there are many more announced accelerators that are implemented with many more architectures and technologies from vector engines, dataflow engines, neuromorphic designs, flash-based analog memory processing, and photonic-based processing.},
	booktitle = {2020 {IEEE} {High} {Performance} {Extreme} {Computing} {Conference} ({HPEC})},
	author = {Reuther, Albert and Michaleas, Peter and Jones, Michael and Gadepally, Vijay and Samsi, Siddharth and Kepner, Jeremy},
	month = sep,
	year = {2020},
	keywords = {accelerator, computational performance, dataflow, embedded inference, Engines, GPU, Machine learning, Market research, Power demand, Program processors, Speech recognition, TPU, Training},
	pages = {1--12},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\wewil\\Zotero\\storage\\IT4MZ69I\\Reuther et al. - 2020 - Survey of Machine Learning Accelerators.pdf:application/pdf},
}

@article{shen_deep_2017,
	title = {Deep learning with coherent nanophotonic circuits},
	volume = {11},
	copyright = {2017 Springer Nature Limited},
	issn = {1749-4893},
	url = {https://www.nature.com/articles/nphoton.2017.93},
	doi = {10.1038/nphoton.2017.93},
	abstract = {Artificial neural networks are computational network models inspired by signal processing in the brain. These models have dramatically improved performance for many machine-learning tasks, including speech and image recognition. However, today's computing hardware is inefficient at implementing neural networks, in large part because much of it was designed for von Neumann computing schemes. Significant effort has been made towards developing electronic architectures tuned to implement artificial neural networks that exhibit improved computational speed and accuracy. Here, we propose a new architecture for a fully optical neural network that, in principle, could offer an enhancement in computational speed and power efficiency over state-of-the-art electronics for conventional inference tasks. We experimentally demonstrate the essential part of the concept using a programmable nanophotonic processor featuring a cascaded array of 56 programmable Mach–Zehnder interferometers in a silicon photonic integrated circuit and show its utility for vowel recognition.},
	number = {7},
	urldate = {2023-07-14},
	journal = {Nature Photonics},
	author = {Shen, Yichen and Harris, Nicholas C. and Skirlo, Scott and Prabhu, Mihika and Baehr-Jones, Tom and Hochberg, Michael and Sun, Xin and Zhao, Shijie and Larochelle, Hugo and Englund, Dirk and Soljačić, Marin},
	month = jul,
	year = {2017},
	keywords = {Integrated optics, Silicon photonics},
	pages = {441--446},
	file = {Full Text PDF:C\:\\Users\\wewil\\Zotero\\storage\\E33JFVAH\\Shen et al. - 2017 - Deep learning with coherent nanophotonic circuits.pdf:application/pdf},
}

@article{tacchino_artificial_2019,
	title = {An artificial neuron implemented on an actual quantum processor},
	volume = {5},
	copyright = {2019 The Author(s)},
	issn = {2056-6387},
	url = {https://www.nature.com/articles/s41534-019-0140-4},
	doi = {10.1038/s41534-019-0140-4},
	abstract = {Artificial neural networks are the heart of machine learning algorithms and artificial intelligence. Historically, the simplest implementation of an artificial neuron traces back to the classical Rosenblatt’s “perceptron”, but its long term practical applications may be hindered by the fast scaling up of computational complexity, especially relevant for the training of multilayered perceptron networks. Here we introduce a quantum information-based algorithm implementing the quantum computer version of a binary-valued perceptron, which shows exponential advantage in storage resources over alternative realizations. We experimentally test a few qubits version of this model on an actual small-scale quantum processor, which gives answers consistent with the expected results. We show that this quantum model of a perceptron can be trained in a hybrid quantum-classical scheme employing a modified version of the perceptron update rule and used as an elementary nonlinear classifier of simple patterns, as a first step towards practical quantum neural networks efficiently implemented on near-term quantum processing hardware.},
	number = {1},
	urldate = {2023-07-14},
	journal = {npj Quantum Information},
	author = {Tacchino, Francesco and Macchiavello, Chiara and Gerace, Dario and Bajoni, Daniele},
	month = mar,
	year = {2019},
	keywords = {Information theory and computation, Quantum information, Quantum physics},
	pages = {1--8},
	file = {Full Text PDF:C\:\\Users\\wewil\\Zotero\\storage\\E8UCBW34\\Tacchino et al. - 2019 - An artificial neuron implemented on an actual quan.pdf:application/pdf},
}

@article{ortin_unified_2015,
	title = {A {Unified} {Framework} for {Reservoir} {Computing} and {Extreme} {Learning} {Machines} based on a {Single} {Time}-delayed {Neuron}},
	volume = {5},
	copyright = {2015 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep14945},
	doi = {10.1038/srep14945},
	abstract = {In this paper we present a unified framework for extreme learning machines and reservoir computing (echo state networks), which can be physically implemented using a single nonlinear neuron subject to delayed feedback. The reservoir is built within the delay-line, employing a number of “virtual” neurons. These virtual neurons receive random projections from the input layer containing the information to be processed. One key advantage of this approach is that it can be implemented efficiently in hardware. We show that the reservoir computing implementation, in this case optoelectronic, is also capable to realize extreme learning machines, demonstrating the unified framework for both schemes in software as well as in hardware.},
	number = {1},
	urldate = {2023-07-14},
	journal = {Scientific Reports},
	author = {Ortín, S. and Soriano, M. C. and Pesquera, L. and Brunner, D. and San-Martín, D. and Fischer, I. and Mirasso, C. R. and Gutiérrez, J. M.},
	month = oct,
	year = {2015},
	keywords = {Dynamical systems, Learning algorithms, Optoelectronic devices and components},
	pages = {14945},
	file = {Full Text PDF:C\:\\Users\\wewil\\Zotero\\storage\\PLL6SV4H\\Ortín et al. - 2015 - A Unified Framework for Reservoir Computing and Ex.pdf:application/pdf},
}

@article{neelakantan_adding_2015,
	title = {Adding {Gradient} {Noise} {Improves} {Learning} for {Very} {Deep} {Networks}},
	url = {http://arxiv.org/abs/1511.06807},
	journal = {arXiv:1511.06807 [stat.ML]},
	abstract = {Deep feedforward and recurrent networks have achieved impressive results in many perception and language processing applications. This success is partially attributed to architectural innovations such as convolutional and long short-term memory networks. The main motivation for these architectural innovations is that they capture better domain knowledge, and importantly are easier to optimize than more basic architectures. Recently, more complex architectures such as Neural Turing Machines and Memory Networks have been proposed for tasks including question answering and general computation, creating a new set of optimization challenges. In this paper, we discuss a low-overhead and easy-to-implement technique of adding gradient noise which we find to be surprisingly effective when training these very deep architectures. The technique not only helps to avoid overfitting, but also can result in lower training loss. This method alone allows a fully-connected 20-layer deep network to be trained with standard gradient descent, even starting from a poor initialization. We see consistent improvements for many complex models, including a 72\% relative reduction in error rate over a carefully-tuned baseline on a challenging question-answering task, and a doubling of the number of accurate binary multiplication models learned across 7,000 random restarts. We encourage further application of this technique to additional complex modern architectures.},
	urldate = {2023-07-14},
	author = {Neelakantan, Arvind and Vilnis, Luke and Le, Quoc V. and Sutskever, Ilya and Kaiser, Lukasz and Kurach, Karol and Martens, James},
	year = {2015}
}

@article{bishop_training_1995,
	title = {Training with {Noise} is {Equivalent} to {Tikhonov} {Regularization}},
	volume = {7},
	issn = {0899-7667},
	doi = {10.1162/neco.1995.7.1.108},
	abstract = {It is well known that the addition of noise to the input data of a neural network during training can, in some circumstances, lead to significant improvements in generalization performance. Previous work has shown that such training with noise is equivalent to a form of regularization in which an extra term is added to the error function. However, the regularization term, which involves second derivatives of the error function, is not bounded below, and so can lead to difficulties if used directly in a learning algorithm based on error minimization. In this paper we show that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping. For a sum-of-squares error function, the regularization term belongs to the class of generalized Tikhonov regularizers. Direct minimization of the regularized error function provides a practical alternative to training with noise.},
	number = {1},
	journal = {Neural Computation},
	author = {Bishop, Chris M.},
	month = jan,
	year = {1995},
	pages = {108--116},
}

@article{noh_regularizing_2017,
	title = {Regularizing {Deep} {Neural} {Networks} by {Noise}: {Its} {Interpretation} and {Optimization}},
	shorttitle = {Regularizing {Deep} {Neural} {Networks} by {Noise}},
	url = {http://arxiv.org/abs/1710.05179},
	abstract = {Overfitting is one of the most critical challenges in deep neural networks, and there are various types of regularization methods to improve generalization performance. Injecting noises to hidden units during training, e.g., dropout, is known as a successful regularizer, but it is still not clear enough why such training techniques work well in practice and how we can maximize their benefit in the presence of two conflicting objectives---optimizing to true data distribution and preventing overfitting by regularization. This paper addresses the above issues by 1) interpreting that the conventional training methods with regularization by noise injection optimize the lower bound of the true objective and 2) proposing a technique to achieve a tighter lower bound using multiple noise samples per training example in a stochastic gradient descent iteration. We demonstrate the effectiveness of our idea in several computer vision applications.},
	urldate = {2023-07-14},
	publisher = {arXiv},
	author = {Noh, Hyeonwoo and You, Tackgeun and Mun, Jonghwan and Han, Bohyung},
	month = nov,
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
    journal = {arXiv:1710.05179 [cs.LG]}
}


% review
@article{Giovannetti_Lloyd_Maccone_2011, 
  title={Advances in quantum metrology}, 
  volume={5}, 
  ISSN={1749-4893}, 
  DOI={10.1038/nphoton.2011.35}, 
  abstractNote={The statistical error in any estimation can be reduced by repeating the measurement and averaging the results. The central limit theorem implies that the reduction is proportional to the square root of the number of repetitions. Quantum metrology is the use of quantum techniques such as entanglement to yield higher statistical precision than purely classical approaches. In this Review, we analyse some of the most promising recent developments of this research field and point out some of the new experiments. We then look at one of the major new trends of the field: analyses of the effects of noise and experimental imperfections.}, 
  number={44}, 
  journal={Nature Photonics}, 
  publisher={Nature Publishing Group}, 
  author={Giovannetti, Vittorio and Lloyd, Seth and Maccone, Lorenzo}, year={2011}, month={Apr}, 
  pages={222–229}
 }

 @book{yariv_photonics_2007,
	title = {Photonics: optical electronics in modern communications, sixth edition},
	isbn = {978-0-19-517946-0},
	shorttitle = {Photonics},
	url = {http://catdir.loc.gov/catdir/enhancements/fy0635/2005047270-t.html},
	abstract = {Designed for senior undergraduate/first year graduate students in electrical engineering departments, this text covers key subjects in optical electronics and their applications in modern optical communications where optical waves are used as carriers of information},
	urldate = {2023-06-13},
	publisher = {Oxford University Press},
	author = {Yariv, Amnon and Yeh, Pochi},
	year = {2007}
}


@book{wiseman_quantum_2009,
	title = {Quantum {Measurement} and {Control}},
	isbn = {978-0-521-80442-4},
	url = {https://www.cambridge.org/core/books/quantum-measurement-and-control/F78F445CD9AF00B10593405E9BAC6B9F},
	abstract = {The control of individual quantum systems promises a new technology for the 21st century - quantum technology. This book is the first comprehensive treatment of modern quantum measurement and measurement-based quantum control, which are vital elements for realizing quantum technology. Readers are introduced to key experiments and technologies through dozens of recent experiments in cavity QED, quantum optics, mesoscopic electronics, and trapped particles several of which are analysed in detail. Nearly 300 exercises help build understanding, and prepare readers for research in these exciting areas. This important book will interest graduate students and researchers in quantum information, quantum metrology, quantum control and related fields. Novel topics covered include adaptive measurement; realistic detector models; mesoscopic current detection; Markovian, state-based and optimal feedback; and applications to quantum information processing.},
	urldate = {2023-06-13},
	publisher = {Cambridge University Press},
	author = {Wiseman, Howard M. and Milburn, Gerard J.},
	year = {2009},
	doi = {10.1017/CBO9780511813948},
	file = {Full Text:C\:\\Users\\wewil\\Zotero\\storage\\ZSNKDBKF\\Wiseman and Milburn - 2009 - Quantum Measurement and Control.pdf:application/pdf},
}

 @book{saleh_fundamentals_1991,
	title = {Fundamentals of photonics},
	isbn = {978-0-471-83965-1},
	url = {http://catalogue.bnf.fr/ark:/12148/cb373665854},
	urldate = {2023-06-13},
	publisher = {Wiley},
	author = {Saleh, Bahaa E. A. and Teich, Malvin Carl},
	year = {1991},
	keywords = {Photonics, Photonique}
}

 
@article{Giovannetti2006,
  doi = {10.1103/physrevlett.96.010401},
  url = {https://doi.org/10.1103/physrevlett.96.010401},
  year = {2006},
  month = jan,
  publisher = {American Physical Society ({APS})},
  volume = {96},
  number = {1},
  author = {Vittorio Giovannetti and Seth Lloyd and Lorenzo Maccone},
  title = {Quantum Metrology},
  journal = {Physical Review Letters},
  pages = {010401}
}


% Barren Plateaus

@article{mcclean_barren_2018,
	title = {Barren plateaus in quantum neural network training landscapes},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-07090-4},
	doi = {10.1038/s41467-018-07090-4},
	abstract = {Many experimental proposals for noisy intermediate scale quantum devices involve training a parameterized quantum circuit with a classical optimization loop. Such hybrid quantum-classical algorithms are popular for applications in quantum simulation, optimization, and machine learning. Due to its simplicity and hardware efficiency, random circuits are often proposed as initial guesses for exploring the space of quantum states. We show that the exponential dimension of Hilbert space and the gradient estimation complexity make this choice unsuitable for hybrid quantum-classical algorithms run on more than a few qubits. Specifically, we show that for a wide class of reasonable parameterized quantum circuits, the probability that the gradient along any reasonable direction is non-zero to some fixed precision is exponentially small as a function of the number of qubits. We argue that this is related to the 2-design characteristic of random circuits, and that solutions to this problem must be studied.},
	
	number = {1},
	urldate = {2021-10-07},
	journal = {Nature Communications},
	author = {McClean, Jarrod R. and Boixo, Sergio and Smelyanskiy, Vadim N. and Babbush, Ryan and Neven, Hartmut},
	month = nov,
	year = {2018},
	pages = {4812}
}

% Global cost functions (like easuring computational basis state projectors) lead to barren platueaus
@article{cerezo_cost_2021,
	title = {Cost function dependent barren plateaus in shallow parametrized quantum circuits},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21728-w},
	doi = {10.1038/s41467-021-21728-w},
	abstract = {Variational quantum algorithms (VQAs) optimize the parameters θ of a parametrized quantum circuit V(θ) to minimize a cost function C. While VQAs may enable practical applications of noisy quantum computers, they are nevertheless heuristic methods with unproven scaling. Here, we rigorously prove two results, assuming V(θ) is an alternating layered ansatz composed of blocks forming local 2-designs. Our first result states that defining C in terms of global observables leads to exponentially vanishing gradients (i.e., barren plateaus) even when V(θ) is shallow. Hence, several VQAs in the literature must revise their proposed costs. On the other hand, our second result states that defining C with local observables leads to at worst a polynomially vanishing gradient, so long as the depth of V(θ) is \$\$\{{\textbackslash}mathcal\{O\}\}({\textbackslash}mathrm\{log\}{\textbackslash},n)\$\$. Our results establish a connection between locality and trainability. We illustrate these ideas with large-scale simulations, up to 100 qubits, of a quantum autoencoder implementation.},
	
	number = {1},
	urldate = {2022-04-21},
	journal = {Nature Communications},
	author = {Cerezo, M. and Sone, Akira and Volkoff, Tyler and Cincio, Lukasz and Coles, Patrick J.},
	month = mar,
	year = {2021},
	keywords = {Information theory and computation, Mathematics and computing, Quantum information, Quantum physics},
	pages = {1791}
}

% Seems that someone want to cite this paper, but does not appear in bibtex
@article{sack_avoiding_2022,
  doi = {10.1103/prxquantum.3.020365},
  url = {https://doi.org/10.1103/prxquantum.3.020365},
  year = {2022},
  month = jun,
  publisher = {American Physical Society ({APS})},
  volume = {3},
  number = {2},
  author = {Stefan H. Sack and Raimel A. Medina and Alexios A. Michailidis and Richard Kueng and Maksym Serbyn},
  title = {Avoiding Barren Plateaus Using Classical Shadows},
  journal = {PRX Quantum},
  pages = {020365}
}



% more expressible ansatz (closer to 2-design) leads to barren platueas



@article{arrasmith_effect_2021,
	title = {Effect of barren plateaus on gradient-free optimization},
	volume = {5},
	url = {https://quantum-journal.org/papers/q-2021-10-05-558/},
	doi = {10.22331/q-2021-10-05-558},
	abstract = {Andrew Arrasmith, M. Cerezo, Piotr Czarnik, Lukasz Cincio, and Patrick J. Coles,
Quantum 5, 558 (2021).
Barren plateau landscapes correspond to gradients that vanish exponentially in the number of qubits. Such landscapes have been demonstrated for variational quantum algorithms and quantum neu…},
	urldate = {2022-10-11},
	journal = {Quantum},
	author = {Arrasmith, Andrew and Cerezo, M. and Czarnik, Piotr and Cincio, Lukasz and Coles, Patrick J.},
	month = oct,
	year = {2021},
	pages = {558},
}

@article{ortiz_marrero_entanglement-induced_2021,
	title = {Entanglement-{Induced} {Barren} {Plateaus}},
	volume = {2},
	url = {https://link.aps.org/doi/10.1103/PRXQuantum.2.040316},
	doi = {10.1103/PRXQuantum.2.040316},
	abstract = {We argue that an excess in entanglement between the visible and hidden units in a quantum neural network can hinder learning. In particular, we show that quantum neural networks that satisfy a volume law in the entanglement entropy will give rise to models that are not suitable for learning with high probability. Using arguments from quantum thermodynamics, we then show that this volume law is typical and that there exists a barren plateau in the optimization landscape due to entanglement. More precisely, we show that for any bounded objective function on the visible layers, the Lipshitz constants of the expectation value of that objective function will scale inversely with the dimension of the hidden subsystem with high probability. We show how this can cause both gradient-descent and gradient-free methods to fail. We note that similar problems can happen with quantum Boltzmann machines, although stronger assumptions on the coupling between the hidden and/or visible subspaces are necessary. We highlight how pretraining such generative models may provide a way to navigate these barren plateaus.},
	number = {4},
	urldate = {2021-11-22},
	journal = {PRX Quantum},
	author = {Ortiz Marrero, Carlos and Kieferová, Mária and Wiebe, Nathan},
	month = oct,
	year = {2021},
	publisher = {American Physical Society},
	pages = {040316}
}

@article{larose_robust_2020,
  title = {Robust data encodings for quantum classifiers},
  author = {LaRose, Ryan and Coyle, Brian},
  journal = {Phys. Rev. A},
  volume = {102},
  issue = {3},
  pages = {032420},
  numpages = {24},
  year = {2020},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.102.032420},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.102.032420}
}

@article{wu_expressivity_2021,
  title = {Expressivity of quantum neural networks},
  author = {Wu, Yadong and Yao, Juan and Zhang, Pengfei and Zhai, Hui},
  journal = {Physical Review Research},
  volume = {3},
  issue = {3},
  pages = {L032049},
  numpages = {6},
  year = {2021},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.3.L032049},
  url = {https://link.aps.org/doi/10.1103/PhysRevResearch.3.L032049}
}

%% QUANTUM RESERVOIR COMPUTING


% quantum annealer as a qks, for classsification
@article{Noori_analogqks_2020, 
    title={Analog-Quantum Feature Mapping for Machine-Learning Applications}, volume={14}, DOI={10.1103/PhysRevApplied.14.034034}, abstractNote={Quantum information processing is likely to have a far-reaching impact in the field of artificial intelligence. Noisy, intermediate-scale quantum devices provide a platform for exploring the possibility of attaining a quantum advantage through hybrid quantum-classical machine-learning algorithms. One example of such a hybrid algorithm is “quantum kitchen sinks,” which builds upon a classical algorithm known as “random kitchen sinks” to leverage a gate model quantum computer for machine-learning applications. We propose an alternative algorithm called “analog-quantum kitchen sinks” (AQKSs), which employs an analog-quantum computer for mapping data features into new features in a nonlinear manner. The new features can then be used by a classical algorithm to perform machine-learning tasks. We show the effectiveness of our algorithm for performing binary classification on both a synthetic dataset and a real-world dataset by simulating the operations of a quantum annealer. We demonstrate that the AQKS algorithm reduces the classification error of a linear classifier from 50 to 0.6 for the synthetic dataset and from 4.4 to 1.6 for the other dataset. Our proposed AQKS algorithm presents the possibility to use current quantum annealers for solving practical machine-learning problems.}, number={3}, journal={Physical Review Applied}, publisher={American Physical Society}, author={Noori, Moslem and Vedaie, Seyed Shakib and Singh, Inderpreet and Crawford, Daniel and Oberoi, Jaspreet S. and Sanders, Barry C. and Zahedinejad, Ehsan}, year={2020}, month={Sep}, pages={034034} }

% most QRC is nonlinear
@article{govia_nonlinear_2022,
	title = {Nonlinear input transformations are ubiquitous in quantum reservoir computing},
	volume = {2},
	issn = {2634-4386},
	url = {https://doi.org/10.1088/2634-4386/ac4fcd},
	doi = {10.1088/2634-4386/ac4fcd},
	abstract = {The nascent computational paradigm of quantum reservoir computing presents an attractive use of near-term, noisy-intermediate-scale quantum processors. To understand the potential power and use cases of quantum reservoir computing, it is necessary to define a conceptual framework to separate its constituent components and determine their impacts on performance. In this manuscript, we utilize such a framework to isolate the input encoding component of contemporary quantum reservoir computing schemes. We find that across the majority of schemes the input encoding implements a nonlinear transformation on the input data. As nonlinearity is known to be a key computational resource in reservoir computing, this calls into question the necessity and function of further, post-input, processing. Our findings will impact the design of future quantum reservoirs, as well as the interpretation of results and fair comparison between proposed designs.},
	
	number = {1},
	urldate = {2022-03-21},
	journal = {Neuromorphic Computing and Engineering},
	author = {Govia, L. C. G. and Ribeill, G. J. and Rowlands, G. E. and Ohki, T. A.},
	month = feb,
	year = {2022},
	publisher = {IOP Publishing},
	keywords = {Condensed Matter - Disordered Systems and Neural Networks, Quantum Physics},
	pages = {014008},
	annote = {Comment: 9 pages, 1 figure}
}

% QRC with spins / qubits
@article{chen_temporal_2020,
	title = {Temporal {Information} {Processing} on {Noisy} {Quantum} {Computers}},
	volume = {14},
	url = {https://link.aps.org/doi/10.1103/PhysRevApplied.14.024065},
	doi = {10.1103/PhysRevApplied.14.024065},
	abstract = {The combination of machine learning and quantum computing has emerged as a promising approach for addressing previously untenable problems. Reservoir computing is an efficient learning paradigm that utilizes nonlinear dynamical systems for temporal information processing, i.e., processing of input sequences to produce output sequences. Here we propose quantum reservoir computing that harnesses complex dissipative quantum dynamics. Our class of quantum reservoirs is universal, in that any nonlinear fading memory map can be approximated arbitrarily closely and uniformly over all inputs by a quantum reservoir from this class. We describe a subclass of the universal class that is readily implementable using quantum gates native to current noisy gate-model quantum computers. Proof-of-principle experiments on remotely accessed cloud-based superconducting quantum computers demonstrate that small and noisy quantum reservoirs can tackle high-order nonlinear temporal tasks. Our theoretical and experimental results pave the path for attractive temporal processing applications of near-term gate-model quantum computers of increasing fidelity but without quantum error correction, signifying the potential of these devices for wider applications including neural modeling, speech recognition, and natural language processing, going beyond static classification and regression tasks.},
	number = {2},
	urldate = {2021-08-12},
	journal = {Physical Review Applied},
	author = {Chen, Jiayin and Nurdin, Hendra I. and Yamamoto, Naoki},
	month = aug,
	year = {2020},
	publisher = {American Physical Society},
	pages = {024065}
}



@misc{kubota_quantum_2022,
	title = {Quantum {Noise}-{Induced} {Reservoir} {Computing}},
	url = {http://arxiv.org/abs/2207.07924},
	doi = {10.48550/arXiv.2207.07924},
	abstract = {Quantum computing has been moving from a theoretical phase to practical one, presenting daunting challenges in implementing physical qubits, which are subjected to noises from the surrounding environment. These quantum noises are ubiquitous in quantum devices and generate adverse effects in the quantum computational model, leading to extensive research on their correction and mitigation techniques. But do these quantum noises always provide disadvantages? We tackle this issue by proposing a framework called quantum noise-induced reservoir computing and show that some abstract quantum noise models can induce useful information processing capabilities for temporal input data. We demonstrate this ability in several typical benchmarks and investigate the information processing capacity to clarify the framework's processing mechanism and memory profile. We verified our perspective by implementing the framework in a number of IBM quantum processors and obtained similar characteristic memory profiles with model analyses. As a surprising result, information processing capacity increased with quantum devices' higher noise levels and error rates. Our study opens up a novel path for diverting useful information from quantum computer noises into a more sophisticated information processor.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Kubota, Tomoyuki and Suzuki, Yudai and Kobayashi, Shumpei and Tran, Quoc Hoan and Yamamoto, Naoki and Nakajima, Kohei},
	month = jul,
	year = {2022},
	keywords = {Quantum Physics, Computer Science - Machine Learning, Physics - Data Analysis, Statistics and Probability},
}
@article{fujii_harnessing_2017,
	title = {Harnessing {Disordered}-{Ensemble} {Quantum} {Dynamics} for {Machine} {Learning}},
	volume = {8},
	issn = {2331-7019},
	url = {https://link.aps.org/doi/10.1103/PhysRevApplied.8.024030},
	doi = {10.1103/PhysRevApplied.8.024030},
	
	number = {2},
	urldate = {2020-08-06},
	journal = {Physical Review Applied},
	author = {Fujii, Keisuke and Nakajima, Kohei},
	month = aug,
	year = {2017},
	pages = {024030}
}

% RC and ML with physical systems

@article{Rumyantsev2020,
  doi = {10.1038/s41586-020-2130-2},
  url = {https://doi.org/10.1038/s41586-020-2130-2},
  year = {2020},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {580},
  number = {7801},
  pages = {100--105},
  author = {Oleg I. Rumyantsev and J{\'{e}}r{\^{o}}me A. Lecoq and Oscar Hernandez and Yanping Zhang and Joan Savall and Rados{\l}aw Chrapkiewicz and Jane Li and Hongkui Zeng and Surya Ganguli and Mark J. Schnitzer},
  title = {Fundamental bounds on the fidelity of sensory cortical coding},
  journal = {Nature}
}

@article{Wright2022,
  doi = {10.1038/s41586-021-04223-6},
  url = {https://doi.org/10.1038/s41586-021-04223-6},
  year = {2022},
  month = jan,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {601},
  number = {7894},
  pages = {549--555},
  author = {Logan G. Wright and Tatsuhiro Onodera and Martin M. Stein and Tianyu Wang and Darren T. Schachter and Zoey Hu and Peter L. McMahon},
  title = {Deep physical neural networks trained with backpropagation},
  journal = {Nature}
}

@article{Tanaka2019,
  doi = {10.1016/j.neunet.2019.03.005},
  url = {https://doi.org/10.1016/j.neunet.2019.03.005},
  year = {2019},
  month = jul,
  publisher = {Elsevier {BV}},
  volume = {115},
  pages = {100--123},
  author = {Gouhei Tanaka and Toshiyuki Yamane and Jean Benoit H{\'{e}}roux and Ryosho Nakane and Naoki Kanazawa and Seiji Takeda and Hidetoshi Numata and Daiju Nakano and Akira Hirose},
  title = {Recent advances in physical reservoir computing: A review},
  journal = {Neural Networks}
}

@article{nakajima_physical_2022,
	title = {Physical deep learning with biologically inspired training method: gradient-free approach for physical hardware},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	shorttitle = {Physical deep learning with biologically inspired training method},
	url = {https://www.nature.com/articles/s41467-022-35216-2},
	doi = {10.1038/s41467-022-35216-2},
	abstract = {Ever-growing demand for artificial intelligence has motivated research on unconventional computation based on physical devices. While such computation devices mimic brain-inspired analog information processing, the learning procedures still rely on methods optimized for digital processing such as backpropagation, which is not suitable for physical implementation. Here, we present physical deep learning by extending a biologically inspired training algorithm called direct feedback alignment. Unlike the original algorithm, the proposed method is based on random projection with alternative nonlinear activation. Thus, we can train a physical neural network without knowledge about the physical system and its gradient. In addition, we can emulate the computation for this training on scalable physical hardware. We demonstrate the proof-of-concept using an optoelectronic recurrent neural network called deep reservoir computer. We confirmed the potential for accelerated computation with competitive performance on benchmarks. Our results provide practical solutions for the training and acceleration of neuromorphic computation.},
	number = {1},
	urldate = {2023-07-19},
	journal = {Nature Communications},
	author = {Nakajima, Mitsumasa and Inoue, Katsuma and Tanaka, Kenji and Kuniyoshi, Yasuo and Hashimoto, Toshikazu and Nakajima, Kohei},
	month = dec,
	year = {2022},
	pages = {7847},

}

@article{wright_deep_2022,
	title = {Deep physical neural networks trained with backpropagation},
	volume = {601},
	copyright = {2022 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-04223-6},
	doi = {10.1038/s41586-021-04223-6},
	number = {7894},
	urldate = {2022-09-07},
	journal = {Nature},
	author = {Wright, Logan G. and Onodera, Tatsuhiro and Stein, Martin M. and Wang, Tianyu and Schachter, Darren T. and Hu, Zoey and McMahon, Peter L.},
	month = jan,
	year = {2022},
	keywords = {Computational science, Nonlinear optics},
	pages = {549--555}
}


@article{markovic_physics_2020,
	title = {Physics for neuromorphic computing},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5820},
	url = {https://www.nature.com/articles/s42254-020-0208-2},
	doi = {10.1038/s42254-020-0208-2},
	abstract = {Neuromorphic computing takes inspiration from the brain to create energy-efficient hardware for information processing, capable of highly sophisticated tasks. Systems built with standard electronics achieve gains in speed and energy by mimicking the distributed topology of the brain. Scaling-up such systems and improving their energy usage, speed and performance by several orders of magnitude requires a revolution in hardware. We discuss how including more physics in the algorithms and nanoscale materials used for data processing could have a major impact in the field of neuromorphic computing. We review striking results that leverage physics to enhance the computing capabilities of artificial neural networks, using resistive switching materials, photonics, spintronics and other technologies. We discuss the paths that could lead these approaches to maturity, towards low-power, miniaturized chips that could infer and learn in real time.},
	number = {9},
	urldate = {2023-07-19},
	journal = {Nature Reviews Physics},
	author = {Marković, Danijela and Mizrahi, Alice and Querlioz, Damien and Grollier, Julie},
	month = sep,
	year = {2020},
	pages = {499--510},

}

% Florian group physical learning
@article{lopez-pastor_self-learning_2021,
	title = {Self-learning {Machines} based on {Hamiltonian} {Echo} {Backpropagation}},
	url = {https://journals.aps.org/prx/abstract/10.1103/PhysRevX.13.031020},
	journal = {Physical Reveiw X},
	author = {Lopez-Pastor, Victor and Marquardt, Florian},
        volume = {13},
        pages = {031020},
	year = {2023}
}


@article{canaday_rapid_2018,
	title = {Rapid time series prediction with a hardware-based reservoir computer},
	volume = {28},
	issn = {1054-1500, 1089-7682},
	url = {http://aip.scitation.org/doi/10.1063/1.5048199},
	doi = {10.1063/1.5048199},
	abstract = {Reservoir computing is a neural network approach for processing time-dependent signals that has seen rapid development in recent years. Physical implementations of the technique using optical reservoirs have demonstrated remarkable accuracy and processing speed at benchmark tasks. However, these approaches require an electronic output layer to maintain high performance, which limits their use in tasks such as time-series prediction, where the output is fed back into the reservoir. We present here a reservoir computing scheme that has rapid processing speed both by the reservoir and the output layer. The reservoir is realized by an autonomous, time-delay, Boolean network conﬁgured on a ﬁeld-programmable gate array. We investigate the dynamical properties of the network and observe the fading memory property that is critical for successful reservoir computing. We demonstrate the utility of the technique by training a reservoir to learn the short- and long-term behavior of a chaotic system. We ﬁnd accuracy comparable to state-of-the-art software approaches of similar network size, but with a superior real-time prediction rate up to 160 MHz.},
	number = {12},
	urldate = {2020-04-16},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Canaday, Daniel and Griffith, Aaron and Gauthier, Daniel J.},
	month = dec,
	year = {2018},
	pages = {123119},
}

@article{rowlands_reservoir_2021,
	title = {Reservoir {Computing} with {Superconducting} {Electronics}},
	url = {http://arxiv.org/abs/2103.02522},
	abstract = {The rapidity and low power consumption of superconducting electronics makes them an ideal substrate for physical reservoir computing, which commandeers the computational power inherent to the evolution of a dynamical system for the purposes of performing machine learning tasks. We focus on a subset of superconducting circuits that exhibit soliton-like dynamics in simple transmission line geometries. With numerical simulations we demonstrate the effectiveness of these circuits in performing higher-order parity calculations and channel equalization at rates approaching 100 Gb/s. The availability of a proven superconducting logic scheme considerably simplifies the path to a fully integrated reservoir computing platform and makes superconducting reservoirs an enticing substrate for high rate signal processing applications.},
	urldate = {2021-07-24},
	journal = {arXiv:2103.02522 [cond-mat]},
	author = {Rowlands, Graham E. and Nguyen, Minh-Hai and Ribeill, Guilhem J. and Wagner, Andrew P. and Govia, Luke C. G. and Barbosa, Wendson A. S. and Gauthier, Daniel J. and Ohki, Thomas A.},
	month = mar,
	year = {2021},
	keywords = {Condensed Matter - Superconductivity, Computer Science - Neural and Evolutionary Computing, Physics - Applied Physics, Computer Science - Emerging Technologies}
}


@article{dong_optical_2020,
	title = {Optical {Reservoir} {Computing} {Using} {Multiple} {Light} {Scattering} for {Chaotic} {Systems} {Prediction}},
	volume = {26},
	issn = {1558-4542},
	doi = {10.1109/JSTQE.2019.2936281},
	abstract = {Reservoir Computing is a relatively recent computational framework based on a large Recurrent Neural Network with fixed weights. Many physical implementations of Reservoir Computing have been proposed to improve speed and energy efficiency. In this study, we report new advances in Optical Reservoir Computing using multiple light scattering to accelerate the recursive computation of the reservoir states. Two different spatial light modulation technologies, namely, phase or binary amplitude modulations, are compared. Phase modulation is a promising direction already employed in other photonic implementations of Reservoir Computing. Additionally, we report a Digital-Micromirror-based Reservoir Computing at up to 640 Hz, more than double the previously reported frequency using a remotely controlled optical device developed by LightOn, and present new binarization strategies to improve the performance of binarized Reservoir Computing.},
	number = {1},
	journal = {IEEE Journal of Selected Topics in Quantum Electronics},
	author = {Dong, Jonathan and Rafayelyan, Mushegh and Krzakala, Florent and Gigan, Sylvain},
	month = jan,
	year = {2020},
	pages = {1--12},
}


%probably the most relevant QRC and QELM papers

% Quantum Kitchen Sinks
@article{wilson_quantum_2019,
	title = {Quantum {Kitchen} {Sinks}: {An} algorithm for machine learning on near-term quantum computers},
	shorttitle = {Quantum {Kitchen} {Sinks}},
	url = {http://arxiv.org/abs/1806.08321},
	abstract = {Noisy intermediate-scale quantum computing devices are an exciting platform for the exploration of the power of near-term quantum applications. Performing nontrivial tasks in such devices requires a fundamentally different approach than what would be used on an error-corrected quantum computer. One such approach is to use hybrid algorithms, where problems are reduced to a parameterized quantum circuit that is often optimized in a classical feedback loop. Here we describe one such hybrid algorithm for machine learning tasks by building upon the classical algorithm known as random kitchen sinks. Our technique, called quantum kitchen sinks, uses quantum circuits to nonlinearly transform classical inputs into features that can then be used in a number of machine learning algorithms. We demonstrate the power and flexibility of this proposal by using it to solve binary classification problems for synthetic datasets as well as handwritten digits from the MNIST database. Using the Rigetti quantum virtual machine, we show that small quantum circuits provide significant performance lift over standard linear classical algorithms, reducing classification error rates from 50\% to \${\textless}0.1{\textbackslash}\%\$, and from \$4.1{\textbackslash}\%\$ to \$1.4{\textbackslash}\%\$ in these two examples, respectively. Further, we are able to run the MNIST classification problem, using full-sized MNIST images, on a Rigetti quantum processing unit, finding a modest performance lift over the linear baseline.},
	urldate = {2021-08-12},
	journal = {arXiv:1806.08321 [quant-ph]},
	author = {Wilson, C. M. and Otterbach, J. S. and Tezak, N. and Smith, R. S. and Polloreno, A. M. and Karalekas, Peter J. and Heidel, S. and Alam, M. Sohaib and Crooks, G. E. and da Silva, M. P.},
	month = nov,
	year = {2019},
	keywords = {Quantum Physics},
	annote = {Comment: 8 pages, 5 figures; v2: Added experimental results and new authors related to experimental effort}
}

%QELMs and measurement
@article{innocenti_potential_2022,
	title = {On the potential and limitations of quantum extreme learning machines},
	url = {https://www.nature.com/articles/s42005-023-01233-w},
	journal = {Communications Physics},
	author = {Innocenti, Luca and Lorenzo, Salvatore and Palmisano, Ivan and Ferraro, Alessandro and Paternostro, Mauro and Palma, Gioacchino Massimo},
        volume = {6},
        pages = {118},
	year = {2023}
}

% QRC experiment, classificaiton, role of noise, 
@article{suzuki_natural_2022,
	title = {Natural quantum reservoir computing for temporal information processing},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-05061-w},
	doi = {10.1038/s41598-022-05061-w},
	abstract = {Reservoir computing is a temporal information processing system that exploits artificial or physical dissipative dynamics to learn a dynamical system and generate the target time-series. This paper proposes the use of real superconducting quantum computing devices as the reservoir, where the dissipative property is served by the natural noise added to the quantum bits. The performance of this natural quantum reservoir is demonstrated in a benchmark time-series regression problem and a practical problem classifying different objects based on temporal sensor data. In both cases the proposed reservoir computer shows a higher performance than a linear regression or classification model. The results indicate that a noisy quantum device potentially functions as a reservoir computer, and notably, the quantum noise, which is undesirable in the conventional quantum computation, can be used as a rich computation resource.},
	number = {1},
	urldate = {2022-04-04},
	journal = {Scientific Reports},
	author = {Suzuki, Yudai and Gao, Qi and Pradel, Ken C. and Yasuoka, Kenji and Yamamoto, Naoki},
	month = jan,
	year = {2022},
	publisher = {Nature Publishing Group},
	keywords = {Computer science, Quantum physics},
	pages = {1353}
}




@article{khan_physical_2021,
	title = {Physical reservoir computing using finitely-sampled quantum systems},
	url = {http://arxiv.org/abs/2110.13849},
	abstract = {The paradigm of reservoir computing exploits the nonlinear dynamics of a physical reservoir to perform complex time-series processing tasks such as speech recognition and forecasting. Unlike other machine-learning approaches, reservoir computing relaxes the need for optimization of intra-network parameters, and is thus particularly attractive for near-term hardware-efficient quantum implementations. However, the complete description of practical quantum reservoir computers requires accounting for their placement in a quantum measurement chain, and its conditional evolution under measurement. Consequently, training and inference has to be performed using finite samples from obtained measurement records. Here we describe a framework for reservoir computing with nonlinear quantum reservoirs under continuous heterodyne measurement. Using an efficient truncated-cumulants representation of the complete measurement chain enables us to sample stochastic measurement trajectories from reservoirs of several coupled nonlinear bosonic modes under strong excitation. This description also offers a mathematical basis to directly compare the information processing capacity of a given physical reservoir operated across classical and quantum regimes. Applying this framework to the classification of Gaussian states of systems that are part of the same measurement chain as the quantum reservoir computer, we uncover its working principles and provide a detailed analysis of its performance as a function of experimentally-controllable parameters. Our results identify the vicinity of bifurcation points as presenting optimal nonlinear processing regimes of an oscillator-based quantum reservoir. The considered models are directly realizable in modern circuit QED experiments, while the framework is applicable to more general quantum nonlinear reservoirs.},
	urldate = {2021-10-27},
	journal = {arXiv:2110.13849 [quant-ph]},
	author = {Khan, Saeed Ahmed and Hu, Fangjun and Angelatos, Gerasimos and Türeci, Hakan E.},
	month = oct,
	year = {2021},
	keywords = {Quantum Physics},
	annote = {Comment: 21+15 pages, 11+5 figures, and 69 references}
}
@article{angelatos_reservoir_2021,
	title = {Reservoir {Computing} {Approach} to {Quantum} {State} {Measurement}},
	volume = {11},
	url = {https://link.aps.org/doi/10.1103/PhysRevX.11.041062},
	doi = {10.1103/PhysRevX.11.041062},
	number = {4},
	urldate = {2021-12-30},
	journal = {Physical Review X},
	author = {Angelatos, Gerasimos and Khan, Saeed A. and Türeci, Hakan E.},
	month = dec,
	year = {2021},
	publisher = {American Physical Society},
	keywords = {Condensed Matter - Disordered Systems and Neural Networks, Quantum Physics},
	pages = {041062},
	annote = {Comment: 15 pages, 7 figures, and 49 references}
}

 @article{Kalfus_2022, 
    title={Hilbert space as a computational resource in reservoir computing}, volume={4}, DOI={10.1103/PhysRevResearch.4.033007}, abstractNote={Accelerating computation with quantum resources is limited by the challenges of high-fidelity control of quantum systems. Reservoir computing presents an attractive alternative, as precise control and full calibration of system dynamics are not required. Instead, complex internal trajectories in a large state space are leveraged as a computational resource. Quantum systems offer a unique venue for reservoir computing, given the presence of interactions unavailable in classical systems and a potentially exponentially-larger computational space. With a reservoir comprised of a single d-dimensional quantum system, we demonstrate clear performance improvement with Hilbert space dimension at two benchmark tasks and advantage over the physically analogous classical reservoir. Quantum reservoirs as realized by current-era quantum hardware offer immediate practical implementation and a promising outlook for increased performance in larger systems.}, number={3}, journal={Physical Review Research}, publisher={American Physical Society}, author={Kalfus, W. D. and Ribeill, G. J. and Rowlands, G. E. and Krovi, H. K. and Ohki, T. A. and Govia, L. C. G.}, year={2022}, month={Jul}, pages={033007} }


@article{govia_quantum_2021,
	title = {Quantum reservoir computing with a single nonlinear oscillator},
	volume = {3},
	url = {https://link.aps.org/doi/10.1103/PhysRevResearch.3.013077},
	doi = {10.1103/PhysRevResearch.3.013077},
	abstract = {Realizing the promise of quantum information processing remains a daunting task given the omnipresence of noise and error. Adapting noise-resilient classical computing modalities to quantum mechanics may be a viable path towards near-term applications in the noisy intermediate-scale quantum era. Here, we propose continuous variable quantum reservoir computing in a single nonlinear oscillator. Through numerical simulation of our model we demonstrate quantum-classical performance improvement and identify its likely source: the nonlinearity of quantum measurement. Beyond quantum reservoir computing, this result may impact the interpretation of results across quantum machine learning. We study how the performance of our quantum reservoir depends on Hilbert space dimension, how it is impacted by injected noise, and briefly comment on its experimental implementation. Our results show that quantum reservoir computing in a single nonlinear oscillator is an attractive modality for quantum computing on near-term hardware.},
	number = {1},
	urldate = {2022-07-14},
	journal = {Physical Review Research},
	author = {Govia, L. C. G. and Ribeill, G. J. and Rowlands, G. E. and Krovi, H. K. and Ohki, T. A.},
	month = jan,
	year = {2021},
	publisher = {American Physical Society},
	pages = {013077}
}

% QRC review (meh)
@article{mujal_opportunities_2021,
	title = {Opportunities in {Quantum} {Reservoir} {Computing} and {Extreme} {Learning} {Machines}},
	volume = {4},
	issn = {2511-9044, 2511-9044},
	url = {http://arxiv.org/abs/2102.11831},
	doi = {10.1002/qute.202100027},
	abstract = {Quantum reservoir computing (QRC) and quantum extreme learning machines (QELM) are two emerging approaches that have demonstrated their potential both in classical and quantum machine learning tasks. They exploit the quantumness of physical systems combined with an easy training strategy, achieving an excellent performance. The increasing interest in these unconventional computing approaches is fueled by the availability of diverse quantum platforms suitable for implementation and the theoretical progresses in the study of complex quantum systems. In this review article, recent proposals and first experiments displaying a broad range of possibilities are reviewed when quantum inputs, quantum physical substrates and quantum tasks are considered. The main focus is the performance of these approaches, on the advantages with respect to classical counterparts and opportunities.},
	number = {8},
	urldate = {2022-02-24},
	journal = {Advanced Quantum Technologies},
	author = {Mujal, Pere and Martínez-Peña, Rodrigo and Nokkala, Johannes and García-Beni, Jorge and Giorgi, Gian Luca and Soriano, Miguel C. and Zambrini, Roberta},
	month = aug,
	year = {2021},
	keywords = {Quantum Physics},
	pages = {2100027}
}


%% QML without parameterized circuits

% can use algorithm to learn properties of quantum system w IBMQ demo
% better than classical processing of measurements
% uses bell measurements between copies of system as input to classical RNN
@article{huang_quantum_2022,
	title = {Quantum advantage in learning from experiments},
	volume = {376},
	url = {https://www.science.org/doi/10.1126/science.abn7293},
	doi = {10.1126/science.abn7293},
	number = {6598},
	urldate = {2022-06-23},
	journal = {Science},
	author = {Huang, Hsin-Yuan and Broughton, Michael and Cotler, Jordan and Chen, Sitan and Li, Jerry and Mohseni, Masoud and Neven, Hartmut and Babbush, Ryan and Kueng, Richard and Preskill, John and McClean, Jarrod R.},
	month = jun,
	year = {2022},
	publisher = {American Association for the Advancement of Science},
	pages = {1182--1186}
}


% Quantum Neuron for classification
@article{tacchino_quantum_2020,
	title = {Quantum implementation of an artificial feed-forward neural network},
	volume = {5},
	issn = {2058-9565},
	url = {https://doi.org/10.1088/2058-9565/abb8e4},
	doi = {10.1088/2058-9565/abb8e4},
	abstract = {Artificial intelligence algorithms largely build on multi-layered neural networks. Coping with their increasing complexity and memory requirements calls for a paradigmatic change in the way these powerful algorithms are run. Quantum computing promises to solve certain tasks much more efficiently than any classical computing machine, and actual quantum processors are now becoming available through cloud access to perform experiments and testing also outside of research labs. Here we show in practice an experimental realization of an artificial feed-forward neural network implemented on a state-of-art superconducting quantum processor using up to 7 active qubits. The network is made of quantum artificial neurons, which individually display a potential advantage in storage capacity with respect to their classical counterpart, and it is able to carry out an elementary classification task which would be impossible to achieve with a single node. We demonstrate that this network can be equivalently operated either via classical control or in a completely coherent fashion, thus opening the way to hybrid as well as fully quantum solutions for artificial intelligence to be run on near-term intermediate-scale quantum hardware.},
	
	number = {4},
	urldate = {2020-10-27},
	journal = {Quantum Science and Technology},
	author = {Tacchino, Francesco and Barkoutsos, Panagiotis and Macchiavello, Chiara and Tavernelli, Ivano and Gerace, Dario and Bajoni, Daniele},
	month = oct,
	year = {2020},
	publisher = {IOP Publishing},
	keywords = {Quantum Physics},
	pages = {044010},
	annote = {Comment: 10 pages, 5 figures}
}

% Annealing and hamiltonian based systems for QML
 @article{Coyle_quantum_born_2020, title={The Born supremacy: quantum advantage and training of an Ising Born machine}, volume={6}, rights={2020 The Author(s)}, ISSN={2056-6387}, DOI={10.1038/s41534-020-00288-9}, abstractNote={The search for an application of near-term quantum devices is widespread. Quantum machine learning is touted as a potential utilisation of such devices, particularly those out of reach of the simulation capabilities of classical computers. In this work, we study such an application in generative modelling, focussing on a class of quantum circuits known as Born machines. Specifically, we define a subset of this class based on Ising Hamiltonians and show that the circuits encountered during gradient-based training cannot be efficiently sampled from classically up to multiplicative error in the worst case. Our gradient-based training methods use cost functions known as the Sinkhorn divergence and the Stein discrepancy, which have not previously been used in the gradient-based training of quantum circuits, and we also introduce quantum kernels to generative modelling. We show that these methods outperform the previous standard method, which used maximum mean discrepancy (MMD) as a cost function, and achieve this with minimal overhead. Finally, we discuss the ability of the model to learn hard distributions and provide formal definitions for ‘quantum learning supremacy’. We also exemplify the work of this paper by using generative modelling to perform quantum circuit compilation.}, number={11}, journal={npj Quantum Information}, publisher={Nature Publishing Group}, author={Coyle, Brian and Mills, Daniel and Danos, Vincent and Kashefi, Elham}, year={2020}, month={Jul}, pages={1–11}}

% quantum boltzmann machine
 @article{Amin_quantum_boltzmann_2018, title={Quantum Boltzmann Machine}, volume={8}, ISSN={2160-3308}, DOI={10.1103/PhysRevX.8.021050}, number={2}, journal={Physical Review X}, author={Amin, Mohammad H. and Andriyash, Evgeny and Rolfe, Jason and Kulchytskyy, Bohdan and Melko, Roger}, year={2018}, month={May}, pages={021050}}

% review of diabatic quantum annealing, where dont contstrain to ground state- ie evolve under H
 @article{Crosson_Lidar_2021, 
    title={Prospects for quantum enhancement with diabatic quantum annealing}, volume={3}, rights={2021 Springer Nature Limited}, ISSN={2522-5820}, DOI={10.1038/s42254-021-00313-6}, abstractNote={Optimization, sampling and machine learning are topics of broad interest that have inspired significant developments and new approaches in quantum computing. One such approach is quantum annealing (QA). In this Review, we assess the prospects for algorithms within the general framework of QA to achieve a quantum speedup relative to classical state-of-the-art methods. We argue for continued exploration in the QA framework on the basis that improved coherence times and control capabilities will enable the near-term exploration of several heuristic quantum optimization algorithms. These continuous-time Hamiltonian computation algorithms rely on control protocols that are more advanced than those in traditional ground-state QA, while still being considerably simpler than those used in gate-model implementations. The inclusion of coherent diabatic transitions to excited states results in a generalization we refer to collectively as diabatic quantum annealing, which we believe is the most promising route to quantum enhancement within this framework. Other promising variants of traditional QA include reverse annealing, continuous-time quantum walks and analogues of parameterized quantum circuit ansatzes for machine learning. Most of these algorithms have no known efficient classical simulations, making them worthy of further investigation with quantum hardware in the intermediate-scale regime.}, number={77}, journal={Nature Reviews Physics}, publisher={Nature Publishing Group}, author={Crosson, E. J. and Lidar, D. A.}, year={2021}, month={Jul}, pages={466–489}}

% example annealing system
 @article{Onodera_Ng_McMahon_2020, title={A quantum annealer with fully programmable all-to-all coupling via Floquet engineering}, volume={6}, rights={2020 The Author(s)}, ISSN={2056-6387}, DOI={10.1038/s41534-020-0279-z}, abstractNote={Quantum annealing is a promising approach to heuristically solving difficult combinatorial optimization problems. However, the connectivity limitations in current devices lead to an exponential degradation of performance on general problems. We propose an architecture for a quantum annealer that achieves full connectivity and full programmability while using a number of physical resources only linear in the number of spins. We do so by application of carefully engineered periodic modulations of oscillator-based qubits, resulting in a Floquet Hamiltonian in which all the interactions are tunable. This flexibility comes at the cost of the coupling strengths between qubits being smaller than they would be compared with direct coupling, which increases the demand on coherence times with increasing problem size. We analyze a specific hardware proposal of our architecture based on Josephson parametric oscillators. Our results show how the minimum-coherence-time requirements imposed by our scheme scale, and we find that the requirements are not prohibitive for fully connected problems with up to at least 1000 spins. Our approach could also have impact beyond quantum annealing, since it readily extends to bosonic quantum simulators, and would allow the study of models with arbitrary connectivity between lattice sites.}, number={11}, journal={npj Quantum Information}, publisher={Nature Publishing Group}, author={Onodera, Tatsuhiro and Ng, Edwin and McMahon, Peter L.}, year={2020}, month={May}, pages={1–10}}


% MISC

% Cross talk in transmons and IBMQ

@article{sheldon_procedure_2016,
	title = {Procedure for systematically tuning up cross-talk in the cross-resonance gate},
	volume = {93},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.93.060302},
	doi = {10.1103/PhysRevA.93.060302},
	abstract = {We present improvements in both theoretical understanding and experimental implementation of the cross resonance (CR) gate that have led to shorter two-qubit gate times and interleaved randomized benchmarking fidelities exceeding 99\%. The CR gate is an all-microwave two-qubit gate that does not require tunability and is therefore well suited to quantum computing architectures based on two-dimensional superconducting qubits. The performance of the gate has previously been hindered by long gate times and fidelities averaging 94–96\%. We have developed a calibration procedure that accurately measures the full CR Hamiltonian. The resulting measurements agree with theoretical analysis of the gate and also elucidate the error terms that have previously limited gate fidelity. The increase in fidelity that we have achieved was accomplished by introducing a second microwave drive tone on the target qubit to cancel unwanted components of the CR Hamiltonian.},
	number = {6},
	urldate = {2021-04-23},
	journal = {Physical Review A},
	author = {Sheldon, Sarah and Magesan, Easwar and Chow, Jerry M. and Gambetta, Jay M.},
	month = jun,
	year = {2016},
	pages = {060302},
}


% Quantum advantage will be tough for classical tasks
% better to understand quantum learning better first, relate to classical
@article{schuld_is_2022,
	title = {Is quantum advantage the right goal for quantum machine learning?},
	url = {http://arxiv.org/abs/2203.01340},
	abstract = {Machine learning is frequently listed among the most promising applications for quantum computing. This is in fact a curious choice: Today's machine learning algorithms are notoriously powerful in practice, but remain theoretically difficult to study. Quantum computing, in contrast, does not offer practical benchmarks on realistic scales, and theory is the main tool we have to judge whether it could become relevant for a problem. In this perspective we explain why it is so difficult to say something about the practical power of quantum computers for machine learning with the tools we are currently using. We argue that these challenges call for a critical debate on whether quantum advantage and the narrative of "beating" classical machine learning should continue to dominate the literature the way it does, and provide a few examples for alternative research questions.},
	urldate = {2022-03-09},
	journal = {arXiv:2203.01340 [quant-ph]},
	author = {Schuld, Maria and Killoran, Nathan},
	month = mar,
	year = {2022},
	keywords = {Quantum Physics},
	annote = {Comment: 10 pages, 3 figures}
}


% MBL

@article{Abanin2019,
  doi = {10.1103/revmodphys.91.021001},
  url = {https://doi.org/10.1103/revmodphys.91.021001},
  year = {2019},
  month = may,
  publisher = {American Physical Society ({APS})},
  volume = {91},
  number = {2},
  author = {Dmitry A. Abanin and Ehud Altman and Immanuel Bloch and Maksym Serbyn},
  title = {$\less$i$\greater$Colloquium$\less$/i$\greater$
		: Many-body localization,  thermalization,  and entanglement},
  journal = {Reviews of Modern Physics},
  pages = {021001}
}

% unsorted

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  Citations from previous drafts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{martinez2021dynamical,
  title = {Dynamical Phase Transitions in Quantum Reservoir Computing},
  author = {Mart\'{\i}nez-Pe\~na, Rodrigo and Giorgi, Gian Luca and Nokkala, Johannes and Soriano, Miguel C. and Zambrini, Roberta},
  journal = {Physical Review Letters},
  volume = {127},
  issue = {10},
  pages = {100502},
  numpages = {7},
  year = {2021},
  month = {Aug},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.127.100502}
}



@article{chen2019learning,
  doi = {10.1007/s11128-019-2311-9},
  url = {https://doi.org/10.1007/s11128-019-2311-9},
  year = {2019},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {18},
  number = {7},
  author = {Jiayin Chen and Hendra I. Nurdin},
  title = {Learning nonlinear input{\textendash}output maps with dissipative quantum systems},
  journal = {Quantum Information Processing}
}




@article{takaki2021learning,
  title = {Learning temporal data with a variational quantum recurrent neural network},
  author = {Takaki, Yuto and Mitarai, Kosuke and Negoro, Makoto and Fujii, Keisuke and Kitagawa, Masahiro},
  journal = {Phys. Rev. A},
  volume = {103},
  issue = {5},
  pages = {052414},
  numpages = {8},
  year = {2021},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.103.052414},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.103.052414}
}

@book{nielsen2002quantum,
  title={Quantum computation and quantum information},
  author={Nielsen, Michael A and Chuang, Isaac},
  year={2010},
  publisher={Cambridge University Press},
  doi = {10.1119/1.1463744},
  url = {https://aapt.scitation.org/doi/pdf/10.1119/1.1463744}
}



@article{tropp2012user,
  doi = {10.1007/s10208-011-9099-z},
  url = {https://doi.org/10.1007/s10208-011-9099-z},
  year = {2011},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {12},
  number = {4},
  pages = {389--434},
  author = {Joel A. Tropp},
  title = {User-Friendly Tail Bounds for Sums of Random Matrices},
  journal = {Foundations of Computational Mathematics}
}

@article{grigoryeva2018echo,
  doi = {10.1016/j.neunet.2018.08.025},
  url = {https://doi.org/10.1016/j.neunet.2018.08.025},
  year = {2018},
  month = dec,
  publisher = {Elsevier {BV}},
  volume = {108},
  pages = {495--508},
  author = {Lyudmila Grigoryeva and Juan-Pablo Ortega},
  title = {Echo state networks are universal},
  journal = {Neural Networks}
}



@article{Modi2010,
  doi = {10.1103/PhysRevLett.104.080501},
  url = {https://doi.org/10.1103/physrevlett.104.080501},
  year = {2010},
  month = {feb},
  publisher = {American Physical Society},
  volume = {104},
  number = {8},
  author = {Kavan Modi and Tomasz Paterek and Wonmin Son and Vlatko Vedral and Mark Williamson},
  title = {Unified View of Quantum and Classical Correlations},
  journal = {Physical Review Letters},
  pages = {080501}
}

@article{Vedral2002,
  doi = {10.1103/RevModPhys.74.197},
  url = {https://link.aps.org/doi/10.1103/RevModPhys.74.197},
  year = {2002},
  month = {Mar},
  publisher = {American Physical Society},
  volume = {74},
  issue = {1},
  numpages = {0},
  author = {Vedral, V.},
  title = {The role of relative entropy in quantum information theory},
  journal = {Reviews of Modern Physics},
  pages = {197-234}
}


@article{Goold2015,
  doi = {10.1103/physrevb.92.180202},
  url = {https://doi.org/10.1103/physrevb.92.180202},
  year = {2015},
  month = nov,
  publisher = {American Physical Society ({APS})},
  volume = {92},
  number = {18},
  author = {J. Goold and C. Gogolin and S. R. Clark and J. Eisert and A. Scardicchio and A. Silva},
  title = {Total correlations of the diagonal ensemble herald the many-body localization transition},
  journal = {Physical Review B}
}

@article{Puchaa2017,
  doi = {10.1515/bpasts-2017-0003},
  url = {https://doi.org/10.1515/bpasts-2017-0003},
  year = {2017},
  month = feb,
  publisher = {Walter de Gruyter {GmbH}},
  volume = {65},
  number = {1},
  pages = {21--27},
  author = {Z. Pucha{\l}a and J.A. Miszczak},
  title = {Symbolic integration with respect to the Haar measure on the unitary groups},
  journal = {Bulletin of the Polish Academy of Sciences Technical Sciences}
}

@article{Wishart1949,
  doi = {10.2307/2332528},
  url = {https://doi.org/10.2307/2332528},
  year = {1949},
  month = jun,
  publisher = {{JSTOR}},
  volume = {36},
  number = {1/2},
  pages = {47},
  author = {John Wishart},
  title = {Cumulants of Multivariate Multinomial Distributions},
  journal = {Biometrika}
}

@article{Bishop1995,
  doi = {10.1162/neco.1995.7.1.108},
  url = {https://doi.org/10.1162/neco.1995.7.1.108},
  year = {1995},
  month = jan,
  publisher = {{MIT} Press - Journals},
  volume = {7},
  number = {1},
  pages = {108--116},
  author = {Chris M. Bishop},
  title = {Training with Noise is Equivalent to Tikhonov Regularization},
  journal = {Neural Computation}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    url = {https://www.deeplearningbook.org},
    year={2016}
}


@book{ShalevShwartz2014,
  doi = {10.1017/cbo9781107298019},
  url = {https://doi.org/10.1017/cbo9781107298019},
  year = {2014},
  month = may,
  publisher = {Cambridge University Press},
  author = {Shai Shalev-Shwartz and Shai Ben-David},
  title = {Understanding Machine Learning}
}

@article{boyd_fading_1985,
	title = {Fading memory and the problem of approximating nonlinear operators with {Volterra} series},
	volume = {32},
	issn = {1558-1276},
	doi = {10.1109/TCS.1985.1085649},
	abstract = {Using the notion of fading memory we prove very strong versions of two folk theorems. The first is that any time-invariant (TI) continuous nonlinear operator can be approximated by a Volterra series operator, and the second is that the approximating operator can be realized as a finite-dimensional linear dynamical system with a nonlinear readout map. While previous approximation results are valid over finite time intervals and for signals in compact sets, the approximations presented here hold for all time and for signals in useful (noncompact) sets. The discretetime analog of the second theorem asserts that any TI operator with fading memory can be approximated (in our strong sense) by a nonlinear moving- average operator. Some further discussion of the notion of fading memory is given.},
	number = {11},
	journal = {IEEE Transactions on Circuits and Systems},
	author = {Boyd, S. and Chua, L.},
	month = nov,
	year = {1985},
	keywords = {Control systems, Convolution, Fading, Fasteners, Mathematics, Nonlinear control systems, Nonlinear equations, Nonlinear systems, Operational amplifiers, Polynomials},
	pages = {1150--1161}
}


@inproceedings{GuangBinHuang,
  doi = {10.1109/ijcnn.2004.1380068},
  url = {https://doi.org/10.1109/ijcnn.2004.1380068},
  publisher = {{IEEE}},
  author = {Guang-Bin Huang and  Qin-Yu Zhu and  Chee-Kheong Siew},
  title = {Extreme learning machine: a new learning scheme of feedforward neural networks},
  booktitle = {2004 {IEEE} International Joint Conference on Neural Networks ({IEEE} Cat. No.04CH37541)},
  year = {2004}
}

@article{faisal_noise_2008,
  doi = {10.1038/nrn2258},
  url = {https://doi.org/10.1038/nrn2258},
  year = {2008},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {9},
  number = {4},
  pages = {292--303},
  author = {A. Aldo Faisal and Luc P. J. Selen and Daniel M. Wolpert},
  title = {Noise in the nervous system},
  journal = {Nature Reviews Neuroscience}
}

@article{khan_quantum_2021,
  url = {https://arxiv.org/abs/2110.13849},
  author = {Khan, Saeed Ahmed and Hu,  Fangjun and Angelatos,  Gerasimos and T\"{u}reci,  Hakan E.},
  keywords = {Quantum Physics (quant-ph),  FOS: Physical sciences,  FOS: Physical sciences},
  title = {Physical reservoir computing using finitely-sampled quantum systems},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International},
  journal = {arXiv:2110.13849 [quant-ph]}
}

@article{sannia_quantum_2022,
  journal = {arXiv:2212.12078 [quant-ph]},
  url = {https://arxiv.org/abs/2212.12078},
  author = {Sannia,  Antonio and Martínez-Peña,  Rodrigo and Soriano,  Miguel C. and Giorgi,  Gian Luca and Zambrini,  Roberta},
  keywords = {Quantum Physics (quant-ph),  FOS: Physical sciences,  FOS: Physical sciences},
  title = {Dissipation as a resource for Quantum Reservoir Computing},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Grienberger2022,
  doi = {10.1038/s43586-022-00147-1},
  url = {https://doi.org/10.1038/s43586-022-00147-1},
  year = {2022},
  month = sep,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {2},
  number = {1},
  author = {Christine Grienberger and Andrea Giovannucci and William Zeiger and Carlos Portera-Cailliau},
  title = {Two-photon calcium imaging of neuronal activity},
  journal = {Nature Reviews Methods Primers},
  pages = {67}
}



@article{Sheldon2022,
  doi = {10.1103/physreve.106.045310},
  url = {https://doi.org/10.1103/physreve.106.045310},
  year = {2022},
  month = oct,
  publisher = {American Physical Society ({APS})},
  volume = {106},
  number = {4},
  author = {Forrest C. Sheldon and Artemy Kolchinsky and Francesco Caravelli},
  title = {Computational capacity of LRC,  memristive, and hybrid reservoirs},
  journal = {Physical Review E},
  pages = {045310}
}

@inproceedings{Saade2016,
  doi = {10.1109/icassp.2016.7472872},
  url = {https://doi.org/10.1109/icassp.2016.7472872},
  year = {2016},
  month = mar,
  publisher = {{IEEE}},
  author = {A. Saade and F. Caltagirone and I. Carron and L. Daudet and A. Dremeau and S. Gigan and F. Krzakala},
  title = {Random projections through multiple optical scattering: Approximating Kernels at the speed of light},
  booktitle = {2016 {IEEE} International Conference on Acoustics,  Speech and Signal Processing ({ICASSP})}
}

@article{Lupo2021,
  doi = {10.1364/oe.433535},
  url = {https://doi.org/10.1364/oe.433535},
  year = {2021},
  month = aug,
  publisher = {Optica Publishing Group},
  volume = {29},
  number = {18},
  pages = {28257},
  author = {Alessandro Lupo and Lorenz Butschek and Serge Massar},
  title = {Photonic extreme learning machine based on frequency multiplexing},
  journal = {Optics Express}
}

@article{Canatar2021,
  doi = {10.1038/s41467-021-23103-1},
  url = {https://doi.org/10.1038/s41467-021-23103-1},
  year = {2021},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {12},
  number = {1},
  author = {Abdulkadir Canatar and Blake Bordelon and Cengiz Pehlevan},
  title = {Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks},
  journal = {Nature Communications},
  pages = {2914}
}

@article{Seung1992,
  doi = {10.1103/physreva.45.6056},
  url = {https://doi.org/10.1103/physreva.45.6056},
  year = {1992},
  month = apr,
  publisher = {American Physical Society ({APS})},
  volume = {45},
  number = {8},
  pages = {6056--6091},
  author = {H. S. Seung and H. Sompolinsky and N. Tishby},
  title = {Statistical mechanics of learning from examples},
  journal = {Physical Review A}
}

@article{Sompolinsky1990,
  doi = {10.1103/physrevlett.65.1683},
  url = {https://doi.org/10.1103/physrevlett.65.1683},
  year = {1990},
  month = sep,
  publisher = {American Physical Society ({APS})},
  volume = {65},
  number = {13},
  pages = {1683--1686},
  author = {H. Sompolinsky and N. Tishby and H. S. Seung},
  title = {Learning from examples in large neural networks},
  journal = {Physical Review Letters}
}

@article{Polloreno2022,
	title = {Limits to Reservoir Learning},
	url = {https://arxiv.org/abs/2307.14474},
	publisher = {arXiv},
	author = {Polloreno,  Anthony M.},
	month = jul,
	year = {2023},
	journal = {arXiv:2307.14474 [cs.LG]}
}