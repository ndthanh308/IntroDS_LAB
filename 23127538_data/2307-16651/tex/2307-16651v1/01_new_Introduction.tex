\section{Introduction}
Deep learning (DL) has been widely applied to many healthcare applications, such as sleep stage classification~\citep{sleep-detection}, stress detection~\citep{stree-detection}, and fitness prediction such as cardiorespiratory fitness and exercise adherence prediction~\citep{fitness-prediction,zhou_2019}.
% \cm{what is future adherence? is that exercise adherence?}\yw{fixed} 
However, the significant breakthroughs and encouraging results brought by DL are often accompanied by the need for accurate data collection under laboratory-controlled experiments and clinically verified labeling, termed as \textit{gold-standard}. 

Collecting high-quality labels (i.e., gold-standard) for healthcare applications may require extensive effort and can be particularly time-consuming. For example, developing a precise epileptic seizure diagnosis model requires electroencephalography (EEG) during ambulatory screening~\citep{seizure} for accurate brain function detection and a diagnosis from physicians or neurologists to label seizure occurrence. Consequently, most existing datasets tend to be small-scale, leading to poor performance and model generalization~\citep{Raschka-2018} when developing DL models for different cohorts. 

\mlhc{In comparison, with the widespread use of mobile and wearable devices, less accurate yet large-scale labels, referred to as \textit{silver-standard}, are available. % under free-living environments. 
For example, Heart rate or Oxygen saturation (SpO$_2$) can be easily gathered from smartwatches in daily life without clinical visits. However, these silver-standard labels, which are derived from a less accurate estimation scheme, often lead to predictions with lower accuracy, as they are often noisy and display distribution shifts compared to gold-standard labels~\citep{karimi2020}.}
% \cm{strong statement which might need to be backed up by reference.} \yw{fixed}

% For example, headbands with embedded reduced-montage dry-electroencephalographic (EEG)~\citep{dreem}, heart rate and Oxygen saturation (SpO2) sensors have gained momentum due to their affordability and high portability. 
% These ubiquitous sensors generate less-accurate but large-scale labeled datasets, which can be used with machine learning applications \hj{(e.g., cite PSG xgboost? paper)}. However, silver-standard labels are usually very noisy, and measurements obtained from less accurate sensors can cause distribution shifts compared with gold-standard labels obtained using more expensive and accurate sensors.
% The extensive data with silver-standard labels not utilized in model deployment can still be valuable. For example, polysomnography (PSG) sensors are considered the gold-standard measurement for sleep stage monitoring, but obtaining expert labeling for PSG data is time-consuming and expensive. Moreover, PSG data is mainly collected in a controlled environment with dedicated equipment and the involvement of clinicians, as shown in Figure 1. However, recent research has shown that inexpensive sensors can also be used to estimate sleep stages, albeit with lower accuracy.\hj{fix these}

% \hj{You want summarize last two paragraph? Maybe use a preamble like 'In sum,' or 'As such,' }
As such, \mlhc{gwojuedold-standard labels are crucial for the development and validation of robust clinical models. Although silver-standard labels with extensive labeling are easy to access, they usually contain noise due to less accurate collection schemes and are characterized by distribution shifts, which makes validation against gold-standard data difficult. In this paper, we answer the following question: \textit{Can we leverage large-scale noisy silver-standard datasets to improve deep learning model validation on gold-standard datasets for healthcare applications?}}

Domain adaptation (DA) is the natural candidate to solve the problem of distribution mismatch between the source (large-scale data) and target domains (small-scale data)~\citep{Patricia-2014}. Specifically, discrepancy-based and adversarial-based techniques are prevalent among recent DA methods and achieve state-of-the-art performance in image and language tasks~\citep{coral,wdgrl, Ganin-2015, Bousmalis-2016, Du-2020}. Discrepancy-based DAs seek to reduce the divergence between domains, especially the distance between two domains in the feature space, and demonstrate promising results~\citep{mmd,da_survey}. On the other hand, adversarial-based DAs employ domain discriminators to encourage domain confusion through an adversarial objective~\citep{da_survey, Ganin-2015}. \mlhc{However, these approaches mainly concentrate on large-scale and gold-standard source labels to adapt to unlabeled target data, while neglecting the fact that the source domain might contain noisy silver-standard labels.}
% This does not apply in the context of wearable healthcare applications where data
% \cm{you mean labelled data? otherwise it's unclear what the difference is. this might need rephrasing} \ yw{fixed}are abundant but noisy.


In this paper, we present \systemname{} and target the \textit{label distribution} shift problem from noisy labeled but large-scale source domains caused by less accurate data collection schemes to target domains with small-scale gold-standard labels. Our proposed framework is inspired by adversarial-based DA methods, which often contain a specific discriminator that categorizes the source or target domains from which samples originate. However, compared to existing approaches that mainly focus on discriminating domains as a binary classification task, \systemname{} captures the fine-grained information that resides within the label distribution shifts. To achieve this, we introduce a fine-grained discriminator that attempts to discriminate the distribution of domain labels, thereby capturing domain-invariant feature representation learning. As a result, through a multi-discriminator learning scheme, \systemname{} can effectively learn cross-domain representation by integrating both coarse-grained and fine-grained domain information, resulting in promising performance on small-scale datasets. 

% \yw{I put the details of CRF in section 3}
\mlhc{We practically demonstrate the potential of \systemname{} in the context of healthcare data by applying it to cardiorespiratory fitness (CRF) prediction. CRF is a significant predictor of cardiovascular disease (CVD)~\citep{predictor}, one of the leading causes of death globally~\citep{Kaptoge2019}. CRF is directly measured by maximal oxygen consumption (VO$_2$max), which is assessed using heart rate responses to standard maximal exercises test (i.e., gold-standard). However, collecting VO$_{2}$max labels through such tests is difficult and expensive and needs extra equipment and clinical monitoring. Alternatively, submaximal VO$_{2}$max tests~\citep{gonzales2020submaximal} have been proposed to capture fitness levels. Despite their potential, such measurements have been shown to provide silver-standard labels with lower accuracy and a shift in distribution compared with gold-standard VO$_{2}$max.}
% Since it requires specific equipment such as treadmills and face masks with a computerized gas analysis system to monitor ventilation and expired gas fractions \hj{cf. Appx.}, as shown in Figure~\ref{fig:workflow}. Clearly, this is not practical for particular groups\hj{cohorts}, such as the elderly.}

% Alternatively, submaximal VO$_{2}$max tests~\citep{gonzales2020submaximal} have been proposed to capture fitness levels. Despite their potential, such measurements have been shown to have a prediction bias ranging from -3.0 to -1.6 ml O2/\textit{min}/\textit{kg} and a Pearsonâ€™s r ranging from 0.57 to 0.79~\citep{gonzales2020submaximal} compared to the gold-standard estimation. Therefore, this leads to silver-standard labels with lower accuracy and a shift in distribution compared with expert labels.

\mlhc{In this paper, we validate the power of silver-standard VO$_{2}$max to enhance the precision of fitness predictions by mitigating distribution shifts using the proposed \systemname{}. Specifically, we apply \systemname{} on a large CRF datasets~\citep{feland,bvs} and show that \systemname{} achieves the SOTA performance.} Our contributions are summarized as follows:
\begin{itemize}
    \item We propose a novel domain adaptation framework via multi-discriminator adversarial training, which incorporates samples from different distributions and allows us to learn better feature representations for (often small) gold-standard datasets.
    
    \item 
    % We perform extensive experiments on the fitness prediction task using \systemname{} by building pre-trained models on physiological signals derived from wearable sensors in the source domain and show effectiveness in addressing domain shift problems in the target domain. \imt{Furthermore, we stress-test our models with semi-synthetic data under various label shifts to show and test for robustness. }
    % \cm{I wonder if this bullet could be rephrased by highlighting the application more and the impact on the application}\yw{fixed}
    \mlhc{In the CRF prediction task, gold-standard VO$_{2}$max are hard to get and silver-standard labels display domain shift problems. We are able to address the domain shift problem using \systemname{}, significantly improving the prediction accuracy in the target domain}. Furthermore, we stress-test our models with semi-synthetic data under various label shifts to show and test for robustness.
    
    \item 
    % Our extensive experiments demonstrate that \systemname{} achieves strong results (corr = 0.701 $\pm$ 0.032) and improves model performance up to 12.0\% compared to baselines on the CRF tasks. 
    Through a set of extensive experiments, we show that \systemname{} achieves strong results (corr = 0.701 $\pm$ 0.032) and improves model performance up to 12.0\% compared to baselines on the CRF tasks. These results show that the proposed model is able to improve fitness prediction by only leveraging large-scale silver-standard labels. 
    
    % \cm{talk about the implications on the CRF task...and impact}\yw{fixed}
    % Our model also shows better interpretability when we visualize the regression activation map, compared to baselines such as TF. 
    % This motivates the use of \systemname{} on silver-standard data for accurate VO$_{2}$max prediction.\cm{cut this last sentence: does not add much?}\yw{fixed}
\end{itemize}

\subsection*{Generalizable Insights about Machine Learning in the Context of Healthcare}
%maybe staring from silver, mention the importance of the silver-standard labels... 
\mlhc{In healthcare, high-quality datasets with gold-standard labels are expensive and hard to collect, leading to sparse and small-scale datasets that make it difficult to generalize to other unseen cohorts and applications. In contrast, collecting silver-standard labels from less accurate collection schemes with modern wearables is more affordable. However, these extensive less-accurate labels exhibit distribution discrepancies when compared to ground truth and cannot be directly leveraged for model deployment. Our work addresses this by introducing a multi-discriminator domain adaptation method for cross-domain representation learning, which transfers knowledge from large-scale weakly labeled data to small-scale health datasets with gold-standard labels. Specifically, in the context of CRF prediction, our results demonstrate that leveraging large-scale noisy VO${2}$max labels using \systemname{} not only achieves improved fitness prediction but also effectively mitigates label distribution shifts. This paves the way for the practical application of machine learning for real-world health outcomes. Furthermore, our approach can be easily adapted to various health-related tasks, particularly those involving high-dimensional time-series data and changes in label distribution for regression tasks.}








