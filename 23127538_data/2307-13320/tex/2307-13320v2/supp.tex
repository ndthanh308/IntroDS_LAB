% \documentclass[aps,prb,twocolumn,9pt,preprint,onecolumn]{article} %one column version
%\documentclass[twoside,twocolumn,9pt]{article}

\documentclass[aps,prl,nobibnotes,onecolumn,11pt,superscriptaddress,citeautoscript,showkeys]{revtex4-2}

\pdfoutput=1
\usepackage{graphicx}
\usepackage{amsmath, amsfonts}
\usepackage{amssymb}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{float}

\usepackage{fancyhdr}
\pagestyle{fancy}

\renewcommand{\thefigure}{S\arabic{figure}}

\renewcommand{\citenumfont}[1]{S#1}
\renewcommand{\bibnumfmt}[1]{[S#1]}

\renewcommand{\andname}{\ignorespaces}

\makeatletter
\def\@hangfrom@section#1#2#3{\@hangfrom{#1#2}#3}%\MakeTextUppercase{#3}}%
\def\@hangfroms@section#1#2{#1#2}%\MakeTextUppercase{#2}}%
\makeatother

\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thepage}{S\arabic{page}}

\begin{document}

\title{Neural information processing and time-series prediction with only two dynamical memristors\\ \vspace{0.5cm}
Supplementary Information \vspace{0.2cm}}

\author{Dániel Molnár}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}
\affiliation{ELKH-BME Condensed Matter Research Group, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}

\author{Tímea Nóra Török}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}
\affiliation{Institute of Technical Physics and Materials Science,\unpenalty~Centre for Energy Research, Konkoly-Thege M. \'{u}t 29-33, 1121 Budapest, Hungary.\looseness=-1}

\author{János Volk Jr.}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}

\author{Roland Kövecs}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}

\author{László Pósa}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}
\affiliation{Institute of Technical Physics and Materials Science,\unpenalty~Centre for Energy Research, Konkoly-Thege M. \'{u}t 29-33, 1121 Budapest, Hungary.\looseness=-1}

\author{Péter Balázs}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}

\author{György Molnár}
\affiliation{Institute of Technical Physics and Materials Science,\unpenalty~Centre for Energy Research, Konkoly-Thege M. \'{u}t 29-33, 1121 Budapest, Hungary.\looseness=-1}

\author{Nadia Jimenez Olalla}
\affiliation{Institute of Electromagnetic Fields, ETH Zurich, Gloriastrasse 35, 8092 Zurich, Switzerland.\looseness=-1}

\author{Zoltán Balogh}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}
\affiliation{ELKH-BME Condensed Matter Research Group, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}

\author{János Volk}
\affiliation{Institute of Technical Physics and Materials Science,\unpenalty~Centre for Energy Research, Konkoly-Thege M. \'{u}t 29-33, 1121 Budapest, Hungary.\looseness=-1}


\author{Juerg Leuthold}
\affiliation{Institute of Electromagnetic Fields, ETH Zurich, Gloriastrasse 35, 8092 Zurich, Switzerland.\looseness=-1}

\author{Miklós Csontos}
\affiliation{Institute of Electromagnetic Fields, ETH Zurich, Gloriastrasse 35, 8092 Zurich, Switzerland.\looseness=-1}

\author{András Halbritter}\email{halbritter.andras@ttk.bme.hu}
\affiliation{Department of Physics, Institute of Physics, Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}
\affiliation{ELKH-BME Condensed Matter Research Group, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\looseness=-1}


\maketitle
\thispagestyle{fancy}
\lhead[]{Supplementary Information}
\rhead[]{}

\newpage

\setcounter{secnumdepth}{1}


\section{Sample fabrication}

The 10~nm thick Ti adhesive layer and the 40~nm thick Pt bottom electrode of the Ta/Ta$_{2}$O$_{5}$/Pt memristor were subsequently deposited on a 280~nm thick SiO$_{2}$ substrate by electron beam evaporation at a base pressure of 10$^{-7}$~mbar at a rate of 0.1~nm/s. The 5~nm thick Ta$_{2}$O$_{5}$ layers were sputtered by reactive high-power impulse magnetron sputtering (HiPIMS) from a Ta target at 6~mTorr pressure, 45~sccm Ar and 5~sccm O$_{2}$ flow rates and 250~W RF power. The thickness and stoichiometric composition of the Ta$_{2}$O$_{5}$ layer were confirmed by XPS spectroscopy. The Ta top electrode and its Pt cap were sputtered on top of the Ta$_{2}$O$_{5}$ film at 4~mTorr pressure, 45~sccm Ar flow and 250~W RF power / 125~W dc power for Ta / Pt, preventing the formation of a native oxide layer at the Ta$_{2}$O$_{5}$/Ta interface. The 2.5~$\mu$m wide bottom and top electrodes were patterned by standard optical lithography and lift-off.

The VO$_{2}$ films were created by the post-deposition heat treatment of a Si/SiO$_{2}$/V structure, where the SiO$_{2}$ / V thickness was 1~$\mu$m / 100~nm. The heat treatment was carried out in air at 400~$^{\circ}$C temperature and 0.1~mbar pressure over 4.5~hours, resulting in a 180~nm thick V$_{2}$O$_{5}$ bottom layer and a 40~nm thick VO$_{2}$ top layer as verified by cross-sectional TEM and EELS analyses \cite{Posa2023}. The metal electrodes consisting of a 10~nm thick Ti adhesion layer and a 50~nm thick Au film were patterned by standard electron-beam lithography and deposited by electron-beam evaporation at 10$^{-7}$~mbar base pressure at rates of 0.1~nm/s and 0.4~nm/s, respectively, followed by lift-off.

\section{Switching dynamics simulation of the Ta$_2$O$_5$ detector circuit}

% Figure environment removed



Figure~\ref{fig7} shows the results of the simulations in comparison with selected experimental $I(V)$ traces of the Ta$_{2}$O$_{5}$ memristor in series with $R_{\rm s,T}$=1~k$\Omega$. The individual simulated traces in Figs.~\ref{fig7}(a) and (b) illustrate the onset of nonvolatile resistive switching as the $V_{\rm drive}^{0}$ is linearly increased at a constant $f_{\rm drive}$ or, alternatively, as $f_{\rm drive}$ is exponentially decreased at a constant $V_{\rm drive}^{0}$. The color-scale plot in Fig.~\ref{fig7}(c) displays the $R_{\rm HRS}/R_{\rm LRS}$ resistance ratio deduced from the zero-bias slopes of the simulated $I(V)$ traces for the experimentally relevant 1.2~V$<V_{\rm drive}^{0}<$1.7~V voltage interval. Note, that while the latter covers a $\approx$40\% variation the $f_{\rm drive}$ driving frequency spans over 5 orders of magnitude. The colored empty circles in Fig.~\ref{fig7}(c) label the driving parameters of the measured $I(V)$ traces shown in the corresponding colors in Fig.~\ref{fig7}(d). The measured $I(V)$ characteristics in Fig.~\ref{fig7}(d) unambiguously confirm that achieving an identical $R_{\rm HRS}/R_{\rm LRS}$ resistance ratio at linearly increasing voltage requires an exponentially increasing frequency. In the experiment, a constant $R_{\rm HRS}/R_{\rm LRS}\approx$1.5 ratio was chosen, representing the onset of resistive switching. We explored those $V_{\rm drive}^{0}$ and $f_{\rm drive}$ settings which reproduced this ratio. Finally, the simulation parameters were optimized at $A$=0.088~V and $B$=1.06~V by finding the best match between the simulated and measured $I(V)$ traces throughout the investigated $V_{\rm drive}^{0}$\,--\,$f_{\rm drive}$ plane.


\section{The implementation of the neural circuit}

% Figure environment removed

The artificial neural circuit consists of two main parts. Its detailed schematic including peripheral instruments is shown in Fig.~\ref{fig8}. The Ta$_2$O$_5$ module (red) is responsible for the detection of the neural spikes in the input signal. The VO$_2$ oscillator module (blue) generates the output spikes. The $V_{\rm drive}$ input voltage pattern of the neuron circuit is provided by adding the off-set spiking output of a Rigol DG5252 arbitrary waveform generator (AWG) and the noise output of a Siglent SDG1050 AWG via a LeCroy DA1850A differential amplifier. $V_{\rm drive}$ is independently recorded at channel B of a Picoscope 6424E digital storage oscilloscope (DSO). The output of the detector module, i.e., the voltage on the $R_{\rm s,T}$ series resistor, is measured via a Femto DLPCA-200 current amplifier (red) at channel C of the DSO. The operation point of the oscillator module is set by the constant voltage output of an Agilent 33220A AWG unit. This constant voltage and the voltage output of the detector module are added and amplified via a Tektronix AM502 differential amplifier (red-blue). Additionally, this unit also incorporates a 100~Hz low-pass filter to remove the noise from the input signal of the oscillator module, greatly improving the reliability of the latter. The output of the oscillator module, i.e., the voltage on the $R_{\rm s,V}$ series resistor, is measured via a second Femto DLPCA-200 current amplifier (blue) at channel A of the DSO. The feedback coupling (black) is incorporated to reset the neural circuit after a detection event, enabling continuous operation. It is implemented through an SRS SR-235 amplifier located at the input of the circuit (red). This unit amplifies the output of the oscillator module and adds it to the input signal of the detector module with a negative polarity. The gain of the feedback must be optimized to match the device characteristics of the Ta$_{2}$O$_{5}$ memristor. A too strong reset pulse increases the risk that the detector circuit will idle in a too high $R_{\rm HRS}$ or exhibit only a smaller, short-lived resistance change upon the arrival of the next neural spike. In contrast, when the gain of the coupling is too low, a single reset pulse may not be sufficient to restore the optimal HRS. Consequently, a single neural spike detection event triggers multiple output spikes.



The circuit with the global feedback resets the detector module autonomously, i.e., this circuit can be fed with a continuous input stream. In our analysis we applied a $50\,$s long input stream of white noise including $50$ Gaussian spikes with $1\,$s repetition rate. Fig. 5(e) demonstrates $10$ different segments of this continuous input stream. The $98\,\%$ detection accuracy was evaluated from the entire stream which was divided to $100$ segments from which 50 (50) segments include (exclude) a Gaussian spike. At the optimized feedback conditions we found that a single output spike of the oscillator circuit was sufficient to reset the Ta$_2$O$_5$ detector module in 46 out of the 50 cases. The low pass filter between the detector and the oscillator module, however, delayed the switch-off of the oscillator circuit yielding multiple output spikes in a portion of the measurements. This delay yielded $1.88$ output spikes on average for the $50$ segments with a Gaussian input spike. 

{\section{{Neural spike detection accuracy at different signal-to-noise ratios}}}

{We have tested the accuracy of neural spike detection at different signal-to-noise ratios (Fig.~\ref{fig81}). The middle panel (Fig.~\ref{fig81}b) represents the measurement also demonstrated in the main text (Fig.~4f in the main text), where the spike amplitude normalized to the rms noise value is $V_\mathrm{spike}/V_\mathrm{rmsnoise}=2$. Note, that this is already a rather small signal-to-noise ratio, where the amplitude of noise peaks frequently exceeds that of the neural spike. The left panel (Fig.~\ref{fig81}a) demonstrates a significantly smaller signal-to-noise ratio ($V_\mathrm{spike}/V_\mathrm{rmsnoise}=1.3$), where the neural spike is visually hardly distinguishable from the largest noise spikes. In this case the detection accuracy decreases to $75\%$, which is still much better than random guess ($\approx 50\%$  detection accuracy). The right panel (Fig.~\ref{fig81}b) demonstrates a larger signal-to-noise ratio ($V_\mathrm{spike}/V_\mathrm{rmsnoise}=2.3$), where also a high, $99\%$ detection accuracy is obtained. The evaluation protocol is same in the three cases, relying on the analysis on 50 time-traces with neural spikes and 50 time-traces without neural spikes. }

% Figure environment removed

\section{{Time series prediction with two memristors: driving scheme and detailed prediction results}}

{For the time-series prediction task we have generated the $u_\mathrm{training}(k)$ (Fig.~\ref{fig9}a) and $u_\mathrm{validation}(k)$ (Fig.~\ref{fig9}b) training and validation input data sets, both including 300 uniformly distributed random numbers. From these numbers the training and validation waveforms were generated with a Rigol DG5252 arbitrary waveform generator following the scheme in Fig.~\ref{fig10}. The $V_\mathrm{in1}(k)=V_\mathrm{in2}(k)=u(k)\cdot a + b$ input voltages (see Fig.~6a in the main text) are encoded in the amplitudes of the positive voltage pulses in the 1$^\mathrm{st}$ $1\,$ms long segment of the $3\,$ms long driving period, afterwards a $1\,$ms long readout voltage is applied ($V_\mathrm{readout}=200\,$mV), and finally a negative $V_\mathrm{offset1}$ or $V_\mathrm{offset2}$ offset voltage is applied to induce forgetting. Figure \ref{fig10} illustrates the first three periods of the driving sequence applied on the first input channel of the memristive circuit. Both input channels are driven by this scheme applying different $V_\mathrm{offset1}$ and $V_\mathrm{offset2}$ offset voltages.  The $V_\mathrm{out1}(k)$ and $V_\mathrm{out2}(k)$ output voltages are evaluated as the average output voltage measured along the given readout voltage segment.}

% Figure environment removed

% Figure environment removed

{In our analysis we measure the response of both memristive channels to both the training and the validation waveforms. The response to the training waveform is used to find the optimized offset values. At a certain $V_\mathrm{offset1}, V_\mathrm{offset2}$  setting the most predictive linear combination of the two physical output channels (i.e. the optimal $w_1, w_2$ and $o$ values) are determined in software using the Adam optimization algorithm, similarly to {Ref.~\citenum{Du2017}} . Finally, the best performing $V_\mathrm{offset1}, V_\mathrm{offset2}$ pair is chosen. Fig.~\ref{fig11}a demonstrates the predicted output stream ($y_\mathrm{predicted}(k)$, red circles) in response to the training waveform using the optimized offset value pair. This is compared to the true $y(k)$ output of the mathematical dynamical system (black line). Following the protocol in {Ref.~\citenum{Du2017}}, we drop the first 50 points from the analysis (red region in the figure), where the $y(k)$ true output of the mathematical dynamical system exhibits an initial transient. This means, that the normalized means squared error is calculated for the last 250 points of the output datastream. For the measurement demonstrated in Fig.~\ref{fig11}a this yields an NMSE$_\mathrm{training}=3.09\cdot10^{-3}$ normalized prediction error. Fig.~\ref{fig11}b represents the predicted output of the same two memristors using the settings optimized along the training process, but measuring the prediction error in response to the independent validation dataset. This figure shows the total measurement from the same data,
of which a shorter, more visible section is shown in Fig.~6b in the main text. Again, the last 250 points are used to evaluate the error, yielding NMSE$_\mathrm{validation}=3.03\cdot10^{-3}$.}

% Figure environment removed

{To explore the possibility for further improvement of the prediction error, a different approach was also applied. The time-series prediction operation was tested spanning an even broader parameter set, such that the programming dynamics was also independently adjustable for the two channels, i.e., different $V_\mathrm{in1}(k)=a_1\cdot u(k) +b_1$ and $V_\mathrm{in2}(k)=a_2\cdot u(k) +b_2$ scaling parameters were applied. Meanwhile, the $V_\mathrm{offset1},V_\mathrm{offset2}$ parameters (i.e. the forgetting dynamics) were scanned with an even finer resolution around the optimal parameter values. In this case, however, solely the response of a single memristor was tested at $100$ different parameters sets. From these response curves we have assembled the combined response of the two memristive channels in software, testing all the $10^4$ possible parameter pairs. With this approach a further improved performance was achieved yielding NMSE$_\mathrm{training}=2.79\cdot10^{-3}$ and NMSE$_\mathrm{validation}=2.47\cdot10^{-3}$.}

% Figure environment removed




%% Figure environment removed

%\section{Extension of the proposed temporal information processing architecture with an arbitrary number of independently adjustable input modules}

%Next, we envision the generalization of the proposed scheme (Fig.~\ref{Fig13}). Due to the simplicity of the design, the system can be extended with arbitrary memristor - series resistor pairs. These $N$ memristive channels perform the essential dynamical  signal processing, so that the dynamics of each channel can be adjusted separately through the $V_\mathrm{offset1}..V_\mathrm{offsetN}$ offset values. These input channels can be fed by the same temporal input signal stream (like in Fig.~6a in the main text), so that the various memristive units are senzitized to different dynamical aspects of the input signal. Moreover, the $N$ memristive channels may also receive multichannel temporal input streams ($V_\mathrm{in1}..V_\mathrm{inN}$, see Fig.~\ref{Fig13}), such that the individual memristors (or smaller groups of memristive channels) analyze a certain input channel. The final readout layer is also not restricted to the most simple linear combination of the $V_\mathrm{out1}..V_\mathrm{outN}$ output voltages, which produces a single output stream. Alternatively the readout layer may include perceptrons or simple few-layer feedforward neural networks, also permitting multiple output channels. 

%We argue that such generalized architectures are applicable for more complex temporal signal recognition or signal analysis tasks. This design grabs the general idea of reservoir computing architectures: the dynamical reservoir projects pre-processed time-domain features from the input to a relatively simple output readout layer, and thereby the system complexity is sqeezed to the complex dynamical operation of the reservoir layer. In our proposed scheme the complex but ill-controlled dynamical operation of a fully hardware-encoded physical reservoir is replaced by a dynamical circuit with detailed control over the dynamical properties.  




%% Figure environment removed

%\section{Material and voltage dependence of the switching dynamics}

%% Figure environment removed

\bibliographystyle{achemso}
\bibliography{ReferencesSupp}

\end{document}