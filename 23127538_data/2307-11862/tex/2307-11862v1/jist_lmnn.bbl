% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{lecun1989backpropagation}
Y.~LeCun, B.~Boser, J.~S. Denker, D.~Henderson, R.~E. Howard, W.~Hubbard, and
  L.~D. Jackel, ``Backpropagation applied to handwritten zip code
  recognition,'' \emph{Neural computation}, vol.~1, no.~4, pp. 541--551, 1989.

\bibitem{krizhevsky2017imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' \emph{Communications of the ACM},
  vol.~60, no.~6, pp. 84--90, 2017.

\bibitem{li2014medical}
Q.~Li, W.~Cai, X.~Wang, Y.~Zhou, D.~D. Feng, and M.~Chen, ``Medical image
  classification with convolutional neural network,'' in \emph{2014 13th
  international conference on control automation robotics \& vision
  (ICARCV)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2014, pp. 844--848.

\bibitem{jha2020doubleu}
D.~Jha, M.~A. Riegler, D.~Johansen, P.~Halvorsen, and H.~D. Johansen,
  ``Doubleu-net: A deep convolutional neural network for medical image
  segmentation,'' in \emph{2020 IEEE 33rd International symposium on
  computer-based medical systems (CBMS)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2020, pp. 558--564.

\bibitem{ronneberger2015u}
O.~Ronneberger, P.~Fischer, and T.~Brox, ``U-net: Convolutional networks for
  biomedical image segmentation,'' in \emph{Medical Image Computing and
  Computer-Assisted Intervention--MICCAI 2015: 18th International Conference,
  Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2015, pp. 234--241.

\bibitem{chauhan2018convolutional}
R.~Chauhan, K.~K. Ghanshala, and R.~Joshi, ``Convolutional neural network (cnn)
  for image detection and recognition,'' in \emph{2018 first international
  conference on secure cyber computing and communication (ICSCCC)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 278--282.

\bibitem{redmon2016you}
J.~Redmon, S.~Divvala, R.~Girshick, and A.~Farhadi, ``You only look once:
  Unified, real-time object detection,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2016, pp. 779--788.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  transformer: Hierarchical vision transformer using shifted windows,'' in
  \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 10\,012--10\,022.

\bibitem{wang2021pyramid}
W.~Wang, E.~Xie, X.~Li, D.-P. Fan, K.~Song, D.~Liang, T.~Lu, P.~Luo, and
  L.~Shao, ``Pyramid vision transformer: A versatile backbone for dense
  prediction without convolutions,'' in \emph{Proceedings of the IEEE/CVF
  international conference on computer vision}, 2021, pp. 568--578.

\bibitem{liu2022convnet}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie, ``A convnet
  for the 2020s,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 11\,976--11\,986.

\bibitem{ding2022scaling}
X.~Ding, X.~Zhang, J.~Han, and G.~Ding, ``Scaling up your kernels to 31x31:
  Revisiting large kernel design in cnns,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp.
  11\,963--11\,975.

\bibitem{liu2022more}
S.~Liu, T.~Chen, X.~Chen, X.~Chen, Q.~Xiao, B.~Wu, M.~Pechenizkiy, D.~Mocanu,
  and Z.~Wang, ``More convnets in the 2020s: Scaling up kernels beyond 51x51
  using sparsity,'' \emph{arXiv preprint arXiv:2207.03620}, 2022.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE conference on computer vision
  and pattern recognition}, 2016, pp. 770--778.

\bibitem{xiao2017fashion}
H.~Xiao, K.~Rasul, and R.~Vollgraf, ``Fashion-mnist: a novel image dataset for
  benchmarking machine learning algorithms,'' \emph{arXiv preprint
  arXiv:1708.07747}, 2017.

\bibitem{coates2011analysis}
A.~Coates, A.~Ng, and H.~Lee, ``An analysis of single-layer networks in
  unsupervised feature learning,'' in \emph{Proceedings of the fourteenth
  international conference on artificial intelligence and statistics}.\hskip
  1em plus 0.5em minus 0.4em\relax JMLR Workshop and Conference Proceedings,
  2011, pp. 215--223.

\bibitem{chollet2017xception}
F.~Chollet, ``Xception: Deep learning with depthwise separable convolutions,''
  in \emph{Proceedings of the IEEE conference on computer vision and pattern
  recognition}, 2017, pp. 1251--1258.

\bibitem{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich, ``Going deeper with convolutions,'' in
  \emph{Proceedings of the IEEE conference on computer vision and pattern
  recognition}, 2015, pp. 1--9.

\bibitem{szegedy2016rethinking}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna, ``Rethinking the
  inception architecture for computer vision,'' in \emph{Proceedings of the
  IEEE conference on computer vision and pattern recognition}, 2016, pp.
  2818--2826.

\bibitem{peng2017large}
C.~Peng, X.~Zhang, G.~Yu, G.~Luo, and J.~Sun, ``Large kernel matters--improve
  semantic segmentation by global convolutional network,'' in \emph{Proceedings
  of the IEEE conference on computer vision and pattern recognition}, 2017, pp.
  4353--4361.

\bibitem{hu2019local}
H.~Hu, Z.~Zhang, Z.~Xie, and S.~Lin, ``Local relation networks for image
  recognition,'' in \emph{Proceedings of the IEEE/CVF International Conference
  on Computer Vision}, 2019, pp. 3464--3473.

\bibitem{iandola2014densenet}
F.~Iandola, M.~Moskewicz, S.~Karayev, R.~Girshick, T.~Darrell, and K.~Keutzer,
  ``Densenet: Implementing efficient convnet descriptor pyramids,'' \emph{arXiv
  preprint arXiv:1404.1869}, 2014.

\bibitem{huang2018condensenet}
G.~Huang, S.~Liu, L.~Van~der Maaten, and K.~Q. Weinberger, ``Condensenet: An
  efficient densenet using learned group convolutions,'' in \emph{Proceedings
  of the IEEE conference on computer vision and pattern recognition}, 2018, pp.
  2752--2761.

\bibitem{howard2017mobilenets}
A.~G. Howard, M.~Zhu, B.~Chen, D.~Kalenichenko, W.~Wang, T.~Weyand,
  M.~Andreetto, and H.~Adam, ``Mobilenets: Efficient convolutional neural
  networks for mobile vision applications,'' \emph{arXiv preprint
  arXiv:1704.04861}, 2017.

\bibitem{zhang2018shufflenet}
X.~Zhang, X.~Zhou, M.~Lin, and J.~Sun, ``Shufflenet: An extremely efficient
  convolutional neural network for mobile devices,'' in \emph{Proceedings of
  the IEEE conference on computer vision and pattern recognition}, 2018, pp.
  6848--6856.

\bibitem{cheng2018model}
Y.~Cheng, D.~Wang, P.~Zhou, and T.~Zhang, ``Model compression and acceleration
  for deep neural networks: The principles, progress, and challenges,''
  \emph{IEEE Signal Processing Magazine}, vol.~35, no.~1, pp. 126--136, 2018.

\bibitem{vanhoucke2011improving}
V.~Vanhoucke, A.~Senior, and M.~Z. Mao, ``Improving the speed of neural
  networks on cpus,'' 2011.

\bibitem{chen2015compressing}
W.~Chen, J.~Wilson, S.~Tyree, K.~Weinberger, and Y.~Chen, ``Compressing neural
  networks with the hashing trick,'' in \emph{International conference on
  machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2015, pp.
  2285--2294.

\bibitem{srinivas2015data}
S.~Srinivas and R.~V. Babu, ``Data-free parameter pruning for deep neural
  networks,'' \emph{arXiv preprint arXiv:1507.06149}, 2015.

\bibitem{han2015learning}
S.~Han, J.~Pool, J.~Tran, and W.~Dally, ``Learning both weights and connections
  for efficient neural network,'' \emph{Advances in neural information
  processing systems}, vol.~28, 2015.

\bibitem{he2017channel}
Y.~He, X.~Zhang, and J.~Sun, ``Channel pruning for accelerating very deep
  neural networks,'' in \emph{Proceedings of the IEEE international conference
  on computer vision}, 2017, pp. 1389--1397.

\bibitem{gong2014compressing}
Y.~Gong, L.~Liu, M.~Yang, and L.~Bourdev, ``Compressing deep convolutional
  networks using vector quantization,'' \emph{arXiv preprint arXiv:1412.6115},
  2014.

\bibitem{wu2016quantized}
J.~Wu, C.~Leng, Y.~Wang, Q.~Hu, and J.~Cheng, ``Quantized convolutional neural
  networks for mobile devices,'' in \emph{Proceedings of the IEEE conference on
  computer vision and pattern recognition}, 2016, pp. 4820--4828.

\bibitem{liu2021post}
Z.~Liu, Y.~Wang, K.~Han, W.~Zhang, S.~Ma, and W.~Gao, ``Post-training
  quantization for vision transformer,'' \emph{Advances in Neural Information
  Processing Systems}, vol.~34, pp. 28\,092--28\,103, 2021.

\bibitem{fang2020post}
J.~Fang, A.~Shafiee, H.~Abdel-Aziz, D.~Thorsley, G.~Georgiadis, and J.~H.
  Hassoun, ``Post-training piecewise linear quantization for deep neural
  networks,'' in \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2020, pp. 69--86.

\bibitem{li2021brecq}
Y.~Li, R.~Gong, X.~Tan, Y.~Yang, P.~Hu, Q.~Zhang, F.~Yu, W.~Wang, and S.~Gu,
  ``Brecq: Pushing the limit of post-training quantization by block
  reconstruction,'' \emph{arXiv preprint arXiv:2102.05426}, 2021.

\bibitem{zhou1994acoustic}
G.~Zhou and D.~Z. Anderson, ``Acoustic signal recognition with a
  photorefractive time-delay neural network,'' \emph{Optics letters}, vol.~19,
  no.~9, pp. 655--657, 1994.

\bibitem{larger2012photonic}
L.~Larger, M.~C. Soriano, D.~Brunner, L.~Appeltant, J.~M. Guti{\'e}rrez,
  L.~Pesquera, C.~R. Mirasso, and I.~Fischer, ``Photonic information processing
  beyond turing: an optoelectronic implementation of reservoir computing,''
  \emph{Optics express}, vol.~20, no.~3, pp. 3241--3249, 2012.

\bibitem{duport2012all}
F.~Duport, B.~Schneider, A.~Smerieri, M.~Haelterman, and S.~Massar,
  ``All-optical reservoir computing,'' \emph{Optics express}, vol.~20, no.~20,
  pp. 22\,783--22\,795, 2012.

\bibitem{jutamulia1996overview}
S.~Jutamulia and F.~Yu, ``Overview of hybrid optical neural networks,''
  \emph{Optics \& Laser Technology}, vol.~28, no.~2, pp. 59--72, 1996.

\bibitem{paquot2012optoelectronic}
Y.~Paquot, F.~Duport, A.~Smerieri, J.~Dambre, B.~Schrauwen, M.~Haelterman, and
  S.~Massar, ``Optoelectronic reservoir computing,'' \emph{Scientific reports},
  vol.~2, no.~1, p. 287, 2012.

\bibitem{woods2012photonic}
D.~Woods and T.~J. Naughton, ``Photonic neural networks,'' \emph{Nature
  Physics}, vol.~8, no.~4, pp. 257--259, 2012.

\bibitem{hughes2018training}
T.~W. Hughes, M.~Minkov, Y.~Shi, and S.~Fan, ``Training of photonic neural
  networks through in situ backpropagation and gradient measurement,''
  \emph{Optica}, vol.~5, no.~7, pp. 864--871, 2018.

\bibitem{fang2015nanoplasmonic}
Y.~Fang and M.~Sun, ``Nanoplasmonic waveguides: towards applications in
  integrated nanophotonic circuits,'' \emph{Light: Science \& Applications},
  vol.~4, no.~6, pp. e294--e294, 2015.

\bibitem{shen2017deep}
Y.~Shen, N.~C. Harris, S.~Skirlo, M.~Prabhu, T.~Baehr-Jones, M.~Hochberg,
  X.~Sun, S.~Zhao, H.~Larochelle, D.~Englund \emph{et~al.}, ``Deep learning
  with coherent nanophotonic circuits,'' \emph{Nature photonics}, vol.~11,
  no.~7, pp. 441--446, 2017.

\bibitem{ovchinnikov1999diffraction}
Y.~B. Ovchinnikov, J.~M{\"u}ller, M.~Doery, E.~Vredenbregt, K.~Helmerson,
  S.~Rolston, and W.~Phillips, ``Diffraction of a released bose-einstein
  condensate by a pulsed standing light wave,'' \emph{Physical review letters},
  vol.~83, no.~2, p. 284, 1999.

\bibitem{lin2018all}
X.~Lin, Y.~Rivenson, N.~T. Yardimci, M.~Veli, Y.~Luo, M.~Jarrahi, and A.~Ozcan,
  ``All-optical machine learning using diffractive deep neural networks,''
  \emph{Science}, vol. 361, no. 6406, pp. 1004--1008, 2018.

\bibitem{george2018electrooptic}
J.~George, R.~Amin, A.~Mehrabian, J.~Khurgin, T.~El-Ghazawi, P.~R. Prucnal, and
  V.~J. Sorger, ``Electrooptic nonlinear activation functions for vector matrix
  multiplications in optical neural networks,'' in \emph{Signal Processing in
  Photonic Communications}.\hskip 1em plus 0.5em minus 0.4em\relax Optica
  Publishing Group, 2018, pp. SpW4G--3.

\bibitem{miscuglio2018all}
M.~Miscuglio, A.~Mehrabian, Z.~Hu, S.~I. Azzam, J.~George, A.~V. Kildishev,
  M.~Pelton, and V.~J. Sorger, ``All-optical nonlinear activation function for
  photonic neural networks,'' \emph{Optical Materials Express}, vol.~8, no.~12,
  pp. 3851--3863, 2018.

\bibitem{ding2021repvgg}
X.~Ding, X.~Zhang, N.~Ma, J.~Han, G.~Ding, and J.~Sun, ``Repvgg: Making
  vgg-style convnets great again,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2021, pp.
  13\,733--13\,742.

\bibitem{kabir2022spinalnet}
H.~D. Kabir, M.~Abdar, A.~Khosravi, S.~M.~J. Jalali, A.~F. Atiya, S.~Nahavandi,
  and D.~Srinivasan, ``Spinalnet: Deep neural network with gradual input,''
  \emph{IEEE Transactions on Artificial Intelligence}, 2022.

\end{thebibliography}
