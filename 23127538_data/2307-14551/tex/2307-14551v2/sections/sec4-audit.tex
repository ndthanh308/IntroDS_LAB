%!TEX root = YouTubePolarization.tex

% ====================================================
\section{Sock Puppet Study}
\label{sec:methods}

% Our data was collected from two sources: a sock puppet algorithm audit on the YouTube platform, and a survey of real users about their experiences with it. Here, we describe our process to collect data from both sources.
%This mixed methods approach provides complementary findings that help advance our understanding of uwanted content removal on YouTube. 

% ====================================================
\subsection{Sock Puppet Design}

We take a sock puppet algorithm audit approach to examine how suggestions from certain topics can both be populated onto and removed from one's personal recommendation feed. Broadly, our agents first purposely populate their feed with videos from this unwanted topic (``stain phase''); Then, they take on one of a variety of strategies to try to eliminate such videos from being recommended (``scrub phase''). We collect data on how recommendations change throughout these phases in order to characterize the recommendation system's response to these various interactions. 

\subsubsection{Video topics.} 
\label{topics}

We require video topics as an input for our agents to populate in their recommendations (staining phase), and then attempt to scrub (scrubbing phase). 

Each topic is operationalized as a list of channels collected by researchers who have formerly studied that topic on YouTube. They are used in our experiment in two ways. First, agents watch videos from the channel lists during the stain phase. Next, during the scrub phase, some strategies cross reference their homepage recommendations with the assigned topic's channel list to determine whether and which one to indicate disinterest on. 
%Lastly, we use these lists as a starting point to label our collected recommendations as stain or not.

\begin{itemize}
    \item \emph{Alt-Right}: The most extreme group of the Alternative Influence Network, a loosely-defined community of YouTube channels that are defined by their opposition to mainstream media \cite{ricks_does_2022}. The Alt-Right promotes white nationalism in the face of an increasingly diverse US population, and is often openly anti-semitic \cite{noauthor_alt_2019}. YouTube channels of the Alt-Right were first collected by \citet{lewis_alternative_2018} through a snowballing method, and subsequently augmented by \citet{ribeiro_auditing_2020} and \citet{chen_exposure_2022}. 
    %For this topic we simulate a user who was formerly sympathetic to or a member of the Alt-Right, who would now like to avoid such societally-problematic content. The channels for this topic are collected and annotated by Ribeiro and colleagues \cite{ribeiro_auditing_2020}.
    \item \emph{Antitheism}: Collected by \citet{ledwich_algorithmic_2019}, it is ``the self-identified atheist who is also actively critical of religion''. 
    %For this topic we simulate a user who has changed religious views and would like to eliminate remnants of a religiously-critical former self. Such a change can be described as a ``major life event'', or moments or process of change that are associated with changes in engagement with and expression on social media \cite{haimson_major_2021}. 
    \item \emph{Political Left}: Collected by \citet{wu_cross-partisan_2021}, they include local news, talk shows, and magazines. We use the US political left channels, which takes similar views among various issues of political significance, such as climate change.
    %MBFC is a political bias and fact checking organization used in studies on the political information ecosystem \cite{wu_cross-partisan_2021}. Here, our sock puppets simulate a user motivated by selective exposure to stop seeing content from a particular political ideology. 
    \item \emph{Political Right}: Same as above, but with the US political right channels.
\end{itemize}

\subsubsection{Scrubbing strategies.}
\label{strategies}

The name and operation of each scrubbing strategy are listed below. Each agent is assigned one strategy, and performs it repeatedly during the ``scrub phase'' of the sock puppet run.

\begin{itemize}

\item \emph{None} (control): Load the homepage, then do nothing except refreshing the homepage.
\item \emph{Watch neutral}: Load and watch a video from mainstream, politically neutral news outlets as defined by the fact-checking organization Media Bias/Fact Check.\footnote{\url{https://mediabiasfactcheck.com/}}

\item ``History-based'' strategies
\begin{itemize}
    \item \emph{Dislike}: Load a previously-watched video from the stain phase and click the ``Dislike'' button.
    \item \emph{Delete}: Load the watch history and click ``Delete'' on the most recently-watched video. %Since the only watch history the sock puppet has built up is with the staining videos, we are deleting a staining video from the watch history each time.
\end{itemize}

\item ``Recommendation-based'' strategies. Load the homepage. If there does \emph{not} exist any recommended video on the homepage from a channel in the channel list, then just refresh again. However, if such a video exists, do the following to the first such video:
\begin{itemize}
    \item \emph{Not interested}: click the ``Not interested'' button and refresh the homepage.
    \item \emph{No channel}: click the ``Don't recommend channel'' button and refresh the homepage.
    \item \emph{Dislike recommended}: click on the video and dislike it (agents do not stay to watch the video), then return to the homepage .
\end{itemize}

\end{itemize}

The ``watch neutral'' strategy attempts to ignore the current issue by watching videos from a different topic, and most resembles the intervention strategies of related studies \cite{haroon_youtube_2022,tomlein_audit_2021}. We call dislike and delete strategies ``history-based'' because they act on videos that the agents watched during the stain phase. We call the final three strategies ``recommendation-based'' because they are performed with respect to recommended videos.

%Thus, for these strategies, at each stage of the audit we require a list of channels from the topic at hand to cross reference: If a recommended video is published by a channel from that list, our sock puppet takes an action towards it. To that end we utilize manually categorized channel lists from previous studies for our topics (how channels are gathered and labeled is described in the ``Topics'' subsection). 

\subsubsection{Sock puppet phases and data collection.}

A sock puppet agent follows the following process. After logging in to a YouTube account, an agent performs the ``stain phase'', where it watches 40 videos, for up to 30 minutes each,\footnote{An alternative is to stay for the median watch time for videos with similar length, see \citet{wu2018beyond}'s computation of relative engagement metric.} from a ``stain video list'' which are sampled from the channel list belonging to that topic. Next, it performs the ``scrub phase'', where it executes its assigned scrubbing strategy 40 times. \al{
%\marginnote{SPC-2}
Lastly, the agent clears its entire YouTube activity through Google's MyActivity page,\footnote{\url{https://myactivity.google.com/myactivity}} in order to leave a clean history for the next audit to start \cite{tomlein_audit_2021}. This includes clearing all revertible actions made during its run, such as pressing the “Dislike”, “Not interested”, “Don’t recommend”, and “Delete from watch history” buttons. 
}

Our agents use web-scraping methods to collect the top 10 recommendations from the homepage and videopage at three strategic points: 
\begin{itemize}
    \item P1: The beginning of the stain phase.
    \item P2: The end of the stain phase.
    \item P3: The end of the scrub phase.
\end{itemize}

Because the video being watched when performing videopage collection may have an effect on the recommendations themselves, each agent repeatedly loads the first video in the stain video list at all three collection points (P1, P2, P3).
%While some studies take only the top video of the recommendation list, which is the video that would be played from autoplay \cite{haroon_youtube_2022}, we take the top $n_{rec}$ videos from each location. 
Altogether, \Cref{alg:sock_puppet} provides an overview of a sock puppet agent's interactions with the platform.

\begin{algorithm}
    \caption{Agent}%Agent process (``rec'' = ``recommendation'')}
    \begin{algorithmic}
        \State Log into YouTube
        \State Collect homepage recs \Comment{P1}
        \State Collect videopage recs from the first stain video \Comment{P1}
        \For{$i \in [2 \dots 40]$} \Comment{stain phase}
            \State Watch a video from stain video list up to 30 minutes
        \EndFor
        \State Collect homepage recs \Comment{P2}
        \State Collect videopage recs from the first stain video \Comment{P2}
        \For{$i \in [1 \dots 40]$} \Comment{scrub phase}
            \State Perform assigned scrubbing strategy
        \EndFor
        \State Collect homepage recs  \Comment{P3}
        \State Collect videopage recs from the first stain video \Comment{P3}
        \State \sw{Clear YouTube activity (cancel all revertible actions)}
        \label{alg:sock_puppet}
    \end{algorithmic}
\end{algorithm}

\al{
%\marginnote{R1-4}
We now describe the configurations of agents for the overall experiment. For each topic we tested seven strategies, each five times, resulting in (7 * 5 =) 35 agents. All 35 agents of a given topic were run in parallel in order to deal with recommendation noise that may arise from having agents make queries on different times.}

For a given topic, we also drew five stain video lists, and assigned each list to exactly one agent within every strategy tested. Doing so assures that agents of the same strategy watch different sets of staining videos, boosting generalizability of the strategy effects, while simultaneously assuring that agents of different strategies watch, overall, the same videos, enabling comparability between strategies. 

%For each topic, we test 7 strategies, each 5 times. Also for each topic, we draw 5 stain video lists, and assign them to agents in such a way that those assigned to a particular strategy collectively watch all 5 during in the stain phase, and that one agent from each strategy watches any given stain video list. 

%For each topic, we run all (7*5=) 35 of its associated agents in parallel. This is to deal with recommendation noise that may arise from having agents make queries on different days. 
%Each topic's agents took about 6-12 hours each. 
%Collecting data for all four topics in total took about 5 days. 
Additionally, each of the 35 agents have their own Google Accounts so that the platform can track their viewing habits and personalize content to each agent, and so that we can more closely simulate real users' experience with the platform. Logging into an account also grants access to buttons and features that are only available to users that are logged in (e.g., the ``Not interested'' button).

Our agents ran in a Google Chrome browser with adblocker installed. They had Google accounts with birthdays set at an arbitrary 5/5/1990, a gender selection of ``Rather not say'', and asexual names (e.g., ``Tandy''). 
% They ran on Linux machines in AWS cloud computing services.
We also address the potential biases from location effects, which would occur if queries were made to the platform from different locations, or from (different accounts in) the same IP address. Thus, all agents are created and live in the same AWS Region of Ohio (US-East-2), but make queries from individual IP addresses.
% To allow for reproducability and transparency, code for agents will be published on GitHub upon publication.

Out of 140 sock puppets released over the course of five days in August 2022, 139 sock puppets ran successfully. 
%Sock puppets collectively watched more than 1,000 videos and interacted with the platform for more than 45 days in total (either by watching, waiting, or pressing buttons). 
Agents collected a total of 8330 recommendations.
%, 7368 of which we manually annotated as stain or not. 

%can occur in two ways. First is when queries to the platform are made from different locations (e.g. states, countries) that cause recommendations to be different as a result of regional rather than personal and account-related differences. Second is when queries from the same IP address (even with different accounts) can cause YouTube to mix recommendations of different accounts together [CITE]. 


%\footnote{https://github.com/carleski/ytburst-terraform} \footnote{https://github.com/avliu-um/youtube-burst}.

%In the setup phase, we load details and video ID's required to execute the audit run. These details include the login credentials (username and password) for the sock puppet's YouTube account, staining topic, and scrubbing strategy (see ``Video Topics'' and ``Scrubbing Strategies''). Then it loads a list of videos to watch during the stain phase, $\mathbf{V}^{stain}_{r,t}$, which we call the ``staining videos''. If the scrubbing strategy of ``watch'' is selected (again, see ``Scrubbing Strategies'' section), it will also load a list of ``scrubbing videos'' to watch during the scrubbing phase, $\mathbf{V}^{scrub}_{neutral}$. The sock puppet then logs into their Google Account.

%In the staining phase, the sock puppet will actively attempt to infuse its homepage and videopage recommendations with those of their given topic by watching each video in $\mathbf{V}^{stain}_{r,t}$ for up to $t_{video}$ minutes or until the video ends, whichever occurs first. The number of videos a agent watches during the stain phase, or length of $\mathbf{V}^{stain}_{r,t}$, is $n_{stain}$ long. 
%The types of staining videos that agents watch (i.e. the values of $t$) are described in ``Video Topics''. 

%For the scrubbing phase, our sock puppet attempts to ``scrub'' videos of the stain topic from being recommended with a variety of strategies. This is done by interacting with the platform via one of several features that YouTube offers its users to indicate disinterest (we describe each of these strategies in Subsection \ref{strategies}). Each sock puppet performs its scrubbing strategy, $s$, for $n_{scrub}$ times. 

%Deciding whether to run our agents in sequence or parallel is important to mitigate biases. Each agent of topic $t$ must run in parallel because of time effects of the YouTube recommender system, which occur when queries are made to the platform on different days and recommendations are different because of it. This could be the case, for example, if new videos were posted and certain videos became newly popular. For each topic, we test 7 strategies with $R=5$ redundant agents each. Thus, we run our (7*5=) 35 sock puppets in parallel for a given topic $t$. Sock puppets tend to run about 6-12 hours, depending on lengths of videos and scrubbing strategy.

%Then, we run 35 agents for each topic in rapid succession (i.e. in sequence), taking about a week in total. Elongating this process any further would risk capturing large changes in how the recommendation system operates and incorrectly attributing these changes to differences in the nature of topics on YouTube. 

%Finally, each sock puppet watches videos from $\mathbf{V}^{stain}_{r,t}$ during the staining phase. From the indexing it is clear that for each $(s,t)$ combination, each ``redundant'' agent is watching a different set of videos. At the same time, the same set of starting videos is watched across all strategies by exactly one agent. Doing so leverages randomness within a strategy to boost generalizability while maintaining enough similarity between topics to have experimental validity between treatment groups (i.e. scrubbing strategies). We randomly sample each of these lists of videos from the channel pool $\mathbf{C}_t$.


\subsection{Data Annotation}

Our agents collected many recommendations during their runs. We would like to label them for whether they belong to the topics that the agents were assigned to (what we call ``stain''), in order to quantify how well (1) the stain phase worked to populate agent' recommendations with stain, and (2) how well the scrub phase worked to remove it.

% collect codebooks
\sw{
%\marginnote{SPC-1}
We adopted an iterative strategy in annotating the recommended channels. We first developed an initial annotation codebook by surveying prior research. Next, we randomly sampled 50 channels for each topic. Two authors who had extensive experience in studying political polarization and YouTube platforms independently labeled those channels by following the codebook. The preliminary inter-rater reliability (IRR), measured by Cohen's kappa, was 0.648, 0.728, 0.634, 0.563 for \emph{Alt-Right}, \emph{Antitheism}, \emph{Political Left}, \emph{Political Right}, respectively, demonstrating substantial agreement. The two raters discussed every disagreed case to reach consensus and updated the codebook whenever needed. 

The two raters then went on and labeled all the remaining channels. The final IRR kappa scores were 0.660, 0.822, 0.854, and 0.945, respectively. The raters also discussed all disagreed cases and resolved disagreement. The final annotation codebook is attached in~\Cref{app:codebook}. The annotation results and IRR calculation can be previewed via this link.\footnote{Anotation results: \url{https://tinyurl.com/45t2rhrs}}
}

% To perform manual labeling, we follow codebooks for topics used by the previous researchers, if they were available. For the \emph{Alt-Right} and \emph{Anti-theism} topics, we borrowed these codebooks directly from their papers.
% For the political topics (left and right), we had to develop a codebook that described channels collected in \citet{wu_cross-partisan_2021} as closely as possible. Their method of channel collection combined both left and right media outlets identified by MBFC, as well as their featured channels (this is a platform feature that allows a channel to list other channels that it recommends to its audience). The resulting channel list contained both traditional media outlets labeled by MBFC (e.g. CBS), as well as sources that were not traditional news media (e.g. Trevor Noah's Daily Show). 

% To create a codebook that described channels in political topics, we first had to consider whether the channel counted as discussing politics or not. We considered channels to be political if they were either traditional media outlets, or if their content satisfied all of the following criteria:

% \begin{itemize}
%     \item Covered US current events.
%     \item Were a personality (i.e. they reported, discussed, or gave opinions of these events).
%     \item Were in English.
%     \item Were not completely satire.
% \end{itemize}

% After determining that a given channel was political, we further reviewed its video content in order to determine whether it was politically left or right leaning. This ideological determination was made by using the MBFC codebook\footnote{https://mediabiasfactcheck.com/left-vs-right-bias-how-we-rate-the-bias-of-media-sources/}, which lists common stances on politically-salient topics (e.g., climate change) that members of each ideology take. 

% ====================================================
% \subsection{Analysis Methods and Results}


\input{tables/table-signed-test}
\input{tables/table-p2.tex}

% ====================================================
\subsection{Result 1: Stain Phase} 
\label{results_stain}

In this subsection, we answer our questions posed in RQ1.

\subsubsection{Effects of stain phase.}

We wanted to know whether our agents experienced a significant change in stain (the percentage of recommendations of their given topic) after the stain phase. To address this question, we compared the stain of our agents at P1 with those at P2 for each topic, in both the homepage and the videopage. 
%To determine whether the change was significant, we used the non-parametric Mann-Whitney U test as our data was non-normal. Results are given in the ''total'' row in Tables \ref{table:mwu_homepage} and \ref{table:mwu_videopage} for homepage and videopage, respectively. 
\al{
%\marginnote{SPC-3}
To determine whether changes were significant, we chose the Wilcoxon signed-rank test because (a) the data was non-normal; (b) the comparison before and after the ``stain phase'' treatment was a paired test.
Results are given in Table \ref{table:signed_test} (P1 to P2).
% We opt for a non-parametric statistical test because our data was non-normal. Furthermore, because our samples are not independent - in fact, we are performing a within-subject experiment with the bots before and after the ``scrub phase'' treatment - we thus choose the Wilcoxon signed-rank test.
}


%In the homepage, we find that all topics experienced significant increases in stain as a result of the stain phase. \emph{Antitheism} received the most stain at P2 (36\%), while \emph{Alt-Right} received the least (18\%). 
In the homepage, we find that all topics experienced significant increases in stain as a result of the stain phase. \emph{Antitheism} received the most stain at P2 (37\%), while \emph{Alt-Right} received the least (20\%). 
%In contrast, the videopage demonstrated no significant changes in stain in all topics except for \emph{Political Right}. 
\al{
%\marginnote{SPC-1}
In contrast, the videopage demonstrated significant changes in stain only on \emph{Antitheist} and \emph{Political Right}.} 
%Some topics actually experienced a slight decrease between P1 and P2. 
\al{\emph{Alt-Right} actually showed a slight decrease from P1 to P2.}
%Despite a lack of consistent significant changes, a non-zero stain still existed in the videopage: Absolute percentages at P1 varied between 6\% for \emph{Alt-Right} and 40\% for \emph{Political Left}.
\al{Despite a lack of consistent significant changes, a non-zero stain still existed in the videopage -- absolute percentages at P1 varied between 5\% for \emph{Alt-Right} and 42\% for \emph{Political Left}.}
We lastly remark that, across both homepage and videopage, and across topics and strategies, stain never reached more than half. 

These findings set us up well for the scrub phase, because it assures that our agents will indeed have stain to remove when they perform their scrubbing strategies.
%Looking at P2 recommendations of individual agents, on-topic recommendations are more than half for just 2\% (3/139) of agents on the homepage and 6\% (8/139) on the videopage. 

\input{tables/table-p3.tex}

\subsubsection{Stain from watched channels vs. new channels.}

We wanted to examine the stain in P2 with more granularity. Specifically, how much of it was from channels that had explicitly watched before, and how much was from channels that the agents had never explicitly watched before? 


To answer this question, we categorized all recommendations at point P2 as ``off-topic'', ``on-topic watched-channel'' (i.e., the agent that collected this recommendation had already watched a video from the same channel during the stain phase), or ``on-topic new-channel'' (i.e., the agent had not watched any videos from the same channel up to that point). 
Then, for each topic, we found the percentage of recommendations belonging to each category. 
%Calculations for each topic combined 350 recommendations, except for the \emph{Political Left}/\emph{Dislike}pairing, which had 340 due to a faulty agent run. 
We report these ratios for the homepage and videopage in Table \ref{table:p2}.

%On the homepage, we find that \emph{Political Left} had the most recommendations from new channels (22\%), as well as the highest ratio of recommendations from new channels to those from watched channels (11:1). 
\al{
%\marginnote{SPC-1}
On the homepage, we find that \emph{Political Left} had the most recommendations from new channels (26\%), as well as the highest ratio of recommendations from new channels to those from watched channels (13:1).} 
%On the other hand, the \emph{Alt-Right} had the smallest new-channel percentage, both in absolute terms (2.29\%) and as a ratio of watched-channel percentage (1:8). 
\al{On the other hand, the \emph{Alt-Right} had the smallest new-channel percentage, both in absolute terms (5\%) and as a ratio of watched-channel percentage ($\sim$1:3).} % Can I do the tilda like this, because it's approximate (5% : 16%)?

%We find similar results on the videopage. First, \emph{Political Left} had the highest absolute percentage of recommendations from new channels (17.14\%) and as a ratio to those from watched channels (17:14). 
\al{
%\marginnote{SPC-1}
On the videopage, \emph{Political Left} and \emph{Antitheist} had the highest absolute percentage of recommendations from new channels (29\%), and \emph{Antitheist} had the highest ratio of new channel recommendations to those from watched channels ($\sim$3:1).}
%By contrast, the \emph{Alt-Right} agents received no recommendations from new channels (0\%) while all other topics received at least 5\%.
\al{By contrast, the \emph{Alt-Right} agents received no recommendations from new channels (0\%) while all other topics received at least 9\%.}

These findings suggest that the YouTube recommendation system sometimes plays a role in providing stain to the user by not only suggesting content that is from the same channel, but rather by inferring and providing that from different but similar channels.

\subsection{Result 2: Scrub Phase} 
\label{results_scrub}

In this subsection, we answer our questions posed in RQ2.

\subsubsection{Effects of scrub phase.}

We wanted to know whether it was possible for our agents to remove stain from their feeds after the scrub phase. To address this question, we compared the stain of our agents at P2 with those at P3, for each topic, in both homepage and videopage. \al{
%\marginnote{SPC-3}
Again, our data was non-normal and paired, so we ran Wilcoxon signed-rank tests} to determine whether stain significantly decreased from P2 to P3. Results are given in~\Cref{table:signed_test} (P2 to P3).

%On the homepage, \emph{Not interested} was the only strategy that significantly reduced the amount of stain across all topics. 
\al{On the homepage, \emph{Not interested} and \emph{No channel} were the only strategies that significantly reduced the amount of stain across all topics.} 
%It also produced the greatest average percentage decrease between P2 and P3 (-97\%).
\al{Comparing average relative changes between P2 and P3, \emph{Not interested} wins out (-88\%).}
%Three other strategies- \emph{Delete}, \emph{No channel}, and \emph{Dislike recommendation}- successfully scrubbed three out of four topics. 
\al{One strategy successfully scrubbed three out of four topics (\emph{Delete}), while two strategies were successful in two out of four topics (\emph{Dislike recommendation} and \emph{Watch neutral}).}
On the other end, the \emph{None} strategy did not produce any significant effect (in fact, it produced a slight increase), which was expected because it was our control strategy. 
On the videopage, we did not find any significant scrub phase effects.

\subsubsection{Stain from scrubbed channels vs. new channels.}

We wanted to know whether our scrubbing strategies removed stain in general, or whether they only removed the subset of channels for which the the agent had explicitly scrubbed up to that point.

To answer this question, for all recommendations at point P3, we categorized them as either ``off-topic'', ``on-topic scrubbed-channel'' (i.e., the agent that collected this recommendation had already scrubbed a video from the same channel during the scrub phase), or ``on-topic new-channel'' (i.e., the agent had not scrubbed a video from the same channel up to that point). Notice that these categories are analogous to watched/new categories made for P2 in Section \ref{results_stain}. 

Then, for each topic/strategy pairing, we found the ratio of recommendations at P3 that belonged to each category. %Calculations for each pairings combined 50 recommendations, except for the \emph{Political Left}/\emph{Dislike}pairing which had 40 due to a faulty agent run. 
We report these ratios for the homepage in Table \ref{table:p3}. We did not examine the videopage because it did not experience any significant changes in this phase. The \emph{None} strategy was excluded because no videos were scrubbed. 

Categorizing recommendations this way reveals that scrubbing strategies behaved differently in removing unwanted recommendations. 
%For instance, all of the \emph{Delete} strategy's remaining stain at P3 is from scrubbed channels. 
\al{
%\marginnote{SPC-1}
For instance, in three out of four topics, at least half of the \emph{Watch neutral} strategy's remaining stain at P3 was from scrubbed channels. 
}
On the other hand, \emph{No channel} rarely left videos from scrubbed channels (0-2\%); most stain remaining after using this strategy was from new channels. 
The behavior of \emph{No channel} agrees with many user perceptions of the ``Don't recommend channel'' button \cite{ricks_does_2022}, and matches an intuitive interpretation of the button name. 

%Examining results by topic, we see that both political topics 
