

\begin{theorem} 
\label{thm1}
Consider a multilayer network model satisfying \eqref{general model} 
defined on a set of $N \geq 3$ nodes and $K \geq 1$ layers 
and assume that $\mbE \, \norm{\bY}_1 \geq 1$ and $p \leq N$.  
Then there exists $N_0 \geq 3$ such that, 
for all $N \geq N_0$,
the following hold with probability at least $1 - 3 \, (\mbE \, \norm{\bY}_1)^{-1}$: 
\ben 
\item (MLE) The set $\Mle$ is non-empty and the unique element $\mle \in \Mle$ satisfies  
\beno
\norm{\mle - \truth}_2 &\leq&
\sqrt{\dfrac{3 \, p \, \log N}{\mbE \norm{\bY}_1}} \; \dfrac{\sqrt{1 + [D_{g}]^{+}}}{\xi_{\epsilon^\star}}, 
\ee
provided the right-hand side tends to $0$ as $N \to \infty$. 
\item (MPLE) The set $\Mple$ is non-empty and each $\mple \in \Mple$ satisfies  
\beno 
\norm{\mple - \truth}_2 &\leq&
\sqrt{\dfrac{3 \, p \, K^2 \, \log N}{\mbE \norm{\bY}_1}} \; \dfrac{\sqrt{1 + [D_{g}]^{+}}}{\widetilde\xi_{\epsilon^\star}},
\ee
provided the right-hand side tends to $0$ as $N \to \infty$. 
\een
\end{theorem}

The results of Theorem \ref{thm1} establish a few key facts concerning statistical estimation 
of the parameter vector $\truth$. 
First, 
we can view the quantity $\xi_{\epsilon^\star} \, \sqrt{\mbE \, \norm{\bY}_1} \,/\, \sqrt{1 + [D_{g}]^{+}}$ 
as the effective sample size in order to compare our results to 
classical settings with independent and identically distributed data. 
The effective sample size, 
together with the dimension of the model $p$, 
helps to determine the rate of convergence (with respect to the Euclidean distance) 
of maximum likelihood and pseudolikelihood estimators. 
As previously mentioned, 
the quantities $\mbE \norm{\bY}_1$ and $[D_{g}]^{+}$ 
are determined by properties of $g(\by)$,
the marginal probability mass function of $\bY$. 
While specification of $g(\by)$ does not directly influence estimation algorithms, 
the statistical guarantees of estimators will depend on $g(\by)$ producing enough activated dyads and not possessing overly strong 
dependence among edges in the single network $\bY$.
The requirement that the right-hand side of the bounds in Theorem \ref{thm1} tend to $0$ as $N \to \infty$ 
ensures that all regularity assumptions remain valid. 
Namely, 
key to our approach lies in the ability to control minimum eigenvalues of matrices 
$\mcI(\nat)$ and $\widetilde\mcI(\nat)$ 
in a neighborhood of the data-generating parameter vector $\truth$. 
The condition that the bounds tend to $0$ ensures that it is sufficient to control the smallest eigenvalue
in a bounded set,
i.e.,
we may let $\epsilon^\star$ be fixed independent of $N$, 
and moreover, 
to ensure consistency in the sense that $\norm{\mle - \truth}_2 \to 0$ 
and $\norm{\mple - \truth}_2 \to 0$ (as $N \to \infty$) with probability approaching $1$.  

 
 
