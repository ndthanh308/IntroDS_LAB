In this section, we add simulation evidence to our major contributions. Section \ref{sec:sim_con} shows the consistency results in Theorem \ref{thm1} for the pseudolikelihood estimator $\mple$. Section \ref{sec:sim_norm} shows the multivariate normality results of Theorem \ref{thm2}. In addition, we discuss several model selection procedures that control the false discovery rate (FDR) at level $\alpha$ in Section \ref{sim:sec_fdr}.


\begin{table}[t]
\begin{center}
\caption{\label{t1}Values of the model-generating parameter $\truth$ and mean of MPLE $\mple$ from 500 replications at network size 1000. Standard errors are in the parenthesis.}
\begin{tabular}{| c | c | c | c | c | c | c |} 
\hline
  & $\theta_{1}$&$\theta_{2}$&$\theta_{3}$& $\theta_{1,2}$ & $\theta_{1,3}$ & $\theta_{2,3}$ \\ 
\hline
$\truth$ & $-3$ & $-2$ & $-1$ & $.5$ & $0$ & $0$  \\
\hline
$\mple$ & $-2.999 \, (.02)$ & $-1.998 \, (.02)$ & $-.999 \, (.02)$ & $.499 \, (.02)$ & $-.001 \, (.02)$ & $-.002 \, (.02)$\\
\hline
\end{tabular}
\end{center}
\end{table}


Throughout the simulation, we sample network concordant multilayer networks $(\bX,\bY)$ with $N$ nodes and $K = 3$ layers according to model \eqref{general model}, where $\bY$ is a Bernoulli random graph with $\mbP(Y_{i,j} = 1) = g$ for all $\{i,j\} \subset \mN$, and
\beno
f(\bx, \nat) = \dprod_{i<j}^N \, \exp\left( \dsum_{k=1}^3\theta_{k}\,x_{i,j}^{(k)} + \dsum_{\substack{k < l}}^{3}\, \theta_{k,l} \, x_{i,j}^{(k)} \, x_{i,j}^{(l)} \right).
\ee
The natural parameter $\nat \in \mbR^{6}$ specifies three different layer densities through $\theta_{1},\,\theta_{2}$, and $\theta_{3}$, as well as three cross-layer interactive effects through $\theta_{1,2},\,\theta_{1,3}$, and $\theta_{2,3}$.




\section{Consistency of MPLE} 
\label{sec:sim_con}

The consistency of the maximum pseudolikelihood estimator (MPLE) is demonstrated through the decay of the relative $\ell_2$ error between the MPLE $\mple$ and the data-generating parameter $\truth$ in Figure \ref{Figure1}(a). As the network size increases from 100 to 1000, the relative $\ell_2$ error decreases to 0. For each network size, $M=500$ samples were taken. The decay rate of the relative $\ell_2$ error as the network size increases can be estimated by the slope of the OLS fitted line in the $\log$-$\log$ plot as shown in Figure \ref{Figure1}(b). The slope of the OLS line is $-1$, indicating a decay rate of order $1/N$, which follows the result in Theorem \ref{thm1}. We report the MPLE $\mple$ averaged from $M = 500$ samples with the selected model-generating parameter $\truth$ at network size 1000 in table \ref{t1}.

% Figure environment removed


% % Figure environment removed



\section{Normality of MPLE} 
\label{sec:sim_norm}
As stated in Theorem \ref{thm2}, the distribution of the maximum likelihood estimator $\mle$ converges to a multivariate normal distribution as the network size increases. We show by simulation that the maximum pseudolikelihood estimators (MPLEs) are approximately multivariate normal as well. We first demonstrate through Q-Q plots in Figure \ref{Figure3} that each component of the MPLE $\mple$ follows a marginal normal distribution. 
% We constructed 95\% confidence ellipses for bivariate components of $\mple$ in figure \ref{Figure4}. The two axes in each sub-plot of figure \ref{Figure4} correspond to two different components of $\mple$. The red ellipse is the 95\% confidence ellipse generated by the mean and covariance matrix of the MPLEs in the plot under the bivariate normal assumption. All 15 bivariate confidence ellipses cover most of estimates points, suggesting probable bivariate normal distributions of $\mple$. 
The multivariate normality of $\mple$ is then tested by Zhou-Shao's multivariate normal test \citep{Zhou13}. The test failed to reject the null hypothesis that $\mple$ is multivariate normal at the significance level of 0.05, confirming that $\mple$ is multivariate normal. We additionally performed marginal tests for normality for each component. In each case, the marginal test failed to reject the null hypotheses that $\mple_i$ is marginal normal at the same significance level, for each component $i = 1,\ldots, p$, the result of which is consistent with the $Q$-$Q$ plots. 

% Figure environment removed


\begin{table}[t]
\begin{center}
\caption{\label{t3} Empirical FDR and power at significance level 0.05 for multiple testing of MPLE $\mple$ estimated from 500 networks of size 1000.  } 
\begin{tabular}{| c | c | c | c |} 
\hline
 Procedure  & Empirical FDR & FDR 95\% one-sided CI  & Empirical power \\ 
\hline
  Bonfferoni & .004 & (0, .052) & 1  \\
\hline
  Benjamini-Hochberg's &  .018 & (0, .134) & 1  \\
\hline
 Hochberg's  & .016 & (0, .127) & 1 \\
\hline
 Holm's  & .013 &  (0, .114) & 1  \\
\hline
\end{tabular}
\end{center}
\end{table}


\section{Model selection and FDR controlling}
\label{sim:sec_fdr}
In this section, we implemented Bonferroni, Benjamini-Hochberg's, Hochberg's, and Holm's procedures to detect components of $\truth$ that are significantly different from 0 while controlling the false discovery rate (FDR) at level $q = 0.05$. We provide the simulated FDR and power in Table \ref{t3}. The hypotheses are $H_{0,i}: (\truth)_i = 0$ vs. $H_{1,i} : (\truth)_i \neq 0$ for $i = 1,\ldots, 6$. Simulation results suggest that all four proceudres are able to correctly detect all non-zero parameters and control the false discovery rate below the predefined threshold $q$. For smaller networks with 200 nodes or more, the four procedures have empirical power of 1 and FDR below $q$.
