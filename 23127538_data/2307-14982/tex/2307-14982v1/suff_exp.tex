\begin{lemma}
\label{lem:s_hetero}
Consider multilayer networks satisfying \eqref{general model} 
with maximum interaction term $H \leq K$
and 
defined on a set of $N \geq 3$ nodes and $K \geq 1$ layers.  
Then the following hold: 
\ben
\item The conditional probability mass function of $\bX$ given $\bY$ is an exponential family:  
\beno
\sepmodel(\bX = \bx \mid \bY = \by)
&\propto& h(\bx, \, \by) \; \exp\left( \langle \nat, \, \bs(\bx) \rangle \right),
\ee
where 
\beno
h(\bx, \, \by)
\= \dprod_{\{i,j\} \subset \mN} \, \one(\norm{\bx_{i,j}}_1 > 0)^{y_{i,j}} \; 
\one(\norm{\bx_{i,j}}_1 = 0)^{1 - y_{i,j}},
\ee
sufficient statistic vector $s : \mbX \mapsto \mbR^p$ and natural parameter vector $\nat \in \mbR^p$. 

\item For each $l \in \{1, \ldots, p\}$,
there exists $h \in \{1, \ldots, H\}$ and $\{k_1, \ldots, k_h\} \subseteq \{1, \ldots, K\}$ such that 
the $l^{\text{th}}$ component of the sufficient statistic vector $s(\bx)$ can be written as 
\be
\label{eq:suff}
s_l(\bx)
\= \dsum_{\{i,j\} \subset \mN} \, s_{l,i,j}(\bx)
\= \dprod_{r=1}^{h} \, x_{i,j}^{(k_r)}. 
\ee
\item The exponential family outlined above is both minimal, full, and regular. 
\een
\end{lemma}

\s 

\llproof \ref{lem:s_hetero}.
First, 
the form of the conditional probability distribution of $\bX$ given $\bY$
derived in Proposition \ref{prop:inference} is given by 
\be
\label{eq:1999}
\mbP_{\nat}(\bX = \bx \,|\, \bY = \by)
\= \exp\left( \log \, f(\bx, \nat) + \log \, \psi(\nat, \by) \right), 
\ee
provided $h(\bx, \by) = 1$.
The form of \eqref{general model} 
suggests that \eqref{eq:1999} will be a minimal exponential family in canonical form
due to the form of the Markov random field specification for $f(\nat, \bx)$
and the definition of $\psi(\nat, \by)$. 
From the form of $f(\bx, \nat)$ in \eqref{general model},
\beno
\log f(\bx, \nat)
\,=\, \dsum_{\{i,j\} \subset \mN} \,
\left(\dsum_{k=1}^K \theta_{k} x_{i,j}^{(k)} 
+  \dsum_{\substack{k < l}}^{K}  \theta_{k,l} x_{i,j}^{(k)} x_{i,j}^{(l)} + \ldots  
+ \dsum_{k_1 <\ldots< k_H}^{K} \theta_{k_1,k_2,\ldots,k_H}  x_{i,j}^{(k_1)} \cdots x_{i,j}^{(k_H)} \right),
\ee
where $H \le K$ is the highest order of cross-layer interactions included in the model.
We write $\theta_{k_1,k_2,\ldots,k_h}$ to reference the $h$-order interaction parameter
for the interaction term among layers $\{k_1, \ldots, k_h\} \subseteq \{1, \ldots, K\}$.
As specified, 
$\psi(\nat, \by)$ is the normalizing constant for the exponential family. 
As such, 
the natural parameter space of the exponential family is $\mbR^p$ 
as the support of $\mbX$ is finite, 
which implies $\psi(\nat, \by) < \infty$ for all $\nat \in \mbR^p$ and $\by \in \mbY$.
We establish minimality by noting that the components of the parameter vector $\nat$ 
satisfy no linear or affine constraints.  
Attached to each parameter $\theta_{k_1,\ldots,k_h}$ 
($\{k_1,\ldots, k_h\} \subset \{1, \ldots K\}$, 
$h \in \{1, \ldots, H\}$) 
is the sufficient statistic 
\beno
s_{k_1, \ldots, k_h}(\bx) 
\= \dsum_{\{i,j\} \subset \mN} \, x_{i,j}^{(k_1)} \,\cdots\, x_{i,j}^{(k_h)}.
\ee
Each statistic $s_{k_1, \ldots, k_h}$ is a function of distinct, non-degenerate random variables,
provided $\norm{\by}_1 > 0$,
and so none of the statistics $s_{k_1, \ldots, k_h}$ satisfy any linear or affine constraints. 
Hence, 
\eqref{general model}
specifies a minimal and full exponential family with natural parameter space $\mbR^p$
of dimension $p = \sum_{h=1}^{H} \, \binom{K}{h}$
and sufficient statistic vector $s(\bx)$ 
with components 
$s_{k_1, \ldots, k_h}(\bx)$ 
($\{k_1, \ldots, k_h\} \subseteq \{1, \ldots, K\}, h = 1, \ldots, H$). 
Regularity follows trivially 
\citep[e.g., Proposition 3.7, pp. 28,][]{Su19}. 
The form of \eqref{eq:suff} outlines this for a linear indexing of the components of the sufficient statistic vector. 

\qed

\s\s

\begin{lemma}
\label{lem:exp_pseudo}
Consider multilayer networks satisfying \eqref{general model} 
with maximum interaction term $H \leq K$ 
and defined on a set of $N \geq 3$ nodes and $K \geq 1$ layers. 
Then the conditional probability mass function of $X_{i,j}^{(k)}$ given 
$\bY = \by$ and $\bX_{i,j}^{(-k)} = \bx_{i,j}^{(-k)}$ is an exponential family 
\beno
\sepmodel(X_{i,j}^{(k)} = x_{i,j}^{(k)} \,|\, \bX_{i,j}^{(-k)} = \bx_{i,j}^{(-k)}, \bY = \by)
&\propto& h(\bx, \, \by) \; \exp\left( \langle \nat, \, \bs(\bx) \rangle \right),
\ee
with sufficient statistic vector $\bs : \mbX \mapsto \mbR^p$ defined in Lemma \ref{lem:s_hetero}, 
natural parameter vector $\nat \in \mbR^p$,  
and 
\beno
h(\bx, \, \by)
\= \dprod_{\{i,j\} \subset \mN} \, \one(\norm{\bx_{i,j}}_1 > 0)^{y_{i,j}} \; 
\one(\norm{\bx_{i,j}}_1 = 0)^{1 - y_{i,j}}.  
\ee
\end{lemma}

\s 

\llproof \ref{lem:exp_pseudo}. First,  
note that the form of \eqref{general model} and Proposition \ref{prop:inference} suggests that 
\be
 \sepmodel(X_{i,j}^{(k)} = x_{i,j}^{(k)} \,|\, \bX_{i,j}^{(-k)} = \bx_{i,j}^{(-k)}, \bY = \by) \s \\
 \quad\quad\quad = \dfrac{h(x_{i,j}^{(k)}, \, \bx_{i,j}^{(-k)}, \, \by) \; \exp\left( \langle \nat, \, \bs(x_{i,j}^{(k)}, \, \bx_{i,j}^{(-k)}) \rangle \right)}{\dsum_{x_{i,j}^{(k)} \in \{0,1\} }\, h(x_{i,j}^{(k)}, \, \bx_{i,j}^{(-k)}, \, \by) \; \exp\left( \langle \nat, \, \bs(x_{i,j}^{(k)}, \, \bx_{i,j}^{(-k)}) \rangle \right)}
\ee
is an exponential family in canonical form
using the Markov random field specification for $f(\nat, \bx)$ 
and the form of the conditional probability distribution of $X_{i,j}^{(k)}$ given $\bY$ 
and $\bX_{i,j}^{(-k)}$.  
However,
this exponential family may not be full rank due to possible 0 values of components of the given ($K$-$1$)-dimensional vector $\bx_{i,j}^{(-k)}$ and thus may not be minimal. 

\qed


