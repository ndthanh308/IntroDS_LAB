
For separable multilayer network models satisfying \eqref{general_model}, 
Proposition \ref{prop:inference} establishes that the log-likelihood function takes the form 
\be
\label{loglikelihood}
\ell(\nat; \bx, \by) 
&\coloneqq& \log \,\sepmodel(\bX = \bx, \bY = \by) \s \\
\= \log \, \mbP_{\nat}(\bX = \bx \,|\, \bY = \by) + \log \, g(\by).
\ee
Given an observation $\bx \in \mbX$ of the multilayer network $\bX$,  
and therefore an observation $\by \in \mbY$ of $\bY$ by Proposition \ref{prop:inference},
we denote the set of maximum likelihood estimators by 
\beno
\Mle &\coloneqq& \left\{ \nat \in \mbR^p 
\,:\, \ell(\nat; \bx, \by) = \sup\limits_{\nat^{\prime} \in \mbR^p} \, \ell(\nat^{\prime}; \bx, \by) \right\},
\ee 
and reference individual elements of the set by $\mle \in \Mle$.
As Proposition \ref{prop:inference} establishes 
$\log \, \mbP_{\nat}(\bX = \bx \,|\, \bY = \by)$ to be a minimal, 
and by construction regular, 
exponential family, 
$|\Mle| \in \{0, 1\}$, 
i.e., 
when the maximum likelihood estimator exists, 
the set $\Mle$ will contain a unique element when non-empty
\citep[Proposition 3.11, pp. 32--33,][]{Su19}.
As seen from the forms of $\ell(\nat; \bx, \by)$ given above, 
the gradients and Hessians of the log-likelihood equations 
do not directly depend on $g(\by)$. 
%echoed by the results in Proposition \ref{prop:inference}.
However, 
the following lemma shows how theoretical guarantees for estimators of $\truth$ will be indirectly influenced by the choice of $g(\by)$.


