We illustrate cross-layer dependence among layers in our modeling framework
by considering a separable multilayer network model using the Markov random field specification 
for $f(\bx, \nat)$ given in the previous section and maximal interaction term $H = 2$:
%i.e.,
%we consider a Markov random field specification which includes all single-layer effects and all pairwise interaction effects
%between layers.  
%We can write this model down as 
\be
\label{pairwise}
f(\bx, \nat)
\= \dprod_{\{i,j\} \subset \mN} \, 
\exp\left( \, \dsum_{k=1}^{K}\,\theta_{k} \,  x_{i,j}^{(k)} +  
\dsum_{k<l}^{K} \, \theta_{k,l} \,  x_{i,j}^{(k)} \, x_{i,j}^{(l)} \right).
\ee
The dimension of the parameter vector $\nat$ is $\dim(\nat) = K + \binom{K}{2}$,
with $K$ parameters governing the single-layer effects for the $K$ layers and $\binom{K}{2}$ combinations 
of layers to form the pairwise interactions for the cross-layer dependence effects.  

Define the ($K$-$1$)-dimensional vector 
$X_{i,j}^{(-k)} \coloneqq (X_{i,j}^{(l)} : l \in \{1, \ldots, K\} \setminus \{k\})$ 
to be the 
vector of edge variables in $\bX_{i,j}$ which excludes the edge variable $X_{i,j}^{(k)}$,
i.e.,
excluding the edge variable between nodes $i$ and $j$ in layer $k$.  
The conditional log-odds of edge $X_{i,j}^{(k)}$ takes the form:    
\beno
\scalebox{0.95}{$\log \, \dfrac{\mbP(X_{i,j}^{(k)} = 1 \,|\, \bX_{i,j}^{(-k)} = \bx_{i,j}^{(-k)}, Y_{i,j} = 1)}
{\mbP(X_{i,j}^{(k)} = 0 \,|\, \bX_{i,j}^{(-k)} = \bx_{i,j}^{(-k)}, Y_{i,j} = 1)}$} 
= \begin{cases}
\theta_{k} +  \dsum_{l \neq k}^{K}\, \theta_{k,l} \, x_{i,j}^{(l)}, & \norm{\bx_{i,j}^{(-k)}}_1 > 0 \\ 
+\infty, & \norm{\bx_{i,j}^{(-k)}}_1 = 0  
\end{cases}.
\ee
A primary advantage and motivation
of using a parametric Markov random field specification for $f(\bx, \nat)$ lies in the interpretability of the model. 
An effective approach to analyzing and understanding marginal network effects in such specifications is to study 
conditional log-odds of edges under different conditioning statements \citep[e.g.,][]{StScBoMo19}.
By the form of $h(\bx, \by)$,
when $Y_{i,j} = 1$,
we require $\norm{\bx_{i,j}}_1 > 0$,
meaning nodes $i$ and $j$ must have at least one connection in $\bX$. 
This is seen through the log-odds formula above,
where the log-odds of edge $X_{i,j}^{(k)}$ is equal to $+\infty$ when $\norm{\bx_{i,j}^{(-k)}}_1 = 0$. 
In contrast, 
when $\norm{\bx_{i,j}^{(-k)}}_1 > 0$,
the constraint $\norm{\bx_{i,j}}_1 > 0$ is already satisfied,
and the log-odds of edge $X_{i,j}^{(k)}$ depends on the layer specific parameter $\theta_k$, 
as well as the pairwise interaction effects where edges present in other layers $l \in \{1, \ldots, K\} \setminus \{k\}$ 
can influence the likelihood of the edge $X_{i,j}^{(k)}$ depending on the signs and magnitudes of the pairwise interaction 
parameters $\theta_{k,l}$ ($\{k,l\} \subseteq \{1, \ldots K\})$. 
