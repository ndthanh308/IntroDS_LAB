\documentclass[journal]{IEEEtran}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subfigure}
\usepackage{bm}
\allowdisplaybreaks[4]
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\newcommand{\todo}[1]{\textcolor{red}{#1}}
\newcommand{\done}[1]{\textcolor{orange}{#1}}
\newcommand{\rev}[1]{\textcolor{blue}{#1}}


\begin{document}
% paper title

\title{Equitable Time-Varying Pricing Tariff Design: \\ A Joint Learning and Optimization Approach}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Liudong~Chen
        and~Bolun~Xu% <-this % stops a space
% \thanks{L.~Chen and B.~Xu are with the Department
% of Earth and Environmental Engineering, Columbia University, New York, NY 10027, USA.
% E-mail: \{lc3671, bx2177\}@columbia.edu. L.~Chen and B.~Xu were supported in part by National Science Foundation under grant ECCS-2239046.}% <-this % stops a space
}

% The paper headers
% \markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
% {Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}



% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Time-varying pricing tariffs incentivize consumers to shift their electricity demand and reduce costs, but may increase the energy burden for consumers with limited response capability. The utility must thus balance affordability and response incentives when designing these tariffs by considering consumers' response expectations. This paper proposes a joint learning-based identification and optimization method to design equitable time-varying tariffs. Our proposed method encodes historical prices and demand response data into a recurrent neural network (RNN) to capture high-dimensional and non-linear consumer price response behaviors. We then embed the RNN into the tariff design optimization, formulating a non-linear optimization problem with a quadratic objective. We propose a gradient-based solution method that achieves fast and scalable computation. Simulation using real-world consumer data shows that our equitable tariffs protect low-income consumers from price surges while effectively motivating consumers to reduce peak demand. The method also ensures revenue recovery for the utility company and achieves robust performance against demand response uncertainties and prediction errors.

% Different from the commonly used time-of-use tariff, in time-varying tariffs, the utility company imposes a different daily price scheme to consumers based on demand and wholesale market price predictions. The utility thus motivates consumers to reduce their electricity bill by changing their demand based on the newly instructed prices, especially to reduce their demand during high price periods, which would help the utility to reduce peak demand or the cost of purchasing energy from the wholesale market. 
% However, the utility does not have the exact response function of how a consumer would react to price variations, and this is the main challenge to the time-varying price tariff design. On the one hand, the utility can significantly increase the cost of electricity, i.e., the energy burden, if it aggressively increases peak price, hoping to drive down 


% We take prices and demand data from ERCOT and build the demand response dataset based on consumers' agent model. We apply our method under normal, demand response, and price surge scenarios, analyze robustness and parameter sensitivity, and test it on real consumers. We find that equitable tariffs protect low-income consumers from demand response and price surges, reallocate electricity bill, and achieve demand reduction goals with strong robustness.

\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Demand response, energy equity, tariff design, neural network
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
Electricity demand will continue to grow due to electrification and increasing occurrences of weather extremes~\cite{energy}. Concurrently, consumers are  becoming more responsive to electricity prices due to the increasing adoption of smart and flexible resources such as home energy storage, smart heat pumps, and home energy management systems~\cite{qdr2006benefits, el2020contracted}. Increasing peak demand significantly stresses the distribution grid security and generation capacity. To this end, utilities are adopting time-varying pricing tariffs, including time of use (ToU) tariffs, and hourly different pricing scheme~\cite{review}, to incentivize consumers to shift their electricity demand and reduce costs. 

ToU tariffs allow operators to take predefined non-flat prices over a long time horizon, which provides consumers the possibility to arrange demand schedules. Utilities worldwide have employed ToU tariffs to facilitate demand shifting, such as incentivizing electric vehicles (EV) to charge during off-peak periods~\cite{tou3, tou9, tou4, tou5}. However, as more consumers become price-responsive, ToU may lead to new demand peaks and fail its design objective to flatten demand, as consumers will simultaneously increase their electricity consumption at the low price periods~\cite{toupeak}.
Besides, while ToU issues different prices over the day, these prices are fixed throughout the seasons. ToU hence is ostensibly a blunt pricing tool to regulate consumers' demand~\cite{tou8} in response to changing grid conditions, especially as the renewable penetration and the share of distributed energy resources (DER) increase.
% renewable energy resources, electric vehicles, and energy storage devices. 

Utilities are now experimenting with dynamic time-varying tariffs beyond ToU to more frequently update price schedules and to better align consumers' responses to changing grid conditions~\cite{rtp5, rtp6}. These prices should jointly reflect wholesale market prices,  distribution grid security constraints, and consumers' willingness to response. On the other hand, utilities must also address energy equity as the volatility in dynamic price tariffs may significantly increase the cost of electricity for low-income consumers who lack the means to reduce demand during peak price periods~\cite{review, nyt}. 
% to very high level in some cases, significantly burden low-income consumers and motivate them quit the programs~\cite{review}, ~\cite{nyt}. In fact, DSO's revenue recovery and demand response effect will also be negatively impacted by the fact that many consumers, due to their income levels or other issues, may have different price response behaviors.
To address these challenges, we provide a novel equitable solution to design day-ahead pricing tariffs using a joint learning and optimization approach. This method accurately capture the price response behavior of individual consumers and design tiered prices consider their social demographics. The detailed contributions are as follows:
\begin{enumerate}
    \item 
    We use energy burden to measure energy equity and formulate the equitable tariff design problem as a non-linear optimization problem, including an embedded recurrent neural network (RNN) architecture for modeling consumers' time-coupling and nonlinear responses to time-varying prices. 
    
    \item 
    We propose a joint learning-based identification and tariff optimization approach by training the RNN using historical price and demand measurements to develop up-to-date consumer response models, then directly incorporating the trained RNN into tariff optimization.  
    
    \item We develop a gradient-based algorithm to solve the optimization problem with proven convergence performance and computation scalability. %The model accurately captures the high-dimensional and nonlinear price response behavior of each consumer, rather than using conventional roughly quadratic or linear models, without introducing extra computational complexity.
    
    \item 
    We design a case study based on real-world data using the proposed approach to design income-tier-based tariffs by modulating wholesale day-ahead market prices. Our approach can effectively achieve peak shaving functions without adding energy burdens to low-income consumers. 
\end{enumerate}

The remaining of the paper is organized as follows: Section~II reviews related literature, Section~III and~IV introduces the proposed equitable tariffs design model and solution algorithm, Section~V describe simulation results under demand response (DR) and price surge settings, and Section~VI concludes the paper.

% \todo{P2 Why TOU not good enough; P3 - we have a solution for day-ahead pricing different from others. Briefly mention why don't just use wholesale day-ahead price. - Equity / affordability; local demand response; revenue recovery;  }
% Utilities are now experimenting with time-varying tariffs beyond ToU to better align consumers' responses to changing grid conditions, \todo{Ref} ...

% Liudong: reorganize section I&II so Section I is a short intro that ends on page I, while Section II is background. 

% donw! Could you also include this paper in the review, it shows the synchronous effect of TOU can cause new peaks if not managed properly: https://www.sciencedirect.com/science/article/pii/S136192092300055X

\section{Backgrounds and Literature Review}
\subsection{Time-varying tariffs}
% To enable consumers to adjust their electricity demand to better suit grid operation conditions, utilities are adopting new types of tariffs and seeking customer responses. With the transition of power grid structure and the increasing ability of demand-side response due to access to DER, schemes such as ToU pricing, and time-varying pricing tariffs are being studied and put into practice~\cite{review}. 

% The critical peak pricing scheme is generally used in event-based demand response (DR), which is conducted event by event and scheduled ahead of time for specific days or hours with very high demand, such as extreme hot days or holidays~\cite{event1}. Event-based DR is typically initiated in response to various trigger conditions, including maintaining system reliability, increasing system economics, and reducing grid congestion~\cite{event2}.
% Research on event-based DR focuses on designing critical peak pricing schemes to maximize the profits of load serving entities~\cite{event3}, investigating the best load curtailment strategies to maintain the stability of microgrids during island mode~\cite{event4}, and optimizing the scheduling of DR events for various conditions to use DR programs judiciously~\cite{event5}. However, event-based DR adjustments are limited and only applicable to a few time periods with intense demand and cannot effectively motivate demand-side flexibility.
Issuing consumers with different prices throughout the day is a convenient way to incentivize demand responses for aligning utilities' needs with consumers' cost-saving motivations~\cite{review}. 
ToU tariffs provide fixed daily price schedules monthly and have been widely adopted by utilities to incentivize consumer responses. For example, Con Edison has a ToU plan with peak and off-peak rates for residential, business, and EVs~\cite{tou4}. The Salt River Project also uses a ToU pricing plan to provide consumers with the greatest opportunity for savings by directing their energy use towards off-peak hours~\cite{tou5}. With ToU tariffs, consumers can arrange their schedules to shift or reduce demand, and their demand adjustment behaviors are predictable, helping operators regulate demand distributions effectively~\cite{tou1}. Many methods are designed to calculate ToU tariffs, including the Gaussian mixture model clustering technique~\cite{tou6} and combinations of statistical analysis and optimization algorithms~\cite{tou7}. % However, distributed system operator (DSO) requires more interactive ways to incentivize demand-side flexibility and achieve better demand regulation as more DER integration~\cite{tou1}. 
% and to design ToU tariffs with various price signals for California residents, varying by season~\cite{tou9}.

Utilities are now experimenting with more advanced time-varying tariffs beyond the ToU, such as day-ahead tariffs, which provide consumers with a different price schedule every day~\cite{rtp5, rtp6}. This effort aims to update tariffs to align with the changing grid conditions, such as distribution grids~\cite{tou3} or wholesale markets~\cite{tou8, rtp2, rtp3, rtp4}. 
Many studies also focus on the design and application of time-varying pricing tariffs. These design methods include a game-theoretic approach with consumers' occupancy status and consumption patterns\cite{rtp7}, a dynamical pricing model based on the supply and demand ratio~\cite{rtp8}, and an online learning method~\cite{rtp9}. Time-varying tariffs are usually used in designing the billing strategy of EV charging processes~\cite{rtp10}, helping consumers control their loads while reducing electricity expenditures~\cite{rtp11}.
% and optimizing the daily operation of battery energy storage systems~\cite{rtp12}.

\subsection{Equity and behavior models in utility tariff designs}
Consumers' demand flexibility is highly associated with their socio-demographic information, such as job type, income level, and household size~\cite{ATUS}. In general, low-income consumers are less flexible in responding due to more restricted working schedules and less access to flexible demand technologies such as smart home controllers or home energy storage. Meaning time-varying tariffs may increase their energy burden as low-income consumers are less likely to reduce their demand during high-price periods~\cite{rtp4}. Additionally, the adoption of solar photovoltaic (PV) by high-income households, which has increased with the development of DERs, will also increase costs for low-income consumers without PV~\cite{add1}. Thus, power systems must consider energy equity and design new tariffs in a fair and effective manner, which requires accurate consideration of consumers' response behaviors~\cite{add4}..

% As the American Time Use Survey (ATUS) shows, consumers' behavior and electricity consumption are highly flexible~\cite{ATUS} because of their subjective nature and varying socio-demographic information, such as income level and household size. As a result, consumers are likely to exhibit varying price response behaviors, and this variation is an essential factor to consider during tariff design since it directly affects consumers' ability to afford their electricity bills and their responsiveness to price signals ~\cite{rtp4}. Inaccurate consideration of their response behavior may weaken the DR effects and even hinder the ability of DSOs to recover their revenue, making it an important aspect to consider in tariff design~\cite{add4}.

Modeling consumers' price response is challenging as their behavior is subjective and often nonlinear features~\cite{Nat1}. Researchers use social science methods to capture user behavior, such as multi-criterion decision-making based on a brief survey to determine the weight of different objectives in DR optimization~\cite{add4}, and prospect theory to mimic consumers' decision-making preferences when facing risks~\cite{Chen}. However, these methods' computational complexity and non-differentiability features make it difficult to calculate behaviors and unsuitable for efficient gradient-based optimization required for various applications. Additionally, consumers' price response is time-coupled, where load consumption shifts to different time slots in response to price signals, presenting another challenge in identifying behaviors.

\subsection{Machine learning for DER management}
Machine learning techniques emerged as an effective way to model diverse and nonlinear participating and response behaviors in electricity markets with partial knowledge. For instance, neural networks can represent the lost load market clearing problem in the bi-level optimal bidding model~\cite{ml1} and capture the power system operation characteristics to solve the optimal power flow problem~\cite{ml4}. Additionally, in building energy systems with complex electrical and thermal dynamics, neural networks are also an emerging useful tool to capture system dynamics and devise optimal control schemes for energy consumption, which opens the door to incorporate system dynamics with decision-making~\cite{ml2, ml3}. In contrast to previous work, we propose a data-driven approach to design income-tiered day-ahead time-varying pricing tariffs. Using an RNN learning model, we can accurately capture time-coupled consumers' price response behavior by observing their historical response to price signals, providing a practical framework for developing equitable time-varying tariffs to facilitate demand flexibility.


\section{Model and Formulation}
% We first state the basic framework for designing the equitable tariff, then formulate the equitable tariff design problem as a non-linear optimization problem.

% \subsection{Joint optimization and learning framework}

We consider a scenario in which a utility supplying consumers with income-based time-varying price tariffs to incentivize response from demands while also controlling the induced energy burden over low-income consumers. The utility designs and issues a new price schedule each day ahead based on wholesale market clearing prices through a joint optimization and learning framework as shown in Fig. \ref{fig1}. Through the framework, we can obtain the price response behavior, i.e., relationships between prices $p$ and demands $D$ with their price response parameters $\theta$ and social demographics $I$, which then generates affordable and effective time-varying electricity tariffs for each consumer, i.e., suitable for their income tier and price response behaviors, despite the tariff volatility, and enable utilities to facilitate demand-side flexibility and realize energy equity.

% We formulate the equitable tariff design problem as a non-linear optimization problem, which explicitly considers consumers' specific price response behaviors and social factors, including demand information such as price elasticity and demand profiles, as well as socio-demographic information such as income level and family members. We then build the identification model by first utilizing an agent model to simulate consumers' demand response according to historical wholesale day-ahead market prices, then building an RNN model to map consumers' time-coupled prices into demand change. Using the price and DR data, we can train the RNN and get the price response parameters $W,b$ for each consumer. We thus model the price response behaviors as non-linear functions based on the neural architectures and learning parameters. 



% model the consumer's price response model identification as a learning problem, to identify unknown parameters in the DR process. With such price response behaviors, we formulate the DR price design problem as a constrained quadratic optimization problem.

% we don't want the cost to be surge, price design part is tariff design constraints, every consumer have different price. DR constraint is one piece of the cases, 
% time varying tariff, DR, price surge, protect low income, still get benefit from price response, we want everybody response to price, determine by the price response design,   market contingency cases

% As consumers participating in DR are highly affected by real-time price fluctuations, there is an urgent need to design an appropriate price strategy that can achieve DR goals while avoiding extra burdens on consumers. Specifically, every consumers receive acceptable electricity prices according to their income tier and price response behaviors despite the price volatility. Then the DR price can be described as reducing the peak demand while charging each consumer proportionally to their energy burden to promote energy equity. With such goal, we model the DR price design problem as a constrained quadratic optimization problem: 

% Figure environment removed



% \subsection{Energy equitable tariffs design model}

% \todo{Define optimization problem first, then identification problem - neural network training}

We formulate a nonlinear optimization problem including a quadratic objective, utilities' revenue recovery constraint, and consumers' response modeled using RNN. The overall goal of the tariff is to redistribute consumers' electricity bills and protect the interests of low-income consumers when participating in price response. We optimize $t \in T$ periods (24 hours in our case studies) over $\mathcal{I}$ consumer groups following $m\in M$ constraints. $\mathcal{I}_n$ represents energy burden-based consumer sub-groups, i.e., consumers within the same sub-group have similar energy burden.

The \textbf{optimization} model designs the price tariff schedule $\bm{p}_i$ for each consumer based on the updated RNN model $G_i(\bm{p}_i|\bm{\theta}_i)$ which predicts consumers' DR based on the price tariff
\begin{subequations}
\begin{align}
    \min_{\bm{p}_i} f=& \sum_{i\in\mathcal{I}} \Big(\Big[\frac{\bm{D}_i^T \bm{p}_i}{I_i} - \overline{E}\Big]^+\Big)^2 + \alpha \lVert \bm{p}_{i} - \bm{\lambda} \rVert_{2}^{2} \label{obj}\\
    &\text{s.t.}  \nonumber\\
    &\bm{D}_i = G_i(\bm{p}_i|\bm{\theta}_i) \label{dr} \\
    &\textstyle \sum_{i\in\mathcal{I}} \bm{D}_i^T \bm{p}_i \geq C + \bm{D}_{0,i}^T \bm{\lambda} \label{rev}\\
    &\bm{p}_i  = \bm{p}_j, \; \forall i,j\in \mathcal{I}_n, \forall n\in \mathcal{N} \label{group}
\end{align}
\end{subequations}
where $[ x]^+ = \max\{0,x\}$ is the positive value function. The objective function reduces the energy burden of low-income consumers by modulating the tariff price from the reference wholesale market price $\bm{\lambda}$.
$\frac{\bm{D}_i^T \bm{p}_i}{I_i}=E_i$ is the energy burden of consumer $i$~\cite{report_energyburden}, in which $\bm{p}_{i}$ and $ \bm{D}_{i}$ are the pricing and demand profile for each consumer $i$, and $I_i$ is the income data. $\bm{D}_{0,i}$ is the baseline demand profile when receiving the wholesale market prices. $\overline{E}$ is the desired energy burden threshold. $\alpha$ is the weighting factor for the wholesale price modulation.

\eqref{dr} uses a RNN $G_i$, parameterized with $\bm{\theta}_i$, to represent each consumer's price response behavior. \eqref{rev} is the utility company's revenue adequacy constraint ensuring the payment collected from the consumer affords the wholesale market purchasing cost and a constant O\&M cost $C$. \eqref{group} ensures all consumers from the same group receive the same price. 
The energy burden includes consumers' income information and energy consumption. Grouping consumers by energy burden promotes fairness by assigning similar energy burden groups the same electricity price. Besides, in practice, due to the large number of consumers and similarities in their performance, it is unnecessary to create personalized tariffs for each individual. While consumers in each group receive the same tariff, they still respond to the tariffs based on their individual behavior and income level, allowing them to be considered equitable entities.

% As (\ref{group}) shows, we group consumers and assign the same tariffs to each group. The group is determined by the energy burden, Here we use average value to express each groups' performance, which can be expressed as follows:
% \begin{align}
%         &E_{m}=\frac{\sum_{i \in \mathcal{I}} E_{i}} {\mathcal{I}}, \ 
%         \bm{D}_{m}=\frac{\sum_{i \in \mathcal{I}} \bm{D}_{i}} {\mathcal{I}}, \ 
%         I_{m}=\frac{\sum_{i \in \mathcal{I}} I_{i}} {\mathcal{I}} \label{average}
% \end{align} 

% \todo{add reasoning about income-based prices}. 


% $\bm{p}_{i}$ and $ \bm{D}_{i}$ are the pricing and demand profile for each consumer $i$; $\bm{D}_{0,i}^T$ is the baseline demand under day-ahead electricity tariffs; $G_{i}$ is the function that reflects consumers' price response behavior, which is different among consumers; $\bm{\lambda}$ is the vector of day ahead wholesale market tariffs, which is also the baseline tariff in the tariff design model; $I_{i}$ is income of consumer $i$; $\alpha$ is the tariff deviation parameters, which control the balance of tariffs change and energy burden optimization; $ G_i$ is consumers'  prices response behavior, determined by the identification process; $\bm{\theta}$ is the learning parameters of RNN, which includes weighing parameters and bias $\bm{W, b}$; $\bm{D}^{R}$ is the measurement demand obtained by the agent model (see Appendix).  

% The first term of (\ref{obj}) regards to energy burden optimization. Energy burden indicates each consumer's electricity bill as a percentage of income. The larger the energy burden, the heavier the consumer's burden and the more vulnerable to tariff fluctuations. Thus, we try to minimize the energy burden for some low-income consumers to the affordability threshold through easy-to-deploy time varying tariffs. At the same time, utility should charge more to high-income consumers to ensure their revenue.
% one effective way is to prioritize charging wealthy consumers with low energy burdens.

% The second term of (\ref{obj}) indicates the tariff design constraints. Although we design different time varying tariffs for each consumer, the designed tariff should be as close as possible to the wholesale market electricity tariff within an acceptable range, i.e., posting a constraint to the tariffs design. Otherwise the utility will charge high electricity bills to certain high-income customers in order to make profit. $\alpha$ in here control the influence of tariff constraints, smaller $\alpha$ means the system cares more about energy burden optimization while may burdening more on high-income user.

% During the identification process, the learning goal is to minimize the difference between predicted demand $G_i(\bm{p}_i|\bm{\theta})$ and measurement demand $\bm{D}^{R}$. Through the identification process, the price response behavior of each consumer (\ref{dr}) with time coupled characteristics can be obtained, which plays a crucial role in the optimization process.
% Besides, the behavior expressed by the network architecture and learning parameters can satisfy efficient gradient-based optimization algorithm since the neural network training use gradient-based algorithm. This enables our method to provide excellent computational performance and scalability suitable for applications under large-scale conditions. 

Our model also includes an optional demand reduction constraint if the utility wishes to incorporate a demand reduction event in the tariff:
\begin{align}
    \sum_{i \in \mathcal{I}} D_{i,t} \leq (1-\beta) \sum_{i \in \mathcal{I}} D_{\mathrm{0},i,t}, \ \forall t \in \{ \mathrm{PeakHours} \} \label{demand2}
\end{align}
where $\beta$ is the required demand reduction ratio in peak hours, and $\{\mathrm{PeakHours}\}$ is the set of hours determined by the utility to conduct demand response.

The optimization model is associated with the following \textbf{identification} model, which trains and updates the RNN model parameters using past price data and observed consumer demand $\bm{D}_i^{R}$ in response to the instructed prices:
\begin{align}
&\min \limits_{\bm{\theta}} L=\lVert G_i(\bm{p}_i|\bm{\theta})- \bm{D}_i^{R} \rVert_{2}^{2}
\end{align}

Hence, the utility executes the identification and the optimization model alternatively to update the user behavior RNN model based on past prices and responses, and use the updated model to design new tariffs.
% With such a formulation, consumers with high energy burdens will be optimized first, while wealthy consumers share some costs, both within acceptable tariff ranges. Besides, this formulation can also protect low-income consumers from price surges and demand reduction events. The major challenge here si to analysis this model and getting an optimal pricing scheme is to know the consumers' price response behavior, i.e., the $G_{i}$. 

  
\section{Solution Methods}
% In this section, we first design a data-driven method to identify consumers' price response behavior. Then proposed a gradient-based solution algorithm to solve the equitable tariff design problem with the learning results. We also divide consumers to different groups according to their energy burden. 

\subsection{Price responses model structure design and training}

% \todo{Better highlight the RNN structure design based on physical insights - consumer behavior over 24-hour}
We initially design a network structure for the identification process, as illustrated in Fig. \ref{fig2}. The $G$ block consists of several layers: an input layer with $T$ neurons representing prices in each time slot, where the number of neurons is determined by the length of the price time series; multiple hidden layers with varying numbers of neurons, which are determined based on the data characteristics; and an output layer with $T$ neurons corresponding to the demand change. The time series of demand determines the number of output neurons. Notably, we focus on learning the demand change during the DR period, denoted as $\Delta D$, because the demand change constitutes only a small portion of the baseline demand. Learning the baseline demand directly proves challenging in adequately capturing the demand change. By utilizing this network structure formulation, we can effectively model the consumer's price response behavior over $T$ hours.
Besides, more blocks can be constructed in the identification process, e.g., noise blocks formulate the agent prediction error (difference between real price response results and agent model results). Here we only consider the price response behavior block. Then the network and neurons model for one consumer can be defined as:

% Figure environment removed
\begin{align}
\Delta D_{t} &= G \left( p_{t}, \bm{\theta} \right) \label{rnn1}\\
\bm{\theta}&=\{ \bm{W}_{\mathrm{p}}, \bm{W}_{\mathrm{h}}, \bm{W}_{\mathrm{y}}, \bm{b}_{\mathrm{h}}, b_{\mathrm{y}} \}\\
\bm{h}_{t}^{(1)}&=\sigma(p_{t} \bm{W}_{\mathrm{p}}^{(1)} 
+ \bm{h}_{t-1}^{(1)} \bm{W}_{\mathrm{h}}^{(1)} 
+ \bm{b}_{\mathrm{h}}^{(1)}) \label{rnn2}\\
\bm{h}_{t}^{(l)}&=\sigma(\bm{h}_{t}^{(l-1)} \bm{W}_{\mathrm{p}}^{(l)} 
+ \bm{h}_{t-1}^{(l)} \bm{W}_{\mathrm{h}}^{(l)}  
+ \bm{b}_{\mathrm{h}}^{(l)} ) \label{rnn3}\\
\Delta D_{t}&= \sigma(\bm{h}_{t}^{(L)} \bm{W}_{\mathrm{y}}+b_{\mathrm{y}}) \label{rnn4}\\
\bm{h}_{0}^{(l)}&=\bm{0}, \   \forall l \in L \label{rnn5}
\end{align}
where $l$ is the hidden layer index of the network (except input and output layer), and $l \in L$. $\bm{h}_{t}$ is the vector of the hidden variable in the hidden layers, whose dimension is determined by the neurons of the corresponding hidden layer. $\bm{W}_{\mathrm{p}}, \bm{W}_{\mathrm{h}}, \bm{W}_{\mathrm{y}}$ are network weighting parameters of input feature $p$, hidden variable $\bm{h}_{t-1}$, and hidden variable in output layer $\bm{h}_{t}$, the dimension of the matrices corresponding to the number of neurons; $\bm{b}_{\mathrm{h}}, b_{\mathrm{y}}$ are the network bias parameters in the hidden layers and output layers, $\bm{b}_{\mathrm{h}}$ is a vector with the same dimension of the neurons number in the hidden layers, and $b_{\mathrm{y}}$ is a number. $\sigma(\cdot)$ is the activation function used to formulate non-linear features of the network, which may differ in layers.

The input to this network is the time series of prices, and the learning process takes place per time period. After processing the first time slot, the learning results are recorded through hidden variables and subsequently updated at each new time slot based on the new time slot's features. This process enable the time series features of prices transfer in the network training process, and realizes the time coupled relationship learning with the demand change. Besides, the network share the same parameters $\bm{W,b}$ in all time slots, which reduces the computation burden of the network.

To train the network, we use an agent model to simulate consumers' price response process, which explicitly describe in Appendix. Consumer will change their reduced demand and shiftable demand to minimize their electricity bill response to specific tariff patterns. Then we can obtain the demand change data and corresponding price data as the output label and input feature of the RNN, respectively, which can be expressed as follows:
\begin{align}
&\{[\bm{p}_{i}],[\bm{\Delta D}_i^{R}]\}
\end{align}

With the datast, we are able to train the RNN and get the parameters $\bm{\theta}$. Here the RNN training is followed by the forward calculation and backward propagation. The gradient of loss function $L$ with regards to $\bm{\theta}$ is calculated by derivative chain rule and computational graphs layer by layer, and the learning rate is computed by adaptive moment estimation (Adam)~\cite{mitbook}.
% During the training process, the learning rate is computed by adaptive moment estimation (Adam), which utilizes the average of the first and second moments of the gradient. This allows the learning rate adaptive to the loss function and makes the method easy-to-use and requires less memory.

\subsection{Gradient-based optimization solution algorithm}
% After training the RNN in the identification process, the equitable tariff design problem is reformulated as follows: \todo{Remove the repetitive formulation?}
% \begin{subequations}
% \begin{align}
%     \min_{\bm{p}_i} \ & f=\sum_{i\in\mathcal{I}} \Big(\Big[\bm{E}_{i} - \overline{E}\Big]^+\Big)^2 + \alpha \lVert \bm{p}_{i} - \bm{\lambda} \rVert_{2}^{2} \label{obj1}\\
%     &\text{s.t.}  \nonumber\\
%     &\bm{D}_i = G_i(\bm{p}_i|\bm{\theta}^*) \label{dr1} \\
%     &\textstyle \sum_{i\in\mathcal{I}} \bm{D}_i^T \bm{p}_i \geq \bm{D}_{0,i}^T \bm{\lambda}\\
%     &\sum_{i \in \mathcal{I}} D_{i,t} \leq (1-\beta) \sum_{i \in \mathcal{I}} D_{\mathrm{0},i,t}, \ \forall t \in \{ \mathrm{PK} \} \label{newd1}\\
%     &\bm{p}_i  = \bm{p}_j, \; \forall i,j\in \mathcal{I}_m, \forall m\in \mathcal{M} \label{group1}
% \end{align}
% \end{subequations}
% where $\bm{\theta}^*$ is the optimal RNN parameters obtained from identification process, $G_{i}$ is the network structure expressed by (\ref{rnn1})-(\ref{rnn5}); 

% \begin{align}
% \begin{split}
%     \min \limits_{p} \ f(p,\bm{\theta},\Delta D^{R},I)&=\lVert \max(\bm{E}, E_{\mathrm{bond}}) - E_{\mathrm{bond}} \rVert_{2}^{2} \\
%     &+\alpha \lVert \bm{p}_{i} - \bm{p_{\mathrm{D}}} \rVert_{2}^{2} \label{newobj2} \\
% \end{split}
% \end{align}

% \begin{align}
%      & \Delta D_{i,t}= g_{i}(p_{t} \ | \ \bm{W,b,h}_{t-1},\bm{h}_{t}),\  \forall i \in \mathcal{I} \label{network}\\
%     \mathrm{s.t.} \ & \sum_{i \in \mathcal{I}} D_{i,t} \leq (1-\beta) \sum_{i \in \mathcal{I}} D_{\mathrm{0},i,t}, \ \forall t \in \{ \mathrm{PK} \} \label{newd1}\\
%     &\sum_{i,t} p_{i,t} D_{i,t} \geq P_{\mathrm{ini}} 
% \end{align}

%Here, without loss of generality, we consider the DR constraints to analyze the solution algorithm. 
The tariff optimization is a non-convex problem due to the inclusion of RNN for modeling consumer responses. 
%Due to the non-linear and high-dimensional price response function, the tariff design problem is not a convex optimization problem. Traditional commonly used methods, such as Karush–Kuhn–Tucker (KKT) conditions, cannot be directly applied. 
We introduce a gradient-based solution algorithm including an identification stage and an optimization stage. % These two stages actually serve for the same purpose with different decision variables. 
% The gradient-based algorithm iteratively updates the decision variables by calculating the gradient and learning rate, which expresses as follows:
% \begin{align}
%      x=x+v\Delta x
% \end{align}
% where $x$ is the decision variable, $v$ is the learning rate, $\Delta x$ is the gradient with regard to $x$. 
To incorporate constraints into the gradient-based algorithm, we move the constraints to the objective function using log-barrier functions to keep the decision variables within bounds during iterations. The augmented optimization problem can be expressed as:
\begin{align}
\begin{split}
        \min \limits_{\bm{p}_i(\mu)}\ &F_{0}=\mu f+\sum_{m \in M} \varphi_{m}(C) \\
        &= \mu  \Big( \sum_{i\in\mathcal{I}} \Big(\Big[E_{i} - \overline{E}\Big]^+\Big)^2 + \alpha \lVert \bm{p}_{i} - \bm{\lambda} \rVert_{2}^{2}   \Big)\\
    &+ \sum_{t\in \{\mathrm{PK}\}} \ln(C_{t}) + \ln(C_{1}) \label{newobj}
\end{split}   
\end{align}
 \vspace{-0.2cm}
\begin{align}
        &C_{t}=-\sum_{i\in\mathcal{I}} D_{i,t}+(1-\beta)* \sum_{i\in\mathcal{I}} D_{\mathrm{0},i,t}, \ \forall t\in \{\mathrm{PeakHours}\} \\
        &C_{1}=-\sum_{i\in\mathcal{I}} \bm{D}_i^T \bm{p}_i + \bm{D}_{0,i}^T \bm{\lambda}
\end{align}
where $\varphi$ is the penalty function, and $\varphi(C)=\ln(C)$; $\mu$ is the parameter of the algorithm, which increase by iterations. We consider constraints in the gradient of the objective function, and the gradient of $F_{0}$ with regard to $\bm{p}_i(\mu)$ will be expressed as a function of parameter $\mu$. 

% \todo{What's W and b again?}
With the parameters $\bm{W,b}$ from the identification process, we are able to calculate the gradient of $F_{0}$ with regard to $p_{i,t}$, which is also obtained through the derivative chain rule: 
\begin{align}
\begin{split}
      \frac{\partial	F_{0}}{\partial p_{i,t}}&=\frac{\partial	F_{0}}{\partial E_{i}}  \left( \frac{\partial E_{i}}{\partial D_{i,t}}  \frac{\partial	D_{i,t}}{\partial p_{i,t}} 
      + \frac{\partial E_{i}}{\partial p_{i,t}}  \right)  + \sum_{m} \frac{\partial \varphi_{m}}{\partial p_{i,t}}\\
      &= \frac{2\mu (E_{i}-E_{\mathrm{bond}})}{I_{i}} 
       \left( D_{i,t} + \frac{\partial D_{i,t}  p_{i,t}}{\partial p_{i,t}} \right) \\
      &-\delta(t)   \frac{\partial D_{i,t}}{\partial p_{i,t}} \frac{1}{{C}_{t}} 
      -\left(D_{i,t} + \frac{\partial D_{i,t}p_{i,t}}{\partial p_{i,t}} \right)\frac{1}{{C}_{1}}  \label{der}  
\end{split}
\end{align}
\begin{align}
    \delta(t)=\left \{
        \begin{aligned}
         &1, \ \ \mathrm{if} \  {t\in \{\mathrm{PeakHours}\}} \\
         &0, \ \ \mathrm{OTW}
        \end{aligned}
    \right.
\end{align}

The most critical part is to calculate the partial derivative $\frac{\partial	D_{i,t}}{\partial p_{i,t}}$, which follows the RNN architecture and should be obtained through derivative chain rule and computational graphs. It is noted that the demand change of consumer $i$ in time slot $t$ is the output of neuron $t$ in the output layer. Here we only analyze one neuron for example.
% Here we analyze the partial derivative of the demand change of consumer $i$ at time slot $t$:
\begin{equation}
\begin{split}
    \frac{\partial D_{t}}{\partial p_{i,t}} &= \frac{\partial D_{t}}{\partial \bm{h}_{t}^{(L)}}  
     \prod_{l=2}^{L} \left( \frac{\partial \bm{h}_{t}^{(l)}}{\partial \bm{h}_{t}^{(l-1)}} 
     + \frac{\partial \bm{h}_{t}^{(l)}}{\partial \bm{h}_{t-1}^{(l)}} 
    \right)
    \left( \frac{\partial \bm{h}_{t}^{(1)}}{\partial p_{i,t}} + \frac{\partial \bm{h}_{t}^{(1)}}{\partial \bm{h}_{t-1}^{(1)}} \right) \\
    &=\bm{W}_{y} \frac{\partial \sigma}{\partial \bm{h}_{t}^{(L)}}
     \prod_{l=2}^{L} \left( \frac{\partial \sigma}{\partial \bm{h}_{t}^{(l-1)}}  \bm{W}_{p}^{(l)} 
     + \frac{\partial \sigma}{\partial \bm{h}_{t-1}^{(l)}}  \bm{W}_{h}^{(l)}
    \right) \\
    &*\left( \frac{\partial \sigma}{\partial {p}_{i,t}} \bm{W}_{p}^{(1)} + \frac{\partial \sigma}{\partial \bm{h}_{t-1}^{(1)}} \bm{W}_{h}^{(1)} \right) \label{derend}
\end{split}
\end{equation}

Since each consumer corresponds to a different structured network, this step should be repeated in each network to obtain all partial derivatives in (\ref{der}). After getting the gradient of the objective function, we use Hessian matrices to calculate the Newton step and update the decision variables during the iteration process. 

% As the RNN architecture with non-linear activation function, the optimization problem is non-convex. Hopefully, 
Previous work and practices have demonstrated that gradient-based algorithms can achieve good convergence performance in RNN~\cite{globalmini, proof2}. Using second-order gradient-based optimization methods can capture curvature information, enabling them to seamlessly escape flat regions and saddle points and contribute to fast convergence and high robustness~\cite{proof4}.
These demonstrate that the identification (network training) and optimization process related to RNN architecture can converge effectively. In the optimization process, the variables are tariff $p$, whose number is significantly less than the weighting variables $\bm{W}$ in the training process. Besides, the gradient of these two variables has the same structure as expressed in the derivative chain and computation graph (Fig. \ref{fig2}). Specifically, according to (\ref{rnn2})-(\ref{rnn3}), taking derivative with regards to $p$ or $\bm{W}$ will get similar results with the same structure. 
Thus, using gradient-based solution algorithms can at least converge to a local minimum that satisfies the error requirements (Please see detailed proof in Appendix). In the case study, we also simulate many times to show the robustness of the solution results. 
% (3.1.2 in~\cite{}, theorm in ).
% The gradient based solution method will converge to a global optimal solution in convex optimization because the negative gradient direction always reduce the objective function in a fast way. The key of this problem is the RNN architecture. Hopefully, as~\cite{du2019gradient} shows, with gradient descent method, fully connected neural networks will converge to the global minimum at a linear rate. This demonstrates that the gradient of the RNN architecture (fully connected) also reduce the objective function until reach a global optimal solution. Thus, the gradient based solution method will converge to a global optimal solution after gradient based iterations. 

% \todo{Move the grouping information into the simulation.}


\begin{algorithm}
	%\textsl{}\setstretch{1.8}
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
        \caption{Gradient-based solution algorithm} 
	\label{alg3} 
	\begin{algorithmic}[1]

  \STATE  Initialization: Dataset $\{\bm{p}_i,\bm{\Delta D}_i^{R}\}$, parameters $\mu$, $\bm{\lambda_{i}}$, $\bm{D}_{0,i}$, $\alpha$, $\beta$, $I_{i}$, $\overline{E}$, tolerance $\epsilon=1e^{-6}$, number of constraints $M$.
   % \STATE Calculate initial energy burden for clustering:\\ $E_{0,i}=\frac{\sum_{t\in T}D_{0,i,t}*P_{\mathrm{D},t}}{I_{i}}$.
   %  \STATE Clustering consumer with similar energy burden $E_{\mathrm{0},i}$ and get $\{U_{1},...,U_{C}\}$
   % \STATE Calculate cluster values following (\ref{average})
	\STATE Train RNN using dataset, obtaining price response function $\bm{D}_{n}=G_{n}(\bm{p}_{n}|\bm{\theta}_{n})$ for each group. 

		\WHILE{$M / \mu  \geq \epsilon$} 
                \WHILE{$ \Vert {\nabla \bm{p}_n} \Vert \geq \epsilon$}
		      \STATE Calculate derivative $\nabla \bm{p}_{n}$ of $F_{0}(\bm{p}_{n})$ based on (\ref{der})-(\ref{derend})
                \STATE Choose step size $v$ via backtracking line search
		      \STATE Update $\bm{p}_{n}=\bm{p}_{n}+v \Delta \bm{p}_{n}$ 
		\ENDWHILE
		\STATE Update $\bm{p}_n=\mu \bm{p}_{n}$
            \STATE Increase $\mu=10\mu$
		\ENDWHILE 
         \STATE Broadcast modified tariffs $\bm{p}_{n}^*$ to consumers, obtain consumers modified demand $\bm{D}_{i}^*$ by agent model.
        \ENSURE Day-ahead time varying electricity tariff $\bm{p}_{n}^*$ and modified consumers demand $\bm{D}_{i}^*$
	\end{algorithmic} 
 \end{algorithm}

% \begin{align}
%     &I_{k}^{(1)}=\left \{
%         \begin{aligned}
%          &1, \ \ \mathrm{if} \ (W_{1,k}^{(1)}*p+b_{0,k}^{(1)}) \geq 0\\
%          &0, \ \ \mathrm{OTW}
%         \end{aligned}
%     \right.\\
%     &I_{j}^{(l)}=\left \{
%         \begin{aligned}
%          &1, \ \ \mathrm{if} \ (\sum_{j=1}^{K_{l-1}} W_{j,k}^{(l)}*z_{l-1,j}+b_{0,k}^{(l)}) \geq 0\\
%          &0, \ \ \mathrm{OTW}
%         \end{aligned}
%     \right. \label{derend}
% \end{align}
% \subsection{Clustering method}
% The design of clustering method is behind three main reasons. At first, Consumers with similar energy burden should receives similar electricity tariffs according to the tariff design formulation (\ref{obj}). From the perspective of equity, it is also a fair way to set similar tariffs for such consumers. Besides, in reality, it is unnecessary to generate personalized tariffs for each consumer due to the large number of end consumers and some of them have similar performance. Therefore, we cluster consumers with similar initial energy burdens (the energy burden when receiving day-ahead tariffs from wholesale market) as follows:
% \begin{align}
%         &\{(W_{c},b_{c},I_{c},\bm{D}_{c},E_{c})\ |\ \forall i\in N_{c}\} : U_{c} \\
%         &E_{c}=\frac{\sum_{i \in N_{c}} E_{i}} {N_{c}}, \ 
%         \bm{D}_{c}=\frac{\sum_{i \in N_{c}} \bm{D}_{i}} {N_{c}}, \ 
%         I_{c}=\frac{\sum_{i \in N_{c}} I_{i}} {N_{c}} \label{average}
% \end{align}
% where $U,c$ are the consumers' cluster and corresponding index, and $c\in C$; $N_{c}$ is the set of consumers in cluster $c$; $E_{c},\bm{D}_{c},I_{c}$ are the average energy burden, demand, and income of cluster $c$; $W_{c},b_{c}$ are the consumers' price response parameters of cluster $c$, which is learned by the average demand change and corresponding tariff information of each cluster.

% We then set time varying tariffs for each cluster according to cluster's overall performance and average price response behaviors. Every consumer receive tariffs according to their cluster and respond to this tariff through agent model individually. Thus, although consumers in a cluster get the same tariff, each consumer still follows its own behavior and income level to respond to the tariffs, which allows them to be regarded as equal entities. The clustering process largely reduce computational burden while reserving each consumer's characteristic.

% The algorithm for the proposed method can be expressed as follows.



\section{Simulation}
% \todo{Talk about how income tiers are decided.}
 In this section, we first provide consumers' price response identification results. Then we design three case studies to analyze the equity time-varying tariffs design results: (1) tariff design; (2) DR events with demand reduction target; (3) price surge with extremely high wholesale market prices.

\subsection{Data}
In this study, we use the raw data of Austin, Texas, from ERCOT, which includes day-ahead 15-minute granularity price and corresponding load consumption data, including 25 consumers in 2018. Here we use one-day load consumption to represent one consumer and transfer 15-minute granularity price and load consumption data to hourly data. Then we choose 40 days of hourly load consumption data of 25 consumers, and calculate their demand change during price response processes using the agent model. We build the dataset with 1000 consumers and 1460 historical day-ahead electricity prices and corresponding demand change information through the overall formulation. In the optimization process, 1000 consumers' incomes are randomly generated between 800\$ to 60000\$ and divided over 365 days to get their daily income. Then we rank consumers according to their energy burden and separate consumers into 10 energy burden groups with 100 consumers in each group and use consumers' average value to express the performance of groups. The parameters $\overline{E}$ is set as 0.06, $\alpha$ is set as 1.


\subsection{Consumers' price response behavior identification}
In the RNN's training process, we set the learning rate to 0.0001, 2 hidden layers with 10 neurons, and chose Adam as the gradient-based optimizer. The first hidden layer uses ReLU as the activation function, and the second uses SeLU~\cite{selu}. The reason is that consumers' demand change is both positive and negative; ReLU will eliminate the negative part and kill the neurons when the negative appears. Thus, use SeLU to replace ReLU but keep the ReLU in the first layer to reduce the computation time. The training process is shown in Fig. \ref{train}, which presents good convergence of RNN. Although some minor fluctuations exist, there is nothing overfitting phenomenon, and MSE keeps around 0.0005. Besides, the prediction error almost concentrates on 0, indicating high prediction accuracy. Here we need to train 10 RNNs to get the price response behaviors of each group. The overall training time is 200s, and the RMSE and MAPE for each group remain at a low level, e.g., 0.065 and 0.78 in group 7. 

% Figure environment removed

By training the RNN architecture using the provided dataset, we are able to derive network parameters that effectively capture consumers' price response behaviors, as represented by the agent model. This is clearly demonstrated in Fig. \ref{predict}, where the prediction results closely match the behavior depicted by the agent model. 


% Figure environment removed





\subsection{Time varying tariff results}
\subsubsection{Case (1) tariff design}
In the tariffs design case, the primary objective is to optimize consumers' load arrangement by incentivizing the reduction and shifting of load, while also redistributing the electricity costs among consumers of varying income levels. Fig. \ref{1price} shows the modified tariffs compared with the baseline scenario. The overall tariffs for low-income groups are reduced while those for high-income groups are increased, particularly during peak demand time slots 11-15. Besides, the high tariffs are shifted to demand valley time slots. As a result of these modified tariffs, consumers adjust parts of reducible demand motivated by the tariffs to reduce the electricity bills and energy burden. This is further illustrated in Fig. \ref{1burden}, which shows energy burden in both the baseline and modified scenario.  

% Figure environment removed


% % Figure environment removed

% % Figure environment removed
From Fig. \ref{1burden}, it is evident that the energy burden experienced by low-income groups (1-4) shows a reduction in terms of variation, range, and expected value. Conversely, high-income groups (5-10) witness an increase in their energy burden due to cost sharing. Moreover, the aggregated demand under the modified tariff is 32,725 kWh, which is similar to the baseline tariff's 35,255 kWh. However, the modified tariff achieves a more favorable energy burden distribution, particularly benefiting low-income consumers by reallocating electricity costs based on income level and demand conditions. The analysis also shows that consumers with higher energy burdens undergo greater modifications and receive increased benefits. In addition to value, the range of each group also expands, suggesting that wealthier consumers contribute a larger share of the costs to promote energy equity. Additionally, the modified average line exhibits a more linear trend, reflecting a fair approach to redistributing electricity bills.

% Figure environment removed

The computation time for this case is about 81s, including 41s for tariffs optimization and 40s for demand optimization using the agent model after receiving the modified tariffs. Actually, the computation time does not increase with the number of consumers, because tariff optimization is performed at the group level and demand optimization is a separate process for each consumer, which can be efficiently achieved through multi-core parallel computing. Besides, the income of the utility increased by nearly 45\$, accounting for 4.5\% when compared to the baseline profit. This increment falls within an acceptable range, demonstrating the viability and effectiveness of the proposed approach.
% The profit change is affected by the tariff deviation parameter $\alpha$, and we conduct the sensitivity analysis in the next section.




\subsubsection{Case (2) DR event}
In this case, we apply our method with a 2\% demand reduction target at the highest 4 time slots. Fig. \ref{2price} shows the average tariff in peak time slots.
The modified tariffs for high-income groups increase to motivate high-income consumers to reduce demand, while tariffs for low-income groups reduce or keep at a low level even during these peak time slots. 
This shows that high-income consumers take the risk during demand reduction events, protect low-income consumers, and share part of the cost of low-income consumers to facilitate energy equity. 

% The demand results also verify that high-income consumers reduce the demand to satisfy the DR target, while low-income consumer almost keep or slightly increase their demand.  
% and in non-peak time slots, high-income consumers also receive higher tariffs to share part of the cost of low-income consumers to facilitate energy equity. The demand results in Fig. \ref{2demand} shows that in peak time slots, high-income consumers reduce the demand to satisfy the DR target, while low-income consumer almost keep their demand. The demand also reduce in off-peak hour because consumers adjust their reducible demand follow the tariff motivation to save cost. 

% % Figure environment removed
% Figure environment removed


% % Figure environment removed

% % Figure environment removed

The modified energy burden, as depicted in Fig. \ref{1burden}, demonstrates a significant decrease in energy burden for low-income groups, while high-income groups experience an increase, indicating that they take risks. These findings highlight the effectiveness of our approach in achieving a fair allocation of electricity costs, without compromising the effectiveness of DR measures and protecting low-income consumers from excessive demand reductions. Besides, high-income consumers' energy burden is slightly higher than in case (1), showing that high-income consumers respond more to the DR. 


% % Figure environment removed

The computation time for this case is 140s, comprising 100s for price optimization and 40s for demand optimization using the individual consumers' agent model. This duration is longer than the tariff design case because the DR constraints prolong the tariff optimization process. The utility's income increased by 55\$ in this case, accounting for 5.5\% compared to the baseline profit. The reason is that the DR event requires consumers to reduce more demand, prompting the utility to set higher prices and get additional revenue.




\subsubsection{Case (3) price surge}
In this case, we intentionally create significantly higher wholesale market prices by multiplying the price by 5 for the 14th and 16th time slots, as depicted in the Surge base and Surge scenarios in Fig. \ref{2price}. The average modified tariffs for these time slots clearly demonstrate that the burden of tariff surges falls on high-income consumers as their tariffs increase, while low-income consumers continue to receive lower tariffs and maintain similar load consumption patterns. It is worth noting that the modified tariffs are also influenced by demand, particularly for high-income groups. For instance, group 9 exhibits a slightly higher tariff than Group 10 due to its higher demand (2.8kWh) compared to Group 10's demand (2.6kWh). This tariff adjustment aligns with the utility company's revenue adequacy constraint, where charging higher tariffs to high-demand groups ensures greater payments from consumers. 
The energy burden results show a slight increase for high-income groups compared to other scenarios, as they bear the impact of the price surges to protect low-income consumers. 

The computation time for this case is 86s, with 46s for price optimization and 40s for demand optimization. The utility's revenue increased by 75\$ (5.4\%), similar to other cases. The slightly higher revenue can be attributed to the changes in wholesale market prices and baseline demand.
% However, due to the modified price reduce in surge time slots, other time slots price slightly increase to keep the operators profit and reduce the overall price manipulations. 

% % Figure environment removed

% % Figure environment removed

% results (Fig. \ref{3burden}) show that high-income consumers energy burden increase more than other scenarios. The reason is that high-income consumers need to undertake the price surge influence to protect low-income consumers. Besides, low-income consumers energy burden can not reduce to the previous level because their baseline energy burden is increased by the price surge.


% % Figure environment removed


% The reason is that higher baseline prices lead to higher baseline energy burdens on low-income consumers, while high-income consumers already share a lot of the cost. Thus, DSO reduce the price largely to keep the low-income consumers benefit and take some cost. 








% \subsection{Sensitivity analysis}
% In this section, we analyze the influence of tariff deviation parameter $\alpha$ on the optimization results - consumers average payment and energy burden. Table \ref{tab1} list the consumers average payment change, which shows that the change of their payment decrease with the parameter increase. That is because the large parameter increase the influence of tariff changes on the objective function, and DSO tends to keep the baseline price, resulting in a decrease in the change of payment. Besides, we choose cluster 1, 3, 8, 10 to show the average energy burden change. Corresponding to the change of consumers payment, the optimization effect of energy burden decreases with the increase of parameters. To satisfy the demand reduction target, more cluster need to reduce their load consumption and pay more bill with high tariffs as the high-income clusters take less risk. Specifically, cluster 3 begin to increase energy burden when parameters larger than 1, while it can reduce energy burden when the parameter is 0.5 because the risk can be fully taken by higher income clusters.
% It is noted that percentage energy change in cluster 10 slightly less than cluster 8 because high-income consumers energy burden change is caused by DSO's revenue balance requirement. Under the demand reduction conditions, consumers with high demand will get a higher tariffs to reduce their demand and thus need to pay a little more. In this case, the total demand in cluster 8 is 34.75kW, larger than cluster 10 33.91kW, so the energy burden in cluster 8 change more. 
% \begin{table}[htbp]
% \centering
% \caption{Consumers payment with different price deviation parameter \todo{Remove sensitivity analysis about $\alpha$}}
% \begin{center}
% \begin{tabular}{|p{0.14\textwidth}|p{0.03\textwidth}|p{0.03\textwidth}|p{0.03\textwidth}|p{0.03\textwidth}|p{0.03\textwidth}|p{0.03\textwidth}|}
% \hline
% \centering
% \textbf{Parameter} & 0.5 & 0.8 &  1 &  1.5 &  2 & 5  \\
% \hline 
% \centering
% \textbf{Consumers payment change}& 7.5\% & 6.2\% &  5\%  & 4.7\% &  4.4\%  &  3.3\%  \\
% \hline
% \end{tabular}
% \label{tab1}
% \end{center}
% % \vspace{-.8cm}
% \end{table}


% % Figure environment removed







\subsection{Model validation and reliability analysis}
\subsubsection{Model validation}
To validate the proposed approach, we use the agent model to simulate real consumers and generate the tested scenario. The results, including the energy burden, utility revenue, and peak shaving, are depicted in Fig. \ref{benchmark} for the baseline, tested, and predicted scenarios with the modified tariff. The profit and the energy burden in each group consistently outperform those of the baseline scenario, demonstrating the effectiveness of our methods. The energy burden of the middle group shows a slight increase, which can be attributed to the consideration of both income and demand information, with the middle group exhibiting higher demand. Furthermore, small changes in the energy burden of higher groups actually corresponded to larger shifts in payments.

There are minor differences observed between tested and predicted scenarios, which mainly come from two parts, the prediction error of the RNN and the grouping approach. In the identification process, the RNN learns the price response behavior of each group based on the average demand of the entire group, instead of individual consumers' demand. However, the tested scenario is calculated by each consumer's agent model. Although the groups can approximate consumers' behavior to some extent, differences still exist when compared to the behavior of individual tested consumers. Specifically, we initialize the RNN training 23 times, the comparison results show the energy burden difference is less than 0.015 (within 11\% when compared to the tested scenario), and the profit difference is within 0.088\$ (8\%). In terms of peak shaving, the proposed method realizes a 2\% demand reduction in peak time slots. The demand reduction in the tested scenario is 18.2\%, 2.4\%, 7.4\%, 2.3\%, similar to that of the predicted scenarios with 15.8\%, 3.9\%, 8.9\%, 4.6\%.

% Figure environment removed


\subsubsection{Demand reduction reliability}
We analyze the influence of RNN's prediction error (Fig. \ref{train}) on the demand reduction goal. Through the validation process of RNN, we get the prediction error distribution, as shown in Fig. \ref{reliable}. It is obvious that although the demand reduction ratio is differently affected by the prediction error, the peak demand reduction targets can be achieved with success rates of 100\%, 100\%, 100\%, and 99.6\%, indicating the strong reliability of our method. 
% Figure environment removed











\section{Conclusion}
This paper proposes an energy equity pricing tariff design method for responsive consumers, using RNN to capture consumers' time-coupled price response behaviors and consider social demographics in the formulations. By leveraging a dataset constructed through the consumers' agent model, we obtain consumers' personal price response behaviors and use it to design energy equity pricing schemes. We apply our method to tariff design, DR event, and price surge cases with demand reduction constraints and high-price time slots, respectively. The results show our method effectively reduces consumers' energy burden difference and protects low-income consumers from the adverse effects of price surges. The demand reduction targets also show great robustness when considering the effect of prediction error. By testing our method on  agent-based consumer models, the identification and optimization framework results are consistent with the benchmark, demonstrating that our method accurately captures consumers' price response behavior and works well in real conditions.
Future directions will move toward distributed energy resource conditions and enhancing the identification process by including more detailed methods, e.g., building uncertainty blocks in structured neural networks.
% We also analyze the parameters sensitivity and find an opposite direction of maintaining prices and reducing energy burden. Thus, operator should find a trade-off between changing wholesale market prices and reducing energy burden.
% if have a single appendix:
\vspace{-.2cm}
\appendix
\subsection{Agent model}
It is noted that many agent models for consumers' price response process can be used in work. Here we use the following agent model to simulate consumers' price response process:
\begin{align}
    \min \limits_{\bm{D}_{\mathrm{r}},\bm{D}_{\mathrm{s}}} \ & \bm{p}^{T}\bm{D} + c_{1} \bm{D}_{\mathrm{r}}^2 + c_{2} \bm{D}_{\mathrm{s}}^2 \\
    &\bm{D} = \bm{D}_{0}+ \bm{D}_{\mathrm{r}} + \bm{D}_{\mathrm{s}} \\
    \mathrm{s.t.} \ &\sum_{t \in T} D_{\mathrm{s},t} = 0  \\
    &\underline{D_{\mathrm{s}}} \leq \bm{D}_{\mathrm{s}} \leq \overline{D_{\mathrm{s}}} \\
    &\underline{D_{\mathrm{r}}} \leq \bm{D}_{\mathrm{r}} \leq \overline{D_{\mathrm{r}}}
\end{align}
where $c_{1}, c_{2}$ are the parameters of reduced demand and shiftable demand, which is determined by each consumer's price response behaviors; $\underline{D_{\mathrm{s}}}, \overline{D_{\mathrm{s}}}$ are the lower and upper bond of shiftable demand, respectively; $\underline{D_{\mathrm{r}}}, \overline{D_{\mathrm{r}}}$ are the lower and upper bond of reduced demand, respectively.




\subsection{Convergence proof of proposed method}
We first show the derivative of (\ref{newobj}) with regard to $p$ is similar to the derivative with regard to $\bm{W}$.
\begin{align}
     &\frac{\partial D_{t}}{\partial p_{t}}
     = \frac{\partial D_{t}}{\partial \bm{h}_{t}^{(L)}}  
    \prod_{l=2}^{L} \left( \frac{\partial \bm{h}_{t}^{(l)}}{\partial \bm{h}_{t}^{(l-1)}} 
     + \frac{\partial \bm{h}_{t}^{(l)}}{\partial \bm{h}_{t-1}^{(l)}} 
    \right)
    \left( \frac{\partial \bm{h}_{t}^{(1)}}{\partial p_{t}} + \frac{\partial \bm{h}_{t}^{(1)}}{\partial \bm{h}_{t-1}^{(1)}} \right)  \label{proof1}
\end{align}
\vspace{-0.3cm}
\begin{align}
\begin{split}
    \frac{\partial D_{t}}{\partial \bm{W}_{\mathrm{p}}^{l}} = \frac{\partial D_{t}}{\partial \bm{h}_{t}^{(L)}} 
     \prod_{j=l+1}^{L} &\left( \frac{\partial \bm{h}_{t}^{(j)}}{\partial \bm{h}_{t}^{(j-1)}} 
     + \frac{\partial \bm{h}_{t}^{(j)}}{\partial \bm{h}_{t-1}^{(j)}} 
    \right)  \\
    * &\left( \frac{\partial \bm{h}_{t}^{(l)}}{\partial \bm{W}_{\mathrm{p}}^{(l)}} + \frac{\partial \bm{h}_{t}^{(l)}}{\partial \bm{h}_{t-1}^{(l)}} \right)  \label{proof2} 
\end{split}
\end{align}

When $l=1$, (\ref{proof1}) and (\ref{proof2}) have the same structure, and when $l>1$, they also have similar structure while (\ref{proof2}) has short derivative chain. The difference is that (\ref{proof1}) obtain the input data $p$, while (\ref{proof2}) get the neural network parameters $\bm{W}$. Then according to ~\cite{globalmini}, because the objective (\ref{obj}) is similar to the loss function defined in the training of the neural network, i.e., both are the distance to constant vectors expressed by $l2$ norm, we formulate the following dynamics to express predictions:
\begin{align}
    E_{t}(k)&=\gamma f(\theta(k),p_{t})\\
    % \bm{E_{\mathrm{bond}}}-\bm{E}(k+1)&=(\bm{I}-\eta\bm{G}(k))(\bm{E_{\mathrm{bond}}}-\bm{E}(k))  \label{dynamic}
    \frac{\partial \bm{E}(k)}{\partial k} &= \bm{G}(\overline{E}-\bm{E}(k))    \label{dynamic}
\end{align}
where $\gamma$ are parameters to transfer $D$ to $E$; $\theta$ is neural network parameters; $k$ is the index of gradient descent iteration; $\bm{G}$ is the Gram matrix, which is defined as follows:
\begin{align}
\begin{split}
    \bm{G}_{i,j}(k)&=\left \langle \frac{\partial E_{i}(k)}{\partial \bm{p}(k)} , \frac{\partial E_{j}(k)}{\partial \bm{p}(k)} \right \rangle \\
    % &=\sum_{l=1}^{L}\left \langle \frac{\partial E_{i}(k)}{\partial \bm{p}(k)} , \frac{\partial E_{j}(k)}{\partial \bm{p}(k)} \right \rangle
    &=\left \langle \frac{\partial E_{i}}{\partial \bm{D}} \frac{\partial \bm{D}}{\partial \bm{p}} , \frac{\partial E_{j}}{\partial \bm{D}} \frac{\partial \bm{D}}{\partial \bm{p}} \right \rangle
    + \left \langle \frac{\partial E_{i}}{\partial \bm{D}} \frac{\partial \bm{D}}{\partial \bm{p}} , \frac{\partial E_{j}}{\partial \bm{p}}  \right \rangle \\
    &+ \left \langle \frac{\partial E_{j}}{\partial \bm{D}} \frac{\partial \bm{D}}{\partial \bm{p}} , \frac{\partial E_{i}}{\partial \bm{p}}  \right \rangle
     + \left \langle \frac{\partial E_{i}}{\partial \bm{p}}  , \frac{\partial E_{j}}{\partial \bm{p}}  \right \rangle
\end{split}
\end{align}

The other part is the linear distance between $D$ and $D_{0}$, which also satisfies similar dynamics as shown in (\ref{dynamic}). 

According to~\cite{globalmini}, if $G(k)$ is strictly positive definite, then the loss $(\bm{E} - \overline{E})^T (\bm{E} -\overline{E})$ decreases at the $k^{\mathrm{th}}$ iteration according to the analysis of power method if the learning rate $\eta$ is properly chosen. Each element of $\bm{G}(k)$ is positively defined as it is formulated by the inner product, and the sum of the positively defined matrix is still positively defined. Thus, $\bm{G}(k)$ is positive definite, and based on the dynamics, the objective function will decrease as the iterations go on, showing that the gradient-based solution method can converge after finite iterations as long as the learning rate is sufficiently low.
%inner product~\cite{psd},
% as From the Appendix F in~\cite{globalmini}, we can see the matrix $G$ is positive definite as long as no two weighting vectors $\mathbf{W}$ are parallel, and the activation function is analytic and is not a polynomial function. In the neural network training process, almost all weighting parameters are different and almost impossible to have parallel vectors. Thus, the gradient based solution method can converge after finite iterations as long as the learning rate is sufficiently small


%     \frac{\partical D_{t}}{\partial \mathbf{W}_{\mathrm{p}}^{l}} &= \frac{\partial D_{t}}{\partial \mathbf{h}_{t}^{(L)}} 
%     * \prod_{j=l+1}^{L} \left( \frac{\partial \mathbf{h}_{t}^{(j)}}{\partial \mathbf{h}_{t}^{(j-1)}} 
%      + \frac{\partial \mathbf{h}_{t}^{(j)}}{\partial \mathbf{h}_{t-1}^{(j)}} 
%     \right)  \label{proof2}
%     *\left( \frac{\partial \mathbf{h}_{t}^{(l)}}{\partial \mathbf{W}_{\mathrm{p}}^{l}} + \frac{\partial \mathbf{h}_{t}^{(l)}}{\partial \mathbf{h}_{t-1}^{(l)}} \right)
% \end{align}


% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%





% you can choose not to have a title for an appendix
% if you want by leaving the argument blank


% use section* for acknowledgment

% \section*{acknowledgment}







\bibliographystyle{IEEEtran}
\bibliography{Ref}


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{% Figure removed}]{Michael Shell}
% or if you just want to reserve a space for a photo:

% \begin{IEEEbiography}{Michael Shell}
% Biography text here.
% \end{IEEEbiography}

% if you will not have a photo at all:
% \begin{IEEEbiographynophoto}{John Doe}
% Biography text here.
% \end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

% \begin{IEEEbiographynophoto}{Jane Doe}
% Biography text here.
% \end{IEEEbiographynophoto}



%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


