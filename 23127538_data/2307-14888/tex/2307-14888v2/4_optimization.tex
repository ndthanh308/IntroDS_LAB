\section{Optimisation of the $\Afb$ reconstruction at ILC}
\label{sec:optimization}
%2 pages. (3 as super max)
\subsection{Optimisation of the default flavour tagging of ILD: Adding hadron PID as input.} \label{PIDsection}

The flavour tagging is performed by the \texttt{LCFI+} package \cite{Suehara:2015ura}.
The vertex reconstruction method distinguishes between vertices and pseudo-vertices, which are \textit{single-track vertices} candidates to be merged in a fully reconstructed vertex in a second iteration of the algorithm. At the end of the process, if these pseudo-vertices are not merged in a full vertex, they are kept in the list of objects and treated as \textit{single-track vertices}.
%Promoting a track to a single-track pseudo-vertex is decided by the algorithm with statistical significance criteria based on impact parameters ($d_0,z_0$) and the vertex displacement values expected for \bquark and \cquark subproducts (as described in \cite{Suehara:2015ura}, page 6).
%Generally, the single-track vertex is meant to represent when \bjets containing only one reconstructed secondary vertex have a possible track that could be interpreted as the result of additional secondary decay. 

The total number of vertices and pseudo-vertices is always two or fewer. Four different categories are defined (A, B, C, D): A are jets without vertices and up to two pseudo-vertices, B are jets with one vertex and no pseudo-vertices, C are jets with one vertex, and one pseudo-vertex and D are jets with two vertices. The flavour content in each category is different as expected due to the different hadronisation products of heavy quarks: Above 95\% of light-quark jets are in category A, more than 90\% of \cquark jets are spread between categories A and B while more than 80\% of the \bquark jets are split between categories B, C and D.

To prepare weights for flavour tagging via \texttt{LCFI+}, two main algorithms have to be run: \textit{MakeNTuple} and \textit{TrainMVA}. MakeNTuple prepares the \texttt{ROOT} files with NTuples with all the different variables that could be used for the flavour tagging. TrainMVA uses 3 NTuples as input (one for \bjets, one for \cjets and one for \udsjets) and then runs a classificator based on Boosted Decision Trees (BDT implemented in \texttt{ROOT}'s TMVA). The input is the signal data separated into the different categories described above. A \texttt{Marlin} processor\footnote{Link: \url{https://github.com/marherje/LCIO_Extraction.git}} was designed \textit{ad hoc} to do this selection. 

New variables were built using the TPC's PID capabilities via \dEdx to improve the flavour tagging. The new variables were a count of kaons, protons and pion candidates. The charged kaon, proton and pion IDs are defined by constructing \textit{likenesses} variables using a statistical distance measurement, comparing theoretical and experimental values. for instance, the definition of \textit{kaonness}, \kaonness, is defined as:
\begin{equation}
\Delta_{\dEdx-K}=\left(\frac{dE/dx_{exp}-dE/dx_{K,BB}}{\Delta dE/dx_{exp}}\right),
\label{formula:kaonness}
\end{equation}
where $dE/dx_{K,BB}$ is the theoretical value given by the Bethe-Bloch formula, $dE/dx_{exp}$ is the experimental value from the TPC's measurements and $\Delta dE/dx_{K,exp}$ is the error associated to that measurement as implemented in the official ILD reconstruction software. This definition is extended to other hadron types (\textit{pionness}, \textit{protonness}). This distance can be modelled as normally distributed. It can be constructed concerning each particle's theoretical values, hence having the Gaussian centred in 0 for each case (\textit{kaonness}, \textit{pionness}, \textit{protonness}). To have a proper distribution, all tracks with momenta below 3 GeV and $\|\cos\theta\| > 0.95$ were discarded before selecting particle candidates. Low-momenta tracks are removed because the Bethe-Bloch curves at low energies for pions and kaons overlap. Removal of very forward/backward tracks is for a loss of geometrical acceptance of the TPC. We count as candidate particles of each type those whose absolute \textit{likeness} value is below 1.5, which minimises overlapping with other particles. All these new variables and selections were implemented in a beta version of \texttt{LCFI+} that is already available and waiting for an official \textit{pull} to the main \texttt{GitHub} repository of \texttt{LCFI+}. This process counts only tracks associated with a secondary vertex (or pseudo-vertex).%, counting tracks in the primary vertex was also explored, but it is not useful. 
The final three new variables added to \textit{MakeNTuple} are named: dEdxNKaonSec, dEdxNProtonSec and dEdxNPionSec, as they represent the number of each particle in secondary vertices.

%Both the \bquark and \cquark hadronisation products can decay into charged kaons. 
There is a direct correlation between quark flavour and kaon production via B-mesons (\bquark) and D-mesons (\bquark and \cquark) decays which motivate using kaon PID in flavour tagging. Identification of kaons is also useful for the charge reconstruction as stated in Sec. \ref{sec:recosel}, which is especially important in the case of \cquark. Using \dEdx is strongly motivated given the expected separation power of high momenta tracks (above 3 GeV)(see \cite{ILD:2020qve}, Figure 8.6). 

The standard training process runs once through the four vertexing categories using the same configuration of the BDTs. Still, in the case of this optimisation, independent training has been performed for each category. To ensure that the BDT configuration is optimal for each different scenario (energy, category and variable selections), a Particle Swarm Optimisation (PSO) was run. 
The PSO\cite{488968} is a parameter-free, stochastic, bio-inspired algorithm that searches for the optimal configuration of a problem by doing an iterative scanning of configurations for the problem.
The \textit{particles} are positions in the space of configurations for the given problem, which move to a new position after each iteration.
It requires the definition of a Function Of Merit (FOM) as scoring to determine the movement of the \textit{particles} after each iteration. 
In this case, a PSO software\cite{CMS:2018hnq} has been adapted and extended to a 3-class classifier with filters suitable to work with \texttt{LCFI+}\footnote{Link: \url{https://github.com/marherje/PSOforLCFIPlus.git}}. The space of configurations for flavour tagging are the hyper-parameters of the BDTs, and the \textit{particles} of the PSO are different selections of such hyper-parameters. The different hyper-parameters for the BDTs are the number of trees, the maximum number of leaves for each tree, the shrinkage, the bagging fraction and the number of bins (for the physical input variables' histograms). The function of merit of choice for this study was the average value of the integral of the Receiving Operating Characteristic (ROC) curve for the three different flavour categories ($b$, $c$, $uds$) from the test sample. To avoid overfitting to the test sample, two different statistical tests (Kolmogorov-Smirnov\cite{kolmogorov1933sulla,smirnov1948table,hodges1958significance} and Anderson-Darling\cite{cf37c5fc-d933-3771-9586-9d6b4b285d8b,doi:10.1080/01621459.1954.10501232,engmann2011comparing}) were run each time a particle finished its training, comparing the BDTs output between the test and training samples. In both statistical tests, a threshold value was set upon observation, always keeping the p-value over the standard $p>0.05$ criteria but also checking that the fluctuations in the FOM values were below 1.5 \%. The complete list of variables used in each category is in Table \ref{tab:bdtvariables} of the Appendix \ref{sec:annex}, where the bold text are the new variables and the rest are original \textit{LCFI+} variables as introduced in \cite{Suehara:2015ura}.

\subsection{Prospects of using a pixel TPC device: From \dEdx to \dNdx } \label{dNdxsection}
A better PID resolution is expected when using \dNdx instead of \dEdx. This will be possible with a pixel-based TPC. 
According to \cite{LCTPC:2022pvp}, an improvement of $\sim 30-40\%$ in the kaon/pion separation power is achievable for tracks with momentum between 3-50 GeV, with the separation power as defined in  \cite{ILD:2020qve} and in the following equation: 
\begin{equation}
    \eta_{A,B}(p)=\frac{\lvert\mu_A(p)-\mu_B(p)\rvert}{\sqrt{\frac{1}{2}(\sigma_A^2(p)+\sigma_B^2(p)}},
    \label{eq:separationpower}
\end{equation}
where $\mu_(p)$ and $\sigma$ are the mean and standard deviations of the gaussian fits to the experimental value of \dEdx, defined as a function of the momenta $p$ of each bin. 
However, the \dNdx reconstruction is not yet implemented in the ILD software, so it is not possible to introduce a \dNdx PID variable for the flavour tagging and charge measurement directly, as for \dEdx. 
Instead, we apply a correction to the \textit{likenesses} distributions by the expected value.
This is done by a dedicated Marlin processor that emulates a $25\%$ reduction in standard deviation in the 
\textit{likenesses} distributions.
This $25\%$ reduction in the  standard deviation in the 
\textit{likenesses} distributions is equivalent to a to a $\sim33\%$ improvement in the separation power,
In addition, in the flavour tagging case, an Ideal PID resolution has been considered by reducing the standard deviation of the simulated \textit{likeness} distributions by a $99\%$, compared with the full simulation.

% Figure environment removed

Once the expected improvement in resolution for the \dNdx case is accounted for, the full analysis is repeated. Given that now the \textit{likeness} distributions offer a better separation between types of hadrons (see Fig.\ref{fig:dEdxdist_cquark}), the criteria to accept a track as kaon candidate requires an absolute value of the \textit{kaonness} smaller than 1.0 instead of 1.5. Besides the separation criteria, the optimisation process is the same, including the PSO for each possible scenario. In Fig.\ref{fig:flavourtagging}, the effects on flavour tagging when adding the three new variables from kaon, protons and pions are shown for the case of \dEdx,\dNdx and ideal PID with 100\% efficiency for both 250 and 500 GeV. In Fig.\ref{fig:kaonID}, the impact of moving from \dEdx to \dNdx, envisioning a pixel PID, is shown for 250 and 500 GeV.


% Figure environment removed

% Figure environment removed

%This has to be 1 page only too. Maybe 1.5
%\begin{itemize}
%    \item The pixel TPC should have been described before.
%    \item Explain how we estimate the better dEdx resolution.
%    \item Plot of the efficiency vs purity (b/c and 250GeV and 500GeV --> Adrian)
%\end{itemize}



