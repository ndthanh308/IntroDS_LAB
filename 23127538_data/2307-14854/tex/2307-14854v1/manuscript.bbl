% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{zhang2021multi}
K.~Zhang, Z.~Yang, and T.~Ba{\c{s}}ar, ``Multi-agent reinforcement learning: A
  selective overview of theories and algorithms,'' \emph{Handbook of
  reinforcement learning and control}, pp. 321--384, 2021.

\bibitem{oroojlooy2022review}
A.~Oroojlooy and D.~Hajinezhad, ``A review of cooperative multi-agent deep
  reinforcement learning,'' \emph{Applied Intelligence}, pp. 1--46, 2022.

\bibitem{wu2021flow}
C.~Wu, A.~R. Kreidieh, K.~Parvate, E.~Vinitsky, and A.~M. Bayen, ``Flow: A
  modular learning framework for mixed autonomy traffic,'' \emph{IEEE
  Transactions on Robotics}, vol.~38, no.~2, pp. 1270--1286, 2021.

\bibitem{boutilier1996planning}
C.~Boutilier, ``Planning, learning and coordination in multiagent decision
  processes,'' in \emph{TARK}, vol.~96.\hskip 1em plus 0.5em minus 0.4em\relax
  Citeseer, 1996, pp. 195--210.

\bibitem{boutilier1999sequential}
------, ``Sequential optimality and coordination in multiagent systems,'' in
  \emph{IJCAI}, vol.~99, 1999, pp. 478--485.

\bibitem{terry2021pettingzoo}
J.~Terry, B.~Black, N.~Grammel, M.~Jayakumar, A.~Hari, R.~Sullivan, L.~S.
  Santos, C.~Dieffendahl, C.~Horsch, R.~Perez-Vicente \emph{et~al.},
  ``Pettingzoo: Gym for multi-agent reinforcement learning,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~34, pp. 15\,032--15\,043, 2021.

\bibitem{Zheng2018MAgent}
L.~Zheng, J.~Yang, H.~Cai, M.~Zhou, W.~Zhang, J.~Wang, and Y.~Yu, ``Magent: A
  many-agent reinforcement learning platform for artificial collective
  intelligence,'' \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, vol.~32, no.~1, Apr. 2018.

\bibitem{lowe2017multi}
R.~Lowe, Y.~Wu, A.~Tamar, J.~Harb, P.~Abbeel, and I.~Mordatch, ``Multi-agent
  actor-critic for mixed cooperative-competitive environments,'' \emph{Neural
  Information Processing Systems (NIPS)}, 2017.

\bibitem{leibo2019autocurricula}
J.~Z. Leibo, E.~Hughes, M.~Lanctot, and T.~Graepel, ``Autocurricula and the
  emergence of innovation from social interaction: A manifesto for multi-agent
  intelligence research,'' \emph{arXiv preprint arXiv:1903.00742}, 2019.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio, ``Generative adversarial nets,'' in
  \emph{Advances in Neural Information Processing Systems}, Z.~Ghahramani,
  M.~Welling, C.~Cortes, N.~Lawrence, and K.~Weinberger, Eds., vol.~27.\hskip
  1em plus 0.5em minus 0.4em\relax Curran Associates, Inc., 2014.

\bibitem{vinyals2019grandmaster}
O.~Vinyals, I.~Babuschkin, W.~M. Czarnecki, M.~Mathieu, A.~Dudzik, J.~Chung,
  D.~H. Choi, R.~Powell, T.~Ewalds, P.~Georgiev \emph{et~al.}, ``Grandmaster
  level in starcraft ii using multi-agent reinforcement learning,''
  \emph{Nature}, vol. 575, no. 7782, pp. 350--354, 2019.

\bibitem{jaderberg2019human}
M.~Jaderberg, W.~M. Czarnecki, I.~Dunning, L.~Marris, G.~Lever, A.~G.
  Castaneda, C.~Beattie, N.~C. Rabinowitz, A.~S. Morcos, A.~Ruderman
  \emph{et~al.}, ``Human-level performance in 3d multiplayer games with
  population-based reinforcement learning,'' \emph{Science}, vol. 364, no.
  6443, pp. 859--865, 2019.

\bibitem{baker2019emergent}
B.~Baker, I.~Kanitscheider, T.~Markov, Y.~Wu, G.~Powell, B.~McGrew, and
  I.~Mordatch, ``Emergent tool use from multi-agent autocurricula,'' in
  \emph{International Conference on Learning Representations}, 2019.

\bibitem{sukhbaatar2017intrinsic}
S.~Sukhbaatar, Z.~Lin, I.~Kostrikov, G.~Synnaeve, A.~Szlam, and R.~Fergus,
  ``Intrinsic motivation and automatic curricula via asymmetric self-play,''
  \emph{arXiv preprint arXiv:1703.05407}, 2017.

\bibitem{dawkins1979arms}
R.~Dawkins and J.~R. Krebs, ``Arms races between and within species,''
  \emph{Proceedings of the Royal Society of London. Series B. Biological
  Sciences}, vol. 205, no. 1161, pp. 489--511, 1979.

\bibitem{bengio2009curriculum}
Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston, ``Curriculum learning,''
  in \emph{Proceedings of the 26th annual international conference on machine
  learning}, 2009, pp. 41--48.

\bibitem{wang2021survey}
X.~Wang, Y.~Chen, and W.~Zhu, ``A survey on curriculum learning,'' \emph{IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, vol.~44, no.~9,
  pp. 4555--4576, 2021.

\bibitem{nolfi1998co}
S.~Nolfi and D.~Floreano, ``How co-evolution can enhance the adaptive power of
  artificial evolution: Implications for evolutionary robotics,'' in
  \emph{Evolutionary Robotics: First European Workshop, EvoRobot98 Paris,
  France, April 16--17, 1998 Proceedings 1}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 1998, pp. 22--38.

\bibitem{Russell2021Artificial}
S.~Russell and P.~Norvig, \emph{Artificial Intelligence: A Modern Approach, 4th
  Edition}.\hskip 1em plus 0.5em minus 0.4em\relax Pearson Education, 2021.

\bibitem{pinto2017robust}
L.~Pinto, J.~Davidson, R.~Sukthankar, and A.~Gupta, ``Robust adversarial
  reinforcement learning,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 2817--2826.

\bibitem{ma2018improved}
X.~Ma, K.~Driggs-Campbell, and M.~J. Kochenderfer, ``Improved robustness and
  safety for autonomous vehicle control with adversarial reinforcement
  learning,'' in \emph{2018 IEEE Intelligent Vehicles Symposium (IV)}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1665--1671.

\bibitem{pan2019risk}
X.~Pan, D.~Seita, Y.~Gao, and J.~Canny, ``Risk averse robust adversarial
  reinforcement learning,'' in \emph{2019 International Conference on Robotics
  and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019,
  pp. 8522--8528.

\bibitem{gleave2019adversarial}
A.~Gleave, M.~Dennis, C.~Wild, N.~Kant, S.~Levine, and S.~Russell,
  ``Adversarial policies: Attacking deep reinforcement learning,'' \emph{arXiv
  preprint arXiv:1905.10615}, 2019.

\bibitem{reynolds1994competition}
C.~W. Reynolds, ``Competition, coevolution and the game of tag,'' in
  \emph{Proceedings of the Fourth International Workshop on the Synthesis and
  Simulation of Living Systems}, 1994, pp. 59--69.

\bibitem{miller1994protean}
G.~F. Miller and D.~Cliff, ``Protean behavior in dynamic games: Arguments for
  the co-evolution of pursuit-evasion tactics,'' \emph{From animals to
  animats}, vol.~3, pp. 411--420, 1994.

\bibitem{miller1994co}
------, \emph{Co-evolution of pursuit and evasion I: Biological and
  game-theoretic foundations}.\hskip 1em plus 0.5em minus 0.4em\relax School of
  Cognitive and Computing Sciences, University of Sussex Brighton, 1994.

\bibitem{maes1996co}
P.~Maes, M.~J. Mataric, J.-A. Meyer, J.~Pollack, and S.~W. Wilson,
  ``Co-evolution of pursuit and evasion ii: Simulation methods and results,''
  1996.

\bibitem{littlewood1953mathematician}
J.~E. Littlewood, \emph{A mathematician's miscellany}.\hskip 1em plus 0.5em
  minus 0.4em\relax Methuen \& Co. Ltd., London, 1953.

\bibitem{samvelyan2019starcraft}
M.~Samvelyan, T.~Rashid, C.~Schroeder~de Witt, G.~Farquhar, N.~Nardelli, T.~G.
  Rudner, C.-M. Hung, P.~H. Torr, J.~Foerster, and S.~Whiteson, ``The starcraft
  multi-agent challenge,'' in \emph{Proceedings of the 18th International
  Conference on Autonomous Agents and MultiAgent Systems}, 2019, pp.
  2186--2188.

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto, \emph{Reinforcement learning: An
  introduction}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 2018.

\bibitem{bonato2011game}
A.~Bonato, \emph{The game of cops and robbers on graphs}.\hskip 1em plus 0.5em
  minus 0.4em\relax American Mathematical Soc., 2011.

\bibitem{benda1986optimal}
M.~Benda, V.~Jagannathan, and R.~Dodhiawala, ``On optimal cooperation of
  knowledge sources-an empirical investigation,'' BCS-G2010-28, Boeing Advanced
  Technology Center, Boeing Computing Services, Seattle, Washington, Tech.
  Rep., 1986.

\bibitem{sun2022toward}
L.~Sun, Y.-C. Chang, C.~Lyu, Y.~Shi, Y.~Shi, and C.-T. Lin, ``Toward
  multi-target self-organizing pursuit in a partially observable markov game,''
  \emph{arXiv preprint arXiv:2206.12330}, 2022.

\bibitem{quilliot1978jeux}
A.~Quilliot, ``Jeux et pointes fixes sur les graphes,'' Ph.D. dissertation,
  Universit{\'e} de Paris VI, 1978.

\bibitem{NOWAKOWSKI1983235}
R.~Nowakowski and P.~Winkler, ``Vertex-to-vertex pursuit in a graph,''
  \emph{Discrete Mathematics}, vol.~43, no.~2, pp. 235 -- 239, 1983.

\end{thebibliography}
