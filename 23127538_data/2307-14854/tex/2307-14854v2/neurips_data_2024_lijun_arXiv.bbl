\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baker et~al.(2019)Baker, Kanitscheider, Markov, Wu, Powell, McGrew,
  and Mordatch]{baker2019emergent}
Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi~Wu, Glenn Powell, Bob
  McGrew, and Igor Mordatch.
\newblock Emergent tool use from multi-agent autocurricula.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Benda et~al.(1986)Benda, Jagannathan, and
  Dodhiawala]{benda1986optimal}
M~Benda, V~Jagannathan, and R~Dodhiawala.
\newblock On optimal cooperation of knowledge sources-an empirical
  investigation.
\newblock Technical report, BCS-G2010-28, Boeing Advanced Technology Center,
  Boeing Computing Services, Seattle, Washington, 1986.

\bibitem[Bengio et~al.(2009)Bengio, Louradour, Collobert, and
  Weston]{bengio2009curriculum}
Yoshua Bengio, J{\'e}r{\^o}me Louradour, Ronan Collobert, and Jason Weston.
\newblock Curriculum learning.
\newblock In \emph{Proceedings of the 26th annual international conference on
  machine learning}, pages 41--48, 2009.

\bibitem[Bonato(2011)]{bonato2011game}
Anthony Bonato.
\newblock \emph{The game of cops and robbers on graphs}.
\newblock American Mathematical Soc., 2011.

\bibitem[Boutilier(1996)]{boutilier1996planning}
Craig Boutilier.
\newblock Planning, learning and coordination in multiagent decision processes.
\newblock In \emph{TARK}, volume~96, pages 195--210. Citeseer, 1996.

\bibitem[Boutilier(1999)]{boutilier1999sequential}
Craig Boutilier.
\newblock Sequential optimality and coordination in multiagent systems.
\newblock In \emph{IJCAI}, volume~99, pages 478--485, 1999.

\bibitem[Dawkins and Krebs(1979)]{dawkins1979arms}
Richard Dawkins and John~Richard Krebs.
\newblock Arms races between and within species.
\newblock \emph{Proceedings of the Royal Society of London. Series B.
  Biological Sciences}, 205\penalty0 (1161):\penalty0 489--511, 1979.

\bibitem[Gao et~al.(2023)Gao, Li, Li, Yan, Lin, and Wu]{gao2023review}
Jianqi Gao, Yanjie Li, Xinyi Li, Kejian Yan, Ke~Lin, and Xinyu Wu.
\newblock A review of graph-based multi-agent pathfinding solvers: From
  classical to beyond classical.
\newblock \emph{Knowledge-Based Systems}, page 111121, 2023.

\bibitem[Gleave et~al.(2019)Gleave, Dennis, Wild, Kant, Levine, and
  Russell]{gleave2019adversarial}
Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine, and Stuart
  Russell.
\newblock Adversarial policies: Attacking deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1905.10615}, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and K.Q.
  Weinberger, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~27. Curran Associates, Inc., 2014.

\bibitem[Jaderberg et~al.(2019)Jaderberg, Czarnecki, Dunning, Marris, Lever,
  Castaneda, Beattie, Rabinowitz, Morcos, Ruderman, et~al.]{jaderberg2019human}
Max Jaderberg, Wojciech~M Czarnecki, Iain Dunning, Luke Marris, Guy Lever,
  Antonio~Garcia Castaneda, Charles Beattie, Neil~C Rabinowitz, Ari~S Morcos,
  Avraham Ruderman, et~al.
\newblock Human-level performance in 3d multiplayer games with population-based
  reinforcement learning.
\newblock \emph{Science}, 364\penalty0 (6443):\penalty0 859--865, 2019.
\newblock \doi{10.1126/science.aau6249}.

\bibitem[Leibo et~al.(2019)Leibo, Hughes, Lanctot, and
  Graepel]{leibo2019autocurricula}
Joel~Z Leibo, Edward Hughes, Marc Lanctot, and Thore Graepel.
\newblock Autocurricula and the emergence of innovation from social
  interaction: A manifesto for multi-agent intelligence research.
\newblock \emph{arXiv preprint arXiv:1903.00742}, 2019.

\bibitem[Littlewood(1953)]{littlewood1953mathematician}
John~Edensor Littlewood.
\newblock \emph{A mathematician's miscellany}.
\newblock Methuen \& Co. Ltd., London, 1953.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock \emph{Neural Information Processing Systems (NIPS)}, 2017.

\bibitem[Ma et~al.(2018)Ma, Driggs-Campbell, and Kochenderfer]{ma2018improved}
Xiaobai Ma, Katherine Driggs-Campbell, and Mykel~J Kochenderfer.
\newblock Improved robustness and safety for autonomous vehicle control with
  adversarial reinforcement learning.
\newblock In \emph{2018 IEEE Intelligent Vehicles Symposium (IV)}, pages
  1665--1671. IEEE, 2018.

\bibitem[Maes et~al.(1996)Maes, Mataric, Meyer, Pollack, and
  Wilson]{maes1996co}
Pattie Maes, Maja~J Mataric, Jean-Arcady Meyer, Jordan Pollack, and Stewart~W
  Wilson.
\newblock Co-evolution of pursuit and evasion ii: Simulation methods and
  results.
\newblock 1996.

\bibitem[Miller and Cliff(1994{\natexlab{a}})]{miller1994co}
Geoffrey~F Miller and Dave Cliff.
\newblock \emph{Co-evolution of pursuit and evasion I: Biological and
  game-theoretic foundations}.
\newblock School of Cognitive and Computing Sciences, University of Sussex
  Brighton, 1994{\natexlab{a}}.

\bibitem[Miller and Cliff(1994{\natexlab{b}})]{miller1994protean}
Geoffrey~F Miller and Dave Cliff.
\newblock Protean behavior in dynamic games: Arguments for the co-evolution of
  pursuit-evasion tactics.
\newblock \emph{From animals to animats}, 3:\penalty0 411--420,
  1994{\natexlab{b}}.

\bibitem[Nolfi and Floreano(1998)]{nolfi1998co}
Stefano Nolfi and Dario Floreano.
\newblock How co-evolution can enhance the adaptive power of artificial
  evolution: Implications for evolutionary robotics.
\newblock In \emph{Evolutionary Robotics: First European Workshop, EvoRobot98
  Paris, France, April 16--17, 1998 Proceedings 1}, pages 22--38. Springer,
  1998.

\bibitem[Nowakowski and Winkler(1983)]{NOWAKOWSKI1983235}
Richard Nowakowski and Peter Winkler.
\newblock Vertex-to-vertex pursuit in a graph.
\newblock \emph{Discrete Mathematics}, 43\penalty0 (2):\penalty0 235 -- 239,
  1983.
\newblock ISSN 0012-365X.
\newblock \doi{https://doi.org/10.1016/0012-365X(83)90160-7}.

\bibitem[Oroojlooy and Hajinezhad(2022)]{oroojlooy2022review}
Afshin Oroojlooy and Davood Hajinezhad.
\newblock A review of cooperative multi-agent deep reinforcement learning.
\newblock \emph{Applied Intelligence}, pages 1--46, 2022.

\bibitem[Pan et~al.(2019)Pan, Seita, Gao, and Canny]{pan2019risk}
Xinlei Pan, Daniel Seita, Yang Gao, and John Canny.
\newblock Risk averse robust adversarial reinforcement learning.
\newblock In \emph{2019 International Conference on Robotics and Automation
  (ICRA)}, pages 8522--8528. IEEE, 2019.

\bibitem[Pinto et~al.(2017)Pinto, Davidson, Sukthankar, and
  Gupta]{pinto2017robust}
Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta.
\newblock Robust adversarial reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2817--2826. PMLR, 2017.

\bibitem[Quilliot(1978)]{quilliot1978jeux}
Alain Quilliot.
\newblock \emph{Jeux et pointes fixes sur les graphes}.
\newblock PhD thesis, Universit{\'e} de Paris VI, 1978.

\bibitem[Reynolds(1994)]{reynolds1994competition}
Craig~W Reynolds.
\newblock Competition, coevolution and the game of tag.
\newblock In \emph{Proceedings of the Fourth International Workshop on the
  Synthesis and Simulation of Living Systems}, pages 59--69, 1994.

\bibitem[Russell and Norvig(2021)]{Russell2021Artificial}
Stuart Russell and Peter Norvig.
\newblock \emph{Artificial Intelligence: A Modern Approach, 4th Edition}.
\newblock Pearson Education, 2021.

\bibitem[Samvelyan et~al.(2019)Samvelyan, Rashid, Schroeder~de Witt, Farquhar,
  Nardelli, Rudner, Hung, Torr, Foerster, and Whiteson]{samvelyan2019starcraft}
Mikayel Samvelyan, Tabish Rashid, Christian Schroeder~de Witt, Gregory
  Farquhar, Nantas Nardelli, Tim~GJ Rudner, Chia-Man Hung, Philip~HS Torr,
  Jakob Foerster, and Shimon Whiteson.
\newblock The starcraft multi-agent challenge.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 2186--2188, 2019.

\bibitem[Stern et~al.(2019)Stern, Sturtevant, Felner, Koenig, Ma, Walker, Li,
  Atzmon, Cohen, Kumar, et~al.]{stern2019multi}
Roni Stern, Nathan Sturtevant, Ariel Felner, Sven Koenig, Hang Ma, Thayne
  Walker, Jiaoyang Li, Dor Atzmon, Liron Cohen, TK~Kumar, et~al.
\newblock Multi-agent pathfinding: Definitions, variants, and benchmarks.
\newblock In \emph{Proceedings of the International Symposium on Combinatorial
  Search}, volume~10, pages 151--158, 2019.

\bibitem[Sukhbaatar et~al.(2017)Sukhbaatar, Lin, Kostrikov, Synnaeve, Szlam,
  and Fergus]{sukhbaatar2017intrinsic}
Sainbayar Sukhbaatar, Zeming Lin, Ilya Kostrikov, Gabriel Synnaeve, Arthur
  Szlam, and Rob Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock \emph{arXiv preprint arXiv:1703.05407}, 2017.

\bibitem[Sun et~al.(2023)Sun, Chang, Lyu, Shi, Shi, and Lin]{sun2023toward}
Lijun Sun, Yu-Cheng Chang, Chao Lyu, Ye~Shi, Yuhui Shi, and Chin-Teng Lin.
\newblock Toward multi-target self-organizing pursuit in a partially observable
  markov game.
\newblock \emph{Information Sciences}, 648:\penalty0 119475, 2023.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Terry et~al.(2021)Terry, Black, Grammel, Jayakumar, Hari, Sullivan,
  Santos, Dieffendahl, Horsch, Perez-Vicente, et~al.]{terry2021pettingzoo}
J~Terry, Benjamin Black, Nathaniel Grammel, Mario Jayakumar, Ananth Hari, Ryan
  Sullivan, Luis~S Santos, Clemens Dieffendahl, Caroline Horsch, Rodrigo
  Perez-Vicente, et~al.
\newblock Pettingzoo: Gym for multi-agent reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 15032--15043, 2021.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{vinyals2019grandmaster}
Oriol Vinyals, Igor Babuschkin, Wojciech~M Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, et~al.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Wang et~al.(2021)Wang, Chen, and Zhu]{wang2021survey}
Xin Wang, Yudong Chen, and Wenwu Zhu.
\newblock A survey on curriculum learning.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 44\penalty0 (9):\penalty0 4555--4576, 2021.

\bibitem[Wu et~al.(2021)Wu, Kreidieh, Parvate, Vinitsky, and Bayen]{wu2021flow}
Cathy Wu, Abdul~Rahman Kreidieh, Kanaad Parvate, Eugene Vinitsky, and
  Alexandre~M Bayen.
\newblock Flow: A modular learning framework for mixed autonomy traffic.
\newblock \emph{IEEE Transactions on Robotics}, 38\penalty0 (2):\penalty0
  1270--1286, 2021.

\bibitem[Zhang et~al.(2021)Zhang, Yang, and Ba{\c{s}}ar]{zhang2021multi}
Kaiqing Zhang, Zhuoran Yang, and Tamer Ba{\c{s}}ar.
\newblock Multi-agent reinforcement learning: A selective overview of theories
  and algorithms.
\newblock \emph{Handbook of reinforcement learning and control}, pages
  321--384, 2021.

\bibitem[Zheng et~al.(2018)Zheng, Yang, Cai, Zhou, Zhang, Wang, and
  Yu]{Zheng2018MAgent}
Lianmin Zheng, Jiacheng Yang, Han Cai, Ming Zhou, Weinan Zhang, Jun Wang, and
  Yong Yu.
\newblock Magent: A many-agent reinforcement learning platform for artificial
  collective intelligence.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  32\penalty0 (1), Apr. 2018.

\end{thebibliography}
