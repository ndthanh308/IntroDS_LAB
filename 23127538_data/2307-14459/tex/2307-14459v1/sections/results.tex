% Figure environment removed

We ran initial numerical experiments comparing uniform coresets, inception distance minimax coresets, and no coresets for a QBM with 36 visible units and 8 hidden units learning the BXS data set. The coresets were of size $m = 128$ and the full data set is of size $n=4096$. We designed our experiments with the idea that the user has some budget number of times to perform Gibbs state sampling, and so we run all experiments for 40 gradient-based updates, equalling 40 Gibbs state samplings. We use mini-batches of size $k = 32$, meaning with 40 iterations we go through 10 epochs with coresets and less than half an epoch with the full data set. Training was scored at each update step by averaging the BXS classification score for each of the 128 samples obtained from Gibbs state sampling. Figure~\ref{fig:results} shows the results of the experiments averaged over 10 runs for each approach. In the plots we can see that all three approaches are able to learn the data set successfully, validating our training methodology. However, using coresets did not improve the training time. We discuss hypotheses for why this occurs and resulting ideas for future work in Section~\ref{discussion}.





