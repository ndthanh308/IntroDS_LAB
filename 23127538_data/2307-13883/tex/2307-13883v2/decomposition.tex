\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}
\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{physics}
\usepackage{arydshln}
\usepackage{textcomp}
\usepackage{url}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{appendix}
\usepackage{enumitem}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{subcaption}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
\usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}
\setlength{\marginparwidth}{3.3cm}
\newcommand{\kensen}[1]{\todo[color=green!40]{kensen: #1}}
\newcommand{\kensenInline}[1]{\todo[inline,color=green!40,caption={}]{kensen: #1}}
\newcommand{\charles}[1]{\todo[color=purple!30]{from charles: #1}}
\newcommand{\joey}[1]{\todo[color=red!30]{joey: #1}}
\newcommand{\pengcheng}[1]{\todo[color=blue!30]{PY: #1}}

% Listings
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    upquote=true,  % Straight quotes
    backgroundcolor=\color{gray!7},
    frame=leftline,
    framerule=2pt,
    rulecolor=\color{gray!25},
    xleftmargin=7pt,
    framesep=5pt,
    framextopmargin=20pt,
    breaklines=true,
    breakatwhitespace=true,
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}

% Autoref tweaks
\renewcommand{\sectionautorefname}{Section}
\let\subsectionautorefname\sectionautorefname
\let\subsubsectionautorefname\sectionautorefname
\newcommand{\algorithmautorefname}{Algorithm}

% Paper-specific custom things
\newcommand\std[1]{\ensuremath{\color{gray} \scriptstyle \pm #1}}
\renewcommand{\tt}[1]{\fontfamily{cmtt}\selectfont #1}
\def\programs{{\mathcal{P}}}
\def\specs{{\mathcal{X}}}
\newcommand{\logicalOR}{\; | \;}
\newcommand{\T}[1]{\texttt{#1}}
\newcommand{\exedec}{ExeDec}

% Colored text
\usepackage{xcolor}
\colorlet{codecolor}{blue!60!black}
\colorlet{speccolor}{green!40!black}
\colorlet{taskcolor}{red!40!black}
\newcommand{\code}[1]{\texttt{\small \color{codecolor} #1}}
\newcommand{\str}[1]{{\color{speccolor}``#1"}}
\newcommand{\spec}[1]{{\color{speccolor}#1}}
\newcommand{\LengthGen}{{\color{taskcolor}\emph{Length-Generalization}}}
\newcommand{\ComposeDiffConcepts}{{\color{taskcolor}\emph{Compose-Different-Concepts}}}
\newcommand{\SwitchConceptOrder}{{\color{taskcolor}\emph{Switch-Concept-Order}}}
\newcommand{\ComposeNewOp}{{\color{taskcolor}\emph{Compose-New-Operation}}}
\newcommand{\AddOpFunctionality}{{\color{taskcolor}\emph{Add-Operation-Functionality}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Begin Algorithm stuff (mostly copied from old papers)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx}
\usepackage{float}
\newfloat{algorithm}{t}{}

\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\Input{\item[\algorithmicinput]}
\algnewcommand\algorithmicoutput{\textbf{Output:}}
\algnewcommand\Output{\item[\algorithmicoutput]}
\algnewcommand\algorithmicdata{\textbf{Auxiliary Data:}}
\algnewcommand\Data{\item[\algorithmicdata]}
\algblockdefx{RepeatUntilTimeout}{EndRepeat}{\textbf{repeat until timeout}}{}
\algblockdefx{RepeatUntil}{EndRepeat}{\textbf{repeat until }}{}
\algtext*{EndRepeat}
\makeatletter
\algnewcommand{\LineComment}[1]{\Statex \hskip\ALG@thistlm \(\triangleright\) #1}
\makeatother

\usepackage{etoolbox}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{tikz}
\usetikzlibrary{tikzmark}
\usetikzlibrary{calc}

% begin vertical rule patch for algorithmicx (http://tex.stackexchange.com/questions/144840)
% note that some of the packages above are also needed
\newcommand{\ALGtikzmarkcolor}{lightgray}% customise this, if you want
\newcommand{\ALGtikzmarkextraindent}{4pt}% customise this, if you want
\newcommand{\ALGtikzmarkverticaloffsetstart}{-.7ex}% customise this, if you want
\newcommand{\ALGtikzmarkverticaloffsetend}{-.5ex}% customise this, if you want
\makeatletter
\newcounter{ALG@tikzmark@tempcnta}

\newcommand\ALG@tikzmark@start{%
    \global\let\ALG@tikzmark@last\ALG@tikzmark@starttext%
    \expandafter\edef\csname ALG@tikzmark@\theALG@nested\endcsname{\theALG@tikzmark@tempcnta}%
    \tikzmark{ALG@tikzmark@start@\csname ALG@tikzmark@\theALG@nested\endcsname}%
    \addtocounter{ALG@tikzmark@tempcnta}{1}%
}

\def\ALG@tikzmark@starttext{start}
\newcommand\ALG@tikzmark@end{%
    \ifx\ALG@tikzmark@last\ALG@tikzmark@starttext
        % ignore this, the block was opened then closed directly without any other blocks in between (so just a \State basically)
        % don't draw a vertical line here
    \else
        \tikzmark{ALG@tikzmark@end@\csname ALG@tikzmark@\theALG@nested\endcsname}%
        \tikz[overlay,remember picture] \draw[\ALGtikzmarkcolor] let \p{S}=($(pic cs:ALG@tikzmark@start@\csname ALG@tikzmark@\theALG@nested\endcsname)+(\ALGtikzmarkextraindent,\ALGtikzmarkverticaloffsetstart)$), \p{E}=($(pic cs:ALG@tikzmark@end@\csname ALG@tikzmark@\theALG@nested\endcsname)+(\ALGtikzmarkextraindent,\ALGtikzmarkverticaloffsetend)$) in (\x{S},\y{S})--(\x{S},\y{E});%
    \fi
    \gdef\ALG@tikzmark@last{end}%
}

% the following line injects our new tikzmarking code
\apptocmd{\ALG@beginblock}{\ALG@tikzmark@start}{}{\errmessage{failed to patch}}
\pretocmd{\ALG@endblock}{\ALG@tikzmark@end}{}{\errmessage{failed to patch}}
\makeatother
% end vertical rule patch for algorithmicx

% Left-justified comments
\algnewcommand{\LeftComment}[1]{\Statex \(\triangleright\) #1}

% Change indentation
\algrenewcommand\algorithmicindent{1em}

% Keep black line numbers, even if we change line colors
\algrenewcommand{\alglinenumber}[1]{\color{black}\footnotesize#1:}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% END Algorithm stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TLDR sentence: We describe different forms of compositional generalization that are desirable in program synthesis, and present a decomposition-based approach to synthesis achieving higher compositional generalization on two domains compared to prior approaches.

\title{\exedec: Execution Decomposition \\ for Compositional Generalization \\in Neural Program Synthesis}

\author{%
Kensen Shi \\
Google DeepMind \\
\small\texttt{kshi@google.com}
\And
Joey Hong \thanks{These authors contributed during internships at Google DeepMind.}\\
UC Berkeley \\
\small\texttt{joey\_hong@berkeley.edu}
\And
Yinlin Deng \footnotemark[1] \\
University of Illinois\\
Urbana-Champaign \\
\small\texttt{yinlind2@illinois.edu}
\And
Pengcheng Yin \\
Google DeepMind \\
\small\texttt{pcyin@google.com}
\And
Manzil Zaheer \\
Google DeepMind \\
\small\texttt{manzilzaheer@google.com}
\And
Charles Sutton \\
Google DeepMind \\
\small\texttt{charlessutton@google.com}
}

\begin{document}


\maketitle

\begin{abstract}
When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose \exedec{}, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. When used with Transformer models trained from scratch, \exedec{} has better synthesis performance and greatly improved compositional generalization ability compared to baselines. Finally, we use our benchmarks to demonstrate that LLMs struggle to compositionally generalize when asked to do programming-by-example in a few-shot setting, but an \exedec{}-style prompting approach can improve the generalization ability and overall performance.
\end{abstract}

\vspace{-1mm}
\section{Introduction}
\label{sec:introduction}


\emph{Program synthesis} aims to assist programmers by automatically producing code according to a user's specification of what the code should do~\citep{RISHABHSURVEY}.
Program synthesis systems, such as programming by example (PBE) systems, have been effective 
for tasks such as  string manipulation~\citep{FLASHFILL,ROBUSTFILL,CROSSBEAM}, 
writing short Java functions~\citep{FRANGEL},
and tensor manipulation~\citep{TFCODER}.
Neural program synthesizers, especially those based on large language models~\citep{Chen2021Evaluating,Austin2021Program,ALPHACODE}, have been particularly successful at
generating code functions and blocks across a variety of general-purpose programming languages.

An essential capability of human programmers is their ability to generalize by recombining parts of prior knowledge to solve new tasks. 
For example, a capable programmer can quickly adapt to new concepts and APIs, and
compose different code idioms in unseen ways to solve novel problems. 
These skills are instances of \emph{compositional generalization}, which is the ability to generalize to test examples consisting of different compositions of components individually seen during training~\citep{Keysers2020Measuring}.
While compositionality has been studied in natural language processing~\citep{Chomsky1957Syntactic,SCAN,Gu2021Beyond}, it has not been studied deeply in the context of programming by example. This problem is potentially
fruitful not only because it might help to build more
robust program synthesizers, but also as an example of how
more general problem-solving is compositional.

To build neural synthesis systems that are better at compositional generalization,
we propose designing systems that learn to
\emph{decompose} a complex task into a list of simpler subtasks.
Each subtask is defined by a goal, so the process of decomposing a task is essentially planning.
Indeed, decomposition is a skill so fundamental to software engineering that the first programming course at Stanford University introduces decomposition within the first week~\citep{cs106a}.
This can enable compositional generalization because subtasks seen during training can be combined in different ways at test time.

Based on this intuition, we propose \exedec{}, a novel search method
for neural program synthesis that performs decomposition within the \emph{execution space}.
A PBE task defines a program by pairs of program inputs with their desired outputs.
Thus, it is natural to describe a subgoal by the desired \emph{intermediate state}, i.e.,
values of local variables, for the next subtask. To describe the intuition in another way,
we imagine that a human programmer does not decide on what code to write one token at a time,
but rather thinks about what the result of the next code block should be, and then writes code
to accomplish that.
Specifically,
\exedec{} uses two neural models, a \emph{subgoal model} that predicts the desired program state
for the next part of the program, and a \emph{synthesizer model} that attempts to generate
a program that reaches that subgoal from the prior state. We interleave neural prediction with program execution within a beam search that enables exploring different predicted decompositions. 

To evaluate this approach, we introduce a new meta-benchmark 
for measuring the compositional generalization abilities of program synthesizers.
Given a standard program synthesis benchmark containing a domain-specific language 
and a distribution over target programs, our meta-benchmark describes train-test splits for 5 different types of compositional generalization, such as length generalization or composing API functions in different combinations in the training and test sets.
While \exedec{} has slightly better performance than a Transformer baseline in the i.i.d.\ setting, \exedec{} also achieves a $2\times$ to $4\times$ accuracy increase in the compositional generalization setting.
Additionally, \exedec{} improves upon an ablation that does not explicitly propose subgoals, showing the importance of reasoning about execution subgoals instead of directly predicting code.

Interestingly, a similar approach can be applied to explore
compositional generalization in large language models (LLMs). We explore whether the LLM can solve PBE tasks that compositionally generalize beyond those in a few-shot prompt.
We similarly find that the LLM performs significantly worse when compositional generalization is required,
and that an adaptation of \exedec{} to the few-shot prompting setup increases the LLM's performance overall, including in compositional generalization. Even so, compositional generalization during program generation in LLMs remains a challenge.

\section{Compositional Generalization in Programming}
\label{sec:generalization}


The goal in program synthesis is to find a program in a given language that is consistent with a specification.
Formally, we are given a domain specific language (DSL) which defines a set $\programs$ of programs. Elements in the DSL include functions (which we call \emph{operations}), identifiers, constants, and so on.
In programming by example (PBE), the desired program is specified by a set of input/output (I/O) examples denoted $X = \{(I_1, O_1), \hdots (I_n, O_n)\}$. Then, solving specification $X$ means finding a program $P\in\programs$ that correctly solves all of the examples: $P(I_i) = O_i, \ \forall i.$
A robust program synthesizer should generalize to programs not in the training set.
Regardless of the programming language or DSL, programs are nearly always built from smaller parts, which we call \emph{subprograms}, such as lines and blocks of code, functions, and so on.
For compositional generalization, we are interested in whether the synthesizer can combine subprograms
in new ways from the training set. 


% Figure environment removed

We design our benchmark around five compositional generalization tasks applicable to program synthesis (\autoref{fig:generalization_tasks}).
These tasks measure whether synthesizers
can generalize to longer programs or to programs that use \emph{concepts}, such as API methods, in different compositional ways.
These concepts partition the DSL operations into groups.\footnote{Ideally, operations within a group should have meaningful commonalities that form one concept, and each concept should have roughly equal semantic complexity, but these are not strictly required.}
In this section, we describe the generalization
tasks abstractly,
forming a \emph{meta-benchmark} that can be applied
in future work
to construct new compositional generalization benchmarks using existing datasets or DSLs.
Then, in \autoref{sec:benchmarks}, we concretize the tasks for specific DSLs for our experiments. The five generalization tasks are:

\begin{enumerate}[leftmargin=1.2em,itemsep=0em]
\item \textbf{\LengthGen}:
Can a model \emph{produce longer code} than seen in training, when necessary?
Here, ``length'' counts the number of subprograms and not the number of tokens, so there is more emphasis on generalizing to more complex compositional patterns. For this task, we train on problems of lengths 1 to $n$ and test on lengths $n+1$ to $m$ (where $m > n$).

\item \textbf{\ComposeDiffConcepts}:
Can a model \emph{use concepts in different combinations} than seen in training?
Specifically, train the model on compositions of operations from the same concept, and test on compositions from different concepts. 
For example, if two concepts consist of operations $\{A_1, A_2, \ldots\}$ and $\{B_1, B_2, \dots\}$, then the training programs have the form $A_i \,\circ\, A_j$ and $B_i \,\circ\, B_j$, and the testing programs have the form $A_i \,\circ\, B_j$ and $B_i \,\circ\, A_j$ (and similarly for compositions of 3 or more operations). A real-world example might be  training on program containing only TensorFlow or only NumPy, but synthesizing code at test time using both libraries.

\item \textbf{\SwitchConceptOrder}:
Can a model \emph{compose concepts in different orders} than seen in training?
 We train on compositions of operations drawn from one sequence of concepts and test on a different sequence of concepts, e.g., train on $A_i \,\circ\, B_j$ and test on $B_i \,\circ\, A_j$. As a real-world example, in the training data a function might be validating inputs at the beginning of the code, but we want to use the function in a different context, e.g., to validate results at the end.

\item \textbf{\ComposeNewOp}:
Can a model learn to \emph{use a new isolated operation within a larger composition}?
In this task, we train on the isolated operation and compositions without the operation, and test on compositions using the operation.
A real-world example of this kind of generalization would be composing a new function with others in a larger solution, after seeing examples of the function used in isolation.

\item \textbf{\AddOpFunctionality}:
Can a model \emph{extend its understanding of an operation by drawing on parallels} to other operations?
We omit from the training data some functionality of an operation that could be inferred from other context, and test on programs using that functionality.
This task can occur when a library function is upgraded with a new parameter whose behavior can be inferred from analogous parameters in other functions.

\end{enumerate}

These five tasks can be grouped into three themes: (a) \emph{length generalization}; (b) \emph{mix and match concepts} (tasks 2 and 3): compose concepts in ways that were not seen during training; and (c) \emph{apply general principles} (tasks 4 and 5): adapt to new, updated, or custom APIs.

\section{Benchmark Creation}
\label{sec:benchmarks}

While \autoref{sec:generalization} focused on the meta-benchmark describing five compositional generalization tasks, this section describes our instantiation of those tasks into compositional generalization datasets for two popular synthesis domains, RobustFill~\citep{ROBUSTFILL} and DeepCoder~\citep{DEEPCODER}.

\textbf{RobustFill.}\quad
In the RobustFill domain, the objective is to synthesize a sequence of string manipulation operations from I/O examples, where each example's input is a single string. A RobustFill program is a concatenation of expressions. There are 4 categories of expressions: operations that extract a substring from the input (e.g., \code{GetToken(\emph{regex}, \emph{index})}), operations that return a modified version of the input (e.g., \code{ToCase(\emph{case})}), a special \code{Compose} operation (applying a modification operation to the result of another operation),
or a constant string character. For example, the program
\code{GetFrom(\textquotesingle\ \textquotesingle) | Const(\textquotesingle .\textquotesingle)\ | Compose(ToCase(PROPER), GetToken(WORD, 1))}
is a concatenation of 3 expressions and
transforms the input string \str{TURING, Alan} into the output string \str{Alan.Turing}.
See \autoref{app:dsls} for the full RobustFill DSL, which we extended from the original RobustFill paper~\citep{ROBUSTFILL} by adding more operations. \autoref{app:datasets} contains further details about our constructed datasets, including the different compositional generalization splits and the process for generating synthetic programming tasks according to those splits.

\textbf{DeepCoder.}\quad
The DeepCoder domain involves manipulation of integer lists in a line-by-line programming style. Tasks have one or more inputs which may be integers or integer lists. Each line of a DeepCoder program applies one DSL operation to inputs or previous variables and assigns the result to a new variable. The result of the last line is the program's output. Operations include first-order list operations (\code{Sort}, \code{Reverse}, and various forms of indexing, slicing, and aggregating) and higher-order operations (Haskell-inspired \code{Map}, \code{Filter}, \code{Count}, \code{ZipWith}, and \code{Scanl1}) which manipulate lists using one of several hardcoded lambda functions. As an example, the program \code{x0 = INPUT | x1 = Map (**2) x0 | x2 = Sort x1} (where ``\code{|}'' denotes a new line) transforms the input list \spec{$[5, 3, -4]$} into the output list \spec{$[9, 16, 25]$}. See \autoref{app:dsls} for the full DeepCoder DSL and \autoref{app:datasets} for more details about our instantiation in the DeepCoder domain.

\textbf{Choice of Domains.}\quad
Both domains allow us to generate a large amount of synthetic training data with ground-truth decompositions into subprograms. For more realistic code in general-purpose programming languages, such data collection requires more effort, especially if ``natural'' decompositions are desired.
Beyond the difference in string versus list manipulation, RobustFill and DeepCoder are quite different in other important ways, allowing us to study the compositional generalization of various approaches in different scenarios. First, RobustFill gradually builds an output by combining results of subprograms that are mostly independent, while DeepCoder applies operations repeatedly to the same few objects until the output is reached. In this sense, RobustFill is closer to inverse CAD~\citep{REPL}, instantiating complex objects with many fields like dataclasses, or other tasks involving several independent analyses, while DeepCoder is closer to tensor manipulation~\citep{TFCODER}, dynamic programming, or other tasks involving sequences of manipulations or updates applied to the same objects. Second, RobustFill uses the same input for each subprogram while DeepCoder involves program states that change due to the new variable bindings on each line, making DeepCoder more complex and closer to realistic programs with execution states changing over time.

\section{Program Synthesis via Decomposition}
\label{sec:method}

In this section we describe our proposed program synthesis method based on execution decomposition, where the model predicts step-by-step execution subgoals and synthesizes subprograms for each step.

\begin{algorithm}[t]
    \caption{\exedec: synthesis via decomposition in the execution space. \\ Note, $\{x_i\}$ is short for $[x_1, \dots, x_n]$ throughout, where $n$ is the number of I/O examples.}
    \label{alg:exedec}
    \begin{algorithmic}[1]
        \Function{\exedec}{$\{(I_i, O_i)\}$}
            \State $t \gets 1$
            \State $(I_i^{(1)}, O_i^{(1)}) \gets (I_i, O_i),\ \forall i$
            \While{True}
                \State $\{S_i^{(t)}\} \gets \Call{SubgoalModel}{\{(I_i^{(t)}, O_i^{(t)})\}}$ \Comment{Predict the next execution subgoals}
                \State $P^{(t)} \gets \Call{SynthesizerModel}{\{(I_i^{(t)}, S_i^{(t)})\}}$ \Comment{Predict the next subprogram}
                \State $E_i^{(t)} \gets \Call{Execute}{P^{(t)}, I_i^{(t)}},\ \forall i$
                \If{$\forall i.\ E_i^{(t)} = O_i^{(t)}$} \Comment{Is this the last subprogram?}
                    \State \Return $\Call{CombineProgramParts}{P^{(1)}, \dots, P^{(t)}}$
                \EndIf
                \LineComment{Update $\{(I_i^{(t)}, O_i^{(t)})\}$ to represent work that is left to be done (domain-specific).}
                \State $(I_i^{(t+1)}, O_i^{(t+1)}) \gets \Call{UpdateSpecification}{I_i^{(t)}, O_i^{(t)}, E_i^{(t)}},\ \forall i$
                \State $t \gets t + 1$
            \EndWhile
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\textbf{Execution Decomposition (\exedec{}).}\quad
The \exedec{} strategy outlined in \autoref{alg:exedec} aims to reason about the step-by-step execution behavior of a program rather than the code tokens. As in \autoref{sec:generalization}, we assume that the program is a sequence of one or more \emph{subprograms} that may be combined later. At each step, to synthesize the next subprogram, we first call a \emph{SubgoalModel} that takes I/O examples and predicts the next execution subgoals, i.e., the output of the next subprogram for each example.
Because the subgoal is the desired output at this step, predicting the
next subprogram is itself a PBE task.
Thus, we provide the inputs and subgoals to a \emph{SynthesizerModel} which predicts the corresponding subprogram.
Finally, we execute the predicted subprogram and compute an \emph{updated specification} that describes the work that remains to be done 
by the rest of the program.

This updated specification is maintained throughout the step-by-step synthesis process. Because the overall program is specified
by I/O examples, we  use I/O examples for the updated specification as well. Intuitively, the inputs in the updated specification will be the current program state, and the outputs will be the output of the overall
task, but the details are slightly different because of specifics of the DSLs.
We begin with the original I/O examples for the overall synthesis task, and we update them in a domain-specific way as subprograms are synthesized (line 10). For instance, in RobustFill the input for each subprogram is the same as the original input, while the output becomes smaller as we remove already-synthesized prefixes of the output: $(I_i^{(t+1)}, O_i^{(t+1)}) \gets (I_i^{(t)}, \Call{RemovePrefix}{O_i^{(t)}, E_i^{(t)}})$; this is because the top level operation in RobustFill programs is always concatenation.\footnote{If the synthesized subprogram does not execute to a prefix of the current output for all examples, this synthesis attempt cannot succeed due to RobustFill's concatenation of subprograms. Such ``invalid'' subprograms are detected and handled during a beam search.} For DeepCoder, the input is the full program state (i.e., the set of variables and their values for each example) which is expanded with new variables as subprograms are synthesized, while the output remains constant for each example: $(I_i^{(t+1)}, O_i^{(t+1)}) \gets (I_i^{(t)}\cup E_i^{(t)}, O_i^{(t)})$. If \exedec{} synthesizes a subprogram that executes to the entire remaining output, there are no more subprograms to synthesize, so the subprograms are combined to form the full synthesized program.

\autoref{alg:exedec} describes a single synthesis attempt, but we actually perform a \emph{search} comprising multiple synthesis attempts running efficiently in parallel using a modified beam search where each beam state is a partial rollout of the step-by-step synthesis algorithm. \autoref{app:beam_search} has more details.

\textbf{Model Architecture.}\quad
Recall from \autoref{alg:exedec} that \exedec{} relies on two models, the SubgoalModel and SynthesizerModel.
We let both be sequence-to-sequence (seq2seq) models, which have been shown to be successful on various natural language~\citep{ATTENTION,TRANSFORMER} and program synthesis tasks~\citep{ROBUSTFILL}.
We choose our seq2seq model to be a Transformer due to its impressive performance on natural language tasks over traditional RNNs~\citep{TRANSFORMER}.
We modify the baseline Transformer architecture to account for the fact that we operate on sets of inputs due to having multiple I/O examples. 
We call our model a Specification-Transformer.

For consistent notation for the two models, we let $\{X_i\}$ be the multi-example input to the transformer and $Y$ its output. 
Formally, $X_i = (I_i, O_i)$ for SubgoalModel and $(I_i, S_i)$ for SynthesizerModel, and $Y = [S_1, \mathrm{Sep}, S_2, \mathrm{Sep}, \hdots, S_n]$ for SubgoalModel and $Y = P$ for SynthesizerModel, where $\mathrm{Sep}$ is a new token added to our vocabulary to partition the subgoals across examples.
Note that subgoals $S_i$ and subprogram $P$ are sequences of tokens.

Our Specification-Transformer consists of two modules. 
A Transformer encoder receives the specification $\{X_i\}$ and produces an encoding $\phi$.
Following \citet{ROBUSTFILL}, our encoder performs \emph{double attention} on the specification. 
That is, for each example $X_i$, the encoder performs the operation $\phi_i \leftarrow \mathrm{TransformerEncoder}(X_i)$, where the encoder performs self-attention on input $I_i$ followed by cross-attention from the output (either $O_i$ or $S_i$) to $I_i$.
Then, the encoding $\phi$ is simply the concatenation across examples $\phi \leftarrow \mathrm{Concat}(\{\phi_i\})$.
Next, a Transformer decoder takes the encoding and autoregressively generates the output token-by-token.
Formally, let $Y_{\ell-1} = [y_1, y_2, \hdots, y_{\ell-1}]$ be the output (subgoals or subprogram) generated so far. The decoder predicts the next output token as
$y_\ell \leftarrow \mathrm{TransformerDecoder}(Y_{\ell-1}, \phi)$.
As described by~\citet{TRANSFORMER}, the Transformer encoder and decoder both apply a stack of self-attention and feed-forward units. For the SubgoalModel, we use Aligned Relative Attention (ARA), a new technique that helps the model output a \emph{sequence of sequences} (a subgoal for each I/O example, concatenated together); see \autoref{app:ara} for details.

\textbf{No-Subgoal Ablation.}\quad
We also experiment with an ablation of \exedec{} that performs step-by-step decomposition but without predicting execution subgoals first, instead directly predicting the next subprogram from the I/O examples. In \autoref{alg:exedec}, this ablation is achieved by replacing lines 5 and 6 with a single line, $P^{(t)} \gets \Call{CombinedModel}{\{(I_i^{(t)}, O_i^{(t)})\}}$, thus skipping the step of predicting execution subgoals. This ablation
uses the same model architecture (without ARA) and an analogous beam search. Several prior works~\citep{GARBAGECOLLECTOR,REPL,Chen2019ExecutionGuided} perform synthesis step-by-step, providing execution feedback to the synthesizer after each step to inform future predictions. Our ablation captures the essence of those approaches adapted to our setting.

\textbf{Model Training.}\quad
We generate training problems as described in \autoref{sec:benchmarks}. We train the \exedec{} and ablation models using \emph{decomposed} data, that is, based on teacher forcing using \autoref{alg:exedec}. Specifically, for each subprogram in the ground-truth solution, we collect (A) the updated specification based on executing the previous ground-truth subprograms, (B) the subprogram's execution result on all examples, and (C) the subprogram itself. Then, we train the SubgoalModel to predict (B) given (A), the SynthesizerModel to predict (C) given (B) and the example inputs from (A), and the CombinedModel to predict (C) given (A). Each model type is trained separately for each generalization task.
\autoref{app:training} contains more training details, including model sizes and hyperparameters.

\section{Experiments}
\label{sec:experiments}

We experiment with Transformers trained from scratch and with LLMs using few-shot prompting.

\subsection{Transformers Trained from Scratch}
\label{subsec:scratch}

These experiments compare \exedec{}, a version with smaller models called \exedec-Small, the no-subgoal ablation, a Transformer baseline without any decomposition, and Latent Programmer~\citep{LATENTPROGRAMMER}. All models use the same hyperparameters and architecture except: (1) \exedec{}-Small and Latent Programmer use smaller models (details and reasoning in \autoref{app:training}), (2) ARA only applies to the SubgoalModel, and (3) because the baseline Transformer and Latent Programmer are trained on entire programs instead of subprograms, but the number of training examples is held constant, they actually see more subprograms during training than our models.

Using our compositional generalization datasets (\autoref{sec:benchmarks}) and models (\autoref{sec:method}), we ran the different approaches and measured their overall success rate on 1000 test examples per generalization task. We repeated the experiments using 5 different random initializations for model training. \autoref{fig:experiments} shows the results when using a beam size of 10, \autoref{app:beam_size_1} contains results with beam size 1, and \autoref{app:single_step_accuracy} analyzes the accuracy of individual steps.

% Figure environment removed


\textbf{Discussion.}\quad
On both domains, \exedec{} significantly outperforms the Transformer baseline on every generalization task and in the i.i.d.\ setting (testing on the training distribution without any compositional generalization).
Specifically, \exedec{} achieves $+44\%$ higher average compositional generalization than the Transformer baseline on RobustFill and $+18\%$ on DeepCoder, a \emph{4.4$\times$ higher} success rate. But despite the notable improvements, DeepCoder in particular remains a difficult domain with deeply nested operation compositions that obscure the intended computation, while RobustFill has a more flat compositional structure that is easier to learn.

Our step-by-step decomposition approach introduces important inductive biases into the approach. By training models on the decomposed data, we teach the models that subprograms can be reasoned about separately, regardless of the compositional patterns present in other subprograms. The SubgoalModel does not see any code tokens and is only affected by compositional generalization patterns indirectly (since the distribution over programs affects the distribution over execution traces), and the SynthesizerModel only sees code tokens for the current subprogram and cannot reference any compositional patterns that appear when comparing to other subprograms. In contrast, the Transformer baseline sees all compositional patterns in the full programs, making it more likely to overfit to those patterns. The decomposition strategy also encourages our models to understand intermediate program states while the Transformer baseline is not trained with such execution information.

Compared to the no-subgoal ablation, \exedec{}
achieves higher compositional generalization performance on a majority of generalization tasks across the two domains, averaging $+7\%$ improvement on RobustFill (a 34\% reduction in failures) and $+5\%$ on DeepCoder (a $1.28\times$ multiplicative improvement). This supports our hypothesis that predicting execution states is more robust than predicting code in the compositional generalization setting. \exedec-Small performs slightly worse than \exedec{} (1.4\% worse on average and up to 3\% worse on any individual generalization task) but \exedec-Small still significantly outperforms the other approaches overall.

Even though \exedec{} performs the best in most situations, the no-subgoal variation is slightly better on DeepCoder's training distribution and \LengthGen. \autoref{app:spurious_patterns} provides some intuition on ``spurious patterns'' related to this result. In theory, one could combine the two decomposition variations in an ensemble to get the best of both approaches on unknown test distributions. Finally, we observe that in most cases \exedec{} has smaller variance across random initializations than the no-subgoal variation, i.e., \exedec{} might be more consistent in practice.

As a case study, we compare \exedec{}, the no-subgoal ablation, and the Transformer baseline on example RobustFill and DeepCoder problems in \autoref{app:case_study}. Through these examples, we discuss some behaviors and observations that clarify the advantages to \exedec{}'s approach.

\subsection{LLM Experiments}

It is fundamentally difficult to measure compositional generalization in LLMs, because compositional
generalization is a function of the relationship between the training and test distributions, but in
LLMs it is not easy to control the pretraining data. However, we have more control in a few-shot prompting setup, as long as we focus on program concepts that cannot have occurred in the pretraining data set.
Based on this insight, in these experiments, we used our benchmarks to measure the compositional generalization ability of
PaLM 2 Unicorn~\citep{PALM2}
during few-shot prompting for PBE. We use the same compositional generalization splits for DeepCoder and RobustFill, except that the few-shot examples and test problems have length at most 3. We make the problems easier because LLMs in general perform poorly on program synthesis tasks specified only through I/O examples, compared to natural language specifications. Within each split we balance the distribution of program lengths as much as possible,\footnote{For example, \ComposeDiffConcepts{}, \SwitchConceptOrder{}, and \ComposeNewOp{} all require programs of length at least 2, so these tasks have a 50/50 split between programs of lengths 2 and 3.} and we use 200 test problems per generalization task. Each prompt contains a description of the DSL including the available functionality, followed by 4 few-shot examples of PBE tasks and solutions drawn from the training split (different tasks are randomly chosen for different test problems), followed by the specification for a test problem (see \autoref{app:llm}). 

To make the tasks better suited to LLMs, we transform our DSL programs into Python functions that call a hypothetical \code{dsl} library to access the DSL functionality. The RobustFill subprogram \code{GetToken(WORD, 1)} becomes \code{dsl.GetToken(x, dsl.Type.Word, 1)}, and the DeepCoder subprogram \code{x2 = Map (**2) x1} becomes \code{x2 = dsl.Map(dsl.SQUARE, x1)}. For DeepCoder, we alternatively try using Pythonic expressions for all DSL functionality except the \code{Scanl1} operation, which is difficult to inline; the previous example then becomes \code{x2 = [x ** 2 for x in x1]}.

By representing DSL programs as Python functions in this way, we enable the LLM to draw upon its general understanding of Python from its pretraining data, while requiring the LLM to use a new Python library from only a description of the library along with 4 few-shot examples. This setting mirrors realistic use-cases where a user asks about a new, custom, or proprietary library that the LLM was not trained on. \autoref{app:llm} contains examples of our prompts and Python-style programs. The LLM is allowed to use arbitrary Python, although it usually follows the style in the examples.

We experimented with three prompting approaches analogous to the other experiments:
\begin{enumerate}[leftmargin=1.2em,itemsep=0em]
    \item The baseline approach is to predict the entire solution program in one decoding.
    \item The Ablation-style approach predicts the program step-by-step. Given the problem specification and history of previous steps, the LLM predicts the next line of code. We then execute the program-so-far and concatenate the predicted line of code along with its execution results into the history portion of the prompt, which will influence future steps. This stepwise process continues until the desired outputs are reached, the program fails to execute, or a budget of 3 steps is exhausted.
    \item The \exedec{}-style approach is similar, except that at each step, the LLM predicts the \emph{next execution subgoal} followed by a line of code for that step (analogous to calling the SubgoalModel and SynthesizerModel). Note that the LLM's subgoal prediction might be inconsistent with the predicted code, so in the history of previous steps, we replace the predicted subgoals with the actual execution results (analogous to how the specification is updated in \exedec{}). Over multiple steps, this process creates a prompt almost identical to that of the Ablation-style approach, except that \exedec{}-style has the execution results of a step \emph{before} the code for that step, while the Ablation-style has the execution results \emph{after} the code.
\end{enumerate}

The results are in \autoref{tab:llm}. The \exedec{}-style prompting strategy leads to the best performance for all no-generalization cases, and all but one case for the generalization average. Also, the \exedec{}-style approach significantly improves when programs are written in a more natural form (going from DeepCoder to DeepCoder-Pythonic), which is a promising sign for its general applicability. For DeepCoder-Pythonic, the \exedec{}-style approach solves between 40\% and 75\% more tasks than the next-best approach, considering each combination of no-generalization vs.\ generalization average and greedy decoding vs.\ pass@5 sampling.
But despite these improvements, compositional generalization remains difficult for LLMs. \autoref{app:llm_failures} discusses common failure modes in the LLM experiments.

\setlength{\tabcolsep}{4.5pt}
\begin{table}[t]
\centering
\small
\caption{Compositional generalization results for the LLM experiments. Each cell contains the number of solved tasks out of 200 test problems.
For approaches, @1 means 1 greedy decoding and @5 means using 5 samples with temperature 0.4.
For columns, ``None'' means no generalization, ``Gen.\ Tasks'' refers to the 5 compositional generalization tasks in the order given in \autoref{sec:generalization} (consistent with the other figures), and ``Avg'' is the average across the 5 generalization tasks.}
\vspace{-4pt}
\label{tab:llm}
\begin{tabular}{l|c*{4}{c@{\hskip5pt}}cc|c*{4}{c@{\hskip5pt}}cc|c*{4}{c@{\hskip5pt}}cc}
\toprule
 & \multicolumn{7}{c|}{RobustFill} & \multicolumn{7}{c|}{DeepCoder} & \multicolumn{7}{c}{DeepCoder-Pythonic} \\
Approach & None & \multicolumn{5}{c}{Gen.\ Tasks} & Avg & None & \multicolumn{5}{c}{Gen.\ Tasks} & Avg & None & \multicolumn{5}{c}{Gen.\ Tasks} & Avg \\
\midrule

Baseline @1  & \phantom{0}4 & 4 & \textbf{0} & \textbf{1} & 0 & 0 & 1.0 & 23 & 0 & 1 & \phantom{0}6 & 0 & \phantom{0}5 & 2.4 & 25 & 1 & 0 & 11 & 0 & \phantom{0}4 & 3.2  \\
Ablation @1  & 16 & 4 & \textbf{0} & 0 & \textbf{1} & \textbf{6} & 2.2 & 31 & 1 & 2 & \textbf{13} & 3 & \phantom{0}5 & 4.8 & 30 & \textbf{4} & 0 & 12 & 4 & \phantom{0}4 & 4.8  \\
\exedec{} @1  & \textbf{21} & \textbf{5} & \textbf{0} & 0 & \textbf{1} & \textbf{6} & \textbf{2.4} & \textbf{36} & \textbf{2} & \textbf{3} & 11 & \textbf{4} & \textbf{10} & \textbf{6.0} & \textbf{46} & 3 & \textbf{3} & \textbf{15} & \textbf{5} & \textbf{16} & \textbf{8.4}  \\

\midrule

Baseline @5  & 15 & 1 & 0 & \textbf{1} & 2 & \phantom{0}5 & 1.8 & 36 & 0 & 1 & 11 & 5 & 13 & \phantom{0}6.0 & 34 & 2 & 1 & 15 & \phantom{0}5 & \phantom{0}8 & \phantom{0}6.2 \\
Ablation @5  & 29 & \textbf{7} & \textbf{1} & 0 & 4 & \phantom{0}7 & 3.8 & 51 & 1 & 4 & \textbf{18} & \textbf{8} & \textbf{21} & \textbf{10.4} & 42 & 4 & 8 & 19 & 10 & 11 & 10.4 \\
\exedec{} @5  & \textbf{32} & 5 & 0 & 0 & \textbf{5} & \textbf{10} & \textbf{4.0} & \textbf{56} & \textbf{2} & \textbf{5} & 17 & \textbf{8} & 17 & \phantom{0}9.8 & \textbf{59} & \textbf{5} & \textbf{9} & \textbf{25} & \textbf{12} & \textbf{30} & \textbf{16.2} \\

\bottomrule
\end{tabular}
\vspace{-8pt}
\end{table}

\section{Related Work}

\textbf{Compositional Generalization.}\quad
Compositional generalization is well-studied in NLP, with established benchmarks evaluating the understanding of natural language sentences with compositionally novel structures, either constructed by synthesizing examples based on predefined generalization patterns similar to this work~\citep{SCAN,CLOSURE}, or by partitioning \textit{i.i.d.}~samples into splits with disjoint compositional structures~\citep{Finegan18Improving,Keysers2020Measuring,Shaw2021Compositional}.
Our benchmark takes inspiration from SCAN~\citep{SCAN} and COGS~\citep{COGS}, which define a taxonomy of compositional patterns in natural language.
While some generalization concepts are similar to those in \autoref{sec:generalization}, we focus on measuring compositional generalization of computer programs using I/O examples without natural language utterances, whose compositional structures are quite different from those in natural language.

To improve compositional generalization in natural language understanding, earlier works have proposed specialized task-dependent neural architectures~\citep{Russin2019Compositional,Li2019Compositional,Liu2020Compositional,Chen2020NeuralSymbolic,Herzig2020SpanBased}.
More generalized approaches include meta-learning~\citep{Lake2019Compositional,Wang2020MetaLearning,Conklin2021MetaLearning} and data augmentation~\citep{Andreas2020GoodEnough,Oren2021Finding,Akyrek2021Learning,Wang2021Learning,Qiu2022Improving}.
There have also been recent attempts in improving the compositional generalization capabilities of large language models via representation learning~\citep{Furrer2020Compositional,Herzig2021Unlocking} and in-context learning~\citep{Zhou2022LeasttoMost,Drozdov2023Compositional}.

In machine learning for code, some works include length generalization results~\citep{IPAGNN,DEEPCODER,REPL}, and \citet{Nye2021Blended} use compositional generalization in some experiments, but we study compositional generalization in a much more systematic manner.

\textbf{Programming by Example.}\quad 
Various techniques have been applied to program synthesis~\citep{RISHABHSURVEY}, and recently
much attention has focused on machine learning for programming by example~\citep{ROBUSTFILL,Parisotto2017NeuroSymbolic,DREAMCODER}.
Many methods incorporate learning to guide the search over programs, 
such as using learned premise selection~\citep{DEEPCODER,SIGNATURES},
syntax-guided search~\citep{Yin2017Syntactic,EUPHONY},
bottom-up search~\citep{TFCODER, PROBE},
two-level search~\citep{SKETCHADAPT},
and execution-guided synthesis methods~\citep{BUSTLE,CROSSBEAM}.

\textbf{Multi-step Program Synthesis.}\quad
\exedec{} is an instance of multi-step program synthesis, which broadly refers to methods involving multiple calls to (potentially different) models.
\emph{Execution-guided synthesis} is a popular form of this, iteratively generating and refining partial programs using execution information~\citep{GARBAGECOLLECTOR,REPL,Chen2019ExecutionGuided,PEPS}, and some approaches do this with latent representations of the program state~\citep{Chen2021Latent} or execution traces~\citep{Shin2018Improving}. \emph{Planning} is another form of multi-step synthesis that first generates high-level plans of what the program should do~\citep{SKETCHADAPT,BAYOU,Zhang2023Planning}, sometimes with latent representations of plans~\citep{LATENTPROGRAMMER}. 
Our method, \exedec{}, draws ideas from both avenues of multi-step synthesis, making plans by predicting subgoals and using step-by-step program execution to guide the search.

\section{Conclusion}
We explored the important aspect of compositional generalization in neural program synthesis. The ability to decompose complex tasks into smaller subtasks is a fundamental skill employed by human programmers, and measuring whether neural program synthesis methods exhibit similar capabilities is crucial for assessing their potential.
We introduced a meta-benchmark that characterizes 5 forms of compositional generalization in program synthesis, and we instantiated these generalization tasks in the RobustFill and DeepCoder domains.
The findings demonstrate that the \exedec{} approach of predicting decompositions of program execution, rather than solely focusing on program syntax, leads to significantly improved compositional generalization for both Transformers trained from scratch and LLMs in a few-shot setting. 
This suggests that incorporating information about the step-by-step decomposition and leveraging it in the synthesis of programs can enhance the ability of neural models to tackle more complex tasks. Even so, compositional generalization remains challenging for neural program synthesizers, and our meta-benchmark can help measure continued progress in this area.

\textbf{Limitations.}\quad
One limitation of \exedec{} is its need for a training dataset with ground-truth decompositions. Our experiments used synthetic programs with line-by-line decomposition, but perhaps better results could be obtained with a dataset containing more \emph{natural} decompositions.
Furthermore, the line-by-line decomposition could be a limitation as programmers often think in larger chunks or hierarchically; \autoref{app:hierarchical} discusses a potential hierarchical formulation of \exedec{} to address this limitation in future work.
Lastly, our SubgoalModel predicts tokenizations of objects, but to handle more complex objects, a more general SubgoalModel might instead predict \emph{abstractions} of objects.

\section*{Reproducibility Statement}
Our code, datasets, and checkpoints for the Transformer models trained from scratch are available at \url{https://github.com/google-deepmind/exedec}. Additionally, \autoref{app:training} contains details about model hyperparameters and sizes for the models we trained.

\section*{Acknowledgements}
The authors would like to thank Xinyun Chen, Martin Abadi, Rif Saurous, and the anonymous reviewers for their helpful comments.

\bibliography{decomposition}
\bibliographystyle{iclr2024_conference}

\input{appendix}

\end{document}
