\section{Conclusions}

We propose a base-to-global framework and a method for constructing CIs for the true ranks of the global FI values. Because rankings are frequently used to summarize FI methods' output, it is crucial to consider the rankings' stability. Our method can be used with robust and nonparametric paired-tests to support non-standard FI distributions.

We present a rigorous criterion  for quantifying uncertainty that can be explicitly modeled (e.g., the explanation set size). We view the proposed method as a step toward producing new forms of stability assessments for explainable ML. In future research, we aim to address other sources of instability, such as the difference between FI methods, although their effect is more challenging to quantify. 

Finally, our current algorithm is conservative, as demonstrated in simulations where the coverage level surpasses the requested (1-$\alpha$)\%. Future research will also be aimed at narrowing the CIs while maintaining nominal coverage and reducing the impact of the number of features on coverage by using a filtering step (e.g., eliminating non-important features).