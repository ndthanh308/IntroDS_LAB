\section{Statistical Model and Inference Goal}\label{sec:prob}

In this section, we describe our statistical model for estimating ranking uncertainty. First, we define a feature's rank-set as a rank that considers information about ties. Then we define our inference goal -- to provide simultaneous CIs for the rank-sets. Finally, we discuss the advantages of simultaneous CIs and provide an example in which the top-$k$ features are highlighted.

\subsection{True Global FI Values and Rank-Sets}

Recall that in Section \ref{sec:framework} we introduced the base FI values matrix $\basematrix$, with rows $\basevalue_i \in \real_p$. Here, we model the rows $\basevalue_i$ as independent samples from distribution $F_\basevalue$ with mean vector $E[\basevalue_i] = (\trueimp_1,\ldots,\trueimp_p)$; these are the \emph{true global FI values}. Each observed global FI value $\imp_j$ is an unbiased but noisy version of $\trueimp_j$. We are interested in understanding the effects of this variability on the possible feature rankings.

In contrast to the observed noisy ranks, the \emph{true ranks} $r_1,...,r_p$ are based on the true global FI values $\trueimp_1,...,\trueimp_p$.
Whereas in the observed global FI values exact ties are unlikely, for the true global FI values we can imagine ties between equivalent features, or we may want to allow an indifference level. We follow \cite{al2022simultaneous} in redefining the true ranks to account for ties:
\begin{definition}(Rank-Set)
\label{def:setrank}
    Define the lower rank of $\trueimp_j$ as $
        l_j = 1 + \#\{k: \trueimp_j > \trueimp_k, \, j \neq k\}$
    and the upper rank of $\trueimp_j$ as $
        u_j = p - \#\{k: \trueimp_j < \trueimp_k, \, j \neq k\} $.    Then the rank-set of $\trueimp_j$ is the set of natural numbers $\{l_j, l_{j+1}, \ldots, u_j\}$ denoted as $[l_j, u_j]$.
\end{definition}

If there are no ties, the lower and upper ranks are identical and equal to the standard definition. In the remainder of the paper, the term `true rank' will refer to the rank-set.

\subsection{CIs for True Ranks}

We propose quantifying the rankings' uncertainty using simultaneous CIs for the true ranks. Here, we define marginal and simultaneous CIs, and in Section \ref{sec:conf_rank} we propose a method for constructing valid simultaneous CIs for the true ranks.

\begin{definition}(CI for a True Rank)
    The ranks interval $[L_j, U_j]$ is an $(1-\alpha)$-level CI for a true rank of the $j$'th feature if $\mathbb{P}_{F_\basevalue}\left([l_j, u_j] \subseteq [L_j, U_j]\right) \geq 1 - \alpha$ for any possible $F_\basevalue$.
\end{definition}

$L_j, U_j$ are functions of $\basematrix$, the matrix of observed base FI values. We note that different sets of observed base FI values will produce different CIs.

The set of intervals $[L_1,U_1] , \ldots, [L_p, U_p]$ has marginal coverage if each interval is a valid CI of the corresponding true rank. For ranking and selection of features, marginal coverage is not sufficient, because it does not support selection after ranking \citep{benjamini2005false}. Therefore, our ranking method constructs simultaneous CIs for the true ranks.

\begin{definition}(Simultaneous Coverage) The set of intervals $[L_1,U_1] , \ldots, [L_p, U_p] \subseteq [1, p]$ has simultaneous coverage at level $1 - \alpha$
if 
\begin{align*}
    \mathbb{P}_{F_\basevalue}\left([l_j, u_j] \subseteq [L_j, U_j] , \quad \forall j \in \{1, \ldots, p\}\right) \geq 1 - \alpha.
    \end{align*}
\end{definition}

In $1-\alpha$ simultaneous CIs, the probability that all intervals cover the true ranks is at least $1-\alpha$. Simultaneous CIs remain valid for any form of selection after ranking (for example, selection of the most important features). We note that simultaneous coverage is conservative and can result in relatively large intervals.

\subsection{Top-K Set}\label{sec:top-k}

Here we present an application of simultaneous CIs for the selection of the most important features (top-$k$) with a guarantee of coverage. Since the ranking is based on the observed FI values, the size of the set of possible top-$k$ features might be greater than $k$.

Denote $\truetopk \subseteq \features$ as the set of features whose true FI value is ranked in the top-$k$ $\truetopk = \{j: u_k \geq p-k+1 \}$. A simple selection method is to select features for which the upper bound of the CI is greater than $p - k$. With simultaneous coverage, the probability of an error for this selection is controlled \citep{hsu1996multiple}. Furthermore, the CIs for the features currently ranked among the top-$k$ still have marginal coverage. These two properties are not guaranteed without simultaneous coverage \citep{ein2006thousands}.

\begin{lemma}
Let $\{ [L_1, U_1],\ldots,[L_p,U_p] \}$ be $1-\alpha$ simultaneous CIs for the true ranks. Define the \emph{top-k set} $\topk  = \{j: U_j \geq p-k+1 \}$. This set includes all features with an upper bound in the top-$k$ ranks $(p, p - 1, \ldots, p - k + 1)$. Then $\mathbb{P}(\truetopk \subseteq \topk) \geq 1-\alpha$.
\end{lemma}

To prove this, consider a case in which $\truetopk \subseteq \topk$ does not hold; then it must follow that there is some $j\in \truetopk$ that is not in $\topk$. This means that the estimated upper bound $U_j$ is less than the true upper rank $u_j$, so the CI $[L_j,U_j]$ does not cover $[l_j, u_j]$. Based on the definition of $1-\alpha$ simultaneous CIs, the probability of any such event is at most $\alpha.$