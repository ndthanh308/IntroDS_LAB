\section{Introduction}\label{sec:introduction}

Complex nonlinear prediction models are widely used to augment or even replace human judgement in fields such as healthcare \citep{bhardwaj2017study}, finance \citep{rundo2019machine}, and science \citep{deiana2022applications, li2022machine}. Regulators, users, and developers of such models are interested in understanding the relative contribution of the different inputs, i.e., features, to the model's predictions \citep{preece2018stakeholders, goodman2017european}.
Feature importance (FI) methods such as permutation feature importance (PFI) \citep{breiman2001random} and SHapley Additive exPlanations (SHAP) \citep{lundberg2017SHAP, lundberg2019Tree} measure the contribution of features by estimating the effect of removing, perturbing, or permuting the feature on the predicted value or prediction loss. The specifics of this manipulation vary depending on the method and implementation \citep{merrick2020explanation, covert2020imputation}.
These FI methods are employed to explain the predictions of models after they  have been trained, and therefore they are called \emph{post-hoc FI methods}. This paper focuses on global FI methods that explain the average model behavior rather than local FI methods that explain individual predictions.

Recently, studies have demonstrated that post-hoc FI methods can be unstable \citep{molnar2020general, marx2023but} due to uncertainty stemming from the size and sampling of the data used to calculate the FI values (explanation set); randomness in the perturbations, permutations \citep{lakkaraju2020robust, agarwal2022rethinking}, or approximations \citep{merrick2020explanation};  hyperparameter selection \citep{slack2021reliable, ahn2023local}; and more. We focus on uncertainty in sampling the explanation set, which affects the stability of the FI values. Most methods for quantifying this type of uncertainty produce per-feature spread estimates (or confidence intervals) in the FI method's output units \citep{ishwaran2019standard, covert2020SAGE, merrick2020explanation, slack2021reliable, ahn2023local, molnar2021relating}.

Existing uncertainty measures are insufficient, because stakeholders often rely on the \emph{rank of the FI value}, rather than the value itself, in their decisions. Feature rankings are unit-independent and are therefore easy to interpret and compare across FI methods \citep{jaxa2021sources, heldt2021early}. Instability in the global FI values can lead to instability in their ranking \citep{rising2021uncertainty} (an example is provided in Figure \ref{fig:intro}). A simple ranking of the features based on the FI values cannot reflect this uncertainty. Moreover, due to the ranking's discrete nature, existing methods for quantifying uncertainty in FI values cannot easily be modified to work for ranking uncertainty. For example, we show that confidence intervals (CIs) produced by a naive bootstrapping method based on the estimation of the ranking distribution do not cover the true ranks. The previously mentioned challenges point to the need for a framework for defining, estimating, and reporting ranking uncertainty. To properly model ranking uncertainty, we first model the uncertainty of the global FI values and then infer the effect of this uncertainty on the rankings.

% Figure environment removed

In this paper, we present a \emph{base-to-global} framework to quantify the uncertainty of global FI values. We define a two-level hierarchy of importance values, namely the \emph{base} and \emph{global} FI values, where the global FI values are the average of independent base FI values.
Based on this framework, we propose a novel method for confidently ranking features. We define the \emph{true rank} as a feature's rank, obtained based on an infinite sample, for both a trained prediction model and an FI method. Our ranking method reports simultaneous CIs, ensuring, with high probability, that each feature's true rank is covered by the appropriate interval. We construct the intervals by examining all pairs of features, testing hypotheses regarding differences in means, and counting the number of rejections for each feature. The examination process tackles the multiple tests problem, which might result in the false discovery of a feature as relevant. The validity of our proposed method is demonstrated in a comprehensive evaluation on both synthetic and real-world datasets. Our findings confirm our method's effectiveness and highlight its potential in quantifying and enhancing ranking stability. Our base-to-global framework can be viewed as a generalization of the formulate, approximate, explain (FAE) \citep{merrick2020explanation} framework for generating and interpreting Shapley-value-based FI methods. We extend the FAE concept in two respects: first, we generalize it to other post-hoc FI methods by defining the base values in a general way; and second, we address the uncertainty in the ranking of the global FI values.

Our main contributions in this paper are as follows: (1) We propose a novel ranking method for FI values. (2) We quantify the uncertainty of the ranking by providing simultaneous CIs for the features' ranks.\footnote{The paper's code is publicly available at: \url{https://github.com/BityaNeuhof/confident_feature_ranking}.} (3) We suggest an improved means of interpreting global FI values.
We generalize confident ranking methods to accommodate correlations and potential departures from normality, which are common in FI values. To the best of our knowledge, our ranking method is the first to formally incorporate uncertainty control in the \emph{ranking} of FI values.