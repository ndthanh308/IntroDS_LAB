\section{PFI Variance Analysis}\label{app:pfi_var}

In Section \ref{sec:framework}, we present two options for defining the base FI values for PFI \citep{breiman2001random}: (1) a single permutation, and (2) a single observation. We obtain the same global FI values from the two base definitions by setting the values of the number of permutations ($B$) and the size of the explanation set ($N$) accordingly. However, the different decomposition of the global FI value to base FI values allows for the analysis of various sources of uncertainty -- the variance of the permutations and the variance of the explanation set. Our framework is limited to quantifying only one source of uncertainty by aggregating base FI values to global FI values. Therefore, using it might be a problem when the uncertainty of the global FI values stems from multiple sources of uncertainty. Nevertheless, if most of the variability comes from one of the sources, it is reasonable to target it and disregard the other sources. In the case of PFI, we expect that the size of the explanation set introduces greater variance than the number of permutations. Our results clearly show this; therefore, we can use our framework to quantify the uncertainty of global PFI values.

\subsection{Experimental Setup}

In this experiment, we use the same DGPs (A and B) described in Section \ref{sec:shap_simulated}, including the definition of $X$, $Y$, and the functions.

\subsubsection{Dummy Prediction Model} 

Instead of training a model, we create a \emph{Dummy} model that predicts $Y$ from $X$ using the DGP's function. We use this approach to control the variability stemming from the training and focus on the variability of the permutations and explanation set.

\subsubsection{Experiment Details}

We sample the data as described above with various configurations of $B$, $p$, and $N$, and the two functions. For each configuration:
\begin{enumerate}[label=(\arabic*)]
    \item We perform $B$ permutations for each observation and calculate the loss difference for each permutation $b$: $L(f(x_{[j]}^b), y) - L(f(x), y)$.
    \item We average all of the permutations for each observation.
    \item We average all of the observations.
\end{enumerate}
The result of steps 1-3 is a set of $p$ global FI values $\imp_1^{PFI}, \ldots, \imp_p^{PFI}$. We repeat this process 100 times and calculate the average and standard deviation (SD) across the repetitions.

\subsection{Results}

For both functions we compare the SD of the global FI values for different values of $B$ and $N$. In Figure \ref{fig:pfi_var_sources}, we can see that different features have different SDs, but in all conditions the SD is almost fixed with respect to $B$ and decreases with $N$. This indicates that the number of observations introduces more variability to the global FI values than the number of permutations.

% Figure environment removed



