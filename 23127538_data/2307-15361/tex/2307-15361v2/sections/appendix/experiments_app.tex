\section{Experiment Details and Additional Results}\label{app:exp}


\subsection{Ranking Method Comparison}\label{app:mock}


\subsubsection{Baseline Ranking Method}\label{app:naive}
We implement a naive ranking method to construct CIs for the features' true ranks based on bootstrap samples. For each sample, we rank the global FI values. We report lower and upper bounds ($L_j, U_j$) by taking the $\alpha/2$ and $1 - \alpha/2$ quantiles of the ranks of the $j$'th feature over the bootstrap distribution.



\subsubsection{Additional Results}

\paragraph{Equal Correlations} In Figure \ref{fig:mock_exp_corr_10_50}, we present the ranking efficiency of three ranking methods for $p=10$ and $p=50$ as a function of $n$, with multiple levels of correlations. We use the same configuration as in Figure \ref{fig:mock_exp_corr}: low and high $\sigma$-factors, $\mu$-exponent=0.25, with and without ties. We can observe the same efficiency trends seen for $p=30$: 
the efficiency increases as $\rho$ increases, the gap between the methods increases as the $\sigma$-factor increases, the efficiency improves as the $n$ increases, and our ranking method is more efficient than ICRanks.

% Figure environment removed


\paragraph{Number of Features} We compare the ranking efficiency for different numbers of features and multiple values of $\mu$-exponent, with $n=500$, $\sigma$-factor=1, equal correlations, and $\rho=0.5$ (see Figure \ref{fig:mock_compare_p}). The efficiency degrades as the means become more dense ($\mu$-exponent decreases), , and the number of features has almost no effect on the efficiency.

% Figure environment removed


\paragraph{Correlation Structure} We compare the equal correlation structure with the block-wise pairs structure of the correlation matrix. In Figure \ref{fig:mock_compare_corr}, we present the results for different numbers of features, $n=500$, $\sigma$-factor=1, $\mu$-exponent-0.25, and low (0.1) and high (0.9) values of $\rho$. The differences between the structures of the correlation matrix are more substantial for $\rho=0.9$.

% Figure environment removed




\subsection{SHAP Ranking Measures}\label{app:shap_simulated}

Here, we sample the training and explanation sets using the DGP described in Section \ref{sec:shap_simulated}. For each configuration of $(X, Y)$, we train an XGB (default hyperparameters) or RF (number of estimators=1,000) regression model for this experiment. We follow the XGB tutorial\footnote{\href{https://xgboost.readthedocs.io/en/stable/tutorials/rf.html}{XGB tutorial}} to train both the XGB and RF models (see the train and test $R^2$ of the model in Table \ref{tab:shap_r2}).

\begin{table}[ht]
\centering
\caption{Prediction Models' Performance}
\label{tab:shap_r2}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Model}       & \multicolumn{1}{l|}{\textbf{DGP}} & \multicolumn{1}{l|}{\textbf{p}} & \multicolumn{1}{l|}{\textbf{Train $R^2$}} & \multicolumn{1}{l|}{\textbf{Test $R^2$}} \\ \hline
\multirow{6}{*}{RF}  & \multirow{3}{*}{DGP-A}           & 10                              & 0.786                                     & 0.783                                    \\ \cline{3-5} 
                     &                                        & 30                              & 0.523                                     & 0.515                                    \\ \cline{3-5} 
                     &                                        & 50                              & 0.346                                     & 0.336                                    \\ \cline{2-5} 
                     & \multirow{3}{*}{DGP-B}           & 10                              & 0.863                                     & 0.862                                    \\ \cline{3-5} 
                     &                                        & 30                              & 0.836                                     & 0.836                                    \\ \cline{3-5} 
                     &                                        & 50                              & 0.745                                     & 0.744                                    \\ \hline
\multirow{6}{*}{XGB} & \multirow{3}{*}{DGP-A}           & 10                              & 0.956                                     & 0.952                                    \\ \cline{3-5} 
                     &                                        & 30                              & 0.963                                     & 0.958                                    \\ \cline{3-5} 
                     &                                        & 50                              & 0.954                                     & 0.945                                    \\ \cline{2-5} 
                     & \multirow{3}{*}{DGP-B}           & 10                              & 0.875                                     & 0.868                                    \\ \cline{3-5} 
                     &                                        & 30                              & 0.951                                     & 0.946                                    \\ \cline{3-5} 
                     &                                        & 50                              & 0.964                                     & 0.959                                    \\ \hline
\end{tabular}
\end{table}


\subsubsection{Additional Results}

In the paper, we present an example of the efficiency of RF with DGP-A and XGB with DGP-B. Here, we present the complementary efficiency results for all configurations (see Figure \ref{fig:shap_additional}). The simultaneous coverage for all configurations is almost one ($0.997 \pm 0.009$). In addition, we compare the efficiency of our CIs (using our method with the Min-P procedure) with $n=1000$ base FI values, to the efficiency of the true FI ranks as an upper bound on the efficiency of the observed values (see Table \ref{tab:true_efficiency}); as can be seen, the efficiency of our ranking method with $n=1000$ is not ideal, even in the case of perfect true ranking.

% Figure environment removed


\begin{table}[ht]
\centering
\caption{Ranking Efficiency}
\label{tab:true_efficiency}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Model}       & \multicolumn{1}{l|}{\textbf{DGP}} & \multicolumn{1}{l|}{\textbf{p}} & \multicolumn{1}{l|}{\textbf{True Efficiency}} & \multicolumn{1}{l|}{\textbf{Mean Efficiency}} \\ \hline
\multirow{6}{*}{RF}  & \multirow{3}{*}{DGP-A}           & 10                              & 0.222                                         & 0.238                                         \\ \cline{3-5} 
                     &                                        & 30                              & 0.393                                         & 0.412                                         \\ \cline{3-5} 
                     &                                        & 50                              & 0.486                                         & 0.495                                         \\ \cline{2-5} 
                     & \multirow{3}{*}{DGP-B}           & 10                              & 0.222                                             & 0.386                                         \\ \cline{3-5} 
                     &                                        & 30                              & 0.634                                         & 0.641                                         \\ \cline{3-5} 
                     &                                        & 50                              & 0.772                                         & 0.777                                         \\ \hline
\multirow{6}{*}{XGB} & \multirow{3}{*}{DGP-A}           & 10                              & 0                                             & 0.204                                         \\ \cline{3-5} 
                     &                                        & 30                              & 0                                             & 0.293                                         \\ \cline{3-5} 
                     &                                        & 50                              & 0                                             & 0.32                                          \\ \cline{2-5} 
                     & \multirow{3}{*}{DGP-B}           & 10                              & 0                                             & 0.299                                         \\ \cline{3-5} 
                     &                                        & 30                              & 0                                             & 0.247                                         \\ \cline{3-5} 
                     &                                        & 50                              & 0                                             & 0.287                                         \\ \hline
\end{tabular}
\end{table}


\subsubsection{Ranking Runtime Analysis}\label{app:shap_simulated_runtime}

We also analyzed TreeSHAP's runtime and our method's runtime. In Figure \ref{fig:shap_times}, we present the runtime of TreeSHAP and the different ranking methods. TreeSHAP's runtime clearly depends on the sample size $n$, since it is a local FI method. In contrast, the runtime of the ranking methods depends on the number of features ($p$). The runtime of our method with Holm's procedure is comparable to that of ICRanks but with lower variance. The runtime of our method with the Min-P procedure is much higher, because it is based on a bootstrap process and increases with the number of repetitions ($B$).

% Figure environment removed

\subsubsection{Non-Normal Base FI Value Distribution}\label{app:shap_simulated_non_normal}

We use the paired-sample t-test to compare base FI values and adjust the p-values with the Min-P or Holm's procedure. Our primary assumption is that the paired test is calibrated for the possible distributions of base FI values (note that the paired-sample t-test is calibrated even when the base FI values are not normally distributed). However, we found that our method does not always maintain simultaneous coverage when the base FI values have an extremely long tail. In this example, we sample the data from:
\begin{equation*}
\begin{split}
    y &= x_1x_2 + x_3^2 - x_4x_7 + x_8x_{10} - x_6^2 \\
    & + x_{11}x_{12} + x_{13}^2 - x_{14}x_{17} + x_{18}x_{20} - x_{16}^2 \\
    & + x_{21}x_{22} + x_{23}^2 - x_{24}x_{27} + x_{28}x_{30} - x_{26}^2 + \epsilon; \\
    & X \sim N_{30}(\mathbf{0}, \Sigma); \, \epsilon \sim N(0, 1), \\
    & \text{where } \Sigma \text{ is an equal correlation matrix} \\
    & \text{with } \rho=0.3 \text{ and } \{\sigma_j^2\} \sim \chi^2.
\end{split}
\end{equation*}

We train an RF model and calculate the base FI values with TreeSHAP. Table \ref{tab:non_normal} summarizes the average coverage and simultaneous coverage. As can be seen, for all sizes of $n$ (the number of base FI values) our method does not maintain simultaneous coverage; the marginal coverage is almost $90\%$ for small sizes of $n$, and the simultaneous coverage of the Min-P procedure is better.

\begin{table}[ht]
\centering
\caption{Ranking Coverage}
\label{tab:non_normal}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{n}            & \multicolumn{1}{l|}{\textbf{Ranking Method}} & \multicolumn{1}{l|}{\textbf{Coverage}} & \multicolumn{1}{l|}{\textbf{Simultaneous Coverage}} \\ \hline
\multirow{2}{*}{100}  & Holm                                         & 0.839                                  & 0.08                                                \\ \cline{2-4} 
                      & Min-P                                        & 0.96                                   & 0.63                                                \\ \hline
\multirow{2}{*}{500}  & Holm                                         & 0.75                                   & 0.01                                                \\ \cline{2-4} 
                      & Min-P                                        & 0.888                                  & 0.56                                                \\ \hline
\multirow{2}{*}{1000} & Holm                                         & 0.7                                    & 0.01                                                \\ \cline{2-4} 
                      & Min-P                                        & 0.85                                   & 0.37                                                \\ \hline
\multirow{2}{*}{3000} & Holm                                         & 0.634                                  & 0.01                                                \\ \cline{2-4} 
                      & Min-P                                        & 0.782                                  & 0.14                                                \\ \hline
\end{tabular}
\end{table}

We further analyze the CIs of the features for $p=30$, an RF model, and a single explanation set of size $n=100,000$. In Figure \ref{fig:non_normal_pair}, the base FI values distribution of two features, for which we found coverage errors for multiple explanation sets. The true global FI values of the two features are almost identical, and the variance is relatively large. More importantly, the distributions of the base FI values of both features display extremely long tails, and the observed global FI values are influenced by the rare values at the tails. In such cases, we recommend replacing the paired t-test with a robust alternative \citep{wilcox2011introduction}.

% Figure environment removed


\subsection{High-Dimensional Example}\label{app:high-dim}

Displaying the global FI values or the CIs for the ranks for many features may be difficult to interpret. Therefore, typically only the top-k features are presented. For example, in SHAP's global bar plot API\footnote{\href{https://shap.readthedocs.io/en/latest/generated/shap.plots.bar.html}{Global bar plot API}.} the default number of features to present is 10. In Figure \ref{fig:high_dim_ranking}, we present the complete ranking for the Nomao dataset\citep{misc_nomao_227} features . Our ranking method makes it easier to interpret which features are irrelevant and determine how to select a threshold $k$ for the most important features to display.

% Figure environment removed