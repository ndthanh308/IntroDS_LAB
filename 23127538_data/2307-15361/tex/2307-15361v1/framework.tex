\section{Uncertainty in FI: a framework}\label{sec:framework}


Consider the supervised learning task of predicting a real-value outcome $Y \in \mathcal{Y}$ from a vector of $p$ features $X = (X_1,\ldots,X_p) \in \mathcal{X}$.
A prediction model $f: \mathcal{X} \rightarrow \mathcal{Y}$ is fit on a training set 
$\mathcal{D}_{train} =  \{(x_i^*, y_i^*)\}_{i=1}^M$, and is found to fit the data well according to standard metrics (e.g., MSE or accuracy on external test sets). 
Researchers are then interested in quantifying each feature's predictive power to the model, the \textit{feature importance value} \cite{covert2020SAGE}.

FI post-hoc methods measure an importance value for each feature, $\imp_1, \imp_2, \ldots, \imp_p \in \real$, based on a sample $\mathcal{D}_{explain} = \{(x_i, y_i)\}_{i=1}^N$, preferably independent of $\mathcal{D}_{train}$, and a trained model $f$. We assume a higher value of $\imp_j$ indicates higher importance. The features are often ranked according to the FI values, and only the top k features are considered.

\subsection{Global feature importance}

In many cases, the FI values are calculated by averaging many independent runs:
\begin{itemize}
\item In SHAP \cite{lundberg2017SHAP}, the global FI is averaged over the absolute values assigned to each example (the \emph{local} FI). Variability in the explanation set $\mathcal{D}_{explain}$ introduces the uncertainty into the global FI.
\item In PFI \cite{breiman2001random}, the global FI is averaged over multiple permutations to each feature. Here, variability in the explanation set and the randomized permutations introduces uncertainty into the global FI.
\end{itemize}


Addressing these examples in a single framework, we identify a two level FI hierarchy: the observed \emph{global} FI is an average of independent \emph{base} FI values. In the first example, the base FIs correspond to the common SHAP local values; in the second example, the base FIs corresponds to the PFI value calculated for a single permutation over the full explanation set.

Setting notations, define matrix $\mathbf{v}$ to be the matrix of \emph{base} FI values,
with rows  $v_1, ..., v_n \in R^p$ representing FI value for each feature\footnote{If base FI are the local values, $n = N$ the size of $\mathcal{D}_{explain}$.}.
$\mathbf{v}_j$ are the columns of this matrix, referring to the base FI values for the $j$'th feature. Then the observed global importance is written 
$\imp_j =\frac{1}{n} \sum v_{ij}$.

%\YB{Do I want a ranking paragraph here? }
%When FI values are unique, the ranks are well defined. Let $\hat{r}_j \in [p]$ define the rank $\imp_j$, where $\hat{r}_j = p$ if $\imp_j = max{\imp_k}$. Otherwise, of \Often only the most important features are discussed or considered for downstream analyses.
%Let $\mathbf{\hat{r}}=(\hat{r}_1, \ldots, \hat{r}_p)$ the ranks associated with be the true ranks of the values, so that $r_p$ these ranks are the target of inference of our framework.  


%After global FI are observed, the features can be ranked according to the observed values. The variability in rankning effect of the sampling in base FI on the final rankings in 

\subsection{Feature ranking}

Global FI methods are used to understand the general decision process of the model and are often interpreted as an order or a ranking \cite{jaxa2021sources, la2021molecular}. This order is then used to highlight or select the most relevant features. Additionally, different FI methods produce values in varying scales. The relative order of the features is used to compare the methods reasonably.


The observed rankings are typically derived directly from the observed global FI. Denote $\hat{r} = (\hat{r}_1, \ldots, \hat{r}_p)$, $\hat{r}_j \in \{1,...,p\}$, with the rank $p$ assigned to the largest global FI and rank $1$ to the smallest.  

To summarize, in our framework the sampling of the base FI values introduces uncertainty into the global FI. 
The global FI are then ranked, propagating the noise into the observed rankings. This process is summarized in Fig. \ref{fig:framework}.
Our \emph{base-to-global} framework can be viewed as a generalization of the formulate, approximate, explain (FAE) \cite{merrick2020explanation} framework for generating and interpreting Shapley-value-based FI methods. We extend the concept of FAE in two ways: first, by generalizing it to other post-hoc FI methods in defining the \emph{base} values in a general way; and second by addressing the uncertainty in the ranking of the \emph{global} values. 

%If feature $j$ has the maximal value ($j = \arg\max\imp_k$), then its observed rank is $\hat{r}_j = p$, see Fig. \ref{fig:framework}.


%The estimated ranks are a function of the estimated FI values; therefore, we suggest estimating the rank uncertainty based on the variability in the estimated importance values.

% Figure environment removed


%Our \emph{base-to-global} framework can be viewed as a generalization of the formulate, approximate, explain (FAE) \cite{merrick2020explanation} framework for generating and interpreting Shapley-value-based FI methods. We extend the concept of FAE to all post-hoc FI methods by suggesting to start with a formulation of the FI values as \emph{base} and \emph{global}, then approximate the base FI values, and finally, explain the model by aggregating the base FI values to global values and report their uncertainty.