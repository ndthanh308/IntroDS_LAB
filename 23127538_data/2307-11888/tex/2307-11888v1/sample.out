\BOOKMARK [1][-]{section.0.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.0.2}{Formal problem definition and known results}{}% 2
\BOOKMARK [1][-]{section.0.3}{Random Linear RNNs compress the input sequence}{}% 3
\BOOKMARK [2][-]{subsection.0.3.1}{Warm-up}{section.0.3}% 4
\BOOKMARK [2][-]{subsection.0.3.2}{Role of sparsity in a data-dependent basis}{section.0.3}% 5
\BOOKMARK [1][-]{section.0.4}{Role of the MLP}{}% 6
\BOOKMARK [1][-]{section.0.A}{Approximation theory of MLPs and RNNs}{}% 7
\BOOKMARK [1][-]{section.0.B}{Reconstruction of sparse multidimensional inputs}{}% 8
\BOOKMARK [1][-]{section.0.C}{Proofs for the MLP}{}% 9
\BOOKMARK [1][-]{section.0.D}{Alternative definition for sequence-to-sequence models}{}% 10
\BOOKMARK [1][-]{section.0.E}{Additional experiments}{}% 11
\BOOKMARK [2][-]{subsection.0.E.1}{Reconstruction using the Vandermonde inverse \(support to \247??\)}{section.0.E}% 12
\BOOKMARK [2][-]{subsection.0.E.2}{Reconstruction under sparsity \(support to \247??\)}{section.0.E}% 13
\BOOKMARK [2][-]{subsection.0.E.3}{MLP approximation}{section.0.E}% 14
