\section{Conclusions}

In this paper, we make the first attempt to explore the long-term traffic forecasting problem.
To this end, we reveal its unique challenges in exploiting the multi-scale representations of traffic data, and propose a novel \textit{Hierarchical U-net TransFormer}~(HUTFormer) to efficiently and effectively address them.
The HUTFormer mainly consists of a hierarchical encoder and decoder.
On the one hand, the hierarchical encoder generates multi-scale representations based on the window self-attention mechanism and segment merging. 
On the other hand, the hierarchical decoder effectively utilizes the extracted multi-scale features based on the cross-scale attention mechanism. 
In addition, HUTFormer adopts segment embedding and spatial-temporal positional encoding as the input embedding strategy to address the complexity issue. 
Extensive experiments on four commonly used traffic datasets show that the proposed HUTFormer significantly outperforms state-of-the-art traffic forecasting and long-sequence time series forecasting baselines.
