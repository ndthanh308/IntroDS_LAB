\section{Experiments}
\label{Sec-exp}
In this section, we introduce the experimental settings and conduct comprehensive experiments to validate the effectiveness of our robust model. 
%To be specific, we summarize the questions to be answered in the following:
Specifically, we outline the questions that we seek to answer below.
\begin{itemize}
    \item \textbf{RQ1:} Comparing with baseline models, does our model achieve better robust performance for node classification and graph clustering downstream tasks?
    %\item \textbf{RQ2:} How does our model perform on the robustness of the graph clustering downstream task?
    \item \textbf{RQ2:} How do different components of the model contribute to its performance?
    \item \textbf{RQ3:} How do the hyperparameters in the proposed model impact the quality of the node embeddings?
\end{itemize}

\subsection{Experimental settings}
\subsubsection{Datasets}
We use six popular benchmark graph datasets: Cora, CiteSeer, Cora-ML, Photo, Computers and WikiCS~\cite{CitationNetwork, WikiCS, Amazon} for evaluation. 
%and deploy the graph contrastive learning for the unsupervised node classification task. 
%Specifically, there are three citation networks (Cora, CiteSeer, and Cora-ML), two co-purchase networks (Photo and Computers), and one reference network. For citation networks, the nodes represent the documents and the edges represent the citation links. The node attribute matrix is constructed by the sparse bag-of-words~\cite{BagofWords} feature vectors for each document. For co-purchase networks, the nodes represent the items on the Amazon e-commerce platform and the edges denote that the two items are frequently bought together. The node representations are the outputs of the bag-of-words model fed by the item views. The WikiCS is a reference network constructed based on Wikipedia. The nodes correspond to articles about computer science and the edges are hyperlinks between the articles. Node features are calculated as the average of pre-trained GloVe~\cite{Glove} word embeddings of words in each article. 
The detailed statistics of these datasets are summarized in Tab.~\ref{tab-dataset}.
\begin{table}[h]
	\centering
	\caption{Dataset statistics.}
	\label{tab-dataset}
	\resizebox{0.8\columnwidth}{!}{%
		\begin{tabular}{l|cccc}
			\toprule[1.pt]
			Datasets & \#Nodes & \#Edges & \#Classes & \#Features \\
			\hline
			Cora     & $2708$  & $5278$  & $7$   & $1433$\\ 
			Citeseer & $3327$  & $4552$  & $6$   & $3703$\\
			Cora-ML & $2995$  & $8416$ & $7$ & $2879$\\
                Photo & $7650$ & $119081$ & $8$ & $745$\\
                Computers & $13752$ & $245861$ & $10$ & $767$\\
                WikiCS & $11701$ & $215863$ & $10$ & $300$\\
			\bottomrule[1.pt]
		\end{tabular}
	}
\end{table}

\subsubsection{Settings}
To validate the quality of the node embeddings effectively, we utilize semi-supervised node classification and unsupervised graph clustering as downstream tasks. For node classification, we train a multi-class logistic regression model with Adam optimizer~\cite{Adam} and randomly split the node labels into three groups: training, validation and testing set with the ratio as $10\%$, $10\%$ and $80\%$. 
%The logistic regression model has a learning rate of $0.01$ and $5000$ training iterations. 
For graph clustering, the K-means clustering~\cite{KMeans} algorithm is run based on the pre-trained node embeddings derived from GCL models and we report the normalized mutual information (NMI) to quantify the robustness of the graph clustering performances.
A two-layered GNN encoder is deployed for all the GCL models. The embedding dimension of the first layer is $128$ for all the datasets and the embedding dimension of the second layer is $32$ for Cora, CiteSeer and Cora-ML and $128$ for Photo, Computers and WikiCS. We train the GNN encoder parameters $\theta$ via Adam optimizer with the learning rate equal to $0.0005$ and the training epochs equal to $1000$. We run all the models $10$ times with different seeds and report the mean value for a fair comparison. The hyperparameter $\eta$ based on $\mathcal{L}_{pnc}^{*}$ in Eqn.~\ref{eqn-pseudo-normalized-cut} without querying the node labels. All the models are executed on an Intel 10C20T Core i9-10850K CPU with GIGABYTE RTX3090 24GB GPU.
\begin{table*}[h]
\centering
    \caption{Performances on node classification against Mettack.}
	\label{tab-defend-Mettack}
	\resizebox{1.8\columnwidth}{!}{%
\begin{tabular}{l|ccccccccc}
\toprule[1.pt]
 Dataset & $\frac{B}{|E|}$ & BGRL       & DGI        & MVGRL               & GRACE       & ARIEL       & GCA         & SPAN        & GCHS                 \\ \hline
\multirow{5}*{Cora}&0\% & 75.12(1.7) & 81.04(1.7) &                                   \textbf{82.93(0.8)} & 81.02(1.17) & 81.14(0.87) 
                   & 82.09(0.36) & 81.83(0.88) & 80.03(0.78) \\
                   \cline{2-10}
                  &5\% & 66.97(1.4) & 73.41(1.0) & 75.73(0.5) & 72.46(1.80) & 74.92(1.23) & 73.80(1.09) & 74.18(0.94) & \textbf{78.78(1.02)} \\
                  &10\% & 60.11(1.7) & 68.03(1.8) & 71.10(1.4) & 65.37(2.80) & 71.93(1.24) & 70.26(1.34) & 68.81(1.89) & \textbf{75.93(0.85)} \\
                  &15\% & 51.85(3.0) & 59.70(2.7) & 64.69(1.9) & 52.62(3.10) & 52.91(4.39) & 57.89(1.52) & 58.44(3.23) & \textbf{71.89(1.56)} \\
                  &20\% & 44.18(4.3) & 51.43(2.3) & 57.29(2.8) & 41.17(3.98) & 43.71(3.87) & 46.03(3.01) & 45.71(2.50) & \textbf{68.81(2.44)} \\
\hline
\multirow{5}*{CiteSeer}&0\% & 62.55(1.4) & 70.63(1.3) & 72.35(0.8)                        & 70.97(1.14) & 71.72(1.26) &                                      \textbf{72.37(1.06)} & 71.61(0.96) &       71.80(1.28) \\
                       \cline{2-10}
                       &5\%  & 56.90(2.7) & 66.43(1.1) & 68.93(0.9) & 69.55(1.96) & 70.79(1.70) & 67.93(1.14) & 69.08(1.32) & \textbf{70.93(1.27)} \\
                       &10\% & 52.30(2.6) & 60.78(2.8) & 65.01(1.2) & 63.49(2.25) & 69.14(2.14) & 60.82(1.26) & 65.18(2.58) & \textbf{69.43(1.28)} \\
                       &15\% & 44.44(2.7) & 53.30(2.4) & 58.51(1.3) & 53.67(2.73) & 56.46(2.33) & 52.52(1.67) & 56.08(3.50) & \textbf{65.84(1.16)} \\
                       &20\% & 40.89(3.2) & 49.54(1.9) & 51.69(1.6) & 47.62(2.95) & 47.93(3.17) & 48.79(1.42) & 50.68(3.02) & \textbf{62.65(1.48)} \\
\hline
\multirow{5}*{Cora-ML}&0\% & 74.74(1.3) & 81.93(0.9) & 
                      \textbf{82.93(0.9)} & 82.46(0.54) & 82.68(0.44) & 82.78(0.76) & 82.03(0.67) & 81.41(0.75) \\
                      \cline{2-10}
                      &5\%  & 64.26(1.9) & 67.06(2.9) & 70.18(2.5) & 68.65(1.96) & 71.21(1.74) & 69.84(1.74) & 69.34(0.88) & \textbf{77.90(0.83)} \\
                      &10\% & 53.08(2.6) & 49.34(2.1) & 54.20(2.4) & 50.49(1.72) & 51.87(1.76) & 46.81(1.86) & 50.44(1.22) & \textbf{71.57(1.66)} \\
                      &15\% & 44.09(3.6) & 42.21(1.5) & 45.96(3.3) & 40.89(3.40) & 41.11(2.31) & 37.17(3.58) & 41.77(2.37) & \textbf{64.56(1.82)} \\
                      &20\% & 37.41(3.3) & 34.35(0.4) & 37.40(2.3) & 31.57(3.28) & 28.52(2.22) & 26.69(2.10) & 33.46(2.47) & \textbf{56.43(2.50)} \\
\hline
\multirow{5}*{Photo}&0\% & 85.79(0.4) & 78.26(0.5) & 89.48(0.8) &                      90.16(0.2) & 89.39(0.7) & 89.19(0.9) & 
                    87.53(1.0) & \textbf{90.87(0.3)} \\
                    \cline{2-10}
                    &5\%  & 66.50(2.8) & 62.24(3.4) & 73.14(1.3) & 70.87(1.1) & 69.85(2.4) & 76.45(2.1) & 72.46(2.3) & \textbf{78.37(2.2)} \\
                    &10\% & 52.62(3.9) & 47.76(3.7) & 58.63(3.3) & 51.39(1.5) & 53.92(1.8) & 60.57(2.0) & 63.46(0.4) & \textbf{67.80(2.4)} \\
                    &15\% & 43.56(2.4) & 40.73(3.6) & 49.82(2.0) & 44.37(1.6) & 45.98(1.8) & 51.66(1.4) & 50.02(0.4) & \textbf{59.19(1.5)} \\
                    &20\% & 35.68(3.5) & 37.91(4.0) & 45.00(2.0) & 32.45(1.4) & 34.19(1.8) & 45.35(1.3) & 46.81(3.4) & \textbf{54.68(2.9)} \\
\hline
\multirow{5}*{Computers}&0\%  & 77.32(1.6) & 72.88(2.9) & 
                        80.03(0.6) & 84.30(0.8) & 83.83(1.4) & \textbf{85.02(1.2)} & 80.87(0.8) & 83.99(1.1) \\
                        \cline{2-10}
                        &5\%  & 63.12(1.3) & 63.91(1.9) & 69.16(0.6) & 66.22(1.0) & 67.51(1.7) & 68.02(0.9) & 64.06(1.4) & \textbf{72.25(2.2)} \\
                        &10\% & 61.33(2.1) & 57.06(1.9) & 64.58(0.4) & 58.07(2.0) & 57.04(1.5) & 58.90(2.1) & 54.81(1.3) & \textbf{66.14(2.1)} \\
                        &15\% & 52.59(3.4) & 51.40(2.0) & 54.99(2.6) & 52.58(2.1) & 43.65(2.6) & 52.90(2.6) & 45.63(3.2) & \textbf{59.93(3.8)} \\
                        &20\% & 37.61(2.3) & 41.54(4.9) & 44.98(3.5) & 37.21(3.9) & 34.71(1.7) & 38.81(3.6) & 37.39(2.1) & \textbf{51.13(4.1)} \\
\hline
\multirow{5}*{WikiCS}&0\%  & 74.78(0.5) & 77.09(0.8) & 78.42(0.4) 
                     & \textbf{79.70(0.2)} & 78.48(0.5) & 79.35(0.3) & 79.27(0.4) & 78.02(0.3) \\
                     \cline{2-10}
                     &5\%  & 40.91(1.0) & 43.71(2.2) & 42.17(1.8) & 41.30(1.1) & 43.92(1.0) & 41.67(0.8) & 40.60(1.1) & \textbf{55.93(0.8)} \\
                     &10\% & 29.93(0.9) & 33.88(2.7) & 30.73(0.7) & 30.89(1.1) & 33.55(1.4) & 31.18(0.7) & 28.48(0.7) & \textbf{49.30(0.6)} \\
                     &15\% & 24.35(0.7) & 27.10(2.0) & 24.54(1.1) & 25.40(0.4) & 27.37(0.6) & 25.25(0.5) & 23.32(0.7) & \textbf{42.96(1.1)} \\
                     &20\% & 21.60(1.8) & 23.79(1.3) & 22.38(0.8) & 23.23(0.4) & 24.56(0.7) & 23.03(0.7) & 21.79(0.5) & \textbf{36.47(1.0)} \\
\bottomrule[1.pt]
\end{tabular}}
\end{table*}

\begin{table*}[h]
\centering
    \caption{Performances on node classification against CLGA.}
	\label{tab-defend-CLGA}
	\resizebox{1.8\columnwidth}{!}{%
\begin{tabular}{l|ccccccccc}
\toprule[1.pt]
 Dataset & $\frac{B}{|E|}$ & BGRL       & DGI        & MVGRL               & GRACE       & ARIEL       & GCA         & SPAN        & GCHS                 \\ \hline
\multirow{4}*{Cora}
&5\%      & 70.78(1.1) & 78.96(1.3) & \textbf{80.09(0.9)} & 78.95(0.93) & 78.47(0.72) & 78.55(0.72) & 78.96(0.72) & 79.13(0.59)           \\
&10\%     & 68.35(1.9) & 75.64(1.2) & 77.92(0.9)          & 76.79(1.35) & 76.31(0.92) & 77.15(0.78) & 77.22(1.09) & \textbf{78.62(1.11))} \\
&15\%     & 66.15(1.3) & 73.72(0.7) & 75.89(1.0)          & 75.38(1.14) & 74.75(0.89) & 74.71(1.15) & 76.11(1.19) & \textbf{78.18(1.02)}  \\
&20\%     & 64.44(1.8) & 71.94(1.7) & 74.64(0.8)          & 73.13(1.06) & 74.44(1.19) & 71.78(1.00) & 74.43(1.64) & \textbf{76.82(1.16)} \\
\hline
\multirow{4}*{CiteSeer}
&5\%      & 58.52(1.3) & 66.24(1.5) & 68.60(1.2) & 69.38(1.22) & 70.43(1.17) & 67.92(1.04)          & 70.38(1.11) & \textbf{71.18(1.22)} \\
&10\%     & 56.27(1.3) & 65.62(1.5) & 67.65(1.0)          & 67.80(1.04) & 69.25(2.09) & 65.43(1.07)          & 68.74(1.34) & \textbf{70.11(0.86)} \\
&15\%     & 54.09(2.0) & 63.75(1.6) & 66.29(0.8)          & 67.52(1.55) & 66.77(2.40) & 62.43(1.74)          & 67.71(1.33) & \textbf{69.58(1.54)} \\
&20\%     & 51.24(1.9) & 62.55(1.5) & 64.24(1.3)          & 65.68(1.65) & 64.99(2.06) & 60.52(1.66)          & 66.62(1.36) & \textbf{67.90(1.12)} \\
\hline
\multirow{4}*{Cora-ML}
&5\%      & 70.38(2.1) & 77.91(0.9) & 78.62(0.8) & 79.16(0.99) & 79.27(0.64) & 77.53(0.70)          & 79.36(0.98) & \textbf{80.02(0.82)} \\
&10\%     & 68.75(1.7) & 76.40(1.1) & 76.29(0.9)          & 77.34(1.01) & 77.87(0.66) & 76.18(0.88)          & 77.96(0.82) & \textbf{78.68(0.90)} \\
&15\%     & 67.38(1.1) & 75.46(1.4) & 74.61(0.6)          & 76.54(0.83) & 76.97(0.90) & 74.09(1.15)          & 77.10(0.56) & \textbf{77.34(0.92)} \\
&20\%     & 65.09(2.0) & 73.42(1.7) & 73.40(0.8)          & 75.36(0.80) & 75.36(1.28) & 72.54(0.89)          & 75.99(0.52) & \textbf{76.72(0.79)} \\
\hline
\multirow{4}*{Photo}
&5\%      & 80.79(1.4) & 75.80(2.8) & 84.86(0.7) & 81.91(0.8) & 82.28(1.0) & 82.25(1.1) & 84.18(0.8) & \textbf{87.09(0.6)} \\
&10\%     & 79.11(1.0) & 72.74(3.4) & 82.27(0.9) & 77.49(1.0) & 78.12(0.9) & 79.17(0.8) & 82.21(0.7) & \textbf{85.04(0.5)} \\
&15\%     & 77.83(0.9) & 68.99(0.5) & 80.39(0.7) & 75.28(1.0) & 76.98(0.6) & 76.68(0.8) & 80.78(0.5) & \textbf{82.11(1.1)} \\
&20\%     & 76.97(0.8) & 68.59(2.0) & 78.88(0.8) & 71.85(1.2) & 74.92(1.3) & 73.10(0.7) & 78.90(0.9) & \textbf{79.21(2.2)} \\
\bottomrule[1.pt]
\end{tabular}}
\end{table*}

% Figure environment removed

\subsubsection{Baseline Models}
To thoroughly validate the robustness of our proposed method, we have conducted a comparative analysis with several state-of-the-art graph contrastive learning models: BGRL~\cite{BGRL}, DGI~\cite{DGI}, MVGRL~\cite{MVGRL}, GRACE~\cite{GRACE}, GCA~\cite{GCA}, ARIEL~\cite{ARIEL}, and SPAN~\cite{SPAN}. Among them, ARIEL and SPAN are known for their robustness in GCL. Meanwhile, it is worth noting that the defense methods proposed in \cite{GRV, LocalGlobal} require access to the \textit{clean} graph, which is not available in a more practical setting such as ours, ARIEL and SPAN. To ensure a rigorous comparison, we have used the same hyperparameter settings as reported in the corresponding literature, where all the baselines are fine-tuned based on the performance of the validation set. 

\subsection{Robustness on Node Classification}
\label{Sec-Robust-NC}
The objective of this paper is to examine the adversarial robustness of our proposed model against two common graph structural attacks: Mettack~\cite{Mettack} (a graph structural attack with GNN as its surrogate model) and CLGA~\cite{CLGA} (a graph structural attack with GCL as its surrogate model). 
\subsubsection{Against Mettack}
Tab.~\ref{tab-defend-Mettack} displays the accuracies of various GCL models for the semi-supervised node classification under different attacking powers. In particular, the attacking power is defined as the percentage $\frac{B}{|E|}$, where $B$ is the attack budget (number of modified edges) and $|E|$ is the total edge number of the clean graph. To cover most attacking scenarios, we have chosen the attacking power from $\{5\%, 10\%, 15\%, 20\%\}$, which is consistent with the prior literature~\cite{Mettack, CLGA}. 

The results in Tab.~\ref{tab-defend-Mettack} indicate that Mettack affects all GCL methods, although it is originally designed to attack vanilla GNNs. This is because the GCL models also rely on the GNN encoder to convert the graph data into low-dimensional embeddings, and thus, Mettack can indirectly compromise the quality of the GCL's node embeddings.
%by decreasing the homophily degree of the clean graph.  

The second observation is that our proposed model outperforms the other baselines across various levels of attacking power. Moreover, the performance gap between our model and other baselines widens as the attacking power grows from $5\%$ to $20\%$.
%Besides, the margin of the proposed model with other baselines increases as the attacking power increase from $5\%$ to $20\%$. 
For example, on the Cora dataset, the performance gaps  between our model with GRACE, ARIEL, GCA, SPAN, BGRL, DGI and MVGRL are $8.02\%$, $4.90\%$, $6.32\%$, $5.84\%$, $14.99\%$, $6.82\%$ and $3.87\%$ when the attacking power is $5\%$. The corresponding margins under $20\%$ attacking power are $40.17\%$, $36.47\%$, $33.11\%$, $33.57\%$, $35.79\%$, $25.26\%$, $16.74\%$. 
%The reason is that there exists more maliciously inserted heterophilous links under the high level of attacking power and in the meanwhile, the sanitation view of the proposed model automatically prunes more malicious edges from the poisoned graph and thus significantly recovers the node embeddings' quality, i.e., node embeddings are distinguishable over different classes. 
This can be attributed to the fact that as the attacking power grows, more malicious heterophilous links are inserted. However, the sanitizer in our proposed model can effectively eliminate a greater number of malicious edges from the heavily poisoned graph, thereby improving the quality of node embeddings and making them more distinguishable across different classes.

Thirdly, it is observed that in certain scenarios, our model cannot surpass other strong baselines on clean graphs. For instance, on the CiteSeer dataset, the node classification accuracy of our model is slightly lower than that of GCA and MVGRL by $0.57\%$ and $0.55\%$. 
This phenomenon is common in the field of adversarial machine learning and can be attributed to the trade-off between expressive power and the robustness of the model~\cite{robustness_tradeoff, zhang2019theoretically}. 
%This phenomenon makes sense and usually exists in the graph security field. It is due to the trade-off between expressive power and the robustness of the robust model~\cite{robustness_tradeoff, zhang2019theoretically}. It is well-studied in the AI security field that a robust model may be insufficient to the target objective. For example, the most robust mapping is the constant map, which always outputs the same representation whatever the input is. However, it is still a profitable business since we only sacrifice a bit of node classification accuracy on the clean graph but reward much performance gain on the poisoned graph.    

\subsubsection{Against CLGA}
%The robust performances of various GCL models against the unsupervised attack CLGA are listed in Tab.~\ref{tab-defend-CLGA}. Similar to the robust performance against Mettack, our model still outperforms other baseline models under various attacking powers from low-level to high-level in most cases. However, since the CLGA is an unsupervised attack, the decreasing degree of the node classification accuracy for GCL models is not as significant as Mettack (Mettack focuses on attacking the test set). Besides, the reason that MVGRL performs well against CLGA and even outperforms our method when the attacking power is equal to $5\%$ on the Cora dataset is that MVGRL does not deploy the infoNCE loss to train the node embeddings but CLGA focuses on maximizing the infoNCE loss. Nevertheless, our model still outperforms MVGRL on the Cora dataset when the attacking power increase to larger or equal to $10\%$. Overall, based on the robust performances presented in Fig.~\ref{fig-defend-Mettack} and Tab.~\ref{tab-defend-CLGA}, the proposed homophily-driven learnable sanitation view can indeed effectively improve the robustness of the vanilla GCL framework by automatically pruning the potential heterophilous edges existed in the poisoned graph. 

Tab.~\ref{tab-defend-CLGA} presents the robustness results under the unsupervised attack CLGA. Similar to its performance under Mettack, our model outperforms other baselines across various levels of attacking power. However, since CLGA is an unsupervised attack, the degree of decreasing node classification accuracy for GCL models is not as significant as in Mettack, which specifically targets the test set. 

We note that MVGRL performs well against CLGA and even outperforms our method when the attacking power is equal to $5\%$ on the Cora dataset. This is because  MVGRL does not use the infoNCE loss for training, which is the attack objective of CLGA. Nevertheless, our model outperforms MVGRL on the Cora dataset when the attacking power is larger or equal to $10\%$. Overall, the proposed homophily-driven learnable sanitation view effectively promotes the robustness of the vanilla GCL framework by automatically detecting and pruning potential heterophilous edges in the poisoned graph, as demonstrated by the robust performance results shown in Tab.~\ref{tab-defend-Mettack} and Tab.~\ref{tab-defend-CLGA}.


\subsection{Robustness on Graph Clustering}
%In this part, we examine the adversarial robustness of GCL models on the graph clustering downstream task. Under this scenario, we focus on the unsupervised graph structural attack method CLGA as the graph attacker since CLGA is the first representative graph attacker that can significantly degenerate the quality of node embeddings via maximizing the infoNCE loss and is independent of the downstream task. The attacking scenario is the same as mentioned in Sec.~\ref{Sec-Robust-NC}. The experiment results are listed in Fig.~\ref{fig-cluster-defend-CLGA}. 

In this section, we examine the adversarial robustness of GCL models on the graph clustering downstream task, with a focus on the unsupervised graph structural attack method CLGA. This attack method is particularly relevant since it can significantly degrade the quality of node embeddings, irrespective of the downstream task. The attacking scenario is the same as described in Section~\ref{Sec-Robust-NC}, and the experiment results are presented in Fig.~\ref{fig-cluster-defend-CLGA}.

Firstly, we investigate the attack performance of CLGA against the graph clustering task by observing the degeneration percentage of GCA's clustering performance (CLGA chooses GCA as its representative surrogate model). It is observed that for the four graph data listed in Fig.~\ref{fig-cluster-defend-CLGA}, the NMI score of the GCA model indeed decreases as the graph attacker increases the attacking power. For example, compared to the clean graph, the decreasing percentages on the poisoned Cora dataset are $22.22\%$, $24.07\%$, $37.04\%$, $40.74\%$ when the attacking power increases from $5\%$ to $20\%$. This phenomenon demonstrates that CLGA can successfully attack the graph clustering task by indirectly attacking the infoNCE loss of the graph contrastive learning framework.  

The second key finding is that our proposed model achieves the best performance in most cases with various attacking powers ranging from $5\%$ to $20\%$. For instance, under the attacking power equal to $10\%$, our method outperforms GCA and SPAN around $19.35\%$ and $25.81\%$ for CiteSeer. Similar to the node classification task, our method cannot achieve the best clustering performance on the clean graph. This bottleneck is still due to the trade-off between the expressive power and the robust model. Alternatively, SPAN can perform well in certain scenarios and even outperform our method on the Photo data when the attacking power is equal to $15\%$ demonstrating that SPAN has intrinsic robustness property on the graph clustering task. The reason is that the spectrum-invariance-based augmentation of SPAN can inherently preserve the clustering consistency to some extent. Specifically, the graph spectrum is a summary of graph structural properties such as clustering~\cite{Chung:1997, 10.1145/2665063}. SPAN enhances the robustness of graph clustering by selecting two augmentation views to simultaneously maximize and minimize the spectrum distance of the original graph and corrupted graph in the augmentation view while maintaining consistency on the embedding space between the two augmentation views from the contrastive loss. However, the fact that our method performs better than SPAN in most cases demonstrates that the homophily-driven sanitation view of sanitizing the potential inter-class links is a more appropriate defense method to promote the robustness of the graph clustering task.  
% Figure environment removed
% Figure environment removed
% Figure environment removed
% Figure environment removed

\subsection{Ablation Study}
In Sec.~\ref{Sec-insights}, we concluded that both infoNCE loss and the graph homophily $\delta_{x}$ can serve as appropriate supervisors and lead to high-quality sanitized node embeddings. In this section, we present the ablation study to verify the effectiveness of these two vital components. Particularly, we introduce two model variants as follows:
\begin{itemize}
    \item GCHS w.o. $\mathcal{L}_{info}$: we remove the infoNCE loss in Eqn.~\ref{eqn-san-obj-2} and first train the sanitation view to optimize $\delta_{x}$. Then, we train the GCL model with the pre-trained sanitation view. 
    \item GCHS w.o. $\delta_{x}$: we remove the $\delta_{x}$ term in Eqn.~\ref{eqn-san-obj-2} and only optimize the infoNCE loss in GCHS.
\end{itemize}
The results are presented in Fig.~\ref{fig-Ablation}. Firstly, comparing the robust performance of GCHS w.o. $\mathcal{L}_{info}$, GCHS w.o. $\delta_{x}$ and GRACE, we find out that both optimizing the infoNCE loss and the graph homophily $\delta_{x}$ can enhance the robustness of the GCL model since in most cases the two model variants outperform GRACE. Secondly, the comparison of GCHS w.o. $\mathcal{L}_{info}$ and GCHS w.o. $\delta_{x}$ under Mettack reveals that optimizing $\delta_{x}$ provides more powerful robustness than optimizing $\mathcal{L}_{info}$. The reason is that Mettack will maliciously inject more inter-class links than CLGA and directly optimizing the graph homophily will have a more significant sanitation gain than indirectly optimizing the task-related loss function. Thirdly, the observation that GCHS outperforms both model variants demonstrate that considering both components is necessary to achieve the best sanitized node embeddings.

\subsection{Sensitivity Analysis}
We examine the sensitivity of GCHS to the hyperparameter $\eta$ in Eqn.~\ref{eqn-san-obj-2}. To be specific, we report the best pseudo normalized cut loss $\mathcal{L}_{pnc}^{t^{*}}$ and the node classification accuracy with attack power equal to $10\%$ for CLGA and Mettack as exemplar and present the results in Fig.~\ref{fig-Sensitivity}. Moreover, we tune the hyperparameter $\eta$ ranged in $[0,0.0001,0.001,0.01,0.1,1,3,5].$ The experiments demonstrate that too large and too small $\eta$ may lead to sub-optimal performance on GCHS under different attacking scenarios. Alternatively, for all the cases listed in Fig.~\ref{fig-Sensitivity} $\eta=1$ can achieve the minimum $\mathcal{L}_{pnc}^{t^{*}}$ (coincide with the best node classification accuracy).   

\subsection{Embeddings Visualization}
We provide the node embeddings visualization for GCHS, SPAN and ARIEL (robust GCLs) to qualitatively evaluate the quality of node embeddings under different attacking scenarios (CLGA and Mettack with attacking power equal to $20\%$) in Fig.~\ref{fig-visual-embs}. The visualization is depicted on the transformed node embeddings generated by GCHS, SPAN and ARIEL via t-SNE~\cite{tSNE}. Clearly, the node embeddings for GCHS are more discriminative than SPAN and ARIEL and the clusters of GCHS are more cohesive than the others.   

\subsection{Robustness on GRV}
To illustrate the robustness of GCHS from an information-theoretic perspective, we utilize GRV~\cite{GRV, LocalGlobal} mentioned in Def.~\ref{lemma-GRV} to indirectly quantify the GCL's robustness. It is worth noting that GRV measures the difference between the mutual information of the node embeddings for the clean graph and the poisoned graph. Here we utilize the infoNCE loss to approximate the mutual information. We emphasize that we only use the clean graph's information on computing GRV instead of training the robust model and hence prevent the information leakage. We compare GCHS with SPAN and ARIEL in this part and report the GRVs for each robust model in Fig.~\ref{fig-GRV}. A lower GRV indicates better robustness. It is observed that GCHS achieves the minimum GRV for both CLGA and Mettack, demonstrating that the node embeddings of GCHS are more robust than those of the other models from an information-theoretic perspective. 

\subsection{Time Cost}
\begin{table}[h]
	\centering
	\caption{Time cost (s).}
	\label{tab-time}
	\resizebox{0.9\columnwidth}{!}{%
	\begin{tabular}{cccccc|ccc}
        \toprule[1.pt]
Dataset & BGRL  & DGI   & MVGRL & GRACE & GCA   & ARIEL & SPAN  & GCHS  \\
Cora      & $0.011$ & $0.005$ & $0.008$ & $0.008$ & $0.009$ & $0.084$ & $0.245$ & $0.045$ \\
CiteSeer  & $0.017$ & $0.006$ & $0.011$ & $0.010$ & $0.009$ & $0.068$ & $0.174$ & $0.041$ \\
Cora-ML & $0.029$ & $0.006$ & $0.013$ & $0.015$ & $0.011$ & $0.111$ & $0.310$ & $0.067$ \\
Photo & $0.031$ & $0.010$ & $0.019$ & $0.038$ & $0.051$ & $1.056$ & $4.347$ & $0.468$ \\
Computers & $0.059$ & $0.023$ & $0.031$ & $0.099$ & $0.090$ & $5.198$ & $8.694$ & $2.293$ \\
WikiCS & $0.043$ & $0.018$ & $0.026$ & $0.067$ & $0.066$ & $4.085$ & $7.394$ & $1.360$ \\
        \bottomrule[1.pt]
        \end{tabular}}
\end{table}
Tab.~\ref{tab-time} presents the time required for each iteration of the training phase of the GCL models. The last three columns show the time cost of using the learnable augmentation views. It is evident that the GCL model with learnable augmentation views requires more computation time than the others. In addition to that, our model consumes the least amount of computation time compared to the other two models with learnable augmentation views.  















