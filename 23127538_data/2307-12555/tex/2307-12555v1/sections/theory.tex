\section{Theoretical Analysis}
Assuming $X=\left\{x_1, x_2, \cdots, x_n\right\}, Y=\left\{y_1, y_2, \cdots, y_n\right\}, A=\left\{a_1, a_2, \cdots, a_n\right\}$ are node attribute set, node label set and node neighbor set respectively. Homophily is essentially a strong relevance between neighbors and labels, that is, neighbors can be determined when labels are known and labels can be determined when neighbors are given. Thus we give the following proposition:

\begin{proposition}\label{proposition:1}
Given a high homophily level graph $G$, conditional entropies $H(A|Y)$ and $H(Y|A)$ between its neighbor set $A$ and node label set $Y$ fulfill:

\begin{equation}
    0 \leq H(A|Y) \leq \epsilon \quad 0 \leq H(Y|A) \leq \epsilon,
\end{equation}

where $\epsilon\rightarrow0+$. 
\end{proposition}

Proposition.~\ref{proposition:1} implies the label of a node can be predicted or determined by the neighbor set of this node, which is similar to the assumption of GNNs. Therefore, the conditional entropies $H(A|Y)$ and $H(Y|A)$ tend to be 0. The proof of this proposition is provided in Appendix.~\ref{proof: proposition 1}. The prediction of GNN-based model $f$ can be represented as:

\begin{equation}
    \hat{Y} = f(X,A),
\end{equation}

which means model $f$ accepts $X$ and $A$ as inputs and outputs the predict label $\hat{Y}$. A well-trained GNN model is able to predict labels very certainly based on the node attributes and neighbors. Since entropy is a measurement of uncertainty, thus we hold:

\begin{proposition}\label{proposition:2}
For a well-trained GNN model $f^{*}$, the conditional entropy $H(Y|f^{*}(X,A))$ between the model output $f^{*}(X,A)$ and label $Y$ fulfill:

\begin{equation}
    0 \leq H(Y|f^{*}(X,A)) \leq \epsilon,
\end{equation}

where $\epsilon\rightarrow0+$. 
\end{proposition}

Proposition.~\ref{proposition:2} assuming a well-trained GNN model can perceive the distributions of attributes $X$ and neighbor $A$, thus learning label-related information and predicting labels accurately. The proof of Proposition.~\ref{proposition:2} is based on cross-entropy loss and is shown in Appendix.~\ref{proof: proposition 2}. Conversely, the target of Meta-attack is inducing the well-trained model $f^{*}$ to give false predictions by removing edges, i.e. perturbing the distribution of neighbor set $A$. After perturbing, $f^{*}$ predicts labels uncertainly, thus we have the following lemma:

\begin{lemma}\label{lemma:1}
    After the attack, the perturbed neighbor set $A^{'}$ meets inequality:
    
    \begin{equation}
        H(Y|X,A) < H(Y|X,A^{'})
    \end{equation}
\end{lemma}

Lemma.\ref{lemma:1} indicates labels can not be predicted or determined via the distributions of $X$ and $A^{'}$. Therefore, the well-trained model $f^{*}$ learns label irrelevance information from distributions and suffers a deterioration performance. The proof of Lemma.\ref{lemma:1} can be found in Appendix.~\ref{proof: lemma 1}.

To against the attack and perturbation, we need to minimize $H(Y|X,A^{'})$ thus the model can learn proper information from the distributions. However, for unsupervised models such as GCL, the label set $Y$ is unknown and results in the impossibility of calculation $H(Y|X,A^{'})$. 

Fortunately, we can utilize strong relevance between neighbor set $A$ and label set $Y$ shown in Proposition.~\ref{proposition:1} to minimize $H(Y|X,A^{'})$ indirectly. Specifically, we select neighbor nodes of each node by minimizing $tr(X^{T}LX)$ and thus minimize conditional entropy $H(X|A^{'})$. The meaning of minimizing $H(X|A^{'})$ is actually maximizing mutual information of $X, A^{'}, Y$:

\begin{lemma}\label{lemma:2}
    Minimizing $H(X|A^{'})$ is equal to maximize $I(X; A^{'}; Y)$.
\end{lemma}

Since minimizing $tr(X^{T}LX)$ is minimizing $H(X|A^{'})$, thus minimizing $tr(X^{T}LX)$ is maximizing mutual information $I(X; A^{'}; Y)$.

Based on Proposition.~\ref{proposition:1}, we further provide Lemma.~\ref{lemma:3}:

\begin{lemma}\label{lemma:3}
    Maximizing mutual information between label $Y$ and perturbed neighbor $A^{'}$: $I(Y; A^{'})$,  is equal to minimizing conditional entropy $H(Y|X,A^{'})$.
\end{lemma}

Lemma.~\ref{lemma:3} implies our target: minimizing $H(Y|X,A^{'})$ can be achieved by maximizing mutual information $I(Y; A^{'})$. Based on Lemma.~\ref{lemma:2} and Lemma.~\ref{lemma:3}, we further introduce Theorem.~\ref{theorem:1}:

\begin{theorem}\label{theorem:1}
    Minimizing conditional entropy $H(X|A^{'})$ is equal to minimizing conditional entropy $H(Y|X,A^{'})$.
\end{theorem}

Proof and more details about the above lemmas and theorem can be found in Appendix.~\ref{proof: lemma 2}, ~\ref{proof: lemma 3}, ~\ref{proof: theorem 1}.

Theorem.~\ref{theorem:1} shows the target of minimizing $tr(X^{T}LX)$ is actually minimizing conditional entropy $H(Y|X,A^{'})$, which is conversely to the attack. In other words, minimizing $tr(X^{T}LX)$ aims at obtaining a clean graph and thus defencing the attack.
