\section{Conclusion}
In this paper, we investigate the adversarial robustness of the GCL model in the face of graph structural attacks. This research proposes a novel homophily-driven, learnable sanitation view that enhances the GCL model's robustness by automatically eliminating potential malicious edges in the augmentation view, which is based on the assumption that an attacker would aim to disrupt the homophily degree and the mutual information of the clean graph. To this end, we choose the objective as the weighted sum of the infoNCE loss with the graph homophily $\delta_{x}$ to jointly optimize the parameters in the sanitation view and GNN encoder. The Gumbel-Softmax re-parametrization technique is employed to overcome the non-differentiable mapping issue during the sampling phase, while the parameters in the sanitation view are optimized via projection gradient descent. Besides, we novelly craft a pseudo normalized cut loss to easily determine the best choice of the hyperparameter $\eta$ without avoiding the unsupervised setting of the GCL framework during training. Extensive experiments demonstrate that our method can prominently boost the robustness of the GCL model. 
%Finally, our work broadens the horizon to explore the robustness of the GCL model and we leave the robust GCL model on graph classification in future work.      










































