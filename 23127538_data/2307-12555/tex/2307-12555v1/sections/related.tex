\section{Related Works}
\label{sec-related}
\subsection{Graph Structural Attack}
Graph-based machine learning models have been shown to be vulnerable to structural attacks. Nettack~\cite{Nettack} was the first targeted attack on GNNs that manipulated both on node attribute matrix and adjacency matrix. Mettack~\cite{Mettack} formulated the global structural poisoning attacks on GNNs as a bi-level optimization problem and leveraged a meta-learning framework to solve it. BinarizedAttack~\cite{BinarizedAttack} simplified graph poisoning attacks against the graph-based anomaly detection to a one-level optimization problem and optimize it by mimicking the training of the binary neural network. HRAT~\cite{HRAT} proposed a heuristic optimization model integrated with reinforcement learning to optimize the structural attacks against Android Malware Detection. CLGA~\cite{CLGA} deployed GCA~\cite{GCA} as the surrogate model and formulated graph structural attacks as a bi-level optimization problem to degenerate the performance of GCL models through poisoning. In this paper, we choose two typical graph structural attacks Mettack and CLGA as our graph attackers to simulate real-world attacking scenarios. 

\subsection{Graph Contrastive Learning}
Contrastive learning is a widely-used deep learning model that originated from SimCLR~\cite{SimCLR}, a simple self-supervised contrastive framework for learning useful representations for image data. SimCLR introduces the infoNCE loss to approximate the mutual information between latent representations from different augmentation views, such as randomly cropping and resizing, rotation, Gaussian blurring and color distortion. GRACE~\cite{GRACE} extended the SimCLR framework to graph data by generating augmentation views through random link removal and feature masking. Later, GCA~\cite{GCA} prevents the removal of the important links during the stochastic augmentations by designing several link removal mechanisms based on degree centrality, eigenvector centrality and PageRank centrality. ARIEL~\cite{ARIEL} introduced an adversarial view via PGD attack and an information regularization penalty to stabilize training. SPAN~\cite{SPAN} explored spectrum invariance during augmentation views and generated augmentation views by maximizing and minimizing the spectral change. MVGRL~\cite{MVGRL} utilized a local-global contrastive loss to measure the agreement between
the neighbor nodes and graph diffusion. DGI~\cite{DGI} generated augmentation views by corrupting the original graph and contrasting the node embeddings between the original graph and the corrupted graphs. Finally, BGRL~\cite{BGRL} introduced bootstrapped graph latent training by predicting alternative augmentations of the input without contrasting with negative samples.    

%\subsection{Graph Sanitation}
%GASOLINE~\cite{GASOLINE} first proposed the concept of graph sanitation, which addresses the problem of improving the quality of a given graph for a graph mining task. To tackle this problem, the author proposed a bi-level graph structural learning framework that sanitized the noisy graph for better semi-supervised node classification performance via deploying the GNN as its surrogate model. Later, FocusedCleaner~\cite{FocusedCleaner} further extended the graph sanitation problem to the graph security field and proposed a poisoned graph sanitation framework via jointly training a bi-level structural learning module with a victim node detection module to enhance the robustness of GNN. However, these graph sanitation algorithms are specially crafted for the semi-supervised node classification task and are not suitable for the unsupervised GCL. To boost the robustness of the GCL models, we introduce a homophily-preserving learnable sanitation view to scholastically produce more sanitized graph samples during training and thus improve the quality of the node embeddings under various attacking scenarios. 




































