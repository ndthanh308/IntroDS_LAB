\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsthm}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

%newly added packages
\usepackage{wrapfig}
\usepackage{bbm}
\usepackage{array, multirow}
\usepackage{diagbox}
\usepackage{caption}
\usepackage{etoolbox}
\usepackage{blindtext}
\usepackage{subcaption}
\usepackage{algorithmic}
\usepackage{wrapfig}
\usepackage{url}
\usepackage{soul}
\usepackage{booktabs}
\usepackage{bbm}
\usepackage[ruled,vlined]{algorithm2e}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\Tr}{Tr}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}



\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Homophily-Driven Sanitation View for
Robust Graph Contrastive Learning}
%\thanks{Identify applicable funding agency here. If none, delete this.}
%}

\author{\IEEEauthorblockN{Yulin Zhu\IEEEauthorrefmark{1}, Xing Ai\IEEEauthorrefmark{1}, Yevgeniy Vorobeychik\IEEEauthorrefmark{2}, Kai Zhou\IEEEauthorrefmark{1}}
\IEEEauthorblockA{yulin.zhu@polyu.edu.hk, xing96.ai@connect.polyu.hk, yvorobeychik@wustl.edu, kaizhou@polyu.edu.hk}
\IEEEauthorblockA{\IEEEauthorrefmark{1}\textit{Department of Computing}, \textit{The Hong Kong Polytechnic University}, HKSAR}
\IEEEauthorblockA{\IEEEauthorrefmark{2}\textit{McKelvey School of Engineering}, \textit{Washington University in Saint Louis}, St. Louis, USA}}

\maketitle
\pagestyle{plain}

\begin{abstract}
    We investigate adversarial robustness of unsupervised Graph Contrastive Learning (GCL) against structural attacks. First, we provide a comprehensive empirical and theoretical analysis of existing attacks, revealing how and why they downgrade the performance of GCL.  Inspired by our analytic results, we present a robust GCL framework that 
    integrates a homophily-driven sanitation view, which can be learned jointly with contrastive learning. 
    A key challenge this poses, however, is the non-differentiable nature of the sanitation objective.
    To address this challenge, we propose a series of techniques to enable gradient-based end-to-end robust GCL. Moreover, we develop a fully unsupervised hyperparameter tuning method which, unlike prior approaches, does not require knowledge of node labels.
    %to tune hyperparameters without the need for node labels in downstream tasks (in contrast to past approaches), a vital ingredient in our approach. 
    We conduct extensive experiments to evaluate the performance of our proposed model, GCHS (Graph Contrastive Learning with Homophily-driven Sanitation View), against two state of the art structural attacks on GCL.  Our results demonstrate that GCHS  consistently outperforms all state of the art baselines in terms of the quality of generated node embeddings as well as  performance on two important downstream tasks. 
    %Overall, our work makes a significant contribution to unsupervised graph representation learning in adversarial environments.
    %Previous literature addresses this problem by training robust models via either adversarial training or leveraging graph properties in the spectrum domain. However, these methods still cannot eliminate the malicious influences of the inter-class edges injected by the graph attacker and highly depends on the mechanism of the adversarial example generation. Inspired by the relationship between graph homophily and graph structural attacks, we propose a robust graph contrastive learning with a homophily-driven learnable sanitation view parametrized by the edge-dropping probability vector, which can be optimized in an end-to-end manner. To tackle the indifferentiation of the training phase, we relax the indifferentiable mapping in the sanitation view with the Gumbel-Softmax re-parametrization strategy and utilize the projection gradient descent to update the parameters. Moreover, to tune the hyperparameters without querying the node labels, we design a pseudo normalized cut loss as the metric to fine-tune the hyperparameter in the loss function. Extensive experiments demonstrate that our proposed method outperforms other baselines on the robust performance of semi-supervised node classification and unsupervised graph clustering tasks.  
\end{abstract}

\begin{IEEEkeywords}
Graph contrastive learning, Graph sanitation, Adversarial robustness
\end{IEEEkeywords}

\input{sections/intro}
\input{sections/related}
%\input{sections/problem}
%\input{sections/framework}
\input{sections/methods}
\input{sections/experiments}
\input{sections/conclusion}

%\begin{appendices}
%    \input{sections/theory}
%    \input{sections/appendix}
%\end{appendices}

\clearpage
\bibliographystyle{ieeetr}
\bibliography{citation}

\end{document}
