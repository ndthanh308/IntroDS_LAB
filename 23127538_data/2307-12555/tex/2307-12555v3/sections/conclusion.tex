\section{Conclusion}
In this paper, we investigate the adversarial robustness of the GCL against the graph structural attacks from an information-theoretical perspective. The vulnerability analysis offers the clue that apart from the conventional observation that structural attacks tend to diminish the graph homophily, these attacks also degenerate the mutual information estimation between the graph and its representations, which are the cornerstone of the powerful representation learning of GCL. Based on our findings, we propose \textbf{GCIR} with a learnable sanitation view to restore the diminished mutual information and graph homophily after attacks and thus achieve adversarial robustness. The whole framework is trained in an end-to-end learning manner. Besides, we novelly craft an unsupervised tuning strategy to easily determine the best choice of the GCL's vital hyperparameter without avoiding the fully unsupervised setting during the training of GCL. Extensive experiments demonstrate that our method can prominently boost the robustness of the GCL model.   

\section*{Acknowledgement}
This research was partly supported by the Hong Kong RGC Project (No. PolyU25210821).









































