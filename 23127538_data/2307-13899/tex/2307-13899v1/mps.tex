\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
% \usepackage{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage{graphbox}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows.meta}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[export]{adjustbox}
\usepackage{tabularray}
\usepackage{fnpara}

% Attempt to make hyperref and algorithmic work together better:
% \newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\TODO}[1]{}
\renewcommand{\TODO}[1]{{\color{cyan} [TODO: {#1}]}}
\newcommand{\WIP}[1]{}
\renewcommand{\WIP}[1]{{\color{magenta} [WIP: {#1}]}}
\definecolor{midblue}{rgb}{0,0.11372549,0.258823529}
\newcommand{\argmax}{\mathop{\rm argmax}\limits}
\newcommand{\argmin}{\mathop{\rm argmin}\limits}

% \theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

\title{Regularizing Neural Networks \\with Meta-Learning Generative Models}

% \author{%
%   Shin'ya Yamaguchi\\
%   NTT, Kyoto University\\
%   \texttt{shinya.yamaguchi@ntt.com} \\
%   % examples of more authors
%   \AND
%   Daiki Chijiwa \\
%   NTT\\
%   % \texttt{daiki.chijiwa@ntt.com} \\
%   \And
%   Sekitoshi Kanai \\
%   NTT \\
%   % \texttt{sekitoshi.kanai@ntt.com} \\
%   \And
%   Atsutoshi Kumagai \\
%   % \texttt{atsutoshi.kumagai@ntt.com} \\
%   NTT \\
%   \And
%   Hisashi Kashima \\
%   Kyoto University \\
%   % \texttt{kashima@i.kyoto-u.ac.jp} \\
% }

\author{
Shin'ya Yamaguchi\textsuperscript{\dag,\ddag}\thanks{Corresponding author. Email: \texttt{shinya.yamaguchi@ntt.com}}~~
Daiki Chijiwa\textsuperscript{\dag}~~
Sekitoshi Kanai\textsuperscript{\dag}~~\\
\textbf{Atsutoshi Kumagai\textsuperscript{\dag}}~~
\textbf{Hisashi Kashima\textsuperscript{\ddag}} \\
\textsuperscript{\dag}NTT\quad\textsuperscript{\ddag}Kyoto University
}

\begin{document}

\maketitle

\begin{abstract}
    This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called \textit{meta generative regularization} (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR can avoid the performance degradation of na\"ive generative data augmentation and boost the baselines. Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines.
\end{abstract}

\section{Introduction}\label{sec:intro}
While deep neural networks achieved impressive performance on various machine learning tasks, training them still requires a large amount of labeled training data in supervised learning.
The labeled datasets are expensive when a few experts can annotate the data, e.g., medical imaging.
In such scenarios, \textit{generative data augmentation} is a promising option for improving the performance of models.
Generative data augmentation basically adds pairs of synthetic samples from conditional generative models and their target labels into real training datasets.
The expectations of generative data augmentation are that the synthetic samples interpolate missing data points and perform as oversampling for classes with less real training samples~\cite{Shorten_JBigData19_survey_on_data_augmentation}.
This simple method can improve the performance of several tasks with less diversity of inputs such as medical imaging tasks~\cite{Calimeri_ICANN17_biomedical_data_aug_using_gans,Frid_NC18_gan_aug_liver_lesion,Frid_ISBI18_gan_aug_liver_lesion,Waheed_IEEEAccess20_covidgan}.

However, in general cases that require the recognition of more diverse inputs (e.g., CIFAR datasets~\cite{krizhevsky09_cifar10}), generative data augmentation degrades rather than improves the test accuracy~\cite{shmelkov_ECCV18_howgoodismygan}. 
Previous studies have indicated that this can be caused by the low quality of synthetic samples in terms of the diversity and fidelity~\cite{shmelkov_ECCV18_howgoodismygan,yamaguchi_AAAI20_effective_data_augmentation_with_GANs}.
If this hypothesis is correct, we can expect high-quality generative models (e.g., StyleGAN2-ADA~\cite{karras_NeurIPS20_training_GANs_with_limited_data}) to resolve the problem; existing generative data augmentation methods adopt earlier generative models e.g., ACGAN~\cite{odena_ICML17_acgan} and SNGAN~\cite{miyato_SNGAN_iclr18}.
Contrary to the expectation, this is not the case.
We observed that generative data augmentation fails to improve models even when using a high-quality StyleGAN2-ADA (Figure~\ref{fig:top}).
Although the samples partially appear to be real to humans, they are not yet sufficient to train classifiers in existing generative data augmentation methods.
This paper investigates methodologies for effectively extracting useful information from generative models to improve model performance.\looseness=-1

% Figure environment removed

We address this problem based on the following hypotheses.
First, \textit{synthetic samples are actually informative but do not perfectly represent class categories in real data}.
This is based on a finding by Brock et~al.~\cite{brock2018biggan} called ``class leakage," where a class conditional synthetic sample contains attributes of other classes.
For example, they observed failure samples including an image of ``tennis ball" containing attributes of ``dogs" (Figure 4(d) of~\cite{brock2018biggan}).
These class leaked samples do not perfectly represent the class categories in the real dataset.
If we use such class leaked samples for updating classifiers, the samples can distort the decision boundaries, as shown in Figure~\ref{fig:gda_problem}.
Second, \textit{regardless of the quality, the generative models originally contain uninformative samples to solve the tasks.}
This is simply because the generative models are not explicitly optimized to generate informative samples for learning the conditional distribution \(p(y|x)\); they are optimized only for learning the data distribution \(p(x)\).
To maximize the gain from synthetic samples, we should select appropriate samples for training tasks.

In this paper, we present a novel regularization method called \textit{meta generative regularization} (MGR).
Based on the above hypotheses, MGR is composed of two techniques for improving generative data augmentation: \textit{pseudo consistency regularization} (PCR) and \textit{meta pseudo sampling} (MPS).
PCR is a regularization term using synthetic samples in training objectives for classifiers. 
Instead of supervised learning with negative log-likelihood \(-\log p(y|x)\), i.e., cross-entropy, on synthetic samples, we regularize the feature extractor to avoid the distortions on decision boundaries.
That is, PCR leverages synthetic samples only for learning feature spaces.
PCR penalizes the feature extractors by minimizing the gap between variations of a synthetic sample, which is inspired by consistency regularization in semi-supervised learning~\cite{bachman_NIPS14_learning_with_pseudo_ensembles,xie_NIPS20_UDA,sohn_NIPS20_fixmatch}.
MPS corresponds to the second hypothesis and its objective is to select useful samples for training tasks by dynamically searching optimal latent vectors of the generative models.
Therefore, we formalize MPS as a bilevel optimization framework of a classifier and a finder that is a neural network for searching latent vectors.
Specifically, this framework updates the finder through meta-learning to reduce the validation loss and then updates the classifier to reduce the PCR loss (Figure~\ref{fig:top_idea}).
By combining PCR and MPS, we can improve the performance even when the existing generative data augmentation degrades the performance (Figure~\ref{fig:top}).

We conducted experiments with multiple vision datasets and observed that MGR can stably improve baselines on various settings by up to 7 percentage points of test accuracy.
Further, through the visualization studies, we confirmed that MGR utilizes the information in synthetic samples to learn feature representations through PCR and obtain meaningful samples through MPS.

% Figure environment removed

\section{Preliminary}\label{sec:preliminary}
\subsection{Problem Setting}\label{sec:problem_setting}
We consider a classification problem in which we train a neural network model \(f_{\theta} :\mathcal{X} \to \mathcal{Y}\) on a labeled dataset \(\mathcal{D}=\{(x^i,y^i) \in \mathcal{X}\times\mathcal{Y}\}^{N}_{i=1}\), where \(\mathcal{X}\) and \(\mathcal{Y}\) are the input and output label spaces, respectively.
Here, we can use a generative model \(G_\Phi:\mathcal{Z}\times\mathcal{Y} \to \mathcal{X}\), which is trained on \(\mathcal{D}\).
We assume that \(G_\Phi\) generates samples from a latent vector \(z \in \mathcal{Z}\) and conditions on samples with a categorical label \(y \in \mathcal{Y}\), where \(z\) is sampled from a standard Gaussian distribution \(p(z)=\mathcal{N}(0,I)\) and \(y\) is uniformly sampled from \(\mathcal{Y}\)\footnote{Although we basically use conditional \(G_\Phi\) for comparing our method and generative data augmentation, our method can be used with unconditional \(G_\Phi\) (see Sec.~\ref{sec:eval_generative_model}).}.
We refer to the classification task on \(\mathcal{D}\) as the main task, and \(f_{\theta}\) as the main model.
\(f_{\theta}\) is defined by a composition of a feature extractor \(g_{\psi}\) and a classifier \(h_{\omega}\), i.e., \(f_{\theta} = h_\omega \circ g_\psi\) and \(\theta = [\psi,\omega]\).
To validate \(f_\theta\), we can use a small validation dataset \(\mathcal{D}_\text{val}=\{(x^i_\text{val}, y^i_\text{val}) \in \mathcal{X}\times\mathcal{Y}\}^{N_\text{val}}_{i=1}\), which has no intersection with \(\mathcal{D}\) (i.e., \(\mathcal{D}\cap\mathcal{D}_\text{val}=\emptyset\)).
\subsection{Generative Data Augmentation}\label{sec:generative_data_augmentation}
A typical generative data augmentation trains a main model \(f_{\theta}\) with both real data and synthetic data from the generative models~\cite{DAGAN_Antoniou}.
We first generate synthetic samples to be utilized as additional training data for the main task.
Most previous studies on generative data augmentation~\cite{DAGAN_Antoniou,tran_NIPS17_bayesian_data_augmentation,yamaguchi_AAAI20_effective_data_augmentation_with_GANs} adopt conditional generative models for \(G_\Phi\), and generate a pseudo dataset \(\mathcal{D}_\mathrm{p}\) as 
\begin{eqnarray}
    \mathcal{D}_\mathrm{p} = \{(x^i_\mathrm{p}, y^i_\mathrm{p})~|~x^i_\mathrm{p} = G_\Phi(z^i,y^i_\mathrm{p})\}^{N_{\mathrm{p}}}_{i=1},
\end{eqnarray}
where \(z^i\) is sampled from a prior distribution \(p(z)\), and \(y^i_\mathrm{p}\) is uniformly sampled from \(\mathcal{Y}\).
Subsequently, \(f_\theta\) is trained on both of \(\mathcal{D}\) and \(\mathcal{D}_\mathrm{p}\) using the following objective function.
\begin{eqnarray}
    % \min_\theta  {\mathbb{E}_{(x,y)\in \mathcal{D}}}\mathcal{L}(f_\theta(x),y)+\lambda{\mathbb{E}_{(x_\mathrm{p},y_\mathrm{p})\in \mathcal{D}_\mathrm{p}}}\mathcal{L}_{p}(f_\theta(x_\mathrm{p}),y_\mathrm{p}),\!\!\!
     & \min\limits_\theta &  \mathcal{L}(\theta)+\lambda\mathcal{L}_{p}(\theta),\label{eq:gda}\\
    \mathcal{L}(\theta) &=& {\mathbb{E}_{(x,y)\in \mathcal{D}}} \ell(f_\theta(x),y),\label{eq:gda_l_sup}\\
    \mathcal{L}_\mathrm{p}(\theta) &=& {\mathbb{E}_{(x_\mathrm{p},y_\mathrm{p})\in \mathcal{D}_\mathrm{p}}} \ell_{\mathrm{p}}(f_\theta(x_\mathrm{p}),y_\mathrm{p}),\label{eq:gda_l_p}
\end{eqnarray}
where \(\ell\) is a loss function of the main task (e.g., cross-entropy), \(\ell_\mathrm{p}\) is a loss function for the synthetic samples, and \(\lambda\) is a hyperparameter for balancing \(\mathcal{L}\) and \(\mathcal{L}_\mathrm{p}\).
In previous works, \(\ell_\mathrm{p}\) is often set the same as \(\ell\).
Although optimizing Eq.~(\ref{eq:gda}) with respect to \(\theta\)  is expected to boost the test performance by interpolating or oversampling conditional samples~\cite{Shorten_JBigData19_survey_on_data_augmentation}, its na\"ive application degrades the performance of \(f_\theta\) on general settings~\cite{shmelkov_ECCV18_howgoodismygan}.
In this paper, we explore methods to resolve the degradation of generative data augmentation and maximize the performance gain from \(\mathcal{D}_\mathrm{p}\).

\section{Proposed Method}\label{sec:method}
In this section, we describe our proposed method, MGR.
The training using MGR is formalized as alternating optimization of a main model and finder network for searching latent vectors of \(G_\Phi\), as shown in Figure~\ref{fig:top_idea}.
To maximize the gain from synthetic samples, MGR regularizes a feature extractor \(g_\psi\) of \(f_\theta\) using PCR by effectively sampling useful samples for the generalization from \(G_\Phi\) using MPS.
We show the overall algorithm of MGR in Appendix~\ref{app:algorithm}.

\subsection{Pseudo Consistency Regularization}\label{sec:pcr}
As discussed in Secion~\ref{sec:intro}, we hypothesize that the synthetic samples do not perfectly represent class categories, and training classifiers using them can distort the decision boundaries.
This is because \(y_\mathrm{p}\) is not reliable due to \(\mathcal{D}_\mathrm{p}\) can contain class leaked samples~\cite{brock2018biggan}.
To avoid the degradation caused by the distortion, we propose utilizing \(x_\mathrm{p}\) to regularize only the feature extractor \(g_{\psi}\) of \(f_\theta\) by discarding a conditional label \(y_\mathrm{p}\).
For the regularization, we borrow the concept of consistency regularization, which was originally proposed for semi-supervised learning (SSL)~\cite{bachman_NIPS14_learning_with_pseudo_ensembles,xie_NIPS20_UDA,sohn_NIPS20_fixmatch}.
These SSL methods were designed to minimize the dissimilarity between the two logits (i.e., the output of \(h_\omega\)) of strongly and weakly transformed unlabeled samples to obtain robust representations.
By following this concept, the PCR loss is formalized as
\begin{eqnarray}
\ell_\text{PCR}(x_\mathrm{p};\psi) =  \|g_\psi(T(x_\mathrm{p})) - g_\psi(x_\mathrm{p})\|^2_2,
\end{eqnarray}
where \(T\) is a strong transformation such as RandAugment~\cite{cubuk_CVPR20_randaugment}, which is similar to the one used in UDA~\cite{xie_NIPS20_UDA} for SSL.
The difference between PCR and UDA is that PCR penalizes only \(g_\psi\), whereas UDA trains the entire \(f_\theta=h_\omega\circ g_\psi\).
\(\ell_\text{PCR}\) can be expected to help \(g_\psi\) learns features of inter-cluster interpolated by \(x_\mathrm{p}\) without distorting the decision boundaries.
Using \(\ell_\text{PCR}\), we rewrite Eq.~(\ref{eq:gda_l_p}) as
\begin{eqnarray}\label{eq:gda_pcr}
    \mathcal{L}_\text{PCR}(\theta) = {\mathbb{E}_{x_\mathrm{p}\in \mathcal{D}_\mathrm{p}}} \ell_\text{PCR}(x_\mathrm{p};\psi).
\end{eqnarray}

\subsection{Meta Pseudo Sampling}\label{sec:mps}
Most generative data augmentation methods generate a synthetic sample \(x_\mathrm{p}\) from \(G_\Phi\) with a randomly sampled latent vector \(z\).
This is not the best option as \(G_\Phi\) is not optimized for generating useful samples to train \(f_\theta\) in predicting the conditional distribution \(p(y|x)\); it is originally optimized to replicate \(p(x|y)\) or \(p(x)\).
The main concept of MPS is to directly determine useful samples for training \(f_\theta\) by optimizing an additional neural network called a \textit{finder} \(F_\phi:\mathcal{Z}\to\mathcal{Z}\).
\(F_\phi\) takes a latent vector \(z\sim p(z)\) as input and outputs a vector of the same dimension as \(z\).
By using \(F_\phi\), we generate a synthetic sample as \(x_\mathrm{p}=G_\Phi(F_\phi(z),y)\).
The role of \(F_\phi\) is to find the optimal latent vectors that improve the training of \(f_\theta\) through \(x_\mathrm{p}\).
Although we can consider optimizing \(G_\Phi\) instead of \(F_\phi\), we observed that optimizing \(G_\Phi\) is unstable and causes the performance degradations of \(f_\theta\) (Section~\ref{sec:eval_mps}).\looseness=-1

The useful samples for generalization should reduce the validation loss of \(f_\theta\) by using them for optimization.
Based on this simple suggestion, we formalize the following bilevel optimization problem for \(F_\phi\).
\begin{eqnarray}\label{eq:mps_bopt}
    &\min\limits_\phi \mathcal{L}_\text{val}(\theta^*) = \mathbb{E}_{(x_\text{val}, y_\text{val})\in\mathcal{D}_\text{val}}\ell(f_{\theta^*}(x_\text{val}),y_\text{val})\nonumber\\
    \text{subject to} & \theta^* = \argmin_\theta \mathcal{L}(\theta)+\lambda\mathcal{L}_\text{PCR}(\theta, \phi).
\end{eqnarray}
Note that the finder parameter \(\phi\) is added to the arguments of \(\mathcal{L}_\text{PCR}\).
We can optimize \(F_\phi\) with a standard gradient descent algorithm because \(F_\phi\), \(G_\Phi\), and \(f_\theta\) are all composed of differentiable functions as well as existing meta-learning methods such as MAML~\cite{Finn_ICML17_maml} and DARTS~\cite{Liu_ICLR18_darts}.
We approximate \(\theta^*\) because the exact computation of the gradient \(\nabla_\phi\mathcal{L}_\text{val}(\theta^*)\) is expensive~\cite{Finn_ICML17_maml,Liu_ICLR18_darts}:
\begin{eqnarray}
    \theta^* \approx \theta^\prime = \theta - \eta\nabla_\theta(\mathcal{L}(\theta) + \lambda\mathcal{L}_\text{PCR}(\theta,\phi)),
\end{eqnarray}
where \(\eta\) is an inner step size.
Thus, we update \(F_\phi\) by using \(\theta^\prime\) that is updated for a single step and then alternately update \(\theta\) by applying Eq.~(\ref{eq:gda_pcr}) with \(x_\mathrm{p}\) generated from the updated \(F_\phi\).
The overall optimization flow is shown in Figure~\ref{fig:mps}.

\paragraph*{Approximating gradients with respect to \(\phi\).}
Computing \(\nabla_\phi\mathcal{L}_\text{val}(\theta^\prime)\) requires the product computation including second-order gradients: \(\nabla^2_{\phi,\theta}\mathcal{L}_\text{PCR}(\theta,\phi)\nabla_{\theta^\prime}\mathcal{L}_\text{val}(\theta^\prime)\).
This causes a computation complexity of \(\mathcal{O}((|\Phi|+|\phi|)|\theta|)\).
To avoid this computation, we approximate the term using the finite difference method~\cite{Liu_ICLR18_darts} as 
\begin{eqnarray}\label{eq:sc-grad_approx}    \nabla^2_{\phi,\theta}\mathcal{L}_\text{PCR}(\theta,\phi)\nabla_{\theta^\prime}\mathcal{L}_\text{val}(\theta^\prime) \approx \frac{\nabla_{\phi}\mathcal{L}_\text{PCR}(\theta^+,\phi)-\nabla_{\phi}\mathcal{L}_\text{PCR}(\theta^-,\phi)}{2\varepsilon},
\end{eqnarray}
where \(\theta^{\pm}\) is \(\theta\) updated by \(\theta\pm\eta\nabla_{\theta}\mathcal{L}_\text{val}(\theta)\).
\(\varepsilon\) is defined by \(\frac{\text{const.}}{\|\nabla_{\theta}\mathcal{L}_\text{val}(\theta)\|_2}\).
We used \(0.01\) of the constant for \(\varepsilon\) based on~\cite{Liu_ICLR18_darts}.
This approximation reduces the computation complexity to \(\mathcal{O}(|\Phi|+|\phi|+|\theta|)\).
We confirm the speedup by Eq.~(\ref{eq:sc-grad_approx}) in Appendix~\ref{app:mps_approx}.

\paragraph*{Techniques for improving finder}
We introduce two techniques for improving the training of \(F_\phi\) in terms of the architectures and a penalty term for the outputs.

While arbitrary neural architectures can be used for the implementation of \(F_\phi\), we observed that the following residual architecture produces better results.
\begin{eqnarray}\label{eq:residual_finder}
    F_\phi(z) := z + \tanh(\text{MLP}_\phi(z)),
\end{eqnarray}
where \(\text{MLP}\) is multi layer perceptron.

To ensure that \(F_\phi(z)\) does not diverge too far from the distribution \(p(z)\), we add a Kullbackâ€“Leibler divergence term \(D_\text{KL}(p_{\phi}(z)\|p(z))\), where \(p_\phi(z)\) is the distribution of \(F_\phi(z)\) into Eq.~(\ref{eq:mps_bopt}).
When \(p(z)\) follows the standard Gaussian \(\mathcal{N}(0,I)\), \(D_\text{KL}(p_{\phi}(z)\|p(z))\) can be computed by
\begin{eqnarray}\label{eq:kl_reg}
    D_\text{KL}(p_{\phi}(z)\|p(z)) = -\frac{1}{2}(1 + \log{\sigma_\phi} - \mu_\phi^2 - \sigma_\phi),
\end{eqnarray}
where \(\mu_\phi\) and \(\sigma_\phi\) is the mean and variance of \(\{F_\phi(z^i)\}^{N_\mathrm{p}}_{i=1}\).
In Appendix~\ref{app:f_ablation}, we discuss the effects of design choice based on the ablation study.

\section{Experiments}\label{sec:experiment}
In this section, we evaluate our MGR (the combination of PCR and MPS with the experiments on multiple image classification datasets.
We mainly aim to answer three research questions with the experiments:
(1) Can PCR avoid the negative effects of \(x_\mathrm{p}\) in existing methods and improve the performance of \(f_\theta\)?
(2) Can MPS find better samples for training than that by uniform sampling?
(3) How practical is the performance of MGR?
We compare MGR with baselines including conventional generative data augmentation and its variants in terms of test performance (Sec.~\ref{sec:eval_multiple_dataset}~and~\ref{sec:eval_smaller_dataset}).
Furthermore, we conduct a comprehensive analysis of PCR and MPS such as the visualization of trained feature spaces (Sec.~\ref{sec:eval_feature_space}), quantitative/qualitative evaluations of the synthetic samples (Sec.~\ref{sec:eval_mps}), performance studies when changing generative models (Sec.~\ref{sec:eval_generative_model}), and comparison to data augmentation methods such as TrivialAugment~\cite{Muller_ICCV21_trivialaugment} (Sec.~\ref{sec:eval_data_augmentation}).

\subsection{Settings}\label{sec:setting}
\paragraph*{Baselines.}
We compare our method with the following baselines.
\textbf{Base Model}: training \(f_\theta\) with only \(\mathcal{D}\).
\textbf{Generative Data Augmentation (GDA)}: training \(f_\theta\) with \(\mathcal{D}\) and \(G_\Phi\) using Eq.~(\ref{eq:gda}).
\textbf{GDA+MH}: training \(f_\theta\) with \(\mathcal{D}\) and \(G_\Phi\) by decoupling the heads into \(h_\omega\) for \(\mathcal{D}\) and \(h_{\omega_\mathrm{p}}\) for \(\mathcal{D}_\mathrm{p}\). MH denotes multi-head. This is a na\"ive approach to avoid the negative effect of \(x_\mathrm{p}\) on \(h_\omega\) by not passing \(x_\mathrm{p}\) through \(h_\omega\). GDA+MH optimizes the parameters as $\argmin\limits_\theta\mathcal{L}(f_\theta(x), y) + \lambda\mathcal{L}(h_{\omega_\mathrm{p}}(g_\psi(x_\mathrm{p})),y_\mathrm{p})$.
\textbf{GDA+SSL}: training \(f_\theta\) with \(\mathcal{D}\) and \(G_\Phi\) by applying an SSL loss for \(\mathcal{D}_\mathrm{p}\) that utilizes the output of \(h_\omega\) unlike PCR.
This method was originally proposed by Yamaguchi et~al.~\cite{Yamaguchi_arXiv22_PSSL} for transfer learning, but we note that \(G_\Phi\) was trained on the main task dataset \(\mathcal{D}\) in contrast to the original paper.
By following~\cite{Yamaguchi_arXiv22_PSSL}, we used UDA~\cite{xie_NIPS20_UDA} as the SSL loss and the same strong transformation \(T\) as of MGR for the consistency regularization.
 
\paragraph*{Datasets.}
We used six image datasets for classification tasks in various domains: Cars~\cite{krause_3DRR2013_stanford_cars}, Aircraft~\cite{maji_13_aircraft}, Birds~\cite{Welinder_10_cub2002011}, DTD~\cite{cimpoi_CVPR14_DTD}, Flowers~\cite{Nilsback_08_flowers}, and Pets~\cite{parkhi_CVPR12_oxford_pets}.
Furthermore, to evaluate smaller dataset cases, we used subsets of Cars that were reduced by \(\{10,25,50,75\}\%\) in volume; we reduced them by random sampling on a fixed random seed.
We randomly split a dataset into \(9:1\) and used the former as \(\mathcal{D}\) and the latter as \(\mathcal{D}_\text{val}\).

\paragraph*{Architectures.}
We used ResNet-18~\cite{he_resnet} as \(f_\theta\) and generators of conditional StyleGAN2-ADA for \(256\times256\) images~\cite{brock_ICLR18_biggan} as \(G_\Phi\).
\(F_\phi\) was composed of a three-layer perceptron with a leaky-ReLU activation function.
We used the ImageNet pre-trained weights of ResNet-18 distributed by PyTorch.\footnote{https://github.com/pytorch/vision}
For StyleGAN2-ADA, we did not use pre-trained weights. 
We trained \(G_\Phi\) on each \(\mathcal{D}\) from scratch according to the default setting of the implementation of StyleGAN2-ADA.\footnote{https://github.com/NVlabs/stylegan2-ada}
Note that we used the same \(G_\Phi\) in the baselines and our proposed method.\looseness=-1

\paragraph*{Training.}
We trained \(f_\theta\) by the Nesterov momentum SGD for 200 epochs with a momentum of 0.9, and an initial learning rate of 0.01; we decayed the learning rate by 0.1 at 60, 120, and 160 epochs.
We trained \(F_\phi\) by the Adam optimizer for 200 epochs with a learning rate of \(1.0\times10^{-4}\).
We used mini-batch sizes of 64 for \(\mathcal{D}\) and 64 for \(\mathcal{D}_\mathrm{p}\).
The input samples were resized into a resolution of \(224\times224\); \(x_\mathrm{p}\) was resized by differentiable transformations. For synthetic samples from \(G_\Phi\) in PCR and GDA+SSL, the strong transformation \(T\) was RandAugment~\cite{cubuk_CVPR20_randaugment} by following~\cite{xie_NIPS20_UDA}, and it was implemented with differentiable transformations provided in Kornia~\cite{Riba_WACV20_kornia}.
We determined the hyperparameter \(\lambda\) by grid search among \([0.1,1.0]\) with a step size of \(0.1\) for each method by \(\mathcal{D}_\text{val}\).
To avoid the overfitting, we set the hyperparameters of MGR that are searched with only applying PCR i.e., we did not use meta-learning to choose them.
We used \(\lambda_\text{KL}\) of \(0.01\).
We selected the final model by checking the validation accuracy for each epoch.
We ran the experiments three times on a 24-core Intel Xeon CPU with an NVIDIA A100 GPU with 40GB VRAM and recorded average test accuracies with standard deviations evaluated on the final models.

\begin{table}[t]
    \centering
    \caption{
        Top-1 accuracy (\%) of ResNet18.
        \underline{Underlined scores} outperform that of Base Model, and \textbf{Bolded scores} are the best among the methods.
        }
    \begin{minipage}{0.54\columnwidth}
        \subcaption{Multiple Datasets}\label{tb:multiple_dataset}
        \resizebox{1.0\columnwidth}{!}{
        \begin{tabular}{lccccccccc}\toprule
            Method / Dataset & Cars & Aircraft & Birds & DTD & Flower & Pets  \\
          \midrule
            Base Model    &  85.80\(^{\pm\text{.10}}\) & 62.61\(^{\pm\text{.79}}\) &  72.24\(^{\pm\text{.32}}\) & 68.16\(^{\pm\text{.35}}\) & 94.18\(^{\pm\text{.08}}\) & 87.21\(^{\pm\text{.13}}\) \\
            GDA &  84.50\(^{\pm\text{.25}}\) & 61.29\(^{\pm\text{.05}}\) &  67.55\(^{\pm\text{.11}}\) & 67.68\(^{\pm\text{.37}}\) & 93.46\(^{\pm\text{.15}}\) & \underline{87.37}\(^{\pm\text{.21}}\) \\
            GDA+MH &  85.77\(^{\pm\text{.10}}\) & \underline{63.16}\(^{\pm\text{.15}}\) &  71.95\(^{\pm\text{.09}}\) & \underline{68.49}\(^{\pm\text{.21}}\) & 93.83\(^{\pm\text{.11}}\) & \underline{87.77}\(^{\pm\text{.10}}\) \\
            GDA+SSL &  85.75\(^{\pm\text{.21}}\) & 62.87\(^{\pm\text{.54}}\) &  71.28\(^{\pm\text{.42}}\) & \underline{68.49}\(^{\pm\text{.59}}\) & 93.66\(^{\pm\text{.08}}\) & 87.75\(^{\pm\text{.21}}\) \\
            \midrule
            GDA+MPS   &  85.28\(^{\pm\text{.05}}\) &  62.11\(^{\pm\text{.34}}\) & 72.25\(^{\pm\text{.13}}\) & \underline{68.87}\(^{\pm\text{.22}}\) & \underline{94.39}\(^{\pm\text{.14}}\) & \underline{87.92}\(^{\pm\text{.11}}\)\\
            PCR &  \underline{86.36}\(^{\pm\text{.08}}\) & \underline{64.43}\(^{\pm\text{.21}}\) &  \underline{73.69}\(^{\pm\text{.10}}\) & \underline{69.17}\(^{\pm\text{.18}}\) & \underline{94.66}\(^{\pm\text{.22}}\) & \underline{88.59}\(^{\pm\text{.44}}\)\\
            MGR (PCR+MPS) &  \underline{\bf 87.22}\(^{\pm\textbf{.15}}\) & \underline{\bf 65.11}\(^{\pm\textbf{.57}}\) &  \underline{\bf 74.24}\(^{\pm\text{.34}}\) & \underline{\bf 69.53}\(^{\pm\textbf{.28}}\) & \underline{\bf 95.42}\(^{\pm\textbf{.20}}\) & \underline{\bf 88.98}\(^{\pm\textbf{.01}}\) \\
            \bottomrule
        \end{tabular}
        }
        \vspace{-3mm}
    \end{minipage} 
    \begin{minipage}{0.44\columnwidth}
    \centering
        \subcaption{Small Datasets (Cars)}
        \label{tb:small_dataset}
        \resizebox{1.0\columnwidth}{!}{
        \begin{tabular}{lccccccc}\toprule
          Method / Dataset size & 10\% & 25\% & 50\% & 75\%  \\
          \midrule
            Base Model   &  20.11\(^{\pm\text{.03}}\) &49.33\(^{\pm\text{.54}}\) &  72.91\(^{\pm\text{.38}}\) & 81.68\(^{\pm\text{.18}}\)\\
            GDA &  18.91\(^{\pm\text{.54}}\) & 46.56\(^{\pm\text{.07}}\) &  68.81\(^{\pm\text{.52}}\) & 80.67\(^{\pm\text{.10}}\) \\
            GDA+MH &  18.40\(^{\pm\text{.93}}\) & 46.63\(^{\pm\text{.32}}\) &  71.51\(^{\pm\text{.10}}\) & 81.25\(^{\pm\text{.32}}\) \\
            GDA+SSL &  19.71\(^{\pm\text{.41}}\) & 47.80\(^{\pm\text{.30}}\) &  71.99\(^{\pm\text{.40}}\) & 81.55\(^{\pm\text{.38}}\)\\
            \midrule
            MGR &  \underline{\bf 23.49}\(^{\pm\textbf{.53}}\) & \underline{\bf 53.16}\(^{\pm\textbf{.32}}\) &  \underline{\bf 75.24}\(^{\pm\text{.21}}\) & \underline{\bf 83.13}\(^{\pm\textbf{.27}}\) \\
            \bottomrule
        \end{tabular}
        }
        \vspace{-3mm}
    \end{minipage}
 \end{table}

\subsection{Evaluation on Multiple Datasets}\label{sec:eval_multiple_dataset}
We confirm the efficacy of MGR across multiple datasets.
Table~\ref{tb:multiple_dataset} shows the top-1 accuracy scores of each method.
As reported in~\cite{shmelkov_ECCV18_howgoodismygan}, GDA degraded the base model on many datasets; it slightly improved the base model on only one dataset.
GDA+MH, which had decoupled classifier heads for GDA, exhibited a similar trend to GDA.
This indicates that simply decoupling the classifier heads is not a solution to the performance degradation caused by synthetic samples.
In contrast, our MGR stably and significantly outperformed the baselines and achieved the best results.
The ablation of MGR discarding PCR or MPS is listed in Table~\ref{tb:multiple_dataset}.
We confirm that both PCR and GDA+MPS improve GDA.
While GDA+SSL underperforms the base models, PCR outperforms the base models.
This indicates that using unsupervised loss alone is not sufficient to eliminate the negative effects of the synthetic samples and that discarding the classifier \(h_\omega\) from the regularization is important to obtain the positive effect.
MPS yields only a small performance gain when combined with GDA, but it significantly improves its performance when combined with PCR i.e., MGR.
This suggests that there is no room for performance improvements in GDA, and MPS can maximize the potential benefits of PCR.

\subsection{Evaluation on Small Datasets}\label{sec:eval_smaller_dataset}
A small dataset setting is one of the main motivations for utilizing generative data augmentation.
We evaluate the effectiveness of MGR on smaller datasets.
Table~\ref{tb:small_dataset} shows the performance when reducing the Cars dataset into a volume of \(\{10,25,50,75\}\%\).
Note that we trained \(G_\Phi\) on each reduced dataset, not on \(100\%\) of Cars.
In contrast to the cases of the full dataset (Table~\ref{tb:multiple_dataset}), no baseline methods outperformed the base model in this setting.
This is because \(G_\Phi\) trained on the small datasets generates low-quality samples with less reliability on the conditional label \(y_\mathrm{p}\) that are not appropriate in supervised learning.
On the other hand, MGR improved the baselines in large margins.
This indicates that, even when the synthetic samples are not sufficient to represent the class categories, our MGR can maximize the information obtained from the samples by utilizing them to regularize feature extractors and dynamically finding useful samples.\looseness=-1

% Figure environment removed

\subsection{Visualization of Feature Spaces}\label{sec:eval_feature_space}
In this section, we discuss the effects of PCR and MPS through the visualizations of feature spaces in training.
To visualize the output of \(g_\psi\) in 2D maps, we utilized UMAP~\cite{Mcinnes_arXiv18_umap} to reduce the dimensions.
UMAP is a visualization method based on the structure of distances between samples, and the low dimensional embeddings can preserve the distance between samples of the high dimensional input.
Thus, the distance among the feature clusters on UMAP visualization of \(g_\psi\) can represent the difficulty of the separation by \(h_\omega\).
We used the official implementation by~\cite{Mcinnes_arXiv18_umap}\footnote{https://github.com/lmcinnes/umap} and its default hyperparameters.
We plotted the UMAP embeddings of \(g_\psi(x)\) and \(g_\psi(x_\mathrm{p})\) at \(\{5,15,30\}\) epochs, as shown in Figure~\ref{fig:feature_viz}; we used ResNet-18 trained on the Cars dataset.
At first glance, we observe that GDA and PCR formed completely different feature spaces.
GDA forms the feature spaces by forcing to treat the synthetic samples the same as the real samples through cross-entropy loss and trying to separate the clusters of samples according to the class labels.
However, the synthetic samples leaked to the inter-cluster region at every epoch because they could not represent class categories perfectly as discussed in Sec.~\ref{sec:intro}.
This means that the feature extractor might be distorted to produce features that confuse the classifier.
On the other hand, the synthetic samples in PCR progressively formed a cluster at the center, and the outer clusters can be seen well separated.
Since UMAP can preserve the distances between clusters, we can say that the sparse clusters that exist far from the center are considered easy to classify, while the dense clusters close to the center are considered difficult to classify.
In this perspective, PCR helps \(g_\psi\) to leverage the synthetic samples for learning feature representations interpolating the dense difficult clusters.
This is because the synthetic samples tend to be in the middle of clusters due to their less representativeness of class categories.
That is, PCR can utilize the partial but useful information contained in the synthetic samples while avoiding the negative effect.
Further, we observe that applying MPS accelerates the convergence of the synthetic samples into the center.
From these observations, we conclude that PCR and MPS can help models learn useful feature representations for solving tasks.\looseness=-1

\subsection{Analysis of MPS}\label{sec:eval_mps}
\paragraph*{Evaluation of validation loss.}
We investigate the effects on validation losses when using MPS.
Through the meta-optimization by~Eq.~(\ref{eq:mps_bopt}), MPS can generate samples that reduce the validation loss of \(f_\theta\).
We recorded the validation loss per epoch when applying uniform sampling (Uniform) and when applying MPS.
We used the models trained on Cars and applied the PCR loss on both models.
Figure~\ref{fig:validation_mps} plots the averaged validation losses.
MPS reduced the validation loss.
In particular, MPS were more effective in early training epochs.
This is related to accelerations of converging the central cluster of synthetic samples discussed in Section~\ref{sec:eval_feature_space} and Figure~\ref{fig:feature_viz}.
That is, MPS can produce effective samples for regularizing features and thus speed up the entire training of \(f_\theta\).

% Figure environment removed

\paragraph*{Quantitative evaluation of synthetic samples.}
We evaluate the synthetic samples generated by MPS.
To assess the characteristics of the samples, we measured the difference between the data distribution and distribution of the synthetic samples.
We leveraged the Fr\'echet Inception distance (FID, \cite{heusel_ttur_fid_nips17}), which is a measurement of the distribution gap between two datasets using the closed-form computation assuming multivariate normal distributions:
\begin{eqnarray}
    \text{FID}(\mathcal{D}, \mathcal{D}_\mathrm{p}) = \|\mu - \mu_\mathrm{p}\|^2_2 + \mathrm{Tr}\left(\Sigma + \Sigma_\mathrm{p} - 2\sqrt{\Sigma\Sigma_\mathrm{p}}\right),\nonumber
\end{eqnarray}
where \(\mu\) and \(\Sigma\)\ are the mean and covariance of the feature vectors on InceptionNet for input \(\{x^i\}\).
Since FID is a distance, the lower \(\text{FID}(\mathcal{D},\mathcal{D}_\mathrm{p})\) means that \(\mathcal{D}_\mathrm{p}\) contains more high-quality samples in terms of realness.
We computed FID scores using 2048 samples in \(\mathcal{D}\) and 2048 synthetic samples every epoch; the other settings are given in Section~\ref{sec:setting}.
The FID scores in training are plotted in Figure~\ref{fig:running_fid}.
We confirm that MPS consistently produced higher-quality samples than Uniform. 
This indicates that the sample quality is important for generalizing \(f_\theta\) even in PCR, and uniform sampling can miss higher quality samples in generative models.
Since the performance gain by GDA+MPS in Table~\ref{tb:multiple_dataset} did not better than MGR,  the higher-quality samples by MPS can still contain uninformative samples for the cross-entropy loss, but they are helpful for PCR learning good feature representations.\looseness=-1

\paragraph*{Qualitative evaluation of synthetic samples.}
We evaluate the qualitative properties of the synthetic samples by visualizing samples of a class.
The samples generated by Uniform and MPS are shown in Figure~\ref{fig:uniform_sample}~and~\ref{fig:mps_sample}, where the dataset was Cars and the class category was {\tt Hummer}.
Compared with Uniform, MPS produced samples with more diverse body colors and backgrounds.
That is, MPS focuses on the color and background of the car as visual features for solving classifications. 
In fact, since {\tt Hummer} has various colors of car bodies and can drive on any road with four-wheel drive, these selective generations of MPS are considered reasonable in solving classification tasks.

\subsection{Effect of Generative Models}~\label{sec:eval_generative_model}
Here, we evaluate MGR by varying the generative model \(G_\Phi\) for producing synthetic samples.
As discussed in Sec.~\ref{sec:pcr}~and~\ref{sec:mps}, MGR can use arbitrary unconditional/conditional generative models as \(G_\Phi\) unless it has a latent space.
To confirm the effects when changing \(G_\Phi\), we tested MGR with FastGAN~\cite{Liu_ICLR21_fastgan}, BigGAN~\cite{brock_ICLR18_biggan}, and StyleGAN-XL~\cite{Sauer_SIGGRAPH22_styleganxl}.
Table~\ref{tb:mgr_g} shows the results on Cars.
The unconditional FastGAN achieved similar improvements as conditional cases.
However, since unconditional generative models are generally of low quality in FID, they are slightly less effective.
For the conditional generative models, we observe that MGR performance improvement increases as the quality of synthetic samples improves.
These results suggest the potential for even greater MGR gains in the future as the performance of the generative model improves.
We also evaluate MGR with recent diffusion models in Appendix~\ref{app:mgr_diffusion}.

\subsection{Combination of MGR and Data Augmentation}~\label{sec:eval_data_augmentation}
To assess the practicality of MGR, we evaluate the comparison and combination of MGR and existing data augmentation methods.
Data augmentation (DA) is a method applied to real data and is an independent research field from generative data augmentation.
Therefore, MGR can be combined with DA to improve performance further.
Table~\ref{tb:mgr_da} shows the evaluation results when comparing and combining MGR and DA methods; we used AugMix~\cite{Hendrycks_ICLR20_augmix}, RandAugment~\cite{cubuk_CVPR20_randaugment}, and TrivialAugment~\cite{Muller_ICCV21_trivialaugment} as the DA methods.
The improvement effect of MGR is comparable to that of DA, and the highest accuracy was achieved by combining the two methods. This suggests that the proposed method using synthetic samples and DA plays different roles in classifier training and that MGR is also very effective in practical use.
\begin{table}[t]
    % \vspace{-8mm}
    \centering
    \begin{minipage}{0.49\columnwidth}
    \centering
        \caption{
            Performance of MGR varying \(G_\Phi\) (ResNet-18, Cars).
            }
        \label{tb:mgr_g}
        \resizebox{\columnwidth}{!}{
        \begin{tabular}{lccc}\toprule
            \(G_\Phi\) & Conditional & FID &Top-1 Acc. (\(\%\))\\
            \midrule
              None (Base Model) & -- & -- &  85.50\(^{\pm\text{.10}}\)\\
              \midrule
              FastGAN~\cite{Liu_ICLR21_fastgan} & No & 23.1 &  86.30\(^{\pm\text{.16}}\)\\
              BigGAN~\cite{brock2018biggan} & Yes & 15.6 & 86.86\(^{\pm\text{.06}}\)\\
              StyleGAN2-ADA~\cite{karras_NeurIPS20_training_GANs_with_limited_data} & Yes & 9.5 &  87.22\(^{\pm\text{.15}}\)\\
              StyleGAN-XL~\cite{Sauer_SIGGRAPH22_styleganxl} & Yes & 6.2 &  88.37\(^{\pm\text{.20}}\)\\
            \bottomrule
        \end{tabular}
        }
    \end{minipage}
    \hspace{1mm}
    \begin{minipage}{0.49\columnwidth}
    \centering
        \caption{
            Performance comparison between MGR and data augmentation methods (ResNet-18, Cars, Top-1 Acc. (\(\%\))).
            }
        \label{tb:mgr_da}
        \resizebox{0.9\columnwidth}{!}{
        \begin{tabular}{lcc}\toprule
            Data Augmentation & Base Model & +MGR\\
            \midrule
              None &  85.50\(^{\pm\text{.10}}\) & 87.22\(^{\pm\text{.15}}\)\\ 
              AugMix~\cite{Hendrycks_ICLR20_augmix} & 86.25\(^{\pm\text{.11}}\) &  87.65\(^{\pm\text{.03}}\)\\
              RandAugment~\cite{cubuk_CVPR20_randaugment} & 87.47\(^{\pm\text{.05}}\) & 88.67\(^{\pm\text{.10}}\) \\
              TrivialAugment~\cite{Muller_ICCV21_trivialaugment} &  87.83\(^{\pm\text{.16}}\) & \textbf{89.10}\(^{\pm\textbf{.19}}\)\\
            \bottomrule
        \end{tabular}
        }
    \end{minipage}
    \vspace{-4mm}
\end{table}
    

\section{Related Work}\label{sec:related_work}
We briefly review generative data augmentation and training techniques using generative models.

The earliest works of geneartive data augmentation are \cite{DAGAN_Antoniou,Zheng_ICCV17,calimeri2017_biomedical_data_augmentation}.
They have demonstrated that simply adding synthetic samples as augmented data for classification tasks can improve performance in few-shot learning, person re-identification, and medical imaging tasks.
Tran et~al.\cite{tran_NIPS17_bayesian_data_augmentation} have proposed a generative data augmentation method that simultaneously trains GANs and classifiers for optimizing \(\theta\) to maximize the posterior \(p(\theta|x)\) by an EM algorithm.
Although this concept is similar to our MPS in terms of updating both \(G_\Phi\) and \(f_\theta\), it requires training the specialized neural architectures based on GANs.
In contrast, MPS is formalized for arbitrary existing generative models with latent variables, and it requires no restrictions to the training objectives of generative models.

On the analysis of generative data augmentation, Shmelkov et al.~\cite{shmelkov_ECCV18_howgoodismygan} have pointed out that leveraging synthetic samples as augmented data degrades the performance in general visual classification tasks.
They have hypothesized that the cause of the degradation is the less diversity and fidelity of synthetic samples from generative models.
Subsequent research by Yamaguchi~et~al.~\cite{yamaguchi_AAAI20_effective_data_augmentation_with_GANs} have shown that the scores related to the diversity and fidelity of synthetic samples (i.e., SSIM and FID) are correlated to the test accuracies when applying the samples for generative data augmentation in classification tasks.
Based on these works, our work reconsiders the training objective and sampling method in generative data augmentation and proposes PCR and MPS.\looseness-1

More recently, He et~al.~\cite{He_ICLR23_synthetic_data} have reported that a text-to-image generative model pre-trained on massive external datasets can achieve high performance on few-shot learning tasks. They also found that the benefit of synthetic data decreases as the amount of real training data increases, which they attributed to a domain gap between real and synthetic samples. In contrast, our method does not depend on any external dataset and successfully improves the accuracy of the classifier even when synthetic data are not representatives of class labels (i.e., having domain gaps).\looseness-1

\section{Limitation}
One of the limitations of our method is the requirement of bilevel optimization of classifier and finder networks.
This optimization is computationally expensive in particular when used with generative models that require multiple inference steps, such as diffusion models as discussed in Appendix~\ref{app:mgr_diffusion}.
We have tried other objective functions not requiring bilevel optimization, but at this time, we have not found an optimization method that outperforms MPS (see Appendix~\ref{app:without-meta}).
Nevertheless, since recent studies rapidly and intensively focus on the speedup of diffusion models~\cite{Rombach_CVPR22_StableDiffusion,Karras_NeurIPS22_edm,Meng_CVPR23_distillation_diffusion}, we can expect that this limitation will be negligible in near the future.

\section{Conclusion}\label{sec:conclusion}
This paper presents a novel method for generative data augmentation called MGR.
MGR is composed of two techniques: PCR and MPS.
To avoid the degradation of classifiers, PCR utilizes synthetic samples to regularize feature extractors by the simple consistency regularization loss.
MPS searches the useful synthetic samples to train the classifier through meta-learning on the validation loss of main tasks.
We empirically showed that MGR significantly improves the baselines and brings generative data augmentation up to a practical level.
We also observed that the synthetic samples in existing generative data augmentation can distort the decision boundaries on feature spaces, and the PCR loss with synthetic samples dynamically generated by MPS can resolve this issue through visualization.
We consider that these findings will help future research in this area.

\clearpage
\bibliographystyle{unsrt}
\bibliography{mps}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section*{Appendix}
The following manuscript provides the supplementary materials of the main paper: Regularizing Neural Networks with Meta-Learning Generative Models.
% We describe 
% (\ref{sec:exrelatedwork}) additional related works of domain adaptation and fine-tuning, 
% (\ref{sec:details_setting}) details of experimental settings used in the main paper,
% (\ref{sec:exexperiments}) additional experiments including comparison of our method and fine-tuning, and detailed analysis of PP and P-SSL,
% and (\ref{sec:qualitative}) qualitative evaluations of pseudo samples by PCS.
\section{Algorithm of Meta Generative Regularization}\label{app:algorithm}

\begin{algorithm}[h]
    \caption{Meta Generative Regularization}\label{alg:mgr}
    \begin{algorithmic}[1]
    {\small
        \REQUIRE{Training dataset \(\mathcal{D}\), validation dataset \(\mathcal{D}_\text{val}\)  main model \(f_\theta\), generator \(G\), finder \(F_\phi\), training batchsize \(B\), pseudo batchsize \(B_\mathrm{p}\), validation batchsize \(B_\text{val}\), step size \(\eta\) and \(\xi\), hyperparameter \(\lambda\) and \(\lambda_\text{KL}\) 
        \ENSURE{Trained main model \(f_\theta\)}}
        \WHILE{not converged}
        \STATE{\(\{(x^i,y^i)\}^B_{i=1}\sim \mathcal{D}\)}
        \STATE{\(\{z^i\}^{B_\mathrm{p}}_{i=1} \sim \mathcal{N}(0,I)\)}
        \STATE{// Updating \(\phi\) for MPS}
        \STATE{\(\{(x^i_\text{val},y^i_\text{val})\}^{B_\text{val}}_{i=1}\sim \mathcal{D}\)}
        \STATE{\(\{x_\mathrm{p}^i\}^{B_\mathrm{p}}_{i=1} = \{G_\Phi(F_\phi(z^i),y_\mathrm{p}^i)\}^{B_\mathrm{p}}_{i=1}\)}
        \STATE{\(\theta^\prime \leftarrow \theta - \eta \nabla_\theta(\frac{1}{B}\ell(f_\theta(x^i),y^i) + \frac{\lambda}{B_\mathrm{p}}\ell_\text{PCR}(x_\mathrm{p}^i;\psi))\)}
        \STATE{\(\phi \leftarrow \phi - \xi \nabla_\phi{(\frac{1}{B_\text{val}}\ell(f_{\theta^\prime}(x_\text{val}), y_\text{val})+\lambda_\text{KL}(D_\text{KL}(p_{\phi}(z)\|p(z))))}\)}
        \STATE{// Updating \(\theta\) with PCR}
        \STATE{\(\{x_\mathrm{p}^i\}^{B_\mathrm{p}}_{i=1} = \{G_\Phi(F_\phi(z^i),y_\mathrm{p}^i)\}^{B_\mathrm{p}}_{i=1}\)}
        \STATE{\(\theta \leftarrow \theta - \eta \nabla_\theta(\frac{1}{B}\ell(f_\theta(x^i),y^i) + \frac{\lambda}{B_\mathrm{p}}\ell_\text{PCR}(x_\mathrm{p}^i;\psi))\)}
        \ENDWHILE
        }
    \end{algorithmic}
\end{algorithm}

\section{Additional Experiments}
\subsection{Evaluation of Gradient Approximation}\label{app:mps_approx}
Here, we evaluate the gradient approximation by Eq.~(\ref{eq:sc-grad_approx}).
As shown in Table~\ref{tb:grad_approximation}, Eq.~(\ref{eq:sc-grad_approx}) well approximated the second-order gradients in speeding up over 10\% with \(0.08\) of the accuracy drop.\looseness=-1
\begin{table}[h]
    \centering
        \caption{
            Performance comparison between MPS with 2nd-order gradients and 1st-order approximated gradients (ResNet-18, Cars).
            }
        \label{tb:grad_approximation}
        % \resizebox{\columnwidth}{!}{
        \begin{tabular}{lcc}\toprule
            Method & Top-1 Acc. (\(\%\)) & Wall Clock Time (hours) \\
            \midrule
              2nd-Order &  87.30\(^{\pm\text{.39}}\) &  6.55 \\
              1st-Order Approx. &  87.22\(^{\pm\text{.15}}\) & 5.79 \\
            \bottomrule
        \end{tabular}
        % }
 \end{table}
\subsection{Ablation study of \(F_\phi\)}\label{app:f_ablation}
In Section~\ref{sec:mps}, we introduce \(F_\phi\) for meta-optimized parameters and the residual architectures with MLP defined by Eq.~(\ref{eq:residual_finder}).
We performed an ablation study of MPS with respect to the meta-optimized parameters and the architectures of \(F_\phi\).
We compared MPS with a variant of MPS optimizing \(G_\Phi\) instead of \(F_\phi\).
We also attempted other architectures for \(F_\phi\) including \textbf{Linear}: \(W_\phi(z)+b\), \textbf{MLP}: \(\text{MLP}_\phi(z)\), and \textbf{Residual+Shallow}: \(z + \tanh(W_\phi(z)+b)\).
The results of these variations are shown in Table~\ref{tb:mps_ablation}.
We observed that MPS with \(G_\Phi\) caused failures of training  \(f_\theta\) and degrades the accuracy.
On the other hand, all variants of MPS with \(F_\phi\) succeeded in boosting the models without MPS.
Thus, restricting the number of optimized parameters is important, and determining an optimal \(z\) with the finder \(F_\phi\) is effective on the optimization problems of MPS.
For the variants of MPS with \(F_\phi\), we observed that the residual architectures and regularization by \(D_\text{KL}(p_\phi(z)\|p(z))\) contributed to the successes.
Interestingly, MPS with Linear \(F_\phi\) outperformed MPS with MLP \(F_\phi\), i.e., significantly transforming the input \(z\sim p(z)\) by complex functions results in low accuracy.
These results suggest that better latent vectors in \(\mathcal{Z}\) to train \(f_\theta\) can exist near the uniformly sampled input \(z\). 
Thus, limiting the search range by \(\tanh\) in the residual architectures can help in finding better latent vectors.\looseness=-1

 \begin{table}[h]
    \centering
        \caption{
            Ablation study of MPS (ResNet-18, Cars).1
            }
        \label{tb:mps_ablation}
        % \resizebox{0.8\columnwidth}{!}{
        \begin{tabular}{lc}\toprule
            Method & Top-1 Acc. (\(\%\))\\
            \midrule
              Without MPS (PCR)  &  86.32\(^{\pm\text{.07}}\)\\
              MPS  &  \textbf{87.22}\(^{\pm\textbf{.15}}\)\\
              MPS with \(G_\Phi\) &  84.47\(^{\pm\text{.05}}\)\\
              MPS with Linear \(F_\phi\) &  86.51\(^{\pm\text{.09}}\)\\
              MPS with MLP \(F_\phi\) &  86.35\(^{\pm\text{.13}}\)\\
              MPS with Residual+Shallow \(F_\phi\) &  86.88\(^{\pm\text{.16}}\)\\
              MPS w/o \(D_\text{KL}(p_\phi(z)\|p(z))\) &  86.92\(^{\pm\text{.22}}\)\\
            \bottomrule
        \end{tabular}
        % }
 \end{table}

\subsection{MGR with Diffusion Models}\label{app:mgr_diffusion}
We tested our method on EDM~\cite{Karras_NeurIPS22_edm}, a recent diffusion model. Due to the computation cost, we used a 10\% reduced CIFAR-10 as the dataset. We optimized $F_\phi$ to search the first step noise of the diffusion process. Table B-4 shows that our method with EDM improves Base Model. However, the overhead of incorporating diffusion models was significant; it takes more than ten times longer training than GANs. In future work, we will investigate lighter-weight methods using the diffusion model.

\begin{table}[h]
    \centering
        \caption{
            Performance studies on Diffusion Model (ResNet-18 on Cars)
            }
        \label{tb:mgr_diffusion}
        % \resizebox{0.8\columnwidth}{!}{
        \begin{tabular}{lc}\toprule
            Method & Top-1 Acc. (\(\%\))\\
            \midrule
              Base Model &  86.49\(^{\pm\text{.48}}\)\\
              GDA (EDM) &  85.80\(^{\pm\text{.30}}\)\\
              MGR &  \textbf{88.49}\(^{\pm\textbf{.12}}\)\\
            \bottomrule
        \end{tabular}
        % }
 \end{table}

\subsection{Updating \(F_\phi\) without Meta-optimization}\label{app:without-meta}
MPS consists of meta-learning on validation losses requiring bi-level optimization, which is a relatively heavy computation.
One can consider if \(F_\phi\) could be trained without meta-optimization.
Here, we try alternative methods other than meta-learning to update \(F_\phi\).
Instead of meta-learning, we used a strategy of choosing hard examples via optimizing $F_\phi$.
That is, we optimize $F_\phi$ by maximizing the training cross-entropy (CE) loss and the PCR loss on synthetic samples. Note that, in both cases, we used the PCR loss for synthetic samples when training classifiers. Table A-2 shows the results. Optimizing $F_\phi$ with CE and PCR slightly improved the baselines but significantly underperformed our method (MGR). This result can justify using meta-optimizing $F_\phi$ to generate useful samples for classifiers. Nevertheless, this idea could inspire a sampling method that does not require bi-level optimization in future work.

\begin{table}[h]
    \centering
        \caption{
            Performance comparison of updating strategies for \(F_\phi\) (ResNet-18 on Cars)
            }
        \label{tb:mps_f_strategy}
        % \resizebox{0.8\columnwidth}{!}{
        \begin{tabular}{lc}\toprule
            Method & Top-1 Acc. (\(\%\))\\
            \midrule
              Base Model &  85.50\(^{\pm\text{.10}}\)\\
              PCR &  86.36\(^{\pm\text{.08}}\)\\
              Optimizing $F_\phi$ w/ CE &  86.52\(^{\pm\text{.21}}\)\\
              Optimizing $F_\phi$ w/ PCR & 86.44\(^{\pm\text{.68}}\)\\
              MGR &  \textbf{87.22}\(^{\pm\textbf{.15}}\)\\
            \bottomrule
        \end{tabular}
        % }
 \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

