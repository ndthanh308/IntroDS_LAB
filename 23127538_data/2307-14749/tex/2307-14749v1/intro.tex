\section{Introduction}
\label{sec:introduction}
Video games are becoming an increasingly important form of expression in Today's culture. Their sociological, economic, and technological impact is well recognized in the literature \citep{jones2008meaning} and their wide diffusion, particularly among the younger generations, has contributed to the growth of the gaming industry in several directions. Playing video games is progressively becoming a work for many: Some play for professional competitions (\eg in e-sports or speed-running), while others play to entertain others (\eg streamers) especially on dedicated platforms such as Twitch\footnote{\url{https://twitch.tv}}.
Besides all challenges that are common to software systems, developing and maintaining video games pose additional difficulties related to complex graphical user interfaces, performance requirements, and higher testing complexity. Concerning the latter point, games tend to have a large number of states that can be reached through different choices made by the player. In such a context, writing automated tests is far from trivial due to the need for an ``intelligent'' interaction triggering the states exploration. Even assuming such ability to explore the game space, determining what the correct behavior is in a specific state usually requires human assessment, with the exception of bugs causing the game to crash. Finally, additional complexity is brought by the non-determinism that occurs in games because of multi-threading, distributed computing, artificial intelligence and randomness injected to increase the difficulty of the game \citep{murphy2014cowboys}. %Besides, video games are characterized by specific measures of quality that are difficult to observe and measure due to their abstract nature, such as fun and entertainment \cite{santos2018computer}.

Because of the few automated approaches available for quality control in video game development \citep{santos2018computer}, many games are released with unknown problems that are revealed only once customers start playing \citep{truelove2021we}. Since many streamers daily publish hours of gameplay videos, it is very likely that some of them experience such issues and leave traces of them in the uploaded videos. For example, a gameplay video on the game Cyberpunk 2077\footnote{\url{https://youtu.be/ybvXzSLy9Ew?t=1448}} shows that the game crashes as soon as the player performs a specific action.
The large amount of publicly available gameplay videos, therefore, might be a goldmine of information for developers. Indeed, such videos not only contain information about which kinds of issues affect a video game, but they also provide examples of interactions that led to the issue in the first place, allowing its reproduction. 
In their seminal work on this topic, \citet{lin2019identifying} defined an approach able to automatically identify videos containing bug reports. However, such an approach mostly relies on the video metadata (\eg its length) and it is not able to pinpoint the specific parts of the video in which the bug is reported. This makes it unsuitable as a reporting tool for game developers, especially when long videos, which are not uncommon, are spot as bug-reporting.

In this paper, we introduce \approach (\approachlong), an automated approach that aims at complementing the approach by \citet{lin2019identifying} by (i) automatically extracting meaningful segments of gameplay videos in which streamers report issues, and (ii) hierarchically organize them. 
Given some gameplay videos as input, \approach (i) partitions them into meaningful segments that might contain bug reports, (ii) automatically distinguishes informative segments from non-informative ones by also determining the type of reported issue (\eg bug, performance-related), (iii) groups them based on the ``context'' in which they appear (\ie whether the issue manifests itself in a specific game area), and (iv) clusters fragments related to the same specific issue (\eg the game crashes when a specific item is collected). 

We evaluate the four components of \approach in isolation, to understand to what extent it is possible to achieve the single goals we set, as we planned in our registered report presented at MSR 2022 \citep{guglielmi2022towards}. We first extract training data for the machine learning model we use to categorize segments (step 2 of \approach). To this end, we used the approach by \citet{lin2019identifying} to identify candidate videos from which we can manually label segments in which the streamer is reporting an issue. Then, we ran \approach on a set of real gameplay videos and validate its components. First, we manually determine to what extent the extracted segments are usable, by annotating their \textit{interpretability} (\ie they can be used as standalone videos) and \textit{atomicity} (\ie they can not be further split). Second, we validate the categorization capabilities of \approach, both when trying to distinguish non-informative segments from informative ones (binary classification) and when trying to pinpoint the specific issue among \textit{logic}, \textit{performance}, \textit{presentation}, \textit{balance}, and \textit{non-informative} through a multi-class classifier. To this and, we compute typical metrics used to evaluate ML models (\ie accuracy and AUC).
Finally, we evaluate to what extent the clusters identified in terms of context and specific issues are similar to the manually determined ones using the MoJoFM metric \citep{wen2004effectiveness}.

The remainder of this paper is organized as follows. In \secref{sec:related} we present the background needed for understanding the paper and some related work, based on which we also define the four specific categories of issues that \approach will identify. In \secref{sec:approach}, we present \approach and its four components in details. In \secref{sec:design} we describe the empirical study design, while in \secref{sec:results} we report the obtained results. In \secref{sec:discussion} we discuss the results, while in \secref{sec:threats} we report the threats to validity. \secref{sec:conclusions} concludes the paper.
