\section{Empirical Study Results}
\label{sec:results}

This section reports the results of the four research questions formulated in \secref{sec:design}.

\subsection{\RQ{1}: Interpretability and Atomicity of Gameplay Video Segments}

The IRR between the two raters when they evaluated the \textit{interpretability} of the segments extracted with \approach is $k = 0.84$, while it is $k = 0.85$ when evaluating them in terms of \textit{atomicity}. Thus, in both the cases, the agreement was \textit{almost perfect}.

% Figure environment removed


%The results of the analysis conducted for \RQ{1} are described in %\tabref{tab:resultRQ1}.
% \subsubsection{Interpretability}
When comparing $t=0$ with $t=5$ in terms of \textit{interpretability} of gameplay video segments generated by \approach, we obtain an adjusted \textit{p-value} $<$ 0.001, with a \textit{negligible} effect size ($\delta$ = -0.146). We obtain an analogous result when comparing $t=5$ with $t=10$ (p $<$ 0.001, $\delta$ = -0.092, \textit{negligible} magnitude). 
We observed also a difference between $t=0$ with $t=10$: In this case, the adjusted \textit{p-value} is the same (p $<$ 0.001), while, this time, the effect size is \textit{small} ($\delta$ = -0.227).
The boxplot in \figref{fig:boxplots} (left part) visually confirms the difference we numerically observed.

In terms of \textit{atomicity}, when comparing $t=0$ with $t=5$ we obtain an adjusted \textit{p-value} $<$ 0.001, with a \textit{large} effect size ($\delta$ = 0.610). We obtain an analogous result when comparing $t=5$ with $t=10$ (p $<$ 0.001, $\delta$ = 0.577, \textit{large} magnitude). 
As expected, again, the difference between $t=0$ with $t=10$ is \textit{large} as well (\textit{p-value} $<$ 0.001, $\delta$ = 0.869).
The boxplot in \figref{fig:boxplots} (right part) visually confirms the difference we numerically observed.
A case in which two annotators disagreed on the evaluation of the atomicity of a segment is related to segment in a gameplay video on Conan Exiles. One author rated the atomicity of the segment as 4, while the second author rated it as 5. The disagreement arose from the presence of a gameplay setting screen that appeared during the video segment, lasting about 3 seconds. This setting screen interrupted the ongoing game phase and then resumed it. The first evaluator considered this interruption significant enough to be considered as a point in which two segments could be detected, while the second annotator considered the screen appearance time negligible, given its short duration.

Considering overall the results, we can conclude that by increasing the $t$ value we obtain negligible advantages in terms of interpretability and substantial disadvantages in terms of atomicity. More specifically, while increasing $t$ from 0 to 5 allows to obtain an observable difference in terms of interpretability, having a $t$ value higher than 5 practically brings no advantage at all (see \figref{fig:boxplots} --- left part). We conclude that $t$ values higher than 5 are most likely not worth considering, while there is a trade-off that users might want to consider between $t = 0$ (which allows having substantially more atomic videos) and $t = 5$ which allows having more interpretable videos, even if slightly). Indeed, we obtain for $t = 0$ an average interpretability of 3.97 and an average atomicity of 4.88, while $t = 5$ provides an average value of 4.27 for both interpretability and atomicity.

\begin{resultbox}
 \textbf{Answer to \RQ{1}.} The proposed segmentation approach achieves satisfactory results. The best results are obtained when using $t = 0$ (privileging atomicity) and $t = 5$ (privileging interpretability).
\end{resultbox}

\subsection{\RQ{2}: Gameplay Video Segments Categorization}

\textbf{ML Pipeline Selection and Training.}
We report in \tabref{tab:rq2binary} and \tabref{tab:rq2multiclass} the results of the 10-fold cross-validation comparison performed on the training set to select the best algorithm both for binary and multi-class categorization, respectively. For deciding which sets of textual features we would include in the combination of image-based features and textual features, we compared the average results obtained with textual features alone and we picked the features that generally allow to achieve the best results (\ie Word2Vec).

The machine learning algorithm that provides the best results for binary classification is Random Forest, while the best set of features is the combination of image-based and textual features. Using both SMOTE and attribute selection, we obtained 0.79 AUC (71.8\% accuracy).
The best results could be achieved with Random Forest and a combination of image-based and textual features for multi-class categorization as well. This time, however, the best model was the one trained by only running attribute selection (\ie without balancing the training set with SMOTE). In this case, the obtained AUC is slightly lower (0.75 AUC, 62.0\% accuracy), most likely due to the inherently more difficult problem (categorizing in five classes instead of two).

\newcommand{\trotate}[1]{\begin{sideways}#1\end{sideways}}
\begin{table*}[t]
\centering
\caption{\RQ{2}: Comparison, in terms of unweighted average AUC, of different sets of features (\textbf{B}ag \textbf{o}f \textbf{W}ords, \textbf{W}ord\textbf{2}\textbf{V}ec, \textbf{D}oc\textbf{2}\textbf{V}ec, \textbf{I}mage-based features), preprocessing techniques (SMOTE and \textbf{A}ttribute \textbf{S}election), and ML algorithms for binary classification (\textit{non-informative}/\textit{informative}).}
\label{tab:rq2binary}
\begin{tabular}{l|lrrrr}
\toprule
                                              & \textbf{Model} & \textbf{Plain} & \textbf{AS} & \textbf{SMOTE} & \textbf{SMOTE + AS}  \\ \midrule
\multirow{5}{*}{\trotate{\textbf{BoW}}}       & RandomForest                       & 0.72  & 0.73                & 0.72  & 0.73                         \\
                                              & Logistic                           & 0.63  & 0.74                & 0.62  & 0.73                         \\
                                              & SMO                                & 0.68  & 0.60                & 0.68  & 0.66                         \\
                                              & MultilayerPerceptron               & 0.52  & 0.73                & 0.68  & 0.73                         \\
                                              & IBk                                & 0.58  & 0.73                & 0.60  & 0.73                         \\ \midrule
\multirow{5}{*}{\trotate{\textbf{W2V}}}       & RandomForest                       & 0.72  & 0.72                & 0.74  & 0.71                          \\
                                              & Logistic                           & 0.68  & 0.70                & 0.69  & 0.70                          \\
                                              & SMO                                & 0.65  & 0.65                & 0.65  & 0.65                          \\
                                              & MultilayerPerceptron               & 0.73  & 0.68                & 0.72  & 0.69                          \\
                                              & IBk                                & 0.62  & 0.62                & 0.62  & 0.63                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{D2V}}}       & RandomForest                       & 0.52  & 0.50                & 0.52  & 0.50                          \\
                                              & Logistic                           & 0.50  & 0.50                & 0.49  & 0.50                          \\
                                              & SMO                                & 0.51  & 0.50                & 0.48  & 0.50                          \\
                                              & MultilayerPerceptron               & 0.52  & 0.50                & 0.56  & 0.50                          \\
                                              & IBk                                & 0.50  & 0.50                & 0.52  & 0.50                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{I}}}         & RandomForest                       & 0.74  & 0.69                & 0.74  & 0.68                          \\
                                              & Logistic                           & 0.69  & 0.66                & 0.69  & 0.66                          \\
                                              & SMO                                & 0.61  & 0.58                & 0.58  & 0.57                          \\
                                              & MultilayerPerceptron               & 0.67  & 0.66                & 0.69  & 0.66                          \\
                                              & IBk                                & 0.62  & 0.61                & 0.62  & 0.60                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{W2V + I}}}   & RandomForest                       & 0.78  & 0.78                & 0.79  & \textbf{0.79}                 \\
                                              & Logistic                           & 0.70  & 0.72                & 0.70  & 0.72                          \\
                                              & SMO                                & 0.68  & 0.65                & 0.67  & 0.63                          \\
                                              & MultilayerPerceptron               & 0.74  & 0.73                & 0.76  & 0.71                          \\
                                              & IBk                                & 0.65  & 0.66                & 0.64  & 0.66                          \\
\bottomrule
\end{tabular}
% }
\end{table*}




\begin{table*}[t]
\centering
\caption{\RQ{2}: Comparison, in terms of unweighted average AUC, of different sets of features (\textbf{B}ag \textbf{o}f \textbf{W}ords, \textbf{W}ord\textbf{2}\textbf{V}ec, \textbf{D}oc\textbf{2}\textbf{V}ec, \textbf{I}mage-based features), preprocessing techniques (SMOTE and \textbf{A}ttribute \textbf{S}election), and ML algorithms for multi-class classification (\textit{logic}, \textit{presentation}, \textit{performance}, \textit{balance}, \textit{non-informative}).}
\label{tab:rq2multiclass}
% \resizebox{\linewidth}{!}{%
\begin{tabular}{llrrrr}
\toprule
                                              & \textbf{Model} & \textbf{Plain} & \textbf{AS} & \textbf{SMOTE} & \textbf{SMOTE + AS}  \\ \midrule
\multirow{5}{*}{\trotate{\textbf{BoW}}}       & RandomForest                       & 0.72  & 0.70                 & 0.71   & 0.69                          \\
                                              & Logistic                           & 0.70  & 0.69                 & 0.70   & 0.70                          \\
                                              & SMO                                & 0.67  & 0.62                 & 0.67   & 0.69                          \\
                                              & MultilayerPerceptron               & 0.70  & 0.71                 & 0.70   & 0.70                          \\
                                              & IBk                                & 0.60  & 0.69                 & 0.60   & 0.69                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{W2V}}}       & RandomForest                       & 0.73  & 0.72                 & 0.70   & 0.71                          \\
                                              & Logistic                           & 0.59  & 0.71                 & 0.63   & 0.69                          \\
                                              & SMO                                & 0.67  & 0.60                 & 0.70   & 0.67                          \\
                                              & MultilayerPerceptron               & 0.67  & 0.64                 & 0.68   & 0.65                          \\
                                              & IBk                                & 0.58  & 0.59                 & 0.61   & 0.60                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{D2V}}}       & RandomForest                       & 0.52  & 0.49                 & 0.51   & 0.49                           \\
                                              & Logistic                           & 0.48  & 0.49                 & 0.48   & 0.49                          \\
                                              & SMO                                & 0.49  & 0.50                 & 0.49   & 0.49                          \\
                                              & MultilayerPerceptron               & 0.52  & 0.49                 & 0.50   & 0.49                          \\
                                              & IBk                                & 0.49  & 0.49                 & 0.51   & 0.49                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{I}}}         & RandomForest                       & 0.69  & 0.62                 & 0.67   & 0.62                          \\
                                              & Logistic                           & 0.66  & 0.64                 & 0.65   & 0.64                          \\
                                              & SMO                                & 0.54  & 0.53                 & 0.62   & 0.61                          \\
                                              & MultilayerPerceptron               & 0.52  & 0.66                 & 0.63   & 0.64                          \\
                                              & IBk                                & 0.56  & 0.58                 & 0.56   & 0.56                          \\ \midrule
\multirow{5}{*}{\trotate{\textbf{W2V + I}}}   & RandomForest                       & 0.74  & \textbf{0.75}        & 0.74   & 0.71                          \\
                                              & Logistic                           & 0.61  & 0.71                 & 0.65   & 0.70                          \\
                                              & SMO                                & 0.70  & 0.57                 & 0.71   & 0.68                          \\
                                              & MultilayerPerceptron               & 0.71  & 0.67                 & 0.71   & 0.66                          \\
                                              & IBk                                & 0.60  & 0.59                 & 0.62   & 0.58                          \\
\bottomrule
\end{tabular}
% }
\end{table*}

\textbf{Testing the Models.}
% For each best model, we conduct the evaluation for each game defined in the test set individually and a total evaluation on all three games. We report the global accuracy (\ie percentage of correctly classified instances) and, for each class, the achieved precision ($\frac{\mathit{TP}}{\mathit{TP} + \mathit{FP}}$), recall ($\frac{\mathit{TP}}{\mathit{TP} + \mathit{FN}}$), and AUC (Area Under the ROC Curve).
\tabref{tab:rq2binary_videogames} and \tabref{tab:rq2multiclass_videogames} report the recall, precision, F-Measure and AUC
scores achieved by the best model for binary and multi-class categorization, respectively. In detail, we report the results achieved both for individual games and for all the instances together. 

Overall, the binary classification model exhibits slightly worse results compared to the ones obtained on the training set with 10-fold cross validation (0.61 AUC vs. 0.79). The model has an acceptable recall (72\%) and a relatively low precision (56\%) on the \textit{informative} class. This means that a developer would be able to get most of the potentially interesting segments, but they also have to manually discard many non-informative ones in the process. The results, however, depend much on the video game at hand: For Conan Exiles, for example, the model always achieves acceptable results both in terms of overall precision (66\%) and recall (64\%). This might depend on many factors. First, on the quality of the streaming videos taken into account: Streamers might be more verbose for some video game genres, thus allowing the classifier to better identify the segments. Second, on the similarity with video games included in the training set: Some genre- or game-specific terms might be indicative of an issue for some games, while not for others. For example, the phrase ``loot hack'' might appear in online multiplayer role play games and indicate a \textit{logic} issue, but it might not be pronounced at all by streamers playing racing games.

Analogous conclusions can be drawn from the results achieved with the multi-class model. In this case, it is interesting to observe that some classes the classifier never categorizes instances as \textit{performance} and \textit{balance} (``\textit{--}'' for precision in \tabref{tab:rq2multiclass_videogames}). This is possibly due to the fact that such issue types are generally less prevalent than others\footnote{33 and 48 in the training set, 31 and 4 in the test set for \textit{performance} and \textit{balance}, respectively.} and, thus, the model fails to learn how to recognize them. It is also worth noting that we were not able to find \textit{balance} issues in one of the games taken into account (\ie DayZ). Overall, the model achieves better results on the \textit{presentation} class. This is probably due to the fact that, for this category, the model also relies on image-based features, which are less relevant for the other classes.

\begin{table*}[t]

\newcommand{\I}{\faIcon[regular]{info}}
\newcommand{\NI}{\faIcon[regular]{trash}}
\newcommand{\OV}{\faIcon[regular]{globe}}
\centering
\caption{\RQ{2}: Performance of the best binary categorization model on the test set. We use the icon \I{} to indicate the \textit{informative} class and the icon \NI{} to indicate the \textit{non-informative} class, while \OV{} indicates their weighted mean.}
\label{tab:rq2binary_videogames}
\resizebox{\linewidth}{!}{%
\begin{tabular}{l|rrr|rrr|rrr|rrr}
\toprule
\multirow{2}{*}{\textbf{Game}}     & \multicolumn{3}{c|}{\textbf{Precision}} & \multicolumn{3}{c|}{\textbf{Recall}} & \multicolumn{3}{c|}{\textbf{F-Measure}} & \multicolumn{3}{c}{\textbf{AUC}} \\
                                   & \I    & \NI    & \OV                     & \I    & \NI    & \OV                 & \I    & \NI    & \OV                    & \I    & \NI    & \OV             \\
\midrule                                                                                                                                                                                         
{Conan Exiles}                     & 61\% & 70\%  & 66\%                      & 77\% & 52\%  & 64\%                  & 68\% & 60\% & 64\%                     & 0.73  & 0.73 & 0.73              \\
{DayZ}                             & 52\% & 54\%  & 53\%                      & 71\% & 34\%  & 53\%                  & 60\% & 42\% & 51\%                     & 0.55  & 0.55 & 0.55              \\
{New World}                        & 65\% & 47\%  & 58\%                      & 71\% & 40\%  & 59\%                  & 68\% & 43\% & 59\%                     & 0.61  & 0.61 & 0.61              \\
\midrule                                                                                                                                                                                                
{Overall}                          & 56\% & 62\%  & 60\%                      & 72\% & 45\%  & 58\%                  & 63\% & 52\% & 58\%                     & 0.58  & 0.64 & 0.61              \\
\bottomrule
\end{tabular}
}
\end{table*}


\begin{table*} [t]
\newcommand{\Lo}{\faIcon[regular]{bug}}
\newcommand{\PR}{\faIcon[regular]{ghost}}
\newcommand{\Pf}{\faIcon[regular]{clock}}
\newcommand{\Bl}{\faIcon[regular]{balance-scale-right}}
\newcommand{\NI}{\faIcon[regular]{trash}}
\newcommand{\OV}{\faIcon[regular]{globe}}
\centering
\caption{\RQ{2}: Performance of the best multi-class categorization model on the test set. We use the icons \Lo{}, \PR{}, \Pf{}, \Bl, and \NI{} to indicate the \textit{logic}, \textit{presentation}, \textit{performance}, \textit{balance}, and \textit{non-informative} classes, respectively, while \OV{} indicates their weighted mean.}
\label{tab:rq2multiclass_videogames}
\resizebox{\linewidth}{!}{%

\begin{tabular}{l|rrrrrr|rrrrrr}
\toprule                                   
\multirow{2}{*}{\textbf{Game}}     & \multicolumn{6}{c|}{\textbf{Precision}}                   & \multicolumn{6}{c}{\textbf{Recall}} \\
                                   & \NI    & \PR    & \Lo   & \Bl   & \Pf   & \OV             & \NI    & \PR    & \Lo   & \Bl   & \Pf   & \OV  \\
\midrule                                                                                                                                                                                         
\textbf{Conan Exiles}              & 58\%   & 48\%   & 25\%  & -     & -     & 48\%               & 81\%   & 39\%   &  3\%  & 0\%   & 0\%   & 55\%    \\
\textbf{DayZ}                      & 51\%   & 35\%   & 0\%   & -     & -     & 39\%               & 61\%   & 34\%   &  0\%  & -     & 0\%   & 43\%    \\
\textbf{New World}                 & 56\%   & 49\%   & 25\%  & -     & -     & 48\%               & 71\%   & 40\%   & 50\%  & 0\%   & 0\%   & 52\%    \\
\midrule                                                                                                                                                                                                                 
\textbf{Overall}                   & 56\%   & 44\%   & 13\%  & -     & -     & 45\%               & 73\%   & 38\%   & 10\%  & 0\%   & 0\%   & 51\%    \\
\bottomrule

\toprule
\multirow{2}{*}{\textbf{Game}}     & \multicolumn{6}{c|}{\textbf{F-Measure}}                   & \multicolumn{6}{c}{\textbf{AUC}} \\
                                   & \NI    & \PR    & \Lo   & \Bl   & \Pf   & \OV             & \NI    & \PR    & \Lo   & \Bl   & \Pf   & \OV  \\
\midrule                                   
\textbf{Conan Exiles}              & 68\%   & 43\%   &  5\%  & -     & -     & 49\%               & 0.69   & 0.65   & 0.58  & 0.33  & 0.57  & 65\%    \\
\textbf{DayZ}                      & 55\%   & 35\%   &  0\%  & -     & -     & 43\%               & 0.52   & 0.52   & 0.53  & -     & 0.47  & 51\%    \\
\textbf{New World}                 & 63\%   & 44\%   & 33\%  & -     & -     & 49\%               & 0.64   & 0.60   & 0.93  & 0.72  & 0.10  & 62\%    \\
\midrule                                                                                                                                              
\textbf{Overall}                   & 63\%   & 40\%   & 10\%  & -     & -     & 47\%              & 0.63   & 0.60   & 0.54  & 0.61  & 0.48  & 60\%    \\
\bottomrule
\end{tabular}
}
\end{table*}

\begin{resultbox}
 \textbf{Answer to \RQ{2}.} The categorization models defined are not able achieve satisfactory results both for binary and multi-class categorization.
\end{resultbox}

\subsection{\RQ{3}: Clustering Gameplay Video Segments by Context}

\tabref{tab:context_clustering} shows the MoJoFM score achieved by the two tested algorithms when comparing their output with the manually defined clusters. First, it can be observed that OPTICS allows to achieve the best results for all games taken into account, between 46.0\% (New World) and 21.9\% (Conan Exiles). It is worth noting that the variability among video games is, in this case, quite high. This is expected: Some games have areas and levels very similar one to another, thus making the task of visually distinguishing the areas quite challenging even for a human who never played the game.
For example, the frames presented in \figref{fig:clusterconan} represent two visually similar areas in Conan Exiles that, however, are different.

% Figure environment removed

Overall, however, we can conclude that the clustering approach we defined in \approach is only partially able to achieve its goal.

\begin{table}[h]
\centering
\caption{\RQ{3}: MoJoFM achived for clustering by context with HSV}
\label{tab:context_clustering}
%\resizebox{\linewidth}{!}{%
\begin{tabular}{l r r }
\toprule
                             & \textbf{DBSCAN}  & \textbf{OPTICS} \\
\midrule
\textbf{Conan Exiles}        & 17.8\%           & 21.9\%      \\
\textbf{DayZ}                & 23.2\%           & 36.6\%        \\
\textbf{New World}           & 28.0\%           & 46.0\%       \\
\textbf{Average}             & 23.0\%           & 34.8\%     \\
\bottomrule
\end{tabular}
%}
\end{table}

\begin{table}[h]
\centering
\caption{\RQ{3}: MoJoFM achived for clustering by context with SSIM}
\label{tab:context_clustering}
%\resizebox{\linewidth}{!}{%
\begin{tabular}{l r r}
\toprule
                             & \textbf{DBSCAN}  & \textbf{OPTICS}  \\
\midrule
\textbf{Conan Exiles}        & 4.8\%           & 21.9\%       \\
\textbf{DayZ}                & 0.0\%           & 2.5\%        \\
\textbf{New World}           & 0.0\%           & 18.5\%       \\
\textbf{Average}             & 1.6\%           & 14.3\%        \\
\bottomrule
\end{tabular}
%}
\end{table}

\begin{resultbox}
 \textbf{Answer to \RQ{3}.} We obtained mixed results for the clustering by context step because its performance strongly depends on the video game at hand.
\end{resultbox}

\subsection{\RQ{4}: Clustering Gameplay Video Segments by Specific Issues}
\tabref{tab:issue_clustering} shows the MoJoFM score achieved by the three tested algorithms when comparing their output with the manually defined clusters. 
In this case, the results are definitely better than the ones obtained in the previous experiment, with the best-performing algorithm (DBSCAN) achieving 72.7\% MoJoFM score. This is due to the fact that, in this case, there were less instances to cluster for two of the games taken into account (DayZ and New World). As a result, the task was inherently easier. It is worth noting, however, that for Conan Exiles the number of instances to cluster was quite large, in some cases, up to 18 and DBSCAN still achieves very good results (71.2\% MoJoFM).

Differently from what observed for \RQ{3}, we have a much less marked variance among the games (between 69.1\% and 77.8\%). OPTICS, in this case, achieved slightly worse results than DBSCAN, while MeanShift is clearly less effective than the others.

\begin{table} [h]
\centering
\caption{\RQ{4}: MoJoFM achived for clustering on the specific-issue.}
\label{tab:issue_clustering}
%\resizebox{\linewidth}{!}{%
\begin{tabular}{lrrrr}
\toprule
                             & \textbf{DBSCAN}  & \textbf{OPTICS}    & \textbf{MeanShift} \\
\midrule                                                             
\textbf{Conan Exiles}        & 71.2\%           & 62.5\%             & 52.9\%             \\
\textbf{DayZ}                & 69.1\%           & 69.1\%             & 58.2\%             \\
\textbf{New World}           & 77.8\%           & 77.8\%             & 55.6\%             \\
\textbf{Average}             & 72.7\%           & 69.8\%             & 55.5\%             \\
\bottomrule
\end{tabular}
%}
\end{table}

\begin{resultbox}
 \textbf{Answer to \RQ{4}.} DBSCAN allows to cluster the segments very similarly to how human annotators clustered them, with a low variability among video games.
\end{resultbox}
