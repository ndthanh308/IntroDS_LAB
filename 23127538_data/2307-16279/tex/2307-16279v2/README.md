# Revision
## Reviewer 1
1. The authors analyze the impact of errors from finite sampling and from performing the projection. At least two other error sources seem relevant, and worthy of additional discussion and analysis:
    (DONE)a. The first is Trotter error. The authors do comment on this, e.g., analyzing the (asymptotic) circuit depth required for obtaining “low enough” Trotter error to use the (more favorable) Toeplitz construction in Eq. (43). However, what if this “low enough” criterion is not met? Can the authors analyze the tradeoffs (even if only numerically)? For example, I can imagine early fault tolerant regimes where satisfying Eq. (43) may not be feasible, and readers could benefit from an understanding of how crucial this criterion is in practice, and what the impacts are when one deviates from it.
b. The second is hardware error/decoherence. A defining feature of the early fault tolerant regime is that we will still be somewhat limited by noise, just less so relative to the present NISQ era. How will the presence of a low but nonzero hardware error rate impact the results in QKSD? Analyzing this would help readers understand an important aspect of QKSD implementations in the early FT era.

2. As mentioned above, a potential impact I see of this work is in driving progress in analyzing other quantum algorithms that involve repeated sampling. The authors also point to this, to some extent, in the conclusion. I think this warrants further elaboration: can the authors be more detailed in their speculation? The more ideas that the authors have for how to extend these types of analyses to new domains, the more interest and impact their paper is likely to generate.

    (DONE) 3. The authors state “However, in the numerical simulation, the condition number d_0^−1 remained large and amplified the sampling error, even though the thresholding alleviated the ill-conditioning. Although little is known about d_0^−1 for the subspace generated by time evolution, it appears to exhibit an exponentially increasing behavior with n, in many cases in the numerical results (Sec. VC). Thus, a significantly large number of Hadamard test samples are required.” The authors then introduce an alternative quantity, cond(S), which they say can overcome a lack of knowledge about d_0^-1. Since d_0^-1 is used throughout the paper, how does the use of cond(S) fit in with e.g. Thm 1 and Thm 5? Furthermore, do the authors expect their findings regarding the scaling of d_0^−1 to be general, or specific to their numerical analyses involving the Hubbard model? Have the authors found problem instances where the scaling is more favorable?

    (DONE) 4. The authors state “Unitary partitioning offers an advantage over the individual measurements of Pauli operators in terms of sampling noise.” Can they elaborate on this or provide a citation?

    (DONE) 5. Below Equation 26 and above the beginning of subsection “B”: it would be good to further discuss/interpret Equations 25-26 for the reader.

6. The authors study different instances of the Fermi-Hubbard model, noting that the “the (0.1, 0.8) case, which is known to be difficult to solve”. Can the authors include a reference for this statement?


## Reviewer 2

    (DONE) 1. Some citation/proof of Eq (3) would be helpful.
    - Added a brief proof.

    (DONE) 2. In section III A, in the last paragraph of the first column of page 4, you introduce the matrices \tilde{A}, \tilde{B} but you never define them. Also, in Theorem 1, I would clarify that you obtain those from algorithm 1 (if that is the case, otherwise the notation feels a little confusing).
    - Annotated that \tilde{A} and \tilde{B} is the output of BasisThresholding(\tilde{H}, \tilde{S}, \epsilon).

    (DONE) 3. In Eq. (15), is there a reason why the smallest eigenvalue B cannot diverge? Otherwise this bound becomes infinity.
    - Added an assumption that B is positive definite in Theorem 1 and 6. Furthermore, B is obtained from the thresholding, so the smallest eigenvalue can not be smaller than \epsilon.

4. In Eqs. (25 – 26), why do you allocate the same numbers in the real and imaginary part in the off-diagonal sampling? Also, it would be helpful if you were to define the sampling variances. Not the result, but the actual definition.
    - 

    (DONE) 5. Eq. (35) hides, in some way, the actual scaling of the bound. Because �" can increase
    exponential it feels like this bound can become trivial. Is this a flaw of the bound? Or
    is it actually observed? I would appreciate further development on this topic. Also, a
    lower-bound would be helpful in this regard. If the lower bound increases
    exponentially, you can see that this is not a flaw of the bound. This is the point I am
    more concerned about. 

    (DONE) 6. It is not clear to me how do you get Eq. (42). That is how do you reach it and why does it work?

(Can not understand) 7. Before Eq. (D13) is it possible that m is actually m(n)?