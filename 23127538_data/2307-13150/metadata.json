{
  "title": "Pilot Performance modeling via observer-based inverse reinforcement learning",
  "authors": [
    "Jared Town",
    "Zachary Morrison",
    "Rushikesh Kamalapurkar"
  ],
  "submission_date": "2023-07-24T22:34:35+00:00",
  "revised_dates": [],
  "abstract": "The focus of this paper is behavior modeling for pilots of unmanned aerial vehicles. The pilot is assumed to make decisions that optimize an unknown cost functional, which is estimated from observed trajectories using a novel inverse reinforcement learning (IRL) framework. The resulting IRL problem often admits multiple solutions. In this paper, a recently developed novel IRL observer is adapted to the pilot modeling problem. The observer is shown to converge to one of the equivalent solutions of the IRL problem. The developed technique is implemented on a quadcopter where the pilot is a linear quadratic supervisory controller that generates velocity commands for the quadcopter to travel to and hover over a desired location. Experimental results demonstrate the robustness of the method and its ability to learn equivalent cost functionals.",
  "categories": [
    "eess.SY",
    "math.OC"
  ],
  "primary_category": "eess.SY",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13150",
  "pdf_url": null,
  "comment": "arXiv admin note: text overlap with arXiv:2210.16299",
  "num_versions": null,
  "size_before_bytes": 3899046,
  "size_after_bytes": 2201985
}