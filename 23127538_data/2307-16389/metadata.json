{
  "title": "STL: A Signed and Truncated Logarithm Activation Function for Neural Networks",
  "authors": [
    "Yuanhao Gong"
  ],
  "submission_date": "2023-07-31T03:41:14+00:00",
  "revised_dates": [],
  "abstract": "Activation functions play an essential role in neural networks. They provide the non-linearity for the networks. Therefore, their properties are important for neural networks' accuracy and running performance. In this paper, we present a novel signed and truncated logarithm function as activation function. The proposed activation function has significantly better mathematical properties, such as being odd function, monotone, differentiable, having unbounded value range, and a continuous nonzero gradient. These properties make it an excellent choice as an activation function. We compare it with other well-known activation functions in several well-known neural networks. The results confirm that it is the state-of-the-art. The suggested activation function can be applied in a large range of neural networks where activation functions are necessary.",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CE",
    "cs.CL",
    "cs.CV",
    "cs.NE"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16389",
  "pdf_url": "https://arxiv.org/pdf/2307.16389v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 119245,
  "size_after_bytes": 37967
}