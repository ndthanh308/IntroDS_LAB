@inproceedings{Dai2020SlicedIN,
  title={Sliced Iterative Normalizing Flows},
  author={Biwei Dai and Uros Seljak},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@misc{kingma2022autoencoding,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{kingma2018glow,
      title={Glow: Generative Flow with Invertible 1x1 Convolutions}, 
      author={Diederik P. Kingma and Prafulla Dhariwal},
      year={2018},
      eprint={1807.03039},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{dinh2017density,
      title={Density estimation using Real NVP}, 
      author={Laurent Dinh and Jascha Sohl-Dickstein and Samy Bengio},
      year={2017},
      eprint={1605.08803},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{grathwohl2018ffjord,
      title={FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models}, 
      author={Will Grathwohl and Ricky T. Q. Chen and Jesse Bettencourt and Ilya Sutskever and David Duvenaud},
      year={2018},
      eprint={1810.01367},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{durkan2019neural,
      title={Neural Spline Flows}, 
      author={Conor Durkan and Artur Bekasov and Iain Murray and George Papamakarios},
      year={2019},
      eprint={1906.04032},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{chen2020residual,
      title={Residual Flows for Invertible Generative Modeling}, 
      author={Ricky T. Q. Chen and Jens Behrmann and David Duvenaud and Jörn-Henrik Jacobsen},
      year={2020},
      eprint={1906.02735},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{sukthanker2022generative,
      title={Generative Flows with Invertible Attentions}, 
      author={Rhea Sanjay Sukthanker and Zhiwu Huang and Suryansh Kumar and Radu Timofte and Luc Van Gool},
      year={2022},
      eprint={2106.03959},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{lee2020nanoflow,
      title={NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity}, 
      author={Sanggil Lee and Sungwon Kim and Sungroh Yoon},
      year={2020},
      eprint={2006.06280},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{meng2020gaussianization,
      title={Gaussianization Flows}, 
      author={Chenlin Meng and Yang Song and Jiaming Song and Stefano Ermon},
      year={2020},
      eprint={2003.01941},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Laparra_2011,
	doi = {10.1109/tnn.2011.2106511},
  
	url = {https://doi.org/10.1109%2Ftnn.2011.2106511},
  
	year = 2011,
	month = {apr},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {22},
  
	number = {4},
  
	pages = {537--549},
  
	author = {V Laparra and G Camps-Valls and J Malo},
  
	title = {Iterative Gaussianization: From {ICA} to Random Rotations},
  
	journal = {{IEEE} Transactions on Neural Networks}
}

@misc{papamakarios2018masked,
      title={Masked Autoregressive Flow for Density Estimation}, 
      author={George Papamakarios and Theo Pavlakou and Iain Murray},
      year={2018},
      eprint={1705.07057},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@article{chen2000gaussianization,
  title={Gaussianization},
  author={Chen, Scott and Gopinath, Ramesh},
  journal={Advances in neural information processing systems},
  volume={13},
  year={2000}
}

@misc{karras2019stylebased,
      title={A Style-Based Generator Architecture for Generative Adversarial Networks}, 
      author={Tero Karras and Samuli Laine and Timo Aila},
      year={2019},
      eprint={1812.04948},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{behrmann2019invertible,
      title={Invertible Residual Networks}, 
      author={Jens Behrmann and Will Grathwohl and Ricky T. Q. Chen and David Duvenaud and Jörn-Henrik Jacobsen},
      year={2019},
      eprint={1811.00995},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{hearst1998support,
  title={Support vector machines},
  author={Hearst, Marti A. and Dumais, Susan T and Osuna, Edgar and Platt, John and Scholkopf, Bernhard},
  journal={IEEE Intelligent Systems and their applications},
  volume={13},
  number={4},
  pages={18--28},
  year={1998},
  publisher={IEEE}
}

@book{young1988introduction,
  title={An introduction to Hilbert space},
  author={Young, Nicholas},
  year={1988},
  publisher={Cambridge university press}
}

@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}
@misc{hensman2013gaussian,
      title={Gaussian Processes for Big Data}, 
      author={James Hensman and Nicolo Fusi and Neil D. Lawrence},
      year={2013},
      eprint={1309.6835},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@misc{damianou2013deep,
      title={Deep Gaussian Processes}, 
      author={Andreas C. Damianou and Neil D. Lawrence},
      year={2013},
      eprint={1211.0358},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{maroñas2021transforming,
      title={Transforming Gaussian Processes With Normalizing Flows}, 
      author={Juan Maroñas and Oliver Hamelijnck and Jeremias Knoblauch and Theodoros Damoulas},
      year={2021},
      eprint={2011.01596},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{klein2022generative,
      title={Generative structured normalizing flow Gaussian processes applied to spectroscopic data}, 
      author={Natalie Klein and Nishant Panda and Patrick Gasda and Diane Oyen},
      year={2022},
      eprint={2212.07554},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{platt1998sequential,
  title={Sequential minimal optimization: A fast algorithm for training support vector machines},
  author={Platt, John},
  year={1998}
}

@misc{germain2015made,
      title={MADE: Masked Autoencoder for Distribution Estimation}, 
      author={Mathieu Germain and Karol Gregor and Iain Murray and Hugo Larochelle},
      year={2015},
      eprint={1502.03509},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
ger
@InProceedings{pmlr-v162-meng22a,
  title = 	 {{B}utterfly{F}low: Building Invertible Layers with Butterfly Matrices},
  author =       {Meng, Chenlin and Zhou, Linqi and Choi, Kristy and Dao, Tri and Ermon, Stefano},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {15360--15375},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/meng22a/meng22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/meng22a.html},
  abstract = 	 {Normalizing flows model complex probability distributions using maps obtained by composing invertible layers. Special linear layers such as masked and 1{\texttimes}1 convolutions play a key role in existing architectures because they increase expressive power while having tractable Jacobians and inverses. We propose a new family of invertible linear layers based on butterfly layers, which are known to theoretically capture complex linear structures including permutations and periodicity, yet can be inverted efficiently. This representational power is a key advantage of our approach, as such structures are common in many real-world datasets. Based on our invertible butterfly layers, we construct a new class of normalizing flow mod- els called ButterflyFlow. Empirically, we demonstrate that ButterflyFlows not only achieve strong density estimation results on natural images such as MNIST, CIFAR-10, and ImageNet-32{\texttimes}32, but also obtain significantly better log-likelihoods on structured datasets such as galaxy images and MIMIC-III patient cohorts{—}all while being more efficient in terms of memory and computation than relevant baselines.}
}

@article{JMLR:v6:quinonero-candela05a,
  author  = {Joaquin Qui{{\~n}}onero-Candela and Carl Edward Rasmussen},
  title   = {A Unifying View of Sparse Approximate Gaussian Process Regression},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {65},
  pages   = {1939--1959},
  url     = {http://jmlr.org/papers/v6/quinonero-candela05a.html}
}

@misc{huang2021forward,
      title={Forward Operator Estimation in Generative Models with Kernel Transfer Operators}, 
      author={Zhichun Huang and Rudrasis Chakraborty and Vikas Singh},
      year={2021},
      eprint={2112.00305},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}




@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{ho2019flow++,
  title={Flow++: Improving flow-based generative models with variational dequantization and architecture design},
  author={Ho, Jonathan and Chen, Xi and Srinivas, Aravind and Duan, Yan and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={2722--2730},
  year={2019},
  organization={PMLR}
}

@inproceedings{scholkopf2001generalized,
  title={A generalized representer theorem},
  author={Sch{\"o}lkopf, Bernhard and Herbrich, Ralf and Smola, Alex J},
  booktitle={Computational Learning Theory: 14th Annual Conference on Computational Learning Theory, COLT 2001 and 5th European Conference on Computational Learning Theory, EuroCOLT 2001 Amsterdam, The Netherlands, July 16--19, 2001 Proceedings 14},
  pages={416--426},
  year={2001},
  organization={Springer}
}

@book{scholkopf2002learning,
  title={Learning with kernels: support vector machines, regularization, optimization, and beyond},
  author={Sch{\"o}lkopf, Bernhard and Smola, Alexander J and Bach, Francis and others},
  year={2002},
  publisher={MIT press}
}

@article{vishwanathan2010graph,
  title={Graph kernels},
  author={Vishwanathan, S Vichy N and Schraudolph, Nicol N and Kondor, Risi and Borgwardt, Karsten M},
  journal={Journal of Machine Learning Research},
  volume={11},
  pages={1201--1242},
  year={2010},
  publisher={MIT Press}
}
@inproceedings{wilson2016deep,
  title={Deep kernel learning},
  author={Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={Artificial intelligence and statistics},
  pages={370--378},
  year={2016},
  organization={PMLR}
}
@inproceedings{wenliang2019learning,
  title={Learning deep kernels for exponential family densities},
  author={Wenliang, Li and Sutherland, Danica J and Strathmann, Heiko and Gretton, Arthur},
  booktitle={International Conference on Machine Learning},
  pages={6737--6746},
  year={2019},
  organization={PMLR}
}

@article{Flux.jl-2018,
  author    = {Michael Innes and
               Elliot Saba and
               Keno Fischer and
               Dhairya Gandhi and
               Marco Concetto Rudilosso and
               Neethu Mariya Joy and
               Tejan Karmali and
               Avik Pal and
               Viral Shah},
  title     = {Fashionable Modelling with Flux},
  journal   = {CoRR},
  volume    = {abs/1811.01457},
  year      = {2018},
  url       = {https://arxiv.org/abs/1811.01457},
  archivePrefix = {arXiv},
  eprint    = {1811.01457},
  timestamp = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-01457},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{hansen2022normalizing,
  title={Normalizing flows for knockoff-free controlled feature selection},
  author={Hansen, Derek and Manzo, Brian and Regier, Jeffrey},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16125--16137},
  year={2022}
}
@article{kirchler2022training,
  title={Training Normalizing Flows from Dependent Data},
  author={Kirchler, Matthias and Lippert, Christoph and Kloft, Marius},
  journal={arXiv preprint arXiv:2209.14933},
  year={2022}
}

@article{sonnenburg2006large,
  title={Large scale multiple kernel learning},
  author={Sonnenburg, S{\"o}ren and R{\"a}tsch, Gunnar and Sch{\"a}fer, Christin and Sch{\"o}lkopf, Bernhard},
  journal={The Journal of Machine Learning Research},
  volume={7},
  pages={1531--1565},
  year={2006},
  publisher={JMLR. org}
}

@article{DBLP:journals/corr/abs-2007-00674,
  author       = {Biwei Dai and
                  Uros Seljak},
  title        = {Sliced Iterative Generator},
  journal      = {CoRR},
  volume       = {abs/2007.00674},
  year         = {2020},
  url          = {https://arxiv.org/abs/2007.00674},
  eprinttype    = {arXiv},
  eprint       = {2007.00674},
  timestamp    = {Mon, 06 Jul 2020 15:26:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2007-00674.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{papamakarios2021normalizing,
      title={Normalizing Flows for Probabilistic Modeling and Inference}, 
      author={George Papamakarios and Eric Nalisnick and Danilo Jimenez Rezende and Shakir Mohamed and Balaji Lakshminarayanan},
      year={2021},
      eprint={1912.02762},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{Kobyzev_2021,
	doi = {10.1109/tpami.2020.2992934},
  
	url = {https://doi.org/10.1109%2Ftpami.2020.2992934},
  
	year = 2021,
	month = {nov},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {43},
  
	number = {11},
  
	pages = {3964--3979},
  
	author = {Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker},
  
	title = {Normalizing Flows: An Introduction and Review of Current Methods},
  
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@misc{misc_individual_household_electric_power_consumption_235,
  author       = {Hebrail,Georges and Berard,Alice},
  title        = {{Individual household electric power consumption}},
  year         = {2012},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C58K54}
}

@article{FONOLLOSA2015618,
title = {Reservoir computing compensates slow response of chemosensor arrays exposed to fast varying gas concentrations in continuous monitoring},
journal = {Sensors and Actuators B: Chemical},
volume = {215},
pages = {618-629},
year = {2015},
issn = {0925-4005},
doi = {https://doi.org/10.1016/j.snb.2015.03.028},
url = {https://www.sciencedirect.com/science/article/pii/S0925400515003524},
author = {Jordi Fonollosa and Sadique Sheik and Ram√≥n Huerta and Santiago Marco},
keywords = {Electronic nose, Chemical sensors, Reservoir computing, Continuous gas prediction, Real-time detection},
abstract = {Metal oxide (MOX) gas sensors arrays are a predominant technological choice to perform fundamental tasks of chemical detection. Yet, their use has been mainly limited to relatively controlled instrument configurations where the sensor array is placed within a closed measurement chamber. Usually, the experimental protocol is defined beforehand and it includes three stages: the array is first exposed to a gas reference, then to the gas sample, and finally to the reference again to recover the initial state. Such sampling procedure requires signal acquisition during the complete experimental protocol and usually delays the output prediction until the predefined measurement duration is complete. Due to the slow time response of chemical sensors, the completion of the measurement typically requires minutes. In this paper we propose the use of reservoir computing (RC) algorithms to overcome the slow temporal dynamics of chemical sensor arrays, allowing identification and quantification of chemicals of interest continuously and reducing measurement delays. We generated two datasets to test the ability of RC algorithms to provide accurate and continuous prediction to fast varying gas concentrations in real time. Both datasets ‚Äì one generated with synthetic data and the other acquired from actual gas sensors ‚Äì provide time series of MOX sensors exposed to binary gas mixtures where concentration levels change randomly over time. Our results show that our approach improves the time response of the sensory system and provides accurate predictions in real time, making the system specifically suitable for online monitoring applications. Finally, the collected dataset and developed code are made publicly available to the research community for further studies.}
}

@article{Baldi_2016,
	doi = {10.1140/epjc/s10052-016-4099-4},
  
	url = {https://doi.org/10.1140%2Fepjc%2Fs10052-016-4099-4},
  
	year = 2016,
	month = {apr},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {76},
  
	number = {5},
  
	author = {Pierre Baldi and Kyle Cranmer and Taylor Faucett and Peter Sadowski and Daniel Whiteson},
  
	title = {Parameterized neural networks for high-energy physics},
  
	journal = {The European Physical Journal C}
}

@article{Roe_2005,
	doi = {10.1016/j.nima.2004.12.018},
  
	url = {https://doi.org/10.1016%2Fj.nima.2004.12.018},
  
	year = 2005,
	month = {may},
  
	publisher = {Elsevier {BV}
},
  
	volume = {543},
  
	number = {2-3},
  
	pages = {577--584},
  
	author = {Byron P. Roe and Hai-Jun Yang and Ji Zhu and Yong Liu and Ion Stancu and Gordon McGregor},
  
	title = {Boosted decision trees as an alternative to artificial neural networks for particle identification},
  
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment}
}

@misc{uria2014rnade,
      title={RNADE: The real-valued neural autoregressive density-estimator}, 
      author={Benigno Uria and Iain Murray and Hugo Larochelle},
      year={2014},
      eprint={1306.0186},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@INPROCEEDINGS{937655,
  author={Martin, D. and Fowlkes, C. and Tal, D. and Malik, J.},
  booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001}, 
  title={A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics}, 
  year={2001},
  volume={2},
  number={},
  pages={416-423 vol.2},
  doi={10.1109/ICCV.2001.937655}}

@online{clanuwat2018deep,
  author       = {Tarin Clanuwat and Mikel Bober-Irizar and Asanobu Kitamoto and Alex Lamb and Kazuaki Yamamoto and David Ha},
  title        = {Deep Learning for Classical Japanese Literature},
  date         = {2018-12-03},
  year         = {2018},
  eprintclass  = {cs.CV},
  eprinttype   = {arXiv},
  eprint       = {cs.CV/1812.01718},
}
@article{8f1d51a8c3974c15a75b78320bffac08,
title = "The UK Biobank resource with deep phenotyping and genomic data",
abstract = "The UK Biobank project is a prospective cohort study with deep genetic and phenotypic data collected on approximately 500,000 individuals from across the United Kingdom, aged between 40 and 69 at recruitment. The open resource is unique in its size and scope. A rich variety of phenotypic and health-related information is available on each participant, including biological measurements, lifestyle indicators, biomarkers in blood and urine, and imaging of the body and brain. Follow-up information is provided by linking health and medical records. Genome-wide genotype data have been collected on all participants, providing many opportunities for the discovery of new genetic associations and the genetic bases of complex traits. Here we describe the centralized analysis of the genetic data, including genotype quality, properties of population structure and relatedness of the genetic data, and efficient phasing and genotype imputation that increases the number of testable variants to around 96 million. Classical allelic variation at 11 human leukocyte antigen genes was imputed, resulting in the recovery of signals with known associations between human leukocyte antigen alleles and many diseases.",
author = "Clare Bycroft and Colin Freeman and Desislava Petkova and Gavin Band and Elliott, {Lloyd T.} and Kevin Sharp and Allan Motyer and Damjan Vukcevic and Olivier Delaneau and Jared O{\textquoteright}Connell and Adrian Cortes and Samantha Welsh and Alan Young and Mark Effingham and Gil McVean and Stephen Leslie and Naomi Allen and Peter Donnelly and Jonathan Marchini",
note = "Funding Information: Acknowledgements We acknowledge Wellcome Trust Core Awards 090532/Z/09/Z and 203141/Z/16/Z and grants 095552/Z/11/Z (to P.D.), 100956/Z/13/Z (to G.M.) and 100308/Z/12/Z (to A.C.). J.M. is supported by European Research Council grant 617306. S.L. is supported by Australian NHMRC Career Development Fellowship 1053756. The sample processing and genotyping was supported by the National Institute for Health Research, Medical Research Council, and British Heart Foundation. We thank the Research Computing Core at the Wellcome Centre for Human Genetics for assistance with the computational workload. We thank Affymetrix for discussions concerning quality control. We thank A. Young, A. Dilthey and L. Moutsianas for their assistance with aspects of the data analysis. We acknowledge UK Biobank co-ordinating centre staff for their role in extracting the DNA for this project. We thank M. Kuzma-Kuzniarska (http://mybioscience. org/) for Fig. 1. Publisher Copyright: {\textcopyright} 2018, Springer Nature Limited.",
year = "2018",
month = oct,
doi = "10.1038/s41586-018-0579-z",
language = "English",
volume = "562",
pages = "203--209",
journal = "Nature",
issn = "0028-0836",
publisher = "Nature Publishing Group",
number = "7726",
}

@inproceedings{Krizhevsky2009LearningML,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:18268744}
}
@misc{english2023mixerflow,
      title={MixerFlow for Image Modelling}, 
      author={Eshant English and Matthias Kirchler and Christoph Lippert},
      year={2023},
      eprint={2310.16777},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{rudi2021psd,
      title={PSD Representations for Effective Probability Models}, 
      author={Alessandro Rudi and Carlo Ciliberto},
      year={2021},
      eprint={2106.16116},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{marteauferey2021sampling,
      title={Sampling from Arbitrary Functions via PSD Models}, 
      author={Ulysse Marteau-Ferey and Francis Bach and Alessandro Rudi},
      year={2021},
      eprint={2110.10527},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{tsuchida2023squared,
      title={Squared Neural Families: A New Class of Tractable Density Models}, 
      author={Russell Tsuchida and Cheng Soon Ong and Dino Sejdinovic},
      year={2023},
      eprint={2305.13552},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}