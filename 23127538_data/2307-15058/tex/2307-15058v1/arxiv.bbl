\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{barron_mip-nerf_2021}
Barron, J.T., Mildenhall, B., Tancik, M., Hedman, P., Martin-Brualla, R.,
  Srinivasan, P.P.: Mip-{NeRF}: {A} {Multiscale} {Representation} for
  {Anti}-{Aliasing} {Neural} {Radiance} {Fields}. In: 2021 {IEEE}/{CVF}
  {International} {Conference} on {Computer} {Vision} ({ICCV}). pp. 5835--5844
  (Oct 2021)

\bibitem{barron_mip-nerf_2022}
Barron, J.T., Mildenhall, B., Verbin, D., Srinivasan, P.P., Hedman, P.:
  Mip-{NeRF} 360: {Unbounded} {Anti}-{Aliased} {Neural} {Radiance} {Fields}.
  In: Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and
  {Pattern} {Recognition}. arXiv (Mar 2022)

\bibitem{cabon_virtual_2020}
Cabon, Y., Murray, N., Humenberger, M.: Virtual {KITTI} 2,
  \url{http://arxiv.org/abs/2001.10773}

\bibitem{chen_tensorf_2022}
Chen, A., Xu, Z., Geiger, A., Yu, J., Su, H.: {TensoRF}: {Tensorial} {Radiance}
  {Fields}. In: Computer {Vision} – {ECCV} 2022: 17th {European}
  {Conference}, {Tel} {Aviv}, {Israel}, {October} 23–27, 2022, {Proceedings},
  {Part} {XXXII}. pp. 333--350. Springer-Verlag, Berlin, Heidelberg (2022)

\bibitem{chen_pq-transformer_2022}
Chen, X., Zhao, H., Zhou, G., Zhang, Y.Q.: {PQ}-{Transformer}: {Jointly}
  {Parsing} {3D} {Objects} and {Layouts} {From} {Point} {Clouds}. IEEE Robotics
  and Automation Letters  \textbf{7}(2),  2519--2526 (Apr 2022)

\bibitem{chen_geosim_2021}
Chen, Y., Rong, F., Duggal, S., Wang, S., Yan, X., Manivasagam, S., Xue, S.,
  Yumer, E., Urtasun, R.: {GeoSim}: {Realistic} {Video} {Simulation} via
  {Geometry}-{Aware} {Composition} for {Self}-{Driving},
  \url{http://arxiv.org/abs/2101.06543}

\bibitem{deng_depth-supervised_2022}
Deng, K., Liu, A., Zhu, J.Y., Ramanan, D.: Depth-supervised {NeRF}: {Fewer}
  {Views} and {Faster} {Training} for {Free}. In: 2022 {IEEE}/{CVF}
  {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}). pp.
  12872--12881 (Jun 2022)

\bibitem{dosovitskiy_carla_2017}
Dosovitskiy, A., Ros, G., Codevilla, F., Lopez, A., Koltun, V.: {CARLA}: {An}
  {Open} {Urban} {Driving} {Simulator}. In: Proceedings of the 1st {Annual}
  {Conference} on {Robot} {Learning}. pp. 1--16. PMLR (Oct 2017)

\bibitem{fridovich-keil_k-planes_2023}
Fridovich-Keil, S., Meanti, G., Warburg, F., Recht, B., Kanazawa, A.:
  K-{Planes}: {Explicit} {Radiance} {Fields} in {Space}, {Time}, and
  {Appearance}. In: Computer {Vision} {And} {Pattern} {Recognition}, 2023
  (2023)

\bibitem{fu_panoptic_2022}
Fu, X., Zhang, S., Chen, T., Lu, Y., Zhu, L., Zhou, X., Geiger, A., Liao, Y.:
  Panoptic {NeRF}: {3D}-to-{2D} {Label} {Transfer} for {Panoptic} {Urban}
  {Scene} {Segmentation}. In: 2022 {International} {Conference} on {3D}
  {Vision} ({3DV}). pp. 1--11 (Sep 2022)

\bibitem{geiger_vision_2013}
Geiger, A., Lenz, P., Stiller, C., Urtasun, R.: Vision meets robotics: {The}
  {KITTI} dataset. International Journal of Robotics Research  \textbf{32}(11),
   1231--1237 (2013)

\bibitem{geiger_are_2012}
Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? {The}
  {KITTI} vision benchmark suite. In: 2012 {IEEE} {Conference} on {Computer}
  {Vision} and {Pattern} {Recognition}. pp. 3354--3361 (Jun 2012)

\bibitem{hu_planning-oriented_2023}
Hu, Y., Yang, J., Chen, L., Li, K., Sima, C., Zhu, X., Chai, S., Du, S., Lin,
  T., Wang, W., Lu, L., Jia, X., Liu, Q., Dai, J., Qiao, Y., Li, H.:
  Planning-{Oriented} {Autonomous} {Driving}. In: Proceedings of the
  {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}.
  pp. 17853--17862 (2023)

\bibitem{jin_adapt_2023}
Jin, B., Liu, X., Zheng, Y., Li, P., Zhao, H., Zhang, T., Zheng, Y., Zhou, G.,
  Liu, J.: {ADAPT}: {Action}-aware {Driving} {Caption} {Transformer}. In: 2023
  {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA}).
  pp. 7554--7561 (May 2023)

\bibitem{kundu_panoptic_2022}
Kundu, A., Genova, K., Yin, X., Fathi, A., Pantofaru, C., Guibas, L.J.,
  Tagliasacchi, A., Dellaert, F., Funkhouser, T.: Panoptic {Neural} {Fields}:
  {A} {Semantic} {Object}-{Aware} {Neural} {Scene} {Representation}. In:
  Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and
  {Pattern} {Recognition}. pp. 12871--12881 (2022)

\bibitem{li_lode_2023}
Li, P., Zhao, R., Shi, Y., Zhao, H., Yuan, J., Zhou, G., Zhang, Y.Q.: {LODE}:
  {Locally} {Conditioned} {Eikonal} {Implicit} {Scene} {Completion} from
  {Sparse} {LiDAR}. In: 2023 {IEEE} {International} {Conference} on {Robotics}
  and {Automation} ({ICRA}). arXiv (Feb 2023)

\bibitem{li_aads_2019}
Li, W., Pan, C.W., Zhang, R., Ren, J.P., Ma, Y.X., Fang, J., Yan, F.L., Geng,
  Q.C., Huang, X.Y., Gong, H.J., Xu, W.W., Wang, G.P., Manocha, D., Yang, R.G.:
  {AADS}: {Augmented} autonomous driving simulation using data-driven
  algorithms. Science Robotics  \textbf{4}(28),  eaaw0863 (Mar 2019)

\bibitem{mildenhall_nerf_2020}
Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T., Ramamoorthi, R.,
  Ng, R.: {NeRF}: {Representing} {Scenes} as {Neural} {Radiance} {Fields} for
  {View} {Synthesis}. In: Vedaldi, A., Bischof, H., Brox, T., Frahm, J.M.
  (eds.) Computer {Vision} – {ECCV} 2020. pp. 405--421. Lecture {Notes} in
  {Computer} {Science}, Springer International Publishing, Cham (2020)

\bibitem{muller_instant_2022}
Müller, T., Evans, A., Schied, C., Keller, A.: Instant neural graphics
  primitives with a multiresolution hash encoding. ACM Transactions on Graphics
   \textbf{41}(4),  1--15 (Jul 2022)

\bibitem{niemeyer_giraffe_2021}
Niemeyer, M., Geiger, A.: {GIRAFFE}: {Representing} {Scenes} {As}
  {Compositional} {Generative} {Neural} {Feature} {Fields}. In: Proceedings of
  the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern}
  {Recognition}. pp. 11453--11464 (2021)

\bibitem{ost_neural_2021}
Ost, J., Mannan, F., Thuerey, N., Knodt, J., Heide, F.: Neural {Scene} {Graphs}
  for {Dynamic} {Scenes}. In: Proceedings of the {IEEE}/{CVF} {Conference} on
  {Computer} {Vision} and {Pattern} {Recognition}. arXiv (Mar 2021)

\bibitem{rematas_urban_2022}
Rematas, K., Liu, A., Srinivasan, P., Barron, J., Tagliasacchi, A., Funkhouser,
  T., Ferrari, V.: Urban {Radiance} {Fields}. In: 2022 {IEEE}/{CVF}
  {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}). pp.
  12922--12932 (Jun 2022)

\bibitem{tancik_nerfstudio_2023}
Tancik, M., Weber, E., Ng, E., Li, R., Yi, B., Kerr, J., Wang, T.,
  Kristoffersen, A., Austin, J., Salahi, K., Ahuja, A., McAllister, D.,
  Kanazawa, A.: Nerfstudio: {A} {Modular} {Framework} for {Neural} {Radiance}
  {Field} {Development}. ACM Transactions on Graphics  \textbf{1}(1) (May 2023)

\bibitem{10160470}
Tian, B., Liu, M., Gao, H.a., Li, P., Zhao, H., Zhou, G.: Unsupervised road
  anomaly detection with language anchors. In: 2023 {IEEE} international
  conference on robotics and automation ({ICRA}). pp. 7778--7785 (2023)

\bibitem{tian_vibus_2022}
Tian, B., Luo, L., Zhao, H., Zhou, G.: {VIBUS}: {Data}-efficient {3D} {Scene}
  {Parsing} with {VIewpoint} {Bottleneck} and {Uncertainty}-{Spectrum}
  {Modeling}. Journal of Photogrammetry and Remote Sensing  (Oct 2022)

\bibitem{turki_suds_2023}
Turki, H., Zhang, J.Y., Ferroni, F., Ramanan, D.: {SUDS}: {Scalable} {Urban}
  {Dynamic} {Scenes}. In: Proceedings of the {IEEE}/{CVF} {Conference} on
  {Computer} {Vision} and {Pattern} {Recognition}. arXiv (Mar 2023)

\bibitem{wang_f2-nerf_2023}
Wang, P., Liu, Y., Chen, Z., Liu, L., Liu, Z., Komura, T., Theobalt, C., Wang,
  W.: F\${\textasciicircum}\{2\}\$-{NeRF}: {Fast} {Neural} {Radiance} {Field}
  {Training} with {Free} {Camera} {Trajectories}. In: Proceedings of the
  {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}
  (Mar 2023)

\bibitem{xie_s-nerf_2023}
Xie, Z., Zhang, J., Li, W., Zhang, F., Zhang, L.: S-{NeRF}: {Neural} {Radiance}
  {Fields} for {Street} {Views}. In: The {Eleventh} {International}
  {Conference} on {Learning} {Representations} (Feb 2023)

\bibitem{yang_unisim_2023}
Yang, Z., Chen, Y., Wang, J., Manivasagam, S., Ma, W.C., Yang, A.J., Urtasun,
  R.: {UniSim}: {A} {Neural} {Closed}-{Loop} {Sensor} {Simulator}. In:
  Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and
  {Pattern} {Recognition}. pp. 1389--1399 (2023)

\bibitem{yu_dair-v2x_2022}
Yu, H., Luo, Y., Shu, M., Huo, Y., Yang, Z., Shi, Y., Guo, Z., Li, H., Hu, X.,
  Yuan, J., Nie, Z.: {DAIR}-{V2X}: {A} {Large}-{Scale} {Dataset} for
  {Vehicle}-{Infrastructure} {Cooperative} {3D} {Object} {Detection}. In:
  Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and
  {Pattern} {Recognition}. arXiv (Apr 2022)

\bibitem{yu_monosdf_2022}
Yu, Z., Peng, S., Niemeyer, M., Sattler, T., Geiger, A.: {MonoSDF}: {Exploring}
  {Monocular} {Geometric} {Cues} for {Neural} {Implicit} {Surface}
  {Reconstruction}. In: Advances in {Neural} {Information} {Processing}
  {Systems} (Oct 2022)

\bibitem{zhang_unreasonable_2018}
Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O.: The {Unreasonable}
  {Effectiveness} of {Deep} {Features} as a {Perceptual} {Metric}. In: 2018
  {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}.
  pp. 586--595 (Jun 2018)

\bibitem{zheng_steps_2023}
Zheng, Y., Zhong, C., Li, P., Gao, H.a., Zheng, Y., Jin, B., Wang, L., Zhao,
  H., Zhou, G., Zhang, Q., Zhao, D.: {STEPS}: {Joint} {Self}-supervised
  {Nighttime} {Image} {Enhancement} and {Depth} {Estimation}. In: 2023 {IEEE}
  {Conference} on {Robotics} and {Automation} ({ICRA} 2023) (Feb 2023)

\bibitem{zhi_-place_2021}
Zhi, S., Laidlow, T., Leutenegger, S., Davison, A.J.: In-{Place} {Scene}
  {Labelling} and {Understanding} with {Implicit} {Scene} {Representation}. In:
  Proceedings of the {IEEE}/{CVF} {International} {Conference} on {Computer}
  {Vision} (Aug 2021)

\end{thebibliography}
