\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc,
  Mensch, Millican, Reynolds, et~al.]{alayrac2022flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds,
  et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{arXiv preprint arXiv:2204.14198}, 2022.

\bibitem[Bao et~al.(2021)Bao, Dong, and Wei]{bao2021beit}
Hangbo Bao, Li Dong, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock \emph{arXiv preprint arXiv:2106.08254}, 2021.

\bibitem[Beyer et~al.(2022)Beyer, Zhai, Royer, Markeeva, Anil, and
  Kolesnikov]{beyer2022knowledge}
Lucas Beyer, Xiaohua Zhai, Am{\'e}lie Royer, Larisa Markeeva, Rohan Anil, and
  Alexander Kolesnikov.
\newblock Knowledge distillation: A good teacher is patient and consistent.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 10925--10934, 2022.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and
  Soricut]{changpinyo2021conceptual}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3558--3568, 2021.

\bibitem[Chen et~al.(2019)Chen, Wang, Pang, Cao, Xiong, Li, Sun, Feng, Liu, Xu,
  et~al.]{chen2019mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, et~al.
\newblock Mmdetection: Open mmlab detection toolbox and benchmark.
\newblock \emph{arXiv preprint arXiv:1906.07155}, 2019.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{IEEE conference on computer vision and pattern recognition},
  pages 248--255. IEEE, 2009.

\bibitem[Desai and Johnson(2021)]{desai2021virtex}
Karan Desai and Justin Johnson.
\newblock Virtex: Learning visual representations from textual annotations.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 11162--11173, 2021.

\bibitem[Dong et~al.(2023)Dong, Bao, Zheng, Zhang, Chen, Yang, Zeng, Zhang,
  Yuan, Chen, et~al.]{dong2023maskclip}
Xiaoyi Dong, Jianmin Bao, Yinglin Zheng, Ting Zhang, Dongdong Chen, Hao Yang,
  Ming Zeng, Weiming Zhang, Lu Yuan, Dong Chen, et~al.
\newblock Maskclip: Masked self-distillation advances contrastive
  language-image pretraining.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10995--11005, 2023.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Fang et~al.(2023)Fang, Wang, Xie, Sun, Wu, Wang, Huang, Wang, and
  Cao]{fang2022eva}
Yuxin Fang, Wen Wang, Binhui Xie, Quan Sun, Ledell Wu, Xinggang Wang, Tiejun
  Huang, Xinlong Wang, and Yue Cao.
\newblock Eva: Exploring the limits of masked visual representation learning at
  scale.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 19358--19369, 2023.

\bibitem[Fang et~al.(2021{\natexlab{a}})Fang, Wang, Hu, Wang, Yang, and
  Liu]{fang2021compressing}
Zhiyuan Fang, Jianfeng Wang, Xiaowei Hu, Lijuan Wang, Yezhou Yang, and Zicheng
  Liu.
\newblock Compressing visual-linguistic model via knowledge distillation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1428--1438, 2021{\natexlab{a}}.

\bibitem[Fang et~al.(2021{\natexlab{b}})Fang, Wang, Wang, Zhang, Yang, and
  Liu]{fang2021seed}
Zhiyuan Fang, Jianfeng Wang, Lijuan Wang, Lei Zhang, Yezhou Yang, and Zicheng
  Liu.
\newblock Seed: Self-supervised distillation for visual representation.
\newblock \emph{ICLR}, 2021{\natexlab{b}}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[He et~al.(2017)He, Gkioxari, Doll{\'a}r, and Girshick]{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2961--2969, 2017.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 16000--16009, 2022.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo,
  Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8340--8349, 2021.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2015.

\bibitem[Howard et~al.(2019)Howard, Sandler, Chu, Chen, Chen, Tan, Wang, Zhu,
  Pang, Vasudevan, et~al.]{howard2019searching}
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing
  Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et~al.
\newblock Searching for mobilenetv3.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 1314--1324, 2019.

\bibitem[Huang et~al.(2024)Huang, Zeng, Yang, An, Diao, and Xu]{huang2023etag}
Libo Huang, Yan Zeng, Chuanguang Yang, Zhulin An, Boyu Diao, and Yongjun Xu.
\newblock etag: Class-incremental learning via embedding distillation and
  task-oriented generation.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  2024.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  4904--4916. PMLR, 2021.

\bibitem[Jiao et~al.(2019)Jiao, Yin, Shang, Jiang, Chen, Li, Wang, and
  Liu]{jiao2019tinybert}
Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang
  Wang, and Qun Liu.
\newblock Tinybert: Distilling bert for natural language understanding.
\newblock \emph{arXiv preprint arXiv:1909.10351}, 2019.

\bibitem[Kornblith et~al.(2019)Kornblith, Norouzi, Lee, and
  Hinton]{kornblith2019similarity}
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton.
\newblock Similarity of neural network representations revisited.
\newblock In \emph{International conference on machine learning}, pages
  3519--3529. PMLR, 2019.

\bibitem[Kuo et~al.(2022)Kuo, Cui, Gu, Piergiovanni, and Angelova]{kuo2022f}
Weicheng Kuo, Yin Cui, Xiuye Gu, AJ Piergiovanni, and Anelia Angelova.
\newblock F-vlm: Open-vocabulary object detection upon frozen vision and
  language models.
\newblock \emph{arXiv preprint arXiv:2209.15639}, 2022.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Fang, Liu, Ling, Tu, and
  Su]{li2023distilling}
Xuanlin Li, Yunhao Fang, Minghua Liu, Zhan Ling, Zhuowen Tu, and Hao Su.
\newblock Distilling large vision-language model with out-of-distribution
  generalizability.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2492--2503, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Liang, Zhao, Cui, Ouyang, Shao, Yu,
  and Yan]{li2021supervision}
Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao,
  Fengwei Yu, and Junjie Yan.
\newblock Supervision exists everywhere: A data efficient contrastive
  language-image pre-training paradigm.
\newblock \emph{arXiv preprint arXiv:2110.05208}, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Fan, Hu, Feichtenhofer, and
  He]{li2023scaling}
Yanghao Li, Haoqi Fan, Ronghang Hu, Christoph Feichtenhofer, and Kaiming He.
\newblock Scaling language-image pre-training via masking.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 23390--23400, 2023{\natexlab{b}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Ye, Song, Huang, and
  Pan]{li2021online}
Zheng Li, Jingwen Ye, Mingli Song, Ying Huang, and Zhigeng Pan.
\newblock Online knowledge distillation for efficient pose estimation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 11740--11750, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2023{\natexlab{c}})Li, Li, Yang, Zhao, Song, Luo, Li, and
  Yang]{li2023curriculum}
Zheng Li, Xiang Li, Lingfeng Yang, Borui Zhao, Renjie Song, Lei Luo, Jun Li,
  and Jian Yang.
\newblock Curriculum temperature for knowledge distillation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 1504--1512, 2023{\natexlab{c}}.

\bibitem[Li et~al.(2024)Li, Li, Fu, Zhang, Wang, Chen, and
  Yang]{li2024promptkd}
Zheng Li, Xiang Li, Xinyi Fu, Xin Zhang, Weiqiang Wang, Shuo Chen, and Jian
  Yang.
\newblock Promptkd: Unsupervised prompt distillation for vision-language
  models.
\newblock \emph{arXiv preprint arXiv:2403.02781}, 2024.

\bibitem[Liang et~al.(2024)Liang, Yu, Yang, Brown, Cui, Zhao, Gong, and
  Zhou]{liang2024module}
Chen Liang, Jiahui Yu, Ming-Hsuan Yang, Matthew Brown, Yin Cui, Tuo Zhao,
  Boqing Gong, and Tianyi Zhou.
\newblock Module-wise adaptive distillation for multimodality foundation
  models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022, 2021.

\bibitem[Loshchilov and Hutter(2017)]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Mehta and Rastegari(2021)]{mehta2021mobilevit}
Sachin Mehta and Mohammad Rastegari.
\newblock Mobilevit: light-weight, general-purpose, and mobile-friendly vision
  transformer.
\newblock \emph{arXiv preprint arXiv:2110.02178}, 2021.

\bibitem[Mu et~al.(2022)Mu, Kirillov, Wagner, and Xie]{mu2022slip}
Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock In \emph{European conference on computer vision}, pages 529--544.
  Springer, 2022.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Peng et~al.(2022)Peng, Dong, Bao, Ye, and Wei]{peng2022beit}
Zhiliang Peng, Li Dong, Hangbo Bao, Qixiang Ye, and Furu Wei.
\newblock Beit v2: Masked image modeling with vector-quantized visual
  tokenizers.
\newblock \emph{arXiv preprint arXiv:2208.06366}, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht2019imagenet}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In \emph{International Conference on Machine Learning}, pages
  5389--5400. PMLR, 2019.

\bibitem[Romero et~al.(2015)Romero, Ballas, Kahou, Chassang, Gatta, and
  Bengio]{romero2014fitnets}
Adriana Romero, Nicolas Ballas, Samira~Ebrahimi Kahou, Antoine Chassang, Carlo
  Gatta, and Yoshua Bengio.
\newblock Fitnets: Hints for thin deep nets.
\newblock \emph{ICLR}, 2015.

\bibitem[Schuhmann et~al.(2021)Schuhmann, Vencu, Beaumont, Kaczmarczyk, Mullis,
  Katta, Coombes, Jitsev, and Komatsuzaki]{schuhmann2021laion}
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk,
  Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran
  Komatsuzaki.
\newblock Laion-400m: Open dataset of clip-filtered 400 million image-text
  pairs.
\newblock \emph{arXiv preprint arXiv:2111.02114}, 2021.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 2556--2565,
  2018.

\bibitem[Tan and Le(2019)]{tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International conference on machine learning}, pages
  6105--6114. PMLR, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{wang2019learning}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Wang et~al.(2021)Wang, Yu, Yu, Dai, Tsvetkov, and Cao]{wang2021simvlm}
Zirui Wang, Jiahui Yu, Adams~Wei Yu, Zihang Dai, Yulia Tsvetkov, and Yuan Cao.
\newblock Simvlm: Simple visual language model pretraining with weak
  supervision.
\newblock \emph{arXiv preprint arXiv:2108.10904}, 2021.

\bibitem[Wang et~al.(2022)Wang, Codella, Chen, Zhou, Dai, Xiao, Yang, You,
  Chang, Chang, et~al.]{wang2022multimodal}
Zhecan Wang, Noel Codella, Yen-Chun Chen, Luowei Zhou, Xiyang Dai, Bin Xiao,
  Jianwei Yang, Haoxuan You, Kai-Wei Chang, Shih-fu Chang, et~al.
\newblock Multimodal adaptive distillation for leveraging unimodal encoders for
  vision-language tasks.
\newblock \emph{arXiv preprint arXiv:2204.10496}, 2022.

\bibitem[Wei et~al.(2022{\natexlab{a}})Wei, Xie, Zhou, Li, and
  Tian]{wei2022mvp}
Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, and Qi Tian.
\newblock Mvp: Multimodality-guided visual pre-training.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXX}, pages 337--353.
  Springer, 2022{\natexlab{a}}.

\bibitem[Wei et~al.(2022{\natexlab{b}})Wei, Cao, Zhang, Yao, Xie, Hu, and
  Guo]{wei2022icar}
Yixuan Wei, Yue Cao, Zheng Zhang, Zhuliang Yao, Zhenda Xie, Han Hu, and Baining
  Guo.
\newblock icar: Bridging image classification and image-text alignment for
  visual recognition.
\newblock \emph{arXiv preprint arXiv:2204.10760}, 2022{\natexlab{b}}.

\bibitem[Wu et~al.(2023)Wu, Peng, Zhou, Xiao, Liu, Yuan, Xuan, Valenzuela,
  Chen, Wang, et~al.]{wu2023tinyclip}
Kan Wu, Houwen Peng, Zhenghong Zhou, Bin Xiao, Mengchen Liu, Lu Yuan, Hong
  Xuan, Michael Valenzuela, Xi~Stephen Chen, Xinggang Wang, et~al.
\newblock Tinyclip: Clip distillation via affinity mimicking and weight
  inheritance.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 21970--21980, 2023.

\bibitem[Xie et~al.(2022)Xie, Zhang, Cao, Lin, Bao, Yao, Dai, and
  Hu]{xie2022simmim}
Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi
  Dai, and Han Hu.
\newblock Simmim: A simple framework for masked image modeling.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9653--9663, 2022.

\bibitem[Yang et~al.(2021)Yang, An, Cai, and Xu]{yang2021hierarchical}
Chuanguang Yang, Zhulin An, Linhang Cai, and Yongjun Xu.
\newblock Hierarchical self-supervised augmented knowledge distillation.
\newblock \emph{International Joint Conference on Artificial Intelligence},
  pages 1217--1223, 2021.

\bibitem[Yang et~al.(2022{\natexlab{a}})Yang, An, Cai, and Xu]{yang2022mutual}
Chuanguang Yang, Zhulin An, Linhang Cai, and Yongjun Xu.
\newblock Mutual contrastive learning for visual representation learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 3045--3053, 2022{\natexlab{a}}.

\bibitem[Yang et~al.(2022{\natexlab{b}})Yang, An, Zhou, Cai, Zhi, Wu, Xu, and
  Zhang]{yang2022mixskd}
Chuanguang Yang, Zhulin An, Helong Zhou, Linhang Cai, Xiang Zhi, Jiwen Wu,
  Yongjun Xu, and Qian Zhang.
\newblock Mixskd: Self-knowledge distillation from mixup for image recognition.
\newblock In \emph{European Conference on Computer Vision}, pages 534--551.
  Springer, 2022{\natexlab{b}}.

\bibitem[Yang et~al.(2022{\natexlab{c}})Yang, Zhou, An, Jiang, Xu, and
  Zhang]{yang2022cross}
Chuanguang Yang, Helong Zhou, Zhulin An, Xue Jiang, Yongjun Xu, and Qian Zhang.
\newblock Cross-image relational knowledge distillation for semantic
  segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12319--12328, 2022{\natexlab{c}}.

\bibitem[Yang et~al.(2023{\natexlab{a}})Yang, An, Zhou, Zhuang, Xu, and
  Zhang]{yang2023online}
Chuanguang Yang, Zhulin An, Helong Zhou, Fuzhen Zhuang, Yongjun Xu, and Qian
  Zhang.
\newblock Online knowledge distillation via mutual contrastive learning for
  visual recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 45\penalty0 (8):\penalty0 10212--10227, 2023{\natexlab{a}}.

\bibitem[Yang et~al.(2023{\natexlab{b}})Yang, Huang, Wei, Peng, Jiang, Jiang,
  Wei, Wang, Hu, Qiu, et~al.]{yang2023attentive}
Yifan Yang, Weiquan Huang, Yixuan Wei, Houwen Peng, Xinyang Jiang, Huiqiang
  Jiang, Fangyun Wei, Yin Wang, Han Hu, Lili Qiu, et~al.
\newblock Attentive mask clip.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2771--2781, 2023{\natexlab{b}}.

\bibitem[Yao et~al.(2021)Yao, Pi, Xu, Zhang, Li, and Zhang]{yao2021g}
Lewei Yao, Renjie Pi, Hang Xu, Wei Zhang, Zhenguo Li, and Tong Zhang.
\newblock G-detkd: towards general distillation framework for object detectors
  via contrastive and semantic-guided feature imitation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 3591--3600, 2021.

\bibitem[Young et~al.(2014)Young, Lai, Hodosh, and Hockenmaier]{young2014image}
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.
\newblock From image descriptions to visual denotations: New similarity metrics
  for semantic inference over event descriptions.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2:\penalty0 67--78, 2014.

\bibitem[Yu et~al.(2022)Yu, Wang, Vasudevan, Yeung, Seyedhosseini, and
  Wu]{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
  Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock \emph{arXiv preprint arXiv:2205.01917}, 2022.

\bibitem[Yuan et~al.(2021)Yuan, Lin, Kuen, Zhang, Wang, Maire, Kale, and
  Faieta]{yuan2021multimodal}
Xin Yuan, Zhe Lin, Jason Kuen, Jianming Zhang, Yilin Wang, Michael Maire,
  Ajinkya Kale, and Baldo Faieta.
\newblock Multimodal contrastive training for visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 6995--7004, 2021.

\bibitem[Zhai et~al.(2023)Zhai, Mustafa, Kolesnikov, and
  Beyer]{zhai2023sigmoid}
Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer.
\newblock Sigmoid loss for language image pre-training.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 11975--11986, 2023.

\end{thebibliography}
