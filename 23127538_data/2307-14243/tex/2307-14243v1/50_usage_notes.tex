The Fluorescent Neuronal Cells collection is available both as a comprehensive archive and as individual image collections for specific research requirements. This enables users to download the data efficiently and selectively, based on their specific needs.
The code provided is based on the Python and PyTorch frameworks, offering a robust foundation for analysis and modeling. However, thanks to the popularity of the annotation formats and the use of PNG images, users can easily employ their preferred deep learning framework.


\subsection*{Peculiar traits}

In all image collections, the visual representation is characterized by the prevalence of two distinct color tones, which result from the deliberate selection of a specific wavelength. One tone appears darker, indicating areas where light has been filtered out, while the other tone is brighter and more intense, emitted by the fluorophore corresponding to the color of each collection (see \Cref{fig:green_image,fig:red_image,fig:yellow_image}).
As a result, the images can generally be depicted using variations of a single color. Consequently, a 1-D representation may be sufficient, or an alternative color space other than RGB could provide more informative and less redundant data.

Notice, however, that the specific colors employed in our studies were dictated not by any inherent or functional property of the stained biological structures, but rather by their accessibility and practicality during the time of the experiments. Therefore, it would be a misinterpretation to associate specific colors to particular neuronal substructures. In fact, these colors serve only as contrasting elements to discern the stained foreground objects from the background. 
Consequently, the emphasis should lie primarily on learning this discrimination rather than matching specific colors with the neuronal structures. 
Thus, the particular colors should not be considered indicative of the type of neuronal cells or their functional attributes, but merely as a practical tool aiding in the overall visualization and interpretation.


\input{challenges}
\subsection*{Challenges}


Some important insights for future studies can be drawn examining ground-truth masks at the pixel level, revealing significant characteristics that impact the training process.

The two classes, namely cells (1) and background (0), exhibit an extreme \textbf{class imbalance}, with background pixels being overwhelmingly predominant, typically exceeding cell pixels by over a factor of 100 (cf. \Cref{tab:summary-stats}, \textit{signal \%}).
These observations highlight the necessity for specialized training strategies to address this pronounced class imbalance and effectively learn the pixel classification.

Additional challenges are associated with the macroscopic content of the images. The Fluorescent Neuronal Cells data showcase a diverse collection of 11704 subnuclear neuronal structures, varying in shape, size, and extension (cf \Cref{tab:summary-stats}, \textit{area, Feret diameter} and \textit{equivalent diameter} columns). 
The distribution of these structures across the collections is uneven, with some images containing numerous cells while others are devoid of them. Consequently, the model needs to be flexible enough to handle both scenarios.

Furthermore, despite considerable efforts to stabilize the acquisition procedure, several technical challenges persist.
Firstly, there is a \textbf{high variability in terms of color, saturation, and contrast} from one image to another. For instance, there are instances where the tissues absorb some of the markers (see \Cref{fig:challenges:yellow_artifact,fig:challenges:yellow_stripe,fig:challenges:green,fig:challenges:green_artifact,fig:challenges:red_stripe}), causing irrelevant compounds to emit light which is then captured by the microscope. 
Consequently, the background's hue may shift towards values similar to those of faint neuronal cells (see \Cref{fig:challenges:yellow_artifact,fig:challenges:yellow_stripe,fig:challenges:green,fig:challenges:green_artifact,fig:challenges:red_filament}).
In such circumstances, relying solely on pixel intensity is insufficient to distinguish between signal and background, necessitating the consideration of additional characteristics such as saturation and contrast. However, even the analysis of these characteristics is not straightforward, as fluorescent emissions are naturally unstable, leading to fluctuations in the saturation levels exhibited by cell pixels (cf. \Cref{fig:challenges:yellow,fig:challenges:yellow_artifact,fig:challenges:yellow_stripe} or \Cref{fig:challenges:red_filament,fig:challenges:red_stripe}).


Moreover, the substructures of interest have a fluid nature. Also, the shot can capture different two-dimensional sections depending on how the cells are oriented within the tissues.
As a consequence, the \textbf{size and the shape of the stained cells can vary significantly} (cf. objects dimension in \Cref{fig:green_mask,fig:red_mask,fig:yellow_mask}), further complicating the discrimination between cells and the background.

Another challenge arises from the occasional presence of accumulations of fluorophore in narrow areas, resulting in emissions that closely resemble those of cells. 
These \textbf{artifacts} can manifest as small areas, such as point artifacts and filaments, or larger structures, like lateral stripes  (see \Cref{fig:challenges:yellow_artifact,fig:challenges:yellow_stripe,fig:challenges:green,fig:challenges:green_artifact,fig:challenges:red_filament,fig:challenges:red_stripe}).
Again, their presence hampers the detection task, making the recognition and the understanding of cells structure and size mandatory for the model.

A further source of complexity is represented by \textbf{overcrowding} (\Cref{fig:challenges:yellow,fig:challenges:green,fig:challenges:red_filament,fig:challenges:red_stripe}). When several cells are close-by, maybe partially overlapping, precisely localizing cell boundaries can be challenging, thus requiring adjustments to prevent the model from merging nearby cells into single agglomerations.

Last but not least, in some occasions the recognition of cells may be ambiguous even for human operators(cf. \textit{marked} and \textit{non-marked} instances in \Cref{fig:challenges:yellow,fig:challenges:green,fig:challenges:red_filament,fig:challenges:red_stripe}). Of course, this poses an issue of intrinsic \textbf{subjectivity} in the annotation process,
% which is then reflected on model performance.
which in turn affects both the training and assessment phases.

By and large, all of these factors make the recognition and counting tasks harder and complicate the learning process.
Likewise, borderline annotations hinder model evaluation as their subjectivity deprives the model of a reliable and indisputable testbed.

% \input{challenges}


\subsection*{Research lines}

As long as potential applications, the FNC dataset offers rich opportunities for diverse research directions, including:

\begin{itemize}
\item \textit{Object Segmentation, Detection, and Counting}: The dataset's comprehensive annotations and diverse neuronal structures support studies focusing on accurate segmentation, detection, and counting of cells. Particularly, FNC may be a challenging benchmark for class imbalance, object overlapping/overcrowding, and uncertainty estimation 

\item \textit{Transfer Learning}: With the availability of multiple image collections within FNC, researchers can explore transfer learning techniques, leveraging knowledge from one collection to improve performance on another.

\item \textit{Unsupervised or Self-/Weakly-Supervised Learning}: The presence of both labeled and unlabeled data within the FNC dataset provides an ideal testbed for evaluating unsupervised or self-/weakly-supervised learning approaches.

\item \textit{Evaluation of Annotation Types}: Researchers can investigate the effectiveness of different annotation types for specific tasks, allowing for a comparative analysis and selection of the most suitable annotations considering the cost/performance requirements of a given use-case.

% \item \textit{Image Restoration or Generation}: given the high-resolution of FNC images, our data may presents an opportunity to explore image restoration or generation approaches specifically designed for microscopy applications.
\end{itemize}

\subsection*{Limitations}

Despite the Fluorescent Neuronal Cells collection presenting a variety of images in many aspects, it has limitations in terms of diversity across several parameters.

Firstly, all the images were collected by the same research laboratory in Bologna, utilizing fixed experimental conditions and acquisition settings. Furthermore, the images were captured using epifluorescence microscopy, which limits the range of techniques employed.
However, we believe that the adopted acquisition settings represent a more challenging scenario. Therefore, pre-training on FNC data should enable generalization to modern equipment such as confocal microscopy, which produces higher-quality images with sharper object boundaries and improved signal-to-noise ratio.

Another limitation lies in the lack of diversity in the cell types depicted and the animal species involved. Our dataset only focuses on subcellular components of rodent neurons. This might potentially impact the generalization of the models to different use cases and restrict their application to other cell types or animal species.
