\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage[nonatbib,preprint]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
%\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts,amsthm,amsmath,amssymb}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{optidef}
\usepackage{subcaption}
\usepackage{cite}
\usepackage[linesnumbered,ruled]{algorithm2e}
\newtheorem{thm}{Theorem}
\newtheorem{ass}{Assumption}
\newtheorem{defi}{Definition}
\newtheorem{lem}{Lemma}
\newtheorem{rmk}{Remark}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\Var}{Var}

\title{High Dimensional Distributed Gradient Descent with Arbitrary Number of Byzantine Attackers}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Puning Zhao, Zhiguo Wan\\%\thanks{Use footnote for providing further information
   % about author (webpage, alternative address)---\emph{not} for acknowledging
   % funding agencies.} \\
  Zhejiang Lab\\
  Hangzhou, Zhejiang, China\\
  \texttt{\{pnzhao,wanzhiguo\}@zhejianglab.com} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
	Robust distributed learning with Byzantine failures has attracted extensive research interests in recent years. However, most of existing methods suffer from curse of dimensionality, which is increasingly serious with the growing complexity of modern machine learning models. In this paper, we design a new method that is suitable for high dimensional problems, under arbitrary number of Byzantine attackers. The core of our design is a direct high dimensional semi-verified mean estimation method. Our idea is to identify a subspace first. The components of mean value perpendicular to this subspace can be estimated via gradient vectors uploaded from worker machines, while the components within this subspace are estimated using auxiliary dataset. We then use our new method as the aggregator of distributed learning problems. Our theoretical analysis shows that the new method has minimax optimal statistical rates. In particular, the dependence on dimensionality is significantly improved compared with previous works.
	%A crucial challenge to distributed machine learning systems is that some worker machines are untrusted. Suppose that among $m$ worker machines, up to $q$ of them suffer Byzantine faults, which can send arbitrary wrong information to the master. Existing research can be divided into two categories: requiring $q<m/2$, and allowing arbitrary $q$, in which the latter case requires an additional dataset in the master. However, a common problem of previous approaches is the curse of dimensionality, which is increasingly serious with the growing complexity of modern machine learning models. \cite{zhu2023byzantine} studied the high dimensional case with $q<m/2$. In this work, we focus on the case with arbitrary $q$. Our main goal is to obtain a desirable learning performance with majority of machines attacked, even in high dimensions. The key is to design a direct semi-verified mean estimation method. Our idea is to identify a subspace first. The components of mean value perpendicular to this subspace can be estimated via gradient vectors uploaded from worker machines, while the components within this subspace are estimated using auxiliary dataset. Our theoretical analysis shows that the error rate of our new semi-verified mean estimation method is minimax optimal under both additive and strong contamination models. We then use our new method as the aggregator of distributed learning problems.
\end{abstract}

\section{Introduction}
Many modern machine learning tasks require distributed computing and storage. In such systems, there are many \textit{worker machines}, which are coordinated by a centralized server, called the \textit{master machine}. Each worker machine has a local training dataset which is never uploaded to the master. Instead, worker machines only need to compute an update to the current model, and send it to the master. Such setting is called Federated Learning (FL) \cite{mcmahan2017communication}, which has drawn considerable attention in recent years \cite{zhang2021survey,kairouz2021advances}. FL has advantages in both computational efficiency and privacy preserving. With the rapid growth of the amount of data, storing and computing data in a distributed manner becomes necessary. Moreover, in many sensitive applications, such as healthcare, recommendation systems and self-driving cars, FL can protect users' privacy, since the model is trained without direct access to local datasets stored in clients.

Despite significant advantages and widespread applications, FL is still facing many challenges \cite{kairouz2021advances}. One critical issue is that not all machines are trustable \cite{lyu2020threats}. In large scale FL problems, some of worker machines may send wrong information to the master due to various reasons, including system crashes, faulty hardware, communication errors, and even malicious attacks \cite{bagdasaryan2020backdoor,bhagoji2019analyzing,fang2020local,sun2021data,luo2021feature,qin2023resisting}. Unfortunately, the vanilla FL \cite{mcmahan2017communication} is highly susceptible to these corrupted worker machines. Without proper handling, the trained model weights may be far from optimal. Consequently, evaluating the impacts of these corrupted worker machines, and designing corresponding defense strategies, have become critical tasks in the research community. %various types of attacks \cite{bagdasaryan2020backdoor,bhagoji2019analyzing,fang2020local,sun2021data,luo2021feature}. These attacks make some worker machines behave maliciously in an FL system. In particular, these attacked machines can send wrong information to the master, and 

Abnormal behaviors of worker machines are usually unpredictable. To build a robust system that is resilient to all corruptions, it is necessary to consider the worst case. With such intuition, researchers typically model these faults as Byzantine failure \cite{lamport1982byzantine}. Under this model, for some worker machines, the messages sent to the master are manipulated carefully by a malicious adversary. It is assumed that the adversary knows the underlying distribution of data, as well as the learning algorithm. With these information, the adversary designs an optimal strategy to deteriorate the model performance as much as possible.  Therefore, Byzantine failure is the most harmful among all corruptions. If our learning algorithm can defend against Byzantine attack, it should also be robust under other possible failures.


There have been extensive research on Byzantine robust distributed learning. Suppose that there are $m$ worker machines, with each machine storing $n$ samples. The attacker can manipulate up to $q$ worker machines. Most of previous works focus on the case with $q<m/2$, i.e. less than half of worker machines are attacked, such as Krum \cite{blanchard2017machine}, geometric median of mean \cite{chen2017distributed}, coordinate-wise median and trimmed mean \cite{yin2018byzantine}. There are also some previous results on the case with arbitrary number of attackers, which allows $q>m/2$. Actually, without additional information, it is impossible to learn the model precisely. Therefore, these works typically rely on the help of an additional clean dataset, so that the real gradient can be estimated by combining the gradient vectors uploaded by these worker machines and the information from the auxiliary clean samples. This line of works include \cite{cao2019distributed,regatti2020bygars,xie2019zeno,xie2020zeno++}, see Section \ref{sec:related} for further discussion. 
%There have been extensive research on Byzantine robust distributed learning, with most of them focusing on the case such that less than half of worker machines are attacked. For example, \cite{blanchard2017machine} proposed Krum, \cite{chen2017distributed} propose to use median of mean approach to estimate the global gradient. These methods are suboptimal. \cite{yin2018byzantine} showed that coordinate-wise median and trimmed mean can significantly improve the convergence property. Nevertheless, a common problem of all these methods is that the final statistical errors grow with the dimensionality $d$ (which is actually the number of model parameters), with a $\sqrt{d}$ factor. In modern machine learning models, such as deep neural networks, there is usually a large number of parameters. As a result, the performances of these methods are far from optimal. In recent years, there are significant progress on statistical and computational efficient high dimensional robust mean estimators, such as \cite{diakonikolas2016robust,diakonikolas2017being,diakonikolas2020outlier,steinhardt2018robust,zhu2022a,zhu2022b,zhu2022c,diakonikolas2023algorithmic}. These methods does not have $\sqrt{d}$ factor, and are thus suitable in high dimensions. \cite{zhu2023byzantine} showed that these robust mean estimators can serve as the gradient aggregator in Byzantine robust federated learning problems. As long as the ratio of attacked machines is less than $1/2$, the methods in \cite{zhu2023byzantine} achieve optimal statistical rates, up to logarithm factors.

Nevertheless, a common problem for all these methods is the curse of dimensionality. The final statistical errors grow with the dimensionality $d$, which is the number of model parameters. As a result, these methods are not suitable in modern large scale machine learning models. A progress towards high dimensional robust federated problem with $q<m/2$ was made in \cite{zhu2023byzantine}, which is based on some high dimensional robust mean estimators proposed in recent years \cite{diakonikolas2016robust,diakonikolas2017being,diakonikolas2020outlier,steinhardt2018robust,zhu2022a,zhu2022b,zhu2022c,diakonikolas2023algorithmic}. These new estimators are statistical and computational efficient. According to \cite{zhu2023byzantine}, with these robust mean estimators as gradient aggregators in Byzantine robust federated learning tasks, if $q<m/2$, then the convergence rate of learning error is nearly minimax optimal. However, to the best of knowledge, high dimensional cases with $q\geq m/2$ has not been solved before.
%However, the assumption that less than half of worker machines are attacked may not hold in practice. In this case, the methods mentioned above no longer works. Actually, for robust mean estimation problem, if more than half samples being contaminated, without additional information, it is impossible to design a desirable mean estimator in general, i.e. the estimation error can be arbitrarily large \cite{diakonikolas2019recent}. To solve this problem, we can collect a small additional clean dataset, which is usually practical. After that, we can combine the information from the gradient uploaded by worker machines and the auxiliary dataset, to obtain a reliable gradient estimation. \cite{cao2019distributed} proposed a method to filter out gradient vectors that are far away from those calculated from the auxiliary data. There is also a slightly different method using reputation scores, which is also calculated by comparing the gradient vectors\cite{regatti2020bygars}. A significantly different approach is proposed in \cite{xie2019zeno,xie2020zeno++}, called Zeno (and its further improvements, Zero+ and Zeno++). In these two methods, the auxiliary dataset is not used calculate a baseline gradient vector for comparison. Instead, they are used to stochastic descent score, which is higher if the gradient descent is effective and the gradient vector itself is small. Unfortunately, similar to the case with less than half worker machines, all of these methods performs badly in high dimensional problems. In particular, the errors of the gradient aggregators of these methods grow with dimensionality with a $\sqrt{d}$ factor. Therefore, these methods are not suitable for large scale models, in which the learned model weights can be far from the ground truth. With growing model size in modern machine learning tasks, a new method that can overcome the curse of dimensionality is crucially needed. 

In this paper, we propose a new approach to distributed gradient descent in high dimensions, which allows arbitrary number of Byzantine attackers. While the focus is primarily on the case with $q\geq m/2$, our method also works with $q<m/2$. Similar to previous works \cite{cao2019distributed,regatti2020bygars,xie2019zeno,xie2020zeno++}, we assume that an auxiliary dataset is available. The main improvements compared with \cite{cao2019distributed,regatti2020bygars,xie2019zeno,xie2020zeno++} is that our method can overcome the curse of dimensionality. The detailed steps are shown as follows.

Firstly, we propose a direct semi-verified mean estimation method. Semi verified mean estimation is the problem of estimating the mean of a distribution, by combining the information of a small clean dataset and a large untrusted dataset, in which a large fraction of samples may be corrupted \cite{charikar2017learning}. Semi verified mean estimation algorithm is important since it can serve as the aggregator function in distributed learning. \cite{charikar2017learning} shows that semi-verified mean estimation can be converted to list-decodable mean estimation problem, which aims at generating a list of $K$ hypotheses $\hat{\mu}_1,\ldots, \hat{\mu}_K$ such that one of them is close to the ground truth $\mu^*$. With a hypotheses list of length $K$, we can then use $O(\ln K)$ clean samples to conduct a hypothesis testing to pick one from the hypotheses list. However, we argue that the indirect semi-verified mean estimation method by conversion to list-decodable mean estimation is a bit complex and sample inefficient. Therefore, we propose a direct method to semi-verified mean estimation. The intuitive idea of our approach can be explained as follows. The first step is to filter out some samples and identify a subspace in which the components of $\mu^*$ is hard to estimate using the corrupted data. These components are then estimated using auxiliary clean dataset. In directions that are perpendicular to the subspace, we just use the projected sample mean of the corrupted dataset. Our design is partially motivated by a list-decodable mean estimation method in \cite{diakonikolas2021list}.

Secondly, we conduct a theoretical analysis of our new proposed semi-verified mean estimation algorithm. Under the condition that the covariance matrix is bounded by $\sigma^2 \mathbf{I}$, and the fraction of good samples among the untrusted dataset is at least $\alpha$, we obtain an upper bound of the estimation error with respect to $\sigma$ and $\alpha$. Our analysis considers two models separately. The first one is additive contamination model. Under this model, attacked samples are injected into a set of good samples. As a result, the distribution of good samples is not influenced by the adversary. Another way to understand this model is that the adversary randomly pick $1-\alpha$ fraction of samples from the corrupted dataset and change their values arbitrarily, The second one is strong contamination model, under which the adversary can pick $1-\alpha$ fraction of samples arbitrarily instead of randomly, and then modify their values to maximize their negative impacts on the estimation performance. As a result, the distribution of good samples is also altered after contamination. Compared with additive contamination model, the adversary is more powerful under strong contamination model. Consequently, the theoretical bound under strong contamination model is also larger. 
Apart from the upper bound of our new method, we also obtain the information theoretic minimax lower bound under both additive and strong contamination model. The result shows that our upper and lower bounds match, indicating that our method is optimal, in the sense that the sample efficiency can not be further improved in general.

Finally, we apply the semi-verified mean estimation algorithm into Byzantine robust distributed learning problem, with the gradient vector returned by each worker machine being regarded as a sample. We conduct theoretical analysis of the performance of distributed learning under Byzantine attack.

The remainder of this paper is organized as follows. In section \ref{sec:related}, we provide a review of previous literatures. Section \ref{sec:estimation} shows our semi-verified mean estimation method. Our theoretical analysis is shown in Section~\ref{sec:theory}. After that, Section \ref{sec:byzantine} discusses the distributed learning algorithm. Finally, we offer numerical results and concluding remarks in Section~\ref{sec:numerical} and Section~\ref{sec:conc}, respectively. Proofs are shown in the appendix.

\section{Related Work}\label{sec:related}
\subsection{Robust mean estimation}\label{sec:mean}
Distributed learning relies on accurate estimation of the statistical mean of gradients gathered from worker machines. Therefore, we provide a brief review of robust mean estimation first. Estimation with corrupted samples has been an important task in statistics since 1960s \cite{huber1964robust,huber2004robust}. Traditional robust estimation methods such as trimmed mean behaves badly as dimensionality increases. An exception is Tukey median \cite{tukey1975mathematics}, which is sample efficient in high dimensional spaces. However, Tukey median is not practical, since the computation can not finish in polynomial time. \cite{lai2016agnostic,diakonikolas2016robust,diakonikolas2017being} proposed convex programming and filtering methods for high dimensional robust mean estimation. Since then, a flurry of works has emerged, focusing on improving the time complexity \cite{cheng2019high}, extending to sparse problems \cite{balakrishnan2017computationally,diakonikolas2020outlier}, and improving the performance under stronger tail assumption with sum of squares method \cite{hopkins2018mixture}. These methods works if the proportion of contaminated samples is less than $1/2$. 

If majority of samples are corrupted, then it is impossible to estimate the mean with a single solution. Suppose that the fraction of clean samples is ensured to be at least $\alpha$, i.e. $q/m<1-\alpha$, then the adversary can produce $\Omega(1/\alpha)$ clusters of points, with one of them composed of clean samples, while others are corrupted. In this case, there is no way to determine which cluster is correct. Therefore, in recent works, the goal of mean estimation is relaxed to generating a list of hypotheses, with the guarantee that at least one of the hypotheses is close to the ground truth $\mu^*$. This paradigm is called list-decodable learning. Typically, the length of generated hypotheses list need to be controlled within $O(1/\alpha)$. We hope to make the minimum estimation error among the hypotheses list to be as low as possible. \cite{charikar2017learning} proposed an SDP-based method, achieving error of $O(\sigma\sqrt{\ln(1/\alpha)/\alpha})$. For spherical Gaussians, a multi filter method can achieve a better rate \cite{diakonikolas2018list}. Several recent works improves the time complexity of list-decodable mean estimation. \cite{diakonikolas2021list} proposed SIFT (Subspace Isotropic Filtering), which achieves nearly PCA time complexity. \cite{cherapanamjeri2020list} introduced an optimization based approach with linear time complexity. 

Apart from the untrusted data, if we also have some auxiliary clean samples, then it is possible to determine one estimated value from the hypotheses list, which is close to the ground truth with high probability. \cite{charikar2017learning} named it semi-verified learning, and claims that with $K$ hypotheses, one needs $O(\ln K)$ clean samples to determine the correct one.

\subsection{Federated Learning with less than half Byzantine machines}

Suppose that there are $m$ worker machines, among which $q$ of them being attacked.  Each working machine has $n$ samples. The total size of dataset is $N=mn$. Here we briefly review the previous works with $q<m/2$.

\cite{blanchard2017machine} proposed Krum, which collects gradient vectors from these $m$ worker machines, and then select a vector that is closest to its $m-q$ neighbors. It is expected that the selected one is close to the ground truth. However, the error bound is suboptimal. \cite{chen2017distributed} uses a geometric median of mean method, with a suboptimal error rate of $\sqrt{qd/N}$. \cite{yin2018byzantine} made the first step towards optimal statistical rates of Byzantine robust federated learning. Two methods are proposed: coordinate-wise median and coordinate-wise trimmed mean. Under the assumption that the gradient has bounded skewness, the coordinate-wise median method achieves $\tilde{O}(q\sqrt{d}/(m\sqrt{n})+d/\sqrt{nm}+\sqrt{d}/n)$. If $n\gtrsim m$, then this method is optimal in $q$, $n$ and $m$. Under the subexponential tail assumption, the coordinate-wise trimmed mean achieves $\tilde{O}(d(q/(m\sqrt{n})+1/\sqrt{nm}))$, which is also optimal. A new approach based on Huber loss minimization was proposed in \cite{zhao2023huber}, which has advantages of not requiring precise knowledge of $q$ and suitability to worker machines with unequal number of samples. However, these methods are not optimal in $d$. As a result, in large scale models, the performance of these models are not desirable. There are also several works on non-i.i.d samples, such as RSA \cite{li2019rsa} and RAGA \cite{zuo2024byzantine}.

Recently, \cite{zhu2023byzantine} shows that by using several recent high dimensional robust mean estimation methods \cite{diakonikolas2016robust,diakonikolas2017being,diakonikolas2020outlier,steinhardt2018robust,zhu2022a,zhu2022b,zhu2022c,diakonikolas2023algorithmic} as the gradient aggregator functions, the error rate of federated learning becomes nearly optimal not only in $m$, $n$, $q$, but also in dimensionality $d$, up to a logarithm factor.  

\subsection{Federated learning with arbitrary number of Byzantine machines}\label{sec:related-arbitrary}
The condition that less than half worker machines are attacked may not hold in practice. In this case, the methods mentioned above no longer works. If $q>m/2$, without additional information, it is impossible to provide a precise solution. \cite{cao2019distributed} provides a simple method with the help of a clean auxiliary dataset. The basic idea is to calculate the gradient vector only using the auxiliary dataset as a baseline, and then filter out gradient vectors uploaded from worker machines that are too far away from such baseline. A slightly different method was proposed in \cite{regatti2020bygars}, which introduces reputation scores as the weights for gradient. However, the error rate of these methods is $\|\hat{\mathbf{w}}-\mathbf{w}^*\| = O(\sqrt{d/N_A})$, with $N_A$ being the size of auxiliary dataset. This rate is not significantly improved compared with learning with auxiliary data only, and is undesirable in high dimension problems. A significantly different method called Zeno was proposed in \cite{xie2019zeno}, which formulates a stochastic descent score to filter out adversarial workers. \cite{xie2020zeno++} proposed Zeno++, an improvement to Zeno. The main advantage of Zeno++ is the suitability under asynchronous setting. Moreover, by computing a first order approximation of the gradient descent score, this method significantly improves the computational efficiency. However, the error bound is also significantly suboptimal. In particular, the error rate of Zeno and Zeno++ is still $O(\sqrt{d/N_A})$ (this comes from calculating the term $V_3$ in Theorem 1 in \cite{xie2020zeno++}), which also scales badly with the increase of dimensionality. To the best of our knowledge, our work is the first attempt to solve Byzantine tolerant distributed learning problem in high dimensions.

\section{Semi Verified Mean Estimation}\label{sec:estimation}
In this section, we analyze the semi-verified mean estimation problem, in which we hope to estimate the mean of distribution by combining a small set of clean samples and a large set of corrupted samples. 

To begin with, denote $S_0$ as the set of all untrusted samples, $\mathcal{B}$ as the set of attacked samples. Suppose that the ratio of clean samples is at least $\alpha$, then $|\mathcal{B}|\leq (1-\alpha) N$. $S_0^*:=S_0\setminus \mathcal{B}$ is the set of clean samples. Denote $\mu^*=\mathbb{E}[\mathbf{X}]$ and $V^*=\mathbb{E}[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T]$ as the statistical mean and covariance matrix, respectively, in which $\mathbf{X}\sim D$. The samples before contamination are denoted as $\mathbf{X}_1,\ldots, \mathbf{X}_N$, which are not observed. Instead, we can observe a corrupted one $\mathbf{Y}_1,\ldots, \mathbf{Y}_N$, in which
\begin{eqnarray}
	\mathbf{Y}_i = \left\{
	\begin{array}{ccc}
		X_i &\text{if} & i\notin \mathcal{B}\\
		\star &\text{if} & i\in \mathcal{B},
	\end{array}
	\right.
\end{eqnarray}
in which $\star$ means arbitrary value determined by the attacker. Apart from the corrupted dataset, an auxiliary clean set $A$ of clean samples is available, with size $N_A=|A|$. We mainly consider the case such that $N_A$ is small.

Here show the definition of two models, i.e. additive contamination model and the strong version. The definitions are from \cite{diakonikolas2016robust,diakonikolas2020outlier}. We would like to remark that if less than half of samples are attacked, then the difference between these two models is not significant. However, our result indicate that if majority of samples are attacked, the parameter selection and error bounds are significantly different between these two models, especially if $\alpha$ is small.
\begin{defi}
	(Additive Contamination Model) Given a parameter $\alpha$ and a distribution family $\mathcal{F}$ on $\mathbb{R}^d$, suppose that there are $N$ samples, in which at least $\alpha N$ of them are drawn from an unknown distribution $D\in \mathcal{F}$. The values of other samples are determined arbitrarily by the attacker.
\end{defi}
\begin{defi}
	(Strong Contamination Model) Given a parameter $\alpha$ and a distribution family $\mathcal{F}$ on $\mathbb{R}^d$, suppose that there are $N$ samples drawn from an unknown distribution $D\in \mathcal{F}$. The adversary is allowed to inspect the samples, and change the values of at most $(1-\alpha)N$ samples arbitrarily.
\end{defi}



Under additive contamination model, samples in $S_0^*$ follow distribution $D$. Therefore, an equivalent formulation of additive contamination model is that suppose $N$ samples are all generated from $D$, and then the attacker selects at most $(1-\alpha) N$ samples randomly, and alter their values arbitrarily. Strong contamination model is crucially different, since the adversary can pick samples carefully instead of randomly, before altering their values. As a result, the distribution of remaining clean samples can be far away from $D$. Therefore, strong contamination model is more challenging. Even if we can identify good samples from the corrupted dataset, estimation of $\mu^*$ is still not guaranteed. Practical scenario usually lie in between these two models. In distributed learning problems, the attacked working machines are usually not randomly selected, thus additive contamination model underestimates the impact of Byzantine attacks. On the contrary, strong contamination model tend to overestimate such impact, since it is unlikely for the adversary to gather full information and design optimal attack strategy. In this work, we analyze both two models.

Now we clarify the knowledge of the adversary.

\begin{ass}\label{ass:knowledge}
	The adversary knows the underlying distribution $D$. Moreover, under strong contamination model, the adversary also knows original sample values $\mathbf{X}_1,\ldots, \mathbf{X}_N$. However, the adversary has no knowledge of the clean auxiliary data $A$.
\end{ass}

Assumption \ref{ass:knowledge} requires that the adversary has no knowledge of $A$. This is both practical and necessary. In real scenarios, it is usually not hard to collect only a small set of auxiliary clean data from a reliable source that is not inspected by the attacker, thus it is practical to assume that adversary does not know sample values in $A$. To see why Assumption \ref{ass:knowledge} is necessary, consider a simple attack strategy: if the adversary knows $A$, just flip half of clean samples with respect to the sample mean of $A$. Recall that the unobserved clean dataset is denoted as $\{\mathbf{X}_1,\ldots, \mathbf{X}_N \}$. The attacker can just let $\mathbf{Y}_i = 2\mu(A)- \mathbf{X}_i$ for half of samples, in which $\mu(A)$ is the sample mean of auxiliary dataset $A$, and $\mathbf{Y}_i=\mathbf{X}_i$ for others. As a result, the corrupted set will have two clusters that are placed symmetrically around $\mu(A)$, and thus it is impossible to distinguish which one is closer to the ground truth $\mu^*$. Therefore, it is necessary to assume that the adversary can not observe auxiliary dataset $A$, otherwise the overall estimation accuracy can not be better than using $A$ only. 

Here we describe the algorithm as following, and the formal statement is shown in Algorithm \ref{alg}. This algorithm is partially motivated by \cite{diakonikolas2021list}. Initialize $S=S_0$. Firstly, we use a prefilter (step \ref{step: prefilter}) to remove the samples whose norms are too large. The prefilter is practically not necessary, and the threshold is also not important. This step is mainly used to simplify theoretical analysis. Then we remove points in $S$ iteratively. We manage to ensure that most of the removed points are corrupted, so that $S$ gradually becomes cleaner. 

In each step, we first calculate the sample mean and covariance:
\begin{eqnarray}
	\mu(S) &=& \frac{1}{|S|}\sum_{i\in S} \mathbf{Y}_i,\label{eq:mean}\\
	V(S)&=&\frac{1}{|S|}\sum_{i\in S} (\mathbf{Y}_i-\mu(S))(\mathbf{Y}_i-\mu(S))^T.
	\label{eq:cov}
\end{eqnarray}
Then we conduct spectral decomposition. If some eigenvalues of $V(S)$ are too large, then there should be some attacked samples which are moved in the directions of corresponding eigenvectors. This indicates that some samples need to be removed, based on their projection onto the subspace corresponds to these large eigenvalues. Based on these intuition, we conduct spectral decomposition of $V(S)$, such that $V(S) = \mathbf{U}\mathbf{\Lambda}\mathbf{U}^T$, with $\mathbf{\Lambda} = \diag(\lambda_1,\ldots, \lambda_d)$, $\lambda_1\geq \ldots \geq \lambda_d$. If there are $p$ eigenvalues larger than a certain threshold $\lambda_c$, i.e. $\lambda_p\geq \lambda_c$, then the algorithm removes some points to reduce the eigenvalue.

\begin{algorithm}[h!]
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\SetKwInOut{Parameter}{Parameter}
	
	%\underline{function Euclid} $(a,b)$\;
	\Input{Large corrupted dataset $S_0$, small clean dataset $A$}
	\Output{Estimated mean $\hat{\mu}$}
	\Parameter{$p$, $\lambda_c$}
	\BlankLine
	Initialize $S = S_0$;\\
	$S=S\setminus\{i|\|\mathbf{Y}_i\|>N^{1/3} \}$;\label{step: prefilter}\\
	\While{True}{
		Calculate sample mean $\mu(S)$ and sample covariance $V(S)$ using \eqref{eq:mean} and \eqref{eq:cov};\\
		Conduct spectral decomposition of $V(S)$, such that $V(S)=\mathbf{U}\mathbf{\Lambda} \mathbf{U}^T$, with $\mathbf{\Lambda} = \diag (\lambda_1,\ldots, \lambda_d)$, $\lambda_1\geq \ldots\geq \lambda_d$;\label{step:spectral}\\
		\eIf{$\lambda_p\geq \lambda_c$}{
			Let $\mathbf{P}=\mathbf{U}_p\mathbf{U}_p^T$, in which $\mathbf{U}_p\in \mathbb{R}^{d\times p}$ is the first $p$ columns of $\mathbf{U}$;\label{step:proj}\\
			For each $i\in S$, calculate $\tau_i$ using \eqref{eq:taudef};\\
			$\tau_{\max}=\max_{i\in S}\tau_i$;\\
			For each $i\in S$, remove $i$ from $S$ with probability $\tau_i/\tau_{\max}$\label{step:remove};
		}{
			break;
		}
	}
	Calculate $V(S)$, $\mathbf{P}$;\\
	$\hat{\mu} = \mathbf{P}\mu(A)+(\mathbf{I}-\mathbf{P})\mu(S)$;\label{step:last}\\
	\Return{$\hat{\mu}$};
	\caption{Semi verified mean estimation}\label{alg}
\end{algorithm}
To determine the samples to remove, we assign to each sample $i\in S$ with a score
\begin{eqnarray}
	\tau_i = \|\mathbf{P}V^{-\frac{1}{2}}(S)(\mathbf{Y}_i-\mu(S))\|_2^2,
	\label{eq:taudef}
\end{eqnarray}
in which $\mathbf{P}=\mathbf{U}_p\mathbf{U}_p^T$, $\mathbf{U}_p\in \mathbb{R}^{d\times p}$ is the matrix of first $p$ columns of $\mathbf{U}$. $\mathbf{P}$ is a projection matrix to the space spanned by $p$ principal components. \eqref{eq:taudef} can be understood as following. Firstly, we regularize the dataset by linear transformation with $V^{-\frac{1}{2}}(S)$. It is easy to show that samples after transformation have an identity covariance matrix:
\begin{eqnarray}
	\frac{1}{|S|}\sum_{i\in S} \left[V^{-\frac{1}{2}}(S)(\mathbf{Y}_i-\mu(S))\right]\left[V^{-\frac{1}{2}}(S)(\mathbf{Y}_i-\mu(S))\right]^T = V^{-\frac{1}{2}}(S) V(S) V^{-\frac{1}{2}}(S)=\mathbf{I}_d.
\end{eqnarray}
After transformation, if a sample is far from the mean, i.e. $\|V^{-\frac{1}{2}}(S)(\mathbf{Y}_i-\mu(S))\|$ is large, then it is likely that this sample is attacked. However, as has been discussed earlier, it would be better to remove samples according to the projection into the subspace corresponds to large eigenvalues. Therefore, we conduct a projection with matrix $\mathbf{P}$, and then use the squared distance to the mean after the projection as the score. This is exactly $\tau_i$ in \eqref{eq:taudef}. Larger $\tau_i$ indicates higher confidence that sample $i$ is attacked. In the algorithm, sample $i$ is removed with probability $\tau_i/\tau_{\max}$, in which $\tau_{\max}=\max_{i\in S} \tau_i$ is the largest $\tau$ value among $S$. We would like to remark here that the random removal with probability $\tau_i/\tau_{\max}$ is only designed for the convenience of theoretical analysis. Practically, it may not be necessary to remove samples randomly. Instead, we can just remove $k$ samples with largest $\tau$ values.

Sometimes $V(S)$ has some very small eigenvalues, thus accurate numerical computation of $V^{-\frac{1}{2}}(S)$ is hard. In this case, we can simplify the calculation of $\tau_i$ using \eqref{eq:taudef}. Consider that $\mathbf{P}=\mathbf{U}_p\mathbf{U}_p^T=\sum_{i=1}^p \mathbf{u}_i\mathbf{u}_i^T$, $V(S)=\sum_{i=1}^d \lambda_i\mathbf{u}_i\mathbf{u}_i^T$, in which $\mathbf{u}$ is the eigenvector corresponding to $\lambda_i$, hence $\mathbf{P}V^{-\frac{1}{2}}(S)=\sum_{i=1}^p \lambda_i^{-\frac{1}{2}} \mathbf{u}_i\mathbf{u}_i^T$. \eqref{eq:taudef} can then be transformed to $\tau_i=\|\sum_{i=1}^p \lambda_i^{-\frac{1}{2}} \mathbf{u}_i\mathbf{u}_i^T (\mathbf{Y}_i-\mu(S))\|_2^2$. This format can avoid the numerical problem of calculating \eqref{eq:taudef} directly.

The removal process is repeated, until $\lambda_p < \lambda_c$. Then we generate the final estimate $\hat{\mu}$ based on the intuition that the mean of $S$ is not accurate in directions with large eigenvalues, but accurate enough in other directions, since corrupted points that are far away from the mean in these directions have been removed. Therefore, for the directions with large eigenvalues, we use the reliable auxiliary data. For other directions, we just use $\mu(S)$. The resulting estimator is
\begin{eqnarray}
	\hat{\mu} = \mathbf{P}\mu(A)+(\mathbf{I}-\mathbf{P})\mu(S).
\end{eqnarray}

Furthermore, we would like to remark that the auxiliary clean data $A$ is only used in the last step (step \ref{step:last}). This is important since we need to use the assumption that the attacker has no knowledge of $A$, and ensure that the estimation error of $\mu(A)$ and $\mu(S)$ are independent.

\section{Theoretical Analysis}\label{sec:theory}

This section provides a theoretical analysis to the method proposed in Section \ref{sec:estimation}. We use the following notations: $N_A$ is the size of auxiliary dataset, $N$ is the size of untrusted dataset $S_0$, i.e. $|S_0|=N$. $\alpha$ is the ratio of clean samples in $S_0$, i.e. $|S_0^*|\geq \alpha N$. For two matrices $\mathbf{A}$ and $\mathbf{B}$, $\mathbf{A}\preceq \mathbf{B}$ if $\mathbf{B}-\mathbf{A}$ is positive semidefinite. $a\lesssim b$ if $a\leq Cb$ for some constant $C$ that does not depend on $N_A$, $N$, $d$ and $\alpha$.

We begin with the following assumption, which requires the boundedness of covariance matrix:

\begin{ass}\label{ass:var}
	Denote $\mu^*=\mathbb{E}[\mathbf{X}]$ and $V^*=\mathbb{E}[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T]$ as the mean and covariance matrix, respectively, in which $\mathbf{X}\sim D$. Then
	\begin{eqnarray}
		V^*\preceq \sigma^2 \mathbf{I}_d.
	\end{eqnarray}
\end{ass}

Right now we only assume that the distribution $D$ has bounded covariance matrix. Under stronger tail assumptions, such as boundedness of higher order moments, it is possible to further improve the convergence \cite{diakonikolas2022list,raghavendra2020list}.

\subsection{Upper Bound}
Theorem \ref{thm:additive} provides a bound of the performance of Algorithm \ref{alg} under additive contamination model.
\begin{thm}\label{thm:additive}
	Under additive contamination model, if Assumption \ref{ass:knowledge} and \ref{ass:var} hold, and parameters $p$, $\lambda_c$ satisfy
	\begin{eqnarray}
		p&>&\frac{8}{\alpha},\label{eq:m}\\
		\lambda_c&>&32\sigma^2\left(1+\frac{2d}{\alpha N}\right),\label{eq:lamc}
	\end{eqnarray}
	then
	\begin{eqnarray}
		\mathbb{E}\left[\|\hat{\mu}-\mu^*\|_2^2\right]\leq \frac{3\sigma^2 p}{N_A}+\frac{15\lambda_c}{2\alpha}+\delta_N,
		\label{eq:result}
	\end{eqnarray}
	in which $\delta_N$ decays faster than any polynomial of $N$.
\end{thm}
\begin{proof}
	The proof is shown in Section \ref{sec:additive} in the appendix.
\end{proof}

Theorem \ref{thm:additive} shows that, if $N\gtrsim d/\alpha$, $\lambda_c\sim \sigma^2$, $1/\alpha\lesssim p\lesssim N_A/\alpha$, then $\mathbb{E}\left[\|\hat{\mu}-\mu^*\|_2^2\right]\lesssim \sigma^2/\alpha$, and $\mathbb{E}[\|\hat{\mu}-\mu^*\|]\lesssim \sigma\alpha^{-1/2}$.

Algorithm \ref{alg} is a direct method for semi-verified mean estimation. This task can also be solved indirectly by converting it to list-decodable mean estimation problem \cite{charikar2017learning}. Now we compare our direct method with the indirect approach:
\begin{itemize}
	\item Our direct method has better sample efficiency. In particular, it requires less auxiliary clean samples. Even if $N_A=1$, we can let $p\sim 1/\alpha$, then $\mathbb{E}[\|\hat{\mu}-\mu^*\|]\lesssim \sigma \alpha^{-1/2}$. However, for indirect method, a single auxiliary sample is not enough. According to discussions in \cite{charikar2017learning} and \cite{cherapanamjeri2020list}, the list-decodable mean estimation methods generate a hypotheses list $\mathcal{L}$ with length $O(1/\alpha)$  whose minimum distance to the ground truth is $O(\sigma\alpha^{-1/2})$. After that, at least $O(\ln (1/\alpha))$ additional clean samples are needed to pick the optimal one from $\mathcal{L}$.
	
	\item If $N_A>1$, then our method does not need precise knowledge of $\alpha$. Previous list decodable mean estimation methods \cite{charikar2017learning,diakonikolas2018list,diakonikolas2021list,diakonikolas2022list,cherapanamjeri2020list} requires the knowledge of $\alpha$, which is usually not practical. These methods can use a conservative estimate of $\alpha$ that is lower than its truth, but the accuracy will be sacrificed. However, our method only requires $1/\alpha\lesssim p\lesssim N_A/\alpha$, which is a broad range if $N_A>1$, while the other parameter $\lambda_c$ does not depend on $\alpha$. As a result, our method is easier to use since the precise knowledge of $\alpha$ is no longer necessary.
\end{itemize}

Theorem \ref{thm:strong} shows the performance of Algorithm \ref{alg} under strong contamination model.

\begin{thm}\label{thm:strong}
	Under strong contamination model, if Assumption \ref{ass:knowledge} and \ref{ass:var} hold, $p$ satisfies \eqref{eq:m}, and $\lambda_c$ satisfies 
	\begin{eqnarray}
		\lambda_c>\frac{8\sigma^2}{\alpha} \left(1+\sqrt{\frac{16d\ln^2 N}{3\alpha N}}\right)^2,
		\label{eq:lamc-strong}
	\end{eqnarray}
	then 	
	\begin{eqnarray}
		\mathbb{E}\left[\|\hat{\mu}-\mu^*\|_2^2\right]\leq \frac{3\sigma^2 p}{N_A}+\frac{15\lambda_c}{2\alpha}+\delta_N,
		\label{eq:result_strong}
	\end{eqnarray}
	in which $\delta_N$ decays faster than any polynomial of $N$.
\end{thm}
Theorem \ref{thm:strong} is about the error rate under strong contamination model. Although \eqref{eq:result_strong} appears to be the same as \eqref{eq:result} for additive contamination model, the minimum value of $\lambda_c$ is different between these two models. If $N/\ln^2 N\gtrsim d$, ignoring constant factor, \eqref{eq:lamc-strong} is larger than \eqref{eq:lamc} with a roughly $1/\alpha$ factor. Hence, under strong contamination model, the performance is worse than in additive model. In particular, given $N/\ln^2 N\gtrsim d/\alpha$, $\lambda_c\sim \sigma^2/\alpha$, $1/\alpha \lesssim p\lesssim N_A/\alpha$, then $\mathbb{E}\left[\|\hat{\mu}-\mu^*\|_2^2\right]\lesssim \sigma^2/\alpha^2$, and $\mathbb{E}[\|\hat{\mu}-\mu^*\|]\lesssim \sigma/\alpha$.

Compared with the additive model, under strong contamination model, the estimation error is larger up to a $\alpha^{-\frac{1}{2}}$ factor. As has been discussed earlier, under additive model, good samples are mixed with adversarial samples. The distribution of good samples is not modified by the attacker. On the contrary, under strong contamination model, the attacker can inspect all samples in $S_0$ and maliciously select $(1-\alpha)N$ of them to modify their values. As a result, the distribution of remaining good samples can become far away from $D$.

%Next, we show that the rates above are optimal. In other words, it is impossible to further improve the bounds in Theorem \ref{thm:additive} and \ref{thm:strong} in general.

\subsection{Minimax lower bound}
Now we show the information theoretic lower bound of semi-verified mean estimation problem. Under additive contamination model, the minimax risk is defined as following:
\begin{eqnarray}
	R_A(\alpha) = \underset{\hat{\mu}}{\inf}\underset{D\in \mathcal{F}}{\sup}\underset{\pi_A(\alpha)}{\sup}\|\hat{\mu}-\mu^*\|_2,
	\label{eq:ra}
\end{eqnarray}
in which $\mathcal{F}$ is the set of all distributions satisfying Assumption \ref{ass:var}. $\pi_A(\alpha)$ is the policy of attacker, which maps $\mathbf{X}_i$ for $i\in S_0$ to $\mathbf{Y}_i$, $i\in S_0$. In particular, it picks $\lceil \alpha N\rceil$ samples randomly, and let $\mathbf{Y}_i=\mathbf{X}_i$ for these samples. For other samples, $\mathbf{Y}_i$ are arbitrary. $\hat{\mu}$ is the estimator, which can be any function of $\mathbf{Y}_i$ for $i\in S_0$ and $\mathbf{X}_i$ for $i\in A$. Similarly, under strong contamination model, the minimax risk is defined as
\begin{eqnarray}
	R_S(\alpha) = \underset{\hat{\mu}}{\inf}\underset{D\in \mathcal{F}}{\sup}\underset{\pi_S(\alpha)}{\sup}\|\hat{\mu}-\mu^*\|_2,
	\label{eq:rs}
\end{eqnarray}
in which $\pi_S(\alpha)$ is policy of strong contamination. It maps $\mathbf{X}_i$ to $\mathbf{Y}_i$ arbitrarily, as long as $\mathbf{Y}_i=\mathbf{X}_i$ for at least $\alpha N$ samples.

The results are shown in Theorem \ref{thm:minimax}.
\begin{thm}\label{thm:minimax}
	If 
	\begin{eqnarray}
		N_A\leq \frac{\ln \frac{d}{4}}{2\alpha \left(\ln \frac{2}{\alpha} + 1\right)},
	\end{eqnarray}
	then with probability at least $1/2-\exp[-(\ln 2-1/2)N\alpha]$,
	\begin{eqnarray}
		R_A(\alpha)&\geq& \frac{\sigma}{\sqrt{2\alpha}},\label{eq:rabound}\\
		R_S(\alpha)&\geq & \frac{\sigma}{\sqrt{2}\alpha}.
		\label{eq:rsbound}
	\end{eqnarray}
\end{thm}

The proof of Theorem \ref{thm:minimax} is provided in section \ref{sec:minimax}. The upper bound matches the minimax lower bound. Such results indicate that the error rates of Algorithm \ref{alg} are optimal. In other words, it is impossible to further improve the bounds in Theorem \ref{thm:additive} and \ref{thm:strong} in general.




\section{Application in Distributed Learning under Byzantine Attack}\label{sec:byzantine}

In this section, we formalize the problem of distributed learning under Byzantine failures. Our formalization follows \cite{chen2017distributed,yin2018byzantine,zhu2023byzantine}.

Suppose that all training samples are i.i.d following a common distribution $Q$. Let $f(\mathbf{w}, \mathbf{z})$ be a loss function of a parameter vector $\mathbf{w}\in \Omega\subseteq \mathbb{R}^d$, in which $\Omega$ is the parameter space. Correspondingly, define the population risk function
\begin{eqnarray}
	F(\mathbf{w}) = \mathbb{E}[f(\mathbf{w}, \mathbf{Z})],
\end{eqnarray} 
in which $\mathbf{Z}$ follows distribution $Q$. Our goal is to learn the model with the minimizer of population risk function $F$:
\begin{eqnarray}
	\mathbf{w}^*=\underset{\mathbf{w}\in \Omega}{\arg\min}F(\mathbf{w}).
\end{eqnarray}

We consider the following model. Suppose there is a master machine $W_0$ and $m$ working machines, $W_1,\ldots, W_m$. A clean dataset $A=\{\mathbf{Z}_{01},\ldots, \mathbf{Z}_{0N_A} \}$ is stored in the master, with size $|A|=N_A$.  Each worker machine $W_i$ has $n$ samples $\mathbf{Z}_{i1},\ldots, \mathbf{Z}_{in}$. All samples stored in both master and working machines follow distribution $Q$. Under this setting, $\mathbf{w}^*$ can be learned via gradient descent, in which gradient can be estimated using sample gradients of each working machine. However, a large fraction of working machines are Byzantine. Denote $\mathcal{B}$ as the set of Byzantine machines. It is guaranteed that at least $\alpha m$ working machines are not attacked, i.e. $|\mathcal{B}|\leq (1-\alpha) m$.

In each iteration, the master machine broadcasts current parameter $\mathbf{w}_t$ to all working machines. Then these working machines calculate the gradient using the local dataset:
\begin{eqnarray}
	\mathbf{X}_i =\frac{1}{n}\sum_{j=1}^n \nabla f(\mathbf{w}, \mathbf{Z}_{ij}).
	\label{eq:localgrad}
\end{eqnarray}
For any normal working machines, the master can receive $\mathbf{X}_i$ exactly. On the contrary, Byzantine machines can send arbitrary messages determined by the attacker. Denote $\mathbf{Y}_i\in \mathbb{R}^d$ as the vector received by the master, then
\begin{eqnarray}
	\mathbf{Y}_i=\left\{
	\begin{array}{ccc}
		\mathbf{X}_i &\text{if} & i\notin \mathcal{B}\\
		\star &\text{if} & i\in \mathcal{B}.
	\end{array}
	\right.
	\label{eq:sendmaster}
\end{eqnarray}
We use the semi-verified mean estimation algorithm (Algorithm \ref{alg}) to estimate the gradient vector. The parameter $\mathbf{w}$ is then updated using this estimated gradient. The detailed steps are shown in Algorithm \ref{alg:learning}.
\begin{algorithm}[h!]
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\SetKwInOut{Parameter}{Parameter}
	
	\Input{Master machine $W_0$, working machines $W_1,\ldots, W_m$}
	\Output{Estimated weight $\hat{\mathbf{w}}$}
	\Parameter{Initial weight parameter $\mathbf{w}_0\in \Omega$, step length $\eta$, algorithm parameters $p$, $\lambda_c$}
	\BlankLine
	\For{$t=0,1,\ldots, T-1$}{
		\underline{Master machine}: broadcast current parameter $\mathbf{w}_t$ to all working machines;\\
		\For{$i\in [m]$ \textbf{in parallel}}{
			\underline{Worker machine $i$}: compute local gradient $\mathbf{X}_i$ using \eqref{eq:localgrad};\\
			\eIf{$i$ is normal machine}{
				send $\mathbf{X}_i$ to master;
			}{
				send arbitrary $d$ dimensional vector to master;
			}
		}
		\underline{Master machine}: Receive $\mathbf{Y}_i$, $i=1,\ldots, m$ from each working machine;\\
		Calculate aggregated gradient $g(\mathbf{w}_t)$ using Algorithm \ref{alg}, in which $S_0=\{\mathbf{Y}_1, \ldots, \mathbf{Y}_m\}$, $A$ is the clean dataset stored in the master, with parameter $p, \lambda_c$;\\
		Update parameter $\mathbf{w}_{t+1} = \mathbf{w}_t-\eta g(\mathbf{w}_t)$;
	}
	\caption{Robust Distributed Gradient Descent}\label{alg:learning}
\end{algorithm}

We then provide a theoretical analysis to the distributed learning method in Algorithm \ref{alg:learning}, which uses our new semi-verified mean estimation method as the aggregator function. Our analysis is based on the following assumption.
\begin{ass}\label{ass:distributed}
	(a) For all $\mathbf{w}\in \Omega$, $\nabla f(\mathbf{w}, \mathbf{Z})$ is sub-exponential with parameter $\sigma$, i.e.
	\begin{eqnarray}
		\underset{\mathbf{v}:\|\mathbf{v}\|_2=1}{\sup}\mathbb{E}\left[\exp\left(\lambda \mathbf{v}^T\left(\nabla f(\mathbf{w}, \mathbf{Z})-\nabla F(\mathbf{w})\right)\right)\right]\leq e^{\frac{1}{2}\sigma^2\lambda^2}, \forall |\lambda|\leq \frac{1}{\sigma};
	\end{eqnarray}
	(b) $F(\mathbf{w})$ is $\alpha$-strong convex and $L$-smooth in $\mathbf{w}$.
\end{ass}

(a) is more restrictive than Assumption \ref{ass:var}. (a) requires the distribution of gradient values to be sub-exponential, while the latter only requires bounded eigenvalues of covariance matrix. Such strengthened assumption is made only for theoretical completeness. For (b), despite that our theoretical results are derived under the assumption that $F$ is strong convex, similar to \cite{yin2018byzantine}, our analysis can be easily generalized to the case with non-strong convex and nonconvex functions.

%We then make assumptions about parameters.
%\begin{ass}\label{ass:param}
%	$\eta\leq 1/L$, $p>8/\alpha$, and
%	\begin{eqnarray}
	%		\lambda_c > 32\frac{\sigma^2}{n}\left(1+\frac{2d}{\alpha m}\right).
	%		\label{eq:lamc-dl}
	%	\end{eqnarray}
%\end{ass}
Theorem \ref{thm:distributed} bounds the final error of $\hat{\mathbf{w}}$ under additive and strong contamination model.
\begin{thm}\label{thm:distributed}
	Suppose that the following conditions are satisfied: 
	
	(1) Assumption \ref{ass:knowledge} and \ref{ass:distributed} hold; 
	
	(2) $p>8/\alpha$; 
	
	(3) $\lambda_c$ satisfies
	\begin{eqnarray}
		\lambda_c > 32\frac{\sigma^2}{n}\left(1+\frac{2d}{\alpha m}\right)
		\label{eq:lamc-dl}
	\end{eqnarray}	
	under additive contamination model, or
	\begin{eqnarray}
		\lambda_c > \frac{8\sigma^2}{n\alpha} \left(1+\sqrt{\frac{16d\ln^2 m}{3\alpha m}}\right)^2.
		\label{eq:lamc-dl-strong}
	\end{eqnarray}
	under strong contamination model;
	
	(4) $\eta \leq 1/L$;
	
	(5) The size of auxiliary clean dataset satisfies
	\begin{eqnarray}
		N_A\geq 2\ln \frac{mT}{\delta}.
		\label{eq:na}
	\end{eqnarray}	
	
	Then with probability at least $1-\delta-Te^{-\frac{1}{64}\alpha N}-4Tme^{-\frac{1}{16} \lambda_cm\alpha^2 m^\frac{1}{3}\epsilon^2}$,
	\begin{eqnarray}
		\|\hat{\mathbf{w}}-\mathbf{w}^*\|\leq (1-\rho)^T\|\mathbf{w}_0-\mathbf{w}^*\|_2+\frac{\eta\Delta}{\rho},
	\end{eqnarray}
	in which $\hat{\mathbf{w}}=\mathbf{w}_T$ is the updated weight after $T$ iterations, and
	\begin{eqnarray}
		\rho = \frac{1}{2}\eta\alpha,
		\label{eq:rho}
	\end{eqnarray}
	\begin{eqnarray}
		\Delta = \sqrt{\frac{6p}{N_A}\sigma^2 \ln \frac{pT}{\delta} + \frac{15\lambda_c}{2\alpha}}.
		\label{eq:delta}
	\end{eqnarray}
\end{thm}

If $m\gtrsim d/\alpha$, $p\sim 1/\alpha$, and $T$ is large enough, then under additive contamination model, with $\lambda_c\sim \sigma^2 /n$,
\begin{eqnarray}
	\|\mathbf{w}_T-\mathbf{w}^*\|_2=\tilde{O}\left(\frac{\sigma}{\sqrt{\alpha}}\left(\frac{1}{\sqrt{N_A}}+\frac{1}{\sqrt{n}}\right)\right).
	\label{eq:final}
\end{eqnarray}

Under strong contamination model, with $\lambda_c\sim \sigma^2 / (\alpha n)$,
\begin{eqnarray}
	\|\mathbf{w}_T-\mathbf{w}^*\|_2=\tilde{O}\left(\frac{\sigma}{\sqrt{\alpha}}\left(\frac{1}{\sqrt{N_A}}+\frac{1}{\sqrt{\alpha n}}\right)\right).
\end{eqnarray}

The above results show that, as long as the number of worker machines $m$ grows proportionally with $d$, and $N_A$ grows slightly with $d$, then the learning error does not increase with dimensionality. Hence, compared with previous works \cite{cao2019distributed,xie2019zeno,xie2020zeno++}, our new method is more suitable in high dimensional problems. 

A drawback of our approach and the corresponding theoretical analysis is that we have not derived a desirable bound under sparse setting, which means that $d\gg m$, i.e. the dimensionality is much larger than the number of worker machines. In this case, theoretical value of $\lambda_c$ in \eqref{eq:lamc-dl} can be very large. This problem also happens in \cite{zhu2023byzantine} for the case with less than half worker machines attacked. However, despite such drawback in sparse settings, in our numerical experiments in section \ref{sec:numerical}, we have shown that the practical performance is still better than existing approaches. Nevertheless, it is hopeful to explore robust aggregators in sparse settings \cite{balakrishnan2017computationally,zeng2022list,diakonikolas2022list}. 

\section{Numerical Results}\label{sec:numerical}
This section provides results of numerical simulation. We compare different gradient aggregators:

\textbf{1.Master only.} This means that we only use the gradient values from the auxiliary clean data stored in the master:
\begin{eqnarray}
	g_{MasterOnly}(\mathbf{w}) = \frac{1}{N_A}\sum_{j=1}^{N_A}\nabla f(\mathbf{w}, \mathbf{Z}_{ij}).
\end{eqnarray}
We use this method as a baseline, in order to show the benefits of combining clean samples with the untrusted gradient information from worker machines.

\textbf{2.Distance based filtering.} This method comes from \cite{cao2019distributed}, which has two different versions depending on whether $q$ is known. Here we just assume that $q$ is known, in order to compare our method with a better baseline.

The idea is that among all $m$ gradient vectors from worker machines, pick $m-q$ closest one, and then calculate the weighted average:
\begin{eqnarray}
	g_{BasicFiltering}(\mathbf{w}) = \frac{N_Ag_{MasterOnly}+n\sum_{i\in \mathcal{N}(g_{MasterOnly}(\mathbf{w}), m-q)} \mathbf{Y}_i}{N_A+n(m-q)},
\end{eqnarray}
in which $\mathcal{N}(g_{MasterOnly}(\mathbf{w}), m-q)$ means the $m-q$ nearest neighbors of $g_{MasterOnly}$ among corrupted gradient vectors from worker machines, $\{\mathbf{Y}_1,\ldots, \mathbf{Y}_m \}$.

\textbf{3.Zeno.} This method was proposed in \cite{xie2019zeno}, which filter gradients by stochastic descent scores, and was improved in \cite{xie2020zeno++}. \cite{xie2020zeno++} introduces several new modifications. Here we use the first order expansion of stochastic descent score mentioned in \cite{xie2020zeno++}. Other new techniques in \cite{xie2020zeno++} are not used, since they aimed at the suitability in asynchronous scenarios, which is out of scope of our work. In particular, this method assigns a score 
\begin{eqnarray}
	Score(\mathbf{Y}_i, g_{MasterOnly}) = \gamma \langle g_{MasterOnly}, \mathbf{Y}_i\rangle - \rho\|\mathbf{Y}_i\|_2^2,
	\label{eq:sdscore}
\end{eqnarray}
and then use the average gradients from $m-q$ worker machines with highest scores:
\begin{eqnarray}
	g_{Zeno}(\mathbf{w}) = \frac{1}{m-q}\mathbf{Y}_{(i)},
\end{eqnarray} 
in which $\mathbf{Y}_{(i)}$ is the gradient vector with $i$-th highest score according to \eqref{eq:sdscore}.

\textbf{4. Our approach.} This refers to our new approach in Algorithm \ref{alg:learning}.

We would like to remark here that our method relies on auxiliary clean dataset, thus we only compare with previous methods that also use auxiliary samples. Other methods designed for $q<m/2$, such as Krum \cite{blanchard2017machine}, geometric median-means \cite{chen2017distributed}, coordinate-wise median or trimmed mean \cite{yin2018byzantine}, and recent high dimensional methods \cite{zhu2023byzantine}, are not shown here due to unfair comparison.

\subsection{Synthesized Data}

We first run experiments with distributed linear regression. The model is
\begin{eqnarray}
	V_i=\langle \mathbf{U}_i, \mathbf{w}^*\rangle +W_i,
	\label{eq:syntheticmodel}
\end{eqnarray}
in which $\mathbf{U}_i, \mathbf{w}^*\in \mathbb{R}^d$, $\mathbf{w}^*$ is the true parameter vector, $W_i$ is the i.i.d noise following normal distribution $\mathcal{N}(0,1)$. Now we randomly generate $\mathbf{w}^*$ with each coordinate follows normal distribution $\mathcal{N}(0,2)$. We generate $N=50,000$ samples. For each sample, all components of $\mathbf{U}_i$ are i.i.d following $\mathcal{N}(0,1)$, and $V_i$ are calculated using \eqref{eq:syntheticmodel}. These samples are distributed into $m= 500$ worker machines. Moreover, we have $N_A=50$ auxiliary clean samples. The results with $q=350$ and $q=150$ Byzantine machines are shown in Fig.\ref{fig:syn1} and Fig.\ref{fig:syn2}, respectively. In both experiments, we show the results with different dimensionality $d=25,50,75,100,150,200$. Here we use a simple attack strategy. If a worker is attacked, each component of the gradient vector follows $\mathcal{N}(0, 0.2)$.
% Figure environment removed

From Fig.\ref{fig:syn1}, with $70\%$ worker machines attacked, if $d=25$, then the convergence of our method (red solid curve) is nearly the same as previous methods including distance based filtering and Zeno. The advantage of our method becomes clear under with $d=50$. From (d)-(f), if $d\geq 100$, then the weight vector does not converge reasonably using previous methods. However, our new approach is still effective.
% Figure environment removed

Now we move on to the case with only $30\%$ worker machines being attacked. The results are shown in Fig.\ref{fig:syn2}. Unlike the case with $q>m/2$, here distance based filtering, Zeno and our method are all effective. However, our method is still better than previous methods.

\subsection{Real data}
Here we use MNIST dataset \cite{lecun1998mnist} to test the performance of robust gradient aggregators. MNIST dataset has $60,000$ images for training and $12,000$ images for testing. The size of each image is $28\times 28$.

The model is a neural network with one hidden layer between input and output. The size of hidden layer is $32$. In each experiment, we first randomly select $N_A=50$ images samples as the auxiliary clean dataset. The remaining samples are distributed into $m=500$ worker machines evenly. The gradients are obtained by backpropagating cross entropy loss function. The results for $q=350$ and $q=150$ are shown in Fig.\ref{fig:mnist} (a) and (b), respectively.
% Figure environment removed

In (a), majority of worker machines are attacked. In this case, distance based filtering can not capture correct gradient information in first $10$ iterations. The accuracy then begins to improve, but the performance is not competitive in general. Zeno performs much better. Our understanding is that the gradient descent score \eqref{eq:sdscore} actually selects gradient vectors whose directions are close to the gradient from auxiliary data. In neural networks with complex loss landscape, this rule may be better than filtering based entirely on distances. However, both methods still suffer from curse of dimensionality. The red solid line in the figure shows that our method performs significantly better than these previous methods. (b) shows the performances with only $30\%$ workers attacked. The results show that our method still performs better than previous methods, although not as obvious as the situation with $q/m>1/2$.

Previous results \cite{cao2019distributed,xie2019zeno,xie2020zeno++} use a much larger auxiliary dataset in their experiments. However, we only use $N_A = 50$. As a result, the accuracy scores of existing methods in our experiments are worse than these early results in general. With large $d$ and small $N_A$, auxiliary dataset is not enough to train a model. In these case,  traditional filtering techniques can improve the performance but the effects are limited. However, our new method performs significantly better.
%Previous results


\section{Conclusion}\label{sec:conc}
This paper solves the problem of high dimensional distributed learning problem under arbitrary number of Byzantine attackers. We primarily focus on the case $q>m/2$, but our method also apply in the case with $q<m/2$. To begin with, we have proposed a new method for semi-verified mean estimation, which combines a small clean dataset and a large corrupted dataset to estimate the statistical mean. We have also conducted theoretical analysis under both additive and strong contamination model. The results show that the new method is minimax rate optimal. We have then applied the semi-verified mean estimation method into the aggregator function in distributed learning. Compared with existing methods, the performance of our method is nearly the same as existing approaches under low dimensionality. In high dimension problems, our method is significantly better. Numerical results validate our theoretical analysis.

\bibliographystyle{ieeetr}
\bibliography{distributed}

\newpage

\appendix

\section{Proof of Theorem \ref{thm:additive}}\label{sec:additive}

This section shows the error bound of semi-verified mean estimation problem under additive contamination model. The notations in this section is slightly different from those in Algorithm \ref{alg}. In Algorithm \ref{alg}, $S$ is a dynamic set with some samples gradually removed, while in this section, $S$ refers to the final remaining dataset after the whole algorithm is finished. This means that $S$ is a fixed set. Furthermore, denote $S_t$ as the remaining set $S$ in Algorithm \ref{alg} after running the while loop $t$ iterations. 

The proof begins with the following lemma.

\begin{lem}\label{lem:G}
	(\cite{charikar2017learning}, Proposition B.1) With probability at least $1-e^{-\alpha N/64}$, there exists a set $G_0\subset S_0^*$ with $|G_0|\geq \alpha N/2$, and
	\begin{eqnarray}
		\left\|\frac{1}{|G_0|}\sum_{i\in G_0}(\mathbf{Y}_i-\mu^*)(\mathbf{Y}_i-\mu^*)^T\right\|_{op}\leq 8\sigma^2 \left(1+\frac{2d}{\alpha N}\right).
		\label{eq:G}
	\end{eqnarray}
\end{lem}

With this lemma, we can pick $G_0$ with $|G_0|\geq \alpha N/2$ and satisfy \eqref{eq:G}. $G_0$ can be intuitively understood as 'good data', which means that samples in $G_0$ are neither corrupted nor outliers in clean samples. Note that with a small probability $e^{-\alpha N/64}$, this is impossible. In this case, just let $G_0$ be a set of $\lceil \alpha N/2\rceil$ samples randomly selected from $S_0^*$.

Recall that 
\begin{eqnarray}
	\hat{\mu}(A)=\mathbf{P}\mu(A) + (\mathbf{I}-\mathbf{P})\mu(S),
\end{eqnarray}
in which $S$ is the remaining set after filtering. Denote $G=G_0\cap S$ and the set of remaining good samples. Then
\begin{eqnarray}
	\|\hat{\mu}-\mu^*\|_2^2 \leq 3\|\mathbf{P}(\mu(A)- \mu^*)\|_2^2 + 3\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2 + 3\|(\mathbf{I}-\mathbf{P})(\mu(G)-\mu^*)\|_2^2.
	\label{eq:mse}
\end{eqnarray}
We bound these three terms in \eqref{eq:mse} separately.

\textbf{Bound of $\|\mathbf{P}(\mu(A)- \mu^*)\|_2^2$.} We prove the following lemma:
\begin{lem}\label{lem:I1bound}
	\begin{eqnarray}
		\mathbb{E}[\|\mathbf{P}(\mu(A)-\mu^*)\|_2^2]\leq \frac{\sigma^2 p}{N_A}.	
	\end{eqnarray}
\end{lem}
Recall that in Algorithm \ref{alg}, the auxiliary clean set $A$ is only used in the last step, and the attacker has no knowledge of $A$. As a result, $\mathbf{P}$ and samples in $A$ are mutually independent. Hence
\begin{eqnarray}
	\mathbb{E}[\|\mathbf{P}(\mu(A)-\mu^*)\|_2^2]&=&\mathbb{E}[\tr(\mathbf{P}(\mu(A)-\mu^*)(\mu(A)-\mu^*)^T\mathbf{P})]\nonumber\\
	&\leq & \frac{1}{|A|}\mathbb{E}[\tr(\sigma^2 \mathbf{P})]\nonumber\\
	&=&\frac{\sigma^2 p}{N_A},
	\label{eq:I1}
\end{eqnarray}
in which $\tr$ denotes trace of a matrix. For the last step, recall that $N_A=|A|$ is the size of auxiliary dataset, and $\mathbf{P}=\mathbf{U}_p\mathbf{U}_p^T$, with $\mathbf{U}_p$ being the matrix of first $p$ column (step \ref{step:proj} in Algorithm \ref{alg}).	

\textbf{Bound of $\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2$.} 
We show the following lemma:
\begin{lem}\label{lem:I2bound}
	Under the following conditions: (1) \eqref{eq:G} holds; (2) there exists an $\epsilon\in (0,1)$, such that
	\begin{eqnarray}
		\lambda_c&\geq& 32\sigma^2 \left(1+\frac{2d}{\alpha N}\right)\frac{1+\epsilon}{1-\epsilon},\label{eq:lamc2}\\
		p&\geq &\frac{8(1+\epsilon)}{\alpha(1-\epsilon)};\label{eq:m2}
	\end{eqnarray}
	
	(3) In all iterations in Algorithm \ref{alg}, denote $L_t\subset S_t$ as removed samples in step $t$, $G_t=G_0\cap S_t$ is the set of remaining good data after $t$ iterations, $L_{Gt}=L_t\cap G_t$, then for all iterations,
	\begin{eqnarray}
		\frac{|L_{Gt}|}{|G_t|}&\leq& \frac{1+\epsilon}{|G_t|}\sum_{i\in G}\frac{\tau_i}{\tau_{\max}},\label{eq:cond1}\\
		\frac{|L_t|}{|S_t|}&\geq & \frac{1-\epsilon}{|S_t|}\sum_{i\in S}\frac{\tau_i}{\tau_{\max}}.\label{eq:cond2}
	\end{eqnarray}
	Then
	\begin{eqnarray}
		\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2 \leq \frac{2\lambda_c}{\alpha}.
		\label{eq:I2bound}
	\end{eqnarray}
\end{lem}
\begin{proof}
	The proof is shown in Appendix \ref{sec:I2bound}.
\end{proof}
Now we discuss three conditions in Lemma \ref{lem:I2bound}. For (1), Lemma \ref{lem:G} has shown that \eqref{eq:G} holds with high probability. (2) has been guaranteed in the statements in Theorem \ref{thm:additive}. It remains to show that \eqref{eq:cond1} and \eqref{eq:cond2} also hold with high probability. The result is stated in the following lemma.
\begin{lem}\label{lem:prob}
	\begin{eqnarray}
		\text{P}\left(\exists t, \frac{|L_{Gt}|}{|G_t|}> \frac{1+\epsilon}{|G_t|}\sum_{i\in G}\frac{\tau_i}{\tau_{\max}} \text{ or } 	\frac{|L_t|}{|S_t|}< \frac{1-\epsilon}{|S_t|}\sum_{i\in S}\frac{\tau_i}{\tau_{\max}}\right)\leq 4N\exp\left[-\frac{1}{16}\lambda_cm\alpha^2 N^\frac{1}{3}\epsilon^2\right].
	\end{eqnarray}
\end{lem}
\begin{proof}
	The proof is shown in section \ref{sec:prob}.
\end{proof}
If at least one of conditions \eqref{eq:G}, \eqref{eq:cond1}, \eqref{eq:cond2} are violated, then due to the prefilter step (step \ref{step: prefilter}) in Algorithm \ref{alg}, the maximum distance between any two samples is at most $2N^{1/3}$. Therefore, $\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2\leq 4N^{2/3}$ always hold. With Lemma \ref{lem:G} and \ref{lem:prob}, \eqref{eq:I2highp} is violated with exponential decaying probability. As a result, 
\begin{eqnarray}
	\mathbb{E}[\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2]\leq \frac{2\lambda_c}{\alpha} + 4N^\frac{2}{3}\left[e^{-\frac{1}{64}\alpha N}+4N\exp\left(-\frac{1}{16}\lambda_cm\alpha^2N^\frac{1}{3}\epsilon^2\right)\right].
	\label{eq:I2}
\end{eqnarray}

\textbf{Bound of $\|(\mathbf{I}-\mathbf{P})(\mu(G)-\mu^*)\|_2^2$.} We show the following lemma:
\begin{lem}\label{lem:I3bound}
	If \eqref{eq:G}, \eqref{eq:lamc2} and \eqref{eq:m2} hold, then
	\begin{eqnarray}
		\|(\mathbf{I}-\mathbf{P})(\mu(G)-\mu^*)\|_2^2\leq \frac{\lambda_c}{2\alpha}.
		\label{eq:I3bound}
	\end{eqnarray}
\end{lem}
\begin{proof}
	The proof is shown in Appendix \ref{sec:I3bound}.
\end{proof}

Following the same argument as \eqref{eq:I2}, we get
\begin{eqnarray}
	\mathbb{E}[\|(\mathbf{I}-\mathbf{P})(\mu(G)-\mu^*)\|_2^2]=\frac{\lambda_c}{2\alpha} + 4e^{-\frac{1}{64}\alpha N}N^\frac{2}{3}.
	\label{eq:I3}
\end{eqnarray}
By \eqref{eq:mse}, \eqref{eq:I1}, \eqref{eq:I2} and \eqref{eq:I3},
\begin{eqnarray}
	\mathbb{E}[\|\hat{\mu}-\mu^*\|_2^2]\leq \frac{3\sigma^2 p}{N_A}+\frac{15\lambda_c}{2\alpha} + \delta_N,
\end{eqnarray}
in which $\delta_N$ decays faster than any polynomial of $N$.

\textbf{Proof of Auxiliary Lemmas.} Here we prove lemmas mentioned above.
\subsection{Proof of Lemma \ref{lem:I2bound}}\label{sec:I2bound}

Denote $Q=S\setminus G$ as the remaining corrupted samples that are not filtered by Algorithm \ref{alg}. Since $\mathbf{P}$ is a projection matrix, $\mathbf{P}^2 = \mathbf{P}$ and $\mathbf{P}=\mathbf{P}^T$. For any vector $\mathbf{u}$ with $\|\mathbf{u}\|_2=1$,
\begin{eqnarray}
	&&\mathbf{u}^T (\mathbf{I}-\mathbf{P})V(S)(\mathbf{I}-\mathbf{P})\mathbf{u} \nonumber\\
	&=& \frac{1}{|S|}\mathbf{u}^T (\mathbf{I}-\mathbf{P})\left[\sum_{i\in S} (\mathbf{Y}_i-\mu(S))(\mathbf{Y}_i-\mu(S))^T\right] (\mathbf{I}-\mathbf{P})\mathbf{u}\nonumber\\
	&=& \frac{1}{|S|}\mathbf{u}^T (\mathbf{I}-\mathbf{P})\left[\sum_{i\in G} (\mathbf{Y}_i-\mu(G)) (\mathbf{Y}_i-\mu(G))^T + |G|(\mu(G)- \mu(S))(\mu(G)-\mu(S))^T\right.\nonumber\\
	&& \left. + \sum_{i\in Q}(\mathbf{Y}_i-\mu(Q))(\mathbf{Y}_i-\mu(Q))^T + |Q|(\mu(Q)-\mu(S))(\mu(Q)-\mu(S))^T\right] (\mathbf{I}-\mathbf{P})\mathbf{u}\nonumber\\
	&\geq & \frac{1}{|S|}\mathbf{u}^T (\mathbf{I}-\mathbf{P})\left[|G|(\mu(G)- \mu(S))(\mu(G)-\mu(S))^T\right.\nonumber\\
	&&\left.+|Q|(\mu(Q)-\mu(S))(\mu(Q)-\mu(S))^T\right](\mathbf{I}-\mathbf{P})\mathbf{u}\nonumber\\
	&\geq & \frac{|G|}{|Q|}\mathbf{u}^T (\mathbf{I}-\mathbf{P})(\mu(G)-\mu(S))(\mu(G)-\mu(S))^T (\mathbf{I}-\mathbf{P})\mathbf{u}.
	\label{eq:diff}
\end{eqnarray}
For the last step, note that $\mu(\cdot)$ is the sample mean, hence $|S|\mu(S)=|G|\mu(G)|+|Q|\mu(Q)$. Hence,
\begin{eqnarray}
	\mu(Q)-\mu(S) = -\frac{|G|}{|Q|}(\mu(G) -\mu(S)).
	\label{eq:meandiff}
\end{eqnarray}
\eqref{eq:meandiff} is then used to derive the last step in \eqref{eq:diff}.

Denote $\lambda_{k+1}(S)$ as the $(k+1)$-th largest eigenvalue of $V(S)$. Recall step \ref{step:spectral} and \ref{step:proj} in Algorithm \ref{alg}, $V(S) = \sum_{i=1}^d \lambda_i(S)\mathbf{u}_i\mathbf{u}_i^T$, in which $\lambda_i(S)$ is the $i$-th largest eigenvalue of $V(S)$. Therefore
\begin{eqnarray}
	(\mathbf{I}-\mathbf{P})V(S) (\mathbf{I}-\mathbf{P})=\sum_{i=k+1}^d \lambda_i(S)\mathbf{u}_i\mathbf{u}_i^T,
\end{eqnarray}
hence for any $\mathbf{u}$ with $\|\mathbf{u}\|_2=1$, $\mathbf{u}^T (\mathbf{I}-\mathbf{P})V(S) (\mathbf{I}-\mathbf{P}) \mathbf{u}\leq \lambda_{k+1} (S)$. Let 
\begin{eqnarray}
	\mathbf{u} = \frac{(\mathbf{I}-\mathbf{P})(\mu(G)-\mu(S))}{\|(\mathbf{I}-\mathbf{P})(\mu(G)-\mu(S))\|_2},
\end{eqnarray}
then from \eqref{eq:diff},
\begin{eqnarray}
	\lambda_{k+1}(V(S))\geq \frac{|G|}{|Q|}\|(\mathbf{I}-\mathbf{P})(\mu(G)-\mu(S))\|_2^2.
	\label{eq:sgdist1}
\end{eqnarray}
$|Q|<|S|$ always hold, thus \eqref{eq:sgdist1} implies 	\begin{eqnarray}
	\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2 \leq \frac{|S|}{|G|}\lambda_{k+1}(S).
	\label{eq:sgdist}
\end{eqnarray}
It remains to bound $|S|/|G|$. From \eqref{eq:m} and \eqref{eq:lamc}, 
From now on, suppose the following condition hold: 
We will show that \eqref{eq:cond1} and \eqref{eq:cond2} hold with high probability later. Now suppose that these two conditions hold for all iterations, then the following lemma holds:

\begin{lem}\label{lem:transition}
	With \eqref{eq:lamc2} and \eqref{eq:m2}, under \eqref{eq:G}, if \eqref{eq:cond1} and \eqref{eq:cond2} is satisfied in all iterations, then for all iterations $t=1,2,\ldots$,
	\begin{eqnarray}
		\frac{|G_t|}{\sqrt{|S_t|}}\geq \frac{|G_0|}{\sqrt{|S_0|}}.
		\label{eq:transition}
	\end{eqnarray}
\end{lem}
\begin{proof}
	The proof is shown in section \ref{sec:transition}.
\end{proof}
\begin{cor}\label{cor}
	Under the conditions of Lemma \ref{lem:transition}, $|G|\geq \alpha^2 N/4$, $|S|/|G|\leq 2/\alpha$.
\end{cor}
\begin{proof}
	From Lemma \ref{lem:transition}, 
	\begin{eqnarray}
		\sqrt{|G|} \geq \frac{|G|}{\sqrt{|S|}}\geq \frac{|G_0|}{\sqrt{|S_0|}}=\frac{1}{2}\alpha\sqrt{N},
	\end{eqnarray} 	
	in which the first inequality holds because $G\subset S$, and
	\begin{eqnarray}
		\frac{|S|}{|G|}=\sqrt{|S|}\frac{\sqrt{|S|}}{|G|}\leq \sqrt{|S|}\frac{\sqrt{|S_0|}}{|G_0|}\leq |S_0|/|G_0|\leq \frac{2}{\alpha}.
	\end{eqnarray}
\end{proof}
After all iterations, $\lambda_{k+1}(S)\leq \lambda_k(S)\leq \lambda_c$. From Corollary \ref{cor}, under \eqref{eq:G}, \eqref{eq:cond1} and \eqref{eq:cond2}, 
\begin{eqnarray}
	\|(\mathbf{I}-\mathbf{P})(\mu(S)-\mu(G))\|_2^2 \leq \frac{2\lambda_c}{\alpha}.
	\label{eq:I2highp}
\end{eqnarray}
\subsection{Proof of Lemma \ref{lem:transition}}\label{sec:transition}

We show the following lemmas first.

\begin{lem}\label{lem:proj}
	\begin{eqnarray}
		\|\mathbf{P}V^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))\|_2^2\leq \frac{|S_t|}{|G_t|}.
	\end{eqnarray}
\end{lem}
\begin{proof}
	The proof is similar to the proof of Lemma \ref{lem:I2bound} in section \ref{sec:I2bound}. Denote $Q_t=S_t\setminus G_t$. For any $\mathbf{u}$ with $\|\mathbf{u}\|_2=1$,
	\begin{eqnarray}
		\mathbf{u}^T \mathbf{P}\mathbf{u} &=& \mathbf{u}^T V^{-\frac{1}{2}}(S_t)V(S_t)V^{-\frac{1}{2}}(S_t)\mathbf{P}\mathbf{u}\nonumber\\
		&=&\frac{1}{|S_t|}\mathbf{u}^T \mathbf{P}V^{-\frac{1}{2}}(S_t)\sum_{i\in S}(\mathbf{Y}_i-\mu(S_t))(\mathbf{Y}_i-\mu(S_t))^TV^{-\frac{1}{2}}(S_t) \mathbf{P}\mathbf{u}\nonumber\\
		&\geq & \frac{1}{|S_t|}\mathbf{u}^T\mathbf{P}V^{-\frac{1}{2}}(S_t)[|G_t|(\mu(G_t)-\mu(S_t))(\mu(G_t)-\mu(S_t))^T\nonumber\\
		&&+|Q|(\mu(Q)-\mu(S_t))(\mu(Q)-\mu(S_t))^T]V^{-\frac{1}{2}}(S_t) \mathbf{P}\mathbf{u}\nonumber\\
		&=&\frac{|G_t|}{|Q|}\mathbf{u}^T \mathbf{P}V^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))(\mu(G_t)-\mu(S_t))^TV^{-\frac{1}{2}}(S_t)\mathbf{P}\mathbf{u}.
	\end{eqnarray}
	Let
	\begin{eqnarray}
		\mathbf{u}=\frac{PV^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))}{\|PV^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))\|_2},
	\end{eqnarray}	
	since $\mathbf{P}$ is a projection matrix, $\mathbf{u}^T \mathbf{P}\mathbf{u}\leq 1$. Hence
	\begin{eqnarray}	\|\mathbf{P}V^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))\|_2^2\leq \frac{|Q|}{|G_t|}.
	\end{eqnarray}
	Lemma \ref{lem:proj} can then be proved using the fact that $|Q|<|S_t|$.
\end{proof}
\begin{lem}\label{lem:tau}
	Under \eqref{eq:G}, 
	\begin{eqnarray}
		\frac{1}{|G_t|}\sum_{i\in G}\tau_i &\leq& 8\sigma^2 \left(1+\frac{2d}{\alpha N}\right) \frac{p}{\lambda_p(S_t)}+\frac{|S_t|}{|G_t|},\label{eq:taug}\\
		\frac{1}{|S_t|}\sum_{i\in S}\tau_i &=& p.\label{eq:taus}
	\end{eqnarray}
\end{lem}
\begin{proof}
	\textbf{Proof of \eqref{eq:taug}}.
	\begin{eqnarray}
		\frac{1}{|G_t|}\sum_{i\in G}\tau_i &=& \frac{1}{|G_t|}\sum_{i\in G}\|\mathbf{P} V^{-\frac{1}{2}}(S_t) (\mathbf{Y}_i-\mu(S_t))\|_2^2\nonumber\\
		&=&\frac{1}{|G_t|}\sum_{i\in G}\tr(\mathbf{P}V^{-\frac{1}{2}}(S_t) (\mathbf{Y}_i-\mu(S_t))(\mathbf{Y}_i-\mu(S_t))^T V^{-\frac{1}{2}}(S_t)\mathbf{P})\nonumber\\
		&=&\frac{1}{|G_t|}\sum_{i\in G}\tr(\mathbf{P}V^{-\frac{1}{2}}(S_t)(\mathbf{Y}_i-\mu(G_t))(\mathbf{Y}_i-\mu(G_t))^T V^{-\frac{1}{2}}(S_t)\mathbf{P})\nonumber\\
		&&+\tr(\mathbf{P}V^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))(\mu(G_t)-\mu(S_t))^T V^{-\frac{1}{2}}(S_t)\mathbf{P})\nonumber\\
		&\overset{(a)}{\leq} & 8\sigma^2 \left(1+\frac{2d}{\alpha N}\right)\tr(\mathbf{P}V^{-1}(S_t)\mathbf{P})+\|PV^{-\frac{1}{2}}(S_t)(\mu(G_t)-\mu(S_t))\|_2^2\nonumber\\
		&\overset{(b)}{\leq} & 8\sigma^2 \left(1+\frac{2d}{\alpha N}\right)\tr(\mathbf{P}V^{-1}(S_t)\mathbf{P}) + \frac{|S_t|}{|G_t|}\nonumber\\
		&\overset{(c)}{\leq} & 8\sigma^2 \left(1+\frac{2d}{\alpha N}\right)\sum_{i=1}^m \frac{1}{\lambda_i(S_t)}+\frac{|S_t|}{|G_t|}\nonumber\\
		&\leq & 8\sigma^2\left(1+\frac{2d}{\alpha N}\right)\frac{p}{\lambda_p(S_t)}+\frac{|S_t|}{|G_t|}.
	\end{eqnarray}
	For (a), from \eqref{eq:G},
	\begin{eqnarray}
		\frac{1}{|G_t|}\sum_{i\in G}(\mathbf{Y}_i-\mu(G_t))(\mathbf{Y}_i-\mu(G_t))^T\preceq \frac{1}{|G_t|}\sum_{i\in G}(\mathbf{Y}_i-\mu^*)(\mathbf{Y}_i-\mu^*)^T\leq 8\sigma^2\left(1+\frac{2d}{\alpha N}\right).
	\end{eqnarray}
	(b) comes from Lemma \ref{lem:proj}. For (c), note that
	\begin{eqnarray}
		V(S_t)=\sum_{i=1}^d \lambda_i(S_t)\mathbf{u}_i\mathbf{u}_i^T,
	\end{eqnarray}
	and $\mathbf{P}\mathbf{u}_i=\mathbf{u}_i$ for $i\leq m$, $\mathbf{P}\mathbf{u}_i=\mathbf{0}$ for $i>m$, then
	\begin{eqnarray}
		\mathbf{P}V^{-1}(S_t)\mathbf{P} = \sum_{i=1}^d \frac{1}{\lambda_i(S_t)}\mathbf{P}\mathbf{u}_i\mathbf{u}_i^T \mathbf{P} = \sum_{i=1}^m \frac{1}{\lambda_i(S_t)}\mathbf{u}_i\mathbf{u}_i^T,
	\end{eqnarray}
	thus $\tr(\mathbf{P} V^{-1}(S_t)\mathbf{P})=\sum_{i=1}^m 1/\lambda_i(S_t)$.
	
	\textbf{Proof of \eqref{eq:taus}}. 
	\begin{eqnarray}
		\frac{1}{|S_t|}\sum_{i\in S}\tau_i &=&\frac{1}{|S_t|}\sum_{i\in S}\tr(\mathbf{P} V^{-\frac{1}{2}}(S_t)(\mathbf{Y}_i-\mu(S_t))(\mathbf{Y}_i-\mu(S_t))^T V^{-\frac{1}{2}}(S_t)\mathbf{P})\nonumber\\
		&=&\tr(\mathbf{P}V^{-\frac{1}{2}}(S_t) V(S_t) V^{-\frac{1}{2}}(S_t)\mathbf{P})\nonumber\\
		&=&\tr(\mathbf{P}) = p.
	\end{eqnarray}
	The proof is complete.
\end{proof}
Now it remains to prove Lemma \ref{lem:transition} with the above lemmas. The proof is by induction. \eqref{eq:transition} holds clearly for $t=0$. Therefore, it remains to show that if \eqref{eq:transition} holds for some $t$, then it must also hold for $t+1$. From \eqref{eq:lamc2}, 
\begin{eqnarray}
	\lambda_p(S_t)\geq \lambda_c\geq 32\sigma^2\left(1+\frac{2d}{\alpha N}\right)\frac{1+\epsilon}{1-\epsilon},
\end{eqnarray}
and from \eqref{eq:m2},
\begin{eqnarray}
	\frac{|S_t|}{|G_t|}=\sqrt{|S_t|}\frac{\sqrt{|S_t|}}{|G_t|}\leq \sqrt{|S_t|}\frac{\sqrt{|S_0|}}{|G_0|}\leq \frac{|S_0|}{|G_0|}=\frac{2}{\alpha}\leq \frac{1}{4}p\frac{1-\epsilon}{1+\epsilon}
\end{eqnarray}
Using \eqref{eq:taug}, 
\begin{eqnarray}
	\frac{1}{|G_t|}\sum_{i\in G}\tau_i &\leq& 8\sigma^2 \left(1+\frac{2d}{\alpha N}\right) \frac{p}{\lambda_p(S_t)}+\frac{|S_t|}{|G_t|}\\
	&\leq & \frac{1}{4}p\frac{1-\epsilon}{1+\epsilon}+\frac{1}{4}p\frac{1-\epsilon}{1+\epsilon}\nonumber\\
	&=&\frac{1}{2}p\frac{1-\epsilon}{1+\epsilon}.
\end{eqnarray}
Recall the condition \eqref{eq:cond1} and \eqref{eq:cond2}. Define $r_G(t)=|L_{Gt}|/|G_t|$ and $r(t)=|L_t|/|S_t|$ as the ratio of removed samples in $G_t$ and $S_t$. Then
\begin{eqnarray}
	\frac{r_0(t)}{r(t)}&\leq& \frac{1+\epsilon}{1-\epsilon}\frac{\frac{1}{|G_t|}\sum_{i\in G_t}\frac{\tau_i}{\tau_{\max}}}{\frac{1}{|S_t|}\sum_{i\in S_t}\frac{\tau_i}{\tau_{\max}}}\nonumber\\
	&\leq& \frac{1+\epsilon}{1-\epsilon}\frac{\frac{1}{2}p\frac{1-\epsilon}{1+\epsilon}}{p}=\frac{1}{2}.
\end{eqnarray}
Therefore, after $t+1$-th iteration,
\begin{eqnarray}
	\frac{|G_{t+1}|}{\sqrt{|S_{t+1}|}} = \frac{|G_t\setminus L_{Gt}|}{\sqrt{|S_t\setminus L_t|}}\geq \frac{|G_t|(1-r_0(t))}{\sqrt{|S_t|(1-r(t))}}\geq \frac{|G_t|(1-r_0(t))}{\sqrt{|S_t|}(1-\frac{r(t)}{2})}\geq \frac{|G_{t}|}{\sqrt{|S_{t}|}}.
\end{eqnarray}
The proof is complete.
\subsection{Proof of Lemma \ref{lem:prob}}\label{sec:prob}
Suppose there are $n$ independent random variables $Z_1,\ldots, Z_n$. $\text{P}(Z_i=1) = p_i$, and $\text{P}(Z_i=0) = 1-p_i$. Let $\bar{p}=(1/n)\sum_{i=1}^n p_i$, then we show a concentration inequality of the mean of $Z_i$. 

Let $Z=\sum_{i=1}^n Z_i$. Then
\begin{eqnarray}
	&&\mathbb{E}[e^{\lambda Z}]=\mathbb{E}\left[\exp\left(\lambda \sum_{i=1}^n Z_i\right)\right]=\Pi_{i=1}^n \mathbb{E}[e^{\lambda Z_i}] =\Pi_{i=1}^n (1-p_i+p_ie^\lambda)\nonumber\\
	&\leq & \exp\left(\sum_{i=1}^n \ln (1-p_i+p_ie^\lambda)\right)\leq \exp\left(\sum_{i=1}^n p_i(e^\lambda - 1)\right)=\exp\left(n\bar{p}(e^\lambda - 1)\right).
\end{eqnarray}
Hence
\begin{eqnarray}
	\text{P}(Z>n\bar{p}(1+\epsilon))&\leq & \underset{\lambda\geq 0}{\inf}\exp\left[-n\bar{p}(1+\epsilon)\lambda+n\bar{p}(e^\lambda - 1)\right]\nonumber\\
	&=& \exp\left[-n\bar{p}((1+\epsilon)\ln (1+\epsilon) - \epsilon)\right].
\end{eqnarray}
Similarly,
\begin{eqnarray}
	\text{P}(Z<n\bar{p}(1-\epsilon))&\leq & \underset{\lambda\geq 0}{\inf}\exp\left[n\bar{p}(1+\epsilon)\lambda+n\bar{p}(e^{-\lambda} - 1)\right]\nonumber\\
	&=& \exp\left[-n\bar{p}((1-\epsilon)\ln (1-\epsilon) - \epsilon)\right].
\end{eqnarray}
It is straightforward to show that $(1+\epsilon)\ln(1+\epsilon)\geq \epsilon+\epsilon^2/4$, $(1-\epsilon)\ln(1-\epsilon)\geq -\epsilon+\epsilon^2/2$ for $\epsilon\in (0,1)$. Therefore
\begin{eqnarray}
	\text{P}\left(\left|\frac{1}{n\bar{p}}\sum_{i=1}^n Z_i-1\right|>\epsilon\right)\leq 2e^{-\frac{1}{4}n\bar{p}\epsilon^2}.
	\label{eq:conc}
\end{eqnarray}
Now we use \eqref{eq:conc} to prove Lemma \ref{lem:prob}. For each step $t$, let $Z_i$ be the indicator that sample $i$ is removed, $n$ be the remaining samples. $n$ can be lower bounded by $\alpha^2N/4$ by Corollary \ref{cor}. $\bar{p}$ can be lower bounded by
\begin{eqnarray}
	\bar{p}\overset{(a)}{\geq} \frac{1}{|S_t|}\sum_{i\in S}\frac{\tau_i}{\tau_{\max}}\overset{(b)}{=}\frac{p}{\tau_{\max}}\overset{(c)}{\geq}\frac{\lambda_c m}{2N^\frac{2}{3}},
\end{eqnarray}
in which (a) comes from step \ref{step:remove} in Algorithm \ref{alg}. (b) comes from \eqref{eq:taus}. (c) holds because the prefilter step (step \ref{step: prefilter}) in Algorithm \ref{alg}, as well as \eqref{eq:taudef}. Hence, by taking union bound,
\begin{eqnarray}
	\text{P}\left(\exists t, \frac{|L_{Gt}|}{|G_t|}> \frac{1+\epsilon}{|G_t|}\sum_{i\in G}\frac{\tau_i}{\tau_{\max}} \text{ or } 	\frac{|L_t|}{|S_t|}< \frac{1-\epsilon}{|S_t|}\sum_{i\in S}\frac{\tau_i}{\tau_{\max}}\right)\leq 4N\exp\left[-\frac{1}{16}\lambda_cm\alpha^2 N^\frac{1}{3}\epsilon^2\right].
\end{eqnarray}

\subsection{Proof of Lemma \ref{lem:I3bound}}\label{sec:I3bound}
Under \eqref{eq:G}, we have
\begin{eqnarray}
	\|\mu(G)-\mu^*\|_2^2 &=&\underset{\|\mathbf{u}\|_2=1}{\max}\mathbf{u}^T (\mu(G)-\mu^*)(\mu(G)-\mu^*)^T\mathbf{u}\nonumber\\
	&\leq&\underset{\|\mathbf{u}\|_2=1}{\max}\mathbf{u}^T\frac{1}{|G|}\sum_{i\in G}(\mathbf{Y}_i-\mu^*)(\mathbf{Y}_i-\mu^*)^T\mathbf{u}\nonumber\\
	&\overset{(a)}{=}& \underset{\|\mathbf{u}\|_2=1}{\max}\mathbf{u}^T\frac{1}{|G|}\sum_{i\in G}(\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T\mathbf{u}\nonumber\\
	&\leq & \frac{|G_0|}{|G|}\underset{\|\mathbf{u}\|_2=1}{\max}\mathbf{u}^T\frac{1}{|G_0|}\sum_{i\in G_0}(\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T\mathbf{u}\nonumber\\
	&\overset{(b)}{\leq} & 8\sigma^2\left(1+\frac{2d}{\alpha N}\right)\frac{|G_0|}{|G|}\nonumber\\
	&\overset{(c)}{<} & \frac{\lambda_c}{2\alpha},
	\label{eq:I3highp}
\end{eqnarray}
in which (a) comes from the definition that $G_0\subset S_0^*$. Therefore, $\mathbf{Y}_i$ is not modified from the clean sample $\mathbf{X}_i$. (b) use Lemma \ref{lem:G}. (c) uses $\lambda_c>32\sigma^2(1+2d/(\alpha N))$, $|G_0|=\alpha N/2$, and from Corollary \ref{cor}, $|G|\geq \alpha^2 N/4$.

Since $\mathbf{P}$ is a projection matrix,
\begin{eqnarray}
	\|(\mathbf{I}-\mathbf{P})(\mu(G) - \mu^*)\|_2^2\leq \frac{\lambda_c}{2\alpha}.
\end{eqnarray}

\section{Proof of Theorem \ref{thm:strong}}\label{sec:strong}
In this section we show Theorem \ref{thm:strong}. Most of the proofs are the same as the proof of Theorem \ref{thm:additive}. The only exception is that Lemma \ref{lem:G} no longer holds under strong contamination model, since the adversary can modify $(1-\alpha)N$ arbitrarily. Therefore, in this section, we derive a new version of Lemma \ref{lem:G}. Other steps can just follow the proof of Theorem \ref{thm:additive} in Appendix~\ref{sec:additive}.

Our proof begins with the matrix Bernstein inequality \cite{tropp2015introduction}.
\begin{lem}\label{lem:bern}
	(From \cite{tropp2015introduction}, Theorem 1.6.2) Let $\mathbf{W}_1,\ldots, \mathbf{W}_N$ be i.i.d random matrices, with $\mathbb{E}[\mathbf{W}_i] = \mathbf{0}$, and $\|\mathbf{W}_i\|\leq L$ almost surely. Define $\mathbf{Z}=\sum_{i=1}^N \mathbf{W}_i$. Then for all $t\geq 0$,
	\begin{eqnarray}
		\text{P}(\|\mathbf{Z}\|>t)\leq 2d\exp\left(-\frac{t^2}{2N\|\mathbb{E}[\mathbf{W}\mathbf{W}^T]\|+2Lt/3}\right),
		\label{eq:bern}
	\end{eqnarray}
	in which $\mathbf{W}$ is an i.i.d copy of $\mathbf{W}_1,\ldots, \mathbf{W}_N$.
\end{lem}

Based on Lemma \ref{lem:bern}, we show the following lemma.

\begin{lem}\label{lem:Gstrong}
	With probability at least $1-\exp[-((1/2)\ln 2-1/4)N\alpha]-2d\exp(-(\ln^2 N)/2)$, there exists a set $G_0\subset S_0^*$ with $|G_0|\geq \alpha N/2$, and
	\begin{eqnarray}
		\left\|\frac{1}{|G_0|}\sum_{i\in G_0} (\mathbf{Y}_i-\mu^*)(\mathbf{Y}_i-\mu^*)^T\right\|_{op}\leq \frac{2\sigma^2}{\alpha} \left(1+\sqrt{\frac{16d\ln^2 N}{3\alpha N}}\right)^2.
	\end{eqnarray}
\end{lem}
\begin{proof}
	Recall that $\mathbf{X}_i$ for all $i\in S_0$ are samples before contamination, while $\mathbf{Y}_i$ are observed values. $\mathbf{Y}_i = \mathbf{X}_i$ for at least $\alpha N$ samples.
	
	Let
	\begin{eqnarray}
		\mathbf{W}_i &=& \frac{1}{N}(\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T \mathbf{1}\left(\|\mathbf{X}_i-\mu^*\|\leq M\right)\nonumber\\
		&&-\frac{1}{N}\mathbb{E}[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T \mathbf{1}\left(\|\mathbf{X}-\mu^*\|\leq M\right)],
	\end{eqnarray}
	in which $\mathbf{X}$ is an i.i.d copy of $\mathbf{X}_i$ for $i\in S_0$, $M$ is a truncation threshold that will be determined later. Define $\mathbf{Z}=\sum_{i=1}^N \mathbf{W}_i$. Note that $\mathbb{E}[\mathbf{W}_i] = \mathbf{0}$. Hence we can bound $\mathbf{Z}$ with high probability using Lemma \ref{lem:bern}. It remains to find $L$ and $\mathbb{E}[\mathbf{W} \mathbf{W}^T]$. From triangle inequality,
	\begin{eqnarray}
		\|\mathbf{W}\|&\leq& \frac{1}{N}\left\|(\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T \mathbf{1}(\|\mathbf{X}_i-\mu^*\|\leq M)\right\|\nonumber\\
		&&+\frac{1}{N}\left\|\mathbb{E}[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T \mathbf{1}(\|\mathbf{X}_i-\mu^*\|\leq M)]\right\|\nonumber\\
		&\leq & \frac{2M^2}{N}.
	\end{eqnarray}
	Hence, in \eqref{eq:bern}, we can let $L=2M^2/N$. Moreover,
	\begin{eqnarray}
		\mathbb{E}[\mathbf{W}\mathbf{W}^T]&=&\frac{1}{N^2}\mathbb{E}\left[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T\mathbf{1}(\|\mathbf{X}-\mu^*\|\leq M)\right]\nonumber\\
		&&-\left[\frac{1}{N}\mathbb{E}[(\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T\mathbf{1}(\|\mathbf{X}_i-\mu^*\|\leq M)]\right]^2\nonumber\\
		&\preceq& \frac{M^2}{N^2}\mathbb{E}\left[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T\right]\nonumber\\
		&=&\frac{M^2}{N^2}V^*\preceq \frac{M^2\sigma^2}{N^2} \mathbf{I}.
	\end{eqnarray}
	Therefore,
	\begin{eqnarray}
		\text{P}(\|\mathbf{Z}\|>t)\leq 2d\exp\left[-\frac{t^2}{2\frac{M^2\sigma^2}{N}+\frac{4M^2}{3N}t}\right].
	\end{eqnarray}
	Let
	\begin{eqnarray}
		t_0=\max\left\{M\sigma\sqrt{\frac{2\ln^2 N}{N}}, \frac{4M^2}{3N}\ln^2 N \right\}.
		\label{eq:t0}
	\end{eqnarray}
	Then
	\begin{eqnarray}
		\text{P}(\|\mathbf{Z}\|>t_0)\leq 2de^{-\frac{1}{2}\ln^2 N}.
		\label{eq:prob1}
	\end{eqnarray}
	If $\|\mathbf{Z}\|\leq t_0$, then
	\begin{eqnarray}
		\left\|\frac{1}{N}\sum_{i\in S_0}(\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T\mathbf{1}(\|\mathbf{X}_i-\mu^*\|\leq M)\right\|&\leq& \left\|\sum_{i\in S_0} \mathbf{W}_i\right\|+\left\|\mathbb{E}[(\mathbf{X}-\mu^*)(\mathbf{X}-\mu^*)^T]\right\|\nonumber\\
		&\leq & t_0+\sigma^2.
		\label{eq:mbound}
	\end{eqnarray}
	Let 
	\begin{eqnarray}
		M=\sqrt{\frac{4\sigma^2 d}{\alpha}}.
		\label{eq:M}
	\end{eqnarray}
	Then
	\begin{eqnarray}
		\text{P}\left(\|\mathbf{X}_i-\mu^*\|>M\right)\leq \frac{\mathbb{E}[\|\mathbf{X}_i-\mu^*\|_2^2]}{M^2}=\frac{\mathbb{E}[\tr(V^*)]}{M^2}=\frac{\sigma^2 d}{M^2}=\frac{\alpha}{4}.
	\end{eqnarray}
	Define $n=|\{i\in S_0|\|\mathbf{X}_i-\mu^*\|>M \}|$ as the number of samples whose distances to $\mu^*$ are more than $M$. From Chernoff inequality,
	\begin{eqnarray}
		\text{P}\left(n>\frac{1}{2}\alpha N\right)\leq \exp\left[-\left(\frac{1}{2}\ln 2-\frac{1}{4}\right) N\alpha\right].
		\label{eq:prob2}
	\end{eqnarray}
	Now we assume that $\|\mathbf{Z}\|\leq t_0$ and $n\leq \alpha N/2$. The probability of violating these two conditions are bounded in \eqref{eq:prob1} and \eqref{eq:prob2}, respectively. Then define
	\begin{eqnarray}
		G_0=\{i\in S_0\setminus \mathcal{B}|\|\mathbf{X}_i-\mu^*\|\leq M \}.
	\end{eqnarray}
	The size of $G_0$ is lower bounded by
	\begin{eqnarray}
		|G_0|\geq N-|\mathcal{B}|-n\geq N-(1-\alpha)N-\frac{1}{2}\alpha N=\frac{1}{2}\alpha N.
	\end{eqnarray}
	Then
	\begin{eqnarray}
		&&\left\|\frac{1}{|G_0|}\sum_{i\in G_0} (\mathbf{Y}_i-\mu^*)(\mathbf{Y}_i-\mu^*)^T\right\|\nonumber\\
		&\overset{(a)}{=}&\left\|\frac{1}{|G_0|}\sum_{i\in G_0} (\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T\right\|\nonumber\\
		&\leq &\frac{|S_0|}{|G_0|}\left\|\frac{1}{|S_0|}\sum_{i\in S_0} (\mathbf{X}_i-\mu^*)(\mathbf{X}_i-\mu^*)^T\mathbf{1}\left(\|\mathbf{X}_i-\mu^*\|\leq M\right)\right\|\nonumber\\
		&\overset{(b)}{\leq} & \frac{2}{\alpha} (\sigma^2 + t_0)\nonumber\\
		&\overset{(c)}{=}&\frac{2}{\alpha}\sigma^2\left(1+\frac{M}{\sigma}\sqrt{\frac{2\ln^2 N}{N}}+\frac{4M^2}{3N\sigma^2}\ln^2 N\right)\nonumber\\
		&\overset{(d)}{=}&\frac{2}{\alpha}\sigma^2 \left(1+\sqrt{\frac{8d\ln^2 N}{\alpha N}}+\frac{16d}{3\alpha} \frac{\ln^2 N}{N}\right)\nonumber\\
		&<&\frac{2\sigma^2}{\alpha}\left(1+\sqrt{\frac{16d\ln^2 N}{3\alpha N}}\right)^2.
		\label{eq:Gresult}
	\end{eqnarray}
	For (a), recall that for all samples that are not attacked, $\mathbf{Y}_i=\mathbf{X}_i$. (b) comes from \eqref{eq:mbound}. (c) comes from \eqref{eq:t0}. (d) comes from \eqref{eq:M}. Recall that \eqref{eq:Gresult} relies on two conditions, $\|\mathbf{Z}\|\leq t_0$ and $n\leq \alpha N/2$. Therefore, the probability that \eqref{eq:Gresult} does not hold is no more than the sum of \eqref{eq:prob1} and \eqref{eq:prob2}. The proof is complete.
\end{proof}
Under strong contamination model, Lemma \ref{lem:Gstrong} can be used to replace Lemma \ref{lem:G} under additive contamination model. Lemma \ref{lem:I1bound} still holds here. For Lemma \ref{lem:I2bound}, \eqref{eq:lamc2} becomes
\begin{eqnarray}
	\lambda_c \geq \frac{8\sigma^2}{\alpha} \left(1+\sqrt{\frac{16d\ln^2 N}{3\alpha N}}\right)^2,
	\label{eq:lamc2-strong}
\end{eqnarray}
while other conditions remain the same. Using the same steps as the proof of Lemma \ref{lem:I2bound}, it can be shown that \eqref{eq:I2bound} in Lemma \ref{lem:I2bound} holds. Similar arguments hold for Lemma \ref{lem:I3bound}. Therefore,
\begin{eqnarray}
	\mathbb{E}[\|\hat{\mu}-\mu^*\|_2^2]\leq \frac{3\sigma^2p}{N_A}+\frac{15\lambda_c}{2\alpha} + \delta_N,
\end{eqnarray}
in which $\delta_N$ decays faster than any polynomial of $N$. The proof of Theorem \ref{thm:strong} is complete.

\section{Proof of Theorem \ref{thm:minimax}}\label{sec:minimax}
\textbf{Proof of \eqref{eq:rabound}}. Now we first derive the minimax lower bound under additive contamination model.

Recall the definition of $R_A$ in \eqref{eq:ra}. Define
\begin{eqnarray}
	R_A'(\beta)=\underset{\hat{\mu}}{\inf}\underset{D\in \mathcal{F}}{\sup}\underset{\pi_A'(\beta)}{\sup} \|\hat{\mu}-\mu^*\|_2,
\end{eqnarray}
in which $\pi_A'(\beta)$ means that for each sample in $S_0$, $\mathbf{Y}_i=\mathbf{X}_i$ with probability $\beta$. In additive contamination model, whether $\mathbf{Y}_i=\mathbf{X}_i$ is independent of the value of $\mathbf{X}_i$. Note that now the number of uncorrupted samples is random, following a binomial distribution $\mathbb{B}(N, \beta)$. On the contrary, $\pi_A(\alpha)$ means that the ratio of uncorrupted sample is fixed to be at least $\alpha$. The following lemma links $R_A$ and $R_A'$.

\begin{lem}\label{lem:link}
	With probability at least $1-\exp[-(\ln 2-1/2)N\alpha]$,
	\begin{eqnarray}
		R_A(\alpha)\geq R_A'\left(\frac{\alpha}{2}\right).
	\end{eqnarray}
\end{lem}
\begin{proof}
	Let $n$ be the number of samples that are not corrupted, under corruption policy $\pi_A'(\beta)$. By Chernoff inequality, for $t>N\beta$,
	\begin{eqnarray}
		\text{P}(n>T)\leq e^{-N\beta}\left(\frac{eN\beta}{t}\right)^t.
	\end{eqnarray}
	Let $t=2N\beta$. Then
	\begin{eqnarray}
		\text{P}(n>2N\beta)\leq e^{-(2\ln 2 - 1)N\beta}.
	\end{eqnarray}
	Let $\beta=\alpha/2$. As long as $n\leq 2N\beta=N\alpha$, the corruption will be not as severe as $\pi_A(\alpha)$, then $R_A(\alpha)\geq R_A'(\beta)$. The proof is complete.
\end{proof}
It remains to get a lower bound of $R_A'(\beta)$. Let $Z$ be a random variable taking values in $\{1,\ldots, d\}$ uniformly, with each value of $Z$ corresponds to a distribution of $\mathbf{X}$. Denote $p_i(\cdot)=\mathbf{P}(\cdot|Z=i)$. Under $Z=i$.
\begin{defi}
	Construct $d$ hypotheses, and denote $p_i$ as the distribution of $\mathbf{X}$ under $i$-th hypothesis. If $Z=i$, then $\mathbf{X}$ follows $p_i$. $p_i$ is defined as follows. Given $Z=i$, $X_i=\sigma/\sqrt{2\beta}$. For all $j\neq i$, $p_i(X_j = 0) = 1-2\beta$, $p_i(X_j = \sigma/\sqrt{2\beta})=\beta$, and $p_i(X_j = -\sigma/\sqrt{2\beta})=\beta$. Conditional on $Z=i$, $\mathbf{X}_j$ are independent for $j\in [d]\setminus\{i\}$. 
\end{defi}

The above construction uses the idea from \cite{diakonikolas2018list}, Proposition 5.4.

The mean of $p_i$ is
\begin{eqnarray}
	\mu_i = \frac{\sigma}{\sqrt{2\beta}}\mathbf{e}_i,
	\label{eq:mui}
\end{eqnarray}
in which $\mathbf{e}_i$ is the unit vector in $i$-th coordinate. Such construction also ensures that $\Var[X_j]=\sigma^2$ for $j\neq i$. Thus assumption \ref{ass:var} is satisfied.

Construct $p_Y$, the distribution of $Y$ as following: $p_Y(Y_j = 0)=1-2\beta$, $p_Y(Y_j = \sigma/\sqrt{2\beta})=p_Y(Y_j=-\sigma/\sqrt{2\beta}) = \beta$. Then it is straightforward to show that for each $i$, there exists a $q_i$ such that $p_Y=\beta p_i+(1-\beta)q_i$. Therefore, we design the contamination strategy $\pi_A'(\beta)$ as follows: with probability $\beta$, $\mathbf{Y}=\mathbf{X}$; with probability $1-\beta$, the sample is corrupted, and then $\mathbf{Y}$ follows a conditional distribution $q_i$. With this operation, for all values of $Z$, the distribution of $\mathbf{Y}$ is always $p_Y$, which does not depend on $Z$.

For all possible estimator $\hat{\mu}$, define
\begin{eqnarray}
	\hat{Z}=\underset{i\in [d]}{\arg\min}\|\hat{\mu}-\mu_i\|.
	\label{eq:zhat}
\end{eqnarray}
From Fano's inequality,
\begin{eqnarray}
	\text{P}(\hat{Z}\neq Z)&\overset{(a)}{\geq}& \frac{H(Z|\mathbf{Y}^{S_0}, \mathbf{X}^A)-\ln 2}{\ln (d-1)}\nonumber\\
	&=&\frac{H(Z)-I(Z;\mathbf{Y}^{S_0}, \mathbf{X}^A)-\ln 2}{\ln(d-1)}\nonumber\\
	&\geq & 1-\frac{I(Z;\mathbf{Y}^{S_0}, \mathbf{X}^A)+\ln 2}{\ln d}\nonumber\\
	&\overset{(b)}{=}&1-\frac{I(Z;\mathbf{X}^A)+\ln 2}{\ln d}.
\end{eqnarray}
In (a), $\mathbf{Y}^{S_0}$ means $\mathbf{Y}_i$ for all $i\in S_0$. For (b), note that the distribution of $\mathbf{Y}$ does not depend on $Z$, hence $I(Z; \mathbf{Y}^{S_0}, \mathbf{X}^A) = I(Z; \mathbf{X}^A)$. The mutual information can be bounded by
\begin{eqnarray}
	I(Z;\mathbf{X}^A) = N_AI(Z;\mathbf{X})=N_A(H(\mathbf{X}) - H(\mathbf{X}|Z)).
\end{eqnarray}
For any $i$, given $Z=i$, $X_i$ is fixed. Therefore
\begin{eqnarray}
	H(\mathbf{X}) - H(\mathbf{X}|Z=i) &\leq& -2\beta\ln \beta - (1-2\beta)\ln (1-2\beta)\nonumber\\
	&\leq & 2\beta\left(\ln \frac{1}{\beta} + 1\right).
\end{eqnarray}
Hence
\begin{eqnarray}
	\text{P}(\hat{Z}\neq Z) \geq 1-\frac{2N_A\beta \left(\ln \frac{1}{\beta} + 1\right)+\ln 2}{\ln d}.
\end{eqnarray}
Now we restrict $N_A$ to ensure that $\text{P}(\hat{Z}\neq Z)\geq 1/2$. This yields
\begin{eqnarray}
	N_A\leq \frac{\ln \frac{d}{4}}{4\beta\left(\ln \frac{1}{\beta} + 1\right)}.
	\label{eq:nabound}
\end{eqnarray}
Recall \eqref{eq:mui}. For $i,j\in [d]$, $i\neq j$, $\|\mu_i-\mu_j\|_2\geq \sigma/\sqrt{\beta}$. Therefore, if $\hat{Z}\neq Z$, then
\begin{eqnarray}
	\|\hat{\mu}-\mu^*\|_2&\overset{(a)}{=}&\|\hat{\mu}-\mu_Z\|_2\nonumber\\
	&\overset{(b)}{\geq}& \frac{1}{2}(\|\hat{\mu}-\mu_Z\|_2+\|\hat{\mu}-\mu_{\hat{Z}}\|_2)\nonumber\\
	&\geq & \frac{1}{2}\|\mu_Z-\mu_{\hat{Z}}\|_2\nonumber\\
	&\geq & \frac{\sigma}{2\sqrt{\beta}}.
\end{eqnarray}
For (a), note that given $Z=i$, the real mean of $\mathbf{X}$ is $\mu^*=mu_i$. For (b) uses \eqref{eq:zhat}, which yields $\|\hat{\mu}-\mu_{\hat{Z}}\|_2\leq \|\hat{\mu}-\mu_Z\|_2$.

From the above analysis, we conclude that if \eqref{eq:nabound} holds, then with probability at least $1/2$, $\|\hat{\mu}-\mu^*\|_2\geq \sigma/(2\sqrt{\beta})$. Taking $\beta=\alpha/2$. From Lemma \ref{lem:link}, with probability at least $1/2-\exp[-(\ln 2-1/2)N\alpha]$, 
\begin{eqnarray}
	\|\hat{\mu}-\mu^*\|_2\geq \frac{\sigma}{2\sqrt{\beta}} = \frac{\sigma}{\sqrt{2\alpha}}.
\end{eqnarray}

\textbf{Proof of \eqref{eq:rsbound}}. Now we move on to strong contamination model. Define
\begin{eqnarray}
	R_S'(\beta)=\underset{\hat{\mu}}{\inf}\underset{D\in \mathcal{F}}{\sup}\underset{\pi_S'(\beta)}{\sup} \|\hat{\mu}-\mu^*\|_2,
\end{eqnarray}
in which $\pi_S'(\beta)$ is a corruption strategy such that $\mathbf{Y}_i=\mathbf{X}_i$ with probability
$\beta$. The difference of $\pi_S'$ with $\pi_A'$ is that $\pi_S'$ allows the whether $\mathbf{Y}_i=\mathbf{X}_i$ depends on the value of $\mathbf{X}_i$. Similar to Lemma \ref{lem:link}, the following relation holds:
\begin{eqnarray}
	R_S(\alpha) \geq R_S'\left(\frac{\alpha}{2}\right),
\end{eqnarray}
Let $\beta = \alpha / 2$. Now we construct hypotheses as following, which is more complex than those in additive contamination model.
\begin{defi}
	Construct $d$ hypotheses, and denote $p_i$ as the distribution of $\mathbf{X}$ under $i$-th hypothesis. If $Z=i$, then $\mathbf{X}$ follows $p_i$. $p_i$ is defined as follows. Given $Z=i$, $X_i=\sigma/(2\beta)$. Moreover, construct another auxiliary random variable $U$, such that $p_i(U=0) = 1-\beta$, $p_i(U=1)=\beta$. Conditional on $U=0$, for all $j\neq i$, $p_i(X_j=0|U=0) = 1-2\beta$, $p_i(X_j = \sigma/(2\sqrt{\beta})|U=0)=p_i(X_j = -\sigma/(2\sqrt{\beta})|U=0)=\beta$. Conditional on $U=1$, for all $j\neq i$, $p_i(X_j=\sigma/(2\beta)|U=1) = p_i(X_j=-\sigma/(2\beta)|U=1) = \beta$. Conditional on $Z=i$ and $U$, $X_j$ are independent for $j\in [d]\setminus\{i\}$. 
\end{defi}

Now the mean of $p_i$ is
\begin{eqnarray}
	\mu_i=\frac{\sigma}{2\beta} \mathbf{e}_i.
\end{eqnarray}
Under $Z=i$, for $j\neq i$, the variance in $j$-th dimension is
\begin{eqnarray}
	\Var_i[X_j]=2\beta^2\left(\frac{\sigma}{2\beta}\right)^2 + 2\beta(1-\beta)\left(\frac{\sigma}{2\sqrt{\beta}}\right)^2\leq \sigma^2,
\end{eqnarray}
hence Assumption \ref{ass:var} is satisfied.

Construct $p_Y$, the distribution of $Y$ as following: $p_Y(Y_j=0)=1-2\beta$, $p_Y(Y_j=\sigma/(2\beta)) = p_Y(Y_j=-\sigma/(2\beta)) = \beta$. Then the total variation distance between $p_i$ and $p_Y$ is $\mathbb{TV}(p_i, p_Y)$. Hence, for any $i\in [d]$, $\mathbf{X}$ follows $p_i$, and the attacker can ensure that $\mathbf{Y}$ follows $p_Y$ and $\mathbf{Y}=\mathbf{X}$ with probability $\beta$. Note that now for $i,j\in [d]$, $i\neq j$, $\|\mu_i-\mu_j\|_2\geq \sigma/(\sqrt{2}\beta)$. Let $\beta=\alpha/2$, and follow similar steps in additive contamination model, with probability at least $1/2-\exp[-(\ln 2-1/2)N\alpha]$,
\begin{eqnarray}
	\|\hat{\mu}-\mu^*\|_2\geq \frac{\sigma}{\sqrt{2}\alpha}.
\end{eqnarray}
The proof is complete.



\section{Proof of Theorem \ref{thm:distributed}}\label{sec:distributed}
Conduct the same decomposition as \eqref{eq:mse} to $\|g(\mathbf{w}) - \nabla F(\mathbf{w})\|_2^2$:
\begin{eqnarray}
	\|g(\mathbf{w})-\nabla F(\mathbf{w})\|_2^2&\leq& 3\|\mathbf{P}(\mu_w(A) - \nabla F(\mathbf{w}))\|_2^2+3\|(\mathbf{I}-\mathbf{P})(\mu_w(S) - \mu_w(G))\|_2^2 \nonumber\\
	&&+ 3\|(\mathbf{I}-\mathbf{P})(\mu_w(G)-\mu^*)\|_2^2,
	\label{eq:msegrad}
\end{eqnarray}
in which
\begin{eqnarray}
	\mu_w(A)=\frac{1}{N_A}\sum_{j=1}^{N_A}\nabla f(\mathbf{w}, \mathbf{Z}_{0j}).
\end{eqnarray}
Then we show the following lemma.
\begin{lem}
	For all $0\leq \lambda \leq N_A/\sigma$,
	\begin{eqnarray}
		\underset{\mathbf{v}:\|\mathbf{v}\|_2=1}{\sup}\mathbb{E}\left[e^{\lambda \mathbf{v}^T(\mu_w(A)-\nabla F(\mathbf{w}))}\right]\leq e^{\frac{1}{2N_A}\sigma^2 \lambda^2}.
	\end{eqnarray}
\end{lem}
\begin{proof}
	For any $\mathbf{v}\in \mathbb{R}^d$ with $\|\mathbf{v}\|_2=1$, from Assumption \ref{ass:distributed}(a), for all $0\leq \lambda\leq N_A/\sigma$,
	\begin{eqnarray}
		\mathbb{E}\left[e^{\lambda \mathbf{v}^T(\mu_w(A)-\nabla F(\mathbf{w}))}\right]&=& \mathbb{E}\left[\exp\left(\frac{1}{N_A}\lambda \mathbf{v}^T \sum_{j=1}^{N_A}\left(\nabla f(\mathbf{w}, Z_{0j}) - \nabla F(\mathbf{w})\right)\right)\right]\nonumber\\
		&\leq & \left(e^{\frac{1}{2}\sigma^2 \frac{\lambda^2}{N_A^2}}\right)^{N_A}\nonumber\\
		&=& e^{\frac{1}{2N_A}\sigma^2 \lambda^2}.
	\end{eqnarray}
\end{proof}
Therefore for any $t$,
\begin{eqnarray}
	\text{P}(\mathbf{v}^T (\mu_w(A)- \nabla F(\mathbf{w})) > t)&\leq & \underset{\lambda \geq 0}{\inf} e^{-\lambda t}\mathbb{E}\left[e^{\lambda \mathbf{v}^T(\mu_w(A)-\nabla F(\mathbf{w}))}\right]\nonumber\\
	&=& \underset{0\leq \lambda \leq N_A/\sigma}{\inf}e^{-\lambda t}e^{\frac{1}{2N_A}\sigma^2 \lambda^2}\nonumber\\
	&=&e^{-\frac{N_A}{2}\min\left\{\frac{t^2}{\sigma^2}, \frac{t}{\sigma} \right\}}
\end{eqnarray}
Let 
\begin{eqnarray}
	t=\sqrt{\frac{2}{N_A}\ln \frac{p}{\delta_0}}\sigma.
\end{eqnarray}
From the condition \eqref{eq:na}, $t\leq \sigma$ holds. Then
\begin{eqnarray}
	\text{P}\left(\mathbf{v}^T(\mu_w(A)- \nabla F(\mathbf{w}))>\sqrt{\frac{2}{N_A}\ln \frac{p}{\delta_0}}\sigma\right)\leq \frac{\delta_0}{p}.
\end{eqnarray}
Note that $\mathbf{P}=\mathbf{U}_p\mathbf{U}_p^T$, hence
\begin{eqnarray}
	\|\mathbf{P}(\mu_w(A)-\nabla F(\mathbf{w}))\|_2^2 &=& \mathbf{U}_p \mathbf{U}_p^T (\mu_w(A)-\nabla F(\mathbf{w}))(\mu_w(A)-\nabla F(\mathbf{w}))^T \mathbf{U}_p \mathbf{U}_p^T\nonumber\\
	&=&\|\mathbf{U}_p^T(\mu(A)-\nabla F(\mathbf{w}))\|_2^2.
\end{eqnarray}
Then
\begin{eqnarray}
	\text{P}\left(\|\mathbf{P}(\mu_w(A)-\nabla F(\mathbf{w}))\|_2^2 > \frac{2p}{N_A}\ln \frac{p}{\delta_0}\sigma^2\right) 
	&=& \text{P}\left(\|\mathbf{U}_p^T(\mu(A)-\nabla F(\mathbf{w}))\|_2^2 > \frac{2p}{N_A}\ln \frac{p}{\delta_0}\sigma^2\right)\nonumber\\
	&\leq & \sum_{k=1}^p \text{P}\left((\mathbf{u}_k^T (\mu_w(A)-\mu^*))^2>\frac{2}{N_A}\ln \frac{p}{\delta_0}\sigma^2\right)\nonumber\\
	&=&\sum_{k=1}^p \text{P}\left(\mathbf{u}_k^T (\mu_w(A)-\mu^*)>\sqrt{\frac{2}{N_A}\ln \frac{p}{\delta_0}}\sigma\right)\nonumber\\
	&=&\delta_0.
\end{eqnarray}
Therefore, with probability at least $1-\delta_0$,
\begin{eqnarray}
	\|\mathbf{P}(\mu_w(A)-\nabla F(\mathbf{w}))\|_2^2\leq \frac{2p}{N_A}\sigma^2\ln \frac{p}{\delta_0}.
	\label{eq:I1grad}
\end{eqnarray}
\eqref{eq:I1grad} bounds the first term in \eqref{eq:msegrad}. For the second and third term in \eqref{eq:msegrad}, we can use \eqref{eq:I2highp} and \eqref{eq:I3highp}. Recall that \eqref{eq:I2highp} and \eqref{eq:I3highp} rely on \eqref{eq:lamc2} and \eqref{eq:m2}. In distributed learning setting, the variance of $\mathbf{X}_i$ satisfies
\begin{eqnarray}
	\Var[X_i]\preceq \frac{\sigma^2}{n} \mathbf{I},
\end{eqnarray} 
and there are $m$ working machines in total, hence under additive contamination model, \eqref{eq:lamc2} becomes
\begin{eqnarray}
	\lambda_c\geq 32\frac{\sigma^2}{n}\left(1+\frac{2d}{\alpha m}\right)\frac{1+\epsilon}{1-\epsilon},
	\label{eq:lamc2new}
\end{eqnarray}
while under strong contamination model, \eqref{eq:lamc2-strong} becomes
\begin{eqnarray}
	\lambda_c \geq \frac{8\sigma^2}{n\alpha} \left(1+\sqrt{\frac{16d\ln^2 m}{3\alpha m}}\right)^2\frac{1+\epsilon}{1-\epsilon}.
	\label{eq:lamc2new-strong}
\end{eqnarray}

Using Lemma \ref{lem:I2bound} and Lemma \ref{lem:I3bound}, if $\lambda_c$ satisfies \eqref{eq:lamc2new} or \eqref{eq:lamc2new-strong} for additive or strong contamination model, respectively, then with probability at least $1-e^{-\frac{1}{64}\alpha m}- 4me^{-\frac{1}{16}\lambda_cp\alpha^2 m^\frac{1}{3}\epsilon^2}$,
\begin{eqnarray}
	\|(\mathbf{I}-\mathbf{P})(\mu_w(S)-\mu_w(G))\|_2^2&\leq& \frac{2\lambda_c}{\alpha},\label{eq:I2grad}\\
	\|(\mathbf{I}-\mathbf{P})(\mu_w(G)-\nabla F(\mathbf{w}))\|_2^2&\leq& \frac{\lambda_c}{2\alpha}.
	\label{eq:I3grad}
\end{eqnarray}
Substitute three terms in \eqref{eq:msegrad} with \eqref{eq:I1grad}, \eqref{eq:I2grad} and \eqref{eq:I3grad}, it can be shown that with probability at least $1-\delta_0-e^{-\frac{1}{64}\alpha m}- 4me^{-\frac{1}{16}\lambda_cp\alpha^2 m^\frac{1}{3}\epsilon^2}$,
\begin{eqnarray}
	\|g(\mathbf{w})-\nabla F(\mathbf{w})\|_2^2 \leq \frac{6p}{N_A}\sigma^2 \ln \frac{p}{\delta_0} + \frac{15\lambda_c}{2\alpha}.
	\label{eq:gradbound} 
\end{eqnarray}
Recall that there are $T$ iterations in total. Therefore, we get the following union bound. With probability at least $1-T\delta_0-Te^{-\frac{1}{64}\alpha m}- 4Tme^{-\frac{1}{16}\lambda_cp\alpha^2 m^\frac{1}{3}\epsilon^2}$, for $t=1,\ldots, T$, \eqref{eq:gradbound} holds for $\mathbf{w}_1,\ldots, \mathbf{w}_T$. Let $\delta_0=\delta/T$. Then with probability at least $1-\delta-Te^{-\frac{1}{64}\alpha m}- 4mTe^{-\frac{1}{16}\lambda_cp\alpha^2 N^\frac{1}{3}\epsilon^2}$, for $t=1,\ldots, T$,
\begin{eqnarray}
	\|g(\mathbf{w}_t)-\nabla F(\mathbf{w}_t)\|_2^2 \leq \frac{6p}{N_A}\sigma^2 \ln \frac{pT}{\delta} + \frac{15\lambda_c}{2\alpha}.	
	\label{eq:union}
\end{eqnarray}
Based on \eqref{eq:union}, we then solve the optimization problem. Recall that $\mathbf{w}_{t+1} = \mathbf{w}_t-\eta g(\mathbf{w}_t)$. Then
\begin{eqnarray}
	\|\mathbf{w}_{t+1} - \mathbf{w}^*\|_2&=& \|\mathbf{w}_t-\eta g(\mathbf{w}_t) - \mathbf{w}^*\|_2\nonumber\\
	&\leq & \|\mathbf{w}_t-\eta\nabla F(\mathbf{w}_t) - \mathbf{w}^*\|_2+\eta \|\nabla F(\mathbf{w}_t) - g(\mathbf{w}_t)\|_2.
	\label{eq:wdecomp}
\end{eqnarray}
For the first term in \eqref{eq:wdecomp},
\begin{eqnarray}
	&&\|\mathbf{w}_t-\eta\nabla F(\mathbf{w}_t) - \mathbf{w}^*\|_2^2\nonumber\\
	&=& \|\mathbf{w}_t-\mathbf{w}^*\|_2^2 - 2\eta \langle \mathbf{w}_t-\mathbf{w}^*, \nabla F(\mathbf{w}_t)\rangle+\eta^2 \|\nabla F(\mathbf{w}_t)\|_2^2\nonumber\\
	&\overset{(a)}{\leq} &\|\mathbf{w}_t-\mathbf{w}^*\|_2^2-2\eta\left(F(\mathbf{w}_t) - F(\mathbf{w}^*)+\frac{\alpha}{2}\|\mathbf{w}_t-\mathbf{w}^*\|_2^2\right)+\eta^2\|\nabla F(\mathbf{w}_t)\|_2^2\nonumber\\
	&\overset{(b)}{\leq}&(1-\eta\alpha)\|\mathbf{w}_t-\mathbf{w}^*\|_2^2 - 2\eta(F(\mathbf{w}_t - F(\mathbf{w}^*))) + 2\eta^2 L(F(\mathbf{w}_t) - F(\mathbf{w}^*))\nonumber\\
	&\overset{(c)}{\leq} & (1-\eta\alpha) \|\mathbf{w}_t-\mathbf{w}^*\|_2^2.
\end{eqnarray}
(a) comes from the $\alpha$-strong convexity of $F$ (Assumption \ref{ass:distributed}(b)), which ensures that
\begin{eqnarray}
	F(\mathbf{w}^*)\geq F(\mathbf{w}_t)+\langle \nabla F(\mathbf{w}_t), \mathbf{w}^*-\mathbf{w}_t\rangle + \frac{\alpha}{2}\|\mathbf{w}_t-\mathbf{w}^*\|_2^2.
\end{eqnarray}
(b) comes from the $L$-smoothness of $F$, which ensures that $\|\nabla F(\mathbf{w}_t)\|_2^2\leq 2L (F(\mathbf{w}_t) - F(\mathbf{w}^*))$. (c) comes from condition (4) in Theorem \ref{thm:distributed}, which requires $\eta\leq 1/L$. Hence
\begin{eqnarray}
	\|\mathbf{w}_t-\eta\nabla F(\mathbf{w}_t) - \mathbf{w}^*\|_2\leq \sqrt{1-\eta\alpha}\|\mathbf{w}_t-\mathbf{w}^*\|_2\leq \left(1-\frac{1}{2}\eta\alpha\right) \|\mathbf{w}_t-\mathbf{w}^*\|_2.	
\end{eqnarray}
For the second term in \eqref{eq:wdecomp}, recall \eqref{eq:gradbound}. Therefore
\begin{eqnarray}
	\|\mathbf{w}_{t+1} - \mathbf{w}^*\|_2\leq (1-\rho)\|\mathbf{w}_t-\mathbf{w}^*\|_2+\eta\Delta,
\end{eqnarray}
in which $\rho$ and $\Delta$ are defined in \eqref{eq:rho} and \eqref{eq:delta}. Then it is straightforward to show by induction that for $t=1,\ldots, T$,
\begin{eqnarray}
	\|\mathbf{w}_t-\mathbf{w}^*\|_2\leq (1-\rho)^t\|\mathbf{w}_0-\mathbf{w}^*\|_2+\frac{\eta\Delta}{\rho}.
\end{eqnarray}
The algorithm returns 	$\hat{\mathbf{w}}=\mathbf{w}_T$. Therefore,
\begin{eqnarray}
	\|\hat{\mathbf{w}}-\mathbf{w}^*\|_2\leq (1-\rho)^T\|\mathbf{w}_0-\mathbf{w}^*\|_2+\frac{\eta\Delta}{\rho}.
\end{eqnarray}
\end{document}