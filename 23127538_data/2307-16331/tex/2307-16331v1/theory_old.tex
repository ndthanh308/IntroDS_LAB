\section{Trade-offs between Detection and False Positives}
%\nm{We can probably take inspiration from layout of Yue's toy model in his randomization paper: https://arxiv.org/pdf/2206.09491.pdf}
% state assumtions here

There exist an implicit tradeoff between detecting attack queries and reducing false positive 

Stateful defenses aim to provide robustness against black box attacks. There are primarily two classes of black box attacks - gradient based (NES, HSJA, ...), and gradient free (Square, SurFree). Stateful defenses are resilient against both these classes of attacks since both need to make similar queries. In our analysis here, we focus on the gradient based attacks and specifically on the gradient estimation step of these attacks. 

% why we focus on only the hash function

% why we assume the two modelling approaches that we do

\subsection{Toy Model}
\noindent\textbf{Feature extractor.} We begin with a toy model in which we consider an explicit class of feature extractors based on simple quantization. The feature extractor is given by $H : [0,1]^d \rightarrow \{0, \cdots, K\}^d$ with a discrete output space of cardinality $K$ along each dimension. Specifically, 
\begin{equation}\label{eqn:hash_fn_toy_model}
    H(\mathbf{x}) = \lfloor K\mathbf{x} + 0.5\rfloor
\end{equation}
where the $\lfloor . \rfloor$ operation is element-wise. Many defenses employ quantization to provide perceptually similarity~\cite{}. In this model, we consider a query to be an attack query if and only if it produces the exact same output as that of a prior query. Later, in Section~\ref{sec:general_analysis} we expand beyond the toy model to consider the case where $H$ is a generic feature extractor, and queries are considered attack queries when their embedding is within some distance $\tau$ of a prior query.

\noindent\textbf{Natural Query Distribution.} Stateful defenses assume that natural images are sufficiently ``spread out'', or dissimilar enough such that they can be distinguished. Therefore, for our model we assume that natural images originate from one of several Gaussian distributions, which are uniformly dispersed across input space $\mathcal{X}$. Each natural image is obtained from a distinct Gaussian distribution. This may be viewed as a ``best case'' situation for the defense, where natural images are sufficiently spread out across the input space to avoid false positives. For simplicity, we assume a total of $K^d$ isotropic Gaussian distributions: $\mathcal{N}(\frac{1}{K}\mathbf{p}, \mathbf{I_d} \sigma^2)$ where vectors $\mathbf{p} \in \{0,1,...,K\}^d$. Intuitively, when applying $H$ to a natural image $\mathbf{x} \sim \mathcal{N}(\frac{1}{K}\mathbf{p}, \mathbf{I_d} \sigma^2)$, it should output the discrete hash vector $\mathbf{p}$.
% Note that $K$ is same as the quantization factor of the hash function $H$.
% \ah{mention that this is kind of best case for attacker, since otherwise there will be high false positives}

\noindent\textbf{Attack Query Distribution.} Now, to estimate the gradient at input $\mathbf{x}$, a Monte Carlo simulation-based approach (e.g., for finite differences) would require sampling a total of $q$ perturbations $\{\mathbf{x},\mathbf{x + \boldsymbol{\delta}_1},...,\mathbf{x + \boldsymbol{\delta}_q}\}$. For our model, we consider the distribution of perturbations for $\mathbf{x}$ to be $\mathcal{N}(0, \mathbf{I_d}\beta^2)$, i.e., the adversary is estimating a gradient using finite differences on a Gaussian basis.

Given the setting described above, we now let the adversary sample natural image $\mathbf{x}$ from one of the above Gaussian distributions $\mathcal{N}(\frac{1}{K}\mathbf{p},\mathbf{I_d}\sigma^2)$, and perturb it with $\boldsymbol{\delta}$ so that they can estimate a gradient. We can then analyze the detection rate $\alpha^{det}$ for perturbed query $\mathbf{x} + \boldsymbol{\delta}$:

\underline{\textit{Upper Bound.}} The hash function $H$ fails to detect the attack query $\mathbf{x + \boldsymbol{\delta}}$ if and only if $H(\mathbf{x} + \boldsymbol{\delta}) \neq H(\mathbf{x})$. Therefore,

\begin{align}
    \alpha^{det} &= 1 - \mathbb{P}[H(\mathbf{x}) \neq H(\mathbf{x+\boldsymbol{\delta}})]\\
    & \leq 1 - \mathbb{P}[H(\mathbf{x+\boldsymbol{\delta}}) \neq \mathbf{p},H(\mathbf{x}) = \mathbf{p}]\\
    &= 1 - \mathbb{P}[H(\mathbf{x+\boldsymbol{\delta}}) \neq \mathbf{p}|H(\mathbf{x}) = \mathbf{p}]\mathbb{P}[H(\mathbf{x}) = \mathbf{p}]\\
    &\leq 1 - \mathbb{P}[H\left(\frac{1}{K}\mathbf{p}+\frac{\mathbf{1}}{2K} +\mathbf{\boldsymbol{\delta}}\right) \neq \mathbf{p}]\mathbb{P}[H(\mathbf{x}) = \mathbf{p}]\\
    %&= 1 - \left(\Phi\left(\frac{1}{\beta K}\right) - \frac{1}{2} \right)^d\left(2\Phi\left(\frac{1}{2\sigma K}\right) - 1 \right)^d
    &= 1 - \left(\frac{3}{2} - \Phi\left(\frac{1}{\beta K}\right) \right)^d(1-\alpha^{fp})
    %&\leq 1 - (2K\sigma)^d\frac{1}{(2\pi)^{\frac{d}{2}}}e^{-\frac{d}{8K^2\sigma^2}}
\end{align}

To go from (6) to the inequality (7), we assign a specific value $\mathbf{x} = \frac{1}{K}\mathbf{p}+\frac{\mathbf{1}}{2K}$, i.e., placing it at the edge of the quantization bin for $H$ (see Equation~\ref{eqn:hash_fn_toy_model}). By placing it at the edge, the probability of collision when adding $\boldsymbol{\delta}$ is minimum, and the resulting event is independent of event $H(\mathbf{x}) = \mathbf{p}$.

To go from (7) to (8) uses standard results for the CDF of a multivariate Gaussian. A detailed proof can be found in Appendix~\ref{}.

% \ah{explain better that we start with a simplistic setting and then generalize; also use consistent notation}

%\underline{\textit{Lower Bound}} Similarly,

%\begin{align}
%    \alpha^{det} &= \mathbb{P}[H(\mathbf{x}) = H(\mathbf{x+\delta})]\\
%    & \geq \mathbb{P}[H(\mathbf{x}) = \mathbf{p_x},H(\mathbf{x+\delta}) = \mathbf{p_x}]\\
    %&= \mathbb{P}[H(\mathbf{x+\delta}) = K\mathbf{p_x}|H(\mathbf{x}) = K\mathbf{p_x}]\mathbb{P}[H(\mathbf{x}) = \mathbf{p_x}]\\
%    &\geq \mathbb{P}[H(\mathbf{p_x}+\frac{\mathbf{1}}{2K}+\mathbf{\delta}) = K\mathbf{p_x}]\mathbb{P}[H(\mathbf{x}) = K\mathbf{p_x}]\\
%    &= \left(\Phi\left(\frac{m}{\beta K}\right) - \frac{1}{2} \right)^d (1-\alpha^{fp})
%\end{align}

\pitfallenv{Takeaway}
{\label{takeaway_toy_model} There exists a trade-off between the detection rate $\alpha^{det}$ and the false positive rate $\alpha^{fp}$, i.e., decreasing $\alpha^{fp}$ also decreases the upper bound for $\alpha^{det}$. Furthermore, this trade-off also depends on the dimension of the input space $d$, cardinality $K$ of the hash function $H$, the standard deviation $\beta$ of the perturbation distribution, i.e., high values of $\beta$ and $K$ lead to a lower detection rate.}


\subsection{General Analysis}\label{sec:general_analysis}
\ah{clearly state what assumptions are for making problem simple and what are for making it general}
\ah{reasons for assumptions - relate lipshitz to need for perceptual hash}
Now, we consider the case of a continuous perceptual hash function (neural encoder or embedding function) and a more generic data distribution. Let the input image distribution be $\mathcal{X} \in \mathbb{R}^d$. Now, we consider a hash function $H : \mathcal{X} \rightarrow \mathcal{Y}$ where $\mathcal{Y} \in \mathbb{R}^{|\mathcal{Y}|}$ is the hash output space. Additionally, we assume $H$ to be lipshitz with constants $K_L$ and $K_U$ :
\ah{where do we need to KL and KU to hold}
\begin{align}\label{eq:lipshitz}
    K_L ||\mathbf{x-y}|| \leq ||H(\mathbf{x})-H(\mathbf{y})|| \leq K_U ||\mathbf{x-y}||
\end{align}
$\forall \; \mathbf{x,y} \in \mathbb{R}^d$. Since, $H$ is now a continuous hash function, we assume a threshold based detection i.e. a query $\mathbf{q}$ is considered an attacked if $||H(\mathbf{q})-H(\mathbf{s})|| \leq \tau$ where $\mathbf{s}$ is any historical query. 

Now, based on the above assumptions, we define the attack detection rate $\alpha^{det}$ and the false positive rate $\alpha^{fp}$.
\begin{align}
    \alpha^{det} = \underset{\mathbf{x} \sim \mathcal{X}, \mathbf{u}\sim\mathcal{N}(0,\mathbf{I_n}\beta^2)}{\mathbb{P}}\left[ ||H(\mathbf{x}) - H(\mathbf{x+u})|| \leq \tau \right]
\end{align}
\begin{align}
    \alpha^{fp} = \underset{\mathbf{x,v} \sim \mathcal{X}}{\mathbb{P}}\left[ ||H(\mathbf{x}) - H(\mathbf{v})|| \leq \tau \right]
\end{align}

Using Eq. \ref{eq:lipshitz}, we get
\begin{align}\label{eq:det}
    \alpha^{det} \leq \underset{ \mathbf{u}\sim\mathcal{N}(0,\mathbf{I_n}\beta^2)}{\mathbb{P}}\left[ ||\mathbf{u}|| \leq \frac{\tau}{K_L} \right]
\end{align}
\begin{align}\label{eq:fp}
    \alpha^{fp} \geq \underset{\mathbf{x,v} \sim \mathcal{X}}{\mathbb{P}}\left[ ||\mathbf{x} - \mathbf{v}|| \leq \frac{\tau}{K_U} \right]
\end{align}

Before proceeding, we state the following lemma :
\begin{lemma}
For a $n$-dimensional gaussian random vector $\textbf{u} \sim \mathcal{N}(0,\sigma^2)$ and $\frac{b}{\sigma} < 1$, 
\begin{equation}\label{eq:cher}
    \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}[||\textbf{u}||_2 \leq  \sqrt{n} b] \leq e^{\frac{n}{2}}\frac{b^n}{\sigma^n}
\end{equation}
\end{lemma}

Now, using Lemma \ref{eq:cher} in Eq. \ref{eq:det} and applying Markov's inequality in Eq. \ref{eq:fp}, we get 
\begin{align}
    (\alpha^{det})^{\frac{1}{d}} (1-\alpha^{fp}) \leq \frac{e^{\frac{1}{2}}}{d^{\frac{1}{2}}} \left(\frac{M_{\mathcal{D}}}{\beta}\right) \left(\frac{K_U}{K_L}\right)
\end{align}

where, $M_{\mathcal{D}} = \underset{\textbf{v},\textbf{x} \sim \mathcal{D}_{\mathcal{X}}}{\mathbb{E}}[||\textbf{v}-\textbf{x}||_2 ]$







