\section{Supplementary Proofs}\label{sec:concentration}

% \begin{lemma}\label{lem:concentration}
% For a $d$-dimensional random vector $\textbf{u} \sim \mathcal{N}(0,\sigma^2)$ and $\frac{b}{\sigma} < 1$, 
% \begin{equation}\label{eq:chi1}
%     \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}[||\textbf{u}||_2 \leq  \sqrt{d} b] \leq e^{\frac{d}{2}}\frac{b^d}{\sigma^d}
% \end{equation}
% \end{lemma}
% \begin{proof}
% We can also write the LHS as
% \begin{equation}\label{eq:chi2}
%         \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}\left[{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 \leq  \frac{d b^2}{\sigma^2}\right]
% \end{equation}
% Now, for $t<0$,
% \begin{equation}\label{eq:chi2}
%         \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}\left[{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 \leq  \frac{d b^2}{\sigma^2}\right] = \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}\left[e^{t{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 } \geq  e^{t\frac{d b^2}{\sigma^2}}\right]
% \end{equation}
% Applying Markov's inequality $\left(\mathbb{P}[X\geq a]\leq \frac{\mathbb{E}[X]}{a}\right)$), we get
% \begin{equation}
%     \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}\left[e^{t{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 } \geq  e^{t\frac{d b^2}{\sigma^2}}\right] \leq \frac{\mathbb{E}\left[e^{t{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 }\right]}{e^{t\frac{d b^2}{\sigma^2}}}
% \end{equation}

% If $\textbf{u} \sim \mathcal{N}(0,\sigma^2)$, then $\frac{\textbf{u}}{\sigma} \sim \mathcal{N}(0,1)$. And $\frac{||\textbf{u}||_2^2}{\sigma^2} \sim \mathcal{X}^2_n$ follows the chi-square distribution. Using the moment generating function for chi-square distribution in Eq. 21 and combining with Eq. 20, we get
% \begin{equation}
% \begin{split}
%     \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}\left[{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 \leq  \frac{d b^2}{\sigma^2}\right] &\leq \frac{{(1-2t)}^{\frac{-d}{2}}}{e^{t\frac{d b^2}{\sigma^2}}} \\
%     &= \exp\left(\frac{-d}{2}\log{(1-2t)} - \frac{td b^2}{\sigma^2}\right)\\
% \end{split}
% \end{equation}
% To get a tight upper bound, we can replace a value of $t$ that minimizes the RHS i.e. $t = \frac{1}{2}\left[1-\frac{\sigma^2}{b^2}\right]$. Since, $t<0$, we need $\sigma > b$. Using this, we get 
% \begin{equation}
% \begin{split}
%     \underset{\textbf{u} \sim \mathcal{N}(0,\sigma^2)}{\mathbb{P}}\left[{\left\lVert \frac{\textbf{u}}{\sigma}\right\rVert}_2^2 \leq  \frac{d b^2}{\sigma^2}\right] &\leq \exp\left( \frac{d}{2}\log\left( \frac{b^2}{\sigma^2} \right) - \frac{db^2}{2\sigma^2} + \frac{d}{2} \right)\\
%     &\leq \exp\left( \frac{d}{2}\log\left( \frac{b^2}{\sigma^2} \right) + \frac{d}{2} \right)\\
%     &= e^{\frac{d}{2}} \frac{b^d}{\sigma^d}
% \end{split}
% \end{equation}
% \end{proof}

\begin{lemma}
Let $G$ be a $k \times d$ random matrix with rows $\sigma g^i \sim \mathcal{N}(0, \mathbf{I_d}\sigma^2) ~\forall 1 \leq i \leq k$. Then, for any unit vector $v \in \mathbb{R}^d$,
\begin{equation*}
    P[|\|Gv\|^2 - 1| > \epsilon] \leq 2 exp\left(-\left(k + \dfrac{\epsilon + 1}{2 \sigma^2}\right)\right)
\end{equation*}
\label{lemma:concn_msur}
\end{lemma}

\begin{proof} Note that by rotational invariance of Gaussians, $Gv \stackrel{D}{=} Ge^1$, where $e^1$ is the standard basis vector. This implies that $\|Gv\|^2 \stackrel{D}{=} \|Ge^1\|^2 \stackrel{D}{=} \sigma^2 \chi_k^2$, where $\chi_k^2$ is a chi-square random variable with $k$-degrees of freedom. Then, by Chernoff's bounding method:

\begin{equation*}
\begin{split}
    P[|\|Gv\|^2 - 1| > & \epsilon] = P[|\sigma^2 \chi_k^2 - 1| > \epsilon] \\ \\
    &\leq 2 \inf\limits_{t>0}e^{-\epsilon t}\mathbb{E}[e^{t(\sigma^2\chi^2-1)}] \\
    &\leq 2 \inf_{t>0} e^{-\epsilon t - t} \mathbb{E}[e^{t\sigma^2 \chi^2}] \\
    & \leq 2 \inf_{t>0} e^{-\epsilon t - t}(1-2\sigma^2 t)^{\frac{-k}{2}} \\
    & \leq 2 \inf_{t > 0} e^{-\epsilon t - t - \frac{k}{2} \log(1-2\sigma^2 t)} \\
    & \leq 2 e^{- \frac{\epsilon - k \sigma^2 + 1}{2\sigma^2} - \frac{k}{2}\log(\frac{\sigma^2 k}{\epsilon + 1})} \\
    & \leq 2 e^{- \frac{(\epsilon + 1 -\sigma^2 k)^2}{2\sigma^2(1+\epsilon)}} \\
    & \leq 2e^{- \frac{(\epsilon+1)^2 - 2\sigma^2 k(\epsilon+1)}{2\sigma^2 (1+\epsilon)}} \\
    & \leq 2e^{- \frac{\epsilon+1 - 2\sigma^2 k}{2\sigma^2}} \\
    & \leq 2e^{-k}e^{-\frac{\epsilon+1}{2\sigma^2}} \\
    & \leq 2e^{-k - \frac{\epsilon+1}{2\sigma^2}}
\end{split}
\end{equation*}
\end{proof}

\subsubsection{Proof for Theorem~\ref{lemma:min_var_grad}}\label{app:proof_min_grad_var}
Let $\nabla_\mathbf{x}$ be the true gradient of $\mathbf{x}$ for the classifier's loss, and $G$ be a matrix of rows $g_1, \cdots, g_k \sim \mathcal{N}(0, \mathbf{I_d}\beta^2)$. Then, the norm of estimated gradient $G\cdot\nabla_\mathbf{x} $ is bounded in probability by:
\begin{equation*}
\begin{split}
    \mathbb{P}[(1-\epsilon)\|\nabla_\mathbf{x}\| \leq \|G\cdot\nabla_\mathbf{x}\| & \leq (1+\epsilon) \|\nabla_\mathbf{x}\|] \geq  \\
     & 1 - 2\cdot exp{\left(- k - \dfrac{1 + \epsilon}{2\beta^2}\right)}
\end{split} 
\end{equation*}
where $0 \leq \epsilon \leq 1$ is the estimation error.

\begin{proof}
    \begin{equation*}
    \begin{split}
   &  P[(1-\epsilon)\|\nabla_\mathbf{x}\| \leq \|G\nabla_\mathbf{x}\| \leq (1+\epsilon)\|\nabla_\mathbf{x}\|] \\
   & = P[(1-\epsilon)^2\|\nabla_\mathbf{x}\|^2 \leq \|G\nabla_\mathbf{x}\|^2 \leq (1+\epsilon)^2\|\nabla_\mathbf{x}\|^2] \\
   & \geq P\left[1-\epsilon \leq \dfrac{\|G \nabla_\mathbf{x}\|^2}{\|\nabla_\mathbf{x}\|^2} \leq 1 + \epsilon \right] \\
   & = P\left[\left|\dfrac{\|G \nabla_\mathbf{x}\|^2}{\|\nabla_\mathbf{x}\|^2} - 1\right| \leq  \epsilon \right] \\
   &= P\left[\left|\left\|G\dfrac{ \nabla_\mathbf{x}}{\|\nabla_\mathbf{x}\|}\right\|^2 - 1\right| \leq  \epsilon \right] \\
   & \geq 1 - 2e^{-k - \frac{\epsilon+1}{2\beta^2}}
    \end{split}
    \end{equation*}
    Where the last step is by Lemma 1.
\end{proof}