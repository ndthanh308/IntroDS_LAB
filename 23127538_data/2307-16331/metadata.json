{
  "title": "Theoretically Principled Trade-off for Stateful Defenses against Query-Based Black-Box Attacks",
  "authors": [
    "Ashish Hooda",
    "Neal Mangaokar",
    "Ryan Feng",
    "Kassem Fawaz",
    "Somesh Jha",
    "Atul Prakash"
  ],
  "submission_date": "2023-07-30T22:31:01+00:00",
  "revised_dates": [],
  "abstract": "Adversarial examples threaten the integrity of machine learning systems with alarming success rates even under constrained black-box conditions. Stateful defenses have emerged as an effective countermeasure, detecting potential attacks by maintaining a buffer of recent queries and detecting new queries that are too similar. However, these defenses fundamentally pose a trade-off between attack detection and false positive rates, and this trade-off is typically optimized by hand-picking feature extractors and similarity thresholds that empirically work well. There is little current understanding as to the formal limits of this trade-off and the exact properties of the feature extractors/underlying problem domain that influence it. This work aims to address this gap by offering a theoretical characterization of the trade-off between detection and false positive rates for stateful defenses. We provide upper bounds for detection rates of a general class of feature extractors and analyze the impact of this trade-off on the convergence of black-box attacks. We then support our theoretical findings with empirical evaluations across multiple datasets and stateful defenses.",
  "categories": [
    "cs.LG",
    "cs.CR"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16331",
  "pdf_url": "https://arxiv.org/pdf/2307.16331v1",
  "comment": "2nd AdvML Frontiers Workshop at ICML 2023",
  "num_versions": null,
  "size_before_bytes": 925273,
  "size_after_bytes": 159741
}