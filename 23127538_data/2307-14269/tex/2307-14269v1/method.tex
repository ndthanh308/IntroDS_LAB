
\section{New method of discretization}
In this section, the Lobatto polynomials are introduced and some relevant associated properties are established.
Furthermore, an approach to achieve an inversion-ready differentiation matrix according to Definition \ref{defn:inversion-ready} is proposed in this section.
At last, we assess the potential Runge's phenomenon associated with the resulting polynomial interpolation, and we briefly overview the Gaussian quadrature rule for the calculation of definite integrals with the new method.

\subsection{Lobatto polynomials}
\label{sec:polynomials}

For an integer $N \geq 0$, let $\mathcal{P}_N(\tau)$ denote the Legendre polynomial of degree $N$, with $\tau \in \closedinterval{-1}{1}$. In addition, for $N \geq 2$, let $\mathcal{L}_N(\tau)$ denote the Lobatto polynomial of degree $N$. Together, these polynomials satisfy the following equations, see \cite{Radau1880,Abramovitz1972,Szegoe1975}:
\begin{align}
    \mathcal{L}_N(\tau) &= (\tau^2-1) \dot{\mathcal{P}}_{N-1}(\tau) \label{eq:lobatto-polynomial} \,, \\
    \dot{\mathcal{L}}_N (\tau) &= N (N-1) \mathcal{P}_{N-1} (\tau) \label{eq:lobatto-first-order} \,, \\
    (\tau^2-1) \ddot{\mathcal{L}}_N (\tau) &= N (N-1) \mathcal{L}_N (\tau) \label{eq:lobatto-second-order} \,, 
\end{align}
with $ \dot{\mathcal{L}}_N (\tau) = \diff{\mathcal{L}_N(\tau)}{\tau}$ and $ \ddot{\mathcal{L}}_N (\tau) = \diff[2]{\mathcal{L}_N(\tau)}{\tau}$.

In these expressions, the integer $N$ always matches the number of roots of the respective functions, see, \emph{e.g.}, \cite{Radau1880,Hildebrand1987}.
The roots of Legendre polynomials $\mathcal{P}_N(\cdot)$ can be obtained via the methods developed in \cite{Golub1969,Bogaert2012,Bogaert2014,Glaser2007,Hale2013}, and the roots of Lobatto polynomials $\mathcal{L}_N(\cdot)$ can be obtained via the methods developed in \cite{Gautschi2000,Golub1973}.

\begin{rem} \label{rem:lobatto-zero-endpoints}
    Due to \eqref{eq:lobatto-polynomial}, the points $-1$ and $1$ are roots of $\mathcal{L}_N(\tau)$, \emph{i.e.}, $\mathcal{L}_N(1) = \mathcal{L}_N(-1) = 0$.
\end{rem}

\begin{rem} \label{rem:lobatto-extrema}
    Due to \eqref{eq:lobatto-first-order}, the stationary points of $\mathcal{L}_N(\tau)$, \emph{i.e.}, the points where $\dot{\mathcal{L}}_N(\tau) = 0$, are given by the roots of $\mathcal{P}_{N-1}(\tau)$.
\end{rem}

\begin{lem} \label{lem:lobatto-symmetry}
    Lobatto polynomials exhibit the following symmetry:
    \begin{equation} \label{eq:lobatto-symmetry}
        \mathcal{L}_N (\tau) = (-1)^N \mathcal{L}_N(-\tau) .
    \end{equation}
\end{lem}
\begin{proof}[Proof of Lemma \ref{lem:lobatto-symmetry}]
    From \cite[Eq. (4.7.4)]{Szegoe1975} the following holds:
    \begin{equation}
        \mathcal{P}_{N-1} (\tau) = (-1)^{N-1} \mathcal{P}_{N-1}(-\tau) \,.
    \end{equation}
    Taking the first derivative with respect to $\tau$, and multiplying both sides by $\tau^2 -1$ yields
    \begin{equation}
        (\tau^2-1) \dot{\mathcal{P}}_{N-1} (\tau) = (-1)^N (\tau^2-1) \dot{\mathcal{P}}_{N-1}(-\tau) \,,
    \end{equation}
    which, recalling \eqref{eq:lobatto-polynomial}, is identical to \eqref{eq:lobatto-symmetry} for $\tau \neq \pm 1$.
    The relationship still holds for $\tau = \pm 1$ due to \eqref{eq:lobatto-polynomial}, see Remark~\ref{rem:lobatto-zero-endpoints}.
\end{proof}

\subsection{Achieving an inversion-ready Lobatto differentiation matrix}
Given the set of roots of the Lobatto polynomial $\mathcal{L}_N(\cdot)$ defined in \eqref{eq:lobatto-polynomial}, the new method suggests the inclusion of \emph{an additional point of discretization along the domain at which the derivative of a continuous function of interest is not observable}, see Problem \ref{prob:discrete-initial-value-problem}.
In this section we show that this approach yields a differentiation matrix which is indeed inversion-ready according to Definition \ref{defn:inversion-ready}.

To simplify the notation henceforth, we define the set of roots of the Lobatto polynomial of degree $N$ as
\begin{equation} \label{eq:set-lobatto-roots}
    \mathcal{T}_N = \{ \tau_k \in \closedinterval{-1}{1}: \mathcal{L}_N(\tau_k) = 0 \}\,, \quad k = 1,2,\ldots,N  \,.
\end{equation}
Furthermore, let $\setS$ be a set that indexes the $N+1$ abscissas of the new method, as follows
\begin{equation} \label{eq:set-s}
    \setS = \{ 1,2, \dots, N, N+1\} \,.
\end{equation}
Then, let $\xid = N + 1$ be the \emph{index associated with the exceptional sample}, and let
\begin{equation} \label{eq:set-c}
    \setC = \setS \backslash \{\xid\} = \{ 1,2, \dots, N \}
\end{equation}
be a set that indexes the set of abscissas $\mathcal{T}_N$.

Consider a function $y: \closedinterval{-1}{1} \mapsto \mathbb{R}$.
Given $N+1$ observations of $y(\cdot)$ at $N+1$ samples $\tau_i \in \mathcal{T}_N \cup \{\tau_\xid\}$ for $i \in \setS$, an approximation of $y(\cdot)$, denoted $\tilde{y}(\cdot)$, can be constructed based on a polynomial of degree $N$ through the use of Lagrange polynomial interpolation, see, \emph{e.g.}, \cite{Berrut2004,Ross2003,Fahroo2008,Rao2010,Garg2011}, such that
\begin{equation} \label{eq:sequence-approximation}
    y(\tau) \approx \tilde{y}(\tau) = \sum_{i \in \setS} l_i(\tau) y(\tau_i) \,, \quad \tau \in \closedinterval{-1}{1} \,,
\end{equation}
where $l_i(\tau)$ denotes the Lagrange interpolating polynomial of index $i$. These polynomials are constructed as:
\begin{equation} \label{eq:poly-interp}
    l_i(\tau) = \prod_{j \in \setS \backslash \{i\}} \frac{\tau - \tau_j}{\tau_i - \tau_j} \,.
\end{equation}
From \eqref{eq:poly-interp} it is straightforward to derive that these polynomials satisfy the following:
\begin{equation} \label{eq:lagrange-kronecker-delta}
    l_i(\tau_k) = \delta_{ki} = \begin{cases} 1 \text{ if } k=i \,, \\ 0 \text{ if } k \neq i \,, \end{cases} \quad i,k \in \setS \,,
\end{equation}
where
$\tau_k \in \mathcal{T}_N \cup \{\tau_\xid\}$ denote the discretization points and $\delta_{ki}$ is called the Kronecker delta.

Finally, based on this interpolation approach, a matrix $\bm{D} \in \mathbb{R}^{N\times (N+1)}$ can be constructed as \cite{Berrut2004,Rao2010,Garg2011}
\begin{multline} \label{eq:diff-matrix}
        \bm{D}_{ki} = \dot{l}_i( \tau_k ) = \sum_{m \in \setS} \dfrac{ \prod_{j \in \setS \backslash \{i,m\}} ( \tau_k - \tau_j ) }{ \prod_{j \in \setS \backslash \{i\}} ( \tau_i - \tau_j ) } \,, \\[1ex] 
                                             k \in \setC \,, \: i \in \setS \,,
\end{multline}
where
$\tau_i \in \mathcal{T}_N \cup \{\tau_\xid\}$, 
and $\bm{D}_{ki}$ denotes the element of matrix $\bm{D}$ in row $k$ and column $i$.

\begin{thm} \label{thm:new-matrix-is-inversion-ready}
    Matrix $\bm{D}$ specified element-wise in \eqref{eq:diff-matrix} is an inversion-ready differentiation matrix over the set of abscissas $\mathcal{T}_N \cup \{ \tau_\xid\}$ with order of accuracy $N$, according to Definition \ref{defn:inversion-ready}.
\end{thm}
\begin{proof}[Proof of Theorem \ref{thm:new-matrix-is-inversion-ready}]
    It is established that matrix $\bm{D}$ has $N$ rows and $N+1$ columns, it remains to be shown that this matrix is indeed a differentiation matrix according to Definition \ref{defn:differentiation-matrix} and that it is a full-rank matrix.
    From \cite{Davis1975,Epperson1987}, given $N+1$ distinct abscissas $\tau_i$ with $i \in \setS$, it is known that the interpolation formula expressed in \eqref{eq:sequence-approximation} is exact if the original function is a polynomial of degree $N$ or less, \emph{i.e.}, the equality $\tau^R = \sum_{i \in \setS} l_i(\tau) \tau_i^R $ holds for an integer $R \leq N$, where $l_i(\tau)$ denotes the Lagrange interpolating polynomial of index $i$. Applying the derivative with respect to $\tau$ to both sides, we get
    \begin{equation}
        \diff{\tau^R}{\tau} = R \tau^{R-1} = \sum_{i \in \setS} \dot{l}_i(\tau) \tau_i^R \,.
    \end{equation}
    Letting $\tau = \tau_k$ and recalling \eqref{eq:diff-matrix} we obtain
    \begin{equation}
        \sum_{i \in \setS} \dot{l}_i(\tau_k) \tau_i^R = \sum_{i \in \setS} \bm{D}_{ki} \tau_i^R = R \tau_k^{R-1}  \,,
    \end{equation}
    which matches Definition \ref{defn:differentiation-matrix} with order of accuracy $N$, therefore, from Lemma \ref{lem:rank-bounds}, we have $N \leq \texttt{Rank}(\bm{D}) \leq N$, implying $\texttt{Rank}(\bm{D}) = N$.
\end{proof}

\begin{rem} \label{rem:prop-is-true-for-any-abscissa}
    Theorem \ref{thm:new-matrix-is-inversion-ready} holds for all choices of $\tau_\xid$, as long as the abscissas are unique.
\end{rem}

\subsection{Determining an appropriate location for the exceptional sample}
We limit the search domain for the exceptional sample to the closed interval $\closedinterval{-1}{1}$, such that the domain of interpolation is preserved with respect to that of the unmodified roots of the Lobatto polynomial.

To find an appropriate location $\tau_\xid$ the following metric is adopted:
\begin{equation} \label{eq:simplified-problem}
    \underset{\tau_\xid}{\text{minimize}} \quad \omega(\tau_\xid) = \norm{ \bm{D}(\tau_\xid) \bm{\delta}_\xid } \,,
\end{equation}
where
$\bm{D}(\tau_\xid)$ is an explicit parametrization of matrix $\bm{D}$ with respect to $\tau_\xid$, characterized by $\bm{D} : \closedinterval{-1}{1} \mapsto \mathbb{R}^{N\times (N+1)}$.
Furthermore, $\bm{\delta}_\xid$ is a vector of zeros except at index $\xid$ where it takes the value $\varepsilon \neq 0$, and the vector norm operator $\norm{\cdot}$ can be chosen arbitrarily for reasons that will become apparent shortly.
This metric is motivated by our intention of minimizing the degradation of interpolation quality with respect to the original set of Lobatto nodes given a perturbation at the exceptional sample.

Figure \ref{fig:intuition} shows an example polynomial interpolation, denoted $y(\tau)$, about three points for two distinct choices of the location $\tau_\xid$ of a perturbation. The perturbation, $\varepsilon$, is kept constant for the two choices. The figure illustrates that the magnitude of the derivative at interpolation nodes is sensitive to the location of the node where the perturbation occurs.
% The metric in \eqref{eq:simplified-problem} expresses our wish to find a location that minimizes these magnitudes.
% Figure environment removed

The metric expressed in \eqref{eq:simplified-problem} is reduced to the problem of finding the minimizer of the norm of the column of matrix $\bm{D}$ with index $\xid$. In this context, from \eqref{eq:diff-matrix}, the elements in column $\xid$ of matrix $\bm{D}$ are
\begin{equation} \label{eq:D-column}
        \bm{D}_{k\xid} (\tau_\xid) =  \dfrac{\sum_{m \in \setC} \prod_{j \in \setC \backslash\{m\}} ( \tau_k - \tau_j )}{ \prod_{j \in \setC} ( \tau_\xid - \tau_j ) }  \,, \quad k \in \setC \,,
\end{equation}
where the index set $\setC$ is defined in \eqref{eq:set-c}.

It becomes apparent that the denominator and the numerator terms are proportional to the Lobatto polynomial and its derivative, respectively. Thus, \eqref{eq:D-column} can be rewritten as 
\begin{equation} \label{eq:Dke-with-lobatto}
    \bm{D}_{k\xid} (\tau_\xid) = \dfrac{\dot{\mathcal{L}}_N(\tau_k)}{ \mathcal{L}_N(\tau_\xid) } \,, \quad k \in \setC \,.
\end{equation}

Notice that the denominator term, which is the only term that depends on $\tau_\xid$, is identical for the entire column, \emph{i.e.}, it does not change with $k$. Therefore, let a constant $\alpha \in \mathbb{R}$ be such that
\begin{equation} \label{eq:alpha}
    \alpha = \norm{ \mathcal{L}_N(\tau_\xid) \bm{D}(\tau_\xid) \bm{\delta}_\xid } \,.
\end{equation}
Notice that the right-hand-side of \eqref{eq:alpha} is constant with respect to $\tau_\xid$, see \eqref{eq:Dke-with-lobatto}.
In this way, we can rewrite the objective from \eqref{eq:simplified-problem} as
\begin{equation} \label{eq:omega-final}
    \omega(\tau_\xid) = \dfrac{ \alpha }{| \mathcal{L}_N(\tau_\xid) |} \,.
\end{equation}

Finally, notice that the vector norm operator in \eqref{eq:simplified-problem} and \eqref{eq:alpha} is arbitrary. The choice of norm operator only scales the value of $\alpha$.

\begin{rem} \label{rem:maxL-minOmega}
    Due to \eqref{eq:omega-final}, the global minimizer of $\omega(\cdot)$ is given by the global maximizer of $| \mathcal{L}_N(\cdot) |$.
    Namely, let $\pi$ be such that $\omega(\pi) \leq \omega(\tau)$, $\forall \tau \in \closedinterval{-1}{1}$ holds. Then, $|\mathcal{L}_N(\pi)| \geq |\mathcal{L}_N(\tau)|$, $\forall \tau \in \closedinterval{-1}{1}$.
\end{rem}

\begin{thm} \label{thm:pattern-of-maxima}
    The global maximum of $|\mathcal{L}_N(\cdot)|$ is the stationary point of $\mathcal{L}_N(\cdot)$ whose abscissa is nearest zero.
\end{thm}
\begin{proof}[Proof of Theorem \ref{thm:pattern-of-maxima}]
    The following derivations are inspired by \cite[Proof of Theorem 7.3.1]{Szegoe1975}.
    Let us define an envelope function for $\mathcal{L}_{N}^2(\cdot)$ as
    \begin{equation} \label{eq:lobatto-envelope}
        \mathcal{F}(\tau) = \mathcal{L}_{N}^2(\tau) + \tfrac{ 1 - \tau^2 }{N(N-1)} \dot{\mathcal{L}}_{N}^2(\tau) \,,
    \end{equation}
    with $\tau \in \closedinterval{-1}{1}$,
    such that $\mathcal{F}(\tau) \geq \mathcal{L}_{N}^2(\tau)$, $\forall \tau \in \closedinterval{-1}{1}$ and $\mathcal{F}(\tau) = \mathcal{L}_{N}^2(\tau)$ when $\dot{\mathcal{L}}_{N}(\tau) = 0$ (stationary points) or when $\tau = \pm 1$ (domain endpoints).
    Applying the first derivative with respect to $\tau$ to both sides of \eqref{eq:lobatto-envelope} yields
    \begin{multline}
        \dot{\mathcal{F}}(\tau) = 2 \mathcal{L}_N(\tau) \dot{\mathcal{L}}_N (\tau) - \tfrac{2\tau}{N(N-1)} \dot{\mathcal{L}}_N^2(\tau) \\
        + \tfrac{2(1-\tau^2)}{N(N-1)}\dot{\mathcal{L}}_N (\tau)\ddot{\mathcal{L}}_N (\tau) \,,
    \end{multline}
    and factoring out the common term leads to
    \begin{multline}
        \dot{\mathcal{F}}(\tau) = 2 \dot{\mathcal{L}}_N (\tau) \bigl[ \mathcal{L}_N(\tau) - \tfrac{\tau^2-1}{N(N-1)} \ddot{\mathcal{L}}_N (\tau) \\ - \tfrac{\tau}{N(N-1)} \dot{\mathcal{L}}_N(\tau) \bigr] \,,
    \end{multline}
    and, due to \eqref{eq:lobatto-second-order}, it simplifies to
    \begin{equation}
        \dot{\mathcal{F}}(\tau) = \frac{-2\tau \dot{\mathcal{L}}_N^2(\tau)}{N(N-1)} \,.
    \end{equation}
    This shows that $\mathcal{F}(\tau)$ is increasing for $\tau<0$ and decreasing for $\tau>0$.
    Finally, let $\pi$ be such that $\dot{\mathcal{L}}_{N}(\pi) = 0$. Then, from \eqref{eq:lobatto-envelope} and Lemma~\ref{lem:lobatto-symmetry} we have
    \begin{equation}
        \mathcal{F}(\pi) = \mathcal{L}_N^2 (\pi) = \mathcal{L}_N^2 (-\pi) = \mathcal{F}(-\pi) \,.
    \end{equation}
\end{proof}

\begin{cor} \label{cor:final}
    The global minimizer of $\omega(\cdot)$ is the root of $\mathcal{P}_{N-1}(\cdot)$ which is nearest zero.
\end{cor}
\begin{proof}[Poof of Corollary \ref{cor:final}]
    Due to \eqref{eq:omega-final}, see Remark \ref{rem:maxL-minOmega}, and Theorem \ref{thm:pattern-of-maxima}, the global minimizer of $\omega(\cdot)$ is the stationary point of $\mathcal{L}_N(\cdot)$ whose abscissa is closest to zero.
    Due to \eqref{eq:lobatto-first-order}, see Remark \ref{rem:lobatto-extrema}, the abscissas associated with stationary points of $\mathcal{L}_N(\cdot)$ are roots of $\mathcal{P}_{N-1}(\cdot)$.
\end{proof}

Ultimately, to minimize \eqref{eq:simplified-problem}, we select $\tau_\xid$ according to Corollary \ref{cor:final}.
This concludes the study for the location of the exceptional sample of the new method.


\subsection{Note on Runge's phenomenon}
Notably, the Lagrange interpolating polynomial of index $\xid$ is proportional to the Lobatto polynomial, in particular with a constant of proportionality of $\frac{1}{\mathcal{L}_N(\tau_\xid)}$. This result is obtained from \eqref{eq:poly-interp} as
\begin{equation}
    l_\xid(\tau) = \prod_{j \in \setC} \frac{\tau - \tau_j}{\tau_\xid - \tau_j} = \frac{\mathcal{L}_N(\tau)}{\mathcal{L}_N(\tau_\xid)} \,, \quad \tau \in \closedinterval{-1}{1} \,.
\end{equation}
Therefore, the relationship $\dot{\mathcal{L}}_N(\tau) = \dot{l}_\xid(\tau) \mathcal{L}_N(\tau_\xid)$ holds, and the stationary points of $l_\xid(\cdot)$ coincide with those of $\mathcal{L}_N(\cdot)$.
This motivates the following proposition.
\begin{prop} \label{prop:runge}
    The global minimizer of $\omega(\cdot)$ mitigates the Runge phenomenon associated with the Lagrange interpolating polynomial of index $\xid$.
\end{prop}
\begin{proof}[Proof of Proposition \ref{prop:runge}]
    Runge's phenomenon is mitigated if the interpolating polynomial remains bounded for arbitrary $N$, such that
    \begin{equation} \label{eq:runge-metric}
        |l_\xid(\tau)| \leq l_\xid(\tau_\xid) = 1 \,, \quad \forall \tau \in \closedinterval{-1}{1} \,.
    \end{equation}
    Therefore, let $\pi \in \closedinterval{-1}{1}$ be such that the inequality \eqref{eq:runge-metric} is not satisfied
    \begin{equation}
        |l_\xid(\pi)| = \frac{|\mathcal{L}_N(\pi)|}{|\mathcal{L}_N(\tau_\xid)|} > 1 \quad \Leftrightarrow \quad
        |\mathcal{L}_N(\pi)| > |\mathcal{L}_N(\tau_\xid)| \,.
    \end{equation}
    From \eqref{eq:omega-final} we know that $|\mathcal{L}_N(\tau_\xid)| \geq |\mathcal{L}_N(\tau)|\,, \quad \forall \tau \in \closedinterval{-1}{1}$, see Remark \ref{rem:maxL-minOmega}, thus:
    % Then, \eqref{eq:omega-final} leads to, see Remark \ref{rem:maxL-minOmega}:
    \begin{equation}
        |\mathcal{L}_N(\pi)| > |\mathcal{L}_N(\tau)| \,, \quad \forall \tau \in \closedinterval{-1}{1} \,,
    \end{equation}
    which is contradictory, therefore such $\pi$ cannot exist. 
\end{proof}


\subsection{Gaussian quadrature}
Gaussian quadrature is a method of approximation of the definite integral of a function within the domain $\closedinterval{-1}{1}$ through a weighted sum of $N$ samples of the function, see, \emph{e.g.}, \cite{Radau1880,Hildebrand1987}.
% The weights are associated with the location of the samples and they are chosen deliberately such that the operation is exact for polynomials up to a certain degree.
In the case of Gauss-Lobatto quadrature, the method is exact for polynomial functions of degree up to $2N-3$, see, \emph{e.g.}, \cite{Radau1880,Hildebrand1987}.

In this regard, consider the polynomial function $y: \mathbb{R} \mapsto \mathbb{R}$ of degree $2N-3$ or less, and the set of roots of the Lobatto polynomial $\tau_k \in \mathcal{T}_N$ with $k \in \setC$, then the quadrature rule is expressed as follows:
\begin{equation} \label{eq:gauss-quadrature}
    \int_{-1}^{1} y(\tau) \dl \tau = \sum_{k \in \setC} w_k y(\tau_k)\,, \quad \tau_k \in \mathcal{T}_N \,,
\end{equation}
where $w_k$ are the associated Gauss-Lobatto quadrature weights which are computed as, see, \emph{e.g.}, \cite{Ross2003,Fahroo2008,Radau1880},
\begin{equation} \label{eq:weights}
    w_k = \frac{2}{N(N-1)\mathcal{P}_{N-1}^2(\tau_k) } \,, \quad k \in \setC \,.
\end{equation}

\begin{rem} \label{rem:min-degree}
    The new method employs a polynomial interpolation of degree $N$, see \eqref{eq:sequence-approximation} and \eqref{eq:poly-interp}. Therefore, to certify that the quadrature rule is always exact for this interpolation function we have to assert $2N-3 \geq N$, implying $N \geq 3$.
\end{rem}

% \begin{prop} \label{prop:min-degree}
%     If Gaussian quadrature is to be used, the new method requires a polynomial interpolation of degree 3 at least.
% \end{prop}
% \begin{proof}[Proof of Proposition \ref{prop:min-degree}]
%     A polynomial interpolation of degree $N$ is used with the new method, see \eqref{eq:sequence-approximation} and \eqref{eq:poly-interp}. Therefore, in order to certify that the quadrature rule is always exact for $\int_{-1}^{1} l_k(\tau) \dl \tau$ one must assert
%     \begin{equation}
%         2N-3 \geq N \quad \Leftrightarrow \quad N \geq 3 \,,
%     \end{equation}
%     where $l_k(\tau)$ denotes the Lagrange interpolating polynomial of index $k$ defined in \eqref{eq:poly-interp}.
% \end{proof}

\begin{lem} \label{lem:lagrange-inner-prod}
    Let $l_k (\tau)$ with $\tau \in \closedinterval{-1}{1}$ denote the Lagrange interpolating polynomial of index $k$, obtained with \eqref{eq:poly-interp}. Furthermore, let $p(\tau)$ denote some polynomial of degree $N-3$ or less. Then the following equation holds:
    \begin{equation} \label{eq:lagrange-inner-product}
        \int_{-1}^{1} l_k(\tau) p(\tau) \dl \tau = w_k p (\tau_k) \,, \quad \tau_k \in \mathcal{T}_N, \: k \in \setC \,,
    \end{equation}
    where $w_k$ denotes the quadrature weight associated with index $k$, obtained from \eqref{eq:weights}.
\end{lem}
\begin{proof}[Proof of Lemma \ref{lem:lagrange-inner-prod}]
    Let $l_k(\tau)$ and $p(\tau)$ be as above. Then the following Gauss-Lobatto quadrature is exact:
    \begin{equation}
        \int_{-1}^{1} l_k(\tau) p(\tau) \dl \tau = \sum_{i \in \setC} w_i l_k(\tau_i) p(\tau_i) \,, \quad k \in \setC \,,
    \end{equation}
    with $\tau_i \in \mathcal{T}_N$. Recalling \eqref{eq:lagrange-kronecker-delta} yields \eqref{eq:lagrange-inner-product}.
\end{proof}

