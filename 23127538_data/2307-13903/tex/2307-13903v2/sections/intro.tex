\section{Introduction}
Consider the dynamic pricing problem, where a seller attempts to sell a product to a buyer each day without any prior knowledge of the maximum price $u$ the buyer is willing to pay (i.e. the buyer's private valuation for the product). The seller must learn this price by observing the buyer's behavior, which takes the form of a binary signal: a purchased or an unpurchased item. An unpurchased item indicates an overpriced product, leading to a possible loss of the entire revenue $u$; a purchased item indicates an underpriced product, leading to a possible loss of surplus (the difference between $u$ and the posted price). However, the seller does not directly observe the revenue loss and only observes the binary signal of the buyer. The seller adjusts the posted price according to the signal and gradually converges to the optimal price. An early important work by~\cite{kleinberg2003value} studied dynamic pricing from a regret-minimization perspective and fully characterize the optimal regret of the seller for the most basic form of this problem. 


The \emph{contextual search} (or \emph{contextual pricing}) problem~(\cite{liu2021optimal, leme2022contextual, mao2018contextual}) is motivated by the fact that buyers have different valuations for differentiated products with different features. Henceforth the features of products are referred to as \emph{context} vectors. A common assumption is that the buyer's valuation is a linear function on the context vector~(\cite{liu2021optimal, leme2022contextual}). In this setting,~\cite{liu2021optimal} obtains a nearly optimal regret bound. Another assumption is that the valuation function is Lipschitz with respect to the context vector. This setting was studied by~\cite{mao2018contextual}, in which they gave nearly optimal algorithms based on discretization of the input space.
\lbcomment{Another assumption that ... input space. -> ~\cite{mao2018contextual} studied the assumption of Lipschitzness: the valuation function only requires Lipschitzness in the context vectors without assuming an explicit parametric form and gave nearly optimal algorithms based on discretization of the input space}

\szcomment{Alternate version. The contextual search problem comes from the idea that various product features influence a buyer's valuation. These product features are referred to as context vectors. A common assumption is that the buyer's valuation is a linear function on the context vectors. Liu et al.~\cite{liu2021optimal} have almost completely characterized the optimal regret in this setting. Lipschitzness is another approach: the valuation function only requires Lipschitzness in the context vectors without assuming an explicit parametric form~\cite{mao2018contextual}. }

In practice, it is unreasonable to assume the signals the seller receives are perfect. For example, buyers can act irrationally, or in extreme cases may even exhibit malicious behaviors, resulting in faulty signals. \lbcomment{could give some specific examples here} This motivates the study of designing contextual search algorithms robust to corruptions in the binary signals that the learner observes. \szdelete{The corruptions are modeled as generated by an adversary who has the power to corrupt the binary signals observed by the learner.}\lbcomment{This sounds weird grammatically} Previous works~(\cite{krishnamurthy2022contextual, leme2022corruption}) studied linear contextual search with corruptions, in which an adversary has the power to corrupt the binary signals. This work studies Lipschitz contextual search with corruptions and proposes corruption-robust algorithms. 

\szcomment{This work considers an adversary model where the adversary has the power to directly corrupt the binary signal after observing the learner's guess. This adversary model is much stronger than the recent works~\cite{krishnamurthy2022contextual, leme2022corruption} on corruption-robust linear contextual search. }\szcomment{studied linear contextual search in an \emph{adversarial corruption} model. In their model, the adversary commits to a corruption $z_t$ to be added to the function value \emph{before} observing the guess by the learner. In the current work, \lbcomment{In the current work -> In this work} the adversary is able to directly decide whether to corrupt the signal, hence the power of the adversary in this work is significantly stronger. }

\paragraph{Loss Functions and Applications. } The literature on contextual search usually considers two loss functions, the \emph{pricing loss} and the \emph{symmetric loss} (synonymous with the \emph{absolute loss} in some work, e.g.~\cite{krishnamurthy2022contextual}). The pricing loss is defined by
\[
\ell(q, f(x)) = f(x) - q\cdot \ind{q\le f(x)}. 
\]
The pricing loss captures the dynamic pricing setting described above. The optimal price for a product with context vector $x$ is $f(x)$. If the seller overprices $q > f(x)$, she loses the entire revenue $f(x)$; if the seller underprices $q \le f(x)$, she loses the potential surplus $f(x) - q$. The cumulative pricing loss then measures the regret of the seller had she known the valuation function $f$. It should be noted the actual loss of each round is never revealed to the learner, and only the binary signal is revealed. 

The symmetric loss is defined as
\[
\ell(q, f(x)) = \abs{q - f(x)}. 
\]
An application of symmetric loss is personalized medicine. Consider a healthcare provider experimenting with a new drug. Assume the optimal dosage for a patient with context feature $x$ is $f(x)$, and the given dosage is $q$. The symmetric loss then measures the distance between the injected dosage and the optimal dosage. The learner (healthcare provider) is not able to directly observe this loss but can observe a binary signal informing whether she overdosed or underdosed. 

For either the pricing loss or symmetric loss $\ell$, the cumulative loss (or regret, this work will use the two terms interchangebly) of the learner after $T$ rounds is then defined as:
\[
\sum_{t\in [T]} \ell_t = \ell(q_t, f(x_t)). 
\]

\subsection{Contributions}
In this work, I design corruption-robust algorithms for learning Lipschitz functions with binary signals. The learner tries to learn a Lipschitz function $f$ chosen by an adversary. The domain of $f$ is the $d$-dimensional cube $[0,1]^d$. At each round, the adversary presents the learner with an adversarially chosen context vector $x_t \in [0,1]^d$, and the learner submits a guess $q_t$ to the value of $f(x_t)$ and observes a binary signal indicating whether the guess is low or high. Throughout the course of $T$ rounds, a total of $C$ signals may be corrupted, though the value of $C$ is unknown to the learner. The goal of the learner will be to incur a small cumulative loss that degrades gracefully as $C$ increases. 

I design corruption-robust algorithms under two loss functions, symmetric loss and pricing loss. The corruption-robust algorithm for symmetric loss is given in~\Cref{sec:symmetric}, and the algorithm for pricing loss is given in~\Cref{sec:pricing}. 

\begin{theorem*}[\Cref{thm:symm1D} restated]
For symmetric loss with $d=1$, there exists an algorithm that achieves regret $L\cdot O(C\log T)$. 
\end{theorem*}

\begin{theorem*}[\Cref{thm:symmMD} restated]
For symmetric loss with $d\ge 2$, there exists an algorithm that achieves regret $L\cdot O_d(C\log T + T^{(d-1)/d})$. 
\end{theorem*}

\szdelete{The pricing loss is defined as
\[
\ell(q, f(x)) = f(x) - q\cdot \ind{q \le f(x)}. 
\]
The natural application is dynamic pricing, as introduced previously. If the seller overprices ($q > f(x)$), she loses the entire revenue $f(x)$; if the seller underprices ($q \le f(x)$), she loses the potential surplus $f(x) - q$. I give corruption-robust algorithms for pricing loss in~\cref{sec:pricing}, a simplified version of the main result is as follows. }
\begin{theorem*}[\Cref{thm:pricing} restated]
    For pricing loss, there exists an algorithm that achieves regret $L\cdot \widetilde{O}(T^{d/(d+1)} + C \cdot T^{1/(d+1)})$. More generally, for any $\tau_0 \in (2,T)$, there exists an algorithm that achieves regret $L\cdot \widetilde{O} (T/\tau_0 + C\tau_0 + T^{d/(d+1)})$. 
\end{theorem*}

For the symmetric loss with either $d = 1$ or $d\ge2$, the dependence on $C$ and $T$ are both optimal in the regret (up to $\log T$ factors). For the pricing loss, the regret is optimal when $C = O(T^{(d-1)/(d+1)})$. 

\lbcomment{consider making the following paragraphs as 1.3, a new subsection. it makes sense to me to introduce related works first and then compare your work to related works}
This work introduces a new algorithmic technique of \emph{agnostic checking} and shows how \emph{agnostic checking} can be incorporated into the adaptive discretization and uniform discretization procedure, usually used in learning Lipschitz functions. At a very high level, the input space is discretized into ``bins", and the learner maintains an associated range for each bin which serves as an estimate for the image of $f$ in the bin. The associated range becomes more accurate as the learner submits more queries and observes more binary signals. However, since the binary signals may be corrupted, the associated range may not be accurate. The learner performs checking steps by querying the boundaries of the associated range and tries to ensure the associated range is accurate. \lbcomment{delete previous sentence}A key challenge is that checking steps may also be corrupted, hence the new technique is termed ``agnostic checking". New analysis techniques are introduced to bound the regret while the learner is agnostic as to whether the checking steps are corrupted or not. 

\szdelete{
\emph{agnostic checks} ensure the estimated function values in the discretized input space are accurate in the presence of adversarial corruptions. The analysis is much more intricate and requires significantly new ingredients, since \emph{agnostic checks} can also be corrupted (hence the name). }\lbcomment{the first and the last sentences seem to convey the same meaning, but it's not clear what's your message to the readers}

\lbcomment{do you ever mention Table 1 in these paragraphs? It seems like Table 1 is related to comparison of previous works. If Table 1 is used in later paragraph, you should consider moving it to a better place}

\subsection{Related Work}
The two most related threads to this work are contextual search and corruption-robust learning. The linear contextual search problem was studied in~\cite{liu2021optimal, leme2022contextual}, and the recent work by \cite{liu2021optimal} achieved state-of-the-art regret bounds. For the Lipschitz contextual search problem,~\cite{mao2018contextual} proposed algorithms based on adaptive discretization and binary search. They also showed their algorithm to be nearly optimal. The contextual search problem is also closely related to the dynamic pricing problem, for an overview see~\cite{den2015dynamic}. 

Recently, designing learning algorithms robust to corruption and data-poisoning attacks has received much attention. \cite{leme2022corruption} gave corruption-robust algorithms for the linear contextual problem based on density updates, improving over the work by~\cite{krishnamurthy2022contextual}. The study of adversarial attack and the design of corruption-robust algorithms has also appeared in bandit learning~(\cite{lykouris2018stochastic, gupta2019better, jun2018adversarial, zuo2023near, garcelon2020adversarial, bogunovic2021stochastic}) and reinforcement learning~(\cite{lykouris2021corruption, zhang2022corruption, chen2021improved}), to name a few. \szcomment{TODO, add cite. }

This work is also related to the contextual bandits and bandits in metric spaces~(\cite{kleinberg2008multi, kleinberg2010sharp, cesa2017algorithmic, slivkins2011contextual}). The notable work by ~\cite{slivkins2011contextual} studied a setting where the learner picks an arm after observing the contextual information each round, and subsequently the context-arm dependent reward (or equivalently loss) is revealed. \szcomment{In this work \lbcomment{In the current work -> In this work}, the loss is not revealed to the learner, and only a binary signal is observed, hence the feedback structure is fundamentally different. \lbcomment{You may want to add a couple of sentences to explain why the difference matter, and perhaps why it matters should go to the end of this paragraph or go to the contribution section to emphasize your novelty; review other people's work first and explain what is unique in your work} }\szcomment{TODO. add cite}

Another interesting direction peripheral to this work is learning with strategic agents. In this setting, the learner is not interacting with an adversary but with a strategic agent whose goal is to maximize his long-term utility.~\cite{amin2013learning} studied designing auctions with strategic buyers; ~\cite{amin2014repeated} and~\cite{drutsa2020optimal} incorporated contextual information and designed contextual auctions with strategic buyers. 

\lbcomment{do you need a paragraph describing what's the novelty of your work? I remember some reviewers are questioning your novelty related to previous work.}

\subsection{Comparison with previous work}
Comparisons with the most relevant works are summarized in~\Cref{table:results}. The problem of Lipschitz contextual search was studied in~\cite{mao2018contextual}, in which they proposed near-optimal algorithms when the binary signals are perfect each round (i.e. no corruptions). This work studies the Lipschitz contextual search with adversarial corruptions and designs corruption-robust algorithms while being agnostic to the corruption level $C$. 

\cite{krishnamurthy2022contextual} and~\cite{leme2022contextual} studied the linear contextual search problem with adversarial corruptions. In their work, the underlying unknown function $f$ takes the parametric linear form $f(x) = \ip{\theta}{x}$, where $\theta$ is the unknown parameter and $x$ is the context vector. This work does not make any parametric assumptions and works with the non-parametric Lipschitz assumption, i.e. $f$ is only assumed to be Lipschitz. Moreover, the adversary model in this work is stronger than the adversary model studied in their work (see remark~\ref{remark:adversaryModel} below). 

\cite{leme2021learning} contained an algorithmic solution to the non-stationary dynamic pricing problem, which is superficially similar to this work. Their work also used the notion of ``checking steps". This work is different from theirs in the following aspects.\lbcomment{previous sentence can be deleted} The algorithm in this work is designed for an \emph{adversarial corruption} setting with \emph{context} information (under the Lipschitz assumption). Since checking steps can also be corrupted and the learner will not know whether the signal obtained from checking steps is accurate, this work terms these as \emph{agnostic checking}. This work shows entirely new analysis techniques on how agnostic checking can be incorporated with the discretization technique used for learning Lipschitz functions. By contrast,~\cite{leme2021learning} studied a non-stationary dynamic pricing setting without context and when there is no corruption in the binary signals. \lbcomment{``where there is'' is not gramatically correct}

Some recent work also studied corruption-robust algorithms for contextual bandit problems (e.g.~\cite{bogunovic2021stochastic} and~\cite{he2022nearly}). Note that the feedback and reward model in this work is fundamentally different from contextual bandit problems. Specifically, for contextual bandits, the adversary first chooses a function (the reward function), and then the learner chooses some action (based on some context) each round and observes a (possibly corrupted) reward. In this work, the contexts are chosen by the adversary, and the learner guesses the value of the unknown function and only observes a (possibly corrupted) binary signal of whether the guess is low or high. 

\renewcommand{\arraystretch}{1.1}
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
                         Setting  & Adversary & Symmetric Loss                                                                                             & Pricing Loss                                                                                  \\ \hline
\multirow{2}{*}{Linear}    & No        & \begin{tabular}[c]{@{}c@{}}$O(d\log d)$\\ \cite{liu2021optimal}\end{tabular}                                & \begin{tabular}[c]{@{}c@{}}$O(d\log\log T + d\log d)$\\ \cite{liu2021optimal}\end{tabular}     \\ \cline{2-4} 
                           & Weak      & \begin{tabular}[c]{@{}c@{}}$O(C+d\log T)$\\ \cite{leme2022corruption}\end{tabular}                              & \begin{tabular}[c]{@{}c@{}}$O(C d^3 \poly\log(T/\delta))$\\ \cite{krishnamurthy2022contextual}\end{tabular} \\ \hline
\multirow{2}{*}{Lipschitz} & No        & \begin{tabular}[c]{@{}c@{}}$O(T^{(d-1)/d})$\\ $O(\log T)$ when $d = 1$\\ \cite{mao2018contextual}\end{tabular} & \begin{tabular}[c]{@{}c@{}}$O(T^{d/(d+1)})$\\ \cite{mao2018contextual}\end{tabular}               \\ \cline{2-4} 
                           & Strong    & \begin{tabular}[c]{@{}c@{}}$O(C\log T + T^{(d-1)/d})$\\ $O(C\log T)$ when $d = 1$\\ \textcolor{red}{This work}\end{tabular} & \begin{tabular}[c]{@{}c@{}}$\Tilde{O}(C\cdot T^{1/(d+1)} + T^{d/(d+1)})$\\ \textcolor{red}{This work}\end{tabular}                          \\ \hline
\end{tabular}
\vspace{0.1in}
\caption{Regret for contextual search under different settings. For the Lipschitz contextual search problem, the Lipschitz $L$ is treated as constant and omitted in the regret. }
\label{table:results}
\end{table}