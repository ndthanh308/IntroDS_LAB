\section{Proof Details for Pricing Loss}
\label{app:pricing}
\szcomment{Don't use adaptive zooming / adaptive discretization, use uniform discretization}


\iffalse
\begin{definition}
\label{def:validPair}
Call a hypercube $I_j$ a pricing-ready hypercube if $\len(Y_j) \le 10 L \cdot \eta$. Call the associated range $Y_j$ the pricing-ready range, and together $I_j, Y_j$ form a pricing-ready pair. A pricing-ready pair is valid if $f(I_j) \in Y_j$, otherwise, it is invalid. 
\end{definition}

\begin{definition}
\label{def:queryType}
Let $I_j, Y_j$ be a pricing-ready pair. A query of $\min(Y_j)$ is said to be a pricing query. A query of $\max(Y_j)$ is said to be a agnostic checking query. A query on a pair that is not pricing-ready (i.e. when $Y_j > 10L\cdot \eta$) is called a search query. 
\end{definition}


\begin{definition}
\label{def:run}
Let $I_j, Y_j$ be a pricing-ready pair. The set of queries that occurred on the pair before the learner becomes surprised or the algorithm terminates is called a run. 
\end{definition}
\fi

% The proof outline is as follows. 
% \begin{enumerate}
%     \item For intervals that are not pricing-ready, use safe/amending/corrupted to analyze. 
%     \item For intervals that are pricing-ready, use valid/invalid to analyze. 
% \end{enumerate}

% The following lemma follow directly from the analogue for symmetric loss, with minor changes. 
% \begin{lemma}
%     Consider all intervals with depth less than $\log 1/\eta$. Safe intervals contribute $O(1)$ loss each, total $O(T^{d/(d+1)})$ loss. Corrupted intervals contribute $O(\log T)$ loss each, total $O(C\log T)$ loss. Amending intervals contribute $O(\log T)$ loss each, total $O(2^d \cdot C\cdot \log T)$ loss. 
% \end{lemma}

Recall that on a pricing-ready hypercube $I_j$, the learner is said to become \emph{surprised} when the signal is inconsistent with $Y_j$. In other words, the learner becomes surprised when she queried $\min(Y_j)$ and receives an overprice signal ($\sigma_t = 1$), or queried $\max(Y_j)$ and receives an underprice signal ($\sigma_t = 0$). 

\szdelete{
The sanity check schedule ensures the following holds. 
\begin{claim}
Let a pricing interval be run for $t_0$ rounds before the learner becomes surprised or the algorithm terminates, then the number of sanity checks is $\Theta(g^{-1}(t_0))$. Conversely, if there are $s_0$ sanity checks in this run, then the interval has been run for $\Theta(g(s_0))$ rounds. 
\end{claim}
}

\begin{lemma}
\label{lemma:surprised}
    %There are at most $C$ invalid pricing intervals. 
    The learner becomes surprised at most $C$ times. 
\end{lemma}

\begin{proof}
    The learner can become surprised for the following two reasons: the signal itself is corrupted, or the signal is uncorrupted, but the associated range $Y_j$ is inaccurate ($f(I_j)\notin Y_j$). In the latter case, a corruption must have occurred in the search queries before the hypercube became pricing ready. Since there are at most $C$ corruptions, the learner can become surprised at most $C$ times. 
\end{proof}


\begin{lemma}
\label{lemma:pricingLoss}
    Consider a run of length $\tau$ on some hypercube $I_j$. Further, assume a total of $\xi$ signals were corrupted during this period. Then pricing rounds pick up a loss of $L\cdot O(\tau \eta_0 + \xi \tau_0)$ during this run. 
\end{lemma}

\begin{proof}
If $f(I_j) \in Y_j$, then each pricing round incurs loss $L\cdot O(\eta_0)$, hence a run with length $\tau$ incurs loss $L\cdot O(\tau \eta_0)$. 

Otherwise there are four cases. 
\begin{enumerate}
    \item $f(I_j) \ge \max(Y_j)$
    \item $f(I_j)$ has some overlap with $Y_j$ and $f(I_j) \ge \min(Y_j)$, $\max(Y_j) \in f(I_j)$
    \item $f(I_j) \le \min(Y_j)$
    \item $f(I_j)$ has some overlap with $Y_j$ and $f(I_j) \le \max(Y_j)$, $\min(Y_j) \in f(I_j)$
\end{enumerate} 
\szcomment{Insert a illustration here. }


For case 1, any uncorrupted signal in agnostic check queries makes the learner surprised. Hence assuming the adversary spent corruption budge $\xi$, then the run must terminate in $O( \xi \tau_0 )$ rounds since the adversary must be corrupting every agnostic check query. The learner then trivially incurs loss $L\cdot O(\xi \tau_0)$. 

For case 2, the loss collected is at most $L\cdot O(\eta_0)$ per pricing round, hence the total loss is $L\cdot O(\tau \eta_0)$. 
%At most $f(c_0)$ corruption. 

For case 3, any uncorrupted signal in pricing rounds makes the learner surprised. Hence assuming the adversary spent a corruption budget $\xi$, the run terminates in $\Theta(\xi)$ rounds (since the adversary must be corrupting all pricing rounds), and the learner incurs regret $L\cdot O(\xi)$. 

For case 4, the adversary does not corrupt agnostic check rounds, or the learner will become immediately surprised. If the learner does not become surprised during pricing rounds, this could be due to either: 1. the learner did not overprice, or 2. the learner overpriced but the adversary corrupted the signal. Consequently in pricing rounds, uncorrupted queries accumulate $L\cdot O(\tau \eta_0)$ loss, and corrupted queries accumulate $L\cdot O(\xi)$ loss. 
%Can terminate very long or terminate in $O(c_0)$ rounds. 

Putting all cases together completes the proof. 
\end{proof}

In the following, let $\cT$ be a multi-set with elements denoting the length of runs of pricing-ready pairs. Let $\cC$ be a multi-set with elements denoting the number of corruptions that occurred in runs of pricing-ready pairs. 
%The learner starts with $2^{d \floor{ \log(1/\eta)} }  \le \eta^{-d}$ hypercubes, and becomes surprised at most $C$ times. 




\begin{theorem}[\Cref{thm:pricing} restated]
\Cref{algo:pricing} incurs cumulative pricing loss 
\[
L\cdot {O} \left( T/\tau_0 + C\tau_0 + T^{d/(d+1)} \log T  + C\log T\right). 
\]
\end{theorem}
\begin{proof}
    First, an upper bound is obtained on the total loss incurred from searching rounds (i.e. $\len(Y_j) > 10L\cdot \eta_0$). The learner searches from scratch when starting from initialization ($Y_j$ is set to $[0, L]$ at initialization) or when she becomes surprised ($Y_j$ is reset to $[0, L]$). This can happen at most $C + \eta_0^{-d}$ times, since the learner becomes surprised at most $C$ times (Lemma~\ref{lemma:surprised}) and there are $\eta_0^{-d}$ hypercubes at initialization.  Whenever the learner searches from scratch, it takes $O(\log T)$ queries before the interval becomes pricing-ready. Thus the total loss incurred from search queries is 
    \begin{align}
    L \cdot ( (C + \eta_0^{-d}) \log T). 
    \end{align}

    Next, the loss incurred when range becomes pricing-ready can be separated into two parts, loss from agnostic check queries and loss from pricing rounds. %that records the number of queries occurred in pricing-ready intervals before the learner becomes surprised or the algorithm terminates. 
    The total loss from agnostic check queries can be bounded by
    \begin{align}
    L\cdot O ( T / \tau_0 ), 
    \end{align}
    since there can be $O(T/\tau_0)$ agnostic check queries, and each query contribute loss at most $L$. 
    
    From Lemma~\ref{lemma:pricingLoss}, the total loss from pricing rounds can be bounded by
    \begin{align}
    L\cdot O\left( \sum_{\xi \in \cC} \xi \cdot \tau_0 + \sum_{\tau\in \cT} \tau \cdot \eta_0 \right) &\le L\cdot O( C \tau_0 +  T \eta_0 ). 
    \end{align}

    Putting everything together, the total loss can be bounded by the sum of loss incurred during agnostic checking rounds, pricing rounds, and searching rounds:
    \[
    L\cdot {O}\left( T / \tau_0 + C\tau_0 + T\eta_0 + \eta_0^{-d} \log T + C\log T \right). 
    \]
    Plugging the choice of parameter $\eta_0 = T^{-1/(d+1)}$ finishes the proof. 
\end{proof}


% \begin{theorem}
% Pricing loss $O(LT^{d/(d+1)} + C\log T)$. 
% \end{theorem}
% \begin{proof}
% Corrupted interval contribute $O(C\log T)$ loss. Amending interval contribute $O(C\log T)$ loss. 

% In safe intervals, the learner queries the lower end of $Y_j$ once the length of $Y_j$ drops below the threshold $\eta = ...$. Such queries contribute loss at most $O(T\eta) = ...$. 

% In safe intervals, the learner incurs regret $O(1)$ for all queries incurring in each interval (as opposed to $O(2^{-h})$ f or the symmetric loss) when the length has not reached the threshold $\eta$. Such intervals have depth $O(\log(1/\eta))$, and there are at most $O((8L)^d 2^{d\log(1/\eta)}) = O((LT)^{d/(d+1)})$. 
% \end{proof}
