

\subsection{Absolute Loss with $d > 1$}
\label[appendix]{app:sym-highd}



\begin{algorithm2e}
\caption{Learning with corrupted binary signal under absolute loss for $d > 1$}
\label{algo:highDsymm}
Learner maintains a partition of hypercubes $I_j$ of the input space $[0,1]^d$ throughout learning process\;
For each hypercube $I_j$, learner stores a checking interval $S_j$ and maintains an associated range $Y_j$\;
The partition is initialized as a single hypercube with checking interval $S_j$ set to $[0, 8L]$\;
\For {$t = 1, 2, ..., T$} {
    Learner receives context $x_t$\;
    Learner finds hypercube $I_j$ such that $x_t \in I_j$\;
    Let $Y_j$ be the feasible interval of $I_j$\;
    \If {Exists an endpoint of $S_j$ not queried} {%\label{algo:queryendpt_beg}
        Query an unqueried endpoint of $S_j$\;
        \If {Queried $\min(S_j)$ and $\sigma_t = 1$, or queried $\max(S_j)$ and $\sigma_t = 0$} {
        Mark $I_j$ as dubious\;%
        %\Comment{Contamination found in the current interval}
        }
        \If {Both endpoints of $S_j$ have been queried}{
            \If {$I_j$ marked dubious}{
                Set range $Y_j := [0, 8L]$\;\label{algoline:highd_marked_rangeset}
            }
            \Else{
                Set range $Y_j = [\min(S_j) - L\cdot \len(I_j)), \max(S_j) + L\cdot \len(I_j))] \cap [0,1]$\; \label{algoline:highd_unmarked_rangeset}
            }
        }
    }%\label{algo:queryendpt_end}
    \Else {%{$I_t$ not marked unsafe} \label{algo:notmarked_beg}
         $Y_j := \algmq(I_j, Y_j)$\;
        \If { $\len(Y_j) < \max (4 L\cdot \len(I_j), 4L / T )$ } { %\Comment{associated range $Y_j$ has shrunk enough}
            Bisect each side of $I_j$ to form $2^d$ new hypercubes each with length $\len(I_j) / 2$\;
            For each new hypercube $I_{ji}$ ($1\le i \le 2^d$) set $S_{ji} = Y_j$\;
        } %\label{algo:notmarked_end}
    %\Else \Comment{$I_t$ is marked dishonest} \label{algo:dishonest_begin}
        %\State Start from scratch until converge, takes $\log T$ steps \label{algo:test}
        
        %\State Let $\set{[], [], []}$ be the sequence of feasible region (endpoints? ) on the path to $I_t$. 
        %\State Perform binary search on this path and find the first interval [] that contains $f(I_t)$. \Comment{Takes $\log\log T$ steps}, set feasible region $I_t = []$
        %\State From this point perform binary search and shrink feasible region \Comment{Takes $c$ steps, where $c$ is number of corruptions before reaching a correction interval? }
    } %\label{algo:dishonest_end}
}
\end{algorithm2e}

The corruption-robust algorithm for learning a Lipschitz function from $\cR^d \rightarrow \cR (d > 1)$ under absolute loss is summarized in~\Cref{algo:highDsymm}. The proposed algorithm initializes the input space as a single hypercube with $S_j$ initialized to $[0, 8L]$ (instead of $8^d$ hypercubes with $S_j$ initialized as $[0,L]$). The two initializations are essentially equivalent but the former slightly simplifies analysis somewhat: there is now only a single root hypercube. %This is purely for ease of exposition: the number of hypercubes at depth $h$ is simplified from $8^d \cdot O(2^{hd})$ to $O(2^{hd})$. \szcomment{TODO here}
%The analysis makes the assumption that $L = 1/8$, so that there is exactly one root interval (line?? in algorithm ??). If $L < 1/8$, the learner can simply scale range of 

% \begin{theorem}[\Cref{thm:symmMD} restated]
% \Cref{algo:highDsymm} achieves cumulative absolute loss $L\cdot O(T^{\nicefrac{(d-1)}{d}} + C\cdot \log T + C\cdot 2^d)$ for $d \ge 2$. 
% \end{theorem}
\thmsymmMD*
The analysis will be similar to that of~\Cref{algo:1dabsolute} and~\Cref{thm:symm1D}. 

\begin{proof}
There are $O(C)$ corrupted intervals, contributing $L\cdot O(C\log T)$ loss. There are $O(C\cdot 2^d)$ correcting intervals, contributing $ L\cdot O( C\cdot 2^d)$ loss. For safe intervals, there are at most $O(2^{hd})$ intervals at depth $h$. Throughout $T$ rounds, a loss with magnitude $L\cdot O(2^{-h})$ can be charged at most $O(2^{hd})$ times, and the total loss of all safe intervals is then at most $L\cdot O(T^{(d-1) / d})$, since the loss coming from safe intervals can be upper bounded by
\begin{align*}
    L\cdot \sum_{h=0}^{\frac{\log T}{d}} O( 2^{(d-1)h} ) = L\cdot O(T^{{(d-1)}/{d}}). 
\end{align*}
Putting the loss of all three types of intervals, the total loss is
\[
L\cdot O(C\log T + C\cdot 2^d + T^{(d-1)/{d}}) = L\cdot O_d(C\log T + T^{(d-1)/d}),
\]
which completes the proof. 
\end{proof}
