%\iffalse
\documentclass[11pt]{article}
\usepackage[margin=1in, top = 0.85in, letterpaper]{geometry}
\usepackage{lineno}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\linenumbers


\makeatletter
\def\thm@space@setup{\thm@preskip=0pt
\thm@postskip=0pt}
\makeatother
\newtheoremstyle{newstyle}      
{} %Aboveskip 
{} %Below skip
{\mdseries} %Body font e.g.\mdseries,\bfseries,\scshape,\itshape
{} %Indent
{\bfseries} %Head font e.g.\bfseries,\scshape,\itshape
{.} %Punctuation afer theorem header
{ } %Space after theorem header
{} %Heading

\theoremstyle{newstyle}
\newtheorem{thm}{Theorem}[]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}

\makeatletter
\newenvironment{pf}[1][\proofname]{\par
  \pushQED{\qed}%
  \normalfont \topsep0\p@\relax
  \trivlist
  \item[\hskip\labelsep\itshape
  #1\@addpunct{.}]\ignorespaces
}{%
  \popQED\endtrivlist\@endpefalse
}
\makeatother

\begin{document}

\noindent I thank all reviewers for the very insightful comments! I first give two lower bounds for pricing loss, showing the upper bounds (Thm 13, Cor 15) are essentially tight. Then I address more specific questions from reviewers. %Also, all reviewers noticed that in Alg 1, the else block containing MidPointQuery in fact should have one less indent, so this block is executed when both endpoints have been queried. %All reviewer's comments will be considered when updating the paper. 

%Due to space constraints, I cannot respond to all, but I believe I responded to the most important comments that will (positively) change your opinion. 

\noindent\textbf{Lower Bound}
In the following assume $L=1$. The first lower bound essentially shows it is impossible to achieve a bound of the form $O(T^{d/(d+1)}) + C\cdot o(T^{1/(d+1)})$ when $C$ is unknown. 

\vspace{0.02in}
\begin{thm}
Let $A$ be any algorithm to which the corruption budget $C$ is unknown. Suppose $A$ achieves a cumulative pricing loss $R(T) = o(T)$ when $C = 0$. Then, there exists some corruption strategy with $C = 2R(T)$, such that the algorithm suffers $\Omega(T)$ regret. 
\end{thm}
\begin{pf}
Let us consider two environments. In the first environment, the adversary chooses $f(x)\equiv 0.5$ and never corrupts the signal. In the second environment, the adversary chooses $f(x)\equiv1$ and corrupts the signal whenever the query is above 0.5. Now since the algorithm achieves regret $R(T)$ when $C=0$, then, when $f(x) = 0.5$, the seller can only query values above $0.5$ for at most $2R(T)$ times. However, by choosing $C = 2R(T)$, the adversary can make the two environments indistinguishable from the seller. Hence the seller necessarily incurs $\Omega(T)$ regret. 
\end{pf}

%effectively manipulating the seller into believing the true price is 0.5. 

Next, we will prove a lower bound against randomized adversary when corruption budget $C$ is known. Define an environment as the tuple $(f, C, \cS)$, representing the function, corruption budget, and corruption strategy respectively. The adversary draws an environment from some probability distribution $\cD$, and the corruption budget is defined as the expected value of $C$ under distribution $\cD$. Note that the upper bounds (Thm 13, Cor 15) also hold for randomized adversaries. 
\vspace{0.02in}
\begin{thm}
There exists some $\cD$ where any algorithm incurs expected regret $\Omega(\sqrt{CT})$. 
\end{thm}
\begin{pf}
The adversary uses two environments $\cE_{\{1,2\}}$. In $\cE_1$, the function $f(x) \equiv 0.5$ and the corruption budget is 0. In $\cE_2$, the function $f(x) \equiv 1$, the corruption budget is $C_0$, and the adversary corrupts any query above 0.5 until the budget is depleted. The adversary chooses the first environment with probability $1-p$ and the second environment with probability $p$. If the learner's algorithm queried more than $C_0$ rounds above $0.5$, then the learner incurs regret $0.5C_0$ in $\cE_1$, giving expected regret $\Omega((1-p) C_0)$. If the algorithm did not query more than $C_0$ rounds above $0.5$, then the algorithm incurs regret $0.5(T - C_0)$ in $\cE_2$, giving expected regret $\Omega((T-C_0)p)$. Choosing $p = \sqrt{C/T}, C_0 = \sqrt{CT}$ completes the proof. 
% Consider the following corruption strategy. The space is discretized into $\sqrt{T/C}$ hypercubes of equal length. The context that the adversary selects will be the center of each hypercube, and the value at each context will be 0.5 except for one context which has value $0.5 + \eps$. Each hypercube will be selected by the adversary for $\sqrt{CT}$ rounds. The adversary will corrupt the first $C$ queries in the hypercube which has value $0.5+\eps$. At a high level, the learner can only detect the hypercube with value $0.5 + \eps$ if he performs checking rounds in every hypercube for at least $C$ rounds. Alternatively, if the learner does not perform checking query, he will incur regret $\eps \sqrt{CT}$. 
% Can we choose there to be $1/\eps = \sqrt{T/C}^{1/d}$ hypercubes that has value $0.5+\eps$? 
\end{pf}


\noindent\textbf{Reviewer 1.} The idea is indeed natural and simple, but the analysis is non-trivial and quite interesting. In the proof for absolute loss in App A, Lemma 17,18 (on MidpointQuery), Lemma 25 and part of proof in Thm 1 (on regret of safe intervals) are borrowed from Mao et. al. The introduction of the three types of intervals and Lemma 19-24 (on various properties of the three types) are entirely new. The analysis for pricing loss is also entirely new (Sec 4.2, App B). Sec 4.1 is adapted from Mao et. al. but leaves out the bisection part as it starts with a uniform discretization. I will add more careful remarks pointing out which results are from previous work. Krishnamurthy et. al. and Leme et. al. study corruption-robust linear contextual search. Their methods are respectively: maintain a knowledge set that contains the true unknown parameter $\theta$; maintain a density over the parameter space. By contrast, our setting is non-parametric and our method is fundamentally different. The different initialization for $d> 1$ does not change the final regret bound, it just makes writing some steps in the proof slightly easier (last sentence in App A.2). For Thm 27, this is because a hypercube at depth $h$ incur loss $2^{-h}$. 

\noindent\textbf{Reviewer 2.} I believe your main concerns are addressed in the lower bound above. For Alg 1, the final else block indeed should have one less indent. 

\noindent\textbf{Reviewer 3.} Indeed, the best the learner can say is that safe intervals are not marked \emph{unsafe}, but not all corrupted or correcting intervals will be marked \emph{unsafe}. Maybe \emph{surprising} is a good choice (also consistent with Sec 4 for pricing). The else block containing MidPointQuery in fact should have one less indent, so this block is executed when both endpoints have been queried. For your final observation, I believe a form of soft-checking with a weight-update may be a suitable solution. 



%Specifically, this means when the first context arrives in some interval, the learner queries an endpoint of $S_j$ (say the higher endpoint); and later in a subsequent round when a context arrives in this interval, the learner queries the other endpoint. 

\end{document}

%\fi