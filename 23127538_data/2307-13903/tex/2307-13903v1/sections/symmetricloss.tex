\section{Algorithm for Symmetric Loss}
\label{sec:symmetric}

This section gives a corruption-robust algorithm for the symmetric loss, defined by
\[
\ell(q_t, f(x_t)) = \abs{f(x_t) - q_t}. 
\] 
I will first design an algorithm for $d = 1$ in this section (\cref{algo:1dabsolute}), then extend the algorithm to $d \ge 2$. 

\begin{algorithm}[h]
\caption{Learning with corrupted binary signals under symmetric loss for $d=1$}
\label{algo:1dabsolute}
\begin{algorithmic}[1]
\State Learner maintains a partition of intervals $I_j$ of the input space throughout learning process
\State For each interval $I_j$ in the partition, learner stores a sanity check interval $S_j$, and maintains an associated range $Y_j$
\State The partition is initialized as $8$ intervals $I_j$ with length $1/8$ each, and each $I_j$ has associated range $Y_j$ and sanity check interval $S_j$ set to $[0,L]$
\For {round $t = 1, 2, ..., T$}
    \State Learner receives context $x_t$
    \State Learner finds interval $I_j$ such that $x_t \in I_j$
    \State Let $Y_j$ be the associated range of $I_j$
    \If {Exists an endpoint of $S_j$ not yet queried} %\label{algo:queryendpt_beg}
        \State Learner selects an unqueried endpoint of $S_j$ as guess
        \If {Learner guessed $\min(S_j)$ and $\sigma_t = 1$, or guessed $\max(S_j)$ and $\sigma_t = 0$} 
        \State Mark $I_j$ as unsafe \Comment{Contamination found in the current interval}
        \EndIf
        \If {Both endpoints of sanity check interval $S_j$ have been queried}
            \If {$I_j$ marked unsafe}
                \State Set range $Y_j := [0,L]$ \label{algoline:marked_rangeset}
            \Else
                \State Set range $Y_j = [\min(S_j) - L\cdot \len(I_j)), \max(S_j) + L\cdot \len(I_j))] \cap [0,L]$ \label{algoline:unmarked_rangeset}
            \EndIf
        \EndIf %\label{algo:queryendpt_end}
    \Else %{$I_t$ not marked unsafe} \label{algo:notmarked_beg}
        \State $Y_j := \algmq(I_j, Y_j)$
        \If { $\len(Y_j) < \max( 4 L\cdot \len(I_j), 4 L / T )$ }  \LineComment{Check if associated range $Y_j$ has shrunk enough}
            \State Bisect $I_j$ into $I_{j1}, I_{j2}$, set $S_{j1} = Y_j, S_{j2} = Y_j$ 
        \EndIf %\label{algo:notmarked_end}
    %\Else \Comment{$I_t$ is marked dishonest} \label{algo:dishonest_begin}
        %\State Start from scratch until converge, takes $\log T$ steps \label{algo:test}
        
        %\State Let $\set{[], [], []}$ be the sequence of feasible region (endpoints? ) on the path to $I_t$. 
        %\State Perform binary search on this path and find the first interval [] that contains $f(I_t)$. \Comment{Takes $\log\log T$ steps}, set feasible region $I_t = []$
        %\State From this point perform binary search and shrink feasible region \Comment{Takes $c$ steps, where $c$ is number of corruptions before reaching a correction interval? }
    \EndIf %\label{algo:dishonest_end}
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
\caption{Midpoint query procedure: $\algmq(I_j, Y_j)$}
\label{algo:midpt_query}
\begin{algorithmic}
    \State Input: $I_j, Y_j$
    \State Let $q$ be midpoint of $Y_j$
    \State Learner queries $q$
    \If {$\sigma_t$ = 1}
        % \State Set $Y'_j := [\min(Y_j), q_t + L\cdot\len(I_j)]$
        \State Set $Y'_j := [0, q_t + L\cdot\len(I_j)] \cap Y_j$
        \szcomment{This and above should be equivalent}
    \Else
        % \State Set $Y'_j := [q_t - L\cdot\len(I_j), \max(Y_j)]$
        \State Set $Y'_j := [q_t - L\cdot\len(I_j), 1] \cap Y_j$
        \szcomment{This and above should be equivalent}
    \EndIf
    \State Return $Y'_j$
\end{algorithmic}
\end{algorithm}

\subsection{Algorithm for $C=0$}

It will be helpful to first give a brief description of an algorithm that appeared in~\cite{mao2018contextual}. This algorithm works when there are no adversarial corruptions and is able to achieve $L\cdot O(\log T)$ loss. At each point in time, the learner maintains a partition of the input space into intervals. For each interval $I_j$ in the partition, the learner also maintains an associated range $Y_j$, which serves as an estimate of the image of $I_j$. In particular, the algorithm ensures the following is true: $f(I_j)\in Y_j, \len(Y_j) = L\cdot O(\len(I_j))$. When a context appears in $I_j$, the learner selects the midpoint of $Y_j$ as the query point, and the associated range $Y_j$ shrinks and gets refined over time. When $Y_j$ reaches a point where significant refinement is no longer possible, the learner zooms in on $I_j$ by bisecting it. This corresponds roughly to the subprocedure summarized in~\cref{algo:midpt_query}, which is termed the midpoint query procedure $\algmq$. The midpoint query procedure shall be used as a subprocedure in the corruption-robust algorithms that this work proposes. 

\subsection{Corruption-Robust Search with Sanity Checks}

The main algorithm for symmetric loss is summarized in~\cref{algo:1dabsolute}. This algorithm is corruption-robust and agnostic to the corruption level $C$. Below I give the key ideas in this algorithm. 

When there are adversarial corruptions, it will generally be impossible to tell for certain whether the associated range $Y_j$ contains the image of the interval $I_j$. That is, the learner will not know with complete certainty whether $f(I_j) \in Y_j$ holds. The analysis divides intervals into three types: \textit{safe intervals}, \textit{amending intervals}, and \textit{corrupted intervals}. An interval is a \textit{corrupted interval} if any query within the interval gave a corrupted signal. An interval is an \textit{amending interval} if its parent interval is corrupted and any query within the interval gave uncorrupted signals. An interval is a \textit{safe interval} if its parent interval is safe or amending, and any query within the interval gave uncorrupted intervals. A root interval with no corruption is also \textit{safe}. 

To combat adversarial corruptions, I introduce the \textit{sanity check} measure. Consider a new interval $I_j$ that has been formed by bisecting its parent interval, and that a context $x_t$ appears in this interval $I_j$. The learner will first query the two endpoints of $Y_j$ and test whether $f(I_j)\in Y_j$ holds (according to the possibly corrupted signals). The interval passes the sanity check if according to the (possibly corrupted) signals $f(I_j) \in Y_j$. If the interval does not pass the sanity check, it is marked as \emph{unsafe}, and the learner resets $Y_j$ to $[0, L]$ and effectively searches from scratch for the associated range. 

The algorithm guarantees the following.
\begin{itemize}
    \item Any interval marked \emph{unsafe} bisects in $O(\log T)$ rounds, any interval not marked \emph{unsafe} bisects in $O(1)$ rounds. 
    \item Any \emph{safe} interval passes the sanity check (i.e. not marked \emph{unsafe}), thus there is no need to search from scratch and the interval incurs small regret. Specifically, any \emph{safe} interval at depth $h$ incurs regret $O(2^{-h})$. 
    \item At the end of any \emph{amending} interval, $f(I_j) \in Y_j$; that is, the amending interval finds the correct associated range, despite corruptions in its parent interval. 
\end{itemize}

The main theorem is stated below. 

\begin{theorem}
\label{thm:symm1D}
\Cref{algo:1dabsolute} incurs $L\cdot O(C \cdot \log T)$ cumulative symmetric loss for $d = 1$. 
\end{theorem}

\begin{remark}
The regret is tight up to $\log T$ factors. To see this, consider the first $C$ rounds, where the adversary corrupts the signal with probability $1/2$ each round. The learner essentially receives no information during this period, and each round incurs regret $\Omega(L)$. 
\end{remark}

% A detailed analysis appears in~\cref{app:proof1d}. The main components of the proof include the following. 
% \begin{enumerate}
%     \item Since any corrupted interval is bisected in $O(\log T)$ rounds, the total loss from corrupted interval can be bounded as $O(C\log T)$. 
%     \item There are at most $O(C)$ amending intervals, and each amending interval contribute $O(1)$ loss. 
%     \item A safe internval at depth $h$ contribute loss $O(2^{-h})$. There are at most $O(2^h)$ intervals at depth $h$, hence a loss with $O(2^{-h})$ can be charged at most $O(2^h)$ times. 
% \end{enumerate}


\begin{remark}
    While it is possible for corrupted intervals to pass the sanity check, it does not affect the analysis. Further, even though the analysis makes use of the three types of intervals, interestingly enough the learner has no complete knowledge of the type of each interval encountered during the run of the algorithm, even after the algorithm terminates. 
\end{remark}

\begin{remark}
If the range of $f$ is replaced by $[0,1]$ as in~\cite{mao2018contextual}, then the algorithm gives a loss bound $O(C\log T + L\log T)$. 
\end{remark}




% If the signal at these two endpoints tells the learner $f(I_j) \notin Y_j$, then the learner will know either the signal at these two endpoints are corrupted, or that corruptions in its parent interval lead to an inaccurate $Y_j$ that failed to contain the image of $I_j$. In either case, the learner marks the interval $I_j$ as an unsafe interval, resets the associated range $Y_j$ to $[0,1]$, and thus effectively start from scratch and searches for the associated range $Y_j$ of the interval $I_j$. 

% If the signal at these two endpoints tells the learner that $Y_j$ is indeed an accurate upper bound for $f(I_j)$, then the interval is not marked unsafe. However, it should be noted that, even if the interval is not marked unsafe, the learner still cannot necessarily ensure that $Y_j$ contains the image $f(I_j)$, since the signal at these two endpoints may be corrupted. The learner has no way of verifying whether the feedback was accurate, and will act as if $Y_j$ is indeed an upper bound on the image of $f(I_j)$, and apply the midpoint querying strategy to refine the estimate $Y_j$. If $Y_j$ was indeed an accurate upper bound on the $f(I_j)$ and signals on the interval $I_j$ were accurate, then the learner will incur small loss on this interval. Otherwise if $Y_j$ was not an accurate upper bound on $f(I_j)$, then it must mean that the signal when querying the endpoints were corrupted, and hence the learner will incur regret as a consequence of the corrupted signals. However we shall see that the total loss incured as a result of the corrupted signals can be bounded above by $\tilde{O}(C)$, where recall $C$ is the number of corruptions. 

%The learner starts with a coarse partition of the input space into intervals, and for each interval $I_j$ maintains a interval $Y_j$ that contains the image of this interval. As the feasible interval $Y_j$ shrinks enough, the interval $I_j$ is split in half, thus allowing for finer estimates of the image of the child intervals. 


% \subsection{Analysis}
% A detailed analysis of algorithm~\cref{algo:1dabsolute} is given. Some definitions are first introduced that will be helpful in the analysis. 

% \begin{definition}[Depth]
%     The intervals at initialization has depth 1, and each interval has depth increased by 1 when split. 
% \end{definition}
% The depth of an interval measures how many splits happened before reaching the current interval. 

% Next, three types of intervals are introduced. 
% \begin{definition}[Corrupted Interval]
%     An interval is called a corrupted interval if any round inside the interval is corrupted. 
% \end{definition}

% \begin{definition}[Correcting Interval]
%     An interval is called a correcting interval if any round inside the interval is uncorrupted and the parent interval is corrupted. 
% \end{definition}

% \begin{definition}[Honest Interval]
%     An interval is called a honest interval if any round inside the interval is uncorrupted and the parent interval is either a correction interval or a honest interval. As a special case, intervals at depth 1 are honest if they are not a corrupted interval. 
% \end{definition}

% It can be seen that these three types of intervals are disjoint, and their union is the set of all intervals reached by the learner in the learning process. 

% We begin with the following lemmas. 

% \begin{restatable}{lemma}{markedAreNotHonest}
%     If interval marked dishonest, then must be correcting or corrupted. 
% \end{restatable}

% \begin{restatable}{lemma}{markedSplits}
%     If an interval marked dishonest, then splits in $O(\log T)$ rounds. If interval not marked dishonest, then splits in $O(1)$ rounds. 
% \end{restatable}

% \begin{restatable}{lemma}{correctionCorrects}
%     Let $I_j$ be a correction interval and $Y_j$ be its feasible interval before $I_j$ is split. Then $f(I_j) \in Y_j$. 
% \end{restatable}

% \begin{restatable}{lemma}{corruptedLoss}
%     Corrupted interval contribute $O(C \log T)$ loss. 
% \end{restatable}

% \begin{restatable}{lemma}{correctingLoss}
%     Correcting interval contribute $O(C)$ loss. 
% \end{restatable}


% \begin{restatable}{lemma}{honestLoss}
% Consider an honest interval in depth $h$. This interval is split within $O(1)$ rounds, and each round incur $O(2^{-h})$ regret. 
% \end{restatable}


\szcomment{Optimal 1d lipschitz? }
\szcomment{1/2, 1/2, 3/4, 3/4, 15/16, 15/16, 35/32, 35/32, 315/256}

\subsection{Extending to $d > 1$}
\Cref{algo:1dabsolute} can be extended in a straightforward way to accommodate the case $d > 1$. The full algorithm and analysis is given in~\cref{app:sym-highd}. The only difference is that the learner maintains $d$-dimensional hypercubes instead of intervals. The main theoretical result is as follows. 
\begin{theorem}
\label{thm:symmMD}
    There exists an algorithm that incurs $L\cdot O_d(C\log T +  T^{(d-1) / d)})$ cumulative symmetric loss for $d\ge 2$. 
\end{theorem}

\begin{remark}
In~\cite{mao2018contextual}, it was shown the optimal regret when $C=0$ is $\Omega(T^{(d-1)/(d)})$. Hence, the dependence on $C$ and $T$ are both optimal in the above theorem (up to $\log T$ factors). 
\end{remark}
