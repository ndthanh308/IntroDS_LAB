\section{Algorithm for Pricing Loss}
\label{sec:pricing}

\begin{algorithm}[h]
\caption{Learning with corrupted binary signal under pricing loss with uniform discretization}
\label{algo:pricing}
\begin{algorithmic}[1]
\State Set parameter $\eta_0 = T^{-1/(d+1)}$, sanity check schedule $\tau_0$
\State Learner uniformly discretizes input space into hypercubes with lengths no larger than $\eta_0$ each
\State For each hypercube $I_j$, learner maintains an associated range $Y_j$ (initialized as $[0, L]$), query count $c_j$ (initialized as $0$)
% \State Set $\eta = 10 L \cdot T^{1/(d+1)}$
\For {round $t = 1, 2, ..., T$}
    \State Learner receives context $x_t$
    \State Learner finds hypercube $I_j$ such that $x_t \in I_j$
    \State Let $Y_j$ be the associated range of $I_j$
    \If {$\len (Y_j) < 10 L \cdot \eta$} \Comment{The interval is pricing-ready}
        \State $c_j := c_j + 1$
        \If { $c_j > \tau_0$ } 
            \State Query $\max(Y_j)$
            \State Set $c_j := 0$
        \Else 
            \State Query $\min(Y_j)$
        \EndIf
        \If {Learner is surprised} \LineComment{Learner is surprised if queried $\max(Y_j)$ and $\sigma_t = 0$, or queried $\min(Y_j)$ and $\sigma_t = 1$}
            \State Set $Y_j := [0,L]$ \Comment{Reset the range of $Y_j$}
            \State Set $c_j := 0$
        \EndIf
    % \ElsIf {Exists an endpoint in $S_j$ not queried} %\label{algo:queryendpt_beg}
    %     \State Query an unqueried endpoint of $S_j$
    %     \If {Queried $\min(S_j)$ and $\sigma_t = 1$, or queried $\max(S_j)$ and $\sigma_t = 0$} 
    %     \State Mark $I_j$ as unsafe \Comment{Contamination found in the current interval}
    %     \EndIf
    %     \If {Both endpoints of $S_j$ have been queried}
    %         \If {$I_j$ marked unsafe}
    %             \State Set range $Y_j := [0,1]$ \label{algoline:marked_rangeset}
    %         \Else
    %             \State Set range $Y_j = [\min(S_j) - L\cdot \len(I_j)), \max(S_j) + L\cdot \len(I_j))] \cap [0,1]$ \label{algoline:unmarked_rangeset}
    %         \EndIf
    %     \EndIf %\label{algo:queryendpt_end}
    \Else %{$I_t$ not marked unsafe} \label{algo:notmarked_beg}
        \State $Y_j := \algmq(I_j, Y_j)$
        % \If { $\len(Y_j) < 4 L\cdot \len(I_j)$}  \Comment{associated range $Y_j$ has shrunk enough}
        %     \State Bisect each side of $I_j$ to form $2^d$ new hypercubes, each with length $...$
        % \EndIf %\label{algo:notmarked_end}
    \EndIf
    %\Else \Comment{$I_t$ is marked dishonest} \label{algo:dishonest_begin}
        %\State Start from scratch until converge, takes $\log T$ steps \label{algo:test}
        
        %\State Let $\set{[], [], []}$ be the sequence of feasible region (endpoints? ) on the path to $I_t$. 
        %\State Perform binary search on this path and find the first interval [] that contains $f(I_t)$. \Comment{Takes $\log\log T$ steps}, set feasible region $I_t = []$
        %\State From this point perform binary search and shrink feasible region \Comment{Takes $c$ steps, where $c$ is number of corruptions before reaching a correction interval? }
    %\EndIf %\label{algo:dishonest_end}
\EndFor
\end{algorithmic}
\end{algorithm}


This section discusses the new ideas needed to design corruption-robust algorithm for the pricing loss. The description shall be given in the context of dynamic pricing, and the learner shall be referred to as the seller in this section. The main algorithm is summarized in~\cref{algo:pricing}. Note that for the pricing loss, the case with $d =1$ and $d > 1$ are treated together. 

Extending~\cref{algo:1dabsolute} for the symmetric loss to pricing loss is not straightforward, since sanity checks will overprice and the seller necessarily incurs a large loss whenever she overprices. The learner did not have this problem with symmetric loss, since the symmetric loss is continuous. 

\subsection{Algorithm for $C = 0$}
I first give the description of an algorithm for $C = 0$. The algorithm starts with a uniform discretization of the input space into hypercubes with length $\eta_0 = T^{-1/(d+1)}$. The learner searches for the associated range $Y_j$ of a hypercube using the midpoint query procedure $\algmq$ (these shall be termed \emph{searching rounds} or \emph{searching queries}) and stops the search process when the associated range $Y_j$ becomes small enough (specifically, when the length of $Y_j$ drops below $10L\cdot \eta_0$). The hypercube is said to become \emph{pricing-ready} when this happens. When there are no adversarial corruptions, the learner now has a good estimate of the optimal price and sets the lower end of $Y_j$ as the price for any context in this hypercube. These shall be termed \emph{pricing rounds}. At \emph{pricing rounds}, the seller expects the buyer to purchase the item, and assuming the range $Y_j$ is accurate (which is the case when $C = 0$), the revenue loss should be no larger than $10 L \cdot \eta$. The total loss from \emph{pricing rounds} can be bounded by $L\cdot O(T\cdot \eta_0)$. The total loss from searching rounds can be bounded by $L\cdot  \widetilde{O}(\eta_0^{-d})$ since there are $O(\eta_0^{-d})$ hypercubes, and for each hypercube, there can be at most $O(\log T)$ queries before the hypercube becomes \emph{pricing-ready}. By the choice of parameter $\eta_0 = T^{-1/(d+1)}$, the regret bound is $L\cdot \widetilde{O} (T^{d/(d+1)})$. 

It should be noted that the above algorithm is similar to the algorithm for pricing loss that appeared in~\cite{mao2018contextual}. Indeed, the above algorithm uses uniform discretization, whereas the algorithm in~\cite{mao2018contextual} used adaptive discretization. Though using adaptive discretization improves the regret bound by a $O(\log T)$ factor, the presentation for the corruption-robust algorithm for pricing loss is based on uniform discretization, as it highlights the new algorithmic ideas more clearly. Nevertheless, the algorithm can be combined with adaptive discretization by using ideas from the previous section. 

\szcomment{TODO. Compare with adaptive discretization. }\szcomment{DONE}

\subsection{Corruption-Robust Pricing using a Sanity Check Schedule}

The seller could potentially run into issues when there are adversarial corruptions. The adversary can manipulate the seller into underpricing by a large margin by only corrupting a small number of signals. Consider the following example. The buyer is willing to pay $0.5$ for an item with context $x$. The adversary can manipulate the signals in the $\algmq$ procedure so that the seller's associated range for $x$ is $[0, 10L\cdot \eta]$, which does not contain and is well below the optimal price $0.5$ for this item. The seller then posts a price of $0$ for item $x$. Even though the buyer purchases the item at a price of $0$, the seller is losing 0.5 revenue per round, and this happens without the adversary corrupting any pricing rounds. \szcomment{TODO, rephrase}

\szcomment{ $Y_j$ is not a valid pricing range, and even though she prices the item at the lower end of $Y_j$ and the buyer is purchasing the item, the true valuation could be much higher and the seller is losing a large amount of revenue. }

To combat adversarial corruptions, the learner performs sanity check queries. These queries differ from sanity checks for the symmetric loss in the following two aspects. First, whereas for the symmetric loss, the learner performs sanity check queries on both ends of the associated range $Y_j$, for the pricing loss the seller only performs sanity check on the upper end of $Y_j$. This ensures the seller is not underpricing the product by a large margin. Second, the seller only performs sanity check queries when the hypercube becomes \emph{pricing-ready}. The seller expects the buyer not the purchase the item during sanity check queries. 

I introduce a new notion termed the \emph{sanity check schedule}. At a high level, performing sanity checks too often incur large regret from overpricing, while performing sanity checks too few may not detect corruptions effectively. The sanity check schedule serves as a mean to balance the two. This schedule informs the learner how often to perform sanity check so as not to incur large regret when overpricing, and at the same time control the loss incurred from corrupted signals. Specifically, the learner keeps track of how many rounds the context vectors arrived in each hypercube. The learner then performs a sanity check every $\tau_0$ rounds. Here, $\tau_0$ will be a paramter to be chosen later. 

\szdelete{\begin{definition}[Sanity Check Schedule, Discrete]
Let $g$ be an increasing function $\bbZ^+ \rightarrow \bbZ^+$. Further suppose $g(0) = 0, g(1) \ge 1, g(x+1) - g(x) \ge g(x) - g(x-1)$ and $g(x+1) < 10g(x)$ for $x \ge 1$. Then $g$ is said to be a valid sanity check schedule. 
\end{definition}}
\szcomment{Remove this as a definition, this might cause confusion. Only do a formal definition in continuous case. }


\szcomment{ The function $g$ then specifies which rounds to perform sanity check: the $i$-th sanity check should be performed at round $g(i)$. In the asymptotic sense, it would be easier to work with a continuous version of $g$ with an explicit form that captures more succinctly the growth rate of $g$. }

\szdelete{
\begin{definition}[Sanity Check Schedule, Continuous]
Let $g$ be an increasing function $\bbR^+ \rightarrow \bbR^+$. Further suppose $g(0) = 0$, $g(1) \ge 1$ and that $g$ is convex with $g(x+1) < 10 g(x)$ for all $x\ge 1$. Then $g$ is said to be a valid sanity check schedule. 
\end{definition}
In the continuous version, the learner will perform sanity checks at time steps $\set{\floor {g(i)}, i \in \bbZ^+}$. 
}

The seller is said to become \emph{surprised} when the signal she receives is inconsistent with her current knowledge. Specifically, the seller becomes surprised when either: she performs a sanity check query but observes an underprice signal $(\sigma_t = 0)$; or she prices the product intending to sell it but observes an overprice signal $(\sigma_t = 1)$. The seller resets the associated range $Y_j$ and searches from scratch when she becomes \emph{surprised}. 

The algorithm guarantees the following: 
\begin{itemize}
    \item The seller becomes \emph{surprised} at most $C$ times. 
    \item There at are most $O(T / \tau_0)$ sanity check queries, contributing loss $L\cdot O(T / \tau_0)$. 
    \item The total loss from \emph{pricing rounds} can be bounded as $O(C\tau_0 + T\eta_0)$. 
    
    \szdelete{Consider a \emph{pricing-ready} hypercube that has been run for $\tau$ rounds before the seller became surprised or the algorithm terminates. Suppose a total of $\xi$ rounds were corrupted during this period. Then the total loss from pricing rounds during this period can be bounded as $O(\tau \eta_0 + \xi \tau_0)$. For more details of this statement, see~\cref{lemma:pricingLoss} in the appendix. }
\end{itemize}

The algorithm gives the following cumulative loss bound. A detailed analysis can be found in appendix~\cref{app:pricing}. 
\begin{theorem}
\label{thm:pricing}
Using~\cref{algo:pricing}, the learner incurs a total loss
\[
L\cdot \widetilde{O}( T/\tau_0 + C\tau_0 + T^{d/(d+1)}). 
\]
Specifically, setting $\tau = T^{1/(d+1)}$, the learner incurs total loss
\[
L\cdot \widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)} ). 
\]
\end{theorem}

\begin{remark}
The loss is sublinear as long as $C = o(T^{d/(d+1)})$. In~\cite{mao2018contextual}, it was shown the optimal regret is $\Omega(T^{d/(d+1)})$ for $C = 0$. Hence, the above theorem is optimal when $C = O(T^{ (d-1)/(d+1) })$. 
\end{remark}

If the asymptotic order of $C$ is known, the learner can set $\tau_0$ to balance the terms and achieve a sharper regret bound. 
\begin{cor}
Assume the asymptotic order of $C$ satisfies $C = O(g(T))$ and is known to the learner. Here, $g$ is some sublinear function. Using~\cref{algo:pricing} with $\tau_0 = \sqrt{T/g(T)}$, the learner incurs total loss
\[
L\cdot \widetilde{O} (T^{d/(d+1)} + \sqrt{TC}). 
\]
\end{cor}
\begin{remark}
When $C = O(T^{(d-1)/(d+1)})$, the loss simplifies to $L\cdot \widetilde{O} (T^{d/(d+1)})$. 
When $C = \Omega(T^{(d-1)/(d+1)})$, the loss simplifies to $L\cdot \widetilde{O} (\sqrt{TC})$. 
\end{remark}

