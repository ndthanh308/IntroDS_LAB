

\autoref{tab:datasets} shows the statistics of the datasets, including the number of attributes, classes within the attributes, and the total number of images. The difficulty increases as the number of attributes increases and for higher classes. These results can also be seen in the evaluation results of \autoref{tab:fashionAI}, \autoref{tab:DARN}, and \autoref{tab:DeepFashion}. 
% \autoref{fig:app2} in \autoref{sec:data_examples} presents examples of the four datasets.
% \vspace*{-10pt}
%
% \paragraph{FashionAI \cite{Zou2019FashionAIAH}}
% The data published in the FashionAI Global Challenge 2018 has 180,335 apparel images. This dataset comprises 8 fashion attributes containing 55 classes each. 
% %\footnote{https://tianchi.aliyun.com/competition/entrance/231671/introduction}
% \vspace*{-15pt}
% %
% \paragraph{DARN \cite{Huang01}} 
% An open dataset for attribute classification and street-to-shop image retrieval, comprising 253,983 images and 9 attributes. Each attribute contains 185 classes. The data is provided as image URLs; excluding broken URLs that cannot be downloaded, we used 195,771 URLs. 
% \vspace*{-15pt}
% %
% \paragraph{DeepFashion \cite{liu2016deepfashion}}
% This dataset comprises 289,222 images and 6 attributes. Each attribute contains 1000 classes. 
% \vspace*{-26pt}
% %
% \paragraph{Zappos50K \cite{Zappos}}
% This dataset comprises 50,025 shoe images collected from Zappos.com. It consists of 4 attributes containing 34 classes each.

\begin{table} [tb!]
%\tiny
\renewcommand{\arraystretch}{1.0}
\centering 
\resizebox{0.9\columnwidth}{!}{
\begin{tabular}{lccc}
\toprule
\textbf{DataSets} & \textbf{\#Attributes} & \textbf{\#Classes} & \textbf{\#Images} \\
\midrule
FashionAI \cite{Zou2019FashionAIAH} & 8 & 55 & 180,335\\
DARN \cite{Huang01} & 9 & 185 & 195,771 \\
DeepFashion \cite{liu2016deepfashion} & 6 & 1000 & 289,222\\
Zappos50k \cite{Zappos} & 4 & 34 & 50,025\\
\bottomrule
\end{tabular}
 }
 \vspace{-8pt}
 \caption{Statistics of the banchmark datasets.}
\label{tab:datasets}
\end{table}

\subsection{Metrics}
\label{sec:Metrics} 
For FashionAI, DARN, and DeepFashion, we used the experimental setting information of ASEN \cite{ma2020fine} and applied the mean average precision (mAP) metric for evaluation. For Zappos50K, we followed the experimental setting of CSN \cite{veit2017} and applied the triplet prediction metric for evaluation. This metric verifies the efficiency of attribute specific embedding learning for predicting triplet relationships.