\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{detr}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{imagenet21k}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, June 2019.

\bibitem{dong2021fine}
Jianfeng Dong, Zhe Ma, Xiaofeng Mao, Xun Yang, Yuan He, Richang Hong, and
  Shouling Ji.
\newblock Fine-grained fashion similarity prediction by attribute-specific
  embedding learning.
\newblock In {\em IEEE Transactions on Image Processing}, 2021.

\bibitem{DeViSE}
Andrea Frome, Greg Corrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean,
  Marc’Aurelio Ranzato, and Tomas Mikolov.
\newblock Devise: A deep visual-semantic embedding model.
\newblock In {\em NIPS}, 2013.

\bibitem{ResNet_He_2016_CVPR}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock {Deep Residual Learning for Image Recognition}.
\newblock In {\em CVPR}, June 2016.

\bibitem{hou2021learning}
Yuxin Hou, Eleonora Vig, Michael Donoser, and Loris Bazzani.
\newblock Learning attribute-driven disentangled representations for
  interactive fashion retrieval.
\newblock In {\em ICCV}, 2021.

\bibitem{Hu01}
Jie Hu, Li Shen, Gang Sun, and Samuel Albanie.
\newblock {Squeeze-and-Excitation Networks}.
\newblock In {\em TPAMI}, 2017.

\bibitem{Huang01}
Junshi Huang, Rogerio Feris, Qiang Chen, and Shuicheng Yan.
\newblock {Cross-Domain Image Retrieval with a Dual Attribute-Aware Ranking
  Network}.
\newblock In {\em ICCV}, 2015.

\bibitem{Kalantidis01}
Yannis Kalantidis, Clayton Mellina, and Simon Osindero.
\newblock {Cross-Dimensional Weighting for Aggregated Deep Convolutional
  Features}.
\newblock In {\em ECCV}, 2016.

\bibitem{VIT}
Alexander Kolesnikov, Alexey Dosovitskiy, Dirk Weissenborn, Georg Heigold,
  Jakob Uszkoreit, Lucas Beyer, Matthias Minderer, Mostafa Dehghani, Neil
  Houlsby, Sylvain Gelly, Thomas Unterthiner, and Xiaohua Zhai.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{liu2016deepfashion}
Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, and Xiaoou Tang.
\newblock {DeepFashion: Powering Robust Clothes Recognition and Retrieval with
  Rich Annotations}.
\newblock In {\em CVPR}, 2016.

\bibitem{ma2020fine}
Zhe Ma, Jianfeng Dong, Zhongzi Long, Yao Zhang, Yuan He, Hui Xue, and Shouling
  Ji.
\newblock {Fine-Grained Fashion Similarity Learning by Attribute-Specific
  Embedding Network}.
\newblock In {\em Thirty-fourth AAAI Conference on Artificial Intelligence},
  2020.

\bibitem{naseer2021intriguing}
Muhammad~Muzammal Naseer, Kanchana Ranasinghe, Salman~H Khan, Munawar Hayat,
  Fahad Shahbaz~Khan, and Ming-Hsuan Yang.
\newblock Intriguing properties of vision transformers.
\newblock In {\em NeurIPS}, 2021.

\bibitem{park2022vision}
Namuk Park and Songkuk Kim.
\newblock How do vision transformers work?
\newblock In {\em ICLR}, 2022.

\bibitem{Paszke01}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas {Köpf}, Edward Yang, Zach DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, and Soumith Chintala.
\newblock {PyTorch: An Imperative Style, High-Performance Deep Learning
  Library}.
\newblock In {\em NeurIPS}, 2019.

\bibitem{raghu2021vision}
Maithra Raghu, Thomas Unterthiner, Simon Kornblith, Chiyuan Zhang, and Alexey
  Dosovitskiy.
\newblock Do vision transformers see like convolutional neural networks?
\newblock 2021.

\bibitem{Schroff_2015_CVPR}
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
\newblock {FaceNet: A Unified Embedding for Face Recognition and Clustering}.
\newblock In {\em CVPR}, 2015.

\bibitem{song2022}
Chull~Hwan Song and Hye~Joo Han.
\newblock Convolutional attribute mask with two-step attention for fashion
  image retrieval.
\newblock In {\em 26th International Conference on Pattern Recognition (ICPR),
  IEEE}, 2022.

\bibitem{SCH01}
Chull~Hwan Song, Hye~Joo Han, and Yannis Avrithis.
\newblock {All the attention you need: Global-local, spatial-channel attention
  for image retrieval}.
\newblock In {\em WACV}, 2022.

\bibitem{dtop}
Chull~Hwan Song, Jooyoung Yoon, Shunghyun Choi, and Yannis Avrithis.
\newblock Boosting vision transformers for image retrieval.
\newblock In {\em WACV}, 2023.

\bibitem{efficientnet_pmlr_tan_19}
Mingxing Tan and Quoc Le.
\newblock {EfficientNet: Rethinking Model Scaling for Convolutional Neural
  Networks}.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning}, pages
  6105--6114, Long Beach, California, USA, June 2019. PMLR.

\bibitem{Laurens01}
Laurens van~der Maaten and Geoffrey Hinton.
\newblock {Visualizing Data using t-SNE}.
\newblock In {\em Journal of Machine Learning Research}, 2008.

\bibitem{van01}
Laurens van~der Maaten and Kilian Weinberger.
\newblock {Stochastic triplet embedding}.
\newblock In {\em MLSP}, 2012.

\bibitem{Transformer_NIPS2017_Vaswani}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, ukasz Kaiser, and Illia Polosukhin.
\newblock {Attention is All you Need}.
\newblock In I Guyon, U~V Luxburg, S Bengio, H Wallach, R Fergus, S
  Vishwanathan, and R Garnett, editors, {\em Advances in Neural Information
  Processing Systems}. Curran Associates, Inc., 2017.

\bibitem{veit2017}
Andreas Veit, Serge Belongie, and Theofanis Karaletsos.
\newblock {Conditional Similarity Networks}.
\newblock In {\em CVPR}, 2017.

\bibitem{Wan01}
Yongquan Wan, Cairong Yan, Bofeng Zhang, and Guobing Zou.
\newblock Learning image representation via attribute-aware attention networks
  for fashion classification.
\newblock In {\em MultiMedia Modeling: 28th International Conference, MMM 2022,
  Phu Quoc, Vietnam, June 6–10, 2022, Proceedings, Part I}, 2022.

\bibitem{wang01}
Qilong Wang, Banggu Wu, Pengfei Zhu, Peihua Li, Wangmeng Zuo, and Qinghua Hu.
\newblock {ECA-Net: Efficient Channel Attention for Deep Convolutional Neural
  Networks}.
\newblock In {\em CVPR}, 2020.

\bibitem{Woo01}
Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In~So Kweon.
\newblock {CBAM: Convolutional Block Attention Module}.
\newblock In {\em ECCV}, 2018.

\bibitem{xuan2020hard}
Hong Xuan, Abby Stylianou, Xiaotong Liu, and Robert Pless.
\newblock {Hard negative examples are hard, but useful}.
\newblock In {\em ECCV}, 2020.

\bibitem{Zappos}
Aron Yu and Kristen Grauman.
\newblock {Fine-grained visual comparisons with local learning}.
\newblock In {\em CVPR}, 2014.

\bibitem{Zou2019FashionAIAH}
Xingxing Zou, Xiangheng Kong, W. Wong, Congde Wang, Yuguang Liu, and Yuanpeng
  Cao.
\newblock {FashionAI: A Hierarchical Dataset for Fashion Understanding}.
\newblock In {\em CVPRW}, pages 296--304, 2019.

\end{thebibliography}
