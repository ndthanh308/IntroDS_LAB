\subsection{Memory Efficiency} 
The ViT used in this study has 98M parameters. Individual networks are required to learn   attributes with the existing naive method, which necessitates 98M $\times K$ parameters. However, our proposed method can form multi-space embeddings with only one backbone network, thus requiring approximately 98M $ \times 1 $ parameters. As shown in \autoref{fig:fig2}, only the last layer of the ViT model is modified in the proposed CCA, and fewer than 0.1M parameters are added for conditional token embedding. Thus, the proposed method achieves SOTA performance with very few parameters, indicating high efficiency of the algorithm.