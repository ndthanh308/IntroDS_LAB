% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{chen2017photographic}
Q.~Chen and V.~Koltun, ``Photographic image synthesis with cascaded refinement
  networks,'' in \emph{ICCV}, 2017.

\bibitem{isola2017image}
P.~Isola, J.-Y. Zhu, T.~Zhou, and A.~A. Efros, ``Image-to-image translation
  with conditional adversarial networks,'' in \emph{CVPR}, 2017.

\bibitem{gu2019mask}
S.~Gu, J.~Bao, H.~Yang, D.~Chen, F.~Wen, and L.~Yuan, ``Mask-guided portrait
  editing with conditional gans,'' in \emph{CVPR}, 2019.

\bibitem{liu2019learning}
X.~Liu, G.~Yin, J.~Shao, X.~Wang \emph{et~al.}, ``Learning to predict
  layout-to-image conditional convolutions for semantic image synthesis,'' in
  \emph{NeurIPS}, 2019.

\bibitem{qi2018semi}
X.~Qi, Q.~Chen, J.~Jia, and V.~Koltun, ``Semi-parametric image synthesis,'' in
  \emph{CVPR}, 2018.

\bibitem{park2019semantic}
T.~Park, M.-Y. Liu, T.-C. Wang, and J.-Y. Zhu, ``Semantic image synthesis with
  spatially-adaptive normalization,'' in \emph{CVPR}, 2019.

\bibitem{wang2018high}
T.-C. Wang, M.-Y. Liu, J.-Y. Zhu, A.~Tao, J.~Kautz, and B.~Catanzaro,
  ``High-resolution image synthesis and semantic manipulation with conditional
  gans,'' in \emph{CVPR}, 2018.

\bibitem{cordts2016cityscapes}
M.~Cordts, M.~Omran, S.~Ramos, T.~Rehfeld, M.~Enzweiler, R.~Benenson,
  U.~Franke, S.~Roth, and B.~Schiele, ``The cityscapes dataset for semantic
  urban scene understanding,'' in \emph{CVPR}, 2016.

\bibitem{zhou2017scene}
B.~Zhou, H.~Zhao, X.~Puig, S.~Fidler, A.~Barriuso, and A.~Torralba, ``Scene
  parsing through ade20k dataset,'' in \emph{CVPR}, 2017.

\bibitem{caesar2018coco}
H.~Caesar, J.~Uijlings, and V.~Ferrari, ``Coco-stuff: Thing and stuff classes
  in context,'' in \emph{CVPR}, 2018.

\bibitem{tang2023edge}
H.~Tang, X.~Qi, G.~Sun, D.~Xu, N.~Sebe, R.~Timofte, and L.~Van~Gool, ``Edge
  guided gans with semantic preserving for semantic image synthesis,'' in
  \emph{ICLR}, 2023.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio, ``Generative adversarial nets,'' in
  \emph{NeurIPS}, 2014.

\bibitem{tang2021total}
H.~Tang and N.~Sebe, ``Total generate: Cycle in cycle generative adversarial
  networks for generating human faces, hands, bodies, and natural scenes,''
  \emph{IEEE TMM}, 2021.

\bibitem{tang2020unified}
H.~Tang, H.~Liu, and N.~Sebe, ``Unified generative adversarial networks for
  controllable image-to-image translation,'' \emph{IEEE TIP}, vol.~29, pp.
  8916--8929, 2020.

\bibitem{mirza2014conditional}
M.~Mirza and S.~Osindero, ``Conditional generative adversarial nets,''
  \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem{tang2019attribute}
H.~Tang, X.~Chen, W.~Wang, D.~Xu, J.~J. Corso, N.~Sebe, and Y.~Yan,
  ``Attribute-guided sketch generation,'' in \emph{FG}, 2019.

\bibitem{tang2019expression}
H.~Tang, W.~Wang, S.~Wu, X.~Chen, D.~Xu, N.~Sebe, and Y.~Yan, ``Expression
  conditional gan for facial expression-to-expression translation,'' in
  \emph{ICIP}, 2019.

\bibitem{tang2022bipartite}
H.~Tang, L.~Shao, P.~H. Torr, and N.~Sebe, ``Bipartite graph reasoning gans for
  person pose and facial image synthesis,'' \emph{Springer IJCV}, pp. 1--15,
  2022.

\bibitem{tang2022facial}
H.~Tang and N.~Sebe, ``Facial expression translation using landmark guided
  gans,'' \emph{IEEE TAFFC}, vol.~13, no.~4, pp. 1986--1997, 2022.

\bibitem{tang2020xinggan}
H.~Tang, S.~Bai, L.~Zhang, P.~H. Torr, and N.~Sebe, ``Xinggan for person image
  generation,'' in \emph{ECCV}, 2020.

\bibitem{tang2019cycle}
H.~Tang, D.~Xu, G.~Liu, W.~Wang, N.~Sebe, and Y.~Yan, ``Cycle in cycle
  generative adversarial networks for keypoint-guided image generation,'' in
  \emph{ACM MM}, 2019.

\bibitem{tang2018gesturegan}
H.~Tang, W.~Wang, D.~Xu, Y.~Yan, and N.~Sebe, ``Gesturegan for hand
  gesture-to-gesture translation in the wild,'' in \emph{ACM MM}, 2018.

\bibitem{xu2022predict}
Z.~Xu, T.~Lin, H.~Tang, F.~Li, D.~He, N.~Sebe, R.~Timofte, L.~Van~Gool, and
  E.~Ding, ``Predict, prevent, and evaluate: Disentangled text-driven image
  manipulation empowered by pre-trained vision-language model,'' in
  \emph{CVPR}, 2022.

\bibitem{tao2022df}
M.~Tao, H.~Tang, F.~Wu, X.-Y. Jing, B.-K. Bao, and C.~Xu, ``Df-gan: A simple
  and effective baseline for text-to-image synthesis,'' in \emph{CVPR}, 2022.

\bibitem{tao2023galip}
M.~Tao, B.-K. Bao, H.~Tang, and C.~Xu, ``Galip: Generative adversarial clips
  for text-to-image synthesis,'' in \emph{CVPR}, 2023.

\bibitem{tao2022net}
M.~Tao, B.-K. Bao, H.~Tang, F.~Wu, L.~Wei, and Q.~Tian, ``De-net: Dynamic
  text-guided image editing adversarial networks,'' in \emph{AAAI}, 2023.

\bibitem{tang2023graph}
H.~Tang, Z.~Zhang, H.~Shi, B.~Li, L.~Shao, N.~Sebe, R.~Timofte, and
  L.~Van~Gool, ``Graph transformer gans for graph-constrained house
  generation,'' in \emph{CVPR}, 2023.

\bibitem{wu2022cross}
S.~Wu, H.~Tang, X.-Y. Jing, J.~Qian, N.~Sebe, Y.~Yan, and Q.~Zhang,
  ``Cross-view panorama image synthesis with progressive attention gans,''
  \emph{Elsevier PR}, vol. 131, p. 108884, 2022.

\bibitem{tang2022local}
H.~Tang, L.~Shao, P.~H. Torr, and N.~Sebe, ``Local and global gans with
  semantic-aware upsampling for image generation,'' \emph{IEEE TPAMI}, 2022.

\bibitem{tang2020dual}
H.~Tang, S.~Bai, and N.~Sebe, ``Dual attention gans for semantic image
  synthesis,'' in \emph{ACM MM}, 2020.

\bibitem{tang2020local}
H.~Tang, D.~Xu, Y.~Yan, P.~H. Torr, and N.~Sebe, ``Local class-specific and
  global image-level generative adversarial networks for semantic-guided scene
  generation,'' in \emph{CVPR}, 2020.

\bibitem{wu2022cross_tmm}
S.~Wu, H.~Tang, X.-Y. Jing, H.~Zhao, J.~Qian, N.~Sebe, and Y.~Yan, ``Cross-view
  panorama image synthesis,'' \emph{IEEE TMM}, 2022.

\bibitem{tang2021layout}
H.~Tang and N.~Sebe, ``Layout-to-image translation with double pooling
  generative adversarial networks,'' \emph{IEEE TIP}, vol.~30, pp. 7903--7913,
  2021.

\bibitem{albahar2019guided}
B.~AlBahar and J.-B. Huang, ``Guided image-to-image translation with
  bi-directional feature transformation,'' in \emph{ICCV}, 2019.

\bibitem{zhu2017unpaired}
J.-Y. Zhu, T.~Park, P.~Isola, and A.~A. Efros, ``Unpaired image-to-image
  translation using cycle-consistent adversarial networks,'' in \emph{ICCV},
  2017.

\bibitem{tang2019multi}
H.~Tang, D.~Xu, N.~Sebe, Y.~Wang, J.~J. Corso, and Y.~Yan, ``Multi-channel
  attention selection gan with cascaded semantic guidance for cross-view image
  translation,'' in \emph{CVPR}, 2019.

\bibitem{tang2019attention}
H.~Tang, D.~Xu, N.~Sebe, and Y.~Yan, ``Attention-guided generative adversarial
  networks for unsupervised image-to-image translation,'' in \emph{IJCNN},
  2019.

\bibitem{mejjati2018unsupervised}
Y.~A. Mejjati, C.~Richardt, J.~Tompkin, D.~Cosker, and K.~I. Kim,
  ``Unsupervised attention-guided image-to-image translation,'' in
  \emph{NeurIPS}, 2018.

\bibitem{chen2018attention}
X.~Chen, C.~Xu, X.~Yang, and D.~Tao, ``Attention-gan for object transfiguration
  in wild images,'' in \emph{ECCV}, 2018.

\bibitem{tang2021attentiongan}
H.~Tang, H.~Liu, D.~Xu, P.~H. Torr, and N.~Sebe, ``Attentiongan: Unpaired
  image-to-image translation using attention-guided generative adversarial
  networks,'' \emph{IEEE TNNLS}, 2021.

\bibitem{wu2019pay}
F.~Wu, A.~Fan, A.~Baevski, Y.~N. Dauphin, and M.~Auli, ``Pay less attention
  with lightweight and dynamic convolutions,'' in \emph{ICLR}, 2019.

\bibitem{chen2019graph}
Y.~Chen, M.~Rohrbach, Z.~Yan, Y.~Shuicheng, J.~Feng, and Y.~Kalantidis,
  ``Graph-based global reasoning networks,'' in \emph{CVPR}, 2019.

\bibitem{xu2018structured}
D.~Xu, W.~Wang, H.~Tang, H.~Liu, N.~Sebe, and E.~Ricci, ``Structured attention
  guided convolutional neural fields for monocular depth estimation,'' in
  \emph{CVPR}, 2018.

\bibitem{fu2019dual}
J.~Fu, J.~Liu, H.~Tian, Y.~Li, Y.~Bao, Z.~Fang, and H.~Lu, ``Dual attention
  network for scene segmentation,'' in \emph{CVPR}, 2019.

\bibitem{ren2019structureflow}
Y.~Ren, X.~Yu, R.~Zhang, T.~H. Li, S.~Liu, and G.~Li, ``Structureflow: Image
  inpainting via structure-aware appearance flow,'' in \emph{ICCV}, 2019.

\bibitem{nazeri2019edgeconnect}
K.~Nazeri, E.~Ng, T.~Joseph, F.~Qureshi, and M.~Ebrahimi, ``Edgeconnect:
  Structure guided image inpainting using edge prediction,'' in \emph{ICCV
  Workshops}, 2019.

\bibitem{li2019progressive}
J.~Li, F.~He, L.~Zhang, B.~Du, and D.~Tao, ``Progressive reconstruction of
  visual structure for image inpainting,'' in \emph{ICCV}, 2019.

\bibitem{nazeri2019edge}
K.~Nazeri, H.~Thasarathan, and M.~Ebrahimi, ``Edge-informed single image
  super-resolution,'' in \emph{ICCV Workshops}, 2019.

\bibitem{bansal2019shapes}
A.~Bansal, Y.~Sheikh, and D.~Ramanan, ``Shapes and context: in-the-wild image
  synthesis \& manipulation,'' in \emph{CVPR}, 2019.

\bibitem{zhu2020sean}
P.~Zhu, R.~Abdal, Y.~Qin, and P.~Wonka, ``Sean: Image synthesis with semantic
  region-adaptive normalization,'' in \emph{CVPR}, 2020.

\bibitem{ntavelis2020sesame}
E.~Ntavelis, A.~Romero, I.~Kastanis, L.~Van~Gool, and R.~Timofte, ``Sesame:
  Semantic editing of scenes by adding, manipulating or erasing objects,'' in
  \emph{ECCV}, 2020.

\bibitem{zhu2020semantically}
Z.~Zhu, Z.~Xu, A.~You, and X.~Bai, ``Semantically multi-modal image
  synthesis,'' in \emph{CVPR}, 2020.

\bibitem{sushko2020you}
V.~Sushko, E.~Sch{\"o}nfeld, D.~Zhang, J.~Gall, B.~Schiele, and A.~Khoreva,
  ``You only need adversarial supervision for semantic image synthesis,'' in
  \emph{ICLR}, 2021.

\bibitem{tan2021efficient}
Z.~Tan, D.~Chen, Q.~Chu, M.~Chai, J.~Liao, M.~He, L.~Yuan, G.~Hua, and N.~Yu,
  ``Efficient semantic image synthesis via class-adaptive normalization,''
  \emph{IEEE TPAMI}, 2021.

\bibitem{tan2021diverse}
Z.~Tan, M.~Chai, D.~Chen, J.~Liao, Q.~Chu, B.~Liu, G.~Hua, and N.~Yu, ``Diverse
  semantic image synthesis via probability distribution modeling,'' in
  \emph{CVPR}, 2021, pp. 7962--7971.

\bibitem{zhang2023adding}
L.~Zhang and M.~Agrawala, ``Adding conditional control to text-to-image
  diffusion models,'' \emph{arXiv preprint arXiv:2302.05543}, 2023.

\bibitem{zeng2023scenecomposer}
Y.~Zeng, Z.~Lin, J.~Zhang, Q.~Liu, J.~Collomosse, J.~Kuen, and V.~M. Patel,
  ``Scenecomposer: Any-level semantic image synthesis,'' in \emph{CVPR}, 2023.

\bibitem{shi2022semanticstylegan}
Y.~Shi, X.~Yang, Y.~Wan, and X.~Shen, ``Semanticstylegan: Learning
  compositional generative priors for controllable image synthesis and
  editing,'' in \emph{CVPR}, 2022.

\bibitem{van2018representation}
A.~Van~den Oord, Y.~Li, and O.~Vinyals, ``Representation learning with
  contrastive predictive coding,'' \emph{arXiv e-prints}, pp. arXiv--1807,
  2018.

\bibitem{hjelm2018learning}
R.~D. Hjelm, A.~Fedorov, S.~Lavoie-Marchildon, K.~Grewal, P.~Bachman,
  A.~Trischler, and Y.~Bengio, ``Learning deep representations by mutual
  information estimation and maximization,'' in \emph{ICLR}, 2018.

\bibitem{pan2021videomoco}
T.~Pan, Y.~Song, T.~Yang, W.~Jiang, and W.~Liu, ``Videomoco: Contrastive video
  representation learning with temporally adversarial examples,'' in
  \emph{CVPR}, 2021.

\bibitem{wu2018unsupervised}
Z.~Wu, Y.~Xiong, S.~X. Yu, and D.~Lin, ``Unsupervised feature learning via
  non-parametric instance discrimination,'' in \emph{CVPR}, 2018.

\bibitem{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton, ``A simple framework for
  contrastive learning of visual representations,'' in \emph{ICML}, 2020.

\bibitem{zhao2021contrastive}
X.~Zhao, R.~Vemulapalli, P.~A. Mansfield, B.~Gong, B.~Green, L.~Shapira, and
  Y.~Wu, ``Contrastive learning for label efficient semantic segmentation,'' in
  \emph{ICCV}, 2021.

\bibitem{gidaris2018unsupervised}
S.~Gidaris, P.~Singh, and N.~Komodakis, ``Unsupervised representation learning
  by predicting image rotations,'' in \emph{ICLR}, 2018.

\bibitem{doersch2015unsupervised}
C.~Doersch, A.~Gupta, and A.~A. Efros, ``Unsupervised visual representation
  learning by context prediction,'' in \emph{ICCV}, 2015.

\bibitem{noroozi2016unsupervised}
M.~Noroozi and P.~Favaro, ``Unsupervised learning of visual representations by
  solving jigsaw puzzles,'' in \emph{ECCV}, 2016.

\bibitem{hu2021region}
H.~Hu, J.~Cui, and L.~Wang, ``Region-aware contrastive learning for semantic
  segmentation,'' in \emph{ICCV}, 2021.

\bibitem{wang2021exploring}
W.~Wang, T.~Zhou, F.~Yu, J.~Dai, E.~Konukoglu, and L.~Van~Gool, ``Exploring
  cross-image pixel contrast for semantic segmentation,'' in \emph{ICCV}, 2021.

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' in \emph{NeurIPS}, 2012.

\bibitem{simonyan2015very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' in \emph{ICLR}, 2015.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{CVPR}, 2016.

\bibitem{huang2017arbitrary}
X.~Huang and S.~Belongie, ``Arbitrary style transfer in real-time with adaptive
  instance normalization,'' in \emph{ICCV}, 2017.

\bibitem{hu2018squeeze}
J.~Hu, L.~Shen, and G.~Sun, ``Squeeze-and-excitation networks,'' in
  \emph{CVPR}, 2018.

\bibitem{zhang2018context}
H.~Zhang, K.~Dana, J.~Shi, Z.~Zhang, X.~Wang, A.~Tyagi, and A.~Agrawal,
  ``Context encoding for semantic segmentation,'' in \emph{CVPR}, 2018.

\bibitem{xie2021segformer}
E.~Xie, W.~Wang, Z.~Yu, A.~Anandkumar, J.~M. Alvarez, and P.~Luo, ``Segformer:
  Simple and efficient design for semantic segmentation with transformers,''
  \emph{NeurIPS}, 2021.

\bibitem{gutmann2010noise}
M.~Gutmann and A.~Hyv{\"a}rinen, ``Noise-contrastive estimation: A new
  estimation principle for unnormalized statistical models,'' in
  \emph{AISTATS}, 2010.

\bibitem{khosla2020supervised}
P.~Khosla, P.~Teterwak, C.~Wang, A.~Sarna, Y.~Tian, P.~Isola, A.~Maschinot,
  C.~Liu, and D.~Krishnan, ``Supervised contrastive learning,'' \emph{NeurIPS},
  2020.

\bibitem{miyato2018spectral}
T.~Miyato, T.~Kataoka, M.~Koyama, and Y.~Yoshida, ``Spectral normalization for
  generative adversarial networks,'' in \emph{ICLR}, 2018.

\bibitem{canny1986computational}
J.~Canny, ``A computational approach to edge detection,'' \emph{IEEE TPAMI},
  no.~6, pp. 679--698, 1986.

\bibitem{tang2022multi}
H.~Tang, P.~H. Torr, and N.~Sebe, ``Multi-channel attention selection gans for
  guided image-to-image translation,'' \emph{IEEE TPAMI}, 2022.

\bibitem{wang2021image}
Y.~Wang, L.~Qi, Y.-C. Chen, X.~Zhang, and J.~Jia, ``Image synthesis via
  semantic composition,'' in \emph{ICCV}, 2021.

\bibitem{shi2022retrieval}
Y.~Shi, X.~Liu, Y.~Wei, Z.~Wu, and W.~Zuo, ``Retrieval-based spatially adaptive
  normalization for semantic image synthesis,'' in \emph{CVPR}, 2022.

\bibitem{lv2022semantic}
Z.~Lv, X.~Li, Z.~Niu, B.~Cao, and W.~Zuo, ``Semantic-shape adaptive feature
  modulation for semantic image synthesis,'' in \emph{CVPR}, 2022.

\bibitem{wang2022pretraining}
T.~Wang, T.~Zhang, B.~Zhang, H.~Ouyang, D.~Chen, Q.~Chen, and F.~Wen,
  ``Pretraining is all you need for image-to-image translation,'' \emph{arXiv
  preprint arXiv:2205.12952}, 2022.

\bibitem{mou2023t2i}
C.~Mou, X.~Wang, L.~Xie, J.~Zhang, Z.~Qi, Y.~Shan, and X.~Qie, ``T2i-adapter:
  Learning adapters to dig out more controllable ability for text-to-image
  diffusion models,'' \emph{arXiv preprint arXiv:2302.08453}, 2023.

\bibitem{wang2022semantic}
W.~Wang, J.~Bao, W.~Zhou, D.~Chen, D.~Chen, L.~Yuan, and H.~Li, ``Semantic
  image synthesis via diffusion models,'' \emph{arXiv preprint
  arXiv:2207.00050}, 2022.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' in
  \emph{ICLR}, 2015.

\bibitem{heusel2017gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter, ``Gans
  trained by a two time-scale update rule converge to a local nash
  equilibrium,'' in \emph{NeurIPS}, 2017.

\bibitem{yu2017dilated}
F.~Yu, V.~Koltun, and T.~Funkhouser, ``Dilated residual networks,'' in
  \emph{CVPR}, 2017.

\bibitem{xiao2018unified}
T.~Xiao, Y.~Liu, B.~Zhou, Y.~Jiang, and J.~Sun, ``Unified perceptual parsing
  for scene understanding,'' in \emph{ECCV}, 2018.

\bibitem{shi2022rcrn}
D.~Shi, X.~Diao, H.~Tang, X.~Li, H.~Xing, and H.~Xu, ``Rcrn: Real-world
  character image restoration network via skeleton extraction,'' in \emph{ACM
  MM}, 2022.

\bibitem{wu2022compiler}
Y.~Wu, Y.~Gong, P.~Zhao, Y.~Li, Z.~Zhan, W.~Niu, H.~Tang, M.~Qin, B.~Ren, and
  Y.~Wang, ``Compiler-aware neural architecture search for on-mobile real-time
  super-resolution,'' in \emph{ECCV}, 2022.

\bibitem{cao2022towards}
J.~Cao, J.~Liang, K.~Zhang, W.~Wang, Q.~Wang, Y.~Zhang, H.~Tang, and
  L.~Van~Gool, ``Towards interpretable video super-resolution via alternating
  optimization,'' in \emph{ECCV}, 2022.

\bibitem{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang, ``The unreasonable
  effectiveness of deep features as a perceptual metric,'' in \emph{CVPR},
  2018.

\bibitem{xie2015holistically}
S.~Xie and Z.~Tu, ``Holistically-nested edge detection,'' in \emph{ICCV}, 2015.

\bibitem{CelebAMask-HQ}
C.-H. Lee, Z.~Liu, L.~Wu, and P.~Luo, ``Maskgan: Towards diverse and
  interactive facial image manipulation,'' in \emph{CVPR}, 2020.

\end{thebibliography}
