\section{Implementation Details}
\label{sec:implement}
This section presents the implementation aspects of \system. We discuss the programming model and APIs, followed by a detailed overview of the system architecture.

% \begin{table}[]
% \centering
% \caption{User-implemented APIs}
% \label{tab:user_api}
% \resizebox{0.48\textwidth}{!}{%
% \begin{tabular}{|p{4cm}|p{6cm}|}
% \hline
% APIs & Description \\ \hline
% {\color{blue}EventBlotter} {\bf PRE\_PROCESS} ({\color{blue}Event}\ $e$)    
% &  Implements the pre-process function (e.g., filter). It returns EventBlotter containing parameter values (e.g., read/write sets) extracted from $e$.           \\ \hline
% {\color{blue}void} {\bf STATE\_ACCESS} ({\color{blue}EventBlotter}\ $eb$)    
% & Implements the state transaction through constructing system-provided APIs such as $READ$, $WRITE$.        
% \\ \hline
% {\color{blue}void} {\bf POST\_PROCESS} ({\color{blue}Event}\ $e$, {\color{blue}EventBlotter}\ $eb$)    &  Implements the post-process function that is dependent on results of state access (stored in EventBlotter).           \\ \hline
% \end{tabular}%
% }
% \end{table}


% \begin{table}[]
% \centering
% \caption{System-provided APIs ($table$, $timestamp$, and $EventBlotter$ parameters are omitted)}
% \label{tab:system_api}
% \resizebox{0.48\textwidth}{!}{%
% \begin{tabular}{|p{4cm}|p{6cm}|}
% \hline
% APIs & Description \\ \hline
% {\color{blue}void} \textbf{READ} ({\color{blue}Key} $d$, {\color{blue}EventBlotter}\ $eb$)  
% &  Issues a read request with key of $d$ and store results in $eb$ for further processing (i.e., post-process).          
% \\ \hline
% {\color{blue}void} \textbf{WRITE} ({\color{blue}Key} $d$, {\color{blue}Fun} $f^*$({\color{blue}Keys} $s...n$))
% & Issues a write request so that $state(d)$ is updated with the results after applying $f^*$ on $state(s...n)$, this request involves data dependency.    
% \\ \hline
% {\color{blue}void} \textbf{READ} ({\color{blue}Window\_Fun} $win\_f^*$({\color{blue}Key} $d$, {\color{blue}Size} $t$), {\color{blue}EventBlotter}\ $eb$)
% & Issues a window read request that applying $win\_f^*$ on a key of $d$ with size $t$ and store results in $eb$ for further processing (i.e., post-process).
% \\ \hline
% {\color{blue}void} {\bf WRITE} ({\color{blue}Key} $d$, {\color{blue}Window\_Fun} $win\_f^*$({\color{blue}Keys} $s...n$, {\color{blue}Size} $t$))
% &   Issues a window write request so that $state(d)$ is updated with the results after applying $win\_f^*$ on $state(s...n)$ with size $t$, this request involves data dependency.  
% \\ \hline
% {\color{blue}void} \textbf{READ} ({\color{blue}Fun} $f^*$, {\color{blue}EventBlotter}\ $eb$)  
% &  Issues a non-deterministic read request on a key determined by a user-defined function $f^*$ and stores results in $eb$ for further processing (i.e., post-process).          
% \\ \hline
% {\color{blue}void} \textbf{WRITE} ({\color{blue}Fun} $f1^*$, {\color{blue}Fun} $f2^*$)  
% &  Issues a non-deterministic write request so that the key to be updated is determined by a user-defined function $f1^*$ and the value to be written back is determined by a user-defined function $f2^*$.          
% \\ \hline
% \end{tabular}%
% }
% \end{table}


\begin{table}[]
\centering
\caption{User-implemented APIs}
\label{tab:user_api}
\resizebox{0.48\textwidth}{!}{%
\begin{tabular}{|p{4cm}|p{6cm}|}
\hline
APIs & Description \\ \hline

\textbf{PRE\_PROCESS} (\textcolor{blue}{Event} $e$)
& Implements a pre-processing function (e.g., filtering). Returns an EventBlotter containing parameter values (e.g., read/write sets) extracted from $e$. \\ \hline

\textbf{STATE\_ACCESS} (\textcolor{blue}{EventBlotter} $eb$)
& Facilitates state transactions by constructing system-provided APIs, such as $READ$ and $WRITE$. \\ \hline

\textbf{POST\_PROCESS} (\textcolor{blue}{Event} $e$, \textcolor{blue}{EventBlotter} $eb$)
& Implements a post-processing function that depends on the results of state access stored in the EventBlotter. \\ \hline

\end{tabular}%
}
\end{table}

\begin{table}[]
\centering
\caption{System-provided APIs (parameters for $table$, $timestamp$, and $EventBlotter$ are omitted)}
\label{tab:system_api}
\resizebox{0.48\textwidth}{!}{%
\begin{tabular}{|p{3cm}|p{5.5cm}|}
\hline
APIs & Description \\ \hline
\textbf{READ} (\textcolor{blue}{Key} $d$, \textcolor{blue}{EventBlotter} $eb$)  
&  Initiates a read request for the key $d$ and stores the results in $eb$ for further processing (i.e., post-process). \\ \hline

\textbf{WRITE} (\textcolor{blue}{Key} $d$, \textcolor{blue}{Fun} $f^*$ (\textcolor{blue}{Keys} $s...n$))
& Initiates a write request so that $state(d)$ is updated with the results after applying $f^*$ on $state(s...n)$, representing a data dependency.  \\ \hline

\textbf{READ} (\textcolor{blue}{Window\_Fun} $win\_f^*$ (\textcolor{blue}{Key} $d$, \textcolor{blue}{Size} $t$), \textcolor{blue}{EventBlotter} $eb$)
& Issues a window read request that applies $win\_f^*$ on a key $d$ with size $t$ and stores the results in $eb$ for further processing (i.e., post-process). \\ \hline

\textbf{WRITE} (\textcolor{blue}{Key} $d$, \textcolor{blue}{Window\_Fun} $win\_f^*$ (\textcolor{blue}{Keys} $s...n$, \textcolor{blue}{Size} $t$))
&  Initiates a window write request so that $state(d)$ is updated with the results after applying $win\_f^*$ on $state(s...n)$ with size $t$, this request implies data dependency. \\ \hline

\textbf{READ} (\textcolor{blue}{Fun} $f^*$, \textcolor{blue}{EventBlotter} $eb$)  
& Issues a non-deterministic read request on a key determined by a user-defined function $f^*$ and stores result in $eb$ for further processing (i.e., post-process). \\ \hline

\textbf{WRITE} (\textcolor{blue}{Fun} $f1^*$, \textcolor{blue}{Fun} $f2^*$)  
& Initiates a non-deterministic write request where the key to be updated is determined by a user-defined function $f1^*$ and the value to be written back is determined by another user-defined function $f2^*$. \\ \hline

\end{tabular}%
}
\end{table}

\subcompact
\subsection{Programming Model and APIs}
\begin{algorithm}[t]
\footnotesize
  boolean $dualmode$;\tcp{\footnotesize{\color{Gray}flag of dual-mode scheduling}}
  Map $cache$;\tcp{\footnotesize{\color{Gray}thread-local storage}}
  \ForEach{\text{event $e$ in input stream}}
  {
    \uIf{$e$ is not punctuation\tcp{\footnotesize{\color{Gray}always true under prior schemes}}}{
        EventBlotter $eb$ $\gets$ \textbf{PRE\_PROCESS}($e$);\tcp{\footnotesize{\color{Gray} e.g., filter events}}
        \textbf{STATE\_ACCESS}($eb$);\tcp{\footnotesize{\color{Gray}issue one state transaction}}
        \uIf{dualmode}{
            \tcc{\footnotesize{\color{Gray}stores events whose state access is postponed under \system scheme.}}
      	    $cache$.add($<e$, $eb>$)\;
            
      	}\Else{
      	    \tcc{\footnotesize{\color{Gray}evaluates three steps contiguously under prior schemes.}}
      	    \textbf{POST\_PROCESS}($<e$, $eb>$);\tcp{\footnotesize{\color{Gray}e.g., computes toll based on obtained road statistics}}
      	}
    }
    \Else{
        \tcc{\color{Gray}if the event is a punctuation, transaction processing can start.}
        \textbf{TXN\_START}()\tcp{\color{Gray}Triggers mode switching.}
        \ForEach{$<e$, $eb>$ $\in$ $cache$}{
            \textbf{POST\_PROCESS}($<e$, $eb>$);
        }
    }
  }
  \caption{Code template of an operator}
  \label{alg:algo_example}
\end{algorithm}

\begin{algorithm}[t]
\footnotesize
    \KwIn{EventBlotter $eb$}
    \SetKwFunction{FMain}{Sender\_Fun}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$sender$, $value$}}{
        \uIf{\textbf{READ}($sender$, $eb$) $>$ $value$}{
            return \textbf{READ}($sender$, $eb$) - $value$\;\tcp{\footnotesize{\color{Gray}decrement money of $sender$ by $value$.}}
        }
    }
   
    \SetKwFunction{FMain}{Recver\_Fun}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$recver$, $sender$, $value$}}{
        \uIf{\textbf{READ}($sender$, $eb$) $>$ $value$}{
            return \textbf{READ}($recver$, $eb$) + $value$\;\tcp{\footnotesize{\color{Gray}increment money of $recver$ by $value$.}}
        }
    }

    \Begin{
         \textbf{WRITE}($eb.sender$, Sender\_Fun($eb.sender$, $eb.v$))\;
         \textbf{WRITE}($eb.recver$, Recver\_Fun($eb.recver$, $eb.sender$, $eb.v$))\;
     }
 \caption{\footnotesize{STATE\_ACCESS of \texttt{\myc{Streaming Ledger}}}}    
  \label{alg:algo2}
\end{algorithm}

\begin{algorithm}[t]
\footnotesize
    \KwIn{EventBlotter $eb$}

    \SetKwFunction{FMain}{Fun1}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$udf1$}}{
         $target\_key$ $\gets$ $udf1$\;\tcp{\footnotesize{\color{Gray}get the targeting key to write through $udf1$.}}
         return $target\_key$\;
    }

    \SetKwFunction{FMain}{Fun2}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$udf2$}}{
         $keys$ $\gets$ $udf2$\;\tcp{\footnotesize{\color{Gray}get keys to read through $udf2$.}}
         $sum\_value$ $\gets$ \textbf{sum} \textbf{READ}($keys$)\;
         $eb.result$.insert($sum\_value$)\;
         return $sum\_value$\;
    }

    \Begin{
        \textbf{WRITE}(Fun1($eb.udf1$), Fun2($eb.udf2$));
     }
 \caption{\footnotesize{STATE\_ACCESS of \texttt{Non-deterministic GrepSum}}}    
  \label{alg:algo3}
\end{algorithm}

\system, similar to many popular DSPEs~\cite{storm,carbone2015apache,spark}, expresses an application as a Directed Acyclic Graph (DAG), where vertices are operators encapsulating user-defined data processing logic, and edges are the event streams connecting these operators. Inside each operator, we encapsulate the data processing logic into a three-step programming model. These steps include preprocessing, state access, and postprocessing, which are recursively applied to every batch of input events. 

In the \textit{preprocessing} step, \system identifies the potential read/write sets from the input events following the predefined event parsing logic. It is noteworthy that these sets may contain non-deterministic functions and thus their concrete values may not be fully determined during preprocessing. 
The second step, \textit{state access}, is where actual state accesses occur. Here, \system applies user-defined functions to each identified read/write set from the preprocessing stage. This state access step is comprehensive and capable of handling special operations such as non-deterministic and window operations. Non-deterministic state accesses, identified during preprocessing, are resolved in this step to achieve concrete state accesses. 
\textit{Postprocessing} is the final step. Here, \system further processes the input event according to the results from state access, generating the corresponding output. If a transaction aborts, \system marks the output with ``failed state access'' to notify users, who can resubmit requests as part of new input events.

\system enhances this programming model by providing a list of APIs, both user-implemented and system-provided. User-implemented APIs, outlined in Table~\ref{tab:user_api}, demand users to incorporate their application requirements into the three-step data processing logic. Note that, \system maintains a thread-local auxiliary data structure called \emph{EventBlotter} for each input event, which acts as the data bridge linking the two processing phases as discussed in Section~\ref{subsec:overview}. An example of an operator's code template based on this programming model is shown in Algorithm~\ref{alg:algo_example}. State transaction execution is conveyed through the \textbf{STATE\_ACCESS} API, which is further defined using system-provided APIs. 
% Algorithm~\ref{alg:algo2} and~\ref{alg:algo3} offer an illustration of \textbf{STATE\_ACCESS} implementation by using \myc{\texttt{Streaming Ledger}} and \texttt{Non-deterministic GrepSum} as two examples. 
\myc{Algorithm~\ref{alg:algo2} and~\ref{alg:algo3} provide an illustration of \textbf{STATE\_ACCESS} implementation using two examples, namely the \texttt{Streaming Ledger} and the \texttt{Non-deterministic GrepSum}. The \texttt{Non-deterministic GrepSum} is a modified version with non-deterministic operations atop the original GrepSum benchmark introduced in our previous work~\cite{tstream}.}



In contrast, system-provided APIs, summarized in Table~\ref{tab:system_api}, stand as library calls, offering functions akin to those in other frameworks~\cite{he2008mars}. \textbf{READ} and \textbf{WRITE} represent atomic operations that a state transaction can decompose. \system's APIs go beyond normal \textbf{READ}/\textbf{WRITE} operations by supporting window and non-deterministic operations, extending the flexibility and adaptability of the platform. For window operations, users can define a window function in \textbf{READ}/\textbf{WRITE} operations, specifying states to access, window size, and a window aggregation function. Non-deterministic operations allow users to specify user-defined functions for both keys to access and values to write back. This indicates that while the number of operations a transaction decomposes is deterministic according to the processing logic, the accessed keys and aggregated results of operations can be non-deterministic.

\begin{comment}
\subsubsection{Programming Model.}
\myc{
In line with many popular DSPEs~\cite{storm,carbone2015apache,spark}, 
\system expresses an application as a DAG (Directed Acyclic Graph) where vertices are operators containing user-defined data processing logic and edges are the event streams connecting operators. 
The difference between TSPEs and DSPEs is in expressing data processing logic in each operator.
In particular, we follow the common programming model of TSPEs to abstract the data processing logic in each operator in the following three steps~\cite{tstream}. 
These three steps are recursively conducted for every batch of input events.
(i) \emph{preprocess} the input events, which will determine the read/write sets of the state transactions. 
The read/write sets are to be extracted from input events based on a pre-defined event parsing logic. 
(ii) \emph{state access}, where all state accesses are actually performed. 
For each read/write set, \system applies the associated state access operations containing user-defined functions for execution.
Note that state access is a general process that can support special operations such as non-deterministic operations and window operations.
(iii) \emph{postprocess}, where the input event will be further processed according to the access result, and the corresponding output will be generated. 
As a stream processing system must keep the data moving~\cite{10.1145/1107499.1107504}, the output of the aborted transaction is marked with ``failed state access'' to notify users, who can resubmit requests which become part of new input events.
}

% For example, in Figure~\ref{}, the system uses~\emph{accID} to determine the ~\emph{account record} in the \emph{Account Table}. Note that, \system does not support non-deterministic state transactions, such as those with random keys. We leave the exploration of such features in the future. 
% Specifically, users can specify keys to be accessed and/or user-defined functions to be applied.

\subsubsection{Programming APIs.}
\myc{
\system adopts a programming API similar to that of Storm~\cite{storm} to specify the DAG for a transactional stream processing application.
Additionally, based on the programming model, \system provides a list of user-implemented and system-provided APIs inside each operator. 
The former are user implemented based on their application requirements
and the latter function as library calls, 
similar to some existing frameworks~\cite{he2008mars}. 
Currently, all APIs are implemented in Java. 
}

\myc{
User-implemented APIs are summarized in Table~\ref{tab:user_api}, which requires users to implement the data processing logic of an operator as three steps. 
A code template of an operator is following the programming model of TSPEs, which can be shown in Algorithm~\ref{alg:algo}. 
State transaction execution is expressed through the \textbf{STATE\_ACCESS} API, which would be further defined using system-provided APIs. 
Algorithm~\ref{alg:algo2} illustrates an implementation of \textbf{STATE\_ACCESS} by using \texttt{Stream Ledger} as an example. 
All operations (i.e., two operations in this example) issued from one invocation of \textbf{STATE\_ACCESS} are treated as one state transaction. 
}

\myc{
System-provided APIs are summarized in Table~\ref{tab:system_api}
\textbf{READ}, \textbf{WRITE} stand for atomic operations that can be decomposed by a state transaction. 
For brevity, $table$, $timestamp$, and $EventBlotter$ parameters are omitted in Table~\ref{tab:system_api} and shown in Algorithm~\ref{alg:algo2}. 
$Key$ and $Value$ stand for key and new value of the state to read/write, respectively. 
$Fun$ stands for a user-defined function such as incrementing the value by 1. 
Users can implement $Fun$ by constructing system-provided APIs (e.g., a conditional update depends on a read operation). 
Except for normal \textbf{READ}/\textbf{WRITE} operations, \system also exposes APIs to easily implement window and non-deterministic \textbf{READ}/\textbf{WRITE} operations.
For window operations, users can specify a user-defined window function $Window\_Fun$ in \textbf{READ}/\textbf{WRITE} operations by defining different 1) states to access, 2) window size, and 3) window aggregation function inside.
For non-deterministic operations, users can specify user-defined functions for both keys to access and values to write back.
Note that the number of operations to be decomposed by a transaction is always deterministic according to the transaction processing logic, while the keys accessed and results to be aggregated of operations can be non-deterministic.
}

% The current sets of system-provided APIs are not meant to be complete and can be easily extended. 
% Implementing them for prior schemes can be done following our description in Section~\ref{sec:motivation}. 
% In the following, we describe \system's implementation. 
\end{comment}

\subcompact
\subsection{System Architecture}
\label{subsec:architecture_overview}
The architecture of  \system is composed of various components working in unison to support the efficient execution of transactional stream processing. This section provides a detailed overview of the key architectural components and outlines their interactions and workflow in \system.

\begin{comment}
\subsubsection{Architecture Overview}
\system's architecture consists of four key components: ProgressController (PC), StreamManager (SM), TxnManager (TM), TxnScheduler (TS), and \myc{TxnExecutor (TE)}. 
The PC is a singleton component that assigns monotonically increasing timestamps to its generated punctuations using a simple global counter. 
The other four components, SM, TM, TS, and TE, are instantiated in each thread locally.

The SM is responsible for preprocessing and postprocessing every input event ($e$). State transactions may be issued during preprocessing but not immediately processed, following the approach of prior works~\cite{tstream}. Input events can be postprocessed by the SM based on transaction processing results only when state transactions are processed (i.e., committed or aborted).

The TM handles dependency resolution among state transactions and inserts decomposed operations to construct a \tpg. Upon receiving punctuation, the TM refines the constructed \tpg with further dependency resolution.

The TS makes three dimensions of scheduling decisions based on the constructed \tpg for concurrent operation execution, as previously discussed in Section~\ref{sec:scheduling}.

\myc{
A TS spawns a new TE that explores operations in \tpg according to scheduling decisions.
Subsequently, the TE executes correct state access/abort for operations in \tpg  with finite
state machine annotations, which is to be discussed in Section~\ref{sec:execution}.
}

\end{comment}

\subsubsection{Architectural Components and Interactions}

% Figure environment removed

\myc{An overview of the system architecture of \system can be shown in Figure~\ref{fig:architecture_overview}}, which is comprised of five primary components: the singleton ProgressController (PC), and per-thread instances of StreamManager (SM), TxnManager (TM), TxnScheduler (TS), and TxnExecutor (TE).

The PC has a pivotal role, where it assigns monotonically increasing timestamps to its generated punctuations using a simple global counter. Its operation ensures a coherent temporal view across all threads in the system.

SM is the first stage in the transactional processing pipeline. It handles the preprocessing and postprocessing of each input event ($e$). During preprocessing, SM can generate state transactions, an approach adapted from prior works~\cite{tstream}. However, unlike traditional models, these transactions are not immediately processed. Instead, the input events are postprocessed based on the results of these state transactions once they are processed, i.e., either committed or aborted.

The responsibility of dependency resolution among state transactions and construction of a \tpg falls on TM. TM's operation comes into play upon receiving punctuation, during which it refines the constructed \tpg with additional dependency resolution. This refined \tpg serves as the basis for the next stage of the pipeline, the TS, which makes scheduling decisions based on the \tpg, guiding the system towards concurrent operation execution, a feature further discussed in Section~\ref{sec:scheduling}. 

Rounding off the pipeline is TE, spawned by TS, which executes operations in \tpg according to the scheduling decisions. It ensures correct state access/abort for operations in \tpg with finite state machine annotations. The details of this process are presented in Section~\ref{sec:execution}.

% Having provided an overview of the individual components and their interactions, the execution algorithm governing the operation of these components within \system's three-stage execution workflow is explored in the subsequent section (Section~\ref{subsec:execution_algorithm}).

% \system's architecture comprises four primary components: the ProgressController (PC), StreamManager (SM), TxnManager (TM), TxnScheduler (TS), and TxnExecutor (TE). 

% The PC is a singleton component that assigns monotonically increasing timestamps to its generated punctuations using a simple global counter. The SM, TM, TS, and TE, on the other hand, are instantiated in each thread locally. 

% SM is responsible for preprocessing and postprocessing each input event ($e$). It can issue state transactions during preprocessing, following the approach of prior works~\cite{tstream}, but these transactions are not immediately processed. Input events can only be postprocessed by the SM based on transaction processing results when state transactions are processed (i.e., committed or aborted).

% The TM handles dependency resolution among state transactions and inserts decomposed operations to construct a transaction precedence graph (\tpg). Upon receiving punctuation, the TM refines the constructed \tpg with further dependency resolution.

% The TS makes scheduling decisions based on the constructed \tpg for concurrent operation execution, as previously discussed in Section~\ref{sec:scheduling}. 

% Lastly, the TS spawns a new TE that explores operations in \tpg according to scheduling decisions. The TE subsequently executes correct state access/abort for operations in \tpg  with finite state machine annotations, which is discussed in detail in Section~\ref{sec:execution}.

% With a clear understanding of the system's components and how they interact, we now delve into the execution algorithm that governs the operation of these components in the context of \system's three-stages execution workflow (Section~\ref{subsec:overview}).

\begin{algorithm}[t]
\footnotesize
    \KwData{$e$ \tcp{Input event}}
    \KwData{$txn_{ts}$ \tcp{State transaction}}
    \KwData{$G$ \tcp{The currently constructed \tpg}}
    \While{!finish processing of input streams}{
        \eIf(\tcp*[h]{Phase 1}){\text{$e$ is not a $punctuation$}}{
                $txn_{ts}$ $\gets$ PRE\_Processing($e$)\;
                \tcp*[h]{Planning: dependency tracking}\;
                \textbf{\circled{1}$^1$}\textbf{TPG\_Construction}($G$, $txn_{ts}$)\; 
          }(\tcp*[h]{Phase 2}){
                \textbf{\circled{1}$^2$}\textbf{TPG\_Refinement}($G$)\; 
                \tcp*[h]{Scheduling: adaptive scheduling}\;
                \textbf{\circled{2}}$M$ $\gets$ \textbf{TPG\_Scheduling}($G$)\;
                \tcp*[h]{Execution: correct execution}\;
                \textbf{\circled{3}}\textbf{TPG\_Execution}($G$, $M$)\; 
                POST\_Processing()\;
          }
    }
    
    \SetKwFunction{FMain}{TPG\_Construction}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$G$, $txn_{ts}$}}{
        $O_{1..k}$ $\gets$ \textbf{Partition} $txn_{ts}$\;
        \ForEach{\text{operation $O_{i}$ $\in$ $O_{1..k}$}}{
            \textbf{Identify} its \ld\;
            $G$ $\gets$ $G$ + $O_{i}$\;
        }
    }
    \SetKwFunction{FMain}{TPG\_Refinement}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$G$}}{
        \ForEach{\text{vertex $e_{i}$ $\in$ $G$}}{
            \textbf{Identify} its \td, \pd\;
        }
    }

    \SetKwFunction{FMain}{TPG\_Scheduling}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$G$}}{
        $M$ $\gets$ Instantiated with $G$;\tcp{Model-guided scheduling decision making.}
    }
    
    \SetKwFunction{FMain}{TPG\_Execution}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{$G$, $M$}}{
        \While{!finish scheduling of $G$
        }{
        $Scheduling Unit$ $\gets$ \emph{Explore}($G$, $M$)\;
        Execute with abort handling ($Scheduling Unit$)\; 
        }
    }
  \caption{Execution Algorithm of \system}
  \label{alg:algo}
\end{algorithm}

\subsubsection{Execution Algorithm}
\label{subsec:execution_algorithm}
In this section, we detail the execution algorithm for \system, which drives the operation of the system's components in line with the three-stages execution workflow (as detailed in Section~\ref{subsec:overview}). This algorithm plays a pivotal role in ensuring the correct and efficient processing of transactions within the stream processing context. Each phase in the workflow — Planning, Scheduling, and Execution — corresponds to a specific set of tasks performed by the algorithm, which leverages the system components introduced above and handles the dependencies among state transactions as identified in the \tpg. In the following paragraphs, we elucidate the algorithm, with particular emphasis on its connection to the three-stage workflow.

The primary execution algorithm of \system, as outlined in Algorithm~\ref{alg:algo}, underscores that transactional stream processing is a continuous process that may potentially never end. By introducing punctuations~\cite{Tucker:2003:EPS:776752.776780}, the algorithm separates the dependency resolution and execution of state transactions into two non-overlapping phases, ensuring that no subsequent input event will have a smaller timestamp.

In the first phase, the \textbf{\circled{1}}$^1$ \textit{StreamManager} preprocesses every input event ($e$). Concurrently, the \textbf{\circled{1}}$^1$ \textit{TxnManager} manages dependency resolution among state transactions and integrates decomposed operations to construct a \tpg.

The second phase sees the \textbf{\circled{1}}$^2$ \textit{TxnManager} refining the constructed \tpg through further dependency resolution. Meanwhile, the \textbf{\circled{2}} \textit{TxnScheduler} schedules operations for concurrent execution based on the refined \tpg. 

In \textbf{\circled{3}}, guided by a scheduling decision model $M$, execution threads adopt an exploration strategy to traverse the constructed \tpg, identifying operations ready to be scheduled while respecting dependency constraints. During this exploration, one or several operations may be treated as the unit of scheduling. Each thread executes the operations in the scheduling unit, implementing various abort handling mechanisms as needed. Input events associated with processed state transactions (i.e., committed or aborted) are then postprocessed by the \textit{StreamManager} according to the transaction processing results.

% In this section, we detail the execution algorithm for \system, which drives the operation of the system's components as per the three-stages execution workflow described in Section~\ref{subsec:overview}. This algorithm plays a vital role in ensuring the correct and efficient processing of transactions within the stream processing context. For each phase in the workflow --- Planning, Scheduling, and Execution --- the algorithm defines specific tasks to be accomplished, leveraging the system components introduced above and applying the dependencies among state transactions identified in the \tpg. Let's walk through the algorithm, highlighting its relationship with the three-stage workflow.

% The core execution algorithm of \system is presented in Algorithm~\ref{alg:algo}. Transactional stream processing is continuous and potentially never ends. The dependency resolution and execution of state transactions are separated into two non-overlapping phases by punctuations~\cite{Tucker:2003:EPS:776752.776780}, which guarantees that no subsequent input event will have a smaller timestamp.

% During the first phase, the \textbf{\circled{1}}$^1$ \textit{StreamManager} conducts preprocessing for every input event ($e$). The \textbf{\circled{1}}$^1$ \textit{TxnManager} handles dependency resolution among state transactions and inserts decomposed operations to construct a $TPG$.

% In the second phase, the \textbf{\circled{1}}$^2$ \textit{TxnManager} refines the constructed $TPG$ with further dependency resolution. The \textbf{\circled{2}} \textit{TxnScheduler} schedules operations for concurrent execution based on the constructed $TPG$. 
% \textbf{\circled{3}} Guided by a scheduling decision model $M$, execution threads adopt an exploration strategy to explore the constructed $TPG$ for operations available to be scheduled constrained by dependencies. During exploration, one or multiple operations may be treated as the unit of scheduling. Every thread executes operation(s) in the unit of scheduling with various abort handling mechanisms. Only when state transactions are processed (i.e., committed or aborted), the associated input events can be postprocessed by the \textit{StreamManager} based on transaction processing results.
\begin{comment}
\subsubsection{Execution Algorithm}
The core execution algorithm of \system is presented in Algorithm~\ref{alg:algo}.
Transactional stream processing is continuous and potentially never ends (Line 1$\sim$8).
The dependency resolution and execution of state transactions are separated into two non-overlapping phases by punctuations~\cite{Tucker:2003:EPS:776752.776780} (Line 2 and 5), which guarantees that no subsequent input event will have a smaller timestamp. 
Effectively, a batch of state transactions is collected during the first phase, and processed during the second phase.

In the first phase, 
the \textbf{StreamManager} conducts preprocessing for every input event ($e$). Similar to some prior works~\cite{tstream}, state transactions may be issued but not immediately processed during preprocessing (Line 3).
The \emph{pre\_processing} and \emph{post\_processing} functions are exposed as APIs to users.
\textbf{\circled{1}}$^1$
The \textbf{TxnManager} handles dependency resolution (Line 4) among state transactions and inserts decomposed operations to construct a $TPG$. We discuss the detailed two-phase $TPG$ construction process in Section~\ref{subsec:construction}.

\myc{
In the second phase, 
\textbf{\circled{1}}$^2$
the \textbf{TxnManager} is first involved again to refine (Line 6) the constructed $TPG$ with further dependency resolution.
\textbf{\circled{2}}
The \textbf{TxnScheduler} 
schedules operations for concurrent execution based on the constructed $TPG$ according to the three dimensions of scheduling decisions (Line 7). 
In particular, a scheduling decision model $M$ is instantiated based on the constructed $TPG$ (Line 14).
\textbf{\circled{3}}
Guided by $M$, execution threads adopt an exploration strategy (Section~\ref{subsec:explore}) to explore the constructed $TPG$ for operations available to be scheduled constrained by dependencies (Line 8). 
During exploration, one or multiple operations may be treated as the unit of scheduling (Section~\ref{subsec:granularity}). 
Subsequently, every thread executes operation(s) in the unit of scheduling with various abort handling mechanisms (Section~\ref{subsec:abort_handling}).
Only when state transactions are processed (i.e., committed or aborted), the associated input events can be postprocessed (Line 9) by the \textbf{StreamManager} based on transaction processing results. 
}
\end{comment}