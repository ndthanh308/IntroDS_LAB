% Figure environment removed
% Figure environment removed
 
\subcompact
\subsection{Impact of Scheduling Decisions}
\label{subsec:scheduling_decision}
In this section, we evaluate the impact of varying scheduling decisions under different workload characteristics using GS due to its flexibility.
% We present the model decisions study to demonstrate how the lightweight model makes decisions under varying S-TPG properties.
% We vary the properties of the constructed S-TPG by varying workload characteristics introduced in Section~\ref{sec:model}.

\subsubsection{Impact of Exploration Strategies}
% We first study the impact of different exploration strategies (i.e., \nse vs. \se).
% As discussed in Section~\ref{subsec:model}, two key factors affect selecting better-performing exploration strategies, namely 1) the \emph{punctuation interval} and 2) \emph{workload skewness}.
We first study the effectiveness of different exploration strategies (i.e., \nse vs. \se) mainly affected by the \emph{punctuation interval} and the \emph{workload skewness}, as discussed in Section~\ref{subsec:model}.
% by tuning the \emph{punctuation interval} and workload \emph{skewness}.
% then use the \emph{batch size / keys} and \emph{skewness} to. 
Figure~\ref{fig:low_skewness} shows the effects of selecting different exploration strategies under varying \emph{punctuation interval} and low \emph{workload skewness}.
\nse works better when \emph{punctuation interval} is low, while \se works better when \emph{punctuation interval} is high. 
%This is because there is a linear proportional relationship between the \emph{punctuation interval} and the number of dependencies (\td/\pd) of the constructed \tpg.
This is due to the linear proportionality between the \emph{punctuation interval} and the number of dependencies (\tds/\pds) of the constructed \tpg.
When the \emph{punctuation interval} is low, \nse resolves the rare dependencies as soon as an operation has been successfully processed, leading to higher system concurrency. \se works better otherwise as the notification overhead of the \nse approach keeps increasing with more dependencies in the workloads. However, \se has a constant construction and synchronization overhead for dependencies resolution.
Figure~\ref{fig:state_access_skewness} shows the effects of selecting different exploration strategies under varying \emph{workload skewness} and high \emph{punctuation interval}. We can see that \se works better when the state accesses are uniformly distributed, i.e., the Zipf skew factor is 0. \nse works better when the state accesses are skewed. This is because a skewed workload leads to load unbalance among threads and intensifies the synchronization overhead when \se is applied as summarized in Table~\ref{tab:decisions}.
\subsubsection{Impact of Scheduling Granularities}
In this section, we study the effectiveness of different scheduling granularities (i.e., \fsu v.s. \csu), which are affected by the following key workload characteristics, namely \emph{cyclic/acyclic}, \emph{number of state access}, \emph{punctuation interval}, and the \emph{ratio of multi-accesses}.
First, 
Figure~\ref{fig:low_num_access} shows the results of different scheduling granularities under the workload with or without cyclic dependencies. \csu performs better when there is no cyclic dependency among the batched scheduling units since each thread can schedule a group of operations together as a scheduling unit to amortize the context switching overheads. 
However, our further experiments reveal that when there is a large number of state access, \fsu is always better than \csu, regardless of whether there are circular dependencies. This is mainly due to the fact that even without circular dependencies, a large number of state accesses will increase the number of \pd, causing a significant overhead on resolving the dependencies among operations of the same group.
Second,
Figure~\ref{fig:punctuation_interval} shows how varying \emph{punctuation interval} affects the selection of scheduling unit granularities when there are no cyclic dependencies. 
We set the number of state accesses to one to avoid the effect of \pd, so the punctuation interval only controls the number of \tds in the \tpg.
We can see that \csu achieves higher throughput at higher punctuation intervals. 
When the punctuation interval is high, the large number of \tds increases the context-switching overhead in \fsu, which is why the performance of \fsu decreases when the punctuation interval is large, such as 81920.
In contrast, \csu schedules the operations in a group resulting in lower context-switching overhead on resolving \td compared to the \fsu.
Third,
Figure~\ref{fig:state_access_number} shows that \fsu works better when the ratio of multiple state access is high, while \csu works better when the ratio is low. The ratio of multiple state access controls the number of \pds among operations, as we can see that the \pd affects the performance of \csu significantly. This is mainly because the execution concurrency drops when the number of \pds is high. 
 
  % Figure environment removed

\subsubsection{Impact of Abort Handling Mechanisms}
Finally, we study the impact of two abort handling mechanisms (i.e., \ea v.s. \la) mainly affected by the \emph{abort ratio} and the \emph{computation complexity} workload characteristics.
Figure~\ref{fig:high_abort_ratio} shows the comparison results of varying \emph{computation complexity} when the \emph{abort ratio} is high. 
A lower computation complexity leads to a low redo overhead, and \la handles frequent aborts together to reduce the context switching overheads. 
\ea is better otherwise, as it makes a minimum impact on the ongoing execution of other operations.
% shows that the \la works better when the abort ratio is high and the computation complexity is low. 
Figure~\ref{fig:abort_ratio} shows the results of different abort handling mechanisms under different abort ratios when the computation complexity is low. The results indicate that as the ratio of aborting transactions increases, \la works better. The key reason is that when the computation complexity is low, the context-switching overheads and the synchronization overhead among threads to achieve fine-grained state rollback and redo become the major bottlenecks.