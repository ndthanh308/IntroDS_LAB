% Figure environment removed


% Figure environment removed


% Figure environment removed

\subcompact
\subsection{Overhead}
\label{subsec:overhead}
\system achieves adaptive scheduling at the cost of more complex runtime operations such as data structures constructing and exploring available state access operations. 
These extra operations can negatively impact the system in the following two ways: 1) the complex construction and exploration process may increase the latency of transaction processing, and 2) the auxiliary data structure will increase the memory consumption of the application. 

\subcompact
\subsubsection{Latency overhead} 
Following a prior work~\cite{tstream}, we show the time breakdown in the following aspects. 
1) \emph{Useful Time} refers to the time spent on doing actual work including accessing shared mutable states and performing user-defined functions.
2) \emph{Sync Time} refers to the time spent on synchronization, including blocking time before lock insertion is permitted or blocking time due to synchronization barriers during mode switching.
3) \emph{Lock Time} refers to the time spent on inserting locks after it is permitted.
4) \emph{Construct Time} refers to the time spent on constructing the auxiliary data structures, e.g., \tpg in \system and operation chains in \tstream.
5) \emph{Explore Time} refers to the time spent on exploring available operations to process.
6) \emph{Abort Time} refers to the wasted computation time due to abort and redos.

Figure~\ref{fig:Breakdown} shows the time breakdown when the system runs the dynamic workload in Section~\ref{subsec:evaluation}. There are three key takeaways.
First, although \tstream and \system spend a significant portion of time during construction (\emph{Construct Time}), they successfully reduce synchronization (\emph{Sync Time}) and lock (\emph{Lock Time}) overhead compared to \sstore. This explains their better performance on multicore processors.
Second, \tstream has the highest abort time (\emph{Abort Time}) because \tstream has to redo the entire batch of transactions when a transaction abort happens. 
In contrast, \sstore spends little time in abort as it involves little redo of state transactions because dependent transactions are executed serially.
Third, we can see that \system still spends a significant fraction of time performing exploration (\emph{Explore Time}). This is mainly caused by excessive message-passing among threads. In the future, we plan to investigate more efficient exploration strategies such as prioritizing mechanisms~\cite{kwok1999static} in \system.

\subsubsection{Memory footprint} 
\label{subsec:memory-footprint}
We use the dynamic workload in Section~\ref{subsec:evaluation} to evaluate memory footprint. Figure~\ref{fig:memory_footprint} demonstrates the memory consumption of three TSPEs without GC involved. 
In the initialization stage, the memory consumption of all systems is almost the same. 
\system spends more time during initialization compared to \tstream as it needs to initialize more data structures to support adaptive scheduling. 
During runtime, \system and \tstream consume a similar amount of memory per batch of state transactions, and both consume much more than \sstore. This is because they construct auxiliary data structures for scheduling, and especially they may maintain multiple physical copies of each state at different timestamps during execution (Section~\ref{subsec:abort_handling}).
Note that, as we have configured \system to not clear temporal objects and the JVM size to be large enough (300GB), the total memory usage keeps increasing until execution is finished, during which no GC is triggered. 
We plan to incorporate stream compression~\cite{Cstream,CompressStreamDB} in \system to reduce such high memory footprints in future.

\subsubsection{Clean-up and GC overhead}
\label{subsec:GC}
Figure~\ref{fig:varying_jvm} shows the impact of clean-up under varying JVM sizes from 100GB to 300GB. We can see that enabling clear temporal objects brings down the performance of \system up to 12.8\%, and still outperforms TStream and S-Store. In Figure~\ref{fig:varying_jvm}(b), the memory usage fluctuates up and down when the JVM size is set to 100GB or 200 GB because the JVM periodically reclaims (GC) the temporary objects in the continued processing of data streams.