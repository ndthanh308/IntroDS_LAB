\subcompact
\subsection{Case Study}
\label{subsec:use_cases}
\myc{
We further demonstrate the practical usefulness of \system with two case studies that need to maintain shared states with the requirements of high performance and correctness.
% : \textit{Online Social Event Detection} and \textit{Stock Exchange Analysis}.
}

\myc{
\subsubsection{Online Social Event Detection}
}
\myc{
Detecting unexpected data patterns on social media platforms is a pressing need known as online social event detection (OSED)~\cite{fedoryszak2019real,hasan2018survey}. This process entails continually processing streaming data while reading and updating three shared states: \textit{Word}, which represents meaningful concepts in alphabetic form; \textit{Tweet}, which denotes a standardized string of words; and \textit{Cluster}, which is a collection of tweets encoding similar event information.
}

% Figure environment removed

\myc{
Numerous ways have been proposed for OSED~\cite{hasan2018survey}. In this demonstration, we use a novel method called \textit{Hybrid Event Detection}~\cite{sahin2019streaming}, which consists of two stages:
\emph{(1) Burst Keyword Detection:}
This stage finds and labels words with a high frequency growth across windows as \textit{burst keywords}. 
\emph{(2) Tweet Clustering:}
Tweets containing \textit{burst keywords} are grouped together into tweet clusters based on cosine similarity. At the end of each window, clusters with significant growth rates are identified as output events.
}

\myc{
OSED exhibits several distinguishing features:
\emph{Firstly,} high data processing capacity is required to successfully capture trending topics from enormous streams of social media posts, along with low latency to respond to real-time event detection requests.
\emph{Secondly,} it requires highly concurrent accesses to shared states (i.e., \textit{Word}, \textit{Tweet}, and \textit{Cluster}) to track event evolution, making it difficult to assure state consistency in complex transactional dependencies.
\emph{Lastly,} the workload characteristics of the input social media post stream are highly dynamic, posing a challenge in allocating tasks effectively among executors.
}

\myc{
To address these challenges, \system structures the three types of shared state (\textit{Word}, \textit{Tweet}, and \textit{Cluster}) as shared mutable key-value pairs, as depicted in Figure~\ref{fig:Online_Event_Detection_Workflow}. Each pair contains multiple fields facilitating the necessary computations for event detection. To ensure state consistency, \system maps simultaneous state access operations as a single transaction. It effectively resolves transaction dependencies and adapts to the most suitable scheduling strategy under dynamic workload characteristics.
}

\myc{
The workflow of OSED on \system is illustrated in Figure~\ref{fig:Online_Event_Detection_Workflow}.
% represented as a DAG with six operators, each responsible for processing a specific type of state transaction through user-defined and system-provided APIs.
% The process begins with the \textit{Tweet Registrant}, which registers pre-processed tweets into the state, decomposes them into word tokens, and distributes them downstream. The \textit{Word Updater} then updates the frequency information of words into the state. The \textit{Trend Calculator} identifies burst keywords with significant increases in their TF-IDF values across windows and emits tweets containing these burst keywords for clustering. These actions are performed after updating the state of all words in the current window, ensuring that no burst keywords are overlooked, controlled by the \textit{punctuation} mechanism~\cite{mao2023morphstream}. Upon receiving filtered tweets, the \textit{Similarity Calculator} measures their similarities with existing clusters and determines the most suitable clusters. New clusters are initialized if no matching clusters are found. Once all tweets in the window are merged into clusters by the \textit{Cluster Updater}, the \textit{Event Selector} identifies clusters with high growth rates as events and propagates them as output. Additionally, clusters with zero updates for a long time are removed.
The \textit{Tweet Registrant} initiates the process by registering pre-processed tweets into the state, decomposing them into word tokens, and distributing them downstream. The \textit{Word Updater} then updates the words' frequencies to the state. The \textit{Trend Calculator} then identifies burst keywords with significant increases in TF-IDF values across windows and emits tweets with these burst keywords for clustering. These actions are carried out after the status of all words in the current window has been updated, ensuring that no burst keywords are overlooked, as controlled by the \textit{punctuation} mechanism~\cite{mao2023morphstream}. After receiving filtered tweets, the \textit{Similarity Calculator} compares them to existing clusters and determines the most suitable clusters. If no matching clusters are found, new clusters are created. Once all tweets in the window are merged into clusters by the \textit{Cluster Updater}, the \textit{Event Selector} identifies clusters with high growth rates as events and propagates them as output. Meanwhile, clusters with no updates over an extended period of time are eliminated.
}

% Figure environment removed

\myc{
We conducted our analysis using a dataset of real-world tweets~\cite{olteanu2014crisislex}, comprising English tweets from five crisis events that occurred in the United States between 2012 and 2013. This dataset consists of approximately 30,000 tweets, both event-related and non-event-related. For our application, we deployed four executors for each operator, with a total punctuation interval of 400 tweets. Each thread was allocated 100 tweets per batch to execute.
In Figure~\ref{fig:ed_performance}, we present the performance results of our online event detection implemented using \system, compared to the actual evolution of events over time. The popularity of events is measured by the number of new tweets merged into a specific event cluster within each time window. 
The results demonstrate that our online event detection, supported by \system, accurately detects the emergence of events and effectively captures changes in event popularity trends within seconds, as indicated by the time difference in event popularity summits. We also observed that \system achieved an overall throughput of up to 1.3k tweets per second for processing and detecting events. These findings provide compelling evidence of \system's ability to efficiently support complex real-time applications.
}



\subsubsection{Real-time Stock Exchange Analysis}
One common stock exchange analysis (SEA)~\cite{sse} task is to get the turnover rates of stocks by calculating the trade ratio of each stock for every period of time. 
% The input data are a stream of quotes and a traded stream that contains traded results of matched quotes.
The input data is a stream of quotes and a stream of trades containing the trade results of matching quotes.
The query joins the traded stream and the quotes stream ($S$) over the same stock id within the same period of time (i.e., window). 
% Such a stock analysis task can be implemented using the hash-based window join algorithm.
Specifically, given the unbounded nature of streaming data, windows are commonly employed to restrict the number of tuples involved in the computation. 
Subsequently, window join matches the traded and quote records for each stock to calculate its associated turnover rates.
% The overlapping windows provide opportunities for work-sharing, i.e., the result of one window evaluation can be used to help with
% the evaluation of the next window. 
% For example, a recent work~\cite{shahvarani2020parallel} successfully utilizes a shared window index to accelerate sliding window joins, reduce redundant memory access during tuple matching, and improve performance. This approach can be particularly useful in parallel and distributed systems, where the goal is to maximize resource utilization and minimize communication overhead.
The SEA can be implemented using the hash-based window join algorithm.
The algorithm maintains two hash tables, one for each input stream.
When it receives a tuple from Traded (or Quote) stream, it inserts the tuple into the hash table of Traded (or Quote) and immediately probes the hash table of the opposite stream Quote (or Traded). 

% Figure environment removed

% \myc{
% Indexing the contents of a sliding window necessitates a significant amount of concurrent updates, which must meet the critical requirements of high throughput and low latency to effectively support stream processing that relies on the index. 
% Intuitively, the arrival of each new tuple will trigger an update to the index structure. Shahvarani et al.~\cite{shahvarani2020parallel} propose an effective concurrency control mechanism to meet the demands of high-rate updates during indexed stream window join. Nevertheless, the proposed concurrency control mechanism is still based on locks, which are known to be costly.
% }

\myc{
With \system, we can intuitively map the hash table structure to the shared state and model insertion and probe requests to the hash table as state transactions. 
% Furthermore, we implement a lightweight data structure to capture the dynamic changes of indexes in streaming settings. 
An overview of the stock analysis workflow implemented by hash-based window join is shown in Figure~\ref{fig:Stock_Exchange_Workflow}. 
\system maintains two hash tables \(Index(Traded)\) and \(Index(Quotes)\) for streams \(Traded\) and \(Quotes\), respectively as shared state. 
The key $k$ of the state is the stock id and the value $<r, ...>$ contains all arrived tuples in the current window slide.
% The index state is implemented in the form of a hashmap $\texttt{<}key,address\texttt{>}$ that associates tuple keys with their in-memory storage addresses. 
% we address two key associated implementation challenges. 
% Firstly, we implement a lightweight data structure to capture the dynamic changes of indexes in streaming settings. 
% Secondly, we implement an efficient, non-blocking concurrency control scheme to ensure indexing correctness under high-intensive read and write operations. 
% The need to ensure high-throughput, low-latency stream processing further magnifies the challenges. We will demonstrate that by leveraging the scalable TSPE \system, we can efficiently maintain shared window indexes with transactional semantics and further optimize the performance of stream window operations on multicore processors.
}

\myc{
% \textbf{Workflow Overview.}
% For simplification, we based the shared window index optimization on \textit{Index-Based Window Join}~\cite{shahvarani2020parallel} with an equality predicate. 
% At runtime, indexes are dynamically updated by multiple worker threads as the window moves.
The join operation involves the following steps. 
When a new tuple \(r\) arrives from stream \(Traded\), \system searches for matching tuples in \(HashTable(Quotes)\) by efficient index lookup. Once matched tuples \(<s, ...>\) are identified, \system calculates turnover rates accordingly during a window slide and propagates the result $\texttt{<}r,s\texttt{>}$ as the join output. 
Subsequently, it deletes the expired tuple and inserts the new tuple \(r\) into \(HashTable(Traded)\), updating the multi-version state storage accordingly. 
All accesses to hash tables, such as insert and delete, are mapped to state access operations and are subsequently modelled as state transactions in \system. Only when all operations of a state transaction are performed successfully, the transaction is committed. Otherwise, the state is restored to the latest version before abort, and the transaction will be re-executed.
}

% % Figure environment removed

% Figure environment removed

% We sampled the turnover rates calculated from 100 continuous quotes/traded events in Figure~\ref{fig:stock_dataset}.


\myc{
Figure~\ref{fig:stock_performance} shows the performance results of the stock exchange analysis implemented based on \system.
% We use a real-world stock exchange dataset~\cite{sse} for this workload that contains tens of millions of quote and traded records. 
% We configured the batch interval as 40k and deployed the application with 4 executors and used the default scheduling strategy for evaluation.
For evaluation, we utilized a real-world stock exchange dataset~\cite{sse} containing tens of millions of quote and traded records. 
The application was deployed with 10 executors, and the batch interval was configured as 1k, where each executor will be evenly allocated with 1k records per batch for execution. 
% We set the default scheduling strategy for \system.
% We mainly showcase the expected accumulated matched result after a traded/quote event has been generated and the actual result output by \system.
The primary focus of the performance evaluation is on the expected accumulated matched result generated by traded/quote events and the actual result output by \system.
The performance results demonstrate that \system consistently outputs the actual results within the millisecond level.
We also measured that the throughput of the \system can process up to 70k events per second.
These findings confirm the efficiency of implementing real-time financial applications in \system, as it can achieve the ACID guarantees for transactions while maintaining high throughput and low latency.
}