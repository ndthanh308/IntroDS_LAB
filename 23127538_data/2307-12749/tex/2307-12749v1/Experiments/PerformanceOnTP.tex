% \subsection{Performance Evaluation on TP}
% \label{subsec:TP}
%We divide the workloads of OB into the following phases.
%In the first phase shown in the Table ~\ref{tab:default}, at the beginning, users will bid on a large number of different items, which leads to a larger number of TD and a uniform vertex degree distribution. 
%In the second phase that follows, we assume that some very popular items appear, so a great quantity of users will bid on the same item. Therefore, we reflect this phenomenon by increasing the skewness of state access distribution in the configuration.
%In the third phase, as the auction progresses, invalid transactions such as the bid price is below the asking price or the quantities of the item are insufficient. So we configure the workload with an increasing ratio of abort transactions.
% \textbf{\system is more flexible to handle complex workload.}
% \noindent
\subsubsection{Evaluation of Multiple Scheduling Strategies}
\label{subsubsec:mutiple}
In TP, the road conditions in different regions can have varying characteristics, which can be divided into multiple groups. \tstream \cite{tstream} and \sstore \cite{S-Store}'s scheduling strategies may work well on one group of state transactions but not on another.
In contrast, \system's modular and flexible design allows it to employ multiple scheduling strategies concurrently.
For illustration, we configure the TP to contain two groups of state transactions simultaneously. 
In \emph{group 1}, the state access distribution of state transactions is skewed, and the ratio of aborting transactions is high. 
In \emph{group 2}, the state distribution of state transactions is uniform and transaction aborts occur rarely. 
\margii{-1pt}{R4O14}
\change{As guided by our decision model (Figure~\ref{fig:model})}, 
\system applies \nse, \csu, and \la for handling transactions of \emph{group 1}, and applies \se, \csu, and \ea for handling transactions of \emph{group 2}. We name such a combination of strategies a \emph{nested} configuration.

Figure~\ref{fig:TP_Throughput} shows the throughput comparison results. We can see that the throughput of the nested configuration is 40.9\% higher than \tstream and 117\% higher than \sstore. 
To further comprehend the advantage of the nested configuration, we compare it against two plain scheduling strategies: \nse, \csu, and \la (denoted as \emph{plain-1}) and \se, \csu, and \ea (denoted as \emph{plain-2}) for handling all transactions from both groups.
% which are either suitable for \emph{group 1} or \emph{group 2}, respectively. 
Unsurprisingly, the throughput of the nested configuration is 1.17$\times$ and 2.87$\times$ higher than that of each plain scheduling strategy. When the ratio of aborting transactions in \emph{group 1} is high, the \emph{plain-2} is bottlenecked by the frequent context switching overheads. 
%\tony{As the skewness of state access increases, the workloads become less balanced among threads, also hampering performance. -- what do you want to say here?} 
At the same time, as the skewness of state access increases in \emph{group 1}, the workloads become less balanced among threads, hampering the system performance when using \se in \emph{plain-2}.
As the state distribution of state transactions is uniform and the ratio of aborting transactions is low in \emph{group 2}, the \emph{plain-1} spends more time resolving dependencies and redoing the entire batch of transactions. 
The \emph{plain-1} performs better than \emph{plain-2} as there are fewer \pds and the computation complexity is low, but it is still lower than that of the \emph{nested} setting. 
% However, there are less \pd in Toll Processing and the computation complexity is low, so the drop in performance of \emph{plain-1} is not as obvious as that of \emph{plain-2}, but it is still lower than that of \emph{nested} setting. 
% \system's flexibility enables a "hybrid" type scheduling strategy for multiple state transaction groups, which get the best of the all scheduling strategies.

Figure~\ref{fig:TP_Latency} shows the comparison results of end-to-end processing latency. Thanks to the significantly improved performance, \system with nested configuration achieves very low processing latency. 
%-- explain why S-Store's latency keeps linearly increase?? and also the purple line. ---
Note that, \sstore spends more time on synchronization and inserting locks under a highly contended workload in \emph{group1} because dependent transactions are executed serially. Under a higher ratio of aborting transactions in \emph{group 1}, \emph{plain-2} spends lots of time achieving fine-grained state rollback because of the high context-switching and synchronization overhead of \se (Table~\ref{tab:decisions}), which is why \emph{plain-2} results in highest latency compared to others. 
% Figure environment removed

\subcompact
\subsubsection{Evaluation of Window-based Queries}
\label{subsubsec:window_exp}

\myc{
We implement an additional application \textit{GrepSum with window reads} as an example to illustrate how MorphStream supports windowing queries. 
Specifically, we modified the GrepSum to perform random state updates and periodical window readings. 
In particular, the application processes two types of state transactions: 
(1) it executes transactions with write-only operations on receiving input events with updating requests, 
and (2) it executes transactions with window-read and sum aggregation operations on receiving input events with
reading requests.
}

For this experiment, we retained the settings of GrepSum outlined in Table~\ref{tab:default}, with an abort ratio of 0 and a punctuation interval of 102400. The process involved periodic state access (one event with reading requests for every 100 input events), where 100 random states were accessed within a default window size of 1000 (which required reading states up to 1000 event-time old) for the GrepSum operation. We modified the window trigger periods and window sizes to simulate a variety of window query scenarios, and evaluated their impact on performance. The overall results are presented in Figure~\ref{figures:window_exp}.

We first adjust window sizes from 1k to 100k, with the performance outcomes depicted in Figure~\ref{fig:window_size_exp}. As anticipated, increasing the window size led to an escalation in state access overhead due to the need to read more state versions. This inflated overhead, in turn, decreased system throughput by up to 30\%.
We then vary the window trigger period from 100 to 10k events. The performance results, shown in Figure~\ref{fig:window_period_exp}, demonstrated that frequent window queries significantly impeded throughput, slowing it down by as much as 60\%.
These experiments underscore \system's optimization potential in window-based transactional stream processing. Opportunities lie in reducing redundant calculations in overlapping window operations. Exploring these improvements is part of our future work.

\subsubsection{Evaluation of Non-Deterministic Queries}
\label{subsubsec:nondeterministic_exp}

% Figure environment removed
% % Figure environment removed
\myc{
We implemented the \textit{GrepSum with non-deterministic queries} to demonstrate \system's support for non-deterministic state access. It involves processing state transactions that read specific states and compute summation results, which are then written back to a designated state. However, the state to be accessed can be deterministic or non-deterministic. Deterministic state access is based solely on the input event, while non-deterministic state access depends on additional factors such as user-defined functions, timers, or random values~\cite{Clonos}. 
}

\myc{
In this experiment, we focused on tuning the number of state transactions involving non-deterministic state access to investigate its impact on the performance of \system. The results, shown in Figure~\ref{fig:non_exp}, led to two key observations. First, the number of non-deterministic state accesses had no significant effect on the performance of \sstore. This is because \sstore executes dependent operations sequentially, resulting in minimal overhead for handling non-deterministic state access. Second, both \system and \tstream experienced notable performance degradation as the number of non-deterministic state accesses increased. This can be attributed to the higher \tpg planning overhead associated with a large number of non-deterministic state accesses, requiring the addition of virtual operations and tracking dependencies across all operation chains. The results of this experiment indicate a significant optimization space within \system to enable efficient tracking of dependencies for non-deterministic state access operations. For instance, one potential approach could involve predicting the accessed state and conducting pilot runs of non-deterministic state access operations. However, developing an efficient and low-overhead training model for this purpose poses challenges and remains a topic for future work.
% GS + (UDF + Random Number + Timers).
}

% For example, some roads in one area are congested, so the state access is more skewed. While in another area, the traffic condition is good and the state access distribution is less skewed.

% for multiple state transaction groups. 
% can still use one scheduling strategy to handle multiple groups of state transactions with different characteristics. In doing so, however, the scheduling strategy that works well on one group of state transactions may not work well on another group.

% For demonstration, 
% The two-layer setting is the scheduling strategy that uses \emph{OG\_NS\_Lazy} and \emph{OG\_DFS\_Eager} scheduling strategies for two groups of state transactions, respectively. 

% \curry{\system's modular and flexible design makes it possible to handle cases not find in the \tstream \cite{tstream} and S-Store \cite{S-Store} by employing different scheduling strategies for multiple state transaction groups. To demonstrate this advantage, we use the Toll Processing ~\cite{TP} as the base application and outline how \system can be improved to address this situation.   }

% \curry{ 
% Nonetheless, \tstream \cite{tstream} and S-Store \cite{S-Store} can still use one scheduling strategy to handle multiple groups of state transactions with different characteristics. In doing so, however, the scheduling strategy that works well on one group of state transactions may not work well on another group.
% For example, when the state access distributions of two state transaction groups are skewed in one and uniform in the other, neither \emph{structured exploration strategy} nor \emph{non-structured exploration strategy} can resolve dependencies well. To alleviate this concern, we leverage \system's modular and flexible design to create not one but multiple scheduling strategies, one for each group. This approach efficiently handles the different workload characteristics in multiple state transactions group.}

% \curry{To evaluate this situation, we configures the Toll Processing to contain two groups of state transactions. In \emph{group1}, the state access distribution of state transactions is skewed and the ratio of aborting transaction is high. On the contrary, in \emph{group2}, the state distribution of state transactions is uniform and transaction aborts occur rarely. }

% \curry{The result are shown in the Figure ~\ref{fig:TP_layer}, the throughput of the two-layer setting is 40.9\% better than \tstream and 117 ~\% better than S-Store. 

% To further outline the advantage of the two-layer approach, we compare the two-layer setting against two single-layer scheduling strategy: \emph{MorphStream(OG\_NS\_Lazy)} and \emph{MorphStream(OG\_DFS\_Eager)}, which are suitable for group1 and group2, respectively. Unsurprisingly, the throughput of the two-layer setting is 1.17$\times$ and 2.87$\times$ higher than that of each single-layer scheduling strategy. When the ratio of aborting transaction in \emph{group1} is high, the \emph{MorphStream(OG\_DFS\_Eager)} scheduling strategy is bottlenecked by the frequent context switching overheads. At the same time, as the skewness of state access increases, the workloads is not balanced among threads, also hampering performance. As the state distribution of state transactions is uniform and the ratio of aborting transactions is low in \emph{group2}, the \emph{MorphStream(OG\_NS\_Lazy)} scheduling strategy spend more time to resolve dependencies and redo the entire batch of transactions. However, there are less \pd in Toll Processing and the computation complexity is low, so the drop in performance of \emph{MorphStream(OG\_NS\_Lazy)} is not as obvious as that of \emph{MorphStream(OG\_DFS\_Eager)}, but it is still lower than that of two-layer setting.  \system's flexibility enables a "hybrid" type scheduling strategy for multiple state transaction groups, which get the best of the all scheduling strategies.}

% \subsubsection{
% \change{Evaluation of Stream Window Queries}
% }