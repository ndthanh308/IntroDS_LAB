\section{Related Work}
%\subsection{Cost Volume based Deep Stereo Matching}
%Stereo matching is a typical problem that has been studied for decades and a well-known four-step pipeline \cite{scharstein2002taxonomy} has been established, where cost volume construction is an indispensable step. Current state-of-the-art stereo matching methods are all cost volume based methods and they can be categorized into two types. Typically, a cost volume is a 4D tensor of height, width, disparity, and features. The first category just uses a full correlation to generate a single-feature cost volume. Such methods are usually efficient but lose much information because of the decimation of feature channels. Many previous work, including Dispnet \cite{dispnet}, MADNet \cite{madnet}, IResNet \cite{iresnet} and AANet \cite{aanet}, belong to this category. The second category usually uses concatenation \cite{gcnet} or group-wise correlation \cite{gwcnet} to generate a multi-feature 4D cost volume. Such a method can achieve better performance while requiring higher computational complexity and memory consumption. Actually, a majority of the top-performing networks in public leaderboards belong to this category, such as GANet \cite{ganet}, CSPN \cite{cspn} and ACFNet \cite{acfnet}. These methods generally employ multiple 3D convolution layers to constantly regularize the 4D cost volume and then apply softmax over the disparity dimension to produce a discrete disparity probability distribution. The final predicted disparity is obtained by softly weighting indices according to their probability, which is also called soft argmin in GCNet \cite{gcnet}. However, soft argmin leaves the output susceptible to multi-modal disparity probability distributions. ACFNet \cite{acfnet} observes this problem and proposes to directly supervise the cost volume with unimodal ground truth distributions. In contrast, we define an uncertainty estimation to quantify the degree to which the cost volume tends to be multi-modal distribution, higher implies the higher possibility of estimation error.

\subsection{Multi-scale Cost Volume based Stereo Matching}
Cost volume construction is an indispensable step in the well-known four-step pipeline for stereo matching \cite{scharstein2002taxonomy, pamisurvey1, pamisurvey2}. Typically, current state-of-the-art stereo matching methods can be categorized into two types of cost volume-based methods, where the cost volume is a 4D tensor of height, width, disparity, and features. The first category usually uses the single-feature 3D cost volume generated by full correlation, which is efficient while losing much information due to the decimation of feature channels. Many real-time methods, such as Dispnet \cite{dispnet}, MADNet \cite{madnet, madnet_pami} and AANet \cite{aanet}, belongs to the category. Moreover, two-stage refinement \cite{mcvmfc} and pyramidal towers \cite{madnet} are commonly applied in the single-feature cost volume based network to construct multi-scale cost volume. The second category usually uses the multi-feature 4D cost volume generated by concatenation \cite{gcnet} or group-wise correlation \cite{gwcnet}, which can achieve better performance with higher computational complexity and memory consumption. Most top-performing networks, including GANet \cite{ganet}, CSPN \cite{cspn} and ACFNet \cite{acfnet} belong to this category. 
% In these methods, the 4D cost volume is constantly regularized by multiple 3D convolution layers and then a discrete disparity probability distribution can be produced by softmax. Next, the final predicted disparity can be obtained by softly weighting indices according to their probability \cite{gcnet}. However, such output is susceptible to multimodal disparity probability distributions and ACFNet \cite{acfnet} gives a solution by directly supervising the cost volume with unimodal ground truth distributions to alleviate this problem. 
Recently, to alleviate the high computational complexity and memory consumption when employing multi-feature 4D cost volumes, \cite{cvpmvsnet, cascade, uscnet} propose to use cascade cost volume representation in multi-view stereo. These methods usually first predict an initial disparity at the coarsest resolution of the image and then gradually refine the disparity by narrowing down the disparity search space. More closely related to our approach is Casstereo \cite{cascade}, which first extended such representation to stereo matching. It selected to uniform sample a pre-defined range to generate the next stage’s disparity search range. Instead, we employ pixel-level uncertainty estimation to adaptively adjust the next stage disparity searching range and generate pseudo-labels for subsequent domain adaptation. Our method also shares similarities with UCSNet \cite{uscnet}, which constructs uncertainty-aware cost volume in multi-view stereo while it doesn’t employ uncertainty estimation to generate pseudo-labels.

%\subsection{Multi-scale Cost Volume based Deep Stereo Matching} 
% \subsection{Multi-scale Cost Volume based Stereo Matching} 
%Multi-scale cost volume firstly was applied in the single-feature cost volume based network with the form of two-stage refinement \cite{mcvmfc} and pyramidal towers \cite{madnet}. Recently, cascade cost volume representation \cite{cvpmvsnet, cascade, uscnet} was proposed in multi-view stereo to alleviate the high computational complexity and memory consumption when employing multi-feature 4D cost volumes. These methods generally predict an initial disparity at the coarsest resolution of the image. Then, they will narrow down the disparity search space and gradually refine the disparity. More closely related to our approach is Casstereo \cite{cascade}, which first extended such representation to stereo matching. It selected to uniform sample a pre-defined range to generate the next stage’s disparity search range. Instead, we employ uncertainty estimation to adaptively adjust the next stage pixel-level disparity searching range and push the next stage's cost volume to be predominantly unimodal.

% The single-feature cost volume based network with the form of two-stage refinement \cite{mcvmfc} and pyramidal towers \cite{madnet} first employ multi-scale cost volume for stereo matching. Recently, to alleviate the high computational complexity and memory consumption when employing multi-feature 4D cost volumes, \cite{cvpmvsnet, cascade, uscnet} propose to use cascade cost volume representation in multi-view stereo, which generally predict an initial disparity at the coarsest resolution of the image. Then, the disparity search space is narrowed down and the disparity is gradually refined. More closely related to our approach is Casstereo \cite{cascade}, which first extended such representation to stereo matching. It selected to uniform sample a pre-defined range to generate the next stage’s disparity search range. Instead, we employ uncertainty estimation to adaptively adjust the next stage pixel-level disparity searching range and push the next stage's cost volume to be predominantly unimodal.

% Figure environment removed

\subsection{Robust Stereo Matching} 
There exist three categories of generalization definitions for robust stereo matching. 1) Cross-domain Generalization: the network’s ability to perform well on unseen scenes (cannot see the image pairs of the target domain in advance). Towards this end, Jia et al \cite{sungeneralizaiton} propose to incorporate scene geometry priors into an end-to-end network. Zhang et al \cite{dsmnet} introduce a domain normalization and a trainable non-local graph-based filter to construct a domain-invariant stereo matching network. 2) Adapt Generalization: the network’s ability to adapt pre-trained models to the new domain with unlabeled target data. Previous work usually pre-trains the models on synthetic data and then adapts it to new target domains with Graph Laplacian regularization \cite{zoom}, non-adversarial progressive color transfer \cite{adastereo}, and Knowledge Reverse Distillation \cite{aohnet}. More closely related to our approach are \cite{aohnet, unsuperviseddomainadaptation} in stereo matching and Monoresmatch \cite{monoresmatch} in monocular depth estimation, which also proposes to generate a pseudo-label for domain adaptation. However, these methods all select to employ classical stereo matching methods \cite{sgm} alongside with confidence estimators, e.g., left-right consistency check to generate pseudo-labels. That is all these methods need an independent method to generate corresponding pseudo-labels. Instead, the proposed method is an end-to-end network that can generate the predicted disparity map, corresponding uncertainty map and pseudo-labels jointly, which is a more simple, yet efficient way. 
% Instead, our proposed method can employ pixel-level and area-level uncertainty estimation to self-distill the predicted disparity maps of our pre-training model and generate sparse while reliable pseudo-labels to align the domain gap, which is a more simple, yet efficient way. 
3) Joint Generalization: the network’s ability to perform well on a variety of datasets with the same model parameters. MCV-MFC \cite{mcvmfc} introduces a two-stage finetuning scheme to achieve a good trade-off between generalization and fitting capability on multiple datasets. However, it doesn’t touch the inner difference between diverse datasets, e.g, the unbalanced disparity distribution. To further address this problem, we propose a cascade cost volume to adaptively the next stage disparity searching space, where the pixel-level uncertainty estimation is at the core.

% \subsection{Monocular Depth Estimation}
% Monocular depth estimation aims to estimate depth values from a single image, instead of stereo images or multiple frames in a video. This problem is ill-posed because of the ambiguity of object sizes. However, humans could estimate the depth from a single image with prior knowledge of the scenes. Recently, learning based methods were explored to learn depth values by supervised or unsupervised learning. Eigen et al. first employed Convolutional Neural Networks (CNN) to predict depth in a coarse-to-fine manner and further improved its performance by multi-task learning. Liu et al. presented deep convolutional neural fields model by combining deep model with continuous CRF. Li et al. [22] refined deep CNN outputs with a hierarchical CRF. Multi-scale continuous CRF was formulated into a deep sequential network by Xu et al. [45] to refine depth estimation. Unsupervised methods tried to train monocular depth estimation with stereo
% image pairs or image sequences and test on single images. Garg et al. [9] used novel image view synthesis loss to train a depth estimation network in an unsupervised way. Godard et al. [11] introduced left-right consistency regularization to improve the performance of view synthesis loss. Recently, some work also propose to use the stereo matching network as a proxy to learn depth from synthetic data or directly employ traditional stereo matching methods to distill proxies labels from the target domain, which proves the feasibility of distilling stereo matching networks to learn monocular depth estimation.


