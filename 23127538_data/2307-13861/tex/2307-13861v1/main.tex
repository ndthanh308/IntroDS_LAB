%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

% \documentclass[nohyperref]{article}
\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{soul}
\usepackage{subfigure}
\usepackage{booktabs,xcolor} % for professional tables
\usepackage{multirow}
\newcommand{\rc}{\textcolor[rgb]{1,0,0}}
\newcommand{\bc}{\textcolor[rgb]{0,0,1}}
\newcommand{\gc}{\textcolor[rgb]{0,1,0}}
\newcommand{\yc}{\textcolor[rgb]{1,0.8,0}}
\newcommand{\rf}{\textcolor[rgb]{1,0,1}}
\newcommand{\tr}{\textcolor[rgb]{0,1,1}}


% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2022} with \usepackage[nohyperref]{icml2022} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2022}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\topm}{top\mathnormal{-m}}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
% \icmltitlerunning{Submission and Formatting Instructions for ICML 2022}

\begin{document}

\twocolumn[
\icmltitle{Learning to Design Analog  Circuits to Meet Threshold Specifications}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2022
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Dmitrii Krylov}{yyy}
\icmlauthor{Pooya Khajeh}{yyy}
\icmlauthor{Junhan Ouyang}{yyy}
\icmlauthor{Thomas Reeves}{yyy}
\icmlauthor{Tongkai Liu}{yyy}
\icmlauthor{Hiba Ajmal}{yyy}
\icmlauthor{Hamidreza Aghasi}{yyy}
\icmlauthor{Roy Fox}{yyy}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{University of California, Irvine}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Dmitrii Krylov}{dkrylov@uci.edu}
\icmlcorrespondingauthor{Hamidreza Aghasi}{haghasi@uci.edu}
\icmlcorrespondingauthor{Roy Fox}{royf@uci.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Automated design of analog and radio-frequency circuits using supervised or reinforcement learning from simulation data has recently been studied as an alternative to manual expert design. It is straightforward for a design agent to learn an inverse function from desired performance metrics to circuit parameters. However, it is more common for a user to have \emph{threshold} performance criteria rather than an exact target vector of feasible performance measures. In this work, we propose a method for generating from simulation data a dataset on which a system can be trained via supervised learning to design circuits to meet threshold specifications. We moreover perform the to-date most extensive evaluation of automated analog circuit design, including experimenting in a significantly more diverse set of circuits than in prior work, covering linear, nonlinear, and autonomous circuit configurations, and show that our method consistently reaches success rate better than 90\% at 5\% error margin, while also improving data efficiency by upward of an order of magnitude. A demo of this system is available at \href{circuits.streamlit.app}{circuits.streamlit.app}
\end{abstract}


\section{Introduction}

% \begin{itemize}
%     \item Analog circuit design is valuable because..., but it is currently done manually, which is a burden because...
%     \item It was recently proposed to do this with deep RL agent, in a limited variety of topologies, and with a lot of simulation runs
%     \item We propose to do this with supervised learning
%     \item We envision an interface where a user specifies thresholds, we propose a method for constructing the dataset for this
%     \item Outline of experiments, results, conclusions
% \end{itemize}

Owing to the immense growth of consumer electronics over the last few decades, integrated circuitry using commercial CMOS/BiCMOS chip technologies has become a major sector of the semiconductor industry \cite{kamal}.
% \rc{In line with the Chips and Science ACT that was inducted by the US governement in 2022, artificial intelligence should be incorporated to foster next-generation of ``smart circuit design'' to realize non-existing systems due to the human design limitations.} %Following the invention of MOS transistors in 1959 \cite{MOS}, rapid development of circuits with miniaturized dimensions gained a critical momentum and exponential development, commonly evaluated by “Moore's law” \cite{1997moore}. %This rapidly increased density of transistors on CMOS circuits has enabled a large group of applications that heavily rely on analog and digital circuits. 
More specifically, fast innovation and skyrocketing demand in several industry segments, such as wireless communication and high-resolution imaging systems, has been driving interest in analog, radio-frequency, and millimeter-wave circuits and systems \cite{kamal}. %\st{and analog circuits into focus %of many industrial and academic groups 
%and it is currently one of the major focuses of the integrated circuit design industry~}.
Despite the economic and technological importance of these types of circuits, %the component of human-to-machine interaction to improve the performance and reduce the design duration, has not been matured proportional to the advances in technologies and the metrics of the circuits. Still in 2022, many research groups (us included) and 
contemporary design in research and industry  is still predominantly manual, using advanced electronic design automation tools such as the Cadence Virtuoso \cite{cadence} and the Keysight ADS~\cite{keysight} circuit simulators.
This heavy reliance on human design slows down and raises the costs of the development of future generations of electronic systems and should inevitably shift toward a more interactive design approach where humans and machines co-design analog circuits substantially faster.

A recent growing literature on automated circuit design has considered the problem of finding the parameters of components in a given circuit that would induce a desired set of performance metrics \cite{mina2022}.
Learning to output such circuit parameters is typically framed in the supervised learning setting, where a model in a given model class — often a neural network — is trained on a dataset of simulated parameter–metrics pairs to solve the \emph{inverse problem} of mapping target performance metrics to circuit parameters that meet these requirements.
%It has recently been proposed to address the same problem with reinforcement learning, where an agent is trained to perturb the inputs to a circuit simulator to meet observed performance metrics.
%In this approach, a dataset of parameters–metrics pairs is first collected by simulating the circuit a large number of times, each with different circuit parameters, and measuring the resulting performance in each simulation.
%Then a model is trained on the \emph{inverse problem} by feeding the metrics as inputs and predicting circuit parameters that minimize a loss from the ground-truth parameters that induced the input metrics.
%The simulator is executed after each perturbation and the agent obtains a reward shaped to encourage having the performance measured by the simulator meet the performance targets.
A limiting factor in this approach is the large number of times that the circuit needs to be simulated to collect enough data for accurate learning. %, both during training and during execution\rf{is this true?}.
As we aim to support larger and more intricate circuits, precise simulation becomes slow, and data efficiency requisite.

%We propose a supervised learning method that directly solves this \emph{inverse problem} by regression.
%Given a simulator that takes in circuit parameters and measures the circuit performance, we trains a model to map target performance metrics as inputs into circuit parameters as outputs.
%We hypothesize that, for a large variety of useful circuit topologies and a wide range of performance metrics, this inverse function is smooth and regular enough to learn from a relatively small number of examples obtained by circuit simulation.
%Supervised learning offers significantly higher data efficiency than reinforcement learning by focusing the training data on the relevant region of circuit parameter space, and does not require multiple simulator interactions during execution.

We address two inverse problems.
For the simpler one, described above and formalized in \cref{sec:prob1}, a dataset is created by simulating a circuit with parameter values on a grid that covers a user-specified range.
%The performance metrics measured by the simulator are stored in the dataset alongside the parameter values that induced them.
A neural network is then trained on this data to predict circuit parameters that would induce a desired performance vector.
We evaluate this approach on a much larger variety of useful circuit topologies than has previously been done, and show that this inverse function is smooth and regular enough to be approximated from a much smaller number of examples than achieved before, namely around 600–4000 points, depending on circuit complexity, compared with 10,000 to 40,000 points in prior work~\cite{datasize_1,datasize_2,datasize_3,datasize_4}.

However, this approach has severely limited usability, because it requires the user to make a rather precise guess of a feasible combination of performance metrics for the model to recover.
As the number of metrics of interest grows, in more complex circuits, the task of precisely specifying all metrics becomes daunting.
We instead envision an interface for a user to specify a vector of performance \emph{thresholds}, and propose a second inverse problem of mapping these thresholds into circuit parameters that satisfy them (\cref{sec:prob2}).
While this problem is natural for reinforcement learning algorithms \cite{2020autockt}, we propose a novel \emph{supervised learning} method for constructing, from the same simulation data as in the simpler problem, a dataset for training and evaluating a model that predicts threshold-satisfying parameters.
We show that training a neural network on this dataset solves this harder inverse problem an order of magnitude more efficiently than existing reinforcement learning methods, the latter using between 5500 and 40,000 simulations~\cite{2018learning,2020autockt}.
% \gc{In the next section, we will present the problem statement and the proposed approach, in Section 3, we will study the related work and compare their performance to our approach. In Section 4, the two deployed methods are explained and the experimental results are provided in Section 5. The paper is concluded in Section 6.}

This work contributes: (1) a novel and vastly more data-efficient method for generating, from circuit simulation data, a dataset for supervised learning of circuit design agents for the threshold specification problem; and (2) the to-date most extensive evaluation of automated circuit design methods on a diverse set of analog and radio frequency circuits, demonstrating the success of the method while also identifying a challenging circuit topology for future research. A demo of our proposed system is available at \href{circuits.streamlit.app}{circuits.streamlit.app}. 
%Our study demonstrates that the proposed method for automated circuit design is highly efficient and requires minimal data points for model training. 
%We compare previous methods with our work on a more diverse set of  analog and radio frequency circuits, which verifies that our method is versatile and applicable to various circuits.
% \rf{summarize contributions}


\section{Problem Statement}\label{sec:prob}

    Human design through the use of advanced electronic design automation (EDA) tools \cite{survey2} is currently the primary method for designing electronic circuits.
    However, human-led design is a slow process and is falling behind the human–computer co-design processes for digital circuits~\cite{genetic}.
In order to bridge the gap and allow for faster design of analog circuits, we aim to facilitate a system that can automatically generate the parameters of an analog circuit to meet a set of performance requirements.
A good system should be able to function with good accuracy across a variety of different circuit topologies.
In this paper, we therefore examine the problem of designing a diverse group of analog circuits, including single-stage amplifiers, multi-stage operational amplifiers, power amplifiers, low-noise amplifiers, nonlinear circuits such as mixers, and autonomous circuits such as voltage-controlled oscillators.
It is noteworthy that the selected performance metrics, themselves diverse across the various circuits, exhibit different kinds of correlations and tradeoffs. 

%% Figure environment removed

%in the selected circuits to rule out any architecture-dependent performance.

% % Figure environment removed

\subsection{Exact Specification}\label{sec:prob1}

For a specified circuit topology, let $n$ be the number of component parameters, such as resistances, transistor widths, and voltages.
Let $X_1, \ldots, X_n$ be the operational ranges of each of these parameters, and $X = \bigtimes_{i=1}^n X_i$ the design space.
We assume the availability of a simulator $f: X \to Y$, where $Y = \mathbb{R}_+^k$ is the positive orthant of the real vector space of $k$ performance metrics of interest.

The problem of design from exact specification is that of finding a function $g \approx f^{-1}: Y \to X$ such that, when a user specifies target performance $y \in Y$, the system can suggest a design $\hat{x} = g(y)$.
Upon suggesting $\hat{x}$, it can be simulated to measure its performance $\hat{y} = f(\hat{x})$.
The \emph{error} of the system is measured by the relative difference in its performance metrics
\begin{equation}\label{eq:acc1}
\delta_i = \frac{|y_i - \hat{y}_i|}{y_i}.
\end{equation}
For evaluation, the relative error is averaged across multiple test points as well as across the $k$ metrics.
% Since real-world applications can typically tolerate accuracy in the ballpark of 5\% before this source of error begins to dominate other sources \rf{cite}, we also report the system's \emph{success rate} as the fraction of test points with error within the $\epsilon \le 0.05$ margin, element-wise.
We also measure the \emph{success rate} as the fraction of test points with relative error within a given margin.

We note that, in a real-world system, users can input a target performance vector $y$ for which no circuit exists with low error.
The system can use the simulator to check that the predicted circuit $g(y)$ is incorrect, but it is a hard problem to determine whether another circuit would be correct, particularly if the instance is out-of-distribution for the data used to train the system.
We therefore focus on evaluating the system on in-distribution data $y \in f(X)$, and leave the challenging and interesting question of out-of-distribution generalization to future work.


\subsection{Threshold Specification}\label{sec:prob2}

%\bc{While being able to meet an exact set of performance metrics is a crucial step for automatic analog circuit design systems, there exists a larger problem we also wish to address. Many circuit design problems are a question of minimizing or maximizing the different performance metrics. As such a system must be able to address these requests.  Presently, some machine learning systems exist that can predict circuit parameters that create the exact performance metrics requested with reasonable accuracy \cite{mina2022,2015process,2016modelling,2017op,2018application,2018exploration,2020artificial,2021automated,2019power,2018learning,2020autockt} Further some prior works address the issue of thresholding certain metrics \cite{2018exploration}. However, we propose a novel method that achieves good accuracy while using less data than prior works. Shown in Figure \ref{PS} is the design-flow of our approach ...} 

When manual circuit design is challenging, guessing a feasible performance vector $y \in f(X)$ can be just as challenging, particularly if it consists of many metrics that are subject to intricate tradeoffs.
Instead, it would be easier for a user to specify performance thresholds that the designed circuit should meet.
We denote by $\lambda_i$ the threshold direction of metric $i$, i.e. $\lambda_i = 1$ or $-1$ respectively whether it is majorative (the more the better) or minorative (the less the better).


% Figure environment removed

The problem of design from threshold specification (\cref{fig:problem}) is that of finding a function $g: Y \to X$ such that, when a user specifies target performance thresholds $y \in Y$, the suggested design $\hat{x} = g(y)$ aims to meet the thresholds $y$ by having its simulated performance $\hat{y} = f(\hat{x})$ satisfy $\lambda \hat{y} \ge \lambda y$ element-wise.
The error of this system is measured by the relative amount of threshold violation
\begin{equation}\label{eq:acc2}
\delta_i = \frac{\max\{\lambda_i(y_i - \hat{y}_i), 0\}}{y_i}.
\end{equation}
As before, we measure success rate by the fraction of test data for which the  thresholds for all metrics are met up to a given error margin.

To evaluate a system solving the threshold specification problem, we should use threshold queries that follow a similar distribution to that of real users.
Leaving user studies to future work, we approximate this distribution by perturbing simulated performance metrics similarly to \citet{2018exploration}.
Given the measured performance $y = f(x)$ of a simulated circuit $x$, we sample standard uniform perturbations $u \sim \mathrm{U}^k$ for the $k$ metrics, independent and identically distributed (i.i.d), and use the perturbed vector
\begin{equation}\label{eq:eps}
\tilde{y}_i = (1 - \epsilon \lambda_i u_i) y_i
\end{equation}
as the threshold query.
Here $\epsilon$ is the perturbation magnitude hyperparameter; in this work we use $\epsilon = 0.2$.
Note that, by construction, $\lambda y \ge \lambda \tilde{y}$, so that there always exists a circuit (namely, $x$) that meets the threshold $\tilde{y}$.


\section{Related Work}

\subsection{Digital Circuits vs. Analog Circuits}
Digital circuit automation and computer-assisted design~(CAD) has progressed steadily over the past few decades \cite{digitalcad1, digitalcad2}.
The invariant architecture of the building blocks in digital design allows the application of graph-theoretic approaches that treat the problem of digital circuit design as a graph connectivity problem, which has led to a large body of work in optimization of digital design \cite{optim1, optim2,optim3}.
Analog circuits, on the other hand, involve a set of unique design challenges that are not considered in the digital domain.
First, analog circuits have a broad range of architectures, and each building block may be optimized individually with respect to a performance metric before all the blocks are integrated into the circuit.
Second, in digital design, there is a small set of critical performance metrics and in most cases only power consumption, area, and speed are considered.
In contrast, in the analog domain, a variety of performance metrics are present, and optimization of an analog circuit becomes a higher-dimensional problem.
Third, in analog circuits, passive components such as capacitors, inductors, and resistors are also deployed, completely changing the dynamics of the circuit design and weakening the relation between graph-theoretic properties and circuit performance. %This is the major reason that in this paper, we focus on the design of analog and RF circuits. 

\subsection{Automated Analog Circuit Design}

Automating the design of analog circuits has been studied before, particularly in operational amplifiers (op-amps) that are specified by their voltage gain, bandwidth, and power consumption (for a survey, see \citet{mina2022}).
% It is noteworthy \rf{why? does this somehow explain why these are the most popular metrics?}, that one of the most well-known trade-offs in analog circuits is the gain-bandwidth product of an amplifier which comes from the device-centric frequency limitations, i.e., the $f_T$ \cite{ft}.\gc{This inherent trade-off between performance metrics of an amplifier impacts the sample space by ...}
\citet{2018learning} propose a reinforcement learning (RL) approach to designing 3-stage amplifier circuits from threshold specification.
Similarly, \citet{2020autockt} adopt RL to design 2-stage operational amplifiers.
While RL is readily amenable to threshold constraints, it suffers from poor data efficiency compared with supervised learning approaches~\cite{mina2022}.
\citet{2015process} use supervised regression to design another type of circuits, a 4-bit current-steering Digital-to-Analog converters (DAC), from exact specification of the performance metrics.
Other works have used supervised learning to design various op-amps~\cite{2020artificial,2018exploration,2021automated} with varying — and often incomparable — data efficiency~\cite{mina2022}.

In this paper, we step beyond the scope of op-amp design to additionally investigate the design of other critical analog circuit blocks, in particular radio-frequency electronic circuits that are commonly used in cellular communication applications \cite{razavi}. It is noteworthy that some of the selected circuits, e.g., mixers and oscillators, are among the most nonlinear analog circuits with high sensitivity to variations in design parameters.
We further show that design agents for amplifiers as well as more intricate circuits can be learned by supervised regression from much smaller datasets than previously accomplished.
Finally, we learn to design these circuits from threshold specification, in contrast to most previous supervised learning works.
\citet{2018exploration} previously considered this setting, and proposed a method that we reproduce in this paper under the name $D^m_\epsilon $.
We show that this method can lead to suboptimal performance, analyze the reason through an ablation study, and propose a new method that mitigates this issue.


\section{Method}

% Figure environment removed

We use supervised learning to approximate the inverse of the simulator function mapping circuit parameters to performance metrics (\cref{fig:method}).
We interface an external simulator to generate
%NgSpice takes in a netlist and some parameters in order to generate a dataset used for training. 
a dataset $D_0$ consisting of circuit parameter vectors $x \in \mathbb{R}^n$ and their respective measured performance metrics vectors $y \in \mathbb{R}^k$.
We (optionally) pass this dataset through a filtering pipeline that prepares it for solving the threshold specification problem (\cref{sec:prob2}).
Finally, we employ a supervised learning algorithm, such as gradient-based optimization, to train a design agent.
%We then use the Adam optimization algorithm~\cite{adam} to train a neural network that takes in the performance metrics $y$ and outputs a prediction of what circuit parameters $\hat{x}$ would achieve the target performance $y$.
In this section we describe the system components: the simulator, the agent model, and several alternatives for the filtering pipeline. 
%The next section details the evaluation experiments and their results.
%Once trained, the network to take in any performance for the circuit it was trained for and output the parameters that make the requested performance. 

\subsection{Simulator}\label{sec:sim}

In this work, we use the NgSpice simulator \cite{ngspice}.
The circuit topology and its fixed parameters, as well as the simulation parameters, are provided to the simulator via a format called netlist \cite{netlist}.
In addition to the netlist, the simulator loads analysis commands that determine how it measures the performance metrics of interest.
For some circuits, multiple analysis commands are given to measure the circuit under distinct conditions.


The external simulator is wrapped by a Python interface to allow easy access to two functionalities.
First, to generate simulation data, a user inputs the range and step size of each circuit parameter, and the simulator loops through this grid to output a dataset $D_0$ of parameter–metrics pairs.
Second, to evaluate the trained model, predicted circuit parameters are input to the simulator, and the measured performance is compared with the target performance.
%, and it can be con-
%trolled by command window which means having well interface with python. Netlists and parameter
%ranges are determined by virtuoso. Reformat the netlist in a .sp file and use ngpsice language to edit
%analysis section. There are two files which are training and testing files for each circuit. Training
%file Generates the data for network to learn, and the parameter ranges will be provided. Testing file
%check the accuracy of parameter predictions.Ngspice can load the circuit file which contains the netlist and analysis command, and it can be controlled by command window which means having well interface with python.
%
%\aqc {In addition to loading circuit files that contain netlists and analysis commands, NGSPICE can be controlled by command windows, which implies a well-integrated Python interface. Netlists and parameter ranges are determined by Cadence Virtuoso.  An analysis section has been added to the netlist by reformatting it for NGspice. Testing analog circuits may require several test benches; similarly, different performance metrics  analyses may require different netlists. Upon simulation results approval, the netlists are applied for training.}


\subsection{Agent Model}\label{sec:model}

Before the raw data from the simulator can be put through the model, we apply a few data pre-processing steps.
The different features of the data have vastly different scales.
In order to allow the model to learn across such different scales, we first shift and scale all values to the range $[-1,1]$.
%In more detail, we scale each feature in the training data (both parameters and performance measures) according to their highest and lowest values. This way all the features have consistent range and values, enabling faster learning. 
This normalization is applied both to the performance metrics before they are fed to the model and to the ground-truth circuit parameters used for training, and an appropriate inverse operator is applied to the model's parameter predictions.  

In this work, we experiment with three different agent models.
The main model is a neural network with an architecture of a simple multi-layer perceptron, trained with the Adam optimizer~\cite{adam}.
%The experiments described in Section 5 involve differing numbers of circuit parameters and performance metrics.
The network takes in a vector of desired performance metrics and predicts a vector of circuit parameters, which is then compared with the ground-truth parameters using an absolute ($L_1$) loss.
The sizes of the first and last layers of the network are adjusted to reflect the number of performance metrics and circuit parameters, respectively, which are different for each experiment described in \cref{sec:exp}.
The architecture is otherwise constant across experiments and detailed in Appendix \ref{appendix_a}.
An alternative model we consider is ensembles of decision trees trained with the Random Forests algorithm~\cite{breiman2001random}.
Finally, to assess the need for any learning at all, we compare with a lookup method that memorizes the training data and selects, for each test performance vector, the training circuit that minimizes the relative performance error.



\subsection{Filtering Pipeline}

The problem of design from exact specification (\cref{sec:prob1}) can be solved by supervised learning, in which the training set is the simulation dataset $D_0$, inverted so that performance metrics $y$ are inputs and circuit parameters $x$ are outputs.
However, this method is unlikely to be sufficient for the threshold specification problem (\cref{sec:prob2}), in which some threshold vectors are out-of-distribution for $D_0$, because no circuit has them as its exact performance.
We therefore propose a filtering pipeline that constructs, from the same $D_0$, a second dataset which, when used for supervised learning, trains a model that predicts circuit parameters from threshold specification.

%We propose to address the two problems stated in \Cref{sec:prob} using supervised learning from simulation data.
%The problem of design from exact specification can be solved by simply learning directly from the simulation data.
%However, for the harder problem of design from threshold specification, there is the question of constructing an appropriate training pipeline.
%We discuss our proposed methods below.
%%In order to address our two stated problems, we define two separate but similar methods in order to train and evaluate the agent. The first method trains and evaluates an agent's ability to predict the exact requested value. The second method uses a modified dataset to train an agent to output the parameter predictions $\hat{x}$ that maximize or minimize each parameter according to a predefined hierarchy. 
%
%
%\subsubsection{Exact Specification}
%
%Our first method uses a standard supervised learning approach to train a neural network on a regression problem.
%We start with a dataset consisting of circuit parameters in a grid and their measured performance metrics, as described in \Cref{sec:sim}.
%% The data we train on is generated using the external simulator NgSpice. In order to simulate the desired circuit. The agent must be provided with the correctly formatted Netlist as described in Section 4.1. In addition to a Netlist the agent needs information describing the range of each parameter. For each parameter $x$ the network requires a high and low value to specify the bounds of the range, as well as a step parameter to determine the spacing along each parameter range.\rf{how is spacing along each parameter range selected?}. Using these parameters, the Simulator generates the training data $D: x->y$. The network then takes in the performance $y$ from the data set. And makes a prediction of the parameters $\hat{x}$ that would create the requested performance $y$ originally fed to the network. 
%The network is then trained on the inverse relation (metrics $\to$ parameters) with an $L_1$ loss between the predicted and ground-truth parameters.
%
%The learned network is evaluated using 10-fold cross-validation.
%Namely, 10 disjoint subsets of the data are each held out to test the model trained on the other 9 subsets, and the results are averaged over these 10 models.
%In addition to measuring the training and test $L_1$ losses, we also feed the circuit parameters predicted for each test data point into the simulator and report the accuracy (\ref{eq:acc1}) with respect to the target performance.
%Finally, we compute the fraction of test data points for which the accuracy is 5\% or better, and report it as the method's success rate.
%
%%The end goal of this system is to output parameters for the simulated circuit that produce a requested performance in the circuit. Therefore, instead of evaluating the network's predicted parameters $\hat{x}$ we feed $\hat{x}$ back to the simulator S. The simulator then gives us the true performance $\hat{y}$ of the network's predictions $\hat{x}$. Thus the final pipeline is defined as follows: $D: (x,y), NN(y) -> \hat{x}, S(\hat{x}) -> \hat{y}$. Finally in order to determine if the network can produce the parameters necessary to achieve the desired performance, we evaluate the true performance $\hat{y}$ of the network's predicted parameters x. We compare $\hat{y}$ to the original requested performance y. We say that if $\hat{y}$ is a valid prediction if it is within $x\%$ of the original performance y, or if $|y’-y| < x/100$\rf{is this correct? there's a different term later in this paragraph}. We give our predictions this $x\%$ tolerance because it is common practice in the circuit design process to allow a certain amount of error in the specifications of a circuit. In this paper we will allow for a $5\%$ error margin in our specifications as a standard. So we say $\hat{y}$ is correct if $|\hat{y}-y|/y < 0.05$. We call this $5\%$ our accuracy level. 
%
%
%\subsubsection{Threshold Specification}
%
%%With this first pipeline we train a network to output the desired performance as precisely as possible; meaning no higher or no lower than the requested performance. 
%Circuit designers often need to meet certain performance thresholds rather than exact values.
%Some metrics, such as gain or bandwidth, need to be above a threshold, and the higher they are the better; while others, such as power consumption, need to be below a threshold, and the lower the better.
%%For example, a specification may ask for as high a gain as possible while minimizing power consumption. 
%Some specifications may further have a preference order over metrics, such that different performance metrics have different levels of importance. %, such that optimizing one takes precedence over optimizing another, as long as both meet their thresholds.
%A specification asking for the most gain at power consumption at most $p$ can be different than one asking for the least power consumption that achieves gain at least $g$.
%The method of the previous section cannot address this problem.

To prepare a circuit for the threshold specification problem, two properties of the metrics vector need to be provided.
First, because some metrics, such as gain or bandwidth, are majorative (the more the better), while others, such as power consumption, are minorative (the less the better), we need to know for each metric $i$ its threshold direction $\lambda_i \in \{-1, 1\}$.
Second, a specification asking for the highest gain at power consumption at most $p$ is different from one asking for the lowest power consumption that achieves gain at least $g$.
We may therefore have a preference order over metrics, such that we lexicographically prefer improving $y_i$ over improving $y_j$, whenever $i < j$, as long as all threshold constraints are approximately met.
We say that $y$ is lexicographically better than $y'$ if there exists $i$ such that $y_j = y'_j$ for all $j < i$ and $\lambda_i y_i > \lambda_i y'_i$.


%Should the circuit designer ask for the previous specification: “a minimum of $g$ gain and while using at most $p$ power” they can only ask the agent for $g$ gain and $p$ power. The agent will then return a set of parameters $\hat{x}_1$ that give as close a $g'$ and $p'$ to the original request as possible. Even if there exists an $\hat{x}_2$ that produces significantly more gain than $g'$ while using the same $p'$, the agent will not output it because it was trained to return as precise a value as possible without regard to maximizing or minimizing any performance metric. 
%For this reason we propose a second pipeline that can address the problem of optimizing different parameters. This second pipeline is identical to the one described previously except for two key differences: we adjust the dataset before training, and use a different method of evaluation. The network, simulator, and training method are all consistent.

%We propose to construct, from the same simulation dataset as above, a second dataset which, when used for supervised learning, trains a model that predicts circuit parameters from threshold specifications.
%In addition to the parameter ranges and step sizes that define the simulation grid, constructing the second dataset requires a user to specify for each performance metric whether it is majorative (the more the better) or minorative (the less the better); and an importance order between the metrics.
%%In this second pipeline adjustments are made to the raw training data returned from the simulator. The agent can now accept input for whether each performance metric should be minimized or maximized, and an order of importance for the metrics.  
%The construction of the new dataset $D'$ from a simulation dataset $D$ is then define as follows.

The filtering pipeline starts by finding, for each performance vector $y \in D_0$, all \emph{feasible} performance vectors $y' \in D_0$ that meet the threshold specification $y$, i.e.
\begin{equation}
F(y; D_0) = \{(x, y') \in D_0 | \lambda y' \ge \lambda y\}.
\end{equation}
The design agent needs to map the threshold specification $y$ to one such $x \in F(y)$, but it may not be immediately clear which one.
We hypothesize that, crucially to learning with high success rate from small datasets, our training dataset must be systematic in selecting a representative of $F(y)$.
This systematicity manifests as a pattern that the learning algorithm can generalize, whereas including the entire $F(y)$ or selecting from it sporadically might lead to conflicts that impede generalization.

We propose to select the lexicographically best training-set circuit that meets the threshold
\begin{equation}
\bar{D}^*_0 = \{(x, y) | y \in D_0, x = \argmax F(y; D_0)\},
\end{equation}
where we select for $x$ a single representative $(x, y')$ of $F(y)$ that maximizes $y'$ lexicographically.
In the notation $\bar{D}^*_0$, the bar denotes feasibility of $x$ for $y$ and the star denotes selection of the best representative.
%With $(x_0, y'_0)$ this representative, we add $(x_0, y)$ to $D'$. {\color{yellow} Maybe we should clarify this method more. For example, why can't we just add $(x_0, y')$}

We note that, by definition, all members of $F(y)$ have good circuit parameters that meet the threshold $y$.
However, adding all of them to our training set, similar to the method proposed by~\citet{2018exploration}, would create conflicts where the same network input $y$ is mapped to different outputs. 
%{\color{teal} We examine the effects of having these conflicts in the method titled All Epsilon Feasible in the results.}
By breaking “ties” in a consistent way — and in accordance with user-specified preference over metrics — we create a dataset more conducive of learning.
The new dataset $\bar{D}^*_0$ has the same size as the simulation dataset $D_0$ and the same set of performance vectors. 
The circuit parameter vectors in $\bar{D}^*_0$ are those that define its Pareto frontier, that is, for which no other simulated circuit is better in all performance metrics.
Thus, $\bar{D}^*_0$ consistently maps feasible performance vectors to frontier circuits.
%{\color{teal} We refer to this dataset construction method as Best Feasible in later sections.}

%{\color{yellow} Here we need to add information about SoftArgmax, Ablation and Lourenco methods}


\subsubsection{Threshold Queries}

In \cref{sec:prob2}, we discussed how performance metrics measured in simulation are perturbed to generate threshold queries (Eq. (\ref{eq:eps})).
We denote thus perturbed data by
\begin{equation}
D_\epsilon = \{ (x, (1 - \epsilon \lambda u)y) | (x, y) \in D_0, u \sim U^k \text{ i.i.d} \}.
\end{equation}
Note that the distribution of threshold queries $y \sim D_\epsilon$ is different than the distribution of simulated metrics vectors $y \sim \bar{D}^*_0$.
To avoid a mismatch of the training and test distributions, we combine the filters to form a dataset of threshold queries with a principled selection of target circuits:
\begin{equation}\label{eq:method}
\bar{D}^*_\epsilon = \{ (x, \tilde{y}) | \tilde{y} \in D_\epsilon, x = \argmax F(\tilde{y}; D_0) \}.
\end{equation}
$\bar{D}^*_\epsilon$ is a dataset mapping $\epsilon$-perturbed metrics vectors $\tilde{y}$ to circuits whose (unperturbed) simulated metrics are feasible for the threshold query $\tilde{y}$, selecting the lexicographically best such circuit.


\subsubsection{Baseline and Ablation}

We compare our dataset construction methods, $\bar{D}^*_0$ and $\bar{D}^*_\epsilon$, with a baseline that closely follows~\citet{2018exploration}.
We define $D^m_\epsilon$ as the union of $m$ i.i.d. samples of $D_\epsilon$
\begin{equation}
D^m_\epsilon = \bigcup_{t=1}^m D_\epsilon[u_t]; \quad u_t \sim U^k \text{ i.i.d}.
\end{equation}
In our experiments, $m = 20$.
The reasons are that by construction, in each $(x, \tilde{y}) \in D^m_\epsilon$ the circuit $x$ is feasible for the threshold query $\tilde{y}$, i.e. $\lambda f(x) \ge \lambda \tilde{y}$ ;
and that the training distribution $\tilde{y} \sim D^m_\epsilon$ is identical to our evaluation distribution $\tilde{y} \sim D_\epsilon$.
Note that, in contrast to most of the literature on analog circuit design automation via supervised learning, which employs a simulation dataset akin to $D_0$, $D^m_\epsilon$ is suited for the threshold specification problem~\cite{2018exploration}.

Unfortunately, the dataset $D^m_\epsilon$ can be very confusing to learn from.
Because the simulator function $f$ is not necessarily injective, there may exist multiple circuits with similar performance vectors.
Moreover, such vectors have overlapping supports of their perturbation distributions.
The result is that $D^m_\epsilon$ will tend to have similar threshold queries mapped to vastly different circuit parameters, rendering their prediction difficult.

We propose an ablation that more directly demonstrates this issue.
In $\bar{D}^m_\epsilon$, we select for each $\tilde{y} \in D_\epsilon$ the $m$ lexicographically-best feasible circuits, rather than only the single best in $\bar{D}^*_\epsilon$ (Eq. (\ref{eq:method})):
\begin{equation}
\bar{D}^m_\epsilon = \{ (x, \tilde{y}) | \tilde{y} \in D_\epsilon, x \in \topm F(\tilde{y}; D_0) \}.
\end{equation}
We expect this method to perform suboptimally, more similarly to $D^m_\epsilon$ than to $\bar{D}^*_\epsilon$.
This would provide evidence that the main aspect impacting the prior method, compared with the novel one, is the existence of multiple targets for each query, rather than the other differences — namely, the selection of circuits from the feasible set $F(y)$, or the preference of lexicographically better circuits.

To summarize, we consider six datasets: (1) $D_0$ is the simulation data; (2) $D_\epsilon$ has perturbed performance metrics that resemble the threshold query distribution, and is used for method evaluation; (3) $\bar{D}^*_0$ and (4) $\bar{D}^*_\epsilon$ are our proposed methods, without and with perturbation to match the test distribution; (5) $D^m_\epsilon$ is a baseline similar to~\citet{2018exploration}; and (6) $\bar{D}^m_\epsilon$ is an ablation study.
% We experiment with these datasets in the next section.

%{\color{teal} In comparison to Best Feasible we also define and test five other dataset construction methods: Base, Epsilon Base, Best Epsilon Feasible, All Epsilon Feasible and K Epsilon Feasible. In these methods we define and use a process called $\emph{ScaleDown}$. Given a dataset $D$ and percent $\epsilon$, $\emph{ScaleDown}$ reduces each $y \in D$  such that $y' = y*\sigma$ where $\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_k) \sim uniform(0,\epsilon), k = \left\| y \right\| $. }
%
%{\color{teal} We define the method named Epsilon Base as the ScaleDown process applied to the original simulator dataset $D$, where $\epsilon$=0.2 such that: $D_{EpsilonBase} = ScaleDown(D, 0.2)$. 
%Further, we define Best Epsilon Feasible as the Best Feasible method, as described before, applied to this Epsilon Base dataset such that $D_{BestEpsilonFeasible} = BestFeasible(D_{EpsilonBase})$.
%The K Epsilon Feasible method is also constructed from the Epsilon Base dataset.
%The K Epsilon Feasible dataset is designed as an ablation study intended to show the effects of adding all parameters $x$ that create a performance $y'$ greater that the requested $y$ to the dataset.
%Like with to Best Feasible, we find $A(y) = \{(x, y') \in D | y' \ge y\}$ where the comparison is element-wise, lexicographic, and according to the majoritive or minorative.
%However, rather than selecting a single representative that maximizes $y'$, we select the top $d$ circuit parameters $x$ for each $(x,y') \in D_{EpsilonBase}$ and adds them to the new $D_{KEpsilonFeasible}$ dataset. In our experiments we set $d=20$.}
%
%{\color{brown} Lastly, the Lorenco method, which is inspired by \tr{cite \& verify}. For each $(x,y) \in D_{Base}$, we first add $(x,y)$ into $D_{Lourenco}$, then for K times, we modify the performance such that $y' = y + \sigma * \delta * \mu * \gamma$, where $\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_k) \sim uniform(0,1)$, $\delta$ is a hyper-parameter where we set to 0.15 in the experiment.  $\mu$ is the average performance for each performance metrics and $\gamma$ represent the sign of performance (majorative performance metrics will be 1 and minorative performance metrics will be -1). And add $(x,y')$ into $D_{Lourenco}$}
%
%
%%For every parameter performance set d: (x,y) in dataset $D$, we loop through the dataset again and find the best d’: (x’,y’) that gives the most optimized performance according to the predefined list. In the case of a tie between two points d1’ and d2’ we use the predefined order of importance of the measures. After selecting the best d’ in the dataset we replace the parameters x in d with the new parameters $\hat{x}$ in d’. This new dataset $D’$ now contains the original range of performances, but where optimization is possible the new parameters that create this optimization are present. The dataset $D’$ is then used to train the neural network with the same architecture and training as before. When the network is trained on a datapoint (x,y), if there exists a more optimized performance in the original dataset $D$ the network's target will be $\hat{x}$ (or the parameters that create the more optimized performance. 
%
%%During training, if there exists a more optimized performance for the original datapoint (x,y), the network will be trained using $y$ as its input and $\hat{x}$ (the parameter that creates the optimized performance) as its target. In turn the true performance of the trained networks output parameters will be closer to the most optimal performance seen in the original dataset. Now the network is not expected to always output parameters that achieve the closest possible performance to the one requested. Thus it is no longer valid to evaluate the network in the same manner. Instead it is only necessary to determine whether the new simulated performance is above or below the requested maximum or minimum. Again we keep the same margin of error so that the evaluation metric is $\hat{y}$ is correct if: if max: $\hat{y} > 0.95*y$, else $\hat{y}<1.05*y$.
%
%Training on the transformed dataset now proceeds as before, using the same network architecture and cross-validation evaluation.
%Accuracy is measured using (\ref{eq:acc2}) and success rate accordingly.
%As is usually done in supervised learning, performance is not evaluated and not guaranteed for out-infeasible performance vectors {\color{yellow} \rf{in Conclusion, say that future user studies are needed to evaluate the method on actual user-provided thresholds}.} {\color{teal} All of the experiments below are performed on expert selected circuits and thresholds, further studies are necessary to evaluate the method on user-provided thresholds. }


\section{Experiments}\label{sec:exp}

We experiment with our methods on a diverse group of seven circuit topologies, detailed below. Best practices in circuit design suggest that circuit parameters are chosen based on their impact on performance metrics ~\cite{Bandler1988,hassan2016novel,Bandler2023}. Only these parameters are used to optimize performance for each circuit.
We simulate each circuit in a parameter grid consisting of approximately 4000 points, except for the simplest two-stage amplifier with around 600 points, as presented in Table \ref{train-data} in Appendix \ref{appendix_f}.
A schematic of each circuit shows the range and step size of each variable parameter, as well as color-coded tags illustrating the diversity of the circuits to which our method applies. To facilitate result reproduction, the code and data used in our experiments are available at github. \footnote{https://github.com/indylab/Circuit-Synthesis} The supplementary details of the circuits employed in our experiments can be found in Tables \ref{range_1}, \ref{range_2}, and \ref{range_3} in Appendix \ref{appendix_f}.

Our main method uses the $\bar{D}^*_\epsilon$ dataset to train a neural network and evaluate its success rate in 10-fold cross-validation.
For each circuit topology, we perform three comparisons of this method.
First, we compare the main method with the five other data construction methods described in the previous section.
Second, we compare the gradient-based learning algorithm with Random Forests and a simple lookup method~(\cref{sec:model}).
Third, %after an exploratory search for the amount of simulation data that is sufficient to successfully train a network for each circuit, 
we study the sensitivity to the amount of training data by varying it.
We compare the success rate of 10-fold cross validation, which uses 90\% of the data for training each fold, with using 5\%, 10\%, 20\% and 50\% of the data for training.
We do this by randomly splitting the data into (respectively) 20, 10, 5, and 2 disjoint subsets, training on one subset, testing on the rest, and then averaging the result across the splits.

In all plots in this section, the solid curve is the average over 10  runs of data splitting and training, and the shaded area is the standard-error of the mean (SEM) over those runs.

% To demonstrate the efficiency of our method, we choose to evaluate the result on 90 percent, 50 percent, 20 percent, 10 percent, and 5 percent of training data. Similar to cross-fold validation. For each training data percentage, we split the data into different folds, and train on one fold while evaluating on all other folds. 

%Besides training a model on those data, we also did a baseline evaluation where for every validation data, instead of training a machine learning model, we try to find parameter design that satisfies the performance requirements directly in the training data. 

%\subsection{Result Visualization}
%
%In this section, we describe the circuit topologies on which we experiment.
%For each, we show a schematic of the circuit marked with the ranges and step size of its parameters.
%Color-coded tags illustrate the diversity of the circuits to which our method applies.
%
%\yc{We then include three plots of the result for the Common Source Amplifier, and we compare margin accuracy for different data generation methods for each circuit}
%
%% \begin{enumerate}
%% 	\item {\color{brown} Margin accuracy comparison across different data sizes}
%% 	\item {\color{brown} Margin accuracy comparison across different supervise learning method}
%% 	\item {\color{brown} Margin accuracy comparison across different data construction method}
%% \end{enumerate}
%
%
%% {\color{brown} We also include \st{three} extra plots in the Appendix section}
%% \begin{enumerate}
%% 	% \item {\color{brown} The train $L_1$ loss throughout training epochs comparison across different data construction method}
%% 	% \item {\color{brown} The test success rate at 5\% accuracy throughout training epochs comparison across different data construction method}
%
%% 	\item { Margin accuracy comparison across different data sizes, training directly on the simulation dataset and without applying ScaleDown method on the testing data} 
%%         \item { Margin accuracy comparison across different data sizes for our method}
%% 	\item {Margin accuracy comparison across different supervise learning method}
%% 	\item { Margin accuracy comparison across different data construction method}
%
%% \end{enumerate}
%    
%In each of the plots, the solid line is the average of different runs and the shaded area is one standard error of the mean across different runs.


\subsection{Analog Voltage Amplifiers}

\subsubsection{Common Source (CS) Amplifier}

Due to its simplicity, the common source (CS) amplifier~(\cref{nmos_cascode}(a)) is among the most popular amplifier configurations using a CMOS transistor.
As design variables, we consider the width of the transistor and the resistance of the load resistor $R_D$.
The target performance metrics, in decreasing importance are: bandwidth, voltage gain, and power consumption.


% % Figure environment removed


% % Figure environment removed

% Figure environment removed

% Figure environment removed


%% Figure environment removed
%
%% Figure environment removed
%
%% Figure environment removed



% % Figure environment removed


% % Figure environment removed


% % Figure environment removed

%% Figure environment removed

% % Figure environment removed

% % Figure environment removed



% % Figure environment removed

% \subsection{Cascode Amplifer}



% \begin{table}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{Nmos Circuit Parameter Training Info}\label{table1}
% \begin{tabular}{|p{3cm}|p{1cm}| p{1cm}| }
% \hline
% \textbf{Parameter/Info} & \textbf{w} & \textbf{r} \\
% \hline
% Parameter start value & 2.88u & 620 \\
% \hline
% Parameter end value & 6.63u & 1450 \\
% \hline
% Parameter step value & 0.2u & 5 \\
% \hline

% \end{tabular}
% \end{table}


% \yc{For the CS Amplifier our model learns the mapping from three different performance metrics to only two different parameters of the circuit. This means that we have to construct a model $f(R^3) \	\rightarrow  R^2$.}
As shown in \cref{res:cs1}, our model achieves near-perfect success at 5\% error margin on the exact specification problem~(\cref{sec:prob1}), even while using 6 times less data than the best previous work \cite{Devi2021}.
In the threshold specification problem (\cref{sec:prob2}), our model trained on the $\bar{D}^*_\epsilon$ dataset also achieves perfect success at 5\% error margin, whereas training on the naïve $D_0$ baseline dataset only achieves 85\% success.
Note, however, that all other data processing methods also achieve perfect success on this simple circuit.
Further results appear in Appendix \ref{appendix_c}.
%\yc{ In the following Figure \ref{p2_nmos1}, using only 5 percent of the training data, the model can achieve accuracy close to 90 percent with a margin of 5 percent}. The two best methods, BestFeasible and BestEpsilonFeasible perform similarly. Random Forest and Neural Network outperformed 1 - Nearest Neighbour by a gap of 5 percent using 90 percent of the data.  


\subsubsection{Cascode Amplifier}

The CS amplifier has limited gain and exhibits a trade-off between critical performance metrics.
The cascode amplifier shown in \cref{nmos_cascode}(b) enhances the amplification bandwidth compared with a CS stage \cite{cascode}.

% Figure environment removed

%% Figure environment removed

% \yc{For the Cascode Amplifier, our model learns the mapping from 3 performance variables to 3 parameters}. 

As illustrated in \cref{res:cascode}, this more challenging circuit shows more sensitivity to the amount of training data, both in (a) the exact specification and (b) the threshold specification settings.
It is also more difficult for the baseline methods to achieve high success rate, particularly when a low error margin is needed: the simulation dataset $D_0$ and the “non-injective” datasets $D^m_\epsilon$ and $\bar{D}^m_\epsilon$ all tend to generate circuits with higher than 1\%, 2\%, and rarely even 5\% threshold violation (\cref{res:cascode3}).
Finally, \cref{res:cascode4} demonstrates the typical underperformance of the lookup method, showing that learning is needed; while also demonstrating an uncommon case where Random Forests slightly underperforms the neural network.
%Unlike the CS amplifier, the baseline method shows a more significant gap of almost 50 percent. We can also see that EpsilonBase performs comparably to our method. 



% \begin{table}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{Cascode Circuit Parameter Training Info}\label{table1}
% \begin{tabular}{|p{3cm}|p{1cm}|p{1cm}|p{1cm}|}
% \hline
% \textbf{Parameter/Info} & \textbf{r} & \textbf{w0} & \textbf{w1}\\
% \hline
% Parameter start value & 200 & 4u & 7u \\
% \hline
% Parameter end value & 500 & 7.5u & 10u \\
% \hline
% Parameter step value & 18.75 & 0.25u & 0.2u \\
% \hline

% \end{tabular}
% \end{table}



% % Figure environment removed



\subsubsection{Two-Stage Amplifier}
The circuits of \cref{nmos_cascode} both suffer from limited gain.
Two-stage amplifiers, as shown in \cref{twostage}, are excellent replacements of single-stage amplifiers and in particular allow simultaneously achieving higher gain and voltage swing~\cite{meyer}.


 % Figure environment removed



% Figure environment removed



%% Figure environment removed


     

% \begin{table}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{Two Stage Circuit Parameter Training Info}\label{table1}
% \begin{tabular}{|p{3cm}|p{1cm}|p{1cm}|p{1cm}|}
% \hline
% \textbf{Parameter/Info} & \textbf{w0} & \textbf{w1} & \textbf{w2}\\
% \hline
% Parameter start value & 25u & 6u & 52u \\
% \hline
% Parameter end value & 30u & 9u & 55.5u \\
% \hline
% Parameter step value & 0.5u & 0.5u & 0.5u \\
% \hline
% \ha{the parameter values are listed in the figures, do we still need these tables?} 

% \end{tabular}
% \end{table}




% % Figure environment removed

Owing to their widespread use, two-stage amplifiers have been among the most popular benchmark circuit configurations examined in prior automation work~\cite{mina2022,2020autockt}.
%; therefore we evaluate our method on this circuit as well.}
% \yc{Two stage amplifier like the Cascode amplifier requires learning  $f(R^3) \rightarrow  R^3$.}
Other than the baseline dataset $D^m_\epsilon$ and ablation dataset $\bar{D}^m_\epsilon$, all other datasets achieve perfect success on this relatively easy circuit (\cref{res:2s}), using 10 times less data than in the best previous work \cite{datasize_1,datasize_2,datasize_3,datasize_4}.
The underperformance of the “non-injective” datasets supports our hypothesis that a systematic selection of representative circuits for similar performance levels is needed to facilitate learning of circuit design agents for threshold specification.
%Stage amplifier achieves similar performance to the BestEpsilonFeasible method. KEpsilonFeasible and AllEpsilonFeasible  have a large gap of 25 and 45 percent compared to BestEpsilonFeasible. }

\subsection{(Non)-Linear Radio Frequency Circuits}
\subsubsection{Low-Noise Amplifier (LNA)}

The cascode low-noise amplifier (LNA) with inductive degeneration is a popular configuration to design an LNA for an RF receiver~\cite{LNASD}. The circuit, depicted in \cref{circuit_LNA_Mixer}(a), can obtain a high gain and minimal loss of input power across a large bandwidth without suffering from additive noise of circuit components (mainly transistors).
This circuit has four parameters (three inductor values and one cascode transistor width) and three metrics: the noise figure (signal-to-noise ratio between the input and output), the return loss, and the power gain.

% \yc{$f(R^3) \rightarrow  R^4$ }

Our findings indicate that the LNA simulation function has a smooth surface, making it easy to invert for all methods, including the baseline, and resulting in perfect success even at very low error margins (\cref{res:lna}).
%Since the LNA circuit performance requirement can be easily met \rc{why is it easy?}, all the methods  including the Baseline achieve almost 100\% test success rate at 0.5\% - 1\% margin. 
Only the ablation method $\bar{D}^m_\epsilon$ performs suboptimally, suggesting that it is even more prone to inconsistencies than the baseline $D^m_\epsilon$.
%We hypothesize that during the data modification phase, \rc{some data with aliasing is generated} which makes the task hard to learn.}


% Figure environment removed

%% Figure environment removed




% \begin{table}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{LNA Circuit Parameter Training Info}\label{table1}
% \begin{tabular}{|p{3cm}|p{1cm}| p{1cm}| p{1cm}| p{1cm}|}
% \hline
% \textbf{Parameter/Info} & \textbf{ls} & \textbf{ld}  & \textbf{lg}  & \textbf{w}\\
% \hline
% Parameter start value & 55p & 3.8n & 14n & 49u \\
% \hline
% Parameter end value & 62p & 6.2n & 17n & 54u 


% \hline
% Parameter step value & 0.6p & 0.6n & 0.4n & 0.5u \\
% \hline

% \end{tabular}
% \end{table}





% % Figure environment removed




\subsubsection{Power Amplifier (PA)}
A wireless communication transmitter requires a power amplifier to amplify the transmitted signal and deliver more power to the antenna, in order to mitigate the propagation loss of the electromagnetic waves and cover a longer operational distance \cite{niknejad}. An efficient design of a two-stage differential cascode amplifier \cite{PAref} that can provide sufficient power gain, while showing efficiency in terms of power consumption, may depend on multiple design parameters (\cref{circuitpa}(a)).

% \yc{$f(R^3) \rightarrow  R^7$ }
%\bc {\color{brown} \st{The second non linear non radio frequency circuits we tested is Power Amplifier, it shows a} 
Similar to LNA, nearly all data filtering methods performed well for the PA circuit, although with higher cross-run variance, with the exception of the baseline $D^m_\epsilon$ and the ablation $\bar{D}^m_\epsilon$ (\cref{res:pa}).
We conclude that both LNA and PA — highly non-linear circuits with intricate tradeoffs, whose design has never before been automated — are easily learned within the operational range tested in this work.
%\rc{Compared to the LNA, we observe a high variance across different runs}.
%We hypothesize that although Power Amplifier is similar to the LNA in that the performance can be easily met, some of the \st{special circuit parameter property} \rc{what is this term?} make it really sensitive to data splitting. We can especially observe this by comparing data size plot \rc{versus something else!?} where 5\% training data \st{have} ]rc{leads} to a huge variance.

% Figure environment removed




%% Figure environment removed

% Inductance of inductors used as transoformators, Width of Transistors in both stages, and $V_b$ are some of the parameters studied in for this topology. Besides, Power Added Efficiency, Power Gain, and Drain Efficiency have been selected  as figures of merit for this Circuit. 

% % Figure environment removed


\subsubsection{Mixer}

An essential component in frequency conversion of modern radio-frequency and millimeter-wave circuits is a mixer.
Given two input signals at frequencies $f_1$ and $f_2$, a mixer %(depending on the type of operation) 
can generate desired signals at subtraction and summation frequencies, i.e., $f_{\Delta}=|f_1-f_2|$ and $f_{\Sigma}=f_1+f_2$. Shown in \cref{circuit_LNA_Mixer}(b) is a common schematic for mixers known as a Gilbert Cell \cite{1049925}. This circuit operates by having radio frequency (RF) and local oscillation (LO) signals as the inputs and multiplying them to generate a signal with the summation or subtraction frequencies.

% \yc{$f(R^3) \rightarrow  R^4$ }
The mixer is a sufficiently complex circuit that different data filtering methods achieve different performance when learning to design it (\cref{res:mixer}).
%By applying different methods on mixer circuit, we can clearly see 
Our proposed method, $\bar{D}^*_\epsilon$, achieves near-perfect success even at very low error margins, and only our other method, $\bar{D}^*_0$, matches it at 5\% error.
Interestingly, the naïve perturbed dataset $D_\epsilon$ also performs much better than the baseline and ablation methods.
%data modification method outperforms other methods, the BestEpsilonFeasible method almost reaches 100\% test success rate at 0.5\% - 1\% evaluation margin while the average for other methods is around 50\% at that evaluation margin.}

%% Figure environment removed


% The combined design parameters in this circuits include Load Resistance, Width of differential transistors, Width of tail transistors and, LO signal DC Level. Performance metrics considered in study of this circuit are Harmonic Distortion, RF to If gain, and noise figure.

%Mixers, serve an invaluable role of frequency conversion in the communication circuits. Transmitter and receiver employ these circuits respectively as upconversion circuits and downconversion circuits. These circuits, due to operating with different frequencies as their inputs and output, show rather nonlinear behaviour, and hence, are challenging to design. In this work a downconversion mixer for IEEE802.11a is considered as shown in fig\ref{Mixer}. \rf{importance of mixer}



% % Figure environment removed

\subsubsection{Voltage-Controlled Oscillators (VCO)}
A critical circuit block in RF applications is the oscillator, specifically voltage-controlled versions with frequency tuning capability \cite{VCO}, which is responsible for generating a sustainable periodic output autonomously.
Shown in \cref{vco} is a CMOS cross-coupled VCO \cite{alihaj}.
VCO's desired behavior is to vary output frequency within a required tuning range with control voltage variation \cite{razavi}.
The transistors consume DC power to compensate for any physical losses while the electromagnetic energy exchange among the capacitors and the inductors leads to a sustainable oscillation.

% \yc{$f(R^3) \rightarrow  R^4$ }

Automatically designing a VCO circuit proved a challenging task for all of the tested method (\cref{res:vco}).
%By testing various methods on the VCO, \rc{as shown in Fig. \ref{Vco1}} we can clearly see that 
The order of relative performance was similar to the mixer, with our proposed method, $\bar{D}^*_\epsilon$ outperforming the others with 83.5\% success rate at 5\% error margin.
Achieving near-perfect success on this circuit therefore remains an open challenge for future research.
%data modification method outperforms other methods similar to the mixer circuit; the \st{BestEpsilonFeasible} \rc{abbreviation} method reaches 80\% test success rate at 0.5\% - 1\% evaluation margin while the average for other methods is around 50\% at the same evaluation margin.


% Figure environment removed


\subsection{Clustering Effect Analysis}
Since our approach involves the replacement of circuit parameters with alternative parameters within the parameter space that yield improved performance, fewer distinct parameters remain after filtering than initially simulated. In situations where multiple performance metrics are mapped to the same parameter vector, it becomes intriguing to investigate the potential impact of this clustering on the performance of our algorithm. After constructing our dataset, we count the number of distinct circuits in the constructed dataset as well as the perplexity of the resulting dataset. The resulting perplexity is defined as $PP(p)=2^{H(p)}$ where entropy is estimated over the constructed dataset based on the counts of the distinct parameters.
In the majority of circuits, the number of distinct parameter vectors in the constructed dataset is only approximately 3-12\% of its size. In the majority of circuits, the number of distinct parameter vectors in the constructed dataset is only approximately 3-12\% of its size. Specifically, for the Cascode circuit, we find 489 distinct circuits, which are 12\% of the dataset size, while the resulting dataset's perplexity is 286. In the case of more advanced circuits like Mixer and VCO, we observe a distinct count of 2-3\% of the data size. The resulting perplexity is 45 for Mixer and 68 for VCO, both amounting to roughly 1\% of their respective dataset sizes. The evident clustering effect observed in our construction method holds significant implications. One plausible hypothesis we put forward is that this clustering phenomenon could potentially be advantageous for training Machine Learning Models. By leveraging this clustering effect, we can effectively sidestep issues arising from overlapping mappings, enabling us to construct sample-efficient dataset.

%However, even in extreme cases, such as CS Amplifier with an unchanged rate of nearly 50\% of the original parameters, we observe perplexity of 8913, which is 36\% of the constructed dataset. Our algorithm consistently outperforms alternative methods. Hence, clustering does not significantly affect the performance of our algorithm.

% Since our approach involves the replacement of circuit parameters with alternative parameters within the parameter space that yield improved performance, fewer distinct parameters remain after filtering than originally simulated. In situations where multiple performance metrics are mapped to the same parameters vector, it becomes intriguing to investigate the potential impact of this clustering on the performance of our algorithm. We count the number of unique remaining parameters  after constructing our dataset. In the majority of circuits, only approximately 5-10\% of the original data points remain unchanged. However, even in extreme cases, such as NMOS circuits with an unchanged rate of nearly 50\%, or in the case of PA circuits with an unchanged rate of almost 0.01\%, our algorithm consistently outperforms alternative methods. Hence, we conclude that clustering does not significantly affect the performance of our algorithm. 

\subsection{Performance Metric Ordering Variations}
In our study, we subjected the LNA circuit to an assessment using two distinct orders of performance metrics: Order A (Power Gain, $S_{11}$, NF), and Order B ($S_{11}$, NF, Power Gain). We optimized for maximizing Power Gain and minimizing $S_{11}$ and NF in both orders. Notably, the circuits generated by Order A showcased an average Power Gain that was larger (thus better) by 0.84 dB compared to those generated by Order B. Additionally, these circuits exhibited an average $S_{11}$ that was higher (thus worse) by 0.53 dB in comparison. We conducted a similar analysis for the Common Source Amplifier, Cascode Amplifier, and Two-Stage circuits. By prioritizing the order of the bandwidth during dataset construction, we observed circuits with higher average bandwidth. Similarly, with regards to power consumption, which we aimed to minimize, assigning the highest priority to power consumption led to the production of circuits with lower power consumption. We conclude that the user-specified order of performance metrics effectively creates the desired preference over them.

% % Figure environment removed


% % Figure environment removed






%% Figure environment removed

% The input parameters are the width of top current device M2, PMOS pair M0, M1 and Varactors. Performance Metrics are Tuning range, Phase noise and Power Consumption.  
% % Figure environment removed



\section{Conclusion}
We present a data filtering pipeline that can generate, from a circuit simulation dataset, a training dataset for supervised learning of a circuit design agent for threshold specification.
%generation method to \rc{modified or modify} circuit data to meet threshold specification. 
In extensive experiments with several baselines on a variety of linear, nonlinear, and autonomous analog and radio-frequency circuits, we find that our proposed method performs near-perfectly in all but the hardest circuit.
This supports our hypothesis that a systematic selection of representative circuits can alleviate the “non-injective” property of the simulator function, which is vastly exacerbated by the threshold specification setting.
%helped machine learning model to learn the relationship between circuit performance specification and circuit parameters easier.
%We demonstrate the robustness of our method on 7 different topologies of \rc{linear, nonlinear, and autonomous radio-frequency and mm-wave} circuits.  
%\yc{Our proposed data generation method achieves 95 percent accuracy or higher given the margin of 1 percent for all the circuits except the VCO circuit. For the VCO circuit our method produces the highest score of 83 percent accuracy given the margin of 1 percent. } 
The results also show the sample efficiency of our method.
While not directly comparable with previous work, we often use a number of simulations an order of magnitude or more smaller than ever before, and learning from even 5\% of this data is often highly successful as well.
% by testing how data size variations will affect performance. For most \rc{of the examined} circuits, even using 5\% of the training data can achieve acceptable performance within circuit \st{generation} \rc{design} industry standard.
Lastly, we also show that our method is, to some extent, model agnostic by training with different machine learning methods and comparing their performance. To the best of our knowledge, this is the first time that a wide collection of analog circuits at various frequencies and of varied operations have been extensively examined and shown capable of being automatically designed.
% while the proposed method outperforms the prior art.} 
We believe that the methods and results of this work can help the growth of the circuit design industry by addressing the rapidly increasing demand for advanced electronic chipsets.

\section*{Acknowledgements}
Roy Fox is partly supported by the Hasso Plattner Foundation.

% \begin{tabular}{ |s|p{3cm}|p{3cm}| }
% \hline
% Circuit Configuration& Variable Parameters &Performance Metrics \\
% \hline
% CS Amplifier &  &gain, banwidth, power consumption \\
% \rowcolor{gray}
% Cascode amplifier & AX & gain, bandwidth, power consumption \\
% two-stage amplifier   &AL & ALB \\
% low-noise amplifier  &DZ & DZA \\
% Power amplifier & AS & ASM \\
% mixer & AD &\\
% Oscillator &  &
% \cellcolor[HTML]{AA0044} AND    \\
% \hline
% \end{tabular}

% \begin{table}
%  \small
% % \singlespacing
% \caption{Selected performance metrics for each circuit}\label{table1}
% \begin{tabular}{|p{2.8cm}|p{4cm}|p{3cm}|p{2cm}|p{2cm}|}
% \hline
% \textbf{Circuit Type} & \textbf{Performance Metrics} & \textbf{Simulation Data Size} & \textbf{Average Accuracy} & \textbf{Success Rate} \\
% \hline
% CS Amplifier & Gain, BW, Power consumption & XXX & \\
% \hline
% Cascode Amplifier & Gain, BW, Power consumption & XXX & \\
% \hline
% Two-stage Amplifier & Gain, BW, Power consumption & XXX & \\
% \hline
% Low-noise Amplifier & Input matching ($S_{11}$), NF, and Power Gain & XXX & \\
% \hline
% Power Amplifier & Power Added Efficiency, Power Gain, and Drain Efficiency & XXX & \\
% \hline
% Mixer & Harmonic Distortion, RF to IF gain, and NF & XXX & \\
% \hline
% Oscillator & Tuning range, phase noise, and Power Consumption & XXX & \\
% \hline

% \end{tabular}
% \end{table}

% \begin{table}[hpt]
% \caption{Results\label{Table}}
% \centering
% \begin{tabular}{c c c c c c }

% \hline
%   Circuit &  Design Parameter &  Ranges  & Performance Metric &   Threshold Direction  \\
% \hline
%  \\
% \hline
%  \\
% \hline
%   \\
% \hline


%       \\
% \hline
%   \\
% \hline
% \end{tabular}
% \end{table}




% \ref{Table1}

\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}


\appendix
\clearpage

\onecolumn
\section{Appendix} 

\subsection{Model Architecture}
\label{appendix_a} 

In this work, we propose a Multi-layer perceptron (MLP) architecture with seven layers for the task at hand. The first layer takes in a vector of size equal to the number of performance metrics for the circuit and outputs a vector of length 200. The last layer takes in a vector of length 200 and outputs the same number of parameters as in the circuit. The middle five layers are constant across all circuits and have the following [input, output] size configurations: [200, 300], [300, 500], [500, 500], [500, 300], [300, 200]. Each layer is separated by the Rectified Linear Unit (ReLU) activation function. We trained each MLP model for 100 epochs using the Adam optimizer \cite{adam} with a default learning rate of 0.001. Additionally, we also trained a Random Forest (RF) model with the default number of trees (100) and default arguments.


\subsection{Comparing Methods}
\label{appendix_b} 

% Figure environment removed

% % Figure environment removed

% Figure environment removed

We compared the performance of three different machine learning methods: Neural Network (NN), Random Forest (RF), and Lookup Table (LT) using a ten-fold cross-validation setup with 90 \% of the data used for training.
The purpose of this work was to demonstrate that our method is model-agnostic, and thus, we did not attempt to fine-tune the NN or RF models. The lookup table approach was implemented by searching for the circuit with the lowest error in the training dataset for a given testing circuit.
The NN and RF models were trained as specified in Section \ref{appendix_a}. The results in table \ref{table_method} suggest that all three methods perform similarly, with most of the circuits achieving 95-100\% accuracy and a margin of 1\%. This suggests that even a simple model like RF can produce good results. The detailed plots are presented in \ref{res:appendix_methods}.





\begin{table*}[!hbt]
 \small
% \singlespacing
 \centering
\caption{Circuit Method Comparison at 1 $\%$ }\label{table_method}
\begin{tabular}{|p{1.4cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{ML/Circuit} & \textbf{CS} & \textbf{Cascode} &\textbf{Two Stage} & \textbf{LNA}  &\textbf{PA}   &\textbf{Mixer} &\textbf{VCO} \\
\hline
Lookup &0.94 $\pm$ 0.005 &0.888 $\pm$ 0.005 &0.961 $\pm$ 0.011 &0.998 $\pm$ 0.001 &$\textbf{0.958}$ $\pm$ 0.004 &0.997 $\pm$ 0.001 &0.833 $\pm$ 0.015\\ 
 \hline 
NN &0.854 $\pm$ 0.023 & $\textbf{0.971}$ $\pm$ 0.004 &$\textbf{0.964}$ $\pm$ 0.02 &$\textbf{0.998}$ $\pm$ 0.0 &0.945 $\pm$ 0.005 &0.994 $\pm$ 0.001 &0.847 $\pm$ 0.022\\ 
 \hline 
RF & $\textbf{0.953}$ $\pm$ 0.004 &0.944 $\pm$ 0.005 &1.0 $\pm$ 0.0 &0.995 $\pm$ 0.001 &0.95 $\pm$ 0.005 &0.996 $\pm$ 0.001 &$\textbf{0.853}$ $\pm$ 0.024\\ 
 \hline 


\end{tabular}
\end{table*}



%%%%Methods Graphs%%%%%%%



% % Figure environment removed


% % Figure environment removed


% % Figure environment removed


% % Figure environment removed

% % Figure environment removed
%%%%


\label{appendix_c} 
\subsection{Comparing Datasizes}


\begin{table*}[!hbt]
 \small
% \singlespacing
 \centering
\caption{Circuit Data Size Comparison for $D_0$ at 1 $\%$ }\label{table1}
\begin{tabular}{|p{1.4cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{\%/Circuit} & \textbf{CS} & \textbf{Cascode} &\textbf{Two Stage} & \textbf{LNA}  &\textbf{PA}   &\textbf{Mixer} &\textbf{VCO} \\
\hline
0.05 &0.295 $\pm$ 0.036 &0.207 $\pm$ 0.029 &0.566 $\pm$ 0.04 &0.944 $\pm$ 0.005 &0.712 $\pm$ 0.026 &0.319 $\pm$ 0.037 &0.375 $\pm$ 0.033\\ 
 \hline 
0.1 &0.278 $\pm$ 0.041 &0.13 $\pm$ 0.025 &0.676 $\pm$ 0.077 &0.933 $\pm$ 0.012 &0.711 $\pm$ 0.02 &0.282 $\pm$ 0.055 &0.342 $\pm$ 0.049\\ 
 \hline 
0.2 &0.351 $\pm$ 0.047 &0.292 $\pm$ 0.067 &0.719 $\pm$ 0.078 &0.991 $\pm$ 0.003 &0.759 $\pm$ 0.029 &0.364 $\pm$ 0.05 &0.38 $\pm$ 0.089\\ 
 \hline 
0.5 &0.54 $\pm$ 0.053 &0.492 $\pm$ 0.065 &0.813 $\pm$ 0.106 &0.992 $\pm$ 0.007 &0.689 $\pm$ 0.091 &0.387 $\pm$ 0.021 &0.452 $\pm$ 0.011\\ 
 \hline 
0.9 &0.539 $\pm$ 0.051 &0.583 $\pm$ 0.053 &0.927 $\pm$ 0.022 &0.998 $\pm$ 0.001 &0.73 $\pm$ 0.014 &0.396 $\pm$ 0.032 &0.454 $\pm$ 0.055\\ 
 \hline 

\end{tabular}
\end{table*}



\begin{table*}[!hbt]
 \small
% \singlespacing
 \centering
\caption{Circuit Data Size Comparison for $\bar{D}^{*}_{\epsilon}$ at 1 $\%$ }\label{table1}
\begin{tabular}{|p{1.4cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{\%/Circuit} & \textbf{CS} & \textbf{Cascode} &\textbf{Two Stage} & \textbf{LNA}  &\textbf{PA}   &\textbf{Mixer} &\textbf{VCO} \\
\hline
0.05 &0.83 $\pm$ 0.018 &0.803 $\pm$ 0.019 &0.817 $\pm$ 0.021 &0.972 $\pm$ 0.003 &0.874 $\pm$ 0.026 &0.927 $\pm$ 0.01 &0.819 $\pm$ 0.009\\ 
 \hline 
0.1 &0.751 $\pm$ 0.035 &0.815 $\pm$ 0.029 &0.962 $\pm$ 0.015 &0.985 $\pm$ 0.003 &0.927 $\pm$ 0.01 &0.942 $\pm$ 0.013 &0.82 $\pm$ 0.013\\ 
 \hline 
0.2 &0.849 $\pm$ 0.029 &0.886 $\pm$ 0.019 &0.978 $\pm$ 0.004 &0.991 $\pm$ 0.002 &0.944 $\pm$ 0.013 &0.969 $\pm$ 0.017 &0.838 $\pm$ 0.019\\ 
 \hline 
0.5 &0.917 $\pm$ 0.027 &0.962 $\pm$ 0.009 &0.938 $\pm$ 0.0 &0.996 $\pm$ 0.003 &0.963 $\pm$ 0.002 &0.995 $\pm$ 0.002 &0.814 $\pm$ 0.017\\ 
 \hline 
0.9 &0.847 $\pm$ 0.04 &0.971 $\pm$ 0.004 &0.973 $\pm$ 0.018 &0.997 $\pm$ 0.001 &0.945 $\pm$ 0.006 &0.995 $\pm$ 0.001 &0.787 $\pm$ 0.037\\ 
 \hline 


\end{tabular}
\end{table*}



% % Figure environment removed


% % Figure environment removed


% % Figure environment removed


% % Figure environment removed



% % Figure environment removed



% % Figure environment removed



% % Figure environment removed



% Figure environment removed




% Figure environment removed


%%%%


% % Figure environment removed


% % Figure environment removed

% % Figure environment removed



% % Figure environment removed



% % Figure environment removed


% % Figure environment removed



% % Figure environment removed



%%%%



In this study, we assess the performance of various circuits by utilizing subsamples of varying sizes, including 5\%, 10\%, 20\%, 50\%, and 90\% of the data. The 90\% subsample corresponds to a range of 2700-3600 points, while the 5\% subsample corresponds to approximately 150-200 points. Results indicate that the accuracy of the Two Stage circuit linearly increases from 56\% to 93\% as the subsample size increases from 5\% to 90\%. Similarly, for the $\bar{D_{\epsilon}^*}$ method, accuracy increases from 81\% to 97\%. Notably, all circuits exhibit an accuracy higher than 80\%, even when using only 5\% of the data. However, the accuracy of the $D_0$ circuit is observed to drop to 20\% for certain subsamples. 


\label{appendix_d} 
\subsection{Comparing Datasets}

In addition to our previous results, we present a table of circuit evaluations for each method at a 1\% margin. It can be observed that the Power Amplifier, VCO, and Mixer circuits achieve the highest scores when utilizing our method. However, for less complex circuits such as the Common Source Amplifier, the $D_{\epsilon}$ method yields a 2\% higher score compared to our method.




% % Figure environment removed






\begin{table*}[!hbt]
 \small
% \singlespacing
 \centering
\caption{Circuit Comparison Info at 1 $\%$ }\label{table1}
\begin{tabular}{|p{1.4cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{D/Circuit} & \textbf{CS} & \textbf{Cascode} &\textbf{Two Stage} & \textbf{LNA}  &\textbf{PA}   &\textbf{Mixer} &\textbf{VCO} \\
\hline

$D_{0}$ &0.7 $\pm$ 0.036 &0.519 $\pm$ 0.043 &0.985 $\pm$ 0.01 &0.996 $\pm$ 0.001 &0.945 $\pm$ 0.005 &0.486 $\pm$ 0.06 &0.378 $\pm$ 0.054\\ 
 \hline 
$D_{\epsilon}$ & $\textbf{0.957}$ $\pm$ 0.009 &0.921 $\pm$ 0.033 & $\textbf{0.99}$ $\pm$ 0.004 & $\textbf{0.999}$ $\pm$ 0.0 &0.97 $\pm$ 0.002 &0.824 $\pm$ 0.019 &0.713 $\pm$ 0.016\\ 
 \hline 
$D^{m}_{\epsilon}$ &0.542 $\pm$ 0.014 &0.435 $\pm$ 0.026 &0.877 $\pm$ 0.033 &0.976 $\pm$ 0.003 &0.37 $\pm$ 0.048 &0.32 $\pm$ 0.011 &0.54 $\pm$ 0.021\\ 
 \hline 
$\bar{D}^{m}_{\epsilon}$ &0.801 $\pm$ 0.038 &0.578 $\pm$ 0.033 &0.518 $\pm$ 0.048 &0.8 $\pm$ 0.024 &0.768 $\pm$ 0.092 &0.401 $\pm$ 0.022 &0.501 $\pm$ 0.015\\ 
 \hline 
$\bar{D}^{*}_0$ &0.847 $\pm$ 0.021 &0.947 $\pm$ 0.019 &0.984 $\pm$ 0.011 &0.997 $\pm$ 0.001 &0.943 $\pm$ 0.004 &0.858 $\pm$ 0.025 &0.827 $\pm$ 0.019\\ 
 \hline 
$\bar{D}^{*}_{\epsilon}$ &0.936 $\pm$ 0.012 &$\textbf{0.962}$ $\pm$ 0.007 &0.981 $\pm$ 0.012 &0.998 $\pm$ 0.001 & $\textbf{0.948}$ $\pm$ 0.005 & $\textbf{0.995}$ $\pm$ 0.001 & $\textbf{0.835}$ $\pm$ 0.016\\ 
 \hline 

\end{tabular}
\end{table*}





% \begin{table*}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{Circuit Data Size Comparison for $\bar{D}^{*}_{\epsilon}$ at 5 $\%$ }\label{table_5percent}
% \begin{tabular}{|p{2.0cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
% \hline
% \textbf{Data \% /Circuit Name} & \textbf{CS} & \textbf{Cascode} &\textbf{Two Stage} & \textbf{LNA}  &\textbf{PA}   &\textbf{Mixer} &\textbf{VCO} \\
% \hline
% 0.05 &0.968 $\pm$ 0.007 &0.959 $\pm$ 0.007 &0.998 $\pm$ 0.001 &1.0 $\pm$ 0.0 &0.907 $\pm$ 0.022 &0.979 $\pm$ 0.004 &0.856 $\pm$ 0.007\\ 
%  \hline 
% 0.1 &0.959 $\pm$ 0.008 &0.966 $\pm$ 0.013 &1.0 $\pm$ 0.0 &1.0 $\pm$ 0.0 &0.952 $\pm$ 0.006 &0.983 $\pm$ 0.005 &0.858 $\pm$ 0.015\\ 
%  \hline 
% 0.2 &0.976 $\pm$ 0.007 &0.984 $\pm$ 0.001 &1.0 $\pm$ 0.0 &1.0 $\pm$ 0.0 &0.961 $\pm$ 0.008 &0.992 $\pm$ 0.005 &0.866 $\pm$ 0.019\\ 
%  \hline 
% 0.5 &0.994 $\pm$ 0.004 &0.998 $\pm$ 0.001 &1.0 $\pm$ 0.0 &1.0 $\pm$ 0.0 &0.974 $\pm$ 0.001 &0.998 $\pm$ 0.0 &0.844 $\pm$ 0.018\\ 
%  \hline 
% 0.9 &0.98 $\pm$ 0.014 &0.999 $\pm$ 0.001 &1.0 $\pm$ 0.0 &1.0 $\pm$ 0.0 &0.963 $\pm$ 0.003 &1.0 $\pm$ 0.0 &0.815 $\pm$ 0.038\\ 
%  \hline 


% \end{tabular}
% \end{table*}

\pagebreak

\label{appendix_e} 
\subsection{Comparing Circuits}
\label{appendix_f} 

As seen in Table \ref{comparing_101}, a comparison of our proposed method is conducted against previous methods. However, due to the lack of standard benchmarks for circuits and limited data availability for many circuits, it should be noted that this comparison should be viewed as a general guide rather than a comprehensive evaluation. Nonetheless, it can be observed that our method demonstrates superior performance in comparison to previous methods, while also maintaining a small data size.

For each circuit, we also provide the following additional information:
\begin{enumerate}
  \item The size of the train dataset, number of parameters, number of points per parameter in Table \ref{table_summary},
  \item Average performance error across all the circuits in Table  \ref{table_average_perf},
  \item Performance metric range for every circuit in Table  \ref{amp_r_table},\ref{nonl_r_table},
  \item Parameters range for every circuit in Table  \ref{Variables}.
\end{enumerate}


\begin{table*}[!hbt]
 \small
% \singlespacing
 \centering
\caption{Average performance error $\%$  for every circuit using $\bar{D}^{*}_{\epsilon}$ }\label{table_average_perf}
\begin{tabular}{|p{1.4cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{Err/Circuit} & \textbf{CS} & \textbf{Cascode} &\textbf{Two Stage} & \textbf{LNA}  &\textbf{PA}   &\textbf{Mixer} &\textbf{VCO} \\
\hline
 Mean Error & 0.06 $ \pm$ 0.0 &  0.04 $ \pm$ 0.0 &  0.03 $ \pm$ 0.0 &  0.0 $ \pm$ 0.0 &  1.29 $ \pm$ 0.002 &  0.01 $ \pm$ 0.0 &  1.13 $ \pm$ 0.002 \\
\hline
\end{tabular}
\end{table*}


 \begin{center}
\begin{table}[h!]
\centering
\caption{Circuit complexity comparison}\label{table_summary}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
  \textbf{Circuit} & \textbf{CS} & \textbf{Cascode} & \textbf{Two-Stage} & \textbf{LNA} & \textbf{PA} & \textbf{Mixer} & \textbf{VCO}\\
     \hline
    
        \textbf{train-data size}  & 3340 &  4080 & 616 & 4096 & 3528 & 3136 &4096  \\
      \hline
         \textbf{Number of Parameters}  & 2 & 3 & 3 & 4 & 4 & 3 & 4\\
      \hline
         \textbf{Points per parameter}  & 1670 & 1360 & 205.3 & 1024 & 882 & 1045.3 & 1024\\
      \hline
\end{tabular}
    \label{train-data}
\end{table}
\end{center}



\begin{table}[h!]
\centering
\caption{ Comparing Results with the previous work }\label{comparing_101}


\begin{tabular}{|c|c||c|c|c|}
\hline
   & \textbf{Performance Metric} & This Work (\%) & Best Reported (\%) & Related Works\\
 \hline
  \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{CS}}} & Gain &  0.135$\pm$0.035 & \multirow{3}{*}{$<2.6$} &  \multirow{3}{*}{\citet{Devi2021}} \\
   \cline{2-3}
     & Bandwidth & 0.048 $\pm$ 0.12 &  & \\
      \cline{2-3}
      & Power Consumption & 0.0044$\pm$ 0.002 &  &  \\
      \cline{1-5}
  \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{Cascode}}} & Gain & 0.0471$\pm$0.02 &\multirow{3}{*}{$\approx$ 1} & \multirow{3}{*}{\shortstack[c]{\citet{Lourenco2019}\\\citet{mina2022}}} \\
   \cline{2-3}
     & Bandwidth & 0.0433$\pm$0.01 &   & \\
      \cline{2-3}
      & Power Consumption & 0.0222$\pm$0.007 &  &  \\
      \cline{1-5}
  \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{2-Stage}}} & Gain & 0.0226$\pm$0.018 & 1.1  & \citet{Fukuda2017} \\
   \cline{2-4}
     & Bandwidth & 0.00001 $\pm$ 0.000003 & NA &  \\
      \cline{2-4}
      & Power Consumption & 0.0716$\pm$0.031 & 3.7 & \citet{HarshaHarish}   \\
      \cline{1-5}
   \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{LNA}}} & $G_{T}$ & 0.0028$\pm$0.001 & \multirow{3}{*}{ $<$ 5} &  \multirow{3}{*}{\citet{Dumesnil2014}} \\
   \cline{2-3}
     & $S_{11}$ & 0.007$\pm$0.001 &  & \\
      \cline{2-3}
      & NF & 0.002$\pm$0.0005 &  &  \\
      \cline{1-5}
   \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{PA}}} & Power Gain & 1.207 $\pm$ 0.14
 &\multirow{3}{*}{NA}& \multirow{3}{*}{NA} \\
   \cline{2-3}
     & Drain Efficiency  & 1.361 $\pm$ 0.2 &  & \\
      \cline{2-3}
      & PAE & 1.30 $\pm $ 0.19 &  & \\
      \cline{1-5}  
 \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{Mixer}}} & Conversion Gain & 0.005$\pm$0.0035 & \multirow{3}{*}{NA}   & \multirow{3}{*}{NA} \\
   \cline{2-3}
     & Power Consumption  & 0.86$\pm$0.002 & & \\
      \cline{2-3}
      & Swing  & 0.66$\pm$ 0.005 &  &  \\
      \cline{1-5}
 \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{VCO}}} & Power Consumption  & 0.017$\pm$ 0.1423 & \multirow{3}{*}{NA}   & \multirow{3}{*}{NA} \\
   \cline{2-3}
     & Output Power & 0.1423$\pm$0.01 &  & \\
      \cline{2-3}
      & Tuning Range  & 3.226$\pm$0.6293 &  &    \\
      \cline{1-5}
\end{tabular}
    \label{previousworks}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%














% % Circuit Performance Table

% \begin{table}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{Circuit Comparison Info}\label{table1}
% \begin{tabular}{|p{2cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}
% \hline
% \textbf{Method/Circuit Name} & \textbf{Two Stage} & \textbf{LNA} & \textbf{Mixer} &\textbf{Cascode} &\textbf{VCO}  &\textbf{PA} &\textbf{NMOS} \\
% \hline
% Ablation & 0.518 & 0.800 & 0.401 & 0.578 & 0.501 & 0.127& 0 \\
% \hline
% Argmax & 0.984 &	0.997&	0.858&	0.947&	0.827&	0.434 & 0 \\
% \hline
% Lourenco & 0.822&	0.495&	0.624&	0.341&	0.566&	0.388 & 0 \\
% \hline
% SoftArgmax & 0.981&	0.998&	0.995&	0.962&	0.835&	0.526 & 0 \\
% \hline
% SoftBase & 0.985&	0.996&	0.486&	0.519&	0.378&	0.156 & 0 \\
% \hline
% \end{tabular}
% \end{table}


% \begin{table*}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{CS Amplifier Circuit Performance Validation Info}\label{table1}
% \begin{tabular}{|p{4cm}|p{2cm}|p{3cm}|p{3cm}|}
% \hline
% \textbf{Average Error/Performance} & \textbf{Bandwidth} & \textbf{Power} & \textbf{Voltage Gain}\\
% \hline
% 5\% train data & 0.008 $\pm$ 0 & 0.004 $\pm$ 0 & 0.011 $\pm$ 0 \\
% \hline
% 10\% train data & 0.022 $\pm$ 0 & 0.004 $\pm$ 0 & 0.004 $\pm$ 0 \\
% \hline
% 20\% train data & 0.008 $\pm$ 0 & 0.002 $\pm$ 0 & 0.005 $\pm$ 0 \\
% \hline
% 50\% train data & 0.017 $\pm$ 0 & 0.004 $\pm$ 0 & 0.002 $\pm$ 0 \\
% \hline
% 90\% train data & 0.007 $\pm$ 0.001 & 0.002 $\pm$ 0 & 0.004 $\pm$ 0 \\
% \hline
% 5\% train data base & 1.064 $\pm$ 0.309 & 0.385 $\pm$ 0.089 & 2.265 $\pm$ 0.781 \\
% \hline
% 10\% train data base & 1.049 $\pm$ 0.316 & 0.375 $\pm$ 0.095 & 2.242 $\pm$ 0.798 \\
% \hline
% 20\% train data base & 1.110 $\pm$ 0.328 & 0.364 $\pm$ 0.104 & 2.203 $\pm$ 0.792 \\
% \hline
% 50\% train data base & 1.109 $\pm$ 0.382 & 0.302 $\pm$ 0.099 & 1.172 $\pm$ 0.268 \\
% \hline
% 90\% train data base & 1.109 $\pm$ 0.629 & 0.210 $\pm$ 0.093 & 1.036 $\pm$ 0.488 \\
% \hline


% \end{tabular}
% \end{table*}


% % Circuit Performance Table
% \begin{table*}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{LNA Circuit Performance Validation Info}\label{table1}
% \begin{tabular}{|p{4cm}|p{1.5cm}|p{1cm}|p{2cm}|}
% \hline
% \textbf{Average Error/Performance} & \textbf{$G_p$} & \textbf{$S_{11}$} & \textbf{Noise Figure}\\
% \hline
% 5\% train data & 0.042 $\pm$ 0 & 0 $\pm$ 0 & 0.034 $\pm$ 0 \\
% \hline
% 10\% train data & 0.026 $\pm$ 0 & 0 $\pm$ 0 & 0.015 $\pm$ 0 \\
% \hline
% 20\% train data & 0.037 $\pm$ 0 & 0 $\pm$ 0 & 0.029 $\pm$ 0 \\
% \hline
% 50\% train data & 0.019 $\pm$ 0 & 0 $\pm$ 0 & 0.013 $\pm$ 0 \\
% \hline
% 90\% train data & 0.015 $\pm$ 0 & 0 $\pm$ 0 & 0.01 $\pm$ 0 \\
% \hline
% 5\% train data base & 0 $\pm$ 0 & 0 $\pm$ 0 & 0.01 $\pm$ 0 \\
% \hline
% 10\% train data base & 0 $\pm$ 0 & 0 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline
% 20\% train data base & 0 $\pm$ 0 & 0 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline
% 50\% train data base & 0 $\pm$ 0 & 0 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline
% 90\% train data base & 0 $\pm$ 0 & 0 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline


% \end{tabular}
% \end{table*}


% % Circuit Performance Table
% \begin{table*}[!hbt]

%  \small
% % \singlespacing
%  \centering

% \caption{Two Stage Circuit Performance Validation Info}\label{table1}
% \begin{tabular}{|p{4cm}|p{2.5cm}|p{2.5cm}|p{2cm}|}
% \hline
% \textbf{Average Error/Performance} & \textbf{Bandwidth} & \textbf{Power} & \textbf{Voltage Gain}\\
% \hline
% 5\% train data & 0 $\pm$ 0 & 0 $\pm$ 0 & 0.001 $\pm$ 0 \\
% \hline
% 10\% train data & 0 $\pm$ 0 & 0 $\pm$ 0 & 0.001 $\pm$ 0 \\
% \hline
% 20\% train data & 0 $\pm$ 0 & 0.001 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline
% 50\% train data & 0 $\pm$ 0 & 0 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline
% 90\% train data & 0 $\pm$ 0 & 0 $\pm$ 0 & 0 $\pm$ 0 \\
% \hline
% 5\% train data base & 0.011 $\pm$ 0.002 & 6.874 $\pm$ 2.475 & 0.012 $\pm$ 0.002 \\
% \hline
% 10\% train data base & 0.006 $\pm$ 0.001 & 5.026 $\pm$ 2.147 & 0.007 $\pm$ 0.001 \\
% \hline
% 20\% train data base & 0.004 $\pm$ 0.001 & 5.036 $\pm$ 2.766 & 0.005 $\pm$ 0.001 \\
% \hline
% 50\% train data base & 0.001 $\pm$ 0.000 & 1.504 $\pm$ 0.544 & 0.004 $\pm$ 0.001 \\
% \hline
% 90\% train data base & 0.001 $\pm$ 0.001 & 1.941 $\pm$ 1.334 & 0.002 $\pm$ 0.001\\
% \hline
% \end{tabular}

% \end{table*}


% % Circuit Performance Table
% \begin{table*}[!hbt]
%  \small
% % \singlespacing
%  \centering
% \caption{Cascode Circuit Performance Validation Info}\label{table1}
% \begin{tabular}{|p{4cm}|p{2cm}|p{4cm}|p{2cm}|}
% \hline
% \textbf{Average Error/Performance} & \textbf{Bandwidth} & \textbf{Power} & \textbf{Voltage Gain}\\
% \hline
% 5\% train data & 0.021 $\pm$ 0.001 & 0.008 $\pm$ 0.001 & 0.034 $\pm$ 0.001 \\
% \hline
% 10\% train data & 0.004 $\pm$ 0 & 0.003 $\pm$ 0 & 0.028 $\pm$ 0.001 \\
% \hline
% 20\% train data & 0.006 $\pm$ 0 & 0.004 $\pm$ 0 & 0.017 $\pm$ 0.001 \\
% \hline
% 50\% train data & 0.009 $\pm$ 0.001 & 0.004 $\pm$ 0 & 0.006 $\pm$ 0.001 \\
% \hline
% 90\% train data & 0.005 $\pm$ 0.001 & 0.003 $\pm$ 0.001 & 0.006 $\pm$ 0.001 \\
% \hline
% 5\% train data base & 0.018 $\pm$ 0.001 & 72438.367 $\pm$ 45924.770 & 0.019 $\pm$ 0.001 \\
% \hline
% 10\% train data base & 0.010 $\pm$ 0.001 & 49357.270 $\pm$ 30500.890 & 0.011 $\pm$ 0.001 \\
% \hline
% 20\% train data base & 0.006 $\pm$ 0.001 & 40557.046 $\pm$ 26120.554 & 0.006 $\pm$ 0 \\
% \hline
% 50\% train data base & 0.003 $\pm$ 0.000 & 33434.152 $\pm$ 23611.404 & 0.004 $\pm$ 0.001 \\
% \hline
% 90\% train data base & 0.002 $\pm$ 0.001 & 26548.997 $\pm$ 25751.998 & 0.003 $\pm$ 0.002\\
% \hline


% \end{tabular}
% \end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage

\begin{table}[H]
\centering
\caption{ Range of Analog Voltage Amplifiers Performance Metrics}\label{range_1}
\resizebox{0.5\columnwidth}{!}{%
%\colorbox{purple!20}{
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
  \multirow{2}{*} {\textbf{Performance Metric}} & 
  \multicolumn{2}{c|}{\textbf{CS }} & 
  \multicolumn{2}{c|}{\textbf{Cascode}} &
  \multicolumn{2}{c|}{\textbf{Two-Stage }} \\
  \cline{2-7}
   
      &Min&Max&Min&Max&Min&Max \\
     \hline
     Gain (db) & 5.25 & 15.14 & 20.94 & 28.23 & 41.28 & 73.82\\
     \hline
      Bandwidth (Hz) & 83.7M & 5.99G & 2.17G & 8.5G  & 12.1M & 1.01G \\
      \hline
       Power Consumption (mW) & 0.57 & 1.34 & 0.38 & 0.56   & 1.32 & 2.00\\
       \hline
\end{tabular}
}
%}
    \label{amp_r_table}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Amplifier Performance Metrics Ranges Table


\begin{table}[H]
\centering
\caption{Range of Non-linear Circuits Performance Metrics }\label{range_2}
\resizebox{0.5\columnwidth}{!}{%

\begin{tabular}{|c|c||c|c|}
\hline
   & \textbf{Performance Metric} & Min & Max\\
 
      \cline{1-4}
   \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{LNA}}} & Power Gain(db) & 12.76 & 15.8  \\
   \cline{2-4}
     & $S_{11}$ & -19.1 & -17.3 \\
      \cline{2-4}
      & NF(db) & 2.154 & 2.39  \\
      \cline{1-4}

 \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{PA}}} & Power Gain (db) & 5.165 & 18.65  \\
   \cline{2-4}
     & Drain Efficiency (\%) & 9.39 & 33.92 \\
      \cline{2-4}
      & PAE(\%) & 3.79 & 28.67  \\
      \cline{1-4}
 \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{Mixer}}} & Conversion Gain & 0.61 & 5.95  \\
   \cline{2-4}
     & Power Consumption (mW) & 0.11 & 7.32 \\
      \cline{2-4}
      & Swing (mV) & 0.61 & 5.95  \\
      \cline{1-4}
 \multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{VCO}}} & Power Consumption (mW) & 3.9 & 12.3  \\
   \cline{2-4}
     & Output Power(mW) & 5.11 & 19.67 \\
      \cline{2-4}
      & Tuning Range (Hz) & 451K & 440M  \\
      \cline{1-4}
      
\end{tabular}

}
    \label{nonl_r_table}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Design Parameters Table


\begin{table}[H]
  \centering
  \caption{ Design Parameters and  Range of Variations }\label{range_3}
  \resizebox{0.5\columnwidth}{!}{%
       \begin{tabular}{|c|c||c|c|c|}
                 \hline
    \textbf{Circuit} & \textbf{Variable} & Start & Step & End\\
    \hline
\multirow{2}{*}{\textbf{CS}} & $M_{1}$[w] & 2.8um & 0.2um & 6.6um \\
   \cline{2-5}
     & $R_{D}$ & 620$\Omega$ & 5$\Omega$  & 1450$\Omega$ \\
      \cline{1-5}
\multirow{3}{*}{\textbf{Cascode}} & $M_{1}$ [w] & 8um & 0.25um & 11.5um \\
   \cline{2-5}
     &  $M_{2}$ [w] & 2um & 0.2um & 5um\\
      \cline{2-5}
      & $R_{D}$ & 9k$\Omega$ & 125$\Omega$ & 11k$\Omega$ \\
      \cline{1-5}
\multirow{3}{*}{\textbf{Two-Stage }} & $M_{1}$[w] & 25um & 0.5um & 30um \\
   \cline{2-5}
     & $M_{2}$[w] & 52um & 0.5um & 55.5um\\
      \cline{2-5}
      & $M_{T}$[w] & 6um & 0.5um & 9um  \\
      \cline{1-5}
\multirow{4}{*}{\textbf{LNA}} & $M_{1,2}$[w] & 73um & 0.5um & 76.5um \\
   \cline{2-5}
     & $L_{g}$ & 9.4nH & 0.2nH & 10.8nH \\
      \cline{2-5}
       & $L_{s}$ & 747pH & 1pH & 754pH \\
      \cline{2-5}
       & $L_{d}$ & 3.7nH & 0.1nH & 4.4nH  \\
      \cline{1-5}
 \multirow{4}{*}{\textbf{PA}} & $M_{1,2,3,4}$[w] & 18um & 0.5um & 22um \\
   \cline{2-5}
     & $M_{5,6,7,8}$[w] & 27um & 1um & 34um \\
      \cline{2-5}
       & $V_{b1}$ & 785mV & 5mV & 815mV \\
      \cline{2-5}
      & $V_{b2}$ & 760mV & 5mV & 790mV  \\
      \cline{1-5}
      
 \multirow{3}{*}{\textbf{Mixer}} & $M_{1}$[w] & 8.55um & 0.45um & 11.7um  \\
   \cline{2-5}
    &$M_{T}$[w] & 17.1um & 0.9um & 23.4um\\
         \cline{2-5}
     & $V_{RF,DC}$ & 630mV & 30mV & 810mV \\
      \cline{2-5}
      & R  & 240 $\Omega$ & 40$\Omega$ & 520$\Omega$\\
      \cline{1-5}

      
 \multirow{4}{*}{\textbf{VCO}} & $M_{1}$[w] & 8.55um & 0.45um & 11.7um\\
   \cline{2-5}
    & $M_{T}$[w] & 145um & 2um & 159um \\
      \cline{2-5}
      &  $M_{V}$[w]& 73um & 2um & 87um  \\
       \cline{2-5}
        & L & 3.6nH & 0.1nH & 4.3nH \\
      \cline{1-5}
      
\end{tabular}
}
    \label{Variables}
\end{table}




%%%%%%%%%%%%%%%%%%%%%%%NMOS%%%%%%%%%%%%%%%%%%%%%%%

% % Figure environment removed



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%CASCODE%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%TWO STAGE%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%LNA%%%




%%%%%%



%%%PA%%%%





%%%%%


%%%MIXER%%%%



%%%%%



%VCO%%%





%%%


% \begin{equation}
% D^m_\epsilon = D_0   \bigcup_{i=1}^m D_\epsilon[u_i]; \quad u_i \sim U^k \text{ i.i.d}.
% \end{equation}

\end{document}

