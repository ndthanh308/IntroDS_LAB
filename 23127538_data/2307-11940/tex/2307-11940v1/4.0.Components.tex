\section{Key Components and Technologies}
\label{sec:comp}

Realizing a safety island requires an SoC capable of executing safety-relevant functionalities, as well as capable of providing safety services to the HPC island. To build a functional and open source safety island, we identify a number of existing and under development components and technologies that need to be consistently integrated to form the safety island. Some of those components and technologies are introduced in this section.

\subsection{Baseline MPSoC}
As part of the H2020 SELENE project, an open source RISC-V based MPSoC suitable for the space, automotive and railway domains has been released~\cite{SELENEpaper}. The SELENE SoC offers a 6-core multicore based on Gaisler's NOEL-V cores~\cite{NOELV} and other GPL IPs~\cite{GRLIB}. Moreover, it includes a wide subset of the IPs described in the remaining of this subsection that make it further appropriate as the starting point to develop a safety island.

{\color{black}
However, there are other alternatives. Unfortunately, high-performance RISC-V cores are mostly proprietary, such as SiFive's P650 and others.
Some open source cores have been recently compared~\cite{dorflinger2021comparative}, including Rocket~\cite{asanovic2016rocket}, BOOM~\cite{celio2019broom}, CVA6~\cite{COREV}, and SHAKTI~\cite{gala2016shakti} C-Class implementations. No core is proven superior to the others in all fronts with varying conclusions for both ASIC and FPGA realizations if we consider performance, power efficiency, area, or maintainability. 
}


\subsection{Multicore Interference Monitors}
A key safety service in multicores relates to monitoring the interference across cores or other type of devices (e.g., accelerators) since such interference may affect real-time guarantees for safety-critical real-time tasks. Recently, the Safe Statistics Unit (SafeSU)~\cite{SafeSU,SafeSU2} has been proposed. It provides capabilities to monitor the traffic in AMBA interfaces such as AHB and AXI4, although its design has been made modular to enable its porting to other interfaces. The SafeSU allows measuring the interference each master device causes on each other device in different interfaces, and has been successfully integrated in the SELENE SoC~\cite{SELENEQoS}.
It remains to be studied how to tailor it to monitor the traffic in remote interconnects rather than those in the safety island itself.


\subsection{Multicore Interference Quotas}
The SafeSU~\cite{SafeSU,SafeSU2} has also been equipped with an interference control mechanism building on its interference monitoring capabilities. In particular, the SafeSU allows programming interference quotas that, upon being exceeded, trigger interrupts that can be immediately captured by the hypervisor or RTOS so that any action needed can be taken, in accordance with system needs (e.g., dropping the offending task, stalling it for a while, increasing QoS guarantees for the offended task). These interrupts have been properly connected to the corresponding interrupt controller at hardware level and successfully captured by the operating system on top, so the integration of the SafeSU with the software layers is simple.


\subsection{Performance Validation}
While monitoring and quota features during operation are key features needed for the design of the system, such system must be thoroughly tested to guarantee that timing overruns will not occur making deadline violation risk residual. Software tests provide limited controllability to exercise all performance corners since multicore interference scenarios can only be induced indirectly and, in some cases, without synchronous control. For instance, some traffic with long bursts can only be produced by devices such as Ethernet ports of the Direct Memory Access (DMA) controller, which are too hard to synchronize with traffic produced by the computing cores. To tackle this issue, the Safe Traffic Injector (SafeTI)~\cite{SafeTI} has been recently proposed. It allows programming arbitrary traffic patterns, including delays between consecutive transactions, fully synchronously, and allowing to generate any type of traffic including read/write, with arbitrary data transfer sizes, with/without burst behavior, etc., including repeated traffic, as well as fixed-size and infinite traffic patterns.
As for the SafeSU, it remains to be studied how to tailor the SafeTI to inject traffic in the HPC island from the safety island.


\subsection{Diverse Redundancy for Cores}
Functionalities with the highest integrity level (e.g., ASIL-D in automotive) require diverse redundancy in several domains, which is efficiently implemented with DCLS. Hence, at least some cores in the safety island need to implement DCLS. The SafeLS realizes DCLS for NOEL-V cores in the SELENE SoC~\cite{SafeLS}. However, as explained before, DCLS is generally expensive if not needed for some tasks since redundant cores are not user visible. Hence, different flavors of diverse redundancy can be deployed providing different tradeoffs, such as allowing cores to be used independently, although failing to provide diverse redundancy for I/O code. This is the case of the Safe Diversity Monitor (SafeDM) module~\cite{SafeDM}, which allows measuring whether diversity exists across two cores. Conversely, the Safe Diversity Enforcement (SafeDE)~\cite{SafeDE} module allows enforcing some time staggering, and hence, diversity across two cores running a task redundantly. The SafeSoftDR software module~\cite{SafeSoftDR} could be used instead since it provides the same functionality as SafeDE in a less efficient manner but without requiring any hardware support. A comparison across the different mechanisms can be found in~\cite{SafeDX}.

Note that, DCLS is intrinsically highly coupled with the redundant cores, and hence, only available for the safety island. Instead, SafeDE, SafeDM and SafeSoftDR can manage diversity for non-DCLS cores. Therefore, they can be tailored to deliver diverse redundancy to cores in the HPC island from the safety island.


\subsection{Diverse Redundancy for Accelerators}
Full redundancy for accelerators such as GPUs is generally not present in HPC devices. Therefore, it is not possible orchestrating diverse redundancy across multiple accelerator instances as done for cores with SafeDE and SafeSoftDR. 

However, accelerators are often highly parallel and offer large internal redundancy this has been leveraged in some works to implement some form of diverse redundancy with appropriate software and hardware support~\cite{divredINTEL,divredNVIDIA}. This type of support can be potentially integrated in the safety island, which can, for instance, offload redundant kernels in a GPU of the HPC island inducing diversity with different means (e.g., intrinsics support, scheduling policy characteristics).

In the context of Deep Neural Networks (DNNs), high -- yet not perfect -- accuracy rates are obtained for processes such as object detection and classification. DNNs often rely on approximation and stochastic behavior, and hence, do not generally require bit-level precision. Instead, high -- yet not full -- precision is wanted at semantic level (e.g., properly detecting and classifying an object) regardless of whether the accuracy is a bit higher or lower. In that context, it is possible deploying lower-cost and approximate (e.g., using lower precision arithmetic) accelerators in the safety island providing diverse redundancy to large and precise accelerators in the HPC island as long as the former are capable of detecting large deviations for the predictions of the latter~\cite{SAURIA}. Such DMR scheme has already been realized in \cite{TRUST}.


\subsection{Watchdogs}
As part of the architectural design of safety-related functionalities, watchdogs are popular since they allow checking the aliveness of specific components. At hardware level, watchdogs are also popular and, in the context of the safety island, they can be deployed to monitor the aliveness of specific components in the safety island as well as in the HPC island (or the complete HPC island). 

Generally, watchdogs are expected to be made sufficiently independent of the item being monitored, e.g., with independent clock and power supply. Hence, this is expected to hold by construction in the case of loose integration of the safety island. However, specific design rules must be followed for both coupled integration of the safety and HPC islands, and watchdogs monitoring components part of the safety island itself.

Watchdogs can monitor clock signals, cycle counters, instruction counters, or time-to-response for some devices. For instance, one could couple a watchdog to the SafeTI so that the latter sends a request requiring response to a specific component in the HPC island, while the watchdog awaits for an answer within a specific time bound. If such response does not arrive timely, the watchdog may raise an interrupt to be captured by the system software in the safety island.


\subsection{Virtualization Extensions}
Hypervisors and RTOSs, often required in safety-critical systems, require appropriate virtualization capabilities to offer partitioning services to the guest operating system. Such virtualization can only be realized if supported by the hardware platform. Hence, virtualization extensions become mandatory for the safety island. For instance, the aforementioned NOEL-V cores in the SELENE SoC implement such extension and have been proven effective to run hypervisors on top, such as fentISS' XtratuM~\cite{SCC,xtratum}.


\subsection{Logging Support}
Most HPC devices include some form of tracing support. However, information traced can be abundant and produced continuously, which, in general, requires a host computer to process it. Such information can be of much use to diagnose the source of some errors, or, at least, to enable reproducibility for diagnostics purposes. 
The safety island can act as such host computer. However, storage capabilities are limited for the safety island (e.g., typically KBs for on-chip storage and MBs for off-chip storage), and hence, either information is dropped by, for instance, retaining the most recent traced information only, or summarized in the form of logs. Retaining recent information can be easily done with trace buffers where information is stored using a FIFO policy. Logging requires, instead, a tradeoff between the details retained and the hardware cost to retain them. The higher the degree of information loss, the lower the cost to store remaining information. For instance, one can track timestamps for specific events, which would require large storage capabilities or restricting trace recording to a limited time window. Alternatively, one could use counters to track occurrences of those events -- potentially broken down across multiple categories, with much lower storage cost, but losing information relative to the timing of those events.
For instance, some authors proposed an error logger for caches tracking error location to diagnose permanent faults~\cite{LogCacheFaults}. 

\subsection{Chiplet Integration Technologies} 
In case of a loose integration with a chiplet-based safety island, Universal Chiplet Interconnect Express (UCIe) comes as the standardizing solution to die-to-die interconnectivity. The layered protocol specifies a die-to-die adapter layer and a protocol layer, the latter supporting PCIe or CXL, with further protocol mappings planned. This requires, however, that communicating chiplets adhere to standards. For instance, UCIe’s specification does not cover packaging/bridging technology used to provide the physical link between chiplets. It is bridge-agnostic, meaning chiplets can be linked via different mechanisms such as fanout bridge, silicon interposers (i.e. 2.5D packaging) or other packaging technologies such as 3D packaging. Nevertheless, standards such as bump pitch, must be taken into account, meaning RISC-V platforms would require dedicated, standardized support for UCIe, which could potentially hinder observability.

In terms of packaging technology, for instance, Intel’s EMIB (Embedded Multi-Die Interconnect Bridge) is a 2.5D packaging technique used to connect dies on the same substrate. 2.5D refers to the integration of dies/chiplets on a substrate using an interposer. It brings specific advantages such as larger die count and larger package configurations, lower cost than full size silicon interposer and support for high data rate signaling between adjacent die.

3D packaging is an alternative to interposers. 3D packaging refers to the direct high-density interconnection of chips through TSV (through-silicon via).
In 3D packaging, chiplets are placed on top of one another instead of horizontally next to one another, forming a 3D structure with each chiplet occupying a layer. Finally, the interposer connects the 3D assembly of the chiplet with the substrate. For instance, Foveros is a high-performance 3D packaging technology. 



