\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{wu2019detectron2}
Y.~Wu, A.~Kirillov, F.~Massa, W.-Y. Lo, and R.~Girshick, ``Detectron2,''
  \url{https://github.com/facebookresearch/detectron2}, 2019.

\bibitem{dd3d}
D.~Park, R.~Ambrus, V.~C. Guizilini, J.~Li, and A.~Gaidon, ``Is pseudo-lidar
  needed for monocular 3d object detection?'' \emph{2021 IEEE/CVF International
  Conference on Computer Vision (ICCV)}, pp. 3122--3132, 2021.

\bibitem{SAM}
A.~Kirillov, E.~Mintun, N.~Ravi, H.~Mao, C.~Rolland, L.~Gustafson, T.~Xiao,
  S.~Whitehead, A.~C. Berg, W.-Y. Lo, P.~Doll{\'a}r, and R.~B. Girshick,
  ``Segment anything,'' \emph{ArXiv}, vol. abs/2304.02643, 2023.

\bibitem{Nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and
  R.~Ng, ``Nerf: Representing scenes as neural radiance fields for view
  synthesis,'' \emph{ArXiv}, vol. abs/2003.08934, 2020.

\bibitem{autorf}
N.~M{\"u}ller, A.~Simonelli, L.~Porzi, S.~R. Bul{\`o}, M.~Nie{\ss}ner, and
  P.~Kontschieder, ``Autorf: Learning 3d object radiance fields from single
  view observations,'' \emph{2022 IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp. 3961--3970, 2022.

\bibitem{snerf}
Z.~Xie, J.~Zhang, W.~Li, F.~Zhang, and L.~Zhang, ``S-nerf: Neural radiance
  fields for street views,'' \emph{ArXiv}, vol. abs/2303.00749, 2023.

\bibitem{PNF}
A.~Kundu, K.~Genova, X.~Yin, A.~Fathi, C.~Pantofaru, L.~J. Guibas,
  A.~Tagliasacchi, F.~Dellaert, and T.~A. Funkhouser, ``Panoptic neural fields:
  A semantic object-aware neural scene representation,'' \emph{2022 IEEE/CVF
  Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.
  12\,861--12\,871, 2022.

\bibitem{SUDS}
H.~Turki, J.~Y. Zhang, F.~Ferroni, and D.~Ramanan, ``Suds: Scalable urban
  dynamic scenes,'' \emph{ArXiv}, vol. abs/2303.14536, 2023.

\bibitem{discoscene}
Y.~Xu, M.~Chai, Z.~Shi, S.~Peng, I.~Skorokhodov, A.~Siarohin, C.~Yang, Y.~Shen,
  H.-Y. Lee, B.~Zhou, and S.~Tulyakov, ``Discoscene: Spatially disentangled
  generative radiance fields for controllable 3d-aware scene synthesis,''
  \emph{ArXiv}, vol. abs/2212.11984, 2022.

\bibitem{neuralscenegraphs}
J.~Ost, F.~Mannan, N.~Thuerey, J.~Knodt, and F.~Heide, ``Neural scene graphs
  for dynamic scenes,'' \emph{2021 IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp. 2855--2864, 2020.

\bibitem{gina3d}
B.~Shen, X.~Yan, C.~Qi, M.~Najibi, B.~Deng, L.~J. Guibas, Y.~Zhou, and
  D.~Anguelov, ``Gina-3d: Learning to generate implicit neural assets in the
  wild,'' \emph{ArXiv}, vol. abs/2304.02163, 2023.

\bibitem{geosim}
Y.~Chen, F.~Rong, S.~Duggal, S.~Wang, X.~Yan, S.~Manivasagam, S.~Xue, E.~Yumer,
  and R.~Urtasun, ``Geosim: Realistic video simulation via geometry-aware
  composition for self-driving,'' \emph{2021 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)}, pp. 7226--7236, 2021.

\bibitem{ners}
J.~Y. Zhang, G.~Yang, S.~Tulsiani, and D.~Ramanan, ``Ners: Neural reflectance
  surfaces for sparse-view 3d reconstruction in the wild,'' in \emph{Neural
  Information Processing Systems}, 2021.

\bibitem{StreetSurf}
J.~Guo, N.~Deng, X.~Li, Y.~Bai, B.~Shi, C.~Wang, C.~Ding, D.~Wang, and Y.~Li,
  ``Streetsurf: Extending multi-view implicit surface reconstruction to street
  views,'' \emph{ArXiv}, vol. abs/2306.04988, 2023.

\bibitem{BlockNeRF}
M.~Tancik, V.~Casser, X.~Yan, S.~Pradhan, B.~Mildenhall, P.~P. Srinivasan,
  J.~T. Barron, and H.~Kretzschmar, ``Block-nerf: Scalable large scene neural
  view synthesis,'' \emph{2022 IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp. 8238--8248, 2022.

\bibitem{FEGR}
Z.~Wang, T.~Shen, J.~Gao, S.~Y. Huang, J.~Munkberg, J.~Hasselgren, Z.~Gojcic,
  W.~Chen, and S.~Fidler, ``Neural fields meet explicit geometric
  representation for inverse rendering of urban scenes,'' \emph{ArXiv}, vol.
  abs/2304.03266, 2023.

\bibitem{urbangiraffe}
Y.~Yang, Y.~Yang, H.~Guo, R.~Xiong, Y.~Wang, and Y.~Liao, ``Urbangiraffe:
  Representing urban scenes as compositional generative neural feature
  fields,'' \emph{ArXiv}, vol. abs/2303.14167, 2023.

\bibitem{airsim}
S.~Shah, D.~Dey, C.~Lovett, and A.~Kapoor, ``Airsim: High-fidelity visual and
  physical simulation for autonomous vehicles,'' in \emph{International
  Symposium on Field and Service Robotics}, 2017.

\bibitem{carla}
A.~Dosovitskiy, G.~Ros, F.~Codevilla, A.~M. L{\'o}pez, and V.~Koltun, ``Carla:
  An open urban driving simulator,'' \emph{ArXiv}, vol. abs/1711.03938, 2017.

\bibitem{kitti}
A.~Geiger, P.~Lenz, and R.~Urtasun, ``Are we ready for autonomous driving? the
  kitti vision benchmark suite,'' \emph{2012 IEEE Conference on Computer Vision
  and Pattern Recognition}, pp. 3354--3361, 2012.

\bibitem{dvm}
J.~Huang, B.~Chen, L.~Luo, S.~Yue, and I.~Ounis, ``Dvm-car: A large-scale
  automotive dataset for visual marketing research and applications,''
  \emph{2022 IEEE International Conference on Big Data (Big Data)}, pp.
  4140--4147, 2021.

\bibitem{mipnerf}
J.~T. Barron, B.~Mildenhall, M.~Tancik, P.~Hedman, R.~Martin-Brualla, and P.~P.
  Srinivasan, ``Mip-nerf: A multiscale representation for anti-aliasing neural
  radiance fields,'' \emph{2021 IEEE/CVF International Conference on Computer
  Vision (ICCV)}, pp. 5835--5844, 2021.

\bibitem{DynamicViewSynthesis}
C.~Gao, A.~Saraf, J.~Kopf, and J.-B. Huang, ``Dynamic view synthesis from
  dynamic monocular video,'' \emph{2021 IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pp. 5692--5701, 2021.

\bibitem{nerfdiff}
J.~Gu, A.~Trevithick, K.-E. Lin, J.~M. Susskind, C.~Theobalt, L.~Liu, and
  R.~Ramamoorthi, ``Nerfdiff: Single-image view synthesis with nerf-guided
  distillation from 3d-aware diffusion,'' \emph{ArXiv}, vol. abs/2302.10109,
  2023.

\bibitem{3DiM}
D.~Watson, W.~Chan, R.~Martin-Brualla, J.~Ho, A.~Tagliasacchi, and M.~Norouzi,
  ``Novel view synthesis with diffusion models,'' \emph{ArXiv}, vol.
  abs/2210.04628, 2022.

\bibitem{Zero1to3}
R.~Liu, R.~Wu, B.~V. Hoorick, P.~Tokmakov, S.~Zakharov, and C.~Vondrick,
  ``Zero-1-to-3: Zero-shot one image to 3d object,'' \emph{ArXiv}, vol.
  abs/2303.11328, 2023.

\bibitem{deceptivenerf}
X.~Liu, S.~hong Kao, J.~Chen, Y.-W. Tai, and C.-K. Tang, ``Deceptive-nerf:
  Enhancing nerf reconstruction using pseudo-observations from diffusion
  models,'' \emph{ArXiv}, vol. abs/2305.15171, 2023.

\bibitem{Magic123}
G.~Qian, J.~Mai, A.~Hamdi, J.~Ren, A.~Siarohin, B.~Li, H.-Y. Lee,
  I.~Skorokhodov, P.~Wonka, S.~Tulyakov, and B.~Ghanem, ``Magic123: One image
  to high-quality 3d object generation using both 2d and 3d diffusion priors,''
  \emph{ArXiv}, vol. abs/2306.17843, 2023.

\bibitem{PixelNeRF}
A.~Yu, V.~Ye, M.~Tancik, and A.~Kanazawa, ``pixelnerf: Neural radiance fields
  from one or few images,'' \emph{2021 IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp. 4576--4585, 2020.

\bibitem{CMR}
A.~Kanazawa, S.~Tulsiani, A.~A. Efros, and J.~Malik, ``Learning
  category-specific mesh reconstruction from image collections,'' \emph{ArXiv},
  vol. abs/1803.07549, 2018.

\bibitem{pixel2mesh}
N.~Wang, Y.~Zhang, Z.~Li, Y.~Fu, W.~Liu, and Y.-G. Jiang, ``Pixel2mesh:
  Generating 3d mesh models from single rgb images,'' in \emph{European
  Conference on Computer Vision}, 2018.

\bibitem{deformation}
P.~Henderson, V.~Tsiminaki, and C.~H. Lampert, ``Leveraging 2d data to learn
  textured 3d mesh generation,'' \emph{2020 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)}, pp. 7495--7504, 2020.

\bibitem{nvdiffrec}
J.~Munkberg, J.~Hasselgren, T.~Shen, J.~Gao, W.~Chen, A.~Evans, T.~M{\"u}ller,
  and S.~Fidler, ``Extracting triangular 3d models, materials, and lighting
  from images,'' \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp. 8270--8280, 2021.

\bibitem{unsup3d}
S.~Wu, C.~Rupprecht, and A.~Vedaldi, ``Unsupervised learning of probably
  symmetric deformable 3d objects from images in the wild,'' \emph{2020
  IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.
  1--10, 2019.

\bibitem{meshrcnn}
G.~Gkioxari, J.~Malik, and J.~Johnson, ``Mesh r-cnn,'' \emph{2019 IEEE/CVF
  International Conference on Computer Vision (ICCV)}, pp. 9784--9794, 2019.

\bibitem{pifu}
S.~Saito, Z.~Huang, R.~Natsume, S.~Morishima, A.~Kanazawa, and H.~Li, ``Pifu:
  Pixel-aligned implicit function for high-resolution clothed human
  digitization,'' \emph{2019 IEEE/CVF International Conference on Computer
  Vision (ICCV)}, pp. 2304--2314, 2019.

\bibitem{3D-RCNN}
A.~Kundu, Y.~Li, and J.~M. Rehg, ``3d-rcnn: Instance-level 3d object
  reconstruction via render-and-compare,'' \emph{2018 IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, pp. 3559--3568, 2018.

\bibitem{CADSim}
J.~Wang, S.~Manivasagam, Y.~Chen, Z.~Yang, I.~A. B{\^a}rsan, A.~Yang, W.-C. Ma,
  and R.~Urtasun, ``Cadsim: Robust and scalable in-the-wild 3d reconstruction
  for controllable sensor simulation,'' in \emph{Conference on Robot Learning},
  2022.

\bibitem{singleshotsr}
S.~Zakharov, R.~Ambrus, V.~C. Guizilini, D.~Park, W.~Kehl, F.~Durand, J.~B.
  Tenenbaum, V.~Sitzmann, J.~Wu, and A.~Gaidon, ``Single-shot scene
  reconstruction,'' in \emph{Conference on Robot Learning}, 2021.

\bibitem{ObjectCompositinalNeRF}
B.~Yang, Y.~Zhang, Y.~Xu, Y.~Li, H.~Zhou, H.~Bao, G.~Zhang, and Z.~Cui,
  ``Learning object-compositional neural radiance field for editable scene
  rendering,'' \emph{2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pp. 13\,759--13\,768, 2021.

\bibitem{MVSNerf}
A.~Chen, Z.~Xu, F.~Zhao, X.~Zhang, F.~Xiang, J.~Yu, and H.~Su, ``Mvsnerf: Fast
  generalizable radiance field reconstruction from multi-view stereo,''
  \emph{2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.
  14\,104--14\,113, 2021.

\bibitem{visionNerf}
K.-E. Lin, Y.-C. Lin, W.-S. Lai, T.-Y. Lin, Y.~Shih, and R.~Ramamoorthi,
  ``Vision transformer for nerf-based view synthesis from a single input
  image,'' \emph{2023 IEEE/CVF Winter Conference on Applications of Computer
  Vision (WACV)}, pp. 806--815, 2022.

\bibitem{SRT}
M.~S.~M. Sajjadi, H.~Meyer, E.~Pot, U.~M. Bergmann, K.~Greff, N.~Radwan,
  S.~Vora, M.~Lucic, D.~Duckworth, A.~Dosovitskiy, J.~Uszkoreit, T.~A.
  Funkhouser, and A.~Tagliasacchi, ``Scene representation transformer:
  Geometry-free novel view synthesis through set-latent scene
  representations,'' \emph{2022 IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp. 6219--6228, 2021.

\bibitem{codenerf}
W.~J. Jang and L.~de~Agapito, ``Codenerf: Disentangled neural radiance fields
  for object categories,'' \emph{2021 IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pp. 12\,929--12\,938, 2021.

\bibitem{resnet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp. 770--778, 2015.

\bibitem{imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei, ``Imagenet: A
  large-scale hierarchical image database,'' \emph{2009 IEEE Conference on
  Computer Vision and Pattern Recognition}, pp. 248--255, 2009.

\bibitem{nerfstudio}
M.~Tancik, E.~Weber, E.~Ng, R.~Li, B.~Yi, J.~Kerr, T.~Wang, A.~Kristoffersen,
  J.~Austin, K.~Salahi, A.~Ahuja, D.~McAllister, and A.~Kanazawa, ``Nerfstudio:
  A modular framework for neural radiance field development,'' \emph{ArXiv},
  vol. abs/2302.04264, 2023.

\bibitem{autorf-pytorch}
``Autorf-pytorch,'' \url{https://github.com/skyhehe123/AutoRF-pytorch}.

\bibitem{radam}
L.~Liu, H.~Jiang, P.~He, W.~Chen, X.~Liu, J.~Gao, and J.~Han, ``On the variance
  of the adaptive learning rate and beyond,'' \emph{ArXiv}, vol.
  abs/1908.03265, 2019.

\bibitem{ssim}
Z.~Wang, E.~P. Simoncelli, and A.~C. Bovik, ``Multiscale structural similarity
  for image quality assessment,'' \emph{The Thrity-Seventh Asilomar Conference
  on Signals, Systems \& Computers, 2003}, vol.~2, pp. 1398--1402 Vol.2, 2003.

\bibitem{lpips}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang, ``The unreasonable
  effectiveness of deep features as a perceptual metric,'' \emph{2018 IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, pp. 586--595, 2018.

\end{thebibliography}
