\section{Conclusion}

In this paper, we presented \methodname, a pipeline for learning car's neural radiance fields from in-the-wild 2D images. Our pipeline includes a data processing component and a neural radiance field component.

We collected CarPatch3D, a dataset that provides multi-perspective images of cars by processing images from existing datasets with different design purposes to address the gap in existing autonomous driving datasets that often provide front or rear views of cars.

Our designed Car-NeRF, a canonical, cone-tracing neural radiance field with extra segmentation loss, enables our model to learn from single-view supervision, anti-aliasing, and sharp contours, leading to competitive performance in rendering realistic images of car objects.

Moreover, the trained Car-NeRF model can serve as a component for an editable autonomous driving simulator. As the scale of CarPatch3D expands, we anticipate that our model's performance in completely invisible perspective synthesis and appearance editing will continue to improve.

