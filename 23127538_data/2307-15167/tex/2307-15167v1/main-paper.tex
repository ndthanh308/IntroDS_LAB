%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}

\usepackage{soul}
\usepackage{fontawesome5}
\usepackage{algorithm2e}
\usepackage{hyperref}
\usepackage{balance}
\captionsetup[table]{position=bottom}


\newcommand{\tlcomment}[1]{\noindent{\\\textcolor{black}{\textbf{\#\#\# TL:} \textsf{#1} \#\#\#\\}}}

\newcommand{\ytcomment}[1]{\noindent{\\\textcolor{black}{\textbf{\#\#\# YT:} \textsf{#1} \#\#\#\\}}}

\newcommand{\zzhighlight}[1]{{\textcolor{black}{#1}}}
\newcommand{\tlhighlight}[1]{{\textcolor{black}{#1}}}

\newcommand{\crhighlight}[1]{{\textcolor{black}{#1}}}

\newcommand{\cmt}[1]{\ignorespaces}

\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}
\SetKwInput{KwName}{Name}

\usepackage{mathtools}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}


\newcommand{\zzcomment}[1]{\noindent{\\\textcolor{blue}{\textbf{\#\#\# ZZ:} \textsf{#1} \#\#\#\\}}}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[UIST '23]{The 36th Annual ACM Symposium on User Interface Software and Technology}{October 29-November 1, 2023}{San Francisco, CA, USA}
\acmBooktitle{The 36th Annual ACM Symposium on User Interface Software and Technology (UIST '23), October 29-November 1, 2023, San Francisco, CA, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3586183.3606776}
\acmISBN{979-8-4007-0132-0/23/10}


\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{PEANUT: A Human-AI Collaborative Tool for Annotating Audio-Visual Data}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.


\author{Zheng Zhang}
\authornote{Both authors contributed equally to this work.}
\affiliation{%
  \institution{University of Notre Dame}
  \city{Notre Dame}
  \state{Indiana}
  \country{USA}}
\email{zzhang37@nd.edu}

\author{Zheng Ning}
\authornotemark[1]
\affiliation{%
  \institution{University of Notre Dame}
  \city{Notre Dame}
  \state{Indiana}
  \country{USA}}
\email{zning@nd.edu}

\author{Chenliang Xu}
\affiliation{%
  \institution{University of Rochester}
  \city{Rochester}
  \state{New York}
  \country{USA}}
\email{chenliang.xu@rochester.edu}

\author{Yapeng Tian}
\affiliation{%
  \institution{The University of Texas at Dallas}
  \city{Richardson}
  \state{TX}
  \country{USA}}
\email{yapeng.tian@utdallas.edu}

\author{Toby Jia-Jun Li}
\affiliation{%
  \institution{University of Notre Dame}
  \city{Notre Dame}
  \state{Indiana}
  \country{USA}}
\email{toby.j.li@nd.edu}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}

% Audio-visual learning is an emerging machine learning domain that seeks to enhance the computer's multi-modal perception leveraging the correlation between the auditory and visual modalities. Despite their many useful downstream tasks such as video retrieval, AR/VR, and accessibility, the performance and the wide adoption of existing audio-visual models have been impeded by the availability of high-quality datasets. Annotating audio-visual datasets is laborious, expensive, and time-consuming. To address this challenge, we design and develop \textsc{Peanut}, a more efficient audio-visual annotation tool. \textsc{Peanut}'s novel human-AI collaborative pipeline separates the multi-modal task into two single-modal tasks and utilizes state-of-the-art object detection and sound-tagging models to reduce the effort and the cognitive load for human annotators to process each frame, as well as lower the number of manually-annotated frames needed. \textsc{Peanut} uses active learning to optimize its models for higher accuracy in the current domain in real-time as users use the tool. The design of \textsc{Peanut} also presents features that address the ``overreliance'' problem reported in prior work on human-AI collaborative data annotation. A within-subject user study with 15 participants found that \textsc{Peanut} can significantly accelerate the audio-visual data annotation process and improve the annotation accuracy. \looseness=-1

Audio-visual learning seeks to enhance the computer's multi-modal perception leveraging the correlation between the auditory and visual modalities. Despite their many useful downstream tasks, such as video retrieval, AR/VR, and accessibility, the performance and adoption of existing audio-visual models have been impeded by the availability of high-quality datasets. Annotating audio-visual datasets is laborious, expensive, and time-consuming. To address this challenge, we designed and developed an efficient audio-visual annotation tool called \textsc{Peanut}. \textsc{Peanut}'s human-AI collaborative pipeline separates the multi-modal task into two single-modal tasks, and utilizes state-of-the-art object detection and sound-tagging models to reduce the annotators' effort to process each frame and the number of manually-annotated frames needed. A within-subject user study with 20 participants found that \textsc{Peanut} can significantly accelerate the audio-visual data annotation process while maintaining high annotation accuracy. 


  
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003120.10003121.10003129</concept_id>
<concept_desc>Human-centered computing~Interactive systems and tools</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002951.10003227.10003251</concept_id>
<concept_desc>Information systems~Multimedia information systems</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Interactive systems and tools}
\ccsdesc[300]{Information systems~Multimedia information systems}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{human-AI collaboration, data annotation, data labeling, audio-visual learning, interactive machine learning}



\begin{teaserfigure}
  % Figure removed
  \caption{The interface of \textsc{Peanut} for audio-visual data annotation. \zzhighlight{A and B: toolbars with editing and annotation assistance functions; C: the annotation workspace; D: the information panel showing meta-information about the annotations on the current frame\looseness=-1} }
  \label{fig:system_screenshot}
\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\input{1-Intro}
\input{2-Related}
\input{3-System}
\input{4-Study}
\input{5-Discussion}

\begin{acks}
This work was supported in part by an AnalytiXIN Faculty Fellowship, an NVIDIA Academic Hardware Grant, a Google Cloud Research Credit Award, a Google Research Scholar Award, and the NSF Grant 2211428. Yapeng Tian was supported by a gift from Cisco systems. Any opinions, findings or recommendations expressed here are those of the authors and do not necessarily reflect views of the sponsors. We would like to thank Dakuo Wang, Yuwen Lu, and Simret Araya Gebreegziabher for useful discussions.
\end{acks}

\balance
\bibliographystyle{ACM-Reference-Format}
\bibliography{main-paper}


\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
