@inproceedings{antol2015vqa,
  title={VQA: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}


@inproceedings{ning2023empirical,
  title={An empirical study of model errors and user error discovery and repair strategies in natural language database queries},
  author={Ning, Zheng and Zhang, Zheng and Sun, Tianyi and Tian, Yuan and Zhang, Tianyi and Li, Toby Jia-Jun},
  booktitle={Proceedings of the 28th International Conference on Intelligent User Interfaces},
  pages={633--649},
  year={2023}
}

@article{zhang2023visar,
  title={VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping},
  author={Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
  journal={arXiv preprint arXiv:2304.07810},
  year={2023}
}

@article{gao2023collabcoder,
  title={CollabCoder: A GPT-Powered Workflow for Collaborative Qualitative Analysis},
  author={Gao, Jie and Guo, Yuchen and Lim, Gionnieve and Zhan, Tianqin and Zhang, Zheng and Li, Toby Jia-Jun and Perrault, Simon Tangi},
  journal={arXiv preprint arXiv:2304.07366},
  year={2023}
}

@inproceedings{liu2022crossa11y,
author = {Liu, Xingyu "Bruce" and Wang, Ruolin and Li, Dingzeyu and Chen, Xiang Anthony and Pavel, Amy},
title = {CrossA11y: Identifying Video Accessibility Issues via Cross-Modal Grounding},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526113.3545703},
doi = {10.1145/3526113.3545703},
abstract = {Authors make their videos visually accessible by adding audio descriptions (AD), and auditorily accessible by adding closed captions (CC). However, creating AD and CC is challenging and tedious, especially for non-professional describers and captioners, due to the difficulty of identifying accessibility problems in videos. A video author will have to watch the video through and manually check for inaccessible information frame-by-frame, for both visual and auditory modalities. In this paper, we present CrossA11y, a system that helps authors efficiently detect and address visual and auditory accessibility issues in videos. Using cross-modal grounding analysis, CrossA11y automatically measures accessibility of visual and audio segments in a video by checking for modality asymmetries. CrossA11y then displays these segments and surfaces visual and audio accessibility issues in a unified interface, making it intuitive to locate, review, script AD/CC in-place, and preview the described and captioned video immediately. We demonstrate the effectiveness of CrossA11y through a lab study with 11 participants, comparing to existing baseline.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {43},
numpages = {14},
keywords = {accessibility, audio description, closed caption, video},
location = {Bend, OR, USA},
series = {UIST '22}
}

@article{gao2021objectfolder,
  title={ObjectFolder: A Dataset of Objects with Implicit Visual, Auditory, and Tactile Representations},
  author={Gao, Ruohan and Chang, Yen-Yu and Mall, Shivani and Fei-Fei, Li and Wu, Jiajun},
  journal={arXiv preprint arXiv:2109.07991},
  year={2021}
}
@article{chen2020learning,
  title={Learning to set waypoints for audio-visual navigation},
  author={Chen, Changan and Majumder, Sagnik and Al-Halah, Ziad and Gao, Ruohan and Ramakrishnan, Santhosh Kumar and Grauman, Kristen},
  journal={arXiv preprint arXiv:2008.09622},
  year={2020}
}
@article{morgado2018self,
  title={Self-supervised generation of spatial audio for 360 video},
  author={Morgado, Pedro and Vasconcelos, Nuno and Langlois, Timothy and Wang, Oliver},
  journal={arXiv preprint arXiv:1809.02587},
  year={2018}
}
@inproceedings{anayurt2019,
  title={Searching for Ambiguous Objects in Videos using Relational Referring Expressions},
  author={Hazan Anayurt and Sezai Artun Ozyegin and Ulfet Cetin and Utku Aktas and Sinan Kalkan},
  booktitle={Proceedings of the British Machine Vision Conference (BMVC)},
  year={2019},
}
@inproceedings{gebreegziabher2023patat,
  title={Patat: Human-ai collaborative qualitative coding with explainable interactive rule synthesis},
  author={Gebreegziabher, Simret Araya and Zhang, Zheng and Tang, Xiaohang and Meng, Yihao and Glassman, Elena L and Li, Toby Jia-Jun},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2023}
}
@article{kehl2021artificial,
  title={Artificial intelligence-aided clinical annotation of a large multi-cancer genomic dataset},
  author={Kehl, Kenneth L and Xu, Wenxin and Gusev, Alexander and Bakouny, Ziad and Choueiri, Toni K and Riaz, Irbaz Bin and Elmarakeby, Haitham and Van Allen, Eliezer M and Schrag, Deborah},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={7304},
  year={2021},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{choi2022ai,
  title={AI-human interactive pipeline with feedback to accelerate medical image annotation},
  author={Choi, Youngwon and Garcia, Marlena and Raman, Steven S and Enzmann, Dieter R and Brown, Matthew S},
  booktitle={Medical Imaging 2022: Computer-Aided Diagnosis},
  volume={12033},
  pages={741--747},
  year={2022},
  organization={SPIE}
}
@article{jarrahi2018artificial,
  title={Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making},
  author={Jarrahi, Mohammad Hossein},
  journal={Business horizons},
  volume={61},
  number={4},
  pages={577--586},
  year={2018},
  publisher={Elsevier}
}
@article{bobes2021improving,
  title={Improving medical data annotation including humans in the machine learning loop},
  author={Bobes-Bascar{\'a}n, Jos{\'e} and Mosqueira-Rey, Eduardo and Alonso-R{\'\i}os, David},
  journal={Engineering Proceedings},
  volume={7},
  number={1},
  pages={39},
  year={2021},
  publisher={MDPI}
}
@InProceedings{Gao_2019_CVPR,
author = {Gao, Ruohan and Grauman, Kristen},
title = {2.5D Visual Sound},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@article{neves2014survey,
  title={A survey on annotation tools for the biomedical literature},
  author={Neves, Mariana and Leser, Ulf},
  journal={Briefings in bioinformatics},
  volume={15},
  number={2},
  pages={327--340},
  year={2014},
  publisher={Oxford University Press}
}

@article{Xiao2018AddressingTB,
  title={Addressing Training Bias via Automated Image Annotation},
  author={Zhujun Xiao and Yanzi Zhu and Yuxin Chen and Ben Y. Zhao and Junchen Jiang and Haitao Zheng},
  journal={arXiv: Computer Vision and Pattern Recognition},
  year={2018}
}

@article{Dar2021AFT,
  title={A Farewell to the Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized Machine Learning},
  author={Yehuda Dar and Vidya Muthukumar and Richard Baraniuk},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.02355}
}

@incollection{langer1989minding,
  title={Minding matters: The consequences of mindlessness--mindfulness},
  author={Langer, Ellen J},
  booktitle={Advances in experimental social psychology},
  volume={22},
  pages={137--173},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{Qiao2022HumanintheLoopVS,
  title={Human-in-the-Loop Video Semantic Segmentation Auto-Annotation},
  author={Nan Qiao and Yuyin Sun and Chongyu Liu and Lu Xia and Jiajia Luo and K. Zhang and Cheng-Hao Kuo},
  year={2022}
}

@inproceedings{10.1145/3411764.3445165,
author = {Chang, Chia-Ming and Lee, Chia-Hsien and Igarashi, Takeo},
title = {Spatial Labeling: Leveraging Spatial Layout for Improving Label Quality in Non-Expert Image Annotation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445165},
doi = {10.1145/3411764.3445165},
abstract = {Non-expert annotators (who lack sufficient domain knowledge) are often recruited for manual image labeling tasks owing to the lack of expert annotators. In such a case, label quality may be relatively low. We propose leveraging the spatial layout for improving label quality in non-expert image annotation. In the proposed system, an annotator first spatially lays out the incoming images and labels them on an open space, placing related items together. This serves as a working space (spatial organization) for tentative labeling. During the process, the annotator observes and organizes the similarities and differences between the items. Finally, the annotator provides definitive labels to the images based on the results of the spatial layout. We ran a user study comparing the proposed method and a traditional non-spatial layout in an image labeling task. The results demonstrated that annotators can complete the labeling tasks more accurately using the spatial layout interface than the non-spatial layout interface.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {12},
keywords = {Non-expert Annotator, Interface Design, Spatial Layout, Manual Image Labeling},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{alamri2019audio,
  title={Audio visual scene-aware dialog},
  author={Alamri, Huda and Cartillier, Vincent and Das, Abhishek and Wang, Jue and Cherian, Anoop and Essa, Irfan and Batra, Dhruv and Marks, Tim K and Hori, Chiori and Anderson, Peter and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7558--7567},
  year={2019}
}

@inproceedings{labelsleuth2022,
   title={{Label} {Sleuth}: From Unlabeled Text to a Classifier in a Few Hours}, 
   author={Shnarch, Eyal and Halfon, Alon and Gera, Ariel and Danilevsky, Marina and Katsis, Yannis and Choshen, Leshem and Cooper, Martin Santillan and Epelboim, Dina and Zhang, Zheng and Wang, Dakuo and Yip, Lucy and Ein-Dor, Liat and Dankin, Lena and Shnayderman, Ilya and Aharonov, Ranit and Li, Yunyao and Liberman, Naftali and Slesarev, Philip Levin and Newton, Gwilym and Ofek-Koifman, Shila and Slonim, Noam and Katz, Yoav},
   booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
   publisher = "Association for Computational Linguistics",
   url={https://arxiv.org/abs/2208.01483},
   year={2022}
}

@article{Chen2021UnderstandingAM,
  title={Understanding and Mitigating Annotation Bias in Facial Expression Recognition},
  author={Yunliang Chen and Jungseock Joo},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={14960-14971}
}

@article{Bhargava2019ExposingAC,
  title={Exposing and Correcting the Gender Bias in Image Captioning Datasets and Models},
  author={Shruti Bhargava and David Forsyth},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.00578}
}

@article{Mollas2020ETHOSAM,
  title={ETHOS: a multi-label hate speech detection dataset},
  author={Ioannis Mollas and Zoe Chrysopoulou and Stamatis Karlos and Grigorios Tsoumakas},
  journal={Complex \& Intelligent Systems},
  year={2020},
  pages={1-16}
}

@article{Ahmed2021AttenuationOH,
  title={Attenuation of Human Bias in Artificial Intelligence: An Exploratory Approach},
  author={Saad Bin Ahmed and Saif Ali Athyaab and Shaik Abdul Muqtadeer},
  journal={2021 6th International Conference on Inventive Computation Technologies (ICICT)},
  year={2021},
  pages={557-563}
}

@inproceedings{Blanzeisky2021AlgorithmicFI,
  title={Algorithmic Factors Influencing Bias in Machine Learning},
  author={William Blanzeisky and Padraig Cunningham},
  booktitle={PKDD/ECML Workshops},
  year={2021}
}

@article{Leavy2020MitigatingGB,
  title={Mitigating Gender Bias in Machine Learning Data Sets},
  author={Susan Leavy and Gerardine Meaney and Karen Wade and Derek Greene},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.06898}
}

@article{berg2019ilastik,
  title={Ilastik: interactive machine learning for (bio) image analysis},
  author={Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and Straehle, Christoph N and Kausler, Bernhard X and Haubold, Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten and Rudy, Markus and others},
  journal={Nature methods},
  volume={16},
  number={12},
  pages={1226--1232},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{li2021space,
  title={Space-Time Memory Network for Sounding Object Localization in Videos},
  author={Li, Sizhe and Tian, Yapeng and Xu, Chenliang},
  journal={arXiv preprint arXiv:2111.05526},
  year={2021}
}

@article{hu2021class,
  title={Class-aware sounding objects localization via audiovisual correspondence},
  author={Hu, Di and Wei, Yake and Qian, Rui and Lin, Weiyao and Song, Ruihua and Wen, Ji-Rong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

@article{liu2020faster,
  title={Faster Human-Machine Collaboration Bounding Box Annotation Framework Based on Active Learning},
  author={Liu, Minzhe and Du, Li and Du, Yuan and Guo, Ruofan and Chen, Xiaoliang},
  year = {2020},
  booktitle = {2020 ICML Workshop on Human in the Loop Learning (HILL2020)}
}

@inproceedings{hu2020discriminative,
 author = {Hu, Di and Qian, Rui and Jiang, Minyue and Tan, Xiao and Wen, Shilei and Ding, Errui and Lin, Weiyao and Dou, Dejing},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {10077--10087},
 publisher = {Curran Associates, Inc.},
 title = {Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching},
 url = {https://proceedings.neurips.cc/paper/2020/file/7288251b27c8f0e73f4d7f483b06a785-Paper.pdf},
 volume = {33},
 year = {2020}
}



@inproceedings{kim21k_interspeech,
  author={You Jin Kim and Hee-Soo Heo and Soyeon Choe and Soo-Whan Chung and Yoohwan Kwon and Bong-Jin Lee and Youngki Kwon and Joon Son Chung},
  title={{Look Who’s Talking: Active Speaker Detection in the Wild}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={3675--3679},
  doi={10.21437/Interspeech.2021-2041}
}

@inproceedings{alcazar2021maas,
  title={Maas: Multi-modal assignation for active speaker detection},
  author={Alc{\'a}zar, Juan Le{\'o}n and Caba, Fabian and Thabet, Ali K and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={265--274},
  year={2021}
}

@inproceedings{kaul2022label,
  title={Label, verify, correct: A simple few shot object detection method},
  author={Kaul, Prannay and Xie, Weidi and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14237--14247},
  year={2022}
}
@inproceedings{gao2019co,
  title={Co-separating sounds of visual objects},
  author={Gao, Ruohan and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3879--3888},
  year={2019}
}
@inproceedings{rahman2019watch,
  title={Watch, listen and tell: Multi-modal weakly supervised dense event captioning},
  author={Rahman, Tanzila and Xu, Bicheng and Sigal, Leonid},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8908--8917},
  year={2019}
}
@article{tian2018attempt,
  title={An attempt towards interpretable audio-visual video captioning},
  author={Tian, Yapeng and Guan, Chenxiao and Goodman, Justin and Moore, Marc and Xu, Chenliang},
  journal={arXiv preprint arXiv:1812.02872},
  year={2018}
}
@inproceedings{wu2021exploring,
  title={Exploring Heterogeneous Clues for Weakly-Supervised Audio-Visual Video Parsing},
  author={Wu, Yu and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1326--1335},
  year={2021}
}
@article{wyatte2019biasing,
  title={De-biasing Weakly Supervised Learning by Regularizing Prediction Entropy},
  author={Wyatte, Dean},
  year={2019}
}
@inproceedings{tian2020unified,
  title={Unified multisensory perception: Weakly-supervised audio-visual video parsing},
  author={Tian, Yapeng and Li, Dingzeyu and Xu, Chenliang},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages={436--454},
  year={2020},
  organization={Springer}
}
@inproceedings{schmitz2012open,
  title={Open language learning for information extraction},
  author={Schmitz, Michael and Soderland, Stephen and Bart, Robert and Etzioni, Oren and others},
  booktitle={Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning},
  pages={523--534},
  year={2012}
}
@article{song2018graph,
  title={A graph-to-sequence model for AMR-to-text generation},
  author={Song, Linfeng and Zhang, Yue and Wang, Zhiguo and Gildea, Daniel},
  journal={arXiv preprint arXiv:1805.02473},
  year={2018}
}

@inbook{cassidy_2017_tools,
title = "Tools for multimodal annotation",
abstract = "Researchers interested in the sounds of speech or the physical gestures of speakers make use of audio and video recordings in their work. Annotating these recordings presents a different set of requirements to the annotation of text. Special purpose tools have been developed to display video and audio signals and to allow the creation of time-aligned annotations. This chapter reviews the most widely used of these tools for both manual and automatic generation of annotations on multimodal data.",
keywords = "Speech, Video, Annotation, Multimodal, Survey",
author = "Steve Cassidy and Thomas Schmidt",
year = "2017",
doi = "10.1007/978-94-024-0881-2_7",
language = "English",
isbn = "9789402408799",
pages = "209--227",
editor = "Nancy Ide and James Pustejovsky",
booktitle = "Handbook of linguistic annotation",
publisher = "Springer, Springer Nature",
address = "United States",
}

@inproceedings{dutta_2019_via,
author = {Dutta, Abhishek and Zisserman, Andrew},
title = {The VIA Annotation Software for Images, Audio and Video},
year = {2019},
isbn = {9781450368896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343031.3350535},
doi = {10.1145/3343031.3350535},
abstract = {In this paper, we introduce a simple and standalone manual annotation tool for images, audio and video: the VGG Image Annotator (VIA). This is a light weight, standalone and offline software package that does not require any installation or setup and runs solely in a web browser. The VIA software allows human annotators to define and describe spatial regions in images or video frames, and temporal segments in audio or video. These manual annotations can be exported to plain text data formats such as JSON and CSV and therefore are amenable to further processing by other software tools. VIA also supports collaborative annotation of a large dataset by a group of human annotators. The BSD open source license of this software allows it to be used in any academic project or commercial application.},
booktitle = {Proceedings of the 27th ACM International Conference on Multimedia},
pages = {2276–2279},
numpages = {4},
keywords = {image annotation, manual annotation, audio/video annotation},
location = {Nice, France},
series = {MM '19}
}

@inproceedings{chen2015event,
  title={Event extraction via dynamic multi-pooling convolutional neural networks},
  author={Chen, Yubo and Xu, Liheng and Liu, Kang and Zeng, Daojian and Zhao, Jun},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={167--176},
  year={2015}
}

@inproceedings{berant2014semantic,
  title={Semantic parsing via paraphrasing},
  author={Berant, Jonathan and Liang, Percy},
  booktitle={Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1415--1425},
  year={2014}
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  number={6},
  pages={82--97},
  year={2012},
  publisher={IEEE}
}

@InProceedings{Tian_2021_CVPR,
    author    = {Tian, Yapeng and Hu, Di and Xu, Chenliang},
    title     = {Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {2745-2754}
}
@inproceedings{qian2020multiple,
  title={Multiple Sound Sources Localization from Coarse to Fine},
  author={Qian, Rui and Hu, Di and Dinkel, Heinrich and Wu, Mengyue and Xu, Ning and Lin, Weiyao},
  booktitle={ECCV},
  year={2020}
}
@inproceedings{arandjelovic2018objects,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={ECCV},
  year={2018}
}

@misc{labelme2016,
  author =       {Kentaro Wada},
  title =        {{labelme: Image Polygonal Annotation with Python}},
  howpublished = {\url{https://github.com/wkentaro/labelme}},
  year =         {2016}
}

@article{oviatt_2000_perceptual,
author = {Oviatt, Sharon and Cohen, Philip},
title = {Perceptual User Interfaces: Multimodal Interfaces That Process What Comes Naturally},
year = {2000},
issue_date = {March 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/330534.330538},
doi = {10.1145/330534.330538},
journal = {Commun. ACM},
month = mar,
pages = {45–53},
numpages = {9}
}

@article{Kong2020PANNsLP,
  title={PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition},
  author={Qiuqiang Kong and Yin Cao and Turab Iqbal and Yuxuan Wang and Wenwu Wang and Mark D. Plumbley},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2020},
  volume={28},
  pages={2880-2894}
}

@online{xtract,
  author = {Xtract.io},
  title = {Xtract.io video annotation tool},
  year = 2020,
  url = {https://www.xtract.io/lp/image-annotation-tool},
  urldate = {2021-10-08}
}

@inproceedings{mitra_comparing_2015,
author = {Mitra, Tanushree and Hutto, C.J. and Gilbert, Eric},
title = {Comparing Person- and Process-Centric Strategies for Obtaining Quality Data on Amazon Mechanical Turk},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702553},
doi = {10.1145/2702123.2702553},
abstract = {In the past half-decade, Amazon Mechanical Turk has radically changed the way many
scholars do research. The availability of a massive, distributed, anonymous crowd
of individuals willing to perform general human-intelligence micro-tasks for micro-payments
is a valuable resource for researchers and practitioners. This paper addresses the
challenges of obtaining quality annotations for subjective judgment oriented tasks
of varying difficulty. We design and conduct a large, controlled experiment (N=68,000)
to measure the efficacy of selected strategies for obtaining high quality data annotations
from non-experts. Our results point to the advantages of person-oriented strategies
over process-oriented strategies. Specifically, we find that screening workers for
requisite cognitive aptitudes and providing training in qualitative coding techniques
is quite effective, significantly outperforming control and baseline conditions. Interestingly,
such strategies can improve coder annotation accuracy above and beyond common benchmark
strategies such as Bayesian Truth Serum (BTS).},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1345–1354},
numpages = {10},
keywords = {qualitative coding, crowd sourcing, micro task, mechanical turk, human computation, experimentation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{laput_2015_zensors,
author = {Laput, Gierad and Lasecki, Walter S. and Wiese, Jason and Xiao, Robert and Bigham, Jeffrey P. and Harrison, Chris},
title = {Zensors: Adaptive, Rapidly Deployable, Human-Intelligent Sensor Feeds},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702416},
doi = {10.1145/2702123.2702416},
abstract = {The promise of "smart" homes, workplaces, schools, and other environments has long
been championed. Unattractive, however, has been the cost to run wires and install
sensors. More critically, raw sensor data tends not to align with the types of questions
humans wish to ask, e.g., do I need to restock my pantry? Although techniques like
computer vision can answer some of these questions, it requires significant effort
to build and train appropriate classifiers. Even then, these systems are often brittle,
with limited ability to handle new or unexpected situations, including being repositioned
and environmental changes (e.g., lighting, furniture, seasons). We propose Zensors,
a new sensing approach that fuses real-time human intelligence from online crowd workers
with automatic approaches to provide robust, adaptive, and readily deployable intelligent
sensors. With Zensors, users can go from question to live sensor feed in less than
60 seconds. Through our API, Zensors can enable a variety of rich end-user applications
and moves us closer to the vision of responsive, intelligent environments.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1935–1944},
numpages = {10},
keywords = {end-user programming, sensing, computer vision, smart environments, human computation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}
@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={91--99},
  year={2015}
}
@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}
@inproceedings{hu2019deep,
  title={Deep Multimodal Clustering for Unsupervised Audiovisual Learning},
  author={Hu, Di and Nie, Feiping and Li, Xuelong},
  booktitle={CVPR},
  year={2019}
}
@inproceedings{kidron2005pixels,
  title={Pixels that sound},
  author={Kidron, Einat and Schechner, Yoav Y and Elad, Michael},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={1},
  pages={88--95},
  year={2005},
  organization={IEEE}
}

@InProceedings{Senocak_2018_CVPR,
author = {Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and So Kweon, In},
title = {Learning to Localize Sound Source in Visual Scenes},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@article{Senocak_2020_TPAMI,
title = {Learning to Localize Sound Source in Visual Scenes: Analysis and Applications},
author = {Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and So Kweon, In},
journal = {TPAMI},
year = {2020},
publisher = {IEEE}
}

@inproceedings{hershey2000audio,
  title={Audio vision: Using audio-visual synchrony to locate sounds},
  author={Hershey, John R and Movellan, Javier R},
  booktitle={Advances in neural information processing systems},
  pages={813--819},
  year={2000}
}
@inproceedings{zhao2018sound,
  title={The sound of pixels},
  author={Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
  booktitle={ECCV},
  year={2018}
}
@inproceedings{gao2018learning,
  title={Learning to separate object sounds by watching unlabeled video},
  author={Gao, Ruohan and Feris, Rogerio and Grauman, Kristen},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={35--53},
  year={2018}
}
@article{ephrat2018looking,
  title={Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation},
  author={Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T and Rubinstein, Michael},
  journal={TOG},
  year={2018}
}
@inproceedings{wu2019DAM,
  title = {Dual Attention Matching for Audio-Visual Event Localization},
  author = {Wu, Yu and Zhu, Linchao and Yan, Yan and Yang, Yi},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year = {2019}
}
@inproceedings{lin2019dual,
  title={Dual-modality seq2seq network for audio-visual event localization},
  author={Lin, Yan-Bo and Li, Yu-Jhe and Wang, Yu-Chiang Frank},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2002--2006},
  year={2019},
  organization={IEEE}
}
@article{ma2019audio,
  title={Audio-visual emotion fusion (AVEF): A deep efficient weighted approach},
  author={Ma, Yaxiong and Hao, Yixue and Chen, Min and Chen, Jincai and Lu, Ping and Ko{\v{s}}ir, Andrej},
  journal={Information Fusion},
  volume={46},
  pages={184--192},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{pavel2020rescribe,
  title={Rescribe: Authoring and Automatically Editing Audio Descriptions},
  author={Pavel, Amy and Reyes, Gabriel and Bigham, Jeffrey P},
  booktitle={Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
  pages={747--759},
  year={2020}
}
@inproceedings{wang2021toward,
  title={Toward Automatic Audio Description Generation for Accessible Videos},
  author={Wang, Yujia and Liang, Wei and Huang, Haikun and Zhang, Yongqi and Li, Dingzeyu and Yu, Lap-Fai},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2021}
}
@inproceedings{richard2021audio,
  title={Audio-and gaze-driven facial animation of codec avatars},
  author={Richard, Alexander and Lea, Colin and Ma, Shugao and Gall, Jurgen and De la Torre, Fernando and Sheikh, Yaser},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={41--50},
  year={2021}
}
@article{morgado2018self,
  title={Self-supervised generation of spatial audio for 360 video},
  author={Morgado, Pedro and Vasconcelos, Nuno and Langlois, Timothy and Wang, Oliver},
  journal={arXiv preprint arXiv:1809.02587},
  year={2018}
}
@inproceedings{zeng2018audio,
  title={Audio-visual embedding for cross-modal music video retrieval through supervised deep CCA},
  author={Zeng, Donghuo and Yu, Yi and Oyama, Keizo},
  booktitle={2018 IEEE International Symposium on Multimedia (ISM)},
  pages={143--150},
  year={2018},
  organization={IEEE}
}

@inproceedings{brew2010interaction,
  title={The interaction between supervised learning and crowdsourcing},
  author={Brew, Anthony and Greene, Derek and Cunningham, P{\'a}draig},
  booktitle={NIPS workshop on computational social science and the wisdom of crowds},
  year={2010}
}

@article{halevy2009unreasonable,
  title={The unreasonable effectiveness of data},
  author={Halevy, Alon and Norvig, Peter and Pereira, Fernando},
  journal={IEEE Intelligent Systems},
  volume={24},
  number={2},
  pages={8--12},
  year={2009},
  publisher={IEEE}
}

@inproceedings{sambasivan_2021_everyone,
author = {Sambasivan, Nithya and Kapania, Shivani and Highfill, Hannah and Akrong, Diana and Paritosh, Praveen and Aroyo, Lora M},
title = {“Everyone Wants to Do the Model Work, Not the Data Work”: Data Cascades in High-Stakes AI},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445518},
doi = {10.1145/3411764.3445518},
abstract = { AI models are increasingly applied in high-stakes domains like health and conservation.
Data quality carries an elevated significance in high-stakes AI due to its heightened
downstream impact, impacting predictions like cancer detection, wildlife poaching,
and loan allocations. Paradoxically, data is the most under-valued and de-glamorised
aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews
with 53 AI practitioners in India, East and West African countries, and USA. We define,
identify, and present empirical evidence on Data Cascades—compounding events causing
negative, downstream effects from data issues—triggered by conventional AI/ML practices
that undervalue data quality. Data cascades are pervasive (92% prevalence), invisible,
delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing
data excellence as a first-class citizen of AI, resulting in safer and more robust
systems for all.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {39},
numpages = {15},
keywords = {India, Uganda, USA, ML, data cascades, data politics, application-domain experts, AI, raters, Ghana, developers, data collectors, data quality, Data, Nigeria, high-stakes AI, Kenya},
location = {Yokohama, Japan},
series = {CHI '21}
}


@article{liu2019use,
  title={Use what you have: Video retrieval using representations from collaborative experts},
  author={Liu, Yang and Albanie, Samuel and Nagrani, Arsha and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.13487},
  year={2019}
}
@article{hu2020discriminative,
  title={Discriminative sounding objects localization via self-supervised audiovisual matching},
  author={Hu, Di and Qian, Rui and Jiang, Minyue and Tan, Xiao and Wen, Shilei and Ding, Errui and Lin, Weiyao and Dou, Dejing},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={609--617},
  year={2017}
}

@article{aytar2016soundnet,
  title={Soundnet: Learning sound representations from unlabeled video},
  author={Aytar, Yusuf and Vondrick, Carl and Torralba, Antonio},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={892--900},
  year={2016}
}
@inproceedings{senocak2018learning,
  title={Learning to localize sound source in visual scenes},
  author={Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and Kweon, In So},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4358--4366},
  year={2018}
}

@inproceedings{owens2018audio,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={631--648},
  year={2018}
}

@inproceedings{tian2018audio,
  title={Audio-visual event localization in unconstrained videos},
  author={Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={247--263},
  year={2018}
}

@article{murray2011neural,
  title={The neural bases of multisensory processes},
  author={Murray, Micah M and Wallace, Mark T},
  year={2011},
  publisher={CRC Press}
}
@article{DBLP:journals/corr/YinN17,
	author    = {Pengcheng Yin and
	Graham Neubig},
	title     = {A Syntactic Neural Model for General-Purpose Code Generation},
	journal   = {CoRR},
	volume    = {abs/1704.01696},
	year      = {2017},
	url       = {http://arxiv.org/abs/1704.01696},
	archivePrefix = {arXiv},
	eprint    = {1704.01696},
	timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/YinN17},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{muller_2021_ground-truth,
author = {Muller, Michael and Wolf, Christine T. and Andres, Josh and Desmond, Michael and Joshi, Narendra Nath and Ashktorab, Zahra and Sharma, Aabhas and Brimijoin, Kristina and Pan, Qian and Duesterwald, Evelyn and Dugan, Casey},
title = {Designing Ground Truth and the Social Life of Labels},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445402},
doi = {10.1145/3411764.3445402},
abstract = { Ground-truth labeling is an important activity in machine learning. Many studies
have examined how crowdworkers apply labels to records in machine learning datasets.
However, there have been few studies that have examined the work of domain experts
when their knowledge and expertise are needed to apply labels. We provide a grounded
account of the work of labeling teams with domain experts, including the experiences
of labeling, collaborative configurations and work-practices, and quality issues.
We show three major patterns in the social design of ground truth data: Principled
design, Iterative design, and Improvisational design. We interpret our results through
theories of from Human Centered Data Science, and particularly work on human interventions
in data science work through the design and creation of data.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {94},
numpages = {16},
keywords = {Critical computing, Human centered data science, human centered machine learning},
location = {Yokohama, Japan},
series = {CHI '21}
}

@article{settles_activelearning_2012,
author = {Settles, Burr},
title = {Active Learning},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
volume = {6},
number = {1},
pages = {1-114},
year = {2012},
doi = {10.2200/S00429ED1V01Y201207AIM018},

URL = { 
        https://doi.org/10.2200/S00429ED1V01Y201207AIM018
    
},
eprint = { 
        https://doi.org/10.2200/S00429ED1V01Y201207AIM018
    
}

}

@article{cohn1996active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={129--145},
  year={1996}
}

@inproceedings{rashid_getting_2002,
author = {Rashid, Al Mamunur and Albert, Istvan and Cosley, Dan and Lam, Shyong K. and McNee, Sean M. and Konstan, Joseph A. and Riedl, John},
title = {Getting to Know You: Learning New User Preferences in Recommender Systems},
year = {2002},
isbn = {1581134592},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/502716.502737},
doi = {10.1145/502716.502737},
abstract = {Recommender systems have become valuable resources for users seeking intelligent ways
to search through the enormous volume of information available to them. One crucial
unsolved problem for recommender systems is how best to learn about a new user. In
this paper we study six techniques that collaborative filtering recommender systems
can use to learn about new users. These techniques select a sequence of items for
the collaborative filtering system to present to each new user for rating. The techniques
include the use of information theory to select the items that will give the most
value to the recommender system, aggregate statistics to select the items the user
is most likely to have an opinion about, balanced techniques that seek to maximize
the expected number of bits learned per presented item, and personalized techniques
that predict which items a user will have an opinion about. We study the techniques
thru offline experiments with a large pre-existing user data set, and thru a live
experiment with over 300 users. We show that the choice of learning technique significantly
affects the user experience, in both the user effort and the accuracy of the resulting
predictions.},
booktitle = {Proceedings of the 7th International Conference on Intelligent User Interfaces},
pages = {127–134},
numpages = {8},
keywords = {recommender systems, user modeling, collaborative filtering, information filtering, startup problem, entropy},
location = {San Francisco, California, USA},
series = {IUI '02}
}

@article{cooper2010predicting,
  title={Predicting protein structures with a multiplayer online game},
  author={Cooper, Seth and Khatib, Firas and Treuille, Adrien and Barbero, Janos and Lee, Jeehyung and Beenen, Michael and Leaver-Fay, Andrew and Baker, David and Popovi{\'c}, Zoran and others},
  journal={Nature},
  volume={466},
  number={7307},
  pages={756--760},
  year={2010},
  publisher={Nature Publishing Group}
}

@article{von2008recaptcha,
  title={recaptcha: Human-based character recognition via web security measures},
  author={Von Ahn, Luis and Maurer, Benjamin and McMillen, Colin and Abraham, David and Blum, Manuel},
  journal={Science},
  volume={321},
  number={5895},
  pages={1465--1468},
  year={2008},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{louie_noivce_2020,
author = {Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry, Michael and Cai, Carrie J.},
title = {Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376739},
doi = {10.1145/3313831.3376739},
abstract = {While generative deep neural networks (DNNs) have demonstrated their capacity for
creating novel musical compositions, less attention has been paid to the challenges
and potential of co-creating with these musical AIs, especially for novices. In a
needfinding study with a widely used, interactive musical AI, we found that the AI
can overwhelm users with the amount of musical content it generates, and frustrate
them with its non-deterministic output. To better match co-creation needs, we developed
AI-steering tools, consisting of Voice Lanes that restrict content generation to particular
voices; Example-Based Sliders to control the similarity of generated content to an
existing example; Semantic Sliders to nudge music generation in high-level directions
(happy/sad, conventional/surprising); and Multiple Alternatives of generated content
to audition and choose from. In a summative study (N=21), we discovered the tools
not only increased users' trust, control, comprehension, and sense of collaboration
with the AI, but also contributed to a greater sense of self-efficacy and ownership
of the composition relative to the AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {generative deep neural networks, co-creation, human-ai interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}


@inproceedings{cai_human-centered_2019,
author = {Cai, Carrie J. and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S. and Stumpe, Martin C. and Terry, Michael},
title = {Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300234},
doi = {10.1145/3290605.3300234},
abstract = {Machine learning (ML) is increasingly being used in image retrieval systems for medical
decision making. One application of ML is to retrieve visually similar medical images
from past patients (e.g. tissue from biopsies) to reference when making a medical
decision with a new patient. However, no algorithm can perfectly capture an expert's
ideal notion of similarity for every case: an image that is algorithmically determined
to be similar may not be medically relevant to a doctor's specific diagnostic needs.
In this paper, we identified the needs of pathologists when searching for similar
images retrieved using a deep learning algorithm, and developed tools that empower
users to cope with the search algorithm on-the-fly, communicating what types of similarity
are most important at different moments in time. In two evaluations with pathologists,
we found that these tools increased the diagnostic utility of images found and increased
user trust in the algorithm. The tools were preferred over a traditional interface,
without a loss in diagnostic accuracy. We also observed that users adopted new strategies
when using refinement tools, re-purposing them to test and understand the underlying
algorithm and to disambiguate ML errors from their own errors. Taken together, these
findings inform future human-ML collaborative systems for expert decision-making.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {clinical health, human-ai interaction, machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{shakeri-etal-2020-end,
    title = "End-to-End Synthetic Data Generation for Domain Adaptation of Question Answering Systems",
    author = "Shakeri, Siamak  and
      Nogueira dos Santos, Cicero  and
      Zhu, Henghui  and
      Ng, Patrick  and
      Nan, Feng  and
      Wang, Zhiguo  and
      Nallapati, Ramesh  and
      Xiang, Bing",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://aclanthology.org/2020.emnlp-main.439",
    doi = "10.18653/v1/2020.emnlp-main.439",
    pages = "5445--5460",
    abstract = "We propose an end-to-end approach for synthetic QA data generation. Our model comprises a single transformer-based encoder-decoder network that is trained end-to-end to generate both answers and questions. In a nutshell, we feed a passage to the encoder and ask the decoder to generate a question and an answer token-by-token. The likelihood produced in the generation process is used as a filtering score, which avoids the need for a separate filtering model. Our generator is trained by fine-tuning a pretrained LM using maximum likelihood estimation. The experimental results indicate significant improvements in the domain adaptation of QA models outperforming current state-of-the-art methods.",
}

@inproceedings{doersch2015unsupervised,
  title={Unsupervised visual representation learning by context prediction},
  author={Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1422--1430},
  year={2015}
}

@article{demirkus2014robust,
  title={Robust semi-automatic head pose labeling for real-world face video sequences},
  author={Demirkus, Meltem and Clark, James J and Arbel, Tal},
  journal={Multimedia Tools and Applications},
  volume={70},
  number={1},
  pages={495--523},
  year={2014},
  publisher={Springer}
}

@article{vajda_2015_semiautomatic,
author = {Vajda, Szil\'{a}rd and Rangoni, Yves and Cecotti, Hubert},
title = {Semi-Automatic Ground Truth Generation Using Unsupervised Clustering and Limited Manual Labeling},
year = {2015},
issue_date = {June 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {58},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2015.02.001},
doi = {10.1016/j.patrec.2015.02.001},
abstract = {We propose a fast and accurate semi-automatic labeling strategy.Human expert knowledge
(time and cost) is reduced to minimum.Unsupervised clustering and voting mechanism
decide for the labels.The method is generic, can be applied to other type of data.
For training supervised classifiers to recognize different patterns, large data collections
with accurate labels are necessary. In this paper, we propose a generic, semi-automatic
labeling technique for large handwritten character collections. In order to speed
up the creation of a large scale ground truth, the method combines unsupervised clustering
and minimal expert knowledge. To exploit the potential discriminant complementarities
across features, each character is projected into five different feature spaces. After
clustering the images in each feature space, the human expert labels the cluster centers.
Each data point inherits the label of its cluster's center. A majority (or unanimity)
vote decides the label of each character image. The amount of human involvement (labeling)
is strictly controlled by the number of clusters - produced by the chosen clustering
approach. To test the efficiency of the proposed approach, we have compared, and evaluated
three state-of-the art clustering methods (k-means, self-organizing maps, and growing
neural gas) on the MNIST digit data set, and a Lampung Indonesian character data set,
respectively. Considering a k-nn classifier, we show that labeling manually only 1.3%
(MNIST), and 3.2% (Lampung) of the training data, provides the same range of performance
than a completely labeled data set would.},
journal = {Pattern Recogn. Lett.},
month = jun,
pages = {23–28},
numpages = {6},
keywords = {Classifier combination, Character recognition, Feature selection, Clustering}
}

@inproceedings{ratner2017snorkel,
  title={Snorkel: Rapid training data creation with weak supervision},
  author={Ratner, Alexander and Bach, Stephen H and Ehrenberg, Henry and Fries, Jason and Wu, Sen and R{\'e}, Christopher},
  booktitle={Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases},
  volume={11},
  number={3},
  pages={269},
  year={2017}
}

@article{zhou2018brief,
  title={A brief introduction to weakly supervised learning},
  author={Zhou, Zhi-Hua},
  journal={National science review},
  volume={5},
  number={1},
  pages={44--53},
  year={2018},
  publisher={Oxford University Press}
}

@inproceedings{schein2002methods,
  title={Methods and metrics for cold-start recommendations},
  author={Schein, Andrew I and Popescul, Alexandrin and Ungar, Lyle H and Pennock, David M},
  booktitle={Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={253--260},
  year={2002}
}

@article{askhtorab_aiassisted_2021,
author = {Ashktorab, Zahra and Desmond, Michael and Andres, Josh and Muller, Michael and Joshi, Narendra Nath and Brachman, Michelle and Sharma, Aabhas and Brimijoin, Kristina and Pan, Qian and Wolf, Christine T. and Duesterwald, Evelyn and Dugan, Casey and Geyer, Werner and Reimer, Darrell},
title = {AI-Assisted Human Labeling: Batching for Efficiency without Overreliance},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449163},
doi = {10.1145/3449163},
abstract = {Human labeling of training data is often a time-consuming, expensive part of machine
learning. In this paper, we study "batch labeling", an AI-assisted UX paradigm, that
aids data labelers by allowing a single labeling action to apply to multiple records.
We ran a large scale study on Mechanical Turk with 156 participants to investigate
labeler-AI-batching system interaction. We investigate the efficacy of the system
when compared to a single-item labeling interface (i.e., labeling one record at-a-time),
and evaluate the impact of batch labeling on accuracy and time. We further investigate
the impact of AI algorithm quality and its effects on the labelers' overreliance,
as well as potential mechanisms for mitigating it. Our work offers implications for
the design of batch labeling systems and for work practices focusing on labeler-AI-batching
system interaction.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {89},
numpages = {27},
keywords = {data labeling, ai, collaboration, agents}
}


@article{hamroun2021multimodal,
  title={Multimodal Video Indexing (MVI): A New Method Based on Machine Learning and Semi-Automatic Annotation on Large Video Collections},
  author={Hamroun, Mohamed and Tamine, Karim and Crespin, Beno{\^\i}t},
  journal={International Journal of Image and Graphics},
  pages={2250022},
  year={2021},
  publisher={World Scientific}
}
@article{noroozi2017audio,
  title={Audio-visual emotion recognition in video clips},
  author={Noroozi, Fatemeh and Marjanovic, Marina and Njegus, Angelina and Escalera, Sergio and Anbarjafari, Gholamreza},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={60--75},
  year={2017},
  publisher={IEEE}
}

@inproceedings{Naderifar2017SnowballSA,
  title={Snowball Sampling: A Purposeful Method of Sampling in Qualitative Research},
  author={M. Naderifar and H. Goli and Fereshteh Ghaljaie},
  year={2017}
}

@misc{yao2021ais,
      title={It is AI's Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset}, 
      author={Bingsheng Yao and Dakuo Wang and Tongshuang Wu and Tran Hoang and Branda Sun and Toby Jia-Jun Li and Mo Yu and Ying Xu},
      year={2021},
      eprint={2109.03423},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{du-etal-2017-learning,
    title = "Learning to Ask: Neural Question Generation for Reading Comprehension",
    author = "Du, Xinya  and
      Shao, Junru  and
      Cardie, Claire",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "ACL",
    url = "https://aclanthology.org/P17-1123",
    doi = "10.18653/v1/P17-1123",
    pages = "1342--1352",
    abstract = "We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (\textit{i.e.,}, grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).",
}

@inproceedings{li_sovite:_2020,
	series = {{UIST} 2020},
	title = {{Multi-Modal} {Repairs} of {Conversational} {Breakdowns} in {Task-Oriented} {Dialogs}},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	doi = {10.1145/3379337.3415820},
	author = {Li, Toby Jia-Jun and Chen, Jingya and Xia, Haijun and Mitchell, Tom M. and Myers, Brad A.},
	year = {2020}
}

@inbook{beneteau_parenting:_2020,
author = {Beneteau, Erin and Boone, Ashley and Wu, Yuxing and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
title = {Parenting with Alexa: Exploring the Introduction of Smart Speakers on Family Dynamics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376344},
abstract = {Smart speakers have become pervasive in family homes, creating the potential for these
devices to influence parent-child dynamics and parenting behaviors. We investigate
the impact of introducing a smart speaker to 10 families with children, over four
weeks. We use pre- and post- deployment interviews with the whole family and in-home
audio capture of parent-child interactions with the smart speaker for our analysis.
Despite the smart speaker causing occasional conflict in the home, we observed that
parents lever-aged the smart speaker to further parenting goals. We found three forms
of influence the smart speaker has on family dynamics: 1) fostering communication,
2) disrupting access, and 3) augmenting parenting. All of these influences arise from
a communally accessible, stand-alone voice interface which democratizes family access
to technology. We discuss design implications in furthering parenting practices and
behaviors as the capabilities of the technology continue to improve.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{frohlich_2019_storybank,
author = {Frohlich, David M. and Rachovides, Dorothy and Riga, Kiriaki and Bhat, Ramnath and Frank, Maxine and Edirisinghe, Eran and Wickramanayaka, Dhammike and Jones, Matt and Harwood, Will},
title = {StoryBank: Mobile Digital Storytelling in a Development Context},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1518972},
abstract = {Mobile imaging and digital storytelling currently support a growing practice of multimedia
communication in the West. In this paper we describe a project which explores their
benefit in the East, to support non-textual information sharing in an Indian village.
Local audiovisual story creation and sharing activities were carried out in a one
month trial, using 10 customized cameraphones and a digital library of stories represented
on a village display. The findings show that the system was usable by a cross-section
of the community and valued for its ability to express a mixture of development and
community information in an accessible form. Lessons for the role of HCI in this context
are also discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1761–1770},
numpages = {10}
}


@inproceedings{rubegni_2014_fiabot,
author = {Rubegni, Elisa and Landoni, Monica},
title = {Fiabot! Design and Evaluation of a Mobile Storytelling Application for Schools},
year = {2014},
isbn = {9781450322720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593968.2593979},
doi = {10.1145/2593968.2593979},
abstract = {This paper contributes to the ongoing debate about how digital technology can be integrated
into the formal education system. Within a longitudinal research study, which lasted
four years, we conducted an investigation on how mobile technology can support educational
activities as defined by a school curriculum. Among the topics included in the school
curriculum, we focused on the literary field and developed a Digital StoryTelling
(DST) application, Fiabot!, to support this activity. Here, we describe the design
of the application and how we evaluated its impact on educational activities. The
application was designed and evaluated in two primary schools. The study had the objectives
of exploring whether Fiabot! supports children in achieving educational objectives
defined by the curriculum, how this effectively supports teachers, and to what extent
children like using it for the creation and sharing of their stories. Our findings
show that the application has a positive impact on curriculum enactment and effectively
supports the related educational activities. Overall, Fiabot! wasdemonstrated to be
very effective in stimulating children's discussion of a story's plot and characters.
Thus, Fiabot! supported children not only in being creative but also in organizing
their work and exploring a digital media opportunity. This resulted in the development
of new skills and the better grounding of previously acquired knowledge, while teachers
also had the opportunity to expand their teaching skills and get a taste of ICT's
potential in education.},
booktitle = {Proceedings of the 2014 Conference on Interaction Design and Children},
pages = {165–174},
numpages = {10},
keywords = {childcomputer interaction, digital storytelling, formal learning, mobile learning},
location = {Aarhus, Denmark},
series = {IDC '14}
}

@inbook{michaelis_2017_development,
author = {Michaelis, Joseph E. and Mutlu, Bilge},
title = {Someone to Read with: Design of and Experiences with an In-Home Learning Companion Robot for Reading},
year = {2017},
isbn = {9781450346559},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025499},
abstract = {The development of literacy and reading proficiency is a building block of lifelong
learning that must be supported both in the classroom and at home. While the promise
of interactive learning technologies has widely been demonstrated, little is known
about how an interactive robot might play a role in this development. We used eight
design features based on recommendations from interest-development and human-robot-interaction
literatures to design an in-home learning companion robot for children aged 11--12.
The robot was used as a technology probe to explore families' (N=8) habits and views
about reading, how a reading technology might be used, and how children perceived
reading with the robot. Our results indicate reading with the learning companion to
be a way to socially engage with reading, which may promote the development of reading
interest and ability. We discuss design and research implications based on our findings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {301–312},
numpages = {12}
}

@inproceedings{kory2014storytelling,
  title={Storytelling with robots: Learning companions for preschool children's language development},
  author={Kory, Jacqueline and Breazeal, Cynthia},
  booktitle={The 23rd IEEE international symposium on robot and human interactive communication},
  pages={643--648},
  year={2014},
  organization={IEEE}
}

@article{zevenbergen2003dialogic,
  title={Dialogic reading: A shared picture book reading intervention for preschoolers},
  author={Zevenbergen, Andrea A and Whitehurst, Grover J},
  journal={On reading books to children: Parents and teachers},
  pages={177--200},
  year={2003}
}

@article{paris2003assessing,
  title={Assessing narrative comprehension in young children},
  author={Paris, Alison H and Paris, Scott G},
  journal={Reading Research Quarterly},
  volume={38},
  number={1},
  pages={36--76},
  year={2003},
  publisher={Wiley Online Library}
}

@article{li_privacy:_2020,
author = {Li, Toby Jia-Jun and Chen, Jingya and Canfield, Brandon and Myers, Brad A.},
title = {Privacy-Preserving Script Sharing in GUI-Based Programming-by-Demonstration Systems},
year = {2020},
issue_date = {May 2020},
publisher = {ACM},
address = {New York, NY, USA},
volume = {4},
number = {CSCW1},
url = {https://doi.org/10.1145/3392869},
doi = {10.1145/3392869},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {060},
numpages = {23},
keywords = {privacy, programming by demonstration, script sharing, end user development}
}

@inbook{garg_conversational:_2020,
author = {Garg, Radhika and Sengupta, Subhasree},
title = {Conversational Technologies for In-Home Learning: Using Co-Design to Understand Children's and Parents' Perspectives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376631},
abstract = {Today, Conversational Agents (CA) are deeply integrated into the daily lives of millions
of families, which has led children to extensively interact with such devices. Studies
have suggested that the social nature of CA makes them a good learning companion for
children. Therefore, to understand children's preferences for the use of CAs for the
purpose of in-home learning, we conducted three participatory design sessions. In
order to identify parents' requirements in this regard, we also included them in the
third session. We found that children expect such devices to possess a personality
and an advanced level of intelligence, and support multiple content domains and learning
modes and human-like conversations. Parents desire such devices to include them in
their children's learning activities, foster social engagement, and to allow them
to monitor their children's use. This understanding will inform the design of future
CAs for the purpose of in-home learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{du_alexa:_2021,
author = {Du, Yao and Zhang, Kerri and Ramabadran, Sruthi and Liu, Yusa},
title = {“Alexa, What is That Sound?” A Video Analysis of Child-Agent Communication From Two Amazon Alexa Games},
year = {2021},
isbn = {9781450384520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459990.3465195},
abstract = {The rapid adoption of smart home speakers into households has enabled young children
to verbally communicate with voice assistants (VAs). VAs, such as Amazon Alexa, allow
children to use their voice to play various game-based activities and offer opportunities
to understand children's communication during child-agent communication. This qualitative
study describes findings from video analysis of young children between three and six
years old who engaged in voice-based gameplay with two commercial Alexa Skills, Animal
Sounds and Animal Game. We report findings about verbal behaviors and communication
breakdowns and repairs between children and Alexa, and discuss key considerations
for designing voice games for children.},
booktitle = {Interaction Design and Children},
pages = {513–520},
numpages = {8}
}

@ARTICLE{lin_parental:_2021,
  
AUTHOR={Lin, Chaolan and Šabanović, Selma and Dombrowski, Lynn and Miller, Andrew D. and Brady, Erin and MacDorman, Karl F.},   
	 
TITLE={Parental Acceptance of Children’s Storytelling Robots: A Projection of the Uncanny Valley of AI},      
	
JOURNAL={Frontiers in Robotics and AI},      
	
VOLUME={8},      

PAGES={49},     
	
YEAR={2021},      
	  
URL={https://www.frontiersin.org/article/10.3389/frobt.2021.579993},       
	
DOI={10.3389/frobt.2021.579993},      
	
ISSN={2296-9144},   
   
ABSTRACT={Parent–child story time is an important ritual of contemporary parenting. Recently, robots with artificial intelligence (AI) have become common. Parental acceptance of children’s storytelling robots, however, has received scant attention. To address this, we conducted a qualitative study with 18 parents using the research technique design fiction. Overall, parents held mixed, though generally positive, attitudes toward children’s storytelling robots. In their estimation, these robots would outperform screen-based technologies for children’s story time. However, the robots’ potential to adapt and to express emotion caused some parents to feel ambivalent about the robots, which might hinder their adoption. We found three predictors of parental acceptance of these robots: context of use, perceived agency, and perceived intelligence. Parents’ speculation revealed an uncanny valley of AI: a nonlinear relation between the human likeness of the artificial agent’s mind and affinity for the agent. Finally, we consider the implications of children’s storytelling robots, including how they could enhance equity in children’s access to education, and propose directions for research on their design to benefit family well-being.}
}



@inbook{hubbard2021chid,
author = {Hubbard, Layne Jackson and Chen, Yifan and Colunga, Eliana and Kim, Pilyoung and Yeh, Tom},
title = {Child-Robot Interaction to Integrate Reflective Storytelling Into Creative Play},
year = {2021},
isbn = {9781450383769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450741.3465254},
abstract = { When young children create, they are exploring their emerging skills. And when young
children reflect, they are transforming their learning experiences. Yet early childhood
play environments often lack toys and tools to scaffold reflection. In this work,
we design a stuffed animal robot to converse with young children and prompt creative
reflection through open-ended storytelling. We also contribute six design goals for
child-robot interaction design. In a hybrid Wizard of Oz study, 33 children ages 4-5
years old across 10 U.S. states engaged in creative play then conversed with a stuffed
animal robot to tell a story about their creation. By analyzing children’s story transcripts,
we discover four approaches that young children use when responding to the robot’s
reflective prompting: Imaginative, Narrative Recall, Process-Oriented, and Descriptive
Labeling. Across these approaches, we find that open-ended child-robot interaction
can integrate personally meaningful reflective storytelling into diverse creative
play practices.},
booktitle = {Creativity and Cognition},
articleno = {16},
numpages = {8}
}

@article{peck1989using,
  title={Using storytelling to promote language and literacy development},
  author={Peck, Jackie},
  journal={The Reading Teacher},
  volume={43},
  number={2},
  pages={138--141},
  year={1989},
  publisher={JSTOR}
}

@article{shanahan2010national,
  title={The National Early Literacy Panel: A summary of the process and the report},
  author={Shanahan, Timothy and Lonigan, Christopher J},
  journal={Educational Researcher},
  volume={39},
  number={4},
  pages={279--285},
  year={2010},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@inproceedings{bodker1999scenarios,
  title={Scenarios in user-centred design-setting the stage for reflection and action},
  author={Bodker, Susanne},
  booktitle={Proceedings of the 32nd Annual Hawaii International Conference on Systems Sciences. 1999. HICSS-32. Abstracts and CD-ROM of Full Papers},
  pages={11--pp},
  year={1999},
  organization={IEEE}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@inproceedings{wang_human_2020,
author = {Wang, Dakuo and Churchill, Elizabeth and Maes, Pattie and Fan, Xiangmin and Shneiderman, Ben and Shi, Yuanchun and Wang, Qianying},
title = {From Human-Human Collaboration to Human-AI Collaboration: Designing AI Systems That Can Work Together with People},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381069},
doi = {10.1145/3334480.3381069},
abstract = {Artificial Intelligent (AI) and Machine Learning (ML) algorithms are coming out of
research labs into the real-world applications, and recent research has focused a
lot on Human-AI Interaction (HAI) and Explainable AI (XAI). However, Interaction is
not the same as Collaboration. Collaboration involves mutual goal understanding, preemptive
task co-management and shared progress tracking. Most of human activities today are
done collaboratively, thus, to integrate AI into the already-complicated human workflow,
it is critical to bring the Computer-Supported Cooperative Work (CSCW) perspective
into the root of the algorithmic research and plan for a Human-AI Collaboration future
of work. In this panel we ask: Can this future for trusted human-AI collaboration
be realized? If so, what will it take? This panel will bring together HCI experts
who work on human collaboration and AI applications in various application contexts,
from industry and academia and from both the U.S. and China. Panelists will engage
the audience through discussion of their shared and diverging visions, and through
suggestions for opportunities and challenges for the future of human-AI collaboration.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {trusted ai, group collaboration, explainable ai, ai-powered healthcare, computer-supported corporative work, ai partner, human-ai collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{tamura2017effects,
author = {Tamura, Yumiko and Kimoto, Mitsuhiko and Shiomi, Masahiro and Iio, Takamasa and Shimohara, Katsunori and Hagita, Norihiro},
title = {Effects of a Listener Robot with Children in Storytelling},
year = {2017},
isbn = {9781450351133},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3125739.3125750},
doi = {10.1145/3125739.3125750},
abstract = {This paper investigates the effects of a listener robot that joins a storytelling
situation for children as a side-participant. For this purpose, we develop a storytelling-robot
system that consists of both reader and listener robots. Our semi-autonomous system
involves a human operator who makes correct responses and provides easily understandable
answers to the children's questions during storytelling. We develop a gaze model for
the natural and autonomous gaze behaviors of a reader robot by considering multiple
listeners and a storytelling object (a display that shows images). We conducted an
experiment with 16 children to investigate whether they preferred storytelling with/without
the listener robot and the changes of speech activities during the storytelling. Children
preferred storytelling with the listener robot to storytelling without it. Their speech
activities decreased when the listener robot was involved in the storytelling.},
booktitle = {Proceedings of the 5th International Conference on Human Agent Interaction},
pages = {35–43},
numpages = {9},
keywords = {human-robot interaction, two robots, storytelling},
location = {Bielefeld, Germany},
series = {HAI '17}
}

@article{muller_participatory:_1993,
author = {Muller, Michael J. and Kuhn, Sarah},
title = {Participatory Design},
year = {1993},
issue_date = {June 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/153571.255960},
doi = {10.1145/153571.255960},
journal = {Commun. ACM},
month = jun,
pages = {24–28},
numpages = {5}
}

@article{xu_same:_2021,
title = {Same benefits, different communication patterns: Comparing Children's reading with a conversational agent vs. a human partner},
journal = {Computers \& Education},
volume = {161},
pages = {104059},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.104059},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520302578},
author = {Ying Xu and Dakuo Wang and Penelope Collins and Hyelim Lee and Mark Warschauer},
keywords = {Conversational agents, Language development, Storybook reading, Communication, Young children},
abstract = {Storybook reading accompanied by adult-guided conversation provides a stimulating context for children's language development. Conversational agents powered by artificial intelligence, such as smart speakers, are prevalent in children's homes and have the potential to engage children in storybook reading as language partners. However, little research has explored the effectiveness of using conversational agents to support children's language development. This study examined how an automated conversational agent can read stories to children via a smart speaker while asking questions and providing contingent feedback. Using a randomized experiment among 90 children aged three to six years, this study compared these children's story comprehension and verbal engagement in storybook reading with a conversational agent versus an adult. The conversational agent's guided conversation was found to be as supportive in improving children's story comprehension as that provided by an adult language partner. At the same time, this study uncovered a number of differences in children's verbal engagement when interacting with a conversational agent versus with an adult. Specifically, children who read with the conversational agent responded to questions with better intelligibility, whereas those who read with an adult responded to questions with higher productivity, lexical diversity, and topical relevance. And the two groups responded to questions with a similar level of accuracy. In addition, questions requiring high cognitive demand amplified the differences in of verbal engagement between the conversational agent and adult partner. The study offers important implications for developing and researching conversational agent systems to support children's language development.}
}

@article{bhatti2021conversational,
  title={Conversational User Interfaces As Assistive interlocutors For Young Children's Bilingual Language Acquisition},
  author={Bhatti, Neelma and Stelter, Timothy L and McCrickard, D Scott},
  journal={arXiv preprint arXiv:2103.09228},
  year={2021}
}

@inproceedings{lovato2019hey,
  title={Hey Google, do unicorns exist? Conversational agents as a path to answers to children's questions},
  author={Lovato, Silvia B and Piper, Anne Marie and Wartella, Ellen A},
  booktitle={Proceedings of the 18th ACM International Conference on Interaction Design and Children},
  pages={301--313},
  year={2019}
}

@misc{wiederhold2018alexa,
  title={“Alexa, are you my Mom?” The role of artificial intelligence in child development},
  author={Wiederhold, Brenda K},
  year={2018},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@inproceedings{xu2020using,
  title={Using conversational agents to foster young children's science learning from screen media},
  author={Xu, Ying},
  booktitle={Proceedings of the 2020 ACM Interaction Design and Children Conference: Extended Abstracts},
  pages={14--19},
  year={2020}
}

@inproceedings{xu2020you,
  title={What Are You Talking To?: Understanding Children's Perceptions of Conversational Agents},
  author={Xu, Ying and Warschauer, Mark},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}

@inbook{xu_current:_2021,
author = {Xu, Ying and Branham, Stacy and Deng, Xinwei and Collins, Penelope and Warschauer, Mark},
title = {Are Current Voice Interfaces Designed to Support Children’s Language Development?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445271},
abstract = { With the rapid development of artificial intelligence, voice user interfaces (VUIs)
capable of speech-based interaction are poised to support children’s language development
by serving as their language partners. This paper reports an analytic evaluation of
the currently available voice-based apps targeting young children to examine whether
and how they incorporate evidence-based dialogue strategies that effectively support
children’s learning. We found that, despite the fact that the current apps support
a variety of language activities, most fail to carry out open-ended dialogue and provide
extended back-and-forth opportunities, thus limiting their ability to encourage children’s
language output and increase children’s language exposure. We discuss four design
implications for developing VUIs that initiate dialogue and provide feedback in ways
that better facilitate children’s language learning.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {633},
numpages = {12}
}

@article{mitchell2018never,
	title={Never-ending learning},
	author={Mitchell, Tom and Cohen, William and Hruschka, Estevam and Talukdar, Partha and Yang, Bo and Betteridge, Justin and Carlson, Andrew and Dalvi, B and Gardner, Matt and Kisiel, Bryan and others},
	journal={Communications of the ACM},
	volume={61},
	number={5},
	pages={103--115},
	year={2018},
	publisher={ACM}
}
@article{grice1975logic,
	title={Logic and conversation},
	author={Grice, H Paul and Cole, Peter and Morgan, Jerry and others},
	journal={1975},
	pages={41--58},
	year={1975}
}

@inproceedings{vaithilingam2019bespoke,
	title={Bespoke: Interactively synthesizing custom GUIs from command-line applications by demonstration},
	author={Vaithilingam, Priyan and Guo, Philip J},
	booktitle={Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology, UIST},
	volume={19},
	year={2019}
}

@article{li2019smartshell,
	title={SmartShell: Automated Shell Scripts Synthesis from Natural Language},
	author={Li, Hao and Wang, Yu-Ping and Yin, Jie and Tan, Gang},
	journal={International Journal of Software Engineering and Knowledge Engineering},
	volume={29},
	number={02},
	pages={197--220},
	year={2019},
	publisher={World Scientific}
}

@book{wright1995storytelling,
  title={Storytelling with children},
  author={Wright, Andrew},
  year={1995},
  publisher={Oxford University}
}



@inbook{dietz_storycoder_2021,
author = {Dietz, Griffin and Le, Jimmy K and Tamer, Nadin and Han, Jenny and Gweon, Hyowon and Murnane, Elizabeth L and Landay, James A.},
title = {StoryCoder: Teaching Computational Thinking Concepts Through Storytelling in a Voice-Guided App for Children},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445039},
abstract = { Computational thinking (CT) education reaches only a fraction of young children,
in part because CT learning tools often require expensive hardware or fluent literacy.
Informed by needfinding interviews, we developed a voice-guided smartphone application
leveraging storytelling as a creative activity by which to teach CT concepts to 5-
to 8-year-old children. The app includes two storytelling games where users create
and listen to stories as well as four CT games where users then modify those stories
to learn about sequences, loops, events, and variables. We improved upon the app design
through wizard-of-oz testing (N = 28) and iterative design testing (N = 22) before
conducting an evaluation study (N = 22). Children were successfully able to navigate
the app, effectively learn about the target computing concepts, and, after using the
app, children demonstrated above-chance performance on a near transfer CT concept
recognition task.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {54},
numpages = {15}
}

@misc{ling_luka_2021,
	title = {Luka {AI} reading companion},
	url = {https://luka.ling.ai/},
	abstract = {Built with cutting-edge AI technology, Luka reads aloud books put in front of him, page by page, in any order.},
	urldate = {2021-08-15},
	author = {Ling},
	year = {2021},
	file = {Snapshot:/Users/toby/Zotero/storage/XUZW4BPJ/luka.ling.ai.html:text/html},
}

@misc{pillar_learning_meet_2021,
	title = {Meet {Codi} - {An} {Interactive}, {AI}-{Enabled} {Smart} {Toy} for {Kids}!},
	url = {https://www.pillarlearning.com/},
	abstract = {Introducing Codi, your new robot friend! With 200+ songs and stories to share, voice recognition, and more, Codi makes playtime fun and interactive for kids!},
	language = {en},
	urldate = {2021-08-15},
	author = {Pillar Learning},
	year = {2021},
	file = {Snapshot:/Users/toby/Zotero/storage/4A7HPNX3/www.pillarlearning.com.html:text/html},
}


@article{kotaman2020impacts,
  title={Impacts of dialogical storybook reading on young children’s reading attitudes and vocabulary development},
  author={Kotaman, Huseyin},
  journal={Reading Improvement},
  volume={57},
  number={1},
  pages={40--45},
  year={2020},
  publisher={Project Innovation}
}

@inproceedings{mostow_generationg:_2009,
author = {Mostow, Jack and Chen, Wei},
title = {Generating Instruction Automatically for the Reading Strategy of Self-Questioning},
year = {2009},
isbn = {9781607500285},
publisher = {IOS Press},
address = {NLD},
abstract = {Self-questioning is an important reading comprehension strategy, so it would be useful
for an intelligent tutor to help students apply it to any given text. Our goal is
to help children generate questions that make them think about the text in ways that
improve their comprehension and retention. However, teaching and scaffolding self-questioning
involve analyzing both the text and the students' responses. This requirement poses
a tricky challenge to generating such instruction automatically, especially for children
too young to respond by typing. This paper describes how to generate self-questioning
instruction for an automated reading tutor. Following expert pedagogy, we decompose
strategy instruction into describing, modeling, scaffolding, and prompting the strategy.
We present a working example to illustrate how we generate each of these four phases
of instruction for a given text. We identify some relevant criteria and use them to
evaluate the generated instruction on a corpus of 513 children's stories.},
booktitle = {Proceedings of the 2009 Conference on Artificial Intelligence in Education: Building Learning Systems That Care: From Knowledge Representation to Affective Modelling},
pages = {465–472},
numpages = {8},
keywords = {Reading Tutor, Reading Comprehension Strategy, Self-Questioning}
}


@article{hill2015goldilocks,
  title={The goldilocks principle: Reading children's books with explicit memory representations},
  author={Hill, Felix and Bordes, Antoine and Chopra, Sumit and Weston, Jason},
  journal={arXiv preprint arXiv:1511.02301},
  year={2015}
}

@inproceedings{labutov-etal-2015-deep,
    title = "Deep Questions without Deep Understanding",
    author = "Labutov, Igor  and
      Basu, Sumit  and
      Vanderwende, Lucy",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "ACL",
    url = "https://aclanthology.org/P15-1086",
    doi = "10.3115/v1/P15-1086",
    pages = "889--898",
}

@article{chkroun2019lia,
	title={LIA: A Virtual Assistant that Can Be Taught New Commands by Speech},
	author={Chkroun, Merav and Azaria, Amos},
	journal={International Journal of Human--Computer Interaction},
	pages={1--12},
	year={2019},
	publisher={Taylor \& Francis}
}

@inproceedings{labutov2018lia,
	title={LIA: A natural language programmable personal assistant},
	author={Labutov, Igor and Srivastava, Shashank and Mitchell, Tom},
	booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
	pages={145--150},
	year={2018}
}




@inproceedings{Lin:2009:EPM:1502650.1502667,
	author = {Lin, James and Wong, Jeffrey and Nichols, Jeffrey and Cypher, Allen and Lau, Tessa A.},
	title = {End-user Programming of Mashups with Vegemite},
	booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
	series = {IUI '09},
	year = {2009},
	isbn = {978-1-60558-168-2},
	location = {Sanibel Island, Florida, USA},
	pages = {97--106},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/1502650.1502667},
	doi = {10.1145/1502650.1502667},
	acmid = {1502667},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {automation, data integration, end-user programming, mashup, programming by demonstration, web},
} 

@inproceedings{Mackay:1990:PSC:99332.99356,
	author = {Mackay, Wendy E.},
	title = {Patterns of Sharing Customizable Software},
	booktitle = {Proceedings of the 1990 ACM Conference on Computer-supported Cooperative Work},
	series = {CSCW '90},
	year = {1990},
	isbn = {0-89791-402-3},
	location = {Los Angeles, California, USA},
	pages = {209--221},
	numpages = {13},
	url = {http://doi.acm.org/10.1145/99332.99356},
	doi = {10.1145/99332.99356},
	acmid = {99356},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@inproceedings{Fraser:2019:RCP:3290605.3300527,
	author = {Fraser, C. Ailie and Ngoon, Tricia J. and Dontcheva, Mira and Klemmer, Scott},
	title = {RePlay: Contextually Presenting Learning Videos Across Software Applications},
	booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
	series = {CHI '19},
	year = {2019},
	isbn = {978-1-4503-5970-2},
	location = {Glasgow, Scotland Uk},
	pages = {297:1--297:13},
	articleno = {297},
	numpages = {13},
	url = {http://doi.acm.org/10.1145/3290605.3300527},
	doi = {10.1145/3290605.3300527},
	acmid = {3300527},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {contextual search, cross-application, video tutorials},
} 

@inproceedings{Barman:2016:RWA:2983990.2984020,
	author = {Barman, Shaon and Chasins, Sarah and Bodik, Rastislav and Gulwani, Sumit},
	title = {Ringer: Web Automation by Demonstration},
	booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	series = {OOPSLA 2016},
	year = {2016},
	isbn = {978-1-4503-4444-9},
	location = {Amsterdam, Netherlands},
	pages = {748--764},
	numpages = {17},
	url = {http://doi.acm.org/10.1145/2983990.2984020},
	doi = {10.1145/2983990.2984020},
	acmid = {2984020},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Automation, Browser, Javascript, Record-Replay},
} 



@article{chasins2017skip,
	title={Skip blocks: reusing execution history to accelerate web scripts},
	author={Chasins, Sarah and Bodik, Rastislav},
	journal={Proceedings of the ACM on Programming Languages},
	volume={1},
	number={OOPSLA},
	pages={51},
	year={2017},
	publisher={ACM}
}

@article{DBLP:journals/corr/abs-1708-06384,
	author    = {Gaurav Srivastava and
	Saksham Chitkara and
	Kevin Ku and
	Swarup Kumar Sahoo and
	Matt Fredrikson and
	Jason I. Hong and
	Yuvraj Agarwal},
	title     = {PrivacyProxy: Leveraging Crowdsourcing and In Situ Traffic Analysis
	to Detect and Mitigate Information Leakage},
	journal   = {CoRR},
	volume    = {abs/1708.06384},
	year      = {2017},
	url       = {http://arxiv.org/abs/1708.06384},
	archivePrefix = {arXiv},
	eprint    = {1708.06384},
	timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-06384},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{continella2017obfuscation,
	title={Obfuscation-Resilient Privacy Leak Detection for Mobile Apps Through Differential Analysis.},
	author={Continella, Andrea and Fratantonio, Yanick and Lindorfer, Martina and Puccetti, Alessandro and Zand, Ali and Kruegel, Christopher and Vigna, Giovanni},
	booktitle={NDSS},
	year={2017}
}

@article{Wang:2019:LTA:3323054.3314415,
	author = {Wang, Xiaolei and Continella, Andrea and Yang, Yuexiang and He, Yongzhong and Zhu, Sencun},
	title = {LeakDoctor: Toward Automatically Diagnosing Privacy Leaks in Mobile Applications},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	issue_date = {March 2019},
	volume = {3},
	number = {1},
	month = mar,
	year = {2019},
	issn = {2474-9567},
	pages = {28:1--28:25},
	articleno = {28},
	numpages = {25},
	url = {http://doi.acm.org/10.1145/3314415},
	doi = {10.1145/3314415},
	acmid = {3314415},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Differential Analysis, Mobile Applications, Privacy Leak, Taint Flow Analysis},
}

@article{Li:2017:PET:3139486.3130941,
	author = {Li, Yuanchun and Chen, Fanglin and Li, Toby Jia-Jun and Guo, Yao and Huang, Gang and Fredrikson, Matthew and Agarwal, Yuvraj and Hong, Jason I.},
	title = {PrivacyStreams: Enabling Transparency in Personal Data Processing for Mobile Apps},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	issue_date = {September 2017},
	volume = {1},
	number = {3},
	month = sep,
	year = {2017},
	issn = {2474-9567},
	pages = {76:1--76:26},
	articleno = {76},
	numpages = {26},
	url = {http://doi.acm.org/10.1145/3130941},
	doi = {10.1145/3130941},
	acmid = {3130941},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Personal data, data granularity, functional programming, mobile apps, transparency},
} 

@Inbook{Siek2014,
	author="Siek, Katie A.
	and Hayes, Gillian R.
	and Newman, Mark W.
	and Tang, John C.",
	editor="Olson, Judith S.
	and Kellogg, Wendy A.",
	title="Field Deployments: Knowing from Using in Context",
	bookTitle="Ways of Knowing in HCI",
	year="2014",
	publisher="Springer New York",
	address="New York, NY",
	pages="119--142",
	abstract="Researchers deploy systems, typically robust prototypes, to users in situ for a number of purposes: to assess changes in behavior, to gather feedback on how to improve the system, to influence the attitude of the population to adopt the final system in the future. Researchers collect both quantitative data (e.g., frequency of use) and qualitative data (e.g., observations and interviews about situations of use and attitudes), and thus, this method is associated with a number of other methods in this book.",
	isbn="978-1-4939-0378-8",
	doi="10.1007/978-1-4939-0378-8_6",
	url="https://doi.org/10.1007/978-1-4939-0378-8_6"
}


@misc{amazon_amazon_nodate,
	title = {Amazon {Alexa} {Design} {Guide}},
	url = {https://developer.amazon.com/docs/alexa-design/get-started.html},
	urldate = {2019-09-13},
		year = {2019},
	author = {Amazon},
	file = {Get Started with the Guide | Alexa Skills Kit:/Users/toby/Zotero/storage/H2D7853L/get-started.html:text/html}
}

@inproceedings{amershi_2019_guidelines,
author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
title = {Guidelines for Human-AI Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300233},
doi = {10.1145/3290605.3300233},
abstract = {Advances in artificial intelligence (AI) frame opportunities and challenges for user
interface design. Principles for human-AI interaction have been discussed in the human-computer
interaction community for over two decades, but more study and innovation are needed
in light of advances in AI and the growing uses of AI technologies in human-facing
applications. We propose 18 generally applicable design guidelines for human-AI interaction.
These guidelines are validated through multiple rounds of evaluation including a user
study with 49 design practitioners who tested the guidelines against 20 popular AI-infused
products. The results verify the relevance of the guidelines over a spectrum of interaction
scenarios and reveal gaps in our knowledge, highlighting opportunities for further
research. Based on the evaluations, we believe the set of design guidelines can serve
as a resource to practitioners working on the design of applications and features
that harness AI technologies, and to researchers interested in the further development
of human-AI interaction design principles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design guidelines, human-ai interaction, ai-infused systems},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}


@misc{google_conversation_nodate,
	title = {Conversation design {\textbar} {Actions} on {Google}},
	url = {https://developers.google.com/actions/design/},
	abstract = {Design guidelines for Actions on Google},
	language = {en},
	urldate = {2019-09-13},
		year = {2019},
	journal = {Google Developers},
	author = {Google}
}

@article{oviatt2000designing,
	title={Designing the user interface for multimodal speech and pen-based gesture applications: state-of-the-art systems and future research directions},
	author={Oviatt, Sharon and Cohen, Phil and Wu, Lizhong and Duncan, Lisbeth and Suhm, Bernhard and Bers, Josh and Holzman, Thomas and Winograd, Terry and Landay, James and Larson, Jim and others},
	journal={Human-computer interaction},
	volume={15},
	number={4},
	pages={263--322},
	year={2000},
	publisher={Taylor \& Francis}
}

@article{branigan2010linguistic,
title={Linguistic alignment between people and computers},
author={Branigan, Holly P and Pickering, Martin J and Pearson, Jamie and McLean, Janet F},
journal={Journal of Pragmatics},
volume={42},
number={9},
pages={2355--2368},
year={2010},
publisher={Elsevier}
}

@inproceedings{mcnair1994improving,
title={Improving recognizer acceptance through robust, natural speech repair},
author={McNair, Arthur E and Waibel, Alex},
booktitle={Third International Conference on Spoken Language Processing},
year={1994}
}

 


@inproceedings{Pearson:2006:ALB:1124772.1124948,
	author = {Pearson, Jamie and Hu, Jiang and Branigan, Holly P. and Pickering, Martin J. and Nass, Clifford I.},
	title = {Adaptive Language Behavior in HCI: How Expectations and Beliefs About a System Affect Users' Word Choice},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	series = {CHI '06},
	year = {2006},
	isbn = {1-59593-372-7},
	location = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
	pages = {1177--1180},
	numpages = {4},
	url = {http://doi.acm.org/10.1145/1124772.1124948},
	doi = {10.1145/1124772.1124948},
	acmid = {1124948},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {HCI, adaptation, alignment, interaction technologies, language behavior, natural language},
} 





@inproceedings{Jiang:2013:URV:2484028.2484092,
	author = {Jiang, Jiepu and Jeng, Wei and He, Daqing},
	title = {How Do Users Respond to Voice Input Errors?: Lexical and Phonetic Query Reformulation in Voice Search},
	booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	series = {SIGIR '13},
	year = {2013},
	isbn = {978-1-4503-2034-4},
	location = {Dublin, Ireland},
	pages = {143--152},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2484028.2484092},
	doi = {10.1145/2484028.2484092},
	acmid = {2484092},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {query reformulation, voice input errors, voice search},
} 


@inproceedings{Luger:2016:LRB:2858036.2858288,
	author = {Luger, Ewa and Sellen, Abigail},
	title = {"Like Having a Really Bad PA": The Gulf Between User Expectation and Experience of Conversational Agents},
	booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
	series = {CHI '16},
	year = {2016},
	isbn = {978-1-4503-3362-7},
	location = {San Jose, California, USA},
	pages = {5286--5297},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/2858036.2858288},
	doi = {10.1145/2858036.2858288},
	acmid = {2858288},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {conversational agents, evaluation, mental models},
} 


@Article{Brennan1991,
	author="Brennan, Susan E.",
	title="Conversation with and through computers",
	journal="User Modeling and User-Adapted Interaction",
	year="1991",
	month="Mar",
	day="01",
	volume="1",
	number="1",
	pages="67--86",
	abstract="People design what they say specifically for their conversational partners, and they adapt to their partners over the course of a conversation. A comparison of keyboard conversations involving a simulated computer partner (as in a natural language interface) with those involving a human partner (as in teleconferencing) yielded striking differences and some equally striking similarities. For instance, there were significantly fewer acknowledgments in human/computer dialogue than in human/human. However, regardless of the conversational partner, people expected connectedness across conversational turns. In addition, the style of a partner's response shaped what people subsequently typed. These results suggest some issues that need to be addressed before a natural language computer interface will be able to hold up its end of a conversation.",
	issn="1573-1391",
	doi="10.1007/BF00158952",
	url="https://doi.org/10.1007/BF00158952"
}

@inproceedings{Cowan:2017:IHY:3098279.3098539,
	author = {Cowan, Benjamin R. and Pantidi, Nadia and Coyle, David and Morrissey, Kellie and Clarke, Peter and Al-Shehri, Sara and Earley, David and Bandeira, Natasha},
	title = {"What Can I Help You with?": Infrequent Users' Experiences of Intelligent Personal Assistants},
	booktitle = {Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services},
	series = {MobileHCI '17},
	year = {2017},
	isbn = {978-1-4503-5075-4},
	location = {Vienna, Austria},
	pages = {43:1--43:12},
	articleno = {43},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/3098279.3098539},
	doi = {10.1145/3098279.3098539},
	acmid = {3098539},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {intelligent personal assistants, privacy, speech interfaces, trust, user experience},
} 


@article{el2011systematic,
	title={A systematic review of re-identification attacks on health data},
	author={El Emam, Khaled and Jonker, Elizabeth and Arbuckle, Luk and Malin, Bradley},
	journal={PloS one},
	volume={6},
	number={12},
	pages={e28071},
	year={2011},
	publisher={Public Library of Science}
}

@misc{google_advertising,
	title = {Advertising {ID} {\textbar} {Android} {Developers}},
	url = {http://www.androiddocs.com/google/play-services/id.html},
	urldate = {2019-08-24},
	author = {Google},
	year={2019},
	file = {Advertising ID | Android Developers:/Users/toby/Zotero/storage/M2VHMCND/id.html:text/html}
}



@inproceedings{Hartmann:2007:PSR:1294211.1294254,
	author = {Hartmann, Bj\"{o}rn and Wu, Leslie and Collins, Kevin and Klemmer, Scott R.},
	title = {Programming by a Sample: Rapidly Creating Web Applications with D.Mix},
	booktitle = {Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology},
	series = {UIST '07},
	year = {2007},
	isbn = {978-1-59593-679-0},
	location = {Newport, Rhode Island, USA},
	pages = {241--250},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/1294211.1294254},
	doi = {10.1145/1294211.1294254},
	acmid = {1294254},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {mashups, programming by example modification, prototyping, web services},
} 

@inproceedings{miller2002multiple,
  title={Multiple selections in smart text editing},
  author={Miller, Robert C and Myers, Brad A},
  booktitle={Proceedings of the 7th international conference on Intelligent user interfaces},
  pages={103--110},
  year={2002},
  organization={ACM}
}

@inproceedings{myers2002flexi,
  title={Flexi-modal and multi-machine user interfaces},
  author={Myers, Brad and Malkin, Robert and Bett, Michael and Waibel, Alex and Bostwick, Ben and Miller, Robert C and Yang, Jie and Denecke, Matthias and Seemann, Edgar and Zhu, Jie and others},
  booktitle={Proceedings. Fourth IEEE International Conference on Multimodal Interfaces},
  pages={343--348},
  year={2002},
  organization={IEEE}
}

@inproceedings{kurihara2006speech,
  title={Speech pen: predictive handwriting based on ambient multimodal recognition},
  author={Kurihara, Kazutaka and Goto, Masataka and Ogata, Jun and Igarashi, Takeo},
  booktitle={Proceedings of the SIGCHI conference on human factors in computing systems},
  pages={851--860},
  year={2006},
  organization={ACM}
}

@article{oviatt2000perceptual,
  title={Perceptual user interfaces: multimodal interfaces that process what comes naturally},
  author={Oviatt, Sharon and Cohen, Philip},
  journal={Communications of the ACM},
  volume={43},
  number={3},
  pages={45--53},
  year={2000},
  publisher={ACM}
}


@article{mankoff2000oops,
	title={OOPS: a toolkit supporting mediation techniques for resolving ambiguity in recognition-based interfaces},
	author={Mankoff, Jennifer and Abowd, Gregory D and Hudson, Scott E},
	journal={Computers \& Graphics},
	volume={24},
	number={6},
	pages={819--834},
	year={2000},
	publisher={Elsevier}
}


@INPROCEEDINGS{Yin:8595231, 
	author={P. {Yin} and B. {Deng} and E. {Chen} and B. {Vasilescu} and G. {Neubig}}, 
	booktitle={2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)}, 
	title={Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow}, 
	year={2018}, 
	volume={}, 
	number={}, 
	pages={476-486}, 
	keywords={data mining;Java;learning (artificial intelligence);neural nets;question answering (information retrieval);data set;high-quality code snippets;heuristic methods;high-quality aligned data;hand-crafted features;probabilistic model;mined NL-code pairs;mining methods;NL-code mining;programming languages;natural language pairs;stack overflow;code synthesis;code retrieval;code summarization;data-driven models;parallel data;StackOverflow;aligned code mining;neural networks;Data mining;Python;Feature extraction;Java;Natural languages;Training;Code Mining;Stack Overflow;Neural Networks}, 
	doi={}, 
	ISSN={2574-3864}, 
	month={May},}

@inproceedings{chasins2018rousillon,
	author = {Chasins, Sarah E. and Mueller, Maria and Bodik, Rastislav},
	title = {Rousillon: Scraping Distributed Hierarchical Web Data},
	booktitle = {Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
	series = {UIST '18},
	year = {2018},
	isbn = {978-1-4503-5948-1},
	location = {Berlin, Germany},
	pages = {963--975},
	numpages = {13},
	url = {http://doi.acm.org/10.1145/3242587.3242661},
	doi = {10.1145/3242587.3242661},
	acmid = {3242661},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {data science, end-user programming, generalization, program synthesis, programming by demonstration, web scraping},
} 


@incollection{Lau:2001:LRT:369505.369519,
	author = {Lau, Tessa and Wolfman, Steven A. and Domingos, Pedro and Weld, Daniel S.},
	chapter = {Learning Repetitive Text-editing Procedures with SMARTedit},
	title = {Your Wish is My Command},
	year = {2001},
	isbn = {1-55860-688-2},
	pages = {209--226},
	numpages = {18},
	url = {http://dl.acm.org/citation.cfm?id=369505.369519},
	acmid = {369519},
	publisher = {Morgan Kaufmann Publishers Inc.},
	address = {San Francisco, CA, USA},
} 

 

@inproceedings{vadas2005programming,
	title={Programming with unrestricted natural language},
	author={Vadas, David and Curran, James R},
	booktitle={Proceedings of the Australasian Language Technology Workshop 2005},
	pages={191--199},
	year={2005}
}

@inproceedings{sap2019atomic,
  title={Atomic: An atlas of machine commonsense for if-then reasoning},
  author={Sap, Maarten and Le Bras, Ronan and Allaway, Emily and Bhagavatula, Chandra and Lourie, Nicholas and Rashkin, Hannah and Roof, Brendan and Smith, Noah A and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3027--3035},
  year={2019}
}

@inproceedings{bosselut-etal-2019-comet,
    title = "{COMET}: Commonsense Transformers for Automatic Knowledge Graph Construction",
    author = "Bosselut, Antoine  and
      Rashkin, Hannah  and
      Sap, Maarten  and
      Malaviya, Chaitanya  and
      Celikyilmaz, Asli  and
      Choi, Yejin",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/P19-1470",
    doi = "10.18653/v1/P19-1470",
    pages = "4762--4779",
    abstract = "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5{\%} (ATOMIC) and 91.7{\%} (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{allen1999mixed,
	title={Mixed-initiative interaction},
	author={Allen, James F. and Guinn, Curry I and Horvtz, Eric},
	journal={IEEE Intelligent Systems and their Applications},
	volume={14},
	number={5},
	pages={14--23},
	year={1999},
	publisher={IEEE}
}

@InProceedings{D18-2025,
	author = 	"Labutov, Igor
	and Srivastava, Shashank
	and Mitchell, Tom",
	title = 	"LIA: A Natural Language Programmable Personal Assistant",
	booktitle = 	"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
	year = 	"2018",
	publisher = 	"Association for Computational Linguistics",
	pages = 	"145--150",
	location = 	"Brussels, Belgium",
	url = 	"http://aclweb.org/anthology/D18-2025"
}

@InProceedings{P18-1029,
	author = 	"Srivastava, Shashank
	and Labutov, Igor
	and Mitchell, Tom",
	title = 	"Zero-shot Learning of Classifiers from Natural Language Quantification",
	booktitle = 	"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	year = 	"2018",
	publisher = 	"Association for Computational Linguistics",
	pages = 	"306--316",
	location = 	"Melbourne, Australia",
	url = 	"http://aclweb.org/anthology/P18-1029"
}

@inproceedings{radensky_how_2018,
	title = {How {End} {Users} {Express} {Conditionals} in {Programming} by {Demonstration} for {Mobile} {Apps}},
	doi = {10.1109/VLHCC.2018.8506492},
	abstract = {Though conditionals are an integral component of programming, providing an easy means of creating conditionals remains a challenge for programming-by-demonstration (PBD) systems for task automation. We hypothesize that a promising method for implementing conditionals in such systems is to incorporate the use of verbal instructions. Verbal instructions supplied concurrently with demonstrations have been shown to improve the generalizability of PBD. However, the challenge of supporting conditional creation using this multi-modal approach has not been addressed. In this extended abstract, we present our study on understanding how end users describe conditionals in natural language for mobile app tasks. We conducted a formative study of 56 participants asking them to verbally describe conditionals in different settings for 9 sample tasks and to invent conditional tasks. Participant responses were analyzed using open coding and revealed that, in the context of mobile apps, end users often omit desired else statements when explaining conditionals, sometimes use ambiguous concepts in expressing conditionals, and often desire to implement complex conditionals. Based on these findings, we discuss the implications for designing a multimodal PBD interface to support the creation of conditionals.},
	booktitle = {2018 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Radensky, Marissa and Li, Toby Jia-Jun and Myers, Brad A.},
	month = oct,
	year = {2018},
	keywords = {Automation, Encoding, Natural languages, Programming, Public transportation, Task analysis, Visualization, conditionals, end-user development, natural programming, programming by demonstration, verbal instruction},
	pages = {311--312}
}

@article{myers_programmers_2016,
	title = {Programmers {Are} {Users} {Too}: {Human}-{Centered} {Methods} for {Improving} {Programming} {Tools}},
	volume = {49},
	issn = {0018-9162},
	shorttitle = {Programmers {Are} {Users} {Too}},
	doi = {10.1109/MC.2016.200},
	abstract = {Human-centered methods can help researchers better understand and meet programmers' needs. Because programming is a human activity, many of these methods can be used without change. However, some programmer needs require new methods, which can also be applied to domains other than software engineering. This article features five Web extras. The video at https://youtu.be/4PH9-qi-yTQ demonstrates Azurite, an Eclipse plug-in with a selective undo feature that lets programmers more easily backtrack their code. The video at https://youtu.be/gOSlR62-rd8 describes Graphite, an Eclipse plug-in offering active code completion, a simple but powerful technique that integrates useful code-generation tools directly into the editor. The video at https://youtu.be/zyrqcYxqDtI describes HANDS, a new programming system that emphasizes usability by building on children's and beginning programmers' natural problem-solving tendencies. The video extra at https://youtu.be/80EctbI7PFc describes Whyline, a debugging tool that lets developers ask questions about their program's output and behavior. The video at https://youtu.be/3L4MK2dG\_6k demonstrates the prototype for Whyline, a debugging tool that lets developers pose questions about their program's output.},
	number = {7},
	journal = {Computer},
	author = {Myers, Brad A. and Ko, Amy J. and LaToza, Thomas D. and Yoon, YoungSeok},
	month = jul,
	year = {2016},
	keywords = {A/B testing, Azurite, Data mining, Eclipse plug-in, Graphite, HANDS, HCI, Human computer interaction, Human-centered computing, Human-computer interaction, Java, Natural language processing, Programming, Software engineering, Whyline, active code completion, contextual inquiry, data mining, debugging tool, end-user software engineering, evaluation studies, exploratory lab studies, human activity, human-centered computing, human-centered methods, human-computer interaction, log analysis, natural problem-solving tendencies, natural-programming elicitation, program debugging, programming tools, rapid prototyping, software development, software engineering, software psychology, software tools, studies of program constructs, think-aloud usability evaluation, undo feature, user centred design, user interfaces},
	pages = {44--52}
}

@incollection{li_teaching_2018,
	title = {Teaching {Agents} {When} {They} {Fail}: {End} {User} {Development} in {Goal}-oriented {Conversational} {Agents}},
	booktitle = {Studies in {Conversational} {UX} {Design}},
	publisher = {Springer},
	author = {Li, Toby Jia-Jun and Labutov, Igor and Myers, Brad A. and Azaria, Amos and Rudnicky, Alexander I. and Mitchell, Tom M.},
	year = {2018}
}

@incollection{pane_more_2006,
	title = {More natural programming languages and environments},
	booktitle = {End user development},
	publisher = {Springer},
	author = {Pane, John F. and Myers, Brad A.},
	year = {2006},
	pages = {31--50}
}

@misc{guo_section_2018,
	title = {Section 4 - 9.26},
	url = {https://docs.google.com/presentation/d/1fuPonhhEwq1YjeXljrjb2ziu77j85rbyhf1-nIpc9ek},
	urldate = {2018-09-24TZ},
	author = {Guo, Anhong},
	month = sep,
	year = {2018}
}

@article{oviatt_paradigm_2015,
	title = {The {Paradigm} {Shift} to {Multimodality} in {Contemporary} {Computer} {Interfaces}},
	volume = {8},
	issn = {1946-7680},
	url = {https://www.morganclaypool.com/doi/abs/10.2200/S00636ED1V01Y201503HCI030},
	doi = {10.2200/S00636ED1V01Y201503HCI030},
	number = {3},
	urldate = {2018-09-21TZ},
	journal = {Synthesis Lectures on Human-Centered Informatics},
	author = {Oviatt, Sharon and Cohen, Philip R.},
	month = apr,
	year = {2015},
	pages = {1--243}
}

@article{wu2019scratchthat,
  title={ScratchThat: Supporting Command-Agnostic Speech Repair in Voice-Driven Assistants},
  author={Wu, Jason and Ahuja, Karan and Li, Richard and Chen, Victor and Bigham, Jeffrey},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={3},
  number={2},
  pages={63},
  year={2019},
  publisher={ACM}
}


@article{cohen_coefficient_1960,
	title = {A coefficient of agreement for nominal scales},
	volume = {20},
	number = {1},
	journal = {Educational and psychological measurement},
	author = {Cohen, Jacob},
	year = {1960},
	pages = {37--46}
}

@inproceedings{green_when_1992,
	title = {When visual programs are harder to read than textual programs},
	booktitle = {Human-{Computer} {Interaction}: {Tasks} and {Organisation}, {Proceedings} of {ECCE}-6 (6th {European} {Conference} on {Cognitive} {Ergonomics}). {GC} van der {Veer}, {MJ} {Tauber}, {S}. {Bagnarola} and {M}. {Antavolits}. {Rome}, {CUD}},
	publisher = {Citeseer},
	author = {Green, Thomas RG and Petre, Marian},
	year = {1992},
	pages = {167--180}
}

@article{sime_scope_1977,
	title = {Scope marking in computer conditionals—a psychological evaluation},
	volume = {9},
	issn = {0020-7373},
	url = {http://www.sciencedirect.com/science/article/pii/S002073737780045X},
	doi = {10.1016/S0020-7373(77)80045-X},
	abstract = {In a previous paper the authors reported that it was easier for non-programmers to learn to use nested conditional constructions than jumping, or branch-to-label, constructions; however, as only single situations were studied, the conclusions were necessarily restricted. The present study extends the comparison to the more general case where nesting requires “scope markers” to disambiguate the syntax. The results showed that if the scope markers were simply the begin and end of ALGOL 60 (abbreviated NEST-BE) then the advantage of nesting over jumping was weakened; but if the scope markers carried redundant information about the conditional tested (NEST-INE) performance was excellent, particularly at debugging. It seems necessary to distinguish sequence information in a program, which describes the order in which things are done, from taxon information, which describes the conditions under which a given action is performed. Conventional programming languages obscure the taxon information. The advantage of nesting over jumping, we speculate, is in clarifying the sequence information by redundant re-coding in spatial terms; the added advantage of NEST-INE over NEST-BE is that it clarifies the taxon information. It is because debugging requires taxon information that NEST-INE is so much superior. On this view one would expect that in decision table and production system languages, where the taxon information is explicit but the sequence information is obscured, the reverse phenomena should occur. Because debugging requires sequence information as well as taxon information, a device that clarified the sequence would greatly improve such languages.},
	number = {1},
	urldate = {2018-09-21TZ},
	journal = {International Journal of Man-Machine Studies},
	author = {Sime, M. E. and Green, T. R. G. and Guest, D. J.},
	month = jan,
	year = {1977},
	pages = {107--118}
}

@article{suhm_multimodal_2001,
	title = {Multimodal {Error} {Correction} for {Speech} {User} {Interfaces}},
	volume = {8},
	issn = {1073-0516},
	url = {http://doi.acm.org/10.1145/371127.371166},
	doi = {10.1145/371127.371166},
	abstract = {Although commercial dictation systems and speech-enabled telephone voice user interfaces have become readily available, speech recognition errors remain a serious problem in the design and implementation of speech user interfaces. Previous work hypothesized that switching modality could speed up interactive correction of recognition errors. This article presents multimodal error correction methods that allow the user to correct recognition errors efficiently without keyboard input. Correction accuracy is maximized by novel recognition algorithms that use context information for recognizing correction input. Multimodal error correction is evaluated in the context of a prototype multimodal dictation system. The study shows that unimodal repair is less accurate than multimodal error correction. On a dictation task, multimodal correction is faster than unimodal correction by respeaking. The study also provides empirical evidence that system-initiated error correction (based on confidence measures) may not expedite error correction. Furthermore, the study suggests that recognition accuracy determines user choice between modalities: while users initially prefer speech, they learn to avoid ineffective correction modalities with experience. To extrapolate results from this user study, the article introduces a performance model of (recognition-based) multimodal interaction that predicts input speed including time needed for error correction. Applied to interactive error correction, the model predicts the impact of improvements in recognition technology on correction speeds, and the influence of recognition accuracy and correction method on the productivity of dictation systems. This model is a first step toward formalizing multimodal interaction.},
	number = {1},
	urldate = {2018-09-21TZ},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Suhm, Bernhard and Myers, Brad and Waibel, Alex},
	month = mar,
	year = {2001},
	keywords = {dictation systems, interactive error correction, multimodal interfaces, pen input, performance model, speech input, speech user interfaces},
	pages = {60--98}
}

@url{ifttt_ifttt_nodate,
	title = {{IFTTT: connects the apps you love.}},
	url = {https://ifttt.com/},
	year = {2016},
	author = {IFTTT}
}

@inproceedings{park_designers_2008,
	title = {Designers’ natural descriptions of interactive behaviors},
	doi = {10.1109/VLHCC.2008.4639082},
	abstract = {While a designer's focus used to be the design of non-interactive elements such as graphics or animations, today's designers deal with various levels of interactivity such as mouse, keyboard and touch screen interaction. Unfortunately, it is challenging for designers to create these diverse interactions since most implementation tools such as Flash require the use of conventional programming languages and do not support the natural expressions used by designers. To better understand how designers think about interactive behaviors, we conducted a lab study where designers and programmers described various primitive and composite interactive behaviors using their own language. From this, we learned that there is significant commonality among designers in terms of the verbs, syntax, and structure when describing interactivity. These results can help guide the way to building more natural programming languages and environments for designers to facilitate the development of interactive behaviors.},
	booktitle = {2008 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}},
	author = {Park, Sunyoung and Myers, Brad A. and Ko, Amy J.},
	month = sep,
	year = {2008},
	keywords = {Animation, Computer languages, Graphical user interfaces, Graphics, Image color analysis, Programming, Shape, high level languages, implementation tools, interactive behaviors, interactive programming, programming languages},
	pages = {185--188}
}

@article{myers_improving_2016,
	title = {Improving {API} {Usability}},
	volume = {59},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2896587},
	doi = {10.1145/2896587},
	abstract = {Human-centered design can make application programming interfaces easier for developers to use.},
	number = {6},
	urldate = {2018-09-19TZ},
	journal = {Commun. ACM},
	author = {Myers, Brad A. and Stylos, Jeffrey},
	month = may,
	year = {2016},
	pages = {62--69}
}

@article{brich_exploring_2017,
	title = {Exploring {End} {User} {Programming} {Needs} in {Home} {Automation}},
	volume = {24},
	issn = {1073-0516},
	url = {http://doi.acm.org/10.1145/3057858},
	doi = {10.1145/3057858},
	abstract = {Home automation faces the challenge of providing ubiquitous, unobtrusive services while empowering users with approachable configuration interfaces. These interfaces need to provide sufficient expressiveness to support complex automation, and notations need to be devised that enable less tech-savvy users to express such scenarios. Rule-based and process-oriented paradigms have emerged as opposing ends of the spectrum; however, their underlying concepts have not been studied comparatively. We report on a contextual inquiry study in which we collected qualitative data from 18 participants in 12 households on the current potential and acceptance of home automation, as well as explored the respective benefits and drawbacks of these two notation paradigms for end users. Results show that rule-based notations are sufficient for simple automation tasks but not flexible enough for more complex use cases. The resulting insights can inform the design of interfaces for smart homes to enable usable real-world home automation for end users.},
	number = {2},
	urldate = {2018-09-19TZ},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Brich, Julia and Walch, Marcel and Rietzler, Michael and Weber, Michael and Schaub, Florian},
	month = apr,
	year = {2017},
	keywords = {Configuration interfaces, contextual inquiry, qualitative analysis, smart home},
	pages = {11:1--11:35}
}

@inproceedings{mihalcea_nlp_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{NLP} ({Natural} {Language} {Processing}) for {NLP} ({Natural} {Language} {Programming})},
	isbn = {978-3-540-32206-1},
	abstract = {Natural Language Processing holds great promise for making computer interfaces that are easier to use for people, since people will (hopefully) be able to talk to the computer in their own language, rather than learn a specialized language of computer commands. For programming, however, the necessity of a formal programming language for communicating with a computer has always been taken for granted. We would like to challenge this assumption. We believe that modern Natural Language Processing techniques can make possible the use of natural language to (at least partially) express programming ideas, thus drastically increasing the accessibility of programming to non-expert users. To demonstrate the feasibility of Natural Language Programming, this paper tackles what are perceived to be some of the hardest cases: steps and loops. We look at a corpus of English descriptions used as programming assignments, and develop some techniques for mapping linguistic constructs onto program structures, which we refer to as programmatic semantics.},
	language = {en},
	booktitle = {Computational {Linguistics} and {Intelligent} {Text} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Mihalcea, Rada and Liu, Hugo and Lieberman, Henry},
	editor = {Gelbukh, Alexander},
	year = {2006},
	keywords = {Direct Object, Loop Variable, Natural Language, Natural Language Processing, Noun Phrase},
	pages = {319--330}
}

@article{capindale_using_1990,
	title = {Using a natural language interface with casual users},
	volume = {32},
	issn = {0020-7373},
	url = {http://www.sciencedirect.com/science/article/pii/S0020737308800077},
	doi = {10.1016/S0020-7373(08)80007-7},
	abstract = {Although there is much controversy about the merits of natural language interfaces, little empirical research has been conducted on the use of natural language interfaces for database access, especially for casual users. In this work casual users were observed while interacting with a real-life database using a natural language interface, Intellect. Results show that natural language is an efficient and powerful means for expressing requests. This is especially true for users with a good knowledge of the database contents regardless of training or previous experience with computers. Users generally have a positive attitude towards natural language. The majority of errors users make are directly related to restrictions in the vocabulary. However, feedback helps users understand the language limitations and learn how to avoid or recover from errors. Natural language processing technology is developed enough to handle the limited domain of discourse associated with a database; it is simple enough to support casual users with a general knowledge of the database contents; and it is flexible enough to assist problem-solving behaviour.},
	number = {3},
	urldate = {2018-09-19TZ},
	journal = {International Journal of Man-Machine Studies},
	author = {Capindale, Ruth A. and Crawford, Robert G.},
	month = mar,
	year = {1990},
	pages = {341--361}
}

@article{biermann_experimental_1983,
	title = {An experimental study of natural language programming},
	volume = {18},
	issn = {0020-7373},
	url = {http://www.sciencedirect.com/science/article/pii/S0020737383800054},
	doi = {10.1016/S0020-7373(83)80005-4},
	abstract = {An experiment is described which gives data related to the usefulness and efficiency of English as a programming language. The experiment was performed with the NLC system, described herein, and used twenty-three paid volunteers from a first course in programming. Subjects were asked to solve two problems, namely (1) solution of linear equations and (2) gradebook averaging. A total of 1581 English sentences were typed, 81\% of which were processed correctly. The remaining 19\% were rejected because of questionable user syntax or system inadequacies. In most cases, subjects were able to paraphrase a rejected input in terminology understandable by the system. The overall success rate at solving an entire problem, within the 2½ h time constraint of the experiment, was 73·9\%. In short, the system was an effective problem solver for the selected classes of problems and users. Many system failures resulted from “bugs” or syntactic oversights which appear amenable to easy repair. None of the Standard concerns about natural language programming related to vagueness, ambiguity, verbosity or correctness was a significant problem, although minor difficulties did arise occasionally.},
	number = {1},
	urldate = {2018-09-19TZ},
	journal = {International Journal of Man-Machine Studies},
	author = {Biermann, Alan W. and Ballard, Bruce W. and Sigmon, Anne H.},
	month = jan,
	year = {1983},
	pages = {71--87}
}

@article{lieberman_beating_2004,
	title = {Beating {Common} {Sense} into {Interactive} {Applications}},
	volume = {25},
	issn = {2371-9621},
	url = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/1785},
	doi = {10.1609/aimag.v25i4.1785},
	language = {en-US},
	number = {4},
	urldate = {2018-09-13TZ},
	journal = {AI Magazine},
	author = {Lieberman, Henry and Liu, Hugo and Singh, Push and Barry, Barbara},
	month = dec,
	year = {2004},
	pages = {63--63}
}

@inproceedings{lieberman_autonomous_1997,
	address = {New York, NY, USA},
	series = {{CHI} '97},
	title = {Autonomous {Interface} {Agents}},
	isbn = {978-0-89791-802-2},
	url = {http://doi.acm.org/10.1145/258549.258592},
	doi = {10.1145/258549.258592},
	urldate = {2018-09-13TZ},
	booktitle = {Proceedings of the {ACM} {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lieberman, Henry},
	year = {1997},
	keywords = {Web, agents, autonomous agents, browsing, interface agents, learning, search},
	pages = {67--74}
}

@article{lieberman_integrating_1998,
	title = {Integrating user interface agents with conventional applications},
	volume = {11},
	number = {1},
	journal = {Knowledge-Based Systems},
	author = {Lieberman, Henry},
	year = {1998},
	pages = {15--23}
}

@article{lieberman_instructible_1996,
	title = {Instructible agents: {Software} that just keeps getting better},
	volume = {35},
	issn = {0018-8670},
	shorttitle = {Instructible agents},
	doi = {10.1147/sj.353.0539},
	abstract = {Agent software is a topic of growing interest to users and developers in the computer industry. Already, agents and wizards help users automate tasks such as editing and searching for information. But just as we expect human assistants to learn as we work with them, we will also come to expect our computer agents to learn from us. This paper explores the idea of an instructible agent that can learn both from examples and from advice. To understand design issues and languages for human-agent communication, we first describe an experiment that simulates the behavior of such an agent. Then we describe some implemented and ongoing instructible agent projects in text and graphic editing, World Wide Web browsing, and virtual reality. Finally, we analyze the trade-offs involved in agent software and argue that instructible agents represent a "sweet spot" in the trade-off between convenience and control.},
	number = {3.4},
	journal = {IBM Systems Journal},
	author = {Lieberman, H. and Maulsby, D.},
	year = {1996},
	pages = {539--556}
}

@book{strauss_basics_1990,
	title = {Basics of qualitative research: {Grounded} theory procedures and techniques.},
	shorttitle = {Basics of qualitative research},
	publisher = {Sage Publications, Inc},
	author = {Strauss, Anselm and Corbin, Juliet M.},
	year = {1990}
}

@inproceedings{pane_using_2002,
	title = {Using {HCI} techniques to design a more usable programming system},
	doi = {10.1109/HCC.2002.1046372},
	abstract = {A programming system is the user interface between the programmer and the computer. Programming is a notoriously difficult activity, and some of this difficulty can be attributed to the user interface as opposed to other factors. Historically, the designs of programming languages and tools have not emphasized usability. This paper describes the process we used to design HANDS, a new programming system for children that focuses on usability, where HCI knowledge, principles, and methods guided all design decisions. The features of HANDS are presented along with their motivations from prior empirical research on programmers and new studies conducted by the authors. HANDS is an event-based language that features a concrete model for computation, provides operators that match the way non-programmers express problem solutions, and includes domain-specific features for the creation of interactive animations and simulations. In user tests, children using HANDS performed significantly better than children using a reduced-feature version of the system where more traditional methods were required to solve tasks.},
	booktitle = {Proceedings {IEEE} 2002 {Symposia} on {Human} {Centric} {Computing} {Languages} and {Environments}},
	author = {Pane, J. F. and Myers, B. A. and Miller, L. B.},
	month = sep,
	year = {2002},
	keywords = {Animation, Computational modeling, Computer interfaces, Computer languages, Concrete, Design methodology, HANDS, HCI techniques, Human computer interaction, Programming profession, Usability, User interfaces, computer aided instruction, event-based language, graphical user interfaces, programming system, usable programming system, user interface, visual languages, visual programming},
	pages = {198--206}
}

@inproceedings{Beneteau_2019,
author = {Beneteau, Erin and Richards, Olivia K. and Zhang, Mingrui and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
title = {Communication Breakdowns Between Families and Alexa},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
series = {CHI '19},
year = {2019},
isbn = {978-1-4503-5970-2},
location = {Glasgow, Scotland Uk},
pages = {243:1--243:13},
articleno = {243},
numpages = {13},
url = {http://doi.acm.org/10.1145/3290605.3300473},
doi = {10.1145/3290605.3300473},
acmid = {3300473},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {communication repairs, digital home assistants, families, human computer interaction, joint media engagement},
} 

@inproceedings{biermann_natural_1983,
	series = {{NATO} {Advanced} {Study} {Institutes} {Series}},
	title = {Natural {Language} {Programming}},
	isbn = {978-94-009-7019-9},
	abstract = {A procedural semantics system is described for English imperative sentences in natural language programming. Issues related to the handling of dialog focus, noun group resolution, quantifier processing, and imperative verb execution are discussed. Sequences of imperative sentences may be assembled to build natural language programs and techniques are given for processing such programs. The final sections include a discussion of related research and a brief overview of the field.},
	language = {en},
	booktitle = {Computer {Program} {Synthesis} {Methodologies}},
	publisher = {Springer Netherlands},
	author = {Biermann, Alan W.},
	editor = {Biermann, Alan W. and Guiho, Gerard},
	year = {1983},
	keywords = {Focus Mechanism, Head Noun, Natural Language, Naval Postgraduate School, Procedural Representation},
	pages = {335--368}
}



@inproceedings{ballard_programming_1979,
	address = {New York, NY, USA},
	series = {{ACM} '79},
	title = {Programming in {Natural} {Language} ``{NLC}'' {As} a {Prototype}},
	isbn = {978-0-89791-008-8},
	shorttitle = {Programming in {Natural} {Language}},
	url = {http://doi.acm.org/10.1145/800177.810072},
	doi = {10.1145/800177.810072},
	abstract = {The state of the art in computational linguistics has progressed to the point where it is now possible to process simple programs written in natural language. This report describes a natural language programming system called NLC which enables a computer user to type English commands into a display terminal and watch them executed on example data shown on the screen. The system is designed to process data stored in matrices or tables, and any problem which can be represented in such structures can be handled if the total storage requirements are not excessive.},
	urldate = {2018-09-11TZ},
	booktitle = {Proceedings of the 1979 {Annual} {Conference}},
	publisher = {ACM},
	author = {Ballard, Bruce W. and Biermann, Alan W.},
	year = {1979},
	pages = {228--237}
}

@article{maclellan_framework_2018,
	title = {A {Framework} for {Natural} {Cognitive} {System} {Training} {Interactions}},
	journal = {Advances in Cognitive Systems},
	author = {MacLellan, Christopher J. and Harpstead, Erik and Marinier III, Robert P. and Koedinger, Kenneth R.},
	year = {2018}
}

@article{wing_computational_2006,
	title = {Computational {Thinking}},
	volume = {49},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1118178.1118215},
	doi = {10.1145/1118178.1118215},
	abstract = {It represents a universally applicable attitude and skill set everyone, not just computer scientists, would be eager to learn and use.},
	number = {3},
	urldate = {2018-09-02TZ},
	journal = {Commun. ACM},
	author = {Wing, Jeannette M.},
	month = mar,
	year = {2006},
	pages = {33--35}
}

@article{myers_natural_2004,
	title = {Natural {Programming} {Languages} and {Environments}},
	volume = {47},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1015864.1015888},
	doi = {10.1145/1015864.1015888},
	abstract = {Over the last six years, we have been working to create programming languages and environments that are more natural, or closer to the way people think about their tasks. Our goal is to make it possible for people to express their ideas in the same way they think about them. To achieve this, we have performed various studies about how people think about programming tasks, both when trying to create a new program and when trying to find and fix bugs in existing programs. We then use this knowledge to develop new tools for programming and debugging. Our user studies have shown the resulting systems provide significant benefits to users.},
	number = {9},
	urldate = {2018-08-31TZ},
	journal = {Commun. ACM},
	author = {Myers, Brad A. and Pane, John F. and Ko, Amy J.},
	month = sep,
	year = {2004},
	pages = {47--52}
}

@inproceedings{fast_iris:_2018,
	address = {New York, NY, USA},
	series = {{CHI} '18},
	title = {Iris: {A} {Conversational} {Agent} for {Complex} {Tasks}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Iris},
	url = {http://doi.acm.org/10.1145/3173574.3174047},
	doi = {10.1145/3173574.3174047},
	abstract = {Today, most conversational agents are limited to simple tasks supported by standalone commands, such as getting directions or scheduling an appointment. To support more complex tasks, agents must be able to generalize from and combine the commands they already understand. This paper presents a new approach to designing conversational agents inspired by linguistic theory, where agents can execute complex requests interactively by combining commands through nested conversations. We demonstrate this approach in Iris, an agent that can perform open-ended data science tasks such as lexical analysis and predictive modeling. To power Iris, we have created a domain-specific language that transforms Python functions into combinable automata and regulates their combinations through a type system. Running a user study to examine the strengths and limitations of our approach, we find that data scientists completed a modeling task 2.6 times faster with Iris than with Jupyter Notebook.},
	urldate = {2018-08-28TZ},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Fast, Ethan and Chen, Binbin and Mendelsohn, Julia and Bassen, Jonathan and Bernstein, Michael S.},
	year = {2018},
	keywords = {conversational agents, data science},
	pages = {473:1--473:12}
}

@inproceedings{price_naturaljava:_2000,
	address = {New York, NY, USA},
	series = {{IUI} '00},
	title = {{NaturalJava}: {A} {Natural} {Language} {Interface} for {Programming} in {Java}},
	isbn = {978-1-58113-134-5},
	shorttitle = {{NaturalJava}},
	url = {http://doi.acm.org/10.1145/325737.325845},
	doi = {10.1145/325737.325845},
	abstract = {NaturalJava is a prototype for an intelligent natural-language-based user interface for creating, modifying, and examining Java programs. The interface exploits three subsystems. The Sundance natural language processing system accepts English sentences as input and uses information extraction techniques to generate case frames representing program construction and editing directives. A knowledge-based case frame interpreter, PRISM, uses a decision tree to infer program modification operations from the case frames. A Java abstract syntax tree manager, TreeFace, provides the interface that PRISM uses to build and navigate the tree representation of an evolving Java program. In this paper, we describe the technical details of each component, explain the capabilities of the user interface, and present examples of NaturalJava in use.},
	urldate = {2018-08-28TZ},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Price, David and Rilofff, Ellen and Zachary, Joseph and Harvey, Brandon},
	year = {2000},
	keywords = {computer program editors, information extraction, intelligent user interfaces, natural language processing, programming environments},
	pages = {207--211}
}

@inproceedings{kate_learning_2005,
	address = {Pittsburgh, Pennsylvania},
	series = {{AAAI}'05},
	title = {Learning to {Transform} {Natural} to {Formal} {Languages}},
	isbn = {978-1-57735-236-5},
	url = {http://dl.acm.org/citation.cfm?id=1619499.1619504},
	abstract = {This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora. one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains.},
	urldate = {2018-08-28TZ},
	booktitle = {Proceedings of the 20th {National} {Conference} on {Artificial} {Intelligence} - {Volume} 3},
	publisher = {AAAI Press},
	author = {Kate, Rohit J. and Wong, Yuk Wah and Mooney, Raymond J.},
	year = {2005},
	pages = {1062--1068}
}

@incollection{lewis_can_1987,
	address = {Norwood, NJ, USA},
	title = {Can principles of cognition lower the barriers to programming?},
	isbn = {978-0-89391-461-5},
	shorttitle = {Empirical {Studies} of {Programmers}},
	booktitle = {Empirical {Studies} of {Programmers}: {Second} {Workshop}},
	publisher = {Ablex Publishing Corp.},
	author = {Lewis, Clayton and Olson, Gary},
	editor = {Olson, Gary M. and Sheppard, Sylvia and Soloway, Elliot},
	year = {1987},
	pages = {248--263}
}

@inproceedings{Banovic:2012:WRE:2380116.2380129,
	author = {Banovic, Nikola and Grossman, Tovi and Matejka, Justin and Fitzmaurice, George},
	title = {Waken: Reverse Engineering Usage Information and Interface Structure from Software Videos},
	booktitle = {Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology},
	series = {UIST '12},
	year = {2012},
	isbn = {978-1-4503-1580-7},
	location = {Cambridge, Massachusetts, USA},
	pages = {83--92},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2380116.2380129},
	doi = {10.1145/2380116.2380129},
	acmid = {2380129},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {pixel-based reverse engineering, tutorials, videos},
} 



@inproceedings{guo_statelens:_2019,
	title = {{StateLens}: {A} {Reverse} {Engineering} {Solution} for {Making} {Existing} {Dynamic} {Touchscreens} {Accessible}},
	language = {en},
	booktitle = {Proceedings of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} ({UIST} 2019)},
	author = {Guo, Anhong and Kong, Junhan and Rivera, Michael and Xu, Frank F and Bigham, Jeffrey P},
	year = {2019},
	pages = {15},
	file = {Guo et al. - StateLens A Reverse Engineering Solution for Maki.pdf:/Users/toby/Zotero/storage/4J9WWGVL/Guo et al. - StateLens A Reverse Engineering Solution for Maki.pdf:application/pdf}
}

@inproceedings{zhang_robust_2018,
	title = {Robust {Annotation} of {Mobile} {Application} {Interfaces} in {Methods} for {Accessibility} {Repair} and {Enhancement}},
	series = {UIST '18},
	booktitle = {Proceedings of the 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Zhang, Xiaoyi and Ross, Anne Spencer and Fogarty, James},
	year = {2018}
}

@inproceedings{li_appinite:_2018,
	title = {{APPINITE}: {A} {Multi}-{Modal} {Interface} for {Specifying} {Data} {Descriptions} in {Programming} by {Demonstration} {Using} {Verbal} {Instructions}},
	booktitle = {Proceedings of  the 2018 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC} 2018)},
	author = {Li, Toby Jia-Jun and Labutov, Igor and Li, Xiaohan Nancy and Zhang, Xiaoyi and Shi, Wenze and Mitchell, Tom M. and Myers, Brad A.},
	year = {2018}
}

@inproceedings{kasturi_cohort_2015,
	title = {The {Cohort} and {Speechify} {Libraries} for {Rapid} {Construction} of {Speech} {Enabled} {Applications} for {Android}},
	booktitle = {Proceedings of the 16th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	author = {Kasturi, Tejaswi and Jin, Haojian and Pappu, Aasish and Lee, Sungjin and Harrison, Beverley and Murthy, Ramana and Stent, Amanda},
	year = {2015},
	pages = {441--443}
}

@inproceedings{intharah_help_2017,
	address = {New York, NY, USA},
	series = {{IUI} '17},
	title = {Help, {It} {Looks} {Confusing}: {GUI} {Task} {Automation} {Through} {Demonstration} and {Follow}-up {Questions}},
	isbn = {978-1-4503-4348-0},
	shorttitle = {Help, {It} {Looks} {Confusing}},
	url = {http://doi.acm.org/10.1145/3025171.3025176},
	doi = {10.1145/3025171.3025176},
	abstract = {Non-programming users should be able to create their own customized scripts to perform computer-based tasks for them, just by demonstrating to the machine how it's done. To that end, we develop a system prototype which learns-by-demonstration called HILC (Help, It Looks Confusing). Users train HILC to synthesize a task script by demonstrating the task, which produces the needed screenshots and their corresponding mouse-keyboard signals. After the demonstration, the user answers follow-up questions. We propose a user-in-the-loop framework that learns to generate scripts of actions performed on visible elements of graphical applications. While pure programming-by-demonstration is still unrealistic, we use quantitative and qualitative experiments to show that non-programming users are willing and effective at answering follow-up queries posed by our system. Our models of events and appearance are surprisingly simple, but are combined effectively to cope with varying amounts of supervision. The best available baseline, Sikuli Slides, struggled with the majority of the tests in our user study experiments. The prototype with our proposed approach successfully helped users accomplish simple linear tasks, complicated tasks (monitoring, looping, and mixed), and tasks that span across multiple executables. Even when both systems could ultimately perform a task, ours was trained and refined by the user in less time.},
	urldate = {2018-04-28TZ},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Intharah, Thanapong and Turmukhambetov, Daniyar and Brostow, Gabriel J.},
	year = {2017},
	keywords = {GUI automation, action segmentation and recognition, programming by demonstration},
	pages = {233--243}
}

@url{noauthor_automate:_nodate,
	author = {LlamaLab},
	title = {Automate: everyday automation for {Android}},
	url = {http://llamalab.com/automate/},
	year = {2016},
	urldate = {2016-09-11TZ}
}

@inproceedings{pasupat_compositional_2015,
	title = {Compositional {Semantic} {Parsing} on {Semi}-{Structured} {Tables}},
	url = {http://arxiv.org/abs/1508.00305},
	abstract = {Two important aspects of semantic parsing for question answering are the breadth of the knowledge source and the depth of logical compositionality. While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision. The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms. We propose a logical-form driven parsing algorithm guided by strong typing constraints and show that it obtains significant improvements over natural baselines. For evaluation, we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available.},
	urldate = {2018-04-26TZ},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing}},
	author = {Pasupat, Panupong and Liang, Percy},
	year = {2015},
	note = {arXiv: 1508.00305},
	keywords = {Computer Science - Computation and Language}
}

@book{pruett_yahoo!_2007,
	edition = {First},
	title = {Yahoo! {Pipes}},
	isbn = {978-0-596-51453-2},
	abstract = {The Internet is transforming itself from a collection of web pages into a huge distributed database. There's a wealth of data out there-not just RSS and Atom feeds, but XML data on where to find a new apartment, how much to pay for a new car, how to see if there's a storm approaching. If the Internet is your new database, you need a tool to mine that data-to merge and sort and search and filter that data. That tool is Yahoo! Pipes. Widely touted as an RSS feed aggregator, Yahoo! Pipes is more than that. With Yahoo! Pipes you can manipulate virtually any web-accessible XML data source, and then publish these data mashups for anyone to use-anywhere. This Short Cut shows you how to use Yahoo! Pipes. Examples illustrate the workings of every Yahoo! Pipes module (more than two dozen), and show how to incorporate these Pipes into your own web pages.},
	publisher = {O'Reilly},
	author = {Pruett, Mark},
	year = {2007}
}

@inproceedings{kuttal_history_2011,
	title = {History repeats itself more easily when you log it: {Versioning} for mashups},
	shorttitle = {History repeats itself more easily when you log it},
	doi = {10.1109/VLHCC.2011.6070381},
	abstract = {Web mashup environments provide a way for users to combine data from web applications and services to create new content. Currently, these environments do not provide support for tracking the development histories of mashups. We have thus added configuration management support to the Yahoo! Pipes mashup environment. We describe this support, and provide results of an experiment studying the ability of programmers to create and debug mashups in its presence. Our results show that versioning support can help both groups of users do both tasks better.},
	booktitle = {2011 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Kuttal, S. K. and Sarma, A. and Rothermel, G.},
	month = sep,
	year = {2011},
	keywords = {Debugging, Educational institutions, History, Mashups, Programming profession, Web mashup environment, Web services, Yahoo! Pipes mashup environment, configuration management},
	pages = {69--72}
}

@article{liang_learning_2013,
	title = {Learning dependency-based compositional semantics},
	volume = {39},
	number = {2},
	journal = {Computational Linguistics},
	author = {Liang, Percy and Jordan, Michael I. and Klein, Dan},
	year = {2013},
	pages = {389--446}
}

@misc{google_accessibilitywindowinfo_nodate,
	title = {{AccessibilityWindowInfo} {\textbar} {Android} {Developers}},
	url = {https://developer.android.com/reference/android/view/accessibility/AccessibilityWindowInfo.html},
	urldate = {2018-04-23TZ},
	author = {Google}
}

@article{huff_who_2015,
	title = {“{Who} are these people?” {Evaluating} the demographic characteristics and political preferences of {MTurk} survey respondents},
	volume = {2},
	shorttitle = {“{Who} are these people?},
	number = {3},
	journal = {Research \& Politics},
	author = {Huff, Connor and Tingley, Dustin},
	year = {2015},
	pages = {2053168015604648}
}

@inproceedings{oviatt_mutual_1999,
	title = {Mutual disambiguation of recognition errors in a multimodal architecture},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Oviatt, Sharon},
	year = {1999},
	pages = {576--583}
}

@incollection{lieberman_feasibility_2006,
	title = {Feasibility studies for programming in natural language},
	booktitle = {End {User} {Development}},
	publisher = {Springer},
	author = {Lieberman, Henry and Liu, Hugo},
	year = {2006},
	pages = {459--473}
}

@inproceedings{farhadi_every_2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Every {Picture} {Tells} a {Story}: {Generating} {Sentences} from {Images}},
	isbn = {978-3-642-15560-4 978-3-642-15561-1},
	shorttitle = {Every {Picture} {Tells} a {Story}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-15561-1_2},
	doi = {10.1007/978-3-642-15561-1_2},
	abstract = {Humans can prepare concise descriptions of pictures, focusing on what they find important. We demonstrate that automatic methods can do so too. We describe a system that can compute a score linking an image to a sentence. This score can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence. The score is obtained by comparing an estimate of meaning obtained from the image to one obtained from the sentence. Each estimate of meaning comes from a discriminative procedure that is learned using data. We evaluate on a novel dataset consisting of human-annotated images. While our underlying estimate of meaning is impoverished, it is sufficient to produce very good quantitative results, evaluated with a novel score that can account for synecdoche.},
	language = {en},
	urldate = {2018-04-16TZ},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Farhadi, Ali and Hejrati, Mohsen and Sadeghi, Mohammad Amin and Young, Peter and Rashtchian, Cyrus and Hockenmaier, Julia and Forsyth, David},
	month = sep,
	year = {2010},
	pages = {15--29}
}

@inproceedings{toomim_attaching_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Attaching {UI} {Enhancements} to {Websites} with {End} {Users}},
	isbn = {978-1-60558-246-7},
	url = {http://doi.acm.org/10.1145/1518701.1518987},
	doi = {10.1145/1518701.1518987},
	abstract = {We present reform, a step toward write-once apply-anywhere user interface enhancements. The reform system envisions roles for both programmers and end users in enhancing existing websites to support new goals. First, a programmer authors a traditional mashup or browser extension, but they do not write a web scraper. Instead they use reform, which allows novice end users to attach the enhancement to their favorite sites with a scraping by-example interface. reform makes enhancements easier to program while also carrying the benefit that end users can apply the enhancements to any number of new websites. We present reform's architecture, user interface, interactive by-example extraction algorithm for novices, and evaluation, along with five example reform enabled enhancements.},
	urldate = {2018-04-10TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Toomim, Michael and Drucker, Steven M. and Dontcheva, Mira and Rahimi, Ali and Thomson, Blake and Landay, James A.},
	year = {2009},
	keywords = {end-user programming, mashups, programming by example, web data extraction},
	pages = {1859--1868}
}

@inproceedings{li_leveraging_2014,
	address = {New York, NY, USA},
	series = {{SIGSPATIAL} '14},
	title = {Leveraging {Advances} in {Natural} {Language} {Processing} to {Better} {Understand} {Tobler}'s {First} {Law} of {Geography}},
	isbn = {978-1-4503-3131-9},
	url = {http://doi.acm.org/10.1145/2666310.2666493},
	doi = {10.1145/2666310.2666493},
	abstract = {Tobler's First Law of Geography (TFL) is one of the key reasons why "spatial is special". The law, which states that "everything is related to everything else, but near things are more related than distant things", is central to the management, presentation, and analysis of geographic information. However, despite the importance of TFL, we have a limited general understanding of its domain-neutral properties. In this paper, we leverage recent advances in the natural language processing domain of semantic relatedness estimation to, for the first time, robustly evaluate the extent to which relatedness between spatial entities decreases over distance in a domain-neutral fashion. Our results reveal that, in general, TFL can indeed be considered a globally recognized domain-neutral property of geographic information but that there is a distance beyond which being nearer, on average, no longer means being more related.},
	urldate = {2018-04-09TZ},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGSPATIAL} {International} {Conference} on {Advances} in {Geographic} {Information} {Systems}},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Sen, Shilad and Hecht, Brent},
	year = {2014},
	keywords = {Tobler's first law of geography, distance, semantic relatedness},
	pages = {513--516}
}

@inproceedings{begel_spoken_2005,
	title = {Spoken programs},
	doi = {10.1109/VLHCC.2005.58},
	abstract = {Programmers who suffer from repetitive stress injuries find it difficult to spend long amounts of time typing code. Speech interfaces can help developers reduce their dependence on typing. However, existing programming by voice techniques make it awkward for programmers to enter and edit program text. To design a better alternative, we conducted a study to learn how software developers naturally verbalize programs. We found that spoken programs are different from written programs in ways similar to the differences between spoken and written English; spoken programs contain lexical, syntactic and semantic ambiguities that do not appear in written programs. Using the results from this study, we designed Spoken Java, a semantically identical variant of Java that is easier to say out loud. Using Spoken Java, software developers can speak more naturally by verbalizing their program code as if they were reading it out loud. Spoken Java is analyzed by extending a conventional Java programming language analysis engine written in our Harmonia program analysis framework to support the kinds of ambiguities that arise from speech.},
	booktitle = {2005 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC}'05)},
	author = {Begel, A. and Graham, S. L.},
	month = sep,
	year = {2005},
	keywords = {English language, Harmonia program analysis, Java, Java programming language, Spoken Java, computer aided software engineering, lexical ambiguity, program code verbalization, programming by voice, semantic ambiguity, software development, speech interfaces, speech-based user interfaces, spoken programs, syntactic ambiguity},
	pages = {99--106}
}

@inproceedings{price_naturaljava:_2000-1,
	address = {New York, NY, USA},
	series = {{IUI} '00},
	title = {{NaturalJava}: {A} {Natural} {Language} {Interface} for {Programming} in {Java}},
	isbn = {978-1-58113-134-5},
	shorttitle = {{NaturalJava}},
	url = {http://doi.acm.org/10.1145/325737.325845},
	doi = {10.1145/325737.325845},
	abstract = {NaturalJava is a prototype for an intelligent natural-language-based user interface for creating, modifying, and examining Java programs. The interface exploits three subsystems. The Sundance natural language processing system accepts English sentences as input and uses information extraction techniques to generate case frames representing program construction and editing directives. A knowledge-based case frame interpreter, PRISM, uses a decision tree to infer program modification operations from the case frames. A Java abstract syntax tree manager, TreeFace, provides the interface that PRISM uses to build and navigate the tree representation of an evolving Java program. In this paper, we describe the technical details of each component, explain the capabilities of the user interface, and present examples of NaturalJava in use.},
	urldate = {2018-04-02TZ},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Price, David and Rilofff, Ellen and Zachary, Joseph and Harvey, Brandon},
	year = {2000},
	keywords = {computer program editors, information extraction, intelligent user interfaces, natural language processing, programming environments},
	pages = {207--211}
}

@article{iba_interactive_2005,
	title = {Interactive {Multimodal} {Robot} {Programming}},
	volume = {24},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364904049250},
	doi = {10.1177/0278364904049250},
	abstract = {As robots enter the human environment and come into contact with inexperienced                     users, they need to be able to interact with users in a multimodal                     fashion—keyboard and mouse are no longer acceptable as the only input                     modalities. In this paper we introduce a novel approach for programming robots                     interactively through a multimodal interface. The key characteristic of this                     approach is that the user can provide feedback interactively at any                     time—during both the programming and the execution phase. The                     framework takes a three-step approach to the problem: multimodal recognition,                     intention interpretation, and prioritized task execution. The multimodal                     recognition module translates hand gestures and spontaneous speech into a                     structured symbolic data stream without abstracting away the user’s                     intent. The intention interpretation module selects the appropriate primitives                     to generate a task based on the user’s input, the system’s                     current state, and robot sensor data. Finally, the prioritized task execution                     module selects and executes skill primitives based on the system’s                     current state, sensor inputs, and prior tasks. The framework is demonstrated by                     interactively controlling and programming a vacuum-cleaning robot. The                     demonstrations are used to exemplify the interactive programming and the plan                     recognition aspect of the research.},
	language = {en},
	number = {1},
	urldate = {2018-04-02TZ},
	journal = {The International Journal of Robotics Research},
	author = {Iba, Soshi and Paredis, Christiaan J. J. and Khosla, Pradeep K.},
	month = jan,
	year = {2005},
	pages = {83--104}
}

@article{gulwani2015inductive,
author = {Gulwani, Sumit and Hern\'{a}ndez-Orallo, Jos\'{e} and Kitzelmann, Emanuel and Muggleton, Stephen H. and Schmid, Ute and Zorn, Benjamin},
title = {Inductive Programming Meets the Real World},
year = {2015},
issue_date = {November 2015},
publisher = {ACM},
address = {New York, NY, USA},
volume = {58},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/2736282},
doi = {10.1145/2736282},
abstract = {Inductive programming can liberate users from performing tedious and repetitive tasks.},
journal = {Commun. ACM},
month = oct,
pages = {90–99},
numpages = {10}
}

@article{gulwani2017program,
  title={Program synthesis},
  author={Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh and others},
  journal={Foundations and Trends{\textregistered} in Programming Languages},
  volume={4},
  number={1-2},
  pages={1--119},
  year={2017},
  publisher={Now Publishers, Inc.}
}

@article{marin_multimodal_2005,
	title = {A multimodal interface to control a robot arm via the web: a case study on remote programming},
	volume = {52},
	issn = {0278-0046},
	shorttitle = {A multimodal interface to control a robot arm via the web},
	doi = {10.1109/TIE.2005.858733},
	abstract = {In this paper, we present the user interface and the system architecture of an Internet-based telelaboratory, which allows researchers and students to remotely control and program two educational online robots. In fact, the challenge has been to demonstrate that remote programming combined with an advanced multimedia user interface for remote control is very suitable, flexible, and profitable for the design of a telelaboratory. The user interface has been designed by using techniques based on augmented reality and nonimmersive virtual reality, which enhance the way operators get/put information from/to the robotic scenario. Moreover, the user interface provides the possibility of letting the operator manipulate the remote environment by using multiple ways of interaction (i.e., from the simplification of the natural language to low-level remote programming). In fact, the paper focuses on the lowest level of interaction between the operator and the robot, which is remote programming. As explained in the paper, the system architecture permits any external program (i.e., remote experiment, speech-recognition module, etc.) to have access to almost every feature of the telelaboratory (e.g., cameras, object recognition, robot control, etc.). The system validation was performed by letting 40 Ph.D. students within the "European Robotics Research Network Summer School on Internet and Online Robots for Telemanipulation" workshop (Benica`ssim, Spain, 2003) program several telemanipulation experiments with the telelaboratory. Some of these experiments are shown and explained in detail. Finally, the paper focuses on the analysis of the network performance for the proposed architecture (i.e., time delay). In fact, several configurations are tested through various networking protocols (i.e., Remote Method Invocation, Transmission Control Protocol/IP, User Datagram Protocol/IP). Results show the real possibilities offered by these remote-programming techniques, in order to design experiments intended to be performed from both home and the campus.},
	number = {6},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Marin, R. and Sanz, P. J. and Nebot, P. and Wirz, R.},
	month = dec,
	year = {2005},
	keywords = {Augmented reality, Control systems, Distributed systems, Educational robots, Internet, Internet-based telelaboratory, Multimedia systems, Programming profession, Protocols, Robot control, Robot programming, User interfaces, augmented reality, distributed system, education, education and training, human-robot interaction, humanoid robots, human–robot interaction, manipulators, multimedia user interface, nonimmersive virtual reality, online robots, remote control, remote programming, robot arm control, robotics, telelabs, telemanipulation, telerobotics, training, user modelling},
	pages = {1506--1520}
}

@inproceedings{li_programming_2017,
	address = {Cham},
	title = {Programming {IoT} {Devices} by {Demonstration} {Using} {Mobile} {Apps}},
	isbn = {978-3-319-58735-6},
	abstract = {The revolutionary advances of Internet of Things (IoT) devices and applications have helped IoT emerge as an increasingly important domain for end-user development (EUD). Past research has shown that end users desire to create various customized automations, which would often utilize multiple IoT devices. Many solutions exist to support EUD across multiple IoT devices, but they are limited to devices from the same manufacturer, within the same “eco-system” or supporting a common API. We present Epidosite, a mobile programming-by-demonstration system that addresses this limitation by leveraging the smartphone as a hub for IoT automation. It enables the creation of automations for most consumer IoT devices on smartphones by demonstrating the desired behaviors through directly manipulating the corresponding smartphone app for each IoT device. Epidosite also supports using the smartphone app usage context and external web services as triggers and data for automations, enabling the creation of highly context-aware IoT applications.},
	booktitle = {End-{User} {Development}},
	publisher = {Springer International Publishing},
	author = {Li, Toby Jia-Jun and Li, Yuanchun and Chen, Fanglin and Myers, Brad A.},
	editor = {Barbosa, Simone and Markopoulos, Panos and Paterno, Fabio and Stumpf, Simone and Valtolina, Stefano},
	year = {2017},
	pages = {3--17}
}

@article{miller_natural_1981,
	title = {Natural language programming: {Styles}, strategies, and contrasts},
	volume = {20},
	shorttitle = {Natural language programming},
	number = {2},
	journal = {IBM Systems Journal},
	author = {Miller, Lance A.},
	year = {1981},
	pages = {184--215}
}

@inproceedings{chen_learning_2011,
	address = {San Francisco, California},
	series = {{AAAI}'11},
	title = {Learning to {Interpret} {Natural} {Language} {Navigation} {Instructions} from {Observations}},
	url = {http://dl.acm.org/citation.cfm?id=2900423.2900560},
	abstract = {The ability to understand natural-language instructions is critical to building intelligent agents that interact with humans. We present a system that learns to transform natural-language navigation instructions into executable formal plans. Given no prior linguistic knowledge, the system learns by simply observing how humans follow navigation instructions. The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks. A previously collected realistic corpus of complex English navigation instructions for these environments is used for training and testing data. By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser, the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus.},
	urldate = {2018-03-27TZ},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {AAAI} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Chen, David L. and Mooney, Raymond J.},
	year = {2011},
	pages = {859--865}
}

@inproceedings{thomason_learning_2015,
	address = {Buenos Aires, Argentina},
	series = {{IJCAI}'15},
	title = {Learning to {Interpret} {Natural} {Language} {Commands} {Through} {Human}-robot {Dialog}},
	isbn = {978-1-57735-738-4},
	url = {http://dl.acm.org/citation.cfm?id=2832415.2832516},
	abstract = {Intelligent robots frequently need to understand requests from naive users through natural language. Previous approaches either cannot account for language variation, e.g., keyword search, or require gathering large annotated corpora, which can be expensive and cannot adapt to new variation. We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing, actively resolves ambiguities using a dialog manager, and incrementally learns from human-robot conversations by inducing training data from user paraphrases. Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days, tasked with understanding navigation and delivery requests through natural language in an office environment. In both contexts, We observe significant improvements in user satisfaction after learning from conversations.},
	urldate = {2018-03-27TZ},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Thomason, Jesse and Zhang, Shiqi and Mooney, Raymond and Stone, Peter},
	year = {2015},
	pages = {1923--1929}
}

@Article{Liu2004,
	author="Liu, H.
	and Singh, P.",
	title="ConceptNet --- A Practical Commonsense Reasoning Tool-Kit",
	journal="BT Technology Journal",
	year="2004",
	month="Oct",
	day="01",
	volume="22",
	number="4",
	pages="211--226",
	abstract="ConceptNet is a freely available commonsense knowledge base and natural-language-processing tool-kit which supports many practical textual-reasoning tasks over real-world documents including topic-gisting, analogy-making, and other context oriented inferences. The knowledge base is a semantic network presently consisting of over 1.6 million assertions of commonsense knowledge encompassing the spatial, physical, social, temporal, and psychological aspects of everyday life. ConceptNet is generated automatically from the 700 000 sentences of the Open Mind Common Sense Project --- a World Wide Web based collaboration with over 14 000 authors.",
	issn="1573-1995",
	doi="10.1023/B:BTTJ.0000047600.45421.6d",
	url="https://doi.org/10.1023/B:BTTJ.0000047600.45421.6d"
}

@book{Paterno:2017:NPE:3152674,
	author = {Paterno, Fabio and Wulf, Volker},
	title = {New Perspectives in End-User Development},
	year = {2017},
	isbn = {331960290X, 9783319602905},
	edition = {1st},
	publisher = {Springer},
}

@article{lau_why_2009,
	title = {Why {Programming}-{By}-{Demonstration} {Systems} {Fail}: {Lessons} {Learned} for {Usable} {AI}},
	volume = {30},
	copyright = {Copyright (c)},
	issn = {0738-4602},
	shorttitle = {Why {Programming}-{By}-{Demonstration} {Systems} {Fail}},
	url = {http://www.aaai.org/ojs/index.php/aimagazine/article/view/2262},
	language = {en},
	number = {4},
	urldate = {2016-09-15TZ},
	journal = {AI Magazine},
	author = {Lau, Tessa},
	month = oct,
	year = {2009},
	keywords = {programming-by-demonstration},
	pages = {65--67}
}
@inproceedings{srivastava_joint_2017,
	title = {Joint concept learning and semantic parsing from natural language explanations},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Srivastava, Shashank and Labutov, Igor and Mitchell, Tom},
	year = {2017},
	pages = {1527--1536}
}

@inbook{desmond_increasing_2021,
author = {Desmond, Michael and Muller, Michael and Ashktorab, Zahra and Dugan, Casey and Duesterwald, Evelyn and Brimijoin, Kristina and Finegan-Dollak, Catherine and Brachman, Michelle and Sharma, Aabhas and Joshi, Narendra Nath and Pan, Qian},
title = {Increasing the Speed and Accuracy of Data Labeling Through an AI Assisted Interface},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450698},
abstract = {Labeling data is an important step in the supervised machine learning lifecycle. It is a laborious human activity comprised of repeated decision making: the human labeler decides which of several potential labels to apply to each example. Prior work has shown that providing AI assistance can improve the accuracy of binary decision tasks. However, the role of AI assistance in more complex data-labeling scenarios with a larger set of labels has not yet been explored. We designed an AI labeling assistant that uses a semi-supervised learning algorithm to predict the most probable labels for each example. We leverage these predictions to provide assistance in two ways: (i) providing a label recommendation and (ii) reducing the labeler’s decision space by focusing their attention on only the most probable labels. We conducted a user study (n=54) to evaluate an AI-assisted interface for data labeling in this context. Our results highlight that the AI assistance improves both labeler accuracy and speed, especially when the labeler finds the correct label in the reduced label space. We discuss findings related to the presentation of AI assistance and design implications for intelligent labeling interfaces. },
booktitle = {26th International Conference on Intelligent User Interfaces},
pages = {392–401},
numpages = {10}
}


@inproceedings{berant_semantic_2013,
	title = {Semantic parsing on freebase from question-answer pairs},
	booktitle = {Proceedings of the 2013 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
	year = {2013},
	pages = {1533--1544}
}

@inproceedings{li_kite:_2018,
	title = {{KITE}: {Building} conversational bots from mobile apps},
	booktitle = {Proceedings of the 16th {ACM} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services} ({MobiSys} 2018)},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Riva, Oriana},
	year = {2018}
}

@inproceedings{myers_peridot:_1993,
	title = {Peridot: creating user interfaces by demonstration},
	shorttitle = {Peridot},
	booktitle = {Watch what {I} do},
	publisher = {MIT Press},
	author = {Myers, Brad A.},
	year = {1993},
	pages = {125--153}
}

@inproceedings{myers_scripting_1998,
	title = {Scripting graphical applications by demonstration},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems},
	publisher = {ACM Press/Addison-Wesley Publishing Co.},
	author = {Myers, Brad A.},
	year = {1998},
	pages = {534--541}
}

@inproceedings{halbert_smallstar:_1993,
	title = {{SmallStar}: programming by demonstration in the desktop metaphor},
	shorttitle = {{SmallStar}},
	booktitle = {Watch what {I} do},
	publisher = {MIT Press},
	author = {Halbert, Daniel C.},
	year = {1993},
	pages = {103--123}
}

@incollection{halbert_watch_1993,
	address = {Cambridge, MA, USA},
	title = {Watch {What} {I} {Do}},
	isbn = {978-0-262-03213-1},
	url = {http://dl.acm.org/citation.cfm?id=168080.168101},
	urldate = {2018-03-16TZ},
	publisher = {MIT Press},
	author = {Halbert, Daniel C.},
	editor = {Cypher, Allen and Halbert, Daniel C. and Kurlander, David and Lieberman, Henry and Maulsby, David and Myers, Brad A. and Turransky, Alan},
	year = {1993},
	pages = {103--123}
}

@patent{gruber_intelligent_2017,
	title = {Intelligent automated assistant},
	nationality = {U.S.},
	number = {9,548,050},
	author = {Gruber, Thomas Robert and Cheyer, Adam John and Kittlaus, Dag and Guzzoni, Didier Rene and Brigham, Christopher Dean and Giuli, Richard Donald and Bastea-Forte, Marcello and Saddler, Harry Joseph},
	month = jan,
	year = {2017}
}

@inproceedings{pappu_knowledge_2014,
	title = {Knowledge acquisition strategies for goal-oriented dialog systems},
	booktitle = {Proceedings of the 15th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue} ({SIGDIAL})},
	author = {Pappu, Aasish and Rudnicky, Alexander},
	year = {2014},
	pages = {194--198}
}

@misc{barkin_when_2016,
	title = {When {Bots} {Fail} {At} {Conversation}},
	abstract = {If there is any skepticism around conversational user experiences, it is due to a lack of confidence in the current state of artificial…},
	journal = {Being Janis},
	author = {Barkin, Josh},
	month = aug,
	year = {2016}
}

@misc{armstrong_helping_2017,
	title = {Helping {Your} {Baby} {Bot} {Learn} {To} {Chat} {Like} {A} {Grown} {Up} {Bot}},
	abstract = {In a conversation the user is always right – what are you doing to keep improving your bot’s understanding? Baby bots need help to grow up.},
	journal = {Chatbots Magazine},
	author = {Armstrong, Gillian},
	month = aug,
	year = {2017}
}

@misc{armstrong_ux_2017,
	title = {The {UX} of not making your users shout at your chatbot},
	abstract = {Have you thought about what your chatbot will do when the conversation goes wrong?},
	journal = {Chatbots Magazine},
	author = {Armstrong, Gillian},
	month = aug,
	year = {2017}
}

@inproceedings{li_designing_2017,
	address = {Denver, CO},
	title = {Designing a {Conversational} {Interface} for a {Multimodal} {Smartphone} {Programming}-by-{Demonstration} {Agent}},
	urldate = {2017-03-18TZ},
	booktitle = {Conversational {UX} {Design} {CHI} 2017 {Workshop}},
	author = {Li, Toby Jia-Jun and Myers, Brad A. and Azaria, Amos and Labutov, Igor and Rudnicky, Alexander I. and Mitchell, Tom M.},
	year = {2017}
}

@misc{mitman93_customer_nodate,
	title = {Customer review for {Amazon}.com: {Pizza} {Hut}: {Alexa} {Skills}},
	url = {https://www.amazon.com/Pizza-Hut/dp/B01MSXEBMC},
	urldate = {2017-10-05TZ},
	author = {Mitman93}
}

@inproceedings{li_end_2017,
	title = {End user mobile task automation using multimodal programming by demonstration},
	doi = {10.1109/VLHCC.2017.8103491},
	abstract = {Conversational agents are often used to perform tasks on smartphones, but existing conversational agents are limited in capabilities and lack of customizability. My work explores using the programming-by-demonstration approach to enable end users to program new tasks for conversational agents by demonstrating using the familiar graphical user interfaces of third-party apps. I propose to use a multi-modal (demonstration and verbal instruction) interface to support generalization, editing, error handling as well as creating control structures in creating such smartphone automation.},
	booktitle = {2017 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Li, Toby Jia-Jun},
	month = oct,
	year = {2017},
	keywords = {Automatic programming, End user development, Human factors, Mobile communication, Programming, Sugilite, automation, control structures, conversational agents, demonstration interface, editing process, end user mobile task automation, error handling, generalization process, graphical user interfaces, mobile computing, multimodal interface, multimodal programming-by-demonstration, programming by demonstration, smart homes, smart phone automation, smart phones, task automation, third-party apps, verbal instruction interface},
	pages = {323--324}
}

@inproceedings{witten_predictive_1993,
	title = {A predictive calculator},
	booktitle = {Watch what {I} do},
	publisher = {MIT Press},
	author = {Witten, Ian H.},
	year = {1993},
	pages = {67--76}
}

@book{lieberman_your_2001,
	title = {Your wish is my command: {Programming} by example},
	shorttitle = {Your wish is my command},
	urldate = {2016-09-10TZ},
	publisher = {Morgan Kaufmann},
	author = {Lieberman, Henry},
	year = {2001}
}

@inproceedings{gajos_supple:_2004,
	title = {{SUPPLE}: automatically generating user interfaces},
	shorttitle = {{SUPPLE}},
	urldate = {2016-09-07TZ},
	booktitle = {Proceedings of the 9th international conference on {Intelligent} user interfaces},
	publisher = {ACM},
	author = {Gajos, Krzysztof and Weld, Daniel S.},
	year = {2004},
	pages = {93--100}
}

@inproceedings{dzikovska_integrating_2003,
	title = {Integrating linguistic and domain knowledge for spoken dialogue systems in multiple domains},
	booktitle = {Proc. of {IJCAI}-03 {Workshop} on {Knowledge} and {Reasoning} in {Practical} {Dialogue} {Systems}},
	author = {Dzikovska, Myroslava O. and Allen, James F. and Swift, Mary D.},
	year = {2003}
}

@book{cypher_watch_1993,
	title = {Watch what {I} do: programming by demonstration},
	shorttitle = {Watch what {I} do},
	urldate = {2016-05-02TZ},
	publisher = {MIT press},
	author = {Cypher, Allen and Halbert, Daniel Conrad},
	year = {1993}
}

@inproceedings{bohus_sorry_2005,
	title = {Sorry, {I} didn't catch that!-{An} investigation of non-understanding errors and recovery strategies},
	booktitle = {6th {SIGdial} {Workshop} on {Discourse} and {Dialogue}},
	author = {Bohus, Dan and Rudnicky, Alexander I.},
	year = {2005}
}

@inproceedings{bohus_error_2005,
	title = {Error handling in the {RavenClaw} dialog management framework},
	booktitle = {Proceedings of the conference on {Human} {Language} {Technology} and {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {ACL},
	author = {Bohus, Dan and Rudnicky, Alexander I.},
	year = {2005},
	pages = {225--232}
}

@inproceedings{azaria_instructable_2016,
	title = {Instructable {Intelligent} {Personal} {Agent}},
	volume = {4},
	urldate = {2016-09-06TZ},
	booktitle = {Proc. {The} 30th {AAAI} {Conference} on {Artificial} {Intelligence} ({AAAI})},
	author = {Azaria, Amos and Krishnamurthy, Jayant and Mitchell, Tom M.},
	year = {2016}
}

@inproceedings{allen_plow:_2007,
	address = {Vancouver, British Columbia, Canada},
	series = {{AAAI}'07},
	title = {{PLOW}: {A} {Collaborative} {Task} {Learning} {Agent}},
	isbn = {978-1-57735-323-2},
	shorttitle = {{PLOW}},
	abstract = {To be effective, an agent that collaborates with humans needs to be able to learn new tasks from humans they work with. This paper describes a system that learns executable task models from a single collaborative learning session consisting of demonstration, explanation and dialogue. To accomplish this, the system integrates a range of AI technologies: deep natural language understanding, knowledge representation and reasoning, dialogue systems, planning/agent-based systems and machine learning. A formal evaluation shows the approach has great promise.},
	booktitle = {Proceedings of the 22Nd {National} {Conference} on {Artificial} {Intelligence} - {Volume} 2},
	publisher = {AAAI Press},
	author = {Allen, James and Chambers, Nathanael and Ferguson, George and Galescu, Lucian and Jung, Hyuckchul and Swift, Mary and Taysom, William},
	year = {2007},
	pages = {1514--1519}
}

@inproceedings{srivastava_joint_2017-1,
	title = {Joint concept learning and semantic parsing from natural language explanations},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Srivastava, Shashank and Labutov, Igor and Mitchell, Tom},
	year = {2017},
	pages = {1527--1536}
}

@inproceedings{koedinger_opening_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Opening the {Door} to {Non}-programmers: {Authoring} {Intelligent} {Tutor} {Behavior} by {Demonstration}},
	isbn = {978-3-540-22948-3 978-3-540-30139-4},
	shorttitle = {Opening the {Door} to {Non}-programmers},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-30139-4_16},
	doi = {10.1007/978-3-540-30139-4_16},
	abstract = {Intelligent tutoring systems are quite difficult and time intensive to develop. In this paper, we describe a method and set of software tools that ease the process of cognitive task analysis and tutor development by allowing the author to demonstrate, instead of programming, the behavior of an intelligent tutor. We focus on the subset of our tools that allow authors to create “Pseudo Tutors” that exhibit the behavior of intelligent tutors without requiring AI programming. Authors build user interfaces by direct manipulation and then use a Behavior Recorder tool to demonstrate alternative correct and incorrect actions. The resulting behavior graph is annotated with instructional messages and knowledge labels. We present some preliminary evidence of the effectiveness of this approach, both in terms of reduced development time and learning outcome. Pseudo Tutors have now been built for economics, analytic logic, mathematics, and language learning. Our data supports an estimate of about 25:1 ratio of development time to instruction time for Pseudo Tutors, which compares favorably to the 200:1 estimate for Intelligent Tutors, though we acknowledge and discuss limitations of such estimates.},
	language = {en},
	urldate = {2018-02-16TZ},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Koedinger, Kenneth R. and Aleven, Vincent and Heffernan, Neil and McLaren, Bruce and Hockenberry, Matthew},
	month = aug,
	year = {2004},
	pages = {162--174}
}

@inproceedings{azaria_recommender_2016,
	address = {New York, NY, USA},
	series = {{RecSys} '16},
	title = {Recommender {Systems} with {Personality}},
	isbn = {978-1-4503-4035-9},
	url = {http://doi.acm.org/10.1145/2959100.2959138},
	doi = {10.1145/2959100.2959138},
	abstract = {We believe that in the future, the most common form of recommender systems will be present in a personal assistant. We claim that such an intelligent agent must be personal, i.e., know its user's preferences and recommend relevant content, a dynamic learner, instructable, supportive and affable. We describe the current state of the art and the challenges which should be addressed in each of these agent properties and provide examples of how we expect future personal agents to convey these properties.},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Azaria, Amos and Hong, Jason},
	year = {2016},
	keywords = {intelligent agents, personal assistant, recommender systems, vision},
	pages = {207--210}
}

@patent{noauthor_intelligent_2011,
	title = {Intelligent automated assistant},
	url = {https://patents.google.com/patent/EP2526511A4/en},
	urldate = {2018-02-16TZ},
	month = jan,
	year = {2011}
}

@patent{noauthor_intelligent_2011-1,
	title = {Intelligent automated assistant},
	url = {https://patents.google.com/patent/EP2526511A4/en},
	urldate = {2018-02-16TZ},
	month = jan,
	year = {2011}
}

@inproceedings{bohus_constructing_2005,
	title = {Constructing accurate beliefs in spoken dialog systems},
	doi = {10.1109/ASRU.2005.1566504},
	abstract = {We propose a novel approach for constructing more accurate beliefs over concept values in spoken dialog systems by integrating information across multiple turns in the conversation. In particular, we focus our attention on updating the confidence score of the top hypothesis for a concept, in light of subsequent user responses to system confirmation actions. Our data-driven approach bridges previous work in confidence annotation and correction detection, providing a unified framework for belief updating. The approach significantly outperforms heuristic rules currently used in most spoken dialog systems},
	booktitle = {{IEEE} {Workshop} on {Automatic} {Speech} {Recognition} and {Understanding}, 2005.},
	author = {Bohus, D. and Rudnicky, A. I.},
	month = nov,
	year = {2005},
	keywords = {Automatic speech recognition, Bridges, Computer science, Error analysis, Face detection, Interactive systems, Natural languages, Robustness, Sections, Speech recognition, Vocabulary, confidence annotation, correction detection, speech processing, spoken dialog systems, spoken language interface, system confirmation actions},
	pages = {272--277}
}

@misc{noauthor_constructing_nodate,
	title = {Constructing accurate beliefs in spoken dialog systems - {IEEE} {Conference} {Publication}},
	url = {http://ieeexplore.ieee.org/abstract/document/1566504/},
	urldate = {2018-02-16TZ}
}

@incollection{myers_making_2017,
	title = {Making {End} {User} {Development} {More} {Natural}},
	isbn = {978-3-319-60290-5 978-3-319-60291-2},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-60291-2_1},
	abstract = {When end users approach a development task, they bring with them a set of techniques, expressions, and knowledge, which can be leveraged in order to make the process easier. The Natural Programming Project has been working for over twenty years to better understand how end users think about their tasks, and to develop new ways for users to express those tasks that will be more “natural,” by which we mean closer to the way they think. Our chapter in the previous book covered the first 10 years of this research; and here we summarize the most recent 10 years. This includes studies on barriers that impede EUD, and a new tool that helps with the understanding and debugging barriers by showing developers why their program has its current behavior. We also describe a tool that we created to help EUDs input, process, and transform data in the context of spreadsheets and web pages. Interaction designers are a class of EUDs that may need to program interactive behaviors, so we studied how they naturally express those behaviors, and then built a spreadsheet-like tool to allow them to author new behaviors. Another spreadsheet tool we created helps EUDs access web service data without writing code, and extends the familiar spreadsheet to support analyzing the acquired web-based hierarchical data and programming data-driven GUI applications. Finally, EUDs often need to engage in exploratory programming, where the goals and tasks are not well-formed in advance. We describe new tools to help users selectively undo past actions, along with on-going research to help EUDs create more efficient behaviors on smartphones and facilitate variations when performing data analysis.},
	language = {en},
	urldate = {2018-02-13TZ},
	booktitle = {New {Perspectives} in {End}-{User} {Development}},
	publisher = {Springer, Cham},
	author = {Myers, Brad A. and Ko, Amy J. and Scaffidi, Chris and Oney, Stephen and Yoon, YoungSeok and Chang, Kerry and Kery, Mary Beth and Li, Toby Jia-Jun},
	year = {2017},
	doi = {10.1007/978-3-319-60291-2_1},
	pages = {1--22}
}

@article{biermann_natural_1983,
	title = {Natural {Language} {Programming}},
	url = {https://link.springer.com/chapter/10.1007/978-94-009-7019-9_10},
	doi = {10.1007/978-94-009-7019-9_10},
	abstract = {A procedural semantics system is described for English imperative sentences in natural language programming. Issues related to the handling of dialog focus, noun group resolution, quantifier...},
	language = {en},
	urldate = {2018-02-13TZ},
	journal = {Computer Program Synthesis Methodologies},
	author = {Biermann, Alan W.},
	year = {1983},
	pages = {335--368}
}

@incollection{biermann_natural_1983-1,
	series = {{NATO} {Advanced} {Study} {Institutes} {Series}},
	title = {Natural {Language} {Programming}},
	isbn = {978-94-009-7021-2 978-94-009-7019-9},
	url = {https://link.springer.com/chapter/10.1007/978-94-009-7019-9_10},
	abstract = {A procedural semantics system is described for English imperative sentences in natural language programming. Issues related to the handling of dialog focus, noun group resolution, quantifier processing, and imperative verb execution are discussed. Sequences of imperative sentences may be assembled to build natural language programs and techniques are given for processing such programs. The final sections include a discussion of related research and a brief overview of the field.},
	language = {en},
	urldate = {2018-02-13TZ},
	booktitle = {Computer {Program} {Synthesis} {Methodologies}},
	publisher = {Springer, Dordrecht},
	author = {Biermann, Alan W.},
	year = {1983},
	doi = {10.1007/978-94-009-7019-9_10},
	pages = {335--368}
}

@article{noauthor_experimental_1983,
	title = {An experimental study of natural language programming},
	volume = {18},
	issn = {0020-7373},
	url = {https://www.sciencedirect.com/science/article/pii/S0020737383800054},
	doi = {10.1016/S0020-7373(83)80005-4},
	language = {en},
	number = {1},
	urldate = {2018-02-13TZ},
	journal = {International Journal of Man-Machine Studies},
	month = jan,
	year = {1983},
	pages = {71--87}
}

@article{biermann_experimental_1983,
	title = {An experimental study of natural language programming},
	volume = {18},
	issn = {0020-7373},
	url = {http://www.sciencedirect.com/science/article/pii/S0020737383800054},
	doi = {10.1016/S0020-7373(83)80005-4},
	abstract = {An experiment is described which gives data related to the usefulness and efficiency of English as a programming language. The experiment was performed with the NLC system, described herein, and used twenty-three paid volunteers from a first course in programming. Subjects were asked to solve two problems, namely (1) solution of linear equations and (2) gradebook averaging. A total of 1581 English sentences were typed, 81\% of which were processed correctly. The remaining 19\% were rejected because of questionable user syntax or system inadequacies. In most cases, subjects were able to paraphrase a rejected input in terminology understandable by the system. The overall success rate at solving an entire problem, within the 2½ h time constraint of the experiment, was 73·9\%. In short, the system was an effective problem solver for the selected classes of problems and users. Many system failures resulted from “bugs” or syntactic oversights which appear amenable to easy repair. None of the Standard concerns about natural language programming related to vagueness, ambiguity, verbosity or correctness was a significant problem, although minor difficulties did arise occasionally.},
	number = {1},
	journal = {International Journal of Man-Machine Studies},
	author = {Biermann, Alan W. and Ballard, Bruce W. and Sigmon, Anne H.},
	month = jan,
	year = {1983},
	pages = {71--87}
}

@article{lauria_mobile_2002,
	series = {Advances in {Robot} {Skill} {Learning}},
	title = {Mobile robot programming using natural language},
	volume = {38},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889002001665},
	doi = {10.1016/S0921-8890(02)00166-5},
	abstract = {How will naive users program domestic robots? This paper describes the design of a practical system that uses natural language to teach a vision-based robot how to navigate in a miniature town. To enable unconstrained speech the robot is provided with a set of primitive procedures derived from a corpus of route instructions. When the user refers to a route that is not known to the robot, the system will learn it by combining primitives as instructed by the user. This paper describes the components of the Instruction-Based Learning architecture and discusses issues of knowledge representation, the selection of primitives and the conversion of natural language into robot-understandable procedures.},
	number = {3},
	journal = {Robotics and Autonomous Systems},
	author = {Lauria, Stanislao and Bugmann, Guido and Kyriacou, Theocharis and Klein, Ewan},
	month = mar,
	year = {2002},
	keywords = {Corpus collection, Human–robot dialogue, Mobile robots learning, Route description, natural language},
	pages = {171--181}
}

@inproceedings{lee_towards_2017,
	address = {New York, NY, USA},
	series = {{IUI} '17},
	title = {Towards {Understanding} {Human} {Mistakes} of {Programming} by {Example}: {An} {Online} {User} {Study}},
	isbn = {978-1-4503-4348-0},
	shorttitle = {Towards {Understanding} {Human} {Mistakes} of {Programming} by {Example}},
	url = {http://doi.acm.org/10.1145/3025171.3025203},
	doi = {10.1145/3025171.3025203},
	abstract = {Programming-by-Example (PBE) enables users to create programs without writing a line of code. However, there is little research on people's ability to accomplish complex tasks by providing examples, which is the key to successful PBE solutions. This paper presents an online user study, which reports observations on how well people decompose complex tasks, and disambiguate sub-tasks. Our findings suggest that disambiguation and decomposition are difficult for inexperienced users. We identify seven types of mistakes made, and suggest new opportunities for actionable feedback based on unsuccessful examples, with design implications for future PBE systems.},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Lee, Tak Yeon and Dugan, Casey and Bederson, Benjamin B.},
	year = {2017},
	keywords = {programming-by-example, user study},
	pages = {257--261}
}

@inproceedings{zhang_interactive_2020,
author = {Zhang, Tianyi and Lowmanstone, London and Wang, Xinyu and Glassman, Elena L.},
title = {Interactive Program Synthesis by Augmented Examples},
year = {2020},
isbn = {9781450375146},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379337.3415900},
doi = {10.1145/3379337.3415900},
abstract = {Programming-by-example (PBE) has become an increasingly popular component in software development tools, human-robot interaction, and end-user programming. A long-standing challenge in PBE is the inherent ambiguity in user-provided examples. This paper presents an interaction model to disambiguate user intent and reduce the cognitive load of understanding and validating synthesized programs. Our model provides two types of augmentations to user-given examples: 1) semantic augmentation where a user can specify how different aspects of an example should be treated by a synthesizer via light-weight annotations, and 2) data augmentation where the synthesizer generates additional examples to help the user understand and validate synthesized programs. We implement and demonstrate this interaction model in the domain of regular expressions, which is a popular mechanism for text processing and data wrangling and is often considered hard to master even for experienced programmers. A within-subjects user study with twelve participants shows that, compared with only inspecting and annotating synthesized programs, interacting with augmented examples significantly increases the success rate of finishing a programming task with less time and increases users? confidence of synthesized programs.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
pages = {627–648},
numpages = {22},
keywords = {program synthesis, disambiguation, example augmentation},
location = {Virtual Event, USA},
series = {UIST '20}
}

@inproceedings{ferdowsifard_small_2020,
author = {Ferdowsifard, Kasra and Ordookhanians, Allen and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
title = {Small-Step Live Programming by Example},
year = {2020},
isbn = {9781450375146},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379337.3415869},
doi = {10.1145/3379337.3415869},
abstract = {Live programming is a paradigm in which the programming environment continually displays runtime values. Program synthesis is a technique that can generate programs or program snippets from examples. deltextThis paper presents a new programming paradigm called Synthesis-Aided Live Programming that combines these two prior ideas in a synergistic way. When using Synthesis-Aided Live Programming, programmers can change the runtime values displayed by the live addtextPrevious works that combine the two have taken a holistic approach to the way examples describe the behavior of functions and programs. This paper presents a new programming paradigm called Small-Step Live Programming by Example that lets the user apply Programming by Example locally. When using Small-Step Live Programming by Example, programmers can change the runtime values displayed by the live visualization to generate local program snippets. % Live programming and program % synthesis work perfectly together because the live programming environment % reifies values, which makes it easy for programmers to provide the examples % needed by the synthesizer. We implemented this new paradigm in a tool called toolname, and performed a user study on $13$ programmers. Our study finds that Small-Step Live Programming by Example with toolname helps users solve harder problems faster, and that for certain types of queries, users prefer it to searching the web. Additionally, we identify the usersynthgap, in which users' mental models of the tool do not match its ability, and needs to be taken into account in the design of future synthesis tools.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
pages = {614–626},
numpages = {13},
keywords = {live programming, program synthesis},
location = {Virtual Event, USA},
series = {UIST '20}
}

@inproceedings{wang_interactive_2017,
author = {Wang, Chenglong and Cheung, Alvin and Bodik, Rastislav},
title = {Interactive Query Synthesis from Input-Output Examples},
year = {2017},
isbn = {9781450341974},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3035918.3058738},
doi = {10.1145/3035918.3058738},
abstract = {This demo showcases Scythe, a novel query-by-example system that can synthesize expressive SQL queries from input-output examples. Scythe is designed to help end-users program SQL and explore data simply using input-output examples. From a web-browser, users can obtain SQL queries with Scythe in an automated, interactive fashion: from a provided example, Scythe synthesizes SQL queries and resolves ambiguities via conversations with the users.In this demo, we first show Scythe how end users can formulate queries using Scythe; we then switch to the perspective of an algorithm designer to show how Scythe can scale up to handle complex SQL features, like outer joins and subqueries.},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
pages = {1631–1634},
numpages = {4},
keywords = {program synthesis, sql, database interface},
location = {Chicago, Illinois, USA},
series = {SIGMOD '17}
}

@inproceedings{mcdaniel_gamut:_1997,
	address = {New York, NY, USA},
	series = {{UIST} '97},
	title = {Gamut: {Demonstrating} {Whole} {Applications}},
	isbn = {978-0-89791-881-7},
	shorttitle = {Gamut},
	url = {http://doi.acm.org/10.1145/263407.263515},
	doi = {10.1145/263407.263515},
	booktitle = {Proceedings of the 10th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {McDaniel, Richard G. and Myers, Brad A.},
	year = {1997},
	keywords = {Gamut, applicaiton builders, end-user programming, inductive learning, programming-by-demonstration, programming-by-example, user interface software},
	pages = {81--82}
}

@inproceedings{gulwani_automating_2011,
	address = {New York, NY, USA},
	series = {{POPL} '11},
	title = {Automating {String} {Processing} in {Spreadsheets} {Using} {Input}-output {Examples}},
	isbn = {978-1-4503-0490-0},
	url = {http://doi.acm.org/10.1145/1926385.1926423},
	doi = {10.1145/1926385.1926423},
	abstract = {We describe the design of a string programming/expression language that supports restricted forms of regular expressions, conditionals and loops. The language is expressive enough to represent a wide variety of string manipulation tasks that end-users struggle with. We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input-output examples. The synthesis algorithm is very efficient taking a fraction of a second for various benchmark examples. The synthesis algorithm is interactive and has several desirable features: it can rank multiple solutions and has fast convergence, it can detect noise in the user input, and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations. The algorithm has been implemented as an interactive add-in for Microsoft Excel spreadsheet system. The prototype tool has met the golden test - it has synthesized part of itself, and has been used to solve problems beyond author's imagination.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Gulwani, Sumit},
	year = {2011},
	keywords = {program synthesis, programming by example (pbe), spreadsheet programming, string manipulation, user intent, version space algebra},
	pages = {317--330}
}

@inproceedings{hartmann_programming_2007,
	address = {New York, NY, USA},
	series = {{UIST} '07},
	title = {Programming by a {Sample}: {Rapidly} {Creating} {Web} {Applications} with {D}.{Mix}},
	isbn = {978-1-59593-679-0},
	shorttitle = {Programming by a {Sample}},
	url = {http://doi.acm.org/10.1145/1294211.1294254},
	doi = {10.1145/1294211.1294254},
	abstract = {Source-code examples of APIs enable developers to quickly gain a gestalt understanding of a library's functionality, and they support organically creating applications by incrementally modifying a functional starting point. As an increasing number of web sites provide APIs, significantlatent value lies in connecting the complementary representations between site and service - in essence, enabling sites themselves to be the example corpus. We introduce d.mix, a tool for creating web mashups that leverages this site-to-service correspondence. With d.mix, users browse annotated web sites and select elements to sample. d.mix's sampling mechanism generates the underlying service calls that yield those elements. This code can be edited, executed, and shared in d.mix's wiki-based hosting environment. This sampling approach leverages pre-existing web sites as example sets and supports fluid composition and modification of examples. An initial study with eight participants found d.mix to enable rapid experimentation, and suggested avenues for improving its annotation mechanism.},
	booktitle = {Proceedings of the 20th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Hartmann, Björn and Wu, Leslie and Collins, Kevin and Klemmer, Scott R.},
	year = {2007},
	keywords = {Mashups, programming by example modification, prototyping, web services},
	pages = {241--250}
}

@inproceedings{eagan_cracking_2011,
	address = {New York, NY, USA},
	series = {{UIST} '11},
	title = {Cracking the {Cocoa} {Nut}: {User} {Interface} {Programming} at {Runtime}},
	isbn = {978-1-4503-0716-1},
	shorttitle = {Cracking the {Cocoa} {Nut}},
	url = {http://doi.acm.org/10.1145/2047196.2047226},
	doi = {10.1145/2047196.2047226},
	abstract = {This article introduces runtime toolkit overloading, a novel approach to help third-party developers modify the interaction and behavior of existing software applications without access to their underlying source code. We describe the abstractions provided by this approach as well as the mechanisms for implementing them in existing environments. We describe Scotty, a prototype implementation for Mac OS X Cocoa that enables developers to modify existing applications at runtime, and we demonstrate a collection of interaction and functional transformations on existing off-the-shelf applications. We show how Scotty helps a developer make sense of unfamiliar software, even without access to its source code. We further discuss what features of future environments would facilitate this kind of runtime software development.},
	booktitle = {Proceedings of the 24th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Eagan, James R. and Beaudouin-Lafon, Michel and Mackay, Wendy E.},
	year = {2011},
	keywords = {User interfaces, meta-toolkits, runtime software development, runtime toolkit overloading},
	pages = {225--234}
}

@inproceedings{deka_rico:_2017,
	address = {New York, NY, USA},
	series = {{UIST} '17},
	title = {Rico: {A} {Mobile} {App} {Dataset} for {Building} {Data}-{Driven} {Design} {Applications}},
	isbn = {978-1-4503-4981-9},
	shorttitle = {Rico},
	url = {http://doi.acm.org/10.1145/3126594.3126651},
	doi = {10.1145/3126594.3126651},
	abstract = {Data-driven models help mobile app designers understand best practices and trends, and can be used to make predictions about design performance and support the creation of adaptive UIs. This paper presents Rico, the largest repository of mobile app designs to date, created to support five classes of data-driven applications: design search, UI layout generation, UI code generation, user interaction modeling, and user perception prediction. To create Rico, we built a system that combines crowdsourcing and automation to scalably mine design and interaction data from Android apps at runtime. The Rico dataset contains design data from more than 9.7k Android apps spanning 27 categories. It exposes visual, textual, structural, and interactive design properties of more than 72k unique UI screens. To demonstrate the kinds of applications that Rico enables, we present results from training an autoencoder for UI layout similarity, which supports query- by-example search over UIs.},
	booktitle = {Proceedings of the 30th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Deka, Biplab and Huang, Zifeng and Franzen, Chad and Hibschman, Joshua and Afergan, Daniel and Li, Yang and Nichols, Jeffrey and Kumar, Ranjitha},
	year = {2017},
	keywords = {app datasets, design mining, design search, mobile app design},
	pages = {845--854}
}

@article{oviatt_ten_1999,
	title = {Ten {Myths} of {Multimodal} {Interaction}},
	volume = {42},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/319382.319398},
	doi = {10.1145/319382.319398},
	number = {11},
	journal = {Commun. ACM},
	author = {Oviatt, Sharon},
	month = nov,
	year = {1999},
	pages = {74--81}
}

@inproceedings{beaudouin-lafon_instrumental_2000,
	address = {New York, NY, USA},
	series = {{CHI} '00},
	title = {Instrumental {Interaction}: {An} {Interaction} {Model} for {Designing} post-{WIMP} {User} {Interfaces}},
	isbn = {978-1-58113-216-8},
	shorttitle = {Instrumental {Interaction}},
	url = {http://doi.acm.org/10.1145/332040.332473},
	doi = {10.1145/332040.332473},
	abstract = {This article introduces a new interaction model called Instrumental Interaction that extends and generalizes the principles of direct manipulation. It covers existing interaction styles, including traditional WIMP interfaces, as well as new interaction styles such as two-handed input and augmented reality. It defines a design space for new interaction techniques and a set of properties for comparing them. Instrumental Interaction describes graphical user interfaces in terms of domain objects and interaction instruments. Interaction between users and domain objects is mediated by interaction instruments, similar to the tools and instruments we use in the real world to interact with physical objects. The article presents the model, applies it to describe and compare a number of interaction techniques, and shows how it was used to create a new interface for searching and replacing text.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Beaudouin-Lafon, Michel},
	year = {2000},
	keywords = {WIMP interfaces, direct manipulation, instrumental interaction, interaction model, post-WIMP interfaces},
	pages = {446--453}
}

@inproceedings{lucente_visualization_1998,
	title = {Visualization space: {A} testbed for deviceless multimodal user interface},
	volume = {98},
	shorttitle = {Visualization space},
	booktitle = {Intelligent {Environments} {Symposium}},
	author = {Lucente, Mark and Zwart, Gert-Jan and George, Andrew D.},
	year = {1998}
}

@inproceedings{bolt_put-that-there:_1980,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '80},
	title = {``{Put}-that-there'': {Voice} and {Gesture} at the {Graphics} {Interface}},
	isbn = {978-0-89791-021-7},
	shorttitle = {“{Put}-that-there”},
	abstract = {Recent technological advances in connected-speech recognition and position sensing in space have encouraged the notion that voice and gesture inputs at the graphics interface can converge to provide a concerted, natural user modality. The work described herein involves the user commanding simple shapes about a large-screen graphics display surface. Because voice can be augmented with simultaneous pointing, the free usage of pronouns becomes possible, with a corresponding gain in naturalness and economy of expression. Conversely, gesture aided by voice gains precision in its power to reference.},
	booktitle = {Proceedings of the 7th {Annual} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques}},
	publisher = {ACM},
	author = {Bolt, Richard A.},
	year = {1980},
	keywords = {Graphics interface, Man-machine interfaces, Space sensing, Spatial data management, Speech input, Voice input, gesture, graphics},
	pages = {262--270}
}

@article{mackay_responding_2000,
	title = {Responding to cognitive overload: {Co}-adaptation between users and technology},
	volume = {30},
	shorttitle = {Responding to cognitive overload},
	number = {1},
	journal = {Intellectica},
	author = {Mackay, Wendy E.},
	year = {2000},
	pages = {177--193}
}

@article{mayer1995integrative,
  title={An integrative model of organizational trust},
  author={Mayer, Roger C and Davis, James H and Schoorman, F David},
  journal={Academy of Management Review},
  volume={20},
  number={3},
  pages={709--734},
  year={1995},
  publisher={Academy of Management}
}

@inproceedings{hsiao_role:_2018,
author = {Hsiao, Joey Chiao-Yin and Moser, Carol and Schoenebeck, Sarita and Dillahunt, Tawanna R.},
title = {The Role of Demographics, Trust, Computer Self-Efficacy, and Ease of Use in the Sharing Economy},
year = {2018},
isbn = {9781450358163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209811.3209816},
doi = {10.1145/3209811.3209816},
abstract = {The digital sharing economy has introduced opportunities for economic growth, productivity, and technological innovation. However, the adoption of sharing economy applications may be inaccessible to certain demographics, including older adults, low-income adults, and individuals who are not college educated. This research investigates how the demographic factors: trust, computer self-efficacy, and perceived ease of use, impact participation in the sharing economy. Drawing on survey data with 508 participants, we found that trust in institutions, computer self-efficacy, and perceived ease of use positively correlate to individuals' past use of and willingness to pay for future sharing economy services, but age is negatively correlated. Surprisingly, we do not find that sharing economy users are more likely to have higher trust in strangers, higher incomes, or more education. We compare our findings to existing research, discuss why institutional trust might negate other concerns about sharing economy use, and explore opportunities to support broader participation in the sharing economy.},
booktitle = {Proceedings of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies},
articleno = {37},
numpages = {11},
keywords = {Income, Quantitative Analysis, Self-efficacy, Sharing economy, Education, Survey, Trust, Age},
location = {Menlo Park and San Jose, CA, USA},
series = {COMPASS '18}
}

@book{usbls_2017, 
title={Contingent and Alternative Employment Arrangements}, 
author={U.S. Bureau of Labor Statistics}, 
year={2017}
}

@article{duggan2020algorithmic,
  title={Algorithmic management and app-work in the gig economy: A research agenda for employment relations and HRM},
  author={Duggan, James and Sherman, Ultan and Carbery, Ronan and McDonnell, Anthony},
  journal={Human Resource Management Journal},
  volume={30},
  number={1},
  pages={114--132},
  year={2020},
  publisher={Wiley Online Library}
}

@article{spurk_flexible_2017,
title = {Flexible employment relationships and careers in times of the COVID-19 pandemic},
journal = {Journal of Vocational Behavior},
volume = {119},
pages = {103435},
year = {2020},
issn = {0001-8791},
doi = {https://doi.org/10.1016/j.jvb.2020.103435},
url = {https://www.sciencedirect.com/science/article/pii/S0001879120300609},
author = {Daniel Spurk and Caroline Straub},
keywords = {COVID-19, Crisis, Change, Flexible work arrangements, Gig work, Careers, Period effect, Corona},
abstract = {The COVID-19 pandemic represents a crisis that affects several aspects of people's lives around the globe. Most of the affected countries took several measures, like lockdowns, business shutdowns, hygiene regulations, social distancing, school and university closings, or mobility tracking as a means of slowing down the distribution of COVID-19. These measures are expected to show short-term and long-term effects on people's working lives. However, most media reports focused on the effects of the COVID-19 pandemic on changes in work arrangements (e.g., short-time work, flexible location and hours) for workers in a regular employment relationship. We here focus on workers in flexible employment relationships (e.g. temporary agency work and other forms of subcontracted labor, as well as new forms of working, such as in the gig economy). Specifically, we will discuss (a) how the work and careers of individuals in flexible employment relationships might get affected by the COVID-19 pandemic; (b) outline ideas how to examine period effects of the COVID-19 pandemic on the work and careers of those individuals, and (c) outline how the pandemic can contribute to the ramification of flexible employment relationships.}
}

@article{farrell2018online,
  title={The online platform economy in 2018: Drivers, workers, sellers, and lessors},
  author={Farrell, Diana and Greig, Fiona and Hamoudi, Amar},
  journal={JPMorgan Chase Institute},
  year={2018}
}

@article{jackson2017rise,
  title={The rise of alternative work arrangements: Evidence and implications for tax filing and benefit coverage},
  author={Jackson, Emilie and Looney, Adam and Ramnath, Shanthi},
  journal={Office of Tax Analysis Working Paper},
  volume={114},
  year={2017}
}

@inproceedings{li_screen2vec:_2021,
	series = {{CHI} '21},
	title = {Screen2Vec: Semantic Embedding of GUI Screens and GUI Components},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Popowski, Lindsay and Mitchell, Tom M. and Myers, Brad A.},
	year = {2021}
}

@inbook{cameron_this:_2021,
author = {Cameron, Lindsey and Christin, Angele and Ann DeVito, Michael and R. Dillahunt, Tawanna and Elish, Madeleine and Gray, Mary and Qadri, Rida and Raval, Noopur and Valentine, Melissa and Anne Watkins, Elizabeth},
title = {“This Seems to Work”: Designing Technological Systems with The Algorithmic Imaginations of Those Who Labor},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3441331},
abstract = {Algorithmically mediated systems and tools are used by workers across the globe. Many of these workers are in low-power positions, where they have little leverage to make demands around transparency, explanation, or terms of use, yet, at the same time rely deeply on these systems for many aspects of their jobs. This tension between little power and high reliance drives the production of intensive algorithmic imaginaries, where workers engage in meaning-making to construct understandings of these systems. Yet, there has been little attention paid to the diversity and ingenuity of algorithmic understandings crafted by the workers. In this workshop, our goal is to bring together researchers and practitioners from across disciplines to create a research agenda, compare vocabularies, and discuss methodologies around this form of “folk tradecraft.” This toolkit will help elicit insights into these phenomena and ultimately build mechanisms by which the labor of algorithmic meaning-making can be respected, understood, and leveraged for system design.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {115},
numpages = {5}
}

@inproceedings{bistaffa_recommending:_2015,
author = {Bistaffa, Filippo and Farinelli, Alessandro and Chalkiadakis, Georgios and Ramchurn, Sarvapali D.},
title = {Recommending Fair Payments for Large-Scale Social Ridesharing},
year = {2015},
isbn = {9781450336925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2792838.2800177},
doi = {10.1145/2792838.2800177},
abstract = {We perform recommendations for the Social Ridesharing scenario, in which a set of commuters, connected through a social network, arrange one-time rides at short notice. In particular, we focus on how much one should pay for taking a ride with friends. More formally, we propose the first approach that can compute fair coalitional payments that are also stable according to the game-theoretic concept of the kernel for systems with thousands of agents in real-world scenarios. Our tests, based on real datasets for both spatial (GeoLife) and social data (Twitter), show that our approach is significantly faster than the state-of-the-art (up to 84 times), allowing us to compute stable payments for 2000 agents in 50 minutes. We also develop a parallel version of our approach, which achieves a near-optimal speed-up in the number of processors used. Finally, our empirical analysis reveals new insights into the relationship between payments incurred by a user by virtue of its position in its social network and its role (rider or driver).},
booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
pages = {139–146},
numpages = {8},
keywords = {ridesharing, innovative applications, social networks, coalition formation, algorithm scalability},
location = {Vienna, Austria},
series = {RecSys '15}
}

@article{dillahunt_sharing:_2017,
author = {Dillahunt, Tawanna R. and Wang, Xinyi and Wheeler, Earnest and Cheng, Hao Fei and Hecht, Brent and Zhu, Haiyi},
title = {The Sharing Economy in Computing: A Systematic Literature Review},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {CSCW},
url = {https://doi.org/10.1145/3134673},
doi = {10.1145/3134673},
abstract = {The sharing economy has quickly become a very prominent subject of research in the
broader computing literature and the in human--computer interaction (HCI) literature
more specifically. When other computing research areas have experienced similarly
rapid growth (e.g. human computation, eco-feedback technology), early stage literature
reviews have proved useful and influential by identifying trends and gaps in the literature
of interest and by providing key directions for short- and long-term future work.
In this paper, we seek to provide the same benefits with respect to computing research
on the sharing economy. Specifically, following the suggested approach of prior computing
literature reviews, we conducted a systematic review of sharing economy articles published
in the Association for Computing Machinery Digital Library to investigate the state
of sharing economy research in computing. We performed this review with two simultaneous
foci: a broad focus toward the computing literature more generally and a narrow focus
specifically on HCI literature. We collected a total of 112 sharing economy articles
published between 2008 and 2017 and through our analysis of these papers, we make
two core contributions: (1) an understanding of the computing community's contributions
to our knowledge about the sharing economy, and specifically the role of the HCI community
in these contributions (i.e.what has been done) and (2) a discussion of under-explored
and unexplored aspects of the sharing economy that can serve as a partial research
agenda moving forward (i.e.what is next to do).},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = dec,
articleno = {38},
numpages = {26},
keywords = {collaborative consumption, collaborative economy, literature review, sharing economy, taxonomy, gig economy, physical crowdsourcing}
}

@inproceedings{dillahunt_reflections:_2017,
author = {Dillahunt, Tawanna R. and Erete, Sheena and Galusca, Roxana and Israni, Aarti and Nacu, Denise and Sengers, Phoebe},
title = {Reflections on Design Methods for Underserved Communities},
year = {2017},
isbn = {9781450346887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3022198.3022664},
doi = {10.1145/3022198.3022664},
abstract = {The goal of this workshop is to facilitate a discussion around the ways in which research
and design methods can be better tailored to support and engage underserved communities.
We aim to create a publicly accessible repository of tools to support research and
design efforts with underserved communities and to facilitate critical conversations
about appropriate methods and solutions in this space. At the workshop, participants
will collaborate with one another to explore their own as well as past, present, and
future research and design initiatives with underserved communities; discuss challenges
and lessons learned from using methods to facilitate technological development and
creation among such populations; and brainstorm methods and solutions to address these
challenges. Discussion and ideas generated from this workshop will be archived online
and made available to the larger research community.},
booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {409–413},
numpages = {5},
location = {Portland, Oregon, USA},
series = {CSCW '17 Companion}
}


@misc{riva2020automatically,
  title={Automatically generating conversational services from a computing application},
  author={Riva, Oriana and Kace, Jason Alan and Burger, Douglas Christopher and Li, Jiajun},
  year={2020},
  month=jul # "~7",
  publisher={Google Patents},
  note={US Patent 10,705,892}
}
{"mode":"full","isActive":false}

@article{lee_understanding:_2018,
author = {Min Kyung Lee},
title ={Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management},
journal = {Big Data \& Society},
volume = {5},
number = {1},
pages = {2053951718756684},
year = {2018},
doi = {10.1177/2053951718756684},

URL = { 
        https://doi.org/10.1177/2053951718756684
    
},
eprint = { 
        https://doi.org/10.1177/2053951718756684
    
}
,
    abstract = { Algorithms increasingly make managerial decisions that people used to make. Perceptions of algorithms, regardless of the algorithms' actual performance, can significantly influence their adoption, yet we do not fully understand how people perceive decisions made by algorithms as compared with decisions made by humans. To explore perceptions of algorithmic management, we conducted an online experiment using four managerial decisions that required either mechanical or human skills. We manipulated the decision-maker (algorithmic or human), and measured perceived fairness, trust, and emotional response. With the mechanical tasks, algorithmic and human-made decisions were perceived as equally fair and trustworthy and evoked similar emotions; however, human managers' fairness and trustworthiness were attributed to the manager's authority, whereas algorithms' fairness and trustworthiness were attributed to their perceived efficiency and objectivity. Human decisions evoked some positive emotion due to the possibility of social recognition, whereas algorithmic decisions generated a more mixed response – algorithms were seen as helpful tools but also possible tracking mechanisms. With the human tasks, algorithmic decisions were perceived as less fair and trustworthy and evoked more negative emotion than human decisions. Algorithms' perceived lack of intuition and subjective judgment capabilities contributed to the lower fairness and trustworthiness judgments. Positive emotion from human decisions was attributed to social recognition, while negative emotion from algorithmic decisions was attributed to the dehumanizing experience of being evaluated by machines. This work reveals people's lay concepts of algorithmic versus human decisions in a management context and suggests that task characteristics matter in understanding people's experiences with algorithmic technologies. }
}

@inproceedings{lee_working:_2015,
author = {Lee, Min Kyung and Kusbit, Daniel and Metsky, Evan and Dabbish, Laura},
title = {Working with Machines: The Impact of Algorithmic and Data-Driven Management on Human Workers},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702548},
doi = {10.1145/2702123.2702548},
abstract = {Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1603–1612},
numpages = {10},
keywords = {human-centered algorithms, cscw, work assignment, sharing economies, sensemaking, on-demand work, algorithmic management, performance evaluation, dynamic pricing, algorithm, data-driven metrics, intelligent systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inbook{niloufar_dynamo:_2015,
author = {Salehi, Niloufar and Irani, Lilly C. and Bernstein, Michael S. and Alkhatib, Ali and Ogbe, Eva and Milland, Kristy and Clickhappier},
title = {We Are Dynamo: Overcoming Stalling and Friction in Collective Action for Crowd Workers},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702508},
abstract = {By lowering the costs of communication, the web promises to enable distributed collectives
to act around shared issues. However, many collective action efforts never succeed:
while the web's affordances make it easy to gather, these same decentralizing characteristics
impede any focus towards action. In this paper, we study challenges to collective
action efforts through the lens of online labor by engaging with Amazon Mechanical
Turk workers. Through a year of ethnographic fieldwork, we sought to understand online
workers' unique barriers to collective action. We then created Dynamo, a platform
to support the Mechanical Turk community in forming publics around issues and then
mobilizing. We found that collective action publics tread a precariously narrow path
between the twin perils of stalling and friction, balancing with each step between
losing momentum and flaring into acrimony. However, specially structured labor to
maintain efforts' forward motion can help such publics take action.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1621–1630},
numpages = {10}
}

@inproceedings{thebault-spieker_avoiding:_2015,
author = {Thebault-Spieker, Jacob and Terveen, Loren G. and Hecht, Brent},
title = {Avoiding the South Side and the Suburbs: The Geography of Mobile Crowdsourcing Markets},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675278},
doi = {10.1145/2675133.2675278},
abstract = {Mobile crowdsourcing markets (e.g., Gigwalk and TaskRabbit) offer crowdworkers tasks
situated in the physical world (e.g., checking street signs, running household errands).
The geographic nature of these tasks distinguishes these markets from online crowdsourcing
markets and raises new, fundamental questions. We carried out a controlled study in
the Chicago metropolitan area aimed at addressing two key questions: (1) What geographic
factors influence whether a crowdworker will be willing to do a task? (2) What geographic
factors influence how much compensation a crowdworker will demand in order to do a
task? Quantitative modeling shows that travel distance to the location of the task
and the socioeconomic status (SES) of the task area are important factors. Qualitative
analysis enriches our modeling, with workers mentioning safety and difficulties getting
to a location as key considerations. Our results suggest that low-SES areas are currently
less able to take advantage of the benefits of mobile crowdsourcing markets. We discuss
the implications of our study for these markets, as well as for "sharing economy"
phenomena like UberX, which have many properties in common with mobile crowdsourcing
markets.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
pages = {265–275},
numpages = {11},
keywords = {volunteered geographic information, mobile crowdsourcing},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}



@misc{democratic_national_committee_plan_2021,
	title = {Plan to {Strengthen} {Organized} {Labor} and {Collective} {Bargaining} {\textbar} {Joe} {Biden}},
	url = {https://joebiden.com/empowerworkers/},
	abstract = {Strong unions built the American middle class. That's why Joe Biden has an extensive plan for strengthening organized labor and collective bargaining.},
	language = {en-US},
	urldate = {2021-07-11},
	journal = {Joe Biden for President: Official Campaign Website},
	author = {Democratic National Committee},
	year = {2021},
	file = {Snapshot:/Users/toby/Zotero/storage/WUY8XQ8V/empowerworkers.html:text/html},
}

@misc{segal_labor_2021,
	title = {Labor {Department} {Rescinds} {Trump} {Administration}’s {Policy} {On} {Gig} {Workers}},
	url = {https://www.forbes.com/sites/edwardsegal/2021/05/05/labor-department-rescinds-trump-administrations-policy-on-gig-workers/},
	abstract = {The U.S. Department of Labor nullified a decision by the Trump administration that would have made it more challenging for gig workers to be considered employees by the federal government.},
	language = {en},
	urldate = {2021-07-11},
	journal = {Forbes},
	year = {2021},
	author = {Segal, Edward},
	note = {Section: Leadership Strategy},
	file = {Snapshot:/Users/toby/Zotero/storage/878V9SZ2/labor-department-rescinds-trump-administrations-policy-on-gig-workers.html:text/html},
}

@misc{gig_worker_rising_gig_2021,
	title = {Gig {Workers} {Rising} - {News} {Coverage}},
	url = {https://gigworkersrising.org/get-informed/news/},
	abstract = {Shining a spotlight on the gig economy},
	language = {en},
	urldate = {2021-07-11},
	journal = {Gig Workers Rising - News Coverage},
	author = {Gig Worker Rising},
	year = {2021},
	file = {Snapshot:/Users/toby/Zotero/storage/SJ9V2H6N/news.html:text/html},
}

@misc{california_attorney_general_proposition_2021,
	title = {Proposition 22 {Official} {Title} and {Summary}},
	url = {https://voterguide.sos.ca.gov/propositions/22/title-summary.htm},
	urldate = {2021-07-11},
	author = {California Attorney General},
	year = {2021},
	file = {Proposition 22 Official Title and Summary | Official Voter Information Guide | California Secretary of State:/Users/toby/Zotero/storage/F3VTFWRR/title-summary.html:text/html},
}



@misc{mitic_24_2021,
	title = {24+ {Crucial} {Gig} {Economy} {Statistics} and {Facts} {\textbar} {Fortunly}.com},
	url = {https://fortunly.com/statistics/gig-economy-statistics/},
	abstract = {The latest gig economy statistics show that the freelancer economy model is taking over the world, and the US is not an exception.},
	language = {en},
	urldate = {2021-07-11},
	year = {2021},
	journal = {Fortunly},
	author = {Mitic, Igor},
	file = {Snapshot:/Users/toby/Zotero/storage/XEC4K6P7/gig-economy-statistics.html:text/html},
}

@book{gray2019ghost,
author = {Gray, Mary L.},
address = {Boston},
booktitle = {Ghost work : how to stop Silicon Valley from building a new global underclass},
isbn = {9781328566249},
keywords = {artificial intelligence},
language = {eng},
publisher = {Houghton Mifflin Harcourt},
title = {Ghost work  : how to stop Silicon Valley from building a new global underclass },
year = {2019},
abstract = {"A startling exposé of the invisible human workforce that powers the web--and how to bring it out of the shadows. Hidden beneath the surface of the internet, a new, stark reality is looming--one that cuts to the very heart of our endless debates about the impact of AI. Anthropologist Mary L. Gray and computer scientist Siddharth Suri unveil how the services we use from companies like Amazon, Google, Microsoft, and Uber can only function smoothly thanks to the judgment and experience of a vast human labor force that is kept deliberately concealed. The people who do 'ghost work' make the internet seem smart. They perform high-tech, on-demand piecework: flagging X-rated content, proofreading, transcribing audio, confirming identities, captioning video, and much more. The shameful truth is that no labor laws protect them or even acknowledge their existence. They often earn less than legal minimums for traditional work, they have no health benefits, and they can be fired at any time for any reason, or for no reason at all. An estimated 8 percent of Americans have worked in this 'ghost economy,' and that number is growing every day. In this unprecedented investigation, Gray and Suri make the case that robots will never completely eliminate 'ghost work' and the unchecked quest for artificial intelligence could spark catastrophic work conditions if not stopped in its tracks. Ultimately, they show how this essential type of work can create opportunity--rather than misery--for those who do it."--Dust jacket.},
}



@article{graham2020fairwork,
  title={The Fairwork Foundation: Strategies for improving platform work in a global context},
  author={Graham, Mark and Woodcock, Jamie and Heeks, Richard and Mungai, Paul and Van Belle, Jean-Paul and du Toit, Darcy and Fredman, Sandra and Osiki, Abigail and van der Spuy, Anri and Silberman, Six M},
  journal={Geoforum},
  volume={112},
  pages={100--103},
  year={2020},
  publisher={Elsevier}
}
{"mode":"full","isActive":false}

@inproceedings{suhr_two-sided:_2019,
author = {S\"{u}hr, Tom and Biega, Asia J. and Zehlike, Meike and Gummadi, Krishna P. and Chakraborty, Abhijnan},
title = {Two-Sided Fairness for Repeated Matchings in Two-Sided Markets: A Case Study of a Ride-Hailing Platform},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330793},
doi = {10.1145/3292500.3330793},
abstract = {Ride hailing platforms, such as Uber, Lyft, Ola or DiDi, have traditionally focused
on the satisfaction of the passengers, or on boosting successful business transactions.
However, recent studies provide a multitude of reasons to worry about the drivers
in the ride hailing ecosystem. The concerns range from bad working conditions and
worker manipulation to discrimination against minorities. With the sharing economy
ecosystem growing, more and more drivers financially depend on online platforms and
their algorithms to secure a living. It is pertinent to ask what a fair distribution
of income on such platforms is and what power and means the platform has in shaping
these distributions.In this paper, we analyze job assignments of a major taxi company
and observe that there is significant inequality in the driver income distribution.
We propose a novel framework to think about fairness in the matching mechanisms of
ride hailing platforms. Specifically, our notion of fairness relies on the idea that,
spread over time, all drivers should receive benefits proportional to the amount of
time they are active in the platform. We postulate that by not requiring every match
to be fair, but rather distributing fairness over time, we can achieve better overall
benefit for the drivers and the passengers. We experiment with various optimization
problems and heuristics to explore the means of achieving two-sided fairness, and
investigate their caveats and side-effects. Overall, our work takes the first step
towards rethinking fairness in ride hailing platforms with an additional emphasis
on the well-being of drivers.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {3082–3092},
numpages = {11},
keywords = {algorithmic fairness, matching, social computing},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{thelisson_towards:_2017,
author = {Thelisson, Eva},
title = {Towards Trust, Transparency, and Liability in AI/AS Systems},
year = {2017},
isbn = {9780999241103},
publisher = {AAAI Press},
abstract = {The research problem being investigated in this article is how to develop governance
mechanisms and collective decision-making processes at a global level for Artificial
Intelligence (AI) systems and Autonomous systems (AS), which would enhance confidence
in AI and AS.},
booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence},
pages = {5215–5216},
numpages = {2},
location = {Melbourne, Australia},
series = {IJCAI'17}
}



@article{thebault-spieker_toward:_2017,
author = {Thebault-Spieker, Jacob and Terveen, Loren and Hecht, Brent},
title = {Toward a Geographic Understanding of the Sharing Economy: Systemic Biases in UberX and TaskRabbit},
year = {2017},
issue_date = {July 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {1073-0516},
url = {https://doi.org/10.1145/3058499},
doi = {10.1145/3058499},
abstract = {Despite the geographically situated nature of most sharing economy tasks, little attention has been paid to the role that geography plays in the sharing economy. In this article, we help to address this gap in the literature by examining how four key principles from human geography—distance decay, structured variation in population density, mental maps, and “the Big Sort” (spatial homophily)—manifest in sharing economy platforms. We find that these principles interact with platform design decisions to create systemic biases in which the sharing economy is significantly more effective in dense, high socioeconomic status (SES) areas than in low-SES areas and the suburbs. We further show that these results are robust across two sharing economy platforms: UberX and TaskRabbit. In addition to highlighting systemic sharing economy biases, this article more fundamentally demonstrates the importance of considering well-known geographic principles when designing and studying sharing economy platforms.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = apr,
articleno = {21},
numpages = {40},
keywords = {residential segregation, big sort, location-aware computing; mobile crowdsourcing, Sharing economy; geography, population density, mental maps, distance decay}
}



@inproceedings{hannak_bias:_2017,
author = {Hann\'{a}k, Anik\'{o} and Wagner, Claudia and Garcia, David and Mislove, Alan and Strohmaier, Markus and Wilson, Christo},
title = {Bias in Online Freelance Marketplaces: Evidence from TaskRabbit and Fiverr},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2998181.2998327},
doi = {10.1145/2998181.2998327},
abstract = {Online freelancing marketplaces have grown quickly in recent years. In theory, these sites offer workers the ability to earn money without the obligations and potential social biases associated with traditional employment frameworks. In this paper, we study whether two prominent online freelance marketplaces - TaskRabbit and Fiverr - are impacted by racial and gender bias. From these two platforms, we collect 13,500 worker profiles and gather information about workers' gender, race, customer reviews, ratings, and positions in search rankings. In both marketplaces, we find evidence of bias: we find that gender and race are significantly correlated with worker evaluations, which could harm the employment opportunities afforded to the workers. We hope that our study fuels more research on the presence and implications of discrimination in online environments.},
booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {1914–1933},
numpages = {20},
keywords = {discrimination, information retrieval, gig economy, linguistic analysis},
location = {Portland, Oregon, USA},
series = {CSCW '17}
}

@inproceedings{jhaver_algorithmic:_2018,
author = {Jhaver, Shagun and Karpfen, Yoni and Antin, Judd},
title = {Algorithmic Anxiety and Coping Strategies of Airbnb Hosts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173995},
doi = {10.1145/3173574.3173995},
abstract = {Algorithms increasingly mediate how work is evaluated in a wide variety of work settings. Drawing on our interviews with 15 Airbnb hosts, we explore the impact of algorithmic evaluation on users and their work practices in the context of Airbnb. Our analysis reveals that Airbnb hosts engage in a double negotiation on the platform: They must negotiate efforts not just to attract potential guests but also to appeal to only partially transparent evaluative algorithms. We found that a perceived lack of control and uncertainty over how algorithmic evaluation works can create anxiety among some Airbnb hosts. We present a framework for understanding this double negotiation, as well as a case study of coping strategies that hosts employ to deal with their anxiety. We conclude with a discussion of design solutions that can help reduce algorithmic anxiety and increase confidence in algorithmic systems.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human-centered algorithms, coping strategies, sharing economies, sensemaking, performance evaluation, airbnb, algorithmic awareness, algorithm},
location = {Montreal QC, Canada},
series = {CHI '18}
}



@inproceedings{li_sugilite:_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {{SUGILITE}: {Creating} {Multimodal} {Smartphone} {Automation} by {Demonstration}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {{SUGILITE}},
	url = {http://doi.acm.org/10.1145/3025453.3025483},
	doi = {10.1145/3025453.3025483},
	abstract = {SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When the user gives verbal commands that SUGILITE does not know how to execute, the user can demonstrate by directly manipulating the regular apps' user interface. By leveraging the verbal instructions, the demonstrated procedures, and the apps? UI hierarchy structures, SUGILITE can automatically generalize the script from the recorded actions, so SUGILITE learns how to perform tasks with different variations and parameters from a single demonstration. Extensive error handling and context checking support forking the script when new situations are encountered, and provide robustness if the apps change their user interface. Our lab study suggests that users with little or no programming knowledge can successfully automate smartphone tasks using SUGILITE.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Azaria, Amos and Myers, Brad A.},
	year = {2017},
	keywords = {end-user development, programming by demonstration, smartphone automation},
	pages = {6038--6049}
}


@inproceedings{brandt_two_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Two {Studies} of {Opportunistic} {Programming}: {Interleaving} {Web} {Foraging}, {Learning}, and {Writing} {Code}},
	isbn = {978-1-60558-246-7},
	shorttitle = {Two {Studies} of {Opportunistic} {Programming}},
	url = {http://doi.acm.org/10.1145/1518701.1518944},
	doi = {10.1145/1518701.1518944},
	abstract = {This paper investigates the role of online resources in problem solving. We look specifically at how programmers - an exemplar form of knowledge workers - opportunistically interleave Web foraging, learning, and writing code. We describe two studies of how programmers use online resources. The first, conducted in the lab, observed participants' Web use while building an online chat room. We found that programmers leverage online resources with a range of intentions: They engage in just-in-time learning of new skills and approaches, clarify and extend their existing knowledge, and remind themselves of details deemed not worth remembering. The results also suggest that queries for different purposes have different styles and durations. Do programmers' queries "in the wild" have the same range of intentions, or is this result an artifact of the particular lab setting? We analyzed a month of queries to an online programming portal, examining the lexical structure, refinements made, and result pages visited. Here we also saw traits that suggest the Web is being used for learning and reminding. These results contribute to a theory of online resource usage in programming, and suggest opportunities for tools to facilitate online knowledge work.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brandt, Joel and Guo, Philip J. and Lewenstein, Joel and Dontcheva, Mira and Klemmer, Scott R.},
	year = {2009},
	keywords = {copy-and-paste, opportunistic programming, prototyping},
	pages = {1589--1598}
}

@inproceedings{chagas_end-user_2017,
	title = {End-user design for the {Internet} of {Things}: {Supporting} incremental evolution through breakdowns},
	shorttitle = {End-user design for the {Internet} of {Things}},
	doi = {10.1109/VLHCC.2017.8103484},
	abstract = {The Internet of Things (IoT) is expected to produce several changes in the ways computer technologies influence our life and in how we interact with them. Computation embedded in interconnected “smart” devices surrounding us is composing an emerging infrastructure able to sense, infer and actuate in the world in unprecedented ways, changing businesses and our everyday life. Among the several challenges that such reality is introducing, there are those related to how end-users will be able to tailor their own technology. For instance, the combined diversity of devices, individual preferences, needs and contexts of use makes it unlikely, if not impossible, for any designer to address all users' needs and preferences beforehand. Moreover, these needs and preferences are likely to change, following the dynamics of everyday life and the idiosyncratic moods, ideas, and goals of individuals. End-User Development (EUD) is an approach to address end-users' specific needs and preferences by enabling them to tailor computer technologies by themselves using simple (e.g. setting parameters) and advanced techniques (e.g. macro and visual programming). With such approach, technology can be tailored by end-users to address unanticipated and changing needs during use-time.},
	booktitle = {2017 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Chagas, B. A.},
	month = oct,
	year = {2017},
	keywords = {EUD approach, Electric breakdown, Internet of Things, IoT, Maintenance engineering, Semiotics, Software, Tools, User interfaces, end-user design, end-user development, incremental evolution, interconnected smart devices, user needs, user preferences, visualization},
	pages = {309--310}
}

@inproceedings{davidoff_principles_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Principles of {Smart} {Home} {Control}},
	isbn = {978-3-540-39634-5 978-3-540-39635-2},
	url = {https://link.springer.com/chapter/10.1007/11853565_2},
	doi = {10.1007/11853565_2},
	abstract = {Seeking to be sensitive to users, smart home researchers have focused on the concept of control. They attempt to allow users to gain control over their lives by framing the problem as one of end-user programming. But families are not users as we typically conceive them, and a large body of ethnographic research shows how their activities and routines do not map well to programming tasks. End-user programming ultimately provides control of devices. But families want more control of their lives. In this paper, we explore this disconnect. Using grounded contextual fieldwork with dual-income families, we describe the control that families want, and suggest seven design principles that will help end-user programming systems deliver that control.},
	language = {en},
	urldate = {2018-01-24TZ},
	booktitle = {{UbiComp} 2006: {Ubiquitous} {Computing}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Davidoff, Scott and Lee, Min Kyung and Yiu, Charles and Zimmerman, John and Dey, Anind K.},
	month = sep,
	year = {2006},
	pages = {19--34}
}

@inproceedings{kery_variolite:_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {Variolite: {Supporting} {Exploratory} {Programming} by {Data} {Scientists}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {Variolite},
	url = {http://doi.acm.org/10.1145/3025453.3025626},
	doi = {10.1145/3025453.3025626},
	abstract = {How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kery, Mary Beth and Horvath, Amber and Myers, Brad},
	year = {2017},
	keywords = {end-user programming, exploratory data analysis, variants, variations, version control systems (vcs)},
	pages = {1265--1276}
}

@inproceedings{kery_exploring_2017,
	title = {Exploring exploratory programming},
	doi = {10.1109/VLHCC.2017.8103446},
	abstract = {In open-ended tasks where a program's behavior cannot be specified in advance, exploratory programming is a key practice in which programmers actively experiment with different possibilities using code. Exploratory programming is highly relevant today to a variety of professional and end-user programmer domains, including prototyping, learning through play, digital art, and data science. However, prior research has largely lacked clarity on what exploratory programming is, and what behaviors are characteristic of this practice. Drawing on this data and prior literature, we provide an organized description of what exploratory programming has meant historically and a framework of four dimensions for studying exploratory programming tasks: (1) applications, (2) required code quality, (3) ease or difficulty of exploration, and (4) the exploratory process. This provides a basis for better analyzing tool support for exploratory programming.},
	booktitle = {2017 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Kery, M. Beth and Myers, B. A.},
	month = oct,
	year = {2017},
	keywords = {Creativity Support, Debugging, Games, Programming, Programming profession, Tools, code quality, end-user programming, exploratory programming, prototyping, software prototyping, source code (software), visualization},
	pages = {25--29}
}

@misc{northwoods_software_gojs_nodate,
	title = {{GoJS} {Diagrams} for {JavaScript} and {HTML}},
	url = {https://gojs.net/},
	urldate = {2017-11-05TZ},
	author = {Northwoods Software}
}

@inproceedings{chaudhri_case_2006,
	address = {Aachen, Germany, Germany},
	series = {{SemDesk}'06},
	title = {A {Case} {Study} in {Engineering} a {Knowledge} {Base} for an {Intelligent} {Personal} {Assistant}},
	url = {http://dl.acm.org/citation.cfm?id=2889986.2889989},
	abstract = {We present a case study in engineering a large knowledge base to meet the requirements of a personal assistant. The agent is designed to function as part of a semantic desktop application with the goal of helping a user manage and organize his information as well as support the user in performing day today tasks. We discuss our development methodology and the knowledge engineering challenges we faced in the process.},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Semantic} {Desktop} and {Social} {Semantic} {Collaboration} - {Volume} 202},
	publisher = {CEUR-WS.org},
	author = {Chaudhri, Vinay K. and Cheyer, Adam and Guili, Richard and Jarrold, Bill and Myers, Karen L. and Niekarsz, John},
	year = {2006},
	pages = {25--32}
}
@misc{noauthor_google_nodate,
	title = {Google {Scholar}},
	url = {https://scholar.google.com/},
	urldate = {2017-10-02TZ}
}

@inproceedings{cypher_eager:_1993,
	title = {Eager: {Programming} repetitive tasks by demonstration},
	shorttitle = {Eager},
	url = {http://dl.acm.org/citation.cfm?id=168111},
	booktitle = {Watch what {I} do},
	publisher = {MIT Press},
	author = {Cypher, Allen},
	year = {1993},
	pages = {205--217}
}

@inproceedings{mikolov_distributed_2013,
	title = {Distributed representations of words and phrases and their compositionality},
	url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality},
	booktitle = {Advances in neural information processing systems},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S. and Dean, Jeff},
	year = {2013},
	pages = {3111--3119}
}

@inproceedings{sen_wikibrain:_2014,
	title = {Wikibrain: democratizing computation on wikipedia},
	shorttitle = {Wikibrain},
	url = {http://dl.acm.org/citation.cfm?id=2641615},
	booktitle = {Proceedings of {The} {International} {Symposium} on {Open} {Collaboration}},
	publisher = {ACM},
	author = {Sen, Shilad and Li, Toby Jia-Jun and Team, WikiBrain and Hecht, Brent},
	year = {2014},
	pages = {27}
}

@article{vrandecic_wikidata:_2014,
	title = {Wikidata: a free collaborative knowledgebase},
	volume = {57},
	shorttitle = {Wikidata},
	url = {http://dl.acm.org/citation.cfm?id=2629489},
	number = {10},
	journal = {Communications of the ACM},
	author = {Vrandečić, Denny and Krötzsch, Markus},
	year = {2014},
	pages = {78--85}
}

@article{auer_dbpedia:_2007,
	title = {Dbpedia: {A} nucleus for a web of open data},
	shorttitle = {Dbpedia},
	url = {http://www.springerlink.com/index/rm32474088w54378.pdf},
	journal = {The semantic web},
	author = {Auer, Sören and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
	year = {2007},
	pages = {722--735}
}

@inproceedings{bollacker_freebase:_2008,
	title = {Freebase: a collaboratively created graph database for structuring human knowledge},
	shorttitle = {Freebase},
	url = {http://dl.acm.org/citation.cfm?id=1376746},
	booktitle = {Proceedings of the 2008 {ACM} {SIGMOD} international conference on {Management} of data},
	publisher = {ACM},
	author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
	year = {2008},
	pages = {1247--1250}
}

@inproceedings{bird_nltk:_2006,
	title = {{NLTK}: the natural language toolkit},
	shorttitle = {{NLTK}},
	url = {http://dl.acm.org/citation.cfm?id=1225421},
	booktitle = {Proceedings of the {COLING}/{ACL} on {Interactive} presentation sessions},
	publisher = {ACL},
	author = {Bird, Steven},
	year = {2006},
	pages = {69--72}
}

@misc{noauthor_nltk_nodate,
	title = {{NLTK}},
	url = {http://dl.acm.org/citation.cfm?id=1118117},
	urldate = {2017-09-21TZ}
}

@misc{noauthor_nltk_nodate-1,
	title = {{NLTK}},
	url = {http://dl.acm.org/citation.cfm?id=1118117},
	urldate = {2017-09-21TZ}
}

@misc{noauthor_openccg_nodate,
	title = {The {OpenCCG} {Homepage}},
	url = {http://openccg.sourceforge.net/},
	urldate = {2017-09-21TZ}
}

@inproceedings{manning_stanford_2014,
	title = {The {Stanford} {CoreNLP} {Natural} {Language} {Processing} {Toolkit}},
	doi = {10.3115/v1/P14-5010},
	abstract = {We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straight-forward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.},
	booktitle = {Proceedings of 52Nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	author = {Manning, Christoper and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and J. Bethard, Steven and McClosky, David},
	month = jan,
	year = {2014}
}

@inproceedings{manning_stanford_2014-1,
	title = {The stanford corenlp natural language processing toolkit.},
	url = {http://www.aclweb.org/website/old_anthology/P/P14/P14-5.pdf#page=67},
	booktitle = {{ACL} ({System} {Demonstrations})},
	author = {Manning, Christopher D. and Surdeanu, Mihai and Bauer, John and Finkel, Jenny Rose and Bethard, Steven and McClosky, David},
	year = {2014},
	pages = {55--60}
}

@incollection{lieberman_end-user_2006,
	series = {Human-{Computer} {Interaction} {Series}},
	title = {End-{User} {Development}: {An} {Emerging} {Paradigm}},
	isbn = {978-1-4020-4220-1 978-1-4020-5386-3},
	shorttitle = {End-{User} {Development}},
	url = {https://link.springer.com/chapter/10.1007/1-4020-5386-X_1},
	abstract = {We think that over the next few years, the goal of interactive systems and services will evolve from just making systems easy to use (even though that goal has not yet been completely achieved) to making systems that are easy to develop by end users. By now, most people have become familiar with the basic functionality and interfaces of computers, but they are not able to manage any programming language. Therefore, they cannot develop new applications or modify current ones according to their needs.In order to address such challenges it is necessary a new paradigm, based on a multidisciplinary approach involving several types of expertise, such as software engineering, human-computer interaction, CSCW, which are now rather fragmented and with little interaction. The resulting methods and tools can provide results useful across many application domains, such as ERP, multi-device services (accessible through both mobile and stationary devices), and professional applications.Key words. tailorability, end user programming, flexibility, usability},
	language = {en},
	urldate = {2017-09-19TZ},
	booktitle = {End {User} {Development}},
	publisher = {Springer, Dordrecht},
	author = {Lieberman, Henry and Paternò, Fabio and Klann, Markus and Wulf, Volker},
	year = {2006},
	doi = {10.1007/1-4020-5386-X_1},
	pages = {1--8}
}

@inproceedings{ritter_data-driven_2011,
	title = {Data-driven response generation in social media},
	url = {http://dl.acm.org/citation.cfm?id=2145500},
	booktitle = {Proceedings of the conference on empirical methods in natural language processing},
	publisher = {ACL},
	author = {Ritter, Alan and Cherry, Colin and Dolan, William B.},
	year = {2011},
	pages = {583--593}
}

@misc{noauthor_data-driven_nodate,
	title = {Data-driven response generation in social media},
	url = {http://dl.acm.org/citation.cfm?id=2145500},
	urldate = {2017-09-04TZ}
}

@misc{noauthor_data-driven_nodate-1,
	title = {Data-driven response generation in social media},
	url = {http://dl.acm.org/citation.cfm?id=2145500},
	urldate = {2017-09-04TZ}
}

@article{chung_empirical_2014,
	title = {Empirical {Evaluation} of {Gated} {Recurrent} {Neural} {Networks} on {Sequence} {Modeling}},
	url = {http://arxiv.org/abs/1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
	journal = {arXiv:1412.3555 [cs]},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3555},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	journal = {Neural Comput.},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780}
}

@inproceedings{abadi_tensorflow:_2016,
	address = {Berkeley, CA, USA},
	series = {{OSDI}'16},
	title = {{TensorFlow}: {A} {System} for {Large}-scale {Machine} {Learning}},
	isbn = {978-1-931971-33-1},
	shorttitle = {{TensorFlow}},
	url = {http://dl.acm.org/citation.cfm?id=3026877.3026899},
	abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
	booktitle = {Proceedings of the 12th {USENIX} {Conference} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	year = {2016},
	pages = {265--283}
}

@article{DBLP:journals/corr/abs-1802-08802,
  author    = {Evan Zheran Liu and
               Kelvin Guu and
               Panupong Pasupat and
               Tianlin Shi and
               Percy Liang},
  title     = {Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration},
  journal   = {CoRR},
  volume    = {abs/1802.08802},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.08802},
  archivePrefix = {arXiv},
  eprint    = {1802.08802},
  timestamp = {Mon, 13 Aug 2018 16:47:14 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1802-08802},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Xu:2011:IDU:2068816.2068847,
 author = {Xu, Qiang and Erman, Jeffrey and Gerber, Alexandre and Mao, Zhuoqing and Pang, Jeffrey and Venkataraman, Shobha},
 title = {Identifying Diverse Usage Behaviors of Smartphone Apps},
 booktitle = {Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference},
 series = {IMC '11},
 year = {2011},
 isbn = {978-1-4503-1013-0},
 location = {Berlin, Germany},
 pages = {329--344},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/2068816.2068847},
 doi = {10.1145/2068816.2068847},
 acmid = {2068847},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {app usage behavior, smartphone apps},
} 
[download]

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning}
}

@inproceedings{finkel_incorporating_2005,
	address = {Stroudsburg, PA, USA},
	series = {{ACL} '05},
	title = {Incorporating {Non}-local {Information} into {Information} {Extraction} {Systems} by {Gibbs} {Sampling}},
	url = {https://doi.org/10.3115/1219840.1219885},
	doi = {10.3115/1219840.1219885},
	abstract = {Most current statistical natural language processing models use only local features so as to permit dynamic programming in inference, but this makes them unable to fully account for the long distance structure that is prevalent in language use. We show how to solve this dilemma with Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models. By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference. We use this technique to augment an existing CRF-based information extraction system with long-distance dependency models, enforcing label consistency and extraction template consistency constraints. This technique results in an error reduction of up to 9\% over state-of-the-art systems on two established information extraction tasks.},
	booktitle = {Proceedings of the 43rd {Annual} {Meeting} on {Association} for {Computational} {Linguistics}},
	publisher = {ACL},
	author = {Finkel, Jenny Rose and Grenager, Trond and Manning, Christopher},
	year = {2005},
	pages = {363--370}
}

@inproceedings{lau_conversational_2010,
	address = {New York, NY, USA},
	series = {{UIST} '10},
	title = {A {Conversational} {Interface} to {Web} {Automation}},
	isbn = {978-1-4503-0271-5},
	url = {http://doi.acm.org/10.1145/1866029.1866067},
	doi = {10.1145/1866029.1866067},
	abstract = {This paper presents CoCo, a system that automates web tasks on a user's behalf through an interactive conversational interface. Given a short command such as "get road conditions for highway 88," CoCo synthesizes a plan to accomplish the task, executes it on the web, extracts an informative response, and returns the result to the user as a snippet of text. A novel aspect of our approach is that we leverage a repository of previously recorded web scripts and the user's personal web browsing history to determine how to complete each requested task. This paper describes the design and implementation of our system, along with the results of a brief user study that evaluates how likely users are to understand what CoCo does for them.},
	booktitle = {Proceedings of the 23Nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Lau, Tessa and Cerruti, Julian and Manzato, Guillermo and Bengualid, Mateo and Bigham, Jeffrey P. and Nichols, Jeffrey},
	year = {2010},
	keywords = {automation, intelligent assistants, natural language interfaces},
	pages = {229--238}
}

@inproceedings{adar_commandspace:_2014,
	address = {New York, NY, USA},
	series = {{UIST} '14},
	title = {{CommandSpace}: {Modeling} the {Relationships} {Between} {Tasks}, {Descriptions} and {Features}},
	isbn = {978-1-4503-3069-5},
	shorttitle = {{CommandSpace}},
	url = {http://doi.acm.org/10.1145/2642918.2647395},
	doi = {10.1145/2642918.2647395},
	abstract = {Users often describe what they want to accomplish with an application in a language that is very different from the application's domain language. To address this gap between system and human language, we propose modeling an application's domain language by mining a large corpus of Web documents about the application using deep learning techniques. A high dimensional vector space representation can model the relationships between user tasks, system commands, and natural language descriptions and supports mapping operations, such as identifying likely system commands given natural language queries and identifying user tasks given a trace of user operations. We demonstrate the feasibility of this approach with a system, CommandSpace, for the popular photo editing application Adobe Photoshop. We build and evaluate several applications enabled by our model showing the power and flexibility of this approach.},
	booktitle = {Proceedings of the 27th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Adar, Eytan and Dontcheva, Mira and Laput, Gierad},
	year = {2014},
	keywords = {application language domain, deep-learning, natural language interfaces},
	pages = {167--176}
}

@inproceedings{laput_pixeltone:_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {{PixelTone}: {A} {Multimodal} {Interface} for {Image} {Editing}},
	isbn = {978-1-4503-1899-0},
	shorttitle = {{PixelTone}},
	url = {http://doi.acm.org/10.1145/2470654.2481301},
	doi = {10.1145/2470654.2481301},
	abstract = {Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone, a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Laput, Gierad P. and Dontcheva, Mira and Wilensky, Gregg and Chang, Walter and Agarwala, Aseem and Linder, Jason and Adar, Eytan},
	year = {2013},
	keywords = {image editing, multimodal interfaces, natural language},
	pages = {2185--2194}
}

@inproceedings{zhang_interaction_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {Interaction {Proxies} for {Runtime} {Repair} and {Enhancement} of {Mobile} {Application} {Accessibility}},
	isbn = {978-1-4503-4655-9},
	url = {http://doi.acm.org/10.1145/3025453.3025846},
	doi = {10.1145/3025453.3025846},
	abstract = {We introduce interaction proxies as a strategy for runtime repair and enhancement of the accessibility of mobile applications. Conceptually, interaction proxies are inserted between an application's original interface and the manifest interface that a person uses to perceive and manipulate the application. This strategy allows third-party developers and researchers to modify an interaction without an application's source code, without rooting the phone, without otherwise modifying an application, while retaining all capabilities of the system (e.g., Android's full implementation of the TalkBack screen reader). This paper introduces interaction proxies, defines a design space of interaction re-mappings, identifies necessary implementation abstractions, presents details of implementing those abstractions in Android, and demonstrates a set of Android implementations of interaction proxies from throughout our design space. We then present a set of interviews with blind and low-vision people interacting with our prototype interaction proxies, using these interviews to explore the seamlessness of interaction, the perceived usefulness and potential of interaction proxies, and visions of how such enhancements could gain broad usage. By allowing third-party developers and researchers to improve an interaction, interaction proxies offer a new approach to personalizing mobile application accessibility and a new approach to catalyzing development, deployment, and evaluation of mobile accessibility enhancements.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhang, Xiaoyi and Ross, Anne Spencer and Caspi, Anat and Fogarty, James and Wobbrock, Jacob O.},
	year = {2017},
	keywords = {accessibility, interaction proxies, runtime modification},
	pages = {6024--6037}
}

@inproceedings{lin_expectation_2012,
	address = {New York, NY, USA},
	series = {{UbiComp} '12},
	title = {Expectation and {Purpose}: {Understanding} {Users}' {Mental} {Models} of {Mobile} {App} {Privacy} {Through} {Crowdsourcing}},
	isbn = {978-1-4503-1224-0},
	shorttitle = {Expectation and {Purpose}},
	url = {http://doi.acm.org/10.1145/2370216.2370290},
	doi = {10.1145/2370216.2370290},
	abstract = {Smartphone security research has produced many useful tools to analyze the privacy-related behaviors of mobile apps. However, these automated tools cannot assess people's perceptions of whether a given action is legitimate, or how that action makes them feel with respect to privacy. For example, automated tools might detect that a blackjack game and a map app both use one's location information, but people would likely view the map's use of that data as more legitimate than the game. Our work introduces a new model for privacy, namely privacy as expectations. We report on the results of using crowdsourcing to capture users' expectations of what sensitive resources mobile apps use. We also report on a new privacy summary interface that prioritizes and highlights places where mobile apps break people's expectations. We conclude with a discussion of implications for employing crowdsourcing as a privacy evaluation technique.},
	urldate = {2017-05-09TZ},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Lin, Jialiu and Amini, Shahriyar and Hong, Jason I. and Sadeh, Norman and Lindqvist, Janne and Zhang, Joy},
	year = {2012},
	keywords = {Android permissions, crowdsourcing, mental model, mobile app, privacy as expectations, privacy summary},
	pages = {501--510}
}

@article{mcleod_factors_2011,
	title = {Factors that affect software systems development project outcomes: {A} survey of research},
	volume = {43},
	shorttitle = {Factors that affect software systems development project outcomes},
	url = {http://dl.acm.org/citation.cfm?id=1978803},
	number = {4},
	urldate = {2017-05-09TZ},
	journal = {ACM Computing Surveys (CSUR)},
	author = {McLeod, Laurie and MacDonell, Stephen G.},
	year = {2011},
	pages = {24}
}

@inproceedings{zhang2022onelabeler,
  title={OneLabeler: A Flexible System for Building Data Labeling Tools},
  author={Zhang, Yu and Wang, Yun and Zhang, Haidong and Zhu, Bin and Chen, Siming and Zhang, Dongmei},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--22},
  year={2022}
}

@article{shnarch2022label,
  title={Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours},
  author={Shnarch, Eyal and Halfon, Alon and Gera, Ariel and Danilevsky, Marina and Katsis, Yannis and Choshen, Leshem and Cooper, Martin Santillan and Epelboim, Dina and Zhang, Zheng and Wang, Dakuo and others},
  journal={arXiv preprint arXiv:2208.01483},
  year={2022}
}

@article{millerand_who_2010,
	title = {Who are the users? {Who} are the developers? {Webs} of users and developers in the development process of a technical standard},
	volume = {20},
	shorttitle = {Who are the users?},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2575.2009.00338.x/full},
	number = {2},
	urldate = {2017-05-09TZ},
	journal = {Information Systems Journal},
	author = {Millerand, Florence and Baker, Karen S.},
	year = {2010},
	pages = {137--161}
}

@inproceedings{xu2020exploring,
  title={Exploring young children's engagement in joint reading with a conversational agent},
  author={Xu, Ying and Warschauer, Mark},
  booktitle={Proceedings of the Interaction Design and Children Conference},
  pages={216--228},
  year={2020}
}

@article{flack2018effects,
  title={The effects of shared storybook reading on word learning: A meta-analysis.},
  author={Flack, Zoe M and Field, Andy P and Horst, Jessica S},
  journal={Developmental psychology},
  volume={54},
  number={7},
  pages={1334},
  year={2018},
  publisher={American Psychological Association}
}

@article{mol2008added,
  title={Added value of dialogic parent--child book readings: A meta-analysis},
  author={Mol, Suzanne E and Bus, Adriana G and De Jong, Maria T and Smeets, Daisy JH},
  journal={Early education and development},
  volume={19},
  number={1},
  pages={7--26},
  year={2008},
  publisher={Taylor \& Francis}
}

@article{mcleod_factors_2011-1,
	title = {Factors that affect software systems development project outcomes: {A} survey of research},
	volume = {43},
	shorttitle = {Factors that affect software systems development project outcomes},
	url = {http://dl.acm.org/citation.cfm?id=1978803},
	number = {4},
	urldate = {2017-05-09TZ},
	journal = {ACM Computing Surveys (CSUR)},
	author = {McLeod, Laurie and MacDonell, Stephen G.},
	year = {2011},
	pages = {24}
}

@article{gallivan_userdeveloper_2003,
	title = {The user–developer communication process: a critical case study},
	volume = {13},
	issn = {1365-2575},
	shorttitle = {The user–developer communication process},
	url = {http://onlinelibrary.wiley.com/doi/10.1046/j.1365-2575.2003.00138.x/abstract},
	doi = {10.1046/j.1365-2575.2003.00138.x},
	abstract = {Abstract.Although user participation in systems development is widely believed to have positive impacts on user acceptance, it does not guarantee success and there is still much that we do not know about how and why user participation sometimes delivers positive benefits, but not always. Much of the prior research on user participation assumes that user–developer communication will ensure that the resulting system will be designed to meet users’ needs and will be accepted by them. The nature and quality of the communication between users and developers, however, remains an understudied aspect of user participation. In this paper, we focus on the user–developer communication process. We propose a process model that delineates four stages of communication between users and software developers, and we argue that these stages must occur for user participation to lead to effective outcomes. To illustrate our model, we apply it to analyse a ‘critical case study’ of a software project that failed despite high levels of user involvement. We show that when ‘communication lapses’ occurred in several of the user–developer communication stages, developers failed to be informed regarding the underlying reasons that users avoided the system. Based on the insights from this case study, we advise researchers and practitioners how to leverage the potential benefits of user participation, rather than take them for granted.},
	language = {en},
	number = {1},
	urldate = {2017-05-09TZ},
	journal = {Information Systems Journal},
	author = {Gallivan, Michael J. and Keil, Mark},
	month = jan,
	year = {2003},
	keywords = {IT project failure, process models, software development, software project management, user participation, user–developer communication},
	pages = {37--68}
}

@book{kollock_design_1997,
	title = {Design principles for online communities},
	url = {https://mccti.hugoramos.eu/Biblioteca_(versao_antiga)/Alumni/Redes%20Sociais%20Online/Moreno,%20Jose/Kollock_Design_principles_for_online_communities.pdf},
	urldate = {2017-05-09TZ},
	publisher = {Peter Kollock},
	author = {Kollock, Peter},
	year = {1997}
}

@inproceedings{haythornthwaite_crowds_2009,
	title = {Crowds and communities: {Light} and heavyweight models of peer production},
	shorttitle = {Crowds and communities},
	url = {http://ieeexplore.ieee.org/abstract/document/4755627/},
	urldate = {2017-05-09TZ},
	booktitle = {System {Sciences}, 2009. {HICSS}'09. 42nd {Hawaii} {International} {Conference} on},
	publisher = {IEEE},
	author = {Haythornthwaite, Caroline},
	year = {2009},
	pages = {1--10}
}

@article{restivo_experimental_2012,
	title = {Experimental study of informal rewards in peer production},
	volume = {7},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0034358},
	number = {3},
	urldate = {2017-05-09TZ},
	journal = {PloS one},
	author = {Restivo, Michael and Van De Rijt, Arnout},
	year = {2012},
	pages = {e34358}
}

@article{rafaeli_online_2008,
	title = {Online motivational factors: {Incentives} for participation and contribution in {Wikipedia}},
	shorttitle = {Online motivational factors},
	url = {https://www.researchgate.net/profile/Yaron_Ariel/publication/237114593_11_Online_Motivational_Factors_Incentives_for_Participation_and_Contribution_in_Wikipedia/links/0deec52d05efdb142f000000.pdf},
	urldate = {2017-05-09TZ},
	journal = {Psychological aspects of cyberspace: Theory, research, applications},
	author = {Rafaeli, Sheizaf and Ariel, Yaron},
	year = {2008},
	pages = {243--267}
}

@inproceedings{campagna_almond:_2017,
	title = {Almond: {The} architecture of an open, crowdsourced, privacy-preserving, programmable virtual assistant},
	shorttitle = {Almond},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Campagna, Giovanni and Ramesh, Rakesh and Xu, Silei and Fischer, Michael and Lam, Monica S.},
	year = {2017},
	pages = {341--350}
}

@article{davidson_wiki_2012,
	title = {Wiki use that increases communication and collarboration motivation},
	copyright = {© 2012 Robyn Davidson},
	issn = {1832-8342},
	url = {https://digital.library.adelaide.edu.au/dspace/handle/2440/76882},
	abstract = {Communication and collaboration can be readily enabled by the use of many ICT tools. Wikis are one such platform that provides the opportunity for students to work on group projects without the barriers that arise from traditional group work. Whilst wiki use is becoming more common, its use in education is patchy and pedagogical reasoning and evaluation of such use is under explored. This paper addresses the gap in pedagogy and evaluation in the context of accounting studies. A traditional assessment task of writing an essay that involved a research and knowledge component was redesigned to enable groups to communicate and collaborate at a distance using a wiki. Through participant observation and student reflections of the group project, a wiki was found to be an effective platform to communicate and collaborate on a group project and enabled different barriers to be broken down. Wikis provide ubiquitous access to group work, organisation and version control, levels the playing field for dominant and shy students, and provides transparency for non-performers and high achievers.},
	language = {en},
	urldate = {2017-05-09TZ},
	journal = {https://www.jld.edu.au/article/view/110},
	author = {Davidson, R.},
	year = {2012}
}

@inproceedings{rietz2021cody,
  title={Cody: An AI-based system to semi-automate coding for qualitative research},
  author={Rietz, Tim and Maedche, Alexander},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2021}
}

@inproceedings{li_comprehensive_2013,
	title = {A comprehensive field study of end-user programming on mobile devices},
	doi = {10.1109/VLHCC.2013.6645242},
	abstract = {TouchDevelop represents a new programming environment that enables users to develop mobile applications directly on mobile devices. TouchDevelop has successfully drawn a huge number of end users, who have published thousands of TouchDevelop scripts online. To enhance end-user programming on mobile devices, we conduct a comprehensive field study of 17322 TouchDevelop scripts and 4275 users. Our study consists of an overall study on the characteristics of scripts (e.g., structural features, code reuse) and users (e.g., expertise), and a longitudinal study on how they evolve over time. Our study results show important characteristics of scripts such as dense external method calls, high code-reuse ratio, and also reveal interesting evolution patterns of users. The findings and implications in our study provide valuable guidelines for improving tool support or services for end users and increasing the popularity of end-user programming on mobile devices.},
	booktitle = {2013 {IEEE} {Symposium} on {Visual} {Languages} and {Human} {Centric} {Computing}},
	author = {Li, S. and Xie, T. and Tillmann, N.},
	month = sep,
	year = {2013},
	keywords = {Electromagnetic compatibility, Market research, Measurement, Programming, Programming environments, TouchDevelop scripts online, comprehensive field study, dense external method calls, end user programming, evolution patterns, high code reuse ratio, libraries, mobile applications, mobile computing, mobile devices, mobile handsets, object-oriented programming, programming environment, tool support, touch sensitive screens},
	pages = {43--50}
}

@inproceedings{li_comprehensive_2013-1,
	title = {A comprehensive field study of end-user programming on mobile devices},
	doi = {10.1109/VLHCC.2013.6645242},
	abstract = {TouchDevelop represents a new programming environment that enables users to develop mobile applications directly on mobile devices. TouchDevelop has successfully drawn a huge number of end users, who have published thousands of TouchDevelop scripts online. To enhance end-user programming on mobile devices, we conduct a comprehensive field study of 17322 TouchDevelop scripts and 4275 users. Our study consists of an overall study on the characteristics of scripts (e.g., structural features, code reuse) and users (e.g., expertise), and a longitudinal study on how they evolve over time. Our study results show important characteristics of scripts such as dense external method calls, high code-reuse ratio, and also reveal interesting evolution patterns of users. The findings and implications in our study provide valuable guidelines for improving tool support or services for end users and increasing the popularity of end-user programming on mobile devices.},
	booktitle = {2013 {IEEE} {Symposium} on {Visual} {Languages} and {Human} {Centric} {Computing}},
	author = {Li, S. and Xie, T. and Tillmann, N.},
	month = sep,
	year = {2013},
	keywords = {Electromagnetic compatibility, Market research, Measurement, Programming, Programming environments, TouchDevelop scripts online, comprehensive field study, dense external method calls, end user programming, evolution patterns, high code reuse ratio, libraries, mobile applications, mobile computing, mobile devices, mobile handsets, object-oriented programming, programming environment, tool support, touch sensitive screens},
	pages = {43--50}
}

@article{kuznetsov_motivations_2006,
	title = {Motivations of {Contributors} to {Wikipedia}},
	volume = {36},
	issn = {0095-2737},
	url = {http://doi.acm.org/10.1145/1215942.1215943},
	doi = {10.1145/1215942.1215943},
	abstract = {This paper aims to explain why people are motivated to contribute to the Wikipedia project. A comprehensive analysis of the motivations of Wikipedians is conducted using the iterative methodology developed by Batya Friedman and Peter Kahn in Value Sensitive Design and Information Systems and co-developed by Nissenbaum and Friedman in Bias in Computer Systems. The Value Sensitive Design (VSD) approach consists of three stages: Empirical Investigation, Conceptual Investigation, and Technical Investigation. During the empirical phase, motivations of the contributors to Wikipedia are identified through analysis of data from two published surveys and a pilot survey conducted at New York University. The underlying values behind these motivations are then defined in the conceptual phase of the study. Finally, a technical investigation is conducted in order to determine how features of the Wiki technology support and facilitate these values.},
	number = {2},
	urldate = {2017-05-09TZ},
	journal = {SIGCAS Comput. Soc.},
	author = {Kuznetsov, Stacey},
	month = jun,
	year = {2006},
	keywords = {Wikipedia, motivations, value sensitive design}
}

@article{wagner_wiki:_2004,
	title = {Wiki: {A} technology for conversational knowledge management and group collaboration},
	volume = {13},
	shorttitle = {Wiki},
	url = {http://aisel.aisnet.org/cgi/viewcontent.cgi?article=3238&context=cais},
	number = {1},
	urldate = {2017-05-09TZ},
	journal = {The Communications of the Association for Information Systems},
	author = {Wagner, Christian},
	year = {2004},
	pages = {58}
}

@article{kille_wikis_2006,
	title = {Wikis in the workplace: how wikis can help manage knowledge in library reference services},
	volume = {15},
	shorttitle = {Wikis in the workplace},
	url = {http://www.ischool.utexas.edu/~i385q/archive/kille_wikis_reference_services.pdf},
	number = {2},
	urldate = {2017-05-09TZ},
	journal = {Libres},
	author = {Kille, Angela},
	year = {2006}
}

@article{raman_wiki_2006,
	title = {Wiki technology as a" free" collaborative tool within an organizational setting},
	volume = {23},
	url = {http://www.tandfonline.com/doi/pdf/10.1201/1078.10580530/46352.23.4.20060901/95114.8},
	number = {4},
	urldate = {2017-05-09TZ},
	journal = {Information systems management},
	author = {Raman, Murali},
	year = {2006},
	pages = {59--66}
}

@article{segal_developing_2008,
	title = {Developing scientific software},
	volume = {25},
	url = {http://ieeexplore.ieee.org/abstract/document/4548403/},
	number = {4},
	urldate = {2017-05-09TZ},
	journal = {IEEE Software},
	author = {Segal, Judith and Morris, Chris},
	year = {2008},
	pages = {18--20}
}

@article{segal_software_2009,
	title = {Software development cultures and cooperation problems: {A} field study of the early stages of development of software for a scientific community},
	volume = {18},
	shorttitle = {Software development cultures and cooperation problems},
	url = {http://link.springer.com/article/10.1007/s10606-009-9096-9},
	number = {5-6},
	urldate = {2017-05-09TZ},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Segal, Judith},
	year = {2009},
	pages = {581}
}

@book{engestrom_learning_2014,
	title = {Learning by expanding},
	url = {https://books.google.com/books?hl=en&lr=&id=a6CTBQAAQBAJ&oi=fnd&pg=PR11&dq=Learning+by+Expanding&ots=nKsJ0vSkGz&sig=rB7SuL261-OhII3GJW0cgOgDA0k},
	urldate = {2017-04-23TZ},
	publisher = {Cambridge University Press},
	author = {Engeström, Yrjö},
	year = {2014}
}
@article{engestrom_expansive_2001,
	title = {Expansive learning at work: {Toward} an activity theoretical reconceptualization},
	volume = {14},
	shorttitle = {Expansive learning at work},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13639080020028747},
	number = {1},
	urldate = {2017-04-23TZ},
	journal = {Journal of education and work},
	author = {Engeström, Yrjö},
	year = {2001},
	pages = {133--156}
}

@article{asand_organization_2008,
	title = {The {Organization} of {End} {User} {Development} in an {Accounting} {Company}},
	copyright = {Access limited to members},
	url = {http://www.igi-global.com/chapter/organization-end-user-development-accounting/18155},
	doi = {10.4018/978-1-59904-295-4.ch007},
	abstract = {The Organization of End User Development in an Accounting Company: 10.4018/978-1-59904-295-4.ch007: The chapter presents a case study following the activities of super users and local developers during the adoption of a new business application by an},
	language = {en},
	urldate = {2017-04-23TZ},
	journal = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-59904-295-4.ch007},
	author = {Asand, Hege-Rene Hansen and Morch, Anders I.},
	year = {2008},
	pages = {102--123}
}

@article{eriksson_combining_2008,
	title = {Combining {Tailoring} and {Evolutionary} {Software} {Development} for {Rapidly} {Changing} {Business} {Systems}},
	copyright = {Access limited to members},
	url = {http://www.igi-global.com/chapter/combining-tailoring-evolutionary-software-development/18212},
	doi = {10.4018/978-1-59904-945-8.ch048},
	abstract = {Combining Tailoring and Evolutionary Software Development for Rapidly Changing Business Systems: 10.4018/978-1-59904-945-8.ch048: This article reports on a case study performed in cooperation with a telecommunication provider. The telecom business changes rapidly as new services are},
	language = {en},
	urldate = {2017-04-23TZ},
	journal = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-59904-945-8.ch048},
	author = {Eriksson, Jeanette and Dittrich, Yvonne},
	year = {2008},
	pages = {623--636}
}

@article{eriksson_combining_2007,
	title = {Combining tailoring and evolutionary software development for rapidly changing business systems},
	volume = {19},
	url = {http://search.proquest.com/openview/a9a9ef6ecd8d5054ac4891069a629f50/1?pq-origsite=gscholar&cbl=29241},
	number = {2},
	urldate = {2017-04-23TZ},
	journal = {Journal of Organizational and End User Computing},
	author = {Eriksson, Jeanette and Dittrich, Yvonne},
	year = {2007},
	pages = {47}
}

@article{erickson_social_2000,
	title = {Social {Translucence}: {An} {Approach} to {Designing} {Systems} {That} {Support} {Social} {Processes}},
	volume = {7},
	issn = {1073-0516},
	shorttitle = {Social {Translucence}},
	url = {http://doi.acm.org/10.1145/344949.345004},
	doi = {10.1145/344949.345004},
	abstract = {We are interested in desiging systems that support communication and collaboration among large groups of people over computing networks. We begin by asking what properties of the physical world support graceful human-human communication in face-to-face situations, and argue that it is possible to design digital systems that support coherent behavior by making participants and their activites visible to one another. We call such systems “socially translucent systems” and suggest that they have three characteristics—visbility, awareness, and accountability—which enable people to draw upon their experience and expertise to structure their interactions with one another. To motivate and focus our ideas we develop a vision of knowledge communities, conversationally based systems that support the creation, management and reuse of knowledge in a social context. We describe our experience in designing and deploying one layer of functionality for knowledge communities, embodied in a working system called “Barbie” and discuss research issues raised by a socially translucent approach to design.},
	number = {1},
	urldate = {2017-04-21TZ},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Erickson, Thomas and Kellogg, Wendy A.},
	month = mar,
	year = {2000},
	keywords = {CMC, CMI, CSCW, computer-mediated communication, social computing, social navigation, social visualization, visualization},
	pages = {59--83}
}

@incollection{fischer_putting_1994,
	title = {Putting the owners of problems in charge with domain-oriented design environments},
	url = {http://link.springer.com/chapter/10.1007/978-3-662-03035-6_23},
	urldate = {2017-04-21TZ},
	booktitle = {User-{Centred} {Requirements} for {Software} {Engineering} {Environments}},
	publisher = {Springer},
	author = {Fischer, Gerhard},
	year = {1994},
	pages = {297--306}
}

@book{brand_how_1995,
	title = {How buildings learn: {What} happens after they're built},
	shorttitle = {How buildings learn},
	url = {https://books.google.com/books?hl=en&lr=&id=zkgRgdVN2GIC&oi=fnd&pg=PT6&dq=How+Buildings+Learn:+What+Happens+After+They%E2%80%99re+Built.+N&ots=2iWUaByEKY&sig=z-unfaZ7sP7_vCayiG6syaPM6Q0},
	urldate = {2017-04-21TZ},
	publisher = {Penguin},
	author = {Brand, Stewart},
	year = {1995}
}

@inproceedings{wulf_lets_1999,
	address = {New York, NY, USA},
	series = {{GROUP} '99},
	title = {“{Let}'s {See} {Your} {Search}-tool!”—{Collaborative} {Use} of {Tailored} {Artifacts} in {Groupware}},
	isbn = {978-1-58113-065-2},
	url = {http://doi.acm.org/10.1145/320297.320303},
	doi = {10.1145/320297.320303},
	abstract = {Groupware applications should be tailorable to fit the requirements of dynamically evolving and differentiated fields of application. To encourage individual and collaborative tailoring activities, applications should be tailorable on different levels of complexity. A search tool has been developed which offers different levels of tailoring complexity by means of hierarchically organized component languages. Users can create alternative search tools and compound components by themselves. Search tool alternatives and compound components can also be shared among the users. When introducing this tool into an organization of the political administration, it turned out that the users had considerable problems in understanding the functioning of artifacts created by someone else. To ease cooperative tailoring activities, we have implemented features, which allow users to structure, describe, and explore shared components and search tool alternatives. Also we provided means to store and exchange examples for components' use.},
	urldate = {2017-04-13TZ},
	booktitle = {Proceedings of the {International} {ACM} {SIGGROUP} {Conference} on {Supporting} {Group} {Work}},
	publisher = {ACM},
	author = {Wulf, Volker},
	year = {1999},
	keywords = {annotation, exploration, groupware, learning, tailorability},
	pages = {50--59}
}

@article{morch_tailoring_2000,
	title = {Tailoring as collaboration: {The} mediating role of multiple representations and application units},
	volume = {9},
	shorttitle = {Tailoring as collaboration},
	url = {http://www.springerlink.com/index/MPH3XT1TR40M5523.pdf},
	number = {1},
	urldate = {2017-04-13TZ},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Mørch, Anders I. and Mehandjiev, Nikolay D.},
	year = {2000},
	pages = {75--100}
}

@article{wulf_economics_2004,
	title = {The {Economics} of {End}-user {Development}},
	volume = {47},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1015864.1015886},
	doi = {10.1145/1015864.1015886},
	abstract = {The productivity paradox raised concerns that IT investment rarely leads to productivity gains [1]. End-user development (EUD), however, may provide the answer to this concern if increased productivity can be demonstrated. Recent research has questioned the productivity paradox and substantially improved our understanding about how IT productivity may be influenced by the manner of change.},
	number = {9},
	urldate = {2017-04-13TZ},
	journal = {Commun. ACM},
	author = {Wulf, Volker and Jarke, Matthias},
	month = sep,
	year = {2004},
	pages = {41--42}
}

@incollection{fischer_meta-design:_2006,
	series = {Human-{Computer} {Interaction} {Series}},
	title = {Meta-design: {A} {Framework} for the {Future} of {End}-{User} {Development}},
	copyright = {©2006 Springer},
	isbn = {978-1-4020-4220-1 978-1-4020-5386-3},
	shorttitle = {Meta-design},
	url = {http://link.springer.com/chapter/10.1007/1-4020-5386-X_19},
	abstract = {In a world that is not predictable, improvisation, evolution, and innovation are more than a luxury: they are a necessity. The challenge of design is not a matter of getting rid of the emergent, but rather of including it and making it an opportunity for more creative and more adequate solutions to problems. Meta-design is an emerging conceptual framework aimed at defining and creating social and technical infrastructures in which new forms of collaborative design can take place. It extends the traditional notion of system design beyond the original development of a system to include a coadaptive process between users and a system, inwhich the users become co-developers or co-designers. It is grounded in the basic assumption that future uses and problems cannot be completely anticipated at design time, when a system is developed. Users, at use time, will discover mismatches between their needs and the support that an existing system can provide for them. These mismatches will lead to breakdowns that serve as potential sources of new insights, new knowledge, and new understanding. This chapter is structured in four parts: conceptual framework, environments, applications, and findings and challenges. Along the structure of the chapter, we discuss and explore the following essential components of meta-design, providing requirements, guidelines, and models for the future of end-user development: (1) the relationship of meta-design to other design methodologies; (2) the Seeding, Evolutionary Growth, Reseeding Model, a process model for large evolving design artifacts; (3) the characteristics of unself-conscious cultures of design, their strengths and their weaknesses, and the necessity for owners of problems to be empowered to engage in end-user development; (4) the possibilities created by meta-design to bring co-creation alive; and (5) the need for an integrated design space that brings together a technical infrastructure that is evolvable, for the design of learning environments and work organizations that allow end-users to become active contributors, and for the design of relational settings in which users can relate, find motivations and rewards, and accumulate social capital. Key words. co-creation, design for change, design space, design time, domain-oriented design environments, Envisionment and Discovery Collaboratory, interactive art, open systems, SER model, social capital, underdesign, unself-conscious cultures of design, use time, value-feelings.},
	language = {en},
	number = {9},
	urldate = {2017-04-13TZ},
	booktitle = {End {User} {Development}},
	publisher = {Springer Netherlands},
	author = {Fischer, Gerhard and Giaccardi, Elisa},
	editor = {Lieberman, Henry and Paternò, Fabio and Wulf, Volker},
	year = {2006},
	doi = {10.1007/1-4020-5386-X_19},
	keywords = {User Interfaces and Human Computer Interaction},
	pages = {427--457}
}

@article{fischer_meta-design:_2004,
	title = {Meta-design: {A} {Manifesto} for {End}-user {Development}},
	volume = {47},
	issn = {0001-0782},
	shorttitle = {Meta-design},
	url = {http://doi.acm.org/10.1145/1015864.1015884},
	doi = {10.1145/1015864.1015884},
	abstract = {End-user development (EUD) activities range from customization to component configuration and programming. Office software, such as the ubiquitous spreadsheet, provides customization facilities, while the growth of the Web has added impetus to end-user scripting for interactive functions in Web sites. In scientific and engineering domains, end users frequently develop complex systems with standard programming languages such as C++ and Java. However, only a minority of users adapt commercial off-the-shelf (COTS) software products. Indeed, composing systems from reusable components, such as enterprise resource planing (ERP) systems, defeats most end users who resort to expensive and scarce expert developers for implementation.},
	number = {9},
	urldate = {2017-04-13TZ},
	journal = {Commun. ACM},
	author = {Fischer, G. and Giaccardi, E. and Ye, Y. and Sutcliffe, A. G. and Mehandjiev, N.},
	month = sep,
	year = {2004},
	pages = {33--37}
}

@incollection{costabile_end-user_2006,
	series = {Human-{Computer} {Interaction} {Series}},
	title = {End-{User} {Development}: {The} {Software} {Shaping} {Workshop} {Approach}},
	copyright = {©2006 Springer},
	isbn = {978-1-4020-4220-1 978-1-4020-5386-3},
	shorttitle = {End-{User} {Development}},
	url = {http://link.springer.com/chapter/10.1007/1-4020-5386-X_9},
	abstract = {In the Information Society, end-users keep increasing very fast in number, as well as in their demand with respect to the activities they would like to perform with computer environments, without being obliged to become computer specialists. There is a great request to provide end-users with powerful and flexible environments, tailorable to the culture, skills, and needs of a very diverse end-user population. In this chapter, we discuss a framework for End-User Development and present our methodology for designing software environments that support the activities of a particular class of end-users, called domain-expert users, with the objective of making their work with the computer easier. Such environments are called Software Shaping Workshops, in analogy to artisan workshops: they provide users only with the necessary tools that allow them to accomplish their specific activities by properly shaping software artifacts without being lost in virtual space. Key words. end-user development, domain expert, user diversity, gain, co-evolution, implicit information, tacit knowledge, user notation, HCI model.},
	language = {en},
	number = {9},
	urldate = {2017-04-13TZ},
	booktitle = {End {User} {Development}},
	publisher = {Springer Netherlands},
	author = {Costabile, Maria Francesca and Fogli, Daniela and Mussio, Piero and Piccinno, Antonio},
	editor = {Lieberman, Henry and Paternò, Fabio and Wulf, Volker},
	year = {2006},
	doi = {10.1007/1-4020-5386-X_9},
	keywords = {User Interfaces and Human Computer Interaction},
	pages = {183--205}
}

@inproceedings{chintakovid_pair_2006,
	title = {Pair {Collaboration} in {End}-{User} {Debugging}},
	doi = {10.1109/VLHCC.2006.36},
	abstract = {The problem of dependability in end-user programming is an emerging area of interest. Pair collaboration in end-user software development may offer a way for end users to debug their programs more effectively. While pair programming studies - primarily of computer science students and professionals - report positive outcomes in terms of overall program quality, little is known about specific activities that pairs engage in that lead to those outcomes, or of how the previous results may pertain to end-user programmers. In this paper we analyze protocols of end-user pairs debugging spreadsheets. The results suggest that end-user pairs can achieve rich reasoning, effective planning, and systematic evaluation. Furthermore, end-user pairs provide specific types of mutual support that facilitate the accomplishment of their goals},
	booktitle = {Visual {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC}'06)},
	author = {Chintakovid, T. and Wiedenbeck, S. and Burnett, M. and Grigoreanu, V.},
	month = sep,
	year = {2006},
	keywords = {Cognition, Collaborative software, Collaborative work, Computer science, Debugging, Programming profession, Protocols, Switches, Testing, collaboration, end-user debugging, end-user programming, pair collaboration, program debugging, program quality, software engineering, team working},
	pages = {3--10}
}

@inproceedings{brandt_opportunistic_2008,
	address = {New York, NY, USA},
	series = {{WEUSE} '08},
	title = {Opportunistic {Programming}: {How} {Rapid} {Ideation} and {Prototyping} {Occur} in {Practice}},
	isbn = {978-1-60558-034-0},
	shorttitle = {Opportunistic {Programming}},
	url = {http://doi.acm.org/10.1145/1370847.1370848},
	doi = {10.1145/1370847.1370848},
	abstract = {At times, programmers work opportunistically, emphasizing speed and ease of development over code robustness and maintainability. They do this to prototype, ideate, and discover; to understand as quickly as possible what the right solution is. Despite its importance, opportunistic programming remains poorly understood when compared with traditional software engineering. Through fieldwork and a laboratory study, we observed five characteristics of opportunistic programming: Programmers build software from scratch using high-level tools, often add new functionality via copy-and-paste, iterate more rapidly than in traditional development, consider code to be impermanent, and face unique debugging challenges because their applications often comprise many languages and tools composed without upfront design. Based on these characteristics, we discuss future research on tools for debugging, code foraging and reuse, and documentation that are specifically targeted at this style of development.},
	urldate = {2017-04-13TZ},
	booktitle = {Proceedings of the 4th {International} {Workshop} on {End}-user {Software} {Engineering}},
	publisher = {ACM},
	author = {Brandt, Joel and Guo, Philip J. and Lewenstein, Joel and Klemmer, Scott R.},
	year = {2008},
	keywords = {end-user software engineering, opportunistic programming, prototyping},
	pages = {1--5}
}

@inproceedings{andersen_mutual_2009,
	title = {Mutual {Development}: {A} {Case} {Study} in {Customer}-{Initiated} {Software} {Product} {Development}},
	shorttitle = {Mutual {Development}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-00427-8_3},
	doi = {10.1007/978-3-642-00427-8_3},
	abstract = {The paper is a case study of customer-initiated software product development. We have observed and participated in system development activities in a commercial software house (company) over a period of two years. The company produces project-planning tools for the oil and gas industry, and relies on interaction with customers for further development of its products. Our main research question is how customers and professional developers engage in mutual development mediated by shared software tools (products and support systems). We have used interviews with developers and customers as our main source of data, and identified the activities (from use to development) where customers have contributed to development. We analyze our findings in terms of co-configuration, meta-design and modding in order to name and compare the various stages of development (adaptation, generalization, improvement request, specialization, and tailoring).},
	language = {en},
	urldate = {2017-04-13TZ},
	booktitle = {End-{User} {Development}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Andersen, Renate and Mørch, Anders I.},
	month = mar,
	year = {2009},
	pages = {31--49}
}

@misc{blackwell_logical_2010,
	title = {A {Logical} {Mind}, not a {Programming} {Mind}: {Psychology} of a {Professional} {End}-{User}},
	shorttitle = {A {Logical} {Mind}, not a {Programming} {Mind}},
	author = {Blackwell, Alan and Morrison, Cecily and Morrison, Cecily and Morrison, Cecily},
	year = {2010}
}

@article{wagner_exploring_2010,
	title = {Exploring the {Enterprise} {Value} of {Wikis} {Through} {Media} {Choice} {Theories}},
	volume = {1},
	issn = {1947-8208},
	url = {http://dx.doi.org/10.4018/jkss.2010040102},
	doi = {10.4018/jkss.2010040102},
	abstract = {Wikis are quickly emerging as a new corporate medium for communication and collaboration. They allow dispersed groups of collaborators to asynchronously engage in persistent conversations, the result of which is stored on a common server as a single, shared truth. To gauge the enterprise value of wikis, the authors draw on Media Choice Theories MCTs as an evaluation framework. MCTs reveal core capabilities of communication media and their fit with the communication task. Based on the evaluation, the authors argue that wikis are equivalent or superior to existing asynchronous communication media in key characteristics. Additionally argued is the notion that wiki technology challenges some of the held beliefs of existing media choice theories, as wikis introduce media characteristics not previously envisioned. The authors thus predict a promising future for wiki use in enterprises.},
	number = {2},
	urldate = {2017-04-13TZ},
	journal = {Int. J. Knowl. Syst. Sci.},
	author = {Wagner, Christian and Schroeder, Andreas and Wong, Wing and Shum, Anna},
	month = apr,
	year = {2010},
	keywords = {Common Ground, Media Choice Theories, Media Richness, Media Synchronicity, wiki},
	pages = {15--26}
}

@inproceedings{ur_trigger-action_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {Trigger-{Action} {Programming} in the {Wild}: {An} {Analysis} of 200,000 {IFTTT} {Recipes}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Trigger-{Action} {Programming} in the {Wild}},
	url = {http://doi.acm.org/10.1145/2858036.2858556},
	doi = {10.1145/2858036.2858556},
	abstract = {While researchers have long investigated end-user programming using a trigger-action (if-then) model, the website IFTTT is among the first instances of this paradigm being used on a large scale. To understand what IFTTT users are creating, we scraped the 224,590 programs shared publicly on IFTTT as of September 2015 and are releasing this dataset to spur future research. We characterize aspects of these programs and the IFTTT ecosystem over time. We find a large number of users are crafting a diverse set of end-user programs---over 100,000 different users have shared programs. These programs represent a very broad array of connections that appear to fill gaps in functionality, yet users often duplicate others' programs.},
	urldate = {2017-04-13TZ},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ur, Blase and Pak Yong Ho, Melwyn and Brawner, Stephen and Lee, Jiyun and Mennicken, Sarah and Picard, Noah and Schulze, Diane and Littman, Michael L.},
	year = {2016},
	keywords = {end-user composition, end-user programming, ifttt, internet of things (iot), trigger-action programming},
	pages = {3227--3231}
}

@inproceedings{wiltse_playbyplay:_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {{PlayByPlay}: {Collaborative} {Web} {Browsing} for {Desktop} and {Mobile} {Devices}},
	isbn = {978-1-60558-246-7},
	shorttitle = {{PlayByPlay}},
	url = {http://doi.acm.org/10.1145/1518701.1518975},
	doi = {10.1145/1518701.1518975},
	abstract = {Collaborative web browsing tasks occur frequently, such as one user showing another how to use a web site, several users working together on a search task, or even one user sending an interesting link to another user. Unfortunately, tools for browsing the web are commonly designed for a single user. PlayByPlay is a general purpose web collaboration tool that uses the communication model of instant messaging to support a variety of collaborative browsing tasks. PlayByPlay also supports collaborative browsing between mobile and desktop users, which we believe is useful for on-the-go scenarios. We conducted user studies of the desktop and mobile versions of PlayByPlay and found the system to be usable and effective.},
	urldate = {2017-04-13TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wiltse, Heather and Nichols, Jeffrey},
	year = {2009},
	keywords = {CoScripter, co-browsing, collaboration, collaborative browsing, design, mobile, web},
	pages = {1781--1790}
}

@inproceedings{admire_code_2014,
	title = {Code you can use: {Searching} for web automation scripts based on reusability},
	shorttitle = {Code you can use},
	doi = {10.1109/VLHCC.2014.6883027},
	abstract = {Web scripting enables users to automate interactions with websites. Online open source repositories provide scripts available for reuse. Yet just because these scripts are open source does not mean they are all reusable: many are specialized and irrelevant to most peoples' needs, while others are hard to understand or learn from. Repositories offer keyword-based search engines to find scripts relevant to specialized needs, but they lack any means for filtering search results according to reusability. To address this shortcoming, we present an approach for creating a model to automatically estimate the reusability of web automation scripts. To test this approach, we prototyped a search engine that uses these reusability estimates to sort one particular kind of web automation scripts, CoScripter macros, according to reusability. An empirical evaluation confirmed that the system's reusability estimates are significantly correlated with user perceptions of macro reusability, thus implying that our approach presents a viable means for helping end-user programmers to find reusable web automation scripts.},
	booktitle = {2014 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Admire, J. and Zawwad, A. A. and Almorebah, A. and Karve, S. and Scaffidi, C.},
	month = jul,
	year = {2014},
	keywords = {CoScripter macros, Computational modeling, Linear regression, Programming, Radio access networks, Web automation scripts searching, Web design, Web scripting, Web sites, Websites interactions, authoring languages, automation, code, end-user programmers, end-user programming, filtering, keyword-based search engines, macro reusability, online open source repositories, open source scripts, reuse, scripting, search engines, software reusability, source code (software), system reusability, user perceptions},
	pages = {81--88}
}

@inproceedings{scaffidi_predicting_2009,
	title = {Predicting reuse of end-user web macro scripts},
	doi = {10.1109/VLHCC.2009.5295290},
	abstract = {Repositories of code written by end-user programmers are beginning to emerge, but when a piece of code is new or nobody has yet reused it, then current repositories provide users with no information about whether that code might be appropriate for reuse. Addressing this problem requires predicting reusability based on information that exists when a script is created. To provide such a model for web macro scripts, we identified script traits that might plausibly predict reuse, then used IBM CoScripter repository logs to statistically test how well each corresponded to reuse. We then built a machine learning model that combines the useful traits and evaluated how well it can predict four different types of reuse that we saw in the repository logs. Our model was able to predict reuse from a surprisingly small set of traits. It is simple enough to be explained in only 6-11 rules, making it potentially viable for integration in repository search engines for end-user programmers.},
	booktitle = {2009 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Scaffidi, C. and Bogart, C. and Burnett, M. and Cypher, A. and Myers, B. and Shaw, M.},
	month = sep,
	year = {2009},
	keywords = {Counting circuits, Databases, Displays, Internet, Predictive models, Programming profession, Runtime, Testing, User interfaces, Web macro scripts, code repositories, end-user programming, machine learning, personal computing, search engines, software reusability},
	pages = {93--100}
}

@article{sampaio_study_nodate,
	title = {A {Study} of {Users} {Cooperation} in {CoScripter}},
	url = {http://sites.google.com/site/chieup09/workshop-submissions/Sampaio.pdf},
	urldate = {2017-04-13TZ},
	author = {Sampaio, Andréia L. and Barbosa, Simone DJ and de Souza, Clarisse S. and de Souza, Críston P.}
}

@inproceedings{scaffidi_characterizing_2008,
	address = {New York, NY, USA},
	series = {{RSSE} '08},
	title = {Characterizing {Reusability} of {End}-user {Web} {Macro} {Scripts}},
	isbn = {978-1-60558-228-3},
	url = {http://doi.acm.org/10.1145/1454247.1454252},
	doi = {10.1145/1454247.1454252},
	urldate = {2017-04-13TZ},
	booktitle = {Proceedings of the 2008 {International} {Workshop} on {Recommendation} {Systems} for {Software} {Engineering}},
	publisher = {ACM},
	author = {Scaffidi, C. and Bogart, C. and Burnett, M. and Cypher, A. and Myers, B. and Shaw, Mary},
	year = {2008},
	pages = {1:1--1:1}
}

@inproceedings{bogart_end-user_2008,
	title = {End-user programming in the wild: {A} field study of {CoScripter} scripts},
	shorttitle = {End-user programming in the wild},
	doi = {10.1109/VLHCC.2008.4639056},
	abstract = {Although a new class of languages has emerged to enable end users to create their own Web applications, little is known about how end-user programmers actually use such languages in the real world. In this paper, we report a field study on over 1400 scripts collected from the Internet which were created by early adopters of CoScripter, a Web macro programming-by-demonstration language. We contrast these Internet scripts with those written by users inside IBM, and describe script usage and re-usage patterns, features used, and users' clever workarounds for features not present in the language. The results show how users grapple with such programming notions as repetition, generalization, and reuse, sometimes inventing their own devices for these. Finally, we discuss the many scripts we found with social implications, whose purposes were to circumvent intended rules, regulations, and usage norm assumptions of a number of Web sites.},
	booktitle = {2008 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}},
	author = {Bogart, C. and Burnett, M. and Cypher, A. and Scaffidi, C.},
	month = sep,
	year = {2008},
	keywords = {Automatic programming, CoScripter scripts, Credit cards, Internet, Internet scripts, Navigation, Programming environments, Programming profession, Web macro programming-by-demonstration language, Web sites, end-user programming, programming notions, web applications},
	pages = {39--46}
}

@inproceedings{li_heres_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {Here's {What} {I} {Did}: {Sharing} and {Reusing} {Web} {Activity} with {ActionShot}},
	isbn = {978-1-60558-929-9},
	shorttitle = {Here's {What} {I} {Did}},
	url = {http://doi.acm.org/10.1145/1753326.1753432},
	doi = {10.1145/1753326.1753432},
	abstract = {ActionShot is an integrated web browser tool that creates a fine-grained history of users' browsing activities by continually recording their browsing actions at the level of interactions, such as button clicks and entries into form fields. ActionShot provides interfaces to facilitate browsing and searching through this history, sharing portions of the history through established social networking tools such as Facebook, and creating scripts that can be used to repeat previous interactions at a later time. ActionShot can also create short textual summaries for sequences of interactions. In this paper, we describe the ActionShot and our initial explorations of the tool through field deployments within our organization and a lab study. Overall, we found that ActionShot's history features provide value beyond typical browser history interfaces.},
	urldate = {2017-04-13TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Li, Ian and Nichols, Jeffrey and Lau, Tessa and Drews, Clemens and Cypher, Allen},
	year = {2010},
	keywords = {ActionShot, CoScripter, reuse, sharing, social networking, web browser history},
	pages = {723--732}
}

@inproceedings{lee_towards_2017,
	address = {New York, NY, USA},
	series = {{IUI} '17},
	title = {Towards {Understanding} {Human} {Mistakes} of {Programming} by {Example}: {An} {Online} {User} {Study}},
	isbn = {978-1-4503-4348-0},
	shorttitle = {Towards {Understanding} {Human} {Mistakes} of {Programming} by {Example}},
	url = {http://doi.acm.org/10.1145/3025171.3025203},
	doi = {10.1145/3025171.3025203},
	abstract = {Programming-by-Example (PBE) enables users to create programs without writing a line of code. However, there is little research on people's ability to accomplish complex tasks by providing examples, which is the key to successful PBE solutions. This paper presents an online user study, which reports observations on how well people decompose complex tasks, and disambiguate sub-tasks. Our findings suggest that disambiguation and decomposition are difficult for inexperienced users. We identify seven types of mistakes made, and suggest new opportunities for actionable feedback based on unsuccessful examples, with design implications for future PBE systems.},
	urldate = {2017-03-21TZ},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Lee, Tak Yeon and Dugan, Casey and Bederson, Benjamin B.},
	year = {2017},
	keywords = {programming-by-example, user study},
	pages = {257--261}
}

@inproceedings{kubitza_towards_2015,
	title = {Towards a {Toolkit} for the {Rapid} {Creation} of {Smart} {Environments}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-18425-8_21},
	doi = {10.1007/978-3-319-18425-8_21},
	abstract = {With the rise of rapid physical prototyping tools such as Arduino it has become very easy for designers, makers and developers to build smart devices, simple installations or other single device solutions. However, as soon as a room, floor or building-wide (prototype-) installation should be build consisting of various types of devices that need to communicate, the effort for building these environments still remains extremely high. A lot of this is due to three factors: programming for different platforms, bridging different communication technologies, and physically connecting devices to network and electricity. In this paper we present a concept that drastically reduces this efforts. Thus, designers and developers can focus more on the implementation of the behaviour of interactive environments. We have implemented this concept as a toolkit for on-site setups that allows to easily mash-up heterogeneous sets of devices using a common scripting language and a web-based IDE. We report from interactive installations in office and museum environments that have been realized based on this platform and we point towards new ways of programming environments.},
	language = {en},
	urldate = {2017-03-19TZ},
	booktitle = {End-{User} {Development}},
	publisher = {Springer, Cham},
	author = {Kubitza, Thomas and Schmidt, Albrecht},
	month = may,
	year = {2015},
	pages = {230--235}
}

@inproceedings{danado_puzzle:_2012,
	title = {Puzzle: {A} {Visual}-{Based} {Environment} for {End} {User} {Development} in {Touch}-{Based} {Mobile} {Phones}},
	shorttitle = {Puzzle},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-34347-6_12},
	doi = {10.1007/978-3-642-34347-6_12},
	abstract = {Despite the widespread usage of mobile devices there is a lack of environments able to allow end users to create applications directly in such devices. In this paper, we present the Puzzle framework, which supports a visual environment for opportunistically creating mobile applications in touch-based mobile phones. The user interface is designed to be usable for mobile users that do not use programming languages in their daily work as well as to motivate end users to playfully experiment and create applications. In particular, we report on its user interface, framework and evaluation.},
	language = {en},
	urldate = {2017-03-19TZ},
	booktitle = {Human-{Centered} {Software} {Engineering}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Danado, Jose and Paternò, Fabio},
	month = oct,
	year = {2012},
	pages = {199--216}
}

@misc{noauthor_research_nodate,
	title = {Research – {Toby} {Jia}-{Jun} {Li}},
	url = {http://www.toby.li/research/},
	urldate = {2017-03-18TZ}
}

@article{coutaz_first-person_2016,
	title = {A {First}-{Person} {Experience} with {End}-{User} {Development} for {Smart} {Homes}},
	volume = {15},
	issn = {1536-1268},
	doi = {10.1109/MPRV.2016.24},
	abstract = {The authors present their "lived-with" experience with an end-user development (EUD) prototype deployed in their home and show how the results overlap and complement findings from more traditional approaches to the study of EUD for the home. This article is part of a special issue on domestic pervasive computing.},
	number = {2},
	journal = {IEEE Pervasive Computing},
	author = {Coutaz, J. and Crowley, J. L.},
	month = apr,
	year = {2016},
	keywords = {Big data, Consumer electronics, Data analysis, EUD prototype, Internet of Things, Internet/Web technologies, Smart devices, User centered design, User interfaces, big data, domestic pervasive computing, end-user development, first-person experience, home computing, pervasive computing, pervasive domestic computing, smart home systems and services, smart homes, ubiquitous computing},
	pages = {26--39}
}

@inproceedings{matejka_patina:_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {Patina: {Dynamic} {Heatmaps} for {Visualizing} {Application} {Usage}},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Patina},
	url = {http://doi.acm.org/10.1145/2470654.2466442},
	doi = {10.1145/2470654.2466442},
	abstract = {We present Patina, an application independent system for collecting and visualizing software application usage data. Patina requires no instrumentation of the target application, all data is collected through standard window metrics and accessibility APIs. The primary visualization is a dynamic heatmap overlay which adapts to match the content, location, and shape of the user interface controls visible in the active application. We discuss a set of design guidelines for the Patina system, describe our implementation of the system, and report on an initial evaluation based on a short-term deployment of the system.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Matejka, Justin and Grossman, Tovi and Fitzmaurice, George},
	year = {2013},
	keywords = {social learning, visualization},
	pages = {3227--3236}
}



@inproceedings{huang_asdroid:_2014,
	address = {New York, NY, USA},
	series = {{ICSE} 2014},
	title = {{AsDroid}: {Detecting} {Stealthy} {Behaviors} in {Android} {Applications} by {User} {Interface} and {Program} {Behavior} {Contradiction}},
	isbn = {978-1-4503-2756-5},
	shorttitle = {{AsDroid}},
	url = {http://doi.acm.org/10.1145/2568225.2568301},
	doi = {10.1145/2568225.2568301},
	abstract = {Android smartphones are becoming increasingly popular. The open nature of Android allows users to install miscellaneous applications, including the malicious ones, from third-party marketplaces without rigorous sanity checks. A large portion of existing malwares perform stealthy operations such as sending short messages, making phone calls and HTTP connections, and installing additional malicious components. In this paper, we propose a novel technique to detect such stealthy behavior. We model stealthy behavior as the program behavior that mismatches with user interface, which denotes the user's expectation of program behavior. We use static program analysis to attribute a top level function that is usually a user interaction function with the behavior it performs. Then we analyze the text extracted from the user interface component associated with the top level function. Semantic mismatch of the two indicates stealthy behavior. To evaluate AsDroid, we download a pool of 182 apps that are potentially problematic by looking at their permissions. Among the 182 apps, AsDroid reports stealthy behaviors in 113 apps, with 28 false positives and 11 false negatives.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Huang, Jianjun and Zhang, Xiangyu and Tan, Lin and Wang, Peng and Liang, Bin},
	year = {2014},
	keywords = {Android, Program Behavior Contradiction, Stealthy Behaviors, user interface},
	pages = {1036--1046}
}

@inproceedings{yang_appintent:_2013,
	address = {New York, NY, USA},
	series = {{CCS} '13},
	title = {{AppIntent}: {Analyzing} {Sensitive} {Data} {Transmission} in {Android} for {Privacy} {Leakage} {Detection}},
	isbn = {978-1-4503-2477-9},
	shorttitle = {{AppIntent}},
	url = {http://doi.acm.org/10.1145/2508859.2516676},
	doi = {10.1145/2508859.2516676},
	abstract = {Android phones often carry personal information, attracting malicious developers to embed code in Android applications to steal sensitive data. With known techniques in the literature, one may easily determine if sensitive data is being transmitted out of an Android phone. However, transmission of sensitive data in itself does not necessarily indicate privacy leakage; a better indicator may be whether the transmission is by user intention or not. When transmission is not intended by the user, it is more likely a privacy leakage. The problem is how to determine if transmission is user intended. As a first solution in this space, we present a new analysis framework called AppIntent. For each data transmission, AppIntent can efficiently provide a sequence of GUI manipulations corresponding to the sequence of events that lead to the data transmission, thus helping an analyst to determine if the data transmission is user intended or not. The basic idea is to use symbolic execution to generate the aforementioned event sequence, but straightforward symbolic execution proves to be too time-consuming to be practical. A major innovation in AppIntent is to leverage the unique Android execution model to reduce the search space without sacrificing code coverage. We also present an evaluation of AppIntent with a set of 750 malicious apps, as well as 1,000 top free apps from Google Play. The results show that AppIntent can effectively help separate the apps that truly leak user privacy from those that do not.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \& {Communications} {Security}},
	publisher = {ACM},
	author = {Yang, Zhemin and Yang, Min and Zhang, Yuan and Gu, Guofei and Ning, Peng and Wang, X. Sean},
	year = {2013},
	keywords = {android security, privacy leakage detection, symbolic execution},
	pages = {1043--1054}
}

@misc{noauthor_uipicker:_nodate,
	title = {{UIPicker}: {User}-{Input} {Privacy} {Identification} in {Mobile} {Applications} {\textbar} {USENIX}},
	url = {https://www.usenix.org/node/190950},
	urldate = {2017-03-07TZ}
}

@misc{noauthor_supor:_nodate,
	title = {{SUPOR}: {Precise} and {Scalable} {Sensitive} {User} {Input} {Detection} for {Android} {Apps} {\textbar} {USENIX}},
	url = {https://www.usenix.org/node/190948},
	urldate = {2017-03-07TZ}
}

@inproceedings{li_peruim:_2016,
	address = {New York, NY, USA},
	series = {{UbiComp} '16},
	title = {{PERUIM}: {Understanding} {Mobile} {Application} {Privacy} with permission-{UI} {Mapping}},
	isbn = {978-1-4503-4461-6},
	shorttitle = {{PERUIM}},
	url = {http://doi.acm.org/10.1145/2971648.2971693},
	doi = {10.1145/2971648.2971693},
	abstract = {Current mobile operating systems such as Android employ the permission-based access control mechanism, but it is difficult for users to understand how and why the permissions are used within a particular application. This paper introduces permission-UI mapping as an easy-to-understand representation to illustrate how permissions are used by different UI components within a given application. Connecting UI components to permissions helps users to understand the purpose of permission requests and also makes it possible to illustrate permission requests in a fine-grained manner. We propose PERUIM to extract the permission-UI mapping from an application based on both dynamic and static analysis, and represent the analysis results with a graphical representation. Experiments on popular mobile applications demonstrate the accuracy and applicability of the proposed approach.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Li, Yuanchun and Guo, Yao and Chen, Xiangqun},
	year = {2016},
	keywords = {Android, functionality, mobile applications, permission, user interface (UI)},
	pages = {682--693}
}

@inproceedings{li_peruim:_2016-1,
	address = {New York, NY, USA},
	series = {{UbiComp} '16},
	title = {{PERUIM}: {Understanding} {Mobile} {Application} {Privacy} with permission-{UI} {Mapping}},
	isbn = {978-1-4503-4461-6},
	shorttitle = {{PERUIM}},
	url = {http://doi.acm.org/10.1145/2971648.2971693},
	doi = {10.1145/2971648.2971693},
	abstract = {Current mobile operating systems such as Android employ the permission-based access control mechanism, but it is difficult for users to understand how and why the permissions are used within a particular application. This paper introduces permission-UI mapping as an easy-to-understand representation to illustrate how permissions are used by different UI components within a given application. Connecting UI components to permissions helps users to understand the purpose of permission requests and also makes it possible to illustrate permission requests in a fine-grained manner. We propose PERUIM to extract the permission-UI mapping from an application based on both dynamic and static analysis, and represent the analysis results with a graphical representation. Experiments on popular mobile applications demonstrate the accuracy and applicability of the proposed approach.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Li, Yuanchun and Guo, Yao and Chen, Xiangqun},
	year = {2016},
	keywords = {Android, functionality, mobile applications, permission, user interface (UI)},
	pages = {682--693}
}

@misc{noauthor_see_nodate,
	title = {See info about what's on your screen - {Android} - {Search} {Help}},
	url = {https://support.google.com/websearch/answer/6304517?co=GENIE.Platform%3DAndroid&hl=en},
	urldate = {2017-03-07TZ}
}

@inproceedings{kuznetsov_checking_2016,
	address = {New York, NY, USA},
	series = {{WAMA} 2016},
	title = {Checking {App} {User} {Interfaces} {Against} {App} {Descriptions}},
	isbn = {978-1-4503-4398-5},
	url = {http://doi.acm.org/10.1145/2993259.2993265},
	doi = {10.1145/2993259.2993265},
	abstract = {Does the advertised behavior of apps correlate with what a user sees on a screen? In this paper, we introduce a technique to statically extract the text from the user interface definitions of an Android app. We use this technique to compare the natural language topics of an app’s user interface against the topics from its app store description. A mismatch indicates that some feature is exposed by the user interface, but is not present in the description, or vice versa. The popular Twitter app, for instance, spots UI elements that al- low to make purchases; however, this feature is not mentioned in its description. Likewise, we identified a number of apps whose user interface asks users to access or supply sensitive data; but this “feature” is not mentioned in the description. In the long run, analyzing user interface topics and comparing them against external descriptions opens the way for checking general mismatches between requirements and implementation.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the {International} {Workshop} on {App} {Market} {Analytics}},
	publisher = {ACM},
	author = {Kuznetsov, Konstantin and Avdiienko, Vitalii and Gorla, Alessandra and Zeller, Andreas},
	year = {2016},
	keywords = {Android, App mining, Topic models, UI Anomalies},
	pages = {1--7}
}

@inproceedings{dixon_prefab_2014,
	address = {New York, NY, USA},
	series = {{UIST} '14},
	title = {Prefab {Layers} and {Prefab} {Annotations}: {Extensible} {Pixel}-based {Interpretation} of {Graphical} {Interfaces}},
	isbn = {978-1-4503-3069-5},
	shorttitle = {Prefab {Layers} and {Prefab} {Annotations}},
	url = {http://doi.acm.org/10.1145/2642918.2647412},
	doi = {10.1145/2642918.2647412},
	abstract = {Pixel-based methods have the potential to fundamentally change how we build graphical interfaces, but remain difficult to implement. We introduce a new toolkit for pixel based enhancements, focused on two areas of support. Prefab Layers helps developers write interpretation logic that can be composed, reused, and shared to manage the multi-faceted nature of pixel-based interpretation. Prefab Annotations supports robustly annotating interface elements with metadata needed to enable runtime enhancements. Together, these help developers overcome subtle but critical dependencies between code and data. We validate our toolkit with (1) demonstrative applications and (2) a lab study that compares how developers build an enhancement using our toolkit versus state of the art methods. Our toolkit addresses core challenges faced by developers when building pixel based enhancements, potentially opening up pixel based systems to broader adoption.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 27th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Dixon, Morgan and Nied, Alexander and Fogarty, James},
	year = {2014},
	keywords = {annotations, layers, pixel-based reverse engineering, prefab},
	pages = {221--230}
}

@inproceedings{dixon_prefab:_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {Prefab: {Implementing} {Advanced} {Behaviors} {Using} {Pixel}-based {Reverse} {Engineering} of {Interface} {Structure}},
	isbn = {978-1-60558-929-9},
	shorttitle = {Prefab},
	url = {http://doi.acm.org/10.1145/1753326.1753554},
	doi = {10.1145/1753326.1753554},
	abstract = {Current chasms between applications implemented with different user interface toolkits make it difficult to implement and explore potentially important interaction techniques in new and existing applications, limiting the progress and impact of human-computer interaction research. We examine an approach based in the single most common characteristic of all graphical user interface toolkits, that they ultimately paint pixels to a display. We present Prefab, a system for implementing advanced behaviors through the reverse engineering of the pixels in graphical interfaces. Informed by how user interface toolkits paint interfaces, Prefab features a separation of the modeling of widget layout from the recognition of widget appearance. We validate Prefab in implementations of three applications: target-aware pointing techniques, Phosphor transitions, and Side Views parameter spectrums. Working only from pixels, we demonstrate a single implementation of these enhancements in complex existing applications created in different user interface toolkits running on different windowing systems.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Dixon, Morgan and Fogarty, James},
	year = {2010},
	keywords = {pixel-based reverse engineering, prefab, user interface toolkits},
	pages = {1525--1534}
}

@inproceedings{dixon_content_2011,
	address = {New York, NY, USA},
	series = {{CHI} '11},
	title = {Content and {Hierarchy} in {Pixel}-based {Methods} for {Reverse} {Engineering} {Interface} {Structure}},
	isbn = {978-1-4503-0228-9},
	url = {http://doi.acm.org/10.1145/1978942.1979086},
	doi = {10.1145/1978942.1979086},
	abstract = {The rigidity and fragmentation of GUI toolkits are fundamentally limiting the progress and impact of interaction research. Pixel-based methods offer unique potential for addressing these challenges independent of the implementation of any particular interface or toolkit. This work builds upon Prefab, which enables the modification of existing interfaces. We present new methods for hierarchical models of complex widgets, real-time interpretation of interface content, and real-time interpretation of content and hierarchy throughout an entire interface. We validate our new methods through implementations of four applications: stencil-based tutorials, ephemeral adaptation, interface translation, and end-user interface customization. We demonstrate these enhancements in complex existing applications created from different user interface toolkits running on different operating systems.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Dixon, Morgan and Leventhal, Daniel and Fogarty, James},
	year = {2011},
	keywords = {content, hierarchy, pixel-based reverse engineering, prefab},
	pages = {969--978}
}

@inproceedings{wang_evertutor:_2014,
	address = {New York, NY, USA},
	series = {{CHI} '14},
	title = {{EverTutor}: {Automatically} {Creating} {Interactive} {Guided} {Tutorials} on {Smartphones} by {User} {Demonstration}},
	isbn = {978-1-4503-2473-1},
	shorttitle = {{EverTutor}},
	url = {http://doi.acm.org/10.1145/2556288.2557407},
	doi = {10.1145/2556288.2557407},
	abstract = {We present EverTutor, a system that automatically generates interactive tutorials on smartphone from user demonstration. For tutorial authors, it simplifies the tutorial creation. For tutorial users, it provides contextual step-by-step guidance and avoids the frequent context switching between tutorials and users' primary tasks. In order to generate the tutorials automatically, EverTutor records low-level touch events to detect gestures and identify on-screen targets. When a tutorial is browsed, the system uses vision-based techniques to locate the target regions and overlays the corresponding input prompt contextually. It also identifies the correctness of users' interaction to guide the users step by step. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, and we compared EverTutor's interactive tutorials to static and video ones. Study results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials. Also, when using the tutorials, the task completion time for interactive tutorials were 3-6 times faster than static and video tutorials regardless of age group. In terms of user preference, 83\% of the users chose interactive type as the preferred tutorial type and rated it easiest to follow and easiest to understand.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 32Nd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wang, Cheng-Yao and Chu, Wei-Chen and Chen, Hou-Ren and Hsu, Chun-Yen and Chen, Mike Y.},
	year = {2014},
	keywords = {contextual help, smartphone, touchscreen gesture, tutorials},
	pages = {4027--4036}
}

@inproceedings{yeh_creating_2011,
	address = {New York, NY, USA},
	series = {{UIST} '11},
	title = {Creating {Contextual} {Help} for {GUIs} {Using} {Screenshots}},
	isbn = {978-1-4503-0716-1},
	url = {http://doi.acm.org/10.1145/2047196.2047214},
	doi = {10.1145/2047196.2047214},
	abstract = {Contextual help is effective for learning how to use GUIs by showing instructions and highlights on the actual interface rather than in a separate viewer. However, end-users and third-party tech support typically cannot create contextual help to assist other users because it requires programming skill and source code access. We present a creation tool for contextual help that allows users to apply common computer skills-taking screenshots and writing simple scripts. We perform pixel analysis on screenshots to make this tool applicable to a wide range of applications and platforms without source code access. We evaluated the tool's usability with three groups of participants: developers, in-structors, and tech support. We further validated the applicability of our tool with 60 real tasks supported by the tech support of a university campus.},
	urldate = {2017-03-07TZ},
	booktitle = {Proceedings of the 24th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Yeh, Tom and Chang, Tsung-Hsiang and Xie, Bo and Walsh, Greg and Watkins, Ivan and Wongsuphasawat, Krist and Huang, Man and Davis, Larry S. and Bederson, Benjamin B.},
	year = {2011},
	keywords = {contextual help, help, pixel analysis},
	pages = {145--154}
}

@inproceedings{wachenfeld_recognition_2006,
	title = {Recognition of {Screen}-{Rendered} {Text}},
	volume = {2},
	doi = {10.1109/ICPR.2006.974},
	abstract = {The recognition of screen-rendered text is to our knowledge a yet unaddressed task. It has to be performed e.g. by translation tools which allow users to click on any text on the screen and give a translation. This often requires to capture a screenshot and to perform optical character recognition which is very challenging due to very small and smoothed fonts. This paper presents a method capable of recognizing smoothed and non-smoothed screen-rendered text of very small size which also works for colored fonts on inhomogeneous backgrounds},
	booktitle = {18th {International} {Conference} on {Pattern} {Recognition} ({ICPR}'06)},
	author = {Wachenfeld, S. and Klein, H. U. and Jiang, Xiaoyi},
	year = {2006},
	keywords = {Application software, Automatic testing, Computer science, Mathematics, Operating Systems, Optical character recognition software, Rendering (computer graphics), Text recognition, character recognition, graphical user interfaces, optical character recognition, screen-rendered text recognition, screenshot capturing, translation tools},
	pages = {1086--1089}
}

@inproceedings{alharbi_collect_2015,
	address = {New York, NY, USA},
	series = {{MobileHCI} '15},
	title = {Collect, {Decompile}, {Extract}, {Stats}, and {Diff}: {Mining} {Design} {Pattern} {Changes} in {Android} {Apps}},
	isbn = {978-1-4503-3652-9},
	shorttitle = {Collect, {Decompile}, {Extract}, {Stats}, and {Diff}},
	url = {http://doi.acm.org/10.1145/2785830.2785892},
	doi = {10.1145/2785830.2785892},
	abstract = {Mobile user interface design patterns have been widely used across different mobile platforms. UI design patterns have evolved and changed significantly as new trends emerge and fade at different times. This paper presents a data-mining approach to analyzing design pattern changes in Android apps. Over a period of 18 months, we tracked 24,436 apps and collected their versions. In total, our sample consists of 56,349 unique app versions, more than 5 million source files, and more than 25 million UI elements. We developed a dedicated infrastructure based on modern big data technologies to support our differential analyses regarding design pattern changes. Some highlights of our findings include a) some apps would switch to a design pattern even after it was deprecated, b) the adoption rate of newly introduced design patterns (e.g., Fragment) is relatively low, c) some apps would update their listing details to reflect changes in design patterns.},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Alharbi, Khalid and Yeh, Tom},
	year = {2015},
	keywords = {Android, UI, analysis, apps, design, pattern},
	pages = {515--524}
}

@article{vasalou2020designing,
  title={Designing for oral storytelling practices at home: A parental perspective},
  author={Vasalou, Asimina and Kalantari, Sara and Kucirkova, Natalia and Vezzoli, Yvonne},
  journal={International Journal of Child-Computer Interaction},
  volume={26},
  pages={100214},
  year={2020},
  publisher={Elsevier}
}

@article{frude2011family,
  title={Family storytelling and the attachment relationship},
  author={Frude, Neil and Killick, Steve},
  journal={Psychodynamic Practice},
  volume={17},
  number={4},
  pages={441--455},
  year={2011},
  publisher={Taylor \& Francis}
}

@inbook{wang_designing_2021,
author = {Wang, Dakuo and Maes, Pattie and Ren, Xiangshi and Shneiderman, Ben and Shi, Yuanchun and Wang, Qianying},
title = {Designing AI to Work WITH or FOR People?},
year = {2021},
isbn = {9781450380959},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450394},
abstract = { Artificial Intelligence (AI) can refer to the machine learning algorithms and the
automation applications built on top of these algorithms. Human-computer interaction
(HCI) researchers have studied these AI applications and suggested various Human-Centered
AI (HCAI) principles for an explainable, safe, reliable, and trustworthy interaction
experience. While some designers believe that computers should be supertools and active
appliances, others believe that these latest AI systems can be collaborators. With
today’s AI algorithm breakthroughs, in this panel we ask whether the supertool or
the collaboration metaphors best support work and play? How can we design AI systems
to work best with people or for people? What does it take to get there? This panel
will bring together panelists with diverse backgrounds to engage the audience through
the discussion of their shared or diverging visions on the future of human-AI interaction
design.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {5}
}


@inproceedings{rebanal_2021_xalgo,
author = {Rebanal, Juan and Combitsis, Jordan and Tang, Yuqi and Chen, Xiang 'Anthony'},
title = {XAlgo: A Design Probe of Explaining Algorithms’ Internal States via Question-Answering},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450676},
doi = {10.1145/3397481.3450676},
abstract = {Algorithms often appear as ’black boxes’ to non-expert users. While prior work focuses
on explainable representations and expert-oriented exploration, we propose and study
an interactive approach using question answering to explain deterministic algorithms
to non-expert users who need to understand the algorithms’ internal states (students
learning algorithms, operators monitoring robots, admins troubleshooting network routing).
We construct XAlgo—a formal model that first classifies the type of question based
on a taxonomy and generates an answer based on a set of rules that extract information
from representations of an algorithm’s internal states, the pseudocode. A design probe
based on an algorithm learning scenario with 18 participants (9 for a Wizard-of-Oz
XAlgo and 9 as a control group) reports findings and design implications based on
what kinds of questions people ask, how well XAlgo responds, and what remain as challenges
to bridge users’ gulf of algorithm understanding. },
booktitle = {26th International Conference on Intelligent User Interfaces},
pages = {329–339},
numpages = {11},
keywords = {Question Answering, Explainable AI, Design Probe, Algorithm},
location = {College Station, TX, USA},
series = {IUI '21}
}


@inproceedings{sun_towards_2006,
author = {Sun, Mingyu and Chai, Joyce Y.},
title = {Towards Intelligent QA Interfaces: Discourse Processing for Context Questions},
year = {2006},
isbn = {1595932879},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111487},
doi = {10.1145/1111449.1111487},
abstract = {Question answering (QA) systems take users' natural language questions and retrieve
relevant answers from large repositories of free texts. Despite recent progress in
QA research, most work on question answering is still focused on isolated questions.
In a real-world information seeking scenario, questions are not asked in isolation,
but rather in a coherent manner that involves a sequence of related questions to meet
users' information needs. Therefore, to support coherent information seeking, intelligent
QA interfaces will inevitably require techniques to support context question answering.
To address this problem, this paper investigates approaches to discourse processing
of a sequence of coherent questions and their implications on query expansion. In
particular, we examine three models for query expansion that are motivated by Centering
Theory. Our empirical results indicate that more sophisticated processing based on
discourse transitions and centers can significantly improve the performance of document
retrieval compared to models that only resolve references.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {163–170},
numpages = {8},
keywords = {question answering, discourse processing, context management, QA interfaces},
location = {Sydney, Australia},
series = {IUI '06}
}

@article{wang2017joint,
  title={A joint model for question answering and question generation},
  author={Wang, Tong and Yuan, Xingdi and Trischler, Adam},
  journal={arXiv preprint arXiv:1706.01450},
  year={2017}
}

@article{tang2017question,
  title={Question answering and question generation as dual tasks},
  author={Tang, Duyu and Duan, Nan and Qin, Tao and Yan, Zhao and Zhou, Ming},
  journal={arXiv preprint arXiv:1706.02027},
  year={2017}
}

@article{dong2019unified,
  title={Unified language model pre-training for natural language understanding and generation},
  author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
  journal={arXiv preprint arXiv:1905.03197},
  year={2019}
}

@inproceedings{scialom-etal-2019-self,
    title = "Self-Attention Architectures for Answer-Agnostic Neural Question Generation",
    author = "Scialom, Thomas  and
      Piwowarski, Benjamin  and
      Staiano, Jacopo",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "ACL",
    url = "https://aclanthology.org/P19-1604",
    doi = "10.18653/v1/P19-1604",
    pages = "6027--6032",
    abstract = "Neural architectures based on self-attention, such as Transformers, recently attracted interest from the research community, and obtained significant improvements over the state of the art in several tasks. We explore how Transformers can be adapted to the task of Neural Question Generation without constraining the model to focus on a specific answer passage. We study the effect of several strategies to deal with out-of-vocabulary words such as copy mechanisms, placeholders, and contextual word embeddings. We report improvements obtained over the state-of-the-art on the SQuAD dataset according to automated metrics (BLEU, ROUGE), as well as qualitative human assessments of the system outputs.",
}

@article{yao2012semantics,
  title={Semantics-based question generation and implementation},
  author={Yao, Xuchen and Bouma, Gosse and Zhang, Yi},
  journal={Dialogue \& Discourse},
  volume={3},
  number={2},
  pages={11--42},
  year={2012}
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "ACL",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{papineni_bleu_2002,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: A Method for Automatic Evaluation of Machine Translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
abstract = {Human evaluations of machine translation are extensive but expensive. Human evaluations
can take months to finish and involve human labor that can not be reused. We propose
a method of automatic machine translation evaluation that is quick, inexpensive, and
language-independent, that correlates highly with human evaluation, and that has little
marginal cost per run. We present this method as an automated understudy to skilled
human judges which substitutes for them when there is need for quick or frequent evaluations.},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}
@inproceedings{lovato_2019_hey,
author = {Lovato, Silvia B. and Piper, Anne Marie and Wartella, Ellen A.},
title = {Hey Google, Do Unicorns Exist? Conversational Agents as a Path to Answers to Children's Questions},
year = {2019},
isbn = {9781450366908},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311927.3323150},
doi = {10.1145/3311927.3323150},
abstract = {Children are known to be curious and persistent questionaskers. The pervasiveness
of voice interfaces represents an opportunity for children who are not yet fluent
readers to independently search the Internet by asking questions through conversational
agents such as Amazon Alexa, Apple's Siri, and the Google Assistant. Through a two-week,
in-home deployment study involving 18 families (children aged 5-6 and their parents),
we report on which questions children choose to ask the conversational agent, the
answers the agent provided, challenges in use, and their perceptions of the technology.
Based on our analysis, we identify several considerations for the design of voice-based
conversational agents that aim to support young children's question-asking behavior
and subsequent development.},
booktitle = {Proceedings of the 18th ACM International Conference on Interaction Design and Children},
pages = {301–313},
numpages = {13},
keywords = {Question-Asking, Voice User Interfaces, Conversational Agents, Smart Speakers, Digital Assistants, Children},
location = {Boise, ID, USA},
series = {IDC '19}
}



@inproceedings{pantoja_voice_2019,
author = {Pantoja, Luiza Superti and Diederich, Kyle and Crawford, Liam and Hourcade, Juan Pablo},
title = {Voice Agents Supporting High-Quality Social Play},
year = {2019},
isbn = {9781450366908},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311927.3323151},
doi = {10.1145/3311927.3323151},
abstract = {While the design of Voice User Interfaces (VUIs) has mostly focused on applications
for adults, VUIs also provide potential advantages for young children in enabling
concurrent interactions with the physical and social world. Current applications for
young children focus mostly on media playing, answering questions, and highly-structured
activities. There is an opportunity to go beyond these applications by using VUIs
to support less structured, developmentally appropriate activities. In this paper,
we describe our first step in pursuing this opportunity through an exploration of
voice agents to facilitate high-quality social play guided by a partnership with eight
3-4 year old children. During 24 design sessions, we explored making voice agents
tangible and enabling children to control what voice agents say. After analyzing the
sessions, we learned voice agents could help keep children socially engaged in play
and children liked incorporating the agents with the physical aspects of their play.
On the other hand, enabling children to control the voice agents caused distractions
from play.},
booktitle = {Proceedings of the 18th ACM International Conference on Interaction Design and Children},
pages = {314–325},
numpages = {12},
keywords = {voice user interfaces, play, preschool, Children, tangible user interfaces, communication, voice agents},
location = {Boise, ID, USA},
series = {IDC '19}
}


@inproceedings{xu_exploring_2020,
author = {Xu, Ying and Warschauer, Mark},
title = {Exploring Young Children's Engagement in Joint Reading with a Conversational Agent},
year = {2020},
isbn = {9781450379816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3392063.3394417},
doi = {10.1145/3392063.3394417},
abstract = {Joint book reading is a highly routinized activity that is nearly universal among
families. Conversational agents (CAs) can potentially act as joint-reading partners
by engaging children in story-related, scaffolded conversations. In this project,
we develop a CA reading partner that incorporates components of effective conversational
guidance (i.e., questions to stimulate thinking, specific feedback, and adaptive scaffolding)
and examine children's interactions with this CA. We identify patterns in children's
language production, flow maintenance, and affect when responding to the CA. We then
lay out a set of affordances and challenges for developing CAs as conversation partners.
We propose that, rather than attempting to develop CAs as an exact replicate of human
conversational partners, we should treat child-agent interaction as a new genre of
conversation and calibrate CAs based on children's actual communicative practices
and needs.},
booktitle = {Proceedings of the Interaction Design and Children Conference},
pages = {216–228},
numpages = {13},
keywords = {early literacy, conversational agents, design, conversation analysis, joint reading},
location = {London, United Kingdom},
series = {IDC '20}
}


@inproceedings{xu_2019_young,
author = {Xu, Ying and Warschauer, Mark},
title = {Young Children's Reading and Learning with Conversational Agents},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3299035},
doi = {10.1145/3290607.3299035},
abstract = {Young children increasingly interact with voice-driven interfaces, such as conversational
agents (CAs). The social nature of CAs makes them good learning partners for children.
We have designed a storytelling CA to engage children in book reading activities.
This case study presents the design of this CA and investigates children's interactions
with and perception of the CA. Through observation, we found that children actively
responded to the CA's prompts, reacted to the CA's feedback with great affect, and
quickly learned the schema of interacting with a digital interlocutor. We also discovered
that the availability of scaffolding appeared to facilitate child-CA conversation
and learning. A brief post-reading interview suggested that children enjoyed their
interaction with the CA. Design implications for dialogic systems for young children's
informal learning are discussed.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {natural language processing, conversational agents, dialogic reading, artificial intelligence, young children, social interaction},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{mack_codesigning_2019,
author = {Mack, Naja A. and Rembert, Dekita G. Moon and Cummings, Robert and Gilbert, Juan E.},
title = {Co-Designing an Intelligent Conversational History Tutor with Children},
year = {2019},
isbn = {9781450366908},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311927.3325336},
doi = {10.1145/3311927.3325336},
abstract = {In a world that demands independent and cooperative problem solving to address complex
social, economic, ethical, and personal concerns, core social studies content is as
basic for success as reading, writing, math, and computing. Nationally, only 20% of
4th grade students are at or above Proficient level in U.S. History, the lowest among
the core disciplines of social studies. Reaching proficiency requires students to
ask more profound questions of the past as well as construct deeper understandings
of it. This research explores the intersection of natural language dialogue and intelligent
tutoring systems to enhance history learning of upper elementary students in 3rd and
4th grade. Elementary and middle school students were participants in a participatory
design study to extract their design needs for the development of an educational learning
technology for social studies.},
booktitle = {Proceedings of the 18th ACM International Conference on Interaction Design and Children},
pages = {482–487},
numpages = {6},
keywords = {history, natural language dialogue, educational learning technologies, social studies, embodied conversational agents, intelligent tutoring system},
location = {Boise, ID, USA},
series = {IDC '19}
}

@inproceedings{li_pumice:_2019,
	series = {{UIST} 2019},
	title = {{PUMICE}: {A} {Multi}-{Modal} {Agent} that {Learns} {Concepts} and {Conditionals} from {Natural} {Language} and {Demonstrations}},
	doi = {http://doi.acm.org/10.1145/3332165.3347899},
	booktitle = {Proceedings of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Li, Toby Jia-Jun and Radensky, Marissa and Jia, Justin and Singarajah, Kirielle and Mitchell, Tom M. and Myers, Brad A.},
	year = {2019}
}

@inbook{myers_2018_patterns,
author = {Myers, Chelsea and Furqan, Anushay and Nebolsky, Jessica and Caro, Karina and Zhu, Jichen},
title = {Patterns for How Users Overcome Obstacles in Voice User Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173580},
abstract = {Voice User Interfaces (VUIs) are growing in popularity. However, even the most current
VUIs regularly cause frustration for their users. Very few studies exist on what people
do to overcome VUI problems they encounter, or how VUIs can be designed to aid people
when these problems occur. In this paper, we analyze empirical data on how users (n=12)
interact with our VUI calendar system, DiscoverCal, over three sessions. In particular,
we identify the main obstacle categories and types of tactics our participants employ
to overcome them. We analyzed the patterns of how different tactics are used in each
obstacle category. We found that while NLP Error obstacles occurred the most, other
obstacles are more likely to frustrate or confuse the user. We also found patterns
that suggest participants were more likely to employ a "guessing" approach rather
than rely on visual aids or knowledge recall.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7}
}

@inproceedings{givens_exploring_2013,
	title = {Exploring the internal state of user interfaces by combining computer vision techniques with grammatical inference},
	doi = {10.1109/ICSE.2013.6606669},
	abstract = {In this paper, we present a promising approach to systematically testing graphical user interfaces (GUI) in a platform independent manner. Our framework uses standard computer vision techniques through a python-based scripting language (Sikuli script) to identify key graphical elements in the screen and automatically interact with these elements by simulating keypresses and pointer clicks. The sequence of inputs and outputs resulting from the interaction is analyzed using grammatical inference techniques that can infer the likely internal states and transitions of the GUI based on the observations. Our framework handles a wide variety of user interfaces ranging from traditional pull down menus to interfaces built for mobile platforms such as Android and iOS. Furthermore, the automaton inferred by our approach can be used to check for potentially harmful patterns in the interface's internal state machine such as design inconsistencies (eg,. a keypress does not have the intended effect) and mode confusion that can make the interface hard to use. We describe an implementation of the framework and demonstrate its working on a variety of interfaces including the user-interface of a safety critical insulin infusion pump that is commonly used by type-1 diabetic patients.},
	booktitle = {2013 35th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Givens, P. and Chakarov, A. and Sankaranarayanan, S. and Yeh, T.},
	month = may,
	year = {2013},
	keywords = {Android, Automata, Calculators, GUI, Insulin, Pumps, Sikuli script, authoring languages, computer vision, computer vision techniques, design inconsistencies, grammatical inference techniques, graphical user interfaces, human computer interaction, iOS, interface internal state machine, keypresses, learning (artificial intelligence), mobile platforms, mode confusion, natural language processing, pointer clicks, pull down menus, python-based scripting language, safety critical insulin infusion pump, type-1 diabetic patients},
	pages = {1165--1168}
}

@inproceedings{chang_associating_2011,
	address = {New York, NY, USA},
	series = {{UIST} '11},
	title = {Associating the {Visual} {Representation} of {User} {Interfaces} with {Their} {Internal} {Structures} and {Metadata}},
	isbn = {978-1-4503-0716-1},
	url = {http://doi.acm.org/10.1145/2047196.2047228},
	doi = {10.1145/2047196.2047228},
	abstract = {Pixel-based methods are emerging as a new and promising way to develop new interaction techniques on top of existing user interfaces. However, in order to maintain platform independence, other available low-level information about GUI widgets, such as accessibility metadata, was neglected intentionally. In this paper, we present a hybrid framework, PAX, which associates the visual representation of user interfaces (i.e. the pixels) and their internal hierarchical metadata (i.e. the content, role, and value). We identify challenges to building such a framework. We also develop and evaluate two new algorithms for detecting text at arbitrary places on the screen, and for segmenting a text image into individual word blobs. Finally, we validate our framework in implementations of three applications. We enhance an existing pixel-based system, Sikuli Script, and preserve the readability of its script code at the same time. Further, we create two novel applications, Screen Search and Screen Copy, to demonstrate how PAX can be applied to development of desktop-level interactive systems.},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 24th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Chang, Tsung-Hsiang and Yeh, Tom and Miller, Rob},
	year = {2011},
	keywords = {accessibility api, graphical user interfaces, pixel, text detection, text segmentation},
	pages = {245--256}
}

@inproceedings{givens_exploring_2013-1,
	title = {Exploring the internal state of user interfaces by combining computer vision techniques with grammatical inference},
	doi = {10.1109/ICSE.2013.6606669},
	abstract = {In this paper, we present a promising approach to systematically testing graphical user interfaces (GUI) in a platform independent manner. Our framework uses standard computer vision techniques through a python-based scripting language (Sikuli script) to identify key graphical elements in the screen and automatically interact with these elements by simulating keypresses and pointer clicks. The sequence of inputs and outputs resulting from the interaction is analyzed using grammatical inference techniques that can infer the likely internal states and transitions of the GUI based on the observations. Our framework handles a wide variety of user interfaces ranging from traditional pull down menus to interfaces built for mobile platforms such as Android and iOS. Furthermore, the automaton inferred by our approach can be used to check for potentially harmful patterns in the interface's internal state machine such as design inconsistencies (eg,. a keypress does not have the intended effect) and mode confusion that can make the interface hard to use. We describe an implementation of the framework and demonstrate its working on a variety of interfaces including the user-interface of a safety critical insulin infusion pump that is commonly used by type-1 diabetic patients.},
	booktitle = {2013 35th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Givens, P. and Chakarov, A. and Sankaranarayanan, S. and Yeh, T.},
	month = may,
	year = {2013},
	keywords = {Android, Automata, Calculators, GUI, Insulin, Pumps, Sikuli script, authoring languages, computer vision, computer vision techniques, design inconsistencies, grammatical inference techniques, graphical user interfaces, human computer interaction, iOS, interface internal state machine, keypresses, learning (artificial intelligence), mobile platforms, mode confusion, natural language processing, pointer clicks, pull down menus, python-based scripting language, safety critical insulin infusion pump, type-1 diabetic patients},
	pages = {1165--1168}
}

@inproceedings{fernandes_appstract:_2016,
	address = {New York, NY, USA},
	series = {{MobiCom} '16},
	title = {Appstract: {On}-the-fly {App} {Content} {Semantics} with {Better} {Privacy}},
	isbn = {978-1-4503-4226-1},
	shorttitle = {Appstract},
	url = {http://doi.acm.org/10.1145/2973750.2973770},
	doi = {10.1145/2973750.2973770},
	abstract = {Services like Google Now on Tap and Bing Snapp enable new user experiences by understanding the semantics of contents that users consume in their apps. These systems send contents of currently displayed app pages to the cloud to identify relevant entities (e.g., a movie) appearing in the current page and show information related to such entities (e.g., local theaters playing the movie). These new experiences come with privacy concerns as they can send sensitive on-screen data (bank details, medical data, etc.) to the cloud. We propose a novel approach that efficiently extracts app content semantics on the device, without exfiltrating user data. Our solution consists of two phases: an offline, user-agnostic, in-cloud phase that automatically annotates apps' UI elements with stable semantics, and a lightweight on-device phase that assigns semantics to captured app contents on the fly, by matching the annotations. With this automatic approach we annotated 100+ food, dining, and music apps, with accuracy over 80\%. Our system implementation for Android and Windows Phone---Appstract---incurs minimal runtime overhead. We built eight use cases on the Appstract framework.},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 22Nd {Annual} {International} {Conference} on {Mobile} {Computing} and {Networking}},
	publisher = {ACM},
	author = {Fernandes, Earlence and Riva, Oriana and Nath, Suman},
	year = {2016},
	keywords = {entity extraction, entity templates, mobile applications},
	pages = {361--374}
}

@inproceedings{ravindranath_appinsight:_2012,
	title = {{AppInsight}: {Mobile} {App} {Performance} {Monitoring} in the {Wild}.},
	volume = {12},
	shorttitle = {{AppInsight}},
	url = {https://www.usenix.org/system/files/conference/osdi12/osdi12-final-91.pdf},
	urldate = {2017-02-16TZ},
	booktitle = {{OSDI}},
	author = {Ravindranath, Lenin and Padhye, Jitendra and Agarwal, Sharad and Mahajan, Ratul and Obermiller, Ian and Shayandeh, Shahin},
	year = {2012},
	pages = {107--120}
}

@inproceedings{tongaonkar_understanding_2013,
	title = {Understanding mobile app usage patterns using in-app advertisements},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-36516-4_7},
	urldate = {2017-02-16TZ},
	booktitle = {International {Conference} on {Passive} and {Active} {Network} {Measurement}},
	publisher = {Springer},
	author = {Tongaonkar, Alok and Dai, Shuaifu and Nucci, Antonio and Song, Dawn},
	year = {2013},
	pages = {63--72}
}

@misc{otoole_mobile_2014,
	title = {Mobile apps overtake {PC} {Web} usage in {U}.{S}.},
	url = {http://money.cnn.com/2014/02/28/technology/mobile/mobile-apps-internet/index.html},
	abstract = {For the first time ever, Americans spent more of their time online last month using mobile apps than PC's.},
	urldate = {2017-02-16TZ},
	journal = {CNNMoney},
	author = {O'Toole, James},
	month = feb,
	year = {2014}
}

@inproceedings{li_platform_2014,
	title = {A {Platform} for {Searching} {UI} {Component} of {Android} {Application}},
	doi = {10.1109/ICDH.2014.46},
	abstract = {Android applications are becoming increasingly popular in digital home nowadays. Building high quality application is still one of biggest changes for Android developer community. The search service in current Android application market can't meet the needs of developers when trying to find the user interface design in other applications. In this paper, we introduce a platform to query the runtime user interfaces of Android applications, which can help developers to reuse the design components to improve their applications. Based on the description information of 8,456 Android applications in Android market and the information of runtime 313,820 UI elements, we implement the platform providing search service for developers to find specified runtime user interfaces in our Android software repository. Our experiment for the quality of search result shows that 76.7\% of top-10 search result contains the relevant UI components that are valuable for users.},
	booktitle = {2014 5th {International} {Conference} on {Digital} {Home}},
	author = {Li, K. and Xu, Z. and Chen, X.},
	month = nov,
	year = {2014},
	keywords = {Android, Android (operating system), Android application UI component, Android application runtime user interfaces, Android software repository, Androids, Humanoid robots, Monitoring, Runtime, User interfaces, search, search engines, smart phones, software reuse, user interface, user interface design},
	pages = {205--210}
}

@inproceedings{fernandes_my_2015,
	title = {My {OS} {Ought} to {Know} {Me} {Better}: {In}-app {Behavioural} {Analytics} as an {OS} {Service}.},
	shorttitle = {My {OS} {Ought} to {Know} {Me} {Better}},
	url = {https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-fernandes.pdf},
	urldate = {2017-02-16TZ},
	booktitle = {{HotOS}},
	author = {Fernandes, Earlence and Riva, Oriana and Nath, Suman},
	year = {2015}
}

@inproceedings{sun_appdialogue:_2016,
	title = {{AppDialogue}: {Multi}-app dialogues for intelligent assistants},
	shorttitle = {{AppDialogue}},
	url = {http://www.lrec-conf.org/proceedings/lrec2016/pdf/75_Paper.pdf},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC})},
	author = {Sun, Ming and Chen, Yun-Nung and Hua, Zhenhao and Tamres-Rudnicky, Yulian and Dash, Arnab and Rudnicky, Alexander I.},
	year = {2016}
}

@inproceedings{sun_weakly_2016,
	title = {Weakly supervised user intent detection for multi-domain dialogues},
	doi = {10.1109/SLT.2016.7846250},
	abstract = {Users interact with mobile apps with certain intents such as finding a restaurant. Some intents and their corresponding activities are complex and may involve multiple apps; for example, a restaurant app, a messenger app and a calendar app may be needed to plan a dinner with friends. However, activities may be quite personal and third-party developers would not be building apps to specifically handle complex intents (e.g., a DinnerPlanner). Instead we want our intelligent agent to actively learn to understand these intents and provide assistance when needed. This paper proposes a framework to enable the agent to learn an inventory of intents from a small set of task-oriented user utterances. The experiments show that on previously unseen user activities, the agent is able to reliably recognize user intents using graph-based semi-supervised learning methods. The dataset, models, and the system outputs are available to research community.},
	booktitle = {2016 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Sun, M. and Pappu, A. and Chen, Y. N. and Rudnicky, A. I.},
	month = dec,
	year = {2016},
	keywords = {Browsers, Covariance matrices, Estimation, Facebook, Kernel, Multi-domain dialogue, Speech, context, mobile applications, user intent detection},
	pages = {91--97}
}

@inproceedings{yan_appjoy:_2011,
	title = {{AppJoy}: personalized mobile application discovery},
	shorttitle = {{AppJoy}},
	url = {http://dl.acm.org/citation.cfm?id=2000007},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 9th international conference on {Mobile} systems, applications, and services},
	publisher = {ACM},
	author = {Yan, Bo and Chen, Guanling},
	year = {2011},
	pages = {113--126}
}

@inproceedings{karatzoglou_climbing_2012,
	title = {Climbing the app wall: enabling mobile app discovery through context-aware recommendations},
	shorttitle = {Climbing the app wall},
	url = {http://dl.acm.org/citation.cfm?id=2398683},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 21st {ACM} international conference on {Information} and knowledge management},
	publisher = {ACM},
	author = {Karatzoglou, Alexandros and Baltrunas, Linas and Church, Karen and Böhmer, Matthias},
	year = {2012},
	pages = {2527--2530}
}

@inproceedings{deka_data-driven_2016,
	title = {Data-driven {Mobile} {App} {Design}},
	url = {http://dl.acm.org/citation.cfm?id=2984786},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 29th {Annual} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Deka, Biplab},
	year = {2016},
	pages = {21--24}
}

@inproceedings{chandramouli_insider:_2015,
	title = {Insider: {Towards} breaking down mobile app silos},
	shorttitle = {Insider},
	booktitle = {{TRIOS} {Workshop} held in conjunction with the {SIGOPS} {SOSP} 2015},
	author = {Chandramouli, Vageesh and Chakraborty, Abhijnan and Navda, Vishnu and Guha, Saikat and Padmanabhan, Venkata and Ramjee, Ramachandran},
	year = {2015}
}

@inproceedings{chen_leveraging_2015,
	title = {Leveraging behavioral patterns of mobile applications for personalized spoken language understanding},
	url = {http://dl.acm.org/citation.cfm?id=2820781},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 2015 {ACM} on {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {ACM},
	author = {Chen, Yun-Nung and Sun, Ming and Rudnicky, Alexander I. and Gershman, Anatole},
	year = {2015},
	pages = {83--86}
}

@inproceedings{sahami_shirazi_insights_2013,
	address = {New York, NY, USA},
	series = {{EICS} '13},
	title = {Insights into {Layout} {Patterns} of {Mobile} {User} {Interfaces} by an {Automatic} {Analysis} of {Android} {Apps}},
	isbn = {978-1-4503-2138-9},
	url = {http://doi.acm.org/10.1145/2494603.2480308},
	doi = {10.1145/2494603.2480308},
	abstract = {Mobile phones recently evolved into smartphones that provide a wide range of services. One aspect that differentiates smartphones from their predecessor is the app model. Users can easily install third party applications from central mobile application stores. In this paper we present a process to gain insights into mobile user interfaces on a large scale. Using the developed process we automatically disassemble and analyze the 400 most popular free Android applications. The results suggest that the complexity of the user interface differs between application categories. Further, we analyze interface layouts to determine the most frequent interface elements and identify combinations of interface widgets. The most common combination that consists of three nested elements covers 5.43\% of all interface elements. It is more frequent than progress bars and checkboxes. The ten most frequent patterns together cover 21.13\% of all interface elements. They are all more frequent than common widget including radio buttons and spinner. We argue that the combinations identified not only provide insights about current mobile interfaces, but also enable the development of new optimized widgets.},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 5th {ACM} {SIGCHI} {Symposium} on {Engineering} {Interactive} {Computing} {Systems}},
	publisher = {ACM},
	author = {Sahami Shirazi, Alireza and Henze, Niels and Schmidt, Albrecht and Goldberg, Robin and Schmidt, Benjamin and Schmauder, Hansjörg},
	year = {2013},
	keywords = {Android, apps, design, mobile applications, pattern, reverse engineering, user interface, widget},
	pages = {275--284}
}

@inproceedings{hao_puma:_2014,
	address = {New York, NY, USA},
	series = {{MobiSys} '14},
	title = {{PUMA}: {Programmable} {UI}-automation for {Large}-scale {Dynamic} {Analysis} of {Mobile} {Apps}},
	isbn = {978-1-4503-2793-0},
	shorttitle = {{PUMA}},
	url = {http://doi.acm.org/10.1145/2594368.2594390},
	doi = {10.1145/2594368.2594390},
	abstract = {Mobile app ecosystems have experienced tremendous growth in the last six years. This has triggered research on dynamic analysis of performance, security, and correctness properties of the mobile apps in the ecosystem. Exploration of app execution using automated UI actions has emerged as an important tool for this research. However, existing research has largely developed analysis-specific UI automation techniques, wherein the logic for exploring app execution is intertwined with the logic for analyzing app properties. PUMA is a programmable framework that separates these two concerns. It contains a generic UI automation capability (often called a Monkey) that exposes high-level events for which users can define handlers. These handlers can flexibly direct the Monkey's exploration, and also specify app instrumentation for collecting dynamic state information or for triggering changes in the environment during app execution. Targeted towards operators of app marketplaces, PUMA incorporates mechanisms for scaling dynamic analysis to thousands of apps. We demonstrate the capabilities of PUMA by analyzing seven distinct performance, security, and correctness properties for 3,600 apps downloaded from the Google Play store.},
	urldate = {2017-02-16TZ},
	booktitle = {Proceedings of the 12th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Hao, Shuai and Liu, Bin and Nath, Suman and Halfond, William G.J. and Govindan, Ramesh},
	year = {2014},
	keywords = {dynamic analysis, large scale, mobile apps, programming framework, separation of concerns, ui-automation},
	pages = {204--217}
}

@inproceedings{nath_smartads:_2013,
	address = {New York, NY, USA},
	series = {{MobiSys} '13},
	title = {{SmartAds}: {Bringing} {Contextual} {Ads} to {Mobile} {Apps}},
	isbn = {978-1-4503-1672-9},
	shorttitle = {{SmartAds}},
	url = {http://doi.acm.org/10.1145/2462456.2464452},
	doi = {10.1145/2462456.2464452},
	abstract = {A recent study showed that while US consumers spent 30\% more time on mobile apps than on traditional web, advertisers spent 1600\% less money on mobile ads. One key reason is that unlike most web ad providers, today's mobile ads are not contextual---they do not take into account the content of the page they are displayed on. Thus, most mobile ads are irrelevant to what the user is interested in. For example, it is not uncommon to see gambling ads being displayed in a Bible app. This irrelevance results in low clickthrough rates, and hence advertisers shy away from the mobile platform. Using data from top 1200 apps in Windows Phone marketplace, and a one-week trace of ad keywords from Microsoft's ad network, we show that content displayed by mobile apps is a potential goldmine of keywords that advertisers are interested in. However, unlike web pages, which can be crawled and indexed offline for contextual advertising, content shown on mobile apps is often either generated dynamically, or is embedded in the apps themselves; and hence cannot be crawled. The only solution is to scrape the content at runtime, extract keywords and fetch contextually relevant ads. The challenge is to do this without excessive overhead and without violating user privacy. In this paper, we describe a system called SmartAds to address this challenge. We have built a prototype of SmartAds for Windows Phone apps. In a large user study with over 5000 ad impressions, we found that SmartAds nearly doubles the relevance score, while consuming minimal additional resources and preserving user privacy.},
	urldate = {2017-02-16TZ},
	booktitle = {Proceeding of the 11th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Nath, Suman and Lin, Felix Xiaozhu and Ravindranath, Lenin and Padhye, Jitendra},
	year = {2013},
	keywords = {advertisement, apps, contextual, mobile},
	pages = {111--124}
}

@inproceedings{deka_erica:_2016,
	address = {New York, NY, USA},
	series = {{UIST} '16},
	title = {{ERICA}: {Interaction} {Mining} {Mobile} {Apps}},
	isbn = {978-1-4503-4189-9},
	shorttitle = {{ERICA}},
	url = {http://doi.acm.org/10.1145/2984511.2984581},
	doi = {10.1145/2984511.2984581},
	abstract = {Design plays an important role in adoption of apps. App design, however, is a complex process with multiple design activities. To enable data-driven app design applications, we present interaction mining -- capturing both static (UI layouts, visual details) and dynamic (user flows, motion details) components of an app's design. We present ERICA, a system that takes a scalable, human-computer approach to interaction mining existing Android apps without the need to modify them in any way. As users interact with apps through ERICA, it detects UI changes, seamlessly records multiple data-streams in the background, and unifies them into a user interaction trace. Using ERICA we collected interaction traces from over a thousand popular Android apps. Leveraging this trace data, we built machine learning classifiers to detect elements and layouts indicative of 23 common user flows. User flows are an important component of UX design and consists of a sequence of UI states that represent semantically meaningful tasks such as searching or composing. With these classifiers, we identified and indexed more than 3000 flow examples, and released the largest online search engine of user flows in Android apps.},
	urldate = {2017-02-15TZ},
	booktitle = {Proceedings of the 29th {Annual} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Deka, Biplab and Huang, Zifeng and Kumar, Ranjitha},
	year = {2016},
	keywords = {app design, design mining, interaction mining, user flows},
	pages = {767--776}
}

@inproceedings{church_understanding_2015,
	address = {New York, NY, USA},
	series = {{MobileHCI} '15},
	title = {Understanding the {Challenges} of {Mobile} {Phone} {Usage} {Data}},
	isbn = {978-1-4503-3652-9},
	url = {http://doi.acm.org/10.1145/2785830.2785891},
	doi = {10.1145/2785830.2785891},
	abstract = {Driven by curiosity and our own three diverse smartphone application usage datasets, we sought to unpack the nuances of mobile device use by revisiting two recent Mobile HCI studies [1, 17]. Our goal was to add to our broader understanding of smartphone usage by investigating if differences in mobile device usage occurred not only across our three datasets, but also in relation to prior work. We found differences in the top-10 apps in each dataset, in the durations and types of interactions as well as in micro-usage patterns. However, it proved very challenging to attribute such differences to a specific factor or set of factors: was it the time frame in which the studies were executed? The recruitment procedure? The experimental method? Using our somewhat troubled analysis, we discuss the challenges and issues of conducting mobile research of this nature and reflect on caveats related to the replicability and generalizability of such work.},
	urldate = {2017-02-06TZ},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Church, Karen and Ferreira, Denzil and Banovic, Nikola and Lyons, Kent},
	year = {2015},
	keywords = {Device usage, Generalizability, Methodology, Micro-usage, Mobile HCI, Mobile usage, Replication, evaluation, smartphone usage, user studies},
	pages = {504--514}
}

@inproceedings{bentley_i_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {"{I} {Thought} {She} {Would} {Like} to {Read} {It}": {Exploring} {Sharing} {Behaviors} in the {Context} of {Declining} {Mobile} {Web} {Use}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {"{I} {Thought} {She} {Would} {Like} to {Read} {It}"},
	url = {http://doi.acm.org/10.1145/2858036.2858056},
	doi = {10.1145/2858036.2858056},
	abstract = {The use of applications on mobile devices has changed dramatically over the past few years. While web browsing was once a common activity, it's now reported that 86\% of time on mobile phones is in apps other than the browser. We set out to understand how the mobile web was currently fitting into people's lives and what web sessions looked like. Finding a dramatic reduction in mobile web revisi-tation rates compared to previous work and that a large number of sessions comprised single page views, we then studied how web content was shared with others in mobile messaging, the source of many single page sessions. The HCI community has not heavily studied this sharing activity that many people perform daily. We conclude with design implications for new mobile applications from our two studies with a combined 287 participants where we studied actual logs of mobile web use and link sharing behavior.},
	urldate = {2017-02-05TZ},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bentley, Frank R. and Peesapati, S. Tejaswi and Church, Karen},
	year = {2016},
	keywords = {link sharing, mobile browsing, mobile search, mobile web, mturk, user research},
	pages = {1893--1903}
}

@inproceedings{azim_ulink:_2016,
	address = {New York, NY, USA},
	series = {{MobiSys} '16},
	title = {{uLink}: {Enabling} {User}-{Defined} {Deep} {Linking} to {App} {Content}},
	isbn = {978-1-4503-4269-8},
	shorttitle = {{uLink}},
	url = {http://doi.acm.org/10.1145/2906388.2906416},
	doi = {10.1145/2906388.2906416},
	abstract = {Web deep links are instrumental to many fundamental user experiences such as navigating to one web page from another, bookmarking a page, or sharing it with others. Such experiences are not possible with individual pages inside mobile apps, since historically mobile apps did not have links equivalent to web deep links. Mobile deep links, introduced in recent years, still lack many important properties of web deep links. Unlike web links, mobile deep links need significant developer effort, cover a small number of predefined pages, and are defined statically to navigate to a page for a given link, but not to dynamically generate a link for a given page. We propose uLink, a novel deep linking mechanism that addresses these problems. uLink is implemented as an application library, which transparently tracks data- and UI-event-dependencies of app pages, and encodes the information in links to the pages; when a link is invoked, the information is utilized to recreate the target page quickly and accurately. uLink also employs techniques, based on static and dynamic analysis of the app, that can provide feedback to users about whether a link may break in the future due to, e.g., modifications of external resources such as a file the link depends on. We have implemented uLink on Android. Our evaluation with 34 (of 1000 most downloaded) Android apps shows that compared to existing mobile deep links, uLink requires minimal developer effort, achieves significantly higher coverage, and can provide accurate user feedback on a broken link.},
	urldate = {2017-02-05TZ},
	booktitle = {Proceedings of the 14th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Azim, Tanzirul and Riva, Oriana and Nath, Suman},
	year = {2016},
	keywords = {application library, mobile applications, mobile deep links, user experiences.},
	pages = {305--318}
}

@inproceedings{chen_bezelcopy:_2014,
	address = {New York, NY, USA},
	series = {{AVI} '14},
	title = {{BezelCopy}: {An} {Efficient} {Cross}-application {Copy}-paste {Technique} for {Touchscreen} {Smartphones}},
	isbn = {978-1-4503-2775-6},
	shorttitle = {{BezelCopy}},
	url = {http://doi.acm.org/10.1145/2598153.2598162},
	doi = {10.1145/2598153.2598162},
	abstract = {Copy-Paste (CP) operations on touchscreen smartphones are not as easy to perform as compared with similar operations on desktop computers. The smaller screen size and input area make both text selection and application switching more difficult to perform. To enable faster copy-paste on touchscreen smartphones, we introduce BezelCopy, a copy-paste technique that uses a bezel-swipe gesture to determine a rough area of interest in the document. Chosen text is magnified in a new panel to enable fast and precise selection. With the new panel, users can perform easy tap-and-drag gestures to select the exact content, and tap the application icon on the bottom of the panel to paste it to the target application. Users can further adjust the location of the pasted text in the target application using drag and drop. We conducted two experiments to compare the performance of BezelCopy with alternative approaches, and our results show that BezelCopy outperform existing copy-paste techniques for a number of commonly performed copy-paste tasks.},
	urldate = {2017-02-02TZ},
	booktitle = {Proceedings of the 2014 {International} {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {ACM},
	author = {Chen, Chen and Perrault, Simon T. and Zhao, Shengdong and Ooi, Wei Tsang},
	year = {2014},
	keywords = {bezel interaction, copy-paste, handheld device, input, mobile computing, smartphone},
	pages = {185--192}
}

@inproceedings{quinn_cost-benefit_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {A {Cost}-{Benefit} {Study} of {Text} {Entry} {Suggestion} {Interaction}},
	isbn = {978-1-4503-3362-7},
	url = {http://doi.acm.org/10.1145/2858036.2858305},
	doi = {10.1145/2858036.2858305},
	abstract = {Mobile keyboards often present error corrections and word completions (suggestions) as candidates for anticipated user input. However, these suggestions are not cognitively free: they require users to attend, evaluate, and act upon them. To understand this trade-off between suggestion savings and interaction costs, we conducted a text transcription experiment that controlled interface assertiveness: the tendency for an interface to present itself. Suggestions were either always present (extraverted), never present (introverted), or gated by a probability threshold (ambiverted). Results showed that although increasing the assertiveness of suggestions reduced the number of keyboard actions to enter text and was subjectively preferred, the costs of attending to and using the suggestions impaired average time performance.},
	urldate = {2017-02-02TZ},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Quinn, Philip and Zhai, Shumin},
	year = {2016},
	keywords = {interface assertiveness, mobile text entry, predictive interfaces},
	pages = {83--88}
}

@article{wiese_evolving_2015,
	title = {Evolving the {Ecosystem} of {Personal} {Behavioral} {Data}},
	url = {http://repository.cmu.edu/dissertations/624/},
	urldate = {2017-01-27TZ},
	author = {Wiese, Jason Stampfer},
	year = {2015}
}

@inproceedings{dey_cappella:_2004,
	title = {a {CAPpella}: programming by demonstration of context-aware applications},
	shorttitle = {a {CAPpella}},
	url = {http://dl.acm.org/citation.cfm?id=985697},
	urldate = {2017-01-27TZ},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems},
	publisher = {ACM},
	author = {Dey, Anind K. and Hamid, Raffay and Beckmann, Chris and Li, Ian and Hsu, Daniel},
	year = {2004},
	pages = {33--40}
}

@article{katasonov_smart_2008,
	title = {Smart {Semantic} {Middleware} for the {Internet} of {Things}.},
	volume = {8},
	url = {https://pdfs.semanticscholar.org/4665/130fd1236d7cf5636b188ca7adcc4fd8d631.pdf},
	urldate = {2017-01-27TZ},
	journal = {ICINCO-ICSO},
	author = {Katasonov, Artem and Kaykova, Olena and Khriyenko, Oleksiy and Nikitin, Sergiy and Terziyan, Vagan Y.},
	year = {2008},
	pages = {169--178}
}

@inproceedings{song_semantic_2010,
	title = {Semantic middleware for the {Internet} of {Things}},
	doi = {10.1109/IOT.2010.5678448},
	abstract = {The Internet of Things (IoT) refers to extending the Internet to devices such as home appliances, consumer electronics, and sensor networks. As multiple heterogeneous devices attempt to create area networks, one of the major challenges is the interoperability and composability of their services. The traditional way to address interoperability is to define standards; however, there are many standards and specifications that are incompatible with each other. In this paper we propose an application layer solution for interoperability. The key idea is to utilize device semantics provided by existing specifications and dynamically wrap them in our middleware into semantic services. Next, with the help of Semantic Web technologies, users can create and then execute complex tasks involving multiple heterogeneous devices. We demonstrate how our framework automates interoperability without any modifications to existing standards, devices, or technologies, while providing to the user an intuitive semantic interface with services that can be executed by combining devices in the network.},
	booktitle = {2010 {Internet} of {Things} ({IOT})},
	author = {Song, Z. and Cardenas, A. A. and Masuoka, R.},
	month = nov,
	year = {2010},
	keywords = {Bluetooth, Grounding, Internet, Internet of Things, Protocols, Semantic Web, Semantics, Standards, User interfaces, application layer solution, area networks, composability, device semantics, interoperability, intuitive semantic interface, middleware, multiple heterogeneous devices, open systems, semantic Web technology, semantic middleware, semantic services},
	pages = {1--8}
}

@inproceedings{blackstock_iot_2014,
	title = {{IoT} interoperability: {A} hub-based approach},
	shorttitle = {{IoT} interoperability},
	url = {http://ieeexplore.ieee.org/abstract/document/7030119/},
	urldate = {2017-01-27TZ},
	booktitle = {Internet of {Things} ({IOT}), 2014 {International} {Conference} on the},
	publisher = {IEEE},
	author = {Blackstock, Michael and Lea, Rodger},
	year = {2014},
	pages = {79--84}
}

@article{mayer_cognitive_1987,
	title = {Cognitive aspects of learning and using a programming language.},
	url = {http://psycnet.apa.org/psycinfo/1987-98055-004},
	urldate = {2017-01-25TZ},
	author = {Mayer, Richard E.},
	year = {1987}
}

@article{green_usability_1996,
	title = {Usability {Analysis} of {Visual} {Programming} {Environments}: {A} '{Cognitive} {Dimensions}' {Framework}},
	volume = {7},
	issn = {1045-926X},
	shorttitle = {Usability {Analysis} of {Visual} {Programming} {Environments}},
	url = {//www.sciencedirect.com/science/article/pii/S1045926X96900099},
	doi = {10.1006/jvlc.1996.0009},
	abstract = {The cognitive dimensions framework is a broad-brush evaluation technique for interactive devices and for non-interactive notations. It sets out a small vocabulary of terms designed to capture the cognitively-relevant aspects of structure, and shows how they can be traded off against each other. The purpose of this paper is to propose the framework as an evaluation technique for visual programming environments. We apply it to two commercially-available dataflow languages (with further examples from other systems) and conclude that it is effective and insightful; other HCI-based evaluation techniques focus on different aspects and would make good complements. Insofar as the examples we used are representative, current VPLs are successful in achieving a good ‘closeness of match’, but designers need to consider the ‘viscosity ’ (resistance to local change) and the ‘secondary notation’ (possibility of conveying extra meaning by choice of layout, colour, etc.).},
	number = {2},
	urldate = {2017-01-25TZ},
	journal = {Journal of Visual Languages \& Computing},
	author = {Green, T. R. G. and Petre, M.},
	month = jun,
	year = {1996},
	pages = {131--174}
}

@book{nielsen_usability_1994,
	title = {Usability engineering},
	url = {https://books.google.com/books?hl=en&lr=&id=DBOowF7LqIQC&oi=fnd&pg=PP1&dq=nielsen&ots=Bk87TSNYES&sig=fWkgUYQKzEmmRJ8G48a6mZMax38},
	urldate = {2017-01-25TZ},
	publisher = {Elsevier},
	author = {Nielsen, Jakob},
	year = {1994}
}

@misc{noauthor_10_nodate,
	title = {10 {Heuristics} for {User} {Interface} {Design}: {Article} by {Jakob} {Nielsen}},
	shorttitle = {10 {Heuristics} for {User} {Interface} {Design}},
	url = {https://www.nngroup.com/articles/ten-usability-heuristics/},
	abstract = {Jakob Nielsen's 10 general principles for interaction design. They are called "heuristics" because they are broad rules of thumb and not specific usability guidelines.},
	urldate = {2017-01-25TZ}
}

@article{wolber_democratizing_2015,
	title = {Democratizing {Computing} with {App} {Inventor}},
	volume = {18},
	issn = {2375-0529},
	url = {http://doi.acm.org/10.1145/2721914.2721935},
	doi = {10.1145/2721914.2721935},
	abstract = {MIT App Inventor is a visual blocks language that enables beginners and non-programmers to create apps for their phones and tablets. It has empowered thousands to create software with real-world usefulness, and see themselves as creators rather than only consumers in the mobile computing environment. Educationally, it offers a "gateway drug" that can help broaden and diversify participation in computing education.},
	number = {4},
	urldate = {2017-01-25TZ},
	journal = {GetMobile: Mobile Comp. and Comm.},
	author = {Wolber, David and Abelson, Harold and Friedman, Mark},
	month = jan,
	year = {2015},
	pages = {53--58}
}

@inproceedings{wagner_using_2013,
	address = {New York, NY, USA},
	series = {{SIGCSE} '13},
	title = {Using {App} {Inventor} in a {K}-12 {Summer} {Camp}},
	isbn = {978-1-4503-1868-6},
	url = {http://doi.acm.org/10.1145/2445196.2445377},
	doi = {10.1145/2445196.2445377},
	abstract = {Educators are often seeking new ways to motivate or inspire students to learn. Our past efforts in K-12 outreach included robotics and media computation as the contexts for teaching Computer Science (CS). With the deep interest in mobile technologies among teenagers, our recent outreach has focused on using smartphones as a new context. This paper is an experience report describing our approach and observations from teaching a summer camp for high school students using App Inventor (AI). The paper describes two separate methods (one using a visual block language, and another using Java) that were taught to high school students as a way to create Android applications. We observed that initiating the instruction with the block language, and then showing the direct mapping to an equivalent Java version, assisted students in understanding app development in Java. Our evaluation of the camp includes observations of student work and artifact assessment of student projects. Although the assessment suggests the camp was successful in several areas, we present numerous lessons learned based on our own reflection on the camp content and instruction.},
	urldate = {2017-01-25TZ},
	booktitle = {Proceeding of the 44th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Wagner, Amber and Gray, Jeff and Corley, Jonathan and Wolber, David},
	year = {2013},
	keywords = {app inventor, java bridge, summer camp},
	pages = {621--626}
}

@inproceedings{nikou_transition_2014,
	title = {Transition in student motivation during a scratch and an app inventor course},
	doi = {10.1109/EDUCON.2014.6826234},
	abstract = {Considering the declining enrolling in computing fields and the increasing demand in STEM disciplines, innovative methods should be employed to attract students in computing disciplines. MIT Scratch and App Inventor for Android visual programming environments are two such approaches. This is a comparative study to investigate any differences in the transition of students' motivation to learn programming using Scratch and App Inventor for Android in K-12 educational settings. Intrinsic goal orientation, task value, control of learning beliefs and self efficacy were found to be increased using these two entry-level learning programming environments from the beginning to the middle of the course. No effect on extrinsic motivation was found. Evaluating the transition in motivation throughout the whole course period for both environments (work in progress) will have an impact on educators to retain students' interest in programming and improve their attitudes towards computing.},
	booktitle = {2014 {IEEE} {Global} {Engineering} {Education} {Conference} ({EDUCON})},
	author = {Nikou, S. A. and Economides, A. A.},
	month = apr,
	year = {2014},
	keywords = {AIA, Android visual programming environments, Androids, App Inventor for Android, AppInventor, Computer languages, Human factors, Humanoid robots, K-12 educational settings, MIT Scratch course, Programming, Programming environments, Programming profession, Scratch, computer aided instruction, computer science education, curriculum, educational courses, educational visual programming environment, entry-level learning programming environments, intrinsic goal orientation, learning beliefs control, motivation, self efficacy, social aspects of automation, student attitude improvement, student interest, student motivation transition, task value, visual programming},
	pages = {1042--1045}
}

@inproceedings{uludag_implementing_2011,
	address = {New York, NY, USA},
	series = {{SIGITE} '11},
	title = {Implementing {IT}0/{CS}0 with {Scratch}, {App} {Inventor} {Forandroid}, and {Lego} {Mindstorms}},
	isbn = {978-1-4503-1017-8},
	url = {http://doi.acm.org/10.1145/2047594.2047645},
	doi = {10.1145/2047594.2047645},
	abstract = {The trend of declining enrollment and interest in computing fields, combined with increased demand from the industry, challenges instructors to come up with new, fresh and appealing methodologies to attract and retain students. Further, with the diffusion of information and computing technologies into almost all fields of study, introductory computing courses for non-majors need approaches that motivate students to feel comfortable with the life-long learning of computing concepts and tools. The goal of this paper is to summarize our teaching experience blending the aforementioned two needs into one course that may be considered as a type of CS0/IT0 course. With the pedagogical underpinnings stemming from constructionist learning and contextualized computing education, we present our motivation and the details of a course that uses the Scratch programming language, App Inventor for Android, and Lego Minstorm robotics.},
	urldate = {2017-01-25TZ},
	booktitle = {Proceedings of the 2011 {Conference} on {Information} {Technology} {Education}},
	publisher = {ACM},
	author = {Uludag, Suleyman and Karakus, Murat and Turner, Stephen W.},
	year = {2011},
	keywords = {CS education, CS0, IT education, IT0, computer science for non-majors, information literacy, introductory programming, novice programming environments},
	pages = {183--190}
}

@inproceedings{wolber_app_2011,
	address = {New York, NY, USA},
	series = {{SIGCSE} '11},
	title = {App {Inventor} and {Real}-world {Motivation}},
	isbn = {978-1-4503-0500-6},
	url = {http://doi.acm.org/10.1145/1953163.1953329},
	doi = {10.1145/1953163.1953329},
	abstract = {App Inventor is a visual "blocks" language for creating mobile apps. As part of a Google pilot program, App Inventor was taught to university students in a core curriculum course at the University of San Francisco. This paper introduces App Inventor and the course, focusing on how the language facilitated interactions with the world outside of the classroom.},
	urldate = {2017-01-25TZ},
	booktitle = {Proceedings of the 42Nd {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Wolber, David},
	year = {2011},
	keywords = {mobile apps, visual programming},
	pages = {601--606}
}

@inproceedings{zhang_empowering_2004,
	title = {Empowering the {User} to {Build} {Smart} {Home} {Applications}},
	abstract = {Recent research has shown that end-user programming will form an important part of any general purpose context-aware computing system, since the system behavior of existing context-aware systems does not reflect the situation the end-user intended. This paper is concerned with end-user programming and modification of context-aware application behavior. We present a three-tier approach to build context-aware applications, which separates context collection and distribution from rule-based inference that controls application behavior. Prototypes were created to evaluate our approach. The primary focus was directed towards the rule conflict management and user interface issue, that are related to defining rules. We conclude this paper with a short usability case study based on these prototypes and an outlook into future work.},
	booktitle = {Proceedings of 2nd {International} {Conference} on {Smart} {Homes} and {Health} ℡ematic (icost2004), {Singapore}, 2004. {Palviainen}, {Marko} {Series}},
	publisher = {Marko Palviainen},
	author = {Zhang, Tao and Brügge, Bernd},
	year = {2004}
}

@article{greenberg_context_2001,
	title = {Context {As} a {Dynamic} {Construct}},
	volume = {16},
	issn = {0737-0024},
	url = {http://dx.doi.org/10.1207/S15327051HCI16234_09},
	doi = {10.1207/S15327051HCI16234_09},
	abstract = {Context is a dynamic construct. Although some contextual situations are fairly stable, discernable, and predictable, there are many others that are not. Similar looking contextual situations may actually differ dramatically, due perhaps to people's previous episodes of use, the state of their social interactions, their changing internal goals, and the nuances of local influences. The consequence is that, for all but simple cases, the designer of a context-aware application may find it difficult or even impossible to (a) enumerate the set of contextual states that may exist, (b) know what information could accurately determine a contextual state within that set, and (c) state what appropriate action should be taken from a particular state.},
	number = {2},
	urldate = {2017-01-22TZ},
	journal = {Hum.-Comput. Interact.},
	author = {Greenberg, Saul},
	month = dec,
	year = {2001},
	pages = {257--268}
}

@article{argall_survey_2009,
	title = {A {Survey} of {Robot} {Learning} from {Demonstration}},
	volume = {57},
	issn = {0921-8890},
	url = {http://dx.doi.org/10.1016/j.robot.2008.10.024},
	doi = {10.1016/j.robot.2008.10.024},
	abstract = {We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research.},
	number = {5},
	urldate = {2017-01-22TZ},
	journal = {Robot. Auton. Syst.},
	author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
	month = may,
	year = {2009},
	keywords = {Autonomous systems, Learning from demonstration, Robotics, machine learning},
	pages = {469--483}
}

@article{fox_integrating_2000,
	title = {Integrating information appliances into an interactive workspace},
	volume = {20},
	issn = {0272-1716},
	doi = {10.1109/38.844373},
	abstract = {The authors present a robust, infrastructure-centric, and platform-independent approach to integrating information appliances into the iRoom, an interactive workspace. The Interactive Workspaces Project at Stanford explores new possibilities for people to work together in technology-rich spaces with computing and interaction devices on many different scales. It includes faculty and students from the areas of graphics, human-computer interaction (HCI), networking, ubiquitous computing, and databases, and draws on previous work in all those areas. We design and experiment with multidevice, multiuser environments based on a new architecture that makes it easy to create and add new display and input devices, to move work of all kinds from one computing device to another, and to support and facilitate group interactions. In the same way that today's standard operating systems make it feasible to write single-workstation software that uses multiple devices and networked resources, we are constructing a higher level operating system for the world of ubiquitous computing. We combine research on infrastructure (ways of flexibly configuring and connecting devices, processes, and communication links) with research on HCI (ways of interacting with heterogeneous changing collections of devices with multiple modalities).},
	number = {3},
	journal = {IEEE Computer Graphics and Applications},
	author = {Fox, A. and Johanson, B. and Hanrahan, P. and Winograd, T.},
	month = may,
	year = {2000},
	keywords = {Computer architecture, Databases, HCI, Home appliances, Human factors, Interactive systems, Operating Systems, Robustness, Space technology, User interfaces, communication links, graphics, group interactions, heterogeneous changing collections, higher level operating system, human computer interaction, human-computer interaction, iRoom, information appliance integration, interaction devices, interactive workspace, multi-access systems, multiple modalities, multiuser environments, network operating systems, pervasive computing, platform-independent approach, technology-rich spaces, ubiquitous computing},
	pages = {54--65}
}

@inproceedings{edwards_at_2001,
	address = {London, UK, UK},
	series = {{UbiComp} '01},
	title = {At {Home} with {Ubiquitous} {Computing}: {Seven} {Challenges}},
	isbn = {978-3-540-42614-1},
	shorttitle = {At {Home} with {Ubiquitous} {Computing}},
	url = {http://dl.acm.org/citation.cfm?id=647987.741327},
	abstract = {The smart home offers a new opportunity to augment people's lives with ubiquitous computing technology that provides increased communications, awareness, and functionality. Recently, a number of trends have increased the likelihood that the aware home can soon become a reality. We examine a number of challenges from the technical, social, and pragmatic domains that we feel must be overcome before the vision of the smart home, posited by ubiquitous computing research, can become a reality. Our hope in raising these issues is to create a conversation among researchers in the varied disciplines that make up ubiquitous computing. In particular, we hope to raise awareness of the existing literature on the adoption, use, and history of domestic technologies, as well as the use of situated studies, and the benefits that these can bring to bear on the design and evaluation of technologies for the home},
	urldate = {2017-01-22TZ},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Ubiquitous} {Computing}},
	publisher = {Springer-Verlag},
	author = {Edwards, W. Keith and Grinter, Rebecca E.},
	year = {2001},
	keywords = {context-awareness, domestic technologies, evaluation, home, ubiquitous computing},
	pages = {256--272}
}
@inproceedings{zhong_smart_2011,
	address = {New York, NY, USA},
	series = {{UbiComp} '11},
	title = {Smart {Home} on {Smart} {Phone}},
	isbn = {978-1-4503-0630-0},
	url = {http://doi.acm.org/10.1145/2030112.2030174},
	doi = {10.1145/2030112.2030174},
	abstract = {Mobile phone with high accessibility and usability is regarded as the ideal interface for the users to monitor and control the approaching smart home environment. Moreover, networking technologies and protocols have been advanced enough to support a universal monitoring and controlling interface on smart phones. This paper presents HouseGenie, an interactive, direct manipulation application on mobile, which supports a range of basic home monitoring and controlling functionalities as a replacement of individual remotes of smart home appliances. HouseGenie also addresses several common requirements that may be behind the vision, such as scenario, short-delay alarm, area restriction and so on. We demonstrate that HouseGenie not only provides intuitive presentations and interactions for smart home management, but also improves user experience comparing to present solutions.},
	urldate = {2017-01-22TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Zhong, Yu and Suo, Yue and Xu, Wenchang and Yu, Chun and Guo, Xinwei and Zhao, Yuhang and Shi, Yuanchun},
	year = {2011},
	keywords = {interaction design, smart home, universal monitor and controller},
	pages = {467--468}
}

@inproceedings{dey_icap:_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{iCAP}: {Interactive} {Prototyping} of {Context}-{Aware} {Applications}},
	copyright = {©2006 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-33894-9 978-3-540-33895-6},
	shorttitle = {{iCAP}},
	url = {http://link.springer.com/chapter/10.1007/11748625_16},
	abstract = {Although numerous context-aware applications have been developed and there have been technological advances for acquiring contextual information, it is still difficult to develop and prototype interesting context-aware applications. This is largely due to the lack of programming support available to both programmers and end-users. This lack of support closes off the context-aware application design space to a larger group of users. We present iCAP, a system that allows end-users to visually design a wide variety of context-aware applications, including those based on if-then rules, temporal and spatial relationships and environment personalization. iCAP allows users to quickly prototype and test their applications without writing any code. We describe the study we conducted to understand end-users’ mental models of context-aware applications, how this impacted the design of our system and several applications that demonstrate iCAP’s richness and ease of use. We also describe a user study performed with 20 end-users, who were able to use iCAP to specify every application that they envisioned, illustrating iCAP’s expressiveness and usability.},
	language = {en},
	urldate = {2017-01-22TZ},
	booktitle = {Pervasive {Computing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dey, Anind K. and Sohn, Timothy and Streng, Sara and Kodama, Justin},
	editor = {Fishkin, Kenneth P. and Schiele, Bernt and Nixon, Paddy and Quigley, Aaron},
	month = may,
	year = {2006},
	doi = {10.1007/11748625_16},
	keywords = {Computer Communication Networks, Computer Engineering, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Operating Systems, Special Purpose and Application-Based Systems},
	pages = {254--271}
}

@inproceedings{humble_playing_2003,
	title = {“{Playing} with the {Bits}” {User}-configuration of {Ubiquitous} {Domestic} {Environments}},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-39653-6_20},
	urldate = {2017-01-19TZ},
	booktitle = {International {Conference} on {Ubiquitous} {Computing}},
	publisher = {Springer},
	author = {Humble, Jan and Crabtree, Andy and Hemmings, Terry and {\textbackslash}AAkesson, Karl-Petter and Koleva, Boriana and Rodden, Tom and Hansson, Pär},
	year = {2003},
	pages = {256--263}
}

@inproceedings{truong_camp:_2004,
	title = {{CAMP}: {A} {Magnetic} {Poetry} {Interface} for {End}-{User} {Programming} of {Capture} {Applications} for the {Home}},
	shorttitle = {{CAMP}},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-30119-6_9},
	abstract = {As the trend towards technology-enriched home environments progresses, the need to enable users to create applications to suit their own lives increases. While several recent projects focus on lowering barriers for application creation by using simplified input mechanisms and languages, these projects often approach application creation from a developer’s perspective, focusing on devices and their interactions, rather than users’ goals or tasks. In this paper, we present a study that examines how users conceptualize applications involving automated capture and playback of home activities and reveals a breadth of home applications that people desire. We introduce CAMP, a system that enables end-user programming for smart home environments based on a magnetic poetry metaphor. We describe how CAMP’s simple interface for creating applications supports users’ natural conceptual models of capture applications. Finally, we present a preliminary evaluation of CAMP and assess its ability to support a breadth of desired home applications as well as the user’s conceptual model.},
	language = {en},
	urldate = {2017-01-19TZ},
	booktitle = {{UbiComp} 2004: {Ubiquitous} {Computing}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Truong, Khai N. and Huang, Elaine M. and Abowd, Gregory D.},
	month = sep,
	year = {2004},
	doi = {10.1007/978-3-540-30119-6_9},
	pages = {143--160}
}

@article{myers_demonstrational_1992,
	title = {Demonstrational interfaces: {A} step beyond direct manipulation},
	volume = {25},
	issn = {0018-9162},
	shorttitle = {Demonstrational interfaces},
	doi = {10.1109/2.153286},
	abstract = {Demonstrational interfaces, interfaces that let the user perform actions on concrete example objects while constructing an abstract program, thus letting the user create parameterized procedures and objects without learning a programming language, are discussed. The motivations for and problems associated with demonstrational interfaces are presented. A survey of the various types of interfaces is also presented. Areas that would benefit from demonstrational technology, including general-purpose programming, visualization, macros for direct-manipulation interfaces, drawing packages, text editing and formatting, and user interface development environments, are discussed. Research issues involving demonstrational interfaces are reviewed.{\textless}{\textgreater}},
	number = {8},
	journal = {Computer},
	author = {Myers, B. A.},
	month = aug,
	year = {1992},
	keywords = {Artificial intelligence, Computer interfaces, Feedback, Heuristic algorithms, Human factors, Inference algorithms, Pattern recognition, Research and development, Uncertainty, User interfaces, abstract program, concrete example objects, demonstrational interfaces, direct manipulation, drawing packages, formatting, general-purpose programming, macros, parameterized procedures, text editing, user interface development environments, visualization},
	pages = {61--73}
}

@inproceedings{guinard_towards_2009,
	title = {Towards physical mashups in the web of things},
	url = {http://ieeexplore.ieee.org/abstract/document/5409925/},
	urldate = {2017-01-19TZ},
	booktitle = {Networked {Sensing} {Systems} ({INSS}), 2009 {Sixth} {International} {Conference} on},
	publisher = {IEEE},
	author = {Guinard, Dominique and Trifa, Vlad and Pham, Thomas and Liechti, Olivier},
	year = {2009},
	pages = {1--4}
}



@article{gama_combining_2012,
	title = {Combining heterogeneous service technologies for building an {Internet} of {Things} middleware},
	volume = {35},
	url = {http://www.sciencedirect.com/science/article/pii/S0140366411003586},
	number = {4},
	urldate = {2017-01-19TZ},
	journal = {Computer Communications},
	author = {Gama, Kiev and Touseau, Lionel and Donsez, Didier},
	year = {2012},
	pages = {405--417}
}

@inproceedings{pintus_anatomy_2011,
	address = {New York, NY, USA},
	series = {{WoT} '11},
	title = {The {Anatomy} of a {Large} {Scale} {Social} {Web} for {Internet} {Enabled} {Objects}},
	isbn = {978-1-4503-0624-9},
	url = {http://doi.acm.org/10.1145/1993966.1993975},
	doi = {10.1145/1993966.1993975},
	abstract = {The ongoing evolution of the Internet of Things toward the Web of Things, where Web-enabled smart objects connect and communicate using the protocols of the Web, has raised several research issues from protocols adoption and communication models to architectural styles. In this paper we present our vision about the anatomy of a scalable architecture for a large scale social Web of Things for smart objects and the solutions adopted. Main faced issues include a reasoned exploration of design choices in conjunction with the related state-of-art analysis, technologies, concepts and social aspects behind our proposed solution. Among them, a prototype is proposed and two experimented scenarios are described. Finally, this paper reports the conclusion, challenges and future works toward the evolution of our social Web of Things architecture and tool.},
	urldate = {2017-01-19TZ},
	booktitle = {Proceedings of the {Second} {International} {Workshop} on {Web} of {Things}},
	publisher = {ACM},
	author = {Pintus, Antonio and Carboni, Davide and Piras, Andrea},
	year = {2011},
	keywords = {REST, Web of Things, computer systems organization, information systems, social networks},
	pages = {6:1--6:6}
}

@inproceedings{guinard_towards_2009-2,
	title = {Towards the web of things: {Web} mashups for embedded devices},
	volume = {15},
	shorttitle = {Towards the web of things},
	url = {http://webofthings.org/2009/04/20/web-mashups-mem/},
	urldate = {2017-01-19TZ},
	booktitle = {Workshop on {Mashups}, {Enterprise} {Mashups} and {Lightweight} {Composition} on the {Web} ({MEM} 2009), in proceedings of {WWW} ({International} {World} {Wide} {Web} {Conferences}), {Madrid}, {Spain}},
	author = {Guinard, Dominique and Trifa, Vlad},
	year = {2009}
}

@article{gonzalez_garcia_midgar:_2014,
	title = {Midgar: {Generation} of heterogeneous objects interconnecting applications. {A} {Domain} {Specific} {Language} proposal for {Internet} of {Things} scenarios},
	volume = {64},
	issn = {1389-1286},
	shorttitle = {Midgar},
	url = {http://www.sciencedirect.com/science/article/pii/S1389128614000528},
	doi = {10.1016/j.comnet.2014.02.010},
	abstract = {Smart Objects and Internet of Things are two ideas that describe the future. The interconnection of objects can make them intelligent or expand their intelligence. This is achieved by a network that connects all the objects in the world. A network where most of the data traffic comes from objects instead of people. Cities, houses, cars or any other objects that come to life, respond, work and make their owner’s life easier. This is part of that future. But first, there are many basic problems that must be solved. In this paper we propose solutions for many of these problems: the interconnection of ubiquitous, heterogeneous objects and the generation of applications allow inexperienced people to interconnect them. For that purpose, we present three possible solutions: a Domain Specific Language capable of abstracting the application generation problem; a graphic editor that simplifies the creation of that DSL; and an IoT platform (Midgar) able to interconnect different objects between them. Through Midgar, you can register objects and create interconnection between ubiquitous and heterogeneous objects through a graphic editor that generates a model defined by the DSL. From this model, Midgar generates the interconnection defined by the user with the graphical editor.},
	urldate = {2017-01-19TZ},
	journal = {Computer Networks},
	author = {González García, Cristian and Pelayo G-Bustelo, B. Cristina and Pascual Espada, Jordán and Cueva-Fernandez, Guillermo},
	month = may,
	year = {2014},
	keywords = {Domain Specific Language, Internet of Things, Model Driven Engineering, Sensor network, Smart Objects, ubiquitous computing},
	pages = {143--158}
}

@article{barricelli_visual_nodate,
	title = {A visual language and interactive system for end-user development of internet of things ecosystems},
	issn = {1045-926X},
	url = {http://www.sciencedirect.com/science/article/pii/S1045926X16300295},
	doi = {10.1016/j.jvlc.2017.01.004},
	abstract = {This paper presents the definition of a visual language and its implementation with the design of a visual interactive system for the collaborative management of Internet of Things (IoT) sensors (e.g., wearable fitness trackers, ambient sensors, fitness apps, nutrition apps, sleep trackers) for improving people's quality of life and promoting wellness awareness. The system, called SmartFit Rule Editor, is designed to be used by coaches and trainers of non-professional teams of athletes for monitoring and analyze fitness and wellness data streams and to support them in detecting relevant events and specifying rules for actions taking. Our research is framed under the scope of computer semiotics and semiotic engineering theories. This allows us to study how to support coaches and trainers as a community of domain experts – but not IT and IoT experts – to use elements of a visual language to indirectly manage physical devices and their data streams without the need to know technical specification of the devices, the apps, and the data. We apply a socio-technical approach to design being able to study the social and the technological aspects of the use of the Internet of Things ecosystem, considering them as closely interconnected and dependent. Such an approach underpins user-centered design and development methodologies in order to design the most suitable User eXperience according to users' culture, needs, context of use, and activity.},
	urldate = {2017-01-19TZ},
	journal = {Journal of Visual Languages \& Computing},
	author = {Barricelli, Barbara Rita and Valtolina, Stefano},
	keywords = {Event detection, Internet of Things, Rule Editor, Sociotechnical design, Unwitting developers, Visual interactive system, Visual language, eWellness, end-user development}
}

@inproceedings{bohmer_whats_2013,
	address = {New York, NY, USA},
	series = {{UbiComp} '13 {Adjunct}},
	title = {What's in the {Apps} for {Context}?: {Extending} a {Sensor} for {Studying} {App} {Usage} to {Informing} {Context}-awareness},
	isbn = {978-1-4503-2215-7},
	shorttitle = {What's in the {Apps} for {Context}?},
	url = {http://doi.acm.org/10.1145/2494091.2496038},
	doi = {10.1145/2494091.2496038},
	abstract = {Mobile phones became multi-purpose devices supporting their users with large variety of applications for various tasks. Not only the number of available applications is increasing, also the number of applications people are using on their devices is growing, as well as the amount of time people spent on their smartphones daily is getting bigger. In this workshop paper, we briefly describe our past work on understanding mobile application usage. We explain our research tool for measuring mobile application usage, called AppSensor, and discuss possibilities to exploit the information of mobile application usage to inform the reasoning about users' contexts. We contribute our source code to the workshop for a discussion and prototyping of use cases leveraging the information of which application a user is currently using.},
	urldate = {2017-01-18TZ},
	booktitle = {Proceedings of the 2013 {ACM} {Conference} on {Pervasive} and {Ubiquitous} {Computing} {Adjunct} {Publication}},
	publisher = {ACM},
	author = {Böhmer, Matthias and Lander, Christian and Krüger, Antonio},
	year = {2013},
	keywords = {app stores, context-awareness, in the large, mobile applications, open source, studies, virtual sensor},
	pages = {1423--1426}
}

@inproceedings{jesdabodi_understanding_2015,
	address = {New York, NY, USA},
	series = {{UbiComp} '15},
	title = {Understanding {Usage} {States} on {Mobile} {Devices}},
	isbn = {978-1-4503-3574-4},
	url = {http://doi.acm.org/10.1145/2750858.2805837},
	doi = {10.1145/2750858.2805837},
	abstract = {Nowadays, mobile apps are used for nearly every situation: for planning the day, communicating with colleagues, ordering goods, or entertaining and socializing. To understand users expectations in each situation and to provide context-aware services, researchers and app vendors started to capture users' interaction with the smartphone and to model user's behavior. This paper reports on a behavioral study based on app usage data logged over one year and the corresponding apps descriptions from the app store. Using Topic Modeling and clustering techniques, we segmented the usage data into meaningful clusters that correspond to different "states", in which users normally use their smartphone, e.g. socializing or consuming media. Researchers and app-vendors can use the insights from our work to improve their contextual recommendation techniques and the overall usage experience.},
	urldate = {2017-01-18TZ},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Jesdabodi, Chakajkla and Maalej, Walid},
	year = {2015},
	keywords = {apps, behavioral profiles, intent identification, usage data},
	pages = {1221--1225}
}

@inproceedings{de_russis_homerules:_2015,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '15},
	title = {{HomeRules}: {A} {Tangible} {End}-{User} {Programming} {Interface} for {Smart} {Homes}},
	isbn = {978-1-4503-3146-3},
	shorttitle = {{HomeRules}},
	url = {http://doi.acm.org/10.1145/2702613.2732795},
	doi = {10.1145/2702613.2732795},
	abstract = {A considerable amount of research has been carried out towards enabling average users to customize their smart homes through trigger-action ("if... then...") programming. However, inhabitants of such smart environments keep having problems understanding, administering, troubleshooting, and deriving benefits from the technologies employed in their homes. By synthesizing a broad body of research on end-user programming in smart homes with observations of commercial products and our own experiences, we provide a set of guidelines for designers of future interfaces and tools. Stemming from them, we present the design and the initial evaluation of HomeRules, a mobile and tangible application for end-user programming in smart homes.},
	urldate = {2017-01-18TZ},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {De Russis, Luigi and Corno, Fulvio},
	year = {2015},
	keywords = {end-user programming, guidelines, home automation, mobile programming, smart home},
	pages = {2109--2114}
}

@inproceedings{demeure_building_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Building and {Using} {Home} {Automation} {Systems}: {A} {Field} {Study}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-18424-1 978-3-319-18425-8},
	shorttitle = {Building and {Using} {Home} {Automation} {Systems}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-18425-8_9},
	abstract = {These last years, several new home automation boxes appeared on the market, the new radio-based protocols facilitating their deployment with respect to previously wired solutions. Coupled with the wider availability of connected objects, these protocols have allowed new users to set up home automation systems by themselves. In this paper, we relate an in situ observational study of these builders in order to understand why and how the smart habitats were developed and used. We led 10 semi-structured interviews in households composed of at least 2 adults and equipped for at least 1 year, and 47 home automation builders answered an online questionnaire at the end of the study. Our study confirms, specifies and exhibits additional insights about usages and means of end-user development in the context of home automation.},
	language = {en},
	urldate = {2017-01-09TZ},
	booktitle = {End-{User} {Development}},
	publisher = {Springer International Publishing},
	author = {Demeure, A. and Caffiau, S. and Elias, E. and Roux, C.},
	editor = {Díaz, Paloma and Pipek, Volkmar and Ardito, Carmelo and Jensen, Carlos and Aedo, Ignacio and Boden, Alexander},
	month = may,
	year = {2015},
	doi = {10.1007/978-3-319-18425-8_9},
	keywords = {Computers and Society, End user development, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction, field study, home automation, software engineering},
	pages = {125--140}
}

@inproceedings{barricelli_designing_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Designing for {End}-{User} {Development} in the {Internet} of {Things}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-18424-1 978-3-319-18425-8},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-18425-8_2},
	abstract = {With the widespread of Internet of Things’ devices, sensors, and applications the quantity of collected data grows enormously and the need of extracting, merging, analyzing, visualizing, and sharing it paves the way for new research challenges. This ongoing revolution of how personal devices are used and how they are becoming more and more wearable has important influences on the most well established definitions of end user and end-user development. The paper presents an analysis of the most diffused applications that allow end users to aggregate quantified-self data, originated by several sensors and devices, and to use it in personalized ways. From the outcomes of the analysis, we present a classification model for Internet of Things and new EUD paradigm and language that extends the ones existing in the current state of the art Internet of Things.},
	language = {en},
	urldate = {2017-01-09TZ},
	booktitle = {End-{User} {Development}},
	publisher = {Springer International Publishing},
	author = {Barricelli, Barbara Rita and Valtolina, Stefano},
	editor = {Díaz, Paloma and Pipek, Volkmar and Ardito, Carmelo and Jensen, Carlos and Aedo, Ignacio and Boden, Alexander},
	month = may,
	year = {2015},
	doi = {10.1007/978-3-319-18425-8_2},
	keywords = {Computers and Society, Information Systems Applications (incl. Internet), Internet of Things, Lifelogging, Quantified self, Unwitting developers, User Interfaces and Human Computer Interaction, end users, end-user development, mobile devices, pervasive computing, software engineering},
	pages = {9--24}
}

@inproceedings{raffle_beyond_2006,
	address = {New York, NY, USA},
	series = {{CHI} '06},
	title = {Beyond {Record} and {Play}: {Backpacks}: {Tangible} {Modulators} for {Kinetic} {Behavior}},
	isbn = {978-1-59593-372-0},
	shorttitle = {Beyond {Record} and {Play}},
	url = {http://doi.acm.org/10.1145/1124772.1124874},
	doi = {10.1145/1124772.1124874},
	abstract = {Digital Manipulatives embed computation in familiar children's toys and provide means for children to design behavior. Some systems use "record and play" as a form of programming by demonstration that is intuitive and easy to learn. With others, children write symbolic programs with a GUI and download them into a toy, an approach that is conceptually extensible, but is inconsistent with the physicality of educational manipulatives. The challenge we address is to create a tangible interface that can retain the immediacy and emotional engagement of "record and play" and incorporate a mechanism for real time and direct modulation of behavior during program execution.We introduce the Backpacks, modular physical components that children can incorporate into robotic creations to modulate frequency, amplitude, phase and orientation of motion recordings. Using Backpacks, children can investigate basic kinematic principles that underly why their specific creations exhibit the specific behaviors they observe. We demonstrate that Backpacks make tangible some of the benefits of symbolic abstraction, and introduce sensors, feedback and behavior modulation to the record and play paradigm. Through our review of user studies with children ages 6-15, we argue that Backpacks extend the conceptual limits of record and play with an interface that is consistent with both the physicality of educational manipulatives and the local-global systems dynamics that are characteristic of complex robots.},
	urldate = {2017-01-09TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Raffle, Hayes and Parkes, Amanda and Ishii, Hiroshi and Lifton, Joshua},
	year = {2006},
	keywords = {children, digital manipulative, education, learning, modular robotics, programming by demonstration, tangible interface, toy},
	pages = {681--690}
}

@inproceedings{schmidt_programming_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Programming {Ubiquitous} {Computing} {Environments}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-18424-1 978-3-319-18425-8},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-18425-8_1},
	abstract = {Computing becomes a part of our everyday environment. Interaction in the “real world” is more and more determined by ubiquitous computing systems that are tailored to fit a specific environment. These systems can only be created with strong domain knowledge. End users may be the right group to develop or at least tailor such systems. We show two examples of how domain expert can program systems: one looks at how to transfer programming by demonstration to ubicomp scenarios and the other on how to use examples as recipes for a new development. In the outlook we extrapolate from current practices of sharing videos to a future where multimodal and sensor-rich examples can be continuously recorded and may become the basis for new approaches for a truly user-centered development of cyber-physical systems.},
	language = {en},
	urldate = {2017-01-09TZ},
	booktitle = {End-{User} {Development}},
	publisher = {Springer International Publishing},
	author = {Schmidt, Albrecht},
	editor = {Díaz, Paloma and Pipek, Volkmar and Ardito, Carmelo and Jensen, Carlos and Aedo, Ignacio and Boden, Alexander},
	month = may,
	year = {2015},
	doi = {10.1007/978-3-319-18425-8_1},
	keywords = {Computers and Society, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction, software engineering},
	pages = {3--6}
}

@inproceedings{mennicken_todays_2014,
	address = {New York, NY, USA},
	series = {{UbiComp} '14},
	title = {From {Today}'s {Augmented} {Houses} to {Tomorrow}'s {Smart} {Homes}: {New} {Directions} for {Home} {Automation} {Research}},
	isbn = {978-1-4503-2968-2},
	shorttitle = {From {Today}'s {Augmented} {Houses} to {Tomorrow}'s {Smart} {Homes}},
	url = {http://doi.acm.org/10.1145/2632048.2636076},
	doi = {10.1145/2632048.2636076},
	abstract = {A considerable amount of research has been carried out towards making long-standing smart home visions technically feasible. The technologically augmented homes made possible by this work are starting to become reality, but thus far living in and interacting with such homes has introduced significant complexity while offering limited benefit. As these technologies are increasingly adopted, the knowledge we gain from their use suggests a need to revisit the opportunities and challenges they pose. Synthesizing a broad body of research on smart homes with observations of industry and experiences from our own empirical work, we provide a discussion of ongoing and emerging challenges, namely challenges for meaningful technologies, complex domestic spaces, and human-home collaboration. Within each of these three challenges we discuss our visions for future smart homes and identify promising directions for the field.},
	urldate = {2017-01-07TZ},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Mennicken, Sarah and Vermeulen, Jo and Huang, Elaine M.},
	year = {2014},
	keywords = {domestic technologies, home automation, smart homes},
	pages = {105--115}
}

@inproceedings{schmidt_programming_2015-1,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Programming {Ubiquitous} {Computing} {Environments}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-18424-1 978-3-319-18425-8},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-18425-8_1},
	abstract = {Computing becomes a part of our everyday environment. Interaction in the “real world” is more and more determined by ubiquitous computing systems that are tailored to fit a specific environment. These systems can only be created with strong domain knowledge. End users may be the right group to develop or at least tailor such systems. We show two examples of how domain expert can program systems: one looks at how to transfer programming by demonstration to ubicomp scenarios and the other on how to use examples as recipes for a new development. In the outlook we extrapolate from current practices of sharing videos to a future where multimodal and sensor-rich examples can be continuously recorded and may become the basis for new approaches for a truly user-centered development of cyber-physical systems.},
	language = {en},
	urldate = {2017-01-04TZ},
	booktitle = {End-{User} {Development}},
	publisher = {Springer International Publishing},
	author = {Schmidt, Albrecht},
	editor = {Díaz, Paloma and Pipek, Volkmar and Ardito, Carmelo and Jensen, Carlos and Aedo, Ignacio and Boden, Alexander},
	month = may,
	year = {2015},
	doi = {10.1007/978-3-319-18425-8_1},
	keywords = {Computers and Society, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction, software engineering},
	pages = {3--6}
}

@inproceedings{ur_practical_2014,
	address = {New York, NY, USA},
	series = {{CHI} '14},
	title = {Practical {Trigger}-action {Programming} in the {Smart} {Home}},
	isbn = {978-1-4503-2473-1},
	url = {http://doi.acm.org/10.1145/2556288.2557420},
	doi = {10.1145/2556288.2557420},
	abstract = {We investigate the practicality of letting average users customize smart-home devices using trigger-action ("if, then") programming. We find trigger-action programming can express most desired behaviors submitted by participants in an online study. We identify a class of triggers requiring machine learning that has received little attention. We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that real users have written a large number of unique trigger-action interactions. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.},
	urldate = {2017-01-04TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ur, Blase and McManus, Elyse and Pak Yong Ho, Melwyn and Littman, Michael L.},
	year = {2014},
	keywords = {Internet of Things, condition-action programming, end-user programming, home automation, smart home},
	pages = {803--812}
}

@misc{toby_li_video_nodate,
	title = {Video {DEMO} - {SUGILITE}: {Creating} {Multimodal} {Smartphone} {Automation} by {Demonstration}},
	shorttitle = {Video {DEMO} - {SUGILITE}},
	url = {https://www.youtube.com/watch?v=IocwhPwy5N4},
	urldate = {2016-12-14TZ},
	author = {{Toby Li}}
}

@article{myers_using_2005,
	title = {Using handhelds for wireless remote control of {PCs} and appliances},
	volume = {17},
	abstract = {This article provides an overview of the capabilities that we are developing as part of the Pebbles research project for wireless handheld devices such as mobile phones and palm-size computers like Palm Organizers and PocketPCs. Instead of just being used as a phone or organizer, handheld devices can also be used as remote controls for computers and household and office appliances. q 2004 Elsevier B.V. All rights reserved.},
	journal = {Interacting with Computers},
	author = {Myers, Brad A.},
	year = {2005},
	pages = {251--264}
}

@inproceedings{rekimoto_multiple_1998,
	address = {New York, NY, USA},
	series = {{CHI} '98},
	title = {A {Multiple} {Device} {Approach} for {Supporting} {Whiteboard}-based {Interactions}},
	isbn = {978-0-201-30987-4},
	url = {http://dx.doi.org/10.1145/274644.274692},
	doi = {10.1145/274644.274692},
	urldate = {2016-10-10TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM Press/Addison-Wesley Publishing Co.},
	author = {Rekimoto, Jun},
	year = {1998},
	keywords = {CSCW, digital whiteboard, multi-computer user interfaces, pick-and-drop, ubiquitous computing},
	pages = {344--351}
}

@inproceedings{nichols_generating_2002,
	address = {New York, NY, USA},
	series = {{UIST} '02},
	title = {Generating {Remote} {Control} {Interfaces} for {Complex} {Appliances}},
	isbn = {978-1-58113-488-9},
	url = {http://doi.acm.org/10.1145/571985.572008},
	doi = {10.1145/571985.572008},
	abstract = {The personal universal controller (PUC) is an approach for improving the interfaces to complex appliances by introducing an intermediary graphical or speech interface. A PUC engages in two-way communication with everyday appliances, first downloading a specification of the appliance's functions, and then automatically creating an interface for controlling that appliance. The specification of each appliance includes a high-level description of every function, a hierarchical grouping of those functions, and dependency information, which relates the availability of each function to the appliance's state. Dependency information makes it easier for designers to create specifications and helps the automatic interface generators produce a higher quality result. We describe the architecture that supports the PUC, and the interface generators that use our specification language to build high-quality graphical and speech interfaces.},
	urldate = {2016-10-10TZ},
	booktitle = {Proceedings of the 15th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Nichols, Jeffrey and Myers, Brad A. and Higgins, Michael and Hughes, Joseph and Harris, Thomas K. and Rosenfeld, Roni and Pignol, Mathilde},
	year = {2002},
	keywords = {appliances, handheld computers, pebbles, personal digital assistants (PDAs), personal universal controller (PUC), remote control, universal speech interface (USI)},
	pages = {161--170}
}

@article{ko_state_2011,
	title = {The {State} of the {Art} in {End}-user {Software} {Engineering}},
	volume = {43},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/1922649.1922658},
	doi = {10.1145/1922649.1922658},
	abstract = {Most programs today are written not by professional software developers, but by people with expertise in other domains working towards goals for which they need computational support. For example, a teacher might write a grading spreadsheet to save time grading, or an interaction designer might use an interface builder to test some user interface design ideas. Although these end-user programmers may not have the same goals as professional developers, they do face many of the same software engineering challenges, including understanding their requirements, as well as making decisions about design, reuse, integration, testing, and debugging. This article summarizes and classifies research on these activities, defining the area of End-User Software Engineering (EUSE) and related terminology. The article then discusses empirical research about end-user software engineering activities and the technologies designed to support them. The article also addresses several crosscutting issues in the design of EUSE tools, including the roles of risk, reward, and domain complexity, and self-efficacy in the design of EUSE tools and the potential of educating users about software engineering principles.},
	number = {3},
	urldate = {2016-10-10TZ},
	journal = {ACM Comput. Surv.},
	author = {Ko, Amy J. and Abraham, Robin and Beckwith, Laura and Blackwell, Alan and Burnett, Margaret and Erwig, Martin and Scaffidi, Chris and Lawrance, Joseph and Lieberman, Henry and Myers, Brad and Rosson, Mary Beth and Rothermel, Gregg and Shaw, Mary and Wiedenbeck, Susan},
	month = apr,
	year = {2011},
	keywords = {end-user development, end-user programming, end-user software engineering, human-computer interaction, visual programming},
	pages = {21:1--21:44}
}

@inproceedings{ricquebourg_smart_2006,
	title = {The {Smart} {Home} {Concept} : our immediate future},
	shorttitle = {The {Smart} {Home} {Concept}},
	doi = {10.1109/ICELIE.2006.347206},
	abstract = {This general paper aims at presenting the Smart Home concept. In this paper, we will detail a) the Smart Home concept b) the various networks infrastructures specific to the habitat c) our concepts to model the habitat and to provide the most adapted services to the inhabitants. Contrary to the other projects, we direct our work towards a sensors approach and an ontology modelling of the Smart Home. Our work has the originality to take into account the real heterogeneity of information present in a habitat and use a service oriented approach (SOA). We can say that our paper is a good overview to present what is a Smart Home and which are the necessary hardware and software components to make a Smart Home},
	booktitle = {2006 1ST {IEEE} {International} {Conference} on {E}-{Learning} in {Industrial} {Electronics}},
	author = {Ricquebourg, V. and Menga, D. and Durand, D. and Marhic, B. and Delahoche, L. and Loge, C.},
	month = dec,
	year = {2006},
	keywords = {Automatic control, Control systems, IP networks, Intelligent sensors, Internet, Lighting control, Monitoring, Optical fiber cables, Smart Home concept, home automation, home computing, network infrastructures, ontologies (artificial intelligence), ontology modelling, service oriented approach, smart homes},
	pages = {23--28}
}

@inproceedings{chen_matrix_2015,
	title = {Matrix factorization with domain knowledge and behavioral patterns for intent modeling},
	url = {https://www.researchgate.net/profile/Yun_Nung_Chen/publication/286931689_Matrix_Factorization_with_Domain_Knowledge_and_Behavioral_Patterns_for_Intent_Modeling/links/5670fd4508aececfd5534f6f.pdf},
	urldate = {2016-09-16TZ},
	booktitle = {{NIPS} {Workshop} on {Machine} {Learning} for {SLU} and {Interaction}},
	author = {Chen, Yun-Nung and Sun, Ming and Rudnicky, Alexander I.},
	year = {2015}
}

@inproceedings{chen_unsupervised_2016,
	title = {Unsupervised user intent modeling by feature-enriched matrix factorization},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7472859},
	urldate = {2016-09-16TZ},
	booktitle = {2016 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Chen, Yun-Nung and Sun, Ming and Rudnicky, Alexander I. and Gershman, Anatole},
	year = {2016},
	pages = {6150--6154}
}

@inproceedings{sun_helpr:_2016,
	title = {{HELPR}: {A} {Framework} to {Break} the {Barrier} across {Domains} in {Spoken} {Dialog} {Systems}},
	shorttitle = {{HELPR}},
	urldate = {2016-09-16TZ},
	booktitle = {International {Workshop} on {Spoken} {Dialog} {Systems}},
	author = {Sun, Ming and Chen, Yun-Nung and Rudnicky, Alexander I.},
	year = {2016}
}

@inproceedings{zhao_discovering_2016,
	address = {New York, NY, USA},
	series = {{UbiComp} '16},
	title = {Discovering {Different} {Kinds} of {Smartphone} {Users} {Through} {Their} {Application} {Usage} {Behaviors}},
	isbn = {978-1-4503-4461-6},
	url = {http://doi.acm.org/10.1145/2971648.2971696},
	doi = {10.1145/2971648.2971696},
	abstract = {Understanding smartphone users is fundamental for creating better smartphones, and improving the smartphone usage experience and generating generalizable and reproducible research. However, smartphone manufacturers and most of the mobile computing research community make a simplifying assumption that all smartphone users are similar or, at best, constitute a small number of user types, based on their behaviors. Manufacturers design phones for the broadest audience and hope they work for all users. Researchers mostly analyze data from smartphone-based user studies and report results without accounting for the many different groups of people that make up the user base of smartphones. In this work, we challenge these elementary characterizations of smartphone users and show evidence of the existence of a much more diverse set of users. We analyzed one month of application usage from 106,762 Android users and discovered 382 distinct types of users based on their application usage behaviors, using our own two-step clustering and feature ranking selection approach. Our results have profound implications on the reproducibility and reliability of mobile computing studies, design and development of applications, determination of which apps should be pre-installed on a smartphone and, in general, on the smartphone usage experience for different types of users.},
	urldate = {2016-09-15TZ},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Zhao, Sha and Ramos, Julian and Tao, Jianrong and Jiang, Ziwen and Li, Shijian and Wu, Zhaohui and Pan, Gang and Dey, Anind K.},
	year = {2016},
	keywords = {clustering, user groups},
	pages = {498--509}
}

@misc{khalaf_seven_nodate,
	title = {Seven {Years} {Into} {The} {Mobile} {Revolution}: {Content} is {King}… {Again}},
	shorttitle = {Seven {Years} {Into} {The} {Mobile} {Revolution}},
	year = {2015},
	abstract = {By Simon Khalaf, SVP Publishing Products 

 Last year, on the eve of the sixth anniversary of the mobile revolution, Flurry issued our annual report on the mobile industry. In that report, we analyzed time spent on a mobile device by the average American consumer. We ran the same analysis in Q2 of this year and found interesting trends we are sharing in this report. 

 After putting the desktop web in the rear view mirror in Q2 2011, and eclipsing television in Q4 2014, mobile and its apps have cemented their position as the top media channel and grabbed more time spent from the average American consumer. In Q2 of 2015, American consumers spent, on average, 3 hrs and 40 minutes per day on their mobile devices. That is a 35\% increase in time spent from one year ago and a 24\% increase from Q4 2014. In just six short months, the average time American consumers spend on their phones each day increased by 43 minutes. 

 To put things in perspective, there are 175 million Americans with at least one mobile device. This means that, in aggregate, since November 2014, the US connected population is spending an extra 125 million hours per day on mobile devices. This growth rate is especially astonishing after seven consecutive growth years. 

 The Browser: Sidelined

 Looking at the chart above, today only 10\% of the time spent on mobile is spent in the browser, down from 14\% a year ago. The rest of the time, 90\%, is spent in apps. Effectively, the browser has been sidelined on mobile. This has major implications on the digital industry in general and the content and media industry in particular. Historically, the media industry has relied almost entirely on search for user and traffic acquisition, building entire teams around SEO and SEM on the desktop web. But search engines are predominantly accessed from a browser. If mobile users aren’t using browsers, the media industry will have to look for new approaches to content discovery and  traffic acquisition. 

 The Media Industry: Absorbed by Apps

 The chart below takes a closer look at app categories. Social, Messaging and Entertainment apps (including YouTube), account for 51\% of time spent on mobile. 

 Entertainment (including YouTube) grew from 8\% of time spent last year, or 13 minutes per day, to 20\% of time spent, or 44 minutes per day this year. This is 240\% growth year-over-year, or an extra 31 minutes. That is more than the time it would take to watch an additional TV sitcom for every US consumer, every day! 

 Messaging and Social apps grew from 28\% of time spent last year or 45 minutes per day to 31\% of time spent or slightly more than 68 minutes per day this year. This is a 50\% year-over-year increase. However, the majority of time spent inside messaging and social apps is actually spent consuming media, such as videos on Tumblr and Facebook or stories on Snapchat. A study by Millward Brown Digital showed that 70\% of social app users are actually consuming media. While we can’t correlate the 70\% directly to time spent, we firmly believe that media consumption, either articles read in the web view in app, or video consumed in the feeds, constitute the majority of time spent in social apps. This is a big trend and one that will be watched very carefully by traditional media companies. These companies have to adjust to a new world where consumers act as individual distribution channels. The growth in entertainment on mobile proves once again that content is in fact king and is beating the gaming industry in its own game.  

 The Gaming Industry: Time is Money

 The completely unexpected result of our analysis this year is the dramatic decline in time spent for mobile gaming. Gaming saw its share decline from 32\% last year (52 minutes per day) to 15\% of time spent (33 minutes per day) this year. This is a 37\% decline year-over-year. We believe there are three factors contributing to the decline. 

 
 Lack of new hits: Gaming is a hit driven industry and there hasn’t been a major new hit the past 6 to nine months. The major titles like Supercell’s Clash of Clans, King’s Candy Crush, and Machine Zone’s Game of War continue to dominate the top grossing charts and haven’t made room for a major new entrant. 

 Users become the game: Millennials are shifting from playing games to watching others play games, creating a new category of entertainment called eSports. This summer, Fortune named eSports, the new Saturday morning cartoons for millennials. In fact, some of the most watched content on Tumblr is Minecraft videos created and curated by the passionate Minecraft community. 

 Pay instead of play: Gamers are buying their way into games versus grinding their way through them. Gamers are spending more money than time to effectively beat games or secure better standings rather than working  their way to the top. This explains the decline in time spent and the major rise in in-app purchases, as Apple saw a record \$1.7B in AppStore sales in July. 


 What the mobile industry in general and the app industry in particular have achieved in the past seven years is amazing. Flurry now measures more than two billion devices each month and sees more than 10 billion sessions per day. That is 1.42 sessions for every human being on this planet, every day. And that is just Flurry! If there is anything to say about the mobile and app industry it is this: Mobile is on fire and it is showing no signs of stopping.},
	journal = {Yahoo Developer Network},
	author = {Khalaf, Simon}
}

@misc{nielsen_so_2015,
	title = {So {Many} {Apps}, {So} {Much} {More} {Time} for {Entertainment}},
	author = {Nielsen},
	year = {2015}
}

@article{namoun_exploring_2016,
	title = {Exploring {Mobile} {End} {User} {Development}: {Existing} {Use} and {Design} {Factors}},
	volume = {PP},
	issn = {0098-5589},
	shorttitle = {Exploring {Mobile} {End} {User} {Development}},
	doi = {10.1109/TSE.2016.2532873},
	abstract = {Mobile devices are everywhere, and the scope of their use is growing from simple calling and texting through Internet browsing to more technical activities such as creating message processing filters and connecting different apps. However, building tools which provide effective support for such advanced technical use of mobile devices by non-programmers (mobile end user development or mEUD) requires thorough understanding of user needs and motivations, including factors which can impact user intentions regarding mEUD activities. We propose a model linking these mEUD factors with mobile users‘ attitudes towards, and intent of doing mEUD, and discuss a number of implications for supporting mEUD. Our research process is user-centered, and we formulate a number of hypotheses by fusing results from an exploratory survey which gathers facts about mEUD motivations and activities, and from a focus group study, which delivers deeper understanding of particular mEUD practices and issues. We then test the hypothesized relationships through a follow-up enquiry mixing quantitative and qualitative techniques, leading to the creation of a preliminary mEUD model. Altogether we have involved 275 mobile users in our research. Our contribution links seven mEUD factors with mEUD intentions and attitudes, and highlights a number of implications for mEUD support.},
	number = {99},
	journal = {IEEE Transactions on Software Engineering},
	author = {Namoun, A. and Daskalopoulou, A. and Mehandjiev, N. and Xun, Z.},
	year = {2016},
	keywords = {Electronic mail, Games, Human Factors in Software Design, Mashups, Mobile Environments, Mobile communication, Models and Principles, context, mobile handsets},
	pages = {1--1}
}

@inproceedings{myers_visual_1986,
	address = {New York, NY, USA},
	series = {{CHI} '86},
	title = {Visual {Programming}, {Programming} by {Example}, and {Program} {Visualization}: {A} {Taxonomy}},
	isbn = {978-0-89791-180-1},
	shorttitle = {Visual {Programming}, {Programming} by {Example}, and {Program} {Visualization}},
	url = {http://doi.acm.org/10.1145/22627.22349},
	doi = {10.1145/22627.22349},
	abstract = {There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms “Visual Programming” and “Program Visualization” have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called “Programming by Example.” This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.},
	urldate = {2016-09-13TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Myers, Brad. A.},
	year = {1986},
	pages = {59--66}
}

@inproceedings{mcdaniel_getting_1999,
	address = {New York, NY, USA},
	series = {{CHI} '99},
	title = {Getting {More} out of {Programming}-by-demonstration},
	isbn = {978-0-201-48559-2},
	url = {http://doi.acm.org/10.1145/302979.303127},
	doi = {10.1145/302979.303127},
	abstract = {Programming-by-demonstration (PBD) can be used to create tools
and methods that eliminate the need to learn difficult computer
languages. Gamut is a PBD tool that nonprogrammers can use to
create a broader range of interactive software, including games,
simulations, and educational software, than they can with other PBD
tools. To do this, Gamut provides advanced interaction techniques
that make it easier for a developer to express all aspects of an
application. These techniques include a simplified way to
demonstrate new examples, called nudges, and a way to highlight
objects to show they are important. Also, Gamut includes new
objects and metaphors like the deck-of-cards metaphor for
demonstrating collections of objects and randomness, guide objects
for demonstrating relationships that the system would find too
difficult to guess, and temporal ghosts which simplify showing
relationships with the recent past. These techniques were tested in
a formal setting with nonprogrammers to evaluate their
effectiveness.},
	urldate = {2016-09-13TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {McDaniel, Richard G. and Myers, Brad A.},
	year = {1999},
	keywords = {Gamut, application builders, end-user programming, inductive learning, programming-by-demonstration, programming-by-example, user interface software},
	pages = {442--449}
}

@inproceedings{frank_model-based_1993,
	address = {New York, NY, USA},
	series = {{UIST} '93},
	title = {Model-based {User} {Interface} {Design} by {Example} and by {Interview}},
	isbn = {978-0-89791-628-8},
	url = {http://doi.acm.org/10.1145/168642.168655},
	doi = {10.1145/168642.168655},
	urldate = {2016-09-13TZ},
	booktitle = {Proceedings of the 6th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Frank, Martin R. and Foley, James D.},
	year = {1993},
	keywords = {model-based user interface design, user interface management systems},
	pages = {129--137}
}

@inproceedings{lau_programming_1999,
	address = {New York, NY, USA},
	series = {{IUI} '99},
	title = {Programming by {Demonstration}: {An} {Inductive} {Learning} {Formulation}},
	isbn = {978-1-58113-098-0},
	shorttitle = {Programming by {Demonstration}},
	url = {http://doi.acm.org/10.1145/291080.291104},
	doi = {10.1145/291080.291104},
	urldate = {2016-09-12TZ},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Lau, Tessa A. and Weld, Daniel S.},
	year = {1999},
	keywords = {inductive logic programming, machine learning, programming by demonstration, version spaces},
	pages = {145--152}
}

@article{maes_agents_1994,
	title = {Agents {That} {Reduce} {Work} and {Information} {Overload}},
	volume = {37},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/176789.176792},
	doi = {10.1145/176789.176792},
	number = {7},
	urldate = {2016-09-12TZ},
	journal = {Commun. ACM},
	author = {Maes, Pattie},
	month = jul,
	year = {1994},
	pages = {30--40}
}

@book{shneiderman_designing_2016,
	address = {Boston},
	edition = {6 edition},
	title = {Designing the {User} {Interface}: {Strategies} for {Effective} {Human}-{Computer} {Interaction}},
	isbn = {978-0-13-438038-4},
	shorttitle = {Designing the {User} {Interface}},
	abstract = {For courses in Human-Computer Interaction                                                                             The Sixth Edition of Designing the User Interface provides a comprehensive, authoritative, and up-to-date introduction to the dynamic field of human-computer interaction (HCI) and user experience (UX) design. This classic book has defined and charted the astonishing evolution of user interfaces for three decades. Students and professionals learn practical principles and guidelines needed to develop high quality interface designs that users can understand, predict, and control. The book covers theoretical foundations and design processes such as expert reviews and usability testing.    By presenting current research and innovations in human-computer interaction, the authors strive to inspire students, guide designers, and provoke researchers to seek solutions that improve the experiences of novice and expert users, while achieving universal usability. The authors also provide balanced presentations on controversial topics such as augmented and virtual reality, voice and natural language interfaces, and information visualization.    Updates include current HCI design methods, new design examples, and totally revamped coverage of social media, search and voice interaction. Major revisions were made to EVERY chapter, changing almost every figure (170 new color figures) and substantially updating the references.},
	language = {English},
	publisher = {Pearson},
	author = {Shneiderman, Ben and Plaisant, Catherine and Cohen, Maxine and Jacobs, Steven and Elmqvist, Niklas and Diakopoulos, Nicholas},
	month = apr,
	year = {2016}
}

@article{myers_sometimes_2001,
	title = {Sometimes you need a little intelligence, sometimes you need a lot},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.8085&rep=rep1&type=pdf},
	urldate = {2016-09-12TZ},
	journal = {Your Wish is My Command: Programming by Example. San Francisco, CA: Morgan Kaufmann Publishers},
	author = {Myers, Brad A. and McDaniel, Richard},
	year = {2001},
	pages = {45--60}
}

@inproceedings{myers_creating_1989,
	title = {Creating graphical interactive application objects by demonstration},
	url = {http://dl.acm.org/citation.cfm?id=73672},
	urldate = {2016-09-12TZ},
	booktitle = {Proceedings of the 2nd annual {ACM} {SIGGRAPH} symposium on {User} interface software and technology},
	publisher = {ACM},
	author = {Myers, Brad A. and Zanden, Brad Vandcr and Dannenberg, Roger B.},
	year = {1989},
	pages = {95--104}
}

@article{myers_creating_1990,
	title = {Creating user interfaces using programming by example, visual programming, and constraints},
	volume = {12},
	url = {http://dl.acm.org/citation.cfm?id=78943},
	number = {2},
	urldate = {2016-09-12TZ},
	journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
	author = {Myers, Brad A.},
	year = {1990},
	pages = {143--177}
}

@article{kahn_toontalk_1996,
	title = {Toontalk {TM}—an animated programming environment for children},
	volume = {7},
	url = {http://www.sciencedirect.com/science/article/pii/S1045926X96900117},
	number = {2},
	urldate = {2016-09-12TZ},
	journal = {Journal of Visual Languages \& Computing},
	author = {Kahn, Ken},
	year = {1996},
	pages = {197--217}
}

@misc{noauthor_workato_nodate,
	title = {Workato — {Connect} your apps. {Automate} your work.},
	url = {https://www.workato.com/},
	abstract = {Workato is the leading enterprise integration platform to integrate and automate your tasks across on-premise, cloud apps and databases – with no coding!},
	urldate = {2016-09-11TZ},
	journal = {Workato}
}
@article{myers_garnet:_1990,
	title = {Garnet: {Comprehensive} support for graphical, highly interactive user interfaces},
	volume = {23},
	shorttitle = {Garnet},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=60882},
	number = {11},
	urldate = {2016-09-11TZ},
	journal = {Computer},
	author = {Myers, Brad A. and Giuse, Dario A. and Dannenberg, Roger B. and Zanden, Brad Vanden and Kosbie, David S. and Pervin, Edward and Mickish, Andrew and Marchal, Philippe},
	year = {1990},
	pages = {71--85}
}

@inproceedings{myers_graphical_1991,
	title = {Graphical techniques in a spreadsheet for specifying user interfaces},
	url = {http://dl.acm.org/citation.cfm?id=108903},
	urldate = {2016-09-11TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Myers, Brad A.},
	year = {1991},
	pages = {243--249}
}

@misc{noauthor_sirikit_nodate,
	title = {{SiriKit} - {Apple} {Developer}},
	url = {https://developer.apple.com/sirikit/},
	urldate = {2016-09-10TZ}
}

@inproceedings{allen_plow:_2007,
	title = {Plow: {A} collaborative task learning agent},
	volume = {22},
	shorttitle = {Plow},
	url = {http://www.aaai.org/Papers/AAAI/2007/AAAI07-240.pdf},
	urldate = {2016-09-09TZ},
	booktitle = {Proceedings of the {National} {Conference} on {Artificial} {Intelligence}},
	publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
	author = {Allen, James and Chambers, Nathanael and Ferguson, George and Galescu, Lucian and Jung, Hyuckchul and Swift, Mary and Taysom, William},
	year = {2007},
	pages = {1514}
}

@inproceedings{bergman_docwizards:_2005,
	address = {New York, NY, USA},
	series = {{UIST} '05},
	title = {{DocWizards}: {A} {System} for {Authoring} {Follow}-me {Documentation} {Wizards}},
	isbn = {978-1-59593-271-6},
	shorttitle = {{DocWizards}},
	url = {http://doi.acm.org/10.1145/1095034.1095067},
	doi = {10.1145/1095034.1095067},
	abstract = {Traditional documentation for computer-based procedures is difficult to use: readers have trouble navigating long complex instructions, have trouble mapping from the text to display widgets, and waste time performing repetitive procedures. We propose a new class of improved documentation that we call follow-me documentation wizards. Follow-me documentation wizards step a user through a script representation of a procedure by highlighting portions of the text, as well application UI elements. This paper presents algorithms for automatically capturing follow-me documentation wizards by demonstration, through observing experts performing the procedure. We also present our DocWizards implementation on the Eclipse platform. We evaluate our system with an initial user study that showing that most users have a marked preference for this form of guidance over traditional documentation.},
	urldate = {2016-09-09TZ},
	booktitle = {Proceedings of the 18th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Bergman, Lawrence and Castelli, Vittorio and Lau, Tessa and Oblinger, Daniel},
	year = {2005},
	keywords = {documentation generation, programming-by-demonstration},
	pages = {191--200}
}

@inproceedings{bolin_automation_2005,
	title = {Automation and customization of rendered web pages},
	url = {http://dl.acm.org/citation.cfm?id=1095062},
	urldate = {2016-09-09TZ},
	booktitle = {Proceedings of the 18th annual {ACM} symposium on {User} interface software and technology},
	publisher = {ACM},
	author = {Bolin, Michael and Webber, Matthew and Rha, Philip and Wilson, Tom and Miller, Robert C.},
	year = {2005},
	pages = {163--172}
}

@misc{noauthor_automation_nodate,
	title = {Automation and customization of rendered web pages. - {Google} {Search}},
	url = {https://www.google.com/#q=Automation+and+customization+of+rendered+web+pages.},
	urldate = {2016-09-09TZ}
}

@incollection{billard_robot_2008,
	title = {Robot programming by demonstration},
	url = {http://link.springer.com/10.1007/978-3-540-30301-5_60},
	urldate = {2016-09-09TZ},
	booktitle = {Springer handbook of robotics},
	publisher = {Springer},
	author = {Billard, Aude and Calinon, Sylvain and Dillmann, Ruediger and Schaal, Stefan},
	year = {2008},
	pages = {1371--1394}
}

@article{nakaoka_learning_2007,
	title = {Learning from observation paradigm: {Leg} task models for enabling a biped humanoid robot to imitate human dances},
	volume = {26},
	shorttitle = {Learning from observation paradigm},
	url = {http://ijr.sagepub.com/content/26/8/829.short},
	number = {8},
	urldate = {2016-09-09TZ},
	journal = {The International Journal of Robotics Research},
	author = {Nakaoka, Shin'ichiro and Nakazawa, Atsushi and Kanehiro, Fumio and Kaneko, Kenji and Morisawa, Mitsuharu and Hirukawa, Hirohisa and Ikeuchi, Katsushi},
	year = {2007},
	pages = {829--844}
}

@article{argall_survey_2009,
	title = {A survey of robot learning from demonstration},
	volume = {57},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889008001772},
	number = {5},
	urldate = {2016-09-09TZ},
	journal = {Robotics and autonomous systems},
	author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
	year = {2009},
	pages = {469--483}
}

@inproceedings{thomason_learning_2015,
	title = {Learning to interpret natural language commands through human-robot dialog},
	url = {https://www.cs.utexas.edu/~szhang/2015_CONF_IJCAI_Thomason.pdf},
	urldate = {2016-09-09TZ},
	booktitle = {Proceedings of the {Twenty}-{Fourth} international joint conference on {Artificial} {Intelligence} ({IJCAI})},
	author = {Thomason, Jesse and Zhang, Shiqi and Mooney, Raymond and Stone, Peter},
	year = {2015}
}

@inproceedings{chen_learning_2011,
	title = {Learning to {Interpret} {Natural} {Language} {Navigation} {Instructions} from {Observations}.},
	volume = {2},
	url = {http://www.cse.iitk.ac.in/users/cs365/2013/hw2/chen-mooney-11_interpret-NLP-navigation-instructions-from-observations.pdf},
	urldate = {2016-09-09TZ},
	booktitle = {{AAAI}},
	author = {Chen, David L. and Mooney, Raymond J.},
	year = {2011},
	pages = {1--2}
}

@inproceedings{ravindranath_code_2012,
	address = {New York, NY, USA},
	series = {{HotMobile} '12},
	title = {Code in the {Air}: {Simplifying} {Sensing} and {Coordination} {Tasks} on {Smartphones}},
	isbn = {978-1-4503-1207-3},
	shorttitle = {Code in the {Air}},
	url = {http://doi.acm.org/10.1145/2162081.2162087},
	doi = {10.1145/2162081.2162087},
	abstract = {A growing class of smartphone applications are tasking applications that run continuously, process data from sensors to determine the user's context (such as location) and activity, and optionally trigger certain actions when the right conditions occur. Many such tasking applications also involve coordination between multiple users or devices. Example tasking applications include location-based reminders, changing the ring-mode of a phone automatically depending on location, notifying when friends are nearby, disabling WiFi in favor of cellular data when moving at more than a certain speed outdoors, automatically tracking and storing movement tracks when driving, and inferring the number of steps walked each day. Today, these applications are non-trivial to develop, although they are often trivial for end users to state. Additionally, simple implementations can consume excessive amounts of energy. This paper proposes Code in the Air (CITA), a system which simplifies the rapid development of tasking applications. It enables non-expert end users to easily express simple tasks on their phone, and more sophisticated developers to write code for complex tasks by writing purely server-side scripts. CITA provides a task execution framework to automatically distribute and coordinate tasks, energy-efficient modules to infer user activities and compose them, and a push communication service for mobile devices that overcomes some shortcomings in existing push services.},
	urldate = {2016-09-08TZ},
	booktitle = {Proceedings of the {Twelfth} {Workshop} on {Mobile} {Computing} {Systems} \& {Applications}},
	publisher = {ACM},
	author = {Ravindranath, Lenin and Thiagarajan, Arvind and Balakrishnan, Hari and Madden, Samuel},
	year = {2012},
	pages = {4:1--4:6}
}

@inproceedings{rodrigues_breaking_2015,
	address = {New York, NY, USA},
	series = {{ASSETS} '15},
	title = {Breaking {Barriers} with {Assistive} {Macros}},
	isbn = {978-1-4503-3400-6},
	url = {http://doi.acm.org/10.1145/2700648.2811322},
	doi = {10.1145/2700648.2811322},
	abstract = {People with disabilities rely on assistive technology (AT) software to interact with their mobile device. The overall functionality of AT depends on a set of requirements that are not always fulfilled by application developers, often resulting in cumbersome and slow interactions, or even render content inaccessible. To address these issues we present Assistive Macros, an accessibility service developed to enable users to perform a sequence of commands with a single selection. Macros can be created manually by the user or automatically by detecting repeated sequences of interactions. In this paper, we report a preliminary case study with our prototype involving a motor impaired user and his caregivers},
	urldate = {2016-09-08TZ},
	booktitle = {Proceedings of the 17th {International} {ACM} {SIGACCESS} {Conference} on {Computers} \& {Accessibility}},
	publisher = {ACM},
	author = {Rodrigues, André},
	year = {2015},
	keywords = {assistive technologies, macros, mobile, multi-impairment},
	pages = {351--352}
}

@misc{noauthor_notitle_nodate,
	url = {http://delivery.acm.org/10.1145/2500000/2493216/p295-maues.pdf?ip=128.237.215.130&id=2493216&acc=ACTIVE%20SERVICE&key=A792924B58C015C1%2E5A12BE0369099858%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=835664796&CFTOKEN=57245166&__acm__=1473363060_b002ab4f5fb9f867bec499bcd20778b4},
	urldate = {2016-09-08TZ}
}

@inproceedings{paynter_developing_2000,
	title = {Developing a practical programming by demonstration tool},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.3189&rep=rep1&type=pdf},
	urldate = {2016-09-08TZ},
	booktitle = {Proc. {Australian} {Conference} on {Computer}-{Human} {Interaction} ({OzCHI})},
	publisher = {Citeseer},
	author = {Paynter, Gordon W. and Witten, Ian H.},
	year = {2000},
	pages = {307--314}
}

@inproceedings{frank_pure_1994,
	address = {New York, NY, USA},
	series = {{UIST} '94},
	title = {A {Pure} {Reasoning} {Engine} for {Programming} by {Demonstration}},
	isbn = {978-0-89791-657-8},
	url = {http://doi.acm.org/10.1145/192426.192466},
	doi = {10.1145/192426.192466},
	abstract = {We present an inference engine that can be used for creating Programming By Demonstration systems. The class of systems addressed are those which infer a state change description from examples of state [9, 11].The engine can easily be incorporated into an existing design environment that provides an interactive object editor.The main design goals of the inference engine are responsiveness and generality. All demonstrational systems must respond quickly because of their interactive use. They should also be general—they should be able to make inferences for any attribute that the user may want to define by demonstration, and they should be able to treat any other attributes as parameters of this definition.The first goal, responsiveness, is best accommodated by limiting the number of attributes that the inference engine takes into consideration. This, however, is in obvious conflict with the second goal, generality.This conflict is intrinsic to the class of demonstrational system described above. The challenge is to find an algorithm which responds quickly but does not heuristically limit the number of attributes it looks at. We present such an algorithm in this paper.A companion paper describes Inference Bear [4], an actual demonstrational system that we have built using this inference engine and an existing user interface builder [5].},
	urldate = {2016-09-08TZ},
	booktitle = {Proceedings of the 7th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Frank, Martin R. and Foley, James D.},
	year = {1994},
	keywords = {Programming, by, demonstration},
	pages = {95--101}
}

@inproceedings{mcdaniel_gamut:_1997,
	address = {New York, NY, USA},
	series = {{UIST} '97},
	title = {Gamut: {Demonstrating} {Whole} {Applications}},
	isbn = {978-0-89791-881-7},
	shorttitle = {Gamut},
	url = {http://doi.acm.org/10.1145/263407.263515},
	doi = {10.1145/263407.263515},
	urldate = {2016-09-08TZ},
	booktitle = {Proceedings of the 10th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {McDaniel, Richard G. and Myers, Brad A.},
	year = {1997},
	keywords = {Gamut, applicaiton builders, end-user programming, inductive learning, programming-by-demonstration, programming-by-example, user interface software},
	pages = {81--82}
}

@inproceedings{grabler_generating_2009,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '09},
	title = {Generating {Photo} {Manipulation} {Tutorials} by {Demonstration}},
	isbn = {978-1-60558-726-4},
	url = {http://doi.acm.org/10.1145/1576246.1531372},
	doi = {10.1145/1576246.1531372},
	abstract = {We present a demonstration-based system for automatically generating succinct step-by-step visual tutorials of photo manipulations. An author first demonstrates the manipulation using an instrumented version of GIMP that records all changes in interface and application state. From the example recording, our system automatically generates tutorials that illustrate the manipulation using images, text, and annotations. It leverages automated image labeling (recognition of facial features and outdoor scene structures in our implementation) to generate more precise text descriptions of many of the steps in the tutorials. A user study comparing our automatically generated tutorials to hand-designed tutorials and screen-capture video recordings finds that users are 20--44\% faster and make 60--95\% fewer errors using our tutorials. While our system focuses on tutorial generation, we also present some initial work on generating content-dependent macros that use image recognition to automatically transfer selection operations from the example image used in the demonstration to new target images. While our macros are limited to transferring selection operations we demonstrate automatic transfer of several common retouching techniques including eye recoloring, whitening teeth and sunset enhancement.},
	urldate = {2016-09-08TZ},
	booktitle = {{ACM} {SIGGRAPH} 2009 {Papers}},
	publisher = {ACM},
	author = {Grabler, Floraine and Agrawala, Maneesh and Li, Wilmot and Dontcheva, Mira and Igarashi, Takeo},
	year = {2009},
	keywords = {macros, photo-editing, programming-by-demonstration, tutorials},
	pages = {66:1--66:9}
}

@inproceedings{modugno_pursuit:_1994,
	address = {New York, NY, USA},
	series = {{CHI} '94},
	title = {Pursuit: {Graphically} {Representing} {Programs} in a {Demonstrational} {Visual} {Shell}},
	isbn = {9780897916516},
	shorttitle = {Pursuit},
	url = {http://doi.acm.org/10.1145/259963.260464},
	doi = {10.1145/259963.260464},
	urldate = {2016-09-08TZ},
	booktitle = {Conference {Companion} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Modugno, Francesmary and Myers, Brad A.},
	year = {1994},
	pages = {455--456}
}

@inproceedings{huang_instructablecrowd:_2016,
	title = {{InstructableCrowd}: {Creating} {IF}-{THEN} {Rules} via {Conversations} with the {Crowd}},
	isbn = {978-1-4503-4082-3},
	shorttitle = {{InstructableCrowd}},
	url = {http://dl.acm.org/citation.cfm?doid=2851581.2892502},
	doi = {10.1145/2851581.2892502},
	language = {en},
	urldate = {2016-09-06TZ},
	publisher = {ACM Press},
	author = {Huang, Ting-Hao Kenneth and Azaria, Amos and Bigham, Jeffrey P.},
	year = {2016},
	pages = {1555--1562}
}

@inproceedings{chen_recovering_2008,
	address = {New York, NY, USA},
	series = {{IUI} '08},
	title = {Recovering from {Errors} {During} {Programming} by {Demonstration}},
	isbn = {978-1-59593-987-6},
	url = {http://doi.acm.org/10.1145/1378773.1378794},
	doi = {10.1145/1378773.1378794},
	abstract = {Many end-users wish to customize their applications, automating common tasks and routines. Unfortunately, this automation is difficult today --- users must choose between brittle macros and complex scripting languages. Programming by demonstration (PBD) offers a middle ground, allowing users to demonstrate a procedure multiple times and generalizing the requisite behavior with machine learning. Unfortunately, many PBD systems are almost as brittle as macro recorders, offering few ways for a user to control the learning process or correct the demonstrations used as training examples. This paper presents CHINLE, a system which automatically constructs PBD systems for applications based on their interface specification. The resulting PBD systems have novel interaction and visualization methods, which allow the user to easily monitor and guide the learning process, facilitating error recovery during training. CHINLE-constructed PBD systems learn procedures with conditionals and perform partial learning if the procedure is too complex to learn completely.},
	urldate = {2016-09-06TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Chen, Jiun-Hung and Weld, Daniel S.},
	year = {2008},
	pages = {159--168}
}

@article{bauer_programming_2000,
	title = {Programming by {Example}: {Programming} by {Demonstration} for {Information} {Agents}},
	volume = {43},
	issn = {0001-0782},
	shorttitle = {Programming by {Example}},
	url = {http://doi.acm.org/10.1145/330534.330547},
	doi = {10.1145/330534.330547},
	number = {3},
	urldate = {2016-09-06TZ},
	journal = {Commun. ACM},
	author = {Bauer, Mathias and Dengler, Dietmar and Paul, Gabriele and Meyer, Markus},
	month = mar,
	year = {2000},
	pages = {98--103}
}

@misc{noauthor_google_nodate,
	title = {Google {Calendar} - {Week} of {Sep} 5, 2016 - {Week} of {Sep} 5, 2016},
	url = {https://calendar.google.com/calendar/render#main_7%7Cweek-2+23845+23851+23849},
	urldate = {2016-09-02TZ}
}

@misc{noauthor_google_nodate-1,
	title = {Google {Calendar} - {Week} of {Sep} 5, 2016 - {Week} of {Sep} 5, 2016},
	url = {https://calendar.google.com/calendar/render#main_7%7Cweek-2+23845+23851+23849},
	urldate = {2016-09-02TZ}
}

@misc{noauthor_notitle_nodate-1,
	url = {http://faculty.washington.edu/wobbrock/pubs/Wobbrock-2012.pdf},
	urldate = {2016-09-02TZ}
}

@misc{noauthor_notitle_nodate-2,
	url = {http://www.billbuxton.com/usabilityHarmful.pdf},
	urldate = {2016-09-02TZ}
}

@inproceedings{jiang_automatic_2015,
	address = {New York, NY, USA},
	series = {{WWW} '15},
	title = {Automatic {Online} {Evaluation} of {Intelligent} {Assistants}},
	isbn = {978-1-4503-3469-3},
	url = {http://doi.acm.org/10.1145/2736277.2741669},
	doi = {10.1145/2736277.2741669},
	abstract = {Voice-activated intelligent assistants, such as Siri, Google Now, and Cortana, are prevalent on mobile devices. However, it is challenging to evaluate them due to the varied and evolving number of tasks supported, e.g., voice command, web search, and chat. Since each task may have its own procedure and a unique form of correct answers, it is expensive to evaluate each task individually. This paper is the first attempt to solve this challenge. We develop consistent and automatic approaches that can evaluate different tasks in voice-activated intelligent assistants. We use implicit feedback from users to predict whether users are satisfied with the intelligent assistant as well as its components, i.e., speech recognition and intent classification. Using this approach, we can potentially evaluate and compare different tasks within and across intelligent assistants ac-cording to the predicted user satisfaction rates. Our approach is characterized by an automatic scheme of categorizing user-system interaction into task-independent dialog actions, e.g., the user is commanding, selecting, or confirming an action. We use the action sequence in a session to predict user satisfaction and the quality of speech recognition and intent classification. We also incorporate other features to further improve our approach, including features derived from previous work on web search satisfaction prediction, and those utilizing acoustic characteristics of voice requests. We evaluate our approach using data collected from a user study. Results show our approach can accurately identify satisfactory and unsatisfactory sessions.},
	urldate = {2016-08-29TZ},
	booktitle = {Proceedings of the 24th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Jiang, Jiepu and Hassan Awadallah, Ahmed and Jones, Rosie and Ozertem, Umut and Zitouni, Imed and Gurunath Kulkarni, Ranjitha and Khan, Omar Zia},
	year = {2015},
	keywords = {evaluation, mobile search, spoken dialog system., user experience, voice-activated intelligent assistant},
	pages = {506--516}
}

@inproceedings{antila_routinemaker:_2012,
	title = {{RoutineMaker}: {Towards} end-user automation of daily routines using smartphones},
	shorttitle = {{RoutineMaker}},
	doi = {10.1109/PerComW.2012.6197519},
	abstract = {People use smartphones in daily activities for accessing and storing information in various situations. In this paper, we present a work in progress for detecting and automating some of these activities. To explore the possible patterns we developed an experimental application to detect daily tasks used by smartphones and analyzed it to provide suggestions for “routines”. We conducted a two-week user study with 10 users to evaluate the approach. During the study the application logged the usage patterns, sent information to the server where it was analysed and clustered. The participants could also automate their smartphone tasks using the analysed data. The findings suggest that people would be willing to automatize tasks given that the approach gives flexibility and expressiveness without too much information overload. Future work includes refining the algorithms based on the gathered real-life data and modifying the interaction design to approach the challenges found with the initial study.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} ({PERCOM} {Workshops})},
	author = {Antila, V. and Polet, J. and Lämsä, A. and Liikka, J.},
	month = mar,
	year = {2012},
	keywords = {Accuracy, Clustering algorithms, Data analysis, Electronic mail, Human factors, Mobile communication, Routine detection, RoutineMaker, Sensing, Sensors, context-awareness, daily routine detection, end-user automation, information access, information overload, information storage, mobile computing, personal computing, smart phones, smartphones, task automation, usage patterns},
	pages = {399--402}
}

@inproceedings{maues_keep_2013,
	address = {New York, NY, USA},
	series = {{MobileHCI} '13},
	title = {Keep {Doing} {What} {I} {Just} {Did}: {Automating} {Smartphones} by {Demonstration}},
	isbn = {978-1-4503-2273-7},
	shorttitle = {Keep {Doing} {What} {I} {Just} {Did}},
	url = {http://doi.acm.org/10.1145/2493190.2493216},
	doi = {10.1145/2493190.2493216},
	abstract = {Automating tasks can make a smartphone easier to use and more battery efficient. However, currently little work has been done to help end-users to create such automations. In this paper, we explore an approach for automating smartphone tasks by demonstration. We have developed a mobile application called Keep Doing It that continuously records users' interactions with their smartphones. After users performed a task that they would like to automate, they can ask our application to create the automation based on their latest actions. Since users only have to use their smartphones, as they would naturally do, to demonstrate automations, we believe that our approach can lower the barrier for creating smartphone automations. Overall, an initial evaluation of the approach suggests that users would be willing to automate their phones by demonstration.},
	urldate = {2016-08-29TZ},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Maués, Rodrigo de A. and Barbosa, Simone Diniz Junqueira},
	year = {2013},
	keywords = {context-aware systems, end-user development, mobile computing, programming by demonstration, smartphone automation, ubiquitous computing},
	pages = {295--303}
}

@inproceedings{leshed_coscripter:_2008,
	address = {New York, NY, USA},
	series = {{CHI} '08},
	title = {{CoScripter}: {Automating} \& {Sharing} {How}-to {Knowledge} in the {Enterprise}},
	isbn = {9781605580111},
	shorttitle = {{CoScripter}},
	url = {http://doi.acm.org/10.1145/1357054.1357323},
	doi = {10.1145/1357054.1357323},
	abstract = {Modern enterprises are replete with numerous online processes. Many must be performed frequently and are tedious, while others are done less frequently yet are complex or hard to remember. We present interviews with knowledge workers that reveal a need for mechanisms to automate the execution of and to share knowledge about these processes. In response, we have developed the CoScripter system (formerly Koala [11]), a collaborative scripting environment for recording, automating, and sharing web-based processes. We have deployed CoScripter within a large corporation for more than 10 months. Through usage log analysis and interviews with users, we show that CoScripter has addressed many user automation and sharing needs, to the extent that more than 50 employees have voluntarily incorporated it into their work practice. We also present ways people have used CoScripter and general issues for tools that support automation and sharing of how-to knowledge.},
	urldate = {2016-08-07TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Leshed, Gilly and Haber, Eben M. and Matthews, Tara and Lau, Tessa},
	year = {2008},
	keywords = {automation, knowledge sharing, procedural knowledge, programming-by-demonstration, scripting, user study, wiki},
	pages = {1719--1728}
}

@inproceedings{baeza-yates_predicting_2015,
	address = {New York, NY, USA},
	series = {{WSDM} '15},
	title = {Predicting {The} {Next} {App} {That} {You} {Are} {Going} {To} {Use}},
	isbn = {978-1-4503-3317-7},
	url = {http://doi.acm.org/10.1145/2684822.2685302},
	doi = {10.1145/2684822.2685302},
	abstract = {Given the large number of installed apps and the limited screen size of mobile devices, it is often tedious for users to search for the app they want to use. Although some mobile OSs provide categorization schemes that enhance the visibility of useful apps among those installed, the emerging category of homescreen apps aims to take one step further by automatically organizing the installed apps in a more intelligent and personalized way. In this paper, we study how to improve homescreen apps' usage experience through a prediction mechanism that allows to show to users which app she is going to use in the immediate future. The prediction technique is based on a set of features representing the real-time spatiotemporal contexts sensed by the homescreen app. We model the prediction of the next app as a classification problem and propose an effective personalized method to solve it that takes full advantage of human-engineered features and automatically derived features. Furthermore, we study how to solve the two naturally associated cold-start problems: app cold-start and user cold-start. We conduct large-scale experiments on log data obtained from Yahoo Aviate, showing that our approach can accurately predict the next app that a person is going to use.},
	urldate = {2016-05-15TZ},
	booktitle = {Proceedings of the {Eighth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Baeza-Yates, Ricardo and Jiang, Di and Silvestri, Fabrizio and Harrison, Beverly},
	year = {2015},
	keywords = {aviate, machine learning, mobile app, prediction},
	pages = {285--294}
}

@book{newell_human_1972,
	title = {Human problem solving},
	volume = {104},
	url = {http://www.sci.brooklyn.cuny.edu/~kopec/cis718/fall_2005/2/Rafique_2_humanthinking.doc},
	number = {9},
	urldate = {2016-05-02TZ},
	publisher = {Prentice-Hall Englewood Cliffs, NJ},
	author = {Newell, Allen and Simon, Herbert Alexander and {others}},
	year = {1972}
}

@article{pane_usability_1996,
	title = {Usability {Issues} in the {Design} of {Novice} {Programming} {Systems}},
	url = {http://repository.cmu.edu/isr/820},
	journal = {Institute for Software Research},
	author = {Pane, John and Myers, Brad},
	month = jan,
	year = {1996}
}

@article{nassi_flowchart_1973,
	title = {Flowchart {Techniques} for {Structured} {Programming}},
	volume = {8},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/953349.953350},
	doi = {10.1145/953349.953350},
	abstract = {With the advent of structured programming and GOTO-less programming a method is needed to model computation in simply ordered structures, each representing a complete thought possibly defined in terms of other thoughts as yet undefined. A model is needed which prevents unrestricted transfers of control and has a control structure closer to languages amenable to structured programming. We present an attempt at such a model.},
	number = {8},
	urldate = {2016-05-02TZ},
	journal = {SIGPLAN Not.},
	author = {Nassi, I. and Shneiderman, B.},
	month = aug,
	year = {1973},
	pages = {12--26}
}

@article{kirk2016learning,
	title={Learning task goals interactively with visual demonstrations},
	author={Kirk, James and Mininger, Aaron and Laird, John},
	journal={Biologically Inspired Cognitive Architectures},
	volume={18},
	pages={1--8},
	year={2016},
	publisher={Elsevier}
}


@article{doane_expertise_1990,
	title = {Expertise in a computer operating system: {Conceptualization} and performance},
	volume = {5},
	shorttitle = {Expertise in a computer operating system},
	url = {http://dl.acm.org/citation.cfm?id=1456615},
	number = {2},
	urldate = {2016-05-02TZ},
	journal = {Human-Computer Interaction},
	author = {Doane, Stephanie M. and Pellegrino, James W. and Klatzky, Roberta L.},
	year = {1990},
	pages = {267--304}
}

@book{black_models_1962,
	title = {Models and metaphors},
	volume = {61},
	url = {http://www.jstor.org/stable/pdf/2183477.pdf},
	urldate = {2016-05-02TZ},
	publisher = {JSTOR},
	author = {Black, Max},
	year = {1962}
}

@book{holyoak_cambridge_2005,
	title = {The {Cambridge} handbook of thinking and reasoning},
	url = {https://books.google.com/books?hl=en&lr=&id=znbkHaC8QeMC&oi=fnd&pg=PR9&dq=Analogy.+In+The+Cambridge+Handbook+of+Thinking+and+Reasoning&ots=a09PXZlfqJ&sig=DTs3nqDn0bhc5J-urkiwUAOL1oU},
	urldate = {2016-05-02TZ},
	publisher = {Cambridge University Press},
	author = {Holyoak, Keith J. and Morrison, Robert G.},
	year = {2005}
}

@book{gentner_language_2003,
	title = {Language in mind: {Advances} in the study of language and thought},
	shorttitle = {Language in mind},
	url = {https://books.google.com/books?hl=en&lr=&id=EGYaXcJ3xW4C&oi=fnd&pg=PR4&ots=d3xv2nf2vF&sig=AYrjBOCdH52hz884LlpPBOvwcjE},
	urldate = {2016-05-02TZ},
	author = {Gentner, Dedre},
	year = {2003}
}

@article{brooks_towards_1999,
	title = {Towards a theory of the cognitive processes in computer programming},
	volume = {51},
	issn = {1071-5819},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581977603062},
	doi = {10.1006/ijhc.1977.0306},
	abstract = {While only in the past ten years have large numbers of people been engaged in computer programming, a small body of studies on this activity have already been accumulated. These studies are, however, largely atheoretical. The work described here has as its goal the creation of an information processing theory sufficient to describe the findings of these studies. The theory postulates understanding, method-finding, and coding processes in writing programs, and presents an explicit model for the coding process.},
	number = {2},
	urldate = {2016-05-02TZ},
	journal = {International Journal of Human-Computer Studies},
	author = {BROOKS, RUVEN},
	month = aug,
	year = {1999},
	pages = {197--211}
}

@article{green_cognitive_1994,
	title = {Cognitive dimensions as discussion tools for programming language design},
	journal = {Human-Computer Interaction},
	author = {Green, T. R. G. and Petre, M.},
	year = {1994}
}

@inproceedings{green_describing_1991,
	title = {Describing information artifacts with cognitive dimensions and structure maps},
	volume = {91},
	booktitle = {{HCI}},
	author = {Green, Thomas RG},
	year = {1991},
	pages = {297--315}
}

@article{green_cognitive_1989,
	title = {Cognitive dimensions of notations},
	url = {https://books.google.com/books?hl=en&lr=&id=BTxOtt4X920C&oi=fnd&pg=PA443&dq=Cognitive+dimensions+of+notations&ots=OEqg1By_Rj&sig=dpg1zZFRHpBVC_r0--XLyLr6718},
	urldate = {2016-05-02TZ},
	journal = {People and computers V},
	author = {Green, Thomas RG},
	year = {1989},
	pages = {443--460}
}

@inproceedings{quirk_language_2015,
	title = {Language to code: {Learning} semantic parsers for if-this-then-that recipes},
	shorttitle = {Language to code},
	url = {http://www.cs.utexas.edu/~ml/publications/area/77/learning_for_semantic_parsing/abstracts/},
	urldate = {2016-05-02TZ},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({ACL}-15)},
	author = {Quirk, Chris and Mooney, Raymond and Galley, Michel},
	year = {2015},
	pages = {878--888}
}

@inproceedings{chen_learning_2011-1,
	title = {Learning to {Interpret} {Natural} {Language} {Navigation} {Instructions} from {Observations}},
	volume = {1},
	url = {https://www.researchgate.net/publication/221606234_Learning_to_Interpret_Natural_Language_Navigation_Instructions_from_Observations},
	abstract = {The ability to understand natural-language instructions is critical to building intelligent agents that interact with humans. We present a system that learns to transform natural-language...},
	urldate = {2016-05-02TZ},
	booktitle = {{ResearchGate}},
	author = {Chen, David L. and Mooney, Raymond J.},
	month = jan,
	year = {2011}
}

@inproceedings{le_smartsynth:_2013,
	address = {New York, NY, USA},
	series = {{MobiSys} '13},
	title = {{SmartSynth}: {Synthesizing} {Smartphone} {Automation} {Scripts} from {Natural} {Language}},
	isbn = {978-1-4503-1672-9},
	shorttitle = {{SmartSynth}},
	url = {http://doi.acm.org/10.1145/2462456.2464443},
	doi = {10.1145/2462456.2464443},
	abstract = {This paper presents SmartSynth, a novel end-to-end programming system for synthesizing smartphone automation scripts from natural language descriptions. Our approach is unique in two key aspects. First, it involves a carefully designed domain-specific language that incorporates standard constructs from smartphone programming platforms to balance its expressivity and the ability to synthesize scripts from natural language. Second, our synthesis algorithm integrates techniques from two research areas: (1) It infers the set of components and their partial dataflow relations from the natural language description using techniques from the Natural Language Processing community; and (2) It uses techniques from the Program Synthesis community to infer missing dataflow relations via type-based synthesis and constructs scripts in a process akin to reverse parsing. SmartSynth also performs conversational interactions with the user when multiple top-ranked scripts exist or it cannot map part of the description to any component. Evaluated on 50 tasks collected from smartphone help forums, our system produces the intended scripts in real time for over 90\% of the 640 natural language descriptions obtained from a user study for those tasks. SmartSynth has also been adapted to TouchDevelop, an end user-targeted programming environment on mobile platforms, with very promising results (see http://www.cs.ucdavis.edu/{\textasciitilde}su/smartsynth.mp4 for a video demo). We believe that SmartSynth is a step toward fully personalized use of smartphones' increasingly rich functionalities.},
	urldate = {2016-05-02TZ},
	booktitle = {Proceeding of the 11th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Le, Vu and Gulwani, Sumit and Su, Zhendong},
	year = {2013},
	keywords = {automation script, natural language processing, program synthesis, smartphone},
	pages = {193--206}
}

@article{sypher_introduction:_nodate,
	title = {Introduction: {Bringing} programming to end users},
	shorttitle = {Introduction},
	journal = {Allen Sypher et al},
	author = {Sypher, A.},
	pages = {1--11}
}
@inproceedings{jost_graphical_2014,
	title = {Graphical {Programming} {Environments} for {Educational} {Robots}: {Open} {Roberta} - {Yet} {Another} {One}?},
	shorttitle = {Graphical {Programming} {Environments} for {Educational} {Robots}},
	doi = {10.1109/ISM.2014.24},
	abstract = {In recent years, an increasing number of school children is beginning to learn about robotics in the classroom in order to stir their interest in STEM professions. Teachers rely on simple educational robots and intuitive programming environments and graphical programming environments have become a frequent starting point for young robotics new bies. However, currently available tools do often not sufficiently support teachers and students in the classroom. In this study, we evaluate programming environments for educational robots, our results point to the need of lowering the complexity of tools as well as of incorporating combinations of web and cloud technologies, embedded systems and communication concepts into these environments. The technical part of this work presents Open Roberta - an open source based addition to commercial educational robot environments that addresses these needs.},
	booktitle = {2014 {IEEE} {International} {Symposium} on {Multimedia} ({ISM})},
	author = {Jost, B. and Ketterl, M. and Budde, R. and Leimbach, T.},
	month = dec,
	year = {2014},
	keywords = {Open Roberta, Programming environments, Programming profession, STEM professions, Software, Web technologies, cloud computing, cloud technologies, commercial educational robot environments, communication concepts, computer aided instruction, computer science education, control engineering computing, control engineering education, e-learning, education, educational institutions, educational robots, embedded systems, graphical programming, graphical programming environments, intuitive programming environments, roberta, robotic, school children, visual programming, web 2.0, web technology, young robotics newbies},
	pages = {381--386}
}

@misc{higginbotham_$30m_2014,
	title = {With \$30M in new funding, {IFTTT} preps to take on rivals},
	url = {https://gigaom.com/2014/08/28/with-30m-in-new-funding-ifttt-preps-to-take-on-rivals/},
	abstract = {As the internet of things heats up, middleware service If This Then That gets \$30 million to continue expanding its options and its user base.},
	urldate = {2016-05-02TZ},
	author = {Higginbotham, Stacey},
	month = aug,
	year = {2014}
}

@inproceedings{curtis_fifteen_1984,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '84},
	title = {Fifteen {Years} of {Psychology} in {Software} {Engineering}: {Individual} {Differences} and {Cognitive} {Science}},
	isbn = {978-0-8186-0528-4},
	shorttitle = {Fifteen {Years} of {Psychology} in {Software} {Engineering}},
	url = {http://dl.acm.org/citation.cfm?id=800054.801956},
	abstract = {Since the 1950's, psychologists have studied the behavioral aspects of software engineering. However, the results of their research have never been organized into a subfield of either software engineering or psychology. This failure results from the difficulty of integrating theory and data from the mixture of paradigms borrowed from psychology. This paper will review some of the psychological research on software engineering performed since the Garmisch Conference in 1968. This review will be organized under two of the psychological paradigms used in exploring programming problems: individual differences and cognitive science. The major theoretical and practical contributions of each area to the theory and practice of software engineering will be discussed. The review will end with a call for more research guided by the paradigm of cognitive science, since such results are the easiest to integrate with new developments in artificial intelligence and computer science theory.},
	urldate = {2016-05-01TZ},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Curtis, Bill},
	year = {1984},
	pages = {97--106}
}

@article{j._m_hoc_language_1990,
	title = {Language {Semantics}, {Mental} {Models} and {Analogy}},
	doi = {10.1016/B978-0-12-350772-3.50014-8},
	author = {J. M Hoc, Anh Nguyen-Xuan},
	year = {1990}
}

@inproceedings{kurlander_history-based_1992,
	address = {New York, NY, USA},
	series = {{UIST} '92},
	title = {A {History}-based {Macro} by {Example} {System}},
	isbn = {9780897915496},
	url = {http://doi.acm.org/10.1145/142621.142633},
	doi = {10.1145/142621.142633},
	abstract = {Many tasks performed using computer interfaces are very repetitive. While programmers can write macros or procedures to automate these repetitive tasks, this requires special skills. Demonstrational systems make macro building accessible to all users, but most provide either no visual representation of the macro or only a textual representation. We have developed a history-based visual representation of commands in a graphical user interface. This representation supports the definition of macros by example in several novel ways. At any time, a user can open a history window, review the commands executed in a session, select operations to encapsulate into a macro, and choose objects and their attributes as arguments. The system has facilities to generalize the macro automatically, save it for future use, and edit it.},
	urldate = {2016-04-29TZ},
	booktitle = {Proceedings of the 5th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Kurlander, David and Feiner, Steven},
	year = {1992},
	keywords = {demonstrational techniques, graphical representations, histories, macros, programming by example},
	pages = {99--106}
}

@article{alexandron_scenario-based_2014,
	title = {Scenario-{Based} {Programming}, {Usability}-{Oriented} {Perception}},
	volume = {14},
	issn = {1946-6226},
	url = {http://doi.acm.org/10.1145/2648814},
	doi = {10.1145/2648814},
	abstract = {In this article, we discuss the possible connection between the programming language and the paradigm behind it, and programmers’ tendency to adopt an external or internal perspective of the system they develop. Based on a qualitative analysis, we found that when working with the visual, interobject language of live sequence charts (LSC), programmers tend to adopt an external and usability-oriented view of the system, whereas when working with an intraobject language, they tend to adopt an internal and implementation-oriented viewpoint. This is explained by first discussing the possible effect of the programming paradigm on programmers’ perception and then offering a more comprehensive explanation. The latter is based on a cognitive model of programming with LSC, which is an interpretation and a projection of the model suggested by Adelson and Soloway [1985] onto LSC and scenario-based programming, the new paradigm on which LSC is based. Our model suggests that LSC fosters a kind of programming that enables iterative refinement of the artifact with fewer entries into the solution domain. Thus, the programmer can make less context switching between the solution domain and the problem domain, and consequently spend more time in the latter. We believe that these findings are interesting mainly in two ways. First, they characterize an aspect of problem-solving behavior that to the best of our knowledge has not been studied before—the programmer’s perspective. The perspective can potentially affect the outcome of the problem-solving process, such as by leading the programmer to focus on different parts of the problem. Second, relating the structure of the language to the change in perspective sheds light on one of the ways in which the programming language can affect the programmer’s behavior.},
	number = {3},
	urldate = {2016-04-29TZ},
	journal = {Trans. Comput. Educ.},
	author = {Alexandron, Giora and Armoni, Michal and Gordon, Michal and Harel, David},
	month = oct,
	year = {2014},
	keywords = {Live sequence charts, psychology of programming},
	pages = {21:1--21:23}
}

@inproceedings{myers_towards_2002,
	address = {New York, NY, USA},
	series = {{ICFP} '02},
	title = {Towards {More} {Natural} {Functional} {Programming} {Languages}},
	isbn = {9781581134872},
	url = {http://doi.acm.org/10.1145/581478.581479},
	doi = {10.1145/581478.581479},
	abstract = {Programming languages are the way for a person to express a mental plan in a way that the computer can understand. Therefore, it is appropriate to consider properties of people when designing new programming languages. In our research, we are investigating how people think about algorithms, and how programming languages can be made easier to learn and more effective for people to use. By taking human-productivity aspects of programming languages seriously, designers can more effectively match programming language features with human capabilities and problem solving methods. Human factors methods can be used to measure the effects, so unsubstantiated claims can be avoided.This talk will present a quick summary of new and old results in what is known about people and programming, from areas that are sometimes called "empirical studies of programmers" and "psychology of programming." Much is known about what people find difficult, and what syntax and language features are especially tricky and bug-prone. Our new research has discovered how people naturally think about algorithms and data structures, which can help with making programming languages more closely match people's problem solving techniques.},
	urldate = {2016-04-29TZ},
	booktitle = {Proceedings of the {Seventh} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Myers, Brad A.},
	year = {2002},
	keywords = {empirical studies of programming, end-user programming, natural programming, psychology of programming},
	pages = {1--1}
}

@inproceedings{curtis_fifteen_1984-1,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '84},
	title = {Fifteen {Years} of {Psychology} in {Software} {Engineering}: {Individual} {Differences} and {Cognitive} {Science}},
	isbn = {9780818605284},
	shorttitle = {Fifteen {Years} of {Psychology} in {Software} {Engineering}},
	url = {http://dl.acm.org/citation.cfm?id=800054.801956},
	abstract = {Since the 1950's, psychologists have studied the behavioral aspects of software engineering. However, the results of their research have never been organized into a subfield of either software engineering or psychology. This failure results from the difficulty of integrating theory and data from the mixture of paradigms borrowed from psychology. This paper will review some of the psychological research on software engineering performed since the Garmisch Conference in 1968. This review will be organized under two of the psychological paradigms used in exploring programming problems: individual differences and cognitive science. The major theoretical and practical contributions of each area to the theory and practice of software engineering will be discussed. The review will end with a call for more research guided by the paradigm of cognitive science, since such results are the easiest to integrate with new developments in artificial intelligence and computer science theory.},
	urldate = {2016-04-29TZ},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Curtis, Bill},
	year = {1984},
	pages = {97--106}
}

@inproceedings{curtis_fifteen_1984-2,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '84},
	title = {Fifteen {Years} of {Psychology} in {Software} {Engineering}: {Individual} {Differences} and {Cognitive} {Science}},
	isbn = {9780818605284},
	shorttitle = {Fifteen {Years} of {Psychology} in {Software} {Engineering}},
	url = {http://dl.acm.org/citation.cfm?id=800054.801956},
	abstract = {Since the 1950's, psychologists have studied the behavioral aspects of software engineering. However, the results of their research have never been organized into a subfield of either software engineering or psychology. This failure results from the difficulty of integrating theory and data from the mixture of paradigms borrowed from psychology. This paper will review some of the psychological research on software engineering performed since the Garmisch Conference in 1968. This review will be organized under two of the psychological paradigms used in exploring programming problems: individual differences and cognitive science. The major theoretical and practical contributions of each area to the theory and practice of software engineering will be discussed. The review will end with a call for more research guided by the paradigm of cognitive science, since such results are the easiest to integrate with new developments in artificial intelligence and computer science theory.},
	urldate = {2016-04-29TZ},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Curtis, Bill},
	year = {1984},
	pages = {97--106}
}

@incollection{rahwan_agent-based_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Agent-{Based} {Support} for {Mobile} {Users} {Using} {AgentSpeak}({L})},
	copyright = {©2004 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-22127-2 978-3-540-25943-5},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-25943-5_4},
	abstract = {This paper describes AbIMA, an agent-based intelligent mobile assistant for supporting users prior to and during the execution of their tasks. The agent is based on the well-known AgentSpeak(L) agent architecture and programming language, which provides explicit representations of agents’ beliefs, desires and intentions (BDI). AbIMA is implemented using Java 2 Mobile Edition and is tested on a hand-held computer. We also provide conceptual foundations and discuss various challenges relating to the use of cognitive agent architectures for intelligent mobile user support.},
	language = {en},
	number = {3030},
	urldate = {2016-04-05TZ},
	booktitle = {Agent-{Oriented} {Information} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rahwan, Talal and Rahwan, Tarek and Rahwan, Iyad and Ashri, Ronald},
	editor = {Giorgini, Paolo and Henderson-Sellers, Brian and Winikoff, Michael},
	year = {2004},
	doi = {10.1007/978-3-540-25943-5_4},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Communication Networks, IT in Business, Information Storage and Retrieval, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction},
	pages = {45--60}
}

@article{wobbrock_analyzing_2006,
	title = {Analyzing the {Input} {Stream} for {Character}- {Level} {Errors} in {Unconstrained} {Text} {Entry} {Evaluations}},
	volume = {13},
	issn = {1073-0516},
	url = {http://doi.acm.org/10.1145/1188816.1188819},
	doi = {10.1145/1188816.1188819},
	abstract = {Recent improvements in text entry error rate measurement have enabled the running of text entry experiments in which subjects are free to correct errors (or not) as they transcribe a presented string. In these “unconstrained” experiments, it is no longer necessary to force subjects to unnaturally maintain synchronicity with presented text for the sake of performing overall error rate calculations. However, the calculation of character-level error rates, which can be trivial in artificially constrained evaluations, is far more complicated in unconstrained text entry evaluations because it is difficult to infer a subject's intention at every character. For this reason, prior character-level error analyses for unconstrained experiments have only compared presented and transcribed strings, not input streams. But input streams are rich sources of character-level error information, since they contain all of the text entered (and erased) by a subject. The current work presents an algorithm for the automated analysis of character-level errors in input streams for unconstrained text entry evaluations. It also presents new character-level metrics that can aid method designers in refining text entry methods. To exercise these metrics, we perform two analyses on data from an actual text entry experiment. One analysis, available from the prior work, uses only presented and transcribed strings. The other analysis uses input streams, as described in the current work. The results confirm that input stream error analysis yields richer information for the same empirical data. To facilitate the use of these new analyses, we offer pseudocode and downloadable software for performing unconstrained text entry experiments and analyzing data.},
	number = {4},
	urldate = {2016-04-01TZ},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Wobbrock, Jacob O. and Myers, Brad A.},
	month = dec,
	year = {2006},
	keywords = {EdgeWrite, character recognition, confusion matrix, deletion, error rate, gesture, input stream, insertion, minimum string distance, nonrecognition, omission, optimal alignment, presented string, recognizer, stream alignment, stroke, substitution, text entry, text input, transcribed string},
	pages = {458--489}
}

@inproceedings{vertanen_velocitap:_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {{VelociTap}: {Investigating} {Fast} {Mobile} {Text} {Entry} {Using} {Sentence}-{Based} {Decoding} of {Touchscreen} {Keyboard} {Input}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {{VelociTap}},
	url = {http://doi.acm.org/10.1145/2702123.2702135},
	doi = {10.1145/2702123.2702135},
	abstract = {We present VelociTap: a state-of-the-art touchscreen keyboard decoder that supports a sentence-based text entry approach. VelociTap enables users to seamlessly choose from three word-delimiter actions: pushing a space key, swiping to the right, or simply omitting the space key and letting the decoder infer spaces automatically. We demonstrate that VelociTap has a significantly lower error rate than Google's keyboard while retaining the same entry rate. We show that intermediate visual feedback does not significantly affect entry or error rates and we find that using the space key results in the most accurate results. We also demonstrate that enabling flexible word-delimiter options does not incur an error rate penalty. Finally, we investigate how small we can make the keyboard when using VelociTap. We show that novice users can reach a mean entry rate of 41 wpm on a 40 mm wide smartwatch-sized keyboard at a 3\% character error rate.},
	urldate = {2016-03-31TZ},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Vertanen, Keith and Memmi, Haythem and Emge, Justin and Reyal, Shyam and Kristensson, Per Ola},
	year = {2015},
	keywords = {mobile text entry, sentence decoding, touchscreen keyboard},
	pages = {659--668}
}

@article{mackenzie_text_2002,
	title = {Text entry for mobile computing: {Models} and methods, theory and practice},
	volume = {17},
	shorttitle = {Text entry for mobile computing},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07370024.2002.9667313},
	number = {2-3},
	urldate = {2016-03-31TZ},
	journal = {Human–Computer Interaction},
	author = {MacKenzie, I. Scott and Soukoreff, R. William},
	year = {2002},
	pages = {147--198}
}

@misc{pew_research_center_communications_nodate,
	title = {Communications {Technology} in {Emerging} and {Developing} {Nations}},
	url = {http://www.pewglobal.org/2015/03/19/1-communications-technology-in-emerging-and-developing-nations/},
	abstract = {Internet access differs substantially across the 32 emerging and developing countries polled, with the lowest rates of internet use in South Asian and},
	urldate = {2016-03-31TZ},
	journal = {Pew Research Center's Global Attitudes Project},
	year = {2015},
	author = {Pew Research Center}
}

@incollection{karlson_working_2009,
	title = {Working overtime: {Patterns} of smartphone and {PC} usage in the day of an information worker},
	shorttitle = {Working overtime},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-01516-8_27},
	urldate = {2016-03-31TZ},
	booktitle = {Pervasive computing},
	publisher = {Springer},
	author = {Karlson, Amy K. and Meyers, Brian R. and Jacobs, Andy and Johns, Paul and Kane, Shaun K.},
	year = {2009},
	pages = {398--405}
}

@misc{apple_inc._managing_nodate,
	title = {Managing the {Keyboard}},
	url = {https://developer.apple.com/library/ios/documentation/StringsTextFonts/Conceptual/TextAndWebiPhoneOS/KeyboardManagement/KeyboardManagement.html},
	urldate = {2016-03-31TZ},
	author = {Apple Inc.}
}

@inproceedings{dingler_ill_2015,
	address = {New York, NY, USA},
	series = {{MobileHCI} '15},
	title = {I'{Ll} {Be} {There} for {You}: {Quantifying} {Attentiveness} {Towards} {Mobile} {Messaging}},
	isbn = {978-1-4503-3652-9},
	shorttitle = {I'{Ll} {Be} {There} for {You}},
	url = {http://doi.acm.org/10.1145/2785830.2785840},
	doi = {10.1145/2785830.2785840},
	abstract = {Social norm has it that people are expected to respond to mobile phone messages quickly. We investigate how attentive people really are and how timely they actually check and triage new messages throughout the day. By collecting more than 55,000 messages from 42 mobile phone users over the course of two weeks, we were able to predict people's attentiveness through their mobile phone usage with close to 80\% accuracy. We found that people were attentive to messages 12.1 hours a day, i.e. 84.8 hours per week, and provide statistical evidence how very short people's inattentiveness lasts: in 75\% of the cases mobile phone users return to their attentive state within 5 minutes. In this paper, we present a comprehensive analysis of attentiveness throughout each hour of the day and show that intelligent notification delivery services, such as bounded deferral, can assume that inattentiveness will be rare and subside quickly.},
	urldate = {2016-03-31TZ},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Dingler, Tilman and Pielot, Martin},
	year = {2015},
	keywords = {Attentiveness, Bounded Deferral, availability, interruptibility, mobile devices, responsiveness},
	pages = {1--5}
}

@inproceedings{avrahami_responsiveness_2006,
	address = {New York, NY, USA},
	series = {{CHI} '06},
	title = {Responsiveness in {Instant} {Messaging}: {Predictive} {Models} {Supporting} {Inter}-personal {Communication}},
	isbn = {978-1-59593-372-0},
	shorttitle = {Responsiveness in {Instant} {Messaging}},
	url = {http://doi.acm.org/10.1145/1124772.1124881},
	doi = {10.1145/1124772.1124881},
	abstract = {For the majority of us, inter-personal communication is an essential part of our daily lives. Instant Messaging, or IM, has been growing in popularity for personal and work-related communication. The low cost of sending a message, combined with the limited awareness provided by current IM systems result in messages often arriving at inconvenient or disruptive times. In a step towards solving this problem, we created statistical models that successfully predict responsiveness to incoming instant messages -- simply put: whether the receiver is likely to respond to a message within a certain time period. These models were constructed using a large corpus of real IM interaction collected from 16 participants, including over 90,000 messages. The models we present can predict, with accuracy as high as 90.1\%, whether a message sent to begin a new session of communication would get a response within 30 seconds, 1, 2, 5, and 10 minutes. This type of prediction can be used, for example, to drive online-status indicators, or in services aimed at finding potential communicators.},
	urldate = {2016-03-31TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Avrahami, Daniel and Hudson, Scott E.},
	year = {2006},
	keywords = {availability, awareness, interruptibility, responsiveness, statistical models of human activity},
	pages = {731--740}
}

@inproceedings{fuccella_gestures_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {Gestures and {Widgets}: {Performance} in {Text} {Editing} on {Multi}-touch {Capable} {Mobile} {Devices}},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Gestures and {Widgets}},
	url = {http://doi.acm.org/10.1145/2470654.2481385},
	doi = {10.1145/2470654.2481385},
	abstract = {We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24\% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.},
	urldate = {2016-03-31TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Fuccella, Vittorio and Isokoski, Poika and Martin, Benoit},
	year = {2013},
	keywords = {Android, caret movement, clipboard, gestures, text editing},
	pages = {2785--2794}
}

@article{nardi_collaborative_1998,
	title = {Collaborative, {Programmable} {Intelligent} {Agents}},
	volume = {41},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/272287.272331},
	doi = {10.1145/272287.272331},
	number = {3},
	urldate = {2016-03-31TZ},
	journal = {Commun. ACM},
	author = {Nardi, Bonnie A. and Miller, James R. and Wright, David J.},
	month = mar,
	year = {1998},
	pages = {96--104}
}

@inproceedings{battestini_large_2010,
	address = {New York, NY, USA},
	series = {{MobileHCI} '10},
	title = {A {Large} {Scale} {Study} of {Text}-messaging {Use}},
	isbn = {978-1-60558-835-3},
	url = {http://doi.acm.org/10.1145/1851600.1851638},
	doi = {10.1145/1851600.1851638},
	abstract = {Text messaging has become a popular form of communication with mobile phones worldwide. We present findings from a large scale text messaging study of 70 university students in the United States. We collected almost 60, 000 text messages over a period of 4 months using a custom logging tool on our participants' phones. Our re- sults suggest that students communicate with a large number of contacts for extended periods of time, engage in simultaneous conversations with as many as 9 contacts, and often use text messaging as a method to switch between a variety of communication mediums. We also explore the content of text messages, and ways text message habits have changed over the last decade as it has become more popular. Finally, we offer design suggestions for future mobile communication tools.},
	urldate = {2016-03-30TZ},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Battestini, Agathe and Setlur, Vidya and Sohn, Timothy},
	year = {2010},
	keywords = {large-scale study, mobile device, short message service, sms, text messaging, texting},
	pages = {229--238}
}

@inproceedings{church_whats_2013,
	address = {New York, NY, USA},
	series = {{MobileHCI} '13},
	title = {What's {Up} with {Whatsapp}?: {Comparing} {Mobile} {Instant} {Messaging} {Behaviors} with {Traditional} {SMS}},
	isbn = {978-1-4503-2273-7},
	shorttitle = {What's {Up} with {Whatsapp}?},
	url = {http://doi.acm.org/10.1145/2493190.2493225},
	doi = {10.1145/2493190.2493225},
	abstract = {With the advent of instant mobile messaging applications, traditional SMS is in danger of loosing it's reign as the king of mobile messaging. Applications like WhatsApp allow mobile users to send real-time text messages to individuals or groups of friends at no cost. While there is a vast body of research on traditional text messaging practices, little is understood about how and why people have adopted and appropriated instant mobile messaging applications. The goal of this work is to provide a deeper understanding of the motives and perceptions of a popular mobile messaging application called WhatsApp and to learn more about what this service offers above and beyond traditional SMS. To this end, we present insights from two studies an interview study and a large-scale survey highlighting that while WhatsApp offers benefits such as cost, sense of community and immediacy, SMS is still considered a more reliable, privacy preserving technology for mobile communication.},
	urldate = {2016-03-30TZ},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Church, Karen and de Oliveira, Rodrigo},
	year = {2013},
	keywords = {interview, mobile instant messaging, short message service, sms, survey, text messaging, user study, whatsapp},
	pages = {352--361}
}

@inproceedings{vertanen_invisid_2016,
	title = {Invisid {Text} {Entry} and {Beyond}},
	booktitle = {{CHI} '16 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	author = {Vertanen, Keith and Kristensson, Per Ola and Dunlop, Mark and Arif, Ahmad Sabbir and Clawson, James},
	year = {2016}
}

@inproceedings{kristensson_grand_2013,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '13},
	title = {Grand {Challenges} in {Text} {Entry}},
	isbn = {978-1-4503-1952-2},
	url = {http://doi.acm.org/10.1145/2468356.2479675},
	doi = {10.1145/2468356.2479675},
	abstract = {Our workshop serves two purposes. First, to bring text entry researchers working in the human-computer interaction (HCI), natural language processing (NLP) and augmentative and alternative communication (AAC) communities together at CHI. Second, we will set three major grand challenges for text entry research: a) removing the performance bottleneck in text entry; b) designing efficient localized text entry methods; and c) bridging the communication gap between users with disabilities and society at large. These challenges will be discussed in a panel format at the workshop. The discussions will center on support activities, such as identifying obstacles for success in meeting these challenges and formalizing procedures for measuring progress in the text entry field.},
	urldate = {2016-03-30TZ},
	booktitle = {{CHI} '13 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kristensson, Per Ola and Brewster, Stephen and Clawson, James and Dunlop, Mark and Findlater, Leah and Isokoski, Poika and Martin, Benoît and Oulasvirta, Antti and Vertanen, Keith and Waller, Annalu},
	year = {2013},
	keywords = {accessibility, augmentative and alternative communication, internationalization, text entry},
	pages = {3315--3318}
}

@inproceedings{sun_understanding_2015,
	title = {Understanding {User}’s {Cross}-{Domain} {Intentions} in {Spoken} {Dialog} {Systems}},
	booktitle = {{NIPS} {Workshop} on {Machine} {Learning} for {SLU} and {Interaction}},
	author = {Sun, Ming and Chen, Yun-Nung and Rudnicky, Alexander I.},
	year = {2015}
}

@incollection{zhang_nihao:_2012,
	series = {Lecture {Notes} of the {Institute} for {Computer} {Sciences}, {Social} {Informatics} and {Telecommunications} {Engineering}},
	title = {Nihao: {A} {Predictive} {Smartphone} {Application} {Launcher}},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-36631-4 978-3-642-36632-1},
	shorttitle = {Nihao},
	language = {en},
	number = {110},
	booktitle = {Mobile {Computing}, {Applications}, and {Services}},
	publisher = {Springer Berlin Heidelberg},
	author = {Zhang, Chunhui and Ding, Xiang and Chen, Guanling and Huang, Ke and Ma, Xiaoxiao and Yan, Bo},
	editor = {Uhler, David and Mehta, Khanjan and Wong, Jennifer L.},
	month = oct,
	year = {2012},
	keywords = {Android applications, Computer Systems Organization and Communication Networks, Computers and Society, Information Storage and Retrieval, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction, adaptive UI, application usage prediction, context awareness, mobile applications},
	pages = {294--313}
}

@incollection{zhang_nihao:_2012-1,
	series = {Lecture {Notes} of the {Institute} for {Computer} {Sciences}, {Social} {Informatics} and {Telecommunications} {Engineering}},
	title = {Nihao: {A} {Predictive} {Smartphone} {Application} {Launcher}},
	copyright = {©2013 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering},
	isbn = {978-3-642-36631-4 978-3-642-36632-1},
	shorttitle = {Nihao},
	abstract = {Increasingly large number of the applications installed on smartphones tends to harm the application lookup efficiency. In this paper, we introduce Nihao, a personalized intelligent app launcher system, which could help the users to find apps quickly. Nihao predicts which app the user will likely open next based on a Bayesian Network model leveraging the contextual information such as the time of day, the day of week, the user’s location and the last used app with the hypothesis that the users’ app usage pattern is context dependent. Through the field study with seven users over six weeks, we first validate the above hypothesis by comparing the prediction accuracy of Nihao with other predictors. We found that the larger UI change did not necessarily yield longer app lookup time as the app lookup time highly depended on the app icon position on screen, which suggested the prediction accuracy was the most important factor in designing such a system. At the end of the study, we conducted a user survey to evaluate Nihao qualitatively. The survey results show that five out of seven users were quite satisfied with the prediction of Nihao and thought it could help to save both app lookup and management time by ranking the app icons automatically while Nihao did not help the other two users much since they used their phones primarily for calling and texting (not for apps).},
	language = {en},
	number = {110},
	urldate = {2016-03-30TZ},
	booktitle = {Mobile {Computing}, {Applications}, and {Services}},
	publisher = {Springer Berlin Heidelberg},
	author = {Zhang, Chunhui and Ding, Xiang and Chen, Guanling and Huang, Ke and Ma, Xiaoxiao and Yan, Bo},
	editor = {Uhler, David and Mehta, Khanjan and Wong, Jennifer L.},
	month = oct,
	year = {2012},
	doi = {10.1007/978-3-642-36632-1_17},
	keywords = {Android applications, Computer Systems Organization and Communication Networks, Computers and Society, Information Storage and Retrieval, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction, adaptive UI, application usage prediction, context awareness, mobile applications},
	pages = {294--313}
}

@article{sun_intelligent_nodate,
	title = {An {Intelligent} {Assistant} for {High}-{Level} {Task} {Understanding}},
	author = {Sun, Ming and Chen, Yun-Nung and Rudnicky, Alexander I.}
}

@inproceedings{van_berkel_systematic_2016,
	address = {ACM},
	title = {A {Systematic} {Assessment} of {Smartphone} {Usage} {Gaps}},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {van Berkel, Niels and Luo, Chu and Anagnostopoulos, Theodoros and Ferreira, Denzil and Goncalves, Jorge and Hosio, Simo and Kostakos, Vassilis},
	year = {2016}
}

@article{zhai_performance_2002,
	title = {Performance {Optimization} of {Virtual} {Keyboards}},
	volume = {17},
	issn = {0737-0024},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07370024.2002.9667315},
	doi = {10.1080/07370024.2002.9667315},
	abstract = {Text entry has been a bottleneck of nontraditional computing devices. One of the promising methods is the virtual keyboard for touch screens. Correcting previous estimates on virtual keyboard efficiency in the literature, we estimated the potential performance of the existing Qwerty, FITALY, and OPTI designs of virtual keyboards to be in the neighborhood of 28, 36, and 38 words per minute (wpm), respectively. This article presents 2 quantitative design techniques to search for virtual keyboard layouts. The first technique simulated the dynamics of a keyboard with digraph springs between keys, which produced a Hooke keyboard with 41.6 wpm movement efficiency. The second technique used a Metropolis random walk algorithm guided by a "Fitts-digraph energy" objective function that quantifies the movement efficiency of a virtual keyboard. This method produced various Metropolis keyboards with different shapes and structures with approximately 42.5 wpm movement efficiency, which was 50\% higher than Qwerty and 10\% higher than OPTI. With a small reduction (41.16 wpm) of movement efficiency, we introduced 2 more design objectives that produced the ATOMIK layout. One was alphabetical tuning that placed the keys with a tendency from A to Z so a novice user could more easily locate the keys. The other was word connectivity enhancement so the most frequent words were easier to find, remember, and type.},
	number = {2-3},
	urldate = {2016-03-29TZ},
	journal = {Human–Computer Interaction},
	author = {Zhai, Shumin and Hunter, Michael and Smith, Barton A.},
	month = sep,
	year = {2002},
	pages = {229--269}
}

@inproceedings{stocky_commonsense_2004,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '04},
	title = {A {Commonsense} {Approach} to {Predictive} {Text} {Entry}},
	isbn = {978-1-58113-703-3},
	url = {http://doi.acm.org/10.1145/985921.986014},
	doi = {10.1145/985921.986014},
	abstract = {People cannot type as fast as they think, especially when faced with the constraints of mobile devices. There have been numerous approaches to solving this problem, including research in augmented input devices and predictive typing aids. We propose an alternative approach to predictive text entry based on commonsense reasoning. Using OMCSNet, a large-scale semantic network that aggregates and normalizes the contributions made to Open Mind Common Sense (OMCS), our system is able to show significant success in predicting words based on their first few letters. We evaluate this commonsense approach against traditional statistical methods, demonstrating comparable performance, and suggest that combining commonsense and statistical approaches could achieve superior performance. Mobile device implementations of the commonsense predictive typing aid demonstrate that such a system could be applied to just about any computing environment.},
	urldate = {2016-03-29TZ},
	booktitle = {{CHI} '04 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Stocky, Tom and Faaborg, Alexander and Lieberman, Henry},
	year = {2004},
	keywords = {open mind common sense, predictive interfaces, typing aids},
	pages = {1163--1166}
}

@inproceedings{teevan_understanding_2011,
	address = {New York, NY, USA},
	series = {{MobileHCI} '11},
	title = {Understanding the {Importance} of {Location}, {Time}, and {People} in {Mobile} {Local} {Search} {Behavior}},
	isbn = {978-1-4503-0541-9},
	url = {http://doi.acm.org/10.1145/2037373.2037386},
	doi = {10.1145/2037373.2037386},
	abstract = {People often search for local information (e.g., a restaurant, store, gas station, or attraction) from their mobile device. We show, via a survey of 929 mobile searchers at a large software company, that local searches tend to be highly contextual, influenced by geographic features, temporal aspects, and the searcher's social context. While location was reported to be very important, respondents looked for information about places close to their current location only 40\% of the time. Instead, they were often in transit (68\% of our searchers) and wanted information related to their destination (27\% of searchers), en route to their destination (12\%), or near their destination (12\%). Additionally, 63\% of our participants' mobile local searches took place within a social context and were discussed with someone else. We discuss these findings to present a picture of how location, time, and social context impact mobile local searches.},
	urldate = {2016-03-29TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Teevan, Jaime and Karlson, Amy and Amini, Shahriyar and Brush, A. J. Bernheim and Krumm, John},
	year = {2011},
	keywords = {location prediction, location-based services, location-enhanced services, mobile local search, mobile systems},
	pages = {77--80}
}

@inproceedings{cui_how_2008,
	address = {New York, NY, USA},
	series = {{WWW} '08},
	title = {How {People} {Use} the {Web} on {Mobile} {Devices}},
	isbn = {978-1-60558-085-2},
	url = {http://doi.acm.org/10.1145/1367497.1367619},
	doi = {10.1145/1367497.1367619},
	abstract = {This paper describes a series of user studies on how people use the Web via mobile devices. The data primarily comes from contextual inquiries with 47 participants between 2004 and 2007, and is complemented with a phone log analysis of 577 panelists in 2007. We report four key contextual factors in using the Web on mobile devices and propose mobile Web activity taxonomy. The framework contains three user activity categories identical to previous stationary Web studies: information seeking, communication, and transaction, and a new category: personal space extension. The new category refers to the practice that people put their content on the Web for personal access, therefore extending their personal information space.},
	urldate = {2016-03-29TZ},
	booktitle = {Proceedings of the 17th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Cui, Yanqing and Roto, Virpi},
	year = {2008},
	keywords = {activity taxonomy, content object handling, information seeking, mobile web, personal space extension},
	pages = {905--914}
}

@inproceedings{cui_how_2008-1,
	address = {New York, NY, USA},
	series = {{WWW} '08},
	title = {How {People} {Use} the {Web} on {Mobile} {Devices}},
	isbn = {978-1-60558-085-2},
	url = {http://doi.acm.org/10.1145/1367497.1367619},
	doi = {10.1145/1367497.1367619},
	abstract = {This paper describes a series of user studies on how people use the Web via mobile devices. The data primarily comes from contextual inquiries with 47 participants between 2004 and 2007, and is complemented with a phone log analysis of 577 panelists in 2007. We report four key contextual factors in using the Web on mobile devices and propose mobile Web activity taxonomy. The framework contains three user activity categories identical to previous stationary Web studies: information seeking, communication, and transaction, and a new category: personal space extension. The new category refers to the practice that people put their content on the Web for personal access, therefore extending their personal information space.},
	urldate = {2016-03-29TZ},
	booktitle = {Proceedings of the 17th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Cui, Yanqing and Roto, Virpi},
	year = {2008},
	keywords = {activity taxonomy, content object handling, information seeking, mobile web, personal space extension},
	pages = {905--914}
}

@inproceedings{church_understanding_2011,
	address = {New York, NY, USA},
	series = {{MobileHCI} '11},
	title = {Understanding {Mobile} {Web} and {Mobile} {Search} {Use} in {Today}'s {Dynamic} {Mobile} {Landscape}},
	isbn = {978-1-4503-0541-9},
	url = {http://doi.acm.org/10.1145/2037373.2037385},
	doi = {10.1145/2037373.2037385},
	abstract = {The term mobile Web is changing. Mobile is traditionally associated with on-the-move, portable and dynamic. However, with the advent of smartphones, an increasing number of users are accessing the mobile Internet via their phone while in more stationary and familiar settings, like at home or at work. This shift in the meaning of mobile is having a significant effect on mobile Web behavior. Designing great mobile Web experiences requires a deeper understanding of the information needs, behaviors and underlying motivations of mobile users. As such, the goal of this work is to study this shift and its impact on mobile Internet access, with a view to determining what this means for the future of the mobile Web and in particular mobile search. In this paper we present the results of an online diary and interview study of 18 active mobile Web users over a 4-week period focusing on how, why, where and in what situations people use the mobile Internet and mobile search. Our findings raise a new set of open research questions and point to a number of implications for enriching the experiences of mobile Web users.},
	urldate = {2016-03-29TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Church, Karen and Oliver, Nuria},
	year = {2011},
	keywords = {context, design implications, diary study, mobile internet, mobile search, mobile web, user behavior},
	pages = {67--76}
}

@article{hall_weka_2009,
	title = {The {WEKA} {Data} {Mining} {Software}: {An} {Update}},
	volume = {11},
	issn = {1931-0145},
	shorttitle = {The {WEKA} {Data} {Mining} {Software}},
	url = {http://doi.acm.org/10.1145/1656274.1656278},
	doi = {10.1145/1656274.1656278},
	abstract = {More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.},
	number = {1},
	urldate = {2016-03-27TZ},
	journal = {SIGKDD Explor. Newsl.},
	author = {Hall, Mark and Frank, Eibe and Holmes, Geoffrey and Pfahringer, Bernhard and Reutemann, Peter and Witten, Ian H.},
	month = nov,
	year = {2009},
	pages = {10--18}
}

@inproceedings{kamisaka_operation_2009,
	title = {Operation {Prediction} for {Context}-{Aware} {User} {Interfaces} of {Mobile} {Phones}},
	doi = {10.1109/SAINT.2009.12},
	abstract = {Nowadays mobile phones are multifunctional devices that provide us with various useful applications and services anytime and anywhere. However, people are sometimes unable to access an appropriate application due to the complexity and depth of the menu structure. This paper focuses on a feasibility study of operation prediction using observable attributes to realize self-optimization functionality in the mobile phones that can automatically and adaptively change their user interface (UI) according to user characteristics and circumstances. Machine learning (ML) is a promising technology for enhancing UI. However, few studies have been conducted for the operation prediction using the ML framework. We analyzed the real usage data collected by practical mobile phones and found that ML-based prediction methods were feasible to estimate future operations, and to provide context-aware UI.},
	booktitle = {Ninth {Annual} {International} {Symposium} on {Applications} and the {Internet}, 2009. {SAINT} '09},
	author = {Kamisaka, D. and Muramatsu, S. and Yokoyama, H. and Iwamoto, T.},
	month = jul,
	year = {2009},
	keywords = {Mobile phones, User interfaces, context awareness, context-aware user interfaces, learning (artificial intelligence), machine learning, mobile computing, mobile handsets, mobile phone, multifunctional devices, opeartion prediction, operation prediction, self-optimization functionality, user interface},
	pages = {16--22}
}

@inproceedings{huang_predicting_2012,
	address = {New York, NY, USA},
	series = {{UbiComp} '12},
	title = {Predicting {Mobile} {Application} {Usage} {Using} {Contextual} {Information}},
	isbn = {978-1-4503-1224-0},
	url = {http://doi.acm.org/10.1145/2370216.2370442},
	doi = {10.1145/2370216.2370442},
	abstract = {As the mobile applications become increasing popular, people are installing more and more Apps on their smart phones. In this paper, we answer the question whether it is feasible to predict which App the user will open. The ability for such prediction can help pre-loading the right Apps to the memory for faster execution or help floating the desired Apps to the home screen for quicker launch. We explored a variety of contextual information, such as last used App, time, location, and the user profile, to predict the user's App usage using the MDC dataset. We present three findings from our studies. First, the contextual information can be used to learn the pattern of user's App usage and to predict App usage effectively. Second, for the MDC dataset, the correlation between sequentially used Apps has a strong contribution to the prediction accuracy. Lastly, the linear model is more effective than the Bayesian model to combine all contextual information and for such predictions.},
	urldate = {2016-03-27TZ},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Huang, Ke and Zhang, Chunhui and Ma, Xiaoxiao and Chen, Guanling},
	year = {2012},
	keywords = {application, context, mobile, prediction},
	pages = {1059--1065}
}

@inproceedings{sun_intelligent_2016,
	address = {New York, NY, USA},
	series = {{IUI} '16},
	title = {An {Intelligent} {Assistant} for {High}-{Level} {Task} {Understanding}},
	isbn = {978-1-4503-4137-0},
	url = {http://doi.acm.org/10.1145/2856767.2856818},
	doi = {10.1145/2856767.2856818},
	abstract = {People are able to interact with domain-specific intelligent assistants (IAs) and get help with tasks. But sometimes user goals are complex and may require interactions with multiple applications. However current IAs are limited to specific applications and users have to directly manage execution spanning multiple applications in order to engage in more complex activities. An ideal personal agent would be able to learn, over time, about tasks that span different resources. This paper addresses the problem of cross-domain task assistance in the context of spoken dialogue systems. We propose approaches to discover users' high-level intentions and using this information to assist users in their task. We collected real-life smartphone usage data from 14 participants and investigated how to extract high-level intents from users' descriptions of their activities. Our experiments show that understanding high-level tasks allows the agent to actively suggest apps relevant to pursuing particular user goals and reduce the cost of users' self-management.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Sun, Ming and Chen, Yun-Nung and Rudnicky, Alexander I.},
	year = {2016},
	keywords = {language understanding, multi-domain, spoken dialog system (sds), user intention},
	pages = {169--174}
}

@inproceedings{wobbrock_alternative_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {An {Alternative} to {Push}, {Press}, and {Tap}-tap-tap: {Gesturing} on an {Isometric} {Joystick} for {Mobile} {Phone} {Text} {Entry}},
	isbn = {978-1-59593-593-9},
	shorttitle = {An {Alternative} to {Push}, {Press}, and {Tap}-tap-tap},
	url = {http://doi.acm.org/10.1145/1240624.1240728},
	doi = {10.1145/1240624.1240728},
	abstract = {A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like "pressure strokes." In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1\% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results showed that a joystick on the back could be used at about 70\% of the speed of the front, and the front joystick could be used eyes-free at about 80\% of the speed of normal use.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wobbrock, Jacob O. and Chau, Duen Horng and Myers, Brad A.},
	year = {2007},
	keywords = {EdgeWrite, Mobile phones, T9, gestures, isometric joysticks, multitap, pointing, smartphones, text input, unistrokes},
	pages = {667--676}
}

@inproceedings{wobbrock_letters_2006,
	address = {New York, NY, USA},
	series = {Assets '06},
	title = {From {Letters} to {Words}: {Efficient} {Stroke}-based {Word} {Completion} for {Trackball} {Text} {Entry}},
	isbn = {978-1-59593-290-7},
	shorttitle = {From {Letters} to {Words}},
	url = {http://doi.acm.org/10.1145/1168987.1168990},
	doi = {10.1145/1168987.1168990},
	abstract = {We present a major extension to our previous work on Trackball EdgeWrite--a unistroke text entry method for trackballs--by taking it from a character-level technique to a word-level one. Our design is called stroke-based word completion, and it enables efficient word selection as part of the stroke-making process. Unlike most word completion designs, which require users to select words from a list, our technique allows users to select words by performing a fluid crossing gesture. Our theoretical model shows this word-level design to be 45.0\% faster than our prior model for character-only strokes. A study with a subject with spinal cord injury comparing Trackball EdgeWrite to the onscreen keyboard WiViK, both using word prediction and completion, shows that Trackball EdgeWrite is competitive with WiViK in speed (12.09 vs. 11.82 WPM) and accuracy (3.95\% vs. 2.21\% total errors), but less visually tedious and ultimately preferred. The results also show that word-level Trackball EdgeWrite is 46.5\% faster and 36.7\% more accurate than our subject's prior peak performance with character-level Trackball EdgeWrite, and 75.2\% faster and 40.2\% more accurate than his prior peak performance with his preferred on-screen keyboard. An additional evaluation of the same subject over a two-month field deployment shows a 43.9\% reduction in unistrokes due to strokebased word completion in Trackball EdgeWrite.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 8th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {ACM},
	author = {Wobbrock, Jacob O. and Myers, Brad A.},
	year = {2006},
	keywords = {EdgeWrite, Hick-Hyman law, WiViK, Zipf's law, fitts' law, gestures, goal crossing, steering law, text input, trackballs, unistrokes, word prediction and completion, word-level text entry},
	pages = {2--9}
}

@inproceedings{wobbrock_edgewrite:_2003,
	address = {New York, NY, USA},
	series = {{UIST} '03},
	title = {{EdgeWrite}: {A} {Stylus}-based {Text} {Entry} {Method} {Designed} for {High} {Accuracy} and {Stability} of {Motion}},
	isbn = {978-1-58113-636-4},
	shorttitle = {{EdgeWrite}},
	url = {http://doi.acm.org/10.1145/964696.964703},
	doi = {10.1145/964696.964703},
	abstract = {EdgeWrite is a new unistroke text entry method for handheld devices designed to provide high accuracy and stability of motion for people with motor impairments. It is also effective for able-bodied people. An EdgeWrite user enters text by traversing the edges and diagonals of a square hole imposed over the usual text input area. Gesture recognition is accomplished not through pattern recognition but through the sequence of corners that are hit. This means that the full stroke path is unimportant and recognition is highly deterministic, enabling better accuracy than other gestural alphabets such as Graffiti. A study of able-bodied users showed subjects with no prior experience were 18\% more accurate during text entry with Edge Write than with Graffiti (p{\textgreater}.05), with no significant difference in speed. A study of 4 subjects with motor impairments revealed that some of them were unable to do Graffiti, but all of them could do Edge Write. Those who could do both methods had dramatically better accuracy with Edge Write.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 16th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Wobbrock, Jacob O. and Myers, Brad A. and Kembel, John A.},
	year = {2003},
	keywords = {PDAs, assistive technology, computer access, corners, edges, gesture recognition, graffiti, handhelds, motor impairments, palm, pebbles, text entry, text input, unistrokes},
	pages = {61--70}
}

@inproceedings{vertanen_versatile_2011,
	address = {New York, NY, USA},
	series = {{MobileHCI} '11},
	title = {A {Versatile} {Dataset} for {Text} {Entry} {Evaluations} {Based} on {Genuine} {Mobile} {Emails}},
	isbn = {978-1-4503-0541-9},
	url = {http://doi.acm.org/10.1145/2037373.2037418},
	doi = {10.1145/2037373.2037418},
	abstract = {Mobile text entry methods are typically evaluated by having study participants copy phrases. However, currently there is no available phrase set that has been composed by mobile users. Instead researchers have resorted to using invented phrases that probably suffer from low external validity. Further, there is no available phrase set whose phrases have been verified to be memorable. In this paper we present a collection of mobile email sentences written by actual users on actual mobile devices. We obtained our sentences from emails written by Enron employees on their BlackBerry mobile devices. We provide empirical data on how easy the sentences were to remember and how quickly and accurately users could type these sentences on a full-sized keyboard. Using this empirical data, we construct a series of phrase sets we suggest for use in text entry evaluations.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Vertanen, Keith and Kristensson, Per Ola},
	year = {2011},
	keywords = {mobile email, phrase set, text entry evaluation},
	pages = {295--298}
}

@inproceedings{mizobuchi_mobile_2005,
	address = {New York, NY, USA},
	series = {{MobileHCI} '05},
	title = {Mobile {Text} {Entry}: {Relationship} {Between} {Walking} {Speed} and {Text} {Input} {Task} {Difficulty}},
	isbn = {978-1-59593-089-7},
	shorttitle = {Mobile {Text} {Entry}},
	url = {http://doi.acm.org/10.1145/1085777.1085798},
	doi = {10.1145/1085777.1085798},
	abstract = {The effect of key size on text entry on a handheld device while walking and standing was examined in order to answer the following questions: 1) Will the additional workload of walking amplify the effect of input difficulty? and 2) Can walking speed be used as a secondary task measure of mental workload during mobile text entry? 13 participants (7 males and 6 females) input well known sayings (sentences) in English into a handheld device in each of four size conditions, with the text input box ranging in width between 2 and 5 millimetres (mm). Text input speed increased with larger size of text box up to a size of 3mm, and text input speed was faster when standing (vs. walking). The effect of size did not depend on whether participants were walking or standing. Errors were significantly higher for the 2mm size condition but did not vary for the wider sizes, while subjective ease of input increased with increasing input box width, only crossing the midpoint of the rating scale (i.e., more easy than difficult) at an input box width of 3mm. Based on these results it is recommended that a minimum text input box width of 3mm be used for handheld text input. Walking speed during text entry in this study was relatively low (with a mean of 1.77 km/h) but width of text input box had no additional effect on walking speed over and above the general slowing caused by text entry. Thus the answers to both of the main questions posed in this study were in the negative, although the fact that people had to enter text slowed walking speed by a fixed amount (independent of level of input difficulty) that varied between individuals. Implications for measuring workload in mobile text entry tasks are discussed.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} \& {Services}},
	publisher = {ACM},
	author = {Mizobuchi, Sachi and Chignell, Mark and Newton, David},
	year = {2005},
	keywords = {mobile handheld devices, pen input, software QWERTY keyboard, text entry, walking, workload},
	pages = {122--128}
}

@inproceedings{shin_understanding_2012,
	address = {New York, NY, USA},
	series = {{UbiComp} '12},
	title = {Understanding and {Prediction} of {Mobile} {Application} {Usage} for {Smart} {Phones}},
	isbn = {978-1-4503-1224-0},
	url = {http://doi.acm.org/10.1145/2370216.2370243},
	doi = {10.1145/2370216.2370243},
	abstract = {It is becoming harder to find an app on one's smart phone due to the increasing number of apps available and installed on smart phones today. We collect sensory data including app use from smart phones, to perform a comprehensive analysis of the context related to mobile app use, and build prediction models that calculate the probability of an app in the current context. Based on these models, we developed a dynamic home screen application that presents icons for the most probable apps on the main screen of the phone and highlights the most probable one. Our models outperformed other strategies, and, in particular, improved prediction accuracy by 8\% over Most Frequently Used from 79.8\% to 87.8\% (for 9 candidate apps). Also, we found that the dynamic home screen improved accessibility to apps on the phone, compared to the conventional static home screen in terms of accuracy, required touch input and app selection time.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Shin, Choonsung and Hong, Jin-Hyuk and Dey, Anind K.},
	year = {2012},
	keywords = {app prediction, context-awareness, mobile computing, user interface},
	pages = {173--182}
}

@inproceedings{xu_preference_2013,
	address = {New York, NY, USA},
	series = {{ISWC} '13},
	title = {Preference, {Context} and {Communities}: {A} {Multi}-faceted {Approach} to {Predicting} {Smartphone} {App} {Usage} {Patterns}},
	isbn = {978-1-4503-2127-3},
	shorttitle = {Preference, {Context} and {Communities}},
	url = {http://doi.acm.org/10.1145/2493988.2494333},
	doi = {10.1145/2493988.2494333},
	abstract = {Reliable smartphone app prediction can strongly benefit both users and phone system performance alike. However, real-world smartphone app usage behavior is a complex phenomena driven by a number of competing factors. In this pa- per, we develop an app usage prediction model that leverages three key everyday factors that affect app usage decisions -- (1) intrinsic user app preferences and user historical patterns; (2) user activities and the environment as observed through sensor-based contextual signals; and, (3) the shared aggregate patterns of app behavior that appear in various user communities. While rapid progress has been made recently in smartphone app prediction, existing prediction models tend to focus on only one of these factors. We evaluate a multi-faceted approach to prediction using (1) a 3-week 35-user field trial, along with (2) analysis of app usage logs of 4,606 smartphone users worldwide. We find our app usage model can not only produce more robust app predictions than conventional techniques, but it can also enable significant smartphone system optimizations.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 2013 {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Xu, Ye and Lin, Mu and Lu, Hong and Cardone, Giuseppe and Lane, Nicholas and Chen, Zhenyu and Campbell, Andrew and Choudhury, Tanzeem},
	year = {2013},
	keywords = {Mobile communication, app prediction},
	pages = {69--76}
}

@inproceedings{parate_practical_2013,
	address = {New York, NY, USA},
	series = {{UbiComp} '13},
	title = {Practical {Prediction} and {Prefetch} for {Faster} {Access} to {Applications} on {Mobile} {Phones}},
	isbn = {978-1-4503-1770-2},
	url = {http://doi.acm.org/10.1145/2493432.2493490},
	doi = {10.1145/2493432.2493490},
	abstract = {Mobile phones have evolved from communication devices to indispensable accessories with access to real-time content. The increasing reliance on dynamic content comes at the cost of increased latency to pull the content from the Internet before the user can start using it. While prior work has explored parts of this problem, they ignore the bandwidth costs of prefetching, incur significant training overhead, need several sensors to be turned on, and do not consider practical systems issues that arise from the limited background processing capability supported by mobile operating systems. In this paper, we make app prefetch practical on mobile phones. Our contributions are two-fold. First, we design an app prediction algorithm, APPM, that requires no prior training, adapts to usage dynamics, predicts not only which app will be used next but also when it will be used, and provides high accuracy without requiring additional sensor context. Second, we perform parallel prefetch on screen unlock, a mechanism that leverages the benefits of prediction while operating within the constraints of mobile operating systems. Our experiments are conducted on long-term traces, live deployments on the Android Play Market, and user studies, and show that we outperform prior approaches to predicting app usage, while also providing practical ways to prefetch application content on mobile phones.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 2013 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Parate, Abhinav and Böhmer, Matthias and Chu, David and Ganesan, Deepak and Marlin, Benjamin M.},
	year = {2013},
	keywords = {app prediction, mobile computing, prefetch},
	pages = {275--284}
}

@inproceedings{zou_prophet:_2013,
	address = {New York, NY, USA},
	series = {{UbiComp} '13 {Adjunct}},
	title = {Prophet: {What} {App} {You} {Wish} to {Use} {Next}},
	isbn = {978-1-4503-2215-7},
	shorttitle = {Prophet},
	url = {http://doi.acm.org/10.1145/2494091.2494146},
	doi = {10.1145/2494091.2494146},
	abstract = {A variety of applications (app) installed on smart phones do greatly enrich our lives, but make it more difficult to organize our screens and folders. Predicting apps that will be in use next can benefit users a lot. In this poster, we propose some light-weighted Bayesian methods to predict the next app based on the app usage history. The evaluation on Mobile Data Challenge (MDC) dataset gives very encouraging results. In addition, we suggest a natural way to integrate the app prediction features to the user interface. Users would find it convenient to access the predicted apps with simple touches.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 2013 {ACM} {Conference} on {Pervasive} and {Ubiquitous} {Computing} {Adjunct} {Publication}},
	publisher = {ACM},
	author = {Zou, Xun and Zhang, Wangsheng and Li, Shijian and Pan, Gang},
	year = {2013},
	keywords = {app prediction, context, smart phone, user interface},
	pages = {167--170}
}

@inproceedings{evans_taming_2012,
	address = {New York, NY, USA},
	series = {{CHI} '12},
	title = {Taming {Wild} {Behavior}: {The} {Input} {Observer} for {Obtaining} {Text} {Entry} and {Mouse} {Pointing} {Measures} from {Everyday} {Computer} {Use}},
	isbn = {978-1-4503-1015-4},
	shorttitle = {Taming {Wild} {Behavior}},
	url = {http://doi.acm.org/10.1145/2207676.2208338},
	doi = {10.1145/2207676.2208338},
	abstract = {We present the Input Observer, a tool that can run quietly in the background of users' computers and measure their text entry and mouse pointing performance from everyday use. In lab studies, participants are presented with prescribed tasks, enabling easy identification of speeds and errors. In everyday use, no such prescriptions exist. We devised novel algorithms to segment text entry and mouse pointing input streams into "trials". We are the first to measure errors for unprescribed text entry and mouse pointing. To measure errors, we utilize web search engines, adaptive offline dictionaries, an Automation API, and crowdsourcing. Capturing errors allows us to employ Crossman's (1957) speed-accuracy normalization when calculating Fitts' law throughputs. To validate the Input Observer, we compared its measures from 12 participants over a week of computer use to the same participants' results from a lab study. Overall, in the lab and field, average text entry speeds were 74.47 WPM and 80.59 WPM, respectively. Average uncorrected error rates were near zero, at 0.12\% and 0.28\%. For mouse pointing, average movement times were 971 ms and 870 ms. Average pointing error rates were 4.42\% and 4.66\%. Average throughputs were 3.48 bits/s and 3.45 bits/s. Device makers, researchers, and assistive technology specialists may benefit from measures of everyday use.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Evans, Abigail and Wobbrock, Jacob},
	year = {2012},
	keywords = {everyday, field studies, fitts' law, human performance, in the wild, mouse pointing, text entry},
	pages = {1947--1956}
}

@inproceedings{chang_plug-architecture_2013,
	title = {A plug-in architecture for connecting to new data sources on mobile devices},
	doi = {10.1109/VLHCC.2013.6645243},
	abstract = {A key use for mobile devices is to search and view online information while on the go. As a result, many mobile applications serve as front ends for online databases. While there are many thousands of data sources that provide web service APIs giving access to their databases, creating mobile applications to use those sources requires significant mobile programming knowledge and a significant amount of time. We introduce Spinel, a plug-in architecture for Android, and a set of web-based configuration tools that together enable users to connect mobile applications to new data sources without programming. Spinel also provides APIs that make it easy for developers to create new applications that use those data sources. We provide three demonstration Android applications that use such data: Listpad for entering personal lists, Listviewer for viewing results of data queries, and Mapviewer for displaying query results on a map. An informal usability study showed that users could successfully attach new data sources to those applications.},
	booktitle = {2013 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Chang, K. S. P. and Myers, B. A. and Cahill, G. M. and Simanta, S. and Morris, E. and Lewis, G.},
	month = sep,
	year = {2013},
	keywords = {Android, Android applications, Authentication, Databases, Internet, Mashups, Mobile communication, Programming, Spinel, Web based configuration tools, Web service API, application program interfaces, data sources, database management systems, end-user programming, libraries, mobile applications, mobile computing, mobile devices, mobile handsets, mobile programming knowledge, new data sources, online databases, online information, plug-in architecture, plug-ins, software architecture, web APIs},
	pages = {51--58}
}

@inproceedings{chang_improving_2013,
	address = {New York, NY, USA},
	series = {{UIST} '13},
	title = {Improving {Structured} {Data} {Entry} on {Mobile} {Devices}},
	isbn = {978-1-4503-2268-3},
	url = {http://doi.acm.org/10.1145/2501988.2502043},
	doi = {10.1145/2501988.2502043},
	abstract = {Structure makes data more useful, but also makes data entry more cumbersome. Studies have found that this is especially true on mobile devices, as mobile users often reject structured personal information management tools because the structure is too restrictive and makes entering data slower. To overcome these problems, we introduce a new data entry technique that lets users create customized structured data in an unstructured manner. We use a novel notepad-like editing interface with built-in data detectors that allow users to specify structured data implicitly and reuse the structures when desired. To minimize the amount of typing, it provides intelligent, context-sensitive autocomplete suggestions using personal and public databases that contain candidate information to be entered. We implemented these mechanisms in an example application called Listpad. Our evaluation shows that people using Listpad create customized structured data 16\% faster than using a conventional mobile database tool. The speed further increases to 42\% when the fields can be autocompleted.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 26th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Chang, Kerry Shih-Ping and Myers, Brad A. and Cahill, Gene M. and Simanta, Soumya and Morris, Edwin and Lewis, Grace},
	year = {2013},
	keywords = {autocomplete, data entry, mobile devices, personal information management (pim), structured data},
	pages = {75--84}
}

@inproceedings{stolee_revealing_2009,
	title = {Revealing the copy and paste habits of end users},
	doi = {10.1109/VLHCC.2009.5295296},
	abstract = {Transferring data across applications is a common end user task, and copying and pasting via the clipboard lets users do so relatively easily. Using the clipboard, however, can also introduce inefficiencies and errors in user tasks. To help researchers and tool developers understand and address these problems, we studied how end users interact with the clipboard through cut, copy, and paste actions. This study was performed by logging clipboard interactions while end users performed everyday tasks. From the clip-board usage data, we have identified several usage patterns that describe how data is transferred within the desktop environment. Such patterns help us understand end user behavior and indicate areas in which clipboard support tools can be improved.},
	booktitle = {{IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}, 2009. {VL}/{HCC} 2009},
	author = {Stolee, K. T. and Elbaum, S. and Rothermel, G.},
	month = sep,
	year = {2009},
	keywords = {Application software, Computer errors, Computer science, Data engineering, Delay, Error correction, Productivity, Programming profession, Switches, behavioural sciences computing, clipboard interactions, clipboard support tools, copy-and-paste habits, desktop environment, end users, information retrieval, usage patterns, user centred design},
	pages = {59--66}
}

@inproceedings{karlson_mobile_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {Mobile {Taskflow} in {Context}: {A} {Screenshot} {Study} of {Smartphone} {Usage}},
	isbn = {978-1-60558-929-9},
	shorttitle = {Mobile {Taskflow} in {Context}},
	url = {http://doi.acm.org/10.1145/1753326.1753631},
	doi = {10.1145/1753326.1753631},
	abstract = {The impact of interruptions on workflow and productivity has been extensively studied in the PC domain, but while fragmented user attention is recognized as an inherent aspect of mobile phone usage, little formal evidence exists of its effect on mobile productivity. Using a survey and a screenshot-based diary study we investigated the types of barriers people face when performing tasks on their mobile phones, the ways they follow up with such suspended tasks, and how frustrating the experience of task disruption is for mobile users. From 386 situated samples provided by 12 iPhone and 12 Pocket PC users, we distill a classification of barriers to the completion of mobile tasks. Our data suggest that moving to a PC to complete a phone task is common, yet not inherently problematic, depending on the task. Finally, we relate our findings to prior design guidelines for desktop workflow, and discuss how the guidelines can be extended to mitigate disruptions to mobile taskflow.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Karlson, Amy K. and Iqbal, Shamsi T. and Meyers, Brian and Ramos, Gonzalo and Lee, Kathy and Tang, John C.},
	year = {2010},
	keywords = {cross-device tasks, diary study, mobile taskflow},
	pages = {2009--2018}
}
@inproceedings{banovic_proactivetasks:_2014,
	address = {New York, NY, USA},
	series = {{MobileHCI} '14},
	title = {{ProactiveTasks}: {The} {Short} of {Mobile} {Device} {Use} {Sessions}},
	isbn = {978-1-4503-3004-6},
	shorttitle = {{ProactiveTasks}},
	url = {http://doi.acm.org/10.1145/2628363.2628380},
	doi = {10.1145/2628363.2628380},
	abstract = {Mobile devices have become powerful ultra-portable personal computers supporting not only communication but also running a variety of complex, interactive applications. Because of the unique characteristics of mobile interaction, a better understanding of the time duration and context of mobile device uses could help to improve and streamline the user experience. In this paper, we first explore the anatomy of mobile device use and propose a classification of use based on duration and interaction type: glance, review, and engage. We then focus our investigation on short review interactions and identify opportunities for streamlining these mobile device uses through proactively suggesting short tasks to the user that go beyond simple application notifications. We evaluate the concept through a user evaluation of an interactive lock screen prototype, called ProactiveTasks. We use the findings from our study to create and explore the design space for proactively presenting tasks to the users. Our findings underline the need for a more nuanced set of interactions that support short mobile device uses, in particular review sessions.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 16th {International} {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} \& {Services}},
	publisher = {ACM},
	author = {Banovic, Nikola and Brant, Christina and Mankoff, Jennifer and Dey, Anind},
	year = {2014},
	keywords = {duration, interaction types, mobile devices, proactive tasks},
	pages = {243--252}
}

@inproceedings{brown_iphone_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {{iPhone} in {Vivo}: {Video} {Analysis} of {Mobile} {Device} {Use}},
	isbn = {978-1-4503-1899-0},
	shorttitle = {{iPhone} in {Vivo}},
	url = {http://doi.acm.org/10.1145/2470654.2466132},
	doi = {10.1145/2470654.2466132},
	abstract = {Despite the widespread use of mobile devices, details of mobile technology use 'in the wild' have proven difficult to collect. This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. We use this data to analyse how mobile device use is threaded into other co-present activities, focusing on the use of maps and internet searches. Close analysis reveals novel aspects of gestures on touch screens, how they serve 'double duty' - both as interface gestures but as as resources for ongoing joint action. We go on to describe how users 'walk the blue dot' to orientate themselves, and how searches are occasioned by the local environment. In conclusion, we argue that mobile devices - rather than pushing us away from the world around us - are instead just another thread in the complex tapestry of everyday interaction.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brown, Barry and McGregor, Moira and Laurier, Eric},
	year = {2013},
	keywords = {ethnography, mobility, smartphone use, video methods},
	pages = {1031--1040}
}

@inproceedings{sohn_diary_2008,
	address = {New York, NY, USA},
	series = {{CHI} '08},
	title = {A {Diary} {Study} of {Mobile} {Information} {Needs}},
	isbn = {978-1-60558-011-1},
	url = {http://doi.acm.org/10.1145/1357054.1357125},
	doi = {10.1145/1357054.1357125},
	abstract = {Being mobile influences not only the types of information people seek but also the ways they attempt to access it. Mobile contexts present challenges of changing location and social context, restricted time for information access, and the need to share attentional resources among concurrent activities. Understanding mobile information needs and associated interaction challenges is fundamental to improving designs for mobile phones and related devices. We conducted a two-week diary study to better understand mobile information needs and how they are addressed. Our study revealed that depending on the time and resources available, as well as the situational context, people use diverse and, at times, ingenious ways to obtain needed information. We summarize key findings and discuss design implications for mobile technology.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sohn, Timothy and Li, Kevin A. and Griswold, William G. and Hollan, James D.},
	year = {2008},
	keywords = {diary study, mobile devices, user requirements},
	pages = {433--442}
}

@misc{noauthor_notitle_nodate,
	url = {http://delivery.acm.org/10.1145/1360000/1357125/p433-sohn.pdf?ip=128.237.166.171&id=1357125&acc=ACTIVE%20SERVICE&key=A792924B58C015C1%2E5A12BE0369099858%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=594135131&CFTOKEN=86875366&__acm__=1458930104_b753056ed2a5f6506f9b528f8621fb41},
	urldate = {2016-03-25TZ}
}

@article{sarker_understanding_2003,
	title = {Understanding {Mobile} {Handheld} {Device} {Use} and {Adoption}},
	volume = {46},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/953460.953484},
	doi = {10.1145/953460.953484},
	abstract = {Without device adoption, there is no mobile commerce.},
	number = {12},
	urldate = {2016-03-25TZ},
	journal = {Commun. ACM},
	author = {Sarker, Suprateek and Wells, John D.},
	month = dec,
	year = {2003},
	pages = {35--40}
}

@article{barkhuus_empowerment_2011,
	title = {Empowerment {Through} {Seamfulness}: {Smart} {Phones} in {Everyday} {Life}},
	volume = {15},
	issn = {1617-4909},
	shorttitle = {Empowerment {Through} {Seamfulness}},
	url = {http://dx.doi.org/10.1007/s00779-010-0342-4},
	doi = {10.1007/s00779-010-0342-4},
	abstract = {In this paper, we describe research into use of multifunctional mobile phones by working adults and posit the device as a plausible realization of ubiquitous computing. We investigate how users actively adapt and adopt the different functions in smart phones to suit their needs and lifestyles. Through an interview and diary study, we discover how the smart phone is used in pragmatic and seamful ways, regardless of the interface of the specific phone selected or the particular features available. Users used phones in highly individual manners; mixed and adapted existing functions to meet their own priorities; added some functions and ignored others to create their own portfolio; and blended their use with the specifics of their everyday lives. While these data challenge some assumptions of human---computer interaction and ubiquitous computing, it also presents new research potential in terms of understanding how users take advantage of the multiple features in smart phone devices and how they utilize seamfulness in everyday smart phones practices.},
	number = {6},
	urldate = {2016-03-25TZ},
	journal = {Personal Ubiquitous Comput.},
	author = {Barkhuus, Louise and Polichar, Valerie E.},
	month = aug,
	year = {2011},
	keywords = {Cell phones, Mobile phones, Multi-functionality, Seamfulness, user study},
	pages = {629--639}
}

@inproceedings{ferreira_contextual_2014,
	address = {New York, NY, USA},
	series = {{MobileHCI} '14},
	title = {Contextual {Experience} {Sampling} of {Mobile} {Application} {Micro}-usage},
	isbn = {978-1-4503-3004-6},
	url = {http://doi.acm.org/10.1145/2628363.2628367},
	doi = {10.1145/2628363.2628367},
	abstract = {Research suggests smartphone users face 'application overload', but literature lacks an in-depth investigation of how users manage their time on smartphones. In a 3-week study we collected smartphone application usage patterns from 21 participants to study how they manage their time interacting with the device. We identified events we term application micro-usage: brief bursts of interaction with applications. While this practice has been reported before, it has not been investigated in terms of the context in which it occurs (e.g., location, time, trigger and social context). In a 2-week follow-up study with 15 participants, we captured participants? context while micro-using, with a mobile experience sampling method (ESM) and weekly interviews. Our results show that about approximately 40\% of application launches last less than 15 seconds and happen most frequently when the user is at home and alone. We further discuss the context, taxonomy and implications of application micro-usage in our field. We conclude with a brief reflection on the relevance of short-term interaction observations for other domains beyond mobile phones.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 16th {International} {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} \& {Services}},
	publisher = {ACM},
	author = {Ferreira, Denzil and Goncalves, Jorge and Kostakos, Vassilis and Barkhuus, Louise and Dey, Anind K.},
	year = {2014},
	keywords = {context-awareness, design implications, mobile automated logging},
	pages = {91--100}
}

@inproceedings{likamwa_moodscope:_2013,
	address = {New York, NY, USA},
	series = {{MobiSys} '13},
	title = {{MoodScope}: {Building} a {Mood} {Sensor} from {Smartphone} {Usage} {Patterns}},
	isbn = {978-1-4503-1672-9},
	shorttitle = {{MoodScope}},
	url = {http://doi.acm.org/10.1145/2462456.2464449},
	doi = {10.1145/2462456.2464449},
	abstract = {We report a first-of-its-kind smartphone software system, MoodScope, which infers the mood of its user based on how the smartphone is used. Compared to smartphone sensors that measure acceleration, light, and other physical properties, MoodScope is a "sensor" that measures the mental state of the user and provides mood as an important input to context-aware computing. We run a formative statistical mood study with smartphone-logged data collected from 32 participants over two months. Through the study, we find that by analyzing communication history and application usage patterns, we can statistically infer a user's daily mood average with an initial accuracy of 66\%, which gradu-ally improves to an accuracy of 93\% after a two-month personal-ized training period. Motivated by these results, we build a service, MoodScope, which analyzes usage history to act as a sensor of the user's mood. We provide a MoodScope API for developers to use our system to create mood-enabled applications. We further create and deploy a mood-sharing social application.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceeding of the 11th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {LiKamWa, Robert and Liu, Yunxin and Lane, Nicholas D. and Zhong, Lin},
	year = {2013},
	keywords = {affective computing, machine learning, mobile systems, mood, smartphone usage},
	pages = {389--402}
}

@inproceedings{srinivasan_mobileminer:_2014,
	address = {New York, NY, USA},
	series = {{UbiComp} '14},
	title = {{MobileMiner}: {Mining} {Your} {Frequent} {Patterns} on {Your} {Phone}},
	isbn = {978-1-4503-2968-2},
	shorttitle = {{MobileMiner}},
	url = {http://doi.acm.org/10.1145/2632048.2632052},
	doi = {10.1145/2632048.2632052},
	abstract = {Smartphones can collect considerable context data about the user, ranging from apps used to places visited. Frequent user patterns discovered from longitudinal, multi-modal context data could help personalize and improve overall user experience. Our long term goal is to develop novel middleware and algorithms to efficiently mine user behavior patterns entirely on the phone by utilizing idle processor cycles. Mining patterns on the mobile device provides better privacy guarantees to users, and reduces dependency on cloud connectivity. As an important step in this direction, we develop a novel general-purpose service called MobileMiner that runs on the phone and discovers frequent co-occurrence patterns indicating which context events frequently occur together. Using longitudinal context data collected from 106 users over 1--3 months, we show that MobileMiner efficiently generates patterns using limited phone resources. Further, we find interesting behavior patterns for individual users and across users, ranging from calling patterns to place visitation patterns. Finally, we show how our co-occurrence patterns can be used by developers to improve the phone UI for launching apps or calling contacts.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Srinivasan, Vijay and Moghaddam, Saeed and Mukherji, Abhishek and Rachuri, Kiran K. and Xu, Chenren and Tapia, Emmanuel Munguia},
	year = {2014},
	keywords = {context prediction, mobile data mining, rule mining},
	pages = {389--400}
}

@inproceedings{hammer_exploiting_2014,
	address = {New York, NY, USA},
	series = {{ISWC} '14},
	title = {Exploiting {Usage} {Statistics} for {Energy}-efficient {Logical} {Status} {Inference} on {Mobile} {Phones}},
	isbn = {978-1-4503-2969-9},
	url = {http://doi.acm.org/10.1145/2634317.2634325},
	doi = {10.1145/2634317.2634325},
	abstract = {Logical statuses of mobile users, such as isBusy and isAlone, are the key enabler for a plethora of context-aware mobile applications. While on-board hardware sensors, such as motion, proximity, and location sensors, have been extensively studied for logical status inference, the continuous usage incurs formidable energy consumption and therefore user experience degradation. In this paper, we argue that smartphone usage statistics can be used for logical status inference with negligible energy cost. To validate this argument, this paper presents a continuous inference engine that (1) intercepts multiple operating system events, in particular foreground app, notifications, screen states, and connected networks; (2) extracts informative features from OS events; and (3) efficiently infers the logical status of mobile users. The proposed inference engine is implemented for unmodified Android phones, and an evaluation on a four-week trial has shown promising accuracy in identifying four logical statuses of mobile users with over 87\% accuracy while the average energy impact on the battery life is less than 0.5\%.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Hammer, Jon C. and Yan, Tingxin},
	year = {2014},
	keywords = {logical status inference, smartphone usage, virtual sensors},
	pages = {35--42}
}

@article{shepard_livelab:_2011,
	title = {{LiveLab}: {Measuring} {Wireless} {Networks} and {Smartphone} {Users} in the {Field}},
	volume = {38},
	issn = {0163-5999},
	shorttitle = {{LiveLab}},
	url = {http://doi.acm.org/10.1145/1925019.1925023},
	doi = {10.1145/1925019.1925023},
	abstract = {We present LiveLab, a methodology to measure real-world smartphone usage and wireless networks with a reprogrammable indevice logger designed for long-term user studies. We discuss the challenges of privacy protection and power impact in LiveLab and offer our solutions. We present an iPhone 3GS based deployment of LiveLab with 25 users intended for one year. Early results from the data collection so far highlight the unique strengths and potential of LiveLab. We have two objectives in this position paper. First, we demonstrate the feasibility and capability of LiveLab. By sharing our experience, we seek to advocate LiveLab as a network and user measurement methodology. Second, we present our preliminary findings, and seek feedback from the community regarding what data to collect.},
	number = {3},
	urldate = {2016-03-25TZ},
	journal = {SIGMETRICS Perform. Eval. Rev.},
	author = {Shepard, Clayton and Rahmati, Ahmad and Tossell, Chad and Zhong, Lin and Kortum, Phillip},
	month = jan,
	year = {2011},
	pages = {15--20}
}

@inproceedings{yan_fast_2012,
	address = {New York, NY, USA},
	series = {{MobiSys} '12},
	title = {Fast {App} {Launching} for {Mobile} {Devices} {Using} {Predictive} {User} {Context}},
	isbn = {978-1-4503-1301-8},
	url = {http://doi.acm.org/10.1145/2307636.2307648},
	doi = {10.1145/2307636.2307648},
	abstract = {As mobile apps become more closely integrated into our everyday lives, mobile app interactions ought to be rapid and responsive. Unfortunately, even the basic primitive of launching a mobile app is sorrowfully sluggish: 20 seconds of delay is not uncommon even for very popular apps. We have designed and built FALCON to remedy slow app launch. FALCON uses contexts such as user location and temporal access patterns to predict app launches before they occur. FALCON then provides systems support for effective app-specific prelaunching, which can dramatically reduce perceived delay. FALCON uses novel features derived through extensive data analysis, and a novel cost-benefit learning algorithm that has strong predictive performance and low runtime overhead. Trace-based analysis shows that an average user saves around 6 seconds per app startup time with daily energy cost of no more than 2\% battery life, and on average gets content that is only 3 minutes old at launch without needing to wait for content to update. FALCON is implemented as an OS modification to the Windows Phone OS.},
	urldate = {2016-03-25TZ},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Yan, Tingxin and Chu, David and Ganesan, Deepak and Kansal, Aman and Liu, Jie},
	year = {2012},
	keywords = {application prediction, context, location, mobile devices},
	pages = {113--126}
}

@misc{google_android_2016,
	title = {Android {Developer} {Reference} - {Activity}},
	url = {http://developer.android.com/reference/android/app/Activity.html},
	author = {Google},
	year = {2016}
}

@inproceedings{kim_xdroid_2019,
author = {Kim, Donghwi and Park, Sooyoung and Ko, Jihoon and Ko, Steven Y. and Lee, Sung-Ju},
title = {X-Droid: A Quick and Easy Android Prototyping Framework with a Single-App Illusion},
year = {2019},
isbn = {9781450368162},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3332165.3347890},
doi = {10.1145/3332165.3347890},
abstract = {We present X-Droid, a framework that provides Android app developers an ability to quickly and easily produce functional prototypes. Our work is motivated by the need for such ability and the lack of tools that provide it. Developers want to produce a functional prototype rapidly to test out potential features in real-life situations. However, current prototyping tools for mobile apps are limited to creating non-functional UI mockups that do not demonstrate actual features. With X-Droid, developers can create a new app that imports various kinds of functionality provided by other existing Android apps. In doing so, developers do not need to understand how other Android apps are implemented or need access to their source code. X-Droid provides a developer tool that enables developers to use the UIs of other Android apps and import desired functions into their prototypes. X-Droid also provides a run-time system that executes other apps' functionality in the background on off-the-shelf Android devices for seamless integration. Our evaluation shows that with the help of X-Droid, a developer imported a function from an existing Android app into a new prototype with only 51 lines of Java code, while the function itself requires 10,334 lines of Java code to implement (i.e., 200\texttimes{} improvement).},
booktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},
pages = {95–108},
numpages = {14},
keywords = {development frameworks, programming by demonstration (pbd), android, functional prototyping},
location = {New Orleans, LA, USA},
series = {UIST '19}
}

@misc{noauthor_suggest_nodate,
	title = {Suggest a {New} {Atlasify} {Reference} {System}!},
	url = {https://docs.google.com/forms/d/1c-DsuDwWjGE7pZMUB0gIX-qi2Af-Zmrv08E9xnSdxq4/viewform?usp=embed_facebook},
	abstract = {Want to visualize your keyword in a new reference system? Let us know! Atlasify is still in beta stage and we are excited to learn about new possibilities for generating cool visualizations to meet your information needs!},
	urldate = {2016-03-15TZ},
	journal = {Google Docs}
}



@inproceedings{yeh_sikuli:_2009,
	address = {New York, NY, USA},
	series = {{UIST} '09},
	title = {Sikuli: {Using} {GUI} {Screenshots} for {Search} and {Automation}},
	isbn = {978-1-60558-745-5},
	shorttitle = {Sikuli},
	url = {http://doi.acm.org/10.1145/1622176.1622213},
	doi = {10.1145/1622176.1622213},
	abstract = {We present Sikuli, a visual approach to search and automation of graphical user interfaces using screenshots. Sikuli allows users to take a screenshot of a GUI element (such as a toolbar button, icon, or dialog box) and query a help system using the screenshot instead of the element's name. Sikuli also provides a visual scripting API for automating GUI interactions, using screenshot patterns to direct mouse and keyboard events. We report a web-based user study showing that searching by screenshot is easy to learn and faster to specify than keywords. We also demonstrate several automation tasks suitable for visual scripting, such as map navigation and bus tracking, and show how visual scripting can improve interactive help systems previously proposed in the literature.},
	urldate = {2016-03-02TZ},
	booktitle = {Proceedings of the 22Nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Yeh, Tom and Chang, Tsung-Hsiang and Miller, Robert C.},
	year = {2009},
	keywords = {automation, image search, online help},
	pages = {183--192}
}

@inproceedings{zimmerman_research_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {Research {Through} {Design} {As} a {Method} for {Interaction} {Design} {Research} in {HCI}},
	isbn = {978-1-59593-593-9},
	url = {http://doi.acm.org/10.1145/1240624.1240704},
	doi = {10.1145/1240624.1240704},
	abstract = {For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.},
	urldate = {2016-03-02TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zimmerman, John and Forlizzi, Jodi and Evenson, Shelley},
	year = {2007},
	keywords = {HCI research, design, design method, design theory, interaction design, interaction design research, research through design, wicked problems},
	pages = {493--502}
}

@article{rittel_dilemmas_1973,
	title = {Dilemmas in a general theory of planning},
	volume = {4},
	issn = {0032-2687, 1573-0891},
	url = {http://link.springer.com/article/10.1007/BF01405730},
	doi = {10.1007/BF01405730},
	abstract = {The search for scientific bases for confronting problems of social policy is bound to fail, becuase of the nature of these problems. They are “wicked” problems, whereas science has developed to deal with “tame” problems. Policy problems cannot be definitively described. Moreover, in a pluralistic society there is nothing like the undisputable public good; there is no objective definition of equity; policies that respond to social problems cannot be meaningfully correct or false; and it makes no sense to talk about “optimal solutions” to social problems unless severe qualifications are imposed first. Even worse, there are no “solutions” in the sense of definitive and objective answers.},
	language = {en},
	number = {2},
	urldate = {2016-03-02TZ},
	journal = {Policy Sciences},
	author = {Rittel, Horst W. J. and Webber, Melvin M.},
	month = jun,
	year = {1973},
	keywords = {Economic Policy, Political Science},
	pages = {155--169}
}

@article{pane_studying_2001,
	title = {Studying the language and structure in non-programmers' solutions to programming problems},
	volume = {54},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581900904105},
	number = {2},
	urldate = {2016-03-02TZ},
	journal = {International Journal of Human-Computer Studies},
	author = {Pane, John F. and Myers, Brad A. and {others}},
	year = {2001},
	pages = {237--264}
}

@book{biermann_natural_1983,
	title = {Natural language programming},
	url = {http://link.springer.com/chapter/10.1007/978-94-009-7019-9_10},
	urldate = {2016-03-02TZ},
	publisher = {Springer},
	author = {Biermann, Alan W.},
	year = {1983}
}

@book{constantine_software_1999,
	title = {Software for use: a practical guide to the models and methods of usage-centered design},
	shorttitle = {Software for use},
	url = {https://books.google.com/books?hl=en&lr=&id=Y0ic4kK9E7cC&oi=fnd&pg=PT9&dq=Software+for+Use:+A+Practical+Guide+to+the+Models+and+Methods+of+Usage-Centered+Design&ots=xkdGYGe6i3&sig=uDVyDC46-Ky2DKtw5p5ZmVhTor4},
	urldate = {2016-03-01TZ},
	publisher = {Pearson Education},
	author = {Constantine, Larry L. and Lockwood, Lucy AD},
	year = {1999}
}

@article{dorst_core_2011,
	series = {Interpreting {Design} {Thinking}},
	title = {The core of ‘design thinking’ and its application},
	volume = {32},
	issn = {0142-694X},
	url = {http://www.sciencedirect.com/science/article/pii/S0142694X11000603},
	doi = {10.1016/j.destud.2011.07.006},
	abstract = {In the last few years, “Design Thinking” has gained popularity – it is now seen as an exciting new paradigm for dealing with problems in sectors as far a field as IT, Business, Education and Medicine. This potential success challenges the design research community to provide unambiguous answers to two key questions: “What is the core of Design Thinking?” and “What could it bring to practitioners and organisations in other fields?”. We sketch a partial answer by considering the fundamental reasoning pattern behind design, and then looking at the core design practices of framing and frame creation. The paper ends with an exploration of the way in which these core design practices can be adopted for organisational problem solving and innovation.},
	number = {6},
	urldate = {2016-03-01TZ},
	journal = {Design Studies},
	author = {Dorst, Kees},
	month = nov,
	year = {2011},
	keywords = {design practice, framing, problem solving, reasoning},
	pages = {521--532}
}

@article{kahn_jr._robovie_2012,
	title = {“{Robovie}, you'll have to go into the closet now”: {Children}'s social and moral relationships with a humanoid robot},
	volume = {48},
	copyright = {(c) 2015 APA, all rights reserved},
	issn = {1939-0599(Electronic);0012-1649(Print)},
	shorttitle = {“{Robovie}, you'll have to go into the closet now”},
	doi = {10.1037/a0027033},
	abstract = {Children will increasingly come of age with personified robots and potentially form social and even moral relationships with them. What will such relationships look like? To address this question, 90 children (9-, 12-, and 15-year-olds) initially interacted with a humanoid robot, Robovie, in 15-min sessions. Each session ended when an experimenter interrupted Robovie's turn at a game and, against Robovie's stated objections, put Robovie into a closet. Each child was then engaged in a 50-min structural–developmental interview. Results showed that during the interaction sessions, all of the children engaged in physical and verbal social behaviors with Robovie. The interview data showed that the majority of children believed that Robovie had mental states (e.g., was intelligent and had feelings) and was a social being (e.g., could be a friend, offer comfort, and be trusted with secrets). In terms of Robovie's moral standing, children believed that Robovie deserved fair treatment and should not be harmed psychologically but did not believe that Robovie was entitled to its own liberty (Robovie could be bought and sold) or civil rights (in terms of voting rights and deserving compensation for work performed). Developmentally, while more than half the 15-year-olds conceptualized Robovie as a mental, social, and partly moral other, they did so to a lesser degree than the 9- and 12-year-olds. Discussion focuses on how (a) children's social and moral relationships with future personified robots may well be substantial and meaningful and (b) personified robots of the future may emerge as a unique ontological category.},
	number = {2},
	journal = {Developmental Psychology},
	author = {Kahn Jr., Peter H. and Kanda, Takayuki and Ishiguro, Hiroshi and Freier, Nathan G. and Severson, Rachel L. and Gill, Brian T. and Ruckert, Jolina H. and Shen, Solace},
	year = {2012},
	keywords = {*Child Attitudes, *Human Computer Interaction, *Robotics, Autonomy, Independence (Personality), Mental models},
	pages = {303--314}
}

@inproceedings{mutlu_robots_2008,
	title = {Robots in organizations: the role of workflow, social, and environmental factors in human-robot interaction},
	shorttitle = {Robots in organizations},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6249448},
	urldate = {2016-03-01TZ},
	booktitle = {Proceedings of the 3rd {ACM}/{IEEE} international conference on {Human} robot interaction},
	publisher = {ACM},
	author = {Mutlu, Bilge and Forlizzi, Jodi},
	year = {2008},
	pages = {287--294}
}

@article{bartneck_influence_2010,
	title = {The influence of robot anthropomorphism on the feelings of embarrassment when interacting with robots},
	volume = {1},
	issn = {2081-4836},
	url = {http://www.degruyter.com/view/j/pjbr.2010.1.issue-2/s13230-010-0011-3/s13230-010-0011-3.xml},
	doi = {10.2478/s13230-010-0011-3},
	abstract = {Medical robots are expected to help with providing care in an aging society. The degree to which patients experience embarrassment in a medical examination might be influenced by the robots’ level of anthropomorphism. The results of our preliminary study show that young, healthy, Dutch university students were less embarrassed when interacting with a technical box than with a robot. Highly human-like robots might therefore not be the best choice for a medical robot. This result also shows that the robot was perceived as a person more so than the technical box. The next step is to compare the robot to a real nurse or doctor. If patients are less embarrassed when interacting with a robot, then, potentially, patients will be less likely to defer important medical examinations when carried out by medical robots.},
	number = {2},
	urldate = {2016-03-01TZ},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Bartneck, Christoph and Bleeker, Timo and Bun, Jeroen and Fens, Pepijn and Riet, Lynyrd},
	year = {2010},
	pages = {109--115}
}

@article{hoorn_role_2006,
	title = {The role of social norm in user-engagement and appreciation of the web interface agent bonzi buddy},
	volume = {456},
	url = {http://link.springer.com/content/pdf/10.1007/11821830.pdf#page=469},
	urldate = {2016-03-01TZ},
	journal = {Lecture Notes in Artificial Intelligence (LNAI) 4133},
	author = {Hoorn, Johan F. and van Vugt, Henriette C.},
	year = {2006}
}

@inproceedings{myers_invited_2006,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '06},
	title = {Invited {Research} {Overview}: {End}-user {Programming}},
	isbn = {1-59593-298-4},
	shorttitle = {Invited {Research} {Overview}},
	url = {http://doi.acm.org/10.1145/1125451.1125472},
	doi = {10.1145/1125451.1125472},
	abstract = {In the past few decades there has been considerable work on empowering end users to be able to write their own programs, and as a result, users are indeed doing so. In fact, we estimate that over 12 million people in American workplaces would say that they "do programming" at work, and almost 50 million people use spreadsheets or databases (and therefore may potentially program), compared to only 3 million professional programmers. The "programming" systems used by these end users include spreadsheet systems, web authoring tools, business process authoring tools such as Visual Basic, graphical languages for demonstrating the desired behavior of educational simulations, and even professional languages such as Java. The motivation for end-user programming is to have the computer be useful for each person's specific individual needs. While the empirical study of programming has been an HCI topic since the beginning the field, it is only recently that there has been a focus on the End-User Programmer as a separate class from novices who are assumed to be studying to be professional programmers. Another recent focus is on making end-user programming more reliable, using "End-User Software Engineering." This paper gives a brief summary of some current and past research in the area of End-User Programming.},
	urldate = {2016-02-28TZ},
	booktitle = {{CHI} '06 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Myers, Brad A. and Ko, Amy J. and Burnett, Margaret M.},
	year = {2006},
	keywords = {empirical studies of programmers (ESP), end-user software engineering, natural programming, programming by demonstration, programming by example, psychology of programming, visual programming},
	pages = {75--80}
}

@inproceedings{burg_interactive_2013,
	address = {New York, NY, USA},
	series = {{UIST} '13},
	title = {Interactive {Record}/{Replay} for {Web} {Application} {Debugging}},
	isbn = {978-1-4503-2268-3},
	url = {http://doi.acm.org/10.1145/2501988.2502050},
	doi = {10.1145/2501988.2502050},
	abstract = {During debugging, a developer must repeatedly and manually reproduce faulty behavior in order to inspect different facets of the program's execution. Existing tools for reproducing such behaviors prevent the use of debugging aids such as breakpoints and logging, and are not designed for interactive, random-access exploration of recorded behavior. This paper presents Timelapse, a tool for quickly recording, reproducing, and debugging interactive behaviors in web applications. Developers can use Timelapse to browse, visualize, and seek within recorded program executions while simultaneously using familiar debugging tools such as breakpoints and logging. Testers and end-users can use Timelapse to demonstrate failures in situ and share recorded behaviors with developers, improving bug report quality by obviating the need for detailed reproduction steps. Timelapse is built on Dolos, a novel record/replay infrastructure that ensures deterministic execution by capturing and reusing program inputs both from the user and from external sources such as the network. Dolos introduces negligible overhead and does not interfere with breakpoints and logging. In a small user evaluation, participants used Timelapse to accelerate existing reproduction activities, but were not significantly faster or more successful in completing the larger tasks at hand. Together, the Dolos infrastructure and Timelapse developer tool support systematic bug reporting and debugging practices.},
	urldate = {2016-02-28TZ},
	booktitle = {Proceedings of the 26th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Burg, Brian and Bailey, Richard and Ko, Amy J. and Ernst, Michael D.},
	year = {2013},
	keywords = {Debugging, deterministic replay, web applications},
	pages = {473--484}
}

@inproceedings{oney_firecrystal:_2009,
	title = {{FireCrystal}: {Understanding} interactive behaviors in dynamic web pages},
	shorttitle = {{FireCrystal}},
	doi = {10.1109/VLHCC.2009.5295287},
	abstract = {For developers debugging their own code, augmenting the code of others, or trying to learn the implementation details of interactive behaviors, understanding how web pages work is a fundamental problem. FireCrystal is a new Firefox extension that allows developers to indicate interactive behaviors of interest, and shows the specific code (Javascript, CSS, and HTML) that is responsible for those behaviors. FireCrystal provides an execution timeline that users can scrub back and forth, and the ability to select items of interest in the actual web page UI to see the associated code. FireCrystal may be especially useful for developers who are trying to learn the implementation details of interactive behaviors, so they can reuse these behaviors in their own web site.},
	booktitle = {{IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}, 2009. {VL}/{HCC} 2009},
	author = {Oney, S. and Myers, B.},
	month = sep,
	year = {2009},
	keywords = {Cascading style sheets, Debugging, FireCrystal, Firefox extension, Formal languages, HTML, Human factors, Internet, Java, Mice, Programming profession, User interfaces, Web page design, Web page user interface, Web pages, code debugging, dynamic Web pages, execution timeline, interactive behavior understanding, online front-ends, program debugging},
	pages = {105--108}
}

@incollection{chen_expressing_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Expressing {Graphical} {User}’s {Input} for {Test} {Specifications}},
	copyright = {©2002 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-44222-6 978-3-540-45785-5},
	url = {http://link.springer.com/chapter/10.1007/3-540-45785-2_27},
	abstract = {As more and more applications now involve graphical user’s interactions, an essential issue we are facing is how to automate effective testing on GUI-based applications. Many factors have contributed to the new dimensions of the complexity in the automated testing in this regard, one of them being how to properly characterize the graphical user’s input from the prospective of test users. Here we propose a possible way of characterizing graphical user’s input. This treatment is used in our prototype implementation of an automated tool to support the testing of the presentation logic in GUI-based applications. It plays an important role in enhancing the scalability of this testing environment with respect to the various types of graphical user’s input. We introduce the respect enhancement and discuss the important design issues in it.},
	language = {en},
	number = {2480},
	urldate = {2016-02-28TZ},
	booktitle = {Engineering and {Deployment} of {Cooperative} {Information} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Chen, Jessica},
	editor = {Han, Yanbo and Tai, Stefan and Wikarski, Dietmar},
	year = {2002},
	doi = {10.1007/3-540-45785-2_27},
	keywords = {Artificial Intelligence (incl. Robotics), Capture/Replay, Computer Communication Networks, Data Structures, Cryptology and Information Theory, Finite State Machines, Graphical User’s Interface, IT in Business, Information Systems and Communication Service, Java Swing and AWT, Software Engineering/Programming and Operating Systems, Specification-based Testing},
	pages = {347--359}
}

@inproceedings{scaffidi_estimating_2005,
	title = {Estimating the numbers of end users and end user programmers},
	doi = {10.1109/VLHCC.2005.34},
	abstract = {In 1995, Boehm predicted that by 2005, there would be "55 million performers" of "end user programming" in the United States. The original context and method which generated this number had two weaknesses, both of which we address. First, it relies on undocumented, judgment-based factors to estimate the number of end user programmers based on the total number of end users; we address this weakness by identifying specific end user sub-populations and then estimating their sizes. Second, Boehm's estimate relies on additional undocumented, judgment-based factors to adjust for rising computer usage rates; we address this weakness by integrating fresh Bureau of Labor Statistics (BLS) data and projections as well as a richer estimation method. With these improvements to Boehm's method, we estimate that in 2012 there will be 90 million end users in American workplaces. Of these, we anticipate that over 55 million will use spreadsheets or databases (and therefore may potentially program), while over 13 million will describe themselves as programmers, compared to BLS projections of fewer than 3 million professional programmers. We have validated our improved method by generating estimates for 2001 and 2003, then verifying that our estimates are consistent with existing estimates from other sources.},
	booktitle = {2005 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}},
	author = {Scaffidi, C. and Shaw, M. and Myers, B.},
	month = sep,
	year = {2005},
	keywords = {Bureau of Labor Statistics, Computer industry, Computer science, Costs, Databases, Employment, Prediction methods, Programming environments, Programming profession, Software performance, Statistics, United States, end user programming, judgment-based factors, software engineering, spreadsheets, user centred design},
	pages = {207--214}
}

@inproceedings{costagliola_visual_2009,
	title = {A visual system for analyzing user behaviour in web tasks},
	doi = {10.1109/VLHCC.2009.5295291},
	abstract = {In this paper we present a visual system for the analysis of user behaviour during the execution of Web tasks based on visual data mining techniques. In particular, our system presents a suite of charts providing views of user behaviour starting from the well known clickstream visualization down to single user page interaction visualizations. The navigation through the views is enabled through ad-hoc defined zoom and filter operations. We give an overview of the architecture of the prototypical system and, in order to demonstrate the effectiveness of the approach and to give the reader an insight of the possible analysis types, we present a comparative analysis of an usability test performed on the two popular Web sites for booking flights.},
	booktitle = {{IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}, 2009. {VL}/{HCC} 2009},
	author = {Costagliola, G. and Fuccella, V.},
	month = sep,
	year = {2009},
	keywords = {Filters, Human factors, Navigation, Performance analysis, Prototypes, Service oriented architecture, System testing, Usability, Web sites, Web tasks, behavioural sciences computing, clickstream visualization, data mining, data visualisation, data visualization, filter operations, flight booking Web sites, prototypical system, usability test, user behaviour, visual data mining techniques, visual system, zoom operations},
	pages = {101--104}
}

@inproceedings{myers_how_2008,
	title = {How designers design and program interactive behaviors},
	doi = {10.1109/VLHCC.2008.4639081},
	abstract = {Designers are skilled at sketching and prototyping the look of interfaces, but to explore various behaviors (what the interface does in response to input) typically requires programming using Javascript, ActionScript for Flash, or other languages. In our survey of 259 designers, 86\% reported that the behavior is more difficult to prototype than the appearance. Often (78\% of the time), designing the behavior requires collaborating with developers, but 76\% of designers reported that communicatin1g the behavior to developers was more difficult than the appearance. Other results include that annotations such as arrows and paragraphs of text are used on top of sketches and storyboards to explain behaviors, and designers want to explore multiple versions of behaviors, but todaypsilas tools make this difficult. The results provide new ideas for future tools.},
	booktitle = {{IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}, 2008. {VL}/{HCC} 2008},
	author = {Myers, Brad A. and Park, Sunyoung and Nakano, Yoko and Mueller, Greg and Ko, Amy J.},
	month = sep,
	year = {2008},
	keywords = {Computer interfaces, Java, Motion pictures, Programming profession, Prototypes, Sun, User interfaces, Web pages, collaboration, human computer interaction, interactive behavior, user interface},
	pages = {177--184}
}

@inproceedings{chi_model-driven_2010,
	title = {Model-{Driven} {Research} in {Human}-{Centric} {Computing}},
	doi = {10.1109/VLHCC.2010.9},
	abstract = {How can we build systems that enable users to mix and match tools together? How will we know whether we have done a good job in creating usable visual interactive systems that help users accomplish a wide variety of goals? How can people share the results of their explorations with each other, and for innovative tools to be remixed? Widely-used tools such as Web Browsers, Wikis, spreadsheets, and analytics environments like R all contain models of how people mix and combine operators and functionalities. In my own research, system developments are very much informed by models such as information scent, sense making, information theory, probabilistic models, and more recently, evolutionary dynamic models. These models have been used to understand a wide-variety of user behaviors in human-centric computing, from individuals interacting with a search system like MrTaggy.com to groups of people working on articles in Wikipedia. These models range in complexity from a simple set of assumptions to complex equations describing human and group behavior. In this talk, I will attempt to illustrate how a model-driven approach to answering the above questions should help to illuminate the path forward for Human-Centric Computing.},
	booktitle = {2010 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Chi, E. H.},
	month = sep,
	year = {2010},
	keywords = {Biological system modeling, Cognition, Computational modeling, HCI, Humans, Interactive systems, Mathematical model, MrTaggy.com, Psychology, Web browsers, Web sites, Wikipedia, analytics environments, component, evolutionary dynamic model, human computer interaction, human-centric computing, human-computer interaction, information scent, information theory, innovative tool, model-driven research, probabilistic model, probability, query processing, search engines, search system, sense making, spreadsheets, system development, usable visual interactive system},
	pages = {3--3}
}

@inproceedings{brand_lowering_2007,
	title = {Lowering {Barriers} to {Interaction}: {Programming} without {Code}},
	shorttitle = {Lowering {Barriers} to {Interaction}},
	doi = {10.1109/VLHCC.2007.46},
	abstract = {We developed a method of annotating pre-existing software so that an end-user can change the underlying program via an interface created from the annotations and generate new executable code.},
	booktitle = {{IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}, 2007. {VL}/{HCC} 2007},
	author = {Brand, C.},
	month = sep,
	year = {2007},
	keywords = {Aging, Automatic programming, Computer interfaces, Ecosystems, Filling, Information resources, Job design, Natural languages, Programming, Programming profession, Software design, User interfaces, executable code, interface, program},
	pages = {250--251}
}

@inproceedings{oney_democratizing_2010,
	title = {Democratizing {Computational} {Tools} for {Interaction} {Designers}},
	doi = {10.1109/VLHCC.2010.43},
	abstract = {I am creating a new programming language and editor that is aimed towards authoring interactive behaviors. This language is intended to allow more interaction designers to write their own interactive applications. This paper discusses the motivation, method, and design ideas for such a language.},
	booktitle = {2010 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Oney, S.},
	month = sep,
	year = {2010},
	keywords = {Computer languages, Fires, Materials, Programming, Prototypes, Reflection, authoring systems, computational tools, interaction designers, interactive behavior authoring, programming editor, programming language, programming languages, visualization},
	pages = {249--250}
}

@inproceedings{hoggan_crossmodal_2006,
	title = {Crossmodal {Interaction} with {Mobile} {Devices}},
	doi = {10.1109/VLHCC.2006.18},
	abstract = {This paper describes an alternative form of interaction for mobile devices using crossmodal output. These crossmodal displays allow alternative senses such as hearing and touch to be used to perceive information normally presented to the visual modality. Initial experiments show that roughness and spatial location can be perceived as equivalent in both the auditory and tactile domain. This paper discusses how crossmodal displays can be constructed using the results from these experiments and the benefits they bring to mobile human computer interfaces},
	booktitle = {{IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing}, 2006. {VL}/{HCC} 2006},
	author = {Hoggan, E. E. and Brewster, S. A.},
	month = sep,
	year = {2006},
	keywords = {Auditory system, Computer displays, Computer interfaces, Humans, Interactive systems, Personal digital assistants, User interfaces, auditory display, auditory displays, crossmodal displays, crossmodal interaction, haptic interfaces, human computer interaction, mobile computing, mobile devices, mobile handsets, mobile human computer interfaces, tactile display, visual modality},
	pages = {234--235}
}

@inproceedings{deshayes_domain-specific_2013,
	title = {A domain-specific modeling approach for gestural interaction},
	doi = {10.1109/VLHCC.2013.6645275},
	abstract = {Natural interaction is gaining widespread use, but more tools and techniques are required to fully support the takeup of gestural interaction. This research focus on providing an expressive an extensible framework and an executable domain-specific modeling language for specifying gestural interaction with real or virtual objects. The main targeted domains are virtual reality for gaming applications and home automation.},
	booktitle = {2013 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Deshayes, R.},
	month = sep,
	year = {2013},
	keywords = {Adaptation models, Computational modeling, Computers, Solid modeling, Three-dimensional displays, computer games, context, executable domain-specific modeling language, gaming applications, gestural interaction, gesture recognition, home automation, natural interaction, specification languages, virtual reality, visualization},
	pages = {181--182}
}

@inproceedings{bottoni_towards_2010,
	title = {Towards a {Formal} {Notion} of {Interaction} {Pattern}},
	doi = {10.1109/VLHCC.2010.40},
	abstract = {While interaction patterns are becoming widespread in the field of interface design, their definitions do not enjoy a common standard yet, as is for software patterns. Moreover, patterns are developed for diverse design aspects, reflecting the complexity of the field. As a consequence, research on formalization of interaction patterns is not developed, and few attempts have been made to extend techniques developed for design pattern formalization. We show here how an extension to our recent approach to pattern formalization can be usefully employed to formalize some classes of interaction patterns, to express relations among them, and to detect conflicts.},
	booktitle = {2010 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Bottoni, P. and Guerra, E. and Lara, J. d},
	month = sep,
	year = {2010},
	keywords = {Equations, HCI patterns, Mathematical model, Usability, Vocabulary, design pattern formalization, diverse design aspects, formal notion, human computer interaction, interaction patterns formalization, interface design, object-oriented methods, object-oriented programming, pattern formalisation, pattern subtyping, software patterns, triple graphs},
	pages = {235--239}
}

@inproceedings{diprose_tools_2014,
	title = {Tools for programming human robot interaction},
	doi = {10.1109/VLHCC.2014.6883046},
	abstract = {Whilst robots are increasingly being used in scenarios that involve human-robot interaction, it is still difficult to program them to interact with humans. This is because current programming tools either require programmers to work at low abstraction levels or they lack features needed to implement particular aspects of human-robot interaction. Our goal is to create an API that is both capable of programming a wide range of human-robot interaction scenarios and is easy to use by the various users of human-robot interaction programming tools. We have taken a first step toward this API by developing an exemplar, high level API for programming social interaction and evaluating it with the Cognitive Dimensions framework. We plan to explore other aspects of human-robot interaction, including navigation and manipulation and exploring how they should be integrated with our existing primitives for programming social interaction.},
	booktitle = {2014 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Diprose, J. P.},
	month = jul,
	year = {2014},
	keywords = {Navigation, Programming, Robots, Speech, Usability, api, application program interfaces, application programming interfaces, cognitive dimensions, cognitive dimensions framework, design, high level API, human robot interaction, human robot interaction programming, human-robot interaction, humanoid robot, manipulation, robot programming, social interaction programming, social robot interaction, visualization},
	pages = {183--184}
}

@inproceedings{weintrop_blocks_2015,
	title = {Blocks, text, and the space between: {The} role of representations in novice programming environments},
	shorttitle = {Blocks, text, and the space between},
	doi = {10.1109/VLHCC.2015.7357237},
	abstract = {The pilot study gave us the opportunity to test out a number of components of the study design, including our attitudinal and content assessments and our curricular materials, interview protocols, and data collection strategies. While the pilot study yielded numerous useful insights, the choice of environment (Snap!) and the lack of a full text-based condition limited our ability to answer our stated research questions. In the next iteration of the study we will be using a customized version of Pencil Code (Fig. 1), which will give us isomorphic blocks, text, and hybrid interfaces. Our expectation is that the second iteration of the study will provide that data necessary to answer the questions at the heart of this dissertation; namely the relationship between programming modality and understanding in introductory high school programing classrooms, and insight into the design of introductory programming tools that can provide guidance on the creation of the next generation of computer science learning environments. In doing so, we hope to contribute to the development of tools and curricula that will prepare today's students for the computational futures that await them.},
	booktitle = {2015 {IEEE} {Symposium} on {Visual} {Languages} and {Human}-{Centric} {Computing} ({VL}/{HCC})},
	author = {Weintrop, D.},
	month = oct,
	year = {2015},
	keywords = {Programming, User interfaces, computer aided instruction, computer science education, computer science learning environments, curricular materials, data acquisition, data collection strategy, educational institutions, high school programming classroom, hybrid interface, interview protocol, introductory programming tool, isomorphic block, novice programming environment, pencil code, programming modality},
	pages = {301--302}
}

@inproceedings{bunt_supporting_2007,
	address = {New York, NY, USA},
	series = {{IUI} '07},
	title = {Supporting {Interface} {Customization} {Using} a {Mixed}-initiative {Approach}},
	isbn = {1-59593-481-2},
	url = {http://doi.acm.org/10.1145/1216295.1216317},
	doi = {10.1145/1216295.1216317},
	abstract = {We describe a mixed-initiative framework designed to support the customization of complex graphical user interfaces. The framework uses an innovative form of online GOMS analysis to provide the user with tailored customization suggestions aimed at maximizing the user's performance with the interface. The suggestions are presented non-intrusively, minimizing disruption and allowing the user to maintain full control. The framework has been applied to a general user-productivity application. A formal user evaluation of the system provides encouraging evidence that this mixed-initiative approach is preferred to a purely adaptable alternative and that the system's suggestions help improve task performance.},
	urldate = {2016-02-26TZ},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Bunt, Andrea and Conati, Cristina and McGrenere, Joanna},
	year = {2007},
	keywords = {GOMS analysis, adaptable, adaptive, mixed-initiative},
	pages = {92--101}
}

@inproceedings{gajos_exploring_2006,
	address = {New York, NY, USA},
	series = {{AVI} '06},
	title = {Exploring the {Design} {Space} for {Adaptive} {Graphical} {User} {Interfaces}},
	isbn = {1-59593-353-0},
	url = {http://doi.acm.org/10.1145/1133265.1133306},
	doi = {10.1145/1133265.1133306},
	abstract = {For decades, researchers have presented different adaptive user interfaces and discussed the pros and cons of adaptation on task performance and satisfaction. Little research, however, has been directed at isolating and understanding those aspects of adaptive interfaces which make some of them successful and others not. We have designed and implemented three adaptive graphical interfaces and evaluated them in two experiments along with a non-adaptive baseline. In this paper we synthesize our results with previous work and discuss how different design choices and interactions affect the success of adaptive graphical user interfaces.},
	urldate = {2016-02-26TZ},
	booktitle = {Proceedings of the {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {ACM},
	author = {Gajos, Krzysztof Z. and Czerwinski, Mary and Tan, Desney S. and Weld, Daniel S.},
	year = {2006},
	keywords = {adaptive interfaces, user study},
	pages = {201--208}
}

@article{debevc_design_1996,
	title = {Design and evaluation of an adaptive icon toolbar},
	volume = {6},
	issn = {0924-1868, 1573-1391},
	url = {http://link.springer.com/article/10.1007/BF00126652},
	doi = {10.1007/BF00126652},
	abstract = {As information systems become increasingly important in many different domains, the potential to adapt them to individual users and their needs also becomes more important. Adaptive user interfaces offer many possible ways to adjust displays and improve procedures for a user's individual patterns of work. This paper describes an attempt to design an adaptive user interface in a computer environment familiar to many users. According to one classification of adaptive user interfaces, the adaptive bar described in this paper would be classified as a user-controlled self-adaptation system. At the user's convenience, the adaptive bar offers suggestions for adding or removing command icons, based on the frequency and probability of specific commands. It also implements these changes once the user has agreed to them. Beyond the adaptive bar, the general behavior of the whole user interface does not change, thereby allowing the user to maintain a clear general model of the system. This paper describes the decision-making algorithm implemented in the bar. It also describes the bar's self-adaptive behavior of displaying the frequency of each icon's use through the icon's size. Finally, we present some encouraging preliminary results of evaluations by users.},
	language = {en},
	number = {1},
	urldate = {2016-02-26TZ},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Debevc, Matjaz and Meyer, Beth and Donlagic, Dali and Svecko, Rajko},
	month = mar,
	year = {1996},
	keywords = {Education (general), Management of Computing and Information Systems, Multimedia Information Systems, Psychology, general, User Interfaces and Human Computer Interaction, User interfaces, adaptive user interfaces, experimental studies of adaptive interface use, icon toolbars, software ergonomics, user modelling, user-controlled self-adaptation},
	pages = {1--21}
}

@inproceedings{bunt_supporting_2007-1,
	address = {New York, NY, USA},
	series = {{IUI} '07},
	title = {Supporting {Interface} {Customization} {Using} a {Mixed}-initiative {Approach}},
	isbn = {1-59593-481-2},
	url = {http://doi.acm.org/10.1145/1216295.1216317},
	doi = {10.1145/1216295.1216317},
	abstract = {We describe a mixed-initiative framework designed to support the customization of complex graphical user interfaces. The framework uses an innovative form of online GOMS analysis to provide the user with tailored customization suggestions aimed at maximizing the user's performance with the interface. The suggestions are presented non-intrusively, minimizing disruption and allowing the user to maintain full control. The framework has been applied to a general user-productivity application. A formal user evaluation of the system provides encouraging evidence that this mixed-initiative approach is preferred to a purely adaptable alternative and that the system's suggestions help improve task performance.},
	urldate = {2016-02-26TZ},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Bunt, Andrea and Conati, Cristina and McGrenere, Joanna},
	year = {2007},
	keywords = {GOMS analysis, adaptable, adaptive, mixed-initiative},
	pages = {92--101}
}

@inproceedings{myers_visual_1986,
	address = {New York, NY, USA},
	series = {{CHI} '86},
	title = {Visual {Programming}, {Programming} by {Example}, and {Program} {Visualization}: {A} {Taxonomy}},
	isbn = {0-89791-180-6},
	shorttitle = {Visual {Programming}, {Programming} by {Example}, and {Program} {Visualization}},
	url = {http://doi.acm.org/10.1145/22627.22349},
	doi = {10.1145/22627.22349},
	abstract = {There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms “Visual Programming” and “Program Visualization” have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called “Programming by Example.” This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Myers, Brad. A.},
	year = {1986},
	pages = {59--66}
}
@article{myers_taxonomies_1990,
	title = {Taxonomies of visual programming and program visualization},
	volume = {1},
	issn = {1045-926X},
	url = {http://www.sciencedirect.com/science/article/pii/S1045926X05800369},
	doi = {10.1016/S1045-926X(05)80036-9},
	abstract = {There has been great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer systems. The terms ‘Visual Programming’ and ‘Program Visualization’ have been applied to these systems. This paper attempts to provide more meaning to these terms by giving precise definitions, and then surveys a number of systems that can be classified as providing Visual Programming or Program Visualization. These systems are organized by classifying them into three different taxonomies.},
	number = {1},
	urldate = {2016-02-25TZ},
	journal = {Journal of Visual Languages \& Computing},
	author = {Myers, Brad A.},
	month = mar,
	year = {1990},
	pages = {97--123}
}

@inproceedings{lim_design_2011,
	address = {New York, NY, USA},
	series = {{MobileHCI} '11},
	title = {Design of an {Intelligible} {Mobile} {Context}-aware {Application}},
	isbn = {978-1-4503-0541-9},
	url = {http://doi.acm.org/10.1145/2037373.2037399},
	doi = {10.1145/2037373.2037399},
	abstract = {Context-aware applications are increasingly complex and autonomous, and research has indicated that explanations can help users better understand and ultimately trust their autonomous behavior. However, it is still unclear how to effectively present and provide these explanations. This work builds on previous work to make context-aware applications intelligible by supporting a suite of explanations using eight question types (e.g., Why, Why Not, What If). We present a formative study on design and usability issues for making an intelligible real-world, mobile context-aware application, focusing on the use of intelligibility for the mobile contexts of availability, place, motion, and sound activity. We discuss design strategies that we considered, findings of explanation use, and design recommendations to make intelligibility more usable.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K.},
	year = {2011},
	keywords = {context-awareness, explanations, intelligibility, user study},
	pages = {157--166}
}

@inproceedings{lim_improving_2010,
	address = {New York, NY, USA},
	series = {{UbiComp} '10 {Adjunct}},
	title = {Improving {Trust} in {Context}-aware {Applications} with {Intelligibility}},
	isbn = {978-1-4503-0283-8},
	url = {http://doi.acm.org/10.1145/1864431.1864491},
	doi = {10.1145/1864431.1864491},
	abstract = {Since context-aware applications use implicit sensing and increasingly complex decision making, they may make mistakes or users may misunderstand their actions. This may hinder trust and adoption of context-aware applications. We hypothesize that making these applications intelligible by explaining themselves to users would help counter this lack of trust. The proposed thesis would contribute to context-aware computing by (i) understanding the need to explain these applications to users, (ii) understanding the benefits and trade-offs of providing intelligibility, and (iii) providing toolkit support intelligibility to ultimately improve the trust, adoption of, and sustained use context-aware systems.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 12th {ACM} {International} {Conference} {Adjunct} {Papers} on {Ubiquitous} {Computing} - {Adjunct}},
	publisher = {ACM},
	author = {Lim, Brian Y.},
	year = {2010},
	keywords = {context-awareness, explanations, intelligibility, toolkits},
	pages = {477--480}
}

@inproceedings{lim_why_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Why and {Why} {Not} {Explanations} {Improve} the {Intelligibility} of {Context}-aware {Intelligent} {Systems}},
	isbn = {978-1-60558-246-7},
	url = {http://doi.acm.org/10.1145/1518701.1519023},
	doi = {10.1145/1518701.1519023},
	abstract = {Context-aware intelligent systems employ implicit inputs, and make decisions based on complex rules and machine learning models that are rarely clear to users. Such lack of system intelligibility can lead to loss of user trust, satisfaction and acceptance of these systems. However, automatically providing explanations about a system's decision process can help mitigate this problem. In this paper we present results from a controlled study with over 200 participants in which the effectiveness of different types of explanations was examined. Participants were shown examples of a system's operation along with various automatically generated explanations, and then tested on their understanding of the system. We show, for example, that explanations describing why the system behaved a certain way resulted in better understanding and stronger feelings of trust. Explanations describing why the system did not behave a certain way, resulted in lower understanding yet adequate performance. We discuss implications for the use of our findings in real-world context-aware applications.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K. and Avrahami, Daniel},
	year = {2009},
	keywords = {context-aware, explanations, intelligibility},
	pages = {2119--2128}
}

@inproceedings{desai_effects_2012,
	address = {New York, NY, USA},
	series = {{HRI} '12},
	title = {Effects of {Changing} {Reliability} on {Trust} of {Robot} {Systems}},
	isbn = {978-1-4503-1063-5},
	url = {http://doi.acm.org/10.1145/2157689.2157702},
	doi = {10.1145/2157689.2157702},
	abstract = {Prior work in human-autonomy interaction has focused on plant systems that operate in highly structured environments. In contrast, many human-robot interaction (HRI) tasks are dynamic and unstructured, occurring in the open world. It is our belief that methods developed for the measurement and modeling of trust in traditional automation need alteration in order to be useful for HRI. Therefore, it is important to characterize the factors in HRI that influence trust. This study focused on the influence of changing autonomy reliability. Participants experienced a set of challenging robot handling scenarios that forced autonomy use and kept them focused on autonomy performance. The counterbalanced experiment included scenarios with different low reliability windows so that we could examine how drops in reliability altered trust and use of autonomy. Drops in reliability were shown to affect trust, the frequency and timing of autonomy mode switching, as well as participants' self-assessments of performance. A regression analysis on a number of robot, personal, and scenario factors revealed that participants tie trust more strongly to their own actions rather than robot performance.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the {Seventh} {Annual} {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Desai, Munjal and Medvedev, Mikhail and Vázquez, Marynel and McSheehy, Sean and Gadea-Omelchenko, Sofia and Bruggeman, Christian and Steinfeld, Aaron and Yanco, Holly},
	year = {2012},
	keywords = {TRUST, automation, experiments},
	pages = {73--80}
}

@inproceedings{kaniarasu_potential_2012,
	address = {New York, NY, USA},
	series = {{HRI} '12},
	title = {Potential {Measures} for {Detecting} {Trust} {Changes}},
	isbn = {978-1-4503-1063-5},
	url = {http://doi.acm.org/10.1145/2157689.2157775},
	doi = {10.1145/2157689.2157775},
	abstract = {It is challenging to quantitatively measure a user's trust in a robot system using traditional survey methods due to their invasiveness and tendency to disrupt the flow of operation. Therefore, we analyzed data from an existing experiment to identify measures which (1) have face validity for measuring trust and (2) align with the collected post-run trust measures. Two measures are promising as real-time indications of a drop in trust. The first is the time between the most recent warning and when the participant reduces the robot's autonomy level. The second is the number of warnings prior to the reduction of the autonomy level.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the {Seventh} {Annual} {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Kaniarasu, Poornima and Steinfeld, Aaron and Desai, Munjal and Yanco, Holly},
	year = {2012},
	keywords = {TRUST, automation, experiments},
	pages = {241--242}
}

@inproceedings{herlocker_explaining_2000,
	address = {New York, NY, USA},
	series = {{CSCW} '00},
	title = {Explaining {Collaborative} {Filtering} {Recommendations}},
	isbn = {1-58113-222-0},
	url = {http://doi.acm.org/10.1145/358916.358995},
	doi = {10.1145/358916.358995},
	abstract = {Automated collaborative filtering (ACF) systems predict a person's affinity for items or information by connecting that person's recorded interests with the recorded interests of a community of people and sharing ratings between like-minded persons. However, current recommender systems are black boxes, providing no transparency into the working of the recommendation. Explanations provide that transparency, exposing the reasoning and data behind a recommendation. In this paper, we address explanation interfaces for ACF systems - how they should be implemented and why they should be implemented. To explore how, we present a model for explanations based on the user's conceptual model of the recommendation process. We then present experimental results demonstrating what components of an  explanation are the most compelling. To address why, we present experimental evidence that shows that providing explanations can improve the acceptance of ACF systems. We also describe some initial explorations into measuring how explanations can improve the filtering performance of users.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 2000 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	publisher = {ACM},
	author = {Herlocker, Jonathan L. and Konstan, Joseph A. and Riedl, John},
	year = {2000},
	keywords = {GroupLens, MoviesLens, collaborative filtering, explanations, recommender systems},
	pages = {241--250}
}

@inproceedings{sharma_social_2013,
	address = {New York, NY, USA},
	series = {{WWW} '13},
	title = {Do {Social} {Explanations} {Work}?: {Studying} and {Modeling} the {Effects} of {Social} {Explanations} in {Recommender} {Systems}},
	isbn = {978-1-4503-2035-1},
	shorttitle = {Do {Social} {Explanations} {Work}?},
	url = {http://doi.acm.org/10.1145/2488388.2488487},
	doi = {10.1145/2488388.2488487},
	abstract = {Recommender systems associated with social networks often use social explanations (e.g. "X, Y and 2 friends like this") to support the recommendations. We present a study of the effects of these social explanations in a music recommendation context. We start with an experiment with 237 users, in which we show explanations with varying levels of social information and analyze their effect on users' decisions. We distinguish between two key decisions: the likelihood of checking out the recommended artist, and the actual rating of the artist based on listening to several songs. We find that while the explanations do have some influence on the likelihood, there is little correlation between the likelihood and actual (listening) rating for the same artist. Based on these insights, we present a generative probabilistic model that explains the interplay between explanations and background information on music preferences, and how that leads to a final likelihood rating for an artist. Acknowledging the impact of explanations, we discuss a general recommendation framework that models external informational elements in the recommendation interface, in addition to inherent preferences of users.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Sharma, Amit and Cosley, Dan},
	year = {2013},
	keywords = {influence, recommender systems, social explanation},
	pages = {1133--1144}
}

@inproceedings{guo_simple_2012,
	address = {Berlin, Heidelberg},
	series = {{UMAP}'12},
	title = {A {Simple} but {Effective} {Method} to {Incorporate} {Trusted} {Neighbors} in {Recommender} {Systems}},
	isbn = {978-3-642-31453-7},
	url = {http://dx.doi.org/10.1007/978-3-642-31454-4_10},
	doi = {10.1007/978-3-642-31454-4_10},
	abstract = {Providing high quality recommendations is important for online systems to assist users who face a vast number of choices in making effective selection decisions. Collaborative filtering is a widely accepted technique to provide recommendations based on ratings of similar users. But it suffers from several issues like data sparsity and cold start. To address these issues, in this paper, we propose a simple but effective method, namely "Merge", to incorporate social trust information (i.e. trusted neighbors explicitly specified by users) in providing recommendations. More specifically, ratings of a user's trusted neighbors are merged to represent the preference of the user and to find similar other users for generating recommendations. Experimental results based on three real data sets demonstrate that our method is more effective than other approaches, both in accuracy and coverage of recommendations.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 20th {International} {Conference} on {User} {Modeling}, {Adaptation}, and {Personalization}},
	publisher = {Springer-Verlag},
	author = {Guo, Guibing and Zhang, Jie and Thalmann, Daniel},
	year = {2012},
	pages = {114--125}
}

@inproceedings{glass_toward_2008,
	address = {New York, NY, USA},
	series = {{IUI} '08},
	title = {Toward {Establishing} {Trust} in {Adaptive} {Agents}},
	isbn = {978-1-59593-987-6},
	url = {http://doi.acm.org/10.1145/1378773.1378804},
	doi = {10.1145/1378773.1378804},
	abstract = {As adaptive agents become more complex and take increasing autonomy in their user's lives, it becomes more important for users to trust and understand these agents. Little work has been done, however, to study what factors influence the level of trust users are willing to place in these agents. Without trust in the actions and results produced by these agents, their use and adoption as trusted assistants and partners will be severely limited. We present the results of a study among test users of CALO, one such complex adaptive agent system, to investigate themes surrounding trust and understandability. We identify and discuss eight major themes that significantly impact user trust in complex systems. We further provide guidelines for the design of trustable adaptive agents. Based on our analysis of these results, we conclude that the availability of explanation capabilities in these agents can address the majority of trust concerns identified by users.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Glass, Alyssa and McGuinness, Deborah L. and Wolverton, Michael},
	year = {2008},
	keywords = {TRUST, adaptive agents, automated assistants, complex agents, evaluation, explanation, user study},
	pages = {227--236}
}

@inproceedings{miller_does_2014,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '14},
	title = {Does {The} {First} {Officer} {Concur}? {Shared} {Control} with {Smart} {Vehicle} {Systems}},
	isbn = {978-1-4503-0725-3},
	shorttitle = {Does {The} {First} {Officer} {Concur}?},
	url = {http://doi.acm.org/10.1145/2667239.2667286},
	doi = {10.1145/2667239.2667286},
	abstract = {New computation and sensing capabilities in road vehicles present possibilities for advanced driver assistance systems that can increase safety and efficiency, if the driver will trust them appropriately and use them properly. The two-stage 'trust fall' is a way to study trust in automated systems by testing whether trust established in normal circumstances transfers to trust under extreme circumstances, which will be essential for the successful employment of new automotive systems. Understanding the mental models drivers create of advanced systems, and how they use those mental models to share control with the computer will be crucial to successful design.},
	urldate = {2016-02-25TZ},
	booktitle = {Adjunct {Proceedings} of the 6th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {ACM},
	author = {Miller, David and Ju, Wendy},
	year = {2014},
	keywords = {Mental models, TRUST, automation, shared control, situation awareness, system image},
	pages = {1--6}
}

@inproceedings{schwarz_help_2015,
	address = {New York, NY, USA},
	series = {{MUM} '15},
	title = {Help {Radar}: {Ubiquitous} {Assistance} for {Newly} {Arrived} {Immigrants}},
	isbn = {978-1-4503-3605-5},
	shorttitle = {Help {Radar}},
	url = {http://doi.acm.org/10.1145/2836041.2836059},
	doi = {10.1145/2836041.2836059},
	abstract = {Help Radar consists of a ubiquitous assistance service which enables immigrants to connect with volunteers, who in turn provide information on a variety of topics, guidance and practical assistance. The system was developed to foster the early integration of immigrants in the host country. In this paper, we present the methodological approach and results obtained from the field evaluation of Help Radar which involved Turkish immigrants in Graz, Austria, as well as immigrants from Latin-American and Arabic speaking countries in London, United Kingdom. During and after the field phase, quantitative and qualitative data were gathered to determine the usage activity, satisfaction, privacy concerns and trust towards the system. Based on results differences in usage among the involved user groups, types of assistance received and potentials of Help Radar toward immigrants' integration are discussed.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {ACM},
	author = {Schwarz, Stephanie and Salazar, Estefanía Palacio and Bobeth, Jan and Bersia, Nicoletta and Tscheligi, Manfred},
	year = {2015},
	keywords = {community building, empowerment, field study, immigrants, privacy, ubiquitous assistance, volunteers},
	pages = {183--194}
}

@inproceedings{pu_trust_2006,
	address = {New York, NY, USA},
	series = {{IUI} '06},
	title = {Trust {Building} with {Explanation} {Interfaces}},
	isbn = {1-59593-287-9},
	url = {http://doi.acm.org/10.1145/1111449.1111475},
	doi = {10.1145/1111449.1111475},
	abstract = {Based on our recent work on the development of a trust model for recommender agents and a qualitative survey, we explore the potential of building users' trust with explanation interfaces. We present the major results from the survey, which provided a roadmap identifying the most promising areas for investigating design issues for trust-inducing interfaces. We then describe a set of general principles derived from an in-depth examination of various design dimensions for constructing explanation interfaces, which most contribute to trust formation. We present results of a significant-scale user study, which indicate that the organization-based explanation is highly effective in building users' trust in the recommendation interface, with the benefit of increasing users' intention to return to the agent and save cognitive effort.},
	urldate = {2016-02-25TZ},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Pu, Pearl and Chen, Li},
	year = {2006},
	keywords = {explanation interfaces, recommender agents, tradeoff assistance, trust building},
	pages = {93--100}
}

@inproceedings{tsiourti_virtual_2014,
	address = {ICST, Brussels, Belgium, Belgium},
	series = {{PervasiveHealth} '14},
	title = {Virtual {Assistive} {Companions} for {Older} {Adults}: {Qualitative} {Field} {Study} and {Design} {Implications}},
	isbn = {978-1-63190-011-2},
	shorttitle = {Virtual {Assistive} {Companions} for {Older} {Adults}},
	url = {http://dx.doi.org/10.4108/icst.pervasivehealth.2014.254943},
	doi = {10.4108/icst.pervasivehealth.2014.254943},
	abstract = {This paper presents a qualitative study conducted to explore perceptions, attitudes and expectations for a virtual assistive companion designed to supplement human caregiving and facilitate an improved quality of life and long-term health benefits for older adults. The study was conducted adopting a human-centred approach; employing focus groups and individual interviews with older adults, professional caregivers and psychologists specialized in the aging process. Results indicated that users were in favour of a virtual companion and highlighted its potential to assist the accomplishment of daily activities and make more efficient use of human care services. Humanlike communication and behaviour were desirable whereas mixed opinions were expressed about humanlike appearance. The ramifications of the study are discussed in the form of design implications for the development of a virtual assistive companion that possesses the appropriate "social skills" to establish and maintain comfortable and acceptable long-term interaction and offers "useful" support to older adults.},
	urldate = {2016-02-24TZ},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Pervasive} {Computing} {Technologies} for {Healthcare}},
	publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
	author = {Tsiourti, Christiana and Joly, Emilie and Wings, Cindy and Moussa, Maher Ben and Wac, Katarzyna},
	year = {2014},
	keywords = {HCI, health promotion, human-centred design, older users, personalization, qualitative field study},
	pages = {57--64}
}

@inproceedings{gordon_designing_2015,
	address = {New York, NY, USA},
	series = {{IDC} '15},
	title = {Designing a {Virtual} {Assistant} for {In}-car {Child} {Entertainment}},
	isbn = {978-1-4503-3590-4},
	url = {http://doi.acm.org/10.1145/2771839.2771916},
	doi = {10.1145/2771839.2771916},
	abstract = {Driving is an attention-demanding task, especially with children in the back seat. While most recommendations prefer to reduce children's screen time in common entertainment systems, e.g. DVD players and tablets, parents often rely on these systems to entertain the children during car trips. These systems often lack key components that are important for modern parents, namely, sociability and educational content. In this contribution we introduce PANDA, a parental affective natural driving assistant. PANDA is a virtual in-car entertainment agent that can migrate around the car to interact with the parent-driver or with children in the back seat. PANDA supports the parent-driver via speech interface, helps to mediate her interaction with children in the back seat, and works to reduce distractions for the driver while also engaging, entertaining and educating children. We present the design of PANDA system and preliminary tests of the prototype system in a car setting.},
	urldate = {2016-02-24TZ},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Interaction} {Design} and {Children}},
	publisher = {ACM},
	author = {Gordon, Michal and Breazeal, Cynthia},
	year = {2015},
	keywords = {cars and robots, children and robots, driving assistant, intelligent agents},
	pages = {359--362}
}

@inproceedings{ahamed_wellness_2007,
	address = {New York, NY, USA},
	series = {{SAC} '07},
	title = {Wellness {Assistant}: {A} {Virtual} {Wellness} {Assistant} {Using} {Pervasive} {Computing}},
	isbn = {1-59593-480-4},
	shorttitle = {Wellness {Assistant}},
	url = {http://doi.acm.org/10.1145/1244002.1244177},
	doi = {10.1145/1244002.1244177},
	abstract = {The number of people over age 65 will almost double by 2030 and as they age, they generally prefer to remain in their home or go to a nursing home. There are a variety of reasons for their decision, such as convenience or a need for security or privacy. So, it is time to break through the physical boundaries of hospitals, and bring the hospital information to the homes of the elderly rather than bringing elderly folks to the hospital. Despite growing requests by people to be able to take a more active part in managing their own health, wireless or internet-based healthcare devices have not been accepted for use in this area. This is probably due to the reluctance of this age group to make use of new technology, as well as the lack of reliable, individualized, or user friendly interfaces. In this paper, we discuss the challenges of developing Wellness Assistant (WA), software which is looking to solve some of these problems. The Assistant will use pervasive computing technologies because of the availability of inexpensive handheld devices such as PDAs, cell phones, and wrist watches with short range wireless capabilities. The WA can also be used by people with obesity, diabetes, or high blood pressure, conditions which need constant monitoring.},
	urldate = {2016-02-24TZ},
	booktitle = {Proceedings of the 2007 {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Ahamed, Sheikh I. and Haque, Munirul M. and Stamm, Karl and Khan, Ahmed J},
	year = {2007},
	keywords = {TinyOS, marks, mote, pervasive health care, wellness assistant},
	pages = {782--787}
}

@article{myers_intelligent_2007,
	title = {An intelligent personal assistant for task and time management},
	volume = {28},
	url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/2039},
	number = {2},
	urldate = {2016-02-24TZ},
	journal = {AI Magazine},
	author = {Myers, Karen and Berry, Pauline and Blythe, Jim and Conley, Ken and Gervasio, Melinda and McGuinness, Deborah L. and Morley, David and Pfeffer, Avi and Pollack, Martha and Tambe, Milind},
	year = {2007},
	pages = {47}
}

@inproceedings{segal_mailcat:_1999,
	title = {{MailCat}: an intelligent assistant for organizing e-mail},
	shorttitle = {{MailCat}},
	url = {http://dl.acm.org/citation.cfm?id=301209},
	urldate = {2016-02-24TZ},
	booktitle = {Proceedings of the third annual conference on {Autonomous} {Agents}},
	publisher = {ACM},
	author = {Segal, Richard B. and Kephart, Jeffrey O.},
	year = {1999},
	pages = {276--282}
}

@article{moran_notes_1950,
	title = {Notes on {Continuous} {Stochastic} {Phenomena}},
	volume = {37},
	issn = {0006-3444},
	url = {http://www.jstor.org/stable/2332142},
	doi = {10.2307/2332142},
	number = {1/2},
	urldate = {2016-02-19TZ},
	journal = {Biometrika},
	author = {Moran, P. A. P.},
	year = {1950},
	pages = {17--23}
}

@article{moran_notes_1950-1,
	title = {Notes on {Continuous} {Stochastic} {Phenomena}},
	volume = {37},
	issn = {0006-3444},
	url = {http://www.jstor.org/stable/2332142},
	doi = {10.2307/2332142},
	number = {1/2},
	urldate = {2016-02-19TZ},
	journal = {Biometrika},
	author = {Moran, P. A. P.},
	year = {1950},
	pages = {17--23}
}

@inproceedings{karlson_fathumb:_2006,
	address = {New York, NY, USA},
	series = {{CHI} '06},
	title = {{FaThumb}: {A} {Facet}-based {Interface} for {Mobile} {Search}},
	isbn = {1-59593-372-7},
	shorttitle = {{FaThumb}},
	url = {http://doi.acm.org/10.1145/1124772.1124878},
	doi = {10.1145/1124772.1124878},
	abstract = {In this paper we describe a novel approach for searching large data sets from a mobile phone. Existing interfaces for mobile search require keyword text entry and are not suited for browsing. Our alternative uses a hybrid model to de-emphasize tedious keyword entry in favor of iterative data filtering. We propose navigation and selection of hierarchical metadata (facet navigation), with incremental text entry to further narrow the results. We conducted a formative evaluation to understand the relative advantages of keyword entry versus facet navigation for both browse and search tasks on the phone. We found keyword entry to be more powerful when the name of the search target is known, while facet navigation is otherwise more effective and strongly preferred.},
	urldate = {2016-02-18TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Karlson, Amy K. and Robertson, George G. and Robbins, Daniel C. and Czerwinski, Mary P. and Smith, Greg R.},
	year = {2006},
	keywords = {Piccolo.NET, faceted metadata, mobile devices, search interfaces, visual interaction, zoomable user interfaces},
	pages = {711--720}
}

@inproceedings{wang_igroup:_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {{IGroup}: {Presenting} {Web} {Image} {Search} {Results} in {Semantic} {Clusters}},
	isbn = {978-1-59593-593-9},
	shorttitle = {{IGroup}},
	url = {http://doi.acm.org/10.1145/1240624.1240718},
	doi = {10.1145/1240624.1240718},
	abstract = {Current web image search engines still rely on user typing textual description: query word(s) for visual targets. As the queries are often short, general or even ambiguous, the images in resulting pages vary in content and style. Thus, browsing with these results is likely to be tedious, frustrating and unpredictable. IGroup, a proposed image search engine addresses these problems by presenting the result in semantic clusters. The original result set was clustered in semantic groups with a cluster name relevant to user typed queries. Instead of looking through the result pages or modifying queries, IGroup users can refine findings to the interested sub-result sets with a navigational panel, where each cluster (sub-result set) was listed with a cluster name and representative thumbnails of the cluster. We compared IGroup with a general web image search engine: MSN, in term of efficiency, coverage, and satisfaction with a substantial user study. Our tool shows significant improvement in such criteria.},
	urldate = {2016-02-18TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wang, Shuo and Jing, Feng and He, Jibo and Du, Qixing and Zhang, Lei},
	year = {2007},
	keywords = {image search interface, image search result clustering (ISRC), search result clustering (SRC), user test},
	pages = {587--596}
}

@inproceedings{moraveji_measuring_2011,
	address = {New York, NY, USA},
	series = {{SIGIR} '11},
	title = {Measuring {Improvement} in {User} {Search} {Performance} {Resulting} from {Optimal} {Search} {Tips}},
	isbn = {978-1-4503-0757-4},
	url = {http://doi.acm.org/10.1145/2009916.2009966},
	doi = {10.1145/2009916.2009966},
	abstract = {Web search performance can be improved by either improving the search engine itself or by educating the user to search more efficiently. There is a large amount of literature describing techniques for measuring the former; whereas, improvements resulting from the latter are more difficult to quantify. In this paper we demonstrate an experimental methodology that proves to successfully quantify improvements from user education. The user education in our study is realized in the form of tactical search feature tips that expand user awareness of task-relevant tools and features of the search application. Initially, these tips are presented in an idealized situation: each tip is shown at the same time as the study participants are given a task that is constructed to benefit from the specific tip. However, we also present a follow-up study roughly one week later in which the search tips are no longer presented but the study participants who previously were shown search tips still demonstrate improved search efficiency compared to the control group. This research has implications for search user interface designers and the study of information retrieval systems.},
	urldate = {2016-02-18TZ},
	booktitle = {Proceedings of the 34th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Moraveji, Neema and Russell, Daniel and Bien, Jacob and Mease, David},
	year = {2011},
	keywords = {assistance, effectiveness measures, efficiency, experimental design, expertise, query reformulation, search interface, suggestions, tactics, tips, user studies},
	pages = {355--364}
}

@inproceedings{moraveji_measuring_2011-1,
	address = {New York, NY, USA},
	series = {{SIGIR} '11},
	title = {Measuring {Improvement} in {User} {Search} {Performance} {Resulting} from {Optimal} {Search} {Tips}},
	isbn = {978-1-4503-0757-4},
	url = {http://doi.acm.org/10.1145/2009916.2009966},
	doi = {10.1145/2009916.2009966},
	abstract = {Web search performance can be improved by either improving the search engine itself or by educating the user to search more efficiently. There is a large amount of literature describing techniques for measuring the former; whereas, improvements resulting from the latter are more difficult to quantify. In this paper we demonstrate an experimental methodology that proves to successfully quantify improvements from user education. The user education in our study is realized in the form of tactical search feature tips that expand user awareness of task-relevant tools and features of the search application. Initially, these tips are presented in an idealized situation: each tip is shown at the same time as the study participants are given a task that is constructed to benefit from the specific tip. However, we also present a follow-up study roughly one week later in which the search tips are no longer presented but the study participants who previously were shown search tips still demonstrate improved search efficiency compared to the control group. This research has implications for search user interface designers and the study of information retrieval systems.},
	urldate = {2016-02-18TZ},
	booktitle = {Proceedings of the 34th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Moraveji, Neema and Russell, Daniel and Bien, Jacob and Mease, David},
	year = {2011},
	keywords = {assistance, effectiveness measures, efficiency, experimental design, expertise, query reformulation, search interface, suggestions, tactics, tips, user studies},
	pages = {355--364}
}

@article{spink_user-centered_2002,
	title = {A user-centered approach to evaluating human interaction with {Web} search engines: an exploratory study},
	volume = {38},
	issn = {0306-4573},
	shorttitle = {A user-centered approach to evaluating human interaction with {Web} search engines},
	url = {http://www.sciencedirect.com/science/article/pii/S030645730100036X},
	doi = {10.1016/S0306-4573(01)00036-X},
	abstract = {A growing body of studies is developing approaches to evaluating human interaction with Web search engines, including the usability and effectiveness of Web search tools. This study explores a user-centered approach to the evaluation of the Web search engine Inquirus – a Web meta-search tool developed by researchers from the NEC Research Institute. The goal of the study reported in this paper was to develop a user-centered approach to the evaluation including: (1) effectiveness: based on the impact of users' interactions on their information problem and information seeking stage, and (2) usability: including screen layout and system capabilities for users. Twenty-two volunteers searched Inquirus on their own personal information topics. Data analyzed included: (1) user pre- and post-search questionnaires and (2) Inquirus search transaction logs. Key findings include: (1) Inquirus was rated highly by users on various usability measures, (2) all users experienced some level of shift/change in their information problem, information seeking, and personal knowledge due to their Inquirus interaction, (3) different users experienced different levels of change/shift, and (4) the search measure precision did not correlate with other user-based measures. Some users experienced major changes/shifts in various user-based variables, such as information problem or information seeking stage with a search of low precision and vice versa. Implications for the development of user-centered approaches to the evaluation of Web and information retrieval (IR) systems and further research are discussed.},
	number = {3},
	urldate = {2016-02-18TZ},
	journal = {Information Processing \& Management},
	author = {Spink, Amanda},
	month = may,
	year = {2002},
	pages = {401--426}
}

@inproceedings{rose_understanding_2004,
	address = {New York, NY, USA},
	series = {{WWW} '04},
	title = {Understanding {User} {Goals} in {Web} {Search}},
	isbn = {1-58113-844-X},
	url = {http://doi.acm.org/10.1145/988672.988675},
	doi = {10.1145/988672.988675},
	abstract = {Previous work on understanding user web search behavior has focused on how people search and what they are searching for, but not why they are searching. In this paper, we describe a framework for understanding the underlying goals of user searches, and our experience in using the framework to manually classify queries from a web search engine. Our analysis suggests that so-called navigational" searches are less prevalent than generally believed while a previously unexplored "resource-seeking" goal may account for a large fraction of web searches. We also illustrate how this knowledge of user search goals might be used to improve future web search engines.},
	urldate = {2016-02-18TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Rose, Daniel E. and Levinson, Danny},
	year = {2004},
	keywords = {information retrieval, query classification, user behavior, user goals, web search},
	pages = {13--19}
}

@article{jansen_real_2000,
	title = {Real life, real users, and real needs: a study and analysis of user queries on the web},
	volume = {36},
	issn = {0306-4573},
	shorttitle = {Real life, real users, and real needs},
	url = {http://www.sciencedirect.com/science/article/pii/S0306457399000564},
	doi = {10.1016/S0306-4573(99)00056-4},
	abstract = {We analyzed transaction logs containing 51,473 queries posed by 18,113 users of Excite, a major Internet search service. We provide data on: (i) sessions — changes in queries during a session, number of pages viewed, and use of relevance feedback; (ii) queries — the number of search terms, and the use of logic and modifiers; and (iii) terms — their rank/frequency distribution and the most highly used search terms. We then shift the focus of analysis from the query to the user to gain insight to the characteristics of the Web user. With these characteristics as a basis, we then conducted a failure analysis, identifying trends among user mistakes. We conclude with a summary of findings and a discussion of the implications of these findings.},
	number = {2},
	urldate = {2016-02-18TZ},
	journal = {Information Processing \& Management},
	author = {Jansen, Bernard J. and Spink, Amanda and Saracevic, Tefko},
	month = mar,
	year = {2000},
	pages = {207--227}
}

@book{kowalski_information_2010,
	title = {Information {Retrieval} {Architecture} and {Algorithms}},
	isbn = {9781441977168},
	abstract = {This text presents a theoretical and practical examination of the latest developments in Information Retrieval and their application to existing systems. By starting with a functional discussion of what is needed for an information system, the reader can grasp the scope of information retrieval problems and discover the tools to resolve them. The book takes a system approach to explore every functional processing step in a system from ingest of an item to be indexed to displaying results, showing how implementation decisions add to the information retrieval goal, and thus providing the user with the needed outcome, while minimizing their resources to obtain those results.The text stresses the current migration of information retrieval from just textual to multimedia, expounding upon multimedia search, retrieval and display, as well as classic and new textual techniques. It also introduces developments in hardware, and more importantly, search architectures, such as those introduced by Google, in order to approach scalability issues.About this textbook:A first course text for advanced level courses, providing a survey of information retrieval system theory and architecture, complete with challenging exercisesApproaches information retrieval from a practical systems view in order for the reader to grasp both scope and solutionsFeatures what is achievable using existing technologies and investigates what deficiencies warrant additional exploration},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Kowalski, Gerald},
	month = dec,
	year = {2010},
	keywords = {Computers / Databases / Data Mining, Computers / Information Technology, Computers / System Administration / Storage \& Retrieval}
}

@article{white_exploratory_2009,
	title = {Exploratory {Search}: {Beyond} the {Query}-{Response} {Paradigm}},
	volume = {1},
	issn = {1947-945X},
	shorttitle = {Exploratory {Search}},
	url = {http://www.morganclaypool.com/doi/abs/10.2200/S00174ED1V01Y200901ICR003},
	doi = {10.2200/S00174ED1V01Y200901ICR003},
	number = {1},
	urldate = {2016-02-15TZ},
	journal = {Synthesis Lectures on Information Concepts, Retrieval, and Services},
	author = {White, Ryen W. and Roth, Resa A.},
	month = jan,
	year = {2009},
	pages = {1--98}
}

@article{marchionini_exploratory_2006,
	title = {Exploratory {Search}: {From} {Finding} to {Understanding}},
	volume = {49},
	issn = {0001-0782},
	shorttitle = {Exploratory {Search}},
	url = {http://doi.acm.org/10.1145/1121949.1121979},
	doi = {10.1145/1121949.1121979},
	abstract = {Research tools critical for exploratory search success involve the creation of new interfaces that move the process beyond predictable fact retrieval.},
	number = {4},
	urldate = {2016-02-15TZ},
	journal = {Commun. ACM},
	author = {Marchionini, Gary},
	month = apr,
	year = {2006},
	pages = {41--46}
}

@inproceedings{buyukkokten_exploiting_1999,
	title = {Exploiting {Geographical} {Location} {Information} of {Web} {Pages}},
	abstract = {Many information sources on the web are relevant primarily to specific geographical communities.  For instance, web sites containing information on restaurants, theatres and apartment  rentals are relevant primarily to web users in geographical proximity to these locations. We  make the case for identifying and exploiting the geographical location information of web sites  so that web applications can rank information in a geographically sensitive fashion. For instance,  when a user in Palo Alto issues a query for "Italian Restaurants," a web search engine  can rank results based on how close such restaurants are to the user's physical location rather  than based on traditional IR measures. In this paper, we first consider how to compute the  geographical location of web pages. Subsequently,we consider how to exploit such information  in one specific "proof-of-concept" application we implemented in JAVA.  1 Introduction  The world wide web (WWW) provides uniform access to information a...},
	booktitle = {In {Proceedings} of the {ACM} {SIGMOD} {Workshop} on the {Web} and {Databases} ({WebDB}’99},
	author = {Buyukkokten, Orkut and Cho, Junghoo and Garcia-molina, Hector and Gravano, Luis and Shivakumar, Narayanan},
	year = {1999},
	pages = {91--96}
}

@inproceedings{ding_computing_2000,
	address = {San Francisco, CA, USA},
	series = {{VLDB} '00},
	title = {Computing {Geographical} {Scopes} of {Web} {Resources}},
	isbn = {1-55860-715-3},
	url = {http://dl.acm.org/citation.cfm?id=645926.672013},
	urldate = {2016-02-15TZ},
	booktitle = {Proceedings of the 26th {International} {Conference} on {Very} {Large} {Data} {Bases}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Ding, Junyan and Gravano, Luis and Shivakumar, Narayanan},
	year = {2000},
	pages = {545--556}
}

@inproceedings{hecht_localness_2010,
	address = {New York, NY, USA},
	series = {{CSCW} '10},
	title = {On the "{Localness}" of {User}-generated {Content}},
	isbn = {978-1-60558-795-0},
	url = {http://doi.acm.org/10.1145/1718918.1718962},
	doi = {10.1145/1718918.1718962},
	abstract = {The "localness" of participation in repositories of user-generated content (UGC) with geospatial components has been cited as one of UGC's greatest benefits. However, the degree of localness in major UGC repositories such as Flickr and Wikipedia has never been examined. We show that over 50 percent of Flickr users contribute local information on average, and over 45 percent of Flickr photos are local to the photographer. Across four language editions of Wikipedia, however, we find that participation is less local. We introduce the spatial content production model (SCPM) as a possible factor in the localness of UGC, and discuss other theoretical and applied implications.},
	urldate = {2016-02-08TZ},
	booktitle = {Proceedings of the 2010 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	publisher = {ACM},
	author = {Hecht, Brent J. and Gergle, Darren},
	year = {2010},
	keywords = {Wikipedia, flickr, local, multilingual, user behavior, user-generated content, volunteered geographic information},
	pages = {229--232}
}

@article{baudisch_my_2010,
	title = {My {New} {PC} is a {Mobile} {Phone}},
	volume = {16},
	issn = {1528-4972},
	url = {http://doi.acm.org/10.1145/1764848.1764857},
	doi = {10.1145/1764848.1764857},
	abstract = {Techniques and devices are being developed to better suit what we think of as the new smallness.},
	number = {4},
	urldate = {2016-01-25TZ},
	journal = {XRDS},
	author = {Baudisch, Patrick and Holz, Christian},
	month = jun,
	year = {2010},
	pages = {36--41}
}

@article{bell_yesterdays_2007,
	title = {Yesterday’s {Tomorrows}: {Notes} on {Ubiquitous} {Computing}’s {Dominant} {Vision}},
	volume = {11},
	issn = {1617-4909},
	shorttitle = {Yesterday’s {Tomorrows}},
	url = {http://dx.doi.org/10.1007/s00779-006-0071-x},
	doi = {10.1007/s00779-006-0071-x},
	abstract = {Ubiquitous computing is unusual amongst technological research arenas. Most areas of computer science research, such as programming language implementation, distributed operating system design, or denotational semantics, are defined largely by technical problems, and driven by building upon and elaborating a body of past results. Ubiquitous computing, by contrast, encompasses a wide range of disparate technological areas brought together by a focus upon a common vision. It is driven, then, not so much by the problems of the past but by the possibilities of the future. Ubiquitous computing’s vision, however, is over a decade old at this point, and we now inhabit the future imagined by its pioneers. The future, though, may not have worked out as the field collectively imagined. In this article, we explore the vision that has driven the ubiquitous computing research agenda and the contemporary practice that has emerged. Drawing on cross-cultural investigations of technology adoption, we argue for developing a “ubicomp of the present” which takes the messiness of everyday life as a central theme.},
	number = {2},
	urldate = {2016-01-25TZ},
	journal = {Personal Ubiquitous Comput.},
	author = {Bell, Genevieve and Dourish, Paul},
	month = jan,
	year = {2007},
	pages = {133--143}
}

@article{burrough-boenisch_international_1999,
	title = {International {Reading} {Strategies} for {IMRD} {Articles}},
	volume = {16},
	issn = {0741-0883, 1552-8472},
	url = {http://wcx.sagepub.com/content/16/3/296},
	doi = {10.1177/0741088399016003002},
	abstract = {This article examines the strategies used to read science articles written in the IMRD (Introduction, Methods, Results, and Discussion) format. Drawing on the results of a survey conducted at an international conference of science editors, it shows how three reader roles—those of the scientist, editor, and reviewer—influence reading strategies. Overall, respondents were more likely to read in IMRD sequence as editors than as reviewers. When reading for personal gain as scientists, they read strategically, not in IMRD order. Other variables considered were the mother tongues (native English or nonnative English), ages, and scientific backgrounds of readers. Nonnative English speakers tended to focus on news-rich sections, especially when reading as scientists. No evidence was found of an effect of age, but there was some evidence of a difference between readers from the hard sciences and those from the humanities. The findings have implications for our understanding of the function and development of the research article and for teaching scientists how to write for publication.},
	language = {en},
	number = {3},
	urldate = {2015-12-14TZ},
	journal = {Written Communication},
	author = {Burrough-Boenisch, Joy},
	month = jul,
	year = {1999},
	pages = {296--316}
}

@inproceedings{salvucci_reconstruction_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {On {Reconstruction} of {Task} {Context} {After} {Interruption}},
	isbn = {978-1-60558-929-9},
	url = {http://doi.acm.org/10.1145/1753326.1753341},
	doi = {10.1145/1753326.1753341},
	abstract = {Theoretical accounts of task resumption after interruption have almost exclusively argued for resumption as a primarily memory-based process. In contrast, for many task domains, resumption can more accurately be represented in terms of a process of reconstruction-perceptual re-encoding of the information necessary to perform the task. This paper discusses a theoretical, computational framework in which one can represent these reconstruction processes and account for aspects of performance, such as measures of resumption lag. The paper also describes computational models of two sample task domains that illustrate the sometimes complex relationship between reconstruction and more general human cognitive, perceptual, and motor processes.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Salvucci, Dario D.},
	year = {2010},
	keywords = {Attention, Multitasking, interruption, problem state},
	pages = {89--92}
}

@inproceedings{jin_self-interruption_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Self-interruption on the {Computer}: {A} {Typology} of {Discretionary} {Task} {Interleaving}},
	isbn = {978-1-60558-246-7},
	shorttitle = {Self-interruption on the {Computer}},
	url = {http://doi.acm.org/10.1145/1518701.1518979},
	doi = {10.1145/1518701.1518979},
	abstract = {The typical information worker is interrupted every 12 minutes, and half of the time they are interrupting themselves. However, most of the research on interruption in the area of human-computer interaction has focused on understanding and managing interruptions from external sources. Internal interruptions -- user-initiated switches away from a task prior to its completion -- are not well understood. In this paper we describe a qualitative study of self-interruption on the computer. Using a grounded theory approach, we identify seven categories of self-interruptions in computer-related activities. These categories are derived from direct observations of users, and describe the motivation, potential consequences, and benefits associated with each type of self-interruption observed. Our research extends the understanding of the self-interruption phenomenon, and informs the design of systems to support discretionary task interleaving on the computer.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Jin, Jing and Dabbish, Laura A.},
	year = {2009},
	keywords = {Attention, interruption, multi-tasking, self-interruption, task-switching, work fragmentation, work spheres},
	pages = {1799--1808}
}

@inproceedings{iqbal_disruption_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {Disruption and {Recovery} of {Computing} {Tasks}: {Field} {Study}, {Analysis}, and {Directions}},
	isbn = {978-1-59593-593-9},
	shorttitle = {Disruption and {Recovery} of {Computing} {Tasks}},
	url = {http://doi.acm.org/10.1145/1240624.1240730},
	doi = {10.1145/1240624.1240730},
	abstract = {We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users' interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Iqbal, Shamsi T. and Horvitz, Eric},
	year = {2007},
	keywords = {Attention, interruption, notifications, task switching},
	pages = {677--686}
}

@article{benbunan-fich_measuring_2011,
	title = {Measuring {Multitasking} {Behavior} with {Activity}-based {Metrics}},
	volume = {18},
	issn = {1073-0516},
	url = {http://doi.acm.org/10.1145/1970378.1970381},
	doi = {10.1145/1970378.1970381},
	abstract = {Multitasking is the result of time allocation decisions made by individuals faced with multiple tasks. Multitasking research is important in order to improve the design of systems and applications. Since people typically use computers to perform multiple tasks at the same time, insights into this type of behavior can help develop better systems and ideal types of computer environments for modern multitasking users. In this paper, we define multitasking based on the principles of task independence and performance concurrency and develop a set of metrics for computer-based multitasking. The theoretical foundation of this metric development effort stems from an application of key principles of Activity Theory and a systematic analysis of computer usage from the perspective of the user, the task and the technology. The proposed metrics, which range from a lean dichotomous variable to a richer measure based on switches, were validated with data from a sample of users who self-reported their activities during a computer usage session. This set of metrics can be used to establish a conceptual and methodological foundation for future multitasking studies.},
	number = {2},
	urldate = {2015-12-10TZ},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Benbunan-Fich, Raquel and Adler, Rachel F. and Mavlanova, Tamilla},
	month = jul,
	year = {2011},
	keywords = {IT usage, Multitasking, activity theory, metrics, task switching, user behavior},
	pages = {7:1--7:22}
}

@inproceedings{leiva_back_2012,
	address = {New York, NY, USA},
	series = {{MobileHCI} '12},
	title = {Back to the {App}: {The} {Costs} of {Mobile} {Application} {Interruptions}},
	isbn = {978-1-4503-1105-2},
	shorttitle = {Back to the {App}},
	url = {http://doi.acm.org/10.1145/2371574.2371617},
	doi = {10.1145/2371574.2371617},
	abstract = {Smartphone users might be interrupted while interacting with an application, either by intended or unintended circumstances. In this paper, we report on a large-scale observational study that investigated mobile application interruptions in two scenarios: (1) intended back and forth switching between applications and (2) unintended interruptions caused by incoming phone calls. Our findings reveal that these interruptions rarely happen (at most 10\% of the daily application usage), but when they do, they may introduce a significant overhead (can delay completion of a task by up to 4 times). We conclude with a discussion of the results, their limitations, and a series of implications for the design of mobile phones.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Leiva, Luis and Böhmer, Matthias and Gehring, Sven and Krüger, Antonio},
	year = {2012},
	keywords = {application switching, interruptions, large-scale study, resumption lags, task deferral, task interleaving},
	pages = {291--294}
}

@inproceedings{leiva_back_2012-1,
	address = {New York, NY, USA},
	series = {{MobileHCI} '12},
	title = {Back to the {App}: {The} {Costs} of {Mobile} {Application} {Interruptions}},
	isbn = {978-1-4503-1105-2},
	shorttitle = {Back to the {App}},
	url = {http://doi.acm.org/10.1145/2371574.2371617},
	doi = {10.1145/2371574.2371617},
	abstract = {Smartphone users might be interrupted while interacting with an application, either by intended or unintended circumstances. In this paper, we report on a large-scale observational study that investigated mobile application interruptions in two scenarios: (1) intended back and forth switching between applications and (2) unintended interruptions caused by incoming phone calls. Our findings reveal that these interruptions rarely happen (at most 10\% of the daily application usage), but when they do, they may introduce a significant overhead (can delay completion of a task by up to 4 times). We conclude with a discussion of the results, their limitations, and a series of implications for the design of mobile phones.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Leiva, Luis and Böhmer, Matthias and Gehring, Sven and Krüger, Antonio},
	year = {2012},
	keywords = {application switching, interruptions, large-scale study, resumption lags, task deferral, task interleaving},
	pages = {291--294}
}

@inproceedings{jesdabodi_understanding_2015,
	address = {New York, NY, USA},
	series = {{UbiComp} '15},
	title = {Understanding {Usage} {States} on {Mobile} {Devices}},
	isbn = {978-1-4503-3574-4},
	url = {http://doi.acm.org/10.1145/2750858.2805837},
	doi = {10.1145/2750858.2805837},
	abstract = {Nowadays, mobile apps are used for nearly every situation: for planning the day, communicating with colleagues, ordering goods, or entertaining and socializing. To understand users expectations in each situation and to provide context-aware services, researchers and app vendors started to capture users' interaction with the smartphone and to model user's behavior. This paper reports on a behavioral study based on app usage data logged over one year and the corresponding apps descriptions from the app store. Using Topic Modeling and clustering techniques, we segmented the usage data into meaningful clusters that correspond to different "states", in which users normally use their smartphone, e.g. socializing or consuming media. Researchers and app-vendors can use the insights from our work to improve their contextual recommendation techniques and the overall usage experience.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Jesdabodi, Chakajkla and Maalej, Walid},
	year = {2015},
	keywords = {apps, behavioral profiles, intent identification, usage data},
	pages = {1221--1225}
}

@inproceedings{brown_iphone_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {{iPhone} in {Vivo}: {Video} {Analysis} of {Mobile} {Device} {Use}},
	isbn = {978-1-4503-1899-0},
	shorttitle = {{iPhone} in {Vivo}},
	url = {http://doi.acm.org/10.1145/2470654.2466132},
	doi = {10.1145/2470654.2466132},
	abstract = {Despite the widespread use of mobile devices, details of mobile technology use 'in the wild' have proven difficult to collect. This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. We use this data to analyse how mobile device use is threaded into other co-present activities, focusing on the use of maps and internet searches. Close analysis reveals novel aspects of gestures on touch screens, how they serve 'double duty' - both as interface gestures but as as resources for ongoing joint action. We go on to describe how users 'walk the blue dot' to orientate themselves, and how searches are occasioned by the local environment. In conclusion, we argue that mobile devices - rather than pushing us away from the world around us - are instead just another thread in the complex tapestry of everyday interaction.},
	urldate = {2015-12-10TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brown, Barry and McGregor, Moira and Laurier, Eric},
	year = {2013},
	keywords = {ethnography, mobility, smartphone use, video methods},
	pages = {1031--1040}
}

@inproceedings{huang_predicting_2012,
	address = {New York, NY, USA},
	series = {{UbiComp} '12},
	title = {Predicting {Mobile} {Application} {Usage} {Using} {Contextual} {Information}},
	isbn = {978-1-4503-1224-0},
	url = {http://doi.acm.org/10.1145/2370216.2370442},
	doi = {10.1145/2370216.2370442},
	abstract = {As the mobile applications become increasing popular, people are installing more and more Apps on their smart phones. In this paper, we answer the question whether it is feasible to predict which App the user will open. The ability for such prediction can help pre-loading the right Apps to the memory for faster execution or help floating the desired Apps to the home screen for quicker launch. We explored a variety of contextual information, such as last used App, time, location, and the user profile, to predict the user's App usage using the MDC dataset. We present three findings from our studies. First, the contextual information can be used to learn the pattern of user's App usage and to predict App usage effectively. Second, for the MDC dataset, the correlation between sequentially used Apps has a strong contribution to the prediction accuracy. Lastly, the linear model is more effective than the Bayesian model to combine all contextual information and for such predictions.},
	urldate = {2015-12-09TZ},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Huang, Ke and Zhang, Chunhui and Ma, Xiaoxiao and Chen, Guanling},
	year = {2012},
	keywords = {application, context, mobile, prediction},
	pages = {1059--1065}
}

@inproceedings{zou_prophet:_2013,
	address = {New York, NY, USA},
	series = {{UbiComp} '13 {Adjunct}},
	title = {Prophet: {What} {App} {You} {Wish} to {Use} {Next}},
	isbn = {978-1-4503-2215-7},
	shorttitle = {Prophet},
	url = {http://doi.acm.org/10.1145/2494091.2494146},
	doi = {10.1145/2494091.2494146},
	abstract = {A variety of applications (app) installed on smart phones do greatly enrich our lives, but make it more difficult to organize our screens and folders. Predicting apps that will be in use next can benefit users a lot. In this poster, we propose some light-weighted Bayesian methods to predict the next app based on the app usage history. The evaluation on Mobile Data Challenge (MDC) dataset gives very encouraging results. In addition, we suggest a natural way to integrate the app prediction features to the user interface. Users would find it convenient to access the predicted apps with simple touches.},
	urldate = {2015-12-09TZ},
	booktitle = {Proceedings of the 2013 {ACM} {Conference} on {Pervasive} and {Ubiquitous} {Computing} {Adjunct} {Publication}},
	publisher = {ACM},
	author = {Zou, Xun and Zhang, Wangsheng and Li, Shijian and Pan, Gang},
	year = {2013},
	keywords = {app prediction, context, smart phone, user interface},
	pages = {167--170}
}

@inproceedings{liao_mining_2013,
	address = {New York, NY, USA},
	series = {{CIKM} '13},
	title = {On {Mining} {Mobile} {Apps} {Usage} {Behavior} for {Predicting} {Apps} {Usage} in {Smartphones}},
	isbn = {978-1-4503-2263-8},
	url = {http://doi.acm.org/10.1145/2505515.2505529},
	doi = {10.1145/2505515.2505529},
	abstract = {Predicting Apps usage has become an important task due to the proliferation of Apps, and the complex of Apps. However, the previous research works utilized a considerable number of different sensors as training data to infer Apps usage. To save the energy consumption for the task of predicting Apps usages, only the temporal information is considered in this paper. We propose a Temporal-based Apps Predictor (abbreviated as TAP) to dynamically predict the Apps which are most likely to be used. First, we extract three Apps usage features, global usage feature, temporal usage feature, and periodical usage feature from the Apps usage trace. Then, based on those explored features, we dynamically derive an Apps usage probability model to estimate the current usage probability of each App in each feature. Finally, we investigate the usage probability in each feature and select k Apps with highest usage probability from the probability model. In this paper, we propose two selection algorithms, MaxProb and MinEntropy. To evaluate the performance of TAP, we use two real mobile Apps usage traces and assess the accuracy and efficiency. The experimental results show that the proposed TAP with the MinEntropy selection algorithm could have shorter response time of Apps prediction. Moreover, the accuracy reaches to 80\% when k is 5, and when k is 7, the accuracy achieves almost 100\% in both of the two real datasets.},
	urldate = {2015-12-09TZ},
	booktitle = {Proceedings of the 22Nd {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Liao, Zhung-Xun and Pan, Yi-Chin and Peng, Wen-Chih and Lei, Po-Ruey},
	year = {2013},
	keywords = {behavior prediction, feature extraction, mobile apps},
	pages = {609--618}
}

@inproceedings{liao_feature_2013,
	title = {On the {Feature} {Discovery} for {App} {Usage} {Prediction} in {Smartphones}},
	doi = {10.1109/ICDM.2013.130},
	abstract = {With the increasing number of mobile Apps developed, they are now closely integrated into daily life. In this paper, we develop a framework to predict mobile Apps that are most likely to be used regarding the current device status of a smartphone. Such an Apps usage prediction framework is a crucial prerequisite for fast App launching, intelligent user experience, and power management of smartphones. By analyzing real App usage log data, we discover two kinds of features: The Explicit Feature (EF) from sensing readings of built-in sensors, and the Implicit Feature (IF) from App usage relations. The IF feature is derived by constructing the proposed App Usage Graph (abbreviated as AUG) that models App usage transitions. In light of AUG, we are able to discover usage relations among Apps. Since users may have different usage behaviors on their smartphones, we further propose one personalized feature selection algorithm. We explore minimum description length (MDL) from the training data and select those features which need less length to describe the training data. The personalized feature selection can successfully reduce the log size and the prediction time. Finally, we adopt the kNN classification model to predict Apps usage. Note that through the features selected by the proposed personalized feature selection algorithm, we only need to keep these features, which in turn reduces the prediction time and avoids the curse of dimensionality when using the kNN classifier. The results based on a real dataset demonstrate the effectiveness of the proposed framework and show the predictive capability for App usage prediction.},
	booktitle = {2013 {IEEE} 13th {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Liao, Zhung-Xun and Li, Shou-Chung and Peng, Wen-Chih and Yu, P.S. and Liu, Te-Chuan},
	month = dec,
	year = {2013},
	keywords = {AUG, App usage graph, App usage log data analysis, App usage transitions, Equations, IF feature, MDL, Mobile Application, Prediction algorithms, Sensors, Testing, Training, built-in sensors, classification, curse of dimensionality, explicit feature, fast App launching, feature discovery, feature selection, graph theory, implicit feature, intelligent user experience, kNN classification model, kNN classifier, log size reduction, minimum description length, mobile App usage prediction framework, mobile apps, mobile computing, pattern classification, personalized feature selection algorithm, power aware computing, prediction time reduction, smart phones, smartphones, training data, usage prediction},
	pages = {1127--1132}
}
@inproceedings{lu_mining_2014,
	title = {Mining mobile application sequential patterns for usage prediction},
	doi = {10.1109/GRC.2014.6982832},
	abstract = {In recent years, researches on smart phone services have received a lot of attention in both of the industry and academia due to a wide range of potential applications. Among them, one of popular topics is the mining and prediction of mobile application usage behaviors. In this paper, we propose a location-based approach to predict the mobile application usage behaviors. In this approach, we first discover the stay locations of the GPS movement data to obtain the mobile application usage database. Then, we consider both of the physical location moving paths and virtual application usage paths of users to mine the Mobile Application Sequential Patterns (MASPs) by the Mobile Application Sequential Pattern Mine (MASP-Mine) algorithm. Furthermore, a prediction strategy is designed to predict the next mobile application usage behaviors based on the MASPs. To our best knowledge, this is the first work on mining and prediction of mobile application usage behaviors with considerations of physical location moving paths and virtual application usage paths simultaneously. Through experimental evaluation under various condition settings by a real mobile application usage data, the proposed approach is shown to deliver excellent performance in terms of precision and recall.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Granular} {Computing} ({GrC})},
	author = {Lu, E.H.-C. and Lin, Yi-Wei and Ciou, Jing-Bin},
	month = oct,
	year = {2014},
	keywords = {Algorithm design and analysis, Databases, GPS movement data, Global Positioning System, MASP-Mine algorithm, Mobile Application, Mobile communication, Prediction algorithms, data mining, location-based approach, mobile application sequential pattern mine algorithm, mobile computing, pattern mining, physical location moving paths, prediction strategy, smart phone services, smart phones, usage prediction, virtual application usage paths},
	pages = {185--190}
}

@inproceedings{liao_feature_2013,
	title = {On the {Feature} {Discovery} for {App} {Usage} {Prediction} in {Smartphones}},
	doi = {10.1109/ICDM.2013.130},
	abstract = {With the increasing number of mobile Apps developed, they are now closely integrated into daily life. In this paper, we develop a framework to predict mobile Apps that are most likely to be used regarding the current device status of a smartphone. Such an Apps usage prediction framework is a crucial prerequisite for fast App launching, intelligent user experience, and power management of smartphones. By analyzing real App usage log data, we discover two kinds of features: The Explicit Feature (EF) from sensing readings of built-in sensors, and the Implicit Feature (IF) from App usage relations. The IF feature is derived by constructing the proposed App Usage Graph (abbreviated as AUG) that models App usage transitions. In light of AUG, we are able to discover usage relations among Apps. Since users may have different usage behaviors on their smartphones, we further propose one personalized feature selection algorithm. We explore minimum description length (MDL) from the training data and select those features which need less length to describe the training data. The personalized feature selection can successfully reduce the log size and the prediction time. Finally, we adopt the kNN classification model to predict Apps usage. Note that through the features selected by the proposed personalized feature selection algorithm, we only need to keep these features, which in turn reduces the prediction time and avoids the curse of dimensionality when using the kNN classifier. The results based on a real dataset demonstrate the effectiveness of the proposed framework and show the predictive capability for App usage prediction.},
	booktitle = {2013 {IEEE} 13th {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Liao, Zhung-Xun and Li, Shou-Chung and Peng, Wen-Chih and Yu, P.S. and Liu, Te-Chuan},
	month = dec,
	year = {2013},
	keywords = {AUG, App usage graph, App usage log data analysis, App usage transitions, Equations, IF feature, MDL, Mobile Application, Prediction algorithms, Sensors, Testing, Training, built-in sensors, classification, curse of dimensionality, explicit feature, fast App launching, feature discovery, feature selection, graph theory, implicit feature, intelligent user experience, kNN classification model, kNN classifier, log size reduction, minimum description length, mobile App usage prediction framework, mobile apps, mobile computing, pattern classification, personalized feature selection algorithm, power aware computing, prediction time reduction, smart phones, smartphones, training data, usage prediction},
	pages = {1127--1132}
}

@inproceedings{liao_feature_2013-1,
	title = {On the {Feature} {Discovery} for {App} {Usage} {Prediction} in {Smartphones}},
	doi = {10.1109/ICDM.2013.130},
	abstract = {With the increasing number of mobile Apps developed, they are now closely integrated into daily life. In this paper, we develop a framework to predict mobile Apps that are most likely to be used regarding the current device status of a smartphone. Such an Apps usage prediction framework is a crucial prerequisite for fast App launching, intelligent user experience, and power management of smartphones. By analyzing real App usage log data, we discover two kinds of features: The Explicit Feature (EF) from sensing readings of built-in sensors, and the Implicit Feature (IF) from App usage relations. The IF feature is derived by constructing the proposed App Usage Graph (abbreviated as AUG) that models App usage transitions. In light of AUG, we are able to discover usage relations among Apps. Since users may have different usage behaviors on their smartphones, we further propose one personalized feature selection algorithm. We explore minimum description length (MDL) from the training data and select those features which need less length to describe the training data. The personalized feature selection can successfully reduce the log size and the prediction time. Finally, we adopt the kNN classification model to predict Apps usage. Note that through the features selected by the proposed personalized feature selection algorithm, we only need to keep these features, which in turn reduces the prediction time and avoids the curse of dimensionality when using the kNN classifier. The results based on a real dataset demonstrate the effectiveness of the proposed framework and show the predictive capability for App usage prediction.},
	booktitle = {2013 {IEEE} 13th {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Liao, Zhung-Xun and Li, Shou-Chung and Peng, Wen-Chih and Yu, P.S. and Liu, Te-Chuan},
	month = dec,
	year = {2013},
	keywords = {AUG, App usage graph, App usage log data analysis, App usage transitions, Equations, IF feature, MDL, Mobile Application, Prediction algorithms, Sensors, Testing, Training, built-in sensors, classification, curse of dimensionality, explicit feature, fast App launching, feature discovery, feature selection, graph theory, implicit feature, intelligent user experience, kNN classification model, kNN classifier, log size reduction, minimum description length, mobile App usage prediction framework, mobile apps, mobile computing, pattern classification, personalized feature selection algorithm, power aware computing, prediction time reduction, smart phones, smartphones, training data, usage prediction},
	pages = {1127--1132}
}

@inproceedings{liao_mining_2013,
	address = {New York, NY, USA},
	series = {{CIKM} '13},
	title = {On {Mining} {Mobile} {Apps} {Usage} {Behavior} for {Predicting} {Apps} {Usage} in {Smartphones}},
	isbn = {978-1-4503-2263-8},
	url = {http://doi.acm.org/10.1145/2505515.2505529},
	doi = {10.1145/2505515.2505529},
	abstract = {Predicting Apps usage has become an important task due to the proliferation of Apps, and the complex of Apps. However, the previous research works utilized a considerable number of different sensors as training data to infer Apps usage. To save the energy consumption for the task of predicting Apps usages, only the temporal information is considered in this paper. We propose a Temporal-based Apps Predictor (abbreviated as TAP) to dynamically predict the Apps which are most likely to be used. First, we extract three Apps usage features, global usage feature, temporal usage feature, and periodical usage feature from the Apps usage trace. Then, based on those explored features, we dynamically derive an Apps usage probability model to estimate the current usage probability of each App in each feature. Finally, we investigate the usage probability in each feature and select k Apps with highest usage probability from the probability model. In this paper, we propose two selection algorithms, MaxProb and MinEntropy. To evaluate the performance of TAP, we use two real mobile Apps usage traces and assess the accuracy and efficiency. The experimental results show that the proposed TAP with the MinEntropy selection algorithm could have shorter response time of Apps prediction. Moreover, the accuracy reaches to 80\% when k is 5, and when k is 7, the accuracy achieves almost 100\% in both of the two real datasets.},
	urldate = {2015-12-09TZ},
	booktitle = {Proceedings of the 22Nd {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Liao, Zhung-Xun and Pan, Yi-Chin and Peng, Wen-Chih and Lei, Po-Ruey},
	year = {2013},
	keywords = {behavior prediction, feature extraction, mobile apps},
	pages = {609--618}
}

@inproceedings{jones_revisitation_2015,
	address = {New York, NY, USA},
	series = {{UbiComp} '15},
	title = {Revisitation {Analysis} of {Smartphone} {App} {Use}},
	isbn = {978-1-4503-3574-4},
	url = {http://doi.acm.org/10.1145/2750858.2807542},
	doi = {10.1145/2750858.2807542},
	abstract = {We present a revisitation analysis of smartphone use to investigate the question: do smartphones induce usage habits? We analysed three months of application launch logs from 165 users in naturalistic settings. Our analysis reveals distinct clusters of applications and users which share similar revisitation patterns. However, we show that much of smartphone usage on a macro-level is very similar to web browsing on desktops, and thus argue that smartphone usage is driven by innate service needs rather than technology characteristics. On the other hand, on a micro-level we identify unique characteristics in smartphone usage, and we present a rudimentary model that accounts for 92\% in the variability of our smartphone use.},
	urldate = {2015-12-09TZ},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Jones, Simon L. and Ferreira, Denzil and Hosio, Simo and Goncalves, Jorge and Kostakos, Vassilis},
	year = {2015},
	keywords = {habits, revisitation, smartphone use, user behaviour},
	pages = {1197--1208}
}

@inproceedings{bohmer_falling_2011,
	address = {New York, NY, USA},
	series = {{MobileHCI} '11},
	title = {Falling {Asleep} with {Angry} {Birds}, {Facebook} and {Kindle}: {A} {Large} {Scale} {Study} on {Mobile} {Application} {Usage}},
	isbn = {978-1-4503-0541-9},
	shorttitle = {Falling {Asleep} with {Angry} {Birds}, {Facebook} and {Kindle}},
	url = {http://doi.acm.org/10.1145/2037373.2037383},
	doi = {10.1145/2037373.2037383},
	abstract = {While applications for mobile devices have become extremely important in the last few years, little public information exists on mobile application usage behavior. We describe a large-scale deployment-based research study that logged detailed application usage information from over 4,100 users of Android-powered mobile devices. We present two types of results from analyzing this data: basic descriptive statistics and contextual descriptive statistics. In the case of the former, we find that the average session with an application lasts less than a minute, even though users spend almost an hour a day using their phones. Our contextual findings include those related to time of day and location. For instance, we show that news applications are most popular in the morning and games are at night, but communication applications dominate through most of the day. We also find that despite the variety of apps available, communication applications are almost always the first used upon a device's waking from sleep. In addition, we discuss the notion of a virtual application sensor, which we used to collect the data.},
	urldate = {2015-12-07TZ},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Human} {Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Böhmer, Matthias and Hecht, Brent and Schöning, Johannes and Krüger, Antonio and Bauer, Gernot},
	year = {2011},
	keywords = {large-scale study, measuring, mobile apps, usage sensor},
	pages = {47--56}
}

@article{daneman_assessing_1992,
	title = {Assessing the importance of subvocalization during normal silent reading},
	volume = {4},
	issn = {0922-4777, 1573-0905},
	url = {http://link.springer.com/article/10.1007/BF01027072},
	doi = {10.1007/BF01027072},
	abstract = {A concurrent speaking paradigm was used to assess the importance of subvocalization during the reading of lengthy natural prose passages. Experiment 1 showed that having subjects count aloud while reading interfered with their comprehension and recall of the text's details as well as its gist, but did not affect the durability of the memory trace. Experiment 2 replicated these findings and established the validity of using concurrent speaking as a technique to interfere with speech-specific processes during silent reading. By pitting concurrent speaking against a nonverbal concurrent task, Experiment 2 provided evidence that its detrimental effect on comprehension was due to a competition for speech-related resources rather than a general competition for cognitive resources. Interfering with speech recoding during silent reading led to an average decrement of 10–12\% in comprehension performance. However, Experiment 2 also showed that there were substantial individual differences in the magnitude of the speech interference effect and that these differences were systematically related to subjective reports about the concurrent speaking manipulation.},
	language = {en},
	number = {1},
	urldate = {2015-12-06TZ},
	journal = {Reading and Writing},
	author = {Daneman, Meredyth and Newson, Margaret},
	month = mar,
	year = {1992},
	keywords = {Articulatory suppression, Comprehension, Education (general), Interdisciplinary Studies, Languages and Literature, Neurology, Psycholinguistics, Reading, Subvocalization, Working memory},
	pages = {55--77}
}

@article{carver_effect_1970,
	title = {Effect of a "chunked" typography on reading rate and comprehension},
	volume = {54},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1854(Electronic);0021-9010(Print)},
	doi = {10.1037/h0029266},
	abstract = {3 studies with 104 undergraduates investigated the effect of a chunked typography on the reading rate and comprehension of mature readers, reading at their normal rates. Passages and questions from a standardized reading test were displayed via an electromechanical device which allowed actual reading times to be recorded. 5 experimental chunked formats were compared with each other and 1 selected for further study. The chunking of the material was arbitrarily intuitive but a subsequent analysis indicated that the chunked boundaries usually coincided with the major phrase boundaries of immediate constituents. There was no important or statistically significant difference between the experimental chunked format and the control format, either on the reading rate or comprehension measures. Another control format, no punctuation or capitalization, did result in significant decrements in reading rate and comprehension. It is concluded that the spatial separation of reading materials into groups of meaningfully related words does not improve the reading efficiency of mature readers when they are reading at their normal rate.},
	number = {3},
	journal = {Journal of Applied Psychology},
	author = {Carver, Ronald P.},
	year = {1970},
	keywords = {*Displays, *Sentences, Words (Phonetic Units)},
	pages = {288--296}
}

@inproceedings{wu_video_2011,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '11},
	title = {Video {Summarization} via {Crowdsourcing}},
	isbn = {978-1-4503-0268-5},
	url = {http://doi.acm.org/10.1145/1979742.1979803},
	doi = {10.1145/1979742.1979803},
	abstract = {Although video summarization has been studied extensively, existing schemes are neither lightweight nor generalizable to all types of video content. To generate accurate abstractions of all types of video, we propose a framework called Click2SMRY, which leverages the wisdom of the crowd to generate video summaries with a low workload for workers. The framework is lightweight because workers only need to click a dedicated key when they feel that the video being played is reaching a highlight. One unique feature of the framework is that it can generate different abstraction levels of video summaries according to viewers' preferences in real time. The results of experiments conducted to evaluate the framework demonstrate that it can generate satisfactory summaries for different types of video clips.},
	urldate = {2015-12-06TZ},
	booktitle = {{CHI} '11 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wu, Shao-Yu and Thawonmas, Ruck and Chen, Kuan-Ta},
	year = {2011},
	keywords = {crowdsourcing, human computation, video skimming, video summarization},
	pages = {1531--1536}
}

@inproceedings{bernstein_soylent:_2010,
	address = {New York, NY, USA},
	series = {{UIST} '10},
	title = {Soylent: {A} {Word} {Processor} with a {Crowd} {Inside}},
	isbn = {978-1-4503-0271-5},
	shorttitle = {Soylent},
	url = {http://doi.acm.org/10.1145/1866029.1866078},
	doi = {10.1145/1866029.1866078},
	abstract = {This paper introduces architectural and interaction patterns for integrating crowdsourced human contributions directly into user interfaces. We focus on writing and editing, complex endeavors that span many levels of conceptual and pragmatic activity. Authoring tools offer help with pragmatics, but for higher-level help, writers commonly turn to other people. We thus present Soylent, a word processing interface that enables writers to call on Mechanical Turk workers to shorten, proofread, and otherwise edit parts of their documents on demand. To improve worker quality, we introduce the Find-Fix-Verify crowd programming pattern, which splits tasks into a series of generation and review stages. Evaluation studies demonstrate the feasibility of crowdsourced editing and investigate questions of reliability, cost, wait time, and work time for edits.},
	urldate = {2015-12-06TZ},
	booktitle = {Proceedings of the 23Nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Bernstein, Michael S. and Little, Greg and Miller, Robert C. and Hartmann, Björn and Ackerman, Mark S. and Karger, David R. and Crowell, David and Panovich, Katrina},
	year = {2010},
	keywords = {crowdsourcing, mechanical turk, outsourcing},
	pages = {313--322}
}

@article{salton_automatic_1997,
	series = {Methods and {Tools} for the {Automatic} {Construction} of {Hypertext}},
	title = {Automatic text structuring and summarization},
	volume = {33},
	issn = {0306-4573},
	url = {http://www.sciencedirect.com/science/article/pii/S0306457396000623},
	doi = {10.1016/S0306-4573(96)00062-3},
	abstract = {In recent years, information retrieval techniques have been used for automatic generation of semantic hypertext links. This study applies the ideas from the automatic link generation research to attack another important problem in text processing—automatic text summarization. An automatic “general purpose” text summarization tool would be of immense utility in this age of information overload. Using the techniques used (by most automatic hypertext link generation algorithms) for inter-document link generation, we generate intra-document links between passages of a document. Based on the intra-document linkage pattern of a text, we characterize the structure of the text. We apply the knowledge of text structure to do automatic text summarization by passage extraction. We evaluate a set of fifty summaries generated using our techniques by comparing them to paragraph extracts constructed by humans. The automatic summarization methods perform well, especially in view of the fact that the summaries generated by two humans for the same article are surprisingly dissimilar.},
	number = {2},
	urldate = {2015-12-06TZ},
	journal = {Information Processing \& Management},
	author = {Salton, Gerard and Singhal, Amit and Mitra, Mandar and Buckley, Chris},
	month = mar,
	year = {1997},
	pages = {193--207}
}

@book{mani_advances_1999,
	address = {Cambridge, MA, USA},
	title = {Advances in {Automatic} {Text} {Summarization}},
	isbn = {0-262-13359-8},
	abstract = {From the Publisher:Text summarization is the process of distilling the most important information from a source to produce an abridged version for a particular user or task.. "Until now there has been no state-of-the-art collection of the most important writings in automatic text summarization. This book presents the key developments in the field in an integrated framework and suggests future research areas. The book is organized into six sections. Classical Approaches, Corpus-Based Approaches, Exploiting Discourse Structure, Knowledge-Rich Approaches, Evaluation Methods, and New Summarization Problem Areas.},
	publisher = {MIT Press},
	author = {Mani, Inderjeet},
	editor = {Maybury, Mark T.},
	year = {1999}
}

@inproceedings{chi_scenthighlights:_2005,
	address = {New York, NY, USA},
	series = {{IUI} '05},
	title = {{ScentHighlights}: {Highlighting} {Conceptually}-related {Sentences} {During} {Reading}},
	isbn = {1-58113-894-6},
	shorttitle = {{ScentHighlights}},
	url = {http://doi.acm.org/10.1145/1040830.1040895},
	doi = {10.1145/1040830.1040895},
	abstract = {Researchers have noticed that readers are increasingly skimming instead of reading in depth. Skimming also occur in re-reading activities, where the goal is to recall specific topical facts. Bookmarks and highlighters were invented precisely to achieve this goal. For skimming activities, readers need effective ways to direct their attention toward the most relevant passages within text. We describe how we have enhanced skimming activity by conceptually highlighting sentences within electronic text that relate to search keywords. We perform the conceptual highlighting by computing what conceptual keywords are related to each other via word co-occurrence and spreading activation. Spreading activation is a cognitive model developed in psychology to simulate how memory chunks and conceptual items are retrieved in our brain. We describe the method used, and illustrate the idea with realistic scenarios using our system.},
	urldate = {2015-12-06TZ},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Chi, Ed H. and Hong, Lichan and Gumbrecht, Michelle and Card, Stuart K.},
	year = {2005},
	keywords = {automatic text highlighting, contextualization, dynamic summarization, eBooks, information scent, personalized information access},
	pages = {272--274}
}

@article{lorch_jr_understanding_2000,
	title = {Understanding {Reading} {Comprehension}},
	volume = {3},
	url = {https://books.google.com/books?hl=en&lr=&id=Whu0voGJvQIC&oi=fnd&pg=PA186&dq=understanding+reading+comprehension+R.F.Lorch+Jr&ots=5KIpWJpY7u&sig=76ZzlAt194Kqh95li_vm4ThWXv0},
	urldate = {2015-12-06TZ},
	journal = {Psychology of Education: The school curriculum},
	author = {Lorch Jr, R. F. and van den Brock, P.},
	year = {2000},
	pages = {186}
}

@book{grellet_developing_1981,
	title = {Developing {Reading} {Skills}: {A} {Practical} {Guide} to {Reading} {Comprehension} {Exercises}},
	isbn = {978-0-521-28364-9},
	shorttitle = {Developing {Reading} {Skills}},
	abstract = {This is a handbook for language teachers who would like to develop their own reading materials or who wish to enrich a reading course. It offers a classification and description of exercises aimed at developing different reading skills. While the book is designed primarily for teachers of English as a second language, the exercises are equally appropriate for the teaching of other foreign languages and much of the book is relevant to the teaching of first-language reading skills. The question-types range from the familiar (for example, multiple-choice and open questions) to highly original exercises which require the integration of different skills and an active, creative response from the student. It encourages teachers to introduce variety into the teaching of reading and offers them a great deal of resource material to draw on.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Grellet, Frangoise},
	month = sep,
	year = {1981},
	keywords = {Foreign Language Study / English as a Second Language}
}

@incollection{just_psychology_1987,
	address = {Newton, MA},
	title = {The psychology of reading and language comprehension},
	booktitle = {Speed {Reading}},
	publisher = {Allyn and Bacon},
	author = {Just, Marcel Adam and Carpenter, Patricia A.},
	year = {1987},
	pages = {425--452}
}

@book{shin_visual_2012,
	edition = {1 edition},
	title = {Visual {Reading} and {The} {Snowball} of {Understanding}},
	language = {English},
	publisher = {Cheese Cake \& Linco Global},
	author = {Shin, Hyo Sang},
	month = feb,
	year = {2012}
}

@article{carver_reading_1992,
	title = {Reading {Rate}: {Theory}, {Research}, and {Practical} {Implications}},
	volume = {36},
	issn = {0022-4103},
	shorttitle = {Reading {Rate}},
	url = {http://www.jstor.org/stable/40016440},
	number = {2},
	urldate = {2015-12-06TZ},
	journal = {Journal of Reading},
	author = {Carver, Ronald P.},
	year = {1992},
	pages = {84--95}
}

@article{writing_studio_duke_university_how_nodate,
	title = {How to {Read} and {Review} a {Scientific} {Journal} {Article}},
	author = {Writing Studio, Duke University}
}

@article{siegel_reading_nodate,
	title = {Reading {Scientific} {Papers}},
	journal = {Bob's Home Page, Stanford University},
	author = {Siegel, Robert}
}

@article{purugganan_how_nodate,
	title = {How to {Read} a {Scientific} {Article}},
	journal = {Cain Project in Engineering and Professional Communication, Rice University},
	author = {Purugganan, Mary and Hewitt, Jan}
}

@article{duggan_text_2009,
	title = {Text skimming: the process and effectiveness of foraging through text under time pressure},
	volume = {15},
	issn = {1939-2192},
	shorttitle = {Text skimming},
	doi = {10.1037/a0016995},
	abstract = {Is Skim reading effective? How do readers allocate their attention selectively? The authors report 3 experiments that use expository texts and allow readers only enough time to read half of each document. Experiment 1 found that, relative to reading half the text, skimming improved memory for important ideas from a text but did not improve memory of less important details or of inferences made from information within the text. Experiment 2 found no advantage of skimming over reading the first or second half of every paragraph. Two final experiments using a hierarchical, Website-like layout of documents showed that the advantage of skimming found in Experiment 1 was dependent on the linkages between pages and, thus, the ease with which participants could navigate through the text. Data on page-by-page reading times and eye-tracking analyses from Experiment 2 indicated that Skim readers spent more time reading text that was earlier in the paragraph, toward the top of the page and in an earlier page of the document. These findings were interpreted as evidence in support of a "satisficing" account of skimming process.},
	language = {eng},
	number = {3},
	journal = {Journal of Experimental Psychology. Applied},
	author = {Duggan, Geoffrey B. and Payne, Stephen J.},
	month = sep,
	year = {2009},
	pmid = {19751073},
	keywords = {Adult, Analysis of Variance, Attention, Comprehension, Eye movements, Female, Humans, Male, Memory, Reading, Students, Time Factors, Young Adult},
	pages = {228--242}
}

@inproceedings{duggan_skim_2011,
	address = {New York, NY, USA},
	series = {{CHI} '11},
	title = {Skim {Reading} by {Satisficing}: {Evidence} from {Eye} {Tracking}},
	isbn = {978-1-4503-0228-9},
	shorttitle = {Skim {Reading} by {Satisficing}},
	url = {http://doi.acm.org/10.1145/1978942.1979114},
	doi = {10.1145/1978942.1979114},
	abstract = {Readers on the Web often skim through text to cope with the volume of available information. In a previous study, Duggan and Payne [11] tracked readers' eye movements as they skimmed through expository text under time pressure. This article presents novel analyses of these eye-movement data. Results indicated that readers were able to explicitly direct attention to the most important information in the text and that this improved performance on a subsequent test of memory for the meaning of text. We suggest readers achieve this by satisficing reading through text until the rate of information gain drops below threshold and then skipping to the next section of text. Further analyses of gaze patterns for paragraphs and pages supported this explanation. Combining satisficing with some form of scanning or sampling behaviour could explain patterns of reading found on the Web. A greater understanding of the way that text is read on the Web would assist many producers of online content.},
	urldate = {2015-12-06TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Duggan, Geoffrey B. and Payne, Stephen J.},
	year = {2011},
	keywords = {Reading, information foraging, skimming, speed reading, time allocation.},
	pages = {1141--1150}
}

@article{dina_kiwan_effects_2000,
	title = {The effects of time-induced stress on making inferences in text comprehension},
	author = {Dina Kiwan, Ayesha Ahmed},
	year = {2000}
}

@article{dyson_effects_2000,
	title = {The effects of reading speed and reading patterns on the understanding of text read from screen},
	volume = {23},
	copyright = {United Kingdom Reading Association 2000},
	issn = {1467-9817},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9817.00115/abstract},
	doi = {10.1111/1467-9817.00115},
	abstract = {With increasing use of the World Wide Web, rapid scanning or skimming of material on screen has become a frequent activity. However, the outcome of this method of reading has not been thoroughly investigated. Using a range of question types, comprehension was measured after reading from screen at both a normal and fast reading speed. In addition, by automatically recording how readers scrolled through each document, reading patterns were explored. A speed-accuracy trade-off was found and, in general, the recall of specific details was less accurate than responses to ‘higher order’ questions. However, questions that addressed the structure of the text were hardest. Analysis of the scrolling movements showed that the overall time spent pausing between movements was the best predictor of comprehension. At a normal reading speed, the most effective readers, in terms of higher comprehension scores, were those who spent more time between scrolling movements, which were fast and frequent.},
	language = {en},
	number = {2},
	urldate = {2015-12-06TZ},
	journal = {Journal of Research in Reading},
	author = {Dyson, Mary and Haselgrove, Mark},
	month = jun,
	year = {2000},
	pages = {210--223}
}

@inproceedings{yi_qndreview:_2014,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '14},
	title = {{QnDReview}: {Read} 100 {CHI} {Papers} in 7 {Hours}},
	isbn = {978-1-4503-2474-8},
	shorttitle = {{QnDReview}},
	url = {http://doi.acm.org/10.1145/2559206.2578884},
	doi = {10.1145/2559206.2578884},
	abstract = {In 2013, 392 research papers and notes were published in the CHI conference (The ACM CHI Conference on Human Factors in Computing Systems) and even more papers in the domain of Human-Computer Interaction (HCI) are constantly published in various conferences and journals. It is quite arduous, if not impossible, to read all of these papers. One approach to deal with this information deluge is to focus on skimming through lots of papers in a short period of time, so that one can more wisely choose what to read before investing time in them. In order to teach such a skimming technique, I have taught a technique, called "Quick and Dirty Review (QnDReview)," in a graduate-level HCI course. The method has been employed in the course for five semesters, and students' responses were collected and analyzed. Results showed that students spent, on average, 4.3 minutes per paper and believed that they got the gist of each paper. However, the largest benefit I noticed is that students get the overall pictures of the fields while exposing themselves to various new ideas through this approach.},
	urldate = {2015-12-06TZ},
	booktitle = {{CHI} '14 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yi, Ji Soo},
	year = {2014},
	keywords = {hci education, quick and dirty review, skimming},
	pages = {805--814}
}

@article{benedetto_rapid_2015,
	title = {Rapid serial visual presentation in reading: {The} case of {Spritz}},
	volume = {45},
	issn = {0747-5632},
	shorttitle = {Rapid serial visual presentation in reading},
	url = {http://www.sciencedirect.com/science/article/pii/S0747563214007663},
	doi = {10.1016/j.chb.2014.12.043},
	abstract = {In the era of small screens, traditional reading (i.e. left-to-right, top-to-bottom) is called into question and rapid serial visual presentation (RSVP) represents one of the main alternatives. RSVP consists of displaying in sequential order one or more words at a time, thus minimizing saccades and eye blinks. Recently, a RSVP application has received a lot of media attention: it is the case of Spritz. According to Spritz’s developers, the elimination of saccades should reduce visual fatigue and improve comprehension. In this study, we had people read on a computer screen a selected part of a book either with Spritz or in the traditional way. Results seem to contradict these claims. The fact that Spritz suppresses parafoveal processing and regressions (i.e. rereadings of words) negatively affected literal comprehension. Furthermore, the important reduction of eye blinks observed for Spritz might contribute to the increase of visual fatigue.},
	urldate = {2015-12-06TZ},
	journal = {Computers in Human Behavior},
	author = {Benedetto, Simone and Carbone, Andrea and Pedrotti, Marco and Le Fevre, Kevin and Bey, Linda Amel Yahia and Baccino, Thierry},
	month = apr,
	year = {2015},
	keywords = {Comprehension, Rapid serial visual presentation, Reading, Spritz, Visual fatigue},
	pages = {352--358}
}

@inproceedings{ahmed_non-visual_2013,
	address = {New York, NY, USA},
	series = {{IUI} '13},
	title = {Non-visual {Skimming} on {Touch}-screen {Devices}},
	isbn = {978-1-4503-1965-2},
	url = {http://doi.acm.org/10.1145/2449396.2449452},
	doi = {10.1145/2449396.2449452},
	abstract = {While reading on touch-screens, sighted users can quickly pan through content, skim it, and pick out bits and pieces of information before deciding to read it more carefully. In contrast, blind users have to rely on the screen reader to narrate the content to them. To go through the text quickly, blind users employ gestures that direct the screen reader to skip to the next line or the next paragraph. However, the serial audio interface of the screen reader makes it difficult for blind users to get a sense of what is important before listening to, at least, a part of the content. This makes ad hoc skimming with gestures slow and ineffective. We address this problem in this paper; specifically we propose a non-visual skimming interface that enables blind users to control the amount of content with simple pinch-in and pinch-out gestures. This interface simulates the skimming experience enjoyed by sighted people, and enables blind users to listen to the gist of content, while controlling the speed of information intake. We report on a user study demonstrating that the proposed interface significantly outperforms ad hoc skimming techniques employed by blind users. Our results suggest that the proposed approach holds promise in empowering blind users to access digitized information much faster.},
	urldate = {2015-12-06TZ},
	booktitle = {Proceedings of the 2013 {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Ahmed, Faisal and Soviak, Andrii and Borodin, Yevgen and Ramakrishnan, I.V.},
	year = {2013},
	keywords = {accessibility, blind, screen reader, skimming, speed reading, summarization, touch interface},
	pages = {435--444}
}

@inproceedings{ahmed_accessible_2012,
	address = {New York, NY, USA},
	series = {{UIST} '12},
	title = {Accessible {Skimming}: {Faster} {Screen} {Reading} of {Web} {Pages}},
	isbn = {978-1-4503-1580-7},
	shorttitle = {Accessible {Skimming}},
	url = {http://doi.acm.org/10.1145/2380116.2380164},
	doi = {10.1145/2380116.2380164},
	abstract = {In our information-driven web-based society, we are all gradually falling ""victims"" to information overload [5].However, while sighted people are finding ways to sift through information faster, Internet users who are blind are experiencing an even greater information overload. These people access computers and Internet using screen-reader software, which reads the information on a computer screen sequentially using computer-generated speech. While sighted people can learn how to quickly glance over the headlines and news articles online to get the gist of information, people who are blind have to use keyboard shortcuts to listen through the content narrated by a serial audio interface. This interface does not give them an opportunity to know what content to skip and what to listen to. So, they either listen to all of the content or listen to the first part of each sentence or paragraph before they skip to the next one. In this paper, we propose an automated approach to facilitate non-visual skimming of web pages. We describe the underlying algorithm, outline a non-visual skimming interface, and report on the results of automated experiments, as well as on our user study with 23 screen-reader users. The results of the experiments suggest that we have been moderately successful in designing a viable algorithm for automatic summarization that could be used for non-visual skimming. In our user studies, we confirmed that people who are blind could read and search through online articles faster and were able to understand and remember most of what they have read with our skimming system. Finally, all 23 participants expressed genuine interest in using non-visual skimming in the future.},
	urldate = {2015-12-06TZ},
	booktitle = {Proceedings of the 25th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Ahmed, Faisal and Borodin, Yevgen and Soviak, Andrii and Islam, Muhammad and Ramakrishnan, I.V. and Hedgpeth, Terri},
	year = {2012},
	keywords = {accessibility, assistive technology, blind, screen reader, skimming, speed reading, summarization},
	pages = {367--378}
}

@article{shaikh_effects_2005,
	title = {The {Effects} of {Line} {Length} on {Reading} {Performance} of {Online} {News} {Articles}},
	volume = {49},
	issn = {1541-9312,},
	url = {http://pro.sagepub.com/content/49/5/701},
	doi = {10.1177/154193120504900514},
	abstract = {Previous research has shown that typographical factors of online text may influence its readability. This study examines the effects of line length on reading speed, comprehension, and user satisfaction of online news articles. Twenty college-age students read news articles displayed in 35, 55, 75, or 95 characters per line (cpl) from a computer monitor. Comprehension was assessed using six question types — title, main idea, main factual, structure, incidental, and recognition (Dyson \& Haselgrove, 2001). Results showed that passages formatted with 95 cpl resulted in faster reading speed. Structure questions were found to be more challenging overall when compared to factual and other lower-level questions. Overall satisfaction was not affected by line length; however, users indicated a strong preference for the extreme line lengths.},
	language = {en},
	number = {5},
	urldate = {2015-12-06TZ},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Shaikh, A. Dawn and Chaparro, Barbara S.},
	month = sep,
	year = {2005},
	pages = {701--705}
}

@article{lowrance_exploring_2013,
	title = {Exploring interface effect on skimming comprehension: {Comparing} low-clutter and no-clutter documentation presentation environments},
	volume = {50},
	copyright = {Copyright © 2013 by American Society for Information Science and Technology},
	issn = {1550-8390},
	shorttitle = {Exploring interface effect on skimming comprehension},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/meet.14505001172/abstract},
	doi = {10.1002/meet.14505001172},
	abstract = {Due to the wide variety of web-based reading environments, it is important to study reading environment effects on the skimming comprehension of information foragers. New readability applications have been developed to reduce visual clutter on web pages and enhance elements of text. This pilot study explored the effects of one of these new readability applications on skimming comprehension in a low-clutter research environment. When comparing the results of skimming for meaning tests between a low-clutter document display and that of the same article in the readability application display, no significant benefits were found. These findings suggest that if a readability application were to have a beneficial effect on skimming, then it would only potentially affect skimming pages presented with higher amounts of web page clutter. Additionally, the exit interview revealed that almost all of the participants preferred the readability display.},
	language = {en},
	number = {1},
	urldate = {2015-12-06TZ},
	journal = {Proceedings of the American Society for Information Science and Technology},
	author = {Lowrance, Nathan and Mouliason, Heather Lea},
	month = jan,
	year = {2013},
	pages = {1--4}
}

@inproceedings{fitzsimmons_skim_2014,
	address = {New York, NY, USA},
	series = {{WebSci} '14},
	title = {Skim {Reading}: {An} {Adaptive} {Strategy} for {Reading} on the {Web}},
	isbn = {978-1-4503-2622-3},
	shorttitle = {Skim {Reading}},
	url = {http://doi.acm.org/10.1145/2615569.2615682},
	doi = {10.1145/2615569.2615682},
	abstract = {It has been suggested that readers spend a great deal of time skim reading on the Web and that if readers skim read they reduce their comprehension of what they have read. There have been a number of studies exploring skim reading, but relatively little exists on the skim reading of hypertext and Webpages. In the experiment documented here, we utilised eye tracking methodology to explore how readers skim read hypertext and how hyperlinks affect reading behaviour. The results show that the readers read faster when they were skim reading and comprehension was reduced. However, the presence of hyperlinks seemed to assist the readers in picking out important information when skim reading. We suggest that readers engage in an adaptive information foraging strategy where they attempt to minimise comprehension loss while maintaining a high reading speed. Readers use hyperlinks as markers to suggest important information and use them to read through the text in an efficient and effective way. This suggests that skim reading may not be as damaging to comprehension when reading hypertext, but it does mean that the words we choose to hyperlink become very important to comprehension for those skim reading text on the Web.},
	urldate = {2015-12-06TZ},
	booktitle = {Proceedings of the 2014 {ACM} {Conference} on {Web} {Science}},
	publisher = {ACM},
	author = {Fitzsimmons, Gemma and Weal, Mark J. and Drieghe, Denis},
	year = {2014},
	keywords = {Eye movements, Psychology, Reading, human computer interaction, hyperlinks, skim reading, web science},
	pages = {211--219}
}

@article{rubin_reading_1992,
	title = {Reading without saccadic eye movements},
	volume = {32},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/004269899290032E},
	doi = {10.1016/0042-6989(92)90032-E},
	abstract = {To assess the limitation on reading speed imposed by saccadic eye movements, we measured reading speed in 13 normally-sighted observers using two modes of text presentations: PAGE text which presents an entire passage conventionally in static, paragraph format, and rapid serial visual presentation (RSVP) which presents text sequentially, one word at a time at the same location in the visual field. In Expt 1, subjects read PAGE and RSVP text orally across a wide range of letter sizes (2X to 32X single-letter acuity) and reading speed was computed from the number of correct words read per minute. Reading speeds were consistently faster for RSVP compared to PAGE text at all letter sizes tested. The average speeds for text of an intermediate letter size (8X acuity) were 1171 words/min for RSVP and 303 words/min for PAGE text. In Expt 2 subjects read PAGE and RSVP text silently and a multiple-choice comprehension test was administered after each passage. All subjects continued to read RSVP text faster, and 6 subjects read at the maximum testable rate (1652 words/min) with at least 75\% correct on the comprehension tests. Experiment 3 assessed the minimum word exposure time required for decoding text using RSVP to minimize potential delays due to saccadic eye movement control. Successive words were presented for a fixed duration (word duration) with a blank interval (ISI) between words. The minimum word duration required for accurate oral reading averaged 69.4 msec and was not reduced by increasing ISI. We interpret these results as an indication that the programming and execution of saccadic eye movements impose an upper limit on conventional reading speed.},
	number = {5},
	urldate = {2015-12-06TZ},
	journal = {Vision Research},
	author = {Rubin, Gary S. and Turano, Kathleen},
	month = may,
	year = {1992},
	keywords = {Eye movements, Reading, Saccades},
	pages = {895--902}
}

@article{yang_saccade_2004,
	title = {Saccade generation during reading: {Are} words necessary?},
	volume = {16},
	issn = {0954-1446},
	shorttitle = {Saccade generation during reading},
	url = {http://dx.doi.org/10.1080/09541440340000231},
	doi = {10.1080/09541440340000231},
	abstract = {Most current theories of eye movement control during reading are word based in multiple ways: They assume that saccade onset times result from word‐based processes, and that words are involved in selecting a saccade target. In the current study the role of words was examined by occasionally replacing the text with one of five alternate stimulus patterns for a single fixation during reading, and observing the effects on the time, direction, and length of the saccade that ends that fixation. The onset times of many saccades are unaffected by replacing spaces with random letters, thus removing visible word‐units; also, the effects of this removal on saccade length is not different than that of having space‐delimited nonwords. It does not appear that words play a critical role in generating saccades. The results are compatible with the Competition/Interaction theory of eye movement control during reading (Yang \& McConkie, 2001).},
	number = {1-2},
	urldate = {2015-12-06TZ},
	journal = {European Journal of Cognitive Psychology},
	author = {Yang, S.-N. and McConkie, G. W.},
	month = jan,
	year = {2004},
	pages = {226--261}
}

@misc{noauthor_google_nodate,
	title = {Google},
	url = {https://www.google.com/},
	abstract = {41st Anniversary of the discovery of Lucy \#GoogleDoodle},
	urldate = {2015-11-24TZ}
}

@inproceedings{menon_machine_2013,
	title = {A {Machine} {Learning} {Framework} for {Programming} by {Example}},
	url = {http://machinelearning.wustl.edu/mlpapers/papers/ICML2013_menon13},
	urldate = {2015-11-20TZ},
	author = {Menon, Aditya and Tamuz, Omer and Gulwani, Sumit and Lampson, Butler and Kalai, Adam},
	year = {2013},
	pages = {187--195}
}

@article{amershi_liveaction:_2013,
	title = {{LiveAction}: {Automating} {Web} {Task} {Model} {Generation}},
	volume = {3},
	issn = {2160-6455},
	shorttitle = {{LiveAction}},
	url = {http://doi.acm.org/10.1145/2533670.2533672},
	doi = {10.1145/2533670.2533672},
	abstract = {Task automation systems promise to increase human productivity by assisting us with our mundane and difficult tasks. These systems often rely on people to (1) identify the tasks they want automated and (2) specify the procedural steps necessary to accomplish those tasks (i.e., to create task models). However, our interviews with users of a Web task automation system reveal that people find it difficult to identify tasks to automate and most do not even believe they perform repetitive tasks worthy of automation. Furthermore, even when automatable tasks are identified, the well-recognized difficulties of specifying task steps often prevent people from taking advantage of these automation systems. In this research, we analyze real Web usage data and find that people do in fact repeat behaviors on the Web and that automating these behaviors, regardless of their complexity, would reduce the overall number of actions people need to perform when completing their tasks, potentially saving time. Motivated by these findings, we developed LiveAction, a fully-automated approach to generating task models from Web usage data. LiveAction models can be used to populate the task model repositories required by many automation systems, helping us take advantage of automation in our everyday lives.},
	number = {3},
	urldate = {2015-10-30TZ},
	journal = {ACM Trans. Interact. Intell. Syst.},
	author = {Amershi, Saleema and Mahmud, Jalal and Nichols, Jeffrey and Lau, Tessa and Ruiz, German Attanasio},
	month = oct,
	year = {2013},
	keywords = {Task modeling and automation, Web repetition, Web usage mining, machine learning},
	pages = {14:1--14:23}
}

@article{lau_programming_2003,
	title = {Programming by {Demonstration} {Using} {Version} {Space} {Algebra}},
	volume = {53},
	issn = {0885-6125},
	url = {http://dx.doi.org/10.1023/A:1025671410623},
	doi = {10.1023/A:1025671410623},
	abstract = {Programming by demonstration enables users to easily personalize their applications, automating repetitive tasks simply by executing a few examples. We formalize programming by demonstration as a machine learning problem: given the changes in the application state that result from the user's demonstrated actions, learn the general program that maps from one application state to the next. We present a methodology for learning in this space of complex functions. First we extend version spaces to learn arbitrary functions, not just concepts. Then we introduce the version space algebra, a method for composing simpler version spaces to construct more complex spaces. Finally, we apply our version space algebra to the text-editing domain and describe an implemented system called SMARTedit that learns repetitive text-editing procedures by example. We evaluate our approach by measuring the number of examples required for the system to learn a procedure that works on the remainder of examples, and by an informal user study measuring the effort users spend using our system versus performing the task by hand. The results show that SMARTedit is capable of generalizing correctly from as few as one or two examples, and that users generally save a significant amount of effort when completing tasks with SMARTedit's help.},
	number = {1-2},
	urldate = {2015-10-25TZ},
	journal = {Mach. Learn.},
	author = {Lau, Tessa and Wolfman, Steven A. and Domingos, Pedro and Weld, Daniel S.},
	month = oct,
	year = {2003},
	keywords = {adaptive user interfaces, complex function learning, programming by demonstration, version spaces},
	pages = {111--156}
}

@inproceedings{de_m._penteado_detection_2006,
	address = {Berlin, Heidelberg},
	series = {{IBERAMIA}-{SBIA}'06},
	title = {Detection of {Repetitive} {Patterns} in {Action} {Sequences} with {Noise} in {Programming} by {Demonstration}},
	isbn = {3-540-45462-4, 978-3-540-45462-5},
	url = {http://dx.doi.org/10.1007/11874850_42},
	doi = {10.1007/11874850_42},
	abstract = {Software applications that exploit implicit programming by demonstration should be able to detect repetitive patterns in user’s actions in an autonomous and efficient way. We present a software agent for the detection of repetitive action patterns that makes use of domain knowledge in this process. We explain its design rationale and discuss some of its advantages, by comparing it with the classic algorithm KRM, which does not make use of domain knowledge. We demonstrate that our agent might have a more efficient detection process for repetitive tasks since it activates the search algorithm fewer times. Moreover, we show that it can detect repetitive tasks even in the presence of noise in the action sequence.},
	urldate = {2015-10-25TZ},
	booktitle = {Proceedings of the 2Nd {International} {Joint} {Conference}, and {Proceedings} of the 10th {Ibero}-{American} {Conference} on {AI} 18th {Brazilian} {Conference} on {Advances} in {Artificial} {Intelligence}},
	publisher = {Springer-Verlag},
	author = {de M. Penteado, Raqueline R. and Da Silva, Sérgio R. P. and Furuta, H. and de S. Godoi, Muriel},
	year = {2006},
	pages = {380--389}
}

@inproceedings{myers_demonstrational_1991,
	address = {New York, NY, USA},
	series = {{CHI} '91},
	title = {Demonstrational {Interfaces}: {Coming} {Soon}?},
	isbn = {0-89791-383-3},
	shorttitle = {Demonstrational {Interfaces}},
	url = {http://doi.acm.org/10.1145/108844.108966},
	doi = {10.1145/108844.108966},
	urldate = {2015-10-19TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Myers, Brad A. and Cypher, Allen and Maulsby, David and Smith, David C. and Shneiderman, Ben},
	year = {1991},
	pages = {393--396}
}

@article{myers_programming_2000,
	title = {Programming by {Example}: {Intelligence} in {Demonstrational} {Interfaces}},
	volume = {43},
	issn = {0001-0782},
	shorttitle = {Programming by {Example}},
	url = {http://doi.acm.org/10.1145/330534.330545},
	doi = {10.1145/330534.330545},
	number = {3},
	urldate = {2015-10-19TZ},
	journal = {Commun. ACM},
	author = {Myers, Brad A. and McDaniel, Richard and Wolber, David},
	month = mar,
	year = {2000},
	pages = {82--89}
}

@incollection{myers_your_2001,
	address = {San Francisco, CA, USA},
	title = {Your {Wish} is {My} {Command}},
	isbn = {1-55860-688-2},
	url = {http://dl.acm.org/citation.cfm?id=369505.369510},
	urldate = {2015-10-19TZ},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Myers, Brad A. and McDaniel, Richard},
	year = {2001},
	pages = {45--60}
}

@article{myers_demonstrational_1992,
	title = {Demonstrational {Interfaces}: {A} {Step} {Beyond} {Direct} {Manipulation}},
	volume = {25},
	issn = {0018-9162},
	shorttitle = {Demonstrational {Interfaces}},
	url = {http://dx.doi.org/10.1109/2.153286},
	doi = {10.1109/2.153286},
	abstract = {Demonstrational interfaces, interfaces that let the user perform actions on concrete example objects while constructing an abstract program, thus letting the user create parameterized procedures and objects without learning a programming language, are discussed. The motivations for and problems associated with demonstrational interfaces are presented. A survey of the various types of interfaces is also presented. Areas that would benefit from demonstrational technology, including general-purpose programming, visualization, macros for direct-manipulation interfaces, drawing packages, text editing and formatting, and user interface development environments, are discussed. Research issues involving demonstrational interfaces are reviewed.},
	number = {8},
	urldate = {2015-10-19TZ},
	journal = {Computer},
	author = {Myers, Brad A.},
	month = aug,
	year = {1992},
	pages = {61--73}
}

@inproceedings{waldner_importance-driven_2011,
	address = {New York, NY, USA},
	series = {{CHI} '11},
	title = {Importance-driven {Compositing} {Window} {Management}},
	isbn = {978-1-4503-0228-9},
	url = {http://doi.acm.org/10.1145/1978942.1979085},
	doi = {10.1145/1978942.1979085},
	abstract = {In this paper we present importance-driven compositing window management, which considers windows not only as basic rectangular shapes but also integrates the importance of the windows' content using a bottom-up visual attention model. Based on this information, importance-driven compositing optimizes the spatial window layout for maximum visibility and interactivity of occluded content in combination with see-through windows. We employ this technique for emerging window manager functions to minimize information overlap caused by popping up windows or floating toolbars and to improve the access to occluded window content. An initial user study indicates that our technique provides a more effective and satisfactory access to occluded information than the well-adopted Alt+Tab window switching technique and see-through windows without optimized spatial layout.},
	urldate = {2015-10-18TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Waldner, Manuela and Steinberger, Markus and Grasset, Raphael and Schmalstieg, Dieter},
	year = {2011},
	keywords = {compositing window management, space management, transparency, visual saliency},
	pages = {959--968}
}

@inproceedings{hutchings_consistency_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {Consistency, {Multiple} {Monitors}, and {Multiple} {Windows}},
	isbn = {978-1-59593-593-9},
	url = {http://doi.acm.org/10.1145/1240624.1240658},
	doi = {10.1145/1240624.1240658},
	abstract = {We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24\% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management.},
	urldate = {2015-10-18TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Hutchings, Dugald Ralph and Stasko, John},
	year = {2007},
	keywords = {Consistency, multiple monitors, window management},
	pages = {211--214}
}

@inproceedings{chapuis_copy-and-paste_2007,
	address = {New York, NY, USA},
	series = {{CHI} '07},
	title = {Copy-and-paste {Between} {Overlapping} {Windows}},
	isbn = {978-1-59593-593-9},
	url = {http://doi.acm.org/10.1145/1240624.1240657},
	doi = {10.1145/1240624.1240657},
	abstract = {Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.},
	urldate = {2015-10-18TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Chapuis, Olivier and Roussel, Nicolas},
	year = {2007},
	keywords = {copy-and-paste, overlapping windows, window management},
	pages = {201--210}
}

@inproceedings{xu_push-and-pull_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {Push-and-pull {Switching}: {Window} {Switching} {Based} on {Window} {Overlapping}},
	isbn = {978-1-60558-929-9},
	shorttitle = {Push-and-pull {Switching}},
	url = {http://doi.acm.org/10.1145/1753326.1753526},
	doi = {10.1145/1753326.1753526},
	abstract = {We propose Push-and-Pull Switching, a window switching technique using window overlapping to implicitly define groups. Push-and-Pull Switching enables switching between groups and restacking the focused window to any position to change its group membership. The technique was evaluated in an experiment which found that Push-and-Pull Switching improves switching performance by more than 50\% compared to other switching techniques in different scenarios. A longitudinal user study indicates that participants invoked this switching technique 15\% of the time on single monitor displays and that they found it easy to understand and use.},
	urldate = {2015-10-18TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Quan and Casiez, Géry},
	year = {2010},
	keywords = {overlapping, window management, window switching},
	pages = {1335--1338}
}

@inproceedings{zhao_autocompaste:_2012,
	address = {New York, NY, USA},
	series = {{AVI} '12},
	title = {{AutoComPaste}: {Auto}-completing {Text} {As} an {Alternative} to {Copy}-paste},
	isbn = {978-1-4503-1287-5},
	shorttitle = {{AutoComPaste}},
	url = {http://doi.acm.org/10.1145/2254556.2254626},
	doi = {10.1145/2254556.2254626},
	abstract = {The copy-paste command is a fundamental and widely used operation in daily computing. It is generally regarded as a simple task but the process can become tedious when frequent window switching is required to copy-paste across different documents. Auto-completion is another popular operation aimed at reducing users' typing effort. It contrasts to copy-paste by allowing for text completion without switching windows. However, the available content for completion is predefined. We introduce AutoComPaste, an enhanced autocompletion technique for cross-document copy-paste. AutoComPaste allows users to copy-paste different granularity of text from all opened documents without window switching. Our theoretical analysis and empirical study show that AutoComPaste nicely complements traditional copy-paste techniques and outperforms the traditional copy-paste techniques when users have knowledge of the content to be copied.},
	urldate = {2015-10-18TZ},
	booktitle = {Proceedings of the {International} {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {ACM},
	author = {Zhao, Shengdong and Chevalier, Fanny and Ooi, Wei Tsang and Lee, Chee Yuan and Agarwal, Arpit},
	year = {2012},
	keywords = {autocompletion, copy-paste, windows management},
	pages = {365--372}
}

@inproceedings{jesdabodi_understanding_2015,
	address = {New York, NY, USA},
	series = {{UbiComp} '15},
	title = {Understanding {Usage} {States} on {Mobile} {Devices}},
	isbn = {978-1-4503-3574-4},
	url = {http://doi.acm.org/10.1145/2750858.2805837},
	doi = {10.1145/2750858.2805837},
	abstract = {Nowadays, mobile apps are used for nearly every situation: for planning the day, communicating with colleagues, ordering goods, or entertaining and socializing. To understand users expectations in each situation and to provide context-aware services, researchers and app vendors started to capture users' interaction with the smartphone and to model user's behavior. This paper reports on a behavioral study based on app usage data logged over one year and the corresponding apps descriptions from the app store. Using Topic Modeling and clustering techniques, we segmented the usage data into meaningful clusters that correspond to different "states", in which users normally use their smartphone, e.g. socializing or consuming media. Researchers and app-vendors can use the insights from our work to improve their contextual recommendation techniques and the overall usage experience.},
	urldate = {2015-10-18TZ},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Jesdabodi, Chakajkla and Maalej, Walid},
	year = {2015},
	keywords = {apps, behavioral profiles, intent identification, usage data},
	pages = {1221--1225}
}

@inproceedings{li_consensus:_2016,
	title = {{ConsensUs}: {Real}-{Time} {Groupware} for {Highlighting} and {Facilitating} {Conflict} {Resolution} on {Comparative} {Decisions}},
	booktitle = {In {Submission} to {CHI} 2016},
	author = {Li, Toby Jia-Jun and Yang, Ming and Mu, Qiaochu and Dow, Steven},
	year = {2016}
}

@inproceedings{li_atlasify_2015,
	address = {Minneapolis, MN},
	title = {Atlasify - {The} {Geography} of {Everything}},
	booktitle = {The {Social} {Media} and {Business} {Analytics} {Collaborative} ({SOBACO}) {Spring} {Research} {Symposium}},
	author = {Li, Toby Jia-Jun and Ford, Joshua and Downey, Doug and Hecht, Brent and Murganoor, Vijay and Sen, Shilad},
	year = {2015}
}

@article{li_using_2015,
	title = {Using {Natural} {Language} {Processing} to {Shed} {New} {Insight} on {Tobler}’s {First} {Law}},
	journal = {In Submission to ACM Transactions on Spatial Algorithms and Systems (TSAS)},
	author = {Li, Toby Jia-Jun and Sen, Shilad and Hecht, Brent},
	year = {2015}
}

@inproceedings{johnson_not_2016,
	title = {Not at {Home} on the {Range}: {Peer} {Production} and the {Urban}/{Rural} {Divide}},
	booktitle = {In {Submission} to {CHI} 2016},
	author = {Johnson, Isaac and Lin, Yilun and Li, Toby Jia-Jun and Hall, Andrew and Halfaker, Aaron and Schöning, Johannes and Hecht, Brent},
	year = {2016}
}

@inproceedings{sen_wikibrain:_2014,
	title = {{WikiBrain}: {Democratizing} computation on {Wikipedia}},
	shorttitle = {{WikiBrain}},
	urldate = {2014-09-15TZ},
	booktitle = {Proceedings of the 10th {International} {Symposium} on {Open} {Collaboration} ({WikiSym} + {OpenSym} 2014)},
	publisher = {ACM},
	author = {Sen, Shilad and Li, Toby Jia-Jun and WikiBrain Team and Hecht, Brent},
	year = {2014}
}

@article{myers_demonstrational_1992-1,
	title = {Demonstrational interfaces: {A} step beyond direct manipulation},
	volume = {25},
	issn = {0018-9162},
	shorttitle = {Demonstrational interfaces},
	doi = {10.1109/2.153286},
	abstract = {Demonstrational interfaces, interfaces that let the user perform actions on concrete example objects while constructing an abstract program, thus letting the user create parameterized procedures and objects without learning a programming language, are discussed. The motivations for and problems associated with demonstrational interfaces are presented. A survey of the various types of interfaces is also presented. Areas that would benefit from demonstrational technology, including general-purpose programming, visualization, macros for direct-manipulation interfaces, drawing packages, text editing and formatting, and user interface development environments, are discussed. Research issues involving demonstrational interfaces are reviewed.{\textless}{\textgreater}},
	number = {8},
	journal = {Computer},
	author = {Myers, B.A.},
	month = aug,
	year = {1992},
	keywords = {Artificial intelligence, Computer interfaces, Feedback, Heuristic algorithms, Human factors, Inference algorithms, Pattern recognition, Research and development, Uncertainty, User interfaces, abstract program, concrete example objects, demonstrational interfaces, direct manipulation, drawing packages, formatting, general-purpose programming, macros, parameterized procedures, text editing, user interface development environments, user interfaces, visualization},
	pages = {61--73}
}
@inproceedings{lu_mining_2014,
	title = {Mining mobile application sequential patterns for usage prediction},
	doi = {10.1109/GRC.2014.6982832},
	abstract = {In recent years, researches on smart phone services have received a lot of attention in both of the industry and academia due to a wide range of potential applications. Among them, one of popular topics is the mining and prediction of mobile application usage behaviors. In this paper, we propose a location-based approach to predict the mobile application usage behaviors. In this approach, we first discover the stay locations of the GPS movement data to obtain the mobile application usage database. Then, we consider both of the physical location moving paths and virtual application usage paths of users to mine the Mobile Application Sequential Patterns (MASPs) by the Mobile Application Sequential Pattern Mine (MASP-Mine) algorithm. Furthermore, a prediction strategy is designed to predict the next mobile application usage behaviors based on the MASPs. To our best knowledge, this is the first work on mining and prediction of mobile application usage behaviors with considerations of physical location moving paths and virtual application usage paths simultaneously. Through experimental evaluation under various condition settings by a real mobile application usage data, the proposed approach is shown to deliver excellent performance in terms of precision and recall.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Granular} {Computing} ({GrC})},
	author = {Lu, E.H.-C. and Lin, Yi-Wei and Ciou, Jing-Bin},
	month = oct,
	year = {2014},
	keywords = {Algorithm design and analysis, Databases, GPS movement data, Global Positioning System, MASP-Mine algorithm, Mobile Application, Mobile communication, Prediction algorithms, data mining, location-based approach, mobile application sequential pattern mine algorithm, mobile computing, pattern mining, physical location moving paths, prediction strategy, smart phone services, smart phones, usage prediction, virtual application usage paths},
	pages = {185--190}
}

@article{hartmann_challenges_2009,
	title = {Challenges in developing user-adaptive intelligent user interfaces},
	volume = {9},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.158.7264&rep=rep1&type=pdf},
	urldate = {2015-10-09TZ},
	journal = {Proc. LWA},
	author = {Hartmann, Melanie},
	year = {2009}
}

@misc{hijmans_global_2009,
	title = {Global {Administrative} {Areas}},
	url = {http://www.gadm.org},
	urldate = {2014-07-01TZ},
	journal = {Global Administrative Areas {\textbar} Boundaries without limits},
	author = {Hijmans, Robert},
	year = {2009}
}

@misc{the_minnesota_population_center_large-scale_2015,
	title = {Large-{Scale} {Demographic} {Data} {Infrastructure}},
	url = {https://www.pop.umn.edu/index.php?q=research/research-themes/large-scale-demog-infrastructure},
	author = {The Minnesota Population Center},
	year = {2015}
}

@article{li_wikibrain:_2014,
	title = {{WikiBrain}: {Making} {Computer} {Programs} {Smarter} with {Knowledge} from {Wikipedia}},
	shorttitle = {{WikiBrain}},
	author = {Li, Toby Jia-Jun and Hecht, Brent},
	year = {2014}
}

@article{goodchild_validity_2004,
	title = {The {Validity} and {Usefulness} of {Laws} in {Geographic} {Information} {Science} and {Geography}},
	volume = {94},
	issn = {1467-8306},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8306.2004.09402008.x/abstract},
	doi = {10.1111/j.1467-8306.2004.09402008.x},
	language = {en},
	number = {2},
	urldate = {2015-04-30TZ},
	journal = {Annals of the Association of American Geographers},
	author = {Goodchild, Michael F.},
	month = jun,
	year = {2004},
	pages = {300--303}
}

@inproceedings{miranda_impact_1993,
	title = {The impact of group support systems on group conflict and conflict management: an empirical investigation},
	volume = {iv},
	shorttitle = {The impact of group support systems on group conflict and conflict management},
	doi = {10.1109/HICSS.1993.284170},
	abstract = {The authors report on a study of the impact of group support systems (GSS) use on groups over the duration of five sessions spaced a week apart. The issue of primary interest in the study was the impact of GSS use on the nature of group conflict and conflict management. Twenty-five groups participated in the study. The first session was a training session. The four subsequent sessions were decision-making sessions, requiring a consensus decision from each group. Subjects reported on the nature of group conflict, conflict management strategies used, and their perceptions on the productivity of conflict. Groups in the GSS-support condition experienced more issue-based conflict in two decision-making sessions than the control groups, and less in the other other two sessions. Overall, GSS-supported groups reported significantly less interpersonal conflict than did control groups},
	booktitle = {Proceeding of the {Twenty}-{Sixth} {Hawaii} {International} {Conference} on {System} {Sciences}, 1993},
	author = {Miranda, S.M. and Bostrom, R.P.},
	month = jan,
	year = {1993},
	keywords = {Collaborative software, Human factors, Information processing, Laboratories, Management training, Power system management, Resource management, Stress, Technology management, Tellurium, conflict management, consensus decision, decision making, decision-making sessions, group conflict, group support systems, groupware, interpersonal conflict, management, training session},
	pages = {83--94 vol.4}
}

@inproceedings{menking_heart_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {The {Heart} {Work} of {Wikipedia}: {Gendered}, {Emotional} {Labor} in the {World}'s {Largest} {Online} {Encyclopedia}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {The {Heart} {Work} of {Wikipedia}},
	url = {http://doi.acm.org/10.1145/2702123.2702514},
	doi = {10.1145/2702123.2702514},
	abstract = {This note explores the issue of women's participation in Wikipedia through the lens of emotional labor. Using a grounded theory approach, we detail the kinds of tasks women Wikipedians choose to do and explore why they choose the work they do. We also explore the emotional costs of their labor and their strategies for coping. Our analysis of 20 interviews leads us to posit that the gendered and emotional labor required of many women to participate in Wikipedia's production renders it, problematically, a space of conflicting public and private spheres, motivated by antithetical open and closed values. In addition to other contributions, we believe this insight sheds light on some of the complex dynamics behind Wikipedia's observed gender gap.},
	urldate = {2015-10-01TZ},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Menking, Amanda and Erickson, Ingrid},
	year = {2015},
	keywords = {Wikipedia, emotional labor, gender gap, women},
	pages = {207--210}
}

@article{dubrovsky_equalization_1991,
	title = {The {Equalization} {Phenomenon}: {Status} {Effects} in {Computer}-{Mediated} and {Face}-to-{Face} {Decision}-{Making} {Groups}},
	volume = {6},
	issn = {0737-0024},
	shorttitle = {The {Equalization} {Phenomenon}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327051hci0602_2},
	doi = {10.1207/s15327051hci0602_2},
	abstract = {New computer-based communications technologies make possible new or expanded forms of group work. Although earlier researchers suggest that scant social information in these technologies might cause status equalization in groups, no experimental test of this phenomenon has been made. In a laboratory experiment, we compared face-to-face communication with electronic mail in decision-making groups whose members differed in social status. We examined status in two ways: by varying the external status of group members, and by varying the decision task to manipulate expertise. When the groups made decisions in face-to-face meetings, the high-status member dominated discussions with the three low-status members. Also, the high-status member more often was a "first advocate" in the face-to-face discussions, and first advocates were more influential than later advocates. These status inequalities in face-to-face decision making were pronounced just when the high-status member's expertise was relevant to the decision task. When the same groups made comparable decisions using electronic mail, status and expertise inequalities in participation were reduced. A striking and unexpected result was that "first" advocacy was shared by high- and low-status members in discussions using electronic mail. This behavior resulted in increased equality of influence across status and expertise. We discuss the implications of these results for research and for design of new communication technologies.},
	number = {2},
	urldate = {2015-09-18TZ},
	journal = {Human–Computer Interaction},
	author = {Dubrovsky, Vitaly J. and Kiesler, Sara and Sethna, Beheruz N.},
	month = jun,
	year = {1991},
	pages = {119--146}
}

@article{liesaputra_realistic_2012,
	title = {Realistic electronic books},
	volume = {70},
	issn = {1071-5819},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581912000316},
	doi = {10.1016/j.ijhcs.2012.02.003},
	abstract = {We describe a software book model that emulates a range of properties associated with physical books—analog page turning, visual location cues, bookmarks and annotations—and, furthermore, incorporates many advantages of digital environments—hyperlinks, multimedia, full-text search, automatic identification of synonyms, cross-referencing of key terms with an online encyclopedia, and an automatically generated back-of-the-book index. Usability studies were conducted to compare performance using these books for various reading tasks with HTML, PDF and physical books. Participants completed the tasks more efficiently with the new interface without any loss in accuracy; they also preferred it.},
	number = {9},
	urldate = {2015-04-29TZ},
	journal = {International Journal of Human-Computer Studies},
	author = {Liesaputra, Veronica and Witten, Ian H.},
	month = sep,
	year = {2012},
	keywords = {Electronic book, Usability studies, Wikipedia, Within-document navigation, Within-document search},
	pages = {588--610}
}

@article{kittur_power_2007,
	title = {Power of the few vs. wisdom of the crowd: {Wikipedia} and the rise of the bourgeoisie},
	volume = {1},
	shorttitle = {Power of the few vs. wisdom of the crowd},
	url = {http://edouard-lopez.com/fac/ICPS%20-%20S7/Complexit%C3%A9/2008-Wikipedia-As-A-Complex-System/Power%20of%20the%20Few%20vs.%20Wisdom%20of%20the%20Crowd:%20Wikipedia%20and%20the%20Rise%20of%20the%20Bourgeoisie.pdf},
	number = {2},
	urldate = {2014-06-13TZ},
	journal = {World wide web},
	author = {Kittur, Aniket and Chi, Ed and Pendleton, Bryan A. and Suh, Bongwon and Mytkowicz, Todd},
	year = {2007},
	pages = {19}
}

@book{alker_mathematics_1965,
	title = {Mathematics and politics},
	publisher = {Macmillan},
	author = {Alker, Hayward R.},
	year = {1965}
}

@inproceedings{wagner_its_2015,
	title = {It's a {Man}'s {Wikipedia}? {Assessing} {Gender} {Inequality} in an {Online} {Encyclopedia}},
	copyright = {Authors who publish a paper in this conference agree to the following terms:    1. Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.    2. The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.    3. The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys’ fees incurred therein.    4. Author(s) retain all proprietary rights other than copyright (such as patent rights).    5. Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.    6. Author(s) may reproduce, or have reproduced, their article/paper for the author’s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author’s employer, and then only on the author’s or the employer’s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author’s or the employer’s creation (including tables of contents with links to other papers) without AAAI’s written permission.    7. Author(s) may make limited distribution of all or portions of their article/paper prior to publication.    8. In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.    9. In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
	shorttitle = {It's a {Man}'s {Wikipedia}?},
	url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/view/10585},
	abstract = {Wikipedia is a community-created encyclopedia that contains information about notable people from different countries, epochs and disciplines and aims to document the world's knowledge from a neutral point of view. However, the narrow diversity of the Wikipedia editor community has the potential to introduce systemic biases such as gender biases into the content of Wikipedia. In this paper we aim to tackle a sub problem of this larger challenge by presenting and applying a computational method for assessing gender bias on Wikipedia along multiple dimensions. We find that while women on Wikipedia are covered and featured well in many Wikipedia language editions, the way women are portrayed starkly differs from the way men are portrayed. We hope our work contributes to increasing awareness about gender biases online, and in particular to raising attention to the different levels in which gender biases can manifest themselves on the web.},
	language = {en},
	urldate = {2015-10-01TZ},
	booktitle = {Ninth {International} {AAAI} {Conference} on {Web} and {Social} {Media}},
	author = {Wagner, Claudia and Garcia, David and Jadidi, Mohsen and Strohmaier, Markus},
	month = apr,
	year = {2015}
}

@inproceedings{lam_wp:clubhouse?:_2011,
	address = {New York, NY, USA},
	series = {{WikiSym} '11},
	title = {{WP}:{Clubhouse}?: {An} {Exploration} of {Wikipedia}'s {Gender} {Imbalance}},
	isbn = {978-1-4503-0909-7},
	shorttitle = {{WP}},
	url = {http://doi.acm.org/10.1145/2038558.2038560},
	doi = {10.1145/2038558.2038560},
	abstract = {Wikipedia has rapidly become an invaluable destination for millions of information-seeking users. However, media reports suggest an important challenge: only a small fraction of Wikipedia's legion of volunteer editors are female. In the current work, we present a scientific exploration of the gender imbalance in the English Wikipedia's population of editors. We look at the nature of the imbalance itself, its effects on the quality of the encyclopedia, and several conflict-related factors that may be contributing to the gender gap. Our findings confirm the presence of a large gender gap among editors and a corresponding gender-oriented disparity in the content of Wikipedia's articles. Further, we find evidence hinting at a culture that may be resistant to female participation.},
	urldate = {2015-10-01TZ},
	booktitle = {Proceedings of the 7th {International} {Symposium} on {Wikis} and {Open} {Collaboration}},
	publisher = {ACM},
	author = {Lam, Shyong (Tony) K. and Uduwage, Anuradha and Dong, Zhenhua and Sen, Shilad and Musicant, David R. and Terveen, Loren and Riedl, John},
	year = {2011},
	keywords = {Wikipedia, collaboration, content coverage, gender gap},
	pages = {1--10}
}

@article{li_spatial_2013,
	title = {Spatial, temporal, and socioeconomic patterns in the use of {Twitter} and {Flickr}},
	volume = {40},
	issn = {1523-0406},
	url = {http://dx.doi.org/10.1080/15230406.2013.777139},
	doi = {10.1080/15230406.2013.777139},
	abstract = {Online social networking and information sharing services have generated large volumes of spatio-temporal footprints, which are potentially a valuable source of knowledge about the physical environment and social phenomena. However, it is critical to take into consideration the uneven distribution of the data generated in social media in order to understand the nature of such data and to use them appropriately. The distribution of footprints and the characteristics of contributors indicate the quantity, quality, and type of the data. Using georeferenced tweets and photos collected from Twitter and Flickr, this research presents the spatial and temporal patterns of such crowd-sourced geographic data in the contiguous United States and explores the socioeconomic characteristics of geographic data creators by investigating the relationships between tweet and photo densities and the characteristics of local people using California as a case study. Correlations between dependent and independent variables in partial least squares regression suggest that well-educated people in the occupations of management, business, science, and arts are more likely to be involved in the generation of georeferenced tweets and photos. Further research is required to explain why some people tend to produce and spread information over the Internet using social media from the perspectives of psychology and sociology. This study would be informative to sociologists who study the behaviors of social media users, geographers who are interested in the spatial and temporal distribution of social media users, marketing agencies who intend to understand the influence of social media, and other scientists who use social media data in their research.},
	number = {2},
	urldate = {2015-10-01TZ},
	journal = {Cartography and Geographic Information Science},
	author = {Li, Linna and Goodchild, Michael F. and Xu, Bo},
	month = mar,
	year = {2013},
	pages = {61--77}
}

@inproceedings{carrascal_-situ_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {An {In}-{Situ} {Study} of {Mobile} {App} \& {Mobile} {Search} {Interactions}},
	isbn = {978-1-4503-3145-6},
	url = {http://doi.acm.org/10.1145/2702123.2702486},
	doi = {10.1145/2702123.2702486},
	abstract = {When trying to satisfy an information need, smartphone users frequently transition from mobile search engines to mobile apps and vice versa. However, little is known about the nature of these transitions nor how mobile search and mobile apps interact. We report on a 2-week, mixed-method study involving 18 Android users, where we collected real-world mobile search and mobile app usage data alongside subjective insights on why certain interactions between apps and mobile search occur. Our results show that when people engage with mobile search they tend to interact with more mobile apps and for longer durations. We found that certain categories of apps are used more intensely alongside mobile search. Furthermore we found differences in app usage before and after mobile search and show how mobile app interactions can both prompt mobile search and enable users to take action. We conclude with a discussion on what these patterns mean for mobile search and how we might design mobile search experiences that take these app interactions into account.},
	urldate = {2015-09-28TZ},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Carrascal, Juan Pablo and Church, Karen},
	year = {2015},
	keywords = {mobile apps, mobile search, user study},
	pages = {2739--2748}
}

@book{tzeng_multiple_2011,
	title = {Multiple attribute decision making: methods and applications},
	shorttitle = {Multiple attribute decision making},
	urldate = {2015-09-01TZ},
	publisher = {CRC press},
	author = {Tzeng, Gwo-Hshiung and Huang, Jih-Jeng},
	year = {2011}
}

@misc{noauthor_multiple_nodate,
	title = {Multiple {Attribute} {Decision} {Making}: {Methods} and {Applications}},
	shorttitle = {Multiple {Attribute} {Decision} {Making}},
	url = {https://www.crcpress.com/Multiple-Attribute-Decision-Making-Methods-and-Applications/Tzeng-Huang/9781439861578},
	abstract = {Decision makers are often faced with several conflicting alternatives. How do they evaluate trade-offs when there are more than three criteria? To help people make optimal decisions, scholars in the discipline of multiple criteria decision making (MCDM) continue to develop new methods for structurin},
	urldate = {2015-09-25TZ},
	journal = {CRC Press}
}

@article{krosnick_evaluation_1987,
	title = {An evaluation of a cognitive theory of response-order effects in survey measurement},
	volume = {51},
	url = {http://poq.oxfordjournals.org/content/51/2/201.short},
	number = {2},
	urldate = {2015-09-25TZ},
	journal = {Public Opinion Quarterly},
	author = {Krosnick, Jon A. and Alwin, Duane F.},
	year = {1987},
	pages = {201--219}
}

@article{munson_developing_1979,
	title = {Developing {Practical} {Procedures} for the {Measurement} of {Personal} {Values} in {Cross}-{Cultural} {Marketing}},
	volume = {16},
	copyright = {Copyright © 1979 American Marketing Association},
	issn = {0022-2437},
	url = {http://www.jstor.org/stable/3150873},
	doi = {10.2307/3150873},
	abstract = {This research investigates a particular value-assessing instrument, the Rokeach Value Survey (RVS), for its applicability to cross-cultural marketing. The study establishes that in measuring values a Likert type of scaling approach is not significantly less reliable than the more cumbersome ranking approach used by psychologists. Scaling also may be better suited to marketing applications. A "multiprofile-multimethod" matrix analysis suggests that the Rokeach "terminal" and "instrumental" profiles are reliable and distinctive.},
	number = {1},
	urldate = {2015-09-25TZ},
	journal = {Journal of Marketing Research},
	author = {Munson, J. Michael and McIntyre, Shelby H.},
	month = feb,
	year = {1979},
	pages = {48--52}
}

@article{munson_developing_1979-1,
	title = {Developing {Practical} {Procedures} for the {Measurement} of {Personal} {Values} in {Cross}-{Cultural} {Marketing}},
	volume = {16},
	copyright = {Copyright © 1979 American Marketing Association},
	issn = {0022-2437},
	url = {http://www.jstor.org/stable/3150873},
	doi = {10.2307/3150873},
	abstract = {This research investigates a particular value-assessing instrument, the Rokeach Value Survey (RVS), for its applicability to cross-cultural marketing. The study establishes that in measuring values a Likert type of scaling approach is not significantly less reliable than the more cumbersome ranking approach used by psychologists. Scaling also may be better suited to marketing applications. A "multiprofile-multimethod" matrix analysis suggests that the Rokeach "terminal" and "instrumental" profiles are reliable and distinctive.},
	number = {1},
	urldate = {2015-09-25TZ},
	journal = {Journal of Marketing Research},
	author = {Munson, J. Michael and McIntyre, Shelby H.},
	month = feb,
	year = {1979},
	pages = {48--52}
}

@inproceedings{poole_conflict_1988,
	address = {New York, NY, USA},
	series = {{CSCW} '88},
	title = {Conflict {Management} and {Group} {Decision} {Support} {Systems}},
	isbn = {0-89791-282-9},
	url = {http://doi.acm.org/10.1145/62266.62284},
	doi = {10.1145/62266.62284},
	abstract = {Computers promise to change collaborative work in profound ways. They are likely to have special impact on processes which require fine judgments, foresight, and handling of large amounts of information, such as decision-making and strategic planning. Several authors (Huber, 1984; Kraemer and King, 1986) have discussed the potential benefits of decision support systems for organizational decision-making.
Group decision support systems (GDSSs) combine communication, computer, and decision support technologies to support problem formulation and solution in group meetings. Communication technologies include electronic messaging, local and wide-area networks, teleconferencing, and store-and-forward facilities. Computer technologies include multi-user operating systems, fourth generation languages, databases, data analysis facilities, and data storage and modification capabilities. Decision support technologies include agenda-setting decision modelling methods (such as decision trees, risk analysis forecasting methods, and multiattribute utility functions), structured group methods (e.g., Nominal Group and Delphi Techniques), and rules for directing group discussion. DeSanctis and Gallupe (1987) have distinguished two levels of GDSS. A level 1 GDSS provides features to eliminate communication barriers, such as large screens for display of ideas, voting solicitation, and anonymous input of ideas and preferences. A level 2 GDSS provides problem-structuring techniques, such as automated planning tools, modelling packages, and information libraries. Level 2 thus represents an enhanced GDSS, as opposed to Level 1, which is a communication medium only.
GDSSs can be tailored to tackle critical situations decision-makers face. One of the most ubiquitous and potentially troublesome situations is interpersonal conflict. Several features of GDSSs can play a key role in conflict management, including methods for the identification of conflict, structured agendas that guide the group through discussion of the conflict, utilities for clarifying the nature of the problem and for generating alternative solutions, and structures that promote members' participation. A few GDSSs have been specifically designed to manage conflicts (e.g., Sainfort, Gustafson, and Bosworth, 1987). However, these tend to be concerned with specific problem types, such as family conflict, and are not well-adapted for dealing with general conflicts.
In this article we will focus on how a nonspecialized multipurpose GDSS influences conflict management in groups. It is this type of GDSS that groups will most often use to deal with conflicts. Groups will not always have the time or inclination to switch into specialized conflict management routines, and what routines there are will rarely fit the specific problems groups face. Moreover, to assume a special routine is needed to deal with conflicts is to assume conflict is somehow distinct from group decision-making. On the contrary, we believe conflict is part and parcel of all collaborative work. So we will study how varying levels of conflict emerge and are handled within a GDSS.
The GDSS used for this search is a “generic”, level I system, version 1.0 of the University of Minnesota SAMM GDSS system (DeSanctis and Gallupe, 1987; Desanctis, Watson, and Sambamurthy, in press). The level 1 version of SAMM is designed to facilitate group communication and organize group interaction. It was purposely designed to embody a widely-used decision procedure, Dewey's Reflective Thinking Model, along with a few popular methods of deciding—rating, ranking, and voting. It purposely omits some of the more advanced features that could and would be incorporated in Level 2 systems (and are available in later versions of SAMM). This was done so we could compare work by groups using the GDSS with that of groups using manual versions of the same procedures.
In the next section we will first consider the effects GDSSs are likely to have on conflict management and advance several research questions and predictions. Following this we will describe a study designed to ascertain these effects.},
	urldate = {2015-09-25TZ},
	booktitle = {Proceedings of the 1988 {ACM} {Conference} on {Computer}-supported {Cooperative} {Work}},
	publisher = {ACM},
	author = {Poole, Marshall Scott and Homes, Michael and DeSanctis, Gerardine},
	year = {1988},
	pages = {227--243}
}

@article{sillars_coding_1982,
	title = {Coding verbal conflict tactics: {Nonverbal} and perceptual correlates of the “avoidance-distributive-integrative” distinction},
	volume = {9},
	shorttitle = {Coding verbal conflict tactics},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1468-2958.1982.tb00685.x/full},
	number = {1},
	urldate = {2015-09-24TZ},
	journal = {Human Communication Research},
	author = {Sillars, Alan L. and Coletti, Stephen F. and Parry, Doug and Rogers, Mark A.},
	year = {1982},
	pages = {83--95}
}

@article{sillars_sequential_1980,
	title = {The sequential and distributional structure of conflict interactions as a function of attributions concerning the locus of responsibility and stability of conflicts},
	volume = {4},
	journal = {Communication yearbook},
	author = {Sillars, Alan L. and Nimmo, Dan},
	year = {1980},
	pages = {217--235}
}

@article{miranda_impact_1993-1,
	title = {The impact of group support systems on group conflict and conflict management},
	url = {http://www.jstor.org/stable/40398068},
	urldate = {2015-09-24TZ},
	journal = {Journal of Management Information Systems},
	author = {Miranda, Shaila M. and Bostrom, Robert P.},
	year = {1993},
	pages = {63--95}
}

@book{janis_groupthink:_1982,
	title = {Groupthink: {Psychological} studies of policy decisions and fiascoes},
	shorttitle = {Groupthink},
	url = {http://www.nhmnc.info/wp-content/uploads/fbpdfs2014/Groupthink-Psychological-Studies-of-Policy-Decisions-and-Fiascoes-by-Irving-L-Janis-How-To-Unanimously-Make-Major-Mistakes.pdf},
	urldate = {2015-09-24TZ},
	publisher = {Houghton Mifflin Boston},
	author = {Janis, Irving Lester},
	year = {1982}
}

@article{de_dreu_productive_1997,
	title = {Productive conflict: {The} importance of conflict management and conflict issue},
	shorttitle = {Productive conflict},
	url = {https://books.google.com/books?hl=en&lr=&id=OzDFwuWH5BMC&oi=fnd&pg=PA9&dq=groupthink+conflict&ots=THEJB-YNrh&sig=S6r_5CZGGN8MPG__RKiRcfhIIN0},
	urldate = {2015-09-24TZ},
	journal = {Using conflict in organizations},
	author = {De Dreu, Carsten KW},
	year = {1997},
	pages = {9--22}
}

@article{driscoll_trust_1978,
	title = {Trust and {Participation} in {Organizational} {Decision} {Making} as {Predictors} of {Satisfaction}},
	volume = {21},
	issn = {0001-4273, 1948-0989},
	url = {http://amj.aom.org/content/21/1/44},
	doi = {10.2307/255661},
	abstract = {This study assesses the usefulness of trust and participation in decision making in predicting satisfaction among a college faculty. Organizational trust, a political assessment of hierarchical decision makers, best predicts overall satisfaction. The congruence between desired and perceived participation best predicts satisfaction with participation in decision making.},
	language = {en},
	number = {1},
	urldate = {2015-09-24TZ},
	journal = {Academy of Management Journal},
	author = {Driscoll, James W.},
	month = mar,
	year = {1978},
	keywords = {COLLEGE teachers, Group decision making, INDUSTRIAL psychology, JOB satisfaction, MANAGEMENT -- Employee participation, ORGANIZATIONAL behavior, STRATEGIC planning -- Employee participation, TRUST, UNIVERSITIES \& colleges -- Faculty, decision making},
	pages = {44--56}
}

@article{chun_examining_1998,
	title = {Examining the conflicting results of {GDSS} research},
	volume = {33},
	issn = {0378-7206},
	url = {http://www.sciencedirect.com/science/article/pii/S037872069800038X},
	doi = {10.1016/S0378-7206(98)00038-X},
	abstract = {The growing interest in group decision support systems (GDSS) was supported by, and gave rise to, a burgeoning academic literature on GDSS during the 1980s. However, GDSS research is now rare. One possible reason is the difference between field experience and many experimental studies. Another reason is that GDSS research over the past years mainly focused on decision rooms. The important question posed is: what are the reasons for the conflicting results of GDSS research? The contradictory findings among GDSS studies are indeed a problem if academic research is to be applied effectively in business settings. Now that group collaborative support is becoming more widespread, it is natural to wish to achieve a better understanding of the implications for organizations in their adoption of GDSS. Thus, this study systematically reviews existing GDSS studies and explores the probable reasons for inconsistent findings.},
	number = {6},
	urldate = {2015-09-24TZ},
	journal = {Information \& Management},
	author = {Chun, Ki Jeong and Park, Hung Kook},
	month = jun,
	year = {1998},
	keywords = {Computer-supported cooperative work, Decision room, GDSS experiments, Group decision support system (GDSS), group decision-making, group support systems},
	pages = {313--325}
}

@inproceedings{kriplean_integrating_2014,
	address = {New York, NY, USA},
	series = {{CSCW} '14},
	title = {Integrating {On}-demand {Fact}-checking with {Public} {Dialogue}},
	isbn = {978-1-4503-2540-0},
	url = {http://doi.acm.org/10.1145/2531602.2531677},
	doi = {10.1145/2531602.2531677},
	abstract = {Public dialogue plays a key role in democratic society. Such dialogue often contains factual claims, but participants and readers are left wondering what to believe, particularly when contributions to such dialogue come from a broad spectrum of the public. We explore the design space for introducing authoritative information into public dialogue, with the goal of supporting constructive rather than confrontational discourse. We also present a specific design and realization of an archetypal sociotechnical system of this kind, namely an on-demand fact-checking service integrated into a crowdsourced voters guide powered by deliberating citizens. The fact-checking service was co-designed with and staffed by professional librarians. Our evaluation examines the service from the perspectives of both users and librarians.},
	urldate = {2015-09-24TZ},
	booktitle = {Proceedings of the 17th {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} \& {Social} {Computing}},
	publisher = {ACM},
	author = {Kriplean, Travis and Bonnar, Caitlin and Borning, Alan and Kinney, Bo and Gill, Brian},
	year = {2014},
	keywords = {civic engagement, deliberation, fact-checking, libraries, value sensitive design},
	pages = {1188--1199}
}

@inproceedings{poole_conflict_1988-1,
	address = {New York, NY, USA},
	series = {{CSCW} '88},
	title = {Conflict {Management} and {Group} {Decision} {Support} {Systems}},
	isbn = {0-89791-282-9},
	url = {http://doi.acm.org/10.1145/62266.62284},
	doi = {10.1145/62266.62284},
	abstract = {Computers promise to change collaborative work in profound ways. They are likely to have special impact on processes which require fine judgments, foresight, and handling of large amounts of information, such as decision-making and strategic planning. Several authors (Huber, 1984; Kraemer and King, 1986) have discussed the potential benefits of decision support systems for organizational decision-making.
Group decision support systems (GDSSs) combine communication, computer, and decision support technologies to support problem formulation and solution in group meetings. Communication technologies include electronic messaging, local and wide-area networks, teleconferencing, and store-and-forward facilities. Computer technologies include multi-user operating systems, fourth generation languages, databases, data analysis facilities, and data storage and modification capabilities. Decision support technologies include agenda-setting decision modelling methods (such as decision trees, risk analysis forecasting methods, and multiattribute utility functions), structured group methods (e.g., Nominal Group and Delphi Techniques), and rules for directing group discussion. DeSanctis and Gallupe (1987) have distinguished two levels of GDSS. A level 1 GDSS provides features to eliminate communication barriers, such as large screens for display of ideas, voting solicitation, and anonymous input of ideas and preferences. A level 2 GDSS provides problem-structuring techniques, such as automated planning tools, modelling packages, and information libraries. Level 2 thus represents an enhanced GDSS, as opposed to Level 1, which is a communication medium only.
GDSSs can be tailored to tackle critical situations decision-makers face. One of the most ubiquitous and potentially troublesome situations is interpersonal conflict. Several features of GDSSs can play a key role in conflict management, including methods for the identification of conflict, structured agendas that guide the group through discussion of the conflict, utilities for clarifying the nature of the problem and for generating alternative solutions, and structures that promote members' participation. A few GDSSs have been specifically designed to manage conflicts (e.g., Sainfort, Gustafson, and Bosworth, 1987). However, these tend to be concerned with specific problem types, such as family conflict, and are not well-adapted for dealing with general conflicts.
In this article we will focus on how a nonspecialized multipurpose GDSS influences conflict management in groups. It is this type of GDSS that groups will most often use to deal with conflicts. Groups will not always have the time or inclination to switch into specialized conflict management routines, and what routines there are will rarely fit the specific problems groups face. Moreover, to assume a special routine is needed to deal with conflicts is to assume conflict is somehow distinct from group decision-making. On the contrary, we believe conflict is part and parcel of all collaborative work. So we will study how varying levels of conflict emerge and are handled within a GDSS.
The GDSS used for this search is a “generic”, level I system, version 1.0 of the University of Minnesota SAMM GDSS system (DeSanctis and Gallupe, 1987; Desanctis, Watson, and Sambamurthy, in press). The level 1 version of SAMM is designed to facilitate group communication and organize group interaction. It was purposely designed to embody a widely-used decision procedure, Dewey's Reflective Thinking Model, along with a few popular methods of deciding—rating, ranking, and voting. It purposely omits some of the more advanced features that could and would be incorporated in Level 2 systems (and are available in later versions of SAMM). This was done so we could compare work by groups using the GDSS with that of groups using manual versions of the same procedures.
In the next section we will first consider the effects GDSSs are likely to have on conflict management and advance several research questions and predictions. Following this we will describe a study designed to ascertain these effects.},
	urldate = {2015-09-24TZ},
	booktitle = {Proceedings of the 1988 {ACM} {Conference} on {Computer}-supported {Cooperative} {Work}},
	publisher = {ACM},
	author = {Poole, Marshall Scott and Homes, Michael and DeSanctis, Gerardine},
	year = {1988},
	pages = {227--243}
}

@book{march_primer_1994,
	title = {Primer on decision making: {How} decisions happen},
	shorttitle = {Primer on decision making},
	urldate = {2015-09-14TZ},
	publisher = {Simon and Schuster},
	author = {March, James G.},
	year = {1994}
}

@book{janis_groupthink:_1982-1,
	title = {Groupthink: psychological studies of policy decisions and fiascoes},
	isbn = {978-0-395-31704-4},
	shorttitle = {Groupthink},
	language = {en},
	publisher = {Houghton Mifflin},
	author = {Janis, Irving Lester},
	year = {1982},
	keywords = {Education / Decision-Making \& Problem Solving, Education / Teaching Methods \& Materials / General, Political Science / General, Political Science / Public Policy / General, Psychology / Social Psychology}
}

@article{johnson_constructive_1983,
	title = {Constructive {Controversy}: {The} {Key} to {Effective} {Decision}-{Making}},
	shorttitle = {Construc-tive {Controversy}},
	journal = {Productive Conflict Management: Perspectives for Organizations, New York, NY: Irvington Publishers},
	author = {Johnson, D. W. and Tjosvold, Dean},
	year = {1983}
}

@article{deutsch_conflicts:_1969,
	title = {Conflicts: {Productive} and destructive*},
	volume = {25},
	shorttitle = {Conflicts},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1540-4560.1969.tb02576.x/abstract},
	number = {1},
	urldate = {2015-09-23TZ},
	journal = {Journal of social issues},
	author = {Deutsch, Morton},
	year = {1969},
	pages = {7--42}
}

@inproceedings{desanctis_gdss_1987,
	title = {{GDSS} software: {A} shell system in support of a program of research},
	volume = {1},
	shorttitle = {{GDSS} software},
	booktitle = {Proceedings of the 20th {Annual} {Hawaii} {International} {Conference} on {System} {Sciences}},
	author = {DeSanctis, Gerardine and Dickson, Gary W.},
	year = {1987},
	pages = {431--439}
}

@article{watson_using_1988,
	title = {Using a {GDSS} to {Facilitate} {Group} {Consensus}: {Some} {Intended} and {Unintended} {Consequences}},
	volume = {12},
	copyright = {Copyright © 1988 Management Information Systems Research Center, University of Minnesota},
	issn = {0276-7783},
	shorttitle = {Using a {GDSS} to {Facilitate} {Group} {Consensus}},
	url = {http://www.jstor.org/stable/249214},
	doi = {10.2307/249214},
	abstract = {A cumulative body of experimental research is emerging that examines the ability of computer technology to support the processes and outcomes of small group meetings. For the most part the group decision support system effort has been concerned with demonstrating the usefulness of the technology in planning and decision-making situations where the quality of the meeting's outcomes can be objectively assessed. In many decision situations, however, there is no objective measure of decision quality available. Rather, the group must reconcile differences in opinion, personal preference, or judgment and achieve consensus about a particular mode of action. As a contribution to the accumulating research on GDSS, the current study examines the effects of a GDSS in resolving conflicts of personal preference. In a task requiring resolution of competing personal preferences, 82 groups-the largest sample size in the GDSS literature to date-were randomly assigned to one of three experiment conditions: (1) a computer-based support system (GDSS); (2) a manual, paper and pencil, support system; or (3) no support whatsoever. Groups were either of size 3 or 4 persons. Use of the GDSS was expected to facilitate democratic participation in group discussion, move group members toward agreement with one another, and result in a high level of satisfaction with the group decision process. While several of the intended effects of the technology were observed, the groups experienced some unintended consequences as a result of using the GDSS. In general, the GDSS technology appeared to offer some advantage over no support, but little advantage over the pencil and paper method of supporting group discussion.},
	number = {3},
	urldate = {2015-09-23TZ},
	journal = {MIS Quarterly},
	author = {Watson, Richard T. and DeSanctis, Gerardine and Poole, Marshall Scott},
	month = sep,
	year = {1988},
	pages = {463--478}
}

@book{janis_decision_1977,
	address = {New York},
	title = {Decision {Making}: {A} {Psychological} {Analysis} of {Conflict}, {Choice}, and {Commitment}},
	isbn = {978-0-02-916160-9},
	shorttitle = {Decision {Making}},
	language = {English},
	publisher = {Free Press},
	author = {Janis, Irving L. and Mann, Leon},
	month = apr,
	year = {1977}
}

@article{bui_dss_1984,
	title = {A {DSS} for {Cooperative} {Multiple} {Criteria} {Group} {Decision} {Making}},
	url = {http://aisel.aisnet.org/icis1984/24},
	journal = {ICIS 1984 Proceedings},
	author = {Bui, Tung and Jarke, Matthias},
	month = jan,
	year = {1984}
}

@book{easterbrook_cscw:_2012,
	title = {{CSCW}: {Cooperation} or {Conflict}?},
	isbn = {978-1-4471-1981-4},
	shorttitle = {{CSCW}},
	abstract = {Computer supported cooperative work (CSCW) systems will undoubtedly play an important role in the application of information systems in the 1990s and beyond. The term "cooperative" is often taken for granted and it is assumed that CSCW users are willing and able to cooperate without any difficulty. This assumption ignores the possibility of conflict and, as a result, the expression, management and resolution of conflict are not supported. CSCW: Cooperation  or Conflict? arose from a one-day meeting on computer supported cooperative work which examined the role of conflict in collaborative work. The aim of the meeting was to examine what people actually do when they say they are cooperating, and to assess how this affects the design of systems. The chapters of this book are fuller accounts of the work presented during the meeting. The first chapter presents a survey of studies of conflict in social psychology and related fields, providing both a summary of the main findings and a set of pointers into the literature. The subsequent chapters each present a different view of conflict, focussing particularly on the social and organizational settings, and the factors which lead to conflict. The earlier chapters provide conceptual frameworks for the study of various types of conflict, while the later chapters concentrate on the implications for CSCW. The book is the first to examine conflict from a CSCW perspective. It offers a unique snapshot of current research work in this exciting field, and establishes the importance of the issue. For the designer of CSCW systems, it offers insights into the role of conflict, and an analysis of some of the assumptions on which existing CSCW sytems have been based. For the student and researcher, it provides both an introduction to the area, and a set of in-depth studies suitable to inform future research.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Easterbrook, Steve},
	month = dec,
	year = {2012},
	keywords = {Computers / Information Technology, Computers / Intelligence (AI) \& Semantics, Computers / Software Development \& Engineering / General, Computers / System Administration / Storage \& Retrieval}
}

@article{miranda_avoidance_1994,
	title = {Avoidance of {Groupthink} {Meeting} {Management} {Using} {Group} {Support} {Systems}},
	volume = {25},
	issn = {1046-4964, 1552-8278},
	url = {http://sgr.sagepub.com/content/25/1/105},
	doi = {10.1177/1046496494251007},
	abstract = {Groupthink is a problem thatplagues decision-making groups. This article reviews antecedent and procedural conditions leading to groupthink and examines productive meeting processes that can prevent groupthink. The article then explores the possible role that group support systems (GSS) may play in the development of these productive meeting processes. Group support systems are an advanced information technology that provide electronic support to groups involved in teamwork. This technology possesses certain inherent resources or structuralfeatures. This article proposes aframeworkfor the study of the effects of GSS on groupthink. It examines the effects of GSS structuralfeatures on antecedent and procedural conditions predisposing groupthink. Existing GSS research relevant to groupthink-related variables is reviewed. The review of GSS structural features and of existing GSS research indicates that GSS use might indeed be an appropriate method of preventing groupthink. Finally, the article proposes a methodologyfor the empirical study of the impact of GSS use on groupthink.},
	language = {en},
	number = {1},
	urldate = {2015-09-23TZ},
	journal = {Small Group Research},
	author = {Miranda, Shaila M.},
	month = feb,
	year = {1994},
	pages = {105--136}
}

@article{desanctis_foundation_1987,
	title = {A {Foundation} for the {Study} of {Group} {Decision} {Support} {Systems}},
	volume = {33},
	issn = {0025-1909},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.33.5.589},
	doi = {10.1287/mnsc.33.5.589},
	abstract = {Technical developments in electronic communication, computing, and decision support, coupled with new interest on the part of organizations to improve meeting effectiveness, are spurring research in the area of group decision support systems (GDSS). A GDSS combines communication, computing, and decision support technologies to facilitate formulation and solution of unstructured problems by a group of people. This paper presents a conceptual overview of GDSS based on an information-exchange perspective of decision making, Three levels of systems are described, representing varying degrees of intervention into the decision process. Research on GDSS is conceived as evolving over time from the study of simple “shell” systems, consisting of menus of features available for selection by a group, to consideration of sophisticated rule-based systems that enable a group to pursue highly structured and novel decision paths. A multi-dimensional taxonomy of systems is proposed as an organizing framework for research in the area. Three environmental contingencies are identified as critical to GDSS design: group size, member proximity, and the task confronting the group. Potential impacts of GDSS on group processes and outcomes are discussed, and important constructs in need of study are identified.},
	number = {5},
	urldate = {2015-09-23TZ},
	journal = {Management Science},
	author = {DeSanctis, Gerardine and Gallupe, R. Brent},
	month = may,
	year = {1987},
	pages = {589--609}
}

@article{desanctis_foundation_1987-1,
	title = {A foundation for the study of group decision support systems},
	volume = {33},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.33.5.589},
	number = {5},
	urldate = {2015-09-23TZ},
	journal = {Management science},
	author = {Desanctis, Gerardine and Gallupe, R. Brent},
	year = {1987},
	pages = {589--609}
}

@inproceedings{farnham_structured_2000,
	address = {New York, NY, USA},
	series = {{CSCW} '00},
	title = {Structured {Online} {Interactions}: {Improving} the {Decision}-making of {Small} {Discussion} {Groups}},
	isbn = {1-58113-222-0},
	shorttitle = {Structured {Online} {Interactions}},
	url = {http://doi.acm.org/10.1145/358916.359001},
	doi = {10.1145/358916.359001},
	abstract = {A quantitative research experiment was used to examine whether a group's computer-mediated decision-making could be improved by providing a scripted structure to the groups text chat discussion. The study compared a regular chat discussion to a scripted chat discussion using Lead Line, a program that allows people to add a layer of pre-authored structure to regular text chat. We found that groups were more likely to come to consensus in structured chat discussions. In addition, groups applied the structure they learned to subsequent regular chat sessions.},
	urldate = {2015-09-21TZ},
	booktitle = {Proceedings of the 2000 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	publisher = {ACM},
	author = {Farnham, Shelly and Chesley, Harry R. and McGhee, Debbie E. and Kawal, Reena and Landau, Jennifer},
	year = {2000},
	keywords = {chat, computer supported collaborative work, computer-mediated communication, group decision-making, structured chat},
	pages = {299--308}
}

@article{chen_extensions_2000,
	title = {Extensions of the {TOPSIS} for group decision-making under fuzzy environment},
	volume = {114},
	url = {http://www.sciencedirect.com/science/article/pii/S0165011497003771},
	number = {1},
	urldate = {2015-09-20TZ},
	journal = {Fuzzy sets and systems},
	author = {Chen, Chen-Tung},
	year = {2000},
	pages = {1--9}
}

@article{delgado_combining_1998,
	title = {Combining numerical and linguistic information in group decision making},
	volume = {107},
	url = {http://www.sciencedirect.com/science/article/pii/S0020025597100445},
	number = {1},
	urldate = {2015-09-20TZ},
	journal = {Information Sciences},
	author = {Delgado, Miguel and Herrera, Francisco and Herrera-Viedma, Enrique and Martínez, Luis},
	year = {1998},
	pages = {177--194}
}

@article{de_dreu_minority_2001,
	title = {Minority dissent and team innovation: the importance of participation in decision making.},
	volume = {86},
	shorttitle = {Minority dissent and team innovation},
	url = {http://psycnet.apa.org/journals/apl/86/6/1191/},
	number = {6},
	urldate = {2015-09-20TZ},
	journal = {Journal of applied Psychology},
	author = {De Dreu, Carsten KW and West, Michael A.},
	year = {2001},
	pages = {1191}
}

@article{campion_relations_1993,
	title = {Relations between work group characteristics and effectiveness: {Implications} for designing effective work groups},
	volume = {46},
	shorttitle = {Relations between work group characteristics and effectiveness},
	url = {http://www.krannert.purdue.edu/faculty/campionm/Relations_Between_Work.pdf},
	number = {4},
	urldate = {2015-09-20TZ},
	journal = {Personnel psychology},
	author = {Campion, Michael A. and Medsker, Gina J. and Higgs, A. Catherine},
	year = {1993},
	pages = {823--850}
}

@article{stasser_effects_1987,
	title = {Effects of information load and percentage of shared information on the dissemination of unshared information during group discussion.},
	volume = {53},
	url = {http://psycnet.apa.org/journals/psp/53/1/81/},
	number = {1},
	urldate = {2015-09-20TZ},
	journal = {Journal of personality and social psychology},
	author = {Stasser, Garold and Titus, William},
	year = {1987},
	pages = {81}
}

@book{taylor_mathematics_2008,
	address = {New York, NY},
	title = {Mathematics and {Politics}},
	isbn = {978-0-387-77643-9 978-0-387-77645-3},
	url = {http://link.springer.com/10.1007/978-0-387-77645-3},
	language = {en},
	urldate = {2015-09-20TZ},
	publisher = {Springer New York},
	author = {Taylor, Alan D. and Pacelli, Allison M.},
	year = {2008}
}
@article{siegel_group_1986,
	title = {Group processes in computer-mediated communication},
	volume = {37},
	issn = {0749-5978},
	url = {http://www.sciencedirect.com/science/article/pii/0749597886900506},
	doi = {10.1016/0749-5978(86)90050-6},
	abstract = {Three experiments explored the effects of computer-mediated communication on communication efficiency, participation, interpersonal behavior, and group choice. Groups of three members were asked to reach consensus on career choice problems; they communicated face-to-face and in simultaneous computer-mediated discussions or through computer mail. When groups were linked by computer, group members made fewer remarks than they did face-to-face and took longer to make their group decisions. Social equalization was higher in computer-mediated groups in that group members participated more equally in discussions. Computer-mediated groups also exhibited more uninhibited behavior—using strong and inflammatory expressions in interpersonal interactions. Decisions of computer-mediated groups shifted further away from the members' initial individual choices than group decisions which followed face-to-face discussions. We discuss the implications of these findings for extension of theories about group interaction and for analyses of the effects of Computers in organizations.},
	number = {2},
	urldate = {2015-09-20TZ},
	journal = {Organizational Behavior and Human Decision Processes},
	author = {Siegel, Jane and Dubrovsky, Vitaly and Kiesler, Sara and McGuire, Timothy W},
	month = apr,
	year = {1986},
	pages = {157--187}
}

@article{kiesler_group_1992,
	title = {Group decision making and communication technology},
	volume = {52},
	url = {http://www.sciencedirect.com/science/article/pii/074959789290047B},
	number = {1},
	urldate = {2015-09-18TZ},
	journal = {Organizational behavior and human decision processes},
	author = {Kiesler, Sara and Sproull, Lee},
	year = {1992},
	pages = {96--123}
}

@article{weisband_group_1992,
	title = {Group discussion and first advocacy effects in computer-mediated and face-to-face decision making groups},
	volume = {53},
	url = {http://www.sciencedirect.com/science/article/pii/074959789290070N},
	number = {3},
	urldate = {2015-09-17TZ},
	journal = {Organizational behavior and human decision processes},
	author = {Weisband, Suzanne P.},
	year = {1992},
	pages = {352--380}
}

@article{davis_group_1973,
	title = {Group decision and social interaction: {A} theory of social decision schemes},
	volume = {80},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1471(Electronic);0033-295X(Print)},
	shorttitle = {Group decision and social interaction},
	doi = {10.1037/h0033951},
	abstract = {Proposes a general theory (social decision scheme theory) for many kinds of group decision-making and illustrates some special case models with a variety of data from several experimental situations. While focusing upon the traditional issue of individual-group differences, the theory is aimed at accounting for the distribution of group decisions by using formal hypotheses about the effects of social interaction when the inputs to discussion are individual member preferences. The basic assumptions underlying the model are similar in several respects to proposals by F. Restle and J. H. Davis (see record 1963-06168-001) and I. D. Steiner (see record 1966-10588-001) in group problem-solving research. The model itself represents the general case of earlier theoretical notions by W. H. Smoke and R. B. Zajonc; Davis, Hoppe, and Hornseth (see record 1968-09967-001); and Zajonc, Wolosin, and Wolosin in group decision making. In addition, several nonintuitive consequences of group decision making, assuming some form of the model, are discussed. (41 ref.)},
	number = {2},
	journal = {Psychological Review},
	author = {Davis, James H.},
	year = {1973},
	keywords = {*Decision Making, *Group Discussion, *Individual Differences, *Social Interaction, Group Problem Solving, Models},
	pages = {97--125}
}

@article{lea_computer-mediated_1991,
	title = {Computer-mediated {Communication}, {De}-individuation and {Group} {Decision}-making},
	volume = {34},
	issn = {0020-7373},
	url = {http://dx.doi.org/10.1016/0020-7373(91)90045-9},
	doi = {10.1016/0020-7373(91)90045-9},
	number = {2},
	urldate = {2015-09-14TZ},
	journal = {Int. J. Man-Mach. Stud.},
	author = {Lea, Martin and Spears, Russell},
	month = feb,
	year = {1991},
	pages = {283--301}
}

@article{mcguire_group_1987,
	title = {Group and computer-mediated discussion effects in risk decision making},
	volume = {52},
	issn = {0022-3514},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1987-25054-001&site=ehost-live},
	doi = {10.1037/0022-3514.52.5.917},
	abstract = {Managers individually and in 3-person groups made multiattribute risk choices (two investment alternatives, each with multiple outcomes). Two group decisions were reached during face-to-face discussion, and two were reached during (real-time) computer-mediated discussion. In comparison with prediscussion individual preferences, groups' multiattribute risk choices and attitudes after face-to-face discussion were risk averse for gains and risk seeking for losses, a tendency predicted by prospect theory and consistent with choice shift and other group extremitization research. By contrast, group decisions during computer-mediated discussion did not shift in the direction of prospect theory predictions. The results are consistent with persuasive-arguments theory, in that computer-mediated discussion contained less argumentation than face-to-face discussion. Social decision schemes were used to evaluate alternative assumptions about the group process. A "(prospect-theory) norm-wins" decision scheme described group choice well in the face-to-face discussion condition, but not in the computer-mediated discussion condition. Another decision scheme, first-advocate wins, which described choices well in both face-to-face and computer-mediated discussions, was explored in a discussion of the role of communication in group decision making. (PsycINFO Database Record (c) 2013 APA, all rights reserved)},
	number = {5},
	urldate = {2015-09-14TZ},
	journal = {Journal of Personality and Social Psychology},
	author = {McGuire, Timothy W. and Kiesler, Sara and Siegel, Jane},
	month = may,
	year = {1987},
	keywords = {Computer Applications, Group Discussion, Group decision making, Persuasive Communication, Risk Taking, Social Influences, face-to-face vs computer-mediated group discussion, implications for prospect \& persuasive arguments theory, multiple attribute risk choices, senior \& middle-level corporate managers \& university administrators},
	pages = {917--930}
}

@article{desanctis_foundation_1987,
	title = {A {Foundation} for the {Study} of {Group} {Decision} {Support} {Systems}},
	volume = {33},
	issn = {0025-1909},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.33.5.589},
	doi = {10.1287/mnsc.33.5.589},
	abstract = {Technical developments in electronic communication, computing, and decision support, coupled with new interest on the part of organizations to improve meeting effectiveness, are spurring research in the area of group decision support systems (GDSS). A GDSS combines communication, computing, and decision support technologies to facilitate formulation and solution of unstructured problems by a group of people. This paper presents a conceptual overview of GDSS based on an information-exchange perspective of decision making, Three levels of systems are described, representing varying degrees of intervention into the decision process. Research on GDSS is conceived as evolving over time from the study of simple “shell” systems, consisting of menus of features available for selection by a group, to consideration of sophisticated rule-based systems that enable a group to pursue highly structured and novel decision paths. A multi-dimensional taxonomy of systems is proposed as an organizing framework for research in the area. Three environmental contingencies are identified as critical to GDSS design: group size, member proximity, and the task confronting the group. Potential impacts of GDSS on group processes and outcomes are discussed, and important constructs in need of study are identified.},
	number = {5},
	urldate = {2015-09-14TZ},
	journal = {Management Science},
	author = {DeSanctis, Gerardine and Gallupe, R. Brent},
	month = may,
	year = {1987},
	pages = {589--609}
}

@article{chidambaram_is_2005,
	title = {Is {Out} of {Sight}, {Out} of {Mind}? {An} {Empirical} {Study} of {Social} {Loafing} in {Technology}-{Supported} {Groups}},
	volume = {16},
	copyright = {Copyright © 2005 INFORMS},
	issn = {1047-7047},
	shorttitle = {Is {Out} of {Sight}, {Out} of {Mind}?},
	url = {http://www.jstor.org/stable/23015909},
	abstract = {Research on group behavior has identified social loafing, i.e., the tendency of members to do less than their potential, as a particularly serious problem plaguing groups. Social Impact Theory (SIT) helps explain social loafing in terms of two theoretical dimensions—the dilution effect (where an individual feels submerged in the group) and the immediacy gap (where an individual feels isolated from the group). In this study, which employed a controlled experiment, we investigated these dimensions of social loafing in the context of group decision making, using collocated and distributed teams of varying sizes. Our results—in line with SIT—indicate that small groups, signifying a small dilution effect, had increased individual contributions and better group outcomes compared to their larger counterparts. However, support for SIT's arguments about the immediacy gap was mixed: Members contributed visibly more when they were collocated, but no significant differences in group outcomes were evident. Regardless of dimension, the quality of the input (ideas generated) determined the quality of the output (decisions made). Also, contrary to the literature on brainstorming, having more ideas to work with resulted in poorer-quality decisions. This apparent paradox is explained using the notion of integrative complexity, which challenges conventional wisdom regarding the relationship between individual inputs and group outputs. The implications of these results for practice and research are examined.},
	number = {2},
	urldate = {2015-09-13TZ},
	journal = {Information Systems Research},
	author = {Chidambaram, Laku and Tung, Lai Lai},
	month = jun,
	year = {2005},
	pages = {149--168}
}

@article{karau_social_1993,
	title = {Social loafing: {A} meta-analytic review and theoretical integration},
	volume = {65},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1315(Electronic);0022-3514(Print)},
	shorttitle = {Social loafing},
	doi = {10.1037/0022-3514.65.4.681},
	abstract = {Social loafing is the tendency for individuals to expend less effort when working collectively than when working individually. A meta-analysis of 78 studies demonstrates that social loafing is robust and generalizes across tasks and S populations. A large number of variables were found to moderate social loafing. Evaluation potential, expectations of co-worker performance, task meaningfulness, and culture had especially strong influence. These findings are interpreted in the light of a collective effort model that integrates elements of expectancy-value, social identity, and self-validation theories.},
	number = {4},
	journal = {Journal of Personality and Social Psychology},
	author = {Karau, Steven J. and Williams, Kipling D.},
	year = {1993},
	keywords = {*Collective Behavior, *Meta Analysis, *Models, Social Loafing},
	pages = {681--706}
}

@misc{center_for_history_and_new_media_zotero_nodate,
	title = {Zotero 快速入门指南},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}}
}

@inproceedings{mentis_development_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Development of {Decision} {Rationale} in {Complex} {Group} {Decision} {Making}},
	isbn = {978-1-60558-246-7},
	url = {http://doi.acm.org/10.1145/1518701.1518904},
	doi = {10.1145/1518701.1518904},
	abstract = {This study explores the characteristics of rationale development in a complex group decision making task and considers design implications for better supporting rationale development in group decision making. Twelve three-person, multi-role teams performed three instances of a collaborative decision making task with physical maps. We used rhetorical structure theory to analyze the structure of their decision making discourse. We found that groups begin their reasoning processing by stating and relating information and finish their reasoning through a point-counterpoint discussion. We also found that established groups reduced their need to analyze information during the last moments of a decision. Implications for the design of group decision support systems to encourage rationale development are presented.},
	urldate = {2015-09-01TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Mentis, Helena M. and Bach, Paula M. and Hoffman, Blaine and Rosson, Mary Beth and Carroll, John M.},
	year = {2009},
	keywords = {CSCW, decision making, rationale, rst},
	pages = {1341--1350}
}

@inproceedings{zhang_designing_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {Designing {Information} for {Remediating} {Cognitive} {Biases} in {Decision}-{Making}},
	isbn = {978-1-4503-3145-6},
	url = {http://doi.acm.org/10.1145/2702123.2702239},
	doi = {10.1145/2702123.2702239},
	abstract = {Software is playing an increasingly important role in supporting human decision-making. Previous HCI research on decision support systems (DSS) has improved the information visualization aspect of DSS information design, but has somewhat overlooked the cognitive aspect of decision-making, namely that human reasoning is heuristic and reflects systematic errors or cognitive biases. We report on an empirical study of two cognitive biases: conservatism and loss aversion. Two remediation techniques recommended by previous research were tested: the expected return method, an actuarial-inspired approach presenting objective metrics; and bootstrapping, a technique successful in improving judgment consistency. The results show that the two biases can occur simultaneously and can have a huge impact on decision-making. The results also show that the two debiasing techniques are only partly effective. These findings suggest a need for more research on debiasing, and indicate some directions for exploring debiasing techniques and building decision support systems.},
	urldate = {2015-09-01TZ},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhang, Yunfeng and Bellamy, Rachel K.E. and Kellogg, Wendy A.},
	year = {2015},
	keywords = {cognitive bias, conservatism, decision making, decision support system, intelligent assistance, loss aversion, multiple-cue probability learning},
	pages = {2211--2220}
}

@inproceedings{shen-hsieh_data_2002,
	address = {New York, NY, USA},
	series = {{CHI} '02},
	title = {Data {Visualization} for {Strategic} {Decision} {Making}},
	url = {http://doi.acm.org/10.1145/507752.507756},
	doi = {10.1145/507752.507756},
	abstract = {Organizations large and small continuously strive to improve strategic decision-making. Strategic decision-making (distinguished from operational decision making) involves making substantial investments of resources over long periods of time before results are evident. These decisions are made using quantitative and qualitative information - experience, intuition, and subjective assessment. These are people decisions, not decisions made by machines.So, how can data interfaces be designed to support these most critical decisions of the organization?This case study looks at approaches taken with one R\&D (research and development) client to address their key strategic decisions: whether to move research efforts into the next stage of development or cancel the project. We will discuss how we've used web-based interface technologies to create visual metaphors for data including: visualizing time, collaborating, and modeling scenarios. We'll also demonstrate approaches to embedding more abstract constructs like decision theory, statistical analysis, and competitive advantage into these interfaces.},
	urldate = {2015-09-01TZ},
	booktitle = {Case {Studies} of the {CHI}2002, {AIGA} {Experience} {Design} {FORUM}},
	publisher = {ACM},
	author = {Shen-Hsieh, Angela and Schindl, Mark},
	year = {2002},
	keywords = {data visualization, decision science, decision support, enterprise applications, enterprise information systems (EIS), enterprise resource planning (ERP), executive dashboards, information architecture, information visualization, strategic decision making},
	pages = {1--17}
}

@inproceedings{farnham_structured_2000,
	address = {New York, NY, USA},
	series = {{CSCW} '00},
	title = {Structured {Online} {Interactions}: {Improving} the {Decision}-making of {Small} {Discussion} {Groups}},
	isbn = {1-58113-222-0},
	shorttitle = {Structured {Online} {Interactions}},
	url = {http://doi.acm.org/10.1145/358916.359001},
	doi = {10.1145/358916.359001},
	abstract = {A quantitative research experiment was used to examine whether a group's computer-mediated decision-making could be improved by providing a scripted structure to the groups text chat discussion. The study compared a regular chat discussion to a scripted chat discussion using Lead Line, a program that allows people to add a layer of pre-authored structure to regular text chat. We found that groups were more likely to come to consensus in structured chat discussions. In addition, groups applied the structure they learned to subsequent regular chat sessions.},
	urldate = {2015-09-01TZ},
	booktitle = {Proceedings of the 2000 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work}},
	publisher = {ACM},
	author = {Farnham, Shelly and Chesley, Harry R. and McGhee, Debbie E. and Kawal, Reena and Landau, Jennifer},
	year = {2000},
	keywords = {chat, computer supported collaborative work, computer-mediated communication, group decision-making, structured chat},
	pages = {299--308}
}

@article{karacapilidis_computer_2001,
	title = {Computer supported argumentation and collaborative decision making: the {HERMES} system},
	volume = {26},
	issn = {0306-4379},
	shorttitle = {Computer supported argumentation and collaborative decision making},
	url = {http://www.sciencedirect.com/science/article/pii/S0306437901000205},
	doi = {10.1016/S0306-4379(01)00020-5},
	abstract = {Collaborative decision making problems can be addressed through argumentative discourse and collaboration among the users involved. Consensus is achieved through the process of collaboratively considering alternative understandings of the problem, competing interests, priorities and constraints. The application of formal modeling and analysis tools to solve the related processes is impossible before the problem can be articulated in a concise and agreed upon manner. This paper describes Hermes, a system that augments classical decision making approaches by supporting argumentative discourse among decision makers. It is fully implemented in Java and runs on the Web, thus providing relatively inexpensive access to a broad public. Using an illustrative example, we present the argumentation elements, discourse acts and reasoning mechanisms involved in Hermes. We also describe the integration of advanced features to the system; these enable users to retrieve data stored in remote databases in order to further warrant their arguments, and stimulate them to perform acts that best reflect their interests and intentions.},
	number = {4},
	urldate = {2015-09-01TZ},
	journal = {Information Systems},
	author = {Karacapilidis, Nikos and Papadias, Dimitris},
	month = jun,
	year = {2001},
	keywords = {Argumentation, CSCW, Collaborative decision making, Information sharing and retrieval, World wide web},
	pages = {259--277}
}

@article{heer2019agency,
  title={Agency plus automation: Designing artificial intelligence into interactive systems},
  author={Heer, Jeffrey},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={6},
  pages={1844--1850},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{wu2021polyjuice,
  title={Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models},
  author={Wu, Tongshuang and Ribeiro, Marco Tulio and Heer, Jeffrey and Weld, Daniel S},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics},
  year={2021}
}

@inproceedings{muller_how_2019,
author = {Muller, Michael and Lange, Ingrid and Wang, Dakuo and Piorkowski, David and Tsay, Jason and Liao, Q. Vera and Dugan, Casey and Erickson, Thomas},
title = {How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300356},
doi = {10.1145/3290605.3300356},
abstract = {With the rise of big data, there has been an increasing need for practitioners in
this space and an increasing opportunity for researchers to understand their workflows
and design new tools to improve it. Data science is often described as data-driven,
comprising unambiguous data and proceeding through regularized steps of analysis.
However, this view focuses more on abstract processes, pipelines, and workflows, and
less on how data science workers engage with the data. In this paper, we build on
the work of other CSCW and HCI researchers in describing the ways that scientists,
scholars, engineers, and others work with their data, through analyses of interviews
with 21 data science professionals. We set five approaches to data along a dimension
of interventions: Data as given; as captured; as curated; as designed; and as created.
Data science workers develop an intuitive sense of their data and processes, and actively
shape their data. We propose new ways to apply these interventions analytically, to
make sense of the complex activities around data practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {work-practices, data discovery, data creation, data capture, data design, grounded theory, data curation, data science},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{wang_human-ai_2019,
author = {Wang, Dakuo and Weisz, Justin D. and Muller, Michael and Ram, Parikshit and Geyer, Werner and Dugan, Casey and Tausczik, Yla and Samulowitz, Horst and Gray, Alexander},
title = {Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359313},
doi = {10.1145/3359313},
abstract = {The rapid advancement of artificial intelligence (AI) is changing our lives in many
ways. One application domain is data science. New techniques in automating the creation
of AI, known as AutoAI or AutoML, aim to automate the work practices of data scientists.
AutoAI systems are capable of autonomously ingesting and pre-processing data, engineering
new features, and creating and scoring models based on a target objectives (e.g. accuracy
or run-time efficiency). Though not yet widely adopted, we are interested in understanding
how AutoAI will impact the practice of data science. We conducted interviews with
20 data scientists who work at a large, multinational technology company and practice
data science in various business settings. Our goal is to understand their current
work practices and how these practices might change with AutoAI. Reactions were mixed:
while informants expressed concerns about the trend of automating their jobs, they
also strongly felt it was inevitable. Despite these concerns, they remained optimistic
about their future job security due to a view that the future of data science work
will be a collaboration between humans and AI systems, in which both automation and
human expertise are indispensable.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {211},
numpages = {24},
keywords = {automation, automl, machine learning, human-in-the-loop ai, future of work, data scientist, autoai, domain experts, data science, ai design ai, human-ai collaboration, human-centered ai}
}



@inproceedings{liu2020admm,
  title={An ADMM based framework for automl pipeline configuration},
  author={Liu, Sijia and Ram, Parikshit and Vijaykeerthy, Deepak and Bouneffouf, Djallel and Bramble, Gregory and Samulowitz, Horst and Wang, Dakuo and Conn, Andrew and Gray, Alexander},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={4892--4899},
  year={2020}
}

@INPROCEEDINGS{galhotra_automated_2019,
  author={Galhotra, Sainyam and Khurana, Udayan and Hassanzadeh, Oktie and Srinivas, Kavitha and Samulowitz, Horst and Qi, Miao},
  booktitle={2019 International Conference on Data Mining Workshops (ICDMW)}, 
  title={Automated Feature Enhancement for Predictive Modeling using External Knowledge}, 
  year={2019},
  volume={},
  number={},
  pages={1094-1097},
  doi={10.1109/ICDMW.2019.00161}}

@article{he2021automl,
  title={AutoML: A Survey of the State-of-the-Art},
  author={He, Xin and Zhao, Kaiyong and Chu, Xiaowen},
  journal={Knowledge-Based Systems},
  volume={212},
  pages={106622},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{dakuo_autods_2021,
author = {Wang, Dakuo and Andres, Josh and Weisz, Justin D. and Oduor, Erick and Dugan, Casey},
title = {AutoDS: Towards Human-Centered Automation of Data Science},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445526},
doi = {10.1145/3411764.3445526},
abstract = {Data science (DS) projects often follow a lifecycle that consists of laborious tasks
for data scientists and domain experts (e.g., data exploration, model training, etc.).
Only till recently, machine learning(ML) researchers have developed promising automation
techniques to aid data workers in these tasks. This paper introduces AutoDS, an automated
machine learning (AutoML) system that aims to leverage the latest ML automation techniques
to support data science projects. Data workers only need to upload their dataset,
then the system can automatically suggest ML configurations, preprocess data, select
algorithm, and train the model. These suggestions are presented to the user via a
web-based graphical user interface and a notebook-based programming user interface.
Our goal is to offer a systematic investigation of user interaction and perceptions
of using an AutoDS system in solving a data science task. We studied AutoDS with 30
professional data scientists, where one group used AutoDS, and the other did not,
to complete a data science project. As expected, AutoDS improves productivity; Yet
surprisingly, we find that the models produced by the AutoDS group have higher quality
and less errors, but lower human confidence scores. We reflect on the findings by
presenting design implications for incorporating automation techniques into human
work in the data science lifecycle.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {79},
numpages = {12},
keywords = {model building, automated data science, AI, collaborative AI, AutoML, human-in-the-loop, XAI, automated machine learning, AutoDS, human-AI collaboration, Data science},
location = {Yokohama, Japan},
series = {CHI '21}
}


@inproceedings{wongsuphasawat_voyager_2017,
author = {Wongsuphasawat, Kanit and Qu, Zening and Moritz, Dominik and Chang, Riley and Ouk, Felix and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
title = {Voyager 2: Augmenting Visual Analysis with Partial View Specifications},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025768},
doi = {10.1145/3025453.3025768},
abstract = {Visual data analysis involves both open-ended and focused exploration. Manual chart
specification tools support question answering, but are often tedious for early-stage
exploration where systematic data coverage is needed. Visualization recommenders can
encourage broad coverage, but irrelevant suggestions may distract users once they
commit to specific questions. We present Voyager 2, a mixed-initiative system that
blends manual and automated chart specification to help analysts engage in both open-ended
exploration and targeted question answering. We contribute two partial specification
interfaces: wildcards let users specify multiple charts in parallel, while related
views suggest visualizations relevant to the currently specified chart. We present
our interface design and applications of the CompassQL visualization query language
to enable these interfaces. In a controlled study we find that Voyager 2 leads to
increased data field coverage compared to a traditional specification tool, while
still allowing analysts to flexibly drill-down and answer specific questions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2648–2659},
numpages = {12},
keywords = {exploratory analysis, visualization recommendation, data visualization, mixed-initiative interfaces, partial specification},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{guo_proactive_2011,
author = {Guo, Philip J. and Kandel, Sean and Hellerstein, Joseph M. and Heer, Jeffrey},
title = {Proactive Wrangling: Mixed-Initiative End-User Programming of Data Transformation Scripts},
year = {2011},
isbn = {9781450307161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2047196.2047205},
doi = {10.1145/2047196.2047205},
abstract = {Analysts regularly wrangle data into a form suitable for computational tools through
a tedious process that delays more substantive analysis. While interactive tools can
assist data transformation, analysts must still conceptualize the desired output state,
formulate a transformation strategy, and specify complex transforms. We present a
model to proactively suggest data transforms which map input data to a relational
format expected by analysis tools. To guide search through the space of transforms,
we propose a metric that scores tables according to type homogeneity, sparsity and
the presence of delimiters. When compared to "ideal" hand-crafted transformations,
our model suggests over half of the needed steps; in these cases the top-ranked suggestion
is preferred 77% of the time. User study results indicate that suggestions produced
by our model can assist analysts' transformation tasks, but that users do not always
value proactive assistance, instead preferring to maintain the initiative. We discuss
some implications of these results for mixed-initiative interfaces.},
booktitle = {Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology},
pages = {65–74},
numpages = {10},
keywords = {mixed-initiative interfaces, data analysis, end-user programming, data transformation, data cleaning},
location = {Santa Barbara, California, USA},
series = {UIST '11}
}

@ARTICLE{kandel_enterprise_2012,
  author={Kandel, Sean and Paepcke, Andreas and Hellerstein, Joseph M. and Heer, Jeffrey},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Enterprise Data Analysis and Visualization: An Interview Study}, 
  year={2012},
  volume={18},
  number={12},
  pages={2917-2926},
  doi={10.1109/TVCG.2012.219}}

@inproceedings{lee_sibyl:_1990,
	address = {New York, NY, USA},
	series = {{CSCW} '90},
	title = {{SIBYL}: {A} {Tool} for {Managing} {Group} {Design} {Rationale}},
	isbn = {0-89791-402-3},
	shorttitle = {{SIBYL}},
	url = {http://doi.acm.org/10.1145/99332.99344},
	doi = {10.1145/99332.99344},
	abstract = {We describe SIBYL, a system that supports group decision making by representing and managing the qualitative aspects of decision making processes: such as the alternatives, the goals to be satisfied, and the arguments evaluating the alternatives with respect to these goals. We use an example session with SIBYL to illustrate the language, called DRL, that SIBYL uses for representing these qualitative aspects, and the set of services that SIBYL provides using this language. We also compare SIBYL to other systems with similar objectives and discuss the additional benefits that SIBYL provides. In particular, we compare SIBYL to gIBIS, a well-known “tool for exploratory policy discussion”, and claim that SIBYL is mainly a knowledge-based system which uses a semi-formal representation, whereas gIBIS is mainly a hypertext system with semantic types. We conclude with a design heuristic, drawn from our experience with SIBYL, for systems whose goal includes eliciting knowledge from people.},
	urldate = {2015-09-01TZ},
	booktitle = {Proceedings of the 1990 {ACM} {Conference} on {Computer}-supported {Cooperative} {Work}},
	publisher = {ACM},
	author = {Lee, Jintae},
	year = {1990},
	pages = {79--92}
}

@inproceedings{conklin_gibis:_1987,
	address = {New York, NY, USA},
	series = {{HYPERTEXT} '87},
	title = {{gIBIS}: {A} {Hypertext} {Tool} for {Team} {Design} {Deliberation}},
	isbn = {0-89791-340-X},
	shorttitle = {{gIBIS}},
	url = {http://doi.acm.org/10.1145/317426.317444},
	doi = {10.1145/317426.317444},
	abstract = {This paper introduces an application-specific hypertext system designed to facilitate the capture of early design deliberations, which implements a specific design method called Issue Based Information Systems (IBIS). The hypertext system described here, gIBIS(for graphical IBIS), makes use of color and a high speed relational database server to facilitate building and browsing typed IBIS networks. Further, gIBIS is designed to support the collaborative construction of these networks by any number of cooperating team members spread across a local area network. Early experiments suggest that the gIBIS tool, while still incomplete, forges a good match between graphical interface and design method even in this experimental version.},
	urldate = {2015-09-01TZ},
	booktitle = {Proceedings of the {ACM} {Conference} on {Hypertext}},
	publisher = {ACM},
	author = {Conklin, Jeff and Begeman, Michael L.},
	year = {1987},
	pages = {247--251}
}

@incollection{resnick_shared_1991,
	address = {Washington, DC, US},
	title = {Shared cognition: {Thinking} as social practice},
	copyright = {(c) 2015 APA, all rights reserved},
	isbn = {1-55798-121-3 (Hardcover)},
	shorttitle = {Shared cognition},
	abstract = {This volume is about a phenomenon that seems almost a contradiction in terms: cognition that is not bounded by the individual brain or mind. In most psychological theory, the social and the cognitive have engaged only peripherally, standing in a kind of figure-ground relationship to one another rather than truly interacting. This book aims to undo this figure-ground relationship between cognitive and social processes. In so doing, it looks beyond psychology to a number of allied disciplines that have traditionally taken a view of human phenomena that is less focused on the individual.},
	booktitle = {Perspectives on socially shared cognition},
	publisher = {American Psychological Association},
	author = {Resnick, Lauren B .},
	editor = {Resnick, L. B. and Levine, J. M. and Teasley, S. D.},
	year = {1991},
	keywords = {*Cognition, *Cognitive Processes, *Social Processes, Social Cognition, Thinking},
	pages = {1--20}
}

@article{nahavandi_restructuring_1994,
	title = {Restructuring teams for the re-engineered organization},
	volume = {8},
	url = {http://amp.aom.org/content/8/4/58.short},
	number = {4},
	urldate = {2015-09-01TZ},
	journal = {The Academy of Management Executive},
	author = {Nahavandi, Afsaneh and Aranda, Eileen},
	year = {1994},
	pages = {58--68}
}

@article{xu_automatic_2009,
	title = {An automatic approach to reaching consensus in multiple attribute group decision making},
	volume = {56},
	issn = {0360-8352},
	url = {http://www.sciencedirect.com/science/article/pii/S0360835208001873},
	doi = {10.1016/j.cie.2008.08.013},
	abstract = {In this work, we consider the problem of consensus of multiple attribute group decision making, and develop an automatic approach to reaching consensus among group opinions. In the process of group decision making, each expert provides his/her preferences over the alternatives with respect to each attribute, and constructs an individual decision matrix. The developed approach first aggregates these individual decision matrices into a group decision matrix by using the additive weighted aggregation (AWA) operator, and then establishes a convergent iterative algorithm to gain a consentaneous group decision matrix. Then based on the consentaneous group decision matrix, the approach utilizes the AWA operator to derive the overall attribute values of alternatives, by which the most desirable alternative can be found out. Finally, we detailedly expound the implementation process of the approach with a practical example.},
	number = {4},
	urldate = {2015-09-01TZ},
	journal = {Computers \& Industrial Engineering},
	author = {Xu, Zeshui},
	month = may,
	year = {2009},
	keywords = {Additive weighted aggregation (AWA) operator, Consensus, Decision matrix, Iterative algorithm, Multiple attribute group decision making (MAGDM)},
	pages = {1369--1374}
}

@article{ben-arieh_multi-criteria_2007,
	series = {Integrated {Decision} {Support}},
	title = {Multi-criteria group consensus under linear cost opinion elasticity},
	volume = {43},
	issn = {0167-9236},
	url = {http://www.sciencedirect.com/science/article/pii/S016792360600203X},
	doi = {10.1016/j.dss.2006.11.009},
	abstract = {Consensus is a pivotal concept in group decision making. Many times, such a consensus is achieved by the experts shifting their opinion towards a point of mutual consent. Such a shift in many cases is the result of laborious negotiations, which escalates the cost of reaching the consensus. Moreover, many times the group decision is multi-criteria oriented in which the experts need to agree on each criterion separately.

This paper describes three problems where experts of unequal importance and with a linear cost of changing their opinion (opinion elasticity) consider a single and a multi-criteria decision consensus. These problems achieve a minimum cost consensus without a budget limit. It turns out that the optimal consensus point is at the median opinion for rectilinear cost function and at the weighted average opinion for squared geometric distance calculations.

Linear-time algorithms are presented for all cost consensus problems with no budget limits. Proofs, computational complexity and examples are provided for these algorithms.},
	number = {3},
	urldate = {2015-09-01TZ},
	journal = {Decision Support Systems},
	author = {Ben-Arieh, D. and Easton, T.},
	month = apr,
	year = {2007},
	keywords = {Consensus, Distributed decision making, Multiple experts},
	pages = {713--721}
}

@article{regan_formal_2006,
	title = {A formal model for consensus and negotiation in environmental management},
	volume = {80},
	issn = {0301-4797},
	url = {http://www.sciencedirect.com/science/article/pii/S0301479705002823},
	doi = {10.1016/j.jenvman.2005.09.004},
	abstract = {Environmental management decisions typically lie at the interface of science and public policy. Consequently, these decisions involve a number of stakeholders with competing agendas and vested interests in the ultimate decision. In such cases, it is appropriate to adopt formal methods for consensus building to ensure transparent and repeatable decisions. In this paper, we use an environmental management case study to demonstrate the utility of a mathematical consensus convergence model in aggregating values (or weights) across groups. Consensus models are applicable when all parties agree to negotiate in order to resolve conflict. The advantage of this method is that it does not require that all members of the group reach agreement, often an impossible task in group decision making. Instead, it uses philosophical foundations in consensus building to aggregate group members' values in a way that guarantees convergence towards a single consensual value that summarizes the group position. We highlight current problems with ad hoc consensus and negotiation methods, provide justification for the adoption of formal consensus convergence models and compare the consensus convergence model with currently used methods for aggregating values across a group in a decision making context. The model provides a simple and transparent decision support tool for group decision making that is straightforward to implement.},
	number = {2},
	urldate = {2015-09-01TZ},
	journal = {Journal of Environmental Management},
	author = {Regan, Helen M. and Colyvan, Mark and Markovchick-Nicholls, Lisa},
	month = jul,
	year = {2006},
	keywords = {Consensus, Group decisions, Multi-criteria decision making, Negotiation, Urban open space},
	pages = {167--176}
}

@article{ben-arieh_linguistic-labels_2006,
	title = {Linguistic-labels aggregation and consensus measure for autocratic decision making using group recommendations},
	volume = {36},
	issn = {1083-4427},
	doi = {10.1109/TSMCA.2005.853488},
	abstract = {Group decision making is a common and important activity in everyday life. In many cases, due to inherent uncertainty, experts cannot express their score or preference using exact numbers. The use of linguistic labels makes expert judgment more reliable and informative for decision-making. One of the problems of group decision making in fuzzy domains is aggregating experts' opinions, expressed using linguistic labels, into a group opinion. This aggregation allows the group to select the most "preferred" alternative from a finite set of candidates. The aggregation of individual judgments into a group opinion requires a measured level of consensus. In this paper, by introducing a new linguistic-labels aggregation operation, we present a procedure for handling an autocratic group decision-making process under linguistic assessments. The methodology presented results in two consequent outcomes: a group-based recommendation, and a score for each expert, reflecting the expert's contribution towards the group recommendation. By changing the weights of the experts based on their contributions, we increase the consensus and reinforce the common decision, without forcing the experts to modify their opinions. This methodology allows an autocratic decision maker to use a diversified group of consultants for a succession of decisions reaching a high level of consensus},
	number = {3},
	journal = {IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans},
	author = {Ben-Arieh, D. and Chen, Zhifeng},
	month = may,
	year = {2006},
	keywords = {Aggregates, Aggregation operators, Group decision making, Industrial relations, Manufacturing industries, Manufacturing systems, Open wireless architecture, Systems engineering and theory, autocratic decision making, computational linguistics, consensus measure, decision making, fuzzy set theory, fuzzy sets, group recommendations, linguistic-labels aggregation, multicriteria decision making, operations research},
	pages = {558--568}
}

@article{xu_deviation_2005,
	title = {Deviation measures of linguistic preference relations in group decision making},
	volume = {33},
	issn = {0305-0483},
	url = {http://www.sciencedirect.com/science/article/pii/S0305048304000696},
	doi = {10.1016/j.omega.2004.04.008},
	abstract = {In this paper, we study the group decision making problem with linguistic preference relations. We first show that the weighted combination of A1,A2,…,Am is linguistic preference relation under the condition that all of A1,A2,…,Am are linguistic preference relations. Then we define the concepts of deviation degree and similarity degree between two linguistic values, and deviation degree and similarity degree between two linguistic preference relations. We also show that the deviation degree between linguistic preference relation Ai of A1,A2,…,Am and their group linguistic preference relation is no greater than the largest deviation degree between the linguistic preference relation Ai and each of the linguistic preference relations A1,A2,…,Am. Thus, a theoretic basis has been established for the application of linguistic preference relations in group decision making.},
	number = {3},
	urldate = {2015-09-01TZ},
	journal = {Omega},
	author = {Xu, Zeshui},
	month = jun,
	year = {2005},
	keywords = {Deviation degree, Group decision making, Linguistic preference relation, Linguistic variable, Operational laws, Similarity degree},
	pages = {249--254}
}

@article{herrera-viedma_consensus_2005,
	title = {A {Consensus} {Support} {System} {Model} for {Group} {Decision}-{Making} {Problems} {With} {Multigranular} {Linguistic} {Preference} {Relations}},
	volume = {13},
	issn = {1063-6706},
	doi = {10.1109/TFUZZ.2005.856561},
	abstract = {The group decision-making framework with linguistic preference relations is studied. In this context, we assume that there exist several experts who may have different background and knowledge to solve a particular problem and, therefore, different linguistic term sets (multigranular linguistic information) could be used to express their opinions. The aim of this paper is to present a model of consensus support system to assist the experts in all phases of the consensus reaching process of group decision-making problems with multigranular linguistic preference relations. This consensus support system model is based on i) a multigranular linguistic methodology, ii) two consensus criteria, consensus degrees and proximity measures, and iii) a guidance advice system. The multigranular linguistic methodology permits the unification of the different linguistic domains to facilitate the calculus of consensus degrees and proximity measures on the basis of experts' opinions. The consensus degrees assess the agreement amongst all the experts' opinions, while the proximity measures are used to find out how far the individual opinions are from the group opinion. The guidance advice system integrated in the consensus support system model acts as a feedback mechanism, and it is based on a set of advice rules to help the experts change their opinions and to find out which direction that change should follow in order to obtain the highest degree of consensus possible. There are two main advantages provided by this model of consensus support system. Firstly, its ability to cope with group decision-making problems with multigranular linguistic preference relations, and, secondly, the figure of the moderator, traditionally presents in the consensus reaching process, is replaced by the guidance advice system, and in such a way, the whole group decision-making process is automated},
	number = {5},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Herrera-Viedma, E. and Martinez, L. and Mata, F. and Chiclana, F.},
	month = oct,
	year = {2005},
	keywords = {Artificial intelligence, Calculus, Computational intelligence, Computer science, Consensus, Context modeling, Feedback, consensus reaching process, consensus support system model, decision making, feedback mechanism, fuzzy preference relation, fuzzy set theory, group decision support systems, group decision-making (GDM), group decision-making problems, linguistic modeling, multigranular linguistic preference relations, reachability analysis},
	pages = {644--658}
}

@article{mohammed_cognitive_2001,
	title = {Cognitive {Diversity} and {Consensus} in {Group} {Decision} {Making}: {The} {Role} of {Inputs}, {Processes}, and {Outcomes}},
	volume = {85},
	issn = {0749-5978},
	shorttitle = {Cognitive {Diversity} and {Consensus} in {Group} {Decision} {Making}},
	url = {http://www.sciencedirect.com/science/article/pii/S0749597800929431},
	doi = {10.1006/obhd.2000.2943},
	abstract = {This study contributes to the new and growing body of research on shared cognition by examining how individuals entering a group decision-making context with different perspectives of the issues to be discussed arrive at cognitive consensus. Cognitive consensus refers to similarity among group members regarding how key matters are conceptualized and was operationalized as shared assumptions underlying decision issues in the present research. Utilizing 37 student groups participating in a multi-issue decision-making exercise, the study investigated antecedents and correlates of cognitive consensus. Results revealed that unanimity decision rule groups achieved more cognitive consensus than majority rule groups. In addition, group members inquiring concerning the reasons underlying others' decision preferences, accepting others' viewpoints as legitimate, and incorporating others' perspectives into their own interpretations of the issues was positively related to arriving at a greater degree of cognitive consensus. Cognitive consensus also positively influenced expectations regarding decision implementation and satisfaction.},
	number = {2},
	urldate = {2015-09-01TZ},
	journal = {Organizational Behavior and Human Decision Processes},
	author = {Mohammed, Susan and Ringseis, Erika},
	month = jul,
	year = {2001},
	pages = {310--335}
}

@article{inohara_consistent_2000,
	title = {On consistent coalitions in group decision making with flexible decision makers},
	volume = {109},
	issn = {0096-3003},
	url = {http://www.sciencedirect.com/science/article/pii/S0096300398100528},
	doi = {10.1016/S0096-3003(98)10052-8},
	abstract = {In this paper we propose a formal framework to deal with situations of group decision making with flexible decision makers. In the framework it is assumed that each decision maker tries to achieve cooperation in a coalition balancing their flexibility as well as to obtain a consequence as desirable for him/herself as possible. We introduce two different concepts of consistency of coalitions in order to express the idea of the assumption, and examine relations between them. We, moreover, define two types of strategic exchanges of information about decision makers' opinions, and provide a sufficient condition to make profitable manipulation of information impossible, in each case. That is, it is impossible for a decision maker to obtain a preferable consequence by strategic information exchange, when the decision maker cannot form any new consistent coalitions by the manipulated information, in both cases.},
	number = {2–3},
	urldate = {2015-09-01TZ},
	journal = {Applied Mathematics and Computation},
	author = {Inohara, Takehiro},
	month = mar,
	year = {2000},
	keywords = {Accommodation, Coalitions, Compromises, Consistence, Flexibility, Group decision making, Opinions},
	pages = {101--119}
}

@article{herrera_rational_1997,
	title = {A rational consensus model in group decision making using linguistic assessments},
	volume = {88},
	issn = {0165-0114},
	url = {http://www.sciencedirect.com/science/article/pii/S0165011496000474},
	doi = {10.1016/S0165-0114(96)00047-4},
	abstract = {A new consensus model for the consensus reaching process, in a linguistic framework, is presented in heterogeneous group decision making problems, called rational consensus model. It is guided by some linguistic consensus and linguistic consistency meaures. All the measures are calculated from a set of linguistic preference relations used to provide experts' opinions. This consensus model allows more rational consensus solutions to be obtained and thus, more human consistency to be incorporated in decision support systems.},
	number = {1},
	urldate = {2015-09-01TZ},
	journal = {Fuzzy Sets and Systems},
	author = {Herrera, F. and Herrera-Viedma, E. and Verdegay, J. L.},
	month = may,
	year = {1997},
	keywords = {Consensus degrees, Consistency, Group decision making, Linguistic modelling},
	pages = {31--49}
}

@article{bordogna_linguistic_1997,
	title = {A {Linguistic} {Modeling} of {Consensus} in {Group} {Decision} {Making} {Based} on {OWA} {Operators}},
	volume = {27},
	issn = {1083-4427},
	url = {http://dx.doi.org/10.1109/3468.553232},
	doi = {10.1109/3468.553232},
	abstract = {In this paper, a model for group decision-making is proposed and defined in a linguistic context. A multiperson multicriteria decision problem is considered, in which a group of experts is involved in the evaluation of the performances of a set of alternatives with respect to a predefined set of criteria. The objective is to evaluate a consensual judgement and a consensus degree on each alternative. Both the experts' evaluations of the alternatives and the degree of consensus are expressed linguistically. A \&ldquo;soft\&rdquo; consensus degree referred to a fuzzy majority of the experts is proposed based on the concept of linguistic quantifier. The entire process is defined in a linguistic domain and modeled within fuzzy set theory by ordered weighted average (OWA) operators},
	number = {1},
	urldate = {2015-09-01TZ},
	journal = {Trans. Sys. Man Cyber. Part A},
	author = {Bordogna, G. and Fedrizzi, M. and Pasi, G.},
	month = jan,
	year = {1997},
	pages = {126--133}
}

@article{herrera_model_1996,
	title = {A model of consensus in group decision making under linguistic assessments},
	volume = {78},
	issn = {0165-0114},
	url = {http://www.sciencedirect.com/science/article/pii/0165011495001077},
	doi = {10.1016/0165-0114(95)00107-7},
	abstract = {This paper presents a consensus model in group decision making under linguistic assessments. It is based on the use of linguistic preferences to provide individuals' opinions, and on the use of fuzzy majority of consensus, represented by means of a linguistic quantifier. Several linguistic consensus degrees and linguistic distances are defined, acting on three levels. The consensus degrees indicate how far a group of individuals is from the maximum consensus, and linguistic distances indicate how far each individual is from current consensus labels over the preferences. This consensus model allows to incorporate more human consistency in decision support systems.},
	number = {1},
	urldate = {2015-09-01TZ},
	journal = {Fuzzy Sets and Systems},
	author = {Herrera, F. and Herrera-Viedma, E. and verdegay, J. L.},
	month = feb,
	year = {1996},
	keywords = {Consensus degree, Group decision making, Linguistic modelling},
	pages = {73--87}
}

@book{hwang_multiple_1981,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Economics} and {Mathematical} {Systems}},
	title = {Multiple {Attribute} {Decision} {Making}},
	volume = {186},
	isbn = {978-3-540-10558-9 978-3-642-48318-9},
	url = {http://link.springer.com/10.1007/978-3-642-48318-9},
	urldate = {2015-09-01TZ},
	publisher = {Springer Berlin Heidelberg},
	author = {Hwang, Ching-Lai and Yoon, Kwangsun},
	editor = {Beckmann, M. and Künzi, H. P.},
	year = {1981}
}

@misc{pardee_measurement_1969,
	type = {Product {Page}},
	title = {Measurement and {Evaluation} of {Transportation} {System} {Effectiveness}},
	url = {http://www.rand.org/pubs/research_memoranda/RM5869.html},
	abstract = {One in a series of studies prepared for the Northeast Corridor Transportation Project.},
	urldate = {2015-09-01TZ},
	author = {Pardee, Frederick S. and Kirkwood, T. F. and MacCrimmon, Kenneth R. and Miller, James R. and Phillips, C. T. and Ranftl, J. W. and Smith, K. V. and Whitcomb, David K.},
	year = {1969}
}

@book{yoon_multiple_1995,
	title = {Multiple attribute decision making: an introduction},
	volume = {104},
	shorttitle = {Multiple attribute decision making},
	url = {https://books.google.com/books?hl=en&lr=&id=dpB2AwAAQBAJ&oi=fnd&pg=PP1&dq=multiple+attribute+decision+making&ots=b83TGavA_x&sig=LFnTAdBfRe8yY0JDLxfH_RCclOk},
	urldate = {2015-09-01TZ},
	publisher = {Sage publications},
	author = {Yoon, K. Paul and Hwang, Ching-Lai},
	year = {1995}
}

@inproceedings{lee_making_2015,
	address = {New York, NY, USA},
	series = {{CSCW} '15},
	title = {Making {Decisions} {From} a {Distance}: {The} {Impact} of {Technological} {Mediation} on {Riskiness} and {Dehumanization}},
	isbn = {978-1-4503-2922-4},
	shorttitle = {Making {Decisions} {From} a {Distance}},
	url = {http://doi.acm.org/10.1145/2675133.2675288},
	doi = {10.1145/2675133.2675288},
	abstract = {Telepresence means business people can make deals in other countries, doctors can give remote medical advice, and soldiers can rescue someone from thousands of miles away. When interaction is mediated, people are removed from and lack context about the person they are making decisions about. In this paper, we explore the impact of technological mediation on risk and dehumanization in decision-making. We conducted a laboratory experiment involving medical treatment decisions. The results suggest that technological mediation influences decision making, but its influence depends on an individual's self-construal: participants who saw themselves as defined through their relationships (interdependent self-construal) recommended riskier and more painful treatments in video conferencing than when face-to-face. We discuss implications of our results for theory and future research.},
	urldate = {2015-08-30TZ},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} \& {Social} {Computing}},
	publisher = {ACM},
	author = {Lee, Min Kyung and Fruchter, Nathaniel and Dabbish, Laura},
	year = {2015},
	keywords = {computer-mediated decision making, decontextualized decision making, dehumanization, risk-preference, risk-taking, teledecision, telemedicine, telepresence},
	pages = {1576--1589}
}

@inproceedings{hassard_analogies_2009,
	address = {Swinton, UK, UK},
	series = {{BCS}-{HCI} '09},
	title = {Analogies in {Design} {Decision}-making},
	url = {http://dl.acm.org/citation.cfm?id=1671011.1671027},
	abstract = {Design is becoming the decisive factor in whether a product is a commercial success, like Windows XP, or a critical failure, like Microsoft Bob. To leverage this factor we need to have a greater understanding of the cognitive processes behind Interaction Design. While there are a wide array of disciplines that fall under the umbrella of design, there are several cognitive processes that are common to all strata of design. Decision Making has been identified as an important factor in the design process but remains woefully under-explored. This paper aims to understand Design Decision-making (DDM) in the light of more recent developments in the wider decision-making field. Two studies were conducted, consisting of an initial theoretical thematic analysis to update the outdated models of design decision-making, and a follow-up quantitative study to validate the findings of the first study. Results indicate that while the current models of DDM do well to explain elements of the decision-making process they do not account for such things as the persistence of analogies across all stages of the decision-making process.},
	urldate = {2015-08-30TZ},
	booktitle = {Proceedings of the 23rd {British} {HCI} {Group} {Annual} {Conference} on {People} and {Computers}: {Celebrating} {People} and {Technology}},
	publisher = {British Computer Society},
	author = {Hassard, Stephen T. and Blandford, Ann and Cox, Anna L.},
	year = {2009},
	keywords = {design decision making, interaction design, naturalistic decision making, recognition-primed decision making},
	pages = {140--148}
}

@article{shih_extension_2007,
	title = {An extension of {TOPSIS} for group decision making},
	volume = {45},
	issn = {0895-7177},
	url = {http://www.sciencedirect.com/science/article/pii/S0895717706003025},
	doi = {10.1016/j.mcm.2006.03.023},
	abstract = {An extension of TOPSIS (technique for order performance by similarity to ideal solution), a multi-attribute decision making (MADM) technique, to a group decision environment is investigated. TOPSIS is a practical and useful technique for ranking and selection of a number of externally determined alternatives through distance measures. To get a broad view of the techniques used, we provide a few options for the operations, such as normalization, distance measures and mean operators, at each of the corresponding steps of TOPSIS. In addition, the preferences of more than one decision maker are internally aggregated into the TOPSIS procedure. Unlike in previous developments, our group preferences are aggregated within the procedure. The proposed model is indeed a unified process and it will be readily applicable to many real-world decision making situations without increasing the computational burden. In the final part, the effects of external aggregation and internal aggregation of group preferences for TOPSIS with different computational combinations are compared using examples. The results have demonstrated our model to be both robust and efficient.},
	number = {7–8},
	urldate = {2015-08-30TZ},
	journal = {Mathematical and Computer Modelling},
	author = {Shih, Hsu-Shih and Shyur, Huan-Jyh and Lee, E. Stanley},
	month = apr,
	year = {2007},
	keywords = {Distance function, Group decision support, Multi-attribute decision making, Normalization, Preference aggregation, TOPSIS},
	pages = {801--813}
}

@inproceedings{wojtinnek_semantic_2011,
	title = {Semantic relatedness from automatically generated semantic networks},
	url = {http://dl.acm.org/citation.cfm?id=2002718},
	urldate = {2015-08-21TZ},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Computational} {Semantics}},
	publisher = {ACL},
	author = {Wojtinnek, Pia-Ramona and Pulman, Stephen},
	year = {2011},
	pages = {390--394}
}

@inproceedings{gouws_measuring_2010,
	title = {Measuring conceptual similarity by spreading activation over {Wikipedia}’s hyperlink structure},
	url = {https://www.seemoo.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2010/proceedings_ws04_coling2010.pdf#page=56},
	urldate = {2015-08-21TZ},
	booktitle = {Proceedings of the 2nd {Workshop} on {The} {People}’s {Web} {Meets} {NLP}: {Collaboratively} {Constructed} {Semantic} {Resources}},
	author = {Gouws, Stephan and Van Rooyen, G. J. and Engelbrecht, Herman A.},
	year = {2010},
	pages = {46--54}
}

@incollection{hecht_geosr:_2008,
	title = {{GeoSR}: {Geographically} explore semantic relations in world knowledge},
	shorttitle = {{GeoSR}},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-78946-8_6},
	urldate = {2015-08-21TZ},
	booktitle = {The {European} {Information} {Society}},
	publisher = {Springer},
	author = {Hecht, Brent and Raubal, Martin},
	year = {2008},
	pages = {95--113}
}


@inproceedings{halawi_large-scale_2012,
	title = {Large-scale learning of word relatedness with constraints},
	url = {http://dl.acm.org/citation.cfm?id=2339751},
	urldate = {2015-08-21TZ},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Halawi, Guy and Dror, Gideon and Gabrilovich, Evgeniy and Koren, Yehuda},
	year = {2012},
	pages = {1406--1414}
}

@inproceedings{radinsky_word_2011,
	title = {A word at a time: computing word relatedness using temporal semantic analysis},
	shorttitle = {A word at a time},
	url = {http://dl.acm.org/citation.cfm?id=1963455},
	urldate = {2015-08-21TZ},
	booktitle = {Proceedings of the 20th international conference on {World} wide web},
	publisher = {ACM},
	author = {Radinsky, Kira and Agichtein, Eugene and Gabrilovich, Evgeniy and Markovitch, Shaul},
	year = {2011},
	pages = {337--346}
}

@article{gabrilovich_wikipedia-based_2009,
	title = {Wikipedia-based semantic interpretation for natural language processing},
	url = {http://www.jair.org/papers/paper2669.html},
	urldate = {2015-08-21TZ},
	journal = {Journal of Artificial Intelligence Research},
	author = {Gabrilovich, Evgeniy and Markovitch, Shaul},
	year = {2009},
	pages = {443--498}
}
@inproceedings{hassan_cross-lingual_2009,
	title = {Cross-lingual semantic relatedness using encyclopedic knowledge},
	url = {http://dl.acm.org/citation.cfm?id=1699665},
	urldate = {2015-08-21TZ},
	booktitle = {Proceedings of the 2009 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {Volume} 3-{Volume} 3},
	publisher = {ACL},
	author = {Hassan, Samer and Mihalcea, Rada},
	year = {2009},
	pages = {1192--1201}
}

@article{zhang_recent_2013,
	title = {Recent advances in methods of lexical semantic relatedness–a survey},
	volume = {19},
	url = {http://journals.cambridge.org/abstract_S1351324912000125},
	number = {04},
	urldate = {2015-05-04TZ},
	journal = {Natural Language Engineering},
	author = {Zhang, Ziqi and Gentile, Anna Lisa and Ciravegna, Fabio},
	year = {2013},
	pages = {411--479}
}

@article{phillips_doing_2004,
	title = {Doing {Justice} to the {Law}},
	volume = {94},
	issn = {1467-8306},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8306.2004.09402006.x/abstract},
	doi = {10.1111/j.1467-8306.2004.09402006.x},
	language = {en},
	number = {2},
	urldate = {2015-04-30TZ},
	journal = {Annals of the Association of American Geographers},
	author = {Phillips, Jonathan D.},
	month = jun,
	year = {2004},
	pages = {290--293}
}

@article{barnes_paper_2004,
	title = {A {Paper} {Related} to {Everything} but {More} {Related} to {Local} {Things}},
	volume = {94},
	issn = {1467-8306},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8306.2004.09402004.x/abstract},
	doi = {10.1111/j.1467-8306.2004.09402004.x},
	language = {en},
	number = {2},
	urldate = {2015-04-30TZ},
	journal = {Annals of the Association of American Geographers},
	author = {Barnes, Trevor J.},
	month = jun,
	year = {2004},
	pages = {278--283}
}

@article{tobler_first_2004,
	title = {On the {First} {Law} of {Geography}: {A} {Reply}},
	volume = {94},
	issn = {1467-8306},
	shorttitle = {On the {First} {Law} of {Geography}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8306.2004.09402009.x/abstract},
	doi = {10.1111/j.1467-8306.2004.09402009.x},
	language = {en},
	number = {2},
	urldate = {2015-04-30TZ},
	journal = {Annals of the Association of American Geographers},
	author = {Tobler, Waldo},
	month = jun,
	year = {2004},
	pages = {304--310}
}

@article{miller_toblers_2004,
	title = {Tobler's {First} {Law} and {Spatial} {Analysis}},
	volume = {94},
	issn = {1467-8306},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8306.2004.09402005.x/abstract},
	doi = {10.1111/j.1467-8306.2004.09402005.x},
	language = {en},
	number = {2},
	urldate = {2015-04-30TZ},
	journal = {Annals of the Association of American Geographers},
	author = {Miller, Harvey J.},
	month = jun,
	year = {2004},
	pages = {284--289}
}

@article{zesch_wisdom_2010,
	title = {Wisdom of crowds versus wisdom of linguists–measuring the semantic relatedness of words},
	volume = {16},
	url = {http://journals.cambridge.org/abstract_S1351324909990167},
	number = {01},
	urldate = {2015-04-29TZ},
	journal = {Natural Language Engineering},
	author = {Zesch, Torsten and Gurevych, Iryna},
	year = {2010},
	pages = {25--59}
}

@incollection{aggarwal_cross-lingual_2013,
	title = {Cross-lingual natural language querying over the web of data},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-38824-8_13},
	urldate = {2015-04-29TZ},
	booktitle = {Natural {Language} {Processing} and {Information} {Systems}},
	publisher = {Springer},
	author = {Aggarwal, Nitish and Polajnar, Tamara and Buitelaar, Paul},
	year = {2013},
	pages = {152--163}
}

@incollection{freitas_querying_2011,
	title = {Querying linked data using semantic relatedness: a vocabulary independent approach},
	shorttitle = {Querying linked data using semantic relatedness},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-22327-3_5},
	urldate = {2015-04-29TZ},
	booktitle = {Natural {Language} {Processing} and {Information} {Systems}},
	publisher = {Springer},
	author = {Freitas, André and Oliveira, João Gabriel and O’Riain, Seán and Curry, Edward and Da Silva, João Carlos Pereira},
	year = {2011},
	pages = {40--51}
}

@inproceedings{sen_towards_2015,
	address = {Menlo Park, CA},
	title = {Towards {Domain}-{Specific} {SR}: {A} {Case} {Study} from {Geography}},
	booktitle = {Proceedings of {IJCAI} 2015},
	publisher = {AAAI Press},
	author = {Sen, Shilad W. and Johnson, Isaac and Harper, Rebecca and Mai, Huy and Olsen, Samuel H. and Mathers, Benjamin and Vonessen, Laura Souza and Wright, Matthew and Hecht, Brent},
	year = {2015}
}

@inproceedings{quercini_uncovering_2014,
	title = {Uncovering the spatial relatedness in {Wikipedia}},
	url = {https://hal-supelec.archives-ouvertes.fr/hal-01105367/},
	urldate = {2015-04-29TZ},
	booktitle = {{ACM} {SIGSPATIAL} 2014},
	author = {Quercini, Gianluca and Hanan, Samet},
	year = {2014}
}

@misc{noauthor_computers_nodate,
	title = {A computers understanding of literature},
	url = {http://www.academia.edu/2088904/A_computers_understanding_of_literature},
	abstract = {A computers understanding of literature},
	urldate = {2015-04-29TZ}
}

@inproceedings{sen_barriers_2015,
	title = {Barriers to the {Localness} of {Volunteered} {Geographic} {Information}},
	url = {http://ironholds.org/papers/barriers.pdf},
	urldate = {2015-04-29TZ},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sen, Shilad W. and Ford, Heather and Musicant, David R. and Graham, Mark and Keyes, Oliver SB and Hecht, Brent},
	year = {2015},
	pages = {197--206}
}

@inproceedings{bergstrom_conversation_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Conversation {Clusters}: {Grouping} {Conversation} {Topics} {Through} {Human}-computer {Dialog}},
	isbn = {978-1-60558-246-7},
	shorttitle = {Conversation {Clusters}},
	url = {http://doi.acm.org/10.1145/1518701.1519060},
	doi = {10.1145/1518701.1519060},
	abstract = {Conversation Clusters explores the use of visualization to highlight salient moments of live conversation while archiving a meeting. Cheaper storage and easy access to recording devices allows extensive archival. However, as the size of the archive grows, retrieving the desired moments becomes increasingly difficult. We approach this problem from a socio-technical perspective and utilize human intuition aided by computer memory. We present computationally detected topics of conversation as visual summaries of discussion and as reference points into the archive. To further bootstrap the system, humans can participate in a dialog with the visualization of the clustering process and shape the development of clustering models.},
	urldate = {2015-04-29TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bergstrom, Tony and Karahalios, Karrie},
	year = {2009},
	keywords = {clustering, meeting archival, visualization},
	pages = {2349--2352}
}

@inproceedings{gilbert_blogs_2009,
	title = {Blogs are {Echo} {Chambers}: {Blogs} are {Echo} {Chambers}},
	shorttitle = {Blogs are {Echo} {Chambers}},
	doi = {10.1109/HICSS.2009.91},
	abstract = {In the last decade, blogs have exploded in number, popularity and scope. However, many commentators and researchers speculate that blogs isolate readers in echo chambers, cutting them off from dissenting opinions. Our empirical paper tests this hypothesis. Using a hand-coded sample of over 1,000 comments from 33 of the world's top blogs, we find that agreement outnumbers disagreement in blog comments by more than 3 to 1. However, this ratio depends heavily on a blog's genre, varying between 2 to 1 and 9 to 1. Using these hand-coded blog comments as input, we also show that natural language processing techniques can identify the linguistic markers of agreement. We conclude by applying our empirical and algorithmic findings to practical implications for blogs, and discuss the many questions raised by our work.},
	booktitle = {42nd {Hawaii} {International} {Conference} on {System} {Sciences}, 2009. {HICSS} '09},
	author = {Gilbert, E. and Bergstrom, T. and Karahalios, K.},
	month = jan,
	year = {2009},
	keywords = {Blogs, Couplings, Humans, Lead, Milling machines, Nominations and elections, Polarization, Psychology, Testing, Web sites, echo chambers, hand-coded blog comments, linguistic markers, natural language processing, natural language processing techniques},
	pages = {1--10}
}

@inproceedings{schuhmacher_knowledge-based_2014,
	address = {New York, NY, USA},
	series = {{WSDM} '14},
	title = {Knowledge-based {Graph} {Document} {Modeling}},
	isbn = {978-1-4503-2351-2},
	url = {http://doi.acm.org/10.1145/2556195.2556250},
	doi = {10.1145/2556195.2556250},
	abstract = {We propose a graph-based semantic model for representing document content. Our method relies on the use of a semantic network, namely the DBpedia knowledge base, for acquiring fine-grained information about entities and their semantic relations, thus resulting in a knowledge-rich document model. We demonstrate the benefits of these semantic representations in two tasks: entity ranking and computing document semantic similarity. To this end, we couple DBpedia's structure with an information-theoretic measure of concept association, based on its explicit semantic relations, and compute semantic similarity using a Graph Edit Distance based measure, which finds the optimal matching between the documents' entities using the Hungarian method. Experimental results show that our general model outperforms baselines built on top of traditional methods, and achieves a performance close to that of highly specialized methods that have been tuned to these specific tasks.},
	urldate = {2015-04-29TZ},
	booktitle = {Proceedings of the 7th {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Schuhmacher, Michael and Ponzetto, Simone Paolo},
	year = {2014},
	keywords = {dbpedia, document modeling, document semantic similarity, entity relatedness, semantic network mining},
	pages = {543--552}
}

@inproceedings{radinsky_word_2011,
	address = {New York, NY, USA},
	series = {{WWW} '11},
	title = {A {Word} at a {Time}: {Computing} {Word} {Relatedness} {Using} {Temporal} {Semantic} {Analysis}},
	isbn = {978-1-4503-0632-4},
	shorttitle = {A {Word} at a {Time}},
	url = {http://doi.acm.org/10.1145/1963405.1963455},
	doi = {10.1145/1963405.1963455},
	abstract = {Computing the degree of semantic relatedness of words is a key functionality of many language applications such as search, clustering, and disambiguation. Previous approaches to computing semantic relatedness mostly used static language resources, while essentially ignoring their temporal aspects. We believe that a considerable amount of relatedness information can also be found in studying patterns of word usage over time. Consider, for instance, a newspaper archive spanning many years. Two words such as "war" and "peace" might rarely co-occur in the same articles, yet their patterns of use over time might be similar. In this paper, we propose a new semantic relatedness model, Temporal Semantic Analysis (TSA), which captures this temporal information. The previous state of the art method, Explicit Semantic Analysis (ESA), represented word semantics as a vector of concepts. TSA uses a more refined representation, where each concept is no longer scalar, but is instead represented as time series over a corpus of temporally-ordered documents. To the best of our knowledge, this is the first attempt to incorporate temporal evidence into models of semantic relatedness. Empirical evaluation shows that TSA provides consistent improvements over the state of the art ESA results on multiple benchmarks.},
	urldate = {2015-04-29TZ},
	booktitle = {Proceedings of the 20th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Radinsky, Kira and Agichtein, Eugene and Gabrilovich, Evgeniy and Markovitch, Shaul},
	year = {2011},
	keywords = {semantic analysis, semantic similarity, temporal dynamics, temporal semantics, word relatedness},
	pages = {337--346}
}

@article{pfeil_cultural_2006,
	title = {Cultural {Differences} in {Collaborative} {Authoring} of {Wikipedia}},
	volume = {12},
	issn = {1083-6101},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1083-6101.2006.00316.x/abstract},
	doi = {10.1111/j.1083-6101.2006.00316.x},
	abstract = {This article explores the relationship between national culture and computer-mediated communication (CMC) in Wikipedia. The articles on the topic game from the French, German, Japanese, and Dutch Wikipedia websites were studied using content analysis methods. Correlations were investigated between patterns of contributions and the four dimensions of cultural influences proposed by Hofstede (Power Distance, Collectivism versus Individualism, Femininity versus Masculinity, and Uncertainty Avoidance). The analysis revealed cultural differences in the style of contributions across the cultures investigated, some of which are correlated with the dimensions identified by Hofstede. These findings suggest that cultural differences that are observed in the physical world also exist in the virtual world.},
	language = {en},
	number = {1},
	urldate = {2015-04-29TZ},
	journal = {Journal of Computer-Mediated Communication},
	author = {Pfeil, Ulrike and Zaphiris, Panayiotis and Ang, Chee Siang},
	month = oct,
	year = {2006},
	pages = {88--113}
}

@article{pfeil_cultural_2006-1,
	title = {Cultural differences in collaborative authoring of {Wikipedia}},
	volume = {12},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1083-6101.2006.00316.x/full},
	number = {1},
	urldate = {2015-04-29TZ},
	journal = {Journal of Computer-Mediated Communication},
	author = {Pfeil, Ulrike and Zaphiris, Panayiotis and Ang, Chee Siang},
	year = {2006},
	pages = {88--113}
}

@inproceedings{filatova_multilingual_2009,
	title = {Multilingual wikipedia, summarization, and information trustworthiness},
	url = {http://storm.cis.fordham.edu/~filatova/PDFfiles/FilatovaCLIR2009.pdf},
	urldate = {2015-04-29TZ},
	booktitle = {{SIGIR} workshop on information access in a multilingual world},
	author = {Filatova, Elena},
	year = {2009}
}

@article{arbia_effects_1996,
	title = {Effects of {MUAP} on image classification},
	volume = {1},
	journal = {Geographical Systems},
	author = {Arbia, Giuseppe and Benedetti, R and Espa, G},
	year = {1996},
	pages = {123--141}
}

@incollection{hecht_beginners_2011,
	title = {A {Beginner}’s {Guide} to {Geographic} {Virtual} {Communities} {Research}},
	volume = {2},
	booktitle = {Handbook of {Research} on {Methods} and {Techniques} for {Studying} {Virtual} {Communities}: {Paradigms} and {Phenomena}},
	publisher = {IGI Global},
	author = {Hecht, Brent and Gergle, Darren},
	year = {2011}
}

@inproceedings{bao_omnipedia:_2012,
	title = {Omnipedia: bridging the wikipedia language gap},
	shorttitle = {Omnipedia},
	url = {http://dl.acm.org/citation.cfm?id=2208553},
	urldate = {2014-09-15TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bao, Patti and Hecht, Brent and Carton, Samuel and Quaderi, Mahmood and Horn, Michael and Gergle, Darren},
	year = {2012},
	pages = {1075--1084}
}

@inproceedings{hecht_tower_2010,
	title = {The tower of {Babel} meets web 2.0: user-generated content and its applications in a multilingual context},
	shorttitle = {The tower of {Babel} meets web 2.0},
	url = {http://dl.acm.org/citation.cfm?id=1753370},
	urldate = {2014-09-15TZ},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Hecht, Brent and Gergle, Darren},
	year = {2010},
	pages = {291--300}
}

@misc{u.s._census_bureau_american_nodate,
	title = {American {Community} {Survey} 2008-2012 {Summary} {File}},
	author = {U.S. Census Bureau}
}

@misc{office_american_nodate,
	title = {American {Community} {Survey}},
	url = {https://www.census.gov/acs/www/},
	abstract = {The American Community Survey (ACS) is an ongoing Census Bureau survey that samples a small percentage of the population every year. The ACS provides statistics yearly -- giving communities the current information they need to manage change.},
	language = {EN-US},
	urldate = {2014-07-02TZ},
	author = {Office, American Community Survey},
	note = {The American Community Survey (ACS) is an ongoing Census Bureau survey that samples a small percentage of the population every year. The ACS provides statistics yearly -- giving communities the current information they need to manage change.},
	keywords = {american community survey, data, main, main page, respond to acs}
}

@article{kuznetsov_motivations_2006,
	title = {Motivations of contributors to {Wikipedia}},
	volume = {36},
	url = {http://dl.acm.org/citation.cfm?id=1215943},
	number = {2},
	urldate = {2014-07-01TZ},
	journal = {ACM SIGCAS computers and society},
	author = {Kuznetsov, Stacey},
	year = {2006},
	pages = {1}
}

@article{reagle_gender_2011,
	title = {Gender bias in {Wikipedia} and {Britannica}},
	volume = {5},
	url = {http://ijoc.org/index.php/ijoc/article/viewArticle/777},
	urldate = {2014-07-01TZ},
	journal = {International Journal of Communication},
	author = {Reagle, Joseph and Rhue, Lauren},
	year = {2011},
	pages = {21}
}

@misc{noauthor_list_2014,
	title = {List of {Wikipedias}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://en.wikipedia.org/w/index.php?title=List_of_Wikipedias&oldid=613664117},
	abstract = {This is a list of many of the different language editions of Wikipedia; as of August 2012, there were 285 Wikipedias. For their number of articles, see the main list.},
	language = {en},
	urldate = {2014-07-01TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = jul,
	year = {2014},
	note = {Page Version ID: 613664117}
}

@article{goodchild_towards_2007,
	title = {Towards a general theory of geographic representation in {GIS}},
	volume = {21},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13658810600965271},
	number = {3},
	urldate = {2014-07-01TZ},
	journal = {International journal of geographical information science},
	author = {Goodchild, Michael F. and Yuan, May and Cova, Thomas J.},
	year = {2007},
	pages = {239--260}
}

@book{daniel_handbook_2010,
	title = {Handbook of {Research} on {Methods} and {Techniques} for {Studying} {Virtual} {Communities}: {Paradigms} and {Phenomena}},
	isbn = {9781609600402, 9781609600419},
	shorttitle = {Handbook of {Research} on {Methods} and {Techniques} for {Studying} {Virtual} {Communities}},
	url = {http://www.igi-global.com/chapter/beginner-guide-geographic-virtual-communities/50349},
	urldate = {2014-07-01TZ},
	publisher = {IGI Global},
	editor = {Daniel, Ben Kei},
	month = nov,
	year = {2010}
}

@book{daniel_handbook_2010-1,
	title = {Handbook of {Research} on {Methods} and {Techniques} for {Studying} {Virtual} {Communities}: {Paradigms} and {Phenomena}},
	isbn = {9781609600402, 9781609600419},
	shorttitle = {Handbook of {Research} on {Methods} and {Techniques} for {Studying} {Virtual} {Communities}},
	url = {http://www.igi-global.com/chapter/beginner-guide-geographic-virtual-communities/50349},
	urldate = {2014-07-01TZ},
	publisher = {IGI Global},
	editor = {Daniel, Ben Kei},
	month = nov,
	year = {2010}
}

@misc{noauthor_mapquest_nodate,
	title = {{MapQuest}},
	url = {http://www.mapquest.com/},
	urldate = {2014-07-01TZ},
	journal = {MapQuest}
}

@article{elith_working_2008,
	title = {A working guide to boosted regression trees},
	volume = {77},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2656.2008.01390.x/full},
	number = {4},
	urldate = {2014-07-01TZ},
	journal = {Journal of Animal Ecology},
	author = {Elith, Jane and Leathwick, John R. and Hastie, Trevor},
	year = {2008},
	pages = {802--813}
}

@article{hall_weka_2009,
	title = {The {WEKA} data mining software: an update},
	volume = {11},
	shorttitle = {The {WEKA} data mining software},
	url = {http://dl.acm.org/citation.cfm?id=1656278},
	number = {1},
	urldate = {2014-07-01TZ},
	journal = {ACM SIGKDD explorations newsletter},
	author = {Hall, Mark and Frank, Eibe and Holmes, Geoffrey and Pfahringer, Bernhard and Reutemann, Peter and Witten, Ian H.},
	year = {2009},
	pages = {10--18}
}

@inproceedings{finkelstein_placing_2001,
	title = {Placing search in context: {The} concept revisited},
	shorttitle = {Placing search in context},
	url = {http://dl.acm.org/citation.cfm?id=372094},
	urldate = {2014-07-01TZ},
	booktitle = {Proceedings of the 10th international conference on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Finkelstein, Lev and Gabrilovich, Evgeniy and Matias, Yossi and Rivlin, Ehud and Solan, Zach and Wolfman, Gadi and Ruppin, Eytan},
	year = {2001},
	pages = {406--414}
}

@inproceedings{hecht_measuring_2009,
	title = {Measuring self-focus bias in community-maintained knowledge repositories},
	url = {http://dl.acm.org/citation.cfm?id=1556463},
	urldate = {2014-07-01TZ},
	booktitle = {Proceedings of the fourth international conference on {Communities} and technologies},
	publisher = {ACM},
	author = {Hecht, Brent and Gergle, Darren},
	year = {2009},
	pages = {11--20}
}

@misc{noauthor_ethnologue:_nodate,
	title = {Ethnologue: {Languages} of the {World}},
	url = {http://www.ethnologue.com/},
	urldate = {2014-07-01TZ},
	journal = {Ethnologue: Languages of the World}
}

@article{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2014-06-29TZ},
	journal = {arXiv:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = jan,
	year = {2013},
	note = {arXiv: 1301.3781},
	keywords = {Computer Science - Computation and Language}
}

@misc{noauthor_wikipedia:wikipedians_2014,
	title = {Wikipedia:{Wikipedians}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	shorttitle = {Wikipedia},
	url = {http://en.wikipedia.org/w/index.php?title=Wikipedia:Wikipedians&oldid=610845239},
	abstract = {Wikipedians are people who write and edit the pages for Wikipedia, unlike readers who simply read the articles. Anyone can be a Wikipedian—including you. Just click the edit link at the top of any page, or at the beginning of each section. Visit the editing tutorial to learn more. You can browse or search the full user list, or request a random Wikipedian's user page.},
	language = {en},
	urldate = {2014-06-13TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = jun,
	year = {2014},
	note = {Page Version ID: 610845239}
}

@misc{noauthor_wikipedia:largest_2014,
	title = {Wikipedia:{Largest} encyclopedia},
	copyright = {Creative Commons Attribution-ShareAlike License},
	shorttitle = {Wikipedia},
	url = {http://en.wikipedia.org/w/index.php?title=Wikipedia:Largest_encyclopedia&oldid=585930832},
	abstract = {[This was a proposed article to link to on the Wikipedia main page]},
	language = {en},
	urldate = {2014-06-13TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = jun,
	year = {2014},
	note = {Page Version ID: 585930832}
}

@article{tobler_computer_1970,
	title = {A computer movie simulating urban growth in the {Detroit} region},
	url = {http://www.jstor.org/stable/143141},
	urldate = {2014-06-13TZ},
	journal = {Economic geography},
	author = {Tobler, Waldo R.},
	year = {1970},
	pages = {234--240}
}

@article{barnes_paper_2004-1,
	title = {A paper related to everything but more related to local things},
	volume = {94},
	url = {http://www.tandfonline.com/doi/full/10.1111/j.1467-8306.2004.09402004.x},
	number = {2},
	urldate = {2014-06-13TZ},
	journal = {Annals of the Association of American Geographers},
	author = {Barnes, Trevor J.},
	year = {2004},
	pages = {278--283}
}

@inproceedings{suchanek_yago:_2007,
	title = {Yago: a core of semantic knowledge},
	shorttitle = {Yago},
	url = {http://dl.acm.org/citation.cfm?id=1242667},
	urldate = {2014-06-13TZ},
	booktitle = {Proceedings of the 16th international conference on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
	year = {2007},
	pages = {697--706}
}
@article{hepp_harvesting_2007,
	title = {Harvesting wiki consensus: {Using} wikipedia entries as vocabulary for knowledge management},
	volume = {11},
	shorttitle = {Harvesting wiki consensus},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4305569},
	number = {5},
	urldate = {2014-06-13TZ},
	journal = {Internet Computing, IEEE},
	author = {Hepp, Martin and Siorpaes, Katharina and Bachlechner, Daniel},
	year = {2007},
	pages = {54--65}
}

@inproceedings{kazama_exploiting_2007,
	title = {Exploiting {Wikipedia} as external knowledge for named entity recognition},
	booktitle = {Joint {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and {Computational} {Natural} {Language} {Learning}},
	author = {Kazama, Jun’ichi and Torisawa, Kentaro},
	year = {2007},
	pages = {698--707}
}

@article{medelyan_mining_2009,
	title = {Mining meaning from {Wikipedia}},
	volume = {67},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581909000561},
	number = {9},
	urldate = {2014-06-13TZ},
	journal = {International Journal of Human-Computer Studies},
	author = {Medelyan, Olena and Milne, David and Legg, Catherine and Witten, Ian H.},
	year = {2009},
	pages = {716--754}
}

@inproceedings{banerjee_clustering_2007,
	title = {Clustering short texts using wikipedia},
	url = {http://dl.acm.org/citation.cfm?id=1277909},
	urldate = {2014-06-13TZ},
	booktitle = {Proceedings of the 30th annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {ACM},
	author = {Banerjee, Somnath and Ramanathan, Krishnan and Gupta, Ajay},
	year = {2007},
	pages = {787--788}
}

@inproceedings{cucerzan_large-scale_2007,
	title = {Large-{Scale} {Named} {Entity} {Disambiguation} {Based} on {Wikipedia} {Data}.},
	volume = {7},
	booktitle = {{EMNLP}-{CoNLL}},
	author = {Cucerzan, Silviu},
	year = {2007},
	pages = {708--716}
}

@inproceedings{adler_assigning_2008,
	title = {Assigning trust to {Wikipedia} content},
	url = {http://dl.acm.org/citation.cfm?id=1822293},
	urldate = {2014-06-13TZ},
	booktitle = {Proceedings of the 4th {International} {Symposium} on {Wikis}},
	publisher = {ACM},
	author = {Adler, B. Thomas and Chatterjee, Krishnendu and De Alfaro, Luca and Faella, Marco and Pye, Ian and Raman, Vishwanath},
	year = {2008},
	pages = {26}
}

@article{fabrikant_first_2002,
	title = {The first law of cognitive geography: {Distance} and similarity in semantic space},
	shorttitle = {The first law of cognitive geography},
	url = {http://geog.ucsb.edu/~sara/html/research/pubs/fabrikant_etal_gis02.pdf},
	urldate = {2014-06-13TZ},
	journal = {Proceedings of GIScience 2002},
	author = {Fabrikant, Sara Irina and Ruocco, Marco and Middleton, Richard and Montello, Daniel R. and Jörgensen, Corinne},
	year = {2002},
	pages = {31--33}
}

@article{kalipeni_using_2008,
	title = {Using {GIS} to model and forecast {HIV}/{AIDS} rates in {Africa}, 1986–2010},
	volume = {60},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00330120701724061},
	number = {1},
	urldate = {2014-06-13TZ},
	journal = {The professional geographer},
	author = {Kalipeni, Ezekiel and Zulu, Leo},
	year = {2008},
	pages = {33--53}
}

@article{oloughlin_bringing_1991,
	title = {Bringing geography back to the study of international relations: {Spatial} dependence and regional context in {Africa}, 1966–1978},
	volume = {17},
	shorttitle = {Bringing geography back to the study of international relations},
	url = {http://www.tandfonline.com/doi/abs/10.1080/03050629108434769},
	number = {1},
	urldate = {2014-06-13TZ},
	journal = {International Interactions},
	author = {O'loughlin, John and Anselin, Luc},
	year = {1991},
	pages = {29--61}
}

@article{bjorholm_what_2008,
	title = {To what extent does {Tobler}'s 1st law of geography apply to macroecology? {A} case study using {American} palms ({Arecaceae})},
	volume = {8},
	shorttitle = {To what extent does {Tobler}'s 1st law of geography apply to macroecology?},
	url = {http://www.biomedcentral.com/1472-6785/8/11},
	number = {1},
	urldate = {2014-06-13TZ},
	journal = {BMC ecology},
	author = {Bjorholm, Stine and Svenning, Jens-Christian and Skov, Flemming and Balslev, Henrik},
	year = {2008},
	pages = {11}
}

@article{ping_exploring_2004,
	title = {Exploring spatial dependence of cotton yield using global and local autocorrelation statistics},
	volume = {89},
	url = {http://www.sciencedirect.com/science/article/pii/S0378429004000693},
	number = {2},
	urldate = {2014-06-13TZ},
	journal = {Field Crops Research},
	author = {Ping, J. L. and Green, C. J. and Zartman, R. E. and Bronson, K. F.},
	year = {2004},
	pages = {219--236}
}

@book{cressie_statistics_1993,
	title = {Statistics for spatial data},
	volume = {900},
	url = {http://pakapaka.6f.sk/134/Statistics%20for%20Spatial%20Data.pdf},
	urldate = {2014-06-13TZ},
	publisher = {Wiley New York},
	author = {Cressie, Noel AC and Cassie, Noel A.},
	year = {1993}
}

@book{goovaerts_geostatistics_1997,
	title = {Geostatistics for natural resources evaluation},
	url = {http://books.google.com/books?hl=en&lr=&id=CW-7tHAaVR0C&oi=fnd&pg=PA3&dq=Geostatistics+for+Natural+Resources+Evaluation&ots=zioeAP8Iry&sig=ypnWPcVyOtlgVhks_-2u1ximPIw},
	urldate = {2014-06-13TZ},
	publisher = {Oxford university press},
	author = {Goovaerts, Pierre},
	year = {1997}
}

@book{burrough_principles_1998,
	title = {Principles of geographical information systems},
	volume = {333},
	url = {http://www.rc.unesp.br/igce/geologia/GAA01048/papers/Burrough_McDonnell-Two.pdf},
	urldate = {2014-06-13TZ},
	publisher = {Oxford university press Oxford},
	author = {Burrough, Peter A. and McDonnell, Rachael and Burrough, Peter A. and McDonnell, Rachael},
	year = {1998}
}

@incollection{montello_testing_2003,
	title = {Testing the first law of cognitive geography on point-display spatializations},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-39923-0_21},
	urldate = {2014-06-13TZ},
	booktitle = {Spatial {Information} {Theory}. {Foundations} of {Geographic} {Information} {Science}},
	publisher = {Springer},
	author = {Montello, Daniel R. and Fabrikant, Sara Irina and Ruocco, Marco and Middleton, Richard S.},
	year = {2003},
	pages = {316--331}
}

@article{hoffart_yago2:_2013,
	title = {{YAGO}2: {A} spatially and temporally enhanced knowledge base from {Wikipedia}},
	volume = {194},
	shorttitle = {{YAGO}2},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370212000719},
	urldate = {2014-06-13TZ},
	journal = {Artificial Intelligence},
	author = {Hoffart, Johannes and Suchanek, Fabian M. and Berberich, Klaus and Weikum, Gerhard},
	year = {2013},
	pages = {28--61}
}

@article{egozi_concept-based_2011,
	title = {Concept-based information retrieval using explicit semantic analysis},
	volume = {29},
	url = {http://dl.acm.org/citation.cfm?id=1961211},
	number = {2},
	urldate = {2014-06-13TZ},
	journal = {ACM Transactions on Information Systems (TOIS)},
	author = {Egozi, Ofer and Markovitch, Shaul and Gabrilovich, Evgeniy},
	year = {2011},
	pages = {8}
}

@article{ballatore_evaluative_2014,
	title = {An evaluative baseline for geo-semantic relatedness and similarity},
	url = {http://link.springer.com/article/10.1007/s10707-013-0197-8},
	urldate = {2014-06-13TZ},
	journal = {GeoInformatica},
	author = {Ballatore, Andrea and Bertolotto, Michela and Wilson, David C.},
	year = {2014},
	pages = {1--21}
}

@inproceedings{hecht_explanatory_2012,
	title = {Explanatory semantic relatedness and explicit spatialization for exploratory search},
	url = {http://dl.acm.org/citation.cfm?id=2348341},
	urldate = {2014-06-13TZ},
	booktitle = {Proceedings of the 35th international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {ACM},
	author = {Hecht, Brent and Carton, Samuel H. and Quaderi, Mahmood and Schöning, Johannes and Raubal, Martin and Gergle, Darren and Downey, Doug},
	year = {2012},
	pages = {415--424}
}

@inproceedings{yeh_wikiwalk:_2009,
	title = {{WikiWalk}: random walks on {Wikipedia} for semantic relatedness},
	shorttitle = {{WikiWalk}},
	url = {http://dl.acm.org/citation.cfm?id=1708133},
	urldate = {2014-06-13TZ},
	booktitle = {Proceedings of the 2009 {Workshop} on {Graph}-based {Methods} for {Natural} {Language} {Processing}},
	publisher = {ACL},
	author = {Yeh, Eric and Ramage, Daniel and Manning, Christopher D. and Agirre, Eneko and Soroa, Aitor},
	year = {2009},
	pages = {41--49}
}

@inproceedings{witten_effective_2008,
	title = {An effective, low-cost measure of semantic relatedness obtained from {Wikipedia} links},
	url = {http://www.aaai.org/Papers/Workshops/2008/WS-08-15/WS08-15-005.pdf},
	urldate = {2014-06-13TZ},
	booktitle = {Proceeding of {AAAI} {Workshop} on {Wikipedia} and {Artificial} {Intelligence}: an {Evolving} {Synergy}, {AAAI} {Press}, {Chicago}, {USA}},
	author = {Witten, I. and Milne, David},
	year = {2008},
	pages = {25--30}
}

@inproceedings{strube_wikirelate!_2006,
	title = {{WikiRelate}! {Computing} semantic relatedness using {Wikipedia}},
	volume = {6},
	url = {http://www.aaai.org/Papers/AAAI/2006/AAAI06-223.pdf},
	urldate = {2014-06-13TZ},
	booktitle = {{AAAI}},
	author = {Strube, Michael and Ponzetto, Simone Paolo},
	year = {2006},
	pages = {1419--1424}
}

@misc{noauthor_wikipedia:size_2014,
	title = {Wikipedia:{Size} of {Wikipedia}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	shorttitle = {Wikipedia},
	url = {http://en.wikipedia.org/w/index.php?title=Wikipedia:Size_of_Wikipedia&oldid=610372767},
	abstract = {This Wikipedia:Statistics page measures the size of the English-language edition of Wikipedia; mostly page and article count. There are currently 4,534,070 articles in the English Wikipedia.},
	language = {en},
	urldate = {2014-06-13TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = jun,
	year = {2014},
	note = {Page Version ID: 610372767}
}

@misc{noauthor_list_2014,
	title = {List of {Wikipedias}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {http://en.wikipedia.org/w/index.php?title=List_of_Wikipedias&oldid=612667819},
	abstract = {This is a list of many of the different language editions of Wikipedia; as of August 2012, there were 285 Wikipedias. For their number of articles, see the main list.},
	language = {en},
	urldate = {2014-06-13TZ},
	journal = {Wikipedia, the free encyclopedia},
	month = jun,
	year = {2014},
	note = {Page Version ID: 612667819}
}

@incollection{hecht_terabytes_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Terabytes of {Tobler}: {Evaluating} the {First} {Law} in a {Massive}, {Domain}-{Neutral} {Representation} of {World} {Knowledge}},
	copyright = {©2009 Springer Berlin Heidelberg},
	isbn = {978-3-642-03831-0, 978-3-642-03832-7},
	shorttitle = {Terabytes of {Tobler}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-03832-7_6},
	abstract = {The First Law of Geography states, “everything is related to everything else, but near things are more related than distant things.” Despite the fact that it is to a large degree what makes “spatial special,” the law has never been empirically evaluated on a large, domain-neutral representation of world knowledge. We address the gap in the literature about this critical idea by statistically examining the multitude of entities and relations between entities present across 22 different language editions of Wikipedia. We find that, at least according to the myriad authors of Wikipedia, the First Law is true to an overwhelming extent regardless of language-defined cultural domain.},
	number = {5756},
	urldate = {2014-06-13TZ},
	booktitle = {Spatial {Information} {Theory}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hecht, Brent and Moxley, Emily},
	editor = {Hornsby, Kathleen Stewart and Claramunt, Christophe and Denis, Michel and Ligozat, Gérard},
	month = jan,
	year = {2009},
	keywords = {Data Mining and Knowledge Discovery, Data Structures, Database Management, First Law of Geography, Geographical Information Systems/Cartography, Information Systems and Communication Service, Models and Principles, Spatial Autocorrelation, Spatial Dependence, Tobler’s Law, Wikipedia},
	pages = {88--105}
}

@inproceedings{liu2018learning,
author = {Liu, Thomas F. and Craft, Mark and Situ, Jason and Yumer, Ersin and Mech, Radomir and Kumar, Ranjitha},
title = {Learning Design Semantics for Mobile Apps},
year = {2018},
isbn = {9781450359481},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242587.3242650},
doi = {10.1145/3242587.3242650},
booktitle = {Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
pages = {569–579},
numpages = {11},
keywords = {design semantics, mobile app design, machine learning},
location = {Berlin, Germany},
series = {UIST ’18}
}

@inproceedings{grudin2019chatbots,
  title={Chatbots, humbots, and the quest for artificial general intelligence},
  author={Grudin, Jonathan and Jacques, Richard},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--11},
  year={2019}
}

@inproceedings{jiang2013users,
  title={How do users respond to voice input errors?: lexical and phonetic query reformulation in voice search},
  author={Jiang, Jiepu and Jeng, Wei and He, Daqing},
  booktitle={Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval},
  pages={143--152},
  year={2013},
  organization={ACM}
}

@inproceedings{jain2018evaluating,
  title={Evaluating and informing the design of chatbots},
  author={Jain, Mohit and Kumar, Pratyush and Kota, Ramachandra and Patel, Shwetak N},
  booktitle={Proceedings of the 2018 Designing Interactive Systems Conference},
  pages={895--906},
  year={2018},
  organization={ACM}
}

@article{jain2018farmchat,
  title={FarmChat: A Conversational Agent to Answer Farmer Queries},
  author={Jain, Mohit and Kumar, Pratyush and Bhansali, Ishita and Liao, Q Vera and Truong, Khai and Patel, Shwetak},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={2},
  number={4},
  pages={170},
  year={2018},
  publisher={ACM}
}

@article{bentley2018understanding,
author = {Bentley, Frank and Luvogt, Chris and Silverman, Max and Wirasinghe, Rushani and White, Brooke and Lottridge, Danielle},
title = {Understanding the Long-Term Use of Smart Speaker Assistants},
year = {2018},
issue_date = {September 2018},
publisher = {ACM},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3264901},
doi = {10.1145/3264901},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {Article 91},
numpages = {24},
keywords = {Mid-Scale Data Collection, Smart Speaker, Voice Assistants, Voice I/O, Google Home}
}

@inproceedings{ashktorab2019resilient,
  title={Resilient Chatbots: Repair Strategy Preferences for Conversational Breakdowns},
  author={Ashktorab, Zahra and Jain, Mohit and Liao, Q Vera and Weisz, Justin D},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={254},
  year={2019},
  organization={ACM}
}

@book{wallach1994language,
  title={Language learning disabilities in school-age children and adolescents: Some principles and applications},
  author={Wallach, Geraldine P and Butler, Katharine G},
  year={1994},
  publisher={Allyn \& Bacon}
}

@inproceedings{myers2018patterns,
  title={Patterns for how users overcome obstacles in voice user interfaces},
  author={Myers, Chelsea and Furqan, Anushay and Nebolsky, Jessica and Caro, Karina and Zhu, Jichen},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2018}
}

@article{bobrow1977gus,
  title={GUS, a frame-driven dialog system},
  author={Bobrow, Daniel G and Kaplan, Ronald M and Kay, Martin and Norman, Donald A and Thompson, Henry and Winograd, Terry},
  journal={Artificial intelligence},
  volume={8},
  number={2},
  pages={155--173},
  year={1977},
  publisher={Elsevier}
}

@article{jurafsky_martin_2019,
    title={Dialogue Systems and Chatbots},
    booktitle={Speech and Language Processing},
    author={Jurafsky, Daniel and Martin, James H},
    journal={Speech and Language Processing},    
    year={2019}
}

@article{li2016deep,
  title={Deep reinforcement learning for dialogue generation},
  author={Li, Jiwei and Monroe, Will and Ritter, Alan and Galley, Michel and Gao, Jianfeng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1606.01541},
  year={2016}
}

@inproceedings{li2017adversarial,
    title = "Adversarial Learning for Neural Dialogue Generation",
    author = "Li, Jiwei  and
      Monroe, Will  and
      Shi, Tianlin  and
      Jean, S{\'e}bastien  and
      Ritter, Alan  and
      Jurafsky, Dan",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1230",
    doi = "10.18653/v1/D17-1230",
    pages = "2157--2169",
    abstract = "We apply adversarial training to open-domain dialogue generation, training a system to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning problem where we jointly train two systems: a generative model to produce response sequences, and a discriminator{---}analagous to the human evaluator in the Turing test{---} to distinguish between the human-generated dialogues and the machine-generated ones. In this generative adversarial network approach, the outputs from the discriminator are used to encourage the system towards more human-like dialogue. Further, we investigate models for adversarial evaluation that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls. Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines",
}

@inproceedings{serban2016building,
  title={Building end-to-end dialogue systems using generative hierarchical neural network models},
  author={Serban, Iulian V and Sordoni, Alessandro and Bengio, Yoshua and Courville, Aaron and Pineau, Joelle},
  booktitle={The 30th AAAI Conference on Artificial Intelligence (AAAI '16)},
  year={2016}
}

@article{wu2019sequential,
    title = "A Sequential Matching Framework for Multi-Turn Response Selection in Retrieval-Based Chatbots",
    author = "Wu, Yu  and
      Wu, Wei  and
      Xing, Chen  and
      Xu, Can  and
      Li, Zhoujun  and
      Zhou, Ming",
    journal = "Computational Linguistics",
    volume = "45",
    number = "1",
    month = mar,
    year = "2019",
    url = "https://www.aclweb.org/anthology/J19-1005",
    doi = "10.1162/coli_a_00345",
    pages = "163--197",
    abstract = "We study the problem of response selection for multi-turn conversation in retrieval-based chatbots. The task involves matching a response candidate with a conversation context, the challenges for which include how to recognize important parts of the context, and how to model the relationships among utterances in the context. Existing matching methods may lose important information in contexts as we can interpret them with a unified framework in which contexts are transformed to fixed-length vectors without any interaction with responses before matching. This motivates us to propose a new matching framework that can sufficiently carry important information in contexts to matching and model relationships among utterances at the same time. The new framework, which we call a sequential matching framework (SMF), lets each utterance in a context interact with a response candidate at the first step and transforms the pair to a matching vector. The matching vectors are then accumulated following the order of the utterances in the context with a recurrent neural network (RNN) that models relationships among utterances. Context-response matching is then calculated with the hidden states of the RNN. Under SMF, we propose a sequential convolutional network and sequential attention network and conduct experiments on two public data sets to test their performance. Experiment results show that both models can significantly outperform state-of-the-art matching methods. We also show that the models are interpretable with visualizations that provide us insights on how they capture and leverage important information in contexts for matching.",
}

@article{McTear2005Handling,
title = "Handling errors and determining confirmation strategies—An object-based approach",
journal = "Speech Communication",
volume = "45",
number = "3",
pages = "249 - 269",
year = "2005",
note = "Special Issue on Error Handling in Spoken Dialogue Systems",
issn = "0167-6393",
doi = "10.1016/j.specom.2004.11.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167639304001426",
author = "Michael McTear and Ian O’Neill and Philip Hanna and Xingkun Liu",
keywords = "Object-based dialogue management, Grounding, Information state, Error handling",
abstract = "A number of different approaches have been applied to the treatment of errors in spoken dialogue systems, including careful design to prevent potential errors, methods for on-line error detection, and error recovery when errors have occurred and have been detected. The approach to error handling presented here is premised on the theory of grounding, in which it is assumed that errors cannot be avoided in spoken dialogue and that it is more useful to focus on methods for determining what information needs to be grounded within a dialogue and how this grounding should be achieved. An object-based architecture is presented that incorporates generic confirmation strategies in combination with domain-specific heuristics that together contribute to determining the system’s confirmation strategies when attempting to complete a transaction. The system makes use of a representation of the system’s information state as it conducts a transaction along with discourse pegs that are used to determine whether values have been sufficiently confirmed for a transaction to be concluded. An empirical evaluation of the system is presented along with a discussion of the advantages of the object-based approach for error handling."
}

@misc{amazon_alexa_2020,
	title = {Alexa {Design} {Guide}},
	url = {https://developer.amazon.com/en-US/docs/alexa/alexa-design/get-started.html},
	abstract = {The emergence of voice user interfaces (VUIs), such as Amazon Alexa, isn’t an incremental improvement to existing technology; it marks a big shift in human-computer interaction....},
	language = {en-US},
	urldate = {2020-04-14},
	author = {Amazon},
	year = {2020},
	file = {Snapshot:/Users/toby/Zotero/storage/NP3QUQKB/get-started.html:text/html}
}

@inproceedings{Porcheron2018Voice,
author = {Porcheron, Martin and Fischer, Joel E. and Reeves, Stuart and Sharples, Sarah},
title = {Voice Interfaces in Everyday Life},
year = {2018},
isbn = {9781450356206},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174214},
doi = {10.1145/3173574.3174214},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
articleno = {Paper 640},
numpages = {12},
keywords = {ethnomethodology, collocated interaction, conversational user interface, intelligent personal assistants, conversation analysis, conversational agent, amazon echo},
location = {Montreal QC, Canada},
series = {CHI ’18}
}

@article{cho_role_2020,
	title = {The {Role} of {Conversational} {Grounding} in {Supporting} {Symbiosis} {Between} {People} and {Digital} {Assistants}},
	volume = {4},
	language = {en},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Cho, Janghee and Rader, Emilee},
	month = may,
	year = {2020},
	file = {Cho and Rader - The Role of Conversational Grounding in Supporting.pdf:/Users/toby/Zotero/storage/IAQDIG6V/Cho and Rader - The Role of Conversational Grounding in Supporting.pdf:application/pdf}
}

@inproceedings{Stumpf2007Toward,
author = {Stumpf, Simone and Rajaram, Vidya and Li, Lida and Burnett, Margaret and Dietterich, Thomas and Sullivan, Erin and Drummond, Russell and Herlocker, Jonathan},
title = {Toward Harnessing User Feedback for Machine Learning},
year = {2007},
isbn = {1595934812},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1216295.1216316},
doi = {10.1145/1216295.1216316},
booktitle = {Proceedings of the 12th International Conference on Intelligent User Interfaces},
pages = {82–91},
numpages = {10},
keywords = {user feedback for learning, machine learning, explanations},
location = {Honolulu, Hawaii, USA},
series = {IUI ’07}
}

@book{schwab2017fourth,
author = {Schwab, Klaus},
title = {The Fourth Industrial Revolution},
year = {2017},
isbn = {1524758868},
publisher = {Crown Publishing Group},
address = {USA},
abstract = {World-renowned economist Klaus Schwab, Founder and Executive Chairman of the World Economic Forum, explains that we have an opportunity to shape the fourth industrial revolution, which will fundamentally alter how we live and work. Schwab argues that this revolution is different in scale, scope and complexity from any that have come before. Characterized by a range of new technologies that are fusing the physical, digital and biological worlds, the developments are affecting all disciplines, economies, industries and governments, and even challenging ideas about what it means to be human. Artificial intelligence is already all around us, from supercomputers, drones and virtual assistants to 3D printing, DNA sequencing, smart thermostats, wearable sensors and microchips smaller than a grain of sand. But this is just the beginning: nanomaterials 200 times stronger than steel and a million times thinner than a strand of hair and the first transplant of a 3D printed liver are already in development. Imagine smart factories in which global systems of manufacturing are coordinated virtually, or implantable mobile phones made of biosynthetic materials. The fourth industrial revolution, says Schwab, is more significant, and its ramifications more profound, than in any prior period of human history. He outlines the key technologies driving this revolution and discusses the major impacts expected on government, business, civil society and individuals. Schwab also offers bold ideas on how to harness these changes and shape a better futureone in which technology empowers people rather than replaces them; progress serves society rather than disrupts it; and in which innovators respect moral and ethical boundaries rather than cross them. We all have the opportunity to contribute to developing new frameworks that advance progress.}
}

@article{qi2020generalized,
  title={A Generalized Earley Parser for Human Activity Parsing and Prediction},
  author={Qi, Siyuan and Jia, Baoxiong and Huang, Siyuan and Wei, Ping and Zhu, Song-Chun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}

@inproceedings{evensen-etal-2020-ruler,
    title = "Ruler: Data Programming by Demonstration for Document Labeling",
    author = "Evensen, Sara  and
      Ge, Chang  and
      Demiralp, Cagatay",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.181",
    doi = "10.18653/v1/2020.findings-emnlp.181",
    pages = "1996--2005",
    abstract = "Data programming aims to reduce the cost of curating training data by encoding domain knowledge as labeling functions over source data. As such it not only requires domain expertise but also programming experience, a skill that many subject matter experts lack. Additionally, generating functions by enumerating rules is not only time consuming but also inherently difficult, even for people with programming experience. In this paper we introduce Ruler, an interactive system that synthesizes labeling rules using span-level interactive demonstrations over document examples. Ruler is a first-of-a-kind implementation of data programming by demonstration (DPBD). This new framework aims to relieve users from the burden of writing labeling functions, enabling them to focus on higher-level semantic analysis, such as identifying relevant signals for the labeling task. We compare Ruler with conventional data programming through a user study conducted with 10 data scientists who were asked to create labeling functions for sentiment and spam classification tasks. Results show Ruler is easier to learn and to use, and that it offers higher overall user-satisfaction while providing model performances comparable to those achieved by conventional data programming.",
}

@inproceedings{yang2020doithere,
author = {Yang, Jackie (Junrui) and Lam, Monica S. and Landay, James A.},
title = {DoThisHere: Multimodal Interaction to Improve Cross-Application Tasks on Mobile Devices},
year = {2020},
isbn = {9781450375146},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379337.3415841},
doi = {10.1145/3379337.3415841},
abstract = {Many computing tasks, such as comparison shopping, two-factor authentication, and checking movie reviews, require using multiple apps together. On large screens, "windows, icons, menus, pointer" (WIMP) graphical user interfaces (GUIs) support easy sharing of content and context between multiple apps. So, it is straightforward to see the content from one application and write something relevant in another application, such as looking at the map around a place and typing walking instructions into an email. However, although today's smartphones also use GUIs, they have small screens and limited windowing support, making it hard to switch contexts and exchange data between apps. We introduce DoThisHere, a multimodal interaction technique that streamlines cross-app tasks and reduces the burden these tasks impose on users. Users can use voice to refer to information or app features that are off-screen and touch to specify where the relevant information should be inserted or is displayed. With DoThisHere, users can access information from or carry information to other apps with less context switching. We conducted a survey to find out what cross-app tasks people are currently performing or wish to perform on their smartphones. Among the 125 tasks that we collected from 75 participants, we found that 59 of these tasks are not well supported currently. DoThisHere is helpful in completing 95% of these unsupported tasks. A user study, where users are shown the list of supported voice commands when performing a representative sample of such tasks, suggests that DoThisHere may reduce expert users' cognitive load; the Query action, in particular, can help users reduce task completion time.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
pages = {35–44},
numpages = {10},
keywords = {multimodal interaction, voice interfaces, cross-app tasks},
location = {Virtual Event, USA},
series = {UIST '20}
}

@inproceedings{yao-etal-2020-imitation,
    title = "An Imitation Game for Learning Semantic Parsers from User Interaction",
    author = "Yao, Ziyu  and
      Tang, Yiqi  and
      Yih, Wen-tau  and
      Sun, Huan  and
      Su, Yu",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.559",
    doi = "10.18653/v1/2020.emnlp-main.559",
    pages = "6883--6902",
    abstract = "Despite the widely successful applications, bootstrapping and fine-tuning semantic parsers are still a tedious process with challenges such as costly data annotation and privacy risks. In this paper, we suggest an alternative, human-in-the-loop methodology for learning semantic parsers directly from users. A semantic parser should be introspective of its uncertainties and prompt for user demonstrations when uncertain. In doing so it also gets to imitate the user behavior and continue improving itself autonomously with the hope that eventually it may become as good as the user in interpreting their questions. To combat the sparsity of demonstrations, we propose a novel annotation-efficient imitation learning algorithm, which iteratively collects new datasets by mixing demonstrated states and confident predictions and retrains the semantic parser in a Dataset Aggregation fashion (Ross et al., 2011). We provide a theoretical analysis of its cost bound and also empirically demonstrate its promising performance on the text-to-SQL problem. Code will be available at https://github.com/sunlab-osu/MISP.",
}

@inproceedings{yao-etal-2019-model,
    title = "Model-based Interactive Semantic Parsing: A Unified Framework and A Text-to-{SQL} Case Study",
    author = "Yao, Ziyu  and
      Su, Yu  and
      Sun, Huan  and
      Yih, Wen-tau",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1547",
    doi = "10.18653/v1/D19-1547",
    pages = "5447--5458",
    abstract = "As a promising paradigm, interactive semantic parsing has shown to improve both semantic parsing accuracy and user confidence in the results. In this paper, we propose a new, unified formulation of the interactive semantic parsing problem, where the goal is to design a model-based intelligent agent. The agent maintains its own state as the current predicted semantic parse, decides whether and where human intervention is needed, and generates a clarification question in natural language. A key part of the agent is a world model: it takes a percept (either an initial question or subsequent feedback from the user) and transitions to a new state. We then propose a simple yet remarkably effective instantiation of our framework, demonstrated on two text-to-SQL datasets (WikiSQL and Spider) with different state-of-the-art base semantic parsers. Compared to an existing interactive semantic parsing approach that treats the base parser as a black box, our approach solicits less user feedback but yields higher run-time accuracy.",
}

@article{li2014constructing,
author = {Li, Fei and Jagadish, H. V.},
title = {Constructing an Interactive Natural Language Interface for Relational Databases},
year = {2014},
issue_date = {September 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735461.2735468},
doi = {10.14778/2735461.2735468},
abstract = {Natural language has been the holy grail of query interface designers, but has generally been considered too hard to work with, except in limited specific circumstances. In this paper, we describe the architecture of an interactive natural language query interface for relational databases. Through a carefully limited interaction with the user, we are able to correctly interpret complex natural language queries, in a generic manner across a range of domains. By these means, a logically complex English language sentence is correctly translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and can be evaluated against an RDBMS. We have constructed a system, NaLIR (Natural Language Interface for Relational databases), embodying these ideas. Our experimental assessment, through user studies, demonstrates that NaLIR is good enough to be usable in practice: even naive users are able to specify quite complex ad-hoc queries.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {73–84},
numpages = {12}
}

@inproceedings{su2018natural,
author = {Su, Yu and Hassan Awadallah, Ahmed and Wang, Miaosen and White, Ryen W.},
title = {Natural Language Interfaces with Fine-Grained User Interaction: A Case Study on Web APIs},
year = {2018},
isbn = {9781450356572},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3210013},
doi = {10.1145/3209978.3210013},
abstract = {The rapidly increasing ubiquity of computing puts a great demand on next-generation human-machine interfaces. Natural language interfaces, exemplified by virtual assistants like Apple Siri and Microsoft Cortana, are widely believed to be a promising direction. However, current natural language interfaces provide users with little help in case of incorrect interpretation of user commands. We hypothesize that the support of fine-grained user interaction can greatly improve the usability of natural language interfaces. In the specific setting of natural language interface to web APIs, we conduct a systematic study to verify our hypothesis. To facilitate this study, we propose a novel modular sequence-to-sequence model to create interactive natural language interfaces. By decomposing the complex prediction process of a typical sequence-to-sequence model into small, highly-specialized prediction units called modules, it becomes straightforward to explain the model prediction to the user, and solicit user feedback to correct possible prediction errors at a fine-grained level. We test our hypothesis by comparing an interactive natural language interface with its non-interactive version through both simulation and human subject experiments with real-world APIs. We show that with the interactive natural language interface, users can achieve a higher success rate and a lower task completion time, which lead to greatly improved user satisfaction.},
booktitle = {The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {855–864},
numpages = {10},
keywords = {web api, user feedback, natural language interface},
location = {Ann Arbor, MI, USA},
series = {SIGIR '18}
}


@inproceedings{gur-etal-2018-dialsql,
    title = "{D}ial{SQL}: Dialogue Based Structured Query Generation",
    author = "Gur, Izzeddin  and
      Yavuz, Semih  and
      Su, Yu  and
      Yan, Xifeng",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/P18-1124",
    doi = "10.18653/v1/P18-1124",
    pages = "1339--1349",
    abstract = "The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries. However, further improvement of the existing approaches turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction. DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3{\%} to 69.0{\%} using only 2.4 validation questions per dialogue.",
}

@article{zhang2020graph,
  title={Graph-based Hierarchical Knowledge Representation for Robot Task Transfer from Virtual to Physical World},
  journal={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2020},
  author={Zhang, Zhenliang and Zhu, Yixin and Zhu, Song-Chun}
}

@inproceedings{gao2020joint,
  title={Joint Mind Modeling for Explanation Generation in Complex Human-Robot Collaborative Tasks},
  author={Gao, Xiaofeng and Gong, Ran and Zhao, Yizhou and Wang, Shu and Shu, Tianmin and Zhu, Song-Chun},
  booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages={1119--1126},
  year={2020},
  organization={IEEE}
}

@inproceedings{she-chai-2017-interactive,
    title = "Interactive Learning of Grounded Verb Semantics towards Human-Robot Communication",
    author = "She, Lanbo  and
      Chai, Joyce",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-1150",
    doi = "10.18653/v1/P17-1150",
    pages = "1634--1644",
    abstract = "To enable human-robot communication and collaboration, previous works represent grounded verb semantics as the potential change of state to the physical world caused by these verbs. Grounded verb semantics are acquired mainly based on the parallel data of the use of a verb phrase and its corresponding sequences of primitive actions demonstrated by humans. The rich interaction between teachers and students that is considered important in learning new skills has not yet been explored. To address this limitation, this paper presents a new interactive learning approach that allows robots to proactively engage in interaction with human partners by asking good questions to learn models for grounded verb semantics. The proposed approach uses reinforcement learning to allow the robot to acquire an optimal policy for its question-asking behaviors by maximizing the long-term reward. Our empirical results have shown that the interactive learning approach leads to more reliable models for grounded verb semantics, especially in the noisy environment which is full of uncertainties. Compared to previous work, the models acquired from interactive learning result in a 48{\%} to 145{\%} performance gain when applied in new situations.",
}

@inproceedings{sarmah_geno:_2020,
	series = {{UIST} 2020},
	title = {{Geno}: a {Developer} {Tool} for {Authoring} {Multimodal} {Interaction} on {Existing} {Web} {Applications}},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Sarmah, Ritam and Ding, Yunpeng and Wang, Di and Lee, Cheuk Yin Phipson and Li, Toby Jia-Jun and Chen, Xiang 'Anthony'},
	year = {2020}
}

@inproceedings{horivitz1999principles,
author = {Horvitz, Eric},
title = {Principles of Mixed-Initiative User Interfaces},
year = {1999},
isbn = {0201485591},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/302979.303030},
doi = {10.1145/302979.303030},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–166},
numpages = {8},
keywords = {probability, direct manipulaton, user modeling, intelligent agents, UI design, decision theory},
location = {Pittsburgh, Pennsylvania, USA},
series = {CHI ’99}
}

@inproceedings{kirk2019learning,
  title     = {Learning Hierarchical Symbolic Representations to Support Interactive Task Learning and Knowledge Transfer},
  author    = {Kirk, James R. and Laird, John E.},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  pages     = {6095--6102},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/844},
  url       = {https://doi.org/10.24963/ijcai.2019/844},
}

@inproceedings{li-etal-2020-widget,
    title = "Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements",
    author = "Li, Yang  and
      Li, Gang  and
      He, Luheng  and
      Zheng, Jingjie  and
      Li, Hong  and
      Guan, Zhiwei",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.443",
    doi = "10.18653/v1/2020.emnlp-main.443",
    pages = "5495--5510",
    abstract = "Natural language descriptions of user interface (UI) elements such as alternative text are crucial for accessibility and language-based interaction in general. Yet, these descriptions are constantly missing in mobile UIs. We propose widget captioning, a novel task for automatically generating language descriptions for UI elements from multimodal input including both the image and the structural representations of user interfaces. We collected a large-scale dataset for widget captioning with crowdsourcing. Our dataset contains 162,860 language phrases created by human workers for annotating 61,285 UI elements across 21,750 unique UI screens. We thoroughly analyze the dataset, and train and evaluate a set of deep model configurations to investigate how each feature modality as well as the choice of learning strategies impact the quality of predicted captions. The task formulation and the dataset as well as our benchmark models contribute a solid basis for this novel multimodal captioning task that connects language and user interfaces.",
}
1.
A sketch or account of anything in words; a portraiture or representation in language; an enumeration of the essential qualities of a thing or species.
2.
The act of describing; a delineation by marks or signs.
3.
A set of characteristics by which someone or something can be recognized.

@ARTICLE{laird2017interactive,
  author={J. E. {Laird} and K. {Gluck} and J. {Anderson} and K. D. {Forbus} and O. C. {Jenkins} and C. {Lebiere} and D. {Salvucci} and M. {Scheutz} and A. {Thomaz} and G. {Trafton} and R. E. {Wray} and S. {Mohan} and J. R. {Kirk}},
  journal={IEEE Intelligent Systems}, 
  title={Interactive Task Learning}, 
  year={2017},
  volume={32},
  number={4},
  pages={6-21},
  doi={10.1109/MIS.2017.3121552}}

@inproceedings{chen2020unblind,
  title={Unblind Your Apps: Predicting Natural-Language Labels for Mobile GUI Components by Deep Learning},
  series = {{ICSE} '20},
  author={Chen, Jieshan and Chen, Chunyang and Xing, Zhenchang and Xu, Xiwei and Zhu, Liming and Li, Guoqiang and Wang, Jinshui},
  booktitle = {Proceedings of the 42nd International Conference on Software Engineering},
  year={2020}
}

@inproceedings{williams2020IoTCodex,
  title={The IoT Codex: A Book of Paper Engineering Techniques for Authoring and Composing Embedded Computing Applications},
  series = {{PLATEAU} '20},
  author={Williams, Kristin},
  booktitle = {Proceedings of the 11th Annual Workshop on the Intersection of HCI and PL},
  year={2020}
}

@inproceedings{mohan2014learning,
author = {Mohan, Shiwali and Laird, John E.},
title = {Learning Goal-Oriented Hierarchical Tasks from Situated Interactive Instruction},
year = {2014},
publisher = {AAAI Press},
abstract = {Our research aims at building interactive robots and agents that can expand their knowledge by interacting with human users. In this paper, we focus on learning goal-oriented tasks from situated interactive instructions. Learning the structure of novel tasks and how to execute them is a challenging computational problem requiring the agent to acquire a variety of knowledge including goal definitions and hierarchical control information. We frame acquisition of novel tasks as an explanation-based learning (EBL) problem and propose an interactive learning variant of EBL for a robotic agent. We show that our approach can exploit information in situated instructions along with the domain knowledge to demonstrate fast generalization on several tasks. The knowledge acquired transfers across structurally similar tasks. Finally, we show that our approach seamlessly combines agent-driven exploration with instructions for mixed-initiative learning.},
booktitle = {Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence},
pages = {387–394},
numpages = {8},
location = {Qu\'{e}bec City, Qu\'{e}bec, Canada},
series = {AAAI'14}
}

@book{gluck2019interactive,
  title={Interactive Task Learning: Humans, Robots, and Agents Acquiring New Tasks through Natural Interactions},
  author={Gluck, Kevin A and Laird, John E},
  volume={26},
  year={2019},
  publisher={MIT Press}
}

@article{Ghiani2017Personalization,
author = {Ghiani, Giuseppe and Manca, Marco and Patern\`{o}, Fabio and Santoro, Carmen},
title = {Personalization of Context-Dependent Applications Through Trigger-Action Rules},
year = {2017},
issue_date = {May 2017},
publisher = {ACM},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {1073-0516},
url = {https://doi.org/10.1145/3057861},
doi = {10.1145/3057861},
abstract = {Our life is characterized by the presence of a multitude of interactive devices and smart objects exploited for disparate goals in different contexts of use. Thus, it is impossible for application developers to predict at design time the devices and objects users will exploit, how they will be arranged, and in which situations and for which objectives they will be used. For such reasons, it is important to make end users able to easily and autonomously personalize the behaviour of their Internet of Things applications, so that they can better comply with their specific expectations. In this paper, we present a method and a set of tools that allow end users without programming experience to customize the context-dependent behaviour of their Web applications through the specification of trigger-action rules. The environment is able to support end-user specification of more flexible behaviour than what can be done with existing commercial tools, and it also includes an underlying infrastructure able to detect the possible contextual changes in order to achieve the desired behaviour. The resulting set of tools is able to support the dynamic creation and execution of personalized application versions more suitable for users’ needs in specific contexts of use. Thus, it represents a contribution to obtaining low threshold/high ceiling environments. We also report on an example application in the home automation domain, and a user study that has provided useful positive feedback.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = apr,
articleno = {14},
numpages = {33},
keywords = {trigger-action programming, internet of things, End-user development}
}

@inproceedings{huang2015supporting,
author = {Huang, Justin and Cakmak, Maya},
title = {Supporting Mental Model Accuracy in Trigger-Action Programming},
year = {2015},
isbn = {9781450335744},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805830},
doi = {10.1145/2750858.2805830},
abstract = {Trigger-action programming is a simple programming model that enables users to create rules that automate behavior of smart homes, devices, and online services. Existing trigger-action programming systems, such as if-this-then-that (IFTTT), already have millions of users worldwide; however, their oversimplification limits the expressivity of the programs that can be created. While extensions of IFTTT to allow more complex programs have been proposed, previous work neglects a key distinction between different trigger types (states and events) and action types (instantaneous, extended, and sustained actions). In this paper, we systematically study the impact of these differences through two user studies that reveal: (i) inconsistencies in interpreting the behavior of trigger-action programs and (ii) errors made in creating programs with a desired behavior. Based on a characterization of these issues, we offer recommendations for improving the IFTTT interface so as to mitigate issues that arise from mental model inaccuracies.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {215–225},
numpages = {11},
keywords = {IFTTT, smart homes, trigger-action programming},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{sereshkeh2020vasta,
  title={VASTA: a vision and language-assisted smartphone task automation system},
  author={Sereshkeh, Alborz Rezazadeh and Leung, Gary and Perumal, Krish and Phillips, Caleb and Zhang, Minfan and Fazly, Afsaneh and Mohomed, Iqbal},
  booktitle={Proceedings of the 25th International Conference on Intelligent User Interfaces},
  pages={22--32},
  year={2020}
}

@inproceedings{li-etal-2020-interactive,
    title = "Interactive Task Learning from {GUI}-Grounded Natural Language Instructions and Demonstrations",
    series = {{ACL} 2020},
    author = "Li, Toby Jia-Jun  and
      Mitchell, Tom  and
      Myers, Brad",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.acl-demos.25",
    pages = "215--223",
    abstract = "We show SUGILITE, an intelligent task automation agent that can learn new tasks and relevant associated concepts interactively from the user{'}s natural language instructions and demonstrations, using the graphical user interfaces (GUIs) of third-party mobile apps. This system provides several interesting features: (1) it allows users to teach new task procedures and concepts through verbal instructions together with demonstration of the steps of a script using GUIs; (2) it supports users in clarifying their intents for demonstrated actions using GUI-grounded verbal instructions; (3) it infers parameters of tasks and their possible values in utterances using the hierarchical structures of the underlying app GUIs; and (4) it generalizes taught concepts to different contexts and task domains. We describe the architecture of the SUGILITE system, explain the design and implementation of its key features, and show a prototype in the form of a conversational assistant on Android.",
}

@inproceedings{Tarakji2018Voice,
author = {Tarakji, Ahmad Bisher and Xu, Jian and Colmenares, Juan A. and Mohomed, Iqbal},
title = {Voice Enabling Mobile Applications with UIVoice},
year = {2018},
isbn = {9781450358378},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213344.3213353},
doi = {10.1145/3213344.3213353},
booktitle = {Proceedings of the 1st International Workshop on Edge Systems, Analytics and Networking},
pages = {49–54},
numpages = {6},
location = {Munich, Germany},
series = {EdgeSys’18}
}

@incollection{clark_grounding_1991,
	address = {Washington, DC, US},
	title = {Grounding in communication},
	isbn = {978-1-55798-121-9},
	abstract = {grounding [the process by which conversants try to establish that what has been said is understood] is so basic to communication . . . that it is important to understand how it works / take up two main factors that shape it / one is purpose—what the two people are trying to accomplish in their communication / the other is the medium of communication—the techniques available in the medium for accomplishing that purpose, and what it costs to use them  begin by briefly describing grounding as it appears in casual face-to-face conversation / then consider how it gets shaped by other purposes and in other media (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	booktitle = {Perspectives on socially shared cognition},
	publisher = {APA},
	author = {Clark, Herbert H. and Brennan, Susan E.},
	year = {1991},
	doi = {10.1037/10096-006},
	keywords = {Communication Skills, Conversation, Verbal Comprehension},
	pages = {127--149},
	file = {Snapshot:/Users/toby/Zotero/storage/M7A4RW9J/1991-98452-006.html:text/html}
}

@article{brennan1998grounding,
  title={The grounding problem in conversations with and through computers},
  author={Brennan, Susan E},
  journal={Social and cognitive approaches to interpersonal communication},
  pages={201--225},
  year={1998}
}

@article{hutchins1985direct,
  title={Direct manipulation interfaces},
  author={Hutchins, Edwin L and Hollan, James D and Norman, Donald A},
  book={User Centered System Design: New Perspectives on Human-Computer Interaction},
  year={1986},
}

@book{norman2013design,
  title={The design of everyday things: Revised and expanded edition},
  author={Norman, Don},
  year={2013},
  publisher={Basic books}
}

@inproceedings{liu2019unakite,
    author = {Liu, Michael Xieyang and Hsieh, Jane and Hahn, Nathan and Zhou, Angelina and Deng, Emily and Burley, Shaun and Taylor, Cynthia and Kittur, Aniket and Myers, Brad A.},
    title = {Unakite: Scaffolding Developers’ Decision-Making Using the Web},
    year = {2019},
    isbn = {9781450368162},
    publisher = {ACM},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3332165.3347908},
    doi = {10.1145/3332165.3347908},
    booktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},
    pages = {67–80},
    numpages = {14},
    keywords = {trade-offs, decision making, programming support tools},
    location = {New Orleans, LA, USA},
    series = {UIST ’19}
}

@article{Shneiderman1983DirectManipulation,
author = {Shneiderman, Ben},
title = {Direct Manipulation: A Step Beyond Programming Languages},
year = {1983},
issue_date = {August 1983},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {8},
issn = {0018-9162},
url = {https://doi.org/10.1109/MC.1983.1654471},
doi = {10.1109/MC.1983.1654471},
journal = {Computer},
month = aug,
pages = {57–69},
numpages = {13}
}

@article{licklider1960man,
  title={Man-computer symbiosis},
  author={Licklider, Joseph CR},
  journal={IRE transactions on human factors in electronics},
  number={1},
  pages={4--11},
  year={1960},
  publisher={IEEE}
}

@inproceedings{pasupat-etal-2018-mapping,
    title = "Mapping natural language commands to web elements",
    author = "Pasupat, Panupong  and
      Jiang, Tian-Shun  and
      Liu, Evan  and
      Guu, Kelvin  and
      Liang, Percy",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/D18-1540",
    doi = "10.18653/v1/D18-1540",
    pages = "4970--4976",
    abstract = "The web provides a rich, open-domain environment with textual, structural, and spatial properties. We propose a new task for grounding language in this environment: given a natural language command (e.g., {``}click on the second article{''}), choose the correct element on the web page (e.g., a hyperlink or text box). We collected a dataset of over 50,000 commands that capture various phenomena such as functional references (e.g. {``}find who made this site{''}), relational reasoning (e.g. {``}article by john{''}), and visual reasoning (e.g. {``}top-most article{''}). We also implemented and analyzed three baseline models that capture different phenomena present in the dataset.",
}

@inproceedings{gorla2014checking,
  title={Checking app behavior against app descriptions},
  author={Gorla, Alessandra and Tavecchia, Ilaria and Gross, Florian and Zeller, Andreas},
  booktitle={Proceedings of the 36th International Conference on Software Engineering},
  series = {ICSE ’14},
  pages={1025--1035},
  year={2014}
}

@article{jin2018they,
  title={Why Are They Collecting My Data? Inferring the Purposes of Network Traffic in Mobile Apps},
  author={Jin, Haojian and Liu, Minyi and Dodhia, Kevan and Li, Yuanchun and Srivastava, Gaurav and Fredrikson, Matthew and Agarwal, Yuvraj and Hong, Jason I},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={2},
  number={4},
  pages={1--27},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{Chen2019MessageOnTap,
author = {Chen, Fanglin and Xia, Kewei and Dhabalia, Karan and Hong, Jason I.},
title = {MessageOnTap: A Suggestive Interface to Facilitate Messaging-Related Tasks},
year = {2019},
isbn = {9781450359702},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300805},
doi = {10.1145/3290605.3300805},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
articleno = {Paper 575},
numpages = {14},
keywords = {messaging/communication, productivity, information seeking & search, user experience design, personal data/tracking, text/speech/language, contextual computing},
location = {Glasgow, Scotland Uk},
series = {CHI ’19}
}

@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "ACL",
    url = "http://arxiv.org/abs/1908.10084",
}



@misc{pew_research_center_demographics_2019,
	title = {Demographics of {Mobile} {Device} {Ownership} and {Adoption} in the {United} {States}},
	url = {https://www.pewresearch.org/internet/fact-sheet/mobile/},
	abstract = {Americans today are increasingly connected to the world of digital information while “on the go” via smartphones, tablets and other mobile devices. Explore the latest patterns, trends and statistics that have shaped the mobile revolution.},
	language = {en-US},
	urldate = {2020-04-29},
	year = {2019},
	author = {Pew Research Center}
}

@article{xiong2017toward,
  title={Toward human parity in conversational speech recognition},
  author={Xiong, Wayne and Droppo, Jasha and Huang, Xuedong and Seide, Frank and Seltzer, Michael L and Stolcke, Andreas and Yu, Dong and Zweig, Geoffrey},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  number={12},
  pages={2410--2423},
  year={2017},
  publisher={IEEE}
}

@article{benitez2010evaluating,
  title={Evaluating re-identification risks with respect to the HIPAA privacy rule},
  author={Benitez, Kathleen and Malin, Bradley},
  journal={Journal of the American Medical Informatics Association},
  volume={17},
  number={2},
  pages={169--177},
  year={2010},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{vatsalan2013taxonomy,
  title={A taxonomy of privacy-preserving record linkage techniques},
  author={Vatsalan, Dinusha and Christen, Peter and Verykios, Vassilios S},
  journal={Information Systems},
  volume={38},
  number={6},
  pages={946--969},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{Surbatovich2017Some,
author = {Surbatovich, Milijana and Aljuraidan, Jassim and Bauer, Lujo and Das, Anupam and Jia, Limin},
title = {Some Recipes Can Do More Than Spoil Your Appetite: Analyzing the Security and Privacy Risks of IFTTT Recipes},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052709},
doi = {10.1145/3038912.3052709},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1501–1510},
numpages = {10},
keywords = {information-flow, internet of things (iot), end-user programming, ifttt service},
location = {Perth, Australia},
series = {WWW ’17}
}

@inproceedings{Gantt:1992:GGP:142750.142767,
	author = {Gantt, Michelle and Nardi, Bonnie A.},
	title = {Gardeners and Gurus: Patterns of Cooperation Among CAD Users},
	booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	series = {CHI '92},
	year = {1992},
	isbn = {0-89791-513-5},
	location = {Monterey, California, USA},
	pages = {107--117},
	numpages = {11},
	url = {http://doi.acm.org/10.1145/142750.142767},
	doi = {10.1145/142750.142767},
	acmid = {142767},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {CAD, cooperative work, end user programming},
}

@article{nardi_collaborative_1998,
	title = {Collaborative, {Programmable} {Intelligent} {Agents}},
	volume = {41},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/272287.272331},
	doi = {10.1145/272287.272331},
	number = {3},
	urldate = {2016-03-31TZ},
	journal = {Commun. ACM},
	author = {Nardi, Bonnie A. and Miller, James R. and Wright, David J.},
	month = mar,
	year = {1998},
	pages = {96--104}
}

@inproceedings{Pipek2006,
	author="Pipek, Volkmar
	and Kahler, Helge",
	editor="Lieberman, Henry
	and Patern{\`o}, Fabio
	and Wulf, Volker",
	title="Supporting Collaborative Tailoring",
	bookTitle="End User Development",
	year="2006",
	publisher="Springer Netherlands",
	address="Dordrecht",
	pages="315--345",
	abstract="In this chapter we depict collaborative aspects of tailoring software. We provide a categorization distinguishing between (at first) three levels of intensity of user ties regarding tools usage (``shared use,'' ``shared context,'' and ``shared tool'') and discuss approaches to support collaborative tailoring in these scenarios. For the two levels with the most intense ties (``Shared Context'' and ``Shared Tool'') we provide the relevant theoretical background as well as empirical evidence from our own fieldwork. Our taxonomy helps us to describe and address two important shortcomings of current tailoring environments. First, current considerations regarding tailorability usually address tailoring within one tool, while current work infrastructures (which we introduce as a forth scenario---``Shared Infrastructure''---in our taxonomy) require a thinking beyond one tool. Second, although studies on tailoring-in-practice and evolving use of organizational software show the importance of user-userinteraction in processes of technology configuration, this interaction was only treated as a side issue in the design of tailoring environments. Respecting the importance of that interaction, we suggest to stronger focus on opportunities to support those appropriation activities of users.",
	isbn="978-1-4020-5386-3",
	doi="10.1007/1-4020-5386-X_15",
	url="https://doi.org/10.1007/1-4020-5386-X_15"
}

@article{enck2014taintdroid,
  title={TaintDroid: an information-flow tracking system for realtime privacy monitoring on smartphones},
  author={Enck, William and Gilbert, Peter and Han, Seungyeop and Tendulkar, Vasant and Chun, Byung-Gon and Cox, Landon P and Jung, Jaeyeon and McDaniel, Patrick and Sheth, Anmol N},
  journal={ACM Transactions on Computer Systems (TOCS)},
  volume={32},
  number={2},
  pages={5},
  year={2014},
  publisher={ACM}
}

@inproceedings {huang_supor_190947,
author = {Jianjun Huang and Zhichun Li and Xusheng Xiao and Zhenyu Wu and Kangjie Lu and Xiangyu Zhang and Guofei Jiang},
title = {{SUPOR}: Precise and Scalable Sensitive User Input Detection for Android Apps},
booktitle = {24th {USENIX} Security Symposium ({USENIX} Security 15)},
year = {2015},
isbn = {978-1-931971-232},
address = {Washington, D.C.},
pages = {977--992},
url = {https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/huang},
publisher = {{USENIX} Association},
month = aug,
}

@inproceedings{pinkas2002securing,
  title={Securing passwords against dictionary attacks},
  author={Pinkas, Benny and Sander, Tomas},
  booktitle={Proceedings of the 9th ACM conference on Computer and communications security},
  pages={161--170},
  year={2002},
  organization={ACM}
}

@inproceedings{oechslin2003making,
  title={Making a faster cryptanalytic time-memory trade-off},
  author={Oechslin, Philippe},
  booktitle={Annual International Cryptology Conference},
  pages={617--630},
  year={2003},
  organization={Springer}
}

@book{mcdonald2009handbook,
  title={Handbook of Biological Statistics},
  author={McDonald, John H},
  volume={2},
  year={2009},
  publisher={Sparky House Publishing}
}

@article{landis1977measurement,
  title={The measurement of observer agreement for categorical data},
  author={Landis, J Richard and Koch, Gary G},
  journal={Biometrics},
  pages={159--174},
  year={1977},
  publisher={JSTOR}
}

@book{nardi1993small,
  title={A small matter of programming: perspectives on end user computing},
  author={Nardi, Bonnie A},
  year={1993},
  publisher={MIT press}
}

@book{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua},
  year={2009},
  publisher={Now Publishers Inc}
}

@inproceedings{li_mapping:_2020,
    title = "Mapping Natural Language Instructions to Mobile {UI} Action Sequences",
    author = "Li, Yang  and
      He, Jiacong  and
      Zhou, Xin  and
      Zhang, Yuan  and
      Baldridge, Jason",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    doi = "10.18653/v1/2020.acl-main.729",
    url = "https://www.aclweb.org/anthology/2020.acl-main.729",
    pages = "8198--8210",
    abstract = "We present a new problem: grounding natural language instructions to mobile user interface actions, and create three new datasets for it. For full task evaluation, we create PixelHelp, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in How-To instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces. We use a Transformer to extract action phrase tuples from long-range natural language instructions. A grounding Transformer then contextually represents UI objects using both their content and screen position and connects them to object descriptions. Given a starting screen and instruction, our model achieves 70.59{\%} accuracy on predicting complete ground-truth action sequences in PixelHelp.",
}

@inproceedings{bigham2009trailblazer,
author = {Bigham, Jeffrey P. and Lau, Tessa and Nichols, Jeffrey},
title = {Trailblazer: Enabling Blind Users to Blaze Trails through the Web},
year = {2009},
isbn = {9781605581682},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502677},
doi = {10.1145/1502650.1502677},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {177–186},
numpages = {10},
keywords = {non-visual interfaces, programming-by-demonstration, blind users, web accessibility, suggestions},
location = {Sanibel Island, Florida, USA},
series = {IUI ’09}
}

@inproceedings{swearngin2018rewire,
author = {Swearngin, Amanda and Dontcheva, Mira and Li, Wilmot and Brandt, Joel and Dixon, Morgan and Ko, Amy J.},
title = {Rewire: Interface Design Assistance from Examples},
year = {2018},
isbn = {9781450356206},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174078},
doi = {10.1145/3173574.3174078},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pixel-based reverse engineering, wireframing, user interface design},
location = {Montreal QC, Canada},
series = {CHI ’18}
}

@inproceedings{lee2020guicomp,
author = {Lee, Chunggi and Kim, Sanghoon and Han, Dongyun and Yang, Hongjun and Park, Young-Woo and Kwon, Bum Chul and Ko, Sungahn},
title = {GUIComp: A GUI Design Assistant with Real-Time, Multi-Faceted Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376327},
doi = {10.1145/3313831.3376327},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design feedback, gui design},
location = {Honolulu, HI, USA},
series = {CHI ’20}
}

@inproceedings{devlin_2018_bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{bowman_large:_2015,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/D15-1075",
    doi = "10.18653/v1/D15-1075",
    pages = "632--642",
}

@inproceedings{williams_broad:_2018,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N18-1101",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
}

@inproceedings{nair_relu_2010,
author = {Nair, Vinod and Hinton, Geoffrey E.},
title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
year = {2010},
isbn = {9781605589077},
publisher = {Omnipress},
address = {Madison, WI, USA},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages = {807–814},
numpages = {8},
location = {Haifa, Israel},
series = {ICML’10}
}

@inproceedings {kingma_adam_2015,
  author = {Diederik P. Kingma and
               Jimmy Ba},
  editor = {Yoshua Bengio and
               Yann LeCun},
  title = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year = {2015},
  url = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kumar_webzeitgeist:_2013,
author = {Kumar, Ranjitha and Satyanarayan, Arvind and Torres, Cesar and Lim, Maxine and Ahmad, Salman and Klemmer, Scott R. and Talton, Jerry O.},
title = {Webzeitgeist: Design Mining the Web},
year = {2013},
isbn = {9781450318990},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466420},
doi = {10.1145/2470654.2466420},
abstract = {Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3083–3092},
numpages = {10},
keywords = {web design, data mining},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{huang_swire_2019,
author = {Huang, Forrest and Canny, John F. and Nichols, Jeffrey},
title = {Swire: Sketch-Based User Interface Retrieval},
year = {2019},
isbn = {9781450359702},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300334},
doi = {10.1145/3290605.3300334},
abstract = {Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, finding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly reflected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the first large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, for the first time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workflows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {design examples, sketching, computer vision, deep learning, information retrieval, user interface design, data-driven design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{lee_neural_2020,
  title={Neural Design Network: Graphic Layout Generation with Constraints},
  author={Lee, Hsin-Ying and Yang, Weilong and Jiang, Lu and Le, Madison and Essa, Irfan and Gong, Haifeng and Yang, Ming-Hsuan},
  journal={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@article{li_layoutgan_2019,
  author={Jianan {Li} and Jimei {Yang} and Aaron {Hertzmann} and Jianming {Zhang} and Tingfa {Xu}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={LayoutGAN: Synthesizing Graphic Layouts with Vector-Wireframe Adversarial Networks}, 
  year={2019},
  volume={},
  number={}
 }
 
@inproceedings{turian_word_2010,
author = {Turian, Joseph and Ratinov, Lev and Bengio, Yoshua},
title = {Word Representations: A Simple and General Method for Semi-Supervised Learning},
year = {2010},
publisher = {ACL},
address = {USA},
booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
pages = {384–394},
numpages = {11},
location = {Uppsala, Sweden},
series = {ACL ’10}
}

@article {bellman-dynamic-1966,
	author = {Bellman, Richard},
	title = {Dynamic Programming},
	volume = {153},
	number = {3731},
	pages = {34--37},
	year = {1966},
	doi = {10.1126/science.153.3731.34},
	publisher = {AAAS},
	abstract = {Little has been done in the study of these intriguing questions, and I do not wish to give the impression that any extensive set of ideas exists that could be called a "theory." What is quite surprising, as far as the histories of science and philosophy are concerned, is that the major impetus for the fantastic growth of interest in brain processes, both psychological and physiological, has come from a device, a machine, the digital computer. In dealing with a human being and a human society, we enjoy the luxury of being irrational, illogical, inconsistent, and incomplete, and yet of coping. In operating a computer, we must meet the rigorous requirements for detailed instructions and absolute precision. If we understood the ability of the human mind to make effective decisions when confronted by complexity, uncertainty, and irrationality then we could use computers a million times more effectively than we do. Recognition of this fact has been a motivation for the spurt of research in the field of neurophysiology. The more we study the information processing aspects of the mind, the more perplexed and impressed we become. It will be a very long time before we understand these processes sufficiently to reproduce them. In any case, the mathematician sees hundreds and thousands of formidable new problems in dozens of blossoming areas, puzzles galore, and challenges to his heart{\textquoteright}s content. He may never resolve some of these, but he will never be bored. What more can he ask?},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/153/3731/34},
	journal = {Science}
}

@inproceedings{pennington-etal-2014-glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
	series = {{EMNLP} '14},
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    series = {NAACL ’18},
    address = "New Orleans, Louisiana",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@inproceedings{nguyen_exploring:_2017,
author = {Nguyen, Trong Duc and Nguyen, Anh Tuan and Phan, Hung Dang and Nguyen, Tien N.},
title = {Exploring API Embedding for API Usages and Applications},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE},
url = {https://doi.org/10.1109/ICSE.2017.47},
doi = {10.1109/ICSE.2017.47},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {438–449},
numpages = {12},
keywords = {migration, API embedding, Word2Vec, API usages},
location = {Buenos Aires, Argentina},
series = {ICSE ’17}
}

@inproceedings{li_interactive:_2020,
    title = "Interactive Task Learning from {GUI}-Grounded Natural Language Instructions and Demonstrations",
    author = "Li, Toby Jia-Jun  and
      Mitchell, Tom  and
      Myers, Brad",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.acl-demos.25",
    doi = "10.18653/v1/2020.acl-demos.25",
    pages = "215--223",
    abstract = "We show SUGILITE, an intelligent task automation agent that can learn new tasks and relevant associated concepts interactively from the user{'}s natural language instructions and demonstrations, using the graphical user interfaces (GUIs) of third-party mobile apps. This system provides several interesting features: (1) it allows users to teach new task procedures and concepts through verbal instructions together with demonstration of the steps of a script using GUIs; (2) it supports users in clarifying their intents for demonstrated actions using GUI-grounded verbal instructions; (3) it infers parameters of tasks and their possible values in utterances using the hierarchical structures of the underlying app GUIs; and (4) it generalizes taught concepts to different contexts and task domains. We describe the architecture of the SUGILITE system, explain the design and implementation of its key features, and show a prototype in the form of a conversational assistant on Android.",
}

@article{intharah_hilc:_2019,
	author = {Intharah, Thanapong and Turmukhambetov, Daniyar and Brostow, Gabriel J.},
	title = {HILC: Domain-Independent PbD System Via Computer Vision and Follow-Up Questions},
	journal = {ACM Trans. Interact. Intell. Syst.},
	issue_date = {March 2019},
	volume = {9},
	number = {2-3},
	month = mar,
	year = {2019},
	issn = {2160-6455},
	pages = {16:1--16:27},
	articleno = {16},
	numpages = {27},
	url = {http://doi.acm.org/10.1145/3234508},
	doi = {10.1145/3234508},
	acmid = {3234508},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {GUI automation, Programming by demonstration, action segmentation and recognition, visual-based programming by demonstration},
} 

