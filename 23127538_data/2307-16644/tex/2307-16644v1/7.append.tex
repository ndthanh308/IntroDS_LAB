\section{APPENDIX FOR REPRODUCIBILITY}
\subsection{Model Implementation Details}\label{sec::implementation}
In this section we provide implementation details of our system. Due to the massive amount of training data and the high demand for low latency in our online system, we simplify each network within the framework. In our final implementation, feature merging network $h^M$ is a one-layer fully-connected network of 120 output units (120D FC). User preference network $h^U$ is a 340D FC. Shared network $E^S$ and expert networks $E^W$/$E^N$ are 256D FCs. Need prediction network $t^N$ is a 10D FC. In-store/delivery classification network $t^W$ is a two-layer perceptron, which has 10 hidden units and 2 output units. Complexifying these neural networks can help us further optimize performance, but at the same time, it would lead to an increase in system latency. The activation function of all mentioned networks is ReLU~\cite{glorot2011deep}. We adopt batch normalization~\cite{ioffe2015batch} right after $h^M$, $h^U$, $E^S$, $E^P$, and $E^N$. Following such implementation, we conduct rich online and offline experiments to prove the effectiveness of our model, which are shown in Section~\ref{sec::experiments} and Section~\ref{sec::online}.
\subsection{Dataset}\label{sec::dataset}
We conduct our offline experiment on a real-world dataset at the scale of billions. The dataset is a sampling of all purchase records in 2022 on the platform. We sample the records according to the percentage of purchases of each kind of life service. The dataset includes more than 7 billion real purchase records from 65 million users.
Each instance in the dataset includes user profile, time, location, and other real-time environmental factors, and the kind of life service the user purchase. The type of life service consumed by the user reflects their actual living need in the spatiotemporal context. Following existing works~\cite{cheng2012fused,palumbo2018knowledge}, we randomly sample 80\% of the dataset as the training set, and 20\% as the test set.
\subsection{Metrics}\label{sec::metrics}
We design a metric named Sort Accuracy (SA) to measure the performance of systems on our problem. The metric SA can be defined as follows.
For user scene $i$, our system outputs scores for all kinds of living needs. We sort the living needs by their scores and get a list. We define \textit{Relative Ranking Error} as the difference between the actual ranking position and the ideal ranking position (the first position) of the ground truth need, and further define \textit{Maximum Ranking Error} as the maximum relative ranking error any system can give for a user scene (the number of categories of user needs - 1). For example, in our system which handles 10 types of living need, for user scene $i$, if the ground truth need is ranked third, then the relative ranking error is 2 (2 = 3-1), and the maximum ranking error is 9 (9 = 10-1). Then Sort Accuracy (SA) can be defined as follows,
\begin{equation}
\text{SA}=\text{average}_{i\in T}\left(1-\frac{\text{Relative Ranking Error}}{\text{Maximum Ranking Error}}\right)
\end{equation}
where $T$ denotes the testing set on which the metric is calculated. We first calculate $1-\text{Relative Ranking Error}/\text{Maximum Ranking Error}$ of every user scene in the testing set and then compute the average. We then define Via-delivery Sort Accuracy (VDSA) and In-store Sort Accuracy (ISSA) to measure systems' performance on delivery and in-store living needs.
\begin{equation}
\text{VDSA}=\text{average}_{i\in T_{VD}}\left(1-\frac{\text{Relative Ranking Error}}{\text{Maximum Ranking Error}}\right)
\end{equation}
\begin{equation}
\text{ISSA}=\text{average}_{i\in T_{IS}}\left(1-\frac{\text{Relative Ranking Error}}{\text{Maximum Ranking Error}}\right)
\end{equation}
$T_{VD}$ and $T_{IS}$ denote sets of testing samples where the ground truth needs-meeting way is via delivery and in store, respectively. In the following, we will use these metrics to measure the living needs prediction performance of our system and baseline systems.
\subsection{Baselines}\label{sec::baselines}
To illustrate the effectiveness of our system, we compare it with two baselines widely in actual production environments, including \textbf{DIN~\cite{zhou2018deep}}, \textbf{DNN~\cite{cheng2016wide}}, \textbf{DCN~\cite{wang2017deep}}, 
\textbf{ESMM~\cite{ma2018entire}},
and \textbf{MMOE~\cite{ma2018modeling}}. We will provide a detailed description of these baselines in the appendix. DIN is a recommendation algorithm that leverages deep neural networks to analyze users' historical behavior and make predictions about their potential interests. It uses an attention-based mechanism to weigh the importance of different historical behaviors for predicting the current interest of a user. As for DNN, We follow the design of Wide \& Deep learning to build a Deep Neural Network (DNN) based system for our task. It can learn both simple and complex relationships in the data. DCN is proposed to keep the benefits of a DNN model while introducing a cross network that is more efficient in learning certain bounded-degree feature interactions. It applies feature crossing at each layer, and it doesn't require manual feature engineering, adding minimal extra complexity to the DNN model. ESMM estimates post-click conversion rates for recommendation systems by using sequential user actions and a feature representation transfer learning strategy to alleviate sample selection bias and data sparsity. MMoE is a multi-task learning approach that learns to model task relationships from data. It adapts the Mixture-of-Experts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task. 
For a clear comparison, the input features for all baselines are kept the same as those for our model.
\subsection{Additional Ablation Study}
To gain a deeper understanding of the impact of each component design of our model, we also conduct ablation studies with a particular focus on the effects of the group behavior pattern features and the spatiotemporal context features. When removing the group behavior pattern features from the model input, the performance decreased by 1.06\%. When removing the spatiotemporal context features from the model input, the performance decreased by 1.46\%. These results provide compelling evidence of the pivotal role that these two features play in accurately predicting users' daily living needs.
