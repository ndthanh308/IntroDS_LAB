

\section{Our NEON System}\label{sec::method}

To address the challenges mentioned in the introduction, we develop the NEON system made up of three phases: feature mining, feature fusion layer, and multitask prediction. 
First, in the feature mining phase, we address the first challenge by carefully designing spatiotemporal features for individual-level users and address the second challenge by extracting behavioral-pattern features for group-level users.
The feature fusion phase then employs a feature-fusion neural network to seamlessly integrate internal preferences, spatiotemporal context impact, and group behavior patterns to generate complete user representations, overcoming both challenges.
Last, in the multitask prediction stage, to enhance the model's understanding of spatiotemporal context, we introduce an auxiliary task of needs-meeting way prediction to the main goal of predicting living needs, providing additional support in addressing the first challenge. The deep feature fusion layer and the multi-task prediction parts of our system are illustrated in Figure~\ref{fig::model}.

% Figure environment removed

\subsection{Feature Mining}\label{sec::FeatureMining}
First of all, we use features that directly reflect user traits, such as users' profile, their recent behavior sequence, and their historical behaviors, as inputs for the model.

 As mentioned above, for a specific user, his living needs are greatly affected by the spatial and temporal scenarios in which he is located. For example, \textit{on a rainy midday, a person at work probably has the need to order food delivery; but on a sunny noon, he/she may have another need of going out to eat in the restaurant}. This complexity and variability of human living needs, driven by the flux of time and space, pose a considerable challenge in accurately modeling the impact of the spatiotemporal context. In order to tackle this challenge, we incorporate spatiotemporal context features as an integral part of our system's input.

What's more, on the platform, users may have potential needs with sparse or even non-existent history records. For example, \textit{a person who never buys medicine on the platform may have a cold and need to buy medicine online one day.} Such potential needs are difficult for the model to grasp. To address the challenge of modeling potential needs, we introduce group behavior pattern features to help the model learn the potential living needs of users. 

Below we give a detailed description of the three categories of features.
\subsubsection{User Features}
This group of features includes user profiles and user history behavior sequences.
\begin{itemize}[leftmargin=*]
\item\textbf{User profiles $\bm{f}^U_p$.} The user's profile, including their age, gender, etc.
\item\textbf{User recent online behavior sequence $\bm{f}^U_{rb}$.} The sequence of items recently clicked by the user in the platform; the sequence of items recently ordered by the user in the platform.
\item\textbf{User aggregated historical online behavior $\bm{f}^U_{hb}$.} The percentage of times users buy each type of life service.
\item\textbf{User offline visitation record $\bm{f}^U_{ov}$.} The 50 most visited POIs (point of interest) by the user in the last six months; the 50 most visited AOIs (area of interest) by the user in the last six months. 
\end{itemize}
We concatenate all the mentioned features above to get a sparse user feature vector $f^U$, formulated as follows:
\begin{equation}
f^U=\left[f^U_p, f^U_{rb}, f^U_{hb}, f^U_{ov}\right].
\end{equation}
\subsubsection{Spatiotemporal Context Features}
Users' living needs are greatly affected by time, location, and other environmental factors. Thus, we introduce spatiotemporal context features as part of the input of our system to help our system model the complex impact of spatiotemporal context, which can be listed as follows.
\begin{itemize}[leftmargin=*]
\item\textbf{Time $\bm{f}^{ST}_t$.} Current time period. More than one time period feature of different granularity is applied, including hour, day, whether it is a holiday, etc.
\item\textbf{Location $\bm{f}^{ST}_l$.} The POI (point of interest) embedding of the user's real-time location; the AOI (area of interest) embedding of the user's real-time location; the city embedding of the user's real-time location. The location features are hourly real-time features.
\item\textbf{Weather $\bm{f}^{ST}_w$.} Weather information for the user's city or region, including wind, humidity, temperature, and weather type (sunny, rainy, snowy, etc.). Weather features are refined to hourly granularity.
\item\textbf{Travel state $\bm{f}^{ST}_{ts}$.} Information about whether the user is located in his/her resident city. Possible states include \textit{based in resident city}, \textit{about to travel}, and \textit{on travel}.
\end{itemize}
The dense spatiotemporal context feature vector $f^{ST}$ is created by concatenating all previously mentioned context features, formulated as follows:
\begin{equation}
f^{ST}=\left[f^{ST}_t, f^{ST}_l, f^{ST}_w, f^{ST}_{ts}\right].
\end{equation}
\subsubsection{Group Behavior Pattern Features}
We introduce group behavior pattern features to supplement the sparse individual behavior of users, in order to assist in identifying the potential living needs of individual users. 
\begin{itemize}[leftmargin=*]
\item\textbf{Group aggregated behavior $\bm{f}^G_{a}$.} We first segment users into groups based on their profiles. In each group, we get the group aggregated behavior by calculating the percentage of views, clicks, and purchases of each type of life service among all views, clicks, and purchases initiated by the group. For each user, the group aggregated behaviors of the groups the user belongs to are used as features. For example, a middle-aged person has group aggregated behaviors feature of middle-aged users and other groups he/she is in. 
\item\textbf{Popularity in the current time period $\bm{f}^G_{ct}$.} We cut all time into time periods according to different criteria, such as whether it is 
a holiday, if it is morning, noon, or night, etc. Then in each time period, we calculate the popularity of each type of life service by calculating the percentage of times the life service is viewed/clicked/purchased among all views/clicks/purchases happening in this time period. We determine the time periods in which the current time is located, and use the popularity of each type of life service in these time periods as a feature. For example, if the user opens the app on Christmas night, popularity on holiday and popularity at night of each kind of life service are set as features.
\item\textbf{Group behavior pattern in spatiotemporal context $\bm{f}^G_{st}$.} By discovering group preferences in different spatiotemporal contexts, we further capture more fine-grained group behavior patterns. We calculate the percentage of views/clicks/purchases of each type of life service initiated by each group in each kind of spatiotemporal context. These fine-grained patterns are used as features of the model. For example, the group preference of middle-aged people at work at noon on working days are used to enrich the representations of every individual within this demographic in such spatiotemporal scenario.
\item\textbf{User behaviors augmented by inter-need correlation $\bm{f}^G_{ic}$.} There is an inherent association across different types of users' living needs. This association can be leveraged to improve prediction performance. For example, \textit{a user who frequently purchases hairdressing services may also be inclined to purchase beauty services.} We use the association rule mining algorithm to analyze the co-occurrence of different life service categories, filter out high-correlation relationships, and employ them to augment user behavior as input features.
\end{itemize}
We combine all previously mentioned group behavior pattern features to generate the dense group behavior pattern feature vector $f^{G}$, which is formulated as follows:
\begin{equation}
f^{G}=\left[f^{G}_a, f^{G}_{ct}, f^{G}_{st}, f^{G}_{ic}\right].
\end{equation}

\subsection{Feature Fusion Layer}\label{sec::FeatureIntegration}
As mentioned in Section~\ref{sec::profdef}, we refer to a user in a specific spatiotemporal context as a user scene. For a user scene $i$, after feature mining, we have dense spatiotemporal features $f^{ST}_i$, dense group pattern features $f^G_i$, and sparse user features $f^U_i$. For brevity of presentation, we omit the subscript $i$ in some of the expressions below. We designed a feature fusion layer to integrate these features into the input of the subsequent prediction module.

We first set up an embedding layer, which processes the high-dimensional sparse user feature vector $f^U$ into a low-dimensional dense vector $v^U$.  To address the challenges of complex impact of spatiotemporal context and users' potential needs, we mine spatiotemporal features and group behavior pattern features in the feature mining phase, respectively. With these features as input, we use a feature merging network to model the interaction between spatiotemporal contexts, group behavior patterns, and  users as follows,
\begin{equation}
x^M=h^M\left(\left[f^{ST}, f^G, v^U\right]\right),
\end{equation}
where $\left[ \cdot \right]$ denotes concatenation operation. Here $h^M$ is the feature merging network, which merges three information sources of spatiotemporal contexts, group behavior patterns, and user preference into a fusion representation $x^M$.

Moreover, users have their own internal characteristics that are independent of the spatiotemporal scene they are in and the group they belong to. To model the internal characteristics of users, we generate a representation as follows,
\begin{equation}
x^U=h^U\left(f^U\right),
\end{equation}
where $h^U$ denotes the user preference network that turns raw user features into dense user preference representation. We then concatenate the two parts of representations into the full representation of the user scene:
\begin{equation}
x=\left[x^M, x^U\right].
\end{equation}
In brief, we design a feature fusion layer to tackle both challenges by considering the influence of spatiotemporal context, incorporating group behavior patterns, as well as extracting individual preferences.

\subsection{Multitask Prediction}\label{sec::Model}
We further design a prediction module which takes user scene representation as input to predict users' living needs. The module is tasked with two objectives: \textit{fine-grained need prediction} and \textit{needs-meeting way prediction}. Fine-grained need prediction is to predict the specific living need of the user. Neets-meeting way prediction is to predict the preferred way of the user to meet their needs. 

Specifically, among the ten kinds of needs which we mentioned in the problem formulation, there are two ways to satisfy the needs: in-store and via-delivery. In other words, consumers can choose to satisfy their needs by visiting a physical store or by ordering online and then receiving goods via delivery. Each type of the 10 needs can be classified into one of two categories, in-store needs or via-delivery needs. We show the classification in Table~\ref{tab::nc}. Actually, needs-meeting way prediction is to predict whether the preferred way of the user to meet their needs is in-store or via-delivery.
\begin{table}[]
\vspace{-0.3cm}
\caption{The classification of the 10 living needs that can be satisfied on Meituan}
\label{tab::nc}
\begin{tabular}{|l|l|}
\hline Living needs that& \fontfamily{ppl}\selectfont Specialty shopping online,\\
 can be satisfied&  \fontfamily{ppl}\selectfont Grocecy shopping online, \\
via delivery& \fontfamily{ppl}\selectfont Ordering food delivery, Buying medicine \\
\hline Living needs that& \fontfamily{ppl}\selectfont Eating in a restaurant, Hotel, \\
can be satisfied& \fontfamily{ppl}\selectfont Hair-dressing, Beauty,  \\
in store& \fontfamily{ppl}\selectfont Tourism, Entertainment \\
\hline
\end{tabular}
\vspace{-0.6cm}
\end{table}

Users' preferences for needs-meeting ways are strongly affected by the spatiotemporal context. For example, \textit{a person at work during lunchtime on a weekday is more likely to have the need to order food delivery (via delivery), while the same person in a shopping district on a weekend evening is more likely to visit a store for a meal (in-store)}. With this in mind, we include the needs-meeting way prediction task which is jointed trained with the main task of need prediction to enhance the model's ability to learn spatiotemporal context information.
Next, we describe how we get the prediction results of the two tasks. 
We use $y^W$ and $y^N$ to denote the prediction result of needs-meeting way and specific need. $y^k, k \in \{W, N\}$ can be generated as follows,
\begin{equation}
 \begin{aligned}
y^k &= t^k(z^k),\\
\text{where }z^k &= g^k(x)_0E^k(x)+g^k(x)_1E^S(x).
\end{aligned}
\end{equation}
Here $t^k$ is the prediction neural network for task $k$. There are a variety of choices in the specific structure of the neural network. In Section~\ref{sec::implementation}, we will state our specific choice. To avoid verbosity, we will use \textit{network} to replace ~\textit{neural network} in the following text. The output of $t^N$, $y^N$, is the scores of ten types of living needs, and the output of $t^W$, $y^W$, is the scores of in-store and via-delivery needs-meeting ways. We use $s^N_{im}$ to denote the score of need $m$ for user scene $i$, and use $s^W_{in}$ to denote the score of needs-meeting way $n$ for user scene $i$. $E^k$ is the expert network~\cite{ma2018modeling,tang2020progressive} for task $k$. $E^S$ is the shared network between the two tasks. $E^S$ is responsible for generating general representations that are common to both tasks, while $E^k$ is responsible for learning task-specific representations that are more fine-tuned to the specific task $k$. The gating network $g_k$ determines what proportion of information input each task's prediction network receives from the shared network and the expert network. We formulate the gating network as follows,
\begin{equation}
g^k(x)=\operatorname{Softmax}(W_k x),
\end{equation}
where $W_k \in \mathbb{R}^{2 \times d}$ is trainable weights for task $k$. The gating network takes $x$ as input, and outputs the relative importance of the shared and task-specific representations for a given tasking, allowing the model to selectively attend to the most relevant information and improve its performance.
In summary, to address the complexity of spatiotemporal context impact, we introduce an auxiliary task of needs-meeting way prediction which is jointly trained with the main task of fine-grained living needs prediction to enhance our system's learning of spatiotemporal context. The multitask prediction module in our system produces a score for each living need and needs-meeting way.
\subsection{Model Training}\label{sec::train}
In this section we describe how our system is trained. Corresponding to the two tasks, we design two parts of loss. We design need prediction loss taking into account the fact that the frequency of different needs arising in users' lives is different. For example, \textit{a user may need to order food delivery for lunch every workday, but rarely need to buy medicine}. In order to address the class imbalance issue for different living needs, we propose using a multi-class focal loss which can decrease the effect of needs with a high volume of training data on the final prediction loss. The need prediction loss can be formulated as follows,
\begin{align}
\text {Loss}_{\text{need}}&=-\sum_{i\in O}\left(\sum_{n=1}^{10}\left(1-q^N_{i n}\right)^\gamma \chi^N_{i n} \log \left(q^N_{i n}\right)\right),\\
\text{where } q^N_{in}&=\operatorname{Softmax}\left(s^N_{i n}\right)=\frac{e^{s^N_{i n}}}{\sum_n e^{s^N_{i n}}}.
\end{align}
Here $O$ is the training set, $s^N_{in}$ is the score of living need $n$ for user scene $i$, $\gamma$ is the hyperparameter which decides the importance of difficult samples, $\chi^N_{in}$ is 1 if $n$ is the ground truth need for user scene $i$, else it is 0.
For the needs-meeting way prediction task, we use BCE loss as prediction loss. We formulate it as follows,
\begin{align}
\text{Loss}_{\text{way}}&=-\sum_{i\in O}\left(\sum_{m=1}^{2}\chi^W_{im}
\log \left(q^W_{im})\right)\right),\\
\text{where } q^W_{im}&=\operatorname{Softmax}\left(s^W_{i m}\right)=\frac{e^{s^W_{i m}}}{\sum_m e^{s^W_{i m}}}.
\end{align}
Here $O$ is the training set, $s^W_{im}$ is the score of needs-meeting way $m$ (in store or via delivery )for user scene $i$.
$\chi^W_{im}$ is 1 if $m$ is the ground truth needs-meeting way for user scene $i$, else it is 0.
In our system, the feature integration module and multitask prediction module are trained end to end. The entire loss function is:
\begin{equation}
\text{Loss} = \lambda_1 \text{Loss}_{\text{need}}+\lambda_2 \text{Loss}_{\text{way}}.
\end{equation}
$\lambda_1$ and $\lambda_2$ are hyperparameters that control the importance of the two parts of loss.

