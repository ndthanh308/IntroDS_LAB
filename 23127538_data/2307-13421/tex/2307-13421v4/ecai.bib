
@InProceedings{pmlr-v37-xuc15,
  title = 	 {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
  author = 	 {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2048--2057},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/xuc15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/xuc15.html},
  abstract = 	 {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.}
}

@inproceedings{Jain2019,
address = {Stroudsburg, PA, USA},
author = {Jain, Sarthak and Wallace, Byron C.},
booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
doi = {10.18653/v1/N19-1357},
file = {:Users/shanest/Documents/Library/Jain, Wallace/Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics Human Language Technologie./Jain, Wallace - 2019 - Attention is not Explanation.pdf:pdf},
keywords = {method: attention},
pages = {3543--3556},
publisher = {Association for Computational Linguistics},
title = {{Attention is not Explanation}},
url = {http://aclweb.org/anthology/N19-1357},
year = {2019}
}

@inproceedings{wiegreffe-pinter-2019-attention,
    title = "Attention is not not Explanation",
    author = "Wiegreffe, Sarah  and
      Pinter, Yuval",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1002",
    doi = "10.18653/v1/D19-1002",
    pages = "11--20",
    abstract = "Attention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model{'}s prediction, and consequently reach insights regarding the model{'}s decision-making process. A recent paper claims that {`}Attention is not Explanation{'} (Jain and Wallace, 2019). We challenge many of the assumptions underlying this work, arguing that such a claim depends on one{'}s definition of explanation, and that testing it needs to take into account all elements of the model. We propose four alternative tests to determine when/whether attention can be used as explanation: a simple uniform-weights baseline; a variance calibration based on multiple random seed runs; a diagnostic framework using frozen weights from pretrained models; and an end-to-end adversarial attention training protocol. Each allows for meaningful interpretation of attention mechanisms in RNN models. We show that even when reliable adversarial distributions can be found, they don{'}t perform well on the simple diagnostic, indicating that prior work does not disprove the usefulness of attention mechanisms for explainability.",
}



@article{Vashishth2019AttentionIA,
  title={Attention Interpretability Across NLP Tasks},
  author={Shikhar Vashishth and Shyam Upadhyay and Gaurav Singh Tomar and Manaal Faruqui},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11218}
}


@inproceedings{
lu2021on,
title={On the Dynamics of Training Attention Models},
author={Haoye Lu and Yongyi Mao and Amiya Nayak},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=1OCTOShAmqB}
}

@inproceedings{wu-etal-2018-hard,
    title = "Hard Non-Monotonic Attention for Character-Level Transduction",
    author = "Wu, Shijie  and
      Shapiro, Pamela  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = "oct-nov",
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1473",
    doi = "10.18653/v1/D18-1473",
    pages = "4425--4438",
    abstract = "Character-level string-to-string transduction is an important component of various NLP tasks. The goal is to map an inp
    ut string to an output string, where the strings may be of different lengths and have characters taken from different alphabets. Recent approaches have used sequence-to-sequence models with an attention mechanism to learn which parts of the input string the model should focus on during the generation of the output string. Both soft attention and hard monotonic attention have been used, but hard non-monotonic attention has only been used in other sequence modeling tasks and has required a stochastic approximation to compute the gradient. In this work, we introduce an exact, polynomial-time algorithm for marginalizing over the exponential number of non-monotonic alignments between two strings, showing that hard attention models can be viewed as neural reparameterizations of the classical IBM Model 1. We compare soft and hard non-monotonic attention experimentally and find that the exact algorithm significantly improves performance over the stochastic approximation and outperforms soft attention.",
}

@inproceedings{NEURIPS2018_b691334c
,
 author = {Deng, Yuntian and Kim, Yoon and Chiu, Justin and Guo, Demi and Rush, Alexander},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Latent Alignment and Variational Attention},
 url = {https://proceedings.neurips.cc/paper/2018/file/b691334ccf10d4ab144d672f7783c8a3-Paper.pdf},
 volume = {31},
 year = {2018}
}


@INPROCEEDINGS{8578734,  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},   title={Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},   year={2018},  volume={},  number={},  pages={6077-6086},  doi={10.1109/CVPR.2018.00636}}

@inproceedings{edunov-etal-2018-classical,
    title = "Classical Structured Prediction Losses for Sequence to Sequence Learning",
    author = "Edunov, Sergey  and
      Ott, Myle  and
      Auli, Michael  and
      Grangier, David  and
      Ranzato, Marc{'}Aurelio",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1033",
    doi = "10.18653/v1/N18-1033",
    pages = "355--364",
    abstract = "There has been much recent work on training neural attention models at the sequence-level using either reinforcement learning-style methods or by optimizing the beam. In this paper, we survey a range of classical objective functions that have been widely used to train linear models for structured prediction and apply them to neural sequence to sequence models. Our experiments show that these losses can perform surprisingly well by slightly outperforming beam search optimization in a like for like setup. We also report new state of the art results on both IWSLT{'}14 German-English translation as well as Gigaword abstractive summarization. On the large WMT{'}14 English-French task, sequence-level training achieves 41.5 BLEU which is on par with the state of the art.",
}



@article{10.5555/972470.972474,
author = {Brown, Peter F. and Pietra, Vincent J. Della and Pietra, Stephen A. Della and Mercer, Robert L.},
title = {The Mathematics of Statistical Machine Translation: Parameter Estimation},
year = {1993},
issue_date = {June 1993},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {19},
number = {2},
issn = {0891-2017},
abstract = {We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus.},
journal = {Comput. Linguist.},
month = {jun},
pages = {263–311},
numpages = {49}
}



@inproceedings{10.5555/2969033.2969073,
author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
title = {Recurrent Models of Visual Attention},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.},
booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2204–2212},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'14}
}


@inproceedings{wu-cotterell-2019-exact,
    title = "Exact Hard Monotonic Attention for Character-Level Transduction",
    author = "Wu, Shijie  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1148",
    doi = "10.18653/v1/P19-1148",
    pages = "1530--1537",
    abstract = "Many common character-level, string-to-string transduction tasks, e.g., grapheme-to-phoneme conversion and morphological inflection, consist almost exclusively of monotonic transduction. Neural sequence-to-sequence models with soft attention, non-monotonic models, outperform popular monotonic models. In this work, we ask the following question: Is monotonicity really a helpful inductive bias in these tasks? We develop a hard attention sequence-to-sequence model that enforces strict monotonicity and learns alignment jointly. With the help of dynamic programming, we are able to compute the exact marginalization over all alignments. Our models achieve state-of-the-art performance on morphological inflection. Furthermore, we find strong performance on two other character-level transduction tasks. Code is available at https://github.com/shijie-wu/neural-transducer.",
}


@inproceedings{Attnall17,
 author = "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia",
 booktitle = "Advances in Neural Information Processing Systems",
 editor = "I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett",
 pages = "5998--6008",
 publisher = "Curran Associates, Inc.",
 title = "Attention is All you Need",
 url = "https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf",
 volume = "30",
 year = "2017"
}

@inproceedings{Bahdanau2016,
  author    = "Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio",
  editor    = "Yoshua Bengio and
               Yann LeCun",
  title     = "Neural Machine Translation by Jointly Learning to Align and Translate",
  booktitle = "3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings",
  year      = "2015",
  url       = "http://arxiv.org/abs/1409.0473",
  timestamp = "Wed, 17 Jul 2019 10:40:54 +0200",
  biburl    = "https://dblp.org/rec/journals/corr/BahdanauCB14.bib",
  bibsource = "dblp computer science bibliography, https://dblp.org"
}

@article{10.5555/92858.92860,
author = {Brown, Peter F. and Cocke, John and Pietra, Stephen A. Della and Pietra, Vincent J. Della and Jelinek, Fredrick and Lafferty, John D. and Mercer, Robert L. and Roossin, Paul S.},
title = {A Statistical Approach to Machine Translation},
year = {1990},
issue_date = {June 1990},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {16},
number = {2},
issn = {0891-2017},
abstract = {In this paper, we present a statistical approach to machine translation. We describe the application of our approach to translation from French to English and give preliminary results.},
journal = {Comput. Linguist.},
month = {jun},
pages = {79–85},
numpages = {7}
}
@Techreport{Krizhevsky09learningmultiple,
  author = {Krizhevsky, Alex and Hinton, Geoffrey},
 address = {Toronto, Ontario},
 institution = {University of Toronto},
 number = {0},
 publisher = {Technical report, University of Toronto},
 title = {Learning multiple layers of features from tiny images},
 year = {2009},
 title_with_no_special_chars = {Learning multiple layers of features from tiny images}
}

@inproceedings{ChorowskiBCB14,
  title={End-to-end continuous speech recognition using attention-based recurrent nn: First results},
  author={Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={NIPS 2014 Workshop on Deep Learning, December 2014},
  year={2014}
}

@article{machine_trns,
  author    = "Graves, Alex",
  title     = "Generating Sequences With Recurrent Neural Networks",
  journal   = "CoRR",
  volume    = "abs/1308.0850",
  year      = "2013",
  url       = "http://arxiv.org/abs/1308.0850",
  archivePrefix = "arXiv",
  eprint    = "1308.0850",
  timestamp = "Mon, 13 Aug 2018 16:47:21 +0200",
  biburl    = "https://dblp.org/rec/journals/corr/Graves13.bib",
  bibsource = "dblp computer science bibliography, https://dblp.org"
}

@article{Mathew_2021, title="HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection", volume="35", url="https://ojs.aaai.org/index.php/AAAI/article/view/17745", DOI="10.1609/aaai.v35i17.17745", abstractNote="Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public for other researchers.", number=
"17", journal="Proceedings of the AAAI Conference on Artificial Intelligence", author="Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh", year="2021", month="May", pages="14867-14875" }


@InProceedings{pmlr-v189-pandey23a,
  title = 	 {On the Interpretability of Attention Networks},
  author =       {Pandey, Lakshmi Narayan and Vashisht, Rahul and Ramaswamy, Harish G.},
  booktitle = 	 {Proceedings of The 14th Asian Conference on Machine
 Learning},
  pages = 	 {832--847},
  year = 	 {2023},
  editor = 	 {Khan, Emtiyaz and Gonen, Mehmet},
  volume = 	 {189},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {12--14 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v189/pandey23a/pandey23a.pdf},
  url = 	 {https://proceedings.mlr.press/v189/pandey23a.html},
  abstract = 	 {Attention mechanisms form a core component of
 several successful deep learning architectures, and
 are based on one key idea: “The output depends only
 on a small (but unknown) segment of the input.” In
 several practical applications like image captioning
 and language translation, this is mostly true. In
 trained models with an attention mechanism, the
 outputs of an intermediate module that encodes the
 segment of input responsible for the output is often
 used as a way to peek into the ‘reasoning’ of the
 network. We make such a notion more precise for a
 variant of the classification problem that we term
 selective dependence classification (SDC) when used
 with attention model architectures. Under such a
 setting, we demonstrate various error modes where an
 attention model can be accurate but fail to be
 interpretable, and show that such models do occur as
 a result of training. We illustrate various
 situations that can accentuate and mitigate this
 behaviour. Finally, we use our objective definition
 of interpretability for SDC tasks to evaluate a few
 attention model learning algorithms designed to
 encourage sparsity and demonstrate that these
 algorithms help improve interpretability.}
}

@inproceedings{lei-etal-2020-tvqa,
    title = "{TVQA}+: Spatio-Temporal Grounding for Video Question Answering",
    author = "Lei, Jie  and
      Yu, Licheng  and
      Berg, Tamara  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.730",
    doi = "10.18653/v1/2020.acl-main.730",
    pages = "8211--8225",
    abstract = "We present the task of Spatio-Temporal Video Question Answering, which requires intelligent systems to simultaneously retrieve relevant moments and detect referenced visual concepts (people and objects) to answer natural language questions about videos. We first augment the TVQA dataset with 310.8K bounding boxes, linking depicted objects to visual concepts in questions and answers. We name this augmented version as TVQA+. We then propose Spatio-Temporal Answerer with Grounded Evidence (STAGE), a unified framework that grounds evidence in both spatial and temporal domains to answer questions about videos. Comprehensive experiments and analyses demonstrate the effectiveness of our framework and how the rich annotations in our TVQA+ dataset can contribute to the question answering task. Moreover, by performing this joint task, our model is able to produce insightful and interpretable spatio-temporal attention visualizations.",
}