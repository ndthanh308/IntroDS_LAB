% !TEX root = ../main.tex




% % Figure environment removed


% Using Shot Filter, the user selected \textit{Top}’s shots, and saw \textit{Top} has 10 errors out of 21 points she lost \textbf{(T2)}. He then selected Errors to focus on those 10 rallies ended with an error shot by \textit{Top}. Seeing the distribution of these error shots on the Heat Map, the user found 70\% of the error shots were from the middle, and could tell that these were defensive shots from seeing the shot trajectories and video previews on the virtual court \textbf{(T3)}. The user further selected a rally from the Rally Menu among all the 10 error shot rallies and examined the player movement and the sequence that led to the error shot \textbf{(T4)}. The user watched several rallies and concluded that \textit{Top} needs to practice her defensive shots on the backhand side  \textbf{(T5)}.

\section{VIRD - \underline{V}R B\underline{ird} Video Analysis Tool}
\label{sec:vird}
Based on the identified goals and tasks, we designed VIRD, an immersive video analysis platform for high-performance badminton coaching. Targeting professional badminton coaches and players, VIRD features a top-down analysis approach and supports an integrated data and video analysis workflow based on CV-based data collection and a 3D interactive environment in VR. The designs were iterated  based on expert feedback from three coaches.
% 
The code for VIRD is open-source\footnote{The code for VIRD will be made available at https://to-be-open.github.io}.

% We first described the data preprocessing techniques, the design of VIRD, and the  design iteration with experts.




\subsection{Top-Down Analysis Workflow} 
 To address G1, we designed a \emph{top-down analysis approach} and verified it with two coaches (I1 and I2) in a follow-up interview.
% 
 The top-down user flow contains the following four steps: First, users find rallies of interest based on summary statistics (\textbf{T1, T2}). Second, they compare and analyze the filtered rallies to derive insights (\textbf{T3, T4}). Third, they investigate game details to verify insights (\textbf{T5}). Finally, they examine similar patterns across rallies to conclude insights (\textbf{T6}).

 
We tested the proposed workflow
by gathering coaches' feedback on a hypothetical top-down analysis workflow for examining a lost game. 

\scriptsize
\begin{adjustwidth}{0.5cm}{0.5cm}
Initially, the user reviews the game summary to form an impression of the match. 
 Observing a tight score of 17 (\textit{Player A}) to 21 (\textit{Player B}), the user chooses to analyze the 21 rallies where \textit{Player A} lost points (\textbf{T1}). 
%
They find 10 errors among the 21 lost points and focus their analysis on those 10 rallies ending in error shots (\textbf{T2}). 
%
On the rally level, the user finds that 6 out of 10 error rallies are short and towards the end of the game (\textbf{T3}).
Examining the heat map and shot trajectories, the user notes that 70\% are from the middle, 
and identifies them as defensive shots (\textbf{T4}). 
%
The user selects a short rally (\textbf{T5}) to study player movement and the sequence leading to the error shot. 
After watching multiple error rallies  (\textbf{T6}), the user concludes that \textit{Player A} needs to improve defensive shots on the backhand side and physical fitness.
\end{adjustwidth}

\normalsize
Both coaches agreed that this workflow is precisely what they need. \textit{``We're manually doing that because currently I won't know where exactly to go back in the video to see all the unforced errors''} (I2). 



\subsection{Computer Vision Data Preprocessing}
\label{sec:data_preprocessing}
To address G2, we applied state-of-the-art computer vision (CV) models to automate the data collection from videos.
We developed a semi-automatic data preprocessing pipeline for monocular match videos, which includes manual game breakdown, shot classification algorithms, and automatic 3D shot and player reconstruction.
% 
Based on task abstraction, three types of data must be extracted from a match video.


\para{1) Game and Rally Summary} are automatically computed based on manual annotation and output from CV models:

\begin{itemize}
    \item \emph{Rally Breakdown}: 
    To obtain a game summary, player scores and average rally statistics are required. Therefore, each game needs to be split by rallies. 
    We manually annotated the time ranges (start and end), player who serves, and the winning side of all rallies from the match video. Our algorithm then derives score and game information based on the rally breakdown.

    \item \emph{Shot Breakdown}: 
    To obtain a rally summary, the duration of each rally and shot count are required. 
    We obtain the timestamps and the hitter of each shot from running MonoTrack~\cite{liu-2022} with minor manual clean-up.
\end{itemize}



\para{2) 3D Spatial Data} are automatically reconstructed from CV models.
\begin{itemize}
    \item \emph{3D Shot Trajectory}: 
    We automatically reconstructed 3D trajectories and velocities for all shots from running MonoTrack~\cite{liu-2022}.

    \item \emph{3D Player Model}: 
    We used MonoTrack~\cite{liu-2022} to estimate  court and player positions, and CLIFF~\cite{li-2022} to predict smooth 3D player poses from videos. This combination allows for the reconstruction of 3D player models.
\end{itemize}

\para{3) Shot Statistics} are automatically derived from the 3D spatial data. 
\jui{I think if we can show some helpful illustrations for these derived statistics, it can be useful} 
\begin{itemize}
    \item \emph{Shot Tendency}: 
    To detect whether a shot leading to a point is a winner or an unforced error (as described in Shot Outcome), we first classified the shot tendency by approximating the shuttle’s velocity vector when it passes the net: the tendency is defensive when the vector is going upward (away from the ground), and offensive if opposite. This classification is derived from expert input in the formative study.
% \jui{this is motivated by Toby's need right? Should we say this (if not here, then somewhere)?}
% The velocity information is obtained from running MonoTrack~\cite{liu-2022}.

    \item \emph{Shot Outcome}:
% \jui{There are two problems here: 1) the writing makes it confusing what is shot tendency and what is classification. One way to separate them is: tendency is the attempt of the shot, and the "classification" is the outcome based on this attempt. I will clarify these two paragraphs more. 2) "classification" might not be the right choice. When I read "shot classification", I immediately think of the types of the shot, like "clears", "drives", "net drops", "smashes" etc.}
    Our algorithm categorizes shots as winners, errors, or normal shots to calculate the winner and error shot counts.
    A rally ends with a winner by the scorer or an error by the point loser.
    If the last shot is offensive by the scorer, it's a winner; if defensive by the point loser, the penultimate shot is the winner. Conversely, if the last shot is offensive by the point loser, it's an error; if defensive by the scorer, the penultimate shot is an error. All others are normal shots.
% % winner
% If the final shot is an offensive shot hit by the scorer, then it is labeled as a winner for the scorer.
% If the final shot is a defensive shot hit by the point loser, then the second last shot is a winner for the scorer.
% % error
% Conversely, if the final shot is an offensive shot hit by the point loser, then it is labeled as an error; if it is a defensive shot hit by the scorer, then the second last shot is labeled as an error by the point loser.

    \item \emph{Shot Distribution}:
    From the formative study, coaches use shot locations to classify shots into six areas on the court, including front/middle/back on the left and right sides. 
    To compute the shot distribution, 
    our algorithm projects each shot's start (from) and endpoint (to) onto the court to decide shot locations.

% Our algorithm projects each shot's start and end point onto the court\jui{it might not be clear to the reader why the projection is needed. Explain it slightly more.}, and computes the shot distribution across seven court areas on each side, including front/middle/back on the left and right sides or out-of-bound.

\end{itemize}

\vspace{1mm}
\noindent
Overall, our data preprocessing pipeline is largely automated. 
Except for rally breakdown and winner/server annotation, all other data are obtained through automatic algorithms. 
% \jui{the winners and serves are also annotated. Also, I might supplement that this limitation can be addressed in cv but is out of scope for this paper}.
The manual annotation takes up roughly half of the video duration (e.g., 30 minutes for labeling a 1-hour video).
While our method is not entirely automatic, we anticipate that CV techniques may be able to address these manual annotations in the future, though they are beyond the scope of our current study.

% In a first step, match videos need to be parsed to extract match-level and rally-level statistics and spatial data. We build on previous work in computer vision to assemble a semi-automatic data processing pipeline.
% Specifically, we use MonoTrack~\cite{liu-2022} to predict court and player positions, detect shots, and reconstruct 3D trajectories from monocular badminton videos for a rally; and we use CLIFF~\cite{li-2022} to predict smooth 3D player poses from monocular videos. 
% In addition, we manually annotate rallies to extract detailed time ranges and label the winning side for each rally.
% We outline the important video-derived data we use in VIRD with a short description of how they are computed in Table~\ref{tab:data}.


% {\renewcommand{\arraystretch}{1.2}% for the vertical padding
% \begin{table}
%     \scriptsize
%     \centering
%     \caption{Preprocessed match data from the video.}
%     \label{tab:data}
%     \vspace{-1em}
%     \begin{tabularx}{\columnwidth}{p{2cm} p{5.7cm}}
%     \toprule
    
%     \textbf{Data Type} & \textbf{Description} \\ \midrule
%     Rally breakdown & Time ranges (start and end), player who serves, and winning side  for all rallies in the match, manually annotated. \\ \hline
%     Shot breakdown  & Timestamps and the hitter of each shot, obtained from running MonoTrack~\cite{liu-2022} with minor manual clean-up. \\ \hline
%      3D shot & 3D trajectories and velocity for all shots from running MonoTrack~\cite{liu-2022}. \\ \hline
%     3D player poses & 3D player poses from running CLIFF~\cite{li-2022} on rally videos.\\ \hline
%     Shot tendency (offensive or defensive)  & Shot tendency approximated by the shuttle's velocity vector when passing the net, i.e., defensive when 
%     % the velocity vector drifts 
%     upward (away from the ground) and offensive when downward.
%     % (it always passes the net unless it is the last shot and one side made a mistake)
%     \\
% 	\bottomrule
% \end{tabularx}
% % \vspace{-6mm}
% \end{table}
% }



%For VIRD to support the goals and tasks outlined, the first step is to parse the match videos -- preferably in an automatic pipeline -- in order to obtain match-level and rally-level statistics, and useful spatial data. 
%Fortunately, several previous work in computer vision have already laid the foundation for what we want. 
%Specifically, MonoTrack~\cite{liu-2022} can predict court position, player poses, detect shots, and reconstruct 3D trajectories from monocular badminton videos for a rally; and CLIFF~\cite{li-2022} can predict smooth 3D player poses from monocular videos. Our data preprocessing pipeline is built on these two work. 
%We outline the important video-derived data we use in VIRD with a short description of how they are computed in Table~\ref{tab:data}.

% \begin{itemize}
%     \item Time ranges (start and end) for all the rallies in a video. We manually annotate this information for all our test videos. We also manually annotate which player serves, and which side wins the point in each rally.
%     \item Each shot in a given rally (in timestamp), and who hit it. This is from running MonoTrack~\cite{liu-2022} with minor manual clean-up.
%     \item 3D trajectories and velocity of each shot. We got this from running MonoTrack~\cite{liu-2022}.
%     \item 3D poses of the players. We got this from running CLIFF~\cite{li-2022}.
%     \item Shot tendency (offensive or defensive). We extract shot tendency by approximating the velocity vector of the shuttle when it passes the net (it always passes the net unless it is the last shot and one side made a mistake). If the velocity vector drifts upward (away from the ground), then it is defensive, otherwise it is offensive.
% \end{itemize}




% % Figure environment removed


\subsection{VIRD Design}
To enable an ideal top-down match analysis, the VIRD interface features two modes: Summary Mode in a black background (Fig.~\ref{fig:teaser}-1) and Game Mode in a blue background (Fig.~\ref{fig:teaser}-2). The distinction between the two modes depends on whether the user is analyzing matches at a summary level (Summary) or exploring individual rallies (Game).
% 
% \noindent \textbf{Summary Mode}, as shown in Fig.~\ref{fig:teaser}-1, provides a high-level overview of the game statistics
% % (score breakdown, duration annotation, shot statistics, etc.), 
% and a rally filtering mechanism. 
% % based on users' interests. 
% This directly supports user needs in quickly summarizing a game, and drilling into details on demand (\textbf{G1} and \textbf{G2}).
% % 
% \noindent \textbf{Game Mode}, as shown in Fig.~\ref{fig:teaser}-2, provides a real-time, 3D reconstructed rally playback with dynamic shot trajectories and player poses. This allows users to investigate and interact with the data in context (\textbf{G2} and \textbf{G3}). 




% VR interface
%As shown in Fig.~\ref{fig:teaser}, the VR interface consists of two modes, a Summary Mode in black background (Fig.~\ref{fig:teaser}-1) and a Game Mode in blue background (Fig.~\ref{fig:teaser}-2), where the distinction between the two modes depends on whether the user is analyzing matches at a summary level (Summary) or delving into individual rally (Game).
%% 
%Summary Mode provides an overview of the match \textbf{(G1)} and guides the focus of the analysis by filtering and linking the static stats to the rally video \textbf{(G2)}. Game Mode presents 3D reconstructed game with dynamic shot trajectories and player pose along with 2D rally video \textbf{(G2 \& G3)}.



% Six main components of VIRD are shown in Fig.~\ref{fig:VIRD}. 
% \textit{Match Summary} (a)  provides an overview of the match and game statistics. 
% \textit{Shot Filter} (b) provides shot-level summary and allow filter shots by players, shot outcomes, and shot locations. 
% \textit{Rally Menu} (c) shows the list of filtered rallies with rally-level data, including length and score. 
% \textit{Virtual Court} (d) shows a 1-to-1 scale badminton court, where situated visualizations of 3D data and game views are projected, including shot arcs, heatmap, dynamic shot trajectory, and player poses. 
% \textit{Video View} (e) displays the original video footage of the selected shot or rally.
% \textit{3D Game View} (f) plays the reconstructed 3D game in sync with the video.
% % 
% Summary Mode always presents (a) to (d), and will show (e) and (f) when the user chooses a shot for preview; Game Mode presents (b) to (f) to show details of the selected rally with access to other similar rallies.
% 

Below, we described the detailed design of VIRD components and interaction between Summary and Game Mode to satisfy six analytic tasks. 
Descriptions are based on 2022 BWF World Championship match between Marin and Yamaguchi~\cite{match_marin_yamaguchi} (M2) used in case studies. 

\subsubsection{Visual Components}
\label{sec:visual_components}

\para{1) Statistical summary and filtering (T1, T2).}
In order to identify rallies of interest, experts need to break down the match and examine the statistics of games and rallies.  
We designed Match Summary and Shot Filter to support experts getting necessary metadata and filtering data in Summary Mode.
% , such as selecting all winner shots by Marin in Game 1. 



\setlength{\intextsep}{0pt}%
\begin{wrapfigure}{L}{0.23\textwidth}
	\centering
	% Figure removed
	 \vspace{-8mm}
	\caption{Match Summary}
	 % \vspace{-2mm}
	\label{fig:match_summary}
\end{wrapfigure}

 % Match Summary 
With Match Summary, users can see the match's duration, rally count, average shot count per rally, the winner, and the scores of each game (T1). These statistics are essential to overview the pace and intensity of the match. 
A user can select the game and rallies won by a player from the game selector, e.g., 17 rallies won by Marin in G1. Similar statistics for the selected game are displayed below the game selector. 
Game 3 is split into two halves by default, as players switch sides at midpoint (when the leading side reaches 11 points) and therefore spatial data cannot be displayed on the same side of the court.
These metadata help experts identify games that were more challenging or outstanding for deeper analysis.
In addition, users can `split' a game into first and second half, similar to Game 3. This design was to provide finer granularity of the game. In the formative study, we found that sometimes experts would analyze each half separately, as players can receive coaching advice in a short break at the midpoint of each game. 

% Shot Filter

\FloatBarrier
\begin{wrapfigure}{R}{0.3\textwidth}
	\centering
	% Figure removed
	 \vspace{-8mm}
	\caption{Shot Filter}
	 % \vspace{-2mm}
	\label{fig:shot_filter}
\end{wrapfigure}
Once the game is selected, Shot Filter allows users to specify the shot they want to analyze based on players and shot attributes, such as winners and errors (T2). According to the coaches in our user testing, this feature was considered extremely valuable as it provides an immediate comparison between the players. 
 
For example, among 17 rallies Marin scored, 9 points were due to Marin's winners while 8 were due to Yamaguchi's errors,
which tells a very different story if Marin had 17 winners. 
Further, a user can overview the shot distribution on the heat map and filter shots by areas, e.g., select the purple 56\% grid to filter Marin's winner shots hit from the back right. The darker color indicates more shots are \textit{from} (purple) or \textit{to} (orange) the area.
% 
The color schemes was considered helpful by experts to recognize hot spots or shot tendency between games or players, e.g. compare two players' heat map of winner shots.  


% Combining Match Summary and Shot Filter, the user can filter rallies based on game, players and shot attributes
% , which supports them focusing on rallies of interest. 
% All interactions are supported through VR controller's pointer and trigger button.
% Next, we discussed features that support detailed insight generation and verification across rallies.

% This feature fulfills the analysis tasks T2 and T3.

\para{2) Analyze statistical and spatial shot attributes (T3, T4).}
To help users identify shot patterns before diving into game details, we designed Rally Menu and Situated Visualizations to support immersive shot analysis within its game contexts in Summary Mode.

% Rally Menu
 \vspace{2mm}
\FloatBarrier
\begin{wrapfigure}{R}{0.18\textwidth}
	\centering
	% Figure removed
	 \vspace{-6mm}
	\caption{Rally Menu}
	\label{fig:rally_menu}
\end{wrapfigure}
Rally Menu provides an overview of shot count and scoring cadence among the rallies of interest (T3). 
Each rally is presented on a rally item with score and length information in the scrollable menu. Short rallies (less than 10 shots) are highlighted in red to allow special focus based on coaches' requirements. For example, a user can tell the tempo of the game from the number of short rallies (4 out of 9) and the variation of shot counts between these rallies won by Marin. This overview of rally statistics supports finding patterns across rallies of interest.



% Situated Vis
\FloatBarrier
\begin{wrapfigure}{R}{0.25\textwidth}
	\centering
	% Figure removed
	 \vspace{-6mm}
	\caption{Situated Visualizations}
	 % \vspace{-2mm}
	\label{fig:virtual_court}
\end{wrapfigure}
Based on the applied filters, 3D shot arcs and heatmap of the filter shots (e.g., all winners by Marin in Game 1) are visualized in-situ on the 1-to-1 virtual court.
The shots are color-coded based on the outcome (red for errors, green for winners, and white for all other shots). 
Upon interacting with the individual shot arcs, the shuttle's dynamic trajectory will be displayed in real-time (details in Sec.~\ref{sec:interaction}). 
The situated visualizations enable the user to derive insights into shots' spatial attributes (i.e., arc shapes, distributions). Experts use this design to quickly observe insights from shots across multiple rallies.

\para{3) Investigate game details of shot and rally (T5, T6).}
\FloatBarrier
\begin{wrapfigure}{R}{0.17\textwidth}
	\centering
	% Figure removed
	 \vspace{-6mm}
	\caption{Game View}
	 % \vspace{-2mm}
	\label{fig:game_vieiw}
\end{wrapfigure}
Once some patterns are observed, it is necessary for experts to investigate actual game details to verify insights and investigate root causes. The user can preview the game moments of the chosen shot in Summary Mode, or delve into the entire rally in Game Mode.

Game View displays a 3D reconstructed game view simultaneously with the video to support a deeper investigation of the game details (T5). 3D game view presents the dynamic movement of shots and players to allow accurate spatial perception and flexible viewing angles. 

Upon examining the exact game moment of the chosen shot, the user can expand the analysis to the entire rally from the Game View or to other rallies containing similar shots from the Rally Menu (T6). 

% 
% Fig.~\ref{fig:Interaction}-2 shows the user interaction of linking from a shot in Summary Mode to the rally in Game Mode. 



% The user can select `View Match' from the hovered shot preview in Summary Mode (Fig.~\ref{fig:Interaction}-1) to watch the entire rally in Game Mode (Fig.~\ref{fig:Interaction}-2).

% 


\subsubsection{User Interaction}
\label{sec:interaction}
Users interact with VIRD interface and visualizations using VR controllers.
% 
Each shot can be hovered to select, which will link to the game context of the shot (Fig.~\ref{fig:Interaction}-1) in Summary Mode, showing Game View that contains 3D dynamic shot trajectory and player poses, and the same shot duration in the video.
This interaction allows users to instantly review the game moment of each shot in the filtered group (e.g., all winner shots) to obtain the context of 3D data. 
To navigate to the Game Mode (Fig.~\ref{fig:Interaction}-2), the users can select \textit{``View Match''} from the Game View of the hovered shot, or select a rally from the Rally Menu.
Furthermore, the user can directly hover over a shot arc in the rally (Fig.~\ref{fig:Interaction}-3) to play the video from the desired game moment.
This feature allows users to replay a specific shot or shot sequence easily.

Meanwhile, users can flexibly navigate the virtual court, by using a thumb stick or physically moving around, to obtain an accurate spatial and temporal perception of 3D data (Fig.~\ref{fig:Interaction}-3).
% 
VR environment also offers flexible viewpoints to analyze the 3D game from different perspectives, such as the first-person player view (Fig.~\ref{fig:Interaction}-4). 
% using shot start/end points on the ground to compare player coverage.


% In Game Mode, the shot arcs and foot positions of all shots in the selected rally are shown.

% When a shot or a rally is selected, \textbf{(e) Video View} displays the original video footage of the selected shot in repeat or the entire rally. \textbf{(f) 3D Game View} will play in sync with the video on the virtual court.
 % Rally Menu shows the list of rallies based on the Match Summary and Shot Filter criteria. Each rally is presented in a rally item card in the scrollable menu with score and length information. A user can select a rally to view the entire rally in Game Mode. The number of short rallies (less than 10 shots, based on formative study) is highlighted in red to allow special focus based on coaches' requirements.
% This feature supports T2, T4 and T5.


% ===========================

% \noindent
% \textbf{(a) Match Summary} provides an overview of the match and game statistics. At the top, a user can see the match's duration, the number of rallies, average shot count per rally, and the winner. A user can select the game and rallies won by a player for further analysis (e.g., 17 rallies won by Marin in G1 were selected in Fig.~\ref{fig:VIRD}a). Similar to the match statistics, duration and rally stats for the selected game are displayed below the game selector.
% This feature fulfills the analysis tasks T1 and T2.

%  \noindent
% \textbf{(b) Shot Filter} allows users to specify the shot they want to analyze based on players, shot outcome (errors, winners, or all shots), and shot locations (six areas on each side). Further, a user can use the shot heatmap to filter shots by areas (e.g., a user can select the purple 56\% grid to filter Marin's winner shots hit from the back right). The total number of filtered shots is shown to the right of the location filter. 
% Combining Match Summary and Shot Filter, the user can filter rallies based on game, players and shots, which supports them in finding rallies of interest.
% This feature fulfills the analysis tasks T2 and T3.
 
% \noindent
% \textbf{(c) Rally Menu} shows the list of rallies based on the Match Summary and Shot Filter criteria. Each rally is presented in a rally item card in the scrollable menu with score and length information. A user can select a rally to view the entire rally in Game Mode. The number of short rallies (less than 10 shots, based on formative study) is highlighted in red to allow special focus based on coaches' requirements.
% This feature supports T2, T4 and T5.
% % \jui{Is 10 justifiable from interview? I would justify more here.}

% \noindent
% \textbf{(d) Virtual Court} presents immersive visualizations for 3D data. In Summary Mode, a user can see the shot arcs, player's foot positions, and shot heat map projected onto the virtual court based on the selection in Shot Filter. The shots are color-coded based on the outcome (red for errors, green for winners, and white for all other shots). Each shot is interactable with the VR controller and will link to a video preview of the hovered shot. Details on the interaction are described in Sec.~\ref{sec:interaction}. In Game Mode, the shot arcs and foot positions of all shots in the selected rally are shown.
% When a shot or a rally is selected, \textbf{(e) Video View} displays the original video footage of the selected shot in repeat or the entire rally. \textbf{(f) 3D Game View} will play in sync with the video on the virtual court.
% These views collectively support T2, T4 and T5.



% Figure environment removed




% \subsection{Interaction}
% \label{sec:interaction}
% Both VR controllers to interact with VIRD are rendered as virtual hands, as shown in Fig.~\ref{fig:Interaction}-1-1. %, with the shape of hands, are used to interact with VIRD, 
% The left controller is used to point at a shot arc to trigger a shot preview in Summary Mode. When a shot is hovered, the left controller will provide a haptic feedback and both (e) Video View and (f) 3D Game View will be displayed while other shot arcs in (d) will be hidden. When the user hovers on the same shot again or presses on the reset button, the shot will be deselected with another haptic feedback, with the view reset to (d). The same interaction applies to Game Mode, with the difference that hovering a shot will repeat the shot in the rally video and deselecting will resume playback of the rest of the rally.
% % 
% The right controller is used to interact with all the buttons on the panels (a-c) to apply filters and select rally of interest. The thumb stick on the right controller allows the user to move freely in the horizontal direction. As shown in Fig.~\ref{fig:Interaction}-1, the user can change viewpoint flexibly to analyze the 3D visualizations or experience the game from the first-person view on the virtual court.

% Fig.~\ref{fig:Interaction}-2 shows the user interaction of linking from a shot in Summary Mode to the rally in Game Mode. For example, the user sets the Shot Filter with the right controller to view all error shots by \textit{Top} player. Then, the user points at an error shot to preview the shot in video with the left controller. Finally, the user selects from Rally Menu with the right controller to watch the entire rally in Game Mode.


\subsection{Design Iterations}
\label{sec:design_iteration}
We conducted three rounds of user testing throughout the design process. Three active high-performance badminton coaches in US were involved  (C1-C3; M=3; Age: 40-60), who were former players on the US, Malaysia, and Nepal badminton national teams, respectively. 
They have coaching experiences ranging from 15 to over 30 years. C1 had participated in our formative study while C2 and C3 were newly introduced at the design iteration stage.
Given the challenges in accessing domain experts, we adopted a progressive approach wherein each coach evaluated our prototype at various design stages, focusing on distinct aspects. 
We tested VIRD on the match of 2020 BWF World Tour Finals of Women Single between Tai and Marin~\cite{match_tai_marin}.

\noindent
\textbf{Round 1. User flow and data analysis.} The first testing was conducted on the initial prototype with C1, where we elicited the coach's feedback on the overall analysis approach and the shot filtering features.
The coach appreciated the top-down approach and interactive analysis process with immediate access to all match data and videos.
On top of the existing summary data and filters, he suggested showing winner and error shots separately to support an immediate comparison of the shot patterns.
Further, we designed two interaction methods to apply Shot Location Filter,  1) select buttons on the Shot Filter panel and 2) physically move to the desired area on the virtual court. However, the coach felt 1) is more useful as moving around the court to filter shots during the analysis would be tedious and distracting.

\noindent
\textbf{Round 2. Interaction with the visualization and interface.} The second testing was run a month later with C2, with a focus on the interaction of linking the static data to the dynamic trajectories and videos. We showed the dynamic bird trajectory of a hovered shot arc, but to view the original rally video the user had to scroll through and select from the Rally Menu.
The coach suggested augmenting the preview of the selected shot arc with the video, as \textit{``it takes time to find the video part of it right now''}.
He also emphasized the importance of pinpointing on the cause of the outcome during coaching. It is not enough to see where an error shot occurred in general, but to let the player see the shot sequence and player movement that lead to the outcome. 
Therefore, we implemented shot-to-rally interaction (Fig.~\ref{fig:Interaction}-1 to 2) to support coaches effectively look into specific rally where the error/winner occurs for detailed analysis into root cause. 

\noindent
\textbf{Round 3. Immersive 3D visualization.} We conducted the third test two months later with C3 on the usefulness of immersive visualizations. The coach was able to preview each group of filtered shots (e.g., winners) efficiently and interpreted the shot types from the 3D shot arcs to answer his coaching question, like \textit{``What are the shots Tai used to win?''- 1 cross drop [shot], 2 smash [shots], 1 block [shot]}. 
He also valued the color usage in the visualizations to tell the shot percentage on the heat map and highlight winner and error shots.
However, since 3D player poses were not implemented at the moment, we found all coaches still mainly watch the video view to analyze the rally as player movement is critical in finding the root cause,  e.g., \textit{``You hit the shot and it was a winning rally, why? Because the opponent wasn’t there yet''} (C2).
Both C2 and C3 mentioned the inclusion of player poses to enhance the usefulness and engagement of the 3D game view. Therefore, we worked on player pose estimation after the third user testing.

During the user testing, we also elicited coaches' feedback on VR environment.
% as all of them were first-time VR users. 
They agreed VR provides additional benefits in analyzing a match video, such as immediate access to all relevant information, flexible viewpoints, and an interactive approach. For instance, C1 commented \textit{``it was very helpful to see the video and the bird going with the trajectory at the same time.''}
% \textit{``when I put the headset on I already have information that I may need without even having to watch the video''} \jui{this is vague. what did D1 mean?}. 
C2 moved to the bottom left of the court while watching the 3D game view because \textit{``this is where I sit as a coach''}. C3 shared that the interaction to select a shot and link to the actual match video is very helpful as \textit{``it’s important to know how the player put the pressure and create a situation [in the game]''}.