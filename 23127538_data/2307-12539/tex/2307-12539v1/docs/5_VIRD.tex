% !TEX root = ../main.tex

\section{VIRD - \underline{V}R B\underline{ird} Video Analysis Tool}
\label{sec:vird}
\re{We designed VIRD, our immersive video analysis platform for high-performance badminton coaching, targeting professional badminton coaches and players. 
VIRD features a top-down analysis approach and supports an integrated data and video analysis workflow based on CV-based data collection and a 3D interactive environment in VR. We iterated the designs based on expert feedback from three coaches.}
%Based on the identified goals and tasks, we designed VIRD, an immersive video analysis platform for high-performance badminton coaching. Targeting professional badminton coaches and players, VIRD features a top-down analysis approach and supports an integrated data and video analysis workflow based on CV-based data collection and a 3D interactive environment in VR. We iterated the designs based on expert feedback from three coaches.
% The code for VIRD is open-source\footnote{The code for VIRD will be made available at https://to-be-open.github.io}.

\subsection{Top-Down Analysis Workflow} 
 To address G1, we designed a \emph{top-down analysis approach} and verified it with two coaches (I1 and I2) in a follow-up interview.
% 
 The top-down user flow contains the following four steps: First, users find rallies of interest based on summary statistics (\textbf{T1, T2}). Second, they compare and analyze the filtered rallies to derive insights (\textbf{T3, T4}). Third, they investigate game details to verify insights (\textbf{T5}). Finally, they examine similar patterns across rallies to conclude insights (\textbf{T6}).
 
We tested the proposed workflow
by gathering coaches' feedback on a hypothetical top-down analysis workflow for examining a lost game: 


\begin{adjustwidth}{0.5cm}{0.5cm}
Initially, the user reviews the game summary to form an impression of the match. 
 Observing a tight score of 17 (\textit{Player A}) to 21 (\textit{Player B}), the user chooses to analyze the 21 rallies where \textit{Player A} lost points (\textbf{T1}). 
%
They find 10 errors among the 21 lost points and focus their analysis on those 10 rallies ending in error shots (\textbf{T2}). 
%
On the rally level, the user finds that 6 out of 10 error rallies are short and towards the end of the game (\textbf{T3}).
Examining the heat map and shot trajectories, the user notes that 70\% are from the middle, 
and identifies them as defensive shots (\textbf{T4}). 
%
The user selects a short rally (\textbf{T5}) to study player movement and the sequence leading to the error shot. 
After watching multiple error rallies  (\textbf{T6}), the user concludes that \textit{Player A} needs to improve defensive shots on the backhand side and work on physical fitness.
\end{adjustwidth}

\normalsize
Both coaches agreed that this workflow is precisely what they need. \textit{``We're manually doing that because currently I won't know where exactly to go back in the video to see all the unforced errors''} (I2). 



\subsection{Computer Vision Data Preprocessing}
\label{sec:data_preprocessing}
To address G2, we applied state-of-the-art computer vision (CV) models to automate the data collection from videos.
We developed a semi-automatic data preprocessing pipeline for monocular match videos, which includes manual game breakdown, shot classification algorithms, and automatic 3D shot and player reconstruction.
% 
Based on our task abstraction, three types of data must be extracted from a match video:


\para{1) Game and Rally Summary} are automatically computed based on manual annotation and output from CV models:

\begin{itemize}[leftmargin=*]
  \item \emph{Rally Breakdown}: 
    To obtain a game summary, player scores and aggregated rally statistics are required. Therefore, each game needs to be split into rallies. 
    We manually annotated the time ranges (start and end), player who serves, and the winning side of all rallies from the match video. Our algorithm then derives score and game information based on the rally breakdown.

    \item \emph{Shot Breakdown}: 
    To obtain a rally summary, the duration of each rally and shot count are required. 
    We obtain the timestamps and each shot's hitter running MonoTrack~\cite{liu-2022} with minor manual clean-up.
\end{itemize}



\para{2) 3D Spatial Data} are automatically reconstructed from CV models.
\begin{itemize}[leftmargin=*]
    \item \emph{3D Shot Trajectory}: 
    We automatically reconstructed 3D trajectories and velocities for all shots from running MonoTrack~\cite{liu-2022}.

    \item \emph{3D Player Model}: 
    To reconstruct 3D player models, we use MonoTrack~\cite{liu-2022} to estimate  court and player positions, and CLIFF~\cite{li-2022} to predict smooth 3D player poses from videos. %This combination allows for the reconstruction of 3D player models.
\end{itemize}

\para{3) Shot Statistics} are automatically derived from the 3D spatial data based on experts' analysis requirements gathered in the formative study. 
% \jui{I think if we can show some helpful illustrations for these derived statistics, it can be useful} 
\begin{itemize}[leftmargin=*]
    \item \emph{Shot Tendency}: 
    To detect whether a shot leading to a point is a winner or an unforced error, we first classify the shot tendency by approximating the shuttle’s velocity vector when it passes the net: the tendency is defensive when the vector is going upward (away from the ground), and offensive if opposite.  %(as described in \emph{Shot Outcome})
    % This classification is derived from expert input in the formative study.
% \jui{this is motivated by Toby's need right? Should we say this (if not here, then somewhere)?}
% The velocity information is obtained from running MonoTrack~\cite{liu-2022}.

    \item \emph{Shot Outcome}:
% \jui{There are two problems here: 1) the writing makes it confusing what is shot tendency and what is classification. One way to separate them is: tendency is the attempt of the shot, and the "classification" is the outcome based on this attempt. I will clarify these two paragraphs more. 2) "classification" might not be the right choice. When I read "shot classification", I immediately think of the types of the shot, like "clears", "drives", "net drops", "smashes" etc.}
    Our algorithm categorizes shots as winners, errors, or normal shots to calculate the winner and error shot counts.
    A rally ends with a winner by the scorer or an error by the point loser.
    If the last shot is offensive by the scorer, it's a winner; if defensive by the point loser, the penultimate shot is the winner. Conversely, if the last shot is offensive by the point loser, it's an error; if defensive by the scorer, the penultimate shot is an error. All others are normal shots.
% % winner
% If the final shot is an offensive shot hit by the scorer, then it is labeled as a winner for the scorer.
% If the final shot is a defensive shot hit by the point loser, then the second last shot is a winner for the scorer.
% % error
% Conversely, if the final shot is an offensive shot hit by the point loser, then it is labeled as an error; if it is a defensive shot hit by the scorer, then the second last shot is labeled as an error by the point loser.

    \item \emph{Shot Distribution}:
    From the formative study, coaches use shot locations to classify shots into six areas on the court, including front/middle/back on the left and right sides. 
    To compute the shot distribution, 
    our algorithm projects each shot's start (from) and endpoint (to) onto the court to decide shot locations.

% Our algorithm projects each shot's start and end point onto the court\jui{it might not be clear to the reader why the projection is needed. Explain it slightly more.}, and computes the shot distribution across seven court areas on each side, including front/middle/back on the left and right sides or out-of-bound.

\end{itemize}

\vspace{1mm}
\noindent
Overall, our data preprocessing pipeline is largely automated. 
Except for rally breakdown and winner/server annotation, all other data are obtained through automatic algorithms. 
% \jui{the winners and serves are also annotated. Also, I might supplement that this limitation can be addressed in cv but is out of scope for this paper}.
The manual annotation takes up roughly half of the video duration (e.g., 30 minutes for labeling a 1-hour video).
While our method is not entirely automatic, we anticipate that CV techniques may be able to address these manual annotations in the future, though they are beyond the scope of our current study.

\subsection{Visual Designs}
\label{sec:visual_components}

% Figure environment removed

% \subsubsection{Statistical summary and filtering}
We design five visual components to support the users' analytic tasks and fulfill design goals (G1, G3 and G4).
% 
On a high level, users analyze data across rallies in \summary{} (\autoref{fig:teaser}-1) and dive into a specific rally in \game{} (\autoref{fig:teaser}-2). 
% 
We describe components with examples
% Descriptions are 
based on the 2022 BWF World Championship match between Marin and Yamaguchi~\cite{match_marin_yamaguchi} (M2) used in our case studies (\autoref{sec:user-study}). 

% In order to identify rallies of interest, experts need to break down the match and examine the statistics of games and rallies.  
% We designed Match Summary and Shot Filter to support experts getting necessary metadata and filtering data in Summary Mode.

% \setlength{\intextsep}{0pt}%
% \begin{wrapfigure}{L}{0.23\textwidth}
% 	\centering
% 	% Figure removed
% 	   \vspace{-8mm}
% 	\caption{Match Summary}
% 	 % \vspace{-2mm}
% 	\label{fig:match_summary}
% \end{wrapfigure}


% % Figure environment removed

 % Match Summary 
\para{(a) Match Summary}
(\autoref{fig:VIRD}a), supporting \textbf{T1},
enables users to identify rallies of interest
by showing essential statistics, including the match's duration, rally count, average shot count per rally, winner, and game scores. 
% These statistics are essential to overview the pace and intensity of the match. 
Users can select a game and view the rallies won by a player from the game selector (e.g., 17 rallies won by Marin in G1). 
 Similar statistics for the selected game are displayed below. 
Game 3 is split into two halves by default due to the switch of sides at the midpoint, 
which prevents spatial data from being displayed on the same side.
 These statistics help experts identify more challenging or outstanding games for deeper analysis.
\re{Furthermore, based on user feedback, we added the option to split games into first and second halves for finer granularity. This was based on the need to}
% Our formative study found that experts sometimes 
analyze each half separately due to coaching advice provided during the midpoint break.
% Game 3 is split into two halves by default, as players switch sides at midpoint (when the leading side reaches 11 points) and therefore spatial data cannot be displayed on the same side of the court.
% These metadata help experts identify games that were more challenging or outstanding for deeper analysis.
% In addition, users can `split' a game into first and second half, similar to Game 3. This design was to provide finer granularity of the game. In the formative study, we found that sometimes experts would analyze each half separately, as players can receive coaching advice in a short break at the midpoint of each game. 




% Shot Filter

% \FloatBarrier
% \begin{wrapfigure}{R}{0.3\textwidth}
% 	\centering
% 	% Figure removed
% 	 \vspace{-8mm}
% 	\caption{Shot Filter}
% 	 % \vspace{-2mm}
% 	\label{fig:shot_filter}
% \end{wrapfigure}

% % Figure environment removed

% Once the game is selected, 
\para{(b) Shot Filter} (\autoref{fig:VIRD}b), supporting \textbf{T2}, enables users to analyze specific shots based on player and shot attributes. 
\re{Finding specific game moments is important to analyze strengths and weaknesses. Therefore, our filter design includes key metrics to support immediate access to the necessary details, including players, shot outcomes, and locations.}
\re{Coaches in our user testing found it extremely valuable to analyze shots filtered by players.}
% Coaches in our user testing found this feature extremely valuable for comparing players. 
For instance, out of Marin's 17 points, 9 were scored through Marin's winners, while 8 were scored due to Yamaguchi's errors.
This provides a different perspective than if Marin had 17 winners. 
% 
\re{Users can also analyze shot distribution by location filtering.}
% Users can also view shot distribution on the heatmap and filter shots by area. 
For instance, users can select the purple 56\% grid to filter Marin's winner shots from the back right. 
Darker colors on the heatmap indicate more shots are from (purple) or to (orange) the area. 
\re{We picked the color scheme to avoid visual clutter and provide an easier comparison of hot spots and shot tendencies between players and games.}
% Experts found the color schemes helpful for recognizing hot spots or shot tendencies between players or games, 
% such as comparing heatmaps of winner shots.



% allows users to specify the shot they want to analyze based on players and shot attributes, such as winners and errors. 
% According to the coaches in our user testing, this feature was considered extremely valuable as it provides an immediate comparison between the players. 
 
% For example, among 17 rallies Marin scored, 9 points were due to Marin's winners while 8 were due to Yamaguchi's errors,
% which tells a very different story if Marin had 17 winners. 
% Further, a user can overview the shot distribution on the heat map and filter shots by areas, e.g., select the purple 56\% grid to filter Marin's winner shots hit from the back right. The darker color indicates more shots are \textit{from} (purple) or \textit{to} (orange) the area.
% The color schemes was considered helpful by experts to recognize hot spots or shot tendency between games or players, e.g. compare two players' heat map of winner shots.  

% \subsubsection{Analyze statistical and spatial shot attributes}

% Rally Menu
% \vspace{2mm}
% \FloatBarrier
% \begin{wrapfigure}{R}{0.18\textwidth}
% 	\centering
% 	% Figure removed
% 	 \vspace{-6mm}
% 	\caption{Rally Menu}
% 	\label{fig:rally_menu}
% \end{wrapfigure}

% % Figure environment removed

% To help users identify shot patterns before diving into game details, we designed Rally Menu and Situated Visualizations to support immersive shot analysis within its game contexts in Summary Mode.

\para{(c) Rally Menu} (\autoref{fig:VIRD}c), supporting \textbf{T2} and \textbf{T6},  provides an overview of shot count and scoring cadence for the rallies of interest, with direct access to the specific rally upon selection. 
Each rally is displayed in a scrollable list with score and length information. 
Short rallies (less than 10 shots) are highlighted in red to draw special attention based on coaches' requirements. 
For instance, users can discern the game's tempo from the number of short rallies (4 out of 9) and the variation of shot counts among the rallies won by Marin. 
This overview of rally statistics helps identify patterns across rallies of interest (\textbf{T4)}.
Further, users can investigate game details in \game{} by selecting a rally (\textbf{T6)}, which allows easy transition to the game context.

% Situated Vis
% \FloatBarrier
% \begin{wrapfigure}{R}{0.25\textwidth}
% 	\centering
% 	% Figure removed
% 	 \vspace{-6mm}
% 	\caption{Situated Visualizations}
% 	 % \vspace{-2mm}
% 	\label{fig:virtual_court}
% \end{wrapfigure}


% % Figure environment removed

\para{(d) Situated 3D Visualizations} (\autoref{fig:VIRD}d), supporting \textbf{T4}, display the 3D shot arcs and heatmap of filtered shots (e.g., all winners by Marin in Game 1) on a 1-to-1 virtual court. 
Shots are color-coded based on their outcome, with red for errors, green for winners, and white for all other shots. 
Interacting with individual shot arcs displays the shuttle's dynamic trajectory in real-time (details in Sec.~\ref{sec:interaction}).
The situated visualizations enable users to glean insights into shots' spatial attributes, 
such as arc shapes and distributions. 
Experts use this design to quickly observe insights from shots across multiple rallies.


% \subsubsection{Investigate game details of shot and rally}
% \FloatBarrier
% \setlength{\intextsep}{0pt}%
% \begin{wrapfigure}{R}{0.25\textwidth}
% 	\centering
% 	% Figure removed
% 	\vspace{-6mm}
% 	\caption{Game View}
% 	 % \vspace{-2mm}
% 	\label{fig:game_vieiw}
% \end{wrapfigure}
% Once some patterns are observed, it is necessary for experts to investigate actual game details to verify insights and investigate root causes. The user can preview the game moments of the chosen shot in Summary Mode, or delve into the entire rally in Game Mode.

\para{(e) Game View} (\autoref{fig:VIRD}e), supporting \textbf{T5}, shows a 3D reconstructed game view along with the video to facilitate a more comprehensive analysis of game details.
The 3D game view displays the dynamic movement of shots and players, enabling accurate spatial perception and flexible viewing angles. 
By examining the exact moment of the selected shot, users can quickly compare multiple shots in \summary{} and expand their analysis to the selected rally in \game{}.
% or to other rallies containing similar shots from the Rally Menu (\textbf{T6}).


% 
% Fig.~\ref{fig:Interaction}-2 shows the user interaction of linking from a shot in Summary Mode to the rally in Game Mode. 



% The user can select `View Match' from the hovered shot preview in Summary Mode (Fig.~\ref{fig:Interaction}-1) to watch the entire rally in Game Mode (Fig.~\ref{fig:Interaction}-2).

% 


\subsection{User Interaction}
\label{sec:interaction}

\noindent
Users interact with the VIRD interface and visualizations using VR controllers.
Each shot can be hovered to select, which will link to the game context of the shot (\autoref{fig:Interaction}-1) while in \summary{}, showing a Game View that contains 3D dynamic shot trajectory and player poses, and the same shot duration in the video.
This interaction allows users to instantly review the game moment of each shot in the filtered group (e.g., all winner shots) to obtain the context of 3D data. 
To navigate to the \game{} (\autoref{fig:Interaction}-2), the users can select \textit{``View Match''} from the Game View of the hovered shot, or select a rally from the Rally Menu.
Furthermore, the user can directly hover over a shot arc in the rally (\autoref{fig:Interaction}-3) to play the video from the desired game moment.
This feature allows replaying a specific shot or shot sequence efficiently.

Meanwhile, users can flexibly navigate the virtual court, by using a thumb stick or physically moving around, to obtain an accurate spatial and temporal perception of 3D data (\autoref{fig:Interaction}-3).
% 
Our VR environment also offers flexible viewpoints to analyze the 3D game from different perspectives, such as the first-person player view (\autoref{fig:Interaction}-4). 



% Figure environment removed




% \subsection{Interaction}
% \label{sec:interaction}
% Both VR controllers to interact with VIRD are rendered as virtual hands, as shown in Fig.~\ref{fig:Interaction}-1-1. %, with the shape of hands, are used to interact with VIRD, 
% The left controller is used to point at a shot arc to trigger a shot preview in Summary Mode. When a shot is hovered, the left controller will provide a haptic feedback and both (e) Video View and (f) 3D Game View will be displayed while other shot arcs in (d) will be hidden. When the user hovers on the same shot again or presses on the reset button, the shot will be deselected with another haptic feedback, with the view reset to (d). The same interaction applies to Game Mode, with the difference that hovering a shot will repeat the shot in the rally video and deselecting will resume playback of the rest of the rally.
% % 
% The right controller is used to interact with all the buttons on the panels (a-c) to apply filters and select rally of interest. The thumb stick on the right controller allows the user to move freely in the horizontal direction. As shown in Fig.~\ref{fig:Interaction}-1, the user can change viewpoint flexibly to analyze the 3D visualizations or experience the game from the first-person view on the virtual court.

% Fig.~\ref{fig:Interaction}-2 shows the user interaction of linking from a shot in Summary Mode to the rally in Game Mode. For example, the user sets the Shot Filter with the right controller to view all error shots by \textit{Top} player. Then, the user points at an error shot to preview the shot in video with the left controller. Finally, the user selects from Rally Menu with the right controller to watch the entire rally in Game Mode.


\subsection{Design Iterations}
\label{sec:design_iteration}
We conducted three rounds of user testing throughout the design process. Three active high-performance badminton coaches in US were involved  (C1-C3; M=3; Age: 40-60), who were former players on the US, Malaysia, and Nepal badminton national teams, respectively. 
They have coaching experiences ranging from 15 to over 30 years. C1 had participated in our formative study while C2 and C3 were newly introduced at the design iteration stage.
Given the challenges in accessing domain experts, we adopted a progressive approach wherein each coach evaluated our prototype at various design stages, focusing on distinct aspects. 
We tested VIRD on the match of 2020 BWF World Tour Finals of Women Single between Tai Tzu Ying and Carolina Marin~\cite{match_tai_marin}.


\para{Round 1. User flow and data analysis.} The first testing was conducted on the initial prototype with C1, where we elicited the coach's feedback on the overall analysis approach and the shot filtering features.
The coach appreciated the top-down approach and interactive analysis process with immediate access to all match data and videos.
On top of the existing summary data and filters, he suggested showing winner and error shots separately to support an immediate comparison of the shot patterns.
Further, \re{we designed two interaction methods to apply the shot location filter,  1) select buttons on the Shot Filter panel and 2) physically move to the desired area on the virtual court. However, the coach felt 1) is more useful as moving around the court to filter shots during the analysis would be tedious and distracting.}

\para{Round 2. Interaction with the visualization and interface.} The second testing was run a month later with C2, with a focus on the interaction of linking the static data to the dynamic trajectories and videos. We showed the dynamic shot trajectory of a hovered shot arc, but to view the original rally video the user had to scroll through and select from the Rally Menu.
The coach suggested augmenting the preview of the selected shot arc with the video, as \textit{``it takes time to find the video part of it right now''}.
He also emphasized the importance of pinpointing on the cause of the outcome during coaching. It is not enough to see where an error shot occurred in general, but to let the player see the shot sequence and player movement that lead to the outcome. 
Therefore, we implemented shot-to-rally interaction (\autoref{fig:Interaction}-1 to 2) to support coaches effectively look into specific rally where the error/winner occurs for detailed analysis into root cause. 

\para{Round 3. Immersive 3D visualization.} We conducted the third test two months later with C3 on the usefulness of immersive visualizations. The coach was able to preview each group of filtered shots (e.g., winners) efficiently and interpreted the shot types from the 3D shot arcs to answer his coaching question, like \textit{``What are the shots Tai used to win?''- 1 cross drop [shot], 2 smash [shots], 1 block [shot]}. 
He also valued the color usage in the visualizations to tell the shot percentage on the heat map and highlight winner and error shots.
However, since 3D player poses were not implemented at the moment, we found all coaches still mainly watch the video view to analyze the rally as player movement is critical in finding the root cause,  e.g., \textit{``You hit the shot and it was a winning rally, why? Because the opponent wasn’t there yet''} (C2).
Both C2 and C3 mentioned the inclusion of player poses to enhance the usefulness and engagement of the 3D game view. Therefore, we worked on player pose estimation after the third user testing.

During the user testing, we also elicited coaches' feedback on VR environment.
% as all of them were first-time VR users. 
They agreed VR provides additional benefits in analyzing a match video, such as immediate access to all relevant information, flexible viewpoints, and an interactive approach. For instance, C1 commented \textit{``it was very helpful to see the video and the bird going with the trajectory at the same time.''}
% \textit{``when I put the headset on I already have information that I may need without even having to watch the video''} \jui{this is vague. what did D1 mean?}. 
C2 moved to the bottom left of the court while watching the 3D game view because \textit{``this is where I sit as a coach''}. C3 shared that the interaction to select a shot and link to the actual match video is very helpful as \textit{``it’s important to know how the player put the pressure and create a situation [in the game]''}.

\subsection{Implementation}
% \re{We implemented VIRD interface using Unity3D~\cite{unity} and run on Meta Quest 2. CV algorithms~\cite{liu-2022, li-2022} were implemented in Python.
% Preprocessed match data were loaded and rendered onto the 3D scene at run time. VR interactions were implemented based on XR Interaction Toolkit\cite{xrinteraction}.
% VIRD interface is available at https://to-be-open.github.io.
% }
\re{
%The VIRB system combines a backend component and a front-end user interface. 
The VIRD backend is implemented in Pytorch and leverages CV models~\cite{liu-2022, li-2022} to extract data from badminton videos. 
The processed match data is subsequently rendered in real-time within the front-end's 3D scene.
The font-end of VIRD is built with Unity3D~\cite{unity},
including the user interface and the 3D scene.
To be compatible with the Meta Quest 2 platform,
we have implemented VR interactions using the XR Interaction Toolkit~\cite{xrinteraction},
ensuring a natural, intuitive user experience. 
The VIRD interface can be accessed at our public website: \url{https://github.com/ticahere/VIRD-demo}.
}