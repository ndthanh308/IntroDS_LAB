@InProceedings{C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Article Title",
  booktitle =        "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803-806"
}

@inproceedings{oktem2020gamayun,
  title={Gamayun-language technology for humanitarian response},
  author={{\"O}ktem, Alp and Jaam, Muhannad Albayk and DeLuca, Eric and Tang, Grace},
  booktitle={2020 IEEE Global Humanitarian Technology Conference (GHTC)},
  pages={1--4},
  year={2020},
  organization={IEEE}
}

@inproceedings{black2019cmu,
  title={Cmu wilderness multilingual speech dataset},
  author={Black, Alan W},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5971--5975},
  year={2019},
  organization={IEEE}
}

@inproceedings{adelani-etal-2021-effect,
    title = "The Effect of Domain and Diacritics in {Y}oruba{--}{E}nglish Neural Machine Translation",
    author = "Adelani, David  and
      Ruiter, Dana  and
      Alabi, Jesujoba  and
      Adebonojo, Damilola  and
      Ayeni, Adesina  and
      Adeyemi, Mofe  and
      Awokoya, Ayodele Esther  and
      Espa{\~n}a-Bonet, Cristina",
    booktitle = "Proceedings of Machine Translation Summit XVIII: Research Track",
    month = aug,
    year = "2021",
    address = "Virtual",
    publisher = "Association for Machine Translation in the Americas",
    url = "https://aclanthology.org/2021.mtsummit-research.6",
    pages = "61--75",
    abstract = "Massively multilingual machine translation (MT) has shown impressive capabilities and including zero and few-shot translation between low-resource language pairs. However and these models are often evaluated on high-resource languages with the assumption that they generalize to low-resource ones. The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets. In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for Yoruba{--}English with standardized train-test splits for benchmarking. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains. Since these pre-trained models use huge amounts of data with uncertain quality and we also analyze the effect of diacritics and a major characteristic of Yoruba and in the training data. We investigate how and when this training condition affects the final quality of a translation and its understandability.Our models outperform massively multilingual models such as Google ($+8.7$ BLEU) and Facebook M2M ($+9.1$) when translating to Yoruba and setting a high quality benchmark for future research.",
}
@inproceedings{commonvoice,
    title = "Common Voice: A Massively-Multilingual Speech Corpus",
    author = "Ardila, Rosana  and
      Branson, Megan  and
      Davis, Kelly  and
      Kohler, Michael  and
      Meyer, Josh  and
      Henretty, Michael  and
      Morais, Reuben  and
      Saunders, Lindsay  and
      Tyers, Francis  and
      Weber, Gregor",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.520",
    pages = "4218--4222",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Related Work (compiled by iroro)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Odejobi2004ACM,
  title={A Computational Model of Intonation for Yor{\`u}b{\'a} Text-to-Speech Synthesis: Design and Analysis},
  author={{Od{\'e}t{\'u}nj{\'\i}} {\`A}j{\`a}d{\'\i} Od{\'e}job{\'\i} and Anthony Joseph Beaumont and Shun Ha Sylvia Wong},
  booktitle={TSD},
  year={2004}
}

@article{ajadi2007quantitative,
  title={A quantitative model of yor{\`u}b{\'a} speech intonation using stem-ml},
  author={{\`A}j{\`a}d{\'\i}, Od{\'e}job{\'\i} Od{\'e}t{\'u}nj{\'\i}},
  journal={INFOCOMP Journal of Computer Science},
  year={2007}
}

@inproceedings{Niekerk2012ToneRI,
  title={Tone realisation in a yor{\`u}b{\'a} speech recognition corpus},
  author={Daniel R. van Niekerk and Etienne Barnard},
  booktitle={SLTU},
  year={2012}
}

@article{Akinwonmi2013APT,
  title={A prosodic Text-to-Speech system for Yor{\`u}b{\'a} language},
  author={Akintoba Emmanuel Akinwonmi and B. K. Alese},
  journal={ICITST},
  year={2013},
}

@inproceedings{ynd2014DevelopmentOG,
  title={Development of grapheme-to-phoneme conversion system for yor{\`u}b{\'a} text-to-speech synthesis},
  author={Ab{\'i}mb{\'o}l{\'a} Rhoda {\`I}y{\`a}nd{\'a} and Odetunji Ajadi Odejobi and Festus Ayodeji Soyoye and Ol{\'u}b{\'e}nga O. Akinad{\'e}},
  year={2014}
}

@article{akinade2014computational,
  title={Computational modelling of Yor{\`u}b{\'a} numerals in a number-to-text conversion system},
  author={Akinad{\'e}, Ol{\'u}gb{\'e}nga O and \d{O}d\d{\'e}j\d{o}b{\'\i}, \d{O}d\d{\'e}t{\'u}nj{\'\i} A},
  journal={Journal of Language Modelling},
  year={2014}
}

@inproceedings{Afolabi2014DevelopmentOT,
  title={Development of Text to Speech System for Yoruba Language},
  author={Akingbemisilu Abiola Afolabi and Elijah Olusayo Omidiora and O. T. Arulogun},
  year={2014}
}

@article{van2015lagos,
  title={Lagos-NWU Yoruba speech corpus},
  author={van Niekerk, Daniel and Barnard, Etienne and Giwa, Oluwapelumi and Sosimi, Azeez},
  year={2015},
  publisher={North-West University}
}

@article{aoga2016integration,
  title={Integration of Yoruba language into MaryTTS},
  author={Aoga, John OR and Dagba, Theophile K and Fanou, Codjo C},
  journal={International Journal of Speech Technology},
  year={2016},
}

@inproceedings{Dagba2016DesignOA,
  title={Design of a Yoruba Language Speech Corpus for the Purposes of Text-to-Speech (TTS) Synthesis},
  author={Th{\'e}ophile K. Dagba and John O. R. Aoga and Codjo C. Fanou},
  booktitle={ACIIDS},
  year={2016}
}

@article{iyanda2017development,
  title={Development of a Yor{\'u}b{\`a} Textto-Speech System Using Festival},
  author={Iyanda, Abimbola Rhoda and Ninan, Olufemi Deborah},
  journal={Innovative Systems Design and Engineering (ISDE)},
  volume={8},
  number={5},
  year={2017}
}

@article{gutkin2020developing,
  title={Developing an open-source corpus of yoruba speech},
  author={Gutkin, Alexander and Demirsahin, Isin and Kjartansson, Oddur and Rivera, Clara E and T{\'u}b{\`o}s{\'u}n, K{\'o}l{\'a}},
  year={2020}
}

@article{meyer2022bibletts,
  title={BibleTTS: a large, high-fidelity, multilingual, and uniquely African speech corpus},
  author={Meyer, Josh and Adelani, David Ifeoluwa and Casanova, Edresson and {\"O}ktem, Alp and Weber, Daniel Whitenack Julian and Kabongo, Salomon and Salesky, Elizabeth and Orife, Iroro and Leong, Colin and Ogayo, Perez and others},
  journal={arXiv preprint arXiv:2207.03546},
  year={2022}
}







@misc{Ethnologue2019,
    author = "David M. Eberhard and Gary F. Simons and Charles D. Fennig (eds.)",
    title = "Ethnologue: Languages of the World. Twenty-second edition.",
    year = "2019",
    organization = "SIL International",
    url = "http://www.ethnologue.com"
}


@article{Asahiah2017,
	author = {Asahiah, F. O. and Odejobi, O. A. and Adagunodo, E. R.},
	year = "2017",
	title={Restoring Tone-Marks in Standard Yoruba Electronic Text: Improved Model},
	journal = {Computer Science},
	volume = "18",
	number = "3",
	pages = "301--315"
}

@inproceedings{adegbolaOdi12,
  title={Quantifying the effect of corpus size on the quality of automatic diacritization of Yoruba texts},
  author={Adegbola, Tunde and Odilinye, Lydia U. },
  booktitle={Spoken Language Technologies for Under-Resourced Languages},
  pages={},
  year={2012},
}

@inproceedings{adelani-etal-2022-masakhaner,
    title = "{M}asakha{NER} 2.0: {A}frica-centric Transfer Learning for Named Entity Recognition",
    author = "Adelani, David  and
      Neubig, Graham  and
      Ruder, Sebastian  and
      Rijhwani, Shruti  and
      Beukman, Michael  and
      Palen-Michel, Chester  and
      Lignos, Constantine  and
      Alabi, Jesujoba  and
      Muhammad, Shamsuddeen  and
      Nabende, Peter  and
      Dione, Cheikh M. Bamba  and
      Bukula, Andiswa  and
      Mabuya, Rooweither  and
      Dossou, Bonaventure F. P.  and
      Sibanda, Blessing  and
      Buzaaba, Happy  and
      Mukiibi, Jonathan  and
      Kalipe, Godson  and
      Mbaye, Derguene  and
      Taylor, Amelia  and
      Kabore, Fatoumata  and
      Emezue, Chris Chinenye  and
      Aremu, Anuoluwapo  and
      Ogayo, Perez  and
      Gitau, Catherine  and
      Munkoh-Buabeng, Edwin  and
      Memdjokam Koagne, Victoire  and
      Tapo, Allahsera Auguste  and
      Macucwa, Tebogo  and
      Marivate, Vukosi  and
      Elvis, Mboning Tchiaze  and
      Gwadabe, Tajuddeen  and
      Adewumi, Tosin  and
      Ahia, Orevaoghene  and
      Nakatumba-Nabende, Joyce  and
      Mokono, Neo Lerato  and
      Ezeani, Ignatius  and
      Chukwuneke, Chiamaka  and
      Oluwaseun Adeyemi, Mofetoluwa  and
      Hacheme, Gilles Quentin  and
      Abdulmumin, Idris  and
      Ogundepo, Odunayo  and
      Yousuf, Oreen  and
      Moteu, Tatiana  and
      Klakow, Dietrich",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.298",
    pages = "4488--4508",
    abstract = "African languages are spoken by over a billion people, but they are under-represented in NLP research and development. Multiple challenges exist, including the limited availability of annotated training and evaluation datasets as well as the lack of understanding of which settings, languages, and recently proposed methods like cross-lingual transfer will be effective. In this paper, we aim to move towards solutions for these challenges, focusing on the task of named entity recognition (NER). We present the creation of the largest to-date human-annotated NER dataset for 20 African languages. We study the behaviour of state-of-the-art cross-lingual transfer methods in an Africa-centric setting, empirically demonstrating that the choice of source transfer language significantly affects performance. While much previous work defaults to using English as the source language, our results show that choosing the best transfer language improves zero-shot F1 scores by an average of 14{\%} over 20 languages as compared to using English.",
}


@inproceedings{gutkin_49562,
title	= {Developing an Open-Source Corpus of Yoruba Speech},
author	= {Alexander Gutkin and Isin Demirsahin and Oddur Kjartansson and Clara E. Rivera and Kólá Túbòsún},
year	= {2020},
URL	= {http://dx.doi.org/10.21437/Interspeech.2020-1096},
booktitle	= {Proc. of Interspeech 2020},
pages	= {404--408},
address	= {October 25--29, Shanghai, China, 2020.}
}



@inproceedings{meyer22c_interspeech,
  author={Josh Meyer and David Adelani and Edresson Casanova and Alp Öktem and Daniel Whitenack and Julian Weber and Salomon {Kabongo Kabenamualu} and Elizabeth Salesky and Iroro Orife and Colin Leong and Perez Ogayo and Chris {Chinenye Emezue} and Jonathan Mukiibi and Salomey Osei and Apelete Agbolo and Victor Akinode and Bernard Opoku and Olanrewaju Samuel and Jesujoba Alabi and Shamsuddeen Hassan Muhammad},
  title={{BibleTTS: a large, high-fidelity, multilingual, and uniquely African speech corpus}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2383--2387},
  doi={10.21437/Interspeech.2022-10850}
}




@article{Communication2023SeamlessM4TMassivelyM,
  title={SeamlessM4T-Massively Multilingual \& Multimodal Machine Translation},
  author={{Seamless Communication} and Lo{\"i}c Barrault and Yu-An Chung and Mariano Cora Meglioli and David Dale and Ning Dong and Paul-Ambroise Duquenne and Hady ElSahar and Hongyu Gong and Kevin Heffernan and John Hoffman and Christopher Klaiber and Peng Li and Daniel Licht and Jean Maillard and Alice Rakotoarison and Kaushik Ram Sadagopan and Guillaume Wenzek and Ethan Ye and Bapi Akula and Peng-Jen Chen and Naji El Hachem and Brian Ellis and Gabriel Mejia Gonzalez and Justin Haaheim and Prangthip Hansanti and Russ Howes and Bernie Huang and Min-Jae Hwang and Hirofumi Inaguma and Somya Jain and Elahe Kalbassi and A J Kallet and Ilia Kulikov and Janice Lam and Shang-Wen Li and Xutai Ma and Ruslan Mavlyutov and Benjamin Peloquin and M.L. Ramadan and Abinesh Ramakrishnan and Anna Sun and Ke M. Tran and Tuan Q Tran and I. A. Tufanov and Vish Vogeti and Carleigh Wood and Yilin Yang and Bo Yu and Pierre Yves Andrews and Can Balioglu and Marta Ruiz Costa-juss{\`a} and Onur Çelebi and Maha Elbayad and Cynthia Gao and Francisco Guzm'an and Justine T. Kao and Ann Lee and Alexandre Mourachko and Juan Miguel Pino and Sravya Popuri and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Paden Tomasello and Changhan Wang and Jeff Wang and Skyler Wang},
  journal={ArXiv},
  year={2023},
  volume={abs/2308.11596},
  url={https://api.semanticscholar.org/CorpusID:261064881}
}

@article{Ritchie2022LargeVS,
  title={Large vocabulary speech recognition for languages of Africa: multilingual modeling and self-supervised learning},
  author={Sandy Ritchie and You-Chi Cheng and Mingqing Chen and Rajiv Mathews and Daan van Esch and Bo Li and Khe Chai Sim},
  journal={ArXiv},
  year={2022},
  volume={abs/2208.03067},
  url={https://api.semanticscholar.org/CorpusID:251371713}
}


@inproceedings{ogayo22interspeech,
    title = {Building African Voices},
    author = {Perez Ogayo and Graham Neubig and Alan W Black},
    booktitle = {23rd Annual Conference of the International Speech Communication Association (InterSpeech 2022)},
    address = {Incheon, Korea},
    month = {September},
    url = {https://arxiv.org/abs/2207.00688},
    year = {2022}
}



@article{Zhang2023GoogleUS,
  title={Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages},
  author={Yu Zhang and Wei Han and James Qin and Yongqiang Wang and Ankur Bapna and Zhehuai Chen and Nanxin Chen and Bo Li and Vera Axelrod and Gary Wang and Zhong Meng and Ke Hu and Andrew Rosenberg and Rohit Prabhavalkar and Daniel S. Park and Parisa Haghani and Jason Riesa and Ginger Perng and Hagen Soltau and Trevor Strohman and Bhuvana Ramabhadran and Tara N. Sainath and Pedro J. Moreno and Chung-Cheng Chiu and Johan Schalkwyk and Franccoise Beaufays and Yonghui Wu},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.01037},
  url={https://api.semanticscholar.org/CorpusID:257280021}
}



@InProceedings{pmlr-v202-radford23a,
  title = 	 {Robust Speech Recognition via Large-Scale Weak Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and Mcleavey, Christine and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {28492--28518},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/radford23a/radford23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/radford23a.html},
  abstract = 	 {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.}
}


@article{pratap2023mms,
  title={Scaling Speech Technology to 1,000+ Languages},
  author={Vineel Pratap and Andros Tjandra and Bowen Shi and Paden Tomasello and Arun Babu and Sayani Kundu and Ali Elkahky and Zhaoheng Ni and Apoorv Vyas and Maryam Fazel-Zarandi and Alexei Baevski and Yossi Adi and Xiaohui Zhang and Wei-Ning Hsu and Alexis Conneau and Michael Auli},
  journal={arXiv},
  year={2023}
}


@INPROCEEDINGS{fleurs,
  author={Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={FLEURS: FEW-Shot Learning Evaluation of Universal Representations of Speech}, 
  year={2023},
  volume={},
  number={},
  pages={798-805},
  doi={10.1109/SLT54892.2023.10023141}}



@inproceedings{shi23g_interspeech,
  author={Jiatong Shi and Dan Berrebbi and William Chen and En-Pei Hu and Wei-Ping Huang and Ho-Lam Chung and Xuankai Chang and Shang-Wen Li and Abdelrahman Mohamed and Hung-yi Lee and Shinji Watanabe},
  title={{ML-SUPERB: Multilingual Speech Universal PERformance Benchmark}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={884--888},
  doi={10.21437/Interspeech.2023-1316}
}


@inproceedings{Shi2023FindingsOT,
  title={Findings of the 2023 ML-SUPERB Challenge: Pre-Training and Evaluation over More Languages and Beyond},
  author={Jiatong Shi and William Chen and Dan Berrebbi and Hsiu-Hsuan Wang and Wei-Ping Huang and En-Pei Hu and Ho-Lam Chuang and Xuankai Chang and Yuxun Tang and Shang-Wen Li and Abdelrahman Mohamed and Hung-yi Lee and Shinji Watanabe},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263829188}
}

@inproceedings{
loshchilov2018decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}


@inproceedings{2014MethodFT,
  title={Method for the subjective assessment of intermediate quality level of},
  author={ITU-RBS.1534},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:36274547}
}


@proceedings{conformer,
title	= {Conformer: Convolution-augmented Transformer for Speech Recognition},
editor	= {Anmol Gulati and Chung-Cheng Chiu and James Qin and Jiahui Yu and Niki Parmar and Ruoming Pang and Shibo Wang and Wei Han and Yonghui Wu and Yu Zhang and Zhengdong Zhang},
year	= {2020}
}



@inproceedings{babu22_interspeech,
  author={Arun Babu and Changhan Wang and Andros Tjandra and Kushal Lakhotia and Qiantong Xu and Naman Goyal and Kritika Singh and Patrick {von Platen} and Yatharth Saraf and Juan Pino and Alexei Baevski and Alexis Conneau and Michael Auli},
  title={{XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2278--2282},
  doi={10.21437/Interspeech.2022-143}
}

@inproceedings{kominek08_sltu,
  author={John Kominek and Tanja Schultz and Alan W. Black},
  title={{Synthesizer voice quality of new languages calibrated with mean mel cepstral distortion}},
  year=2008,
  booktitle={Proc. Speech Technology for Under-Resourced Languages (SLTU-2008)},
  pages={63--68}
}

@misc{yvspeechrecorder,
  author = {Iroro Orife and Aremu Anuoluwapo and K\d{\'{o}}l\'{a} T\'{u}b\d{\`{o}}s\'{u}n and and David Ifeoluwa Adelani and Tol\'{u}l\d{o}p\d{\'{e}} \'{O}g\'{u}nr\d{\`{e}}m\'{i}},
  title = {Yorùbá Voice Speech Recorder},
  url = {https://github.com/Niger-Volta-LTI/yoruba-voice-speech-recorder},
  version = {v0.1-alpha},
  date = {2022-08-31},
  year = {2022},
}