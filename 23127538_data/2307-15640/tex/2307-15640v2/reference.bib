
@article{talebi2018nima,
  title={NIMA: Neural image assessment},
  author={Talebi, H. and Milanfar, P.},
  journal={IEEE Trans. Image Process.},
  volume={27},
  number={8},
  pages={3998--4011},
  year={2018},
  publisher={IEEE}
}

@inproceedings{ke2021musiq,
  title={Musiq: Multi-scale image quality transformer},
  author={Ke et al.},
  booktitle={CVPR},
  pages={5148--5157},
  year={2021}
}

@article{kwon2024clip,
  title={CLIP-Guided Attribute Aware Pretraining for Generalizable Image Quality Assessment},
  author={Kwon et al.},
  journal={arXiv preprint arXiv:2406.01020},
  year={2024}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu et al.},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@inproceedings{zhang2023blind,
  title={Blind image quality assessment via vision-language correspondence: A multitask learning perspective},
  author={Zhang et al.},
  booktitle={CVPR},
  pages={14071--14081},
  year={2023}
}

@inproceedings{ke2023vila,
  title={{Vila}: Learning image aesthetics from user comments with vision-language pretraining},
  author={Ke et al.},
  booktitle={CVPR},
  pages={10041--10051},
  year={2023}
}

@article{li2024graphadapter,
  title={Graphadapter: Tuning vision-language models with dual knowledge graph},
  author={Li et al.},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@inproceedings{wang2023exploring,
  title={Exploring clip for assessing the look and feel of images},
  author={Wang et al.},
  booktitle={Proceedings of the AAAI Conference},
  volume={37},
  number={2},
  pages={2555--2563},
  year={2023}
}

@inproceedings{saha2023re,
  title={Re-{iqa}: Unsupervised learning for image quality assessment in the wild},
  author={Saha et al.},
  booktitle={CVPR},
  pages={5846--5855},
  year={2023}
}

@inproceedings{talebi2018learned,
  title={Learned perceptual image enhancement},
  author={Talebi et al.},
  booktitle={2018 IEEE international conference on computational photography},
  pages={1--13},
  year={2018},
  organization={IEEE}
}

@article{chang2016automatic,
  title={Automatic triage for a photo series},
  author={Chang et al.},
  journal={ACM Transactions on Graphics},
  volume={35},
  number={4},
  pages={1--10},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@InProceedings{Ren_2017_ICCV,
author = {Ren et al.},
title = {Personalized Image Aesthetics},
booktitle = {CVPR},
month = {Oct},
year = {2017}
}

@inproceedings{xu2021end,
  title={End-to-end semi-supervised object detection with soft teacher},
  author={Xu et al.},
  booktitle={CVPR},
  pages={3060--3069},
  year={2021}
}

@article{wang2021knowledge,
  title={Knowledge distillation and student-teacher learning for visual intelligence: A review and new outlooks},
  author={Wang et al.},
  journal={CVPR},
  year={2021},
  publisher={IEEE}
}

@incollection{valenzise2022advances,
  title={Advances and challenges in computational image aesthetics},
  author={Valenzise et al.},
  booktitle={Human Perception of Visual Information},
  pages={133--181},
  year={2022},
  publisher={Springer}
}

@article{hou2021learning,
  title={Learning Image Aesthetic Assessment from Object-level Visual Components},
  author={Hou et al.},
  journal={arXiv preprint arXiv:2104.01548},
  year={2021}
}

@article{tarvainen2017mean,
  title={Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
  author={Tarvainen, A. and Valpola, H.},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@inproceedings{mai2016composition,
  title={Composition-preserving deep photo aesthetics assessment},
  author={Mai et al.},
  booktitle={CVPR},
  pages={497--506},
  year={2016}
}

@inproceedings{sheng2020revisiting,
  title={Revisiting image aesthetic assessment via self-supervised feature learning},
  author={Sheng et al.},
  booktitle={Proceedings of the AAAI Conference},
  volume={34},
  number={04},
  pages={5709--5716},
  year={2020}
}

@inproceedings{lu2015deep,
  title={Deep multi-patch aggregation network for image style, aesthetics, and quality estimation},
  author={Lu et al.},
  booktitle={ICCV},
  pages={990--998},
  year={2015}
}

@inproceedings{datta2008algorithmic,
  title={Algorithmic inferencing of aesthetics and emotion in natural images: An exposition},
  author={Datta, R. and Li, J. and Wang, J. Z.},
  booktitle={2008 15th IEEE international conference on image processing},
  pages={105--108},
  year={2008},
  organization={IEEE}
}

@InProceedings{Ke_2023_CVPR,
    author    = {Ke et al.},
    title     = {VILA: Learning Image Aesthetics From User Comments With Vision-Language Pretraining},
    booktitle = {CVPR},
    month     = {June},
    year      = {2023},
    pages     = {10041-10051}
}

@article{kuznetsova2020open,
  title={The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale},
  author={Kuznetsova et al.},
  journal={International Journal of Computer Vision},
  volume={128},
  number={7},
  pages={1956--1981},
  year={2020},
  publisher={Springer}
}

@inproceedings{luo2011content,
  title={Content-based photo quality assessment},
  author={Luo et al.},
  booktitle={2011 ICCV},
  pages={2206--2213},
  year={2011},
  organization={IEEE}
}

@inproceedings{dhar2011high,
  title={High level describable attributes for predicting aesthetics and interestingness},
  author={Dhar et al.},
  booktitle={CVPR},
  pages={1657--1664},
  year={2011},
  organization={IEEE}
}

@inproceedings{nishiyama2011aesthetic,
  title={Aesthetic quality classification of photographs based on color harmony},
  author={Nishiyama et al.},
  booktitle={CVPR},
  pages={33--40},
  year={2011},
  organization={IEEE}
}

@inproceedings{marchesotti2011assessing,
  title={Assessing the aesthetic quality of photographs using generic image descriptors},
  author={Marchesotti et al.},
  booktitle={2011 ICCV},
  pages={1784--1791},
  year={2011},
  organization={IEEE}
}

@inproceedings{murray2012ava,
  title={AVA: A large-scale database for aesthetic visual analysis},
  author={Murray et al.},
  booktitle={CVPR},
  pages={2408--2415},
  year={2012},
  organization={IEEE}
}

@inproceedings{lee2013pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee et al.},
  booktitle={Workshop on challenges in representation learning, ICML},
  number={2},
  pages={896},
  year={2013}
}

@article{yang2021survey,
  title={A survey on deep semi-supervised learning},
  author={Yang, X. and Song, Z. and King, I. and Xu, Z.},
  journal={arXiv preprint arXiv:2103.00550},
  year={2021}
}

@inproceedings{kd1,
  title={Model compression},
  author={Bucilu«é et al.},
  booktitle={Proceedings of the 12th ACM SIGKDD},
  pages={535--541},
  year={2006}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton et al.},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@article{rizve2021defense,
  title={In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning},
  author={Rizve et al.},
  journal={arXiv preprint arXiv:2101.06329},
  year={2021}
}

@article{chen2022debiased,
  title={Debiased Pseudo Labeling in Self-Training},
  author={Chen et al.},
  journal={arXiv preprint arXiv:2202.07136},
  year={2022}
}

@inproceedings{arazo2020pseudo,
  title={Pseudo-labeling and confirmation bias in deep semi-supervised learning},
  author={Arazo et al.},
  booktitle={2020 IJCNN},
  pages={1--8},
  year={2020},
  organization={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He et al.},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, M. and Le, Q.},
  booktitle={ICML},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu et al.},
  booktitle={CVPR},
  pages={10012--10022},
  year={2021}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler et al.},
  booktitle={CVPR},
  pages={4510--4520},
  year={2018}
}

@InProceedings{Wang_2021_ICCV,
    author    = {Wang et al.},
    title     = {Uncertainty-Aware Pseudo Label Refinery for Domain Adaptive Semantic Segmentation},
    booktitle = {CVPR},
    month     = {October},
    year      = {2021},
    pages     = {9092-9101}
}

@article{sohn2020fixmatch,
  title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author={Sohn et al.},
  journal={NeurIPS},
  volume={33},
  pages={596--608},
  year={2020}
}

@inproceedings{xie2020self,
  title={Self-training with noisy student improves imagenet classification},
  author={Xie et al.},
  booktitle={CVPR},
  pages={10687--10698},
  year={2020}
}

@article{xie2020unsupervised,
  title={Unsupervised data augmentation for consistency training},
  author={Xie et al.},
  journal={NeurIPS},
  volume={33},
  pages={6256--6268},
  year={2020}
}

@article{berthelot2019mixmatch,
  title={Mixmatch: A holistic approach to semi-supervised learning},
  author={Berthelot et al.},
  journal={NeurIPS},
  volume={32},
  year={2019}
}

@inproceedings{samuli2017temporal,
  title={Temporal ensembling for semi-supervised learning},
  author={Laine, S. and Aila, T.},
  booktitle={ICLR},
  volume={4},
  number={5},
  pages={6},
  year={2017}
}

@inproceedings{hou2020object,
  title={Object-level attention for aesthetic rating distribution prediction},
  author={Hou et al.},
  booktitle={ACM Multimedia},
  pages={816--824},
  year={2020}
}

@inproceedings{li2019personality,
  title={Personality driven multi-task learning for image aesthetic assessment},
  author={Li et al.},
  booktitle={ICME},
  pages={430--435},
  year={2019},
  organization={IEEE}
}

@inproceedings{she2021hierarchical,
  title={Hierarchical layout-aware graph convolutional network for unified aesthetics assessment},
  author={She et al.},
  booktitle={CVPR},
  pages={8475--8484},
  year={2021}
}

@inproceedings{sheng2023aesclip,
  title={Aesclip: Multi-attribute contrastive learning for image aesthetics assessment},
  author={Sheng et al.},
  booktitle={ACM Multimedia},
  pages={1117--1126},
  year={2023}
}

@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman et al},
  booktitle={CVPR},
  pages={7959--7971},
  year={2022}
}

@inproceedings{kong2016photo,
  title={Photo aesthetics ranking network with attributes and content adaptation},
  author={Kong et al.},
  booktitle={ECCV},
  pages={662--679},
  year={2016},
  organization={Springer}
}

@article{murray2017deep,
  title={A deep architecture for unified aesthetic prediction},
  author={Murray, N. and Gordo, A.},
  journal={arXiv preprint arXiv:1708.04890},
  year={2017}
}

@inproceedings{ma2017lamp,
  title={A-lamp: Adaptive layout-aware multi-patch deep convolutional neural network for photo aesthetic assessment},
  author={Ma et al.},
  booktitle={CVPR},
  pages={4535--4544},
  year={2017}
}

@inproceedings{sheng2018attention,
  title={Attention-based multi-patch aggregation for image aesthetic assessment},
  author={Sheng et al.},
  booktitle={ACM Multimedia},
  pages={879--886},
  year={2018}
}

@article{kao2017deep,
  title={Deep aesthetic quality assessment with semantic information},
  author={Kao et al.},
  journal={IEEE Trans. Image Process.},
  volume={26},
  number={3},
  pages={1482--1495},
  year={2017},
  publisher={IEEE}
}

@inproceedings{hosu2019effective,
  title={Effective aesthetics prediction with multi-level spatially pooled features},
  author={Hosu et al.},
  booktitle={CVPR},
  pages={9375--9383},
  year={2019}
}

@article{li2020personality,
  title={Personality-assisted multi-task learning for generic and personalized image aesthetics assessment},
  author={Li et al.},
  journal={IEEE Trans. Image Process.},
  volume={29},
  pages={3898--3910},
  year={2020},
  publisher={IEEE}
}

@inproceedings{chen2020adaptive,
  title={Adaptive fractional dilated convolution network for image aesthetics assessment},
  author={Chen et al.},
  booktitle={CVPR},
  pages={14114--14123},
  year={2020}
}

@inproceedings{tong2004classification,
  title={Classification of digital photos taken by photographers or home users},
  author={Tong et al.},
  booktitle={Proceedings of the Pacific-Rim Conference on Multimedia},
  pages={198--205},
  year={2004}
}

@inproceedings{ke2006design,
  title={The design of high-level features for photo quality assessment},
  author={Ke et al.},
  booktitle={CVPR},
  pages={419--426},
  year={2006}
}

@ARTICLE{9777255,
  author={Yang et al.},
  journal={IEEE Trans. Cybern.},
  title={MetaMP: Metalearning-Based Multipatch Image Aesthetics Assessment},
  year={2022},
  volume={},
  number={},
  pages={1-13},
  doi={10.1109/TCYB.2022.3169017}}

@article{zeng2019unified,
  title={A unified probabilistic formulation of image aesthetic assessment},
  author={Zeng et al.},
  journal={IEEE Trans. Image Process},
  volume={29},
  pages={1548--1561},
  year={2019},
  publisher={IEEE}
}

@ARTICLE{9340578,
  author={Wang, L. and Yoon, K.-J.},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  title={Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks},
  year={2022},
  volume={44},
  number={6},
  pages={3048-3068}}

@article{chen2020big,
  title={Big self-supervised models are strong semi-supervised learners},
  author={Chen et al.},
  journal={NeurIPS},
  volume={33},
  pages={22243--22255},
  year={2020}
}

@InProceedings{Yang_2022_CVPR,
    author    = {Yang et al.},
    title     = {Personalized Image Aesthetics Assessment With Rich Attributes},
    booktitle = {CVPR},
    month     = {June},
    year      = {2022},
    pages     = {19861-19869}
}

@inproceedings{yang2020webly,
  title={Webly supervised image classification with metadata: Automatic noisy label correction via visual-semantic graph},
  author={Yang et al.},
  booktitle={ACM Multimedia},
  pages={83--91},
  year={2020}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju et al.},
  booktitle={CVPR},
  pages={618--626},
  year={2017}
}

@inproceedings{he2022rethinking,
  title={Rethinking Image Aesthetics Assessment: Models, Datasets and Benchmarks},
  author={He et al.},
  booktitle={IJCAI},
  year={2022}
}

@article{hou2022distilling,
  title={Distilling knowledge from object classification to aesthetics assessment},
  author={Hou et al.},
  journal={ IEEE Trans. Circ. Syst. Video Tech.},
  volume={32},
  number={11},
  pages={7386--7402},
  year={2022},
  publisher={IEEE}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford et al.},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford et al.},
  year={2018},
  publisher={OpenAI},
  journal={openai}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford et al.},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown et al.},
  journal={NeurIPS},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{li2023theme,
  title={Theme-aware Visual Attribute Reasoning for Image Aesthetics Assessment},
  author={Li et al.},
  journal={IEEE Trans. Circ. Syst. Video Tech. },
  year={2023},
  publisher={IEEE}
}

@inproceedings{zhou2022extract,
  title={Extract free dense labels from clip},
  author={Zhou et al.},
  booktitle={ECCV},
  pages={696--712},
  year={2022},
  organization={Springer}
}

@article{wang2022exploring,
  title={Exploring CLIP for Assessing the Look and Feel of Images},
  author={Wang et al.},
  journal={arXiv preprint arXiv:2207.12396},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach et al.},
  booktitle={CVPR},
  pages={10684--10695},
  year={2022}
}

@inproceedings{yang2022personalized,
  title={Personalized image aesthetics assessment with rich attributes},
  author={Yang et al.},
  booktitle={CVPR},
  pages={19861--19869},
  year={2022}
}
@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron et al.},
  booktitle={ICML},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}
@article{wang2022closer,
  title={A closer look at self-supervised lightweight vision transformers},
  author={Wang et al.},
  journal={arXiv preprint arXiv:2205.14443},
  year={2022}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng et al.},
  booktitle={CVPR},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{hentschel2022clip,
  title={CLIP knows image aesthetics},
  author={Hentschel et al.},
  journal={Frontiers in Artificial Intelligence},
  volume={5},
  pages={976235},
  year={2022},
  publisher={Frontiers Media SA}
}

@inproceedings{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan et al.},
  booktitle={2010 AISTATS},
  pages={201--208},
  year={2010},
  organization={JMLR}
}

@article{celona2022composition,
  title={Composition and style attributes guided image aesthetic assessment},
  author={Celona et al.},
  journal={IEEE Trans. Image Process},
  volume={31},
  pages={5009--5024},
  year={2022},
  publisher={IEEE}
}

@misc{rw2019timm,
  author = {Wightman, R.},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@article{wei2022contrastive,
  title={Contrastive learning rivals masked image modeling in fine-tuning via feature distillation},
  author={Wei et al.},
  journal={arXiv preprint arXiv:2205.14141},
  year={2022}
}

@inproceedings{fang2023eva,
  title={Eva: Exploring the limits of masked visual representation learning at scale},
  author={Fang et al.},
  booktitle={CVPR},
  pages={19358--19369},
  year={2023}
}
