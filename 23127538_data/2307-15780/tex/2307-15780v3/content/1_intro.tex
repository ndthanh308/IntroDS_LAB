\section{Introduction}


Text-based recommendation systems exhibit a broad spectrum of applications, spanning across diverse domains and industries. This versatility mainly stems from the capability of natural language to effectively describe nearly \textit{any} type of items, encompassing not only products, movies, and books but also news articles and user-generated content, including short videos and social media posts~\citep{pazzani2007content, javed2021review, poirier2010towards,bai2022improving, wu-etal-2020-mind, oppermann2020vizcommender, chen2017joint, gupta2017scientific, wang2018explainable}. Nonetheless, these text-based recommendation systems are frequently challenged by the inherent limitation of \textbf{incomplete or insufficient information within item descriptions}, which hinders the task of accurately \textit{aligning} item characteristics with user preferences~\citep{perez2007building, dumitru2011demand}. The incompleteness may arise from two sources: a limited comprehension of the items themselves and an insufficient understanding of the users for whom recommendations are generated. 

\input{tab_fig/appendix_applicable_domain}

This challenge is not confined only to domains with well-defined and categorized items (\eg movies), but also extends to domains characterized by novel, unclassified, or less categorically structured items, as observed in the case of user-generated content. In the context of movie recommendations, a movie's description usually include the main actors, and a brief plot summary. However, this limited information may not capture crucial elements like genre, tone, cinematography style, or thematic depth, resulting in less effective recommendations.
As for user-generated content, imagine a social platform where users regularly post recipes which are often accompanied with brief textual descriptions like the name of the dish and a few ingredients, but limited details regarding preparation time, dietary restrictions, or flavor profiles. Consider a user who follows a vegan diet and is interested in discovering new plant-based recipes. Since the user-generated content often lacks comprehensive dietary information and may not explicitly mention terms like ``vegan'', ``plant-based'', or ``vegetarian'', in this scenario, the recommendation system, relying solely on the incomplete descriptions, may struggle to discern the vegan-friendliness of the recipes. 

The recent advances in the development of large language models (LLMs) underscore their exceptional capacity to store comprehensive world knowledge~\citep{peters2018dissecting, goldberg2019assessing, tenney2019you, petroni2019language}, engage in complex reasoning~\citep{wei2022chain, zhou2022least}, and function as versatile task solvers~\citep{zhao2023survey,ouyang2022training, kaplan2020scaling}. In light of this advancement and recognizing the challenge posed by incomplete item descriptions, our study introduces the \model framework. This approach is designed to exploit various prompting strategies to \textit{enrich input text} with the intrinsic capabilities of LLMs for personalized recommendations. By leveraging LLMs, which have been fine-tuned on extensive language datasets~\citep{ouyang2022training, touvron2023llama}, our goal is to unlock their potential in generating input text that is not only contextually aware but also of high quality, thereby elevating the overall recommendation quality. 

Through comprehensive empirical experiments, we evaluate the effectiveness of the \model framework. We find that integrating the augmented text as the new input achieves comparable or even superior recommendation performance compared to more advanced content-based recommendation approaches that rely solely on the original item descriptions. Further in-depth analyses reveal that the devised prompting strategies prompt LLMs to generate words that represent both general and specific item characteristics. It is applicable in a diverse range of domains and is not limited to datasets with rich textual information (Figure~\ref{fig:applicable_domain}). Our study provides insights into the impact of different prompting strategies on recommendation performance and sheds light on the potential of leveraging LLMs for personalized recommendation.

