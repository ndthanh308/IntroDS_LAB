
\section{Extended Related Work}\label{sec:detailed_related_work}
\textbf{Augmentation in Text-based Recommendation.} Traditionally, researchers have advocated the augmentation of item descriptions through the incorporation of external knowledge sources~\citep{di2012linked,musto2018semantics,sachdeva2020useful}. Notably, \citet{di2012linked} harnesse data from external databases such as {\tt DBpedia}~\citep{bizer2009dbpedia}, {\tt Freebase}~\citep{bollacker2008freebase}, and {\tt LinkedMDB}~\citep{hassanzadeh2009linked} to gather comprehensive information pertaining to movies, including details about actors, directors, genres, and categories. This approach aimed to enrich the background knowledge available to movie recommender systems. The explicit semantics embedded in these external knowledge sources have demonstrated a discernible enhancement in recommendation performance~\citep{musto2017introducing}. However, this process necessitates a profound domain expertise to effectively and efficiently select and leverage the precise database, ensuring the incorporation of genuinely valuable information into item descriptions~\citep{dumitru2011demand}.


\noindent\textbf{LLM for Recommendation.} The use of large language models in recommender systems has garnered significant attention in recent research~\cite{lin2023can, chen2023large}. Many studies have explored the direct use of LLMs as recommender models. The underlying principle of these approaches involves constructing prompts that encompass the recommendation task, user profiles, item attributes, and user-item interactions. These task-specific prompts are then presented as input to the LLMs, which is instructed to predict the likelihood of interaction between a given user and item~\citep{dai2023uncovering, gao2023chat,geng2022recommendation,li2023exploring,liu2023chatgpt,zhang2023recommendation}. For instance, \citet{wang2023zero} designed a three-step prompting strategy to directly guide LLMs to capture users' preferences, select representative previously interacted items, and recommend a ranked list of 10 items. While these works demonstrate the potential of LLMs as powerful recommender models, the focus primarily revolves around utilizing the LLMs directly for recommendation purposes. However, a potential issue of these methods is that LLMs may generate predictions merely from memorizing training samples which poses a challenge for conducting effective evaluations. In this study, we approach the problem from a different perspective. Rather than using LLMs as recommender models, this study explores diverse prompting strategies to \textit{augment input text} with LLMs for personalized content recommendation. The actual recommendation process still relies on existing recommendation methodologies.