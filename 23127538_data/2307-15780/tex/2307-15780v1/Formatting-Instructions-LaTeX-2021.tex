% \def\year{2021}\relax
%File: formatting-instructions-latex-2021.tex
%release 2021.2
\documentclass{article} % DO NOT CHANGE THIS
% \usepackage{aaai21}  % DO NOT CHANGE THIS
\usepackage[preprint, nonatbib]{nips_2018}
% \usepackage[nonatbib]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% \usepackage{times}  % DO NOT CHANGE THIS
% \usepackage{helvet} % DO NOT CHANGE THIS
% \usepackage{courier}  % DO NOT CHANGE THIS
% \usepackage{url}  % DO NOT CHANGE THIS

% \usepackage{csquotes}
\usepackage{amssymb}
% \usepackage{rotating}
\usepackage{amsmath}
% \urlstyle{rm} % DO NOT CHANGE THIS
% \def\UrlFont{\rm}  % DO NOT CHANGE THIS
% % \usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
% \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
% \usepackage{array}
% \usepackage{flushend}
% \frenchspacing  % DO NOT CHANGE THIS
% \setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
% \setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
% % \usepackage[utf8]{inputenc}
% % \usepackage[T1]{fontenc}
% %\usepackage{lineno}
% \usepackage{setspace} 
% %\linenumbers
% \usepackage{makecell}
% \usepackage[flushleft]{threeparttable}
% \usepackage{booktabs,caption}
% \usepackage[toc,page]{appendix}
\usepackage{subcaption}
% \usepackage{rotating}
% \usepackage{multirow}

% % \usepackage{ulem}

% \usepackage[usenames,dvipsnames]{xcolor}
% \usepackage{tikz}
% \newcommand*\circled[1]{\tikz[baseline=(char.base)]{
%             \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\newcommand{\etal}{\textit{et al}. }
\newcommand{\ie}{\textit{i}.\textit{e}., }
\newcommand{\eg}{\textit{e}.\textit{g}., }
% \def\year{2021}\relax
% %File: formatting-instructions-latex-2021.tex
% %release 2021.2
% \documentclass[letterpaper]{article} % DO NOT CHANGE THIS
% \usepackage{aaai21}  % DO NOT CHANGE THIS
% \usepackage{times}  % DO NOT CHANGE THIS
% \usepackage{helvet} % DO NOT CHANGE THIS
% \usepackage{courier}  % DO NOT CHANGE THIS
% \usepackage[hyphens]{url}  % DO NOT CHANGE THIS
% \usepackage{graphicx} % DO NOT CHANGE THIS
% \urlstyle{rm} % DO NOT CHANGE THIS
% \def\UrlFont{\rm}  % DO NOT CHANGE THIS
% \usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOnT ADD ANY OPTIONS TO IT
% \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
% \usepackage{hyperref} 
% \usepackage{float}
% \usepackage{array}
% \newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
% \frenchspacing  % DO NOT CHANGE THIS
% \setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
% \setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS


% % svg package
% \usepackage{svg}
% \usepackage{tabularx,colortbl}
% \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
% \newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}

%\nocopyright
%PDF Info Is REQUIRED.
% For /Author, add all authors within the parentheses, separated by commas. No accents or commands.
% For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses.
% \pdfinfo{
% /Title (Understanding Public Opinion on Chinese Technology Companies Using Reddit Data)
% /Author (Enting Zhou, Yurong Liu)
% /TemplateVersion (2021.2)
% } %Leave this
% /Title ()
% Put your actual complete title (no codes, scripts, shortcuts, or LaTeX commands) within the parentheses in mixed case
% Leave the space between \Title and the beginning parenthesis alone
% /Author ()
% Put your actual complete list of authors (no codes, scripts, shortcuts, or LaTeX commands) within the parentheses in mixed case.
% Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands,
% remove them.

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference
\usepackage{amsbsy}
\usepackage{graphicx}
% \setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai21.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% \title{LLM-Rec: Prompting Strategies to Leverage Large Language Models for Personalized Content Recommendation}
% \title{LLM-Rec: Prompting Strategies in Large Language Models for Personalized Content Recommendation}
% \title{Prompting Strategies in LLM-Rec: Personalized Content Recommendation with Large Language Models}
\title{LLM-Rec: Personalized Recommendation via Prompting Large Language Models}

\author{%
  Hanjia~Lyu\\
  University of Rochester\\
  \texttt{hlyu5@ur.rochester.edu} \\
   \And
   Song~Jiang \\
  University of California, Los Angeles \\
  \texttt{songjiang@cs.ucla.edu} \\
  \And
  Hanqing~Zeng \\
  Meta AI \\
  \texttt{zengh@meta.com} \\
  \And
  Yinglong~Xia \\
  Meta AI \\
  \texttt{yxia@meta.com} \\
  \And
  Jiebo~Luo \\
  University of Rochester \\
  \texttt{jluo@cs.rochester.edu} \\
}


\begin{document}

\maketitle



\begin{abstract}
We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through \textit{input augmentation}. Our proposed approach, termed \textbf{LLM-Rec}, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to \textit{improved} recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
\end{abstract}

% Figure environment removed

\section{Introduction}
The use of large language models in recommender systems has garnered significant attention in recent research. Numerous studies have explored the direct use of LLMs as recommender models. The underlying principle of these approaches involves constructing prompts that encompass the recommendation task, user profiles, item attributes, and user-item interactions. These task-specific prompts are then presented as input to the LLM, which is instructed to predict the likelihood of interaction between a given user and item~\cite{liu2023chatgpt, geng2022recommendation, gao2023chat,zhang2023recommendation, dai2023uncovering}.

While these works demonstrate the potential of LLMs as powerful recommender models, the focus primarily revolves around utilizing the LLM directly for recommendation purposes. However, in this study, we approach the problem from a different perspective. Rather than using LLMs as recommender models, this study delves into the exploration of prompting strategies to augment input text with LLMs for personalized content recommendation. By leveraging LLMs, which have been fine-tuned on extensive language datasets, we seek to unlock their potential in generating high-quality and context-aware input text for enhanced recommendations.

Specifically, we propose \textbf{LLM-Rec} prompting, which encompasses various prompting strategies tailored for personalized content recommendation. These strategies include basic prompting, recommendation-driven prompting, engagement-guided prompting, and the combination of recommendation-driven and engagement-guided prompting. By leveraging these strategies, we aim to enhance the generation of input text by LLMs and improve the accuracy and relevance of content recommendations.

Through comprehensive empirical experiments, we evaluate the effectiveness of the \textbf{LLM-Rec} framework and compare it against baseline approaches. Our study provides insights into the impact of different prompting strategies on recommendation performance and sheds light on the potential of leveraging LLMs for personalized content recommendation.



\section{LLM-Rec Prompting}
\subsection{Basic prompting}
We consider three basic prompting and refer to them as $\pmb{\tt p_{1}}$, $\pmb{\tt p_{2}}$, and $\pmb{\tt p_{3}}$, respectively in the following experiments. 
\begin{itemize}
    \item $\pmb{\tt p_{1}}$: This prompt instructs LLM to paraphrase the original content description, emphasizing the objective of maintaining the same information without introducing any additional details.
    \item $\pmb{\tt p_{2}}$: This prompt instructs LLM to summarize the content description by using tags, aiming to generate a more concise overview that captures key information.
    \item $\pmb{\tt p_{3}}$: This prompt instructs LLM to deduce the characteristics of the original content description and provide a categorical response that operates at a broader, less detailed level of granularity.
\end{itemize}
The exact prompts and corresponding responses by LLM are shown in Figure~\ref{fig:example_basic_rec} (upper).

\subsection{Recommendation-driven prompting}
This prompting strategy is to add a recommendation-driven instruction into the basic prompting. We refer to the three recommendation-driven prompting as $\pmb{\tt p_{1}^{rec}}$, $\pmb{\tt p_{2}^{rec}}$, and $\pmb{\tt p_{3}^{rec}}$, respectively in the following experiments, aligning with their counterparts in the basic prompts. The exact prompts and corresponding responses by LLM are shown in Figure~\ref{fig:example_basic_rec} (lower).

The use of recommendation-driven prompting exhibits several compelling characteristics, making it an appealing approach for generating high-quality content descriptions:

\begin{enumerate}
    \item \textbf{Enhanced Context:} By explicitly mentioning that the generated content description is intended for content recommendation, models gain a clearer understanding of the task at hand. This additional context helps models align their responses more closely with the purpose of generating content descriptions for recommendation purposes.
    \item \textbf{Guided Generation:} The specific instruction acts as a guiding cue for models, directing their attention towards generating content descriptions that are better suited for recommendation scenarios. The mention of ``content recommendation'' likely prompts LLM to focus on key features, relevant details, and aspects of the content that are more helpful in guiding users towards their preferred choices.
    \item \textbf{Improved Relevance:} The instruction aids LLM in generating content descriptions that are tailored to the requirements of content recommendation. This alignment with the recommendation task leads to more relevant and informative descriptions, as LLM is primed to emphasize aspects that are important for users seeking recommendations.
\end{enumerate}

% Figure environment removed


\subsection{Engagement-guided prompting}
This prompting strategy is to leverage user behavior (\ie user-item engagement) to design prompts with the intention to guide LLM to better capture the characteristics inside the content description that align with user preferences. We aim to generate more meaningful description with this type of prompts for recommendation tasks. We refer to this variant as $\pmb{\tt p^{eng}}$. 

To create the engagement-guided prompt, we combine the content description of the target item, denoted as $d_{target}$, with the content descriptions of $T$ \textbf{important} neighbor items, represented as $d_{1}, d_{2}, \cdots, d_{T}$. The importance is measured based on user engagement. We will discuss more details in the \textit{Experiment} section. This fusion of information forms the basis of the prompt, which is designed to leverage user engagement and preferences in generating more contextually relevant content descriptions:

{\it ``Summarize the commonalities among the following descriptions: `{$d_{target}$}'; `{$d_{1}$}; {$d_{2}$}; ... {$d_{T}$}'.''}

An engagement-guided prompt can assist the Language Model (LLM) in generating more useful content descriptions for content recommendation due to several reasons:
\begin{enumerate}
    \item \textbf{Contextual Relevance:} By incorporating information from both the target item and its important neighbor items, the prompt provides LLM with a broader context and a more comprehensive understanding of the content. This contextual information helps LLM generate descriptions that are more relevant to the specific item and its related items, thereby increasing their usefulness in content recommendation scenarios.
    \item  \textbf{User Preference Alignment:} Including the content descriptions of important neighbor items, which are determined based on user engagement, enables LLM to align with user preferences. By considering items that are frequently engaged by users, the generated content descriptions are more likely to capture the content characteristics and features that are appealing to the target users. This alignment enhances the usefulness of the generated descriptions in effectively recommending items that align with user preferences.
    \item \textbf{Enhanced Recommendation Quality:} The engagement-guided prompt leverages user engagement data to identify important neighbor items. By including information from these items in the prompt, LLM can potentially uncover meaningful connections, similarities, or relevant aspects between the target item and its neighbors. This can result in more accurate, informative, and high-quality content descriptions, thereby improving the overall performance of the content recommendation system.
\end{enumerate}

\subsection{Recommendation-driven + engagement-guided prompting}
This type of prompt intends to incorporate both the recommendation-driven and engagement-guided instructions (Figure~\ref{fig:llm-rec}), which we denote as $\pmb{p^{eng\text{-}rec}}$. The prompt is designed as following:

{\it ``The description of an item is as follows: `{$d_{target}$}'. What should I say if I want to recommend it to others? This content is considered to hold some similar attractive characteristics as the following descriptions: `{$d_{1}$}; {$d_{2}$}; ... {$d_{T}$}'.''}



\section{Experiment}

\subsection{Experiment Setup}
In this study, we delve into the realm of content recommendation prompting for large language models using a well-established recommendation benchmark. The evaluation architecture, as depicted in Figure~\ref{fig:evaluate}, comprises three key components: the item module, the user module, and the recommendation module. Throughout our evaluation, we ensure that the user module and the recommendation module \textbf{remain consistent} across all baselines. The sole variation lies in the augmented text, which is generated by the Language Model (LLM) using different prompts. Consequently, the augmented text is the sole distinguishing factor among the baselines.

To assess the generation quality of the augmented text in the context of the recommendation task, we meticulously design and conduct an empirical experiment. This experiment allows us to gauge and compare the performance and effectiveness of the various prompts employed across the baselines.


% Figure environment removed



\subsubsection{Benchmark.}
\textbf{MovieLens-1M}~\cite{harper2015movielens} is a highly recognized benchmark dataset commonly used for evaluating item recommendation systems. It contains a vast collection of 1,000,209 ratings provided by 6,040 MovieLens users, covering 3,900 movies. Each user has at least 20 ratings. Following  He~\etal~\cite{he2017neural}, we convert the rating data into implicit feedback. More specifically, each entry is marked as 0 or 1 indicating whether the user has rated the corresponding item. The original movie data only contain movie titles and genres. We employ GPT-3 ({\tt text-davinci-003}) to generate the content description of each movie using the following prompt:

{\it ``Summarize the movie} \{{\tt title}\} {\it with one sentence. The answer cannot include the movie title.''}

The response from GPT-3 is used as the content description. {\tt Temperature} is set at 0 to generate more focused and deterministic responses. 


\subsubsection{Item module.}
\begin{itemize}
    \item \textbf{Response generation:} In our evaluation, we focus on assessing the performance of \textbf{GPT-3}~\cite{brown2020language}, particularly the variant known as {\tt text-davinci-003}. This model is an advancement over the InstructGPT models~\cite{ouyang2022training}, incorporating several improvements. We specifically select this variant due to its ability to consistently generate high-quality writing, effectively handle complex instructions, and demonstrate enhanced proficiency in generating longer form content~\cite{raf2023davinci}.
    \item \textbf{Text encoder:} We use Sentence-BERT~\cite{reimers2019sentence} to derive the textual embeddings from the original content description and augmented text. The embedding model is {\tt all-MiniLM-L6-v2}. 
    \item \textbf{Baselines:} In addition to the basic prompting (\ie $\pmb{\tt p_{1}}$, $\pmb{\tt p_{2}}$, $\pmb{\tt p_{3}}$), recommendation-driven prompting (\ie $\pmb{\tt p_{1}^{rec}}$, $\pmb{\tt p_{2}^{rec}}$, $\pmb{\tt p_{3}^{rec}}$), engagement-guided prompting (\ie $\pmb{\tt p^{eng}}$), and recommendation-driven + engagemen guided prompting (\ie $\pmb{\tt p^{eng\text{-}rec}}$), we include a baseline where no augmented text is added. The only item input is the original content description, which we denote as $\pmb{CD}$.
    \item  \textbf{Module architecture:} The augmented text embeddings and the original content description embeddings are combined by concatenation and then passed through a two-layer MLP (Multi-Layer Perceptron). In most baselines, the input dimension of the first MLP layer is 768, except for the baseline where only the original content description ($\pmb{CD}$) serves as input, which has an input dimension of 384. The first MLP layer's output dimension, as well as the input/output dimensions of the second MLP layer, are all set to 128. A ReLU activation function and a dropout layer are applied to the first MLP layer
    \item \textbf{Importance measurement for engagement-guided prompting: } In our study, we show an example of use Personalized PageRank (PPR) score as the importance measurement. In particular, we first construct the user-item bipartite graph $G=(V, E)$. In this notation, $G$ represents the bipartite graph, $E$ denotes the set of nodes, and $E$ represents the set of edges. There are two types of nodes including users $V_{user} \subset V$ and items $V_{item} \subset V \:(V_{user} \cup V_{item} = V, V_{user} \cap V_{item} = \varnothing)$. An edge $e \in E$ between a user node $v_{user} \in V_{user}$ and an item node $v_{item} \in V_{item}$ is created if this user interacts with this item. 
    
    Next, we proceed by calculating the Personalized PageRank (PPR) score for each item node, which quantifies their relative importance from an individual node's perspective. For every item node, we construct a set of significant neighboring items. By identifying the top $T$ item nodes with the highest PPR scores that share the same genre as the target item node, we pinpoint essential neighbor items guided by user engagement. The rationale behind this approach lies in the observation that when users frequently engage with two items, there tends to be a greater similarity in terms of user preferences. By incorporating this information, we aim to capture user preferences more effectively, leading to enhanced performance in content recommendation. For\textbf{ Movielens-1M}, we set $T=3$.
\end{itemize}

\subsubsection{User module.}
We employ an embedding table to convert user ID into latent representations. For MovieLens-1M, the output dimension is set at 128.


\subsubsection{Recommendation module.}
In our study, the recommendation module is implemented using a straightforward dot product approach. The dot product of the latent embeddings of the user and the item is calculated, and the resulting value is then passed through a Sigmoid function. This Sigmoid function transforms the dot product into a final relevance score between the user and the item.

\subsubsection{Model training.}
To train the model, we employ the Binary Cross Entropy Loss. Each user-item interaction is considered as a positive sample. Each user-item interaction within the dataset is treated as a positive sample. In addition to positive samples, we randomly select negative samples by pairing users and items that do not have any recorded interactions. To prevent overfitting and optimize training efficiency, we employ an early stop mechanism. It is worth noting that we have also explored the possibility of using the Bayesian Personalized Ranking (BPR) Loss~\cite{rendle2012bpr} within the framework. However, after experimentation, we find that the BPR Loss does not yield superior performance compared to the Binary Cross Entropy Loss. As a result, we choose to use the Binary Cross Entropy Loss as our primary loss function.




\subsubsection{Evaluation protocols.}
To assess the recommendation performance, we adopt the evaluation methodology employed by Wei~\etal~\cite{wei2019mmgcn}. Initially, we randomly divide the dataset into training, validation, and testing sets using an 8:1:1 ratio. Negative training samples are created using random negative sampling, as mentioned earlier. 

For the validation and testing sets, we pair each observed user-item interaction with 1,000 unobserved items that the user has not previously interacted with. It is important to note that there is \textit{no} overlap between the negative samples in the training set and the unobserved user-item pairs in the validation and testing sets. This ensures the independence of the evaluation data.

To evaluate the performance of top-K recommendations, we employ widely-used metrics such as Precision@K, Recall@K, and NDCG@K. In our case, we set $K=10$, indicating that we consider the top 10 recommendations. We report the average scores across five different splits of the testing sets, providing a comprehensive evaluation of the recommendation performance. 

\subsubsection{Parameter settings.}
We initialize the model parameters randomly, following a Gaussian distribution. To optimize the framework, we employ the AdamW algorithm~\cite{loshchilov2017decoupled} with a weight decay value of 0.0005. The hyperparameter grids for the learning rate and dropout rate are $\{0.0001, 0.0005, 0.001\}$ and $\{0.1, 0.3, 0.5\}$, respectively. Settings that achieve the highest Recall@K on the validation set are chosen for the evaluation on the testing set. The performance is evaluated every five epochs, and the early stop mechanism is configured to have a patience of 5. Additionally, we set the batch size to 4096.

\subsubsection{Implementation details.}
Our methods are implemented and experiments are conducted using PyTorch. The computation of PPR scores is facilitated by the use of the {\tt torch-ppr} library. The experiments are conducted on a NVIDIA A100 GPU with 40 GB of memory. Each experiment is run on one GPU at a time.

\section{Results}
The recommendation performances are summarized in Figure~\ref{fig:basic_rec}. With the exception of $\pmb{CD}$, all other baselines use a concatenation of the $\pmb{CD}$ embeddings and prompt response embeddings as their textual input. For instance, the bar corresponding to $\pmb{p_{1}}$ represents the recommendation performance of the baseline that combines the $\pmb{CD}$ and $\pmb{p_{1}}$ embeddings as input. In this figure, we have \textbf{omitted the explicit representation of $\pmb{CD}$ for the sake of simplicity}.


Four key takeaways can be observed from the figure. Firstly, the combination of augmented text and the original content description leads to an improvement in recommendation performance. This finding suggests that all three types of prompting, namely basic, recommendation-driven, and engagement-guided, provide additional and valuable information for the recommendation module to effectively model content recommendation.


Secondly, the results indicate that recommendation-driven prompting primarily enhances the generation of text input for content recommendation. However, when comparing $\pmb{p_{3}}$ and $\pmb{p_{3}^{rec}}$, which instruct LLM to deduce the characteristics of the original content description, a \textit{decrease in performance} is observed. This suggests that the reduced recommendation performance may stem from the discrepancy between the inferred context and the original context. In other words, the desired response from $\pmb{p_{3}}$ requires inference \textit{beyond} the information provided in the original context, making it less effective. Conversely, recommendation-driven prompting proves beneficial for $\pmb{p_{1}}$ and $\pmb{p_{2}}$, as these prompts do not rely on LLM inferring information beyond the original input.

Thirdly, when comparing $\pmb{p^{eng}}$ with basic prompting, we observe improvements in content recommendation. This suggests that engagement-guided prompting, which incorporates engagement signals into prompts, allows the Language Model (LLM) to generate responses that better align with user preferences.

Fourthly, among all the baselines, the combination of the original content description with augmented text generated from both recommendation-driven and engagement-guided prompts (denoted as $\pmb{p^{eng\text{-}rec}}$) achieves the highest performance gains. To further investigate the quality of the combined augmented text, we concatenate the embeddings of the responses from $\pmb{p_{1}^{rec}}$, $\pmb{p_{2}^{rec}}$, $\pmb{p_{3}^{rec}}$, $\pmb{p^{eng}}$, $\pmb{p^{eng\text{-}rec}}$, along with the original content description. We then conduct the same experiment again, searching for hyperparameters in the similar manner as discussed previously. On the testing set, the Precision@10, Recall@10, and NDCG@10 scores are found to be 0.3109, 0.2695, and 0.3891, respectively. These results \textbf{outperform} the model that solely uses the original content description (represented as $\pmb{CD}$ in Figure~\ref{fig:basic_rec}) by an absolute gain of 1.95\%, 2.55\%, and 2.65\%, respectively. This finding emphasizes the added value of incorporating both recommendation-driven and engagement-guided prompts for augmenting text, to further enhance the recommendation performance over using the original content description alone.



% Figure environment removed

\section{Discussion}
In this study, we have investigated the effectiveness of \textbf{LLM-Rec} prompting as a straightforward yet impactful mechanism for improving personalized content recommendation through large language models. Our findings reveal several key insights.

Firstly, we demonstrate that by combining augmented text with the original content description, we observe a significant enhancement in recommendation performance. This highlights the value of incorporating additional context to facilitate more accurate and relevant recommendations.

Furthermore, our experimental results on recommendation-driven and engagement-guided prompting strategies illustrate their ability to encourage the large language model to generate high-quality input text specifically tailored for recommendation purposes. These prompting strategies effectively leverage recommendation goals and user engagement signals to guide the model towards producing more desirable recommendations.

Lastly, by combining both recommendation-driven and engagement-guided prompting strategies, we achieve the best overall recommendation performance. This suggests the complementary nature of these strategies and their collective impact in further improving recommendation quality.

Overall, our study showcases the effectiveness of \textbf{LLM-Rec} prompting in facilitating large language models to generate enhanced and relevant input text for personalized content recommendation. These findings contribute to the advancement of recommendation systems, emphasizing the significance of thoughtful prompt design to enhance recommendation performance.

Throughout our experimental analysis, we also uncover a potential limitation when employing LLM for augmenting input text in recommendation systems. We notice a distinction between prompts that solely instruct LLM to modify the content description and those that prompt LLM to infer additional information. In the latter case, where inference beyond the original context is required, the recommendation-biased prompting strategy may not yield the expected benefits. Our hypothesis suggests that the quality, specifically in terms of recommendation relevance, of the inferred context might have an unknown impact on the overall recommendation performance.

This observation emphasizes the need for careful consideration and evaluation of the prompts employed, particularly when instructing LLM to infer information beyond the provided context. While recommendation-biased prompting strategies prove effective for prompts that do not necessitate inference, their effectiveness may be hindered when the prompts require LLM to extrapolate information. Further research is necessary to explore techniques for managing and improving the quality and impact of inferred context on recommendation outcomes.

In addition to its superior performance in personalized content recommendation, the incorporation of engagement signals in prompt designs may have broader associated benefits. The engagement-guided prompting strategy instructs the LLM to generate commonalities among different items, resembling the concept of neighborhood aggregation in Graph Neural Network (GNN) learning. In GNN, each target node is partially learned by aggregating information from its neighboring nodes. In this context, we highlight the potential of using engagement-guided prompts as a means to replace the learning process of GNN, thereby simplifying the overall model architecture. 

Furthermore, leveraging the fine-tuned LLM opens up possibilities for zero-shot generation without incurring any additional learning cost. Since the LLM has already undergone training to capture linguistic patterns and semantic understanding, it can be harnessed to generate responses or recommendations in unseen scenarios without requiring further training. This zero-shot generation capability enables flexibility and scalability in recommendation systems, allowing for efficient adaptation to new domains or contexts.

The combination of engagement-guided prompting and the zero-shot generation potential of the fine-tuned LLM presents promising opportunities for streamlining model architectures, reducing computational complexity, and expanding the applicability of recommendation systems. Further exploration and investigation in this direction could unlock novel techniques for efficient and effective personalized content recommendation.

\section{Related Work}

In addition to leveraging LLMs directly as recommenders, there have been efforts to use LLMs for augmenting the input side of personalized recommendation. For instance, Chen~\etal~\cite{chen2023palr} incorporated user history behaviors, such as clicks, purchases, and ratings, into LLMs to generate user profiles. These profiles were then combined with the history interaction sequence and candidate items to construct the final recommendation prompt. LLMs were subsequently employed to predict the likelihood of user-item interaction based on this prompt. However, our study takes a different approach, focusing specifically on input augmentation for items. By employing prompting strategies, we aim to generate augmented input text that better captures the characteristics and nuances of items, leading to improved personalized content recommendations.

Xi~\etal~\cite{xi2023towards} introduced a method that leverages the reasoning knowledge of LLMs regarding user preferences and the factual knowledge of LLMs about items to augment input features. Their approach assumes that LLMs possess factual knowledge about the items to be recommended. In contrast, our studies differ in the underlying assumptions and prompting strategies. We do not assume that LLMs inherently possess factual knowledge about the items to be recommended. Instead, we focus on the augmentation of input text solely through item descriptions, thereby expanding the scope of items to include those with only textual descriptions. Furthermore, building upon this assumption, we have designed various prompting strategies specifically tailored for personalized recommendation. These strategies take into account the unique nature of the input text augmentation process and are devised to optimize the recommendation performance.



\section{Conclusions}
In this study, we introduce \textbf{LLM-Rec} prompting strategies, which leverage large language models (LLMs) for input augmentation, aiming to enhance personalized content recommendation. Through rigorous experimentation across four variants of \textbf{LLM-Rec}, we observe that the combination of augmented input text and original content descriptions yields notable improvements in recommendation performance.

These findings emphasize the potential of using LLMs and strategic prompting techniques to enhance the accuracy and relevance of personalized content recommendation. By incorporating additional context through augmented text, we enable the recommendation algorithms to capture more nuanced information and generate recommendations that better align with user preferences.

The experimental results of \textbf{LLM-Rec} highlights the importance of innovative approaches in leveraging LLMs for content recommendation and showcases the value of input augmentation in improving recommendation performance. As personalized content recommendation continues to play a pivotal role in various domains, our study provides insights into effective strategies for leveraging LLMs to deliver enhanced recommendation experiences.



\bibliography{report} 
\bibliographystyle{plain}

\end{document}
