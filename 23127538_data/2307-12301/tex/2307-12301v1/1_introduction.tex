Outliers, or data points that do not conform to the overall pattern of the dataset, are a common occurrence during large-scale data collection (see Figure \ref{fig:problem-statement}). In the field of computer vision, image outliers can pose significant challenges to the development of machine learning models, which are often trained on large-scale image datasets. 
The presence of outliers can lead to model overfitting, reduced generalization performance, and inaccurate predictions as shown in our experiments. Therefore, detecting and addressing outliers from image datasets remains a critical task in computer vision.


% Figure environment removed

There have been a range of outlier detection (OD) methods proposed in machine learning literature, from probabilistic models \cite{ecod, gmm} to outlier ensemble techniques \cite{algo-iforest, algo-inne} to even proximity-based algorithms \cite{knn-od, local_outlier_factor}. The majority of such methods, however, are targeted toward tabular data. Tabular data describes a type of structured data where the features take on attribute values of certain entities. Images, on the contrary, are high-dimensional unstructured data formed by a collection of pixel arrays. 

To address the disparity in data representation, innovative approaches \cite{iForest_on_NN} have emerged that aim to bridge the gap by substituting tabular data with image embeddings. The approach involves passing an image through a neural network, also known as a feature extractor, to obtain an embedding, followed by the use of tabular methods to perform OD.
However, unlike tabular data, embeddings are representations in the latent space (non-human readable), and their representation depends on the choice of the feature extractor \cite{representation_learning, deep_neural_nets_tabular_data_survey}. 
This difference, we believe, may limit the performance of existing OD methods when applied to image data. 

In this paper, we introduce an unsupervised two-stage approach named RANSAC-NN, which comprises Inlier Score Prediction (ISP) and Threshold Sampling (TS).
ISP, inspired by Random Sample Consensus (RANSAC) \cite{ref_ransac}, relies on iterative sub-sampling of the dataset to compute an estimate of the inlier distribution using nearest neighbors (NN) scores. TS, on the other hand, leverages the estimated inlier distribution from ISP to make fine-grained outlier score predictions.

Unlike methods \cite{deepsvdd, Outlier_Analysis} that require a supervised {\em clean} set of inliers, RANSAC-NN performs OD completely unsupervised. Additionally, our algorithm does not involve any training, making it a widely-applicable solution that can be employed right out of the box.

We evaluate the effectiveness of RANSAC-NN on several benchmark datasets and compare its performance to state-of-the-art (SOTA) OD methods. 
The results show that our algorithm achieves superior performance compared to existing methods across varying levels of outlier presence. 
Furthermore, RANSAC-NN maintains a relatively competitive performance when paired with a variety of feature extractors, indicating its accessibility to a wide range of feature embeddings. 

In summary, we make the following contributions.% in this work:
\begin{itemize}
    % \setlength\itemsep{0em}
    \item We demonstrate how image outliers in training datasets can negatively impact a model's image classification performance if they are not addressed properly prior to model training. 
    \item We present a novel image outlier detection algorithm, RANSAC-NN, that does not require any annotation and training to produce quality results. Our method was evaluated quantitatively and qualitatively across a range of datasets and achieved competitive performance against existing SOTA methods.
    \item We provide an in-depth analysis on the components of RANSAC-NN and elaborate on how each contributes to the success of the algorithm.
    
\end{itemize} 
