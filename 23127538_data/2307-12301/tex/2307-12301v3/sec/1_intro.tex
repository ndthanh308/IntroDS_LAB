\section{Introduction}
\label{sec:intro}

Outlier detection (OD) refers to the task of identifying abnormal data that deviates from a given target distribution. 
Abnormal data are known as \textit{outliers}, and \textit{inliers} are data that belong within the target distribution. In general, the outlier distributions are not known in advance, and the goal of OD methods is to separate inliers from outliers in a \textit{one-class classification} fashion \cite{one_class_classification, oc-svm, 2004_svdd, 2019_deep_feature_for_oneclass_cls, a_surve_of_one_class_khan}.

% Most OD algorithms can be categorized into three main categories: unsupervised, semi-supervised, or supervised methods \cite{od_survey, Outlier_Analysis_aggarwal, generalize_ood_survey, zhao2019pyod}. 
% In unsupervised methods \cite{isolation_forest, local_outlier_factor, knn-distance-algo}, a \textit{contaminated} dataset containing \textbf{inliers with possible outliers} is provided. It is assumed that inliers constitute the majority of the dataset, whereas outliers reside in low-density regions in the sample space. 
% % This allows unsupervised methods to identify outliers within the contaminated set by modeling the data distribution.
% Semi-supervised methods \cite{2018_deepsvdd, algo-lunar, 2015_vae_anomaly_det, 2019_deep_feature_for_oneclass_cls, 2021_neural_transformation} utilize a \textit{clean} dataset consisting of \textbf{exclusively inlier samples}. 
% Unique characteristics of the inlier distribution are learned during model training to differentiate future outliers from inliers. 
% A model is trained on the clean dataset prior to OD.
% Supervised methods \cite{2021_exploring_limits_of_ood, 2018_outlier_exposure, 2021_ood_Abstention, 2021_dermatology_ood} assume a predefined outlier distribution. a set of labeled inliers and outliers are employed to train a classification model.

% train a model on a labeled set of inlier and outlier samples. Since the outlier distribution is often unknown, we concentrate on semi-supervised an supervised methods in this paper.

% additional knowledge of the outlier distribution. These methods entail training a model on a labeled dataset comprised of both inlier and outlier samples before prediction. 
% Given that supervised methods are more closely related to imbalanced classification, this paper focuses primarily on semi-supervised and unsupervised approaches.

Image OD is an extension of general OD for the field of computer vision  \cite{od_survey, generalize_ood_survey, ImageOD-survey}. The objective is to identify complete images or patches of images that are visually distinct. Low-level pixel regions that protrude from neighboring patches are considered patch-level abnormalities. Abnormality at the image level is an image that looks different from a regular image as a whole. For the scope of this paper, we limit our discussion towards OD at the image level.

The variety of image OD methods ranges from traditional tabular techniques to recent deep learning-based approaches. Traditional techniques often assume the data to consist of low-dimensional tabular features \cite{isolation_forest, algo-inne, local_outlier_factor, loda}.  However, these methods have not been designed to handle the high-dimensional pixel array in natural images. Deep learning introduced an automated method of extracting meaningful, resolution-independent features directly from images. This allowed the use of feature embeddings extracted by pre-trained neural networks to replace traditional features used by tabular methods \cite{knn-distance-algo, iForest_on_NN, 2019_deep_feature_for_oneclass_cls}. Neural network methods that learn unique features of the inlier distribution have also been proposed \cite{2018_deepsvdd, anogan, 2015_vae_anomaly_det, geom, goad}.

A big challenge among existing image OD methods is the dependence on a \textbf{clean inlier set} for model training. To build a good representation of the inlier distribution, the training data must contain enough inlier samples while avoiding outlier \textit{contamination}. Outlier presence causes actual outliers to be incorrectly treated as inliers during training, which leads to deteriorated OD performance during test time. Manual inspection is often necessary to ensure data quality, but this can be a time-consuming and expensive process.  

In this paper, we present RANSAC-NN, a novel image OD algorithm that addresses outlier contamination in image datasets. Inspired by RANSAC \cite{ref_ransac}, which was intended for the fundamental matrix estimation, our algorithm applies a two-stage iterative nearest neighbor sub-sampling for outlier prediction. Specifically, Inlier Score Prediction (ISP) in the first stage generates a set of \textit{inlier score} estimations, which are used by the second stage Threshold Sampling (TS) to predict the \textit{outlier score} of each sample. Outliers in the contaminated set can be removed by filtering out samples with outlier scores exceeding a certain threshold. Unlike previous approaches, whose objective is to develop a task-specific OD model for inference purposes, the goal of RANSAC-NN is to quantify outlier samples in a given contaminated set based on its image distribution alone. As a result, our algorithm does not require training or data preparation and can be applied straight out of the box.

% one class classification
We evaluate RANSAC-NN in comparison to existing methods on a range of OD tasks. The first observation is that almost all existing methods achieve similar performance when trained on a clean inlier set. However, when the training set is contaminated by outliers, a noticeable drop in performance occurs depending on the amount of outlier contamination. We then attempt to filter the outlier samples by applying RANSAC-NN on the contaminated sets. Models of existing OD algorithms were trained using the filtered datasets, and the results show significant improvements in all the algorithms. Additional experiments regarding the RANSAC-NN setup and hyper-parameter settings have also been explored in our evaluations.

In summary, we make the following contributions:
\begin{itemize}

    \item We demonstrate that the majority of image OD algorithms can achieve favorable and robust performance when trained properly using a clean inlier set. 
    
    \item We emphasize the importance of training on a clean inlier set by examining the performance drop of existing methods when trained on a contaminated dataset. 

    \item We present a novel image OD algorithm called RANSAC-NN that delivers promising performance in comparison to existing methods on a number of benchmarks. Our algorithm does not require data preparation or model training, and it is effective on datasets contaminated by outliers.

    \item We demonstrate an improved robustness against outlier contamination in all existing OD algorithms by employing RANSAC-NN during data preparation. 
    
\end{itemize} 

The remaining of this paper is organized as follows. In Section \ref{sec:related_works}, we provide an overview of some well-known OD methods. In Section \ref{sec:methods}, we present the proposed RANSAC-NN algorithm. In Section \ref{sec:experiments}, we detail the experimental results. Finally, we conclude the paper in Section \ref{sec:conclusions}.
    
% outlier contamination can impact the performance of existing image OD methods. 






% The results show that almost all existing methods can easily achieve near perfect performance when trained on a clean inlier set. However, a noticeable performance drop occurs when outliers are introduced into the training set. We then evaluate RANSAC-NN as pre-processing strategy, which we observe an overall improvement in performance. 


% The first apparent observation is that almost all existing methods achieve near perfect performance when trained on a clean inlier set. However, a decline in performance among existing algorithms can be observed, depending on the amout of 

% when outliers are present in the training set. 


% when a clean inlier set is provided, almost all existing methods achieved near perfect performance. However, when contamination 
% We first demonstrate that in cases where a clean inlier set is provided, we show that almost all existing OD algorithms perform equally well.

% The results show that almost all existing OD methods perform equally well when trained on a clean inlier set. However

% and we evaluate its performance in comparison to other state-of-the-art algorithms. The results show that our algorithm achieves favorable performance in comparison to the well

% RANSAC-NN does not estimate any model parameters or require any training to be applied. 

% neither any model or training is required to apply RANSAC-NN on a contaminated set. 

% that ranks the dataset samples by their outlier likelihood. Unlike the original RANSAC, our algorithm does not build or estimate any model parameters. Furthermore, RANSAC-NN can be applied directly on a contaminated set without any training.

% To address this issue, we present an unsupervised image OD algorithm that operates directly on a contaminated set. Rerank inspired by 


% forms a boundary while learning to identify real from generated data. 
% Energy based methods and diffusion based methods have also demonstrated potential in effective image OD.  


% Prior to the prominence of deep learning, the vast majority of OD algorithms attempted image OD by flattening the 2D pixel arrays into vectors and applying the respective algorithm. Most algorithms, however, were designed for tabular data, which are  structured concatenations of hand-crafted features. Unlike images, which are unstructured high dimensional pixel arrays, tabular data possess significantly lower feature dimensions with weakly correlated attributes. 

% often weakly correlated, and the feature dimension is comparatively smaller. This difference has 
% This has limited the application of most OD methods to only low-dimension images. 

% limited their applications to only low-dimension images. Since most methods were designed with the focus on the tabular data domain, transferring such methods to images have  

% This is a good paragraph, but maybe leave to related works since it talks about the details of tabular data
% Within the OD literature, most methods focus on detecting abnormality using hand-crafted features common in tabular data. The tabular features are often interpretable and weakly correlated, and the dimension size is relatively low. In contrast, images are high dimensional pixel arrays with strong locally correlating features. This has limited the application of most OD methods to only low-dimension images. 

% Deep learning provided a method to learning feature representations automatically. Specifically, a deep neural network is trained with large amounts of data for an objective, and the feature representations are the intermediate neuron outputs. Unlike tabular data, the feature representations (also known as ``embeddings'') are non-interpretable latent vectors.

% has been an active area of research within the computer vision community. Several studies have explored the use of auto-encoders to model the inlier image distribution. During inference, images that exhibit abnormally large reconstruction error in the latent space can be considered outliers. Another class of solutions have suggested the use of generative-adversarial networks (GAN's) as a method of modeling the inlier and outlier distributions. <something here about GANs> < Softmax probability method > <Cleanlab recent discovery> <all methods rely on a clean inlier set> 

% has also been an active area of research. As deep learning continues to gain prevalence in recent years, a number of studies have suggested reconstruction-based methods as well as generative-adversarial training for OD purposes.  

% remember, these guys are here to help


% TODO:
% leave outlier score to methods
% describe one class classification when introducing our method

% predicting an ``outlier score''. 


% P3: Challenge with starting with clean set to begin, Talk about image OD & 
% In computer vision (CV), image OD methods have been prevalent in applications involving xxx, yyy, and data cleaning. 
% plays an important role in ensuring the quality of image datasets, as well as robustness of  [image OD is common in CV]. [However, most of these image OD algorithms require a clean dataset to begin with.] [It is expensive, time-consuming to manually clean.] [In this work, we present...]
% P4: Talk about our method




