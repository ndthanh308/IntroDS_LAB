\section{Introduction}
\label{sec:intro}
Modern data analytics like SQL and BI are predicated on a standard format of relational tables, where each row corresponds to a distinct ``entity'', and each column corresponds to an ``attribute'' for the entities that contains homogeneous data-values. While such tables are de-facto standards in relational databases, such that as database people we may take this for granted, a significant fraction of tables ``in the wild'' actually fail to conform to such standards, making them considerably more difficult to query using SQL-based tools.


% Figure environment removed

% Figure environment removed







%web table examples:
% https://en.wikipedia.org/wiki/Demographics_of_the_United_States
% https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_historical_population
% https://en.wikipedia.org/wiki/List_of_countries_by_past_and_projected_GDP_(nominal)
% https://en.wikipedia.org/wiki/List_of_regions_by_past_GDP_(PPP)_per_capita
% https://en.wikipedia.org/wiki/List_of_countries_by_largest_historical_GDP

\textbf{Non-relational tables are common, but hard to query.} 
Real tables in the wild, such as spreadsheet-tables or web-tables, can often be ``non-relational'' and hard to query, unlike tables that we expect to find in relational databases. We randomly sampled hundreds of user spreadsheets (in Excel), and web tables (from Wikipedia), and found around 30-50\% tables to have such issues.
Figure~\ref{fig:combined-ex} and Figure~\ref{fig:combined-web-ex} show real samples taken
from spreadsheets and the web, respectively, to demonstrate these common issues. (We emphasize that the problem is prevalent at a very large scale, since there are millions of tables like these in spreadsheets and on the web.)


%and found these issues are widespread in real tables in the wild --  around 30-50\% tables we sampled have similar structural issues that make them hard to query. Considering that there are hundreds of millions of tables out there on the web and in spreadsheets, it is evident that the problem is prevalent on a large scale, if we want to help users unlock analytical value from these tables. %in analytical use cases.

%\yeye{add link to excel forum questions, to show non-relational tables cannot be queried easily}


%Figure~\ref{fig:combined-ex} and Figure~\ref{fig:combined-web-ex} show real examples taken from spreadsheets and the web, respectively.

%To illustrate common structural issues for these non-relational tables, we present four real examples taken from spreadsheets in the wild in Figure~\ref{fig:combined-ex}. 

Take Figure~\ref{fig:combined-ex}(a) for example. The table on the left is not a standard relational table, because each column marked in green contains sales numbers for only a single day (``\code{19-Oct}'', ``\code{20-Oct}'', etc.), making these column values highly homogeneous in the horizontal direction (while in typical relational tables, we expect values in columns to be homogeneous in the vertical direction). Although this specific table format makes it easy for humans to eyeball changes day-over-day by reading horizontally, it is unfortunately hard to analyze using SQL. Imagine that one needs to compute the 14-day average of sales, starting from  \code{``20-Oct''} -- for this table, one has to write: \code{SELECT SUM(``20-Oct'', ``21-Oct'', ``22-Oct'', ...) FROM T}, across 14 different columns, which is long and unwieldy to write. Now imagine we need 14-day moving averages with every day in October as the starting date -- the resulting SQL is highly repetitive and  hard to manage. %because these dates that are ordinarily data-values are now encoded as column-headers that  are hard to manipulate.

In contrast, consider a transformed version of this table, shown on the right of Figure~\ref{fig:combined-ex}(a). Here the homogeneous columns in the original table (marked in green) are transformed into only two new columns: ``\code{Date}'' and ``\code{Units Sold}'', using  a transformation operator called ``\code{stack}'' (listed in the first row of Table~\ref{tab:dsl}). This transformed table contains the same information as the original table, but is much easier to query -- e.g., the same 14-day moving average can be computed using a succinct range-predicate on the `\code{Date}'' column, where the starting date ``\code{20-Oct}'' is a literal parameter that can be easily changed into other values.

There are many such spreadsheet tables that require different kinds of transformations before they are ready for SQL-based analysis. Figure~\ref{fig:combined-ex}(b) shows another example where every 3 columns form a group, representing ``\code{Revenue}/\code{Units Sold}/\code{Margin}'' for a different year, repeating for many times (marked in red/green/blue in the figure). Tables with these repeating column-groups are also hard to query just like Figure~\ref{fig:combined-ex}(a), but in this case the required transformation operator is different and called ``\code{wide-to-long}'' (listed in the second row of Table~\ref{tab:dsl}).

Figure~\ref{fig:combined-ex}(c) shows yet another example, where each hotel corresponds to a column (whose names are in row-1), and each ``attribute'' of these hotels corresponds to a row. Note that in this case values in the same rows are homogeneous  (marked in different colors), unlike relational tables where values in the same columns are homogeneous. A transformation called ``\code{transpose}'' is required in this case (listed in the third row of Table~\ref{tab:dsl}), to make the resulting table, shown on the right of the figure, easy to query -- for instance, a query to sum up the total number of hotel rooms is hard to write on the original table, but can be easily achieved using a simple SUM query on the  ``\code{Single Room}'' column in the transformed table.


Figure~\ref{fig:combined-ex}(d) shows another example where columns are represented as rows in the table on the left. This is similar to Figure~\ref{fig:combined-ex}(c), except that the rows in this case are ``repeating'' in groups, thus requiring a different transformation operator called ``\code{pivot}'' (listed in the fourth row of Table~\ref{tab:dsl}) as opposed to ``\code{transpose}''.  The resulting table is shown on the right, which becomes easy to query.

While the examples so far are all taken from spreadsheets, we note that similar structural issues are also widespread in Web tables. Figure~\ref{fig:combined-web-ex} shows real examples from Wikipedia, which share similar characteristics as the spreadsheet tables in Figure~\ref{fig:combined-ex}, which all require transformations before these tables can be queried effectively. 

\begin{table*}[t]
\vspace{-15mm}
\caption{\at DSL: table-restructuring operators and their parameters to ``relationalize'' tables. These operators are common and exist in many different languages, like Python Pandas and R, sometimes under different names.}
\label{tab:dsl}
\vspace{-4mm}
\scalebox{0.8}{
\vspace{-16mm}
\hspace{-6mm}
\begin{tabular}{l|l|l|l}
\toprule
DSL operator & Python Pandas equivalent & Operator parameters & Description (example in parenthesis) \\
\midrule
stack & melt~\cite{op-melt} &  start\_idx, end\_idx & collapse homogeneous cols into rows (Fig.~\ref{fig:combined-ex}a) \\
wide-to-long & wide\_to\_long~\cite{op-wide-to-long} &  start\_idx, end\_idx, delim &  collapse repeating col-groups into rows (Fig.~\ref{fig:combined-ex}b) \\
transpose & transpose~\cite{op-transpose} & - & convert rows to columns and vice versa (Fig.~\ref{fig:combined-ex}c) \\
pivot & pivot~\cite{op-pivot} & repeat\_frequency & pivot repeating row-groups into cols (Fig.~\ref{fig:combined-ex}d) \\
explode & explode~\cite{op-explode} &  column\_idx, delim & convert composite cells into atomic values \\
ffill & ffill~\cite{op-ffill} & start\_idx, end\_idx & fill structurally empty cells in tables \\
subtitles & copy, ffill, del & column\_idx, row\_filter & convert table subtitles into a column \\
none &  - & -  & no-op, the input table is already relational \\
\bottomrule
\end{tabular}
}
\end{table*}

\textbf{Non-relational tables are hard to ``relationalize''.}
We mentioned that the example tables in Figure~\ref{fig:combined-ex} and Figure~\ref{fig:combined-web-ex} require different transformation operators. Table~\ref{tab:dsl} shows 8 such transformation operators commonly needed to relationalize tables (where the first 4 operators correspond to  the examples we see in Figure~\ref{fig:combined-ex}). 

The first column of Table~\ref{tab:dsl} shows the name of the ``logical operator'', which may be instantiated differently in different languages (e.g., in Python or R), with different names and syntax. The second column of the table shows the equivalent Pandas operator in Python~\cite{pandas}, which is a popular API for manipulating tables among developers and data scientists, that readers may be familiar with.
%. (Similar equivalent operators can be found in other languages such as R, with a different syntax.)

While the functionalities listed in Table~\ref{tab:dsl} already exist in languages such as R and Python, they are not easy for users to invoke correctly, because users need to:
\begin{enumerate}[leftmargin=*,noitemsep]
%\setlength{\itemindent}{-5mm}
\item Visually identify different structural issues in an input table that make it hard to query (e.g., repeating row-/column-groups shown in Fig.~\ref{fig:combined-ex}(a-d)), which is not obvious to non-expert users; 
\item Map the visual pattern identified from the input table, to a corresponding operator in Table~\ref{tab:dsl} that can handle such issues. This is hard as users are often unfamiliar with the exact terminologies to describe these transformation operators (e.g., \code{pivot} vs. \code{stack}), often needing to search online for help;
\item Parameterize the chosen operator appropriately, using parameters tailored to the input table (e.g., which columns need to collapse into rows, what is the repeating frequency of column groups, etc.). This is again hard, as even developers need to consult the API documentation, which is often long and complex.
\item Certain input tables require more than one transformation step, for which users need to repeat steps (1)-(3) multiple times.
\end{enumerate}


% Figure environment removed


Completing these steps is a tall order even for technical users, as evidenced by a large number of related questions on forums like StackOverflow (e.g.,~\cite{stackoverflow-forum-1, stackoverflow-forum-2, stackoverflow-forum-3, stackoverflow-forum-4}).  Figure~\ref{fig:stackoverflow-ex} shows such an example question (popular with many up-votes), where the developer provides example input/output tables to demonstrate the desired transformation, and seek help on what Pandas operators to invoke. %Note that questions like this are highly up-voted, showing that such questions are common pain points for developers. % (e.g., which Pandas API to invoke, and what parameters to use, etc.). Completing these steps is all the more challenging, for an average non-technical user who often need to manipulate tables in spreadsheets.
%(the authors to this date still need to consult the Pandas API reference pages of these operators to program them appropriately). 
%where developers ask for suggestions on how to restructure their tables. 



If technical users like developers find it hard to restructure their tables, as these StackOverflow questions would show, it comes as no surprise that non-technical enterprise users, who often deal with tables in spreadsheets, would find the task even more challenging. We find a large number of similar questions on Excel and Tableau forums (e.g.,~\cite{excel-forum-1, excel-forum-2, excel-forum-3, excel-forum-4}), where users complain that without the required transformations it is hard to analyze data using SQL-based or Excel-based tools (e.g.,~\cite{forum-hard-to-query-1, forum-hard-to-query-2, forum-hard-to-query-3, forum-hard-to-query-4}).

The prevalence of these  questions confirms table-restructuring as a common pain point for both technical and non-technical users.


\textbf{\at: synthesize transformations without examples.}
In this work, we propose a new paradigm to automatically synthesize table-restructuring steps to relationalize tables, using the Domain Specific Language (DSL) of operators in Table~\ref{tab:dsl}, \textit{without requiring users to provide examples}. Our key intuition of why we can do away with examples in our task, lies in the observation that given an input table, the logical steps required to relationalize it are \textit{almost always unique} and with little ambiguity, as the examples in Figure~\ref{fig:combined-ex} would all show. This is because the transformations required in our task only ``restructure'' tables, that do not actually ``alter'' the table content, which is unlike prior work that focuses on \textit{row-to-row transformations} (e.g., TDE~\cite{tde} and FlashFill~\cite{flashfill}), or SQL-by-example (e.g.~\cite{SQLSynthesizer, Scythe-code}), where the output is ``altered'' that can produce many possible outcomes, which would require users to provide input/output examples to demonstrate the desired outcome. %Asking for even a small number of output samples in our table-to-table transformation task means that users need to specify \textit{an entire output table}, which is a significant amount of effort, especially for large and complex real tables. 

%which typically require only 1-3 output examples, applying the same user-paradigm to our task of table-restructuring would mean that users have to specify \textit{an output table}, which is usually too much effort, especially for large and complex real tables.

%Our unique insight is that for our task, it may be possible to synthesize transformations without asking users to provide explicit examples. This is because to ``relationalize'' a given input table, the sequence of steps is almost always uniquely determined, given the unique characteristics of an input table as shown in Figure~\ref{fig:combined-ex}. 
For our task, we believe it is actually important \textit{not} to ask users to provide examples, because in the context of table-to-table transformations like in our case, asking users to provide examples would mean users have to specify \textit{an output table}, which is a substantial amount of typing effort, making it cumbersome to use.

%The reason we believe we can pull this off using algorithms and without examples, is because 
As humans, we can ``visually'' recognize  rows/columns patterns (e.g., homogeneous value groups, as color-coded vertically and horizontally in Figure~\ref{fig:combined-ex}), to correctly predict which operator to use. The question we ask in this paper, is whether an algorithm can ``learn'' to recognize such patterns by scanning the input tables alone, to predict suitable transformations, in a manner that is analogous to how computer-vision algorithms would scan a picture to identify common but more complex objects like dogs and cats.  

We should note that like computer vision problems such as object detection, where hand-crafted heuristics are hard to write, the row/column-level patterns existing in our target tables are also data-dependent and subtle, which are hard to write as heuristic rules. Consider for example the table in Figure~\ref{fig:combined-ex}(b) -- for ease of illustration we pick a case with three distinct groups of columns (currency, integers, and percentage-numbers, marked in different colors). One may hand-craft a heuristic ``similarity function'' between columns that may work for this simple example,  but imagine the common scenario where all these  columns have similar-looking integer numbers (e.g., with no dollar signs and percentage signs), which is much more challenging to predict using heuristics, as fine-grained differentiation is required to tell the subtle differences between columns (e.g., difference in column header semantics or column value ranges), which is best learned from the data. In fact, we tested a baseline using heuristic rules to predict only the simple ``stack'', which has a low 0.38 accuracy, because of the subtle differences in data that are not captured by heuristics. We also tested an LLM-based approach using GPT-3.5, also without success (with more details in our experiments), further underlining the challenging nature of our task. These motivate us to develop a learning-based method specifically tailored to our table transformation task.


In computer vision, in order to pick up subtle clues from pictures, object detection algorithms are typically trained using large amounts of labeled data~\cite{imagenet} (e.g., pictures of dogs that are manually labeled as such). In our task, we do not have such labeled datasets. Therefore, we devise a novel \textit{self-training framework} that exploits the \textit{inverse functional relationships} between operators (e.g., the inverse of ``\code{stack}'' is known as ``\code{unstack}''),  to automatically build large amounts of training data without requiring humans to label, as we will explain in Figure~\ref{fig:inverse-function}. Briefly, in order to build a training example for operator $O$ (e.g., ``\code{stack}''), we start from a relational table $R$ and apply the inverse of $O$, denoted by $O^{-1}$ (e.g., ``\code{unstack}''), to generate a table $T = O^{-1}(R)$, which we know is non-relational. For our task, given $T$ as input, we know $O$ must be its ground-truth transformation, because by definition $O(T) = O(O^{-1}(R))=R$, which turns $T$ back to its relational form $R$. This makes $(T, O)$ an (example, label) pair that we can automatically generate at scale, and use as our training data. 

%This is possible because starting from a relational table $R$, and in order to build a training example for operator $O$ (e.g., ``\code{stack}''), we can first apply the inverse of $O$, denoted by $O^{-1}$ (e.g., ``\code{unstack}''), to generate a table $T = O^{-1}(R)$. 

Leveraging training data so generated, we  develop an \at system that can ``learn-to-synthesize'' table-restructuring transformations, using a deep tabular model we develop inspired by CNN-like architectures popular in the computer vision literature. We show our approach is effective on real-world tasks, which can solve over 70\% of test cases collected from user forums and spreadsheets, while being interactive with sub-second latency.



%- where to get training? leverage inverse relationships of operators to learn from self-supervision.

%- show an example output program in python

%- why existing work is insufficient (by-example, too cumbersome)

\textbf{Contributions.} We make these contributions in \at:

\begin{itemize}[noitemsep,topsep=0pt,leftmargin=*]
\item We propose a novel problem to automatically relationalize tables without examples, which addresses a common pain point for both technical and non-technical users, when they deal with tables in the wild outside of database settings.
\item We develop \at that learns-to-synthesize transformations, using a computer-vision inspired model architecture that exploits the common ``visual'' patterns in tables.
\item We propose a self-supervision framework unique in our setting to overcome the lack of training data, by exploiting the inverse functional relationships between operators to auto-generate training data, obviating the expensive process of human labeling.
\item We compile an extensive benchmark for this task by collecting 244 real test cases from user spreadsheets and online forums.\footnote{Available at \url{https://github.com/LiPengCS/Auto-Tables-Benchmark}.}  Our evaluation suggests that \at can successfully synthesize transformations for over 70\% of test cases at interactive speeds (with sub-second latency).
\end{itemize}