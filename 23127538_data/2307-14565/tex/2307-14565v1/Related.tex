\vspace{-2mm}
\section{Related work}
\label{sec:related}

\textbf{By-example transformation using program synthesis.} There is a large body of prior work on using input/output examples to synthesize transformations. One class of techniques focuses on the so-called ``row-to-row'' transformations where one input row maps to one output row (e.g., TDE~\cite{tde} and FlashFill~\cite{flashfill}), which are orthogonal to the table-restructuring transformations in \at, because these systems do not consider operators shown in Table~\ref{tab:dsl} that can change the structure of tables. Other forms of row-to-row transformations using partial specifications (e.g., transform-by-pattern~\cite{yang2021auto, trifacta-transform-by-pattern}, transform-by-target~\cite{jin2020auto, koehler2019incorporating}, and transform-for-joins~\cite{zhu2017auto, nobari2022efficiently}), are similarly also orthogonal to the problem we study in this work.

A second class of by-example transformation consider ``table-to-table'' operators, such as Foofah~\cite{jin2017foofah} and SQL-by-example techniques like PATSQL~\cite{takenouchi2020patsql}, QBO~\cite{qbo}, and Scythe~\cite{sql-by-example}. These techniques consider a subset of table-restructuring operators, %(e.g., SQL-by-example techniques focus on SPJ queries and not restructuring steps), 
which fall short in the \at task as we will show experimentally. It is also worth pointing out that unlike \at that takes no examples, these  systems require users to provide \textit{one example output table}, which is a significant amount of effort for users.



\textbf{Computer vision models for object detection.} Substantial progress has been made in the computer vision literature on object detection, with variants of CNN architectures being developed to extract salient visual features from pictures~\cite{vgg, resnet, alexnet}. 

Given the ``visual'' nature of our problem shown in Figure~\ref{fig:combined-ex}, and the strong parallel between ``pixles'' in images and ``rows/columns'' in tables, both of which form two-dimensional rectangles,  our model architecture is inspired by CNN-architectures for object detection, but specifically designed for our table transformation task. %(e.g., the use of 2x2 filters that are suited for homogeneity test between neighboring rows/columns). 

% removed in revision
%\revised{}
%\begin{comment}
\textbf{Representing tables using deep models.} Different techniques have been proposed to represent tables using deep models  (e.g., TaBERT~\cite{yin2020tabert}, Tapas~\cite{herzig2020tapas}, Turl~\cite{deng2022turl}, etc.). Most of these focus on natural-language (NL) aspects of tables, and tailor to NL-related tasks (e.g., NL-to-SQL and entity-linking~\cite{herzig2020tapas, yin2020tabert}), which we show are not suited for our table-transformation task, as it needs to exploit the structural homogeneity of tables (e.g., cell similarity in row/column-directions.). %There is also a line of work on representing spreadsheets using rich visual features (fonts, colors, etc.)~\cite{dong2019tablesense, wang2021tuta}, which are not considered in this work as \at aims to handle general-purpose tables that may not have such spreadsheet features. 

\textbf{Database schema design.} There is a body of classical database research on schema design, which typically involves normalizing or decomposing one large table into multiple smaller tables, so that the decomposed tables satisfy relational ``normal forms'' (3NF, BCNF, etc.)~\cite{normal-forms}, that can improve storage efficiency and avoid update anomalies, among other things.  In contrast, our work has the goal of restructuring an input table to make it easy to query, which is always \textit{single-table to single-table}, and thus both orthogonal and complementary to schema design (e.g., our transformed table can then be subject to schema-design steps if it needs to be stored in databases). 
%\end{comment}