@inproceedings{neurips2018,
 author = {Blum, Avrim and Gunasekar, Suriya and Lykouris, Thodoris and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {On preserving non-discrimination when combining expert advice},
 url = {https://proceedings.neurips.cc/paper/2018/file/2e855f9489df0712b4bd8ea9e2848c5a-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{chouldechova2017fair,
  title={Fair prediction with disparate impact: A study of bias in recidivism prediction instruments},
  author={Chouldechova, Alexandra},
  journal={Big data},
  volume={5},
  number={2},
  pages={153--163},
  year={2017},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@article{klein16,
  author    = {Jon M. Kleinberg and
               Sendhil Mullainathan and
               Manish Raghavan},
  title     = {Inherent Trade-Offs in the Fair Determination of Risk Scores},
  journal   = {CoRR},
  volume    = {abs/1609.05807},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.05807},
  eprinttype = {arXiv},
  eprint    = {1609.05807},
  timestamp = {Mon, 13 Aug 2018 16:46:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KleinbergMR16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{malnoise,
author = {Kearns, Michael and Li, Ming},
title = {Learning in the Presence of Malicious Errors},
year = {1988},
isbn = {0897912640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/62212.62238},
doi = {10.1145/62212.62238},
booktitle = {Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing},
pages = {267–280},
numpages = {14},
location = {Chicago, Illinois, USA},
series = {STOC '88}
}

@InProceedings{forc2020,
  author =	{Avrim Blum and Kevin Stangl},
  title =	{{Recovering from Biased Data: Can Fairness Constraints Improve Accuracy?}},
  booktitle =	{1st Symposium on Foundations of Responsible Computing (FORC 2020)},
  pages =	{3:1--3:20},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-142-9},
  ISSN =	{1868-8969},
  year =	{2020},
  volume =	{156},
  editor =	{Aaron Roth},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/opus/volltexte/2020/12019},
  URN =		{urn:nbn:de:0030-drops-120192},
  doi =		{10.4230/LIPIcs.FORC.2020.3},
  annote =	{Keywords: fairness in machine learning, equal opportunity, bias, machine learning}
}


@inproceedings{dwork2021outcome,
  title={Outcome indistinguishability},
  author={Dwork, Cynthia and Kim, Michael P and Reingold, Omer and Rothblum, Guy N and Yona, Gal},
  booktitle={Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1095--1108},
  year={2021}
}

@inproceedings{hebert2018multicalibration,
  title={Multicalibration: Calibration for the (computationally-identifiable) masses},
  author={H{\'e}bert-Johnson, Ursula and Kim, Michael and Reingold, Omer and Rothblum, Guy},
  booktitle={International Conference on Machine Learning},
  pages={1939--1948},
  year={2018},
  organization={PMLR}
}

@article{minimaxfair,
  author    = {Emily Diana and
               Wesley Gill and
               Michael Kearns and
               Krishnaram Kenthapadi and
               Aaron Roth},
  title     = {Convergent Algorithms for (Relaxed) Minimax Fairness},
  journal   = {CoRR},
  volume    = {abs/2011.03108},
  year      = {2020},
  url       = {https://arxiv.org/abs/2011.03108},
  eprinttype = {arXiv},
  eprint    = {2011.03108},
  timestamp = {Thu, 12 Nov 2020 15:14:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-03108.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lum2016predict,
  title={To predict and serve?},
  author={Lum, Kristian and Isaac, William},
  journal={Significance},
  volume={13},
  number={5},
  pages={14--19},
  year={2016},
  publisher={Wiley Online Library}
}

@article{schrouff2022maintaining,
  title={Maintaining fairness across distribution shift: do we have viable solutions for real-world applications?},
  author={Schrouff, Jessica and Harris, Natalie and Koyejo, Oluwasanmi and Alabdulmohsin, Ibrahim and Schnider, Eva and Opsahl-Ong, Krista and Brown, Alex and Roy, Subhrajit and Mincu, Diana and Chen, Christina and others},
  journal={arXiv preprint arXiv:2202.01034},
  year={2022}
}

@inproceedings{hardt2016strategic,
  title={Strategic classification},
  author={Hardt, Moritz and Megiddo, Nimrod and Papadimitriou, Christos and Wootters, Mary},
  booktitle={Proceedings of the 2016 ACM conference on innovations in theoretical computer science},
  pages={111--122},
  year={2016}
}

@article{Kozodoi_2022,
	doi = {10.1016/j.ejor.2021.06.023},
	year = {2022},
	month = {mar},
	publisher = {Elsevier {BV}},
	volume = {297},  
	number = {3},
	pages = {1083--1094},
  	author = {Nikita Kozodoi and Johannes Jacob and Stefan Lessmann},
	title = {Fairness in credit scoring: Assessment, implementation and profit implications},
	journal = {European Journal of Operational Research}
}

@article{dieterich2016compas,
  title={COMPAS risk scales: Demonstrating accuracy equity and predictive parity},
  author={Dieterich, William and Mendoza, Christina and Brennan, Tim},
  journal={Northpointe Inc},
  volume={7},
  number={7.4},
  pages={1},
  year={2016}
}

@article{compassgender,
author={Melissa Hamilton},
title={The Sexist Algorithm},
journal={Behavioral Sciences and the Law},
volume={145},
year={2019},
biburl={https://ssrn.com/abstract=3375129}
}

@article{dawid,
  title={The well-calibrated Bayesian},
  author={Dawid, Phillip},
  journal={Journal of the American Statistical Association},
  volume={77},
  number={379},
  pages={605--610},
  year={1982},
  publisher={Taylor \& Francis}
}
@article{faircalib,
  author       = {Geoff Pleiss and
                  Manish Raghavan and
                  Felix Wu and
                  Jon M. Kleinberg and
                  Kilian Q. Weinberger},
  title        = {On Fairness and Calibration},
  journal      = {CoRR},
  volume       = {abs/1709.02012},
  year         = {2017},
  url          = {http://arxiv.org/abs/1709.02012},
  eprinttype    = {arXiv},
  eprint       = {1709.02012},
  timestamp    = {Mon, 13 Aug 2018 16:48:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1709-02012.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{celis2021fair,
  title={Fair classification with adversarial perturbations},
  author={Celis, L Elisa and Mehrotra, Anay and Vishnoi, Nisheeth},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8158--8171},
  year={2021}
}



@article{flores2016false,
  title={False positives, false negatives, and false analyses: A rejoinder to machine bias: There's software used across the country to predict future criminals. and it's biased against blacks},
  author={Flores, Anthony W and Bechtel, Kristin and Lowenkamp, Christopher T},
  journal={Fed. Probation},
  volume={80},
  pages={38},
  year={2016},
  publisher={HeinOnline}
}





@misc{fairprojection,
  doi = {10.48550/ARXIV.2206.07801},
  
  url = {https://arxiv.org/abs/2206.07801},
  
  author = {Alghamdi, Wael and Hsu, Hsiang and Jeong, Haewon and Wang, Hao and Michalak, P. Winston and Asoodeh, Shahab and Calmon, Flavio P.},
  
  keywords = {Machine Learning (cs.LG), Computers and Society (cs.CY), Information Theory (cs.IT), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Beyond Adult and COMPAS: Fairness in Multi-Class Prediction},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{hardt16,
  author    = {Moritz Hardt and
               Eric Price and
               Nathan Srebro},
  title     = {Equality of Opportunity in Supervised Learning},
  journal   = {CoRR},
  volume    = {abs/1610.02413},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.02413},
  eprinttype = {arXiv},
  eprint    = {1610.02413},
  timestamp = {Tue, 26 Apr 2022 09:17:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HardtPS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vapnik2015uniform,
  title={On the uniform convergence of relative frequencies of events to their probabilities},
  author={Vapnik, Vladimir N and Chervonenkis, A Ya},
  journal={Measures of complexity: festschrift for alexey chervonenkis},
  pages={11--30},
  year={2015},
  publisher={Springer}
}

@inproceedings{dwork2012fairness,
  title={Fairness through awareness},
  author={Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  booktitle={Proceedings of the 3rd innovations in theoretical computer science conference},
  pages={214--226},
  year={2012}
}

@article{metricsinpractice,
  author    = {Michael Madaio and
               Lisa Egede and
               Hariharan Subramonyam and
               Jennifer Wortman Vaughan and
               Hanna M. Wallach},
  title     = {Assessing the Fairness of {AI} Systems: {AI} Practitioners' Processes,
               Challenges, and Needs for Support},
  journal   = {CoRR},
  volume    = {abs/2112.05675},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.05675},
  eprinttype = {arXiv},
  eprint    = {2112.05675},
  timestamp = {Tue, 14 Dec 2021 14:21:31 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-05675.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{calders2009building,
  title={Building classifiers with independency constraints},
  author={Calders, Toon and Kamiran, Faisal and Pechenizkiy, Mykola},
  booktitle={2009 IEEE international conference on data mining workshops},
  pages={13--18},
  year={2009},
  organization={IEEE}
}


 @InProceedings{multicalib,
  title = 	 {Multicalibration: Calibration for the ({C}omputationally-Identifiable) Masses},
  author =       {Hebert-Johnson, Ursula and Kim, Michael and Reingold, Omer and Rothblum, Guy},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1939--1948},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/hebert-johnson18a/hebert-johnson18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/hebert-johnson18a.html},
  abstract = 	 {We develop and study multicalibration as a new measure of fairness in machine learning that aims to mitigate inadvertent or malicious discrimination that is introduced at training time (even from ground truth data). Multicalibration guarantees meaningful (calibrated) predictions for every subpopulation that can be identified within a specified class of computations. The specified class can be quite rich; in particular, it can contain many overlapping subgroups of a protected group. We demonstrate that in many settings this strong notion of protection from discrimination is provably attainable and aligned with the goal of obtaining accurate predictions. Along the way, we present algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and illustrate tight connections to the agnostic learning model.}
}

@article{long2011learning,
  title={Learning large-margin halfspaces with more malicious noise},
  author={Long, Phil and Servedio, Rocco},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@inproceedings{awasthi2014power,
  title={The power of localization for efficiently learning linear separators with noise},
  author={Awasthi, Pranjal and Balcan, Maria Florina and Long, Philip M},
  booktitle={Proceedings of the forty-sixth annual ACM symposium on Theory of computing},
  pages={449--458},
  year={2014}
}

@article{auer1998line,
  title={On-line learning with malicious noise and the closure algorithm},
  author={Auer, Peter and Cesa-Bianchi, Nicolo},
  journal={Annals of mathematics and artificial intelligence},
  volume={23},
  pages={83--99},
  year={1998},
  publisher={Springer}
}

@article{servedio2003smooth,
  title={Smooth boosting and learning with malicious noise},
  author={Servedio, Rocco A},
  journal={The Journal of Machine Learning Research},
  volume={4},
  pages={633--648},
  year={2003},
  publisher={JMLR. org}
}

@article{klivans2009learning,
  title={Learning Halfspaces with Malicious Noise.},
  author={Klivans, Adam R and Long, Philip M and Servedio, Rocco A},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={12},
  year={2009}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{gianfrancesco2018potential,
  title={Potential biases in machine learning algorithms using electronic health record data},
  author={Gianfrancesco, Milena A and Tamang, Suzanne and Yazdany, Jinoos and Schmajuk, Gabriela},
  journal={JAMA internal medicine},
  volume={178},
  number={11},
  pages={1544--1547},
  year={2018},
  publisher={American Medical Association}
}

@article{HAUSSLER199278,
title = {Decision theoretic generalizations of the PAC model for neural net and other learning applications},
journal = {Information and Computation},
volume = {100},
number = {1},
pages = {78-150},
year = {1992},
issn = {0890-5401},
doi = {https://doi.org/10.1016/0890-5401(92)90010-D},
url = {https://www.sciencedirect.com/science/article/pii/089054019290010D},
author = {David Haussler},
abstract = {We describe a generalization of the PAC learning model that is based on statistical decision theory. In this model the learner receives randomly drawn examples, each example consisting of an instance x ∈ X and an outcome y ∈ Y, and tries to find a decision rule h: X → A, where h ∈ H, that specifies the appropriate action a ∈ A to take for each instance x in order to minimize the expectation of a loss l(y, a). Here X, Y, and A are arbitrary sets, l is a real-valued function, and examples are generated according to an arbitrary joint distribution on X × Y. Special cases include the problem of learning a function from X into Y, the problem of learning the conditional probability distribution on Y given X (regression), and the problem of learning a distribution on X (density estimation). We give theorems on the uniform convergence of empirical loss estimates to true expected loss rates for certain decision rule spaces H, and show how this implies learnability with bounded sample size, disregarding computational complexity. As an application, we give distribution-independent upper bounds on the sample size needed for learning with feedforward neural networks. Our theorems use a generalized notion of VC dimension that applies to classes of real-valued functions, adapted from Vapnik and Pollard's work, and a notion of capacity and metric dimension for classes of functions that map into a bounded metric space.}
}

@inproceedings{balcan2022robustly,
  title={Robustly-reliable learners under poisoning attacks},
  author={Balcan, Maria-Florina and Blum, Avrim and Hanneke, Steve and Sharma, Dravyansh},
  booktitle={Conference on Learning Theory},
  pages={4498--4534},
  year={2022},
  organization={PMLR}
}

@article{bshouty2002pac,
  title={PAC learning with nasty noise},
  author={Bshouty, Nader H and Eiron, Nadav and Kushilevitz, Eyal},
  journal={Theoretical Computer Science},
  volume={288},
  number={2},
  pages={255--275},
  year={2002},
  publisher={Elsevier}
}

@article{massart2006risk,
  title={Risk bounds for statistical learning},
  author={Massart, Pascal and N{\'e}d{\'e}lec, {\'E}lodie},
  year={2006}
}

@article{diakonikolas2022cryptographic,
  title={Cryptographic hardness of learning halfspaces with massart noise},
  author={Diakonikolas, Ilias and Kane, Daniel and Manurangsi, Pasin and Ren, Lisheng},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3624--3636},
  year={2022}
}

@article{cao2022data,
  title={Data-Efficient Learning via Minimizing Hyperspherical Energy},
  author={Cao, Xiaofeng and Liu, Weiyang and Tsang, Ivor W},
  journal={arXiv preprint arXiv:2206.15204},
  year={2022}
}

@article{lampert,
  publtype={informal},
  author={Nikola Konstantinov and Christoph H. Lampert},
  title={Fairness-Aware Learning from Corrupted Data},
  year={2021},
  cdate={1609459200000},
  journal={CoRR},
  volume={abs/2102.06004},
  url={https://arxiv.org/abs/2102.06004}
}

@article{blum2019recovering,
  title={Recovering from biased data: Can fairness constraints improve accuracy?},
  author={Blum, Avrim and Stangl, Kevin},
  journal={arXiv preprint arXiv:1912.01094},
  year={2019}
}


@inproceedings{kearns1988learning,
  title={Learning in the presence of malicious errors},
  author={Kearns, Michael and Li, Ming},
  booktitle={Proceedings of the twentieth annual ACM symposium on Theory of computing},
  pages={267--280},
  year={1988}
}

@book{becker2010economics,
  title={The economics of discrimination},
  author={Becker, Gary S},
  year={2010},
  publisher={University of Chicago press}
}

@inproceedings{valiant,
author = {Valiant, L. G.},
title = {Learning Disjunction of Conjunctions},
year = {1985},
isbn = {0934613028},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {The question of whether concepts expressible as disjunctions of conjunctions can be learned from examples in polynomial time is investigated. Positive results are shown for significant subclasses that allow not only propositional predicates but also some relations. The algorithms are extended so as to be provably tolerant to a certain quantifiable error rate in the examples data. It is further shown that under certain restrictions on these subclasses the learning algorithms are well suited to implementation on neural networks of threshold elements. The possible importance of disjunctions of conjunctions as a knowledge representation stems from the observations that on the one hand humans appear to like using it andon the other, that there is circumstantial evidence that significantly larger classes may not be learnable in polynomial time. An NP-completeness result corroborating the latter is also presented.},
booktitle = {Proceedings of the 9th International Joint Conference on Artificial Intelligence - Volume 1},
pages = {560–566},
numpages = {7},
location = {Los Angeles, California},
series = {IJCAI'85}
}
