{
  "title": "VPP: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation",
  "authors": [
    "Zekun Qi",
    "Muzhou Yu",
    "Runpei Dong",
    "Kaisheng Ma"
  ],
  "submission_date": "2023-07-28T17:59:10+00:00",
  "revised_dates": [
    "2023-10-20T16:14:12+00:00"
  ],
  "abstract": "Conditional 3D generation is undergoing a significant advancement, enabling the free creation of 3D content from inputs such as text or 2D images. However, previous approaches have suffered from low inference efficiency, limited generation categories, and restricted downstream applications. In this work, we revisit the impact of different 3D representations on generation quality and efficiency. We propose a progressive generation method through Voxel-Point Progressive Representation (VPP). VPP leverages structured voxel representation in the proposed Voxel Semantic Generator and the sparsity of unstructured point representation in the Point Upsampler, enabling efficient generation of multi-category objects. VPP can generate high-quality 8K point clouds within 0.2 seconds. Additionally, the masked generation Transformer allows for various 3D downstream tasks, such as generation, editing, completion, and pre-training. Extensive experiments demonstrate that VPP efficiently generates high-fidelity and diverse 3D shapes across different categories, while also exhibiting excellent representation transfer performance. Codes will be released at \\url{https://github.com/qizekun/VPP}.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16605",
  "pdf_url": "https://arxiv.org/pdf/2307.16605v2",
  "comment": "Accepted at NeurIPS 2023",
  "num_versions": null,
  "size_before_bytes": 14684224,
  "size_after_bytes": 643065
}