\begin{thebibliography}{104}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Armeni et~al.(2016)Armeni, Sener, Zamir, Jiang, Brilakis, Fischer, and Savarese]{S3DIS16}
Iro Armeni, Ozan Sener, Amir~R Zamir, Helen Jiang, Ioannis Brilakis, Martin Fischer, and Silvio Savarese.
\newblock 3d semantic parsing of large-scale indoor spaces.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2016.

\bibitem[Bao et~al.(2022)Bao, Dong, Piao, and Wei]{BEiT}
Hangbo Bao, Li~Dong, Songhao Piao, and Furu Wei.
\newblock Beit: {BERT} pre-training of image transformers.
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}. OpenReview.net, 2022.

\bibitem[Chan et~al.(2022)Chan, Lin, Chan, Nagano, Pan, Mello, Gallo, Guibas, Tremblay, Khamis, Karras, and Wetzstein]{EG3D22}
Eric~R. Chan, Connor~Z. Lin, Matthew~A. Chan, Koki Nagano, Boxiao Pan, Shalini~De Mello, Orazio Gallo, Leonidas~J. Guibas, Jonathan Tremblay, Sameh Khamis, Tero Karras, and Gordon Wetzstein.
\newblock Efficient geometry-aware 3d generative adversarial networks.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Chang et~al.(2015)Chang, Funkhouser, Guibas, Hanrahan, Huang, Li, Savarese, Savva, Song, Su, Xiao, Yi, and Yu]{ShapeNet15}
Angel~X. Chang, Thomas~A. Funkhouser, Leonidas~J. Guibas, Pat Hanrahan, Qi{-}Xing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao, Li~Yi, and Fisher Yu.
\newblock Shapenet: An information-rich 3d model repository.
\newblock \emph{CoRR}, abs/1512.03012, 2015.

\bibitem[Chang et~al.(2022)Chang, Zhang, Jiang, Liu, and Freeman]{MaskGiT22}
Huiwen Chang, Han Zhang, Lu~Jiang, Ce~Liu, and William~T. Freeman.
\newblock Maskgit: Masked generative image transformer.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Chang et~al.(2023)Chang, Zhang, Barber, Maschinot, Lezama, Jiang, Yang, Murphy, Freeman, Rubinstein, Li, and Krishnan]{muse23}
Huiwen Chang, Han Zhang, Jarred Barber, Aaron Maschinot, Jos{\'{e}} Lezama, Lu~Jiang, Ming{-}Hsuan Yang, Kevin Murphy, William~T. Freeman, Michael Rubinstein, Yuanzhen Li, and Dilip Krishnan.
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2023.

\bibitem[Chen et~al.(2019)Chen, Choy, Savva, Chang, Funkhouser, and Savarese]{2019text2shape}
Kevin Chen, Christopher~B Choy, Manolis Savva, Angel~X Chang, Thomas Funkhouser, and Silvio Savarese.
\newblock Text2shape: Generating shapes from natural language by learning joint embeddings.
\newblock In \emph{Asian Conf. Comput. Vis. (ACCV)}, 2019.

\bibitem[Chen et~al.(2023)Chen, Chen, Jiao, and Jia]{Fantasia3D}
Rui Chen, Yongwei Chen, Ningxin Jiao, and Kui Jia.
\newblock Fantasia3d: Disentangling geometry and appearance for high-quality text-to-3d content creation.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2023.

\bibitem[Cheng et~al.(2023)Cheng, Lee, Tulyakov, Schwing, and Gui]{sdfusion22}
Yen{-}Chi Cheng, Hsin{-}Ying Lee, Sergey Tulyakov, Alexander~G. Schwing, and Liangyan Gui.
\newblock Sdfusion: Multimodal 3d shape completion, reconstruction, and generation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Choy et~al.(2016)Choy, Xu, Gwak, Chen, and Savarese]{R2N216}
Christopher~B. Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, and Silvio Savarese.
\newblock 3d-r2n2: {A} unified approach for single and multi-view 3d object reconstruction.
\newblock In \emph{Eur. Conf. Comput. Vis. (ECCV)}, 2016.

\bibitem[Curless \& Levoy(1996)Curless and Levoy]{SDF96}
Brian Curless and Marc Levoy.
\newblock A volumetric method for building complex models from range images.
\newblock In \emph{Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques, {SIGGRAPH} 1996, New Orleans, LA, USA, August 4-9, 1996}, pp.\  303--312. {ACM}, 1996.

\bibitem[Dai et~al.(2017)Dai, Chang, Savva, Halber, Funkhouser, and Nie{\ss}ner]{ScanNet17}
Angela Dai, Angel~X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and Matthias Nie{\ss}ner.
\newblock Scannet: Richly-annotated 3d reconstructions of indoor scenes.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2017.

\bibitem[Deitke et~al.(2023{\natexlab{a}})Deitke, Liu, Wallingford, Ngo, Michel, Kusupati, Fan, Laforte, Voleti, Gadre, VanderBilt, Kembhavi, Vondrick, Gkioxari, Ehsani, Schmidt, and Farhadi]{objaversexl23}
Matt Deitke, Ruoshi Liu, Matthew Wallingford, Huong Ngo, Oscar Michel, Aditya Kusupati, Alan Fan, Christian Laforte, Vikram Voleti, Samir~Yitzhak Gadre, Eli VanderBilt, Aniruddha Kembhavi, Carl Vondrick, Georgia Gkioxari, Kiana Ehsani, Ludwig Schmidt, and Ali Farhadi.
\newblock Objaverse-xl: {A} universe of 10m+ 3d objects.
\newblock \emph{CoRR}, abs/2307.05663, 2023{\natexlab{a}}.

\bibitem[Deitke et~al.(2023{\natexlab{b}})Deitke, Schwenk, Salvador, Weihs, Michel, VanderBilt, Schmidt, Ehsani, Kembhavi, and Farhadi]{objaverse23}
Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali Farhadi.
\newblock Objaverse: A universe of annotated 3d objects.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023{\natexlab{b}}.

\bibitem[Deng et~al.(2021)Deng, Shi, Li, Zhou, Zhang, and Li]{voxelrcnn21}
Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and Houqiang Li.
\newblock Voxel r-cnn: Towards high performance voxel-based 3d object detection.
\newblock In \emph{AAAI Conf. Artif. Intell. (AAAI)}, 2021.

\bibitem[Ding et~al.(2023)Ding, Yang, Xue, Zhang, Bai, and Qi]{PLA23}
Runyu Ding, Jihan Yang, Chuhui Xue, Wenqing Zhang, Song Bai, and Xiaojuan Qi.
\newblock Language-driven open-vocabulary 3d scene understanding.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Dong et~al.(2022)Dong, Tan, Wu, Zhang, and Ma]{DGMS22}
Runpei Dong, Zhanhong Tan, Mengdi Wu, Linfeng Zhang, and Kaisheng Ma.
\newblock Finding the task-optimal low-bit sub-distribution in deep neural networks.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2022.

\bibitem[Dong et~al.(2023{\natexlab{a}})Dong, Han, Peng, Qi, Ge, Yang, Zhao, Sun, Zhou, Wei, Kong, Zhang, Ma, and Yi]{dreamllm23}
Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, Jinrong Yang, Liang Zhao, Jianjian Sun, Hongyu Zhou, Haoran Wei, Xiangwen Kong, Xiangyu Zhang, Kaisheng Ma, and Li~Yi.
\newblock Dreamllm: Synergistic multimodal comprehension and creation.
\newblock \emph{CoRR}, abs/2309.11499, 2023{\natexlab{a}}.

\bibitem[Dong et~al.(2023{\natexlab{b}})Dong, Qi, Zhang, Zhang, Sun, Ge, Yi, and Ma]{ACT23}
Runpei Dong, Zekun Qi, Linfeng Zhang, Junbo Zhang, Jianjian Sun, Zheng Ge, Li~Yi, and Kaisheng Ma.
\newblock Autoencoders as cross-modal teachers: Can pretrained 2d image transformers help 3d representation learning?
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}, 2023{\natexlab{b}}.

\bibitem[Engel et~al.(2021)Engel, Belagiannis, and Dietmayer]{PointTrans21}
Nico Engel, Vasileios Belagiannis, and Klaus Dietmayer.
\newblock Point transformer.
\newblock \emph{{IEEE} Access}, 9:\penalty0 134826--134840, 2021.

\bibitem[Esser et~al.(2021)Esser, Rombach, and Ommer]{vqgan21}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2021.

\bibitem[Fan et~al.(2023)Fan, Qi, Shi, and Ma]{PointGCC23}
Guofan Fan, Zekun Qi, Wenkai Shi, and Kaisheng Ma.
\newblock Point-gcc: Universal self-supervised 3d scene pre-training via geometry-color contrast.
\newblock \emph{CoRR}, abs/2305.19623, 2023.

\bibitem[Fan et~al.(2017)Fan, Su, and Guibas]{ChamferDistance17}
Haoqiang Fan, Hao Su, and Leonidas~J. Guibas.
\newblock A point set generation network for 3d object reconstruction from a single image.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2017.

\bibitem[Fu et~al.(2022)Fu, Zhan, Chen, Ritchie, and Sridhar]{2022shapecrafter}
Rao Fu, Xiao Zhan, Yiwen Chen, Daniel Ritchie, and Srinath Sridhar.
\newblock Shapecrafter: {A} recursive text-conditioned 3d shape generation model.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2022.

\bibitem[Gao et~al.(2022)Gao, Shen, Wang, Chen, Yin, Li, Litany, Gojcic, and Fidler]{get3d22}
Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li, Or~Litany, Zan Gojcic, and Sanja Fidler.
\newblock Get3d: A generative model of high quality 3d textured shapes learned from images.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2022.

\bibitem[Graves(2011)]{PracticalELBO11}
Alex Graves.
\newblock Practical variational inference for neural networks.
\newblock In John Shawe{-}Taylor, Richard~S. Zemel, Peter~L. Bartlett, Fernando C.~N. Pereira, and Kilian~Q. Weinberger (eds.), \emph{Adv. Neural Inform. Process. Syst. (NIPS)}, 2011.

\bibitem[Guo et~al.(2021)Guo, Cai, Liu, Mu, Martin, and Hu]{PCT}
Meng{-}Hao Guo, Junxiong Cai, Zheng{-}Ning Liu, Tai{-}Jiang Mu, Ralph~R. Martin, and Shi{-}Min Hu.
\newblock {PCT:} point cloud transformer.
\newblock \emph{Comput. Vis. Media}, 7\penalty0 (2):\penalty0 187--199, 2021.

\bibitem[Gupta et~al.(2023)Gupta, Xiong, Nie, Jones, and Oguz]{3dgen23}
Anchit Gupta, Wenhan Xiong, Yixin Nie, Ian Jones, and Barlas Oguz.
\newblock 3dgen: Triplane latent diffusion for textured mesh generation.
\newblock \emph{CoRR}, abs/2303.05371, 2023.

\bibitem[Hamdi et~al.(2021)Hamdi, Giancola, and Ghanem]{MVTN}
Abdullah Hamdi, Silvio Giancola, and Bernard Ghanem.
\newblock {MVTN:} multi-view transformation network for 3d shape recognition.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2021.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'{a}}r, and Girshick]{MAE}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'{a}}r, and Ross~B. Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{FID17}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NIPS)}, 2017.

\bibitem[Hinton \& van Camp(1993)Hinton and van Camp]{ELBO93}
Geoffrey~E. Hinton and Drew van Camp.
\newblock Keeping the neural networks simple by minimizing the description length of the weights.
\newblock In \emph{ACM Conf. Comput. Learn. Theory (COLT)}, 1993.

\bibitem[Ho \& Salimans(2021)Ho and Salimans]{cfg}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock In \emph{NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications}, 2021.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{denoising20}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2020.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{seresnet}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2018.

\bibitem[Hughes et~al.(2021)Hughes, Zhu, and Bednarz]{2021generative}
Rowan~T Hughes, Liming Zhu, and Tomasz Bednarz.
\newblock Generative adversarial networks--enabled human--artificial intelligence collaborative applications for creative and design industries: A systematic review of current approaches and trends.
\newblock \emph{Frontiers in artificial intelligence}, 4:\penalty0 604234, 2021.

\bibitem[Jain et~al.(2022)Jain, Mildenhall, Barron, Abbeel, and Poole]{dreamfields22}
Ajay Jain, Ben Mildenhall, Jonathan~T Barron, Pieter Abbeel, and Ben Poole.
\newblock Zero-shot text-guided object generation with dream fields.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Jun \& Nichol(2023)Jun and Nichol]{shapee23}
Heewoo Jun and Alex Nichol.
\newblock Shap-e: Generating conditional 3d implicit functions.
\newblock \emph{CoRR}, abs/2305.02463, 2023.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{VAE14}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}, 2014.

\bibitem[Lewiner et~al.(2003)Lewiner, Lopes, Vieira, and Tavares]{Lewiner03}
Thomas Lewiner, H{\'e}lio Lopes, Ant{\^o}nio~Wilson Vieira, and Geovan Tavares.
\newblock Efficient implementation of marching cubes' cases with topological guarantees.
\newblock \emph{Journal of graphics tools}, 8\penalty0 (2):\penalty0 1--15, 2003.

\bibitem[Li et~al.(2022)Li, Li, Xiong, and Hoi]{blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven C.~H. Hoi.
\newblock {BLIP:} bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2022.

\bibitem[Li et~al.(2023)Li, Chang, Mishra, Zhang, Katabi, and Krishnan]{mage23}
Tianhong Li, Huiwen Chang, Shlok Mishra, Han Zhang, Dina Katabi, and Dilip Krishnan.
\newblock Mage: Masked generative encoder to unify representation learning and image synthesis.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Li et~al.(2018)Li, Bu, Sun, Wu, Di, and Chen]{PointCNN}
Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di, and Baoquan Chen.
\newblock Pointcnn: Convolution on x-transformed points.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2018.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Cai, and Lee]{MaskPoint}
Haotian Liu, Mu~Cai, and Yong~Jae Lee.
\newblock Masked discrimination for self-supervised learning on point clouds.
\newblock In \emph{Eur. Conf. Comput. Vis. (ECCV)}, 2022{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Xu, Jin, Chen, T, Xu, and Su]{one2345}
Minghua Liu, Chao Xu, Haian Jin, Linghao Chen, Mukund~Varma T, Zexiang Xu, and Hao Su.
\newblock One-2-3-45: Any single image to 3d mesh in 45 seconds without per-shape optimization.
\newblock \emph{CoRR}, abs/2306.16928, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Wu, Hoorick, Tokmakov, Zakharov, and Vondrick]{zero123}
Ruoshi Liu, Rundi Wu, Basile~Van Hoorick, Pavel Tokmakov, Sergey Zakharov, and Carl Vondrick.
\newblock Zero-1-to-3: Zero-shot one image to 3d object.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Qiao, and Chilton]{2022opal}
Vivian Liu, Han Qiao, and Lydia Chilton.
\newblock Opal: Multimodal image generation for news illustration.
\newblock In \emph{Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology}, pp.\  1--17, 2022{\natexlab{b}}.

\bibitem[Liu et~al.(2022{\natexlab{c}})Liu, Vermeulen, Fitzmaurice, and Matejka]{20223dall}
Vivian Liu, Jo~Vermeulen, George~W. Fitzmaurice, and Justin Matejka.
\newblock 3dall-e: Integrating text-to-image {AI} in 3d design workflows.
\newblock \emph{CoRR}, abs/2210.11603, 2022{\natexlab{c}}.

\bibitem[Liu et~al.(2021)Liu, Zhang, Cao, Hu, and Tong]{groupfree21}
Ze~Liu, Zheng Zhang, Yue Cao, Han Hu, and Xin Tong.
\newblock Group-free 3d object detection via transformers.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2021.

\bibitem[Liu et~al.(2022{\natexlab{d}})Liu, Wang, Qi, and Fu]{2022towards}
Zhengzhe Liu, Yi~Wang, Xiaojuan Qi, and Chi-Wing Fu.
\newblock Towards implicit text-guided 3d shape generation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022{\natexlab{d}}.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Dai, Li, Qi, and Fu]{iss22}
Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, and Chi-Wing Fu.
\newblock Iss: Image as stetting stone for text-guided 3d shape generation.
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}, 2023{\natexlab{c}}.

\bibitem[Lyu et~al.(2023)Lyu, Wang, An, Zhang, Lin, and Dai]{slide23}
Zhaoyang Lyu, Jinyi Wang, Yuwei An, Ya~Zhang, Dahua Lin, and Bo~Dai.
\newblock Controllable mesh generation through sparse latent point diffusion models.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Ma et~al.(2022)Ma, Qin, You, Ran, and Fu]{PointMLP}
Xu~Ma, Can Qin, Haoxuan You, Haoxi Ran, and Yun Fu.
\newblock Rethinking network design and local geometry in point cloud: {A} simple residual {MLP} framework.
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}, 2022.

\bibitem[Mao et~al.(2021)Mao, Xue, Niu, Bai, Feng, Liang, Xu, and Xu]{voxeltransformer21}
Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu.
\newblock Voxel transformer for 3d object detection.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2021.

\bibitem[Maturana \& Scherer(2015)Maturana and Scherer]{voxelnet15}
Daniel Maturana and Sebastian~A. Scherer.
\newblock Voxnet: {A} 3d convolutional neural network for real-time object recognition.
\newblock In \emph{IEEE/RSJ Int. Conf. Intell. Robot. and Syst. (IROS)}, 2015.

\bibitem[Mildenhall et~al.(2021)Mildenhall, Srinivasan, Tancik, Barron, Ramamoorthi, and Ng]{nerf21}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view synthesis.
\newblock \emph{Communications of the ACM}, 65\penalty0 (1):\penalty0 99--106, 2021.

\bibitem[Mittal et~al.(2022)Mittal, Cheng, Singh, and Tulsiani]{2022autosdf}
Paritosh Mittal, Yen-Chi Cheng, Maneesh Singh, and Shubham Tulsiani.
\newblock Autosdf: Shape priors for 3d completion, reconstruction and generation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Mohammad~Khalid et~al.(2022)Mohammad~Khalid, Xie, Belilovsky, and Popa]{2022clipmesh}
Nasir Mohammad~Khalid, Tianhao Xie, Eugene Belilovsky, and Tiberiu Popa.
\newblock Clip-mesh: Generating textured meshes from text using pretrained image-text models.
\newblock In \emph{SIGGRAPH Asia 2022 Conference Papers}, pp.\  1--8, 2022.

\bibitem[Nichol et~al.(2022)Nichol, Jun, Dhariwal, Mishkin, and Chen]{pointe22}
Alex Nichol, Heewoo Jun, Prafulla Dhariwal, Pamela Mishkin, and Mark Chen.
\newblock Point-e: {A} system for generating 3d point clouds from complex prompts.
\newblock \emph{CoRR}, abs/2212.08751, 2022.

\bibitem[Pang et~al.(2022)Pang, Wang, Tay, Liu, Tian, and Yuan]{PointMAE}
Yatian Pang, Wenxiao Wang, Francis E.~H. Tay, Wei Liu, Yonghong Tian, and Li~Yuan.
\newblock Masked autoencoders for point cloud self-supervised learning.
\newblock In \emph{Eur. Conf. Comput. Vis. (ECCV)}, 2022.

\bibitem[Park et~al.(2019)Park, Florence, Straub, Newcombe, and Lovegrove]{DeepSDF19}
Jeong~Joon Park, Peter~R. Florence, Julian Straub, Richard~A. Newcombe, and Steven Lovegrove.
\newblock Deepsdf: Learning continuous signed distance functions for shape representation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2019.

\bibitem[Patashnik et~al.(2021)Patashnik, Wu, Shechtman, Cohen-Or, and Lischinski]{2021styleclip}
Or~Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski.
\newblock Styleclip: Text-driven manipulation of stylegan imagery.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2021.

\bibitem[Peng et~al.(2021)Peng, Jiang, Liao, Niemeyer, Pollefeys, and Geiger]{sap21}
Songyou Peng, Chiyu Jiang, Yiyi Liao, Michael Niemeyer, Marc Pollefeys, and Andreas Geiger.
\newblock Shape as points: A differentiable poisson solver.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2021.

\bibitem[Peng et~al.(2023)Peng, Genova, Jiang, Tagliasacchi, Pollefeys, and Funkhouser]{OpenScene23}
Songyou Peng, Kyle Genova, Chiyu~"Max" Jiang, Andrea Tagliasacchi, Marc Pollefeys, and Thomas~A. Funkhouser.
\newblock Openscene: 3d scene understanding with open vocabularies.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Poole et~al.(2023)Poole, Jain, Barron, and Mildenhall]{dreamfusion22}
Ben Poole, Ajay Jain, Jonathan~T. Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}, 2023.

\bibitem[Qi et~al.(2017{\natexlab{a}})Qi, Su, Mo, and Guibas]{PointNet}
Charles~Ruizhongtai Qi, Hao Su, Kaichun Mo, and Leonidas~J. Guibas.
\newblock Pointnet: Deep learning on point sets for 3d classification and segmentation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2017{\natexlab{a}}.

\bibitem[Qi et~al.(2017{\natexlab{b}})Qi, Yi, Su, and Guibas]{PointNet++}
Charles~Ruizhongtai Qi, Li~Yi, Hao Su, and Leonidas~J. Guibas.
\newblock Pointnet++: Deep hierarchical feature learning on point sets in a metric space.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NIPS)}, 2017{\natexlab{b}}.

\bibitem[Qi et~al.(2023)Qi, Dong, Fan, Ge, Zhang, Ma, and Yi]{recon23}
Zekun Qi, Runpei Dong, Guofan Fan, Zheng Ge, Xiangyu Zhang, Kaisheng Ma, and Li~Yi.
\newblock Contrast with reconstruct: Contrastive 3d representation learning guided by generative pretraining.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2023.

\bibitem[Qian et~al.(2022)Qian, Li, Peng, Mai, Hammoud, Elhoseiny, and Ghanem]{PointNext}
Guocheng Qian, Yuchen Li, Houwen Peng, Jinjie Mai, Hasan Abed Al~Kader Hammoud, Mohamed Elhoseiny, and Bernard Ghanem.
\newblock Pointnext: Revisiting pointnet++ with improved training and scaling strategies.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{CLIP}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2021.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{DALL-E}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with {CLIP} latents.
\newblock \emph{CoRR}, abs/2204.06125, 2022.

\bibitem[Rissanen(1978)]{MDL78}
Jorma Rissanen.
\newblock Modeling by shortest data description.
\newblock \emph{Autom.}, 14\penalty0 (5):\penalty0 465--471, 1978.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{StableDiffusion22}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"{o}}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford, and Chen]{ISS16}
Tim Salimans, Ian~J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi~Chen.
\newblock Improved techniques for training gans.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NIPS)}, 2016.

\bibitem[Sanghi et~al.(2022)Sanghi, Chu, Lambourne, Wang, Cheng, Fumero, and Malekshan]{clipforge22}
Aditya Sanghi, Hang Chu, Joseph~G Lambourne, Ye~Wang, Chin-Yi Cheng, Marco Fumero, and Kamal~Rahimi Malekshan.
\newblock Clip-forge: Towards zero-shot text-to-shape generation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Sanghi et~al.(2023)Sanghi, Fu, Liu, Willis, Shayani, Khasahmadi, Sridhar, and Ritchie]{clipsculptor23}
Aditya Sanghi, Rao Fu, Vivian Liu, Karl Willis, Hooman Shayani, Amir~Hosein Khasahmadi, Srinath Sridhar, and Daniel Ritchie.
\newblock Clip-sculptor: Zero-shot generation of high-fidelity and diverse shapes from natural language.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Schuhmann et~al.(2021)Schuhmann, Vencu, Beaumont, Kaczmarczyk, Mullis, Katta, Coombes, Jitsev, and Komatsuzaki]{2021laion}
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki.
\newblock {LAION-400M:} open dataset of clip-filtered 400 million image-text pairs.
\newblock \emph{CoRR}, abs/2111.02114, 2021.

\bibitem[Shen et~al.(2021)Shen, Gao, Yin, Liu, and Fidler]{dmtet}
Tianchang Shen, Jun Gao, Kangxue Yin, Ming{-}Yu Liu, and Sanja Fidler.
\newblock Deep marching tetrahedra: a hybrid representation for high-resolution 3d shape synthesis.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2021.

\bibitem[Shue et~al.(2023)Shue, Chan, Po, Ankner, Wu, and Wetzstein]{TriplaneDiffusion22}
J.~Ryan Shue, Eric~Ryan Chan, Ryan Po, Zachary Ankner, Jiajun Wu, and Gordon Wetzstein.
\newblock 3d neural field generation using triplane diffusion.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Su et~al.(2015)Su, Maji, Kalogerakis, and Learned{-}Miller]{mvcnn15}
Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik~G. Learned{-}Miller.
\newblock Multi-view convolutional neural networks for 3d shape recognition.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2015.

\bibitem[Tang et~al.(2023)Tang, Wang, Zhang, Zhang, Yi, Ma, and Chen]{MakeIt3D23}
Junshu Tang, Tengfei Wang, Bo~Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, and Dong Chen.
\newblock Make-it-3d: High-fidelity 3d creation from {A} single image with diffusion prior.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2023.

\bibitem[Uy et~al.(2019)Uy, Pham, Hua, Nguyen, and Yeung]{ScanObjectNN19}
Mikaela~Angelina Uy, Quang-Hieu Pham, Binh-Son Hua, Thanh Nguyen, and Sai-Kit Yeung.
\newblock Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{AttentionIsAllYouNeed}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NIPS)}, 2017.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, and Manzagol]{DAE}
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre{-}Antoine Manzagol.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{Int. Conf. Mach. Learn. (ICML)}, 2008.

\bibitem[Wang et~al.(2021)Wang, Liu, Yue, Lasenby, and Kusner]{occo}
Hanchen Wang, Qi~Liu, Xiangyu Yue, Joan Lasenby, and Matt~J Kusner.
\newblock Unsupervised point cloud pre-training via occlusion completion.
\newblock In \emph{Int. Conf. Comput. Vis. (ICCV)}, 2021.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Du, Li, Yeh, and Shakhnarovich]{sjc22}
Haochen Wang, Xiaodan Du, Jiahao Li, Raymond~A. Yeh, and Greg Shakhnarovich.
\newblock Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2018)Wang, Zhang, Li, Fu, Liu, and Jiang]{Pixel2Mesh}
Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu{-}Gang Jiang.
\newblock Pixel2mesh: Generating 3d mesh models from single {RGB} images.
\newblock In \emph{Eur. Conf. Comput. Vis. (ECCV)}, 2018.

\bibitem[Wang et~al.(2019)Wang, Sun, Liu, Sarma, Bronstein, and Solomon]{DGCNN}
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay~E. Sarma, Michael~M. Bronstein, and Justin~M. Solomon.
\newblock Dynamic graph {CNN} for learning on point clouds.
\newblock \emph{ACM Trans. Graph.}, 38\penalty0 (5):\penalty0 146:1--146:12, 2019.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Lu, Wang, Bao, Li, Su, and Zhu]{ProlificDreamer23}
Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu.
\newblock Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2023{\natexlab{b}}.

\bibitem[Wei et~al.(2022)Wei, Xie, Zhou, Li, and Tian]{MVP22}
Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, and Qi~Tian.
\newblock {MVP:} multimodality-guided visual pre-training.
\newblock In \emph{Eur. Conf. Comput. Vis. (ECCV)}, 2022.

\bibitem[Wu et~al.(2015)Wu, Song, Khosla, Yu, Zhang, Tang, and Xiao]{ModelNet15}
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao.
\newblock 3d shapenets: A deep representation for volumetric shapes.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2015.

\bibitem[Xie et~al.(2020)Xie, Gu, Guo, Qi, Guibas, and Litany]{PointContrast20}
Saining Xie, Jiatao Gu, Demi Guo, Charles~R. Qi, Leonidas~J. Guibas, and Or~Litany.
\newblock Pointcontrast: Unsupervised pre-training for 3d point cloud understanding.
\newblock In \emph{Eur. Conf. Comput. Vis. (ECCV)}, 2020.

\bibitem[Xu et~al.(2023)Xu, Wang, Cheng, Cao, Shan, Qie, and Gao]{dream3d22}
Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, and Shenghua Gao.
\newblock Dream3d: Zero-shot text-to-3d synthesis using 3d shape prior and text-to-image diffusion models.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Xue et~al.(2023)Xue, Gao, Xing, Mart{\'{\i}}n{-}Mart{\'{\i}}n, Wu, Xiong, Xu, Niebles, and Savarese]{ULIP22}
Le~Xue, Mingfei Gao, Chen Xing, Roberto Mart{\'{\i}}n{-}Mart{\'{\i}}n, Jiajun Wu, Caiming Xiong, Ran Xu, Juan~Carlos Niebles, and Silvio Savarese.
\newblock {ULIP:} learning unified representation of language, image and point cloud for 3d understanding.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023.

\bibitem[Yi et~al.(2016)Yi, Kim, Ceylan, Shen, Yan, Su, Lu, Huang, Sheffer, and Guibas]{ShapeNetPart16}
Li~Yi, Vladimir~G Kim, Duygu Ceylan, I-Chao Shen, Mengyan Yan, Hao Su, Cewu Lu, Qixing Huang, Alla Sheffer, and Leonidas Guibas.
\newblock A scalable active framework for region annotation in 3d shape collections.
\newblock \emph{ACM Trans. Graph.}, 35\penalty0 (6):\penalty0 1--12, 2016.

\bibitem[Yi et~al.(2017)Yi, Su, Guo, and Guibas]{SyncSpecCNN17}
Li~Yi, Hao Su, Xingwen Guo, and Leonidas~J. Guibas.
\newblock Syncspeccnn: Synchronized spectral {CNN} for 3d shape segmentation.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2017.

\bibitem[Yu et~al.(2022)Yu, Tang, Rao, Huang, Zhou, and Lu]{PointBERT}
Xumin Yu, Lulu Tang, Yongming Rao, Tiejun Huang, Jie Zhou, and Jiwen Lu.
\newblock Point-bert: Pre-training 3d point cloud transformers with masked point modeling.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2022.

\bibitem[Zeng et~al.(2022)Zeng, Vahdat, Williams, Gojcic, Litany, Fidler, and Kreis]{lion22}
Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Gojcic, Or~Litany, Sanja Fidler, and Karsten Kreis.
\newblock {LION:} latent point diffusion models for 3d shape generation.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2022.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Dong, and Ma]{CLIPFO3D23}
Junbo Zhang, Runpei Dong, and Kaisheng Ma.
\newblock Clip-fo3d: Learning free open-world 3d scene representations from 2d dense clip.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops}, pp.\  2048--2059, October 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Fan, Wang, Su, Ma, and Yi]{LAS3D23}
Junbo Zhang, Guofan Fan, Guanghan Wang, Zhengyuan Su, Kaisheng Ma, and Li~Yi.
\newblock Language-assisted 3d feature learning for semantic scene understanding.
\newblock In \emph{AAAI Conf. Artif. Intell. (AAAI)}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2022)Zhang, Guo, Gao, Fang, Zhao, Wang, Qiao, and Li]{PointM2AE22}
Renrui Zhang, Ziyu Guo, Peng Gao, Rongyao Fang, Bin Zhao, Dong Wang, Yu~Qiao, and Hongsheng Li.
\newblock Point-m2{AE}: Multi-scale masked autoencoders for hierarchical point cloud pre-training.
\newblock In \emph{Adv. Neural Inform. Process. Syst. (NeurIPS)}, 2022.

\bibitem[Zhang et~al.(2023{\natexlab{c}})Zhang, Wang, Qiao, Gao, and Li]{i2pmae23}
Renrui Zhang, Liuhui Wang, Yu~Qiao, Peng Gao, and Hongsheng Li.
\newblock Learning 3d representations from 2d pre-trained models via image-to-point masked autoencoders.
\newblock In \emph{IEEE/CVF Conf. Comput. Vis. Pattern Recog. (CVPR)}, 2023{\natexlab{c}}.

\bibitem[Zhou et~al.(2022)Zhou, Wei, Wang, Shen, Xie, Yuille, and Kong]{iBoT}
Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan~L. Yuille, and Tao Kong.
\newblock ibot: Image {BERT} pre-training with online tokenizer.
\newblock In \emph{Int. Conf. Learn. Represent. (ICLR)}, 2022.

\end{thebibliography}
