\section{Conclusion}
\label{chapter:Conclusion}

%In this work, 
We have proposed a new adaptive layerwise clipping method as well as a new batch clipping method for DPSGD. Our experiments show that DPSGD with BC and new ALC  can achieve faster convergence and  higher accuracy compared to DPSGD with IC. We have provided rigorous DP proofs for ALC and BC.

Our experiments are for small $\sigma$ which leads to weak differential privacy. We still need additional techniques beyond (optimizing) ALC and BC for training a deep neural network like resnet-18 with CIFAR10  in order to achieve a practical balance between test accuracy and DP guarantee. 

%We believe that our new methods significantly reduce  the gap between DPSGD and mini-batch SGD for deep neural networks. 