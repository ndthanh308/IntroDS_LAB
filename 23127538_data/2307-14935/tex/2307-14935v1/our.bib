@INPROCEEDINGS{1617373,

  author={Chaudhuri, S. and Ganti, V. and Kaushik, R.},

  booktitle={22nd International Conference on Data Engineering (ICDE'06)}, 

  title={A Primitive Operator for Similarity Joins in Data Cleaning}, 

  year={2006},

  volume={},

  number={},

  pages={5-5},

  doi={10.1109/ICDE.2006.9}}

  

@article{DBLP:journals/datamine/HernandezS98,
  author    = {Mauricio A. Hern{\'{a}}ndez and
               Salvatore J. Stolfo},
  title     = {Real-world Data is Dirty: Data Cleansing and The Merge/Purge Problem},
  journal   = {Data Min. Knowl. Discov.},
  volume    = {2},
  number    = {1},
  pages     = {9--37},
  year      = {1998},
  url       = {https://doi.org/10.1023/A:1009761603038},
  doi       = {10.1023/A:1009761603038},
  timestamp = {Sat, 20 May 2017 00:25:07 +0200},
  biburl    = {https://dblp.org/rec/journals/datamine/HernandezS98.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{DBLP:journals/corr/abs-2301-05965,
  author    = {George A. Chernishev and
               Michael Polyntsov and
               Anton Chizhov and
               Kirill Stupakov and
               Ilya Shchuckin and
               Alexander Smirnov and
               Maxim Strutovsky and
               Alexey Shlyonskikh and
               Mikhail Firsov and
               Stepan Manannikov and
               Nikita Bobrov and
               Daniil Goncharov and
               Ilia Barutkin and
               Vladislav Shalnev and
               Kirill Muraviev and
               Anna Rakhmukova and
               Dmitriy Shcheka and
               Anton Chernikov and
               Dmitrii Mandelshtam and
               Mikhail Vyrodov and
               Arthur Saliou and
               Eduard Gaisin and
               Kirill Smirnov},
  title     = {Desbordante: from benchmarking suite to high-performance science-intensive
               data profiler (preprint)},
  journal   = {CoRR},
  volume    = {abs/2301.05965},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2301.05965},
  doi       = {10.48550/arXiv.2301.05965},
  eprinttype = {arXiv},
  eprint    = {2301.05965},
  timestamp = {Thu, 19 Jan 2023 15:40:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2301-05965.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{MFD,
author = {Koudas, Nick and Saha, Avishek and Srivastava, Divesh and Venkatasubramanian, Suresh},
year = {2009},
month = {03},
pages = {1275-1278},
title = {Metric Functional Dependencies},
doi = {10.1109/ICDE.2009.219}
}

@misc{pybind11,
   author = {Wenzel Jakob and Jason Rhinelander and Dean Moldovan},
   year = {2017},
   note = {https://github.com/pybind/pybind11},
   title = {pybind11 -- Seamless operability between C++11 and Python}
}

@INPROCEEDINGS{9435469,
  author={Strutovskiy, Maxim and Bobrov, Nikita and Smirnov, Kirill and Chernishev, George},
  booktitle={2021 29th Conference of Open Innovations Association (FRUCT)}, 
  title={Desbordante: a Framework for Exploring Limits of Dependency Discovery Algorithms}, 
  year={2021},
  volume={},
  number={},
  pages={344--354},
  doi={10.23919/FRUCT52173.2021.9435469}
}

@article{10.14778/3192965.3192968,
author = {Kruse, Sebastian and Naumann, Felix},
title = {Efficient Discovery of Approximate Dependencies},
year = {2018},
issue_date = {March 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/3192965.3192968},
doi = {10.14778/3192965.3192968},
abstract = {Functional dependencies (FDs) and unique column combinations (UCCs) form a valuable ingredient for many data management tasks, such as data cleaning, schema recovery, and query optimization. Because these dependencies are unknown in most scenarios, their automatic discovery has been well researched. However, existing methods mostly discover only exact dependencies, i.e., those without violations. Real-world dependencies, in contrast, are frequently approximate due to data exceptions, ambiguities, or data errors. This relaxation to approximate dependencies renders their discovery an even harder task than the already challenging exact dependency discovery. To this end, we propose the novel and highly efficient algorithm Pyro to discover both approximate FDs and approximate UCCs. Pyro combines a separate-and-conquer search strategy with sampling-based guidance that quickly detects dependency candidates and verifies them. In our broad experimental evaluation, Pyro outperforms existing discovery algorithms by a factor of up to 33, scales to larger datasets, and at the same time requires the least main memory.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {759–772},
numpages = {14}
}

@article{10.14778/2824032.2824086,
author = {Papenbrock, Thorsten and Bergmann, Tanja and Finke, Moritz and Zwiener, Jakob and Naumann, Felix},
title = {Data Profiling with {M}etanome},
year = {2015},
issue_date = {August 2015},
publisher = {VLDB Endowment},
volume = {8},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2824032.2824086},
doi = {10.14778/2824032.2824086},
abstract = {Data profiling is the discipline of discovering metadata about given datasets. The metadata itself serve a variety of use cases, such as data integration, data cleansing, or query optimization. Due to the importance of data profiling in practice, many tools have emerged that support data scientists and IT professionals in this task. These tools provide good support for profiling statistics that are easy to compute, but they are usually lacking automatic and efficient discovery of complex statistics, such as inclusion dependencies, unique column combinations, or functional dependencies.We present Metanome, an extensible profiling platform that incorporates many state-of-the-art profiling algorithms. While Metanome is able to calculate simple profiling statistics in relational data, its focus lies on the automatic discovery of complex metadata. Metanome's goal is to provide novel profiling algorithms from research, perform comparative evaluations, and to support developers in building and testing new algorithms. In addition, Metanome is able to rank profiling results according to various metrics and to visualize the, at times, large metadata sets.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {1860–1863},
numpages = {4}
}

@article{10.14778/3476311.3476339,
author = {M\"{u}ller, Heiko and Castelo, Sonia and Qazi, Munaf and Freire, Juliana},
title = {From Papers to Practice: The Openclean Open-Source Data Cleaning Library},
year = {2021},
issue_date = {July 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3476311.3476339},
doi = {10.14778/3476311.3476339},
abstract = {Data preparation is still a major bottleneck for many data science projects. Even though many sophisticated algorithms and tools have been proposed in the research literature, it is difficult for practitioners to integrate them into their data wrangling efforts. We present openclean, a open-source Python library for data cleaning and profiling, openclean integrates data profiling and cleaning tools in a single environment that is easy and intuitive to use. We designed openclean to be extensible and make it easy to add new functionality. By doing so, it will not only become easier for users to access state-of-the-art algorithms for their data wrangling efforts, but also allow researchers to integrate their work and evaluate its effectiveness in practice. We envision openclean as a first step to build a community of practitioners and researchers in the field. In our demo, we outline the main components and design decisions in the development of openclean and demonstrate the current functionality of the library on real-world use cases.},
journal = {Proc. VLDB Endow.},
month = {oct},
pages = {2763–2766},
numpages = {4}
}