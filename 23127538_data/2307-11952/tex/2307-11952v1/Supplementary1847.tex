% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
% \documentclass[runningheads]{llncs}
% %
% \usepackage[T1]{fontenc}
% % T1 fonts will be used to generate the final print and online PDFs,
% % so please use T1 fonts in your manuscript whenever possible.
% % Other font encondings may result in incorrect characters.
% %
% \usepackage{graphicx}


% \usepackage{color}

% \usepackage{algorithmicx}
% \usepackage{algorithm, algpseudocode}
% \usepackage{amsmath}
% \usepackage{amsfonts}
% \usepackage{amssymb}
% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}
% \usepackage{makecell}
% \usepackage{hyperref}
% \usepackage{multirow}
% \usepackage{mathrsfs}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
% \begin{document}
%
\title{Appendix}
% \thanks{This study has been partially supported by fund of STCSM (19511121400)}}

%\title{Feature-enhanced Graph Networks for Genetic Mutational Prediction Using Histopathological Images in Colon cancer}
%
% \titlerunning{Scaling Nuclei Segmentation via Large-scale Synthetic Pathological Images}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%

\author{Kexin Ding\inst{1}\and Mu Zhou\inst{2}\and Dimitris N. Metaxas\inst{2}\and Shaoting Zhang\inst{3}}

% 1{Ding, Kexin}
% 2{Zhou, Mu}
% 3{Metaxas, Dimitris}
% 5{Zhang, Shaoting}

\authorrunning{K. Ding et al.}
% \authorrunning{Anonymous Author(s)}

% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%

\institute{Department of Computer Science, UNC at Charlotte, North Carolina, USA \and Department of Computer Science, Rutgers University, New Jersey, USA \and Shanghai Artificial Intelligence Laboratory, Shanghai, China\\}

% \author{Kexin Ding\inst{1}\and Mu Zhou\inst{2}\and Shaoting Zhang\inst{3}}


% \author{Kexin Ding\inst{1}\and Qiao Liu\inst{2} \and Edward Lee\inst{3}\and Mu Zhou\inst{4}\and \\Aidong Lu\inst{1}\and Shaoting Zhang\inst{5}}

%
% \authorrunning{K. Ding et al.}
% \authorrunning{Anonymous Author(s)}

% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
% \institute{Department of Computer Science, UNC Charlotte, Charlotte, NC, USA \and SenseBrain Research, CA, USA\and SenseTime Research, Shanghai, China\\\email{szhang16@uncc.edu}}
% \institute{Anonymous Organization\\\email{xxx@xxx.xxx}}
% 
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
%\institute{XXX \email{XX@XXX}\\
% \and XXXX, XXX\\\email{XX@XXX}}
%
\maketitle              % typeset the header of the contribution
\renewcommand{\thetable}{S\arabic{table}}
\section{Multi-head Self-attention}
The Multihead self-attention (MSA) is the concatenation of k self-attention (SA) operations. The SA uses $d_{k}$-dim patient embedding as the query Q, key K, and value V to learn the pairwise relationship $a_{ij} \in A$ between $q_{i} \in Q $ and $k_{i} \in K $:

\begin{equation}
softmax(\frac{QK^{T}}{\sqrt{d_{k}}}) = A
\label{eqS1}
\end{equation}

\begin{equation}
SA(Q,K,V) = AV
\label{eqS2}
\end{equation}

\section{Discrete-time Survival Prediction and Evaluation}
We extend the definition and detailed proof of "discrete-time survival prediction" as follows. The continuous event time $T_{j,continue} \in [t_r, t_r+1)$ could be discretized as $T_{j}$, which is equal to r, where $r \in \{0, 1, 2, 3\}$ and j is the index of four non-overlapped intervals. The discrete ground truth is $Y_{j}\in \{0, 1, 2, 3\}$. With patient-wise embedding $h_{final_j}$, we define the hazard function $f_{hazard}(r| h_{final_j})$ as $P(T_{j}=r|T_{j}\geq r, h_{final_j})$, which is used for calculating the survival function (i.e., C-index calculation) $f_{surv}(r| h_{final_j})$ through $P(T_{j}>r|h_{final_j})$ (i.e., $\prod_{u=1}^{r}(1-f_{hazard}(u|h_{final_j}))$). During the supervised finetuning, the log-likelihood loss for model parameter updation is defined as $-c_{j}\cdot log(f_{surv}(Y_{j}|h_{final_j}))-(1-c_{j})\cdot log(f_{surv}(Y_{j}-1|h_{final_j}))-(1-c_{j})\cdot log(f_{hazard}(Y_{j}|h_{final_j}))$, where $c_{j} = 0$ means patient passed away during $T_{j}$ and $c_{j} = 1$ means patient lived after $T_{j}$.

\section{Appendix Results of Baseline Models}
% compare with our sutdies
\subsection{The Results of Baseline Models with Single-modal Data}
In Table~\ref{tabS1}, We reported the results of the baselines with single modality data. Each column represents the C-index values on the testing set in single modality.

\begin{table}[t!]
\centering
\caption{Single-modal finetuning and testing on TCGA-COAD and TCGA-READ.}\label{tabS1}
\begin{tabular}{c|c|c|c|c|c|c}
\hline
\multicolumn{7}{c}{TCGA-COAD}\\
\hline
Model & \multicolumn{2}{c|}{\makecell{Pretrain with \\image and mRNA}} & \multicolumn{2}{c|}{\makecell{Pretrain with \\image and CNA}} & \multicolumn{2}{c}{\makecell{Pretrain with \\image and methylation}}\\
 \cline{2-7}
 & Image & mRNA & Image & CNA & Image & Methy\\
 \hline
\makecell{Deep\\-Sets} & $52.95\pm2.27 $ & $55.17\pm3.19 $& $50.94\pm2.28 $& $58.78\pm2.11 $& $55.71\pm2.02 $& $54.18\pm2.86 $\\
\hline
\makecell{AB\\-MIL} & $56.82\pm2.73 $ & $60.63\pm2.56 $& $54.68\pm2.38 $& $54.18\pm2.51 $& $55.02\pm2.32 $& $55.78\pm2.43$\\
\hline
\makecell{Trans\\-MIL} & $59.68\pm1.65 $ & $58.72\pm1.21 $& $61.28\pm1.66 $& $50.27\pm2.27 $& $55.83\pm1.75 $& $50.73\pm2.02 $\\
\hline
MCAT & $60.32\pm2.57 $ & $58.63\pm2.29 $& $59.24\pm1.93 $& $55.01\pm2.74 $& $60.85\pm1.74 $& $61.11\pm2.25 $\\
\hline
\makecell{PORP\\-OISE} & $57.50\pm1.83 $ & $60.44\pm2.71 $& $55.87\pm2.88 $& $51.76\pm2.05 $& $43.58\pm2.15 $& $55.92\pm2.65 $\\
\hline
\multicolumn{7}{c}{TCGA-READ}\\
\hline
\makecell{Deep\\-Sets} & $60.45\pm2.49 $ & $61.33\pm1.64 $& $56.59\pm2.72 $& $50.47\pm2.19 $& $57.82\pm2.14 $& $60.01\pm2.23 $\\
\hline
\makecell{AB\\-MIL} & $68.73\pm1.98 $ & $56.58\pm1.86 $& $62.63\pm1.62 $& $60.57\pm2.24 $& $61.63\pm2.19$& $53.49\pm2.31 $\\
\hline
\makecell{Trans\\-MIL} & $50.59\pm2.49 $ & $50.33\pm2.67 $& $60.92\pm2.82 $& $55.46\pm2.19 $& $51.48\pm1.52 $& $60.47\pm1.82 $\\
\hline
MCAT & $66.95\pm2.51 $ & $62.41\pm2.05 $& $58.73\pm2.38 $& $63.77\pm2.03 $& $62.78\pm2.15 $& $58.87\pm2.09 $\\
\hline
\makecell{PORP\\-OISE} & $62.42\pm1.84$ & $58.49\pm1.60 $& $56.87\pm2.18 $& $58.41\pm2.20 $& $67.60\pm2.26 $& $66.38\pm2.74 $\\
\hline
\end{tabular}
\end{table} 


\begin{table}[t!]
\centering
\caption{Fewer data finetuning performance on TCGA-COAD and TCGA-READ.}\label{tabS2}
\begin{tabular}{c|c|c|c|c|c|c}
\hline

\makecell{Model} & \multicolumn{3}{c|}{TCGA-COAD} & \multicolumn{3}{c}{TCGA-READ}\\
 \cline{2-7}
 & 50\% & 25\% & 10\% & 75\% & 50\% & 25\%\\
\hline
 & $63.16\pm 2.23 $ & $62.76\pm2.54 $& $40.39\pm3.11 $& $69.05\pm2.31 $& $55.55\pm2.05 $& $47.12\pm2.82 $\\
 % \cline{2-6}
\makecell{Deep\\-Sets} & $58.91\pm2.44 $ & $58.31\pm2.01 $& $49.50\pm2.25 $& $60.90\pm2.34 $& $55.45\pm2.51 $& $49.77\pm2.19$\\
 % \cline{2-6}
 & $45.37\pm3.42 $ & $54.88\pm3.27 $& $54.23\pm2.76 $& $64.26\pm1.98 $& $51.38\pm2.23 $& $49.65\pm2.62 $\\
\hline
 & $51.35\pm2.31$ & $54.64\pm1.82 $& $45.26\pm1.91 $& $66.66\pm2.43 $& $48.78\pm1.82 $& $49.35\pm2.61 $\\
 % \cline{2-6}
\makecell{AB\\-MIL} & $53.02\pm2.44 $ & $44.93\pm2.84 $& $47.40\pm2.23 $& $62.93\pm2.30 $& $62.90\pm2.04 $& $62.37\pm2.54 $\\
 % \cline{2-6}
 & $52.20\pm2.00 $ & $54.50\pm2.91 $& $50.34\pm2.55 $& $51.87\pm2.66 $& $50.71\pm2.31 $& $50.33\pm2.86 $\\
\hline
 & $53.25\pm1.92$ & $59.06\pm2.53 $& $45.10\pm2.40 $& $59.32\pm2.92 $& $63.25\pm2.57 $& $63.63\pm2.82 $\\
 % \cline{2-6}
\makecell{Trans\\-MIL} & $48.62\pm2.61 $ & $50.60\pm2.23 $& $48.13\pm2.32 $& $62.15\pm2.63 $& $52.50\pm2.44 $& $56.36\pm2.73 $\\
 % \cline{2-6}
 & $52.90\pm2.37 $ & $53.59\pm2.01 $& $52.31\pm2.91 $& $53.62\pm2.69 $& $58.70\pm2.43 $& $54.12\pm2.62 $\\
\hline

 & $54.88\pm1.53 $ & $53.58\pm1.69 $& $59.01\pm1.82 $& $61.66\pm2.13 $& $60.75\pm2.56 $& $62.47\pm2.26 $\\
 % \cline{2-6}
MCAT & $52.33\pm2.04 $ & $56.76\pm2.31 $& $48.65\pm1.92 $& $65.33\pm2.87 $& $56.22\pm2.37 $& $60.45\pm2.74 $\\
 % \cline{2-6}
 & $57.73\pm1.72 $ & $54.89\pm1.90 $& $50.16\pm2.11 $& $60.94\pm1.78 $& $50.27\pm2.07 $& $48.73\pm1.92 $\\
\hline
 & $55.87\pm 2.31 $ & $55.37\pm2.14 $& $43.69\pm3.52 $& $64.48\pm2.01 $& $60.89\pm2.36 $& $60.34\pm2.29 $\\
 % \cline{2-6}
\makecell{PORP\\-OISE} & $55.40\pm2.57 $ & $50.20\pm2.43 $& $53.51\pm2.46 $& $54.21\pm2.83 $& $42.67\pm2.74 $& $45.23\pm2.72$\\
 % \cline{2-6}
 & $50.70\pm2.34 $ & $54.95\pm2.37 $& $49.48\pm2.17 $& $63.00\pm2.05 $& $55.27\pm2.41 $& $50.89\pm2.10 $\\
\hline
\end{tabular}
\end{table} 


\subsection{The Results of Baseline Models with Fewer Finetuning Data}
In Table~\ref{tabS2}, for each baseline, we include three rows to show the C-index values. The three rows are shown as "image and mRNA", "image and CNA", and "image and Methylation" in order. The baseline models are trained by fewer finetuning multimodal data. 


% \bibliographystyle{splncs04}
% \bibliography{reference}


% \end{document}
