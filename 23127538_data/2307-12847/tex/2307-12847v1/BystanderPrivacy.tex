\documentclass[a4paper,11pt]{article}

\usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{hyperref}
\expandafter\def\expandafter\UrlBreaks\expandafter{\UrlBreaks\do\/\do\*\do\-\do\~\do\'\do\"\do\-}
%\usepackage{upmath,color}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{adjustbox,lipsum}
\usepackage[top=1.25in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newcommand{\bo}[1]{{\small\color{teal}[Bo: #1]}}
\newcommand{\charlie}[1]{{\small\color{cyan}[Charlie: #1]}}
\newcommand{\jiacheng}[1]{{\small\color{purple}[Jiacheng: #1]}}
\newcommand{\bdj}[1]{{\small\color{red}[Brendan: #1]}}
\newcommand{\matt}[1]{{\color{blue}[#1]}}
\newcommand{\mattremove}[1]{{\small\color{red}[Matt: #1]}}
\setcounter{secnumdepth}{1}




\begin{document}
\setcounter{secnumdepth}{3}
\title{Securing Bystander Privacy in Mixed Reality While Protecting the User Experience}

\author{Matthew~Corbett$^1$, Brendan~David-John$^1$, Jiacheng~Shang$^2$, \\Y.~Charlie~Hu$^3$,
        and~Bo~Ji$^1$ %\textcolor{red}{add affiliations?}
}

\date{%
    $^1$Virginia Tech, Blacksburg, VA, USA\\%
    $^2$Montclair State University, Montclair, NJ, USA\\%
    $^3$Purdue University, West Lafayette, IN, USA\\[2ex]%
    \today
}



\maketitle

\begin{abstract}
%\bo{How about this title: ``Securing Bystander Privacy While Protecting the User Experience in Mixed Reality''?}
The modern Mixed Reality devices that make the Metaverse viable can also require vast information about the physical world. These devices can also violate the privacy of unsuspecting or unwilling bystanders in their vicinity. In this article, we explore the problem, existing solutions, and avenues for future research. 
\end{abstract}

\section{Introduction}
As the promise of the Metaverse 
 %\bo{it is probably okay to use ``Metaverse'' here, but I am wondering if we should simply focus on MR in the rest of the article.} 
 grows, more and more powerful devices are required to satisfy user expectations of the kinds of experiences that make an immersive world so enticing. These experiences must immerse the user in either a completely digital reality (Virtual Reality or VR) or a physical reality altered with digital information (Augmented Reality or AR). We consider the breadth of devices from VR to AR, and all hybrid technologies in between to be Mixed Reality (MR) devices. MR devices include sensor suites that provide camera, depth, audio, and eye-tracking information that are essential to displaying immersive content and enabling naturalistic interaction. The sensor data is input to machine learning models to understand how to overlay digital content within the physical world and create predictive models of human intention to support low-friction interaction~\cite{AA19, AA20}.
%\bdj{Can we cite \url{https://tanyajonker.com/assets/publications/David-John_et_al_2021_ETRA.pdf} and \url{https://tanyajonker.com/assets/publications/Jonker_et_al_2020_ai4hci.pdf} here? Also works so you don't have to keep re-ordering the in-text citations at least.} 
However, the sensor suite on these devices does not discern between the data required for its functionality and data that can be used in a way that violates the privacy of \emph{bystanders}, i.e., those surrounding the user who have not or cannot give consent for their information to be collected.  
%\bo{even if you give formal definitions later, we should probably give an informal definition of bystander here.}


%\matt{Matt: I have to re-number the references in order, but am waiting until edits are complete to keep from changing multiple times and potentially creating errors. }

These violations, real or perceived, can manifest serious consequences for bystanders and for device manufacturers alike. As shown in a brief case study in Section~\ref{sec:GoogleGlassStudy}, Google's Glass wearable was a new and innovative MR device that was ultimately hamstrung for a multitude of reasons, including the device's perceived lack of bystander privacy protection. The devices were met with large-scale criticism from both the public (wearers were derisively called ``Glassholes'') and governments alike. These concerns create marketability issues and also spurred legislation in multiple countries to regulate and restrain devices such as Glass. In the end, privacy concerns, as well as marketing and cost issues, ultimately become the demise of this product. 

A simple and naive solution to this problem would be to strip all bystander data from any recording (audio, visual, etc.). However, certain applications could require such information to function. Consider an example of a facial recognition program, implemented on an AR device, to assist patients in a memory care facility. This application could seek to assist the patient (i.e., the user) with remembering the names of friends, family, and healthcare workers by detecting these faces and labeling them in 3D on the augmented display of the device. In this case, detecting the identity of bystanders (e.g., other patients) could be a privacy violation. Knowing that \emph{some} faces are required, we are then presented with the problem of how to discern which faces are to be presented, known as \emph{subjects},
%\bdj{should we introduce subject term here?}
and which are simply bystanders. This means that we cannot simply remove all identifying information, such as faces, from sensor input. Doing so would limit the functionality of legitimate third-party applications that may require the use of this information. We must decide which information to remove and which to provide to such applications. 
%\bdj{double negative in this sentence. I'm not sure I follow what the sentence is saying, you might need to re-phrase it. Are you saying we have to consider how the user is interacting with someone before classifying them as a subject and exposing them?}.   
%\bo{refer to where you present the care study}

We define the gap between the expectations of privacy that bystanders demand and the level of privacy that an MR device can provide to be the \emph{Bystander Privacy Problem} or \emph{BPP}. This problem is comprised of two main components. The first is the technical vulnerabilities present in modern MR devices. These vulnerabilities stem from coarse-grained permissions for third-party applications and the machine-learning inference tools that allow these permissions to be exploited to violate the privacy of bystanders. The second, the perception that these devices can invade bystander or user privacy, does not have to be founded in technical reality but has also been shown to be a hindrance to the success of MR devices. As shown in our case study in Section~\ref{sec:GoogleGlassStudy}, the BPP can create real issues for bystanders and device manufacturers. We further explore existing solutions to address the BPP, and where the solutions often fall short by removing required data for legitimate applications or inadequately addressing bystander privacy concerns.
%\bdj{the order of these two points/paragraphs in the gaps subsection is presented in the other order (legitimate applications is first, then concerns)}. 
Finally, we present potential future directions in this field, including research into technical solutions and ways to address potentially unfounded perceptions of privacy violations from bystanders. We intend to illuminate the issue of bystander privacy in MR devices, and specifically, the lack of viable solutions~(Section~\ref{Problems}), while presenting a framework for future solutions designed to address this problem (Section~\ref{AddressingIssues}).
%\bo{shall we add here references to later sections?}

\section{WHAT IS A BYSTANDER?}
We present a few key definitions for clarity. A \emph{user} is a person who wears an MR device; a \emph{subject} is a person with whom the user intends to interact that has also given any form of consent for data capture; a \emph{bystander} is any non-user, non-subject third-party surrounding the device during its use. This bystander can be aware or unaware of the device's presence. We acknowledge that these definitions are relatively simple and that more nuanced and detailed definitions exist such as the taxonomy of Pierce et al.~\cite{AA2}. We choose to use this simple and binary definition as it streamlines the decision between the two labels (i.e., subject and bystander), making generalization across many different contexts possible. Using a more nuanced approach, with multiple definitions, could be overly burdensome when designing and considering a system that could span across scenarios such as interpersonal communications, industry, exercise and fitness uses, and others. 
%\bdj{we should justify why a relatively simple taxonomy is used here when a more complex one exists, i.e., for simplicity of modeling (ex: binary classification from model makes it simple to develop and evaluate research systems) or due to ease of use in an analogy that benefits the reader, or because we are generalizing the BPP across many different contexts, making it difficult to employ a taxonomy that relies heavily on context}

In order to make these definitions more concrete, we present an example from the field of healthcare. Fig.~\ref{fig:MedicalExample} illustrates an AR-enhanced memory care scenario. In this example, a patient in memory care is suffering from memory loss from Alzheimer's disease. The patient requires assistance in order to identify close friends and family. The application, on an AR device, uses facial recognition to identify and label persons of interest to the patient in real time. However, identifying bystanders, such as other patients or family members of other patients, would be a violation of privacy as their faces were used as part of the application without their consent. 

% Figure environment removed


\section{MODERN MR DEVICES CREATE PRIVACY CONCERNS FOR BYSTANDERS}
\label{Problems}
Modern MR devices can effectively immerse the user in an altered reality, either completely or in part. This immersion requires the use of sensors that can absorb information about bystanders and violate privacy expectations. For reference, Table~\ref{tab:deviceListing} shows a listing of some of the most modern MR devices available. This table shows the sensing capabilities of modern MR devices, specifically, the ever-increasing ability of these devices to capture data about their surroundings in the form of camera data, depth data, or voice data from onboard microphones. We also include information about the ability of these devices to record, and potentially transfer, detailed information about the physical world surrounding the device and the eye data of the user. We briefly explore the problems created by these new devices and the impact these problems may have on future technologies.

\setcounter{subsection}{0} 
\subsection{The Bystander Privacy Problem}
%\textcolor{red}{Can we add back Subsection numbers?}
\begin{table*}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabularx}{\columnwidth}{|X||X|X|X|X|X|X|}

 \hline
 \textbf{Device} & \textbf{Released} & \textbf{Environ-ment Mapping} & \textbf{Cameras (including tracking cameras)} & \textbf{Eye Tracking Cameras} & \textbf{Depth Cameras} & \textbf{Micro-phone} \\
 \hline
 \hline
  Microsoft HoloLens 2 & 2019 & Yes & 5 & Yes & Yes & Yes \\
 \hline
  Google Glass Enterprise Edition 2 & 2019 & No & 1 & No & No & Yes \\
 \hline
    Varjo XR-3 & 2020 & Yes & 2 & Yes & Yes & No \\
 \hline
 Magic Leap 2 & 2022 & Yes & 5 (including controller) & Yes & Yes & Yes \\
 \hline
Meta Quest Pro & 2022 & Yes & 5 & Yes & Yes & Yes \\
 \hline

  Nreal Air & 2022 & No & 0 & No & No & No \\
 \hline
 Apple Vision Pro* & 2023 & Yes & 8+ & Yes & Yes & Yes \\
 \hline
\end{tabularx}
\end{adjustbox}
\caption{ A list of popular MR devices released since 2019 and their onboard sensing capabilities.\\ (* = expected or assumed capabilities)}
\label{tab:deviceListing}
\end{table*}

A gap in privacy expectations and the type of inferences from sensor data 
%\charlie{this inferred information is the key, not the sensors - can we somehow emphasis this?}
creates concerns for bystanders in the presence of MR devices but also creates legal and marketability issues. While one-half of the BPP can exist without the other, recent work has shown that modern devices not only suffer from the vulnerabilities that allow for violations of bystander privacy but also create worry in the minds of those that could be recorded by the sensors embedded in such devices. %\bo{I feel we referred to this use case too many times}
%\bdj{Is this sentence redundant based on the last section? Next sentence could start 'A gap in privacy expectations and the type of inferences from sensor data creates ...'}
%\bo{this entire paragraph seems to be redundant, compared to the paragraph before Section 1 (end of Page 1 and beginning of Page 2).}. 

% starting a new pargraph to talk left pasrt of BPP

Research by Lehman et. al.~\cite{AA3} has borne out the fear of
technical vulnerabilities in AR devices.
In so-called
``Hidden Operations'', stealthy operations by third-party applications
to exploit collected camera data have been proven a viable threat. In
this kind of exploitation, a malicious application can collect camera
frames, infer information such as gender, age, or the presence of
specific objects and exfiltrate that information using a network
connection.


%% Figure environment removed


This information threatens to violate bystander privacy by uniquely identifying bystanders using a facial recognition dataset, recording information about their face, weight, gait, or medical conditions, 
%\charlie{I wlays wonder where this personnel info come from -- isn't this the source of privacy problem, not the sensors?}
or recording their voices for later identification, among other examples. Violations like these can be made possible even with well-meaning device users, through the relatively coarse-grained permissions granted to an application after a cursory request from the application. These permissions are very often not well understood by the user and can lead to data exploitation in this way by a malicious application. 

With or without
%\bdj{wouldn't saying 'without' here suggest that bystander perceptions are still negative even when the BystandAR system was running eliminating the technical vulnerability?}
actual technical vulnerability, O'Hagan et. al. and Corbett et. al have shown that bystander perceptions of privacy in the face of these threats are generally negative~\cite{AA4, AA10}, especially before these bystanders are given information about how they may be protected by privacy solutions. These concerns have had tangible impacts on the devices, public perception, and international law. Public perception, specifically, has spurred legislation that is designed to control the risk these devices present to bystanders and has also contributed to the market failure of devices in the past. This consumer blowback and legislation threaten to derail the acceptance of MR technologies.

Even so, not all bystanders have the same expectations of privacy. This is partly due to bystander ignorance of the threat, the relationship to the user, and differing perspectives of the threat based on the types of activities potentially observed. For example, it has been shown that a majority of participants have a relatively low awareness of the capabilities of the AR device and the threats to their privacy~\cite{AA4}. In general, once made aware of the threats to their privacy, bystanders become generally more concerned with potential violations of their privacy. This illustrates another facet of the problem: bystander protection policies cannot be static; they must adapt to different user relationships, bystander preferences/consent, and situations. At the industrial level, even Facebook (now Meta) expressed concern about the use of facial recognition technologies on future devices, saying ``Face recognition $\dots$ might be the thorniest issue, where the benefits are so clear, and the risks are so clear, and we donâ€™t know where to balance those things''.\footnote{\url{https://www.buzzfeed.com/ryanmac/facebook-considers-facial-recognition-smart-glasses}} Quotes like this show both an acknowledgment and a lack of policy solutions to the bystander privacy problem.

\subsection{Legislation and Global Policy}
In 1967, U.S. Supreme Court Justice Potter Stewart expressed that personal information cannot be considered private if the person ``knowingly exposes it to the public''.\footnote{\url{https://supreme.justia.com/cases/federal/us/389/347/}} Since this ruling, however, the definition of what can be considered ``reasonable'' has eroded as technology has advanced.\footnote{\url{https://repository.law.miami.edu/fac_articles/539/}} As technology has enabled average users to infer more and more detailed (and potentially sensitive) information, what can be considered a ``reasonable'' expectation of privacy is under constant discussion and scrutiny. Even so, the advent of more advanced MR devices has created a policy vacuum that is increasingly filled with legislation designed to protect bystanders from privacy infringement.

Legislation, such as the General Data Protection Regulation (GDPR) in
the European Union (EU), seeks to protect bystanders by requiring a
balance of data collection justification and bystander input to
lawfully allow the collection of data. In the U.S., a ``patchwork of
state and national policies'' comprise protections~\cite{AA7}. Even
while different in content and scope, these laws emphasize consent in
data collection from the person whose information is collected. This
consent has been shown to make the collection of information far more
acceptable~\cite{AA4}, but such an option is rarely afforded to
bystanders who are not even aware of the presence of the
device. However, mechanisms to ``opt-in'' are far from standardized
and generally only exist as academic solutions. Such mechanisms have
not knowingly been implemented as part of any existing MR device and
have only been proposed as potential future guidelines~\cite{AA8}.

%\bdj{far from is repeated twice, could say it has not knowingly been implemented as part of ...}

\subsection{Manufacturer-Driven Policies and Standards}
Public concern over the dangers of MR devices violating bystander privacy has forced some device manufacturers to develop and enforce their own standards in an effort to ameliorate this concern. For example, Meta's Project Aria is an effort to collect and synthesize data from everyday life using a set of glasses issued to researchers equipped with embedded sensors.\footnote{\url{https://about.meta.com/realitylabs/projectaria/}} These sensors include cameras, an IMU, eye gaze sensors, and more, and are designed to record the nuances of everyday life in an effort to accelerate the development of machine learning techniques. While these glasses are not strictly MR devices due to the lack of a user-focused display, they collect data constantly using an array of sensors, presenting the same privacy problems as any modern MR device has. 

In order to lessen public concern, Meta published both a privacy
policy and answers to likely questions from the general public on the
project's main web page. Notably, Meta is requiring researchers that
use the device to wear signs or distinct clothing that give bystanders
an understanding of what the wearer's glasses are doing and require
the researcher to stop and/or remove bystanders from recorded data
upon their request. This provides the 
%\charlie{opt-out??}
consent and bystander awareness that are recommended for bystander privacy policies but
would be unwieldy in more ubiquitous devices worn by members of the
general public. Wearing clothing and stopping to remove audio, camera,
or depth data at the request of a bystander is likely acceptable for
research. Additionally, even these measures have caused discomfort and
concern about the project's privacy implications~\cite{AA21}.
%\bdj{I'd argue it didn't go over well, research has supported this point as well that you can cite \url{https://www.sciencedirect.com/science/article/pii/S2666659621000032}}. 

Other manufacturers, like Google, have learned from the previous public outcry from their AR glasses (for a deeper review of Google's Glass and its issues, please see Section~\ref{sec:GoogleGlassStudy}). 
%\bo{the reference does not work properly here}). 
%\charlie{the transitoon to the next sentence not smooth?}
However, it appears Google has learned from past negative perceptions of their devices. Google's new AR glasses have been shown to consumers, using real-time translation and a closed captioning system as an extension of Google's Translate software.\footnote{\url{https://arvr.google.com/}} In preparation for the release of this device, Google released information that the device would not be able to take pictures like the Glass did in order to avoid the public scrutiny that plagued the Glass.\footnote{\url{https://blog.google/products/google-ar-vr/building-and-testing-helpful-ar-experiences/}}

%\bdj{Google ref for this is you prefer \url{https://blog.google/products/google-ar-vr/building-and-testing-helpful-ar-experiences/}}.

\subsection{Impacts on Future Devices}
As we will see with Google's Glass AR device, the perception that a device will negatively impact the privacy of bystanders in public places can hamper both the marketability of a device and run afoul of future regulations and legislation designed to protect such information. As public perception of the danger of collecting personal data in public places increases, device manufacturers must comply with ever-evolving regulations and codes, either officially codified into law or proposed as community best practices. Future solutions will need to address these concerns with consent mechanisms, information collection limits, and other methods to assure both a potential user base and potential bystanders that their devices are not actively collecting sensitive information. 

\section{GOOGLE GLASS: A CASE STUDY}
\label{sec:GoogleGlassStudy}
Google released the Glass in 2013 as one of the first attempts at a fully immersive heads-up display.  While not truly an AR device, as the device did not interact and respond to the physical world, the Glass was designed to provide navigation and directions, notifications, and other passive alerts to the user. Fig.~\ref{fig:GoogleGlass} shows an image of the device. 

% Figure environment removed

The Google Glass was met with an immediate negative perception, as indicated by wide-spread concerns about the cost, harassment in public,
%\bdj{health suggest the device makes user sick or similar, but I think you are referring to not being attacked by others who are against the device. Perhaps this can be generalized as 'social acceptance' or 'harassement in public'}
and privacy. Specific to concerns about privacy, most concerns were due to its onboard camera.\footnote{\url{https://variety.com/2013/biz/news/google-glass-cons-how-the-camera-embedded-eyeglasses-could-shatter-privacy-1200563731/}} The camera was capable of taking still images and video but required the user to either use a touchpad on the rim of the glasses or issue a voice command. Video capture was also signaled by a visible light on the glasses. This would prevent the completely stealthy capture of a photo or video by the user, and allow bystanders some knowledge of the user's intent. However, this did not stop local bars, advocacy groups, and local governments from protesting and banning the device from use. Users of the device were given the derisive term ``Glassholes'' for the perceived narcissism and intrusion into the privacy of others. Even the threat of facial recognition, a relatively new field ten years ago, rose to the surface as a complaint from detractors of the device. Some governments, including the U.S. and the U.K., vigorously debated legislation to limit the types of privacy violations that the public feared from the device. The device became hampered by public perception and negative publicity. Eventually, Google announced a partial discontinuation of the device in 2015, with full removal of the device from the market in 2023. 

With all of the concerns of video capture and facial recognition aside, this device was relatively limited by modern standards. The Glass had no depth sensors, a limited camera resolution, and restrictive onboard processing power. In contrast, today's MR devices are far more powerful and are becoming capable of the types of exploitation feared in 2013. However, we have yet to see the types of public outcry that plagued Google Glass against current MR devices. Likely, this is due to the fact that these devices have not yet achieved the types of consumer-grade ubiquitous wear that Glass has sought. Even so, from examining the Glass and its troubles with negative public perception, we can see clear evidence that public scrutiny is high around devices that can record audio or visual data in everyday situations, potentially surreptitiously, and without explicit consent from the persons recorded. The Google Glass example demonstrates a case where a technical vulnerability did not exist, but even so, the significant barrier to product success was a result of negative public perception.
%\bdj{grammar seems a bit off here, is it better to say 'The Google Glass example demonstrates a case where a technical vulnerability did exist (or didn't due to voice commands for photos? I'm not sure what arguement you are making here) though the significant barrier to product success was a result of negative public perception.'}

\section{ADDRESSING BYSTANDER PRIVACY ISSUES}
\label{AddressingIssues}

\subsection{Principles}
Any viable design or system that seeks to improve bystander expectations of privacy in the face of modern MR devices is required to maintain an acceptable immersive experience that benefits the device user. This means that practical solutions not only protect the information of bystanders, but also keep from reducing device rendering speeds, introducing latency, adding unnecessary user input (GUIs or physical tokens/actions), and preventing legitimate operations (such as object detection or facial recognition).
%\bdj{maybe remove this last comment? Is our perspective that passive is best, or is there is a place for active/opt-in systems? We can voice that opinion in this type of paper, but here we are just providing hard requirements for a practical system, while this last one is something that is not as concrete (could be passive or active)}. 

\paragraph{Usability.} MR devices provide an immersive and fluid experience, but have strict requirements for performance. As an example, device frame rates ensure that the digital world is rendered fast enough to ensure the experience does not appear choppy or cause sickness to the user. Bystander privacy solutions that rely on compute-intensive mechanisms such as onboard machine learning inference can interfere with this experience by adding additional overhead to the device, reducing frame rates, and negatively impacting user experience. An optimal solution should have a small enough computational footprint to be completely seamless for the user. Additionally, the solution should not present overly complicated decisions in the form of GUIs, pop-ups, or require users/bystanders to possess or use complicated artifacts such as QR codes, or other physical items. Such interventions can reduce the ``flow'' that is the optimal experience for MR device users~\cite{AA9}. 

\paragraph{Bystander Protection.} It should be evident that a successful bystander privacy solution should seek to protect bystanders in as many ways as possible. However, no solution currently available can claim to be completely effective in all scenarios. Ideally, solutions should seek to minimize the amount of bystander information available to third-party applications in as many use cases as possible. Some solutions force a classification between bystanders and non-bystanders (e.g. subjects) with the assumption that there must always be a subject. This requires a privacy solution to understand nuanced situations where a subject may not always exist, or potentially more than one. This can create errors when non-standard situations arise, such as jogging or when the device user is simply working alone.
%\bo{check previous sentence}
%\bdj{is it better to generalize this to say some solutions have to classify between bystanders and non-bystanders, meaning solutions have to also perform classification or even understand which moments there should non-bystanders? Right now it reads as if the 'at least one' subject use case is a highly frequent and very specific case that we think is important to mention this early in bystander protection.}
This requirement forces error in use cases where no subject exists, such as if the user is running or moving about an office building between meetings. Other solutions use the user's physiological information, such as eye gaze and voice, to identify subjects and exclude bystanders. Solutions like these address this issue by capitalizing on the natural dynamics of human interaction.
%\bdj{the malicious user is kind of new to this subsection, and not well explained to end the paragraph, perhaps we can remove the mention of it and say some solutions address this issues by capitalizing on the natural dynamics ...}. 

\paragraph{Availability of Legitimate Bystander Information.}
%\bdj{Legitimate bystander information maybe? I can see a case for an app asking how many people are around the user to determine if they are in a busy location or not, and this can be privacy-preserving w/o facial identity, or even other information like all bystanders are looking at a specific object that can be considered legitimate w/o leaking facial identity, so the case is not binary (face or not) it is more like there is legitimate bystander info that an app may want to use w/o leaking privacy}\bo{good point}
No bystander privacy solution can simply strip away the information of all persons in the device's capture radius. Legitimate applications, such as the memory care example in Fig.~\ref{fig:MedicalExample}, can require facial detection or recognition techniques. Removing all potentially identifying information would reduce the experience and usefulness of the device. Any solution needs a mechanism to decide what persons need to be removed and which do not. Section~\ref{AddressingIssues} divides these solutions based on whether the mechanism involved user or bystander actions, or makes a decision on who to remove based on existing context. In this Section, we create a dichotomy of solutions, with Explicit Solutions requiring user input and Implicit Solutions using the available context in the interaction to separate the subject from bystanders.
%\bo{should mention explicit and implicit solutions here. Otherwise, it reads abrupt later when you introduce explicit solutions and implicit solutions}

\paragraph{Consent.} 
  From both the case study on Google's Glass, legislation, and
  proposed policies, two facets of a successful bystander privacy
  system have emerged - bystander awareness of the device's state and
  bystander consent to be recorded~\cite{AA4, AA7,
    AA8}. 
    %\charlie{following did not say about awareness?}
These mechanisms, whether they involve verbal communication
  from the bystander, a physical or digital token (e.g., a cell phone
  with a Near Field Communication (NFC) channel to express recording
  preference and/or consent to nearby devices), or registration with a
  database, have been proven to increase bystander confidence in the
  safety of their personal information in the face of MR devices.

Additionally, consent can be given in different ways.  For instance, if a business decides to limit the use of MR devices in its stores in order to protect bystander privacy, as was the case with Google's Glass, this is a passive consent mechanism. However, we remain optimistic that future solutions would address bystander privacy concerns and limit this blanket-type of passive consent.
%\bdj{Would you also consider a private business's ability to consent on whether AR devices, or devices w/ bystander solutions installed, are allowed to be operated in their establishment/buildings? Even w/ such solutions, based on what we say w/ Google Glass store owners who value their customer's privacy may still have the right to ban such devices, though we are optimistic that bystander solutions could eventually address these concerns.}


\subsection{Explicit Solutions}
\label{ExplicitSolutions}
We define explicit systems to the BPP as solutions that require the
device user or the bystander 
%\charlie{what about the subject opt-in? vs. bystander opt-out}
to interact with the system to either opt-in or opt-out from the recording by the device's sensors. This can be done through a
published privacy policy, hand gestures, physical tokens, etc.~\cite{AA10}. Some
solutions, such as Cardea~\cite{AA11}, require the bystander to
establish a preference profile or upload images to pre-train a
classifier on an edge or cloud server. Such a node then processes this
data to decide if certain portions of the image need to be sanitized
of bystander data by recognizing gestures, faces, sensitive locations,
etc. Other solutions, such as PrivacEye, require specialized physical
equipment or tokens to be worn by either the user or the
bystander~\cite{AA12}.

These systems generally provide the bystander with a tangible mechanism of providing consent, which has been shown to be preferable~\cite{AA4}. Additionally, many of these systems give the bystander the ability to give or reserve consent to be recorded. However, these systems impose a burden on the bystander to intervene in some way to protect their own privacy, especially with systems that require explicit bystander input in the form of physical tokens or a registration in a system. If a bystander chooses not to do so, they may not be able to expect that the system is working to protect their information from exploitation and misuse. 

\subsection{Implicit Solutions}
\label{ImplicitSolutions}
Implicit BPP systems protect the bystander without explicit actions, by inferring context from the bystander, user, or environment~\cite{AA10}. In general, these systems use a machine learning model to infer the presence (or lack) of some indicator to decide if a person is either a subject or a bystander. Some systems, such as BystandAR, use information about the user's eye gaze and voice to determine the subject of an interaction and remove the visual information of the remaining persons in view~\cite{AA10}. Others use the position of the person relative to the center of a captured image or the direction of the person's eye gaze~\cite{AA13}. 

These systems have the advantage of not requiring explicit input from the bystander to expect protection. By inferring information about the context and environment, the solution does not require hand gestures, tokens, or registration to make a decision about who to protect and when. However, if the context is not as expected, these solutions can falter. For example, if the bystander happens to be captured near the center of the frame, and also happens to be looking at the camera, then a machine learning model can report a false negative for the presence of a bystander. If the solution relies on context from the user, such as in BystandAR, a malicious user could override the protection in order to capture the visual information of victims. 

\subsection{Gaps in Current Solutions} With the exception of only a few (e.g., BystandAR), current solutions struggle to operate in real time on live sensor data. Most existing solutions are designed to protect bystanders after the moment of capture, by offloading and inferring the presence of a bystander on an edge node or similar. This forces such solutions to be used exclusively in roles that can tolerate the delay, such as static image captures for use on social media. When considering MR devices, we recommend that this information be protected in real-time. If not, a legitimate application could not expect access to live data for legitimate reasons (Fig.~\ref{fig:MedicalExample}) without delay. Additionally, transferring unprotected data off the device has been shown to create vulnerabilities during data transmission. This presents a challenge to convincing device users and application designers to integrate bystander privacy solutions in their workflow. 

%\bo{besides latency, shall we mention attacks during the data transmission?}
%\bdj{we expect, or we recommend?}

Additionally, even a perfect technical solution that protects a bystander completely in all cases cannot be deemed successful if bystanders do not perceive the system as safe. As shown by Google's Glass, the perception of the safety of the system can outweigh the actual threat when it comes to marketability and public backlash. While studies such as those done in O'Hagan et. al.~\cite{AA4} have illustrated initial privacy directions and issues with public perception, the next step should involve deploying and testing actual bystander protection systems on commodity MR devices and studying the effect they have. %\bdj{This feels somewhat dismissive of the O'Hagan suvery work. I think they had some nice findings there, and it can be pitched that we are at a point where the field has used design studies to understand initial directions in this space and the next step should be deploying and evaluating perceptions of real systems.}\bo{agreed} 
Much more work is needed to actually gauge the bystander reaction to a real-time, fully implemented system that can be used on MR devices. 

An ideal solution must address the requirements of usability, protection, availability, and consent. The solution must run near-seamlessly on modern MR devices, provide an acceptable amount of protection for bystanders, provide the required information for third-party applications, and give bystanders a mechanism to provide consent to be recorded. Since, to our best knowledge, such a system does not yet exist, there remains much work to be done in this regard. 

%\bdj{good job revisiting this set of components, I'd say this section is the meat of our contribution, and we may find that we expand on it a bit to give readers a high-level understanding of this topic, but also enough specifics and details to find the latest work that needs to be expanded upon}

\section{FUTURE DIRECTIONS IN BYSTANDER PRIVACY}
\label{FutureDirections}
In addition to addressing the lack of a technical solution to address bystander privacy concerns, research must also address the more nuanced areas of public education and perceptions. As shown in previous work, there is simultaneously a lack
%\bdj{maybe use a more simple synonym here?}\bo{just use ``lack''? try to avoid using less common words}
of understanding of the threats posed to bystanders, and unnecessary apprehension towards devices that do not pose a threat~\cite{AA4}. In order to make future MR devices viable and publicly acceptable, we must address these interrelated problems holistically. 

\subsection{Education}
At the root of the perception problem facing MR devices, education provides an understanding of the true threat of such devices. A lack of either user or bystander education has been shown to be the cause of both the demise of past devices and a lack of understanding of the actual threats posed by modern ones. For instance, the Glass suffered from a vast overestimation of the device's capability to record and exploit data, while modern devices that pose far more risk have been shown to be overlooked~\cite{AA4}. From this, it stands to reason that a more thorough understanding of the capabilities of modern MR devices would ameliorate both extremes. Understanding that modern MR devices are capable of facial recognition, weight estimation, and voice recording (among other exploitation avenues) would create the wariness that we believe would be commensurate with the threat. This would also direct the public's focus to risks that actually exist, direct future technical and policy solutions towards more refined language, and prevent overly-restrictive limits. 

The mechanism to convey this understanding, however, is not as clear. Clearly, existing methods have failed to impress a full understanding of these threats on the public outside of research circles. There is much room for future research that investigates how best to bridge this understanding gap. Future work should explore what data should be conveyed, at which times, and on what mediums. This information, when properly conveyed, could simultaneously reduce undue scrutiny on unlikely or infeasible threats, while increasing scrutiny on viable ones. 

\subsection{Bystander Perceptions}
Even when provided with the correct information about the viability of a threat, we must better understand the psychological impact of MR devices in public areas. Existing work on this topic focuses on protection techniques and consent mechanisms but does little to evaluate an implemented, real-time system that seeks to provide the proper (and only the proper) information to third-party applications. Using implemented and tested solutions, such as BystandAR~\cite{AA10}, future work can explore the actual impact of technical solutions on bystander perceptions of privacy. Additionally, example privacy policies, similar to those used by Meta in Project Aria, can be evaluated for the confidence they do or do not provide. 

\subsection{Experience}
Certain technologies have always created distrust at the onset of their proliferation in the public. Even the cellphone, now ubiquitous, was viewed warily by a public concerned with its ability to record personal data as recently as the year 2000~\cite{AA23}. However, over time these technologies have become more widely used and more widely accepted. In time, after more exposure and public understanding, MR devices are likely to follow this path and become more widely accepted and with less apprehension. Surveys on bystander perceptions and apprehension shed light on the current state of the problem, but a wider familiarization with MR devices may be necessary to fully realize any solution.
%\bdj{Potential new subsection: Experience. If you look at technologies historically, there are social effects like the Walkman effect, in which some of the public acceptance and social norms requires experience and public deployment of the device, there is only so much we can do in education and surveying users, as the perspectives can start to change once users actually try out the technology. So actually using, experiencing devices and seeing a societal shift in where the devices have benefits and trends towards adoption may be a necessary direction to achieve the goals you are targeting in this future directions section}
%\bo{Thanks, Brendan. I think this is a good subsection to have.}

\section{CONCLUSION}
Bystander concerns about privacy in public situations have been shown to be crucial to the wide acceptance of MR devices. Technical solutions to this suffer from a lack of context or viability on modern MR devices but 
make making progress towards easing bystander concern with advances such as explicit consent mechanisms or implicit contextual understanding. However, much work is still needed to fully understand the impact of the bystander privacy problem on future devices, and also in designing more efficient and viable solutions. We believe that these potential future solutions can reduce the public apprehension that has plagued devices in the past, and make the devices that support the Metaverse more prolific and less controversial. If so, we move even closer to the ultimate promise of the Metaverse.

%\bdj{this reads pretty negatively. A re-framing is that the technical problem is sufficiently difficult, with the latest solutions making progress in X and Y, but still needing work on Z}
\vspace*{-8pt}


\section{ACKNOWLEDGMENTS}

This work was supported under NSF grants 2112778 and 2153397 and by the Commonwealth Cyber Initiative (CCI). 

\def\refname{REFERENCES}

%\begin{thebibliography}{1}

\bibliographystyle{IEEEtran}
\bibliography{BystanderPrivacy}


\end{document}

