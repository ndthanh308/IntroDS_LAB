{
  "2406-10774": {
    "title": "Quest: Query-Aware Sparsity for Efficient Long-Context LLM Inference",
    "authors": [
      "Jiaming Tang",
      "Yilong Zhao",
      "Kan Zhu",
      "Guangxuan Xiao",
      "Baris Kasikci",
      "Song Han"
    ],
    "submission_date": "2024-06-16",
    "semantic_scholar_id": "1c7db9fb18246787fbe3de6e0eaa370ae749e795"
  },
  "2405-14366": {
    "title": "MiniCache: KV Cache Compression in Depth Dimension for Large Language Models",
    "authors": [
      "Akide Liu",
      "Jing Liu",
      "Zizheng Pan",
      "Yefei He",
      "Gholamreza Haffari",
      "Bohan Zhuang"
    ],
    "submission_date": "2024-05-23",
    "semantic_scholar_id": "d372fb69c485472385f152bc832bf1d35e223324"
  },
  "2404-06654": {
    "title": "RULER: What's the Real Context Size of Your Long-Context Language Models?",
    "authors": [
      "Cheng-Ping Hsieh",
      "Simeng Sun",
      "Samuel Kriman",
      "Shantanu Acharya",
      "Dima Rekesh",
      "Fei Jia",
      "Boris Ginsburg"
    ],
    "submission_date": "2024-04-09",
    "semantic_scholar_id": "ac5824e9ff924a937d9eef379d0b581de2417678"
  },
  "2402-13718": {
    "title": "∞Bench: Extending Long Context Evaluation Beyond 100K Tokens",
    "authors": [
      "Xinrong Zhang",
      "Yingfa Chen",
      "Shengding Hu",
      "Zihang Xu",
      "Junhao Chen",
      "Moo Khai Hao",
      "Xu Han",
      "Z. Thai",
      "Shuo Wang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "submission_date": "2024-02-21",
    "semantic_scholar_id": "f05e84702562cb693dd68d3d1c88072519a7bd71"
  },
  "2402-08268": {
    "title": "World Model on Million-Length Video And Language With Blockwise RingAttention",
    "authors": [
      "Hao Liu",
      "Wilson Yan",
      "Matei Zaharia",
      "Pieter Abbeel"
    ],
    "submission_date": "2024-02-13",
    "semantic_scholar_id": "db7498f569be9852a04b2bb5bd68bd2885820bea"
  },
  "2401-06104": {
    "title": "Transformers are Multi-State RNNs",
    "authors": [
      "Matanel Oren",
      "Michael Hassid",
      "Yossi Adi",
      "Roy Schwartz"
    ],
    "submission_date": "2024-01-11",
    "semantic_scholar_id": "3e8d4062ec4353ff2701c7769336dbdb97f8814c"
  },
  "2312-04985": {
    "title": "SparQ Attention: Bandwidth-Efficient LLM Inference",
    "authors": [
      "Luka Ribar",
      "Ivan Chelombiev",
      "Luke Hudlass-Galley",
      "Charlie Blake",
      "Carlo Luschi",
      "Douglas Orr"
    ],
    "submission_date": "2023-12-08",
    "semantic_scholar_id": "713806165610c237f551a7b68e6b09b3ded75502"
  },
  "2310-17157": {
    "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time",
    "authors": [
      "Zichang Liu",
      "Jue Wang",
      "Tri Dao",
      "Tianyi Zhou",
      "Binhang Yuan",
      "Zhao Song",
      "Anshumali Shrivastava",
      "Ce Zhang",
      "Yuandong Tian",
      "Christopher Ré",
      "Beidi Chen"
    ],
    "submission_date": "2023-10-26",
    "semantic_scholar_id": "95240dda409e28acccdc5cf619ad0c036cf4292d"
  },
  "2310-06825": {
    "title": "Mistral 7B",
    "authors": [
      "Albert Qiaochu Jiang",
      "Alexandre Sablayrolles",
      "A. Mensch",
      "Chris Bamford",
      "Devendra Singh Chaplot",
      "Diego de Las Casas",
      "Florian Bressand",
      "Gianna Lengyel",
      "Guillaume Lample",
      "Lucile Saulnier",
      "Lélio Renard Lavaud",
      "M. Lachaux",
      "Pierre Stock",
      "Teven Le Scao",
      "Thibaut Lavril",
      "Thomas Wang",
      "Timothée Lacroix",
      "William El Sayed"
    ],
    "submission_date": "2023-10-10",
    "semantic_scholar_id": "db633c6b1c286c0386f0078d8a2e6224e03a6227"
  },
  "2310-05869": {
    "title": "HyperAttention: Long-context Attention in Near-Linear Time",
    "authors": [
      "Insu Han",
      "Rajesh Jayaram",
      "Amin Karbasi",
      "V. Mirrokni",
      "David P. Woodruff",
      "A. Zandieh"
    ],
    "submission_date": "2023-10-09",
    "semantic_scholar_id": "93e58491830abe1eb965ab37ec64fa97263f6048"
  },
  "2310-05209": {
    "title": "Scaling Laws of RoPE-based Extrapolation",
    "authors": [
      "Xiaoran Liu",
      "Hang Yan",
      "Shuo Zhang",
      "Chen An",
      "Xipeng Qiu",
      "Dahua Lin"
    ],
    "submission_date": "2023-10-08",
    "semantic_scholar_id": "539fadfb615ef84c240f4741061c44eeda540091"
  },
  "2310-01801": {
    "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs",
    "authors": [
      "Suyu Ge",
      "Yunan Zhang",
      "Liyuan Liu",
      "Minjia Zhang",
      "Jiawei Han",
      "Jianfeng Gao"
    ],
    "submission_date": "2023-10-03",
    "semantic_scholar_id": "6c323c535365e1c7cbfd9703cbec3b5650a3346b"
  },
  "2309-17453": {
    "title": "Efficient Streaming Language Models with Attention Sinks",
    "authors": [
      "Guangxuan Xiao",
      "Yuandong Tian",
      "Beidi Chen",
      "Song Han",
      "Mike Lewis"
    ],
    "submission_date": "2023-09-29",
    "semantic_scholar_id": "fdc53c2c10742464087c0525f77e32604827a21d"
  },
  "2309-16609": {
    "title": "Qwen Technical Report",
    "authors": [
      "Jinze Bai",
      "Shuai Bai",
      "Yunfei Chu",
      "Zeyu Cui",
      "Kai Dang",
      "Xiaodong Deng",
      "Yang Fan",
      "Wenhang Ge",
      "Yu Han",
      "Fei Huang",
      "Binyuan Hui",
      "Luo Ji",
      "Mei Li",
      "Junyang Lin",
      "Runji Lin",
      "Dayiheng Liu",
      "Gao Liu",
      "Chengqiang Lu",
      "K. Lu",
      "Jianxin Ma",
      "Rui Men",
      "Xingzhang Ren",
      "Xuancheng Ren",
      "Chuanqi Tan",
      "Sinan Tan",
      "Jianhong Tu",
      "Peng Wang",
      "Shijie Wang",
      "Wei Wang",
      "Shengguang Wu",
      "Benfeng Xu",
      "Jin Xu",
      "An Yang",
      "Hao Yang",
      "Jian Yang",
      "Jian Yang",
      "Shusheng Yang",
      "Yang Yao",
      "Bowen Yu",
      "Yu Bowen",
      "Hongyi Yuan",
      "Zheng Yuan",
      "Jianwei Zhang",
      "Xing Zhang",
      "Yichang Zhang",
      "Zhenru Zhang",
      "Chang Zhou",
      "Jingren Zhou",
      "Xiaohuan Zhou",
      "Tianhang Zhu"
    ],
    "submission_date": "2023-09-28",
    "semantic_scholar_id": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0"
  },
  "2309-06180": {
    "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention",
    "authors": [
      "Woosuk Kwon",
      "Zhuohan Li",
      "Siyuan Zhuang",
      "Ying Sheng",
      "Lianmin Zheng",
      "Cody Hao Yu",
      "Joseph E. Gonzalez",
      "Haotong Zhang",
      "Ion Stoica"
    ],
    "submission_date": "2023-09-12",
    "semantic_scholar_id": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05"
  },
  "2307-03172": {
    "title": "Lost in the Middle: How Language Models Use Long Contexts",
    "authors": [
      "Nelson F. Liu",
      "Kevin Lin",
      "John Hewitt",
      "Ashwin Paranjape",
      "Michele Bevilacqua",
      "F. Petroni",
      "Percy Liang"
    ],
    "submission_date": "2023-07-06",
    "semantic_scholar_id": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5"
  },
  "2306-15595": {
    "title": "Extending Context Window of Large Language Models via Positional Interpolation",
    "authors": [
      "Shouyuan Chen",
      "Sherman Wong",
      "Liangjian Chen",
      "Yuandong Tian"
    ],
    "submission_date": "2023-06-27",
    "semantic_scholar_id": "f5afaccfe90268485a9961c5771ec5e71e9b806c"
  },
  "2306-14893": {
    "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion",
    "authors": [
      "Daya Guo",
      "Canwen Xu",
      "Nan Duan",
      "Jian Yin",
      "Julian McAuley"
    ],
    "submission_date": "2023-06-26",
    "semantic_scholar_id": "2a09ebbfcca1a6994eeb472cd4159f5f3858dbf9"
  },
  "2306-14048": {
    "title": "H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
    "authors": [
      "Zhenyu (Allen) Zhang",
      "Ying Sheng",
      "Tianyi Zhou",
      "Tianlong Chen",
      "Lianmin Zheng",
      "Ruisi Cai",
      "Zhao Song",
      "Yuandong Tian",
      "Christopher Ré",
      "Clark W. Barrett",
      "Zhangyang Wang",
      "Beidi Chen"
    ],
    "submission_date": "2023-06-24",
    "semantic_scholar_id": "e586a4591ba0303b769f2c07cbddaf1899cb72e4"
  },
  "2306-12929": {
    "title": "Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing",
    "authors": [
      "Yelysei Bondarenko",
      "Markus Nagel",
      "Tijmen Blankevoort"
    ],
    "submission_date": "2023-06-22",
    "semantic_scholar_id": "d193675b92fbfbf22ed82fda35cd2e73587e33bd"
  },
  "2305-19466": {
    "title": "The Impact of Positional Encoding on Length Generalization in Transformers",
    "authors": [
      "Amirhossein Kazemnejad",
      "Inkit Padhi",
      "K. Ramamurthy",
      "Payel Das",
      "Siva Reddy"
    ],
    "submission_date": "2023-05-31",
    "semantic_scholar_id": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4"
  },
  "2305-16300": {
    "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers",
    "authors": [
      "Amirkeivan Mohtashami",
      "Martin Jaggi"
    ],
    "submission_date": "2023-05-25",
    "semantic_scholar_id": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed"
  },
  "2305-13245": {
    "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
    "authors": [
      "J. Ainslie",
      "J. Lee-Thorp",
      "Michiel de Jong",
      "Yury Zemlyanskiy",
      "Federico Lebr'on",
      "Sumit K. Sanghai"
    ],
    "submission_date": "2023-05-22",
    "semantic_scholar_id": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200"
  },
  "2305-05280": {
    "title": "VCSUM: A Versatile Chinese Meeting Summarization Dataset",
    "authors": [
      "Han Wu",
      "Mingjie Zhan",
      "Haochen Tan",
      "Zhaohui Hou",
      "Ding Liang",
      "Linqi Song"
    ],
    "submission_date": "2023-05-09",
    "semantic_scholar_id": "61fa56fbdb3b7668a0ac1b895312a9c7bca682e4"
  },
  "2304-07493": {
    "title": "OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization",
    "authors": [
      "Cong Guo",
      "Jiaming Tang",
      "Weiming Hu",
      "Jingwen Leng",
      "Chen Zhang",
      "Fan Yang",
      "Yun-Bo Liu",
      "Minyi Guo",
      "Yuhao Zhu"
    ],
    "submission_date": "2023-04-15",
    "semantic_scholar_id": "e92a5332390f0ba94615935541da4da9bed56512"
  },
  "2212-10560": {
    "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    "authors": [
      "Yizhong Wang",
      "Yeganeh Kordi",
      "Swaroop Mishra",
      "Alisa Liu",
      "Noah A. Smith",
      "Daniel Khashabi",
      "Hannaneh Hajishirzi"
    ],
    "submission_date": "2022-12-20",
    "semantic_scholar_id": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb"
  },
  "2212-02027": {
    "title": "Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer",
    "authors": [
      "Zhengbao Jiang",
      "Luyu Gao",
      "J. Araki",
      "Haibo Ding",
      "Zhiruo Wang",
      "Jamie Callan",
      "Graham Neubig"
    ],
    "submission_date": "2022-12-05",
    "semantic_scholar_id": "87126a964ed14d0d2207747fc732b197e2fc9493"
  },
  "2208-03299": {
    "title": "Few-shot Learning with Retrieval Augmented Language Models",
    "authors": [
      "Gautier Izacard",
      "Patrick Lewis",
      "M. Lomeli",
      "Lucas Hosseini",
      "F. Petroni",
      "Timo Schick",
      "Jane A. Yu",
      "Armand Joulin",
      "Sebastian Riedel",
      "Edouard Grave"
    ],
    "submission_date": "2022-08-05",
    "semantic_scholar_id": "916be31cbf847faa65cad0549e153f0c25b9f424"
  },
  "2205-14135": {
    "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",
    "authors": [
      "Tri Dao",
      "Daniel Y. Fu",
      "Stefano Ermon",
      "A. Rudra",
      "Christopher R'e"
    ],
    "submission_date": "2022-05-27",
    "semantic_scholar_id": "87c5b281fa43e6f27191b20a8dd694eda1126336"
  },
  "2203-15556": {
    "title": "Training Compute-Optimal Large Language Models",
    "authors": [
      "Jordan Hoffmann",
      "Sebastian Borgeaud",
      "A. Mensch",
      "Elena Buchatskaya",
      "Trevor Cai",
      "Eliza Rutherford",
      "Diego de Las Casas",
      "Lisa Anne Hendricks",
      "Johannes Welbl",
      "Aidan Clark",
      "Tom Hennigan",
      "Eric Noland",
      "Katie Millican",
      "George van den Driessche",
      "Bogdan Damoc",
      "Aurelia Guy",
      "Simon Osindero",
      "K. Simonyan",
      "Erich Elsen",
      "Jack W. Rae",
      "O. Vinyals",
      "L. Sifre"
    ],
    "submission_date": "2022-03-29",
    "semantic_scholar_id": "8342b592fe238f3d230e4959b06fd10153c45db1"
  },
  "2201-11903": {
    "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "authors": [
      "Jason Wei",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Maarten Bosma",
      "Ed H. Chi",
      "F. Xia",
      "Quoc Le",
      "Denny Zhou"
    ],
    "submission_date": "2022-01-28",
    "semantic_scholar_id": "1b6e810ce0afd0dd093f789d2b2742d047e316d5"
  },
  "2112-00114": {
    "title": "Show Your Work: Scratchpads for Intermediate Computation with Language Models",
    "authors": [
      "Maxwell Nye",
      "Anders Andreassen",
      "Guy Gur-Ari",
      "H. Michalewski",
      "Jacob Austin",
      "David Bieber",
      "David Dohan",
      "Aitor Lewkowycz",
      "Maarten Bosma",
      "D. Luan",
      "Charles Sutton",
      "Augustus Odena"
    ],
    "submission_date": "2021-11-30",
    "semantic_scholar_id": "92173d081b15824d22a9ef070e118744ceee8052"
  },
  "2108-12409": {
    "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation",
    "authors": [
      "Ofir Press",
      "Noah A. Smith",
      "M. Lewis"
    ],
    "submission_date": "2021-08-27",
    "semantic_scholar_id": "9ca329408813d209b1dcb36936f7f9cba82506bd"
  },
  "2108-08877": {
    "title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models",
    "authors": [
      "Jianmo Ni",
      "Gustavo Hernández Abrego",
      "Noah Constant",
      "Ji Ma",
      "Keith B. Hall",
      "Daniel Matthew Cer",
      "Yinfei Yang"
    ],
    "submission_date": "2021-08-19",
    "semantic_scholar_id": "dbe87b171bfb789e1d22a047aeeee69105e6fd02"
  },
  "2105-03011": {
    "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers",
    "authors": [
      "Pradeep Dasigi",
      "Kyle Lo",
      "Iz Beltagy",
      "Arman Cohan",
      "Noah A. Smith",
      "Matt Gardner"
    ],
    "submission_date": "2021-05-07",
    "semantic_scholar_id": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044"
  },
  "2104-09864": {
    "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding",
    "authors": [
      "Jianlin Su",
      "Yu Lu",
      "Shengfeng Pan",
      "Bo Wen",
      "Yunfeng Liu"
    ],
    "submission_date": "2021-04-20",
    "semantic_scholar_id": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4"
  },
  "2104-02112": {
    "title": "Efficient Attentions for Long Document Summarization",
    "authors": [
      "L. Huang",
      "Shuyang Cao",
      "Nikolaus Nova Parulian",
      "Heng Ji",
      "Lu Wang"
    ],
    "submission_date": "2021-04-05",
    "semantic_scholar_id": "9dc624d7258d1a56117ca720aea953ce46b66b21"
  },
  "2011-06700": {
    "title": "Deep Reinforcement Learning of Transition States",
    "authors": [
      "Jun Zhang",
      "Yao-Kun Lei",
      "Zhen Zhang",
      "Xu Han",
      "Maodong Li",
      "Lijiang Yang",
      "Y. Yang",
      "Y. Gao"
    ],
    "submission_date": "2020-11-13",
    "semantic_scholar_id": "70e5771c9c8e0ef2d7535d63a3b111c94696a7a6"
  },
  "2004-04906": {
    "title": "Dense Passage Retrieval for Open-Domain Question Answering",
    "authors": [
      "Vladimir Karpukhin",
      "Barlas Oğuz",
      "Sewon Min",
      "Patrick Lewis",
      "Ledell Yu Wu",
      "Sergey Edunov",
      "Danqi Chen",
      "Wen-tau Yih"
    ],
    "submission_date": "2020-04-10",
    "semantic_scholar_id": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee"
  },
  "1911-12237": {
    "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization",
    "authors": [
      "Bogdan Gliwa",
      "Iwona Mochol",
      "M. Biesek",
      "A. Wawer"
    ],
    "submission_date": "2019-11-27",
    "semantic_scholar_id": "f9700e31a1d0ae34d4571ab056dfb268c1543349"
  },
  "1911-05507": {
    "title": "Compressive Transformers for Long-Range Sequence Modelling",
    "authors": [
      "Jack W. Rae",
      "Anna Potapenko",
      "Siddhant M. Jayakumar",
      "T. Lillicrap"
    ],
    "submission_date": "2019-11-13",
    "semantic_scholar_id": "f51497f463566581874c941353dd9d80069c5b77"
  },
  "1809-09600": {
    "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",
    "authors": [
      "Zhilin Yang",
      "Peng Qi",
      "Saizheng Zhang",
      "Yoshua Bengio",
      "William W. Cohen",
      "R. Salakhutdinov",
      "Christopher D. Manning"
    ],
    "submission_date": "2018-09-25",
    "semantic_scholar_id": "22655979df781d222eaf812b0d325fa9adf11594"
  },
  "1808-08745": {
    "title": "Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",
    "authors": [
      "Shashi Narayan",
      "Shay B. Cohen",
      "Mirella Lapata"
    ],
    "submission_date": "2018-08-27",
    "semantic_scholar_id": "305b2cf37e5dece81e95c92883d5a6e28ac93b22"
  },
  "1712-07040": {
    "title": "The NarrativeQA Reading Comprehension Challenge",
    "authors": [
      "Tomás Kociský",
      "Jonathan Schwarz",
      "Phil Blunsom",
      "Chris Dyer",
      "Karl Moritz Hermann",
      "Gábor Melis",
      "Edward Grefenstette"
    ],
    "submission_date": "2017-12-19",
    "semantic_scholar_id": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a"
  },
  "1705-03551": {
    "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    "authors": [
      "Mandar Joshi",
      "Eunsol Choi",
      "Daniel S. Weld",
      "Luke Zettlemoyer"
    ],
    "submission_date": "2017-05-01",
    "semantic_scholar_id": "f010affab57b5fcf1cd6be23df79d8ec98c7289c"
  }
}