

\subsection{Scene Reconstruction}
Scene reconstruction refers to the problem of estimating the 3D geometry of an environment, usually containing multiple objects, from a single image. While object reconstruction, completing the 3D geometry of a single object, is well-studied, scene reconstruction is explored in limited settings.  Previously, much of the work in scene completion focused on either room scales~\cite{song2017semantic, dai2018scancomplete}, or in autonomous driving settings~\cite{cheng2021s3cnet, rist2021semantic, cao2022monoscene} where the scene geometries are usually more structured. In our paper, we focus on an object-level scale, specifically tabletop environments, where objects can be in cluttered configurations.  While methods like Mesh R-CNN~\cite{gkioxari2019mesh}, CoReNet~\cite{popov2020corenet} and CenterSnap~\cite{irshad2022centersnap} 
show accurate reconstruction of objects at the scene level, they do not show generalization capabilities to objects in novel categories. 
Recently,~\cite{wu2023multiview} introduced a method for reconstructing 3D geometries of objects and scenes of unseen categories, and demonstrated strong generalization performance to objects in-the-wild. However, different from our setting, they mostly focus on isolated objects and scenes with little to no clutter. In contrast, our method can reconstruct geometries and textures of complex scenes with objects from novel categories under heavy occlusions, as we show in our experiments.



\subsection{Inpainting}
Inpainting is the process of filling in missing areas of images.  
Traditionally, inpainting methods made use of image priors such as self-similarity for tasks like image restoration, where gaps with missing or corrupt values to be filled are usually small holes.
Deep learning methods, on the other hand, using large amounts of training data achieved remarkable success for inpainting images with semantically consistent contents.
Generative adversarial networks~\cite{goodfellow2020generative}, for example, were shown to handle many challenging inverse problems, including image denoising~\cite{chen2018image}, super-resolution~\cite{ledig2017photo}, and inpainting~\cite{pathak2016context, iizuka2017globally, zhao2021large}.
% \todo{While inpainting was typically done using, ... .  Deep learning methods such as ... also demonstrated improvement with inpainting capabilities in similar images the models had been trained on
% \url{https://openaccess.thecvf.com/content_cvpr_2017/papers/Yeh_Semantic_Image_Inpainting_CVPR_2017_paper.pdf}
% ~\cite{yeh2017semantic}.}
More recently, resulting from the growth of visual language diffusion models, inpainting through image diffusion has also taken off~\cite{ramesh2022hierarchical}. These models, having been trained on millions of images, have demonstrated their ability to generalize to many different objects, scenes, and styles. In this paper, we develop a process to use a visual language diffusion model for inpainting cluttered scenes involving heavy occlusions.





\subsection{Text-to-3D Synthesis}
Another area that is currently rapidly being explored is that of shape completion using visual-language models with a combination of neural radiance fields (NeRF)~\cite{mildenhall2021nerf}.  Papers such as~\cite{jain2022zero, poole2022dreamfusion, lin2022magic3d} demonstrate the ability to generate 3D models of very diverse objects from merely a text description.  While the objects these methods can render may appear very realistic, they are not grounded to any real world geometry, so may not be as useful when estimating the shape of real objects.  To overcome this limitation, papers such as~\cite{xu2022neurallift, melas2023realfusion} extend these methods to reconstruct based on a ground truth reference image. These papers demonstrate high accuracy on individual objects, but do not demonstrate the ability to reconstruct multiple objects in cluttered scenes.  While runtime is a concern for these methods, as optimizing neural radiance fields can take up to an hour to produce realistic results, even newer methods attempt to produce faster results by optimization without NeRF~\cite{nichol2022point}.  While better optimized for speed, this method is still limited in focus to only single object reconstruction and does not directly generalize to the setting we study in this paper.