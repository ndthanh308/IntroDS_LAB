We presented \ours{}, a novel method for 3D scene reconstruction. 
\ours{} solves the problem of 3D reconstruction of a cluttered scene of novel objects by leveraging the generalization capabilities of large visual language models. More specifically, our method utilizes the 2D inpainting capabilities of \dalle{} and generates a coherent set of inpainted views of the scene. It then lifts that information into 3D through a novel geometric multi-step method to finally output the point cloud of the reconstructed scene.

While we demonstrate the effectiveness of our method for generalizable scene completion, we also note that \dalle{} can generate unrealistic objects and parts of objects in the inpainted images. We mitigate this issue through various ways described in our method section, but these irregularities can adversely affect the reconstruction quality in a few cases.
%
While \ours{} shows the ability to complete the front and sides of objects in our scene, the backside of objects is often left incomplete due inpainting requiring enough context to accurately reconstruct the scene. At large angles away from the original viewpoint, the inpainting quality degrades due to the large areas of missing information - an exciting yet challenging problem for future work.
