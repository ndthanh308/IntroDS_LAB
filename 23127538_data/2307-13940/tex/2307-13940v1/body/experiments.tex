In this section, we assess the performance of using \wects to represent images generated under
different weight distributions for the pixel intensities, different domain shapes,
and different function extensions for assigning weights to the simplexes.
We then build classification models for each pair of image types in order to
evaluate the informativeness of \wects.
Rather than seeking to minimize the misclassification rate,
the goal is to understand how changing intensity distributions affects the classification performance.
% The performance of \wects is compared to the performance using the same classification model (i.e., support vector machines), but with different inputs, namely, (unweighted) ECTs and the original image \jessi{Assuming we do these comparsons}.
% \jessi{We also compute the estimated \wect for each of the images settings investigated.}

%

\subsection{Data Sets}
We generated image datasets
using the following parameters: shape, pixel intensity distribution,
and function extension (see Equations~\eqref{eqn:max_extension}-\eqref{eqn:avg_extension}).
The domain of an image is a $65\times 65$ grid centered at $(0,0)$,
with vertices on an integer lattice, triangulated using the Freudenthal triangulation~\cite{freudenthal}; see
\subfigref{image}{tri}.


% Figure environment removed
%
\paragraph{Shape.}
%
The \emph{shapes} are the domain of the image pixels with positive intensity.
We consider the following shapes:  disc, annulus, square, Tetris, clusters, and Swiss
cheese; see \figref{shapes} for example images of these shapes.
% \camera{should we not have distribution showing here too? - BTF}
%
When creating these shapes, we ensure that
they have approximately the same number of non-zero pixel intensities  (of the
$4225$ pixels in the $65 \times 65$ grid); see
\tabref{nonzeroPixels}.
%
\begin{table}[]
    \centering
    \caption{Number of nonzero pixels for each shape in the $65\times65$ grid.}
    \label{tab:nonzeroPixels}
    \begin{tabular}{r|llll}
        \hline
        Shape & Nonzero Pixels \\
        \hline
        Disc & $1257$ \\
        Square & $1225$ \\
        Tetris & $1249$ \\
        Annulus & $1212$ \\
        Clusters & $1125$ \\
        Swiss Cheese & $1495$ \\
        Square Annulus & $1296$ \\
    \end{tabular}
\end{table}

%
% Figure environment removed
%
\paragraph{Pixel Intensity.}
We consider four weight distributions for the pixel intensities:  a uniform and three truncated normal distribution with
different standard deviations.
The uniform distribution takes values greater in the interval~$(0,1]$, and is
denoted~$U(0,1)$.
The truncated normal is centered at $\mu=0.5$ with a standard deviation of
$\sigma$, $N(0.5, \sigma)$, and truncated to take values in the interval~$(0,1]$.
The $\sigma$ takes three values so that $\mu \pm i \sigma$, for~$i=1,2,3$, is
(approximately) the support, $(0,1]$; in other words, we consider the
distributions~$N(0.5, 0.17)$, $N(0.5, 0.25)$, and $N(0.5, 0.5)$.
\figref{pixel_distributions} displays the probability densities for these distributions.
Notice that as the $\sigma$ increases, the distribution of the weights looks
more like those of a~$U(0,1)$,
and therefore, when doing binary classification, the misclassification rate
should increase as~$U(0,1)$ is compared to~$N(0.5,\sigma)$ with $\sigma$
increasing.
\figref{image-annulus} includes an example of an annulus with pixel intensities
drawn from a~$U(0,1)$
distribution and from a~$N(0.5, 0.17)$ distribution.
%
% Figure environment removed
%

\paragraph{Function Extension.}
For these experiments, we consider the maximum and average extensions
(Equations~\eqref{eqn:max_extension} and \eqref{eqn:avg_extension}, respectively) for the weight functions to evaluate differences in classification performance.



\subsection{Classification Methods}

The seven shapes, four distributions, and two function extensions define 56 image classes.
The \wect is evaluated on the task of binary classification using support vector machines (SVM)~\cite{cortes1995support}
and $K$-nearest-neighbors \cite{knn1951}.
For each classification model, 250 images (half from each class) are independently generated,
with 80 percent of the images (200 images) used for training and the remaining 20 percent (50 images) used for testing.
To approximate the \wect, we sample equally-spaced directions
from $\sph^1$.
We discuss results below for choosing different numbers of directions from $\sph^1$.
To vectorize each \fwec,~$91$ equally-spaced threshold values from $-45$ to $45$ are considered.
This ensures that there is at least one discretization value for each height threshold in any direction
of filtration.

\paragraph{Implementation.}
The simulation study was implemented in Python, using the Dionysus~2 library~\cite{dionysus2}.
For classification tasks using SVM, we train an SVM separately for each binary classification model.
All SVMs in this work use a regularization parameter of value 20.
The classification was done using an SVM classifier library from Scikit-learn \cite{scikit-learn}.
For classification tasks using $K$-nearest-neighbors, a simple Python implmentation was created using
our implementation of the \wect distance function.

\subsection{Results}


% Figure environment removed
%
To better understand the \wect, we considered several experiments
that provide insight into how different factors affect the \wect and
the information it encodes.
In particular, we analyze changes in the number of directions, pixel intensity distributions,
function extensions, and use of the \wect vs.\ the vectorized \wect.
However, first, as \figref{square-expectation} demonstrates, we verify that for all four pixel intensity
distributions, the computation of the \wect  matches the theoretical expectation
given in \eqnref{expWECTSquare}.

% Figure environment removed
%
Next, we analyze how changing the number of directions of the filtration impacts
the ability of the \wect to capture information about the underlying image.
In order to do so, the following classification task was executed using the SVM classifier.
For each shape, the~$U(0,1)$ image was compared against the
$N(0.5,25)$ in a binary classification task for a varying number of directions.
The average function extension was used when computing the \wects.
For a given shape, if the \wect successfully encoded the structure of the two different images, the classification
accuracy is closer to one.
The classifier accuracy was tested on all the shapes for $2,3,5,8,15$ and $30$ directions.
As \figref{changing-directions} shows, as the number of directions increases,
accuracy of the classifier improved only for some shapes.
In order to balance an increase of encoded information in the \wect with computational cost,
the remainder of the experiments are executed using 15 directions.

% Figure environment removed
%
In order to gain a deeper understanding of the \wect properties, we conducted experiments to observe how changing pixel
intensity distributions in various filtration directions affect its behavior.
Again, we examined the \wect's capacity to extract image information through binary
classification tasks using an SVM classifier.
For each shape, we consider the task of binary classification of \wects in $15$ directions from each of the four distributions
against the \wect from the $U(0,1)$ distribution.
All pairwise classification models were considered, but when image shape differed the
classifier performed nearly perfect regardless of the pixel intensity distribution so those results are not summarized further.
Results where the two classes have the same shape can be found in \figref{pairwiseResults} for both function extensions.
As anticipated, the accuracy of the classifier for~$U(0,1)$ against~$U(0,1)$ is
roughly random,~$U(0,1)$ against~$N(0.5, 0.17)$ is nearly perfect,~$U(0,1)$ against $N(0.5, 0.25)$ is slightly worse,
and~$U(0,1)$ against $N(0.5, 0.5)$ is barely better than random.
Ultimately, the decrease in accuracy as the normal distribution becomes more similar to the uniform distribution (i.e., as $\sigma$ increases)
demonstrates that the \wect encodes information about the pixel intensity distribution.
In other words, \emph{the \wect captures and encodes structural information from the images that is not encoded by the ECT.}

Next, we compare the results using the maximum function extension (\figref{pairwiseResultsMaxFE})
and the average function extension (\figref{pairwiseResultsAvgFE}).
Overall, across nearly all the distributions, the classifier performs better
on \wects computed using the maximum function extension as opposed to the average function extension.
As the distributions differ more at their extremes in the current setting, it is likely that
the maximum function extension better emphasizes these differences, which in turn increases the
accuracy of the~classifier.

% Additionally, we analyze how the number of directions used in the filtration
% impacts the ability of the \wect to capture information.
% For this experiment, the disc and Tetris shapes were selected for comparison as the structure of the disc is similar from every direction, while the structure of the Tetris is not.
% For each of these two shapes, a binary classification task was performed with
% each of the four distributions against the shape with pixel intensities from
% the $U(0,1) distribution.
% The experiment was carried out for both function extensions, and the results are displayed in Figure \ref{fig:8vs15results}.
% As before, using the maximum function extension results in the classifier performing slightly better.
% When comparing the disc against the Tetris, there are not large differences in the classification results when the number of directions is increased.
% This indicates that the \wects computed in 15 directions do not capture more
% structural information than the \wects computed in eight directions, even for the Tetris shape.
% However, in the average function extension experiment classifying
% $N(0.5,0.25)$ against $U(0,1)$, increasing the number of directions increased the accuracy of the classifier.
% This provides another indication that the \wect captures information about the
% underlying distribution, and that increasing the number of directions
% emphasizes the encoding of the distribution in the \wect.


% % Figure environment removed

% Figure environment removed
%
To better understand the classification performance in the above experiments,
we consider visualizations of the \wect for the setting that considers fifteen directions.
\figref{square_avgwect} displays the average \wect
in one direction of 250 generated images under the two different function extensions.
The shaded region indicates the values within one standard deviation of the mean.
For both function extensions, the average \wect generally follows the same pattern,
but the values of the \wect depend on the distribution of the pixel intensities.
The \wect using the $U(0,1)$ distribution generally has the lowest values,
and the \wect using the $N(0.50, 0.50)$ and distribution tends to have slightly greater values, then
$N(0.50, 0.25)$, and finally the $N(0.50, 0.17)$ distribution tends to have the highest values.
These results hold also for the rest of the shapes, as indicated in \figref{maxwect_mean} and \figref{avgwect_mean}.
This, along with the classification results, indicate that incorporating the weights into the ECT is important for
distinguishing images generated under different intensity distributions.
Note also that the average \wect for different shape classes have varying levels and patterns of smoothness, which reveals why the
classification rate between different shapes is nearly perfect.
%
% Figure environment removed
%
% Figure environment removed

% Figure environment removed
%
A final result is the use of the
true (non-vectorized) \wect in the classification experiments.
As explained in Section~\ref{par:distances}, one can compute a distance between
two \wects by integrating the difference between the piecewise \wecfs in each direction
(and taking the maximum difference across all directions).
Thus, a natural extension use of this distance is in a nonparametric classification
method such as $K$-nearest-neighbors (KNN).
\figref{knnsvm} summarizes results for the KNN classifier
based on the \wect distance with $K=5$ for eight directions with the maximum extension.
In general, it appears that performance of SVM was better in these binary classification tasks.
Extensive experiments with KNN were less feasible due to the high computational
cost of nonparametric methods.
However, the focus is not on using the \wect as a classifier, but instead
using the classification tasks to understand the information that is encoded in
the \wect.
For both methods, we observe a decrease in accuracy as the pixel intensity distribution becomes more similar,
which indicates that both the vectorized \wect and the \wect distance successfully encode
underlying information about the image.

% % Figure environment removed
