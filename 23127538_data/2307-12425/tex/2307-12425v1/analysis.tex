\section{Analysis}
\label{analysis}

% \subsection{Performance bounds}

% % Write out perfomance bounds with sample complexity terms (with N)
% \begin{enumerate}
%     \item DT performance bound
%     \item Q-learning performance bound
%     \item TF-Top performance bound
% \end{enumerate}

\subsection{Performance of DT vs Q-learning}
\begin{enumerate}
    \item Compare trade-offs between the two. Highlight that in general, we expect Q-learning to be better because of it's stitching ability. Mention why that is not reflected in current application.
    \item Introduce the Tree MDP. Motivate connection to the current application. 
    \item State intuitively why for such a tree MDP, DT and Q-learning should be equivalent in terms of performance
    \item Show theoretically they are same up to polynomial terms
\end{enumerate}

% Three differences between DT vs TF Top
% 1. \eps_approx of DT is more than TF TOP ( a|s,g vs a|s )
% 2. Ratio mismatch should be similar (C_f / \alpha_f vs C_\rho)
% 3. TF Top worse sample complexity O(1/(1-\rho)N) vs O(1/N)
\subsection{Performance of DT vs TF Top}
\begin{enumerate}
    \item Compare trade-offs between the two (three points). Mention that while TF Top works with a simpler function class, it pays by throwing out data.
    \item Go back to the tree MDP and show conditions under which the two should be exactly the same. This is true when return = 0, teaches you nothing about return = 1. 
\end{enumerate}