% Figure environment removed

The process \eqref{eq:repetitive-process} is assumed to be nonlinear and unknown, as well its gradient and Hessian.
We assume it to be possible to evaluate \eqref{eq:repetitive-process}, and to have access to a model of the process either from first principles, experimental data or combinations of both, from which gradient and Hessian models can be derived. %
Our goal is to efficiently improve the quality of the output trajectory by leveraging the model information to reduce the number of experiments needed.

Driving the output of the repetitive process to the target geometry can be encoded as an optimization problem, where the cost function encodes the objective of tracking the target trajectory $\Target$ and the limits on input and output are framed as constraints.
The challenge is to incorporate process data into the optimization problem.
We can use tools from optimization theory to solve the nontrivial nonlinear constrained ILC problem.
In this work, we focus on adapting the SQP algorithm to compute the ILC updates.

We encode our control objective in the following optimization problem 
\begin{mini!}{z}{J(z)}{\label{eq:original-problem}}{}{\label{eq:original-problem-a}}%
	\addConstraint{h(z) \equiv p - f(u) }{= 0}{\label{eq:original-problem-b}}
	\addConstraint{g(z)}{\leq 0},
\end{mini!}%
where
$p$ is an optimization variable constrained by \eqref{eq:original-problem-b} to be equal to the noise-free system response $f(u)$,
$z = (u, p)$,
$\mathcal{U} \times \mathcal{Y} = \{z\,|\,g(z) \leq 0\}$, and
$J(z)$ is a function measuring the distance between the output and target trajectory (e.g., $J(z) = \|p - \Target\|$).

This is a nonlinear program, that we aim to solve using SQP. In SQP, we construct and solve a sequence of quadratic programs (QPs) that eventually converge to a solution of the original nonlinear problem. The Lagrangian associated with \eqref{eq:original-problem} is
\begin{equation}
	\mathcal{L}(z, \lambda, \sigma) = J(z) + \lambda^T h(z) + \sigma^T g(z),
\end{equation} 
and the standard quadratic subproblem is
\begin{mini!}{\Delta z}{\frac{1}{2} \Delta z\tp B \Delta z + \nabla J(z)\tp \Delta z }{\label{eq:qp-1}}{}
	\addConstraint{ \nabla h(z) \tp \Delta z + h(z)}{=0}
	\addConstraint{ \nabla g(z) \tp \Delta z + g(z)}{\leq 0},
\end{mini!} %
where $B \approx \nabla^2 \mathcal{L} (z, \lambda, \sigma)$ is an approximation for the Hessian of the Lagrangian.
We can use the primal-dual solution $(\Delta z^*,\lambda^*,\sigma^*)$  of the subproblem to construct the SQP-based ILC policy
\begin{equation}
	\mathcal{T}(z,\lambda,\sigma) = \begin{bmatrix}
	z + {\Delta z}^* \\
				\lambda^*\\
				\sigma^*
			\end{bmatrix}
\end{equation}

It is known that the iteration
\begin{equation}
	x_{k+1} = \mathcal{T}(x_k)
\end{equation}
where $x = (z,\lambda,\sigma)$ converges locally at a quadratic rate to minimizers of the original problem \eqref{eq:original-problem} that satisfy appropriate regularity conditions (e.g., the linear independence constraint qualification and strong second order sufficient conditions \cite{boggs1995sequential}).


We modify the SQP algorithm to design an ILC policy by incorporating data. 
	We assume that $f(u)$ is unknown but can be evaluated for any given $u_k$ by running an experiment leading to the output data $y_k = f(u_k) + w_k$  is corrupted by noise $w_k$.
Further, we assume to have access to approximations of the Jacobian and Hessian of the process derived from a system model
\begin{subequations}\label{eq:approximations}
\begin{align}
	F(u_k) & \approx \nabla f(u_k) \label{eq:gradient}\\ 
    H(u_k) & \approx \nabla^2 f(u_k) \label{eq:hessian} %
    \end{align}
\end{subequations}
We adapt \eqref{eq:qp-1} to deal with the fact that we do not have direct access to $f(u)$, replacing 
$h(z)$ with $p - y_k$, and
$\nabla h = [I~~-\nabla f]$ with $[I~~-F]$.
\if01
\begin{mini!}{\Delta z}{\frac{1}{2} \Delta z\tp \nabla^2 \mathcal{L}(z, \lambda, \sigma) \Delta z + \nabla J(z) \tp \Delta z}{\label{eq:qp-1}}{}
	\addConstraint{ [I~~-\nabla f] \tp \Delta z + p - y}{=0}
	\addConstraint{ \nabla g(z) \tp \Delta z + g(z)}{\leq 0}.
\end{mini!} %
\fi
\begin{mini!}{\!\Delta u, \Delta p}{\frac{1}{2}\! \dz\tp\! \begin{bmatrix} R & S \\ S\tp & Q\end{bmatrix} \!\dz\! \!+\!\! \begin{bmatrix} \nabla_u J \\ \nabla_p J \end{bmatrix}\tp \!\dz}{\label{eq:qp-2}}{\label{eq:qp-2a}}
	\addConstraint{ \Delta p }{= F(u_k) \Delta u + (y_k - p_k) \label{eq:qp-2b}}
    \addConstraint{ u_k + \Delta u}{\in \mathcal{U} \label{eq:qp-2c}}
    \addConstraint{ p_k + \Delta p}{\in \mathcal{Y} \label{eq:qp-2d}}
,\end{mini!} %
where
$R \approx \nabla^2_u \Lagrangian $, 
$S \approx \nabla^2_{y,u} \Lagrangian$, and 
$Q \approx \nabla^2_y \Lagrangian$.
The first term in \eqref{eq:qp-2b} imposes a linearized version of the dynamic constraint,
while the second term corrects the local estimate of the system output given the new measurement $y_k$.
Additionally, $R$ is constructed using the Hessian approximation $H(u_k)$.

Finally, we introduce a step size
$\eta_k$ as damping factor for the algorithm's iterates to encourage convergence; below we use a diminishing step size and provide simulation results on the effect of the decay rate. 
The resulting
\if01
iteration
\begin{equation}
    z_{k+1} = z_k + \eta_k \Delta z_k^*
\end{equation}
where $\Delta z^*$ is the solution to the modified data-dependant subproblem \eqref{eq:qp-2}
\else
OB-ILC policy then becomes
\begin{equation}
	\mathcal{T}(z,\lambda,\sigma, k) = \begin{bmatrix}
	   z_k + \eta_k \Delta z_k^* \\
	   \lambda^*\\
	   \sigma^*
	\end{bmatrix}
\end{equation}
where $(\Delta z^*, \lambda^*,\sigma^*)$ is the solution to the modified data-dependant subproblem \eqref{eq:qp-2} and $\Delta z^*=\left(\Delta u^*, \Delta p^* \right)$.
Note that constraint \eqref{eq:qp-2b} explicitely incorporates data from the real unknown system into our SQP algorithm to compensate for model mismatch and improve robustness.

\fi












The overall algorithm is outlined in Algorithm~\ref{alg:cap}.
The ILC loop is terminated when $\|\Delta z^*\|$ goes below a certain threshold, or when a maximum number of iterations is reached.
The SQP steps can be solved using a standard quadratic programming solver. In our implementation, we use OSQP~\cite{OSQP} via the Casadi~\cite{Casadi} interface for Python.
\begin{algorithm}
\caption{OB-ILC with SQP steps}\label{alg:cap}
\begin{algorithmic}[1]
\State $u \gets u_0$ \Comment{Initialization}
\Repeat
    \State $y_k \gets f(u_k) + w_k$ \Comment{Measurement}
    \State $\Delta z^*_k \gets$ Solution of \eqref{eq:qp-2}%
    \State $z_{k+1} \gets z_k + \eta_k \Delta z^*_k$ \Comment{Update}
    \State $k \gets k+1$
\Until{termination criteria is met}
\end{algorithmic}
\end{algorithm}



