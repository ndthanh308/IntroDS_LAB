Iterative learning control (ILC) is used in repetitive tasks to improve performance over iterations by learning from previous trials. In ILC, the control input is updated between iterations using the measured error, which is shown to ensure monotonic convergence to an approximate fixed point of the original problem under various assumptions~\cite{liao2022robustness,barton2010norm,son2015robust,tayebi2007unified}.  

An important challenge with ILC is to ensure convergence and constraint satisfaction, which is especially difficult when the underlying system is nonlinear. 
Optimization-based ILC (OB-ILC) methods have been proposed in the literature to systematically study iteration-wise error dynamics and constraint satisfaction.
Robust optimization-based methods~\cite{adlakha2020optimization,son2015robust}, interior point-based OB-ILC~\cite{mishra2010optimization}, and norm-optimal ILC methods~\cite{amann1996iterative,barton2010norm,balta2021learning,gunnarsson2001design} are some of the common approaches in the literature for linear systems.
While some of the works consider model mismatch and process constraints jointly, many of the existing works do not provide robust constraint satisfaction, and convergence results in the presence of measurement noise. 
Recently, OB-ILC has been extended to handle process constraints in linear processes while accounting for noise and model mismatch during all iterations~\cite{liao2022robustness}.

This work aims to extend existing OB-ILC methods to nonlinear system dynamics.
Specifically, our goal is to leverage approximate process models to pose an optimization problem that we iteratively solve using the underlying nonlinear system while ensuring constraint satisfaction.

A survey of the ILC method for nonlinear dynamics is given in~\cite{xu2011survey}.
In~\cite{tayebi2007unified} robust convergence for a class of nonlinear systems is given, while a neural network-based nonlinear ILC method is presented in~\cite{yu2021neural}.%
Linearization-based OB-ILC methods for nonlinear systems are studied in~\cite{schollig2009optimization,lu2017nonlinear}. 
Variants of Newton-based methods are used for nonlinear ILC problems~\cite{avrachenkov1998iterative,lin2006newton,volckaert2009model}.
In~\cite {baumgartner2020zero} a zeroth-order ILC for nonlinear processes is proposed. It requires solving a nonlinear program after each iteration and difficult-to-verify properties with approximate sensitivities. 
In this paper, we consider a similar setting but propose a novel nonlinear OB-ILC method based on the well-known sequential quadratic programming (SQP) method for nonconvex optimization~\cite{boggs1995sequential}. 
Specifically, we consider model mismatch and constraints to form approximate subproblems, which are solved by using measurements from the nonlinear process. 
The main contribution of this paper is a nonlinear OB-ILC scheme based on the SQP framework, that requires solving convex quadratic subproblems after each trial and can handle constraints and approximate models.

ILC is used extensively in motion tracking problems and has been shown to improve the performance of gantry systems~\cite{chen2021iterative}, wafer stages~\cite{mishra2010optimization}, precision motion systems~\cite{balta2021learning,barton2010norm} and various related applications~\cite{bolder2014rational,bristow2006high}.
Similarly, we illustrate our proposed OB-ILC method for nonlinear dynamics on a precision motion tracking problem. 
We present a detailed case study using a high-fidelity simulator of a precision motion system, and we compare the achieved tracking accuracy by using models with different fidelity (linear and neural network-based).

The rest of the paper is structured as follows. Section~\ref{sec:problem} presents the problem setting and the control approach. Section~\ref{sec:ob-ilc} presents the optimization problem and the proposed OB-ILC approach. Section~\ref{sec:case-study} presents a detailed case study in precision motion control and Section~\ref{sec:conclusion} provides closing remarks with potential future directions.
 













We denote the Jacobian by $\nabla$ and the Jacobian along a certain direction $d$ by $\nabla_d$.
Similarly $\nabla^2$ and $\nabla^2_d$ are the Hessian and the Hessian along the direction $d$ respectively. $\partial^n$ denotes the discrete derivative of order $n$, defined by $\partial^n x =(\partial^{n-1} x(i+1) - \partial^{n-1} x(i))/{\Delta t}$, $\partial^0 x = x$, where $\Delta t$ is the discrete time interval.

\if01
\sam{Notation:\\
$u_k$: Input \\
$y_k$: Measurement\\
$p_k$: Local estimate of $f(u_k)$ \\
$z_k = \begin{bmatrix} u_k \\ p_k \end{bmatrix}$: Collection of variables\\
$x_k = \begin{bmatrix} z_k \\ \lambda \\ \sigma \end{bmatrix} = \begin{bmatrix} \begin{bmatrix} u_k \\ p_k \end{bmatrix} \\ \lambda \\ \sigma \end{bmatrix} $: ILC policy internal state\\
$\eta_k = \frac{\eta_0}{\sqrt{k}}$: damping coeficient "SQP / Newton style".\\
$\mathcal{T}$: ILC policy.
}
\fi
