\begin{thebibliography}{10}

\bibitem{neal1990learning}
R.~M. Neal, Learning stochastic feedforward networks.
\newblock {\em Department of Computer Science, University of Toronto}
  {\bfseries 64}, 1577 (1990).

\bibitem{lee2017energy}
V.~T. Lee, A.~Alaghi, J.~P. Hayes, V.~Sathe, and L.~Ceze, Energy-efficient
  hybrid stochastic-binary neural networks for near-sensor computing. In {\em
  Design, Automation \& Test in Europe Conference \& Exhibition (DATE), 2017},
  13--18 (2017).

\bibitem{liu2018stochastic}
Y.~Liu, S.~Liu, Y.~Wang, F.~Lombardi, and J.~Han, A stochastic computational
  multi-layer perceptron with backward propagation.
\newblock {\em IEEE Transactions on Computers} {\bfseries 67}, 1273--1286
  (2018).

\bibitem{hinton1984boltzmann}
G.~E. Hinton, T.~J. Sejnowski, and D.~H. Ackley, (1984) {\em Boltzmann
  machines: Constraint satisfaction networks that learn}.
\newblock (Carnegie-Mellon University, Department of Computer Science
  Pittsburgh, PA).

\bibitem{ackley1985learning}
D.~H. Ackley, G.~E. Hinton, and T.~J. Sejnowski, A learning algorithm for
  Boltzmann machines.
\newblock {\em Cognitive Science} {\bfseries 9}, 147--169 (1985).

\bibitem{williams1992simple}
R.~J. Williams, Simple statistical gradient-following algorithms for
  connectionist reinforcement learning.
\newblock {\em Machine learning} {\bfseries 8}, 229--256 (1992).

\bibitem{weaver2013optimal}
L.~Weaver and N.~Tao, The optimal reward baseline for gradient-based
  reinforcement learning.
\newblock {\em arXiv:1301.2315} (2013).

\bibitem{fiete2006gradient}
I.~R. Fiete and H.~S. Seung, Gradient learning in spiking neural networks by
  dynamic perturbation of conductances.
\newblock {\em Physical Review Letters} {\bfseries 97}, 048104 (2006).

\bibitem{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville, Estimating or propagating
  gradients through stochastic neurons for conditional computation.
\newblock {\em arXiv:1308.3432} (2013).

\bibitem{hinton2012}
G.~Hinton, {\em Neural netowrks for machine learning}.
\newblock Coursera, Video Lectures (2012).

\bibitem{yin2019understanding}
P.~Yin, J.~Lyu, S.~Zhang, S.~Osher, Y.~Qi, and J.~Xin, Understanding
  straight-through estimator in training activation quantized neural nets.
\newblock {\em arXiv:1903.05662} (2019).

\bibitem{chung2016hierarchical}
J.~Chung, S.~Ahn, and Y.~Bengio, Hierarchical multiscale recurrent neural
  networks.
\newblock {\em arXiv:1609.01704} (2016).

\bibitem{bottou2012stochastic}
L.~Bottou, Stochastic gradient descent tricks.
\newblock {\em Neural Networks: Tricks of the Trade: Second Edition} pp.
  421--436 (2012).

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, Adam: A method for stochastic optimization.
\newblock {\em arXiv:1412.6980} (2014).

\bibitem{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter, Decoupled weight decay regularization.
\newblock {\em arXiv:1711.05101} (2017).

\bibitem{sludds2022delocalized}
A.~Sludds, S.~Bandyopadhyay, Z.~Chen, Z.~Zhong, J.~Cochrane, L.~Bernstein,
  D.~Bunandar, P.~B. Dixon, S.~A. Hamilton, M.~Streshinsky et~al. Delocalized
  photonic deep learning on the internetâ€™s edge.
\newblock {\em Science} {\bfseries 378}, 270--276 (2022).

\bibitem{shen2017deep}
Y.~Shen, N.~C. Harris, S.~Skirlo, M.~Prabhu, T.~Baehr-Jones, M.~Hochberg,
  X.~Sun, S.~Zhao, H.~Larochelle, D.~Englund et~al. Deep learning with coherent
  nanophotonic circuits.
\newblock {\em \href{https://doi.org/10.1038/nphoton.2017.93}{Nature
  Photonics}} \href{https://doi.org/10.1038/nphoton.2017.93}{{\bfseries 11},
  441} (2017).

\bibitem{miscuglio2020massively}
M.~Miscuglio, Z.~Hu, S.~Li, J.~K. George, R.~Capanna, H.~Dalir, P.~M. Bardet,
  P.~Gupta, and V.~J. Sorger, Massively parallel amplitude-only Fourier neural
  network.
\newblock {\em \href{https://doi.org/10.1364/OPTICA.408659}{Optica}}
  \href{https://doi.org/10.1364/OPTICA.408659}{{\bfseries 7}, 1812--1819}
  (2020).

\bibitem{bogaerts2020programmable}
W.~Bogaerts, D.~P{\'e}rez, J.~Capmany, D.~A.~B. Miller, J.~Poon, D.~Englund,
  F.~Morichetti, and A.~Melloni, Programmable photonic circuits.
\newblock {\em \href{https://doi.org/10.1038/s41586-020-2764-0}{Nature}}
  \href{https://doi.org/10.1038/s41586-020-2764-0}{{\bfseries 586}, 207--216}
  (2020).

\bibitem{lin2018all}
X.~Lin, Y.~Rivenson, N.~T. Yardimci, M.~Veli, Y.~Luo, M.~Jarrahi, and A.~Ozcan,
  All-optical machine learning using diffractive deep neural networks.
\newblock {\em
  \href{https://www.science.org/doi/abs/10.1126/science.aat8084}{Science}}
  \href{https://www.science.org/doi/abs/10.1126/science.aat8084}{{\bfseries
  361}, 1004--1008} (2018).

\bibitem{spall2020fully}
J.~Spall, X.~Guo, T.~D. Barrett, and A.~Lvovsky, Fully reconfigurable coherent
  optical vector--matrix multiplication.
\newblock {\em Optics Letters} {\bfseries 45}, 5752--5755 (2020).

\bibitem{feldmann2021parallel}
J.~Feldmann, N.~Youngblood, M.~Karpov, H.~Gehring, X.~Li, M.~Stappers,
  M.~Le~Gallo, X.~Fu, A.~Lukashchuk, A.~S. Raja et~al. Parallel convolutional
  processing using an integrated photonic tensor core.
\newblock {\em \href{https://doi.org/10.1038/s41586-020-03070-1}{Nature}}
  \href{https://doi.org/10.1038/s41586-020-03070-1}{{\bfseries 589}, 52--58}
  (2021).

\bibitem{xu202111}
X.~Xu, M.~Tan, B.~Corcoran, J.~Wu, A.~Boes, T.~G. Nguyen, S.~T. Chu, B.~E.
  Little, D.~G. Hicks, R.~Morandotti, A.~Mitchell, and D.~J. Moss, 11 TOPS
  photonic convolutional accelerator for optical neural networks.
\newblock {\em \href{https://doi.org/10.1038/s41586-020-03063-0}{Nature}}
  \href{https://doi.org/10.1038/s41586-020-03063-0}{{\bfseries 589}, 44--51}
  (2021).

\bibitem{ramachandran2017searching}
P.~Ramachandran, B.~Zoph, and Q.~V. Le, Searching for activation functions.
\newblock {\em arXiv:1710.05941} (2017).

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, Learning multiple layers of features from tiny images.
\newblock (2009).

\bibitem{wang2022optical}
T.~Wang, S.-Y. Ma, L.~G. Wright, T.~Onodera, B.~C. Richard, and P.~L. McMahon,
  An optical neural network using less than 1 photon per multiplication.
\newblock {\em Nature Communications} {\bfseries 13}, 1--8 (2022).

\bibitem{wu2021harnessing}
C.~Wu, X.~Yang, H.~Yu, R.~Peng, I.~Takeuchi, Y.~Chen, and M.~Li, Harnessing
  Optoelectronic Noises in a Hybrid Photonic Generative Adversarial Network
  (GAN).
\newblock {\em \href{https://doi.org/10.21203/rs.3.rs-795091/v1}{Preprint at
  Research Square:10.21203}} (2021).

\bibitem{hubara2016binarized}
I.~Hubara, M.~Courbariaux, D.~Soudry, R.~El-Yaniv, and Y.~Bengio, Binarized
  neural networks.
\newblock {\em Advances in Neural Information Processing Systems} {\bfseries
  29} (2016).

\bibitem{rastegari2016xnor}
M.~Rastegari, V.~Ordonez, J.~Redmon, and A.~Farhadi, Xnor-net: Imagenet
  classification using binary convolutional neural networks. In {\em Computer
  Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands,
  October 11--14, 2016, Proceedings, Part IV}, 525--542 (2016).

\bibitem{bulat2019matrix}
A.~Bulat, J.~Kossaifi, G.~Tzimiropoulos, and M.~Pantic, Matrix and tensor
  decompositions for training binary neural networks.
\newblock {\em arXiv:1904.07852} (2019).

\bibitem{qin2020binary}
H.~Qin, R.~Gong, X.~Liu, X.~Bai, J.~Song, and N.~Sebe, Binary neural networks:
  A survey.
\newblock {\em Pattern Recognition} {\bfseries 105}, 107281 (2020).

\end{thebibliography}
