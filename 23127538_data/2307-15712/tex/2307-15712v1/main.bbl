\begin{thebibliography}{100}

\bibitem{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton, Deep learning.
\newblock {\em \href{https://doi.org/10.1038/nature14539}{Nature}}
  \href{https://doi.org/10.1038/nature14539}{{\bfseries 521}, 436--444} (2015).

\bibitem{canziani2016analysis}
A.~Canziani, A.~Paszke, and E.~Culurciello, An analysis of deep neural network
  models for practical applications.
\newblock {\em \href{https://arxiv.org/abs/1605.07678}{arXiv:1605.07678}}
  (2016).

\bibitem{thompson2020computational}
N.~C. Thompson, K.~Greenewald, K.~Lee, and G.~F. Manso, The computational
  limits of deep learning.
\newblock {\em \href{https://arxiv.org/abs/2007.05558}{arXiv:2007.05558}}
  (2020).

\bibitem{markovi2020physics}
D.~Markovi{\'{c}}, A.~Mizrahi, D.~Querlioz, and J.~Grollier, Physics for
  neuromorphic computing.
\newblock {\em \href{https://doi.org/10.1038/s42254-020-0208-2}{Nature Reviews
  Physics}} \href{https://doi.org/10.1038/s42254-020-0208-2}{{\bfseries 2},
  499--510} (2020).

\bibitem{christensen20222022}
D.~V. Christensen, R.~Dittmann, B.~Linares-Barranco, A.~Sebastian, M.~Le~Gallo,
  A.~Redaelli, S.~Slesazeck, T.~Mikolajick, S.~Spiga, S.~Menzel et~al. 2022
  roadmap on neuromorphic computing and engineering.
\newblock {\em \href{https://dx.doi.org/10.1088/2634-4386/ac4a83}{Neuromorphic
  Computing and Engineering}}
  \href{https://dx.doi.org/10.1088/2634-4386/ac4a83}{{\bfseries 2}, 022501}
  (2022).

\bibitem{shen2017deep}
Y.~Shen, N.~C. Harris, S.~Skirlo, M.~Prabhu, T.~Baehr-Jones, M.~Hochberg,
  X.~Sun, S.~Zhao, H.~Larochelle, D.~Englund et~al. Deep learning with coherent
  nanophotonic circuits.
\newblock {\em \href{https://doi.org/10.1038/nphoton.2017.93}{Nature
  Photonics}} \href{https://doi.org/10.1038/nphoton.2017.93}{{\bfseries 11},
  441} (2017).

\bibitem{lin2018all}
X.~Lin, Y.~Rivenson, N.~T. Yardimci, M.~Veli, Y.~Luo, M.~Jarrahi, and A.~Ozcan,
  All-optical machine learning using diffractive deep neural networks.
\newblock {\em
  \href{https://www.science.org/doi/abs/10.1126/science.aat8084}{Science}}
  \href{https://www.science.org/doi/abs/10.1126/science.aat8084}{{\bfseries
  361}, 1004--1008} (2018).

\bibitem{rios2019memory}
C.~R{\'\i}os, N.~Youngblood, Z.~Cheng, M.~Le~Gallo, W.~H. Pernice, C.~D.
  Wright, A.~Sebastian, and H.~Bhaskaran, In-memory computing on a photonic
  platform.
\newblock {\em Science Advances} {\bfseries 5}, eaau5759 (2019).

\bibitem{wetzstein2020inference}
G.~Wetzstein, A.~Ozcan, S.~Gigan, S.~Fan, D.~Englund, M.~Solja{\v{c}}i{\'c},
  C.~Denz, D.~A. Miller, and D.~Psaltis, Inference in artificial intelligence
  with deep optics and photonics.
\newblock {\em Nature} {\bfseries 588}, 39--47 (2020).

\bibitem{xu202111}
X.~Xu, M.~Tan, B.~Corcoran, J.~Wu, A.~Boes, T.~G. Nguyen, S.~T. Chu, B.~E.
  Little, D.~G. Hicks, R.~Morandotti, A.~Mitchell, and D.~J. Moss, 11 TOPS
  photonic convolutional accelerator for optical neural networks.
\newblock {\em \href{https://doi.org/10.1038/s41586-020-03063-0}{Nature}}
  \href{https://doi.org/10.1038/s41586-020-03063-0}{{\bfseries 589}, 44--51}
  (2021).

\bibitem{feldmann2021parallel}
J.~Feldmann, N.~Youngblood, M.~Karpov, H.~Gehring, X.~Li, M.~Stappers,
  M.~Le~Gallo, X.~Fu, A.~Lukashchuk, A.~S. Raja et~al. Parallel convolutional
  processing using an integrated photonic tensor core.
\newblock {\em \href{https://doi.org/10.1038/s41586-020-03070-1}{Nature}}
  \href{https://doi.org/10.1038/s41586-020-03070-1}{{\bfseries 589}, 52--58}
  (2021).

\bibitem{zhou2021large}
T.~Zhou, X.~Lin, J.~Wu, Y.~Chen, H.~Xie, Y.~Li, J.~Fan, H.~Wu, L.~Fang, and
  Q.~Dai, Large-scale neuromorphic optoelectronic computing with a
  reconfigurable diffractive processing unit.
\newblock {\em \href{https://doi.org/10.1038/s41566-021-00796-w}{Nature
  Photonics}} \href{https://doi.org/10.1038/s41566-021-00796-w}{{\bfseries 15},
  367--373} (2021).

\bibitem{wang2022optical}
T.~Wang, S.-Y. Ma, L.~G. Wright, T.~Onodera, B.~C. Richard, and P.~L. McMahon,
  An optical neural network using less than 1 photon per multiplication.
\newblock {\em Nature Communications} {\bfseries 13}, 1--8 (2022).

\bibitem{davis2022frequency}
R.~Davis~III, Z.~Chen, R.~Hamerly, and D.~Englund, Frequency-encoded deep
  learning with speed-of-light dominated latency.
\newblock {\em arXiv:2207.06883} (2022).

\bibitem{ashtiani2022chip}
F.~Ashtiani, A.~J. Geers, and F.~Aflatouni, An on-chip photonic deep neural
  network for image classification.
\newblock {\em Nature} {\bfseries 606}, 501--506 (2022).

\bibitem{sludds2022delocalized}
A.~Sludds, S.~Bandyopadhyay, Z.~Chen, Z.~Zhong, J.~Cochrane, L.~Bernstein,
  D.~Bunandar, P.~B. Dixon, S.~A. Hamilton, M.~Streshinsky et~al. Delocalized
  photonic deep learning on the internet’s edge.
\newblock {\em Science} {\bfseries 378}, 270--276 (2022).

\bibitem{bandyopadhyay2022single}
S.~Bandyopadhyay, A.~Sludds, S.~Krastanov, R.~Hamerly, N.~Harris, D.~Bunandar,
  M.~Streshinsky, M.~Hochberg, and D.~Englund, Single chip photonic deep neural
  network with accelerated training.
\newblock {\em arXiv:2208.01623} (2022).

\bibitem{moon2019enhancing}
S.~Moon, K.~Shin, and D.~Jeon, Enhancing reliability of analog neural network
  processors.
\newblock {\em IEEE Transactions on Very Large Scale Integration (VLSI)
  Systems} {\bfseries 27}, 1455--1459 (2019).

\bibitem{joshi2020accurate}
V.~Joshi, M.~Le~Gallo, S.~Haefeli, I.~Boybat, S.~R. Nandakumar, C.~Piveteau,
  M.~Dazzi, B.~Rajendran, A.~Sebastian, and E.~Eleftheriou, Accurate deep
  neural network inference using computational phase-change memory.
\newblock {\em Nature Communications} {\bfseries 11}, 1--13 (2020).

\bibitem{semenova2022understanding}
N.~Semenova, L.~Larger, and D.~Brunner, Understanding and mitigating noise in
  trained deep neural networks.
\newblock {\em Neural Networks} {\bfseries 146}, 151--160 (2022).

\bibitem{klachko2019improving}
M.~Klachko, M.~R. Mahmoodi, and D.~Strukov, Improving noise tolerance of
  mixed-signal neural networks. In {\em 2019 International Joint Conference on
  Neural Networks (IJCNN)}, 1--8 (2019).

\bibitem{zhou2020noisy}
C.~Zhou, P.~Kadambi, M.~Mattina, and P.~N. Whatmough, Noisy machines:
  Understanding noisy neural networks and enhancing robustness to analog
  hardware errors using distillation.
\newblock {\em arXiv:2001.04974} (2020).

\bibitem{yang2022tolerating}
X.~Yang, C.~Wu, M.~Li, and Y.~Chen, Tolerating Noise Effects in
  Processing-in-Memory Systems for Neural Networks: A Hardware--Software
  Codesign Perspective.
\newblock {\em Advanced Intelligent Systems} {\bfseries 4}, 2200029 (2022).

\bibitem{wright2022deep}
L.~G. Wright, T.~Onodera, M.~M. Stein, T.~Wang, D.~T. Schachter, Z.~Hu, and
  P.~L. McMahon, Deep physical neural networks trained with backpropagation.
\newblock {\em Nature} {\bfseries 601}, 549--555 (2022).

\bibitem{wu2022harnessing}
C.~Wu, X.~Yang, H.~Yu, R.~Peng, I.~Takeuchi, Y.~Chen, and M.~Li, Harnessing
  optoelectronic noises in a photonic generative network.
\newblock {\em Science Advances} {\bfseries 8}, eabm2956 (2022).

\bibitem{borras2022walking}
H.~Borras, B.~Klein, and H.~Fr{\"o}ning, Walking Noise: Understanding
  Implications of Noisy Computations on Classification Tasks.
\newblock {\em arXiv:2212.10430} (2022).

\bibitem{semenova2022noise}
N.~Semenova and D.~Brunner, Noise-mitigation strategies in physical feedforward
  neural networks.
\newblock {\em Chaos: An Interdisciplinary Journal of Nonlinear Science}
  {\bfseries 32}, 061106 (2022).

\bibitem{anderson2023optical}
M.~G. Anderson, S.-Y. Ma, T.~Wang, L.~G. Wright, and P.~L. McMahon, Optical
  transformers.
\newblock {\em arXiv:2302.10360} (2023).

\bibitem{jiang2023physical}
Y.~Jiang, W.~Zhang, X.~Liu, W.~Zhu, J.~Du, and Z.~He, Physical Layer-aware
  Digital-Analog Co-Design for Photonic Convolution Neural Network.
\newblock {\em IEEE Journal of Selected Topics in Quantum Electronics} (2023).

\bibitem{bernstein2023single}
L.~Bernstein, A.~Sludds, C.~Panuski, S.~Trajtenberg-Mills, R.~Hamerly, and
  D.~Englund, Single-shot optical neural network.
\newblock {\em Science Advances} {\bfseries 9}, eadg7904 (2023).

\bibitem{beenakker2003quantum}
C.~Beenakker and C.~Sch{\"o}nenberger, Quantum shot noise.
\newblock {\em Physics Today} {\bfseries 56}, 37--42 (2003).

\bibitem{agarwal2012quantum}
G.~S. Agarwal, (2012) {\em Quantum Optics}.
\newblock (Cambridge University Press).

\bibitem{machida1987observation}
S.~Machida, Y.~Yamamoto, and Y.~Itaya, Observation of amplitude squeezing in a
  constant-current--driven semiconductor laser.
\newblock {\em Physical Review Letters} {\bfseries 58}, 1000 (1987).

\bibitem{hadfield2009single}
R.~H. Hadfield, Single-photon detectors for optical quantum information
  applications.
\newblock {\em Nature Photonics} {\bfseries 3}, 696--705 (2009).

\bibitem{alaghi2013survey}
A.~Alaghi and J.~P. Hayes, Survey of stochastic computing.
\newblock {\em ACM Transactions on Embedded Computing Systems (TECS)}
  {\bfseries 12}, 1--19 (2013).

\bibitem{ackley1985learning}
D.~H. Ackley, G.~E. Hinton, and T.~J. Sejnowski, A learning algorithm for
  Boltzmann machines.
\newblock {\em Cognitive Science} {\bfseries 9}, 147--169 (1985).

\bibitem{neal1990learning}
R.~M. Neal, Learning stochastic feedforward networks.
\newblock {\em Department of Computer Science, University of Toronto}
  {\bfseries 64}, 1577 (1990).

\bibitem{neal1992connectionist}
R.~M. Neal, Connectionist learning of belief networks.
\newblock {\em Artificial Intelligence} {\bfseries 56}, 71--113 (1992).

\bibitem{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville, Estimating or propagating
  gradients through stochastic neurons for conditional computation.
\newblock {\em arXiv:1308.3432} (2013).

\bibitem{tang2013learning}
C.~Tang and R.~R. Salakhutdinov, Learning stochastic feedforward neural
  networks.
\newblock {\em Advances in Neural Information Processing Systems} {\bfseries
  26} (2013).

\bibitem{raiko2014techniques}
T.~Raiko, M.~Berglund, G.~Alain, and L.~Dinh, Techniques for learning binary
  stochastic feedforward neural networks.
\newblock {\em arXiv:1406.2989} (2014).

\bibitem{hubara2016binarized}
I.~Hubara, M.~Courbariaux, D.~Soudry, R.~El-Yaniv, and Y.~Bengio, Binarized
  neural networks.
\newblock {\em Advances in Neural Information Processing Systems} {\bfseries
  29} (2016).

\bibitem{ji2015hardware}
Y.~Ji, F.~Ran, C.~Ma, and D.~J. Lilja, A hardware implementation of a radial
  basis function neural network using stochastic logic. In {\em 2015 Design,
  Automation \& Test in Europe Conference \& Exhibition (DATE)}, 880--883
  (2015).

\bibitem{lee2017energy}
V.~T. Lee, A.~Alaghi, J.~P. Hayes, V.~Sathe, and L.~Ceze, Energy-efficient
  hybrid stochastic-binary neural networks for near-sensor computing. In {\em
  Design, Automation \& Test in Europe Conference \& Exhibition (DATE), 2017},
  13--18 (2017).

\bibitem{liu2020survey}
Y.~Liu, S.~Liu, Y.~Wang, F.~Lombardi, and J.~Han, A survey of stochastic
  computing neural networks for machine learning applications.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}
  {\bfseries 32}, 2809--2824 (2020).

\bibitem{vodenicarevic2017low}
D.~Vodenicarevic, N.~Locatelli, A.~Mizrahi, J.~S. Friedman, A.~F. Vincent,
  M.~Romera, A.~Fukushima, K.~Yakushiji, H.~Kubota, S.~Yuasa et~al. Low-energy
  truly random number generation with superparamagnetic tunnel junctions for
  unconventional computing.
\newblock {\em Physical Review Applied} {\bfseries 8}, 054045 (2017).

\bibitem{hassan2019low}
O.~Hassan, R.~Faria, K.~Y. Camsari, J.~Z. Sun, and S.~Datta, Low-barrier magnet
  design for efficient hardware binary stochastic neurons.
\newblock {\em IEEE Magnetics Letters} {\bfseries 10}, 1--5 (2019).

\bibitem{chowdhury2023full}
S.~Chowdhury, A.~Grimaldi, N.~A. Aadit, S.~Niazi, M.~Mohseni, S.~Kanai,
  H.~Ohno, S.~Fukami, L.~Theogarajan, G.~Finocchio et~al. A full-stack view of
  probabilistic computing with p-bits: devices, architectures and algorithms.
\newblock {\em IEEE Journal on Exploratory Solid-State Computational Devices
  and Circuits} (2023).

\bibitem{hylton2021vision}
T.~Hylton, T.~M. Conte, and M.~D. Hill, A vision to compute like nature:
  Thermodynamically.
\newblock {\em Communications of the ACM} {\bfseries 64}, 35--38 (2021).

\bibitem{coles2023thermodynamic}
P.~J. Coles, C.~Szczepanski, D.~Melanson, K.~Donatella, A.~J. Martinez, and
  F.~Sbahi, Thermodynamic AI and the fluctuation frontier.
\newblock {\em arXiv:2302.06584} (2023).

\bibitem{wu2022photonic}
C.~Wu, X.~Yang, Y.~Chen, and M.~Li, Photonic Bayesian neural network using
  programmed optical noises.
\newblock {\em IEEE Journal of Selected Topics in Quantum Electronics}
  {\bfseries 29}, 1--6 (2022).

\bibitem{ma2023stochastic}
B.~Ma, J.~Zhang, X.~Li, and W.~Zou, Stochastic photonic spiking neuron for
  Bayesian inference with unsupervised learning.
\newblock {\em Optics Letters} {\bfseries 48}, 1411--1414 (2023).

\bibitem{gu2015muprop}
S.~Gu, S.~Levine, I.~Sutskever, and A.~Mnih, Muprop: Unbiased backpropagation
  for stochastic neural networks.
\newblock {\em arXiv:1511.05176} (2015).

\bibitem{liu2018stochastic}
Y.~Liu, S.~Liu, Y.~Wang, F.~Lombardi, and J.~Han, A stochastic computational
  multi-layer perceptron with backward propagation.
\newblock {\em IEEE Transactions on Computers} {\bfseries 67}, 1273--1286
  (2018).

\bibitem{gerry2005introductory}
C.~Gerry and P.~L. Knight, (2005) {\em Introductory Quantum Optics}.
\newblock (Cambridge University Press).

\bibitem{rastegari2016xnor}
M.~Rastegari, V.~Ordonez, J.~Redmon, and A.~Farhadi, Xnor-net: Imagenet
  classification using binary convolutional neural networks. In {\em Computer
  Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands,
  October 11--14, 2016, Proceedings, Part IV}, 525--542 (2016).

\bibitem{zhou2016dorefa}
S.~Zhou, Y.~Wu, Z.~Ni, X.~Zhou, H.~Wen, and Y.~Zou, Dorefa-net: Training low
  bitwidth convolutional neural networks with low bitwidth gradients.
\newblock {\em arXiv:1606.06160} (2016).

\bibitem{hayasaki1992optical}
Y.~Hayasaki, I.~Tohyama, T.~Yatagai, M.~Mori, and S.~Ishihara, Optical learning
  neural network using Selfoc microlens array.
\newblock {\em \href{https://doi.org/10.1143/JJAP.31.1689}{Japanese Journal of
  Applied Physics}} \href{https://doi.org/10.1143/JJAP.31.1689}{{\bfseries 31},
  1689} (1992).

\bibitem{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner, Gradient-based learning applied
  to document recognition.
\newblock {\em Proceedings of the IEEE} {\bfseries 86}, 2278--2324 (1998).

\bibitem{hamerly2019large}
R.~Hamerly, L.~Bernstein, A.~Sludds, M.~Solja{\v{c}}i{\'c}, and D.~Englund,
  Large-scale optical neural networks based on photoelectric multiplication.
\newblock {\em \href{https://doi.org/10.1103/PhysRevX.9.021032}{Physical Review
  X}} \href{https://doi.org/10.1103/PhysRevX.9.021032}{{\bfseries 9}, 021032}
  (2019).

\bibitem{laydevant2021training}
J.~Laydevant, M.~Ernoult, D.~Querlioz, and J.~Grollier, Training dynamical
  binary neural networks with equilibrium propagation. In {\em Proceedings of
  the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  4640--4649 (2021).

\bibitem{dhimitri2022scientific}
K.~Dhimitri, S.~M. Fullerton, B.~Coyle, K.~E. Bennett, T.~Miura, T.~Higuchi,
  and T.~Maruno, Scientific CMOS (sCMOS) camera capabilities with a focus on
  quantum applications. In {\em Photonics for Quantum 2022}, PC122430L (2022).

\bibitem{agarap2018deep}
A.~F. Agarap, Deep learning using rectified linear units (ReLU).
\newblock {\em arXiv:1803.08375} (2018).

\bibitem{chang2018hybrid}
J.~Chang, V.~Sitzmann, X.~Dun, W.~Heidrich, and G.~Wetzstein, Hybrid
  optical-electronic convolutional neural networks with optimized diffractive
  optics for image classification.
\newblock {\em Scientific Reports} {\bfseries 8}, 12324 (2018).

\bibitem{spall2020fully}
J.~Spall, X.~Guo, T.~D. Barrett, and A.~Lvovsky, Fully reconfigurable coherent
  optical vector--matrix multiplication.
\newblock {\em Optics Letters} {\bfseries 45}, 5752--5755 (2020).

\bibitem{miscuglio2020massively}
M.~Miscuglio, Z.~Hu, S.~Li, J.~K. George, R.~Capanna, H.~Dalir, P.~M. Bardet,
  P.~Gupta, and V.~J. Sorger, Massively parallel amplitude-only Fourier neural
  network.
\newblock {\em \href{https://doi.org/10.1364/OPTICA.408659}{Optica}}
  \href{https://doi.org/10.1364/OPTICA.408659}{{\bfseries 7}, 1812--1819}
  (2020).

\bibitem{lee2016generalizing}
C.-Y. Lee, P.~W. Gallagher, and Z.~Tu, Generalizing pooling functions in
  convolutional neural networks: Mixed, gated, and tree. In {\em Artificial
  Intelligence and Statistics}, 464--472 (2016).

\bibitem{esser2016convolutional}
S.~K. Esser, P.~A. Merolla, J.~V. Arthur, A.~S. Cassidy, R.~Appuswamy,
  A.~Andreopoulos, D.~J. Berg, J.~L. McKinstry, T.~Melano, D.~R. Barch,
  C.~di~Nolfo, P.~Datta, A.~Amir, B.~Taba, M.~D. Flickner, and D.~S. Modha,
  Convolutional networks for fast, energy-efficient neuromorphic computing.
\newblock {\em \href{https://doi.org/10.1073/pnas.1604850113}{Proceedings of
  the National Academy of Sciences}}
  \href{https://doi.org/10.1073/pnas.1604850113}{{\bfseries 113}, 11441--11446}
  (2016).

\bibitem{qin2020binary}
H.~Qin, R.~Gong, X.~Liu, X.~Bai, J.~Song, and N.~Sebe, Binary neural networks:
  A survey.
\newblock {\em Pattern Recognition} {\bfseries 105}, 107281 (2020).

\bibitem{sze2020evaluate}
V.~Sze, Y.-H. Chen, T.-J. Yang, and J.~S. Emer, How to evaluate deep neural
  network processors: TOPS/W (alone) considered harmful.
\newblock {\em \href{https://doi.org/10.1109/MSSC.2020.3002140}{IEEE
  Solid-State Circuits Magazine}}
  \href{https://doi.org/10.1109/MSSC.2020.3002140}{{\bfseries 12}, 28--41}
  (2020).

\bibitem{nahmias2019photonic}
M.~A. Nahmias, T.~F. De~Lima, A.~N. Tait, H.-T. Peng, B.~J. Shastri, and P.~R.
  Prucnal, Photonic multiply-accumulate operations for neural networks.
\newblock {\em IEEE Journal of Selected Topics in Quantum Electronics}
  {\bfseries 26}, 1--18 (2019).

\bibitem{bruschini2023linospad2}
C.~Bruschini, S.~Burri, E.~Bernasconi, T.~Milanese, A.~C. Ulku, H.~Homulle, and
  E.~Charbon, LinoSPAD2: A 512x1 linear SPAD camera with system-level 135-ps
  SPTR and a reconfigurable computational engine for time-resolved
  single-photon imaging. In {\em Quantum Sensing and Nano Electronics and
  Photonics XIX} Vol.{} 12430, 126--135 (2023).

\bibitem{shainline2017superconducting}
J.~M. Shainline, S.~M. Buckley, R.~P. Mirin, and S.~W. Nam, Superconducting
  optoelectronic circuits for neuromorphic computing.
\newblock {\em Physical Review Applied} {\bfseries 7}, 034013 (2017).

\bibitem{wang2023image}
T.~Wang, M.~M. Sohoni, L.~G. Wright, M.~M. Stein, S.-Y. Ma, T.~Onodera, M.~G.
  Anderson, and P.~L. McMahon, Image sensing with multilayer nonlinear optical
  neural networks.
\newblock {\em Nature Photonics} {\bfseries 17}, 408--415 (2023).

\bibitem{huang2023photonic}
L.~Huang, Q.~A. Tanguy, J.~E. Froch, S.~Mukherjee, K.~F. Bohringer, and
  A.~Majumdar, Photonic Advantage of Optical Encoders.
\newblock {\em arXiv:2305.01743} (2023).

\bibitem{carolan2015universal}
J.~Carolan, C.~Harrold, C.~Sparrow, E.~Mart{\'\i}n-L{\'o}pez, N.~J. Russell,
  J.~W. Silverstone, P.~J. Shadbolt, N.~Matsuda, M.~Oguma, M.~Itoh et~al.
  Universal linear optics.
\newblock {\em Science} {\bfseries 349}, 711--716 (2015).

\bibitem{bogaerts2020programmable}
W.~Bogaerts, D.~P{\'e}rez, J.~Capmany, D.~A.~B. Miller, J.~Poon, D.~Englund,
  F.~Morichetti, and A.~Melloni, Programmable photonic circuits.
\newblock {\em \href{https://doi.org/10.1038/s41586-020-2764-0}{Nature}}
  \href{https://doi.org/10.1038/s41586-020-2764-0}{{\bfseries 586}, 207--216}
  (2020).

\bibitem{tait2015demonstration}
A.~N. Tait, J.~Chang, B.~J. Shastri, M.~A. Nahmias, and P.~R. Prucnal,
  Demonstration of WDM weighted addition for principal component analysis.
\newblock {\em Optics Express} {\bfseries 23}, 12758--12765 (2015).

\bibitem{mazets2007multiatom}
I.~Mazets and G.~Kurizki, Multiatom cooperative emission following
  single-photon absorption: Dicke-state dynamics.
\newblock {\em Journal of Physics B: Atomic, Molecular and Optical Physics}
  {\bfseries 40}, F105 (2007).

\bibitem{pinotsi2008single}
D.~Pinotsi and A.~Imamoglu, Single photon absorption by a single quantum
  emitter.
\newblock {\em Physical Review Letters} {\bfseries 100}, 093603 (2008).

\bibitem{sotier2009femtosecond}
F.~Sotier, T.~Thomay, T.~Hanke, J.~Korger, S.~Mahapatra, A.~Frey, K.~Brunner,
  R.~Bratschitsch, and A.~Leitenstorfer, Femtosecond few-fermion dynamics and
  deterministic single-photon gain in a quantum dot.
\newblock {\em Nature Physics} {\bfseries 5}, 352--356 (2009).

\bibitem{kiilerich2019input}
A.~H. Kiilerich and K.~M{\o}lmer, Input-output theory with quantum pulses.
\newblock {\em Physical Review Letters} {\bfseries 123}, 123604 (2019).

\bibitem{li2023single}
Q.~Li, K.~Orcutt, R.~L. Cook, J.~Sabines-Chesterking, A.~L. Tong, G.~S.
  Schlau-Cohen, X.~Zhang, G.~R. Fleming, and K.~B. Whaley, Single-photon
  absorption and emission from a natural photosynthetic complex.
\newblock {\em Nature} pp. 1--5 (2023).

\bibitem{roques2023biasing}
C.~Roques-Carmes, Y.~Salamin, J.~Sloan, S.~Choi, G.~Velez, E.~Koskas,
  N.~Rivera, S.~E. Kooi, J.~D. Joannopoulos, and M.~Soljacic, Biasing the
  quantum vacuum to control macroscopic probability distributions.
\newblock {\em arXiv:2303.03455} (2023).

\bibitem{zhou2020insitu}
T.~Zhou, L.~Fang, T.~Yan, J.~Wu, Y.~Li, J.~Fan, H.~Wu, X.~Lin, and Q.~Dai, In
  situ optical backpropagation training of diffractive optical neural networks.
\newblock {\em Photonics Research} {\bfseries 8}, 940--953 (2020).

\bibitem{guo2021backpropagation}
X.~Guo, T.~D. Barrett, Z.~M. Wang, and A.~Lvovsky, Backpropagation through
  nonlinear units for the all-optical training of neural networks.
\newblock {\em Photonics Research} {\bfseries 9}, B71--B80 (2021).

\bibitem{pai2023experimentally}
S.~Pai, Z.~Sun, T.~W. Hughes, T.~Park, B.~Bartlett, I.~A. Williamson,
  M.~Minkov, M.~Milanizadeh, N.~Abebe, F.~Morichetti et~al. Experimentally
  realized in situ backpropagation for deep learning in photonic neural
  networks.
\newblock {\em Science} {\bfseries 380}, 398--404 (2023).

\bibitem{bengio2015towards}
Y.~Bengio, D.-H. Lee, J.~Bornschein, T.~Mesnard, and Z.~Lin, Towards
  biologically plausible deep learning.
\newblock {\em arXiv:1502.04156} (2015).

\bibitem{lillicrap2020backpropagation}
T.~P. Lillicrap, A.~Santoro, L.~Marris, C.~J. Akerman, and G.~Hinton,
  Backpropagation and the brain.
\newblock {\em Nature Reviews Neuroscience} {\bfseries 21}, 335--346 (2020).

\bibitem{hinton2023mortal}
G.~Hinton, The concept of mortal computation.
\newblock Keynote address presented at the Neural Information Processing
  Systems conference, New Orleans (2023).

\bibitem{stern2023learning}
M.~Stern and A.~Murugan, Learning without neurons in physical systems.
\newblock {\em Annual Review of Condensed Matter Physics} {\bfseries 14},
  417--441 (2023).

\bibitem{bulat2019xnor}
A.~Bulat and G.~Tzimiropoulos, Xnor-net++: Improved binary neural networks.
\newblock {\em arXiv:1909.13863} (2019).

\bibitem{bulat2019matrix}
A.~Bulat, J.~Kossaifi, G.~Tzimiropoulos, and M.~Pantic, Matrix and tensor
  decompositions for training binary neural networks.
\newblock {\em arXiv:1904.07852} (2019).

\bibitem{mohseni2022ising}
N.~Mohseni, P.~L. McMahon, and T.~Byrnes, Ising machines as hardware solvers of
  combinatorial optimization problems.
\newblock {\em Nature Reviews Physics} {\bfseries 4}, 363--379 (2022).

\bibitem{torrejon2017neuromorphic}
J.~Torrejon, M.~Riou, F.~A. Araujo, S.~Tsunegi, G.~Khalsa, D.~Querlioz,
  P.~Bortolotti, V.~Cros, K.~Yakushiji, A.~Fukushima et~al. Neuromorphic
  computing with nanoscale spintronic oscillators.
\newblock {\em Nature} {\bfseries 547}, 428--431 (2017).

\bibitem{grollier2020neuromorphic}
J.~Grollier, D.~Querlioz, K.~Camsari, K.~Everschor-Sitte, S.~Fukami, and M.~D.
  Stiles, Neuromorphic spintronics.
\newblock {\em Nature Electronics} {\bfseries 3}, 360--370 (2020).

\bibitem{cai2020power}
F.~Cai, S.~Kumar, T.~Van~Vaerenbergh, X.~Sheng, R.~Liu, C.~Li, Z.~Liu,
  M.~Foltin, S.~Yu, Q.~Xia et~al. Power-efficient combinatorial optimization
  using intrinsic noise in memristor Hopfield neural networks.
\newblock {\em Nature Electronics} {\bfseries 3}, 409--418 (2020).

\bibitem{harabi2023memristor}
K.-E. Harabi, T.~Hirtzlin, C.~Turck, E.~Vianello, R.~Laurent, J.~Droulez,
  P.~Bessi{\`e}re, J.-M. Portal, M.~Bocquet, and D.~Querlioz, A memristor-based
  Bayesian machine.
\newblock {\em Nature Electronics} {\bfseries 6}, 52--63 (2023).

\bibitem{islam2023hardware}
A.~N. M.~N. Islam, K.~Yang, A.~K. Shukla, P.~Khanal, B.~Zhou, W.-G. Wang, and
  A.~Sengupta, Hardware in Loop Learning with Spin Stochastic Neurons.
\newblock {\em \href{https://arxiv.org/abs/2305.03235}{arXiv:2305.03235}}
  (2023).

\bibitem{markovic2020quantum}
D.~Markovi{\'c} and J.~Grollier, Quantum neuromorphic computing.
\newblock {\em Applied Physics Letters} {\bfseries 117} (2020).

\bibitem{cerezo2022challenges}
M.~Cerezo, G.~Verdon, H.-Y. Huang, L.~Cincio, and P.~J. Coles, Challenges and
  opportunities in quantum machine learning.
\newblock {\em Nature Computational Science} {\bfseries 2}, 567--576 (2022).

\bibitem{prezioso2015training}
M.~Prezioso, F.~Merrikh-Bayat, B.~D. Hoskins, G.~C. Adam, K.~K. Likharev, and
  D.~B. Strukov, Training and operation of an integrated neuromorphic network
  based on metal-oxide memristors.
\newblock {\em Nature} {\bfseries 521}, 61--64 (2015).

\bibitem{hughes2019wave}
T.~W. Hughes, I.~A. Williamson, M.~Minkov, and S.~Fan, Wave physics as an
  analog recurrent neural network.
\newblock {\em Science Advances} {\bfseries 5}, eaay6946 (2019).

\bibitem{mitarai2018quantum}
K.~Mitarai, M.~Negoro, M.~Kitagawa, and K.~Fujii, Quantum circuit learning.
\newblock {\em Physical Review A} {\bfseries 98}, 032309 (2018).

\bibitem{cramer2022surrogate}
B.~Cramer, S.~Billaudelle, S.~Kanya, A.~Leibfried, A.~Gr{\"u}bl, V.~Karasenko,
  C.~Pehle, K.~Schreiber, Y.~Stradmann, J.~Weis et~al. Surrogate gradients for
  analog neuromorphic computing.
\newblock {\em Proceedings of the National Academy of Sciences} {\bfseries
  119}, e2109194119 (2022).

\bibitem{chen2020classification}
T.~Chen, J.~van Gelder, B.~van~de Ven, S.~V. Amitonov, B.~De~Wilde, H.-C.
  Ruiz~Euler, H.~Broersma, P.~A. Bobbert, F.~A. Zwanenburg, and W.~G. van~der
  Wiel, Classification with a disordered dopant-atom network in silicon.
\newblock {\em Nature} {\bfseries 577}, 341--345 (2020).

\bibitem{berggren2020roadmap}
K.~Berggren, Q.~Xia, K.~K. Likharev, D.~B. Strukov, H.~Jiang, T.~Mikolajick,
  D.~Querlioz, M.~Salinga, J.~R. Erickson, S.~Pi et~al. Roadmap on emerging
  hardware and technology for machine learning.
\newblock {\em Nanotechnology} {\bfseries 32}, 012002 (2020).

\bibitem{finocchio2023roadmap}
G.~Finocchio, S.~Bandyopadhyay, P.~Lin, G.~Pan, J.~J. Yang, R.~Tomasello,
  C.~Panagopoulos, M.~Carpentieri, V.~Puliafito, J.~{\AA}kerman et~al. Roadmap
  for unconventional computing with nanotechnology.
\newblock {\em arXiv:2301.06727} (2023).

\bibitem{leiserson2020there}
C.~E. Leiserson, N.~C. Thompson, J.~S. Emer, B.~C. Kuszmaul, B.~W. Lampson,
  D.~Sanchez, and T.~B. Schardl, There’s plenty of room at the Top: What will
  drive computer performance after Moore’s law?
\newblock {\em Science} {\bfseries 368}, eaam9744 (2020).

\bibitem{kellman2020physics}
M.~Kellman, M.~Lustig, and L.~Waller, How to do physics-based learning.
\newblock {\em arXiv:2005.13531} (2020).

\bibitem{hinton2012}
G.~Hinton, {\em Neural netowrks for machine learning}.
\newblock Coursera, Video Lectures (2012).

\bibitem{yin2019understanding}
P.~Yin, J.~Lyu, S.~Zhang, S.~Osher, Y.~Qi, and J.~Xin, Understanding
  straight-through estimator in training activation quantized neural nets.
\newblock {\em arXiv:1903.05662} (2019).

\bibitem{williams1992simple}
R.~J. Williams, Simple statistical gradient-following algorithms for
  connectionist reinforcement learning.
\newblock {\em Machine learning} {\bfseries 8}, 229--256 (1992).

\bibitem{bottou2012stochastic}
L.~Bottou, Stochastic gradient descent tricks.
\newblock {\em Neural Networks: Tricks of the Trade: Second Edition} pp.
  421--436 (2012).

\bibitem{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter, Decoupled weight decay regularization.
\newblock {\em arXiv:1711.05101} (2017).

\bibitem{de2015comparison}
P.~De~Chazal, J.~Tapson, and A.~Van~Schaik, A comparison of extreme learning
  machines and back-propagation trained feed-forward networks processing the
  mnist
  database\href{https://doi.org/10.1109/ICASSP.2015.7178354}{\href{https://doi.org/10.1109/ICASSP.2015.7178354}{.
  In {\em 2015 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}}, 2165--2168} (2015).

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, Learning multiple layers of features from tiny images.
\newblock (2009).

\end{thebibliography}
