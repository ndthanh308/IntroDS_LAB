\begin{thebibliography}{10}

\bibitem{neal1990learning}
R.~M. Neal, Learning stochastic feedforward networks.
\newblock {\em Department of Computer Science, University of Toronto} {\bfseries 64}, 1577 (1990).

\bibitem{lee2017energy}
V.~T. Lee, A.~Alaghi, J.~P. Hayes, V.~Sathe, and L.~Ceze, Energy-efficient hybrid stochastic-binary neural networks for near-sensor computing. In {\em Design, Automation \& Test in Europe Conference \& Exhibition (DATE), 2017}, 13--18 (2017).

\bibitem{liu2018stochastic}
Y.~Liu, S.~Liu, Y.~Wang, F.~Lombardi, and J.~Han, A stochastic computational multi-layer perceptron with backward propagation.
\newblock {\em IEEE Transactions on Computers} {\bfseries 67}, 1273--1286 (2018).

\bibitem{hinton1984boltzmann}
G.~E. Hinton, T.~J. Sejnowski, and D.~H. Ackley, (1984) {\em Boltzmann machines: Constraint satisfaction networks that learn}.
\newblock (Carnegie-Mellon University, Department of Computer Science Pittsburgh, PA).

\bibitem{ackley1985learning}
D.~H. Ackley, G.~E. Hinton, and T.~J. Sejnowski, A learning algorithm for Boltzmann machines.
\newblock {\em Cognitive Science} {\bfseries 9}, 147--169 (1985).

\bibitem{williams1992simple}
R.~J. Williams, Simple statistical gradient-following algorithms for connectionist reinforcement learning.
\newblock {\em Machine learning} {\bfseries 8}, 229--256 (1992).

\bibitem{weaver2013optimal}
L.~Weaver and N.~Tao, The optimal reward baseline for gradient-based reinforcement learning.
\newblock {\em arXiv:1301.2315} (2013).

\bibitem{fiete2006gradient}
I.~R. Fiete and H.~S. Seung, Gradient learning in spiking neural networks by dynamic perturbation of conductances.
\newblock {\em Physical Review Letters} {\bfseries 97}, 048104 (2006).

\bibitem{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville, Estimating or propagating gradients through stochastic neurons for conditional computation.
\newblock {\em arXiv:1308.3432} (2013).

\bibitem{hinton2012}
G.~Hinton, {\em Neural netowrks for machine learning}.
\newblock Coursera, Video Lectures (2012).

\bibitem{yin2019understanding}
P.~Yin, J.~Lyu, S.~Zhang, S.~Osher, Y.~Qi, and J.~Xin, Understanding straight-through estimator in training activation quantized neural nets.
\newblock {\em arXiv:1903.05662} (2019).

\bibitem{chung2016hierarchical}
J.~Chung, S.~Ahn, and Y.~Bengio, Hierarchical multiscale recurrent neural networks.
\newblock {\em arXiv:1609.01704} (2016).

\bibitem{bottou2012stochastic}
L.~Bottou, Stochastic gradient descent tricks.
\newblock {\em Neural Networks: Tricks of the Trade: Second Edition} pp. 421--436 (2012).

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, Adam: A method for stochastic optimization.
\newblock {\em arXiv:1412.6980} (2014).

\bibitem{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter, Decoupled weight decay regularization.
\newblock {\em arXiv:1711.05101} (2017).

\bibitem{sludds2022delocalized}
A.~Sludds, S.~Bandyopadhyay, Z.~Chen, Z.~Zhong, J.~Cochrane, L.~Bernstein, D.~Bunandar, P.~B. Dixon, S.~A. Hamilton, M.~Streshinsky et~al. Delocalized photonic deep learning on the internetâ€™s edge.
\newblock {\em Science} {\bfseries 378}, 270--276 (2022).

\bibitem{shen2017deep}
Y.~Shen, N.~C. Harris, S.~Skirlo, M.~Prabhu, T.~Baehr-Jones, M.~Hochberg, X.~Sun, S.~Zhao, H.~Larochelle, D.~Englund et~al. Deep learning with coherent nanophotonic circuits.
\newblock {\em Nature Photonics} {\bfseries 11}, 441 (2017).

\bibitem{miscuglio2020massively}
M.~Miscuglio, Z.~Hu, S.~Li, J.~K. George, R.~Capanna, H.~Dalir, P.~M. Bardet, P.~Gupta, and V.~J. Sorger, Massively parallel amplitude-only {Fourier} neural network.
\newblock {\em Optica} {\bfseries 7}, 1812--1819 (2020).

\bibitem{bogaerts2020programmable}
W.~Bogaerts, D.~P{\'e}rez, J.~Capmany, D.~A.~B. Miller, J.~Poon, D.~Englund, F.~Morichetti, and A.~Melloni, Programmable photonic circuits.
\newblock {\em Nature} {\bfseries 586}, 207--216 (2020).

\bibitem{lin2018all}
X.~Lin, Y.~Rivenson, N.~T. Yardimci, M.~Veli, Y.~Luo, M.~Jarrahi, and A.~Ozcan, All-optical machine learning using diffractive deep neural networks.
\newblock {\em Science} {\bfseries 361}, 1004--1008 (2018).

\bibitem{spall2020fully}
J.~Spall, X.~Guo, T.~D. Barrett, and A.~Lvovsky, Fully reconfigurable coherent optical vector--matrix multiplication.
\newblock {\em Optics Letters} {\bfseries 45}, 5752--5755 (2020).

\bibitem{feldmann2021parallel}
J.~Feldmann, N.~Youngblood, M.~Karpov, H.~Gehring, X.~Li, M.~Stappers, M.~Le~Gallo, X.~Fu, A.~Lukashchuk, A.~S. Raja et~al. Parallel convolutional processing using an integrated photonic tensor core.
\newblock {\em Nature} {\bfseries 589}, 52--58 (2021).

\bibitem{xu202111}
X.~Xu, M.~Tan, B.~Corcoran, J.~Wu, A.~Boes, T.~G. Nguyen, S.~T. Chu, B.~E. Little, D.~G. Hicks, R.~Morandotti, A.~Mitchell, and D.~J. Moss, 11 {TOPS} photonic convolutional accelerator for optical neural networks.
\newblock {\em Nature} {\bfseries 589}, 44--51 (2021).

\bibitem{ramachandran2017searching}
P.~Ramachandran, B.~Zoph, and Q.~V. Le, Searching for activation functions.
\newblock {\em arXiv:1710.05941} (2017).

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, Learning multiple layers of features from tiny images.
\newblock {\em Technical Report} pp. 32--33 (2009).

\bibitem{clanuwat2018deep}
T.~Clanuwat and et~al., Deep Learning for Classical Japanese Literature.
\newblock {\em arXiv preprint arXiv:1812.01718} (2018).

\bibitem{xiao2017fashion}
H.~Xiao and et~al., Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.
\newblock {\em arXiv preprint arXiv:1708.07747} (2017).

\bibitem{wang2022optical}
T.~Wang, S.-Y. Ma, L.~G. Wright, T.~Onodera, B.~C. Richard, and P.~L. McMahon, An optical neural network using less than 1 photon per multiplication.
\newblock {\em Nature Communications} {\bfseries 13}, 1--8 (2022).

\bibitem{dhimitri2022scientific}
K.~Dhimitri, S.~M. Fullerton, B.~Coyle, K.~E. Bennett, T.~Miura, T.~Higuchi, and T.~Maruno, {Scientific CMOS (sCMOS)} camera capabilities with a focus on quantum applications. In {\em Photonics for Quantum 2022}, PC122430L (2022).

\bibitem{wu2021harnessing}
C.~Wu, X.~Yang, H.~Yu, R.~Peng, I.~Takeuchi, Y.~Chen, and M.~Li, Harnessing Optoelectronic Noises in a Hybrid Photonic Generative Adversarial Network (GAN).
\newblock {\em Preprint at Research Square:10.21203} (2021).

\bibitem{hubara2016binarized}
I.~Hubara, M.~Courbariaux, D.~Soudry, R.~El-Yaniv, and Y.~Bengio, Binarized neural networks.
\newblock {\em Advances in Neural Information Processing Systems} {\bfseries 29} (2016).

\bibitem{rastegari2016xnor}
M.~Rastegari, V.~Ordonez, J.~Redmon, and A.~Farhadi, {XNOR-Net}: Imagenet classification using binary convolutional neural networks. In {\em Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV}, 525--542 (2016).

\bibitem{bulat2019matrix}
A.~Bulat, J.~Kossaifi, G.~Tzimiropoulos, and M.~Pantic, Matrix and tensor decompositions for training binary neural networks.
\newblock {\em arXiv:1904.07852} (2019).

\bibitem{qin2020binary}
H.~Qin, R.~Gong, X.~Liu, X.~Bai, J.~Song, and N.~Sebe, Binary neural networks: A survey.
\newblock {\em Pattern Recognition} {\bfseries 105}, 107281 (2020).

\bibitem{alaghi2013survey}
A.~Alaghi and J.~P. Hayes, Survey of stochastic computing.
\newblock {\em ACM Transactions on Embedded Computing Systems (TECS)} {\bfseries 12}, 1--19 (2013).

\bibitem{neal1992connectionist}
R.~M. Neal, Connectionist learning of belief networks.
\newblock {\em Artificial Intelligence} {\bfseries 56}, 71--113 (1992).

\bibitem{tang2013learning}
C.~Tang and R.~R. Salakhutdinov, Learning stochastic feedforward neural networks.
\newblock {\em Advances in Neural Information Processing Systems} {\bfseries 26} (2013).

\bibitem{raiko2014techniques}
T.~Raiko, M.~Berglund, G.~Alain, and L.~Dinh, Techniques for learning binary stochastic feedforward neural networks.
\newblock {\em arXiv:1406.2989} (2014).

\bibitem{ji2015hardware}
Y.~Ji, F.~Ran, C.~Ma, and D.~J. Lilja, A hardware implementation of a radial basis function neural network using stochastic logic. In {\em 2015 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)}, 880--883 (2015).

\bibitem{liu2020survey}
Y.~Liu, S.~Liu, Y.~Wang, F.~Lombardi, and J.~Han, A survey of stochastic computing neural networks for machine learning applications.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems} {\bfseries 32}, 2809--2824 (2020).

\bibitem{vodenicarevic2017low}
D.~Vodenicarevic, N.~Locatelli, A.~Mizrahi, J.~S. Friedman, A.~F. Vincent, M.~Romera, A.~Fukushima, K.~Yakushiji, H.~Kubota, S.~Yuasa et~al. Low-energy truly random number generation with superparamagnetic tunnel junctions for unconventional computing.
\newblock {\em Physical Review Applied} {\bfseries 8}, 054045 (2017).

\bibitem{hassan2019low}
O.~Hassan, R.~Faria, K.~Y. Camsari, J.~Z. Sun, and S.~Datta, Low-barrier magnet design for efficient hardware binary stochastic neurons.
\newblock {\em IEEE Magnetics Letters} {\bfseries 10}, 1--5 (2019).

\bibitem{chowdhury2023full}
S.~Chowdhury, A.~Grimaldi, N.~A. Aadit, S.~Niazi, M.~Mohseni, S.~Kanai, H.~Ohno, S.~Fukami, L.~Theogarajan, G.~Finocchio et~al. A full-stack view of probabilistic computing with p-bits: devices, architectures and algorithms.
\newblock {\em IEEE Journal on Exploratory Solid-State Computational Devices and Circuits} (2023).

\bibitem{hylton2021vision}
T.~Hylton, T.~M. Conte, and M.~D. Hill, A vision to compute like nature: Thermodynamically.
\newblock {\em Communications of the ACM} {\bfseries 64}, 35--38 (2021).

\bibitem{coles2023thermodynamic}
P.~J. Coles, C.~Szczepanski, D.~Melanson, K.~Donatella, A.~J. Martinez, and F.~Sbahi, Thermodynamic AI and the fluctuation frontier.
\newblock {\em arXiv:2302.06584} (2023).

\bibitem{wu2022harnessing}
C.~Wu, X.~Yang, H.~Yu, R.~Peng, I.~Takeuchi, Y.~Chen, and M.~Li, Harnessing optoelectronic noises in a photonic generative network.
\newblock {\em Science Advances} {\bfseries 8}, eabm2956 (2022).

\bibitem{wu2022photonic}
C.~Wu, X.~Yang, Y.~Chen, and M.~Li, Photonic Bayesian neural network using programmed optical noises.
\newblock {\em IEEE Journal of Selected Topics in Quantum Electronics} {\bfseries 29}, 1--6 (2022).

\bibitem{ma2023stochastic}
B.~Ma, J.~Zhang, X.~Li, and W.~Zou, Stochastic photonic spiking neuron for Bayesian inference with unsupervised learning.
\newblock {\em Optics Letters} {\bfseries 48}, 1411--1414 (2023).

\bibitem{nahmias2019photonic}
M.~A. Nahmias, T.~F. De~Lima, A.~N. Tait, H.-T. Peng, B.~J. Shastri, and P.~R. Prucnal, Photonic multiply-accumulate operations for neural networks.
\newblock {\em IEEE Journal of Selected Topics in Quantum Electronics} {\bfseries 26}, 1--18 (2019).

\bibitem{hamerly2019large}
R.~Hamerly, L.~Bernstein, A.~Sludds, M.~Solja{\v{c}}i{\'c}, and D.~Englund, Large-scale optical neural networks based on photoelectric multiplication.
\newblock {\em Physical Review X} {\bfseries 9}, 021032 (2019).

\bibitem{anderson2024optical}
M.~Anderson, S.-Y. Ma, T.~Wang, L.~Wright, and P.~McMahon, Optical Transformers.
\newblock {\em \href{https://openreview.net/forum?id=Xxw0edFFQC}{Transactions on Machine Learning Research}} (2024).

\bibitem{bruschini2023linospad2}
C.~Bruschini, S.~Burri, E.~Bernasconi, T.~Milanese, A.~C. Ulku, H.~Homulle, and E.~Charbon, LinoSPAD2: A 512x1 linear SPAD camera with system-level 135-ps SPTR and a reconfigurable computational engine for time-resolved single-photon imaging. In {\em Quantum Sensing and Nano Electronics and Photonics XIX} Vol.{} 12430, 126--135 (2023).

\bibitem{shainline2017superconducting}
J.~M. Shainline, S.~M. Buckley, R.~P. Mirin, and S.~W. Nam, Superconducting optoelectronic circuits for neuromorphic computing.
\newblock {\em Physical Review Applied} {\bfseries 7}, 034013 (2017).

\bibitem{wetzstein2020inference}
G.~Wetzstein, A.~Ozcan, S.~Gigan, S.~Fan, D.~Englund, M.~Solja{\v{c}}i{\'c}, C.~Denz, D.~A. Miller, and D.~Psaltis, Inference in artificial intelligence with deep optics and photonics.
\newblock {\em Nature} {\bfseries 588}, 39--47 (2020).

\bibitem{wang2023image}
T.~Wang, M.~M. Sohoni, L.~G. Wright, M.~M. Stein, S.-Y. Ma, T.~Onodera, M.~G. Anderson, and P.~L. McMahon, Image sensing with multilayer nonlinear optical neural networks.
\newblock {\em Nature Photonics} {\bfseries 17}, 408--415 (2023).

\bibitem{huang2023photonic}
L.~Huang, Q.~A. Tanguy, J.~E. Froch, S.~Mukherjee, K.~F. Bohringer, and A.~Majumdar, Photonic Advantage of Optical Encoders.
\newblock {\em arXiv:2305.01743} (2023).

\bibitem{chang2018hybrid}
J.~Chang, V.~Sitzmann, X.~Dun, W.~Heidrich, and G.~Wetzstein, Hybrid optical-electronic convolutional neural networks with optimized diffractive optics for image classification.
\newblock {\em Scientific Reports} {\bfseries 8}, 12324 (2018).

\bibitem{zhou2021large}
T.~Zhou, X.~Lin, J.~Wu, Y.~Chen, H.~Xie, Y.~Li, J.~Fan, H.~Wu, L.~Fang, and Q.~Dai, Large-scale neuromorphic optoelectronic computing with a reconfigurable diffractive processing unit.
\newblock {\em Nature Photonics} {\bfseries 15}, 367--373 (2021).

\bibitem{carolan2015universal}
J.~Carolan, C.~Harrold, C.~Sparrow, E.~Mart{\'\i}n-L{\'o}pez, N.~J. Russell, J.~W. Silverstone, P.~J. Shadbolt, N.~Matsuda, M.~Oguma, M.~Itoh et~al. Universal linear optics.
\newblock {\em Science} {\bfseries 349}, 711--716 (2015).

\bibitem{tait2015demonstration}
A.~N. Tait, J.~Chang, B.~J. Shastri, M.~A. Nahmias, and P.~R. Prucnal, Demonstration of {WDM} weighted addition for principal component analysis.
\newblock {\em Optics Express} {\bfseries 23}, 12758--12765 (2015).

\bibitem{mazets2007multiatom}
I.~Mazets and G.~Kurizki, Multiatom cooperative emission following single-photon absorption: Dicke-state dynamics.
\newblock {\em Journal of Physics B: Atomic, Molecular and Optical Physics} {\bfseries 40}, F105 (2007).

\bibitem{pinotsi2008single}
D.~Pinotsi and A.~Imamoglu, Single photon absorption by a single quantum emitter.
\newblock {\em Physical Review Letters} {\bfseries 100}, 093603 (2008).

\bibitem{sotier2009femtosecond}
F.~Sotier, T.~Thomay, T.~Hanke, J.~Korger, S.~Mahapatra, A.~Frey, K.~Brunner, R.~Bratschitsch, and A.~Leitenstorfer, Femtosecond few-fermion dynamics and deterministic single-photon gain in a quantum dot.
\newblock {\em Nature Physics} {\bfseries 5}, 352--356 (2009).

\bibitem{kiilerich2019input}
A.~H. Kiilerich and K.~M{\o}lmer, Input-output theory with quantum pulses.
\newblock {\em Physical Review Letters} {\bfseries 123}, 123604 (2019).

\bibitem{li2023single}
Q.~Li, K.~Orcutt, R.~L. Cook, J.~Sabines-Chesterking, A.~L. Tong, G.~S. Schlau-Cohen, X.~Zhang, G.~R. Fleming, and K.~B. Whaley, Single-photon absorption and emission from a natural photosynthetic complex.
\newblock {\em Nature} pp. 1--5 (2023).

\bibitem{roques2023biasing}
C.~Roques-Carmes, Y.~Salamin, J.~Sloan, S.~Choi, G.~Velez, E.~Koskas, N.~Rivera, S.~E. Kooi, J.~D. Joannopoulos, and M.~Solja{\v{c}}i{\'c}, Biasing the quantum vacuum to control macroscopic probability distributions.
\newblock {\em Science} {\bfseries 381}, 205--209 (2023).

\bibitem{zhou2020insitu}
T.~Zhou, L.~Fang, T.~Yan, J.~Wu, Y.~Li, J.~Fan, H.~Wu, X.~Lin, and Q.~Dai, In situ optical backpropagation training of diffractive optical neural networks.
\newblock {\em Photonics Research} {\bfseries 8}, 940--953 (2020).

\bibitem{guo2021backpropagation}
X.~Guo, T.~D. Barrett, Z.~M. Wang, and A.~Lvovsky, Backpropagation through nonlinear units for the all-optical training of neural networks.
\newblock {\em Photonics Research} {\bfseries 9}, B71--B80 (2021).

\bibitem{bandyopadhyay2022single}
S.~Bandyopadhyay, A.~Sludds, S.~Krastanov, R.~Hamerly, N.~Harris, D.~Bunandar, M.~Streshinsky, M.~Hochberg, and D.~Englund, Single chip photonic deep neural network with accelerated training.
\newblock {\em arXiv:2208.01623} (2022).

\bibitem{pai2023experimentally}
S.~Pai, Z.~Sun, T.~W. Hughes, T.~Park, B.~Bartlett, I.~A. Williamson, M.~Minkov, M.~Milanizadeh, N.~Abebe, F.~Morichetti et~al. Experimentally realized in situ backpropagation for deep learning in photonic neural networks.
\newblock {\em Science} {\bfseries 380}, 398--404 (2023).

\bibitem{bengio2015towards}
Y.~Bengio, D.-H. Lee, J.~Bornschein, T.~Mesnard, and Z.~Lin, Towards biologically plausible deep learning.
\newblock {\em arXiv:1502.04156} (2015).

\bibitem{lillicrap2020backpropagation}
T.~P. Lillicrap, A.~Santoro, L.~Marris, C.~J. Akerman, and G.~Hinton, Backpropagation and the brain.
\newblock {\em Nature Reviews Neuroscience} {\bfseries 21}, 335--346 (2020).

\bibitem{hinton2023mortal}
G.~Hinton, The concept of mortal computation.
\newblock Keynote address presented at the Neural Information Processing Systems conference, New Orleans (2023).

\bibitem{stern2023learning}
M.~Stern and A.~Murugan, Learning without neurons in physical systems.
\newblock {\em Annual Review of Condensed Matter Physics} {\bfseries 14}, 417--441 (2023).

\bibitem{bulat2019xnor}
A.~Bulat and G.~Tzimiropoulos, {XNOR-Net}++: Improved binary neural networks.
\newblock {\em arXiv:1909.13863} (2019).

\bibitem{mohseni2022ising}
N.~Mohseni, P.~L. McMahon, and T.~Byrnes, Ising machines as hardware solvers of combinatorial optimization problems.
\newblock {\em Nature Reviews Physics} {\bfseries 4}, 363--379 (2022).

\bibitem{grollier2020neuromorphic}
J.~Grollier, D.~Querlioz, K.~Camsari, K.~Everschor-Sitte, S.~Fukami, and M.~D. Stiles, Neuromorphic spintronics.
\newblock {\em Nature Electronics} {\bfseries 3}, 360--370 (2020).

\end{thebibliography}
