{
  "title": "Quantum-limited stochastic optical neural networks operating at a few quanta per activation",
  "authors": [
    "Shi-Yuan Ma",
    "Tianyu Wang",
    "Jérémie Laydevant",
    "Logan G. Wright",
    "Peter L. McMahon"
  ],
  "submission_date": "2023-07-28T17:59:46+00:00",
  "revised_dates": [
    "2025-02-03T17:23:03+00:00"
  ],
  "abstract": "Energy efficiency in computation is ultimately limited by noise, with quantum limits setting the fundamental noise floor. Analog physical neural networks hold promise for improved energy efficiency compared to digital electronic neural networks. However, they are typically operated in a relatively high-power regime so that the signal-to-noise ratio (SNR) is large, and the noise can be treated as a perturbation. We study optical neural networks where all layers except the last are operated in the limit that each neuron can be activated by just a single photon, and as a result the noise on neuron activations is no longer merely perturbative. We show that by using a physics-based probabilistic model of the neuron activations in training, it is possible to perform accurate machine-learning inference in spite of the extremely high shot noise (SNR ~ 1). We experimentally demonstrated MNIST handwritten-digit classification with a test accuracy of 98% using an optical neural network with a hidden layer operating in the single-photon regime; the optical energy used to perform the classification corresponds to just 0.038 photons per multiply-accumulate (MAC) operation. Our physics-aware stochastic training approach might also prove useful with non-optical ultra-low-power hardware.",
  "categories": [
    "physics.optics",
    "cs.ET",
    "cs.LG",
    "cs.NE",
    "quant-ph"
  ],
  "primary_category": "physics.optics",
  "doi": "10.1038/s41467-024-55220-y",
  "journal_ref": "Nature Communications 16, 359 (2025)",
  "arxiv_id": "2307.15712",
  "pdf_url": "https://arxiv.org/pdf/2307.15712v2",
  "comment": "65 pages, 28 figures",
  "num_versions": null,
  "size_before_bytes": 39679364,
  "size_after_bytes": 462726
}