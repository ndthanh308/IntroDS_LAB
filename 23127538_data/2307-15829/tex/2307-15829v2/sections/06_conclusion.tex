\section{Conclusion}
We introduce a novel event-based approach for background image reconstruction in the presence of dynamic occlusions.
It leverages the complementary nature of event camera and frames to reconstruct true scene information instead of hallucinating occluded areas as done by image inpainting approaches.
Specifically, our proposed data-driven approach reconstructs the background image using only one occluded image and events.
The high temporal resolution of the events provides our method additional information on the relative intensity changes between the foreground and background, making it robust to dense occlusions. %
To evaluate our approach, we present the first large-scale dataset recorded in the real world containing over $230$ challenging scenes with synchronized events, occluded images, and groundtruth images.
Our method achieves an improvement of 3dB in PSNR over state-of-the-art frame-based and event-based methods on both synthetic and real datasets.
We will release our synthetic and recorded dataset representing the first datasets for background image reconstruction using events and images in the presence of dynamic occlusions.
We believe that our proposed method and dataset lay the foundation for future research.
