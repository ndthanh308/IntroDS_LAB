\section{Experiments}
\label{sec:Experiments}
Within this section, we give the details about out experimental settings and conduct extensive experiments.

\subsection{Experimental Setting}

\textbf{Dataset}:
In our experiments, we primarily utilized two datasets: the ZRR dataset~\cite{ignatov2020replacing} and the SR-RAW dataset~\cite{zhang2019zoom}. The ZRR dataset served as the training dataset, comprising 47,863 paired images. This dataset consists of RAW images of size $448 \times 448 \times 1$, captured by Huawei p20, and RGB images of size $448 \times 448 \times 3$, captured and processed by the Canon 5D Mark IV camera. The test set of the ZRR dataset was used to conduct various experiments, including ablation and robustness testing experiments.

However, since the RAW images in the aforementioned dataset are stored in PNG format, they lack the camera parameters saved during shooting. Consequently, traditional ISP pipelines cannot directly convert them to RGB format. To overcome this limitation, we conducted traditional ISP test experiments using the test set of the SR-RAW dataset. The test set collected 50 scenes of images, with the authors of dataset taking 7 photos at different focal lengths (24, 35, 50, 70, 100, 150, and 240 mm) in each scene. We randomly selected 100 of these images for the traditional ISP test experiment.


\textbf{Hyper-Parameter Setting and Implementation Details}:
As highlighted in Section \ref{section:Three}, the training phase of our model is segregated into three stages. Specifically, we conducted 5,5 and 10 epochs for the first stage, second stage, and the third stage respectively. 

Two optimizers were used in the model training process. The Adam optimizer was assigned to the task of optimizing the RAW image encoder and the RGB image decoder. The RMSProp was to optimize the discriminator. The learning rate of both optimizers is $5 \times 10^{-5}$. The batch size is set to 4.

For our watermarking, we elected to generate the 100-bit binary strings randomly during the training phase. In the testing phase, we restricted the embeded watermarking to 56 bits, subsequently incorporating error-correcting codes using Bose–Chaudhuri–Hocquenghem (BCH) codes~\cite{bose1960class} to fill the remaining 44 bits, ultimately arriving at a 100-bit watermarking.

It is important to note that we have made certain adjustments to the number of submodules proposed by MW-ISPNet and AWNet in comparison to their respective public models. This reduction in the number of submodules has proven to be beneficial for the convergence of the entire framework, resulting in faster training. We used publicly available code for training purposes but made specific modifications to the models, such as adjusting the number of modules and channel features. Specifically, for AWNet, we set the number of GCRDB submodules to [1, 1, 1, 2, 3]. As for MWNet, we configured the feature channels to [32, 64, 64]. On the other hand, the UNet ISP employs a similar framework to the encoder, and the training process closely resembles that of AWNet.


\begin{table}
\renewcommand{\arraystretch}{1.1}
  \caption{Traditional ISP pipeline test results. For the ISP (traditional ISP pipelines), key: R-A: auto white balance; R-C: camera white balance; R-D: daylight white balance. For the ISPT (deep ISP pipelines in training of models). For the distortion, $\checkmark$ indicating the distortion network is used in training of model and $\times$ indicating not. }
  \label{ISP}
\begin{tabular}{c|c|c|cccc}
\toprule
\multicolumn{1}{c|}{ISP} & ISPT & Distortion & PSNR   & SSIM  & BER    & SER     \\ \midrule
\multirow{6}{*}{R-A}    & AWNet            & $\times     $       & 32.653 & 0.811 & 3.73\% & 8.33\%  \\ 
                        & AWNet           & \checkmark          & 30.794 & 0.857 & 2.81\% & 0.02\%  \\
                        & MWNet       & $\times     $        & 27.047 & 0.689 & 5.63\% & 0.27\%  \\
                        & MWNet       & \checkmark           & 27.884 & 0.691 & 3.10\% & 0.00\%  \\
                        & UNet            & $\times     $        & 31.736 & 0.891 & 3.85\% & 14.58\% \\
                        & UNet            & \checkmark           & 31.477 & 0.904 & 2.50\% & 0.00\%  \\ \hline
\multirow{6}{*}{R-C}    & AWNet           & $\times     $        & 32.704 & 0.812 & 3.67\% & 10.42\% \\ 
                        & AWNet           & \checkmark           & 30.866 & 0.859 & 3.08\% & 4.17\%  \\
                        & MWNet       & $\times     $        & 27.110 & 0.698 & 5.60\% & 0.25\%  \\
                        & MWNet       & \checkmark           & 28.060 & 0.693 & 2.77\% & 0.00\%  \\
                        & UNet            & $\times     $        & 31.474 & 0.905 & 3.71\% & 12.50\% \\
                        & UNet            & \checkmark           & 31.870 & 0.892 & 2.42\% & 0.00\%  \\ \hline
\multirow{6}{*}{R-D}    & AWNet           & $\times     $        & 32.939 & 0.820 & 3.40\% & 4.17\%  \\ 
                        & AWNet           & \checkmark          & 30.954 & 0.860 & 2.92\% & 2.08\%  \\
                        & MWNet       &$\times     $        & 27.222 & 0.679 & 5.42\% & 16.67\% \\
                        & MWNet       & \checkmark           & 28.348 & 0.707 & 2.77\% & 4.17\%  \\
                        & UNet            & $\times     $        & 31.727 & 0.907 & 2.56\% & 0.00\%  \\
                        & UNet            & \checkmark           & 31.947 & 0.892 & 4.25\% & 0.15\%  \\
    \bottomrule
  \end{tabular}
\end{table}



\textbf{Evaluation Metrics}:
In the subsequent experiments, we assessed the efficacy of our model in terms of its concealment and robustness capabilities. In regards to concealment, three metrics were employed, namely Peak Signal to Noise Ratio (PSNR), Structural Similarity (SSIM)~\cite{1284395}, and Learned Perceptual Image Patch Similarity (LPIPS)~\cite{zhang2018perceptual}. It is noteworthy that, in this paper, version 0.1 of LPIPS trained on the AlexNet network was utilized. 

On the other hand, the evaluation of robustness involved the use of two metrics: Bit Error Rate (BER), and String Error Rate (SER):
\begin{equation}
    BER = \frac{E_{bit}}{A_{bit}}, SER = \frac{E_{str}}{A_{str}},
\end{equation}
in which $E_{bit}$ represents the number of bits in error, and $A_{bit}$ represents the total number of bits to be hidden. The meaning of $E_{str}$ and $A_{str}$ is similar. It is noteworthy that, in our experiment, the string was subjected to BCH coding. Consequently, even if the number of erroneous bits is small, the string can still be accurately restored.



\subsection{Robustness Test}
In this section, we test the robustness of our model to different distortions. We test the distortions used in training,  For each distortion category, we set 10 different distortion levels (The larger the number, the greater the distortion). 
1) Color temperature adjustment: color temperature is uniform sampling in $ T \sim U[6500 - \frac{5500}{10-\varepsilon}, 6500 + \frac{5500}{10-\varepsilon}] $;
2) JPEG Compression: JPEG quality is uniform sampling in $J \sim  U[60 + \frac{40}{\varepsilon+1}, 100]$;
3) Brightness and contrast adjustment: affine histogram rescaling $mx + b$ with  $ m \sim U[0-\frac{0.1}{10-\varepsilon}, 0+\frac{0.1}{10-\varepsilon}]$ and $b \sim U[0-\frac{0.3}{10-\varepsilon}, 0+ \frac{0.3}{10-\varepsilon}]$;
4) Noise and Saturation adjustment: we use a Gaussian noise (sampling the standard deviation $\sigma \sim U[0,0+ \frac{0.05}{10-\varepsilon}]$) and saturation factor is uniform sampling in $S \sim  U[0, 0+ \frac{0.1}{10-\varepsilon}]$.
where $\varepsilon $ is the distortion level.
The specific results of the experiment are shown in Fig \ref{figroubusttest}.

\subsection{Traditional ISP Pipeline Test}
% #SR-RAW
To assess the robustness of the proposed method against the traditional ISP pipeline, a validation experiment was conducted. To achieve the necessary processing from RAW to RGB images, In the experiment, the traditional ISP pipeline we selected is Rawpy library. The Rawpy library, built on the foundation of LibRaw, serves as the underlying implementation for our work. This library offers a range of image processing operations that enable the conversion of RAW images into RGB images. These operations include essential tasks like white balance correction, color space conversion, and brightness adjustment. Given the capabilities and functionality of rawpy, we consider it to effectively represent traditional ISP methodologies. The {R}awpy library has three white balance models: R-A (it \textbf{A}utomatically calculates the white balance), R-C (it uses the as-shot white balance values of \textbf{C}amera), and R-D (it uses \textbf{D}aylight white balance correction). The encoding and decoding processes of the proposed method remains unchanged throughout the experiment.
One hundred unique images were randomly selected from the SR-RAW dataset, with the condition that these images were disjoint from the training set used in the proposed method. The random 56-bit messages, after being subjected to using BCH coding to 100-bit messages, were embedded within each of these selected images. The results of this experiment are presented in Table \ref{ISP}. A total of six models were subjected to testing, which are all using combined encoder. 
Examples of watermarked images generated by different models in this experiment are shown in Fig \ref{figisp}.
The experimental results demonstrate the robustness of proposed RAWIW framework against the traditional ISP pipelines, and using the distortion network in training can improve the decoding accuracy of the watermarking for the traditional ISP pipeline.


\begin{table*}
    \renewcommand{\arraystretch}{1.05}
    \renewcommand{\tabcolsep}{10.5pt} %
    \caption{Ablation study results with distortion network. `R', `D' and `C' stand for RAW encoder, demosaicing encoder and combined encoder respectively. Best in \textcolor{red}{red} and second in \textcolor{blue}{blue}.}
    \label{Table2}
    \begin{tabular}{c|c|ccc|cc|cc|c|c}
    \toprule
    % \multicolumn{1}{l}{ISP}  & Encoder  & $PSNR_{raw}\uparrow$ & $PSNR_{gt}\uparrow$ & $PSNR_{isp}\uparrow$ & $LPIPS_{gt} \downarrow$ & $LPIPS_{isp}\downarrow$ & $SSIM_{gt}\uparrow$ & $SSIM_{isp}\uparrow$ & $BER\downarrow$ & $SER\downarrow$ \\ \midrule
\multirow{2}{*}{ISP} & \multirow{2}{*}{Encoder} & \multicolumn{3}{c|}{PSNR$\uparrow$} & \multicolumn{2}{c|}{LPIPS$\downarrow$}  & \multicolumn{2}{c|}{SSIM$\uparrow$}  & \multirow{2}{*}{BER$\downarrow$} & \multirow{2}{*}{SER$\downarrow$} \\ \cline{3-9}
   &   & RAW    & GT   & ISP     & GT     & ISP    & GT     & ISP      & &  \\\midrule
    \multirow{3}{*}{MW-ISPNet~\cite{ignatov2020aim}} & R    & 45.389 & 20.164 &  28.979 &  0.154 & 0.068 & 0.804 & 0.975 & \textcolor{blue}{1.035\%} &  \textcolor{blue}{0.083\%}            \\ 
                               & D    & 37.060 &  20.487 & 31.078 &  0.134 &  0.051 & 0.804 &  0.974 & 3.006\% &  \textcolor{blue}{0.083\%} \\ 
                               & C    & 37.890 & 20.144 & 29.169 &  \textcolor{red}{0.113} &  \textcolor{red}{0.020} & 0.804 &  0.981 & 1.155\% & 1.080\% \\ \midrule

    \multirow{3}{*}{Unet~\cite{ronneberger2015u}}      & R    & \textcolor{red}{47.581}  & 19.088 & 32.242 &  0.174 &  0.040 & 0.792 & \textcolor{blue}{0.988} & 1.088\% &  0.332\% \\  
                               & D    & 44.858 & 18.486 & 30.749 &  0.180 &  0.038 & 0.787 & 0.986 & 4.002\% &  0.332\% \\ 
                               & C    & 44.859  &  19.637 & 31.693 & 0.154  & 0.036  & 0.797  &  0.987  & 2.029\%   & 0.166\%     \\ \midrule
    \multirow{3}{*}{AWNet~\cite{dai2020awnet}}     & R   & 44.347 &  20.507 &  31.407 & \textcolor{blue}{0.116}  & \textcolor{blue}{0.024} & 0.812  & 0.978 & 2.014\%  & 0.166\% \\
                               & D    & \textcolor{blue}{46.399} & \textcolor{blue}{20.782}  &  \textcolor{blue}{32.751} &  0.143 & 0.056 &  \textcolor{blue}{0.816} &  0.984 & 2.086\% & 0.498\% \\ 
                               & C    & 40.277 &  \textcolor{red}{21.046} & \textcolor{red}{35.143}  & 0.144 & 0.057 & \textcolor{red}{0.819} &  \textcolor{red}{0.989} & \textcolor{red}{0.880\%} &  \textcolor{red}{0.000\%} \\ 
                               \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}
    \renewcommand{\arraystretch}{1.05}
    \renewcommand{\tabcolsep}{10.5pt} %
    \caption{Ablation study results without distortion network. `R', `D' and `C' stand for RAW encoder, demosaicing encoder and combined encoder respectively. Best in \textcolor{red}{red} and second in \textcolor{blue}{blue}.}
    \label{Table3}
    \begin{tabular}{c|c|ccc|cc|cc|c|c}
    \toprule
    % \multicolumn{1}{l}{ISP}  & Encoder  & $PSNR_{raw}\uparrow$ & $PSNR_{gt}\uparrow$ & $PSNR_{isp}\uparrow$ & $LPIPS_{gt} \downarrow$ & $LPIPS_{isp}\downarrow$ & $SSIM_{gt}\uparrow$ & $SSIM_{isp}\uparrow$ & $BER\downarrow$ & $SER\downarrow$ \\  \midrule
\multirow{2}{*}{ISP} & \multirow{2}{*}{Encoder} & \multicolumn{3}{c|}{PSNR$\uparrow$} & \multicolumn{2}{c|}{LPIPS$\downarrow$}  & \multicolumn{2}{c|}{SSIM$\uparrow$}  & \multirow{2}{*}{BER$\downarrow$} & \multirow{2}{*}{SER$\downarrow$} \\ \cline{3-9}
   &   & RAW    & GT   & ISP     & GT     & ISP    & GT     & ISP      & &  \\\midrule
    \multirow{3}{*}{MW-ISPNet~\cite{ignatov2020aim}} & R         & 45.240 & 20.737 & 36.762 & 0.111 & 0.012 & 0.814 & 0.983 & 4.071\% & 1.495\% \\
                               & D         & 43.531 & 20.728 & 39.480 & 0.109 & 0.008 & 0.814 & 0.984 & 2.354\% & 2.658\% \\ 
                               & C         & 47.623 & 20.871 & 45.018 & \textcolor{red}{0.106} & \textcolor{red}{0.001} & \textcolor{blue}{0.816} & \textcolor{red}{0.989} & \textcolor{red}{2.179\%} & 0.831\% \\  
                               \midrule
    \multirow{3}{*}{Unet~\cite{ronneberger2015u}}      & R         & \textcolor{blue}{50.110} & 19.289 & 38.834 & 0.163 & 0.006 & 0.798 & \textcolor{blue}{0.988} & 3.034\% & 0.664\% \\  
                               & D         & 48.806 & 19.449 & 40.052 & 0.156 & 0.006 & 0.799 & 0.987 & \textcolor{blue}{2.252\%} & 1.495\%         \\ 
                               & C         & 44.292 & 19.402 & 40.814 & 0.160 & 0.004 & 0.798 & \textcolor{blue}{0.988} & 3.686\% & \textcolor{red}{0.166\%}         \\ \midrule
    \multirow{3}{*}{AWNet~\cite{dai2020awnet}}     & R         & \textcolor{red}{50.966} & \textcolor{red}{21.316} & 46.145 & \textcolor{blue}{0.108} & \textcolor{blue}{0.002} & \textcolor{red}{0.826} & \textcolor{red}{0.989} & 3.100\% & 0.748\% \\
                               & D         & 49.489 & 21.281 & \textcolor{blue}{46.294} & 0.109 & 0.003 & \textcolor{red}{0.826} & \textcolor{blue}{0.988} & 4.041\% & \textcolor{blue}{0.498\%} \\        
                               & C         & 46.181 & \textcolor{blue}{21.311} & \textcolor{red}{47.303} & \textcolor{blue}{0.108} & \textcolor{blue}{0.002} & \textcolor{red}{0.826} & \textcolor{blue}{0.988} & 3.359\% & 2.409\% \\       
                               \bottomrule
    \end{tabular}
\end{table*}

\begin{table}[]
\renewcommand{\arraystretch}{1.1}
\renewcommand{\tabcolsep}{10.5pt} %
\caption{Comparison results with state-of-the-art RGB image watermarking methods. Best in \textcolor{red}{red} and second in \textcolor{blue}{blue}.}
\label{Table4}
\begin{tabular}{c|cc|cc}
\toprule
model & PSNR $\uparrow$  & SSIM $\uparrow$  & BER $\downarrow$    & SER $\downarrow$    \\
\midrule
Stegastamp\cite{tancik2020stegastamp} & 29.31  & 0.927 & \textcolor{blue}{0.230\%} & \textcolor{red}{0.000\%} \\\midrule
RIHOOP\cite{jia2020rihoop}    & 29.42  & 0.940 & \textcolor{red}{0.120\%} &\textcolor{red}{ 0.000\%} \\\midrule
RAWIW(M)                  & 29.169 & 0.981 & 1.155\% & 1.080\% \\\midrule
RAWIW(U)                 & \textcolor{blue}{31.693} & \textcolor{blue}{0.987} & 2.029\% & \textcolor{blue}{0.166\%} \\\midrule
RAWIW(A)                 & \textcolor{red}{35.143} & \textcolor{red}{0.989} & 0.880\% & \textcolor{red}{0.000\%} \\
\bottomrule
\end{tabular}

\end{table}

\subsection{Ablation Study}
\label{section:abst}
In this section, we conduct ablation experiments to compare watermarking concealment and robustness metrics under different ISP pipeline, encoders and  distortions. We use the test data in the ZRR dataset for testing, a total of 1204 paired images. Throughout the ablation experiment, we trained a total of 18 ($3 \times 3 \times 2$) models, using three ISP networks, UNet, MW-ISPNet, and AWNet, three encoder structures, and whether to use a distortion network.
Our model can be trained to store different numbers of bits. We settle on a message length of 100 bits in our experiment as it provides a good compromise between image quality and information transfer. The watermarking is random 100 bits binary string in training and 100 bits binary string encoded by random 56 bits binary through BCH coding. We can recover watermarking in the case of a few bit errors by using BCH coding.
The experimental results in Table ~\ref{Table2} and ~\ref{Table3} show that: 
1) The ISP network adopts the AWNet structure to make the watermarking concealment better.
2) The combined encoder structure is better than the RAW structure and demosaicing structure.
3) The distortion network will reduce the concealment and improve the robustness of watermarking. Distortion networks enable encoders to add more ``obvious'' watermarking to RAW images against distortion caused by distortion networks. 

\subsection{Comparison with SOTA}

In this section, we have conducted a comparative experiment between two state-of-the-art RGB image watermarking methods: Stegastamp and RIHOOP. To ensure consistency and accurate evaluation, the experiment settings were derived from the ablation experiment \ref{section:abst}, and the RGB image watermarking methods encoded watermarking into RGB images generated by ISP. The corresponding results are presented in Table \ref{Table4}. It is evident that both our RAW image watermarking and RGB watermarking methods can maintain good visual quality while preserving high decoding accuracy. However, it is worth noting that our RAW image watermarking uses RAW images as covers, which have one-third the capacity of RGB images. As a result, the information hiding density of our method is higher compared to the RGB watermarking methods.




% Figure environment removed