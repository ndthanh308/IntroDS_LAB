\begin{table*}
\centering

\begin{tabular}{l|l|l|l}
\toprule
\textbf{Hyperparameter}        & \textbf{Lift} & \textbf{Can} & \textbf{Square} \\
\midrule
Ctrl           & Pos  & Pos  & Pos  \\
$T_o$             & 2    & 2    & 2    \\
$T_a$            & 8    & 8    & 8    \\
$T_p$             & 10   & 10   & 10   \\
\# $D$-params     & 9    & 9    & 9    \\
\# $V$-params     & 22   & 22   & 22   \\
\# Layers       & 8    & 8    & 8    \\
Emb Dim        & 256  & 256  & 256  \\
Attn Dropout   & 0.3  & 0.3  & 0.3  \\
Lr            & 1e-4 & 1e-4 & 1e-4 \\
WDecay         & 1e-3 & 1e-3 & 1e-3 \\
$D$-Iters Train  & 100  & 100  & 100  \\
$D$-Iters Eval   & 100  & 100  & 100  \\
Control Multiplier   & 10  & 1  & 10  \\
\bottomrule
\end{tabular}

\caption{
Hyperparameters for diffusion policy.
\label{tab:hparam_transformer}
Ctrl: position or velocity control, $T_o$: observation horizon, $T_a$: action horizon, $T_p$: action prediction horizon , \#$D$-Params: diffusion network number of parameters in millions, \#$V$-Params: vision encoder number of parameters in millions, Emb Dim: transformer token embedding dimension, Attn Dropout: transformer attention dropout probability, Lr: learining rate, WDecay: weight decay (for transformer only), $D$-Iters, Train: number of training diffusion iterations, $D$-Iters Eval: number of inference diffusion iterations, Control Multiplier: multiplier for the low-level control steps.
}
\vspace{-5mm}
\end{table*}