

%\naman{TODO - replace taint with integrity or confidentiality constraints as suggested by Max in comments?

%Highlight why data-driven approach is useful a.) lot of public code -- b.) connect with how developers look at existing examples and we learn good stuff from them; 

%Highlight on we are fixing javascript so type-driven techniques do not work

%Highlight that we don't need version control ; 

%Highlight we do very expensive static analysis and it is not feasible to do at this scale across all commits and is therefore a non-baseline! [this is a bit of a lie because LGTM has some version control static analysis codeql data already but that will be a massive baseline to implement (a paper worthy contribution in itself) ; also LGTM itself would be VERY VERY expensive to run -- I believe it stores  1000s of TB of code databases!]
%}
Static analysis (\sa for brevity) takes a program $P$ and a property $\varphi$ as inputs, and checks if the program satisfies the property. 
If the program violates the property, \sa\ outputs an error report, which the developer uses to fix the violation.
In this paper, we present a system called \sysname\, which automates the process of fixing these violations.

Given a \sa\ tool, a property $\varphi$, and a large corpus of programs $\mathcal{P}$ with a sufficient variety of programs that satisfy $\varphi$, our system \sysname\ automatically learns to fix static analysis violations in a data-driven manner.
\sysname\ consists of two stages:
\begin{enumerate}
\item
Data collection: This stage uses the corpus $\mathcal{P}$ to construct a set of "paired" programs $\{ (P_1,P'_1), (P_2,P'_2), \ldots, (P_n,P'_n)\}$, such that, for each pair 
$(P_i,P'_i)$, the first program $P_i$ violates the property $\varphi$, the second program $P'_i$ contains the fix for the violation. Furthermore, except for the fix for the violation of $\varphi$, we have that $P_i$ and $P'_i$ are identical.
\item
Strategy learning: This stage uses the paired set of programs above as a training set to automatically learn a repair strategy \strategy for fixing the violation. Specifically, for any program, $P$ that violates $\varphi$ and roughly resembles one or more programs in $\mathcal{P}$, the goal is for $\strategy(P)$ to fix the violation of $\varphi$.
\end{enumerate}

We consider the class of information flow
safety properties. Violating these properties can result in the system becoming vulnerable to information flow attacks, allowing malicious user input to flow from an untrusted {\em source} (e.g., a server request, socket message, file upload) to a sensitive {\em sink} (e.g., dynamic function execution,
shell command, database query).
SQL Injection~\cite{sqlinjowasp},
cross-site scripting~\cite{wasp}, 
and prototype pollution~\cite{prototypepoll} are all
examples of information flow vulnerabilities. A common strategy to defend against such violations
is to use {\em sanitizers} and {\em guards} in the code to block such bad flows.
Sanitizers and guards ensure that only safe information reaches the sensitive sinks. Information flow safety is a non-local property and both checking and fixing violations require non-local analysis. 

\definecolor{dIns}{RGB}{227,255,237}
\definecolor{dInsP}{RGB}{199,255,217}
\definecolor{dInsPP}{RGB}{163,242,190}
\newcommand{\cbox}[2]{\adjustbox{margin=0pt 1.9pt, bgcolor=#1}{#2}}
\newcommand{\cmbox}[2]{\adjustbox{margin=0pt 2.4pt, bgcolor=#1, margin=0pt -2.4pt}{#2}}
\newcommand{\cmboxp}[2]{\adjustbox{margin=0pt 2.4pt, bgcolor=#1, margin=0.7pt -0.7pt, cframe=red, margin=0pt -2.4pt}{#2}}
\newcommand{\INS}[1]{\cbox{dIns}{\textbf{+}}\cbox{dIns}{ #1}}
\newcommand{\mINS}[1]{\cbox{dIns}{#1}}
\newcommand{\INSp}[1]{\cbox{dInsPP}{+ #1}}
%\newcommand{\INSp}[1]{\cbox{dInsPP}{\textbf{+}}\cbox{dInsPP}{ #1}}
\newcommand{\mINSp}[1]{\cbox{dInsPP}{#1}}
\newcommand{\yINS}[1]{\cbox{yellow}{#1}}


% Figure environment removed

We introduce \textbf{\sawitnessfull}, a new technique to collect a high-quality paired dataset of unsafe and safe programs. Instead of using the \sa tool to flag programs with violations, we use the internal information captured by the \sa\ tool on programs that satisfy the property, and identify the {\em reason} why the property is satisfied as a {\em witness}. In the case of information flow safety properties, these witnesses are usually sanitizers and guards in programs, which break the flow between untrusted sources and a trusted sinks.
By identifying and removing the witness, we introduce a violation and convert the safe program to an unsafe program, enabling us to construct safe-unsafe program pairs from programs that satisfy the property.

\lstMakeShortInline[columns=fixed]@
Consider the code snippets shown in Figure~\ref{fig:static-analysis-vs-witnessing}. In these code snippets, the value of @req@ comes from an untrusted source, and executing @action@ (which is dynamically derived from @actions@ map using @req.action@) can result in attacks. Programs (a), (b), and (c) are all examples of safe programs that satisfy the property, and the witnesses are highlighted. Program (d) is an unsafe program. By removing the witnesses, we transform each of the safe programs into unsafe variants and use these variants to construct safe-unsafe program pairs for the data collection phase.

For the strategy learning step, we use the paired set of programs as a training set and synthesize repair-strategies in a domain-specific-language (\dsl). We build on prior work in synthesizing program transformations from paired programs~\cite{rolim2017learning,zhang2022overwatch,bavishi2019phoenix}. However, information flow vulnerabilities are non-local, and repairing them is beyond the scope of previous work. Therefore, we design both a novel \dsl and a strategy learning algorithm that is able to learn strategies for such non-local repairs.
Consider the example shown in Figure~\ref{fig:vulnerabilty-example1}. The program in Figure~\ref{fig:unsafememberex} is vulnerable since there is a flow from the untrusted @JSON.Parse@ statement in line 12 to the trusted method invocation in line 6 without an intervening sanitizer. The repair here involves the introduction of the guard @if (handlers.hasOwnProperty(data.id))@ in line 5, as shown in Figure~\ref{fig:safememberex}. Learning such a repair involves (1) learning the location to introduce the repair (which is line 5 in this case), (2) learning the template of the guard that needs to be introduced (which is of the form @REF1.hasOwnProperty(REF2)@, where @REF1@ and @REF2@ are references, and (3) learning that @REF1@ and @REF2@ need to be materialized to @handlers@ and @data.id@ based on the given program. Our \dsl and strategy-learning algorithms (described in Section~\ref{sec:impl}) are novel, and are able to learn such intricate and non-local repairs, which involve analyzing both control and dataflows in the program.
\lstDeleteShortInline@



Prior works in static repair~\cite{bader2019getafix,bavishi2019phoenix,rolim2017learning,vurle,exampleBasedJava,sonarcube,revisar,genesis} make  simplifying assumptions. First, they assume the availability of  paired unsafe-safe program versions from version control. 
Second, the scope of repairs they consider are typically local.
Third, they consider statically typed languages like Java.
We focus on information flow vulnerabilities, which are inherently non-local, and we consider \js, which lacks static types. Moreover, we don't make the assumption that we have access to pairs of unsafe and safe programs.   
Instead, a single static snapshot of source-code repositories is sufficient for our technique.
Other approaches~\cite{hypergi,ACS:ICSE2017} in automatic program repair (APR) use program execution on vulnerability-causing examples which do not apply to repairing static 
vulnerabilities.
Crafting repair templates manually~\cite{senx,FootPatch,cdrep,bovinspector} is also challenging given the semantic nature of repairs.

We implemented the above approach consisting of static-analysis witnessing and strategy learning steps in a system \sysname.  In Section 6, we present an empirical evaluation of \sysname with code from several hundred {\sc JavaScript} open source repositories on Github. We use \codeql~\cite{codeql} as our \sa tool, and consider two specific instances of information flow vulnerabilities:
(1) unvalidated dynamic call (UDC), and (2) cross-site scripting (XSS).
For both these instances, we use static analysis witnessing and witness removal to generate unsafe-safe pairs, and learn repair strategies from this data. Then we evaluate the effectiveness of the learned repair strategies on all the violations detected by \codeql in these repositories. Thus, our training set is generated from correct coding patterns (which is that static analysis witnessing uses), and our validation set is the set of violations in these repositories (which are disjoint from the training set). We find that \sysname is able to correctly repair: (1)  {\bf 310} vulnerabilities with a success rate of {\bf 93.94\%}, in the case of unvalidated dynamic call, and (2) {\bf 617} vulnerabilities with a success rate of {\bf 91.82\%}, in the case of cross-site scripting. We compare the results with two neural baselines, namely one obtained by finetuning {\sc CodeT5}~\cite{Wang2021CodeT5IU} and the other obtained by few-shot prompting {\sc Codex}\cite{Codex} with the same training 
set as \sysname. We find that \sysname\ outperforms both these neural baselines.

\medskip
\noindent
To summarize, our main contributions are:
\begin{itemize}
\item
A new approach called static-analysis witnessing to produce unsafe-safe code pairs from programs that satisfy a property, and
\item
A novel DSL and strategy learning algorithm to learn non-local repair strategies from paired data sets (such as the ones generated from static analysis witnessing, or other approaches)
\end{itemize}
We present an implementation of the approaches in a tool, \sysname.  Our empirical results show that \sysname is able to correctly repair hundreds of violations in open source {\sc JavaScript} repositories, while outperforming neural baselines. We will publicly release the datasets used in our evaluation (Section~\ref{sec:experiments}).

% \out{
% Static analysis (\sa for brevity) checks that 
% a program satisfies a given formal specification 
%  by analyzing the source, without executing it. %It is an integral component of the software development cycle with a vital intake in the industry.
% However, the burden on developers for fixing the specification rule-violations 
%  detected by \sa
% can be significant. 
% We build a \textit{repair strategy learning system} (called \sysname) that fixes these rule-violations automatically. 
% In particular, we focus on repairing
% %the class of 
% \taintprop security vulnerabilities. %in programs where the repair operations require knowledge of program semantics. 
% Our primary insight is that the domain-knowledge  about program properties and semantics,  implicitly embedded in \sa tools  to find violations, is also  beneficial for repair. 
% %We tightly integrate this knowledge into our system to collect relevant program examples and learn general repair strategies efficiently.

% %Building on previous works~\cite{bader2019getafix,bavishi2019phoenix,rolim2017learning}, we learn repair strategies from data,  a tighter integration with the \sa tool in the  

% %We demonstrate how to use the implicit domain knowledge embedded within these \sa tools to build an automatic \textit{repair strategy learning system}. We instantiate our approach (\sysname) for learning repair strategies for \taintprop security vulnerabilities in \js. 
% %a static analysis rule, it is \unsure{easy} to also simultaneously build automatic program repair (\apr for brevity) systems that will also suggest fixes apart from pointing out the violations.

% %\naman{Dataflow, source, sink, sanitizer, guard, flow, are all undefined here and explained in 2.1} 
% Security vulnerabilities are challenging to repair.
% %\unsure{These challenges arise from the fact that repairing them requires esoteric knowledge which is usually present only with domain-experts. 
% %Therefore, developers have to resort to online forums, documentation, and looking at examples of existing repairs to understand repair strategies. 
% %On top of it, even after understanding the appropriate patching strategy, it needs to be applied in the context of the given program, which is still complex and requires repetitive operations.}
% %Hence, automatically suggesting repairs within the development cycle while detecting vulnerabilities will make the underlying system more secure and improve developer efficiency. 
% We focus on the class of \taintprop bugs where a user input from an unsafe \textit{source} can flow into a sensitive \textit{sink}. Thus, \taintprop bugs are long-context bugs with \textit{flow} across function or even file boundaries. Hence, local syntactic edits are insufficient and this inherent \textit{semantic} nature of the \taintprop bugs makes the automated repair process particularly challenging. 

% Prior work in static repair~\cite{bader2019getafix,bavishi2019phoenix,rolim2017learning,vurle,exampleBasedJava,sonarcube,revisar,genesis} make two simplifying assumptions. First, they assume the availability of  multiple versions of the same program. Given two {\em parallel} program versions, an unsafe version with the violation and a fixed version without the violation, these tools can automatically learn repairs to transform unsafe programs to safe programs. Second, these repairs have only been evaluated on  statically typed languages like Java. We focus on  \js that lacks static types. Moreover, we don't make the assumption that we have access to pairs of unsafe and safe programs.   
% %Here, we build upon the existing line of works~\cite{bader2019getafix,bavishi2019phoenix,rolim2017learning,vurle,exampleBasedJava,sonarcube,revisar,genesis} that learn repair strategies by using signals from \textit{good programs} written by developers in the past, for instance, present in public source code. However, unlike those approaches, we do not assume access to parallel safe and unsafe programs obtained by running \sa tool across version-controlled codebases, which  is prohibitively expensive because of the complex oracle \taintprop analysis.
% Instead,
% %we collect learning signals from 
% a single static snapshot of source-code repositories is sufficient for our technique. %In addition, we learn repair strategies that are aware of program semantics by using annotations from \sa and thus being more general. 
% Other approaches~\cite{ACS:ICSE2017,hypergi} in automatic program repair (APR) use program execution on vulnerability-causing examples which do not apply to repairing static %\taintprop 
% vulnerabilities %in \js.
% Crafting repair templates manually~\cite{liu2019avatar,cdrep,bovinspector} is also challenging given the semantic nature of repairs.

% % Previous approaches in automatic program repair have never attempted to fix \taintprop vulnerabilities in \js. These methods fall into the following classes, each with associated challenges preventing them from applying to \taintprop vulnerabilities.  
% % \begin{itemize}
% %     \item \unsure{type-driven input-output examples which do not work for \js!?} and depend on the set of inputs for generalization
% %     \item template-based repair with manually crafted templates which do not scale to a large number of vulnerabilities.
% %     \item data-driven techniques for mining templates or repair strategies~\cite{bavishi2019phoenix,bader2019getafix, rolim2017learning} -these approaches are closest to our work but a.) they assume access to parallel safe and unsafe programs, b.) learn repair strategies relying only on syntactic program patterns and do not use program semantics which is necessary for fixing \taintprop bugs.
% % \end{itemize}
% We propose a novel two-step pipeline where we generate parallel unsafe and safe data from a single program version, without  any version-controlled data, and then learn \textit{semantic} repair strategies from this data. We describe these stages below.

% %\aksays{This sentence doesn't seem necessary.} As described above, fixing these security violations is challenging. 
% %Existing works for automatic repair \aksays{citations?} of security violations tend to ignore the \textit{property} \aksays{Not clear what this means} aspect altogether and try to use test-cases for security bug identification which a.) can be expensive because of dynamic execution and \unsure{b.) may produce incomplete repairs that do not generalize beyond the examples?}. Alternative approaches \aksays{citations?} manually build patterns that can be applied to fix programs rather than learning them automatically in a scalable fashion. In this work, we learn these repair strategies from data, using a programming-by-examples (\pbe for brevity) approach that relies on \sa tools honoring the property aspect of security violations.
% %Another advantage of this reliance on \sa tools is that we can make use of the rich domain knowledge encoded in these tools primarily written manually and perfected over years. Specifically, our approach demonstrates that this knowledge is beneficial for repairing violations beyond just their detection. To this end, we develop \sysname, which is able to use these encoded semantics and knowledge to generate example pairs of unsafe-safe programs and learn more-general \aksays{more? general compared to what} strategies from them. \spsays{Add references to the related works?} \spsays{Categorize existing works into categories, ones that require manual patterns, neural fixers, etc..}

% % Figure environment removed

% %The way \sysname uses these \sa tools is partly inspired by how human developers use them. Specifically, apart from pointing out the location of violations, these tools also provide some explanation for the violation. In this work, we focus on source-sink taint-tracking violations where a tainted (external/user-controlled) value flows from a source variable into a sink function which can lead to malicious executions. \sa tools will usually point out the source and sink in the program along with the \textit{dataflow} between them. Developers then use the locations and explanations (inferred annotations) to fix the violation methodically. We automate this high-level process by providing the repair system access to the same information and encoding the repair steps as programmatic \aksays{programmatic -> learning of} repair strategies in a \dsl.

%  %Prior approaches for programming-by-example (\pbe) based program-repair~\cite{bavishi2019phoenix,bader2019getafix, rolim2017learning, zhang2022overwatch} (\unsure{this is beyond repair for static analysis, for e.g. prose refazer is not just for SA violations}) follow a two-step process where they first collect examples of incorrect-correct program pairs.  
% %for solving this would first require collecting appropriate data where these mistakes are fixed. A typical way to obtain this kind of data is to run a static analysis tool across source-control in a code base and use the commits where violations disappear as initial guesses for the edits to learn. Often, this is accompanied by hand-written heuristics to identify the minimal editing required to fix the bug (such as the delta-debugging approach used in ~\citet{bavishi2019phoenix}). 
% %With these examples, they learn repair strategies that transform examples of incorrect programs, operating on their abstract-syntax-tree (\astree) representations. 
% %\sysname also follows this two-staged approach, however, while using \sa tools in both phases, which in turn leads to better, more generalizable repair strategies. We outline our approach below.

% \lstMakeShortInline[columns=fixed]@
% \noindent \textbf{(I) Data Collection}  We introduce \textbf{\sawitnessfull}, a new technique to collect high-quality examples of safe and unsafe programs.
% Instead of using the \sa tool to detect programs with violations, we repurpose them to detect programs without violations along with \textit{witnesses} that lead to the absence of violations. These witnesses are usually \textit{sanitizers} and \textit{guards} (see Section ~\ref{sec:background}) in programs which \textit{break} the \unsure{flow} between a \textit{source} and a \textit{sink}.
% %that reasons and detects \safeprogs using the existing domain knowledge implemented in \sa tools.  
% %More specifically, instead of using the \sa tool to detect programs with violations, we can detect programs without violations along with features (\textit{witnesses}) of programs that lead to this absence. These witnesses are usually \textit{sanitizers} and \textit{guards} (see Section ~\ref{sec:background}) in programs which \textit{break} the \unsure{flow} between a \textit{source} and a \textit{sink}. We use this technique to collect high-quality examples of safe and unsafe programs.
% Figures~\ref{fig:static-witnessing-1},\ref{fig:static-witnessing-2}, and \ref{fig:static-witnessing-3} shows our technique in action for the \unvalidatedtype vulnerability~\cite{unvalidatedcodeql} where we detect the witness @typeof action === 'function'@ check. %is necessary for making the program safe. 
% Notice that this check occurs in different forms in different programs -- directly or alongside another condition logically (Line~\ref{lst:line:witness-1-line} in Figure~\ref{fig:static-witnessing-1}) or early returning (Line~\ref{lst:line:witness-2-line} in Figure~\ref{fig:static-witnessing-2}) or by cleverly using lazy execution\footnote{\js minification structurally modifies conditions into this fashion. Our witnessing technique detects such guards successfully} (Line~\ref{lst:line:witness-3-line} in Figure~\ref{fig:static-witnessing-3}). We remove these \textit{witnesses} to generate unsafe programs from safe programs.
% %and record these {\em edits}.
% %and \textit{edits}. 
% %which \sa tool detects originally. In contrast, Figure~\ref{fig:static-obedience} shows safe code detected by static-analysis-obedience with the highlighted snippet acting as the sanitizing agent. Once such annotated snippets are found, we simply perturb the detected code, removing the sanitizing agent and making it unsafe, thus obtaining high-quality unsafe-safe code pairs.
% \\
% \noindent \textbf{(II) Strategy Learning} We design a  domain-specific-language (\dsl) to express repair strategies and synthesize programs in this language using the collected data. These repair strategies take an unsafe program,
% annotated with semantic information by \sa,  as input and output an \textit{edit} operation sufficient to repair the AST of the input program. The annotations  include marking the AST nodes as \textit{sources} or \textit{sinks}, inserting semantic dataflow edges, etc., which are done by running the \sa tool on the unsafe program to detect violations.
% %itself and are beneficial for fixing these \taintprop vulnerabilities. 
% %Our repair strategies are strictly more expressive (capture a wider variety of fixes) than repairs that do not use program semantics. 
% Finally, we build a programming-by-examples (\pbe) program synthesis engine that uses the unsafe and safe programs collected in \textbf{(I)} to synthesize general repair strategies as programs in our \dsl. To this end, we define \textit{back-propagation} functions over the operators in our \dsl and use top-down enumerative synthesis. 
% %and develop a synthesis algorithm that can \aksays{learn} repair strategies in this \dsl from the examples collected in step \textbf{I}.
% \\
% \lstDeleteShortInline@



% % \begin{table}[]
% %     \centering
% %     \begin{tabular}{|p{0.36\linewidth}|p{0.6\linewidth}|}
% %         \hline
% %         Vulnerability & Description  \\
% %         \hline
% %         \unvalidatedmembership &  \\
% %         \unvalidatedtype & \\
% %         \unvalidatedcall & \\
% %         \protopoll & \\
% %         \xss & \\
% %         \hline
% %     \end{tabular}
% %     \caption{Various vulnerabilities we fix in this work}
% %     \label{tab:target-vulnerabities}
% % \end{table}

% We evaluate \sysname on five \js \taintprop vulnerabilities described in Table~\ref{tab:target-vulnerabities} with diverse and \textit{multi-step} repairs. We show that the repair strategies learned using our approach generalize beyond only repairing the artificially generated unsafe programs and can actually repair unsafe programs in public source code. We can repair up to \textbf{??\%} instances of ?? vulnerability. 
% %We also demonstrate the need for using semantic edges in the repair process (Section~\ref{}).
% To summarize, our work makes the following contributions 

% %We build our repair system for fixing security violations in \js which poses additional challenges because of the lack of type and run-time information. \js is a primary choice of developers for building servers and frontends because of well-backed ecosystems supporting the same making it an enticing choice for building our system. However, since we use \astree and \sa tools, our approach is general and can be made to work for any language. We instantiate \sysname, for the five vulnerabilities described in Table~\ref{tab:target-vulnerabities}. 
% %This set of vulnerabilities allows us to demonstrate the generalization of our framework across multiple repair types and languages. To evaluate our approach, we use two datasets - a) artificially generated unsafe program from \textbf{I)}, and b) naturally occurring unsafe program in public repositories. We find that our method, owing to its usage of semantic information from programs \aksays{the term "program snippets" has not be used/defined below}, outperforms existing static program repair tools~\cite{bavishi2019phoenix,??}. Additionally, we test our approach against and in conjunction with code-completion systems and find ??????.

% \begin{itemize}
%     \item We present \sysname, a general mechanism to build a repair system from a static analysis tool by utilizing  domain knowledge implicit in the implementations of these tools. We instantiate it for repairing five \taintprop vulnerabilities in \js.
%     \item We introduce the novel technique of \sawitnessfull for collecting high-quality examples of safe programs with their  witnesses from a snapshot of source code and a witness-removal step for generating their unsafe counterparts and corresponding edits (Section~\ref{sec:data}). We will release the collected data for public analysis. 
%     \item We design a \dsl that succinctly expresses repair strategies 
% %    operating over semantics annotated programs, thus making fixes more general 
% (Section~\ref{subsec:dsl}).
%  We further implement a top-down program synthesis that allows us to learn such repair strategies automatically in a \pbe fashion (Section~\ref{subsec:synthesis}).
%     \item \naman{We test our strategy for ??? vulnerabilities and fix ??? many violations in open source code }
% \end{itemize}

% %The rest of the paper proceeds as follows: Section~\ref{sec:background} motivates the approach with examples, Section~\ref{sec:data} and Section~\ref{sec:learning} explain our data collection and transformation learning steps, and Section~\ref{sec:experiments} demonstrates the efficacy of our approach.

% %Our hypothesis is that
% }}