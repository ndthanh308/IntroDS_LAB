\begin{thebibliography}{10}

\bibitem{hogan2016feedback}
F.~R. Hogan and A.~Rodriguez.
\newblock Feedback control of the pusher-slider system: A story of hybrid and
  underactuated contact dynamics.
\newblock {\em arXiv preprint arXiv:1611.08268}, 2016.

\bibitem{bauza2018data}
M.~Bauza, F.~R Hogan, and A.~Rodriguez.
\newblock A data-efficient approach to precise and controlled pushing.
\newblock In {\em Conference on Robot Learning}, pages 336--345. PMLR, 2018.

\bibitem{kloss2022combining}
A.~Kloss, S.~Schaal, and J.~Bohg.
\newblock Combining learned and analytical models for predicting action effects
  from sensory data.
\newblock {\em The International Journal of Robotics Research}, 41(8):778--797,
  2022.

\bibitem{yu2016more}
K.~Yu, M.~Bauza, N.~Fazeli, and A.~Rodriguez.
\newblock More than a million ways to be pushed. a high-fidelity experimental
  dataset of planar pushing.
\newblock In {\em 2016 IEEE/RSJ international conference on intelligent robots
  and systems (IROS)}, pages 30--37, 2016.

\bibitem{bauza2019omnipush}
M.~Bauza, F.~Alet, Y.~Lin, T.~Lozano-P{\'e}rez, L.~P Kaelbling, P.~Isola, and
  A.~Rodriguez.
\newblock Omnipush: accurate, diverse, real-world dataset of pushing dynamics
  with rgb-d video.
\newblock In {\em 2019 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 4265--4272, 2019.

\bibitem{zeng2018learning}
A.~Zeng, S.~Song, S.~Welker, J.~Lee, A.~Rodriguez, and T.~Funkhouser.
\newblock Learning synergies between pushing and grasping with self-supervised
  deep reinforcement learning.
\newblock In {\em 2018 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 4238--4245, 2018.

\bibitem{manuelli2020keypoints}
L.~Manuelli, Y.~Li, P.~Florence, and R.~Tedrake.
\newblock Keypoints into the future: Self-supervised correspondence in
  model-based reinforcement learning.
\newblock {\em arXiv preprint arXiv:2009.05085}, 2020.

\bibitem{krivic2019pushing}
S.~Krivic and J.~Piater.
\newblock Pushing corridors for delivering unknown objects with a mobile robot.
\newblock {\em Autonomous Robots}, 43(6):1435--1452, 2019.

\bibitem{lynch1992manipulation}
K.~M Lynch, H.~Maekawa, and K.~Tanie.
\newblock Manipulation and active sensing by pushing using tactile feedback.
\newblock In {\em IROS}, volume~1, pages 416--421, 1992.

\bibitem{lloyd2021goal}
J.~Lloyd and N.~Lepora.
\newblock Goal-{{Driven Robotic Pushing Using Tactile}} and {{Proprioceptive
  Feedback}}.
\newblock {\em IEEE Transactions on Robotics}, 38(2):1201--1212, April 2022.

\bibitem{church_tactile_2021}
A.~Church, J.~Lloyd, R.~Hadsell, and N.~Lepora.
\newblock Tactile {{Sim-to-Real Policy Transfer}} via {{Real-to-Sim Image
  Translation}}.
\newblock In {\em Proceedings of the 5th {{Conference}} on {{Robot Learning}}},
  pages 1645--1654. {PMLR}, October 2021.

\bibitem{lin2022tactile}
Y.~Lin, J.~Lloyd, A.~Church, and N.~F Lepora.
\newblock Tactile gym 2.0: Sim-to-real deep reinforcement learning for
  comparing low-cost high-resolution robot touch.
\newblock {\em IEEE Robotics and Automation Letters}, 7(4):10754--10761, 2022.

\bibitem{ward2018tactip}
B.~{Ward-Cherrier}, N.~Pestell, L.~Cramphorn, B.~Winstone, M.~E. Giannaccini,
  J.~Rossiter, and N.~Lepora.
\newblock The {{TacTip Family}}: {{Soft Optical Tactile Sensors}} with
  {{3D-Printed Biomimetic Morphologies}}.
\newblock {\em Soft Robotics}, 5(2):216--227, April 2018.

\bibitem{lepora2020optimal}
N.~F Lepora and J.~Lloyd.
\newblock Optimal deep learning for robot touch: Training accurate pose models
  of 3d surfaces and edges.
\newblock {\em IEEE Robotics \& Automation Magazine}, 27(2):66--77, 2020.

\bibitem{mason1986mechanics}
M.~T Mason.
\newblock Mechanics and planning of manipulator pushing operations.
\newblock {\em The International Journal of Robotics Research}, 5(3):53--71,
  1986.

\bibitem{ajay2018augmenting}
A.~Ajay, J.~Wu, N.~Fazeli, M.~Bauza, L.~P Kaelbling, J.~B Tenenbaum, and
  A.~Rodriguez.
\newblock Augmenting physical simulators with stochastic neural networks: Case
  study of planar pushing and bouncing.
\newblock In {\em 2018 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 3066--3073, 2018.

\bibitem{arruda2017uncertainty}
E.~Arruda, M.~J Mathew, M.~Kopicki, M.~Mistry, M.~Azad, and J.~L Wyatt.
\newblock Uncertainty averse pushing with model predictive path integral
  control.
\newblock In {\em 2017 IEEE-RAS 17th International Conference on Humanoid
  Robotics (Humanoids)}, pages 497--502, 2017.

\bibitem{cong2020self}
L.~Cong, M.~Grner, P.~Ruppel, H.~Liang, N.~Hendrich, and J.~Zhang.
\newblock Self-adapting recurrent models for object pushing from learning in
  simulation.
\newblock In {\em 2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 5304--5310, 2020.

\bibitem{plappert2018multi}
M.~Plappert, M.~Andrychowicz, A.~Ray, B.~McGrew, B.~Baker, G.~Powell,
  J.~Schneider, J.~Tobin, M.~Chociej, P.~Welinder, et~al.
\newblock Multi-goal reinforcement learning: Challenging robotics environments
  and request for research.
\newblock {\em arXiv preprint arXiv:1802.09464}, 2018.

\bibitem{ebert2018visual}
F.~Ebert, C~Finn, S.~Dasari, A.~Xie, A.~Lee, and S.~Levine.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock {\em arXiv preprint arXiv:1812.00568}, 2018.

\bibitem{nair2018visual}
A.~V Nair, V.~Pong, M.~Dalal, S.~Bahl, S.~Lin, and S.~Levine.
\newblock Visual reinforcement learning with imagined goals.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{cong2022reinforcement}
L.~Cong, H.~Liang, P.~Ruppel, Y.~Shi, M.~G{\"o}rner, N.~Hendrich, and J.~Zhang.
\newblock Reinforcement learning with vision-proprioception model for robot
  planar pushing.
\newblock {\em Frontiers in Neurorobotics}, 16, 2022.

\bibitem{dong2021tactile}
S.~Dong, D.~K Jha, D.~Romeres, S.~Kim, D.~Nikovski, and A.~Rodriguez.
\newblock Tactile-rl for insertion: Generalization to objects of unknown
  geometry.
\newblock In {\em 2021 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 6437--6443, {Xi'an China}, May 2021.

\bibitem{Ding2020Sim-to-RealSensing}
Z.~Ding, N.~F. Lepora, and E.~Johns.
\newblock {Sim-to-Real Transfer for Optical Tactile Sensing}.
\newblock In {\em 2020 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 1639--1645, Paris, France, May 2020.

\bibitem{bauza2020tactile}
M.~Bauza, E.~Valls, B.~Lim, T.~Sechopoulos, and A.~Rodriguez.
\newblock Tactile object pose estimation from the first touch with geometric
  contact rendering.
\newblock {\em arXiv preprint arXiv:2012.05205}, 2020.

\bibitem{gomes2021generation}
P.~Paoletti D.~F.~Gomes and S.~Luo.
\newblock Generation of gelsight tactile images for sim2real learning.
\newblock {\em IEEE Robotics and Automation Letters}, 6(2):4177--4184, April
  2021.

\bibitem{wang2022tacto}
S.~Wang, M.~Lambeta, P.~Chou, and R.~Calandra.
\newblock {{TACTO}}: {{A Fast}}, {{Flexible}}, and {{Open-Source Simulator}}
  for {{High-Resolution Vision-Based Tactile Sensors}}.
\newblock {\em IEEE Robotics and Automation Letters}, 7(2):3930--3937, April
  2022.

\bibitem{si2022taxim}
Z.~Si and W.~Yuan.
\newblock Taxim: An example-based simulation model for gelsight tactile
  sensors.
\newblock {\em IEEE Robotics and Automation Letters}, 7(2):2361--2368, April
  2022.

\bibitem{kaelbling1993learning}
L.~P. Kaelbling.
\newblock Learning to achieve goals.
\newblock In {\em IJCAI}, volume~2, pages 1094--8. Citeseer, 1993.

\bibitem{haarnoja2018soft}
T.~Haarnoja, A.~Zhou, P.~Abbeel, and S.~Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In {\em International conference on machine learning}, pages
  1861--1870. PMLR, 2018.

\bibitem{raffin2019stable}
A.~Raffin, A.~Hill, M.~Ernestus, A.~Gleave, A.~Kanervisto, and N.~Dormann.
\newblock Stable baselines3, 2019.

\bibitem{chua2018deep}
K.~Chua, R.~Calandra, R.~McAllister, and S.~Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{pineda2021mbrl}
L.~Pineda, B.~Amos, A.~Zhang, N.~O Lambert, and R.~Calandra.
\newblock Mbrl-lib: A modular library for model-based reinforcement learning.
\newblock {\em arXiv preprint arXiv:2104.10159}, 2021.

\bibitem{trott2019keeping}
A.~Trott, S.~Zheng, C.~Xiong, and R.~Socher.
\newblock Keeping your distance: Solving sparse reward tasks using
  self-balancing shaped rewards.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{lepora2022digitac}
N.~F Lepora, Y.~Lin, B.~Money-Coomes, and J.~Lloyd.
\newblock Digitac: A digit-tactip hybrid tactile sensor for comparing low-cost
  high-resolution robot touch.
\newblock {\em IEEE Robotics and Automation Letters}, 7(4):9382--9388, 2022.

\bibitem{calli2015benchmarking}
B.~Calli, A.~Walsman, A.~Singh, S.~Srinivasa, P.~Abbeel, and A.~M Dollar.
\newblock Benchmarking in manipulation research: The ycb object and model set
  and benchmarking protocols.
\newblock {\em arXiv preprint arXiv:1502.03143}, 2015.

\end{thebibliography}
