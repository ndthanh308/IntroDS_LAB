@inproceedings{sunderhauf2018limits,
  title={The limits and potentials of deep learning for robotics},
  author={S{\"u}nderhauf, Niko and Brock, Oliver and Scheirer, Walter and Hadsell, Raia and Fox, Dieter and Leitner, J{\"u}rgen and Upcroft, Ben and Abbeel, Pieter and Burgard, Wolfram and Milford, Michael and others},
  journal={The International journal of robotics research},
  volume={37},
  number={4-5},
  pages={405--420},
  month = apr,
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}


@article{lepora2021soft,
  title = {Soft {{Biomimetic Optical Tactile Sensing With}} the {{TacTip}}: {{A Review}}},
  shorttitle = {Soft {{Biomimetic Optical Tactile Sensing With}} the {{TacTip}}},
  author = {Lepora, N.},
  year = {2021},
  month = oct,
  journal = {IEEE Sensors Journal},
  volume = {21},
  number = {19},
  pages = {21131--21143},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2021.3100645},
  abstract = {Reproducing the capabilities of the human sense of touch in machines is an important step in enabling robot manipulation to have the ease of human dexterity. A combination of robotic technologies will be needed, including soft robotics, biomimetics and the high-resolution sensing offered by optical tactile sensors. This combination is considered here as a SoftBOT (Soft Biomimetic Optical Tactile) sensor. This article reviews the BRL TacTip as a prototypical example of such a sensor. Topics include the relation between artificial skin morphology and the transduction principles of human touch, the nature and benefits of tactile shear sensing, 3D printing for fabrication and integration into robot hands, the application of AI to tactile perception and control, and the recent step-change in capabilities due to deep learning. This review consolidates those advances from the past decade to indicate a path for robots to reach human-like dexterity.},
  langid = {english},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\C9LJUVKZ\\Lepora - 2021 - Soft Biomimetic Optical Tactile Sensing With the T.pdf}
}

@article{fernandez2016comparison,
  title={A comparison of tactile sensors for in-hand object location},
  author={Fernandez, Raul and Vazquez, Andres S and Payo, Ismael and Adan, Antonio},
  journal={Journal of Sensors},
  volume={2016},
  year={2016},
  publisher={Hindawi}
}

@article{vidal2011three,
  title={Three realizations and comparison of hardware for piezoresistive tactile sensors},
  author={Vidal-Verd{\'u}, Fernando and Oballe-Peinado, {\'O}scar and S{\'a}nchez-Dur{\'a}n, Jos{\'e} A and Castellanos-Ramos, Juli{\'a}n and Navas-Gonz{\'a}lez, Rafael},
  journal={Sensors},
  volume={11},
  number={3},
  pages={3249--3266},
  year={2011},
  publisher={Molecular Diversity Preservation International}
}

@inproceedings{chorley2009development,
  title={Development of a tactile sensor based on biologically inspired edge encoding},
  author={Chorley, Craig and Melhuish, Chris and Pipe, Tony and Rossiter, Jonathan},
  booktitle={2009 International Conference on Advanced Robotics},
  pages={1--6},
  year={2009},
  
}


@article{lloyd2021goal,
  title = {Goal-{{Driven Robotic Pushing Using Tactile}} and {{Proprioceptive Feedback}}},
  author = {Lloyd, J. and Lepora, N.},
  year = {2022},
  month = apr,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {2},
  pages = {1201--1212},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2021.3104471},
  abstract = {In robots, nonprehensile manipulation operations such as pushing are a useful way of moving large, heavy, or unwieldy objects, moving multiple objects at once, or reducing uncertainty in the location or pose of objects. In this study, we propose a reactive and adaptive method for robotic pushing that uses rich feedback from a high-resolution optical tactile sensor to control push movements instead of relying on analytical or data-driven models of push interactions. Specifically, we use goal-driven tactile exploration to actively search for stable pushing configurations that cause the object to maintain its pose relative to the pusher while incrementally moving the pusher and object toward the target. We evaluate our method by pushing objects across planar and curved surfaces. For planar surfaces, we show that the method is accurate and robust to variations in initial contact position/angle, object shape, and start position; for curved surfaces, the performance is degraded slightly. An immediate consequence of our work is that it shows that explicit models of push interactions might be sufficient but are not necessary for this type of task. It also raises the interesting question of which aspects of the system should be modeled to achieve the best performance and generalization across a wide range of scenarios. Finally, it highlights the importance of testing on nonplanar surfaces and in other more complex environments when developing new methods for robotic pushing.},
  langid = {english},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\26XVU7QN\\Lloyd and Lepora - 2022 - Goal-Driven Robotic Pushing Using Tactile and Prop.pdf}
}

@article{do2022densetact,
  title={DenseTact: Optical Tactile Sensor for Dense Shape Reconstruction},
  author={Do, Won Kyung and Kennedy III, Monroe},
  journal={arXiv preprint arXiv:2201.01367},
  year={2022}
}

@article{yuan2017gelsight,
  title={Gelsight: High-resolution robot tactile sensors for estimating geometry and force},
  author={W. Yuan and S. Dong and E. H. Adelson},
  journal={Sensors},
  volume={17},
  number={12},
  pages={2762},
  year={2017},
  month=nov,
}

@inproceedings{luo2018vitac,
  title={Vitac: Feature sharing between vision and tactile sensing for cloth texture recognition},
  author={Luo, Shan and Yuan, Wenzhen and Adelson, Edward and Cohn, Anthony G and Fuentes, Raul},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2722--2727},
  year={2018},
  
}

@article{pestell2019sense,
  title={A sense of touch for the shadow modular grasper},
  author={Pestell, Nicholas and Cramphorn, Luke and Papadopoulos, Fotios and Lepora, Nathan F},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={2},
  pages={2220--2226},
  year={2019},
  
}


@article{lambeta2020digit,
  title = {{{DIGIT}}: {{A Novel Design}} for a {{Low-Cost Compact High-Resolution Tactile Sensor With Application}} to {{In-Hand Manipulation}}},
  shorttitle = {{{DIGIT}}},
  author = {Lambeta, M. and Chou, P. and Tian, S. and Yang, B. and Maloon, B. and Most, V. and Stroud, D. and Santos, R. and Byagowi, A. and Kammerer, G. and Jayaraman, D. and Calandra, R.},
  year = {2020},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {3},
  pages = {3838--3845},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2020.2977257},
  abstract = {Despite decades of research, general purpose in-hand manipulation remains one of the unsolved challenges of robotics. One of the contributing factors that limit current robotic manipulation systems is the difficulty of precisely sensing contact forces \textendash{} sensing and reasoning about contact forces are crucial to accurately control interactions with the environment. As a step towards enabling better robotic manipulation, we introduce DIGIT, an inexpensive, compact, and high-resolution tactile sensor geared towards in-hand manipulation. DIGIT improves upon past vision-based tactile sensors by miniaturizing the form factor to be mountable on multi-fingered hands, and by providing several design improvements that result in an easier, more repeatable manufacturing process, and enhanced reliability. We demonstrate the capabilities of the DIGIT sensor by training deep neural network model-based controllers to manipulate glass marbles in-hand with a multi-finger robotic hand. To provide the robotic community access to reliable and low-cost tactile sensors, we open-source the DIGIT design at www.digit.ml.},
  langid = {english},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\NWQPBML7\\Lambeta et al. - 2020 - DIGIT A Novel Design for a Low-Cost Compact High-.pdf}
}



@article{ward2018tactip,
  title = {The {{TacTip Family}}: {{Soft Optical Tactile Sensors}} with {{3D-Printed Biomimetic Morphologies}}},
  shorttitle = {The {{TacTip Family}}},
  author = {{Ward-Cherrier}, B. and Pestell, N. and Cramphorn, L. and Winstone, B. and Giannaccini, M. E. and Rossiter, J. and Lepora, N.},
  month=apr,
  year = {2018},
  journal = {Soft Robotics},
  volume = {5},
  number = {2},
  pages = {216--227},
  issn = {2169-5172},
  doi = {10.1089/soro.2017.0052},
  abstract = {Tactile sensing is an essential component in human\textendash robot interaction and object manipulation. Soft sensors allow for safe interaction and improved gripping performance. Here we present the TacTip family of sensors: a range of soft optical tactile sensors with various morphologies fabricated through dual-material 3D printing. All of these sensors are inspired by the same biomimetic design principle: transducing deformation of the sensing surface via movement of pins analogous to the function of intermediate ridges within the human fingertip. The performance of the TacTip, TacTip-GR2, TacTip-M2, and TacCylinder sensors is here evaluated and shown to attain submillimeter accuracy on a rolling cylinder task, representing greater than 10-fold super-resolved acuity. A version of the TacTip sensor has also been open-sourced, enabling other laboratories to adopt it as a platform for tactile sensing and manipulation research. These sensors are suitable for real-world applications in tactile perception, exploration, and manipulation, and will enable further research and innovation in the field of soft tactile sensing.},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\26J7UBYF\\Ward-Cherrier et al. - 2018 - The TacTip Family Soft Optical Tactile Sensors wi.pdf;C\:\\Users\\nl13426\\Zotero\\storage\\86QJT4J8\\soro.2017.html;C\:\\Users\\nl13426\\Zotero\\storage\\WBVXCBCY\\soro.2017.html}
}



@inproceedings{church_tactile_2021,
  title = {Tactile {{Sim-to-Real Policy Transfer}} via {{Real-to-Sim Image Translation}}},
  booktitle = {Proceedings of the 5th {{Conference}} on {{Robot Learning}}},
  author = {Church, A. and Lloyd, J. and Hadsell, R. and Lepora, N.},
  year = {2021},
  month = oct,
  pages = {1645--1654},
  publisher = {{PMLR}},
  abstract = {Simulation has recently become key for deep reinforcement learning to safely and efficiently acquire general and complex control policies from visual and proprioceptive inputs. Tactile information is not usually considered despite its direct relation to environment interaction. In this work, we present a suite of simulated environments tailored towards tactile robotics and reinforcement learning. A simple and fast method of simulating optical tactile sensors is provided, where high-resolution contact geometry is represented as depth images. Proximal Policy Optimisation (PPO) is used to learn successful policies across all considered tasks. A data-driven approach enables translation of the current state of a real tactile sensor to corresponding simulated depth images. This policy is implemented within a real-time control loop on a physical robot to demonstrate zero-shot sim-to-real policy transfer on several physically-interactive tasks requiring a sense of touch.},
  langid = {english},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\TJHBC8B6\\Church et al. - 2022 - Tactile Sim-to-Real Policy Transfer via Real-to-Si.pdf}
}

@article{lepora2020optimal,
  title={Optimal deep learning for robot touch: Training accurate pose models of 3D surfaces and edges},
  author={Lepora, N. F and Lloyd, J.},
  journal={IEEE Robotics \& Automation Magazine},
  volume={27},
  number={2},
  pages={66--77},
  year={2020},
  
}



@InProceedings{isola2017image,
author = {P. Isola and J. Y. Zhu and T. Zhou and A. A Efros},
title = {Image-To-Image Translation With Conditional Adversarial Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages={1125--1134},
month = {July},
year = {2017}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={O. Ronneberger and P. Fischer and T. Brox},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  month=nov,
}





@InProceedings{ioffe2015batch,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {S. Ioffe and C. Szegedy},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  volume = 	 {37},
  address = 	 {Lille, France},
  month = jul,
  pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/ioffe15.html},
  abstract = 	 {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={A. Krizhevsky and I. Sutskever and G. E Hinton},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012},
  month=dec,
}



@article{church2020deep,
  title = {Deep reinforcement learning for tactile robotics: Learning to type on a braille keyboard},
  author = {A. Church and J. Lloyd and R. Hadsell and N. F Lepora},
  year = {2019},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume={5},
  number={4},
  pages={6145--6152},
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{donlon2018gelslim,
  title={Gelslim: A high-resolution, compact, robust, and calibrated tactile-sensing finger},
  author={Donlon, Elliott and Dong, Siyuan and Liu, Melody and Li, Jianhua and Adelson, Edward and Rodriguez, Alberto},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1927--1934},
  year={2018},
  
}

@article{abad2020visuotactile,
  title={Visuotactile sensors with emphasis on gelsight sensor: A review},
  author={A. C. Abad and A. Ranasinghe},
  journal={IEEE Sensors Journal},
  volume={20},
  number={14},
  pages={7628--7638},
  year={2020},
  month=jul,
  
}



@article{lepora2021pose,
  title = {Pose-{{Based Tactile Servoing}}: {{Controlled Soft Touch Using Deep Learning}}},
  shorttitle = {Pose-{{Based Tactile Servoing}}},
  author = {Lepora, N. and Lloyd, J.},
  year = {2021},
  month = dec,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {28},
  number = {4},
  pages = {43--55},
  issn = {1070-9932, 1558-223X},
  doi = {10.1109/MRA.2021.3096141},
  langid = {english},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\VGECSD88\\Lepora and Lloyd - 2021 - Pose-Based Tactile Servoing Controlled Soft Touch.pdf}
}

@misc{raffin2019stable,
  title={Stable baselines3},
  author={Raffin, A. and Hill, A. and Ernestus, M. and Gleave, A. and Kanervisto, A. and Dormann, N.},
  year={2019}
}

@inproceedings{padmanabha2020omnitact,
  title={Omnitact: A multi-directional high-resolution touch sensor},
  author={Padmanabha, A. and Ebert, F. and Tian, S. and Calandra, R. and Finn, C. and Levine, S.},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={618--624},
  year={2020},
  
}


@inproceedings{lambeta2021pytouch,
  title = {{{PyTouch}}: {{A Machine Learning Library}} for {{Touch Processing}}},
  shorttitle = {{{PyTouch}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lambeta, M. and Xu, H. and Xu, J. and Chou, P. and Wang, S. and Darrell, T. and Calandra, R.},
  year = {2021},
  month = may,
  pages = {13208--13214},
  address = {{Xi'an, China}},
  doi = {10.1109/ICRA48506.2021.9561084},
  abstract = {With the increased availability of rich tactile sensors, there is an an equally proportional need for open-source and integrated software capable of efficiently and effectively processing raw touch measurements into high-level signals that can be used for control and decision-making. In this paper, we present PyTouch \textendash{} the first machine learning library dedicated to the processing of touch sensing signals. PyTouch, is designed to be modular, easy-to-use and provides state-of-the-art touch processing capabilities as a service with the goal of unifying the tactile sensing community by providing a library for building scalable, proven, and performance-validated modules over which applications and research can be built upon. We evaluate PyTouch on real-world data from several tactile sensors on touch processing tasks such as touch detection, slip and object pose estimations. PyTouch is open-sourced at https://github.com/facebookresearch/pytouch.},
  keywords = {Libraries,Machine learning,Pose estimation,Sensors,Software architecture,Software libraries,Tactile sensors},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\BUXADCU9\\Lambeta et al. - 2021 - PyTouch A Machine Learning Library for Touch Proc.pdf;C\:\\Users\\nl13426\\Zotero\\storage\\EE7W2T93\\9561084.html}
}


@article{wang2022tacto,
  title = {{{TACTO}}: {{A Fast}}, {{Flexible}}, and {{Open-Source Simulator}} for {{High-Resolution Vision-Based Tactile Sensors}}},
  shorttitle = {{{TACTO}}},
  author = {Wang, S. and Lambeta, M. and Chou, P. and Calandra, R.},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {3930--3937},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3146945},
  abstract = {Simulators perform an important role in prototyping, debugging, and benchmarking new advances in robotics and learning for control. Although many physics engines exist, some aspects of the real world are harder than others to simulate. One of the aspects that have so far eluded accurate simulation is touch sensing. To address this gap, we present TACTO \textendash{} a fast, flexible, and open-source simulator for vision-based tactile sensors. This simulator allows to render realistic high-resolution touch readings at hundreds of frames per second, and can be easily configured to simulate different vision-based tactile sensors, including DIGIT and OmniTact. In this letter, we detail the principles that drove the implementation of TACTO and how they are reflected in its architecture. We demonstrate TACTO on a perceptual task, by learning to predict grasp stability using touch from 1 million grasps, and on a marble manipulation control task. Moreover, we provide a proof-of-concept that TACTO can be successfully used for Sim2Real applications. We believe that TACTO is a step towards the widespread adoption of touch sensing in robotic applications, and to enable machine learning practitioners interested in multi-modal learning and control.},
  keywords = {Cameras,Deep Learning in Robotics and Automation,Engines,force and tactile sensing,Force and Tactile Sensing,learning and adaptive systems,Learning and Adaptive Systems,perception for grasping and manipulation,Perception for Grasping and Manipulation,Physics,Rendering (computer graphics),Robot sensing systems,Simulation and animation; deep learning in robotics and automation,Tactile sensors,Task analysis},
  file = {C\:\\Users\\nl13426\\Zotero\\storage\\23WRMBL5\\Wang et al. - 2022 - TACTO A Fast, Flexible, and Open-Source Simulator.pdf;C\:\\Users\\nl13426\\Zotero\\storage\\9T6MDYRG\\Wang et al. - 2022 - TACTO A Fast, Flexible, and Open-source Simulator.pdf;C\:\\Users\\nl13426\\Zotero\\storage\\FHAFVNMJ\\9697425.html}
}

@inproceedings{dong2021tactile,
  title={Tactile-rl for insertion: Generalization to objects of unknown geometry},
  author={S. Dong and D. K Jha and D. Romeres and S. Kim and D. Nikovski and A. Rodriguez},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6437--6443},
  year = {2021},
  month = may,
  address = {{Xi'an China}},
}



@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author =       {S. Fujimoto and H. Hoof and D. Meger},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1587--1596},
  year = 	 {2018},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = jul,
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/fujimoto18a.html},
  abstract = 	 {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.}
}



@inproceedings{kim2021active,
  title={Active Extrinsic Contact Sensing: Application to General Peg-in-Hole Insertion},
  author={S. Kim and A. Rodriguez},
  booktitle={2022 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10241--10247},
  year = {2022},
  month = may,
  address = {{Philadelphia, PA, USA}},
}


@article{xu2021towards,
  title={Towards Learning to Play Piano with Dexterous Hands and Touch},
  author={H. Xu and Y. Luo and S. Wang and T. Darrell and R. Calandra},
  journal={arXiv preprint arXiv:2106.02040},
  year={2021},
  month=jun
}

@inproceedings{van2016stable,
  title={Stable reinforcement learning with autoencoders for tactile and visual data},
  author={H. van Hoof and N. Chen and M. Karl and P. van der Smagt and J. Peters},
  booktitle={2016 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={3928--3934},
  year={2016},
  month=oct,
  
}

@inproceedings{veiga2017tactile,
  title={Tactile based forward modeling for contact location control},
  author={F. Veiga and D. Notz and T. Hesse and J. Peters},
  booktitle={RSS Workshop on Tactile Sensing for Manipulation},
  year={2017},
  month=may
}



@inproceedings{tian2019manipulation,
  title = {Manipulation by feel: Touch-based control with deep predictive models},
  booktitle = {2019 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {S. Tian and F. Ebert and D. Jayaraman and M. Mudigonda and C. Finn and R. Calandra and S. Levine},
  year = {2019},
  month = may,
  pages = {818--824},
  address = {{Montreal, QC, Canada}},
}


@inproceedings{narang2021sim,
  title={Sim-to-real for robotic tactile sensing via physics-based simulation and learned latent projections},
  author={Y. Narang and B. Sundaralingam and M. Macklin and A. Mousavian and D. Fox},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  address = {{Xi'an, China}},
  year={2021},
  page={6444--6451},
  month=may
}

@article{narang2021interpreting,
  title={Interpreting and predicting tactile signals for the SynTouch Biotac},
  author={Y. S Narang and B. Sundaralingam and K. Van Wyk and A. Mousavian and D. Fox},
  volume={40},
  number={12-14},
  pages = {1467--1487},
  journal={The International Journal of Robotics Research},
  year={2021},
  month= dec
}


@inproceedings{sferrazza2020learning,
  title={Learning the sense of touch in simulation: a sim-to-real strategy for vision-based tactile sensing},
  author={C. Sferrazza and T. Bi and R. D’Andrea},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4389--4396},
  year={2020},
  month=oct,
  address={Las Vegas, NV, USA},
  
}

@article{sferrazza2020sim,
  title={Sim-to-real for high-resolution optical tactile sensing: From images to 3D contact force distributions},
  author={C. Sferrazza and R. D’Andrea},
  journal={Soft Robotics},
  volume = {ahead-of-print},
  number = {},
  pages={},
  year={2021},
  month=nov,
}



  
  
@article{bi2021zero,
  title={Zero-shot sim-to-real transfer of tactile control policies for aggressive swing-up manipulation},
  author={T. Bi and C. Sferrazza and R. D’Andrea},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={5761--5768},
  month=jul,
  year={2021},
}


@inproceedings{Ding2020Sim-to-RealSensing,
 author = {Z. Ding and N. F. Lepora and E. Johns},
 booktitle = {2020 IEEE International Conference on Robotics and Automation (ICRA)},
 pages = {1639--1645},
 title = {{Sim-to-Real Transfer for Optical Tactile Sensing}},
 address={Paris, France},
 year = {2020},
 month= may,
}



@article{gomes2021generation,
  title={Generation of gelsight tactile images for sim2real learning},
  author={D. F. Gomes, P. Paoletti and S. Luo},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={4177--4184},
  year={2021},
  month=apr,
  
}

@article{si2022taxim,
  title={Taxim: An Example-based Simulation Model for GelSight Tactile Sensors},
  author={Z. Si and W. Yuan},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={2361--2368},
  year={2022},
  month=apr,
}

@article{jianu2021reducing,
  title={Reducing Tactile Sim2Real Domain Gaps via Deep Texture Generation Networks},
  author={Jianu, T. and Gomes, D. F. and Luo, S.},
  journal={arXiv preprint arXiv:2112.01807},
  year={2021}
}

@Manual{blender,
   title = {Blender - a 3D modelling and rendering package},
   author = {Blender Online Community},
   organization = {Blender Foundation},
   address = {Stichting Blender Foundation, Amsterdam},
   year = {2018},
   url = {http://www.blender.org},
 }
 
@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@article{plappert2018multi,
  title={Multi-goal reinforcement learning: Challenging robotics environments and request for research},
  author={Plappert, M. and Andrychowicz, M. and Ray, A. and McGrew, B. and Baker, B. and Powell, G. and Schneider, J. and Tobin, J. and Chociej, M. and Welinder, P. and others},
  journal={arXiv preprint arXiv:1802.09464},
  year={2018}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, T. and Zhou, A. and Abbeel, P. and Levine, S.},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, K. and Calandra, R. and McAllister, R. and Levine, S.},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{pineda2021mbrl,
  title={Mbrl-lib: A modular library for model-based reinforcement learning},
  author={Pineda, L. and Amos, B. and Zhang, A. and Lambert, N. O and Calandra, R.},
  journal={arXiv preprint arXiv:2104.10159},
  year={2021}
}

@article{lin2022tactile,
  title={Tactile Gym 2.0: Sim-to-Real Deep Reinforcement Learning for Comparing Low-Cost High-Resolution Robot Touch},
  author={Lin, Y. and Lloyd, J. and Church, A. and Lepora, N. F},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={10754--10761},
  year={2022},
  publisher={IEEE}
}

@inproceedings{yu2016more,
  title={More than a million ways to be pushed. a high-fidelity experimental dataset of planar pushing},
  author={Yu, K. and Bauza, M. and Fazeli, N. and Rodriguez, A.},
  booktitle={2016 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={30--37},
  year={2016},
  
}

@article{mason1986mechanics,
  title={Mechanics and planning of manipulator pushing operations},
  author={Mason, M. T},
  journal={The International Journal of Robotics Research},
  volume={5},
  number={3},
  pages={53--71},
  year={1986},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{hogan2016feedback,
  title={Feedback control of the pusher-slider system: A story of hybrid and underactuated contact dynamics},
  author={Hogan, F. R. and Rodriguez, A.},
  journal={arXiv preprint arXiv:1611.08268},
  year={2016}
}

@inproceedings{hogan2020feedback,
  title={Feedback control of the pusher-slider system: A story of hybrid and underactuated contact dynamics},
  author={Hogan, Fran{\c{c}}ois Robert and Rodriguez, Alberto},
  booktitle={Algorithmic Foundations of Robotics XII: Proceedings of the Twelfth Workshop on the Algorithmic Foundations of Robotics},
  pages={800--815},
  year={2020},
  organization={Springer}
}

@inproceedings{bauza2018data,
  title={A data-efficient approach to precise and controlled pushing},
  author={Bauza, M. and Hogan, F. R and Rodriguez, A.},
  booktitle={Conference on Robot Learning},
  pages={336--345},
  year={2018},
  organization={PMLR}
}

@article{kloss2022combining,
  title={Combining learned and analytical models for predicting action effects from sensory data},
  author={Kloss, A. and Schaal, S. and Bohg, J.},
  journal={The International Journal of Robotics Research},
  volume={41},
  number={8},
  pages={778--797},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{bauza2019omnipush,
  title={Omnipush: accurate, diverse, real-world dataset of pushing dynamics with rgb-d video},
  author={Bauza, M. and Alet, F. and Lin, Y. and Lozano-P{\'e}rez, T. and Kaelbling, L. P and Isola, P. and Rodriguez, A.},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4265--4272},
  year={2019},
  
}

@inproceedings{lowrey2018reinforcement,
  title={Reinforcement learning for non-prehensile manipulation: Transfer from simulation to physical system},
  author={Lowrey, Kendall and Kolev, Svetoslav and Dao, Jeremy and Rajeswaran, Aravind and Todorov, Emanuel},
  booktitle={2018 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)},
  pages={35--42},
  year={2018},
  
}

@article{cong2022reinforcement,
  title={Reinforcement Learning With Vision-Proprioception Model for Robot Planar Pushing},
  author={Cong, L. and Liang, H. and Ruppel, P. and Shi, Y. and G{\"o}rner, M. and Hendrich, N. and Zhang, J.},
  journal={Frontiers in Neurorobotics},
  volume={16},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{manuelli2020keypoints,
  title={Keypoints into the future: Self-supervised correspondence in model-based reinforcement learning},
  author={Manuelli, L. and Li, Y. and Florence, P. and Tedrake, R.},
  journal={arXiv preprint arXiv:2009.05085},
  year={2020}
}

@inproceedings{cong2020self,
  title={Self-adapting recurrent models for object pushing from learning in simulation},
  author={Cong, L. and Grner, M. and Ruppel, P. and Liang, H. and Hendrich, N. and Zhang, J.},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5304--5310},
  year={2020},
  
}

@inproceedings{zeng2018learning,
  title={Learning synergies between pushing and grasping with self-supervised deep reinforcement learning},
  author={Zeng, A. and Song, S. and Welker, S. and Lee, J. and Rodriguez, A. and Funkhouser, T.},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4238--4245},
  year={2018},
  
}

@article{goyal1991planar,
  title={Planar sliding with dry friction part 1. limit surface and moment function},
  author={Goyal, S. and Ruina, A. and Papadopoulos, J.},
  journal={Wear},
  volume={143},
  number={2},
  pages={307--330},
  year={1991},
  publisher={Elsevier}
}

@inproceedings{lynch1992manipulation,
  title={Manipulation and active sensing by pushing using tactile feedback.},
  author={Lynch, K. M and Maekawa, H. and Tanie, K.},
  booktitle={IROS},
  volume={1},
  pages={416--421},
  year={1992}
}

@inproceedings{ajay2018augmenting,
  title={Augmenting physical simulators with stochastic neural networks: Case study of planar pushing and bouncing},
  author={Ajay, A. and Wu, J. and Fazeli, N. and Bauza, M. and Kaelbling, L. P and Tenenbaum, J. B and Rodriguez, A.},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3066--3073},
  year={2018},
  
}

@inproceedings{arruda2017uncertainty,
  title={Uncertainty averse pushing with model predictive path integral control},
  author={Arruda, E. and Mathew, M. J and Kopicki, M. and Mistry, M. and Azad, M. and Wyatt, J. L},
  booktitle={2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids)},
  pages={497--502},
  year={2017},
  
}

@inproceedings{hermans2013decoupling,
  title={Decoupling behavior, perception, and control for autonomous learning of affordances},
  author={Hermans, T. and Rehg, J. M and Bobick, A. F},
  booktitle={2013 IEEE International Conference on Robotics and Automation},
  pages={4989--4996},
  year={2013},
  
}

@article{krivic2019pushing,
  title={Pushing corridors for delivering unknown objects with a mobile robot},
  author={Krivic, S. and Piater, J.},
  journal={Autonomous Robots},
  volume={43},
  number={6},
  pages={1435--1452},
  year={2019},
  publisher={Springer}
}

@inproceedings{ebert2017self,
  title={Self-Supervised Visual Planning with Temporal Skip Connections.},
  author={Ebert, F. and Finn, C. and Lee, A. X and Levine, S.},
  booktitle={CoRL},
  pages={344--356},
  year={2017}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, F. and Finn, C and Dasari, S. and Xie, A. and Lee, A. and Levine, S.},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, X. B. and Andrychowicz, M. and Zaremba, W. and Abbeel, P.},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3803--3810},
  year={2018},
  
}


@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, A. V and Pong, V. and Dalal, M. and Bahl, S. and Lin, S. and Levine, S.},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, M. and Fu, J. and Zhang, M. and Levine, S.},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@ARTICLE{lin2020iter,
  author={Lin, Yijiong and Huang, Jiancong and Zimmer, Matthieu and Guan, Yisheng and Rojas, Juan and Weng, Paul},
  journal={IEEE Robotics and Automation Letters}, 
  title={Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning}, 
  year={2020},
  volume={5},
  number={4},
  pages={6615-6622},
  doi={10.1109/LRA.2020.3013937}}
  
  
@article{jia1999pose,
  title={Pose and motion from contact},
  author={Jia, Yan-Bin and Erdmann, Michael},
  journal={The International Journal of Robotics Research},
  volume={18},
  number={5},
  pages={466--487},
  year={1999},
  publisher={SAGE Publications}
}

@article{liu2022goal,
  title={Goal-conditioned reinforcement learning: Problems and solutions},
  author={Liu, M. and Zhu, M. and Zhang, W.},
  journal={arXiv preprint arXiv:2201.08299},
  year={2022}
}

@article{trott2019keeping,
  title={Keeping your distance: Solving sparse reward tasks using self-balancing shaped rewards},
  author={Trott, A. and Zheng, S. and Xiong, C. and Socher, R.},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{stuber2020let,
  title={Let's push things forward: A survey on robot pushing},
  author={St{\"u}ber, J. and Zito, C. and Stolkin, R.},
  journal={Frontiers in Robotics and AI},
  pages={8},
  year={2020},
  publisher={Frontiers}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, L. P.},
  booktitle={IJCAI},
  volume={2},
  pages={1094--8},
  year={1993},
  organization={Citeseer}
}

@article{bauza2020tactile,
  title={Tactile object pose estimation from the first touch with geometric contact rendering},
  author={Bauza, M. and Valls, E. and Lim, B. and Sechopoulos, T. and Rodriguez, A.},
  journal={arXiv preprint arXiv:2012.05205},
  year={2020}
}

@article{lepora2022digitac,
  title={Digitac: A digit-tactip hybrid tactile sensor for comparing low-cost high-resolution robot touch},
  author={Lepora, N. F and Lin, Y. and Money-Coomes, B. and Lloyd, J.},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={9382--9388},
  year={2022},
  publisher={IEEE}
}

@article{calli2015benchmarking,
  title={Benchmarking in manipulation research: The ycb object and model set and benchmarking protocols},
  author={Calli, B. and Walsman, A. and Singh, A. and Srinivasa, S. and Abbeel, P. and Dollar, A. M},
  journal={arXiv preprint arXiv:1502.03143},
  year={2015}
}