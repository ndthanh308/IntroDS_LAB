% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{tikz}
\usepackage{ifthen}
\usepackage{subfigure}
\usepackage{ulem}
\usepackage{xspace}
\usepackage{cite}
\usepackage{lineno}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\newtheorem{algorithm}{Algorithm}
\newtheorem{observation}{Observation}

\definecolor{darkgreen}{rgb}{.25,.5,.25}
\newcommand{\arya}[1]{{\color{darkgreen} #1}}
\newcommand{\snote}[1]{{\color{blue} #1}}

\newcommand{\imped}{impedensable\xspace}
\newcommand{\Imped}{Impedensable\xspace}
\newcommand{\gmrit}{GMRIT\xspace}
\begin{document}
%
\title{Lattice Linearity in Assembling Myopic Robots on an Infinite Triangular Grid}

% % \titlerunning{Abbreviated paper title}
% % If the paper title is too long for the running head, you can set
% % an abbreviated paper title here

\author{Arya Tanmay Gupta \and Sandeep S Kulkarni}

\authorrunning{Gupta and Kulkarni}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.

\institute{Computer Science and Engineering, Michigan State University\\
\email{\{atgupta,sandeep\}@msu.edu}
}

% \linenumbers
\pagestyle{plain}
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
In this paper, we study the problem of gathering distance-1 myopic robots on an infinite triangular grid. We show that the algorithm developed by Goswami et al. (SSS, 2022) is lattice linear. This implies that a distributed scheduler, assumed therein, is not required for this algorithm: it runs correctly in asynchrony. 
% This implies that the algorithm will work correctly even if robots are executing with old information about their neighbours.
It also implies that the algorithm works correctly even if the robots are equipped with a unidirectional \textit{camera} to see the neighbouring robots (rather than an omnidirectional one, which would be required under a distributed scheduler).
%The robots are allowed to execute on old information. 
%In addition, we present tighter bounds on the arena traversed by the robots, and show that the point of gathering can be predetermined based on the initial configuration. 
Due to lattice linearity, we can predetermine the point of gathering.
% based on the initial global state.
% Furthermore, it also allows us to provide a tighter bound on the convergence (from $2.5(n+1)$ rounds to $2n$ rounds).
We also show that this algorithm converges in $2n$ rounds, which is lower than that ($2.5(n+1)$ rounds) shown in Goswami et al.
% This bound is tight, i.e., it is also the lower bound for the convergence time required by this problem.
\keywords{robot gathering\and infinite triangular grid\and lattice linear\and bounding polygon\and convergence time}
\end{abstract}
%
%
%
\section{Introduction}

%Parallel processing systems contain multiple standalone threads running to solve one problem. These processes need to run in coordination with each other in order to reach a state in which the problem is deemed solved. Processes read data from each other in order to be able to collectively solve the problem. To accommodate the coordination among the processes, they have to be synchronized. This is to ensure that they read the latest copy of data while performing an execution.

A parallel processing system contains multiple processes running to solve one problem. 
Each process may store some data. While the system executes, all processes perform executions based on the information that they read from each other. The goal of these processes is to reach a state where the problem is deemed solved. 
To ensure correct execution, synchronization primitives are deployed. Synchronization ensures that the processes read the latest copy of data.
%and ensures that the system does not transition cyclically.

% \snote{
In some of the synchronization models, a selected process acts as a scheduler for the rest of the processes. A \textit{scheduler/daemon} is a process whose function is to choose one, some, or all processes in a time step, throughout the execution, so that the selected processes can evaluate their guards and take the corresponding action. A \textit{central scheduler} chooses only one process per time step. A \textit{distributed scheduler} one or more nodes, possibly arbitrarily, per time step. A \textit{synchronous scheduler} chooses all the processes in each time step.

Enforcing synchronization adds cost to the system. For this reason, the community is interested in developing algorithms that require minimal synchronization. The recent introduction of lattice linearity has shown that algorithms can be developed in such a way that the processes can execute asynchronously. 
% 
% The key ideas of lattice linearity is (1) the requirement that the local states of a process form a total order, and (2) the notion of a \imped process. 
% Regarding the first part, total ordering among local states requires that the execution of a process does not cause it to move to a \textit{lower} state. 
% Regarding the second part, a process is \imped if it can determine that its local state is infeasible with any optimal global state. Hence, it must move \textit{up} in its local state. In turn, the global state space of the program forms a lattice. 
% Together, this ensures that if a process determines that it is \imped using old information about the state of others, it remains \imped in the current state. Hence, even if a process determines that it is \imped while reading old variables of other processes, it is \imped in the current state, i.e., it is necessary and acceptable for it to move \textit{up} in the lattice to find the optimal solution. It follows that processes can now execute without synchronization among them.  
% 
The key idea of lattice linearity is that a process/node determines that its local state is not feasible in any reachable optimal global state. In other words, it has to change its state to reach an optimal state.
%a node being able to determine that its current state is not feasible in any reachable optimal global state. 
%Then it can perform executions even based on old values of other nodes.
% The problems in which nodes can make such decisions are called \textit{lattice linear problems}.
Thus, if node $i$ changes its state from $st.i$ to $st'.i$ it never revisits state $st.i$ again. 
Hence, it can change its state even if it is relying on the old values of its neighbours. 
%In such systems, a node once discards its state, discards it forever. 
%This can form a total order among the local states visited by a node, resulting in the induction of a lattice among the global states. 
Thus, the nodes can run without synchronization and the system is guaranteed to reach an optimal state.

Concepts of lattice linearity can be used to develop new lattice linear algorithms or to study if existing algorithms exploit lattice linearity.
% (shortest path \cite{Garg2020})
%While developing new lattice linear  algorithms is extremely interesting, it is also worthwhile to study if existing algorithms can exploit lattice linearity. 
If existing algorithms can exploit lattice linearity, it would imply that we can eliminate the synchronization assumptions -- thereby saving the time and resources involved in synchronization during their execution. 
% 
%While developing new algorithms for lattice linear and non-lattice linear problems is extremely interesting, it is also worthwhile to study if existing algorithms can exploit lattice linearity.
% 
For example, lattice linearity was found to be exploited by Gale-Shapley's algorithm for stable marriage \cite{Garg2020}, Johnson's algorithm for shortest paths in graphs \cite{Garg2020} and by Galeâ€™s top trading cycle algorithm for housing market \cite{Garg2021}.


In this paper, we study the problem of gathering distance-1 myopic robots on an infinite triangular grid. Authors of \cite{Goswami2022} showed this algorithm to work correctly under a distributed scheduler. We demonstrate that this algorithm is lattice linear.
%In this paper, we study an algorithm by Goswami et al. \cite{Goswami2022} which is developed for the gathering problem of distance-1 myopic robots on an infinite triangular grid. 
% The authors of \cite{Goswami2022} showed that their
Hence, it will run correctly even if the robots run in asynchrony. 

% 
% An interesting observation of this algorithm is that the initial distribution of the robots determines the lattice structure. And, the optimal state (which is unique for the given initial configuration) is the supremum of that lattice. This provides an alternate proof of the stabilization of \cite{Goswami2022}.

% We also observe that this problem allows self-stabilization, unlike some other problems studied in the literature, and this algorithm traverses a self-stabilizing lattice.

\subsection{Contributions of the paper}

\begin{itemize}
    \item We show that the algorithm developed by Goswami et al. \cite{Goswami2022} is lattice linear. Hence, this algorithm will run correctly even if the robots run in asynchrony.
  %  \item We show that the initial distribution of robots identifies the lattice structure and the supremum of this lattice is the optimal state/gathering point. The lattice structure implies that all robots will converge to that gathering point thereby providing an alternate proof of stabilization. 
    %\item We also observe that this problem allows self-stabilization, and this algorithm traverses a self-stabilizing lattice.
    %\item The use of the lattice allows us to provide a tighter bound to the arena covered by the robots executing this algorithm. 
    \item Lattice linearity follows that the moves of the robots are predictable. 
    %This allows us to show that the meeting point of the robots is \textit{optimal}, i.e., under the constraints of the problem, they cannot meet at a \textit{better} point. \snote{Add this where Q is defined.} 
    This allows us to show tighter bounds to the arena traversed by the robots under the algorithm. Consequently, we obtain a better convergence time bound for this algorithm, which is lower than that showed in \cite{Goswami2022}.
    \item We show that the gathering point of the robots can be uniquely determined from the initial global state. 
    % \item The initial distribution of robots identifies the lattice structure. The supremum of this lattice is the optimal state: it depicts the location of the gathering point. In turn, this provides an alternate proof of stabilization. 

    % 
    
    \item We also show that this algorithm converges in $2n$ rounds, which is lower as compared to the time complexity bound ($2.5(n+1)$ rounds) shown in \cite{Goswami2022}.
    % This bound is tight, i.e., it is also the lower bound for the convergence time required by this problem. 

    
    
    %In fact, the upper bound that we show is also the lower bound for the converging time of the robots.
    \item We present a revised version of this algorithm. The revised algorithm has simpler guards and demonstrates lattice linearity more clearly. It converges in the same number of rounds.
    \item Because of lattice linearity, this algorithm the algorithm works correctly even if the robots are equipped with a unidirectional \textit{camera} to see neighbouring robots. In other words, the robots can use old information about the presence of robots at any number of locations in their neighbourhood. Authors of \cite{Goswami2022} assumed a distributed scheduler, which would require an omnidirectional camera, capable to get fresh values from all neighbouring locations.
\end{itemize}

% \arya{reput articles}

\subsection{Organization of the paper}

In \Cref{section:preliminaries}, we describe the notations and definitions that we utilize in this paper. In \Cref{section:gmrit}, we describe the problem of gathering distance-1 myopic robots on an infinite triangular grid. In \Cref{section:algorithm-gsgs}, we describe the lattice linearity of the algorithm in \cite{Goswami2022}; we also show some tighter bounds on the properties of this algorithm. We provide a revised algorithm for this problem in \Cref{section:gsgs-new-algo}.
% We also discuss its properties in this section.
We discuss the related work in \Cref{section:literature} and conclude in \Cref{section:conclusion}.

\section{Preliminaries}\label{section:preliminaries}

A parallel/distributed algorithm consists of nodes where each node is associated with a set of variables. A \textit{global state}, say $s$, is obtained by assigning each variable of each node a value from its respective domain. $s$ is represented as a vector, where $s[i]$ itself is a vector of the variables of node $i$.
$S$ denotes the \textit{state space}, which is the set of all global states that a given system can obtain. 

Each node is associated with actions. Each action at node $i$ checks the values of other nodes and updates its own variables. An \textit{action} is of the form $g\longrightarrow a_c$, where $g$ is the \textit{guard} (a Boolean predicate involving variables of $i$ and other nodes) and $a_c$ is an instruction that updates the variables of $i$
atomically.

A \textit{move} is an event where a node 
%evaluates its guards, and consequently, 
changes its state when one of its guards evaluates to true. A \textit{round} is a sequence of events in which every node evaluates its guards at least once, and makes a move accordingly.

An algorithm $A$ is \textit{self-stabilizing} with respect to the subset $S_o$ of $S$ iff (1) \textit{convergence}: starting from an  arbitrary state, any sequence of computations of $A$ reaches a state in $S_o$, and (2) \textit{closure}: any computation of $A$ starting from $S_o$ always stays in $S_o$. 
We assume $S_o$ to be the set of \textit{optimal} states: the system is deemed converged once it reaches a state in $S_o$. $A$ is a \textit{silent} self-stabilizing algorithm if no node makes a move once a state in $S_o$ is reached.
% An algorithm is \textit{snap-stabilizing} iff starting from an arbitrary state, it makes the system follow a sequence of state transitions as per the specification of that system.

\subsection{Execution without Synchronization}

Typically, we view the \textit{computation} of an algorithm as a sequence of global states $\langle s_0, s_1, \cdots\rangle$, where $s_{t+1}, t\geq 0,$ is obtained by executing some action by one or more nodes in $s_t$.  
For the sake of discussion, assume that only node $i$ executes in state $s_t$. 
The computation prefix uptil $s_{t}$ is $\langle s_0, s_1, \cdots, s_t\rangle$. The state that the system traverses to after $s_t$ is $s_{t+1}$.
Under proper synchronization, $i$ would evaluate its guards on the \textit{current} local states of its neighbours in $s_t$.

To understand the execution in asynchrony, let $x(s)$ be the value of some variable $x$ 
in state $s$. 
If $i$ executes in asynchrony, then it views the global state that it is in to be $s'$, 
where $x(s')\in\{ x(s_0), x(s_1), \cdots, x(s_t) \}.$
In this case, $s_{t+1}$ is evaluated as follows.
If all guards in $i$ evaluate to false, then the system will continue to remain in state $s_t$, i.e., $s_{t+1} = s_{t}$.
If a guard $g$ evaluates to true then $i$ will execute its corresponding action $a_c$.
Here, we have the following observations:
(1) $s_{t+1}[i]$ is the state that $i$ obtains after executing an action in $s'$, and (2) $\forall j\neq i$, $s_{t+1}[j] = s_t[j]$.

The model described above allows nodes to read old values of other nodes arbitrarily. In this paper, however, we require that the nodes (robots) take a \textit{snapshot} of their surroundings after every move. However, doing so does not require synchronization. 

\subsection{Embedding a $<$-lattice among Global States}

Let $s$ denote a global state, and let $s[i]$ denote the state of node $i$ in $s$. First, we define a total order $<_l$; all local states of a node $i$ are totally ordered under $<_l$. 
Using $<_l$, we define a partial order $<_g$ among global states as follows. 

We say that $s <_g s^\prime$ iff $(\forall i: s[i]=s'[i]\lor s[i]<_l s'[i]) \land (\exists i:s[i]<_ls'[i])$.
Also, $s=s'$ iff $\forall i~s[i] = s'[i]$. 
For brevity, we use $<$ to denote $<_l$ and $<_g$: $<$ corresponds to $<_l$ while comparing local states, and $<$ corresponds to $<_g$ while comparing global states. 
We also use the symbol `$>$' which is such that $s>s'$ iff $s' < s$.
Similarly, we use symbols `$\leq$' and `$\geq$'; e.g., $s\leq s'$ iff  $s=s' \vee s < s'$.
We call the lattice, formed from such partial order, a \textit{$<$-lattice}.

\begin{definition}\label{definition:<-lattice}
    \textbf{{\boldmath$<$}-\textit{lattice}}. 
    Given a total relation $<_l$ that orders the states visited by a node $i$ (for each $i$) the $<$-lattice corresponding to $<_l$ is defined by the following partial order:
    $s <_g s'$ iff $(\forall i \ \ s[i] \leq_l s'[i]) \wedge (\exists i \ \ s[i] <_l s'[i])$.
\end{definition}

% A $<$-lattice constraints how global states can transition among one another: state $s$ can transition to state $s'$ iff $s<s'$.
In the $<$-lattice discussed above, we can define the meet and join of two states in the standard way: the meet (respectively, join), of two states $s_1$ and $s_2$ is a state $s_3$ where $\forall i, s_3[i]$ is equal to $min(s_1[i], s_2[i])$ (respectively, $max(s_1[i], s_2[i])$), where $\min(x, y) = \min(y, x)=x$ iff $(x<_l y \lor x=y)$, and 
 $\max(x, y) = \max(y, x)=y$ iff $(y>_l x \lor y=x)$.
 For $s_1$ and $s_2$, their meet (respectively, join) has paths to (respectively, is reachable from) both $s_1$ and $s_2$.

% By varying $<_l$ that identifies a total order among the states of a node, one can obtain different lattices.
A $<$-lattice, embedded in the state space, is useful for permitting the algorithm to execute asynchronously.
Under proper constraints on the structure of $<$-lattice, convergence can be ensured. 

\subsection{Lattice Linear Problems}

A \textit{lattice linear problem} $P$ can be represented by a predicate $\mathcal{P}$ such that if any node $i$ is violating $\mathcal{P}$ in a state $s$, then it must change its state. Otherwise, the system will not satisfy $\mathcal{P}$.
Let $\mathcal{P}(s)$ be true iff state $s$ satisfies $\mathcal{P}$. A node violating $\mathcal{P}$ in $s$ is called an \textit{\imped} node (an \textit{impediment} to progress if does not execute, \textit{indispensable} to execute for progress). Formally,

\begin{definition}\label{definition:impedensable-node}\cite{Garg2020} \textbf{\textit{\Imped node.}} $\textsc{\Imped}(i,s,\mathcal{P})\equiv \lnot \mathcal{P}(s)$ $\land$ $(\forall s'>s:s'[i]=s[i]\implies\lnot \mathcal{P}(s'))$. \end{definition}

If a node $i$ is \imped in state $s$, then in any state $s'$ such that $s'>s$, if the state of $i$ remains the same, then the algorithm will not converge.
Thus, predicate $\mathcal{P}$ induces a total order among the local states visited by a node, for all nodes. Consequently, the discrete structure that gets induced among the global states is a $<$-lattice, as described in \Cref{definition:<-lattice}. 
% Thus $<$-lattice is induced by $\mathcal{P}$ satisfying \Cref{definition:impedensable-node}.
We say that $\mathcal{P}$, satisfying \Cref{definition:impedensable-node}, is \textit{lattice linear} with respect to that $<$-lattice.

There can be multiple arbitrary lattices that can be induced among the global states. A system cannot guarantee convergence while traversing an arbitrary lattice. To guarantee convergence, we design the predicate $\mathcal{P}$ such that it fulfils some properties, and guarantees reachability to an optimal state. $\mathcal{P}$ is used by the nodes to determine if they are \imped, using \Cref{definition:impedensable-node}.
% Thus, $\mathcal{P}$ induces a $<_l$ relation among the local states, and as a result, a $<$-lattice among the global states.
Thus, in any suboptimal global state, there will be at least one \imped node. Formally,

\begin{definition}\cite{Garg2020}\textbf{\textit{Lattice linear predicate.}}
    $\mathcal{P}$ is a lattice linear predicate with respect to a $<$-lattice induced among the global states iff $\forall s\in S: \lnot\mathcal{P}(s) \Rightarrow \exists i:\textsc{\Imped}(i,s,\mathcal{P})$.
\end{definition}

Now we complete the definition of lattice linear problems. In a lattice linear problem $P$, given any suboptimal global state $s$, we can identify all and the only nodes which cannot retain their local states. 
% In this paper, we observe that the algorithms that we study exploit this nature of their respective problems.
$\mathcal{P}$ is thus designed conserving this nature of the subject problem $P$.

\begin{definition}\label{definition:ll-problem}
    \textbf{Lattice linear problems}.
    A problem $P$ is lattice linear 
    iff there exists a predicate $\mathcal{P}$ and a $<$-lattice such that
    
    \begin{itemize}
        \item $P$ is deemed solved iff the system reaches a state where $\mathcal{P}$ is true,
        \item $\mathcal{P}$ is lattice linear with respect to the $<$-lattice induced among the states in $S$, i.e., $\forall s: \neg \mathcal{P}(s) \Rightarrow \exists i:\textsc{\Imped}(i,s,\mathcal{P})$, and
        \item $\forall s:(\forall i:\textsc{\Imped}(i,s,\mathcal{P})\Rightarrow (\forall s':\mathcal{P}(s')\Rightarrow s'[i]\neq s[i]))$.
    \end{itemize}
\end{definition}

\noindent\textbf{\textit{Remark:}} A $<$-lattice, induced under $\mathcal{P}$, allows asynchrony because if a node, reading old values, reads the current state $s$ as $s'$, then $s'<s$. So $\lnot\mathcal{P}(s')\Rightarrow \lnot\mathcal{P}(s)$ because $\textsc{\Imped}(i,s',\mathcal{P})$ and $s'[i]=s[i]$.

% Problems such as stable marriage, job scheduling and market clearing price, as studied in \cite{Garg2020}, are lattice linear problems.

\begin{definition}\label{definition:ssll-problem}
    \textbf{Self-stabilizing lattice linear predicate}.
    Continuing from \Cref{definition:ll-problem},
    $\mathcal{P}$ is a self-stabilizing lattice linear predicate if and only if the supremum of the lattice, that $\mathcal{P}$ induces, is an optimal state, i.e., $\mathcal{P}(supremum(S))=true$.
\end{definition}

\noindent Note that a self-stabilizing lattice linear predicate $\mathcal{P}$ can also be true in states other than the supremum of the $<$-lattice. 

\subsection{Lattice Linear Algorithms}\label{subsection:lla}

Certain problems are \textit{non-lattice linear problems}. In such problems, there are instances in which the \imped nodes cannot be determined naturally, i.e., in those instances
$\exists s :\lnot\mathcal{P}(s) \wedge   (\forall i : \exists s' : \mathcal{P}(s')\land s[i]=s'[i]$).
For such problems, $<$-lattices may be induced algorithmically, through \textit{lattice linear algorithms}.

\begin{definition}\label{definition:ll-algos}\textbf{Lattice linear algorithms (LLA)}.
    Algorithm $A$ is an LLA for a problem $P$, iff there exists a predicate $\mathcal{P}$ and $A$ induces a $<$-lattice among the states of $S_1, ..., S_w \subseteq S (w\geq 1)$, such that
    \begin{itemize}
        \item State space $S$ of $P$ contains mutually disjoint lattices, i.e.
        \begin{itemize}
            \item $S_1, S_2, \cdots, S_w\subseteq S$ are pairwise disjoint.
            \item $S_1 \cup S_2 \cup \cdots \cup S_w$ contains all the reachable states (starting from a set of initial states, if specified; if an arbitrary state can be an initial state, then $S_1 \cup S_2 \cup \cdots \cup S_w=S$).
        \end{itemize}
        \item Lattice linearity is satisfied in each subset under $\mathcal{P}$, i.e., 
        \begin{itemize}
            \item $P$ is deemed solved iff the system reaches a state where $\mathcal{P}$ is true
            \item $\forall k$, $1 \leq k \leq w$, 
            $\mathcal{P}$ is lattice linear with respect to the partial order induced in $S_k$ by $A$, i.e., $\forall s\in S_k: \lnot\mathcal{P}(s) \Rightarrow \exists i \ \
            \textsc{\Imped}(i,s,\mathcal{P})$.
        \end{itemize}
    \end{itemize}
\end{definition}

% \snote{watch for forbidden}

In the next section, we discuss how the gathering problem of distance-1 myopic robots is not a lattice linear problem is a non-lattice linear problem. The lattice linear algorithm developed for this problem imposes the lattice structure among the global states reachable by the system of robots.

\begin{definition}\textbf{Self-stabilizing LLA}.
    From \Cref{definition:ll-algos}, $A$ is self-stabilizing only if $S_1 \cup S_2 \cup \cdots \cup S_w=S$ and $\forall k:1\leq k\leq w$, $\mathcal{P}(supremum(S_k))=true$.
\end{definition}

%In the following section, we discuss that the \gmrit problem requires self-stabilization. The algorithm that we study in this paper is self-stabilizing.

\section{Gathering of Distance-1 Myopic Robots on Infinite Triangular Grid (\gmrit)}\label{section:gmrit}

This paper focuses on the problem where the input is a swarm of robots
% is a collection of a large number of robots
with minimal capabilities. 
Each robot is present at a vertex on an infinite triangular grid. 
In the initial global state, the robots form a connected graph on the underlying grid. The robots agree on an axis (i.e. a direction and its orientation).
The robots can move only across one edge at a time.
%any robot can move to a vertex connected to the vertex by an edge which it is currently present on.
Each robot is myopic, i.e., it can only sense if another robot is present at an adjacent vertex.
Robots do not have an abiliy to \textit{communicate} with each other. 
%and can see only one hop on the grid from the vertex on which it is present. 
Under these constraints, it is required that all robots gather at one point.

\subsection{Problem Statement}
%The problem can be defined as follows. 
The input is a global state $s$ that describes the location of $n$ robots placed on the grid points of an infinite triangular grid $G$ such that the robots form a connected graph. 
The \gmrit problem requires that all robots gather at one vertex of $G$ and stay forever at that vertex subject to the following constraints:

\begin{itemize}
    \item \textit{Visibility:}
    A robot can only determine if another robot is present in a neighbouring location. It cannot exchange data with another robot.
    % \footnote{A robot can only read the location of the robots at distance-1 from itself. \cite{Goswami2022} show that this, along with the one-axis agreement, is the minimum capability that the robots must have in order to converge.}
    \item \textit{One Axis Agreement:}
    All robots agree on one axis and the orientation of that axis. (cf. $y$-axis as shown in \Cref{figure:infinite-triangular-grid}).
    % \footnote{Any vertex in the infinite triangular grid is an intersection of three lines; for all the vertices on the grid, the three lines respectively are parallel to each other. The robots will agree on the orientation and direction of any one of these three types of lines. In this paper, we consider that axis as the $y$-axis. Thus, the robots have a common understanding of up and down the $y$-axis but not of left or right, say, along the $x$-axis.}
\end{itemize}

\newcounter{diags}
\newcounter{rdiag}
\newcounter{vert}
% Figure environment removed

All robots are independent and identical from a physical and computational perspective and do not have an ID.
They are oblivious to the coordinates of their location on the infinite triangular grid $G$.
Observe that we can allow a global state $s$ to be a multiset of vertices, each of which is the location of a robot.
For $s$, its \textit{visibility graph} is the subgraph of $G$ induced by the set of vertices in $s$.

Notice that by definition of the problem statement, a solution to \gmrit will provide silent self-stabilization.
% 
An instance of \gmrit
%An example of robots on an infinite triangular grid 
is shown in \Cref{figure:infinite-triangular-grid}. 
Here, each round highlighted vertex represents a robot. 
Observe that the visibility graph of this global state is a connected graph.
%A robot, $X$ is able to see robots $Y$ and $Z$ and can decide to move to one of the locations marked with $?$.

Next, we discuss how \gmrit problem is not a lattice linear problem. This can be illustrated by a system containing two robots $x_1$ and $x_2$ present at locations $l_1$ and $l_2$ ($l_1$ and $l_2$ are different vertices on the same edge) on $G$. In such a system $x_1$ can move to $l_2$, in which case, $x_2$ is not \imped, or otherwise, $x_2$ can move to $l_1$, in which case, $x_1$ is not \imped. Hence it cannot be determined which robot is \imped.


\subsection{Problem Specific Definitions}\label{subsection:gsgs-definitions}

Some of the definitions that we discuss in this subsection are from \cite{Goswami2022}. 
A \textit{horizontal layer} is a line perpendicular to the $y$-axis that passes through at least one robot.
The \textit{top layer} of a global state $s$ is a horizontal layer such that there is no horizontal layer above it (cf. $AD$ in \Cref{figure:infinite-triangular-grid}).
\textit{Bottom layer} of $s$ is a horizontal layer such that there is no horizontal layer below it (cf. $BC$ in \Cref{figure:infinite-triangular-grid}).

A \textit{vertical layer} is parallel to the $y$-axis such that it passes through at least one robot.
The \textit{left layer} of $s$ is the vertical layer such that there is no vertical layer on its left (cf. $AB$ in \Cref{figure:infinite-triangular-grid}).
The \textit{right layer} of $s$ is the vertical layer such that there is no vertical layer on its right (cf. $CD$ in \Cref{figure:infinite-triangular-grid}).


As seen in \Cref{figure:infinite-triangular-grid}, vertices in $G$ are intersections of three groups of parallel lines; one of these groups are lines parallel to the $y$-axis. We use $p$-axis (positive slope) and $n$ axis (negative slope) to denote the other group of parallel lines.
% \snote{add examples}
% 
% As seen in \ref{?}, edges in $G$ are either along $y$ axis, or along $p$ axis or along $n$ axis.
% A \textit{slanting line} is any line that is parallel to $p$ axis or parallel to $n$ axis. 
% 
% Any line in $G$ that is not parallel to the $y$-axis is a \textit{slanting line}. 
% % A \textit{slanting line} is a line, part of $G$ or imaginary, that goes diagonally or anti-diagonally on $G$.
% Of these, lines \ref{??} are denoted as negative slants (slope of the line is negative) and lines \ref{??} are denoted as positive slants (slope of the line is positive). 
% 
The \textit{positive slant} is a line
parallel to $p$-axis (cf. $BP$ in \Cref{figure:infinite-triangular-grid}) and \textit{negative slant} is a line
parallel to $n$-axis (cf. $CP$ in \Cref{figure:infinite-triangular-grid}).
% 
The \textit{bottom $l2r$ slant} of $s$ is a negative slant that passes through a robot such that there is no negative slant on its left passing through a robot (cf. $B'Q$ in \Cref{figure:infinite-triangular-grid}).
The \textit{bottom $r2l$ slant} of $s$ is a positive slant that passes through a robot such that there is no positive slant on its right passing through a robot (cf. $C'Q$ in \Cref{figure:infinite-triangular-grid}).
Note that a negative slant and a positive slant can be imaginary, or a line in $G$.

% \arya{change terms accordingly}

The \textit{depth} of $s$ is the distance between its top layer and its bottom layer.
The \textit{width} of $s$ is defined as the distance between its left layer and right layer.

As shown in \Cref{figure:infinite-triangular-grid}, a polygon $ABPCD$ is a \textit{bounding polygon} of a global state $s$ if
(1) $AB$ and $CD$ are line segments of the left layer and the right layer of $s$ respectively, (2) $AD$ and $BC$ are line segments of the top layer and the bottom layer of $s$ respectively, and (3) $P$ is the point of intersection between the negative slant passing through $B$ and the positive slant passing through $C$.

% \snote{$l2r$ and r2 in itilics in the paper}

Note that these definitions (top/bottom layer, etc.) are only used for discussion of the protocol and proofs. The robots are not aware of them. Similarly, the robots can distinguish between $up$ and $down$, but not $left$ and $right$.

\subsection{General Idea of the Algorithm}

% In a triangular grid, each robot can see if their is another robot at its neighbouring location.
A robot has six possible neighbours. The naming convention for these locations is as shown in \Cref{figure:local-states} (a) \cite{Goswami2022}. Since each robot has 6 neighbouring locations, it can be in one of $2^6$ possible local states. Of these, the robot can move in only 11 states. Of these 7 states are shown in \Cref{figure:local-states} (b) \cite{Goswami2022}. The other 4 states are mirror images of those shown in cases 2, 5, 6 and 7 in \Cref{figure:local-states} (b).
% \snote{review. some mirror images are identical. Move figure here and change title}

% Figure environment removed

As an illustration, in Case 3, the center robot (marked with dark circle) sees that there are two robots in its vicinity in locations marked with hollow circle. Then, the center robot moves to location marked with an asterisk.
% \snote{add star to figure}

Authors of \cite{Goswami2022} show that the robots do not move out of the bounding polygon. They also show that the visibility graph induced among the robots stay connected, and the dimensions of the bounding polygon reduce with every round. 

\section{GSGS Algorithm \cite{Goswami2022} for \gmrit problem}\label{section:algorithm-gsgs}
%\section{Algorithm for Gathering Distance-1 Myopic Robots on Infinite Triangular Grid}

In this section, we reword the algorithm in \cite{Goswami2022} to demonstrate its lattice linearity. 
We define the following macros. 
% For a node $i$, $Pos_i$ is the set of all its neighbouring locations.
For a set $L$ of locations around a node $i$, $\textsc{At}(i,L)$ is true iff if there is at least one robot at each location in $L$. $\textsc{Only-At}(i,L)$ is true iff $\textsc{At}(i,L)$ and there is no other robot at locations other than locations in $L$.
% A robot is able to see if there is another robot at any of its 6 neighbouring locations shown in \Cref{figure:gcgc-convergence-cases}. 
A robot $i$ is \textit{extreme} if (1) there is no robot on \textit{top} ($v_4.i$) of $i$ and (2) if there is a robot on the left ($v_2^l$ or $v_3^l$) of $i$, then there is no robot on the right ($v_2^r$ or $v_3^r$) of $i$.
%We utilize the following macros. 
If a robot $i$ is extreme, and there is no robot around it, then $i$ is a \textit{terminating} robot.
If $i$ is extreme, and there is a robot only on $v_3(i)$ or there are robots only on both $v_1(i)$ and $v_3(i)$, then $i$ is a \textit{staying} robot.



If $i$ is extreme, and there is a robot on $v_1(i)$ and no robot on $v_3(i)$, then $i$ is a \textit{downward \imped} robot.
% (cf. Case ?? Figure \ref{?}).
If $i$ is not a downward \imped robot, not a staying robot, and not a terminating robot, then it is a \textit{downslant \imped} robot.
% Such a robot has to move to its $v_2(i)$ location.
If $i$ is not an extreme robot, and there is a robot on both $v_2(i)$ and no robot at its y-coordinate $>$ 0, then $i$ is a \textit{non-extreme \imped} robot.
$$
\begin{array}{|l|}
    \hline 
    \textsc{Extreme}(i)\equiv \lnot\textsc{At}(i,\{v_4\})\land\\
    % \quad\quad (\textsc{At}(i,\{v_1\})\lor\\
    \quad\quad ((\textsc{At}(i,\{v_2^r\})\lor \textsc{At}(i,\{v_3^r\}))\Rightarrow(\lnot \textsc{At}(i,\{v_2^\ell\})\land \lnot\textsc{At}(i,\{v_3^\ell\}))) \\
    % \quad\quad ((\textsc{At}(i,\{v_2^\ell\})\lor \textsc{At}(i,\{v_3^\ell\}))\land(\lnot \textsc{At}(i,\{v_2^r\})\land \lnot\textsc{At}(i,\{v_3^r\}))) )\\
    \textsc{Terminating}(r)\equiv \textsc{Extreme}(i)\land (\forall q\in \{v_1,v_2^r,v_3^r,v_4,v_3^\ell,v_2^\ell\}:\lnot\textsc{At}(i,\{q\})).\\
    \textsc{Staying}(i)\equiv \textsc{Extreme}(i)\land (\textsc{Only-At}(i,\{v_3^r\}) \lor \textsc{Only-At}(i,\{v_3^l\}) \lor \\
    \quad\quad \textsc{Only-At}(i,\{v_1,v_3^r\}) \lor \textsc{Only-At}(i,\{v_1,v_3^\ell\})).\\
    \textsc{Downward}(i)\equiv \textsc{Extreme}(i)\land \textsc{At}(i,\{v_1\})\land \lnot(\textsc{At}(i,\{v_3^r\})\lor \textsc{At}(i,\{v_3^\ell\})).\\
    \textsc{Downslant-Right}(i)\equiv \textsc{Extreme}(i)\land \lnot \textsc{Downward}(i)\land \lnot\textsc{Staying}(i) \land\\
    \quad\quad \lnot\textsc{Terminating}(r) \land \textsc{At}(i,\{v_2^r\}).\\
    \textsc{Downslant-Left}(i)\equiv \textsc{Extreme}(i)\land \lnot \textsc{Downward}(i)\land \lnot\textsc{Staying}(i) \land\\
    \quad\quad \lnot\textsc{Terminating}(r) \land \textsc{At}(i,\{v_2^\ell\}).\\
    \textsc{Non-Extreme}(i)\equiv \lnot\textsc{Extreme}(i) \land \textsc{At}(i,\{v_2^r,v_2^\ell\}) \land\\
    \quad\quad \lnot(\textsc{At}(i,\{v_3^r\}) \lor \textsc{At}(i,\{v_3^\ell\}) \lor \textsc{At}(i,\{v_4\})).\\
    \textsc{\Imped-GSGS}(i)\equiv \textsc{Downward}(i)\lor \textsc{Downslant-Right}(i) \lor\\
    \quad\quad \textsc{Downslant-Left}(i) \lor \textsc{Non-Extreme}(i).\\
    \hline 
\end{array}
$$

The algorithm is described as follows.
If a robot $i$ is \textit{downward \imped}, then $i$ moves downwards to $v_1(i)$.
If $i$ is \textit{downslant \imped}, then $i$ moves to $v_2(i)$.
If $i$ is a \textit{non-extreme \imped} robot, then $i$ moves to $v_1(i)$.

% \begin{algorithm}\label{algorithm:gsgs-algo}
%     Rules for robot $r$.
% \end{algorithm}
% \begin{tabular}{|l l|}
%     \hline
%     1 & \textbf{if} r is extreme, then\\
%     2 & \quad \textbf{if} There is no robot on the adjacent grid points then\\
%     3 & \quad\quad terminate;\\
%     4 & \quad \textbf{else if} There is a robot only on $v_3(r)$ or there are robots only on both $v_1(r)$ and $v_3(r)$, then\\
%     5 & \quad\quad do not move;\\
%     6 & \quad \textbf{else if} There is a robot on $v_1(r)$ and no robot on $v_3(r)$, then\\
%     7 & \quad\quad move to $v_1(r)$;\\
%     8 & \quad \textbf{else}\\
%     9 & \quad\quad move to $v_2(r)$;\\
%     10 & \textbf{else}\\
%     11 & \quad \textbf{if} There is a robot on both $v_2(r)$ and no robot on the vertices with y - coordinate $>$ 0, then\\
%     12 & \quad\quad move to v1(r);\\
%     13 & \quad \textbf{else}\\
%     14 & \quad\quad do not move;\\
%     \hline 
% \end{tabular}

\begin{algorithm}\label{algorithm:gsgs-algo}
    Rules for robot $i$.
\end{algorithm}
$$
\begin{array}{|l|}
    \hline 
    \textsc{\Imped-GSGS}(i)\longrightarrow
    \begin{cases}
        move(i,v_1(i)) & \text{if $\textsc{Downward}(i)$}\\
        move(i,v_2^r(i)) & \text{if $\textsc{Downslant-Right}(i)$}\\
        move(i,v_2^\ell(i)) & \text{if $\textsc{Downslant-Left}(i)$}\\
        move(i,v_1(i)) & \text{if $\textsc{Non-Extreme}(i)$}
    \end{cases}~\\
    \hline 
\end{array}
$$

% \snote{text removed}
%A robot has six neighbouring locations, it can be in one of $2^6$ possible local states. Of these, the robot can move only if it is in one of the 14 local states. Of these 7 local states are shown in \Cref{figure:impedensable} and the other 7 local states are their mirror images.
% There are seven cases \cite{Goswami2022} in which a robot can be \imped under \Cref{algorithm:gsgs-algo}, as shown in \Cref{figure:impedensable}.

%Asynchronous executions are assumed to be impractical in \cite{Goswami2022}. 

In \cite{Goswami2022}, authors assume a distributed scheduler. Next, we show that \Cref{algorithm:gsgs-algo} is lattice linear, Thus, it will be correct even in asynchrony. 

%we show that GDOMRIT problem is a lattice linear problem: the predicate, on which \Cref{algorithm:gsgs-algo} is working, is lattice linear. Consequently, \Cref{algorithm:gsgs-algo} can be executed in an asynchronous environment.

% A robot has six possible neighbours (cf \Cref{figure:local-states} (a)). Each robot has 6 neighbouring locations, so it can be in one of $2^6$ local states. A robot is \imped in only 11 states. Of these 7 states are shown in \Cref{figure:local-states} (b). The other 4 states are mirror images of those shown in cases 2, 5, 6 and 7 \Cref{figure:local-states} (b).

\subsection{Lattice Linearity}\label{subsection:gsgs-lattice-linearity}

In this subsection, we show lattice linearity of \Cref{algorithm:gsgs-algo}. Among the lemmas and theorems presented here, \Cref{lemma:lr-layers} and \Cref{lemma:horizontal-layer-moves-down} are adopted from \cite{Goswami2022}. We use them to help prove some properties of \Cref{algorithm:gsgs-algo}. 
%All other lemmas and theorems are novel, and arise from the lattice linearity of \Cref{algorithm:gsgs-algo}.
All other results show or arise from the lattice linearity of \Cref{algorithm:gsgs-algo}. 

% \snote{change the statement of lemma to include gc connectivity}
\begin{lemma}\label{lemma:gmrit-llp}
    The predicate $\forall i:\lnot\textsc{\Imped-GSGS}(i)$ is a lattice linear predicate on $n$ robots, and the visibility graph does not get disconnected by the actions under \Cref{algorithm:gsgs-algo}.
\end{lemma}

\begin{proof}

%A robot is \imped iff it has to change its location to solve GODMRIT.
% \snote{need to fix text below}
% In \Cref{algorithm:gsgs-algo}, there are 4 scenarios for a robot being \imped: Downward(i), Downslant-right(i), Downslant-left(i) and Non-extreme(i). Of these, Downward(i) corresponds to Case 1 and 2 in \ref{figure:gcgc-convergence-cases}, ...
% Hence, in the subsequent discussion, 
In this proof, we consider the 7 cases as shown in \Cref{figure:local-states} (b) and show that if robot $i$ is \imped, it must execute to reach the goal state.
We show that if a robot $i$ is \imped, then there exists at least one robot around $i$ which does not move until $i$ moves. It means that the gathering point is not at the location of $i$.
%located where $i$ is present.
Furthermore, since it is essential for convergence that the visibility graph stays connected, this proof also shows that it stays connected throughout the execution of \Cref{algorithm:gsgs-algo}. 
% The predicate $GCCon => imepd$ will remain false if GCConn remains true and imped remains false. Hence, in each case, we show that action of node $i$ keeps the graph connected
%Furthermore, its action will not cause the graph to be disconnected
% even if its neighbouring robots move in the interim. 


 

    % Any robot is \imped if and only if it has to change its location on the graph.
    % Now from the above predicate, we have that a robot $i$ is \imped only if it is extreme or otherwise, only if there is a robot on both $v_2(i)$ and no robot on the vertices with y - coordinate $>$ 0.
    
    % From \Cref{figure:impedensable}, we have 7 cases, for each subfigure respectively, in which a robot is \imped. Next, we show that if a robot $i$ is \imped, then there exists at least one robot around $i$ which does not move until $i$ moves. It means that the point of convergence is not located where $i$ is present.
    
    \textit{Case 1}: This robot $i$ is a downward \imped robot. The other robot that is present below it is not extreme and is also not a non-extreme \imped robot because $i$ is present above it, so it will not move until $i$ changes its location.

    \textit{Case 2}: This robot $i$ is a downward \imped robot. There are two robots, $x_1$ and $x_2$, present at locations $v_1(i)$ and $v_2(i)$ respectively. $x_1$ is not extreme and is also not non-extreme \imped because $i$ is present above it. So $x_1$ will not move until $i$ changes its location. $x_2$ may be \imped.
    $x_2$ can only move to the location of $x_1$ thereby resulting in case 1.
    In this possibility, the robot $i$ remains \imped and its required action does not change.
    % As discussed in Case 1, robot $i$ must still move to reach the optimal state.
    %based on its surrounding configuration, but its action does not make the graph disconnected.

    \textit{Case 3}: This robot $i$ is a non-extreme \imped robot. There are two robots, $x_1$ and $x_2$, present at locations $v_2(i)$-left and $v_2(i)$-right respectively. For $x_1$ or $x_2$ to be impedensable, there must be some robot at the $v_1(i)$ location, which is not the case, thus, they are not \imped. Hence, $x_1$ and $x_2$ will not move until $i$ changes its location.

    \textit{Case 4}: This robot $i$ is a non-extreme \imped robot. There are three robots, $x_1$, $x_2$ and $x_3$, present at locations $v_2(i)$-left, $v_1(i)$ and $v_2(i)$-right respectively. $x_2$ is not \imped. $x_1$ and $x_3$ may be \imped, based on their local states. If one or both of them move, they will move to the location of $x_2$, resulting in case 2 or case 1.
    In these possibilities, the robot $i$ remains \imped and its required action does not change.

    \textit{Case 5}: This robot $i$ is a downslant \imped robot. There are two robots, $x_1$ and $x_2$, present at locations $v_2(i)$ and $v_3(i)$ respectively. $x_1$ is not extreme and is also not non-extreme \imped. So $x_1$ will not move until $i$ changes its location. $x_2$ may be \imped, based on its local state.
    $x_2$ can move to the location of $x_1$ or $i$ thereby resulting in case 7.
    In this possibility, the robot $i$ remains \imped and its required action does not change.
    % If it moves, the graph is not disconnected.
    
    \textit{Case 6}: This robot $i$ is a downslant \imped robot. There are three robots, $x_1$, $x_2$ and $x_3$, present at locations $v_1(i)$, $v_2(i)$ and $v_3(i)$ respectively. $x_1$ and $x_2$ are not extreme and are also not non-extreme \imped. Initially, $x_1$ and $x_2$ cannot move. $x_3$ may be downward \imped, based on its local state.
    $x_3$ can only move to the location of $x_2$ thereby resulting in case 2. After this, one or both of $x_1$ and $x_2$ can move to the location of $x_1$, resulting in case 1.
    In these possibilities, $i$ remains \imped, its required may change, but the graph does not get disconnected if it executes under case 6.
    % If it moves, the graph is not disconnected.

    \textit{Case 7}: This robot $i$ is a downslant \imped robot. The other robot $x_1$ that is present at $v_2(i)$ is not extreme and is also not a non-extreme \imped robot, so $x_1$ will not move until $i$ changes its location.
    \qed
\end{proof}
% From the proof of \Cref{lemma:gmrit-llp}, it can be observed that the visibility graph induced among the robots remains connected throughout the execution.
% , if it was connected in the initial global state. 

% Authors of \cite{Goswami2022} show that no robot executing \Cref{algorithm:gsgs-algo} steps out of the bounding polygon $ABPCD$.
The robots executing \Cref{algorithm:gsgs-algo}, as shown in \cite{Goswami2022}, stay in the bounding polygon $ABPCD$.
Next, we show, using the above proof, a tighter polygon bounding the robots. To define this polygon, we let $Q$ to be the point such that it is an intersection between the bottom $l2r$ slant of $s$ and the bottom $r2l$ slant of $s$ (cf. \Cref{figure:infinite-triangular-grid}). Let $B'$ be the point of intersection between left layer ($AB$) and the bottom $l2r$ slant of $s$ and let $C'$ be the point of intersection between the right layer ($CD$) and the bottom $r2l$ slant of $s$.
We show that the robots never step out of the polygon $AB'QC'D$, which is tighter than $ABPCD$. 

%An example is shown in \Cref{figure:infinite-triangular-grid}.

% \snote{Think if you want it or not and if is correct. Move to revised algorithm.}
\begin{observation}\label{observation:imped-5-6}
    If the neighbouring robot, say $j$ of an \imped robot $i$ moves then $i$ or $j$ fall under case 5 or case 6.

    %If the neighbouring robot of an \imped robot $i$ would move, it will move only if it falls under case 5 or case 6.
\end{observation}


\begin{lemma}\label{lemma:lower-slants}
    Throughout the execution of \Cref{algorithm:gsgs-algo}, the bottom $r2l$ slant and the bottom $l2r$ slant will not change.
\end{lemma}

\begin{proof}
    In a global state $s$, a 
    % robot present at the left layer or right layer is represented in cases 1, 2, 5, 6 and 7 in \Cref{figure:local-states} (b). A 
    robot present at the bottom $l2r$ slant of $s$ or a bottom $r2l$ slant of $s$ is represented in cases 5 and 7. From \Cref{algorithm:gsgs-algo} and the proof of \Cref{lemma:gmrit-llp}, if a robot is present at bottom $l2r$ slant (respectively, bottom $r2l$ slant), it will never move below ($v_1(i)$) or left ($v_2^\ell(i)$) of its location (respectively, below ($v_1(i)$) or right ($v_2^r(i)$) of its location).
    \qed 
\end{proof}

% \begin{definition}
%     Q-point is defined as the intersection of the bottom $l2r$ slant and the bottom $r2l$ slant.
% \end{definition}

% We have the following lemma from \cite{Goswami2022}.

\begin{lemma}\label{lemma:lr-layers}\cite{Goswami2022}
    Throughout the execution of \Cref{algorithm:gsgs-algo}, left layer does not move leftwards and right layer does not move rightwards.
\end{lemma}

\begin{lemma}\cite{Goswami2022}\label{lemma:horizontal-layer-moves-down}
    In every round of \Cref{algorithm:gsgs-algo}, the top layer moves at least 1/2 unit in the negative direction of the $y$-axis.
\end{lemma}

\begin{corollary}\label{corollary:never-step-out}(From \Cref{lemma:lower-slants} and \Cref{lemma:lr-layers})
    The robots will never step out of the polygon $AB'C'DQ$.
\end{corollary}

\begin{theorem}\label{theorem:gathering-point}
\Cref{algorithm:gsgs-algo} is a lattice linear self-stabilizing algorithm for the \gmrit problem on $n$ robots executing asynchronously.
% Robots will converge at the intersection point of the bottom $l2r$ slant and the bottom $r2l$ slant.

%The point where the robots will gather is point $Q$: the point of intersection of the bottom $l2r$ slant and the bottom $r2l$ slant.
\end{theorem}

\begin{proof}
    From \Cref{lemma:lower-slants}, we have that bottom $l2r$ slant and bottom $r2l$ slant do not change. From \Cref{corollary:never-step-out}, we have that the robots will never step out of the polygon $AB'C'DQ$.
    From \Cref{lemma:horizontal-layer-moves-down}, we have that the top layer moves down by at least half a unit in the negative direction of $y$-axis. Thus we have that the robots converge at the point of intersection of the bottom $l2r$ slant and the bottom $r2l$ slant, and the robots will eventually gather at that point.
    \qed 
\end{proof}

\begin{corollary}\label{corollary:gathering-point}(From \Cref{lemma:horizontal-layer-moves-down}, \Cref{corollary:never-step-out} and \Cref{theorem:gathering-point})
    The point, $Q$, where the robots gather, can be uniquely determined from the initial global state.
\end{corollary}  

% \begin{corollary} (From \Cref{lemma:gmrit-llp}, \Cref{lemma:horizontal-layer-moves-down} and \Cref{theorem:gathering-point})
    
% \end{corollary}
%An example gathering point demonstrating \Cref{theorem:gathering-point} is shown in \Cref{figure:infinite-triangular-grid}.

\subsection{Time Complexity Properties}

In \cite{Goswami2022}, authors showed that \Cref{algorithm:gsgs-algo} converges in $2.5(n+1)$ rounds.
%Due to the predictability that is observable, because of lattice linearity, on the movements of the robots executing \Cref{algorithm:gsgs-algo}, 
% Using the fact that the algorithm is lattice-linear,
Based on \Cref{corollary:gathering-point} which identifies a predictable gathering point, 
we show that a maximum of $2n$ rounds is sufficient, which is a tighter bound. 

% First, we recall the following observation.

% \begin{observation}\label{observation:triangle} \cite{Goswami2022}
%     Let there be a global state of $n$ robots such that
%     % all robots are present along the top layer. Then, 
%     its bounding polygon is an inverted triangle: it only contains a top layer, a bottom $l2r$ slant and a bottom $r2l$ slant. Let its width be $w$. Then this global state converges in $\dfrac{w}{2}\leq \dfrac{n}{2}$ rounds. This is because (1) the depth of the bounding polygon is $\dfrac{w}{4}$, and (2) when a robot travels slanting, it takes two moves to cover one unit respective to the $y$-axis. Another global state, containing a subset of these robots, also converges within $\dfrac{w}{2}$ rounds.
% \end{observation}

\begin{theorem}\label{theorem:time-gsgs}
    \Cref{algorithm:gsgs-algo} converges in $2n$ rounds.
\end{theorem}

\begin{proof}

We use \Cref{figure:infinite-triangular-grid} to discuss convergence of robots in \Cref{algorithm:gsgs-algo}. As discussed in \Cref{subsection:gsgs-definitions} and \Cref{subsection:gsgs-lattice-linearity}, let $A$, $B'$, $Q$, $C'$ and $D$ be the points obtained by pairwise intersection of the top layer, left layer, bottom $l2r$ slant, bottom $r2l$ slant and right layer. 
%Consider the case where robots are arranged as shown in \Cref{figure:infinite-triangular-grid}. 
Let $h_\ell$ be the depth of the line segment $AB'$, $h_r$ be the depth of the line segment $C'D$, and $w$ be the width of the line segment $AD$. Note that a unit of length of the depth of $AB'$ or $C'D$ is $\sqrt{3}$ times a unit of length of the width of $AD$ due to the geometry of $G$.
Since the robots form a connected graph, $w \leq n$. And, if $w > 0$ then $h_\ell+h_r\leq n$. If $w=0$, we define $h_\ell=0$ and $h_r=n$.

In the case where $w=0$, it can be clearly observed that \Cref{algorithm:gsgs-algo} converges in $n$ moves. 
% 
Next, we consider if $w>0$. Without the loss of generality, let $h_r\geq h_\ell$. Thus, $h_\ell\leq n/2$. 
% By definition of bottom $l2r$ slant and bottom $r2l$ slant, point $Q$ cannot be on the right (respectively, left) of the right-layer (respectively, right layer). 

Let $E$ be the point of intersection between the bottom $l2r$ slant and the right layer
% We extend $B'Q$ from $Q$ and $DC'$ from $C'$ and denote their intersection as $E$ 
(cf. \Cref{figure:infinite-triangular-grid}).
We draw a horizontal line (perpendicular to the $y$-axis) through $B'$ and use $J$ to denote its intersection with $DC'$.
%Let $J$ be a point on $DC'$ on a horizontal layer passing through $B'$. 
Thus, the depth of $AB'JD$ is $h_\ell$. 
Additionally, observe that the length of $B'E$ on the $n$-axis is $w$. Thus the height of $JE$ is $w/2$ units on the $y$-axis.
This means that the depth of $B'EJ$ is $w/2$. By construction of $E$, the depth of $B'QC'J$ is upper bounded by the depth of $B'EJ$. Thus, the depth of $B'QC'J$ cannot exceed $w/2\leq n/2$ units.

% Since $depth(AB'JD) \leq n/2$ and $depth(B'QC'J) \leq n/2 $, $depth(AB'QC'DA) \leq n$. 
% Using the fact that the depth of $AB'JD$ is upper bounded by $n/2$ and the fact that the depth of $B'QC'J$ is upper bounded by $n/2$, 
Thus, the total depth of $AB'QC'D$ is equal to the sum of the depth of $AB'JD$ and the depth of $B'QC'J$, which is 
upper bounded by $n/2+n/2=n$ units.
From \Cref{lemma:horizontal-layer-moves-down}, the total number of rounds required for the robots to gather is upper bounded by $2n$ moves.
% Using this, consider Figure \Cref{figure:gcgc-convergence-cases} as follows> Points, $A, B', Q, C'$ and $D$ are same as in \Cref{figure:infinite-triangular-grid}. We draw horizontal line through $B'$ and a vertical line through $Q$. 
% Let $D''$ be their intersection. 
% 
% 
% , as shown in \Cref{figure:gcgc-convergence-cases}. 
% 
% %Hence, e have $w\leq n$.
% %Also, note that one unit on the $y$-axis is equal to $\sqrt{3}$ units on the axis perpendicular to the $y$-axis in terms of distance.
%     From \Cref{observation:triangle}, we have that the depth of polygon $B'QC'D'$ is $\dfrac{2w-(w-h_r)}{4}$. The depth of $AB'QC'D$ in terms of unit of distance on the $y$-axis is $h_\ell+\dfrac{2w-(w-h_r)}{4}=h_\ell+\dfrac{w+h_r}{4}\leq n$. The number of rounds required to converge is upper bounded by twice the depth. Thus, the number of rounds required to gather is upper bounded by $2n$.
%     % For any initial global state, we have that the value of $h+w$ is upper bounded by $n+1$, where the minimum value of both $h$ and $w$ is 1. The depth $\mathcal{H}$ of the polygon $AB'C'DQ$ is $h+\dfrac{w}{4}$. The maximum value of $\mathcal{H}$ is $n+\dfrac{1}{4}$. Due to the discretion of the structure of the underlying grid $G$, the value of $\mathcal{H}$ cannot exceed $n$. The number of rounds required is twice of this value, because a robot can take atmost two moves to move one unit of depth. Thus, a maximum of $2n$ rounds are required for the robots to gather.
    \qed 
\end{proof}

% \arya{remove the last $A$ from $A'B'QC'DA$}

% % Figure environment removed

% \section{Discussion}

% We show an example global states forming a lattice in \Cref{figure:example}. Through this figure, we explain one more scenario that can arise in this algorithm as follows.

% % Figure environment removed

% Notice from \Cref{lemma:gmrit-llp}, and \Cref{algorithm:gsgs-algo} has shown to be correct under a distributed scheduler in \cite{Goswami2022}, that in all the cases, specifically cases 5 and 6, the move of a \imped robot $i$ will be correct if (1) $i$ moves in current state with the new information, (2) $i$ moves in a future time with old information (from this current state), or (3) $i$ moves in a future time with new information. In all three of these scenarios, the action of $i$ remains the same. This induces a total order in the sequence of moves that $i$ makes throughout the execution. Consequently, the global states form a lattice. An example lattice is shown in \Cref{figure:example}.

\section{Revised Algorithm for \gmrit}\label{section:gsgs-new-algo}

In this section, we present a revised algorithm that simplifies the proof of lattice linearity. This algorithm is based on the difficulties involved in the proof of \Cref{lemma:gmrit-llp} where we needed to consider the possible actions taken by the neighbours of the \imped robot. Our proof would have been simpler
% Lattice linearity could have been shown more easily 
if all the neighbours of an \imped robot $i$ could not move until $i$ moves.
Additionally, from \Cref{observation:imped-5-6}, we have that if a robot $j$, neighbouring to an \imped node $i$, is \imped, then $i$ or $j$ fall in case $5$ or case $6$.
% In this section, we present a revised algorithm based on this insight. 

% From the proof of \Cref{lemma:gmrit-llp}, if $i$ was \imped then neighbours of $i$ could move only in cases 5 and 6.
These issues can be alleviated by removing cases 5 and 6 from the algorithm.
The macros that we utilize are as follows. A robot is \textit{downward \imped} if its local state is one of those represented in cases 1, 2, 3 or 4 (and their mirror images; cf \Cref{figure:local-states} (b)). A robot is is \textit{downslant \imped} if its local state is that represented in case 7.
$$
\begin{array}{|l|}
    \hline 
    \textsc{Downward-II}(i)\equiv (\textsc{At}(i,\{v_1\})\land \lnot\textsc{At}(i,\{v_3^\ell, v_4, v_3^r\}))\lor \textsc{Only-At}(i,\{v_2^\ell, v_2^r\}).\\
    \textsc{Downslant-Left-II}(i)\equiv \textsc{Only-At}(i,\{v_2^\ell\}).\\
    \textsc{Downslant-Right-II}(i)\equiv \textsc{Only-At}(i,\{v_2^r\}).\\
    \hline 
\end{array}
$$

The revised algorithm is as follows. A downward impedensable robot moves to $v_1(i)$ location, and a downslant \imped robot moves to $v_2(i)$ location.

\begin{algorithm}\label{algorithm:gsgs-new-algo}
    Rules for robot $i$.
\end{algorithm}
$$
\begin{array}{|l|}
    \hline 
    \textsc{Downward-II}(i)\longrightarrow move(i,v_1(i)).\\
    \textsc{Downslant-Right-II}(i)\longrightarrow move(i,v_2^r(i)).\\
    \textsc{Downslant-Left-II}(i)\longrightarrow move(i,v_2^\ell(i)).\\
    \hline 
\end{array}
$$

In \Cref{algorithm:gsgs-new-algo}, because of the removal of cases 5 and 6, any robot around an \imped robot does not move. Thus lattice linearity of this algorithm can be visualized more intuitively. Consequently, we have the following lemma.

\begin{lemma}
    The predicate $\forall i: \lnot(\textsc{Downward-II}(i)$ $\lor$
        $\textsc{Downslant-Right-II}(i)$ $\lor$
        $\textsc{Downslant-Left-II}(i))$,
    is a lattice linear predicate on $n$ robots, and the visibility graph does not get disconnected by the actions under \Cref{algorithm:gsgs-new-algo}.
\end{lemma}

\Cref{lemma:horizontal-layer-moves-down} shows the top-layer moves down in each round. This proof is not affected by cases 5 and 6, as the robot executing in cases 5 or 6 is \textit{not} a top-layer robot. 
%Cases 1-4 and 7 (and their mirror images) are sufficient cases describing a top layer robot. 
Consequently, \Cref{algorithm:gsgs-new-algo} follows the properties as described in \Cref{lemma:horizontal-layer-moves-down}, \Cref{theorem:gathering-point} and hence \Cref{theorem:time-gsgs}. 
Thus, we have the following theorem.
%Thus, the proof of convergence of \Cref{algorithm:gsgs-new-algo} is based on the fact that the top layer moves down. We have the following theorem (cf \Cref{figure:infinite-triangular-grid}).
% Based on this, we present our revised algorithm, next. 
% 

% As discussed above, by eliminating cases 5 and 6, we obtain a simpler proof to show the lattice linearity of \Cref{algorithm:gsgs-new-algo}. 

%It follows from \Cref{lemma:gmrit-llp} that \Cref{algorithm:gsgs-new-algo} also traverses a lattice of global states. Notice that in this algorithm, cases 5 and 6 do not arise. It also means that when a robot is \imped, then the robots surrounding it are not \imped. All we need to prove is this algorithm will lead to convergence.

\begin{theorem}
    \Cref{algorithm:gsgs-new-algo} is a lattice linear self-stabilizing algorithm for \gmrit problem on $n$ robots executing asynchronously. It converges in $2n$ rounds, and the robots gather at $Q$.
\end{theorem}

% The guards of this algorithm is less complex. In the predicate on which \Cref{algorithm:gsgs-algo} is based, i.e. 
% \begin{center}
%     $\forall i: (\textsc{Downward-\Imped}(i)\lor$\\
%     $\textsc{Downslant-Right-\Imped}(i)\lor$\\
%     $\textsc{Downslant-Left-\Imped}(i))$,    
% \end{center}
% imposes that if a robot $i$ is \imped, then no robot around $i$ moves until $i$ moves. Hence this algorithm emphasizes better on the lattice linearity of the GDOMRIT problem.

\section{Related Work}\label{section:literature}

\textbf{Lattice Linearity}: 
The notion of representing problems through a predicate under which the states form a lattice was introduced in \cite{Garg2020}. We call the problems for which such a representation is possible \textit{lattice linear problems}. Lattice linear problems are also studied in \cite{Garg2021,Garg2022}, where the authors have studied lattice linearity in, respectively, housing market problem and several dynamic programming problems. 
% 
% Many lattice linear problems do not allow self-stabilization \cite{Garg2020,Garg2021,Garg2022}. For a system of lattices to allow synchronization, the supermum of all the lattices induced must be an optimal state. This ensures that starting from any state, the system can traverse to an optimal state. Note that other states can be optimal states as well. 
% 
Gupta and Kulkarni introduced eventually lattice linear algorithms \cite{Gupta2021} and fully lattice linear algorithms \cite{Gupta2022} for non-lattice linear problems.

\noindent\textbf{Robot gathering problem on discrete grids}:
In a general case, it is impossible to gather a system of robots if their visibility graph is not a connected graph. One-axis agreement and distance-1 myopia are the minimal capabilities that robots need to converge on a triangular grid \cite{Goswami2022}.
% They also showed that a system of robots on a triangular grid will take at least $\Omega (n)$ rounds to converge.

A system of robots with minimal capabilities has been studied with several output requirements, including gathering \cite{Goswami2022,DAngelo2016,Flocchini2005}, dispersion \cite{Augustine2018}, arbitrary pattern formation \cite{Bose2020}. Gathering of robots has been studied more recently in \cite{Bhagat2015,Klasing2010}. We focus on systems of robots on grids, mainly the papers that study gathering.

Robots placed on an infinite rectangular grid were studied in \cite{Poudel2021}, where the authors presented two algorithms for gathering. A synchronous scheduler is assumed and the robots require, respectively, distance-2 and distance-3 visibility.
Moreover, under the latter algorithm, robots may not gather at one point but will gather a horizontal line segment of unit length.

Robots placed on an infinite triangular grid were studied in \cite{Cicerone2021}, where the authors provided an algorithm to form any arbitrary pattern.
They require full visibility.
% Their algorithm can be used to gather robots as well.
Their algorithm works only when the the initial global state is asymmetric.
Authors of \cite{Shibata2021} have studied gathering problem of 7 robots -- initially, 6 of them form a hexagon and one robot is present at the centre of that hexagon. They require the initial state to form a connected visibility graph; the system finally reaches a global state where the maximum distance between two robots is minimized. A synchronous scheduler is assumed.
In \cite{DAngelo2016}, authors  characterized the problem of gathering on a tree and finite grid.

This paper studies the algorithm developed by Goswami et al. \cite{Goswami2022}. As discussed above, this algorithm requires only minimal capabilities in robots.

\section{Conclusion}\label{section:conclusion}

In this paper, we show lattice linearity of the algorithm developed by Goswami et al \cite{Goswami2022} for gathering robots on an infinite triangular grid. This removes the assumptions of synchronization from the algorithm and thus makes a system running this algorithm fully tolerant to asynchrony. We also present a revised algorithm that simplifies the proof of lattice linearity without losing any of the desired properties (e.g., convergence time, stabilization).

%revise this algorithm and present an algorithm that is more intuitive to visualize as a lattice linear algorithm, as in the revised algorithm, all robots around an \imped robot do not move until it moves.

Lattice linearity implies that the locations, possibly visited by a robot, form a total order. The total order is a result of the fact that we are able to determine all and the only robots in any global state that are \imped, and an \imped robot has only one choice of action. By making this observation, it can also be noticed that we can closely predict the executions that the robots would perform. As a result, we are able to (1) compute the exact arena traversed by the robots throughout the execution of the algorithm (\Cref{lemma:lower-slants} and \Cref{lemma:lr-layers}), and (2) deterministically predict the point of gathering of the robots (\Cref{corollary:gathering-point}).

We also provided a better upper bound on the time complexity of this algorithm. Specifically, we show that it converges in $2n$ rounds, whereas \cite{Goswami2022} showed that a maximum of $2.5(n+1)$ rounds are required.
This was possible due to the observations that followed from the proof of lattice linearity of this algorithm. 

%This is possible because, as discussed in the above paragraph, we are better able to predict the movement of the robots throughout the execution of the algorithm. We are able to tightly visualize a global state and the geometry of its boundaries. We also discuss how, in a general case, this algorithm requires a minimum of $2n$ rounds, which makes this observation tight.

Being able to design systems that fully tolerate asynchrony has been a desired, albeit unattainable, objective. Lattice linear systems provide with a deterministic, discrete, guarantee to attain such fault tolerance. Studying whether existing algorithms exploit lattice linearity is extremely interesting and beneficial. Specifically, it allows us to eliminate costly, sophisticated, assumptions of synchronization from existing systems, instead of redesigning them from scratch.

% We also corrected some definitions from \cite{Goswami2022}. For example, a robot $i$ is said to be extreme in \cite{Goswami2022} only if there is no robot on the positive $y$-axis of $i$, which is ambiguous as we have to allow robots at $v_3(i)$ according to the definition of the algorithm. In addition, $BP$ and $DP$ in \cite{Goswami2022} are required to be the line segments on one of the lines of the grid $G$, whereas, as we can see in \Cref{figure:infinite-triangular-grid}, we have to allow these line segments to be arbitrary and parallel to $n$-axis and $p$-axis respectively.

% Similarly, the robots can be gathered at right, left, or above. Corresponding changes have to be made in \Cref{algorithm:gsgs-new-algo}.

\bibliography{gsgs.bib}
\bibliographystyle{acm}
% \textbf{location -- position: use one of these words}\\
% \textbf{neighbour, colour, behaviour}\\
% \textbf{configuration}\\
% \textbf{more citation}

\renewcommand{\thesubsection}{\Alph{subsection}}

% \section*{Appendix}

% \begin{theorem}\label{theorem:time-gsgs-2}
%     \Cref{algorithm:gsgs-algo} converges in $n$ rounds.
% \end{theorem}

% \begin{proof}
%     Let $h_r$ be the length of the line segment $AB'$, $h_\ell$ be the length of the line segment $C'D$, and $w$ be the width of the line segment $AD$. Without loss of generality, let $h_r\geq h_\ell$. We have $w\leq n-h_r-h_\ell$. Also note that one unit on the $y$-axis is equivalent to $\sqrt{3}$ units on the axis perpendicular to the $y$-axis in terms of distance. 
%     There are two cases, which are as follows. These cases are presented in \Cref{figure:gcgc-convergence-cases}.

%     \textit{Case 1}: $h_r\geq w/2+h_\ell$. In this case, the robots converge on the line segment $C'D$, as shown in \Cref{figure:gcgc-convergence-cases} (case 1). The robots in the polygon $AB'C'D$ will not step out of this polygon. Then the robots will move down along the line $C'Q$.
%     Uptil $C'$, the robots will move 1 unit of the $y$-axis in almost 2 rounds. Then, 1 unit will be moved in 1 round.
%     The robots in $AB'D'D$ will take $2h_\ell$ rounds to move to $B'D'$. Then, the robots will gather at $C'$ in $w$ additional rounds (\Cref{observation:triangle}). The robots on $C'Q$ will gather at $Q$ $h_r-h_\ell-w/2$ rounds.
%     Thus, the number of rounds is upper bounded by $(2h_\ell)+(w)+(h_r-h_\ell-w/2)=h_r+w/2+h_\ell\leq n$.

%     \textit{Case 2}: $h_r< w/2+h_\ell$. In this case, the robots converge on the point $Q$, which is the intersection point of the bottom $l2r$ slant and the bottom $r2l$ slant, as shown in \Cref{figure:gcgc-convergence-cases} (case 2). The robots in the polygon $AB'QC'D$ will not step out of this polygon.
%     The robots in $AB'D'D$ will take $2h_\ell$ rounds to move to $B'D'$. Then, the robots will only take $w$ more rounds to gather at $Q$ (\Cref{observation:triangle}).
%     Thus, the number of rounds is upper bounded by $(2h_\ell)+(w)\leq 2h_\ell+n-h_r-h_\ell\leq n$.
%     \qed 
% \end{proof}

% % Figure environment removed

% % Figure environment removed

% Assume a global state in which all the $n$ robots are place over each other in a straight line -- parallel to the $y$-axis. This is case 1 as presented in \Cref{figure:gcgc-convergence-cases}, where $h_\ell$ and $w$ are zero. Such a global state will take a minimum of $n$ rounds to converge.
% Thus the bounds provided by \Cref{theorem:gathering-point} is also a lower bound that this algorithm would take in a general case.
% Similarly, \Cref{observation:triangle} describes a global state, which case 2 as presented in \Cref{figure:gcgc-convergence-cases}, where $h_l=0$ and $h_r=0$.

% \textbf{line numbers}

\end{document}
