% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{zhang2019image}
H.~Zhang, V.~Sindagi, and V.~M. Patel, ``Image de-raining using a conditional
  generative adversarial network,'' \emph{IEEE transactions on circuits and
  systems for video technology (TCSVT)}, vol.~30, no.~11, pp. 3943--3956, 2019.

\bibitem{tan2020incremental}
D.~S. Tan, Y.-X. Lin, and K.-L. Hua, ``Incremental learning of multi-domain
  image-to-image translations,'' \emph{IEEE Transactions on Circuits and
  Systems for Video Technology (TCSVT)}, vol.~31, no.~4, pp. 1526--1539, 2020.

\bibitem{gao2021wallpaper}
Y.~Gao, X.~Feng, T.~Zhang, E.~Rigall, H.~Zhou, L.~Qi, and J.~Dong, ``Wallpaper
  texture generation and style transfer based on multi-label semantics,''
  \emph{IEEE Transactions on Circuits and Systems for Video Technology
  (TCSVT)}, vol.~32, no.~3, pp. 1552--1563, 2021.

\bibitem{fu2021let}
L.~Fu, H.~Yu, F.~Juefei-Xu, J.~Li, Q.~Guo, and S.~Wang, ``Let there be light:
  Improved traffic surveillance via detail preserving night-to-day transfer,''
  \emph{IEEE Transactions on Circuits and Systems for Video Technology
  (TCSVT)}, 2021.

\bibitem{gatys2016image}
L.~A. Gatys, A.~S. Ecker, and M.~Bethge, ``Image style transfer using
  convolutional neural networks,'' in \emph{Proceedings of the IEEE Conference
  on Computer Vision and Pattern Recognition (CVPR)}, 2016, pp. 2414--2423.

\bibitem{johnson2016perceptual}
J.~Johnson, A.~Alahi, and L.~Fei-Fei, ``Perceptual losses for real-time style
  transfer and super-resolution,'' in \emph{Proceedings of the European
  Conference on Computer Vision (ECCV)}, 2016, pp. 694--711.

\bibitem{kolkin2019style}
N.~Kolkin, J.~Salavon, and G.~Shakhnarovich, ``Style transfer by relaxed
  optimal transport and self-similarity,'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, 2019, pp.
  10\,051--10\,060.

\bibitem{risser2017stable}
E.~Risser, P.~Wilmot, and C.~Barnes, ``Stable and controllable neural texture
  synthesis and style transfer using histogram losses,'' \emph{arXiv preprint
  arXiv:1701.08893}, 2017.

\bibitem{chen2016fast}
T.~Q. Chen and M.~Schmidt, ``Fast patch-based style transfer of arbitrary
  style,'' \emph{arXiv preprint arXiv:1612.04337}, 2016.

\bibitem{chen2017stylebank}
D.~Chen, L.~Yuan, J.~Liao, N.~Yu, and G.~Hua, ``Stylebank: An explicit
  representation for neural image style transfer,'' in \emph{Proceedings of the
  IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2017, pp.
  1897--1906.

\bibitem{li2017universal}
Y.~Li, C.~Fang, J.~Yang, Z.~Wang, X.~Lu, and M.-H. Yang, ``Universal style
  transfer via feature transforms,'' in \emph{Advances in Neural Information
  Processing Systems (NeurIPS)}, 2017, pp. 385--395.

\bibitem{li2019learning}
X.~Li, S.~Liu, J.~Kautz, and M.-H. Yang, ``Learning linear transformations for
  fast image and video style transfer,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2019, pp. 3809--3817.

\bibitem{sheng2018avatar}
L.~Sheng, Z.~Lin, J.~Shao, and X.~Wang, ``Avatar-net: Multi-scale zero-shot
  style transfer by feature decoration,'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, 2018, pp.
  8242--8250.

\bibitem{park2019arbitrary}
D.~Y. Park and K.~H. Lee, ``Arbitrary style transfer with style-attentional
  networks,'' in \emph{Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 2019, pp. 5880--5888.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{huang2017adain}
X.~Huang and S.~Belongie, ``Arbitrary style transfer in real-time with adaptive
  instance normalization,'' in \emph{Proceedings of the IEEE International
  Conference on Computer Vision (ICCV)}, 2017, pp. 1501--1510.

\bibitem{liu2021adaattn}
S.~Liu, T.~Lin, D.~He, F.~Li, M.~Wang, X.~Li, Z.~Sun, Q.~Li, and E.~Ding,
  ``Adaattn: Revisit attention mechanism in arbitrary neural style transfer,''
  in \emph{Proceedings of the IEEE International Conference on Computer Vision
  (ICCV)}, 2021, pp. 6649--6658.

\bibitem{wu2021styleformer}
X.~Wu, Z.~Hu, L.~Sheng, and D.~Xu, ``Styleformer: Real-time arbitrary style
  transfer via parametric style composition,'' in \emph{Proceedings of the IEEE
  International Conference on Computer Vision (ICCV)}, 2021, pp.
  14\,618--14\,627.

\bibitem{cernekova2005information}
Z.~Cernekova, I.~Pitas, and C.~Nikou, ``Information theory-based shot cut/fade
  detection and video summarization,'' \emph{IEEE Transactions on circuits and
  systems for video technology (TCSVT)}, vol.~16, no.~1, pp. 82--91, 2005.

\bibitem{shwartz2017opening}
R.~Shwartz-Ziv and N.~Tishby, ``Opening the black box of deep neural networks
  via information,'' \emph{arXiv preprint arXiv:1703.00810}, 2017.

\bibitem{achille2018emergence}
A.~Achille and S.~Soatto, ``Emergence of invariance and disentanglement in deep
  representations,'' \emph{Journal of Machine Learning Research}, vol.~19,
  no.~1, pp. 1947--1980, 2018.

\bibitem{winnemoller2006real}
H.~Winnem{\"o}ller, S.~C. Olsen, and B.~Gooch, ``Real-time video abstraction,''
  \emph{ACM Transactions on Graphics (TOG)}, vol.~25, no.~3, pp. 1221--1226,
  2006.

\bibitem{hertzmann2001image}
A.~Hertzmann, C.~E. Jacobs, N.~Oliver, B.~Curless, and D.~H. Salesin, ``Image
  analogies,'' in \emph{Proceedings of the ACM International Conference on
  Computer Graphics and Interactive Techniques}, 2001, pp. 327--340.

\bibitem{frigo2016split}
O.~Frigo, N.~Sabater, J.~Delon, and P.~Hellier, ``Split and match:
  Example-based adaptive patch sampling for unsupervised style transfer,'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2016, pp. 553--561.

\bibitem{song2017learning}
Y.~Song, J.~Zhang, S.~He, L.~Bao, and Q.~Yang, ``Learning to hallucinate face
  images via component generation and enhancement,'' in \emph{International
  Joint Conferences on Artificial Intelligence (IJCAI)}, 2017.

\bibitem{song2019joint}
Y.~Song, J.~Zhang, L.~Gong, S.~He, L.~Bao, J.~Pan, Q.~Yang, and M.-H. Yang,
  ``Joint face hallucination and deblurring via structure generation and detail
  enhancement,'' \emph{International Journal of Computer Vision (IJCV)}, vol.
  127, no.~6, pp. 785--800, 2019.

\bibitem{hertzmann1998painterly}
A.~Hertzmann, ``Painterly rendering with curved brush strokes of multiple
  sizes,'' in \emph{Proceedings of the ACM International Conference on Computer
  Graphics and Interactive Techniques}, 1998, pp. 453--460.

\bibitem{gatys2015texture}
L.~Gatys, A.~S. Ecker, and M.~Bethge, ``Texture synthesis using convolutional
  neural networks,'' in \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, vol.~28, 2015.

\bibitem{ruder2016artistic}
M.~Ruder, A.~Dosovitskiy, and T.~Brox, ``Artistic style transfer for videos,''
  in \emph{German conference on pattern recognition}.\hskip 1em plus 0.5em
  minus 0.4em\relax Springer, 2016, pp. 26--36.

\bibitem{champandard2016semantic}
A.~J. Champandard, ``Semantic style transfer and turning two-bit doodles into
  fine artworks,'' \emph{arXiv preprint arXiv:1603.01768}, 2016.

\bibitem{li2017demystifying}
Y.~Li, N.~Wang, J.~Liu, and X.~Hou, ``Demystifying neural style transfer,'' in
  \emph{International Joint Conferences on Artificial Intelligence (IJCAI)},
  2017.

\bibitem{gatys2017controlling}
L.~A. Gatys, A.~S. Ecker, M.~Bethge, A.~Hertzmann, and E.~Shechtman,
  ``Controlling perceptual factors in neural style transfer,'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2017, pp. 3985--3993.

\bibitem{du2020much}
L.~Du, ``How much deep learning does neural style transfer really need? an
  ablation study,'' in \emph{IEEE Winter Conference on Applications of Computer
  Vision}, 2020, pp. 3150--3159.

\bibitem{deng2021arbitrary}
Y.~Deng, F.~Tang, W.~Dong, H.~Huang, C.~Ma, and C.~Xu, ``Arbitrary video style
  transfer via multi-channel correlation,'' in \emph{Proceedings of the AAAI
  Conference on Artificial Intelligence (AAAI)}, vol.~35, no.~2, 2021, pp.
  1210--1217.

\bibitem{lin2021drafting}
T.~Lin, Z.~Ma, F.~Li, D.~He, X.~Li, E.~Ding, N.~Wang, J.~Li, and X.~Gao,
  ``Drafting and revision: Laplacian pyramid network for fast high-quality
  artistic style transfer,'' in \emph{Proceedings of the IEEE Conference on
  Computer Vision and Pattern Recognition (CVPR)}, 2021, pp. 5141--5150.

\bibitem{deng2022stytr2}
Y.~Deng, F.~Tang, W.~Dong, C.~Ma, X.~Pan, L.~Wang, and C.~Xu, ``Stytr2: Image
  style transfer with transformers,'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022, pp.
  11\,326--11\,336.

\bibitem{huang2018multimodal}
X.~Huang, M.-Y. Liu, S.~Belongie, and J.~Kautz, ``Multimodal unsupervised
  image-to-image translation,'' in \emph{Proceedings of the European Conference
  on Computer Vision (ECCV)}, 2018, pp. 172--189.

\bibitem{lee2018diverse}
H.-Y. Lee, H.-Y. Tseng, J.-B. Huang, M.~Singh, and M.-H. Yang, ``Diverse
  image-to-image translation via disentangled representations,'' in
  \emph{Proceedings of the European Conference on Computer Vision (ECCV)},
  2018, pp. 35--51.

\bibitem{lee2020drit++}
H.-Y. Lee, H.-Y. Tseng, Q.~Mao, J.-B. Huang, Y.-D. Lu, M.~Singh, and M.-H.
  Yang, ``Drit++: Diverse image-to-image translation via disentangled
  representations,'' \emph{International Journal of Computer Vision (IJCV)},
  vol. 128, pp. 2402--2417, 2020.

\bibitem{kotovenko2019content}
D.~Kotovenko, A.~Sanakoyeu, S.~Lang, and B.~Ommer, ``Content and style
  disentanglement for artistic style transfer,'' in \emph{Proceedings of the
  IEEE International Conference on Computer Vision (ICCV)}, 2019, pp.
  4422--4431.

\bibitem{deng2020arbitrary}
Y.~Deng, F.~Tang, W.~Dong, W.~Sun, F.~Huang, and C.~Xu, ``Arbitrary style
  transfer via multi-adaptation network,'' in \emph{Proceedings of the ACM
  International Conference on Multimedia (ACM MM)}, 2020, pp. 2719--2727.

\bibitem{tishby2015deep}
N.~Tishby and N.~Zaslavsky, ``Deep learning and the information bottleneck
  principle,'' in \emph{IEEE Information Theory Workshop}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2015, pp. 1--5.

\bibitem{schulz2019restricting}
K.~Schulz, L.~Sixt, F.~Tombari, and T.~Landgraf, ``Restricting the flow:
  Information bottlenecks for attribution,'' in \emph{International Conference
  on Learning Representations (ICLR)}, 2019.

\bibitem{rame2020dice}
A.~Rame and M.~Cord, ``Dice: Diversity in deep ensembles via conditional
  redundancy adversarial estimation,'' in \emph{International Conference on
  Learning Representations (ICLR)}, 2020.

\bibitem{lee2021reducing}
J.~Lee, J.~Choi, J.~Mok, and S.~Yoon, ``Reducing information bottleneck for
  weakly supervised semantic segmentation,'' \emph{Advances in Neural
  Information Processing Systems (NeurIPS)}, vol.~34, 2021.

\bibitem{jeon2021ib}
I.~Jeon, W.~Lee, M.~Pyeon, and G.~Kim, ``Ib-gan: Disengangled representation
  learning with information bottleneck generative adversarial networks,'' in
  \emph{Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  vol.~35, no.~9, 2021, pp. 7926--7934.

\bibitem{gao2021information}
G.~Gao, H.~Huang, C.~Fu, Z.~Li, and R.~He, ``Information bottleneck
  disentanglement for identity swapping,'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021, pp.
  3404--3413.

\bibitem{sun2022information}
H.~Sun, N.~Pears, and Y.~Gu, ``Information bottlenecked variational autoencoder
  for disentangled 3d facial expression modelling,'' in \emph{IEEE Winter
  Conference on Applications of Computer Vision}, 2022, pp. 157--166.

\bibitem{tishby2000information}
N.~Tishby, F.~C. Pereira, and W.~Bialek, ``The information bottleneck method,''
  in \emph{The 37th annual Allerton Conference on Communication, Control, and
  Computing}, 1999, pp. 368--377.

\bibitem{alemi2016deep}
A.~A. Alemi, I.~Fischer, J.~V. Dillon, and K.~Murphy, ``Deep variational
  information bottleneck,'' in \emph{International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem{peng2018variational}
X.~B. Peng, A.~Kanazawa, S.~Toyer, P.~Abbeel, and S.~Levine, ``Variational
  discriminator bottleneck: Improving imitation learning, inverse rl, and gans
  by constraining information flow,'' in \emph{International Conference on
  Learning Representations (ICLR)}, 2019.

\bibitem{fisher1922mathematical}
R.~A. Fisher, ``On the mathematical foundations of theoretical statistics,''
  \emph{Philosophical transactions of the Royal Society of London. Series A,
  containing papers of a mathematical or physical character}, vol. 222, no.
  594-604, pp. 309--368, 1922.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' in
  \emph{International Conference on Learning Representations (ICLR)}, 2014.

\bibitem{zhu2017unpaired}
J.-Y. Zhu, T.~Park, P.~Isola, and A.~A. Efros, ``Unpaired image-to-image
  translation using cycle-consistent adversarial networks,'' in
  \emph{Proceedings of the IEEE International Conference on Computer Vision
  (ICCV)}, 2017, pp. 2223--2232.

\bibitem{doersch2016tutorial}
C.~Doersch, ``Tutorial on variational autoencoders,'' \emph{arXiv preprint
  arXiv:1606.05908}, 2016.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in
  context,'' in \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, 2014, pp. 740--755.

\bibitem{karayev2013recognizing}
S.~Karayev, M.~Trentacoste, H.~Han, A.~Agarwala, T.~Darrell, A.~Hertzmann, and
  H.~Winnemoeller, ``Recognizing image style,'' in \emph{Proceedings of the
  British Machine Vision Conference (BMVC)}, 2014.

\bibitem{kingma2015adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' in
  \emph{International Conference on Learning Representations (ICLR)}, 2015.

\bibitem{wang2004image}
Z.~Wang, A.~C. Bovik, H.~R. Sheikh, and E.~P. Simoncelli, ``Image quality
  assessment: from error visibility to structural similarity,'' \emph{IEEE
  Transactions on Image Processing (TIP)}, vol.~13, no.~4, pp. 600--612, 2004.

\end{thebibliography}
