{
  "title": "Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering",
  "authors": [
    "Ce Feng",
    "Nuo Xu",
    "Wujie Wen",
    "Parv Venkitasubramaniam",
    "Caiwen Ding"
  ],
  "submission_date": "2023-07-25T03:45:56+00:00",
  "revised_dates": [],
  "abstract": "Differential privacy is a widely accepted measure of privacy in the context of deep learning algorithms, and achieving it relies on a noisy training approach known as differentially private stochastic gradient descent (DP-SGD). DP-SGD requires direct noise addition to every gradient in a dense neural network, the privacy is achieved at a significant utility cost. In this work, we present Spectral-DP, a new differentially private learning approach which combines gradient perturbation in the spectral domain with spectral filtering to achieve a desired privacy guarantee with a lower noise scale and thus better utility. We develop differentially private deep learning methods based on Spectral-DP for architectures that contain both convolution and fully connected layers. In particular, for fully connected layers, we combine a block-circulant based spatial restructuring with Spectral-DP to achieve better utility. Through comprehensive experiments, we study and provide guidelines to implement Spectral-DP deep learning on benchmark datasets. In comparison with state-of-the-art DP-SGD based approaches, Spectral-DP is shown to have uniformly better utility performance in both training from scratch and transfer learning settings.",
  "categories": [
    "cs.LG",
    "cs.CR",
    "cs.CY"
  ],
  "primary_category": "cs.LG",
  "doi": "10.1109/SP46215.2023.00171",
  "journal_ref": null,
  "arxiv_id": "2307.13231",
  "pdf_url": null,
  "comment": "Accepted in 2023 IEEE Symposium on Security and Privacy (SP)",
  "num_versions": null,
  "size_before_bytes": 10438356,
  "size_after_bytes": 546599
}