\section{Related Work}
\label{sec:related_work}
We discuss related research to our proposed attacks. Such research either exploited iGPUs, memory controller resources, or write requests. 
%We also go through different defenses relevant to our attack.

\noindent\textbf{Attacks Targeting Memory Controller's and DRAM Resources.}
%Several works targeted MC buffers and DRAM resources to leak secret information. 
DRAMA~\cite{drama_usenix} targeted row buffer conflicts and exploit it for covert and side channel attacks. Their approach required attack parties to agree on a set of channel, rank, and bank. Similar to DRAMA, Xiao et al.~\cite{xiao_ohio} reversed engineering bank bit addressing, but their attack is for double-sided row hammer in virtualized environments.
Wang et al.~\cite{cornell_defense_hpca} demonstrated the possibility of contention-based covert and side channel attacks to motivate their defense scheme. Their side channel attack targeted RSA decryption algorithm by causing a cache miss when a modulo operation is executed. Their work neither developed end-to-end attacks nor reverse-engineered the source of contention. Unlike these attacks, our attack mainly exploits the management policy of the write buffer in MC.

\noindent\textbf{iGPU as an Attack Vector.} Some existing work exploited integrated accelerators to infer secret data. They are also used to speed up the process of known attacks such as finding eviction sets or DRAM bit flipping. Leaky Buddies~\cite{leaky_buddies} used iGPU in their covert channel attacks which targeted LLC and Ring Interconnect. %The attack targeted LLC is prime+probe while contention based attack targeted Ring Interconnect. 
Our attack does not target LLC or ring-interconnect. Grand Pawning Unit~\cite{Glitch-2018} used integrated accelerators (GPUs) for accelerating bit flipping used in attacks such as rowhammer and breaking ASLR. 

\noindent\textbf{Attacks Targeting Cache/Memory Writes.} Most of the existing side and covert channel attacks targeted cache/memory reads rather than writes (temporal writes). CPU processes can not time cache/memory writes beyond updating associated cache lines; therefore they can not reveal much of information about the program's behavior, especially at the MC level. Also, approaches such as write-no-allocate and write-back caches can exacerbate this case. Thoma et al.~\cite{raid_cpu_write} proposed Write-After-Write side channel attack where they noticed that writing to an address in cache can make subsequent writes slower to addresses colliding with the previously written address.


% In this section, we briefly overview the related research work on attacks and defenses. 

% \subsection{Attacks}
% To the best of our knowledge, this is the first practical attack to target contention on the memory controller in a heterogeneous SoC.

% \noindent \textbf{Contention attacks on memory:} Wang et al. \cite{cornell_defense_hpca} demonstrated a possible attack to leak AES using contention on the memory controller. However, the work does not provide any  details on contention creation on the memory controller. Pessl et al. \cite{drama_usenix} targeted contention on resources such as row buffer within DRAM banks to build covert and side channels. Their attacks do not target contention on memory controller resources.

% \noindent  \textbf{Cross-component attack in heterogeneous SoCs:} Dutta et al.~\cite{leaky_buddies} proposed covert channel attacks between CPU and GPU through the shared LLC and ring interconnect in Intel integrated CPU-GPU systems. Weissman et al.~\cite{Jackhammer-2020} and Frigo et al.~\cite{Glitch-2018} developed Rowhammer attack in integrated CPU-FPGA and integrated CPU-GPU systems, respectively.


% %\textbf{Integrated Accelerators as Attack Vectors.}
% \noindent  \textbf{Attacks exploiting data writes:} One recent work \cite{raid_cpu_write} proposed a new side channel called Write+Write based on cache set contention. Their main observation is that a write after writing to an address will be slower than the first address. They exploited this observation to leak secret information.


% \subsection{Defenses}

% %\hoda{I rewrote this section. It seems that none of these defenses target heterogeneous SoCs, but I remember you talked about some defenses in heterogeneous SoCs before. Have not you included those? If those are all for perfromance and there isn't any defense in heterogeneous SoC , I write the following paragraph.}
% %\ghadeer{\cite{sms} is not a defense, they propose new algorithm for performance purposes. no consideration to security.}

% There are several works that propose defense mechanisms against memory timing channels in multi-core CPUs, however, since there is no prior work targeting memory controller attacks in a heterogeneous SoC, none of these defense mechanisms considers memory traffic generated by an accelerator in a heterogeneous SoC.  
 
% \noindent  \textbf{Temporal partitioning:} Wang et al.~\cite{cornell_defense_hpca} proposed a defense mechanism to protect against memory contention channels in multi-core CPUs. They proposed grouping memory requests from a single security domain together and serving memory requests from different security domains based on temporal partitioning. 
% Shafiee et al. \cite{utah_defense_micro} proposed a fixed service policy and static and fine-grained temporal partitioning to avoid information leakage in memory controllers, such that every memory request has a slot and every thread has a constant memory injection rate and a uniform memory access pattern. According to their approach, if a thread has no memory requests to issue, they issue dummy operations to avoid information leakage. These temporal partitioning approaches can lead to a high overhead on the performance and memory bandwidth utilization, specifically in a heterogeneous SoC with massively parallel memory requests from the accelerators. %in a given time.


% \noindent  \textbf{Traffic shaping:} Some other approaches explored memory traffic shaping to overcome timing attacks. Zhou et al. propose Camouflage ~\cite{princeton_defense_hpca} which shapes memory requests' and responses' inter-arrival time into a pre-determined distribution, and even insert fake requests to preserve the pre-determined distribution.  To improve the performance, Deutsch et al. propose DAGguise \cite{mit_defense_asplos}, a memory traffic shaping approach by representing memory traffic using Directed Acyclic Request Graphs (rDAGs) that can match the bandwidth requirements of the program to be protected. Camouflage and DAGguise do not consider the large number of memory requests and responses which can be generated from/to accelerators like GPUs. 

%Even though DAGguise proposed to use suppressed fake requests by updating timing parameters and DRAM state rather than issuing a fake request, considering the large number of threads each issuing its own memory request on GPUs, using such an approach can lead to large performance degradation especially when iGPU is not active.


%Lin et al. propose Duplicon Cache~\cite{duplicon_micro2018} which only targets contention on DRAM bank and bank group conflicts and does not consider resources within the memory controller such as transaction queues.


%\textbf{Temporal Partitioning.} Some of existing defenses targeting contention and interference on memory controller proposed spatial and temporal partitioning to avoid secret information leakage. Wang et al. \cite{cornell_defense_hpca} proposed grouping memory requests from a single security domain together and serving memory requests from different security domains based on temporal partitioning (TP). Each security domain will have a turn with a fixed length to serve its memory requests. They also proposed including extra interval of time (Dead Time) to avoid interference from issued memory transaction at the end of previous turn with memory requests from the next turn. Wang et al. \cite{cornell_defense_hpca} on targeted traffic from CPU cores and did not consider parallel memory request from possible integrated accelerators such as iGPU. Wang et al. \cite{cornell_defense_hpca} also proposed having variable length turns based on application memory accesses. If the iGPU is assigned its own security domain and thus longer turn due to its high number of memory requests, this will affect performance of other CPU applications especially memory intensive and latency sensitive applications since they have to wait for iGPU kernel to finish its turn so that these applications' memory requests can be served. Another challenge, is that even if the iGPU finished its turn, a lot of memory transactions will still be served by the memory controller increasing the possibly of contention. If dead time is added as the paper proposes, such time has to be large enough to ensure all iGPU memory requests will not cause contention with incoming requests from other turns. If dead time is selected to be short, turn has to be long enough to avoid effect of in flight transactions. Such approach will affect the performance of CPU applications especially latency sensitive ones. Also, iGPU applications are not always executing kernels, if they assigned a long turn even if there is no memory traffic to avoid information leakage, performance degradation of other CPU applications will always exists regardless of active or non-active iGPU.

%\textbf{Fixed Service Policy.} Shafiee et al. \cite{utah_defense_micro} proposed fixed level of service to avoid information leakage via memory controller in cloud environments. Such environments do not deploy integrated GPUs in most cases. The paper proposes triple alteration as an optimization to avoid performance drawbacks of no partitioning to ensure different threads do not access the same bank in consecutive accesses. They also propose read write re-ordering due to pipeline limitation by write-to-read delay. In this approach, they serve the reads then the writes. According to their approach, if a thread has no memory requests to issue, they issue dummy operations to avoid information leakage. This approach if applied to environments with hundreds of threads active at the same time, it will lead to unnecessary and large performance degradation. This is especially because iGPU is running less common than CPU cores.

%\textbf{Memory Traffic Shaping.} Other approach explored memory traffic shaping as away to overcome timing attacks. Camouflage \cite{princeton_defense_hpca}proposes memory traffic shaping according the pre-determined distribution. Their approach would insert fake requests to preserve the pre-determined distribution. Their work does not consider the amount of memory requests and responses which can be generated from/to iGPU. If fake requests are used to represent memory traffic from iGPU when it is not active. This will lead to unnecessarily and large performance degradation because number of iGPU threads are large. DAGguise \cite{mit_defense_asplos} proposed memory traffic shaping by representing memory traffic using Directed Acyclic Request Graphs (rDAGs). The paper does not address large memory traffic from devices such as iGPU. Even though they proposed to use suppressed fake requests by updating timing parameters and DRAM state rather than issuing a fake request. Considering the large amount of threads each issuing its own memory request, using such approach can lead to large performance degradation especially when iGPU is not active.

%\textbf{Bank Contention.} Duplicon Cache \cite{duplicon_micro2018} only targets contention on DRAM bank and bank group and does not consider resource with in memory controller such as transaction queue.


%Considering the large number of memory requests from iGPU compared to CPU memory requests, and fixed length turns proposed by Wang et al. \cite{cornell_defense_hpca}. Such approach could either deteriorate the performance of iGPU kernel or performance of applications running on CPU cores based on turn length. In other words, to serve iGPU memory requests the turn interval has to be large enough to ensure serving them. But if the turn interval is small, then iGPU kernel will suffer performance overhead.




%\subsection{DRAM-Based Contention Attacks}

%\subsection{Cache-Based Contention Attacks}