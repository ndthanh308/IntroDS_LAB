\section{Possible Mitigations}
\label{sec:mitigations}
% discuss mitigations which proposed to solve the write buffer issue
% comment on their security, and how it can be improved with consideration to securtity
In this section, we discuss different possible mitigations to thwart the attacks or to make it challenging for attackers to exploit memory write requests.\newline
\noindent{\textbf{Prioritizing Memory Read Requests.}} One of the possible solutions for the latency observed by the CPU process due to iGPU kernel memory write requests is deploying a policy other than \textit{drain\_when\_full}. Deploying a management policy that gives priority to memory read requests whenever they are inserted in the read buffer will thwart our attack. Such an approach may prevent iGPU kernel or CPU processes from issuing write requests if there are read requests in the read buffer and the write and writeback buffers are full. This will deteriorate the performance of CPU processes or iGPU kernel if they are issuing a lot of memory write requests. Also, latency overhead will appear due to \textit{read\_after\_write} and \textit{write\_after\_read} especially if there is frequent alteration between serving memory read and write requests.

\noindent{\textbf{Directing CPU Process's Memory Reads to Ideal DRAM Banks.}} Chatterjee et al.~\cite{staged_reads} proposed Staged Reads to serve memory read requests while memory write requests are being served. This happens only if memory reads are accessing banks not used by memory writes (i.e. ideal banks). Such an approach will not completely thwart our attack, but it will make it challenging for attackers to utilize the effect of \textit{drain\_when\_full} management policy. If Staged Reads \cite{staged_reads} technique is deployed in the system, spy and trojan should pre-agree on accessing same banks for spy read requests to be stalled.

\noindent{\textbf{Channel Partitioning.}} It is possible to thwart our covert channel attack using channel partitioning in multi-channel MCs. This is because each MC channel has its own pair of read and write buffers. One of the MC channels can be dedicated to iGPU during its kernel execution. If the CPU process needs to read from memory associated with this channel, it has to stall until the iGPU kernel finishes execution. Obviously, this approach has a performance impact on CPU processes, especially in the case of kernels with long execution times.





% We believe classes of defenses that have been developed against other microarchitectural covert and side channels on a single component (either CPU or GPU) can potentially apply to cross-component attacks on heterogeneous systems. Rather than securing each component in isolation, these defense designs require some adaptations to consider the system-wide security, functionality, performance, and power goals. These solutions include: 

% \noindent \textbf{Dynamic partitioning of resources:} memory controller request queues (specifically transaction queue) or DRAM banks using dedicated hardware. These partitioning schemes need to support the isolation of memory requests from different processors in heterogeneous systems and also support the bandwidth requirement of each processor dynamically to minimize the performance overhead. 

% \noindent \textbf{Memory scheduling and traffic control in memory controllers:} eliminating the contention among processes running on different processors, such that memory requests from each processor are grouped into the same queue (or sub-queues) and possibly scheduled and routed to the same subset of memory banks or channels. 






%In this section, we suggest different possible mitigations to address contention on memory controller resources due to iGPU memory traffic.

%\textbf{Spatial Partitioning.} One of the possible approaches to avoid contention on MC resources is to partition them spatially. The high level of contention we observe in this attack is due to sharing of resources such as queues within the memory controller. If we partition these resources between CPU cores and iGPU, spy process will never observe same level of contention. Partitioning should also be considered for other resources such as memory channels. Current iGPU is usually deployed in processor chips with one memory controller with two channels. It is possible to assign one of the channels for iGPU traffic and the other channel for CPU cores traffic. The drawback of this approach is that iGPU is not always executing kernels and resources assigned to iGPU will become under utilized.

%\hoda{temporal partitioning has huge performance impact, not a good solution in any case}
%\textbf{Temporal Partitioning.} Another possible approach to avoid contention caused by iGPU memory traffic is to use temporal partitioning. In this approach, a turn is designated to each source whether its iGPU or CPU cores for its memory requests to be served. With temporal partitioning iGPU and CPU cores memory requests will not use the same resources at the same time. This approach still has to consider in flight memory requests even if resource turn finishes issuing its requests \cite{cornell_defense_hpca}.

%time and space multiplexting
%resource paritioning
%