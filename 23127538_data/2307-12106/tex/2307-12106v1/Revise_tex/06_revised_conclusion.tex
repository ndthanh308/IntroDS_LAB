\section{Conclusion and Future Work}
\label{sec:conclusion}

In this paper, we study the camera-to-robot pose estimation using single-view successive frames from an image sequence. By leveraging the robot structure priors, we use a temporal attention mechanism to efficiently fuse keypoint features from different frames. 
Our method demonstrates significant improvements over synthetic and real-world datasets, strong dominance compared with traditional hand-eye calibration and high accuracy and stability in downstream grasping tasks.
One limitation of our method is that although domain randomisation can narrow the sim-to-real gap to some extent, generalising to arbitrary scenes remains a significant challenge. To address this limitation, future work could explore domain adaptation between real and simulated scenes and fine-tuning in real-world settings.
%%However, our method requires images containing in-frame robot keypoints as many as possible, which has a high demand for data generation, and in extreme conditions, our performance needs improvement.\textit{e.g.the camera is too close to the robot.} 
% Besides, the sim2real gap within RGB images still haunts the task, and utilising RGB-D images to estimate camera-to-robot pose should be a novel way. %We leave this to future work.  
% The advantage of our method concerning the previous works is that