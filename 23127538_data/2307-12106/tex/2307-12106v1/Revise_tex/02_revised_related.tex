\vspace{-2mm}
\section{Related Works}
\label{sec:related}

\noindent\textbf{Instance-level 6D Object Pose Estimation.}
Given RGB images and the robot's CAD model,  the camera-to-robot pose is solely determined by the 6D pose of the robot base.
Therefore, our objective is highly correlated with the instance-level 6D rigid object pose estimation \cite{Zhu2022ARO, Kehl2017SSD6DMR}.
Its goal is to infer an object's 6D pose given a reference frame by assuming the exact 3D CAD model is available.
Traditional methods, including iterative closest point (ICP) \cite{besl1992method}, perform template matching by aligning CAD models with the observed pointclouds. 
Some recent works \cite{Song2020HybridPose6O, Lin2021SparseSC, Iwase2021RePOSEF6, 6d1} regard the pose estimation as a regression or a classification task.
2D parameter representation or geometry-guided features will be predicted \cite{Li2019DeepIMDI,Simonyan2015VeryDC,Dosovitskiy2015FlowNetLO}, and then improved PnP solvers \cite{Wang2021PnPDETRTE, Chen2022EProPnPGE} are used to estimate poses.
Although these works are closely related to ours, the manipulator is an articulated object with several degrees of freedom and potential entangling parts, whose pose is tougher to estimate. 

\noindent\textbf{2D Center-based Object Detection and Tracking.}
Our approach predicts camera-to-robot pose via keypoint estimation, which shares similar goals in 2D center-based object detection and tracking.
% % 介绍概述，这是一个center-based, anchor free的目标检测方法，从19年开始兴起
The center-based method \cite{CenterNet, CenterKT} has been an emerging anchor-free object detection method in recent years,
% % 它将object看做一个点，然后
which models an object as a single point via keypoint estimation and regresses other object properties such as bounding boxes, 3D locations, or poses \cite{ct1, ct2, ct3}. 
% % 后续有人将它用在tracking任务中
Some works \cite{CenterTrack, DEFT, Track, ct4} also extend these center-based models to tracking tasks such as multi-category tracking and pose tracking, applying a detection model to a pair of images and detections from the previous frame.
% % 除了2D的目标检测，也有人将它运用在3D中
% Besides, in the 3D object detection area, center-based networks \cite{CenterFormer, CenterPoint} are utilised to process point cloud data and have achieved great performances.
% % center-based model最负盛名的是什么？简单，效果好，实时
These center-based methods \cite{ct5, ct6, ct7} have succeeded in simplicity and speed. 
However, the methods mentioned \cite{CenterNet, CenterTrack, CenterPoint} mainly adopt simple concatenations to fuse temporal information and thus overlook accurate pixel-wise correspondence, where we propose a robot structure guided feature alignment module and a temporal cross-attention module to produce better feature fusion.

\noindent\textbf{Robot Arm Pose Estimation.}
Recently, many learning-based camera-to-robot pose estimation methods have been proposed, which can be divided into three types.
The first type falls into keypoint-based methods via a single RGB image.
For example, DREAM\cite{Lee2020CameratoRobotPE} designs a CNN-based pipeline to regress 2D keypoints, construct 2D-3D correspondence and recover the camera-to-robot pose via a PnP-solver. 
Lately, \cite{lu2022pose} seeks to find the optimal 2D keypoint candidates for better acquiring pose estimations.
The second type falls into rendering-based methods given robots' 3D CAD models \cite{rb1, labbe2021single}. 
Robopose \cite{labbe2021single} optimises the camera-to-robot pose by iteratively rendering images and comparing them with ground truth.
This method requires a long time (1s) to predict an excellent initial pose and fails in dynamic scenarios. 
The last type falls into depth-based methods \cite{rb2,Simoni2022SemiPerspectiveDH}, which rely highly on depth sensors' precision and lack high accuracy in real-world experiments.