\section{\ourtool{}: Fuzzing Processors with PSO}\label{sec:method}
In this section, we first formulate the problem of selecting optimal mutation operators as a PSO problem. However, the formulation has critical limitations, such as saturation of particles' performance and inefficient seed generation. We analyze these limitations and devise appropriate solutions, resulting in a final formulation that outperforms fuzzers without PSO.

\subsection{Selecting Mutation Operators Using PSO}\label{sec:PSO_mutation_prelim_formulation}
Most existing hardware fuzzers select mutation operators uniformly at random, i.e., they have an equal probability of selecting from all possible mutation operators~\cite{rfuzz,kande2022thehuzz,chen2023hypfuzz, canakci2021directfuzz, muduli2020hyperfuzzing, ragab_bugsbunny_2022,fuzzhwlikesw, hur2021difuzzrtl}. 
This is not ideal as mutation operators have varying impacts on covering new points in hardware. The following example demonstrates this.

\lstinputlisting[language=Verilog, label = {listing:example_listing}, caption={Code snippet from \cva{}~\cite{cva6} processor (simplified to improve readability)},style=prettyverilog,float,belowskip=-15pt,aboveskip=0pt,firstnumber=1,linewidth=\linewidth]{Codes/Verilog/list_example.v}
\textbf{Motivational Example.} Consider a component from the decoder module in the \cva{}~\cite{cva6} processor as shown in Listing~\ref{listing:example_listing}. 
When decoding the \texttt{CSRRS rd, csrReg, rs1} instruction, the processor performs \texttt{CSR\_READ} (line 5) or \texttt{CSR\_SET} (line 7) operation on the control and status register~(CSR), \texttt{csrReg}, based on the register operand \texttt{rs1} (line 4).
Assume the coverage points $c_1$ and $c_2$ in the \textit{if-else} block as shown in line 5 and line 7.
Suppose the instruction in the current input is \texttt{CSRRS x16, stvec, x0}. 
The value of \texttt{rs1} for this instruction is \texttt{0}. Hence the \textit{if} condition evaluates to \texttt{True}, and the \texttt{CSR\_READ} operation is performed on the CSR, \texttt{stvec}, covering the point $c_1$. 
Now, our objective, when mutating this input, is to cover $c_2$. Also, suppose we have only two mutation operators in this toy example: \textit{Bitflip}, which flips one bit of the operand, \texttt{rs1}, and \textit{OpcodeMut}, which mutates the opcode to another opcode. If both mutation operators are equally likely to be selected, the probability of covering $c_2$ after mutation is $(0.5\times 0) + (0.5\times 1) = 0.5$. On the other hand, if we assign a higher weight to \textit{Bitflip}, say $0.9$, the probability of covering $c_2$ is $(0.1\times 0) + (0.9\times 1) = 0.9$. So, selecting mutation operators with equal probability is not ideal.
To address this problem, we formulate the problem of finding the optimal weights for the mutation operators as a PSO problem, as explained next.

\textbf{Notation.} Let $M$ be an ordered list of all mutation operators (i.e., $M[j]$ is the $j^{\text{th}}$ mutation operator).
Let $W^M = [w^M_1, w^M_2, \ldots, w^M_{|M|}]$ be a weight vector for the $|M|$ operators. So, $w^M_j$ is the weight of the $j^{\text{th}}$ mutation operator $M[j]$. Note that since we interpret the weights as the probabilities of selecting the mutation operators, we normalize the weights so that $\sum_{j=1}^{|M|} w^M_j = 1$ and $w^M \geq 0, \forall w^M \in W^M$.

\textbf{Particles.} We associate a particle with one thread of the fuzzer. Since fuzzers run multiple, say $|N|$, threads simultaneously, we have a swarm of $|N|$ particles associated with the fuzzer. Each of these $|N|$ threads has a different weight vector $W_i^M$ for mutating the inputs in its thread. Each such $W_i^M$ is assigned as the position $p_i^M$ of the corresponding particle $i^M$ ($M$ indicates that the particle refers to mutation operators). Mathematically, $W_i^M = p_i^M$.

\textbf{Local Best Position.} Following PSO, we assign the local best position, $l_i^{best,M}$, of a particle as the best position 
of that particle so far. In our case, we define a position at iteration $t_2$, $p_i^M(t_2)$, as better than the position at iteration $t_1$, $p_i^M(t_1)$, if and only if $p_i^M(t_2)$ results in higher coverage than $p_i^M(t_1)$.


\textbf{Global Best Position.} Likewise, following PSO, we assign a single global best position, $g^{best,M}$, as the best position of all particles in the swarm.

Fig.~\ref{fig:integrating_PSO_in_TheHuzz} illustrates the high-level flow of this formulation. Like other hardware fuzzers, we generate a set of seeds, which are simulated to obtain their coverage information. Then, we use this coverage information to update the $L^{best,M} = [l_1^{best,M}, l_2^{best,M}, \ldots, l_{|N|}^{best,M}]$ and the $g^{best,M}$. Then, we update the velocities ($v_i^M$) and positions ($p_i^M$) of all particles according to Eqs.~(\ref{eq:up_v}) and~(\ref{eq:up_p}). 
We sample the mutation operators according to the updated positions ($p_i^M$), i.e., mutation operator weights ($W_i^M$), and perform the mutations to generate new tests. These new tests are simulated to obtain coverage, and the cycle continues. After several iterations, the particles are expected to converge to the optimal solution.

% Figure environment removed

This preliminary solution provides a way to find a weight distribution of the mutation operators. However, it has two critical limitations, as explained below.

% Figure environment removed
\subsection{Reset Particles and Seeds}\label{sec:solution1}

\textbf{Challenge 1: Saturation of Particles' Performance.} Traditional PSO is designed so that the particles converge to an optimum (ideally the global optimum) in the solution space. However, for fuzzing hardware, one must find new coverage points in each iteration that have not been covered. In other words, the optimal solution (i.e., the weights of the mutation operators) changes based on the coverage achieved so far, as explained in the following example. 


\textbf{Motivational Example.} 
Refer to Listing.~\ref{listing:example_listing} with two coverage points, $c_1$ and $c_2$. Without loss of generality, assume two mutation operators $m_1$ and $m_2$ with the following property: $\mathcal{P}(c_1|m_1)=0.9$ and $\mathcal{P}(c_1|m_2) = 0.2$, where $\mathcal{P}(c_i|m_j)$ denotes the probability of covering $c_i$ conditioned on the event that mutation operator $m_j$ is used.\footnote{Note that since the coverage points belong to two different mutually exclusive and exhaustive branches, $\mathcal{P}(c_2|m_1)=0.1$ and $\mathcal{P}(c_2|m_2) = 0.8$.} Suppose during the first iteration ($t=1$), the weights for the two mutation operators are equal, i.e., $0.5$. Then, the probability of covering $c_1$, $\mathcal{P}(c_1)^{t=1} = (0.5 \times 0.9) + (0.5 \times 0.2) = 0.55$, and $\mathcal{P}(c_2)^{t=1} = (0.5 \times 0.1) + (0.5 \times 0.8) = 0.45$. Now, if $c_1$ is covered in the first iteration, then, for the second iteration ($t=2$), having equal weights for both operators results in $\mathcal{P}(c_2)^{t=2} = \mathcal{P}(c_2)^{t=1} = 0.45$. On the other hand, if we have a larger weight for $m_2$, say $0.9$, then $\mathcal{P}(c_2)^{t=2} = (0.1 \times 0.1) + (0.9 \times 0.8) = 0.73$. In fact, to maximize the likelihood of covering $c_2$ in the second iteration, the weight for $m_2$ should be $1$. 

This simple example shows that to maximize the likelihood of covering the maximal number of points with the minimal number of iterations (i.e., input tests), the weights of the mutation operators should be decided dynamically based on the coverage achieved so far.
However, during our experiments with the preliminary PSO formulation, we observe that the positions of the particles ($p_i^M$) 
saturate after a few iterations because their velocities ($v_i^M$) become zero according to Eq.~(\ref{eq:up_v}). In other words, the weights of selecting the mutation operators ($W_i^M$) stagnate very quickly.
Fig.~\ref{fig:cva6_particle_position_103_evolution_without_and_with_reset}~(a) demonstrates this phenomenon for the \texttt{CVA6} processor. The particles saturate within $50$ iterations. Due to this, the preliminary formulation fails to detect critical vulnerabilities (more details in Sec.~\ref{sec:exp}).

\textbf{Solution 1.} To address challenge 1, we reset the position ($p_i^M$) and velocity ($v_i^M$) of the particles that saturate, i.e., that do not yield new coverage. Resetting removes saturating particles and replaces them with new particles, leading to new weights for the mutation operators ($W_i^M$). Along with resetting the position and velocity of the saturated particle, we also reset the associated seed because the position and velocity of a particle are a function of the seed it started from (as seen in Fig.~\ref{fig:integrating_PSO_in_TheHuzz}). Using the same seed when resetting the particle will likely lead to the exploration of design space that has already been explored by that particle. This is suboptimal since our objective is to cover new regions in the design.

The condition for resetting the particles and their seeds is decided based on the coverage trend in recent iterations. We reset when there is no improvement in coverage for $\beta^M$ consecutive iterations. Here, $\beta^M$ controls the trade-off between runtime and exploitation of learned knowledge by the particles. Larger values of $\beta^M$ can lead to a deeper exploration of design but will incur runtime overhead since the particles are not reset quickly after they saturate.
On the other hand, smaller values of $\beta^M$ can reduce runtime but will make the algorithm similar to random exploration, which will not cover deeper regions of the design. 

Fig.~\ref{fig:cva6_particle_position_103_evolution_without_and_with_reset}~(b) shows the positions of the particles for different mutation operators after implementing this solution for \texttt{CVA6}. When the particles saturate, they are reset (along with the associated seeds), resulting in higher coverage speedup (as seen in Table~\ref{tab:cov}). 
Algorithm~\ref{alg:reset} details how this solution is incorporated using a reset monitor, \textit{RstMon}. It takes as input a set of particles, their $L^{best}$, resetting threshold ($\beta$), a variable to count the number of consecutive iterations with no improvement ($Ct$), and a function $\mathcal{F}$ that returns the fitness (i.e., coverage) of a particle. 
The algorithm iterates over all particles and compares the coverage with the particle's local best coverage (lines 2 and 3). If a particle's coverage is more than its local best coverage, the local best is updated, and the counter ($Ct$) is reset (lines 4 and 5). Otherwise, the counter is incremented, indicating no improvement in coverage for one more consecutive iteration for that particle (line 7). If the counter exceeds the threshold $\beta$ for a particle, that particle is added to the set of particles to be reset, $rst\_P$ (lines 8 and 9). Finally, the algorithm updates the global best ($g^{best}$) using all particles' local bests (line 10).

\input{Codes/pseudoalgo/alg1}

% Figure environment removed
\subsection{Seed Generation Using PSO}\label{sec:solution2}

\textbf{Challenge 2: Ineffective Seed Generation.} 
A drawback of existing hardware fuzzers (as well as our preliminary formulation) is that they use a static probability distribution of instructions to generate the seeds~\cite{rfuzz,kande2022thehuzz,chen2023hypfuzz, canakci2021directfuzz, muduli2020hyperfuzzing, ragab_bugsbunny_2022}. 
However, the optimal set of instructions required by the seeds to trigger new coverage points changes with time during fuzzing.\footnote{An example similar to the one described in Sec.~\ref{sec:solution1} can demonstrate this, but we omit it in the interest of space.} 
Moreover, the performance of each particle for mutation operators ($i^M$), i.e., the number of iterations it survives, is highly related to the quality of its seed. 

\textbf{Solution 2.} To address this problem of static distribution of instructions for seed generation, we devise a dynamic seed generation algorithm using PSO. The idea is to map the problem of identifying optimal probabilities of the instructions for seeds as a PSO problem. Next, we discuss this formulation.

\textbf{Notation.} Let $T$ be an ordered list of instruction types, such as R-type and I-type~\cite{riscv_home}. Let $W^T = [w^T_1, w^T_2, \ldots, w^T_{|T|}]$ be the weight vector for the $|T|$ instruction types. So, $w^T_j$ is the weight of the $j^{\text{th}}$ instruction type $T[j]$, and $\sum_{j=1}^{|T|} w^T_j = 1$ and $w^T \geq 0, \forall w^T \in W^T$. 

\textbf{Particles.} Similar to the PSO formulation for selecting mutation operators (Sec.~\ref{sec:PSO_mutation_prelim_formulation}), we associate a particle with one thread of the fuzzer. So, there are a total of $|N|$ particles in the swarm, where $|N|$ is the number of fuzzer threads. Suppose that each seed consists of a sequence of $|O|$ instructions.
Then, for each of  the $|N|$ threads being run simultaneously, we have a different weight vector $W_i^T$ 
(which contains $|O|\times |T|$ entries, one for each of the $|T|$ instruction types for each of the $|O|$ instructions in the seed).

Each weight vector $W_i^T$ is assigned as the position $p_i^T$ of the corresponding particle $i^T$. Here, the $T$ in the superscript indicates that the particle is for the instruction types, as opposed to the $M$ in the particles for selecting mutation operators in Sec.~\ref{sec:PSO_mutation_prelim_formulation}.
Mathematically, $W_i^T = p_i^T$.

\textbf{Local Best Position.} Following PSO, we assign the local best position, $l_i^{best,T}$, of a particle as the best position (i.e., the probabilities of the instruction types) of that particle so far. Since this PSO is for seed generation, the objective it aims to maximize is the quality of the generated seed. 
We measure the quality of a particle for selecting instruction types ($i^T$) as the number of iterations the associated particles for selecting mutation operators ($i^M$) survive.
For instance, for a given particle, $i^T$, if at iteration $t_1$ and  $t_2$, its associated particle for selecting mutation operators ($i^M$) survived for $150$ and $200$ iterations, respectively (as explained in Sec.~\ref{sec:solution1}), then $p_{i}^T(t_2)$ is better than $p_{i}^T(t_1)$.


\textbf{Global Best Position.} Likewise, following PSO, we assign a single global best position, $g^{best,T}$, as the best position of all particles in the swarm.


The high-level flow of this PSO for seed generation is very similar to that of the PSO for selecting mutation operators. We start with randomly initialized particles and update their velocities and positions according to Eqs.~(\ref{eq:up_v}) and (\ref{eq:up_p}), respectively. Moreover, learning from the prior pitfall of saturation of particles' performance (Sec.~\ref{sec:solution1}), we also reset the particles for this PSO-based seed generation when they saturate. 
Since the quality of a particle for selecting instruction types ($i^T$) is measured by the number of iterations its corresponding particle for selecting mutation operators ($i^M$) survives, we reset $i_T$ when its corresponding $i^M$ is reset $\beta^T$ consecutive times.
Similar to $\beta^M$, $\beta^T$ controls the trade-off between runtime and exploitation of learned knowledge by $i^T$s.

\subsection{Putting it All Together}

Fig.~\ref{fig:PSOHuzz_framework} shows the \ourtool{} framework, which includes PSO formulation along with the resetting of seeds and particles for selecting mutation operators as well as the PSO formulation for seed generation.
The PSO formulation of seed generation guides the \textit{seed generator} by selecting the instruction type from the instruction set architecture (ISA) pool. 
Once the instruction type is sampled, the \textit{seed generator} randomly selects an opcode of that instruction type and then the operands to create the instruction. These instructions are then used to create the seeds, which are added to the \textit{input test database}. 
The DUT is simulated with the tests to obtain coverage. 
This coverage data is used to update the particles' velocities and positions through their local and global bests and the reset monitor. The updated positions are used to generate seeds and mutate tests in the subsequent iterations.

\input{Codes/pseudoalgo/alg2}
Algorithm~\ref{alg:overall} details the steps of~\ourtool. It takes the DUT, a user-defined time limit, $t_{limit}$, a user-defined target coverage, $tc$, the thresholds for resetting the PSOs for mutation operators and seed generation, $\beta^M$ and $\beta^T$, and the constant, $k$, used to update the velocities of the particles (Eq.~(\ref{eq:up_v})). We fuzz the DUT and return the coverage achieved, $cov$. 
First, we initialize all required variables for PSO ($P^M,V^M,P^T,V^T,L^{best,M},g^{best,M},L^{best,T},g^{best,T}$). We also initialize 
the saturation counters ($Ct^M, Ct^T$) along with the sets indicating particles that need to be reset because of saturation ($rst\_P^M,rst\_P^T$). 
Next, on line 7, we use the positions $P^T$ to generate the initial set of seed $tests$.
Then, the main fuzzing loop starts on line 8, which iterates until either the target coverage ($tc$) is achieved or the runtime exceeds the time limit, $t_{limit}$.
In each iteration of the fuzzing loop, we first simulate the DUT with the generated $tests$ to obtain the function $\mathcal{F}^M$ (which calculates the fitness of the particles)
and the coverage achieved so far, $cov$ (line 9). 
Next, on line 10, this $\mathcal{F}^M$ is used to calculate the local and global bests for the particles for mutation operators and to decide which particles need to be reset according to $\beta^M$ following Algorithm~\ref{alg:reset}.
Then, skipping ahead on line 15, the velocities and the positions of the particles for mutation operators are updated, 
and on lines 16 and 17, the new $tests$ are generated for both particles that are reset
and not reset, respectively.

Additionally, on line 11, we check if any of the particles for the mutation operators needs to be reset, i.e., $rst\_P^M \neq \phi$, and
calculate the number of iterations those particles survived (i.e., fitness) and return $\mathcal{F}^T$ on line 12.
This $\mathcal{F}^T$ is used to calculate the local and global bests for the particles for seed generation and to decide which ones to reset according to $\beta^T$ on line 13.
Finally, on line 14, the velocities and the positions of the particles for seed generation are updated.