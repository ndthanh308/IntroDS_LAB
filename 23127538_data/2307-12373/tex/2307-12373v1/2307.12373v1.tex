\documentclass[12pt]{amsart}
\usepackage{amssymb,amsmath,amsfonts,latexsym}
\usepackage{bm, enumerate}
\usepackage{hyperref}


%%%%%%%%%%%%
\setlength{\textheight}{9in}\setlength{\textwidth}{475pt}
\oddsidemargin -0mm \evensidemargin -0mm \topmargin -0pt
\newcommand{\newsection}[1]{\setcounter{equation}{0} \section{#1}}
\setcounter{footnote}{1}
\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}
%%%%%%%%%%%
%\setlength{\textheight}{600pt} \setlength{\textwidth}{475pt}
%\oddsidemargin -0mm \evensidemargin -0mm \topmargin -0pt
%\newcommand{\newsection}[1]{\setcounter{equation}{0} \section{#1}}
%\setcounter{footnote}{1}
%\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%Shortenings%%%%%%%%%%%%%%%%%%%
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\dsp}{\displaystyle}
\newcommand{\di}{ \mbox {diag}}
\newcommand{\kmat}{I\!\!\!\:M_k}
%\newcommand{\vp}{\varphi}
\newcommand{\cd}{\cdot}
\newcommand{\bolda}{{\mbox{\boldmath $a$}}}
\newcommand{\boldb}{{\mbox{\boldmath $b$}}}
%\newcommand{\bl}{{\mbox{\boldmath $\lambda$}}}
\newcommand{\bL}{{\mbox{\boldmath $\Lambda$}}}
\newcommand{\bmu}{{\mbox{\boldmath $\mu$}}}
\newcommand{\bal}{{\mbox{\boldmath $\alpha$}}}
\newcommand{\bbe}{{\mbox{\boldmath $\beta$}}}
\newcommand{\1}{{\mbox{\bf 1}}}
\newcommand{\sma}{\sigma}
\newcommand{\smat}{\sigma_{\rm{T}}}
\newcommand{\spt}{\sigma_{\rm{pt}}}
\newcommand{\al}{\alpha}
\newcommand{\lmd}{\lambda}
\newcommand{\Lmd}{\Lambda}
\newcommand{\cla}{\mathcal{A}}
\newcommand{\clb}{\mathcal{B}}
\newcommand{\clc}{\mathcal{C}}
\newcommand{\cld}{\mathcal{D}}
\newcommand{\cle}{\mathcal{E}}
\newcommand{\clf}{\mathcal{F}}
\newcommand{\clg}{\mathcal{G}}
\newcommand{\clh}{\mathcal{H}}
\newcommand{\clk}{\mathcal{K}}
\newcommand{\cll}{\mathcal{L}}
\newcommand{\clm}{\mathcal{M}}
\newcommand{\cln}{\mathcal{N}}
\newcommand{\clo}{\mathcal{O}}
\newcommand{\clp}{\mathcal{P}}
\newcommand{\clq}{\mathcal{Q}}
\newcommand{\clr}{\mathcal{R}}
\newcommand{\cls}{\mathcal{S}}
\newcommand{\clt}{\mathcal{T}}
\newcommand{\clu}{\mathcal{U}}
\newcommand{\clw}{\mathcal{W}}
\newcommand{\clx}{\mathcal{X}}
\newcommand{\cly}{\mathcal{Y}}
\newcommand{\clz}{\mathcal{Z}}


\newcommand\Tt{\tilde{T}}
\newcommand\Zp{\mathbb{Z}_+^n}
\newcommand\bH{\mathbb{H}}
\newcommand\bk{\bm{k}}
\newcommand\bl{\bm{l}}
\newcommand\bv{\bm{v}}
\newcommand\T{\bm{T}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\z}{\bm{z}}
\newcommand{\w}{\bm{w}}
\newcommand{\bh}{\mathcal{L}(\mathcal{H})}
\newcommand{\bx}{\mathcal{L}(\mathcal{X})}
\newcommand{\ahat}{\widehat{\bf A}}
\newcommand{\ma}{{\bf M_A}}
\newcommand{\lnh}{\Lmd_n( \clh )}
\newcommand{\fal}{\forall}
\newcommand{\raro}{\rightarrow}
\newcommand{\Raro}{\Rightarrow}
\newcommand{\bydef}{\stackrel{\rm def}{=}}
\newcommand{\subnq}{\begin{array}[t]{c} \subset \\*[-15pt] \scriptstyle\neq
\end{array}}
\newcommand{\supnq}{\begin{array}[t]{c} \supset \\*[-15pt] \scriptstyle\neq
\end{array}}
\newcommand{\vsp}{\vspace{5mm}}
\newcommand{\hsp}{\hspace{5mm}}
\newcommand{\vspp}{\vspace{1cm}}
\def \qed {\hfill \vrule height6pt width 6pt depth 0pt}
\def\textmatrix#1&#2\\#3&#4\\{\bigl({#1 \atop #3}\ {#2 \atop #4}\bigr)}
\def\dispmatrix#1&#2\\#3&#4\\{\left({#1 \atop #3}\ {#2 \atop #4}\right)}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\ben}{\begin{eqnarray*}}
\newcommand{\een}{\end{eqnarray*}}
\newcommand{\CC}{\centerline}
\newcommand{\NI}{\noindent}
\newcommand{\addeqn}{\addtocounter{equation}{1}}
\def \pf {{\sc Proof}\hspace{.5cm}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\diag}{\mbox{diag}}
\def\npair{{\mbox{\boldmath $n$}}}


\newcommand\lar{\leftarrow}
\newcommand\Lar{\Leftarrow}
\newcommand\rar{\rightarrow}
\newcommand\Rar{\Rightarrow}
\newcommand\tT{{\tilde{T}}}
\newcommand\h{\frac{1}{2}}

\newcommand\la{\langle}
\newcommand\ra{\rangle}







%%%%%%%%%%%%%Theorem Environment%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{Theorem}{\sc Theorem}[section]
\newtheorem{Lemma}[Theorem]{\sc Lemma}
\newtheorem{Proposition}[Theorem]{\sc Proposition}
\newtheorem{Corollary}[Theorem]{\sc Corollary}
\newtheorem{Definition}[Theorem]{\sc Definition}
\newtheorem{Example}[Theorem]{\sc Example}
\newtheorem{Remark}[Theorem]{\sc Remark}
\newtheorem{Remarks}[Theorem]{\sc Remarks}
\newtheorem{Note}[Theorem]{\sc Note}
\newtheorem{Question}{\sc Question}
\newtheorem{ass}[Theorem]{\sc Assumption}
%\newtheorem{Definition}[Theorem]{\sc Definition}
\newcommand{\bt}{\begin{Theorem}}
\def\beginlem{\begin{Lemma}}
\def\beginprop{\begin{Proposition}}
\def\begincor{\begin{Corollary}}
\def\begindef{\begin{Definition}}
\def\beginexamp{\begin{Example}}
\def\beginrem{\begin{Remark}}
\def\beginq{\begin{Question}}
\def\beginass{\begin{ass}}
\def\beginnote{\begin{Note}}
\newcommand{\et}{\end{Theorem}}
\def\endlem{\end{Lemma}}
\def\endprop{\end{Proposition}}
\def\endcor{\end{Corollary}}
\def\enddef{\end{Definition}}
\def\endexamp{\end{Example}}
\def\endrem{\end{Remark}}
\def\endq{\end{Question}}
\def\endass{\end{ass}}
\def\endnote{\end{Note}}

\numberwithin{equation}{section}

%\newcommand{\Complex}{\mathbb{C}}



\begin{document}

\title{Completely non-unitary contractions and analyticity }


\author[Das]{Susmita Das}
\address{Indian Institute of Science, Department of Mathematics, Bangalore, 560012,
India}
\email{susmitadas@iisc.ac.in, susmita.das.puremath@gmail.com}

\today

\subjclass[2010]{47A08, 47A55, 47A75, 47B20, 47B32, 47B38, 47B91, 47B99}

\keywords{Contractions, Defect spaces, Unilateral shifts, Analytic operators, Hyponormal operators}

\begin{abstract}
 We study non isometric completely non unitary contraction $T$ with defect spaces $\cld_T$ and $\cld_{T^*}$. If $\cld_T\subseteq\cld_{T^*}$ and $\dim\cld_{T^*}<\infty$, we show that $T$ is analytic if and only if it has no non-zero eigenvalue. We also characterize hyponormality of such operators.
\end{abstract}


\maketitle


\newsection{Introduction}\label{sec: intro}

Let $\clh$ be a separable, infinite dimensional, complex Hilbert space and $\clb(\clh)$ denote the algebra of all bounded linear operators on $\clh$. An operator $T \in \clb(\clh)$ is called a contraction if $\|T\|\leq 1$.  To each contraction $T$ one can associate two operators $D_T= (I-T^*T)^{1/2}$ and $D_{T^*}=(I-TT^*)^{1/2}$, called the defect operators (\cite{NF}). The spaces $\cld_T= \overline{D_T \clh}$ and $\cld_{T^*}=\overline{D_{T^*}\clh}$ are known as the defect spaces and their corresponding dimensions are called indices of $T$. If an operator $T$ is hyponormal (\cite{Martin-Putinar}) i.e, $T^*T> TT^*$, $\text{Ran }T$ will be included in the $\text{Ran }T^*$ by Douglas Lemma (\cite{Douglas}). Formally, it states that: \textsf{If $A$ and $B$ are bounded operators on a Hilbert space $\clh$, the following are equivalent:
\begin{enumerate}
\item $\text{Ran }A \subseteq\text{Ran }B $
\item $AA^*\leq \lambda^2 BB^* \text{ for some }\lambda\geq 0$
\item \text{ There exists a bounded operator } $C$ on $\clh$ such that $A=BC$.
\end{enumerate}
}
The property of hyponormality and there spectral behaviours has been extensively studied by many authors (e.g. \cite{Curto 1}, \cite{Curto 2}, \cite{Curto}, \cite{DB}, \cite{Exner}, \cite{Xia}). However, a complete characterization of hyponormality for a general bounded linear operator is still not known. If a hyponormal operator $T$ is also a contraction, we can go further. In fact, the relation $T^*T\geq TT^*$, together with the existence of defect operators will allow us to write $I-T^*T\leq I-TT^*$, which is exactly the second condition of the Douglas lemma with $A=D_T$, $B=D_{T^*}$ and $\lambda=1$. As a consequence, for a hyponormal contraction, one will always have $\cld_T\subseteq\cld_{T^*}$.

A contraction $T$ is called completely non-unitary (c.n.u. for short), if there is no nontrivial $T$ reducing subspace $\clm$ of $\clh$ such that $T|_\clm$ is unitary. It is well known \cite{NF}, that any nontrivial bounded contraction can be uniquely decomposed as the direct sum of a unitary and a completely non unitary contraction. Since the unitary part of a contraction has no role in the computation of associated defect operators and the corresponding indices, we will consider only c.n.u. contractions throughout the paper. The Unilateral shift $S$ on the Hardy space $H^2(\D)$ is one of the most well-studied example of a c.n.u. contraction (\cite{AS}). Since $S$ is an isometry, $D_S=0$. Not only that, $\cld_S\subseteq\cld_{S^*}$ and $D_{S^*}$ is of finite dimension. $S$ is also hyponormal. Therefore, it is natural to ask, if a c.n.u contraction $T$ with finite indices satisfy $\cld_T\subseteq\cld_{T^*}$, can we recover hyponormality? The answer is `No'. In Section \ref{sec:Characterization}, we give a counter example \ref{n-hyp/analytic}, which shows that such operators are not hyponormal in general. In Theorem \ref{thm: char}, we first characterize a c.n.u contraction $T$ with finite indices and having the property $\cld_T\subseteq\cld_{T^*}$. This characterization result establishes a deep connection between the theory of contraction and the theory of finite rank perturbations of unilateral shift (\cite{Nakamura 1}, \cite{Nakamura}). On the basis of this, we give a complete classification of hyponormality of such contractions in terms of certain finite rank operators in Theorem \ref{Hyponormal}. As an application, we show in Theorem \ref{D_T=1} that, if in addition, $T$ is a c.n.u. with $\dim\cld_T=1$, $T$ will always be hyponormal.

A bounded linear operator $T$ on a Hilbert space $\clh$ is called  analytic if $\bigcap_{n\geq 1}T^n \clh=\{0\}$. Any nilpotent operator and the multiplication operators $M_z$ on  reproducing kernel Hilbert space of complex analytic functions (\cite{Aronszajn}) are a wide class of examples of analytic operators. The property of analyticity plays a crucial role in (\cite{SS}) to establish the unitary equivalence of a left invertible operator and the multiplication operator $M_z$ on some reproducing kernel Hilbert space. Again, it is curious to note that, if a contraction is analytic, it must be completely non-unitary. However, a c.n.u. contraction $T$ with finite indices neither satisfies $\cld_T\subseteq\cld_{T^*}$ nor it has to be analytic in general. For example, let us consider the bounded operator $T$ on $H^2(\D)$ defined by, $$T(1)=T(z)=\frac{1}{\sqrt{2}}$$ and $T(z^n)=z^{n+1}$ for all $n\geq 2$. Then, an easy computation will show that $T$ is a c.n.u. and $\cld_T=\mathbb{C}(1-z)$, $\cld_{T^*}=\C z\oplus \C z^2$ and hence $\cld_T\nsubseteq\cld_{T^*}$. Also, as $1$ is an eigen vector of $T$, it is not analytic. Under this circumstances, one can definitely ask for a classification result of analyticity for a general c.n.u. contraction. We provide an answer for the analyticity of a c.n.u. contraction in the light of characterization result, Theorem \ref{thm: char}. The rest of the paper is organized as follows:

\medskip

In Section \ref{sec: example}, we consider an example of an operator $T$ which is not an isometry but a c.n.u contraction with $\cld_T \subseteq \cld_{T^*}$ and $\dim\cld_{T^*}<\infty$. We eventually show that, $T$ is both hyponormal and analytic. In Theorem \ref{thm: char}, we provide a complete characterization of such operators. In fact, we show that, these contractions are certain finite rank perturbations of unilateral shifts of finite multiplicities. Using this structure theorem, we classify c.n.u. contractions that are hyponormal in Theorem \ref{Hyponormal}. In the last section \ref{sec: Analyticity}, we prove that such a c.n.u contraction $T$ is analytic if and only if it has no non-zero eigenvalue.


\newsection{An Example}\label{sec: example}

We know that the unilateral shift $S$ on the Hardy space $H^2(\D)$ is a well-known example of operator whose defect spaces $\cld_S$ and $\cld_{S^*}$ are finite dimensional. In fact, $\cld_S =\{0\}$ and $\cld_{S^*}=\C1$. Clearly $D_S \subseteq \cld_{S^*}$. $S$ is a c.n.u contraction and also analytic, i.e., $\bigcap_{n\geq 0}S^n H^2(\D)=\{0\}$. However, since $S$ is an isometry, the defect space $\cld_S$ is trivial.

\medskip
We will now look at an example whose defect spaces are non trivial and finite dimensional. We will consider a rank one perturbation $T$ of the unilateral shift operator on the Hardy space defined by, $$T(1)= a_1z +a_2 z^2$$ and $$T(z^n)= z^{n+2},$$ for $n\geq 1$, where $a_1, a_2$ are both non zero and $|a_1|^2+ |a_2|^2 <1$.

The matrix representation of $T$ with respect to the orthonormal basis $\{z^n\}_{n\geq 0}$ on $H^2(\D)$ is given by,
\begin{equation}\label{eqn: T matrix}
[T] = \begin{bmatrix}
0 & 0 & 0 & 0 & \dots
\\
a_1& 0 & 0 & 0 & \dots
\\
a_2 & 0 & 0 & 0 & \ddots
\\
0 & 1 & 0 & 0 & \ddots
\\
0 & 0 & 1 & 0 & \ddots
\\
0 & 0 & 0 & 1 & \ddots
\\
\vdots & \vdots & \vdots& \vdots &\ddots
\end{bmatrix}.
\end{equation}

The matrix of $T^*$ will have the following representation:

\begin{equation}\label{eqn: T^* matrix}
[T^*] = \begin{bmatrix}
0 & \bar{a_1} & \bar{a_2} & 0 & 0 & 0 & \dots
\\
0 & 0 & 0 & 1 & 0 & 0 &\ddots
\\
0 & 0 & 0 & 0 & 1 & 0 &\ddots
\\
0 & 0 & 0 & 0 & 0 & 1 & \ddots
\\
\vdots & \vdots & \vdots &\vdots &\vdots &\ddots
\end{bmatrix}.
\end{equation}

A simple computation will show that the matrix representations of the operators $(I- T^*T)$ and $(I- TT^*)$  with respect to the same orthonormal basis are  given by

\begin{equation}\label{eqn: D_T matrix}
[I-T^*T] = \begin{bmatrix}
1-(|a_1|^2+|a_2|^2)& 0 & 0 & 0 & \dots
\\
0 & 0 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & \ddots
\\
\vdots & \vdots & \vdots&\ddots &\ddots
\end{bmatrix}.
\end{equation}

\begin{equation}\label{eqn: D_{T^*} matrix}
[I-TT^*] = \begin{bmatrix}
1 & 0 & 0 & 0 & 0 & \dots
\\
0 & 1-|a_1|^2 & -a_1\bar{a_2} & 0 & 0 & \dots
\\
0 & -\bar{a_1}a_2 & 1-|a_2|^2 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & 0 & \ddots
\\
\vdots & \vdots & \vdots & \vdots &\ddots &\ddots
\end{bmatrix}.
\end{equation}

Since, $1-(|a_1|^2+|a_2|^2)$, $(1-|a_1|^2)$ are strictly positive and $$\det\begin{pmatrix} 1 & 0 & 0\\ 0 & 1-|a_1|^2 & -a_1\bar{a_2} \\0 & -\bar{a_1}a_2 & 1-|a_2|^2 & \end{pmatrix}=1-(|a_1|^2+|a_2|^2)>0,$$ it follows that, $T^*T\leq I$ and $TT^*\leq I$. Hence $T$ is a contraction, $\cld_T= \mathbb{C}1$ and $\cld_{T^*}=\overline{span}\{ 1, z, z^2\}$. So we have, $\cld_T\subseteq\cld_{T^*}$ with $\dim\cld_T=1$ and $\dim\cld_{T^*}=3$.

We now show that, $T$ is analytic. Indeed, $T(1)=a_1z+a_2 z^2= z(a_1+a_2z)$ and $T(z^n)=z^{n+2}$ for all $n\geq 1$ imply, $T(H^2(\D))\subseteq zH^2(\D)$ and further $T^n(H^2(\D))\subseteq z^{n+2}(H^2(\D))$ for $n\geq 2$. Hence $\bigcap_{n\geq 1}T^n(H^2(\D))\subseteq\bigcap_{n\geq 1}z^n H^2(\D)=\{0\}$.

\smallskip

Every analytic contraction $T$ on a Hilbert space $\clh$ is completely nonunitary. Indeed, if $M\subseteq\clh$ is such that $T|_M$ is unitary, then $M= TM$ and hence $M \subseteq \bigcap_{n \geq 0} T^n\clh =\{0\}$. This implies that $M$ must be zero. Since $T$ in our context is analytic, it is also c.n.u.

It is also easy to see that $T$ is hyponormal. In fact, an easy computation will show that the matrix representation of $T^*T-TT^*$ with respect to the basis $\{ z^n\}_{n\geq 0}$, is given by

\begin{equation}\label{eqn: hyponormal matrix}
[T^*T-TT^*] = \begin{bmatrix}
|a_1|^2+|a_2|^2 & 0 & 0 & 0 & 0 & \dots
\\
0 & 1-|a_1|^2 & -a_1\bar{a_2} & 0 & 0 & \dots
\\
0 & -\bar{a_1}a_2 & 1-|a_2|^2 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & 0 & \ddots
\\
0 & 0 & 0 & 0 & 0 & \ddots
\\
\vdots & \vdots & \vdots & \vdots&\ddots &\ddots
\end{bmatrix}.
\end{equation}

Since $|a_1|^2+|a_2|^2> 0$ and $$\det \begin{pmatrix} |a_1|^2+|a_2|^2 & 0 & 0\\ 0 & 1-|a_2|^2 & -a_1\bar{a_2}\\0 & -\bar{a_1}a_2 & 1-|a_2|^2\end{pmatrix}=(|a_1|^2+|a_2|^2)(1-(|a_1|^2+|a_2|^2))>0,$$ $T^*T-TT^*\geq 0$ and hence $T$ is hyponormal.

For any hyponormal operator $T$, $\cld_T$ is always contained in $\cld_{T^*}$. We will soon see that the converse is not always true.

Our goal is to find the answer in a general set up. For a c.n.u contraction $T$ on a Hilbert space $H$ with $\cld_T \subseteq\cld_{T^*}$ and $\dim\cld_{T^*}<\infty$, we will give a complete characterization in the next section.

\newsection{Characterization}\label{sec:Characterization}

Let us first fix some convention. Corresponding to an orthonormal basis $\{e_m\}_{m\geq 1}$ on a Hilbert space $\clh$, and $n\in \mathbb{N}$, we will denote by $P_n$, the orthogonal projection onto the set of first $n$ vectors $\{e_1, e_2, \ldots, e_n\}$. For $k \geq 1$, $S_k$ will denote the unilateral shift of multiplicity $k$ on $\clh$ i.e.,

\begin{equation}\label{S_k}
S_k(e_m)=e_{m+k},\quad n \geq 1.
\end{equation}


In association with the same orthonormal basis $\{e_m\}_{m\geq 1}$, the unilateral shift $S_k$ and the orthogonal projection $P_n$, we define the finite rank operators $F$ and $F_r$ ( $r\in\mathbb{N}$) as follows:

\begin{equation}\label{F}
F(e_i)=
\begin{cases}
x_1^ie_1+x_2^ie_2+\cdots+(x_{i+k}^i-1)e_{i+k}+\cdots+x_{n+k}^ie_{n+k}, & \mbox{if } i\leq n \\
0, & \mbox{if } i\geq n+1,
\end{cases}
\end{equation}
for some scalars $x^i_{i+k}\in\C$,  $i\in \{1, 2,\cdots, n\}$ and $k\geq 1$.
\begin{equation}\label{F_1'}
F_1= F+ S_kP_n
\end{equation}
and
\begin{equation}\label{F_r}
F_r=
\begin{cases}
F_1 & \mbox{if } r=1
\\
F_1^r+S_k(I-P_n)F_1^{r-1}+\cdots + S_k^{r-1}(I-P_n)F_1 & \mbox{if } r\geq 2
\end{cases}
\end{equation}
\medskip

In this setting, we will prove the following proposition that will play a crucial role throughout the paper.

\begin{Proposition}\label{prop: char}
Let $\clh$ be a Hilbert space with orthonormal basis $\{e_m\}_{m\geq 1}$. Let us consider the operator $T=S_k+F$ on $\clh$, where $S_k$ and $F$ are defined and satisfying the above equations \eqref{S_k}-\eqref{F_r} with respect to $\{e_m\}_{m\geq 1}$. If $T$ is a c.n.u contraction with finite indices such that $\cld_T\subseteq\cld_{T^*}$, $\dim\cld_{T}=n$ and $\dim(\cld_{T^*}\ominus\cld_T)=k$, for some $n \geq 0$ and $ k \in \mathbb{N}$, the following conditions hold:
\begin{enumerate}
%\item $F= F_1-S_k P_n$
\item $\text{rank} (P_n-F_1^*F_1)=n$
\item $F_1(I-P_n)=(I-P_{n+k})F_1=0$
\item $\lambda\|F_1^*x\|^2-\|F_1x\|^2\leq \lambda \|P_{n+k} x\|^2-\|P_n x\|^2, \quad \forall x\in \clh$ and for some $\lambda\geq 0$
\item $\|F_rx\|\leq \|P_n x\|$ \text{and} $\|F_r^*x\|\leq \|P_{n+kr}x\|$  \text{hold for all} $r \in \mathbb{N}$ and $x\in \clh,$
\end{enumerate}
\text{ with zero as the only common solution to the corresponding equalities.}
\end{Proposition}

\begin{proof}

Let $T$ be a c.n.u contraction with finite indices such that, $\dim\cld_T=n$, $\dim(\cld_{T^*}\ominus\cld_T)=k$, and $\cld_T\subseteq\cld_{T^*}$. Let, with respect to some orthonormal basis $\{e_m\}_{m\geq 1}$ of $\clh$, we can write $T$ as $T= S_k +F$, where $S_k$ shifts the element $e_m$ to $e_{m+k}$ for all $m\geq 1$ and $F$ acts on $\{e_m\}_{m\geq 1}$ as defined in (\ref{F}) and satisfies \eqref{F_1'} and \eqref{F_r}. Then, with respect to the same orthonormal basis $\{e_m\}_{m\geq 1}$, $T$ can be represented by the following matrix:


\begin{equation}\label{eqn: T new matrix}
[T] = \begin{bmatrix}
x^1_1 & x^2_1 &\cdots &x^n_1 & 0 & 0 & 0 & \dots
\\
x^1_2 & x^2_2 &\cdots & x^n_2 & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
x^1_k & x^2_k &\cdots & x^n_k & 0 & 0 & 0 & \dots
\\
1+(x^1_{k+1}-1) & x^2_{k+2} &\cdots & x^n_{k+1} & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\dots
\\
x^1_{n+k} & x^2_{n+k} &\cdots & 1+(x^n_{n+k}-1) & 0 & 0 & 0 & \dots
\\
0 & 0 &\cdots & 0 & 1 & 0 & 0 & \dots
\\
0 & 0 &\cdots & 0 & 0 & 1 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}

As,
\begin{equation}\label{eqn: F=F_1-S_kP_n}
F=F_1-S_kP_n,
\end{equation}

\NI by the equation \eqref{F}, it readily follows,

\[F_1(e_i)=
\begin{cases}
x_1^ie_1+x_2^ie_2+\cdots+x_{i+k}^ie_{i+k}+\cdots+x_{n+k}^ie_{n+k}, & \mbox{if } i\leq n \\
0, & \mbox{if } i\geq n+1,
\end{cases}
\]
and hence,
\begin{equation}\label{eqn: F_1(I-P_n)=(I-P_{n+k})F_1=0}
F_1(I-P_n)=(I-P_{n+k})F_1=0,
\end{equation}

\NI which proves the assertion $(2)$.

\medskip

Now by equations (\ref{eqn: F=F_1-S_kP_n}), we can write $T=S_k+F$ as
\begin{equation}\label{T= F_1+ S_k(I-P_n)}
T= F_1+ S_k(I-P_n)
\end{equation}

\text{Claim:} For $r\geq 2$,
\begin{equation}\label{T^r}
T^r= F_1^r+ S_k(I-P_n)F_1^{r-1}+\cdots +S_k^{r-1}(I-P_n)F_1+S_k^r(I-P_n).
\end{equation}

\medskip

We will prove this by induction. For $r=2$,


\begin{equation*}
\begin{split}
T^2 &= [F_1+S_k(I-P_n)][F_1+ S_k(I-P_n)] \\
&= F_1^2 + F_1 S_k(I-P_n)+S_k(I-P_n)F_1+S_k(I-P_n)S_k(I-P_n) \\
&= F_1^2 +0 +S_k(I-P_n)F_1 + S_k^2(I-P_n) \\
&= F_1^2 + S_k(I-P_n)F_1 + S_k^2(I-P_n)
\end{split}
\end{equation*}

\NI Hence the claim is true for $r=2$. Let us assume that the claim is true for some $r>2$.
Then,

\begin{equation*}
\begin{split}
T^{r+1} &= T^r T  \\
&= [ F_1^r+ S_k(I-P_n)F_1^{r-1}+\cdots +S_k^{r-1}(I-P_n)F_1+S_k^r(I-P_n)][F_1+S_k(I-P_n)] \\
&= F_1^{r+1}+ S_k(I-P_n)F_1^r+\cdots+ S_k^{r-1}(I-P_n)F_1^2+ S_k ^r(I-P_n)F_1+ S_k^r(I-P_n)S_k(I-P_n) \\
&= F_1^{r+1}+ S_k(I-P_n)F_1^r+ \cdots +S_k^r(I-P_n)F_1 + S_k^{r+1}(I-P_n) \\
\end{split}
\end{equation*}
Hence, by induction, the claim follows.

\medskip

\NI Therefore by (\ref{F_r}), we can deduce from (\ref{T^r}),


\begin{equation}\label{T^r short}
T^r= F_r+ S_k^r(I-P_n) , r \geq 2.
\end{equation}

\medskip

We now compute the defect opetators of $T$. Note that,

\begin{equation*}
\begin{split}
T^*T &= \Big(F_1^*+(I-P_n)S_k^*\Big)\Big(F_1+S_k(I-P_n)\Big) \\
&= F_1^*F_1+ F_1^*S_k(I-P_n)+(I-P_n)S_k^*F_1+(I-P_n)S_k^*S_k(I-P_n) \\
& = F_1^*F_1 + 0 + 0 + (I-P_n),
\end{split}
\end{equation*}

and we have,
\begin{equation}\label{D_T=D_F_1}
I-T^*T= P_n-F_1^*F_1
\end{equation}

Since $\dim \cld_T=n$, we will have $$\text{Rank}(P_n-F_1^*F_1)=n.$$ This proves the first assertion.

\medskip

Again,
\begin{equation*}
\begin{split}
TT^* &=\Big(F_1+S_k(I-P_n)\Big)\Big(F_1^*+(I-P_n)S_k^*\Big) \\
& F_1F_1^* + F_1(I-P_n)S_k^*+S_k(I-P_n)F_1^*+S_k(I-P_n)S_k^*
\end{split}
\end{equation*}

Since by \eqref{eqn: F_1(I-P_n)=(I-P_{n+k})F_1=0}, $F_1(I-P_n)=0$, we have $(I-P_n)F_1^*=0$. Therefore

\begin{equation}\label{D_{T^*}}
TT^* = F_1F_1^* + S_k(I-P_n)S_k^*
\end{equation}

We now show that, $$I-S_k(I-P_n)S_k^*=P_{n+k}.$$

Indeed, for $1\leq m <k$, $S_k^*(e_m)=0$ and hence in this case, $\Big(I-S_k(I-P_n)S_k^*\Big)e_m= e_m$. For $k\leq m\leq n+k$, $S_k^* e_m=e_{m-k}\in \{e_1, e_2, \ldots, e_n\}$ where $e_0=0$. Therefore, $(I-P_n)S_k^*e_m=0$ and $\Big(I-S_k(I-P_n)S_k^*\Big)e_m = e_m$ for $k\leq m\leq n+k$.

Next, for $m \geq n+k+1$, $\Big(I-S_k(I-P_n)S_k^*\Big)e_m= e_m- S_k(I-P_n)e_{m-k}=e_m-S_k e_{m-k}=e_m-e_m=0$. Therefore we have,

\[\Big(I-S_k(I-P_n)S_k^*\Big)e_m=
\begin{cases}
e_m, & \mbox{if } 1\leq m \leq n+k \\
0, & \mbox{if }  m\geq n+k+1,
\end{cases}
\]
so that we can write,
\begin{equation}\label{P_{n+k}}
\Big(I-S_k(I-P_n)S_k^*\Big)e_m= P_{n+k}.
\end{equation}
The equations (\ref{D_{T^*}}) and (\ref{P_{n+k}}) together imply

\begin{equation}\label{D_T*=D_F_1^*}
I-TT^*= P_{n+k}-F_1F_1^*
\end{equation}

For $r\geq 2$, by \eqref{T^r short} we have,

\begin{equation}\label{T^*r T^r}
\begin{split}
T^{*r} T^r &= \Big(F_r^*+(I-P_n)S_k^{*r}\Big)\Big(F_r+S_k^r(I-P_n)\Big) \\
&= F_r^*F_r+F_r^*S_k^r(I-P_n)+(I-P_n)S_k^{*r}F_r+(I-P_n)S_k^{*r}S_k^r(I-P_n)
\end{split}
\end{equation}

 For $r\geq 2$, by \eqref{F_r},

\begin{equation*}
F_r^* = F_1^{*r}+F_1^{*(r-1)}(I-P_n)S_k^*+ \cdots +F_1^*(I-P_n)S_k^{*(r-1)}
\end{equation*}
and hence
\begin{equation}\label{F_rS_k}
F_r^*S_k^r(I-P_n)=F_1^{*r}S_k^r(I-P_n)+F_1^{*(r-1)}(I-P_n)S_k^{(r-1)}(I-P_n)+ \cdots + F_1^*(I-P_n)S_k(I-P_n).
\end{equation}

Since $F_1^*(e_{n+k+l})=0$ for all $l\geq 1$, we will get by (\ref{F_rS_k}), $F_r^*S_k^r(I-P_n)=0$ and hence $(I-P_n)S_k^{*r}F_r=0$. This, together with (\ref{T^*r T^r}) yields,

\begin{equation}\label{D_{T^r}}
I-T^{*r}T^r=P_n-F_r^*F_r,\quad r\geq 2.
\end{equation}

Again, for $r \geq 2$,

\begin{equation}\label{T^r T^*r}
\begin{split}
T^rT^{*r} &= \Big(F_r+ S_k^r(I-P_n)\Big)\Big(F_r^*+(I-P_n)S_k^{*r}\Big) \\
&= F_rF_r^*+ F_r(I-P_n)S_k^{*r}+S_k^r(I-P_n)F_r^*+ S_k^r(I-P_n)S_k^{*r}.
\end{split}
\end{equation}

Since $F_1(e_m)=0, \quad \forall m \geq (n+1)$,  it follows by the given equation of  $F_r$, $F_r(I-P_n)S_k^{*r}=0$  and hence  $S_k^r(I-P_n)F_r^*=0$  for  $r \geq 2$.

Again for $l\geq 1$ and $r\geq 2$, $S_k^r(I-P_n)S_k^{*r}(e_{n+kr+l})=S_k^r(e_{n+l})= e_{n+kr+l}$ and for $ 1\leq m \leq (n+kr)$, $S_k^r(I-P_n)S_k^{*r}(e_m)=0$ and hence we have for $r\geq 2$,

\[S_k^r(I-P_n)S_k^{*r}(e_m)=
\begin{cases}
e_m, & \mbox{if } m\geq n+kr+1 \\
0, & \mbox{if }   m\leq n+kr,
\end{cases}
\]
so that
\begin{equation}\label{P_{n+kr}}
S_k^r(I-P_n)S_k^{*r}=I- P_{n+kr}, \quad r\geq 2.
\end{equation}
Therefore it follows by \eqref{T^r T^*r} and \eqref{P_{n+kr}},

\begin{equation}\label{D_{T^*r}}
I- T^rT^{*r}= P_{n+kr}-F_rF_r^*, \quad r\geq 2.
\end{equation}

Combining the equations \eqref{D_T=D_F_1}, \eqref{D_{T^r}}, \eqref{D_T*=D_F_1^*} and \eqref{D_{T^*r}}, we will have for all $r\geq 1$,

\begin{equation}\label{D_Tr}
D_{T^r}^2= (I-T^{*r}T^r)=(P_n-F_r^*F_r)
\end{equation}

and

\begin{equation}\label{D_T*r}
D_{T^{*r}}^2= (I-T^rT^{*r})=(P_{n+kr}-F_rF_r^*).
\end{equation}


We now show that for all $r\geq 1$,
\begin{equation}\label{ker D_T^r}
\ker D_{T^r}=\{x \in \clh: \|F_r x\|=\|P_n x\|\}
\end{equation}

Indeed,

\begin{align*}
\begin{aligned}
& D_{T^r}x =0
\\
\iff & (P_n-F_r^*F_r)^{1/2} x =0
\\
\iff & \la(P_n-F_r^*F_r)^{1/2} x, (P_n-F_r^*F_r)^{1/2} x\ra =0
\\
\iff & \la(P_n-F_r^*F_r) x, x\ra =0
\\
\iff & \la F_r x, F_r x\ra =\la P_n x, x\ra
\\
\iff & \| F_r x\| = \|P_n x\|
\end{aligned}
\end{align*}

Similarly, it can be shown that for $r \geq 1$,

\begin{equation}\label{ker D_T^*r}
\ker D_{T^{*r}}=\{x \in \clh: \|F_r^* x\|=\|P_{n+kr}x\|\}
\end{equation}

Since $T$ is a contraction, $T^r$ is also a contraction for all $r\geq 1$. Hence $(I-T^{*r}T^r)\geq 0$ and $(I-T^r T^{*r})\geq 0$ for all $r\geq 1$.

This together with equations (\eqref{D_Tr} and \eqref{D_T*r} imply,


\begin{equation}\label{ker inq}
\begin{split}
\|F_r x\| &\leq \|P_n x\| \\
\|F_r^*x\| &\leq \|P_{n+kr}x\|
\end{split}
\end{equation}

holds for all $x\in \clh$ and all $r\geq 1$. Since $T$ is c.n.u, we will have (page 9, \cite{NF}),
\[
(\bigcap_{r\geq 1}\ker D_{T^r})\bigcap(\bigcap_{r\geq 1}\ker D_{T^{*r}})=\{0\}.
\]

Hence it follows by \eqref{ker D_T^r} and \eqref{ker D_T^*r}, that zero is the only common solution to the corresponding equalities in \eqref{ker inq}.
This settles the assertion $(4)$.
\medskip

We will now prove the assertion $(3)$.

By Douglas Lemma,
\begin{align*}
\begin{aligned}
&\cld_T \subseteq \cld_{T^*}
\\
\iff & D_T D_T^* \leq \lambda D_{T^*}D_{T^*}^*, \text{ for some } \lambda\geq 0
\\
\iff & D_T^2 \leq \lambda D_{T^*}^2
\\
\iff & I-T^*T \leq \lambda (I-TT^*)
\\
\iff & P_n- F_1^*F_1 \leq \lambda (P_{n+k}-F_1F_1^*), \text{ by \eqref{D_T=D_F_1} and \eqref{D_T*=D_F_1^*}}
\\
\iff &\lambda F_1F_1^*-F_1^*F_1 \leq \lambda P_{n+k}-P_n
\\
\iff & \lambda \|F_1^*x\|^2- \|F_1x\|^2 \leq \lambda \|P_{n+k}x\|^2-\|P_n x\|^2, \quad \forall x\in \clh.
\end{aligned}
\end{align*}


\end{proof}


We will now state and prove the following theorem. We show that, any c.n.u contraction $T$ with finite indices and $\cld_T\subseteq\cld_{T^*}$ can be written as some finite rank perturbation of unilateral shift of a finite multiplicity. It is well known that a c.n.u contraction $T$ with $\cld_T=\{0\}$ is a pure isometry and hence is a unilateral shift of some multiplicity. Such operators are always analytic and hyponormal. To avoid this case, we will assume that\textsf{ the contraction $T$ in our next theorem is not an isometry.}

\begin{Theorem}\label{thm: char}

Let $T$ be a bounded linear operator on a Hilbert space $\clh$ and $n, k \in \N$. Then $T$ is a c.n.u contraction such that $\cld_T \subseteq\cld_{T^*}$ with $\dim\cld_T=n$, $\dim\cld_{T^*}<\infty$ and $\dim (\cld_T^*\ominus\cld_T)=k$ if and only if there exists an orthonormal basis$\{e_m\}_{m\geq 1}$ with respect to which $T$ can be written as $T= S_k+F$, where $S_k$ is the unilateral shift of multiplicity $k$ and $F$ is a finite rank operator satisfying the conditions of Proposition \ref{prop: char}.
\end{Theorem}


\begin{proof}
Let $T$ be a c.n.u contraction on $\clh$ such that it's defect spaces satisfy all the conditions as stated. It is well known (page 8, \cite{NF}) that $T: \clh\ominus\cld_T\longrightarrow \clh\ominus \cld_{T^*}$ is unitary. Since $T$ is c.n.u and $\dim \cld_T$ is a non zero finite number, $\cld_T$ must be a proper subspace of $\cld_{T^*}$. Hence $T: \clh\ominus \cld_T \longrightarrow \clh\ominus \cld_T$ is an isometry. Now,
\[
(\clh\ominus\cld_T)\ominus T(\clh\ominus\cld_T)=(\clh\ominus\cld_T)\ominus (\clh\ominus \cld_{T^*})=\cld_{T^*}\ominus \cld_T
\]

\NI and $\dim(\cld_{T^*}\ominus\cld_T)=k$. We show that $T$ on $\clh\ominus\cld_T$ is a pure isometry. If possible, let $M\subseteq \clh\ominus\cld_T$ such that $T|_{\clh\ominus\cld_T}$ on $M$ is unitary and $M$ reduces $T|_{\clh\ominus\cld_T}$. Note that $M=TM$ implies $M\subseteq T(\clh\ominus\cld_T)=\cld_{T^*}^{\perp}$. This shows that $\cld_{T^*}\subseteq M^{\perp}$.

\[
M^{\perp}=H\ominus M= \cld_T \oplus \Big((\clh\ominus\cld_T)\ominus M \Big),
\]
and since $M$ reduces $T|_{\clh\ominus\cld_T}$, $T|_{\clh\ominus\cld_T}\Big((\clh\ominus\cld_T)\ominus M \Big)\subseteq (\clh\ominus\cld_T)\ominus M \subseteq M^{\perp}$ and $T(\cld_T)\subseteq \cld_{T^*}\subseteq M^{\perp}$, we will have $T(M^{\perp})\subseteq M^{\perp}$. This shows that $M$ reduces the operator $T$ and $T|_M$ is unitary. Since $T$ is completely non unitary, $M$ must be zero. Hence $T: \clh\ominus\cld_T\longrightarrow \clh\ominus\cld_T$ is a pure isometry and by Wold decomposition, can be realized as a unilateral shift of multiplicity $k=\dim(\cld_{T^*}\ominus\cld_T)$. Let us denote $T|_{\clh\ominus \cld_T}$ by $S_k'$. Since $\dim\cld_T =n < \infty$ and $T$ maps $\cld_T$ into $\cld_{T^*}$, $T|_{\cld_T}: \cld_T \longrightarrow \cld_{T^*}$ is a finite rank operator of rank at most $n$. Let us define $F_1: \clh \longrightarrow \clh$ by

\[
F_1 x=
\begin{cases}
Tx & \mbox{if } x\in\cld_T
\\
0 & \mbox{if } x\in \cld_T^{\perp}
\end{cases}
\]

Suppose, $\{e_1, e_2,\ldots, e_n\}$ and $\{e_{n+1}, e_{n+2},\ldots\}$ are the orthonormal bases of $\cld_T$ and $(\clh\ominus \cld_T)$ respectively, such that with respect to $\{e_{n+1}, e_{n+2},\ldots\}$, $T|_{\clh\ominus\cld_T}$ is $S_k'$. Clearly $\{e_m\}_{m\geq 1}$ is an orthonormal basis of $\clh$. Also, there exist scalars $x^i_j \in\C$ for $i=1, 2,\ldots n$ ; $j\geq 1$ such that, $F_1$ can be written as,

\[
F_1 (e_i)=
\begin{cases}
\sum_{j\geq 1}x^i_j e_j, & \mbox{if } i\leq n
\\
0, & \mbox{if } i\geq n+1
\end{cases}
\]

The matrix representation of $T$ with respect to this orthonormal basis $\{e_m\}_{m\geq 1}$ is given by,

\begin{equation}\label{eqn: T matrix}
[T] = \begin{bmatrix}
x^1_1 & x^2_1 &\cdots &x^n_1 & 0 & 0 & 0 & \dots
\\
x^1_2 & x^2_2 &\cdots & x^n_2 & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
x^1_{n+k} & x^2_{n+k} &\cdots &x^n_{n+k} & 0 & 0 & 0 & \dots
\\
x^1_{n+k+1} & x^2_{n+k+1} &\cdots &x^n_{n+k+1} & 1 & 0 & 0 & \dots
\\
x^1_{n+k+2} & x^2_{n+k+2} &\cdots &x^n_{n+k+2} & 0 & 1 & 0 & \dots
\\
x^1_{n+k+3} & x^2_{n+k+3} &\cdots &x^n_{n+k+3} & 0 & 0 & 1 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}

Since $T$ is a contraction, $T^*$ is also so. Hence, $\|T^*e_{n+k+l}\|\leq 1$ for all $l\geq 1$. This yields,
\[1+|x^1_{n+k+l}|^2+|x^2_{n+k+l}|^2+\cdots+|x^n_{n+k+l}|^2\leq 1.
\]

Hence $x^p_{n+k+l}=0$ for $p=1, 2, \ldots , n$ and $l\geq 1$. Now $F_1$ becomes,
\[
F_1 (e_i)=
\begin{cases}
\sum_{j= 1}^{n+k} x^i_j e_j & \mbox{if } i\leq n
\\
0 & \mbox{if } i\geq n+1
\end{cases}
\]

The matrix representation \eqref{eqn: T matrix} of $T$, with respect to the orthonormal basis $\{e_m\}_{m\geq 1}$, can be rewritten as

\begin{equation}\label{eqn: T new matrix}
[T] = \begin{bmatrix}
x^1_1 & x^2_1 &\cdots &x^n_1 & 0 & 0 & 0 & \dots
\\
x^1_2 & x^2_2 &\cdots & x^n_2 & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
x^1_k & x^2_k &\cdots & x^n_k & 0 & 0 & 0 & \dots
\\
1+(x^1_{k+1}-1) & x^2_{k+1} &\cdots & x^n_{k+1} & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\dots
\\
x^1_{n+k} & x^2_{n+k} &\cdots & 1+(x^n_{n+k}-1) & 0 & 0 & 0 & \dots
\\
0 & 0 &\cdots & 0 & 1 & 0 & 0 & \dots
\\
0 & 0 &\cdots & 0 & 0 & 1 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}


Let us define the operator $F: \clh \longrightarrow \clh$ by,

\[
F (e_i)=
\begin{cases}
x_1^ie_1+ x_2^i e_2+\cdots +(x_{i+k}^i-1)e_{i+k}+\cdots +x_{n+k}^i e_{n+k}, & \mbox{if } i\leq n
\\
0, & \mbox{if } i\geq n+1.
\end{cases}
\]

Then, with respect to $\{e_m\}_{m\geq 1}$, $T$ can be written as

\begin{equation}\label{T=S_k+F}
T=S_k+F
\end{equation}
where $S_k$ is the unilateral shift of multiplicity $k$ on $\clh$. Clearly, $F_1=F+S_kP_n$ and if for $r\geq 2$, we write $F_r$ as \eqref{F_r}, then $T=S_k+F$ will satisfy all the assertions of Proposition \ref{prop: char}. Hence $S_k$ and $F$ will satisfy all the conditions $(1)-(4)$ as stated there.


Conversely, let there exists an orthonormal basis $\{e_m\}_{m\geq 1}$ on $\clh$ such that $T$ can be written as $T= S_k+F$, where $S_k$ acts on $\{e_m\}_{m\geq 1}$ as the unilateral shift of multiplicity $k$ and $F$ is a finite rank operator satisfying the given conditions of the Proposition \ref{prop: char}. Then $S_k(e_m)=e_{m+k}$ for all $m\geq 1$ and there exist scalars $x^i_j\in\C, i=1,2,\ldots n$ and $ j= 1,2, \ldots n+k$ such that
\[
F (e_i)= (F_1-S_kP_n)(e_i)=
\begin{cases}
x_1^ie_1+ x_2^i e_2+\cdots +(x_{i+k}^i-1)e_{i+k}+\cdots +x_{n+k}^i e_{n+k}, & \mbox{if } i\leq n
\\
0, & \mbox{if } i\geq n+1,
\end{cases}
\]
where

\[
F_1 (e_i)=
\begin{cases}
x_1^ie_1+ x_2^i e_2+\cdots + x_{i+k}^i e_{i+k}+\cdots +x_{n+k}^i e_{n+k}, & \mbox{if } i\leq n
\\
0, & \mbox{if } i\geq n+1,
\end{cases}
\]
Then, with respect to $\{e_m\}_{m\geq 1}$, the matrix representation of $T$ will be,

\begin{equation}\label{eqn: T new matrix}
[T] = \begin{bmatrix}
x^1_1 & x^2_1 &\cdots &x^n_1 & 0 & 0 & 0 & \dots
\\
x^1_2 & x^2_2 &\cdots & x^n_2 & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
x^1_k & x^2_k &\cdots & x^n_k & 0 & 0 & 0 & \dots
\\
x^1_{k+1} & x^2_{k+1} &\cdots & x^n_{k+1} & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\\
x^1_{n+k} & x^2_{n+k} &\cdots & x^n_{n+k} & 0 & 0 & 0 & \dots
\\
0 & 0 &\cdots & 0 & 1 & 0 & 0 & \dots
\\
0 & 0 &\cdots & 0 & 0 & 1 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}

Now proceeding exactly in the same way as the proof of Proposition (\ref{prop: char}), it will follow by condition $(4)$, $T$ is a c.n.u contraction. The condition $(1)$ will imply that, $\dim\cld_T=n$ and the inequality in $(3)$ will say that, $\cld_T\subseteq\cld_{T^*}$. Lastly, it will follow by the condition $\|F_r^* x\|\leq \|P_{n+kr}x\|$ with $r=1$ in $(4)$ that, $\dim\cld_{T^*}\leq n+k\leq\infty$. If possible, let $\dim\cld_{T^*}< n+k$. Then $\dim (\cld_{T^*}\ominus\cld_T)= k_1< k$ for some $k_1 \in\N$. Now $T$ is a c.n.u contraction with $\cld_T\subseteq\cld_{T^*}<\infty$ such that $\dim\cld_T=n$ and $\dim (\cld_{T^*}\ominus\cld_T)= k_1$, and so it follows by first part of the theorem itself, $T= S_{k_1}+F'$, where $S_{k_1}$ is the unilateral shift of multiplicity $k_1$ and $F'$ is a finite rank operator with rank atmost $n$. Since the Fredholm index remains unchanged under finite rank perturbation, $k_1$ must be equal to $k$. This is a contradiction. Therefore $\dim (\cld_{T^*}\ominus\cld_T)$ must be $k$.
\end{proof}

\begin{Remark}
A c.n.u contraction $T$ with $\cld_T\subseteq\cld_{T^*}$ need not be hyponormal nor analytic in general. The following example will show this.
\end{Remark}

\textbf{Example:}\label{n-hyp/analytic} Let $T$ be a bounded linear operator on $H^2(\D)$ defined by, $T(1)=T(z)=\frac{1}{2}$ and $T(z^m)= z^{m+1}$ for all $m\geq 2$.
The matrix representation of $T$ with respect to the orthonormal basis $\{z^m\}_{m\geq 1}$ is given by,

\[
[T] = \begin{bmatrix}
\frac{1}{2} & \frac{1}{2} & 0  & 0 & \cdots
\\
0 & 0 & 0 & 0 & \ddots
\\
0 & 0 & 0  & 0 & \ddots
\\
0 & 0 & 1 & 0 & \ddots
\\
0 & 0 & 0 & 1 & \ddots
\\
\vdots & \ddots & \ddots & \ddots & \ddots
\end{bmatrix}
\]
An easy computation will show that

\[
[I-T^*T] = \begin{bmatrix}
\frac{3}{4} & -\frac{1}{4} & 0  & 0 & \cdots
\\
-\frac{1}{4} & \frac{3}{4} & 0 & 0 & \ddots
\\
0 & 0 & 0  & 0 & \ddots
\\
0 & 0 & 0 & 0 & \ddots
\\
\vdots & \ddots & \ddots & \ddots & \ddots
\end{bmatrix}
\]
 Since the matrix
$\begin{pmatrix}
\frac{3}{4} & -\frac{1}{4} \\
-\frac{1}{4} & \frac{3}{4}
\end{pmatrix}$  is positive definite and
$\det \begin{pmatrix}
\frac{3}{4} & -\frac{1}{4} \\
-\frac{1}{4} & \frac{3}{4}
\end{pmatrix}= \frac{1}{2}>0$, $T$ is a contraction with $\dim \cld_T= 2$ and $\cld_T= \overline{span}\{1, z\}$.

We show that, $T$ satisfies the conditions $(1)-(4)$ of Proposition \ref{prop: char}.

Note that, with resect to the orthonormal basis $\{z^m\}_{m\geq 0}$, $T$ can be written as $T= F_1+S_1(I-P_2)$, where $S_1$ is the Hardy shift on $H^2(\D)$ and $F_1(1)=F_1(z)=\frac{1}{2}$ and $F_1(z^m)=0$ for $m\geq 2$. Clearly $F_1(I-P_2)=(I-P_3)F_1=0$ and hence the condition $(2)$ of the Proposition \ref{prop: char} is satisfied. By \eqref{F_r}, it follows that,

\[ F_r=
\begin{cases}
F_1 , & \mbox{if } r=1 \\
F_1^r , & \mbox{if } r\geq 2.
\end{cases}
\]

Now, For $x= \sum_{m=0}^{\infty}x_m z^m \in H^2(\D)$, $F_r(x)= \frac{1}{2^{r}}(x_0+x_1)$ for all $r\geq 1$. By Cauchy-Schwarz inequality,
$\frac{1}{2^{2r}}|x_0+x_1|^2 \leq \frac{1}{2^{2r-1}}(|x_0|^2+|x_1|^2)$ holds for $r\geq 1$. Hence $\|F_r x\|\leq \|P_2 x\|$ holds for all $x\in H^2(\D)$ and all $r\geq 1$.

\NI Similarly it can be shown that, $\|F_r^* x\|\leq\|P_{2+r}x\|$ for all $x\in H^2(\D)$ and $r\geq 1$.

Let $x = \sum_{m=0}^{\infty}x_m z^m\in H^2(\D)$, such that $\|F_r x\|=\|P_2 x\|$ and $\|F_r^* x\|=\|P_{2+r}x\|$ hold for all $r\geq 1$. We show that $x=0$.

$\|F_r x\|=\|P_2 x\|$ for all $r\geq 1$ implies, $\frac{1}{2^{2r}}|x_0+x_1|^2= |x_0|^2+|x_1|^2$ hold for all $r\geq 1$. Since the quantity in the left hand side decreases as $r$ increases, we must have $x_0=x_1=0$. Therefore $x$ reduces to $x= \sum_{m=2}^{\infty}x_m z^m$.
Hence $\|F_r^* x\|=0$ for all $r \geq 1$. Now $\|F_r^* x\|=\|P_{2+r}x\|$ for all $r\geq 1$ implies,

\[
|x_2|^2+|x_3|^2+\cdots +|x_{1+r}|^2=0
\]

and hence $x_2=x_3=\cdots= x_{1+r}=0$, for all $r\geq 1$. This implies that $x=0$. Hence the condition $(4)$ of the Proposition \ref{prop: char} holds true.

Proceeding similarly as in the proof of Proposition \ref{prop: char}, it will follow that, $I-F_1^*F_1= I-T^*T$. Hence by above computation, $\text{rank  }(I-F_1^*F_1) =2$, and this is equivalent to satisfying condition $(1)$ of Proposition \ref{prop: char}.

Again, another simple computation will show that,

\[
[I-TT^*] = \begin{bmatrix}
\frac{1}{2} & 0 & 0  & 0 & \cdots
\\
0 & 1 & 0 & 0 & \ddots
\\
0 & 0 & 1  & 0 & \ddots
\\
0 & 0 & 0 & 0 & \ddots
\\
\vdots & \ddots & \ddots & \ddots & \ddots
\end{bmatrix}
\]

\NI and hence $\dim\cld_{T^*}=3$ and $\cld_{T^*}=\overline{span}\{1, z, z^2 \}$. Clearly $\cld_T\subseteq\cld_{T^*}$. Hence by Douglas Lemma, there exists $\lambda\geq 0$ such that, $\lambda||F_1^*x||^2-||F_1x||^2\leq \lambda||P_3 x||^2-||P_2 x||^2$ holds for all $x\in H^2(\D)$ and this is the condition $(3)$ of the Proposition \ref{prop: char}.
Hence, by the converse part of the Theorem \ref{thm: char}, it follows that, $T$ is a c.n.u. with $\cld_T\subseteq\cld_{T^*}$ such that $\dim\cld_T=2$ and $\cld_T\ominus\cld_{T^*}=1$.

We now show that $T$ is not hyponormal. An easy computation will show that the matrix representation of $T^*T-TT^*$ with respect to the orthonormal basis $\{z^m\}_{m\geq 0}$ is,

\[
[T^*T-TT^*] = \begin{bmatrix}
-\frac{1}{4} & -\frac{1}{4} & 0  & 0 & \cdots
\\
-\frac{1}{4} & \frac{1}{4} & 0 & 0 & \ddots
\\
0 & 0 & 1  & 0 & \ddots
\\
0 & 0 & 0 & 0 & \ddots
\\
\vdots & \ddots & \ddots & \ddots & \ddots.
\end{bmatrix}
\]

Since $\la (T^*T-TT^*)(1), 1\ra= \la(-\frac{1}{4}+\frac{1}{4}z), 1\ra=-\frac{1}{4}< 0$, $(T^*T-TT^*)$ is not positive definite and hence is not hyponormal. Note that, $1 \in T^m H^2(\D)$ for all $m \geq 1$. This shows that $T$ is not analytic.


We will discuss the analyticity of a c.n.u. contraction in the setting of Theorem \ref{thm: char} in the next section. Let us now discuss the hyponormality of such c.n.u contractions. Note that, if a  contraction $T$ is hyponormal, then $\cld_T \subseteq\cld_{T^*}$. We have just shown in the above example \eqref{n-hyp/analytic}, the converse is not true. However, the condition $(3)$ in Theorem \ref{thm: char} is suggestive in this direction. We will now show that, under the assumption of Theorem \ref{thm: char}, $T$ is hyponormal if and only if $\lambda =1$.

\begin{Theorem}\label{Hyponormal}
T be a c.n.u contraction on a Hilbert space $\clh$ satisfying the assertions of Theorem \ref{thm: char}. $T$ is hyponormal if and only if for all $x\in \clh$, $$\|F_1^*x\|^2-\|F_1x\|^2\leq \|P_{n+k}x\|^2-\|P_n x\|^2$$ holds, where $F_1$ is the finite rank operator associated with $T$ with respect to some orthonormal basis $\{e_m\}_{m\geq 1}$ as defined in \eqref{F_1'}.
\ref{thm: char}.
\end{Theorem}

\begin{proof}

We know that $T$ is hyponormal if and only if $T^*T-TT^*\geq 0$. By Theorem \ref{thm: char}, $T$ can be written as $T=S_k+F$  with respect to some orthonormal basis $\{e_m\}_{m\geq 1}$ where $S_k$ and $F$ will satisfy the conditions $(1)-(4)$ of Proposition \ref{prop: char}.
Now,
\begin{align*}
\begin{aligned}
& T^*T-TT^* \geq 0 \\
\iff & (I-TT^*)- (I-T^*T) \geq 0 \\
\iff & (P_{n+k}-F_1F_1^*)-(P_n-F_1^*F_1) \geq 0, (\text{ by \eqref{D_T=D_F_1}, \eqref{D_T*=D_F_1^*}})\\
\iff & F_1F_1^*- F_1^*F_1   \leq P_{n+k}-P_n \\
\iff & \|F_1^*x\|^2-\|F_1x\|^2 \leq \|P_{n+k}x\|^2-\|P_n x\|^2,\quad \forall x\in \clh.
\end{aligned}
\end{align*}
\end{proof}

We will now discuss a particular case of Theorem \ref{thm: char} in the setting of a c.n.u contraction $T$ with $\dim\cld_T=1$. Unlike the other c.n.u contractions, we will show that, such contractions are always hyponormal.


\begin{Theorem}\label{1-Hypo}
Let $T$ be a bounded linear operator on a Hilbert space $\clh$. Then $T$ is a c.n.u contraction with $\cld_T\subseteq\cld_{T*}<\infty$ such that $\dim\cld_T=1$ and $\dim\cld_{T^*}=k+1$ for some $k>0$ if and only if there exists an orthonormal basis $\{e_n\}_{n\geq 0}$ on $\clh$, with respect to which $T$ can be written as $T=S_k+F$, where $S_k$ acts on $\{e_n\}_{n\geq 0}$ as the unilateral shift of multiplicity $k$ and $F$ is an operator of rank at most one defined by, $F(e_0)=\alpha_0e_0+\alpha_1e_1+\cdots+(\alpha_k-1)e_k$ with $(\sum_{i=0}^{k}|\alpha_i|^2)<1$ and $F(e_n)=0$ for all $n\geq 1$.
\end{Theorem}

\begin{proof}

Let $T$ be a c.n.u contraction on $\clh$ with $\cld_T\subseteq\cld_{T*}<\infty$ such that $\dim\cld_T=1$ and $\dim\cld_{T^*}=k+1$ for some $k> 0$. By Theorem \ref{thm: char}, there exists an orthonormal basis $\{e_n\}_{n\geq 0}$ such that, $T$ can be written as,
$T=S_k+F$ where $S_k(e_n)=e_{n+k}$ for all $n\geq 0$ and $F=F_1-S_kP_1$ where $F_1(e_0)=\alpha_0e_0+\alpha_1e_1+\cdots+\alpha_ke_k$ for some scalars $\alpha_i\in\C$ for $i=0, 1,2,\ldots, k$  and $F_1(e_n)=0$ for all $n\geq 1$. Also, $F_1$ satisfies the conditions $(1)-(4)$ of Theorem \ref{thm: char}. Following the lines of proof of Proposition \ref{prop: char}, By condition $(4)$ of the Theorem \ref{thm: char}, with $x=e_0$ we get, $\|F_1 e_0\|\leq \|P_1e_0\|$ and this yields,
\begin{equation}\label{dim D_T=1}
|\alpha_0|^2+ |\alpha_1|^2 + \cdots + |\alpha_k|^2 \leq 1
\end{equation}
We will show that the strict inequality holds in \eqref{dim D_T=1}. Note that, the matrix representation of $T$ with respect to the orthonormal basis $\{e_n\}_{n\geq 0}$ is given by,

\begin{equation}\label{eqn: T (1) matrix}
[T] = \begin{bmatrix}
\alpha_0 &  0 & 0 &  \dots
\\
\alpha_1 & 0 & 0 & \dots
\\
\vdots & \vdots & \vdots & \dots
\\
\alpha_k & 0 & 0 & \dots
\\
0 & 1 & 0 & \dots
\\
0 & 0 & 1 & \ddots
\\
\vdots & \vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}

An easy computation will show that the matrix representation of $I-T^*T$ with respect to the orthonormal basis $\{e_n\}_{n\geq 0}$ is,

\begin{equation}\label{eqn: D_T (1) matrix}
[I-T^*T] = \begin{bmatrix}
1-(\sum_{i=0}^{k}|\alpha_i|^2) &  0 & 0 &  \dots
\\
0 & 0 & 0 & \dots
\\
0 & 0 & 0 & \dots
\\
\vdots & \vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}

Since $\dim \cld_T=1$, we must have $\sum_{i=0}^{k}|\alpha_i|^2< 1$.

For the converse part, let there exists an orthonormal basis $\{e_n\}_{n\geq 0}$, with respect to the orthonormal basis which $T$ can be written as $T= S_k+F$ where $F$ is as given in the statement. Then with respect to $\{e_n\}_{n\geq 0}$, $T$ can be represented as

\begin{equation}\label{eqn: T (2) matrix}
[T] = \begin{bmatrix}
\alpha_0 &  0 & 0 &  \dots
\\
\alpha_1 & 0 & 0 & \dots
\\
\vdots & \vdots & \vdots & \dots
\\
\alpha_k & 0 & 0 & \dots
\\
0 & 1 & 0 & \dots
\\
0 & 0 & 1 & \ddots
\\
\vdots & \vdots & \vdots &\ddots
\end{bmatrix}.
\end{equation}

A similar computation to get the operator $(I-T^*T)$, as done in the first part, together with $\sum_{i=0}^{k}|\alpha_i|^2< 1$ would imply, $T$ is contraction with $\dim\cld_T=1$. By \eqref{eqn: T (2) matrix}, we can write $T$ as $T= F_1+ S_k(I-P_1)$, where $F_1(e_0)= \alpha_0 e_0+\alpha_1 e_1+\cdots +\alpha_k e_k$ and $F_1(e_n)=0$ for all $n\geq 1$. We show that $F$ and $F_1$ will satisfy the conditions $(1)-(4)$ of the Proposition \ref{prop: char}. Clearly $F= F_1-S_kP_1$ and $F_1(I-P_1)=(I-P_{1+k})F_1=0$. Since $I-T^*T= P_1-F_1^*F_1$, we will have, $\text{rank}(P_1-F_1^*F_1)=1$. We now show that the inequality $(3)$ in Proposition \ref{prop: char} holds for $\lambda =1$.

Let $x=x_0e_0 + x_1e_1 + x_2e_2 + \cdots \in\clh$ be arbitrary. Then
\[
\|F_1^*x\|^2=\|(x_0\bar{\alpha_0}+x_1\bar{\alpha_1}+ \cdots + x_k\bar{\alpha_k})e_0\|^2= |x_0\bar{\alpha_0}+x_1\bar{\alpha_1}+ \cdots + x_k\bar{\alpha_k}|^2
\]
and
\[
\|F_1x\|^2= \|x_0(\alpha_0e_0+\alpha_1e_1+\cdots + \alpha_k e_k)\|^2=|x_0|^2(|\alpha_0|^2+|\alpha_1|^2+ \cdots + |\alpha_k|^2).
\]
Therefore,
\begin{equation}\label{F_1*-F_1}
\|F_1^*x\|^2-\|F_1 x\|^2= |x_0\bar{\alpha_0}+x_1\bar{\alpha_1}+ \cdots + x_k\bar{\alpha_k}|^2- |x_0|^2 (|\alpha_0|^2+|\alpha_1|^2+ \cdots + |\alpha_k|^2)
\end{equation}

By Cauchy-Schwarz inequality,

\[
|x_0\bar{\alpha_0}+x_1\bar{\alpha_1}+ \cdots + x_k\bar{\alpha_k}|^2\leq (|x_0|^2+|x_1|^2+\cdots + |x_k|^2)(|\alpha_0|^2+|\alpha_1|^2+\cdots + |\alpha_k|^2)
\]
and hence by \eqref{F_1*-F_1},

\[
\|F_1^*x\|^2-\|F_1 x\|^2 \leq (|x_1|^2+|x_2|^2+\cdots+|x_k|^2)(|\alpha_0|^2+|\alpha_1|^2+\cdots+ |\alpha_k|^2)< |x_1|^2+|x_2|^2+\cdots+|x_k|^2,
\]
where the second inequality follows by $\sum_{i=0}^{k}|\alpha_i|^2 <1$.  Since $|x_1|^2+|x_2|^2+\cdots+|x_k|^2= \|P_{1+k}x\|^2-\|P_1x\|^2$, we will have,
\begin{equation}\label{F_1hyp }
\|F_1^*x\|^2-\|F_1 x\|^2 \leq \|P_{1+k}x\|^2-\|P_1x\|^2,\quad \forall x\in \clh.
\end{equation}

If we write

\[
F_r=
\begin{cases}
F_1, & \mbox{if } r=1 \\
F_1^r+S_k(I-P_1)F_1^{r-1}+\cdots+S_k^{r-1}(I-P_1)F_1, & \mbox{if } r\geq 2,
\end{cases}
\]
then proceeding exactly in the same way as in Proposition \ref{prop: char}, we will get for all $r\geq 1$, $I-T^{*r}T^r= P_1-F_r^*F_r$ and $I-T^rT^{*r}=P_{1+kr}-F_rF_r^*$. Since $T$ is a contraction, $T^r$ are also contractions for all $r\geq 2$. Hence for all $x\in \clh$ and all $r\geq 1$,
\begin{equation}\label{F_1}
\|F_rx\|\leq \|P_1 x\|,
\end{equation}
and
\begin{equation}\label{F_1*}
\|F_r^* x\|\leq \|P_{1+kr}x\|.
\end{equation}
We now show that zero is the only common solution to the corresponding equalities in \eqref{F_1} and \eqref{F_1*}.

Let $x= x_0e_0+x_1e_1+\cdots + x_ne_n+\cdots \in \clh$ such that $\|F_rx\|=\|P_1x\|$ and $\|F_r^*x\|=\|P_{1+kr}x\|$ hold for all $r\geq 1$.
Now,

\begin{align*}
\begin{aligned}
& \|F_1x\| = \|P_1x\| \\
\iff & \|x_0(\alpha_0e_0+\alpha_1e_1+\cdots+\alpha_ke_k)\|^2 = |x_0|^2 \\
\iff & |x_0|^2(|\alpha_0|^2+|\alpha_1|^2+\cdots+|\alpha_k|^2)=|x_0|^2.
\end{aligned}
\end{align*}
Since $(|\alpha_0|^2+|\alpha_1|^2+\cdots+|\alpha_k|^2)<1$, $x_0$ must be zero. Hence $x$ becomes $x= x_1e_1+x_2e_2+\cdots + x_ne_n+\cdots$.

Again,
\begin{align*}
\begin{aligned}
& \|F_1^* x\| = \|P_{1+k}x\| \\
\iff &\|(x_1\bar{\alpha_1}+x_2\bar{\alpha_2}+\cdots+x_k\bar{\alpha_k}) e_0\|^2 = \|x_1e_1+x_2e_2+\cdots + x_ke_k\|^2  \\
\iff & |x_1\bar{\alpha_1}+x_2\bar{\alpha_2}+\cdots+x_k\bar{\alpha_k}|^2 = |x_1|^2+|x_2|^2+\cdots+|x_k|^2
\end{aligned}
\end{align*}

By Cauchy-Schwarz inequality,
\[
|x_1\bar{\alpha_1}+x_2\bar{\alpha_2}+\cdots+x_k\bar{\alpha_k}|^2 \leq (|x_1|^2+|x_2|^2+\cdots+|x_k|^2)(|\alpha_1|^2+|\alpha_2|^2+\cdots+|\alpha_k|^2)
\]

Since $\sum_{i=0}^{k}|\alpha_i|^2< 1$, we will have, $x_1=x_2=\cdots=x_k=0$. Therefore $x$ becomes,
$$x=x_{k+1}e_{k+1}+x_{k+2}e_{k+2}+\cdots+ x_n e_n+\cdots.$$
Now, for $r=2$, $F_2 = F_1^2+ S_k(I-P_1)F_1$. Now proceeding exactly in the similar way, the equation $\|F_2^*x\|=\|P_{1+2k}x\|$ will imply,
$x_{k+1}=x_{k+2}=\cdots= x_{2k}=0$.

\medskip

Let $r\geq 2$. We show that, $x_0=x_1=\cdots= x_{rk}=0$ implies  $$x_{rk+1}=x_{rk+2}=\cdots=x_{(r+1)k}=0.$$

Let $x_0=x_1=\ldots x_{rk}=0$. Then $x= x_{rk+1}e_{rk+1}+x_{rk+2}e_{rk+2}+\cdots$.

Recall, for $r\geq 2$ it follows from \eqref{F_r},
\[
F_{r+1}^*= F_1^{*(r+1)}+F_1^{*r}(I-P_1)S_k^*+\cdots+ F_1^{*2}(I-P_1)S_k^{*(r-1)}+F_1^*(I-P_1)S_k^{*r}.
\]
For $1\leq p\leq r-1$,
\begin{equation}\label{F_1*(I-P_1)}
\begin{split}
F_1^*(I-P_1)S_k^{*p}(x)&= F_1^*(I-P_1)S_k^{*p}(x_{rk+1}e_{rk+1}+x_{rk+2}e_{rk+2}+\cdots)\\
&= F_1^*(I-P_1)(x_{rk+1}e_{rk+1-pk}+x_{rk+2}e_{rk+2-pk}+\cdots)
\end{split}
\end{equation}

Note that,
\begin{align*}
\begin{aligned}
& p  \leq r-1 \\
& pk  \leq rk-k \quad (\text{as}\quad k\geq 1)\\
& k  \leq rk-pk\\
& rk-pk+l  \geq k+l\geq k+1 \quad (\text{ for all }\geq 1),
\end{aligned}
\end{align*}
and this implies, $F_1^*(e_{rk+l-pk})=0$ for all $l \geq 1$ and hence by (\ref{F_1*(I-P_1)}),
\[
F_1^*(I-P_1)(x_{rk+1}e_{rk+1-pk}+x_{rk+2}e_{rk+2-pk}+\cdots)=0
\]
and this further implies, $F_1^{*(r-p+1)}(I-P_1)S_k^{*p}x=0$ for $1\leq p\leq (r-1)$ and we get,
\[
F_{r+1}^*x= F_1^*(I-P_1)S_k^{*r}(x).
\]
Therefore,
\[
\begin{split}
F_{r+1}^*x &= F_1^*(I-P_1)S_k^{*r}(x_{rk+1}e_{rk+1}+ x_{rk+2}e_{rk+2}+ \cdots+ x_{(r+1)k}e_{rk+k}+x_{(r+1)k+1}e_{(r+1)k+1}+\cdots)
\\
 &= F_1^*(I-P_1)(x_{rk+1}e_1+ x_{rk+2}e_2+ \cdots+ x_{(r+1)k}e_k+ x_{(r+1)k+1}e_{k+1}+\cdots)
\\
&= (x_{rk+1}\bar{\alpha_1}+ x_{rk+2}\bar{\alpha_2}+ \cdots+ x_{(r+1)k}\bar{\alpha_k})e_0,
\end{split}
\]
and $\|F_{r+1}^*x\|=\|P_{(r+1)k+1}x\|$ implies,
\[
|x_{rk+1}\bar{\alpha_1}+x_{rk+2}\bar{\alpha_2}+\cdots+ x_{(r+1)k}\bar{\alpha_k}|^2 = |x_{rk+1}|^2+|x_{rk+2}|^2+\cdots+ |x_{(r+1)k}|^2.
\]

\NI Again, by Cauchy-Schwarz inequality and $\sum_{i=0}^{k}|\alpha_i|^2<1$, we will get $x_{rk+1}=x_{rk+2}=\ldots= x_{(r+1)k}=0$. Hence by induction, it follows that $x_m=0$ for all $m\geq 0$ and we get $x=0$. This shows that, the condition $(4)$ of Proposition \ref{prop: char} is satisfied.
Therefore, by the converse part of Theorem \ref{thm: char}, $T$ is a c.n.u contraction with $\cld_T\subseteq\cld_{T^*}<\infty$ such that $\dim\cld_T=1$ and $\dim\cld_{T^*}=k+1$.
\end{proof}

\begin{Corollary}\label{D_T=1}
If $T$ is a c.n.u contraction on a Hilbert space $\clh$ with finite dimensional defect spaces such that $\cld_T \subseteq\cld_{T^*}$ and $\dim\cld_T=1$, then $T$ is hyponormal.
\end{Corollary}
\begin{proof}
The proof is a direct consequence of Theorem \ref{Hyponormal}, Theorem \eqref{1-Hypo} and the inequality \eqref{F_1hyp }.
\end{proof}

Note that, if $\alpha_0=0$ in Theorem \ref{1-Hypo}, then $T$ is analytic. Indeed, $\alpha_0=0$ implies, $T\clh \subseteq \overline{span}\{e_1, e_2, e_3, \ldots,\}$ so that for $n\geq 1$, $T^{n+1}\clh \subseteq \{e_{nk+1}, e_{nk+2},\ldots\}$ and hence $\bigcap_{m\geq 1}T^m \clh=\{0\}$. However if $\alpha_0 \neq 0$, $T$ need not be analytic. For example, if $\alpha_1=\alpha_2=\cdots=\alpha_k=0$, then $\alpha_0$ is an eigen value of $T$ corresponding to the eigen vector $e_0$. Hence $\{e_0\} \in \bigcap_{m\geq 1} T^m \clh$.
In the next section, we will discuss when such operators are analytic in a more general setting.

\newsection{Analyticity}\label{sec: Analyticity}

In this section we will give the criteria for analyticity of a c.n.u contraction $T$ on $\clh$ with finite indices such that $\cld_T\subseteq\cld_{T^*}$. We assume that $\dim\cld_T=n+1$ and $\dim(\cld_{T^*}\ominus\cld_T)=k$, where $n\geq 0$ and $k\geq 1$. By Theorem \ref{thm: char}, there exists an orthonormal basis $\{e_m\}_{m\geq 0}$ on $\clh$ with respect to which the matrix representation of $T$ is given by,

\begin{equation}\label{eqn: T Analytic matrix}
[T] = \begin{bmatrix}
a_{00}& a_{01} & a_{02} &\cdots & a_{0n}& 0 & 0 & \dots
\\
a_{10}& a_{11} & a_{12} &\cdots & a_{1n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
a_{n0}& a_{n1} & a_{n2} &\cdots & a_{nn} & 0 & 0 & \dots
\\
a_{n+1,0}& a_{n+1,1} & a_{n+1,2} &\cdots & a_{n+1,n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
a_{n+k,0}& a_{n+k,1} & a_{n+k,2} &\cdots & a_{n+k,n} & 0 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 1 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 0 & 1 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\end{bmatrix}
\end{equation}
for some suitable scalars $a_{ij}$, $i= 0,1,2,\ldots, n+k$ and $j= 0,1,2,\ldots, n$.

Via the canonical unitary map $U: \clh\longrightarrow H^2(\D)$, defined by $U(e_m)=z^m, m\geq 0$, $T$ can be viewed as an operator on the Hardy space $H^2(\D)$ having the same matrix representation \eqref{eqn: T Analytic matrix} with respect to $\{z^m\}_{m\geq 0}$.

Let us consider the finite rank operators $A$ and $B$ on $H^2(\D)$ whose matrix representations with respect to $\{z^m\}_{m\geq 0}$ are given by,

\begin{equation}\label{eqn: A Analytic matrix}
[A] = \begin{bmatrix}
a_{00}& a_{01} & a_{02} &\cdots & a_{0n}& 0 & 0 & \dots
\\
a_{10}& a_{11} & a_{12} &\cdots & a_{1n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
a_{n0}& a_{n1} & a_{n2} &\cdots & a_{nn} & 0 & 0 & \dots
\\
0 & 0 & 0 &\cdots & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots & \ddots
\end{bmatrix}
\end{equation}
and

\begin{equation}\label{eqn: B Analytic matrix}
[B] = \begin{bmatrix}
0 & 0 & 0 &\cdots & 0 & 0 & 0 & \dots
\\
0 & 0 & 0 &\cdots & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
0 & 0 & 0 &\cdots & 0 & 0 & 0 & \dots
\\
a_{n+1,0}& a_{n+1,1} & a_{n+1,2} &\cdots & a_{n+1,n} & 0 & 0 & \dots
\\
a_{n+2,0}& a_{n+2,1} & a_{n+2,2} &\cdots & a_{n+2,n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
a_{n+k,0}& a_{n+k,1} & a_{n+k,2} &\cdots & a_{n+k,n} & 0 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 0 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \vdots &\ddots
\end{bmatrix}
\end{equation}
respectively. Then $T$ can be written as $$T=A+B+S_k(I-P_{n+1}),$$ where $S_k$ is the unilateral shift of multiplicity $k$ on $H^2(\D)$
and $P_{n+1}$ is the orthogonal projection onto the space $\overline{span}\{1, z, z^2,\cdots, z^n\}$.
We will show that, for $r\geq 2$,
\begin{equation}\label{T^r=A+B}
T^r= A^r+BA^{r-1}+S_k B A^{r-2}+S_k^2 B A^{r-3}+\cdots+ S_k^{r-2}B A+ S_k^{r-1}B + S_k^r(I-P_{n+1}).
\end{equation}

We will prove by induction. For $r=2$,
\begin{equation*}
\begin{split}
T^2 &= [A+B+S_k(I-P_{n+1})][A+B+S_k(I-P_{n+1})]\\
&= A^2+AB+AS_k(I-P_{n+1})+BA+B^2+BS_k(I-P_{n+1})+S_k(I-P_{n+1})A\\
& +S_k(I-P_{n+1})B+S_k(I-P_{n+1})S_k(I-P_{n+1})
\end{split}
\end{equation*}
\medskip
Since the operators $AB,  AS_k(I-P_{n+1}),  B^2,  BS_k(I-P_{n+1}),  S_k(I-P_{n+1})A$ are all zero and $S_k(I-P_{n+1})S_k(I-P_{n+1})=S_k^2(I-P_{n+1})$ and $S_k(I-P_{n+1})B=S_k B$, we have
\[
T^2= A^2 + BA + S_k B+S_k^2(I-P_{n+1}),
\]
so that the equality in \eqref{T^r=A+B} holds for $r=2$.
\medskip

Let the equality hold for some $r\geq 3$. Then,

\[
\begin{split}
T^{r+1}&= T^r T \\
&= [A^r+BA^{r-1}+S_k B A^{r-2}+S_k^2 B A^{r-3}+\cdots+ S_k^{r-2}B A + S_k^{r-1}B + S_k^r(I-P_{n+1})] \\
&  [A+B+S_k(I-P_{n+1})] \\
&= A^{r+1}+BA^r+S_k BA^{r-1}+S_k^2BA^{r-2}+\cdots+ S_k^{r-2}BA^2+S_k^{r-1}BA\\
&  +S_k^r(I-P_{n+1})B+S_k^{r+1}(I-P_{n+1})  \\
&= A^{r+1}+BA^r+S_k BA^{r-1}+ S_k^2BA^{r-2}+\cdots + S_k^{r-1}BA+S_k^r B+ S_k^{r+1}(I-P_{n+1}) \\
\end{split}
\]
Hence by induction, the equality \eqref{T^r=A+B} holds for all $r\geq 2$.
\medskip

\textsf{First we discuss the case when $A$ is nilpotent.} Then $A^{n+1}=0$ and hence, $T^{n+1}H^2(\D)\subseteq \{e_{n+1}, e_{n+2},\ldots\}$, which further implies,
\[
T^{n+l+1}H^2(\D)\subseteq \{e_{n+kl+1}, e_{n+kl+2},\ldots\},\quad \forall l\geq 1.
\]
Therefore we have,
\[
\bigcap_{l\geq 1}T^{n+l+1}H^2(\D)\subseteq \bigcap_{l\geq 1}\{e_{n+kl+1}, e_{n+kl+2},\ldots\}=\{0\}
\]
and hence $\bigcap_{m\geq 1}T^m H^2(\D)=\{0\}$. Therefore, \textsf{if $A$ is nilpotent, $T$ is analytic.}


\medskip

\NI Note that, with respect to $\{z^m\}_{m\geq 0}$, $A$ can be written as, $ A=\begin{pmatrix}A_1 & 0  \\0 & 0\end{pmatrix}$ where $A_1(z^m)=\sum_{i=0}^{n}a_{im}z^i$, for $0\leq m\leq n$. Clearly,

\begin{enumerate}
\item $A$ is nilpotent if and only if $A_1$ is nilpotent.
\item $A$ has a non-zero eigenvalue if and only if $A_1$ has a non-zero eigenvalue.
\end{enumerate}

\NI Now \textsf{suppose, $A$ is not nilpotent. This is equivalent to saying that $A_1$ is not nilpotent. We will consider the cases when $B=0$ and $B\neq 0$, separately.}
\medskip

\textsf{Suppose $B=0$.} Then there exists $\lambda(\neq 0)\in\C$ and $h=(h_i)_{i=0}^n (\neq 0)\in\C^{n+1}$ such that $A_1h=\lambda h$. Now if we consider the sequence $h'=(h_0, h_1, \ldots, h_n, 0,0,\ldots)$, then it is easy to see that $Th'=\lambda h'$. Since $h'\in T^m H^2(\D)$ for all $m\geq 1$, \textsf{$T$ is not analytic.}

\medskip

\textsf{Let us now suppose that $B$ is non-zero.} Let $\lambda (\neq 0)\in\C$ be an eigenvalue of $T$. Then there exists a non-zero vector $h=\sum_{m=0}^{\infty}h_m z^m \in H^2(\D)$ such that $Th=\lambda h$. This yields,
\[
%\begin{equation}\label{eqn: T eigenvalue}
\begin{bmatrix}
a_{00}& a_{01} & a_{02} &\cdots & a_{0n}& 0 & 0 & \dots
\\
a_{10}& a_{11} & a_{12} &\cdots & a_{1n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
a_{n0}& a_{n1} & a_{n2} &\cdots & a_{nn} & 0 & 0 & \dots
\\
a_{n+1,0}& a_{n+1,1} & a_{n+1,2} &\cdots & a_{n+1,n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
a_{n+k,0}& a_{n+k,1} & a_{n+k,2} &\cdots & a_{n+k,n} & 0 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 1 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 0 & 1 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \ddots
\end{bmatrix}
\begin{bmatrix}
h_0 \\
h_1\\
\vdots\\
h_n \\
h_{n+1} \\
h_{n+2}\\
\vdots\\
h_{n+k}\\
h_{n+k+1} \\
h_{n+k+2}\\
\vdots
\end{bmatrix}
=
\lambda
\begin{bmatrix}
h_0 \\
h_1\\
\vdots\\
h_n \\
h_{n+1} \\
h_{n+2}\\
\vdots\\
h_{n+k}\\
h_{n+k+1} \\
h_{n+k+2}\\
\vdots
\end{bmatrix}
%\end{equation}
\]

and we further have,
\begin{equation}\label{T eigenvalue}
\begin{bmatrix}
a_{00}h_0+a_{01}h_1+a_{02}h_2+\cdots+ a_{0n}h_n \\
a_{10}h_0+a_{11}h_1+a_{12}h_2+\cdots+ a_{1n}h_n\\
\vdots\\
a_{n0}h_0+a_{n1}h_1+a_{n2}h_2+\cdots+ a_{nn}h_n \\
a_{n+1,0}h_0+a_{n+1,1}h_1+a_{n+1,2}h_2+\cdots+ a_{n+1,n}h_n \\
a_{n+2,0}h_0+a_{n+2,1}h_1+a_{n+2,2}h_2+\cdots+ a_{n+2,n}h_n \\
\vdots\\
a_{n+k,0}h_0+a_{n+k,1}h_1+a_{n+k,2}h_2+\cdots+ a_{n+k,n}h_n \\
h_{n+1} \\
h_{n+2}\\
\vdots\\
h_{n+k}\\
h_{n+k+1}\\
h_{n+k+2}\\
\vdots\\
h_{n+2k}\\
\vdots
\end{bmatrix}
=\lambda
\begin{bmatrix}
h_0 \\
h_1\\
\vdots\\
h_n \\
h_{n+1} \\
h_{n+2}\\
\vdots\\
h_{n+k}\\
h_{n+k+1} \\
h_{n+k+2}\\
\vdots\\
h_{n+2k}\\
h_{n+2k+1}\\
h_{n+2k+2}\\
\vdots\\
h_{n+3k}\\
\vdots
\end{bmatrix}
\end{equation}
From the above expression, it will follow by successive iteration, for $p\geq 0$ and $l= 1,2,\ldots k$,
\begin{equation}\label{eqn: h iterates}
h_{n+pk+l}=\frac{h_{n+l}}{\lambda^p}
\end{equation}
Suppose $h_m=0$ for all $m=0,1,2,\ldots, n$. Since $\lambda \neq 0$, it follows by \eqref{T eigenvalue}, $h_{n+l}=0$ for all $l= 1,2, \ldots k$. Now by \eqref{eqn: h iterates}, $h_{n+pk+l}=0$ for all $l= 1, 2, \ldots, k$ and $p\geq 1$ and hence, $h=0$. this contradicts the fact that $h$ is an eigenvector. Therefore $h_m$ must be non-zero for at least one $m\in \{0, 1, 2, \ldots,n\}$.

From equation \eqref{T eigenvalue}, we will have

\[
A_1\begin{bmatrix}
h_0 \\
h_1 \\
\vdots\\
h_n
\end{bmatrix}
=
\lambda \begin{bmatrix}
h_0 \\
h_1 \\
\vdots\\
h_n
\end{bmatrix},
\]
i.e., $\lambda(\neq 0)$ is also an eigenvalue of $A_1$.
\medskip
We now show that,

\begin{equation}\label{B eigen vector}
a_{n+l,0}h_0+a_{n+l,1}h_1+a_{n+l,2}h_2+\cdots +a_{n+l,n}h_n=0, \text{ for all } l= 1,2,\ldots k.
\end{equation}

If possible, let there exists $l\in \{1,2,\ldots, k\}$, such that the L.H.S of \eqref{B eigen vector} is non-zero. For the sake of definiteness, let us assume that, this non-zero quantity corresponds to $l=1$. This will imply by \eqref{T eigenvalue}, $h_{n+1}\neq 0$ and by \eqref{eqn: h iterates}, $h_{n+pk+1}$ are non-zero for all $p\geq 0$. Since $h\in H^2(\D)$, the sequence $h_{n+1}(1,\frac{1}{\lambda}, \frac{1}{\lambda^2}, \ldots)$ is square summable. But this is a contradiction as $0<|\lambda|\leq \|T\|\leq 1$.

Conversely, if $\lambda (\neq 0)$ is an eigenvalue of $A_1$ and there exists an eigenvector $(h_0, h_1,\cdots, h_n)$ corresponding to $\lambda$ of $A_1$ such that $\sum_{i=0}^{n}a_{n+l,i}h_i=0$ for all $l= 1, 2,\ldots , k$, then by \eqref{T eigenvalue}, we will have $Th=\lambda h$ for $h=(h_0, h_1, h_2,\ldots, h_n, 0, 0, \ldots)$, i.e., $\lambda (\neq 0)$ is also an eigenvalue of $T$.
Formally, we have the following Lemma:

\begin{Lemma}\label{B-eigen vector}
Let $T$ be a c.n.u contraction on a Hilbert space $\clh$ such that $\cld_T\subseteq\cld_{T^*}$ with $\dim\cld_{T^*}<\infty$. Let $\dim\cld_T=n+1$ and $\dim(\cld_{T^*}\ominus\cld_T)=k$ for some $n\geq 0$ and  $k\geq 1$. Assume that, $T$ can be represented as \eqref{eqn: T Analytic matrix} with respect to some orthonormal basis $\{e_n\}_{n\geq 0}$ on $\clh$. Then, $T$ has no non-zero eigenvalue if and only if for every eigenvector $(h_0, h_1, \ldots, h_n)$ corresponding to any non-zero eigenvalue of the sub-matrix

\[
\begin{bmatrix}
a_{00}& a_{01} & a_{02} &\cdots & a_{0n}
\\
a_{10}& a_{11} & a_{12} &\cdots & a_{1n}
\\
\vdots & \vdots & \cdots & \vdots & \vdots
\\
a_{n0}& a_{n1} & a_{n2} &\cdots & a_{nn}
\end{bmatrix},
\]

there exists at least one $l\in \{1, 2, \ldots, k\}$, such that, $(\sum_{r=0}^{n}a_{n+l,r}h_r)\neq 0$.
\end{Lemma}

\begin{Corollary}\label{Non-contractive}
Let $T$ be a bounded linear operator on a Hilbert space $\clh$ with matrix representation \eqref{eqn: T Analytic matrix} of which only the submatrix \eqref{eqn: A Analytic matrix} is a contraction. Then the Lemma \ref{B-eigen vector} will hold as good for any such operator $T$.
\end{Corollary}
\begin{proof}
The discussion prior to Lemma \ref{B-eigen vector}, will remain same if we just consider the sub matrix $A_1$ of $T$ to be a contraction.
\end{proof}

We will now come to the main theorem of this section.

\begin{Theorem}\label{Analytic}
Let $T$  be a bounded linear operator on $H^2(\D)$ with matrix representation \eqref{eqn: T Analytic matrix} with respect to the basis $\{z^m\}_{m\geq 0}$. Let the sub matrix
\[A_1=
\begin{bmatrix}
a_{00}& a_{01} & a_{02} &\cdots & a_{0n}
\\
a_{10}& a_{11} & a_{12} &\cdots & a_{1n}
\\
\vdots & \vdots & \cdots & \vdots & \vdots
\\
a_{n0}& a_{n1} & a_{n2} &\cdots & a_{nn}
\end{bmatrix}
\]
of $T$ be a contraction. T is analytic if and only if $T$ has no non-zero eigenvalue.
\end{Theorem}

\begin{proof}
Let $T$ be analytic. If possible let $\lambda (\neq 0)\in\C$ be a eigenvalue of $T$. Then there exists $h(\neq 0)\in H^2(\D)$ such that $T^m h=\lambda^m h$ for all $m\geq 1$ and $h\in \bigcap_{m\geq 1}T^m H^2(\D)$, which is a contradiction.

Conversely, let $T$ have no non-zero eigenvalue. (Lemma \ref{B-eigen vector} ensures that such thing can actually happen). Two cases can arise:
\begin{enumerate}
\item $A_1$ is nilpotent.
\item $A_1$ has non-zero eigenvalues.
\end{enumerate}

\textbf{Case 1:} Let $A_1$ be nilpotent. Then, as we have seen earlier, $T$ is analytic.

\textbf{Case 2:} Let $A_1$ have non-zero eigenvalues. Since $A_1 \in M_{n+1}(\C)$ is a finite matrix, by Schur decomposition and standard theory of matrix (\cite{HJ}, \cite{HK}), $A_1$ is similar to a lower triangular matrix with its eigenvalue $\lambda_0, \lambda_1,\ldots, \lambda_n$ on the main diagonal. Let there exist scalars $b_{ij}, b_{ij}', c_{ij}$ for $i,j = 0,1, 2,\ldots n$ such that

\[W=
\begin{bmatrix}
b_{00}& b_{01} & b_{02} &\cdots & b_{0n}
\\
b_{10}& b_{11} & b_{12} &\cdots & b_{1n}
\\
\vdots & \vdots & \cdots & \vdots & \vdots
\\
b_{n0}& b_{n1} & b_{n2} &\cdots & b_{nn}
\end{bmatrix}\in GL_{n+1}(\C),
\medskip
W^{-1}=
\begin{bmatrix}
b_{00}' & b_{01}' & b_{02}' &\cdots & b_{0n}'
\\
b_{10}' & b_{11}' & b_{12}' &\cdots & b_{1n}'
\\
\vdots & \vdots & \cdots & \vdots & \vdots
\\
b_{n0}' & b_{n1}' & b_{n2}' &\cdots & b_{nn}'
\end{bmatrix}
\]
and

\[W^{-1}A_1W=
\begin{bmatrix}
\lambda_0 & 0 & 0 &\cdots & 0
\\
c_{10}& \lambda_1 & 0 &\cdots & 0
\\
c_{20} & c_{21}& \lambda_2 &\cdots & 0
\\
\vdots & \vdots & \cdots & \vdots & \vdots
\\
c_{n0}& c_{n1} & c_{n2} &\cdots & \lambda_n
\end{bmatrix}
\]

Without loss of generality, we may assume that the non-zero eigenvalues correspond to the first columns of $W^{-1}A_1W$, i.e., if $\lambda_0, \lambda_1,\ldots, \lambda_q$ with $(q\leq n)$ are the only non-zero eigenvalues of $A_1$, then $\lambda_0, \lambda_1,\ldots, \lambda_q $ appear on the first $(q+1)$ columns of $W^{-1}A_1W$. Clearly the operator with matrix representation (with respect to $\{z^m\}_{m\geq 0}$)
$\begin{pmatrix}
W & 0 \\
0 & I
\end{pmatrix}(=R)$ on $H^2(\D)$ is invertible with inverse
$\begin{pmatrix}
W^{-1} & 0 \\
0 & I
\end{pmatrix}(=R^{-1})$. Let $T_1= R^{-1}TR$. Then $T_1$ is a bounded linear operator on $H^2(\D)$. Since $T_1^m = R^{-1}T^m R$ for all $m\geq 1$, $T$ is analytic if and only if $T_1$ is analytic. We will show that $T_1$ is analytic. There exists suitable scalars $c_{n+l, j}$ for $l=1,2,\ldots, k$ and $j= 0,1, 2,\ldots, n$ such that with respect to the orthonormal basis $\{z^m\}_{m\geq 0}$, $T_1$ can be represented as,

\[
%\begin{equation}\label{eqn: T eigenvalue}
\begin{bmatrix}
\lambda_0 & 0 & 0 &\cdots & 0 & 0 & 0 & \dots
\\
c_{10}& \lambda_1 & 0 &\cdots & 0 & 0 & 0 & \dots
\\
c_{20}& c_{21} & \lambda_2 &\cdots & 0 & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
c_{n0}& c_{n1} & c_{n2} &\cdots & \lambda_n & 0 & 0 & \dots
\\
c_{n+1,0}& c_{n+1,1} & c_{n+1,2} &\cdots & c_{n+1,n} & 0 & 0 & \dots
\\
c_{n+2,0}& c_{n+2,1} & c_{n+2,2} &\cdots & c_{n+2,n} & 0 & 0 & \dots
\\
\vdots & \vdots & \cdots & \vdots & \vdots &\vdots &\vdots & \dots
\\
c_{n+k,0}& c_{n+k,1} & c_{n+k,2} &\cdots & c_{n+k,n} & 0 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 1 & 0 & \dots
\\
0 & 0 & 0 & \cdots & 0 & 0 & 1 & \dots
\\
\vdots & \vdots & \cdots &\vdots &\vdots &\vdots & \ddots
\end{bmatrix}
\]

First we assume that, $0\leq q<n$.

Clearly, $\overline{T_1H^2(\D)}$ is spanned by $\{p_0, p_1, \cdots, p_n ;  z^{n+k+1}, z^{n+k+2}, \ldots\}$, where
\[
p_r(z)=
\begin{cases}
\lambda_rz^r+c_{r+1,r}z^{r+1}+\cdots+c_{n,r}z^n+c_{n+1,r}z^{n+1}+c_{n+2,r}z^{n+2}+\cdots+ c_{n+k, r}z^{n+k}, & \mbox{if } 0\leq r< n \\
\lambda_nz^n+c_{n+1,n}z^{n+1}+c_{n+2,n}z^{n+2}+\cdots+c_{n+k,n}z^{n+k}, & \mbox{if }r=n.
\end{cases}
\]
Infact, $\overline{T_1\{1, z, z^2, \ldots, z^n\}}$ is spanned by $\{p_0, p_1, p_2, \ldots, p_n\}$. Note that $p_0, p_1, p_2, \ldots, p_q$ are linearly independent and the non-zero elements (if any) of the set $\{p_{q+1}, p_{q+2}, \ldots, p_n\}$ are polynomials with $z^{ q+2}$ as a factor.
For any $m\geq 1$, $p_{r,m}(z)=T_1^mp_r(z) = \lambda_r^{m+1} z^rp_r'(z)$ for all r with $0\leq r\leq q$ and some polynomials $p_r'$ such that $p_r'(0)=1$. Also, $p_{r,m}(z)$ are linearly independent for $0\leq r\leq q$ and $m\geq 1$.
Let $m_1$ be the smallest positive integer such that non-zero elements (if any) of the set $ X:=\{T_1^{m_1}(p_{q+l}(z)): 1\leq l\leq (n-q)\}$ are polynomials with $z^{n+2}$ as a factor. Suppose, there are some non-zero elements in the set $X$. Without loss of generality, we may assume that all the elements of $X$ are non-zero.

Let us choose $m> m_1$. Then there exists $r_m \in\N$ such that $m= r_m+m_1$. Clearly $r_m$ increases with $m$ and the polynomials,
$p_{q+l,m}(z)=T_1^m(p_{q+l}(z))$, for $1\leq l\leq (n-q)$, have a factor $z^{n+2+kr_m}$.

Note that, for $1\leq l\leq n-q $, $\deg p_{q+l,m}(z)\leq n+(m+1)k$.
Now, for any $m\geq m_1$,
\[
\overline{T_1^{m+1}\{1, z, z^2,\ldots, z^n\}}=\overline{span}\{p_{r,m}(z) (0\leq r\leq q);\quad p_{q+l,m}(z)(1\leq l\leq n-q)\},
\]
where, $p_{r,m}(z)$ are linearly independent for $(0\leq r\leq q)$. We can find elements from the set $\{p_{q+l,m}(z)(1\leq l\leq n-q)\}$ to form a basis for $\overline{T_1^{m+1}\{1, z, z^2,\ldots, z^n\}}$ containing the set $\{p_{r,m}(z), (0\leq r\leq q)\}$. For simplicity (as there will be no harm), let us assume that the set $\{p_{r,m}(z) (0\leq r\leq q);\quad p_{q+l,m}(z)(1\leq l\leq n-q)\}$ itself is linearly independent and form a basis for $\overline{T_1^{m+1}\{1, z, z^2,\ldots, z^n\}}$. Note that, this basis is not necessarily orthonormal.

Hence for $m\geq m_1$, the set
\[\{p_{r,m}(z) (0\leq r\leq q);\quad p_{q+l,m}(z)(1\leq l\leq n-q);\quad z^{n+(m+1)k+1}, z^{n+(m+1)k+2}, \ldots\}
\]
form a basis for $\overline{T_1^{m+1}H^2(\D)}$
i.e.,
\[
\overline{T_1^{m+1}H^2(\D)}=\overline{span}\{p_{r,m}(z) (0\leq r\leq q);\quad p_{q+l,m}(z)(1\leq l\leq n-q);\quad z^{n+(m+1)k+1}, z^{n+(m+1)k+2}, \ldots\}
\]

If possible, let $h(\neq 0)\in H^2(\D)$, such that $h \in \bigcap_{p\geq 1}\overline{T_1^pH^2(\D)}$. Then $[h]_{T_1} \subseteq \bigcap_{p\geq 1}\overline{T_1^pH^2(\D)}$. Two subcases can arise: For $0\leq i\leq q$,

\begin{enumerate}[(a)]
\item $\la h, z^i\ra=0$
\item $\la h, z^i\ra \neq 0$.
\end{enumerate}

\textbf{Subcase (a):} $\la h, z^i\ra=0$  for $0\leq i\leq q$.

We can write, $h= z^{q+l_1}(t_0+t_1z+t_2z^2+\cdots)$ for some $l_1\geq 1$ and $\sum_{m_1=0}^{\infty}t_{m_1}z^{m_1}$ with $t_0\neq 0$.
Corresponding to this $(q+l_1)$, we can choose $m(> m_1)$ large enough, so that $ q+l_1< n+2+k r_m$. For this $m$, $h\in \overline{T_1^{m+1}H^2(\D)}$.

Hence there exist scalars $\alpha_r (0\leq r\leq q)$, $\beta_l (1\leq l\leq n-q)$; and $\{\gamma_{l_2}, l_2\geq 1\}$ such that

\begin{equation}\label{h}
\begin{split}
h &= (\alpha_0p_{0,m}+\alpha_1p_{1,m}+\alpha_2p_{2,m}+\cdots+\alpha_q p_{q,m})+(\beta_1p_{q+1,m}+\beta_2p_{q+2,m}+\cdots+\beta_{n-q}p_{n,m})\\
 & + \sum_{l_2\geq 1}\gamma_{l_2}z^{n+(m+1)k+l_2}.
\end{split}
\end{equation}

As, $\Big(q+l_1< n+2+kr_m< n+(m+1)k+l_2\Big)$, and $\la h, z^{q+l_1}\ra=t_0\neq 0$, equation (\ref{h}) implies, at least one of the scalars $\alpha_0,\alpha_1,\ldots \alpha_q$ must be non-zero. Again, $q+l_1\geq q+1$ yields, $\alpha_0\lambda_0^{m+1}=0$. Since $\lambda_0$ is non-zero, we must have $\alpha_0=0$. Similarly $\alpha_r\lambda_r^{m+1} =0$ for $1\leq r\leq q$ and will imply $\alpha_r=0$ for $1\leq r\leq q$. This is a contradiction. Hence $\bigcap_{p\geq 1}\overline{T_1^pH^2(\D)}=\{0\}$ and consequently $\bigcap_{p\geq 1}T_1^pH^2(\D)=\{0\}$.

\medskip

\textbf{Subcase (b):} $\la h,z^i\ra\neq 0$ for some $i\in \{0,1,2,\ldots, q\}$.

We may assume that, $i$ is the smallest such integer. We can write $h= z^i(t_0+t_1 z+t_2 z^2+\cdots)$ for some $\sum_{r=0}^{\infty}t_rz^r\in H^2(\D)$ such that $t_0\neq 0$.
Since $\lambda_i$ is not an eigenvalue of $T_1$, $h_1= T_1h-\lambda_i h$ is non-zero and $h_1 \in [h]_{T_1}\subseteq\bigcap_{p\geq 1}\overline{T_1^p H^2(\D)}$.

We can write $h_1= z^{i+j}(t_0'+t_1'z+t_2'z^2+\cdots)$ for some $j\geq 1$, where $t_0'\neq 0$.

\smallskip

If $i+j\geq (q+1)$, we will have $\la h_1,z^i\ra=0$ for all $i=0,1,2,\ldots,q$ and will proceed as in subcase (a).

If $i+j\leq q$, we will consider the non-zero element $T_1h_1- \lambda_{i+j}h_1$ in $[h]_{T_1}$. Since $q$ is finite, only after finitely many steps, we will find some $h' (\neq 0)\in\bigcap_{p\geq 1}\overline{T_1^p H^2(\D)}$ such that $\la h', z^i\ra=0$ for all $i=0,1,2,\ldots q$. Again, we will proceed as in subcase (a) and conclude that $T_1$ is analytic.

\textsf{If there exists a positive integer $m_1'$ such that the  elements in the set $X'=\{T_1^{m_1'}p_{q+l}(z): 1\leq l\leq n-q\}$ are all zero, the subcases (a) and (b) will follow similarly and we will get the same conclusion.}

\medskip

In the remaining case $q=n$, the polynomials $p_{r,m}(z)=T_1^m p_r(z)$, for $0\leq r\leq n$ and $m\geq 1$ are linearly independent and form a basis of $\overline{T_1^{m+1}\{1, z, z^2,\ldots, z^n\}}$. Hence the set $\{p_{r, m}(z),(0\leq r\leq n); z^{n+(m+1)k+l},l\geq 1\}$ is linearly independent and forms a basis of $T_1^{m+1}H^2(\D)$. Now proceeding exactly in the similar way as before, we will have the same conclusion.
\end{proof}

\begin{Corollary}
Let $T$ on $\clh$ be a non isometric c.n.u contraction with $\cld_T\subseteq\cld_{T^*}$ and $\dim\cld_{T^*}<\infty$. Then $T$ is analytic if and only if it has no non-zero eigenvalue.
\end{Corollary}

\begin{proof}
Follows by Theorem \ref{thm: char} and Theorem \ref{Analytic}.
\end{proof}


\begin{Corollary}\label{1-analytic}
Let $T$ be a bounded linear operator on $H^2(\D)$ such that $T=S_k+F$ where $S_k$  acts on $\{z^n\}_{n\geq 0}$ as the unilateral shift of some finite multiplicity $k (\geq 1)$ and $F$ is defined by,
\[
F(z^n)=\begin{cases}
\alpha_0+\alpha_1 z+\cdots+(\alpha_k-1)z^k & \mbox{if } n=0 \\
0, & \mbox{if } n\geq 1,
\end{cases}
\]
such that $0<|\alpha_0|\leq 1$. Then $T$ is analytic if and only if at least one of $\alpha_j$ is non-zero for some $1\leq j\leq k$.
\end{Corollary}

\begin{proof}
Follows by Lemma \ref{B-eigen vector}, Corollary \ref{Non-contractive} and Theorem \ref{Analytic}.
\end{proof}

\begin{Corollary}
Let $T$ be a c.n.u. contraction with $\dim\cld_T=1$, $\cld_T\subseteq\cld_{T^*}$ and $\dim\cld_{T^*}<\infty$, as described in Theorem \ref{1-Hypo}. $T$ is analytic if and only if either $\alpha_0=0$ or at least one of $\alpha_j$ is non-zero for some $1\leq j\leq k$.
\end{Corollary}

\begin{proof}
The proof is a direct consequence of the Corollary \ref{1-analytic} and the discussion prior to Lemma \ref{B-eigen vector}, as $\alpha_0=0$ can be considered as a nilpotent matrix of order one over $\C$.
\end{proof}


\vspace{0.1in}

\noindent\textbf{Acknowledgement:}
The author is thankful to Prof. E. K. Narayanan for many helpful discussions, suggestions and corrections throughout the work. The research of the author is supported by IoE-IISc fellowship at Indian Institute of Science, Bangalore, India.



\bibliographystyle{amsplain}
\begin{thebibliography}{99}

\bibitem{Aronszajn}
N. Aronszajn, {\em Theory of reproducing kernels}, Trans. Am. Math. Soc. 68 (1950) 337404.

\bibitem{AS}
A.  Shields, \emph{Weighted shift operators and analytic function theory}, Topics in Operator Theory, Math. Surveys Monographs, vol.
13, Amer. math. Soc., Providence, RI 1974, 49-128.

\bibitem{Curto 1}
R. Curto, {\em Polynomially hyponormal operators on Hilbert space}, in Proceedings of ELAM VII, Revista Union Mat. Arg. 37(1991), 29-56.

\bibitem{Curto 2}
R. Curto and S.S. Park, {\em k-hyponormality of powers of weighted shifts via Schur products}, Proc. Amer. Math. Soc. 131(2003), 2761-2769.

\bibitem{Curto}
R. Curto, S.H. Lee and W.Y. Lee,{\em A new criterion for k-hyponormality via weak subnormality}, Proc. Amer. Math. Soc. 133(2005), 1805-1816.

\bibitem{Douglas}
R. G. Douglas, {\em On Majorization, Factorization, and Range Inclusion of Operators on Hilbert Space}, Proc. Amer. Math. Soc. 17 (1966), 413415.

\bibitem{DB}
Duggal, B. P.  {\em On p-Hyponormal Contractions}, Proc. Amer. Math. Soc., 123(1), 81-86 (1995).

\bibitem{Exner}
G. Exner, I.B. Jung and D. Park, Some quadratically hyponormal weighted shifts, Integral Equ. Oper. Th. 60 (2008), 1336.

\bibitem{HK}
K. Hoffman and R.Kunge , {\em Linear Algebra}, New Jersey, 1971.

\bibitem{HJ}
Horn, R.A. and Johnson, C.R., {\em Matrix Analysis}, Cambridge University Press, (1985).

\bibitem{Martin-Putinar}
M. Martin and M. Putinar, {\em Lectures on hyponormal operators}, Operator Theory: Advances and Applications, Vol. 39, Birkhuser Verlag, Basel, 1989.

\bibitem{NF}
B. Sz.-Nagy and C. Foias, {\em Harmonic analysis of operators on Hilbert space}, North Holland, Amsterdam, 1970.

\bibitem{Nakamura 1}
Y. Nakamura, {\em One-dimensional perturbations of isometries}, Integral Equ. Oper. Th. 9 (1986), 286294.


\bibitem{Nakamura}
Y. Nakamura, {\em One-dimensional perturbations of the shift}, Integr. Equat. Oper. Th. 17 (1993), 373403.

\bibitem{SS}
S. Shimorin, {\em Wold-type decompositions and wandering subspaces for operators close to isometries}, J. Reine Angew. Math. 531 (2001), 147189.

\bibitem{Xia}
D. X. Xia, {\em Spectral theory of hyponormal operators}, Operator Theory: Advances and Applications, Vol. 10, Birkhuser Verlag, Basel, 1983.
\end{thebibliography}











\end{document} 