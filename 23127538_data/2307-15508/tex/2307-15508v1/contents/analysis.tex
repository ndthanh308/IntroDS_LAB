We now apply our methodology to profile the revision policy behaviour of three models: The reference restart-incremental Transformer and the two \textsc{Tapir} variations, which have a recomputation policy, proposed by \citet{tapir}. We evaluate them on three sequence labelling tasks: Slot filling \citep{coucke2018snips}, POS tagging \citep{silveira-etal-2014-gold} and NER \citep{tjong-kim-sang-de-meulder-2003-introduction}, using the final output as gold standard.\footnote{Here we use only the buffer outputs to evaluate the resulting revisions on prefixes that would have been passed on to downstream processors. We do not consider the temporary outputs of the LSTM that the original model had access to when deciding to perform a recomputation. Please refer to the original paper for the details on non-incremental and incremental performance on these tasks.} Note that the same profiling can be applied to any model with the ability of performing revisions on any sequence labelling task.

\paragraph{Quantitative Assessment} Table \ref{table:rates} shows that the recomputation policy implemented in \textsc{Tapir} reduces the number of restarts to between $10\%$ and $25\%$ in comparison to the restart incremental approach, considerably alleviating the computation load; the number of revisions is also 2 to 3 times lower. Still, only up to 40\% of the remaining recomputations are active, which means that the use of computational budget is still suboptimal. Furthermore, in Figure \ref{fig:analysis-metrics} we see that A-Appropriateness is very close to 1, as it should be. R-Pertinence is slightly below the ideal 1, but still greater than 0.8 in all cases, although it is around 0.1 lower when only effective revisions are considered. A-Pertinence is at similar values, with a lower result for POS-tagging. R-Appropriateness and R$_e$-appropriateness, however, are low in the restart-incremental Transformer and becomes even lower in the \textsc{Tapir} models. 

This may be evidence that the \textsc{Tapir} models are waiting for more input before deciding to recompute an incorrect prefix, which is in line with the shifts in the distributions we observe in Figure \ref{fig:revision-when}. \textsc{Tapir} tends to have more revisions towards the end of the sentence than the restart-incremental Transformer. This strategy can indeed help revisions be more effective, given that more left context is available, but it also results in having to wait longer for final decisions, which is not ideal. 

The cumulative distributions of the fraction of time steps with revisions per sentence, shown in Figure \ref{fig:revision-freq}, illustrate that the policy reduces the number of revisions per sentence: 50\% or less of the sentences have no revisions in the naive policy, which makes all recomputation effort be used to perform only an addition, while \textsc{Tapir}'s policy caused more sentences to not trigger revisions.


% Figure environment removed

% Figure environment removed


% Figure environment removed

\paragraph{Qualitative Assessment} Figures \ref{fig:edit-types} and \ref{fig:revision-types} show the percentages of edits and revisions types to characterise \textsc{Tapir}-TrfReviser's policy. In terms of edits, most are effective, convenient, innovative and steady. Only around 50\% are short range, which means that delay strategies would have limited improvements in reducing edit overhead. For slot filling, around 20\% of the edits occur in the last time step, which is undesired, because it means that the intermediate predictions for these labels are wrong until the model processes the full sentence.

Regarding revisions, \textsc{Tapir}'s policy works best for POS-tagging in terms of effectiveness, convenience, oscillation and recurrence, and worse for slot filling. Most of the edits are isolated, which means that recomputations have been performed for the full partial input to only result in one edit. The proportion of short vs. long range and temporary vs. definite revisions was, in general, balanced. We also see that proportionally fewer revisions occurred in the final step. Although the high percentage of intermediate revisions is high, Figure \ref{fig:revision-when} shows that they are happening towards the end, which prevents incremental subprocessors to reliably count on the intermediate outputs. Slot filling is, here, an example of the occurrence of final revisions being less than ideal.

% Figure environment removed

Based on these results, we conclude that \textsc{Tapir}'s policy is very successful in reducing the number of recomputations and also in revising less, but there is room for improving the quality of the resulting revisions, both in terms of metrics and of characteristics. This speaks for a more dedicated revision policy that could avoid full recomputations and use the state of the incremental chart and internal representations of the model for a more fine-grained prediction of which labels should change.

