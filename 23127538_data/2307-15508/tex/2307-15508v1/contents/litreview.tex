\input{tables/properties-table}

Revisability is in the nature of incremental processing: Hypothesis revision is a necessary operation to correct mistakes and build up a high-quality final output \citep{iu-restart}. Still, there is a trade-off between requiring that later modules handle a processor's revisions and buying stability by reducing some of its incrementality, which makes the concept of \textit{hypothesis stability} very relevant \citep{baumann-etal-2009-assessing}. \citet{beuck-etal-2011-decision} argue that performing revisions should not take as long as the initial processing, so as to retain the advantages of incremental processing. They propose two strategies: Allowing revisions only within a fixed window or limiting their types. Empirically determining how often a model changes the output is an aspect of their analysis we also rely on.

 The restart-incremental paradigm was investigated for Transformer-based sequence labelling by \citet{madureira-schlangen-2020-incremental} and \citet{kahardipraja-etal-2021-towards}; recently, adaptive policies were proposed to reduce the computational load \citep{kaushal-etal-2023-efficient,tapir}. \citet{rohanian-hough-2021-best} and \citet{chen-etal-2022-teaching} explored adaptation strategies to use Transformers for incremental disfluency detection. In simultaneous translation, where policies are a central concept \citep{zheng-etal-2020-simultaneous,zhang-etal-2020-learning-adaptive}, the restart-incremental approach is in use and revisions are studied \citep{arivazhagan-etal-2020-translation,sen-etal-2023-self}. 

 Sequence labelling is a staple of various incremental linguistic tasks possibly used in dialogue systems, like SRL \citep{konstas-etal-2014-incremental}, POS-tagging \citep{beuck-etal-2011-decision}, dialogue act segmentation \citep{manuvinakurike-etal-2016-toward}, disfluency detection \citep{Hough-2015} and dependency parsing \citep{honnibal-johnson-2014-joint}.

\paragraph{\textbf{Revision Categorisation and Prediction}} Approaches to categorise the properties of revisions or edits exist in various areas. \citet{faigley1981analyzing} examine the effects and causes of revisions in writing, providing a taxonomy on whether revisions change meaning and bring new information. \citet{afrin-litman-2018-annotation} classify revision quality by whether they improve student essays. \citet{anthonio-etal-2020-wikihowtoimprove} categorise revisions and edits in WikiHow in terms of what they cause to the text. Wikipedia's edits have also been classified according to factuality and fluency \citep{bronner-monz-2012-user} and intents \citep{rajagopal-etal-2022-one}. Other typologies and taxonomies have been proposed for translation revisions \citep{fujita-etal-2017-consistent} and multilingual NLG revision operations \citep{callaway-2003-multilingual}.

\citet{vaughan-mcdonald-1986-model} outline three phases of the revision process in NLG: Recognition, editing and re-generation. Revision rules have been applied for incremental summarisation by \citet{robin-1996-evaluating}. Non-incremental revision learning models also exist, relying on revision rules for dependency parsing \citep{attardi-ciaramita-2007-tree} or classification in POS-tagging \citep{nakagawa-etal-2002-revision}. Predicting stability and accuracy of hypotheses is a relevant task \citep{selfridge-etal-2011-stability}, which allows to distinguish hypotheses that will survive and are thus more reliable \citep{baumann-etal-2009-assessing}.

\paragraph{\textbf{Incremental Evaluation}} Table \ref{table:properties} presents an overview of relevant properties for incremental evaluation. In their seminal work, \citet{baumann-incremental} define three general categories of metrics for incremental processing: \textit{similarity}, \textit{timing} and \textit{diachronic}, which can be employed in incremental sequence labelling. They are suitable for capturing \textit{e.g.}~instability (edit overhead), quality of prefixes (correctness) and lag (correction time). \citet{kaushal-etal-2023-efficient} propose streaming exact match, comparing prefixes with the final gold standard. While these metrics capture instability and correctness of output prefixes, we lack a standard way to evaluate the quality of the performed revisions. We thus complement their work by proposing fine-grained metrics focusing on revisions and recomputations. 
