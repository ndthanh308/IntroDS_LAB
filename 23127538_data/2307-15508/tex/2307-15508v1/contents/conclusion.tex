In this work, we have argued that the importance of a solid evaluation framework for revision policies in incremental sequence labelling cannot be overstated. Despite being very useful to capture some incremental aspects like instability or timeliness, existing evaluation metrics set aside other major strands of revisions. To fill that void, we have introduced metrics, characteristics and rationale to support the analysis of revision policies. This methodology serves as a tool to ascertain their quality, to determine their appropriateness in different contexts and to compare different policies. 

We identify a few more roads to quality: The creation of incremental gold standards containing locally valid hypothesis, the development of fine-grained revision policies predicting what to revise and a more systematic integration of linguistic aspects of the input into the evaluation procedure. For those willing to drive those routes, we hope our methodology has paved the road well. 