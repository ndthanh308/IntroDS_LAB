{
  "title": "FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition",
  "authors": [
    "Yuzhao Mao",
    "Di Lu",
    "Xiaojie Wang",
    "Yang Zhang"
  ],
  "submission_date": "2023-07-23T04:01:24+00:00",
  "revised_dates": [],
  "abstract": "This paper concentrates on the understanding of interlocutors' emotions evoked in conversational utterances. Previous studies in this literature mainly focus on more accurate emotional predictions, while ignoring model robustness when the local context is corrupted by adversarial attacks. To maintain robustness while ensuring accuracy, we propose an emotion recognizer augmented by a full-attention topic regularizer, which enables an emotion-related global view when modeling the local context in a conversation. A joint topic modeling strategy is introduced to implement regularization from both representation and loss perspectives. To avoid over-regularization, we drop the constraints on prior distributions that exist in traditional topic modeling and perform probabilistic approximations based entirely on attention alignment. Experiments show that our models obtain more favorable results than state-of-the-art models, and gain convincing robustness under three types of adversarial attacks.",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.12221",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 812427,
  "size_after_bytes": 115336
}