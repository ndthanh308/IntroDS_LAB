\vspace{-1ex}
\section{Conclusion}
\vspace{-1ex}
In this paper, we present a novel two-stage detector called Point Generation R-CNN (PG-RCNN), that address the LiDAR-based 3D object detection problem by generating semantic surface points of the foreground objects.
PG-RCNN is distinguished from existing point cloud completion approaches in three aspects.
First, our RoI point generation (RPG) module takes grid-pooled backbone features instead of raw coordinates of the points in RoI.
Therefore, it can process the contextual information of the proposal's surrounding and estimate the actual shape and displacement of foreground objects.
Secondly, our method discriminates the generated points by giving them semantic features that represent foreground probabilities, allowing the model to distinguish incorrect proposals during the refinement stage.
Lastly, the RPG module is jointly trained with the rest of the PG-RCNN components without demanding an external dataset for supervision.
%In a nutshell, our method use different input, produce different output, and have different training methods.
Consequently, the proposed method provides intuitive and informative point clouds with semantic features for accurate object detection.
PG-RCNN achieves highly competitive performance on the KITTI dataset while exhibiting significantly better efficiency than previous methods.