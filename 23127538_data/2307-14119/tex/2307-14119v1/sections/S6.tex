In this work, we build on top of the ImageNet work~\cite{IMAGENET-2009}. With respect to this work, the main innovations are as follows. First, the idea of using (differentia) properties, and not class names, for labeling images. Second, the idea of defining an annotation methodology, rather than just producing a data set. Third, exploiting the faceted classification approach as a powerful technique for further improving the annotation quality. Finally, the fact that our approach allows for the generation of natural language aware annotations. As a consequence, the relabeling of the ImageNet images will open the door to the possibility of a dataset labeled in up to 1000+ languages, including a large number of minority languages. %A relevant issue here, which is a consequence of the work on the development of multi-lingual lexical resources which this work builds upon, is that the labels across language with the same meaning are all connected, still dealing with the well-known untranslatability problems which exist when moving from one language to another, including the presence of lexical gaps \cite{UKC-IJCAI,UKC-CICLING}.

As from the introduction, the problem of dataset quality has been known for a while, with \cite{torralba2011unbiased} being an early paper focusing on it and \cite{SGP-2000} being the work which identified the SGP as the main cause of the problem. Recent work has started focusing on ways for dealing with the problem of dataset quality. Thus, \cite{2021-MLDatasetDev} advocates more careful practices in the development of datasets that are attentive to their limitations and impact. \cite{2020-ACMFAT} advocates for fairer datasets and provides a vertical methodology for balancing the people subtree of ImageNet. \cite{yun2021re} shows how to improve the quality of ImageNet by using a classifier trained in a higher-quality dataset; this work is complementary to ours as it leaves open the problem of how to generate the higher quality dataset. As far as we know, \texttt{vTelos} is the first methodology for generating high-quality datasets and it does so by using a highly inter-disciplinary KR/CV/NLP approach.  

With respect to the annotation process, the crowdsourcing community has focused extensively on the problem of quality, see, e.g., \cite{nowak2010reliable,ewerth2017machines}.  \cite{daniel2018quality} provides a quite comprehensive characterization of quality in crowdsourcing and an extensive analysis of the state of the art. Very recently some work has started to focus on how to operationally improve the quality of the process, see, e.g.,  \cite{kyriakou2021crowdsourcing,demartini2021managing}. Most relevant to this paper, \cite{nassar2019assessing} provides and exploits a set of metrics, including Krippendorff's alpha, with the goal of monitoring the image annotation process.
However, as far as we know, there two are key differences. The first is that \texttt{vTelos} is an end-to-end general methodology. The second is that, differently from the work above, which focuses on how to measure the effects and control the behaviour of annotators, here the focus is on aligning the semantics encoded in images and in NLP descriptions, i.e., in dealing with the SGP many-to-many mappings.

Earlier work on the SGP has focused on how to integrate feature-level and semantic-level information. Thus, some have proposed the use of ontologies \cite{hare2006mind}, others of high-level features \cite{ma2010bridging,elahi2017exploring}, and others to ask users \cite{tang2011semantic}. More recently  \cite{pang2019} has proposed to handle the SGP when aggregating multi-level features. All these approaches focus on object labels and not on the differentia. 

From a methodological point of view, this work is based on a mix of KR and NLP. In KR, as applied to CV, a fair amount of work, motivated by (Cognitive) Robotic applications has concentrated on identifying the function of objects see, e.g., %\cite{dimanzo1989understanding,woods1995learning,stark1991achieving,
%bogoni1995interactive,pechuk2005function,levesque2008cognitive}. 
\cite{bogoni1995interactive,pechuk2005function,levesque2008cognitive}. 
None of this work uses the faceted classification approach. Furthermore, a second difference is that this work has concentrated on how to enable a meaningful human-machine interaction and not, as it is the case here, on how to enforce coherence between how humans and machines describe and name objects. A lot of work has also focused on the integration of NLP and CV, see \cite{CV-2021-mogadala} for a recent very extensive survey of the field. While none of this work is focused on the definition of a general methodology for high quality dataset generation, image captioning could be used towards the automatic generation of glosses. This would be relevant when there is a need for new corpora for which human annotation is not an option (for instance because requiring expert annotators).




