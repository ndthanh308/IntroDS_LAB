As from the introduction, the \texttt{vTelos} annotation process is articulated into four main choices C1-C4. Let us analyze them in detail following the order in which they are made.
\begin{enumerate}
\vspace{-0.1cm}
  \item \textit{Choice C3: Label generation.} Choose the space of labels used to annotate images. Here the meaning of each label is \textit{defined} in terms of linguistically defined properties encoding  a selected set of visual properties.  One such example is the definition of a \textit{guitar} as being a \textit{``string instrument with six strings"}. This eliminates any source of \textit{linguistic ambiguity} intrinsic to \textit{informally defined labels} and it allows to say that two labels are \textit{synonyms}.

    \item \textit{Choice C4: Label disambiguation.} Choose a unique concept identifier for each of the (one or more) meanings of each label. This eliminates any source of \textit{linguistic ambiguity} intrinsic to \textit{polysemous labels} (see footnote \footref{f1}).
    
    \item \textit{Choice C1: Object localization.} Choose one of the (one or more) objects in an image, thus eliminating any possible source of \textit{object ambiguity}.
    
    \item \textit{Choice C2: Visual classification.} Choose the relevant \textit{visual properties} of the object under consideration and annotate the image with one of the labels selected in Choice C3. This choice is conceptually similar to the usual annotation choice. The key difference is that what is selected is not the label but, rather, the linguistic properties that describe the visual properties of the object. Thus for instance, if the object occurring in the image is a guitar, the annotator would not choose the label \textit{Guitar} but, rather the property \textit{having six strings}. The label \textit{Guitar} would then be automatically associated to the label because of the definition of guitar generated by Choice C3. This eliminates any  source of \textit{visual ambiguity}.

  

\end{enumerate}
\noindent
These four choices allow us to deal with the annotation mistakes described in Section \ref{S2}. Consider Table \ref{T1}, where the first column reports the two \texttt{vTelos} roles (with \textit{Annotator} can also be read as \textit{Classifier}), the second, the design choice, the third, the purpose behind the choice, the fourth, the source of subjectivity which is addressed and the last, the solution that is enforced. 

In Table \ref{T1}, the  first and the last column are 
 crucial to the \texttt{vTelos} approach for three reasons.
The first is the splitting of the annotation tasks into two roles, i.e., \textit{classificationist} and \textit{annotator},
 where the first is in charge of preparing a well-specified annotation task for the second. The second reason is that, opposite to the annotation standard practice, in \texttt{vTelos}, Choices C3,C4 are performed before Choices C1,C2. This is in order to force the annotator to select a label within of a (possibly very large) pre-selected \textit{controlled vocabulary}. Following \texttt{vTelos} this vocabulary should be built by a domain expert. 
 %
 The third reason is that 
 classificationist and classifier coordinate through the use of the
    \textit{Visual} and the \textit{Linguistic Genus-Differentia} (see the last column in Table \ref{I1}). The idea behind the notion of Linguistic Genus-Differentia is that the meaning of a label (e.g., \textit{Guitar}) is defined in terms of a linguistic description composed of two parts, the \textit{(linguistic) Genus}, which describes what the object has in common with other objects (in the case of a guitar the fact that it is a \textit{string instrument}), and the \textit{(linguistic) Differentia} which describes which properties differentiate the object from the other objects with the same genus (in the case of a guitar, the fact that it has \textit{six strings}). In turn, given a label whose meaning is defined in terms of Linguistic Genus-Differentia, any object denoted by that label, e.g., a guitar, must have a \textit{(visual) Genus} which is described by the linguistic genus of the label and similarly for the \textit{(visual) differentia}. We often talk of linguistic and visual differentia in terms of \textit{linguistic} and \textit{visual properties}.\footnote{The distinction between the visual properties of an object and the linguistic properties which are used, in natural language, to define the label used to name the object, is based on the \emph{Teleosemantics} theory of meaning \cite{millikan2000,millikan2020neuroscience}, as adapted to CV in  \cite{2016-FOIS}.}
    
For what concerns the classifier, the goal of Choice C1 is to select the image \textit{main object} (see Section \ref{S2}). Consider for instance, in Fig.\ref{I1} (II), the objects in the MOI Image \#171, i.e., a \emph{Koto} but also a \emph{Flute}, \emph{Music Stand} etc., all labelled as \emph{Koto}. Choice C1 solves the problem of the MOI source of subjectivity. The possible strategies are: (i) removing the image just because of multi-object, (ii) splitting the image into sub-images, one per object,  or (iii) isolating objects, e.g., via bounding polygons, in this case allowing for multi-label images. Notice how Choices C1, C2 are crucially based on the distinction between \textit{object localization} and \textit{visual (image) classification}, where the former is an \textit{inherently visual activity} where an object is localized but not recognized, while the latter is an \textit{inherently semantics-driven activity} which determines the relevant properties of an object. This distinction, while being well known, is often not enforced in many state-of-the-art approaches, which collapse object detection and recognition (see \cite{he2015spatial,ILSVRC}).

Choice 2 enables the classifier to select the label whose genus and differentia align with the visual genus and differentia of the object in the image. There are only two possibilities. Either such a label does not exist, in which case the object does not belong to that class, or it does exist, in which case the opposite holds. The case of multiple possible labels cannot occur as two different objects with the same genus cannot have the same differentia. This is the key guideline
enforced by the classificationist to avoid the occurrence of the SGP many-to-many problem, modulo mistakes on the side of the annotator, i.e., the selection of a label that does not describe the contents of the image.
Thus, for instance, a positive example is Image \#238 in Fig.\ref{I1}-(II), where  the ImageNet gloss of the label \emph{Keyboard Instrument} forces the selection of the visual property of being a \emph{``a musical instrument that is played by means of a keyboard"}. Dually, Choice 2 forces the rejection of all images which do not satisfy the meaning of the label. Thus, for instance, \texttt{vTelos} will reject the MI Image \#383,  as the ImageNet label \emph{Acoustic Guitar} is defined as \emph{``a guitar with no input jack"}; but the picture does not represent a guitar and, more in general, not even a musical instrument. 

