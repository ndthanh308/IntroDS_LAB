

% Figure environment removed

% Figure environment removed

\section{Components of \toolname{}}
\toolname{} allows the user to edit both the chart and caption (Figure~\ref{fig:base-interface}).
The user can not only write captions (Figure~\ref{fig:base-interface}d) but also edit the dimensions and the x- and y-axis ranges (Figure~\ref{fig:base-interface}b). The tool provides two main features in addition to this basic chart and caption editing interface (Figure~\ref{fig:system}):
(1) The \textit{time-series prominent feature detector} computes the visual prominence of the chart features in the time-series line chart (Figure~\ref{fig:teaser}b) and
(2) the \textit{text reference extractor} identifies references between the caption text and the time-series line chart (Figure~\ref{fig:teaser}a).

\subsection{Time-Series Prominent Feature Detector}
\label{sec:prominent-detector}



The \textit{time-series prominent-feature detector} identifies visually prominent features of a given time-series line chart by looking for features that persist through multiple levels of detail.

Prior work~\cite{jugel2014m4,keogh2001dimensionality,rong2017asap,Rosen2020LineSmoothAA} has sought ways to simplify line charts to enhance the perceivability of patterns in line charts that are often obscured by the variations in the chart.
However, these methods leave the interpretation of the features to the users and do not provide ways to compare the features.
Based on the strength of the Ramer-Douglas-Peuker (RDP) line simplification algorithm (Figure~\ref{fig:rdp}a) in enhancing important extrema in time series~\cite{Rosen2020LineSmoothAA}, we modify the vanilla RDP algorithm to compute \textit{$\varepsilon$-persistence} for measuring visual prominence of both point and trend features.
 
The RDP algorithm (Figure~\ref{fig:rdp}a) takes a polyline and a distance threshold parameter $\varepsilon$, and modifying $\varepsilon$ changes the level of detail in the resulting simplified polyline (Figure~\ref{fig:rdp}b).
Our key observation is that visually prominent features persist through multiple $\varepsilon$ values (e.g., orange peak ({\color[RGB]{207,113,52}$\CIRCLE$}) in Figure~\ref{fig:rdp}b).

Based on the observation, our persistence algorithm initiates by running 
the RDP algorithm on the input time series data multiple times. On each run, the algorithm varies the $\varepsilon$ threshold, stepping through the range of values $[0.0, 0.25]$ with a step size of $0.01$, 
relative to a chart whose diagonal length is normalized to equal
$1$.
This normalization allows us to reduce the dependencies of the algorithm on the scale of the rendered charts (e.g., the algorithm would treat a 300px-by-400px chart the same as a 600px-by-800px chart).
We chose the step size to have a sufficient amount of resolution into the range of $\varepsilon$ values while being able to be run in real-time.
We do not proceed to higher values of $\varepsilon$ as most charts degenerate into just two points and no longer provide useful signal (Figure~\ref{fig:rdp}b, $\varepsilon = 0.50$).

Finally, we 
define the $\epsilon$-persistence of each point in the input time series as the
greatest $\varepsilon$ value at which the point is deemed important and included in the simplified polyline by the RDP algorithm,
capped to 0.25 by our choice of the range of $\varepsilon$ values.
In Figure~\ref{fig:rdp}b, for example, the prominent orange peak ({\color[RGB]{207,113,52}$\CIRCLE$}) persists all the way up to $\varepsilon = 0.25$ and therefore has an $\varepsilon$-persistence of $0.25$.

We extend this $\varepsilon$-persistence measure for points to a measure of $\varepsilon$-persistence of trends between any two points $p_i$ and $p_j$ on the original polyline.
Observe the green trend ({\scalebox{1.5}[1]{\color[RGB]{122,161,71}$\blacksquare$}}) to the left of the orange peak ({\color[RGB]{207,113,52}$\CIRCLE$}) in Figure~\ref{fig:rdp}b.
Below $\varepsilon = 0.10$, the trend is broken into smaller trends by the blue point ({\color[RGB]{77,103,184}$\CIRCLE$}) left of the orange peak ({\color[RGB]{207,113,52}$\CIRCLE$}).
Somewhere above $\varepsilon = 0.25$, the orange peak ({\color[RGB]{207,113,52}$\CIRCLE$}) is removed and the trend is absorbed into a larger trend.
Thus, the green trend ({\scalebox{1.5}[1]{\color[RGB]{122,161,71}$\blacksquare$}}) persists from $\varepsilon = 0.10$ to $\varepsilon = 0.25$ and hence has $\varepsilon$-persistence of $0.15$.
Generalizing this observation, we can compute $\varepsilon$-persistence of trends between any two points $p_i$ and $p_j$ by subtracting the maximum $\varepsilon$-persistence of points lying between $p_i$ and $p_j$ from the minimum $\varepsilon$-persistence for $p_i$ and $p_j$ and adding 0.01, the $\varepsilon$ step size we use.

\toolname{} displays the top five most prominent features above the chart in order (Figure~\ref{fig:teaser}b), the most prominent closest to the chart, using circles to depict point features and bars to depict trend features.
To help users get a sense of the degree of prominence of these features, the tool displays more prominent features using darker shades ({\color[RGB]{207,113,52}$\blacksquare$}/{\color[RGB]{97,158,58}$\blacksquare$}; e.g., the two most prominent features in Figure~\ref{fig:user-interface}a) and less prominent features using lighter shades ({\color[RGB]{245,216,183}$\blacksquare$}/{\color[RGB]{168,205,151}$\blacksquare$}; e.g., the fifth most prominent feature in Figure~\ref{fig:user-interface}a).

\subsection{Text References Extractor}
\label{sec:reference-identifier}

Our \textit{text reference extractor} uses a five-step pipeline to determine the matches between chart features and caption text (Figure~\ref{fig:pipeline}). 

\vspace{0.05in}
\noindent \textbf{\textit{Step 1. Extract time references in caption text.}}
To detect the time ranges described in the caption text, our tool first uses the Named Entity Module in the Stanford CoreNLP toolkit~\cite{chang2012sutime,finkel2005incorporating,manning2014stanford}. It first identifies phrases describing points in time (e.g., \textit{`1970'}, \textit{`March 2020'}) or durations (e.g., \textit{`the last six months'}).
Since the time-series data in the chart is often represented at a finer granularity than the dates and durations mentioned in the caption text, we convert the detected time points and durations into a set of time points at the finest granularity of the time-series data. In practice, the time-series data we have worked with is at a granularity of days, weeks, months or years. 

The time points mentioned in the caption text occasionally signify the start or the end point of a time range.
For example, \textit{`between 1970 and 1980'} or \textit{`from 1970 to 1980'} indicates the start point 1970 and 1980.
To detect these start and end points, we utilize the context template patterns near the time words (Table~\ref{tab:boundary-points}).
In the example phrases, our tool would detect the time range 1970-1980.
However, caption text sometimes gives only one endpoint of a time range (e.g., `\textit{since Nov 1997}', `\textit{after March 2020}').
In these cases, we detect one endpoint and leave the other endpoint undetermined (e.g., 1997/11-?, 2020/03-?).

% Figure environment removed

\vspace{0.05in}
\noindent \textbf{\textit{Step 2. Extract data descriptions in caption text.}} 
We next extract trend descriptions (i.e., upward, downward) and local extrema (i.e., maximum and minimum) in the caption text by looking for a predefined set of keywords (Table~\ref{tab:feature-words}) in the caption.
We compiled these keywords by examining 
captions collected through our survey of line charts in the wild
and expanding them using a thesaurus~\cite{merriam2022thesaurus}.

We first compared lemmas (i.e., base forms of words; e.g., `\textit{rising}' - `\textit{rise},' `\textit{soared}' - `\textit{soar}') of each word in the input sentence with the lemmas of words in our compiled list of keywords to find any exact matches.
To capture any synonyms that we may have missed in our list, we use the cosine similarity of the BERT contextual embedding vectors~\cite{devlin-etal-2019-bert} between the words in the input sentence and the words in the keywords list.
We obtained the BERT contextual embedding vectors of the keywords by running a pre-trained BERT model~\cite{devlin-etal-2019-bert} on the sentences from which the words originated and extracting the results of the final layer.
For each of the words in the input sentence, we similarly obtain its BERT contextual embedding vector. We consider the word in the sentence a description of the data if the cosine similarity of its BERT contextual embedding vector and any of the BERT contextual embedding vectors of the keywords is greater than the empirically determined threshold of $0.7$.

\vspace{0.05in}
\noindent \textbf{\textit{Step 3. Pairing time references with data descriptions.}} 
Complex caption sentences may sometimes refer to more than one point or duration in time along with more than one time feature. 
For example, the sentence \textit{``The 30-year fixed mortgage rates peaked in 1981 and then declined sharply until 1987''} includes the time duration \textit{`30-year'}, and points in time \textit{`1981'} and \textit{`until 1987,'} with features \textit{`peaked'} and \textit{`declined.'}

To connect the times with their features, we first use the Stanford CoreNLP dependency parser~\cite{chen2014fast,manning2014stanford} to obtain a dependency tree for the caption (Figure~\ref{fig:pipeline} Step 3 left). 
We match each of the time references to the closest data description within the dependency tree that does not have a closer time reference.
When two time references complement each other, with one only mentioning the start point and the other only mentioning the end point,
we combine them into a single time range.
For example, in Figure~\ref{fig:results}b, Sentence 2, 
\textit{``From 1950, North Korea's GDP increased quite rapidly until 1985,''}
the data description \textit{`increased'} is closest to the two time references, \textit{`from 1950'} (1950-?) and \textit{`until 1985'} (?-1985) and the tool combines the two end dates into a single range, 1950-1985.
We discard time references or data descriptions not matched through this process.
In our example, we follow the
relation from \textit{`1981'} and \textit{`1987,'} to pair the corresponding time references with the data descriptions \textit{`peaked'} and \textit{`declined'} at a distance of $1$, respectively. 
On the other hand, the time phrase, \textit{`30-year'} remains unmatched and is therefore discarded.


\begin{table}
    \centering
    \caption{List of context template patterns near the mention of time \textit{T} that we use to determine whether \textit{T} is a start point or an end point of a time range.}
    % Figure removed
    \label{tab:boundary-points}
\end{table}

\begin{table}
    \centering
    \caption{The word list \toolname{} uses to identify data descriptions in caption text.}
    % Figure removed
    \vspace{-0.15in}
    \label{tab:feature-words}
\end{table}

\vspace{0.05in}
\noindent \textbf{\textit{Step 4. Match text references with chart data.}}
The data descriptions and time references in the caption text obtained from the previous three steps may require further disambiguation to accurately pinpoint the referenced features in the chart. 
For example, the time reference \textit{`1981'} could refer to any of the points in the chart whose year is 1981. The time reference \textit{`until 1987'} could end at any of the points in the chart whose year is 1987, and the start point is yet to be determined.

To find a suitable selection, we join the information specified in the data descriptions and the time references with the chart data.
When the data description refers to a local maximum, our tool infers that the chart point being referenced is the point within the time reference with the greatest value; if it refers to a local minimum, our tool infers that the chart point being referenced is the point within the time reference with the smallest value.
Hence, in our example, we select the global maximum point in the chart for the pair (\textit{`peaked'}, \textit{`1981'}) (blue point ({\color[RGB]{152,167,214}$\CIRCLE$}) in Figure~\ref{fig:pipeline}).
For rising trends, we select the point with the minimum value among the start point candidates and the point with the maximum value among the endpoint candidates, and vice versa for falling trends.
Thus, for the pair (\textit{`decreased'}, \textit{`until 1987'}), the tool matches the decreasing trend between the maximum point in 1981 and the minimum point in 1987 (green line ({\scalebox{1.5}[1]{\color[RGB]{132,188,121}$\blacksquare$}}) in Figure~\ref{fig:pipeline}).

\toolname{} highlights the time references and data descriptions in the caption text and adds bars (for trend features) and circles (for point features) in the region above the prominent features (Figure~\ref{fig:teaser}a) using the same colors. Users can hover over either the text highlighting or the bars and circles to view the set of referenced points on the chart.
During this process, \toolname{} performs a basic check for factual errors between references to trend features in the text and the actual change of data between the two endpoints of the trend feature. If the data reference is an upward trend but the data decreases, or vice versa, our system detects a factual error. For example, we detect pair (\textit{`soared'}, \textit{`from 1980 to 1991'}) in the first sentence of Figure~\ref{fig:teaser}. Although the text indicates that the value in 1991 would be higher than the value in 1980, this actually is not the case.
The tool alerts authors of such factual errors by drawing a red squiggly underline (% Figure removed) on the time references and data descriptions in the text, similar to spell-checkers.

\vspace{0.05in}
\noindent \textbf{\textit{Step 5. Match referenced feature with prominent features.}}
We finally compare the references with the prominent chart features returned by our prominent feature detector.
We consider points features as a match if they are exactly the same.
On the other hand, we 
detect a match between text references to time segments and a visually prominent trend if the intersection of the points in the two sets covers at least 95\% of the union of the two sets.
This way, we are able to detect that (\textit{`peaked'}, \textit{`1981'}) matches the most prominent feature and that trend feature referred to by (\textit{`decreased'}, \textit{`until 1987'}) matches the fourth most prominent feature, whereas its endpoint of in 1987 does not match any feature as it is off from the third most prominent feature by couple weeks.

If a prominent feature is matched to a reference, \toolname{} highlights the feature in green {\color[RGB]{97,158,58}$\blacksquare$} (e.g., Figure~\ref{fig:teaser} most prominent and fourth most prominent features).
On the contrary, if the feature the caption text refers to is not matched to any text (e.g., Figure~\ref{fig:teaser} Sentence 3), the tool alerts the authors of the emphasis mismatch by drawing a blue squiggly underline (% Figure removed) on the time references and data descriptions in the caption task, similarly to grammatical errors in grammar-checkers.