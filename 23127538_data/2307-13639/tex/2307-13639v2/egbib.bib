@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



% SUPERVISED METHODS

@inproceedings{tuan2017regressing,
  title={Regressing robust and discriminative 3D morphable models with a very deep neural network},
  author={Tuan Tran, Anh and Hassner, Tal and Masi, Iacopo and Medioni, G{\'e}rard},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5163--5172},
  year={2017}
}


% FAKE IT TILL YOU MAKE IT
@inproceedings{wood2021faketill,
  title={Fake it till you make it: face analysis in the wild using synthetic data alone},
  author={Wood, Erroll and Baltru{\v{s}}aitis, Tadas and Hewitt, Charlie and Dziadzio, Sebastian and Cashman, Thomas J and Shotton, Jamie},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3681--3691},
  year={2021}
}

% ArcFace paper
@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2019}
}


%REALY
@inproceedings{chai2022realy,
  title={REALY: Rethinking the Evaluation of 3D Face Reconstruction},
  author={Chai, Zenghao and Zhang, Haoxian and Ren, Jing and Kang, Di and Xu, Zhengzhuo and Zhe, Xuefei and Yuan, Chun and Bao, Linchao},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part VIII},
  pages={74--92},
  year={2022},
  organization={Springer}
}

% NoW Paper
@inproceedings{sanyal2019learningNoW,
  title={Learning to regress 3D face shape and expression from an image without 3D supervision},
  author={Sanyal, Soubhik and Bolkart, Timo and Feng, Haiwen and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7763--7772},
  year={2019}
}

% Control Net
@article{zhang2023addingcontrol,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Agrawala, Maneesh},
  journal={arXiv preprint arXiv:2302.05543},
  year={2023}
}

% FLAME head model
@article{li2017learningFLAME,
  title={Learning a model of facial shape and expression from 4D scans.},
  author={Li, Tianye and Bolkart, Timo and Black, Michael J and Li, Hao and Romero, Javier},
  journal={ACM Trans. Graph.},
  volume={36},
  number={6},
  pages={194--1},
  year={2017}
}

% MICA
@inproceedings{zielonka2022towardsMICA,
  title={Towards metrical reconstruction of human faces},
  author={Zielonka, Wojciech and Bolkart, Timo and Thies, Justus},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIII},
  pages={250--269},
  year={2022},
  organization={Springer}
}

% DENG - weak-supervised to train R-net and C-net
@inproceedings{deng2019accurate,
  title={Accurate 3d face reconstruction with weakly-supervised learning: From single image to image set},
  author={Deng, Yu and Yang, Jiaolong and Xu, Sicheng and Chen, Dong and Jia, Yunde and Tong, Xin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={0--0},
  year={2019}
}

% Stable diffusion paper
@inproceedings{rombach2022highstable,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}


% 3DMM intro
@inproceedings{blanz1999morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={Proceedings of the 26th annual conference on Computer graphics and interactive techniques},
  pages={187--194},
  year={1999}
}

% 3DMM survey paper
@article{egger20203d,
  title={3d morphable face modelsâ€”past, present, and future},
  author={Egger, Bernhard and Smith, William AP and Tewari, Ayush and Wuhrer, Stefanie and Zollhoefer, Michael and Beeler, Thabo and Bernard, Florian and Bolkart, Timo and Kortylewski, Adam and Romdhani, Sami and others},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={5},
  pages={1--38},
  year={2020},
  publisher={ACM New York, NY, USA}
}


% All landmarks for face reconstruction - energy based fit of landmarks to model
@inproceedings{wood20223d,
  title={3d face reconstruction with dense landmarks},
  author={Wood, Erroll and Baltru{\v{s}}aitis, Tadas and Hewitt, Charlie and Johnson, Matthew and Shen, Jingjing and Milosavljevi{\'c}, Nikola and Wilde, Daniel and Garbin, Stephan and Sharp, Toby and Stojiljkovi{\'c}, Ivan and others},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIII},
  pages={160--177},
  year={2022},
  organization={Springer}
}


% SUPERVISED LEARNING

@inproceedings{feng2018joint,
  title={Joint 3d face reconstruction and dense alignment with position map regression network},
  author={Feng, Yao and Wu, Fan and Shao, Xiaohu and Wang, Yanfeng and Zhou, Xi},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={534--551},
  year={2018}
}

@inproceedings{richardson20163d,
  title={3D face reconstruction by learning from synthetic data},
  author={Richardson, Elad and Sela, Matan and Kimmel, Ron},
  booktitle={2016 fourth international conference on 3D vision (3DV)},
  pages={460--469},
  year={2016},
  organization={IEEE}
}

% Domain gap paper - much broader
@inproceedings{kar2019meta,
  title={Meta-sim: Learning to generate synthetic datasets},
  author={Kar, Amlan and Prakash, Aayush and Liu, Ming-Yu and Cameracci, Eric and Yuan, Justin and Rusiniak, Matt and Acuna, David and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4551--4560},
  year={2019}
}

@inproceedings{liu2018disentangling,
  title={Disentangling features in 3D face shapes for joint face reconstruction and recognition},
  author={Liu, Feng and Zhu, Ronghang and Zeng, Dan and Zhao, Qijun and Liu, Xiaoming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5216--5225},
  year={2018}
}


@inproceedings{sela2017unrestricted,
  title={Unrestricted facial geometry reconstruction using image-to-image translation},
  author={Sela, Matan and Richardson, Elad and Kimmel, Ron},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1576--1585},
  year={2017}
}

@article{feng2021learningdeca,
  title={Learning an animatable detailed 3D face model from in-the-wild images},
  author={Feng, Yao and Feng, Haiwen and Black, Michael J and Bolkart, Timo},
  journal={ACM Transactions on Graphics (ToG)},
  volume={40},
  number={4},
  pages={1--13},
  year={2021},
  publisher={ACM New York, NY, USA}
}



% PARAMETRIC CONTROL OVER IMAGE GENERATION

@inproceedings{ghosh2020gif,
  title={GIF: Generative interpretable faces},
  author={Ghosh, Partha and Gupta, Pravir Singh and Uziel, Roy and Ranjan, Anurag and Black, Michael J and Bolkart, Timo},
  booktitle={2020 International Conference on 3D Vision (3DV)},
  pages={868--878},
  year={2020},
  organization={IEEE}
}

% STYLEGAN2
@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8110--8119},
  year={2020}
}

% NeRF-based conditioning of a GAN on 3DMMs
@article{sun2022cgof++,
  title={CGOF++: Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields},
  author={Sun, Keqiang and Wu, Shangzhe and Zhang, Ning and Huang, Zhaoyang and Wang, Quan and Li, Hongsheng},
  journal={arXiv preprint arXiv:2211.13251},
  year={2022}
}
 %StyleRig
@inproceedings{tewari2020stylerig,
  title={Stylerig: Rigging stylegan for 3d control over portrait images},
  author={Tewari, Ayush and Elgharib, Mohamed and Bharaj, Gaurav and Bernard, Florian and Seidel, Hans-Peter and P{\'e}rez, Patrick and Zollhofer, Michael and Theobalt, Christian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6142--6151},
  year={2020}
}


% Monocular reconstruction survey paper
@inproceedings{zollhofer2018state,
  title={State of the art on monocular 3D face reconstruction, tracking, and applications},
  author={Zollh{\"o}fer, Michael and Thies, Justus and Garrido, Pablo and Bradley, Derek and Beeler, Thabo and P{\'e}rez, Patrick and Stamminger, Marc and Nie{\ss}ner, Matthias and Theobalt, Christian},
  booktitle={Computer graphics forum},
  volume={37},
  number={2},
  pages={523--550},
  year={2018},
  organization={Wiley Online Library}
}

% SELF SUPERVISION

% Uses graph convolutional networks 
@inproceedings{lin2020towards,
  title={Towards high-fidelity 3D face reconstruction from in-the-wild images using graph convolutional networks},
  author={Lin, Jiangke and Yuan, Yi and Shao, Tianjia and Zhou, Kun},
  booktitle={Proceedings of the ieee/cvf conference on computer vision and pattern recognition},
  pages={5891--5900},
  year={2020}
}

@inproceedings{tewari2017mofa,
  title={Mofa: Model-based deep convolutional face autoencoder for unsupervised monocular reconstruction},
  author={Tewari, Ayush and Zollhofer, Michael and Kim, Hyeongwoo and Garrido, Pablo and Bernard, Florian and Perez, Patrick and Theobalt, Christian},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={1274--1283},
  year={2017}
}

@inproceedings{tewari2018self,
  title={Self-supervised multi-level face model learning for monocular reconstruction at over 250 hz},
  author={Tewari, Ayush and Zollh{\"o}fer, Michael and Garrido, Pablo and Bernard, Florian and Kim, Hyeongwoo and P{\'e}rez, Patrick and Theobalt, Christian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2549--2559},
  year={2018}
}

@inproceedings{shang2020self,
  title={Self-supervised monocular 3d face reconstruction by occlusion-aware multi-view geometry consistency},
  author={Shang, Jiaxiang and Shen, Tianwei and Li, Shiwei and Zhou, Lei and Zhen, Mingmin and Fang, Tian and Quan, Long},
  booktitle={European Conference on Computer Vision},
  pages={53--70},
  year={2020},
  organization={Springer}
}



@article{chen2020self,
  title={Self-supervised learning of detailed 3d face reconstruction},
  author={Chen, Yajing and Wu, Fanzi and Wang, Zeyu and Song, Yibing and Ling, Yonggen and Bao, Linchao},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={8696--8705},
  year={2020},
  publisher={IEEE}
}

@inproceedings{wu2019mvf,
  title={Mvf-net: Multi-view 3d face morphable model regression},
  author={Wu, Fanzi and Bao, Linchao and Chen, Yajing and Ling, Yonggen and Song, Yibing and Li, Songnan and Ngan, King Ngi and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={959--968},
  year={2019}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{ha2016hypernetworks,
  title={Hypernetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  journal={arXiv preprint arXiv:1609.09106},
  year={2016}
}

@article{ranftl2020towards,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Ranftl, Ren{\'e} and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={3},
  pages={1623--1637},
  year={2020},
  publisher={IEEE}
}

@article{rai2023towards,
  title={Towards Realistic Generative 3D Face Models},
  author={Rai, Aashish and Gupta, Hiresh and Pandey, Ayush and Carrasco, Francisco Vicente and Takagi, Shingo Jason and Aubel, Amaury and Kim, Daeil and Prakash, Aayush and De la Torre, Fernando},
  journal={arXiv preprint arXiv:2304.12483},
  year={2023}
}

@misc{FaceLib, 
  author={Sajjad Ayoubi}, 
  title={FaceLib}, 
  year={2019}, 
  url={https://github.com/sajjjadayobi/FaceLib}, 
}

@inproceedings{deng2020retinaface,
  title={Retinaface: Single-shot multi-level face localisation in the wild},
  author={Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5203--5212},
  year={2020}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% Bias in commercial gender classification programs
@inproceedings{buolamwini2018gender,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018}
}

% Rachel's clinical trial paper
@article{jablonski2023improving,
  title={IMproving facial PRosthesis construction with contactlESs Scanning and Digital workflow (IMPRESSeD): study protocol for a feasibility crossover randomised controlled trial of digital versus conventional manufacture of facial prostheses in patients with orbital or nasal facial defects},
  author={Jablonski, Rachael Y and Coward, Trevor J and Bartlett, Paul and Keeling, Andrew J and Bojke, Chris and Pavitt, Sue H and Nattress, Brian R},
  journal={Pilot and Feasibility Studies},
  volume={9},
  number={1},
  pages={110},
  year={2023},
  publisher={Springer}
}

% race-balanced dataset
@inproceedings{karkkainen2021fairface,
  title={Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement and mitigation},
  author={K\"{a}rkk\"{a}inen, Kimmo and Joo, Jungseock},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1548--1558},
  year={2021}
}