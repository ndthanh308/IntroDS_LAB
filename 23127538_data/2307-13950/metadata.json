{
  "title": "Deep Robust Multi-Robot Re-localisation in Natural Environments",
  "authors": [
    "Milad Ramezani",
    "Ethan Griffiths",
    "Maryam Haghighat",
    "Alex Pitt",
    "Peyman Moghadam"
  ],
  "submission_date": "2023-07-26T04:04:14+00:00",
  "revised_dates": [],
  "abstract": "The success of re-localisation has crucial implications for the practical deployment of robots operating within a prior map or relative to one another in real-world scenarios. Using single-modality, place recognition and localisation can be compromised in challenging environments such as forests. To address this, we propose a strategy to prevent lidar-based re-localisation failure using lidar-image cross-modality. Our solution relies on self-supervised 2D-3D feature matching to predict alignment and misalignment. Leveraging a deep network for lidar feature extraction and relative pose estimation between point clouds, we train a model to evaluate the estimated transformation. A model predicting the presence of misalignment is learned by analysing image-lidar similarity in the embedding space and the geometric constraints available within the region seen in both modalities in Euclidean space. Experimental results using real datasets (offline and online modes) demonstrate the effectiveness of the proposed pipeline for robust re-localisation in unstructured, natural environments.",
  "categories": [
    "cs.RO"
  ],
  "primary_category": "cs.RO",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13950",
  "pdf_url": null,
  "comment": "7 pages, 8 figures, Accepted for publication in the Proceedings of the 2023 IEEE/RSJ International Conference on Intelligent Robots and System (IROS 2023)",
  "num_versions": null,
  "size_before_bytes": 11988688,
  "size_after_bytes": 1043588
}