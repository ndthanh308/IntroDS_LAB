\section{Conclusion}
\label{sec:conclusion}
This work introduced a robust multi-robot re-localisation system. Our re-localisation pipeline benefits from deep lidar representation in place recognition and pose estimation. Self-supervised image-to-lidar
knowledge distillation was used to reason about the alignment between the image captured at the same time of query point cloud and the top-candidate point cloud. The system's modules were separately tested on a large-scale public dataset, and the entire pipeline, integrated with our lidar SLAM system, has been tested online in a wake-up case scenario. In future, we will further investigate how to improve the cross-modal perception by end-to-end learning of representation, including image segmentation for superpixel creation in unstructured environments, and verification models.


     
