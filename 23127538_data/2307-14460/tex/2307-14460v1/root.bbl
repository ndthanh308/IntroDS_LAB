\begin{thebibliography}{10}

\bibitem{rombach2021highresolution}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models, 2021.

\bibitem{zhang2023adding}
Lvmin Zhang and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock {\em arXiv preprint arXiv:2302.05543}, 2023.

\bibitem{hollein2023text2room}
Lukas H{\"o}llein, Ang Cao, Andrew Owens, Justin Johnson, and Matthias
  Nie{\ss}ner.
\newblock Text2room: Extracting textured 3d meshes from 2d text-to-image
  models.
\newblock {\em arXiv preprint arXiv:2303.11989}, 2023.

\bibitem{mildenhall2021nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock {\em Communications of the ACM}, 65(1):99--106, 2021.

\bibitem{hu2023consistentnerf}
Shoukang Hu, Kaichen Zhou, Kaiyu Li, Longhui Yu, Lanqing Hong, Tianyang Hu,
  Zhenguo Li, Gim~Hee Lee, and Ziwei Liu.
\newblock Consistentnerf: Enhancing neural radiance fields with 3d consistency
  for sparse view synthesis.
\newblock {\em arXiv preprint arXiv:2305.11031}, 2023.

\bibitem{chen2023improving}
Shu Chen, Junyao Li, Yang Zhang, and Beiji Zou.
\newblock Improving neural radiance fields with depth-aware optimization for
  novel view synthesis.
\newblock {\em arXiv preprint arXiv:2304.05218}, 2023.

\bibitem{liu2022vision}
Fei Liu, Zihao Lu, and Xianke Lin.
\newblock Vision-based environmental perception for autonomous driving.
\newblock {\em arXiv preprint arXiv:2212.11453}, 2022.

\bibitem{fonder2021m4depth}
Micha{\"e}l Fonder, Damien Ernst, and Marc Van~Droogenbroeck.
\newblock M4depth: Monocular depth estimation for autonomous vehicles in unseen
  environments.
\newblock {\em arXiv preprint arXiv:2105.09847}, 2021.

\bibitem{ranftl2020towards}
Ren{\'e} Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen
  Koltun.
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  44(3):1623--1637, 2020.

\bibitem{Ranftl_2021_ICCV_DPT}
Ren\'e Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.
\newblock Vision transformers for dense prediction.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 12179--12188, October 2021.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{liu2023summary}
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian,
  Hao He, Antong Li, Mengshen He, Zhengliang Liu, Zihao Wu, Dajiang Zhu, Xiang
  Li, Ning Qiang, Dingang Shen, Tianming Liu, and Bao Ge.
\newblock Summary of chatgpt/gpt-4 research and perspective towards the future
  of large language models, 2023.

\bibitem{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em 9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.

\bibitem{convnext}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
  and Saining Xie.
\newblock A convnet for the 2020s.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2022.

\bibitem{efficientnetl2}
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc~V Le.
\newblock Self-training with noisy student improves imagenet classification.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 10687--10698, 2020.

\bibitem{yu2022metaformer}
Weihao Yu, Mi~Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi
  Feng, and Shuicheng Yan.
\newblock Metaformer is actually what you need for vision.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 10819--10829, 2022.

\bibitem{bhat2021adabins}
Shariq~Farooq Bhat, Ibraheem Alhashim, and Peter Wonka.
\newblock Adabins: Depth estimation using adaptive bins.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4009--4018, 2021.

\bibitem{bhat2022localbins}
Shariq~Farooq Bhat, Ibraheem Alhashim, and Peter Wonka.
\newblock Localbins: Improving depth estimation by learning local
  distributions.
\newblock In {\em European Conference on Computer Vision}, pages 480--496.
  Springer, 2022.

\bibitem{jun2022depth}
Jinyoung Jun, Jae-Han Lee, Chul Lee, and Chang-Su Kim.
\newblock Depth map decomposition for monocular depth estimation.
\newblock {\em arXiv preprint arXiv:2208.10762}, 2022.

\bibitem{li2022binsformer}
Zhenyu Li, Xuyang Wang, Xianming Liu, and Junjun Jiang.
\newblock Binsformer: Revisiting adaptive bins for monocular depth estimation.
\newblock {\em arXiv preprint arXiv:2204.00987}, 2022.

\bibitem{yuan2022new}
Weihao Yuan, Xiaodong Gu, Zuozhuo Dai, Siyu Zhu, and Ping Tan.
\newblock New crfs: Neural window fully-connected crfs for monocular depth
  estimation.
\newblock {\em arXiv preprint arXiv:2203.01502}, 2022.

\bibitem{lee2019monocular}
Jae-Han Lee and Chang-Su Kim.
\newblock Monocular depth estimation using relative depth maps.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9729--9738, 2019.

\bibitem{He_2016_CVPR}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem{xian2018monocular}
Ke~Xian, Chunhua Shen, Zhiguo Cao, Hao Lu, Yang Xiao, Ruibo Li, and Zhenbo Luo.
\newblock Monocular relative depth perception with web stereo data supervision.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 311--320, 2018.

\bibitem{Tan2019EfficientNetRM}
Mingxing Tan and Quoc~V. Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock 2019.

\bibitem{beit1}
Hangbo Bao, Li~Dong, and Furu Wei.
\newblock Beit: {BERT} pre-training of image transformers.
\newblock {\em CoRR}, abs/2106.08254, 2021.

\bibitem{beit2}
Zhiliang Peng, Li~Dong, Hangbo Bao, Qixiang Ye, and Furu Wei.
\newblock {BEiT v2}: Masked image modeling with vector-quantized visual
  tokenizers.
\newblock 2022.

\bibitem{beit3}
Wenhui Wang, Hangbo Bao, Li~Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti
  Aggarwal, Owais~Khan Mohammed, Saksham Singhal, Subhojit Som, and Furu Wei.
\newblock Image as a foreign language: {BEiT} pretraining for vision and
  vision-language tasks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2023.

\bibitem{swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 10012--10022, 2021.

\bibitem{swin2}
Ze~Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue
  Cao, Zheng Zhang, Li~Dong, Furu Wei, and Baining Guo.
\newblock Swin transformer v2: Scaling up capacity and resolution.
\newblock In {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 11999--12009, 2022.

\bibitem{rw2019timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem{nextvit}
Jiashi Li, Xin Xia, Wei Li, Huixia Li, Xing Wang, Xuefeng Xiao, Rui Wang, Min
  Zheng, and Xin Pan.
\newblock Next-vit: Next generation vision transformer for efficient deployment
  in realistic industrial scenarios.
\newblock {\em arXiv preprint arXiv:2207.05501}, 2022.

\bibitem{levit}
Benjamin Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin,
  Herve Jegou, and Matthijs Douze.
\newblock Levit: A vision transformer in convnet's clothing for faster
  inference.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 12259--12269, October 2021.

\bibitem{deit3}
Hugo Touvron, Matthieu Cord, and Herv{\'e} J{\'e}gou.
\newblock Deit iii: Revenge of the vit.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXIV}, pages 516--533.
  Springer, 2022.

\bibitem{mehta2022mobilevitv2}
Sachin Mehta and Mohammad Rastegari.
\newblock Separable self-attention for mobile vision transformers.
\newblock {\em arXiv preprint arXiv:2206.02680}, 2022.

\bibitem{tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, pages 6105--6114. PMLR, 2019.

\bibitem{steiner2021vit}
Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob
  Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in
  vision transformers.
\newblock {\em arXiv preprint arXiv:2106.10270}, 2021.

\bibitem{resnext-101}
Dhruv~Kumar Mahajan, Ross~B. Girshick, Vignesh Ramanathan, Kaiming He, Manohar
  Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van~der Maaten.
\newblock Exploring the limits of weakly supervised pretraining.
\newblock In {\em ECCV}, 2018.

\bibitem{he2016residual}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, pages 770--778, 2016.

\bibitem{howard2019searching}
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo~Chen, Mingxing
  Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et~al.
\newblock Searching for mobilenetv3.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 1314--1324, 2019.

\bibitem{sener2018opt}
Ozan Sener and Vladlen Koltun.
\newblock Multi-task learning as multi-objective optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In {\em 3rd International Conference on Learning Representations,
  {ICLR}}, 2015.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, pages 248--255. Ieee, 2009.

\bibitem{diml}
Youngjung Kim, Hyungjoo Jung, Dongbo Min, and Kwanghoon Sohn.
\newblock Deep monocular depth estimation via integration of global and local
  predictions.
\newblock {\em IEEE Transactions on Image Processing}, 27(8):4131--4144, 2018.

\bibitem{li2018megadepth}
Zhengqi Li and Noah Snavely.
\newblock Megadepth: Learning single-view depth prediction from internet
  photos.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2041--2050, 2018.

\bibitem{wang2019web}
Chaoyang Wang, Simon Lucey, Federico Perazzi, and Oliver Wang.
\newblock Web stereo video supervision for depth prediction from dynamic
  scenes.
\newblock In {\em 2019 International Conference on 3D Vision (3DV)}, pages
  348--357. IEEE, 2019.

\bibitem{tartanair2020iros}
Wenshan Wang, Delong Zhu, Xiangwei Wang, Yaoyu Hu, Yuheng Qiu, Chen Wang, Yafei
  Hu, Ashish Kapoor, and Sebastian Scherer.
\newblock Tartanair: A dataset to push the limits of visual slam.
\newblock 2020.

\bibitem{xian2020structure}
Ke~Xian, Jianming Zhang, Oliver Wang, Long Mai, Zhe Lin, and Zhiguo Cao.
\newblock Structure-guided ranking loss for single image depth prediction.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 611--620, 2020.

\bibitem{apolloscape}
Xinyu Huang, Peng Wang, Xinjing Cheng, Dingfu Zhou, Qichuan Geng, and Ruigang
  Yang.
\newblock The apolloscape open dataset for autonomous driving and its
  application.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  42(10):2702--2719, 2020.

\bibitem{yao2020blendedmvs}
Yao Yao, Zixin Luo, Shiwei Li, Jingyang Zhang, Yufan Ren, Lei Zhou, Tian Fang,
  and Long Quan.
\newblock Blendedmvs: A large-scale dataset for generalized multi-view stereo
  networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1790--1799, 2020.

\bibitem{irs}
Qiang Wang, Shizhen Zheng, Qingsong Yan, Fei Deng, Kaiyong Zhao, and Xiaowen
  Chu.
\newblock Irs: A large naturalistic indoor robotics stereo dataset to train
  deep models for disparity and surface normal estimation.
\newblock In {\em 2021 IEEE International Conference on Multimedia and Expo
  (ICME)}, pages 1--6, 2021.

\bibitem{Silberman2012}
Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus.
\newblock Indoor segmentation and support inference from rgbd images.
\newblock In {\em Computer Vision -- ECCV 2012}, pages 746--760, Berlin,
  Heidelberg, 2012. Springer Berlin Heidelberg.

\bibitem{Menze_2015_CVPR}
Moritz Menze and Andreas Geiger.
\newblock Object scene flow for autonomous vehicles.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2015.

\bibitem{chen2016single}
Weifeng Chen, Zhao Fu, Dawei Yang, and Jia Deng.
\newblock Single-image depth perception in the wild.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{schops2017multi}
Thomas Schops, Johannes~L Schonberger, Silvano Galliani, Torsten Sattler,
  Konrad Schindler, Marc Pollefeys, and Andreas Geiger.
\newblock A multi-view stereo benchmark with high-resolution images and
  multi-camera videos.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3260--3269, 2017.

\bibitem{butler2012naturalistic}
Daniel~J Butler, Jonas Wulff, Garrett~B Stanley, and Michael~J Black.
\newblock A naturalistic open source movie for optical flow evaluation.
\newblock In {\em Computer Vision--ECCV 2012: 12th European Conference on
  Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part VI
  12}, pages 611--625. Springer, 2012.

\bibitem{sturm2012benchmark}
J{\"u}rgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram Burgard, and Daniel
  Cremers.
\newblock A benchmark for the evaluation of rgb-d slam systems.
\newblock In {\em 2012 IEEE/RSJ international conference on intelligent robots
  and systems}, pages 573--580. IEEE, 2012.

\bibitem{zoedepth}
Shariq~Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka, and Matthias
  Müller.
\newblock Zoedepth: Zero-shot transfer by combining relative and metric depth,
  2023.

\bibitem{wofk2023videpth}
{Wofk, Diana and Ranftl, Ren\'{e} and M{\"u}ller, Matthias and Koltun,
  Vladlen}.
\newblock {Monocular Visual-Inertial Depth Estimation}.
\newblock In {\em {IEEE International Conference on Robotics and Automation
  (ICRA)}}, {2023}.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6840--6851, 2020.

\bibitem{stan2023ldm3d}
Gabriela Ben~Melech Stan, Diana Wofk, Scottie Fox, Alex Redden, Will Saxton,
  Jean Yu, Estelle Aflalo, Shao-Yen Tseng, Fabio Nonato, Matthias Muller, and
  Vasudev Lal.
\newblock Ldm3d: Latent diffusion model for 3d.
\newblock {\em arXiv preprint arXiv:2305.10853}, 2023.

\bibitem{lee2019big}
Jin~Han Lee, Myung-Kyu Han, Dong~Wook Ko, and Il~Hong Suh.
\newblock From big to small: Multi-scale local planar guidance for monocular
  depth estimation.
\newblock {\em arXiv preprint arXiv:1907.10326}, 2019.

\end{thebibliography}
