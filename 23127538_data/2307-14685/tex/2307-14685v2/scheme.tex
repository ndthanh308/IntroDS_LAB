\section{Third order space-time fully implicit discretization} \label{sec:scheme}

We consider a finite volume approximation of~\eqref{eq:hyp:sys} through the method of lines (MOL) on the compact computational domain $\Omega=[a,b]\subset\mathbb{R}$. To this end, we discretize $\Omega$ with $N$ uniform cells $\Omega_j=[x_j-\nicefrac{h}{2},x_j+\nicefrac{h}{2}]$ of amplitude $h>0$, such that $\cup_{j=1}^N \Omega_j=\Omega$ and $x_j = a + (j-\nicefrac12)h$ are the cell centers. For the sake of simplicity, we will describe the scheme for a uniform grid, but it is easy to generalize the scheme to a non uniform mesh. 
Defining the cell averages of the exact solution on a given space cell $\Omega_j$ as
$$
\ca{\mathbf{u}}_j(t)= \frac1h \int_{\Omega_j} \mathbf{u}(x,t) \dx, \quad t \geq 0
$$
the MOL provides the following semi-discrete form of system~\eqref{eq:hyp:sys}:
\begin{equation} \label{eq:MOL}
	\TotDer{\ca{\mathbf{u}}_j(t)}{t} = -\frac{1}{h}\left[ \mathbf{f}\left(\mathbf{u}_{j+\frac12}(t)\right) - \mathbf{f}\left(\mathbf{u}_{j-\frac12}(t)\right)\right], \quad j=1,\dots,N, \ t\geq 0,
\end{equation}
where $\mathbf{u}_{j\pm\nicefrac12}(t) = \mathbf{u}\left(x_j\pm\nicefrac{h}{2},t\right)$. System~\eqref{eq:MOL} describes the conservation of the cell averages as \revision{the difference of the right and left fluxes} at the cell boundaries. Up to now, no numerical approximation of the exact solution has been introduced. In fact, \eqref{eq:MOL} is still exact.

In order to transform the MOL in a numerical scheme, \revision{first one has to transform the exact system~\eqref{eq:MOL} in a closed system for the cell averages and, afterwards, one can} introduce a time discretization of the \revision{resulting} coupled ODE system which evolves in time the cell averages. Consequently, there is the problem of the knowledge of point values of the solution at the cell interfaces for the evaluation of the flux function. The extrapolation of these values from the cell averages is the so-called \emph{reconstruction problem}. WENO and CWENO schemes, see e.g.~\cite{JiangShu:96,Shu:97,LPR:00:SIAMJSciComp,CPSV:cweno}, and their developments~\cite{Balsara:AOWENO,CCD:11,ABC16:improvedWENOZ,SempliceVisconti:2020}, are examples of numerical procedures computing point values as function of the cell averages. The advantage of WENO and CWENO schemes is that they achieve high order approximations of the reconstructions, but they pay the price of enlarging the stencil, compared to low order schemes, and of being highly nonlinear, which is a computational bottleneck in implicit time integration.

In the following, before dealing with the time integration of~\eqref{eq:MOL}, we recall the space reconstruction based on \revision{a} recently developed CWENO scheme~\cite{STP23:cweno:boundary}.

\subsection{Space reconstruction: third order CWENOZ without ghost cells} \label{sec:scheme:cweno}

In reconstruction procedures, the goal is to provide a space limited approximation of the exact solution $\mathbf{u}(\cdot,t)$, at a given time $t\geq 0$, using the knowledge of its cell averages. Since the reconstruction is typically applied component-wise, we will describe the procedure on a component $u$ of the vector solution $\mathbf{u}$ \revision{in one-dimension}.

A CWENO type reconstruction defines an approximation of $u(\cdot,t)$ as
$$
u(x,t) \approx \sum_{j=1}^N R_j(x;t)\chi_{\Omega_j}(x), \quad t\geq 0,
$$
where $\chi_{\Omega_j}$ is the characteristic function of the cell $\Omega_j$, and $R_j(x;t)$ is the reconstruction polynomial \revision{for} $x\in\Omega_j$, which depends on time through the time-dependent cell averages. If the desired reconstruction point, say $\hat{x}$, lies within the cell $\Omega_j$, then the evaluation of the polynomial $R_j(\hat{x};t)$ provides the needed point values of $u(\hat{x},t)$. The CWENO type procedure differs from the classical WENO scheme by the fact that each polynomial $R_j(x;t)$ is globally defined in its reference cell $\Omega_j$ and, therefore, it can be pre-computed and later evaluated at the needed locations.

We focus on third order space reconstructions. Then, the CWENO scheme with Z-type nonlinear weights~\cite{CCD:11,CSV19:cwenoz} defines the polynomial $R_j(x;t)$ \revision{for} $x\in\Omega_j$ as follows.

\begin{definition}[Third order CWENOZ reconstruction, see~\cite{CSV19:cwenoz}] \label{def:CWENOZ}
	Let $\Popt\in\Poly{2}$ be the \emph{optimal} polynomial of degree $2$, which interpolates all the data in the three-cell stencil $\Sopt = \{ \Omega_{j-1}, \Omega_j, \Omega_{j+1} \}$. Further, let ${P}_L, {P}_R\in\Poly{1}$ be polynomials of degree $1$ such that $P_L$ interpolates the cell averages of the left-biased sub-stencil $\mathcal{S}_L = \{ \Omega_{j-1}, \Omega_j \}$, and $P_R$ interpolates the cell averages of the right-biased sub-stencil $\mathcal{S}_R = \{ \Omega_j, \Omega_{j+1} \}$.
	Let also $\{d_0,d_L,d_R\}$ be a set of strictly positive real coefficients such that $\sum_{k=0,L,R} d_k=1$.
	
	The CWENOZ procedure computes the reconstruction polynomial on $\Omega_j$ as
	\begin{equation}
		R_j^{\mathsf{CWZ}}(x;t) 
		= \frac{\omega_0}{d_0} \left( \Popt(x;t) - \sum_{k=L,R} d_k P_k(x;t) \right) + \sum_{k=L,R} \omega_k P_k(x;t) \in\Poly{2}, \label{eq:precCWZ}
	\end{equation}
	where $\omega_0$, $\omega_L$ and $\omega_R$ are the (nonlinear) coefficients defined as
	\begin{equation} \label{eq:omegaZ}
		\alpha_k = {d_k} \left( 1 + \left( \frac {\tau} {I_k+\epsilon} \right)^{p} \right),
		\qquad
		\omega_k = \frac{\alpha_k}{\sum_{i=L,0,R}\alpha_i}, \quad k=0,L,R.
	\end{equation}
	In~\eqref{eq:omegaZ}, $I_0$, $I_L$ and $I_R$ are the regularity indicators of the associated polynomials $P_L$, $\Popt$ and $P_R$, respectively, computed as the Jiang-Shu indicators from~\cite{JiangShu:96}:
	\begin{equation} \label{eq:ind}
		I[P_k] := 
		\sum_{i=1}^{\deg(P_k)}  h^{2i-1} \int_{\Omega_j} \left(\frac{\d^i}{\dx^i} P_k(x;t)\right)^2 \dx, \quad k=0,L,R.
	\end{equation}		
	Finally, $\epsilon=h^{q}$, $q\geq 1$, $p \ge 1$ and $\tau$ is the following global smoothness indicator 
	\begin{equation}  \label{eq:tau}
		\tau := \left| 2I_0 - I_L - I_R \right|.
	\end{equation}
\end{definition}

The CWENOZ reconstruction polynomial switches between the high accurate polynomial $\Popt$, when the cell averages in the stencil $\Sopt$ are a sampling of a smooth enough function, and a nonlinear blending of $\Popt$ and of the lower degree polynomials $P_L, P_R$ when a discontinuity is present in the stencil $\Sopt$. 
%The switch is automatically performed thanks to the definition of the nonlinear weights $\omega_0$, $\omega_L$ and $\omega_R$, computed with the help of the regularity indicators~\eqref{eq:ind}. In practice, these are of order $o(1)$ when the stencil $\Sopt$ is smooth, so that $\omega_i \approx d_i$, $i=0,L,R$, and thus $R_j^{\mathsf{CWZ}} \approx \Popt$. In this case, the reconstruction is able to achieve the maximal desired order of accuracy. Instead, the regularity indicator of a polynomial interpolating discontinuous data is of order $\mathcal{O}(1)$, so that the corresponding nonlinear weight deviates from its optimal value, avoiding the appearance of spurious oscillations in the reconstruction polynomial.

The use of the Z-type weights~\eqref{eq:omegaZ} allows to have better accuracy on smooth data compared to classical weights~\cite{CPSV:cweno,Shu:97,LPR:00:SIAMJSciComp}, especially on coarse grids, without sacrificing the non-oscillatory properties. This is obtained by using the optimal choice~\eqref{eq:tau} of the global smoothness indicator that makes $\tau$ much smaller than the regularity indicators when the data in $\Sopt$ are smooth enough. %Typically, $\tau$ is restricted to be a linear combination of the other smoothness indicators for efficiency. For results on the optimal choices of $\tau$ we refer to~\cite{CSV19:cwenoz}.
In~\cite{CSV19:cwenoz}, it is proven that the accuracy of the CWENOZ reconstruction on smooth flows is the optimal one, provided that $\deg(\Popt) \leq 2\deg(P_k)$, for $k = L,R$. %This condition is satisfied by the third-order reconstruction in Definition~\ref{def:CWENOZ}.

Close to boundaries, the central stencil $\Sopt$ may not be defined, because it would not be fully contained in $\Omega$. In this case, one can consider for $\Popt$ a 3-cell stencil entirely biased towards the domain interior, but the need of controlling spurious oscillations requires the inclusion of a polynomial $\tilde{P}\in\Poly{0}$\revision{, defined on the cells which contain the endpoints of the physical domain}. \revision{Indeed, assume that the 3-cell stencil is given by $\{\Omega_1,\Omega_2,\Omega_3\}$, then $\tilde{P}$ allows to select the smooth part of the stencil when a discontinuity is present either in $\Omega_2$ or $\Omega_3$.} Optimal accuracy can still be achieved provided \revision{that} the corresponding linear weight is infinitesimal of order $\mathcal{O}(h^r)$, for some $r > 0$. This approach was introduced for CWENOZ type reconstructions in~\cite{SempliceVisconti:2020}, where a thorough study of sufficient conditions on $r$, and on the other parameters of the scheme, to achieve optimal accuracy has been performed, and exploited for reconstructions free of ghost cells in \cite{STP23:cweno:boundary}. In the following definition, we recall a particular third order CWENOZ Adaptive Order reconstruction which will be used to define the boundary reconstruction. \revision{Again, we consider the one-dimensional case. For two-dimensional reconstructions we refer to~\cite{STP23:cweno:boundary}.}
%can be recast in the framework of~\cite{SempliceVisconti:2020}.

\begin{definition}[Third order CWENOZ reconstruction without ghost cells, see~\cite{STP23:cweno:boundary}] \label{def:CWENOZb}
	Let $R_j(x;t)$ be the reconstruction polynomial related to the cell $\Omega_j$. Then,
	\begin{equation} \label{eq:precCWZb}
		R_j(x;t) =
		\begin{cases}
			R_j^{\mathsf{CWZ}}(x;t), & j=2,\dots,N-1, \\[1ex]
			R_j^{\mathsf{AO}}(x;t), & j=1 \ \mbox{ with } \ \Sopt=\{\Omega_1,\Omega_2,\Omega_3\}, \\[1ex]
			R_j^{\mathsf{AO}}(x;t), & j=N \ \mbox{ with } \ \Sopt=\{\Omega_{N-2},\Omega_{N-1},\Omega_N\},
		\end{cases}
	\end{equation}
	where $\tau_j = \tau$ in~\eqref{eq:tau}, for $j=2,\dots,N-1$, and $\tau_1=\tau_2$, $\tau_N=\tau_{N-1}$.
\end{definition}

The reconstruction in the first and last computational cells appearing in \eqref{eq:precCWZb} are defined exploting the results  in \cite{SempliceVisconti:2020}, which we report here for completeness in the third order case.

\begin{definition}[Third order CWENO-AO reconstruction, see~\cite{SempliceVisconti:2020}] \label{def:CWENOZAO}
	Let $\Popt\in\Poly{2}$ be the \emph{optimal} polynomial of degree $2$ which interpolates all the given data in the three-cell stencil $\Sopt$ such that $\Omega_j \in \Sopt$. Let $P\in\Poly{1}$ be the polynomial of degree $1$ such that $P$ interpolates the cell averages of a two-cell sub-stencil $\mathcal{S}$ such that $\Omega_j\in\mathcal{S}\subset\Sopt$. Further, let $\tilde{P}\in\Poly{0}$ be the constant polynomial associated to the sub-stencil $\tilde{\mathcal{S}} = \{ \Omega_j \}$\revision{, namely $\tilde{P}(x;t)=\bar{u}_j$ for $x\in\Omega_j$.}
	Let also $\{d_0,d,\tilde{d}\}$ be a set of strictly positive real coefficients such that $d_0+d+\tilde{d}=1$ and $\tilde{d}=h^r$ for some $r>0$.
	
	The CWENOZ-AO reconstruction polynomial on $\Omega_j$ is
	\begin{equation}
		R_j^{\mathsf{AO}}(x;t) 
		= \frac{\omega_0}{d_0} \left( \Popt(x;t) - d P(x;t) - \tilde{d} \revision{\tilde{P}(t)} \right) + \omega P(x;t) + \tilde{\omega} \revision{\tilde{P}(t)} \in\Poly{2}, \label{eq:precAO}
	\end{equation}
	where $\omega_0$, $\omega$ and $\tilde{\omega}$ are the (nonlinear) Z-type coefficients, see~\eqref{eq:omegaZ}, associated to the regularity indicators $I_0$, $I$ and $\tilde{I}$, respectively for the polynomials $\Popt$, $P$ and $\tilde{P}$, see~\eqref{eq:ind}.
	
	Since $\tilde{I}=0$, the global smoothness indicator $\tau$ 
	in this case can be chosen as
	\begin{equation} \label{eq:tauAO}
		\tau := \left| I -  I_0 \right|,
	\end{equation}
\end{definition}

%Another useful application of 
% The CWENOZ-AO reconstruction is very useful to avoid the need of ghost cells to impose boundary conditions,  
%provided by the boundary treatment which is typically performed by enlarging the computational domain with ghost cells and by setting their values according to the boundary conditions. In this way, classical high order non-oscillatory reconstruction procedures, as the CWENOZ in Definition~\ref{def:CWENOZ}, can be computed on every cell in the domain, also close to the boundaries. Instead, the ability of designing reconstructions with low degree polynomials, as in CWENOZ-AO in Definition~\ref{def:CWENOZAO}, allows to consider a different strategy, 
% see~\cite{STP23:cweno:boundary,NKS:18}. There, third-order reconstructions that do not make use of ghost cells have been investigated, where the stencil for the first and last cell at the boundary extends towards the interior of the computational domain. Thus, we can give the following definition.


%More precisely, for an interior cell $\Omega_j$, $j=2,\dots,N-1$, one builds the reconstruction polynomial as in Definition~\ref{def:CWENOZ}. This reconstruction can be computed on every cell $\Omega_j$ of the computational domain $\Omega$ except for the first and the last ones close to boundary without enlarging the domain with ghost cells. Therefore, in the first cell of the domain $\Omega$, the reconstruction polynomial is built with the adaptive order procedure given in Definition~\ref{def:CWENOZAO} on the stencil $\Sopt = \{\Omega_1,\Omega_2,\Omega_3\}$ which does not involve ghost cells. Moreover, since the role of the global smoothness is to detect smooth flows in the global stencil $\Sopt$, which is composed by the first three cells and, thus, coincides with the stencil employed by the second cell, following~\cite{STP23:cweno:boundary} $\tau_1$ is taken as the global smoothness indicator $\tau_2$ computed for the second cell. This choice allows, from one hand, to save computations, and, from the other hand, to guarantee that $\tau_1$ is much smaller than the regularity indicators on smooth flows, yielding a better reconstruction. Similar considerations hold for the last cell, which is treated symmetrically to the first one.

The analysis in~\cite{SempliceVisconti:2020} shows that the reconstruction of Definition~\ref{def:CWENOZb} achieves third order of accuracy for $r=1,2$, provided that the exponent $p$ in \eqref{eq:omegaZ} is $p \geq 1$ and that $\epsilon=h^q$ for $q=1,2,3$.

%\begin{notation} \label{notation:poly}
%In the following, for convenience of notation, we denote $P_L$ the constant polynomial on its stencil denoted by $\mathcal{S}_L=\{\Omega_1\}$ and $P_R$ the linear polynomial interpolating the data in its stencil denoted by $\mathcal{S}_R=\{\Omega_1,\Omega_2\}$ when the reconstruction on $\Omega_1$ is performed. Symmetrically, for the last cell.
%\end{notation}

%In the following, for convenience, we illustrate the boundary reconstruction on the left boundary for the cell $\Omega_1$.

The reconstruction polynomial $R_j(x;t)$ given in~\eqref{eq:precCWZb} provides the approximation \revision{for each component $u_j$ of $\mathbf{u}_j$}. Thus, one can estimate the values $u\left(x_j\pm\nicefrac{h}{2},t\right)$, $t\geq 0$, with
\begin{subequations} \label{eq:bed}
	\begin{gather}
		u^-_{j+\frac12}(t)=R_{j}\left(x_j+\frac{h}{2};t\right) \ \text{ and } \ u^+_{j+\frac12}(t)=R_{j+1}\left(x_j+\frac{h}{2};t\right), \quad j=1,\dots,N-1 \label{eq:bed:interior} \\
		u^-_{\frac12}(t)=u^-_{\mathsf{out}} \ \text{ and } \ 	u^+_{\frac12}(t)=R_1\left(a;t\right) \label{eq:bed:first} \\
		u^-_{N+\frac12}(t)=R_N\left(b;t\right) \ \text{ and } \ 	u^+_{N+\frac12}(t)=u^+_{\mathsf{out}} \label{eq:bed:last}	
	\end{gather}
\end{subequations}
which are named \emph{boundary extrapolated data} (BED). The outer values $u^{\mp}_{\mathsf{out}}$ are determined by the boundary conditions. For instance, for periodic boundary conditions the outer values $u^{\mp}_{\mathsf{out}}$ are set to the inner reconstructions at the last and first interfaces, respectively. \revision{Instead, for free-flow boundary conditions, the outer values $u^{\mp}_{\mathsf{out}}$ are set to the inner reconstructions at the first and last interfaces, respectively, namely imposing zero jumps at the boundaries of the physical domain.}

Notice that at each interface the two BED in~\eqref{eq:bed} are different, although computed at the same interface $x_{j+\nicefrac{h}{2}}$. Therefore, in order to approximate the flux function at the interfaces, one introduces a consistent and monotone numerical flux function
\begin{subequations} \label{eq:numfluxfnc}
	\begin{equation}
		(\mathbf{v},\mathbf{w}) \in \R^m\times\R^m \mapsto \NumFlux(\mathbf{v},\mathbf{w}) \in \R^m,
	\end{equation}
	such that
	\begin{equation}
		\mathbf{f}\left(\mathbf{u}(x_{j+\frac{1}{2}},t)\right) \approx %\NumFlux_{j+\nicefrac12}(t) = 
		\NumFlux\left(\mathbf{u}^-_{j+\frac12}(t),\mathbf{u}^+_{j+\frac12}(t)\right) \in \R^m.
	\end{equation}
\end{subequations}
The function $\NumFlux$ may be any approximate or exact Riemann solver, which is applied component-wise on vector-valued inputs. Finally, the exact system of ODEs~\eqref{eq:MOL} is reduced to a finite system of ODEs for the evolution of the cell averages. The right hand side is completely defined by the space reconstruction along with the numerical flux, and one obtains
\begin{equation} \label{eq:spaceApprox}
	\TotDer{\ca{\mathbf{U}}_j(t)}{t} = - \frac{1}{h}\left[ \NumFlux_{j+\frac12}(t)-\NumFlux_{j-\frac12}(t)\right],
\end{equation}
which provides the approximation $\ca{\mathbf{U}}_j(t)$ of the cell averages $\ca{\mathbf{u}}_j(t)$ of the solution $\mathbf{u}(x,t)$, $x\in\Omega_j$, and where
\begin{equation} \label{eq:numflux}
	\NumFlux_{j+\frac12}(t) = \NumFlux\left(\mathbf{U}^-_{j+\frac12}(t),\mathbf{U}^+_{j+\frac12}(t)\right) \in \R^m,
\end{equation}
with $\mathbf{U}^{\mp}_{j+\nicefrac12}(t)$ BED of the data $\ca{\mathbf{U}}(t) = \left[\ca{\mathbf{U}}_1(t),\dots,\ca{\mathbf{U}}_N(t)\right]^T$ according to~\eqref{eq:bed}.

%In the following, we use the reconstruction of Definition~\ref{def:CWENOZb} in the implicit time treatment of system~\eqref{eq:spaceApprox}.

\subsection{Time integration: third order Diagonally Implicit Runge-Kutta} \label{sec:scheme:dirk}

In order to employ a timestep $\Delta t$ which is not constrained by the CFL stability condition,
we solve numerically equation~\eqref{eq:spaceApprox} with a Diagonally Implicit Runge-Kutta (DIRK) scheme with $s$ stages and general Butcher tableau
\begin{equation}
	\label{eq:tableau:dirk}
	\begin{array}{c|cccc}
		c_1 & a_{11} & 0 & \dots & 0 \\[1.5ex]
		c_2 & a_{21} & a_{22} & \dots & 0 \\[1.5ex]
		\vdots & \vdots & \vdots & \ddots & \\[1.5ex]
		c_s & a_{s1} & a_{s2} & \dots & a_{ss} \\[1ex]
		\hline
		&&&&\\[-1.8ex]
		& b_1 & b_2 & \dots & b_s
	\end{array}
\end{equation}
A typical assumption is that $c_k = \sum_{i=1}^s a_{ki}$, $k=1,\dots,s$, and one has $\sum_{k=1}^s b_k=1$ for consistency. 
Further, choosing a scheme in which $a_{kk}$ is independent of $k$, the construction of the Jacobian in the nonlinear solves is simplified.
Clearly, one uses a Butcher tableau with order matching the order of the space reconstruction, in this case a third order accurate scheme. Therefore, DIRK schemes with number of stages $s\geq 2$ must be considered, e.g.~see~\cite{Alexander1977}.

The space-time discretization leads to the fully-discrete scheme
\begin{subequations} \label{eq:implicit}
	\begin{align}
		\ca{\mathbf{U}}_j^{(k)} &= \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{i=1}^k a_{ki} \left[ \NumFlux_{j+\frac12}^{(i)} - \NumFlux_{j-\frac12}^{(i)} \right], \quad k=1,\dots,s, \label{eq:implicit:stage} \\
		\ca{\mathbf{U}}_j^{n+1} &= \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{k=1}^s b_k \left[ \NumFlux_{j+\frac12}^{(k)} - \NumFlux_{j-\frac12}^{(k)} \right], \quad n\geq 0, \label{eq:implicit:update} \\
		\NumFlux_{j+\frac12}^{(k)} &= \NumFlux\left(\mathbf{U}_{j+\frac12}^{-,(k)},\mathbf{U}_{j+\frac12}^{+,(k)}\right) \in \R^m \label{eq:implicit:flux}
	\end{align}
\end{subequations}
for each $j=1,\dots,N$, where $\Delta t$ is the time-step, $\ca{\mathbf{U}}_j^{n} \approx \ca{\mathbf{u}}_j(n\Delta t)$, and $\mathbf{U}_{j+\nicefrac12}^{\mp,(k)}$ are the BED of the stage values $\ca{\bigvec{U}}^{(k)} = \left[ \ca{\mathbf{U}}_1^{(k)}, \dots, \ca{\mathbf{U}}_N^{(k)} \right]^T$, 
approximations of the solution at times $t^{(k)} = (n + c_k) \Delta t$, according to~\eqref{eq:bed}. \revision{Here and in the following, the notation suggests the use of a uniform time-step $\Delta t$. Nevertheless, the scheme can be formulated for a non-uniform time-step, but we prefer not to burden the notation.}

The advantage of DIRK schemes is that the implicit computation of a given stage value~\eqref{eq:implicit:stage} can be performed sequentially from $k=1$ to $k=s$. Therefore, at each time-step one has to solve $s$ systems of nonlinear equations \revision{of size $mN$ by $mN$}:
\begin{equation}\label{eq:DIRK:stage}
	\mathbf{G}\left(\ca{\bigvec{U}}^{(k)}\right) := \ca{\bigvec{U}}^{(k)} 
	+ \frac{a_{kk}\Delta t}{h} \Delta \bigvec{F}^{(k)} 
	- \ca{\bigvec{U}}^{n} 
	+ \frac{\Delta t}{h} \sum_{i=1}^{k-1} a_{ki} \Delta \bigvec{F}^{(i)} = \mathbf{0},
\end{equation}
where $\Delta\bigvec{F}^{(k)} \in \R^{mN}$ whose $j$-th block is 
$ \Delta\bigvec{F}^{(k)}_j = \left( \NumFlux_{j+\nicefrac12}^{(k)}-\NumFlux_{j-\nicefrac12}^{(k)} \right) \in \R^m$, for $j=1,\dots,N$.
Above we have highlighted the term $\Delta \bigvec{F}^{(k)}$, which makes the system for the $k$-th stage value nonlinear. In fact, the other flux differences $\Delta \bigvec{F}^{(i)}$, $i=1,\dots,k-1$, are already available, thanks to the structure of DIRK schemes.

As already noticed in~\cite{PSV23:Quinpi}, $\mathbf{G}$ has two sources of nonlinearity. One is unavoidable because it is due to the physics when the phenomenon under study is described by \revision{the} nonlinear flux function $\mathbf{f}$ in~\eqref{eq:hyp:sys}. The second, instead, is introduced by the high order space reconstruction procedure, needed for the computation of the BED, which is highly nonlinear because of the nonlinear weights~\eqref{eq:omegaZ} and of the regularity indicators~\eqref{eq:ind}. Therefore, even for linear PDEs, a standard implicit scheme requires a nonlinear solver to find the solution of $\mathbf{G}(\ca{\bigvec{U}}^{(k)})=\mathbf{0}$, in equation \eqref{eq:DIRK:stage} for $k=1,\dots,s$. Typically, one uses \revision{Newton-Raphson's method}, which requires \revision{assembling} the Jacobian of the nonlinear system $\mathbf{G}$, resulting in a high computational cost. In fact, the Jacobian required for the Newton iterations has bandwidth one point larger than the stencil size in each direction, so for a third order scheme it is a block-pentadiagonal matrix with $m\times m$ blocks, with entries depending on the nonlinear weights and on the regularity indicators, which have very complicated expressions.

The Quinpi approach, introduced in~\cite{PSV23:Quinpi} for scalar conservation laws, provides a way to circumvent the nonlinearity determined by the high order reconstruction procedure. In the following section, we extend the Quinpi idea to the hyperbolic system~\eqref{eq:hyp:sys}.

\section{Third order Quinpi scheme for one-dimensional hyperbolic systems}
\label{sec:quinpi}

The name Quinpi stands for implicit CWENO and it is based on a predictor-corrector approach to avoid the nonlinearity of the high order scheme, \revision{introduced} by the space reconstruction, and keep the nonlinearity of the flux function $\mathbf{f}$ only.

The Quinpi idea relies on the following considerations on the structure of most essentially-non-oscillatory reconstructions. Since reconstructions are typically applied component-wise, we use the notation for scalar conservation laws in this section.

Let $\mathcal{S}_p = \{ \Omega_{j-p}, \dots, \Omega_{j+p} \}$ be a stencil of $2p+1$ computational cells, and $P\in\Poly{2p}$ be the \revision{optimal} interpolating polynomial of the cell averages in $\mathcal{S}_p$. Then, the dependence of $P$ on the data is linear, i.e.
\begin{equation*}
	P(x;t) = \sum_{\alpha=-p}^{p} \mu_{j,\alpha}(x) \ca{u}_{j+\alpha}(t).
\end{equation*}
Therefore, unrolling the linearity \revision{with respect to the data} of all the interpolating polynomials involved in the third order reconstruction procedure of Definition~\ref{def:CWENOZb}, one can write the reconstruction polynomial as
\begin{equation*}
	\begin{aligned}
		R_j(x;t) &= \sum_{i=0,L,R} \omega_i\left(\{\ca{u}_k(t)\}_{k\in\Sopt}\right)	P^i_j(x) \\
		&= \sum_{i=0,L,R} \omega_i\left(\{\ca{u}_k(t)\}_{k\in\Sopt}\right)	\sum_{\alpha=-1}^{1} \mu^{i}_{j,\alpha}(x) \ca{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t) \\
		&= \sum_{\alpha=-1}^{1} W_{j,\alpha} \left(x;\{\ca{u}_k(t)\}_{k\in\Sopt}\right)  \ca{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t),
	\end{aligned}
\end{equation*}
where we have collected the nonlinear weigths in the quantities
\begin{equation*}
	W_{j,\alpha} \left(x;\{\ca{u}_k(t)\}_{k\in\Sopt}\right)
	= \sum_{i=0,L,R} \omega_i\left(\{\ca{u}_k(t)\}_{k\in\Sopt}\right)	\mu^{i}_{j,\alpha}(x),
\end{equation*}
\revision{and $\delta_{ij}$ denotes the Kronecker delta.}
For the first and the last cell, the range of summation over $\alpha$ is adjusted according to the stencil of the reconstruction.
%where we have used the notation convention~\ref{notation:poly}.
Then, it is possible to write the inner BED in~\eqref{eq:bed} as
%\begin{subequations} \label{eq:bed:split}
\begin{equation} \label{eq:bed:split}%\label{eq:bed:split:inner}
	\begin{aligned}
		u_{j+\frac12}^{-}(t) &= R_j\left(x_{j+\frac12};t\right) \\
		&= \sum_{\alpha=-1}^1 W_{j,\alpha}\left(x_{j+\frac12};\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t), \\
		%
		u_{j+\frac12}^{+}(t) &= R_{j+1}\left(x_{j+\frac12};t\right) \\
		&= \sum_{\alpha=-1}^1 W_{j+1,\alpha}\left(x_{j+\frac12};\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+1+\alpha+\delta_{j1}-\delta_{jN}}(t),
	\end{aligned}
\end{equation}
% for $j=1,\dots,N-1$, and
% 	\begin{equation} \label{eq:bed:split:bound}
	% 		\begin{aligned}
		% 		u_{\frac12}^{+}(t) &= R_1\left(a;t\right) = \sum_{\alpha=-1}^1 W_{1,\alpha}\left(a;\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{2+\alpha}(t), \\
		% 		%
		% 		u_{N+\frac12}^{-}(t) &= R_{N}\left(b;t\right) = \sum_{\alpha=-1}^1 W_{N,\alpha}\left(b;\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{N+\alpha-1}(t).
		% 		\end{aligned}
	% 	\end{equation}
%\end{subequations}
We have highlighted the dependence of $W_{j,\alpha}$ on the data $\{\ca{u}_k\}_{k\in\Sopt}$, since this is highly nonlinear because it contains the nonlinear weights.

\revision{
	\begin{remark}
		For the third order reconstruction considered in this work, the quantities $W_{j,\alpha} \left(x;\{\ca{u}_k(t)\}_{k\in\Sopt}\right)$ have the following expressions. For the left BED at $x=x_{j+\nicefrac12}$, with $j=2,\dots,N-1$:
		\begin{gather*}
			W_{j,-1} = \left( \frac{-1+3 d_L}{6} \right) \frac{\omega_0}{d_0} - \frac12 \omega_L, \quad W_{j,0} = \left( \frac{5-9d_L-3d_R}{6} \right) \frac{\omega_0}{d_0} + \frac32 \omega_L + \frac12 \omega_R \\
			W_{j,1} = \left( \frac{2-3 d_R}{6} \right) \frac{\omega_0}{d_0} + \frac12 \omega_R.
		\end{gather*}
		For the right BED at $x=x_{j+\nicefrac12}$, with $j=1,\dots,N-2$:
		\begin{gather*}
			W_{j+1,-1} = \left( \frac{2-3 d_L}{6} \right) \frac{\omega_0}{d_0} + \frac12 \omega_L, \quad W_{j+1,0} = \left( \frac{5-3d_L-9d_R}{6} \right) \frac{\omega_0}{d_0} + \frac12 \omega_L + \frac32 \omega_R \\
			W_{j+1,1} = \left( \frac{-1+3 d_R}{6} \right) \frac{\omega_0}{d_0} - \frac12 \omega_R.
		\end{gather*}
	\end{remark}
}

The main idea of Quinpi is to exploit a predictor
$\{\ca{u}^{\star}_j(t)\}_{j=1}^N$
of the solution $\{\ca{u}_j(t)\}_{j=1}^N$ at time $t$ and use it to pre-compute and freeze the nonlinear weights in~\eqref{eq:bed:split}, so that the BED can be approximated as
\begin{equation} \label{eq:bed:linearized}
	\begin{aligned}
		u_{j+\frac12}^{-}(t) &\approx \hat{u}_{j+\frac12}^{-}(t) := \sum_{\alpha=-1}^1 W_{j,\alpha}\left(x_{j+\frac12};\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t), \\
		u_{j+\frac12}^{+}(t) &\approx \hat{u}_{j+\frac12}^{+}(t) := \sum_{\alpha=-1}^1 W_{j+1,\alpha}\left(x_{j+\frac12};\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+1+\alpha+\delta_{j1}-\delta_{jN}}(t). \\
		% u_{\frac12}^{+}(t) &\approx \hat{u}_{\frac12}^{+}(t) := \sum_{\alpha=-1}^1 W_{1,\alpha}\left(a;\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{2+\alpha}(t), \\
		% u_{N+\frac12}^{-}(t) &\approx \hat{u}_{N+\frac12}^{-}(t) := \sum_{\alpha=-1}^1 W_{N,\alpha}\left(b;\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{N+\alpha-1}(t).
	\end{aligned}
\end{equation}
In this way, the complete scheme would be linear with respect to the space reconstruction, and nonlinear only through the flux function.

The proposal of a predictor to linearize an implicit high order scheme was first discussed in~\cite{Gottlieb:iWENO:2006} for WENO reconstructions. There, the solution of a first order explicit scheme is used as predictor in order to compute the nonlinear WENO weights.
Instead, in~\cite{PSV23:Quinpi,2020Arbogast} an implicit first order scheme was chosen as predictor. Although an implicit predictor is more expensive than the explicit approach proposed in~\cite{Gottlieb:iWENO:2006}, it is stable and non-oscillatory even for higher Courant numbers, thus allowing for reliable prediction of the nonlinear weights.

In this work, we follow the approach in~\cite{PSV23:Quinpi} and describe it for systems of conservation laws below. With respect to the above description, in the case of a system of $m$ conservation laws, one has a reconstruction polynomial $\mathbf{R}_j(x;t)\in(\mathbb{P}^{2p})^m$ computed component-wise, $m$-vectors $\pmb{\omega}_i$ of nonlinear coefficients in each cell computed component-wise, while of course the linear coefficients $\mu^i_{j,\alpha}$ are independent of the component being reconstructed.

\subsection{The space-time first order implicit prediction} \label{sec:quinpi:predictor}

Without loss of generality, assume that the nodes $c_1,\dots,c_s$ of the DIRK method are ordered. Then, we approximate the system of ODEs~\eqref{eq:spaceApprox} with an implicit first order scheme at any time $t^{(k)}=(n+c_{k}) \Delta t \in [n\Delta t,(n+1)\Delta t]$, where $\Delta t$ is the time-step of the high order scheme~\eqref{eq:implicit}. Specifically, the system is numerically approximated in space using piecewise constant reconstructions and integrated in time using a composite backward Euler method, providing the $s$ approximations 
$\ca{\bigvec{U}}^{\star,(k)} = \left[\ca{\mathbf{U}}^{\star,(k)}_1,\dots,\ca{\mathbf{U}}^{\star,(k)}_N\right]^T$, $k=1,\dots,s$. Therefore, for each $j=1,\dots,N$, 
$\ca{\mathbf{U}}_j^{\star,(k)} \approx \ca{\mathbf{u}}_j(t^{(k)})$ is given by
\begin{subequations} \label{eq:predictor}
	\begin{align}
		\ca{\mathbf{U}}_j^{\star,(k)} &= \ca{\mathbf{U}}_j^{\star,(k-1)} - \frac{\theta_k\Delta t}{h} \left[ \NumFlux_{j+\frac12}^{\star,(k)} - \NumFlux_{j-\frac12}^{\star,(k)} \right], \quad k=1,\dots,s, \label{eq:predictor:stage} \\
		\ca{\mathbf{U}}_j^{\star,n+1} &= \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{k=1}^s \theta_k \left[ \NumFlux_{j+\frac12}^{\star,(k)} - \NumFlux_{j-\frac12}^{\star,(k)} \right], \quad n\geq 0, \label{eq:predictor:update} \\
		\NumFlux_{j+\frac12}^{\star,(k)} &= \NumFlux\left(\ca{\mathbf{U}}_{j}^{\star,(k)},\ca{\mathbf{U}}_{j+1}^{\star,(k)}\right) \in \R^m \label{eq:predictor:flux}
	\end{align}
\end{subequations}
where $\theta_k:=c_{k}-c_{k-1}$, with $c_0=0$ and $\ca{\mathbf{U}}_j^{\star,(0)}:=\ca{\mathbf{U}}_j^{n}$, and where the convention 
$$
\ca{\mathbf{U}}_{0}^{\star,(k)} = u_{\mathsf{out}}^-, \quad \ca{\mathbf{U}}_{N+1}^{\star,(k)} = u_{\mathsf{out}}^+,
$$
is used. The outer values $u_{\mathsf{out}}^{\mp}$ are imposed by the chosen boundary conditions. For instance, for periodic conditions one has
\begin{equation} \label{eq:predictor:periodic}
	\ca{\mathbf{U}}_{0}^{\star,(k)} = \ca{\mathbf{U}}_{N}^{\star,(k)}, \quad \ca{\mathbf{U}}_{N+1}^{\star,(k)} = \ca{\mathbf{U}}_{1}^{\star,(k)},
\end{equation}
whereas for \revision{free-flow conditions} one gets
\begin{equation} \label{eq:predictor:freeflow}
	\ca{\mathbf{U}}_{0}^{\star,(k)} = \ca{\mathbf{U}}_{1}^{\star,(k)}, \quad \ca{\mathbf{U}}_{N+1}^{\star,(k)} = \ca{\mathbf{U}}_{N}^{\star,(k)}.
\end{equation}
\revision{For more general boundary conditions, one should project on characteristic variables, providing the prescribed upwind conditions.}
\revision{Summarizing, the first order} scheme~\eqref{eq:predictor} is equivalent to applying a DIRK scheme with Butcher tableau given by
\begin{equation}
	\label{eq:tableau:be}
	\begin{array}{c|cccc}
		c_1 & \theta_{1} & 0 & \dots & 0 \\[1.5ex]
		c_2 & \theta_{1} & \theta_{2} & \dots & 0 \\[1.5ex]
		\vdots & \vdots & \vdots & \ddots & \\[1.5ex]
		c_s & \theta_{1} & \theta_{2} & \dots & \theta_{s} \\[1ex]
		\hline
		&&&&\\[-1.8ex]
		& \theta_1 & \theta_2 & \dots & \theta_s
	\end{array}
\end{equation}
where the coefficients $c_i$, $i=1,\dots,s$, are the same as the high order DIRK in~\eqref{eq:tableau:dirk}.

Notice that the numerical flux function $\NumFlux$ in~\eqref{eq:predictor:flux} is now computed on piecewise constant, unlimited, reconstructions from the cell averages. In fact, first order schemes do not require space-limiting, because they are unconditionally Total Variation Diminishing, see~\cite[Section 2]{PSV23:Quinpi}. Therefore, despite of the high order approximation~\eqref{eq:implicit}, the first order scheme~\eqref{eq:predictor} is characterized by a single nonlinearity, that is the one induced by the flux function $\mathbf{f}$.
Computing~\eqref{eq:predictor:stage} requires the solution of $s$ nonlinear systems of dimension $m N$, which are fully linear with respect to the \revision{unknown cell averages}:
\begin{equation} \label{eq:predictor:system}
	\mathbf{G}^\star(\ca{\bigvec{U}}^{\star,(k)}) := 
	\ca{\bigvec{U}}^{\star,(k)} 
	+ \frac{\theta_k \Delta t}{h} \Delta\bigvec{F}^{\star,(k)} 
	- \ca{\bigvec{U}}^{\star,(k-1)} = \mathbf{0},
\end{equation}
where $\Delta\bigvec{F}^{\star,(k)}\in\R^{mN}$ whose $j$-th block is $\Delta\bigvec{F}^{\star,(k)}_j=\left(\NumFlux_{j+\nicefrac12}^{\star,(k)}-\NumFlux_{j-\nicefrac12}^{\star,(k)} \right) \in\R^m$, for $j=1,\dots,N$.

The solution of~\eqref{eq:predictor:system} requires the use of a nonlinear solver $s$ times within a single time-step. In this work, we rely on Newton's iterations
\begin{equation} \label{eq:predicor:newton}
	\ca{\bigvec{U}}^{\star,(k)}_{(\ell+1)} 
	= \ca{\bigvec{U}}^{\star,(k)}_{(\ell)} 
	- \left( \mathbb{I} + \frac{\theta_k \Delta t}{h} J^{\star}\left( \ca{\bigvec{U}}^{\star,(k)}_{(\ell)} \right) \right)^{-1} \mathbf{G}^\star\left( \ca{\bigvec{U}}^{\star,(k)}_{(\ell)} \right), \quad \ell \geq 0,
\end{equation}
with given initial guess \revision{$\ca{\bigvec{U}}^{\star,(k)}_{(0)}=\ca{\bigvec{U}}^{\star,(k-1)}$}. Here, $\mathbb{I}\in\R^{mN\times mN}$ is the identity matrix, whereas $J^{\star}$ is the Jacobian matrix of the numerical flux difference $\Delta \bigvec{F}^{\star}$ \revision{which is organized in $N\times N$ blocks of size $m\times m$}. Then, each block of the Jacobian is given by
$$
\left( J^{\star} \right)_{ji} = \frac{\partial \Delta \bigvec{F}^{\star}_j}{\partial \ca{\mathbf{U}}^{\star}_i} \in \R^{m\times m}, \quad j,i=1,\dots,N.
$$
In particular, for a first order space approximation one has
%\begin{align*}
%	\Delta \NumFlux^{\star}_1 &= \Delta \NumFlux^{\star} (\ca{\mathbf{U}}^{\star}_{1},\ca{\mathbf{U}}^{\star}_2,\ca{\mathbf{U}}^{\star}_{N}), \\
%	\Delta \NumFlux^{\star}_j &= \Delta \NumFlux^{\star} (\ca{\mathbf{U}}^{\star}_{j-1},\ca{\mathbf{U}}^{\star}_j,\ca{\mathbf{U}}^{\star}_{j+1}), \quad j=2,\dots,N-1 \\
%	\Delta \NumFlux^{\star}_N &= \Delta \NumFlux^{\star} (\ca{\mathbf{U}}^{\star}_{1},\ca{\mathbf{U}}^{\star}_{N-1},\ca{\mathbf{U}}^{\star}_{N}),
%\end{align*}
%which are fully linear on the data, it turns out
that the Jacobian is a tridiagonal block matrix of the form
$$
\frac{\partial \Delta \bigvec{F}^{\star}_j}{\partial \ca{\mathbf{U}}^{\star}_i} = \begin{cases}
	-\dfrac{\partial \NumFlux}{\partial \mathbf{v}} \left( \ca{\mathbf{U}}^{\star}_i,\ca{\mathbf{U}}^{\star}_{i+1} \right), & \text{if } i=j-1 \\[2.5ex]
	\dfrac{\partial \NumFlux}{\partial \mathbf{v}}\left( \ca{\mathbf{U}}^{\star}_i,\ca{\mathbf{U}}^{\star}_{i+1} \right) - \dfrac{\partial \NumFlux}{\partial \mathbf{w}} \left( \ca{\mathbf{U}}^{\star}_{i-1},\ca{\mathbf{U}}^{\star}_i \right), & \text{if } i=j \\[2.5ex]
	\dfrac{\partial \NumFlux}{\partial \mathbf{w}} \left( \ca{\mathbf{U}}^{\star}_{i-1},\ca{\mathbf{U}}^{\star}_i \right), & \text{if } i=j+1 \\
\end{cases}
$$
for $j=2,\dots,N-1$, where $\partial_{\mathbf{v}} \NumFlux$ and $\partial_{\mathbf{w}} \NumFlux$ denote the Jacobian of the vector-valued numerical flux function~\eqref{eq:numfluxfnc} with respect to its first and second variable, respectively.

\subsection{The space-time third order implicit correction} \label{sec:quinpi:corrector}

Assume that the first order predictor is available at a time $t^{(k)} \in [n\Delta t,(n+1)\Delta t]$. The obtained approximation $\ca{\bigvec{U}}^{\star,(k)}$ is used to evaluate the nonlinear terms of the high order BED as explained at the beginning of this section, see~\eqref{eq:bed:linearized}. Therefore, the third order ``correction'' at time $t^{(k)}$ can be computed as in~\eqref{eq:implicit:stage} with
\begin{equation} \label{eq:implicit:fluxLinearized}
	\begin{aligned}
		\NumFlux_{j+\frac12}^{(k)} = \NumFlux\left(\mathbf{U}_{j+\frac12}^{-,(k)},\mathbf{U}_{j+\frac12}^{+,(k)}\right) \approx \hat{\NumFlux}_{j+\frac12}^{(k)} = \NumFlux\left(\hat{\mathbf{U}}_{j+\frac12}^{-,(k)},\hat{\mathbf{U}}_{j+\frac12}^{+,(k)}\right),
	\end{aligned}
\end{equation}
where $\hat{\mathbf{U}}_{j+\frac12}^{\mp,(k)}$ are the linearized BED, which are fully linear with respect to the unknown cell averages at time $t^{(k)}=t_n+c_k\Delta t$. Therefore, the nonlinear system
\begin{equation} \label{eq:corrector:system}
	\mathbf{G}\left(\ca{\bigvec{U}}^{(k)}\right) 
	:= \ca{\bigvec{U}}^{(k)} 
	+ \frac{a_{kk}\Delta t}{h} \Delta \hat{\bigvec{F}}^{(k)} 
	- \ca{\bigvec{U}}^{(k-1)} = \mathbf{0},
\end{equation}
obtained from~\eqref{eq:implicit:stage} and \eqref{eq:implicit:fluxLinearized}, can be tackled with Newton's iterations
\begin{equation} \label{eq:corrector:newton}
	\ca{\bigvec{U}}^{(k)}_{(\ell+1)} = \ca{\bigvec{U}}^{(k)}_{(\ell)} 
	- \left( \mathbb{I} + \frac{a_{kk} \Delta t}{h} J\left( \ca{\bigvec{U}}^{(k)}_{(\ell)} \right) \right)^{-1} \mathbf{G}\left( \ca{\bigvec{U}}^{(k)}_{(\ell)} \right), \quad \ell \geq 0,
\end{equation}
with initial guess $\ca{\bigvec{U}}^{(k)}_{(0)}$ set to the predictor's output. The stencil of the Jacobian $J\in\R^{mN\times mN}$ is still as in the fully implicit approach, because of the stencil of the space reconstructions, but the entries can now be computed explicitly. In fact, one has that each block $\left( J \right)_{ji} \in \R^{m\times m}$, $j,i=1,\dots,N$, can be written as
\begin{align*}
	\left( J \right)_{ji} = \frac{\partial \Delta \hat{\bigvec{F}}_j}{\partial \ca{\mathbf{U}}_{i}}
	=& \frac{\partial \NumFlux}{\partial \mathbf{v}} \left( \hat{\mathbf{U}}^-_{j+\frac12} , \hat{\mathbf{U}}^+_{j+\frac12}\right) \frac{\partial \hat{\mathbf{U}}^-_{j+\frac12}}{\partial \ca{\mathbf{U}}_i} + \frac{\partial \NumFlux}{\partial \mathbf{w}} \left( \hat{\mathbf{U}}^-_{j+\frac12} , \hat{\mathbf{U}}^+_{j+\frac12}\right) \frac{\partial \hat{\mathbf{U}}^+_{j+\frac12}}{\partial \ca{\mathbf{U}}_i} \\
	&- \frac{\partial \NumFlux}{\partial \mathbf{v}} \left( \hat{\mathbf{U}}^-_{j-\frac12} , \hat{\mathbf{U}}^+_{j-\frac12}\right) \frac{\partial \hat{\mathbf{U}}^-_{j-\frac12}}{\partial \ca{\mathbf{U}}_i} - \frac{\partial \NumFlux}{\partial \mathbf{w}} \left( \hat{\mathbf{U}}^-_{j-\frac12} , \hat{\mathbf{U}}^+_{j-\frac12}\right) \frac{\partial \hat{\mathbf{U}}^+_{j-\frac12}}{\partial \ca{\mathbf{U}}_i}
\end{align*}
where $\partial_{\mathbf{v}}\NumFlux$ and $\partial_{\mathbf{w}}\NumFlux$ contain the Jacobian of the flux function $\mathbf{f}$, whereas $\partial_{\ca{\mathbf{U}}_i} \mathbf{U}^{\mp}_{j\pm\nicefrac12}$ are assembled with the frozen nonlinear weights, cf.~\eqref{eq:bed:linearized}.

For nontrivial boundary conditions, the above expression for the Jacobian blocks has to be modified according to the dependence of the external BED ($\ca{\mathbf{U}}_{\nicefrac12}^-$ and $\ca{\mathbf{U}}_{N+\nicefrac12}^+$) on the interior data.

Finally, once all the stage values $\ca{\bigvec{U}}^{(k)}$, $k=1,\dots,s$, are computed, the third order solution $\ca{\bigvec{U}}^{n+1}$ at time level $(n+1)\Delta t$ is obtained as in~\eqref{eq:implicit:update}.

\begin{remark}[Implicit reconstruction along characteristic variables.]
	\revision{The Quinpi framework can be used also for reconstruction along characteristic variables.
		The linearity of the scheme can be kept provided that the nonlinear transformation matrix from conservative to characteristic variables is computed by the predictor scheme and stored at each time step $t^{(k)} = t^{n} + c_k \Delta t$, $k=1,\dots,s$.}
	
	\revision{More precisely, let $\mathbf{U}$ denote the vector of conservative variables and let $\mathbf{V}$ denote the vector of characteristic variables which are linked through the nonlinear transformation
		$$
		\mathbf{U} = T^{-1} \mathbf{V}.
		$$
		Then, the time advancement $\mathbf{\ca{U}}_j^{(k-1)} \mapsto \mathbf{\ca{U}}_j^{(k)}$ on the cell $\Omega_j$, with reconstruction from cell averages performed in characteristic variables, is obtained for $k=2,\dots,s$ as follows.}
	
	\revision{First one can perform the time advancement of the predictor solution $\mathbf{\ca{U}}_j^\star$ and store the nonlinear transformation matrix:
		$$
		\{ \mathbf{\ca{U}}_j^{\star,(k-1)} \} \xmapsto{\textnormal{advance}} \{ \mathbf{\ca{U}}_j^{\star,(k)} \} \xmapsto{\textnormal{store}} \{ T_j^{(k)} \},
		$$
		where $T_j^{(k)}$ is the map to characteristic variables on the state $\mathbf{\ca{U}}^{\star,(k)}_j$, i.e.~the map whose columns are the right eigenvectors of the flux Jacobian at $\mathbf{\ca{U}}^{\star,(k)}_j$.}
	
	\revision{Then, the high-order solution at time $t^{(k)}$ is obtained as
		$$
		\{ \mathbf{\ca{U}}_\ell^{(k-1)},\mathbf{\ca{U}}_\ell^{\star,(k)} \}_{\ell\in\mathcal{S}_{\text{opt}}}
		\xmapsto{T_j^{(k)}, \textnormal{ linear.~BED}} 
		\{ \mathbf{\hat{V}}_{j\pm\frac12}^{(k)} \} \xmapsto{(T_j^{(k)})^{-1}} \{ \mathbf{\hat{U}}_{j\pm\frac12}^{(k)} \} \xmapsto{\textnormal{advance}} \{ \mathbf{\ca{U}}_j^{(k)} \}.
		$$
	}
\end{remark}

\subsubsection{On the accuracy of the reconstruction in the smooth case}

\revision{
	In CWENO reconstructions optimal accuracy is obtained provided that the nonlinear weights $\omega_k$ are sufficiently close to the linear weights $d_k$. More precisely, for the third order CWENO scheme a sufficient condition to have optimal accuracy on smooth data is, cf.~\cite{CPSV:cweno},
	$$
	d_k-\omega_k = \mathcal{O}(h), \quad k=0,L,R.
	$$
	Indeed, let $R_j^{\text{CWZ}}\in\mathbb{P}^2$ be the reconstruction polynomial, defined in~\eqref{eq:precCWZ}, of a sufficiently smooth function $u$. Then, the reconstruction error is
	\begin{equation} \label{eq:rec:accuracy}
		\begin{aligned}
			u(x,\cdot)-R_j^{\text{CWZ}}(x;\cdot) =& \underbrace{(u(x,\cdot)-\Popt(x;\cdot))}_{\mathcal{O}(h^{3})} \\
			&+ \sum_{k=L,R} (d_k-\omega_k) \underbrace{(P_k(x;\cdot)-u(x,\cdot))}_{\mathcal{O}(h^{2})}, \quad x\in\Omega_j,
		\end{aligned}
	\end{equation}
	when the polynomials $\Popt$, $P_L$ and $P_R$ interpolate the exact cell averages of $u$. Therefore, the optimal order of accuracy, in this case $3$, is obtained on smooth data if
	\begin{equation} \label{eq:wmend}
		d_k-\omega_k = \mathcal{O}(h), \quad k=0,L,R.
	\end{equation}
}

\revision{
	We investigate numerically the convergence rate $d_k-\omega_k$ when the nonlinear weights are computed on a low order approximation of the cell-averages of a smooth function $u$. Thus, let us consider
	$$
	u(x) = \sin(\pi x)+\sin(15\pi x) \exp(-20x^2), \quad x\in[-1,1].
	$$
	We discretize the space domain by $N$ cells with periodic boundary conditions. We take the optimal weights $d_0 = 0.75$, $d_L = d_R = 0.125$. Then, we compute the nonlinear weights $\hat{\omega}_{j,k}$, $k=0,L,R$, based on a first order approximation of the cell averages of $u$ in the $j$-th cell, and the nonlinear weights $\omega_{j,k}$, $k=0,1,2$, on a third order approximation of the cell averages of $u$ in the $j$-th cell. We study the behavior of the errors
	\begin{equation*} \label{eq:err3}
		\begin{aligned}
			\hat{e}(N) &= \frac{1}{N} \sum_{j=1}^N \max_{k=0,L,R} |d_k-\hat{\omega}_{j,k}| \\
			e(N) &= \frac{1}{N} \sum_{j=1}^N \max_{k=0,L,R} |d_k-\omega_{j,k}|
		\end{aligned}
	\end{equation*}
	under grid refinement. The results are given in Table~\ref{tab:order3_omegad} which shows that the sufficient condition on the convergence rate of the nonlinear weights to the linear weights to guarantee optimal accuracy is fulfilled in both cases. In Quinpi the accuracy conditions in~\eqref{eq:rec:accuracy} are guaranteed since the $\Popt$ and $P_k$ polynomials are computed on the high order cell averages in the nonlinear solver, while the first order predictor is accurate enough to guarantee condition~\eqref{eq:wmend} on the nonlinear weights.
}

\begin{table}[t!]
	\centering
	\caption{Experimental convergence of the nonlinear to the linear weights.\label{tab:order3_omegad}}
	\begin{tabular}{ccccc}
		\toprule
		$N$ & $\hat{e}$ & rate & $e$ & rate \\
		\midrule
		20 & 3.58e-1 & -      & 3.83e-1 & - \\
		40 & 2.56e-1 & 0.48   & 2.92e-1 & 0.39 \\
		80 & 2.43e-1 & 0.08   & 2.46e-1 & 0.25 \\
		160 & 1.57e-1 & 0.63  & 1.56e-1 & 0.65 \\
		320 & 7.23e-2 & 1.12  & 7.23e-2 & 1.11 \\
		640 & 3.96e-2 & 0.87  & 3.96e-2 & 0.87 \\
		1,280 & 1.76e-2 & 1.17 & 1.76e-2 & 1.17 \\
		2,560 & 5.59e-3 & 1.65 & 5.59e-3 & 1.65 \\
		5,120 & 1.37e-3 & 2.03 & 1.37e-3 & 2.03 \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Conservative a-posteriori time-limiting based on numerical entropy} \label{sec:quinpi:entropy}

The solution obtained with the predictor-corrector approach is third order accurate, and has \revision{some} control over spurious oscillations thanks to the limited CWENO space reconstruction. However, when using a large $\Delta t$, space limiting is not enough, and the high order solution may still exhibit oscillations as already noticed in~\cite{PSV23:Quinpi,2020Arbogast,2007DurasaisamyBaeder}. In such situations, limiting in time is also required.
\revision{For this reason,} the Quinpi scheme that we propose in this paper employs a time-limiting procedure of the third order solution.

In~\cite{PSV23:Quinpi} the time-limiting is performed in a WENO-like framework. In fact, nonlinear weights are suitably defined in order to blend \revision{cell averages} between the computed high order solution and the low order predictor, which is reliable, stable and non-oscillatory. However, the procedure in~\cite{PSV23:Quinpi} does not \revision{preserve} mass conservation property and must be followed by a suitable conservative correction, analogously to~\cite{Marsha:AMR} in adaptive mesh refinement.

\revision{Extending the conservative correction of~\cite{PSV23:Quinpi} to a generic system~\eqref{eq:hyp:sys} is nontrivial. Instead,} conservation can be ensured avoiding a cell-centered blending by means of flux-based Runge-Kutta, as, e.g., in~\cite{Ketcheson:fluxbased:2013,2020Arbogast}.
Similarly, a flux-centered conservative a-posteriori time-limiting inspired by the MOOD technique~\cite{CDL11:MOOD,CDL12:MOOD} was investigated in~\cite{VTSP23:Quinpi:Book}. MOOD was originally designed as an a-posteriori space-limiting technique for multi-dimensional finite volume schemes. Instead, in~\cite{VTSP23:Quinpi:Book}, the typical MOOD detectors were used to limit the high order solution at time level $(n+1)\Delta t$. \revision{However, contrary to the classical MOOD approach, in~\cite{VTSP23:Quinpi:Book} the method uses a convex combination of the high order and the low-order numerical fluxes at the interfaces of oscillatory cells.} A similar idea was also employed in~\cite{EBS22:Implicit:Networks} for a-posteriori limiting of fully implicit finite volume schemes on transport networks.

In this paper we still rely on the MOOD technique, and the high order numerical fluxes of oscillatory cells are dropped to the low-order numerical fluxes of the predictor. The novelty here is that the detection of troubled cells is performed with the numerical entropy production introduced in~\cite{PS11:numerical:entropy,Puppo04:numerical:entropy}, extended to balance laws in~\cite{PS16:entropy:balance}, and already exploited in \cite{SCR:CWENOquadtree,SL:18:AMRMOOD} as a-posteriori error of adaptive schemes and indicator of the qualitative structure of the flow.

\subsubsection{Indicators based on numerical entropy production} \label{sec:quinpi:entropy:indicators}

Assume that system~\eqref{eq:hyp:sys} is endowed with an entropy-entropy flux pair, namely \revision{that there exists} a convex function $\mathbf{u}\in\R^m\mapsto\eta(\mathbf{u})\in\R$ and a corresponding entropy flux $\mathbf{u}\in\R^m\mapsto\psi(\mathbf{u})\in\R$ such that $\nabla^T\eta(\mathbf{u}) \mathbf{f}^\prime(\mathbf{u})=\nabla^T\psi(\mathbf{u})$. Then, all entropy solutions of~\eqref{eq:hyp:sys} satisfy the entropy inequality
\begin{equation} \label{eq:entropy}
	\frac{\partial}{\partial t} \eta(\mathbf{u}(x,t)) + \frac{\partial}{\partial x} \psi(\mathbf{u}(x,t)) \leq 0,
\end{equation}
in the weak sense. It is well known that~\eqref{eq:entropy} is an equality on smooth flows. Instead, if the solution has a singularity, the sign of~\eqref{eq:entropy} selects the unique physically admissible weak solution of~\eqref{eq:hyp:sys}. For this reason, the novel idea of~\cite{Puppo04:numerical:entropy} was to consider the numerical residual of
the entropy inequality as an a-posteriori error indicator for the numerical solution of~\eqref{eq:hyp:sys}, since it is a scalar value (even in the case of systems of conservation laws) which provides information on the size of the local truncation error and on the presence of singularities. Recently, the numerical entropy residual has been employed also in the context of stochastic Galerkin formulations of hyperbolic systems, see~\cite{2023GersterSemplice}.

Following~\cite{PS11:numerical:entropy} we give the subsequent definition.

\begin{definition}
	Let $\ca{\mathbf{U}}^n$ be the solution of~\eqref{eq:spaceApprox} obtained using a $s$-stage Runge-Kutta scheme of order $p$ with weights $\{ b_i \}_{i=1}^s$ and time-step $\Delta t$. Then, the numerical entropy production $\left(S^p\right)_j^n$ of the scheme in the control volume $V_j^n = \Omega_j \times [n\Delta t , (n+1)\Delta t]$ is given by
	\begin{equation} \label{eq:numerical:entropy}
		\left(S^p\right)_j^n = \frac{1}{\Delta t} \left[ \ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n+1} \right) \right)_j - \ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n} \right) \right)_j + \frac{\Delta t}{h} \sum_{i=1}^s b_i \left( \Psi_{j+\frac12}^{(i)} - \Psi_{j-\frac12}^{(i)} \right) \right]
	\end{equation}
	where
	$$
	\Psi_{j+\frac12}^{(i)} = \Psi\left( \mathbf{U}_{j+\frac12}^{-,(i)},\mathbf{U}_{j+\frac12}^{+,(i)} \right),
	$$
	is a numerical entropy flux function consistent with the exact entropy flux $\psi$ of~\eqref{eq:entropy}, with $(\mathbf{v},\mathbf{w}) \in \R^m\times\R^m \to \Psi(\mathbf{v},\mathbf{w})\in\R$, and where $\ca{\mathbf{U}}_{j\pm\nicefrac12}^{\mp},(i)$ are the BED of the numerical solution. In~\eqref{eq:numerical:entropy}, $\ca{Q}\left( \cdot \right)_j$ denotes a quadrature rule of order $p$ to compute the cell average on the cell $\Omega_j$.
\end{definition}

The rate of convergence of~\eqref{eq:numerical:entropy} is shown in~\cite{PS11:numerical:entropy}. In particular, for a general numerical scheme of order $p$ one has
$$
\left(S^p\right)_j^n = \begin{cases}
	\mathcal{O}(h^p), & \text{if the solution is regular on $\Omega_j$} \\
	\mathcal{O}(h^{-1}), & \text{if the solution has a shock on $\Omega_j$} \\
	\mathcal{O}(h), & \text{if $\Omega_j$ exhibits a rarefaction corner} \\
	\mathcal{O}(1), & \text{if $\Omega_j$ exhibits a contact wave}.
\end{cases}
$$
In other words, $\left(S^p\right)_j^n\to 0$, as $h\to 0$, with the same rate of the local truncation error of the scheme on smooth flows. Whereas, the numerical entropy production increases in magnitude on shocks.

For the first order predictor solution $\ca{\bigvec{U}}^\star$, defined in Section~\ref{sec:quinpi:predictor}, we can consider the midpoint quadrature rule and observe that the cell average and the \revision{pointwise} value at the cell center are $\mathcal{O}(h^2)$ apart, and thus set
$
\ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n} \right) \right)_j =  \eta\left(\ca{\mathbf{U}}_j^{n}\right),
$
in~\eqref{eq:numerical:entropy}. The numerical entropy production becomes
\begin{equation} \label{eq:entropy:1}
	\left(S^1\right)_j^n = \frac{1}{\Delta t} \left[ \eta\left( \ca{\mathbf{U}}^{\star,n+1}_j \right) - \eta\left( \ca{\mathbf{U}}^{\star,n}_j \right) + \frac{\Delta t}{h} \sum_{i=1}^s \theta_i \left( \Psi_{j+\frac12}^{\star,(i)} - \Psi_{j-\frac12}^{\star,(i)} \right) \right],
\end{equation}
where
$$
\Psi_{j+\frac12}^{\star,(i)} = \Psi\left( \mathbf{U}_j^{\star,(i)},\mathbf{U}_{j+1}^{\star,(i)} \right).
$$
Instead, for the third order solution $\ca{\bigvec{U}}$ defined in Section~\ref{sec:quinpi:corrector}, in this work we consider the two-point Gauss-Legendre quadrature rule:
$$
\ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n} \right) \right)_j = \frac{1}{2} \left( \eta\left(\mathbf{U}_{j-\frac{\sqrt{3}}{6}}^{n}\right) + \eta\left(\mathbf{U}_{j+\frac{\sqrt{3}}{6}}^{n}\right) \right),
$$
where $\mathbf{U}_{j\pm\nicefrac{\sqrt{3}}{6}}^{n}$ denote the reconstructions of the solution in $x_j\pm\nicefrac{\sqrt{3}h}{6}$. Observe that the computation of the quadrature rule does not require significant additional computational cost since the computation of $\mathbf{U}_{j\pm\nicefrac{\sqrt{3}}{6}}^{n}$ involves just the evaluation of a CWENO reconstruction polynomial, which is already available, because it is computed in order to advance the solution from $n\Delta t$ to $(n+1)\Delta t$. Thus, for the third order solution, the numerical entropy production becomes
\begin{equation} \label{eq:entropy:3}
	\begin{aligned}
		\left(S^3\right)_j^n = \frac{1}{\Delta t}  
		\bigg[ &\frac{1}{2} \left( \eta\left(\mathbf{U}_{j-\frac{\sqrt{3}}{6}}^{n+1}\right) + \eta\left(\mathbf{U}_{j+\frac{\sqrt{3}}{6}}^{n+1}\right) \right) - \frac{1}{2} \left( \eta\left(\mathbf{U}_{j-\frac{\sqrt{3}}{6}}^{n}\right) + \eta\left(\mathbf{U}_{j+\frac{\sqrt{3}}{6}}^{n}\right) \right)  \\
		& + \frac{\Delta t}{h} \sum_{i=1}^s b_i \left( \Psi_{j+\frac12}^{(i)} - \Psi_{j-\frac12}^{(i)} \right) \bigg].
	\end{aligned}
\end{equation}

At the discrete level, $\left(S^1\right)_j^n$ and $\left(S^3\right)_j^n$ provide a regularity indicator of the predictor and of the corrector solution, respectively. Therefore, in order to determine where time-limiting has to occur, we detect spurious oscillations using $\left(S^1\right)_j^n$ and $\left(S^3\right)_j^n$ in the following ways.
\begin{description}
	\item[$\mathcal{I}_1$:] The indicator~\eqref{eq:entropy:3} of the third order scheme is used to detect troubled cells. We expect that on smooth cells $\Omega_j$ one has $\left(S^3\right)_j^n = \mathcal{O}(h^3)$, whereas $\left(S^3\right)_j^n = \mathcal{O}(h^{-1})$ in presence of shocks. In particular, a cell $\Omega_j$ is marked for time-limiting if
	\begin{equation} \label{eq:strategy1}
		\left(S^3\right)_j^n > \gamma_{1},
	\end{equation}
	where $\gamma_{1}$ is a given threshold.
	\item[$\mathcal{I}_2$:] The ratio of the indicators~\eqref{eq:entropy:1} and~\eqref{eq:entropy:3} is used to detect problematic cell $\Omega_j$ whenever
	\begin{equation} \label{eq:strategy2}
		\frac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n+\sigma} > \gamma_{2},
	\end{equation}
	where $\gamma_{2}$ is a given threshold and $\sigma$ \revision{is} a small quantity which prevents $\nicefrac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n} \sim \mathcal{O}(1)$ on constant regions of the solution. In fact, we expect that on a smooth cell $\Omega_j$ one has $\nicefrac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n} = \mathcal{O}(h^2)$, whereas $\nicefrac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n} = \mathcal{O}(1)$ if the solution is not regular on $\Omega_j$.
	\item[$\mathcal{I}_3$:] Both the detecting techniques $\mathcal{I}_1$ and $\mathcal{I}_2$ are used, so that a cell $\Omega_j$ is marked for time-limiting if
	\begin{equation} \label{eq:strategy3}
		\left(S^3\right)_j^n > \gamma_{1} \ \text{ and } \ \frac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n+\sigma} > \gamma_{2}.
	\end{equation}
	\revision{We will compare these strategies in the numerical section. For now let us remark that $\mathcal{I}_2$ should be more robust than $\mathcal{I}_1$ since it involves ratios, but that it may fail on flat regions where both $S^3$ and $S^1$ can be floating point zeros. Thus in $\mathcal{I}_3$ we propose to combine} the $\mathcal{I}_1$ and the $\mathcal{I}_2$ strategies. In fact, the $\mathcal{I}_2$ strategy may mark \revision{flat} regions as irregular cells, i.e.~where a shock appears, if $\left(S^3\right)_j^n = \mathcal{O}(\left(S^1\right)_j^n)$. Then, the $\mathcal{I}_1$ strategy allows to detect the regularity of the solution. 
\end{description}

\revision{The thresholds $\gamma_1$ and $\gamma_2$ are very important for the performance of the regularity detection. We will come back to this point in Section~\ref{sec:numerics} when we discuss the values we choose for the two thresholds.}

\subsubsection{Time limited solution and the final Quinpi algorithm}

% Figure environment removed

Once the detector has been chosen, the flux-centered time-limiting is performed by computing the limited numerical flux $\NumFlux^{\mathsf{TL},(k)}_{j+\nicefrac12}$
for the face between $\Omega_{j}$ and $\Omega_{j+1}$, for 
all stages $k=1,\dots,s$, as
\begin{equation} \label{eq:timelimited:fluxes}
	\NumFlux^{\mathsf{TL},(k)}_{j+\frac12} = \begin{cases}
		\theta_k \NumFlux^{\star,(k)}_{j+\frac12}, & \text{if either $\Omega_j$ or $\Omega_{j+1}$ is marked},\\[2ex]
		b_k \NumFlux^{(k)}_{j+\nicefrac12}, & \text{if both $\Omega_j$ and $\Omega_{j+1}$ are not marked},
	\end{cases}
\end{equation}
where the acronym $\mathsf{TL}$ stands for Time-Limited. Notice that, since the predictor scheme is based on a composite backward Euler, the low order numerical fluxes $\NumFlux^{\star,(k)}_{j\pm\nicefrac12}$ are available at each stage $k=1,\dots,s$, for $j=1,\dots,N$.

Thus, the high order numerical fluxes at the interfaces of a problematic cell $\Omega_j$ are replaced with the low order numerical fluxes reducing locally the order of the solution, which is then computed as
\begin{equation} \label{eq:timelimited:sol}
	\ca{\mathbf{U}}_j^{n+1} = \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{k=1}^s \left[ \NumFlux_{j+\tfrac12}^{\mathsf{TL},(k)} - \NumFlux_{j-\tfrac12}^{\mathsf{TL},(k)} \right], \quad j=1,\dots,N.
\end{equation}
The time-limiting procedure is repeated until the solution $\ca{\bigvec{U}}^{n+1}$ is detected as smooth on each cell.

Overall, the update of the solution from time $n\Delta t$ to time $(n+1)\Delta t$ computed with the Quinpi scheme is summarized in Figure~\ref{fig:algorithm}. 