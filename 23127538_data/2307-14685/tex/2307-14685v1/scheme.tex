\section{Third order space-time fully implicit discretization} \label{sec:scheme}

We consider a finite volume approximation of~\eqref{eq:hyp:sys} through the method of lines (MOL) on the compact computational domain $\Omega=[a,b]\subset\mathbb{R}$. To this end, we discretize $\Omega$ with $N$ uniform cells $\Omega_j=[x_j-\nicefrac{h}{2},x_j+\nicefrac{h}{2}]$ of amplitude $h>0$, such that $\cup_{j=1}^N \Omega_j=\Omega$ and $x_j = a + (j-\nicefrac12)h$ are the cell centers. For the sake of simplicity, we will describe the scheme for a uniform grid, but it is easy to generalize the scheme to a non uniform mesh. 
Defining the cell averages of the exact solution on a given space cell $\Omega_j$ as
$$
	\ca{\mathbf{u}}_j(t)= \frac1h \int_{\Omega_j} \mathbf{u}(x,t) \dx, \quad t \geq 0
$$
the MOL provides the following semi-discrete form of system~\eqref{eq:hyp:sys}:
\begin{equation} \label{eq:MOL}
	\TotDer{\ca{\mathbf{u}}_j(t)}{t} = -\frac{1}{h}\left[ \mathbf{f}\left(\mathbf{u}_{j+\frac12}(t)\right) - \mathbf{f}\left(\mathbf{u}_{j-\frac12}(t)\right)\right], \quad j=1,\dots,N, \ t\geq 0,
\end{equation}
where $\mathbf{u}_{j\pm\nicefrac12}(t) = \mathbf{u}\left(x_j\pm\nicefrac{h}{2},t\right)$. System~\eqref{eq:MOL} describes the conservation of the cell averages as the difference of the outgoing and incoming fluxes at the cell boundaries. Up to now, no numerical approximation of the exact solution has been introduced. In fact, \eqref{eq:MOL} is still exact.

In order to transform the MOL in a numerical scheme, one has to introduce a time discretization of the coupled ODE system~\eqref{eq:MOL} which evolves in time the cell averages. Consequently, there is the problem of the knowledge of point values of the solution at the cell interfaces for the evaluation of the flux function. The extrapolation of these values from the cell averages is the so-called \emph{reconstruction problem}. WENO and CWENO schemes, see e.g.~\cite{JiangShu:96,Shu:97,LPR:00:SIAMJSciComp,CPSV:cweno}, and their developments~\cite{Balsara:AOWENO,CCD:11,ABC16:improvedWENOZ,SempliceVisconti:2020}, are examples of numerical procedures computing point values as function of the cell averages. The advantage of WENO and CWENO schemes is that they achieve high order approximations of the reconstructions, but they pay the price of enlarging the stencil, compared to low order schemes, and of being highly nonlinear, which is a computational bottleneck in implicit time integration.

In the following, before dealing with the time integration of~\eqref{eq:MOL}, we recall the space reconstruction based on the recently developed CWENO scheme~\cite{STP23:cweno:boundary}.

\subsection{Space reconstruction: third order CWENOZ without ghost cells} \label{sec:scheme:cweno}

In reconstruction procedures, the goal is to provide a space limited approximation of the exact solution $\mathbf{u}(\cdot,t)$, at a given time $t\geq 0$, using the knowledge of its cell averages. Since the reconstruction is typically applied component-wise, we will describe the procedure on a component $u$ of the vector solution $\mathbf{u}$.

A CWENO type reconstruction defines an approximation of $u(\cdot,t)$ as
$$
	u(x,t) \approx \sum_{j=1}^N R_j(x;t)\chi_{\Omega_j}(x), \quad t\geq 0,
$$
where $\chi_{\Omega_j}$ is the characteristic function of the cell $\Omega_j$, and $R_j(x;t)$ is the reconstruction polynomial on $x\in\Omega_j$, which depends on time through the time-dependent cell averages. If the desired reconstruction point, say $\hat{x}$, lies within the cell $\Omega_j$, then the evaluation of the polynomial $R_j(\hat{x};t)$ provides the needed point values of $u(\hat{x},t)$. The CWENO type procedure differs from the classical WENO scheme by the fact that each polynomial $R_j(x;t)$ is globally defined in its reference cell $\Omega_j$ and, therefore, it can be pre-computed and later evaluated at the needed locations.

We focus on third order space reconstructions. Then, the CWENO scheme with Z-type nonlinear weights~\cite{CCD:11,CSV19:cwenoz} defines the polynomial $R_j(x;t)$ on $x\in\Omega_j$ as follows.

\begin{definition}[Third order CWENOZ reconstruction, see~\cite{CSV19:cwenoz}] \label{def:CWENOZ}
	Let $\Popt\in\Poly{2}$ be the \emph{optimal} polynomial of degree $2$, which interpolates all the data in the three-cell stencil $\Sopt = \{ \Omega_{j-1}, \Omega_j, \Omega_{j+1} \}$. Further, let ${P}_L, {P}_R\in\Poly{1}$ be polynomials of degree $1$ such that $P_L$ interpolates the cell averages of the left-biased sub-stencil $\mathcal{S}_L = \{ \Omega_{j-1}, \Omega_j \}$, and $P_R$ interpolates the cell averages of the right-biased sub-stencil $\mathcal{S}_R = \{ \Omega_j, \Omega_{j+1} \}$.
	Let also $\{d_0,d_L,d_R\}$ be a set of strictly positive real coefficients such that $\sum_{k=0,L,R} d_k=1$.
	
	The CWENOZ procedure computes the reconstruction polynomial on $\Omega_j$ as
	\begin{equation}
		R_j^{\mathsf{CWZ}}(x;t) 
		= \frac{\omega_0}{d_0} \left( \Popt(x;t) - \sum_{k=L,R} d_k P_k(x;t) \right) + \sum_{k=L,R} \omega_k P_k(x;t) \in\Poly{2}, \label{eq:precCWZ}
	\end{equation}
	where $\omega_0$, $\omega_L$ and $\omega_R$ are the (nonlinear) coefficients defined as
	\begin{equation} \label{eq:omegaZ}
		\alpha_k = {d_k} \left( 1 + \left( \frac {\tau} {I_k+\epsilon} \right)^{p} \right),
		\qquad
		\omega_k = \frac{\alpha_k}{\sum_{i=L,0,R}\alpha_i}, \quad k=0,L,R.
	\end{equation}
	In~\eqref{eq:omegaZ}, $I_0$, $I_L$ and $I_R$ are the regularity indicators of the associated polynomials $P_L$, $\Popt$ and $P_R$, respectively, computed as the Jiang-Shu indicators from~\cite{JiangShu:96}:
	\begin{equation} \label{eq:ind}
		I[P_k] := 
			\sum_{i=1}^{\deg(P_k)}  h^{2i-1} \int_{\Omega_j} \left(\frac{\d^i}{\dx^i} P_k(x;t)\right)^2 \dx, \quad k=0,L,R.
	\end{equation}		
	Finally, $\epsilon=h^{q}$, $q\geq 1$, $p \ge 1$ and $\tau$ is the following global smoothness indicator 
	\begin{equation}  \label{eq:tau}
		\tau := \left| 2I_0 - I_L - I_R \right|.
	\end{equation}
\end{definition}

The CWENOZ reconstruction polynomial switches between the high accurate polynomial $\Popt$, when the cell averages in the stencil $\Sopt$ are a sampling of a smooth enough function, and a nonlinear blending of $\Popt$ and of the lower degree polynomials $P_L, P_R$ when a discontinuity is present in the stencil $\Sopt$. 
%The switch is automatically performed thanks to the definition of the nonlinear weights $\omega_0$, $\omega_L$ and $\omega_R$, computed with the help of the regularity indicators~\eqref{eq:ind}. In practice, these are of order $o(1)$ when the stencil $\Sopt$ is smooth, so that $\omega_i \approx d_i$, $i=0,L,R$, and thus $R_j^{\mathsf{CWZ}} \approx \Popt$. In this case, the reconstruction is able to achieve the maximal desired order of accuracy. Instead, the regularity indicator of a polynomial interpolating discontinuous data is of order $\mathcal{O}(1)$, so that the corresponding nonlinear weight deviates from its optimal value, avoiding the appearance of spurious oscillations in the reconstruction polynomial.

The use of the Z-type weights~\eqref{eq:omegaZ} allows to have better accuracy on smooth data compared to classical weights~\cite{CPSV:cweno,Shu:97}, especially on coarse grids, without sacrificing the non-oscillatory properties. This is obtained by using the optimal choice~\eqref{eq:tau} of the global smoothness indicator that makes $\tau$ much smaller than the regularity indicators when the data in $\Sopt$ are smooth enough. %Typically, $\tau$ is restricted to be a linear combination of the other smoothness indicators for efficiency. For results on the optimal choices of $\tau$ we refer to~\cite{CSV19:cwenoz}.
In~\cite{CSV19:cwenoz}, it is proven that the accuracy of the CWENOZ reconstruction on smooth flows is the optimal one, provided that $\deg(\Popt) \leq 2\deg(P_k)$, for $k = L,R$. %This condition is satisfied by the third-order reconstruction in Definition~\ref{def:CWENOZ}.

Close to boundaries, the central stencil $\Sopt$ may not be defined, because it would not be fully contained in $\Omega$. In this case, one can consider for $\Popt$ a 3-cell stencil entirely biased towards the domain interior, but the need of controlling spurious oscillations requires the inclusion of a polynomial $\tilde{P}\in\Poly{0}$. Optimal accuracy can still be achieved provided the corresponding linear weight is infinitesimal of order $\mathcal{O}(h^r)$, for some $r > 0$. This approach was introduced for CWENOZ type reconstructions in~\cite{SempliceVisconti:2020}, where a thorough study of sufficient conditions on $r$, and on the other parameters of the scheme, to achieve optimal accuracy has been performed, and exploited for reconstructions free of ghost cells in \cite{STP23:cweno:boundary}. In the following definition, we recall a particular third-order CWENOZ Adaptive Order reconstruction which will be used to define the boundary reconstruction.
%can be recast in the framework of~\cite{SempliceVisconti:2020}.

\begin{definition}[Third order CWENOZ reconstruction without ghost cells, see~\cite{STP23:cweno:boundary}] \label{def:CWENOZb}
	Let $R_j(x;t)$ be the reconstruction polynomial related to the cell $\Omega_j$. Then,
	\begin{equation} \label{eq:precCWZb}
		R_j(x;t) =
			\begin{cases}
				R_j^{\mathsf{CWZ}}(x;t), & j=2,\dots,N-1, \\[1ex]
				R_j^{\mathsf{AO}}(x;t), & j=1 \ \mbox{ with } \ \Sopt=\{\Omega_1,\Omega_2,\Omega_3\}, \\[1ex]
				R_j^{\mathsf{AO}}(x;t), & j=N \ \mbox{ with } \ \Sopt=\{\Omega_{N-2},\Omega_{N-1},\Omega_N\},
			\end{cases}
	\end{equation}
	where $\tau_j = \tau$ in~\eqref{eq:tau}, for $j=2,\dots,N-1$, and $\tau_1=\tau_2$, $\tau_N=\tau_{N-1}$.
\end{definition}

The reconstruction in the first and last computational cells appearing in \eqref{eq:precCWZb} are defined exploting the results  in \cite{SempliceVisconti:2020}, which we report here for completeness in the third order case.

\begin{definition}[Third order CWENO-AO reconstruction, see~\cite{SempliceVisconti:2020}] \label{def:CWENOZAO}
	Let $\Popt\in\Poly{2}$ be the \emph{optimal} polynomial of degree $2$ which interpolates all the given data in the three-cell stencil $\Sopt$ such that $\Omega_j \in \Sopt$. Let $P\in\Poly{1}$ be the polynomial of degree $1$ such that $P$ interpolates the cell averages of a two-cell sub-stencil $\mathcal{S}$ such that $\Omega_j\in\mathcal{S}\subset\Sopt$. Further, let $\tilde{P}\in\Poly{0}$ be the constant polynomial associated to the sub-stencil $\tilde{\mathcal{S}} = \{ \Omega_j \}$.
	Let also $\{d_0,d,\tilde{d}\}$ be a set of strictly positive real coefficients such that $d_0+d+\tilde{d}=1$ and $\tilde{d}=h^r$ for some $r>0$.
	
	The CWENOZ-AO reconstruction polynomial on $\Omega_j$ is
	\begin{equation}
		R_j^{\mathsf{AO}}(x;t) 
		= \frac{\omega_0}{d_0} \left( \Popt(x;t) - d P(x;t) - \tilde{d} \tilde{P}(x;t) \right) + \omega P(x;t) + \tilde{\omega} \tilde{P}(x;t) \in\Poly{2}, \label{eq:precAO}
	\end{equation}
	where $\omega_0$, $\omega$ and $\tilde{\omega}$ are the (nonlinear) Z-type coefficients, see~\eqref{eq:omegaZ}, associated to the regularity indicators $I_0$, $I$ and $\tilde{I}$, respectively for the polynomials $\Popt$, $P$ and $\tilde{P}$, see~\eqref{eq:ind}.

Since $\tilde{I}=0$, the global smoothness indicator $\tau$ 
in this case can be chosen as
\begin{equation} \label{eq:tauAO}
	\tau := \left| I -  I_0 \right|,
\end{equation}
\end{definition}

%Another useful application of 
% The CWENOZ-AO reconstruction is very useful to avoid the need of ghost cells to impose boundary conditions,  
%provided by the boundary treatment which is typically performed by enlarging the computational domain with ghost cells and by setting their values according to the boundary conditions. In this way, classical high order non-oscillatory reconstruction procedures, as the CWENOZ in Definition~\ref{def:CWENOZ}, can be computed on every cell in the domain, also close to the boundaries. Instead, the ability of designing reconstructions with low degree polynomials, as in CWENOZ-AO in Definition~\ref{def:CWENOZAO}, allows to consider a different strategy, 
% see~\cite{STP23:cweno:boundary,NKS:18}. There, third-order reconstructions that do not make use of ghost cells have been investigated, where the stencil for the first and last cell at the boundary extends towards the interior of the computational domain. Thus, we can give the following definition.


%More precisely, for an interior cell $\Omega_j$, $j=2,\dots,N-1$, one builds the reconstruction polynomial as in Definition~\ref{def:CWENOZ}. This reconstruction can be computed on every cell $\Omega_j$ of the computational domain $\Omega$ except for the first and the last ones close to boundary without enlarging the domain with ghost cells. Therefore, in the first cell of the domain $\Omega$, the reconstruction polynomial is built with the adaptive order procedure given in Definition~\ref{def:CWENOZAO} on the stencil $\Sopt = \{\Omega_1,\Omega_2,\Omega_3\}$ which does not involve ghost cells. Moreover, since the role of the global smoothness is to detect smooth flows in the global stencil $\Sopt$, which is composed by the first three cells and, thus, coincides with the stencil employed by the second cell, following~\cite{STP23:cweno:boundary} $\tau_1$ is taken as the global smoothness indicator $\tau_2$ computed for the second cell. This choice allows, from one hand, to save computations, and, from the other hand, to guarantee that $\tau_1$ is much smaller than the regularity indicators on smooth flows, yielding a better reconstruction. Similar considerations hold for the last cell, which is treated symmetrically to the first one.

The analysis in~\cite{SempliceVisconti:2020} shows that the reconstruction of Definition~\ref{def:CWENOZb} achieves third order of accuracy for $r=1,2$, provided that the exponent $p$ in \eqref{eq:omegaZ} is $p \geq 1$ and that $\epsilon=h^q$ for $q=1,2,3$.

%\begin{notation} \label{notation:poly}
%In the following, for convenience of notation, we denote $P_L$ the constant polynomial on its stencil denoted by $\mathcal{S}_L=\{\Omega_1\}$ and $P_R$ the linear polynomial interpolating the data in its stencil denoted by $\mathcal{S}_R=\{\Omega_1,\Omega_2\}$ when the reconstruction on $\Omega_1$ is performed. Symmetrically, for the last cell.
%\end{notation}

%In the following, for convenience, we illustrate the boundary reconstruction on the left boundary for the cell $\Omega_1$.

The reconstruction polynomial $R_j(x;t)$ given in~\eqref{eq:precCWZb} provides the approximation of each quantity of interest $u\in\mathbf{u}$. Thus, one can estimate the values $u\left(x_j\pm\nicefrac{h}{2},t\right)$, $t\geq 0$, with
\begin{subequations} \label{eq:bed}
	\begin{gather}
		u^-_{j+\frac12}(t)=R_{j}\left(x_j+\frac{h}{2};t\right) \ \text{ and } \ u^+_{j+\frac12}(t)=R_{j+1}\left(x_j+\frac{h}{2};t\right), \quad j=1,\dots,N-1 \label{eq:bed:interior} \\
		u^-_{\frac12}(t)=u^-_{\mathsf{out}} \ \text{ and } \ 	u^+_{\frac12}(t)=R_1\left(a;t\right) \label{eq:bed:first} \\
		u^-_{N+\frac12}(t)=R_N\left(b;t\right) \ \text{ and } \ 	u^+_{N+\frac12}(t)=u^+_{\mathsf{out}} \label{eq:bed:last}	
	\end{gather}
\end{subequations}
which are named \emph{boundary extrapolated data} (BED). The outer values $u^{\mp}_{\mathsf{out}}$ are determined by the boundary conditions. For instance, for periodic boundary conditions the outer values $u^{\mp}_{\mathsf{out}}$ are set to the inner reconstructions at the last and first interfaces, respectively. Instead, for zero Neumann boundary conditions, the outer values $u^{\mp}_{\mathsf{out}}$ are set to the inner reconstructions at the first and last interfaces, respectively.

Notice that at each interface the two BED in~\eqref{eq:bed} are different, although computed at the same interface $x_{j+\nicefrac{h}{2}}$. Therefore, in order to approximate the flux function at the interfaces, one introduces a consistent and monotone numerical flux function $\NumFlux:\R\times\R\to\R$ such that
\begin{subequations} \label{eq:numfluxfnc}
\begin{equation}
	(\mathbf{v},\mathbf{w}) \in \R^m\times\R^m \mapsto \NumFlux(\mathbf{v},\mathbf{w}) \in \R^m,
\end{equation}
where $\NumFlux(\mathbf{v},\mathbf{w}) = \left[ \NumFlux(v_1,w_1),\dots,\NumFlux(v_m,w_m) \right]$, and
\begin{equation}
	\mathbf{f}\left(\mathbf{u}(x_{j+\frac{1}{2}},t)\right) \approx %\NumFlux_{j+\nicefrac12}(t) = 
	\NumFlux\left(\mathbf{u}^-_{j+\frac12}(t),\mathbf{u}^+_{j+\frac12}(t)\right) \in \R^m.
\end{equation}
\end{subequations}
The function $\NumFlux$ may be any approximate or exact Riemann solver, which is applied component-wise on vector-valued inputs. Finally, the exact system of ODEs~\eqref{eq:MOL} is reduced to a finite system of ODE's for the evolution of the cell averages. The right hand side is completely defined by the space reconstruction along with the numerical flux, and one obtains
\begin{equation} \label{eq:spaceApprox}
	\TotDer{\ca{\mathbf{U}}_j(t)}{t} = - \frac{1}{h}\left[ \NumFlux_{j+\frac12}(t)-\NumFlux_{j-\frac12}(t)\right],
\end{equation}
which provides the approximation $\ca{\mathbf{U}}_j(t)$ of the cell averages $\ca{\mathbf{u}}_j(t)$ of the solution $\mathbf{u}(x,t)$, $x\in\Omega_j$, and where
\begin{equation} \label{eq:numflux}
	\NumFlux_{j+\frac12}(t) = \NumFlux\left(\mathbf{U}^-_{j+\frac12}(t),\mathbf{U}^+_{j+\frac12}(t)\right) \in \R^m,
\end{equation}
with $\mathbf{U}^{\mp}_{j+\nicefrac12}(t)$ BED of the data $\ca{\mathbf{U}}(t) = \left[\ca{\mathbf{U}}_1(t),\dots,\ca{\mathbf{U}}_N(t)\right]^T$ according to~\eqref{eq:bed}.

%In the following, we use the reconstruction of Definition~\ref{def:CWENOZb} in the implicit time treatment of system~\eqref{eq:spaceApprox}.

\subsection{Time integration: third order Diagonally Implicit Runge-Kutta} \label{sec:scheme:dirk}

In order to employ a timestep $\Delta t$ which is not constrained by the CFL stability condition,
we solve numerically equation~\eqref{eq:spaceApprox} with a Diagonally Implicit Runge-Kutta (DIRK) scheme with $s$ stages and general Butcher tableau
\begin{equation}
	\label{eq:tableau:dirk}
	\begin{array}{c|cccc}
		c_1 & a_{11} & 0 & \dots & 0 \\[1.5ex]
		c_2 & a_{21} & a_{22} & \dots & 0 \\[1.5ex]
		\vdots & \vdots & \vdots & \ddots & \\[1.5ex]
		c_s & a_{s1} & a_{s2} & \dots & a_{ss} \\[1ex]
		\hline
		&&&&\\[-1.8ex]
		& b_1 & b_2 & \dots & b_s
	\end{array}
\end{equation}
A typical assumption is that $c_k = \sum_{i=1}^s a_{ki}$, $k=1,\dots,s$, and one has $\sum_{k=1}^s b_k=1$ for consistency. 
Further, choosing a scheme in which $a_{kk}$ is independent of $k$, the construction of the Jacobian in the nonlinear solves is simplified.
Clearly, one uses a Butcher tableau with order matching the order of the space reconstruction, in this case a third order accurate scheme. Therefore, DIRK schemes with number of stages $s\geq 2$ must be considered, e.g.~see~\cite{Alexander1977}.

The space-time discretization leads to the fully-discrete scheme
\begin{subequations} \label{eq:implicit}
	\begin{align}
		\ca{\mathbf{U}}_j^{(k)} &= \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{i=1}^k a_{ki} \left[ \NumFlux_{j+\frac12}^{(i)} - \NumFlux_{j-\frac12}^{(i)} \right], \quad k=1,\dots,s, \label{eq:implicit:stage} \\
		\ca{\mathbf{U}}_j^{n+1} &= \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{k=1}^s b_k \left[ \NumFlux_{j+\frac12}^{(k)} - \NumFlux_{j-\frac12}^{(k)} \right], \quad n\geq 0, \label{eq:implicit:update} \\
		\NumFlux_{j+\frac12}^{(k)} &= \NumFlux\left(\mathbf{U}_{j+\frac12}^{-,(k)},\mathbf{U}_{j+\frac12}^{+,(k)}\right) \in \R^m \label{eq:implicit:flux}
	\end{align}
\end{subequations}
for each $j=1,\dots,N$, where $\Delta t$ is the time-step, $\ca{\mathbf{U}}_j^{n} \approx \ca{\mathbf{u}}_j(n\Delta t)$, and $\mathbf{U}_{j+\nicefrac12}^{\mp,(k)}$ are the BED of the stage values $\ca{\bigvec{U}}^{(k)} = \left[ \ca{\mathbf{U}}_1^{(k)}, \dots, \ca{\mathbf{U}}_N^{(k)} \right]^T$, 
approximations of the solution at times $t^{(k)} = (n + c_k) \Delta t$, according to~\eqref{eq:bed}.

The advantage of DIRK schemes is that the implicit computation of a given stage value~\eqref{eq:implicit:stage} can be performed sequentially from $k=1$ to $k=s$. Therefore, at each time-step one has to solve $s$ $Nm$ by $Nm$ systems of nonlinear equations:
\begin{equation}\label{eq:DIRK:stage}
\mathbf{G}\left(\ca{\bigvec{U}}^{(k)}\right) := \ca{\bigvec{U}}^{(k)} 
+ \frac{a_{kk}\Delta t}{h} \Delta \bigvec{F}^{(k)} 
- \ca{\bigvec{U}}^{n} 
+ \frac{\Delta t}{h} \sum_{i=1}^{k-1} a_{ki} \Delta \bigvec{F}^{(i)} = \mathbf{0},
\end{equation}
where $\Delta\bigvec{F}^{(k)} \in \R^{mN}$ whose $j$-th block is 
$ \Delta\bigvec{F}^{(k)}_j = \left( \NumFlux_{j+\nicefrac12}^{(k)}-\NumFlux_{j-\nicefrac12}^{(k)} \right) \in \R^m$, for $j=1,\dots,N$.
Here above we have highlighted the term $\Delta \bigvec{F}^{(k)}$, which makes the system for the $k$-th stage value nonlinear. In fact, the other flux differences $\Delta \bigvec{F}^{(i)}$, $i=1,\dots,k-1$, are already available, thanks to the structure of DIRK schemes.

As already noticed in~\cite{PSV23:Quinpi}, $\mathbf{G}$ has two sources of nonlinearity. One is unavoidable because it is due to the physics when the phenomenon under study is described by a nonlinear flux function $\mathbf{f}$ in~\eqref{eq:hyp:sys}. The second, instead, is introduced by the high order space reconstruction procedure, needed for the computation of the BED, which is highly nonlinear because of the nonlinear weights~\eqref{eq:omegaZ} and of the regularity indicators~\eqref{eq:ind}. Therefore, even for linear PDEs, a standard implicit scheme requires a nonlinear solver to find the solution of $\mathbf{G}(\ca{\bigvec{U}}^{(k)})=\mathbf{0}$, in equation \eqref{eq:DIRK:stage} for $k=1,\dots,s$. Typically, one uses Newton's algorithm, which requires the computation of the Jacobian of the nonlinear system $\mathbf{G}$ resulting in a high computational cost. In fact, the Jacobian required for the Newton iterations has bandwidth one point larger than the stencil size in each direction, so for a third order scheme it is a block-pentadiagonal matrix with $m\times m$ blocks, with entries depending on the nonlinear weights and on the regularity indicators, which have very complicated expressions.

The Quinpi approach, introduced in~\cite{PSV23:Quinpi} for scalar conservation laws, provides a way to circumvent the nonlinearity determined by the high order reconstruction procedure. In the following section, we extend the Quinpi idea to the hyperbolic system~\eqref{eq:hyp:sys}.

\section{Third order Quinpi scheme for one-dimensional hyperbolic systems}
\label{sec:quinpi}

The name Quinpi stands for implicit CWENO and it is based on a predictor-corrector approach to avoid the nonlinearity of the high order scheme, induced by the space reconstruction, and keep the nonlinearity of the flux function $\mathbf{f}$ only.

The Quinpi idea relies on the following considerations on the structure of most essentially-non-oscillatory reconstructions. Since reconstructions are typically applied component-wise, we use the notation for scalar conservation laws in this section.

Let $\mathcal{S}_p = \{ \Omega_{j-p}, \dots, \Omega_{j+p} \}$ be a stencil of $2p+1$ computational cells, and $P\in\Poly{2p}$ be the interpolating polynomial of the cell averages in $\mathcal{S}_p$. Then, the dependence of $P$ on the data is linear, i.e.
\begin{equation*}
	P(x;t) = \sum_{\alpha=-p}^{p} \mu_{j,\alpha}(x) \ca{u}_{j+\alpha}(t).
\end{equation*}
Therefore, unrolling the linearity of all the interpolating polynomial involved in the third order reconstruction procedure of Definition~\ref{def:CWENOZb}, one can write the reconstruction polynomial as
\begin{equation*}
	\begin{aligned}
		R_j(x;t) &= \sum_{i=0,L,R} \omega_i\left(\{\ca{u}_k(t)\}_{k\in\Sopt}\right)	P^i_j(x) \\
		&= \sum_{i=0,L,R} \omega_i\left(\{\ca{u}_k(t)\}_{k\in\Sopt}\right)	\sum_{\alpha=-1}^{1} \mu^{i}_{j,\alpha}(x) \ca{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t) \\
		&= \sum_{\alpha=-1}^{1} W_{j,\alpha} \left(x;\{\ca{u}_k(t)\}_{k\in\Sopt}\right)  \ca{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t),
	\end{aligned}
\end{equation*}
where we have collected the nonlinear weigths in the quantities
\begin{equation*}
    W_{j,\alpha} \left(x;\{\ca{u}_k(t)\}_{k\in\Sopt}\right)
    = \sum_{i=0,L,R} \omega_i\left(\{\ca{u}_k(t)\}_{k\in\Sopt}\right)	\mu^{i}_{j,\alpha}(x).
\end{equation*}
For the first and the last cell, the range of summation over $\alpha$ is adjusted according to the stencil of the reconstruction.
%where we have used the notation convention~\ref{notation:poly}.
Then, it is possible to write the inner BED in~\eqref{eq:bed} as
%\begin{subequations} \label{eq:bed:split}
	\begin{equation} \label{eq:bed:split}%\label{eq:bed:split:inner}
		\begin{aligned}
		u_{j+\frac12}^{-}(t) &= R_j\left(x_{j+\frac12};t\right) \\
		&= \sum_{\alpha=-1}^1 W_{j,\alpha}\left(x_{j+\frac12};\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t), \\
		%
		u_{j+\frac12}^{+}(t) &= R_{j+1}\left(x_{j+\frac12};t\right) \\
		&= \sum_{\alpha=-1}^1 W_{j+1,\alpha}\left(x_{j+\frac12};\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+1+\alpha+\delta_{j1}-\delta_{jN}}(t),
		\end{aligned}
	\end{equation}
% for $j=1,\dots,N-1$, and
% 	\begin{equation} \label{eq:bed:split:bound}
% 		\begin{aligned}
% 		u_{\frac12}^{+}(t) &= R_1\left(a;t\right) = \sum_{\alpha=-1}^1 W_{1,\alpha}\left(a;\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{2+\alpha}(t), \\
% 		%
% 		u_{N+\frac12}^{-}(t) &= R_{N}\left(b;t\right) = \sum_{\alpha=-1}^1 W_{N,\alpha}\left(b;\{\ca{u}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{N+\alpha-1}(t).
% 		\end{aligned}
% 	\end{equation}
%\end{subequations}
We have highlighted the dependence $W_{j,\alpha}$ on the data $\{\ca{u}_k\}_{k\in\Sopt}$, since this is highly nonlinear because it contains the nonlinear weights.

The main idea of Quinpi is to exploit a predictor
$\{\ca{u}^{\star}_j(t)\}_{j=1}^N$
of the solution $\{\ca{u}_j(t)\}_{j=1}^N$ at time $t$ and use it to pre-compute and freeze the nonlinear weights in~\eqref{eq:bed:split}, so that the BED can be approximated as
\begin{equation} \label{eq:bed:linearized}
	\begin{aligned}
		u_{j+\frac12}^{-}(t) &\approx \hat{u}_{j+\frac12}^{-}(t) := \sum_{\alpha=-1}^1 W_{j,\alpha}\left(x_{j+\frac12};\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+\alpha+\delta_{j1}-\delta_{jN}}(t), \\
		u_{j+\frac12}^{+}(t) &\approx \hat{u}_{j+\frac12}^{+}(t) := \sum_{\alpha=-1}^1 W_{j+1,\alpha}\left(x_{j+\frac12};\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{j+1+\alpha+\delta_{j1}-\delta_{jN}}(t). \\
		% u_{\frac12}^{+}(t) &\approx \hat{u}_{\frac12}^{+}(t) := \sum_{\alpha=-1}^1 W_{1,\alpha}\left(a;\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{2+\alpha}(t), \\
		% u_{N+\frac12}^{-}(t) &\approx \hat{u}_{N+\frac12}^{-}(t) := \sum_{\alpha=-1}^1 W_{N,\alpha}\left(b;\{\ca{u}^{\star}_k(t)\}_{k\in\Sopt}\right) \overline{u}_{N+\alpha-1}(t).
	\end{aligned}
\end{equation}
In this way, the complete scheme would be linear with respect to the space reconstruction, and nonlinear only through the flux function.

The proposal of a predictor to linearize an implicit high order scheme was first discussed in~\cite{Gottlieb:iWENO:2006} for WENO reconstructions. There, the solution of a first order explicit scheme is used as predictor in order to compute the nonlinear WENO weights.
Instead, in~\cite{PSV23:Quinpi,2020Arbogast} an implicit first order scheme was chosen as predictor. Although an implicit predictor is more expensive than the explicit approach proposed in~\cite{Gottlieb:iWENO:2006}, it is stable and non-oscillatory even for higher Courant numbers, thus allowing for reliable prediction of the nonlinear weights.

In this work, we follow the approach in~\cite{PSV23:Quinpi} and describe it for systems of conservation laws below. With respect to the above description, in the case of a system of $m$ conservation laws, one has a reconstruction polynomial $\mathbf{R}_j(x;t)\in(\mathbb{P}^{2p})^m$ computed component-wise, $m$-vectors $\pmb{\omega}_i$ of nonlinear coefficients in each cell computed component-wise, while of course the linear coefficients $\mu^i_{j,\alpha}$ are independent of the component being reconstructed.

\subsection{The space-time first order implicit prediction} \label{sec:quinpi:predictor}

Without loss of generality, assume that the nodes $c_1,\dots,c_s$ of the DIRK method are ordered. Then, we approximate the system of ODEs~\eqref{eq:spaceApprox} with an implicit first order scheme at any time $t^{(k)}=(n+c_{k}) \Delta t \in [n\Delta t,(n+1)\Delta t]$, where $\Delta t$ is the time-step of the high order scheme~\eqref{eq:implicit}. Specifically, the system is numerically approximated in space using piecewise constant reconstructions and integrated in time using a composite backward Euler method, providing the $s$ approximations 
$\ca{\bigvec{U}}^{\star,(k)} = \left[\ca{\mathbf{U}}^{\star,(k)}_1,\dots,\ca{\mathbf{U}}^{\star,(k)}_N\right]^T$, $k=1,\dots,s$. Therefore, for each $j=1,\dots,N$, 
$\ca{\mathbf{U}}_j^{\star,(k)} \approx \ca{\mathbf{u}}_j(t^{(k)})$ is given by
\begin{subequations} \label{eq:predictor}
	\begin{align}
		\ca{\mathbf{U}}_j^{\star,(k)} &= \ca{\mathbf{U}}_j^{\star,(k-1)} - \frac{\theta_k\Delta t}{h} \left[ \NumFlux_{j+\frac12}^{\star,(k)} - \NumFlux_{j-\frac12}^{\star,(k)} \right], \quad k=1,\dots,s, \label{eq:predictor:stage} \\
		\ca{\mathbf{U}}_j^{\star,n+1} &= \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{k=1}^s \theta_k \left[ \NumFlux_{j+\frac12}^{\star,(k)} - \NumFlux_{j-\frac12}^{\star,(k)} \right], \quad n\geq 0, \label{eq:predictor:update} \\
		\NumFlux_{j+\frac12}^{\star,(k)} &= \NumFlux\left(\ca{\mathbf{U}}_{j}^{\star,(k)},\ca{\mathbf{U}}_{j+1}^{\star,(k)}\right) \in \R^m \label{eq:predictor:flux}
	\end{align}
\end{subequations}
where $\theta_k:=c_{k}-c_{k-1}$, with $c_0=0$ and $\ca{\mathbf{U}}_j^{\star,(0)}:=\ca{\mathbf{U}}_j^{n}$, and where the convention 
$$
	\ca{\mathbf{U}}_{0}^{\star,(k)} = u_{\mathsf{out}}^-, \quad \ca{\mathbf{U}}_{N+1}^{\star,(k)} = u_{\mathsf{out}}^+,
$$
is used. The outer values $u_{\mathsf{out}}^{\mp}$ are imposed by the chosen boundary conditions. For instance, for periodic conditions one has
\begin{equation} \label{eq:predictor:periodic}
	\ca{\mathbf{U}}_{0}^{\star,(k)} = \ca{\mathbf{U}}_{N}^{\star,(k)}, \quad \ca{\mathbf{U}}_{N+1}^{\star,(k)} = \ca{\mathbf{U}}_{1}^{\star,(k)},
\end{equation}
whereas for zero Neumann conditions one gets
\begin{equation} \label{eq:predictor:freeflow}
	\ca{\mathbf{U}}_{0}^{\star,(k)} = \ca{\mathbf{U}}_{1}^{\star,(k)}, \quad \ca{\mathbf{U}}_{N+1}^{\star,(k)} = \ca{\mathbf{U}}_{N}^{\star,(k)}.
\end{equation}
The scheme~\eqref{eq:predictor} is equivalent to applying a DIRK scheme with Butcher tableau given by
\begin{equation}
	\label{eq:tableau:be}
	\begin{array}{c|cccc}
		c_1 & \theta_{1} & 0 & \dots & 0 \\[1.5ex]
		c_2 & \theta_{1} & \theta_{2} & \dots & 0 \\[1.5ex]
		\vdots & \vdots & \vdots & \ddots & \\[1.5ex]
		c_s & \theta_{1} & \theta_{2} & \dots & \theta_{s} \\[1ex]
		\hline
		&&&&\\[-1.8ex]
		& \theta_1 & \theta_2 & \dots & \theta_s
	\end{array}
\end{equation}
where the coefficients $c_i$, $i=1,\dots,s$, are the same as the high order DIRK in~\eqref{eq:tableau:dirk}.

Notice that the numerical flux function $\NumFlux$ in~\eqref{eq:predictor:flux} is now computed on piecewise constant, unlimited, reconstructions from the cell averages. In fact, first order schemes do not require space-limiting, because they are unconditionally Total Variation Diminishing, see~\cite[Section 2]{PSV23:Quinpi}. Therefore, despite of the high order approximation~\eqref{eq:implicit}, the first order scheme~\eqref{eq:predictor} is characterized by a single nonlinearity, that is the one induced by the flux function $\mathbf{f}$.
Computing~\eqref{eq:predictor:stage} requires the solution of $s$ nonlinear systems of dimension $m N$, which are fully linear with respect to the boundary reconstructions:
\begin{equation} \label{eq:predictor:system}
	\mathbf{G}^\star(\ca{\bigvec{U}}^{\star,(k)}) := 
    \ca{\bigvec{U}}^{\star,(k)} 
    + \frac{\theta_k \Delta t}{h} \Delta\bigvec{F}^{\star,(k)} 
    - \ca{\bigvec{U}}^{\star,(k-1)} = \mathbf{0},
\end{equation}
where $\Delta\bigvec{F}^{\star,(k)}\in\R^{mN}$ whose $j$-th block is $\Delta\bigvec{F}^{\star,(k)}_j=\left(\NumFlux_{j+\nicefrac12}^{\star,(k)}-\NumFlux_{j-\nicefrac12}^{\star,(k)} \right) \in\R^m$, for $j=1,\dots,N$.

The solution of~\eqref{eq:predictor:system} requires the use of a nonlinear solver $s$ times within a single time-step. In this work, we rely on Newton's iterations
\begin{equation} \label{eq:predicor:newton}
	\ca{\bigvec{U}}^{\star,(k)}_{(\ell+1)} 
    = \ca{\bigvec{U}}^{\star,(k)}_{(\ell)} 
    - \left( \mathbb{I} + \frac{\theta_k \Delta t}{h} J^{\star}\left( \ca{\bigvec{U}}^{\star,(k)}_{(\ell)} \right) \right)^{-1} \mathbf{G}^\star\left( \ca{\bigvec{U}}^{\star,(k)}_{(\ell)} \right), \quad \ell \geq 0,
\end{equation}
with given initial guess $\ca{\bigvec{U}}^{\star,(k)}_{(0)}$. Here, $\mathbb{I}\in\R^{mN\times mN}$ is the identity matrix. Whereas, $J^{\star}$ is the $N\times N$ block Jacobian matrix of the numerical flux difference $\Delta \bigvec{F}^{\star}$. Then, each block of the Jacobian is given by
$$
	\left( J^{\star} \right)_{ji} = \frac{\partial \Delta \bigvec{F}^{\star}_j}{\partial \ca{\mathbf{U}}^{\star}_i} \in \R^{m\times m}, \quad j,i=1,\dots,N.
$$
In particular, for a first order space approximation one has
%\begin{align*}
%	\Delta \NumFlux^{\star}_1 &= \Delta \NumFlux^{\star} (\ca{\mathbf{U}}^{\star}_{1},\ca{\mathbf{U}}^{\star}_2,\ca{\mathbf{U}}^{\star}_{N}), \\
%	\Delta \NumFlux^{\star}_j &= \Delta \NumFlux^{\star} (\ca{\mathbf{U}}^{\star}_{j-1},\ca{\mathbf{U}}^{\star}_j,\ca{\mathbf{U}}^{\star}_{j+1}), \quad j=2,\dots,N-1 \\
%	\Delta \NumFlux^{\star}_N &= \Delta \NumFlux^{\star} (\ca{\mathbf{U}}^{\star}_{1},\ca{\mathbf{U}}^{\star}_{N-1},\ca{\mathbf{U}}^{\star}_{N}),
%\end{align*}
%which are fully linear on the data, it turns out
that the Jacobian is a tridiagonal block matrix of the form
$$
	\frac{\partial \Delta \bigvec{F}^{\star}_j}{\partial \ca{\mathbf{U}}^{\star}_i} = \begin{cases}
		-\dfrac{\partial \NumFlux}{\partial \mathbf{v}} \left( \ca{\mathbf{U}}^{\star}_i,\ca{\mathbf{U}}^{\star}_{i+1} \right), & \text{if } i=j-1 \\[2.5ex]
		\dfrac{\partial \NumFlux}{\partial \mathbf{v}}\left( \ca{\mathbf{U}}^{\star}_i,\ca{\mathbf{U}}^{\star}_{i+1} \right) - \dfrac{\partial \NumFlux}{\partial \mathbf{w}} \left( \ca{\mathbf{U}}^{\star}_{i-1},\ca{\mathbf{U}}^{\star}_i \right), & \text{if } i=j \\[2.5ex]
		\dfrac{\partial \NumFlux}{\partial \mathbf{w}} \left( \ca{\mathbf{U}}^{\star}_{i-1},\ca{\mathbf{U}}^{\star}_i \right), & \text{if } i=j+1 \\
	\end{cases}
$$
for $j=2,\dots,N-1$, where $\partial_{\mathbf{v}} \NumFlux$ and $\partial_{\mathbf{w}} \NumFlux$ denote the Jacobian of the vector-valued numerical flux function~\eqref{eq:numfluxfnc} with respect to its first and second variable, respectively.

\subsection{The space-time third order implicit correction} \label{sec:quinpi:corrector}

Assume that the first order predictor is available at a time $t^{(k)} \in [n\Delta t,(n+1)\Delta t]$. The obtained approximation $\ca{\bigvec{U}}^{\star,(k)}$ is used to evaluate the nonlinear terms of the high order BED as explained at the beginning of this section, see~\eqref{eq:bed:linearized}. Therefore, the third order ``correction'' at time $t^{(k)}$ can be computed as in~\eqref{eq:implicit:stage} with
\begin{equation} \label{eq:implicit:fluxLinearized}
	\begin{aligned}
		\NumFlux_{j+\frac12}^{(k)} = \NumFlux\left(\mathbf{U}_{j+\frac12}^{-,(k)},\mathbf{U}_{j+\frac12}^{+,(k)}\right) \approx \hat{\NumFlux}_{j+\frac12}^{(k)} = \NumFlux\left(\hat{\mathbf{U}}_{j+\frac12}^{-,(k)},\hat{\mathbf{U}}_{j+\frac12}^{+,(k)}\right),
	\end{aligned}
\end{equation}
where $\hat{\mathbf{U}}_{j+\frac12}^{\mp,(k)}$ are the linearized BED, which are fully linear with respect to the unknown cell averages at time $t^{(k)}=t_n+c_k\Delta t$. Therefore, the nonlinear system
\begin{equation} \label{eq:corrector:system}
	\mathbf{G}\left(\ca{\bigvec{U}}^{(k)}\right) 
    := \ca{\bigvec{U}}^{(k)} 
    + \frac{a_{kk}\Delta t}{h} \Delta \hat{\bigvec{F}}^{(k)} 
    - \ca{\bigvec{U}}^{(k-1)} = \mathbf{0},
\end{equation}
obtained from~\eqref{eq:implicit:stage} and \eqref{eq:implicit:fluxLinearized}, can be tackled with Newton's iterations
\begin{equation} \label{eq:corrector:newton}
	\ca{\bigvec{U}}^{(k)}_{(\ell+1)} = \ca{\bigvec{U}}^{(k)}_{(\ell)} 
    - \left( \mathbb{I} + \frac{a_{kk} \Delta t}{h} J\left( \ca{\bigvec{U}}^{(k)}_{(\ell)} \right) \right)^{-1} \mathbf{G}\left( \ca{\bigvec{U}}^{(k)}_{(\ell)} \right), \quad \ell \geq 0,
\end{equation}
with initial guess $\ca{\bigvec{U}}^{(k)}_{(0)}$ set to the predictor's output, 
where the the stencil of the Jacobian $J\in\R^{mN\times mN}$ is still as in the fully implicit approach, because of the stencil of the space reconstructions, but the entries can now be computed explicitly. In fact, one has that each block $\left( J \right)_{ji} \in \R^{m\times m}$, $j,i=1,\dots,N$, can be written as
\begin{align*}
	\left( J \right)_{ji} = \frac{\partial \Delta \hat{\bigvec{F}}_j}{\partial \hat{\mathbf{U}}_{i}}
	=& \frac{\partial \NumFlux}{\partial \mathbf{v}} \left( \hat{\mathbf{U}}^-_{j+\frac12} , \hat{\mathbf{U}}^+_{j+\frac12}\right) \frac{\partial \hat{\mathbf{U}}^-_{j+\frac12}}{\partial \ca{\mathbf{U}}_i} + \frac{\partial \NumFlux}{\partial \mathbf{w}} \left( \hat{\mathbf{U}}^-_{j+\frac12} , \hat{\mathbf{U}}^+_{j+\frac12}\right) \frac{\partial \hat{\mathbf{U}}^+_{j+\frac12}}{\partial \ca{\mathbf{U}}_i} \\
	&- \frac{\partial \NumFlux}{\partial \mathbf{v}} \left( \hat{\mathbf{U}}^-_{j-\frac12} , \hat{\mathbf{U}}^+_{j-\frac12}\right) \frac{\partial \hat{\mathbf{U}}^-_{j-\frac12}}{\partial \ca{\mathbf{U}}_i} - \frac{\partial \NumFlux}{\partial \mathbf{w}} \left( \hat{\mathbf{U}}^-_{j-\frac12} , \hat{\mathbf{U}}^+_{j-\frac12}\right) \frac{\partial \hat{\mathbf{U}}^+_{j-\frac12}}{\partial \ca{\mathbf{U}}_i}
\end{align*}
where $\partial_{\mathbf{v}}\NumFlux$ and $\partial_{\mathbf{w}}\NumFlux$ contain the Jacobian of the flux function $\mathbf{f}$, whereas $\partial_{\ca{\mathbf{U}}_i} \mathbf{U}^{\mp}_{j\pm\nicefrac12}$ are assembled with the frozen nonlinear weights,cf.~\eqref{eq:bed:linearized}.

For nontrivial boundary conditions, the above expression for the Jacobian blocks has to be modified according to the dependence of the external BED ($\ca{\mathbf{U}}_{\nicefrac12}^-$ and $\ca{\mathbf{U}}_{N+\nicefrac12}^+$) on the interior data.

Finally, once all the stage values $\ca{\bigvec{U}}^{(k)}$, $k=1,\dots,s$, are computed, the third order solution $\ca{\bigvec{U}}^{n+1}$ at time level $(n+1)\Delta t$ is obtained as in~\eqref{eq:implicit:update}.

\subsection{Conservative a-posteriori time-limiting based on numerical entropy} \label{sec:quinpi:entropy}

The solution obtained with the predictor-corrector approach is third order accurate, and has control over spurious oscillations thanks to the limited CWENO space reconstruction. However, when using a large $\Delta t$, the space limiting is not enough, and the high order solution may still exhibit oscillations as already noticed in~\cite{PSV23:Quinpi,2020Arbogast,2007DurasaisamyBaeder}. In such situation limiting in time is also required.
Also, the Quinpi scheme that we propose in this paper employs a time-limiting procedure of the third order solution.

In~\cite{PSV23:Quinpi} the time-limiting is performed in a WENO-like framework. In fact, nonlinear weights are suitably defined in order to blend cells between the computed high order solution and the low order predictor, which is reliable, stable and non-oscillatory. However, the procedure in~\cite{PSV23:Quinpi} does not have mass conservation property and must be followed up by a suitable conservative correction, analogously to~\cite{Marsha:AMR} in adaptive mesh refinement.

Conservation can be ensured avoiding a cell-centered blending by means of flux-based Runge-Kutta, as, e.g., in~\cite{Ketcheson:fluxbased:2013,2020Arbogast}.
Similarly, a flux-centered conservative a-posteriori time-limiting inspired by the MOOD technique~\cite{CDL11:MOOD,CDL12:MOOD} was investigated in~\cite{VTSP23:Quinpi:Book}. MOOD was originally designed as an a-posteriori space-limiting technique for multi-dimensional finite volume schemes. Instead, in~\cite{VTSP23:Quinpi:Book}, the typical MOOD detectors were used to limit the high order solution at time level $(n+1)\Delta t$. Specifically, at the interfaces of oscillatory cells, the method uses a convex combination of the high order and the low-order numerical fluxes. A similar idea was also employed in~\cite{EBS22:Implicit:Networks} for a-posteriori limiting of fully implicit finite volume schemes on transport networks.

In this paper we still rely on the MOOD technique, and the high order numerical fluxes of oscillatory cells are dropped to the low-order numerical fluxes of the predictor. The novelty here is that the detection of troubled cells is performed with the numerical entropy production introduced in~\cite{PS11:numerical:entropy,Puppo04:numerical:entropy}, extended to balance laws in~\cite{PS16:entropy:balance}, and already exploited in \cite{SCR:CWENOquadtree,SempliceLoubere:AMRMOOD} as a-posteriori error of adaptive schemes and indicator of the qualitative structure of the flow.

\subsubsection{Indicators based on numerical entropy production}

Assume that system~\eqref{eq:hyp:sys} is endowed with an entropy-entropy flux pair, namely there exist a convex function $\mathbf{u}\in\R^m\mapsto\eta(\mathbf{u})\in\R$ and a corresponding entropy flux $\mathbf{u}\in\R^m\mapsto\psi(\mathbf{u})\in\R$ such that $\nabla^T\eta(\mathbf{u}) \mathbf{f}^\prime(\mathbf{u})=\nabla^T\psi(\mathbf{u})$. Then, all entropy solutions of~\eqref{eq:hyp:sys} satisfy the entropy inequality
\begin{equation} \label{eq:entropy}
	\frac{\partial}{\partial t} \eta(\mathbf{u}(x,t)) + \frac{\partial}{\partial x} \psi(\mathbf{u}(x,t)) \leq 0,
\end{equation}
in the weak sense. It is well known that~\eqref{eq:entropy} is an equality on smooth flows. Instead, if the solution has a singularity, the sign of~\eqref{eq:entropy} selects the unique physically admissible weak solution of~\eqref{eq:hyp:sys}. For this reason, the novel idea of~\cite{Puppo04:numerical:entropy} was to consider the numerical residual of
the entropy inequality as an a-posteriori error indicator for the numerical solution of~\eqref{eq:hyp:sys}, since it is a scalar value (even in the case of systems of conservation laws) which provides information on the size of the local truncation error and on the presence of singularities. Recently, the numerical entropy residual has been employed also in the context of stochastic Galerkin formulations of hyperbolic systems, see~\cite{2023GersterSemplice}.

Following~\cite{PS11:numerical:entropy} we give the subsequent definition.

\begin{definition}
	Let $\ca{\mathbf{U}}^n$ be the solution of~\eqref{eq:spaceApprox} obtained using a $s$-stage Runge-Kutta scheme of order $p$ with weights $\{ b_i \}_{i=1}^s$ and time-step $\Delta t$. Then, the numerical entropy production $\left(S^p\right)_j^n$ of the scheme in the control volume $V_j^n = \Omega_j \times [n\Delta t , (n+1)\Delta t]$ is given by
	\begin{equation} \label{eq:numerical:entropy}
		\left(S^p\right)_j^n = \frac{1}{\Delta t} \left[ \ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n+1} \right) \right)_j - \ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n} \right) \right)_j + \frac{\Delta t}{h} \sum_{i=1}^s b_i \left( \Psi_{j+\frac12}^{(i)} - \Psi_{j-\frac12}^{(i)} \right) \right]
	\end{equation}
	where
	$$
		\Psi_{j+\frac12}^{(i)} = \Psi\left( \mathbf{U}_{j+\frac12}^{-,(i)},\mathbf{U}_{j+\frac12}^{+,(i)} \right),
	$$
	is a numerical entropy flux function consistent with the exact entropy flux $\psi$ of~\eqref{eq:entropy}, with $(\mathbf{v},\mathbf{w}) \in \R^m\times\R^m \to \Psi(\mathbf{v},\mathbf{w})\in\R$, and where $\ca{\mathbf{U}}_{j\pm\nicefrac12}^{\mp},(i)$ are the BED of the numerical solution. In~\eqref{eq:numerical:entropy}, $\ca{Q}\left( \cdot \right)_j$ denotes a quadrature rule of order $p$ to compute the cell average on the cell $\Omega_j$.
\end{definition}

The rate of convergence of~\eqref{eq:numerical:entropy} is shown in~\cite{PS11:numerical:entropy}. In particular, for a general numerical scheme of order $p$ one has
$$
	\left(S^p\right)_j^n = \begin{cases}
		\mathcal{O}(h^p), & \text{if the solution is regular on $\Omega_j$} \\
		\mathcal{O}(h^{-1}), & \text{if the solution has a shock on $\Omega_j$} \\
		\mathcal{O}(h), & \text{if $\Omega_j$ exhibits a rarefaction corner} \\
		\mathcal{O}(1), & \text{if $\Omega_j$ exhibits a contact wave}.
	\end{cases}
$$
In other words, $\left(S^p\right)_j^n\to 0$, as $h\to 0$, with the same rate of the local truncation error of the scheme on smooth flows. Whereas, the numerical entropy production increases in the magnitude on shocks.

For the first order predictor solution $\ca{\bigvec{U}}^\star$, defined in Section~\ref{sec:quinpi:predictor}, we can consider the midpoint quadrature rule and observe that the cell average and the point value at the cell center are $\mathcal{O}(h^2)$ apart, and thus set
$
	\ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n} \right) \right)_j =  \eta\left(\ca{\mathbf{U}}_j^{n}\right),
$
 in~\eqref{eq:numerical:entropy}. The numerical entropy production becomes
\begin{equation} \label{eq:entropy:1}
	\left(S^1\right)_j^n = \frac{1}{\Delta t} \left[ \eta\left( \ca{\mathbf{U}}^{\star,n+1}_j \right) - \eta\left( \ca{\mathbf{U}}^{\star,n}_j \right) + \frac{\Delta t}{h} \sum_{i=1}^s \theta_i \left( \Psi_{j+\frac12}^{\star,(i)} - \Psi_{j-\frac12}^{\star,(i)} \right) \right],
\end{equation}
where
$$
	\Psi_{j+\frac12}^{\star,(i)} = \Psi\left( \mathbf{U}_j^{\star,(i)},\mathbf{U}_{j+1}^{\star,(i)} \right).
$$
Instead, for the third order solution $\ca{\bigvec{U}}$ defined in Section~\ref{sec:quinpi:corrector}, in this work we consider the two-point Gauss-Legendre quadrature rule:
$$
	\ca{Q}\left( \eta\left( \ca{\mathbf{U}}^{n} \right) \right)_j = \frac{1}{2} \left( \eta\left(\mathbf{U}_{j-\frac{\sqrt{3}}{6}}^{n}\right) + \eta\left(\mathbf{U}_{j+\frac{\sqrt{3}}{6}}^{n}\right) \right),
$$
where $\mathbf{U}_{j\pm\nicefrac{\sqrt{3}}{6}}^{n}$ denote the reconstructions of the solution in $x_j\pm\nicefrac{\sqrt{3}h}{6}$. Observe that the computation of the quadrature rule does not require significant additional computational cost since the computation of $\mathbf{U}_{j\pm\nicefrac{\sqrt{3}}{6}}^{n}$ involves just the evaluation of a CWENO reconstruction polynomial which is already available, because it is computed in order to advance the solution from $n\Delta t$ to $(n+1)\Delta t$. Thus, for the third order solution, the numerical entropy production becomes
\begin{equation} \label{eq:entropy:3}
\begin{aligned}
	\left(S^3\right)_j^n = \frac{1}{\Delta t}  
      \bigg[ &\frac{1}{2} \left( \eta\left(\mathbf{U}_{j-\frac{\sqrt{3}}{6}}^{n}\right) + \eta\left(\mathbf{U}_{j+\frac{\sqrt{3}}{6}}^{n}\right) \right) - \frac{1}{2} \left( \eta\left(\mathbf{U}_{j-\frac{\sqrt{3}}{6}}^{n}\right) + \eta\left(\mathbf{U}_{j+\frac{\sqrt{3}}{6}}^{n}\right) \right)  \\
	   & + \frac{\Delta t}{h} \sum_{i=1}^s b_i \left( \Psi_{j+\frac12}^{(i)} - \Psi_{j-\frac12}^{(i)} \right) \bigg].
\end{aligned}
\end{equation}

At the discrete level, $\left(S^1\right)_j^n$ and $\left(S^3\right)_j^n$ provide a regularity indicator of the predictor and of the corrector solution, respectively. Therefore, in order to determine where the time-limiting has to occur, we detect spurious oscillations using $\left(S^1\right)_j^n$ and $\left(S^3\right)_j^n$ in the following ways.
\begin{description}
	\item[$\mathcal{I}_1$:] The indicator~\eqref{eq:entropy:3} of the third order scheme is used to detect troubled cells. We expect that on smooth cells $\Omega_j$ one has $\left(S^3\right)_j^n = \mathcal{O}(h^3)$, whereas $\left(S^3\right)_j^n = \mathcal{O}(h^{-1})$ in presence of shocks. In particular, a cell $\Omega_j$ is marked for the time-limiting if
	\begin{equation} \label{eq:strategy1}
		\left(S^3\right)_j^n > \gamma_{1},
	\end{equation}
	where $\gamma_{1}$ is a given threshold.
	\item[$\mathcal{I}_2$:] The ratio of the indicators~\eqref{eq:entropy:1} and~\eqref{eq:entropy:3} is used to detect problematic cell $\Omega_j$ whenever
	\begin{equation} \label{eq:strategy2}
		\frac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n+\sigma} > \gamma_{2},
	\end{equation}
	where $\gamma_{2}$ is a given threshold and $\sigma$ a small quantity which prevents $\nicefrac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n} \sim O(1)$ on constant regions of the solution. In fact, we expect that on a smooth cell $\Omega_j$ one has $\nicefrac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n} = \mathcal{O}(h^2)$, whereas $\nicefrac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n} = \mathcal{O}(1)$ if the solution is not regular on $\Omega_j$.
	\item[$\mathcal{I}_3$:] Both the detecting techniques $\mathcal{I}_1$ and $\mathcal{I}_2$ are used, so that a cell $\Omega_j$ is marked for the time-limiting if
	\begin{equation} \label{eq:strategy3}
	\left(S^3\right)_j^n > \gamma_{1} \ \text{ and } \ \frac{\left(S^3\right)_j^n}{\left(S^1\right)_j^n+\sigma} > \gamma_{2}.
	\end{equation}
	Combining the $\mathcal{I}_1$ and the $\mathcal{I}_2$ strategies is particularly helpful on very flat regions of the solutions. In fact, the $\mathcal{I}_2$ strategy may mark these regions as irregular cells, i.e.~where a shock appears, if $\left(S^3\right)_j^n = O(\left(S^1\right)_j^n)$. Then, the $\mathcal{I}_1$ strategy allows to detect the regularity of the solution. 
\end{description}

\subsubsection{Time limited solution and the final Quinpi algorithm}

% Figure environment removed

Once the detector has been chosen, the flux-centered time-limiting is performed by computing the limited numerical flux $\NumFlux^{\mathsf{TL},(k)}_{j+\nicefrac12}$
for the face between $\Omega_{j}$ and $\Omega_{j+1}$, for 
all stages $k=1,\dots,s$, as
\begin{equation} \label{eq:timelimited:fluxes}
	\NumFlux^{\mathsf{TL},(k)}_{j+\frac12} = \begin{cases}
		 \theta_k \NumFlux^{\star,(k)}_{j+\frac12}, & \text{if either $\Omega_j$ or $\Omega_{j+1}$ is marked},\\[2ex]
		 b_k \NumFlux^{(k)}_{j+\nicefrac12}, & \text{if both $\Omega_j$ and $\Omega_{j+1}$ are not marked},
	\end{cases}
\end{equation}
where the acronym $\mathsf{TL}$ stands for Time-Limited. Notice that, since the predictor scheme is based on a composite backward Euler, the low order numerical fluxes $\NumFlux^{\star,(k)}_{j\pm\nicefrac12}$ are available at each stage $k=1,\dots,s$, for $j=1,\dots,N$.

Thus, the high order numerical fluxes at the interfaces of a problematic cell $\Omega_j$ are replaced with the low order numerical fluxes reducing locally the order of the solution, which is then computed as
\begin{equation} \label{eq:timelimited:sol}
	\ca{\mathbf{U}}_j^{n+1} = \ca{\mathbf{U}}_j^{n} - \frac{\Delta t}{h} \sum_{k=1}^s \left[ \NumFlux_{j+\tfrac12}^{\mathsf{TL},(k)} - \NumFlux_{j-\tfrac12}^{\mathsf{TL},(k)} \right], \quad j=1,\dots,N.
\end{equation}
The time-limiting procedure is repeated until the solution $\ca{\bigvec{U}}^{n+1}$ is detected as smooth on each cell.

Overall, the update of the solution from time $n\Delta t$ to time $(n+1)\Delta t$ computed with the Quinpi scheme is summarized in Figure~\ref{fig:algorithm}. 