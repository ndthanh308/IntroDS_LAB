\documentclass[11pt]{article}
%
%\usepackage{amsmath}
\usepackage[dvips]{graphicx}%,color} %use for latex->dvips
%\usepackage[pdftex]{graphicx} %use for pdflatex
%\usepackage{epsfig}
%\usepackage{psfrag}
%\usepackage{psfig}
%\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{amsbsy}
\usepackage{latexsym}
\usepackage[mathscr]{eucal}
\usepackage{amsfonts,amsmath,amsthm}
\usepackage{amssymb}
\usepackage[usenames]{xcolor}
% \usepackage{showkeys}
%\usepackage{stmaryrd}
\usepackage{hyperref}

\usepackage{mathtools}

%\topmargin=-0.5truein
%\textheight=9truein
%\oddsidemargin=0in
%\textwidth=7.5truein


%
\usepackage{fullpage}
\def\anew{\color{red} }
\def\PW{\color{orange}}
\def\rnew{\color{magenta}}
\def\cnew{\color{blue} }
%\def\rnew{}
%\def\anew{}
%\def\cnew{ }

%\voffset=-3cm
%
\begin{document}
%

%
\title
{Weighted variation spaces and approximation by shallow ReLU networks\footnote{This research was supported by the NSF grants DMS-2134077 and DMS-2134140 of the MoDL program as well as the MURI ONR grant N00014-20-1-2787 (RD and RN). 
RP was supported by the European Research Council (ERC Project FunLearn) under grant 101020573. JS was supported by NSF grants DMS-2111387 and CCF-2205004.}}
\author{ 
Ronald DeVore, Robert D. Nowak, Rahul Parhi, and Jonathan W. Siegel}
%
%
\hbadness=10000
\vbadness=10000
%
\newtheorem{lemma}{Lemma}[section]
\newtheorem{prop}[lemma]{Proposition}
\newtheorem{cor}[lemma]{Corollary}
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{remark}[lemma]{Remark}
\newtheorem{example}[lemma]{Example}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{proper}[lemma]{Properties}
\newtheorem{assumption}[lemma]{Assumption}
%
% Albert symbols
\newenvironment{disarray}{\everymath{\displaystyle\everymath{}}\array}{\endarray}

\def\RR{\rm \hbox{I\kern-.2em\hbox{R}}}
\def\NN{\rm \hbox{I\kern-.2em\hbox{N}}}
\def\ZZ{\rm {{\rm Z}\kern-.28em{\rm Z}}}
\def\CC{\rm \hbox{C\kern -.5em {\raise .32ex \hbox{$\scriptscriptstyle
|$}}\kern
-.22em{\raise .6ex \hbox{$\scriptscriptstyle |$}}\kern .4em}}
\def\vp{\varphi}
\def\<{\langle}
\def\>{\rangle}
\def\t{\tilde}
\def\i{\infty}
\def\e{\varepsilon}
\def\sm{\setminus}
\def\nl{\newline}
\def\o{\overline}
\def\wt{\widetilde}
\def\wh{\widehat}
\def\cT{{\cal T}}
\def\cA{{\cal A}}
\def\cI{{\cal I}}
\def\cV{{\cal V}}
\def\cB{{\cal B}}
\def\cF{{\cal F}}
\def\cY{{\cal Y}}

\def\cD{{\cal D}}
\def\cP{{\cal P}}
\def\cJ{{\cal J}}
\def\cM{{\cal M}}
\def\cO{{\cal O}}
\def\Chi{\raise .3ex
\hbox{\large $\chi$}} \def\vp{\varphi}
\def\lsima{\hbox{\kern -.6em\raisebox{-1ex}{$~\stackrel{\textstyle<}{\sim}~$}}\kern -.4em}
\def\lsim{\hbox{\kern -.2em\raisebox{-1ex}{$~\stackrel{\textstyle<}{\sim}~$}}\kern -.2em}
\def\[{\Bigl [}
\def\]{\Bigr ]}
\def\({\Bigl (}
\def\){\Bigr )}
\def\[{\Bigl [}
\def\]{\Bigr ]}
\def\({\Bigl (}
\def\){\Bigr )}
\def\L{\pounds}
\def\pr{{\rm Prob}}
% End Albert symbols
% color coding for modifications by Chris
\newcommand{\cs}[1]{{\color{magenta}{#1}}}
\def\ds{\displaystyle}
\def\ev#1{\vec{#1}}     % arrow over letter
%
\newcommand{\lt}{\ell^{2}(\nabla)}
\def\Supp#1{{\rm supp\,}{#1}}
%\def\R{{\relax\ifmmode I\!\!R\else$I\!\!R$\fi}}
\def\R{\mathbb{R}}
%\def\E{{\relax\ifmmode I\!\!E\else$I\!\!E$\fi}}
\def\E{\mathbb{E}}
\def\nl{\newline}
\def\T{{\relax\ifmmode I\!\!\hspace{-1pt}T\else$I\!\!\hspace{-1pt}T$\fi}}
%\def\N{{\relax\ifmmode I\!\!N\else$I\!\!N$\fi}}
\def\N{\mathbb{N}}
%\def\Z{{\relax\ifmmode Z\!\!\!Z\else$Z\!\!\!Z$\fi}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\Zd{\Z^d}
%\def\Q{{\relax\ifmmode I\!\!\!\!Q\else$I\!\!\!\!Q$\fi}}
\def\Q{\mathbb{Q}}
%\def\C{{\relax\ifmmode I\!\!\!\!C\else$I\!\!\!\!C$\fi}}
\def\C{\mathbb{C}}
\def\Rd{\R^d}
\def\gsim{\mathrel{\raisebox{-4pt}{$\stackrel{\textstyle>}{\sim}$}}}
\def\sime{\raisebox{0ex}{$~\stackrel{\textstyle\sim}{=}~$}}
\def\lsim{\raisebox{-1ex}{$~\stackrel{\textstyle<}{\sim}~$}}
\def\div{\mbox{ div }}
\def\M{M}  \def\NN{N}                  % parameter M, N in [DKU]
\def\L{{\ell}}               % parameter L = l in [DKU] (support)
\def\Le{{\ell^1}}            % support of xi: [\ell^1,\ell^2]
\def\Lz{{\ell^2}}
\def\Let{{\tilde\ell^1}}     % support of xi\tilde:[\t\ell^1,\t\ell^2]
\def\Lzt{{\tilde\ell^2}}
\def\Ltw{\ell^\tau^w(\nabla)}
\def\t#1{\tilde{#1}}
\def\la{\lambda}
\def\La{\Lambda}
\def\ga{\gamma}
\def\BV{{\rm BV}}
\def\Ga{\eta}
\def\al{\alpha}
\def\cZ{{\cal Z}}
\def\cA{{\cal A}}
\def\cU{{\cal U}}
\def\argmin{\mathop{\rm argmin}}
\def\argmax{\mathop{\rm argmax}}
\def\prob{\mathop{\rm prob}}

%\def{\th}{\theta}
%\def{\O}{\Omega}
\def\cO{{\cal O}}
\def\cA{{\cal A}}
\def\cC{{\cal C}}
\def\cS{{\cal F}}
\def\bu{{\bf u}}
\def\bz{{\bf z}}
\def\bZ{{\bf Z}}
\def\bI{{\bf I}}
\def\cE{{\cal E}}
\def\cD{{\cal D}}
\def\cG{{\cal G}}
\def\cI{{\cal I}}
\def\cJ{{\cal J}}
\def\cM{{\cal M}}
\def\cN{{\cal N}}
\def\cT{{\cal T}}
\def\cU{{\cal U}}
\def\cV{{\cal V}}
\def\cW{{\cal W}}
\def\cL{{\cal L}}
\def\cB{{\cal B}}
\def\cG{{\cal G}}
\def\cK{{\cal K}}
\def\cX{{\cal X}}
\def\cS{{\cal S}}
\def\cP{{\cal P}}
\def\cQ{{\cal Q}}
\def\cR{{\cal R}}
\def\cU{{\cal U}}
\def\bL{{\bf L}}
\def\bl{{\bf l}}
\def\bK{{\bf K}}
\def\bC{{\bf C}}
\def\X{X\in\{L,R\}}
\def\ph{{\varphi}}
\def\D{{\Delta}}
\def\H{{\cal H}}
\def\bM{{\bf M}}
\def\bx{{\bf x}}
\def\bj{{\bf j}}
\def\bG{{\bf G}}
\def\bP{{\bf P}}
\def\bW{{\bf W}}
\def\bT{{\bf T}}
\def\bV{{\bf V}}
\def\bv{{\bf v}}
\def\bt{{\bf t}}
\def\bz{{\bf z}}
\def\bw{{\bf w}}
\def \span{{\rm span}}
\def \meas {{\rm meas}}
\def\rhom{{\rho^m}}
\def\diff{\hbox{\tiny $\Delta$}}
\def\EE{{\rm Exp}}
%
\def\lll{\langle}
\def\argmin{\mathop{\rm argmin}}
\def\codim{\mathop{\rm codim}}
\def\rank{\mathop{\rm rank}}

\newcommand{\rob}[1]{{\color{red}{#1}}}



\def\argmax{\mathop{\rm argmax}}
%\def\R{\rangle}
\def\dJ{\nabla}
\newcommand{\ba}{{\bf a}}
\newcommand{\bb}{{\bf b}}
\newcommand{\bc}{{\bf c}}
\newcommand{\bd}{{\bf d}}
\newcommand{\bs}{{\bf s}}
\newcommand{\bff}{{\bf f}}
\newcommand{\bp}{{\bf p}}
\newcommand{\bg}{{\bf g}}
\newcommand{\by}{{\bf y}}
\newcommand{\br}{{\bf r}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bea}{$$ \begin{array}{lll}}
\newcommand{\eea}{\end{array} $$}
%\newcommand{\bv}{{\bf v}}
\def \Vol{\mathop{\rm  Vol}}
\def \mes{\mathop{\rm mes}}
\def \Prob{\mathop{\rm  Prob}}
\def \exp{\mathop{\rm    exp}}
\def \sign{\mathop{\rm   sign}}
\def \sp{\mathop{\rm   span}}
\def \rad{\mathop{\rm   rad}}
\def \vphi{{\varphi}}
\def \csp{\overline \mathop{\rm   span}}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\beqn}{\begin{equation}}
\newcommand{\eeqn}{\end{equation}}
\def\beginproof{\noindent{\bf Proof:}~ }
\def\endproof{\hfill\rule{1.5mm}{1.5mm}\\[2mm]}

% -----------------------------
% Neue Definitionen (Th. Lange)
% -----------------------------
\newenvironment{Proof}{\noindent{\bf Proof:}\quad}{\endproof}

\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}

\makeatletter
\@addtoreset{equation}{section}
\makeatother

\newcommand\abs[1]{\left|#1\right|}
\newcommand\clos{\mathop{\rm clos}\nolimits}
\newcommand\trunc{\mathop{\rm trunc}\nolimits}
\renewcommand\d{d}
\newcommand\dd{d}
\newcommand\diag{\mathop{\rm diag}}
\newcommand\dist{\mathop{\rm dist}}
\newcommand\diam{\mathop{\rm diam}}
\newcommand\cond{\mathop{\rm cond}\nolimits}
\newcommand\eref[1]{{\rm (\ref{#1})}}
\newcommand{\iref}[1]{{\rm (\ref{#1})}}
\newcommand\Hnorm[1]{\norm{#1}_{H^s([0,1])}}
\def\int{\intop\limits}
\renewcommand\labelenumi{(\roman{enumi})}
\newcommand\lnorm[1]{\norm{#1}_{\ell^2(\Z)}}
\newcommand\Lnorm[1]{\norm{#1}_{L_2([0,1])}}
\newcommand\LR{{L_2(\R)}}
\newcommand\LRnorm[1]{\norm{#1}_\LR}
\newcommand\Matrix[2]{\hphantom{#1}_#2#1}
\newcommand\norm[1]{\left\|#1\right\|}
\newcommand\ogauss[1]{\left\lceil#1\right\rceil}
\newcommand{\QED}{\hfill
\raisebox{-2pt}{\rule{5.6pt}{8pt}\rule{4pt}{0pt}}%
  \smallskip\par}
\newcommand\Rscalar[1]{\scalar{#1}_\R}
\newcommand\scalar[1]{\left(#1\right)}
\newcommand\Scalar[1]{\scalar{#1}_{[0,1]}}
\newcommand\Span{\mathop{\rm span}}
\newcommand\supp{\mathop{\rm supp}}
\newcommand\ugauss[1]{\left\lfloor#1\right\rfloor}
\newcommand\with{\, : \,}
\newcommand\Null{{\bf 0}}
\newcommand\bA{{\bf A}}
\newcommand\bB{{\bf B}}
\newcommand\bR{{\bf R}}
\newcommand\bD{{\bf D}}
\newcommand\bE{{\bf E}}
\newcommand\bF{{\bf F}}
\newcommand\bH{{\bf H}}
\newcommand\bU{{\bf U}}

%\newcommand\a{{\rm a}}   

%\newcommand\e{\e}
\newcommand\cH{{\cal H}}
\newcommand\sinc{{\rm sinc}}
\def\enorm#1{| \! | \! | #1 | \! | \! |}

\newcommand{\dm}{\frac{d-1}{d}}

\let\bm\bf
\newcommand{\bbeta}{{\mbox{\boldmath$\beta$}}}
\newcommand{\bal}{{\mbox{\boldmath$\alpha$}}}
\newcommand{\bbi}{{\bm i}}

\def\nnew{\color{Red}}
\def\mnew{\color{Blue}}
\def\wnew{\color{magenta}}

%-----------------------
% Neues von T. Bronger
%-----------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%von mir
\newcommand{\dI}{\Delta}
\newcommand\aconv{\mathop{\rm absconv}}
%\newcommand{\dJ}{\nabla}
%

\newcommand{\RadonOp}{\cR}


\date{}
\maketitle
 %
  \begin{abstract}   We investigate  the  approximation of functions $f$ on a bounded domain $\Omega\subset \R^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$.  This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is  the simplest case of neural network approximation (NNA).  There are several celebrated approximation results for this form of NNA that introduce novel model classes  of functions on $\Omega$ whose approximation rates    avoid the curse of dimensionality.  These novel classes include Barron classes \cite {B}, and classes based on sparsity or variation \cite{O+, PN} such as the Radon-domain BV classes.
  
   
   The present paper is concerned with the definition of these novel model classes  on   domains $\Omega$.   The current definition of these model  classes    does not depend on  the domain $\Omega$.  A new and more proper definition of   model classes on domains  is given by introducing the concept of  weighted variation spaces.  These new model classes are  intrinsic to the domain itself.
   The importance of these new model classes is that they are strictly larger than the classical (domain-independent) classes. Yet, it is shown that they maintain the same NNA rates.
   
   \end{abstract}
   \textbf{Keywords---}Neural networks, approximation rates, variation spaces, curse of dimensionality.

  \section{Introduction}
  \label{S:intro}
  Neural networks (NNs) are now the numerical method  of choice for the development of learning algorithms in regression and classification, especially when dealing with functions of $d$ variables with $d$ large.
  It is   therefore  important to understand, through mathematical theory, the reasons for this  success.  In learning,
  we are tasked with approximating an unknown function $f$ on a domain $\Omega\subset \R^d$ from some finite set of data observations of $f$.   Thus, at least part of the success in using NNs for such learning problems, must lie in their ability to effectively  approximate
  the functions of interest. This has led to the study of approximation by NNs and, in particular, to understand exactly which functions are well approximated by NNs and what is their approximation rate in terms of the number of neurons employed (so-called $n$-term approximation).
  
  A large number of papers have been written in recent years that give quantitative bounds on the approximation rates of various model classes of functions when using neural networks.  General accountings of such results can be found in \cite{BGKP, DHP,GK, P}.
  Two types of results have emerged.  The first is to show that  deep NNs with ReLU activation functions (see, e.g.,  \cite{lu2021deep,ZX,JX,Y}) are surprisingly effective in approximating functions from classical model classes such as finite balls in a Sobolev or Besov space when the approximation error is measured in an $L_p(\Omega)$ norm with $1\le p\le \infty$.  While such results are deep and interesting, they do not match the most common  setting of learning in high dimensions ($d$ large) because these model classes necessarily suffer the curse of dimensionality.  Indeed, the approximation rates for such smoothness classes  is
  of the form $O(n^{-s/d})$ with $s$ related to the smoothness assumption on $f$. Here and later $n$ always refers to the number of neurons used in the approximation. Thus, for large values of $d$, membership in such a   model class is  not a realistic assumption to make on the target function $f$ to be learned.  This negativity for classical smoothness as a model class asssumption for $f$ can be ameliorated by assuming that the input variable to $f$ (and hence the data as well) is restricted  by a probability
  measure $\mu$ on $\Omega$ supported on a low-dimensional submanifold.
    
    The second type of approximation  result introduces
  novel high-dimensional model classes for which neural network approximation (NNA) does not suffer this curse of dimensionality.  Thus, membership in these new model classes    can   be a realistic model class assumption for learning a function of many variables. The most celebrated examples of such new model classes are the Barron class $\cB^s$, $s>0$,  introduced in \cite{B}.  The set $\cB^s=\cB^s(\R^d)$    consists of all functions $f$ defined on $\R^d$ whose Fourier transform $\hat f$ satisfies
  %
  \be
  \label{barron}
 \|f\|_{\cB^s}:= \int_{\R^d}(1+|\omega|)^s|\hat f(\omega)|\, d\omega < +\infty.
  \ee
  
  The original result of Barron showed that on a bounded domain $\Omega\subset \R^d$, any function $f$ on $\Omega$ which is the restriction of a function from    $\cB^1(\R^d)$ can be approximated in the $L_2(\Omega)$ norm by single-hidden-layer sigmoidal networks with $n$ neurons to an accuracy of $C_\Omega \|f\|_{\cB^1}n^{-1/2}$, $n\ge 1$, where the constant $C_\Omega$ only depends upon the measure of $\Omega$.  Notice that this  approximation rate does not deteriorate with increasing  $d$ in contrast with classical smoothness model classes.  However, one must note that the above definition of Barron spaces depend on $d$ and indeed   get more demanding as $d$ increases.
  
 Barron's result spurred a lot of study and generalizations   over the last decades. In particular, new model classes of functions which have sparse representation of as linear combinations of neural atoms were introduced. In the case of ReLU neurons, the sparsity  class is larger than the (second-order) Barron class and yet preserves the rate of approximation of $n$-term approximation~\cite{ma2022barron}. These spaces based on sparsity are called \emph{variation spaces}~\cite{Bach,kurkova2001bounds,mhaskar2004tractability,SXSharp,SXDict}. We summarize these activities for ReLU neurons in the following two sections.  For the moment, we only wish to focus on the existing theory for these model classes and their approximation rates on domains $\Omega\subset\R^d$. This is the typical setting in applications. The existing theory defines the corresponding model classes on $\R^d$ and then extends the definition to  domains as the restriction of functions defined on $\R^d$.  As such, the theory and corresponding results are in a strong sense \emph{independent of the domain $\Omega$}.
    While this leads to a simple approximation theory on domains, these results never take into consideration 
  the nature of $\Omega$, e.g., its geometry.  
  
  The purpose of the present paper is to show there is a more satisfactory definition of these
    novel model classes on domains $\Omega$ that leads to domain-dependent results  that are stronger than that provided by the existing theory. We call these new model classes \emph{weighted} variation spaces since they generalize the classical variation space for ReLU neurons by introducing a domain-dependent weighting of the ReLU atoms. These new model classes are strictly larger than the existing variation spaces while still maintaining the same rate of approximation of $n$-term approximation. We develop this domain-dependent theory primarily in the case when $\Omega=B^d$ is the Euclidean unit ball in $\R^d$. To indicate how the theory would depend on the domain $\Omega$,   we also consider the domain $Q^d:=[-1,1]^d$ and contrast the difference in this case with that of $B^d$.


While we develop our results only for the case of ReLU neurons, 
  it will be clear how  they generalize to the case of ReLU$^k$ neurons, $k>1$.  So, for the remainder of this paper the activation function
  is 
  \be 
  \label{RELU}
  \sigma(t)=t_+=\max\{0,t\}.
  \ee 
  
  This paper is organized as follows.  In the next two sections, we review some of the existing results on ReLU neural network approximation.  This will serve to frame the new results proved in this paper.  In \S \ref{S:variation} we introduce our new (domain-dependent) model classes. In \S \ref{S:approxdictionary}, we prove our new approximation results for $\Omega=B^2$ the unit Euclidean ball in $\R^2$.  We separate out this case since it is the simplest setting to understand. The remaining sections of this paper
  formulate and prove our results for $\Omega=B^d$ which is the Euclidean unit ball in $\R^d$. We also contrast how the results change when $\Omega = Q^d$.
  Finally, we discuss the possible significance of these new model classes for the problem of learning from data.
  
 \section{Approximation by shallow ReLU networks}
 \label{S:ReLU}
  In this paper, we concentrate on a very specific case of NNA, namely approximation by single-hidden-layer ReLU NNs, i.e., the activation function $\sigma$
  is given by \eref{RELU}.
     We study neural network approximation  on a given  bounded domain (the closure of an  open connected set) $\Omega$  of $\R^d$. The most natural choices for $\Omega$
  are the unit Euclidean ball $B^d$ of $\R^d$ or  the   $d$-dimensional cube $Q^d:=[-1,1]^d$.  
  The case $\Omega=B^d$  will be the   primary example considered in this paper.  In going further, we let $\|\cdot\|$ denote  the Euclidean norm on $\R^d$.  
  
  We define the ReLU atoms
  %
  \be
  \label{atoms}
  \phi(x;\xi,t):=    \sigma(\xi \cdot x-t)=(\xi\cdot x-t)_+,\quad \xi \in \R^d,\ \|\xi\|=1,\ t\in\R. 
  \ee
 Given the atom $\phi$,  we let 
  \be
  \label{hyperplane}
  H_\phi := \{x\in \Omega: \xi \cdot x=t\}
  \ee
  be its hyperplane cut.
     $H_\phi$  divides $\Omega$ into two regions $H_\phi^\pm$.  The function $\phi$ is identically zero on   the region $H_\phi^-:=\{x\in\Omega: \ \xi\cdot x\le t\}$  and the  linear function $=\xi \cdot x-t$ on the second region $H_\phi^+:=\{x\in\Omega:\ \xi\cdot x>t\}$.  Notice that for some values of $t$, the atom $\phi$ is identically zero on $\Omega$ so that $ H_\phi^- =\Omega$.
  
  
   For each $\Omega$, there is a smallest  interval $T=T(\Omega)$ such that for $t\notin T$, the dictionary element $\phi(\cdot;\xi,t)$ is either identically zero on $\Omega$ or a linear function on $\Omega$.  Let $\cD= \cD(\Omega):=\{\phi(\cdot;\xi,t)\}$   be the dictionary of all   atoms $\phi$ for which $t\in T=T(\Omega)$. We are interested in 
  $n$-term approximation from the dictionary $\cD$.  For $n=1,2,\dots$, let $\Sigma_n:=\Sigma_n(\cD)$ be the set of functions of the form
  \be
  \label{nterms}
  S(x)=\sum_{j=1}^n a_j\phi_j(x),\quad x\in \Omega,
  \ee 
  where the $\phi_j$ are chosen arbitrarily from $\cD$ and $a_1,\dots,a_n$ are real numbers.  When $n=0$, we define  $\Sigma_0:=\{0\}$. The functions $S\in\Sigma_n$ are precisely  the functions on $\Omega$  produced by a single-hidden-layer ReLU network with $n$ neurons, i.e., width $n$.  The set $\Sigma_n$ is thus a $(d+2)n$ dimensional parametric nonlinear manifold parameterized by the $\xi_j\in B^d$, $j=1,\dots,n$,    the $t_j\in\R$, $j=1,\dots,n$,  and the coefficients $a_1,\dots,a_n\in\R$.  Note that a given
  $S\in\Sigma_n$  has in general many representations of the form \eref{nterms}.  In other words, the dictionary $\cD(\Omega)$ is redundant.

  The above paragraph tells us that there are two ways to view shallow network approximation with ReLU activation.  One view is that it is a special case of $n$-term approximation from a dictionary of functions.  Another view is that it is a special case of manifold approximation.  Therefore, a proper assessment of this form of NN approximation would be to compare it with other
  approximation methods of either one of these forms.
  
   Approximation by $\Sigma_n$ is one of the
  simplest examples of neural network approximation (NNA).  It is therefore a fundamental problem to completely understand the approximation properties of $\Sigma_n$, $n\ge 1$, i.e., what are the properties of a function $f$ that determine how well $f$ is approximated by the elements of  $\Sigma_n$.  
  In the case $d=1$ and $\Omega$ is an interval, the set $\Sigma_n$ is the space of piecewise linear function with $n$ breakpoints.  In this special case, approximation by $\Sigma_n$ is well understood (see e.g. \cite{DHP,DNonlinear}).  So, we restrict ourselves to the case $d\ge 2$ in going
  further in this paper.
  
  
  
  
 For a function $f$ in $L_p(\Omega)$, $1\le p\le\infty$, we define
  %
  \be
  E_n(f)_p:=E_n(f)_{L_p(\Omega)}:=\inf_{S\in\Sigma_n}\|f-S\|_{L_p(\Omega)}.
  \ee
  This is a form of nonlinear approximation since the set $\Sigma_n$ is not a linear space but rather  a nonlinear manifold.   Rightfully, we often put this form of   approximation in competition with other examples of manifold approximation
  (see e.g. \cite{CDPW,DHP}).
  
  
  
    From the viewpoint of approximation theory, an understanding of the approximation properties of $\Sigma_n$   would seek to precisely  characterize the approximation classes for $\Sigma_n$ approximation.  An approximation class is the collection of all functions whose approximation error decays at a prescribed decay rate.  For example, for a given $\alpha>0$, we seek a characterization of  the set 
  \be
  \label{approxclass}
  \cA^\alpha:= \cA^\alpha((\Sigma_n)_{n\ge 0},L_p(\Omega))
  \ee
   of
  functions $f\in L_p(\Omega)$ for which
  %
  \be
  \label{Aalpha}
  E_n(f)_p
\le M(n+1)^{-\alpha},\quad n=0,1,2,\dots.
\ee
Note that by definition, $\Sigma_0=\{0\}$  and hence $E_0(f)_p=\|f\|_{L_p(\Omega)}$
The smallest value of $M$ for which \eref{Aalpha} holds is defined as $\|f\|_{\cA^\alpha}$. Notice that $\cA^\alpha$ is a quasi-normed linear space. While for most classical methods of linear and nonlinear approximation,
e.g. polynomials, splines, $n$-term wavelets, there is a characterization of the spaces $\cA^\alpha$ (at least for a certain range of $\alpha$), the case for neural network approximation is much different.
There is at present no known
characterization of $\cA^\alpha$ for any value of $\alpha>0$.   There are however many sufficient conditions that guarantee membership in $\cA^\alpha$ (see \cite{DHP}). 
  
Another (less ambitious) viewpoint of approximation by $\Sigma_n$ is to propose model classes $K$, i.e., compact subsets $K\subset L_p(\Omega)$, and study how well the elements of $K$ can be approximated by the elements of $\Sigma_n$.   This leads to the study of
%
\be
\label{EK}
E_n(K)_p:=\sup_{f\in K} E_n(f)_p,\quad n\ge 0.
\ee
If one comes up with a set $K$ for which $E_n(K)\le Cn^{-\alpha}$, $n\ge 1$, then clearly $K\subset \cA^\alpha$ and we gain some information about  $\cA^\alpha$.
Many interesting approximation results have been proven for various classical model classes $K$ such as Sobolev and Besov balls, however, the best approximation rates are not known in all cases~\cite{DHP}.
These results show no gain in approximation efficiency when compared with more classical  methods of approximation such as those that use splines or wavelets.   Moreover, these  classical model classes all suffer the curse of dimensionality: smoothness of order $s$ gives rate decay
$E_n(K)_p\ge Cn^{-s/d}$, $n\ge 0$.  


One of the celebrated accomplishments in the study of NNA was the introduction of new model classes   $K$ which are known to not  suffer the curse of dimensionality and also give us information on $\cA^\alpha$.   We discuss these model classes in the next two sections. In going further in this paper
we only treat the case of approximation in $L_2(\Omega)$.  However, the case of $L_p(\Omega)$ approximation has also been well studied (see \cite{SXSharp}).

\section{Novel (non-classical) model classes}
\label{S:nonclassical}
  While the classical model classes based on smoothness all suffer the curse of dimensionality, certain novel model classes $K$
  have been introduced that avoid this curse.  The discovery of these novel model classes begin with the celebrated work of Barron \cite{B}.  We have already defined the Barron spaces $\cB^s(\R^d)$  in the introduction.  
    
  Barron's original results on NNA were for sigmoidal activation and the Barron class $\cB^1(\R^d)$ where he showed that functions in this class, when restricted to a domain $\Omega\subset\R^d$, had an $L_2(\Omega)$ approximation rate $n^{-1/2}$, $n\ge 1$.  It was rather straightforward to extend his approach to proving that
  functions in $\cB^2$ had the same approximation rate when using ReLU activation.  Several follow up papers significantly improved on these original results as we now describe.
  
   Notice that the Barron classes are  formulated for functions which are defined on all of $\R^d$.  Given   a bounded domain $\Omega$, it is not obvious how these classes should be defined on $\Omega$. The definition employed in the literature is that 
  the space $\cB^s(\Omega)$ is the set of function $f$ defined on $\Omega$ which are the restriction of a function $F\in \cB^s(\R^d)$ with norm given by
  %
  \be
  \label{Bnorm}
  \|f\|_{\cB^s(\Omega)}:=\inf_{F|_\Omega=f}\|F\|_{\cB^s(\R^d)},\quad s>0.
  \ee






  
   With this definition, we have
  %
  \be
  \label{firstbarron}
  E_n(U(\cB^2(\Omega))_{L_2(\Omega)}\le C n^{-1/2},\quad n\ge 1,
  \ee
  where $C$ depends only on the diameter and measure of $\Omega$.  
  Here and later we use the notation $U(Y)$ to denote the unit ball of a normed space $Y$.
  This approximation rate was improved over the years starting with Makovoz \cite{Makovoz} and continuing on with the results of \cite{Bach,KB,SXSharp}.  The current best known approximation rate for $n$-term ReLU NNA is
  \be
  \label{currentbarron}
  E_n(U(\cB^2(\Omega))_{L_2(\Omega)}\le C n^{-\frac 1 2 -\frac{3}{2d}},\quad n\ge 1,
  \ee
  where again $C$ depends only on $d$.
We refer the reader to \cite{SXSharp} for a more detailed discussion of these approximation results.  It is still not known if this rate can be improved for the Barron class $\mathcal{B}^2$.

We turn next to a second family of novel model classes for NNA referred to as variation spaces.     Let
$\cD=\cD(\Omega)$ be the dictionary of   ReLU atoms whose hyperplane cut intersects $\Omega$.   Consider  any function $S=\sum_{j=1}^n a_j \phi_j$, i.e., $S\in\Sigma_n$.   Recall that this representation is not unique.  We define

\be
\label{defV}
V(S):= \inf\left\{\sum_{j=1}^n  |a_j|: S=\sum_{j=1}^na_j\phi_j \right\},
\ee
which is  called  the variation of  $S$ with respect to the dictionary $\cD$.  

  

With this notation in hand, we can define a new space $\cV:=\cV(\Omega)=\cV(\Omega,\cD)$ as the set of all $f$ in $L_2(\Omega)$ for which there is a sequence $S_n\in\Sigma_n$, $n\ge 1$,  such that $\|f-S_n\|_{L_2(\Omega)}\to 0$, $n\to\infty$,
and $V(S_n)\le M$, $n\ge 1$.  Throughout the paper, we will use $\cV$ when the domain $\Omega$ and dictionary $\cD$ are clear from the context, and use $\cV(\Omega)$, $\cV(\cD)$, or  $\cV(\Omega,\cD)$ when we want to call attention to the domain and/or dictionary. The smallest $M$ for which this is true is defined as $\|f\|_{\cV(\Omega)}$.   This space is  called
the {\it variation space} of the dictionary $\cD$.  The space $\cV(\Omega)$ is a Banach space with respect to this norm (see \cite{SXDict} for properties of variation spaces).  A fundamental relation between the Barron and variation space is the embedding
%
\be
\label{containment}    
\|f\|_{\cV(\Omega)}\le C_\Omega \|f\|_{\cB^2(\Omega)},\quad f\in\cB^2(\Omega),
\ee
with $C_\Omega$ the embedding constant  (which depends only on the diameter of $\Omega$).   The space $\cV(\Omega)$ is strictly larger than $\cB^2(\Omega)$.   

 The variation space $\cV(\Omega)$ has been carefully studied and in particular it has been proven that
that (see~\cite{SXSharp})
\be
  \label{vapproxrate}
  E_n(U(\cV(\Omega)))_{L_2(\Omega)}\le C n^{-\frac 1 2 -\frac{3}{2d}},\quad n\ge 1,
  \ee
  where $C$ depends only on $\Omega$ and $d$. This approximation rate also matches the decay rate of the metric entropy of $U(\cV(\Omega))$~\cite{SXSharp}.
  Notice that this gives the bound \eref{currentbarron} and is in fact how approximation rates for the Barron class are proved. The important thing to note here is that $\cV$ is a larger space than $\cB^2$ but the current best known approximation rates (with shallow ReLU NNs) for both of these classes is the same, namely $O( n^{-\frac 1 2 -\frac{3}{2d}})$, $n\ge 1$.
  
 
 
 A major breakthrough in the understanding of $\cV(\Omega)$ was made by characterizing membership of a function $f$ in $\cV(\Omega)$ through the smoothness of its Radon transform.  Namely, it was originally proved in \cite{O+} that a function $f$ is in $\cV(\Omega)$ if and only if $f$ has an extension $F$ to all of $\R^d$ such that the Radon transform $\mathcal{R}(F;\xi,t)$  is in a certain
 smoothness space. Properties and generalizations of this notion of smoothness were extensively studied in~\cite{PN,PNDeep,PNMinimax}, giving rise to a new family of Banach spaces, now referred to as the Radon BV spaces. These spaces are denoted by $\mathcal{R}\mathrm{BV}^k$, $k \in \mathbb{N}$.   
 
 
 The key result of~\cite{PN} is the following \emph{representer theorem} for these spaces. Let $x_i\in\R^d$, $i=1,\dots,m$, and $y_i \in \R$, $i=1,\dots,m$. Then, there always exists a solution to the data-fitting problem
 
 \be
 \label{minprob}
    \min_{f \in \mathcal{R}\mathrm{BV}^k} \sum_{i=1}^m \mathcal{L}(y_i, f(x_i)) + \lambda |f|_{\mathcal{R}\mathrm{BV}^k}
 \ee
 that takes the form of a function $S$ which is the output of a single-hidden-layer neural network with $\leq m$ neurons and ReLU$^{k-1}$ activation functions. Here, $\mathcal{L}$ is any loss function which is lower-semi-continuous in its second argument and $|f|_{\mathcal{R}\mathrm{BV}^k}$ is the semi-norm which defines the $\mathcal{R}\mathrm{BV}^k$ spaces, which measures smoothness in the Radon domain.  The Radon BV spaces are defined on domains $\Omega\subset \R^d$ via restrictions. For the case $k=2$ (which corresponds to shallow ReLU NNs) it has been shown in~\cite[Theorem~6]{PNMinimax} (see also~\cite[Theorem~2~and~Corollary~1]{SXDict}) that
 \be 
 \label{RBVvar}
 \mathcal{R}\mathrm{BV}^2(\Omega)= \cV(\Omega),
 \ee 
 with equivalent norms. It has also been shown that there exists a solution $S$ to \eref{minprob} which  is in $\Sigma_m(\cD)$ on any bounded domain $\Omega\subset \R^d$~\cite[Theorem~5]{PNMinimax}.
 
  
 



\section{Weighted variation model classes}
  \label{S:variation}
 One of the main points of the present paper is that one can derive improved results on approximation by shallow ReLU networks if one considers new model classes that generalize the
 standard variation space by including weights on the atoms.  In this section, we introduce these  new model classes for the case when we want the error of approximation to be taken  in the   $L_2(\Omega)$ norm with  $\Omega$   a bounded domain in $\R^d$.    We begin with the general principle of {\it  weighted variation spaces}.
  
  Let $\cD  $ be the dictionary  of ReLU atoms.  Let $S^{d-1}$ be the boundary of the unit Euclidean ball $B^d$ of $\R^d$.
  That is, $S^{d-1}:=\{\xi\in \R^d: \ \|\xi\|=1\} $.   Any atom $\phi$ in $\cD$ is of the form $\phi(x)=(\xi\cdot x-t)_+$ where   $t\in \R $.  We are interested in the atoms $\phi$ whose hyperplane cut intersects $\Omega$ (since otherwise the atom is identically an affine function).  Accordingly, we define
  %
  \be 
  \label{defZ}
  Z(\Omega):=\{(\xi,t): \xi\in S^{d-1}, \ t\in \R \ {\rm such\  that}\ H_{\phi(\cdot;\xi,t)} \cap \Omega \neq \varnothing\}
  \ee
  and $\bar Z(\Omega)$ its closure in the Euclidean norm.
  Note that whenever $\phi(x)=\phi(x;\xi,t)$ is positive for some $x\in \Omega$, it is positive in a neighborhood
  of $x$ and hence $\|\phi\|_{L_2(\Omega)}>0$.
  Given the domain $\Omega$ we define the dictionary
  \be 
  \label{dictionaryOmega}
  \cD(\Omega):= \{\phi(\cdot,\xi,t): \ (\xi,t)\in \bar Z(\Omega)\}.
  \ee 
  The set $\bar Z(\Omega)$ is a compact subset of $S^{d-1} \times \R$.  If we equip $\bar Z(\Omega)$ with the Euclidean norm topology then
  the mapping $(\xi,t)\mapsto \phi(\cdot;\xi,t)$ is a continuous mapping from $\bar Z(\Omega)$ into $L_2(\Omega)$.
  
  
  Here is an important observation about the atoms in this dictionary which underlies the improved approximation results of this paper.  While each atom $\phi\in\cD(\Omega)$ is in $L_2(\Omega)$ whenever $\Omega$ is a bounded domain, the   $L_2(\Omega)$ norm of $\phi$ will depend heavily on $\phi$ and $\Omega$.  Namely,
  if the support of $\phi$ lies near the boundary of $\Omega$ then this norm will be small and we
  expect that $\phi$ has a less important role in approximating a given target function $f\in L_2(\Omega)$.   

  As an example, consider the case when $\Omega=B^d$ is the $d$-dimensional Euclidean ball. It is easy to see that the atom $\phi(x)=(\xi\cdot x-t)_+$,  has $L_2(\Omega)$-norm satisfying
  \be  
  \label{normphi}
  \|\phi\|_{L_2(\Omega)}\approx (1-t)^{\frac{3}{2}+ \frac{d-1}{4}}, \quad -1\le t\le 1,
  \ee
  with constants of equivalence depending only on $d$.
Indeed, the $L_\infty(\Omega)$ norm of $\phi$ is $1-t$ and the measure of its support
$\approx (1-t)[\sqrt{1-t}]^{d-1}$.  It follows that the norms of atoms get smaller as $t$ approaches one.
  
  
  
  
  
  % Returning to  the case of general $\Omega$, we recall that the classical variation space $\cV(\Omega)$ is defined through the closed convex hull $\cK$ of $\cD(\Omega)$.  A function $f$ is in $\cV(\Omega)$ if and only if some multiple
  % $\alpha f$, $\alpha\neq 0$, is in $\cK$ and its norm is
  % \be
  % \label{vnorm}
  % \|f\|_{\cV(\Omega)}: =\sup\{|\alpha|:\ \alpha f\in \cK\}.
  % \ee 
  The compactness of $\bar Z(\Omega)$ implies that the dictionary $\cD(\Omega)$ is a compact subset of $L_2(\Omega)$. Thus, there is another useful characterization of the functions
  in $\cV(\Omega)$. Consider the space $\cM:=\cM(\bar Z(\Omega))$ of all finite (signed) Radon measures on $\bar Z(\Omega)$, equipped with the variation norm $\|\mu\|_{\cM}:=\int _{\bar Z(\Omega)} d |\mu|$.  For $\mu\in\cM$, we introduce the function
  \be
  \label{fmu}
   f_\mu:= \int_{\bar Z(\Omega)} \phi(\cdot;\xi,t)\, d\mu(\xi, t),
  \ee 
  where the integral in \eqref{fmu} can be understood as a Bochner integral (see~\cite[Lemma~3]{SXDict} for more details).
 Then, any $f\in\cV(\Omega)$ has a representation
  \be
  \label{Vrep}
  f= f_\mu,\quad \text{for some }\mu\in\cM.
  \ee 
      This representation is not unique in the sense that different measures $\mu$ can give rise to the same $f$.  It then follows (see \cite{SXDict}) that the $\cV$-norm can be alternatively specified by
  %
  \be 
  \label{Vnorm}
  \|f\|_{\cV}= \inf\{ \|\mu\|_{\cM}: \ f=f_\mu, \ \mu\in\cM\}.
  \ee
  
   In order to simplify the geometry, in going further in this section, we assume that $\Omega$ is a convex subset of $\R^d$  and $\cD:=\cD(\Omega)$. 
  We say that  
  \be 
  \label{weightform}
  w(\xi,t),  \quad (\xi,t)\in \bar Z(\Omega),
  \ee 
  is a weight function if $w$ is a non-negative continuous function on $\bar Z(\Omega)$. Given an atom $\phi(\cdot; \xi, t)$ we will abuse notation and also write $w(\phi)$ or $w(\phi(\cdot; \xi, t))$ for $w(\xi, t)$.

  \vskip .1in
  \noindent 

 
  
   
{\bf Admissible Weights:}  {\it Given  a weight function $w$ defined on $\bar Z(\Omega)$, we define 
%
\be\label{defW}
\tilde \phi(\cdot;\xi,t):= \frac{\phi(\cdot;\xi,t)}{w(\xi,t)}, \quad (\xi,t) \in \bar Z(\Omega),
\ee
where $\tilde \phi(\cdot;\xi,t)$ is defined to be the zero function whenever  $w(\xi,t)=0$.  
We say that the weight function $w$ is admissible for $\Omega$, if the mapping $(\xi,t)\to \tilde \phi(\cdot;\xi,t)$  is continuous as a mapping from $\bar Z(\Omega)$ into $L_2(\Omega)$.  It follows that 
\be 
\label{wa}
\|\tilde \phi(\cdot; \xi, t)\|_{L_2(\Omega)} \leq C_w,
\ee
with $C_w$ an absolute constant.
Notice that if a weight function $w$ is admissible, then any larger weight function $\tilde w$ is also admissible.}
\vskip .1in
 When given an admissible weight $w$, the set of functions 
 \be 
 \label{newdictionary} 
 \cD_w:=\cD_w(\Omega)=\{\tilde\phi(\cdot;\xi,t):\ (\xi,t)\in \bar Z(\Omega)\}.
 \ee    
 is a new dictionary contained  in $L_2(\Omega)$.  Furthermore, this dictionary is compact in $L_2(\Omega)$.  
 We define the weighted variation space $\cV_w:=\cV_w(\Omega)$ to be variation space of this new dictionary $\cD_w$. Since the admissibility conditions ensure that the dictionary $\cD_w$ is compact in $L_2(\Omega)$, we have, from the discussion above, that, for every $f\in \cV_w(\Omega)$, there exists a signed Radon measure $\mu=\mu_f$ on $\bar Z(\Omega)$ such that
\begin{equation}
\label{weightrep}
f= \tilde f_\mu:= \int_{\bar Z(\Omega)} \tilde \phi(\cdot;\xi,t) \,d\mu(\xi,t)\quad {\rm with} \quad  \|f\|_{\cV_w(\Omega)}=\|\tilde f_\mu\|_{\cV_w(\Omega)}=\|\mu_f\|_{\cM}.
\end{equation}
We also clearly have
% Any $f\in\cV_w(\cD(\Omega)$ has an atomic representation
%   \be
%   \label{Vwrep}
%   f=\sum_{j=1}^\infty a_j\phi_j\quad {\rm with} \quad \sum_{j=1}^\infty w(\phi_j)|a_j|=\|f\|_{\cV_w(\Omega)},
%   \ee 
%   where again the  series converges in the $L_2(\Omega)$. For admissible weights, we have the embedding inequality
   \be 
   \label{Vwembed}
   \|f\|_{L_2(\Omega)}\le C_w\|f\|_{\cV_w(\Omega)}, \quad f\in\cV_w(\Omega),
   \ee 
   where $C_w$ is the   constant in \eqref{wa}. We also have that, if $\tilde w\ge w$, then $\cV_{\tilde w}(\Omega)\subset \cV_w(\Omega)$ and $\|f\|_{\cV_{\tilde w}}\le\|f\|_{\cV_w(\Omega)}$ which implies that
   \be
   \label{betterapprox}
   E_n(\cV_{\tilde w}(\Omega)) \le E_n(\cV_w(\Omega)),\quad n\ge 0.
   \ee
   


 

   While $\cV_w(\Omega)$ is defined for any nonnegative weight $w$ which is admissible, there is a particular choice of $w$ which we will consider in this paper. Specifically, we show that the approximation rates derived for shallow ReLU neural networks on the unweighted space $\cV(\Omega)$ actually hold on the larger space $\cV_w(\Omega)$ for a certain collection of  admissible weights $w$. As we will later see, the smallest admissible weight with this property will depend upon the domain $\Omega$. 
   %we will see that  for a given domain $\Omega$, there will be only one choice of $w$ which is a match for the results we prove about ReLU approximation
   %in this paper.  
   % \rob{could we say more about what we mean by a "match" for the results we prove?  this is a bit vague and i'm not sure we clear this notion of "match" up in a direct way later in the paper. could we say something like we want to find the largest weighted variation space that enjoys the same approximation rates as the standard $\cV(\Omega)$?}
   % {\rnew RD:  This is a good point that we briefly talked about during our last zoom.  Jonathan argued that the improvement from approximation rate $n^{-1/2}$ for standard dictionaries to $n^{-\frac{1}{2}-\frac{3}{2d}}$ is due to the fact that the mapping from parameters $(\xi,t)$ to atoms $\phi(\cdot;\xi,t)$ has a certain smoothness. If we renormalize the atoms to $\tilde \phi(\cdot;\xi,t)$ then we can retain this improved order of approximation only in so far that under this renormalization the parameter to atom mapping retains its smoothness.  I did not check this statement of Jonathan carefully but this seems correct.  Maybe this is what we should add here.
   % }
   This domain-dependent smallest weight is related to the measure of the intersection of the hyperplane of $\phi$ restricted to $\Omega$.  
   To describe this particular weight $w$  and our new approximation results,  we start with the case $d=2$ where the proofs of approximation rates are simplest to understand.   We consider the two domains  $\Omega= B^2$ and $\Omega=Q^2$. Later, we treat the general cases $\Omega=B^d$, $d\ge 2$.
    We then explain how the same theory carries over to  $\Omega=Q^d$ (see Remark \eref{R:Qd}).


    Variation spaces $\cV(\cD_0)$ are defined as above for any dictionary $\cD_0$ in any Hilbert space
    $H$ provided that the dictionary elements $\psi\in\cD_0$ satisfy $\|\psi\|_H\le \delta$ for a fixed value of $\delta>0$. Given such a dictionary $\cD_0$, we define $\Sigma_n:=\Sigma_n(\cD_0)$  as the set of all functions $S\in H$ that are a linear combination of at most $n$ terms of $\cD_0$.  For any $f\in H$, we define the error of $n$ term approximation to be
    \be 
    \label{ntermH}
    E(f,\Sigma_n)_H:=\inf_{S\in \Sigma_n}\|f-S\|_H.
    \ee 
    This  $n$-term approximation error from a dictionary is well studied.  A fundamental result for such $n$-term approximation is   the theorem of Maurey \cite{M} (see also \cite{B, Jones}).   Maurey's theorem says that for each $n\ge0$ and $f\in\cV(\cD_0)$ we have
    %
    \be    
    \label{Mtheorem}
    \inf_{S_n\in \Sigma_n}\|f-S_n\|_H\le \|f\|_{\cV(\cD_0)}\delta n^{-1/2},\quad n\ge 1.
    \ee
    In fact, Maurey's theorem can be generalized beyond the setting of a Hilbert space to the class of type-$2$ Banach spaces (see \cite{SXSharp} for the application to non-linear dictionary approximation). This introduces an extra constant factor which depends upon the type-$2$ constant of the space.
We shall use this theorem going forward, but restrict ourselves to the Hilbert space setting.

 

  
  
  
  
  
  
   
   
   
   
   
   
      
  \section{Approximation in $\Omega=B^2$}
  \label{S:approxdictionary}
  
   
   In this section, we develop our  results  in the case   $\Omega=B^2$ where $B^2$ is the unit Euclidean ball in $\R^2$. Here, $\bar{Z}(\Omega) = S^1 \times [-1, 1]$. This will illustrate, in their simplest form, all of  the principles needed to treat   the more  general  case $\Omega=B^d$, $d\ge 2$.  The   treatment of $B^d$ is given
   in \S\ref{S:generald}  but with a significant increase in the level of technicality.  

   
In this section, we let $\cD=\cD(\Omega)$ be the ReLU dictionary of atoms $\phi=\phi(\cdot;\xi,t)$,
$\xi\in S^1$ and $t\in [-1,1]$.
%\textcolor{red}{rahul: $(-1, 1)$ or $[-1, 1]$?}
      Note that since $d=2$, the hyperplane $H_\phi$ associated to the atom $\phi$ is a line  and $L_\phi:=H_\phi\cap \Omega$ is a line segment whose length is $|L_\phi|=(1-t^2)^{1/2}$.
      We define the weight of this atom by
      %
      \be 
      \label{aw2}
      w(\phi) = w(\phi(\cdot; \xi, t)) :=1-t,\quad t\in [-1, 1].
      \ee 
      It is easy to check that this weight is admissible since $\|\phi(\cdot; \xi,t)\|_{L_2(\Omega)}\approx (1-t)^{7/4}$ (see \eref{normphi}).
  
   
   
   
    We first want to prove results on the linear approximation of the atoms $\phi$. Namely, for each $n=1,2,\dots$, we want to construct an $n$ dimensional linear  space $X_n$ which is good at approxating all of the atoms
    $\phi\in\cD(\Omega)$.  The linear space $X_n$ will be the span of $n$ well chosen atoms $\phi_j$, $j=1,\dots,n$, from $\cD(\Omega)$. The construction we give for $X_n$  is  a modification of ideas from \cite{SXSharp}. Our   analysis of the approximation error in approximating $\phi$ by the elements of $X_n$ is new in that it gives an improved error estimate when the support of $\phi$ is near the boundary of $\Omega$.

    To define the space $X_n:=\span\{\phi_1,\dots,\phi_n\}$, we want to choose the atoms $\phi_j$, $j=1,\dots,n$, to have as a special discrete distribution from $\cD$.
       In the case $d=2$,  these atoms are rather easy to describe geometrically as is given in the next paragraph.   When $d>2$, we will need more sophisticated arguments (see \S\ref{S:generald}).   
  
  
              
  
   
  
 We fix $m\ge 4$ and let  $P=P_m$ be the set of points  
 \be  
 \mu_j=\mu_j(m):=(\cos \theta_{j}, \sin \theta_{j}), \quad  \theta_j=\theta_{j,m}:=\frac{2\pi j}m, \ j\in \Z.
 \ee  
 There are $m$ distinct points and $\mu_j=\mu_{j'}$ if $j$ and $j'$ are congruent modulo $m$, i.e., if  $j\equiv j'$.  These points are equally spaced on the circle. 
 
 Let $X_n$ be the linear space spanned by  the dictionary elements
 $\phi$ whose line segment $L_\phi$ has end points $\mu_i$ and $\mu_j$, $1\le i<j\le m$.  Notice that for each pair $i,j$ there are two such atoms.
Hence, the dimension of $X_n$ is $n:=m(m-1)$.  We also note that $X_n$ contains all linear functions on $\Omega$.
 
    Given $i,j\in\Z$, we define the distance between $i$ and $j$ by
   $$
    d(i,j) :=  \min\{|i'-j'|:\ i\equiv i',\ j\equiv j'\},
   $$
   i.e. to be the periodic distance between the indices $i$ and $j$. 

   
   Let $\cL_{i,j}=\cL_{i,j}(m)$ be the set of all line segments $L$  whose end points $a,b$ are the points $(\cos \theta,\sin\theta)$ where $\theta\in[\theta_{i}, \theta_{i+1}]$ in the case of $a$ and $\theta\in[\theta_{j}, \theta_{j+1}]$ in the case of $b$.  We denote by $S_{i,j}=S_{i,j}(m)$ the union of all the line segments $L_\phi$  in $\cL_{i,j}$. % i.e. $S_{i,j}$ is the strip which is the convex hull of the circular arcs $[\theta_{j},\theta_{j+1}]$ and $[\theta_i,\theta_{i+1}]$.
   
    Note that the length $L_{i,j}$ and width $W_{i,j}$ of $S_{i,j}$ satisfy 
   %Note that if $i\neq j$, then all of these line segments have length bounded (up to a constant) by $|i-j|/m$:
   %
   \be
   \label{comparelength}
   |L_{ij}|\approx \frac{d(i,j)+1}{m},\quad |W_{ij}|\approx \frac{d(i,j)+1}{m^2},\quad 1\le i\le j\le m.
   \ee
   Here and later in this section, all constants of equivalence are absolute.
        %The set $S_{i,j}$ also has a certain width which is the maximum (Hausdorff) distance between two line segments contained in $\cL_{i,j}$.   This width is comparable with $(|i-j|+1)/m^2$.     
        It follows that the measure of $S_{i,j}$ satisfies
 %
 \be
 \label{measS}
 |S_{i,j}|\lesssim    \frac{(d(i,j)+1)^2}{m^3},\quad 1\le i\le j\le m.
 \ee
  
  
  
   
   
  \begin{lemma}
  \label{L:AD}
  Suppose that $m\ge 4$ is an even integer, $n=m(m-1)$,  and   $\phi=\sigma(\cdot;\xi,t)$  is any dictionary element whose line segment $L_\phi$ is in $\cL_{i,j}=\cL_{i,j}(m)$ with $\mu_i\neq \mu_j$.  Then there is a function $g\in X_n$   such that
  
  \noindent
  {\rm (i)}  $\phi(x)=g(x),\ x\notin S_{i,j}$,
  
  \noindent
  {\rm (ii)} $ \|\phi-g\|_{L_\infty(\Omega)}\le C  \frac{d(i,j)}{m^2} $,
  with $C$ an absolute constant.
  
  \noindent
  {\rm (iii)}       
  $ \|\phi-g\|_{L_2(\Omega )}\le     Cw(\phi)n^{-3/4}$, 
    with $C$ an absolute constant.
\vskip .1in
\noindent
If $\phi\in\cL_{i,i}$ for some $i$, then there is a $g\in X_n$ such that statement {\rm (iii)} holds.

  \end{lemma}
    
  %
  \noindent
  {\bf Proof:}   We first assume that  $0\le i<j\le m$.   Also, by reversing the roles of $i$ and $j$ if necessary, we can also assume that $j< m/2$.  Because of rotational symmetry we can assume that $i=0$, $i+1=1$, $0<j<m/2$. 
  Consider the linear function $\ell(x):= \xi \cdot x-t$.    Let the line segment $L_\phi=H_\phi \cap \Omega$ associated with $\phi$ be in
  $\cL_{i,j}$. Let $\mu_i=\mu_i(m)$, $i\in\Z$.  We use the following three functions $\phi_1,\phi_2,\phi_3$ in $X_n$ each of  whose line segments $L_{\phi_i}$ are contained in $\cL_{i,j}$.  Here, $L_{\phi_1}$ has endpoints $\mu_{i},\mu_{j+1}$, the second segment $L_{\phi_2}$ has end points $\mu_i,\mu_{j}$, and the third function $\phi_3$ has line segment $L_{\phi_3}$ with endpoints $\mu_{i+1},\mu_{j+1}$.  The orientation of these three atoms matches that of $\phi$.
  By this we mean that whenever $x\in\Omega$ is strictly outside $S_{i,j}$ and $\phi(x)>0$ then
  each of the functions $\phi_i$, $i=1,2,3$, will likewise be positive.  Similarly, if $x$ is strictly outside this strip and $\phi(x)=0$ the three functions $\phi_i$, $i=1,2,3$, will likewise vanish.
  
  Consider the three linear functions $\ell_j$, $j=1,2,3$, corresponding to these line segments.  That is, we have $\ell_i(x)=\xi_i'\cdot x-t_i'$  and $\phi_i(x)=\ell_i(x)_+$ with $\xi_i'\in S^1$ and $t_i'\in [-1,1]$. 
     Since these three linear functions are linearly independent, we can write
  %
  \be
  \label{write1}
  \ell=c_1\ell_1+c_2\ell_2+c_3\ell_3.
  \ee
  Specifically, let $\zeta$ be the point where $\ell_2(\zeta)=\ell_3(\zeta) = 0$. Then,
    %
    \be 
    \label{thecoeff}
    c_1= \frac{\ell(\zeta)}{\ell_1(\zeta)},\quad c_2= \frac{\ell(\mu_{j+1})}{\ell_2(\mu_{j+1})}, \quad c_3=\frac{\ell(\mu_{i})}{\ell_3(\mu_{i})}.
   \ee
   This follows by noting that with this choice \eqref{write1} holds at the affinely independent set of points $\zeta$, $\mu_{j+1}$ and $\mu_i$.
    
   We claim that
   \be
   \label{boundcoeff}
   |c_i| \le 1,\quad i=1,2,3.
   \ee
    Indeed, since the $\xi,\xi_i$ lie on the sphere it is clear that $|\ell_i(x)| = d(x,L_{\phi_i})$ and $|\ell(x)| = d(x,L_\phi)$ for any $x\in \mathbb{R}^2$ (here $d(x,L)$ denotes the distance from the point $x$ to the line $L$). We will show that 
   \be
   \label{toshow1}
   d(\mu_i,L_\phi) \leq d(\mu_i,L_{\phi_3}),
   \ee
   which implies $|c_3| \leq 1$. 
   A completely analogous argument shows that $|c_2| \leq 1$.
   
    For the proof of \eref{toshow1}, we assume that $j>i+1$.  If $j=i+1$, a similar argument applies (which we leave to the reader). Consider the trapezoid whose vertices are $\mu_i, \mu_{i+1}, \mu_j, \mu_{j+1}$ and let $T$ denote its interior.  
   Let $\bar{\mu}_i$ denote the orthogonal projection of $\mu_i$ onto the line $L_{\phi_3}$.  The angle formed by the vertices $\mu_{j+1}, \mu_{i+1},\mu_i$ is larger than or equal to $\pi/2$.  This means that  $\bar{\mu}_i$ lies either on or outside of the circle.  By the defining property of $L_\phi$ this line must intersect the segment   $[\mu_i,\bar{\mu}_i]$.  Therefore, $d(\mu_i,L_\phi) \leq d(\mu_i,L_{\phi_3})$ which proves \eref{toshow1} as desired.

    

   
    Next, we consider bounding $|c_1|$. The line segments $[\mu_i,\mu_{j+1}]$ and $[\mu_{i+1},\mu_j]$ are parallel, and the intersection point $\zeta$ lies on the perpendicular line $L_p$ connecting the midpoints of these two line segments.  Moreover,     the lengths of these segments satisfy $l([\mu_i,\mu_{j+1}]) > l([\mu_{i+1},\mu_j])$. This means that the distance from $\zeta$ to $L_{\phi_1}$ is greater than the distance to the parallel line segment $[\mu_{i+1},\mu_j]$. Finally, since $L_\phi\in \cL_{i,j}$, $L_\phi$ must intersect $L_p$, which implies that $d(\zeta,L_\phi) \leq d(\zeta,L_{\phi_1})$. This means that $|c_1| \leq 1$ as claimed.

    Now, consider the function 
   \be 
   \label{defg}
   g:=c_1\phi_1+c_2\phi_2+c_3\phi_3,
   \ee 
   which is in the linear space $X_n$.  This function agrees with $\phi$ outside $S_{i,j}$ so that
   (i) is satisfied. Each of the functions $\phi$ and $g$ have $L_\infty(S_{i,j})$ norm not exceeding the width $W_{ij} \leq C\frac{d(i,j)}{m^2}$ (they are $1$-Lipschitz and vanish on one edge) and so the  upper bound in (ii) follows.
   The function  $\phi-g$ is supported on $S_{i,j}$ and we have 
   \be
  \|\phi-g\|_{L_2(\Omega )}\le  \|\phi - g\|_{L_\infty(\Omega)} |S_{i,j}|^{1/2}\le C d(i,j)^{2} m^{-2-3/2} \le C|L_{ij}|^{2}m^{-1-1/2}.
  \label{phipnorm}
\ee
      Note that in this calculation we have use that $d(i,j) \approx (d(i,j) + 1)$. Since $d(i,j) > 1$, we easily see that $|L_{ij}| \approx |L_\phi| = w(\phi)$, which verifies (iii).
      
      Finally, if $L_\phi $ is in $\cL_{i,j}$ with $d(i,j) \leq 1$ then the conclusion follows   in the same way we proved \eref{phipnorm} by taking either $v=0$ or $v = w\cdot x + b$ to be linear function which matches the  linear part of $\phi$. 
          \hfill $\Box$
   

   
 
   
   
  
    \subsection{The approximation theorem}
    \label{SS:d2}
    
    Throughout this section $E_n(f):= E_n(f)_{L_2(\Omega)}$, $n\ge 1$ for any $f\in L_2(\Omega)$. 
    We can now state  the main theorem  to be proved in  this section.
        \begin{theorem}
   \label{T:d2}
   Let    $\Omega=B^2$ and $w(\phi)$, $\phi\in\cD(\Omega)$, be defined by \eref{aw2}.  Then for any $f\in\cV_w$,  we have
   %
   \be
   \label{Ta1}
   E_{n}(f) \le C \|f\|_{\cV_w(\Omega)} n^{- \frac {5}{4}}, \quad n\ge 1,
   \ee
   where $C$ is an absolute constant.     \end{theorem}
   \vskip .1in
   \noindent
   {\bf Proof:}    Since $\Sigma_n\subset \Sigma_{n+1}$, $n\ge 0$,  it is enough to prove the theorem for any $n=m(m-1)$ with $m\ge 4$ an even integer.  This means that we can apply Lemma \ref{L:AD}.    It is enough to prove the theorem for any function  $f$ from $U(\cV_w(\Omega))$. According to the definition of $\cV_w(\Omega)$, for $N$ sufficiently large, there is an $S\in\Sigma_N$ with $S=\sum_{j=1}^Na_j\phi_j$  such that
   %
   \be
   \label{T11}
   \|f-S\|_{L_2(\Omega)}\le n^{-5/4}\quad {\rm and} \quad \sum_{j=1}^N w(\phi_j) |a_j|\le 1.
   \ee
   For each $j$, let 
    $g_j\in X_n$ approximate the function $\phi_j$ appearing in the representation of $S$ according to (iii) of Lemma \ref{L:AD}.
    That is, we have
    %
    \be
    \label{wehave}
    \|\phi_j-g_j\|_{L_2(\Omega)}\le C_0 w(\phi_j)  n^{-3/4},
    \ee
    with $C_0$ an absolute constant.  The function $g:=\sum_{j=1}^N a_jg_j$ is in $X_n$ and hence in $\Sigma_n$.  We write
    %
    \be
    \label{writedecomp}
    f= f-S+h+g,\quad h:=S-g.
    \ee
      Therefore,
      %
      \be
      \label{T1}
      E_{3n}(f)\le  n^{-5/4} +E_{2n}(h).
      \ee
      We want to bound $E_{2n}(h)$.   We have $h=\sum_{j=1}^N a_j[\phi_j-v_j]$.  
      We consider the dictionary $\cD'=\{\psi_j\}_{j=1}^N$ with $\psi_j:= w(\phi_j)^{-1}(\phi_j-g_j)$.    According to \eref{T11} and \eref{wehave},  each $\psi_j$ has $L_2(\Omega)$ norm at most $C_0n^{-3/4}$ and $h=\sum_{j=1}^Nc_j'\psi_j$ with $\sum_{j=1}^N|c_j'|\le 1$.  It follows from  Maurey's theorem (see \eref{Mtheorem}) that $h$ can be approximated by a sum $T$ of $n$ terms from the dictionary $\cD'$ with error
      %
      \be
      \label{T12}
      \|h-T\|_{L_2(\Omega)} \le C n^{-3/4}n^{-1/2}=Cn^{-5/4},
      \ee
      with $C$ an absolute constant.
         The function $T $ is a sum of at most $2n$ terms from the original dictionary $\cD$.  Hence,
      %
      \be
      \label{T13}
      E_{2n}(h) \le C n^{-5/4}.
      \ee
    If we place this inequality back into \eref{T1}, we obtain 
   \be
      \label{T14}
      E_{3n}(f)\le  [1+C]n^{-5/4}
      \ee
  and the theorem follows.\hfill $\Box$

      We close this section by again emphasizing that Theorem \ref{T:d2} is an improvement on the
      known theorem that any $f\in\cV(\cD)$ satisfies $E_n(f)\le Cn^{-5/4}$ because the weighted
      variation space $\cV_w$ is strictly larger than the standard variation space $\cV$.
   \subsection{Weighted variation spaces for $\Omega=Q^2$}
   \label{SS:Q2}
    Although we do not formulate a general result, it will be clear that the techniques of this paper can be generalized to any convex domain $\Omega$.  In this section, we want to point out what such a result is for $Q^2:=[-1,1]^2$  since this will allow us to see the effect of the geometry of $\Omega$.    So, in going further in this section, we
    take $\Omega=Q^2$.  
    
    If $\phi$ is a ReLU atom, then the line segment $L_\phi$ relative to $\Omega$ is   $H_\phi\cap\Omega$.  The length
   $|L_\phi|$ can now be large even if $L_\phi$ is close to the boundary of $\Omega$,  for example when $L_\phi$ is parallel to 
   one of the sides of $\Omega$.  In other words, many fewer atoms $\phi$ will have small $|L_\phi|$.
   
   Let us sketch how the results and analysis for approximating general atoms $\phi$ given in \S \ref{SS:d2} for $B^2$,  changes in this case.   We now take a set of $m\sim \sqrt{n}$ equally spaced points on the boundary of $Q^2$.  We can associate
   each $\phi$ to a $\cL_{i,j}$ similar to the case of $B^2$ and create a linear space $X_n$ of dimension $m^2\sim n$ as before.  Now the analogue of Lemma \ref{L:AD}  says that any dictionary element $\phi$ can be approximated by an element of $g\in X_n$ to an accuracy  (corresponding to (iii) in that lemma)
   %
   \be
   \label{a2}
   \|\phi-g\|_{L_2(\Omega)} \le C_0 m^{-1} [|L_\phi| m^{-1}]^{1/2} =C_0m^{-3/2} |L_\phi|^{1/2}.
   \ee
   Here the factor $m^{-1}$ reflects the $L_\infty$ error and the bracketed factor is the measure of the support where $\phi$ and $g$
   differ.    
   
   Given the above calculations, we define $w(\phi):=|L_\phi|^{1/2}$  as the weight of the atom $\phi$ and use this weight to define
   $\cV_w(Q^2)$. The proof of Theorem \ref{T:d2}   now gives
     \begin{theorem}
   \label{T:Q2}
   Let  $d=2$ and  $\Omega=Q^2$ and define $w(\phi):=|L_\phi|^{1/2}$.  Then for any $f\in \cV_w$,  we have
   %
   \be
   % \label{Ta1}
   E_{n}(f) \le C \|f\|_{\cV_w(Q^2)}n^{- \frac {5}{4}}, \quad n\ge 1,
   \ee
   where $C$ is an absolute constant.     \end{theorem} 

    \section{Approximation in $L_2(B^d)$}
   \label{S:generald}
    
   We turn now to the case of approximation on the domain $\Omega=B^d$, $d>2$,  i.e.,  $\Omega$ is the unit  Euclidean ball
   of $\R^d$.   
       Recall that each atom $\phi=\phi(\cdot;\xi,t)$, satisfies $(\xi, t) \in \bar{Z}(\Omega) = S^{d-1} \times [-1,1]$.  To each atom, we assign the special weight
   %
   \be  
   \label{defweightd}
   w(\xi,t):= w^*(\xi,t) := (1-t)^{\frac{1}{2}+\frac{d}{4} }.
   \ee
    From \eref{normphi}, we see that this weight is admissible for $\Omega$. Thus, $w$ is taken to be given by \eref{defweightd}
    throughout this section.
    
    We recall the variation space $\cV_w$ introduced and studied in \S \ref{S:variation}. 
The main result of this paper is the following theorem
\begin{theorem}
    \label{T:B^d}
    If $f\in \cV_w=\cV_w(\Omega)$ then
    \be  
    \label{T21}
    E_n(f):=E_n(f)_{L_2(\Omega)}\le C\|f\|_{\cV_w}  n^{-\frac{1}{2}-\frac{3}{2d}}, \quad n\ge 1,
    \ee  
    where $C$ depends only on $d$.
\end{theorem}
\noindent
Notice that this theorem gives a stronger result than the previously known results on approximation by shallow neural networks with ReLU activation.  Indeed, although the approximation rate 
$O( n^{-\frac{1}{2}-\frac{3}{2d}})$ is the same as known whenever $f\in\cV$, the assumption of   membership in $\cV_w$
is a strictly weaker assumption than the membership in the traditional  variation space $\cV$.
       
   The remainder of this section is devoted to proving Theorem \ref{T:B^d}.  The proof is similar, in spirit, to the case $d=2$ which was given in Theorem \ref{T:d2}, but it is quite a bit more technical.
   Our first goal is to construct
    certain  linear  spaces $X_n$ of dimension at most $n$, which can be used to effectively approximate general ReLU atoms.
    The space $X_n$ will be the span of at most $n$  well chosen atoms from $\cD(\Omega)$.  The choice of the atoms used to define $X_n$ would intuitively be gotten by    discretizing the unit Euclidean sphere $S^{d-1}$ with $m^{d-1}$ uniformly spaced vectors and then  
    and to discretize the offsets in $T=[-1,1]$ with $m$ points.  Here $m$ is chosen so that $n\approx m^d$.   The discretization of $T$ will not be uniform but instead  will be be done in such a way that atoms whose support is small, i.e., atoms whose associated hyperplane lies near the boundary $S^{d-1}$ of $B^d$ will be very well approximated.
    
    Since there is no natural discretization of $S^{d-1}$, when $d>2$,  we proceed as follows. 
    Let $Q:=Q^d:=[-1,1]^d$ and $F$ be a face of $Q$. Each face $F$ is gotten by setting one of the coordinates, say, coordinate $i$,  equal to either $+1$ or $-1$.  Given one of these faces $F$, 
    we shall use dyadic partitions of $F$ into $d-1$ dimensional cubes of side length $2^{-k}$.
    We let $V_k(F)$ be the set of all vertices of this partition.  
     Thus, the cardinality of $V_k(F)$ is $(2^k+1)^{d-1}$.  We define $V_k$ to be the union    of all of the sets $V_k(F)$ as $F$ runs through the $2d$ faces of $Q$.  This gives a discrete set of points on the boundary of $Q$ with $\ell_\infty$ spacing $2^{-k}$.   To obtain our discrete set of points on $S^{d-1}$, we simply renormalize.  Namely,
    \be  
    \label{Wm}
    W_k:=\left\{\xi=\frac{\bar \xi}{\|\bar \xi\|}:\ \bar \xi\in V_k\right\}
    \ee
    gives a set of points on the boundary of $B^d$ that are quasi-uniformly spaced
     in the sense that
   %
   \be
   \label{qu}
    c_0 2^{-k}\le \dist (\xi_i, W_k\setminus \{\xi_i\}) \le C_02^{-k},
   \ee
   where the constants\footnote{In this paper, all constants depend only on $d$ and may change from line to line.  We use $c$ for small constants and $C$ for large constants, sometimes with subscripts.} depend only on $d$.  After adjusting for redundancy, we see that the cardinality of $W_k$ is   $2d(2^k)^{d-1}$.  It is important to note that
   %
   \be  
   \label{nesting}
   V_k\subset V_{k+1} \quad {\rm and} \quad W_k\subset W_{k+1},\quad k\ge 1.
   \ee 
   
   We also want to discretize the offsets $t$.  For this, we take  
   \be  
   \label{Tm}
   T_m:=\{-1<t_1<\dots   < t_{2m}=1\}.
   \ee
   We take the first $m$ of these to be equally spaced in $[-1,0]$, i.e., $t_j:=-1+j/m$, $j=1,\dots,m$.  For the remainder of these points, we take

\be  
\label{discretet}
     t_{j+m}:= \cos \frac{\pi (m-j)}{2m}=:\cos \theta_{j,m},\quad j=1,\dots, m.
     \ee
   Notice that the points in $T_m$ have a finer spacing near one.  Concerning this spacing, in going further we will use   the fact that for each  $m<j<2m-1$ and $t\in [t_j,t_{j+1}]$ we have
   %
   \be  
   \label{factspacing}
 \frac{ \pi\sqrt{1-t_{j+1}^2}}{2m}\le  |t_{j+1}-t_{j}|\le \frac{\pi \sqrt{1-t_j^2}}{2m}  \quad  {\rm and} \quad \sqrt{1-t_{j}^2}\le   2 \sqrt{1-t_{j+1}^2}\le 2 \sqrt{1-t^2}.
   \ee 
   To prove this, we note that for fixed $j=i+m$, $1\le i<m$, we have
   $$|t_{j+1}-t_j|= \frac{\pi}{2m} \sin\zeta =\frac{\pi}{2m}\sqrt{1-\cos^2 \zeta} $$ 
   where $\zeta\in [\theta_{i+1,m},\theta_{i,m}]$.  This gives the first inequalities in \eref{factspacing}.
   The second inequalities are proved similarly.
   The inequalities in \eref{factspacing} show that  for any given $t\in [t_j,t_{j+1}]$, $j\le 2m-2$, we have $|t_{j+1}-t_j|\approx  \sqrt{1-t^2}/m$ 
    with absolute constants in this comparison.  We shall use this fact repeatedly.
    
    We now want to define the linear space $X_n$.  Consider the set of atoms given by  
   \be 
   \label{phim}
   \Phi_{k,m}:=\{\phi(\cdot;\xi,t),\ \xi \in W_k,\ t\in T_m\}.
   \ee 
   This is a set of at most $ 4d m(2^k)^{d-1}$ ReLU atoms.  We  choose $k$ as the largest integer   such that $ 4d 2^k (2^k)^{d-1}\le n$ and then take $m=2^k$.
   Then, $\Phi_n:= \Phi_{k,m}$ is a set of at most $n$ atoms.
   We define 
   $X_n$ 
 as the linear space  
 %
 \be  
 \label{Vatoms}
 X_n:=\span (\Phi_n),
 \ee 
 Then, $X_n$ is a linear  space of  dimension  at most  $n$.

 We caution the reader that for the remainder of this paper, the integer $n$ is always taken of the form $n=4dm^d$, where $m=2^k$.
 It is enough to prove our approximation results for these $n$.

 
     
  



   
         

We now  proceed to show that any atom $\phi:=\phi(\cdot;\xi,t)$ from $\cD(\Omega)$  can be well approximated by
an element of the linear space $X_n$. We fix $\xi, t$ and $n$.  The approximation result we prove
is given in the following theorem.

\begin{theorem}
    \label{T:approxphi}
    For any $(\xi,t)\in\bar Z(\Omega)=S^{d-1}\times [-1,1]$, there is an element $g=g_\phi\in X_n$ such that
    \be 
    \label{Taphi}
    \|\phi-g\|_{L_2(\Omega)}\le C w(\phi)n^{-\frac{3}{2d}},
    \ee 
    with the constant $C$ depending only on 
    $d$.
\end{theorem}
The proof of this theorem is a bit technical and given in the next subsection.  After proving this 
theorem we prove Theorem \ref{T:B^d}. In the constructions given below there are two important constants $A$ and $L$ which depend only on $d$.  It will be useful to the reader if we explain their role and their definition. To prove Theorem \ref{T:approxphi}, we are presented with an atom
$\phi(x) =(\xi\cdot x-t)_+$ and need to construct an element $g\in X_n$ that approximates $\phi$ to the given accuracy.  From the definition of $X_n$, the function $g$ will take the form
%
\be 
\label{gform}
g=\sum_{j=1}^na_j\phi_j,
\ee 
where the $\phi_j$ are the atoms $\phi_j(x)=(\xi_j\cdot x-\tau_j)_+$ used to define $X_n$, where $\tau_j = t_{i(j)}$. The function $g$ that we construct to provide the approximation will agree with $\phi$
except on a certain set of small measure.  The only atoms active
in the definition of $g$, i.e., which have nonzero coefficients, will satisfy $\|\xi-\xi_j\|\le \frac{A}{m}$,
with $A\ge 2$ a fixed  integer constant depending only on $d$.  The size of $A$ is determined by the proof of Lemma \ref{L:decomega}
which is formulated later in this section and then proved  in the Appendix. Hence, in going forward, we can consider   $d$
arbitrary but fixed and $A$ depending only on $d$ to be fixed as well.
 

The constant $L$ is an integer which  is chosen in the proof of Lemma \ref{L:ti+}.  We will only have to consider values of $t$ such that $t\le t_{2m-L}$.  This restriction can be applied on $t$ because of the following remark.   

\begin{remark}
    \label{R:proof}
     Let us note and record the following: 
    
    \noindent {\rm (i)} If $t\ge t_{2m}$ or even $t\ge t_{m'}$ with $m'=2m- L$ with $L$ a fixed integer, then
    for any atom $\phi(\cdot;\xi,t)$ the statement \eref{Taphi} holds by simply taking $g=0$ and using the
    estimate \eref{normphi} for the norm of the atom.

\noindent {\rm (ii)} If $t\le C<1$ with $C$ fixed then the weight $w(\xi,t)\ge c$.  In this case, the existence of a space
$X_n$ spanned by $n$ atoms that provides the estimate \eref{Taphi} was given in \cite{SXSharp}.  While our space $X_n$ is defined differently  (we use a different discretization of the offsets $t$), the proof in this case is simpler and we exclude this case going forward.

\noindent {\rm (iii)}  If $\xi$ is one of the discrete vectors from $W_k$, then the proof of the existence of a $g$ for which \eref{Taphi} is quite simple. Indeed, one can take $g= a\phi(\cdot;\xi,t_i) +(1-a)\phi(\cdot;\xi, t_{i+1})$ where $t_i$ is the closest discrete offset to $t$ and $a$ is chosen so that $at_i+(1-a)t_{i+1}=t$.

In the proof of \eref{Taphi} we only need to provide a proof in the case that none of the special cases {\rm (i-iii)} holds.


\end{remark}
    
 

 

\subsection{The proof of Theorem \ref{T:approxphi}}
\label{SS:Proofapproxphi}
Obviously, we only need to prove the theorem for $m$ sufficiently large, say $m\ge m^*$ where $m^*$ depends on $d$.  The integer $m^*$ will be specified as we go along. Because of Remark \ref{R:proof} we only need to prove the theorem in the case $1/2<t\le t_{m-L}$, where $L$ is a fixed integer depending only on $d$. Again, we shall specify $L$ as we proceed in the proof.  Similarly, we can assume $\xi$ is not in $W_k$. 
We fix such an $\xi\in S^{d-1}$ and such a $t$ throughout this subsection. 


            We define
\be  
\label{defH}
H^+:=\{x:\ \xi\cdot x\ge 
t\} \quad  {\rm and} \quad H^-:=\{x:\ \xi\cdot x < t\}.
\ee
So $\phi$ is identically zero on $H^-$ and the linear function $\xi\cdot x -t$ on $H^+$.
For  any  one of the vectors $\xi_i$ appearing in the set $W_k$   and  any given a $t_j\in T_m$, we similarly define    
\be  
\label{hyper}
H_j^+:=H_j(\xi_i):=\{x\in\Omega: \xi_i\cdot x \ge t_j\},\quad H_j^-:=H_j^-(\xi_i):=\{x\in\Omega: \xi_i\cdot x<  t_j\}.
\ee

Given $\xi_i$, we want to choose a $t_j$ with $j\le 2m-1$ (depending on $i$) that is close to $t$ and so that $H_j^+$ is a subset of $H^+$.
This is always possible whenever $\|\xi-\xi_i\|\le A/m$ and  $t\le t_{m-L}$ and $L$ is sufficiently large (depending only on $A$).
One such choice for $t_j$ is to take
%
\be  
\label{appt1}
 t_i^+:=t^+(\xi_i):=\min \{t_j\in T_m:  H_j^+\subset H^+\}.
\ee
 
  

 If $t_i^+=t_j$,  we let 
 \be
 \label{deftildeT}
 \tilde t_i:= t_{j+1}.
 \ee
 Then, we will also have $H^+_{j+1}\subset H^+$.
 
 

 We now proceed to proving Theorem \ref{T:approxphi}.  We begin by  recalling  the following fact.
\begin{lemma}
    \label{L:ip}
    If $\xi,\xi'\in S^{d-1}$ with $\|\xi-\xi'\|=\delta$, then we have
    %
    \be 
    \label{Lip}
    \xi\cdot\xi'=1-\delta^2/2.
    \ee
\end{lemma}
\vskip .1in
\noindent{\bf Proof:} By rotation, we can assume $\xi=e_1=(1,0,\dots,0)$ and $\xi'=\alpha e_1+\eta$ where $\eta$ is orthogonal to $e_1$ and $\|\eta\|^2=1-\alpha^2$.  Therefore,
$$
\delta^2= (1-\alpha)^2+\|\eta\|^2 = 2-2\alpha =2-2\xi\cdot\xi' $$
 and so \eref{Lip} follows. \hfill $\Box$
 
 




The last lemma allows us to compare $t_i^+$ with $t$.
\begin{lemma}
     \label{L:ti+}
    Given the integer $A$, we define 
    \be 
    \label{defL}
    L:=(A+1)^2=A^2+2A+1.
    \ee 
    If $m^*$ is sufficiently large, depending only on $d$ and $m\ge m^*$, then  whenever  $t\in [1/2,t_{2m-L}]$  and $ \|\xi-\xi_i\|\le \frac{A}{m}$,  then $t_i^+$ and $\tilde t_i$ are well defined, and  we have
     \be 
     \label{Ltin}
     t\le t_i^+ \le \tilde t_i\le  t+\frac{C_1}{m}\sqrt{1-{t}^2}, 
     \ee 
     where $C_1 $ depends only on $d$.
\end{lemma}
\vskip .1in
\noindent 
{\bf Proof:}  
     Consider first the existence of $t_i^+, \tilde t_i$.   It is enough to show that if $t\le t_{2m-L}$, and $\xi_i$ satisfies $\|\xi-\xi_i\|\le \frac{A}{m}$, then there is a $j\le 2 m-2$ such that $H_j^+\subset H^+$. Suppose that $j$ is such that $t_{j}\ge t$ but $H_{j}^+$ is not contained in $H^+$.   Then,    there is an $x=t_{j}\xi_i+\eta$
     with $\eta$ orthogonal to $\xi_i$ and $\|\eta\|\le \sqrt{1-t_{j}^2}$ and
     $$
     x\cdot\xi = t_{j}\xi\cdot\xi_i + \eta\cdot(\xi-\xi_i)< t .
     $$
      From Lemma \ref{L:ip}, we know that $\xi\cdot \xi_j\ge 1-\frac{A^2}{m^2}$ and so we must have
      
    \be 
    \label{Ltin1}
       \left(1-\frac{A^2}{m^2}\right) t_{j} \le t+ \|\xi-\xi_i\|\sqrt{1-t_{j}^2}\le  t+ \frac{A}{m}\sqrt{1-t_j^2}.
     \ee  
      That is, we must have
      \be 
    \label{Ltin11}
     t_{j}\le  t+ \frac{A}{m}\sqrt{1-t_j^2}+\frac{A^2}{m^2}\le  t_{2m-L}+ \frac{A}{m}\sqrt{1-t_j^2}+\frac{A^2}{m^2}.
     \ee  
If we write $j=2m-k$, and use the definition of the $t_j$ (see \eref{discretet}) we can rewrite \eref{Ltin11}
as
\be 
\label{Ltin12}
     \cos \frac{\pi k}{2m} - \cos \frac{\pi L}{2m}  \le     \frac{A}{m}\sin \frac{\pi k}{2m}+\frac{A^2}{m^2}
     \le \frac{\pi A k}{2m^2} +\frac{A^2}{m^2}\le \frac{A^2+2Ak}{m^2}.
     \ee 
The left side of \eref{Ltin12} is larger than $\frac{k(L-k)}{m^2}$ and so we see with the above definition of $L$,
\eref{Ltin12} is violated when $k=2$.   This proves that $t_i^+$ and $\tilde t_i$ are well defined.

We turn now to proving \eref{Ltin}.
      First note that if there is  $j\in\{m+1,\dots,2m\}$   such that $H_j^+\subset H^+$,
 then  we must have
     $t_j\xi_i\cdot \xi\ge t$ which gives the left inequality in
     \eref{Ltin}.   To prove the right  inequality in \eref{Ltin}, we let $t_i^+=t_j$, $\tilde t_i=t_{j+1}$.  It follows
     from the minimality in the definition of $t_i^+$ that we must have $H_{j-1}^+$ is not contained in $H^+$.  Thus, the inequality \eref{Ltin1} holds with $j$ replaced by $j-1$. This gives
      \be 
    \label{Ltin2}
      \left(1-\frac{A^2}{m^2}\right)  t_{j-1}  \le t+ \|\xi-\xi_i\|\sqrt{1-t_{j-1}^2}\le  t+  \frac{2A}{m}\sqrt{1-{t_i^+}^2},
     \ee  
   where the last inequality uses \eref{factspacing}. 
      From \eref{factspacing}, we also have
      $$ 
       t_j\le t_{j-1}+ (t_j-t_{j-1}) \le  t_{j-1}+ \frac{\pi}{m}\sqrt{1-t_j^2}.
      $$
        If we multiply both sides of this last inequality by $(1-\frac{A^2}{m^2}) $ and use \eref{Ltin2} we obtain 
$$   \left(1-\frac{A^2}{m^2}\right)  t_i^+ \le  t+\frac{2(A+2)}{m}\sqrt{1-t^2},$$
      where we used that $t_i^+\ge t$ .    We also have $\tilde t_i\le t_i^++ \frac{\pi}{2m}\sqrt{1-t^2}$ because of \eref{factspacing}.  When these facts are used in the last inequality we   obtain the right inequality       in \eref{Ltin}.\hfill $\Box$
    
  Now consider any $\xi\in S^{d-1}$ and define
  %
  \be 
  \label{defWomega}
  W_k(\xi):=\left\{\xi_i\in W_k: \ \|\xi-\xi_i\|\le \frac{A}{m}\right\}\quad{\rm and} \quad t^+:=t^+(\xi):=\max_{\xi_i\in W_k(\xi)}t_i^+.
  \ee 
  We can write $t_i^+=t_j$ for some $j\le 2m-1$ and define $\tilde t:=\tilde t(\xi):=t_{j+1}$. From the previous lemma, we know that
  % 
   
  \be 
     \label{Ltin3}
     t\le t^+ \le \tilde t\le  t+\frac{C_1}{m}\sqrt{1-{t}^2}, 
     \ee 
     where $C_1 $ depends only on $d$.
  
For the construction of $g$, we use the following  lemma.  

\begin{lemma}
\label{L:decomega}
There is a constant $m^*$ depending only on $d$   such that the following holds.
Given any $m\ge m^*$ and any $\xi\in S^{d-1}$ and any $ 1/2\le t\le t_{2m-L}$, there exists  $(a_i^+) $, $(\tilde a_i) $ such that
\vskip .1in
\noindent 
{\rm(i)}\quad 
       $ \xi = \sum_{\xi_i\in W_k(\xi)} a^+_i\xi_i + \sum_{\xi_i\in W_k(\xi)} \tilde a_i\xi_i $,
  \vskip .1in
 

\noindent 
{\rm(ii)}\quad     
     $t^+\sum_{\xi_i\in W_k(\xi)} a^+_i + \tilde t \sum_{\xi_i\in W_k(\xi)} \tilde a_i  = t$,
     \vskip .1in
     \noindent 
{\rm(iii)}\quad     
      $\sum_{\xi_i\in W_k(\xi)} |a^+_i| + \sum_{\xi_i\in W_k(\xi)} |\tilde a_i| \leq C_1$, 
  where $C_1$ depends only on $d$.   

\end{lemma}
\noindent
The proof of this lemma is technical and so we place it in the Appendix so as not to interrupt the flow of the proof of  Theorem \ref{T:approxphi}.
 
    
 


We define the following function $g$ which will be used to approximate $\phi=\phi(\cdot;\xi,t)$ in the case
$1/2\le t\le t_{2m-L}$
\be\label{defv}
g(x):=\sum_{\xi_i\in W_k(\xi)}[ a^+_i (\xi_i\cdot x -t^+)_+ +   \tilde a_i(\xi_i\cdot x-\tilde t)_+]
\ee
where the coefficients   come from Lemma \ref{L:decomega}.
The functions appearing in the representation of $g$ are all in $X_n$ and therefore $g$ is also in $X_n$.
 From Lemma \ref{L:decomega},  we obtain
\be\label{yes}
\phi(x)-g(x)=\left[ \sum_{\xi_i\in W_k(\xi)} a^+_i (\xi_i\cdot x -t^+) +  \tilde a_i(\xi_i\cdot x-\tilde t)\right]_+  -\sum_{\xi_i\in W_k(\xi)} [a^+_i (\xi_i\cdot x -t^+)_+ +  \tilde a_i(\xi_i\cdot x-\tilde t)_+]
\ee
 

Before bounding the error in approximating $\phi$ by $g$, let us make some remarks to motivate the idea
of how to estimate this error. Notice that if $x\in \Omega$ is such that $\xi_i\cdot x\ge \tilde t$ for all $\xi_i\in W_k(\xi)$,  then $x$ is also in $H^+$ and so
  $g(x)=\phi(x)$.  Similarly, if 
$x\in H^-$ then   $\phi(x)=g(x)=0$.  This means that the only points $x\in \Omega$ where
$\phi(x)\neq g(x)$ must be in one of the sets
%
\be  
\label{must}
\tilde \Omega_i:=\{x\in\Omega: \xi\cdot x> t,\ \xi_i\cdot x\le   \tilde t\}.
\ee  
We will now proceed to bound the measure of each of these sets and also bound the error $|\phi(x)-g(x)|$ on each of these sets.

 
\begin{lemma}
 \label{L:error}
There are constants $C$ and $m^*$ depending only on $d$ such that the following holds for $m\ge m^*$ and any $1/2\le t\le t_{2m-L}$:

\noindent
{\rm (i)} If $x\in \tilde \Omega:= \bigcup_{\xi_i\in W_k(\xi)} \tilde \Omega_i$, then 
%
 \be  
 \label{Le1}
 |\phi(x)-g(x)|\le C\sqrt{1-t^2}/m.
 \ee 
 \noindent{\rm (ii)} The measure of $\tilde \Omega$ is bounded by
 \be 
 \label{Le2}
  |\tilde \Omega|_d\le C (1-t^2)^{d/2}/m.
 \ee
 
 
   \end{lemma}
 \vskip .1in
\noindent
{\bf Proof:}  
From Lemma \ref{L:ti+} we have that

\be  
\label{boundti2}
t\le  t^+\le \tilde t \le  t+C_1\frac{\sqrt{1-t^2}}{m},\quad i=1,\dots,M
\ee 
where $C_1$ depends only on $d$.
Now, for any fixed $i$ consider any $x\in \tilde \Omega_i$.  Our   goal is to estimate the distance from $x$ to the hyperplane $H:=\{z:\ z\cdot \xi=t\}$.  From the definition of $W_k(\xi)$, we have
$\|\xi-\xi_i\|\le  A/m$.  Since $\alpha:=x\cdot\xi>t$, we can write  
   \be  
   \label{repx} x= \alpha   \xi+  \eta, 
   \ee  
   where   $ \eta$ is orthogonal to $  \xi$ and  
   \be  
   \label{eta}
   \|  \eta\|\le \sqrt{1-\alpha^2}\le \sqrt{1-t^2} .
   \ee
   We want to show that $\alpha$ cannot be too large.  Since $x\in \tilde \Omega_i$, we know that 
   \be  
   \label{proj}
   (x\cdot\xi_i)=\alpha\xi\cdot \xi_i + \eta\cdot\xi_i \le \tilde t ,
   \ee  
   and
   \be  
   \label{note}
   |  \eta\cdot\xi_i|=| \eta\cdot (\xi_i- \xi)|\le A\frac{ \sqrt{1-  t ^2}}{m}.
   \ee  
Using   the inequality $\xi\cdot\xi_i\ge 1-A^2/m^2$ (see Lemma \ref{L:ip}) and \eref{note} back in \eref{proj}, we obtain
%
\be  
\label{gives1}
  (1-A^2m^{-2})\alpha \le \tilde t + A\frac{ \sqrt{1-  t ^2}}{m}\le  t+C_1\frac{\sqrt{1-t^2}}{m} +A\frac{ \sqrt{1-  t ^2}}{m} , 
 \ee 
 where the last inequality used \eref{boundti2}.  Going further, we note that since by assumption
 $t\le t_{2m-L}$, we have
 $$(1-A^2m^{-2})^{-1}\le 1+2Am^{-2}\le 1+2A\frac{\sqrt{1-t^2}}{m}.$$
 Using this estimate back in \eref{gives1}, we arrive at
 \be  
 \label{arriveat}
 \alpha \le t+C_2\frac{\sqrt{1-t^2}}{m},
 \ee
 with $C_2$ depending only on $d$.
 It is important to note that this bound is independent of $i$.  Therefore any point $x$ in $\tilde \Omega$
 can be written as $x=\alpha\xi+\eta$ where $\alpha $ satisfies \eref{arriveat} and $\|\eta\|\le \sqrt{1-t^2}$.  The measure of the set of such $\eta$ is $\le C_3[\sqrt{1-t^2}]^{d-1}$. Hence, we have proven (ii).  
 
  The inequality \eref{arriveat} also shows that  
 \be 
 \label{boundphi1}\phi(x)\le C_2\frac{\sqrt{1-t^2}}{m},\quad x\in \tilde \Omega.
 \ee 
  Since the functions appearing in the sum for $g$ are all smaller than $\phi$ from (iii) of Lemma \ref{L:decomega}
  we conclude that
\be 
 |g(x)|\le   C_3\frac{\sqrt{1-t^2}}{m},\quad x\in \tilde \Omega.
 \ee 
This proves (i) and concludes the proof of the lemma.
\hfil $\Box$
\vskip .1in
\noindent{\bf  Proof of  Theorem \ref{T:approxphi}}  According to Remark \ref{R:proof}, we only need to consider  the case $\phi=\phi(\cdot;\xi,t)$ when $1/2\le  t<t_{2m-L}$.
We return to our representation \eref{yes}. As already mentioned $\phi(x)=g(x)$ outside
the set $\tilde \Omega$.  From Lemma \ref{L:error} it follows that
\be  
\label{wehave3}
\|\phi-g\|_{L_2(\Omega)}\le    C|\tilde \Omega|_d^{1/2}\frac{\sqrt{1-t^2}}{m}\le Cw(\phi)m^{-3/2}.
\ee 
Since $m^d\ge c_dn$, we have completed the proof of Theorem \ref{T:approxphi}.
\hfill $\Box$

\subsection{Proof of Theorem \ref{T:B^d}}
We can now prove Theorem \ref{T:B^d}
in the same way we proved the case $d=2$.    Let  $f$ be any fixed function from $\cV_w(\Omega)$. According to the definition of $\cV_w(\Omega)$, for $N$ sufficiently large, there is an $S\in\Sigma_N$ with $S=\sum_{j=1}^Na_j\phi_j$  such that
   %
   \be
   % \label{T111}
   \|f-S\|_{L_2(\Omega)}\le M n^{-\frac{1}{2}-\frac{3}{2d}}\quad {\rm and} \quad \sum_{j=1}^N w(\phi_j) |a_j|\le \|f\|_{\cV_w}=:M.
   \ee
   For each $j$, let 
    $g_j\in X_n$ approximate the function $\phi_j$ appearing in the representation of $S$ according to   Theorem \ref {T:approxphi}.
    That is, we have
    %
    \be
    \label{wehave1}
    \|\phi_j-g_j\|_{L_2(\Omega)}\le C w(\phi_j) n^{-\frac{3}{2d}},
    \ee
    with $C$ depending only on $d$.  The function $g:=\sum_{j=1}^N a_jg_j$ is in $X_n$ and hence in $\Sigma_n$.  We write
    %
    \be
    \label{writedecomp1}
    f= f-S+h+g,\quad h:=S-g=\sum_{j=1}^N a_j[\phi_j-g_j].
    \ee
      Therefore,
      %
      \be
      \label{T111}
      E_{3n}(f)\le M n^{-\frac{1}{2}-\frac{3}{2d}} +E_{2n}(h).
      \ee 
      
      To bound $E_{2n}(h)$, we  consider the dictionary $\cD'=\{\psi_j\}_{j=1}^N$ with $\psi_j:= w(\phi_j)^{-1}(\phi_j-g_j)$.    According to Theorem \ref{T:approxphi}  each $\psi_j$ has $L_2(\Omega)$ norm at most $Cn^{-\frac{3}{3d}}$ and $h=\sum_{j=1}^Nc_j\psi_j$ with  $\sum_{j=1}^N|c_j|\le M$.  It follows from Maurey's Theorem (see \eref{Mtheorem}) that $h$ can be approximated by a sum $T$ of $n$ terms from the dictionary $\cD'$ with error
      %
      \be
      \label{T121}
      \|h-T\|_{L_2(\Omega)} \le CMn^{-\frac{3}{2d}}n^{-1/2}=CMn^{\frac{1}{2}-\frac{3}{2d}}.
      \ee
         The function $T $ is a sum of at most $2n$ terms from the original dictionary $\cD$.  Hence,
      %
      \be
      \label{T131}
      E_{2n}(h) \le CM n^{-\frac{1}{2}-\frac{3}{2d}}.
      \ee
    If we place this inequality back into \eref{T111}, we obtain 
   \be
      \label{T141}
      E_{3n}(f)\le  CM n^{-\frac{1}{2}-\frac{3}{2d}},
      \ee
  and the theorem follows.\hfill $\Box$

\begin{remark}
    \label{R:Qd}
If we consider $\Omega=Q^d$ in place of $B^d$ then for the weight $w(\phi(\cdot; \xi,t))= |L_\phi|^{1/2}$ where $|L_\phi|$ is the $(d-1)$-dimensional measure of the intersection $Q_d\cap L_\phi$, we obtain
%
\be 
\label{RQd}
E_n(f)_{L_2(Q^d)}\le Cn^{-\frac{1}{2}-\frac{3}{2d}} \|f\|_{\cV_w},\quad f\in\cV_w.
\ee 
We do not give the proof which follows along the lines of the case $d=2$ given in \S \ref{SS:Q2}.
\end{remark}


\input{conclusion}
 




   


 

 
 
     \section{Appendix}
     \label{S:appendix}
    In this appendix, we prove Lemma \ref{L:decomega}.  We let $\xi $ be arbitrary but fixed throughout this section.  We begin by recalling some well known results on the representation of points $x$ in a cube $R\subset \R^d$ in terms of the vertices of $R$.
     Given any cube $R\subset \R^d$, we let $V(R)$ denote its set of vertices.
 Let us first consider the case $R=U$ where  $U:=U^d:=[0,1]^d$.     We denote the vertices in $V(U)$ by $e$.
 So $e$ is a vector with $d$ components $e=(e_1,\dots,e_d)$ with each $e_j\in\{0,1\}$.  There are $2^d$ such $e$. 
 
 Let
 %
 \be 
 \label{erep}
 \ell_{0}(s):= (1-s)\quad \ell_1(s)=s,\quad s\in \R.
 \ee 
 For each $e\in V$, we define
 \be 
 \label{defell}
 \ell_e(x):=\prod_{j=1}^d \ell_{e_j}(x_j),\quad  x=(x_1,\dots,x_d)\in U.
 \ee
 Then,  $\ell_e(e')=0$, $e'\neq e$ and $\ell_e(e)=1$.  Any $x\in U$ is represented as
 \be 
 \label{erep1}
 x=\sum_{e\in V}\ell_e(x) e.
 \ee
 This is a convex representation in that the coefficients $\ell_e(x)\in[0,1]$, $e\in V(U)$,  and they sum to one.
 
 
 Now consider an  arbitrary  cube $R\subset \R^d$.   We can write $R=v+\alpha [0,1]^d=v+\alpha U$ with $\alpha>0$.  This cube has vertices $v+ \alpha e$, $e\in V$.   Any point  $x=v+\alpha y$, $y\in U$,  from  this cube,
 has the representation  
 \be 
 \label{erep2}
 x=v+\alpha \sum_{e\in V}\ell_e(y) e=\sum_{e\in V} \ell_e(y)[v+\alpha  e],
 \ee
 because $\sum_{e\in V}\ell_e(y)=1$.
 Again this is the representation of $x$ as a convex combination of the vertices  $V(R)$ of $R$.
 Let us note that here we are taking $v$ as the smallest vertex of $R$.  We can derive a similar decomposition by starting with any other vertex of $R$.
 
 We use the above to find a variety of representations of any $x$ on the boundary of  the cube $Q^d:=[-1,1]^d$. Later, we shall apply these representations to $x=\bar\xi$ and subsequently to $\xi\in S^{d-1}$.   Let $x$ be in the face $F$ of $Q^d$. We assume that the   $d-1$ dimensional face $F$ of $Q^d$ corresponds to $x_1=1$.  
 We will derive representations for points $x\in F$.  Similar representations hold for any of the other faces of $Q^d$. 
 
 Any $x\in F$ takes the form $x=(1,\tilde x)$ with $\tilde x\in [-1,1]^{d-1}$.   
 Suppose now that $R$ is any $d-1$ dimensional cube on $F$, i.e., $R$ consist of points $(1,\tilde x)$ where $\tilde x$ is in a $d-1$ dimensional cube $\tilde R$.
      From the above, we can write $\tilde x=\tilde v +\alpha y$, $y\in U^{d-1}$, where $\tilde v$ is the smallest vertex of $R$.  Therefore, we have  
 \be 
 \label{xrep}
 \tilde x= \tilde v +\alpha y=\tilde v+\alpha \sum_{e\in V(U^{d-1})}\ell_e(y) e=\sum_{e\in V(U^{d-1})} \ell_e(y)[\tilde v+\alpha  e] =\sum_{\nu\in V(\tilde R)} \gamma_\nu \nu,
  \ee
  where the $\nu$ are the vertices of $\tilde R$ and
  \be 
  \label{gammas}
  \gamma_\nu =\ell_e(y),\quad {\rm when} \ \nu= \tilde v+ \alpha e.
  \ee
   This is a representation of $\tilde x$ as a convex combination of the vertices $V(\tilde R)$.

   
 
 
  
 
 
 
  We  turn now to representations of  $\xi\in S^{d-1}$. We write $\xi=\frac{\bar \xi }{\|\bar\xi\|}$ where $\bar\xi$ lies on the boundary of $Q^d=[-1,1]^d$. 
  We assume $\bar\xi $ lies on the face $F$ corresponding to first coordinate equal to one.  All other cases are handled similarly.
 We write $\bar \xi=(1,\tilde x)$ with $\tilde x\in [-1,1]^{d-1}$ and use the representations of $\tilde x$ given above.
 Recall the discrete set of points $F_k$, with $m=2^{k}$. If $k'<k$ then $F_{k'}\subset F_k$. We fix such a $k'$ to be chosen in a moment. 
 
 We let $A\ge 1$ be an integer whose value will be chosen below. We place ourselves in the following
 situation where $\tilde x \in \tilde v+\delta U^{d-1}=:\tilde R\subset \tilde R':=\tilde v+\delta' U^{d-1}$ where $\tilde v\in F_k$, $\delta=2^{-k}=1/m$  and
 $\delta'=2^{-k'}=A\delta$ with $A=2^{k-k'}$.    The assumption that  $\tilde x\in \tilde R$ for which there is such a $\tilde R$ and $\tilde R'$ is a restriction on the position of $\tilde x$ in $[-1,1]^{d-1}$.  When this is not the case, the argument below needs to be adjusted by changing the choice of the initial vertex and the direction for the representation.  Since the adjustment is purely notational, we leave it to the reader.
 
 
 
 
 
 
 
 
     We will give two representations of  $\tilde x$, respectively $\bar \xi$; the one in terms of the vertices of $\tilde R$ and the second in terms of the vertices of $\tilde R'$.
   For the first representation, we use \eref{xrep} with $\alpha=\delta$ to write
 \be 
 \label{repomegabar}
 \bar \xi= \sum_{\nu\in V(\tilde R)} \gamma_\nu (1,\nu)=\sum_{\nu\in V(\tilde R)} \gamma_\nu  \sqrt{(1+\|\nu\|^2)} \xi_\nu,\quad \xi_\nu= \frac{(1,\nu)}{\sqrt{1+\|\nu\|^2}},
 \ee
 with the coefficients $\gamma_\nu$  given by \eref{gammas}.  Notice that the $\xi_\nu$ are all in $W_k$. This gives the representation  
 \be 
 \label{repomega1}
  \xi=  \sum_{\nu\in V(\tilde R)} a_\nu \xi_\nu,\quad a_\nu:= \frac{\gamma_\nu  \sqrt{(1+\|\nu\|^2)} }{\|\bar\xi\|}.
 \ee

%%%% JONATHAN'S ARGUMENT IS COMMENTED OUT BELOW

%  \textcolor{red}{Alternative argument follows.}
 
%  \textcolor{red}{We obtain the second representation in an analogous manner by writing $\tilde x = \tilde v + A\delta y'$ with $y'\in U^{d-1}$. This gives the representation  
%  \be 
%  \label{repomega2-alt}
%   \xi=  \sum_{\nu\in V(\tilde R')} a'_\nu \xi_\nu,\quad a'_\nu:= \frac{\gamma'_\nu  \sqrt{(1+\|\nu\|^2)} }{\|\bar\xi\|}.
%  \ee
%  with the coefficients $\gamma_\nu' = \ell_e(y')$  given by \eref{gammas}.}

%  \textcolor{red}{We now want to estimate the  sums 
%  \be
%  \label{sums-alt} S:=\sum_{\nu\in V(\tilde R)} a_\nu,\quad S'= \sum_{\nu\in V(\tilde R')} a'_\nu,
%  \ee}

%  \textcolor{red}{\begin{lemma} There is an $m^*=m^*(d)$, depending only on $d$, such that whenever $m\ge m^*$ and $A$ is sufficiently large (depending only on $d$), the following holds.
% Whenever $\xi$ is not a vertex in $W_k$, i.e.,   $\bar\xi=(1,\tilde x)$ where $\tilde x=\tilde v+y$ where $y\neq 0$, we have 
% \be 
% \label{compare} 
% S=1+\epsilon\quad {\rm and} \quad S'= 1+\epsilon ',\quad {\rm where}\quad 0<2\epsilon < \epsilon',
% \ee 
% \end{lemma}}
 
%  \textcolor{red}{{\bf Proof:} Consider the function $h:[-1,1]^{d-1}\rightarrow \mathbb{R}$ defined by $h(\nu) = \sqrt{1+\|\nu\|^2}$. From equations \eqref{repomega1} and \eqref{repomega2-alt} we see that
% \be\label{equations-for-S}
%     S = \frac{1}{h(\tilde x)}\sum_{\nu\in V(\tilde R)} \gamma_\nu h(\nu),~S' = \frac{1}{h(\tilde x)}\sum_{\nu\in V(\tilde R')} \gamma'_\nu h(\nu),
% \ee
% where $\bar{\xi} = (1,\tilde x)$ as before. We calculate first that
% \be
%     D^2 h(\nu) = \frac{1}{h(\nu)}\left(I_{d-1} - \frac{\nu \nu^T}{h(\nu)^2}\right).
% \ee
% For $\nu \in [-1,1]^{d-1}$, we have $1 \leq h(\nu) \leq \sqrt{d}$ and $0\leq \|\nu\|/h(\nu) \leq \sqrt{1-1/d}$ so that
% \be\label{hessian-bound}
%     \frac{1}{d^{3/2}}I_{d-1} \preceq D^2h(\nu) \preceq I_{d-1}.
% \ee
% The next step is to write, for $\nu\in V(\tilde R)$ or $\nu\in V(\tilde R')$
% \be
%     h(\nu) = h(\tilde x) + \nabla h(\tilde{x})\cdot (\nu - \tilde x) + \int_0^1 t\left[(\nu - \tilde x)^TD^2h((1-t)\nu + t\tilde x)(\nu - \tilde x)\right]dt.
% \ee
% Equation \eqref{hessian-bound} now implies that
% \be
%     \frac{1}{2d^{3/2}}\|\nu - \tilde x\|^2\leq h(\nu) - h(\tilde x) - \nabla h(\tilde{x})\cdot (\nu - \tilde x)\leq \frac{1}{2}\|\nu - \tilde x\|^2.
% \ee
% Plugging this into equation \eqref{equations-for-S} and using the fact that by construction
% $$
%     \sum_{\nu\in V(\tilde R)} \gamma_\nu (\nu - \tilde x) = \sum_{\nu\in V(\tilde R')} \gamma'_\nu (\nu - \tilde x) = 0
% $$
% we get that $\epsilon,\epsilon' > 0$ and 
% \be\label{epsilon-bound-eq}
%     \epsilon \leq \frac{1}{2h(\tilde x)} \sum_{\nu\in V(\tilde R)} \gamma_\nu\|\nu - \tilde x\|^2,~\epsilon' \geq \frac{1}{2d^{3/2}h(\tilde x)}\sum_{\nu\in V(\tilde R')} \gamma'_\nu\|\nu - \tilde x\|^2.
% \ee
% Thus it suffices to compare the two quantities
% $$
%  \sum_{\nu\in V(\tilde R)} \gamma_\nu\|\nu - \tilde x\|^2~~\text{and}~~\sum_{\nu\in V(\tilde R')} \gamma'_\nu\|\nu - \tilde x\|^2.
% $$
% We expand out the squared norms and the coefficients $\gamma_\nu$ to obtain (recall that $\tilde x = \tilde v + \delta y$)
% \be
% \begin{split}
% \sum_{\nu\in V(\tilde R)} \gamma_\nu\|\nu - \tilde x\|^2 &= \sum_{i=1}^{d-1} \sum_{\nu\in V(\tilde R)} \gamma_\nu(\nu_i - \tilde x_i)^2\\
% &=\sum_{i=1}^{d-1} \sum_{e\in \{0,1\}^{d-1}} \prod_{j=1}^{d-1}\ell_{e_j}(y_j)(\tilde v_i + \delta e_i - \tilde x_i)^2\\
% &= \sum_{i=1}^{d-1} \sum_{\tau=0}^1 \ell_{\tau}(y_i)(\tilde v_i + \delta k - \tilde x_i)^2\sum_{\substack{e\in \{0,1\}^{d-1}\\e_i=\tau}}\prod_{j\neq i}\ell_{e_j}(y_j)\\
% &=\sum_{i=1}^{d-1} \sum_{\tau=0}^1 \ell_{\tau}(y_i)(\tilde v_i + \delta k - \tilde x_i)^2,
% \end{split}
% \ee
% since by construction $$\sum_{\substack{e\in \{0,1\}^{d-1}\\e_i=\tau}}\prod_{j\neq i}\ell_{e_j}(y_j) = \prod_{j\neq i}(\ell_0(y_j) + \ell_1(y_j)) = 1.$$
% Next, recalling the definition of $\ell_\tau$ and $y$, we finally get
% \be
% \begin{split}
%     \sum_{\nu\in V(\tilde R)} \gamma_\nu\|\nu - \tilde x\|^2 &= \delta^{-1}\sum_{i=1}^{d-1} (\tilde x_i - \tilde v_i)^2\left(\delta-(\tilde x_i - \tilde v_i)\right) +  (\tilde x_i - \tilde v_i)\left(\delta-(\tilde x_i - \tilde v_i)\right)^2\\
%     &= \sum_{i=1}^{d-1} (\tilde x_i - \tilde v_i)\left(\delta-(\tilde x_i - \tilde v_i)\right).
% \end{split}
% \ee
% Likewise, for the other sum we get
% \be
% \sum_{\nu\in V(\tilde R')} \gamma'_\nu\|\nu - \tilde x\|^2 =  \sum_{i=1}^{d-1} (\tilde x_i - \tilde v_i)\left(A\delta-(\tilde x_i - \tilde v_i)\right).
% \ee
% Since $\tilde{x}_i - \tilde{v}_i \geq 0$, we have $A\delta-(\tilde x_i - \tilde v_i) \geq A\left(\delta-(\tilde x_i - \tilde v_i)\right)$ so that
% \be
% \sum_{\nu\in V(\tilde R')} \gamma'_\nu\|\nu - \tilde x\|^2 \ge A\sum_{\nu\in V(\tilde R)} \gamma_\nu\|\nu - \tilde x\|^2.
% \ee
% Combining this with \eqref{epsilon-bound-eq} and choosing $A \geq 2d^{3/2}$ (which also determines the choice of $m^*$) gives the desired bound.
% }
 
 We obtain  a second representation as follows. We again write $\tilde x=\tilde v+\delta y$ with $y\in U^{d-1}$.  Then,
 \be 
 \label{xrep1}
 \tilde x= \tilde v +\delta \sum_{e\in V(U^{d-1})}\ell_e(y) e =\tilde v + \sum_{e\in V(U^{d-1})}\frac{\ell_e(y)}{A}  A \delta e=\left(1-\frac{1}{A}\right)\tilde v+\sum_{e\in V(U^{d-1})} \frac{\ell_e(y)}{A}[\tilde v+A\delta e].
 \ee
  This gives the representation
  \be 
 \label{xrep2}
 \tilde x=  \sum_{\nu\in V(\tilde R')} \gamma_\nu ' \nu,
 \ee
where
\be 
  \label{gammas1}
  \gamma'_\nu = \frac{\ell_e(y)}{A},\quad {\rm when} \ \nu= \tilde v+ A\delta e \ {\rm with} \ e\neq 0\ {\rm and} \ \gamma'_{0}=1-\frac{1}{A} +\frac{\ell_0(y)}{A}.
  \ee
Notice that this representation of $\tilde x$ is again a convex combination of the vertices of $\tilde R'$.  It follows that
 

 \be 
 \label{repomega2}
  \xi=  \sum_{\nu\in V(\tilde R')} a_\nu' \xi'_\nu,\quad a'_\nu:= \frac{\gamma'_\nu  \sqrt{(1+\|\nu\|^2)} }{\|\bar\xi\|}.\quad \xi'_\nu= \frac{(1,\nu)}{\sqrt{1+\|\nu\|^2}}
 \ee
 
 We now want to estimate the  sums 
 \be
 \label{sums} S:=\sum_{\nu\in V(\tilde R)} a_\nu,\quad S'= \sum_{\nu\in V(\tilde R')} a'_\nu,
 \ee

 \begin{lemma} 
\label{L:compare}  There is an $m^*=m^*(d)$, depending only on $d$,  such that whenever $m\ge m^*$ and $A$ is sufficiently large (depending only on $d$), the following hold.
Whenever $\xi$ is not a vertex in $W_k$, i.e.,   $\bar\xi=(1,\tilde x)$ where $\tilde x=\tilde v+y$ where $y\neq 0$,  we have 
\be 
\label{compare} 
S=1+\epsilon\quad {\rm and} \quad S'= 1+\epsilon ',\quad {\rm where}\quad 0<2|\epsilon|<  |\epsilon'|\le  \sigma \delta^2,
\ee 
 and
 %
    \be 
    \label{sigma}
    \sigma:=\sigma(y) =\sum_{e\neq 0} \ell_e(y)>0,
    \ee
    where the strict  inequality holds because $y\neq 0$.
\end{lemma}
\vskip .1in
\noindent

{\bf Proof:}  Let $B^2:=1+ \|\tilde v\|^2$ and recall that $\delta:=1/m$.  Observe that when $\nu=\tilde v+a\delta e$, $e\in V(U^{d-1})$, we have
  \be 
  \label{esta0}
  1+  \| \nu\|^2=B^2+ 2a\delta  \langle \tilde v,e\rangle +a^2\delta^2\|e\|^2=B^2+s_\nu(a), 
    \ee
    where 
    \be
    \label{snu}
    s_\nu(a):= 2a\delta \langle \tilde v,e\rangle +a^2\delta^2\|e\|^2.
    %\rob{\mbox{RN: remove } \nu =\tilde v+a\delta e, \ e\in V(U^{d-1})}.
    \ee
   We are interested in the cases, $a=1,A$.  Notice that $s_\nu(a)=0$ when $e=0$, i.e., $\nu=\tilde v$, and also $|s_\nu(a)|\le 1/2$ for these two values of $a$ provided $m^*$ is large enough.  These facts will be used without further mention in what follows.
    
We will use the Taylor expansion
 of the function $F(s):= \sqrt{B^2+s}$.  We have
 %
 \be
 \label{taylor}
 F(s)=  B+ \frac{1}{2}B^{-1}s- \frac{1}{4} B^{-3}s^2+ O(s^3),\quad |s|<1.
 \ee
 This gives that
 %
 \be 
 \label{observe}
 \sqrt{1+\|\nu\|^2}=F(s_\nu(a)) =B+ \frac{1}{2}B^{-1}s_\nu(a)- \frac{1}{4} B^{-3}s_\nu(a) ^2+ O(s_\nu(a)^3)
\ee 
From the above  observations, we can write
    \begin{eqnarray} 
    \label{S2}
    \|\bar\xi\|S'&=&\sum_{\nu\in V(\tilde R')} \gamma'_\nu F(s_\nu(A))\nonumber\\
    &=&(1-1/A)B+\sum_{e\in V(U^{d-1} )}\frac{\ell_e(y)}{A}\left(B+ \frac{1}{2}B^{-1}s_\nu(A)- \frac{1}{4} B^{-3}s_\nu(A)^2+ O(s_\nu(A)^3)\right)\nonumber\\
     &=& B+ \frac{B^{-1}}{2}\sum_{e\in V(U^{d-1})}\frac{\ell_e(y)s_\nu(A)}{A} - \frac{B^{-3}}{4}\sum_{e\in V(U^{d-1} )}\frac{\ell_e(y)s_\nu(A)^2}{A}+ O(A^2\sigma \delta^3).
     \end{eqnarray}  

% \rob{RN: $\sigma = \sum_e \ell_e(y)$, so need to understand why $\sum_{e\in V(U^{d-1} )}\frac{\ell_e(y)}{A}B = B/A$}  {\rnew RD answer:  $\sigma$ is the sume over the nonzero veertices while the above sum includes $0$ and gives the sum equals one (cconvex combination).}

     Let us analyze the first sum $\Sigma_1$ in \eref{S2}.  Using the definition of the $s_\nu$, we see that this sum equals
     %
     \be 
     \label{firstsum} 
    \Sigma_1= C_1\delta+C_2A\delta^2,\quad {\rm where} \quad C_1=B^{-1}\sum_{e\neq 0} \ell_e(y)\langle \tilde v,e\rangle \ {\rm and}  \ C_2=\frac{B^{-1}}{2}\sum_{e\neq 0}\ell_e(y)\|e\|^2 .
     \ee 
     A similar analysis of the second sum $\Sigma_2$ gives
 \be 
     \label{secondsum} 
    \Sigma_2= C_3A\delta^2+C_4A^2\delta^3+C_5A^3\delta^4,\quad {\rm where}  \quad C_3=B^{-3}\sum_{e\neq 0}\ell_e(y)\langle \tilde v,e\rangle ^2, \quad {\rm and} \ |C_4|,|C_5|\le C_0\sigma,
     \ee
     where $C_0$ depends at most on $d$.
   In total, this gives
   \be 
   \label{totalS}
   \|\bar\xi\|S'=   B+ C_1\delta + \tilde C \sigma A\delta^2 +O(\sigma A^2\delta^3),
   \ee 
   where 
   \be 
   \label{tildeC} 
   \sigma\tilde C= C_2 +C_3,
   \ee
   and where the constants in the "$O$" term depend only on $d$.
   It is important to notice that 
   %
   \be 
   \label{noticeC}
   \tilde C\ge \sigma^{-1} C_2 \ge 1/4.
   \ee 
   Replacing $A$ by one, we get
   \be 
   \label{totalS1}
   \|\bar\xi\|S=   B+ C_1\delta +\tilde C \sigma \delta^2 +O(\sigma  \delta^3).
   \ee 
Notice that these constants   are the same as those in \eref{totalS} and again the constants in the "$O$" term depend only on $d$.

Next, we want to compute $\|\bar\xi\|$ and compare this number with $B+C_1\delta$.  We have $\bar\xi=(1,\tilde x)$
where 
$$\tilde x= \tilde v+\delta y= \tilde v +\delta\sum_{e\in V(U^{d-1})} \ell_e(y)e.$$
Therefore,
%
\be 
\label{normtildeomega}
\|\tilde \xi\|^2= 1+\|\tilde v\|^2 +2\delta \sum_{e\in V(U^{d-1})}\ell_e(y)\langle \tilde v,e\rangle +\delta^2\|y\|^2 = B^2+s.
\ee 



    
    If we  now use \eref{taylor}, we obtain
$$\|\bar\xi\|= F(s)=B+\frac{B^{-1}}{2}s-\frac{B^{-3}}{4}s^2 + O(s^3)= B+C_1\delta+ \tilde C'\sigma \delta^2 + O( \sigma \delta^3).
$$
where 
%
\be 
\label{next C}
\sigma \tilde C'= \frac{B^{-1}}{2}\delta^2\|y\|^2+ B^{-3}\left[\sum_{e\neq 0}\ell_e(y) \langle \tilde v,e\rangle\right]^2\delta^2.
\ee 
Here, we have also used the fact that   $\|y\|\le \sigma$.    If we use this expression for $\|\bar\xi\|$ in \eref{totalS1}, we obtain
%
\be 
\label{Cstar} 
S= 1+C^* \sigma \delta^2+ O(\sigma\delta^3)=:1+\e, \quad C^*=\tilde C-\tilde C'.
\ee 
Similarly
\be 
\label{Cstar1} 
S'= 1+C^{**} \sigma \delta^2+ O(\sigma A^2\delta^3)=:1+\e', \quad  C^{**}=\tilde C  A^2-\tilde C' .
\ee 
If we choose $m$ sufficiently large ($m\ge m^*$ with $m^*$ depending only on $d$ and $A$ as a sufficiently large integer depending only on $d$ we will have $0<2\e<\e'$ (see \eref{noticeC}). This completes the proof of the Lemma.
    \hfill $\Box$

    Note that the constant $A$ of this lemma serves to define $A$ for this paper and then $L=(A+1)^2$ is defined as in Lemma \ref{L:ti+}.

\vskip .1in
\noindent
{\bf Proof of Lemma \ref{L:decomega}:}  
\vskip .1in
\noindent
{\bf Case $\xi\in W_k$:}  Let $\xi=\xi_i\in W_k$.  
Given $t\in [1/2,t_{2m-L}]$,  we have $t_i^+=t_j$ and we take
$\tilde t_i:=t_{j+1}$.  We define $\alpha$ by the requirement
%
\be 
\label{defalpha}
\alpha t_i^++(1-\alpha)\tilde t_i =t, \quad {\rm i.e.} \quad \alpha =\frac{t-\tilde t_i}{t_i^+-\tilde t_i}.
\ee
Then, $\xi = \alpha \xi +(1-\alpha) \xi$, which is  the decomposition for $\xi$ required in Lemma \ref{L:decomega}.
Indeed, $|\alpha|\le C$ with $C$ depending only on $d$ because  of Lemma \ref{L:ti+}  and \eref{factspacing}.

\vskip .1in
\noindent
{\bf Case $\xi$ is not in $W_k$:}     
 We will use the constructions given above. We take $A$ to be an integer as given in Lemma \ref{L:compare}. We have given two ways of representing $\xi$ as given in \eref{repomega1} and \eref{repomega2}. The $\xi_\nu$ and $\xi_\nu'$ appearing in these representations are all from $W_k$.   We take $W_k(\xi)$ as the collection of all these points.  
Property (ii) of Lemma \ref{L:decomega} is satisfied  since $\|\xi-\xi_i\|\le A/m$ for each $i$.
We define $\alpha$ by the requirement
 \be 
\label{defbeta}
\alpha \epsilon+(1-\alpha)\epsilon '=0, \quad {\rm i.e.} \quad \alpha =\frac{\epsilon ' }{\epsilon'-\epsilon }.
\ee
It follows that 
\be 
\label{lastomega}
\xi = \alpha  \sum_{\nu\in V(R)} a_\nu \xi_\nu+(1-\alpha) \sum_{\nu\in V(R')} a'_\nu \xi'_\nu,
= \sum_{j=1}^M b_j\xi_j,\quad \sum_{j=1}^M b_j=1,
\ee
where all of the $\xi_j$ are in $W(\xi)$.  The key here is that the coefficients in this representation sum to one.



 Now, given $t\in[1/2,t_{m-L}]$, we define
 \be 
 \label{deft+tilde}
 t^+:=\max \{t_i^+: \ \xi_i\in W_k(\xi)\}=t_j,\quad \tilde t: =t_{j+1}.
 \ee 
 Similar to the above, we define $\beta$ by requiring that 
 \be 
\label{defalpha1}
\beta t^++(1-\beta)\tilde t =t, \quad {\rm i.e.} \quad \beta =\frac{t-t^+}{t^+-\tilde t}.
\ee
It follows that
\be 
\label{lastomega1}
\xi\cdot x-t =  
 \sum_{j=1}^M \beta b_j(\xi_j\cdot x-t^+)+\sum_{j=1}^M (1-\beta) b_j(\xi_j\cdot x-\tilde t). 
\ee
 This is the decomposition promised in Lemma \ref{L:decomega} and thereby completes the proof of the lemma.
 \hfill $\Box$
 
  

 


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    



\bibliographystyle{plain}
 \bibliography{refs}
 
 
%\vskip .3in
%\noindent
%Peter Binev, Department of Mathematics, University of South Carolina,
%Columbia, SC 29208
\vskip .1in
\noindent 
Ronald DeVore, Department of Mathematics, Texas A\&M University,
College Station, TX 77843
\vskip .1in
\noindent 
Robert D. Nowak, Department of Electrical and Computer Engineering, University of Wisconsin--Madison,  Madison, WI 53706
\vskip .1in
\noindent
Rahul Parhi, Biomedical Imaging Group, \'Ecole polytechnique f\'ed\'erale de Lausanne, CH-1015 Lausanne, Switzerland
\vskip .1in
\noindent 
 Jonathan W. Siegel, Department of Mathematics, Texas A\&M University,
College Station, TX 77843
 


 \end{document}





 \section{Weighted $L_2$ approximation}
\label{S:weightedapprox}

{\rnew Left over materrial to be deleted}
{\rnew RD: I originally thought that I could introduce a weight $\mu_n(x)\ge 1$ which is large on the boundary of $B_d$  and prove that for any $f\in \cV(\cD)$ there is $g\in\Sigma_n$ such that
$$ \int_\Omega |f(x)-g(x)|^2\mu_n(x)\le n^{-2\alpha},\quad  \alpha =1/2+\frac{3}{2d} $$
but now I do not see this.  We need to discuss this on a zoom.



 There is another way to formulate the results of the previous section.  The results of that section say  that there are new model classes (weighted variation spaces) which are significantly larger than
 the traditional model classes (classical variation spaces) with the same approximation rate
 as the traditional model classes.  An alternate formulation is that functions in the traditional
 model classes are approximated better near the boundary of a domain $\Omega$ than in the interior.  We give one such formulation in this section. 
 
 This new formulation is similar to results on algebraic polynomial approximation.  As an example consider the  the case of polynomial approximation in the $L_\infty(I)$ norm with $I=[-1,1]$.  It is known that algebraic polynomials of degree $n$ approximate  a univariate Lip 1 function $f$   to accuracy $O(1/n)$, $n\ge 1$.  It is also known that this approximation can be improved near the boundary of $I$ in the following sense (see \cite{DLbook}).   If $\|f\|_{{\rm Lip}\ 1}=1$, then there are algebraic polynomials $P_n$ of degree $n$ such that
 \be 
 \label{polyapprox}
 |f(x)-P_n(x)|\le C \min (\frac{\sqrt{1-x^2}}{n}, \frac{1}{n^2}),\quad n\ge 1,
 \ee
 with $C$ an absolute constant. 
    The importance of this result in approximation theory is that it can be reversed.  Namely, if $f$ is any function for which \eref{polyapprox} holds then $f$
 is necessarily in Lip 1.

 We consider approximation by shallow ReLU networks on $\Omega=B_d$.  For each $n\ge 1$ we introduce the weight functions
 %
 \be 
 \label{wf}
 \mu_n(x):= \max( 1, \dist(x,\partial \Omega)+1/n)^{-1},\quad n\ge 1 ?
 \ee 
 and the weighted $L_2$ norms
 \be 
 \label{wnorm}
 \|f\|^2_{L_2(\Omega,\mu_n)}:= \int_\Omega \mu_n(x)|f(x)|^2\, dx, \quad n\ge 1. 
 \ee 
  \begin{lemma}
      \label{L:wf}
      If $f\in\cV(\Omega)$, then there exists $g\in \Sigma_n$ such that
      %
      \be 
      \label{werror}
      \|f-g\|_{L_2(\Omega,\mu_n)}\le C\|f\|_{\cV(\Omega)} n^{-\frac{1}{2}-\frac{3}{2d}},\quad n\ge 1.
      \ee 
  \end{lemma}
 \vskip .1in
 {\bf Proof:}  We sketch the proof. We fix $n=m^d$. It is enough to prove \eref{werror}  for functions $f=\sum_{i=1}^N a_i\phi_i$, $\sum_{i=1}^N |a_i|=1$,  where $N$ is arbitrarily large.  
 Let $X_n$ be the $n$ dimensional linear space as defined in the previous section.  
 Let us first check how well we can approximate a ReLU atoms $\phi=\phi(\cdot;\xi,t)$ in the $L_2(\mu_n)$ norm.  
 
{\bf Case: $t>1/2$}  We let $g$ be the function in \eref{defv}.  We  know that $\phi=g$ outside of the strip
 $S$ where any $x\in S$ can be written as
 \be  
 \label{strip}
 x=\alpha
 \ee 
 
 
 
 
 
 this sum, we let $g_i\in X_n$ be as defined in \S\ref{SS:Proofapproxphi} which provided
 the proof of Theorem \ref{T:approxphi}.  We know that $g_i(x)=\phi_i(x)$ except when $x$ in the set $\Omega^+$ for this atom.
 It follows that
 %
 \be  
 \label{wa1}
 \int_\Omega|\phi_i(x)-g_i(x)|^2 \, d\mu_n(x) =\int_{\Omega^+}|\phi_i(x)-g_i(x)|^2 \, d\mu_n(x)
 \ee 



    \begin{lemma}
\label{L:decomega1}
There is a constant $C$ depending only on $d$ such that the following holds.
Given any $k\ge 1$ and any $\xi\in S_d$ and any $t\ge??$, there exists a set $W_k(\xi)=\{\xi_i\in W_k:\ i=1,\dots,M\}$  such that
\vskip .1in
\noindent 
{\rm(i)}\quad 
       $ w = \sum_{i=1}^{M} a_i\xi_i$,
  \vskip .1in
\noindent 
{\rm(ii)}\quad    
     $\|\xi_i - w\| \leq C/m$, $i=1,\dots,M$,
 
  \vskip .1in

\noindent 
{\rm(iii)}\quad     
     $\sum_{i=1}^M a_it_i^+ = t$,
     \vskip .1in
     \noindent 
{\rm(iii)}\quad     
      $\sum_{i=1}^M |a_i| \leq C$. 
     

\end{lemma}

 }
  



     \begin{lemma}
 \label{L:Hdist}
There is a constant $C_d$ depending only on $d$ such that the following hold ???

\noindent
{\rm (i)} any $x\in S(\phi,\bar\phi)$ satisfies
%
 \be  
 \label{Hdist1}
 \dist(x,\cH)\le |\bar t \xi\cdot \bar\xi  -t|+ \delta  \sqrt{1-\bar t^2}=:R,
 \ee 
 
 
 \noindent
 {\rm (ii)} The measure of the set $S(\phi,\bar\phi)\subset \R^d$ is bounded by
 \be 
 \label{measS}
  |S(\phi,\bar\phi)|_d\le C_d  R\sqrt{1-(t-R)^2},
 \ee
 where the constant $C_d$ is the measure of the Euclidean ball of dimension $d-1$.
   \end{lemma}
 \vskip .1in
\noindent{\bf Proof:}  
     Any point $x$ in  $S(\phi,\bar\phi)$ is represented by
   \be  
   \label{repx} x= \alpha \bar \xi+ \bar\eta,
   \ee  
   where $\alpha>\bar t$ and $\bar\eta$ is orthogonal to $\bar \xi$ with  
   \be  
   \label{eta}
   \|\bar \eta\|\le \sqrt{1-\alpha^2}\le \sqrt{1-\bar t ^2}.
   \ee
   It follows that
   \be  
   \label{proj}
   (x\cdot\xi)=\alpha\xi\cdot \bar\xi +\bar\eta\cdot\xi\ge \bar t \xi\cdot \bar\xi +\bar\eta\cdot\xi,
   \ee  
   and 
   \be  
   \label{note}
   |\bar \eta\cdot\xi|=|\bar\eta\cdot (\xi-\bar\xi)|\le \delta  \sqrt{1-\bar t ^2}.
   \ee  
This gives that
%
\be  
\label{gives1}
0\ge  (x\cdot\xi)-t \ge \bar t \xi\cdot \bar\xi  -t- \delta  \sqrt{1-\bar t ^2}\ge -R.
 \ee 
Since  $\dist(x,\cH)=|x\cdot \xi-t|$ we have \eref{Hdist1}.
%

We next prove (ii) as  follows.  If $x\in S(\phi,\bar\phi)$ then in view of \eref{gives1}, we have
%
\be 
\label{repx1}
x= \beta \xi+\eta,
\ee 
where $\beta=x\cdot\xi\in[ t-R ,t]$ and $\eta$ is orthogonal to $\xi$ and $\|\eta\|\le \sqrt{1-\beta^2}\le \sqrt{1-(t-R)^2}$.    
Hence, $x$ is in a set whose measure is the right side of \eref{measS}.\hfill $\Box$
\vskip .1in

We next want to construct an approximation to a general atom $\phi=\phi(\cdot;\xi,t)$ by an element
$v$ from $V_n$.  In view of the Lemma \ref{L:linear} , we can write
%
\be  
\label{writephi}
 \xi\cdot x =\sum_{j=1}^d \alpha_j \xi_j\cdot x.
\ee 
For each $j=1,\dots,d$,  we choose $t_i\in T_0$, $i=i(j)$, as the largest element in $T_0$ such that
%
\be  
??
\ee

Similarly for each $j$








Placing this in \eref{writephi}  gives
\be  
\label{writephi1}
\xi\cdot x -t=\sum_{j=1}^d \alpha_j[\xi_j\cdot x -\beta t_i-(1-\beta)t_{i+1}]  
=\sum_{j=1}^d \beta \alpha_j[\xi_j\cdot x-t_i] + \sum_{j=1}^d (1-\beta)\alpha_j[\xi_j\cdot x-  t_{i+1}].
\ee
We define
%
\be  
\label{defvj}
v_j(x):= [\xi_j\cdot x-t_i]_+\quad \tilde v_j(x):=[\xi_j\cdot x-  t_{i+1}]_+
\ee  
and 
%
\be  
\label{defv}
v := \sum_{j=1}^d \beta \alpha_jv_j+ \sum_{j=1}^d (1-\beta)\alpha_j\tilde v_j 
\ee  










 








 




 
      \begin{lemma}
  \label{L:AD1}
  Let  $\phi=\sigma(\cdot;\xi,t)$  be any  element in $\cD$.  Further, let  $v\in V_n$   be defined by \eref{defv}.  Then,
  
  \noindent
  {\rm (i)}  $\phi(x)=v(x) $, $x\in \Omega$ outside a set $S\subset  \Omega$ of measure $|S_\phi|\le C_1 ??$.
     
  \noindent
  {\rm (ii)} $ \|\phi-v\|_{L_\infty(\Omega)}\le C_1 $,
  with $C_1$ depending only on $d$
  
  \noindent
  {\rm (iii)}  For any $\phi\in \cD(\Omega)$, we have    
  $$ \|\phi-v\|_{L_2(\Omega )}\le    C_1 m^{-3/2}\lambda(\phi)^{1/2}$$
    with $C_1$ an absolute constant.

  \end{lemma}
  %
  \noindent
  {\bf Proof:}   We start with the representation \eref{writephi1}. We define
  \be  
  \label{defv}
  v:=\sum_{j=1}^d \beta \alpha_j[\xi_j\cdot x-t_i]_+ + \sum_{j=1}^d (1-\beta)\alpha_j[\xi_j\cdot x-  t_{i+1}]_+.
  \ee
  Then $v\in V_n$.   Let
  %
  \be\label{Sj} 
  S_j^-:=\{x: ??\}   \quad S_j^+:=
  \ee  
  us note that $v=\phi$ except on the set ???
  
  
  Then, $t=\alpha t'+(1-\alpha)t"$ with $\alpha\ge 0$.  Let  $W(\xi) $  be the set of $d$   elements $\xi_1,\dots,\xi_d$  that satisfy Lemmma \ref{repomega}.   We define
  %
  \be   
  v(x):=  \sum_{j=1}^d v_i(x),\quad v_i(x):= \alpha a_i (\xi_j\cdot x + t')_+ + (1-\alpha)   (\xi_j\cdot x + t")_+=v_{j,0}(x)+v_{j,1}(x),
  \ee  
  which is clearly a function in $V_n$.  We proceed to show that it satisfies the properties of the lemma.
  
  Let,
  %
  \be\label{defS}
  S:=S_\phi:=\{x\in\Omega:\ v(x)\neq \phi(x)\}.
  \ee  
 
    
  Let $t_i$ be chosen so that
%
\be  
\label{chosen}
t_i\le t/S<t_{i+1}.
\ee 

\begin{lemma}
    \label{L:ti} 
    Let $t\ge 1/2$ and let $t_i$ satisfy \eref{chosen}.  Then, we have
    \be  
    \label{estti}
    |t_{i+1}-t_i|\le \pi \sqrt{1-t^2} /m.
    \ee 
    \end{lemma}
\vskip  .1in
{\bf Proof:}?????????
By the definition of the $t_i$, we have
\be  
t_{i+1}=\cos (\pi (i+1)/m) \le t/S\le \cos \pi i /m =t_i.
\ee 
Therefore, $t/S=\cos \theta$ with $\theta \in[\pi i/m,\pi (i+1)/m]$. This gives
$$
| t_{i+1}-t_i|\le \pi  \sin \theta' /m ,
$$
with $\theta' \in[\pi i/m,\pi (i+1)/m]$. Hence  
$$  
\sin \theta'\le \sin \frac{\pi(i+1)}{m}\le 2 \sin \frac{\pi i}{m} =2 \sqrt{1-\cos^2\frac{\pi i}{m} }\le 2\sqrt {(1-(\frac t S)^2}\le 2\sqrt{1-t^2}
$$ 
\hfill $\Box$  


 \vskip .1in  
We now fix $\xi$ and $t$ and proceed to construct an approximation $v\in V_n$ to $\phi:=\phi(\cdot;\xi,t)$.           We define
\be  
\label{defH}
H^+:=\{x:\ \xi\cdot x\ge 
t\} \quad  {\rm and} \quad H^-:=\{x:\ \xi\cdot x\le t\}.
\ee  
We fix any  one of the vectors $\xi'_i$ appearing in the set $W'(\xi)$   and given a $t_j\in T_m$, we similarly define    
\be  
\label{hyper}
H_j^+:=H_j(\xi_i):=\{x\in\Omega: \xi_i\cdot x \ge t_j\},\quad H_j^-:=H_j^-(\xi_i):=\{x\in\Omega: \xi_i\cdot x\le  t_j\}.
\ee
Going further, for this value of $i$, we define 
%
\be  
\label{appt1}
 t_i^+:=\min \{t_j\in T_m:  H_j^+\subset H^+\},\quad   t_i^-:=\max \{t_j\in T_m:  H_j^-\subset H_0^-\}.
\ee
and then define
\be 
\label{appphi}
\phi_i^+(x): =(\xi_i\cdot x-t_i^+)_+,\quad \phi_i^-(x): =(\xi_i\cdot x-t_i^-)_+,\quad i=1,\dots,d'.
\ee  
These functions are in $V$ and and will be used to create the approximation $v$ to $\phi$. 
\begin{remark}
    \label{R:t_i}
   Suppose $m\ge 8d$.  For each $i=1,\dots,d'$, we have 

   \noindent 
   {\rm (i)}  $\|\xi_i'-\xi\|\le \frac{4\sqrt{d}}{m}$,

   \noindent
   {\rm (ii)}
   $t_i^-\le t\le t_i^+$.
   \end{remark}
\noindent
{\bf Proof:}  The inequalities in (i) were proved in (iii) of Lemma \ref{L:linear} for the original vertices of $W(\xi)$ and the same proof applies for the four new verticew.
Since  $x=t_i^+\xi_i$ is in $H_i^+$, the definition of $t_i^+$ gives that $x\in H^+$ and so
$$
x\cdot \xi=t_i^+\xi_i\cdot \xi\ge t.
$$  
It follows from (i)  that $0<\xi\cdot\xi_i\le 1$.  Therefore, dividing by $\xi\cdot\xi_i$ in the last inequality gives
$t/S\le t_i+$. The lower inequality in (i) is proved similarly.    $\Box$

 We define $\beta $ by the requirement  that 
$$
\beta T^+ +(1-\beta)T^-=t.
$$
In view of (ii), we have $\beta\in[0,1]$.
We now have
\be 
\label{finalwrite}
  \xi\cdot x-t=\beta\sum_{i=1}^d \alpha_i (\xi_i\cdot x-t_i^+)+(1-\beta)\sum_{i=1}^d \alpha_i(\xi_i\cdot x-t_i^-) .
\ee 
This motivates the following definition for the approximant $v\in V_n$: let $\phi_i^\pm(x):=(\xi_i\cdot x -t_i^\pm)_+$
and define
\be 
\label{defv}
v:=\sum_{i=1}^d[\gamma_i^-\phi_i^-(x)+\gamma_i^+\phi_i^+(x)],\quad \gamma_i^+:=\beta\alpha_i,\ \gamma_i^-:=(1-\beta)\alpha_i,\ i=1,\dots,d .
\ee  

Before bounding the error in approximating $\phi$ by $v$, let us make some remarks to motivate the idea
of how to estimate this error. Notice that if $x\in \Omega$ is such that $x\in H_i^+$ for all $i=1,\dots,d$,
then $v(x)=\phi(x)$.  Similarly if 
$x\in H_i^-$ for all $i=1,\dots,d$, then $\phi(x)=v(x)=0$.  This means that the only point $x\in \Omega$ where
$\phi(x)\neq v(x)$ must be in one of the sets
%
\be  
\label{must}
\Omega^+_i:=\{x\in\Omega: \xi\cdot x> t,\ \xi_i\cdot x\le t_i^+\}\quad \Omega^-_i:=\{x\in\Omega: \xi\cdot x<t,\ \xi_i\cdot x\ge t_i^-\}.
\ee  
    
   \section{Intrinsic characterization of $\cV_w(\Omega)$}
   \label{S:convex}
   We have defined the new model class $\cV_w(\Omega)$ as a weighted sum of dictionary elements where the weight
   $w$ depends on $\Omega$ and reflects the  relative contribution of the atom on the domain.  In this section, we show that
   $\cV_w(\Omega)$ has a more intrinsic definition given by a certain smoothness condition on the intrinsic Radon transform on $\Omega$.  The result we prove has the same flavor as the characterization of Radon BV given in \cite{O+,PN} except that we now
   do not have to deal with extensions and can work with the Radon transform of $f$ relative to the domain $\Omega$.
   
    

   Key to this section is the Radon inversion formula. We first detail this on the whole space $\mathbb{R}^d$, where we write it abstractly as
   \begin{equation}\label{radon-inversion}
    \mathcal{R}^*K\mathcal{R}(f) = f,
   \end{equation}
   for \textcolor{red}{sufficiently nice} functions $f:\mathbb{R}^d\rightarrow \mathbb{R}$ \textcolor{red}{(e.g., $f \in L^1(\R^d)$ suffices)}, where the Radon transform is defined by
   \begin{equation}\label{radon-transform}
    \mathcal{R}(f)(\xi,b) = \int_{\xi\cdot x = b} f(x)dx,
   \end{equation}
   and the adjoint of the Radon transform is given by
   \begin{equation}
    \mathcal{R}^*(g)(x) = \int_{S^{d-1}} g(\xi,x\cdot \xi)d\xi,
   \end{equation}
   and the filtering operator $K$ is given by the Fourier multiplier in $b$ space
   \begin{equation}
    \widehat{K(g)}(\xi,\xi) = C_d|\xi|^{d-1}\widehat{g}(\xi,\xi).
   \end{equation}
   Note that here the Fourier transform is taken in the $b$ space. A key question is how these three operators are defined and in what sense the inversion formula \eqref{radon-inversion} holds. One approach to this is to define everything using duality with appropriate function spaces. I don't this that this approach is strong enough for what we want, however.

   Instead, we can make sense of this for any $f\in L^1(\mathbb{R}^d)$ by smoothing the Radon transform appropriately. Specifically, let $\epsilon > 0$ and consider a Gaussian kernel
   \begin{equation}
    g_\epsilon(t) = \frac{1}{\sqrt{2\pi\epsilon}}e^{-t^2/2\epsilon}.
   \end{equation}
   Define the smoothed Radon transform as
   \begin{equation}
    \mathcal{R}_\epsilon(f)(\xi,b) = g_\epsilon * \mathcal{R}(f)(\xi,\cdot) = \frac{1}{\sqrt{2\pi\epsilon}}\int_{\mathbb{R}^d} f(x)e^{-(\xi\cdot x - b)^2/2\epsilon}dx,
   \end{equation}
    which makes sense for any $L^1$ function $f$. Next, we can apply the $K$ operator by applying it to the Gaussian kernel $g_\epsilon$. This gives
    \begin{equation}
        \widehat{Kg_\epsilon}(\xi) = C_d|\xi|^{d-1}\sqrt{\frac{\epsilon}{2\pi}}e^{-\epsilon \xi^2/2}.
    \end{equation}
    The function $Kg_\epsilon$ is a bit of a mess to write down, but at least in odd dimensions it is equal to a polynomial times the Gaussian $g_\epsilon$. Further, it is $C^\infty$ due to the decay in its Fourier transform. We then write
    \begin{equation}
        K\mathcal{R}_\epsilon(f)(\xi,b) = Kg_\epsilon * \mathcal{R}(f)(\xi,\cdot) = \int_{\mathbb{R}^d} f(x)Kg_\epsilon(\xi\cdot x - b)dx
    \end{equation}
    Note that this is a $C^\infty$ function of $b$ for any $\xi$ due to the smoothness of $Kg_\epsilon$. Finally, the Radon inversion becomes
    \begin{equation}
        \mathcal{R}^*K\mathcal{R}_\epsilon(f)(x) = \int_{S^{d-1}} \int_{\mathbb{R}^d} f(y)Kg_\epsilon(\xi\cdot (x-y))dyd\xi = \int_{\mathbb{R}^d} f(y)\int_{S^{d-1}}Kg_\epsilon(\xi\cdot (x-y))d\xi dy.
    \end{equation}
    Now the $K$ operator has been defined so that
    \begin{equation}
        \int_{S^{d-1}}Kg_\epsilon(\xi\cdot (x-y))d\xi dy = \frac{1}{(2\pi\epsilon)^{d/2}}e^{-\|x-y\|^2/2\epsilon}.
    \end{equation}
    Finally, we get
    \begin{equation}
        \mathcal{R}^*K\mathcal{R}_\epsilon(f)(x) = \frac{1}{(2\pi\epsilon)^{d/2}}\int_{\mathbb{R}^d} f(y)e^{-\|x-y\|^2/2\epsilon}dy
    \end{equation}
    It is now well-known that $\lim_{\epsilon\rightarrow 0} \mathcal{R}^*K\mathcal{R}_\epsilon(f) = f$ in a variety of senses, for instance in $L^p$ for any $1\leq p < \infty$.
    Based upon this, I think a more explicit description of the Radon BV seminorm would be
    \begin{equation}
        |f|_{RBV^k} = \sup_{\epsilon > 0} \int_{S^{d-1}} \int_{-\infty}^\infty \left|\frac{\partial^k}{\partial b^k}K\mathcal{R}_\epsilon(f)(\xi,b)\right|dbd\xi.
    \end{equation}
    This can be defined for any $f\in L^1$. 
    \textcolor{red}{rahul: For the $\mathcal{R}BV^k$ spaces defined on $\R^d$, this isn't enough. We're forced to do that by duality because the important property that is exploited is that ReLU$^{k+1}$ ridge functions (which are not in $L^p(\R^d)$ for any $1 \leq p < \infty$) are in the spaces.
    \\
    On a \textbf{bounded domain} with the intrinisic operators, the above definition should work just fine.}
    Next, we will consider functions $f:B^1\rightarrow \mathbb{R}$ defined on the unit ball $B^1$ in $\mathbb{R}^d$ and extend this analysis to this situation.
    \textcolor{red}{rahul: Given $f \in L^1(B_1)$ and considering its zero extension to $\R^d$, which will be in $L^1(\R^d)$, I think the above analysis applies automatically. To see why the intrinisic Hilbert transform arises in the inversion formula, we note that the support theorem for the Radon transform says that if a function is compactly supported on the unit ball, its Radon transform will be supported on $S^{d-1} \times [-1, 1]$.}

    Also, there are numerous open problems. For instance, I have not been able to find a theory which describes how to recover an function $f\in B_q^s(L_p(B))$ in a Besov space on the ball from finitely many Radon measurements. 

    \section{Intrinsic Characterization on the Ball $B_2^d$}
    We have defined the new model class $\cV_w(\Omega)$ as a weighted sum of dictionary elements where the weight $w$ depends on $\Omega$ and reflects the  relative contribution of the atom on the domain.  In this section, we show that $\cV_w(\Omega)$ has a more intrinsic definition given by a certain smoothness condition on the intrinsic Radon transform on $\Omega$. We focus on the case $\Omega = B_d^2$. The result we prove has the same flavor as the characterization of the second-order Radon BV space given in \cite{O+,PN} defined on the whole space $\R^d$. Importantly, the definition is completely intrinsic rather than simply using the definition on $\R^d$ and dealing with extensions and restrictions as was recently explored in~\cite{PN2}.
    
    We begin by recalling some important properties of the \emph{intrinsic} Radon transform~\cite{Lud,Pet}. The intrinsic Radon transform of $f \in L_1(B_2^d)$ is specified by
    \be
        \RadonOp(f; \xi, t) = \int_{\xi^\perp \,\cap\, B_2^d} f(x + \xi t) d x = \int_{\{\xi \cdot x = t\} \,\cap\, B_2^d} f(x) dx , \quad \xi \in S^{d-1}, t \in [-1, 1],
    \ee
    where $\xi^\perp = \{ x \in \R^d \,:\, \xi \cdot x = 0\}$. The quantity $\RadonOp(f; \xi, t)$ corresponds to the integral of $f$ over the hyperplane $\{x \in \R^d \,:\, \xi \cdot x = t\} \cap B_2^d$. We can recover $f$ from its Radon transform using the Radon inversion formula. The Radon inversion formula uses the operator $K$ that acts on the $t$ variable
    \be
        Kg = \begin{cases}
            \frac{(-1)^{\frac{d-1}{2}}}{2(2\pi)^{d-1}} \partial_t^{d-1} g, & \text{ if $d$ is odd}, \\[1em]
            \frac{(-1)^{\frac{d-2}{2}}}{2(2\pi)^{d-1}} \cH \partial_t^{d-1} g, & \text{ if $d$ is even},
        \end{cases}
    \ee
    where $\cH$ denotes the \emph{intrinisic} Hilbert transform, which is defined to be the usual Hilbert transform of the zero extension of functions in $L_1([-1, 1])$~\cite[Equation~(2.7)]{Pet}. For every sufficiently smooth function $f$ supported on $B_2^d$, the Radon inversion formula is given by
    \be
        f = \RadonOp^* K \RadonOp,
    \ee
    where the dual Radon transform of $h \in L_\infty(S^{d-1} \times [-1, 1])$ is
    \be
        \RadonOp^*(h; x) = \int_{S^{d-1}} h(\xi, \xi \cdot x) d \xi, \quad x \in B_2^d.
    \ee

    We will first compute the intrinsic Radon transform of the Heaviside ridge $g(x) = H(x_1 - t_0)$. First suppose that $\xi \neq \pm e_1$. Consider the orthogonal tranformation $y = U^Tx$, where $U \in \R^{d \times d}$ is an orthogonal matrix whose first column is $\xi \in S^{d-1}$ and whose second column $\widetilde{\xi} \in S^{d-1}$ is such that it is orthogonal to $\xi$ and lies in $\span\{\xi, e_1\}$. This gives the following system of equations
    \be
        \begin{aligned}
        \widetilde{\xi} &= c_1 \xi + c_2 e_1 \\
        \widetilde{\xi} \cdot \xi &= 0 \\
        \widetilde{\xi} \cdot \widetilde{\xi} &= 1.
        \end{aligned}
    \ee
    These imply that $\widetilde{\xi}_1 = e_1 \cdot \widetilde{\xi} = \pm\sqrt{1 - (e_1 \cdot \xi)^2} = \pm\sqrt{1 - \xi_1^2}$. Without loss of generality, we will pick the negative one. Therefore,
    \be
        \begin{aligned}
            \RadonOp(g; \xi, t)
            &= \int_{\{\xi \cdot x = t\} \,\cap\, B_2^d} g(x) dx \\
            &= \int_{\{y_1 = t\} \,\cap\, B_2^d} g(Uy) dx \\
            &= \int_{\{y_1 = t\} \,\cap\, B_2^d} H(\xi_1 y_1 + \widetilde{\xi}_1 y_2 - t_0) dy \\
            &= \int_{\{y_1 = t\} \,\cap\, B_2^d} H\left(\xi_1 t - y_2 \sqrt{1 - \xi_1^2} - t_0 \right) dy
        \end{aligned}
    \ee
    Note that the third line holds since the first two columns of $U$ span the space spanned by $\xi$ and $e_1$ and so all the other columns are orthogonal to $e_1$. We can then write the integral as
    \be
            \RadonOp(g; \xi, t)
            = \int_{
                \substack{
                    y \in B_2^d \\
                    y_1 = t \\
                    y_2 \leq (\xi_1 t - t_0)/\sqrt{1 - \xi_1^2}
                }
            }
            1 \, dy
    \ee
    Thus, the problem reduces to computing the volume
    \be
        \RadonOp(g; \xi, t) = \abs{\left\{
            y \in B_2^d \,:\,
            y_1 = t\right\} \cap
            \left\{y \in B_2^d \,:\, y_2 \leq \frac{\xi_1 t - t_0}{\sqrt{1 - \xi_1^2}}
        \right\}}.
    \ee
    This volume corresponds to a $(d-2)$-dimensional spherical cap of the $(d-1)$-dimensional ball. The radius of the $(d-1)$-dimensional ball is
    \be
    r \coloneqq (1 - t^2)_+^{1/2}.
    \ee
    Therefore, the height of the cap is 
    \be
        h \coloneqq r + \frac{\xi_1 t - t_0}{\sqrt{1 - \xi_1^2}} = (1 - t^2)_+^{1/2} + \frac{\xi_1 t - t_0}{\sqrt{1 - \xi_1^2}}.
    \ee
    The $(d-1)$-dimensional volume of a spherical cap of a ball of radius $r$ and of height $h$ is given by
    \be 
        \frac{\pi^{\frac{d-2}{2}} r^{d-1}}{\Gamma\left(\frac{d}{2}\right)} \int_0^{\arccos\left(\frac{r-h}{r}\right)} \sin(\tau)^{d-1} \, d\tau,
    \ee
    where this formula applies to the small cap (i.e., for $0 \leq h \leq r$ and so the $\arccos$ is between $0$ and $\pi/2$)~\cite{li2011concise}. In the case that $r < h \leq 2r$, we simply use the formula with $h$ redefined to be $2r - h$ and subtract the resulting volume from the volume of the sphere. Finally, if $\xi = e_1$ we have
    \be
        \RadonOp(g; e_1, t) = H(t - t_0) \frac{\pi^\frac{d-1}{2}}{\Gamma\left(\frac{d+1}{2}\right)} (1 - t^2)_+^{\frac{d-1}{2}}
    \ee
    and if $\xi = -e_1$ we have
    \be
        \RadonOp(g; -e_1, t) = H(-t + t_0) \frac{\pi^\frac{d-1}{2}}{\Gamma\left(\frac{d+1}{2}\right)} (1 - t^2)_+^{\frac{d-1}{2}}
    \ee
    Putting everything together, we find

 
  
   {\color{red} RD:  This is put in for Andrea.  I did not think we have to give the argument to prove \eref{dist}  in the actual paper.
   Given $f\in K=U(W^1(L_p))$ consider the piecewise linear interpolant $S$ to $f$ at the equally spaced points  $0=\xi_0<\xi_1<\dots,\xi_n=1$.
   Then $N_j:=\int_{I_j}|f'|^p\,dx$, with $I_j:=[\xi_{j-1},\xi_j]$, satisfies $\sum_{j=1}^n N_j\le 1$.  The slope $s_j$ of $S$ on $I_j$ equals 
   $$s_j= n\int_{I_j}f'\le n^{1/p}[\int_{I_j}|f'|^p]^{1/p}\le [nN_j]^{1/p}.$$
   Hence, $\int_{I_j}|S'|^p\le N_j$ and
   $$\|S'\|_{L_p}^p= \sum_{j=1}^n N_j^p\le 1$$
   and so $S\in K$.
   
   To see the approximation error, we note that $g:=f-S$ vanishes
   at the endpoints of  $I_j$ and so  
   $$|g(x)|\le  \int_{I_j}|g'|\le n^{1/p-1}[\int_{I_j}|g'|^p]^{1/p}\le n^{1/p-1} [2N_j]^{1/p}. $$
   There is a more involved argument to get rid of the factor $2$ in $2N_j$ by using the fact that $g$ vanishes at both ned points.  This is why I dropped the $2$ in what follows.  This gives
   $$\int_{I_j}|g(x)|^2\le  n^{-1}  n^{2/p-2} [2N_j]^{2/p}= n^{2/p-3[2}N_j]^{2/p}. $$
   Note that there is a more sophisticated argument (if I remember correctly) to replace $2N_j$ by $N_j$  by using the symmetry of If  $p\le 2$.   Then,
   $\sum_{j=1}^n N_j^{2/p}\le \sum_{j=1}^nN_j\le 1$ and we get $\|g\|_{L_2}\le n^{1/p-3/2}=n^{-s}$.  The case $p>2$ follows from the case $p=2$.
   }


   
 \begin{thebibliography}{77}

\bibitem{Armijo} L. Armijo, {\it Minimization of functions having Lipschitz continuous first partial derivatives}, Pacific Journal of Mathematics, {\bf 16}(1), 1966.
 
\bibitem{Barron} A.  Barron, {\it Universal approximation bounds for superpositions of a sigmoidal function},  IEEE Transactions
on Information theory {\bf 39}(1993), 930-945.


\bibitem {CDD} A. Cohen, W. Dahmen, R. DeVore, {\it Compressed sensing and best $k$ term approximation}, JAMS, {\bf 22}(2009), 211-231. 

\bibitem{CDL} A. Cohen, M. Davenport, and D. Leviatan,
{\it On the stability and accuracy of least squares approximation}, FOCM {\bf 13}(2013), 819-834.


 \bibitem{DHP} R. DeVore, B. Hanin, and G. Petrova, {\it Neural network approximation}, Acta Numerica, {\bf 30}, 327--444, 2021.

\bibitem{DPW} R. DeVore,  G. Petrova, and P. Wojtaszczyk, {\it Data assimilation in and sampling Banach spaces}, Calcolo, {\bf 54},  963-1007, 2017.

\bibitem {Do}  D. Donoho, {\it Compressed sensing}. IEEE Transactions on Information Theory. 52(2006),  1289-1306.


\bibitem{EMW} W. E, C. Ma, and L. Wu, {\it Barron spaces and the compositional function spaces for neural network models}
 - arXiv preprint arXiv:1906.08039, 2019.

\bibitem{FR} S. Foucart and H. Rahut, An Invitation to Compressive Sensing,
Birkhau\"ser, 2013.

\bibitem{HN} B. Hanin and M. Nica, {\it Finite Depth and Width Corrections to the Neural Tangent Kernel}, 	arXiv:1909.05989 [cs.LG].

\bibitem {HTT}  T. Hastie, R. Tibshirani, R. Tibshirani,
{\it Best subset, forward stepwise or lasso? Analysis and recommendations based on extensive comparisons},
Statistical Science, {\bf 35} (4), 579--592, 2020.   

\bibitem{JGH} A. Jacot, F. Gabriel, and C.  Hongler. {\it Neural tangent kernel: Convergence and generalization in neural networks},  in:  Advances in neural information processing systems, pages 85718580, 2018. 



 \bibitem{KNS}  D. Krieg, E. Novak, and M. Sonnleitner, {\it Recovery of Sobolev functions restricted to iid sampling},
ArXiv preprint arXiv:2108.02055, 2021.
  


\bibitem{KS} D. Krieg and M. Sonnleitner. Random points are optimal for the approximation of Sobolev
functions. arXiv preprints, arXiv:2009.11275, 2020.



\bibitem{KU} D. Krieg and  M. Ullrich, {\it  Function Values Are Enough for $L_2$-Approximation }, JFoCM  21(2021), 1141--1151.

\bibitem{LGM} G. G. Lorentz, M. v. Golitschek, and Y. Makovoz, {\it  Constructive approximation: Advanced Problems}, Grundlehren der Mathematischen Wissenschaften, Springer-Verlag, Berlin, 1996.  
 
\bibitem{MR}   C. Micchelli and T. Rivlin, {\it  A Survey of Optimal Recovery},  In: Micchelli C.A., Rivlin T.J. (eds) Optimal Estimation in Approximation Theory, 1--54, 1977.



\bibitem{T} N. Nagel, M. Schafer, and T. Ullrich. {\it A new upper bound for sampling numbers}  JFoCM  (2021), to appear, https://doi.org/10.1007/s10208-021-09504-0


\bibitem{NWW} F. J. Narcowich, J. D. Ward, and H. Wendland, {\it Sobolev bounds on functions with scattered zeros, with applications to radial basis function surface fitting}, Math. Comp. {\bf 74}(2004), 743--763.


\bibitem{NT} E. Novak and H. Triebel. {\it Function spaces in Lipschitz domains and optimal rates of convergence for sampling}, Constr. Approx.{\bf 23}(2006), 325-350.


\bibitem{NW} E. Novak and H. Wozniakowski, {\it Tractability of Multivariate Problems}, Volume I: Linear Information. EMS Tracts in Mathematics, Vol. 6, Eur. Math. Soc. Publ. House, Z\"urich, 2008.


\bibitem{PN}    R. Parhi and R. Nowak, {\it Banach space representer theorems for neural networks and ridge splines}, JMLR {\bf }(2021), 1--40.


\bibitem{PV} Ph. Petersen and F. Voigtlaender, {\it
Optimal learning of high-dimensional classification problems
using deep neural networks}, ArXiv preprint 2112.12555.


 \bibitem{P} A. Pinkus, {\it N-widths in Approximation Theory}, Vol. 7 of A Series of Modern Surveys in Mathematics, Springer Science \& Business Media, 2012.



\bibitem{SX}  J. Siegel and J. Xu, {\it Characterization of the variation spaces corresponding to shallow neural networks},
arXiv:2106.15002

\bibitem{SX1}  J. Siegel and J. Xu, {\it Sharp bounds on the
approximation rates, metric entropy, and $n$-widths of shallow
neural networks},  arXiv:2101.12365



\bibitem {Ti}  R. Tibshirani,
 {\it Regression Shrinkage and Selection via the Lasso}, % J. R. Statist. Soc. B  {\bf58}.1, (1996), 267--288.
 Journal of the Royal Statistical Society: Series B (Methodological) {\bf58}.1 (1996), 267--288.
 
\bibitem{TW} J. Traub and H. Wozniakowski, {\it A General Theory of Optimal Algorithms}, Academic Press, 1980.

\bibitem{U} M. Unser, {\it A unifying representer theorem for inverse problems and machine learning}, J. of FoCM{\bf 21}(2021), 941-960, 


.
\bibitem{yosida} K. Yosida, {\it Functional analysis}, Springer Science \& Business Media, 2012.










\end{thebibliography}





    % Left over material:
    
    
    %         &= (\xi_1 t - t_0) \int_{
    %             \substack{
    %                 y \in B_2^d \\
    %                 y_1 = t \\
    %                 y_2 \leq (\xi_1 t - t_0)/\sqrt{1 - \xi_1^2}
    %             }
    %         }
    %         dy
    %         -
    %         \sqrt{1 - \xi_1^2} 
    %         \int_{
    %             \substack{
    %                 y \in B_2^d \\
    %                 y_1 = t \\
    %                 y_2 \leq (\xi_1 t - t_0)/\sqrt{1 - \xi_1^2}
    %             }
    %         }
    %         y_2 d y
    %     \end{aligned}
    % \ee
    % \textcolor{red}{These seem like integrals we can actually compute (maybe using hyperspherical coordinates) and less challenging geometrically than directly trying to geometrically do the Radon transform of a ReLU atom. The case of $\xi = \pm e_1$ will be easy since it's just the measure of the hyerplane through the domain times the (constant) value of the ReLU atom.}
    
    % Let $C_n^\lambda$ denote the Gegenbauer polynomial of degree $n$ associated with $\lambda$ and define $\mathcal{U}_n \coloneqq C_n^{d/2}$ for $n \in \N_0$. It was shown in~\cite{petrushev1998approximation} that
    % \be
    %     K \RadonOp(f; \xi, \cdot) = \sum_{n=0}^\infty \nu_n A_n(\xi) \mathcal{U}_n(\cdot),
    %     \label{eq:KR-series}
    % \ee
    % where
    % \be
    %     \nu_n = \frac{(n+1) (n+2)  \cdots (n + d - 1)}{2(2\pi)^{d-1}}
    % \ee
    % and
    % \be
    %     A_n(\xi) = \int_{-1}^1 \RadonOp(f; \xi, t) \mathcal{U}_n(t) dt = \int_{B_1^d} f(x) \mathcal{U}_n(\xi \cdot x) dx.
    % \ee
    % The series in (\ref{eq:KR-series}) converges in the $L^2([-1, 1]; w(t) dt)$, where $w(t) = (1 - t^2)^{d-1}$. Notice that this is the exact same weight function in ???.

    % {\color{red}
    %     We now want to show that $\norm{\partial_t^2 K \RadonOp f}_{\cM}$ is uniformly bounded for all $f$ in the dictionary. To do this we will use the series decomposition in \eqref{eq:KR-series} and show that we are allowed to term-by-term differentiate it (there are some technicalities about uniform convergence that we need to check).
        
    %     Furthermore, even though we will take the $L^1$-norm of the series, in the limit it will converge to the $\cM$-norm of $\partial_t^2 K \RadonOp f$. This needs to be proven.

    %     Given that \eqref{eq:KR-series} converges in the weighted norm, I think the weight actually will play an important role. Something probably won't converge without the weight.

    %     We also note that when $d = 1$, \eqref{eq:KR-series} simply represents the expansion of $f \in L^2[-1, 1]$ in terms of the Gegenbaur polynomials $\mathcal{U}_n$ since $\nu_n = 1$.
    % }
% \bibliographystyle{amsplain} 
\bibliography{refs}
   
  
    \section{Appendix}
    \label{S:appendix}
    We gather in this section certain technical results which were mentioned (and used) without proof in the text above.
    \subsection{Representing linear function on $\R^d$}
    \label{SS:A1}
    Consider the space $\P_1$ of  linear function $\xi\cdot x -t$,  $\xi\in\R^d$, $t\in\R$.  This is a linear space of dimension
    $d+1$ and so any set of $d+1$ linearly independent functions are a basis for $\P_1$.
  \end{document}
  
  Left over
  
     We want to bound the measure $|S|$ of $S$. To provide such a bound, we shall show that  
  %
  \be  
  \label{toshow}
  S\subset \{x:\ \dist (x,H_\phi)\le \delta\},
  \ee  
  where $H_\phi$ is the hyperplane $\xi\cdot x=t$ and is$\delta \le ??$.
  For this, we write any $x\in \Omega$ as $x=[\xi\cdot x] \xi+\eta$ where
  $\eta\cdot \xi=0$.
   \vskip .1in
   \noindent
   {\bf Case 1: $\xi\cdot x\le t$:}
  
  
  
  $v_j:=\phi(\xi_j,t')$,
  $j=1,\dots,d+1$.  
   





    
   
    We want to take
    the set of all atoms in $\cD(\Omega)$ and put them into buckets $B_{i,j}$ with each bucket associated to the atom $\phi_{i,j}$ ({\rnew RD: I have
    not thought out  enough  how to best  do this}).  There will be $\sim n$ buckets.  These correspond to the $\cL_{i,j}$ in the case $\Omega=B_2$ which we have discussed in detail. Each $\phi=\phi(\xi,t;\cdot)\in\cD(\Omega)$ should be assigned a unique bucket.   This bucket
    should be associated to a $\phi_{i,j}$ for which $\xi_{i}$ is close to $\xi$ and $t_j$ is close to $t$.
    We want each of the $\phi$ in a given bucket to have comparable $h(\phi)$.  I think I can do this without imposing more conditions on $\Omega$. {\bf  We should have that all of the $h(\phi)$ for $\phi$ in the same bucket are comparable.}  We then define  the sets
    %
    \be
    \label{Sij}
    S_{i,j}:=\bigcup\{ H_\phi:\phi\in B_{i,j}\}.
    \ee
     The set $S_{i,j}$ will have a certain width $\lambda$.  We can then define $\lambda
     (\phi)$ to be the same as the width of the $S_{i,j}$ when $\phi$ is in $B_{i,j}$. The measure $|S_{i,j}|$ will look like 
     \be
     \label{measS}
     |S_{i,j}| \sim |H_\phi| \lambda(\phi)/m.
     \ee
     Recall that this $\lambda$ looks like $|L_\phi|/m$ when $\Omega=B_2$ and like $1/m$ when $\Omega=Q_2$. For arbitrary $d$,
     the width of $S_{i,j}$ will look like $1/m$ for $Q_d$ and  $h(\phi) /m$ for $B_2$.
   
   \section{Weighted variation spaces on general domains in $\R^d$}
   \label{SS:general}
    
   
   In this section, we generalize the results of the previous section, which were proven in the case $d=2$, to more geeneral domains in $\R^d$, $d\ge 1$.  We consider any domain $\Omega$ which is convex and  centrally symmetric (about the origin).   We assume we have the normalization $\Omega\subset Q_d  $.   Let 
   %
   \be
   \label{dictionary}
   \cD=\cD(\Omega)
   \ee
   be the dictionary of ReLU atoms that do not vanish on $\Omega$. 

   Given any ReLU atom $\phi(\cdot;\xi,t)$ we associate two domain dependent quantities that will determine the appropriate weight associated to $\phi$.
   The first of these is the Hausdorff distance
    \be  
    \label{atomdist}
    \delta(\phi):=\delta(\phi,\Omega):= \dist (H_\phi\cap \Omega,\partial\Omega),\quad \phi\in\cD.
    \ee  
    Notice that $\delta(\phi)$ is related to the $L_\infty$ norm of $\phi$ on $\Omega$ and in particular, we have
    %
    \be  
    \|\phi\|_{L_\infty(\Omega)}\le \delta(\phi),\quad \phi\in\cD.
    \ee 
Indeed,  if $x\in \Omega$ with $\phi(x)=\xi\cdot x-t>0$, we write $x= \alpha \xi +\eta$ with $\alpha =x\cdot\xi$ and  $\eta\perp \xi$.  Then,
$$\phi(x)=\alpha -t  =\dist (x,H_\phi)  \le \dist(x,H_\phi\cap\Omega)\le  \delta(\phi).$$




    
    The second domain dependent quantity associated to $\phi$ is
    % 
   \be
   \label{Hmeasure}
   \mu(\phi):=\mu(\phi,\Omega):=|H_\phi\cap\Omega|_{d-1}, 
   \ee
    which is the $d-1$ dimensional Lebesgue measure of the hyperplane for $\phi$ intersected with $\Omega$.   Let us note for further use, that if the atoms $\phi(\cdot;\xi,t)$ have a fixed $\xi$ and $t>0$ increases, then both $\delta(\phi))$ and $\mu(\phi)$
    decrease.

    \subsection{A finite dimensional NN subspace}
    \label{SS:fdspace}
   We next construct certain finite dimensional NN spaces which will be used to approximate general ReLU atoms.  The general idea that defines these spaces is to choose a set $W_m$ of $m^{d-1}$ vectors $\xi$ that are
   roughly equally spaced on the unit sphere in $\R^d$ and likewise choose a set $T=T_m=T_{m,\Omega}$ of $m$ real numbers 
 that are equally spaced on $T_\Omega$.  Recall that $T_\Omega$ is the smallest interval outside of which
 no offset $t\notin T_\Omega$ admits a ReLU atom which is non-vanishing on $\Omega$.  Then $V_n$, $n=m^d$,
 is the linear space  
 %
 \be  
 \label{Vatoms}
 V_n:=\{\phi(\cdot;\xi,t),\ \xi \in W_m,\ t\in T_m\}.
 \ee 
 Then, $V_n$ is a linear subspace of $\Sigma_n$ of dimension at most $n$.

 
     
  



   
         For $W_m$, we take  a set of $m^{d-1}$ vectors $\xi_j$, $j=1,\dots,m^{d-1}$ that are quasi-uniformly spaced on the sphere $S^d$ in the sense that
   %
   \be
   \label{qu}
   \frac{c_0}{m}\le \dist (\xi_i, W\setminus \{\xi_i\}) \le \frac{ C_0}{m},
   \ee
   where the constants $c_0,C_0$ depend only on $d$. Since, by assumption $\Omega\subset [-1,1]^d$,  we know that $T_\Omega\subset [-\sqrt{d},\sqrt{d}]$  This leads us to define $T_m$ be the set of equally spaced points $t_1,\dots,t_m$ in the interval
   $[-\sqrt{d},\sqrt{d}]$.  The finite dictionary $\cD'$ of ReLU atoms
   %
   \be
   \label{atoms1}
   \phi_{i,j}(\cdot ):=\phi (\cdot ;\xi_i,t_j),\quad i=1,\dots,m^{d-1},\ j=1,\dots,m,
   \ee
    has cardinality at most $n$.  We only include in $\cD'$ atoms that are not identically zero on $\Omega$.
    So the space $V_n$ spanned by the $\phi_{i,j}$ has dimension at most $n$.

  
The following lemma is the analogue of Lemma \ref{L:AD}.  
    
     \begin{lemma}
  \label{L:AD1}
  Let  $\phi=\sigma(\cdot;\xi,t)$  be any  element in $\cD$.  Then,  there is a function $v\in V_n$   such that
  
  \noindent
  {\rm (i)}  $\phi(x)=v(x) $, $x\in \Omega$ outside a set $S_\phi\subset \Omega$ of measure $|S_\phi|\le C_1\mu(\phi)$.
     
  \noindent
  {\rm (ii)} $ \|\phi-v\|_{L_\infty(\Omega)}\le C_1  \lambda(\phi)$,
  with $C_1$ depending only on $d$
  
  \noindent
  {\rm (iii)}  For any $\phi\in \cD(\Omega)$, we have    
  $$ \|\phi-v\|_{L_2(\Omega )}\le    C_1 m^{-3/2}\lambda(\phi)^{1/2}$$
    with $C_1$ an absolute constant.

  \end{lemma}
  %
  \noindent
  {\bf Proof:}  Let  $W_\phi=\{w_1,\dots,w_{d+1}\}$  be a set of $d+1$ distinct elements $\xi_1,\dots,\xi_d$  from $W$ closest to $\xi$ with respect to the Euclidean norm $\|\cdot\|$.  In view of \eref{??}, it follows that
  %
  \be   
  \label{closew}
  \|w-w_j\|\le C_0/m,\quad j=1,\dots,d,
  \ee  
  where $C_0$ depends only on $d$.  Next let $t'\in T_0$ be the   points in $T_0$ closest to  $t$.   Consider the $d+1$ linear functions $w_j\cdot x+t'$.
  
  
  
  
  $v_j:=\phi(\xi_j,t')$,
  $j=1,\dots,d+1$.  
   





    
   
    We want to take
    the set of all atoms in $\cD(\Omega)$ and put them into buckets $B_{i,j}$ with each bucket associated to the atom $\phi_{i,j}$ ({\rnew RD: I have
    not thought out  enough  how to best  do this}).  There will be $\sim n$ buckets.  These correspond to the $\cL_{i,j}$ in the case $\Omega=B_2$ which we have discussed in detail. Each $\phi=\phi(\xi,t;\cdot)\in\cD(\Omega)$ should be assigned a unique bucket.   This bucket
    should be associated to a $\phi_{i,j}$ for which $\xi_{i}$ is close to $\xi$ and $t_j$ is close to $t$.
    We want each of the $\phi$ in a given bucket to have comparable $h(\phi)$.  I think I can do this without imposing more conditions on $\Omega$. {\bf  We should have that all of the $h(\phi)$ for $\phi$ in the same bucket are comparable.}  We then define  the sets
    %
    \be
    \label{Sij}
    S_{i,j}:=\bigcup\{ H_\phi:\phi\in B_{i,j}\}.
    \ee
     The set $S_{i,j}$ will have a certain width $\lambda$.  We can then define $\lambda
     (\phi)$ to be the same as the width of the $S_{i,j}$ when $\phi$ is in $B_{i,j}$. The measure $|S_{i,j}|$ will look like 
     \be
     \label{measS}
     |S_{i,j}| \sim |H_\phi| \lambda(\phi)/m.
     \ee
     Recall that this $\lambda$ looks like $|L_\phi|/m$ when $\Omega=B_2$ and like $1/m$ when $\Omega=Q_2$. For arbitrary $d$,
     the width of $S_{i,j}$ will look like $1/m$ for $Q_d$ and  $h(\phi) /m$ for $B_2$.
    
    
  \section{Approximation in $L_\infty$}
  \label{S: infinity}
  
  In this section,  we discuss rates of approximation in $L_\infty$ in the case $d=2$ and domain $\Omega$ the unit disc.  At first we
  will not concern ourselves with results with weights.   There are results in this case that give an approximation rate
  $O(n^{-5/4}\log n)$ for functions in $K=K_{\rm conv} = U(RBV)$.  The proofs of this rate of convergence is not deterministic
  or constructive.  We want to prove these results with deterministic arguments.
  
  Let $\delta>0$. Given a vector $w$ on the unit circle,  we let $B:=B_w(\delta)$ be the set of all lines $L$ passing through $\Omega$ which have   direction vector $v$ satisfying
  %
  \be
  \label{satisfy}
  | v\cdot w|\le \delta.
  \ee
 We will refer to $\delta$ as the {\it width} of $B$.  In other words,  all the lines $L\in B$ have direction close to $w^\perp$.
 
 To understand $B$, it is enough to consider $w=(1,0)$ .  The other cases are a rotation of this.  When $w=(1,0)$, the lines in $B=B_{e_1}(\delta)$ are of the form $v\cdot x=t$ where $v=(v_1,v_2) $ and $v_1\in [-\delta,\delta]$ and $t\in [-1,1]$. This means that the lines in $B$ have direction close to $e_2=(0,1)$ and intersect the $x$-axis at a point   $(\tau,0)$ where $\tau=\tau_L\in[-1.2]$.
 
 
 
  Given $f\in K$, we can write
 %
 \be
 \label{writef}
 f=\sum_{j=1}^\infty c_j\phi_j, \quad \phi_j=\phi(\cdot;w_j,t_j),\ \sum_{j=1}^\infty |c_j|\le 1.
 \ee
 Going further, we let $f_+$ be that portion of the sum in \eref{writef} for which $c_j\ge 0$ and let $f_-$ be the remaining sum.
 It is enough to bound the error in approximating $f_+$ by the elements of $\Sigma_n$.    So in going further, we assume that all coefficients in the representation \eref{writef} are nonnegative.  So $f_+$ is a nonnegative function on $\R^2$.  We can also
 break up the sum for $f_+$ into two sums where the atoms $\phi$  have the same orientation in the sense that  $\phi(1,1)>0$.
 In going further we assume that $f$ has only such atoms.
 
  We let $J_B$ be the set of indices $j$ such
 that $\phi_j$ has its line $L_j$ in $B$.
 Let
 %
 \be
 \label{energy}
 f_B:= \sum_{j\in J_B} c_j\phi_j\quad  E(B):=\sum_{j\in J_B} c_j,
 \ee
 which we think of as the {it energy} associated to $B$.
 
 We next see how we can approximate $f_B$ (in $L_\infty$). 
   For any interval $I\subset [-1,1]$, we define
   %
   \be
   \label{energy1}
   E_I:=E_I(B):= \sum_{j\in J_B, \tau_{L_j}\in I} c_j.
   \ee
  Given any integer $k$, we want to create an approximation to $f_B$ that is a sum of  $C_0k$ atoms.  For this, we choose a partition
  of $[-1,1]$ into  $3k$ intervals $I_1,\dots I_{2k}$ such that the length of each $I_j$ is at most $1/k$ and the energy $E_{I_j}$ is at most $ E(B)/k$.  Let $F_i$ be the portion of the sum \eref{energy} corresponding to lines intersecting $I_i$.
  
  Usual construction gives a sum $S_B$ of $C_0k$ atoms that approximates $f_B$ to $L_\infty$ accuracy $ E(B)/k^2$ with disjoint support strips.. 
  
  
     
  \section{Approximation in $L_p$}
  \label{Ainfinity}
  In this section, we want to  extend the result of the previous section to any $p\ge 2$.  For this, we recall that it is known that
  when $f\in\cK=\cK_\infty$, we have  %
  \be
  \label{inf1}
  E_n(f)_\infty \le C_3 n^{-5/4}\log n, \quad n\ge 1,
  \ee
  with $C_3$ an absolute constant.  To prove a result on approximating functions from $\cD_p$ by elements of $\Sigma_n(\cD)$,
  we will interpolate between \eref{inf1} and the approximation result of the previous section for $L_2$.
  
  \begin{lemma}
  \label{L:int}
  ???
  \end{lemma}
  
  
  
  
  The advantage of this estimate is that it removes the logarithm which currently exists in the best
  known estimates.  We prove \eref{infty1} when $n=m^2$ with $m$ an integer.  
  We discretize the boundary $\Gamma$ of $\Omega$ into intervals of length $1/m$.  There are $M=4m$ such intervals $I_1,\dots,I_M$.   Each atom $\phi$ has a support line segment $L_\phi$ whose endpoints are each in one of the $I_j$. For each pair
  $(i,j)$, we let $\cL_{i,j}$ be the collection of all line segments whose endpoints are one in $I_i$ and one in $I_j$.  There are $n$ such bucket $\cL_{i,j}$.  We label these  buckets $B_1,\dots,B_n$.  Each bucket $B_k$ has a support strip $S_k$.   Any 
    line segment $L\in B_k$ is contained in $S_k$.  The strip $S_k$ has width $1/m$ and any atom $\phi$  whose line segment is in bucket
    $B_k$ will satisfy
    %
    \be
    \label{inf2}
    \phi(x)|\le 1/m,\quad x\in S_k.
    \ee
   
  
  Let 
  \be\label{atomf}
  f=\sum_{k=1}^\infty \alpha_k\phi_k,
  \ee
  with $\sum_{k=1}^\infty|\alpha_k\le  1$.
 
    We bound $E_n(f)_\infty$ for this $f$. For each atom $\phi_k$ appearing in \eref{atomf} we identify $\phi_k$ with its bucket.
    
   
  
   \section{New weighted model classes}
 \label{S:new}
  The main point of the present paper is to show that when considering approximation on a domain $\Omega$ the  model
  classes defined above are not the right fit since they do not depend on the domain $\Omega$ in an appropriate manner.  To gain some intuition on why this is the case, consider an
  atom  $\phi\in\cD$ for which $H_\phi^+\cap \Omega$ has small Lebesgue  measure.   For such an atom, we have that $\|\phi\|_{L_p(\Omega)}$ is very small. This is the case for two reasons.  First $\phi$ is small on $\Omega$ since no point $x\in\Omega$ is far from the hyperplane $H_\phi$.  Secondly, the support of $\phi$ has small measure.  It follows that  such a function has little importance in providing
   an approximation to a given target function $f$.  However, the novel model classes given in the previous section do not
   reflect this fact.
   To circumvent the above fact, we use the weight $w(\phi)$ introduced in \eref{weight}.
      This weight   reflects the importance of $\phi$ on $\Omega$. 
    and  allows us to define a new space of functions $V_w:=V_w(\Omega)$ on $\Omega$ as we now describe.
    
    Recall from the previous section, that for any dictionary $D$ of functions from $L_2(\Omega)$ we can define the space $V(D,\Omega)$.    We now take for $D$ the normalized dictionary  $\cD(w)=\{\phi/w(\phi):\phi\in  \cD\}$ of ReLU atoms $\phi$.    The unit ball of $V_w$ is the closure (in $L_2(\Omega)$) of the convex hull of $\cD(w)$ and the norm of any $f\in V_w$ is
      %
    \be
    \label{Vnorm}
    \|f\|_{V_w}:=\|f\|_{V_w(\Omega)}:= \inf_{f=\sum_{j=1}^\infty c_j\phi_j} \sum_{j=1}^\infty w(\phi_j)|c_j|,
    \ee
    where the infimum is taken over all possible representations of $f$ by elements of $\cD$.  Clearly, the criteria for membership
    in $V_w$ is much weaker than for membership in $V$ and the unit ball $U(V_w)$ is larger
    than $U(V)$.  In \S\ref{S:Radon} we give another intrinsic definition of $V_w$ by using the intrinsic Radon transform on $\Omega$.
    For now, we want to prove results on the approximation rate of functions from $V_w$ by $\Sigma_n$ ($n$ term approximation by
    ReLU atoms).  The next sections of the paper show that this rate of approximation is the same as that proven   for $V$.  Moreover,
    these approximation properties clearly depend on $\Omega$ and its geometry.
    
    
    
      The presentation that follows begins with the case $\Omega=B_2$ (the unit Euclidean ball in $\R^2$) where all arguments are quite transparent.  We then turn to the general case when $\Omega$ is a convex centrally symmetric bounded domain in $\R^d$.
    
         Our next lemma concerns the Hausdorff distance between two sets $H_\phi$ and $H_{\bar \phi}$ when $\phi$ and $\bar\phi$ are dictionary elements.  Recall that
 $H_\phi$ is the intersection of the hyperplane $x\cdot \xi =t$  with $B_2^d$ when $\phi=\phi(\cdot;\xi,t)$.

 \begin{lemma} 
 \label{L:Haus}
 For any two atoms $\phi(\cdot,\xi,t)$ and $\bar\phi=\phi(\cdot;\bar \xi,\bar t)$, we have
 %
 \be
 \dist ( H_{\bar\phi},H_\phi)\le ??,
 \ee  
 where the distance  between these two sets is measured in the Euclidean norm $\|\cdot\|$.
 \end{lemma}

 \noindent 
 {\bf Proof:} We first consider the case where $t=\bar t$.
 Because of rotational symmetry, we may suppose that $\xi=e_1=(1,0,\dots,0)$ and therefore
 $H_\phi=\{( t,\eta):\ \eta\in \R^{d-1},\ \|\eta\|\le \sqrt{(1- t^2}\}$.
 Now consider $\bar \xi =(a,z)$  with $a\in\R$ and define $\delta:=\|\bar\xi -e_1\|$.  Then,
 %
 \be  
 \label{delta}
 \delta^2=|a-1|^2+\|z\|^2.
 \ee  
 
 
 
 Let $x=(x_1,y)$ with $x_1\in\R$ be any point
 on $H_{\bar\phi}$.  Then,
 \be  
 ax_1+ y\cdot z =t,
 \ee  
 and so 
 \be  
 a(x_1-t)=   (1-a)t- y\cdot z,
 \ee  
    Therefore, we can write $x=(\bar t,y)$ where $y\in \R^{d-1}$ with $\|y\|\le \sqrt{(1-\bar t^2}$. 


 




The first of these model classes   was introduced by Andrew Barron   \cite{B} where membership of a function $f$ in a Barron class is  defined by requiring that $f$ has an extension to all of $\R^d$ whose   Fourier transform satisfies certain decay.  The Barron classes have been generalized in several directions. Barron himself pointed out the that membership in Barron classes implies that $f$ has a sparse decomposition in terms of the atoms in the ReLU dictionary.  This sparse dictionary class was in turn   characterized in \cite{O+, PN} by a smoothness condition   on the Radon transform of $f$ .
   Determining the exact $L_p(\Omega)$  approximation rates (decay of error versus the number of neurons) for
  these new model classes  has been a challenging problem and is still not completely settled
  (see \cite{SX} for a summary of known results).




   We begin with some remarks on the ReLU atoms $\phi(\cdot;\xi,t)$ on $B_d$ and later specialize to $d=2$.   For any fixed atom $\phi$, we introduce a new coordinate system for $B_d$.  Namely, each $x\in B_d$ can be written as
   %
   \be
   \label{newdoord}
   x=  \alpha  \xi +\eta, \quad \alpha\in [-1,1],\ \eta \perp \xi=0.
   \ee
   Because of this,  any atom $\phi(\cdot;\xi ,t)$ behaves the same as $\phi(\cdot;e_1,t)$ where $e_1:=(1,0,\dots,0)$ except it is rotated. 


  Consider now the hyperplane $H_\phi$.  The Hausdorff distance between $H_\phi\cap\Omega$ and the boundary of $B_d$
     is $1-t$ and  
   %
   \be
   \label{Hmeas}
  |H_\phi\cap\Omega|_{d-1} \approx (1-t^2)^{\frac{d-1}{2}}, \quad |H_\phi^+|_{d} \approx (1-t)^{1+\frac{d-1}{2}} , \quad t\in[0,1],
  \ee
  where the notation $|\cdot |_d$ denotes Lebesgue measure of a set in $\R^d$.  Usually, we drop the subscript  when it is known from context.  In \eref{Hmeas} the constants of equivalence 






  
    
    
    This will not be the final decomposition of the lemma.  It will be subsequently adjusted to give
    the decomposition of the lemma.

     It will be useful to begin by discussing the renormalization that takes us from a vector $\bar\xi'$ on the boundary of $Q$ to its corresponding element $\frac{\bar\xi'}{\|\bar\xi'\|} $ which lies on the unit sphere.  Let $F$ be the face of $Q$ which contains $\bar\xi'$.  This face corresponds to fixing a $j\in\{1,\dots,d\}$ and a sign $s\in\{-1,+1\}$.  All points on this face  have $j$-th coordinate equal to $s$.  For the following discussion, we assume $j=1$ and the sign is $+1$.
    All other cases are handled similarly.  It follows that $\bar\xi'=e_1+\tilde \xi'$ where $\tilde\xi'\cdot e_1=0$ 
    and $\|\tilde \xi'\|_{\ell_\infty}\le 1$.
    Thus, we have
    %
    \be 
    \label{renorm1}
    \|\bar \xi'\|^2= 1+\|\tilde \xi'\|^2.
    \ee 
     This in turn gives
     \be 
    \label{renorm2}
    1\le \|\bar \xi'\|= [1+\|\tilde \xi'\|^2]^{1/2}\le 1+\|\tilde\xi'\|^2/2.
    \ee 
    Here and later in this section we use the inequalities
    \be 
    \label{theinequality}
    ??\le \sqrt{1+\theta}\le 1+\theta/2,\quad \theta\in (0,1).
    \ee 
We see that renormalization of $\bar\xi'$ will depend very much on the size of  $\|\tilde w'\|$.


     We use the notation $\bar w$ for an element on the boundary of $Q$ and $\tilde w$ for the above component throughout this appendix.
We also recall the notation $m=2^k$.  We begin by proving the following lemma.
    \begin{lemma}
\label{L:linear}
If  $\xi\in S_d$,  then   there exists a set $W'(\xi):=\{\xi_i \in W_k,\ i=1,\dots,d\}$,   such that 

\noindent{\rm (i)} there is a face $F$ of $Q$ that contains $\bar\xi$ and each $\xi_i$, $i=1,\dots,d$, is the renormalization of an $\bar\xi_i\in V_k$ from  $F$,

\noindent{\rm (ii)} $\xi=\sum_{i=1}^{d} \gamma_i\xi_i$,  $\gamma_i\ge 0$, $i=1,\dots,d$.

\noindent{\rm (iii)} $\|\xi-\xi_i\|\le 4d/m$, $i=1,\dots,d$,

\noindent
{\rm (iv)} $ 1-\eta(w) \le \sum_{i=1}^d\gamma_i\le  1+ \eta(w)$,   where  $\eta(w):=\frac{2\sqrt{d} \|\tilde \xi\|}{m} +\frac{d}{m^2}$.
 \end{lemma}
  \noindent
  {\bf Proof:}   Given such a $\xi$, we can write $\xi=\frac{\bar \xi}{\|\bar \xi\|}$ where $\bar \xi $ is on the boundary of $Q$.
  Let $F$ be a face of $Q$ that contains $\bar \xi$.  Recall that this face corresponds to setting one of the coordinates equal to $\pm 1$.  Without loss of generality we can assume that the points on this face have their first coordinate equal to $1$.  All other possibilities are handled exactly the same way.

  
  The points in $V_k$ induce a partition of $F$ into $d-1$ dimensional cubes with side length $2^{-k}=1/m$.  Let $Q_0$ be the dyadic cube of side length $2^{-k}$ 
  that contains $\bar \xi$.  By Caratheodory's theorem, we can write
  $$\bar\xi=\sum_{i=1}^d c_i\bar \xi_i,$$ 
  with $c_i\ge 0$ and 
  $\sum_{i=1}^dc_i=1$, where the $\bar\xi_i$ are $d$ of the vertices of $Q_0$.  This gives the representation
  \be  
  \label{repomega}
  \xi = \sum_{i=1}^d \gamma_i  \xi_i,\quad \gamma_i:= \frac{\|\bar \xi_i\|}{\|\bar\xi\|}c_i \ge 0.
  \ee  
  This serves to define $W'(\xi)$ and gives property (i) and the decomposition in (ii). 
  
In order to prove (iii) and (iv), we consider the univariate function $F_A(\theta)=(A+\theta)^{1/2}$ where $A\ge 1$.  From Taylor's expansion, we have
 \be 
 \label{Taylor}
 F_A(\theta)=\sqrt{A}+\frac{1}{2\sqrt{A}}\theta+ R(\theta), \quad |R(\theta)|\le \frac{1}{4A\sqrt{A}} \theta^2, \ \theta\ge 0.
 \ee 
 

  For the proof of the upper inequality in (iv), we have
  $$ 
  \|\bar\xi_i\|^2=1+ \|\tilde\xi_i\|^2\le 1+ [\|\tilde \xi\| +\frac{\sqrt{d}}{m}]^2= \|\bar \xi\|^2+\eta(\xi) .
$$
This gives in turn 
  $$
  \frac{ \|\bar\xi_i\|}{ \|\bar\xi\|}\le  \sqrt{1+\eta(\xi)}\le 1+\eta(\xi), \quad i=1,\dots,d
  $$
  Inserting this into the definition of the $\gamma_i$ in \eref{repomega} proves the upper inequality in (iv). A similar estimation gives
   $$
  \frac{ \|\bar\xi_i\|}{ \|\bar\xi\|}\ge    1-\eta(\xi), \quad i=1,\dots,d
  $$
  and therefore proves the lower  inequality in (iv).
  
  To prove (iii), we write  
  \be  
  \label{lastin}
   \|\bar\xi_i\|\|\xi-\xi_i\|=    \|\frac{\|\bar \xi_i\|}{\|\bar \xi\|}\bar\xi-\bar\xi_i\|\le  \|\bar \xi-\bar\xi_i\|+\eta(w) \|\bar\xi\|\le
  \frac{\sqrt{d}}{m} + \frac{3d}{m} \|\bar\xi\|\le \frac{4d}{m} .
  \ee
 Dividing both sides  by $\|\bar \xi_i\|$ (which is larger than one) gives (iii).
\hfill $\Box$
 \vskip .1in 

 

While the above lemma gives a decomposition of $\xi$, the coefficients $\gamma_i$ do not satisfy  property (iii) of  Lemma \ref{L:decomega}.    Indeed, in the  representation \eref{repomega}  we have
\be  
\label{defS}
 \sum_{i=1}^d\gamma_it_i^+ =:S,
\ee 
and we do not know that $S=t$.    We will remedy this by adding a few new vertices in the representation \eref{repomega} which will allow us to satisfy (iii) of Lemma \ref{L:decomega1} while not destroying any of the other properties.  Before doing this, let us note that $S$ and $t$ do not differ by much.
\begin{lemma}
    \label{L:S}
    For each $t>1/2$, we have the number $S$ of \eref{defS} satisfies
    \be
    \label{LS}
    t-\eta(w)t\le S\le t+\eta(\xi)t+ \eta)\xi)\delta,\quad \delta:=C_3[\frac{\sqrt{1-t^2}}{m}+\frac{1}{m^2}]
    \ee 
    where $C_3$ depends only on $d$.
    \end{lemma}
    \vskip .1in
    \noindent 
    {\bf Proof:} From Lemma \ref{L:ti+}, we know that 
    \be 
    \label{LS1}
    t\le t_i^+\le t+C[\frac{\sqrt{1-t^2}}{m}+\frac{1}{m^2}]\le t+\delta.\quad i=1,\dots,d.
    \ee
   We now apply (iv) of Lemma \ref{L:linear} to complete the proof of the lemma. \hfill $\Box$ 

To prove Lemma \ref{L:decomega} we shall make an adjustment to the decomposition of Lemma \ref{L:linear} by adding a few
more vertices to $W'(\xi)$.  These new vertices will allow us to maintain (i-iii) of Lemma \ref{L:linear} 
but to also ensure that
property (iii) of Lemma \ref{L:decomega} is now satisfied.   We continue with the setting of the previous lemma, in particular that $\xi = \frac{\bar\xi}{\|\bar\xi\|}$ where $\bar \xi$ lies on a face $F$  of $[-1,1]^d$.  We assume that this face  corresponds to all vectors whose first coordinate is one.  The other possibilities are handled similarly.  The vertices
on the face $F$ all take the form
%
\be 
\label{thevertices}
v=e_1+ 2^{-k}\underbar i=e_1+\frac{1}{m} \underbar i,
\ee 
where $\underbar i$ is an integer vector in $\R^d$ whose first coordinate is zero. 


Let $Q_0$ be  the cube at dyadic level $k$ which contains $\bar\xi$.  We choose a vertex $\tilde v$   of $Q_0$ and a   vector $\tilde e$ of $\R^{d-1}$ with all entries in $\tilde e$ either $-1$ or $1$.    We define $\nu= \frac{1}{m}(0,\tilde e)\in \R ^d$.  Then, if $m
$ is large enough, say $m\ge m^*$, with a proper choice for $\tilde v$ and $\tilde e$ the   three vertices  
\be 
\label{three}
  v_1:=e_1+ \tilde v, \quad v_2:=v_1 +\nu,\quad v_3:=v_1 +2\nu ,
\ee 
will all remain on the face $F$ and hence be in $V_k$.   Moreover, we can require $|\tilde v\cdot \tilde e |\ge \|\tilde v\|$.  



Notice that we have the identity
\be  
\label{identity}
v_1-2v_2+v_3=0.
\ee
Now define
\be 
\label{three1}
\xi_1^*:=\frac{ v_1}{\| v_1\|}, \quad \xi_2^*:=\frac{ v_2}{\| v_2\|},\quad \ \xi_3^*:=\frac{ v_3}{\| v_3\|}.
\ee 
These three vertices are in $W_k$ and in fact $w_1$* may be  one of the vertices in the set $W(\xi)$.  Let us notice that
%
\be 
\label{notice}
a_1\xi_1^*+ a_2\xi_2^*+a_3\xi_3^* =0, \quad {\rm where} \quad a_1=\| v_1\|, \ \ a_2=-2\| v_2\|,\ \ a_3=\| v_3\|.
\ee 

 We next want to show the following result.
\begin{lemma}
\label{L:tstar}
There exists an $m^*$ depending only on $d$ such that whenever $t>t^*$ and $m\ge m^*$, we have
\be  
\label{tstar}
|a_1 + a_2+a_3|>c\eta(\xi),
\ee 
with $c$ depending only on $d$.
\end{lemma}
  


\vskip .1in
\noindent 
{\bf Proof:} Let $ B:=\| v_1\|^2=1+\|\tilde v\|^2$.   Then, we have
%
\be 
\label{tstar1}
\|\bar v_2\|^2=B+ 2\langle \tilde v,\nu\rangle+\|\nu\|^2=:B+\lambda_2,\quad \|\bar v_3\|^2=B +4\langle \tilde v,\nu\rangle+4\|\nu\|^2=:B+\lambda_3.
\ee
Let us note that
% 
\be 
\label{notelambda}
\lambda_2= 2\frac{\|\tilde\nu\|_{\ell_1}}{m} +\frac{d-1}{m^2}\quad {\rm and}\quad \lambda_3= 4\frac{\|\tilde\nu\|_{\ell_1}}{m} +\frac{4(d-1)}{m^2}.
\ee
From \eref{tstar1}, it follows that 
\be  
\label{tstar2}
|a_1 + a_2+a_3|\ge [\sqrt{B+\lambda_2}-\sqrt{B}]-[\sqrt{B+\lambda_3}-\sqrt{B+\lambda_2}].
\ee 
We want to give bounds for the bracketed terms.   The mean value theorem applied to the function $f(u)=\sqrt{u}$ gives
$f(1+\alpha)-f(1)=f'(\xi) \alpha$, with $\xi\in (1,1+\alpha)$.  This gives the inequalities
%
\be 
\label{inequalities}
1+\frac{\alpha}{2\sqrt{1+\alpha}}\le \sqrt{1+\alpha} \le 1+\frac{\alpha}{2},\quad  \alpha>0.
\ee 
 Applying this to the first bracketed term in \eref{tstar2} give
 %
 \be
 \label{firstterm}
 |\sqrt{B+\lambda_2}-\sqrt{B}|= \sqrt{B} \sqrt{1+\frac{\lambda_2}{B}}-\sqrt{B}\le \frac{\lambda_2}{2\sqrt{B}}.
 \ee 
 
\begin{lemma}
\label{L:tstar}
There exists an $m^*$ depending only on $d$ such that whenever $t>t^*$ and $m\ge m^*$, we have
\be  
|\label{tstar}
a_1t^+(\xi_1^*) + a_2t^+(\xi_2^*)+a_3t^+(\xi_3^*)|>\frac{c}{m},
\ee 
with $c$ depending only on $d$.
\end{lemma}
  


\vskip .1in
\noindent 
{\bf Proof:}






The $\gamma_i$ are from Lemma \ref{L:linear}.  In view of (iv) of Lemma \ref{L:linear} and   Remark \ref{R:ti+}, we have 
%
\be 
\label{haveforS}
[1-\frac{\sqrt{d}}{m}]t \le \sum_{i=1}^d\gamma_it_i^+\le  [1+\frac{\sqrt{d}}{m}](t+4\sqrt{d}/m].
\ee 
In other words,
\be 
\label{haveforS1}
|S-t| \le    \frac{5\sqrt{d}}{m}+\frac{4d}{m^2}.
\ee 

We now describe the adjustment we shall make. Without loss of generality, we can assume $\bar \xi$ lies on the face $F$ of $Q$ corresponding to $e_1=1$. Let $Q_0$ be the cube for the partition $F_k$ that contains $\xi$.  The vertices in $V_k(F)$ are of the form $e_1+v'$.  Let $\bar v$ be the   vertex in the cube $Q_0$ that contains $\bar\xi$ for which $v'$ is largest.   We assume   that $\|v'\|\le 1/2$ and introduce 
%
\be  
\label{introduce}
\bar v_i:= e_1+(1+2^{-k+i}) v', \quad i=1,\dots,k-1,
\ee  
These points are all in $V_k$.  If $\|v'\|\ge 1/2$, we would define the $ \bar v_i=e_1+(1-2^{-k-i}) v'$ and give a similar argument to the one we now give.


 

Each of the $v_i:= \bar v_i/\|\bar v_i\|$ are in $W_k$.  We need to compute the norms $\|v_i\|$.  We have
%
\be  
\label{normvi}
 V_i^{-2}:=\|\bar v_i\|^2= (1+2^{-1}v' , \quad i=0,1,\dots,\ell.
\ee  
The number $V_i$ is the renormalization constant to go from $ v_i$ to $v_i$, namely $v_i=V_i\bar v_i$.
Notice that 
\begin{lemma}
    \label{L:adjust}
    If $\ell$ is large enough depending only on $d$, there exists constants $\beta_i$, $i=1,\dots,\ell$ such that 
    \vskip .1in
    \noindent
    {\rm (i)} $\sum_{i=0}^\ell \beta_iv_i=0$.
    \vskip .1in
    \noindent
    {\rm (ii)} $\sum_{i=0}^\ell \beta_it^+(v_i)=t-S$.
    \vskip .1in
    \noindent
    {\rm (iii)} $\sum_{i=0}^\ell |\beta_i|\le C$,
    with $C$ depending only on $d$.  Here $t^+(v_i)$ are the $t^+$ for these vectors.
\end{lemma}
\vskip .1in
\noindent{\bf Proof:}  We have $\bar v_i=\bar v+2^{-k+i}e$.  Therefore, (i) will be satisfied if
\be 
\label{satisfy}
\sum_{i=0}^\ell \beta_i(1+2^i/m)=0.
\ee 




Regarding (ii), it is enough for use to find $(\beta_i)\neq 0$ that in addition to \eref{satisfy} satisfies
\be 
\label{satisfy2}
|\sum_{i=0}^\ell \beta_it^+(v_i)|\ge c\sum_{i=0}^\ell |\beta_i|. 
\ee 
  To show this, we examine the inner product $I$ of $(1+2^i/m)_{i=0}^\ell$ with $(t^+(v_i))_{i=0}^\ell$.
  From Remark \ref{R:ti+} we have that this inner product satisfies
  \be 
\label{ip} 
I\ge t[\sum_{i=0}^\ell (1+2^i/m)[\xi\cdot v_i]^{-1}   \ge t\|v\| ???
\ee  
\be 
\label{reii} 
t\le t_i^+\xi\cdot\xi_i\le t+C_1\|\xi-\xi_i\|\sqrt{1-{t_i^+}^2}
\ee  
%
\be  
\label{knowti}
0\le \delta_i:=t^+(v_i)-t\le    2\|\xi-v_i\|\le 2^{-k+i}\sqrt{d}+2^{-k}\sqrt{d}\le 2^{-k+i+1}\sqrt{d}.
\ee 
Here, the last inequality is derived in the same way we have proved (iii) in Lemma \ref{L:linear}.
Therefore, to satisfy (ii) we need
\be 
\label{satisfy3}
\sum_{i=0}^\ell \beta_i =??.
\ee  

The requirement (ii) reads
%
\be  
\label{require}
\sum_{i=0}^\ell \beta_i \tau_i^+ = t-S.
\ee 
We write $e=e_j$ for  the unit vector for this coordinate.  We will consider vertices 
\be 
\label{newvertices}
\bar v_i:=\bar v+2^{-k+i}e=\bar v+2^{i}e/m, \quad i=0,1,\dots,k-1.
\ee 
These vertices all remain in $V_k$.  
The $\bar v_i$ are all in $V_k$ provided $B\le1/2$.  If $B>1/2$ we would take the $\bar v_i=\bar v-2^{-k+i}e$.  We assume $B<1/2$ in going forward.  The other case is handled in exactly the same way.

   
    
    
    
    
    
    
    
    
    
    
    
 \vskip .5in   
    
    
    
    
    Suppose without loss of generality that $\bar w$ lies on the face of $Q$ corresponding to $x_d = 1$, i.e.
    \begin{equation}
        \bar w = (w_1,...,w_{d-1},1)
    \end{equation}
    with $|w_i| \leq 1$. Let $k$ be an integer to be determined later and consider the subdivisions of $\bar{W}_m$ and $\bar{W}_{km}$ which contain $\bar w$. Specifically, for $i=1,...,d-1$ let
    \begin{equation}
        x^-_i \leq w_i\leq x^+_i
    \end{equation}
    be the nearest multiples of $2/m$ to the components $w_i$ and
    \begin{equation}
        y^-_i \leq w_i\leq y^+_i
    \end{equation}
    be the nearest multiples of $2/(km)$ to the components $w_i$. In addition, we set
    \begin{equation}
        \alpha^+_i = \frac{w_i - x_i^-}{x_i^+ - x_i^-},~\alpha^-_i = \frac{x_i^+ - w_i}{x_i^+ - x_i^-}
    \end{equation}
    and
    \begin{equation}
        \beta^+_i = \frac{w_i - y_i^-}{y_i^+ - y_i^-},~\beta^-_i = \frac{y_i^+ - w_i}{y_i^+ - y_i^-}.
    \end{equation}
    We begin with the following two representations of $\bar{w}$ as convex combinations
    \begin{equation}
        \bar{w} = \sum_{j\in \{\pm\}^{n-1}} \left(\prod_{i=1}^{n-1} \alpha_i^{j_i}\right)x^j,
    \end{equation}
    and
    \begin{equation}
        \bar{w} = \sum_{j\in \{\pm\}^{n-1}} \left(\prod_{i=1}^{n-1} \beta_i^{j_i}\right)y^j.
    \end{equation}
    Here the sums are over all sign patters $j$ and the points $x^j$ and $y^j$ are defined as
    \begin{equation}
        x^j = (x_1^{j_i},...,x_{d-1}^{j_{d-1}},1),~y^j = (y_1^{j_i},...,y_{d-1}^{j_{d-1}},1).
    \end{equation}
    Normalizing these representations, we get two representation of $w$ as
    \begin{equation}
        w = \sum_{j\in \{\pm\}^{n-1}} a_j\xi_j = \sum_{j\in \{\pm\}^{n-1}} b_j\xi'_j,
    \end{equation}
    where $\xi_j = x^j/\|x^j\|\in W_m$ and $\xi'_j = y^j/\|y^j\|\in W_{km}$ and the coefficients are given by
    \begin{equation}
        a_j = \left(\prod_{i=1}^{n-1} \alpha_i^{j_i}\right)\frac{\|x^j\|}{\|\bar{w}\|},~b_j= \left(\prod_{i=1}^{n-1} \beta_i^{j_i}\right)\frac{\|y^j\|}{\|\bar{w}\|}.
    \end{equation}
    Set $C_1 = \sum a_j$ and $C_2 = \sum b_j$. Note that since the fractions $\frac{\|x^j\|}{\|\bar{w}\|}$ and $\frac{\|y^j\|}{\|\bar{w}\|}$ are bounded by $\sqrt{d}$, we have $C_1,C_2 \leq \sqrt{d}$ are bounded by a constant depending upon $d$. 
    
    Our strategy for obtaining the decomposition \eqref{omega-decomposition} will be to write as a linear combination
    \begin{equation}
        w = X_1\sum_{j\in \{\pm\}^{n-1}} a_j\xi_j + X_2\sum_{j\in \{\pm\}^{n-1}} b_j\xi'_j,
    \end{equation}
    where the coefficients $X_i$ satisfy $X_1 + X_2 = 1$ (to ensure that that the above expression represents $w$) and $C_1X_1 + C_2X_2 = 1$ (to ensure that the coefficients sum to $1$). Solving these equation for $X_1$ and $X_2$, we get
    \begin{equation}
        X_1 = \frac{C_2 - 1}{C_2 - C_1},~X_2 = \frac{C_1 - 1}{C_1 - C_2}.
    \end{equation}
    Thus, we will be done if we can show that $C_1 - 1 \geq 2(C_2 - 1)$ since this will imply that $|X_1|,|X_2| \leq 2$ (so that the absolute values of the coefficients are summable).
    
    We calculate
    \begin{equation}\label{C-1-estimate}
        C_1 - 1 = \left(\sum_{j\in \{\pm\}^{n-1}} a_j\right) - 1 = \frac{1}{\|\bar{w}\|}\sum_{j\in \{\pm\}^{n-1}} \left(\prod_{i=1}^{n-1} \alpha_i^{j_i}\right)(\|x^j\| - \|\bar{w}\|),
    \end{equation}
    and likewise for $C_2 - 1$. Consider the function $f_w$ on $\mathbb{R}^{d-1}$ defined by
    \begin{equation}
        f_w(x) = \sqrt{1 + x_1^2 + \cdots x_{d-1}^d} - \|\bar{w}\|
    \end{equation}
    We easily calculate that for $x\in [-1,1]^d$ the Hessian of $f_w$ satisfies
    \begin{equation}
        \frac{1}{d\sqrt{d}}I \preccurlyeq Hf_w(x) \preccurlyeq I,
    \end{equation}
    where $I$ is the identity matrix. This means that for $x\in [-1,1]^d$ we have
    \begin{equation}
        \nabla f_w(\bar{w})\cdot (x - \bar{w}) + \frac{1}{2d\sqrt{d}}\|x - \bar{w}\|^2 \leq f_w(x) \leq \nabla f_w(\bar{w})\cdot (x - \bar{w}) + \frac{1}{2}\|x - \bar{w}\|^2.
    \end{equation}
    Plugging this into \eqref{C-1-estimate} and using the definition of $\alpha_i^+$ and $\alpha_i^-$ we calculate that
    \begin{equation}
        C_1 - 1 \geq \frac{1}{2\|\bar{w}\|d\sqrt{d}}\sum_{i=1}^{d-1} (w_i - x_i^-)(x_i^+ - w_i).
    \end{equation}
    Likewise, we calculate that
    \begin{equation}
        C_2 - 1 \leq \frac{1}{2\|\bar{w}\|}\sum_{i=1}^{d-1} (w_i - y_i^-)(y_i^+ - w_i).
    \end{equation}
    Finally, we calculate that since $x_i^+$ and $x_i^-$ are the nearest multiples of $2/m$ to $w_i$ and $y_i^+$ and $y_i^-$ are the nearest multiples of $2/(km)$ to $w_i$, we have that
    \begin{equation}
        (w_i - x_i^-)(x_i^+ - w_i) \geq k(w_i - y_i^-)(y_i^+ - w_i).
    \end{equation}
    Indeed, $$(w_i - x_i^-) = (w_i - y_i^-) + \frac{2j^-}{km}$$ and $$(x_i^+ - w_i) = (y_i^+ - w_i) + \frac{2j^+}{km}$$ for non-negative integers $j^-$ and $j^+$ which eatisfy $j^- + j^+ = k-1$. Since $(y_i^+ - w_i),(w_i - y_i^-) \leq 2/(km)$ we have
    \begin{equation}
    \begin{split}
        (w_i - x_i^-)(x_i^+ - w_i) &= \left((w_i - y_i^-) + \frac{2j^-}{km}\right)\left((y_i^+ - w_i) + \frac{2j^+}{km}\right)\\
        &\geq (w_i - y_i^-)(y_i^+ - w_i) + \frac{2j^-}{km}(y_i^+ - w_i) + \frac{2j^+}{km}((w_i - y_i^-)) \\
        &\geq k(w_i - y_i^-)(y_i^+ - w_i).
    \end{split}
    \end{equation}
    Thus, choosing $k \geq 2d\sqrt{d}$ and combining these bounds, we get $C_1 - 1 \geq 2(C_2 - 1)$ as desired.
% \end{Proof}


Returning to our representation of $\xi$ we obtain
%
\be  
\label{newomegarep}
\xi =\sum_{j=1}^d \alpha_j\xi_j+\sum_{j=1}^4 \beta_j v_j =\sum_{j=1}^{d'}  \gamma_j\xi'_j.
\ee
Here, the $\gamma_j$ satisfy
%
\be  
\label{gsatisfy}
\sum_{j=1}^{d'}\gamma_j=1\quad {\rm and} \quad \sum_{j=1}^{d'} |\gamma_j| \le C_d.
\ee 
This gives the following representation for the atom  $\phi(x)=\phi(x;\xi,t)$
%
\be  
\label{repphi}
 \xi\cdot x -t=\sum_{i=1}^{d'}\gamma_i
[\xi_i\cdot x-t],\quad {\rm where} .
\ee
\begin{remark}
\label{R:ti+}
The above definition of $t_i^+$ as the minimum value of $t_j$ satisfying $H_j^+(\xi)\subset H^+(\xi)$ was made for specificity.
The results that follow in this section all remain true if we change the definition of $t_i^+$ by allowing it to be
a value $t_k$ with $k$ larger than the $j$ for which $t_i^+=t_j$ provided that $k\le j+C_0$ with $C_0$ is a fixed constant.
We use this fact  later in the Appendix.
\end{remark}