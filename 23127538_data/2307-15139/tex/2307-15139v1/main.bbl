\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{agustsson2017soft}
Eirikur Agustsson, Fabian Mentzer, Michael Tschannen, Lukas Cavigelli, Radu
  Timofte, Luca Benini, and Luc~V Gool.
\newblock Soft-to-hard vector quantization for end-to-end learning compressible
  representations.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems (NeurIPS)}, volume~30, 2017.

\bibitem{arthur2007k}
D ARTHUR.
\newblock k-means++: the advantages of careful seeding.
\newblock In {\em Proceedings of the eighteenth annual ACM-SIAM symposium on
  Discrete algorithms, New Orleans, Louisiana, 2007}, pages 1027--1035. Society
  for Industrial and Applied Mathematics, 2007.

\bibitem{baobeit}
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock In {\em Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2022.

\bibitem{bradley1998refining}
Paul~S Bradley and Usama~M Fayyad.
\newblock Refining initial points for k-means clustering.
\newblock In {\em ICML}, volume~98, pages 91--99. Citeseer, 1998.

\bibitem{celebi2013comparative}
M~Emre Celebi, Hassan~A Kingravi, and Patricio~A Vela.
\newblock A comparative study of efficient initialization methods for the
  k-means clustering algorithm.
\newblock {\em Expert systems with applications}, 40(1):200--210, 2013.

\bibitem{chang2022maskgit}
Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William~T. Freeman.
\newblock Maskgit: Masked generative image transformer.
\newblock In {\em The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2022.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition (CVPR)}, pages 248--255. Ieee, 2009.

\bibitem{dhariwal2020jukebox}
Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong~Wook Kim, Alec Radford,
  and Ilya Sutskever.
\newblock Jukebox: A generative model for music.
\newblock {\em arXiv preprint arXiv:2005.00341}, 2020.

\bibitem{ding2021cogview}
Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da Yin, Junyang
  Lin, Xu Zou, Zhou Shao, Hongxia Yang, et~al.
\newblock Cogview: Mastering text-to-image generation via transformers.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  34, 2021.

\bibitem{esser2021imagebart}
Patrick Esser, Robin Rombach, Andreas Blattmann, and Bjorn Ommer.
\newblock Imagebart: Bidirectional context with multinomial diffusion for
  autoregressive image synthesis.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  volume~34, 2021.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition (CVPR)}, pages 12873--12883, 2021.

\bibitem{1162229}
R. Gray.
\newblock Vector quantization.
\newblock {\em IEEE ASSP Magazine}, 1(2):4--29, 1984.

\bibitem{gu2022rethinking}
Yuchao Gu, Xintao Wang, Yixiao Ge, Ying Shan, Xiaohu Qie, and Mike~Zheng Shou.
\newblock Rethinking the objectives of vector-quantized tokenizers for image
  synthesis.
\newblock {\em arXiv preprint arXiv:2212.03185}, 2022.

\bibitem{hamerly2002alternatives}
Greg Hamerly and Charles Elkan.
\newblock Alternatives to the k-means algorithm that find better clusterings.
\newblock In {\em Proceedings of the eleventh international conference on
  Information and knowledge management}, pages 600--607, 2002.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems (NeurIPS)}, pages 6626--6637, 2017.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  33:6840--6851, 2020.

\bibitem{hu2022global}
Minghui Hu, Yujie Wang, Tat-Jen Cham, Jianfei Yang, and Ponnuthurai~N
  Suganthan.
\newblock Global context with discrete diffusion in vector quantised modelling
  for image generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 11502--11511, 2022.

\bibitem{hu2022unified}
Minghui Hu, Chuanxia Zheng, Heliang Zheng, Tat-Jen Cham, Chaoyue Wang, Zuopeng
  Yang, Dacheng Tao, and Ponnuthurai~N Suganthan.
\newblock Unified discrete diffusion for simultaneous vision-language
  generation.
\newblock {\em arXiv preprint arXiv:2211.14842}, 2022.

\bibitem{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 4401--4410, 2019.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lee2022autoregressive}
Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han.
\newblock Autoregressive image generation using residual quantization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 11523--11532, 2022.

\bibitem{li2022unimo}
Wei Li, Can Gao, Guocheng Niu, Xinyan Xiao, Hao Liu, Jiachen Liu, Hua Wu, and
  Haifeng Wang.
\newblock Unimo-2: End-to-end unified vision-language grounded learning.
\newblock In {\em Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 3187--3201, 2022.

\bibitem{liu2022cross}
Alex Liu, SouYoung Jin, Cheng-I Lai, Andrew Rouditchenko, Aude Oliva, and James
  Glass.
\newblock Cross-modal discrete representation learning.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 3013--3035, 2022.

\bibitem{lloyd1982least}
Stuart Lloyd.
\newblock Least squares quantization in pcm.
\newblock {\em IEEE transactions on information theory}, 28(2):129--137, 1982.

\bibitem{maodiscrete}
Chengzhi Mao, Lu Jiang, Mostafa Dehghani, Carl Vondrick, Rahul Sukthankar, and
  Irfan Essa.
\newblock Discrete representations strengthen vision transformer robustness.
\newblock In {\em Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2022.

\bibitem{mittal2022autosdf}
Paritosh Mittal, Yen-Chi Cheng, Maneesh Singh, and Shubham Tulsiani.
\newblock Autosdf: Shape priors for 3d completion, reconstruction and
  generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition(CVPR)}, pages 306--315, 2022.

\bibitem{rakhimov2021latent}
Ruslan Rakhimov, Denis Volkhonskiy, Alexey Artemov, Denis Zorin, and Evgeny
  Burnaev.
\newblock Latent video transformer.
\newblock In {\em 16th International Joint Conference on Computer Vision,
  Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2021}, pages
  101--112. SciTePress, 2021.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  8821--8831. PMLR, 2021.

\bibitem{razavi2019generating}
Ali Razavi, Aaron Van~den Oord, and Oriol Vinyals.
\newblock Generating diverse high-fidelity images with vq-vae-2.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  volume~32, 2019.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition(CVPR)}, pages 10684--10695, 2022.

\bibitem{sanghi2023sketch}
Aditya Sanghi, Pradeep~Kumar Jayaraman, Arianna Rampini, Joseph Lambourne,
  Hooman Shayani, Evan Atherton, and Saeid~Asgari Taghanaki.
\newblock Sketch-a-shape: Zero-shot sketch-to-3d shape generation.
\newblock {\em arXiv preprint arXiv:2307.03869}, 2023.

\bibitem{sargent2023vq3d}
Kyle Sargent, Jing~Yu Koh, Han Zhang, Huiwen Chang, Charles Herrmann, Pratul
  Srinivasan, Jiajun Wu, and Deqing Sun.
\newblock Vq3d: Learning a 3d-aware generative model on imagenet.
\newblock {\em arXiv preprint arXiv:2302.06833}, 2023.

\bibitem{sauer2021projected}
Axel Sauer, Kashyap Chitta, Jens M{\"u}ller, and Andreas Geiger.
\newblock Projected gans converge faster.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  34:17480--17492, 2021.

\bibitem{takida2022sq}
Yuhta Takida, Takashi Shibuya, Weihsiang Liao, Chieh-Hsin Lai, Junki Ohmura,
  Toshimitsu Uesaka, Naoki Murata, Shusuke Takahashi, Toshiyuki Kumakura, and
  Yuki Mitsufuji.
\newblock Sq-vae: Variational bayes on discrete representation with
  self-annealed stochastic quantization.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  20987--21012. PMLR, 2022.

\bibitem{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems (NeurIPS)}, 2017.

\bibitem{vuong2023vector}
Tung-Long Vuong, Trung Le, He Zhao, Chuanxia Zheng, Mehrtash Harandi, Jianfei
  Cai, and Dinh Phung.
\newblock Vector quantized wasserstein auto-encoder.
\newblock {\em arXiv preprint arXiv:2302.05917}, 2023.

\bibitem{williams2020hierarchical}
Will Williams, Sam Ringer, Tom Ash, David MacLeod, Jamie Dougherty, and John
  Hughes.
\newblock Hierarchical quantized autoencoders.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  volume~33, 2020.

\bibitem{wu2022nuwa}
Chenfei Wu, Jian Liang, Lei Ji, Fan Yang, Yuejian Fang, Daxin Jiang, and Nan
  Duan.
\newblock N{\"u}wa: Visual synthesis pre-training for neural visual world
  creation.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XVI}, pages 720--736.
  Springer, 2022.

\bibitem{xiao2017online}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock {\em arXiv}, 2017.

\bibitem{yan2021videogpt}
Wilson Yan, Yunzhi Zhang, Pieter Abbeel, and Aravind Srinivas.
\newblock Videogpt: Video generation using vq-vae and transformers.
\newblock {\em arXiv preprint arXiv:2104.10157}, 2021.

\bibitem{yu2015lsun}
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong
  Xiao.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock {\em arXiv preprint arXiv:1506.03365}, 2015.

\bibitem{yu2022vectorquantized}
Jiahui Yu, Xin Li, Jing~Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander
  Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.
\newblock Vector-quantized image modeling with improved {VQGAN}.
\newblock In {\em Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2022.

\bibitem{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 586--595, 2018.

\bibitem{zheng2022high}
Chuanxia Zheng, Guoxian Song, Tat-Jen Cham, Jianfei Cai, Dinh Phung, and Linjie
  Luo.
\newblock High-quality pluralistic image completion via code shared vqgan.
\newblock {\em arXiv preprint arXiv:2204.01931}, 2022.

\bibitem{zhengmovq}
Chuanxia Zheng, Long~Tung Vuong, Jianfei Cai, and Dinh Phung.
\newblock Movq: Modulating quantized vectors for high-fidelity image
  generation.
\newblock In {\em Proceedings of the 36st International Conference on Neural
  Information Processing Systems (NeurIPS)}, 2022.

\end{thebibliography}
