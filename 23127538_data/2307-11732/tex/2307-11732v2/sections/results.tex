\raggedbottom
\section{Results}
\label{sec:results}
In this section, we provide our results. T he code implementing the learning algorithms described in \S\ref{sec:learning} is shared in our submission and will be available on GitHub. 
% at \href{https://github.com/amzn/advancing-ad-auctions}{this GitHub repository link}.

\subsection{Standard auctions}
\label{sec:results:textbook}

We first consider a standard, symmetric auction environment with a single query, so $Q = \{q^*\}$, and pay-per-impression pricing, so all CTRs are equal to 1. We consider both a small auction with $N = 2$ bidders, and a more realistic one with $N=10$ bidders. Values are uniformly distributed on a grid $B$ in the interval $[0,1]$. Formally, given the grid $B$, for all $i$, we let $\mathcal T_i = B$, $V_i(b, q^*) = b$, $\mathit{CTR}_i(b, q^*) = 1$, and $F_i(b) = \frac{1}{|B|}$ for all $b \in B$. Furthermore, we allow all bids $b_i$ on the grid $B$.

In a second-price auction, it is a dominant strategy for every bidder to bid their value. In a first-price auction, with $N$ bidders, a continuum of values (uniformly distributed on $[0,1]$) and bids, the unique symmetric Bayesian Nash equilibrium is for each bidder to bid a fraction $\frac{N-1}{N}$ of their value. Furthermore, Myerson's revenue equivalence applies, so the expected revenue for the advertising service is the same under both formats, namely $\frac{N-1}{N+1}$. We want to compare these theoretical predictions with the output of our learning algorithms with a fine enough grid $B$, and a long enough horizon $T$.

We choose $B = \{\frac{i}{20} : i = 0,\ldots, 20\}$ and $T = 1,000,000$ for \verb|EXP3-IX|. We also choose the tuning parameters optimally, as described in \citet{lattimore2020bandit} (Theorem 12.1, Chapter 12).  Table \ref{tab:standard-EXP3IX} displays revenues for the advertising service in first- and second-price auctions under \verb|EXP3-IX|, averaged over the last $10\%$ of the learning period, i.e., $100,000$ iterations, and 5 different runs of the algorithm, as well as the standard deviation of revenues across different runs\footnote{Throughout the paper, we draw a fixed sequence of type realizations for all bidders. This ensures that the only randomness is from the algorithms' choice of action.}.
% 
% \begin{table}[ht]
%     \parbox{0.52\linewidth}{
%     \small
%     \caption{Standard single-item auction, \texttt{EXP3-IX}}
%     \label{tab:standard-EXP3IX}
%     \centering
%     \begin{tabular}{|l|c|c|}
%     \hline
%     Auction format & Mean Revenue & Std. Dev.  \\ \hline
%     First price, $N=2$ & $0.3474$ & $0.0205$ \\
%     Second price, $N=2$ & $0.3346$ & $0.0016$ \\ \hline
%     First price, $N=10$ & $0.780$ & $0.0095$ \\
%     Second price, $N=10$ & $0.7723$ & $0.0171$ \\ \hline
%     \end{tabular}
%     }
%     %
%     \parbox{0.52\linewidth}{
%     \small
%     \caption{Standard single-item auction, \texttt{Hedge}.}
%     \label{tab:standard-Hedge}
%     \centering
%     \begin{tabular}{|l|c|c|}
%     \hline
%     Auction format & Mean Revenue & Std. Dev.  \\ \hline
%     First price, $N=2$ & $0.3201$ & $0.0018$ \\
%     Second price, $N=2$ & $0.3256$ & $0.0018$ \\ \hline
%     First price, $N=10$ & $0.8305$ & $0.0011$ \\
%     Second price, $N=10$ & $0.8334$ & $0.0008$ \\ \hline
%     \end{tabular}
%     }
% \end{table}
% 
\begin{table}[ht]
    \caption{Standard single-item auction, \texttt{EXP3-IX}}
    \label{tab:standard-EXP3IX}
    \vskip 0.1in
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price, $N=2$ & $0.3474$ & $0.0205$ \\
    Second price, $N=2$ & $0.3346$ & $0.0016$ \\ \hline
    First price, $N=10$ & $0.780$ & $0.0095$ \\
    Second price, $N=10$ & $0.7723$ & $0.0171$ \\ \hline
    \end{tabular}
\end{table}

Table \ref{tab:standard-Hedge} reports the results for \verb|Hedge|. We choose $T = 400,000$ and $\eta = 0.02$. We averaged over 5 different runs of the algorithm and over the last $40,000$ time periods.
% 
\begin{table}[H]
    \caption{Standard single-item auction, \texttt{Hedge}.}
    \label{tab:standard-Hedge}
    \vskip 0.1in
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price, $N=2$ & $0.3201$ & $0.0018$ \\
    Second price, $N=2$ & $0.3256$ & $0.0018$ \\ \hline
    First price, $N=10$ & $0.8305$ & $0.0011$ \\
    Second price, $N=10$ & $0.8334$ & $0.0008$ \\ \hline
    \end{tabular}
\end{table}

The key take-away is that expected revenues are close to the theoretical value $\frac13$ for $N=2$ under both $\texttt{Hedge}$ and $\texttt{Exp3-IX}$. With $N=10$, $\texttt{Hedge}$ again approximates the theoretical value $0.\overline{81}$, while $\texttt{Exp3-IX}$ is not as close. Revenues do not vary much across different runs. Even when $N=2$, \verb|EXP3-IX| required a considerably larger number of periods to achieve similar results
as \verb|Hedge|. 

\subsection{Soft floors}
\label{sec:results:SFRP}

Soft floors, also known as soft-floor reserve prices, are commonly used in online advertising; to the best of our knowledge, \citet{zeithammer2019soft} provides the most exhaustive formal analysis to date. 

This pricing mechanism works as follows; we consider the case of equal click-through rates for simplicity. Let $s > 0$ denote the soft-floor, and $b_{(1)}$ and $b_{(2)}$ be the first- and, respectively, second-highest bids. If $b_{(2)} \geq s$, then the price charged is $p = b_{(2)}$, as in a standard second-price auction. If $b_{(1)} \geq s > b_{(2)}$, then $p = s$, as if $s$ was a standard reserve price (``hard floor''). Crucially, if $s > b_{(1)}$, then the high bidder still wins the auction (on the contrary, with a standard reserve price, the seller would keep the object) and $p = b_{(1)}$. 

\citet{zeithammer2019soft} shows that, in a symmetric auction for a single object, bid functions are monotonic. As a consequence, the revenue equivalence theorem \citep{myerson1981optimal} applies\footnote{Intuitively, under different pricing rules, bidding behavior is also different, in a way that exactly offsets differences in the way prices are computed.}, and introducing soft-floors in second-price auctions do not affect either the final allocation or the advertising service's revenues. He then demonstrates by way of examples that, with asymmetric bid distributions, revenues in a second-price auction with a soft-floor can be either higher or lower than in a standard second-price auction.

As noted in \S\ref{sec:intro}, our contribution here is twofold. First, we demonstrate through simulations that, with multi-query targeting, different auction formats---and in particular auctions with a soft floor---\emph{can} yield different revenues, even if bidder types are drawn from the same distribution. Second, restricting attention to single-query auctions, we consider a collection of asymmetric bid distributions that complement those analyzed by \citet{zeithammer2019soft}, and do not allow for analytical equilibrium solutions. For such environments, we demonstrate how a second-price auction with a suitably chosen reserve price yields higher revenue than a soft-floor auction. 

For completeness, we first consider the symmetric, single-query environment of \S\ref{sec:results:textbook} and simulate an auction with a soft-floor equal to $s = 0.5$. Consistently with \citet{zeithammer2019soft}, we find that soft-floors have virtually no impact on revenues.\footnote{Results are as follows (compare with Tables \ref{tab:standard-EXP3IX} and \ref{tab:standard-Hedge}): \texttt{Hedge} with $N=2$ bidders yields average revenues equal to $0.324$ (standard deviation $0.0024$); \texttt{Hedge} with $N=10$ yields $0.834$ ($7e-6$); \texttt{EXP3-IX} with $N=2$ yields $0.377$ ($0.032$); \texttt{EXP3-IX} with $N=10$ yields $0.774$ ($0.0176$).}

Now turn to a multi-query environment, which, as noted, is beyond the scope of \citet{zeithammer2019soft}. Our objective is to demonstrate the \emph{possibility} of raising revenues in symmetric environments through soft floor; to do so, we analyze the following parameterized example.

We assume $N = 3$ bidders, all with the same set of possible types $\mathcal T_1 = \mathcal T_2 = \mathcal T_3 =  \{1,2,3\}$. There are two queries, so $Q = \{1, 2\}$. Values and click-through rates for all bidders are as described in Table \ref{tab:SFRP}. Thus, for example, $V_i(2,1) = 0.25$ and $\mathit{CTR}_i(1, 2) = 0.1$. Both queries are equally likely, and all types are also equally likely. We let $B = \{\frac{i}{20} \: : \: i = 0,\ldots,20\}$ and $T = 1,000,000$.\footnote{We also ran these simulations with higher values of $T$, and similar patterns emerge.}
%
\begin{table}[ht]
\caption{Values and Click-Through Rates for all bidders.}
\vskip 0.1in
\label{tab:SFRP}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$\tau_i$ & $V_i(\tau_i, 1)$ & $\mathit{CTR}_i(\tau_i, 1)$ &  $V_i(\tau_i, 2)$ & $\mathit{CTR}_i(\tau_i, 2)$ \\ \hline
1 & 0.5 & 0.3 & 0.25 & 0.1 \\
2 & 0.25 & 0.1 & 1 & 0.1 \\
3 & 0.25 & 0.1 & 1 & 0.2 \\ \hline
\end{tabular}
\end{table}

Table \ref{tab:SFRP-results-EXP3IX-ming} reports expected revenues per impression (where expectations are taken over search queries, bidder types, and click-through rates) for \verb|EXP3-IX|, averaged over 5 runs. Table \ref{tab:SFRP-results-Hedge-ming} reproduces the results for \verb|Hedge|, with $T = 400,000$.

\begin{table}[ht]
    \caption{Multi-query auctions and soft-floors, \texttt{EXP3-IX} output for $T = 1\mathrm M$, averaged over 5 runs.}
    \vskip 0.1in
    \label{tab:SFRP-results-EXP3IX-ming}
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price &  $0.0830$ & $0.0007$ \\
    Second price & $0.0509$ & $0.0008$ \\ 
    soft-floor $s=0.65$ & $0.0813$ & $0.0007$ \\ \hline
    \end{tabular}
\end{table}

\begin{table}[ht]
    \caption{Multi-query auctions and soft-floors, \texttt{Hedge} output for $T = 400 \mathrm K$, averaged over 5 runs.}
    \vskip 0.1in
    \label{tab:SFRP-results-Hedge-ming}
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price &  $0.0691$ & $0.0016$ \\
    Second price & $0.0857$ & $0.0001$ \\ 
    soft-floor $s=0.65$ & $0.0741$ & $0.0061$ \\ \hline
    \end{tabular}
\end{table}

Our first key finding is that, as anticipated, the three auction formats yield different expected revenues.  Soft-floor reserve prices can impact revenues; thus, our simulations provide some support to this common industry practice. Under \texttt{Hedge}, revenues are higher in soft-floor reserve price auctions than in first-price auctions, but second-price auctions perform best. With \texttt{EXP3-IX}, second-price auctions do not fare as well; the highest revenues come from first-price auctions, with soft-floor pricing behind. 

A second key finding is that \texttt{EXP3-IX} results do not align with \texttt{Hedge} even when run for longer periods. Each panel in Figure \ref{fig:hedge-SP} shows the frequency of bids in the final $40,000$ periods of the learning algorithm, summed over 5 runs, divided by type and targeting clause (i.e., queries actually targeted). The main take-away point is that every type eventually learns to choose a specific targeting clause \emph{and} for the most part also places fairly concentrated bids. 
% Figure environment removed

Now compare with Figure \ref{fig:EXP3IX-SP}, which summarizes predicted bids for bidder 1 under \texttt{EXP3-IX}, with Figure \ref{fig:hedge-SP} above (again we sum over 5 runs and only look at the last $100,000$ periods).

% Figure environment removed

Type 1 occasionally bids on one or both queries, showing little convergence even after one million runs. \texttt{EXP3-IX} requires more experimentation, as it only learns from played actions, while \texttt{Hedge} converges faster but assumes learning about unplayed actions. This supports the idea that leveraging knowledge of the pricing mechanism enhances performance. \texttt{Hedge} outperforms due to its reliance on full reward information. We suggest that incorporating heuristics into \texttt{EXP3-IX} may partially address this imbalance; we leave this to future work.

\subsection{Soft-floor vs standard reserve price with a single query}
\label{sfrp_vs_rp}

We now restrict attention to single-query auctions, and explore the implications of bidder asymmetry. Recall that standard reserve prices in second-price auctions work as follows. Again, let $b_{(1)}$ and $b_{(2)}$ denote the first- and second-highest bids, and assume that click-through rates are the same for all bidders for simplicity. Given a reserve price $r > 0$, if $b_{(2)} \geq r$ then the high bidder receives the slot and pays $b_{(2)}$; if $b_{(1)} \geq r > b_{(2)}$, the high bidder receives the slot but pays $r$ (the reserve provides ``price support''). Finally, if $r > b_{(1)}$, the slot is not sold. As noted above, this is the key difference between standard and soft floors.

A common concern in ad auctions, which motivated the introduction of soft floors, is the possible presence of dominant bidders in a market---bidders whose valuation is substantially higher than that of other bidders. The key question is what is meant by ``substantially higher.'' 

\citet{zeithammer2019soft} considers two qualitatively different parametric illustrations. In the first, one bidder has values drawn from the $[0,1]$, and the other from $[0,M]$, with $M \geq 0$. The latter bidder is the ``stronger'' participant. Crucially, this stronger bidder is only present in the auction with probability $\alpha$. In this case (see Fig. 5 in \citealp{zeithammer2019soft}), a soft floor \emph{may} yield higher revenues than a standard reserve price. The second case is that of a randomly appearing strong bidder, with values drawn from an interval $[L,M]$ with $L \geq 1$, facing one or more ``regular'' bidders with values in $[0,1]$. Here, a closed-form solution is not possible in all cases. Proposition 4 shows that, if the soft floor $s$ is \emph{lower} than the highest bid of the regular bidders in a first-price auction, the auctioneer would obtain higher revenues by using the vale $s$ as standard reserve price. However, the model is analytically intractable if $s$ is above the highest bid of regular bidders in a first-price auction. 

We thus perform a variety of simulations that include such intractable scenarios. In our first experiment, we consider two regular bidders with i.i.d., equally likely values of $0.2, 0.4, 0.6, 0.8$, and $1.0$.

Also, two strong bidders with value 2 participate with i.i.d. probability of 0.5. Consider soft-floors from 0 (which corresponds to a simple second-price auction) to 2 (effectively, a first-price auction with a reserve of 2). For each parameter value, we run 500,000 simulation periods and compute average revenues in the final 50,000 periods. We report the average of the results over 5 repetitions of the simulation. 

We then repeat the entire set of simulations, this time using a standard reserve price rather than a soft-floor reserve price. We consider only the values in the support of the regular biddersâ€™ value distribution, plus $1.8$ and $2.0$: this is because a reserve price of $0.0$ is the same as a soft-floor of $0.0$, and reserve price between $1.2$ and $1.6$ exclude the low bidders, just like a reserve price equal to $1.8$, but provides a lower price support than $1.8$. Therefore, reserve prices strictly between $1.0$ and $1.8$ always yield strictly lower revenue than either $1.8$ or some reserve price between $0$ and $1$; for this reason, we do not include them in our graphs and tables.

The results in Table \ref{tab:sfrp-vs-rp-first} show that, even without optimizing hard floors, there is no benefit to soft-floors, whether high or low; this is true, even considering soft floors that are not covered by the analysis in \citet{zeithammer2019soft}.\footnote{In a first-price auction without a reserve price, no regular bidder would bid above $0.5$. Even with a higher reserve price, no regular bidder would bid above $1.0$. Thus, soft floors above $1.0$ are not covered by the results in \citet{zeithammer2019soft}.} In fact, soft-floors lead to lower revenues than standard reserve prices. One feature of the above parameterization is that, since the stronger bidders have a high valuation and at least one of them appears with high probability $(0.75)$, it is optimal for the seller to  target that bidder only, by fixing a high reserve price of $1.8$. This means that the regular bidders are excluded from participation. This may be undesirable even if it does maximize ad revenues. Yet even without completely shutting the low-valuation bidders out of the market, a moderate standard reserve price ($0.6$ in this case) yields higher revenues than any soft-floor, or no floor.

\begin{table}[h]
\centering
\caption{Ad revenue: soft-floor reserve price (SFRP) vs standard reserve price (RP). We exclude reserve prices between $1.0$ and $1.8$, as they yield lower revenue than reserve prices at $1.8$ or below $1.0$. RP=$0$ is the same as SFRP=$0$.}
\vskip 0.1in
\begin{tabular}{|c|c|c|c|c|}
\hline
Floor & Revenue (SFRP) & Stdev & Revenue (RP) & Stdev \\\hline
0.  & 0.965 & 0.0001  &         &         \\
0.2 & 0.985 & 0.0001  & 0.975   & 0.0002  \\
0.4 & 0.96  & 0.0001  & 0.9894  & 0.0003  \\
0.6 & 0.893 & 0.00006 & 0.9979  & 0.0001  \\
0.8 & 0.84  & 0.162   & 0.991   & 0.0002  \\
1   & 0.766 & 0.001   & 1.0053  & 0.0002  \\
1.2 & 0.836 & 0.056   &         &         \\
1.4 & 0.839 & 0.139   &         &         \\
1.6 & 0.861 & 0.064   &         &         \\
1.8 & 0.813 & 0.045   & 1.3656  & 0.0005  \\
2   & 0.836 & 0.113   & 0.0464  & 0.002   \\
\hline
\end{tabular}
\label{tab:sfrp-vs-rp-first}
\end{table}

\paragraph{Exploring different value distributions}
The caveat is that the preceding results are based on a specific distribution of values for the regular bidders---a uniform distribution. To explore the robustness of the conclusions, we re-run all simulations for a sample of discretized Beta distributions with different parameter values. These are chosen to represent right-skewed, left-skewed, and centered but differently concentrated value distributions. We also re-ran all simulations with standard reserve prices instead of soft-floors, as as in the preceding section.

For each parameterization, the graphs below (Figures \ref{right_skewed}--\ref{left_skewed}) depict the value distribution (left panel) and the corresponding expected revenue for soft-floors between $0$  and $2.2$ (in blue), and standard reserve prices from $0$ to $1.0$, plus $1.8$ and $2.0$ (orange).
The results are qualitatively similar: soft-floors, whether low (in the range of values of the regular bidders) or high (above the highest value of regular bidders) do not lift revenues beyond those in a second-price auction. Furthermore, an optimally chosen reserve price does better than any soft-floor. Finally, even restricting attention to standard reserve prices between $0$ and $1$, one can still extract higher revenues than with a soft-floor. One additional finding is that noise is roughly increasing in the magnitude of the soft-floor, reflecting a more complex auction environment for bidders to learn.
% Appendix \ref{asym_value} reports the actual numerical values as well as the standard deviation of simulated expected returns over 5 runs. 
% Figure environment removed
% 
% Figure environment removed
% 
% Figure environment removed


\subsection{Inferring values and bid shading}
\label{sec:results:bid-shading-prod}

Next, we demonstrate how our approach can be used as a step in an inference procedure aimed at determining the distribution of bidders' values, which is not directly observable, from the observed distribution of bids. In \S\ref{evals}, to validate our approach, we start from randomly generated values, then simulate bids, and use them in an iterative procedure to retrieve values from bid. Then, in  \S\ref{prod}, we leverage our simulator in a production environment. This application involves inferring the bidder's value distributions for two scenarios: low and high traffic shopper queries. We utilize \texttt{Hedge} for the inference procedure, due to the bid dispersion observed with \texttt{EXP3-IX} (\S\ref{sec:results:SFRP}).

\subsubsection{Validation with randomly generated values}
\label{evals}

For expository purposes, to reduce the number of cases to consider, we consider auctions with a single query ($Q = 1$) and set all bidders' click-through rate to 1, though our approach is by no means limited to this case. This implies that types coincide with values for the query. We also assume bidders are symmetric, i.e. their types are drawn from the same distribution.

At a broad level, our analysis proceeds as follows. First, we choose different type (i.e. value) distributions and pricing rules, described below. Second, for each such type distribution and pricing rule, we run our auction simulation to generate bids, and compute the distribution of bids in the last 10\% of the learning periods. Henceforth, we call this the \emph{observed} distribution of bids, because it is a stand-in for bid data one might in principle have access to (whereas values are not directly observable).
Finally, we take as input the observed distribution of bids thus obtained, and infer the value distribution through an iterative procedure. 
We initialize this procedure by setting the \emph{inferred} value distribution equal to the \emph{observed} \underline{bid} distribution. We then run the learning algorithm and derive a \emph{predicted} bid distribution. In computing rewards, we need to select a pricing rule. %As shown below, we report the results for different choices. This reflects the fact that, as noted in the Introduction, ad services do not typically specify the details of their pricing rules.

The next step involves adjusting inferred values for each percentile. To do so, we use the following heuristic. Suppose that, for a given percentile, the currently inferred value is $v$, the observed bid is $b^o$, and the predicted bid is $b^p$. This means that the predicted extent of bid shading (reducing one's bid below one's value) is $\sigma = \frac{b^p}{v}$. We then update $v$ according to
\begin{equation}
\label{eq:inference}
v \leftarrow v + \alpha \left(  \frac{b^o}{\sigma} - v \right).
\end{equation}
Intuitively, a bidder with value $\frac{b^o}{\sigma}$ who bids by applying a shading factor of $\sigma$ will bid exactly $b^o$, the actually observed bid for this quantile. We then adjust the inferred $v$ in the direction of $\frac{b^o}{\sigma}$, but apply a learning rate adjustment $\alpha$ to reduce overshooting. We then use the inferred values thus obtained as input for the next iteration of the inference procedure. To compensate for randomness in the learning algorithm, we average predicted bids over multiple runs.

For the present paper, we generated three possible ``true'' value distributions: uniform on $[0,3]$, ``right-skewed'', and ``left-skewed.'' The latter two are, respectively, a discretized log-normal (with location parameter 0 and scale parameter $0.7$) and its mirror image. We consider the 10th, 25th, 40th, 50th, 60th, 75th and 90th percentiles of these distributions, all of which lie in the interval $[0,3]$, and re-normalize the corresponding probabilities. The resulting probability distributions are provided in Table \ref{tab:values} below.

\begin{table}[ht]
    \caption{``True'' value distributions}
    \vskip 0.1in
    \label{tab:values}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
         $F(\tau)$ & Uniform & Right-Skewed & Left-Skewed \\ \hline
         $10/ 90$ & 0.250 & 0.194 & 0.278 \\
         $25/ 90$ & 0.625 & 0.357 & 1.426 \\
         $40/ 90$ & 1.000 & 0.543 & 1.900 \\
         $50/ 90$ & 1.250 & 0.700 & 2.100 \\
         $60/ 90$ & 1.500 & 0.902 & 2.257 \\
         $75/ 90$ & 1.875 & 1.374 & 2.443 \\
         $90/ 90$ & 2.250 & 2.522 & 2.606 \\ \hline
    \end{tabular}
\end{table}

Furthermore, we considered three possible ``true'' pricing rules: first-price, second-price, and second-price with a soft-floor equal to $1.0$. We emphasize that these choices are arbitrary and only meant to be illustrative.

To implement our inference procedure, we run 100 iterations (stopping early if search has converged) and report the results for the iteration in which the difference between observed and predicted bids was smallest. Also, in each iteration, we average predicted bids over 10 instances.

% % 
% \begin{table}[ht]
% \parbox{0.49\linewidth}{
% \footnotesize
% \caption{MAE of predicted percentiles, Uniform}
% \label{tab:MAE-uniform}
% \centering
% \begin{tabular}{|l|r|r|r|}
% \hline
% {} &  First Price &  Second Price &  softRP\_1.0 \\ \hline
% First Price  &    \textbf{0.078647 }&     0.253015 &    0.235419 \\
% Second Price &    0.260861 &     \textbf{0.005953} &    0.067475 \\
% softRP\_1.0  &    0.206956 &     0.028616 &    \textbf{0.012303} \\ \hline
% \end{tabular}
% }
% %
% \parbox{0.49\linewidth}{
% \footnotesize
% \caption{MAE of predicted percentiles, Right-Skewed}
% \label{tab:MAE-right}
% \centering
% \begin{tabular}{|l|r|r|r|}
% \hline
% {} &  First Price &  Second Price &  softRP\_1.0 \\ \hline
% First Price  &    \textbf{0.062768} &     0.502484 &    0.474484 \\
% Second Price &    0.319719 &     \textbf{0.006436} &    0.110450 \\
% softRP\_1.0  &    0.223529 &     0.097096 &    \textbf{0.039177} \\ \hline
% \end{tabular}
% }
% \medskip
% \centering
% \footnotesize
% \caption{MAE of predicted percentiles, Left- Skewed}
% \label{tab:MAE-left}
% \centering
% \begin{tabular}{|l|r|r|r|}
% \hline
% {} &  First Price &  Second Price &  softRP\_1.0 \\ \hline
% First Price  &  \textbf{0.058486} &   0.137498 &    0.177831 \\
% Second Price &  0.215690 & \textbf{0.009505} &  0.102813 \\
% softRP\_1.0  &  0.173198 &   0.029954  &    \textbf{0.017729} \\ \hline
% \end{tabular}
% \end{table}

\begin{table}[ht]
\caption{MAE of Predicted Percentiles, Uniform}
\label{tab:MAE-uniform}
\vskip 0.1in
\centering
\begin{tabular}{|l|r|r|r|}
\hline
{} &  FirstPrice &  SecondPrice &  softRP\_1.0 \\ \hline
FirstPrice  &    \textbf{0.078647 }&     0.253015 &    0.235419 \\
SecondPrice &    0.260861 &     0.005953 &    \textbf{0.067475} \\
softRP\_1.0  &    0.206956 &     0.028616 &    \textbf{0.012303} \\ \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\caption{MAE of Predicted Percentiles, Right Skewed}
\label{tab:MAE-right}
\vskip 0.1in
\centering
\begin{tabular}{|l|r|r|r|}
\hline
{} &  FirstPrice &  SecondPrice &  softRP\_1.0 \\ \hline
FirstPrice  &    \textbf{0.062768} &     0.502484 &    0.474484 \\
SecondPrice &    0.319719 &     \textbf{0.006436} &    0.110450 \\
softRP\_1.0  &    0.223529 &     0.097096 &    \textbf{0.039177} \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\caption{MAE of Predicted Percentiles, Left Skewed}
\label{tab:MAE-left}
\vskip 0.1in
\centering
\begin{tabular}{|l|r|r|r|}
\hline
{} &  FirstPrice &  SecondPrice &  softRP\_1.0 \\ \hline
FirstPrice  &  \textbf{0.058486} &   0.137498 &    0.177831 \\
SecondPrice &  0.215690 & \textbf{0.009505} &  0.102813 \\
softRP\_1.0  &  0.173198 &   0.029954  &    \textbf{0.017729} \\ \hline
\end{tabular}
\end{table}

Tables \ref{tab:MAE-uniform}, \ref{tab:MAE-right} and \ref{tab:MAE-left} report the Mean Absolute Error (MAE)\footnote{We compute this as the arithmetic average of the absolute difference between predicted and actual value for each quantile.} for different choices of ``true'' value distributions and pricing rules. Each table corresponds to a different ``true'' value distribution. Within each table, each row corresponds to a ``true'' pricing rule, and each column to the pricing rule used in the inference procedure---henceforth, the ``hypothesized'' pricing rule.

The main take-away is that the prediction error is  smallest when the hypothesized pricing rule is  the true one; it is also numerically small (see the diagonal in each table). When there is a pricing mismatch, however, the error is larger. This is a useful consistency check for our learning approach. 

We also conducted an investigation of \emph{bid shading}, assuming that the hypothesized pricing rule is the actual one. Figure \ref{fig:bidshading} 
%and Table \ref{tab:bidshading} report 
summarize
%
the results. Each line of sub-figures in Figure \ref{fig:bidshading} corresponds to a different pricing rule---from top to bottom, first-price, second-price, and a \$1.0 soft-floor. Each column corresponds to a different true value distribution---from left to right, left-skewed, uniform, and right-skewed. The amount of bid shading was computed based on the \emph{inferred} values and \emph{predicted} bids.

The results for first- and second-price auctions are in line with theoretical expectations. Since this is a single-object auction, there is no evidence of bid shading in second-price auctions, but bids in first-price auctions are largely below the corresponding (inferred) values. The key point is that these theoretical predictions are confirmed even though we use inferred rather than true values (the latter being un-observable in reality). 

Furthermore, we find evidence of bid shading in the presence of a soft-floor. This is especially the case for lower values (left tail), which is in accordance with the fact that the soft-floor turns low-\emph{bid} auctions into first-price auctions, and low-\emph{value} bidders are the ones most likely to place low bids. These results demonstrate that our simulation approach is able to infer bid shading even in the presence of complex or ``non-textbook'' pricing rules.

We note that \citet{nekipelov2015econometrics} finds evidence of bid shading in Bing search ad data. The authors analyze the data assuming it comes from a generalized second-price auction. However, current Microsoft documentation does not explicitly indicate the pricing rule.\footnote{See \url{https://help.ads.microsoft.com/\#apex/ads/en/53099/0}.} By way of contrast, our simulation analysis generates ``observed bids''  by using the second-price rule. Correspondingly, we find no bid shading in second-price auctions even using inferred values.
% Figure environment removed

% \begin{table}[H]
% \caption{Average bid shading for different price rules and value distribution, 95\% CI}
% \label{tab:bidshading}
% \centering
% \begin{tabular}{|c|c|c|c|c}
% \cline{1-4}
% \multicolumn{1}{|l|}{}  & \text{Uniform}  & \text{Right-Skewed} & \text{Left-Skewed} &  \\ \cline{1-4}
%  \multirow{2}{*}{\text{First Price}}  & 0.248  & 0.194     & 0.143  &  \\ \cline{2-4}
%  & (0.230,0.265) & (0.176,0.211) & (0.124,0.162)  &  \\ \cline{1-4}
%  \multirow{2}{*}{\text{Second Price}} & 0.011 & 0.010      & 0.010 &  \\ \cline{2-4}
%  & (0.001, 0.020) & (0.002, 0.018)   & (0.002, 0.019)  &  \\ \cline{1-4}
%  \multirow{2}{*}{\text{Soft-floor=1.0}}   & 0.17  & 0.105    & 0.069  &  \\ \cline{2-4}
%  & (0.157, 0.190) & (0.082, 0.127)   & (0.050, 0.089)  &  \\ \cline{1-4}
% \end{tabular}
% \end{table}

\subsubsection{Inferring values in  production environment}
\label{prod}
Finally, we use our approach to infer the distribution of bidders' values from the observed distribution of bids in a production environment. 
% The analysis is based on aggregated bid data for two specific shopper queries in an e-commerce setting. To limit the amount of data, we focused on a specific locale, ad placement, and time window. One query ``record sleeves'' averaged 8 bids per auction, relatively low compared to the other high-traffic query ``iPhone 14 case'', which averaged 23 bids.
The analysis is based on aggregated bid data for two specific shopper queries in an e-commerce setting, one characterized by low traffic and the other by high traffic. The data aggregation process converts all bids into a bid per impression, so we set all click-through rates to 1. Thus, we apply our analysis to a symmetric environment with a single query, unit click-through rates, and two different scenarios, one with a low number of bidders (low traffic) and one with a high number of bidders (high traffic). 
% $N=8$ or $N=23$ bidders.

We normalize all bids to lie in a grid $B$ in the interval $[0,4]$. Specifically, we take $B = \{\frac{i}{10} : i = 0,\ldots,40\}$. We also define the set of types to be quantiles of the given bid distribution, with a step size of $0.1$.
As in the previous  subsection, we initialize our iterative procedure by setting the \emph{inferred} \emph{value} distribution to be the \emph{observed} \underline{bid} distribution, except that now the latter are real data from the noted e-commerce setting. We then apply multiple iterations of the procedure described in \eqref{eq:inference}, with a learning rate adjustment of $\alpha=0.2$. In every inference iteration, since the inferred values are associated with increasing quantiles, we apply a ``flattening'' step to ensure that they are indeed increasing.

Figure \eqref{fig:record-sleeve-prod}  represents the inferred values of bidders for 
% the low-traffic search query, ``record sleeve'',
the low-traffic search query,
under the three pricing rules we analyzed in \S \ref{sec:results:SFRP}: first price, second price, and soft-floor with a reserve price of $\$0.65$. We chose these pricing rules arbitrarily, to demonstrate their impact on the inference process. We used 8 iterations of the inference procedure and 3 runs of the learning algorithm per iteration, each with $T = 500,000$, averaging bids over the last $50,000$ periods.

As anticipated, we observe bid shading in the first price auction, as well as within the lower to middle quantiles in the case of the soft-floor. The second price auction also displays bid shading at lower quantiles. We hypothesize that this deviation from theoretical prediction is due to a lack of learning amongst low-valuation types: players with low valuation win rarely, so the feedback they receive is coarse on most periods and hence insufficient to converge to bidding one's value.\footnote{We observe the same pattern of deviations from truthful bidding for low types in the second-price auction studied in \S \ref{sec:results:textbook}.} Figure \ref{fig:bid-shading-prod} analyzes the 
% high-traffic query, ``iPhone 14 case''. 
high-traffic query. We increased the length of the simulation to $T=800,000$ periods. As observed, even with a large number of bidders,
% (recall that we use $N=23$), 
inferred values converge in a few iterations.\footnote{We used a realistic pricing function, but for confidentiality reasons we are unable to provide details.}

% Figure environment removed
% 
% Figure environment removed


