\section{Empirical Results}
\label{sec:results}

\subsection{Textbook auctions}
\label{sec:results:textbook}

To validate our approach, we first consider a textbook, symmetric auction environment with a single query, so $Q = \{q^*\}$, and $N = 2$ bidders, whose values are uniformly distributed on a grid $B$ in the interval $[0,1]$. Formally, given the grid $B$, for all $i = 1,2$, we let $\mathcal T_i = B$, $V_i(b, q^*) = b$, $\mathit{CTR}_i(b, q^*) = 1$, and $F_i(b) = \frac{1}{|B|}$ for all $b \in B$. Furthermore, we allow all bids $b_i$ on the grid $B$.

In a second-price auction, it is a dominant strategy for every bidder to bid their value. In a first-price auction, with a continuum of values and bids, the unique symmetric Bayesian Nash equilibirum is for each bidder to bid a fraction $\frac12$ of their value. Furthermore, Myerson's revenue equivalence applies, so the expected revenue for the advertising service is the same under both formats, namely $\frac13$. We want to compare these theoretical predictions with the output of our learning algorithms with a fine enough grid $B$, and a long enough horizon $T$.

We choose $B = \{\frac{i}{20} : i = 0,\ldots, 20\}$ and $T = 5,000,000$ for \verb|EXP3-IX|. We also choose the tuning parameters optimally, as described in \citet{lattimore2020bandit} (Theorem 12.1, Chapter 12).  Table \ref{tab:standard-EXP3IX} displays revenues for the advertising service in first- and second-price auctions, averaged over 10 runs of the algorithm.
\vskip -0.1in
\begin{table}[ht]
    \caption{Standard single-item auction, \texttt{EXP3-IX}}
    \label{tab:standard-EXP3IX}
    \vskip 0.1in
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price & $0.3440$ & $0.0012$ \\
    Second price & $0.3330$ & $0.0011$ \\ \hline
    \end{tabular}
    %\vskip -0.in
\end{table}

The key take-away point is that expected revenues are close to the theoretical value $\frac13$ in both auction formats. Also, revenues do not vary much across different runs.


For comparison, Table \ref{tab:standard-Hedge} reports the results for \verb|Hedge|. We choose $T = 400,000$ and $\eta = 0.02$. Again, we averaged over 5 different runs of the algorithm.
\vskip -0.1in
\begin{table}[H]
    \caption{Standard single-item auction, \texttt{Hedge}.}
    \label{tab:standard-Hedge}
    \vskip 0.1in
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price & $0.3221$ & $0.0019$ \\
    Second price & $0.3251$ & $0.0011$ \\ \hline
    \end{tabular}
    \vskip -0.1in
\end{table}

The same qualitative features emerge: the simulation approximates the theoretical results, and there is little variation across runs. However,  \verb|EXP3-IX| required a considerably larger number of learning periods to achieve similar results as \verb|Hedge|.  In addition, \verb|Hedge| tends to \emph{under}estimate revenues, whereas \verb|EXP3-IX| tends to \emph{over}estimate them.\footnote{We conjecture that this is a consequence of the ``optimistic'' nature of reward estimates in \texttt{EXP3-IX}. As discussed in \citet{lattimore2020bandit}, to obtain an unbiased estimate of the reward from the arm chosen at time $t$, one would need to set $\gamma=0$. However, this leads to too little exploration. \texttt{EXP3-IX} trades off a slight upward bias in reward estimates (or downward bias in loss estimates) with better regret bounds. However, we conjecture that this ``optimism'' leads to more aggressive bidding.}

% MW -- T = 200000
% Run 0 Revenues 0.3252375
% Run 1 Revenues 0.32523500000000005
% Run 2 Revenues 0.32671999999999995
% Run 3 Revenues 0.3245625

% EXP3IX -- T = 1000000
% Run 0 Revenues 0.22625800000000004
% Run 1 Revenues 0.22643550000000004
% Run 2 Revenues 0.22428399999999998
% Run 3 Revenues 0.22659899999999994

% EXP3IX -- T = 2000000
% Run 0 Revenues 0.24562325000000007
% Run 1 Revenues 0.24396900000000002
% Run 2 Revenues 0.24532474999999998

% EXP3IX -- T = 5000000
% Run 0 (Ming) Revenues 0.2692366666666667
% Run 1 (Marc) Revenues 0.2656288

% EXP3IX -- T = 10000000
% Run 0 Revenues 0.28256166666666666




\subsection{Soft floors}
\label{sec:results:SFRP}

\citet{zeithammer2019soft} shows that, in a symmetric auction for a single object, bid functions are monotonic. As a consequence, the Revenue Equivalence Theorem applies,\footnote{Intuitively, under different pricing rules, bidding behavior is also different, in a way that exactly offsets differences in the way prices are computed.} and introducing soft floors in second-price auctions do not affect either the final allocation or the advertising service's revenues. He then demonstrates by way of examples that, with asymmetric bid distributions, revenues in a second-price auction with a soft floor can be either higher or lower than in a standard second-price auction.

To illustrate our approach, we now show by example that, with two (or more) queries, soft floors can have an impact on key performance indicators even if the type distributions are symmetric. This suggests a rationale for the use of soft floors in online ad auctions that, differently from the message coming from the received literature, does not depend upon asymmetries among bidders. For concreteness, we analyze the revenues of the ad service, although other metrics (e.g., click-through rates) can be computed as well.

Given a soft floor equal to $s$, the price is determined as follows; we describe the case of equal click-through rates for simplicity. Let $b_{(1)}$ and $b_{(2)}$ be the first- and, respectively, second-highest bids. If $b_{(2)} \geq s$, then $p = b_{(2)}$, as in a standard second-price auction. If $b_{(1)} \geq s > b_{(2)}$, then $p = s$, as if $s$ was a standard reserve price (``hard floor''). Crucially, if $s > b_{(1)}$, then the high bidder still wins the auction (on the contrary, with a standard reserve price, the seller would keep the object) and $p = b_{(1)}$. 

We consider $N = 3$ bidders, all with the same set of possible types $\mathcal T_1 = \mathcal T_2 = \mathcal T_3 =  \{1,2,3\}$. There are two queries, so $Q = \{1, 2\}$. Values and click-through rates for all bidders are as described in Table \ref{tab:SFRP}. Thus, for example, $V_i(2,1) = 0.25$ and $\mathit{CTR}_i(1, 2) = 0.1$. Both queries are equally likely, and all types are also equally likely. To clarify, these parameters are artificial and purposely chosen to illustrate the point.
\vskip -0.15in
\begin{table}[ht]
\caption{Values and Click-Through Rates for all bidders}
\label{tab:SFRP}
\vskip 0.1in
\small
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$\tau_i$ & $V_i(\tau_i, 1)$ & $\mathit{CTR}_i(\tau_i, 1)$ &  $V_i(\tau_i, 2)$ & $\mathit{CTR}_i(\tau_i, 2)$ \\ \hline
1 & 0.5 & 0.3 & 0.25 & 0.1 \\
2 & 0.25 & 0.1 & 1 & 0.1 \\
3 & 0.25 & 0.1 & 1 & 0.2 \\ \hline
\end{tabular}
\vskip -0.03in
\end{table}

We let $B = \{\frac{i}{20} \: : \: i = 0,\ldots,20\}$ and $T = 5,000,000$. Table \ref{tab:SFRP-results-EXP3IX-ming} reports expected revenues per impression (where expectations are taken over search queries, bidder types, and click-through rates) for \verb|EXP3-IX|, averaged over 10 runs.


% \begin{table}[ht]
%     \centering
%     \begin{tabular}{|l|c|c|}
%     \hline
%     Auction format & Mean Revenue & Std. Dev.  \\ \hline
%     First price &  TODO & TODO \\
%     Second price & TODO & TODO \\ 
%     Soft floor $s=0.65$ & TODO & TODO \\ \hline
%     \end{tabular}
%     \caption{Multi-query auctions and soft floors, \texttt{EXP3-IX}}
%     \label{tab:SFRP-results-EXP3IX}
% \end{table}


%MING / SAREH: this \href{https://quip-amazon.com/yaOhAmHhNlb4/Auction-Simulator-UM-Science-Weekly-Demo#temp:C:MUKcbd2348f116f4eb9b172d4b7f}{quip doc} describes the results with multiplicative weights.


% \begin{table}[ht]
%     \centering
%     \begin{tabular}{|l|c|c|}
%     \hline
%     Auction format & Mean Revenue & Std. Dev.  \\ \hline
%     First price &  $0.0699$ & $0.0025$ \\
%     Second price & $0.0849$ & $0.0025$ \\ 
%     Soft floor $s=0.65$ & $0.0739$ & $0.0030$ \\ \hline
%     \end{tabular}
%     \caption{Multi-query auctions and soft floors, \texttt{Hedge}}
%     \label{tab:SFRP-results-Hedge}
% \end{table}

\vskip -0.15in
\begin{table}[ht]
    \caption{Multi-query auctions and soft floors, \texttt{EXP3IX} output for $T = 5 \mathrm M$, averaged over 10 runs.}
    \label{tab:SFRP-results-EXP3IX-ming}
    \vskip 0.1in
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price &  $0.0766$ & $0.0008$ \\
    Second price & $0.0584$ & $0.0006$ \\ 
    Soft floor $s=0.65$ & $0.0777$ & $0.0010$ \\ \hline
    \end{tabular}
    \vskip -0.03in
\end{table}

For comparison, we include results using \verb|Hedge|, with $T = 400,000$.

\vskip -0.1in
\begin{table}[ht]
    \caption{Multi-query auctions and soft floors, \texttt{Hedge} output for $T = 400 \mathrm K$, averaged over 10 runs.}
    \label{tab:SFRP-results-Hedge-ming}
    \vskip 0.1in
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Auction format & Mean Revenue & Std. Dev.  \\ \hline
    First price &  $0.0708$ & $0.0022$ \\
    Second price & $0.0865$ & $0.0008$ \\ 
    Soft floor $s=0.65$ & $0.0748$ & $0.0031$ \\ \hline
    \end{tabular}
    \vskip -0.03in
\end{table}


The first main take-away is that revenue equivalence does not hold: the three formats yield different expected revenues. The second is that, as anticipated, soft-floor reserve prices can indeed affect revenues: as shown in Table \ref{tab:SFRP-results-Hedge-ming}, under \texttt{Hedge}, revenues are higher than in a first-price auction, though a second-price auction performs better still. 

Third, it is informative to look at predicted bids. For definiteness, consider Figure \ref{fig:hedge-SP}, which depicts bidding behavior under generalized second-price rules. 
% Figure environment removed
Each panel in Figure \ref{fig:hedge-SP} shows the distribution of bids in the final periods of the learning algorithm, divided by type and targeting clause (i.e., queries actually targeted). Interestingly, types 2 and 3 choose to target only query 2. This reduces competition for query 1: only type 1 is bidding on it, and unless more than one bidder of type 1 shows up at the auction, the ad slot for query 1 is assigned for a price of zero. Yet, in terms of revenues, this is compensated by the fact that competition is intense for query 2.

The fourth take-away is that there is a significant difference in the revenues and bidding behavior obtained using \texttt{Hedge} and \texttt{EXP3-IX}. In particular, the difference in revenues is especially pronounced under second-price rules. This is reflected in bidding behavior: compare Figure \ref{fig:EXP3IX-SP}, which summarizes predicted bids under \texttt{EXP3-IX}, with Figure \ref{fig:hedge-SP} above.

% Figure environment removed

For instance, type 0 sometimes bids on query 2 only, sometimes on query 1 only, and sometimes on both. Even after 10 million runs, there is little convergence. The algorithm is still experimenting widely.

This confirms the basic trade-off highlighted in Section \ref{sec:learning}. \texttt{EXP3-IX} is more principled, in that it  assumes that bidders only learn the performance of the action (bid and clause) they actually played. However, this comes at the expense of greater experimentation. \texttt{Hedge} makes the less realistic assumption that bidders are able to learn about actions they did not play. However, convergence is faster and predictions are tighter. As discussed in Section \ref{sec:related}, the literature on optimal bidding in online auctions does show that leveraging knowledge of the pricing mechanism can improve performance. We conjecture that  \texttt{Hedge} performs better because it replaces knowledge of the mechanism with full information about rewards. Further, we conjecture that enriching \texttt{EXP3-IX} with  heuristics that apply across a range of pricing mechanisms might strike a balance between these two extremes. This is left to future research. 


\subsection{Inferring values and bid shading}
\label{sec:results:bid-shading}

Next, we demonstrate how our approach can be used as a step in an inference procedure aimed at determining the distribution of bidders' values, which is not directly observable, from the observed distribution of bids. In light of the findings in Section \ref{sec:results:SFRP} concerning the convergence issues with \texttt{EXP3-IX}, we use \texttt{Hedge} throughout this section.

For expository purposes, to reduce the number of cases to consider, we consider auctions with a single query ($Q = 1$) and set all bidders' click-through rate to 1---though our approach is by no means limited to this case. This implies that types coincide with values for the query. We also assume bidders are symmetric---their types are drawn from the same distribution.

At a broad level, our analysis proceeds as follows. First, we choose different type (i.e. value) distributions and pricing rules, described below. Second, for each such type distribution and pricing rule, we run our auction simulation to generate bids, and compute the distribution of bids in the last 10\% of the learning periods. Henceforth, we call this the \emph{observed} distribution of bids, because it is a stand-in for bid data one might in principle have access to (whereas values are not directly observable).

Finally, we take as input the observed distribution of bids thus obtained, and infer the value distribution through an iterative procedure. 

We initialize this procedure by setting the \emph{inferred} value distribution equal to the \emph{observed} \underline{bid} distribution. We then run the learning algorithm and derive a \emph{predicted} bid distribution. In computing rewards, we need to select a pricing rule. As shown below, we report the results for different choices. This reflects the fact that, as noted in the Introduction, ad services do not typically specify the details of their pricing rules.

The next step involves adjusting inferred values for each percentile. To do so, with use the following heuristic. Suppose that, for a given percentile, the currently inferred value is $v$, the observed bid is $b^o$, and the predicted bid is $b^p$. This means that the predicted extent of bid shading (reducing one's bid below one's value) is $\sigma = \frac{b^p}{v}$. We then update $v$ according to
\begin{equation}
\label{eq:inference}
v \leftarrow v + \alpha \left(  \frac{b^o}{\sigma} - v \right).
\end{equation}
Intuitively, a bidder with value $\frac{b^o}{\sigma}$ who bids by applying a shading factor of $\sigma$ will bid exactly $b^o$, the actually observed bid for this quantile. We then adjust the inferred $v$ in the direction of $\frac{b^o}{\sigma}$, but apply a learning rate adjustment $\alpha$ to reduce overshooting.

We then use the inferred values thus obtained as input for the next iteration of the inference procedure, To compensate for randomness in the learning algorithm, we average predicted bids over multiple runs.

For the present paper, we generated three possible ``true'' value distributions: uniform on $[0,3]$, ``right-skewed'' and ``left-skewed.'' The latter two are, respectively, a discretized log-normal (with location parameter 0 and scale parameter $0.7$) and its mirror image. We consider the 10th, 25th, 40th, 50th, 60th, 75th and 90th percentiles of these distributions, all of which lie in the interval $[0,3]$, and re-normalize the corresponding probabilities. The resulting probability distributions are provided in Table \ref{tab:values} below.

\vskip -0.15in
\begin{table}[ht]
    \caption{``True'' value distributions}
    \label{tab:values}
    \vskip 0.1in
    \centering
    \small
    \begin{tabular}{|c|c|c|c|}
        \hline
         $F(\tau)$ & Uniform & Right-Skewed & Left-Skewed \\ \hline
         $10/ 90$ & 0.250 & 0.194 & 0.278 \\
         $25/ 90$ & 0.625 & 0.357 & 1.426 \\
         $40/ 90$ & 1.000 & 0.543 & 1.900 \\
         $50/ 90$ & 1.250 & 0.700 & 2.100 \\
         $60/ 90$ & 1.500 & 0.902 & 2.257 \\
         $75/ 90$ & 1.875 & 1.374 & 2.443 \\
         $90/ 90$ & 2.250 & 2.522 & 2.606 \\ \hline
    \end{tabular}
    %\vskip -0.1in
\end{table}


Furthermore, we considered three possible ``true'' pricing rules: first-price, second-price, and second-price with a soft floor equal to $1.0$. We emphasize that these choices are arbitrary and only meant to be illustrative.

To implement our inference procedure, we run 100 iterations (stop early if search is converged) and report the results for the iteration in which the difference between observed and predicted bids was smallest. Also, in each iteration, we average predicted bids over 10 instances.


%Figures \ref{fig:bid-shading-2020}  and  \ref{fig:bid-shading-2021} display the predicted bids agains the observed bids and the diagonal, which represents truthful bidding. 


% TODO see \href{https://quip-amazon.com/jEmMAwEjwzQ1/SBLowerBidInvestigation#temp:C:PRW339fdc09035fb7b81e578c307}{this quip doc} (TODONOTES COMPLAINS IF I PUT THE LINK IN A COMMENT)

% % Figure environment removed

% % Figure environment removed

%\siniscam{The first take-away will need to be changed/reworded if we use Ming's Bayesian hyperparameter search algorithm --- which sounds cool. Also, in any case, we need to add a measure of fit --- MSE perhaps.}
\vskip -0.1in
\begin{table}[ht]
\caption{MAE of Predicted Percentiles, Uniform}
\label{tab:MAE-uniform}
\vskip 0.1in
\small
\centering
\begin{tabular}{|l|r|r|r|}
\hline
{} &  FirstPrice &  SecondPrice &  softRP\_1.0 \\ \hline
FirstPrice  &    \textbf{0.078647 }&     0.253015 &    0.235419 \\
SecondPrice &    0.260861 &     0.005953 &    \textbf{0.067475} \\
softRP\_1.0  &    0.206956 &     0.028616 &    \textbf{0.012303} \\ \hline
\end{tabular}
\vskip -0.04in
\end{table}

%\vskip -0.085in
\begin{table}[ht]
\caption{MAE of Predicted Percentiles, Right Skewed}
\label{tab:MAE-right}
\vskip 0.1in
\small
\centering
\begin{tabular}{|l|r|r|r|}
\hline
{} &  FirstPrice &  SecondPrice &  softRP\_1.0 \\ \hline
FirstPrice  &    \textbf{0.062768} &     0.502484 &    0.474484 \\
SecondPrice &    0.319719 &     \textbf{0.006436} &    0.110450 \\
softRP\_1.0  &    0.223529 &     0.097096 &    \textbf{0.039177} \\ \hline
\end{tabular}
\vskip -0.1in
\end{table}


%\vskip -0.14in
\begin{table}[H]
\caption{MAE of Predicted Percentiles, Left Skewed}
\label{tab:MAE-left}
\vskip 0.1in
\small
\centering
\begin{tabular}{|l|r|r|r|}
\hline
{} &  FirstPrice &  SecondPrice &  softRP\_1.0 \\ \hline
FirstPrice  &    \textbf{0.058486} &     0.137498 &    0.177831 \\
SecondPrice &    0.215690 &     \textbf{0.009505} &    0.102813 \\
softRP\_1.0  &    0.173198 &     0.029954 &    \textbf{0.017729} \\ \hline
\end{tabular}
%\vskip -0.1in
\end{table}


Tables \ref{tab:MAE-uniform}, \ref{tab:MAE-right} and \ref{tab:MAE-left} report the mean absolute prediction error\footnote{We compute this as the arithmetic average of the absolute difference between predicted and actual value for each quantile.} for different choices of ``true'' value distributions and pricing rules. Each table corresponds to a different ``true'' value distribution. Within each table, each row corresponds to a ``true'' pricing rule, and each column to the pricing rule used in the inference procedure---henceforth, the ``hypothesized'' pricing rule.

The main take-away is that, when the hypothesized pricing rule is actually the true one, the prediction error is generally small: see the diagonal in each table.\footnote{One exception seems to be for first-price auctions under a uniform distribution.} When there is a pricing mismatch, however, the error is larger. This is a useful consistency check for our learning approach. 


We also conducted an investigation of \emph{bid shading}, assuming that the hypothesized pricing rule is the actual one. Figure \ref{fig:bidshading} and Table \ref{tab:bidshading} report the results. Each line of sub-figures in Figure \ref{fig:bidshading} corresponds to a different pricing rule---from top to bottom, first-price, second-price, and a \$1.0 soft floor. Each column corresponds to a different true value distribution---from left to right, left-skewed, uniform, and right-skewed. The amount of bid shading was computed based on the \emph{inferred} values and \emph{predicted} bids.

The results for first- and second-price auctions are in line with theoretical expectations. Since this is a single-object auction, there is no evidence of bid shading in second-price auctions, but bids in first-price auctions are largely below the corresponding (inferred) values. The key point is that these theoretical predictions are confirmed even though we use inferred rather than true values (the latter being unobservable in reality). 

Furthermore, we find evidence of bid shading in the presence of a soft floor. This is especially the case for lower values (left tail), which is in accordance with the fact that the soft floor turns low-\emph{bid} auctions into first-price auctions, and low-\emph{value} bidders are the ones most likely to place low bids. These results demonstrate that our simulation approach is able to infer bid shading even in the presence of complex or ``non-textbook'' pricing rules.

We note that  \citet{nekipelov2015econometrics} finds evidence of bid shading in Bing search ad data. The authors analyze the data assuming it comes from a generalized second-price auction. However, current Microsoft documentation does not explicitly indicate the pricing rule.\footnote{See \url{https://help.ads.microsoft.com/\#apex/ads/en/53099/0}.} By way of contrast, our simulation analysis generates ``observed bids''  by using the second-price rule. Correspondingly, we find no bid shading in second-price auctions even using inferred values.
%
% Figure environment removed

\vskip -0.15in
\begin{table}[h]
\caption{Average Bid Shading for different price rules and value distribution, 95\% CI}
\label{tab:bidshading}
\vskip 0.13in
\centering
\small
\hspace*{-0.1cm}
\begin{tabular}{|c|l|l|l|l}
\cline{1-4}
\multicolumn{1}{|l|}{}                  & Uniform         & Right Skewed       & Left Skewed      &  \\ \cline{1-4}
 \multirow{2}{*}{\textbf{FirstPrice}}  & 0.248        & 0.194          & 0.143         &  \\ \cline{2-4}
                                        & (0.230, 0.265) & (0.176	, 0.211)    & (0.124, 0.162)   &  \\ \cline{1-4}
 \multirow{2}{*}{\textbf{SecondPrice}} & 0.011        & 0.010          & 0.010        &  \\ \cline{2-4}
& (0.001, 0.020) & (0.002, 0.018)   & (0.002, 0.019)  &  \\ \cline{1-4}
 \multirow{2}{*}{\textbf{softRP\_1.0}}   & 0.174       & 0.105          & 0.069         &  \\ \cline{2-4}
    & (0.157, 0.190) & (0.082, 0.127)   & (0.050, 0.089)  &  \\ \cline{1-4}
\end{tabular}
\vskip -0.1in
\end{table}





