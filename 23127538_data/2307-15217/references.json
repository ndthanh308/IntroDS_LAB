{
  "2311-14455": {
    "title": "Universal Jailbreak Backdoors from Poisoned Human Feedback",
    "authors": [
      "Javier Rando",
      "Florian Tramèr"
    ],
    "submission_date": "2023-11-24",
    "semantic_scholar_id": "90de1938a64d117d61b9e7149d2981df49b81433"
  },
  "2311-05553": {
    "title": "Removing RLHF Protections in GPT-4 via Fine-Tuning",
    "authors": [
      "Qiusi Zhan",
      "Richard Fang",
      "R. Bindu",
      "Akul Gupta",
      "Tatsunori Hashimoto",
      "Daniel Kang"
    ],
    "submission_date": "2023-11-09",
    "semantic_scholar_id": "ccae9fcb1f344e56a3f7cb05a4b49a6e658f9dd2"
  },
  "2311-03348": {
    "title": "Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation",
    "authors": [
      "Rusheb Shah",
      "Quentin Feuillade--Montixi",
      "Soroush Pour",
      "Arush Tagade",
      "Stephen Casper",
      "Javier Rando"
    ],
    "submission_date": "2023-11-06",
    "semantic_scholar_id": "bfc0e3e651cd4b715272fe68add8a180a112293c"
  },
  "2310-16048": {
    "title": "AI Alignment and Social Choice: Fundamental Limitations and Policy Implications",
    "authors": [
      "Abhilash Mishra"
    ],
    "submission_date": "2023-10-24",
    "semantic_scholar_id": "0ee1abb960511e689a9001da6780ca382bcafea1"
  },
  "2310-15288": {
    "title": "Active teacher selection for reinforcement learning from human feedback",
    "authors": [
      "Rachel Freedman",
      "Justin Svegliato",
      "Kyle Hollins Wray",
      "Stuart Russell"
    ],
    "submission_date": "2023-10-23",
    "semantic_scholar_id": "1a5c6deab4fc087776c7f382f8df2649bb67319a"
  },
  "2310-11589": {
    "title": "Eliciting Human Preferences with Language Models",
    "authors": [
      "Belinda Z. Li",
      "Alex Tamkin",
      "Noah D. Goodman",
      "Jacob Andreas"
    ],
    "submission_date": "2023-10-17",
    "semantic_scholar_id": "b4ba53eca9c286c8ba4e06f83bf20ee0145af1c0"
  },
  "2310-03693": {
    "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",
    "authors": [
      "Xiangyu Qi",
      "Yi Zeng",
      "Tinghao Xie",
      "Pin-Yu Chen",
      "Ruoxi Jia",
      "Prateek Mittal",
      "Peter Henderson"
    ],
    "submission_date": "2023-10-05",
    "semantic_scholar_id": "0e0e706e13f160e74cac9556f28ab9a358c148d2"
  },
  "2310-02949": {
    "title": "Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models",
    "authors": [
      "Xianjun Yang",
      "Xiao Wang",
      "Qi Zhang",
      "L. Petzold",
      "William Yang Wang",
      "Xun Zhao",
      "Dahua Lin"
    ],
    "submission_date": "2023-10-04",
    "semantic_scholar_id": "84b7c486c56bd3880cb8eb01de9ae90ba3ebdaed"
  },
  "2309-00267": {
    "title": "RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback",
    "authors": [
      "Harrison Lee",
      "Samrat Phatale",
      "Hassan Mansoor",
      "Kellie Lu",
      "Thomas Mesnard",
      "Colton Bishop",
      "Victor Carbune",
      "Abhinav Rastogi"
    ],
    "submission_date": "2023-09-01",
    "semantic_scholar_id": "600ff4c4ae9fc506c86673c5ecce4fa90803e987"
  },
  "2308-15812": {
    "title": "Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models",
    "authors": [
      "Hritik Bansal",
      "John Dang",
      "Aditya Grover"
    ],
    "submission_date": "2023-08-30",
    "semantic_scholar_id": "b931b242f40a032b9ae7dae9d9fc10c6ab90695e"
  },
  "2308-03825": {
    "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",
    "authors": [
      "Xinyue Shen",
      "Zeyuan Chen",
      "M. Backes",
      "Yun Shen",
      "Yang Zhang"
    ],
    "submission_date": "2023-08-07",
    "semantic_scholar_id": "1104d766527dead44a40532e8a89444d9cef5c65"
  },
  "2307-09288": {
    "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
    "authors": [
      "Hugo Touvron",
      "Louis Martin",
      "Kevin R. Stone",
      "Peter Albert",
      "Amjad Almahairi",
      "Yasmine Babaei",
      "Niko-lay Bashlykov",
      "Soumya Batra",
      "Prajjwal Bhargava",
      "Shruti Bhosale",
      "D. Bikel",
      "Lukas Blecher",
      "Cris-tian Cantón Ferrer",
      "Moya Chen",
      "Guillem Cucurull",
      "David Esiobu",
      "Jude Fernandes",
      "J. Fu",
      "Wenyin Fu",
      "Brian Fuller",
      "Cynthia Gao",
      "Vedanuj Goswami",
      "Naman Goyal",
      "A. Hartshorn",
      "Saghar Hosseini",
      "Rui Hou",
      "Hakan Inan",
      "Marcin Kardas",
      "Viktor Kerkez",
      "Madian Khabsa",
      "Isabel M. Kloumann",
      "A. Korenev",
      "Punit Singh Koura",
      "M. Lachaux",
      "Thibaut Lavril",
      "Jenya Lee",
      "Diana Liskovich",
      "Yinghai Lu",
      "Yuning Mao",
      "Xavier Martinet",
      "Todor Mihaylov",
      "Pushkar Mishra",
      "Igor Molybog",
      "Yixin Nie",
      "Andrew Poulton",
      "J. Reizenstein",
      "Rashi Rungta",
      "Kalyan Saladi",
      "A. Schelten",
      "Ruan Silva",
      "Eric Michael Smith",
      "R. Subramanian",
      "Xia Tan",
      "Binh Tang",
      "Ross Taylor",
      "Adina Williams",
      "Jian Xiang Kuan",
      "Puxin Xu",
      "Zhengxu Yan",
      "Iliyan Zarov",
      "Yuchen Zhang",
      "Angela Fan",
      "M. Kambadur",
      "Sharan Narang",
      "Aur'elien Rodriguez",
      "Robert Stojnic",
      "Sergey Edunov",
      "Thomas Scialom"
    ],
    "submission_date": "2023-07-18",
    "semantic_scholar_id": "104b0bb1da562d53cbda87aec79ef6a2827d191a"
  },
  "2307-06333": {
    "title": "Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation",
    "authors": [
      "Andi Peng",
      "Aviv Netanyahu",
      "Mark K. Ho",
      "Tianmin Shu",
      "Andreea Bobu",
      "J. Shah",
      "Pulkit Agrawal"
    ],
    "submission_date": "2023-07-12",
    "semantic_scholar_id": "bd981f0afaf5bb10b3daf80ec98c158e23c16339"
  },
  "2307-05782": {
    "title": "Large Language Models",
    "authors": [
      "Michael R Douglas"
    ],
    "submission_date": "2023-07-11",
    "semantic_scholar_id": "d62c4d00b277e948956b6610ce2644e88fe1577b"
  },
  "2307-03718": {
    "title": "Frontier AI Regulation: Managing Emerging Risks to Public Safety",
    "authors": [
      "Markus Anderljung",
      "Joslyn Barnhart",
      "Anton Korinek",
      "Jade Leung",
      "Cullen O'Keefe",
      "Jess Whittlestone",
      "S. Avin",
      "Miles Brundage",
      "Justin B. Bullock",
      "D. Cass-Beggs",
      "Ben Chang",
      "Tantum Collins",
      "Tim Fist",
      "Gillian K. Hadfield",
      "Alan Hayes",
      "Lewis Ho",
      "Sara Hooker",
      "Eric Horvitz",
      "Noam Kolt",
      "Jonas Schuett",
      "Yonadav Shavit",
      "Divya Siddarth",
      "Robert Trager",
      "Kevin J. Wolf"
    ],
    "submission_date": "2023-07-06",
    "semantic_scholar_id": "494b043fce4da2ecc7f87bc96f7c29a5278cca61"
  },
  "2307-02483": {
    "title": "Jailbroken: How Does LLM Safety Training Fail?",
    "authors": [
      "Alexander Wei",
      "Nika Haghtalab",
      "J. Steinhardt"
    ],
    "submission_date": "2023-07-05",
    "semantic_scholar_id": "929305892d4ddae575a0fc23227a8139f7681632"
  },
  "2306-15447": {
    "title": "Are aligned neural networks adversarially aligned?",
    "authors": [
      "Nicholas Carlini",
      "Milad Nasr",
      "Christopher A. Choquette-Choo",
      "Matthew Jagielski",
      "Irena Gao",
      "Anas Awadalla",
      "Pang Wei Koh",
      "Daphne Ippolito",
      "Katherine Lee",
      "Florian Tramèr",
      "Ludwig Schmidt"
    ],
    "submission_date": "2023-06-26",
    "semantic_scholar_id": "8724579d3f126e753a0451d98ff57b165f722e72"
  },
  "2306-09442": {
    "title": "Explore, Establish, Exploit: Red Teaming Language Models from Scratch",
    "authors": [
      "Stephen Casper",
      "Jason Lin",
      "Joe Kwon",
      "Gatlen Culp",
      "Dylan Hadfield-Menell"
    ],
    "submission_date": "2023-06-16",
    "semantic_scholar_id": "1db819afb3604c4bfd1e5a0cb2ee9ab9dec52642"
  },
  "2306-09995": {
    "title": "Fairness in Preference-based Reinforcement Learning",
    "authors": [
      "Umer Siddique",
      "Abhinav Sinha",
      "Yongcan Cao"
    ],
    "submission_date": "2023-06-16",
    "semantic_scholar_id": "5af0197ebf4f4ba809f66b00ea344551135f061d"
  },
  "2306-08647": {
    "title": "Language to Rewards for Robotic Skill Synthesis",
    "authors": [
      "Wenhao Yu",
      "Nimrod Gileadi",
      "Chuyuan Fu",
      "Sean Kirmani",
      "Kuang-Huei Lee",
      "Montse Gonzalez Arenas",
      "H. Chiang",
      "Tom Erez",
      "Leonard Hasenclever",
      "Jan Humplik",
      "Brian Ichter",
      "Ted Xiao",
      "Peng Xu",
      "Andy Zeng",
      "Tingnan Zhang",
      "N. Heess",
      "Dorsa Sadigh",
      "Jie Tan",
      "Yuval Tassa",
      "F. Xia"
    ],
    "submission_date": "2023-06-14",
    "semantic_scholar_id": "94bcf0390d5acb1b92323bd15cc1dc311314122c"
  },
  "2306-07899": {
    "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks",
    "authors": [
      "Veniamin Veselovsky",
      "Manoel Horta Ribeiro",
      "Robert West"
    ],
    "submission_date": "2023-06-13",
    "semantic_scholar_id": "8834e8f3799ae759ee8a5bb5c8b939cf650b01cd"
  },
  "2306-04488": {
    "title": "Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards",
    "authors": [
      "Alexandre Ramé",
      "Guillaume Couairon",
      "Mustafa Shukor",
      "Corentin Dancette",
      "Jean-Baptiste Gaya",
      "L. Soulier",
      "M. Cord"
    ],
    "submission_date": "2023-06-07",
    "semantic_scholar_id": "0e2f8491b7af5f715c8ac7e3a7fd96494bd417d8"
  },
  "2306-03341": {
    "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model",
    "authors": [
      "Kenneth Li",
      "Oam Patel",
      "Fernanda Vi'egas",
      "H. Pfister",
      "M. Wattenberg"
    ],
    "submission_date": "2023-06-06",
    "semantic_scholar_id": "405f8f5f1c6df1b3343c812832479aad5180b65f"
  },
  "2306-01693": {
    "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training",
    "authors": [
      "Zeqiu Wu",
      "Yushi Hu",
      "Weijia Shi",
      "Nouha Dziri",
      "Alane Suhr",
      "Prithviraj Ammanabrolu",
      "Noah A. Smith",
      "Mari Ostendorf",
      "Hannaneh Hajishirzi"
    ],
    "submission_date": "2023-06-02",
    "semantic_scholar_id": "e2e52461194bc81351da7caa978ac42e9e9549cc"
  },
  "2305-20050": {
    "title": "Let's Verify Step by Step",
    "authors": [
      "H. Lightman",
      "Vineet Kosaraju",
      "Yura Burda",
      "Harrison Edwards",
      "Bowen Baker",
      "Teddy Lee",
      "Jan Leike",
      "John Schulman",
      "I. Sutskever",
      "K. Cobbe"
    ],
    "submission_date": "2023-05-31",
    "semantic_scholar_id": "be8db99310602d66bba64bcf41a572c45816fbfc"
  },
  "2305-18290": {
    "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model",
    "authors": [
      "Rafael Rafailov",
      "Archit Sharma",
      "E. Mitchell",
      "Stefano Ermon",
      "Christopher D. Manning",
      "Chelsea Finn"
    ],
    "submission_date": "2023-05-29",
    "semantic_scholar_id": "0d1c76d45afa012ded7ab741194baf142117c495"
  },
  "2305-17608": {
    "title": "Reward Collapse in Aligning Large Language Models",
    "authors": [
      "Ziang Song",
      "Tianle Cai",
      "Jason D. Lee",
      "Weijie Su"
    ],
    "submission_date": "2023-05-28",
    "semantic_scholar_id": "6fca85024354e3fafa75b767961bee9245263170"
  },
  "2305-17319": {
    "title": "Moral Machine or Tyranny of the Majority?",
    "authors": [
      "Michael Feffer",
      "Hoda Heidari",
      "Zachary Chase Lipton"
    ],
    "submission_date": "2023-05-27",
    "semantic_scholar_id": "d655026a443d3de40ebacf61274e562ec05936ef"
  },
  "2305-16147": {
    "title": "Learning Safety Constraints from Demonstrations with Unknown Rewards",
    "authors": [
      "David Lindner",
      "Xin Chen",
      "Sebastian Tschiatschek",
      "Katja Hofmann",
      "A. Krause"
    ],
    "submission_date": "2023-05-25",
    "semantic_scholar_id": "9e8a32813ba30ffb8691835ef6ec026d79d86138"
  },
  "2305-14710": {
    "title": "Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models",
    "authors": [
      "Jiashu Xu",
      "Mingyu Derek Ma",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "submission_date": "2023-05-24",
    "semantic_scholar_id": "82fe948f18ca0138d035f553286c5e4b712dbdbe"
  },
  "2305-15324": {
    "title": "Model evaluation for extreme risks",
    "authors": [
      "Toby Shevlane",
      "Sebastian Farquhar",
      "Ben Garfinkel",
      "Mary Phuong",
      "Jess Whittlestone",
      "Jade Leung",
      "Daniel Kokotajlo",
      "Nahema Marchal",
      "Markus Anderljung",
      "Noam Kolt",
      "Lewis Ho",
      "Divya Siddarth",
      "S. Avin",
      "W. Hawkins",
      "Been Kim",
      "Iason Gabriel",
      "Vijay Bolina",
      "Jack Clark",
      "Y. Bengio",
      "P. Christiano",
      "A. Dafoe"
    ],
    "submission_date": "2023-05-24",
    "semantic_scholar_id": "65f604325b1403bc835691d905c2cd50bc04a309"
  },
  "2305-14325": {
    "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
    "authors": [
      "Yilun Du",
      "Shuang Li",
      "A. Torralba",
      "J. Tenenbaum",
      "Igor Mordatch"
    ],
    "submission_date": "2023-05-23",
    "semantic_scholar_id": "4780d0a027c5c5a8e01d7cf697f6296880ffc945"
  },
  "2305-13860": {
    "title": "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study",
    "authors": [
      "Yi Liu",
      "Gelei Deng",
      "Zhengzi Xu",
      "Yuekang Li",
      "Yaowen Zheng",
      "Ying Zhang",
      "Lida Zhao",
      "Tianwei Zhang",
      "Yang Liu"
    ],
    "submission_date": "2023-05-23",
    "semantic_scholar_id": "fc50a6202e2f675604543c1ae4ef22ec74f61ad5"
  },
  "2305-13735": {
    "title": "Aligning Large Language Models through Synthetic Feedback",
    "authors": [
      "Sungdong Kim",
      "Sanghwan Bae",
      "Jamin Shin",
      "Soyoung Kang",
      "Donghyun Kwak",
      "Kang Min Yoo",
      "Minjoon Seo"
    ],
    "submission_date": "2023-05-23",
    "semantic_scholar_id": "5b8f0460d408a8688d9ee0cba127c779d3291d99"
  },
  "2305-13534": {
    "title": "How Language Model Hallucinations Can Snowball",
    "authors": [
      "Muru Zhang",
      "Ofir Press",
      "William Merrill",
      "Alisa Liu",
      "Noah A. Smith"
    ],
    "submission_date": "2023-05-22",
    "semantic_scholar_id": "6825ba09383bc758f9a2feaebabe35a6cd4adc4c"
  },
  "2305-11455": {
    "title": "Shattering the Agent-Environment Interface for Fine-Tuning Inclusive Language Models",
    "authors": [
      "Wanqiao Xu",
      "Shi Dong",
      "Dilip Arumugam",
      "Benjamin Van Roy"
    ],
    "submission_date": "2023-05-19",
    "semantic_scholar_id": "f8f6942be75d102a14c6441e0bb31ac7c59235a4"
  },
  "2305-11206": {
    "title": "LIMA: Less Is More for Alignment",
    "authors": [
      "Chunting Zhou",
      "Pengfei Liu",
      "Puxin Xu",
      "Srini Iyer",
      "Jiao Sun",
      "Yuning Mao",
      "Xuezhe Ma",
      "Avia Efrat",
      "Ping Yu",
      "L. Yu",
      "Susan Zhang",
      "Gargi Ghosh",
      "M. Lewis",
      "Luke Zettlemoyer",
      "Omer Levy"
    ],
    "submission_date": "2023-05-18",
    "semantic_scholar_id": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445"
  },
  "2305-08844": {
    "title": "RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs",
    "authors": [
      "Afra Feyza Akyürek",
      "Ekin Akyürek",
      "Aman Madaan",
      "A. Kalyan",
      "Peter Clark",
      "Derry Tanti Wijaya",
      "Niket Tandon"
    ],
    "submission_date": "2023-05-15",
    "semantic_scholar_id": "ebf35cef5c249d90b40043fffa41f8802c27f132"
  },
  "2305-00944": {
    "title": "Poisoning Language Models During Instruction Tuning",
    "authors": [
      "Alexander Wan",
      "Eric Wallace",
      "Sheng Shen",
      "D. Klein"
    ],
    "submission_date": "2023-05-01",
    "semantic_scholar_id": "bf52c9d94fd61fae0d231a7e43d45d673584c282"
  },
  "2304-11082": {
    "title": "Fundamental Limitations of Alignment in Large Language Models",
    "authors": [
      "Yotam Wolf",
      "Noam Wies",
      "Yoav Levine",
      "A. Shashua"
    ],
    "submission_date": "2023-04-19",
    "semantic_scholar_id": "dbac86036cb5ed4dd6bbdda4a8613b163e20ec90"
  },
  "2304-09991": {
    "title": "Supporting Human-AI Collaboration in Auditing LLMs with LLMs",
    "authors": [
      "Charvi Rastogi",
      "Marco Tulio Ribeiro",
      "Nicholas King",
      "Saleema Amershi"
    ],
    "submission_date": "2023-04-19",
    "semantic_scholar_id": "784e03977f16b0b5a00c16523fdbcb9ffcefc545"
  },
  "2304-06767": {
    "title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment",
    "authors": [
      "Hanze Dong",
      "Wei Xiong",
      "Deepanshu Goyal",
      "Rui Pan",
      "Shizhe Diao",
      "Jipeng Zhang",
      "Kashun Shum",
      "T. Zhang"
    ],
    "submission_date": "2023-04-13",
    "semantic_scholar_id": "3ab661db57d924f4ff1706e05ac807873ca00e0a"
  },
  "2304-06528": {
    "title": "Power-seeking can be probable and predictive for trained agents",
    "authors": [
      "Victoria Krakovna",
      "János Kramár"
    ],
    "submission_date": "2023-04-13",
    "semantic_scholar_id": "a7e37c8258069529823491a3d44f76c5b3803483"
  },
  "2304-04914": {
    "title": "Regulatory Markets: The Future of AI Governance",
    "authors": [
      "Gillian K. Hadfield",
      "Jack Clark"
    ],
    "submission_date": "2023-04-11",
    "semantic_scholar_id": "ac1e0e124fbc42db4ec0f5f388d372900928c42a"
  },
  "2304-05197": {
    "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
    "authors": [
      "Haoran Li",
      "Dadi Guo",
      "Wei Fan",
      "Mingshi Xu",
      "Jie Huang",
      "Yangqiu Song"
    ],
    "submission_date": "2023-04-11",
    "semantic_scholar_id": "025ca4c125d6ecabc816a56f160e5c992abc76d9"
  },
  "2304-05302": {
    "title": "RRHF: Rank Responses to Align Language Models with Human Feedback without tears",
    "authors": [
      "Zheng Yuan",
      "Hongyi Yuan",
      "Chuanqi Tan",
      "Wei Wang",
      "Songfang Huang",
      "Feiran Huang"
    ],
    "submission_date": "2023-04-11",
    "semantic_scholar_id": "748698bd4387afd08594e0dc8150c2afa210d9ae"
  },
  "2303-17548": {
    "title": "Whose Opinions Do Language Models Reflect?",
    "authors": [
      "Shibani Santurkar",
      "Esin Durmus",
      "Faisal Ladhak",
      "Cinoo Lee",
      "Percy Liang",
      "Tatsunori Hashimoto"
    ],
    "submission_date": "2023-03-30",
    "semantic_scholar_id": "e38a29f6463f38f43797b128673b9e44d18a991e"
  },
  "2303-17651": {
    "title": "Self-Refine: Iterative Refinement with Self-Feedback",
    "authors": [
      "Aman Madaan",
      "Niket Tandon",
      "Prakhar Gupta",
      "Skyler Hallinan",
      "Luyu Gao",
      "Sarah Wiegreffe",
      "Uri Alon",
      "Nouha Dziri",
      "Shrimai Prabhumoye",
      "Yiming Yang",
      "S. Welleck",
      "Bodhisattwa Prasad Majumder",
      "Shashank Gupta",
      "A. Yazdanbakhsh",
      "Peter Clark"
    ],
    "submission_date": "2023-03-30",
    "semantic_scholar_id": "3aaf6a2cbad5850ad81ab5c163599cb3d523436f"
  },
  "2303-16749": {
    "title": "Improving Code Generation by Training with Natural Language Feedback",
    "authors": [
      "Angelica Chen"
    ],
    "submission_date": "2023-03-28",
    "semantic_scholar_id": "28dafb94a87daa71ad3edf9f04f3c8c32753398b"
  },
  "2303-16755": {
    "title": "Training Language Models with Language Feedback at Scale",
    "authors": [
      "J'er'emy Scheurer",
      "Jon Ander Campos",
      "Tomasz Korbak",
      "Jun Shern Chan",
      "Angelica Chen",
      "Kyunghyun Cho",
      "Ethan Perez"
    ],
    "submission_date": "2023-03-28",
    "semantic_scholar_id": "c11810fa8887b678facea62da4607c4898360308"
  },
  "2303-15056": {
    "title": "ChatGPT outperforms crowd workers for text-annotation tasks",
    "authors": [
      "F. Gilardi",
      "Meysam Alizadeh",
      "M. Kubli"
    ],
    "submission_date": "2023-03-27",
    "semantic_scholar_id": "a9e155fda1d97baa2b8712f580cc61887cc64e9b"
  },
  "2303-11341": {
    "title": "What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring",
    "authors": [
      "Yonadav Shavit"
    ],
    "submission_date": "2023-03-20",
    "semantic_scholar_id": "b9efcc0930946333bbf4dcf59a5c7a06a5c68389"
  },
  "2303-10130": {
    "title": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models",
    "authors": [
      "Tyna Eloundou",
      "Sam Manning",
      "Pamela Mishkin",
      "Daniel Rock"
    ],
    "submission_date": "2023-03-17",
    "semantic_scholar_id": "5501d00310b06e00351295529498cc684187148d"
  },
  "2303-09387": {
    "title": "Characterizing Manipulation from AI Systems",
    "authors": [
      "Micah Carroll",
      "Alan Chan",
      "Hal Ashton",
      "David Krueger"
    ],
    "submission_date": "2023-03-16",
    "semantic_scholar_id": "0057921f8231ef36ac5bb95368e78bc0beb5521c"
  },
  "2303-09001": {
    "title": "Reclaiming the Digital Commons: A Public Data Trust for Training Data",
    "authors": [
      "Alan Chan",
      "Herbie Bradley",
      "Nitarshan Rajkumar"
    ],
    "submission_date": "2023-03-16",
    "semantic_scholar_id": "6b2395ebcdc3f284d30fefe5d9877aa3caa7b53f"
  },
  "2303-06074": {
    "title": "Susceptibility to Influence of Large Language Models",
    "authors": [
      "L. D. Griffin",
      "Bennett Kleinberg",
      "Maximilian Mozes",
      "Kimberly T. Mai",
      "Maria Vau",
      "M. Caldwell",
      "Augustine Marvor-Parker"
    ],
    "submission_date": "2023-03-10",
    "semantic_scholar_id": "ab90169f7213482efff246cc5f5f057351265f18"
  },
  "2303-05453": {
    "title": "Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback",
    "authors": [
      "Hannah Rose Kirk",
      "Bertie Vidgen",
      "Paul Röttger",
      "Scott A. Hale"
    ],
    "submission_date": "2023-03-09",
    "semantic_scholar_id": "e5174aeda1baa67c17f4ac630ae2e44453954cc3"
  },
  "2303-00894": {
    "title": "Active Reward Learning from Multiple Teachers",
    "authors": [
      "Peter Barnett",
      "Rachel Freedman",
      "Justin Svegliato",
      "Stuart J. Russell"
    ],
    "submission_date": "2023-03-02",
    "semantic_scholar_id": "c28af43206867cb5529164e3dd6d9ea8b7cfe7f2"
  },
  "2302-10149": {
    "title": "Poisoning Web-Scale Training Datasets is Practical",
    "authors": [
      "Nicholas Carlini",
      "Matthew Jagielski",
      "Christopher A. Choquette-Choo",
      "Daniel Paleka",
      "Will Pearce",
      "H. Anderson",
      "A. Terzis",
      "Kurt Thomas",
      "Florian Tramèr"
    ],
    "submission_date": "2023-02-20",
    "semantic_scholar_id": "2cf43a61d0937ad25f23eaef7c90253ab799b3c7"
  },
  "2302-10329": {
    "title": "Harms from Increasingly Agentic Algorithmic Systems",
    "authors": [
      "Alan Chan",
      "Rebecca Salganik",
      "Alva Markelius",
      "Chris Pang",
      "Nitarshan Rajkumar",
      "Dmitrii Krasheninnikov",
      "L. Langosco",
      "Zhonghao He",
      "Yawen Duan",
      "Micah Carroll",
      "Michelle Lin",
      "A. Mayhew",
      "Katherine Collins",
      "Maryam Molamohammadi",
      "John Burden",
      "Wanru Zhao",
      "Shalaleh Rismani",
      "Konstantinos Voudouris",
      "Umang Bhatt",
      "Adrian Weller",
      "David Krueger",
      "Tegan Maharaj"
    ],
    "submission_date": "2023-02-20",
    "semantic_scholar_id": "25d4ffc9fb1b320137ea51612ad4fdb1fdfcee19"
  },
  "2302-08500": {
    "title": "Auditing large language models: a three-layered approach",
    "authors": [
      "Jakob Mokander",
      "Jonas Schuett",
      "Hannah Rose Kirk",
      "Luciano Floridi"
    ],
    "submission_date": "2023-02-16",
    "semantic_scholar_id": "22e2f488ecd88bd2adf79092d0d390d8f7b06a0f"
  },
  "2302-08582": {
    "title": "Pretraining Language Models with Human Preferences",
    "authors": [
      "Tomasz Korbak",
      "Kejian Shi",
      "Angelica Chen",
      "Rasika Bhalerao",
      "C. L. Buckley",
      "Jason Phang",
      "Sam Bowman",
      "Ethan Perez"
    ],
    "submission_date": "2023-02-16",
    "semantic_scholar_id": "c5120b546f1bd99df5bd2e2bf44db5c7c46d1545"
  },
  "2302-08215": {
    "title": "Aligning Language Models with Preferences through f-divergence Minimization",
    "authors": [
      "Dongyoung Go",
      "Tomasz Korbak",
      "Germán Kruszewski",
      "Jos Rozen",
      "Nahyeon Ryu",
      "Marc Dymetman"
    ],
    "submission_date": "2023-02-16",
    "semantic_scholar_id": "e8e035f9768a4d4e7fe9a2e167cd93d170407b1b"
  },
  "2302-06503": {
    "title": "Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making",
    "authors": [
      "Luke Guerdan",
      "Amanda Coston",
      "Zhiwei Steven Wu",
      "Kenneth Holstein"
    ],
    "submission_date": "2023-02-13",
    "semantic_scholar_id": "cffb72b4d815461c8122a03f5d9b5b62d80e294b"
  },
  "2302-04782": {
    "title": "CLARE: Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning",
    "authors": [
      "Sheng Yue",
      "Guan Wang",
      "Wei Shao",
      "Zhaofeng Zhang",
      "Sen Lin",
      "Junkai Ren",
      "Junshan Zhang"
    ],
    "submission_date": "2023-02-09",
    "semantic_scholar_id": "47ce36618ea2426b076e62fe4d5bedf86de708c1"
  },
  "2302-00270": {
    "title": "Internally Rewarded Reinforcement Learning",
    "authors": [
      "Mengdi Li",
      "Xufeng Zhao",
      "Jae Hee Lee",
      "C. Weber",
      "Stefan Wermter"
    ],
    "submission_date": "2023-02-01",
    "semantic_scholar_id": "575eb1ac16135bf8a8ebbf5914e2486309b8f073"
  },
  "2301-11270": {
    "title": "Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons",
    "authors": [
      "Banghua Zhu",
      "Jiantao Jiao",
      "Michael I. Jordan"
    ],
    "submission_date": "2023-01-26",
    "semantic_scholar_id": "4f16e5f4793cdf2a184ae9259ea0f0c04b889eb4"
  },
  "2301-04709": {
    "title": "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
    "authors": [
      "Atticus Geiger",
      "D. Ibeling",
      "Amir Zur",
      "Maheep Chaudhary",
      "Sonakshi Chauhan",
      "Jing Huang",
      "Aryaman Arora",
      "Zhengxuan Wu",
      "Noah D. Goodman",
      "Christopher Potts",
      "Thomas F. Icard"
    ],
    "submission_date": "2023-01-11",
    "semantic_scholar_id": "6247d7bb9093b4f6c222c6c224b3df4335d4b8bd"
  },
  "2301-04213": {
    "title": "Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models",
    "authors": [
      "Peter Hase",
      "Mohit Bansal",
      "Been Kim",
      "Asma Ghandeharioun"
    ],
    "submission_date": "2023-01-10",
    "semantic_scholar_id": "9c0a434b240299cec0029a1be93ab263d7ec9963"
  },
  "2301-03652": {
    "title": "On The Fragility of Learned Reward Functions",
    "authors": [
      "Lev McKinney",
      "Yawen Duan",
      "David Krueger",
      "Adam Gleave"
    ],
    "submission_date": "2023-01-09",
    "semantic_scholar_id": "f1e7332a76be8f38091193e6e929d0d653f4867c"
  },
  "2301-01768": {
    "title": "The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation",
    "authors": [
      "Jochen Hartmann",
      "Jasper Schwenzow",
      "Maximilian Witte"
    ],
    "submission_date": "2023-01-05",
    "semantic_scholar_id": "b6f8cffc5da51581aec71d919d010d55e5ac068a"
  },
  "2301-00901": {
    "title": "Towards Modeling and Influencing the Dynamics of Human Learning",
    "authors": [
      "Ran Tian",
      "M. Tomizuka",
      "A. Dragan",
      "Andrea V. Bajcsy"
    ],
    "submission_date": "2023-01-02",
    "semantic_scholar_id": "b42924c654f5284b240c400026249302a48525b4"
  },
  "2212-10420": {
    "title": "Settling the Reward Hypothesis",
    "authors": [
      "Michael Bowling",
      "John D. Martin",
      "David Abel",
      "Will Dabney"
    ],
    "submission_date": "2022-12-20",
    "semantic_scholar_id": "36f167b3652158a50bde6c48f76d6c5663f2811d"
  },
  "2212-09251": {
    "title": "Discovering Language Model Behaviors with Model-Written Evaluations",
    "authors": [
      "Ethan Perez",
      "Sam Ringer",
      "Kamilė Lukošiūtė",
      "Karina Nguyen",
      "Edwin Chen",
      "Scott Heiner",
      "Craig Pettit",
      "Catherine Olsson",
      "Sandipan Kundu",
      "Saurav Kadavath",
      "Andy Jones",
      "Anna Chen",
      "Benjamin Mann",
      "Brian Israel",
      "Bryan Seethor",
      "C. McKinnon",
      "Chris Olah",
      "Daisong Yan",
      "D. Amodei",
      "Dario Amodei",
      "Dawn Drain",
      "Dustin Li",
      "Eli Tran-Johnson",
      "G. Khundadze",
      "John Kernion",
      "J. Landis",
      "Jamie Kerr",
      "J. Mueller",
      "Jeeyoon Hyun",
      "J. Landau",
      "Kamal Ndousse",
      "L. Goldberg",
      "Liane Lovitt",
      "Martin Lucas",
      "M. Sellitto",
      "Miranda Zhang",
      "Neerav Kingsland",
      "Nelson Elhage",
      "Nicholas Joseph",
      "Noem'i Mercado",
      "Nova Dassarma",
      "Oliver Rausch",
      "Robin Larson",
      "Sam McCandlish",
      "Scott Johnston",
      "Shauna Kravec",
      "S. E. Showk",
      "Tamera Lanham",
      "Timothy Telleen-Lawton",
      "Tom B. Brown",
      "T. Henighan",
      "Tristan Hume",
      "Yuntao Bai",
      "Zac Hatfield-Dodds",
      "Jack Clark",
      "Sam Bowman",
      "Amanda Askell",
      "Roger C. Grosse",
      "Danny Hernandez",
      "Deep Ganguli",
      "Evan Hubinger",
      "Nicholas Schiefer",
      "Jared Kaplan"
    ],
    "submission_date": "2022-12-19",
    "semantic_scholar_id": "cef330bacf014d60daabbd489647b2006af130ca"
  },
  "2212-08073": {
    "title": "Constitutional AI: Harmlessness from AI Feedback",
    "authors": [
      "Yuntao Bai",
      "Saurav Kadavath",
      "Sandipan Kundu",
      "Amanda Askell",
      "John Kernion",
      "Andy Jones",
      "A. Chen",
      "Anna Goldie",
      "Azalia Mirhoseini",
      "C. McKinnon",
      "Carol Chen",
      "Catherine Olsson",
      "Chris Olah",
      "Danny Hernandez",
      "Dawn Drain",
      "Deep Ganguli",
      "Dustin Li",
      "Eli Tran-Johnson",
      "E. Perez",
      "Jamie Kerr",
      "J. Mueller",
      "Jeffrey Ladish",
      "J. Landau",
      "Kamal Ndousse",
      "Kamilė Lukošiūtė",
      "Liane Lovitt",
      "M. Sellitto",
      "Nelson Elhage",
      "Nicholas Schiefer",
      "Noem'i Mercado",
      "Nova Dassarma",
      "R. Lasenby",
      "Robin Larson",
      "Sam Ringer",
      "Scott Johnston",
      "Shauna Kravec",
      "S. E. Showk",
      "Stanislav Fort",
      "Tamera Lanham",
      "Timothy Telleen-Lawton",
      "Tom Conerly",
      "T. Henighan",
      "Tristan Hume",
      "Sam Bowman",
      "Zac Hatfield-Dodds",
      "Benjamin Mann",
      "Dario Amodei",
      "Nicholas Joseph",
      "Sam McCandlish",
      "Tom B. Brown",
      "Jared Kaplan"
    ],
    "submission_date": "2022-12-15",
    "semantic_scholar_id": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654"
  },
  "2212-04717": {
    "title": "On the Sensitivity of Reward Inference to Misspecified Human Models",
    "authors": [
      "Joey Hong",
      "K. Bhatia",
      "A. Dragan"
    ],
    "submission_date": "2022-12-09",
    "semantic_scholar_id": "aef62643b561991d7db70ff29b009822065641d8"
  },
  "2212-03201": {
    "title": "Misspecification in Inverse Reinforcement Learning",
    "authors": [
      "Joar Skalse",
      "A. Abate"
    ],
    "submission_date": "2022-12-06",
    "semantic_scholar_id": "aae382fe95b061018f214b1f101c55b6f4ae176b"
  },
  "2212-03363": {
    "title": "Few-Shot Preference Learning for Human-in-the-Loop RL",
    "authors": [
      "Joey Hejna",
      "Dorsa Sadigh"
    ],
    "submission_date": "2022-12-06",
    "semantic_scholar_id": "18d750263f1dfe43374e8791cefa580a511c2098"
  },
  "2211-15006": {
    "title": "Fine-tuning language models to find agreement among humans with diverse preferences",
    "authors": [
      "Michiel A. Bakker",
      "Martin Chadwick",
      "Hannah Sheahan",
      "Michael Henry Tessler",
      "Lucy Campbell-Gillingham",
      "Jan Balaguer",
      "Nat McAleese",
      "Amelia Glaese",
      "John Aslanides",
      "M. Botvinick",
      "C. Summerfield"
    ],
    "submission_date": "2022-11-28",
    "semantic_scholar_id": "de1c7ae2818aa26fc86a0ea8ed70014cffc8b20a"
  },
  "2211-14275": {
    "title": "Solving math word problems with process- and outcome-based feedback",
    "authors": [
      "Jonathan Uesato",
      "Nate Kushman",
      "Ramana Kumar",
      "Francis Song",
      "Noah Siegel",
      "L. Wang",
      "Antonia Creswell",
      "G. Irving",
      "I. Higgins"
    ],
    "submission_date": "2022-11-25",
    "semantic_scholar_id": "6d7b8a478801bd9d21df82d5f33ae6eced90da5e"
  },
  "2211-06519": {
    "title": "The Expertise Problem: Learning from Specialized Feedback",
    "authors": [
      "Oliver Daniels-Koch",
      "Rachel Freedman"
    ],
    "submission_date": "2022-11-12",
    "semantic_scholar_id": "0bec67b22a85cc4344bbbeb837f369afde091288"
  },
  "2211-03622": {
    "title": "Do Users Write More Insecure Code with AI Assistants?",
    "authors": [
      "Neil Perry",
      "Megha Srivastava",
      "Deepak Kumar",
      "D. Boneh"
    ],
    "submission_date": "2022-11-07",
    "semantic_scholar_id": "ce3f027b68dad014a58aa35f52380932c8d0b209"
  },
  "2211-03540": {
    "title": "Measuring Progress on Scalable Oversight for Large Language Models",
    "authors": [
      "Sam Bowman",
      "Jeeyoon Hyun",
      "Ethan Perez",
      "Edwin Chen",
      "Craig Pettit",
      "Scott Heiner",
      "Kamilė Lukošiūtė",
      "Amanda Askell",
      "Andy Jones",
      "Anna Chen",
      "Anna Goldie",
      "Azalia Mirhoseini",
      "C. McKinnon",
      "Chris Olah",
      "D. Amodei",
      "Dario Amodei",
      "Dawn Drain",
      "Dustin Li",
      "Eli Tran-Johnson",
      "John Kernion",
      "Jamie Kerr",
      "J. Mueller",
      "Jeffrey Ladish",
      "J. Landau",
      "Kamal Ndousse",
      "Liane Lovitt",
      "Nelson Elhage",
      "Nicholas Schiefer",
      "Nicholas Joseph",
      "Noem'i Mercado",
      "Nova Dassarma",
      "Robin Larson",
      "Sam McCandlish",
      "S. Kundu",
      "Scott Johnston",
      "Shauna Kravec",
      "S. E. Showk",
      "Stanislav Fort",
      "Timothy Telleen-Lawton",
      "Tom B. Brown",
      "T. Henighan",
      "Tristan Hume",
      "Yuntao Bai",
      "Zac Hatfield-Dodds",
      "Benjamin Mann",
      "Jared Kaplan"
    ],
    "submission_date": "2022-11-04",
    "semantic_scholar_id": "99ca5162211a895a5dfbff9d7e36e21e09ca646e"
  },
  "2210-11416": {
    "title": "Scaling Instruction-Finetuned Language Models",
    "authors": [
      "Hyung Won Chung",
      "Le Hou",
      "S. Longpre",
      "Barret Zoph",
      "Yi Tay",
      "W. Fedus",
      "Eric Li",
      "Xuezhi Wang",
      "Mostafa Dehghani",
      "Siddhartha Brahma",
      "Albert Webson",
      "S. Gu",
      "Zhuyun Dai",
      "Mirac Suzgun",
      "Xinyun Chen",
      "A. Chowdhery",
      "Dasha Valter",
      "Sharan Narang",
      "Gaurav Mishra",
      "Adams Wei Yu",
      "Vincent Zhao",
      "Yanping Huang",
      "Andrew M. Dai",
      "Hongkun Yu",
      "Slav Petrov",
      "Ed H. Chi",
      "J. Dean",
      "Jacob Devlin",
      "Adam Roberts",
      "Denny Zhou",
      "Quoc V. Le",
      "Jason Wei"
    ],
    "submission_date": "2022-10-20",
    "semantic_scholar_id": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1"
  },
  "2210-10760": {
    "title": "Scaling Laws for Reward Model Overoptimization",
    "authors": [
      "Leo Gao",
      "John Schulman",
      "Jacob Hilton"
    ],
    "submission_date": "2022-10-19",
    "semantic_scholar_id": "fb3dc5e20e0a71134ca916f0d6d8d41f01225b4b"
  },
  "2210-10899": {
    "title": "Learning Preferences for Interactive Autonomy",
    "authors": [
      "Erdem Biyik"
    ],
    "submission_date": "2022-10-19",
    "semantic_scholar_id": "8cb42836e1d6945078a17214f2349651bb81de56"
  },
  "2210-07229": {
    "title": "Mass-Editing Memory in a Transformer",
    "authors": [
      "Kevin Meng",
      "Arnab Sen Sharma",
      "A. Andonian",
      "Yonatan Belinkov",
      "David Bau"
    ],
    "submission_date": "2022-10-13",
    "semantic_scholar_id": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413"
  },
  "2210-01790": {
    "title": "Goal Misgeneralization: Why Correct Specifications Aren't Enough For Correct Goals",
    "authors": [
      "Rohin Shah",
      "Vikrant Varma",
      "Ramana Kumar",
      "Mary Phuong",
      "Victoria Krakovna",
      "Jonathan Uesato",
      "Zachary Kenton"
    ],
    "submission_date": "2022-10-04",
    "semantic_scholar_id": "7d6f17706cbcfcca55f08485bcbf8c82e00c9279"
  },
  "2210-01241": {
    "title": "Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization",
    "authors": [
      "Rajkumar Ramamurthy",
      "Prithviraj Ammanabrolu",
      "Kianté Brantley",
      "Jack Hessel",
      "R. Sifa",
      "C. Bauckhage",
      "Hannaneh Hajishirzi",
      "Yejin Choi"
    ],
    "submission_date": "2022-10-03",
    "semantic_scholar_id": "912a39c2e0e4a35747531669cfa952d2c5627729"
  },
  "2209-14375": {
    "title": "Improving alignment of dialogue agents via targeted human judgements",
    "authors": [
      "Amelia Glaese",
      "Nat McAleese",
      "Maja Trkebacz",
      "John Aslanides",
      "Vlad Firoiu",
      "T. Ewalds",
      "Maribeth Rauh",
      "Laura Weidinger",
      "Martin Chadwick",
      "Phoebe Thacker",
      "Lucy Campbell-Gillingham",
      "Jonathan Uesato",
      "Po-Sen Huang",
      "R. Comanescu",
      "Fan Yang",
      "A. See",
      "Sumanth Dathathri",
      "Rory Greig",
      "Charlie Chen",
      "Doug Fritz",
      "Jaume Sanchez Elias",
      "Richard Green",
      "Sovna Mokr'a",
      "Nicholas Fernando",
      "Boxi Wu",
      "Rachel Foley",
      "Susannah Young",
      "Iason Gabriel",
      "William S. Isaac",
      "John F. J. Mellor",
      "D. Hassabis",
      "K. Kavukcuoglu",
      "Lisa Anne Hendricks",
      "G. Irving"
    ],
    "submission_date": "2022-09-28",
    "semantic_scholar_id": "74eae12620bd1c1393e268bddcb6f129a5025166"
  },
  "2209-13085": {
    "title": "Defining and Characterizing Reward Hacking",
    "authors": [
      "Joar Skalse",
      "Nikolaus H. R. Howe",
      "Dmitrii Krasheninnikov",
      "David Krueger"
    ],
    "submission_date": "2022-09-27",
    "semantic_scholar_id": "004357dd9bbf3012c8fe0ccada4da401bf85dfff"
  },
  "2209-00626": {
    "title": "The alignment problem from a deep learning perspective",
    "authors": [
      "Richard Ngo"
    ],
    "submission_date": "2022-08-30",
    "semantic_scholar_id": "eef33138ee3fbef970c74697b46acf60462d690c"
  },
  "2207-13243": {
    "title": "Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks",
    "authors": [
      "Tilman Raukur",
      "A. Ho",
      "Stephen Casper",
      "Dylan Hadfield-Menell"
    ],
    "submission_date": "2022-07-27",
    "semantic_scholar_id": "2c709ef6186bd607494a3344c903552ea500e449"
  },
  "2207-02774": {
    "title": "Local Relighting of Real Scenes",
    "authors": [
      "Audrey Cui",
      "Ali Jahanian",
      "Àgata Lapedriza",
      "A. Torralba",
      "Shahin Mahdizadehaghdam",
      "Rohit Kumar",
      "David Bau"
    ],
    "submission_date": "2022-07-06",
    "semantic_scholar_id": "dadbcb368a71fcb7f6c8f84953a7d59fd29eaf79"
  },
  "2206-13477": {
    "title": "Parametrically Retargetable Decision-Makers Tend To Seek Power",
    "authors": [
      "A. Turner",
      "Prasad Tadepalli"
    ],
    "submission_date": "2022-06-27",
    "semantic_scholar_id": "17ba357eb02b6242bdd3bebae50ead67b4f7b056"
  },
  "2206-13316": {
    "title": "Humans are not Boltzmann Distributions: Challenges and Opportunities for Modelling Human Feedback and Interaction in Reinforcement Learning",
    "authors": [
      "David Lindner",
      "Mennatallah El-Assady"
    ],
    "submission_date": "2022-06-27",
    "semantic_scholar_id": "6fb26101dc28d6972abccd0c4e9b6f7be07d86fe"
  },
  "2206-05802": {
    "title": "Self-critiquing models for assisting human evaluators",
    "authors": [
      "W. Saunders",
      "Catherine Yeh",
      "Jeff Wu",
      "Steven Bills",
      "Ouyang Long",
      "Jonathan Ward",
      "Jan Leike"
    ],
    "submission_date": "2022-06-12",
    "semantic_scholar_id": "29acc890e521f7a6415666ab9eb3432c49b4587a"
  },
  "2206-02231": {
    "title": "Models of human preference for learning reward functions",
    "authors": [
      "W. B. Knox",
      "Stephane Hatgis-Kessell",
      "S. Booth",
      "S. Niekum",
      "P. Stone",
      "A. Allievi"
    ],
    "submission_date": "2022-06-05",
    "semantic_scholar_id": "9f9b61e429e85e37d6df0e3c478a074f7e6cb9fc"
  },
  "2206-11871": {
    "title": "Offline RL for Natural Language Generation with Implicit Language Q Learning",
    "authors": [
      "Charles Burton Snell",
      "Ilya Kostrikov",
      "Yi Su",
      "Mengjiao Yang",
      "S. Levine"
    ],
    "submission_date": "2022-06-05",
    "semantic_scholar_id": "a5cea6716378949a2b73f0401237d29791a6ee6c"
  },
  "2206-00761": {
    "title": "On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting",
    "authors": [
      "Tomasz Korbak",
      "Hady ElSahar",
      "Germán Kruszewski",
      "Marc Dymetman"
    ],
    "submission_date": "2022-06-01",
    "semantic_scholar_id": "1e34c51b52002796fea6f523b9f794f1d75d9ba8"
  },
  "2206-11349": {
    "title": "Prompt Injection: Parameterization of Fixed Inputs",
    "authors": [
      "Eunbi Choi",
      "Yongrae Jo",
      "Joel Jang",
      "Minjoon Seo"
    ],
    "submission_date": "2022-05-31",
    "semantic_scholar_id": "1c475acaa1060c8318a625f24bfd88c12f367516"
  },
  "2205-11930": {
    "title": "The Authenticity Gap in Human Evaluation",
    "authors": [
      "Kawin Ethayarajh",
      "Dan Jurafsky"
    ],
    "submission_date": "2022-05-24",
    "semantic_scholar_id": "20eca4866bb257b8d701bc7c9b19864b7c05bc23"
  },
  "2205-12401": {
    "title": "Reward Uncertainty for Exploration in Preference-based Reinforcement Learning",
    "authors": [
      "Xi-Xi Liang",
      "Katherine Shu",
      "Kimin Lee",
      "P. Abbeel"
    ],
    "submission_date": "2022-05-24",
    "semantic_scholar_id": "cc9f2fd320a279741403c4bfbeb91179803c428c"
  },
  "2205-11275": {
    "title": "RL with KL penalties is better viewed as Bayesian inference",
    "authors": [
      "Tomasz Korbak",
      "Ethan Perez",
      "C. Buckley"
    ],
    "submission_date": "2022-05-23",
    "semantic_scholar_id": "cf18a9f5a334e574f1d1f6ffdd64b6dac11fe9be"
  },
  "2205-01663": {
    "title": "Adversarial Training for High-Stakes Reliability",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Benjamin Weinstein-Raun",
      "D. Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "submission_date": "2022-05-03",
    "semantic_scholar_id": "dffe2aef88a3925b249bfe14dd0f8c7645860d64"
  },
  "2204-14146": {
    "title": "Training Language Models with Language Feedback",
    "authors": [
      "J'er'emy Scheurer",
      "Jon Ander Campos",
      "Jun Shern Chan",
      "Angelica Chen",
      "Kyunghyun Cho",
      "Ethan Perez"
    ],
    "submission_date": "2022-04-29",
    "semantic_scholar_id": "fd7c3c8fbe8cf88bd967ead02738b43081e306a7"
  },
  "2204-11966": {
    "title": "Estimating and Penalizing Induced Preference Shifts in Recommender Systems",
    "authors": [
      "Micah Carroll",
      "Dylan Hadfield-Menell",
      "Stuart J. Russell",
      "A. Dragan"
    ],
    "submission_date": "2022-04-25",
    "semantic_scholar_id": "2cd4a21584555ea4ec3acac58ff647c6a12f820b"
  },
  "2204-10817": {
    "title": "Reward Reports for Reinforcement Learning",
    "authors": [
      "T. Gilbert",
      "Sarah Dean",
      "Nathan Lambert",
      "T. Zick",
      "Aaron J. Snoswell"
    ],
    "submission_date": "2022-04-22",
    "semantic_scholar_id": "4c868a92c615df3859433e28b2441bbce9e65fb3"
  },
  "2204-06601": {
    "title": "Causal Confusion and Reward Misidentification in Preference-Based Reward Learning",
    "authors": [
      "J. Tien",
      "Jerry Zhi-Yang He",
      "Zackory Erickson",
      "A. Dragan",
      "Daniel S. Brown"
    ],
    "submission_date": "2022-04-13",
    "semantic_scholar_id": "6be327602deb674d0e9f3b606f3e6baf733bf266"
  },
  "2204-05862": {
    "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
    "authors": [
      "Yuntao Bai",
      "Andy Jones",
      "Kamal Ndousse",
      "Amanda Askell",
      "Anna Chen",
      "Nova Dassarma",
      "Dawn Drain",
      "Stanislav Fort",
      "Deep Ganguli",
      "T. Henighan",
      "Nicholas Joseph",
      "Saurav Kadavath",
      "John Kernion",
      "Tom Conerly",
      "S. El-Showk",
      "Nelson Elhage",
      "Zac Hatfield-Dodds",
      "Danny Hernandez",
      "Tristan Hume",
      "Scott Johnston",
      "Shauna Kravec",
      "Liane Lovitt",
      "Neel Nanda",
      "Catherine Olsson",
      "Dario Amodei",
      "Tom B. Brown",
      "Jack Clark",
      "Sam McCandlish",
      "Chris Olah",
      "Benjamin Mann",
      "Jared Kaplan"
    ],
    "submission_date": "2022-04-12",
    "semantic_scholar_id": "0286b2736a114198b25fb5553c671c33aed5d477"
  },
  "2204-05186": {
    "title": "Correcting Robot Plans with Natural Language Feedback",
    "authors": [
      "Pratyusha Sharma",
      "Balakumar Sundaralingam",
      "Valts Blukis",
      "Chris Paxton",
      "Tucker Hermans",
      "A. Torralba",
      "Jacob Andreas",
      "D. Fox"
    ],
    "submission_date": "2022-04-11",
    "semantic_scholar_id": "a58b3f2ab75fdbda082e684d027ab4f552b0b5d3"
  },
  "2204-02515": {
    "title": "Inferring Rewards from Language in Context",
    "authors": [
      "Jessy Lin",
      "Daniel Fried",
      "D. Klein",
      "A. Dragan"
    ],
    "submission_date": "2022-04-05",
    "semantic_scholar_id": "c0e8846eb5ce574a6dca3f3a600e82b184339254"
  },
  "2203-07475": {
    "title": "Invariance in Policy Optimisation and Partial Identifiability in Reward Learning",
    "authors": [
      "Joar Skalse",
      "Matthew Farrugia-Roberts",
      "Stuart J. Russell",
      "A. Abate",
      "Adam Gleave"
    ],
    "submission_date": "2022-03-14",
    "semantic_scholar_id": "3ba0be15b292aa4107a4f06da100fd98490c1b39"
  },
  "2203-07472": {
    "title": "Uncertainty Estimation for Language Reward Models",
    "authors": [
      "Adam Gleave",
      "G. Irving"
    ],
    "submission_date": "2022-03-14",
    "semantic_scholar_id": "acbe813244e07f32eb034d6c27547d772a995d1d"
  },
  "2203-02155": {
    "title": "Training language models to follow instructions with human feedback",
    "authors": [
      "Long Ouyang",
      "Jeff Wu",
      "Xu Jiang",
      "Diogo Almeida",
      "Carroll L. Wainwright",
      "Pamela Mishkin",
      "Chong Zhang",
      "Sandhini Agarwal",
      "Katarina Slama",
      "Alex Ray",
      "John Schulman",
      "Jacob Hilton",
      "Fraser Kelton",
      "Luke E. Miller",
      "Maddie Simens",
      "Amanda Askell",
      "Peter Welinder",
      "P. Christiano",
      "Jan Leike",
      "Ryan J. Lowe"
    ],
    "submission_date": "2022-03-04",
    "semantic_scholar_id": "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
  },
  "2202-11812": {
    "title": "Investigations of Performance and Bias in Human-AI Teamwork in Hiring",
    "authors": [
      "Andi Peng",
      "Besmira Nushi",
      "Emre Kıcıman",
      "K. Inkpen",
      "Ece Kamar"
    ],
    "submission_date": "2022-02-21",
    "semantic_scholar_id": "8179b8645596fd931c623db9ca3ed474a64917d0"
  },
  "2202-05262": {
    "title": "Locating and Editing Factual Associations in GPT",
    "authors": [
      "Kevin Meng",
      "David Bau",
      "A. Andonian",
      "Yonatan Belinkov"
    ],
    "submission_date": "2022-02-10",
    "semantic_scholar_id": "996445d847f06e99b0bd259345408a0cf1bce87e"
  },
  "2202-03629": {
    "title": "Survey of Hallucination in Natural Language Generation",
    "authors": [
      "Ziwei Ji",
      "Nayeon Lee",
      "Rita Frieske",
      "Tiezheng Yu",
      "D. Su",
      "Yan Xu",
      "Etsuko Ishii",
      "Yejin Bang",
      "Delong Chen",
      "Wenliang Dai",
      "Andrea Madotto",
      "Pascale Fung"
    ],
    "submission_date": "2022-02-08",
    "semantic_scholar_id": "3def68bd0f856886d34272840a7f81588f2bc082"
  },
  "2202-03286": {
    "title": "Red Teaming Language Models with Language Models",
    "authors": [
      "Ethan Perez",
      "Saffron Huang",
      "Francis Song",
      "Trevor Cai",
      "Roman Ring",
      "John Aslanides",
      "Amelia Glaese",
      "Nat McAleese",
      "G. Irving"
    ],
    "submission_date": "2022-02-07",
    "semantic_scholar_id": "5d49c7401c5f2337c4cc88d243ae39ed659afe64"
  },
  "2202-02950": {
    "title": "Jury Learning: Integrating Dissenting Voices into Machine Learning Models",
    "authors": [
      "Mitchell L. Gordon",
      "Michelle S. Lam",
      "J. Park",
      "Kayur Patel",
      "Jeffrey T. Hancock",
      "Tatsunori Hashimoto",
      "Michael S. Bernstein"
    ],
    "submission_date": "2022-02-07",
    "semantic_scholar_id": "b13a37d0a044b63975a338f5005aca6120bbecf0"
  },
  "2201-10081": {
    "title": "Dynamics-Aware Comparison of Learned Reward Functions",
    "authors": [
      "Blake Wulfe",
      "A. Balakrishna",
      "Logan Ellis",
      "Jean-Pierre Mercat",
      "R. McAllister",
      "Adrien Gaidon"
    ],
    "submission_date": "2022-01-25",
    "semantic_scholar_id": "bd45112d6f1745a6dccf10f4c423ad9331102cde"
  },
  "2201-03544": {
    "title": "The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models",
    "authors": [
      "Alexander Pan",
      "K. Bhatia",
      "J. Steinhardt"
    ],
    "submission_date": "2022-01-10",
    "semantic_scholar_id": "10b9ca173c665e3f2c322c2d5ce9b9d433fe4629"
  },
  "2112-04359": {
    "title": "Ethical and social risks of harm from Language Models",
    "authors": [
      "Laura Weidinger",
      "John F. J. Mellor",
      "Maribeth Rauh",
      "Conor Griffin",
      "Jonathan Uesato",
      "Po-Sen Huang",
      "Myra Cheng",
      "Mia Glaese",
      "Borja Balle",
      "Atoosa Kasirzadeh",
      "Zachary Kenton",
      "S. Brown",
      "W. Hawkins",
      "T. Stepleton",
      "Courtney Biles",
      "Abeba Birhane",
      "Julia Haas",
      "Laura Rimell",
      "Lisa Anne Hendricks",
      "William S. Isaac",
      "Sean Legassick",
      "G. Irving",
      "Iason Gabriel"
    ],
    "submission_date": "2021-12-08",
    "semantic_scholar_id": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf"
  },
  "2112-15422": {
    "title": "Scalar reward is not enough: a response to Silver, Singh, Precup and Sutton (2021)",
    "authors": [
      "P. Vamplew",
      "Benjamin J. Smith",
      "Johan Kallstrom",
      "G. Ramos",
      "Roxana Rădulescu",
      "D. Roijers",
      "Conor F. Hayes",
      "F. Heintz",
      "P. Mannion",
      "Pieter J. K. Libin",
      "Richard Dazeley",
      "Cameron Foale"
    ],
    "submission_date": "2021-11-25",
    "semantic_scholar_id": "443d21148f28d56b8d52a1fbb49971956efed999"
  },
  "2110-14754": {
    "title": "Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality",
    "authors": [
      "Songyuan Zhang",
      "Zhangjie Cao",
      "Dorsa Sadigh",
      "Yanan Sui"
    ],
    "submission_date": "2021-10-27",
    "semantic_scholar_id": "d29dc62d70ff2a55fb5fba503c706c380cc4fd2a"
  },
  "2110-08207": {
    "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
    "authors": [
      "Victor Sanh",
      "Albert Webson",
      "Colin Raffel",
      "Stephen H. Bach",
      "Lintang Sutawika",
      "Zaid Alyafeai",
      "Antoine Chaffin",
      "Arnaud Stiegler",
      "Teven Le Scao",
      "Arun Raja",
      "Manan Dey",
      "M Saiful Bari",
      "Canwen Xu",
      "Urmish Thakker",
      "S. Sharma",
      "Eliza Szczechla",
      "Taewoon Kim",
      "Gunjan Chhablani",
      "Nihal V. Nayak",
      "Debajyoti Datta",
      "Jonathan D. Chang",
      "Mike Tian-Jian Jiang",
      "Han Wang",
      "Matteo Manica",
      "Sheng Shen",
      "Zheng-Xin Yong",
      "Harshit Pandey",
      "Rachel Bawden",
      "Thomas Wang",
      "Trishala Neeraj",
      "Jos Rozen",
      "Abheesht Sharma",
      "Andrea Santilli",
      "Thibault Févry",
      "Jason Alan Fries",
      "R. Teehan",
      "Stella Biderman",
      "Leo Gao",
      "T. Bers",
      "Thomas Wolf",
      "Alexander M. Rush"
    ],
    "submission_date": "2021-10-15",
    "semantic_scholar_id": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca"
  },
  "2110-05719": {
    "title": "Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations",
    "authors": [
      "A. Davani",
      "M. D'iaz",
      "Vinodkumar Prabhakaran"
    ],
    "submission_date": "2021-10-12",
    "semantic_scholar_id": "8b245254996160ff3885c15e0bdb6bc2e5dd01bd"
  },
  "2110-05699": {
    "title": "On Releasing Annotator-Level Labels and Information in Datasets",
    "authors": [
      "Vinodkumar Prabhakaran",
      "A. Davani",
      "M. D'iaz"
    ],
    "submission_date": "2021-10-12",
    "semantic_scholar_id": "766912db878d4ca14680600e982faff44e508a8d"
  },
  "2110-03605": {
    "title": "Robust Feature-Level Adversaries are Interpretability Tools",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Dylan Hadfield-Menell",
      "G. Kreiman"
    ],
    "submission_date": "2021-10-07",
    "semantic_scholar_id": "081f8d70df9d0cb3733c3b118eccb88dd2cfac58"
  },
  "2110-00284": {
    "title": "Learning Reward Functions from Scale Feedback",
    "authors": [
      "Nils Wilde",
      "Erdem Biyik",
      "Dorsa Sadigh",
      "Stephen L. Smith"
    ],
    "submission_date": "2021-10-01",
    "semantic_scholar_id": "b7c00c15485c2589052d014724a117834405ce23"
  },
  "2109-13916": {
    "title": "Unsolved Problems in ML Safety",
    "authors": [
      "Dan Hendrycks",
      "Nicholas Carlini",
      "John Schulman",
      "J. Steinhardt"
    ],
    "submission_date": "2021-09-28",
    "semantic_scholar_id": "05c2e1ee203be217f100d2da05bdcc52004f00b6"
  },
  "2109-12750": {
    "title": "Learning Multimodal Rewards from Rankings",
    "authors": [
      "Vivek Myers",
      "Erdem Biyik",
      "Nima Anari",
      "Dorsa Sadigh"
    ],
    "submission_date": "2021-09-27",
    "semantic_scholar_id": "3fb50a3c764d0a800af529ff9b8e359f59b1fcc2"
  },
  "2109-10862": {
    "title": "Recursively Summarizing Books with Human Feedback",
    "authors": [
      "Jeff Wu",
      "Long Ouyang",
      "Daniel M. Ziegler",
      "Nissan Stiennon",
      "Ryan Lowe",
      "Jan Leike",
      "P. Christiano"
    ],
    "submission_date": "2021-09-22",
    "semantic_scholar_id": "a6fdb277d0a4b09899f802bda3359f5c2021a156"
  },
  "2109-07445": {
    "title": "Challenges in Detoxifying Language Models",
    "authors": [
      "Johannes Welbl",
      "Amelia Glaese",
      "Jonathan Uesato",
      "Sumanth Dathathri",
      "John F. J. Mellor",
      "Lisa Anne Hendricks",
      "Kirsty Anderson",
      "Pushmeet Kohli",
      "Ben Coppin",
      "Po-Sen Huang"
    ],
    "submission_date": "2021-09-15",
    "semantic_scholar_id": "d64e57b9780f30f5b49bf620fdfb8584651b7f85"
  },
  "2109-00157": {
    "title": "A Survey of Exploration Methods in Reinforcement Learning",
    "authors": [
      "Susan Amin",
      "Maziar Gomrokchi",
      "Harsh Satija",
      "H. V. Hoof",
      "Doina Precup"
    ],
    "submission_date": "2021-09-01",
    "semantic_scholar_id": "3be84e24b144541a8cd9030526ef2b8ef2cbfe54"
  },
  "2107-02349": {
    "title": "Physical interaction as communication: Learning robot objectives online from human corrections",
    "authors": [
      "Dylan P. Losey",
      "Andrea V. Bajcsy",
      "M. O'Malley",
      "A. Dragan"
    ],
    "submission_date": "2021-07-06",
    "semantic_scholar_id": "0919c581a273fa7201d5be9d0072d04ac0b1cdd3"
  },
  "2106-10328": {
    "title": "Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets",
    "authors": [
      "Irene Solaiman",
      "Christy Dennison"
    ],
    "submission_date": "2021-06-18",
    "semantic_scholar_id": "d624bc273821c871f899d8256a34be40c09fc3cd"
  },
  "2106-11022": {
    "title": "Hard Choices in Artificial Intelligence",
    "authors": [
      "Roel Dobbe",
      "T. Gilbert",
      "Yonatan Dov Mintz"
    ],
    "submission_date": "2021-06-10",
    "semantic_scholar_id": "d11217e882e54fc3dfe948fa102555f75d0c80bc"
  },
  "2106-05091": {
    "title": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training",
    "authors": [
      "Kimin Lee",
      "Laura M. Smith",
      "P. Abbeel"
    ],
    "submission_date": "2021-06-09",
    "semantic_scholar_id": "45f573f302dc7e77cbc5d1a74ccbac3564bbebc8"
  },
  "2106-04511": {
    "title": "Designing Toxic Content Classification for a Diversity of Perspectives",
    "authors": [
      "Deepak Kumar",
      "Patrick Gage Kelley",
      "Sunny Consolvo",
      "Joshua Mason",
      "Elie Bursztein",
      "Zakir Durumeric",
      "Kurt Thomas",
      "Michael C. Bailey"
    ],
    "submission_date": "2021-06-04",
    "semantic_scholar_id": "bfd34931564c2f09f03108391197436c3a387c15"
  },
  "2105-14111": {
    "title": "Goal Misgeneralization in Deep Reinforcement Learning",
    "authors": [
      "L. Langosco",
      "Jack Koch",
      "Lee D. Sharkey",
      "J. Pfau",
      "David Krueger"
    ],
    "submission_date": "2021-05-28",
    "semantic_scholar_id": "06f5d950699f4e5484786e59177201463cbba254"
  },
  "2105-01850": {
    "title": "Preference learning along multiple criteria: A game-theoretic perspective",
    "authors": [
      "K. Bhatia",
      "A. Pananjady",
      "P. Bartlett",
      "A. Dragan",
      "M. Wainwright"
    ],
    "submission_date": "2021-05-05",
    "semantic_scholar_id": "79032b17f6b7645395dd16cb251699302100eb78"
  },
  "2104-05565": {
    "title": "Survey on reinforcement learning for language processing",
    "authors": [
      "Víctor Uc Cetina",
      "Nicolás Navarro-Guerrero",
      "A. Martín-González",
      "C. Weber",
      "Stefan Wermter"
    ],
    "submission_date": "2021-04-12",
    "semantic_scholar_id": "a0c40c5bf41c7bbb95014132d25f99ac15b2d0d9"
  },
  "2104-00078": {
    "title": "Learning Human Objectives from Sequences of Physical Corrections",
    "authors": [
      "Mengxi Li",
      "Alper Canberk",
      "Dylan P. Losey",
      "Dorsa Sadigh"
    ],
    "submission_date": "2021-03-31",
    "semantic_scholar_id": "1d944b57ca35cf8f3a89841ecee19d3731656c41"
  },
  "2103-14659": {
    "title": "Alignment of Language Agents",
    "authors": [
      "Zachary Kenton",
      "Tom Everitt",
      "Laura Weidinger",
      "Iason Gabriel",
      "Vladimir Mikulik",
      "G. Irving"
    ],
    "submission_date": "2021-03-26",
    "semantic_scholar_id": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea"
  },
  "2102-03896": {
    "title": "Consequences of Misaligned AI",
    "authors": [
      "Simon Zhuang",
      "Dylan Hadfield-Menell"
    ],
    "submission_date": "2021-02-07",
    "semantic_scholar_id": "ad962c10e83c4b0c4857a5813b5ce6726b911837"
  },
  "2101-07691": {
    "title": "Choice Set Misspecification in Reward Inference",
    "authors": [
      "Rachel Freedman",
      "Rohin Shah",
      "A. Dragan"
    ],
    "submission_date": "2021-01-19",
    "semantic_scholar_id": "de599e0fed4795bd63f1d2a81c7607ff19ab618b"
  },
  "2012-11635": {
    "title": "A Distributional Approach to Controlled Text Generation",
    "authors": [
      "Muhammad Khalifa",
      "Hady ElSahar",
      "Marc Dymetman"
    ],
    "submission_date": "2020-12-22",
    "semantic_scholar_id": "07fd366a8ebdefe54cdb57d87c81dcd22de25a91"
  },
  "2012-05862": {
    "title": "Understanding Learned Reward Functions",
    "authors": [
      "Eric J. Michaud",
      "Adam Gleave",
      "Stuart J. Russell"
    ],
    "submission_date": "2020-12-10",
    "semantic_scholar_id": "e4609613a9efb85103424abb0cb15e814464ccd9"
  },
  "2012-07532": {
    "title": "An overview of 11 proposals for building safe advanced AI",
    "authors": [
      "Evan Hubinger"
    ],
    "submission_date": "2020-12-04",
    "semantic_scholar_id": "3d62e6bc0ad0f13370cb2f5144a2c9806e37b9c9"
  },
  "2011-09999": {
    "title": "Inverse Constrained Reinforcement Learning",
    "authors": [
      "Usman Anwar",
      "Shehryar Malik",
      "A. Aghasi",
      "Ali Ahmed"
    ],
    "submission_date": "2020-11-19",
    "semantic_scholar_id": "1b75dc0186ad5a8ddf0cafb0b3494d1c0a7436b9"
  },
  "2010-14603": {
    "title": "Learning to be Safe: Deep RL with a Safety Critic",
    "authors": [
      "K. Srinivasan",
      "Benjamin Eysenbach",
      "Sehoon Ha",
      "Jie Tan",
      "Chelsea Finn"
    ],
    "submission_date": "2020-10-27",
    "semantic_scholar_id": "96055d058984b15a9b83024bb2e07292ee7559f5"
  },
  "2010-07487": {
    "title": "Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI",
    "authors": [
      "Alon Jacovi",
      "Ana Marasović",
      "Tim Miller",
      "Yoav Goldberg"
    ],
    "submission_date": "2020-10-15",
    "semantic_scholar_id": "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9"
  },
  "2010-05418": {
    "title": "Achilles Heels for AGI/ASI via Decision Theoretic Adversaries",
    "authors": [
      "Stephen L. Casper"
    ],
    "submission_date": "2020-10-12",
    "semantic_scholar_id": "a1cf60dcc862cdfcb3a41915fc3751d765596aad"
  },
  "2009-14715": {
    "title": "Learning Rewards from Linguistic Feedback",
    "authors": [
      "T. Sumers",
      "Mark K. Ho",
      "Robert D. Hawkins",
      "Karthik Narasimhan",
      "T. Griffiths"
    ],
    "submission_date": "2020-09-30",
    "semantic_scholar_id": "9c49a2178134517701befea536400c01a1cdefe7"
  },
  "2009-11462": {
    "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models",
    "authors": [
      "Samuel Gehman",
      "Suchin Gururangan",
      "Maarten Sap",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "submission_date": "2020-09-24",
    "semantic_scholar_id": "399e7d8129c60818ee208f236c8dda17e876d21f"
  },
  "2009-09153": {
    "title": "Hidden Incentives for Auto-Induced Distributional Shift",
    "authors": [
      "David Krueger",
      "Tegan Maharaj",
      "Jan Leike"
    ],
    "submission_date": "2020-09-19",
    "semantic_scholar_id": "1f95b66969fc6c4c2efbd80439df7a3801baa1f8"
  },
  "2009-01325": {
    "title": "Learning to summarize from human feedback",
    "authors": [
      "Nisan Stiennon",
      "Long Ouyang",
      "Jeff Wu",
      "Daniel M. Ziegler",
      "Ryan J. Lowe",
      "Chelsea Voss",
      "Alec Radford",
      "Dario Amodei",
      "Paul Christiano"
    ],
    "submission_date": "2020-09-02",
    "semantic_scholar_id": "053b1d7b97eb2c91fc3921d589c160b0923c70b1"
  },
  "2008-06924": {
    "title": "Inverse Reinforcement Learning with Natural Language Goals",
    "authors": [
      "Li Zhou",
      "Kevin Small"
    ],
    "submission_date": "2020-08-16",
    "semantic_scholar_id": "40848d6a0157d04e2d92576abe6923e8a6370108"
  },
  "2008-02840": {
    "title": "Assisted Perception: Optimizing Observations to Communicate State",
    "authors": [
      "S. Reddy",
      "S. Levine",
      "A. Dragan"
    ],
    "submission_date": "2020-08-06",
    "semantic_scholar_id": "a7a8e68befc76e80d8cfa0b033ffc4387b78d6e0"
  },
  "2007-03177": {
    "title": "Modeling and Mitigating Human Annotation Errors to Design Efficient Stream Processing Systems with Human-in-the-loop Machine Learning",
    "authors": [
      "Rahul Pandey",
      "Hemant Purohit",
      "C. Castillo",
      "V. Shalin"
    ],
    "submission_date": "2020-07-07",
    "semantic_scholar_id": "97e304330279b6021cf03f3675153f51eb987da0"
  },
  "2006-14091": {
    "title": "Learning reward functions from diverse sources of human feedback: Optimally integrating demonstrations and preferences",
    "authors": [
      "Erdem Biyik",
      "Dylan P. Losey",
      "Malayandi Palan",
      "Nicholas C. Landolfi",
      "Gleb Shevchuk",
      "Dorsa Sadigh"
    ],
    "submission_date": "2020-06-24",
    "semantic_scholar_id": "e5fc53230b7abced54d83058286dfff7f631289d"
  },
  "2006-13900": {
    "title": "Quantifying Differences in Reward Functions",
    "authors": [
      "Adam Gleave",
      "Michael Dennis",
      "S. Legg",
      "Stuart J. Russell",
      "Jan Leike"
    ],
    "submission_date": "2020-06-24",
    "semantic_scholar_id": "18f44e605082388ffc0a59b895ff70b01cfc0034"
  },
  "2006-04948": {
    "title": "AI Research Considerations for Human Existential Safety (ARCHES)",
    "authors": [
      "Andrew Critch",
      "David Krueger"
    ],
    "submission_date": "2020-05-30",
    "semantic_scholar_id": "a9c46dfd9a24c754a67386e02424ad68b1f4ab3b"
  },
  "2005-02575": {
    "title": "Active preference-based Gaussian process regression for reward learning and optimization",
    "authors": [
      "Erdem Biyik",
      "Nicolas Huynh",
      "Mykel J. Kochenderfer",
      "Dorsa Sadigh"
    ],
    "submission_date": "2020-05-06",
    "semantic_scholar_id": "061bfda5b75e03dcb15ee4e94e841c2aeeaeccbf"
  },
  "2005-01643": {
    "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
    "authors": [
      "S. Levine",
      "Aviral Kumar",
      "G. Tucker",
      "Justin Fu"
    ],
    "submission_date": "2020-05-04",
    "semantic_scholar_id": "5e7bc93622416f14e6948a500278bfbe58cd3890"
  },
  "2004-07450": {
    "title": "Subjectifying objectivity: Delineating tastes in theoretical quantum gravity research",
    "authors": [
      "T. Gilbert",
      "A. Loveridge"
    ],
    "submission_date": "2020-04-16",
    "semantic_scholar_id": "85d1acc4af1fb9cd4ec6e3ad95dbdc14541b10d7"
  },
  "2002-09089": {
    "title": "Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences",
    "authors": [
      "Daniel S. Brown",
      "Russell Coleman",
      "R. Srinivasan",
      "S. Niekum"
    ],
    "submission_date": "2020-02-21",
    "semantic_scholar_id": "658018e556484e3d9c6bcc00c726bf5eb503ef86"
  },
  "2002-00941": {
    "title": "Quantifying Hypothesis Space Misspecification in Learning From Human–Robot Demonstrations and Physical Corrections",
    "authors": [
      "Andreea Bobu",
      "Andrea V. Bajcsy",
      "J. Fisac",
      "Sampada Deglurkar",
      "A. Dragan"
    ],
    "submission_date": "2020-02-03",
    "semantic_scholar_id": "3ae0467efbfdc837686be0c23f5021c8b105a356"
  },
  "2002-04833": {
    "title": "Reward-rational (implicit) choice: A unifying formalism for reward learning",
    "authors": [
      "Hong Jun Jeon",
      "S. Milli",
      "A. Dragan"
    ],
    "submission_date": "2020-02-01",
    "semantic_scholar_id": "1f52deff193c7c3dfc77c48cbdc653c94f093a92"
  },
  "1912-11595": {
    "title": "The Windfall Clause: Distributing the Benefits of AI for the Common Good",
    "authors": [
      "Cullen O'Keefe",
      "P. Cihon",
      "Ben Garfinkel",
      "Carrick Flynn",
      "Jade Leung",
      "A. Dafoe"
    ],
    "submission_date": "2019-12-25",
    "semantic_scholar_id": "ebb734ab78d7e755566c977997e39a3935878b92"
  },
  "1912-01683": {
    "title": "Optimal Policies Tend To Seek Power",
    "authors": [
      "A. Turner",
      "Logan Smith",
      "Rohin Shah",
      "Andrew Critch",
      "Prasad Tadepalli"
    ],
    "submission_date": "2019-12-03",
    "semantic_scholar_id": "46d4452eb041e33f1e58eab64ec8cf5af534b6ff"
  },
  "1910-04365": {
    "title": "Asking Easy Questions: A User-Friendly Approach to Active Reward Learning",
    "authors": [
      "Erdem Biyik",
      "Malayandi Palan",
      "Nicholas C. Landolfi",
      "Dylan P. Losey",
      "Dorsa Sadigh"
    ],
    "submission_date": "2019-10-10",
    "semantic_scholar_id": "8cc77d98ea62a4ad0515e74dcd2635a0d7b338d3"
  },
  "1909-08593": {
    "title": "Fine-Tuning Language Models from Human Preferences",
    "authors": [
      "Daniel M. Ziegler",
      "Nisan Stiennon",
      "Jeff Wu",
      "Tom B. Brown",
      "Alec Radford",
      "Dario Amodei",
      "Paul Christiano",
      "G. Irving"
    ],
    "submission_date": "2019-09-18",
    "semantic_scholar_id": "7a15950dc71079285a4eaf195de5aadd87c41b40"
  },
  "1909-03567": {
    "title": "What You See Is What You Get? The Impact of Representation Criteria on Human Bias in Hiring",
    "authors": [
      "Andi Peng",
      "Besmira Nushi",
      "Emre Kıcıman",
      "K. Quinn",
      "Siddharth Suri",
      "Ece Kamar"
    ],
    "submission_date": "2019-09-08",
    "semantic_scholar_id": "3f97d452bff652847243e29b029e6055ae240e29"
  },
  "1908-04734": {
    "title": "Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective",
    "authors": [
      "Tom Everitt",
      "Marcus Hutter"
    ],
    "submission_date": "2019-08-13",
    "semantic_scholar_id": "6cc143037044cd3ef3a3f194ba0a1b2446854e26"
  },
  "1906-03926": {
    "title": "A Survey of Reinforcement Learning Informed by Natural Language",
    "authors": [
      "Jelena Luketina",
      "Nantas Nardelli",
      "Gregory Farquhar",
      "Jakob N. Foerster",
      "Jacob Andreas",
      "Edward Grefenstette",
      "S. Whiteson",
      "Tim Rocktäschel"
    ],
    "submission_date": "2019-06-10",
    "semantic_scholar_id": "7dc156eb9d84ae8fd521ecac5ccc5b5426a42b50"
  },
  "1905-10615": {
    "title": "Adversarial Policies: Attacking Deep Reinforcement Learning",
    "authors": [
      "Adam Gleave",
      "Michael Dennis",
      "Neel Kant",
      "Cody Wild",
      "S. Levine",
      "Stuart J. Russell"
    ],
    "submission_date": "2019-05-25",
    "semantic_scholar_id": "6ff50528f3d7c72772f8c0e3f8398f9dd8e06575"
  },
  "1906-09624": {
    "title": "On the Feasibility of Learning, Rather than Assuming, Human Biases for Reward Inference",
    "authors": [
      "Rohin Shah",
      "Noah Gundotra",
      "P. Abbeel",
      "A. Dragan"
    ],
    "submission_date": "2019-05-24",
    "semantic_scholar_id": "3771ee5dff0beb52e13428b9f617b7f59a3968da"
  },
  "1904-06387": {
    "title": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations",
    "authors": [
      "Daniel S. Brown",
      "Wonjoon Goo",
      "P. Nagarajan",
      "S. Niekum"
    ],
    "submission_date": "2019-04-12",
    "semantic_scholar_id": "2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d"
  },
  "1903-03877": {
    "title": "Literal or Pedagogic Human? Analyzing Human Model Misspecification in Objective Learning",
    "authors": [
      "S. Milli",
      "A. Dragan"
    ],
    "submission_date": "2019-03-09",
    "semantic_scholar_id": "18786349b4b7cfc628a6813eb09eacca63977dc5"
  },
  "1903-02020": {
    "title": "Using Natural Language for Reward Shaping in Reinforcement Learning",
    "authors": [
      "Prasoon Goyal",
      "S. Niekum",
      "R. Mooney"
    ],
    "submission_date": "2019-03-05",
    "semantic_scholar_id": "0fa1c75a452a046e11e775eb6120051c696d9366"
  },
  "1902-07742": {
    "title": "From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following",
    "authors": [
      "Justin Fu",
      "Anoop Korattikara Balan",
      "S. Levine",
      "S. Guadarrama"
    ],
    "submission_date": "2019-02-20",
    "semantic_scholar_id": "758311575a6385bb15d4f9af8c0e671cb98184b4"
  },
  "1902-04257": {
    "title": "Deep Reinforcement Learning from Policy-Dependent Human Feedback",
    "authors": [
      "Dilip Arumugam",
      "Jun Ki Lee",
      "S. Saskin",
      "M. Littman"
    ],
    "submission_date": "2019-02-12",
    "semantic_scholar_id": "2b46e8f2f2339e4dfbc8c3db33b7a6fb65ee62ad"
  },
  "1901-08654": {
    "title": "The Assistive Multi-Armed Bandit",
    "authors": [
      "Lawrence Chan",
      "Dylan Hadfield-Menell",
      "S. Srinivasa",
      "A. Dragan"
    ],
    "submission_date": "2019-01-24",
    "semantic_scholar_id": "aa9126046f3b2917ca5dbc3a3cda367597928eb8"
  },
  "1811-07871": {
    "title": "Scalable agent alignment via reward modeling: a research direction",
    "authors": [
      "Jan Leike",
      "David Krueger",
      "Tom Everitt",
      "Miljan Martic",
      "Vishal Maini",
      "S. Legg"
    ],
    "submission_date": "2018-11-19",
    "semantic_scholar_id": "c6f913e4baa7f2c85363c0625c87003ad3b3a14c"
  },
  "1811-06521": {
    "title": "Reward learning from human preferences and demonstrations in Atari",
    "authors": [
      "Borja Ibarz",
      "Jan Leike",
      "Tobias Pohlen",
      "G. Irving",
      "S. Legg",
      "Dario Amodei"
    ],
    "submission_date": "2018-11-15",
    "semantic_scholar_id": "3e6cde685fdf321d7edf9319f7b07c01ff79c11a"
  },
  "1810-04303": {
    "title": "Batch Active Preference-Based Learning of Reward Functions",
    "authors": [
      "Erdem Biyik",
      "Dorsa Sadigh"
    ],
    "submission_date": "2018-10-10",
    "semantic_scholar_id": "48692cce7e9e49bab6e012524fbe403edcb22b91"
  },
  "1809-04790": {
    "title": "Adversarial Examples: Opportunities and Challenges",
    "authors": [
      "Jiliang Zhang",
      "Chen Li"
    ],
    "submission_date": "2018-09-13",
    "semantic_scholar_id": "1879d6b29eee6efab8f6217a7a6f47ec04f25b3e"
  },
  "1807-06096": {
    "title": "Safe Reinforcement Learning via Probabilistic Shields",
    "authors": [
      "N. Jansen",
      "Bettina Konighofer",
      "Sebastian Junges",
      "A. Serban",
      "R. Bloem"
    ],
    "submission_date": "2018-07-16",
    "semantic_scholar_id": "4fb1122c9e02b1dce59094dcf78d5af354e3bac7"
  },
  "1805-08010": {
    "title": "Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior",
    "authors": [
      "S. Reddy",
      "A. Dragan",
      "S. Levine"
    ],
    "submission_date": "2018-05-21",
    "semantic_scholar_id": "e58ef68b95d9b03f37991c31ef2363fab8d0a5b4"
  },
  "1805-00899": {
    "title": "AI safety via debate",
    "authors": [
      "G. Irving",
      "P. Christiano",
      "Dario Amodei"
    ],
    "submission_date": "2018-05-02",
    "semantic_scholar_id": "5a5a1d666e4b7b933bc5aafbbadf179bc447ee67"
  },
  "1803-04585": {
    "title": "Categorizing Variants of Goodhart's Law",
    "authors": [
      "David Manheim",
      "Scott Garrabrant"
    ],
    "submission_date": "2018-03-13",
    "semantic_scholar_id": "80939dd8a5cad405053c88ed856c28791bdc0582"
  },
  "1712-05812": {
    "title": "Occam's razor is insufficient to infer the preferences of irrational agents",
    "authors": [
      "S. Armstrong",
      "Sören Mindermann"
    ],
    "submission_date": "2017-12-15",
    "semantic_scholar_id": "cdabff298e9467de9babf0baad04c19789cde44b"
  },
  "1711-02827": {
    "title": "Inverse Reward Design",
    "authors": [
      "Dylan Hadfield-Menell",
      "S. Milli",
      "P. Abbeel",
      "Stuart J. Russell",
      "A. Dragan"
    ],
    "submission_date": "2017-11-08",
    "semantic_scholar_id": "59094d64844ee21e32560fb08db6d53cc3af0c51"
  },
  "1709-06560": {
    "title": "Deep Reinforcement Learning that Matters",
    "authors": [
      "Peter Henderson",
      "Riashat Islam",
      "Philip Bachman",
      "Joelle Pineau",
      "Doina Precup",
      "D. Meger"
    ],
    "submission_date": "2017-09-19",
    "semantic_scholar_id": "33690ff21ef1efb576410e656f2e60c89d0307d6"
  },
  "1709-06692": {
    "title": "A Voting-Based System for Ethical Decision Making",
    "authors": [
      "Ritesh Noothigattu",
      "Snehalkumar `Neil' Gaikwad",
      "E. Awad",
      "Sohan Dsouza",
      "Iyad Rahwan",
      "Pradeep Ravikumar",
      "Ariel D. Procaccia"
    ],
    "submission_date": "2017-09-01",
    "semantic_scholar_id": "13ee78c1a97c5eca44e54062ab70128ad611b257"
  },
  "1707-07402": {
    "title": "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback",
    "authors": [
      "Khanh Nguyen",
      "Hal Daumé",
      "J. Boyd-Graber"
    ],
    "submission_date": "2017-07-01",
    "semantic_scholar_id": "abcbfc9742e8f4825cfc536091fd414e08d03998"
  },
  "1706-03741": {
    "title": "Deep Reinforcement Learning from Human Preferences",
    "authors": [
      "P. Christiano",
      "Jan Leike",
      "Tom B. Brown",
      "Miljan Martic",
      "S. Legg",
      "Dario Amodei"
    ],
    "submission_date": "2017-06-12",
    "semantic_scholar_id": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd"
  },
  "1705-06452": {
    "title": "Delving into adversarial attacks on deep policies",
    "authors": [
      "Jernej Kos",
      "D. Song"
    ],
    "submission_date": "2017-02-16",
    "semantic_scholar_id": "cf8ed2793bc6aec88da5306fe2de560dc0be9b15"
  },
  "1701-06049": {
    "title": "Interactive Learning from Policy-Dependent Human Feedback",
    "authors": [
      "J. MacGlashan",
      "Mark K. Ho",
      "R. Loftin",
      "Bei Peng",
      "Guan Wang",
      "David L. Roberts",
      "Matthew E. Taylor",
      "M. Littman"
    ],
    "submission_date": "2017-01-21",
    "semantic_scholar_id": "630bf4c0b7e5abd276ec38468f490b7d6222f3a2"
  },
  "1610-02136": {
    "title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks",
    "authors": [
      "Dan Hendrycks",
      "Kevin Gimpel"
    ],
    "submission_date": "2016-10-07",
    "semantic_scholar_id": "6ff2a434578ff2746b9283e45abf296887f48a2d"
  },
  "1606-06565": {
    "title": "Concrete Problems in AI Safety",
    "authors": [
      "Dario Amodei",
      "Chris Olah",
      "J. Steinhardt",
      "P. Christiano",
      "John Schulman",
      "Dandelion Mané"
    ],
    "submission_date": "2016-06-21",
    "semantic_scholar_id": "e86f71ca2948d17b003a5f068db1ecb2b77827f7"
  },
  "1606-03137": {
    "title": "Cooperative Inverse Reinforcement Learning",
    "authors": [
      "Dylan Hadfield-Menell",
      "Stuart J. Russell",
      "P. Abbeel",
      "A. Dragan"
    ],
    "submission_date": "2016-06-01",
    "semantic_scholar_id": "1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777"
  },
  "1603-07323": {
    "title": "Learning Mixtures of Plackett-Luce Models",
    "authors": [
      "Zhibing Zhao",
      "P. Piech",
      "Lirong Xia"
    ],
    "submission_date": "2016-03-23",
    "semantic_scholar_id": "4e2d0a6aacd02d1ba409ff421cfc3bf9cad7958f"
  },
  "1205-2618": {
    "title": "BPR: Bayesian Personalized Ranking from Implicit Feedback",
    "authors": [
      "Steffen Rendle",
      "Christoph Freudenthaler",
      "Zeno Gantner",
      "L. Schmidt-Thieme"
    ],
    "submission_date": "2009-06-18",
    "semantic_scholar_id": "db16e908246f32b60a6e0a8e27093aa145fbb1ed"
  }
}