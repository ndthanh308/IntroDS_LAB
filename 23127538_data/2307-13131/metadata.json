{
  "title": "Why Don't You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations",
  "authors": [
    "Yi Han",
    "Matthew Chan",
    "Eric Wengrowski",
    "Zhuohuan Li",
    "Nils Ole Tippenhauer",
    "Mani Srivastava",
    "Saman Zonouz",
    "Luis Garcia"
  ],
  "submission_date": "2023-07-24T21:16:38+00:00",
  "revised_dates": [
    "2023-07-31T00:05:16+00:00"
  ],
  "abstract": "Camera-based autonomous systems that emulate human perception are increasingly being integrated into safety-critical platforms. Consequently, an established body of literature has emerged that explores adversarial attacks targeting the underlying machine learning models. Adapting adversarial attacks to the physical world is desirable for the attacker, as this removes the need to compromise digital systems. However, the real world poses challenges related to the \"survivability\" of adversarial manipulations given environmental noise in perception pipelines and the dynamicity of autonomous systems. In this paper, we take a sensor-first approach. We present EvilEye, a man-in-the-middle perception attack that leverages transparent displays to generate dynamic physical adversarial examples. EvilEye exploits the camera's optics to induce misclassifications under a variety of illumination conditions. To generate dynamic perturbations, we formalize the projection of a digital attack into the physical domain by modeling the transformation function of the captured image through the optical pipeline. Our extensive experiments show that EvilEye's generated adversarial perturbations are much more robust across varying environmental light conditions relative to existing physical perturbation frameworks, achieving a high attack success rate (ASR) while bypassing state-of-the-art physical adversarial detection frameworks. We demonstrate that the dynamic nature of EvilEye enables attackers to adapt adversarial examples across a variety of objects with a significantly higher ASR compared to state-of-the-art physical world attack frameworks. Finally, we discuss mitigation strategies against the EvilEye attack.",
  "categories": [
    "cs.CR",
    "cs.AI"
  ],
  "primary_category": "cs.CR",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13131",
  "pdf_url": null,
  "comment": "15 pages, 11 figures",
  "num_versions": null,
  "size_before_bytes": 34113952,
  "size_after_bytes": 2710884
}