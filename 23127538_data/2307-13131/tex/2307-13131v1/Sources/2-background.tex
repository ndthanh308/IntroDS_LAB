 %The checkmark-style table for comparison with previous works.
 
\begin{table}[t]
	\centering 
	\caption{A comparison of the characteristics of closely related works. \Tdot \  indicates taking this approach,\  \LEFTcircle \ indicates the work could plausibly take this approach, and \ \Twdot \ means that the work does not utilize the approach. OM: Object-Modifying; SM: Sensor-Modifying; SA: Static Attack; DA: Dynamic Attack; OA: Online Attack.}
	\vspace{-0.1in}
	\label{tab:relatedWorks}
	\begin{adjustbox}{max width=0.8\linewidth}
		\setlength{\tabcolsep}{0.36em}
		\begin{tabular}{rcc|cccc}%cccccc}%cccccccccccc}
			\toprule 
			
%			&\rota{Object-Modifying}
%			&\rota{Sensor-Modifying}
%			&\rota{Static Attack}
%			&\rota{Dynamic Attack}
%			&\rota{Real-Time Attack}
%			\tabularnewline
			
			&OM
			&SM
			&SA
			&DA
			&OA
			\tabularnewline
			
			% Eykholt \etal\cite{eykholt2018robust} (2018) & $\Tdot$ & $\Twdot$ & $\Tdot$ & $\Twdot$ & $\Twdot$
			% \tabularnewline
			
			% Athalye \etal\ \cite{athalye2018synthesizing} (2018) & $\Tdot$ & $\Twdot$ & $\Tdot$ & $\Twdot$ &  $\Twdot$ 
			% \tabularnewline
			
			Li \etal\cite{li2019adversarial} (2019) & $\Twdot$ & $\Tdot$ & $\Tdot$ & $\Twdot$ & $\Twdot$ 
			\tabularnewline
			
			Nassi \etal\cite{nassi2020phantom} (2020) & $\Tdot$ & $\Twdot$ & $\Twdot$ & $\Tdot$ & $\LEFTcircle$
			\tabularnewline
			
			Lovisotto \etal\cite{lovisotto2020slap} (2020) & $\Tdot$ & $\Twdot$ & $\Tdot$ & $\LEFTcircle$ & $\Twdot$ 
			\tabularnewline

   			Zolfi \etal\cite{zolfi2021translucent} (2021) & $\Twdot$ & $\Tdot$ & $\Tdot$ & $\Twdot$ & $\Twdot$ 
			\tabularnewline

               Wang \etal\cite{wang2021daedalus} (2021) & $\Tdot$ & $\Twdot$ & $\Tdot$ & $\Twdot$ & $\Twdot$ 
               \tabularnewline

               Wang \etal\cite{wang2021dual} (2021) & $\Tdot$ & $\Twdot$ & $\Tdot$ & $\Twdot$ & $\Twdot$ 
               \tabularnewline

               % Ji \etal\cite{ji2021poltergeist} (2021) & $\Twdot$ & $\Tdot$ & $\Tdot$ & $\Tdot$ & $\LEFTcircle$ 
               % \tabularnewline   

               % Kohler \etal\cite{kohler2021they} (2021) & $\Twdot$ & $\Tdot$ & $\Tdot$ & $\Twdot$ & $\LEFTcircle$ 
               % \tabularnewline  
			
			Jia \etal\cite{jia2022fooling} (2022) & $\Tdot$ & $\Twdot$ & $\Tdot$ & $\LEFTcircle$ & $\Twdot$ 
			\tabularnewline
			

			
			\name (this work) & $\Twdot$ & $\Tdot$ & $\Tdot$ & $\Tdot$ & $\Tdot$ 	      
			
			\tabularnewline
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\vspace{-0.15in}
\end{table}
%\matt{Reformulation of table 1; May need to modify column titles to send the right message. Also, might remove Nassi (very different system \& threat model)}

\section{Preliminaries}
\label{sec:preliminaries}
In this section, we will describe common object perception pipelines in safety-critical, camera-based autonomous systems. 
% and describe the motivating use cases for the rest of the paper. 
We then provide an overview of the different classes of physical AEs presented in Table~\ref{tab:relatedWorks}. Finally, we provide the necessary preliminaries on the transparent display technology used to realize \namenospace. %In particular, \name aims to  We then define our system and attacker model.
% Transition into adversarial example generation --> the physical world is a blackbox



\subsection{Camera-based Object Detection}
%\luis{Add a subsection distinguishing between objectness and classification}
% The sense-to-actuate pipeline for deep learning-enabled, camera-based safety-critical systems such as autonomous vehicles
Deep learning-enabled, camera-based safety-critical systems are typically compartmentalized into perception, planning, and control stages~\cite{pendleton2017perception}. In this paper, we target the perception stage, where a camera captures the light reflecting off scene objects. The camera produces a single frame within a video sequence for a given time interval. Next, the object recognition module behind the optical sensors detects, regionally segments, and classifies the objects within each frame. Finally, the perceived objects are fed into the planning and control stages, which are domain-specific and tied to the underlying applications. Crowd surveillance and analysis~\cite{sreenu2019intelligent} and autonomous navigation~\cite{bagloee2016autonomous} are both examples of such systems. 
% We describe our motivating use case that will serve as the premise for our system and attack models: traffic sign recognition for autonomous driving. %Deep learning-enabled safety-critical systems perception, planning and control pipeline of a vision-based autonomous system is as follows. The optical sensors \eric{optical sensors == cameras?} perceive the scene in front of it containing objects in the form of a frame feed. \eric{how about: ``The light reflecting off scene objects is captured by a camera. For a given time interval, the camera produces a single frame within a video sequence.''} The recognition module behind the optical sensors detect and regionally segment the objects within each frame. The objects within each segment as classified. For example, classifying a detected traffic sign. \eric{this is unclear. be more specific. walk through each of the perception, planning and control pipeline steps for an autonomous vehicle that approaches a stop sign. Name specific algorithms used in each step.} The system makes control actions based on the output of the recognition module. In the traffic sign recognition scenario, one example can be braking in front of a stop sign. \eric{this may be obvious, but we should explicitly define what a `Stop Sign' is.} \eric{we should reference Figure~\ref{fig:setup-diagram} here.}

% \noindent\textbf{Safety-critical use case: autonomous driving.} Level-4 Auto-nomous Driving systems~\cite{bagloee2016autonomous} directly follow the perception, planning, and control pipeline. Implementations are platform-specific and depend on the set of equipped sensors. Generally, the perception module detects objects from a single sensor or fuses information stemming from multiple sensors~\cite{fan2018baidu}. A common attribute of obstacle detection pipelines is a set of sensors that emit signals which reflect off nearby surfaces, such as LIDAR or radar systems. However, vision- or camera-based sensors are required to capture semantic information that transcends geometric shape, such as the color of a traffic light or the text on a street sign. The classification task depends on the camera placement and can range from lane following~\cite{pendleton2017perception} to traffic light detection~\cite{fan2018baidu}. In this paper, we focus on the traffic sign recognition problem~\cite{de2003traffic}: where a vehicle aims to automatically detect and classify traffic signs that dictate the rules of autonomous navigation, e.g., a vehicle should come to a complete stop upon detecting a ``Stop" sign. 

%\matt{todo: no more face, right? (possible discussion point?)}
%\noindent\textbf{Use case \#2: facial recognition for authentication.} Facial recognition is a ubiquitous camera-based biometric authentication technique across a wide range of applications, e.g., mobile device user authentication~\cite{adesuyi2013secure}, virtual classroom authentication~\cite{valera2015review}, or even ``unfamiliar face" recognition for smart-home security cameras~\cite{pierce2019smart}. Researchers developed facial encoding technologies such as FaceNet ~\cite{schroff2015facenet} that robustly extract facial features to facilitate deep learning training for facial recognition. In the case of facial recognition for authentication, the planning and control stages are comprised of the actuation that follows a user being authenticated, e.g., unlocking a smart-home lock~\cite{pawar2018smart}.  
%\noindent\textbf{Deep learning for processing.} 
%\begin{itemize}
%    \item Give a very brief, general overview of how the perception, planning, control pipeline is typically structured.
%    \item Focus on deep learning in this context.
%\end{itemize}

\subsection{Physical Adversarial Examples}  
%\luis{This entire subsection is redundant with our description in the intro. We may want to copy and paste paragraphs 2 and 3 of the intro here (including the table), and then shorten/merge the second and third paragraphs of the introduction, removing the table from the intro as well.}
\begin{comment}
\begin{itemize}
    \item One paragraph introducing them (in the context of Table 1)
    \item Transferring digital attacks to physical space
    \item Targeted vs. untargeted attacks \luis{This could be subpoint of digital attacks}
    \item sensor-based vs object-level attacks
    \item Static vs Dynamic attacks
    \item Detection
\end{itemize}
\end{comment}
A substantial body of research focuses on adversarial examples (AEs) in the digital domain~\cite{wang2019security}. 
% where the adversarial perturbations are applied digitally as mathematical operations between two matrices. 
Recent research has emerged where AEs are crafted in the physical domain to demonstrate the practicality of these attacks in the real world. In order to account for dynamic physical environmental conditions, many existing physical attacks employ Expectation over Transformation (EOT) \cite{athalye2018synthesizing} when generating adversarial perturbations. EOT is a data augmentation technique where data is synthesized using various transformations naturally found in a physical environment, such as varying lighting and camera angle. The adversarial perturbation pipeline highly depends on the placement of the perturbation relative to the victim sensor as well as the target perceived object.

As shown in Table~\ref{tab:relatedWorks}, we categorize physical domain attacks based on the location of the perturbation, i.e., object-level modification (OM) versus sensor-level modification (SM), as well as the dynamicity of the attack, i.e., static attacks (SA) calculated ahead of time versus dynamic attacks (DA) that can change at runtime. Additionally, we distinguish online attacks (OA) that generate dynamic perturbations based on the current context of the attack. %on the sensor)for physical domain attacks can be classified along two axes: object-level to sensor-level attacks, and static to dynamic attacks. 
Early static approaches targeted specific, individual objects~\cite{eykholt2018robust,chen2018shapeshifter,athalye2018synthesizing,thys2019fooling,zhao2019seeing,wu2020making, jia2022fooling, wang2021dual, wang2021daedalus}. These attacks change the appearance of a target object by attaching carefully crafted adversarial ``patches" (e.g., stickers or posters) to the object. However, these static attacks have the disadvantage that the patches cannot be changed once applied.
%A vast body of research has been studying adversarial examples in the digital domain~\cite{wang2019security}, i.e., the adversarial perturbations are applied digitally as mathematical operations between two matrices. However, recent research has emerged where adversarial examples are crafted in the physical domain. As shown in Table~\ref{tab:attack-cats}, existing approaches can be classified along two axes: object-level to sensor-level attacks and static to dynamic attacks. The very early works are static attacks targeting specific, individual objects~\cite{}. These attacks apply carefully crafted adversarial patches \eric{is ``patches'' the best word here?}\yi{The term ``patch'' is used in prior work} (e.g., stickers or posters) to the object. These static attacks have the disadvantage that once applied, the patches cannot be changed. For example, if a stop sign is attacked by one of these adversarial patches, it will be perceived by all the vehicles passing by. \eric{replace ``vehicles'' with ``vehicles and agents''?} This is equivalent to removing the sign or replacing the sign forever. 
% \eric{remove ``basically''. too imprecise} 

More recent efforts focus on enabling dynamic adversarial attacks to increase stealthiness or situational awareness. For example, an adversarial perturbation would only be displayed when a target vehicle is approaching a target street sign. Similarly, different perturbations could be generated for targeting different street signs. Lovisotto et al. \cite{lovisotto2020slap} propose using a projector to cast adversarial perturbations onto the object. Such an attack works well for dynamically generating perturbations for specific objects, like a stop sign at a particular intersection. Recent attacks also proposed sensor-first approaches. Instead of altering objects in a scene, they focus on what the optical sensor perceives. In the work of Li et al.~\cite{li2019adversarial} and Zolfi et al.~\cite{zolfi2021translucent}, an adversary prints adversarial perturbations on a transparent paper and attaches the paper to a victim's camera. In this way, the adversarial perturbation follows the victim camera continuously. However, the sticker perturbations are static and do not have the advantages of stealthiness and situational awareness associated with dynamic attacks. In this paper, we aim to bridge the gap between both approaches by proposing a dynamic, sensor-first attack framework. We now describe the transparent mediums that enable such a framework.

%However, an adversary might want to target a specific vehicle. It would also require extra efforts to attack multiple objects. \eric{unnatural flow between the preceding 2 sentences: ``However...'' and ``Moreover...''. Too many sentence qualifiers are used in general throughout this paper} Therefore, Lovisotto et al. \cite{lovisotto2020slap} proposed to use a projector to project adversarial perturbations on the object. This is a dynamic attack since the adversary is able to dynamically change the projected perturbation. However, it is still physically more expensive to replicate the setup to attack multiple objects. \eric{more expensive than what?} Li et al. \cite{li2019adversarial} addressed this problem by attacking the sensor directly. Instead of altering scene objects, they alter what the optical sensor perceives. \eric{optical sensor == camera?}\yi{yes we use these two terms interchangeably.}\eric{maybe we should just pick one to use throughout the paper for clarity, otherwise we might confuse readers.}
%In their approach, an adversary prints adversarial perturbations on a transparent paper and attaches the paper to a victim's optical sensor. In this way, the adversarial perturbation follows the victim optical sensor and continuously takes effect. However, this approach has the same disadvantage of static attacks that once the adversarial perturbation is applied, it cannot be changed easily. \eric{need to explain why this is a problem}\yi{One single perturbation might not have the capacity to account for multiple type of targets.} To account for dynamic physical environmental conditions, many existing physical attacks employ Expectation over Transformation (EOT) when generating adversarial perturbations. EOT is a data augmentation technique. It synthesizes data by considering various transformations that an adversarial perturbation might encounter in the physical environment and includes these data during the adversarial perturbation generation process. 
% \eric{training set for what? we haven't even begun discussing supervised versus unsupervised ML. what is being trained? are we assuming that these/our attacks only target supervised ML algorithms? are the attacks themselves trained?}
%\eric{this paragraph is huge. let's break it up.}

%To fill the gap of prior work, we propose to attack the sensor pipeline dynamically. With dynamic attacks, the adversary can control the adversarial perturbation based on different scenarios. \eric{have we clearly defined ``adversarial pertibation''?} This allows the adversary to have more freedom when attacking a vehicle. For instance, in a autonomous vehicle use case where the vehicle perceives traffic signs in front of it using optical sensors and take certain actions (e.g., acceleration, brake etc) accordingly in a autonomous fashion, the adversary can turn the adversarial perturbation on only at specific locations (e.g., school zone) to cause more damage. \eric{mention stealth. deploy the attack only at critical moments. Stuxnet could be a cool analog} \eric{in the previous sentence, nothing is specific to ``a autonomous vehicle use case'' except ``(e.g., school zone)''. break the sentence up. 1st sentence describes the general phenomenon. 2nd sentence describes in more detail the ``autonomous vehicle use case''.} Also, the adversary can prepare adversarial perturbations for each type of traffic signs to mislead the vehicle instead of one single perturbation. \eric{this seems obvious, but we need to clearly define the relationships between ``autonomous vehicles'' and ''traffic signs''. something about how one of the major components of an autonomous vehicle system is traffic sign detection and classification.}\yi{This should be defined when we introduce the autonomous vehicle use case} This results in a more accurate attack. \eric{now we're suddenly discussing results without describing the experiment?? at least reference the figure, table, or section.}\yi{Maybe just say this results in a more accurate attack.} 

%\yi{rephrased the description of light condition below.}
%The light condition greatly affects the capability of a projection-based physical adversarial perturbation. \eric{why do we keep repeating this? it's a contribution or result, not prior work. it doesn't belong here. you should describe the effects of environmental illumination on prior approaches, but that is missing.} As is mentioned in \cite{lovisotto2020slap}, the achievable color intensity of an adversarial perturbation shone on an object under attack by a projector is greatly affected by the ambient light of the environment. \eric{what's ``the object''? the object targeted for misclassification?}\yi{We might just say object under attack.} A strong illuminance would significantly reduce the color intensity, thus result in a much weaker perturbation. \eric{problematic, inaccurate use of ``color spectrum'' here. what are you trying to say? something about the limited dynamic range of cameras? or something about the limited colors emmitted by a projector? keep in mind that for color `hue' and `intensity' are orthogonal.} Since in our attack the adversarial perturbation is in close proximity to the optical sensor, it is less affected by strong lights. \eric{Again??} 
% The empirical evaluation also shows that our attack can survive much stronger light conditions than prior work. 
%\eric{And again we mention our attack's performance with respect to light conditions. This section isn't the place to discuss results. It's a place to describe the status and limitations of previous approaches, and how we design our method to overcome those limitations. there's no good discussion of why environmental lighting is a limiting factor for previous approaches, and there's no good discussion of why our approach should do any better. at a minimum, a short paragraph is needed describing the physics.}\yi{I agree we need to be more accurate about hue and intensity. In SLAP, the hue is affected more as the perturbation is shone on the object. If it's a stop sign, the resulting color will be red-ish no matter what color is projected. In our case, the hue of our perturbation is much less affected by the object since our perturbation is closer to the camera. Actually In our attack design we do not consider the hue change. However, ambient lights do affect intensity significantly. So I changed color spectrum to color intensity.}

\subsection{Transparent Displays}
%\luis{This subsection should be about mediums we can use. Probably can use static vs dynamic}

%\luis{TODO (MAYBE): add a small figure here showing the components of an AR display and how we intend to use it.}
A dynamic, sensor-first attack hinges on the availability of an appropriate attack medium. For camera-based sensing systems, our desired attack vector is light. We seek a medium that will project directly into a camera's optics. The ideal medium is a transparent display that 1) supports dynamic perturbations--as in the projector-based attacks~\cite{hoory2020dynamic,lovisotto2020slap,nichols2018projecting,nassi2020phantom}, 2) can generate perturbations based on the context of a target object ~\cite{nassi2020phantom}, and 3) resides on or near the camera lens such that all light perceived by the camera is transmitted through the medium--as in the case of adversarial camera stickers~\cite{li2019adversarial}. A variety of transparent displays are available as consumer products, with a majority catered to augmented reality (AR) applications such as AR glasses or heads-up displays (HUDs). These products display visual objects and auxiliary information within the user's field of view for various applications, including gaming~\cite{thomas2012survey}, driving assistance~\cite{abdi2015vehicle}, surgical assistance~\cite{vavra2017recent}, and construction safety~\cite{li2018critical}. 

At their core, existing AR solutions consist of two main components: a light source and a holographic combiner (i.e., a specialized lens) that renders images from the projected light into the user's field of view. Precise positioning of the combiner and projection source results in the user simultaneously viewing a scene along with the overlaid projection. Thus, AR technology provides an ideal transparent medium to project dynamic perturbations into the field-of-view of a target camera--serving as a premise for \namenospace's design.
%There exist a variety of transparent displays available as consumer products, with a majority catered towards augmented reality (AR) applications such as AR glasses, heads-up displays (HUD), etc. These products display auxiliary information within the user's field of view to better assist people in everyday activities (e.g. driving assistance, smart glasses etc.). \eric{1. ``auxiliary information''? just say virtual objects or text. 2. ``assist people in everyday activities''? that's not really true. name 1 ``everyday task'' that existing AR products help people with.} In our attack, we consider an optical sensor as an analog to the human eye and we make malicious use of the transparent display. 
% \eric{woah. we do NOT consider an optical sensor to be the human eye. a camera is an analog to the human eye. let's be precise about what we mean here.} 
%Instead of assist the optical sensor, we disturb it by displaying adversarial information to alter the perception of the optical sensor. \eric{``disturb the optical sensor'' feels wrong.} \eric{we don't need to describe our threat model again here. we're just getting background on transparent display technology, which we use.}

%At their core, existing AR solutions consist of two main components: a holographic combiner (i.e. a specialized lens) rendering images projected from a light source into the user's field of view. Precise positioning of the combiner and projection source result in the user simultaneously viewing the scene  with the overlaid projection. In this work we employ a commodity setup to emulate potential commercial solutions, consisting of a 1" OLED display with a 50:50 ratio beam splitter, described in Figures~\ref{fig:setup-diagram}~and~\ref{fig:trans-display}. \matt{we might want to restructure this part} %\yi{this shows section 4 because in the caption of fig:trans-display there is someone's comment}
%Existing transparent displaying solutions mostly come down to the following setup. \eric{``mostly''? precise language should always be used in technical writing.} A combiner consists of a projecting device (e.g., a projector or an LED screen) and an angled flat piece of glass (e.g. a beam splitter). \eric{it's called a ``combiner''?} The projecting device shines lights to the glass. \eric{it's worth mentioning that products like the Hololens (the most widely known AR device) uses a slightly different system than our approach that includes a high-speed laser. not sure if it's worth explicitly mentioning in the paper, but we need to ensure that our definition of an AR display does not conflict with the reality of the best-known AR device.} The glass redirects the projected lights such that a viewer in front of the combiner is able to perceive the physical scene and the projected lights at the same time. In this paper, we employ a portable and economical setup in a similar way (\autoref{fig:trans-display}). We combine a 1" LCD display with a 50:50 ratio beam-splitter to form the combiner.
%Our setup is ultra low-cost compared to existing transparent display solutions on the market, yet works perfectly for our proposed attack. \eric{``ultra low-cost''?? remove the superfluous adjectives} \eric{``works perfectly''???? remove. it does not work perfectly. our results are not perfect!}

