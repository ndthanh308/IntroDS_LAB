@article{williams2002trusting,
  title={Trusting records: legal, historical and diplomatic perspectives},
  author={Williams, Caroline},
  journal={Journal of Documentation},
  volume={58},
  number={1},
  pages={136--139},
  year={2002},
  doi={10.1108/jd.2002.58.1.136.14},
  publisher={Emerald Group Publishing Limited}
}

@article{an2014reinventing,
  title={Reinventing the concept of the state archival fond in {C}hina},
  author={An, Xiaomi and Deng, Hepu and Zhang, Bin},
  journal={Archives and Manuscripts},
  volume={42},
  number={2},
  pages={146--150},
  year={2014},
  doi={10.1080/01576895.2014.911673},
  publisher={Taylor \& Francis}
}

@article{henninger2016new,
  title={How are the new documents of social networks shaping our cultural memory},
  author={Henninger, Maureen and Scifleet, Paul},
  journal={Journal of Documentation},
  volume={72},
  number={2},
  pages={277--298},
  year={2016},
  doi={10.1108/JD-06-2015-0069},
  publisher={Emerald Group Publishing Limited}
}

@article{an2017knowledge,
  title={A knowledge management framework for effective integration of national archives resources in {C}hina},
  author={An, Xiaomi and Bai, Wenlin and Deng, Hepu and Sun, Shuyang and Zhong, Wenrui and Dong, Yu},
  journal={Journal of Documentation},
  volume={73},
  number={1},
  pages={18--34},
  year={2017},
  doi={10.1108/JD-04-2016-0040},
  publisher={Emerald Publishing Limited}
}

@article{moss1996dang,
  title={Dang'an: contemporary {C}hinese archives},
  author={Moss, William W},
  journal={The China Quarterly},
  volume={145},
  pages={112--129},
  year={1996},
  doi={10.1017/S0305741000044155},
  publisher={Cambridge University Press}
}

@article{xiao2021security,
  title={Security status of electronic records preservation in central {C}hina: The survey results of 34 archives in Wuhan City},
  author={Xiao, Qiuhui and Xu, Xiaotong and Liu, Panpan},
  journal={Library Hi Tech},
  volume={39},
  number={1},
  pages={22--36},
  year={2021},
  doi={10.1108/LHT-04-2019-0088},
  publisher={Emerald Publishing Limited}
}

@misc{saac2022,
  title = {Summary of Basic Information on National Archives Administration and Archives in 2021 (Part 2)},
  howpublished = {\url{https://www.saac.gov.cn/daj/zhdt/202208/b9e2f459b5b1452d8ae83d7f78f51769.shtml}},
  author = {{National Archives Administration}},
  year = {2023}
}

@article{roper2003archives,
  title={Archives and the public good: Accountability and records in modern society},
  author={Roper, Michael},
  journal={Journal of documentation},
  volume={59},
  number={5},
  pages={617--619},
  year={2003},
  doi={10.1108/00220410310499645},
  publisher={Emerald Group Publishing Limited}
}

@article{moss2018reconfiguration,
  title={The reconfiguration of the archive as data to be mined},
  author={Moss, Michael and Thomas, David and Gollins, Tim},
  journal={Archivaria},
  volume={86},
  number={86},
  pages={118--151},
  year={2018},
  publisher={Association of Canadian Archivists}
}

@mastersthesis{aangenendt2022archives,
  title={Archives in the Digital Age. The use of AI and machine learning in the Swedish archival sector},
  author={Aangenendt, Gijs},
  school={Uppsala University},
  year={2022}
}

@article{hutchinson2020natural,
  title={Natural language processing and machine learning as practical toolsets for archival processing},
  author={Hutchinson, Tim},
  journal={Records Management Journal},
  volume={30},
  number={2},
  pages={155--174},
  year={2020},
  doi={10.1108/RMJ-09-2019-0055},
  publisher={Emerald Publishing Limited}
}

@article{shabou2020algorithmic,
  title={Algorithmic methods to explore the automation of the appraisal of structured and unstructured digital data},
  author={Shabou, Basma Makhlouf and Ti{\`e}che, Julien and Knafou, Julien and Gaudinat, Arnaud},
  journal={Records management journal},
  volume={30},
  number={2},
  pages={175--200},
  year={2020},
  doi={10.1108/RMJ-09-2019-0049},
  publisher={Emerald Publishing Limited}
}

@inproceedings{hutchinson2018protecting,
  title={Protecting privacy in the archives: supervised machine learning and born-digital records},
  author={Hutchinson, Tim},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)},
  pages={2696--2701},
  year={2018},
  doi={10.1109/BigData.2018.8621929},
  organization={IEEE}
}

@inproceedings{blanke2017identifying,
  title={Identifying epochs in text archives},
  author={Blanke, Tobias and Wilson, Jon},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)},
  pages={2219--2224},
  year={2017},
  doi={10.1109/BigData.2017.8258172},
  organization={IEEE}
}

@article{lee2019machine,
  title={Machine learning, template matching, and the International Tracing Service digital archive: Automating the retrieval of death certificate reference cards from 40 million document scans},
  author={Lee, Benjamin Charles Germain},
  journal={Digital Scholarship in the Humanities},
  volume={34},
  number={3},
  pages={513--535},
  year={2019},
  doi={10.1093/llc/fqy063},
  publisher={Oxford University Press}
}

@article{lansdall2020history,
  title={History playground: a tool for discovering temporal trends in massive textual corpora},
  author={Lansdall-Welfare, Thomas and Cristianini, Nello},
  journal={Digital Scholarship in the Humanities},
  volume={35},
  number={2},
  pages={328--341},
  year={2020},
  doi={10.1093/llc/fqy077},
  publisher={Oxford University Press}
}

@article{cao2023comprehensive,
  title={A comprehensive survey of {AI}-generated content ({AIGC}): A history of generative {AI} from gan to {C}hat{GPT}},
  author={Cao, Yihan and Li, Siyu and Liu, Yixin and Yan, Zhiling and Dai, Yutong and Yu, Philip S and Sun, Lichao},
  journal={arXiv preprint arXiv:2303.04226},
  year={2023}
}

@article{benoit2009challenges,
  title={Challenges for estimating policy preferences: Announcing an open access archive of political documents},
  author={Benoit, Kenneth and Br{\"a}uninger, Thomas and Debus, Marc},
  journal={German Politics},
  volume={18},
  number={3},
  pages={441--454},
  year={2009},
  doi={10.1080/09644000903055856},
  publisher={Taylor \& Francis}
}

@article{man2010functional,
  title={A functional approach to appraisal and retention scheduling},
  author={Man, Elizabeth},
  journal={Records Management Journal},
  volume={20},
  number={1},
  pages={104--116},
  year={2010},
  doi={10.1108/09565691011039870},
  publisher={Emerald Group Publishing Limited}
}

@article{dunn1998protecting,
  title={Protecting confidentiality in archival data resources},
  author={Dunn, Christopher S and Austin, Erik W},
  journal={IASSIST Quarterly},
  volume={22},
  number={2},
  pages={16--16},
  doi={10.29173/iq724},
  year={1998}
}

@article{nguyen2021survey,
  title={Survey of post-OCR processing approaches},
  author={Nguyen, Thi Tuyet Hai and Jatowt, Adam and Coustaty, Mickael and Doucet, Antoine},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--37},
  year={2021},
  doi = {10.1145/3453476},
  publisher={ACM New York, NY, USA}
}

@article{Hosseini2023FightingRF,
  title={Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of {C}hat{GPT} and other Large Language Models in scholarly peer review},
  author={Mohammad Hosseini and Serge P.J.M. Horbach},
  journal={Research Square},
  year={2023}
}

@article{Zhao2023ASO,
  title={A Survey of Large Language Models},
  author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Z. Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jianyun Nie and Ji-rong Wen},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.18223}
}

@article{Fan2023ABR,
  title={A Bibliometric Review of Large Language Models Research from 2017 to 2023},
  author={Lizhou Fan and Lingyao Li and Zihui Ma and Sanggyu Lee and Huizi Yu and Libby Hemphill},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.02020}
}

@misc{wang2023mediagpt,
      title={Media{GPT} : A Large Language Model Target {C}hinese Media}, 
      author={Zhonghao Wang},
      year={2023},
      eprint={2307.10930},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

  @article{cui2023efficient,
  title={Efficient and effective text encoding for {C}hinese llama and alpaca},
  author={Cui, Yiming and Yang, Ziqing and Yao, Xin},
  journal={arXiv preprint arXiv:2304.08177},
  year={2023}
}
  @article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{cui-etal-2020-revisiting,
    title = "Revisiting Pre-Trained Models for {C}hinese Natural Language Processing",
    author = "Cui, Yiming  and
      Che, Wanxiang  and
      Liu, Ting  and
      Qin, Bing  and
      Wang, Shijin  and
      Hu, Guoping",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.58",
    pages = "657--668",
}

@article{liu2019roberta,
  title={{RoBERTa}: A robustly optimized {BERT} pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}
  @article{shao2021cpt,
  title={{CPT}: A pre-trained unbalanced transformer for both {C}hinese language understanding and generation},
  author={Shao, Yunfan and Geng, Zhichao and Liu, Yitao and Dai, Junqi and Yan, Hang and Yang, Fei and Zhe, Li and Bao, Hujun and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2109.05729},
  year={2021}
}
  @article{zhang2021mengzi,
  title={Mengzi: Towards lightweight yet ingenious pre-trained models for {C}hinese},
  author={Zhang, Zhuosheng and Zhang, Hanqing and Chen, Keming and Guo, Yuhang and Hua, Jingyun and Wang, Yulong and Zhou, Ming},
  journal={arXiv preprint arXiv:2110.06696},
  year={2021}
}

@article{Shanahan2022TalkingAL,
  title={Talking About Large Language Models},
  author={Murray Shanahan},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.03551}
}

@misc{li2023cmmlu,
      title={{CMMLU}: Measuring massive multitask language understanding in {C}hinese}, 
      author={Haonan Li and Yixuan Zhang and Fajri Koto and Yifei Yang and Hai Zhao and Yeyun Gong and Nan Duan and Timothy Baldwin},
      year={2023},
      eprint={2306.09212},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Touvron2023LLaMAOA,
  title={{LLaMA}: Open and Efficient Foundation Language Models},
  author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timoth{\'e}e Lacroix and Baptiste Rozi{\`e}re and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.13971}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}

@article{Chowdhery2022PaLMSL,
  title={{PaLM}: Scaling Language Modeling with Pathways},
  author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and others},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.02311}
}

@article{Zeng2022GLM130BAO,
  title={{GLM-130B}: An Open Bilingual Pre-trained Model},
  author={Aohan Zeng and Xiao Liu and Zhengxiao Du and Zihan Wang and Hanyu Lai and Ming Ding and Zhuoyi Yang and Yifan Xu and Wendi Zheng and Xiao Xia and Weng Lam Tam and Zixuan Ma and Yufei Xue and Jidong Zhai and Wenguang Chen and P. Zhang and Yuxiao Dong and Jie Tang},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.02414}
}

@article{Scao2022BLOOMA1,
  title={{BLOOM}: A 176B-Parameter Open-Access Multilingual Language Model},
  author={Teven Le Scao and Angela Fan and Christopher Akiki and Elizabeth-Jane Pavlick and Suzana Ili'c and others},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.05100}
}

@article{OpenAI2023GPT4TR,
  title={{GPT}-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774}
}


@article{Wu2023BloombergGPTAL,
  title={Bloomberg{GPT}: A Large Language Model for Finance},
  author={Shijie Wu and Ozan Irsoy and Steven Lu and Vadim Dabravolski and Mark Dredze and Sebastian Gehrmann and Prabhanjan Kambadur and David Rosenberg and Gideon Mann},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.17564}
}

@article{Xie2023PIXIUAL,
  title={{PIXIU}: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance},
  author={Qianqian Xie and Weiguang Han and Xiao Zhang and Yanzhao Lai and Min Peng and Alejandro Lopez-Lira and Jimin Huang},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.05443}
}

@article{Xiong2023DoctorGLMFY,
  title={Doctor{GLM}: Fine-tuning your {C}hinese Doctor is not a Herculean Task},
  author={Honglin Xiong and Sheng Wang and Yitao Zhu and Zihao Zhao and Yuxiao Liu and Linlin Huang and Qian Wang and Dinggang Shen},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.01097}
}

@inproceedings{Du2021GLMGL,
  title={{GLM}: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Zhengxiao Du and Yujie Qian and Xiao Liu and Ming Ding and Jiezhong Qiu and Zhilin Yang and Jie Tang},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2021}
}

@article{Wu2023PMCLLaMAFF,
  title={PMC-LLaMA: Further Finetuning LLaMA on Medical Papers},
  author={Chaoyi Wu and Xiaoman Zhang and Ya Zhang and Yanfeng Wang and Weidi Xie},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.14454}
}

@article{Taylor2022GalacticaAL,
  title={Galactica: A Large Language Model for Science},
  author={Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony S. Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.09085}
}

@article{Pahune2023SeveralCO,
  title={Several Categories of Large Language Models ({LLM}s): A Short Survey},
  author={Saurabh A Pahune and Manoj Chandrasekharan},
  journal={International Journal for Research in Applied Science and Engineering Technology},
  year={2023}
}

@misc{conneau2018senteval,
      title={SentEval: An Evaluation Toolkit for Universal Sentence Representations}, 
      author={Alexis Conneau and Douwe Kiela},
      year={2018},
      eprint={1803.05449},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2019glue,
      title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}, 
      author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2019},
      eprint={1804.07461},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2020superglue,
      title={Super{GLUE}: A Stickier Benchmark for General-Purpose Language Understanding Systems}, 
      author={Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2020},
      eprint={1905.00537},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{Austin2021ProgramSW,
  title={Program Synthesis with Large Language Models},
  author={Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie J. Cai and Michael Terry and Quoc V. Le and Charles Sutton},
  journal={ArXiv},
  year={2021},
  volume={abs/2108.07732}
}

@article{Chen2021EvaluatingLL,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and others},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03374}
}

@inproceedings{Rajpurkar2018KnowWY,
  title={Know What You Donâ€™t Know: Unanswerable Questions for SQuAD},
  author={Pranav Rajpurkar and Robin Jia and Percy Liang},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2018}
}

@article{Kwiatkowski2019NaturalQA,
  title={Natural Questions: A Benchmark for Question Answering Research},
  author={Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and others},
  journal={Transactions of the Association for Computational Linguistics},
  year={2019},
  volume={7},
  pages={453-466},
  doi={10.1162/tacl_a_00276}
}

@inproceedings{Li2022MultiSpanQAAD,
  title={Multi{S}pan{QA}: A Dataset for Multi-Span Question Answering},
  author={Haonan Li and Martin Tomko and Maria Vasardani and Timothy Baldwin},
  booktitle={North American Chapter of the Association for Computational Linguistics},
  year={2022}
}

@article{Clark2018ThinkYH,
  title={Think you have Solved Question Answering? Try {ARC}, the {AI}2 Reasoning Challenge},
  author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.05457}
}

@article{Talmor2019CommonsenseQAAQ,
  title={Commonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge},
  author={Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},
  journal={ArXiv},
  year={2019},
  volume={abs/1811.00937}
}

@misc{sawada2023arb,
      title={{ARB}: Advanced Reasoning Benchmark for Large Language Models}, 
      author={Tomohiro Sawada and Daniel Paleka and Alexander Havrilla and Pranav Tadepalli and Paula Vidas and Alexander Kranias and John J. Nay and Kshitij Gupta and Aran Komatsuzaki},
      year={2023},
      eprint={2307.13692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{pal2022medmcqa,
      title={{MedMCQA}: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering}, 
      author={Ankit Pal and Logesh Kumar Umapathi and Malaikannan Sankarasubbu},
      year={2022},
      eprint={2203.14371},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{jin2019pubmedqa,
      title={{PubMedQA}: A Dataset for Biomedical Research Question Answering}, 
      author={Qiao Jin and Bhuwan Dhingra and Zhengping Liu and William W. Cohen and Xinghua Lu},
      year={2019},
      eprint={1909.06146},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Shah2022WhenFM,
  title={When {FLUE} Meets {FLANG}: Benchmarks and Large Pretrained Language Model for Financial Domain},
  author={Raj Sanjay Shah and Kunal Chawla and Dheeraj Eidnani and Agam Shah and Wendi Du and Sudheer Chava and Natraj Raman and Charese Smiley and Jiaao Chen and Diyi Yang},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.00083}
}

@article{Lu2023BBTFinCC,
  title={{BBT-F}in: Comprehensive Construction of {C}hinese Financial Domain Pre-trained Language Model, Corpus and Benchmark},
  author={Dakuan Lu and Jiaqing Liang and Yipei Xu and Qi He and Yipeng Geng and Mengkun Han and Ying Xin and Hengkui Wu and Yanghua Xiao},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.09432}
}

@misc{chen2022convfinqa,
      title={Conv{F}in{QA}: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering}, 
      author={Zhiyu Chen and Shiyang Li and Charese Smiley and Zhiqiang Ma and Sameena Shah and William Yang Wang},
      year={2022},
      eprint={2210.03849},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2023batgpt,
      title={Bat{GPT}: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer}, 
      author={Zuchao Li and Shitou Zhang and Hai Zhao and Yifei Yang and Dongjie Yang},
      year={2023},
      eprint={2307.00360},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{su2022roformer,
      title={Ro{F}ormer: Enhanced Transformer with Rotary Position Embedding}, 
      author={Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
      year={2022},
      eprint={2104.09864},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following {LLaMA} model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@inproceedings{wang-etal-2019-confusionset,
    title = "Confusionset-guided Pointer Networks for {C}hinese Spelling Check",
    author = "Wang, Dingmin  and
      Tay, Yi  and
      Zhong, Li",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1578",
    doi = "10.18653/v1/P19-1578",
    pages = "5780--5785",
    abstract = "This paper proposes Confusionset-guided Pointer Networks for {C}hinese Spell Check (CSC) task. More concretely, our approach utilizes the off-the-shelf confusionset for guiding the character generation. To this end, our novel Seq2Seq model jointly learns to copy a correct character from an input sentence through a pointer network, or generate a character from the confusionset rather than the entire vocabulary. We conduct experiments on three human-annotated datasets, and results demonstrate that our proposed generative model outperforms all competitor models by a large margin of up to 20{\%} F1 score, achieving state-of-the-art performance on three datasets.",
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{lewis2020bart,
  title={{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7871--7880},
  year={2020}
}

@inproceedings{tseng-etal-2015-introduction,
    title = "Introduction to {SIGHAN} 2015 Bake-off for {C}hinese Spelling Check",
    author = "Tseng, Yuen-Hsien  and
      Lee, Lung-Hao  and
      Chang, Li-Ping  and
      Chen, Hsin-Hsi",
    booktitle = "Proceedings of the Eighth {SIGHAN} Workshop on {C}hinese Language Processing",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-3106",
    doi = "10.18653/v1/W15-3106",
    pages = "32--37",
}
