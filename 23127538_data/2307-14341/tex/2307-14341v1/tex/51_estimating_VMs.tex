\section{Addressing the missing cone}
\label{sec:contribution-2:goal-2}

% Figure environment removed

% Figure environment removed

\new{In the following, we propose \newww{a procedure} to address the missing-cone problem. Our key insight is that we can obtain information of surfaces inside the null-reconstruction space by analyzing the fourth-bounce illumination \NEW{that reaches} the relay surface through multiple interreflections with other surfaces in the hidden scene. First, we \newww{show how to analyze elements \NEW{captured} in time-resolved images of the hidden scene} to infer the position and orientation of surfaces inside the null-reconstruction space of third-bounce methods. \newww{As this inference is limited by ambiguities, we propose a procedure} to directly image such surfaces without requiring inference. All experiments in this section rely on simulated data using transient rendering~\cite{royo2022non, jarabo2014framework}.}

\paragraph{\new{Problem statement}} \fref{fig:goal2-overview}a shows an example scene, consisting of two surfaces $\lM$ and $\lG$, the NLOS imaging aperture $\lS$, and the illuminated point $\xl$. \neww{In the real domain, some light paths will bounce on the illuminated point $\xl$, then on $\lG$ and finally on a point in the aperture $\lS$, for a total of three bounces. However, }\new{in the NLOS computational domain, $\lG$ reflects third-bounce illumination specularly, away from $\lS$ (pink\neww{, note that not all three bounces are shown}). Therefore, imaging $\lG$ is limited if using third-bounce methods. \fref{fig:goal2-diagram}a illustrates the procedure of third-bounce methods, showing \NEW{that} $\lG$ is inside the null-reconstruction space.}

\new{Our key observation is that \NEW{four}-bounce paths (purple\neww{, note that not all four bounces are shown}) that reach $\lS$ through a specular-like reflection on $\lM$ ($\xl \rarr \lG \rarr \lM \rarr \lS$) provide valuable information about $\lG$. 
%
In particular, \newww{we show how to analyze illumination in time-resolved images of the scene} to infer the position and orientation of $\lG$ through mirror images of scene elements \NEW{produced} by $\lG$ (\sref{sec:mirrorimages}), and then propose a procedure to directly image $\lG$ by creating secondary apertures at surfaces that are visible by third-bounce methods such as $\lM$ (\sref{sec:secondaryaperture}).}
%

\subsection{Inferring surfaces from mirror images}
\label{sec:mirrorimages}
In this section, we show how to infer the position and orientation of $\lG$ \new{from the impulse response function $H(\xl, \xs, t)$}. The key insight is that if we can observe mirror images of scene elements created by $\lG$, it is because $\lG$ lies on the plane between such scene element and its mirror image, just like what happens with a real mirror. \fref{fig:goal2-overview}b points the location of mirror images of the illuminated point $\xl$ and $\lM$, \NEW{produced} by $\lM$ and $\lG$ in our example scene. Superscripts \NEW{denote the surface (or surfaces, in order) that produces the mirror images of each scene element:}
%
$\xl$ is mirrored by $\lM$ and $\lG$ at $\xlM$ and $\xlG$, respectively; 
$\lM$ is mirrored by $\lG$ at $\lMG$;
$\xlG$ is mirrored by $\lM$ at $\xlGM$;
\NEW{and} $\xlM$ is mirrored by $\lG$ at $\xlMG$.


\paragraph{Observing mirror images from $\lS$} 
\neww{Previously, we described the location of mirror images of the illuminated point $\xl$ produced by surfaces in the hidden scene, as shown in \fref{fig:goal2-overview}b.}
\neww{To show which of these mirror images are visible from the aperture $\lS$ and use them to infer the location and orientation of $\lG$}, we implement a transient camera model $\ftc$ (\eref{eq:RSD_freq_tc}), and evaluate it at different time instants.
%
\new{In the resulting time-resolved image $\ftc(\xv,t)$, light emitted from the illuminated point $\xl$ \newww{is captured in the frame} at $t=0$. \neww{We show \NEW{the frame} $\ftc(\xv,t=0)$ in \fref{fig:mirror_images_from_S}a, \NEW{which captures} several bright spots at the locations of the mirror images of $\xl$ that are visible from aperture $\lS$ \NEW{over a volume that covers the whole scene.} In particular, the}}
%
 aperture $\lS$ can observe the mirror images \neww{at} $\xlM$ (produced by \NEW{three}-bounce paths $\xl\rarr\lM\rarr\lS$), \neww{at} $\xlMG$ and \new{at} $\xlGM$ (both produced by \NEW{four}-bounce paths $\xl\rarr\lM\rarr\lG\rarr\lS$ and $\xl\rarr\lG\rarr\lM\rarr\lS$).
%
We cannot, however, observe the mirror image \neww{at} $\xlG$, since \NEW{three}-bounce paths from $\xl$ to $\lG$ do not reach $\lS$ in the computational domain (\fref{fig:goal2-overview}a, pink).
%
\neww{Evaluating $\ftc(\xv,t)$ at \NEW{frames with} $t>0$ may show other scene elements and their mirror images, similarly to $\xl$, based on the time of flight from $\xl$ to \NEW{each scene element.} % \xv$.
For example,
\new{light from the \NEW{illuminated point} $\xl$ will reach the central point of $\lM$, denoted as $\overline{\mathbf{x}}_m$ (\fref{fig:mirror_images_from_S}a), at the time of flight $\overline{t}_m = \norm{\overline{\mathbf{x}}_m - \xl}/c$.} We can therefore identify reflections at points near the center of the plane $M$ by \NEW{looking at the frame at $t=\overline{t}_m$ of} $\ftc(\xv, t)$ (\fref{fig:mirror_images_from_S}b), \NEW{which captures}}
%
not only $\lM$ and $\lMG$, but many other mirror images produced by $\lM$ and $\lG$.


% Figure environment removed


\neww{Both images in \fref{fig:mirror_images_from_S} show bright areas outside the points or surfaces mentioned before. This is mainly \NEW{because} the impulse response function $H(\xl, \xs, t)$ \NEW{combines coupled information from paths of different bounces and optical lengths}, which introduces out-of-focus, low-frequency artifacts at each imaged location $\xv$.}
% 
\neww{Also, note that during the NLOS imaging process we only know the location of the illuminated point at $\xl$, \NEW{and} we do not have any prior knowledge of other \NEW{hidden} scene elements. Consequently, there exist ambiguities when identifying the \NEW{captured} bright spots as mirror images of $\xl$,} so we cannot guarantee that e.g., $\xlMG$ is a mirror image of $\xlM$; instead e.g., there may be two physical surfaces located at $\lMG$ and $\lM$, respectively. %At the end of 


\new{\paragraph{Inferring the position and orientation of $\lG$} By assuming that $\xlMG$ is a mirror image of $\xlM$
%
---i.e., $\xl$ has undergone two reflections \NEW{produced} by $\lM$ and \NEW{then} $\lG$---the surface $\lG$ that produced $\xlMG$ should lie in the perpendicular plane between $\xlM$ and $\xlMG$.} We obtain a point $\xg$ on such plane and its normal vector $\normalg$ as
\begin{equation}
\xg = \frac{\xlM+\xlMG}{2}, \quad \normalg = \frac{\xlM - \xlMG}{\norm{\xlM - \xlMG}},
\label{eq:infer-cg-ng}
\end{equation}
%
\new{which define the position and orientation of $\lG$, respectively.}
%
We could also infer \new{the position and orientation} of $\lG$ from $\lM$ and its mirror reflection $\lMG$. 
%
Such inferences require assumptions on the number of reflections undergone by the observed patterns (\fref{fig:mirror_images_from_S}). For this particular inference, $\xlM$ can be identified as the reflection of $\xl$ from the visible orientation of $\lM$, and \NEW{$\xlMG$} cannot be produced by $\lM$, so we assume it is a second mirror reflection by another hidden surface. 

In general, there are ambiguities on recognizing the source of every identified reflection, which may introduce errors when inferring hidden surfaces. 
%
\newww{To avoid errors due to such ambiguities}, in the following we propose a procedure to directly image $\lG$ without requiring inference.


\subsection{Imaging surfaces from secondary apertures}
\label{sec:secondaryaperture}
%
\new{Here we show a procedure to directly image $\lG$ using fourth-bounce illumination. The key idea is that, while the surface $\lG$ is inside the null-reconstruction space of imaging systems created at $\lS$ (\fref{fig:goal2-overview}a, pink), $\lG$ is not inside the null-reconstruction space of imaging systems created at $\lM$, since there exist three-bounce paths $\xl \rarr \lG \rarr \lM$ that reach $\lM$ (\fref{fig:goal2-overview}d, purple). Based on this observation, we show how to computationally translate our imaging system from $\lS$ to $\lM$ (\fref{fig:goal2-overview}c) to directly image $\lG$ using $\lM$ as a secondary aperture (\fref{fig:goal2-overview}d).}

\new{Our procedure is illustrated in \fref{fig:goal2-diagram}b: first, how to obtain a phasor field at $\lM$, and then how to use this response to generate computational cameras with the aperture located at $\lM$. The rest of this section describes this procedure in detail along with its results.}


\paragraph{\new{Phasor field at $\lM$}} \new{The phasor-field formulation uses phasors $\Pf(\xs, \fq)$ at points $\xs$, which encode the response of the scene to the illumination function, to implement imaging models with a camera aperture $\lS$. To translate the camera aperture from points $\xs$ to points $\xm \in \lM$, we need to compute their corresponding phasors $\Pf(\xm,\fq)$.
%
The transient camera model $\ftc$ achieves this goal, since $\Pf(\xm, \fq) \equiv \fftc(\xm, \fq)$ propagates phasors from all points $\xs$ to \NEW{each point} $\xm$. To determine where $\lM$ is, we first implement a confocal camera model \neww{to capture} $\fcc(\xv,t)$ from $\lS$---equivalent to existing NLOS imaging models---\neww{to image all points $\xv$ in the region $\lV$ (\fref{fig:goal2-overview}c). The computed \NEW{frame at $t=0$} can be seen in \fref{fig:goal2-diagram}a. We can \NEW{estimate} all points $\xm$ in $\lM$ by thresholding the image $\fcc(\xv, t=0)$.
%
} We then implement a transient camera model \neww{to obtain} $\fftc(\xm,\fq)$, yielding a phasor field at $\lM$ that can be used to implement new imaging systems at $\lM$.}


\new{\paragraph{$\lM$ as a secondary aperture}
Based on RSD propagation principles, we implement a lens at $\lM$ which focuses the phasors $\fftc(\xm,\fq)$ at points $\xw$ in a volume $\lW$ that contains $\lG$ (\fref{fig:goal2-overview}d), equivalent to what the transient camera model does. In practice, we include an RSD propagator from points $\xm$ to points $\xw$, yielding the transient camera model with aperture $\lM$ (denoted as $\ftcM$) as
\begin{align}
    \fftcM(\xw, \fq) = \int\limits_{M} \frac{e^{i k \norm{\xw-\xm}}}{\norm{\xw-\xm}}\fftc\left(\xm, \fq\right) \diff \xm.
    \label{eq:second_RSD}
\end{align}}
%
The \new{time-domain version $\ftcM(\xw, t) = \mathcal{F}^{-1}\left\{ \fftcM(\xw, \fq) \right\}$} represents a time-resolved image of the scene as captured from $\lM$.
%
\NEW{The frame at $t=0$ of} $\ftcM(\xw, t)$ \NEW{captures} the initial light up of the \NEW{illuminated point} $\xl$ and its mirror image at $\xlG$.
%
Similarly to the mirror images captured from $\lS$ (\fref{fig:mirror_images_from_S}), given $\xl$ and its mirror image $\xlG$ (\NEW{captured by the aperture at} $\lM$) we can infer the position and orientation of the surface $\lG$ that \NEW{produced} $\xlG$ (\eref{eq:infer-cg-ng}).


\new{\paragraph{Imaging $\lG$ from $\lM$} 
Instead of approximating $\lG$ through geometric inference, we \emph{directly} image $\lG$ by extending \eref{eq:second_RSD} to implement a confocal camera model at $\lM$. Under a single \NEW{illuminated point} $\xl$, this is equivalent to incorporating an RSD operator to \eref{eq:second_RSD} that propagates the phasor \NEW{$\Pf(\xm, \fq) \equiv \fftc(\xm, \fq)$} accounting for the distance between $\xl$ and $\xw$, yielding a confocal camera model with aperture $\lM$ (denoted as $\fccM$) as
%
\begin{align}
    \ffccM(\xw,\fq) & = \fftcM(\xw, \fq) \frac{e^{i k \norm{\xw-\xl}}}{\norm{\xw-\xl}} \nonumber \\
                    & = \int\limits_{\lM} \frac{e^{i k \left(\norm{\xw-\xm} + \norm{\xw-\xl}\right)}}{\norm{\xw-\xm}\norm{\xw-\xl}} \fftc(\xm, \fq) \diff \xm.
\label{eq:second_RSD_confocal}
\end{align}
}
\new{The time-resolved image $\fccM(\xw, t) = \mathcal{F}^{-1}\left\{ \ffccM(\xw, \fq) \right\}$ of this confocal camera model \NEW{captures} $\lG$ \NEW{in the frame at} $t=0$.} This follows the basis of classic NLOS reconstruction methods, which directly image $\lG$ from the time of flight of \NEW{three}-bounce paths $\xl \rarr \lG \rarr \lM$, but instead using \NEW{four}-bounce paths $\xl \rarr \lG \rarr \lM \rarr \lS$ in the captured impulse response $H(\xl, \xs, t)$.


% Figure environment removed

\new{\subsection{Results}
We illustrate results of our \newww{procedure} using the scene in \fref{fig:goal2-overview}a for both inference based on $\xl$ and its mirror image $\xlG$, and direct imaging of $\lG$ in \fref{fig:goal2-results}. We use different orientations of the plane $\lG$ to show how it affects the resulting mirror image $\xlG$ and the direct image of $\lG$.
%
In the left column we show an overview of the scenes.
%
Note that while inference (\sref{sec:mirrorimages}) and direct imaging (\sref{sec:secondaryaperture}) are two separate procedures, here we illustrate inference using the mirror image \NEW{at} $\xlG$ \new{captured} through the secondary aperture at $\lM$ of the direct imaging procedure (\sref{sec:secondaryaperture}).}

\new{We show results for inference, identifying both $\xl$ and $\xlG$ in the computed images $\ftcM(\xw, t)$ (\eref{eq:second_RSD}) at $\xw \in \lW$ and $t=0$ (\fref{fig:goal2-results}, middle column). From $\xl$ and $\xlG$ we infer a point $\xg$ and the normal $\normalg$ of a plane corresponding to the surface $\lG$.}

\new{To illustrate our direct imaging procedure, we compute \eref{eq:second_RSD_confocal} to directly image $\lG$, evaluating $\fccM(\xw, t)$ at $\xw \in \lW$ and $t=0$ (\fref{fig:goal2-results}, right column).
This yields a clear image \neww{of the surface $\lG$ which} is entirely on the null-reconstruction space of third-bounce methods (\fref{fig:goal2-diagram}a). Note only part of $\lG$ is visible, the rest is inside the null-reconstruction space of the imaging system at $\lM$ as some fourth-bounce illumination paths do not reach $\lS$ through specular bounces on $\lM$ in the computational domain. }
%
\neww{The results also show a bright region near $\xl$. In this case, we use our fourth-bounce imaging method, but the impulse
response function $H(\xl, \xs, t)$ \newww{combines coupled information from paths of different bounces and optical lengths}, which translates into out-of-focus, low-frequency artifacts.}
