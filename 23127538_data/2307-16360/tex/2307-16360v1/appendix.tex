\appendix
\onecolumn
\section{Technical Proofs}

In this section, we prove the theoretical results in the main paper.
To make it complete and self-contained, we also include the proof of Proposition 1, i.e., Theorem 1 in \citep{gendler2022adversarially}, with the framework and notations used in our paper.

\begin{proposition}
\label{proposition:AR_coverage_ARCP_appendix}
(Proposition 1 restated, adversarially robust coverage of RSCP, Theorem 1 in \citep{gendler2022adversarially})
Assume the score function $S$ is $M_r$-adversarially inflated.
Let $\calC^\AR(\widetilde X) = \{ y \in \calY : S(\widetilde X, y) \leq \tau^\AR(\alpha) \}$ be the prediction set for a testing sample $\widetilde X$.
Then RSCP achieves ($1-\alpha$)-adversarially robust coverage.
\end{proposition}
\begin{proof}
(of Proposition \ref{proposition:AR_coverage_ARCP_appendix})

After reviewing the inflated quantile in the adversarial sense, we extend it to the following probabilistic sense.
\begin{align*}
\P_Z \{ 
S(X + \epsilon, Y) \leq \tau^\AR(\alpha)
\}
\geq &
\P_Z \{
S(X, Y) + M_r
\leq 
\tau^\AR(\alpha)
\}
\\
= &
\P_Z \{
S(X, Y) + M_r
\leq 
Q(\alpha) + M_r
\}
\\
= &
\P_Z \{ S(X, Y) \leq Q(\alpha) \}
\\
= &
\P_{X,Y} \{ S(X, Y) \leq Q(\alpha) \}
\geq 
1 - \alpha ,
\end{align*}
where the first inequality is due to the condition of $M_r$-adversarially inflated conformity score function (Definition 2), the first equality is due to the setting of the inflated threshold $\tau^\AR(\alpha) = Q(\alpha) + M_r$,
and the last inequality is due to the definition of quantile $Q(\alpha)$.
\end{proof}



\begin{proposition}
\label{proposition:PR_coverage_iPRCP_appendix}
(Proposition 2 restated, probabilistically robust coverage of iPRCP)
Assume the score function $S$ is $M_{r, \eta}$-probabilistically inflated.
Let $\calC^\iPR(\widetilde X) = \{ y \in \calY : S(\widetilde X, y) \leq \tau^\iPR(\alpha; \eta) \}$ be the prediction set for a testing sample $\widetilde X=X+\epsilon$. 
Then iPRCP achieves ($1-\alpha$)-probabilistically robust coverage.
\end{proposition}


\begin{proof}
(of Proposition \ref{proposition:PR_coverage_iPRCP_appendix})

Denote $A_{r, \eta} = \{ Z \in \calX \times \calY \times \calE_r : S(X + \epsilon, Y) \leq S(X, Y) + M_{r, \eta} \}$, which implies $\P_Z \{ Z \in A_{ r, \eta } \} \geq 1 - \eta$.
Recall $\tau^\iPR(\alpha'; \eta) = Q(\alpha') + M_{r, \eta}$ for $\alpha'$ and $\eta$.
\begin{align*}
&
\P_Z \{ S(X + \epsilon, Y) \leq \tau^\iPR(\alpha'; \eta) \}
\\
= &
\P\{ Z \in A_{r, \eta} \} \cdot \P_Z \{ S(X + \epsilon, Y) \leq \tau^\iPR(\alpha'; \eta) | Z \in A_{r, \eta} \}
\\
&
+ \P\{ Z \notin A_{r, \eta} \} \cdot \P_Z \{ S(X + \epsilon, Y) \leq \tau^\iPR(\alpha'; \eta) | Z \notin A_{r, \eta} \}
\\
\geq & 
( 1 - \eta ) \cdot \P_Z \{ S(X + \epsilon, Y) \leq \tau^\iPR(\alpha'; \eta) | Z \in A_{r, \eta} \}
\\
\geq &
( 1 - \eta ) \cdot \P_Z \{ S(X, Y) + M_{r, \eta} \leq Q(\alpha') + M_{r, \eta} | Z \in A_{r, \eta} \} 
\\
= &
( 1 - \eta ) \cdot \P_{X, Y} \{ S(X, Y) \leq Q(\alpha') \}
\\
\geq &
( 1 - \eta ) ( 1 - \alpha' ) ,
\end{align*}
where the first inequality is due to the non-negativity of probability and the definition of $A_{r, \eta}$, and
the second inequality is due to $M_{r, \eta}$-probabilistically inflated score function (7).


In this case, define $\alpha^*_\iPR(\alpha; \eta) := \max\{ \alpha' : (1-\eta)(1-\alpha') \geq 1-\alpha \}$, and we can use $\tau^\iPR(\alpha^*_\iPR(\alpha; \eta); \eta)$ as the threshold to derive $(1-\alpha)$-probabilistically robust coverage.
However, we have to know the conformity score function very well, so that we access the value of $M_{r, \eta}$ given $\eta$ to determine $\tau^*_\iPR(\alpha; \eta)$, which is not always possible in practice.
\end{proof}




\begin{theorem}
\label{theorem:appendix:prob_robust_coverage_aPRCP}
(Theorem 1 restated, probabilistically robust coverage of aPRCP)
Let $\calC^\aPR(\widetilde X = X + \epsilon) = \{ y \in \calY : S(\widetilde X, y) \leq \tau^\aPR(\alpha; s) \}$ be the prediction set for a testing sample $\widetilde X$.
Then aPRCP achieves ($1-\alpha$)-probabilistically robust coverage.
\end{theorem}



\begin{proof}
(of Theorem \ref{theorem:appendix:prob_robust_coverage_aPRCP})

Denote $B = \{ (X, Y) \in \calX \times \calY : Q^\rob(X, Y; \alpha^*_\aPR) \leq \tau^\aPR(\alpha; s)\}$,
which implies that 
\begin{align}\label{eq:prob_B}
\P_{X,Y}\{ (X,Y) \in B \} \geq 1-\alpha+s
\end{align}
due to the definition of $\tau^\aPR(\alpha; s)$ in (9).
We simply check whether $\tau^\aPR(\alpha; s)$ can give us probabilistically robust coverage as follows:
\begin{align}\label{eq:PRCP_coverage}
&
\P_Z \{ S(X + \epsilon, Y) \leq \tau^\aPR(\alpha; s) \}
\nonumber\\
= &
\P_{X, Y}\{ X, Y : Q^\rob(X, Y; \alpha^*_\aPR) \leq \tau^\aPR(\alpha; s) \} \cdot \P_{\epsilon | X, Y} \{ S(X + \epsilon, Y) \leq \tau^\aPR(\alpha; s) \}
\nonumber\\
&
+ \P_{X, Y}\{ X : Q^\rob(X, Y; \alpha^*_\aPR) > \tau^\aPR(\alpha; s) \} \cdot \P_{\epsilon | X, Y} \{ S(X + \epsilon, Y) \leq \tau^\aPR(\alpha; s) \}
\nonumber\\
\geq &
\P_{X, Y}\{ X, Y : Q^\rob(X, Y; \alpha^*_\aPR) \leq \tau^\aPR(\alpha; s) \} \cdot \P_{\epsilon | (X, Y) \in B} \{ S(X + \epsilon, Y) \leq \tau^\aPR(\alpha; s) \}
\nonumber\\
\geq &
\P_{X, Y}\{ (X, Y) \in B \} \cdot \P_{\epsilon | (X, Y) \in B} \{ S(X + \epsilon, Y) \leq Q^\rob(X, Y; \alpha^*_\aPR) \}
\nonumber\\
\geq &
( 1 - \alpha + s ) \cdot \P_{\epsilon | (X, Y) \in B } \{ S(X + \epsilon, Y) \leq Q^\rob(X, Y; \alpha^*_\aPR) \}
\\
\geq &
( 1 - \alpha + s ) ( 1 - \alpha^*_\aPR ),
\nonumber
\end{align}
where the first inequality is due to the non-negativity of probability,
the second inequality is due to $Q^\rob(X,Y;\alpha^\aPR(\alpha)) \leq \tau^\aPR(\alpha; s)$ for $(X,Y) \in B$,
the third inequality is due to (\ref{eq:prob_B}),
and the last inequality is due to the definition of robust quantile $Q^\rob(X, Y; \tilde \alpha)$ in (8).

Recall $\alpha^*_\aPR = 1 - (1-\alpha) / (1-\alpha + s)$, so $( 1 - \alpha + s ) ( 1 - \alpha^*_\aPR ) = 1-\alpha$, which shows
\begin{align*}
\P_Z \{ S(X + \epsilon, Y) \leq \tau^\aPR(\alpha; s) \}
\geq 
1 - \alpha .
\end{align*}
\end{proof}


\begin{lemma}
\label{lemma:cross_domain_noise_coverage}
(Inflated probability for cross domain noise)
Assume $ \P_{\epsilon \sim \calP_\epsilon^{cal}}\{\epsilon\} - \P_{\epsilon \sim \calP_\epsilon^{test}}\{\epsilon\} \leq d$ for all $\| \epsilon \| \leq r$.
Then, for any threshold $\tau$, the following inequality holds:
\begin{align}
\label{eq:lemma1}
\P_{ \epsilon \sim \calP_\epsilon^{cal} | X, Y } \{ S(X + \epsilon, Y) \leq \tau \}
-
\P_{ \epsilon \sim \calP_\epsilon^{test} | X, Y } \{ S(X + \epsilon, Y) \leq \tau \} 
\leq
d .
\end{align}
\end{lemma}

\begin{proof}
(of Lemma \ref{lemma:cross_domain_noise_coverage})

\begin{align*}
&
\P_{\epsilon \sim \calP_\epsilon^{cal}} \{ S(X + \epsilon, Y) \leq \tau \}
-
\P_{\epsilon \sim \calP_\epsilon^{test}} \{ S(X + \epsilon, Y) \leq \tau \}
\\
= &
\E_{\epsilon \sim \calP_\epsilon^{cal}} [ \indicator [ S(X + \epsilon, Y) \leq \tau ] ]
-
\E_{\epsilon \sim \calP_\epsilon^{test}} [ \indicator[ S(X + \epsilon, Y) \leq \tau ] ]
\\
= &
\int_\epsilon \P_{\epsilon \sim \calP_\epsilon^{cal}} \{ \epsilon \} \cdot \indicator [ S(X + \epsilon, Y) \leq \tau ] d\epsilon
- \int_\epsilon \P_{\epsilon \sim \calP_\epsilon^{test}} \{ \epsilon \} \cdot \indicator [ S(X + \epsilon, Y) \leq \tau ] d\epsilon
\\
= &
\int_\epsilon \Big( \P_{\epsilon \sim \calP_\epsilon^{cal}} \{ \epsilon \} - \P_{\epsilon \sim \calP_\epsilon^{test}} \{ \epsilon \} \Big) \cdot \indicator [ S(X + \epsilon, Y) \leq \tau ] d\epsilon
\\
\leq &
\int_\epsilon ( d \cdot 1 ) d\epsilon
=
d .
\end{align*}
\end{proof}


\begin{theorem}
\label{theorem:appendix:prob_robust_coverage_aPRCP_cross_domain_noise}
(Theorem 2 restated, probabilistically robust coverage of aPRCP for cross domain noise)
Let $\calP_\epsilon^{test}$ and $\calP_\epsilon^{cal}$ denote different distributions of $\epsilon$ during the testing and calibration phase, respectively.
Assume $\P_{\epsilon \sim \calP_\epsilon^{cal}}\{\epsilon\} - \P_{\epsilon \sim \calP_\epsilon^{test}}\{\epsilon\} \leq d$ for all $\| \epsilon \| \leq r$.
Set $\alpha^*_\aPR = 1 - d - ( 1 - \alpha) / (1 - \alpha + s )$ in (9).
Let $\calC^\aPR(\widetilde X = X + \epsilon) = \{ y \in \calY : S(\widetilde X, y) \leq \tau^\aPR(\alpha; s) \}$ be the prediction set for a testing sample $\widetilde X$.
Then aPRCP achieves ($1-\alpha$)-probabilistically robust coverage under $\calP_\epsilon^{test}$.
\end{theorem}

\begin{proof}
(of Theorem \ref{theorem:appendix:prob_robust_coverage_aPRCP_cross_domain_noise})
We start with (\ref{eq:PRCP_coverage}) in the proof of Theorem \ref{theorem:appendix:prob_robust_coverage_aPRCP_cross_domain_noise} which only considers the noise $\epsilon$ drawn from the same distribution during calibration and testing as follows.
\begin{align*}
&
\P_{ X, Y, \epsilon \sim \calP_\epsilon^{test}} \{ S(X + \epsilon, Y) \leq \tau^\aPR(\alpha; s) \}
\\
\geq &
( 1 - \alpha + s ) \cdot \P_{\epsilon \sim \calP_\epsilon^{test} | (X, Y) \in B } \{ S(X + \epsilon, Y) \leq Q^\rob(X, Y; \alpha^*_\aPR) \}
\\
\geq &
( 1 - \alpha + s ) \cdot \Big( \P_{\epsilon \sim \calP_\epsilon^{cal} | (X, Y) \in B } \{ S(X + \epsilon, Y) \leq Q^\rob(X, Y; \alpha^*_\aPR) \} - d \Big)
\\
\geq &
( 1 - \alpha + s ) \cdot \Bigg( 1 - \Big( 1 - d - \frac{1-\alpha}{1-\alpha+s} \Big) - d \Bigg)
\\
= &
( 1 - \alpha + s ) \cdot \frac{ 1 - \alpha }{ 1 - \alpha + s }
= 
1 - \alpha ,
\end{align*}
where the first inequality follows (\ref{eq:PRCP_coverage}), 
the second inequality is due to inequality \ref{eq:lemma1} in Lemma \ref{lemma:cross_domain_noise_coverage}, and
the third inequality is due to the definition $Q^\rob(X, Y; \alpha^*_\aPR)$ in (8) with $\alpha^*_\aPR = 1 - d - (1-\alpha) / (1-\alpha+s)$.
\end{proof}

\begin{corollary}
\label{corollary:compare_aPRCP_ARCP_appendix}
(Corollary 3 restated)
To achieve the same ($1-\alpha$)-probabilistically robust coverage on $Z$, the following inequalities hold: \begin{align*}
\min_{ \eta \in [0, \alpha] } \tau^\iPR(\alpha; \eta) \leq \tau^\AR(\alpha), ~~
\min_{ s \in [0, \alpha] }  \tau^\aPR(\alpha; s) \leq \tau^\AR(\alpha) .
\end{align*}
\end{corollary}


\begin{proof}
(of Corollary \ref{corollary:compare_aPRCP_ARCP_appendix})
For adaptive PRCP, if $s = 0$, to achieve ($1-\alpha$)-probabilistically robust coverage over $Z$, we must have $\alpha^*_\aPR = 0$.
Since $\alpha^*_\aPR$ controls how aggressively we derive the robust quantile for $(X, Y)$, it indicates that we have to consider $1$-robust quantile.
This is equivalent to deriving the adversarial $S(X+\epsilon, Y)$ for all $(X, Y)$.



For inflated PRCP, if $\eta=0$, to achieve ($1-\alpha$)-probabilistically robust coverage, we have $M_{\delta, \eta} = M_\delta$ and $\alpha^*_\iPR = \alpha$, recovering ARCP (adversarially robust conformal prediction).
This case is exactly the same with adpative PRCP with $s=0$.
Therefore, $\tau^\AR(\alpha) = \tau^\iPR(\alpha; 0) = \tau^\aPR(\alpha; 0)$.


Note that $\min_{s \in [0, \alpha]} \tau^\aPR(\alpha; s) \leq \tau^\aPR(\alpha; 0)$ 
and $\min_{\eta\in [0, \alpha]} \tau^\iPR(\alpha; \eta) \leq \tau^\iPR(\alpha; 0)$,
so by tuning the value of $s$ for aPRCP and the value of $\eta$ for iPRCP, to achieve the same probabilistically robust coverage $1-\alpha$, we can have a more efficient threshold than ARCP.
\end{proof}


\begin{proposition}
\label{proposition:empirical_quantile_concentration_appendix}
(Proposition 3 restated, concentration inequality for quantiles)
Let $Q(\alpha) = \max\{ t : \P_V\{ V \leq t \} \geq 1 - \alpha \}$ be the true quantile of a random variable $V$ given $\alpha$,
and $\widehat Q_n(\alpha) = V_{ ( \lceil (n+1) ( 1 - \alpha ) \rceil ) }$ be the empirical quantile estimated by $n$ randomly sampled set $\{V_1, ..., V_n\}_{i=1}^n$.
Then with probability at least $1-\delta$, we have
$
\widehat Q_n(\alpha + \tilde O(1/\sqrt{n}))
\leq
Q(\alpha)
\leq
\widehat Q_n(\alpha - \tilde O(1/\sqrt{n}))
$  
where $\tilde O$ hides the logarithmic factor.
\end{proposition}

\begin{proof}
(of Proposition \ref{proposition:empirical_quantile_concentration_appendix})

Define $Z_i = \indicator{ [ V_i \leq Q(\alpha) ] }$ where $1 \leq i \leq n$ and $\indicator[\cdot]$ is an indicator function.
Then $Z_{i}$ is a Bernoulli random variable with $\P\{ Z_i = 1 \} = 1 - \alpha$ and $\P\{ Z_i = 0 \} = \alpha$ from the definition of $Q(\alpha)$.
Let $\widehat Z = \frac{1}{n} \sum_{i=1}^n Z_i$ and $\E[\widehat Z] = 1-\alpha.$


According to Chernoff bound, we know
\begin{align*}
\P\Bigg\{ \Bigg| \frac{1}{n} \sum_{i=1}^n Z_i - \E[\widehat Z] \Bigg| \geq \varepsilon \E[\widehat Z] \Bigg\}
\leq 
2 \exp\Bigg( - \E[\widehat Z] \varepsilon^2 / 3 \Bigg) 
=
2 \exp\Bigg( - n (1-\alpha) \varepsilon^2 / 3 \Bigg) .
\end{align*}


By setting $\delta = 2 \exp( - n (1-\alpha) \varepsilon^2 / 3 )$, i.e., $\varepsilon = \sqrt{ ( 3 \log(2/\delta) ) / ( ( 1 - \alpha ) n  ) }$, we have with probability at least $1-\delta$:
\begin{align}\label{eq:abs_bound}
\Bigg| \frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq Q(\alpha) ] - ( 1 - \alpha ) \Bigg| 
\leq 
\varepsilon ( 1 - \alpha )
=
\sqrt{ ( 3 ( 1 - \alpha )  \log(2/\delta) ) / n }
=
\tilde O(1 / \sqrt{n}) .
\end{align}


Recall the definition of the empirical quantile $\widehat Q_n(\alpha)$ given $\alpha$:
\begin{align*}
\widehat Q_n(\alpha) = \max\Bigg\{ t : \frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq t ] \geq 1 - \alpha \Bigg\} .
\end{align*}
Then we know the following upper bound and lower bound for $1-\alpha$:
\begin{align*}
( 1 - \alpha )
\leq 
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq \widehat Q_n(\alpha) ] , ~~~
( 1 - \alpha )
\geq 
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq \widehat Q_n(\alpha + 1 / n ) ] .
\end{align*}



Re-arranging (\ref{eq:abs_bound}) and using the above upper/lower bounds, with probability at least $1-\delta$, we have
\begin{align*}
&
( 1 - \alpha ) ( 1 - \varepsilon )
\leq 
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq Q(\alpha) ]
\leq 
( 1 - \alpha ) ( 1 + \varepsilon)
\\
\Leftrightarrow ~~~
& 
1 - ( \underbrace{ 1 - ( 1 - \alpha ) ( 1 - \varepsilon ) }_{ = \alpha' } )
\leq 
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq Q(\alpha) ]
\leq 
1 - ( \underbrace{ 1 - ( 1 - \alpha ) ( 1 + \varepsilon) }_{ = \alpha'' } )
\\
\Rightarrow ~~~ 
& 
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq \widehat Q_n( \alpha' + 1/n ) ]
\leq
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq Q(\alpha) ]
\leq 
\frac{1}{n} \sum_{i=1}^n \indicator[ V_i \leq \widehat Q_n( \alpha'' ) ] 
\\
\Leftrightarrow ~~~
&
\widehat Q_n(\alpha' + 1/n)
\leq 
Q(\alpha)
\leq 
\widehat Q_n(\alpha'') .
\end{align*}


Finally, we analyze $\alpha'$ and $\alpha''$ as follows
\begin{align*}
\alpha' 
=
1 - (1-\alpha) (1-\varepsilon)
=
\alpha + \varepsilon (1-\alpha)
=
\alpha + \sqrt{ 3 ( 1 - \alpha ) \log(2/\delta) / n }
=
\alpha + \tilde O(1/\sqrt{n}),
\\
\alpha''
=
1 - (1-\alpha) (1+\varepsilon)
=
\alpha - \varepsilon (1-\alpha)
=
\alpha - \sqrt{ 3 ( 1 - \alpha ) \log(2/\delta) / n }
=
\alpha - \tilde O(1/\sqrt{n}).
\end{align*}


Therefore, we have
\begin{align*}
\widehat Q_n(\alpha + \tilde O(1/\sqrt{n}))
\leq
Q(\alpha)
\leq
\widehat Q_n(\alpha - \tilde O(1/\sqrt{n})) .
\end{align*}
\end{proof}





\section{ADDITIONAL EXPERIMENTS AND IMPLEMENTATION DETAILS}

\textbf{Implementation details.}
Table \ref{tab:appendix_Acc_clean_adv} shows the testing accuracy of the different deep models using both standard training ($\sigma=0$) and Gaussian augmented training ($\sigma>0$). 
\begin{table*}[!h]
\centering
\begin{tabular}{|c|c|cc|cc|cc|}
\hline
\multirow{2}{*}{Architecture} & \multirow{2}{*}{Training} & \multicolumn{2}{c|}{CIFAR10}             & \multicolumn{2}{c|}{CIFAR100}            & \multicolumn{2}{c|}{ImageNet}            \\ \cline{3-8} 
                              &                                    & \multicolumn{1}{c|}{Clean(\%)} & Adv(\%) & \multicolumn{1}{c|}{Clean(\%)} & Adv(\%) & \multicolumn{1}{c|}{Clean(\%)} & Adv(\%) \\ \hline
\multirow{2}{*}{ResNet-110}   & $\sigma = 0.0$                                & \multicolumn{1}{c|}{89.99}     & 26.71   & \multicolumn{1}{c|}{71.12}     & 12.20   & \multicolumn{1}{c|}{-}         & -       \\ \cline{2-8} 
                              & $\sigma = 0.125$                              & \multicolumn{1}{c|}{81.70}     & 67.80   & \multicolumn{1}{c|}{58.11}     & 42.01   & \multicolumn{1}{c|}{-}         & -       \\ \hline
\multirow{2}{*}{VGG-19}       & $\sigma = 0.0$                                & \multicolumn{1}{c|}{93.10}     & 54.96   & \multicolumn{1}{c|}{72.22}     & 23.10   & \multicolumn{1}{c|}{-}         & -       \\ \cline{2-8} 
                              & $\sigma = 0.125$                              & \multicolumn{1}{c|}{86.50}     & 72.10   & \multicolumn{1}{c|}{55.12}     & 40.85   & \multicolumn{1}{c|}{-}         & -       \\ \hline
\multirow{2}{*}{DenseNet-161} & $\sigma = 0.0$                                & \multicolumn{1}{c|}{95.42}     & 23.28   & \multicolumn{1}{c|}{77.10}     & 04.30   & \multicolumn{1}{c|}{-}     & -   \\ \cline{2-8} 
                              & $\sigma = 0.125$                              & \multicolumn{1}{c|}{88.17}     & 73.15   & \multicolumn{1}{c|}{60.32}     & 46.91   & \multicolumn{1}{c|}{-}         & -       \\ \hline
\multirow{2}{*}{ResNet-50}    & $\sigma = 0.0$                                & \multicolumn{1}{c|}{-}         & -       & \multicolumn{1}{c|}{-}         & -       & \multicolumn{1}{c|}{75.69}     & 19.56   \\ \cline{2-8} 
                              & $\sigma = 0.250$                               & \multicolumn{1}{c|}{-}         & -       & \multicolumn{1}{c|}{-}         & -       & \multicolumn{1}{c|}{68.62}     & 56.15   \\ \hline
\end{tabular}
\caption{Testing accuracy of different deep models on clean and adversarial test examples (generated using the PGD attack algorithm) for all three data sets.}
\label{tab:appendix_Acc_clean_adv}
\end{table*}




\subsection{Case of Similar Noise Distribution for both Calibration  and Testing}
\noindent{\bf Performance evaluation with a fixed $s$ hyper-parameter and varying $\tilde{\alpha}$. }
We present in Figures \ref{C100_uni_cal_uni_eval_ratio_0.0PRCP_fixed_ns_cvg_Size_Both} and \ref{C10_uni_cal_uni_eval_ratio_0.0PRCP_fixed_ns_cvg_Size_Both}
the probabilistic robust coverage and prediction set size performance of aPRCP using \textit{the Uniform distribution as a noise distribution for both calibration and testing purposes} respectively for the CIFAR100 and CIFAR10 datasets with the three different models that are trained with clean data. Similarly, we present in Figures \ref{C100_gaussian_cal_gaussian_eval_ratio_0.0PRCP_fixed_ns_cvg_Size_Both} and \ref{C10_gaussian_cal_gaussian_eval_ratio_0.0PRCP_fixed_ns_cvg_Size_Both}
the probabilistic robust coverage and prediction set size performance of aPRCP using \textit{the Gaussian distribution as a noise distribution for both calibration and testing purposes}. For calibration, we sample $m_s = 128$ noisy data points from the surrounding of each data point ($||\epsilon||_2 \leq 0.125$). For testing, we sample $n_s = 128$ data points from the surrounding of each testing point ($||\epsilon||_2 \leq 0.125$). We observe that the probabilistic robust coverage for noisy data increases monotonically as we increase the quantile robust coverage for each ball from $1 - \tilde{\alpha} = 0.90$ to $1 - \tilde{\alpha} = 1.0$. These observations hold for both conformal scores (HPS and APS) and using different deep neural network models. 




% Figure environment removed

% Figure environment removed


% Figure environment removed
\clearpage
% Figure environment removed


\noindent{\bf Performance evaluation with a fixed $\tilde{\alpha}$ hyper-parameter and varying $s$.}

Figures \ref{C100_s_changes_ratio_0.0PRCP_fixed_ns_cvg_Size_Both} and \ref{C10_s_changes_ratio_0.0PRCP_fixed_ns_cvg_Size_Both}
show the probabilistic robust coverage and prediction set size respectively for the CIFAR100 and CIFAR10 datasets with three different deep models that are trained using standard training. For calibration, we sample $m_s = 128$ noisy data points using the uniform sampling distribution from the surrounding of each data point ($||\epsilon||_2 \leq 0.125$). For testing, we sample $n_s = 128$ data points uniformly from the surrounding of each testing point ($||\epsilon||_2 \leq 0.125$). We observe that the probabilistic robust coverage for noisy data increases as we increase the $s$ parameter value from $0.0$ to $0.09$. This observation matches our proposition as a higher $s$ value produces higher coverage. The above observations hold for both conformal scores (APS and HPS) using different deep neural network models. 

% Figure environment removed


% Figure environment removed


\noindent{\bf Performance evaluation with fixed $s$ and $\tilde{\alpha}$ hyper-parameter and varying sampling radius ($||\epsilon||_2 \leq r$) around test samples.}
Figures \ref{C10_delta_changes_cvg} and \ref{C10_delta_changes_size}
present the probabilistic robust coverage and the prediction set size respectively for the CIFAR10 dataset. Similarly, figures \ref{C100_delta_changes_cvg} and \ref{C100_delta_changes_size}
present probabilistic robust coverage and prediction set size for the CIFAR100 dataset. We employ three different deep models that are trained with clean data. For calibration, we sample $m_s = 128$ noisy data points using the uniform sampling distribution from the surrounding of each data point ($||\epsilon||_2 \leq 0.125$), where $\epsilon$ is sampled uniformly over the segment $[0, 0.125]$. For testing, we sample $n_s = 128$ data points uniformly from the surrounding of each testing point ($||\epsilon||_2 \leq \{1.0, 2.0, 3.0\}$), where $\epsilon$ is uniformly sampled over the segment $[0, 1], [0, 2], [0, 3]$ respectively.  
We observe that the probabilistic robust coverage for noisy data decays as we increase the sampling radius. Additionally, we note that when we set the $d$ parameter to $0.1$ (accounting for the change in noise distribution between calibration and testing as per Theorem 2), we guarantee achieving the target coverage. These observations hold for both conformal scores (APS and HPS) using different deep neural network models. 



% Figure environment removed

% Figure environment removed

% Figure environment removed


\clearpage

% Figure environment removed


\subsection{Case of Dissimilar Noise Distributions for Calibration and Testing}
\noindent{\bf Gaussian distribution for Calibration  and  Uniform distribution for Testing with a fixed $s$ hyper-parameter and varying $\tilde{\alpha}$.}
Figures \ref{C100_gaussian_cal_uni_eval_ratio_0.0PRCP_fixed_ns_cvg_Size_Both} and \ref{C10_gaussian_cal_uni_eval_ratio_0.0PRCP_fixed_ns_cvg_Size_Both} present probabilistic robust coverage and prediction set size respectively for the CIFAR100 and CIFAR10 datasets with  three different deep models that are trained with clean data. For calibration, we sample $m_s = 128$ data points using the Gaussian sampling distribution from the surrounding of each data point($||\epsilon||_2 \leq 0.125$). For testing, we sample $n_s = 128$ data points uniformly from the surrounding of each testing point($||\epsilon||_2 \leq 0.125$). We observe that the probabilistic robust coverage increased over the case of using the same distribution for sampling during the testing and calibration phases. 

% Figure environment removed

% Figure environment removed


\noindent{\bf Uniform distribution for Calibration and  Gaussian distribution for Testing with a fixed $s$ hyper-parameter and varying $\tilde{\alpha}$.}
Figures \ref{uni_cal_C100_fixed_ms_APS_HPS_sigma_0_0_cvg} and \ref{uni_cal_C100_fixed_ms_APS_HPS_sigma_0_0_size} present probabilistic robust coverage and prediction size for CIFAR100 and CIFAR10 datasets respectively with three different deep models that are trained with clean data. For calibration, we sample $m_s = 128$ data points using the Uniform sampling distribution from the surrounding of each data point ($||\epsilon||_2 \leq 0.125$). For testing, we sample $n_s = 128$ data points using Gaussian distribution from the surrounding of each testing point ($||\epsilon||_2 \leq 0.125$). We observe a slightly different performance of aPRCP compared to the case of using the same distribution for noise during the testing and calibration phases. This observation corroborate the statement of Theorem 2 and Remark 2 explaining the relation between the gap of the density probability between the calibration and testing noise distributions with the probabilistic robust coverage for aPRCP.

% Figure environment removed

% Figure environment removed



\clearpage

\subsection{Performance of \texttt{aPRCP(worst-adv)} with varying $m_s$}
Figures \ref{C10_ms_APS_HPS_sigma_0.25} and \ref{C100_ms_APS_HPS_sigma_0.25} show the performance of aPRCP with three different deep models when varying $m_s$ (number of noisy samples for calibration) for CIFAR10 and CIFAR100 datasets respectively. We show the robust coverage and prediction set size for both \texttt{APS} and \texttt{HPS} conformity scores. Both figures show that the \texttt{aPRCP(worst-adv)} reported performance is consistent for different values of $m_s$.

We show in Figure \ref{C100_ms_APS_HPS_ARCPworstadv_RSCP} the comparison of the prediction set size and the coverage between \texttt{RSCP} and \texttt{aPRCP(worst-adv)} using both \texttt{APS} and \texttt{HPS}. We employ ResNet110 model trained with Gaussian augmented data ($\sigma = 0.125$). We observe that \texttt{RSCP} is more conservative compared to our method \texttt{aPRCP(worst-adv)} for both \texttt{APS} and \texttt{HPS} conformity scores.

We show in Figure \ref{C10_ms_APS_ARCPworstadv_RSCP_different_sigma} and \ref{C100_ms_APS_ARCPworstadv_RSCP_different_sigma} the comparison of the  prediction set size and coverage between \texttt{RSCP} and \texttt{aPRCP(worst-adv)} for two different deep models trained with Gaussian augmented data ($\sigma = 0.0625$ and $\sigma = 0.125$). We observe that \texttt{aPRCP(worst-adv)} produces smaller prediction sets than \texttt{RSCP}.



% Figure environment removed

% Figure environment removed

% Figure environment removed


% Figure environment removed


% Figure environment removed

\clearpage
\subsection{The effect of Varying $||\epsilon||_2 \leq r$ during calibration}
We show in Figure \ref{fig:C100_radius_changes_worst_adv} 
the robust coverage and the prediction set size achieved by aPRCP(worst-adv) on CIFAR100 with a ResNet model that is trained with Gaussian augmented data ($\sigma = 0.125$). For calibration, we sample $m_s = 128$ noisy data points using the uniform sampling distribution from the surrounding of each data point ($||\epsilon||_2 \leq r$), where $r = \{0.125, 0.250, 1.0\}$. For testing, we generate data using an adversarial attack algorithm of energy $0.125$. We observe that the effect of the small changes in the sampling radius is negligible.
% Figure environment removed


\subsection{Performance of aPRCP(worst-adv) with different Deep models}
Figure \ref{arcp_model_changes_C10_C100} shows the performance of our \texttt{aPRCP}(worst-adv) using DenseNet\citep{iandola2014densenet} and VGG\citep{simonyan2014very} models on the CIFAR10 and CIFAR100 datasets. We use the same adversarial attack algorithm for test examples with a magnitude of $r = 0.125$. During calibration, we sample $m_s = 128$ noisy samples ($r = 0.125$) for each calibration example. We observe that the robust coverage is achieved on all three deep models with small prediction sets.

% Figure environment removed

\clearpage 

\subsection{Results on Adversarial Examples Generated from a probability density distribution}
We evaluate the performance of aPRCP with a  different adversarial attack algorithm, namely NATTACK \citep{Black_box}. This attack algorithm generates a probability density distribution centered around an input from which adversarial examples can be sampled.
We employ this algorithm using an adversarial magnitude $||\epsilon||_2 \leq r = 0.125$ to generate adversarial examples for the test data of CIFAR10 and CIFAR100 on three different deep models trained with Gaussian augmented data ($\sigma = 0.125$). In all our experiments, we set $T = 1000$ as the number of maximum iterations, and a learning rate $\eta = 0.008$.

Both Figures \ref{All_blackBox_C10} and \ref{All_blackBox_C100} show that aPRCP is the only algorithm that can guarantee the adversarial robust coverage. This can be explained by the fact that RSCP requires the design of a specialized scoring function to guarantee coverage while aPRCP uses a quantile-of-quantile design and can employ any existing score function.

% Figure environment removed


% Figure environment removed



\subsection{Importance of Gaussian Augmented Training}
While aPRCP can work without any assumption on the base classifier, Figure \ref{Why_gaussian_training_C10} shows the importance of the model robustness to produce smaller prediction sets. Both \texttt{RSCP} and \texttt{aPRCP}(worst-adv) construct prediction sets that are larger when the base model is not adversarially robust.
% Figure environment removed

\subsection{aPRCP nominal performance}
Figure \ref{Clean_data_results} shows a comparison of the nominal performance (evaluation on only clean inputs) on CIFAR10 and CIFAR100 datasets. We employ $m_s = 128$ for calibration and standard training to train the base model. We can observe that aPRCP achieves better trade-off between the nominal performance (evaluation on clean inputs) and the robust performance (evaluation on perturbed inputs). For both datasets, aPRCP achieves a tighter empirical coverage (closer to 90\%) with smaller prediction sets than RSCP.


% Figure environment removed
