{
  "title": "TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition",
  "authors": [
    "Shilin Lu",
    "Yanzhu Liu",
    "Adams Wai-Kin Kong"
  ],
  "submission_date": "2023-07-24T02:50:44+00:00",
  "revised_dates": [
    "2023-07-26T00:35:07+00:00",
    "2023-10-10T00:39:13+00:00",
    "2023-10-11T00:15:11+00:00"
  ],
  "abstract": "Text-driven diffusion models have exhibited impressive generative capabilities, enabling various image editing tasks. In this paper, we propose TF-ICON, a novel Training-Free Image COmpositioN framework that harnesses the power of text-driven diffusion models for cross-domain image-guided composition. This task aims to seamlessly integrate user-provided objects into a specific visual context. Current diffusion-based methods often involve costly instance-based optimization or finetuning of pretrained models on customized datasets, which can potentially undermine their rich prior. In contrast, TF-ICON can leverage off-the-shelf diffusion models to perform cross-domain image-guided composition without requiring additional training, finetuning, or optimization. Moreover, we introduce the exceptional prompt, which contains no information, to facilitate text-driven diffusion models in accurately inverting real images into latent representations, forming the basis for compositing. Our experiments show that equipping Stable Diffusion with the exceptional prompt outperforms state-of-the-art inversion methods on various datasets (CelebA-HQ, COCO, and ImageNet), and that TF-ICON surpasses prior baselines in versatile visual domains. Code is available at https://github.com/Shilin-LU/TF-ICON",
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.12493",
  "pdf_url": null,
  "comment": "Accepted by ICCV 2023",
  "num_versions": null,
  "size_before_bytes": 140541906,
  "size_after_bytes": 3246756
}