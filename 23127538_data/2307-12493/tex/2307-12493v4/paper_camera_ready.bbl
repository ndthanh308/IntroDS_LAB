\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{abdal2019image2stylegan}
Rameen Abdal, Yipeng Qin, and Peter Wonka.
\newblock Image2stylegan: How to embed images into the stylegan latent space?
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4432--4441, 2019.

\bibitem{abdal2020image2stylegan}
Rameen Abdal, Yipeng Qin, and Peter Wonka.
\newblock Image2stylegan++: How to edit the embedded images?
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 8296--8305, 2020.

\bibitem{alaluf2021restyle}
Yuval Alaluf, Or Patashnik, and Daniel Cohen-Or.
\newblock Restyle: A residual-based stylegan encoder via iterative refinement.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6711--6720, 2021.

\bibitem{alaluf2022hyperstyle}
Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, and Amit Bermano.
\newblock Hyperstyle: Stylegan inversion with hypernetworks for real image
  editing.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer Vision and
  pattern recognition}, pages 18511--18521, 2022.

\bibitem{avrahami2022blended_latent}
Omri Avrahami, Ohad Fried, and Dani Lischinski.
\newblock Blended latent diffusion.
\newblock {\em arXiv preprint arXiv:2206.02779}, 2022.

\bibitem{avrahami2022blended}
Omri Avrahami, Dani Lischinski, and Ohad Fried.
\newblock Blended diffusion for text-driven editing of natural images.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18208--18218, 2022.

\bibitem{azadi2020compositional}
Samaneh Azadi, Deepak Pathak, Sayna Ebrahimi, and Trevor Darrell.
\newblock Compositional gan: Learning image-conditional binary composition.
\newblock {\em International Journal of Computer Vision}, 128(10):2570--2585,
  2020.

\bibitem{brown2022end}
Andrew Brown, Cheng-Yang Fu, Omkar Parkhi, Tamara~L Berg, and Andrea Vedaldi.
\newblock End-to-end visual editing with a generatively pre-trained artist.
\newblock {\em arXiv preprint arXiv:2205.01668}, 2022.

\bibitem{cai2022diffdreamer}
Shengqu Cai, Eric~Ryan Chan, Songyou Peng, Mohamad Shahbazi, Anton Obukhov, Luc
  Van~Gool, and Gordon Wetzstein.
\newblock Diffdreamer: Consistent single-view perpetual view generation with
  conditional diffusion models.
\newblock {\em arXiv preprint arXiv:2211.12131}, 2022.

\bibitem{cao2023painterly}
Junyan Cao, Yan Hong, and Li Niu.
\newblock Painterly image harmonization in dual domains.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~37, pages 268--276, 2023.

\bibitem{chang2023muse}
Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang,
  Ming-Hsuan Yang, Kevin Murphy, William~T Freeman, Michael Rubinstein, et~al.
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock {\em arXiv preprint arXiv:2301.00704}, 2023.

\bibitem{chefer2023attend}
Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, and Daniel Cohen-Or.
\newblock Attend-and-excite: Attention-based semantic guidance for
  text-to-image diffusion models.
\newblock {\em arXiv preprint arXiv:2301.13826}, 2023.

\bibitem{chen2019toward}
Bor-Chun Chen and Andrew Kae.
\newblock Toward realistic image compositing with adversarial learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8415--8424, 2019.

\bibitem{choi2022perception}
Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon Kim, Hyunwoo Kim, and
  Sungroh Yoon.
\newblock Perception prioritized training of diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11472--11481, 2022.

\bibitem{cong2020dovenet}
Wenyan Cong, Jianfu Zhang, Li Niu, Liu Liu, Zhixin Ling, Weiyuan Li, and Liqing
  Zhang.
\newblock Dovenet: Deep image harmonization via domain verification.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8394--8403, 2020.

\bibitem{couairon2022diffedit}
Guillaume Couairon, Jakob Verbeek, Holger Schwenk, and Matthieu Cord.
\newblock Diffedit: Diffusion-based semantic image editing with mask guidance.
\newblock {\em arXiv preprint arXiv:2210.11427}, 2022.

\bibitem{cun2020improving}
Xiaodong Cun and Chi-Man Pun.
\newblock Improving the harmony of the composite image by spatial-separated
  attention module.
\newblock {\em IEEE Transactions on Image Processing}, 29:4759--4771, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems},
  34:8780--8794, 2021.

\bibitem{ding2022cogview2}
Ming Ding, Wendi Zheng, Wenyi Hong, and Jie Tang.
\newblock Cogview2: Faster and better text-to-image generation via hierarchical
  transformers.
\newblock {\em arXiv preprint arXiv:2204.14217}, 2022.

\bibitem{dwibedi2017cut}
Debidatta Dwibedi, Ishan Misra, and Martial Hebert.
\newblock Cut, paste and learn: Surprisingly easy synthesis for instance
  detection.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 1301--1310, 2017.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 12873--12883, 2021.

\bibitem{everingham2009pascal}
Mark Everingham, Luc Van~Gool, Christopher~KI Williams, John Winn, and Andrew
  Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock {\em International journal of computer vision}, 88:303--308, 2009.

\bibitem{feng2022training}
Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna
  Narayana, Sugato Basu, Xin~Eric Wang, and William~Yang Wang.
\newblock Training-free structured diffusion guidance for compositional
  text-to-image synthesis.
\newblock {\em arXiv preprint arXiv:2212.05032}, 2022.

\bibitem{gafni2020wish}
Oran Gafni and Lior Wolf.
\newblock Wish you were here: Context-aware human generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7840--7849, 2020.

\bibitem{gal2022image}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit~H Bermano, Gal
  Chechik, and Daniel Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation
  using textual inversion.
\newblock {\em arXiv preprint arXiv:2208.01618}, 2022.

\bibitem{gal2023designing}
Rinon Gal, Moab Arar, Yuval Atzmon, Amit~H Bermano, Gal Chechik, and Daniel
  Cohen-Or.
\newblock Designing an encoder for fast personalization of text-to-image
  models.
\newblock {\em arXiv preprint arXiv:2302.12228}, 2023.

\bibitem{hertz2022prompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel
  Cohen-Or.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock {\em arXiv preprint arXiv:2208.01626}, 2022.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6840--6851, 2020.

\bibitem{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock {\em arXiv preprint arXiv:2207.12598}, 2022.

\bibitem{hong2022shadow}
Yan Hong, Li Niu, and Jianfu Zhang.
\newblock Shadow generation for composite image in real-world scenes.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 914--922, 2022.

\bibitem{jiang2021ssh}
Yifan Jiang, He Zhang, Jianming Zhang, Yilin Wang, Zhe Lin, Kalyan Sunkavalli,
  Simon Chen, Sohrab Amirghodsi, Sarah Kong, and Zhangyang Wang.
\newblock Ssh: A self-supervised framework for image harmonization.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4832--4841, 2021.

\bibitem{karras2017progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock {\em arXiv preprint arXiv:1710.10196}, 2017.

\bibitem{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock {\em arXiv preprint arXiv:2206.00364}, 2022.

\bibitem{karras2020analyzing}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
  Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 8110--8119, 2020.

\bibitem{kawar2022imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar
  Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock {\em arXiv preprint arXiv:2210.09276}, 2022.

\bibitem{kim2022diffusionclip}
Gwanghyun Kim, Taesung Kwon, and Jong~Chul Ye.
\newblock Diffusionclip: Text-guided diffusion models for robust image
  manipulation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2426--2435, 2022.

\bibitem{kingma2021variational}
Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock Variational diffusion models.
\newblock {\em Advances in neural information processing systems},
  34:21696--21707, 2021.

\bibitem{kumari2022multi}
Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu.
\newblock Multi-concept customization of text-to-image diffusion.
\newblock {\em arXiv preprint arXiv:2212.04488}, 2022.

\bibitem{kuznetsova2020open}
Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi
  Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander
  Kolesnikov, et~al.
\newblock The open images dataset v4: Unified image classification, object
  detection, and visual relationship detection at scale.
\newblock {\em International Journal of Computer Vision}, 128(7):1956--1981,
  2020.

\bibitem{kwon2022diffusionb}
Mingi Kwon, Jaeseok Jeong, and Youngjung Uh.
\newblock Diffusion models already have a semantic latent space.
\newblock {\em arXiv preprint arXiv:2210.10960}, 2022.

\bibitem{li2023gligen}
Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao,
  Chunyuan Li, and Yong~Jae Lee.
\newblock Gligen: Open-set grounded text-to-image generation.
\newblock 2023.

\bibitem{lin2018st}
Chen-Hsuan Lin, Ersin Yumer, Oliver Wang, Eli Shechtman, and Simon Lucey.
\newblock St-gan: Spatial transformer generative adversarial networks for image
  compositing.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 9455--9464, 2018.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich,
  Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755.
  Springer, 2014.

\bibitem{liu2020arshadowgan}
Daquan Liu, Chengjiang Long, Hongpan Zhang, Hanning Yu, Xinzhi Dong, and
  Chunxia Xiao.
\newblock Arshadowgan: Shadow generative adversarial network for augmented
  reality in single light scenes.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8139--8148, 2020.

\bibitem{liu2021opa}
Liu Liu, Zhenchen Liu, Bo Zhang, Jiangtong Li, Li Niu, Qingyang Liu, and Liqing
  Zhang.
\newblock Opa: object placement assessment dataset.
\newblock {\em arXiv preprint arXiv:2107.01889}, 2021.

\bibitem{liu2022pseudo}
Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao.
\newblock Pseudo numerical methods for diffusion models on manifolds.
\newblock {\em arXiv preprint arXiv:2202.09778}, 2022.

\bibitem{liu2022compositional}
Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua~B Tenenbaum.
\newblock Compositional visual generation with composable diffusion models.
\newblock {\em arXiv preprint arXiv:2206.01714}, 2022.

\bibitem{lu2022dpma}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model
  sampling in around 10 steps.
\newblock {\em arXiv preprint arXiv:2206.00927}, 2022.

\bibitem{lu2022dpmb}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver++: Fast solver for guided sampling of diffusion
  probabilistic models.
\newblock {\em arXiv preprint arXiv:2211.01095}, 2022.

\bibitem{lu2023painterly}
Lingxiao Lu, Jiangtong Li, Junyan Cao, Li Niu, and Liqing Zhang.
\newblock Painterly image harmonization using diffusion model.
\newblock {\em arXiv preprint arXiv:2308.02228}, 2023.

\bibitem{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and
  Stefano Ermon.
\newblock Sdedit: Guided image synthesis and editing with stochastic
  differential equations.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{mildenhall2021nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock {\em Communications of the ACM}, 65(1):99--106, 2021.

\bibitem{mokady2022null}
Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Null-text inversion for editing real images using guided diffusion
  models.
\newblock {\em arXiv preprint arXiv:2211.09794}, 2022.

\bibitem{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock {\em arXiv preprint arXiv:2112.10741}, 2021.

\bibitem{niu2021making}
Li Niu, Wenyan Cong, Liu Liu, Yan Hong, Bo Zhang, Jing Liang, and Liqing Zhang.
\newblock Making images real again: A comprehensive survey on deep image
  composition.
\newblock {\em arXiv preprint arXiv:2106.14490}, 2021.

\bibitem{parmar2023zero}
Gaurav Parmar, Krishna~Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, and
  Jun-Yan Zhu.
\newblock Zero-shot image-to-image translation.
\newblock {\em arXiv preprint arXiv:2302.03027}, 2023.

\bibitem{patashnik2021styleclip}
Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski.
\newblock Styleclip: Text-driven manipulation of stylegan imagery.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2085--2094, 2021.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{richardson2021encoding}
Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav
  Shapiro, and Daniel Cohen-Or.
\newblock Encoding in style: a stylegan encoder for image-to-image translation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 2287--2296, 2021.

\bibitem{roich2022pivotal}
Daniel Roich, Ron Mokady, Amit~H Bermano, and Daniel Cohen-Or.
\newblock Pivotal tuning for latent-based editing of real images.
\newblock {\em ACM Transactions on Graphics (TOG)}, 42(1):1--13, 2022.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{ruiz2022dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and
  Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for
  subject-driven generation.
\newblock {\em arXiv preprint arXiv:2208.12242}, 2022.

\bibitem{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily
  Denton, Seyed Kamyar~Seyed Ghasemipour, Burcu~Karagol Ayan, S~Sara Mahdavi,
  Rapha~Gontijo Lopes, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock {\em arXiv preprint arXiv:2205.11487}, 2022.

\bibitem{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock {\em arXiv preprint arXiv:2202.00512}, 2022.

\bibitem{schuhmann2022laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock {\em arXiv preprint arXiv:2210.08402}, 2022.

\bibitem{sheng2021ssn}
Yichen Sheng, Jianming Zhang, and Bedrich Benes.
\newblock Ssn: Soft shadow network for image compositing.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4380--4390, 2021.

\bibitem{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock {\em arXiv preprint arXiv:2010.02502}, 2020.

\bibitem{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2011.13456}, 2020.

\bibitem{song2022objectstitch}
Yizhi Song, Zhifei Zhang, Zhe Lin, Scott Cohen, Brian Price, Jianming Zhang,
  Soo~Ye Kim, and Daniel Aliaga.
\newblock Objectstitch: Generative object compositing.
\newblock {\em arXiv preprint arXiv:2212.00932}, 2022.

\bibitem{tov2021designing}
Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, and Daniel Cohen-Or.
\newblock Designing an encoder for stylegan image manipulation.
\newblock {\em ACM Transactions on Graphics (TOG)}, 40(4):1--14, 2021.

\bibitem{tripathi2019learning}
Shashank Tripathi, Siddhartha Chandra, Amit Agrawal, Ambrish Tyagi, James~M
  Rehg, and Visesh Chari.
\newblock Learning to generate synthetic data via compositing.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 461--470, 2019.

\bibitem{tumanyan2022plug}
Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel.
\newblock Plug-and-play diffusion features for text-driven image-to-image
  translation.
\newblock {\em arXiv preprint arXiv:2211.12572}, 2022.

\bibitem{wallace2022edict}
Bram Wallace, Akash Gokul, and Nikhil Naik.
\newblock Edict: Exact diffusion inversion via coupled transformations.
\newblock {\em arXiv preprint arXiv:2211.12446}, 2022.

\bibitem{wang2022score}
Haochen Wang, Xiaodan Du, Jiahao Li, Raymond~A Yeh, and Greg Shakhnarovich.
\newblock Score jacobian chaining: Lifting pretrained 2d diffusion models for
  3d generation.
\newblock {\em arXiv preprint arXiv:2212.00774}, 2022.

\bibitem{wang2022high}
Tengfei Wang, Yong Zhang, Yanbo Fan, Jue Wang, and Qifeng Chen.
\newblock High-fidelity gan inversion for image attribute editing.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11379--11388, 2022.

\bibitem{witteveen2022investigating}
Sam Witteveen and Martin Andrews.
\newblock Investigating prompt engineering in diffusion models.
\newblock {\em arXiv preprint arXiv:2211.15462}, 2022.

\bibitem{wu2019gp}
Huikai Wu, Shuai Zheng, Junge Zhang, and Kaiqi Huang.
\newblock Gp-gan: Towards realistic high-resolution image blending.
\newblock In {\em Proceedings of the 27th ACM international conference on
  multimedia}, pages 2487--2495, 2019.

\bibitem{xue2022dccf}
Ben Xue, Shenghui Ran, Quan Chen, Rongfei Jia, Binqiang Zhao, and Xing Tang.
\newblock Dccf: Deep comprehensible color filter learning framework for
  high-resolution image harmonization.
\newblock In {\em European Conference on Computer Vision}, pages 300--316.
  Springer, 2022.

\bibitem{yang2022paint}
Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong
  Chen, and Fang Wen.
\newblock Paint by example: Exemplar-based image editing with diffusion models.
\newblock {\em arXiv preprint arXiv:2211.13227}, 2022.

\bibitem{yu2022scaling}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang,
  Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, et~al.
\newblock Scaling autoregressive models for content-rich text-to-image
  generation.
\newblock {\em arXiv preprint arXiv:2206.10789}, 2022.

\bibitem{zhang2021deep}
He Zhang, Jianming Zhang, Federico Perazzi, Zhe Lin, and Vishal~M Patel.
\newblock Deep image compositing.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 365--374, 2021.

\bibitem{zhang2020learning}
Lingzhi Zhang, Tarmily Wen, Jie Min, Jiancong Wang, David Han, and Jianbo Shi.
\newblock Learning object placement by inpainting for compositional data
  augmentation.
\newblock In {\em European Conference on Computer Vision}, pages 566--581.
  Springer, 2020.

\bibitem{zhang2020deep}
Lingzhi Zhang, Tarmily Wen, and Jianbo Shi.
\newblock Deep image blending.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 231--240, 2020.

\bibitem{zhang2018perceptual}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em CVPR}, 2018.

\bibitem{zhang2019shadowgan}
Shuyang Zhang, Runze Liang, and Miao Wang.
\newblock Shadowgan: Shadow synthesis for virtual objects with conditional
  adversarial networks.
\newblock {\em Computational Visual Media}, 5(1):105--115, 2019.

\bibitem{zhang2021k}
Wenwei Zhang, Jiangmiao Pang, Kai Chen, and Chen~Change Loy.
\newblock K-net: Towards unified image segmentation.
\newblock {\em Advances in Neural Information Processing Systems},
  34:10326--10338, 2021.

\end{thebibliography}
