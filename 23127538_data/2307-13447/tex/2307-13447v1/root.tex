%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{float}
\usepackage[caption=false,font=footnotesize]{subfig}

\title{\LARGE \bf
% A behavioural transformer that enables robots to collaborate with previously unseen simulated (non-stationary) humans

A behavioural transformer for effective collaboration between a robot and a non-stationary human
}


\author{Ruaridh Mon-Williams$^{1}$, Theodoros Stouraitis$^{2}$ and Sethu Vijayakumar$^{1,3}$% <-this % stops a space
\thanks{*This work was supported by the Edinburgh Centre for Robotics.}% <-this % stops a space
\thanks{$^{1}$Ruaridh Mon-Williams and Sethu Vijayakumar are with the School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, U.K. (e-mail:
ruaridh.mw@ed.ac.uk, sethu.vijayakumar@ed.ac.uk)}%
\thanks{$^{2}$Theodoros Stouraitis is with the Honda Research
Institute Europe (HRI-EU), 63073 Offenbach am Main, Germany (e-mail:
theostou@honda-ri.de).%
}
\thanks{$^{3}$Sethu Vijayakumar is also with The Alan Turing Institute, London, U.K.}}

% ru added package
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{float} % to force figure placement
\usepackage{cleveref}

\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[style=ieee]{biblatex}
\addbibresource{references.bib}

\usepackage{xcolor}

\newcommand{\theo}[1]{{\color{green}#1}}

\newcommand{\ruaridh}[1]{{\color{blue}#1}}


\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\input{sections/abstract.tex}
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

\input{sections/introduction.tex}

% \section{RELATED WORK}

\input{sections/related_work/related_work.tex}

% \section{SOLUTION CONCEPT}
\section{PROBLEM DESCRIPTION}

\input{sections/preliminaries.tex}

% \section{PROBLEM FORMULATION}

\input{sections/problem_statement/problem_statement.tex}

\section{THE PROPOSED APPROACH}

\input{sections/proposed_approach/the_proposed_approach.tex}

\section{RESULTS}
\input{sections/experiment/experiment.tex}

% \section{RESULTS}
\input{sections/results/results}

\section{CONCLUSIONS}
\input{sections/conclusions}


% \addtolength{\textheight}{-12cm}   




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \bibliographystyle{IEEEtran}
% \bibliography{references.bib}

% \renewcommand*{\bibfont}{\footnotesize}

% \printbibliography

\begin{thebibliography}{99}

 \bibitem{c1} A. Xie, D. P. Losey, R. Tolsma, C. Finn, and D. Sadigh, "Learning Latent Representations to Influence Multi-Agent Interaction," arXiv, Tech. Rep. arXiv:2011.06619, Nov. 2020. [Online]. Available: http://arxiv.org/abs/2011.06619.

\bibitem{2} H. Nguyen and H. La, "Review of Deep Reinforcement Learning for Robot Manipulation," in 2019 Third IEEE International Conference on Robotic Computing (IRC), Naples, Italy, Feb. 2019, pp. 590-595. DOI: 10.1109/IRC.2019.00120. [Online]. Available: https://ieeexplore.ieee.org/document/8675643/.

\bibitem{3} T. Stouraitis, I. Chatzinikolaidis, M. Gienger, and S. Vijayakumar, "Online Hybrid Motion Planning for Dyadic Collaborative Manipulation via Bilevel Optimization," IEEE Transactions on Robotics, vol. 36, no. 5, pp. 1452-1471, Oct. 2020. DOI: 10.1109/TRO.2020.2992987. [Online]. Available: https://ieeexplore.ieee.org/document/9166536/.

\bibitem{4} S. S. Obhi and N. Sebanz, "Moving together: Toward understanding the mechanisms of joint action," Experimental Brain Research, vol. 211, no. 3-4, pp. 329-336, Jun. 2011. DOI: 10.1007/s00221-011-2721-0. [Online]. Available: http://link.springer.com/10.1007/s00221-011-2721-0.

\bibitem{5} T. B. Sheridan, "Eight ultimate challenges of human-robot communication," in Proceedings 6th IEEE International Workshop on Robot and Human Communication (RO-MAN '97), Sendai, 1997, pp. 9-14. DOI: 10.1109/ROMAN.1997.646944.

\bibitem{6} D.-K. Kim, M. Riemer, M. Liu, et al., "Influencing Long-Term Behavior in Multiagent Reinforcement Learning," arXiv, Tech. Rep. arXiv:2203.03535, May 2022. [Online]. Available: http://arxiv.org/abs/2203.03535.

\bibitem{7} M. Yang, M. Carroll, and A. Dragan, "Optimal Behavior Prior: Data-Efficient Human Models for Improved Human-AI Collaboration," arXiv, Tech. Rep. arXiv:2211.01602, Nov. 2022. [Online]. Available: http://arxiv.org/abs/2211.01602.

\bibitem{8} A. Bobu, D. R. R. Scobee, J. F. Fisac, S. S. Sastry, and A. D. Dragan, "LESS is More: Rethinking Probabilistic Models of Human Behavior," in Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction, Cambridge, United Kingdom, Mar. 2020, pp. 429-437. DOI: 10.1145/3319502.3374811. [Online]. Available: https://dl.acm.org/doi/10.1145/331.

\bibitem{9} T. Nomura, T. Kanda, T. Suzuki, and K. Kato, "Prediction of Human Behavior in Human–Robot Interaction Using Psychological Scales for Anxiety and Negative Attitudes Toward Robots," IEEE Transactions on Robotics, vol. 24, no. 2, pp. 442-451, Apr. 2008. DOI: 10.1109/TRO.2007.914004. [Online]. Available: http://ieeexplore.ieee.org/document/4481184/.

\bibitem{10} S. Nikolaidis, Y. X. Zhu, D. Hsu, and S. Srinivasa, "Human-Robot Mutual Adaptation in Shared Autonomy," in Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, Vienna, Austria, Mar. 2017, pp. 294-302. DOI: 10.1145/2909824.3020252. [Online]. Available: https://dl.acm.org/doi/10.1145/2909824.3020252.

\bibitem{11} G. Papoudakis, F. Christianos, A. Rahman, and S. V. Albrecht, "Dealing with non-stationarity in multi-agent deep reinforcement learning," arXiv preprint arXiv:1906.04737, 2019. [Online]. Available: https://arxiv.org/abs/1906.04737.

\bibitem{12} S. V. Albrecht and P. Stone, "Autonomous agents modelling other agents: A comprehensive survey and open problems," Artificial Intelligence, vol. 258, pp. 66-95, May 2018. DOI: 10.1016/j.artint.2018.01.002. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0004370218300249.

\bibitem{13} W. Z. Wang, A. Shih, A. Xie, and D. Sadigh, "Influencing towards stable multi-agent interactions," in Conference on Robot Learning, PMLR, 2022, pp. 1132-1143.

\bibitem{14} S. Parekh, S. Habibian, and D. P. Losey, "RILI: Robustly Influencing Latent Intent," arXiv, Tech. Rep. arXiv:2203.12705, Jul. 2022. [Online]. Available: http://arxiv.org/abs/2203.12705.

\bibitem{15} S. Karita, N. Chen, T. Hayashi, et al., "A Comparative Study on Transformer vs RNN in Speech Applications," in 2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), Dec. 2019, pp. 449-456. DOI: 10.1109/ASRU46091.2019.9003750. [Online]. Available: http://arxiv.org/abs/1909.06317.

\bibitem{16} A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al., "Language models are unsupervised multitask learners," OpenAI Blog, vol. 1, no. 8, pp. 9, 2019.

\bibitem{17} A. Vaswani, N. Shazeer, N. Parmar, et al., "Attention is all you need," arXiv preprint arXiv:1706.03762, Dec. 2017. [Online]. Available: http://arxiv.org/abs/1706.03762.

\bibitem{18} S. Reddy, A. D. Dragan, and S. Levine, "Where do you think you're going?: Inferring beliefs about dynamics from behavior," arXiv preprint arXiv:1805.08010, Jan. 2019. [Online]. Available: http://arxiv.org/abs/1805.08010.

\bibitem{19} C. Laidlaw and A. Dragan, "The Boltzmann policy distribution: Accounting for systematic suboptimality in human models," arXiv preprint arXiv:2204.10759, Apr. 2022. [Online]. Available: http://arxiv.org/abs/2204.10759.

\bibitem{20} L. Chan, A. Critch, and A. Dragan, "Human irrationality: Both bad and good for reward inference," arXiv preprint arXiv:2111.06956, Nov. 2021. [Online]. Available: http://arxiv.org/abs/2111.06956.

\bibitem{21} Z. Bing, D. Lerch, K. Huang, and A. Knoll, "Meta-reinforcement learning in non-stationary and dynamic environments," IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1-17, 2022, ISSN: 0162-8828, 2160-9292, 1939-3539. DOI: 10.1109/TPAMI.2022.3185549. [Online]. Available: https://ieeexplore.ieee.org/document/9804728.

\bibitem{22} S. P. Arango, F. Heinrich, K. Madhusudhanan, and L. Schmidt-Thieme, "Multimodal meta-learning for time series regression," arXiv preprint arXiv:2108.02842, Nov. 2021. [Online]. Available: http://arxiv.org/abs/2108.02842.

\bibitem{23} J. Ditterich, "Evidence for time-variant decision making," European Journal of Neuroscience, vol. 24, no. 12, pp. 3628–3641, 2006. Available: https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1460-9568.2006.05221.x.

\bibitem{24} E. Jang, S. Gu, and B. Poole, "Categorical reparameterization with Gumbel-Softmax," arXiv preprint arXiv:1611.01144, Aug. 2017. [Online]. Available: http://arxiv.org/abs/1611.01144.

\bibitem{25} J. Jiang, G. G. Xia, D. B. Carlton, C. N. Anderson, and R. H. Miyakawa, "Transformer VAE: A hierarchical model for structure-aware and interpretable music representation learning," in 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, May 2020, pp. 516-520. DOI: 10.1109/ICASSP40776.2020.9054554.

\bibitem{26} T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor," arXiv preprint arXiv:1801.01290, Aug. 2018. [Online]. Available: https://arxiv.org/abs/1801.01290.

\bibitem{27} G. Papoudakis, F. Christianos, L. Schäfer, and S. V. Albrecht, "Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks," arXiv preprint arXiv:2006.07869, Nov. 2021. [Online]. Available: https://arxiv.org/abs/2006.07869.

\bibitem{28} S. Huang, R. F. J. Dossa, C. Ye, J. Braga, D. Chakraborty, K. Mehta, and J. G. M. Araújo, "CleanRL: High-quality single-file implementations of deep reinforcement learning algorithms," The Journal of Machine Learning Research, vol. 23, no. 1, pp. 12585–12602, 2022.

\bibitem{29} T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor," arXiv preprint arXiv:1801.01290, Aug. 2018. [Online]. Available: https://arxiv.org/abs/1801.01290.

\bibitem{30} G. Loaiza-Ganem and J. P. Cunningham, "The continuous Bernoulli: Fixing a pervasive error in variational autoencoders," arXiv preprint arXiv:1907.06845, Dec. 2019. [Online]. Available: https://arxiv.org/abs/1907.06845.

\end{thebibliography}

\end{document}
