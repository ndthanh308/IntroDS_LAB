Several multi-agent reinforcement learning (MARL) techniques have been suggested for dealing with non-stationarity \cite{albrecht_autonomous_2018}. Effective MARL approaches have adopted a centralised framework to enable multiple agents to coordinate their behaviour together and collaborate effectively. However, in pHRC scenarios, the training needs to be decentralised as it is not possible to control both of the agents â€“ only the reinforcement learning robot agent. Therefore, the human agent needs to be created as part of the environment and a separate model of the human is required to predict and influence its behaviour.  