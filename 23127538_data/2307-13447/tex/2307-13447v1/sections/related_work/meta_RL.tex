Meta-RL provides a paradigm for leveraging latent strategies to deal with non-stationarity. Meta-RL ("learning to learn") utilises a set of tasks with a common form during a training phase to enable quick adaption to similar but new tasks unseen during training. One approach - which will be adopted in this paper - is to consider meta-RL as an expansion of multi-task RL where the task information must be inferred. Meta-RL refers to learning a multi-task robot policy  $\pi_{\theta}$ and inferring the task $z$. Meta-RL consists of two settings for adapting to new tasks. First, 'few-shot' (episodic) adaptation where the agent is allowed to collect data for a few episodes. Second, 'zero-shot' adaptation where the agent may encounter a new task at every timestep and react immediately. The zero-shot adaptation setting is thus relevant to the non-stationarity issue. In this paper we use the zero-shot meta-learning approach to enable the robot to deal with non-stationarity. \theo{not sure if it does zero-shot learning}
