\section{Experiments}
\subsection{Experimental Setup}
\boldparagraph{Datasets} We evaluate our method in single-agent setting on Argoverse v1.1~\cite{Chang2019CVPR} and in multi-agent setting on Interaction~\cite{Wei2019ARXIV}. Argoverse, with 323,557 scenarios, is the commonly used benchmark for single-agent motion forecasting. Given the HD map and the history of agents for 2s, the goal is to predict the future locations of the agent of interest for the next 3s. Interaction contains 62,022 multi-agent scenarios with up to 40 agents per scenario. The goal is to predict the future for all agents in the scene. 

\boldparagraph{Metrics} We use standard metrics including minimum Average Displacement Error~($\text{mADE}_k$), minimum Final Displacement Error~($\text{mFDE}_k$), Miss Rate~($\text{MR}_k$), and brier minimum Final Displacement Error~(brier-$\text{mFDE}_k$). These metrics are calculated based on the trajectory with the closest endpoint to the ground truth over $k$ trajectory predictions. $\text{mADE}_k$ measures the average $\ell_2$ difference between the full prediction and the ground truth, $\text{mFDE}_k$ measures the difference between the predicted endpoint and the ground truth. $\text{MR}_k$ is the ratio of scenes where $\text{mFDE}_k$ is higher than 2 meters. The brier-$\text{mFDE}_k$ is calculated as $(1 - p)^2 + $ $\text{mFDE}_k$ where $p$ is the probability predicted for the trajectory. In multi-agent setting, each metric is computed per agent and then averaged over all agents.

\boldparagraph{Training Details}  We set the number of layers $L$ to 3 for both polyline subgraphs and interaction modeling. We train our models with a batch size of 64 for 36 epochs. We use Adam optimizer~\cite{Kingma2015ICLR} with an initial learning rate of $1 \times 10^{-4}$ and $2 \times 10^{-4}$ for Argoverse and Interaction experiments, respectively. We anneal the learning rate with a factor of $0.15$ at the $70^{th}$ and $90^{th}$ percentiles. We generate lane vectors for lanes that are closer than $50$m to any available agent. For data augmentation, we use random scaling in the range of $[0.75, 1.25]$  for Argoverse and random agent drop with the probability of $0.1$ for both Argoverse and Interaction experiments. We also use other agents on Argoverse as additional training data as done in previous work~\cite{Zhou2022CVPR}. Specifically,  we only consider agents that move by at least $6$m following previous work~\cite{Girgis2022ICLR, Ngiam2022ICLR}. In agent-centric reference frame, we translate and rotate the scene with respect to the agent of interest. In scene-centric reference frame, we orient the scene based on the mean location of all agents.

\subsection{Quantitative Results}
\input{tab/sota_argoverse_test}
\boldparagraph{Single-Agent Prediction on Argoverse}
We compare our method in single-agent setting using an agent-centric reference frame to the state-of-the-art on test~(\tabref{tab:sota_argoverse_test}) and validation~(\tabref{tab:sota_argoverse_val}) sets of Argoverse. 
We report results without ensembles, except for Multipath++~\cite{Varadarajan2022ICRA} (only the result of the ensemble is reported). Our method achieves comparable results to the top-performing methods on the test set in all metrics. In particular, we approach the the performance of the state-of-the-art PAGA~\cite{Da2022ICRA} in the official metric, \ie brier-$\text{mFDE}_6$ and reach the performance of HiVT~\cite{Zhou2022CVPR} in 
other metrics by using only $56\%$ of its parameters.
On the validation set, our method performs the best in terms of $\text{mFDE}_6$ and $\text{MR}_6$.
Impressively, ADAPT achieves these results with one of the smallest and fastest models~(\figref{fig:acc_vs_eff}). 

\input{tab/sota_argoverse_val}

In \tabref{tab:sota_argoverse_val}, we report the average runtime per scene on the validation set of Argoverse using a Tesla T4 GPU. To align the settings between different approaches and alleviate implementation differences in parallelism, we set the batch size to 1 and predict the future only for agent of interest per scene. Our method is the second fastest method, only behind mmTransformer~\cite{Liu2021CVPR} but with significantly better results than mmTransformer on both validation and test sets. Note that HiVT~\cite{Zhou2022CVPR} suffers significantly in terms of inference time due to agent-centric approach where the scene is normalized for each agent iteratively. Our approach can achieve similar results, and even slightly better, on the test set with only $18\%$ of HiVT's inference time. 
We provide a comparison of methods in terms of computational complexity in Supplementary to justify our design choices in feature encoding, contributing to our method's efficiency.
A full comparison in terms of brier-$\text{mFDE}_6$ vs. inference time is provided in \figref{fig:time_v_brier}. ADAPT achieves the best performance without sacrificing efficiency.

\boldparagraph{Multi-Agent Predictions on Argoverse} 
We extend the Argoverse setting from single-agent in agent-centric reference frame to multi-agent in scene-centric reference frame by modifying the reference point to be the same for all agents. In this case, we use ADAPT with adaptive head instead of static head. For evaluating multi-agent predictions, we only consider the agents that are visible at all timestamps. As shown at the bottom row of \tabref{tab:sota_argoverse_val}, ADAPT can predict the future trajectories of all agents in scene-centric reference frame with similar accuracy to single-agent case which has the advantage of agent-centric reference frame. Please note that the inference time remains the same from single-agent to multi-agent case since we predict all future trajectories in a single pass.

\input{tab/sota_interaction}

\boldparagraph{Multi-Agent Prediction on Interaction}
We compare our method in multi-agent setting using a scene-centric reference frame to other methods on the Interaction validation set in \tabref{tab:interaction_sota}. Our method significantly outperforms other methods with a large gap in all metrics. Impressively, it reaches $1\%$ miss rate, showing that our method can predict future trajectories accurately for all agents in the scene. %

\input{tab/meta_info_robustness}
\boldparagraph{Robustness of Adaptive Head} To evaluate the effect of noisy input data, we conducted an experiment in multi-agent setting on Interaction. Specifically, we perturb input coordinates with noise $\mathcal{N}(0, \sigma)$ where $\sigma \in \{0.4, 0.8, 1.6, 3.2\}$, corresponding to an average of $\{0.32, 0.64, 1.28, 2.56\}$ meters deviation in 0.1 seconds, respectively. As shown in \tabref{tab:meta_info_robustness}, the performance is quite robust to increasing noise levels in input coordinates.

% Figure environment removed

\subsection{Qualitative Analysis}
In \figref{fig:qualitative}, we visualize the predictions of our model in multi-agent setting on Interaction~(\subref{fig:interaction_qual}) and in single-agent setting on Argoverse~(\subref{fig:argoverse_qual}). Our model can predict accurate multi-modal trajectories for all agents in complex intersection scenarios on Interaction. In single-agent case, our model can vary predictions for the agent of interest in terms of intention and speed. Our model can successfully capture the interactions between the agents and predict futures by considering other agents, \eg on the top left in~\figref{fig:argoverse_qual}.


\boldparagraph{Visualizing Effect of Adaptive Head} To understand the importance of adaptive head, we compare the predictions of adaptive head (left) to the predictions of static head (right) in the same scenario in \figref{fig:adaptive_comparison}.
The adaptive head significantly improves the consistency and accuracy of predictions by allowing the model to adapt to the initial state of the agent, including its rotation, location, and speed.

% Figure environment removed

\boldparagraph{Understanding Dynamic Weights} To understand how the proposed adaptive prediction head changes according to each agent, we visualize dynamically learned weights for each agent by projecting them into the 3D hypersphere as shown in \figref{fig:w_hypersphere}. Specifically, we project the $\bW_2$ matrix~(\eqnref{eq:dynamic}) for each agent to a 3-dimensional vector with PCA and normalize it to unit length as shown on top of each scene. Despite differences in absolute position, the learned weights for agents moving in the same lane map to similar vectors on the hypersphere. For example, the brown and green agents on the left column map to almost identical vectors, although they are spatially far from each other. A separating factor is the orientation of agents, which is preserved in the mapping. For example, the green and purple agents on the right column map along the same direction, while the orange, red, brown, and cyan agents on the opposite lane map to the opposite direction.






\input{tab/ablation_single}

\subsection{Ablation Study}
\label{sec:ablation}
We conduct ablation studies on the validation split of the Argoverse for single-agent setting and the validation split of the Interaction dataset for multi-agent setting.

\input{tab/ablation_multi}



\boldparagraph{Ablations on Single-Agent} In \tabref{tab:ablation_single}, we perform an ablation study on our architectural choices in single-agent setting of the Argoverse. First, using other agents in a scene as done in previous work~\cite{Zhou2022CVPR, Ngiam2022ICLR, Girgis2022ICLR} improves the performance in all metrics as it provides more samples for training. 
Second, gradient stopping in the trajectory predictor enhances the performance by providing independent updates for endpoint refinement and trajectory scoring. Third, refinement improves the accuracy of both the endpoint and the full trajectory by improving the accuracy of the initial endpoint as well.
Fourth, data augmentation increases the diversity of the training data, leading to better performance. 
Finally, combining all results in the best performance, proving the importance of each component and design choice.

\boldparagraph{Ablations on Multi-Agent} In \tabref{tab:ablation_multi}, we analyze the effect of adaptive head with dynamic weights on multi-agent prediction. The results show that the performance is improved significantly with the adaptive head. %
This indicates that the adaptive head can adjust the weights according to the initial state of each agent. %
