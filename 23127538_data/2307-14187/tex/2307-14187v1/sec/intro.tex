\section{Introduction}

A self-driving agent needs to be able to anticipate the future behavior of other agents around it to plan its trajectory. This problem, known as trajectory forecasting, is an important requirement for safe navigation.
There are multiple challenges to solving this problem. First of all, traffic scenes are highly dynamic. The behavior of an agent depends not only on the scene properties, such as configurations of lanes but also on other agents, such as yielding to another vehicle that has priority. Second, multiple futures need to be predicted due to the inherent uncertainty in future predictions. While these two challenges are studied in the literature, one challenge remains mostly unresolved: The future is shaped according to \textit{all} agents in the scene acting together. Therefore, trajectories of all agents need to be predicted as opposed to the current practice of predicting only the trajectory of a selected agent~\cite{Chang2019CVPR, Caesar2020CVPR}. 


% Figure environment removed

The progress in trajectory forecasting has focused mainly on scene representations for predicting the trajectory of a single agent. Typically, the existing methods~\cite{Liang2020ECCV, Ye2021CVPR, Gilles2022ICLR} follow an agent-centric reference frame where the scene is centered around the agent of interest, and everything else is positioned relative to it. This way, the prediction network is provided with the same initial state regardless of the agent's location or orientation, providing \textit{pose-invariance}. 
In other words, the scene is observed from the viewpoint of the agent of interest. In multi-agent setting, each agent has a different view of the world, and one cannot be prioritized over another as in the case of the agent-centric approach. A straightforward extension of an agent-centric approach to multi-agent is iterating the process for each agent in its own reference frame~(\figref{fig:scene_vs_agent}). This is achieved by transforming the scene according to each agent to obtain pose-invariant features. However, this solution scales linearly with the number of agents and causes a variable inference time that cannot be afforded in the real-time setting of driving. As a solution, SceneTransformer~\cite{Ngiam2022ICLR} introduces a global frame that is shared across agents. In their scene-centric approach, all agents are positioned with respect to the same reference point but at the cost of pose-invariance. 


Ideally, the pose-invariance is a desirable property but for multi-agent prediction, a scene-centric approach can be preferred in real world due to efficiency concerns~\cite{Ngiam2022ICLR}. Then the question is how do we avoid the problems of a scene-centric approach without sacrificing efficiency? In this paper, we propose a solution to adapt to the situation of each agent with dynamic weight learning~\cite{Jia2016NeurIPS, Tian2020ECCV, Sun2021CVPR}.
Dynamic networks can adjust the model structure based on input by adapting network weights according to the changes in the input states~\cite{Han2021PAMI}. %
Therefore, they are well-suited for the multi-agent prediction task where each agent has a different initial state. Additionally, dynamic networks are capable of expanding the parameter space without increasing computation cost, therefore meeting the real-time requirements of our task.
We learn the weights of the network that predicts the endpoints so that they can change and adapt to each agent's reference frame. %
With dynamic weights, we can efficiently adapt the prediction head to each agent in a scene-centric approach without iterating over agents.


Our method is not only the first to achieve multi-agent prediction accurately and efficiently in a scene-centric approach but also one of the smallest and fastest among all trajectory prediction models including single-agent prediction. 
Using a goal-conditioning approach, we can easily switch between single and multi-agent prediction settings. To further enhance the performance of our model, we employ gradient stopping to stabilize the training of trajectory and endpoint prediction. This technique enables us to achieve good performance by fully leveraging the capacity of a small decoder with simple MLP layers rather than a complex one.

We show that our method outperforms the state-of-the-art methods with a fraction of their parameters in both single-agent setting of the Argoverse~\cite{Chang2019CVPR} and multi-agent setting of the Interaction~\cite{Wei2019ARXIV}. On Interaction, specifically designed for evaluating multi-agent predictions, our method achieves a $1\%$ miss rate in comparison to $5\%$ which was the lowest achieved so far~\cite{Gilles2022ICLR}. Our contributions can be summarized as follows:
\begin{itemize}[topsep=0.5pt]
    \setlength\itemsep{0em}
    \item We propose a novel approach for predicting the trajectories of all agents in the scene. Our adaptive head can predict accurate trajectories by dynamically adapting to various initial states of multiple agents.
    \item We achieve state-of-the-art results efficiently with one of the smallest and fastest models including the ones in single-agent setting. We validate our design choices in endpoint prediction and trajectory prediction with gradient stopping for stabilized training.
    \item We have created a unified prediction process that can be used for both single and multi-agent settings with the same backbone by utilizing endpoint conditioning. Our method allows for easy switching between scene-centric and agent-centric reference frames, achieving state-of-the-art in both settings.
\end{itemize}

