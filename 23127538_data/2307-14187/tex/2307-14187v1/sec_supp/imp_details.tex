\section{Implementation Details}
\label{sec:imp_details}

\boldparagraph{Scene Representation} We follow VectorNet~\cite{Gao2020CVPR} in our polyline subgraph implementation to obtain the updated node features $\bv_i$ of the subgraph as follows:
\begin{align}
    \bv^{(l + 1)}_i =&~ ~\text{cat}\left(\text{MLP}_{l}(\bv^{(l)}_i), ~\text{pool}(\text{MLP}_{l}(\bv^{(l)}))\right) \nonumber
\end{align}
where $\bv_i^{(l)}$ denotes the feature vector of agent $i$ at layer $l$, pool the max-pool operation, and cat the concatenation operation. We use an MLP with 2 linear layers and ReLU for non-linearity with a layer normalization~\cite{Ba2016ARXIV} after the first layer. We set the layer number $l$ to $3$ and the size of the feature vector to $128$ for both the agent and the lane subgraph.

\boldparagraph{Interaction Modelling} For each multi-head attention block (MHAB), we set the number of attention heads to $8$ and apply a dropout rate of $0.1$ to the attention probabilities. We set the size of the hidden layer in the feed-forward networks to $128$ and the number of iterations $L$ to 3. 

\boldparagraph{Meta Info} Meta info includes the location of the agent at time $t$, $t - 1$, and the yaw angle at $t$. Locations are in 2D coordinates and the angle is in radians, resulting in a 5-dimensional vector. We concatenate the meta info to the corresponding agent feature before decoding.

\boldparagraph{Trajectory Predictor} For both dynamic and static heads, we use a 2-layer MLP with ReLU for the non-linearity and a layer normalization~\cite{Ba2016ARXIV} after the first layer. Differently from subgraphs, we use residual connections in the last layer. 