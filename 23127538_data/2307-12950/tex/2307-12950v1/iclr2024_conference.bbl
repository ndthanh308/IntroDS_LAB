\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anthropic(2023)]{anthropic2023claude}
Anthropic.
\newblock Introducing claude, 2023.
\newblock URL \url{https://www.anthropic.com/index/introducing-claude}.

\bibitem[Askell et~al.(2021)Askell, Bai, Chen, Drain, Ganguli, Henighan, Jones,
  Joseph, Mann, DasSarma, et~al.]{askell2021general}
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan,
  Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et~al.
\newblock A general language assistant as a laboratory for alignment.
\newblock \emph{arXiv preprint arXiv:2112.00861}, 2021.

\bibitem[Bai et~al.(2022{\natexlab{a}})Bai, Jones, Ndousse, Askell, Chen,
  DasSarma, Drain, Fort, Ganguli, Henighan, et~al.]{bai2022training}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
  Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning
  from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022{\natexlab{a}}.

\bibitem[Bai et~al.(2022{\natexlab{b}})Bai, Kadavath, Kundu, Askell, Kernion,
  Jones, Chen, Goldie, Mirhoseini, McKinnon, et~al.]{bai2022constitutional}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,
  Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,
  et~al.
\newblock Constitutional ai: Harmlessness from ai feedback.
\newblock \emph{arXiv preprint arXiv:2212.08073}, 2022{\natexlab{b}}.

\bibitem[Chang et~al.(2023)Chang, Brantley, Ramamurthy, Misra, and
  Sun]{chang2023learning}
Jonathan~D Chang, Kiante Brantley, Rajkumar Ramamurthy, Dipendra Misra, and Wen
  Sun.
\newblock Learning to generate better than your llm.
\newblock \emph{arXiv preprint arXiv:2306.11816}, 2023.

\bibitem[Chen et~al.(2023)Chen, Wong, Chen, and Tian]{chen2023extending}
Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian.
\newblock Extending context window of large language models via positional
  interpolation.
\newblock \emph{arXiv preprint arXiv:2306.15595}, 2023.

\bibitem[Choi et~al.(2022)Choi, Jo, Jang, and Seo]{choi2022prompt}
Eunbi Choi, Yongrae Jo, Joel Jang, and Minjoon Seo.
\newblock Prompt injection: Parameterization of fixed inputs.
\newblock \emph{arXiv preprint arXiv:2206.11349}, 2022.

\bibitem[Dubois et~al.(2023)Dubois, Li, Taori, Zhang, Gulrajani, Ba, Guestrin,
  Liang, and Hashimoto]{dubois2023alpacafarm}
Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba,
  Carlos Guestrin, Percy Liang, and Tatsunori~B Hashimoto.
\newblock Alpacafarm: A simulation framework for methods that learn from human
  feedback.
\newblock \emph{arXiv preprint arXiv:2305.14387}, 2023.

\bibitem[Eysenbach et~al.(2022)Eysenbach, Zhang, Levine, and
  Salakhutdinov]{eysenbach2022contrastive}
Benjamin Eysenbach, Tianjun Zhang, Sergey Levine, and Russ~R Salakhutdinov.
\newblock Contrastive learning as goal-conditioned reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 35603--35620, 2022.

\bibitem[Huang et~al.(2022)Huang, Gu, Hou, Wu, Wang, Yu, and
  Han]{huang2022large}
Jiaxin Huang, Shixiang~Shane Gu, Le~Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu,
  and Jiawei Han.
\newblock Large language models can self-improve.
\newblock \emph{arXiv preprint arXiv:2210.11610}, 2022.

\bibitem[Kim \& Rush(2016)Kim and Rush]{kim2016sequence}
Yoon Kim and Alexander~M Rush.
\newblock Sequence-level knowledge distillation.
\newblock \emph{arXiv preprint arXiv:1606.07947}, 2016.

\bibitem[Laskin et~al.(2020)Laskin, Srinivas, and Abbeel]{laskin2020curl}
Michael Laskin, Aravind Srinivas, and Pieter Abbeel.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5639--5650. PMLR, 2020.

\bibitem[Laskin et~al.(2022)Laskin, Liu, Peng, Yarats, Rajeswaran, and
  Abbeel]{laskin2022cic}
Michael Laskin, Hao Liu, Xue~Bin Peng, Denis Yarats, Aravind Rajeswaran, and
  Pieter Abbeel.
\newblock Cic: Contrastive intrinsic control for unsupervised skill discovery.
\newblock \emph{arXiv preprint arXiv:2202.00161}, 2022.

\bibitem[Liu et~al.(2021)Liu, Zhang, Zhao, Qin, Zhu, Li, Yu, and
  Liu]{liu2021return}
Guoqing Liu, Chuheng Zhang, Li~Zhao, Tao Qin, Jinhua Zhu, Jian Li, Nenghai Yu,
  and Tie-Yan Liu.
\newblock Return-based contrastive representation learning for reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2102.10960}, 2021.

\bibitem[Liu et~al.(2023)Liu, Lin, Hewitt, Paranjape, Bevilacqua, Petroni, and
  Liang]{liu2023lost}
Nelson~F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua,
  Fabio Petroni, and Percy Liang.
\newblock Lost in the middle: How language models use long contexts.
\newblock \emph{arXiv preprint arXiv:2307.03172}, 2023.

\bibitem[MosaicML(2023)]{mosaic202364k}
MosaicML.
\newblock Introducing mpt-7b: A new standard for open-source, commercially
  usable llms, 2023.
\newblock URL \url{https://www.mosaicml.com/blog/mpt-7b}.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[OpenAI(2022)]{openai2022chatgpt}
OpenAI.
\newblock Introducing chatgpt, 2022.
\newblock URL \url{https://www.openai.com/blog/chatgpt}.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[Pei et~al.(2023)Pei, Yang, and Klein]{pei2023preadd}
Jonathan Pei, Kevin Yang, and Dan Klein.
\newblock Preadd: Prefix-adaptive decoding for controlled text generation,
  2023.

\bibitem[Rafailov et~al.(2023)Rafailov, Sharma, Mitchell, Ermon, Manning, and
  Finn]{rafailov2023direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher~D
  Manning, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a
  reward model.
\newblock \emph{arXiv preprint arXiv:2305.18290}, 2023.

\bibitem[Rajani et~al.(2023)Rajani, Lambert, Han, Wang, Nitski, Beeching, and
  Tunstall]{rajani2023llm_labels}
Nazneen Rajani, Nathan Lambert, Sheon Han, Jean Wang, Osvald Nitski, Edward
  Beeching, and Lewis Tunstall.
\newblock Can foundation models label data like humans?
\newblock \emph{Hugging Face Blog}, 2023.
\newblock https://huggingface.co/blog/llm-v-human-data.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Snell et~al.(2022)Snell, Klein, and Zhong]{snell2022learning}
Charlie Snell, Dan Klein, and Ruiqi Zhong.
\newblock Learning by distilling context.
\newblock \emph{arXiv preprint arXiv:2209.15189}, 2022.

\bibitem[Stiennon et~al.(2020)Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei, and Christiano]{stiennon2020learning}
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea
  Voss, Alec Radford, Dario Amodei, and Paul~F Christiano.
\newblock Learning to summarize with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 3008--3021, 2020.

\bibitem[Sun et~al.(2023)Sun, Shen, Zhou, Zhang, Chen, Cox, Yang, and
  Gan]{sun2023principle}
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David
  Cox, Yiming Yang, and Chuang Gan.
\newblock Principle-driven self-alignment of language models from scratch with
  minimal human supervision.
\newblock \emph{arXiv preprint arXiv:2305.03047}, 2023.

\bibitem[Tian(2022)]{tian2022understanding}
Yuandong Tian.
\newblock Understanding deep contrastive learning via coordinate-wise
  optimization.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 19511--19522, 2022.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet,
  Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar,
  et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023{\natexlab{a}}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert,
  Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale,
  et~al.]{touvron2023llamatwo}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
  Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
  et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023{\natexlab{b}}.

\bibitem[Welbl et~al.(2021)Welbl, Glaese, Uesato, Dathathri, Mellor, Hendricks,
  Anderson, Kohli, Coppin, and Huang]{welbl2021challenges}
Johannes Welbl, Amelia Glaese, Jonathan Uesato, Sumanth Dathathri, John Mellor,
  Lisa~Anne Hendricks, Kirsty Anderson, Pushmeet Kohli, Ben Coppin, and Po-Sen
  Huang.
\newblock Challenges in detoxifying language models.
\newblock \emph{arXiv preprint arXiv:2109.07445}, 2021.

\bibitem[Zhu et~al.(2023)Zhu, Jiao, and Jordan]{zhu2023principled}
Banghua Zhu, Jiantao Jiao, and Michael~I Jordan.
\newblock Principled reinforcement learning with human feedback from pairwise
  or $ k $-wise comparisons.
\newblock \emph{arXiv preprint arXiv:2301.11270}, 2023.

\end{thebibliography}
