{
  "title": "Instance-Wise Adaptive Tuning and Caching for Vision-Language Models",
  "authors": [
    "Chunjin Yang",
    "Fanman Meng",
    "Shuai Chen",
    "Mingyu Liu",
    "Runtong Zhang"
  ],
  "submission_date": "2023-07-29T13:12:34+00:00",
  "revised_dates": [],
  "abstract": "Large-scale vision-language models (LVLMs) pretrained on massive image-text pairs have achieved remarkable success in visual representations. However, existing paradigms to transfer LVLMs to downstream tasks encounter two primary challenges. Firstly, the text features remain fixed after being calculated and cannot be adjusted according to image features, which decreases the model's adaptability. Secondly, the model's output solely depends on the similarity between the text and image features, leading to excessive reliance on LVLMs. To address these two challenges, we introduce a novel two-branch model named the Instance-Wise Adaptive Tuning and Caching (ATC). Specifically, one branch implements our proposed ConditionNet, which guides image features to form an adaptive textual cache that adjusts based on image features, achieving instance-wise inference and improving the model's adaptability. The other branch introduces the similarities between images and incorporates a learnable visual cache, designed to decouple new and previous knowledge, allowing the model to acquire new knowledge while preserving prior knowledge. The model's output is jointly determined by the two branches, thus overcoming the limitations of existing methods that rely solely on LVLMs. Additionally, our method requires limited computing resources to tune parameters, yet outperforms existing methods on 11 benchmark datasets.",
  "categories": [
    "cs.MM"
  ],
  "primary_category": "cs.MM",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15983",
  "pdf_url": "https://arxiv.org/pdf/2307.15983v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 767482,
  "size_after_bytes": 93152
}