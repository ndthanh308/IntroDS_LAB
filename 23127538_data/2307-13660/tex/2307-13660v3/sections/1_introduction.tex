\section{Introduction}
The Gromov--Hausdroff distance \cite{gromov1999metric} measures the difference in shape between geometric objects, and is a natural metric on the space of (isometry classes of) compact metric spaces. It is widely used in Riemannian geometry and appears in other areas of modern mathematics such as computational topology and graph theory (see e.g. \cite{gromov1999metric, latschev2001vietoris, chazal2009gromov, tuzhilin2020lectures}). Starting from the late 2000s, it has become increasingly popular in data science as a model for dissimilarity measures between shapes such as point clouds \cite{memoli2007use, chazal2009gromov, villar2016polynomial, bronstein2010gromov} and graphs \cite{lee2012persistent, chung2017topological, fehri2018characterizing}).

Formally, the Gromov--Hausdorff distance between a pair of compact metric spaces $X, Y$ minimizes the distortion of distances between the points of $X$ and $Y$ and their images under some bi-directional mapping pair $(f,g)\in(X\to Y)\times(Y\to X)$. Solving this combinatorial minimization is an NP-hard problem, and in fact even approximating it up to a multiplicative factor of $\sqrt{n}$ (where $n \defeq \max\{|X|, |Y|\}$) in the general case remains an intractable task \cite{schmiedl2017computational}. High computational cost of the distance has motivated its relaxations such as the modified Gromov--Hausdorff distance \cite{memoli2012some}, the Gromov--Wasserstein distance (which became a broadly used metric between metric measure spaces in its own right) \cite{memoli2011gromov}, and GHMatch \cite{villar2016polynomial}. Other studies have proposed more feasible algorithms for approximating the Gromov--Hausdorff distance for the special cases of subsets of $\R^1$ \cite{majhi2023approximating}, metric trees \cite{agarwal2018computing, touli2018fpt}, and ultrametric spaces \cite{memoli2021gromov}. 

\input{figures/nonbijective}

While the Gromov--Wasserstein distance and GHMatch are similar to our proposed approach in leveraging gradient methods to obtain approximate solutions, both of these relaxations are constrained to some generalization of bijections between $X$ and $Y$.
% While the Gromov--Wasserstein distance is a broadly used metric between metric measure spaces in its own right, both of these relaxations are constrained to some generalization of bijections between $X$ and $Y$.
Assuming $|X|=|Y|$ (and, for the Gromov--Wasserstein distance, equal measure assigned to each point), they can retrieve only those solutions $(f,g)$ to the original minimization that satisfy $f = g^{-1}$. However, the existence of such solutions is not guaranteed, as is illustrated by the example from Figure \ref{fig:nonbijective}. In particular, the search space of the Gromov--Wasserstein distance between the depicted $X$ and $Y$ under the uniform probability measure does not contain any of the original solutions. Moreover, the example demonstrates that the minimum distortion over all mapping pairs (i.e. the ``short'' distance) can be arbitrarily smaller than the minimum distortion over bijections (i.e. the difference between the ``long'' and the ``short'' distances).
%all mapping pairs can be arbitrary small in comparison to its counterpart constrained to the set of bijections.
This is perhaps unsurprising considering that $(X\to Y)\times (Y\to X)$ grows super-exponentially faster than the set of bijections between $X$ and $Y$. % due to  $\frac{n^{2n}}{n!} \geq \left(\sqrt{2}n\right)^n$.
From a practical standpoint, such an expressivity of the Gromov--Hausdorff distance can be useful for aligning metric spaces of irregular density, e.g. those obtained by uneven sampling from the underlying objects.% or simply of distinct cardinality.

In the below Section \ref{relaxation}, we propose a parametrized relaxation of the Gromov--Hausdorff distance over the same search space $(X\to Y)\times (Y\to X)$. We derive a threshold value for the parameter ensuring that any solution to the relaxed problem minimizes the distortion and therefore delivers the Gromov--Hausdorff distance. Section \ref{minimization} describes solving the relaxation using conditional gradient descent and discusses the associated computational complexity and optimization landscape. We detail on our implementation and demonstrate its performance in numerical experiments in Section \ref{numerical}. As a byproduct, we tighten the upper bound on the Gromov--Hausdorff distance between a unit circle $S^1 \subset \R^2$ and a unit hemisphere $H^2 \subset \R^3$ (Section \ref{spheres}). For brevity, theorem proofs are relegated to the appendix.% \ref{proofs}.

% The scope of this work is restricted to computing the GH distance between finite metric spaces.% as those appearing in the computational context.
% Such a capacity however would be sufficient for approximating the GH distance between any compact spaces with an arbitrary precision. This is because the GH distance between any pair of spaces is within $\epsilon$ from the GH distance between their finite $\epsilon$-nets, existent for any $\epsilon > 0$ \cite{oles2022lipschitz}. This approach is exemplified in Section \ref{} where we numerically bound the GH distance between continuous objects.


% Intuitively speaking, dGH tries to align distances in $X$ and $Y$ by mapping the two spaces into each other

% GHMatch in \cite{villar2016polynomial}:
% - its objective is p-norm relaxation of the original $\infty$-norm formulation (no guarantee of coinciding minima);
% - its search space ($\mathbf{y}$) is Birkhoff polytope which generalizes bijections and does not fully capture the space of all mapping pairs;
% - its iteration is $O(n^4)$
