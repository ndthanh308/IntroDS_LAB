
 In this section, we introduce  related works from two aspects, the knob tuning methods and the interpretable machine learning.

\textbf{The Knob Tuning Methods}
Existing related works for database knobs focus on the knob tuning task~\cite{2017BestConfig}. BestConfig~\cite{2017BestConfig} uses divide-and-conquer sampling strategy to find the knob configuration on the MySQL database.  ITunes~\cite{duan2009tuning} proposed the automatic tuning method based on Gaussian process regression for relational database configuration knobs. This method firsly utilizes Gaussian process regression to model and characterize the relationship between various knobs and database target metrics. Then for reduding the tuning cost, Opentuner~\cite{ansel2014opentuner} proposes an extensive framework and refines the tuning steps, containing  knob dimensionality reduction, knob importance sorting, and historical data matching. ResTune~\cite{zhang2021restune} designed a Gaussian regression knob tuning algorithm for cloud server hardware resource optimization. CGPTuner~\cite{cereda2021cgptuner} considers all directly or indirectly dependent environments such as the hardware, operating system, and JVM on which the database runs, and tunes the adjustable knobs in various environments, and proposes a context-based Bayesian tuning algorithm (Contextual Gaussian Process Bandit Optimization). Zhang~\cite{zhang2022towards} proposed a context-based Bayesian tuning algorithm for security considerations. This algorithm mainly considers the importance of server and database security in cloud scenarios. LlamaTune~\cite{kanellis2022llamatune} proposed a Bayesian optimization method that uses random mapping to reduce the knob space. CDBTune~\cite{reinforcement} is an automatic tuning tool for database knobs based on deep reinforcement learning. Qtune~\cite{li2019qtune} uses a two-state DDPG reinforcement learning model, considers three-level granularity tuning, and supports workload-oriented and query cluster-oriented tuning.

\textbf{The Interpretable Machine Learning} Recently, we have witnessed the remarkable achievements of machine learning in many fields, such as image processing~\cite{wu2017new,Vu_2018_ECCV_Workshops}, natural language processing~\cite{chowdhary2020natural}, etc. However, these ML models which have complex structures and parameters cannot be trusted by users in some high-reliability scenarios. Interpretable machine learning emerged and has become an important research direction in the field of machine learning in recent years~\cite{burkart2021survey}. SHAP~\cite{lundberg2017unified}  explain the black-box model by analyzing the input features. XNN~\cite{mishra2017local} propose a local interpretable model-agnostic explanations for music content analysis. TREPAN~\cite{craven1995extracting} induces a decision tree by querying the neural network and approximating the output of networks by maximizing the gain ratio. Zhang et al.~\cite{zhang2018interpretable} explicit knowledge representation in an interpretable CNN can help people understand the logic inside. Augasta et al.~\cite{augasta2012reverse} reverses engineering the the neural networks for rule extraction in classification problems. Hein et al.~\cite{hein2018interpretable} proposes a genetic programming method for explaining the reinforcement learning.
Explainable machine learning~\cite{burkart2021survey} aims to provide intuitive and clear explanations for the prediction results of machine learning models, thereby enhancing the transparency and predictability of the models.
