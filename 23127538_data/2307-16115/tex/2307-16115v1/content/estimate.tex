While our interpretable ML model could effectively estimate the knob performance under various scenarios, the learning model have to collect multiple training sets for model training. This process may take hours (or days) time since a large number of queries need to be executed to gather the performance label of knob configuration. In order to achieve the knob estimator transfer, we design a two-stage transfer learning method based on ER in this section. We first overview the transfer learning approach in Section~\ref{sec:know}. We propose ranking transfer and estimator transfer mechanisms in Section~\ref{sec:rtran} and~\ref{sec:estimator}, respectively. At last, we introduce the overall transfer learning algorithm in Section~\ref{sec:zeroalgor}.

\subsection{The Overview of Two-stage Transfer}\label{sec:know}



As shown in Figure~\ref{fig:transferstructure}, the two-stage knob transfer approach performs transfer estimation for new scenario defined as $O$ with limited training data, containing the ranking transfer mechanism in Section~\ref{sec:rtran} and the estimator transfer mechanism in Section~\ref{sec:estimator}. The ranking transfer mechanism is in steps 1-5. Step 1 collects the fingerprint from database log, and step 2 matches the similar experiences according to the fingerprint. Steps 3-4 calculate the transferred knob ranking results from the top-$k$ experiences. Step 5 delivers the ranking transfer results to support the knob estimator transfer. The estimator transfer mechanism is in steps 6-13. Steps 6-10 obtain the K-P distribution of $O$ and experiences. Step 11 calculate similarities of the K-P distributions. Steps 12-13 utilizes the K-P distribution to match the similar knob estimator experiences and construct the transfer knob estimator. In the remaining of this section, we introduce the design of ranking transfer and estimator transfer mechanisms in detail.


\subsection{Ranking Transfer Mechanism}\label{sec:rtran}

In this section, we propose the ranking transfer mechanism that aims to match similar knob ranking experiences.


To match the similar experiences for ranking, we encode the features of the scenario into a fingerprint. Generally speaking, existing works utilize some fine-grained and embedding approaches, like the tree network~\cite{marcus2019plan} and GPT~\cite{trummer2022codexdb}. Even though these methods could effectively catch the detailed query and data features, these embedding approaches need a huge amount of training data to gather the embeddings of features, resulting in high computational overhead. To obtain the features with limited training data, we select statistic features of the scenarios to efficiently find knob ranking and estimator with similar scenarios. Next, we introduce our design criteria of the fingerprint in detail.

We design the fingerprint of scenarios from the aspect of the knobs. Roughly, we need to consider two types of knobs~\cite{knobsurvey}: resource-knobs (such as memory and concurrency knobs) and execution-knobs (such as join and index knobs). Resource-knobs and execution-knobs are particularly relevant to workload execution of scenarios, so we design two kinds of statistic features that capture the resource and the execution features, i.e., the ratio of SUID (select, insert, update and delete) and the ratio of different pysical operators. 

Thus, we define a fingerprint $f$ as a vector concatenated by the SUID vector ($v_1$) and the operator vector($v_2$), i.e. $f$ = $<v_1, v_2>$. $v_1$ consists of the ratio of selection queries, update queries, insertion queries and deletion queries. The ratio of SUIDs identifies whether current scenario is memory intensive, CPU intensive or disk extensive. The demand of memory, CPU and disk determines the importance of resource-orient knobs. $v_2$ consists of the ratio of physical operators (including scan, sort, etc.). Different from the SUIDs, the operators of scenarios determine the scope of knob execution. For example, the enable\_index\_scan may be useful for a scenario with index scan while not useful for the scenario without index scan.

% Figure environment removed


We illustrate fingerprint with an example for the workload on YCSB shown in Figure~\ref{fig:finger}, which is a read-heavy workload with large amount of index scan operations. This workload is memory intensive, disk intensive and index intensive. Then, the corresponding kinds of knobs (such as shared\_buffers of Postgresql) are important for this scenario. Clearly, all the above features could be directly collected from the database log without consuming DBMS resources. 




After obtaining the fingerprint of scenarios, we use the similarity function to match the similar knob ranking experiences. Since fingerprints are composed of a series of ratios, the similarity should focus on the gap between each dimension. As shown in Formula~\ref{equ:sim1}, we utilize the Euclidean distance~\cite{euclidean} to measure the gap of the corresponding dimensions with type float.

\begin{equation}
  \label{equ:sim1}
    dis\_ranking(f_1, f_2) = \sqrt{\sum(f_1[i]-f_2[i])^2}  
  \end{equation}

\subsection{Estimator Transfer Mechanism}\label{sec:estimator}


Similar to the ranking transfer mechanism, we also consider to construct the features and similarity function for the knob estimator transfer. If we directly utilize the comprehensive  features of scenarios to match the similar knob estimator. The major challenge is the irregular features (like the various table design and workload structure) of scenarios caused by their too many detailed and complex feature, including workload, data table and hardwares. Existing works utilize the large model~\cite{trummer2022codexdb} to gather unify feature representations of scenarios for model transfer. Although the large deep learning models could obtain some effective feature representations of different scenarios, their black-box nature and multiple neural layers bring unstable performance and huge time consumption, respectively. 

Thus, in this section, we propose a unified and stabled feature based on splines for the knob estimator transfer. Our core idea is to abandon complex scenarios features and calculate the similarity between two scenarios from the aspect of K-P data distribution instead. Specifically, if the $O$ shares the similar K-P data distributions with the historical estimator experiences. It means that they have similar performance trend under same knob configurations. we could transfer the knob estimator to $O$. As shown in Figure~\ref{fig:transferstructure}, the K-P distribution similarity gathering approach for knob estimators consists of four main parts, sampling strategy (step 6), K-P points collection (steps 7-10), feature calculation(step 11) and similarity measure (step 12). We then introduce them respectively. 


\textbf{Sampling Strategy:} For the $O$, we guarantee the sampling efficiency by the uniform sampling algorithm and controlling the sampling space.  (i) We utilize the Latin HyperCube Sampling to achieve the uniformity of the multiple dimension of knobs. (ii) Sampling Space: Different from existing works~\cite{ibtune}, our sampling strategy is based on the important knobs obtained by the transfer ranking transfer mechanism in Section~\ref{sec:rtran}. After determining the sampling space and sampling algorithm, we can collect a high quality samples ($S$) in the $O$, as the basis for calculating K-P distribution similarity.  %We collect N points under the adjustable knob space of object scenario. Then we utilize these samples to learn the knob-performance distribution (or called estimator distribution) of the object scenario

\textbf{K-P Points Collection:} To fairly compare the similarity among experiences, we utilize the same samples ($S$) to process the experiences with the $O$. Firstly, we directly collect the performance label of $S$ on $O$ to construct the K-P data. For the experiences, we utilize the trained historical estimator to predict the performance label of $S$. For adapting to the experiences, we reshape the dimensions of the input knob configurations according to the following rules.


The knob set $L_1$ of input $x_1$ of $S$ has three kinds of relationships with the knob set $L_2$ of input $x_2$ of estimator experiences $m$, fully contained (F), partially contained (P), not contained (N). We describe how to deal with $F$, $P$, $N$ separately.(i) If the input of  and historical estimator satisfy $L_2 \subset L_1$, we simply cut $x_1$ by $L_2$. Since the removed knobs are unimportant according to the historical ranking experience, we can simply ignore the effect of these unimportant knobs. (ii) For partially contained, we reduce the uninvolved knobs and fill the gaps with the default configuration of $O$. For example, $L_1 = [knob1, knob2, knob3]$ and $ x_2 = [knob1 = d, knob2 = e, knob4 = f]$, we cut $knob3$ of $x_1$ and reshape the $x_1$ as $[knob1 = a, knob2 = b, knob4 = O(knob4)]$, where $O(knob4)$ represents the default configuration of knob4 on scenario $O$. (iii) For the case 3, we return the zero due to its totally mismatching.

Then, we obtain the K-P point set for the $O$ and all the experiences.

\textbf{Feature Calculation:} Based  on the K-P points, some natural distribution features exist, such as the mean and variance. However, these simple features could only measure the distance between point sets and ignore the differences of data distribution trends. To efficiently fit the trend feature of K-P points, we employ the spline interpolation method~\cite{linear2}  due to the powerful fitting ability of spline interpolation of describing the distribution, e.g., some simple splines could fit the complex curve distribution~\cite{linear}. Then, the coefficients of the spline function are used as the distribution features of the point set. %\textcolor{red}{For an example for interpolation results, $y=ax_1 + bx_2$, the [a,b] is the coefficients of splines ($f_1 = x_1, f_2 = x_2$).}
Compared to the simple statistics, these coefficients can describe the trend of K-P distribution. Next, we introduce how to calculate the direction distance between these coefficients.

\textbf{Similarity Measure:} As shown in Formula~\ref{equ:cosine}, we utilize the cosine distance~\cite{cosine} to calculate the similarity of two statistic feature. Since we focus on the direction distance between two statistic features under interpolation model. The similar direction means the similar performance distribution of two estimator.%\footnote{what is the motivation of cosine motivation?}


\begin{equation}
  \label{equ:cosine}
    dis\_estimator(d_1, d_2) =\frac{\sum d_1[i]*d_2[i] }{\sqrt {\sum (d_1[i])^2} \sqrt{\sum (d_2[i])^2}} 
  \end{equation}

\begin{algorithm}
    \caption{knob estimator transfer}\label{alg:zero}
    \SetAlgoNoLine
    \LinesNumbered
    \SetKwInOut{Input}{input}
    \Input{
        experience repository ($ER$), fingerprint of $O$ ($f$), the number of experience ($K$), the number of samples($N$).
    }
    \SetKwInOut{Output}{output}
    \Output{
        \ $M$ is the transfered estimator of $O$
    }
    \BlankLine
    
    $E \leftarrow \textit{Find nearest top-k experiences in ER by f}$ \\
    $weights \leftarrow \textit{assign the weights of E by f's similarity.}$\\
    $k = \sum_{i}{ weights_i * E_i.k}$ // \textit{ranking transfer by the weighted average experiences}\\
    $S \leftarrow LHS(N, k)$ // \textit{sample N points under ranking results}\\ 
    $d_1 \leftarrow \textit{collect K-P points of O under S.}$\\
    $similarity \leftarrow \varnothing $\\
    \For(){$e \in E$}{
    $d_2 = \{S, e.IKE(S)\}$ // \textit{obtain the K-P points of experiences }\\
    $similarity.add(dis\_estimator(d_1, d_2))$ \\
    }
    $mweights \leftarrow \textit{assign weight based on the similarity}$\\
    $M \leftarrow \sum_{i} {mweight_i * E_i.m }$ // \textit{estimator transfer by the weighted average experiences}\\ 
    $\textit{return M}$\\
\end{algorithm}



\subsection{Transfer Learning Algorithm}\label{sec:zeroalgor}
In this section, we introduce the overall transfer knob estimation algorithm based on the above feature design and similarity design.%\footnote{challenge and the basic idea}

As shown in Algorithm~\ref{alg:zero}, our method consists of two main stages. In the first stage (Lines 1-3), we perform the transfer of knob ranking by matching the fingerprints. The fingerprints contain some statistic features of current scenario which determine the important knobs. Line 1 finds the top-k experiences by $f$. Line 2 assigns the weight for $E$ according to the similarity of $f$. Line 3 calculates the final ranking by the weighted average of top-$K$ experiences.


In the second stage (Lines 4-12), base on the top-$K$ experiences, we perform estimator transfer by matching the similar K-P distribution. Line 4 samples $N$ points based on the ranking results for $O$. Line 5 collects the performance label for $O$ and returns the K-P dataset for $O$. Lines 6-10 calculate the similarities of K-P points. Line 11 assigns weight for the knob estimator of experiences. Line 12 calculates the transfer estimator for the $O$ according to the weight average of experiences.


Overall, the only database accessing operation of our algorithm is the collection of labeled data for $O$. Such operation could be performed on the cloned instance to avoid affecting the efficiency of online database service. 

% Figure environment removed
