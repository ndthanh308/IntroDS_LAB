

In this section we study four formal systems, 
$\IFP$, $\RIFP$, $\CFP$, and $\RCFP$ 
(Sections~\ref{sub-IFP} - \ref{sub-RCFP}).
%
$\IFP$ (Intuitionistic Fixed Point Logic)
is an intuitionistic first-order logic with strictly positive 
inductive and coinductive definitions from the proofs of which programs 
can be extracted.
%
$\RIFP$ (Realizability for $\IFP$) extends $\IFP$ to enable the 
formalization of types and programs and their denotational semantics,
as well a realizability,
and hence the formal verification of the extracted programs.
%
Both systems were introduced in~\cite{IFP}.
%
$\CFP$ is obtained by adding to $\IFP$ two propositional
operators, $\rt{A}{B}$ and $\Set(B)$, that facilitate the extraction of 
nondeterministic and concurrent programs. 
$\RCFP$ is the extension of $\RIFP$ by 
type and program constructs for concurrency.
While $\RIFP$ is intuitionistic, $\RCFP$ is based on classical logic, 
which is necessary for proving realizability of a concurrent form
of the law of excluded middle.



\subsection{IFP}
\label{sub-IFP}
%
\paragraph{Language.}
The system $\IFP$ is defined relative to a
many-sorted first-order language. 
IFP expressions consist of formulas, predicates, and operators. 
%
$\IFP$ formulas 
have the form 
$A \land B$,  $A \lor B$, $A \to B$,  
$\forall x\, A$, $\exists x\, A$, 
$s = t$ ($s$, $t$ terms of the same sort), 
$P(\vec t)$ (for a predicate $P$ and terms $\vec t$ of fitting arities).
%
Predicates are either predicate constants (as given by the first-order language),
or predicate variables (denoted $X,Y,\ldots$), 
or comprehensions $\lambda\vec x\,A$ (where $A$ is a formula and $\vec x$ 
is a tuple of first-order variables), 
or fixed points $\mu(\Phi)$ and $\nu(\Phi)$
(least fixed point a.k.a.\ inductive predicate 
and greatest fixed point a.k.a.\ coinductive predicate) where $\Phi$ is a
strictly positive (s.p.) operator. 
%
Operators are of the form
$\lambda X\,Q$ where $X$ is a predicate variable
and $Q$ is a predicate
that has 
the same arity as $X$. 
$\lambda X\,Q$ is s.p.\ if 
every free occurrence of $X$ in $Q$ 
is at a strictly positive position,
that is, at a position that is not in
the left part of an implication.
%
Every term has a fixed sort and every predicate variable has a 
fixed arity which is a tuple of sorts. We usually 
suppress sorts and arities, notationally. 
%
\emph{Notation}: $P(\vec t)$ will also be written $\vec t \in P$, and
if $\Phi$ is 
$\lambda X\,Q$, then
$\Phi(P)$ stands for $Q[P/X]$.
Definitions (on the meta-level) 
of the form 
$P \eqdef \munu(\Phi)$ 
($\munu\in\{\mu,\nu\}$) 
where $\Phi = \lambda X\,\lambda \vec x\,A$,
will usually be written $P(\vec x) \eqmunu A[P/X]$. 
We write $P \subseteq Q$ for 
$\forall \vec{x}\  (P(\vec{x}) \to Q(\vec{x}))$,
$P\equiv Q$ for $(P \subseteq Q)\land(Q \subseteq P)$, 
  $\forall x \in P\ A$ for $\forall x\  (P(x) \to  A)$, and
  $\exists x \in P\ A$ for $\exists  x\  (P(x) \land  A)$.
$\neg A \eqdef A \to \False$ where $\False\eqdef\mu(\lambda X\, X)$
and $X$ has empty arity (i.e.\ $X$ is a propositional variable). 
We identify $(\lambda\vec x\,A)(\vec t)$ with $A[\vec t/\vec x]$ where
$[\vec t/\vec x]$ means capture-avoiding substitution.
%
Formulas are identified with predicates of empty arity. 
Hence, every statement about predicates is also a statement about formulas.
In particular, $A\equiv B$
means that $A$ and $B$ are equivalent if $A$ and $B$ are formulas.

\begin{example}[Inductively defined predicates]
\label{ex-ind}
%
In our examples and case study, we work with
an instance of $\IFP$ (and also its extension $\CFP$) 
that contains a sort for real numbers,
whose language includes
constants, operations and relations such as 
$0,1,+,-,*, <, |\cdot|, /$.
 In this instance, one can express the predicate 
$\NN(x)$ that $x$ is a natural number inductively as
%
$$\NN(x) \eqmu  x = 0 \lor \NN(x-1) $$
%
which  is shorthand for 
%
$\NN \eqdef \mu(\lambda X\, \lambda x\, (x = 0 \lor X(x-1)))$.
\end{example}


\paragraph{Proofs.}
The proof rules 
of $\IFP$ are the 
usual natural deduction rules for 
intuitionistic first-order logic with equality 
plus rules for induction and 
coinduction, as shown in Table~\ref{table-proof-ifp},
where in a sequent $\Gamma\vdash A$ it is assumed that 
$\Gamma$ is a finite set of $\IFP$ formulas and $A$ is an $\IFP$ formula.
In the last four rules (in~\cite{IFP} called closure, induction, coclosure, coinduction),
$\Phi$ is a s.p.\ operator.
%
The induction rule has a strong and a half strong
variant where the premise is weakened to
$\Phi(P\cap\mu(\Phi))\subseteq P$ respectively $\Phi(P)\cap\mu(\Phi)\subseteq P$.
Similarly, the coinduction rule has a strong and a half strong
variant where the premise is weakened to
$P\subseteq\Phi(P\cup\nu(\Phi))$ respectively $P\subseteq\Phi(P)\cup\nu(\Phi)$.
Logically, these variants are redundant since they 
can be derived from the original versions. However, they can be given
more efficient realizers than those that would be obtained by extraction from 
their derivations (see~\cite{IFP}). 

\begin{table}
%
\fbox{\small
\begin{minipage}{\textwidth}
%
\begin{center}
%
$\Gamma, A \vdash A$
\hspace{3em} 
$\Gamma \vdash A$\quad ($A$ a non-computational axiom)
%
\\[1em]
%
$\Gamma \vdash t=t$
\hspace{3em} 
\AxiomC{$\Gamma\vdash A[s/x]$}
\AxiomC{$\Gamma\vdash s=t$}
             \BinaryInfC{$\Gamma \vdash A[t/x]$}
            \DisplayProof 
%
\\[1em]
%
\AxiomC{$\Gamma\vdash A$}
\AxiomC{$\Gamma\vdash B$}
             \BinaryInfC{$\Gamma \vdash A \land B$}
            \DisplayProof 
%
\hspace{2em} 
%
\AxiomC{$\Gamma \vdash A \land B$}
       \UnaryInfC{$\Gamma \vdash A$}
            \DisplayProof 
%
\hspace{2em} 
%
\AxiomC{$\Gamma \vdash A \land B$}
       \UnaryInfC{$\Gamma \vdash B$}
            \DisplayProof 
%
\\[1em]
%
\AxiomC{$\Gamma\vdash A$}
             \UnaryInfC{$\Gamma \vdash A\lor B$}
            \DisplayProof 
\hspace{2em} 
%
\AxiomC{$\Gamma\vdash B$}
             \UnaryInfC{$\Gamma \vdash A\lor B$}
            \DisplayProof %
\hspace{2em} 
%
\AxiomC{$\Gamma\vdash A \lor B$}\AxiomC{$\Gamma, A\vdash C$}\AxiomC{$\Gamma, B\vdash C$}             \TrinaryInfC{$\Gamma \vdash C$}
            \DisplayProof \ \ \ \ 
%
\\[1em]
%
\AxiomC{$\Gamma, A\vdash B$}
             \UnaryInfC{$\Gamma \vdash A\to B$}
            \DisplayProof 
\hspace{3em} 
\AxiomC{$\Gamma\vdash A \to B$}  
\AxiomC{$\Gamma\vdash A$}
             \BinaryInfC{$\Gamma \vdash B$}
            \DisplayProof \ \ \ \ 
%
\\[1em]
%
\AxiomC{$\Gamma \vdash A$}
             \UnaryInfC{$\Gamma \vdash \forall x\,A$}
            \DisplayProof
($x$ not free in $\Gamma$)
\hspace{2em}  
\AxiomC{$\Gamma \vdash \forall x\,A$}
             \UnaryInfC{$\Gamma \vdash A[t/x]$}
            \DisplayProof 
%
\\[0.5em]
%
\AxiomC{$\Gamma \vdash A[t/x]$}
             \UnaryInfC{$\Gamma \vdash \exists x\,A$}
            \DisplayProof
\hspace{2em}  
\AxiomC{$\Gamma \vdash \exists x\,A$}
\AxiomC{$\Gamma, A \vdash B$}
             \BinaryInfC{$\Gamma \vdash B$}
            \DisplayProof 
($x$ not free in $\Gamma,B$) 
%
\\[1em]
%
$\Gamma \vdash \Phi(\mu(\Phi))\subseteq \mu(\Phi)$
\hspace{3em} 
\AxiomC{$\Gamma \vdash \Phi(P)\subseteq P$}
             \UnaryInfC{$\Gamma \vdash \mu(\Phi)\subseteq P$}
            \DisplayProof 
%
\\[1em]
%
$\Gamma\vdash\nu(\Phi) \subseteq \Phi(\nu(\Phi))$
\hspace{3em} 
\AxiomC{$\Gamma \vdash P \subseteq \Phi(P)$}
             \UnaryInfC{$\Gamma \vdash P \subseteq \nu(\Phi)$}
            \DisplayProof 
\end{center}
\end{minipage}
}
\caption{Derivation rules of IFP. \label{table-proof-ifp}}
\end{table}

\paragraph{Axioms.}
$\IFP$, as well as all the systems introduced later, is parametric in 
a set $\ax$ of \emph{axioms}, which have to be 
%
\emph{non-computational 
(nc)} 
formulas, i.e., 
closed
formulas
%
built from atomic formulas by the propositional operators $\land$, $\to$,
the quantifiers $\forall$, $\exists$, and least and greatest fixed points.
Disjunction and other logical operators introduced later are excluded.
%
Axioms should be chosen such that they are true in an intended 
Tarskian model.
Since Tarskian semantics admits classical logic, this means that
a fair amount of classical logic is available through axioms.
For example, for each nc-formula $A(\vec x)$, stability, 
$\forall \vec x\,(\neg\neg A(\vec x) \to A(\vec x))$
can be postulated as an axiom.
%
The significance of the restriction to nc-formulas is that these
are identical to their (formalized) realizability interpretation given below.
In particular, Tarskian and realizability semantics coincide for axioms.
%
Throughout our examples and our case study (Section~\ref{sec-gray}), we will assume
in all proofs a set of nc axioms describing the arithmetic operations and the
ordering on the real numbers. Since these axioms have no bearing on
extracted programs, their exact choice does not matter. It suffices if
they are (classically) true in the real numbers.


\begin{rem}
\label{rem-nc}
It might look strange that nc-formulas must not contain disjunction 
but may contain the existential quantifier.
However, in our setting, the usual encoding of $A \lor B$ as
$\exists x \,.\, (x = 0 \to A) \land (x \neq 0 \to B)$ does not work,
since to prove the elimination rule,
$(A\lor B) \to (A\to C) \to (B\to C) \to C$, 
w.r.t.\  this encoding,
one needs a case analysis
on the formula $x=0$, or induction on natural numbers.
But this requires the encoding to be relativized to the natural numbers:
$\exists x \,.\, \NN(x) \land (x = 0 \to A) \land (x \neq 0 \to B)$. 
This is 
%
a formula containing disjunction in the definition of the inductive predicate $\NN$ 
(Example~\ref{ex-ind}).
\end{rem}



\subsection{RIFP (realizability for IFP)}
\label{sub-RIFP}
%
From an IFP proof of a formula $A$, one can extract a program $M$ that is a realization of the
computational content of $A$.
%
Realizability is formalized in an extension of $\IFP$, called $\RIFP$.
%
To give an informal overview,
program extraction is done by
\begin{enumerate}
\item\label{reali-type} 
defining, for each formula $A$, a subdomain $\tau(A)$  
and
a predicate $\rea(A)$ on 
the Scott domain $D$ (see Section~\ref{sub-denot} for the definition of $D$)  
specifying which elements of $\tau(A)$  
%
realize $A$.
We use types and programs as terms of RIFP to denote subdomains and elements of $D$, respectively.
%
\item\label{reali-prog} 
showing that 
from a proof of $A$ one can extract a program $M$ such that
the typing rules prove $M : \tau(A)$ and $\RIFP$ proves $\rea(A)(M)$
(and hence the program's denotation 
belongs to the subdomain $\tau(A)$ and satisfies $\rea(A)$).

\end{enumerate}

%
$\RIFP$ has additional sorts, constants,
and axioms.
$\RIFP$ has the new sorts $\delta$ 
for the domain $D$ 
and $\subd$ for the set of subdomains of $D$,
a binary relation symbol $:$ for the typing relation
(hence, for closed $M$ and $\rho$, $M:\rho$ means $\val{M}\in\tval{\rho}{}$,
in accordance with the notation introduced in Section~\ref{sub-denot})
as well as constants for the type and program constructs in Section~\ref{sec-ang}, 
excluding $\Am$, $\Amb$ and $\strictapp{}{}$. 
%
It also has axioms describing the denotational semantics of $\RIFP$ programs and types,
which can be found in~\cite{IFP}.
As a consequence, the typing rules of Table~\ref{fig-typing}, excluding those concerning
$\amb$ and $\Am$, are provable in $\IFP$.
In addition, RIFP has special predicate variables and type variables, corresponding to IFP 
predicate variables, as well as axioms connecting them, which we describe below.

%
To avoid `computational garbage' we distinguish between formulas with (nontrivial)
computational content and those with trivial computational content.
The latter are called \emph{Harrop formulas} and are defined as those $\IFP$ formulas
which contain at strictly positive positions neither free predicate variables nor 
disjunctions ($\lor$). 
Their
trivial computational content is represented by the
program $\Nil$.
A formula is \emph{non-Harrop} if it is not Harrop.
The definition of the Harrop property extends to predicates 
in the obvious way.



\begin{table}
\fbox{
\begin{minipage}{\textwidth}  
\begin{align*}
  %
  \tau(P(\vec t)) &= \tau(P)\\
  %
  \tau(A \lor B) &= \tau(A) + \tau(B)\\
  %
  \tau(A \land B) &= \tau(A) \times \tau(B) &\hbox{($A,B$ non-Harrop)}\\
  %
                    &= \tau(A)  &\hbox{($B$ Harrop, $A$ non-Harrop)}\\             
  %
                    &= \tau(B)  &\hbox{($A$ Harrop, $B$ non-Harrop)}\\             
  %
                 &= \one  &\hbox{($A,B$ Harrop)}\\             
  %
  \tau(A \to B) &= \ftyp{\tau(A)}{\tau(B)}  &\hbox{($A,B$ non-Harrop)}\\
                &= \tau(B)  &\hbox{(otherwise)}\\
  %
  \tau(\diamond x\,A) &= 
    \tau(A) &\hbox{($\diamond \in\{\forall,\exists\}$)}\\[.5em]
  %
  \tau(X) &= \alpha_X & \hspace{-1cm}
           \hbox{($X$ a predicate variable, $\alpha_X$ a fresh type variable)}\\
  %
  \tau(P) &= \one &\hbox{($P$ a predicate constant)}\\
  %
  \tau(\lambda \vec x\,A) &= \tau(A)\\
  %
  \tau(\diamond (\lambda X\,P)) &= \tfix{\alpha_X}{\tau(P)}
                    &\hbox{($\diamond \in\{\mu,\nu\}$, $\diamond (\lambda X\,P)$ non-Harrop)}\\
           &= \one &\hbox{($\diamond \in\{\mu,\nu\}$, $\diamond (\lambda X\,P)$ Harrop)}
  %
  \end{align*}
%
\end{minipage}
}
\caption{Types of $\IFP$ expressions. \label{table-type}}
\end{table}
%
Table~\ref{table-type} defines the type $\tau(A)$ of an $\IFP$ formula. 
%
Simultaneously, a type $\tau(P)$ is defined for every $\IFP$ predicate $P$.
For a predicate variable, $\tau(X)$ is a fresh type variable 
$\alpha_X$ representing the unknown type of the unknown predicate $X$.
One easily sees that $\tau(A) = \one$ iff $A$ is a Harrop formula,
and $\tau(A)$ is a regular type for every formula $A$ (Harrop or non-Harrop).
The regularity of $\tau(A)$ will continue to hold for formulas in the extension, $\CFP$,
of $\IFP$ (Lemma~\ref{lem-strict}).

The realizability predicate
$\rea(A)$ is defined 
in Table \ref{table-realizability} 
by structural recursion on the IFP formula $A$.
We often write $\ire{a}{A}$ for $\rea(A)(a)$ (`$a$ realizes $A$')
and $\re\,A$ for $\exists\, a\ \ire{a}{A}$ (`$A$ is realizable').
Simultaneously with $\rea(A)$, we define for every IFP predicate $P$ an 
$\RIFP$-predicate $\rea(P)$ with an extra argument for (potential) realizers.
Since Harrop formulas have trivial computational content, 
it only matters whether they are  realizable or not. 
Therefore, we define for a Harrop formula $A$, an $\RIFP$-formula
 $\reah(A)$ that represents the realizability of $A$. For a predicate variable, 
$\rea(X)$ is a fresh predicate variable $\reali{X}$
representing the unknown computational content of the unknown predicate $X$.



%
\begin{table}
%
\fbox{\small
\begin{minipage}{\textwidth}
$\rea(A)$ for Harrop formulas $A$:
\begin{align*}
%
\rea(A) &= \lambda a\,(a = \Nil \land \reah(A))
\hspace*{17.7em}
\\
%
\end{align*}

$\rea(A)$ for non-Harrop
formulas $A$:
\begin{align*}
%
\rea(P(\vec t)) &= \lambda a\,(\rea(P)(\vec t,a))\\
                                        \rea(A\lor B)   &=\lambda c\,(\ex{a}(c=\inl{a}\land\ire{a}{A})\lor
                              \ex{b}(c=\inr{b}\land\ire{b}{B}))\\
%
\rea(A\land B)  &=\left\{ \begin{array}{ll}
   \lambda c\,(\exists a,b\,(c = \Pair(a,b) \land \ire{a}{A}\land \ire{b}{B}))
                            &\hbox{($A,B$ non-Harrop)}\\
              \lambda a\,(\ire{a}{A} \land \reah(B)) 
                            &\hbox{($B$ Harrop)}\\
              \lambda b\,(\reah(A) \land \ire{b}{B})
                            &\hbox{($A$ Harrop)}
                          \end{array} \right.\\ 
\rea(A\to B)    &= \left\{ \begin{array}{ll}
  \lambda c\,(c:\ftyp{\tau(A)}{\tau(B)} \land  
          \all{a}(\ire{a}{A}\to\ire{(c\,a)}{B})) 
                     &\hbox{($A$ non-Harrop)}\\ 
          \lambda b\,(b:\tau(B) \land (\reah(A) \to \ire{b}{B}))  
                     &\hbox{($A$ Harrop)}
                           \end{array}\right.\\
\rea(\allex x\,A)  &=\lambda a\,(\allex x\,(\ire{a}{A})) 
  \qquad \hbox{($\allex\in\{\forall,\exists\}$)}\\
\end{align*} 

$\rea(P)$ for non-Harrop predicates $P$:
\begin{align*}
\rea(X) &= \reali{X} \\
%
\rea(\lambda \vec x\,A) &= \lambda (\vec x,a)\,(\ire{a}{A})  \\
\rea(\munu(\lambda X\,P)) &= 
\munu(\lambda\reali{X}\,\rea(P)
[\tfix{\alpha_X}{\tau(P)}/\alpha_X])
 \qquad \hbox{($\munu\in\{\mu,\nu\}$)} 
\hspace*{9em}
\\
\end{align*}
%
%
$\reah(A)$ for Harrop formulas $A$:
\begin{align*}
  \reah(P(\vec t)) &= \reah(P)(\vec t) \\ %
\reah(A\land B)  &=
      \reah(A)\land \reah(B) \\
%
\reah(A\to B)    &= \re\,A \to\reah(B)\\
%
\reah(\allex x\,A)  &=\allex x\,\reah(A)
  \quad \hbox{($\allex\in\{\forall,\exists\}$)}
\hspace*{18.6em}
\\
\end{align*}
%
$\reah(P)$ for Harrop predicates  $P$:
\begin{align*}
%
\reah(P) &= P\quad \hbox{($P$ a predicate constant)}\\
%
\reah(\lambda \vec x\,A) &= \lambda \vec x\,\reah(A) 
\\
%
\reah(\munu(\lambda X\,P)) &= \munu(\lambda X\,\reah_X(P))
  \qquad \hbox{($\munu\in\{\mu,\nu\}$)}
\hspace*{16em}
\\
%
\end{align*}
%
\begin{itemize}
\item Recall that $\ire{a}{A}$ stands for $\rea(A)(a)$ and 
$\re\,A$ stands for $\exists a\,\rea(A)(a)$.
\item To each $\IFP$ predicate variable $X$ there are 
assigned a fresh type variable $\alpha_X$ and a fresh $\RIFP$ predicate 
variable $\reali{X}$ with one extra argument for domain elements. 
%
\item $\reah_X(P) \eqdef\reah(P[\pcv{X}/X])[X/\pcv{X}]$
where $\pcv{X}$ is a fresh predicate constant assigned to the (non-Harrop) 
predicate variable $X$. 
This is motivated by the fact that $\munu(\lambda X\,P)$ is Harrop
iff $P[\pcv{X}/X]$ is. The idea is that $\reah_X(P)$ is the same as 
$\reah(P)$ but considering $X$ as a (Harrop) predicate constant.
\end{itemize}
\end{minipage}
}
\caption{Realizability interpretation of $\IFP$}
\label{table-realizability}
\end{table}
The main difference of our interpretation to the 
usual realizability interpretation of intuitionistic number theory lies in the
interpretation of quantifiers. While in number theory variables range over
natural numbers, which have concrete computationally meaningful representations,
we make no general assumption of this kind,
since it is our goal to extract programs from proofs in abstract mathematics.
This is the reason why we interpret quantifiers \emph{uniformly}, that is, 
a realizer of a universal statement must be independent
of the quantified variable and a realizer of an existential statement does not contain a
witness.
%
A similar uniform interpretation of quantifiers can be found in the
Minlog system.
The usual definition of realizability of quantifiers in intuitionistic number theory 
can be recovered by relativization to the inductively defined predicate $\NN$ in 
Example~\ref{ex-ind}, i.e., by writing
%
$\forall x\,(\NN(x) \to A)$.

\begin{example}[Natural numbers]
The type $\tau(\NN)$ assigned to the predicate $\NN$ 
(recall that $\NN(x) \eqmu  x = 0 \lor \NN(x-1)$)
is the 
type of unary lazy natural numbers,
%
$\nat\eqdef  \tfix{\alpha}{1+\alpha}$, introduced in Section~\ref{sec-ang}. 
%
Realizability for $\NN$ works out as
%
\[
\ire{a}{\NN(x)} \eqmu (a = \Left \land x = 0)  
\lor \exists b\,(a = \Right(b) \land \ire{b}{\NN(x-1))}\,.
\]
Therefore, the formulas $\NN(0)$, $\NN(1)$, $\NN(2)$, \ldots 
are realized by 
the domain elements $\Left$ ($= \Left(\Nil)$),
$\Right(\Left)$, $\Right(\Right(\Left))$, \ldots,
which means that if $x$ is a natural number, 
then the (unique) realizer of $\NN(x)$ is the unary 
(domain) representation of $x$ introduced in Section~\ref{sec-ang}.
Other ways of defining natural numbers may induce different
(e.g.~binary) representations.  
%
\end{example}
 
\begin{example}[Functions]
As an example of an extraction of a program with function type,
consider the formula 
expressing that the sum of two natural numbers is a natural number,
\begin{equation}
\label{eq:intro1}
\forall x, y\ (\NN(x) \to \NN(y) \to \NN(x+y)).
\end{equation}
It has type $\ftyp{\nat}{\ftyp{\nat}{\nat}}$ and
is realized by a function $f$ that, given realizers of $\NN(x)$ and $\NN(y)$, 
returns a realizer of $\NN(x+y)$, hence $f$ performs addition of unary numbers.
\end{example}

\begin{example}[Non-terminating realizer - this example will be used in Section~\ref{sec-gray}]
\label{ex-d}
Let
$$
\D(x) \eqdef  x\neq 0 \to (x\leq 0 \lor x\geq 0)\,.
$$  
Then 
$\tau(\D) = \bool$ where $\bool = \one + \one$, and $\ire{a}{\D(x)}$ 
%unfolds to
is equivalent to
$$
a: \bool \land (x \neq 0 \to (a = \Left \land x \leq 0) \lor 
(a = \Right \land x \geq 0)).
$$
Therefore, $\D(x)$ is realized by $\Left$ if $x < 0$ and by $\Right$ if $x > 0$.
If $x=0$, any element of $\bool$ realizes $\D(x)$,
in particular $\bot$. 
Hence, nonterminating programs of type $\bool$,
which denote $\bot$ by 
%
Lemma \ref{lem:ssp}~(\ref{lem:ssp:ade}),
%
realize 
$\D(0)$.
%
In contrast, \emph{strict} formulas (defined in Section~\ref{sub-CFP}) 
are never realized 
by a nonterminating program, as will be shown in Lemma~\ref{lem-strict}~(2)
in Section~\ref{sub-RCFP}.
%
\end{example}
%

\subsection{CFP}
\label{sub-CFP}

\paragraph{Language.}
$\CFP$ extends $\IFP$ by two propositional operators,
$\rt{A}{B}$ for restriction, and $\Set(B)$ for concurrency.
Logically, 
these operators 
are equivalent to $A \to B$ and $B$, respectively because
the logical rules in Table \ref{table-infrule} are valid in 
a Tarskian semantics provided we identify $\rt{A}{B}$ with $A \to B$ and 
$\Set(B)$ with $B$.  Their importance relies exclusively on their realizability
interpretations, which are meaningful only when the realizers of $B$ 
%
are neither $\bot$ nor of the form $\Amb(a,b)$.
Therefore, we require in $\rt{A}{B}$ and $\Set(B)$ 
the formula $B$ to be \emph{strict} in the following inductively defined sense\footnote{The notions ``strict'' in \cite{CFPesop} and ``productive'' in \cite{BergerSpreen23} have the same purpose and imply our notion of strictness.}: 
%
\begin{itemize}
%
  \item[-] Harrop formulas and disjunctions are strict 
(the notions of a Harrop formula and a s.p.\ position are extended to $\CFP$ below). 
\item[-] A non-Harrop conjunction is strict if either both conjuncts are non-Harrop or it is a conjunction of a Harrop formula and a strict formula.
\item[-] A non-Harrop implication is strict if the premise is non-Harrop.
\item[-] A formula of the form $\diamond x\,A$ ($\diamond\in\{\forall,\exists\}$) or $\munu(\lambda X\lambda\vec x\,A)$ ($\munu\in\{\mu,\nu\}$) is
 strict if $A$ is strict.
 \item[-] Formulas of other forms ($\rt{A}{B}$,  $\Set(B)$, $X(\vec{t})$) are not strict.
\end{itemize} 
%
The notion of a Harrop formula, referred to above, is extended to
$\CFP$ by disallowing at strictly positive positions 
not only disjunction and predicate variables, 
but also restriction, $\rt{A}{B}$, and concurrency, $\Set(B)$.
 %
Here, a position in a $\CFP$ expression
counts as strictly positive if for any occurrence of a subformula of the form 
$A \to B$  %,
 or $\rt{A}{B}$, that position is not in $A$. 
The operators used for least and greatest fixed point constructions 
are subject to this extended notion of strict positivity as well. 

A $\CFP$-formula is called \emph{well-formed} if it satisfies all the conditions 
above, i.e.\ in all its subformulas of the form $\rt{A}{B}$ or $\Set(B)$, the formula
$B$ is strict, and in all subformulas which are least or greatest fixed points of 
an operator, that operator must satisfy the above extended strict positivity condition.
%
Note that every $\IFP$ formula is also a well-formed $\CFP$ formula.
%
\paragraph{Proofs.}
The inference rules of $\CFP$ are those of $\IFP$ extended with the rules 
in Table~\ref{table-infrule} 
%
where all occurring formulas are assumed to be well-formed $\CFP$-formulas.
%
Since the rules in Table~\ref{table-infrule} do not change the assumptions 
of a sequent, we display them with formulas instead of sequents.
Hence, each premise or conclusion $A$ stands for a sequent $\Gamma\vdash A$
with the same $\Gamma$ in the premises and the conclusion of each rule.
%

\begin{table}
\medbreak
\noindent
\fbox{\small
\begin{minipage}{\textwidth}

\[
\infer[\hbox{\begin{tabular}{l}($A, B_0, B_1$ Harrop)\\
Rest-intro\end{tabular}
}]{
        \rt{A}{(B_0 \vee B_1)}
}{
A \to (B_0 \vee B_1) \ \ \     \neg A \to B_0 \wedge B_1
}
\]

\smallskip

\[
\begin{array}{ll}
\infer[\hbox{Rest-bind}]{
      \rt{A}{B'}
}{
 \rt{A}{B}\ \ \          B \to (\rt{A}{B'})
}
\ \ \ \ \ \ \ \ & 
\infer[\hbox{($B$ strict, $A$ well-formed) Rest-return}]{   \rt{A}{B}
}{
  B
}  \\\\
  \infer[\hbox{Rest-antimon}]{
    \rt{A'}{B}
    }{
      A' \to A \ \ \ \rt{A}{B}  
}&
  \infer[\hbox{Rest-mp}]{
    B
}{
\rt{A}{B} \ \ \    A
}
\end{array}
\]

\smallskip

\[
\begin{array}{ll}
  \infer[\hbox{($B$ well-formed and strict) Rest-efq}]{
  \rt{\False}{B}
}{
}
\ \ \ \ \ \ \ \ &
\infer[\hbox{Rest-stab}]{
    \rt{\neg\neg A}{B}
    }{
    \rt{A}{B}
}
%
\end{array}
\]

\smallskip

\[
  \infer[\hbox{Conc-lem}]{
  \Set(B)
}{
\rt{A}{B}   \ \ \ \     \rt{\neg A}{B}
}
%
\qquad
%
  \infer[\hbox{($B$ strict) Conc-return}]{\ 
  \Set(B)
}{
B
}
%
\]

\smallskip

\[
  \infer[\hbox{($B$ strict) Conc-mp}]{\
\Set(B)
}{
  A\to B\ \ \  \Set(A) 
}\ \ \ \ \ 
%
\]
%
%
\begin{itemize}
\item[] Assumption contexts are omitted since they do not change.
%
\end{itemize}
\end{minipage}
}
\medbreak
\caption{Inference rules for $\rt{A}{B}$ and $\Set{B}$ \label{table-infrule}.}
\end{table}


\subsection{RCFP (realizability for CFP)}
\label{sub-RCFP}
%
Realizability for $\CFP$ is expressed in $\RCFP$, an extension of $\RIFP$ by the 
type constructor $\Am$, the amb operator $\Amb$
 and the strict application operator $\strictapp{}{}$.
Note that $\RCFP$ is not an extension of $\CFP$ since %the operators
the propositional operators 
$\rt{A}{B}$ and $\Set(B)$ are not included.
Typing and realizability interpretation of $\CFP$-formulas are the 
extension of Table \ref{table-type} 
and Table \ref{table-realizability} with those in Table \ref{table-realizability-cfp}.
%
\begin{table}
\medbreak
\noindent
\fbox{\small
\begin{minipage}{\textwidth}
\begin{align*}
\tau(\rt{A}{B}) &= \tau(B) \\ \tau(\Set(B)) &= \Am(\tau(B))\ \end{align*}
\begin{align*}
  \rea(\rt{A}{B}) &= \lambda b\,( b\! :\! \tau(B) \land  
                                (\re\, A \to \defined{b}) \land
                               (\defined{b} \to b\,\re\,B)) 
                                         \\
\rea(\Set(B)) &= \lambda c\, \ex{a,b}\, 
      (c = \Amb(a, b) \land a,b:\tau(B) \land (\defined{a} \lor \defined{b})\ \land \\
              &\hspace{5em} (\defined{a} \to a\, \re\, B) \land 
                             (\defined{b} \to b\, \re\, B))
\end{align*}
\end{minipage}
}
\medbreak
\caption{Typing and realizability for $\rt{A}{B}$ and $\Set{B}$\label{table-realizability-cfp}.}
\end{table}
%
In addition to the axioms of $\RIFP$, $\RCFP$ has axioms for
strict application ($b\neq\bot \to\strictapp{a}{b}=a\,b$, $\strictapp{a}{\bot}=\bot$) 
and the type operator 
$\Am$ ($c:\Am(\rho) \toot (\exists a,b:\rho\,(c=\Amb(a,b)) \lor c=\bot)$).
In $\RCFP$ all typing rules of Table~\ref{fig-typing} are provable.
The proof rules of $\RCFP$ are those of $\RIFP$ (extended to $\RCFP$ formulas)
plus the law of excluded middle,
$A \lor \neg A$.
%

Note that in the name `$\RCFP$' the `C' should be interpreted as `classical' 
(rather than `concurrent') since $\RCFP$ is based on classical logic
but does not have nonstandard constructs for concurrency
(recall that, denotationally, the constructor $\Amb$ is just a pairing operator and 
$\Am$ constructs a type containing such pairs).

In the following, all lemmas and theorems concerning the denotational semantics
of programs and types, including realizability, can be formalized in $\RCFP$.

\begin{lem}
  \label{lem-strict}
  %
  For every well-formed $\CFP$-formula $A$:
\begin{enumerate}
% 
   \item\label{lem-strict-bot}
If $A$ is strict, then $\bot$ and domain elements of the form 
     $\Amb(a,b)$ do not realize $A$. 
     Furthermore, $\tau(A)$ is 
    determined.   
% 
   \item\label{lem-strict-reg}
$\tau(A)$ is a regular type.
% 
   \item\label{lem-strict-amb}
  $\Amb(\bot, \bot)$ is not a realizer of $A$,
   and if $\Amb(a, b)$ realizes $A$, then neither $a$ nor $b$ is
   of the form $\Amb(u,v)$. 
  \end{enumerate}
  \end{lem}
  %
  \begin{proof} 
%
(\ref{lem-strict-bot})
is easily proved by induction on the definition of strictness.

%
(\ref{lem-strict-reg})
is easily proved by structural induction on formulas, using the
    fact, proven in 
%
(\ref{lem-strict-bot}),
that the type of a strict formula is determined.
For least and greatest fixedpoints one 
also needs the following facts (a) and (b), 
both of which can be easily 
proven by induction on $A$:
(a) if $A$ is s.p.\ in $X$, % and $X$ occurs freely in $A$, 
then $\tau(A)$ is s.p.\ in $\alpha_X$, %and $\alpha_X$ occurs freely in $\tau(A)$,
(b) if $\tau(A)=\alpha_X$ and $\pcv{X}$ is a predicate constant, 
then $A[\pcv{X}/X]$ is Harrop.

%
To prove (\ref {lem-strict-amb}), assume that $\Amb(a,b)$ realizes $A$.
Then, by the definition of realizability, $A$ must be of the form $\Set(B)$
and $a$, $b$ cannot both be $\bot$. Furthermore, by well-formedness, 
$B$ is strict and therefore neither $a$ nor $b$ can be of the form $\Amb(u,v)$.
\end{proof}
%

\begin{rem}
\label{rem-harrop}
The characterization of Harrop formulas as those formulas whose type equals $\one$,
which is valid for $\IFP$, does no longer hold for $\CFP$ since
if $B$ is a Harrop formula, then $\tau(\rt{A}{B}) = \tau(B)=\one$,
but $\rt{A}{B}$ is not Harrop.  However, it is still the case that
Harrop formulas have type $\one$.
%
\end{rem}


The following lemma says that the result from \cite{IFP} regarding 
the typability
of realizers carries over to $\CFP$.
%
We use the notation
%
\[\adummy{\rho} \eqdef \lambda (\vec x,a)\,(a:\rho),\]
%
so that $Q\subseteq\adummy{\rho}$   unfolds to 
$\forall (\vec x,a)\,(Q(\vec x,a) \to a:\rho)$.
%
\begin{lem}
\label{lem-realizers-typed}
%
If $P$ is a $\CFP$ predicate, then 
$\RCFP$ proves $\rea(P)\subseteq\adummy{\tau(P)}$ from the 
assumptions
$\reali{X}\subseteq\adummy{\alpha_X}$ for every free predicate variable 
$X$ in $P$. 
In particular, if $P$ is a formula $A$, then $\ire{a}{A}$ implies $a:\tau(A)$
under these assumptions.
%
\end{lem}
%
\begin{proof}
%
The proof is by structural induction on $P$ and,
in the largest parts, carries over from \cite{IFP}.
For the case that $P$ is a predicate variable $X$, the assumption
$\reali{X}\subseteq\adummy{\alpha_X}$ is used. 
Looking at the definitions of realizability for $\rt{A}{B}$ and $\Set(B)$, 
one sees that they preserve the type correctness of realizers.
\end{proof}

%
\begin{lem}
\label{lem-prod-notbot}
For a program $M$ that realizes a well-formed formula $A$, 
              $M$ is productive iff $\val{M} \neq \bot$.
\end{lem}
\begin{proof}
%  (4) 
This follows from 
%
Lemma~\ref{lem-strict}~(\ref{lem-strict-reg}) and~(\ref{lem-strict-amb}), 
Lemma~\ref{lem-realizers-typed}, and Theorem~\ref{cor:ddatabot}.  
%
\end{proof}


%
  \begin{rem}
    \label{rem-partial}
    For a closed program $M$, we explain 
    the operational meaning of $\rea(\rt{A}{B})(M)$:
%
    By combining the definition of $\rea(\rt{A}{B})$ 
  with 
%
Lemma~\ref{lem-prod-notbot}, 
we see that 
  $\rea(\rt{A}{B})(M)$ says two things: 
  (1) if $A$ is realizable, then $M$ is productive, and
  (2) if $M$ is productive then $M$ realizes $B$.
  Recall that `productive' is the counterpart of `terminating' for concurrent 
  infinite computation. Therefore, one can consider (2) the 
 `partial correctness'  of $M$ with respect to the specification $B$.
  
  (1) and (2) together imply that if $A$ is realizable, then
 $M$ realizes $B$, a property one can call `conditional correctness' of $M$,
 and which is what $\rea(A \to B)(M)$ means if $A$ is Harrop
 (see Example~\ref{ex-d}).
 However, $\rea(\rt{A}{B})(M)$ says more than that.
 It says that even if $A$ is not realizable, 
 all the defined (i.e., non-bottom) values obtained by computing $M$ are correct.
 This is what we need for concurrent computation as we explained 
 in the introduction.


  To highlight the difference between restriction and implication
in a more concrete situation, 
consider $\rt{A}{(A\lor B)}$ vs.\ $A \to (A \lor B)$
where $A$ is Harrop. Clearly $\Left$ realizes $A \to (A \lor B)$,
but $\Left$ does not realize $\rt{A}{(A\lor B)}$ 
unless $A$ is realizable.
%
\end{rem}

%
\begin{rem}
  \label{rem-mult}
Next, let us discuss $\rea(\Set(B))(M)$ from an operational point of view:
%
By the 
%
Adequacy Lemma (\ref{lem:ssp}(\ref{lem:ssp:ade})), 
%
this formula
means that    
$M$ reduces with $\ssp^*$ to $\Amb(N, K)$ 
such that        
both terms $N$ and $K$ are partially correct realizers of $B$ 
and at least one of them is productive.  
    Therefore, by executing 
%
both 
concurrently and 
taking the one that produces some
value (i.e., is reduced to a deterministic w.h.n.f.), one has a realizer of $B$.
Hence, if $\rea(\Set(B))(M)$, 
then there is a program $M'$ such that $M\newprintp^* M'$  and 
$M'$ realizes $B$. 
This conclusion is a part of the Program Extraction Theorem (Theorem \ref{thm-pe}).
\end{rem}

\begin{rem}
\label{rem-reali-denot}
In the literature, realizability is usually \emph{operational},
i.e.\ realizers are syntactic objects, such as programs or processes 
(or codes thereof) with an operational semantics
%
(see e.g.\ Kleene's original realizability~\cite{Kleene45}, 
or Krivine's classical realizability~\cite{Krivine03}).
In contrast, in our setting realizability is \emph{denotational}
since realizers can be arbitrary (even uncomputable) 
elements of the Scott domain $D$. 
%(some of which may be denoted by programs).
%
The operational interpretation of realizability is 
provided indirectly, through the Computational Adequacy Theorem applied to programs
that denote realizers (the previous remarks refer to instances of this).
%
As an immediate consequence we obtain the operational correctness of 
the extracted programs
which is summarized in the Program Extraction Theorem (Thm.~\ref{thm-pe}).
%
This theorem states the realizability of a formula by a limit
of an infinite sequence of data that can, in general, 
not be represented by a single program.
%
Therefore, it is necessary to define realizability denotationally, 
for arbitrary domain elements. 
%
Moreover, the denotational approach 
makes results about realizability more abstract, 
more general, and also more robust since an extension of the programming language 
will not affect them. 
It also simplifies the specification and the proof of the
correctness of extracted programs~(Section~\ref{sec-pe}) 
since these can be formalized in the system $\RCFP$ whose soundness only 
refers to the denotational but not the operational semantics of programs.
%
\end{rem}


%
%






