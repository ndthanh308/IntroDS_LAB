\begin{thebibliography}{63}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Ali and Silvey(1966)}]{classic-fdiv}
S.~M. Ali and S.~D. Silvey. 1966.
\newblock \href {http://www.jstor.org/stable/2984279} {A general class of
  coefficients of divergence of one distribution from another}.
\newblock \emph{Journal of the Royal Statistical Society}, 28(1):131--142.

\bibitem[{Banerjee and Lavie(2005)}]{banerjee-lavie-2005-meteor}
Satanjeev Banerjee and Alon Lavie. 2005.
\newblock \href {https://aclanthology.org/W05-0909} {{METEOR}: An automatic
  metric for {MT} evaluation with improved correlation with human judgments}.
\newblock In \emph{Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic
  Evaluation Measures for Machine Translation and/or Summarization}, pages
  65--72.

\bibitem[{Bao et~al.(2020)Bao, He, Wang, Wu, and Wang}]{bao-etal-2020-plato}
Siqi Bao, Huang He, Fan Wang, Hua Wu, and Haifeng Wang. 2020.
\newblock \href {https://aclanthology.org/2020.acl-main.9} {{PLATO}:
  Pre-trained dialogue generation model with discrete latent variable}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 85--96.

\bibitem[{Barrault et~al.(2019)Barrault, Bojar, Costa-juss{\`a}, Federmann,
  Fishel, Graham, Haddow, Huck, Koehn, Malmasi, Monz, M{\"u}ller, Pal, Post,
  and Zampieri}]{barrault-etal-2019-findings}
Lo{\"\i}c Barrault, Ond{\v{r}}ej Bojar, Marta~R. Costa-juss{\`a}, Christian
  Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Philipp
  Koehn, Shervin Malmasi, Christof Monz, Mathias M{\"u}ller, Santanu Pal, Matt
  Post, and Marcos Zampieri. 2019.
\newblock \href {https://aclanthology.org/W19-5301} {Findings of the 2019
  {C}onference on {M}achine {T}ranslation ({WMT}19)}.
\newblock In \emph{Proceedings of the Conference on Machine Translation}, pages
  1--61.

\bibitem[{Bishop(2006)}]{bishop2006pattern}
Christopher~M. Bishop. 2006.
\newblock \href {https://link.springer.com/book/9780387310732} {\emph{Pattern
  Recognition and Machine Learning}}.
\newblock Springer.

\bibitem[{Bojar et~al.(2016)Bojar, Chatterjee, Federmann, Graham, Haddow, Huck,
  Jimeno~Yepes, Koehn, Logacheva, Monz, Negri, N{\'e}v{\'e}ol, Neves, Popel,
  Post, Rubino, Scarton, Specia, Turchi, Verspoor, and
  Zampieri}]{bojar-etal-2016-wmt16}
Ond{\v{r}}ej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry
  Haddow, Matthias Huck, Antonio Jimeno~Yepes, Philipp Koehn, Varvara
  Logacheva, Christof Monz, Matteo Negri, Aur{\'e}lie N{\'e}v{\'e}ol, Mariana
  Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia
  Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016.
\newblock \href {https://aclanthology.org/W16-2301} {Findings of the 2016
  {C}onference on {M}achine {T}ranslation}.
\newblock In \emph{Proceedings of the Conference on Machine Translation}, pages
  131--198.

\bibitem[{Buciluǎ et~al.(2006)Buciluǎ, Caruana, and
  Niculescu-Mizil}]{bucilua2006model}
Cristian Buciluǎ, Rich Caruana, and Alexandru Niculescu-Mizil. 2006.
\newblock \href {https://doi.org/10.1145/1150402.1150464} {Model compression}.
\newblock In \emph{Proceedings of the ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining}, page 535–541.

\bibitem[{Fan et~al.(2021)Fan, Li, Zhang, Ao, Wu, Meng, and
  Sun}]{fan-etal-2021-layer}
Chun Fan, Jiwei Li, Tianwei Zhang, Xiang Ao, Fei Wu, Yuxian Meng, and Xiaofei
  Sun. 2021.
\newblock \href {https://aclanthology.org/2021.emnlp-main.246} {Layer-wise
  model pruning based on mutual information}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 3079--3090.

\bibitem[{Fang et~al.(2021)Fang, Bao, Song, Wang, Xie, Shen, and
  Song}]{NEURIPS2021_63dc7ed1}
Gongfan Fang, Yifan Bao, Jie Song, Xinchao Wang, Donglin Xie, Chengchao Shen,
  and Mingli Song. 2021.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2021/file/63dc7ed1010d3c3b8269faf0ba7491d4-Paper.pdf}
  {Mosaicking to distill: Knowledge distillation from out-of-domain data}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  11920--11932.

\bibitem[{Frankle and Carbin(2018)}]{frankle2018lottery}
Jonathan Frankle and Michael Carbin. 2018.
\newblock \href {https://openreview.net/forum?id=rJl-b3RcF7} {The lottery
  ticket hypothesis: Finding sparse, trainable neural networks}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio}]{goodfellow2014GAN}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014.
\newblock \href
  {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}
  {Generative adversarial nets}.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Gu et~al.(2018)Gu, Bradbury, Xiong, Li, and Socher}]{gu2018non}
Jiatao Gu, James Bradbury, Caiming Xiong, Victor~OK Li, and Richard Socher.
  2018.
\newblock \href {https://openreview.net/forum?id=B1l8BtlCb&utm_campaign}
  {Non-autoregressive neural machine translation}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Hinton et~al.(2015)Hinton, Vinyals, Dean
  et~al.}]{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et~al. 2015.
\newblock \href {https://arxiv.org/abs/1503.02531} {Distilling the knowledge in
  a neural network}.
\newblock \emph{arXiv preprint arXiv:1503.02531}.

\bibitem[{Huang et~al.(2022)Huang, Zhou, Zaïane, Mou, and
  Li}]{Huang_Zhou_Zaïane_Mou_Li_2022}
Chenyang Huang, Hao Zhou, Osmar~R. Zaïane, Lili Mou, and Lei Li. 2022.
\newblock \href {https://doi.org/10.1609/aaai.v36i10.21323} {Non-autoregressive
  translation with layer-wise prediction and deep supervision}.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 10776--10784.

\bibitem[{Jiao et~al.(2021)Jiao, Chang, Yin, Shang, Jiang, Chen, Li, Wang, and
  Liu}]{jiao2021improving}
Xiaoqi Jiao, Huating Chang, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen,
  Linlin Li, Fang Wang, and Qun Liu. 2021.
\newblock \href
  {https://www.sciencedirect.com/science/article/pii/S0925231221010948}
  {Improving task-agnostic {BERT} distillation with layer mapping search}.
\newblock \emph{Neurocomputing}, 461:194--203.

\bibitem[{Jiao et~al.(2020)Jiao, Yin, Shang, Jiang, Chen, Li, Wang, and
  Liu}]{jiao-etal-2020-tinybert}
Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang
  Wang, and Qun Liu. 2020.
\newblock \href {https://aclanthology.org/2020.findings-emnlp.372}
  {{T}iny{BERT}: Distilling {BERT} for natural language understanding}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP}, pages 4163--4174.

\bibitem[{Kasai et~al.(2020)Kasai, Pappas, Peng, Cross, and
  Smith}]{kasai2020deep}
Jungo Kasai, Nikolaos Pappas, Hao Peng, James Cross, and Noah Smith. 2020.
\newblock \href {https://openreview.net/forum?id=KpfasTaLUpq} {Deep encoder,
  shallow decoder: Reevaluating non-autoregressive machine translation}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Keymanesh et~al.(2022)Keymanesh, Benton, and
  Dredze}]{keymanesh-etal-2022-makes}
Moniba Keymanesh, Adrian Benton, and Mark Dredze. 2022.
\newblock \href {https://aclanthology.org/2022.gem-1.50} {What makes
  data-to-text generation hard for pretrained language models?}
\newblock In \emph{Proceedings of the Workshop on Natural Language Generation,
  Evaluation, and Metrics}, pages 539--554.

\bibitem[{Kim and Rush(2016)}]{kim-rush-2016-sequence}
Yoon Kim and Alexander~M. Rush. 2016.
\newblock \href {https://www.aclweb.org/anthology/D16-1139} {Sequence-level
  knowledge distillation}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 1317--1327.

\bibitem[{Kingma and Ba(2015)}]{adam-optimizer}
Diederik~P. Kingma and Jimmy Ba. 2015.
\newblock \href {http://arxiv.org/abs/1412.6980} {Adam: {A} method for
  stochastic optimization}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Lebret et~al.(2016)Lebret, Grangier, and
  Auli}]{lebret-etal-2016-neural}
R{\'e}mi Lebret, David Grangier, and Michael Auli. 2016.
\newblock \href {https://aclanthology.org/D16-1128} {Neural text generation
  from structured data with application to the biography domain}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 1203--1213.

\bibitem[{LeCun et~al.(1989)LeCun, Denker, and Solla}]{classic-pruning}
Yann LeCun, John Denker, and Sara Solla. 1989.
\newblock \href
  {https://papers.nips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html}
  {Optimal brain damage}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  598--605.

\bibitem[{Lewis et~al.(2020)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer}]{lewis-etal-2020-bart}
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
  Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.
\newblock \href {https://aclanthology.org/2020.acl-main.703} {{BART}: Denoising
  sequence-to-sequence pre-training for natural language generation,
  translation, and comprehension}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 7871--7880.

\bibitem[{Li et~al.(2020)Li, Liu, Zhao, Xu, Yang, and Jin}]{li2020bertEMD}
Jianquan Li, Xiaokang Liu, Honghong Zhao, Ruifeng Xu, Min Yang, and Yaohong
  Jin. 2020.
\newblock \href {https://aclanthology.org/2020.emnlp-main.242} {{BERT}-{EMD}:
  Many-to-many layer mapping for {BERT} compression with earth mover{'}s
  distance}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 3009--3018.

\bibitem[{Li et~al.(2016{\natexlab{a}})Li, Galley, Brockett, Gao, and
  Dolan}]{li-etal-2016-dist}
Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan.
  2016{\natexlab{a}}.
\newblock \href {https://aclanthology.org/N16-1014/} {A diversity-promoting
  objective function for neural conversation models}.
\newblock In \emph{Proceedings of the Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 110--119.

\bibitem[{Li et~al.(2016{\natexlab{b}})Li, Monroe, Ritter, Jurafsky, Galley,
  and Gao}]{dialogue-reinforcement}
Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng
  Gao. 2016{\natexlab{b}}.
\newblock \href {https://aclanthology.org/D16-1127} {Deep reinforcement
  learning for dialogue generation}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 1192--1202.

\bibitem[{Li and Liang(2021)}]{li-liang-2021-prefix}
Xiang~Lisa Li and Percy Liang. 2021.
\newblock \href {https://aclanthology.org/2021.acl-long.353} {Prefix-tuning:
  Optimizing continuous prompts for generation}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics and the International Joint Conference on Natural
  Language Processing}, pages 4582--4597.

\bibitem[{Li et~al.(2022)Li, Hu, Guo, Chen, Qin, and
  Zhang}]{li-etal-2022-unsupervised-multiple}
Zhuoran Li, Chunming Hu, Xiaohui Guo, Junfan Chen, Wenyi Qin, and Richong
  Zhang. 2022.
\newblock \href {https://aclanthology.org/2022.acl-long.14} {An unsupervised
  multiple-task and multiple-teacher model for cross-lingual named entity
  recognition}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 170--179.

\bibitem[{Lin et~al.(2020)Lin, Wohlwend, Chen, and
  Lei}]{lin-etal-2020-autoregressive}
Alexander Lin, Jeremy Wohlwend, Howard Chen, and Tao Lei. 2020.
\newblock \href {https://aclanthology.org/2020.emnlp-main.494} {Autoregressive
  knowledge distillation through imitation learning}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 6121--6133.

\bibitem[{Lin(2004)}]{lin-2004-rouge}
Chin-Yew Lin. 2004.
\newblock \href {https://aclanthology.org/W04-1013} {{ROUGE}: A package for
  automatic evaluation of summaries}.
\newblock In \emph{Text Summarization Branches Out}, pages 74--81.

\bibitem[{Liu et~al.(2016)Liu, Lowe, Serban, Noseworthy, Charlin, and
  Pineau}]{liu-etal-2016-evaluate}
Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and
  Joelle Pineau. 2016.
\newblock \href {https://aclanthology.org/D16-1230} {How {NOT} to evaluate your
  dialogue system: An empirical study of unsupervised evaluation metrics for
  dialogue response generation}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 2122--2132.

\bibitem[{Liu et~al.(2018)Liu, Ren, Shang, Gu, Peng, and
  Han}]{liu-etal-2018-efficient}
Liyuan Liu, Xiang Ren, Jingbo Shang, Xiaotao Gu, Jian Peng, and Jiawei Han.
  2018.
\newblock \href {https://aclanthology.org/D18-1153} {Efficient contextualized
  representation: Language model pruning for sequence labeling}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 1215--1225.

\bibitem[{Louizos et~al.(2018)Louizos, Welling, and
  Kingma}]{louizos2018learning}
Christos Louizos, Max Welling, and Diederik~P Kingma. 2018.
\newblock \href {https://openreview.net/forum?id=H1Y8hhg0b} {Learning sparse
  neural networks through ${L}_0$ regularization}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Nan et~al.(2021)Nan, Radev, Zhang, Rau, Sivaprasad, Hsieh, Tang,
  Vyas, Verma, Krishna, Liu, Irwanto, Pan, Rahman, Zaidi, Mutuma, Tarabar,
  Gupta, Yu, Tan, Lin, Xiong, Socher, and Rajani}]{nan-etal-2021-dart}
Linyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad,
  Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna,
  Yangxiaokang Liu, Nadia Irwanto, Jessica Pan, Faiaz Rahman, Ahmad Zaidi,
  Mutethia Mutuma, Yasin Tarabar, Ankit Gupta, Tao Yu, Yi~Chern Tan,
  Xi~Victoria Lin, Caiming Xiong, Richard Socher, and Nazneen~Fatema Rajani.
  2021.
\newblock \href {https://aclanthology.org/2021.naacl-main.37} {{DART}:
  Open-domain structured data record to text generation}.
\newblock In \emph{Proceedings of the Conference of the North American Chapter
  of the Association for Computational Linguistics: Human Language
  Technologies}, pages 432--447.

\bibitem[{Narayan et~al.(2018)Narayan, Cohen, and
  Lapata}]{narayan-etal-2018-xsum}
Shashi Narayan, Shay~B. Cohen, and Mirella Lapata. 2018.
\newblock \href {https://aclanthology.org/D18-1206} {Don{'}t give me the
  details, just the summary! {T}opic-aware convolutional neural networks for
  extreme summarization}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, pages 1797--1807.

\bibitem[{Papineni et~al.(2002)Papineni, Roukos, Ward, and
  Zhu}]{papineni-etal-2002-bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.
\newblock \href {https://aclanthology.org/P02-1040} {{BLEU}: A method for
  automatic evaluation of machine translation}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 311--318.

\bibitem[{Paulus et~al.(2018)Paulus, Xiong, and Socher}]{paulus2018deep}
Romain Paulus, Caiming Xiong, and Richard Socher. 2018.
\newblock \href {https://openreview.net/forum?id=HkAClQgA-} {A deep reinforced
  model for abstractive summarization}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Popovi{\'c}(2015)}]{popovic-2015-chrf}
Maja Popovi{\'c}. 2015.
\newblock \href {https://aclanthology.org/W15-3049} {chr{F}: character n-gram
  {F}-score for automatic {MT} evaluation}.
\newblock In \emph{Proceedings of the Tenth Workshop on Statistical Machine
  Translation}, pages 392--395.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, Liu et~al.}]{t52020}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, Peter~J Liu, et~al. 2020.
\newblock \href {https://jmlr.org/papers/v21/20-074.html} {Exploring the limits
  of transfer learning with a unified text-to-text {T}ransformer.}
\newblock \emph{Journal of Machine Learning Research}, 21(140):1--67.

\bibitem[{Sason and Verdú(2016)}]{ieee-fdiv}
Igal Sason and Sergio Verdú. 2016.
\newblock \href {https://ieeexplore.ieee.org/abstract/document/7552457}
  {$f$-divergence inequalities}.
\newblock \emph{IEEE Transactions on Information Theory}, 62(11):5973--6006.

\bibitem[{Sellam et~al.(2020)Sellam, Das, and Parikh}]{sellam-etal-2020-bleurt}
Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.
\newblock \href {https://aclanthology.org/2020.acl-main.704} {{BLEURT}:
  Learning robust metrics for text generation}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 7881--7892.

\bibitem[{Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch}]{sennrich-etal-2016-neural}
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.
\newblock \href {https://doi.org/10.18653/v1/P16-1162} {Neural machine
  translation of rare words with subword units}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 1715--1725.

\bibitem[{Shao et~al.(2022)Shao, Wu, and Feng}]{shao-etal-2022-one}
Chenze Shao, Xuanfu Wu, and Yang Feng. 2022.
\newblock \href {https://aclanthology.org/2022.naacl-main.277} {One reference
  is not enough: Diverse distillation with reference selection for
  non-autoregressive translation}.
\newblock In \emph{Proceedings of the Conference of the North American Chapter
  of the Association for Computational Linguistics: Human Language
  Technologies}, pages 3779--3791.

\bibitem[{Shazeer and Stern(2018)}]{pmlr-v80-adafactor}
Noam Shazeer and Mitchell Stern. 2018.
\newblock \href {https://proceedings.mlr.press/v80/shazeer18a.html} {Adafactor:
  Adaptive learning rates with sublinear memory cost}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 4596--4604.

\bibitem[{Shleifer and Rush(2020)}]{shleifer2020pre}
Sam Shleifer and Alexander~M Rush. 2020.
\newblock \href {https://arxiv.org/abs/2010.13002} {Pre-trained summarization
  distillation}.
\newblock \emph{arXiv preprint arXiv:2010.13002}.

\bibitem[{Snover et~al.(2006)Snover, Dorr, Schwartz, Micciulla, and
  Makhoul}]{snover-etal-2006-study}
Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, and John Makhoul.
  2006.
\newblock \href {https://aclanthology.org/2006.amta-papers.25} {A study of
  translation edit rate with targeted human annotation}.
\newblock In \emph{Proceedings of the Conference of the Association for Machine
  Translation in the Americas: Technical Papers}, pages 223--231.

\bibitem[{Sun et~al.(2019)Sun, Cheng, Gan, and Liu}]{sun2019pkd}
Siqi Sun, Yu~Cheng, Zhe Gan, and Jingjing Liu. 2019.
\newblock \href {https://aclanthology.org/D19-1441} {Patient knowledge
  distillation for {BERT} model compression}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing and the International Joint Conference on Natural
  Language Processing}, pages 4323--4332.

\bibitem[{Tang et~al.(2022)Tang, Zhao, Wang, Luo, Xie, and
  Zeng}]{Tang_Zhao_Wang_Luo_Xie_Zeng_2022}
Chuanxin Tang, Yucheng Zhao, Guangting Wang, Chong Luo, Wenxuan Xie, and Wenjun
  Zeng. 2022.
\newblock \href {https://ojs.aaai.org/index.php/AAAI/article/view/20133}
  {Sparse {MLP} for image recognition: Is self-attention really necessary?}
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 2344--2351.

\bibitem[{Tang et~al.(2019)Tang, Lu, Liu, Mou, Vechtomova, and
  Lin}]{tang2019distilling}
Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, and Jimmy Lin.
  2019.
\newblock \href {https://arxiv.org/abs/1903.12136} {Distilling task-specific
  knowledge from {BERT} into simple neural networks}.
\newblock \emph{arXiv preprint arXiv:1903.12136}.

\bibitem[{Tu et~al.(2020)Tu, Pang, Wiseman, and Gimpel}]{tu-etal-2020-engine}
Lifu Tu, Richard~Yuanzhe Pang, Sam Wiseman, and Kevin Gimpel. 2020.
\newblock \href {https://aclanthology.org/2020.acl-main.251} {{ENGINE}:
  Energy-based inference networks for non-autoregressive machine translation}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, pages 2819--2826.

\bibitem[{Wei et~al.(2019)Wei, Lu, Mou, Zhou, Poupart, Li, and
  Jin}]{wei2019neural}
Bolin Wei, Shuai Lu, Lili Mou, Hao Zhou, Pascal Poupart, Ge~Li, and Zhi Jin.
  2019.
\newblock \href {https://ieeexplore.ieee.org/document/8682634} {Why do neural
  dialog systems generate short and meaningless replies? {A} comparison between
  dialog and translation}.
\newblock In \emph{Proceedings of the International Conference on Acoustics,
  Speech and Signal Processing}, pages 7290--7294.

\bibitem[{Wen et~al.(2023)Wen, Hao, Cao, and Mou}]{wen2022equal}
Yuqiao Wen, Yongchang Hao, Yanshuai Cao, and Lili Mou. 2023.
\newblock \href {https://openreview.net/forum?id=k5PEHHY4spM} {An equal-size
  hard {EM} algorithm for diverse dialogue generation}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Wu et~al.(2021)Wu, Wu, and Huang}]{wu2021one}
Chuhan Wu, Fangzhao Wu, and Yongfeng Huang. 2021.
\newblock \href {https://aclanthology.org/2021.findings-acl.387} {One teacher
  is enough? {P}re-trained language model distillation from multiple teachers}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL-IJCNLP}, pages 4408--4413.

\bibitem[{Yang et~al.(2020)Yang, Shou, Gong, Lin, and Jiang}]{multi-teacher-3}
Ze~Yang, Linjun Shou, Ming Gong, Wutao Lin, and Daxin Jiang. 2020.
\newblock \href {https://doi.org/10.1145/3336191.3371792} {Model compression
  with two-stage multi-teacher knowledge distillation for web question
  answering system}.
\newblock In \emph{Proceedings of the International Conference on Web Search
  and Data Mining}, page 690–698.

\bibitem[{Yin et~al.(2020)Yin, Molchanov, Alvarez, Li, Mallya, Hoiem, Jha, and
  Kautz}]{Yin_2020_CVPR}
Hongxu Yin, Pavlo Molchanov, Jose~M. Alvarez, Zhizhong Li, Arun Mallya, Derek
  Hoiem, Niraj~K. Jha, and Jan Kautz. 2020.
\newblock \href
  {https://openaccess.thecvf.com/content_CVPR_2020/html/Yin_Dreaming_to_Distill_Data-Free_Knowledge_Transfer_via_DeepInversion_CVPR_2020_paper.html}
  {Dreaming to distill: Data-free knowledge transfer via {D}eep{I}nversion}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 8715--8724.

\bibitem[{Yu et~al.(2017)Yu, Zhang, Wang, and Yu}]{Yu_Zhang_Wang_Yu_2017}
Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017.
\newblock \href {https://ojs.aaai.org/index.php/AAAI/article/view/10804}
  {Seq{GAN}: Sequence generative adversarial nets with policy gradient}.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 2852--2858.

\bibitem[{Zhang et~al.(2020{\natexlab{a}})Zhang, Zhao, Saleh, and
  Liu}]{pmlr-v119-zhang20ae}
Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. 2020{\natexlab{a}}.
\newblock \href {https://proceedings.mlr.press/v119/zhang20ae.html} {{PEGASUS}:
  Pre-training with extracted gap-sentences for abstractive summarization}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 11328--11339.

\bibitem[{Zhang et~al.(2019)Zhang, Kishore, Wu, Weinberger, and
  Artzi}]{zhang2019bertscore}
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian~Q Weinberger, and Yoav Artzi.
  2019.
\newblock \href {https://openreview.net/forum?id=SkeHuCVFDr} {{BERTS}core:
  Evaluating text generation with {BERT}}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Zhang et~al.(2021)Zhang, Niu, and Sugiyama}]{pmlr-v139-zhang21n}
Yivan Zhang, Gang Niu, and Masashi Sugiyama. 2021.
\newblock \href {https://proceedings.mlr.press/v139/zhang21n.html} {Learning
  noise transition matrix from only noisy labels via total variation
  regularization}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 12501--12512.

\bibitem[{Zhang et~al.(2020{\natexlab{b}})Zhang, Sun, Galley, Chen, Brockett,
  Gao, Gao, Liu, and Dolan}]{zhang-etal-2020-dialogpt}
Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao,
  Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020{\natexlab{b}}.
\newblock \href {https://aclanthology.org/2020.acl-demos.30} {{DIALOGPT} :
  Large-scale generative pre-training for conversational response generation}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics: System Demonstrations}, pages 270--278.

\bibitem[{Zhao et~al.(2020)Zhao, Cong, Dai, and Carin}]{zhao2020rkl}
Miaoyun Zhao, Yulai Cong, Shuyang Dai, and Lawrence Carin. 2020.
\newblock \href {https://ojs.aaai.org/index.php/AAAI/article/view/6172}
  {Bridging maximum likelihood and adversarial learning via
  $\alpha$-divergence}.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 6901--6908.

\bibitem[{Zhao et~al.(2019)Zhao, Peyrard, Liu, Gao, Meyer, and
  Eger}]{zhao-etal-2019-moverscore}
Wei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Christian~M. Meyer, and Steffen
  Eger. 2019.
\newblock \href {https://aclanthology.org/D19-1053} {{M}over{S}core: Text
  generation evaluating with contextualized embeddings and earth mover
  distance}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing and the International Joint Conference on Natural
  Language Processing}, pages 563--578.

\bibitem[{Zhou et~al.(2021)Zhou, Gopalakrishnan, Hedayatnia, Kim, Pujara, Ren,
  Liu, and Hakkani-Tur}]{zhou-etal-2021-commonsense}
Pei Zhou, Karthik Gopalakrishnan, Behnam Hedayatnia, Seokhwan Kim, Jay Pujara,
  Xiang Ren, Yang Liu, and Dilek Hakkani-Tur. 2021.
\newblock \href {https://aclanthology.org/2021.sigdial-1.13}
  {Commonsense-focused dialogues for response generation: An empirical study}.
\newblock In \emph{Proceedings of the Annual Meeting of the Special Interest
  Group on Discourse and Dialogue}, pages 121--132.

\end{thebibliography}
