%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

\documentclass[12pt]{article}
%
\usepackage[T1]{fontenc}
\usepackage{graphicx}
 
%\documentclass[review]{elsarticle} %preprint,12pt
\pdfminorversion=7
%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
%\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\usepackage{enumitem}

\newcommand{\Figure}{Figure\xspace}
\newcommand{\Algorithm}{Algorithm\xspace}
\newcommand{\Algorithms}{Algorithms\xspace}
\newcommand{\SectionAbv}{Section\xspace}
\newcommand{\SectionsAbv}{Sections\xspace}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\pinf}{\mathcal{\ell}_\sS}
\newcommand{\init}{\mathsf{init}}

\usepackage{amsmath,amssymb,latexsym,amsopn,amsfonts}
\usepackage[boxed,ruled,vlined,linesnumbered,noresetcount]{algorithm2e}
\newcommand\bull{{\operatorname{-\xspace}}}
%\usepackage{url,fullpage}
\usepackage{fullpage}
\usepackage{framed} %microtype
\usepackage[normalem]{ulem}
%\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{array,xspace}
%
\usepackage{graphicx}
%
%\usepackage[hidelinks]{hyperref} %% Hyperref after all packages
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\definecolor{orange}{rgb}{0.99, 0.27, 0.0}
\definecolor{frenchBlue}{rgb}{0.13, 0.55, 0.13}
%
%\newcommand{\EMS}[1]{[\textcolor{blue}{EMS: #1}]}
\newcommand{\ems}[1]{\textcolor{black}{#1}}
\newcommand{\emsA}[1]{\textcolor{black}{#1}}
%\newcommand{\emsB}[1]{{#1}} % \textcolor{blue}
%\newcommand{\emsC}[1]{\textcolor{black}{#1}}
%\newcommand{\CGC}[1]{[\textcolor{red}{CG: #1}]} %{\textcolor{blue}{#1}}
%\newcommand{\cgu}[1]{\textcolor{red}{#1}}
%
%\newcommand{\emS}[1]{\sout{\textcolor{orange}{#1}}}
%\newcommand{\eMs}[1]{\textcolor{orange}{#1}}
%\definecolor{oskar_green}{rgb}{0.0, 0.5, 0.0}
%\newcommand{\OL}[1]{\textcolor{oskar_green}{[\textbf{OL: #1}]}}
%\newcommand{\EE}[1]{#1}%{\textcolor{blue}{[\textbf{EE: #1}]}}
\newcommand{\algSize}{normalsize} %scriptsize %normalsize  
%\newcommand{\algSizeSmall}{scriptsize} %scriptsize %normalsize  
%\newcommand{\algSizeVerySmall}{scriptsize}

\newcommand{\rv}[1]{#1}%{{Red}{#1}}
\newcommand{\nw}[1]{#1}%{\textcolor{Cerulean}{#1}}
\newcommand{\up}[1]{#1}%{\textcolor{ForestGreen}{#1}}
%\usepackage[margin=0.99in]{geometry}


\newcommand{\IM}[1]{[\textcolor{magenta}{IM: #1}]} %{\textcolor{blue}{#1}}
\newcommand{\im}[1]{\textcolor{magenta}{#1}}

%\usepackage[printwatermark]{xwatermark}
%\usepackage{xcolor}

\newcommand{\blitza}{{\usefont{U}{ulsy}{m}{n}\symbol{'011}}}
\newcommand{\trusted}{\mathsf{progressing}\xspace}

\newcommand{\B}{}%{\vspace*{-\smallskipamount}}
\newcommand{\BB}{}%{\vspace*{-\medskipamount}}
\newcommand{\BBB}{}%{\vspace*{-\bigskipamount}}
\newcommand{\F}{\vspace*{\smallskipamount}}
\newcommand{\FF}{\vspace*{\medskipamount}}
\newcommand{\FFF}{\vspace*{\bigskipamount}}
\newcommand{\T}{\hspace*{1em}}
\newcommand{\TT}{\hspace*{2em}}
\newcommand{\TTT}{\hspace*{3em}}
\newcommand{\NT}{\hspace*{-1em}}

\usepackage{wrapfig}

%\newwatermark[allpages,color=red!50,angle=45,scale=3,xpos=0,ypos=0]{CONFIDENTIAL}



%\usepackage{xcolor}
%\usepackage[framemethod=tikz]{mdframed}

%\newcommand{\xspace}{}
\newcommand{\polylog}{\mathrm{polylog}\xspace}
\newcommand{\bigO}{\mathcal{O}\xspace}
\newcommand{\remove}[1]{}
\newcommand{\reduce}[1]{#1}
\newcommand{\smallO}{\mathrm{o}\xspace}

\newcommand{\txS}{\mathit{txObsS}\xspace}
\newcommand{\txSJ}{\mathit{txObsSJ}\xspace}
\newcommand{\rxS}{\mathit{rxObsS}\xspace}
\newcommand{\rxSJ}{\mathit{rxObsSJ}\xspace}
\newcommand{\maxS}{\mathsf{maxSeq}\xspace}
\newcommand{\obsolete}{\mathsf{obsolete}\xspace}
\newcommand{\maxSeq}{\mathsf{maxSeq}\xspace}
\newcommand{\minTxObstSeq}{\mathsf{minTxObsS}\xspace}
\newcommand{\msgSet}{\mathit{buffer}\xspace}
\newcommand{\gc}{\mathit{delivered}\xspace} %garbageCollection
\newcommand{\GC}{\textit{delivered}\xspace} %garbageCollection
\newcommand{\txD}{\mathit{txDes}\xspace} %txDescriptor
\newcommand{\exist}{\mathsf{hasTerminated}\xspace}
\newcommand{\nonActive}{\mathsf{allHaveTerminated}\xspace}
\newcommand{\done}{\mathsf{result}\xspace}
\newcommand{\deactivate}{\mathsf{deactivate}\xspace}
\newcommand{\test}{\mathsf{test}\xspace} %{\mathsf{consistencyTest}\xspace}
\newcommand{\dCS}{\bot} %{\mathrm{defaultCS}\xspace}
\newcommand{\dBS}{\bot} %{\mathrm{defaultBS}\xspace}
\newcommand{\counts}{\mathsf{counts}\xspace}
\newcommand{\checkC}{\mathsf{check}\xspace}
\newcommand{\Correct}{\mathit{Correct}\xspace}



\newcommand{\snapshotIteration}{\mathrm{baseSnapshot}}
\newcommand{\exceed}{\Delta}	
\newcommand{\pndSnap}{pndTsk}
\newcommand{\repSnap}{repSnap}
\newcommand{\etal}{\emph{et al.}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\Eg}{\emph{E.g.,}\xspace}
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\Ie}{\emph{I.e.,}\xspace}
\newcommand{\figScale}{0.5}

%\usepackage{etoolbox}
%\patchcmd{\thebibliography}{\chapter*}{\section*}{}{}

\newtheorem{challenge}{Challenge}[section]
%\newtheorem{requirement}{Requirement}[section]
%\newtheorem{remark}{Remark}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{property}[theorem]{Property}
\newtheorem{definition}{Definition}[section]
\newtheorem{interface}{Interface}[section]
%%%%%%%%%% ARGUMENTS MADE INTO LEMMAS %%%%%%%%%%%%%%
\newtheorem{argument}{Lemma}[section]
%\newtheorem{argument}{Argument}[section]
\newtheorem{assumption}{Assumption}
\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{claim}[theorem]{Claim}
\newtheorem{myClaim}{Claim}
\newcommand{\true}{\mathsf{True}\xspace}
\newcommand{\True}{\textsf{True}\xspace}
\newcommand{\false}{\mathsf{False}\xspace}
\newcommand{\False}{\textsf{False}\xspace}

\newcommand{\sS}{\mathcal{S}\xspace}
\newcommand{\sP}{\mathcal{P}\xspace}
\newcommand{\sT}{\mathcal{REMOVE}}
\newcommand{\sV}{\mathcal{REMOVE}}
\newcommand{\sD}{\mathcal{REMOVE}}
\newcommand{\sQ}{\mathcal{REMOVE}}
\newcommand{\N}{\mathbb{N}\xspace}
\newcommand{\capacity}{\mathsf{channelCapacity}\xspace}
\newcommand{\buffCapacity}{\mathsf{bufferUnitSize}\xspace}

\newcommand{\op}{\mathsf{op}\xspace}
\newcommand{\sWrite}{\mathsf{write}\xspace}
\newcommand{\sSnapshot}{\mathsf{snapshot}\xspace}
\newcommand{\sStore}{\mathsf{safeReg}\xspace}
\newcommand{\qdplt}{\text{qdplt}\xspace}



%\newcommand*{\TitleFont}{%
%      \usefont{\encodingdefault}{\rmdefault}{} {n}%
%      \fontsize{20}{0}%
%      \selectfont}
%\newcommand*{\AffFont}{%
%      \usefont{\encodingdefault}{\rmdefault}{} {n}%
%      \fontsize{10}{-5}%
%      \selectfont}
%\newcommand*{\AuthorFont}{%
%      \usefont{\encodingdefault}{\rmdefault}{} {n}%
%      \fontsize{12}{1}%
%      \selectfont}
%\makeatletter
%\def\thm@space@setup{\thm@preskip=0pt
%\thm@postskip=0pt}
%\makeatother
%\makeatletter
%\newenvironment{pf}[1][\proofname]{\par
%  \pushQED{\qed}%
%  \normalfont \topsep0\p@\relax
%  \trivlist
%  \item[\hskip\labelsep\itshape
%  #1\@addpunct{.}]\ignorespaces
%}{%
%  \popQED\endtrivlist\@endpefalse
%}
%\makeatother

%\newcommand{\F}{\vspace*{\smallskipamount}}
%\newcommand{\FF}{\vspace*{\medskipamount}}
%\newcommand{\FFF}{\vspace*{\bigskipamount}}
%\usepackage{xparse}




\newenvironment{majority}{maj}

\newenvironment{Argument}{Lemma}

\newenvironment{Arguments}{Lemmas}

%\usepackage{caption}
%\setcapindent{0pt}
%\addtokomafont{caption}{\centering}

\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}

\newenvironment{claimProof}{\par\noindent\textbf{Proof of Claim  \clmcnt\space}}{\hfill $\Box_{Claim ~ \clmcnt}$}
\newenvironment{claimProofSketch}{\par\noindent\textbf{Proof Sketch of Claim  \clmcnt\space}}{\hfill $\Box_{Claim ~ \clmcnt}$}
\newenvironment{lemmaProof}{\par\noindent\textbf{Proof of Lemma  \lemcnt\space}}{\hfill $\Box_{Lemma ~ \lemcnt}$}
\newenvironment{lemmaProofSketch}{\par\noindent\textbf{Proof Sketch of Lemma  \lemcnt\space}}{\hfill $\Box_{Lemma ~ \lemcnt}$}
\newenvironment{theoremProof}{\par\noindent\textbf{Proof of Theorem  \thmcnt\space}}{\hfill $\Box_{Theorem ~ \thmcnt}$}
\newenvironment{theoremProofSketch}{\par\noindent\textbf{Proof Sketch of Theorem  \thmcnt\space}}{\hfill $\Box_{Theorem ~ \thmcnt}$}
\newcommand{\clmcnt}{0}
\newcommand{\lemcnt}{0}
\newcommand{\thmcnt}{0}


\newenvironment{proof}{\noindent \textbf{Proof.}}{\hfill$\blacksquare$}
%\renewenvironment{claimProof}{\noindent\textbf{Proof of claim.}}{\hfill$\Box$}
\newenvironment{proofsketch}{\noindent\textbf{Proof Sketch.}}{\hfill$\Box$}



\newcommand{\Section}[1]{\BBB\section{#1}\BB}
%\newcommand{\Subsection}[1]{\subsection{#1}}
%%\newcommand{\SubsectionS}[1]{\subsection*{#1}}
%\newcommand{\Subsubsection}[1]{\subsubsection{#1.}}
%\newcommand{\Subsubsubsection}[1]{\paragraph{#1.}}

%\newcommand{\Subsubsubsubsection}[1]{\subparagraph{#1}}
%\newcommand{\SSubsection}[1]{\FF \paragraph{#1}~~~~~~}
%\newcommand{\Subsubsection}[1]{\subparagraph{#1.}~~~~~~}


\newcommand{\Subsection}[1]{\smallskip\noindent \textbf{#1.}~~~}
\newcommand{\Subsubsection}[1]{\noindent \emph{#1.}~~}
\newcommand{\Subsubsubsection}[1]{\noindent $\bullet$ \textbf{#1}~~~~~~}

%\newcommand{\Subsubsection}[1]{\smallskip\noindent \emph{#1.~~~}}
%\newcommand{\SUBsubsection}[1]{\FF \noindent $\bullet$ \emph{#1}~~~~~~}%\circ~

%\newcommand{\cg}[1]{\textcolor{blue}{#1}}
%\newcommand{\cgr}[1]{\textcolor{red}{[CG: #1]}}
%\newcommand{\cgred}[1]{#1}%{\textcolor{red}{#1}}

\usepackage[utf8]{inputenc}

%\setcounter{section}{1}
%\setcounter{\thesubsection}{4}

%Conf version
\newcommand{\technicalReport}[1]{#1}%{\textcolor{red}{TR START}#1\textcolor{blue}{TR END}}%{#1}
\newcommand{\extendedAbstract}[1]{}%{#1}%{\textcolor{orange}{EA START}#1\textcolor{purple}{EA END}}

%{#1}

%TR version
%\newcommand{\technicalReport}[1]{#1}
%\newcommand{\extendedAbstract}[1]{}

%\newcommand{\rmAlg}[1]{SSBFT multivalued consensus\xspace}
%\newcommand{\rvAlg}[1]{Algorithm~\ref{alg:ssbftMVC}\xspace}

%\renewcommand{\baselinestretch}{0.98}

\hyphenation{sta-bi-li-z-ing}

%\slopy  

\raggedbottom
\setcounter{footnote}{0}
%\flushbottom 
\begin{document}





\technicalReport{\title{Self-stabilizing Byzantine-tolerant Recycling \footnote{This document is a complementary technical report to the extended abstract version of this work~\cite{TR}.}}}

\extendedAbstract{\title{Self-stabilizing Byzantine-tolerant Recycling}}
%\extendedAbstract{\subtitle{(extended abstract)}}


	\author{Chryssis Georgiou \footnote{ Computer Science, Univ. Cyprus, Cyprus.
				Email: \texttt{chryssis@cs.ucy.ac.cy}} \and
	Michel Raynal \footnote{ IRISA, Univ. Rennes 1, France.
			Email: \texttt{michel.raynal@irisa.fr}} \and
	Elad M.\ Schiller \footnote{ Computer Science and Engineering, Chalmers Univ. Tech., Sweden.
			Email: \texttt{elad@chalmers.se}}}
%
%\authorrunning{C.\ Georgiou, M.\ Raynal, E.\ M.\ Schiller}

%\institute{Computer Science, Univ. Cyprus, Cyprus.
%	\email{chryssis@cs.ucy.ac.cy} \and
%	\textit{IRISA, Univ. Rennes 1}, France.
%	\email{michel.raynal@irisa.fr}\and
%	Computer Science and Engineering, Chalmers Univ. Tech., Sweden.
%	\email{elad@chalmers.se}}

\maketitle              % typeset the header of the contribution
%

\begin{abstract}
%\extendedAbstract{\vspace*{-4.0em}}
Numerous distributed applications, such as cloud computing and distributed ledgers, necessitate the system to invoke asynchronous consensus objects an unbounded number of times, where the completion of one consensus instance is followed by the invocation of another. With only a constant number of objects available, object reuse becomes vital. 

We investigate the challenge of object recycling in the presence of \emph{Byzantine} processes, which can deviate from the algorithm code in any manner. Our solution must also be \emph{self-stabilizing}, as it is a powerful notion of fault tolerance. Self-stabilizing systems can recover automatically after the occurrence of \emph{arbitrary transient-faults}, in addition to tolerating communication and (Byzantine or crash) process failures, provided the algorithm code remains intact.

We provide a recycling mechanism for asynchronous objects that enables their reuse once their task has ended, and all non-faulty processes have retrieved the decided values. This mechanism relies on synchrony assumptions and builds on a new self-stabilizing Byzantine-tolerant synchronous multivalued consensus algorithm, along with a novel composition of existing techniques.
\end{abstract}




%% \linenumbers


\Section{Introduction}
%
\label{sec:intro}
%
\ems{We study the problem of recycling asynchronous consensus objects.
We propose a more robust solution than the state-of-the-art solution to achieve this goal.
}

\Subsection{Fault model} 
%
\label{sec:fdIn}
%
We study solutions for message-passing systems. 
We model a broad set of failures that can occur to computers and networks. 
\extendedAbstract{Our}\technicalReport{Specifically, our} model includes up to $t$ process failures, \ie crashed or Byzantine~\cite{DBLP:journals/toplas/LamportSP82}. \ems{In detail, the adversary completely controls any Byzantine node, \eg the adversary can send a fake message that the node never sent, modify the payload of its messages, delay the delivery of its messages, or omit any subset of them.} 
\technicalReport{The adversary can challenge the algorithm by creating failure patterns in which a fault occurrence appears differently to different system components.
The adversary is empowered with the unlimited ability to coordinate the most severe failure patterns.} 
We assume a known maximum number, $t$, of \ems{Byzantine} processes. 
\ems{For solvability's sake, we} also restrict the adversary from letting a \ems{Byzantine} process impersonate a non-faulty one, \ems{\ie as in~\cite{DBLP:books/sp/Raynal18}, we assume private channels between any pair of nodes.} 

\remove{
%\Subsubsection{Asynchronous vs. synchronous components}
%
\label{sec:hybridIntro}
%
The proposed solution uses a hybridization of two fault models, which their notations follow Raynal~\cite{DBLP:books/sp/Raynal18}.

%, \ie $\mathsf{BAMP_{n,t}[FC, t < n/3,RCCs]}$ and $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$.

\begin{itemize}[topsep=0.2em, partopsep=0pt, parsep=0pt, itemsep=3pt,leftmargin=3pt, rightmargin=0pt, listparindent=0pt, labelwidth=0.15em, labelsep=0.35em, itemindent=0.75em]
	\item \textbf{$\mathsf{BAMP_{n,t}[FC, t < n/3,RCCs]}$---used by the consensus object.~~} The studied asynchronous \ems{consensus objects} are for message-passing systems where the algorithm cannot explicitly access the local clock or assume the existence of guarantees on the communication delay. These systems are also prone to communication failures, \eg packet omission, duplication, and reordering, as long as Fair Communication (FC) holds between non-faulty processes.
	That is, we limit the adversary's ability to impact the delivery of messages between any two non-faulty processes by assuming fair scheduling of message arrivals.
	For the sake of solvability~\cite{DBLP:journals/toplas/LamportSP82,DBLP:journals/jacm/PeaseSL80,DBLP:conf/podc/Toueg84}, we also assume that the number of faulty processes $t<n/3$ is less than one-third of the number of processes in the system. This fault model, $\mathsf{BAMP_{n,t}[FC, t < n/3,RCCs]}$, is called the Byzantine Asynchronous Message-Passing model with at most $t$ (out of $n$) faulty processes. The array $\mathsf{[FC, t < n/3,RCCs]}$ denotes the list of all assumptions, \ie FC and $t<n/3$ as well as \emph{random common coins} (RCCs). 
	\SectionAbv~\ref{sec:sys} discusses RCCs in detail.
	
	\item \textbf{The \ems{recycling mechanism} assumes $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$.~~} This model is called the Byzantine Synchronous Message-Passing with at most $t$ (out of $n$) faulty processes, and $t < n/3$. The $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$ model is defined by enriching the  $\mathsf{BAMP_{n,t}[FC,t < n/3]}$ model with a $\kappa$-state global clock, reliable communication, and an RCC service. A detailed presentation of $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$ appears in \SectionAbv~\ref{sec:sys}.
\end{itemize}
} % REMOVE




\Subsection{Self-stabilization} 
%
\label{sec:SelfStabIntro}
%
In addition to the failures captured by our model, we also aim to recover from \emph{arbitrary transient-faults}, \ie any temporary violation of assumptions according to which the system was designed to operate. This includes the corruption of control variables, such as the program counter, packet payload, and indices, \eg sequence numbers, which are responsible for the correct operation of the studied system, as well as operational assumptions, such as that at least a distinguished majority of processes never fail. Since the occurrence of these failures can be arbitrarily combined, we assume that these transient-faults can alter the system state in unpredictable ways. In particular, when modeling the system, Dijkstra~\cite{DBLP:journals/cacm/Dijkstra74} assumes that these violations bring the system to an arbitrary state from which a \emph{self-stabilizing system} should recover. Dijkstra requires recovery after the last occurrence of a transient-fault and once the system has recovered, it must never violate the task \ems{specifications. \Ie there could be any finite number of transient faults before the last one occurs, which may leave the system in an arbitrary state. Moreover, recovery from an arbitrary system state is demonstrated once all transient faults cease to happen, see~\cite{DBLP:series/synthesis/2019Altisen,DBLP:books/mit/Dolev2000}\technicalReport{ for details}.} 

\Subsubsection{Memory constraints} 
%
\ems{In the absence of transient faults, one can safely assume that the algorithm variables, such as a counter for the message sequence number, are unbounded. 
This assumption can be made valid for any practical setting by letting each counter use enough bits, say, $64$, because counting (using sequential steps) from zero to the maximum value of the counter will take longer than the time during which the system is required to remain operational. 
Specifically, if each message transmission requires at least one nanosecond, it would take at least 584 years until the maximum value can be reached. 
However, in the context of self-stabilization, a single transient fault can set the counter value into one that is close to the maximum value.
Thus, any self-stabilizing solution must cope with this challenge and use only bounded memory and communication.}

\Subsubsection{\ems{Self-stabilization via algorithmic transformation}} 
%
\ems{This work is dedicated to designing a generic transformer, which takes an algorithm as input and systematically redesigns it into its self-stabilizing variation as output. Existing transformers differ in the range of input algorithms and fault models they can transform, see Dolev~\cite[2.8]{DBLP:books/mit/Dolev2000}, Katz and Perry~\cite{DBLP:conf/podc/KatzP90}, Afek \etal~\cite{DBLP:conf/wdag/AfekKY90}, and Awerbuch \etal~\cite{DBLP:conf/wdag/AwerbuchPVD94}.}

\ems{Dolev, Petig, and Schiller~\cite{DBLP:journals/algorithmica/DolevPS23} (DPS in short) proposed a transformer of crash-tolerant algorithms for asynchronous message-passing systems into ones that also recover from transient faults\technicalReport{ via self-stabilization}.}
\ems{\technicalReport{Georgiou \etal~\cite{DBLP:conf/netys/GeorgiouGLS19} implemented DPS.}} 
\ems{Lundström \etal show DPS's applicability to various communication abstractions, such as atomic snapshot~\cite{DBLP:conf/podc/GeorgiouLS19}, consensus~\cite{DBLP:conf/icdcn/LundstromRS21,DBLP:conf/edcc/LundstromRS21}, reliable broadcast~\cite{DBLP:conf/netys/LundstromRS20}, and state-machine replication~\cite{DBLP:conf/sss/LundstromRS22}.}
\ems{DPS mandates that (DPS.i) the input algorithm guarantees,  after the last transient fault occurrence, the completion of each invocation of the communication abstraction, \ie it should eventually terminate regardless of the starting state. This condition facilitates the eventual release of resources used by each invocation.}
\ems{Additionally, (DPS.ii) it associates a sequence number with each invocation to differentiate the resources utilized by different invocations. This enables the recycling of resources associated with obsolete invocations through a sliding window technique, along with a global restart once the maximum sequence number is reached.}


% \technicalReport{DBLP:conf/icdcs/LundstromRS20,}

%DPS was recently utilized by Duvignau, Raynal, and Schiller~\cite{DBLP:conf/sss/DuvignauRS22}. They converted the Byzantine fault-tolerant (BFT) reliable broadcast algorithm proposed by Bracha and Toueg~\cite{DBLP:conf/podc/BrachaT83} into a Self-stabilizing Byzantine fault-tolerant (SSBFT) algorithm.

\ems{Recently, DPS was utilized by Duvignau \etal~\cite{DBLP:conf/sss/DuvignauRS22} for converting Byzantine fault-tolerant (BFT) reliable broadcast proposed by Bracha and Toueg~\cite{DBLP:conf/podc/BrachaT83} into a Self-Stabilizing BFT (SSBFT) variation.
This solution recycles reliable broadcast objects using synchrony assumptions.
It also relies on the fact that the process may allocate independent local memory and sequence numbers per sender.
However, consensus objects often use shared sequence numbers, and thus, parts of their local memories are codependent.
Therefore, we use another approach.}

%
% in a way that is not applicable to consensus objects, as the problem of reliable broadcast is inherently weaker than consensus.


\Subsection{\ems{Problem description}} 
%
\ems{This work studies an important building block that is needed for the SSBFT implementation of asynchronous consensus objects.
With only a bounded number of consensus objects available, it becomes essential to reuse them robustly. 
We examine the case in which the repeated invocation of consensus needs to reuse the same memory space and the $(k+1)$-th invocation can only start after the completion of the $k$-th instance. 
In an asynchronous system that uses only a bounded number of objects, ensuring the termination of the $k$-th instance before invoking the $(k+1)$-th might be crucial, \eg for total order broadcasting, as in some blockchains.
Thus, we require SSBFT consensus objects to eventually terminate regardless of their starting state, as in (DPS.i).}

% Recall the fact that an SSBFT solution is required to use bounded memory and the fact that the adversary can create failure patterns in which a fault occurrence appears differently to different system components.


We focus \ems{on addressing the challenge of recycling asynchronous consensus objects after they have completed their task and delivered their decision to all non-faulty processes. 
This task becomes complex due to the presence of asynchrony and Byzantine failures. 
Utilizing the joint sequence numbers of (DPS.ii) for recycling consensus objects is not straightforward, because it requires ensuring that all non-faulty processes have delivered the decided value (for the $k$-th consensus invocation) as well as agreeing that such collective delivery occurred before incrementing the sequence number counter (that is going to be used by the $(k+1)$-th invocation). 
To overcome this chicken-and-egg problem, we relax the problem requirements by allowing the recycling mechanism to depend on synchrony assumptions.}
To mitigate the impact of these assumptions, a single recycling action can be performed for a batch of $\delta$ objects, where $\delta$ is a predefined constant determined by the available memory. 
Thus, our approach \ems{facilitates asynchronous networking} in communication-intensive components, \ems{\ie the consensus objects,} while \emsA{synchronous recycling} \ems{actions are performed according to a load parameter,} $\delta$.

\Subsection{\ems{Our solution in a nutshell}}
%
\ems{Our solution aims to emulate (DPS.ii) by incorporating synchrony assumptions specifically for the recycling service, while keeping the consensus object asynchronous to handle intensive message exchange.}

\ems{To begin, we maintain an index that points to the most recently invoked object in a constant-size array.
In order to ensure that all non-faulty processes agree on the value of the index, we utilize a novel technique called \emph{simultaneous increment-or-get indexes} (SGI-index).
When recycling an object, we increment the index, but this increment is performed only after an agreement among the non-faulty processes that the relevant object has made its decision and delivered it to all non-faulty processes.
Thus, we use a new SSBFT multivalued consensus before each increment, ensuring that consensus is reached before the increment. \Ie all needed deliveries had occurred before the increment.}

\ems{Additionally, our solution answers how an SSBFT asynchronous consensus object can provide an indication that at least one non-faulty process has made a decision and delivered. We utilize this indication as input to trigger the recycling action, effectively incorporating it into the SSBFT multivalued consensus.}

\Subsection{Related work}
%
%	In this paper, the design criteria for non-self-stabilizing Byzantine fault-tolerant solutions are called BFT, and the ones for self-stabilizing Byzantine fault-tolerant are called SSBFT. We review the most related BFT and SSBFT solutions for the studied problem.
%	
\reduce{\Subsubsection{Object recycling}} 
%
Object recycling was studied mainly in the context of \ems{crash-tolerant (non-BFT)} systems~\cite{DBLP:conf/iwmm/PlainfosseS95,DBLP:conf/ipps/VeigaF05}.
There are a few \ems{(non-self-stabilizing)} implementations of garbage collection in the presence of Byzantine processes, \eg~\cite{DBLP:conf/opodis/OliveiraMB16}.

\reduce{
\Subsubsection{Impossibilities} 
%
\label{sec:impo}
%
As mentioned, FLP~\cite{DBLP:journals/jacm/FischerLP85} concluded that consensus is impossible to solve deterministically in asynchronous settings in the presence of even a single crash failure. In~\cite{DBLP:journals/ipl/FischerL82} it was shown that a lower bound of $t+1$ communication steps are required to solve consensus deterministically in both synchronous and asynchronous environments. 
%
%The proposed solution consider another model, \ie $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$.
%
In the presence of Byzantine faults, the consensus problem is not solvable (without signatures) if a third or more of the processes are faulty~\cite{DBLP:journals/toplas/LamportSP82}. 
%
\technicalReport{Thus, optimally resilient signature-free Byzantine consensus algorithms, tolerate $t<n/3$ faulty processes.}  
%
The task is also impossible if a process can impersonate some other process in its communication with the other entities~\cite{DBLP:conf/podc/Ben-Or83}. 
\ems{As in~\cite{DBLP:conf/podc/MostefaouiMR14}, we} assume the absence of spoofing attacks and similar means of impersonation.
%We clarify that in the context of self-stabilization, it is not clear how one can use digital signatures since a single transient fault can corrupt all copies of the private key.
}

\Subsubsection{Non-self-stabilizing BFT \ems{consensus}}
\label{sec:nonSSBFTsols}
%
Rabin~\cite{DBLP:conf/focs/Rabin83} offers a solution to BFT \emph{consensus} (cf. \SectionAbv~\ref{sec:recyclableGMRS} for definitions). 
It assumes the availability of \ems{\emph{random common coins} (RCCs),} allowing for a polynomial number of communication steps and optimal resilience, \ie $t<n/3$, \ems{where $n$ is the number of participating processes.} 
Mostéfaoui, Moumen, and Raynal~\cite{DBLP:conf/podc/MostefaouiMR14}, or MMR in short, is a signature-free BFT binary consensus solution.
MMR is optimal in resilience, uses $O(n^2)$ messages per consensus invocation, and completes within $O(1)$ expected time.
	
\Subsubsection{Non-self-stabilizing synchronous BFT multivalued consensus}
%
The proposed recycling mechanism uses an SSBFT multivalued consensus, which is based on a non-self-stabilizing BFT multivalued consensus. 
Kowalski and Most{\'{e}}faoui~\cite{DBLP:conf/podc/KowalskiM13} proposed the first multivalued optimal resilience, polynomial communication cost, and optimal $t+1$ rounds, but without early stopping. Abraham and Dolev~\cite{DBLP:conf/stoc/AbrahamD15} advanced the state of the art by offering also optimal early stopping.
Unlike the above BFT\reduce{ multivalued consensus} solutions, our SSBFT multivalued solution \ems{adds} self-stabilization.
	
\technicalReport{
\Subsubsection{SSBFT solutions} 
%
%In the context of this dual design criteria, there are solutions for clock synchronization~\cite{DBLP:conf/podc/Ben-OrDH08}, storage~\cite{DBLP:conf/sss/BonomiPPT18}, and gathering of mobile robots~\cite{DBLP:journals/dc/DefagoPP20} to name a few.
%Another relevant work is the one by Binun \etal~\cite{DBLP:conf/sss/BinunCDKLPYY16,DBLP:conf/cscml/BinunDH19} and Dolev \etal~\cite{DBLP:conf/cscml/DolevGMS18} for a deterministic BFT emulation of state-machine replication. 
%We study another problem, which is the recycling of consensus objects.
}
%
In the broader context of SSBFT solutions for message-passing systems, we find topology discovery~\cite{DBLP:conf/netys/DolevLS13}, storage~\cite{DBLP:conf/sss/BonomiPPT18,DBLP:conf/ipps/BonomiPT15,DBLP:conf/podc/BonomiDPR15}, clock synchronization~\cite{DBLP:conf/podc/DolevW95,DBLP:journals/jacm/LenzenR19}, approximate agreement \cite{DBLP:journals/tcs/BonomiPPT19}, asynchronous unison~\cite{DBLP:journals/jpdc/DuboisPNT12}, communication in dynamic networks~\cite{DBLP:conf/opodis/Maurer20}, and SSBFT state-machine replication~\cite{DBLP:conf/sss/BinunCDKLPYY16,DBLP:conf/cscml/DolevGMS18} to name a few.

\Subsubsection{\ems{SSBFT consensus}}
%
To the best of our knowledge, the only SSBFT RCCs construction is the one by Ben{-}Or, Dolev, and Hoch~\cite{DBLP:conf/podc/Ben-OrDH08}, in short BDH, for synchronous systems with private channels. 
BDH uses its SSBFT RCCs construction as a building block for devising an SSBFT clock synchronization solution.
\reduce{Our work borrows several mechanisms from BDH, such as SSBFT RCCs and SSBFT clock synchronization.} 
Recently, Georgiou, Marcoullis, Raynal, and Schiller~\cite{DBLP:conf/netys/GeorgiouMRS21}, or GMRS in short, presented an SSBFT variation on MMR, which offers a BFT binary consensus\technicalReport{ solution}.
GMRS preserves MMR's optimality\reduce{ properties}, and thus, we\extendedAbstract{ use}\technicalReport{ base our example consensus object on} GMRS \ems{in this work}.

\emsA{GMRS follows the design criteria of loosely self-stabilizing systems~\cite{DBLP:journals/tcs/SudoNYOKM12}, ensuring task completion but with rare safety violation events. In the context of the studied problem, the former guarantee renders the latter one irrelevant.}
We point out that related work to loosely self-stabilizing systems include randomized congestion control~\cite{DBLP:conf/sss/0001GS19} and leader election~\cite{DBLP:journals/ieicet/SudoOKM20,DBLP:journals/tpds/SudoOKMDL19,DBLP:journals/tcs/SudoOKMDL20,DBLP:conf/sirocco/Izumi15}.

\Subsubsection{Self-stabilizing non-Byzantine fault-tolerant solutions} 
%
Lundstr{\"{o}}m, Raynal, and Schiller~\cite{DBLP:conf/icdcn/LundstromRS21} presented the first self-stabilizing solution for the problem of binary consensus for message-passing systems where nodes may fail by crashing. 
They provided a line of self-stabilizing solutions~\cite{DBLP:journals/corr/abs-2104-03129,DBLP:conf/icdcs/LundstromRS20,DBLP:conf/netys/LundstromRS20,DBLP:conf/netys/GeorgiouLS19,DBLP:conf/netys/GeorgiouGLS19}. 
This line follows the approach proposed by Dolev, Petig, and Schiller~\cite{DBLP:journals/corr/abs-1806-03498,DBLP:conf/podc/DolevPS15} for self-stabilization in the presence of seldom fairness. 
Namely, in the absence of transient-faults, these self-stabilizing solutions are wait-free and no assumptions are made regarding the system's synchrony or fairness of its scheduler. However, the recovery from transient faults does require fair execution, \eg to perform a global reset, see~\cite{DBLP:conf/netys/GeorgiouGLS19}, but only during the recovery period. 
The studied problem is more challenging than the above due to the presence of Byzantine processes and transient faults.   
Thus, we consider synchrony assumptions.


\Subsection{Our contribution} 
%
We propose an important building block for reliable distributed systems: a \ems{new} SSBFT mechanism  for recycling SSBFT consensus objects.
The proposed mechanism \ems{stabilizes} within expected $\bigO(\kappa)$ synchronous rounds, where $\kappa \in \bigO(t)$ is a predefined constant (that depends on synchrony assumptions) and $t$ is an upper bound on the number of Byzantine processes.
We also present, to the best of our knowledge, the \ems{first} SSBFT synchronous multivalued consensus solution.
The \ems{novel} composition of (i) SSBFT recycling and (ii) SSBFT \ems{recyclable} objects has a long line of applications, such as replication and blockchain. 
\ems{Thus, our transformation advances the state of the art by facilitating} solutions that are more fault-tolerant than the existing implementations, which cannot recover \ems{from} transient faults. 


For convenience, a Glossary is provided in Table~\ref{fig:Glossary}.

\begin{table*}[t!]
	\begin{center}
		%		\begin{\algSizeVerySmall}
			\begin{tabular}{|l|l|}
				\hline
				\textbf{Notation} & \textbf{Meaning} \\ \hline \hline
				%			$\mathsf{BAMP_{n,t}}$ &    Byzantine Asynchronous Message-Passing model    \\ \hline
				BC & Byzantine-tolerant Consensus\\ \hline
				BDH &     Ben{-}Or, Dolev, and Hoch~\cite{DBLP:conf/podc/Ben-OrDH08}    \\ \hline
				BFT &    non-self-stabilizing Byzantine fault-tolerant solutions     \\ \hline
				%			$\mathsf{BSMP_{n,t}}$ &     Byzantine synchronous message-passing model \\ \hline
				COR & Consensus Object Recycling (Definition~\ref{def:probDef})  \\ \hline
				%			$FC$& fair communication assumption        \\ \hline
				{DPS} & Dolev, Petig, and Schiller~\cite{DBLP:journals/algorithmica/DolevPS23}     \\ \hline 
				MMR & Mostéfaoui, Moumen, and Raynal~\cite{DBLP:conf/podc/MostefaouiMR14}        \\ \hline
				RCCs&  random common coins   \\ \hline
				SSBFT &    self-stabilizing Byzantine fault-tolerant     \\ \hline
				$\kappa\mathit{-}SGC$&    $\kappa$-state global clock     \\ \hline
			\end{tabular}
			\FF
			\caption{\label{fig:Glossary}Glossary}
			%		\end{\algSizeVerySmall}
	\end{center}
\end{table*}

	
\begin{algorithm*}[t!]
	\begin{\algSize}
%		\smallskip
		
		\noindent \textbf{local variables:}\technicalReport{\\}
		%
		\tcc{the algorithm's local state is defined here.}
		
		\fbox{$delivered[\sP]:=[\false,\ldots,\false]$ delivery indications; $delivered[i]$ stores the local} 
		
		\fbox{indication and $delivered[j]$ stores the last received indication from $p_j \in \sP$\;} 
		
		\smallskip
		
		\textbf{constants:} \technicalReport{\\}
		%
		$\mathit{initState} := (\bullet,$ \fbox{$[\false,\ldots,\false])$\;}
		
		\smallskip
		
		\textbf{interfaces:}\technicalReport{\\}  	
		%			
		\fbox{\label{ln:recycle}$\mathsf{recycle}()$ \textbf{do} (local state, $delivered)$ $ \gets \mathit{initState}$\;} \tcc{also initialize all attached communication channels~\cite[Ch. 3.1]{DBLP:books/mit/Dolev2000}}
		
		\smallskip
		
		\fbox{$\mathsf{wasDelivered}()$ \textbf{do} \{\textbf{if} $\exists S \subseteq\sP: n\mathit{-}t\leq |S|: \forall {p_k \in S} : delivered[k]=\true$ \textbf{then}} \fbox{\textbf{return} $1$ \textbf{else return} $0$;\}\label{ln:wasDelivered}}
		
		\smallskip
		
		\textbf{operations:} $\mathsf{propose}(v)$ \label{ln:RSproposeV}\textbf{do} $\{$implement the algorithm logic$\}$\;
		
		\smallskip
		
		$\mathsf{result}()$ \label{ln:RresultV}\textbf{do} \Begin{
			\lIf{there is a decided value}{\fbox{\{$delivered[i]\gets \true$;} \Return{$v$}\label{ln:nonBot1}\}} 
			\lElseIf{an error occurred}{\fbox{\{$delivered[i]\gets \true$;} \Return{\blitza}\label{ln:nonBot2}\}}
			\textbf{else return} {$\bot$}\label{ln:RresultVBot};
		}
		
		
		
		\smallskip
		
		\textbf{do forever} \Begin{
			
			
			
			\fbox{\lIf{$\mathsf{result}()=\bot$}{$delivered[i]\gets \bot$}\label{ln:ifResultBotDeliveredBot}\tcc{consistency test}}
			
			\tcc{implementation of the algorithm's logic}
			
			\lForEach{$p_j \in \sP$}{\textbf{send} $\mathrm{EST}(\bullet,$\fbox{$delivered[i])$}  \textbf{to} $p_j$\label{ln:RESTrepeatB}}}			
		
		\textbf{upon} $\mathrm{EST}(\bullet,$\fbox{$delivered\mathit{J})$} \label{ln:RuponEst} \textbf{arrival from} $p_j$ \Begin{ 
			
			$delivered[j]\gets delivered\mathit{J}$\label{ln:RRESTrepeatB}\;
			
			\tcc{merge arriving information with the local one}
			
		}
		
%		\smallskip
		
		
%		\EMS{Why do we need $\exists r'\in \{0, \ldots, r\}:$?---internal marking---no need to be considered by CG.}%\CGC{I assume you mean in the original algorithm. $r'$ being in that set it means that it fell behind wrt rounds.}
		
		\caption{\label{alg:RconsensusB}A recyclable variation on GMRS; \technicalReport{code for node $p_i$}\extendedAbstract{$p_i$'s code}.}
	\end{\algSize}
\end{algorithm*}


\Section{\ems{Basic Result:} Recyclable SSBFT Consensus Objects}
%
\label{sec:recyclableGMRS}
%
\ems{In this section, we define a recyclable variation on the consensus problem, which facilitates the use of an unbounded number of consensus instances via the reuse of a constant number of objects (as presented in \SectionAbv~\ref{sec:bck}). 
Then, we sketch \Algorithm~\ref{alg:RconsensusB}, which presents a recyclable variation on an SSBFT asynchronous consensus algorithm (such as GMRS).
Towards the end of this section, Theorem~\ref{thm:COR-proposal-validity} demonstrates that \Algorithm~\ref{alg:RconsensusB} constructs recyclable SSBFT consensus objects.}

%  for $\mathsf{BAMP_{n,t}[FC, t < n/3,RCCs]}$

\Subsection{\ems{Byzantine-tolerant Consensus (BC)}}
%
\ems{This problem} requires agreeing on a\technicalReport{ single} value from a given set $V$, \ems{which every \emsA{(non-faulty)} node inputs via $\mathsf{propose}()$.
It} requires 
\emph{BC-validity}, \ie if all non-faulty nodes propose the same value $v\in V,$ only $v$ can be decided, 
\emph{BC-agreement}, \ie no two non-faulty nodes can decide different values, and 
\emph{BC-completion}, \ie all non-faulty nodes decide a value.
When the set, $V$, from which the proposed values are taken is $\{0,1\}$, the problem is called \emph{binary consensus}. Otherwise, it is referred to as \emph{multivalued consensus}.

\Subsection{\ems{Recyclable Consensus Objects}}
%
\ems{We study systems that implement consensus objects using storage of constant size allocated at program compilation time. 
Since these objects can be instantiated an unbounded number of times, it becomes necessary to reuse the storage once consensus is reached and each non-faulty node has received the object result via $\mathsf{result}()$.}
%
\ems{To facilitate this, we assume that the object has two meta-statuses: \emph{used} and \emph{unused}. 
The \emph{unused} status represents both objects that were never used and those that are no longer in current use, indicating they are available (for reuse).
Our definition of recyclable objects assumes that the objects implement an interface function called $\mathsf{wasDelivered}()$ that must return $1$ anytime after the result delivery. 
Recycling is triggered by the recycling mechanism (\SectionAbv~\ref{sec:bck}), which invokes $\mathsf{recycle}()$ at each non-faulty node, thereby setting the meta-status of the corresponding consensus object to \emph{unused}.}
%
\ems{We specify the task of recyclable object construction as one that requires eventual agreement on the value of $\mathsf{wasDelivered}()$. In detail, if a non-faulty node $p_i$ reports delivery (\ie $\mathsf{wasDelivered}_i()=1$), then all non-faulty nodes will eventually report delivery as well.
We clarify that during the recycling process, \ie when at least one non-faulty node invokes $\mathsf{recycle}()$, there is no need to maintain agreement on the values of $\mathsf{wasDelivered}()$.}

\B
\Subsection{\ems{Algorithm} outline}
%
\label{sec:ourlineAlg}
%
\Algorithm~\ref{alg:RconsensusB}'s \fbox{boxed} code lines highlight the \ems{code lines relevant to recyclability.}
\emsA{The set of nodes is denoted by $\sP$. We} avoid the restatement of the algorithm, and to focus \ems{on} the parts that matter in this work, the other parts are given in words (cf. \ems{GMRS}~\cite{DBLP:conf/netys/GeorgiouMRS21} for full details). 
The code uses the symbol $\bullet$ to denote any sequence of values.
We assume that the object allows the proposal of $v$ via $\mathsf{propose}(v)$ (line~\ref{ln:RSproposeV}). 
As in $\mathsf{result}()$ (line~\ref{ln:RresultV}), once the consensus algorithm decides, one of the decided value is returned (line~\ref{ln:nonBot1}). 
\ems{Since the algorithm tolerates transient faults,} the object may need to indicate an internal error via the return of the (transient) error symbol, $\blitza$ (line~\ref{ln:nonBot2}). 
In all other cases,\reduce{ \ie as long as no value was decided,} the $\bot$-value is returned (line~\ref{ln:RresultVBot}). 
GMRS uses a do-forever loop that broadcasts the protocol messages (line~\ref{ln:RESTrepeatB}). 
Any node that receives this protocol message, merges the arriving information with the one stored by the local state (line~\ref{ln:RRESTrepeatB}).

\B
\Subsection{Recyclable variation}
%
\label{sec:recyclableVar}
%
\Algorithm~\ref{alg:RconsensusB} uses the array $delivered[\sP]$ (initialized to the vector $[\false,\ldots,\false]$) for delivery indications, where $delivered_i[i]:p_i \in \sP$ stores the local indication and $delivered_i[j]:p_i,p_j \in \sP$ stores the indication that was last received from $p_j$. This indication is set to $\true$ whenever $\done()$ returns a non-$\bot$ value (lines~\ref{ln:nonBot1} to~\ref{ln:nonBot2}). \Algorithm~\ref{alg:RconsensusB} updates $delivered[j]$ according to the arriving values from $p_j$ (lines~\ref{ln:RESTrepeatB} and~\ref{ln:RRESTrepeatB}). The interface function $\mathsf{wasDelivered}()$ (line~\ref{ln:wasDelivered}) returns $1$ if at least $n-t$ entries in $delivered[]$ hold $\true$. The interface function $\mathsf{recycle}()$ (line~\ref{ln:recycle}) allows the node to restart its local state w.r.t. \Algorithm~\ref{alg:RconsensusB}.

\technicalReport{Theorem~\ref{thm:COR-proposal-validity} shows that \Algorithm~\ref{alg:RconsensusB} satisfies \ems{the requirements for Recyclable Consensus Objects, which we defined above.} 
Following the definition of the BC problem and GMRS, the theorem assumes that every \emsA{(non-faulty)} node invokes $\mathsf{result}()$ infinitely often.}

\BB\begin{theorem}
	\label{thm:COR-proposal-validity}
	\technicalReport{Suppose that every \emsA{(non-faulty)} node invokes $\mathsf{result}()$ infinitely often.}
	\Algorithm~\ref{alg:RconsensusB} \ems{offers a recyclable asynchronous consensus object.} 
\end{theorem}\B
\renewcommand{\thmcnt}{\ref{thm:COR-proposal-validity}}
\BB

\extendedAbstract{
	\begin{theoremProofSketch}
		If $\exists i \in \Correct:\mathsf{wasDelivered}_i()=1$, then $\mathsf{result}_i()\neq\bot$ (line~\ref{ln:ifResultBotDeliveredBot}). By BC-completion, eventually $\forall j \in \Correct: \mathsf{result}_j()\neq\bot \land \mathsf{wasDelivered}_j()=1$ (lines~\ref{ln:nonBot1} and~\ref{ln:nonBot2}). 
	\end{theoremProofSketch}
} %\extendedAbstract

\technicalReport{
	\begin{theoremProof}
		Let $R$ be an unbounded execution of \Algorithm~\ref{alg:RconsensusB} in which no \emsA{(non-faulty)} node invokes $\mathsf{recycle}()$.
		Suppose $\exists i\in \Correct:\mathsf{wasDelivered}_i()=1$ in any system state in $R$.
		We show that the system reaches a state $c \in R$ in which $\forall j \in \Correct:\mathsf{wasDelivered}_j()=1$.
		
		By line~\ref{ln:ifResultBotDeliveredBot} and the assumption that $i \in \Correct:\mathsf{wasDelivered}_i()=1$ holds throughout $R$, $\mathsf{result}_i()\neq\bot$ holds in every system state $R$, \ie $p_i$'s state encodes completion.
		By BC-completion and the assumption that \Algorithm~\ref{alg:RconsensusB} is an SSBFT implementation of consensus, $\forall j \in \Correct: \mathsf{result}_j()\neq\bot$ eventually.
		By lines~\ref{ln:nonBot1} to~\ref{ln:nonBot2} and the theorem assumption that every \emsA{(non-faulty)} node invokes $\mathsf{result}()$ infinitely often, $\forall j \in \Correct:\mathsf{wasDelivered}_j()=1$. 
	\end{theoremProof}
} % \technicalReport	

 
	
\Section{System Settings for the Recycling Mechanism}
%
\label{sec:sys}
%
This model considers a synchronous message-passing system. 
The system consists of a set, $\sP$, of $n$ \emph{nodes} (sometimes called \emph{processes} or \emph{processors}) with unique identifiers. 
At most $t < n/3$, out of the $n$ nodes, are faulty. 
Any pair of nodes $p_i,p_j \in \sP$ has access to a bidirectional reliable communication channel, $\mathit{channel}_{j,i}$. 
%	
%	Any pair of nodes $p_i,p_j \in \sP$ has access to a bidirectional reliable communication channel, $\mathit{channel}_{j,i}$ (\SectionAbv~\ref{sec:relComm}). 
%The model also assume that availability of a $\kappa$-state global clock, see \SectionAbv~\ref{sec:kappaState}, and \emph{random common coins} (RCCs), see \SectionAbv~\ref{sec:rcc}. 
%	
%	\Subsection{Execution model}
	%
	%\label{sec:interModel}
	%
	In the \emph{interleaving model}~\cite{DBLP:books/mit/Dolev2000}, the node's program is a sequence of \emph{(atomic) steps}. 
	Each step starts with (i) the communication operation \ems{for receiving messages} that is followed by (ii) an internal computation, and (iii) finishes with a single $send$ operation. 
	The \emph{state}, $s_i$, of node $p_i \in \sP$ includes all of $p_i$'s variables and $\mathit{channel}_{j,i}$. 
	The term \emph{system state}\technicalReport{ (or configuration)} refers to the tuple $c = (s_1, s_2, \cdots,  s_n)$. 
%
Our model also assumes the availability of a $\kappa$-state global clock, reliable communications, and random common coins (RCCs). 
	
	
	%We define an \emph{execution (or run)} $R={c[0],a[0],c[1],a[1],\ldots}$ as an alternating sequence of system states $c[x]$ and steps $a[x]$, such that each $c[x+1]$, except for the starting one, $c[0]$, is obtained from $c[x]$ by $a[x]$'s execution. 
	
	\Subsection{A $\kappa$-state global clock}
	%
	\label{sec:kappaState}
	%
	We assume that the algorithm takes steps according to a common global pulse (beat) that triggers a simultaneous step of every node in the system. 
	Specifically, we denote synchronous executions by $R=c[0],c[1],\ldots$, where $c[x]$ is the system state that immediately precedes the $x$-th global pulse. 
	And, $a_i[x]$ is the step that node $p_i$ takes between $c[x]$ and $c[x+1]$ simultaneously with all other nodes. 
	We also assume that each node has access to a $\kappa$-state global clock via the function $clock(\kappa)$, which returns an integer between $0$ and $\kappa-1$.
	Algorithm 3 of BDH~\cite{DBLP:conf/podc/Ben-OrDH08} offers an SSBFT $\kappa$-state global clock that stabilizes within a constant time.    
	
	\Subsection{Reliable communication}
	%
	\label{sec:relComm}
	%
	Recall that we assume the availability of reliable communication.
	Also, any non-faulty node $p_i \in \sP$ starts any step $a_i[x]$ with receiving all pending messages from all nodes. And, if $p_i$ sends any message during $a_i[x]$, it does so only at the end of $a_i[x]$. We require (i) any message that a non-faulty node $p_i$ sends during step $a_i[x]$ to another non-faulty node $p_j$ is received at $p_j$ at the start of step $a_j[x+1]$, and
	(ii) any message that $p_j$ received during step $a_j[x+1]$, was sent at the end of $a_i[x]$. 
	
	\Subsection{Random common coins (RCCs)}
	%
	\label{sec:rcc}
	%
	As\reduce{ already} mentioned, BDH presented a synchronous SSBFT RCCs solution\reduce{ for message passing systems}. Algorithm $\mathcal{A}$, which has the output of $rand_i \in \{0,1\}$, is said to provide an RCC if $\mathcal{A}$ satisfies the following:
	
	\begin{itemize}[topsep=0.2em, partopsep=0pt, parsep=0pt, itemsep=3pt,leftmargin=3pt, rightmargin=0pt, listparindent=0pt, labelwidth=0.15em, labelsep=0.35em, itemindent=0.75em]
		\item \textbf{RCC-completion:} $\mathcal{A}$ \technicalReport{provides an output}\extendedAbstract{completes} within $\Delta_{\mathcal{A}} \in \mathbb{Z}^+$ synchronous rounds. 
		
		\item \textbf{RCC-unpredictability:} Denote by $E_{x\in \{0,1\}}$ the event that for any non-faulty process, $p_j$, $rand_j=x$ holds with constant probability $p_x > 0$. Suppose either $E_0$ or $E_1$ occurs at the end of round $\Delta_{\mathcal{A}}$. We require that the adversity can predict the output of $\mathcal{A}$ by the end of round $\Delta_{\mathcal{A}}- 1$ with a probability that is not greater than $1 - \min\{p_0, p_1\}$. 
		%Just like MMR's PODC 2014 variation, this work assumes 
		Following~\cite{DBLP:conf/podc/MostefaouiMR14}, we assume that $p_0=p_1=1/2$.
	\end{itemize}
	
	Our solution depends on the existence of a self-stabilizing RCC service, \eg BDH.
	BDH considers \emph{(progress) enabling} instances of RCCs if there is $x \in \{0,1\}$ such that for any non-faulty process $p_i$, we have $rand_i=x$. BDH correctness proof depends on the consecutive existence of two enabling RCCs instances. 
	
	\Subsection{Legal executions}
	%
	The set of \emph{legal executions} ($LE$) refers to all the executions in which the requirements of task $T$ hold. In this work, $T_{\text{recycl}}$ denotes the task of consensus object recycling \ems{(specified in \SectionAbv~\ref{sec:bck}),} and $LE_{\text{recycl}}$ denotes the set of executions in which the system fulfills $T_{\text{recycl}}$'s requirements. 
	
\Subsection{Arbitrary node failures}
%
\label{sec:arbitraryNodeFaults}
%
\ems{As explained in \SectionAbv~\ref{sec:intro},} Byzantine faults model any fault in a node including crashes, arbitrary behavior, and malicious behavior~\cite{DBLP:journals/toplas/LamportSP82}. 
For the sake of solvability~\cite{DBLP:journals/toplas/LamportSP82,DBLP:journals/jacm/PeaseSL80,DBLP:conf/podc/Toueg84}, our fault model limits only the number of nodes that can be captured by the adversary. That is, the number, $t$, of Byzantine failure needs to be less than one-third of the number, $n$, of nodes.
The set of non-faulty nodes is denoted by $\Correct$. 
	
	\Subsection{Arbitrary transient-faults}
	%
	\label{sec:arbitraryTransientFaults}
	%
	We consider any temporary violation of the assumptions according to which the system was designed to operate. We refer to these violations and deviations as \emph{arbitrary transient-faults} and assume that they can corrupt the system state arbitrarily (while keeping the program code intact). 
	Our model assumes that the last\technicalReport{ arbitrary} transient fault occurs before the system execution \ems{starts~\cite{DBLP:series/synthesis/2019Altisen,DBLP:books/mit/Dolev2000}.} Also, it leaves the system to start in an arbitrary state.
	
	\Subsection{Self-stabilization}
	%
	\label{sec:Dijkstra}
	%
	An algorithm is \emph{self-stabilizing} \ems{for} the task of $LE$, when every (unbounded) execution $R$ of the algorithm reaches within a finite period a suffix $R_{legal} \in LE$ that is legal. Namely, Dijkstra~\cite{DBLP:journals/cacm/Dijkstra74} requires $\forall R:\exists R': R=R' \circ R_{legal} \land R_{legal} \in LE \land |R'| \in \mathbb{Z}^+$, where the operator $\circ$ denotes that $R=R' \circ R''$ is the concatenation of $R'$ with $R''$. The part of the proof that shows the existence of $R'$ is called the \emph{convergence} (or recovery) proof, and the part that shows that $R_{legal} \in LE$ is called the \emph{closure} proof. 
	\ems{We clarify that once the execution of a self-stabilizing system becomes legal, it stays legal due to the property of closure.}
	The main complexity measure of a self-stabilizing system is \ems{its stabilization time, which is} the length of the recovery period, $R'$, which is counted by the number of its synchronous rounds.
	
	%
	%\Subsection{Task specifications}
	%%
	%\label{sec:spec}
	%
	%Next, we detail the studied task.
	
	
	%\Subsubsection{Returning the decided value}
	%%
	%Definition~\ref{def:consensus} considers the $\mathsf{propose}(v)$ operation. 
	%We refine the definition of $\mathsf{propose}(v)$ by specifying how the decided value is retrieved. 
	%This value is either returned by the $\mathsf{propose}()$ operation (as in the studied algorithm~\cite{DBLP:conf/podc/MostefaouiMR14}) or via the returned value of the $\done()$ operation (as in the proposed solution).
	%In the latter case, the symbol $\bot$ is returned as long as no value was decided. 
	%Also, the symbol $\blitza$ indicates a (transient) error that occurs only when the proposed algorithm exceeds the bound on the number of iterations that it may take.
	
	
	%\Subsubsection{{Invocation by algorithms from higher layers}}
	%%
	%\label{sec:initialization}
	%%
	%We assume that the studied problem is invoked by algorithms that run at higher layers, such as multivalued consensus, see Figure~\ref{fig:suit}. This means that eventually there is an invocation, $I$, of the proposed algorithm that starts from a well-initialized system state. That is, immediately before invocation $I$, all local states of all non-faulty nodes have the (predefined) initial values in all variables and the communication channels do not include messages related to invocation $I$.
	%
	%For the sake of completeness, we illustrate briefly how the assumption above can be covered~\cite{DBLP:conf/ftcs/Powell92} in the studied hybrid asynchronous/synchronous architecture presented in Figure~\ref{fig:suit}. Suppose that upon the periodic installation of the common seed, the system also initializes the array of binary consensus objects that are going to be used with this new installation. In other words, once all operations of a given common seed installation are done, a new installation occurs, which also initializes the array of binary consensus objects that are going to be used with the new common seed installation. Note that the efficient implementation of a mechanism that covers the above assumption is outside the scope of this work.
	
	
	
	%\Subsection{The fault model and self-stabilization}
	%%
	%A failure occurrence is a step that the environment takes rather than the algorithm. 
	%
	%We consider failures that can and cannot cause the system to deviate from fulfilling its task (Figure~\ref{fig:self-stab-SDN}).
	
	%% Figure environment removed
	
	
	
	
	%\renewcommand{\algorithmcfname}{Part A of Algorithm}
%		\renewcommand{\algorithmcfname}{Algorithm}
	
	%
%\Subsection{Extension}
%%
%\label{sec:recyclableExt}
%%
%The approach studied here considers the instantiation of one object at a time. A straightforward extension is to allow the allocation and recycling of a set of objects. Specifically, one can run $\delta$ concurrent instances, where $\delta$ is a parameter for balancing the trade-off between fault recovery time and the number of instances that can be used (before the next $\delta$ concurrent instances can start). 
	


\Section{SSBFT Recycling Mechanism} % for $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$}}
%
\label{sec:bck}
%
\ems{We present an SSBFT recycling mechanism for recyclable objects (\SectionAbv~\ref{sec:recyclableGMRS}). 
The mechanism is a service that recycles consensus objects via the invocation of $\mathsf{recycle}()$ by all (non-faulty) nodes.
The coordinated invocation of $\mathsf{recycle}()$ can occur only after the consensus object \ems{has} terminated and the non-faulty nodes have delivered the result, via $\mathsf{result}()$, as indicated by $\mathsf{wasDelivered}()$.}

%As explained, these objects implement $\mathsf{propose}()$, $\mathsf{result}()$, $\mathsf{wasDelivered}()$, and $\mathsf{recycle}()$, as in \Algorithm~\ref{alg:RconsensusB}.

\Subsection{\ems{Consensus Object Recycling (COR)}}
%
\ems{Definition~\ref{def:probDef} specifies the COR problem for a single object.
COR-validity-1 is a safety property requiring that $\mathsf{recycle}()$ is invoked only if there was at least one reported delivery by a non-faulty node. 
COR-validity-2 is a liveness property requiring that eventually $\mathsf{recycle}()$ is invoked. 
COR-agreement is a safety property requiring that all non-faulty nodes simultaneously set the object's status to unused.
This allows any node $p_i$ to reuse the object immediately after the return from $\mathsf{recycle}_i()$. 
}


% Figure environment removed  


\B
\begin{definition}[Consensus Object Recycling] 	\technicalReport{The following properties are required:}
	%
	\label{def:probDef}
	%
	\begin{itemize}[topsep=0.2em, partopsep=0pt, parsep=0pt, itemsep=3pt,leftmargin=3pt, rightmargin=0pt, listparindent=0pt, labelwidth=0.15em, labelsep=0.35em, itemindent=0.75em]
%		\item \textbf{COR-client-eventual-agreement:} 	Suppose no non-faulty process invokes $\mathsf{recycle}()$. 
%		If a non-faulty process, $p_i$, reports delivery, \ie $\mathsf{wasDelivered}_i()=1$, then all non-faulty processes report delivery eventually. 
		\item \textbf{COR-validity-1:} If a non-faulty node, $p_j$, invokes $\mathsf{recycle}_j()$, then at least one non-faulty node, $p_i$, reported delivery.
		\technicalReport{\Ie no non-faulty node, $p_j$, invokes $\mathsf{recycle}_j()$ if only faulty nodes report delivery.} 
		
		\item \textbf{COR-validity-2:} If all non-faulty nodes report delivery, then at least one non-faulty node, $p_j$, eventually invokes $\mathsf{recycle}_j()$. 
		
		\item \textbf{COR-agreement:} If a non-faulty node invokes $\mathsf{recycle}()$, then all non-faulty nodes, $p_i$, invoke $\mathsf{recycle}_i()$ simultaneously. 
	\end{itemize}
\end{definition}
\BB



\Subsection{\ems{Multiple objects}}
%
\ems{We also specify that the recycling mechanism makes} sure that, at any time, there are at most a constant number, $logSize$, of active objects, \ie objects that have not completed their tasks. 
Once an object completes its task, the recycling mechanism can allocate a new object by moving to the next array entry as long as some constraints are satisfied. 
Specifically, the proposed solution is based on a synchrony assumption that guarantees that every (correct) node retrieves (at least once) the result of a completed object, $x$, within $logSize$ synchronous rounds since the first time in which at least $t+1$ (correct) nodes have retrieved the result of $x$, and thus, $x$ can be recycled. 




\Subsection{Solution overview}
%
\label{sec:over}
%
The SSBFT recycling solution is a composition of several algorithms, \ems{see \Figure~\ref{fig:arc}.} Our recycling mechanism is presented in \Algorithm~\ref{alg:logOneRecycling}. It allows every (correct) node to retrieve at least once the result of any object that is stored in a \ems{constant-size} array and yet over time that array can store an unbounded number of object instances. 
\ems{The proposed service mechanism (\Algorithm~\ref{alg:logOneRecycling}) ensures that every instance of the recyclable object, which is implemented by \Algorithm~\ref{alg:RconsensusB}, is guaranteed that every (correct) node calls $\done()$ (line~\ref{ln:wasDelivered}) at least once before all (correct) nodes simultaneously invoke $\mathsf{recycle}()$ (line~\ref{ln:recycle}). This aligns with the solution architecture (\Figure~\ref{fig:arc}).}

%\ems{The proposed service mechanism (\Algorithm~\ref{alg:logOneRecycling}) for recycling used consensus objects} guarantees that for every instance of the recyclable object, \ems{which is implemented by the client (\Algorithm~\ref{alg:RconsensusB}),} every correct node calls $\done()$ (line~\ref{ln:wasDelivered}) at least once before every correct node simultaneously invokes $\mathsf{recycle}()$ (line~\ref{ln:recycle}), \ems{cf. the problem definition in \SectionAbv~\ref{sec:recyclable} .} 

%The retrieval of the object results is done by an entity external to the proposed solution. Thus, we assume such once at least $t+1$ correct nodes have performed this retrieval then this retrieval is performed by all $n-t$ correct nodes within a known constant number of synchronous rounds, which we denote by $logSize$ (line~\ref{ln:logSize}). The evidence for result retrieval by at least $t+1$ correct nodes is collected by at least $t+1$ node for which $\mathsf{wasDelivered}()$ returns '1' (line~\ref{ln:wasDelivered}), as we explain next.     

We consider the case in which the entity that retrieves the result of object $obj$ might be external (and perhaps, asynchronous) to the proposed solution. The proposed solution does not decide to recycle $obj$ before there is sufficient evidence that, within $logSize$ synchronous cycles, the system is going to reach a state in which $obj$ can be \ems{properly} recycled. Specifically, Assumption~\ref{def:logSize} considers an event that can be locally learned about when $\mathsf{wasDelivered}()$ returns `1' (line~\ref{ln:wasDelivered}).



\begin{algorithm}[t!]
	\begin{\algSize}	
		
%		\medskip
		\textbf{constants:} 
		$indexNum$ number of indices of recyclable objects\label{ln:indexNum}\;
		$logSize \in \{0,\ldots,indexNum-2\}$ user-defined bound on the object log size\label{ln:logSize}\;
		
		\smallskip
		
		\textbf{variables:} 
		%
		$obj[indexNum]:$ \extendedAbstract{array of recyclable objects, \eg GMRS}\technicalReport{array of recyclable objects, \eg GMRS. Note that during legal execution only at most $(logSize+1)$ objects are stored at any given point of time}\label{ln:objIndexNum}\; 
		
		\smallskip
		
		$\mathit{ssbftIndex}:$ an SSBFT index of the current object in use (\Algorithm~\ref{alg:ssbftIndexViaSimRelInc})\;
		
		\smallskip	
		
		\textbf{upon pulse} \texttt{/* signal from global pulse system */} \label{ln:vbbBradcastAAA} \Begin{
			\technicalReport{\indent \ForEach{$x \notin \{y ~\bmod$ $ indexNum:y\in \{z-logSize,\ldots,z\}\}$ \textbf{\emph{where}} $z=indexNum+\mathit{ssbftIndex}.getIndex()$}{$obj[x].\mathsf{recycle}()$}}
			\extendedAbstract{\indent \lForEach{$x \notin \{y ~\bmod$ $ indexNum:y\in \{z-logSize,\ldots,z\}\}$ \textbf{\emph{where}} $z=indexNum+\mathit{ssbftIndex}.getIndex()$}{$obj[x].\mathsf{recycle}()$}}
		}
%		\medskip		
		
		\caption{\label{alg:logOneRecycling}SSBFT synchronous recycling\technicalReport{ with a predefined log size}; \technicalReport{code for node $p_i$}\extendedAbstract{$p_i$'s code}}		
	\end{\algSize}
	
\end{algorithm}

\BB
\begin{assumption}[A bounded time result \emsA{retrieval}]
%
\label{def:logSize}
%
Let us consider the system state, $c[r]$, in which the result of object $obj$ was retrieved by at least $t+1$ (correct) nodes. We assume, within $logSize$ synchronous cycles from $c[r]$, the system reaches a state, $c[r+logSize]$, in which all $n-t$ (correct) nodes have retrieved the result of $obj$ at least once.
\end{assumption}
\BB\B
%%  %% \technicalReport{



\Algorithm~\ref{alg:logOneRecycling}'s recycling guarantees are facilitated by an SSBFT multivalued consensus object (\Algorithm~\ref{alg:ssbftMVC}).
It helps to decide on a single piece of evidence from all collected ones \ems{(regarding recyclability)} and \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} uses the agreed evidence for updating\reduce{ the value of} the index that points to the current entry in the object array.
We later add details on \Algorithm~\ref{alg:logOneRecycling} before proving its correctness (Theorem~\ref{thm:ssbftBinCon}).


\Subsubsection{Evidence collection using an SSBFT (multivalued) consensus (\Algorithm~\ref{alg:ssbftMVC})}
%
The SSBFT multivalued consensus protocol returns within $t+1$ synchronous rounds an agreed non-$\bot$ value as long as at least $t+1$ nodes proposed that value, \ie at least one (correct) node proposed that value. 
As mentioned, $\mathsf{wasDelivered}()$ (line~\ref{ln:wasDelivered}) provides the \ems{input} to this consensus protocol. 
Thus, whenever '1' is decided, at least one (correct) node gets an indication from at least $n-t$ nodes that they have retrieved the results of the current object. 
This implies that by at least $t+1$ (correct) nodes have retrieved the results, and, by Assumption~\ref{def:logSize}, all $n-t$ (correct) nodes will retrieve the object result within a known number of synchronous rounds. 
Then, the object could be recycled. 
We later add details on \Algorithm~\ref{alg:ssbftMVC} before proving its correctness\technicalReport{ (Theorem~\ref{thm:algorithmMVC})}.

%\technicalReport{We later add details on \Algorithm~\ref{alg:ssbftMVC} before proving its correctness (Theorem~\ref{thm:algorithmMVC}).}




\Subsubsection{SSBFT simultaneous increment-or-get index (SIG-index)}
%
\Algorithm~\ref{alg:ssbftIndexViaSimRelInc} allows the proposed solution to keep track of the current object index that is currently used as well as facilitate synchronous increments to the index\reduce{ value}. 
We call this task \emph{simultaneous increment-or-get index} (SIG-index). 
During legal executions of \Algorithm~\ref{alg:ssbftIndexViaSimRelInc}, the (correct) nodes assert their agreement on the index value and update the index according to the result of the agreement on $\mathsf{wasDelivered}()$'s value. 
We later add details on \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} before proving its correctness (Theorem~\ref{thm:isSelf}).


%As explained above, \Algorithm~\ref{alg:ssbftMVC} contributes to the proposed solution the ability to uniformly decide that a given object should be recycled within $logSize$ synchronous rounds. Yet, there is a need to keep track of the current object index that is currently used and allow synchronous updates. We call this task \emph{simultaneous increment-or-get index} (SIG-index) and use \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} for achieving it. During legal executions, the correct nodes asserts that they all agree on the same index and then update the index according to the result of \Algorithm~\ref{alg:ssbftMVC}.     


\begin{algorithm}[t!]
	\begin{\algSize}	
		
		
%		\smallskip
		\textbf{variables:} $currentResult$ stores the most recent result of $co$\label{ln:varResults}\; 
		
		$co$ a (non-self-stabilizing) BFT (multivalued) consensus object\label{ln:varCo}\;
		
		\smallskip
		
		\textbf{interface required:} 
		
		$input():$ source of (the proposed values) of the given consensus protocol\;
		
		\smallskip
		
		\textbf{interface provided:} 
		
		
		$\done()$\label{ln:doneSSBFTcon}: \textbf{do} $\Return{(currentResult)}$ \texttt{//} \extendedAbstract{most recent $co$'s decided value}\technicalReport{decided value of the most recent $co$'s invocation}\;
		
		\smallskip
		
		\textbf{message structure:} 
		$\langle appMsg \rangle$, where $appMsg$ is the application message, \ie a message sent by the given consensus protocol\; 
		
		\smallskip
		
		\textbf{upon pulse} \texttt{/* signal from global pulse system */} \label{ln:vbbBradcastAAAB} \Begin{
			
			
			
			
			\textbf{let} $M$ be \ems{a} message that holds at $M[j]$ the arriving $\langle appMsg_j \rangle$ messages from $p_j$ for the current synchronous round and $M'=[\bot, \ldots,\bot]$\label{ln:messageArrival}\;
			
			
			
			
			
			
			
			\If{$clock(\kappa)=0$\label{ln:case0co}}{
				
				$currentResult \gets co.\done()$\label{ln:getResults}\;  
				$co.\mathit{restart}()$\label{ln:coRestart}\;				
				$M' \gets co.\mathit{propose}(input())$\label{ln:coPrupuse} \texttt{//} {for recycling $input()\equiv\mathsf{wasDelivered}()$\label{ln:coWasDelivered}}
				
			}
			
			\lElseIf{$clock(cycleSize) \in \{1,\ldots,t\}$\label{ln:processIf}}{$M' \gets co.\mathit{process}(M)$\label{ln:processThen}}
			
			\lForEach{$p_j \in \sP$\label{ln:sendMjToAllIFor}}{\textbf{send} $\langle M'[j] \rangle$ \textbf{to} $p_j$\label{ln:sendMjToAllIDo}}
			
		}
		
		
		
%		\smallskip
		
		
		\caption{\label{alg:ssbftMVC}SSBFT \ems{synchronous} multivalued consensus; \technicalReport{code for node $p_i$}\extendedAbstract{$p_i$'s code}}		
	\end{\algSize}
	
\end{algorithm}

%%  %% }  % \technicalReport




\Subsubsection{Scheduling strategy}
%
As mentioned, our SSBFT multivalued consensus requires $t+1$ synchronous rounds to complete and provide input to \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} and $\kappa-(t+1)$ synchronous rounds after that, any (correct) node can recycle the current object (according to the multivalued consensus result), where $\kappa=\max\{t+1,logSize\}$. 
Thus, \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} has to defer its index updates until that time. \Figure~\ref{fig:schdule} depicts this scheduling strategy, which considers the schedule cycle of $\kappa$. 
That is, the SIG-index and multivalued consensus starting points are $0$ and $\kappa-4$, respectively. 
Note that \Algorithm~\ref{alg:logOneRecycling} does not require scheduling since it accesses the index only via \Algorithm~\ref{alg:ssbftIndexViaSimRelInc}'s interface of SIG-index, see \Figure~\ref{fig:arc}.  

\begin{algorithm}[t!]
	\begin{\algSize}	
		
		%	\smallskip
		
		\textbf{constants:} $I:$ bound on the number of states an index may have\; 
		
		\smallskip
		
		\textbf{variables:} 
		$\mathit{index} \in \{0,\ldots, I-1\}:$ a local copy of the global\reduce{ logical} object index\;
		
		\smallskip
		
		$\mathit{ssbftCO}:$ an SSBFT multivalued consensus object (\Algorithm~\ref{alg:ssbftMVC})\technicalReport{ that is} used for agreeing on the recycling state, \ie 1 when there is a need to recycle (otherwise 0)\; 
		
		\smallskip
		
		\textbf{interfaces provided:} 
		%
		$getIndex()$ \textbf{do} \Return{$index$}\;
		
		
		\smallskip
		
		\textbf{message structure:} 
		$\langle index \rangle$: the logical object index\; 
		
		\smallskip
		
		\textbf{upon pulse} \texttt{/* signal from global pulse system */} \label{ln:vbbBradcastAAAC} \Begin{
			
			\textbf{let} $M$ be the arriving $\langle index_j\rangle$ messages from $p_j$\label{ln:MarrivingIndex}\;
			
			\Switch{$clock(\kappa)$\label{ln:switchA} \emph{\texttt{/* consider $clock()$ at the pulse beginning */}}}{
				
				\lCase{$\kappa-4$\label{ln:case0}}{\textbf{broadcast} $\langle index=getIndex() \rangle$\label{ln:clockAZero}}
				
				\Case{$\kappa-3$}{
					
					\textbf{let} $propose := \bot$\label{ln:proposeGetsBotprp}\;
					\lIf{$\exists v \neq \bot:|\{  \langle v  \rangle \in M\}|\geq \emsA{n-t}$}{$propose \gets v$\label{ln:existsVNeqBotVBull}}
					
					\textbf{broadcast} $\langle propose \rangle$\label{ln:broadcastPropose}\;
				}
				
				\Case{$\kappa-2$\label{ln:case2}}{
					
					\textbf{let} $bit := 0$\label{ln:saveBitGetsBot}; $save \gets \bot$\label{ln:saveBitGetsBotS}\;
					
					\lIf{$\exists s \neq \bot:|\{  \langle s  \rangle \in M\}|> n/2$}{$save\gets s$\label{ln:sNeqBot}}
					
					\lIf{$|\{\langle save \neq \bot\rangle \in M\}|\geq \emsA{n-t}$}{$bit \gets 1$\label{ln:saveNeqBot}}
					
					\lIf{$save = \bot$}{$save \gets 0$\label{ln:saveBot}}
					
					\textbf{broadcast} $\langle bit\rangle$\label{ln:saveBotX}\;	
				}
				
				\Case{$\kappa-1$\label{ln:case3}}{
					\textbf{let} $\mathit{inc} := 0$\label{ln:glbSvV}\;
					
					\lIf{$\mathit{ssbftCO}.\done()$}{$\mathit{inc}\gets 1$\label{ln:glbSvVONE}}
					
					%					\lIf{$TEST$}{$\mathit{inc} \gets 1$\label{ln:glbSv}}
					\lIf{$|\{\langle 1\rangle \in M\}|\geq \emsA{n-t}$}{$\mathit{index} \gets (save + \mathit{inc})\bmod I$\label{ln:logicSavePlusSv}}
					\lElseIf{$|\{\langle 0\rangle \in M\}|\geq \emsA{n-t}$}{$\mathit{index} \gets 0$\label{ln:logicZero}}
					\lElse{$\mathit{index} \gets rand(save + \mathit{inc}) \bmod I$\label{ln:logicRandSavePlusSv}}
				}				
			}
		}
		%	\smallskip
		
		
		\caption{\label{alg:ssbftIndexViaSimRelInc}SSBFT \ems{synchronous} SIG-index; $p_i$'s code}		
	\end{\algSize}	
\end{algorithm}

\Subsubsection{Communication piggybacking and multiplexing}
%
We use a piggybacking technique to facilitate the spread of the result (decision) values of the recyclable objects. As \Figure~\ref{fig:arc} illustrates, all communications are piggybacked. Specifically, we consider a meta-message $MSG()$ that has a field for each message sent by all algorithms in \Figure~\ref{fig:arc}. 
That is, when any of these algorithms is active, its respective field in $MSG()$ includes a non-$\bot$ value. 
With respect to GMRS's field, $MSG()$ includes the most recent message that GMRS has sent (or currently wishes to send). 
This piggybacking technique allows the multiplexing of timed and reliable communication (assumed for \ems{the recycling mechanism)} and fair communication (assumed for \ems{the recyclable object).}

\Subsection{SSBFT recycling\remove{ in $\mathsf{BSMP_{n,t}[t < n/3,(t+1)\mathit{-}SGC]}$} (\Algorithm~\ref{alg:logOneRecycling})}
%
\label{sec:ssbftBinCon}
%
As mentioned, \Algorithm~\ref{alg:logOneRecycling} \ems{has} an array, $obj[]$ (line~\ref{ln:objIndexNum}), of $indexNum$ recyclable objects (line~\ref{ln:indexNum}). The array size needs to be larger than $logSize$ (line~\ref{ln:logSize} and Assumption~\ref{def:logSize}). 
%
%In addition to the array $obj[]$, 
%
\Algorithm~\ref{alg:logOneRecycling}'s variable set also includes $\mathit{ssbftIndex}$, which is an integer that holds the entry number of the latest object in use. \Algorithm~\ref{alg:logOneRecycling} accesses the agreed current index \ems{via} $\mathit{ssbftIndex}.getIndex()$. 
This lets the code \ems{to} nullify any entry in $obj[]$ that is not $\mathit{ssbftIndex}.getIndex()$ or at most $logSize$ older than $\mathit{ssbftIndex}.getIndex()$.
Theorem~\ref{thm:ssbftBinCon} shows \Algorithm~\ref{alg:logOneRecycling}'s correctness.


\technicalReport{% Figure environment removed} 

 
%\extendedAbstract{
%	\Subsection{SSBFT multivalued consensus in $\mathsf{BSMP_{n,t}[t < n/3,(t+1)\mathit{-}SGC]}$}
%	%
%	\label{sec:ssbftMVC}
%	%
%}  %\extendedAbstract

%%  %% \technicalReport{
\Subsection{SSBFT \ems{synchronous} multivalued consensus}
%
\label{sec:ssbftMVC}
%
\Algorithm~\ref{alg:ssbftMVC} assumes access to a deterministic (non-self-stabilizing) BFT (multivalued) consensus object, $co$, such as the ones proposed by Kowalski and Most{\'{e}}faoui~\cite{DBLP:conf/podc/KowalskiM13} or Abraham and Dolev~\cite{DBLP:conf/stoc/AbrahamD15}, for which completion is guaranteed to occur within $t+1$ synchronous rounds. We list our assumptions regarding the interface to \ems{$co$} in Definition~\ref{sec:assumptionsMVC}.

\Subsubsection{Required \ems{consensus object interface}}
%
Our solution uses the technique of recomputation of $co$'s floating output~\cite[Ch. 2.8]{DBLP:books/mit/Dolev2000}, where $co$ is specified in Definition~\ref{sec:assumptionsMVC}.		

\BB
\begin{definition}[Synchronous BFT Consensus]
%
\label{sec:assumptionsMVC}
%
Let $co$ be a BFT (non-self-stabilizing) synchronous multivalued consensus that implements the following.
\begin{itemize}[topsep=0.2em, partopsep=0pt, parsep=0pt, itemsep=0pt,leftmargin=3pt, rightmargin=0pt, listparindent=0pt, labelwidth=0.15em, labelsep=0.35em, itemindent=0.75em]
\item $\mathit{restart}()$ sets $co$ to its initial state.		

\item $\mathit{propose}(v)$ proposes the value $v$ when invoking (or re-invoking) $co$.\technicalReport{ This operation is effective only after $\mathit{restart}()$ was invoked.} The returned value is a message vector, $M[]$, that includes all the messages, $M[j]$, that $co$ wishes to send to node $p_j$ for the current synchrony round.

\item $\mathit{process}(M)$ runs a single step of $co$.\technicalReport{ The input vector $M$ includes the arriving messages for the current synchronous round, where $M[j]$ is $p_j$'s message.} The returned value is a message vector that includes all the messages that $co$ wishes to send for the current\technicalReport{ synchrony} round.\technicalReport{ This operation is guaranteed to work correctly only after all (correct) nodes have simultaneously taken a consecutive sequence of steps that include invocations of either (i) $\mathit{process}()$, or (ii) $\mathit{restart}()$ immediately before proposing a non-$\bot$ value via the invocation of $\mathit{propose}()$.}

\item $\done()$ returns a non-$\bot$ results after the completion of $co$.\technicalReport{ The returned value is required to satisfy the consensus specifications only if all (correct) nodes have simultaneity taken a sequence of correct $\mathit{process}()$ invocations.}
\end{itemize}
\end{definition}
\BB

\Subsubsection{Detailed description}
%
\Algorithm~\ref{alg:ssbftMVC}'s set of variables includes $co$ itself (line~\ref{ln:varCo}) and the current version of the result, \ie $currentResult$ (line~\ref{ln:varResults}). This way, the SSBFT version of $co$'s result can be retrieved via a call to $\done()$ (line~\ref{ln:doneSSBFTcon}). \Algorithm~\ref{alg:ssbftMVC} proceeds in synchronous rounds. At the start of any round, node $p_i$ stores all the arriving messages at the message vector $M$ (line~\ref{ln:messageArrival}).

When the clock value is zero (line~\ref{ln:case0co}), it is time to start the re-computation of $co$'s result. Thus, \Algorithm~\ref{alg:ssbftMVC} first stores\reduce{ the current value of} $co$'s result at $currentResult_i$ (line~\ref{ln:getResults}). Then, it restarts $co$'s local state and proposes a new value to $co$ (lines~\ref{ln:coRestart} and~\ref{ln:coPrupuse}). For the recycling solution presented in this paper, the proposed value is retrieved from $\mathsf{wasDelivered}()$ (line~\ref{ln:wasDelivered}).
%
For the case in which the clock value is not zero (line~\ref{ln:processIf}), \Algorithm~\ref{alg:ssbftMVC} simply lets $co$ process the arriving messages of the current round. 
%
Both for the case in which the clock value is zero and the case it is not, \Algorithm~\ref{alg:ssbftMVC} broadcasts $co$'s messages for the current round (line~\ref{ln:sendMjToAllIFor}).   




\Subsubsection{Correctness proof}
%
\label{sec:corrAlgorithmMVC}
%
Theorem~\ref{thm:algorithmMVC} shows that \Algorithm~\ref{alg:ssbftMVC} stabilizes within $2\kappa$\technicalReport{ synchronous} rounds.

\BB\begin{theorem}
\label{thm:algorithmMVC}
%
\Algorithm~\ref{alg:ssbftMVC} is an SSBFT deterministic (multivalued) consensus solution that \ems{stabilizes} within $2\kappa$ synchronous rounds. 
\end{theorem}\B
\renewcommand{\thmcnt}{\ref{thm:algorithmMVC}}
\BB\begin{theoremProof}
	Let $R$ be an execution of \Algorithm~\ref{alg:ssbftMVC}
	Within $\kappa$ synchronous rounds, the system reaches a state $c \in R$ in which $clock(\kappa)=0$ holds. 
	Immediately after $c$, every (correct) node, $p_i$, simultaneously restarts $co_i$ and proposes the input (lines~\ref{ln:coRestart} and~\ref{ln:coPrupuse}) before sending the needed messages (line~\ref{ln:sendMjToAllIDo}). 
	Then, for the $t<\kappa$ synchronous rounds that follow, all (correct) nodes simultaneously process the arriving messages and send their replies (line~\ref{ln:processIf} and~\ref{ln:sendMjToAllIDo}). 
	Thus, within $2\kappa$ synchronous rounds from $R$'s start, the system reaches a state $c'\in R$ in which $clock(\kappa)=0$ holds. 
	Also, in the following synchronous round, all (correct) nodes store $co$'s results. 
	\ems{These results are}\technicalReport{ guaranteed to be} correct due to Definition~\ref{sec:assumptionsMVC}\technicalReport{'s assumptions}.  	   
\end{theoremProof}\B
%%  %% } % \technicalReport

\Subsection{SSBFT simultaneous increment-or-get index}
%
\label{sec:ssbftIndexViaSimRelInc}
%
The task of \emph{simultaneous increment-or-get index} (SGI-index) requires all (correct) nodes to maintain identical index values that all nodes can independently retrieve via $getIndex()$. 
%
%We use the $\mathsf{BSMP_{n,t}[t < n/3,RCC,4\mathit{-}SGC]}$ model. 
%
The task assumes that all increments are performed according to the result of a consensus object, $\mathit{ssbftCO}$, such as \Algorithm~\ref{alg:ssbftMVC}. \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} presents an SGI-index solution that recovers from disagreement on the index value using RCCs. That is, whenever a (correct) node receives \emsA{$n-t$} reports from other nodes that they have each observed \emsA{$n-t$} identical index values, an agreement on the index value is assumed and the index is incremented according to the most recent result of $\mathit{ssbftCO}$. Otherwise, a randomized strategy is taken for guaranteeing recovery from a disagreement on the index value. Our strategy is inspired by BDH~\cite{DBLP:conf/podc/Ben-OrDH08}\technicalReport{'s SSBFT clock synchronization algorithm}.

%, which is in turn derived from non-self-stabilizing BFT solutions by Rabin~\cite{DBLP:conf/focs/Rabin83} as well as Turpin and Coan~\cite{DBLP:journals/ipl/TurpinC84}. 

%its structure resembles the SSBFT clock synchronization solution by Ben-Or, Dolev, and Hoch~\cite{DBLP:conf/podc/Ben-OrDH08}. Their solution lets every correct node to increment that clock on every pulse and in every fourth pulse         


\Subsubsection{Detailed description}
%
\Algorithm~\ref{alg:ssbftIndexViaSimRelInc} is active during four clock phases, \ie $\kappa-4$ to $\kappa-1$. Each phase starts with storing all arriving messages (from the previous round) in the array, $M$ (line~\ref{ln:MarrivingIndex}). The first phase broadcasts the local index value (line~\ref{ln:clockAZero}). The second phase lets each node vote on the majority arriving index value, or $\bot$ in case such value was not received (lines~\ref{ln:proposeGetsBotprp} to~\ref{ln:broadcastPropose}). The third phase resolves the case in which there is an arriving non-$\bot$ value, $save$,  that received sufficient support when voting during phase two (lines~\ref{ln:saveBitGetsBotS} to~\ref{ln:saveBot}). Specifically, if $save\neq \bot$ exists, then $\langle bit=1\rangle$ is broadcast. Otherwise, $\langle bit=0\rangle$ is broadcast. On the fourth phase (lines~\ref{ln:glbSvV} to~\ref{ln:logicRandSavePlusSv}), the (possibly new) index is set either to be the majority-supported index value of phase two plus $inc$ (lines~\ref{ln:glbSvV} to~\ref{ln:logicSavePlusSv}), where $inc$ is the output of $\mathit{ssbftCO}$, or (if there was insufficient support) to a randomly chosen output of the RCC (lines~\ref{ln:logicZero} and~\ref{ln:logicRandSavePlusSv}).

\Subsubsection{Correctness proof}
%
\label{sec:corrIsSelf}
%
%    presents the BDH solution for a self-stabilizing Byzantine-tolerant $\kappa$-bits clock synchronization by Ben{-}Or, Dolev, and Hoch~\cite{DBLP:conf/podc/Ben-OrDH08}. BDH has a constant overhead both in message complexity and in its expected stabilization time. BDH uses coin-flipping and $2$-bit solutions, which can be found at~\cite[figures 1 and 3]{DBLP:conf/podc/Ben-OrDH08}.
%
%BDH executes four phases. Each executed in a consecutive pulse. The first phase sends the clock value to everyone. In the second phase, each node votes on the majority clock value it received, or the $\bot$ value if no such value exists. The third phase determines whether enough nodes voted on a non-$\bot$ value, thus ensuring that those nodes that have voted, voted on the same value in phase 2. Lastly, in the fourth phase the new clock value is set either to be the majority clock value of phase 2, or (if there were not enough votes) is randomly selected using the output of BDH's coin-flipping solution. 
%
Theorem~\ref{thm:isSelf} \ems{bounds \Algorithm~\ref{alg:ssbftIndexViaSimRelInc}'s \emsA{stabilization} time.}

\B
\extendedAbstract{
\B\begin{theorem}
	\label{thm:isSelf}
	\Algorithm~\ref{alg:ssbftIndexViaSimRelInc} is an SSBFT SGI-index implementation that stabilizes within expected $\bigO(1)$ synchronous rounds.
\end{theorem}\B
\renewcommand{\thmcnt}{\ref{thm:isSelf}}
\B\begin{theoremProofSketch}
	Lemma~\ref{thm:atLeast} implies that, within $O(1)$ of expected rounds, all (correct) nodes have identical $index$ values. Recall that $c[r] \in R$ is \emph{(progress) enabling} if $\exists x \in \{0,1\}: \forall i \in \Correct: rand_i=x$ holds at $c[r]$ (\SectionAbv~\ref{sec:rcc}).
	Due to the page limit, the Closure proof appears in~\cite{TR}.
	
	\B\B\begin{lemma}[Convergence]
		\label{thm:atLeast}
		Let $r> \kappa$. Suppose $c[r] \in R$ is (progress) enabling system state (\SectionAbv~\ref{sec:rcc}) for which $clock(\kappa) = \kappa - 1$ holds. With probability at least $\min \{p_0, p_1\}$, all (correct) nodes have the same $index$ at $c[r+1]$.
	\end{lemma}\B
	\renewcommand{\lemcnt}{\ref{thm:atLeast}}
	\B\begin{lemmaProofSketch}
		The proof is implied by claims~\ref{thm:atLeastNoVal} to~\ref{thm:atLeastOneVal}.
		
		\B\B\begin{myClaim}
			\label{thm:atLeastNoVal}
			%		
			Suppose no (correct) $p_i \in \sP$ receives $\langle x\rangle$ from at least \emsA{$n -t$} different nodes  at $a_i[r]$. 
			With probability $p_0$, any (correct) $p_j $ assigns $0$ to $index_j$ at $a_j[r]$.
		\end{myClaim}\B 
		\renewcommand{\clmcnt}{\ref{thm:atLeastNoVal}}
		\B\begin{claimProof}
			The proof is implied directly from lines~\ref{ln:glbSvVONE} to~\ref{ln:logicRandSavePlusSv}.
		\end{claimProof}\B
		
		\B\begin{myClaim}
			\label{thm:atLeastZeoVal}
			%		
			Suppose $p_i : i \in \Correct$ receives $\langle 0\rangle$ from at least \emsA{$n-t$} different nodes at $a_i[r]$. Also, $p_j : j\in \Correct$ receive $\langle x\rangle$ from at least \emsA{$n-t$} different nodes at $a_j[r]$, where $i=j$ may or may not hold. The step $a_j[r]$ assigns $0$ to $index_j$.
			%			
			%						Suppose $p_i \in \sP:i \in \Correct$ receives at the start of step $a_i[r]$ the message $\langle 0\rangle$ from at least \emsA{$n-t$} different nodes. Also, suppose there are $x \in \{0,1\}$ and $p_j \in \sP:j \in \Correct$ that receive at the start of step $a_j[r]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes. The step $a_j[r]$ assigns $0$ to $index_j$.
		\end{myClaim}\B
		\renewcommand{\clmcnt}{\ref{thm:atLeastZeoVal}}
		\B\begin{claimProofSketch}
			Line~\ref{ln:logicZero} implies the proof since $x=0$.
		\end{claimProofSketch}\B
		
		\B\begin{myClaim}
			\label{thm:atLeastOneValSame}
			%		
			Suppose $p_i$ receives $\langle 1\rangle$ from at least \emsA{$n-t$} different nodes at $a_i[r]$. 
			At $c[r]$, $(\mathit{ssbftCO}_i.\done(),save_i)=(\mathit{ssbftCO}_j.\done(),save_j):i,j \in \Correct$.
		\end{myClaim}\B
		\renewcommand{\clmcnt}{\ref{thm:atLeastOneValSame}}
		\B\begin{claimProofSketch}
			At $c[r]$, $\mathit{ssbftCO}_i.\done() = \mathit{ssbftCO}_j.\done()$ holds (BC-agreement).
			%			
			There is $p_k :k\in \Correct$ that has sent $\langle 1\rangle$ at $a[r-1]$. By lines~\ref{ln:saveBitGetsBotS} to~\ref{ln:saveNeqBot}, $p_j$ receives at $a_j[r-1]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes, where $x=save_j \neq \bot$. 
			%
			Any (correct) node broadcasts (line~\ref{ln:broadcastPropose}) either $\bot$ or $x$ at $a[r-2]$. At $a[r-1]$, (correct) nodes receive at most $f <n-2f$ values that are neither $\bot$ nor $x\neq \bot$. Thus, $save_i = save_j$.
		\end{claimProofSketch}\B
		
		
		\B\begin{myClaim}
			\label{thm:atLeastOneVal}
			%		
			Let $i,j \in \Correct$. Suppose $p_i$ receives $\langle 1\rangle$ from at least \emsA{$n-t$} different nodes at $a_i[r]$ and $p_j$ receives $\langle x\rangle$ from at least \emsA{$n-t$} different nodes at $a_j[r]$. With a probability of at least $\min \{p_0, p_1\}$, $a_i[r]$ and $a_j[r]$ assign the same value to $index_j$, and resp., $index_j$. 
		\end{myClaim}\B
		\renewcommand{\clmcnt}{\ref{thm:atLeastOneVal}}
		\B\begin{claimProofSketch}
			Steps $a[r-1]$ and $a[r]$ independently assign $x$, and resp., $rand$.
			With a probability of at least $\min \{p_0, p_1\}$, all (correct) nodes update $index$ to\reduce{ either} $0$ or $save+inc$ (Claim~\ref{thm:atLeastOneValSame}).
		\end{claimProofSketch}
	\end{lemmaProofSketch}
\end{theoremProofSketch}\B
} % \extendedAbstract

\technicalReport{
	\B\begin{theorem}
		\label{thm:isSelf}
		Let $R$ be an execution of algorithms~\ref{alg:ssbftMVC} and~\ref{alg:ssbftIndexViaSimRelInc} that is legal w.r.t. \Algorithm~\ref{alg:ssbftMVC} (Theorem~\ref{thm:algorithmMVC}). \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} is an SSBFT SGI-index implementation that stabilizes within expected $\bigO(1)$ synchronous rounds.
	\end{theorem}\B
	\renewcommand{\thmcnt}{\ref{thm:isSelf}}
\B\begin{theoremProof}
Corollaries~\ref{thm:vAvB} and~\ref{thm:atMostOneV} are needed for Lemmas~\ref{thm:atLeast} and~\ref{thm:bmodKappa}. The pigeonhole principle implies Corollary~\ref{thm:vAvB}.

% Corollary~\ref{thm:atMostOneV} is implied by Corollary~\ref{thm:vAvB}.

\B\begin{corollary}%[Observation 3.1 in~\cite{DBLP:conf/podc/Ben-OrDH08}]
	\label{thm:vAvB}
	Let $V_{x \in \{a,b\}}$ be two $n$-length vectors that differ in at most $f<n/3$ entries. For any $x \in \{a,b\}$, suppose $V_x$ contains \emsA{$n-t$} copies of $v_x$. Then $v_a = v_b$.
\end{corollary}\B

Corollary~\ref{thm:atMostOneV} is implied by Corollary~\ref{thm:vAvB}.

\B\begin{corollary}
	\label{thm:atMostOneV}
	Let $c[r] \in R$ be a system state in which $clock(\kappa)=\kappa-3$ and $X=\{x_i:i\in\Correct\}$ be the set of values encoded in the messages $\langle x_i\rangle$ that any (correct) node, $p_i \in \sP$, broadcasts in line~\ref{ln:broadcastPropose} at the end of $a_i[r]$. The set $X$ includes at most one non-$\bot$ value.
\end{corollary}\B

Lemma~\ref{thm:atLeast} implies that, within $O(1)$ of expected rounds, all (correct) nodes have identical $index$ values. Recall that $c[r] \in R$ is \emph{(progress) enabling} if $\exists x \in \{0,1\}: \forall i \in \Correct: rand_i=x$ holds at $c[r]$ (\SectionAbv~\ref{sec:rcc}).

\B\begin{lemma}[Convergence]
	\label{thm:atLeast}
	Let $r> \kappa$. Suppose $c[r] \in R$ is (progress) enabling system state (\SectionAbv~\ref{sec:rcc}) for which $clock(\kappa) = \kappa - 1$ holds. With probability at least $\min \{p_0, p_1\}$, all (correct) nodes have the same $index$ at $c[r+1]$.
\end{lemma}\B
\renewcommand{\lemcnt}{\ref{thm:atLeast}}
\B\begin{lemmaProof}
	The proof is implied by claims~\ref{thm:atLeastNoVal} to~\ref{thm:atLeastOneVal}.
	
	\B\begin{myClaim}
		\label{thm:atLeastNoVal}
		%		
		Suppose (i) there is no value $x \in \{0,1\}$ and (ii) there is no (correct) node $p_i \in \sP$ that receives at the start of step $a_i[r]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes. For any (correct) node, $p_j \in \sP$, it holds that step $a_j[r]$ assigns $0$ to $index_j$ with probability $p_0$.
	\end{myClaim}\B
	\renewcommand{\clmcnt}{\ref{thm:atLeastNoVal}}
	\B\begin{claimProof}
		The proof is implied directly from lines~\ref{ln:glbSvVONE} to~\ref{ln:logicRandSavePlusSv}.
	\end{claimProof}
	
	\B\begin{myClaim}
		\label{thm:atLeastZeoVal}
		%		
		Suppose there is a (correct) node $p_i \in \sP$ that receives at the start of step $a_i[r]$ the message $\langle 0\rangle$ from at least \emsA{$n-t$} different nodes. Also, suppose there is $x \in \{0,1\}$ and a (correct) node $p_j \in \sP$ that receives at the start of step $a_j[r]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes, where $i=j$ may or may not hold. The step $a_j[r]$ assigns $0$ to $index_j$.
		%			
		%						Suppose $p_i \in \sP:i \in \Correct$ receives at the start of step $a_i[r]$ the message $\langle 0\rangle$ from at least \emsA{$n-t$} different nodes. Also, suppose there are $x \in \{0,1\}$ and $p_j \in \sP:j \in \Correct$ that receive at the start of step $a_j[r]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes. The step $a_j[r]$ assigns $0$ to $index_j$.
	\end{myClaim}\B
	\renewcommand{\clmcnt}{\ref{thm:atLeastZeoVal}}
	\B\begin{claimProof}
		Line~\ref{ln:logicZero} implies the proof since $x=0$ (Corollary~\ref{thm:vAvB}).
	\end{claimProof}
	
	\B\begin{myClaim}
		\label{thm:atLeastOneValSame}
		%		
		Suppose there is a (correct) $p_i \in \sP$ that receives at the start of step $a_i[r]$ the message $\langle 1\rangle$ from at least \emsA{$n-t$} different nodes. Let $p_j \in \sP$ be a (correct) node. At $c[r]$, $\mathit{ssbftCO}_i.\done() = \mathit{ssbftCO}_j.\done()$ and $save_i=save_j$ hold.
	\end{myClaim}\B
	\renewcommand{\clmcnt}{\ref{thm:atLeastOneValSame}}
	\B\begin{claimProof}
		At $c[r]$, $\mathit{ssbftCO}_i.\done() = \mathit{ssbftCO}_j.\done()$ holds (\Algorithm~\ref{alg:ssbftMVC}'s agreement property). We show that $save_i=save_j$ holds at $c[r]$.
		%			
		Since $p_i$ has received $\langle 1\rangle$ from at least \emsA{$n-t$} different nodes at the start of $a_i[r]$, we know that there is a (correct) node, $p_k \in \sP$, that has sent $\langle 1\rangle$ at the end of $a[r-1]$. By lines~\ref{ln:saveBitGetsBotS} to~\ref{ln:saveNeqBot}, node $p_j$ receives at the start of $a_j[r-1]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes, where $x=save_j \neq \bot$. 
		%
		By Corollary~\ref{thm:atMostOneV}, any (correct) node broadcasts (line~\ref{ln:broadcastPropose}) either $\bot$ or $x$ at the end of step $a[r-2]$. This means that at the start of $a[r-1]$, (correct) nodes receive at most $f <n-2f$ messages with values that are neither $\bot$ nor $x\neq \bot$. Therefore, $save_i = save_j$ since, at the start of $a_i[r]$ and $a_j[r]$ both $p_i$, and resp., $p_j$ receive from at least \emsA{$n-t$} different nodes the messages  $\langle x_i \rangle$, and resp., $\langle x_j \rangle$, where neither $x_i$ nor $x_j$ is $\bot$.
	\end{claimProof}
	
	\B\begin{myClaim}
	\label{thm:atLeastOneVal}
	%		
	Suppose there is a (correct) node $p_i \in \sP$ that receives at the start of step $a_i[r]$ the message $\langle 1\rangle$ from at least \emsA{$n-t$} different nodes. Suppose there is $x \in \{0,1\}$ and a (correct) node $p_j \in \sP$ that receives at the start of step $a_j[r]$ the message $\langle x\rangle$ from at least \emsA{$n-t$} different nodes, where $i=j$ may or may not hold. With a probability of at least $\min \{p_0, p_1\}$, the steps $a_i[r]$ and $a_j[r]$ assign the same value to $index_j$, and resp., $index_j$. 
	%		
	%		Also, the updated values are either $0$ or $(save+inc) \bmod I$, where the values of $save$ and $inc$ are determined in lines~\ref{ln:glbSvV},~\ref{ln:glbSvVONE} and~\ref{ln:saveBitGetsBotS}, and respectively, lines~\ref{ln:sNeqBot} and~\ref{ln:saveBot}.
\end{myClaim}\B
\renewcommand{\clmcnt}{\ref{thm:atLeastOneVal}}
\B\begin{claimProof}
	By Corollary~\ref{thm:vAvB}, $x=1$. The step $a[r-1]$ determines $x$'s value and $rand$ is chosen at the start of step $a[r]$. Due to $rand$'s unpredictability (\SectionAbv~\ref{sec:rcc}), $rand$ and $x$ are two independent values.
	%
	Thus, with a probability of at least $\min \{p_0, p_1\}$, all (correct) nodes update $index$ in the same manner, \ie to either $0$ or $save+inc$ (Claim~\ref{thm:atLeastOneValSame}), where $save$ and $inc$ are values determined by lines~\ref{ln:saveBitGetsBotS} to~\ref{ln:saveBot}, and resp.~\ref{ln:glbSvV} to~\ref{ln:glbSvVONE}.
\end{claimProof}
\end{lemmaProof}

\FF

Lemma~\ref{thm:bmodKappa} shows that all (correct) nodes forever agree on their indexes and simultaneously increment them by one (modulo $I$) only when $clock(\kappa)=\kappa-1$ and $\mathit{ssbftCO}_i.\done()=1$. Lemma~\ref{thm:bmodKappa} uses the following notation. Let $R=c[0],c[1],\ldots,c[r],\ldots$ an unbounded synchronous execution of \Algorithm~\ref{alg:ssbftIndexViaSimRelInc}, where $c[r]$ is the system state that immediately precedes the arrival of the $r$-th common pulse. Denote by $indices^{start}_r$ and $indices^{end}_r$ the sets of all $index_i: i \in \Correct$\remove{ values of (correct) nodes} at $c[r]$, and resp., $c[r+1]$, \ie the beginning, and resp., the end of step $a[r]$. Note that, for all $r$ and $x \in \{start, end\}$, we have $indices^{x}_r \subseteq \{0, 1,\ldots, I -1\}$.

\B\begin{lemma}[Closure] 
	\label{thm:bmodKappa}
	Let $c[r] \in R$, such that $clock(\kappa) = \kappa-1$ at $c[r]$. Suppose $indices^{end}_r = \{v\neq\bot\}$. For every $c[r'] \in R:r'  \in \{r+1,r+\kappa \}$ it holds that $indices^{start}_{r'} = \{ v + x \bmod  I \}$ where $x1$ when $r'=r+\kappa$ and $\mathit{ssbftCO}.\done()=1$. Otherwise, $x=0$, \ie when $r'  \in \{r+1,\ldots ,r+\kappa-1 \}$ or $\mathit{ssbftCO}.\done()\neq 1$.
\end{lemma}\B
\renewcommand{\lemcnt}{\ref{thm:bmodKappa}}
\B\begin{lemmaProof}
	For $r' = r + 1$ the lemma holds since, by definition, $\forall r'': indices^{end}_{r''} = indices^{start}_{r''+1}$. Also, for any system state $c[r']:r' \in \{r+1,\ldots,r +\kappa-1\}$, no (correct) node, $p_i \in \sP$, updates $index_i$ during the step, $a_i[r']$, since $clock(\kappa)\neq\kappa-1$ at $c[r']:r' \in \{r+1,\ldots,r +\kappa-1\}$ and thus lines~\ref{ln:logicSavePlusSv} to~\ref{ln:logicRandSavePlusSv} are not executed, which are the only lines that update $index_i$.
	
	It remains to show that all (correct) nodes, $p_i \in \sP$, update $index_i$ in the same way during the steps $a_i[r']:r'=r+\kappa$ that immediately follow $c[r']$. This is due to the agreement property of \Algorithm~\ref{alg:ssbftMVC}, the arguments above about $c[r']:r' \in \{r+1,r +\kappa-1\}$ as well as Claim~\ref{thm:theSameV}.
	
	\B\begin{myClaim}
		\label{thm:theSameV}
		%
		$indices^{start}_{r+\kappa} = \{v\}:v\neq\bot$.
	\end{myClaim}\B
	\renewcommand{\clmcnt}{\ref{thm:theSameV}}
	\B\begin{claimProof}
		By the schedule (\Figure~\ref{fig:schdule}) and its cycle length, $\kappa$, we know that \Algorithm~\ref{alg:ssbftIndexViaSimRelInc} is not active between $c[r+1]$ and $c[r+\kappa-3]$, but it is active during steps $a[r+\kappa-3]$, $a[r+\kappa-2]$, $a[r+\kappa-1]$, and $a[r+\kappa]$. During steps $a[r+\kappa-3]$, all (correct) nodes broadcast $\langle v \rangle$ (line~\ref{ln:clockAZero}). Thus, at the start of steps $a[r+\kappa-3]$, all (correct) nodes receive $\langle v \rangle$ at least \emsA{$n-t$} times (from different nodes). Thus, during $a[r+\kappa-2]$, all (correct) nodes assign $v$ to their $propose$ variables (line~\ref{ln:existsVNeqBotVBull}) and broadcast  $\langle v \rangle$ (line~\ref{ln:broadcastPropose}). By similar arguments, during $a[r+\kappa-1]$, all (correct) nodes assign $v$ and $1$ to their $save$, and resp., $bit$ variables (lines~\ref{ln:sNeqBot} to~\ref{ln:saveNeqBot}) and broadcast $\langle 1 \rangle$ (line~\ref{ln:saveBotX}). Therefore, all (correct) nodes receive $\langle 1 \rangle$ at least \emsA{$n -t$} times. This implies that during $a[r+\kappa]$, the if-statement condition in line~\ref{ln:logicSavePlusSv} holds and thus $indices^{start}_{r+\kappa} = \{v\neq\bot\}$ holds.
	\end{claimProof}
\end{lemmaProof}
\end{theoremProof}
} % \technicalReport

\B\begin{theorem}
	\label{thm:ssbftBinCon}
	\Algorithm~\ref{alg:logOneRecycling} is an SSBFT recycling mechanism (Definition~\ref{def:probDef})\remove{ for $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$} that stabilizes within expected $\bigO(\kappa)$ synchronous rounds.
\end{theorem}\B
\renewcommand{\thmcnt}{\ref{thm:ssbftBinCon}}
\B\begin{theoremProof}
%We show that \Algorithm~\ref{alg:logOneRecycling} satisfies Definition~\ref{def:probDef}'s requirements.
%
%\EMS{COR-client-eventual-agreement} is shown by Theorem~\ref{thm:COR-proposal-validity}. 
%
%COR-validity-1 and COR-validity-2 hold are implied by arguments 1 and 2 resp. 
%
\ems{COR-validity-1 and COR-validity-2 are implied by arguments 1 and 2, respectively.}
%
COR-agreement is implied by Argument 3. 
The stabilization time is due to the underlying algorithms.

\noindent \textbf{Argument 1} \emph{During legal executions, if the value of $index$ is incremented \emph{(}line~\ref{ln:logicSavePlusSv}\emph{)}, $\exists i \in \Correct:\mathsf{wasDelivered}()=1$ holds.~~}
 %	
By the assumption that $\mathsf{wasDelivered}()$ provides the proposed values used by the SSBFT multivalued consensus.
\technicalReport{Specifically, \Algorithm~\ref{alg:ssbftMVC} explicitly requires this, see the comment in line~\ref{ln:coPrupuse}.}
The value decided by this SSBFT consensus is used in line~\ref{ln:glbSvVONE} determines whether, during legal executions, the value of $index$ is incremented module $I$ (line~\ref{ln:logicSavePlusSv}), say, from $ind_1$ to $ind_2$.

\noindent \textbf{Argument 2} \emph{During legal executions, if $\forall i \in \Correct:\mathsf{wasDelivered}_i()=1$ holds, $index$ is incremented.~~}
%
Implied by Argument 1 and BC-validity\technicalReport{ of the consensus protocol}.

\noindent \textbf{Argument 3} \emph{During legal executions, the increment of $index$ is followed by the recycling of a single object, $obj[x]$, the same for all (correct) nodes.~~}
%
Line~\ref{ln:vbbBradcastAAA} (\Algorithm~\ref{alg:logOneRecycling}) uses the value of $index$ as the returned value from $\mathit{ssbftIndex}.getIndex()$ when calculating the set $S(ind) = \{y ~\bmod indexNum:y\in \{ indexNum + ind-logSize,\ldots, indexNum + ind\}\}$, where $ind \in \{ind_1,ind_2\}$.  
For every $x \notin S(ind)$, $obj[x].\mathsf{recycle}()$ is invoked.
Since $ind_2=ind_1+1 \bmod I$, during legal executions, there is exactly one index, $x$, that is in $S(ind_1)$ but not in $S(ind_2)$. 
\Ie $x=(indexNum + ind_1-logSize) \bmod indexNum$ and only $obj[x]$ is recycled by all (correct) nodes (BC-agreement of the SSBFT consensus).
\end{theoremProof}

\Section{Conclusion}
%
\label{sec:conclusions}
%
We have presented an SSBFT algorithm for object recycling.
%
% for the model of $\mathsf{BSMP_{n,t}[\kappa\mathit{-}SGC,t < n/3,RCCs]}$.
%
Our proposal can support an unbounded sequence of SSBFT object instances.
The\remove{ proposed solution offers optimal fault-tolerance, and the} expected stabilization time is in $\bigO(t)$ synchronous rounds.
We believe that this work is preparing the groundwork needed to construct SSBFT\reduce{ algorithms for} distributed systems, such as Blockchains\reduce{ and the Cloud}.

\emsA{When deploying an asynchronous solution, such as a consensus algorithm, in real-world systems, it is crucial to ensure the solution's correctness remains independent of any timing bounds, which are assumed to be unknown at the time in which the solution is designed and developed. However, given a specific real-world system, which has bounded computation and communication delays, the consensus algorithm can be expected to terminate and deliver results to all non-faulty nodes within a known bounded time, which we refer to as $logSize$ (Assumption~\ref{def:logSize}). This time corresponds to the duration in which it is required to log consensus objects until their results reach all non-faulty nodes. It is important to note that synchrony assumptions are imperative for any deterministic solution to the studied problem since it is equivalent to consensus. This is because the problem entails deciding both the termination of an asynchronous consensus object and whether the agreed-upon value was received by all non-faulty nodes.}    
    
\ems{As a potential avenue for future research, one could explore deterministic recycling mechanisms, say by utilizing the Dolev and Welch approach to SSBFT clock synchronization~\cite{DBLP:journals/jacm/DolevW04}, to design an SSBFT SIG-index. However, their solution has exponential stabilization time, making it unfeasible in practice.}

\subsection*{Acknowledgments}
We express our gratitude to anonymous reviewers for their valuable comments.
The work of E. M. Schiller was partially supported by VINNOVA, the Swedish Governmental Agency
for Innovation Systems through the CyReV project under Grant 2019-03071.
%\bibliographystyle{abbrv}
%\bibliography{referances}	
%\end{document}

\begin{thebibliography}{10}
	
	\bibitem{DBLP:conf/stoc/AbrahamD15}
	I.~Abraham and D.~Dolev.
	\newblock {Byzantine} agreement with optimal early stopping, optimal resilience
	and polynomial complexity.
	\newblock In {\em {STOC}}, pages 605--614. {ACM}, 2015.
	
	\bibitem{DBLP:conf/wdag/AfekKY90}
	Y.~Afek, S.~Kutten, and M.~Yung.
	\newblock Memory-efficient self stabilizing protocols for general networks.
	\newblock In {\em {WDAG}}, volume 486 of {\em Lecture Notes in Computer
		Science}, pages 15--28. Springer, 1990.
	
	\bibitem{DBLP:journals/jcss/AlonADDPT15}
	N.~Alon, H.~Attiya, S.~Dolev, S.~Dubois, M.~Potop{-}Butucaru, and S.~Tixeuil.
	\newblock Practically stabilizing {SWMR} atomic memory in message-passing
	systems.
	\newblock {\em J. Comput. Syst. Sci.}, 81(4):692--701, 2015.
	
	\bibitem{DBLP:series/synthesis/2019Altisen}
	K.~Altisen, S.~Devismes, S.~Dubois, and F.~Petit.
	\newblock {\em Introduction to Distributed Self-Stabilizing Algorithms}.
	\newblock Synthesis Lectures on Distributed Computing Theory. Morgan {\&}
	Claypool Publishers, 2019.
	
	\bibitem{DBLP:conf/wdag/AwerbuchPVD94}
	B.~Awerbuch, B.~Patt{-}Shamir, G.~Varghese, and S.~Dolev.
	\newblock Self-stabilization by local checking and global reset (extended
	abstract).
	\newblock In {\em {WDAG}}, volume 857 of {\em Lecture Notes in Computer
		Science}, pages 326--339. Springer, 1994.
	
	\bibitem{DBLP:conf/podc/Ben-Or83}
	M.~Ben{-}Or.
	\newblock Another advantage of free choice: Completely asynchronous agreement
	protocols (extended abstract).
	\newblock In {\em Proceedings of the Second Annual {ACM} {SIGACT-SIGOPS}
		Symposium on Principles of Distributed Computing}, pages 27--30, 1983.
	
	\bibitem{DBLP:conf/podc/Ben-OrDH08}
	M.~Ben{-}Or, D.~Dolev, and E.~N. Hoch.
	\newblock Fast self-stabilizing {Byzantine} tolerant digital clock
	synchronization.
	\newblock In {\em Proceedings of the Twenty-Seventh Annual {ACM} Symposium on
		Principles of Distributed Computing, {PODC} 2008, Toronto, Canada, August
		18-21, 2008}, pages 385--394. {ACM}, 2008.
	
	\bibitem{DBLP:conf/sss/BinunCDKLPYY16}
	A.~Binun, T.~Coupaye, S.~Dolev, M.~Kassi{-}Lahlou, M.~Lacoste, A.~Palesandro,
	R.~Yagel, and L.~Yankulin.
	\newblock Self-stabilizing {Byzantine}-tolerant distributed replicated state
	machine.
	\newblock In {\em Stabilization, Safety, and Security of Distributed Systems -
		18th International Symposium, {SSS}}, pages 36--53, 2016.
	
	\bibitem{DBLP:conf/podc/BonomiDPR15}
	S.~Bonomi, S.~Dolev, M.~Potop{-}Butucaru, and M.~Raynal.
	\newblock Stabilizing server-based storage in {Byzantine} asynchronous
	message-passing systems: Extended abstract.
	\newblock In {\em Proceedings of the 2015 {ACM} Symposium on Principles of
		Distributed Computing, {PODC}}, pages 471--479, 2015.
	
	\bibitem{DBLP:conf/ipps/BonomiPT15}
	S.~Bonomi, M.~Potop{-}Butucaru, and S.~Tixeuil.
	\newblock Stabilizing {Byzantine}-fault tolerant storage.
	\newblock In {\em 2015 {IEEE} International Parallel and Distributed Processing
		Symposium, {IPDPS}}, pages 894--903, 2015.
	
	\bibitem{DBLP:conf/sss/BonomiPPT18}
	S.~Bonomi, A.~D. Pozzo, M.~Potop{-}Butucaru, and S.~Tixeuil.
	\newblock Brief announcement: Optimal self-stabilizing mobile
	{Byzantine}-tolerant regular register with bounded timestamps.
	\newblock In {\em Stabilization, Safety, and Security of Distributed Systems -
		20th International Symposium, {SSS}}, pages 398--403, 2018.
	
	\bibitem{DBLP:journals/tcs/BonomiPPT19}
	S.~Bonomi, A.~D. Pozzo, M.~Potop{-}Butucaru, and S.~Tixeuil.
	\newblock Approximate agreement under mobile {Byzantine} faults.
	\newblock {\em Theor. Comput. Sci.}, 758:17--29, 2019.
	
	\bibitem{DBLP:conf/podc/BrachaT83}
	G.~Bracha and S.~Toueg.
	\newblock Resilient consensus protocols.
	\newblock In {\em {PODC}}, pages 12--26. {ACM}, 1983.
	
	\bibitem{DBLP:journals/cacm/Dijkstra74}
	E.~W. Dijkstra.
	\newblock Self-stabilizing systems in spite of distributed control.
	\newblock {\em Commun. {ACM}}, 17(11):643--644, 1974.
	
	\bibitem{DBLP:books/mit/Dolev2000}
	S.~Dolev.
	\newblock {\em Self-Stabilization}.
	\newblock {MIT} Press, 2000.
	
	\bibitem{DBLP:journals/jcss/DolevGMS18}
	S.~Dolev, C.~Georgiou, I.~Marcoullis, and E.~M. Schiller.
	\newblock Practically-self-stabilizing virtual synchrony.
	\newblock {\em J. Comput. Syst. Sci.}, 96:50--73, 2018.
	
	\bibitem{DBLP:conf/cscml/DolevGMS18}
	S.~Dolev, C.~Georgiou, I.~Marcoullis, and E.~M. Schiller.
	\newblock Self-stabilizing {Byzantine} tolerant replicated state machine based
	on failure detectors.
	\newblock In {\em Cyber Security Cryptography and Machine Learning - Second
		International Symposium, {CSCML}}, pages 84--100, 2018.
	
	\bibitem{DBLP:conf/netys/DolevLS13}
	S.~Dolev, O.~Liba, and E.~M. Schiller.
	\newblock Self-stabilizing {Byzantine} resilient topology discovery and message
	delivery.
	\newblock In {\em Networked Systems - First International Conference, {NETYS}},
	pages 42--57, 2013.
	
	\bibitem{DBLP:conf/podc/DolevPS15}
	S.~Dolev, T.~Petig, and E.~M. Schiller.
	\newblock Brief announcement: Robust and private distributed shared atomic
	memory in message passing networks.
	\newblock In {\em Proceedings of the 2015 {ACM} Symposium on Principles of
		Distributed Computing, {PODC}}, pages 311--313, 2015.
	
	\bibitem{DBLP:journals/corr/abs-1806-03498}
	S.~Dolev, T.~Petig, and E.~M. Schiller.
	\newblock Self-stabilizing and private distributed shared atomic memory in
	seldomly fair message passing networks.
	\newblock {\em CoRR}, abs/1806.03498, 2018.
	\newblock Also to appear in Springer's Algorithmica.
	
	\bibitem{DBLP:journals/algorithmica/DolevPS23}
	S.~Dolev, T.~Petig, and E.~M. Schiller.
	\newblock Self-stabilizing and private distributed shared atomic memory in
	seldomly fair message passing networks.
	\newblock {\em Algorithmica}, 85(1):216--276, 2023.
	
	\bibitem{DBLP:conf/podc/DolevW95}
	S.~Dolev and J.~L. Welch.
	\newblock Self-stabilizing clock synchronization in the presence of {Byzantine}
	faults (abstract).
	\newblock In {\em Proceedings of the Fourteenth Annual {ACM} Symposium on
		Principles of Distributed Computing}, page 256, 1995.
	
	\bibitem{DBLP:journals/jacm/DolevW04}
	S.~Dolev and J.~L. Welch.
	\newblock Self-stabilizing clock synchronization in the presence of {Byzantine}
	faults.
	\newblock {\em J. {ACM}}, 51(5):780--799, 2004.
	
	\bibitem{DBLP:journals/jpdc/DuboisPNT12}
	S.~Dubois, M.~Potop{-}Butucaru, M.~Nesterenko, and S.~Tixeuil.
	\newblock Self-stabilizing {Byzantine} asynchronous unison.
	\newblock {\em J. Parallel Distributed Comput.}, 72(7):917--923, 2012.
	
	\bibitem{DBLP:conf/sss/DuvignauRS22}
	R.~Duvignau, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing {Byzantine} fault-tolerant repeated reliable
	broadcast.
	\newblock In {\em {SSS}}, volume 13751 of {\em Lecture Notes in Computer
		Science}, pages 206--221. Springer, 2022.
	
	\bibitem{DBLP:conf/sss/0001GS19}
	M.~Feldmann, T.~G{\"{o}}tte, and C.~Scheideler.
	\newblock A loosely self-stabilizing protocol for randomized congestion control
	with logarithmic memory.
	\newblock In {\em Stabilization, Safety, and Security of Distributed Systems -
		21st International Symposium, {SSS}}, volume 11914 of {\em Lecture Notes in
		Computer Science}, pages 149--164. Springer, 2019.
	
	\bibitem{DBLP:journals/ipl/FischerL82}
	M.~J. Fischer and N.~A. Lynch.
	\newblock A lower bound for the time to assure interactive consistency.
	\newblock {\em Inf. Process. Lett.}, 14(4):183--186, 1982.
	
	\bibitem{DBLP:journals/jacm/FischerLP85}
	M.~J. Fischer, N.~A. Lynch, and M.~Paterson.
	\newblock Impossibility of distributed consensus with one faulty process.
	\newblock {\em J. {ACM}}, 32(2):374--382, 1985.
	
	\bibitem{DBLP:conf/netys/GeorgiouGLS19}
	C.~Georgiou, R.~Gustafsson, A.~Lindh{\'{e}}, and E.~M. Schiller.
	\newblock Self-stabilization overhead: {A} case study on coded atomic storage.
	\newblock In {\em {NETYS}}, volume 11704 of {\em Lecture Notes in Computer
		Science}, pages 131--147. Springer, 2019.
	
	\bibitem{DBLP:conf/podc/GeorgiouLS19}
	C.~Georgiou, O.~Lundstr{\"{o}}m, and E.~M. Schiller.
	\newblock Self-stabilizing snapshot objects for asynchronous failure-prone
	networked systems.
	\newblock In P.~Robinson and F.~Ellen, editors, {\em Proceedings of the 2019
		{ACM} Symposium on Principles of Distributed Computing, {PODC} 2019, Toronto,
		ON, Canada, July 29 - August 2, 2019.}, pages 209--211. {ACM}, 2019.
	
	\bibitem{DBLP:conf/netys/GeorgiouLS19}
	C.~Georgiou, O.~Lundstr{\"{o}}m, and E.~M. Schiller.
	\newblock Self-stabilizing snapshot objects for asynchronous failure-prone
	networked systems.
	\newblock In {\em Networked Systems - 7th International Conference, {NETYS}
		2019, Marrakech, Morocco, June 19-21, 2019, Revised Selected Papers}, pages
	113--130, 2019.
	
	\bibitem{DBLP:conf/netys/GeorgiouMRS21}
	C.~Georgiou, I.~Marcoullis, M.~Raynal, and E.~M. Schiller.
	\newblock Loosely-self-stabilizing {Byzantine}-tolerant binary consensus for
	signature-free message-passing systems.
	\newblock In {\em {NETYS}}, volume 12754 of {\em Lecture Notes in Computer
		Science}, pages 36--53. Springer, 2021.
	
	\bibitem{TR}
	C.~Georgiou, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing byzantine-tolerant recycling.
	\newblock {\em To appear in SSS}, 2023.
	
	\bibitem{DBLP:conf/sirocco/Izumi15}
	T.~Izumi.
	\newblock On space and time complexity of loosely-stabilizing leader election.
	\newblock In C.~Scheideler, editor, {\em Structural Information and
		Communication Complexity - 22nd International Colloquium, {SIROCCO}}, volume
	9439 of {\em Lecture Notes in Computer Science}, pages 299--312. Springer,
	2015.
	
	\bibitem{DBLP:conf/podc/KatzP90}
	S.~Katz and K.~J. Perry.
	\newblock Self-stabilizing extensions for message-passing systems.
	\newblock In {\em {PODC}}, pages 91--101. {ACM}, 1990.
	
	\bibitem{DBLP:conf/podc/KowalskiM13}
	D.~R. Kowalski and A.~Most{\'{e}}faoui.
	\newblock Synchronous {Byzantine} agreement with nearly a cubic number of
	communication bits: synchronous byzantine agreement with nearly a cubic
	number of communication bits.
	\newblock In {\em {PODC}}, pages 84--91. {ACM}, 2013.
	
	\bibitem{DBLP:journals/toplas/LamportSP82}
	L.~Lamport, R.~E. Shostak, and M.~C. Pease.
	\newblock The {Byzantine} generals problem.
	\newblock {\em {ACM} Trans. Program. Lang. Syst.}, 4(3):382--401, 1982.
	
	\bibitem{DBLP:journals/jacm/LenzenR19}
	C.~Lenzen and J.~Rybicki.
	\newblock Self-stabilising {Byzantine} clock synchronisation is almost as easy
	as consensus.
	\newblock {\em J. {ACM}}, 66(5):32:1--32:56, 2019.
	
	\bibitem{DBLP:conf/icdcs/LundstromRS20}
	O.~Lundstr{\"{o}}m, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing set-constrained delivery broadcast (extended
	abstract).
	\newblock In {\em 40th {IEEE} International Conference on Distributed Computing
		Systems, {ICDCS}}, pages 617--627, 2020.
	
	\bibitem{DBLP:conf/netys/LundstromRS20}
	O.~Lundstr{\"{o}}m, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing uniform reliable broadcast.
	\newblock In {\em Networked Systems - 8th International Conference, {NETYS}},
	pages 296--313, 2020.
	
	\bibitem{DBLP:conf/icdcn/LundstromRS21}
	O.~Lundstr{\"{o}}m, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing indulgent zero-degrading binary consensus.
	\newblock In {\em {ICDCN} '21: International Conference on Distributed
		Computing and Networking}, pages 106--115, 2021.
	
	\bibitem{DBLP:conf/edcc/LundstromRS21}
	O.~Lundstr{\"{o}}m, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing multivalued consensus in asynchronous crash-prone
	systems.
	\newblock In {\em {EDCC}}, pages 111--118. {IEEE}, 2021.
	
	\bibitem{DBLP:journals/corr/abs-2104-03129}
	O.~Lundstr{\"{o}}m, M.~Raynal, and E.~M. Schiller.
	\newblock Self-stabilizing multivalued consensus in asynchronous crash-prone
	systems.
	\newblock {\em CoRR}, abs/2104.03129, 2021.
	
	\bibitem{DBLP:conf/sss/LundstromRS22}
	O.~Lundstr{\"{o}}m, M.~Raynal, and E.~M. Schiller.
	\newblock Brief announcement: Self-stabilizing total-order broadcast.
	\newblock In {\em {SSS}}, volume 13751 of {\em Lecture Notes in Computer
		Science}, pages 358--363. Springer, 2022.
	
	\bibitem{DBLP:conf/opodis/Maurer20}
	A.~Maurer.
	\newblock Self-stabilizing {Byzantine}-resilient communication in dynamic
	networks.
	\newblock In {\em {OPODIS}}, volume 184 of {\em LIPIcs}, pages 27:1--27:11.
	Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik, 2020.
	
	\bibitem{DBLP:conf/podc/MostefaouiMR14}
	A.~Most{\'{e}}faoui, H.~Moumen, and M.~Raynal.
	\newblock Signature-free asynchronous {Byzantine} consensus with t{\textless}
	n/3, {O}(n\({}^{\mbox{2}}\)) messages.
	\newblock In {\em {ACM} Symposium on Principles of Distributed Computing,
		{PODC}}, pages 2--9, 2014.
	
	\bibitem{DBLP:conf/opodis/OliveiraMB16}
	T.~Oliveira, R.~Mendes, and A.~N. Bessani.
	\newblock Exploring key-value stores in multi-writer {Byzantine}-resilient
	register emulations.
	\newblock In {\em {OPODIS}}, volume~70 of {\em LIPIcs}, pages 30:1--30:17.
	Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik, 2016.
	
	\bibitem{DBLP:journals/jacm/PeaseSL80}
	M.~C. Pease, R.~E. Shostak, and L.~Lamport.
	\newblock Reaching agreement in the presence of faults.
	\newblock {\em J. {ACM}}, 27(2):228--234, 1980.
	
	\bibitem{DBLP:conf/iwmm/PlainfosseS95}
	D.~Plainfoss{\'{e}} and M.~Shapiro.
	\newblock A survey of distributed garbage collection techniques.
	\newblock In {\em {IWMM}}, volume 986 of {\em Lecture Notes in Computer
		Science}, pages 211--249. Springer, 1995.
	
	\bibitem{DBLP:conf/focs/Rabin83}
	M.~O. Rabin.
	\newblock Randomized {Byzantine} generals.
	\newblock In {\em 24th Annual Symposium on Foundations of Computer Science},
	pages 403--409, 1983.
	
	\bibitem{DBLP:books/sp/Raynal18}
	M.~Raynal.
	\newblock {\em Fault-Tolerant Message-Passing Distributed Systems - An
		Algorithmic Approach}.
	\newblock Springer, 2018.
	
	\bibitem{DBLP:conf/netys/SalemS18}
	I.~Salem and E.~M. Schiller.
	\newblock Practically-self-stabilizing vector clocks in the absence of
	execution fairness.
	\newblock In {\em Networked Systems - 6th International Conference, {NETYS}},
	pages 318--333, 2018.
	
	\bibitem{DBLP:journals/tcs/SudoNYOKM12}
	Y.~Sudo, J.~Nakamura, Y.~Yamauchi, F.~Ooshita, H.~Kakugawa, and T.~Masuzawa.
	\newblock Loosely-stabilizing leader election in a population protocol model.
	\newblock {\em Theor. Comput. Sci.}, 444:100--112, 2012.
	
	\bibitem{DBLP:journals/ieicet/SudoOKM20}
	Y.~Sudo, F.~Ooshita, H.~Kakugawa, and T.~Masuzawa.
	\newblock Loosely stabilizing leader election on arbitrary graphs in population
	protocols without identifiers or random numbers.
	\newblock {\em {IEICE} Trans. Inf. Syst.}, 103-D(3):489--499, 2020.
	
	\bibitem{DBLP:journals/tpds/SudoOKMDL19}
	Y.~Sudo, F.~Ooshita, H.~Kakugawa, T.~Masuzawa, A.~K. Datta, and L.~L. Larmore.
	\newblock Loosely-stabilizing leader election for arbitrary graphs in
	population protocol model.
	\newblock {\em {IEEE} Trans. Parallel Distributed Syst.}, 30(6):1359--1373,
	2019.
	
	\bibitem{DBLP:journals/tcs/SudoOKMDL20}
	Y.~Sudo, F.~Ooshita, H.~Kakugawa, T.~Masuzawa, A.~K. Datta, and L.~L. Larmore.
	\newblock Loosely-stabilizing leader election with polylogarithmic convergence
	time.
	\newblock {\em Theor. Comput. Sci.}, 806:617--631, 2020.
	
	\bibitem{DBLP:conf/podc/Toueg84}
	S.~Toueg.
	\newblock Randomized {Byzantine} agreements.
	\newblock In T.~Kameda, J.~Misra, J.~G. Peters, and N.~Santoro, editors, {\em
		Proceedings of the Third Annual {ACM} Symposium on Principles of Distributed
		Computing}, pages 163--178. {ACM}, 1984.
	
	\bibitem{DBLP:conf/ipps/VeigaF05}
	L.~Veiga and P.~Ferreira.
	\newblock Asynchronous complete distributed garbage collection.
	\newblock In {\em {IPDPS}}. {IEEE} Computer Society, 2005.
	
\end{thebibliography}

\end{document}
\extendedAbstract{\noindent\ems{\underline{Glossary:}
\textbf{BC} Byzantine-tolerant Consensus;
\textbf{BDH} Ben{-}Or, Dolev, and Hoch~\cite{DBLP:conf/podc/Ben-OrDH08};
\textbf{BFT}   non-self-stabilizing Byzantine fault-tolerant solutions;
\textbf{COR} Consensus Object Recycling (Definition~\ref{def:probDef});
\textbf{DPS} Dolev, Petig, and Schiller~\cite{DBLP:journals/algorithmica/DolevPS23}; 
\textbf{MMR} Mostéfaoui, Moumen, and Raynal~\cite{DBLP:conf/podc/MostefaouiMR14};
\textbf{RCCs}  random common coins;
\textbf{SSBFT}    self-stabilizing Byzantine fault-tolerant;
$\mathbf{\kappa\mathit{-}SGC}$  $\kappa$-state global clock.}}



%\renewcommand{\thmcnt}{\ref{thm:algorithmMVC}}
%\begin{theoremProof}
%Let $R$ be an execution of \Algorithm~\ref{alg:ssbftMVC}. Within $\kappa$ synchronous rounds, the system reaches a state $c \in R$ in which $clock(\kappa)=0$ holds. Immediately after $c$, every correct node, $p_i$, simultaneously restarts $co_i$ and proposes the input (lines~\ref{ln:coRestart} and~\ref{ln:coPrupuse}) before sending the needed messages (line~\ref{ln:sendMjToAllIDo}). Then, for the $t$ synchronous rounds that follows, all correct nodes simultaneously process the arriving messages and send their replies (line~\ref{ln:processIf} and~\ref{ln:sendMjToAllIDo}). Thus, after $\max\{ \kappa,2(t+1)\}$ synchronous rounds from $c$, the system reaches a state $c'\in R$ in which $clock(\kappa)=0$ holds. Also, in the following synchronous round, all correct nodes store $co$'s results. That results in guaranteed to be correct due to Definition~\ref{sec:assumptionsMVC}'s assumptions.  	   
%\end{theoremProof}

\end{document}

\endinput
%%
%% End of file `elsarticle-template-num-names.tex'.

SUBMISSION: 6231
TITLE: Self-stabilizing Byzantine-tolerant Recycling


----------------------- REVIEW 1 ---------------------
SUBMISSION: 6231
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: -1 (weak reject)
----- TEXT:
This paper presents a protocol to recycle Consensus objects in a synchronous self-stabilizing Byzantine-prone distributed systems. The motivation relies on the fact that the memory of each process is bounded and that distributed applications rarely execute single consensus. The proposed algorithm is randomized and relies on random common coins. It tolerate up to t<n/3 Byzantine processes and its expected stabilization is in O(t) rounds.

The problem is of interest for the SSS community. Nevertheless, I am not in favor of acceptance of this paper. Indeed, the paper is very hard to follow. I am not sure to understood the main specification of COR, I find the presentation very drafty, I was not able to clearly understand what is new, what is already existing and what the paper really brings. Subalgorithms of Figure 1 have no specification, so it is difficult to grasp what subproblems they solve. I do not understand the motivation to choose an hybrid system that greatly improve the complexity of the paper without bringing any particular insight in my opinion. Technically, the paper does not seem to bring new approaches or new technical tools.

For these reasons, I recommend the authors to carefully rework the presentation of their paper and to try to simplify the context. In particular, I think that specifications of considered problems has to be clarified and motivated.



----------------------- REVIEW 2 ---------------------
SUBMISSION: 6231
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 1 (weak accept)
----- TEXT:
The paper studies a self-stabilizing recycling of consensus objects, in which successive instances of Byzantine consensus must be realized. Its claimed originality is a more robust synchronous solution than the previous solutions to the problem. The solution is randomized.

The proposed algorithm is a composition of existing building blocks with an original block. It gives a solid background for an implementation. The blocks deal with a recycling mechanism, clock synchronization and an original multi-valued consensus. The solution recovers after the last transient fault within expected O(K) rounds, where K depends on the specific synchrony assumptions and on the number of faulty processes.

Comments to authors:
The model is informal in many aspects. Thus, instead of using the constrained space for precise definitions, the paper describes a context that could be interesting in a practical approach, but which is not relevant from the purely algorithmic point of view. As a consequence, the complete proofs and the original algorithm are not presented in the paper (but in the appendix) and thus not destined to appear in the published paper, which diminishes considerably its pertinence.
In particular, the Byzantine fault model is not enough precise and confusing. It considers an adversary able to ''capture'' some processes, but at the same time it is said that ''the adversary completely controls the messages that the algorithm sends''. 
It is also said informally that a captured process cannot impersonate a correct one. But, in the state of the art part, the possible corruption of private keys is mentioned, without more explanations, and that seems contradictory. 

Technically, the notion used in the paper is pseudo-stabilization, since the definition of self-stabilization uses legitimate configurations. Pseudo-stabilization is strictly weaker than self-stabilization. This is not what is used in the seminal paper of Dijkstra. The authors should explain why they made this choice, since from a practical point of view self-stabilization is easier to be observed by an external (correct) observer. Also the claims: “The occurrence of an arbitrary transient fault is rare. Thus, our model assumes that the last arbitrary transient fault occurs before the system execution starts [10]” sound strange, like if not a pure self-stabilization is considered, because a self-stabilizing algorithm recovers after any number of transient faults and which can arrive at any  moment in the execution. This is confusing. 
The model indeed seems to assume that there is a single transient failure at the start of an execution. That comes to consider that the initial configuration is arbitrary. Then, when the second instance of recycling starts, no failure ever happens. Thus in fact the problem seems only to stabilize the first iteration. The authors should make this point clear.

The state of the art is difficult to read, due to an accumulation of acronyms (18 in the last 10 lines).

More generally, an informal and intuitive explanation of how the solution works is lacking and should be added. For instance, Figure 1 is interesting, but not sufficiently commented.

The paper should also justify, component by component, the necessity of the assumptions it makes (synchrony, randomization, both).

Summary:
The paper presents a combination of building blocks for obtaining an original stabilizing algorithm. The construction is interesting in itself and is a good start for an implementation. However the paper in its actual state has to be revised. I would advise the authors to drop some generalities and to focus on the algorithmic part, to include the missing algorithm, the more complete proofs and an informal description of each of the modules and of their interactions.



----------------------- REVIEW 3 ---------------------
SUBMISSION: 6231
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 2 (accept)
----- TEXT:
This paper is about the consensus problem, where all distributed processes should agree on a single value. The authors present a technique for reusing consensus objects, i.e., it enables an unbounded number of repeated invocations on a bounded number of consensus objects.

The presented technique handles the situation where some of the processes are byzantine (however, they cannot impersonate non-faulty processes). Moreover, the recycling mechanism is self-stabilizing.

In particular, the authors take an existing self-stabilizing fault-tolerant consensus algorithm, and give a recyclable variation of it. In their solution, they use randomness and some synchrony assumptions.

This work considers an interesting problem in the field of distributed systems, and the suggested solution seems practical.

Minor comments:
- Page 5, last paragraph: "soultion" --> solution

- Page 10, 1st paragraph: It seems like an explanation about Algorithm 2, but it refers to some parts of Algorithm 1 (line 5, line 6). I suggest to give more details in this explanation. 

- Page 14, Proof of Theorem 3, 1st paragraph: "hold are implied by" - Rephrase.



----------------------- REVIEW 4 ---------------------
SUBMISSION: 6231
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 0 (borderline paper)
----- TEXT:
In this paper, the authors study the problem of recycling asynchronous consensus objects when they completed their task and delivered their decision to non-faulty processes in a distributed system. The algorithm consists of (i) a client algorithm that uses consensus objects and the recycling mechanism for the objects and (ii) a recycling mechanism that recycles used consensus objects. 

The client algorithm reports the delivery of the result of the consensus using the return value of the interface function wasDelivered(). Also, the algorithm recycles the objects when the recycle mechanism invokes the function recycle(). Using the functions, the consensus object recycling (COR) problem is defined roughly as follows.

(1) COR-client-eventual-agreement: If a non-faulty process p_i set to wasDelivered_i() = True, then all non-faulty processes report delivery eventually.
(2)COR-servie-validity-1: If a non-faulty process p_j invokes recycle_j(), then at least one non-faulty process p_i reported delivery.
(3)COR-servie-validity-2: If all non-faulty processes report delivery, then at least one non-faulty process p_j eventually invokes recycle_j().
(4)COR-servie-agreement: If a non-faulty process invokes recycle(), then all non-faulty processes p_i invokes recycle_i().

For the client algorithm and recycle mechanism, the paper adopts the hybrid synchronous and asynchronous approaches. In the client algorithm, the system is assumed to be asynchronous, and for the recycling mechanism, the synchronous system is assumed.  In more detail, for the client algorithm, the model BAMP_{n,t}[FC, t < n/3, RCCs] is used. The model assumes asynchronous and fair communication of message passing, the number of faulty processes is at most n/3, and random common coins. For the recycling mechanism, the model BSMP_{n,t}[¥kappa-SGC, t<n/3, RCCs] is assumed. The model assumes ¥kappa-state global clock, reliable communication, and an RCC service.

As the contribution, the authors propose a self-stabilizing Byzantine fault-tolerant recycling mechanism, which recovers after the occurrence of the last transient fault within expected O(¥kappa) synchronous rounds, where ¥kappa = O(t) (the upper bound on the number of Byzantine processes).

For the recycling mechanism, the paper proposes three components. I can find detailed descriptions of the first two components, namely the main algorithm for the recycling mechanism and the second algorithm called SSBFT SIG-index in the model. However, for the third algorithm, I only find some abstract descriptions. Due to the lack of detailed descriptions of the algorithm and its guarantees, it is hard for me to understand how the whole algorithm works.  Also, since the third algorithm (SSBFT multivalued consensus) is a building block of the algorithm SIG-index, the correctness proof of the second algorithm should use some guarantee of the third algorithm in the correctness proof. Instead of detailed proofs, adding a little more explanation of the SSBFT multivalued consensus algorithm in the extended abstract might help the reader's understanding.



----------------------- REVIEW 5 ---------------------
SUBMISSION: 6231
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: -1 (weak reject)
----- TEXT:
These are the comments from the track chairs. We found this paper to be very interesting. However, we also noted that some parts lack formality and clarity, preventing us from verifying the correctness of your claims. Therefore, we suggest you resubmit the revised version of this paper for the second round of SSS 2023. We hope the reviewers' comments will help you improve the paper and that you will consider our recommendation.



----------------------------------  2nd round of revision -------------

SUBMISSION: 4610
TITLE: Self-stabilizing Byzantine-tolerant Recycling


----------------------- REVIEW 1 ---------------------
SUBMISSION: 4610
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 1 (weak accept)
----- TEXT:
The paper studies the recycling of consensus objects, in which successive instances of consensus must be realized. Its originality is a more robust synchronous solution than the previous solutions to the problem, since the self-stabilization property is added. The solution is synchronous and randomized.
The proposed solution is a composition of existing building blocks with an original block. It gives a solid background for an implementation. The blocks concern a recycling mechanism, a clock synchronization and an original multi-valued consensus. The solution recovers after a transient fault within expected O(K) rounds, where K depends on the specific synchrony assumptions and on the number of faulty processes.
I had many criticisms on the original version of the paper, but the authors made a considerable effort to answer them, point by point. 
The paper still does not establish the necessity of the assumptions made, it just indicates now their usefulness. Also, references to impossibility results would be a nice addition.
However the revised version of the paper is much better structured. The problem is clearly defined and the chain of the modules forming the solution is correctly described.
In my opinion, the actual paper fulfills expected requirements of clarity and readability and its publication in the proceedings of SSS can be considered.


Specific:

p. 13: stabilizing time instead of stabilizes time



----------------------- REVIEW 2 ---------------------
SUBMISSION: 4610
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 0 (borderline paper)
----- TEXT:
This paper is about the consensus problem, where all distributed processes should agree on a single value. The authors present a technique for reusing consensus objects, i.e., it enables an unbounded number of repeated invocations on a bounded number of consensus objects.

The presented technique handles the situation where some of the processes are byzantine (however, they cannot impersonate non-faulty processes). Moreover, the recycling mechanism is self-stabilizing.

In particular, the authors take an existing self-stabilizing fault-tolerant consensus algorithm, and give a recyclable variation of it. In their solutions, they use randomness and some synchrony assumptions.

This work considers an interesting problem in the field of distributed systems, and the suggested solution seems practical.
In the revised version the authors added some important details and explanations that make it easier to follow.
However, the proofs are not formal enough so I could not completely verify the correctness of the suggested solution.



----------------------- REVIEW 3 ---------------------
SUBMISSION: 4610
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 1 (weak accept)
----- TEXT:
The contribution of this paper is to take an existing asynchronous Byzantine-tolerant consensus algorithm and add a number of mechanisms that allow processes to recycle the memory used by the consensus algorithm's state once the results have been received by all of the correct nodes in the system. It does this utilizing a new algorithm referred to as "simultaneous increment-or-get index" that stands between the consensus algorithm and the recycling mechanism. All of this is done in a loosely self-stabilizing setting ("loosely" because the underlying consensus algorithm only self-stabilizes with high probability) in which arbitrary transient faults can be recovered from.

This paper requires a very high degree of familiarity with its subject matter. The underlying consensus algorithm (referred to as GMRS) that the recycling mechanism is built on is never explained in full; only partial pseudocode is presented for it, with omitted segments intermixed with this paper's new additions. This reviewer mostly has experience with non-self-stabilizing, semi-synchronous consensus algorithms, but it is hard to see how even a specialist in this field could understand this paper as a standalone work. The explanations of even simple relevant concepts like random common coins are strictly formal and not intuitive. Also, the "loosely" self-stabilizing nature of the original algorithm is never acknowledged by this paper; the term "self-stabilizing" is presented without qualifiers, which seems potentially misleading.

EMS: Clarified. 

However, this paper found a meaningful problem regarding consensus in its chosen setting and solved it using an in-depth spelled-out algorithm with proofs of its correctness. This seems to me to be a worthwhile contribution to the field.



----------------------- REVIEW 4 ---------------------
SUBMISSION: 4610
TITLE: Self-stabilizing Byzantine-tolerant Recycling
AUTHORS: Chryssis Georgiou, Michel Raynal and Elad Michael Schiller

----------- Overall evaluation -----------
SCORE: 1 (weak accept)
----- TEXT:
In this paper, the authors examine the problem of recycling asynchronous consensus objects after they have reached a consensus and delivered their decision to non-faulty processes. The proposed algorithm comprises two main components:(i) A client algorithm that utilizes consensus objects and the recycling mechanism for these objects. (ii) A recycling mechanism responsible for efficiently reusing consensus objects that have been utilized before.

The proposed recycling mechanism consists of three sub-algorithms as follows. (1)The main part that handles if an object can be recycled. (2) The SIG-index that controls the index of the array of consensus objects globally. (3) SSBFT synchronous multivalued consensus that monitors the global completions of each execution of the client consensus algorithm. Especially the algorithm SIG-index is the original and key algorithm to achieve the recycling of asynchronous consensus objects.

The presentation of the paper has shown improvement compared to the previously submitted version. However, there is still an area of concern regarding the clarity of Assumption 1 on page 9. My understanding is that Assumption 1 states that if at least t + 1 correct nodes have wasDelivered() = True at synchronous round r, then all n - t correct nodes will also have wasDelivered() = True at synchronous round r + logSize. Regarding the model assumed for Algorithm 1 (the client algorithm), it may not be entirely asynchronous since in a fully asynchronous setting, the delay range of any message is unbounded. However, it is possible that the assumption is practical and reasonable. Nonetheless, to ensure a clear understanding of the model for Algorithm 1, some clarification of this assumption is necessary.

EMS: Tried to clarify that the mechanism constraints all synchrony assumptions. 

Minor comments:

- Some terminologies such as \script{P} and \emph{Correct} are used before explaining their definitions. 

EMS: Fixed.

-In Assumption 1 on page 9, A bounded time result retrial -> A bounded time result retrieval?

EMS: Fixed.

-Is there any difference between the symbols t and f? For example, in the last sentence of page 12, is it more appropriate to use n - t instead of n - f?

EMS: Fixed.

