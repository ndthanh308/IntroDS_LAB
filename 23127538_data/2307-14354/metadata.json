{
  "title": "Learned Gridification for Efficient Point Cloud Processing",
  "authors": [
    "Putri A. van der Linden",
    "David W. Romero",
    "Erik J. Bekkers"
  ],
  "submission_date": "2023-07-22T19:40:00+00:00",
  "revised_dates": [],
  "abstract": "Neural operations that rely on neighborhood information are much more expensive when deployed on point clouds than on grid data due to the irregular distances between points in a point cloud. In a grid, on the other hand, we can compute the kernel only once and reuse it for all query positions. As a result, operations that rely on neighborhood information scale much worse for point clouds than for grid data, specially for large inputs and large neighborhoods.\n  In this work, we address the scalability issue of point cloud methods by tackling its root cause: the irregularity of the data. We propose learnable gridification as the first step in a point cloud processing pipeline to transform the point cloud into a compact, regular grid. Thanks to gridification, subsequent layers can use operations defined on regular grids, e.g., Conv3D, which scale much better than native point cloud methods. We then extend gridification to point cloud to point cloud tasks, e.g., segmentation, by adding a learnable de-gridification step at the end of the point cloud processing pipeline to map the compact, regular grid back to its original point cloud form. Through theoretical and empirical analysis, we show that gridified networks scale better in terms of memory and time than networks directly applied on raw point cloud data, while being able to achieve competitive results. Our code is publicly available at https://github.com/computri/gridifier.",
  "categories": [
    "cs.CV",
    "cs.LG"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14354",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 10229682,
  "size_after_bytes": 199300
}