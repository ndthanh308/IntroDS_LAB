\section{Approximate Damped Sinkhorn Scheme}
\label{sec:approximate-damped-sinkhorn}

In this section, we extend the analysis of Algorithm~\ref{alg:exact} to an
approximate version of the algorithm. Then, in
Section~\ref{sec:inexact-oracle-implementation}, we describe how inexact
updates may be implemented via approximate random sampling, thus enabling
the computation of $(\lambda,\tau)$-barycenters in the free-support setting
with convergence guarantees.

Algorithm~\ref{alg:inexact} describes an inexact version of
Algorithm~\ref{alg:exact}. It replaces the damped Sinkhorn iterations of
Algorithm~\ref{alg:exact} via approximate updates computed by
an approximate Sinkhorn oracle -- a procedure that satisfies the properties listed
in Definition~\ref{dfn:approximate-sinkhorn-oracle}.

\begin{definition}[Approximate Sinkhorn Oracle]
  \label{dfn:approximate-sinkhorn-oracle}
  An $\varepsilon$-approximate Sinkhorn oracle is a procedure that given
  any $\vecpsi$ and any index $j \in
  \{1, \dots, k\}$, returns a Radon-Nikodym derivative
  $\frac{d\widehat{\nu}^{j}_{\vecpsi}}{d\nu^{j}}$
  of a measure
  $\widehat{\nu}^{j}_{\vecpsi} \ll \nu^{j}$ that satisfies the following
  properties:
  \begin{enumerate}
    \item $\frac{d\widetilde{\nu}^{j}_{\vecpsi}}{d\nu^{j}}$ is strictly positive
      on the support of $\nu^{j}$;
    \item $\|\widetilde{\nu}^{j}_{\vecpsi} - \nu^{j}_{\vecpsi}\|_{\mathrm{TV}} \leq
      \varepsilon/(2c_{\infty}(\mathcal{X}))$;
    \item
      $\mathbf{E}_{Y \sim
      \nu^{j}}[
        \frac{d\nu_{\vecpsi}^{j}}{d\widetilde{\nu}_{\vecpsi}^{j}}(Y)
      ]
      \leq 1 + \varepsilon^{2}/(2c_{\infty}(\mathcal{X})^{2})$;
    \item For any $\eta \in [0,1]$ and any $j \in \{1,\dots,k\}$ it holds that
      $\|\psi^{j}
      + \eta\lambda
      \log(d\widetilde{\nu}^{j}_{\vecpsi}/d\nu^{j})\|_{\mathrm{osc}}
      \leq (1-\eta)\|\psi^{j}\|_{\mathrm{osc}} +
      \eta c_{\infty}(\mathcal{X})$.
  \end{enumerate}
\end{definition}

\begin{algorithm}
  \caption{Approximate Damped Sinkhorn Scheme}
  \label{alg:inexact}
  \KwIn{error tolerance parameter $\varepsilon>0$, a function
  ``ApproximateSinkhornOracle'' satisfying properties listed in
  Definition~\ref{dfn:approximate-sinkhorn-oracle},
  regularization strengths $\lambda,\tau > 0$,
  reference measure $\piref$,number of iterations $T$ and
  $k$ marginal measures $\nu^{1},\dots,\nu^{k}$ with positive weights
  $w_{1}, \dots, w_{k}$ such that $\sum_{j=1}^{k}w_{j} = 1$.}
  \begin{enumerate}
    \item
      Set $\eta=\min(1, \tau/\lambda)$
      and initialize $(\psi^{j}_{0})=0$ for $j \in \{1,\dots,k\}$.
  \item For $t=0,1\dots,T-1$ do
  \begin{enumerate}
    \item
      $\frac{d\widehat{\nu}^{j}_{t}}{d\nu^{j}}(y)
      \leftarrow \mathrm{ApproximateSinkhornOracle}(
      \vecnu, \lambda, \tau, \vecpsi_{t}, \varepsilon, j)$
      for $j \in \{1,\dots,k\}$.
    \item $\psi^{j}_{t+1}(y) \leftarrow \psi^{j}_{t}(y) - \eta\lambda\log
      \frac{d\widehat{\nu}^{j}_{t}}{d\nu^{j}}(y)$
      for $j \in \{1,\dots,k\}$.
    \end{enumerate}
  \item Return $(\phi_{T}^{j}, \psi_{T}^{j})_{j=1}^{k}$.
  \end{enumerate}
\end{algorithm}

The following theorem shows that Algorithm~\ref{alg:inexact}
enjoys the same convergence guarantees as Algorithm~\ref{alg:exact}
up to the error tolerance of the procedure used to implement the approximate
updates. A noteworthy aspect of the below theorem is that the error does not
accumulate over the iterations.

\begin{theorem}
  \label{thm:inexact-scheme-convergence}
  Fix any $\lambda,\tau > 0$ and $\vecnu,w$.
  Let $\psi^{*}$ be the maximizer of dual problem
  $E^{\vecnu, w}_{\lambda,\tau}$.
  Let $(\widetilde{\vecpsi}_{t})_{t \geq 0}$ be the sequence of iterates generated by
  Algorithm~\ref{alg:inexact} with the accuracy parameter $\varepsilon \geq 0$.
  Let $T = \min\{t : E^{\vecnu, w}_{\lambda,\tau}(\vecpsi^{*}) -
  E^{\vecnu, w}_{\lambda,\tau}(\widetilde{\vecpsi}_{t}) \leq 2\varepsilon\}$.
  Then, for any $t \leq T$ it holds that
  \begin{equation}
    E^{\vecnu, w}_{\lambda,\tau}(\vecpsi^{*})
    -
    E^{\vecnu, w}_{\lambda,\tau}(\widetilde{\vecpsi}_{t})
    \leq 2\varepsilon +
    \frac{2c_{\infty}(\mathcal{X})^{2}}{\min(\lambda,\tau)}
    \,\frac{1}{t}.
  \end{equation}
\end{theorem}

The proof of the above theorem can be found in
Appendix~\ref{sec:inexact-algorithm-convergence-proof}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Implementing the Approximate Sinkhorn Oracle}
\label{sec:inexact-oracle-implementation}
In this section, we show that the approximate Sinkhorn oracle (see
Definition~\ref{dfn:approximate-sinkhorn-oracle}) can be implemented using
approximate random sampling when the marginal distributions $\nu^{j}$ are
discrete. To this end, fix the regularization parameters $\lambda, \tau > 0$,
the weight vector $w$, and consider a set of $k$ discrete marginal distributions
$$
  \nu^{j} = \sum_{l=1}^{m_{j}}\nu^{j}(y^{j}_{l})\delta_{y^{j}_{l}},
$$
where $\delta_{x}$ is the Dirac measure located at $x$ and $\nu^{j}(y^{j}_{l})$
is equal to the probability of sampling the point $y^{j}_{l}$ from measure
$\nu^{j}$.
We denote the total cardinality of the support of all measures $\nu^{j}$ by
$$
  m = \sum_{j=1}^{m}m_{j}.
$$
Fix any $\vecpsi \in L_{1}(\vecnu)$. Suppose we are given access to
$n$ i.i.d.\ samples $X_{1},\dots,X_{n}$ from a probability measure
$\mu'_{\vecpsi}$ that satisfies
\begin{equation}
  \|\mu_{\vecpsi} - \mu_{\vecpsi}'\|_{\mathrm{TV}} \leq \varepsilon_{\mu}.
\end{equation}
Then, for $j=1,\dots,k$ and $l=1,\dots,m_{j}$ consider
\begin{equation}
  \widehat{\nu}^{j}(y^{j}_{i})
  =
  \nu^{j}(y^{j}_{i})\frac{1}{n}
  \sum_{i=1}^{n}\exp\left(
    \frac{\phi_{\psi^{j}}(X_{i}) + \psi^{j}(y) - c(x,y)}{\lambda}\right)
\end{equation}
and for any parameter $\zeta \in (0,1/2]$ define
\begin{equation}
  \label{eq:approximate-oracle}
  \widetilde{\nu}^{j} = (1-\zeta)\widehat{\nu}^{j} + \zeta\nu^{j}.
\end{equation}
We claim that $\widetilde{\nu}^{j}$ implements the approximate Sinkhorn oracle
with accuracy parameter arbitrarily close to $\sqrt{\varepsilon_{\mu}}$
provided that $n$ is large enough.
This is shown in the following lemma, the proof of which can be found in
Appendix~\ref{sec:proof-of-approximate-oracle-implementation}.

\begin{lemma}
  \label{lemma:approximate-oracle-implementation}
  Fix any $\delta \in (0,1)$ and consider the setup described above.
  With probability at least $1-\delta$,
  for each $j \in \{1,\dots,k\}$ it holds simultaneously that
  the measure
  $\widetilde{\nu}^{j}$ defined in \eqref{eq:approximate-oracle}
  satisfies all the properties listed in
  Definition~\ref{dfn:approximate-sinkhorn-oracle}
  with accuracy parameter
  $$
    \varepsilon_{j} \leq
    c_{\infty}(\mathcal{X})
    \Bigg(
      2\zeta
      + \frac{1}{\zeta}
      m_{j}\varepsilon_{\mu}
      +
      \frac{1}{\zeta}
      m_{j}
        \sqrt{\frac{2\log\left(\frac{2m}{\delta}\right)}{n}}
    \Bigg)^{1/2}.
  $$
\end{lemma}

The above lemma shows that a step of Algorithm~\ref{alg:inexact} can be implemented
  provided access to i.i.d.\ sampling from some measure $\mu_{\vecpsi}'$ close
  to $\mu_{\vecpsi}$ in total variation norm, where $\vecpsi$ is an arbitrary
  iterate of Algorithm~\ref{alg:inexact}. The remainder of this section is
  dedicated to showing that this can be achieved by sampling via Langevin Monte
Carlo.

Henceforth, fix $\piref$ to be the Lebesgue measure on $\mathcal{X}$, which
corresponds to the free-support barycenters setup.
Then, for any $\vecpsi$ we have
$$
  \mu_{\vecpsi}(dx)
  \propto
  \mathbb{1}_{\mathcal{X}}
  \exp(-V_{\vecpsi}(x)/\tau)dx,
  \quad\text{where}\quad V_{\vecpsi}(x) =
  \sum_{j=1}^{k}w_{j}\phi^{j}_{\psi^{j}},
$$
where $\mathbb{1}_{\mathcal{X}}$ is equal to one on $\mathcal{X}$
and zero everywhere else.
It follows by \eqref{eq:schroedinger-potentials-bounded}
that $\|V_{\vecpsi}\|_{\mathrm{osc}} \leq c_{\infty}(\mathcal{X})/\tau$.
Further, let $\mathrm{diam}{\mathcal{X}} = \sup_{x,x' \in \mathcal{X}} \|x - x'\|_{2}$.
By the convexity of $\mathcal{X}$, the uniform measure on $\mathcal{X}$
satisfies the logarithmic Sobolev inequality (LSI) with constant
$\mathrm{diam}(\mathcal{X})^{2}/4$ (cf.\ \cite{lehec2021langevin}).
Hence, by the Holley-Stroock perturbation argument
\cite{holley1986logarithmic}, the measure $\mu_{\vecpsi}$ satisfies LSI with
constant at most
$\exp\left(2c_{\infty}(\mathcal{X})/\tau\right)\mathrm{diam}(\mathcal{X})^{2}/4
< \infty$.

It is well-established that Langevin Monte Carlo algorithms offer convergence
guarantees for approximate sampling from a target measure subject to functional
inequality constraints provided additional conditions hold such as
the smoothness of the function $V_{\vecpsi}$.
However, such guarantees do not directly apply to the measure $\mu_{\vecpsi}$
due to its constrained support.
Instead, it is possible to approximate $\mu_{\vecpsi}$
arbitrarily well in total variation norm by a family of measures
$(\mu_{\vecpsi,\sigma})_{\sigma > 0}$ (see Appendix~\ref{sec:langevin-sampling-guarantees} for details)
supported on all of $\mathbb{R}^{d}$.
Tuning the parameter $\sigma$ allows us to
trade-off between the approximation quality of $\mu_{\vecpsi,\sigma}$ and its
LSI constant. Crucially, standard sampling guarantees for Langevin Monte Carlo
(e.g., \cite{vempala2019rapid}) apply to the regularized measures
$\mu_{\vecpsi,\sigma}$, which leads to provable guarantees for an
implementation of Algorithm~\ref{alg:inexact}, thus furnishing
the first convergence guarantees for computation of Wasserstein barycenters
in the free support setup; see
Theorem~\ref{thm:inexact-algorithm-implementation} stated below.


The above approximation argument applies to any cost function $c$ that is Lipschitz on
$\mathcal{X}$ and exhibits quadratic growth at infinity. For the sake of
simplicity, we consider the quadratic cost $c(x,y) = \|x-y\|_{2}^{2}$.
The exact problem setup where we are able to obtain computational guarantees
for free-support barycenter computation via Langevin Sampling is formalized
below.

\begin{setup}
  \label{setup:ball-and-squared-loss}
  Consider the setting described at the beginning of
  Section~\ref{sec:inexact-oracle-implementation}. In addition, suppose that
  \begin{enumerate}
    \item the reference measure $\piref(dx) = \mathbb{1}_{\mathcal{X}}dx$
      is the Lebesgue measure supported on $\mathcal{X}$
      (free-support setup);
    \item it holds that
      $\mathcal{X} \subseteq \mathcal{B}_{R} = \{ x \in \mathbb{R}^{d} : \|x\|_{2} \leq R\}$ for some constant $R < \infty$;
    \item the cost function
      $c: \mathbb{R}^{d} \times \mathbb{R}^{d} \to [0, \infty)$ is defined
      by $c(x,y) = \|x - y\|_{2}^{2}$;
    \item for any $\vecpsi$ we have
      access to a stationary point $x_{\vecpsi}$ of $V_{\vecpsi}$ over $\mathcal{X}$.
  \end{enumerate}
\end{setup}
The last condition can be implemented in polynomial time
using a first order gradient method. For our purposes, this condition is needed
to obtain a good initialization point for the Unadjusted Langevin Algorithm
following the explanation in \cite[Lemma 1]{vempala2019rapid}; see
Appendix~\ref{sec:langevin-sampling-guarantees} for further details.

We now proceed to the main result of this section, the proof of which can be
found in Appendix~\ref{sec:langevin-sampling-guarantees}.
The following theorem provides the first provably convergent method for
computing Wasserstein barycenters in the free-support setting.
We remark that a stochastic approximation argument of a rather different flavor
used to
compute fixed-support Wasserstein barycenters (for $\tau \geq \lambda$) has
been previously analyzed in \cite{ballu2020stochastic}.


\begin{theorem}
  \label{thm:inexact-algorithm-implementation}
  Consider the setup described in Problem Setting~\ref{setup:ball-and-squared-loss}.
  Then, for any confidence parameter $\delta \in (0,1)$ and any
  accuracy parameter $\varepsilon > 0$, we can simulate a step
  of Algorithm~\ref{alg:inexact} with success probability at least $1-\delta$
  in time polynomial in
  \begin{equation}
    \varepsilon^{-1}, d, R, \exp(R^{2}/\tau),
    (Rd^{-1/4})^{d}, \tau^{-1}, \lambda^{-1}, d, m, \log(m/\delta).
  \end{equation}
  In particular, an $\varepsilon$-approximation of the
  $(\lambda, \tau)$-Barycenter can be obtained within the same computational
  complexity.
\end{theorem}



Comparing the above guarantee with the discussion following the statement of
Lemma~\ref{lemma:approximate-oracle-implementation},
we see an additional polynomial dependence on $(Rd^{-1/4})^{d}$ (note that for
$R \leq d^{1/4}$ this term disappears). We believe this term to be an
artefact of our analysis appearing due to the approximation argument described
above. Considering the setup with $R \leq d^{1/4}$, the
running time of our algorithm depends exponentially in $R^{2}/\tau$.

We conclude with two observations. First, since approximating
Wasserstein barycenters is generally NP-hard \cite{altschuler2022wasserstein},
an algorithm with polynomial dependence on all problem parameters does not
exist if $\mathrm{P}\neq\mathrm{NP}$. Second, notice that
computing an $\varepsilon$ approximation of $(\lambda,\tau)$-Barycenter can be
done in time polynomial in $\varepsilon^{-1}$.
This should be contrasted with numerical schemes based on discretizations of the
set $\mathcal{X}$, which would, in general, result in computational complexity
of order $(R/\varepsilon)^{d}$ to reach the same accuracy.

