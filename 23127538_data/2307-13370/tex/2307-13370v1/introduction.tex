%!TEX root = main.tex

\section{Introduction}
\label{sec:introduction}

The Wasserstein distance between two probability distributions measures the
least amount of effort needed to reconfigure one measure into the other.
Unlike other notions of distances based solely on the numerical values taken by
the distribution functions (e.g., the Kullback-Leibler divergence), the
Wasserstein distance incorporates an additional layer of complexity by
considering pairwise distances between distinct points, measured by some
predetermined cost function.  As a result, the Wasserstein distances can be seen
to lift the geometry of the underlying space where the probability
measures are defined to the space of the probability measures itself.
This allows for a more thorough and geometrically nuanced understanding of the
relationships between different probability measures, which
proved to be a versatile tool of increasing importance in a broad spectrum of
areas.

Given a collection of probability measures and an associated set of positive weights that sum
to one, the corresponding Wasserstein barycenter minimizes the  weighted
sum of Wasserstein distances to the given measures.
In the special case of two measures and the squared Euclidean cost function,
Wasserstein barycenters concide with the notion of McCann's displacement
interpolation introduced in the seminal paper  \cite{mccann1997convexity}.
The general case, encompassing an arbitrary number of measures, was first
studied by \citet*{agueh2011barycenters}, where they also demonstrated a close
link between Wasserstein barycenters and the multi-marginal optimal transport
problem \cite{gangbo1998optimal}.
Recent years have witnessed an increasing number of applications of
Wasserstein barycenters across various scientific disciplines.
See, for instance, the following sample of works in economics
\cite{chiappori2010hedonic,carlier2010matching}, statistics
\cite{bernton2019parameter}, image processing \cite{rabin2012wasserstein},
and machine learning \cite{courty2017joint}, among other areas.
For further background and references we point the interested reader to the introductory surveys
\cite{peyre2019computational, panaretos2019statistical}
and the textbooks \cite{villani2003topics,
villani2009optimal, santambrogio2015optimal,
panaretos2020invitation, figalli2021invitation}.


Despite their compelling theoretical characteristics, the computation of
Wasserstein barycenters poses significant computational challenges, particularly
in large-scale applications.
While Wasserstein barycenters can be computed in polynomial time
for fixed dimensions \cite{altschuler2021wasserstein},
the approximation of Wasserstein barycenters is known to be NP--hard
\cite{altschuler2022wasserstein}.
Currently employed methods for approximating Wasserstein barycenters are
predominantly based on space discretizations. Unfortunately,
such strategies are only computationally practical for problems of relatively
modest scale. Although there are a handful of grid-free techniques available for
approximating Wasserstein barycenters (e.g.,
\cite{cohen2020estimating, korotin2021continuous, daaloul2021sampling, lindheim2023simple}),
we are not aware of any existing methods that provide bounds on computational
complexity.
One contribution of the present paper is to introduce a method that in some
regimes can provably approximate Wasserstein barycenters without relying on
space discretizations, but instead employing approximate Monte Carlo sampling.


More broadly, the difficulties associated with computation of the
optimal transport cost has prompted the exploration of
computationally efficient alternatives, leading to the consideration of
regularized Wasserstein distances.
Among these, the entropic penalty has
emerged as one of the most successful in applications.
The practical success of entropic penalization can be attributed to
Sinkhorn's algorithm \cite{sinkhorn1967diagonal},
which enables efficient and highly parallelizable
computation, an algorithm that gained substantial traction in the machine
learning community following the work of \citet*{cuturi2013sinkhorn}.
It is worth noting that entropic Wasserstein distances are of intrinsic
interest, beyond their approximation capabilities. Indeed, they hold a rich
historical connection to the Schr\"{o}dinger bridge problem
\cite{schrodinger1932theorie, wilson1969use, erlander1990gravity}, as
highlighted in the recent surveys \cite{leonard2013survey, chen2021stochastic}.
Furthermore, they increasingly serve as an analytically convenient tool
for studying the unregularized optimal transport problem (see, e.g.,  \cite{leonard2012schrodinger,
gentil2017analogy, fathi2020proof, chewi2022entropic})
and they underlie some favorable statistical properties
that are currently under active investigation; see the works
\cite{mena2019statistical, genevay2019sample, del2020statistical,
  pooladian2021entropic, rigollet2022sample,
  pooladian2023minimax} and the
references therein.

Let us now define the entropic optimal transport cost.
Consider two probability measures, $\mu$ and $\nu$, both supported on
$\mathcal{X}$, and let $c: \mathcal{X}\times\mathcal{X} \to
[0,\infty)$ be a cost function.
The entropic Wasserstein distance with a regularization level
$\lambda>0$ is defined as

\begin{equation}
  \label{eq:entropic-Wasserstein-distance}
  T_{\lambda}(\mu,\nu)
  = \inf_{\gamma \in \Pi(\mu, \nu)}\mathbf{E}_{(X,Y) \sim \gamma}[c(X,Y)] +
  \lambda \kl{\gamma}{\mu \otimes \nu},
\end{equation}
where $\Pi(\mu,\nu)$ denotes the set of probability measures on $\mathcal{X}
\times \mathcal{X}$ with marginal distributions equal to $\mu$ and $\nu$,
and $\mathrm{KL}(\cdot,\cdot)$ is the Kullback-Leibler divergence.
When $\lambda \to 0$, the regularized cost $T_{\lambda}(\mu,\nu)$ converges
to the unregularized Wasserstein distance.
Various properties of entropic optimal transport can be found in the
recent lecture notes by \citet*{leonard2013survey}.

To develop efficiently computable approximations for Wasserstein barycenters, a
natural approach is to replace the unregularized Wasserstein cost with the
minimizer of the weighted sum of entropy-regularized costs.
This method was first explored
by \citet*{cuturi2014fast} and it has gained additional traction in the recent
years. There is some flexibility in the definition of \eqref{eq:entropic-Wasserstein-distance},
which arises from substituting the reference product measure $\mu \otimes \nu$ with
alternatives such as the Lebesgue measure. Consequently, various notions of
entropic barycenters have emerged in the literature, which can be
unified through the following optimization problem:
\begin{equation}
  \label{eq:doubly-entropic-barycenter-definition}
  \min_{\mu} \sum_{j=1}^{k} T_{\lambda}(\mu, \nu^{j}) + \tau\kl{\mu}{\piref}.
\end{equation}
Here $\nu^{1},\dots,\nu^{k}$ are the probability measures whose barycenter we
wish to compute and $w_{1}, \dots, w_{k}$ are positive weights that sum to one.
The inner regularization strength is denoted by $\lambda > 0$ while
$\tau > 0$ is the outer regularization strength.
The measure $\piref$ is an arbitrary reference measure, the support of which
dictates the support of the computed barycenter.
For instance, if we take $\piref$ to be a uniform measure on a particular
discretization of the underlying space, we are dealing with a fixed-support
setup. On the other hand, letting $\piref$ be the Lebesgue measure
puts us in the free-support setup.
We shall refer to the minimizer of \eqref{eq:doubly-entropic-barycenter-definition}
as the $(\lambda, \tau)$-barycenter, which exists and is unique due to the
strict convexity of the outer regularization penalty; however, uniqueness may no
longer holds when $\tau = 0$.

The objective \eqref{eq:doubly-entropic-barycenter-definition} was recently
studied in \cite{chizat2023doubly}; it also appeared earlier in
\cite{ballu2020stochastic} for the special case $\tau \geq \lambda$, where
  stochastic approximation algorithms were considered for the computation of
fixed-support barycenters.
In \cite[Section 1.3]{chizat2023doubly}, it is discussed how various choices
of $(\lambda, \tau)$ relate to Barycenters previously explored in the
literature. To provide a brief overview, $(0,0)$
are the unregularized Wasserstein barycenters studied in
\cite{agueh2011barycenters}. Inner-regularized barycenters $(\lambda, 0)$
introduce a shrinking bias; this can be seen already when $k=1$, in which
case the solution computes a maximum-likelihood deconvolution
\cite{rigollet2018entropic}.
The $(\lambda, \lambda)$-barycenters were considered in
\cite{cuturi2014fast, benamou2015iterative, cuturi2018semidual,
bigot2019penalization, kroshnin2019complexity}; they introduce a blurring
bias. Likewise, blurring bias is introduced by the outer-regularized
barycenters $(0,\tau)$, studied in \cite{bigot2019data, carlier2021entropic}.
The only case not covered via the
formulation \eqref{eq:doubly-entropic-barycenter-definition} appears to be
the one of debiased Sinkhorn barycenters \cite{ramdas2017wasserstein,
janati2020debiased}, for which an algorithm exists but without
computational guarantees.
Of particular interest are the $(\lambda,\lambda/2)$ barycenters: the choice
$\tau=\lambda/2$ for smooth densities yields approximation bias of order
$\lambda^{2}$, while the
choice $\tau=\lambda$ results in bias of order $\lambda$, which is
significantly larger than $\lambda^{2}$ in the regimes of interest.
This is a new notion of entropic barycenters that was unveiled in the analysis
of \cite{chizat2023doubly}.
We provide the first convergence guarantees for this type of barycenters.

The regularity, stability, approximation, and statistical sample complexity
properties of $(\lambda,\tau)$-barycenters were investigated in
\cite{chizat2023doubly}. However, the question of obtaining non-asymptotic
convergence guarantees for the computation of $(\lambda, \tau)$-barycenters with arbitrary
regularization parameters was not addressed therein.
In particular, the $(\lambda, \lambda/2)$ case, which has stood out due to its
compelling mathematical features, has not yet been addressed in the
existing literature. This gap is addressed by the present paper;
we summarize our contributions in the following section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Contributions}

The remainder of this paper is organized as follows:
Section~\ref{sec:background} provides the necessary background on
entropic optimal transport and a particular dual problem of the doubly
regularized entropic objective \eqref{eq:doubly-entropic-barycenter-definition}.
Section~\ref{sec:damped-sinkhorn} introduces a damped Sinkhorn iteration scheme
and complements it with convergence guarantees.
An approximate version of the algorithm together with convergence results and
implementation details is discussed in Section~\ref{sec:approximate-damped-sinkhorn}.
We summarize our key contributions:
\begin{enumerate}
  \item
    Lemma~\ref{lemma:suboptimality-to-kl}, presented in
    Section~\ref{sec:damped-sinkhorn}, demonstrates that bounds on the dual
    suboptimality gap for the dual problem \eqref{eq:doubly-entropic-dual},
    defined in Section~\ref{sec:doubly-entropic-barycenters}, can be
    translated into Kullback-Leibler divergence bounds between the
    $(\lambda,\tau)$-barycenter and the barycenters corresponding to dual-feasible variables.
    This translation enables us to formulate all our subsequent results in
    terms of optimizing the dual objective \eqref{eq:doubly-entropic-dual}.

  \item
    In Section~\ref{sec:damped-sinkhorn}, we introduce a damped Sinkhorn scheme
    (Algorithm~\ref{alg:exact}) that can be employed to optimize
    $(\lambda,\tau)$-barycenters for any choice of regularization parameters.
    The damping factor $\min(1,\tau/\lambda)$ accommodates the degrading
    smoothness properties of the dual objective \eqref{eq:doubly-entropic-dual}
    as a function of decreasing outer regularization parameter $\tau$.  The
    introduced damping of the Sinkhorn iterations is, in fact, necessary and it
    is one of our core contributions:
    undamped exact scheme can be experimentally shown to diverge as soon as
    $\tau < \lambda/2$.

  \item The main result of this paper is
    Theorem~\ref{thm:exact-scheme-convergence} proved in
    Section~\ref{sec:damped-sinkhorn}. It provides
    convergence guarantees for Algorithm~\ref{alg:exact} with
    arbitrary choice of regularization parameters $\lambda,\tau > 0$.
    This, in particular, results in the first algorithm with guarantees
    for computing $(\lambda,\lambda/2)$ barycenters. For smooth densities,
    these barycenters incur a
    bias of order $\lambda^{2}$ in contrast to the predominantly studied
    $(\lambda, \lambda)$ barycenters that incur bias of order $\lambda$.


  \item In Section~\ref{sec:approximate-damped-sinkhorn}, we describe
    Algorithm~\ref{alg:inexact}, an extension of Algorithm~\ref{alg:exact} that
    allows us to perform inaccurate updates.
    We formulate sufficient conditions on the inexact updates oracle under
    which the errors in the convergence analysis do not accumulate.
    Section~\ref{sec:inexact-oracle-implementation} details an implementation
    of this inexact oracle, based on approximate Monte Carlo sampling.

  \item Theorem~\ref{thm:inexact-scheme-convergence} proved in
    Section~\ref{sec:approximate-damped-sinkhorn} furnishes convergence
    guarantees for Algorithm~\ref{alg:inexact}.
    When combined with the implementation of the inexact oracle described in
    Section~\ref{sec:inexact-oracle-implementation}, this yields a provably
    convergent scheme for a grid-free computation of entropic Wasserstein
    barycenters between discrete distributions, provided sufficient regularity
    on the domain $\mathcal{X}$ and the cost function $c$.
\end{enumerate}



