\section{Introduction}\label{sec:introduction}
Many words are ambiguous.
The English word \textit{bank} may denote a financial institution or a riverside.
Besides such well-known ambiguities, it turns out that most words are ambiguous, at least to a certain extent.
For example the word \textit{Coca-Cola} may refer to a specific soft-drink, the respective company, as well as the
shares of that company.

Ambiguities are often related to topics or domains.
Within the domain \textit{finance and economy}, the word \textit{bank} almost always denotes a financial institution
rather than a riverside.
However, within this domain there may be further ambiguities of the word \textit{bank}.
Depending on the document context, \textit{bank} may refer to multiple individual financial institutions.
Figure~\ref{fig:mars_meanings} illustrates various domains for the word \textit{Mars},
each bearing multiple meanings.

% Figure environment removed

Shifting the context of an ambiguous word also changes its meaning, leading to misunderstanding, and
creating the necessity to reaffirm the context or ask for further information.
These communication phenomena occur in both human-to-human and human-to-machine interaction.
A search engine or a chatbot might, for example, have to ask for further information before answering an ambiguous query
or question.
While this implies the necessity to recognize ambiguities in queries,
we are less interested in identifying and resolving general ambiguities.
Instead, we focus on ambiguities w.r.t.\ a specific data set (document corpus) and knowledge available to the system,
since these are the ambiguities most relevant for query/question answering.

In his \textit{Philosophical Investigations}~\cite{wittgenstein1953philosophical} Wittgenstein claimed
\textit{`The meaning of a word is its use in the language'} (ยง43).
We translate \textit{`use in language'} to context.
The context may contain information about the interacting participants, location, past interactions, as well as non-verbal
communication.
Within this paper we focus on textual context of a target word, more precisely,
the five tokens preceding and following a target word.
This quote of Wittgenstein can be seen as the philosophical foundation of current approaches to
Natural Language Processing.

Transformers~\cite{vaswani2017attention} produce embeddings for sentences or paragraphs.
The representations they produce for individual words are highly context dependent.
However, transformers do not help us identify or resolve ambiguity.
A generative language model such as ChatGPT may produce a reasonable answer for the question
\textit{`What are the different meanings of the word bank'}, but it cannot be easily used to identify ambiguities of
a word w.r.t.\ a given document corpus~\cite{ChatGPT}.
We decided to look into much simpler word embedding models since they require much less resources
to train and operate and results are easier to understand and interpret.
Word embedding models produce one embedding per word based on all contexts of the training corpus (document corpus),
which makes them more compatible with the bag-of-words model, the foundation of classical search engine technology.
The focus of this paper is to identify and resolve word ambiguity in unsupervised manner, using the CBOW
(continuous bag of words) architecture from word2vec~\cite{mikolov2013efficient} conjoined with the
DBSCAN~\cite{DensitybasedAlgorithmDiscovering1996} clustering algorithm.

We first show similarities and differences to related work in section~\ref{sec:related-work}.
Section~\ref{sec:data-and-preprocessing} contains data selection, preprocessing and tokenization,
as well as the training of word embeddings and the generation of context vectors.
We then describe the clustering process and the proposed parameter score for automatic cluster parameter
selection in section~\ref{sec:clustering-and-automatic-parameter-selection}.
Finally, we qualitatively analyse the clustering results and discuss next steps.
The code used in this paper is freely accessible at\newline
\url{https://github.com/thurnbauermatthi/WordDisambiguation}.


