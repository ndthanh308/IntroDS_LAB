\section{Experiments}
\label{section-2}

\subsection{Experimental Settings}
We closely follow the experimental settings in DyGLib \cite{yu2023towards} and TGB \cite{huang2023temporal}. Our project is developed based on the repositories of DyGLib\footnote{\url{https://github.com/yule-BUAA/DyGLib}} and TGB\footnote{\url{https://github.com/shenyangHuang/TGB}}.

\textbf{Datasets, Baselines, and Evaluation Metrics}. We conduct the experiments on TGB, including five datasets (i.e., tgbl-wiki, tgbl-review, tgbl-coin, tgbl-comment, and tgbl-flight) for the dynamic link property prediction task, as well as three datasets (i.e., tgbn-trade, tgbn-genre, and tgbn-reddit) for the dynamic node property prediction task. We report the performance of nine methods (i.e., JODIE \cite{DBLP:conf/kdd/KumarZL19}, DyRep \cite{DBLP:conf/iclr/TrivediFBZ19}, TGAT \cite{DBLP:conf/iclr/XuRKKA20}, TGN \cite{DBLP:journals/corr/abs-2006-10637}, CAWN \cite{DBLP:conf/iclr/WangCLL021}, EdgeBank \cite{poursafaei2022towards}, TCL \cite{DBLP:journals/corr/abs-2105-07944}, GraphMixer \cite{cong2023do}, and DyGFormer \cite{yu2023towards}) on the dynamic link property prediction task, and evaluate ten methods (i.e., JODIE \cite{DBLP:conf/kdd/KumarZL19}, DyRep \cite{DBLP:conf/iclr/TrivediFBZ19}, TGAT \cite{DBLP:conf/iclr/XuRKKA20}, TGN \cite{DBLP:journals/corr/abs-2006-10637}, CAWN \cite{DBLP:conf/iclr/WangCLL021}, TCL \cite{DBLP:journals/corr/abs-2105-07944}, GraphMixer \cite{cong2023do}, DyGFormer \cite{yu2023towards}, Persistent Forecast \cite{salcedo2022persistence}, and Moving Average \cite{panch2018artificial}) on the dynamic node property prediction task. Mean Reciprocal Rank (MRR) is used to evaluate dynamic link property prediction and Normalized Discounted Cumulative Gain (NDCG) is computed for measuring dynamic node property prediction. We direct interested readers to the above references for further details of the datasets and methods.

\textbf{Model Configurations}. Currently, due to the limitations of computational resources, we treat the optimal hyperparameters of baselines on the small-scale tgbl-wiki dataset as the default setting and apply it to other datasets. More comprehensive selections of the hyperparameters are expected in the future. Please see \secref{section-appendix-configurations} for the detailed configurations of various models, which most of the contents are borrowed from \cite{yu2023towards}.

\textbf{Implementation Details}. Following \cite{yu2023towards}, we use Adam \cite{DBLP:journals/corr/KingmaB14} as the optimizer. We train models that contain learnable parameters (i.e., excluding EdgeBank, Persistent Forecast, and Moving Average) for 100 epochs and use the early stopping strategy with the patience of 20 or 5 (when the model training speed is slow). The model that performs best on the validation set is selected for testing. We set the learning rate and batch size to 0.0001 and 200 for all the methods on all the datasets. We run the methods five times and report the average performance to eliminate deviations. The experiments are conducted on an NVIDIA GeForce RTX 3090 with 24 GB memory, and an NVIDIA Tesla V100 GPU with 32 GB memory is used for models with more computational costs.

\subsection{Existing Issues in TGB} \label{section-2-issues} 
During the experiments, we find some problems in the current version of TGB (until July 22, 2023).

\textbf{Mismatched Data Statistics}. The numbers of nodes and links on datasets for dynamic node property prediction reported in \cite{huang2023temporal} are inconsistent with those in the released datasets\footnote{Please see \url{https://github.com/shenyangHuang/TGB/issues/49} for more details.}. We show the differences (colored in \textcolor{red}{red}) in \tabref{tab:different_data_statistics}. The mismatch of node numbers in tgbn-genre and tgbn-reddit is because these two datasets are bipartite graphs but the reported numbers are only about users. The mismatch of link numbers is indeed an inconsistency that needs to be resolved. It is desired to revise the mismatched data statistics issue in the future version of \cite{huang2023temporal}.


\begin{table}[!htbp]
\centering
\caption{Differences in data statistics.}
\label{tab:different_data_statistics}
\setlength{\tabcolsep}{1.25mm}
{
\begin{tabular}{c|cccc}
\hline
Datasets    & Reported \#Nodes     & Released \#Nodes & Reported \#Links   & Released \#Links     \\ \hline
tgbn-trade   &   255    & 255  & \textcolor{red}{507,497}   & \textcolor{red}{468,245}       \\
tgbn-genre      &   \textcolor{red}{992}    & \textcolor{red}{1,505} & 17,858,395   & 17,858,395      \\
tgbn-reddit    & \textcolor{red}{11,068}  & \textcolor{red}{11,766}   & 27,174,118 & 27,174,118     \\ \hline
\end{tabular}
}
\end{table}

\textbf{Inaccurate Evaluation Metric Computation}. The calculation of the NDCG metric on dynamic node property prediction is problematic. The computed results of each time slot are divided by the number of examples rather than the number of time slots
\footnote{See https://github.com/shenyangHuang/TGB/blob/b859771c6aa94bae2207f9e0856430caf88f85c1/examples/nodeproppred/tgbn-trade/tgn.py\#L197 as an example.}, leading to extremely low performance of the baselines (i.e., all of the reported NDCGs in \cite{huang2023temporal} are lower than 0.01). 
% Moreover, it seems that labels in the last time slot are ignored for evaluation\footnote{See \url{https://github.com/shenyangHuang/TGB/issues/49} for more details.}.

\textbf{Potential Numerical Errors in Loss Function}. In the TGB repository\footnote{https://github.com/shenyangHuang/TGB/blob/b859771c6aa94bae2207f9e0856430caf88f85c1/modules/decoder.py\#L39}, the node predictor provides the outputs computed by log\_softmax function. Moreover, the dynamic node property prediction is optimized by nn.CrossEntropyLoss\footnote{See https://github.com/shenyangHuang/TGB/blob/b859771c6aa94bae2207f9e0856430caf88f85c1/examples/nodeproppred/tgbn-trade/tgn.py\#L95 as an example.}. However, the nn.CrossEntropyLoss expects raw logits as inputs, and it will apply log softmax to the logits internally. Feeding the outputs computed by log\_softmax function into nn.CrossEntropyLoss would potentially obtain incorrect values. 

\textbf{Suboptimal Model Performance}. Most of the baselines' results reported in \cite{huang2023temporal} are relatively low, and they can be significantly improved when building the project based on DyGLib.

This work makes an initial attempt to address the above problems and it will be encouraging to see efforts from the community for better solutions.

\subsection{Performance for Dynamic Link Property Prediction}
We report the performance of different methods for dynamic link property prediction in \tabref{tab:mrr_dynamic_link_property_prediction}. The best and second-best results are emphasized by \textbf{bold} and \underline{underlined} fonts. The results are multiplied by 100 for a better display layout. Note that some results are missing since the models either took too long to train or raised an out-of-memory issue on GPU. Numbers in \textcolor{red}{red} mean that we cannot obtain results due to computational cost issues and instead use the numbers reported in \cite{huang2023temporal} (although some of them may be problematic).

\begin{table}[!htbp]
\centering
\caption{MRR for dynamic link property prediction.}
\label{tab:mrr_dynamic_link_property_prediction}
\resizebox{1.01\textwidth}{!}
{
\setlength{\tabcolsep}{1.05mm}
{
\begin{tabular}{c|cccccc}
\hline
                             & Methods                 & tgbl-wiki    & tgbl-review  & tgbl-coin & tgbl-comment & tgbl-flight \\ \hline
\multirow{12}{*}{Validation} & JODIE                   & 79.44 $\pm$ 0.17 &    \textbf{47.85 $\pm$ 0.84}          &           &              &             \\
                             & DyRep                   & 76.08 $\pm$ 0.27 &    \textcolor{red}{35.60 $\pm$ 1.60}          &  \textcolor{red}{50.70 $\pm$ 2.90}         &    \underline{\textcolor{red}{29.10 $\pm$ 2.80}}          &    \underline{\textcolor{red}{52.80 $\pm$ 2.20}}         \\
                             & TGAT                    & 82.57 $\pm$ 0.51 &  40.73 $\pm$ 2.47            &   59.96 $\pm$ 1.39        &              &             \\
                             & TGN                     & \textbf{85.81 $\pm$ 0.07} &   \underline{\textcolor{red}{46.50 $\pm$ 1.00}}           &  \textcolor{red}{59.40 $\pm$ 2.30}         &    \textbf{\textcolor{red}{35.60 $\pm$ 1.90}}          &     \textbf{\textcolor{red}{73.90 $\pm$ 1.20}}        \\
                             & CAWN                    & 79.82 $\pm$ 0.12 &  29.72 $\pm$ 1.57            &           &              &             \\
                             & EdgeBank$_\infty$       & 55.11 $\pm$ 0.00 & 7.86 $\pm$ 0.00  &    \textcolor{red}{31.50 $\pm$ 0.00}       &    \textcolor{red}{10.87 $\pm$ 0.00}          &    \textcolor{red}{16.60 $\pm$ 0.00}         \\
                             & EdgeBank$_\text{tw-ts}$ & 64.09 $\pm$ 0.00 & 9.78 $\pm$ 0.00  &     \textcolor{red}{49.20 $\pm$ 0.00}      &     \textcolor{red}{12.44 $\pm$ 0.00}         &    \textcolor{red}{38.80 $\pm$ 0.00}         \\
                             & EdgeBank$_\text{tw-re}$ & 58.90 $\pm$ 0.00 & 10.03 $\pm$ 0.00 &           &              &             \\
                             & EdgeBank$_\text{th}$    & 55.25 $\pm$ 0.00 & 9.05 $\pm$ 0.00  &           &              &             \\
                             & TCL                     & 82.99 $\pm$ 0.84 & 35.33 $\pm$ 0.47 &   62.97 $\pm$ 0.66         &             &             \\
                             & GraphMixer              & 83.98 $\pm$ 0.09 &  43.69 $\pm$ 0.53            &    \underline{70.38 $\pm$ 1.69}        &              &             \\
                             & DyGFormer               & \underline{85.75 $\pm$ 0.08} &    36.50 $\pm$ 2.87          &    \textbf{72.89 $\pm$ 0.07}       &              &             \\ \hline
\multirow{12}{*}{Test}       & JODIE                   & 77.15 $\pm$ 0.22 &    \textbf{54.97 $\pm$ 0.91}          &           &              &             \\
                             & DyRep                   & 73.37 $\pm$ 0.22 &    \textcolor{red}{36.70 $\pm$ 1.30}          &     \textcolor{red}{43.40 $\pm$ 3.80}      &    \underline{\textcolor{red}{28.90 $\pm$ 3.30}}          &     \underline{\textcolor{red}{54.30 $\pm$ 2.40}}        \\
                             & TGAT                    & 79.89 $\pm$ 0.52 &  45.50 $\pm$ 2.57            &   60.88 $\pm$ 1.25        &              &             \\
                             & TGN                     & \underline{84.30 $\pm$ 0.32} &   \underline{\textcolor{red}{53.20 $\pm$ 2.00}}           &    \textcolor{red}{58.30 $\pm$ 5.00}        &   \textbf{\textcolor{red}{37.90 $\pm$ 2.10}}            &    \textbf{\textcolor{red}{70.60 $\pm$ 1.60}}         \\
                             & CAWN                    & 78.15 $\pm$ 0.09 &  34.43 $\pm$ 1.39            &           &              &             \\
                             & EdgeBank$_\infty$       & 53.76 $\pm$ 0.00 & 7.95 $\pm$ 0.00  &    \textcolor{red}{35.90 $\pm$ 0.00}       &   \textcolor{red}{12.85 $\pm$ 0.00}           &   \textcolor{red}{16.70 $\pm$ 0.00}          \\
                             & EdgeBank$_\text{tw-ts}$ & 63.87 $\pm$ 0.00 & 9.99 $\pm$ 0.00  &     \textcolor{red}{58.00 $\pm$ 0.00}      &   \textcolor{red}{14.94 $\pm$ 0.00}           &   \textcolor{red}{36.40 $\pm$ 0.00}          \\
                             & EdgeBank$_\text{tw-re}$ & 55.94 $\pm$ 0.00 & 9.90 $\pm$ 0.00  &           &              &             \\
                             & EdgeBank$_\text{th}$    & 55.11 $\pm$ 0.00 & 9.05 $\pm$ 0.00  &           &              &             \\
                             & TCL                     & 80.68 $\pm$ 0.79 & 36.13 $\pm$ 0.54 &   63.95 $\pm$ 0.62          &            &             \\
                             & GraphMixer              & 82.38 $\pm$ 0.16 &  53.12 $\pm$ 0.22            &   \underline{73.25 $\pm$ 1.75}         &              &             \\
                             & DyGFormer               & \textbf{85.03 $\pm$ 0.05} &    39.10 $\pm$ 2.24         &    \textbf{74.88 $\pm$ 0.04}       &              &             \\ \hline
\end{tabular}
}
}
\end{table}

From \tabref{tab:mrr_dynamic_link_property_prediction}, we have two key observations. 
Firstly, different methods show varying performance on different datasets, demonstrating their unique characteristics as well as the diversity of datasets. Moreover, trainable parametric methods can always perform better than the non-parametric EdgeBank, which indicates the complexity of the dynamic link property prediction task. Secondly, compared with \cite{huang2023temporal}, the performance of baselines (e.g., DrRep, TGN, TCL, GraphMixer) can be effectively promoted when using DyGLib for experiments, which proves the importance of introducing a unified library for dynamic graph learning methods \cite{yu2023towards}.

\subsection{Performance for Dynamic Node Property Prediction}
Due to the incorrect calculation of metrics for dynamic node property prediction in TGB (discussed in \secref{section-2-issues}), we only report the results we can produce in \tabref{tab:ndcg_dynamic_node_property_prediction} and leave the results empty when we encounter computational cost issues. From \tabref{tab:ndcg_dynamic_node_property_prediction}, we find that (\romannumeral1) simple non-trainable Persistent Forecast and Moving Average methods could achieve surprisingly good performance than other trainable methods; (\romannumeral2) current popular dynamic graph learning methods mainly focus on link-based tasks and cannot obtain satisfactory results on node-based tasks, which indicates the necessity of designing specialized models for the dynamic node property prediction task; (\romannumeral3) some trainable baselines tend to obtain approximate performance, which may be because we do not perform hyperparameter selection due to computational resources. More exhaustive selections of hyperparameters may help alleviate this phenomenon. 

\begin{table}[!htbp]
\caption{NDCG for dynamic node property prediction.}
\label{tab:ndcg_dynamic_node_property_prediction}
\resizebox{1.01\textwidth}{!}
{
\setlength{\tabcolsep}{1.1mm}
{
\begin{tabular}{c|cc|cc|cc}
\hline
Methods             & \multicolumn{2}{c|}{tgbn-trade} & \multicolumn{2}{c|}{tgbn-genre} & \multicolumn{2}{c}{tgbn-reddit} \\ \hline
                    & Validation     & Test           & Validation     & Test           & Validation        & Test        \\ \hline
JODIE               & 39.34 $\pm$ 0.05   & 37.45 $\pm$ 0.02   &    35.76 $\pm$ 0.08            &    34.94 $\pm$ 0.06            &                   &             \\
DyRep               & 39.38 $\pm$ 0.08   & 37.46 $\pm$ 0.08   &     \underline{35.89 $\pm$ 0.14}           &    35.03 $\pm$ 0.10            &                   &            \\
TGAT                & 39.35 $\pm$ 0.06   & 37.47 $\pm$ 0.07   &      35.63 $\pm$ 0.19          &    34.88 $\pm$ 0.11            &                   &             \\
TGN                 & 39.36 $\pm$ 0.08   & 37.45 $\pm$ 0.04   &      35.79 $\pm$ 0.06          &    34.98 $\pm$ 0.04            &                  &             \\
CAWN                &    39.41 $\pm$ 0.02            &  37.45 $\pm$ 0.14              &                &                &                   &             \\
TCL                 & 39.44 $\pm$ 0.21   & 37.48 $\pm$ 0.12   &     35.61 $\pm$ 0.20           &   34.95 $\pm$ 0.18             &                   &             \\
GraphMixer          & 39.24 $\pm$ 0.04   & 37.29 $\pm$ 0.08   &     35.77 $\pm$ 0.07          &     34.91 $\pm$ 0.06           &                   &             \\
DyGFormer           & 39.34 $\pm$ 0.05   & 37.42 $\pm$ 0.03   &     35.79 $\pm$ 0.06           &    34.99 $\pm$ 0.04            &                   &             \\
Persistent Forecast & \textbf{86.72 $\pm$ 0.00}   & \textbf{84.69 $\pm$ 0.00}   & 35.24 $\pm$ 0.00   & \underline{35.96 $\pm$ 0.00}   &     \underline{37.99 $\pm$ 0.00}           & \underline{37.72 $\pm$ 0.00}          \\
Moving Average      & \underline{84.25 $\pm$ 0.00}   & \underline{80.93 $\pm$ 0.00}   & \textbf{50.74 $\pm$ 0.00}   & \textbf{51.79 $\pm$ 0.00}   &    \textbf{57.41 $\pm$ 0.00}             &    \textbf{56.24 $\pm$ 0.00}     \\ \hline
\end{tabular}
}
}
\end{table}
