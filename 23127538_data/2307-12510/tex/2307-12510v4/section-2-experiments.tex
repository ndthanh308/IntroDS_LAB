\section{Experiments}
\label{section-2}

\subsection{Experimental Settings}
We closely follow the experimental settings in DyGLib \cite{yu2023towards} and TGB \cite{huang2023temporal}. Our project is developed based on the repositories of DyGLib\footnote{\url{https://github.com/yule-BUAA/DyGLib}} and TGB\footnote{\url{https://github.com/shenyangHuang/TGB}}.

\textbf{Datasets, Baselines, and Evaluation Metrics}. We conduct the experiments on TGB, including five datasets (i.e., tgbl-wiki, tgbl-review, tgbl-coin, tgbl-comment, and tgbl-flight) for the dynamic link property prediction task, as well as three datasets (i.e., tgbn-trade, tgbn-genre, and tgbn-reddit) for the dynamic node property prediction task. We report the performance of nine methods (i.e., JODIE \cite{DBLP:conf/kdd/KumarZL19}, DyRep \cite{DBLP:conf/iclr/TrivediFBZ19}, TGAT \cite{DBLP:conf/iclr/XuRKKA20}, TGN \cite{DBLP:journals/corr/abs-2006-10637}, CAWN \cite{DBLP:conf/iclr/WangCLL021}, EdgeBank \cite{poursafaei2022towards}, TCL \cite{DBLP:journals/corr/abs-2105-07944}, GraphMixer \cite{cong2023do}, and DyGFormer \cite{yu2023towards}) on the dynamic link property prediction task, and evaluate ten methods (i.e., JODIE \cite{DBLP:conf/kdd/KumarZL19}, DyRep \cite{DBLP:conf/iclr/TrivediFBZ19}, TGAT \cite{DBLP:conf/iclr/XuRKKA20}, TGN \cite{DBLP:journals/corr/abs-2006-10637}, CAWN \cite{DBLP:conf/iclr/WangCLL021}, TCL \cite{DBLP:journals/corr/abs-2105-07944}, GraphMixer \cite{cong2023do}, DyGFormer \cite{yu2023towards}, Persistent Forecast \cite{salcedo2022persistence}, and Moving Average \cite{panch2018artificial}) on the dynamic node property prediction task. Mean Reciprocal Rank (MRR) is used to evaluate dynamic link property prediction and Normalized Discounted Cumulative Gain (NDCG) is computed for measuring dynamic node property prediction. We direct interested readers to the above references for further details of the datasets and methods.

\textbf{Model Configurations}. We perform the grid search on the small-scale tgbl-wiki and tgbn-trade datasets to find the optimal configurations of several critical hyperparameters of various methods. Due to the limitations of computational resources, we treat the optimal hyperparameters of baselines on tgbl-wiki/tgbn-trade as the default setting and apply it to other dynamic link/node property prediction datasets. More comprehensive selections of the hyperparameters are expected in the future. Please see \secref{section-appendix-configurations} for details of the grid search as well as the detailed configurations of various models.

\textbf{Implementation Details}. Following \cite{yu2023towards}, we use Adam as the optimizer. We train models that contain learnable parameters (i.e., excluding EdgeBank, Persistent Forecast, and Moving Average) for 100 epochs and use the early stopping strategy with the patience of 20 or 10 (used when the model training speed is slow). The model that performs best on the validation set is selected for testing. We set the learning rate and batch size to 0.0001 and 200 for all the methods on all the datasets. We run the methods five times and report the average performance to eliminate deviations. The experiments are conducted on an NVIDIA GeForce RTX 3090 with 24 GB memory, and an NVIDIA Tesla V100 GPU with 32 GB memory is used for models with more computational costs.


\subsection{Performance for Dynamic Link Property Prediction}
We report the performance of different methods for dynamic link property prediction in \tabref{tab:mrr_dynamic_link_property_prediction}. The best and second-best results are emphasized by \textbf{bold} and \underline{underlined} fonts. The results are multiplied by 100 for a better display layout. Note that some results are missing since the models either took too long to train or raised an out-of-memory issue on GPU. Numbers in \textcolor{red}{red} mean that we cannot obtain results due to computational cost issues and instead use the numbers reported in \cite{huang2023temporal} (although some of them may be not so rigorous).

\begin{table}[!htbp]
\centering
\caption{MRR for dynamic link property prediction, where Val is the abbreviation of Validation.}
\label{tab:mrr_dynamic_link_property_prediction}
\resizebox{1.01\textwidth}{!}
{
\setlength{\tabcolsep}{0.5mm}
{
\begin{tabular}{c|c|ccccc}
\hline
        Sets                     & Methods                 & tgbl-wiki-v2  & tgbl-review-v2  & tgbl-coin & tgbl-comment & tgbl-flight \\ \hline
\multirow{12}{*}{Val} & JODIE                   &  71.42 $\pm$ 0.76          &  \textbf{34.76 $\pm$ 0.06}    &           &              &             \\
                             & DyRep                   &  59.38 $\pm$ 1.82          &  \underline{33.85 $\pm$ 0.18}  &    \textcolor{red}{50.70 $\pm$ 2.90}         &    \textcolor{red}{29.10 $\pm$ 2.80}          &    \underline{\textcolor{red}{52.80 $\pm$ 2.20}}         \\
                             & TGAT                   &  65.14 $\pm$ 1.22    &    17.24 $\pm$ 0.89       &   59.96 $\pm$ 1.39        &     50.73 $\pm$ 2.47         &             \\
                             & TGN                    &  73.80 $\pm$ 0.39        &     33.17 $\pm$ 0.13    &  \textcolor{red}{59.40 $\pm$ 2.30}         &    \textcolor{red}{35.60 $\pm$ 1.90}          &     \textbf{\textcolor{red}{73.90 $\pm$ 1.20}}        \\
                             & CAWN                   &  75.36 $\pm$ 0.34       &     \textcolor{red}{20.00 $\pm$ 0.10}      &           &              &             \\
                             & EdgeBank$_\infty$       &  56.13 $\pm$ 0.00  &  2.29 $\pm$ 0.00  &      31.54 $\pm$ 0.00       &    \textcolor{red}{10.87 $\pm$ 0.00}          &    \textcolor{red}{16.60 $\pm$ 0.00}         \\
                             & EdgeBank$_\text{tw-ts}$  &  66.51 $\pm$ 0.00  &  2.90 $\pm$ 0.00  &     49.67 $\pm$ 0.00      &     \textcolor{red}{12.44 $\pm$ 0.00}         &    \textcolor{red}{38.80 $\pm$ 0.00}         \\
                             & EdgeBank$_\text{tw-re}$  &  68.82 $\pm$ 0.00  &  2.98 $\pm$ 0.00  &    54.51 $\pm$ 0.00        &              &             \\
                             & EdgeBank$_\text{th}$   &  53.77 $\pm$ 0.00   &  1.98 $\pm$ 0.00  &     41.99 $\pm$ 0.00       &              &             \\
                             & TCL                   &  \underline{80.82 $\pm$ 0.14}   &   17.99 $\pm$ 1.72     &     62.97 $\pm$ 0.66         &      \underline{65.10 $\pm$ 0.67}       &             \\
                             & GraphMixer          &  63.87 $\pm$ 0.53        &    28.28 $\pm$ 2.07       &    \underline{70.38 $\pm$ 1.69}        &     \textbf{70.19 $\pm$ 0.23}         &             \\
                             & DyGFormer             &  \textbf{81.62 $\pm$ 0.46}       &    21.92 $\pm$ 1.74      &    \textbf{72.89 $\pm$ 0.07}       &      61.33 $\pm$ 0.27        &             \\ \hline
\multirow{12}{*}{Test}       & JODIE                 &  63.05 $\pm$ 1.69        &   \textbf{41.43 $\pm$ 0.15}     &           &              &             \\
                             & DyRep                  &  51.91 $\pm$ 1.95     &     \underline{40.06 $\pm$ 0.59}      &     \textcolor{red}{43.40 $\pm$ 3.80}      &    \textcolor{red}{28.90 $\pm$ 3.30}          &     \underline{\textcolor{red}{54.30 $\pm$ 2.40}}        \\
                             & TGAT                   &    59.94 $\pm$ 1.63    &    19.64 $\pm$ 0.23       &   60.88 $\pm$ 1.25        &    56.20 $\pm$ 2.11          &             \\
                             & TGN                     &  68.93 $\pm$ 0.53       &    37.48 $\pm$ 0.23       &    \textcolor{red}{58.30 $\pm$ 5.00}        &   \textcolor{red}{37.90 $\pm$ 2.10}            &    \textbf{\textcolor{red}{70.60 $\pm$ 1.60}}         \\
                             & CAWN                     &  73.04 $\pm$ 0.60      &     \textcolor{red}{19.30 $\pm$ 0.10}      &           &              &             \\
                             & EdgeBank$_\infty$      &  52.50 $\pm$ 0.00  &  2.29 $\pm$ 0.00  &      35.90 $\pm$ 0.00       &   \textcolor{red}{12.85 $\pm$ 0.00}           &   \textcolor{red}{16.70 $\pm$ 0.00}          \\
                             & EdgeBank$_\text{tw-ts}$ &  63.25 $\pm$ 0.00   &  2.94 $\pm$ 0.00  &      57.36 $\pm$ 0.00      &   \textcolor{red}{14.94 $\pm$ 0.00}           &   \textcolor{red}{36.40 $\pm$ 0.00}          \\
                             & EdgeBank$_\text{tw-re}$  &  65.88 $\pm$ 0.00    &  2.84 $\pm$ 0.00  &    59.16  $\pm$ 0.00        &              &             \\
                             & EdgeBank$_\text{th}$    &  52.81 $\pm$ 0.00   &  1.97 $\pm$ 0.00  &       43.36 $\pm$ 0.00       &              &             \\
                             & TCL                    &  \underline{78.11 $\pm$ 0.20}  &  16.51 $\pm$ 1.85  &     63.95 $\pm$ 0.62          &    \underline{70.11 $\pm$ 0.83}        &             \\
                             & GraphMixer              &  59.75 $\pm$ 0.39      &     36.89 $\pm$ 1.50     &   \underline{73.25 $\pm$ 1.75}         &      \textbf{76.17 $\pm$ 0.17}        &             \\
                             & DyGFormer               &  \textbf{79.83 $\pm$ 0.42}     &     22.39 $\pm$ 1.52     &    \textbf{74.88 $\pm$ 0.04}       &      67.03 $\pm$ 0.14        &             \\ \hline
\end{tabular}
}
}
\end{table}

From \tabref{tab:mrr_dynamic_link_property_prediction}, we have two key observations. 
Firstly, different methods show varying performance on different datasets, demonstrating their unique characteristics as well as the diversity of datasets. Moreover, trainable parametric methods can always perform better than the non-parametric EdgeBank, which indicates the complexity of the dynamic link property prediction task. Secondly, compared with \cite{huang2023temporal}, the performance of some baselines (e.g., DyRep, TGN, TCL, and GraphMixer) can be effectively promoted when using DyGLib as the backbone, which proves the importance of introducing a unified library for dynamic graph learning methods \cite{yu2023towards}.

\subsection{Performance for Dynamic Node Property Prediction}
We report the results of dynamic node property prediction in \tabref{tab:ndcg_dynamic_node_property_prediction}. We find that (\romannumeral1) simple non-trainable Persistent Forecast and Moving Average methods can achieve surprisingly good performance than other trainable methods; (\romannumeral2) current popular dynamic graph learning methods mainly focus on link-based tasks and cannot obtain satisfactory results on node-based tasks, which indicates the necessity of designing specialized models for the dynamic node property prediction task.

\begin{table}[!htbp]
\caption{NDCG for dynamic node property prediction.}
\label{tab:ndcg_dynamic_node_property_prediction}
\resizebox{1.01\textwidth}{!}
{
\setlength{\tabcolsep}{1.0mm}
{
\begin{tabular}{c|cc|cc|cc}
\hline
Methods             & \multicolumn{2}{c|}{tgbn-trade} & \multicolumn{2}{c|}{tgbn-genre} & \multicolumn{2}{c}{tgbn-reddit} \\ \hline
                    & Validation     & Test           & Validation     & Test           & Validation        & Test        \\ \hline
JODIE               & 39.35 $\pm$ 0.05   & 37.43 $\pm$ 0.09   &    35.79 $\pm$ 0.03            &    34.99 $\pm$ 0.04            &     34.64 $\pm$ 0.02              &    31.39 $\pm$ 0.01         \\
DyRep               & 39.48 $\pm$ 0.14   & 37.50 $\pm$ 0.07   &     36.00 $\pm$ 0.04           &    35.22 $\pm$ 0.03            &        34.64 $\pm$ 0.01           &    31.40 $\pm$ 0.01        \\
TGAT                & 39.31 $\pm$ 0.01   & 37.40 $\pm$ 0.06   &      35.77 $\pm$ 0.01          &    34.95 $\pm$ 0.01            &      34.65 $\pm$ 0.01             &     31.40 $\pm$ 0.01        \\
TGN                 & 39.35 $\pm$ 0.07   & 37.39 $\pm$ 0.06   &      35.92 $\pm$ 0.06          &    35.18 $\pm$ 0.05            &      34.67 $\pm$ 0.02          &      	31.42 $\pm$ 0.01       \\
CAWN                &    39.28 $\pm$ 0.07            &  37.35 $\pm$ 0.09              &                &                &                   &             \\
TCL                 & 39.41 $\pm$ 0.11   & 37.46 $\pm$ 0.09   &     36.23 $\pm$ 0.04           &   35.44 $\pm$ 0.02             &  34.68 $\pm$ 0.01                 &     31.43 $\pm$ 0.01         \\
GraphMixer          & 39.44 $\pm$ 0.17   & 37.47 $\pm$ 0.11   &     36.06 $\pm$ 0.04          &     35.23 $\pm$ 0.03           &    34.67 $\pm$ 0.01               &    31.42 $\pm$ 0.01         \\
DyGFormer           & 40.77 $\pm$ 0.58   & 38.78 $\pm$ 0.64   &     \underline{37.09 $\pm$ 0.06}           &    \underline{36.51 $\pm$ 0.20}            &      34.84 $\pm$ 0.02             &    31.56 $\pm$ 0.01         \\
Persistent Forecast & \textbf{86.72 $\pm$ 0.00}   & \textbf{84.69 $\pm$ 0.00}   & 35.24 $\pm$ 0.00   & 35.96 $\pm$ 0.00   &     \underline{37.99 $\pm$ 0.00}           & \underline{37.72 $\pm$ 0.00}          \\
Moving Average      & \underline{84.25 $\pm$ 0.00}   & \underline{80.93 $\pm$ 0.00}   & \textbf{50.74 $\pm$ 0.00}   & \textbf{51.79 $\pm$ 0.00}   &    \textbf{57.41 $\pm$ 0.00}             &    \textbf{56.24 $\pm$ 0.00}     \\ \hline
\end{tabular}
}
}
\end{table}



% \subsection{Existing Issues in TGB} \label{section-2-issues} 
% During the experiments, we find some problems in the current version of TGB (until July 22, 2023).

% \textbf{Mismatched Data Statistics}. The numbers of nodes and links on datasets for dynamic node property prediction reported in \cite{huang2023temporal} are inconsistent with those in the released datasets\footnote{Please see \url{https://github.com/shenyangHuang/TGB/issues/49} for more details.}. We show the differences (colored in \textcolor{red}{red}) in \tabref{tab:different_data_statistics}. The mismatch of node numbers in tgbn-genre and tgbn-reddit is because these two datasets are bipartite graphs but the reported numbers are only about users. The mismatch of link numbers is indeed an inconsistency that needs to be resolved. It is desired to revise the mismatched data statistics issue in the future version of \cite{huang2023temporal}.


% \begin{table}[!htbp]
% \centering
% \caption{Differences in data statistics.}
% \label{tab:different_data_statistics}
% \setlength{\tabcolsep}{1.25mm}
% {
% \begin{tabular}{c|cccc}
% \hline
% Datasets    & Reported \#Nodes     & Released \#Nodes & Reported \#Links   & Released \#Links     \\ \hline
% tgbn-trade   &   255    & 255  & \textcolor{red}{507,497}   & \textcolor{red}{468,245}       \\
% tgbn-genre      &   \textcolor{red}{992}    & \textcolor{red}{1,505} & 17,858,395   & 17,858,395      \\
% tgbn-reddit    & \textcolor{red}{11,068}  & \textcolor{red}{11,766}   & 27,174,118 & 27,174,118     \\ \hline
% \end{tabular}
% }
% \end{table}

% \textbf{Inaccurate Evaluation Metric Computation}. The calculation of the NDCG metric on dynamic node property prediction is problematic. The computed results of each time slot are divided by the number of examples rather than the number of time slots
% \footnote{See https://github.com/shenyangHuang/TGB/blob/b859771c6aa94bae2207f9e0856430caf88f85c1/examples/nodeproppred/tgbn-trade/tgn.py\#L197 as an example.}, leading to extremely low performance of the baselines (i.e., all of the reported NDCGs in \cite{huang2023temporal} are lower than 0.01). 
% % Moreover, it seems that labels in the last time slot are ignored for evaluation\footnote{See \url{https://github.com/shenyangHuang/TGB/issues/49} for more details.}.

% \textbf{Potential Numerical Errors in Loss Function}. In the TGB repository\footnote{https://github.com/shenyangHuang/TGB/blob/b859771c6aa94bae2207f9e0856430caf88f85c1/modules/decoder.py\#L39}, the node predictor provides the outputs computed by log\_softmax function. Moreover, the dynamic node property prediction is optimized by nn.CrossEntropyLoss\footnote{See https://github.com/shenyangHuang/TGB/blob/b859771c6aa94bae2207f9e0856430caf88f85c1/examples/nodeproppred/tgbn-trade/tgn.py\#L95 as an example.}. However, the nn.CrossEntropyLoss expects raw logits as inputs, and it will apply log softmax to the logits internally. Feeding the outputs computed by log\_softmax function into nn.CrossEntropyLoss would potentially obtain incorrect values. 
% % Moreover, according to the descriptions in \cite{huang2023temporal}, it seems that we should treat the dynamic node property prediction task as a multi-label classification instead of a multi-class classification problem. Therefore, we attempt to use nn.MultiLabelSoftMarginLoss to optimize models.

% \textbf{Suboptimal Model Performance}. Most of the baselines' results reported in \cite{huang2023temporal} are relatively low, and they can be significantly improved when building the project based on DyGLib.

% This work makes an initial attempt to address the above problems and it will be encouraging to see efforts from the community for better solutions.


% \begin{table}[!htbp]
% \centering
% \caption{MRR for dynamic link property prediction, where Val is the abbreviation of Validation.}
% \label{tab:mrr_dynamic_link_property_prediction_complete}
% \resizebox{1.01\textwidth}{!}
% {
% \setlength{\tabcolsep}{0.5mm}
% {
% \begin{tabular}{c|c|ccccccc}
% \hline
%         Sets                     & Methods                 & tgbl-wiki-v1  & tgbl-wiki-v2  & tgbl-review-v1  & tgbl-review-v2  & tgbl-coin & tgbl-comment & tgbl-flight \\ \hline
% \multirow{12}{*}{Val} & JODIE                   & 79.44 $\pm$ 0.17 &  71.42 $\pm$ 0.76  &    \textbf{47.85 $\pm$ 0.84}          &      &           &              &             \\
%                              & DyRep                   & 76.08 $\pm$ 0.27 &  59.38 $\pm$ 1.82  &    \textcolor{red}{35.60 $\pm$ 1.60}          &  \textcolor{red}{21.60 $\pm$ 3.10}  &    \textcolor{red}{50.70 $\pm$ 2.90}         &    \underline{\textcolor{red}{29.10 $\pm$ 2.80}}          &    \underline{\textcolor{red}{52.80 $\pm$ 2.20}}         \\
%                              & TGAT                    & 82.57 $\pm$ 0.51 &    &    40.73 $\pm$ 2.47       &           &   59.96 $\pm$ 1.39        &              &             \\
%                              & TGN                     & \textbf{85.81 $\pm$ 0.07} &  73.80 $\pm$ 0.39  &     \underline{\textcolor{red}{46.50 $\pm$ 1.00}}       &     \underline{\textcolor{red}{31.30 $\pm$ 1.20}}     &  \textcolor{red}{59.40 $\pm$ 2.30}         &    \textbf{\textcolor{red}{35.60 $\pm$ 1.90}}          &     \textbf{\textcolor{red}{73.90 $\pm$ 1.20}}        \\
%                              & CAWN                    & 79.82 $\pm$ 0.12 &  \textcolor{red}{74.30 $\pm$ 0.40}  &  29.72 $\pm$ 1.57       &     \textcolor{red}{20.00 $\pm$ 0.10}      &           &              &             \\
%                              & EdgeBank$_\infty$       & 55.11 $\pm$ 0.00 &  56.13 $\pm$ 0.00 & 7.86 $\pm$ 0.00   &  2.29 $\pm$ 0.00  &      31.54 $\pm$ 0.00       &    \textcolor{red}{10.87 $\pm$ 0.00}          &    \textcolor{red}{16.60 $\pm$ 0.00}         \\
%                              & EdgeBank$_\text{tw-ts}$ & 64.09 $\pm$ 0.00 &  66.51 $\pm$ 0.00  & 9.78 $\pm$ 0.00  &  2.90 $\pm$ 0.00  &     49.67 $\pm$ 0.00      &     \textcolor{red}{12.44 $\pm$ 0.00}         &    \textcolor{red}{38.80 $\pm$ 0.00}         \\
%                              & EdgeBank$_\text{tw-re}$ & 58.90 $\pm$ 0.00 &  68.82 $\pm$ 0.00  & 10.03 $\pm$ 0.00 &  2.98 $\pm$ 0.00  &             &              &             \\
%                              & EdgeBank$_\text{th}$    & 55.25 $\pm$ 0.00 &  53.77 $\pm$ 0.00  & 9.05 $\pm$ 0.00  &  1.98 $\pm$ 0.00  &     41.99 $\pm$ 0.00       &              &             \\
%                              & TCL                     & 82.99 $\pm$ 0.84 &  \underline{80.82 $\pm$ 0.14}  & 35.33 $\pm$ 0.47 &   \textcolor{red}{19.90 $\pm$ 0.70}     &     62.97 $\pm$ 0.66         &             &             \\
%                              & GraphMixer              & 83.98 $\pm$ 0.09 &  63.87 $\pm$ 0.53  &  43.69 $\pm$ 0.53       &    \textbf{\textcolor{red}{42.80 $\pm$ 1.90}}       &    \underline{70.38 $\pm$ 1.69}        &              &             \\
%                              & DyGFormer               & \underline{85.75 $\pm$ 0.08} &  \textbf{81.62 $\pm$ 0.46}  &    36.50 $\pm$ 2.87      &          &    \textbf{72.89 $\pm$ 0.07}       &              &             \\ \hline
% \multirow{12}{*}{Test}       & JODIE                   & 77.15 $\pm$ 0.22 &  63.05 $\pm$ 1.69  &    \textbf{54.97 $\pm$ 0.91}        &        &           &              &             \\
%                              & DyRep                   & 73.37 $\pm$ 0.22 &  51.91 $\pm$ 1.95  &    \textcolor{red}{36.70 $\pm$ 1.30}     &     \textcolor{red}{22.00 $\pm$ 3.00}      &     \textcolor{red}{43.40 $\pm$ 3.80}      &    \underline{\textcolor{red}{28.90 $\pm$ 3.30}}          &     \underline{\textcolor{red}{54.30 $\pm$ 2.40}}        \\
%                              & TGAT                    & 79.89 $\pm$ 0.52 &    &  45.50 $\pm$ 2.57       &           &   60.88 $\pm$ 1.25        &              &             \\
%                              & TGN                     & \underline{84.30 $\pm$ 0.32} &  68.93 $\pm$ 0.53  &   \underline{\textcolor{red}{53.20 $\pm$ 2.00}}      &    \underline{\textcolor{red}{34.90 $\pm$ 2.00}}       &    \textcolor{red}{58.30 $\pm$ 5.00}        &   \textbf{\textcolor{red}{37.90 $\pm$ 2.10}}            &    \textbf{\textcolor{red}{70.60 $\pm$ 1.60}}         \\
%                              & CAWN                    & 78.15 $\pm$ 0.09 &  \textcolor{red}{71.10 $\pm$ 0.60}  &  34.43 $\pm$ 1.39       &     \textcolor{red}{19.30 $\pm$ 0.10}      &           &              &             \\
%                              & EdgeBank$_\infty$       & 53.76 $\pm$ 0.00 &  52.50 $\pm$ 0.00  & 7.95 $\pm$ 0.00  &  2.29 $\pm$ 0.00  &      35.90 $\pm$ 0.00       &   \textcolor{red}{12.85 $\pm$ 0.00}           &   \textcolor{red}{16.70 $\pm$ 0.00}          \\
%                              & EdgeBank$_\text{tw-ts}$ & 63.87 $\pm$ 0.00 &  63.25 $\pm$ 0.00  & 9.99 $\pm$ 0.00  &  2.94 $\pm$ 0.00  &      57.36 $\pm$ 0.00      &   \textcolor{red}{14.94 $\pm$ 0.00}           &   \textcolor{red}{36.40 $\pm$ 0.00}          \\
%                              & EdgeBank$_\text{tw-re}$ & 55.94 $\pm$ 0.00 &  65.88 $\pm$ 0.00  & 9.90 $\pm$ 0.00  &  2.84 $\pm$ 0.00  &              &              &             \\
%                              & EdgeBank$_\text{th}$    & 55.11 $\pm$ 0.00 &  52.81 $\pm$ 0.00  & 9.05 $\pm$ 0.00  &  1.97 $\pm$ 0.00  &       43.36 $\pm$ 0.00       &              &             \\
%                              & TCL                     & 80.68 $\pm$ 0.79 &  \underline{78.11 $\pm$ 0.20}  & 36.13 $\pm$ 0.54 &  \textcolor{red}{19.30 $\pm$ 0.90}  &     63.95 $\pm$ 0.62          &            &             \\
%                              & GraphMixer              & 82.38 $\pm$ 0.16 &  59.75 $\pm$ 0.39  &  53.12 $\pm$ 0.22       &     \textbf{\textcolor{red}{52.10 $\pm$ 1.50}}      &   \underline{73.25 $\pm$ 1.75}         &              &             \\
%                              & DyGFormer               & \textbf{85.03 $\pm$ 0.05} &  \textbf{79.83 $\pm$ 0.42}  &    39.10 $\pm$ 2.24     &          &    \textbf{74.88 $\pm$ 0.04}       &              &             \\ \hline
% \end{tabular}
% }
% }
% \end{table}
