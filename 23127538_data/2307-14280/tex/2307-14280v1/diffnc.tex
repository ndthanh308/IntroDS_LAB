
\section{Differential Network Calculus}
\label{sec:diffnc}

The steps towards computing a delay bound as described in \Cref{sec:dncintro} cater to an analysis that requires a fully specified model.
I.e., in case there are design alternatives, each of these needs to be fully specified and analyzed independently.
A related topic are \ac{NC} analyses that explore alternative orders of (min,plus)-operations internally.
There, exhaustive enumeration may be feasible \cite{Bondorf2017a} but is often prohibitive \cite{Bondorf2017c}.
For either case, it was shown to be possible to design heuristics that vastly increase efficiency at little cost in terms of loss of delay bound accuracy \cite{Geyer2019b,2023-GSB-1}.
We propose \acl{DiffNC} (\acs{DiffNC}) that allows applying gradient-based \ac{NLP} to efficiently find a design alternative in a design space, subject to \ac{NC} delay bounds and at very low cost loss of accuracy.

\subsection{Generalized, parameterized \ac{NC} model}
\label{sec:formulation}

We generalize the server graph model of \ac{NC} to a more comprehensive, parameterized one where newly added parameters define design space alternatives.
We simply allow each variable in the model (e.g., those defining an arrival or service curve) to remain open and each part of the \ac{NC} model (e.g., entire curves) to be accompanied by an open parameter.
The added parameters can, e.g., be binary to decide whether the parameterized part of the model is to be considered;
continuous parameters can be added for weighing parameterized parts.
Combinations of parameters can also be restricted to express certain mutually exclusive design alternatives.
Without further restrictions on the parameters or their combinations, finding a parameter setting may become a \ac{MINLP}.
In this article, we exemplarily consider two instances of the generalized, parameterized \ac{NC} model.

\subsubsection{Alternative flow paths}
\label{sec:path_assignment}

Let $\mathcal{G} = (\mathcal{S}, \mathcal{E})$ be the server graph of the analyzed communication network and let $\mathcal{F}$ be the set of flows crossing $\mathcal{G}$.
We adopt here a path flow model, where each flow $f_i\in\mathcal{F}$ is associated with multiple alternative paths $\mathcal{P}_{f_i}$.
We amend each potential path $j \in \mathcal{P}_{f_i}$, or rather the data sent over $j$ by $f_i$, with a binary variable $p_{f_{i,j}}$ such that \cref{eq:arrival_curve} becomes:
\begin{equation} \label{eq:vitual_arrival_curve}
	\forall\,0\leq d\le t\,:\, A_{f_{i,j}}(t) - A_{f_{i,j}}(t-d) \leq \alpha_{f_i}(d) \cdot p_{f_{i,j}}
\end{equation}

To express that only a single path can be taken by a flow, we add the following constraint to our model:
\begin{equation} \label{eq:p_ij_sum}
	\sum_{j \in \mathcal{P}_{f_i}} p_{f_{i,j}} = 1, \forall f_i \in \mathcal{F}
\end{equation}

We call the alternatives along the different potential paths \emph{virtual flows}.
Virtual flow arrival curves would then be set to $0$ on the non-optimal paths, and remain constrained by $\alpha_{f_i}$ on the optimal paths.
See \cref{fig:illustration_virtual_flow} for an illustration of the model.

% Figure environment removed



Due to our formulation, servers may be overloaded, leading to invalid network configurations.
Hence the following constraint is required for each server $s$ in the server graph:
\begin{equation}
	\sum_{f \in \mathcal{F}_s} \mathit{rate}_f \leq \mathit{rate}_s
\end{equation}
with $\mathcal{F}_s$ the set of flows traversing server $s$.


As expected, we essentially defined a \ac{MINLP}, a combinatorial optimization problem with a number of potential solutions growing in $\mathcal{O}(|\mathcal{F}|^{|\mathcal{P}|})$.


\subsubsection{Flow priority assignment}

We can use the virtual flow concept to define the search space for (network-wide) priority assignment.
Namely, a flow $f_i$ is extended to a set of virtual flows, one for each priority class.
For each virtual flow of $f_i$ with its potential path $j$ and potential priority class $k$, we define $p_{f_{i,j,k}}$ as a binary variable representing the choice of path $j$ and priority $k$ for flow $f_i$.
The arrival curve of each virtual flow is then amended by $p_{f_{i,j,k}}$, analog to \cref{eq:vitual_arrival_curve}. 
Again, the sum of $p_{f_{i,j,k}}$ variable must be equal to $1$ to enforce that only one virtual flow is selected, i.e., only one path and priority class are globally defined per flow.
\Cref{fig:illustration_virtual_priority} illustrates this model.

% Figure environment removed


\subsection{Generalized \ac{NC} analysis by constrained \ac{NLP}}
\label{sec:constr_nlp}

Traditional \ac{NC} analyses such as \ac{SFA} would not be able to capture the virtual flow model.
Their backtracking of flow dependencies can succeed by ignoring the newly introduced binary variables, 
i.e, by including all alternatives of a virtual flow in the resulting (min,plus)-algebraic \ac{NC} term.
Analysis results are then valid, yet, overly pessimistic.
For an example of this practice, see \cite{2016-BG-1} where multicast flows are converted into a set of partially overlapping unicast flows.
If we extended the resulting (min,plus)-algebraic \ac{NC} term with the binary variables, then any unchanged traditional analyses would not be able to analyze this term anymore.
To solve this problem, we propose to use nonlinear optimization as analysis method.

\subsubsection{Closed-form expressions}

First, we need to derive closed-form expressions of the \ac{NC} operations presented in \cref{def:MinPlusOperations}.
We restrict our models to the curves shapes most commonly used in practice for industrial networks:
the rate-latency service curve $\beta_{R,L}$ and the token-bucket arrival curve $\gamma_{r,B}$:
\begin{eqnarray}
	\beta_{R,L}(t) & = & R [t - L]^+, \forall t \geq 0 \\
	\gamma_{r,B}(t) & = & B + r \cdot t, \forall t \geq 0
\end{eqnarray}
with $R$, $L$, $r$, and $B$ in $\R^+$, and $[x]^+ = x$ if $x \geq 0$ and 0 otherwise.

Applying \ac{NC}'s (min,plus)-algebraic operations to the above curve shapes, the following closed-form expression can be derived:
\begin{lemma}[Closed-form expression of \ac{NC} operations]
	\label{thm:nc_ops}
	With the assumption of using rate-latency service curves and token-bucket arrival curves, the \ac{NC} operations listed in \cref{def:MinPlusOperations} have the following closed-form solutions:
	\begin{eqnarray}
		\text{aggregation:} & \gamma_{r_1,B_1} + \gamma_{r_2,B_2} = \gamma_{r_1+r_2,B_1+B_2} \\
		\text{concatenation:} & \beta_{R_1,L_1} \otimes \beta_{R_2,L_2} = \beta_{\min(R_1, R_2),L_1 + L_2} \\
		\text{output bounding:} & \gamma_{r,B} \oslash \beta_{R,L} = \gamma_{r,B+r \cdot L} \\
		\text{left-over:} & \beta_{R,L} \ominus \gamma_{r,B} = \beta_{R - r, (B + R \cdot L) / (R - r)} \\
		\text{delay bound:} & h(\gamma_{r,B}, \beta_{R,L}) = B / R + L
	\end{eqnarray}
	under the previously mentioned stability condition that $r < R$.
\end{lemma}

Note that we restrict the curve shapes for brevity, our approach is not limited to these curve shapes.
Using different shapes requires to provide the closed-form expressions as in \cref{thm:nc_ops}.
This can be relatively simple, e.g., for concave arrival curves and convex service curves.

\subsubsection{Constrained \ac{NLP} Modeling}

Next, we show here how to model the network design problem as a differentiable \ac{NLP} of the following form:
\begin{align}
\min_{x \in \R^n}      & \quad f(x) \label{eq:general_nonlin_obj} \\
\text{s.t.} & \quad  g_l \leq g(x) \leq g_u \label{eq:general_nonlin_constr}
\end{align}
with $f()$ and $g()$ differentiable functions w.r.t. $x$, and $g_l$ and $g_u$ the upper and lower bounds for $g()$.

To make this problem solvable in polynomial time, we apply a commonly used technique known as relaxation, namely: the $p_{f_{i,j}}$ binary variables are relaxed as continuous variables on the interval $[0, 1]$.
Following \cref{thm:nc_diff}, the end-to-end delay bound expression of a virtual flow is then differentiable w.r.t. the $p_{f_{i,j}}$ variables.
This relaxation technique transforms the \ac{MINLP} into a continuous \ac{NLP}, enabling the use of \ac{NLP} methods based on gradient information.

Using on the previous formulations, we define the following constrained nonlinear optimization problem that minimizes the average delay bound:
\begin{align} \label{eq:nonlin_obj}
	\min_{p_{f_{i,j}}, \forall f_i \in \mathcal{F}, j \in \mathcal{P}_{f_i}} & \quad \frac{1}{|\mathcal{F}|} \sum_{i, j} \textit{delay bound}(f_{i,j}) \cdot p_{f_{i,j}} \\
	\text{s.t.} & \quad 0 \leq p_{f_{i,j}} \leq 1, \forall f_i \in \mathcal{F}, j \in \mathcal{P}_{f_i} \\
	& \quad \sum_{j \in \mathcal{P}_{f_i}} p_{f_{i,j}} = 1, \forall f_i \in \mathcal{F} \\
	& \quad \sum_{i \in T(k)} r_i \cdot p_{f_{i,j}} \leq R_k, \forall k \in \mathcal{S} \label{eq:cstr_server_overload}
\end{align}
with $T(k)$ the set of virtual flows traversing server $k$ with service curve $\beta_{R_k,L_k}$, and $\textit{delay bound}(f_{i,j})$ the end-to-end delay bound of the virtual flow $f_{i,j}$ computed with any of the classical algebraic \ac{NC} analyses (e.g., \ac{SFA}).
Note, that we thus also generalized the analysis to consider the delay bounds of multiple flows $f_{i,j}$ simultaneously
whereas the classical analyses can only analyze a single flow of interest in isolation.
Due to the operations in \cref{thm:nc_ops}, \cref{eq:nonlin_obj} is a non-convex objective function.


% Figure environment removed


\subsubsection{Extended Analysis Capabilities}

We already showed the ability to consider multiple flows' delay bounds simultaneously.
With our formulation, we also enable a wider range of constraints and objective functions.
Constraints can be added such that a maximum delay requirement is satisfied for a given flow, saving us a subsequent check against the requirement:
\begin{equation} \label{eq:delay_req}
	\sum_{j \in \mathcal{P}_{f_i}} \textit{delay bound}(f_{i,j}) \cdot p_{f_{i,j}} \leq \textit{requirement}
\end{equation}

This formulation is able to express complex objectives, enabling finer control over the type of solution which is required.
A popular mathematical framework for describing hard or soft requirements on network performance (such as delay or bandwidth) is the concept of utility-based network optimization introduced in \cite{Kelly1998}.
The objective function can be formulated with nonlinear utility functions $U_i$ for the delay bounds:
\begin{equation}
	\min_{p_{f_{i,j}}, \forall i, j} \sum_{i} U_i \left(\sum_j \textit{delay bound}(f_{i,j}) \cdot p_{f_{i,j}} \right)
\end{equation}
with $U_i$ a differentiable utility function mapping the delay bonds to a utility value in the interval $[0, 1]$.

Additionally, aspects such as the tail of the delay bound distribution can be minimized by defining the objective function:
\begin{equation}
	\min_{p_{f_{i,j}}, \forall i, j} \max_{i} \left(\sum_j \textit{delay bound}(f_{i,j}) \cdot p_{f_{i,j}} \right)
\end{equation}

The optimization formulation can be applied to any curve parameter, including the service curve parameters.
This means that the optimization formulation can also be defined w.r.t. scheduler characteristics.


\subsection{Differentiation of expressions for gradient-based \ac{NLP}}
\label{sec:diff_delay_term}

\ac{NLP} techniques based on gradient information -- such as Newton's method -- are known to usually outperform other \ac{NLP} optimization techniques.
Therefore, we show here that the delay bounding terms as well as the constraints are differentiable and confirm later in \cref{sec:numerical_evaluation} that this is key to a high performance analysis.

From \cref{thm:nc_ops}, the following theorem is derived:
\begin{theorem}[Differentiability of delay expression]
	\label{thm:nc_diff}
	With the assumption of using rate-latency service curves and token-bucket arrival curves, a \ac{NC} end-to-end delay bound is differentiable w.r.t. the curves parameters.
\end{theorem}

\textit{Proof:} Using the closed-form (min,plus) operations from \cref{thm:nc_ops}, all \ac{NC} operations use the following basic operators: addition, multiplication, division and min.
For the $\min$ operator, we use the following partial derivates for $x \neq y$:
\begin{align*}
	\frac{\partial \min(x, y)}{\partial x} = \begin{cases}
		1 \text{, if } x < y \\
		0 \text{, if } x > y
	\end{cases} & & \frac{\partial \min(x, y)}{\partial y} = \begin{cases}
	0 \text{, if } x < y \\
	1 \text{, if } x > y
	\end{cases}
\end{align*}
All of the applied operators are then differentiable, proving \cref{thm:nc_diff}.
\hfill $\square$

Partial derivates for the min operator used in the above proof are easily implemented using the Heaviside step function.

Following the previous theorems, \crefrange{eq:nonlin_obj}{eq:cstr_server_overload} are differentiable w.r.t the relaxed $p_{f_{i,j}}$ variables.


\section{Automatic differentiation and optimization} %
\label{sec:diffnc_ad}

The previous theorems build the mathematical foundations of \ac{DiffNC}.
Connecting them to the conceptual \ac{DiffNC} proceeding is straight-forward.
\Cref{fig:system_overview} illustrates the steps.
We detail here how to put \ac{DiffNC} into practice in order to efficiently compute partial derivatives of the end-to-end delay bounds w.r.t. the curves parameters.
We also present a preliminary numerical evaluation of the performances of our toolchain.


\subsection{Software architecture}

While computer-assisted symbolic differentiation could be used for deriving closed-form expressions of the gradient, our initial numerical evaluations with SymPy \cite{Meurer2017} showed that this method had difficulties scaling to networks with 100+ flows.

To overcome this scalability issues, we selected \ac{AD}.
It is a family of techniques based on the calculus' chain rule for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs.
This technique has gained a lot of popularity recently due its wide use in computing packages used for machine learning \cite{Baydin2018}.

While the first version of \ac{DiffNC} from \cite{GeyerBondorf_INFOCOM2022} was based on CasADi \cite{Andersson2019}, we implemented our own \acf{AD} tool in Go for this work, specialized for (min,plus) operations and delay bound calculations.
As shown later in \cref{sec:eval:toolchain,sec:eval:execution_time}, our implementation enables us better scalability on large networks and to parallelize various parts of the code.
This stems from the fact that most available \ac{AD} tools are targeting relatively small computation graphs (i.e. series of mathematical operations described as a directed graph) with arithmetically intense operations such as large matrix multiplications.
This specialization makes these tools poorly scalable for \ac{NC} operations, as millions of (min,plus) operations are required to compute delay bounds in our use-cases.
Our tool also directly uses the (min,plus) operations, enabling a better scalability compared to a conversion to basic mathematical operations.

As network analysis, we choose \ac{SFA} and execute its backtracking to derive a (min,plus)-algebraic \ac{NC} term.
Then we extend the term with the $p_{f_{i,j}}$ binary variables (see \cref{sec:formulation}) and convert it to closed form expressions in (plus,times) algebra according to \cref{thm:nc_ops}.
Combined with nonlinear optimization methods using gradients -- as detailed later in \cref{sec:diffnc_implementation} -- our generalized network models can efficiently be optimized.

Additionally, since most optimization methods require multiple evaluations of the objective function, our tool also allows us to run the \ac{NC} network analysis a single time and generate a so-called computation graph.
This graph translates the delay expressions (i.e., the objective function) to a combination of basic mathematical operations (addition, multiplication, etc.) and (min,plus) operations.
These saved operations can then be evaluated multiple times in our so-called \emph{\ac{DiffNC} \ac{VM}}, without requiring to run the \ac{NC}-specific parts again.

A network to-be-optimized with alternative flow paths is used as input of our framework.
Based on the end-to-end delay bounds calculations, the computation graph of the objective function and its gradient, and the constraint functions and its gradients, are then generated and compiled for our \ac{DiffNC} \ac{VM}.
The compiled formulas are then used as input to a nonlinear optimizer supporting the generalized \ac{NLP} presented in \cref{eq:general_nonlin_obj,eq:general_nonlin_constr}.


\subsection{The Frank-Wolfe algorithm}
\label{sec:fw}

We detail here the nonlinear optimization part using gradient-based constrained optimization methods with open-source implementations.

We selected the Frank-Wolfe algorithm \cite{Frank1956,Braun2022} -- also known as conditional gradient method -- as our main solution for solving the \ac{NLP} described in \cref{sec:diffnc}.
To optimize a \ac{NLP} with objective function $f$, the Frank-Wolfe algorithm can be summarized as the following loop.
Given a solution $x_k$ at iteration $k$:
\begin{itemize}
	\item \emph{Step 1:} Find the solution $s_k$ to the linearized version of the \ac{NLP} using the gradient information (i.e., $s_k^T \triangledown f(x_k)$),
	\item \emph{Step 2:} Update $x_{k+1} \gets x_k + \delta (s_k - x_k)$.
\end{itemize}
The choice of $\delta$ determines the so-called step size of the Frank-Wolfe algorithm.

While this algorithm was designed to solve convex \ac{NLP}, it was shown to also perform well on non-convex problems in practice by choosing $\delta = 1 / \sqrt{k+1}$ \cite{Braun2022}.
As we show later, it achieves good optimality at a low computational cost.

Several extensions of this algorithm have been proposed in the literature.
We explored some of them and found that its variant with momentum \cite{Braun2022} achieves good results in our problem setting.
Momentum is a technique to build inertia in a direction in the search space in order to overcome the oscillations of noisy gradients.

We implemented the standard Frank-Wolfe algorithm to be our main optimization algorithm in the following evaluations.
\Cref{sec:eval:frankwolfe} provides a peak into the performance of the Frank-Wolfe algorithm with momentum.


\subsection{Implementation details of our toolchain}
\label{sec:eval:toolchain}

We describe and numerically evaluate in this section key elements of our toolchain to enable fast evaluations.
The numerical evaluations were performed on the datasets described later in \cref{sec:dataset}.

\subsubsection{Parallelization}
\label{sec:eval:parallelization}

We evaluate in this section the impact of parallelization of the operations on the \ac{DiffNC} \ac{VM}.
For our implementation, we use different strategies for parallelization.
First, we parallelize the different delay bound computations both during the preparation of the (min,plus) terms and during the execution in the \ac{DiffNC} \ac{VM}.
These computations are independent of each other and our objective function from \cref{eq:nonlin_obj} requires the computation of the delay bounds of all flows in the network.
Secondly, we also parallelized part of the computations during the preparation of the (min,plus) terms of the \ac{SFA} network analysis.

The impact of the parallelization is highlighted in \cref{fig:execution_time_parallelization_afdx}, where the delay bound calculations of all flows from the \ac{AFDX} network were performed.
We notice that, as we increase the number of cores used for the computations, the total execution time of the analysis is reduced.
Overall, a gain of more than one order of magnitude was possible thanks to parallelization.

The benefit of precomputing the (min,plus) computations is also illustrated in \cref{fig:execution_time_parallelization_afdx}.
Running the compiled analysis can be performed 50 times faster than running it without precomputation.

% Figure environment removed




\subsubsection{Impact of VM vs. native code}

Finally, we also benchmark our \ac{DiffNC} \ac{VM} against compiled code, i.e., against the same \ac{NC} operations compiled to Intel assembly.
Results on the \ac{AFDX} topology are presented in \cref{fig:execution_time_comparison_netcalvm_cjit_afdx}.

When comparing the execution time of the (min,plus) operations, the \ac{DiffNC} \ac{VM} is slower than compiled code.
Yet, the cost of compiling the (min,plus) operations to assembly makes it overall slower than using the \ac{DiffNC} \ac{VM}, as shown by the total execution time.

% Figure environment removed
