
\section{Numerical evaluation}
\label{sec:numerical_evaluation}

We evaluate in this section our approach on a wide range of networks.
We illustrate its scalability and compare it against other optimization methods.

\subsection{Competing nonlinear optimization algorithms for \ac{DiffNC}}
\label{sec:diffnc_implementation}

For our evaluation, we also selected \ac{SLSQP}.
It was shown in \cite{GeyerBondorf_INFOCOM2022} to perform the best in terms of optimality.
Finally, we used the \ac{MMA} \cite{Svanberg1987} and in conjunction with an augmented Lagrangian method \cite{Hestenes1969,Powell1969} in order to include the equality constraints from \cref{eq:p_ij_sum}.
For all these algorithms, the implementation from \cite{Johnson2020} is used.

Integer relaxation was used and the final solution is then converted back to integer and verified against the constraints.
Note that these are local optimization methods, each requiring a starting point.
For our evaluation and metrics, a single randomly generated starting point was used.

\subsection{Other heuristics}
\label{sec:otherheuristics}

To benchmark our approach against potential competitors, the following other optimization methods were selected.
They include both na√Øve and greedy approaches, as well as other optimization techniques often used for solving constrained combinatorial problems.
A maximum of 500 evaluations of the objective function has been defined for the heuristics described here.

\subsubsection{Randomized search}
In this greedy approach, $500$ random combinations of paths are chosen and evaluated.
The combination leading to the best objective is presented.
In the figures, this method is labeled as Random.

\subsubsection{Hop-count shortest path}
For this approach, the path minimizing the number of hops for each flow is selected.
This approach does not use other information about the network and is equivalent to a traditional Dijkstra shortest-path algorithm.

\subsubsection{Minimum-delay shortest path}
This approach is similar to the previous one, except that we partially take into account the arrival and service curves in the network.
The minimum delay bound that \iac{NC} end-to-end delay analysis can compute for a flow is in the absence of crosstraffic impact,
e.g., if the flow had highest priority among all flows. 
In that case, the end-to-end delay bound is $h(\gamma_{r,B},\beta_{R_j,L_j}) = L_j+\frac{B}{R_j}$ with $R_j$ the minimum rate on its path $j\in\mathcal{P}_i$ and $L_j$ the sum of server latencies.
We use this as a proxy metric and select the path with minimum end-to-end delay in hypothetical absence of crosstraffic.

\subsubsection{Non-gradient based methods}
We also evaluate the Nelder-Mead \cite{Nelder1965} and Subplex \cite{Rowan1990} algorithms, both direct search methods based on the simplex algorithm.
Both algorithms do not make use of the gradient information.

Our original work \cite{GeyerBondorf_INFOCOM2022} already evaluated other heuristics based on meta-heuristics or evolutionary algorithms.
They were omitted here since our previous evaluation showed that they underperformed compared to \ac{DiffNC}.


\subsection{Evaluated networks}
\label{sec:dataset}

To numerically evaluate our approach, we randomly generated a set of evaluation networks.
First, a random amount of servers was generated, connected in a directed graph.
Each server has a rate-latency service curve, with rate and latency parameters randomly sampled from a uniform distribution.
A random amount of source-destination pairs was then generated for flows, each with a token-bucket arrival curve, with rate and burst parameters randomly sampled from a uniform distribution.
For each pair, a set of virtual flows were generated according to the available paths in the directed graph.

The goal of the optimization is to find the best path and the best priority (high or low, network-wide) for a given flow.
For each network, the minimization of the average end-to-end delay bound of the flows is used as objective function, computed using multicast \ac{SFA} under the assumption of arbitrary multiplexing \cite{2016-BG-1}.

Overall, our dataset contains topologies with up to 1000 flows, matching the number of flows found in some industrial settings \cite{Boyer2012,TamasSelicean2015,Belliardi2018}.
\Cref{tab:dataset:full} contains statistics about the dataset.

\begin{table}[h!]
	\centering
	\caption{Statistics about the generated dataset.}
	\label{tab:dataset:full}
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Number of}    & \textbf{Min} & \textbf{Mean} & \textbf{Median} & \textbf{Max} \\ \midrule
		Servers               &            8 &         17.08 &              16 &           31 \\
		Flows                 &            5 &        170.67 &             164 &         1001 \\
		Virtual flows         &            9 &        355.22 &             343 &         1884 \\
		Path combinations     &    \TP{1.08} &    \TP{46.04} &      \TP{44.10} &  \TP{229.08} \\
		Path + priority comb. &    \TP{2.58} &    \TP{97.41} &      \TP{94.28} &  \TP{530.41} \\ \bottomrule
	\end{tabular}
\end{table}

Additionally for the numerical evaluation performed in \cref{sec:optlp,fig:nclp_networksize_vs_solvetime}, a dataset containing smaller networks was also generated using the same approach.
\Cref{tab:dataset:lpeval} contains relevant statistics about this additional dataset.

\begin{table}[h!]
	\centering
	\caption{Statistics about the networks used for the evaluations in \cref{sec:optlp,sec:eval:optimality}.}
	\label{tab:dataset:lpeval}
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Number of}    & \textbf{Min} & \textbf{Mean} & \textbf{Median} & \textbf{Max} \\ \midrule
		Servers               &            3 &          8.68 &               8 &           18 \\
		Flows                 &            3 &          9.70 &               9 &           21 \\
		Virtual flows         &            4 &         18.62 &              17 &           45 \\
		Path combinations     &    \TP{0.30} &     \TP{2.07} &       \TP{1.81} &    \TP{5.52} \\
		Path + priority comb. &    \TP{1.20} &    \TP{11.32} &       \TP{9.20} &   \TP{32.81} \\ \bottomrule
	\end{tabular}
\end{table}

This is the same dataset as used in \cite{GeyerBondorf_INFOCOM2022}\footnote{Online \texttt{https://github.com/fabgeyer/dataset-infocom2022}}, with the addition that we also optimize for the best priority for a given flow.

Finally, we also used the \ac{AFDX} network from the Airbus A350 as a representative industrial network for our evaluations in \cref{sec:evaluation_afdx,sec:eval:execution_time}.
This network contains approximately 1100 multicast flows with an average of 8 destinations per multicast flow.
In this industrial network, multicast paths are fixed such that we focus only on optimizing the (network-wide) priority of the flows.


\subsection{Reduction of delay bounds}
\label{sec:eval:gaptobest}

We evaluate here the solution of each optimization method presented in \cref{sec:otherheuristics} on our evaluation dataset.
We use here \cref{eq:nonlin_obj} as objective function, i.e., we minimize the average end-to-end delay bound in the networks, an objective function found in many other related works.

We first compare the optimization methods using the result of the hop-count shortest path approach as a baseline.
We use the relative gap of the objective function as our metric, namely:
\begin{equation}
\mathit{RelGapShortestPath}_\text{method} = \frac{\mathit{objective}_\text{method}}{\mathit{objective}_{\text{shortest path}}} - 1
\end{equation}
Since we aim at minimizing delay bounds, a negative value of the relative gap means that the evaluated optimization method achieved better results than simply using shortest path.

Results are presented in \cref{fig:relative_gap_shortest_path}.
\ac{DiffNC} with Frank-Wolfe is able to achieve the best results compared to all the other heuristics evaluated here, closely followed by \ac{SLSQP}.
Overall, Frank-Wolfe achieved a reduction of \SI{39.25}{\percent} of the average delay bounds.
Compared to the non-gradient-based algorithms, all gradient-based optimization methods based on \ac{DiffNC} achieve much better results.
Interestingly, the delay-based shortest path approach is able to surpass the non-gradient-based optimization methods, showing that a simple heuristic using domain knowledge about the model and analysis used in the optimization problem can be somewhat effective.

% Figure environment removed

Given the large number of path combinations in some networks (larger than 10\textsuperscript{530} in some cases), the optimal network configurations are not known and cannot be computed in reasonable time by simply enumerating the combinations.
To address this, we use the best result which was obtained by any evaluated method as a baseline, called here virtual best.
We use the relative gap of the objective function to the best objective as metric:
\begin{equation}
\mathit{RelGapBest}_\text{method} = \frac{\mathit{objective}_\text{method}}{\mathit{objective}_{\text{virtual best}}} - 1
\end{equation}


Results are presented in \cref{fig:relative_gap_best_objective}.
With an average relative gap of \SI{0.25}{\percent}, \ac{DiffNC} with Frank-Wolfe achieves the best results compared to all the other heuristics.
\ac{DiffNC} with \ac{SLSQP} closely follows it with an average relative gap of \SI{0.56}{\percent}.
Both methods outperform all the other heuristics by at least one order of magnitude.
Most observations made from \cref{fig:relative_gap_shortest_path} for the other methods also apply for \cref{fig:relative_gap_best_objective}.
The only noteworthy exception is that the \ac{NLP} algorithms not using gradient information are not beaten by the hop-count shortest path w.r.t. the relative gap to the virtually best method.

% Figure environment removed


\subsection{Optimality gap}
\label{sec:eval:optimality}

We evaluate the gap of \ac{DiffNC} to the optimum found by exhaustive enumeration, restricted to networks from \cref{tab:dataset:lpeval} where the analysis terminates within \SI{1}{\hour}.
\Cref{tab:comparison_bruteforce} shows the results:
\ac{SLSQP} and Frank-Wolfe were able to respectively find the optimum in \SI{89.1}{\percent} and \SI{83.0}{\percent} of networks.
The relative gap to the optimum is of \SI{0.1}{\percent} and \SI{0.3}{\percent}, outperforming all the other methods by one or two orders of magnitude.


\begin{table}[h!]
	\centering
	\caption{Number of networks where the optimal solution from exhaustive enumeration was found and average relative gap to the optimal solution.}
	\label{tab:comparison_bruteforce}
	\begin{tabular}{lcc}
		\toprule
		\textbf{Method}             & \textbf{Opt. found} & \textbf{Rel. gap to opt} \\ \midrule
		DiffNC w/ SLSQP             & \SI{89.1}{\percent} &    \SI{0.1}{\percent}    \\
		DiffNC w/ Frank-Wolfe       & \SI{83.0}{\percent} &    \SI{0.3}{\percent}    \\
		Random                      & \SI{62.4}{\percent} &    \SI{3.9}{\percent}    \\
		DiffNC w/ MMA               & \SI{52.5}{\percent} &   \SI{29.8}{\percent}    \\
		Subplex                     & \SI{39.7}{\percent} &   \SI{36.5}{\percent}    \\
		Minimum-delay shortest path & \SI{36.7}{\percent} &   \SI{51.5}{\percent}    \\
		Hop-count shortest path     & \SI{30.3}{\percent} &   \SI{98.0}{\percent}    \\
		Nelder-Mead                 & \SI{25.3}{\percent} &   \SI{73.0}{\percent}    \\ \bottomrule
	\end{tabular}
\end{table}



\subsection{Application to an industrial network}
\label{sec:evaluation_afdx}

We evaluate in this section our approach on the \ac{AFDX} network from the Airbus A350.
We use the average reduction in delay bound compared to using only one priority level as our metric for evaluating \ac{DiffNC}, namely:
\begin{equation}
	\frac{\mathit{objective}_{n\:\mathit{priorities}}}{\mathit{objective}_{\mathit{one\:priority}}} - 1
\end{equation}

Results are presented in \cref{fig:reduction_delay_bound_vs_nprios_a350_frankwolfe_vs_mma}.
\ac{DiffNC} with Frank-Wolfe is able to outperform both \ac{DiffNC} with \ac{MMA} and with \ac{SLSQP}.
This result confirms the conclusions from \cref{sec:eval:gaptobest} where a similar behavior was observed.

% Figure environment removed



\subsection{Frank-Wolfe algorithm with momentum}
\label{sec:eval:frankwolfe}

Due to its good performances in terms of optimality and computational cost, the Frank-Wolfe algorithm has been extended in various works, as shown in a recent survey \cite{Braun2022}.
In order to explore the potential to further improve its performance in terms of optimality, we used its variant with momentum \cite{Braun2022}.%
In practice, momentum builds inertia in a direction in the search space and overcome the oscillations of noisy gradients.

\Cref{fig:comparison_frankwolfe_momentum} illustrates the impact of using momentum on Frank-Wolfe.
Overall, the relative gap to the best objective is indeed reduced.
As a reference, \cref{fig:comparison_frankwolfe_momentum} also illustrates the gap to \ac{DiffNC} with \ac{SLSQP}, showing also better optimality.

% Figure environment removed


\subsection{Execution time}
\label{sec:eval:execution_time}

Following our discussion on the ways to optimize the computation speed of \ac{DiffNC}, we compare here the execution time of the optimization part of \ac{DiffNC} against the other heuristics.
Results are presented in \cref{fig:ecdf_execution_time}.
Due to the limit of 500 evaluations of the objective function, most of the algorithms exhibit here similar execution times.
The evaluations presented here were performed on an AMD EPYC 7702P with 128 cores with use of the parallelization approach presented in \cref{sec:eval:parallelization}.

% Figure environment removed

One outlier is \ac{SLSQP} which is one order of magnitude slower than the other methods.
This is due to the fact that its execution time grows quadratically with the number of variables of the optimization problem.
To illustrate this issue, we used \ac{DiffNC} on the \ac{AFDX} network, where we incrementally increase the number of virtual links in the network.
Results are presented in \cref{fig:afdx_execution_time_scalability}.
\ac{DiffNC} with \ac{SLSQP} is almost 3 orders of magnitude slower than \ac{DiffNC} with Frank-Wolfe on the full network, showing its poor scalability.

% Figure environment removed

To further illustrate the scalability of \ac{DiffNC} with Frank-Wolfe, we optimized the \ac{AFDX} network with an increasing number of (network-wide) priorities.
Results are presented in \cref{fig:execution_time_vs_nprios_a350_frankwolfe}.
The execution time grows linearly with the number of priorities.
Compared to \ac{DiffNC} with \ac{SLSQP}, \ac{DiffNC} with Frank-Wolfe is three orders of magnitude faster.

% Figure environment removed

Overall, our evaluations show that \ac{DiffNC} with Frank-Wolfe is an efficient method for optimizing networks under delay bound constraints, outperforming all the other optimization methods evaluated here, and at a reasonable computational cost.
This also applies to large real networks with more than \num{1000} flows, illustrating that this method scales to real industrial networks.
