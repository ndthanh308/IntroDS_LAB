\section{Communications Threat Model}\label{sec:threatmodel}

The threat model primarily focuses on the communication aspects of DFL, presuming the co-existence of trusted participants who abide by network protocols and malicious participants who pose multilayered threats. The threat landscape in the communication channels of a DFL environment is complex, with malicious entities potentially playing passive or active roles. Passive malicious entities might eavesdrop on network communications, surreptitiously gaining access to sensitive information such as model parameters, aggregated gradients, or participants' metadata. In contrast, active malicious entities could actively interfere with network operations, manipulate data, introduce false information, or disrupt communication channels. These threats can originate from internal and external sources, with internal threats emerging from compromised or malicious network participants and external threats from entities outside the DFL topology.

As outlined in Table~\ref{table:1}, a malicious participant can potentially extract a wide range of sensitive information, each with its distinct implications. One example is model parameters, including the weights and biases for each neural network layer, encoding the knowledge the model has acquired. It's worth noting that while Homomorphic Encryption or Differential Privacy methods may prevent or obfuscate this extraction to some extent, the threat remains similar to the one faced in FL vanilla. The illicit acquisition of these parameters could enable a malicious actor to reconstruct the learning model, resulting in substantial data privacy breaches and potentially revealing sensitive insights. Furthermore, the topology offers valuable insights into the overall structure and interaction within the network. It can provide an adversary with knowledge of the structure, facilitating further targeted attacks.

Additionally, the roles assigned to participants within the DFL network could grant an adversary a comprehensive understanding of functional distribution and control mechanisms. Unlike in FL vanilla, where all clients primarily hold the same role, this aspect of DFL architecture can aid an attacker in identifying which nodes to target for maximum disruption. Moreover, performance metrics and resource usage data could expose system vulnerabilities regarding performance and resource allocation strategies. An attacker might infer these metrics from the patterns and volume of network communications \cite{MartinezBeltran:fedstellar:2023}. Information about participant activity periods and the underlying model architecture could prove invaluable for an attacker. By analyzing communication timings and frequencies, an attacker might discern when specific nodes are most active, providing insights into the operational rhythms of the network. Knowledge of the model architecture, obtained through careful observation of network interactions and data exchanges, can expose the fundamental structure and operational logic of the model, thereby revealing potential weaknesses ripe for exploitation. Finally, understanding communication patterns could prove beneficial for a malicious entity. By scrutinizing the frequency and nature of participant interactions, an attacker could detect valuable patterns, forecast behaviors, and potentially impersonate trusted nodes, thereby gaining unauthorized access or sowing discord within the network.

\begin{table*}[htb!]
\centering
\small
\caption{Information accessible to a malicious participant in DFL}
\begin{tabular}{|p{3.7cm}|p{11.6cm}|}
\hline
\textbf{Information} & \textbf{Description} \\ [0.5ex] 
\hline\hline
Model Parameters & Each layer $l_i$ in a model $M$ with $n$ layers has weight $w_i \in \mathbb{R}^{d_i \times d_{i-1}}$ and bias $b_i \in \mathbb{R}^{d_i}$, where $d_i$ is the number of neurons in layer $i$. The parameters of $M$ are the collection $\{w_i, b_i\}_{i=1}^{n}$. \\ 
\hline
Topology & The graph of the network $G(V,E)$, where $V$ is the set of vertices (participants) and $E$ is the set of edges (connections). If $V = \{v_1, v_2, ..., v_n\}$ and $E = \{(v_i, v_j) | v_i, v_j \in V, i \neq j\}$, the topology is fully connected.\\
\hline
Roles & Each participant $p_i \in V$ has a role $r_i \in \{$idle, trainer, aggregator, proxy$\}$. This can be mathematically represented by a function $R: V \rightarrow \{$idle, trainer, aggregator, proxy$\}$, where $R(p_i) = r_i$. \\
\hline
Metrics & Performance of the model (e.g., accuracy, precision, recall, F1 score) and resource usage (CPU, RAM, network) of the nodes. For resources, let $R$ be the resource, $U_R$ the usage, and $C_R$ the capacity. The usage rate is $R_{rate} = \frac{U_R}{C_R}$.\\
\hline
Activity Periods & If $T = \{t_1, t_2, ..., t_n\}$ represent the set of all time intervals and $A = \{a_1, a_2, ..., a_k\} \subseteq T$ the active intervals, then the activity ratio is $A_{ratio} = \frac{\sum_{i=1}^{k} a_i}{\sum_{i=1}^{n} t_i}$.\\
\hline
Model Architecture & A feedforward neural network with $n$ layers can be represented as a sequence of function compositions $f(x) = f_n(f_{n-1}(...f_2(f_1(x))))$, where $f_i(x) = \sigma(w_i \cdot x + b_i)$ is the operation for layer $i$, and $\sigma$ is the activation function.\\
\hline
Communication Patterns & If $M = \{m_{ij}\}$ is the set of all messages sent from participant $i$ to participant $j$, the frequency of communication between these participants can be quantified as $F_{ij} = \frac{|m_{ij}|}{\sum_{i,j}|m_{ij}|}$, where $|m_{ij}|$ is the number of messages exchanged. \\
\hline
\end{tabular}
\label{table:1}
\end{table*}

Numerous potential security threats can compromise the confidentiality, integrity, and availability of federated data and models. These threats primarily arise from the inherent vulnerabilities presented by the decentralization of learning processes and model sharing without the control of a central authority. The following communications threats have been identified (see \tablename~\ref{table:2}):

\newcommand{\noimportant}{{\color{ao}$\mathord{!}$}}
\newcommand{\important}{{\textbf{\color{amber}$\mathord{!!}$}}}
\newcommand{\critical}{{\color{red}$\mathord{!!!}$}}

\begin{table*}[htb!]
\caption{Attacks, goals, and information at risk in DFL}
\label{table:2}
\centering
\small
\begin{threeparttable}
\begin{tabular}{|p{2.8cm}|p{8cm}|p{4cm}|}
\hline
\textbf{Attack} & \textbf{Goal} & \textbf{Information at Risk} \\ 
\hline\hline
Eavesdropping & Extract sensitive information to undermine integrity and security of the federated participants [\important] & $\sbullet[0.75]$ Model Parameters \newline $\sbullet[0.75]$ Topology \newline $\sbullet[0.75]$ Roles \\
\hline
MitM & Manipulate information or insert malicious data to disrupt federation operations [\critical] & $\sbullet[0.75]$ Communication Patterns \newline $\sbullet[0.75]$ Roles \\
\hline
Network Mapping & Know the network structure to launch more targeted future attacks on the federation [\noimportant] & $\sbullet[0.75]$ Topology \newline $\sbullet[0.75]$ Model Architecture \\
\hline
Eclipse Attacks & Isolate a node or group of nodes to extract information or disrupt DFL communications [\critical] & $\sbullet[0.75]$ Activity Periods \newline $\sbullet[0.75]$ Topology \newline $\sbullet[0.75]$ Roles \newline $\sbullet[0.75]$ Communication Patterns \\
\hline
\end{tabular}
\begin{tablenotes}
\item \noimportant\space Low importance,\space\important\space High importance,\space\critical\space Critical
\end{tablenotes}
\end{threeparttable}
\end{table*}


\begin{itemize}
    \item \textit{TH1. Eavesdropping}. In a DFL setting, an adversary could covertly monitor network communications or infiltrate a participant node to gain unauthorized access to sensitive data. This data could include model parameters, network topology, and participant roles. The adversary could then leverage this information to disrupt the federated process or impersonate a legitimate participant. This threat often persists undetected due to its covert nature, leading to prolonged periods of sensitive data leakage.

    \item \textit{TH2. MitM}. It involves an attacker intercepting and potentially manipulating the communication between two participant nodes. This enables the attacker to alter exchanged model parameters, introduce spurious data, or eavesdrop on the exchanged information, posing significant challenges to the integrity of the federated process.

    \item \textit{TH3. Network Mapping}. It aims to understand the structure of the federated network and the roles of participant nodes. By gaining this knowledge, attackers can predict and interfere with network operations, facilitating more targeted and potentially detrimental exploits.

    \item \textit{TH4. Eclipse}. This attack in DFL seeks to isolate a specific node or a group of nodes from the rest of the network. This isolation distorts the affected nodes' perception of the network state, causing them to act based on inaccurate information and potentially paving the way for additional security breaches.

\end{itemize}

In light of the identified threats, a comprehensive security module for DFL must account for these potential attack vectors and implement countermeasures to ensure robust operation and resilience against attacks. Crucially, achieving this goal involves striking a careful balance between enhancing security and managing the additional computational and network overhead that security measures may introduce.