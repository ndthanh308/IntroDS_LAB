\section{Theoretical Analysis}
\label{sec:MCanalysis}

\begin{algorithm}[t]
%\caption{\localpush for $L$-hop Transition Probabilities}
\caption{The Algorithm}
\label{alg:MC}
\BlankLine
%\KwIn{Graph $G=(V,E)$, source node $s\in V$, length of random walk $L$, relative error threshold $\delta$, failure probability $p_f$, the number of random walk $n_r$\\}
\KwIn{Undirected graph $G=(V,E)$, teleport probability $\alpha$, target node $t\in V$, the number of random walk $n_r$\\}
\KwOut{An estimator of $\vpi(t)$\\}
Initialize an $n$-dimensional vector $\epi_t \gets \bm{0}$\; 
\For{$w$ from $1$ to $n_r$}{
    Generate an $\alpha$-discounted random walk from node $t$, and let $s$ denote the termination node of the walk\;
    $\epi_t(s) \gets \epi_t(s)+\frac{1}{n_r}$\;
}
$\epi(t) \gets \frac{1}{n}\sum_{s\in V}\frac{\epi_t(s)}{d_s}\cdot d_t$\;
\Return $\epi(t)$ as an estimator of $\vpi(t)$;
\end{algorithm}


\begin{lemma}[Unbiasedness]\label{lem:unbiasedness}
Algorithm~\ref{alg:MC} returns an unbiased estimator $\epi(t)$ of the PageRank value of node $t$ that $\E[\epi(t)]=\vpi(t)$. 
\end{lemma}

\begin{proof}
Let $\I^{(w)}_t(s)$ denote an indicator variable that $\I^{(w)}_t(s)=1$ if the $w$-th $\alpha$-discounted random walk generated from node $t$ terminates at node $s$. Thus, acccording to Algorithm~\ref{alg:MC}, we have $\epi_t(s)=\frac{1}{n_r}\cdot \sum_{w=1}^{n_r}\I^{(w)}_t(s)$. Note that $E\left[\I^{(w)}_t(s)\right]=\vpi_t(s)$ holds by the definition of Personalized PageRank. Thus, it follows: 
\begin{align*}
\E\left[\epi_t(s)\right]=\frac{1}{n_r}\cdot \sum_{w=1}^{n_r}\E\left[\I^{(w)}_t(s)\right]=\frac{1}{n_r}\cdot\sum_{w=1}^{n_r}\vpi_t(s)=\vpi_t(s), 
\end{align*}
where we apply the linearity of expectation in the first equality. Furthermore, by Fact~\ref{fact:undirectedPPR}, we can further derive: 
\begin{align*}
\E\left[\epi(t)\right]=\frac{1}{n}\cdot \hspace{-1mm}\sum_{s\in V}\frac{\E[\epi_t(s)]}{d_s}\cdot d_t=\frac{1}{n}\cdot \hspace{-1mm}\sum_{s\in V}\frac{\vpi_t(s)}{d_s}\cdot d_t=\frac{1}{n}\cdot \hspace{-1mm}\sum_{s\in V}\vpi_s(t). 
\end{align*}
Plugging into Fact~\ref{fact:PageRank_PPR}, we can derive $\E[\epi(t)]=\vpi(t)$, which follows the lemma. 
\end{proof}


\begin{lemma}[Variance]\label{lem:variance}
The variance of the estimator $\epi(t)$ returned by Algorithm~\ref{alg:MC} can be bounded as $\Var[\epi(t)]\le \frac{d_t}{n\cdot n_r}\cdot \vpi(t)$. 
\end{lemma}

\begin{proof}
Recall that we have defined $\I_t^{(w)}(s)$ as an indicator variable in the proof of Lemma~\ref{lem:unbiasedness}, such that $\I_t^{(w)}(s)=1$ if the $w$-th $\alpha$-discounted random walk generated from node $t$ stops at node $s$. We also prove the expectation of $\I_t^{(w)}(s)$ that $\E[\I_t^{(w)}(s)]=\vpi_t(s)$. In other words, $\I_t^{(w)}(s)=1$ holds with probability $\vpi_t(s)$. We now bound the variance of $\I_t^{(w)}(s)$. Specifically, we have:
\begin{align*}
\Var[\I_t^{(w)}(s)]\le \E\left[\left(\I_t^{(w)}(s)\right)^2\right]=1^2\cdot \vpi_t(s)=\vpi_t(s). 
\end{align*}
Since $\epi(t)=\frac{1}{n}\sum_{s\in V}\frac{d_t}{n_r\cdot d_s}\sum_{w=1}^{n_r}\I_t^{(w)}(s)$, we can further derive: 
\begin{align*}
\Var\left[\epi(t)\right]=\frac{d^2_t}{n^2\cdot n_r^2}\cdot \Var\left[\sum_{w=1}^{n_r}\sum_{s\in V}\frac{\I_t^{(w)}(s)}{d_s}\right]. 
\end{align*}
Note that for each $w\in [1,n_r]$, $\I_t^{(w)}(s)$ is independent with each other due to the independent generation of each $\alpha$-discounted random walk. Thus, we have: 
\begin{align}\label{eqn:var1}
\Var\left[\epi(t)\right]=\frac{d^2_t}{n^2\cdot n_r^2}\cdot \sum_{w=1}^{n_r}\Var\left[\sum_{s\in V}\frac{\I_t^{(w)}(s)}{d_s}\right]. 
\end{align}
Moreover, we note: 
\begin{align*}
\Var\left[\sum_{s\in V}\hspace{-1mm}\frac{\I_t^{(w)}\hspace{-0.5mm}(s)}{d_s}\right]\hspace{-0.5mm}=\hspace{-1mm}\sum_{s\in V}\hspace{-0.5mm}\Var\left[\frac{\I_t^{(w)}\hspace{-0.5mm}(s)}{d_s}\right]\hspace{-0.5mm}+\hspace{-0.5mm}\sum_{u\neq v}\hspace{-0.5mm}\cov\left\{\frac{\I_t^{(w)}\hspace{-0.5mm}(u)}{d_u}, \frac{\I_t^{(w)}\hspace{-0.5mm}(v)}{d_v}\right\}.   
\end{align*}
And for $\forall u,v\in V$ and $u\neq v$, 
\begin{equation*}
\begin{aligned}
&\cov\left\{\frac{\I_t^{(w)}\hspace{-0.5mm}(u)}{d_u}, \frac{\I_t^{(w)}\hspace{-0.5mm}(v)}{d_v}\right\}\\
&=\E\left[\frac{\I_t^{(w)}\hspace{-0.5mm}(u)}{d_u}\cdot \frac{\I_t^{(w)}\hspace{-0.5mm}(v)}{d_v}\right]-E\left[\frac{\I_t^{(w)}\hspace{-0.5mm}(u)}{d_u}\right]\cdot E\left[\frac{\I_t^{(w)}\hspace{-0.5mm}(v)}{d_v}\right]\le 0, 
\end{aligned}
\end{equation*}
since the two indicator variables $\I_t^{(w)}\hspace{-0.5mm}(u)$ and $\I_t^{(w)}\hspace{-0.5mm}(v)$ cannot both be $1$ at the same time. Therefore, it follows
\begin{align*}
\Var\left[\sum_{s\in V}\frac{\I_t^{(w)}(s)}{d_s}\right]\le \sum_{s\in V}\Var\left[\frac{\I_t^{(w)}(s)}{d_s}\right]=\sum_{s\in V}\frac{\vpi_t(s)}{d_s^2}.
\end{align*}
Plugging into Equation~\eqref{eqn:var1}, we have: 
\begin{align*}
\Var\left[\epi(t)\right] \le \frac{d^2_t}{n^2\cdot n_r^2}\cdot \sum_{w=1}^{n_r} \sum_{s\in V}\frac{\vpi_t(s)}{d_s^2}=\frac{d_t}{n^2\cdot n_r^2}\cdot \sum_{w=1}^{n_r} \sum_{s\in V}\frac{\vpi_s(t)}{d_s}, 
\end{align*}
where we adopt Fact~\ref{fact:undirectedPPR} into the last equality. It follows: 
\begin{align*}
\Var\left[\epi(t)\right] \le \frac{d_t}{n^2\cdot n_r^2}\cdot \hspace{-1mm}\sum_{w=1}^{n_r} \sum_{s\in V}\vpi_s(t)=\frac{d_t}{n\cdot n_r^2}\cdot \hspace{-1mm}\sum_{w=1}^{n_r} \vpi(t)=\frac{d_t}{n\cdot n_r}\cdot \vpi(t)
\end{align*}
by applying Fact~\ref{fact:PageRank_PPR} to the last equality, which follows the lemma. 
\end{proof}



\begin{theorem}\label{thm:nranalysis}
By setting $n_r=O\left(d_t\right)$, Algorithm~\ref{alg:MC} returns an unbiased estimator of $\vpi(t)$, such that $|\vpi(t)-\epi(t)|\le c\cdot \vpi(t)$ holds with constant probability. 
%\vspace{-1mm}
\end{theorem}

\begin{proof} 
Given Lemma~\ref{lem:unbiasedness} and Lemma~\ref{lem:variance}, we can prove this theorem based on the Chebyshev's Inequality as shown below. 
\begin{fact}[Chebyshev's Inequality~\cite{mitzenmacher2017probability}]\label{fact:chebyshev}
Let $X$ denote a random variable. For any real number $\e>0$, $\Pr\left\{X-\E[X]\ge \e\right\}\le \frac{\Var[X]}{\e^2}$. 
\end{fact}
Specifically, we let $X=\epi(t)$ and $\varepsilon=c\cdot \vpi(t)$, and thus have: 
\begin{align}\label{eqn:bound1}
\Pr\left\{\epi(t)-\vpi(t)\ge c\cdot \vpi(t)\right\}\le \frac{\Var[\epi(t)]}{c^2\cdot (\vpi(t))^2}=\frac{d_t}{c^2 n\cdot n_r\cdot \vpi(t)}. 
\end{align}
Note that $\vpi(t)\ge \frac{\alpha}{n}$ always holds by Equation~\eqref{eqn:ite_pagerank}. Plugging into the Inequality~\eqref{eqn:bound1}, we can further derive: 
\begin{align*}
\Pr\left\{\epi(t)-\vpi(t)\ge c\cdot \vpi(t)\right\}\le \frac{d_t}{c^2 \alpha n_r}. 
\end{align*}
Thus, by setting $n_r=\frac{3d_t}{c^2\alpha}=O(d_t)$, we can ensure $\epi(t)-\vpi(t)\ge c\cdot \vpi(t)$ holds with a constant probability $\frac{1}{3}$. On the other hand, the expected time cost of Algorithm~\ref{alg:MC} can be bounded by $O(\frac{n_r}{\alpha})$ for generating $n_r$ $\alpha$-discounted random walks with $\frac{1}{\alpha}$ as the expected length of walk. Consequently, the expected time cost of Algorithm~\ref{alg:MC} can be further bounded by $O(d_t)$ given the fact that $\alpha$ is a constant and $n_r=O(d_t)$ as derived above. 
 
    
\end{proof}





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
