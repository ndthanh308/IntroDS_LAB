\section{Analysis of Existing Methods} \label{sec:related}

% Figure environment removed

In this section, we present a brief review on existing approaches for single-node PageRank computation. Specifically, we classify existing methods into four categories: the power method~\cite{page1999pagerank}, the Monte-Carlo method~\cite{fogaras2005MC}, the reverse exploration method~\cite{andersen2007contribution, lofgren2013personalized} and the hybrid method~\cite{lofgren2014FastPPR, lofgren2016BiPPR, bressan2018sublinear, wang2020RBS}. %for combining the Monte-Carlo sampling and reverse explorations. 
Figure~\ref{fig:related} provides a sketch to illustrate the differences among these methods. 


\subsection{The Power Method} 
The power method~\cite{page1999pagerank} is an iterative method for computing PageRank values of all nodes in the graph. It defines an $n$-dimensional vector $\epi$ as an approximation of the PageRank vector $\vpi$, where $\epi(t)$ is an estimate of node $t$'s PageRank $\vpi(t)$. The power method initially sets $\epi$ as $\frac{1}{n}\cdot \bm{1}$, and iteratively updates $\epi$ according to the definition formula given in Equation~\eqref{eqn:def_pagerank} 
%\begin{align*}
%\epi'=(1-\alpha)\A \D^{-1}\epi+\frac{\alpha}{n}\cdot \bm{1},   
%\end{align*}
until $\epi$ merely converges. As demonstrated in~\cite{haveliwala2003convergence_rate}, the convergence rate of the power method is given by $(1-\alpha)$. For the typical setting that $\alpha=0.2$, the convergence rate of PageRank becomes $0.8$, which turns out to be every fast even on large-scale graphs. 

However, a major drawback of the power method is that the power method involves a multiplication between the transition matrix $\P=\A \D^{-1}$ and the PageRank vector $\vpi$ in each iteration. Note that $\P$ is an $n\times n$ matrix with $m$ nonzero entries and $\vpi$ is an $n$-dimensional vector. Thus, the power method requires at least $O(m)$ time in each iteration, which is time-costly especially for single-node PageRank queries on large-scale graphs. 

\subsection{The Monte-Carlo Method} 
Recall that the PageRank score of node $t$ equals the probability that an $\alpha$-random walk simulated from a uniformly selected source node terminates at node $t$. Thus, the Monte-Carlo method~\cite{fogaras2005MC} generates $n_r$ $\alpha$-random walks in the graph, where the source node of each walk is independently selected from $V$ uniformly at random. Then the Monte-Carlo method computes $\frac{1}{n_r}\cdot \sum_{w=1}^{n_r} \I^{(w)}(t)$ as an estimate of $\vpi(t)$,  
%each of which starts from a random node on the graph and terminates at the $L$-th step that $L\sim G(\alpha)$. 
where $\I^{(w)}(t)$ is an indicator variable that $\I^{w}(t)=1$ if the $w$-th random walk terminates at node $t$. %The method computes $\frac{1}{n_r}\cdot \sum_{w=1}^{n_r} \I^{(w)}(t)$ as an estimator of $\vpi(t)$. 
{\rev 
By the Chernoff bound, the number of $\alpha$-random walks that is required to derive a $(c,p_f)$-approximation of $\vpi(t)$ can be bounded as $n_r=\tilde{O}\left(\frac{1}{\e^2}\right)$. Recall that the expected length $L$ of an $\alpha$-random walk is $\E[L]=\frac{1}{\alpha}$, which is a constant. Consequently, the expected time cost of the Monte-Carlo method for achieving the $(\rela, \pf)$-approximation of single-node PageRank is bounded by $O(n_r)=\tilde{O}\left(n\right)$.
}

\begin{comment}
By utilizing the Chernoff bound as shown below, Fogaras et al~\cite{fogaras2005MC} prove $n_r=\tilde{O}\left(\frac{1}{\e^2}\right)$ is a sufficient number of $\alpha$-random walks for estimating $\vpi(t)$ within an absolute error of $\e$. 
%With probability $(1-\alpha)$, the $i$-th node $w_i$ is selected uniformly at random from the neighbors of node $w_{i-1}$; or with probability $\alpha$, $w_i$ is uniformly selected from the graph's vertex set $V$. 

\begin{fact}[Chernoff Bound~\cite{chung2006concentration}]
Let $x_1, x_2, \ldots, x_{n_x}$ be independent random variables with mean $\mu$. For each $i\in \{1,2, \ldots, n\}$, $x_i \in [0,1]$. Then we have: 
\begin{align}\label{eqn:chernoff_ineq}
\Pr\left\{\left|\frac{1}{n_x}\cdot \sum_{i=1}^{n_x} x_i -\mu\right|\ge \e \right\} \le \exp\left(-\frac{n_x \cdot \e^2}{\frac{2}{3}\e+2\mu}\right). 
\end{align}
\end{fact}
If we further substitute $\e$ in Inequality~\eqref{eqn:chernoff_ineq} with $\rela \vpi(t)$, we have: 
\begin{align*}
\Pr\left\{\left|\frac{1}{n_r}\cdot \sum_{i=w}^{n_r} \I^{(w)}(t) -\vpi(t)\right|\ge \rela \vpi(t) \right\} \le \exp\left(-\frac{n_r \cdot \rela^2 \cdot \vpi(t)}{\frac{2}{3}\rela+2}\right). 
\end{align*}
Therefore, setting $n_r=\frac{\frac{2}{3}\rela+2}{\rela^2 \cdot \vpi(t)}\cdot \ln{\frac{1}{\pf}}$ is sufficed to achieve an $(\rela, \pf)$-approximation of $\vpi(t)$. However, we do not know the value of $\vpi(t)$ in advance, and thus $\vpi(t)$ can only be in place of the lower bound of $\vpi(t)$. By Equation~\eqref{eqn:ite_pagerank}, we have $\vpi(t)\ge \frac{\alpha}{n}$ holds for each node $t$, resulting in $n_r=\frac{\left(\frac{2}{3}\rela+2\right)n}{\rela^2 \alpha}\cdot \ln{\frac{1}{\pf}}=\tilde{O}\left(n\right)$. Recall that the expected length $L$ of an $\alpha$-random walk is a constant that $\E[L]=\frac{1}{\alpha}$. Consequently, the expected time cost of the Monte-Carlo method for achieving the $(\rela, \pf)$-approximation of single-node PageRank is bounded by $O(n_r)=\tilde{O}\left(n\right)$. %given the fact the expected length of the $\alpha$-random walk $L$ is a constant that $\E[L]=\frac{1}{\alpha}$. 
\end{comment}


\subsection{The Reverse Exploration Method}\label{subsec:reverse_exploration}
%Another line of research~\cite{andersen2007contribution, lofgren2013personalized, wang2020RBS,jeh2003scaling} addressed the problem of computing the linear system given in Equation~\eqref{eqn:def_pagerank} via local exploration. %The main idea of these methods is based on the recursive formula as shown in Equation~\eqref{eqn:ite_pagerank}. 
Another line of research~\cite{andersen2007contribution, lofgren2013personalized,jeh2003scaling} computes single-node PageRank via reverse explorations. Specifically, given a target node $t$, this line of methods aim to estimate the contribution that each node makes to node $t$'s PageRank. Specifically, as a well-known reverse exploration method, LocalPush~\cite{lofgren2013personalized} reversely explores the graph from the target node $t$ to its ancestors, propagating the probability mass initially at the target node $t$ to its neighbors step by step. %The computation of PageRank contribution is commonly referred to as the single-target PPR query, which asks for the PPR value $\vpi_u(t)$ of each node $u$ on the graph to a given target node $t$. Recall that $\vpi(t)=\frac{1}{n}\cdot \sum_{u\in V} \vpi_u(t)$
%\begin{align*}%\label{eqn:pagerank_ppr_eqn}
%\vpi(t)=\frac{1}{n}\cdot \sum_{u\in V} \vpi_u(t)
%\end{align*}
%as shown in Equation~\eqref{eqn:PageRank_PPR}. Thus, this line of research use the reverse exploration first to estimate the PPR value $\vpi_u(t)$ of each node $u$, then utilize Equation~\eqref{eqn:PageRank_PPR} to derive the estimator of $\vpi(t)$. %In Figure~\ref{fig:related}, we present a sketch to illustrate the differences between the methods of reverse explorations and Monte-Carlo simulation. 
To be more specific, the LocalPush method repeatedly conducts {\em backward push} operations, updating two variables $\r^b(v)$ and $\epi^b(v)$ for each node $v$ in graph $G$ during the query phase.
%two $n$-dimensional vectors $\r^b$ and $\epi^b$. 
In particular, $\r^b(v)$ is called the (reverse) {\em residue} of node $v$, which records the probability mass that is to be reversely pushed from node $v$ to its ancestors. $\epi^b(v)$ is called the (reverse) {\em reserve} of $v$, which records the probability mass that has been received by node $v$ so far. Initially, LocalPush sets $\r^b(v)=\epi^b(v)=0$ for every $v\in V$ except $\r^b(t)=1$. 
During the query phase, 
LocalPush repeatedly conducts the following backward push operations from all nodes $v$ with $\r^{b}(v)\ge \e$. Specifically, in the backward push operation at node $v$, LocalPush updates $\epi^b(v)$ and $\r^b(v)$ as follows: 
%\begin{align*}
%$\epi^b=\epi^b+\alpha\cdot (\r^b(v)\cdot \bm{e}_v)$,  
%\end{align*}
%and 
%\begin{align*}
%\r^b=\r^b-\r^b(v)\bm{e}_v +(1-\alpha)\cdot \D^{-1}\A\cdot \left(\r^b(v)\cdot \bm{e}_u\right), 
%\end{align*}
%respectively. 
%Here $\r^b(v)$ denotes the probability mass maintained at node $v$ before this backward push. 
%In the backward push at node $v$, we conduct the following steps: 
\begin{itemize}
    \item convert $\alpha$ fraction of the probability mass currently at $\r^b(v)$ to its reserve: $\epi^b(v) \gets \epi^b(v)+\alpha \cdot \r^b(v)$; 
    \item reversely push the remained mass at $\r^b(v)$ to the neighbors of node $v$: for each $u\in N(v)$, $\r^b(u) \gets \r^b(u)+(1-\alpha)\cdot \frac{\r^b(v)}{d_u}$; 
    \item set $\r^b(v)$ as $0$: $\r^b(v)\gets 0$. 
\end{itemize} 
%Moreover, $\r^b$ admits an recurrence relation for $\epi$ and $\r$: 
%update $\r^b$ following: 
%Here node $v$ is called as the {\em current node}, which denotes the node from which we are going to perform the backward push operation currently. 
%To be more specific, in the backward push operation at node $v$, 
%we convert $\alpha$ fraction of the probability mass maintained by $\r^b(v)$ to its reserve $\epi^b(v)$, i.e., $\epi^b(v) \gets \epi^b(v)+\alpha \r^b(v)$, reversely push the remained probability mass (i.e., $(1-\alpha)\r^b(v)$) to all the neighbors of node $v$ (i.e., $\r^b(u) \gets \r^b(u)+(1-\alpha)\cdot \frac{\r^b(v)}{d_u}$ for each $u\in N(v)$), and reduce $\r^b(v)$ to $0$. 
%Additionally, $\epi^b(u)$ is an underestimate of the PPR value $\epi_u(t)$, which admits the recurrence relation for $\epi$ and $\r$: 
%\begin{align*}
%    \epi^b=\epi^b+\alpha\cdot (\r^b(u)\cdot \bm{e}_u). 
%\end{align*}
%Initially, LocalPush sets $\r^b(v)$ and $\epi^b(v)$ as $0$, except $\r^b(t)=1$. During the query phase, 
When no node in graph $G$ has the residue that is larger than $\e \in (0,1)$, the algorithm terminates. 
%LocalPush repeatedly conducts backward push operations until all nodes' residue is smaller than a threshold $\e \in (0,1)$. Finally, 
LocalPush then uses $\epi(t)=\frac{1}{n}\cdot \sum_{u\in V}\epi^b(u)$ as an estimate of $\vpi(t)$. 

In particular, %Lofgren et al. proposed the LocalPush method~\cite{lofgren2013personalized}, which sets an additional push threshold $\e \in (0,1)$ for scalability, and only performs backward push operations at the nodes $v$ with $\r^b(v)\ge \e$. %For example, in Figure~\ref{fig:related}, we omit the backward push operations at node $x$ and $y$ since $\r^b(x)<\e$ and $\r^b(y)<\e$. 
Lofgren et al.~\cite{lofgren2013personalized} prove that throughout the backward push process, $\epi^b(v)$ is always an underestimate of $\vpi_v(t)$ that $\vpi_v(t)-\epi^b(v)\le \e$, where $\vpi_v(t)$ denotes the PPR of $t$ (w.r.t node $v$), and $\epi^b(v)$ is the reserve of node $v$. Hence, by setting the push threshold $\e=\frac{\rela \alpha}{n}$, we can derive: 
\begin{align}\label{eqn:localpush_time}
\vpi(t)-\epi(t)=\frac{1}{n}\sum_{v\in V}\left(\vpi_v(t)-\epi^b(v)\right)\le \frac{1}{n}\sum_{v\in V} \frac{\rela \alpha}{n}\le \rela \vpi(t) 
\end{align}
when the LocalPush algorithm terminates. In the last inequality of Equation~\eqref{eqn:localpush_time}, we also adopt the lower bound $\vpi(t)\ge \frac{\alpha}{n}$, as shown in Equation~\eqref{eqn:ite_power_method}. 
In other words, by setting $\e=\frac{\rela \alpha}{n}$, the estimate $\epi(t)$ derived by LocalPush is a $(\rela, \pf)$-approximation of $\vpi(t)$. Furthermore, Lofgren et al.~\cite{lofgren2013personalized} bound the worst-case time complexity of reverse exploration method as $\sum_{u\in V}\frac{\vpi_u(t)\cdot d_u}{\e}$. By plugging into $\e=\frac{\rela \alpha}{n}$ and the reversibility property $\vpi_u(t)\cdot d_u=\vpi_t(v)\cdot d_t$ as shown in Equation~\eqref{eqn:undirectedPPR}, we have: 
\begin{align*}
\sum_{v\in V}\frac{\vpi_v(t)\cdot d_v \cdot n}{\rela \alpha}=\frac{n}{\rela \alpha}\cdot \left(\sum_{v\in V}\vpi_t(v)\cdot d_t\right)=\frac{n\cdot d_t}{\rela \alpha}=O\left(n \cdot d_t\right)    
\end{align*}
%we can further bound the time complexity of LocalPush as $\frac{n\cdot d_t}{\alpha}\cdot \sum_{v\in V}\vpi_t(v)$. 

Note that the $O(n\cdot d_t)$ complexity may become $O(n^2)$ on some dense graphs where $d_t \to n$. To circumvent this problem, Lofgren and Goel~\cite{lofgren2013personalized} use a priority queue ordered by the residue $\r^b(v)$ of node $v$. Each time we pop off the node $v$ with the greatest $\r^b(v)$ on the graph and conduct the backward push at node $v$. %For the ease of presentation, we denote such method as PriorityPush. 
As a result, the worse-case time complexity of LocalPush is improved to $\tilde{O}\left(\min\left\{n\cdot d_t, m\right\}\right)$ for deriving a $(\rela, \pf)$-approximation of $\vpi(t)$. %Nonetheless, such complexity is even worse than that of the Monte-Carlo method.  


%Specifically, these methods first estimate the Personalized PageRank $\vpi_u(t)$ of each node $u\in V$, and utilize the relation $\vpi(t)=\frac{1}{n}\cdot \sum_{u\in V}\vpi_u(t)$ given in Fact~\ref{fact:PageRank_PPR} to derive the estimator of $\vpi(t)$. 


%\vspace{-2mm}
\subsection{The Hybrid Method} 
Another set of papers~\cite{lofgren2014FastPPR, lofgren2016BiPPR, bressan2018sublinear, wang2020RBS} prove some novel results by combining the Monte-Carlo method and the reverse exploration method together. The key idea is first proposed in FastPPR~\cite{lofgren2014FastPPR}, which introduces a bi-directional approximation algorithm for single-node PageRank:
\begin{align}\label{eqn:bidirection_estimator}
\vspace{-2mm}
\vpi(t)=\sum_{v\in B(t)}\Pr\left\{RW(\alpha)=v\right\} \cdot \vpi_v(t). 
\vspace{-4mm}
\end{align}
Here $B(t)$ is a blanket set of the target node $t$ that all $\alpha$-random walks to node $t$ pass through set $B(t)$. Additionally, $\Pr\left\{RW(\alpha)=v\right\}$ denotes the probability that node $v$ is the first node in $B(t)$ hit by a randomly simulated $\alpha$-random walk. FastPPR first invokes the reverse exploration method to estimate all the PPR values $\vpi_v(t)$ for $v\in V$. Then FastPPR simulates $\alpha$-random walks to collect these estimators according to Equation~\eqref{eqn:bidirection_estimator}. %We present a sketch to illustrate this process in Figure~\ref{fig:related}. 
As a result, to achieve an $\e$-absolute error of $\vpi(t)$, FastPPR first allows an $\sqrt{\e}$ absolute error for each $\epi_v(t)$ derived in the reverse exploration phase, and only take $\frac{1}{\sqrt{\e}}$ $\alpha$-random walks in the Monte-Carlo simulation phase. Thus, the query time complexity of FastPPR can be bounded by $\frac{1}{\alpha \rela^2}\cdot \sqrt{\frac{d_t\cdot n}{\alpha}}\cdot \sqrt{\frac{\log{\left(1/\pf\right)\cdot \log{\left(n/\alpha\right)}}}{\log{\left(1/(1-\alpha)\right)}}}=\tilde{O}\left(\sqrt{n\cdot d_t}\right)$ for achieving a $(\rela, \pf)$-approximation of $\vpi(t)$. The result is subsequently improved by BiPPR~\cite{lofgren2016BiPPR, lofgren2015BiPPRundirected} to $\frac{1}{\alpha \rela}\cdot \sqrt{\frac{d_t\cdot n}{\alpha}}\cdot \sqrt{\log{(1/\pf)}}=\tilde{O}\left(\sqrt{n\cdot d_t}\right)$. Furthermore, Bressan et al.~\cite{bressan2018sublinear} proposed the \sublinear method, which optimizes the complexity result to {\rev $\tilde{O}\left(\min\left\{\frac{m^{2/3}\dmax^{1/3}}{\davg^{2/3}}, \frac{m^{4/5}}{\davg^{3/5}} \right\}\right)$}. Here $\davg$ and $\dmax$ denote the average and maximum degree of all the nodes in the graph, respectively. 

%% Figure environment removed


 \header{\bf The RBS Method. } Reviewing the hybrid methods mentioned above, the Monte-Carlo sampling phase and the reverse exploration phase serve as two separate phases and are conducted sequentially. In comparison, a recent method, RBS~\cite{wang2020RBS}, proposes to mix the two phases in a more flexible way. Specifically, the RBS method follows the framework of the reverse exploration, which reversely propagates the probability mass from the given target node $t$ to its ancestors in the graph. The difference is, in each backward push step (e.g. at node $v$), the RBS method only deterministically pushes the probability mass at $\r^b(v)$ to a small fraction of $v$'s neighbors (i.e., deterministically increase the residue of $u\in N(v)$ if the residue increment $\frac{(1-\alpha)\r^b(v)}{d_u}\ge \theta$, where $\theta$ is a threshold for deterministic push). For the other neighbors $u$, the RBS method generates a uniform random $rand \in (0,1)$ and only updates the residues $\r^b(u)$ if $\frac{(1-\alpha)\r^b(v)}{d_u}\ge rand \cdot \theta$. 
 {\rev 
 By this means, the RBS method avoids to touch all neighbors, and successfully reduces an $O(\davg)$ gap between the time complexity of LocalPush~\cite{andersen2007contribution} and the lower bound for single-target PPR queries. Here $\davg$ denotes the average node degree in the graph. For the single-node PageRank computation, the expected time complexity of RBS can be bounded by $\tilde{O}\left(n\right)$ by setting $\theta=\frac{\rela^2 \cdot \vpi(t)}{12\cdot \log_{1-\alpha}{(c \alpha /2n)}}$. 
 
 The theoretical insight introduced by RBS is encouraging, which enlightens us that we may flexibly mix the deterministic reverse exploration and the randomized Monte-Carlo sampling in each step, instead of separately performing the two phases one by one. 
 }
 %With careful choice of the switch threshold, we may achieve better scalability without the decrement of approximation accuracy. 
%However, the limitation of the RBS method is that the sampling operation invoked in each backward push is not independent, which causes large variance and can only achieve a $\tilde{O}\left(n\right)$ expected time cost at best for $(\rela, \pf)$-approximation of single-node PageRank. 












%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
