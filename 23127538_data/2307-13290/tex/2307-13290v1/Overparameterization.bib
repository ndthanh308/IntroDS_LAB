@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{bottou2012stochastic,
  title={Stochastic gradient descent tricks},
  author={Bottou, L{\'e}on},
  journal={Neural Networks: Tricks of the Trade: Second Edition},
  pages={421--436},
  year={2012},
  publisher={Springer}
}

@article{tieleman2017divide,
  title={Divide the gradient by a running average of its recent magnitude. coursera: Neural networks for machine learning},
  author={Tieleman, Tijmen and Hinton, G},
  journal={Technical report},
  year={2017}
}

@article{kingma2014method,
  title={A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={ArXiv Prepr},
  year={2014}
}

@book{amari2000methods,
  title={Methods of information geometry},
  author={Amari, Shun-ichi and Nagaoka, Hiroshi},
  volume={191},
  year={2000},
  publisher={American Mathematical Soc.}
}

@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}

@inproceedings{bordelon2020spectrum,
  title={Spectrum dependent learning curves in kernel regression and wide neural networks},
  author={Bordelon, Blake and Canatar, Abdulkadir and Pehlevan, Cengiz},
  booktitle={International Conference on Machine Learning},
  pages={1024--1034},
  year={2020},
  organization={PMLR}
}

@inproceedings{huang2020self,
  title={Self-challenging improves cross-domain generalization},
  author={Huang, Zeyi and Wang, Haohan and Xing, Eric P and Huang, Dong},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  pages={124--140},
  year={2020},
  organization={Springer}
}

@inproceedings{zhang2019your,
  title={Be your own teacher: Improve the performance of convolutional neural networks via self distillation},
  author={Zhang, Linfeng and Song, Jiebo and Gao, Anni and Chen, Jingwei and Bao, Chenglong and Ma, Kaisheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3713--3722},
  year={2019}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3351--3361},
  year={2020}
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}


@article{canatar2021spectral,
  title={Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks},
  author={Canatar, Abdulkadir and Bordelon, Blake and Pehlevan, Cengiz},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={2914},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{bartlett2002rademacher,
  title={Rademacher and Gaussian complexities: Risk bounds and structural results},
  author={Bartlett, Peter L and Mendelson, Shahar},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={463--482},
  year={2002}
}

@article{jacot2020kernel,
  title={Kernel alignment risk estimator: Risk prediction from training data},
  author={Jacot, Arthur and Simsek, Berfin and Spadaro, Francesco and Hongler, Cl{\'e}ment and Gabriel, Franck},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15568--15578},
  year={2020}
}

@article{loureiro2021learning,
  title={Learning curves of generic features maps for realistic datasets with a teacher-student model},
  author={Loureiro, Bruno and Gerbelot, Cedric and Cui, Hugo and Goldt, Sebastian and Krzakala, Florent and Mezard, Marc and Zdeborov{\'a}, Lenka},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18137--18151},
  year={2021}
}

@article{shawe2005eigenspectrum,
  title={On the eigenspectrum of the Gram matrix and the generalization error of kernel-PCA},
  author={Shawe-Taylor, John and Williams, Christopher KI and Cristianini, Nello and Kandola, Jaz},
  journal={IEEE Transactions on Information Theory},
  volume={51},
  number={7},
  pages={2510--2522},
  year={2005},
  publisher={IEEE}
}

@article{liu2020linearity,
  title={On the linearity of large non-linear models: when and why the tangent kernel is constant},
  author={Liu, Chaoyue and Zhu, Libin and Belkin, Misha},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15954--15964},
  year={2020}
}

@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{arora2019exact,
  title={On exact computation with an infinitely wide neural net},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{geifman2020similarity,
  title={On the similarity between the laplace and neural tangent kernels},
  author={Geifman, Amnon and Yadav, Abhay and Kasten, Yoni and Galun, Meirav and Jacobs, David and Ronen, Basri},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1451--1461},
  year={2020}
}

@article{ortiz2021can,
  title={What can linearized neural networks actually say about generalization?},
  author={Ortiz-Jim{\'e}nez, Guillermo and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8998--9010},
  year={2021}
}

@inproceedings{arora2018stronger,
  title={Stronger generalization bounds for deep nets via a compression approach},
  author={Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle={International Conference on Machine Learning},
  pages={254--263},
  year={2018},
  organization={PMLR}
}

@inproceedings{safran2021effects,
  title={The effects of mild over-parameterization on the optimization landscape of shallow relu neural networks},
  author={Safran, Itay M and Yehudai, Gilad and Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={3889--3934},
  year={2021},
  organization={PMLR}
}

@article{liu2020toward,
  title={Toward a theory of optimization for over-parameterized systems of non-linear equations: the lessons of deep learning},
  author={Liu, Chaoyue and Zhu, Libin and Belkin, Mikhail},
  journal={arXiv preprint arXiv:2003.00307},
  year={2020}
}

@article{velikanov2021explicit,
  title={Explicit loss asymptotics in the gradient descent training of neural networks},
  author={Velikanov, Maksim and Yarotsky, Dmitry},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2570--2582},
  year={2021}
}

@inproceedings{suzuki2018fast,
  title={Fast generalization error bound of deep learning from a kernel perspective},
  author={Suzuki, Taiji},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1397--1406},
  year={2018},
  organization={PMLR}
}

@article{cao2019generalization,
  title={Generalization bounds of stochastic gradient descent for wide and deep neural networks},
  author={Cao, Yuan and Gu, Quanquan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{allen2019learning,
  title={Learning and generalization in overparameterized neural networks, going beyond two layers},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{liu2022loss,
  title={Loss landscapes and optimization in over-parameterized non-linear systems and neural networks},
  author={Liu, Chaoyue and Zhu, Libin and Belkin, Mikhail},
  journal={Applied and Computational Harmonic Analysis},
  volume={59},
  pages={85--116},
  year={2022},
  publisher={Elsevier}
}

@article{martens2020new,
  title={New insights and perspectives on the natural gradient method},
  author={Martens, James},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5776--5851},
  year={2020},
  publisher={JMLRORG}
}

@article{bernacchia2018exact,
  title={Exact natural gradient in deep linear networks and its application to the nonlinear case},
  author={Bernacchia, Alberto and Lengyel, M{\'a}t{\'e} and Hennequin, Guillaume},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{rudner2019natural,
  title={The natural neural tangent kernel: Neural network training dynamics under natural gradient descent},
  author={Rudner, Tim GJ and Wenzel, Florian and Teh, Yee Whye and Gal, Yarin},
  booktitle={4th workshop on Bayesian Deep Learning (NeurIPS 2019)},
  year={2019}
}

@article{karakida2020understanding,
  title={Understanding approximate fisher information for fast convergence of natural gradient descent in wide neural networks},
  author={Karakida, Ryo and Osawa, Kazuki},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10891--10901},
  year={2020}
}

@inproceedings{martens2015optimizing,
  title={Optimizing neural networks with kronecker-factored approximate curvature},
  author={Martens, James and Grosse, Roger},
  booktitle={International conference on machine learning},
  pages={2408--2417},
  year={2015},
  organization={PMLR}
}

@inproceedings{grosse2016kronecker,
  title={A kronecker-factored approximate fisher matrix for convolution layers},
  author={Grosse, Roger and Martens, James},
  booktitle={International Conference on Machine Learning},
  pages={573--582},
  year={2016},
  organization={PMLR}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}