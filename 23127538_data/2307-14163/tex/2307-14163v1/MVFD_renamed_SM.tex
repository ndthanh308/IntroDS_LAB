\documentclass[12pt]{article}
%
%
% Retirez le caractere "%" au debut de la ligne ci-dessous si votre
% editeur de texte utilise des caracteres accentues
% \usepackage[latin1]{inputenc}

%
% Retirez le caractere "%" au debut des lignes ci-dessous si vous
% utiisez les symboles et macros de l'AMS
%
%




\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\setlength{\parskip}{6pt}


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor,graphicx}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{tikz}


\hypersetup{%
colorlinks=true,
breaklinks=true,
linkcolor=red,
anchorcolor=black,
citecolor=brown,
filecolor=blue,
menucolor=red,
urlcolor=red,
}
\usepackage[round,longnamesfirst]{natbib}
\usepackage{mathtools, amsfonts, amssymb,amsthm,stmaryrd}
\mathtoolsset{showonlyrefs}
\usepackage{enumerate}
\usepackage{comment}
\usepackage{ifthen}
%\usepackage{mathrsfs}

\renewcommand{\thesection}{\Roman{section}}

\newtheorem{assump}{Assumption}
\newtheorem{assumpA}{Assumption}
\newtheorem{definition}{Definition}
\renewcommand\theassump{H\arabic{assump}}

\newtheorem{propSM}{Proposition SM.\!\!}
\newtheorem{lemSM}{Lemma SM.\!\!}
\newtheorem{theoSM}{Theorem SM.\!\!}
\newtheorem{corSM}{Corollary SM.\!\!}

\newcommand{\EE}{\mathbb{E}}
\newcommand{\EEMT}{\mathbb{E}_{M,T}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\utheta}{\overline{\widehat \theta}}
\newcommand{\ltheta}{\underline{\widehat \theta}}
\newcommand{\htheta}{\widehat \theta}
\newcommand{\HH}{\widehat H}
\newcommand{\TX}{\widetilde X^{(i)}}
\newcommand{\TL}{\widetilde L}
\newcommand{\Ttmh}{\frac{T_m^{(i)} - t}{h}}
\newcommand{\Tsmh}{\frac{T_m^{(i)} - s}{h}}

%%%%%%%%%% Commandes Omar
\newcommand{\Xtemp}[1]{%
\ifthenelse{\equal{#1}{0}}
{X^{(\n0)}}
{
\ifthenelse{\equal{#1}{1}}
{X^{[\n1]}}
{X^{(#1)}}
}}
\newcommand{\hXtemp}[1]{%
\ifthenelse{\equal{#1}{0}}
{\widehat X^{(\n0)}}
{
\ifthenelse{\equal{#1}{1}}
{\widehat X^{[\n1]}}
{\widehat X^{(#1)}}
}}

\newcommand{\Zz}{\boldsymbol z}
\newcommand{\Yy}{\boldsymbol y}
\newcommand{\Tt}{\boldsymbol t}
\newcommand{\Xx}{\boldsymbol x}
\newcommand{\TT}{\boldsymbol T}
\newcommand{\Ss}{\boldsymbol s}
\newcommand{\Uu}{\boldsymbol u}
\newcommand{\Vv}{\boldsymbol v}
\newcommand{\mO}{\mathcal O}
\newcommand{\cT}{\mathcal T}
\newcommand{\cU}{\mathcal U}
\newcommand{\Ynm}{{Y^{(j)}_m}}
\newcommand{\Tnm}{{\boldsymbol t^{(j)}_m}}
\newcommand{\Tnlm}{{T^{[n_1]}_m}}
\newcommand{\enm}{{\varepsilon^{(j)}_m}}
\newcommand{\unm}{{e^{(j)}_m}}
\newcommand{\Xp}[1]{X^{(#1)}}
\newcommand{\Xtp}[1]{\tilde{X}^{(#1)}}
\newcommand{\Xc}[1]{X^{[#1]}}
\newcommand{\X}[1]{{\Xtemp{#1}}}
\newcommand{\Xt}[1]{{\Xtemp{#1}_t}}
\newcommand{\XT}[1]{{\Xtemp{#1}_\T}}
%\newcommand{\Xn}{{\Xtemp{i}}}
\newcommand{\Xn}{{\Xtemp{j}}}
\newcommand{\Xtn}{{\Xtemp{j}_t}}
\newcommand{\XTn}{{\Xtemp{j}_\T}}  
\newcommand{\D}{{\rm d}}
%%%%%%%%%%%%% Fin commandes Omar


\newcommand{\Ee}{\boldsymbol e}
\newcommand{\Eeps}{\boldsymbol \varepsilon}
\newcommand{\Eeta}{\boldsymbol \eta}
\newcommand{\Hh}{\boldsymbol H }
\newcommand{\Rplus}{\mathbb R_+}


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}

\newcounter{assumptionHt}
\newcounter{assumptionH}
\newcounter{assumptionE}
\newcounter{assumptionLP}
\renewcommand{\theequation}{SM.\arabic{equation}}

\newenvironment{assumptionHt}%
{%
\begin{enumerate}[({G}1)]%
    \setcounter{enumi}{\value{assumptionHt}}%
    }{%
    \setcounter{assumptionHt}{\value{enumi}}%
\end{enumerate}
}
%
\newenvironment{assumptionH}%
{%
\medskip
\noindent\textbf{Assumptions.}
  \begin{enumerate}[({H}1)]%
  \setcounter{enumi}{\value{assumptionH}}%
}{%
  \setcounter{assumptionH}{\value{enumi}}%
  \end{enumerate}
}

\newenvironment{assumptionHbis}[1][]%
{%
\medskip
\noindent \textbf{Assumptions.}
#1
\begin{enumerate}[({H}1)]%
  \setcounter{enumi}{\value{assumptionH}}%
  }{%
  \setcounter{assumptionH}{\value{enumi}}%
\end{enumerate}
}

\newenvironment{assumptionE}%
{%
\medskip
\noindent \textbf{Assumptions.}
\begin{enumerate}[({E}1)]%
  \setcounter{enumi}{\value{assumptionE}}%
  }{%
  \setcounter{assumptionE}{\value{enumi}}%
\end{enumerate}
}

\newenvironment{assumptionLP}%
{%
\medskip
\noindent \textbf{Assumptions.}
\begin{enumerate}[({LP}1)]%
  \setcounter{enumi}{\value{assumptionLP}}%
  }{%
  \setcounter{assumptionLP}{\value{enumi}}%
\end{enumerate}
}

\newcommand{\assrefHt}[1]{(\hyperref[#1]{G\ref{#1}})}
\newcommand{\assrefH}[1]{(\hyperref[#1]{H\ref{#1}})}
\newcommand{\assrefE}[1]{(\hyperref[#1]{E\ref{#1}})}
\newcommand{\assrefLP}[1]{(\hyperref[#1]{LP\ref{#1}})}

\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\LL}{\mathbb{L}}

\newcommand{\T}{{t_0}}
\newcommand{\HT}{H_\T}
\newcommand{\KT}{\degree}
\newcommand{\ST}{\varsigma_\T}
\newcommand{\hHT}{\widehat{H}_\T}
\newcommand{\hKT}{\hdegree}
\newcommand{\hST}{\widehat{\alpha}_\T}
\newcommand{\Mmu}{\mathfrak{m}}



\title{Learning the regularity of multivariate functional data\\
	\emph{Supplementary Material} }
\author{Omar Kassi\footnote{Ensai, CREST - UMR 9194, France; omar.kassi@ensai.fr} \qquad	
	Nicolas Klutchnikoff\footnote{Univ Rennes, IRMAR - UMR 6625, France; Nicolas.klutchnikoff@univ-rennes2.fr}	\qquad
	Valentin Patilea\footnote{Ensai, CREST - UMR 9194, France; valentin.patilea@ensai.fr}
}
\date{\today}


\mathtoolsset{showonlyrefs}
\usepackage{xr}
\externaldocument{MVFD}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		In this Supplementary Material we provide complementary arguments for the proofs of the propositions in the Appendix of the main manuscript. More precisely, in Sections \ref{secSM_propCH}, \ref{secSM_conc_Lest}, \ref{secSM_mprop}, \ref{secSM_prop_risk1} below we complete the proofs of Propositions \ref{propCH}, \ref{conc_Lest}, \ref{mprop}, \ref{prop_risk1}, respectively.  
		Moreover, in Section \ref{tech_lem} below we provide the justification for the local  Hölder continuity of the  realizations of $X$, as stated in Section \ref{sec6} of the main manuscript, and we prove some technical lemmas. 
	\end{abstract}


%--------------------------------------------------------------------------



\section{Complements for the proof of Proposition \ref{propCH}}\label{secSM_propCH}
\begin{proof}[Proof of \eqref{eq:assumption-theta-hat_main}]
We show that  a constant $\mathfrak u >0$ exists such that, for any $i=1,2$ and $\Delta>0$~:
\begin{equation}\label{eq:assumption-theta-hat_SM}
	\max\left\{
	\PP\left(\widehat{\theta}_{\Tt}^{(i)}(\Delta)-\theta_{\Tt}^{(i)}(\Delta)\geq \varepsilon\right),
	\PP\left(\widehat{\theta}_{\Tt}^{(i)}(\Delta)-\theta_{\Tt}^{(i)}(\Delta)\leq -\varepsilon\right)
	\right\}
	\leq \exp\left( -\mathfrak{u}N\varepsilon^2\varrho(\Delta)\right),
\end{equation}
with $\widehat{\theta}_{\Tt}^{(i)}(\Delta)$ defined in \eqref{eq_theta_hat}. We  decompose
 $$
 \widehat{\theta}^{(i)}_{\Tt}(\Delta)-\theta^{(i)}_{\Tt}(\Delta)= \underbrace{\frac{1}{N}\sum_{j=1}^N \Bar{Z}_j }_{\text{stochastic term}}
 +\underbrace{\EE\left[\widehat{\theta}^{(i)}_{\Tt}(\Delta)\right]-\theta^{(i)}_{\Tt}(\Delta)}_{\text{bias term}},\qquad i=1,2,
 $$
where $\Bar{Z}_j= Z_j- \EE[Z_j]$, and 
$$
Z_j= \left(\widetilde X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\widetilde X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)^2,  \qquad j\in\{1,\cdots, N\}.
$$ 

\medskip

\noindent \textbf{Bounding the bias term :} Recall that $\xi^{(j)}(\Tt)=\widetilde X^{(j)}(\Tt)- X^{(j)}(\Tt)$.
Using the identities $a^2 - b^2 = (a-b)^2 + 2b(a-b)$ and  $(a-b)^2\leq 2a^2+2b^2$,  and  Cauchy-Schwarz inequality,  we obtain
\begin{multline*}
    \EE\left[\widehat {\theta}^{(i)}_{\Tt}(\Delta)\right]-\theta^{(i)}_{\Tt}(\Delta)\\
    =   \EE\!\left[\! \frac{1}{N}\sum_{j=1}^N \! \left(\!\widetilde X^{(j)}\!\left(\! \Tt-\frac{\Delta}{2}e_i\right) \!- \!\widetilde X^{(j)}\!\left(\Tt+\frac{\Delta}{2}e_i\right)\!\right)^{\!2}\right]\!
     -\EE\!\left[ \left(\! X\!\left(\Tt-\frac{\Delta}{2}e_i\right)\!-X\!\left(\!\Tt+\frac{\Delta}{2}e_i\right)\!\right)^{\!2}\right]
     %\\
%    \leq& \;  \EE\left[ \! \frac{1}{N}\sum_{j=1}^N  \left(\widetilde X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\widetilde X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)^2 \!- \left( X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)- X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)^2\right]\\
%    \hspace{-6cm}\color{blue} =  \EE\left[ \frac{1}{N}\sum_{j=1}^N\left\{\xi^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\xi^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}\right.\\
%   \hspace{.5cm} \left.\times\left \{\xi^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\xi^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)+ 2\left(X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)- X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)\right\}\right]
   \\
    \hspace{-5.5cm} \color{blue} = \color{black} \frac{1}{N}\sum_{j=1}^N  \EE\left[\left\{\xi^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\xi^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}^2\right]\\
    +\frac{2}{N}\sum_{j=1}^N \EE\left[\left\{\xi^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\xi^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}\right.\\ \hspace{4cm} \times \left.\left\{ X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)- X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}\right]\\
    \leq  4R_2(\mathfrak m) +4\left( R_2(\mathfrak m)\times \theta^{(i)}_{\Tt}(\Delta)\right)^{1/2}  := \frac{\eta^*_{\Tt}(\Delta)}{2}.
\end{multline*}

\medskip

\noindent \textbf{Bounding the stochastic term~:}
Using the convexity of the function $x\mapsto x^p$, (H\ref{ass_H1}) and (H\ref{ass_H2}) we obtain :
\begin{align*}
    \EE\left[|\Bar{Z}_j|^p\right]
    \leq& 2^p \EE[|Z_j|^p]\\
    =& 2^p \EE\left[\left(\widetilde X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)-\widetilde X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)^{2p}\right]\\
    =& 2^p \EE\left[\left\{X^{(j)}\!\left(\!\Tt-\frac{\Delta}{2}e_i\right)\!- X^{(j)}\!\left(\Tt+\frac{\Delta}{2}e_i\right)\! +\xi^{(j)}\!\left(\!\Tt-\frac{\Delta}{2}e_i\right)-\xi^{(j)}\!\left(\!\Tt+\frac{\Delta}{2}e_i\right)\right\}^{2p}\right] \\
    \leq & \frac{18^p}{3}\EE\left[\left(X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)- X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)^{2p}\right]\\
    &+\frac{18^p}{3}\EE\left[\left|\xi^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)\right|^{2p}+\left|\xi^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right|^{2p}\right]\\
    \leq& \frac{18^p}{3}\left(\EE\left[ \left(X^{(j)}\left(\Tt-\frac{\Delta}{2}e_i\right)- X^{(j)}\left(\Tt+\frac{\Delta}{2}e_i\right)\right)^{2p} \right]+ 2R_{2p}(\mathfrak m) \right)\\
    \leq & \frac{18^p}{3}\left( \frac{p!}{2}\mathfrak{a} \mathfrak{A}^{p-2}\Delta^{2p\underline H (\Tt)}+p!\mathfrak{c} \mathfrak{D}^{p-2} \rho(\mathfrak m)^{2p}\right)\\
    \leq& \mathfrak{g}\frac{p!}{2}\mathbf{\mathfrak{G}}^{p-2}\times \max\{ \Delta^{2p\underline H (\Tt)},\rho(\mathfrak m)^{2p}\}=\mathfrak{g}\frac{p!}{2}\mathbf{\mathfrak{G}}^{p-2}\times\varrho(\Delta,\mathfrak m)^{-p} ,
\end{align*}
for some positive constants $\mathfrak G$ and $\mathfrak g$. The bounds on the moments of $\Bar{Z}_j$ allows to derive exponential bounds for the concentration $\widehat{\theta}^{(i)}_{\Tt}(\Delta)-\theta^{(i)}_{\Tt}(\Delta)$. 
Let $\mathfrak{m}$ sufficiently large such that  $0<\eta^*_{\Tt}(\Delta) \leq  1 $, and let $\eta^*_{\Tt}(\Delta)\leq \eta \leq 1$.   By Bernstein's inequality,  we get  
\begin{align*}
    \PP \left[\widehat { \theta} ^{(i)}_{\Tt}(\Delta) -\ \theta^{(i)}_{\Tt}(\Delta)\geq \eta \right]=& \PP \left [\frac{1}{N} \sum_{j=1}^N\Bar{Z}_j+\EE\left[\widehat { \theta}^{(i)}_{\Tt}(\Delta)\right]- \theta^{(i)}_{\Tt}(\Delta)\geq \eta\right]\\
    \leq & \PP\left [ \frac{1}{N} \sum_{j=1}^N\Bar{Z}_j+\frac{\eta^*_{\Tt}(\Delta)}{2}\geq \eta \right]\\
    \leq & \PP\left [ \frac{1}{N} \sum_{j=1}^N\Bar{Z}_j\geq \frac{\eta}{2}\right]\\
    \leq & \exp\left(-\frac{N\eta^2}{8\mathfrak{g}\varrho(\Delta,\mathfrak m)^{-2}+4\mathfrak{G}\varrho(\Delta,\mathfrak m)^{-1}\eta} \right).
\end{align*}
Then   
\begin{equation*}
\PP \left[\hat  \theta^{(i)}_{\Tt}(\Delta) -\ \theta^{(i)}_{\Tt}(\Delta)\geq \eta \right] \leq \exp\left(-\mathfrak{u}N\eta^2\varrho(\Delta,\mathfrak m) \right), 
\end{equation*}
where $\mathfrak{u}=\{8\mathfrak{g}+4\mathfrak{G}\}^{-1}$, because  $\eta,\varrho(\Delta,\mathfrak m)\leq 1$. A similar bound can be derived for $\mathbb{P}\left[\widehat{\theta}^{(i)}_{\Tt}(\Delta)-\theta^{(i)}_{\Tt}(\Delta)\leq - \eta  \right] .$
\end{proof}

\medskip
	
	
\begin{proof}[Proof of  \eqref{eq:bound-alpha_main}]
We have to prove that 
constants $\tilde L_5$, $\tilde L_6$ exist such that, for sufficiently small  $\Delta$,
\begin{equation}\label{eq:bound-alpha_SM}
	\PP(|\widehat{\alpha_{\Tt}}(\Delta)-\alpha_{\Tt}(\Delta)|\geq \varepsilon)
	\leq \tilde L_5
	\exp\left(
	-\tilde L_6N\varepsilon^2\frac{\Delta^{4\overline{H}(\Tt)}\varrho(\Delta)}{\log^2(\Delta)}
	\right).
\end{equation} 
 Here, $\varrho(\Delta)$ is a short notation for $\varrho(\Delta)=\varrho(\Delta,\mathfrak m)$.  Let us define the event
\begin{equation*}
    \Omega_1 = \left\{ \frac{\widehat{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{\widehat{\underline{H}}(\Tt)}} \neq \frac{\widehat{\gamma_{\Tt}}(\Delta)}{(\Delta)^{\widehat{\underline{H}}(\Tt)}} \right\}.
\end{equation*}
Using the definition of $\widehat\alpha_{\Tt}(\Delta)$, we have, for any $\varepsilon\in(0,1)$:
\begin{align}
    \PP(|\widehat{\alpha}_{\Tt}(\Delta)-\alpha_{\Tt}(\Delta)|\geq \varepsilon, \Omega_1)
    &\leq
    \PP\left(\left|
        \left|\frac{\widehat\gamma_{\Tt}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}}-\frac{\widehat\gamma_{\Tt}(\Delta)}{\Delta^{2\widehat{\underline{H}}(\Tt)}}\right|
        -
        \left|\frac{\gamma_{\Tt}(2\Delta)}{(2\Delta)^{2\underline{H}(\Tt)}}-\frac{\gamma_{\Tt}(\Delta)}{\Delta^{2\underline{H}(\Tt)}}\right|
    \right| \geq \varepsilon\right)\nonumber \\
    &\leq
    \PP\left(\left|
        \frac{\widehat\gamma_{\Tt}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}}- \frac{\gamma_{\Tt}(2\Delta)}{(2\Delta)^{2\underline{H}(\Tt)}}\right|
        +
        \left| \frac{\widehat\gamma_{\Tt}(\Delta)}{\Delta^{2\widehat{\underline{H}}(\Tt)}}-\frac{\gamma_{\Tt}(\Delta)}{\Delta^{2\underline{H}(\Tt)}}\right|
    \geq \varepsilon\right)\nonumber\\
    &\leq B_\varepsilon + B_\varepsilon' + B_\varepsilon'' + B_\varepsilon''',
    \label{eq:decomposition-concentration-alpha}
\end{align}
where
\begin{equation*}
    B_\varepsilon 
    = \PP\left(\frac{\widehat{\gamma_{\Tt}}(\Delta)}{\Delta^{2\widehat{\underline{H}}(\Tt)}} -\frac{{\gamma_{\Tt}}(\Delta)}{\Delta^{2\underline{H}(\Tt)}}\geq \frac{\varepsilon}{2}\right),
    \qquad
    B_\varepsilon' 
    = \PP\left(\frac{\widehat{\gamma_{\Tt}}(\Delta)}{\Delta^{2\widehat{\underline{H}}(\Tt)}} -\frac{{\gamma_{\Tt}}(\Delta)}{\Delta^{2\underline{H}(\Tt)}}\leq -\frac{\varepsilon}{2}\right).
\end{equation*}
\begin{equation*}
    B_\varepsilon''
    = \PP\left(\frac{\widehat{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}} -\frac{{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\underline{H}(\Tt)}}\geq \frac{\varepsilon}{2}\right),
    \qquad
    B_\varepsilon''' 
    = \PP\left(\frac{\widehat{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}} -\frac{{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\underline{H}(\Tt)}}\leq -\frac{\varepsilon}{2}\right).
\end{equation*}
Since all these terms can be bounded in a similar way, we  focus on $B_\varepsilon$. By rearranging the different terms and using simple algebra, we get
\begin{align*}
    B_\varepsilon
    &=\PP\left(\frac{{\gamma_{\Tt}}(\Delta)}{\Delta^{2\underline{H}(\Tt)}}\left(\frac{\widehat{\gamma_{\Tt}}(\Delta) \Delta ^{2\underline{H}(\Tt)}}{\gamma_{\Tt}(\Delta)\Delta^{2\widehat{\underline{H}}(\Tt)}} -1\right)\geq \frac{\varepsilon}{2}\right)\\
    &\leq \PP\left(\frac{\widehat{\gamma_{\Tt}}(\Delta)}{\gamma_{\Tt}(\Delta)}\geq\left(1+ \frac{\varepsilon}{2}\frac{\Delta^{2\underline{H}(\Tt)}}{\gamma_{\Tt}(\Delta)}\right)^{\frac{1}{2}}\right)+ \PP\left(\frac{\Delta^{2\widehat{\underline{H}}(\Tt)}}{\Delta^{2\underline{H}(\Tt)}}\leq\left(1+ \frac{\varepsilon}{2}\frac{\Delta^{2\underline{H}(\Tt)}}{\gamma_{\Tt}(\Delta)}\right)^{-\frac{1}{2}}\right)\\
    &\leq \PP\left(\frac{\widehat{\gamma_{\Tt}}(\Delta)}{\gamma_{\Tt}(\Delta)}\geq 1+\delta(\Delta)\frac{\varepsilon}{2}\right)
    + \PP\left(\frac{\Delta^{2\widehat{\underline{H}}(\Tt)}}{\Delta^{2\underline{H}(\Tt)}}\leq1-\delta(\Delta) \frac{\varepsilon}{2}\right),
\end{align*}
where
\begin{equation*}
    \delta^2(\Delta)=
    \frac{\Delta^{4\underline{H}(\Tt)}/\gamma^2_{\Tt}(\Delta)}%
    {4\{1+\Delta^{2\underline{H}(\Tt)}/\gamma_{\Tt}(\Delta)\}} 
    = K_1^*(\Tt)\{1+o(1)\}
    \quad \text{with} \quad
    K_1^*(\Tt)=\frac{1}{4\{1+K_1^2(\Tt)\}}.
\end{equation*}
 Using~\eqref{eq:assumption-theta-hat_SM},   the first term can easily be bounded by
\begin{equation}\label{eq:first-term}
    \PP\left(\frac{\widehat{\gamma_{\Tt}}(\Delta)}{\gamma_{\Tt}(\Delta)}\geq 1+\delta(\Delta)\frac{\varepsilon}{2}\right) 
    \leq  2\exp \left(-\frac{\mathfrak{u}}{4}N\varepsilon^2\delta^2(\Delta)\Delta^{4\underline{H}(\Tt)}\varrho(\Delta)\right).
\end{equation}
The study of the second term boils down to the concentration of $\widehat{\underline{H}}(\Tt)$ around $\underline{H}(\Tt)$. Indeed, using~\eqref{eq:concentration-Hhat-around-H}, we have
\begin{align}
    \PP\left(\frac{\Delta^{2\widehat{\underline{H}}(\Tt)}}{\Delta^{2\underline{H}(\Tt)}}\leq1-\delta(\Delta) \frac{\varepsilon}{2}\right)
    &\leq \PP\left(2\widehat{\underline{H}}(\Tt)-2\underline{H}(\Tt)\leq \frac{-\delta(\Delta)}{\log(\Delta)} \frac{\varepsilon}{2}\right)\nonumber\\
    &\leq  C_1\exp \left(-C_2N\varepsilon^2\frac{\delta^2(\Delta)}{16\log^2(\Delta)}\Delta ^{4\underline{H}(\Tt)}\varrho(\Delta)\right)\label{eq:second-term}.
\end{align}
Therefore, taking together~\eqref{eq:first-term} and~\eqref{eq:second-term}, two positive constants $\tilde L_1$ and $\tilde L_2$ exist such that, for $\Delta$ small enough:
\begin{equation}\label{eq:control-Bvarepsilon}
    B_\varepsilon
    \leq 
    \widetilde{L}_1\exp\left(-\widetilde{L}_2N\varepsilon^2\frac{K_1^*(\Tt)}{\log^2(\Delta)}\Delta ^{4\underline{H}(\Tt)}\varrho(\Delta)\right).
\end{equation}
By~\eqref{eq:decomposition-concentration-alpha}, this implies that two positive constants $L_3$ and $L_4$ exist such that, for $\Delta$ small enough:
\begin{equation*}
    \PP(|\widehat{\alpha_{\Tt}}(\Delta)-\alpha_{\Tt}(\Delta)|\geq \varepsilon)
    \leq 
    L_3\exp\left(-L_4N\varepsilon^2\frac{\Delta ^{4\underline{H}(\Tt)}\varrho(\Delta)}{\log^2(\Delta)}\right)
    + \PP(\overline{\Omega}_1).
\end{equation*}
It remains to bound $\PP(\overline{\Omega}_1)$. For this, assume without loss of generality, that 
$$
 {{\gamma_{\Tt}}(2\Delta)}/{(2\Delta)^{2{\underline{H}}(\Tt)}}  \geq {{\gamma_{\Tt}}(\Delta)}/{\Delta^{{2\underline{H}}(\Tt)}}.
$$ 
By definition of $\overline{\Omega}_1$, we then have, for any $0<\varepsilon\leq 1$~: 
\begin{align*}
    \PP(\overline{\Omega}_1) 
    &= \PP\left(
        \frac{\widehat{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}}  - \frac{\widehat{\gamma_{\Tt}}(\Delta)}{(\Delta)^{2\widehat{\underline{H}}(\Tt)}}
        = 0
    \right) \\
    &\leq \PP\left(
        \frac{\widehat{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}}  - \frac{\widehat{\gamma_{\Tt}}(\Delta)}{(\Delta)^{2\widehat{\underline{H}}(\Tt)}}
        \leq (1-\varepsilon) 
        \left(
        \frac{{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2{\underline{H}}(\Tt)}}  - \frac{{\gamma_{\Tt}}(\Delta)}{(\Delta)^{2{\underline{H}}(\Tt)}}
        \right)
    \right)\\
    &\leq \PP\left(\frac{\widehat{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\widehat{\underline{H}}(\Tt)}}-\frac{{\gamma_{\Tt}}(2\Delta)}{(2\Delta)^{2\underline{H}(\Tt)}}\leq \frac{\varepsilon}{2}\alpha_{\Tt}(\Delta)\right)+\PP\left(\frac{\widehat{\gamma_{\Tt}}(\Delta)}{\Delta^{2\widehat{\underline{H}}(\Tt)}}-\frac{{\gamma_{\Tt}}(\Delta)}{\Delta^{2\underline{H}(\Tt)}}\geq- \frac{\varepsilon}{2}\alpha_{\Tt}(\Delta)\right)\\ 
    &\leq \widetilde{L}_3\exp \left(-\widetilde{L}_4N\varepsilon^2\alpha_{\Tt}^2(\Delta)\frac{\Delta ^{4\underline{H}(\Tt)}\varrho(\Delta)}{\log^2(\Delta)}\right).
\end{align*}
 For the last inequality,  we use inequalities similar to~\eqref{eq:control-Bvarepsilon} applied with $\Delta$ and $2\delta$, and where $\varepsilon$ was replaced by $\varepsilon\alpha_{\Tt}(\Delta)$.  Now, let us notice that
\begin{equation*}
    \alpha_{\Tt}(\Delta) = \frac{K_2(\Tt)}{2^{2D(\Tt)}-1} \Delta^{2D(\Tt)} (1+o(1)),
\end{equation*}
where $K_2(\Tt)$ is defined by \eqref{eq:K1K2} and, recall that $D(\Tt)= \overline H(\Tt) - \underline H(\Tt)$.
This implies that constants $\tilde L_5$ and $\tilde L_6$ exist such that, for sufficiently small $\Delta$,
\begin{equation}\label{eq:bound-alpha}
    \PP(|\widehat{\alpha}_{\Tt}(\Delta)-\alpha_{\Tt}(\Delta)|\geq \varepsilon)
    \leq \tilde L_5
    \exp\left(
        -\tilde L_6N\varepsilon^2\frac{\Delta^{4\overline{H}(\Tt)}\varrho(\Delta)}{\log^2(\Delta)}
    \right).
\end{equation}
\end{proof}

%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%


\section{Complements for the proof of Proposition \ref{conc_Lest}}\label{secSM_conc_Lest}
The following result implies the bounds for the terms $B^{(i)}_3$, $B^{(i)}_4$, $i=1,2$, in \eqref{B3B4_main} in the proof of Proposition \ref{conc_Lest} in the Appendix. 


\begin{lemSM}\label{lemma_L2_use}
Let $\varepsilon\in (0,1)$ and set 
\begin{equation*}
\mathfrak D_{\varepsilon}=\PP\left( \frac{1}{(2^{2\widehat{D}(\Tt)}-1)\Delta^{2\widehat{D}(\Tt)}} -\frac{1}{(2^{2D(\Tt)}-1)\Delta^{2D(\Tt)}}\geq \varepsilon\right).
\end{equation*}
Then two positive constants $\tilde C_3$ and $\tilde C_4$ exists such that~:
\begin{equation}\label{proba-interm}
\mathfrak D_{\varepsilon}\leq \tilde C_3 \exp\left(
	-\tilde C_4 N\varepsilon^2\left(2^{2D(\Tt)}-1\right)^2\frac{\Delta^{4\overline H (\Tt)}\varrho(\Delta)}{\log^4(\Delta)}\Delta^{8D(\Tt)}
	\right).
\end{equation}
\end{lemSM}


\begin{proof}[Proof of Lemma SM.\ref{lemma_L2_use}]
 We first  decompose as follow~:
\begin{multline}
\mathfrak D_{\varepsilon}= \PP\left(\Delta^{2D(\Tt)-2\widehat{D}(\Tt)}\frac{2^{2\widehat{D}(\Tt)}-1}{2^{2D(\Tt)}-1}-1\geq \varepsilon\Delta^{2D(\Tt)}(2^{2D(\Tt)}-1)\right)\\
\leq \PP\left(\Delta^{2D(\Tt)-2\widehat{D}(\Tt)}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right)\\
+ \PP\left(\frac{2^{2\widehat{D}(\Tt)}-1}{2^{2D(\Tt)}-1}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right).
\end{multline}
Since $\Delta $ is assumed to be sufficiently small, we first have~:
\begin{equation*}
    \PP\left(\Delta^{2D(\Tt)-2\widehat{D}(\Tt)}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right)\leq \PP\left(D(\Tt)-\widehat{D}(\Tt)\leq \varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{4\log(\Delta)}\right).
\end{equation*}
Now using \eqref{eq:concentration-Difference} we obtain for any $\varepsilon \in (0,1)$~:
\begin{multline}\label{T1}
\PP\left(\Delta^{2D(\Tt)-2\widehat{D}(\Tt)}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right)\\
\leq\tilde L_8 \exp\left(
	-\frac{\tilde L_7}{4} N\varepsilon^2\left(2^{2D(\Tt)}-1\right)^2\frac{\Delta^{4\overline{H}(\Tt)}\varrho(\Delta)}{\log^4(\Delta)}\Delta^{8D(\Tt)}
	\right).
\end{multline}
For the second term, and by using simple algebra we have~:
\begin{equation}
\PP\left(\frac{2^{2\widehat{D}(\Tt)}-1}{2^{2D(\Tt)}-1}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right)=\PP\left(2^{2\widehat{D}(\Tt)-2D(\Tt)}\geq \varepsilon\Delta^{2D(\Tt)}\frac{\left(2^{2D(\Tt)}-1\right)^2}{2^{2D(\Tt)+1}}+1\right)
\end{equation}
Taking the logarithm on both sides and using the  inequality $\log(x)\leq x-1$,  $\forall x>0$, we obtain~:
\begin{equation}
\PP\left(\frac{2^{2\widehat{D}(\Tt)}-1}{2^{2D(\Tt)}-1}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right)\leq \PP\left(\widehat{D}(\Tt)-D(\Tt)\geq\varepsilon\Delta^{2D(\Tt)}\frac{\left(2^{2D(\Tt)}-1\right)^2}{2^{2D(\Tt)+2}\log2} \right).
\end{equation}
Finally, using \eqref{eq:concentration-Difference}
\begin{multline}\label{T2}
\PP\left(\frac{2^{2\widehat{D}(\Tt)}-1}{2^{2D(\Tt)}-1}\geq 1+\varepsilon\Delta^{2D(\Tt)}\frac{2^{2D(\Tt)}-1}{2}\right)\\\leq \tilde L_8\exp\left(-\frac{\tilde L_7}{2^{4D(\Tt)+2}\log^22} N\varepsilon^2\left(2^{2D(\Tt)}-1\right)^4\frac{\Delta^{4\overline H(\Tt)}\varrho(\Delta)}{\log^2(\Delta)}\Delta^{8D(\Tt)}\right).
\end{multline}
Taking together \eqref{T1} and \eqref{T2}, we deduce that  positive constants $\tilde C_3$ and $\tilde C_4$ exist such that, $\forall \varepsilon\in (0,1)$, 
\begin{equation}\label{proba-interm}
\mathfrak D_{\varepsilon}\leq \tilde C_3 \exp\left(
	-\tilde C_4 N\varepsilon^2\left(2^{2D(\Tt)}-1\right)^2\frac{\Delta^{4\overline H (\Tt)}\varrho(\Delta)}{\log^4(\Delta)}\Delta^{8D(\Tt)}
	\right).
\end{equation}
\end{proof}

\medskip

We can now derive the bounds for the terms $B_3$, $B_4$ in
\eqref{B3B4_main}
 %\eqref{eq:bound-B3} and \eqref{eq:bound-B4}, 
 from the proof of Proposition \ref{conc_Lest}.
We first notice that  
$$
B_3= \mathfrak D_{\frac{\varepsilon}{3\alpha_{\Tt}^{(i)}(\Delta)}}\quad \text{ and }\quad B_4= \mathfrak D_{\sqrt{\varepsilon/3}}.
$$
Since  $\alpha_{\Tt}^{(i)}(\Delta)\sim L_2^{(i)}(\Tt)(2^{2D(\Tt)}-1)\Delta^{2D(\Tt)}$, we obtain~:
\begin{equation}\label{eq:bound-B3}
B_3 \leq \tilde C_3 \exp\left(
	-\tilde C_4 N\left(\frac{\varepsilon \Delta^{-2D(\Tt)}}{3L_2^{(i)}(\Tt)(2^{2D(\Tt)}-1)} \right)^2\left(2^{2D(\Tt)}-1\right)^2\frac{\Delta^{4\overline H (\Tt)}\varrho(\Delta)}{\log^4(\Delta)}\Delta^{8D(\Tt)}
	\right), 
\end{equation}
\begin{equation}\label{eq:bound-B4}
B_4\leq  \tilde C_3 \exp\left(
	-\tilde C_4 N\varepsilon\left(2^{2D(\Tt)}-1\right)^2\frac{\Delta^{4\overline H (\Tt)}\varrho(\Delta)}{3\log^4(\Delta)}\Delta^{8D(\Tt)}
	\right).   
\end{equation}
Finally, by combining \eqref{eq:bound-B1}, %\eqref{eq:bound-B2},
 \eqref{eq:bound-B3} and \eqref{eq:bound-B4},  
 two positive constants $C_3$ and $C_4$ exists such that for any $\varepsilon\in (0,1)$ we have 
\begin{equation}
%\mathfrak G^{(i)}_\varepsilon
\PP\left(\left|\widehat{L_2^{(i)}}(\Tt)-L_2^{(i)}(\Tt)\right|\geq \varepsilon\right)
 \leq C_3\exp\left(\!
	-C_4N\varepsilon\min\{\varepsilon,\Delta^{4D(\Tt)}\}(4^{D(\Tt)}\!-1)^2\frac{\Delta^{4\overline H (\Tt)}\varrho(\Delta)}{\log^4(\Delta)}\Delta^{4D(\Tt)}\!
	\right)\!,
\end{equation} 
$i=1,2$. Here, we also use the fact that $L_2^{(1)}, L_2^{(2)}$ are a bounded function.

%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%

\section{Complements for the proof of Proposition \ref{mprop}}\label{secSM_mprop}

\subsection{Proof of equation (\ref{eq:B-diag})}

We have to prove  
\begin{equation}\label{eq:B-dia_SM}
	B(\Tt,\Ss)= \frac{1}{2}+O(\|\Tt-\Ss\|^2),
\end{equation}
for $\Tt$ and $\Ss$ sufficiently close. Here  $B(\Tt,\Ss) =2D(H_1(\Tt),H_1(\Ss))D(H_2(\Tt),H_2(\Ss))$.
Let us note that the map $(x,y)\mapsto D(x,y)$ admits partial derivatives of any order on $(0,1)\times (0,1)$. Next, let
$$
g(x) = \log(\Gamma (2x+1)) + \log( \sin(\pi x)) =:g_1(x) - g_2(x).
$$
We notice that $g^{\prime\prime}(x) < 0$, for any $x\in (0,1)$. Indeed, using the expression of the derivative of the digamma function, cf. \citet[page 260]{AS1964}, we have
$$
g^{\prime\prime}(x) = 4\sum_{k\geq 0} \frac1{(2x+1+k)^2} - \frac{\pi^2}{\sin^2 (\pi x)}
= g_1^{\prime\prime}(x) - g_2^{\prime\prime}(x).
$$
We deduce that $g^{\prime\prime}$ is decreasing on $[1/2, 1)$ and, since $g^{\prime\prime}(0+) = -\infty$, the function $g^{\prime\prime}_1$ is decreasing on $(0,1/2]$ with
$$
g^{\prime\prime}_1(0) =\pi^2/6, \;\; g^{\prime\prime}_1(1/4) =4 \{\pi^2/2 -4\}, \;\; g^{\prime\prime}_1(1/2) = 4 \{\pi^2/6 - 1\} ,
$$
and the function $g^{\prime\prime}_2$ is decreasing on $(0,1/2]$ with
$$
g_2^{\prime\prime}(0+) =\infty, \;\; g_2^{\prime\prime}(1/4) =2\pi^2, \;\; g^{\prime\prime}_2(1/2) = \pi^2 ,
$$
we conclude that $g^{\prime\prime}<0$ on $(0,1]$. In other words, $x\mapsto g(x)$ is log-concave, and thus
$$
2D(x,y)=\frac{\sqrt{\exp(g(x))\times \exp(g(y))}} {\exp(g((x+y)/2))} <1,\qquad \forall 0<x\neq y \leq 1.
$$
We deduce that $1/2$ is the maximum value that the function  $B$ could reach. Which means that the gradient of $B$ on the diagonal is zero and therefore, we have \eqref{eq:B-dia_SM}.

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%

\subsection{Proof of equation (\ref{eq:double-a})}
We here  prove that
\begin{equation}\label{eq:double-a_SM}
	a(\Tt,\Ss)a(\Ss,\Tt)-1 =O(\|\Tt-\Ss\|^2).
\end{equation}
Since the functions $H_1$ and $H_2$ are supposed to be continuously differentiables, we obtain~:
\begin{equation*}
a(\Tt,\Ss)=\frac{\frac{1}{2}+\left\{\log(|A_1(\Tt)|)\nabla H_1(\Tt)+\log(|A_2(\Tt)|)\nabla H_2(\Tt)\right\}\cdot(\Tt-\Ss)+O(\|\Tt-\Ss\|^2)}{B(\Tt,\Ss)},
\end{equation*} 
where \eqref{eq:B-diag} is used here. Same arguments lead to~:
\begin{equation*}
a(\Ss,\Tt)=\frac{\frac{1}{2}-\left\{\log(|A_1(\Ss)|)\nabla H_1(\Tt)+\log(|A_2(\Ss)|)\nabla H_2(\Tt)\right\}\cdot(\Tt-\Ss)+O(\|\Tt-\Ss\|^2)}{B(\Tt,\Ss)}.
\end{equation*}
Thus, by multiplying those two quantities, we obtain when $\Ss$ is close  to $\Tt$~:
\begin{multline}\label{eq:petit-a}
a(\Tt,\Ss)a(\Ss,\Tt)
=\frac{1}{B^2(\Tt,\Ss)}\\
\times \left(\frac{1}{4}+\frac{1}{2} \left\{\log\left(\frac{|A_1(\Tt)|}{|A_1(\Ss)|}\right)\nabla H_1(\Tt)+\log \left(\frac{|A_2(\Tt)|}{|A_2(\Ss)|}\right)\nabla H_2(\Tt)\right\}\cdot(\Tt-\Ss)+O(\|\Tt-\Ss\|^2)\right).
\end{multline}
In another hand we have~:
$$
\log\left(\frac{|A_1(\Tt)|}{|A_1(\Ss)|}\right)=\frac{\nabla A_1(\Tt)}{|A_1(\Tt)|}.(\Tt-\Ss)+O(\|\Tt-\Ss\|^2),$$
 means that 
\begin{equation}\label{inq:firstone}
\log\left(\frac{|A_1(\Tt)|}{|A_1(\Ss)|}\right)\nabla H_1(\Tt).(\Tt-\Ss)=O(\|\Tt-\Ss\|^2).
\end{equation}
Same arguments gives~:
\begin{equation}\label{inq:secondeone}
\log\left(\frac{|A_2(\Tt)|}{|A_2(\Ss)|}\right)\nabla H_2(\Tt).(\Tt-\Ss)=O(\|\Tt-\Ss\|^2).
\end{equation}
By plugging \eqref{inq:firstone} and \eqref{inq:secondeone} in \eqref{eq:petit-a}, and using \eqref{eq:B-dia_SM}, we obtain 
\eqref{eq:double-a_SM} and thus \eqref{eq:double-a}. 


\quad


%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%



\section{Proof of Proposition \ref{prop_risk1}}\label{secSM_prop_risk1}


The proof of  Proposition \ref{prop_risk1} is a direct consequence of the following lemmas. 
	
	
\begin{lemSM}\label{Tsy}
Assumptions  (LP\ref{LP1}), (LP\ref{LP2}) and (LP\ref{LP3e}) hold true.
Then  a positive constant $a_1>1$ exists such that  
$$
\EE\left[\underset{1\leq m\leq M_0}{\max} W_m(\Tt)\Big{|}M_0\right]\leq \frac{\kappa^2}{ c\pi M_0h_1h_2}\left\{1+a_1M_0^{-1/4}\right\}.
$$
\end{lemSM}

\begin{proof}[Proof of Lemma SM.\ref{Tsy}]
For $1\leq m\leq M_0$ and $\Tt\in \cT$ we have  
$$
W_m(\Tt)= \frac{K\left(\boldsymbol{B}(\Tt^{new}_m-\Tt)\right)}{\sum_{m=1}^{M_0}K
	\left(\boldsymbol{B}(\Tt^{new}_m-\Tt)\right)}, \quad \text{with}\quad \frac{0}{0}=0.
$$
Let
$$
N_{h_1,h_2}(\Tt) =  \operatorname{Card} \left\{ \Tt^{new}_m, 1\leq m \leq M_0, \|\boldsymbol{B}(\Tt^{new}_m-\Tt)\| \leq 1\right\}.
$$
Given $M_0$, $N_{h_1,h_2}(\Tt)$ can also be written  as 
$$
N_{h_1,h_2}(\Tt)=B_1(\Tt)+B_2(\Tt)+\dots +B_{M_0}(\Tt) \leq M_0,
$$
where $\left(B_m(\Tt)\right)_{1\leq m\leq M_0} $ are iid Bernoulli random variables with  parameter $p(\Tt)$ given by $$
p(\Tt)=p(\Tt;\boldsymbol{B}) = \PP\left(\boldsymbol{B}(\Tt^{new}_m-\Tt)\in B(0,1)\big{|}M_0\right).
$$ 
Using (LP\ref{LP1})  we have
$$
W_m(\Tt)\leq \kappa^2\frac{\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\}}}{N_{h_1,h_2}(\Tt)},\quad \forall 1\leq m\leq M_0,
$$
which implies 
\begin{equation}
\EE\left[\underset{1\leq m\leq M_0}{\max} W_m(\Tt)\Big{|}M_0\right]
=\EE\left[\underset{m}{\max} W_m(\Tt)\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\}}\Big{|}M_0\right]\\
\leq\kappa^2 \EE\left[\frac{\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\}}}{N_{h_1,h_2}(\Tt)}\Big{|}M_0\right].
\end{equation}
Let
$$
\mathcal G:=\left\{p(\Tt)M_0\frac{\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\}}}{N_{h_1,h_2}(\Tt)}\leq 1+M_0^{-1/4} \right\}.
$$
Since (LP\ref{LP2}) holds true, by Lemma SM.\ref{Ber_par} we have that  $p(\Tt)\geq \pi ch_1h_2$, and therefore~:
\begin{align*}
\EE\left[\frac{\kappa^2\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\} }}{N_{h_1,h_2}(\Tt)}\Big{|}M_0\right]\leq&\frac{\kappa^2}{ c\pi M_0h_1h_2} \EE\left[\frac{M_0p(\Tt)}{N_{h_1,h_2}(\Tt)}
\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\}}\Big{|}M_0\right]\\
\leq & \frac{\kappa^2}{ c\pi M_0h_1h_2}\left(1+M_0^{-1/4}\right)+\EE\left[\frac{M_0p(\Tt)}{N_{h_1,h_2}(\Tt)}
\mathbf{1}_{\{N_{h_1,h_2}(\Tt)\geq 1\}}\mathbf{1}_{\overline{ \mathcal G}}\Big{|}M_0\right]\\
\leq& \frac{\kappa^2}{ c\pi M_0h_1h_2}\left(1+M_0^{- 1/4}\right)+M_0 p(\Tt)\PP\left(\overline{ \mathcal G} \mid M_0\right)
\end{align*}
It remains to bound $\PP\left(\overline{ \mathcal G} \mid M_0\right)$. By Hoeffding’s inequality we obtain
\begin{multline}
\PP\left(\overline{ \mathcal G} \mid M_0\right)
= \PP\left(\frac{p(\Tt)M_0}{N_{h_1,h_2}(\Tt)}\geq 1+M_0^{-1/4} \Big{|}M_0\right)\\
= \PP\left( \left\{-N_{h_1,h_2}(\Tt)+ p(\Tt)M_0\right\}(1+M_0^{-1/4})\geq p(\Tt)M_0^{3/4}\right)\\
\leq  \PP\left( -N_{h_1,h_2}(\Tt)+ p(\Tt)M_0\geq \frac{p(\Tt)M_0^{3/4}}{1+M_0^{-1/4}}\right)\\
\leq\exp\left(-2\left(\frac{p(\Tt)M_0^{3/4}}{1+M_0^{-1/4}}\right)^2M_0 \right)
\leq \exp\left(-\frac{\left\{M^{5/4}_0p(\Tt)\right\}^2}{2}\right).
\end{multline}
Since $\mathfrak m h_1h_2$ tends to infinity, there exists $a_1 >1$ such that   
$$
\EE\left[\underset{1\leq m\leq M_0}{\max} W_m(\Tt)\Big{|}M_0\right]\leq \frac{\kappa^2}{ c\pi M_0h_1h_2}\left(1+a_1M_0^{-1/4}\right).
$$
\end{proof}

\medskip

\begin{lemSM}\label{lemma_BV}
Under the assumptions of Lemma SM.\ref{Tsy}, a positive constant $a_1>1$ exists  such that 
    $$ 
    \EE\!\left[\left(\sum_{m=1}^{M_0}\left\{X^{new}(\Tt^{new}_m)\!-X^{new}(\Tt) \right\} W_m(\Tt)\right)^2 \Big{|}M_0 \right]\! \leq 2\left\{L_1(\Tt) h_1^{2H_1(\Tt)}+L_2(\Tt) h_2^{2H_2(\Tt)}\right\}\{1+o(1)\},
    $$
and
$$
\EE\left[\left(\sum_{m=1}^{M_0}\varepsilon_m W_m(\Tt)\right)^2 \Big{|}M_0\right]\leq \frac{\kappa^2\sigma^2}{c\pi}\frac{1}{M_0 h_1h_2}\left\{1+ a_1M_0^{-1/4}\right\}.
$$
\end{lemSM}



\begin{proof}[Proof of Lemma SM.\ref{lemma_BV}]
We start by proving the second inequality. For $1\leq m\neq m^\prime\leq M_0$,  $\varepsilon_m$ and $\varepsilon_{m^\prime}$ are independent. Moreover, the $\varepsilon_m $ and $W_m (\Tt)$ are independent, and the $\varepsilon_m$ are centered. From these, the fact that  
$\sum_{m=1}^{M_0}W_m(\Tt)=1 $, and Lemma SM.\ref{Tsy}, we deduce that 
\begin{multline}
\EE\left[\left(\sum_{m=1}^{M_0}\varepsilon_mW_m(\Tt) \right)^2\Big{|}M_0 \right]=\EE\left[\sum_{m=1}^{M_0}\varepsilon_m^2W_m^2(\Tt) \Big{|}M_0 \right]= \sigma^2 \EE\left[\sum_{m=1}^{M_0}W_m^2(\Tt) \Big{|}M_0 \right]\\
\leq  \sigma^2 \EE\left[\max_{1\leq m \leq M_0}W_m(\Tt)  \times \sum_{m=1}^{M_0}W_m(\Tt) \Big{|}M_0 \right]\leq \frac{\sigma^2 \kappa^2}{ c\pi M_0h_1h_2}\left\{1+a_1M_0^{-1/4}\right\}.
\end{multline}

For the first inequality, denote $\Tt^{new}_m=(t^{new}_{m,1},t^{new}_{m,2})$ and  $\mathcal T ^{new}_{obs}=\left\{\Tt^{new}_m, 1\leq m\leq M_0 \right\}$.
Let $\Tt=(t_1,t_2)\in \cT$. Recall that $K$ is a density with the support in $[-1,1]^2$, and thus $W_m(\Tt)=0$ as soon as  $|t_1-t_{m,1}^{new}|\geq h_1$ or $|t_2-t_{m,2}^{new}|\geq h_2$. By Jensen's inequality,
$$
\EE\!\left[\left\{\sum_{m=1}^{M_0}[X^{new}(\Tt^{new}_m)\!-\!X^{new}(\Tt)] W_m(\Tt)\right\}^{\!2} \Big{|}M_0 \right]\! \leq  \EE\!\left[\sum_{m=1}^{M_0}\left[X^{new}(\Tt^{new}_m)\!-\!X^{new}(\Tt)\right]^2 W_m(\Tt) \Big{|}M_0 \right].
$$
Next, for $1\leq m\leq M_0$, we have
\begin{multline*}
	\EE\left[\left\{X^{new}(\Tt^{new}_m)-X^{new}(\Tt)\right\}^2\big{|}M_0,\mathcal T ^{new}_{obs}\right]\\
	\leq
	2\EE\left[\left\{X^{new}(\Tt^{new}_m)-X^{new}(t_1,t^{new}_{m,2}) \right\}^2 \big{|} M_0,\mathcal T ^{new}_{obs} \right]\\
	+2\EE\left[\left\{X^{new}(t_1,t^{new}_{m,2})-X^{new}(\Tt)\right\}^2\big{|}M_0,\mathcal T ^{new}_{obs}\right] .
\end{multline*}
Let $\rho_i=:|t_i-t^{new}_{m,i}|$,  $i=1,2$.
Then by Lemma SM.\ref{lemme_tec_1}, we have 
\begin{multline*}
	\EE\left[\left(X^{new}(\Tt^{new}_m)-X^{new}(t_1,t^{new}_{m,2}) \right)^2 \big{|} M_0,\mathcal T ^{new}_{obs},\rho_1 \leq h_1\right]\leq  L_1(\Tt^{new}_m) \rho_1^{2H_1(\Tt)} \mathbf 1_{\{\rho_1 \leq h_1\}}\\
	\leq L_1(\Tt)\rho_1^{2H_1(\Tt)}\mathbf 1_{\{\rho_1 \leq h_1\}}+|L_1(\Tt)-L_1(\Tt^{new}_m)|\rho_1^{2H_1(\Tt)}\mathbf 1_{\{\rho_1 \leq h_1\}}\\
	\leq L_1(\Tt) h_1^{2H_1(\Tt)}+ k_1h_1^{2H_1(\Tt)}\|\Tt-\Tt_m^{new}\|.
\end{multline*}
For the last inequality we used the fact that  $L_1$ is Lipschitz continuous with Lipschitz constant $k_1$. Using the same type of arguments, and the fact that $L_2$ is Lipschitz continuous with Lipschitz constant $k_2$, we get 
$$
\EE\left[\left(X^{new}(t_1,t^{new}_{m,2})-X^{new}(\Tt)\right)^2\big{|}M_0,\mathcal T ^{new}_{obs},\rho_2 \leq h_2\right] \leq   L_2(\Tt) h_2 ^{2H_2(\Tt)}+ k_2h_2^{2H_2(\Tt)}\|\Tt-\Tt_m^{new}\|.
$$
Gathering facts,
$$
\EE\left[\sum_{m=1}^{M_0}\left\{X^{new}(\Tt^{new}_m)-X^{new}(\Tt)\right\}^2 W_m(\Tt) \Big{|}M_0 \right]\leq 2\left\{L_1(\Tt)h_1^{2H_1(\Tt)}+L_2(\Tt)h_2^{2H_2(\Tt)}\right\}\{1+o(1)\}.
$$
\end{proof}



%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%

%
%\subsection{Proof of Proposition \ref{risk_2}}
%\begin{proof}[Proof of Proposition \ref{risk_2}]
%\color{blue}
%Let $\widehat \omega (\Tt)$,  $\widehat \alpha_i(\Tt)$ and  $\widehat \Lambda_i (\Tt)$ be the estimators obtained by replacing $H_i(\Tt)$ and $L_i(\Tt)$ in the definitions of     $ \omega (\Tt)$,  $ \alpha_i(\Tt)$ and $ \Lambda_i(\Tt)$, respectively. We define the sets 
%$$
%\mathcal{F}=\bigcap_{i=1,2} \left\{ |\widehat \alpha _i(\Tt)-\alpha_i(\Tt)|\leq \log^{-a}(\mathfrak m)\right\}
%%\cap \left\{ |\widehat \alpha _2(\Tt)-\alpha_2(\Tt)|\leq \log^{-a}(\mathfrak m)\right\},
%%		$$
%\quad\text{		and } \quad 
%%		$$
%\mathcal E= \bigcap_{i=1,2}\left\{ \left|  \widehat \Lambda_i(\Tt)/\Lambda_i(\Tt)-1\right| \leq \log^{-a}(\mathfrak m)\right\},
%%\cap\left\{ \left| \frac{\widehat \Lambda_2(\Tt)}{\Lambda_2(\Tt)}-1\right| \leq \log^{-a}(\mathfrak m)\right\},
%$$
%with $a$ from assumption (LP\ref{LP4}).	
%
%
%Since  $\widehat h^*_1$ and $\widehat h^*_2$ are independent of the new realization $X^{new}$,   by  \eqref{risk_1} we obtain 
%$$
%\EE\left[\{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2 \big{|}M_0 \right]\leq  \frac{\kappa^2}{c\pi} \frac{\sigma^2}{M_0 \widehat h^*_1 \widehat h^*_2}+ 2L_1(\Tt)\{\widehat h_1^*\}^{2
%	H_1(\Tt)}+ 2L_2(\Tt)\{\widehat h_2^*\}^{2H_2(\Tt)}.
%$$
%Replacing the expressions of $\widehat h^*_1$ and $\widehat h^*_2$, we have 
%$$
%\frac{\kappa^2}{c\pi} \frac{\sigma^2}{M_0 \widehat h_1^* \widehat h_2^*}=  \frac{\kappa^2\sigma^2}{c\pi} M_0^{ \alpha_1(\Tt)+\alpha_2(\Tt)-1}\Lambda_1^{-\alpha_1(\Tt)}(\Tt)\Lambda_2^{-\alpha_2(\Tt)}(\Tt)\times \widehat {\Upsilon}(\Tt),
%$$
%where 	
%\begin{equation}
%	\widehat {\Upsilon}(\Tt)=
%	M_0^{ \widehat \alpha_1(\Tt)+\widehat\alpha_2(\Tt)-\alpha_1(\Tt)-\alpha_2(\Tt)}\frac{\widehat \Lambda_1^{-\widehat\alpha_1(\Tt)}(\Tt)\widehat \Lambda_2^{-\widehat\alpha_2(\Tt)}(\Tt)}{ \Lambda_1^{-\alpha_1(\Tt)}(\Tt)\Lambda_2^{-\alpha_2(\Tt)}(\Tt)}.
%\end{equation}
%Then, under the event $\mathcal F$ and using Cauchy-Schwarz inequality, we obtain
%\begin{multline*}
%	\EE\left[ \frac{\kappa^2}{c\pi} \frac{\sigma^2}{M_0 \hat h_1 \hat h_2}  \mathbf{1}_\mathcal{F} \big{|} M_0 \right]
%	\leq \frac{\kappa^2\sigma^2}{c\pi} M_0^{ \alpha_1(\Tt)+\alpha_2(\Tt)-1}\Lambda_1^{-\alpha_1(\Tt)}(\Tt)\Lambda_2^{-\alpha_2(\Tt)}(\Tt) \EE\left[  \widehat {\Upsilon}(\Tt)\big{|}M_0\right]\\
%	\leq \frac{\kappa^2\sigma^2}{c\pi} M_0^{ \alpha_1(\Tt)+\alpha_2(\Tt)-1}\Lambda_1^{-\alpha_1(\Tt)}(\Tt)\Lambda_2^{-\alpha_2(\Tt)}(\Tt) M_0^{2\log^{-a}(\mathfrak m)}\EE\left[\frac{\hat \Lambda_1^{-\hat\alpha_1(\Tt)}(\Tt)\hat \Lambda_2^{-\hat\alpha_2(\Tt)}(\Tt)}{ \Lambda_1^{-\alpha_1(\Tt)}(\Tt)\Lambda_2^{-\alpha_2(\Tt)}(\Tt)}\mathbf{1}_\mathcal{F}\big{|}M_0\right]\\
%	\leq\frac{\kappa^2\sigma^2}{c\pi} M_0^{ \alpha_1(\Tt)+\alpha_2(\Tt)-1+2\log^{-a}(\mathfrak m)}\Lambda_1^{-\alpha_1(\Tt)}(\Tt)\Lambda_2^{-\alpha_2(\Tt)}(\Tt)\EE\left[\frac{\hat \Lambda_1^{-2\hat\alpha_1(\Tt)}(\Tt)\hat \Lambda_2^{-2\hat\alpha_2(\Tt)}(\Tt)}{ \Lambda_1^{-2\alpha_1(\Tt)}(\Tt)\Lambda_2^{-2\alpha_2(\Tt)}(\Tt)}\big{|}M_0\right].
%\end{multline*}
%
%
%
%Next, on the event $\mathcal E$, for $i=1,2$, we have
%$$
%\frac{\widehat \Lambda_i^{-2\widehat\alpha_i(\Tt)}(\Tt)}{\Lambda_i^{-2\alpha_i(\Tt)}(\Tt)}= \frac{\widehat \Lambda_i^{-2\widehat\alpha_i(\Tt)}(\Tt)}{\Lambda_i^{-2\widehat\alpha_i(\Tt)}(\Tt)}\frac{\Lambda_i^{-2\widehat\alpha_i(\Tt)}(\Tt)}{\Lambda_i^{-2\alpha_i(\Tt)}(\Tt)}\leq \left(1+\log^{-a}(\mathfrak m)\right)^{-2\widehat \alpha_i(\Tt)}\Lambda_i(\Tt)^{2\log^{-a}(\mathfrak m)}.
%$$
%Note that, by definition, $2\alpha_i(\Tt)<1$, $i=1,2$. 	It follows that on the event $\mathcal F \cap \mathcal E$ we have  
%$$
%\frac{\widehat \Lambda_1^{-2\widehat\alpha_1(\Tt)}(\Tt)\widehat \Lambda_2^{-2\widehat\alpha_2(\Tt)}(\Tt)}{ \Lambda_1^{-2\alpha_1(\Tt)}(\Tt)\Lambda_2^{-2\alpha_2(\Tt)}(\Tt)}= 1+O_\PP(\log^{-a}(\mathfrak m)).
%$$
%Consequently, under $\mathcal F \cap \mathcal E$ we obtain 
%$$
%\EE\left[ \frac{\kappa^2}{c\pi} \frac{\sigma^2}{M_0 \widehat h_1 \widehat h_2}  \mathbf{1}_\mathcal{F} \mathbf{1}_{\mathcal E}\big{|} M_0 \right]\leq \frac{\kappa^2 \sigma^2}{c\pi\Lambda_1^{\alpha_1(\Tt)}(\Tt)\Lambda_2^{\alpha_2(\Tt)}(\Tt)} M_0^{ -\frac{\omega(\Tt)}{2\omega(\Tt)+1}+2\log^{-a}(\mathfrak m)}\left( 1+O(\log^{-a}(\mathfrak m))\right).
%$$
%By similar argument, we can also show that on the event $\mathcal F \cap \mathcal E$ we have 
%$$
%\EE\left[ L_1(\Tt)\widehat h_1^{2H_1(\Tt)}\mathbf{1}_\mathcal{F} \mathbf{1}_{\mathcal E}\big{|}M_0\right]\leq L_1(\Tt)\left(\frac{\Lambda_1(\Tt)^{2H_1(\Tt)+1}}{\Lambda_2(\Tt)}\right)^{\alpha_1(\Tt)}\!M_0^{-\frac{\omega(\Tt)}{2\omega(\Tt)+1}+2\log^{-a}(\mathfrak m)}\times (1+O(\log^{-a}(\mathfrak m))),
%$$
%and 
%$$
%\EE\left[ L_2(\Tt)\widehat h_2^{2H_2(\Tt)}\mathbf{1}_\mathcal{F} \mathbf{1}_{\mathcal E}\big{|}M_0\right]\leq L_2(\Tt)\left(\frac{\Lambda_2(\Tt)^{2H_2(\Tt)+1}}{\Lambda_1(\Tt)}\right)^{\alpha_2(\Tt)}M_0^{-\frac{\omega(\Tt)}{2\omega(\Tt)+1}+2\log^{-a}(\mathfrak m)}\times (1+O(\log^{-a}(\mathfrak m))).
%$$
%Since
%\begin{multline*}
%	\EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\Big{|}M_0\right]\leq \EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\mathbf{1}_{\mathcal F}\mathbf{1}_{\mathcal E}\Big{|}M_0\right]\\
%	+\EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\mathbf{1}_{\overline{\mathcal F}}\Big{|}M_0\right]+\EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\mathbf{1}_{\overline{\mathcal E}}\Big{|}M_0\right],
%\end{multline*}
%and given the facts above, it remains to investigate the last two terms in the last diplay. 
%Using (LP\ref{LP4}), (H\ref{ass_D}) and Cauchy-Schwarz inequality,  we obtain 
%$$
%\EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\mathbf{1}_{\overline{\mathcal F}}\Big{|}M_0\right]+\EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\mathbf{1}_{\overline{\mathcal E}}\Big{|}M_0\right]= o(\log^{-a}(\mathfrak m)).
%$$ 
%We finally deduce 
%$$
%\EE\left[ \{\widehat X^{new}(\Tt;\widehat{\mathbf{B}}^* )-X^{new}(\Tt)\}^2\Big{|}M_0\right]\leq \Gamma_2(\Tt) M_0^{-\frac{\omega(\Tt)}{2\omega(\Tt)+1}+2\log^{-a}(\mathfrak m)}\times (1+o(\log^{-a}(\mathfrak m))),
%$$
%where 
%$$
%\Gamma_2(\Tt)= \frac{\kappa^2\sigma^2}{c\pi\Lambda_1^{\alpha_1(\Tt)}(\Tt)\Lambda_2^{\alpha_2(\Tt)}(\Tt)}+L_1(\Tt)\left(\frac{\Lambda_1(\Tt)^{2H_1(\Tt)+1}}{\Lambda_2(\Tt)}\right)^{\alpha_1(\Tt)}+L_2(\Tt)\left(\frac{\Lambda_2(\Tt)^{2H_2(\Tt)+1}}{\Lambda_1(\Tt)}\right)^{\alpha_2(\Tt)}.
%$$
%\color{black}
%
%\end{proof}
%

%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%

\section{Technical lemmas}\label{tech_lem}

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%


\subsection{Proof of the local  Hölder continuity of the  realizations of $X$}

In Section \ref{sec6} of the main manuscript, we linked the  local regularity in quadratic mean to the (analytic) regularity of the  realizations of $X$. Let us provide a detailed justification for our statement. 


\begin{lemSM}\label{reg_RY_SM}
	Consider $\mathcal{H}^{H_1,H_2}$ in Definition \ref{def} is built with restricted $\boldsymbol L = (L_1,0,0,L_2)$, and let  $X\in \mathcal H^{H_1,H_2}$ 
	Assume that 
	\begin{equation}\label{Yor_us_SM}
		\max_{i=1,2}\sup_{0<\Delta \leq \Delta_0}  \frac{\EE\left[\left\{X\left(\Tt-\Delta e_i/2\right)-X\left(\Tt+\Delta e_i/2\right)\right\}^{2p}\right]}{\EE\left[\left\{X\left(\Tt-\Delta e_i/2\right)-X\left(\Tt+ \Delta e_i/2\right)\right\}^2\right]^p}<\infty, \qquad \forall  p\in \mathbb N.
	\end{equation}
	The, almost  any realization of $X$  is locally $\alpha-$Hölder continuous in the direction $e_i$, for any order $0\leq \alpha < H_i(\Tt)$, $i=1,2$.
\end{lemSM}

\begin{proof}[Proof of Lemma SM.\ref{reg_RY_SM}]
	Condition \eqref{Yor_us_SM} means that, for any $p\in \mathbb N$, there exists $C_p(\Tt)$, independent of $\Delta$, such that
	$$
	\EE\left[\left\{X\left(\Tt-\frac{\Delta}{2}e_i\right)-X\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}^{2p}\right]\leq C_p(\Tt)\EE\left[\left\{X\left(\Tt-\frac{\Delta}{2}e_i\right)-X\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}^2\right]^p.
	$$
	Since   $\boldsymbol L = (L_1,0,0,L_2),$  we obtain
	$$
	\EE\left[\left\{X\left(\Tt-\frac{\Delta}{2}e_i\right)-X\left(\Tt+\frac{\Delta}{2}e_i\right)\right\}^{2p}\right]\leq C_p(\Tt)L_i^p(\Tt) \Delta^{2pH_i(\Tt)}, \quad \forall \Delta\in [0,\Delta_0].  $$
	Using \citet[Theorem 2.1, page 26]{Yor}, we then get that 
	$$
	\EE\!\left[ \underset{0<\Delta\leq \Delta_0}{\sup}\!\left(\frac{|X\left(\Tt-\Delta e_i/2 \right)-X\left(\Tt+ \Delta e_i/2 \right)|}{\Delta^{\nu}}\right)^{2p}\right]< \infty,\quad \forall p\in \mathbb N,  \; \forall \nu \in \left[0, \frac{2pH_i(\Tt)-2}{2p}\right).
	$$
	Letting $p\rightarrow \infty$, we obtain the stated local Hölder property. \end{proof}
\color{black} 


%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%

\begin{lemSM}\label{lem}
Let $a_N,b_N, c_N$ be three positives sequences such that 
$$
c_N\geq 1 \quad \text{ and  } \quad \max\{a/b, a_N/b_N\}\leq \mathfrak C,
$$ 
for some constant $\mathfrak C >1$.
Let $a,b>0$ and $c\geq 1$. For $0 \leq u\leq 1$, let 
$$
\varphi_1(u)=\PP\left(|a_N-a|\geq u\right), \quad 
\varphi_2(u)=\PP\left(|b_N-b|\geq u\right)
\quad \text{ and } \quad  \varphi_3(u)=\PP\left(|c_N-c|\geq u\right).
 $$
Define
$$
r_1=\frac{a\mathfrak C}{2  \min\left\{1, 1/c\right\}} \quad ,\quad r_2= \frac{b}{6\mathfrak C} \min\left\{1,\frac{1}{c} \right\}  \quad \text{and} \quad r_3= \min\left\{\frac{1}{\sqrt{2\mathfrak C}}, \frac{1}{\left(a/b\right)^c|\log\left(a/b\right)|}\right\}.
$$
We then have 
$$\PP\left(\left|\left(\frac{a_N}{b_N}\right)^{c_N}-\left(\frac{a}{b}\right)^{c}\right|\geq u\right)\leq 2\varphi_1\left(r_1u\right)+2\varphi_2\left( r_2u\right)+2\varphi_3\left(r_3 u\right).
$$

\end{lemSM}

\begin{proof}[Proof of Lemma SM.\ref{lem}]
	By elementary algebra, and using the conditions $c_N,c\geq 1$, and $0 \leq u\leq 1$, 
\begin{multline}
    \PP\left(\left|\left(\frac{a_N}{b_N}\right)^{c_N}-\left(\frac{a}{b}\right)^{c}\right|\geq 2u\right)
    \leq  \PP\left(\left|\left(\frac{a_N}{b_N}\right)^{c_N}-\left(\frac{a}{b}\right)^{c_N}\right|\geq u\right)+\PP\left(\left|\left(\frac{a}{b}\right)^{c_N}-\left(\frac{a}{b}\right)^{c}\right|\geq u\right)\\
    = \PP\left(\left|\int_{\frac{a}{b}}^{\frac{a_N}{b_N}}c_Nx^{c_N-1}{\rm{d}}x\right|\geq u\right)+\PP\left(\left(\frac{a}{b}\right)^{c}\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\right)\\
    \leq \PP\left(c_N\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\mathfrak C\geq u\right)+\PP\left(\left(\frac{a}{b}\right)^{c}\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\right)\\
    \leq \PP\left((c_N-c)\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\geq u/(2 \mathfrak C)\right)+\PP\left(c\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\geq u/(2 \mathfrak C)\right)\\ \hspace{6cm} + \PP\left(\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\left(\frac{a}{b}\right)^{-c}\right)\\
    \leq\varphi_3(\sqrt{u/(2\mathfrak C)})+\PP\left(\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\geq \sqrt{u/(2 \mathfrak C)}\right)+\PP\left(c\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\geq u/(2\mathfrak C)\right)\\\hspace{6cm} + \PP\left(\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\left(\frac{a}{b}\right)^{-c}\right)\\
    \leq \varphi_3(\sqrt{u/(2 \mathfrak C)})+\PP\left(\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\geq \min\left\{1,\frac{1}{c}\right\}u/(2\mathfrak C)\right)+ \PP\left(\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\left(\frac{a}{b}\right)^{-c}\right).
\end{multline}
Moreover, using the inequality 
$$
|xy-1|\leq |x-1||y-1| + |x-1|+|y-1|,
$$
for $\varepsilon>0$, we have

\begin{multline}
\PP\left(\left|\frac{a}{a_N}\times \frac{b_N}{b}-1\right|\geq  \varepsilon \right)\\
\leq \PP\left(\left| \frac{a}{a_N}-1\right|\times\left| \frac{b_N}{b}-1\right|\geq\varepsilon/3 \right)+\PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right)+\PP\left(\left| \frac{b_N}{b}-1\right|\geq\varepsilon/3 \right)\\
 \leq \PP\left(\left| \frac{a}{a_N}-1\right|\geq\sqrt{\varepsilon/3} \right)+ \PP\left(\left| \frac{b_N}{b}-1\right|\geq\sqrt{\varepsilon/3} \right)+\PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right)+\varphi_2\left(b\varepsilon/3 \right)\\
 = \PP\left(\left| \frac{a}{a_N}-1\right|\geq\sqrt{\varepsilon/3} \right)+\PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right)+ \varphi_2\left(b\sqrt{\varepsilon/3} \right)+\varphi_2\left(b\varepsilon/3 \right).
\end{multline}
We next relate 
$$ 
\PP\left(\left| \frac{a}{a_N}-1\right|\geq\sqrt{\varepsilon/3} \right)+\PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right),
$$ 
to the function $\varphi_1$. We have 
\begin{multline}
 \PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right)= \PP\left(\frac{a}{a_N}-1\geq\varepsilon/3 \right)+\PP\left( \frac{a}{a_N}-1<-\varepsilon/3 \right)\\
 = \PP\left( a-a_N\geq a_N \varepsilon/3 \right)+ \PP\left(a-a_N<-a_N\varepsilon/3 \right)\\
 =  \PP\left( a-a_N\geq \frac{a\varepsilon}{3+\varepsilon} \right)+ \PP\left(a-a_N<-\frac{a\varepsilon}{3-\varepsilon}\right).
\end{multline}
Since $a>0$ and $-a\varepsilon/\{3-\varepsilon\} \leq -a\varepsilon/\{3+\varepsilon\} $ we obtain 
\begin{equation}
 \PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right)\leq  \PP\left( a-a_N\geq \frac{a\varepsilon}{3+\varepsilon} \right)+ \PP\left( a-a_N< -\frac{a\varepsilon}{3+\varepsilon} \right)= \varphi_1\left(\frac{a\varepsilon}{3+\varepsilon} \right).
\end{equation}
By similar arguments we obtain 
\begin{equation}
\PP\left(\left| \frac{a}{a_N}-1\right|\geq\sqrt{\varepsilon/3} \right)\leq \varphi_1\left(\frac{a\sqrt \varepsilon}{\sqrt 3+\sqrt\varepsilon} \right).
\end{equation}
We finally deduce that 
\begin{equation}
 \PP\left(\left| \frac{a}{a_N}-1\right|\geq\varepsilon/3 \right)\leq 2\varphi_1\left( \frac{a\varepsilon}{3+\varepsilon}\right)+2\varphi_2(\varepsilon/3).
\end{equation}
Which means that for $u\in (0,1)$ we have 
\begin{equation}
\PP\left(\left|\frac{a}{b}-\frac{a_N}{b_N}\right|\geq \min\left\{1,\frac{1}{c}\right\}u/(2\mathfrak C)\right)\leq 2\varphi_1(r_1 u)+2\varphi_2(r_2 u),
\end{equation}
where, 
$$
r_1=\frac{a\mathfrak C}{2  \min\left\{1,\frac{1}{c}\right\}} \quad \text{and} \quad r_2= \min\left\{1,\frac{1}{c} \right\}\frac{b}{6\mathfrak C}.
$$
It finally remains to control $$
\PP\left(\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\left(\frac{a}{b}\right)^{-c}\right).
$$ 
We have 
\begin{multline}
\PP\left(\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\left(\frac{a}{b}\right)^{-c}\right)\\
= \PP\left(\left(\frac{a}{b}\right)^{c_N-c}\geq 1+u\left(\frac{a}{b}\right)^{-c}\right)+\PP\left(\left(\frac{a}{b}\right)^{c_N-c}\leq 1-u\left(\frac{a}{b}\right)^{-c}\right).
\end{multline} 
Since for $x>0$ we have $\log(x)\leq x-1$, for $u$ small such that  $1 -\left(a/b\right)^{-c}u>0$, we obtain~:
\begin{equation}\label{eq_C11}
\PP\left((c_N-c)\log\frac{a}{b}\leq \log\left(1-u\left(\frac{a}{b}\right)^{-c}\right)\right)\leq \PP\left((c_N-c)\log\frac{a}{b}\leq -\left(\frac{a}{b}\right)^{-c}u\right),
\end{equation}
and since  for $x\in[0,1]$ we have $\log(1+x)\geq x/2$ we obtain~:
\begin{equation}\label{eq_C22}
\PP\left((c_N-c)\log\frac{a}{b}\geq \log\left(1+u\left(\frac{a}{b}\right)^{-c}\right)\right)\leq \PP\left((c_N-c)\log\frac{a}{b}\geq \left(\frac{a}{b}\right)^{-c}u/2\right).
\end{equation}
Combining \eqref{eq_C11} and \eqref{eq_C22}, whatever the sign of $\log(a/b)$ is, we obtain 
\begin{equation}
\PP\left(\left|\left(\frac{a}{b}\right)^{c_N-c}-1\right|\geq u\left(\frac{a}{b}\right)^{-c}\right)\leq \PP\left(\left|c_N-c\right|\geq\frac{u}{2(a/b)^{c}\left|\log(a/b)\right|} \right)= \varphi_3(r_3u),
\end{equation}
where $$
r_3=\min\left\{1/\sqrt{2} , \left(\left(\frac{a}{b}\right)^{c}\left|\log(\frac{a}{b})\right|\right)^{-1}\right\}
$$

\end{proof}


\medskip



\begin{lemSM}\label{concentration:variance}
Under the conditions of Proposition \ref{prop_def_A}, a positive constant $\mathfrak e$ exists such that, for sufficiently large $\mathfrak m$,
\begin{equation}
\PP\left(|\widehat v(\Tt) -v(\Tt)|\geq \eta \right)\leq 2\exp\left(-\mathfrak e N\eta^2 \right),
\end{equation}
where $\widehat v(\Tt) =\max\{\widetilde v(\Tt), \underline v\}$ with
$$
\widetilde v(\Tt) = \frac{1}{N}\sum_{j=1}^N\{\widetilde X ^{(j)}(\Tt)\}^2.
$$
\end{lemSM}

\begin{proof}[Proof of Lemma SM.\ref{concentration:variance}]
Recall the notation $\xi^{(j)}(\Tt)= \widetilde X^{(j)}- X^{(j)}$ for $1\leq j\leq N.$ We decompose as follow
\begin{equation}
    \widetilde v(\Tt) -v(\Tt)=\frac{1}{N}\sum_{j=1}^N\left(\{\widetilde X ^{(j)}(\Tt)\}^2-\EE[\{\widetilde X ^{(j)}(\Tt)\}^2]\right)+\EE[\widehat v(\Tt)]- \EE[\{X(\Tt)\}^2].
\end{equation}

\textbf{The bias term :}  We have 
\begin{equation}
    \EE\left[\widetilde v(\Tt)-\{X(\Tt)\}^2\right]
   % = \frac{1}{N}\sum _{j=1}^N\EE\left[\{\widetilde X(\Tt)\}^2-\{X(\Tt)\}^2\right]\\
        =\frac{1}{N}\sum _{j=1}^N\EE\left[\{\widetilde X(\Tt)-X(\Tt)\}\times \{\widetilde X(\Tt)+X(\Tt)\}\right],
\end{equation}
and by  Cauchy-Schwartz inequality,
\begin{equation}
     \EE\left[\widetilde v(\Tt)-\{X(\Tt)\}^2\right]\leq 
     R_2(\mathfrak m)^{1/2}\frac{1}{N}\sum _{j=1}^N \EE\left[\{\widetilde X^{(j)}(\Tt)+X^{(j)}(\Tt)\}^2\right]^{1/2}.
\end{equation}
In addition we have 
\begin{multline}
\EE\left[\{\widetilde X^{(j)}(\Tt)+X^{(j)}(\Tt)\}^2\right]= \EE\left[\{\xi^{(j)}(\Tt)+2X^{(j)}(\Tt)\}^2\right]
\\ \leq 2 R_2(\mathfrak m)+8\EE[\{X^{(j)}(\Tt)\}^{2}]\leq 2 R_2(\mathfrak m)+8\mathfrak a_1. 
\end{multline}
Therefore,
\begin{equation}
\EE\left[\widehat v(\Tt)-\{X(\Tt)\}^2\right]\leq R_2(\mathfrak m)^{1/2}\left( 2 R_2(\mathfrak m)+8\mathfrak a_1\right)^{1/2}:= \eta_*.
\end{equation}

\textbf{The variance term :} 
\begin{multline}
    \EE\left[\left|\{\widetilde X(\Tt)\}^2-\EE[\{\widetilde X(\Tt)\}^2]\right|^p\right]\leq 2^p\EE\left[\{\widetilde X (\Tt)\} ^{2p}\right]\\
    \leq 2^{3p-1}\left(\EE[\{\xi^{(j)}(\Tt)\}^{2p}]+\EE[\{X^{(j)}(\Tt)\}^{2p}]\right)\\
    \leq 2^{3p-1}\left( \frac{p!}{2} \mathfrak c\mathfrak D ^{p-2}\rho(\mathfrak m)^{2p}+ \frac{p!}{2}\mathfrak a_1\mathfrak A_1^{p-2} \right).
\end{multline}
Since $\rho(\mathfrak m)\leq 1$, two positive constants $\widetilde {\mathfrak {a}}$ and $\widetilde {\mathfrak A}$ exist such that 
\begin{equation}
  \EE\left[\left|\{\widetilde X(\Tt)\}^2-\EE[\{\widetilde X(\Tt)\}^2]\right|^p\right]\leq \frac{p!}{2}\widetilde {\mathfrak{a}}\widetilde{\mathfrak{A}}^{p-2}.
\end{equation}

\textbf{Exponential bound:}
Let $0<2\eta\leq\eta_* $, We have
\begin{multline}
\PP\left(\widetilde v(\Tt) -v(\Tt)\geq \eta \right)\leq \PP\left(\frac{1}{N}\sum_{j=1}^N\left(\{\widetilde X ^{(j)}(\Tt)\}^2-\EE[\{\widetilde X ^{(j)}(\Tt)\}^2]\right)+\EE[\widehat v(\Tt)]- \EE[\{X(\Tt)\}^2]\geq \eta \right)\\
\leq \PP\left(\frac{1}{N}\sum_{j=1}^N\left(\{\widetilde X ^{(j)}(\Tt)\}^2-\EE[\{\widetilde X ^{(j)}(\Tt)\}^2]\right)+\eta_*\geq \eta \right)\\
\leq \PP\left(\frac{1}{N}\sum_{j=1}^N\left(\{\widetilde X ^{(j)}(\Tt)\}^2-\EE[\{\widetilde X ^{(j)}(\Tt)\}^2]\right)\geq \eta/2 \right).
\end{multline} 
Bernstein's inequality implies 
\begin{equation}
\PP\left(\widetilde v(\Tt) -v(\Tt)\geq \eta \right)\leq \exp\left(-\frac{N\eta^2}{8\widetilde{\mathfrak a}+4\widetilde{\mathfrak A}\eta}\right).
\end{equation}
For  $\eta\in (0,1)$ and sufficiently large $\mathfrak m$, we have 
\begin{equation}
\PP\left(\widetilde v(\Tt) -v(\Tt)\geq \eta \right)\leq \exp\left(-\mathfrak e N\eta^2 \right),
\end{equation}
for some positive constant $\mathfrak e.$ The same bound is valid for $\PP\left(\widetilde v(\Tt) -v(\Tt)\leq -\eta \right).$
Finally, it suffices to notice that by definition
$$
\PP\left(|\widehat v(\Tt) -v(\Tt)|\geq \eta \right) \leq \PP\left(|\widetilde v(\Tt) -v(\Tt)|\geq \eta \right).
$$
\end{proof}


\medskip

\begin{lemSM}\label{lemme_tec_1}
   Let  $X\in \mathcal H^{H_1,H_2}$ and $\boldsymbol L =(L_1,0,0,L_2)$. For any $\rho\leq \Delta_0$, 
    \begin{equation*}
             \EE\left[\left\{X(\Tt)-X(\Tt+\rho e_i)\right\}^2\right] \leq L_i(\Tt) \rho^{2H_i(\Tt)}\times\{1 + O(\rho\log(\rho))\},\quad \forall\Tt\in\cT,\quad i=1,2.
    \end{equation*}
\end{lemSM}

\begin{proof}[Proof of Lemma SM.\ref{lemme_tec_1}]
    We fix $i=1,2$ and  denote $\tilde \Tt_i =  \Tt+\rho/2 e_i$. Since $X\in \mathcal H^{H_1,H_2}$ and $\boldsymbol L =(L_1,0,0,L_2)$, we have 
    \begin{equation}
     \EE\left[\left\{X(\Tt)-X(\Tt+\rho e_i)\right\}^2\right]=  \EE\left[\left\{X\left(\tilde \Tt_i -\frac{\rho}{2}e_i\right)-X\left(\tilde\Tt_i+\frac{\rho}{2} e_i\right)\right\}^2\right]
     \leq L_i(\tilde \Tt_i)\rho^{2H_i(\tilde\Tt_i)}.
    \end{equation}
    The function $H_i$ is continuously differentiable, and thus 
    \begin{equation}
    \rho^{2H_i(\tilde\Tt_i)}= \rho^{2H_i(\Tt)}\rho^{2H_i(\tilde\Tt_i)-2H_i(\Tt)}
    = \rho^{2H_i(\Tt)}\rho^{2R(\Tt)},
     \end{equation}   
    with
    $$
    R(\Tt) = \nabla H_i(\Tt_*) (\tilde \Tt_i-\Tt),
    $$
    where $\Tt_*$ is a point on the segment between $\tilde \Tt_i$ and $\Tt$, $\nabla H_i$ is the row matrix of partial derivatives of $H_i$, and $\tilde \Tt_i-\Tt$ is considered as a column matrix. 
    Since by the assumptions, a constant $C>0$ exists such that  $|R(\Tt)|\leq C \rho$  and 
    $$
    \left|\rho^{2R(\Tt)} - 1\right| = \left|\exp\{ 2R(\Tt)\log(\rho) \}- 1\right| \leq C 2R(\Tt)\log(\rho),
    $$
    we deduce 
    $$
    \rho^{2H_i(\tilde\Tt_i)}
      = \rho^{2H_i(\Tt)}\times \{1+O\left(\rho\log(\rho)\right)\}.
$$
    On the hand, the function $L_i$ is Lipschitz continuous, and thus 
    \begin{align}
    \EE\left[\left\{X(\Tt)-X(\Tt+\rho e_i)\right\}^2\right] &\leq L_i(\tilde \Tt_i) \rho^{2H_i(\Tt)}\times \{1+O\left(\rho\log(\rho)\right)\}\\
    &\leq \left (L_i(\Tt) \rho^{2H_i(\Tt)}+ |L_i(\tilde \Tt_i)-L_i(\Tt)| \rho^{2H_i(\Tt)}\right)\times \{1+O\left(\rho\log(\rho)\right)\}\\
    &=\left (L_i(\Tt) \rho^{2H_i(\Tt)}+O(\rho^{2H_i(\Tt)+1})\right)\times \{1+O\left(\rho\log(\rho)\right)\}\\
    &= L_i(\Tt) \rho^{2H_i(\Tt)} + O(\rho^{2H_i(\Tt)+1}\log(\rho))
    \end{align}
    We finally obtain 
    \begin{equation}
     \EE\left[\left\{X(\Tt)-X(\Tt+\rho e_i)\right\}^2\right] \leq L_i(\Tt) \rho^{2H_i(\Tt)}\times\{1 + O(\rho\log(\rho))\}.
    \end{equation}
\end{proof}



%%%%%%%%%%%%%%%%%%%%



\begin{lemSM}\label{Ber_par}
 We have that 
 $$
 p(\Tt)\geq \pi c h_1h_2.
 $$
 \end{lemSM}
\begin{proof}[Proof of Lemma SM.\ref{Ber_par}]
We have 
\begin{equation}
p(\Tt)=\PP\left(\mathbf{B}(\Tt^{[0]}_m-\Tt)\in B(0,1)\big{|}M_0\right)
=\int_{\mathbf{B}(\Uu-\Tt)\in B(0,1)}f_{\TT}(\Uu)\D \Uu.
\end{equation}
By substitution $(\Ss=\mathbf{B}(\Uu-\Tt))$,  using (LP\ref{LP2}) and the Lebesgue measure of the unit ball, we obtain
$$
p(\Tt)= \int_{\Ss \in B(0,1)}f_{\TT}(\mathbf{B}^{-1}\Ss +\Tt)|\mathbf{B}^{-1}| \D \Ss \geq c \pi h_1h_2.
$$
\end{proof}
%\newpage

%\bibliographystyle{chicago}
\bibliographystyle{apalike}
%\bibliographystyle{plainnat}

\bibliography{biblio_final.bib}


\end{document}