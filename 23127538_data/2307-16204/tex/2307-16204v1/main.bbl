\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{bucci2020effectiveness}
Silvia Bucci, Mohammad~Reza Loghmani, and Tatiana Tommasi.
\newblock On the effectiveness of image rotation for open set domain
  adaptation.
\newblock In {\em ECCV}, 2020.

\bibitem{carlucci2017autodial}
Fabio~Maria Carlucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and
  Samuel~Rota Bulo.
\newblock Autodial: Automatic domain alignment layers.
\newblock In {\em ICCV}, 2017.

\bibitem{chen2020generative}
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
  Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em ICML}, 2020.

\bibitem{chen2019uniter}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El~Kholy, Faisal Ahmed, Zhe Gan, Yu
  Cheng, and Jingjing Liu.
\newblock Uniter: Learning universal image-text representations.
\newblock In {\em ECCV}, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL}, 2018.

\bibitem{dosovitskiyimage}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock {\em JMLR}, 2016.

\bibitem{ghifary2016deep}
Muhammad Ghifary, W~Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li.
\newblock Deep reconstruction-classification networks for unsupervised domain
  adaptation.
\newblock In {\em ECCV}, 2016.

\bibitem{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em CVPR}, 2022.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{kundu2020universal}
Jogendra~Nath Kundu, Naveen Venkat, R~Venkatesh Babu, et~al.
\newblock Universal source-free domain adaptation.
\newblock In {\em CVPR}, 2020.

\bibitem{liang2020we}
Jian Liang, Dapeng Hu, and Jiashi Feng.
\newblock Do we really need to access the source data? source hypothesis
  transfer for unsupervised domain adaptation.
\newblock In {\em ICML}, 2020.

\bibitem{long2018conditional}
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael~I Jordan.
\newblock Conditional adversarial domain adaptation.
\newblock In {\em NeurIPS}, 2018.

\bibitem{lu2019vilbert}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock In {\em NeurIPS}, 2019.

\bibitem{mingdelving}
Yifei Ming, Ziyang Cai, Jiuxiang Gu, Yiyou Sun, Wei Li, and Yixuan Li.
\newblock Delving into out-of-distribution detection with vision-language
  representations.
\newblock In {\em NeurIPS}, 2022.

\bibitem{pan2022integration}
Xuran Pan, Chunjiang Ge, Rui Lu, Shiji Song, Guanfu Chen, Zeyi Huang, and Gao
  Huang.
\newblock On the integration of self-attention and convolution.
\newblock In {\em CVPR}, 2022.

\bibitem{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em NeurIPS}, 2019.

\bibitem{peng2019moment}
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang.
\newblock Moment matching for multi-source domain adaptation.
\newblock In {\em CVPR}, 2019.

\bibitem{peng2017visda}
Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate
  Saenko.
\newblock Visda: The visual domain adaptation challenge.
\newblock {\em arXiv preprint arXiv:1710.06924}, 2017.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em ICML}, 2021.

\bibitem{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{redmon2016you}
Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi.
\newblock You only look once: Unified, real-time object detection.
\newblock In {\em CVPR}, 2016.

\bibitem{saenko2010adapting}
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell.
\newblock Adapting visual category models to new domains.
\newblock In {\em ECCV}, 2010.

\bibitem{saito2019semi}
Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Trevor Darrell, and Kate Saenko.
\newblock Semi-supervised domain adaptation via minimax entropy.
\newblock In {\em ICCV}, 2019.

\bibitem{saito2020dance}
Kuniaki Saito, Donghyun Kim, Stan Sclaroff, and Kate Saenko.
\newblock Universal domain adaptation through self-supervision.
\newblock In {\em NeurIPS}, 2020.

\bibitem{saito2021ovanet}
Kuniaki Saito and Kate Saenko.
\newblock Ovanet: One-vs-all network for universal domain adaptation.
\newblock In {\em ICCV}, 2021.

\bibitem{saito2018maximum}
Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada.
\newblock Maximum classifier discrepancy for unsupervised domain adaptation.
\newblock In {\em CVPR}, 2018.

\bibitem{saito2018open}
Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada.
\newblock Open set domain adaptation by backpropagation.
\newblock In {\em ECCV}, 2018.

\bibitem{su2019vl}
Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
\newblock Vl-bert: Pre-training of generic visual-linguistic representations.
\newblock {\em arXiv preprint arXiv:1908.08530}, 2019.

\bibitem{taigman2016unsupervised}
Yaniv Taigman, Adam Polyak, and Lior Wolf.
\newblock Unsupervised cross-domain image generation.
\newblock In {\em ICLR}, 2017.

\bibitem{tzeng2017adversarial}
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In {\em CVPR}, 2017.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em NeurIPS}, 2017.

\bibitem{venkateswara2017deep}
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman
  Panchanathan.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In {\em CVPR}, 2017.

\bibitem{yang2021generalized}
Shiqi Yang, Yaxing Wang, Joost Van De~Weijer, Luis Herranz, and Shangling Jui.
\newblock Generalized source-free domain adaptation.
\newblock In {\em CVPR}, 2021.

\bibitem{yang2022one}
Shiqi Yang, Yaxing Wang, Kai Wang, Shangling Jui, and Joost van~de Weijer.
\newblock One ring to bring them all: Towards open-set recognition under domain
  shift.
\newblock {\em arXiv preprint arXiv:2206.03600}, 2022.

\bibitem{you2019universal}
Kaichao You, Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael~I Jordan.
\newblock Universal domain adaptation.
\newblock In {\em CVPR}, 2019.

\bibitem{zhang2021amortized}
Xin Zhang, Yusuke Iwasawa, Yutaka Matsuo, and Shixiang~Shane Gu.
\newblock Amortized prompt: Lightweight fine-tuning for clip in domain
  generalization.
\newblock {\em arXiv preprint arXiv:2111.12853}, 2021.

\end{thebibliography}
