\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{adebayo2018}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., Kim, B.: Sanity
  checks for saliency maps. Advances in neural information processing systems
  \textbf{31} (2018)

\bibitem{knockoffs}
Barber, R.F., Cand{\`e}s, E.J.: Controlling the false discovery rate via
  knockoffs  (2015)

\bibitem{bjerge2021automated}
Bjerge, K., Nielsen, J.B., Sepstrup, M.V., Helsing-Nielsen, F., H{\o}ye, T.T.:
  An automated light trap to monitor moths (lepidoptera) using computer
  vision-based tracking and deep learning. Sensors  \textbf{21}(2), ~343 (2021)

\bibitem{Brust2017AVM}
Brust, C.A., Burghardt, T., Groenenberg, M., K{\"a}ding, C., K{\"u}hl, H.,
  Manguette, M., Denzler, J.: Towards automated visual monitoring of individual
  gorillas in the wild. In: ICCV Workshop on Visual Wildlife Monitoring
  (ICCV-WS). pp. 2820--2830 (2017). \doi{10.1109/ICCVW.2017.333}

\bibitem{chang2018explaining}
Chang, C.H., Creager, E., Goldenberg, A., Duvenaud, D.: Explaining image
  classifiers by counterfactual generation. In: International Conference on
  Learning Representations (2018)

\bibitem{Cui_2018_CVPR_large}
Cui, Y., Song, Y., Sun, C., Howard, A., Belongie, S.: Large scale fine-grained
  categorization and domain-specific transfer learning. In: Proceedings of CVPR
  (6 2018). \doi{10.1109/cvpr.2018.00432}

\bibitem{dabkowski2017real}
Dabkowski, P., Gal, Y.: Real time image saliency for black box classifiers.
  Advances in neural information processing systems  \textbf{30} (2017)

\bibitem{fong2017interpretable}
Fong, R.C., Vedaldi, A.: Interpretable explanations of black boxes by
  meaningful perturbation. In: Proceedings of the IEEE international conference
  on computer vision. pp. 3429--3437 (2017)

\bibitem{gal2017concrete}
Gal, Y., Hron, J., Kendall, A.: Concrete dropout. Advances in neural
  information processing systems  \textbf{30} (2017)

\bibitem{gan}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., Bengio, Y.: Generative adversarial networks.
  Communications of the ACM  \textbf{63}(11),  139--144 (2020)

\bibitem{he2022transfg}
He, J., Chen, J.N., Liu, S., Kortylewski, A., Yang, C., Bai, Y., Wang, C.:
  Transfg: A transformer architecture for fine-grained recognition. In:
  Proceedings of the AAAI Conference on Artificial Intelligence. vol.~36, pp.
  852--860 (2022)

\bibitem{resnet}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition. pp. 770--778 (2016)

\bibitem{he2019and}
He, X., Peng, Y., Zhao, J.: Which and how many regions to gaze: Focus
  discriminative regions for fine-grained visual categorization. IJCV pp. 1--21
  (2019)

\bibitem{hu2019see}
Hu, T., Qi, H., Huang, Q., Lu, Y.: See better before looking closer: Weakly
  supervised data augmentation network for fine-grained visual classification.
  arXiv preprint arXiv:1901.09891  (2019)

\bibitem{hughes2017automated}
Hughes, B., Burghardt, T.: Automated visual fin identification of individual
  great white sharks. International Journal of Computer Vision
  \textbf{122}(3),  542--557 (2017)

\bibitem{jang2016categorical}
Jang, E., Gu, S., Poole, B.: Categorical reparameterization with
  gumbel-softmax. In: 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings.
  OpenReview.net (2017), \url{https://openreview.net/forum?id=rkE3y85ee}

\bibitem{Kaeding18_ALR}
K{\"a}ding, C., Rodner, E., Freytag, A., Mothes, O., Barz, B., Denzler, J.:
  Active learning for regression tasks with expected model output changes. In:
  British Machine Vision Conference (BMVC) (2018)

\bibitem{sam}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
  T., Whitehead, S., Berg, A.C., Lo, W.Y., Doll{\'a}r, P., Girshick, R.:
  Segment anything. arXiv:2304.02643  (2023)

\bibitem{Korsch22:AVM_NID}
Korsch, D., Bodesheim, P., Brehm, G., Denzler, J.: Automated visual monitoring
  of nocturnal insects with light-based camera traps. In: CVPR Workshop on
  Fine-grained Visual Classification (CVPR-WS) (2022)

\bibitem{Korsch19_CSPARTS}
Korsch, D., Bodesheim, P., Denzler, J.: Classification-specific parts for
  improving fine-grained visual categorization. In: Proceedings of the German
  Conference on Pattern Recognition. pp. 62--75 (2019)

\bibitem{Korsch21:ETE}
Korsch, D., Bodesheim, P., Denzler, J.: End-to-end learning of fisher vector
  encodings for part features in fine-grained recognition. In: German
  Conference on Pattern Recognition (DAGM-GCPR). pp. 142--158 (2021).
  \doi{10.1007/978-3-030-92659-5\_9}

\bibitem{krause2016unreasonable}
Krause, J., Sapp, B., Howard, A., Zhou, H., Toshev, A., Duerig, T., Philbin,
  J., Fei-Fei, L.: The unreasonable effectiveness of noisy data for
  fine-grained recognition. In: ECCV. pp. 301--320. Springer (2016)

\bibitem{StanfordCars}
Krause, J., Stark, M., Deng, J., Fei-Fei, L.: 3d object representations for
  fine-grained categorization. In: 4th International IEEE Workshop on 3D
  Representation and Recognition (3dRR-13) (2013). \doi{10.1109/iccvw.2013.77}

\bibitem{Koerschens19:ELPephants}
Körschens, M., Denzler, J.: Elpephants: A fine-grained dataset for elephant
  re-identification. In: ICCV Workshop on Computer Vision for Wildlife
  Conservation (ICCV-WS) (2019)

\bibitem{mnist}
LeCun, Y., Cortes, C., Burges, C., et~al.: Mnist handwritten digit database
  (2010)

\bibitem{lin2015bilinear}
Lin, T.Y., RoyChowdhury, A., Maji, S.: Bilinear cnn models for fine-grained
  visual recognition. In: Proceedings of ICCV. pp. 1449--1457 (2015).
  \doi{10.1109/iccv.2015.170}

\bibitem{adamw}
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. In:
  International Conference on Learning Representations (2018)

\bibitem{maddison2017concrete}
Maddison, C., Mnih, A., Teh, Y.: The concrete distribution: A continuous
  relaxation of discrete random variables. In: Proceedings of the international
  conference on learning Representations. International Conference on Learning
  Representations (2017)

\bibitem{pytorch}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in pytorch
  (2017)

\bibitem{Popescu21Knockoffs}
Popescu, O.I., Shadaydeh, M., Denzler, J.: Counterfactual generation with
  knockoffs. arXiv preprint arXiv:2102.00951  (2021)

\bibitem{yolov3}
Redmon, J., Farhadi, A.: Yolov3: An incremental improvement. arXiv preprint
  arXiv:1804.02767  (2018)

\bibitem{reimers2021conditional}
Reimers, C., Penzel, N., Bodesheim, P., Runge, J., Denzler, J.: Conditional
  dependence tests reveal the usage of abcd rule features and bias variables in
  automatic skin lesion classification. In: CVPR ISIC Skin Image Analysis
  Workshop (CVPR-WS). pp. 1810--1819 (2021)

\bibitem{Rodner15:FRD}
Rodner, E., Simon, M., Brehm, G., Pietsch, S., Wägele, J.W., Denzler, J.:
  Fine-grained recognition datasets for biodiversity analysis. In: CVPR
  Workshop on Fine-grained Visual Classification (CVPR-WS) (2015)

\bibitem{ImageNet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.: Imagenet large scale visual
  recognition challenge. International journal of computer vision
  \textbf{115}(3),  211--252 (2015)

\bibitem{sakib2021visual}
Sakib, F., Burghardt, T.: Visual recognition of great ape behaviours in the
  wild. In: International Conference on Pattern Recognition (ICPR) Workshop on
  Visual Observation and Analysis of Vertebrate And Insect Behavior (2021)

\bibitem{shrikumar2017}
Shrikumar, A., Greenside, P., Kundaje, A.: Learning important features through
  propagating activation differences. In: International conference on machine
  learning. pp. 3145--3153. PMLR (2017)

\bibitem{Simon19:Implicit}
Simon, M., Rodner, E., Darell, T., Denzler, J.: The whole is more than its
  parts? from explicit to implicit pose normalization. IEEE Transactions on
  Pattern Analysis and Machine Intelligence pp. 1--13 (2018).
  \doi{10.1109/TPAMI.2018.2885764}

\bibitem{simonyan2014deep}
Simonyan, K., Vedaldi, A., Zisserman, A.: Deep inside convolutional networks:
  visualising image classification models and saliency maps. In: Proceedings of
  the International Conference on Learning Representations (ICLR). ICLR (2014)

\bibitem{guided_backprop}
Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.: Striving for
  simplicity: The all convolutional net. In: ICLR (workshop track) (2015)

\bibitem{integrated_grads}
Sundararajan, M., Taly, A., Yan, Q.: Axiomatic attribution for deep networks.
  In: International conference on machine learning. pp. 3319--3328. PMLR (2017)

\bibitem{inceptionv3}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the
  inception architecture for computer vision. In: Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (June 2016)

\bibitem{birdyolo}
Tran, B.: Bird detection by yolo-v3.
  \url{https://github.com/xmba15/yolov3_pytorch} (2023), [Online; accessed
  30-May-2023]

\bibitem{iNaturalist}
Van~Horn, G., Mac~Aodha, O., Song, Y., Cui, Y., Sun, C., Shepard, A., Adam, H.,
  Perona, P., Belongie, S.: The inaturalist species classification and
  detection dataset. In: Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition. pp. 8769--8778 (2018)

\bibitem{WahCUB_200_2011}
Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S.: The caltech-ucsd
  birds-200-2011 dataset. Tech. Rep. CNS-TR-2011-001, California Institute of
  Technology (2011)

\bibitem{yang2019great}
Yang, X., Mirmehdi, M., Burghardt, T.: Great ape detection in challenging
  jungle camera trap footage via attention-based spatial and temporal feature
  blending. In: Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops. pp.~0--0 (2019)

\bibitem{yu2022metaformer}
Yu, W., Luo, M., Zhou, P., Si, C., Zhou, Y., Wang, X., Feng, J., Yan, S.:
  Metaformer is actually what you need for vision. In: Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition. pp.
  10819--10829 (2022)

\bibitem{zhang2019learning}
Zhang, L., Huang, S., Liu, W., Tao, D.: Learning a mixture of
  granularity-specific experts for fine-grained categorization. In: Proceedings
  of ICCV. pp. 8331--8340 (2019)

\end{thebibliography}
