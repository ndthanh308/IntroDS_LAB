\subsection{Overview of the Method}
% Figure environment removed

In this section, we describe the proposed method to estimate image quality for different image regions in a scanned document page which can be used to determine the optimal scanning resolution for each image region.
Our system consists of two phases: the training phase and the inference phase. During the training phase, we utilize the ground truth ratings collected from the psychophysical experiment and several full-reference image features to train a classifier that predicts raster image quality. We formulate the research question into a binary classification problem by categorizing quality scores A (Visually Pleasant) and B (Visually Okay) into one class as ``Visually Acceptable", and categorizing C (Visually Okay with Some Artifacts) and D (Visually Unacceptable) into a second class as ``Visually Unacceptable". The multi-choice setting in ratings enables a more flexible threshold for different applications with different requirements. For example, in business applications, if higher quality is required, then we can categorize only quality scores A as "Visually Acceptable" and the rest as "Visually Unacceptable". In this paper me mainly focus on the standard setting, which is A,B as "Visually Acceptable" and C,D as "Visually Unacceptable". A Support Vector Machine \cite{SVM} is used to fuse different input image features and take joint consideration for training. At the inference stage, given an image pair including the original document scanned at the base resolution dpi, \textit{e.g.}, 300 dpi, and the lower resolution image, we first extract the set of image features. The feature vectors are then merged and are fed to the trained support vector machine model to classify if the given raster image quality is acceptable or not to derive the minimum acceptable resolution setting. An overview of the proposed method is illustrated in Figure \ref{fig:overview_diagram}.

\subsection{Feature Extraction}
For no-reference metrics, we include mean and stddev Edge Density (ED), which is the Canny edge map \cite{canny1986computational} intensity for the low resolution images. For full-reference metrics, the low resolution images are resized back to original scale of base resolution. The features we used in our method include Differential Spatial Activity (DSA), the root mean square difference between Sobel edge maps of the two images \cite{DSA}; mean and stddev Mean Square Error (MSE); mean and stddev Power Spectrum Difference (PSD), difference of 2D discrete-time Fourier transform images between the two images, and the mean and stddev of Tile-SSIM \cite{tile_ssim}. In order to calculate Tile-SSIM, we follow the method in \cite{tile_ssim}. 
For the mean and standard deviation (stddev) for each feature, the different feature maps are partitioned into tiles, and then calculate the mean and stddev among different tiles. The corresponding tile size for 300dpi, 200dpi, 150dpi, 100dpi are 12, 8, 6, 4, respectively.%\ref{tab:scan_tile_table}. 
% Given an image, based on the corresponding tile size in Table \ref{tab:scan_tile_table}, different resolution images are then transformed to the same number of tiles. We calculate the standard deviation of each tile and combine them to form the standard deviation map. The standard deviation maps are then partitioned into $7\times7$ blocks. We then calculate the tile-SSIM by simply computing the mean and standard deviation SSIM values from the standard deviation map blocks. Note that we only focus on the foreground pixels of the standard deviation map as described in~\cite{tile_ssim}. We use Otsu's method \cite{otsu} to determine the foreground pixels.
%Previous work has shown that Tile-SSIM \cite{tile_ssim} can serve as an effective image quality metric when assessing image quality for scan documents among different resolutions . In order to assess image quality of images with different resolutions, they need to be pre-processed to the same resolution for a fair comparison. When calculating Tile-SSIM features, we follow the practice of the original paper \cite{tile_ssim}, where the size of tile is resolution dependent.   The relationship between the tile size and image resolution can be found in Table \ref{tab:scan_tile_table}.  After the partitioning, the number of tiles for the base resolution image is the same as the number of tiles for the low resolution image.


% \subsubsection{Differential Spatial Activity}
% Intuitively, the difference between high resolution scanned document and low resolution scanned document is mainly in the high frequency components. The high frequency components of low resolution scanned document will have distortion due to lowering the resolution. Differential spatial activity (DSA) is defined as the root mean square difference between Sobel edge maps of the two images \cite{DSA}, which is used to study the difference in the intensity of the edges of the two images, because the edge is a way of presenting high frequencies. 
% %The overall process for calculating DSA is described as below: input images are first converted to grayscale images before calculating the DSA. Since this is a full-reference metric, we need to resize the lower resolution image back to the resolution of the base resolution image. Sobel operators are used to do convolution with the image in order to obtain the edge map. 

% % The two edge maps, $E_{baseres}$ for the base resolution image and $E_{lores}$ for the low resolution image, are calculated as follows:
% % \begin{equation}
% %     E_{baseres}=(\sqrt{(S * I_{baseres})^2 + (S^{T} * I_{baseres})^2}
% % \end{equation}
% % \begin{equation}
% %     E_{lores}=(\sqrt{(S * I_{lores})^2 + (S^{T} * I_{lores})^2}
% % \end{equation}
% % Here $I_{baseres}$ and $I_{lores}$ correspond to the input grayscale image in the base resolution and the lower resolution. $S$ is the horizontal Sobel operator, while $S^{T}$ is the transpose of $S$.

% % After obtaining the two edge maps $E_{baseres}$ and $E_{lores}$, we calculate the DSA using the equation below:
% % \begin{equation}
% %     DSA = \sqrt{\frac{1}{HW} * (E_{baseres} - E_{lores})^{2}}
% % \end{equation}
% % Here H and W are the height and width, respectively, of the base resolution image.

% \subsubsection{Edge Density (ED)}
% As the scanning resolution gradually decreases, we observed loss of details due to blurriness. Therefore, we include edge density in our features to address this issue. Since the edge density is also a full-reference metric, we first convert the input image pair into grayscale images. Then Canny edge detector \cite{canny1986computational} is applied to calculate the edge density. In order to capture the loss of fine-grained details during the resolution reduction, we partition the edge map into small tiles. When comparing edge density among different resolutions, we use different tile size according to the resolution setting for a fair comparison. The tile sizes are shown in Table \ref{tab:scan_tile_table}.

% \begin{table}[t]
% \caption{Scan resolutions and corresponding tile size.}
%     \centering
%     \begin{tabular}{|c|c|} 
%         \hline 
%         Resolution (dpi)& Tile size (pixels length)\\ \hline
%         300&12\\ \hline
%         200&8\\ \hline
%         150&6\\ \hline
%         100&4\\ \hline
%     \end{tabular}
% \label{tab:scan_tile_table}
% \end{table}


% \subsubsection{Mean Square Error (MSE)}
% As the resolution of a raster image decreases, the visual difference between the base resolution image and the low resolution image becomes more noticeable. Therefore we include the mean square error (MSE) between the base-resolution image and the low-resolution image in our feature set to take into consideration the image difference. 
% %The mean and standard deviation of MSE is computed by partitioning the two images, the base-resolution image and the low-resolution image, into non-overlapping small blocks, then we calculate the mean and standard deviation among the blocks. Note that the images are first converted into grayscale.


% \subsubsection{Power Spectrum Difference (PSD)}
% The power spectrum difference becomes gradually obvious as the resolution of the raster image decreases. The loss of high frequency content can be easily discovered compared to that of the base resolution image. Therefore we included power spectrum difference in our feature set to emphasize the importance of high frequency details. 
% %The overall process of calculating the PSD is described as following. We first convert the input image pair to grayscale, then we use the 2D discrete-time Fourier transform to obtain the power spectrum of the base resolution image and the low resolution image. PSD is the difference of these two power spectrum images. We further partition the PSD image into non-overlapping small blocks to calculate the mean and standard deviation among the blocks.


% \subsubsection{Tile-SSIM}
% Previous work has shown that Tile-SSIM \cite{tile_ssim} can serve as an effective image quality metric when assessing image quality for scan documents among different resolutions . In order to assess image quality of images with different resolutions, they need to be pre-processed to the same resolution for a fair comparison. When calculating Tile-SSIM features, we follow the practice of the original paper \cite{tile_ssim}, where the size of tile is resolution dependent.   The relationship between the tile size and image resolution can be found in Table \ref{tab:scan_tile_table}.  After the partitioning, the number of tiles for the base resolution image is the same as the number of tiles for the low resolution image.

% The detailed process of obtaining Tile-SSIM is described below. Following \cite{tile_ssim}, given an image, based on the corresponding tile size in Table \ref{tab:scan_tile_table}, different resolution images are then transformed to the same number of tiles. We can calculate the standard deviation of each tile and combine them to form the standard deviation map. The standard deviation maps are then partitioned into $7\times7$ blocks. We then calculate the tile-SSIM by simply computing the mean and standard deviation SSIM values from the standard deviation map blocks. Note that we only focus on the foreground pixels of the standard deviation map as described in~\cite{tile_ssim}. We use Otsu's method \cite{otsu} to determine the foreground pixels.



\subsection{Feature Selection}
Feature selection is the process of selecting a subset of relevant features from the original feature set. A good feature selection not only can compress the dimensionality of the feature space, but also improve the learning efficiency at the training stage and the prediction accuracy at the inference stage by preventing the trained model from overfitting. 
% After feature selection, the model size is typically smaller and more efficient. 
% Feature selection is commonly used in pattern recognition \cite{fs_for_pr}, data mining \cite{fs_for_dm}, etc., and can be designed based on statistics and information theory \cite{feature_selection_survey}. 

% Feature selection not only helps to improve the classification performance of the model, but also prevents it from overfitting. It also makes the model size smaller and more efficient. Finally it provides insight for the dataset that implies the importance of different feature. 
Our feature selection method follows the standard process of sequential floating forward selection (SFFS) \cite{SFFS}, which reduces an initial $t$-dimensional feature space, where $t$ is the total number of features, to a target $d$-dimensional feature subspace, $d<t$. After the feature selection process, the selected features are normalized, equally weighted and concatenated. The fused feature vector from the training image set is used to train a support vector machine (SVM) based classifier. The classifier makes prediction of whether the image quality is acceptable or not based on these features. 
% For our feature selection method, we basically follow the standard process of sequential floating forward selection (SFFS) that eventually reduces an initial $t$-dimensional feature space, where $t$ is the total number of features, into a target $d$-dimensional feature subspace, where $d  \textless  t$. 
% The process mainly consists of two steps, the forward selection step and the backward elimination step. Given a bag of features and a target number of features to use, SFFS starts with an empty set. During the forward step, the single best feature is selected based on the classification performance and then added to the feature set. During the backward step, SFFS removes one feature at a time based on the classification performance.

% \subsection{Classification}
% % Figure environment removed
%Figure \ref{fig:svm_diagram} describes the SVM-based classification.


% We then concatenate the features We use a support vector machine (SVM) based classifier to fuse the selected feature set. The selected features are normalized, equally weighted and concatenated into one single feature vector as a representation of the given low-dpi image, which integrates different aspects of the image. The fused features from the training image set is used to train a classification model that aims to analyze the content information from low-level image features and further distinguish whether the image quality is acceptable or not. Figure \ref{fig:svm_diagram} describes the SVM-based classification.
