\subsection{IEEE Arithmetic}
\label{subsec:ieee}

We remind the reader of some details of IEEE floating point arithmetic
\cite{overtonbook,IEEEnew}. The standard precisions in most software
environments are single and double precision. Half precision was originally
proposed as a storage format \cite{ieee} and is not implemented in
hardware on many platforms.
We will describe the details
of these three precisions in terms of the amount of storage a floating
point number requires (the width) and the unit roundoff $u$. As is standard
\cite{higham} we define
$u$ in terms of the floating point error in rounding the result of
any binary operation $\circ = \pm, \times, \div$ applied to two floating
point numbers $x$ and $y$
\[
fl( x \circ y ) = (x \circ y) ( 1 + \delta ), \  | \delta | \le u.
\]
Here $fl$ is the rounding map which takes a real $z$ in the range
of the floating point number system to the nearest floating point number.
If $z$ is not in the range of the floating point number system, then
attempting to compute $fl(z)$ will generate an exception. The range
will be important in this paper because one must pay particular
attention to that
when computing a Newton step with a half-precision Jacobian. We define
the range of the floating point number system as
\[
{\cal R} = \{ z \ | \ \sigma_L \le | z | \le \sigma_H \}
\]
where $\sigma_L$ is the smallest positive floating point number and
$\sigma_H$ is the largest positive floating point number.

We can now summarize the properties of the three precisions in this paper.
We took the data in Table~\ref{tab:precision} from a similar table in
\cite{NickCSE}.

\begin{table}[h!]
\caption{IEEE precisions}
\label{tab:precision}
\begin{center}
\begin{tabular}{|l|l|l|l|l|l}
\hline
Precision & width (bits) & $u$ & $\sigma_L$ & $\sigma_H$ \\
\hline
Half &  $16$ & $\approx 5 \times 10^{-4}$ & $10^{-5}$ & $10^5$\\
\hline
Single &  $32$ & $\approx 6 \times 10^{-8}$ & $10^{-38}$ & $10^{38} $ \\
\hline
Double &  $64$ & $\approx 10^{-16}$ & $10^{-308}$ & $10^{308} $ \\
\hline
\end{tabular}
\end{center}
\end{table}
When we discuss multiprecision computations we will let 
$u_d, u_s, u_h$ be  unit roundoff in double, single, or half precision.

Double and single precisions have been
supported in hardware for decades. Recently new computer architectures such
as the Apple M1 and M2 chips have been offering hardware support for half
precision. However, tools such as LAPACK and the BLAS 
\cite{lapack} do not support half precision
yet and run far more slowly in half precision
than they do in double precision. There is
active research on extending
the BLAS and LAPACK to use half precision \cite{newblas}.
The algorithm we propose in this paper will exploit half
precision well once the tools catch up.

