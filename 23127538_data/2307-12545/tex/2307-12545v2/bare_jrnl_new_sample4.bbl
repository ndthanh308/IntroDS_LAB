% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{sabokrou2017deep}
M.~Sabokrou, M.~Fayyaz, M.~Fathy, and R.~Klette, ``Deep-cascade: Cascading 3d
  deep neural networks for fast anomaly detection and localization in crowded
  scenes,'' \emph{IEEE Transactions on Image Processing}, vol.~26, no.~4, pp.
  1992--2004, 2017.

\bibitem{liu2018future}
W.~Liu, W.~Luo, D.~Lian, and S.~Gao, ``Future frame prediction for anomaly
  detection--a new baseline,'' in \emph{Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition}, 2018, pp. 6536--6545.

\bibitem{wu2019deep}
P.~Wu, J.~Liu, and F.~Shen, ``A deep one-class neural network for anomalous
  event detection in complex scenes,'' \emph{IEEE Transactions on Neural
  Networks and Learning Systems}, vol.~31, no.~7, pp. 2609--2622, 2019.

\bibitem{park2020learning}
H.~Park, J.~Noh, and B.~Ham, ``Learning memory-guided normality for anomaly
  detection,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2020, pp. 14\,372--14\,381.

\bibitem{georgescu2021anomaly}
M.-I. Georgescu, A.~Barbalau, R.~T. Ionescu, F.~S. Khan, M.~Popescu, and
  M.~Shah, ``Anomaly detection in video via self-supervised and multi-task
  learning,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2021, pp. 12\,742--12\,752.

\bibitem{sultani2018real}
W.~Sultani, C.~Chen, and M.~Shah, ``Real-world anomaly detection in
  surveillance videos,'' in \emph{Proceedings of the IEEE Conference on
  Computer Vision and Pattern Recognition}, 2018, pp. 6479--6488.

\bibitem{wu2020not}
P.~Wu, J.~Liu, Y.~Shi, Y.~Sun, F.~Shao, Z.~Wu, and Z.~Yang, ``Not only look,
  but also listen: Learning multimodal violence detection under weak
  supervision,'' in \emph{Proceedings of the European Conference on Computer
  Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 322--339.

\bibitem{feng2021mist}
J.-C. Feng, F.-T. Hong, and W.-S. Zheng, ``Mist: Multiple instance
  self-training framework for video anomaly detection,'' in \emph{Proceedings
  of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021,
  pp. 14\,009--14\,018.

\bibitem{tian2021weakly}
Y.~Tian, G.~Pang, Y.~Chen, R.~Singh, J.~W. Verjans, and G.~Carneiro,
  ``Weakly-supervised video anomaly detection with robust temporal feature
  magnitude learning,'' in \emph{Proceedings of the IEEE/CVF International
  Conference on Computer Vision}, 2021.

\bibitem{wu2021weakly}
J.~Wu, W.~Zhang, G.~Li, W.~Wu, X.~Tan, Y.~Li, E.~Ding, and L.~Lin,
  ``Weakly-supervised spatio-temporal anomaly detection in surveillance
  video,'' \emph{arXiv preprint arXiv:2108.03825}, 2021.

\bibitem{miech2018learning}
A.~Miech, I.~Laptev, and J.~Sivic, ``Learning a text-video embedding from
  incomplete and heterogeneous data,'' \emph{arXiv preprint arXiv:1804.02516},
  2018.

\bibitem{liu2019use}
Y.~Liu, S.~Albanie, A.~Nagrani, and A.~Zisserman, ``Use what you have: Video
  retrieval using representations from collaborative experts,'' \emph{arXiv
  preprint arXiv:1907.13487}, 2019.

\bibitem{gabeur2020multi}
V.~Gabeur, C.~Sun, K.~Alahari, and C.~Schmid, ``Multi-modal transformer for
  video retrieval,'' in \emph{Proceedings of the 16th European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  214--229.

\bibitem{yang2022video}
X.~Yang, S.~Wang, J.~Dong, J.~Dong, M.~Wang, and T.-S. Chua, ``Video moment
  retrieval with cross-modal neural architecture search,'' \emph{IEEE
  Transactions on Image Processing}, vol.~31, pp. 1204--1216, 2022.

\bibitem{yang2022tubedetr}
A.~Yang, A.~Miech, J.~Sivic, I.~Laptev, and C.~Schmid, ``Tubedetr:
  Spatio-temporal video grounding with transformers,'' in \emph{Proceedings of
  the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022,
  pp. 16\,442--16\,453.

\bibitem{cui2022video}
R.~Cui, T.~Qian, P.~Peng, E.~Daskalaki, J.~Chen, X.~Guo, H.~Sun, and Y.-G.
  Jiang, ``Video moment retrieval from text queries via single frame
  annotation,'' in \emph{Proceedings of the 45th International ACM SIGIR
  Conference on Research and Development in Information Retrieval}, 2022, pp.
  1033--1043.

\bibitem{wang2022cross}
G.~Wang, X.~Xu, F.~Shen, H.~Lu, Y.~Ji, and H.~T. Shen, ``Cross-modal dynamic
  networks for video moment retrieval with text query,'' \emph{IEEE
  Transactions on Multimedia}, vol.~24, pp. 1221--1232, 2022.

\bibitem{han2021dynamic}
Y.~Han, G.~Huang, S.~Song, L.~Yang, H.~Wang, and Y.~Wang, ``Dynamic neural
  networks: A survey,'' \emph{arXiv preprint arXiv:2102.04906}, 2021.

\bibitem{rao2021dynamicvit}
Y.~Rao, W.~Zhao, B.~Liu, J.~Lu, J.~Zhou, and C.-J. Hsieh, ``Dynamicvit:
  Efficient vision transformers with dynamic token sparsification,''
  \emph{arXiv preprint arXiv:2106.02034}, 2021.

\bibitem{zhi2021mgsampler}
Y.~Zhi, Z.~Tong, L.~Wang, and G.~Wu, ``Mgsampler: An explainable sampling
  strategy for video action recognition,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021.

\bibitem{fayyaz2022adaptive}
M.~Fayyaz, S.~A. Koohpayegani, F.~R. Jafari, S.~Sengupta, H.~R.~V. Joze,
  E.~Sommerlade, H.~Pirsiavash, and J.~Gall, ``Adaptive token sampling for
  efficient vision transformers,'' in \emph{Proceedings of the European
  Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2022, pp. 396--414.

\bibitem{li2021align}
J.~Li, R.~Selvaraju, A.~Gotmare, S.~Joty, C.~Xiong, and S.~C.~H. Hoi, ``Align
  before fuse: Vision and language representation learning with momentum
  distillation,'' \emph{Advances in Neural Information Processing Systems},
  vol.~34, pp. 9694--9705, 2021.

\bibitem{hou2022milan}
Z.~Hou, F.~Sun, Y.-K. Chen, Y.~Xie, and S.-Y. Kung, ``Milan: Masked image
  pretraining on language assisted representation,'' \emph{arXiv preprint
  arXiv:2208.06049}, 2022.

\bibitem{lee2019bman}
S.~Lee, H.~G. Kim, and Y.~M. Ro, ``Bman: Bidirectional multi-scale aggregation
  networks for abnormal event detection,'' \emph{IEEE Transactions on Image
  Processing}, vol.~29, pp. 2395--2408, 2019.

\bibitem{ionescu2019object}
R.~T. Ionescu, F.~S. Khan, M.-I. Georgescu, and L.~Shao, ``Object-centric
  auto-encoders and dummy anomalies for abnormal event detection in video,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2019, pp. 7842--7851.

\bibitem{gong2019memorizing}
D.~Gong, L.~Liu, V.~Le, B.~Saha, M.~R. Mansour, S.~Venkatesh, and A.~v.~d.
  Hengel, ``Memorizing normality to detect anomaly: Memory-augmented deep
  autoencoder for unsupervised anomaly detection,'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision}, 2019, pp. 1705--1714.

\bibitem{wang2022video}
G.~Wang, Y.~Wang, J.~Qin, D.~Zhang, X.~Bao, and D.~Huang, ``Video anomaly
  detection by solving decoupled spatio-temporal jigsaw puzzles,'' 2022.

\bibitem{yang2022dynamic}
Z.~Yang, P.~Wu, J.~Liu, and X.~Liu, ``Dynamic local aggregation network with
  adaptive clusterer for anomaly detection,'' in \emph{Proceedings of the
  European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2022, pp. 404--421.

\bibitem{yang2023video}
Z.~Yang, J.~Liu, Z.~Wu, P.~Wu, and X.~Liu, ``Video event restoration based on
  keyframes for video anomaly detection,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2023, pp.
  14\,592--14\,601\color{black}.

\bibitem{yan2023feature}
C.~Yan, S.~Zhang, Y.~Liu, G.~Pang, and W.~Wang, ``Feature prediction diffusion
  model for video anomaly detection,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2023, pp.
  5527--5537\color{black}.

\bibitem{lv2021localizing}
H.~Lv, C.~Zhou, Z.~Cui, C.~Xu, Y.~Li, and J.~Yang, ``Localizing anomalies from
  weakly-labeled videos,'' \emph{IEEE transactions on image processing},
  vol.~30, pp. 4505--4515, 2021.

\bibitem{wu2021learning}
P.~Wu and J.~Liu, ``Learning causal temporal relation and feature
  discrimination for anomaly detection,'' \emph{IEEE Transactions on Image
  Processing}, vol.~30, pp. 3513--3527, 2021.

\bibitem{cao2022adaptive}
C.~Cao, X.~Zhang, S.~Zhang, P.~Wang, and Y.~Zhang, ``Adaptive graph
  convolutional networks for weakly supervised anomaly detection in videos,''
  \emph{arXiv preprint arXiv:2202.06503}, 2022.

\bibitem{huang2022weakly}
C.~Huang, C.~Liu, J.~Wen, L.~Wu, Y.~Xu, Q.~Jiang, and Y.~Wang, ``Weakly
  supervised video anomaly detection via self-guided temporal discriminative
  transformer,'' \emph{IEEE Transactions on Cybernetics}, 2022\color{black}.

\bibitem{peng2017overview}
Y.~Peng, X.~Huang, and Y.~Zhao, ``An overview of cross-media retrieval:
  Concepts, methodologies, benchmarks, and challenges,'' \emph{IEEE
  Transactions on Circuits and Systems for Video Technology}, vol.~28, no.~9,
  pp. 2372--2385, 2017.

\bibitem{peng2017cross}
Y.~Peng, W.~Zhu, Y.~Zhao, C.~Xu, Q.~Huang, H.~Lu, Q.~Zheng, T.~Huang, and
  W.~Gao, ``Cross-media analysis and reasoning: advances and directions,''
  \emph{Frontiers of Information Technology \& Electronic Engineering},
  vol.~18, no.~1, pp. 44--57, 2017.

\bibitem{yu2022coca}
J.~Yu, Z.~Wang, V.~Vasudevan, L.~Yeung, M.~Seyedhosseini, and Y.~Wu, ``Coca:
  Contrastive captioners are image-text foundation models,'' \emph{arXiv
  preprint arXiv:2205.01917}, 2022.

\bibitem{zuo2023fine}
R.~Zuo, X.~Deng, K.~Chen, Z.~Zhang, Y.-K. Lai, F.~Liu, C.~Ma, H.~Wang, Y.-J.
  Liu, and H.~Wang, ``Fine-grained video retrieval with scene sketches,''
  \emph{IEEE Transactions on Image Processing}, 2023.

\bibitem{monfort2021spoken}
M.~Monfort, S.~Jin, A.~Liu, D.~Harwath, R.~Feris, J.~Glass, and A.~Oliva,
  ``Spoken moments: Learning joint audio-visual representations from video
  descriptions,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2021, pp. 14\,871--14\,881.

\bibitem{oncescu2021audio}
A.-M. Oncescu, A.~Koepke, J.~F. Henriques, Z.~Akata, and S.~Albanie, ``Audio
  retrieval with natural language queries,'' \emph{arXiv preprint
  arXiv:2105.02192}, 2021.

\bibitem{gabeur2021masking}
V.~Gabeur, A.~Nagrani, C.~Sun, K.~Alahari, and C.~Schmid, ``Masking modalities
  for cross-modal video retrieval,'' \emph{arXiv preprint arXiv:2111.01300},
  2021.

\bibitem{rouditchenko2021cascaded}
A.~Rouditchenko, A.~Boggust, D.~Harwath, S.~Thomas, H.~Kuehne, B.~Chen,
  R.~Panda, R.~Feris, B.~Kingsbury, M.~Picheny \emph{et~al.}, ``Cascaded
  multilingual audio-visual learning from videos,'' \emph{arXiv preprint
  arXiv:2111.04823}, 2021.

\bibitem{morgado2021audio}
P.~Morgado, N.~Vasconcelos, and I.~Misra, ``Audio-visual instance
  discrimination with cross-modal agreement,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp.
  12\,475--12\,486.

\bibitem{shen2023end}
W.~Shen, J.~Song, X.~Zhu, G.~Li, and H.~T. Shen, ``End-to-end pre-training with
  hierarchical matching and momentum contrast for text-video retrieval,''
  \emph{IEEE Transactions on Image Processing}, 2023.

\bibitem{tian2018audio}
Y.~Tian, J.~Shi, B.~Li, Z.~Duan, and C.~Xu, ``Audio-visual event localization
  in unconstrained videos,'' in \emph{Proceedings of the European conference on
  computer vision (ECCV)}, 2018, pp. 247--263\color{black}.

\bibitem{wei2022learning}
Y.~Wei, D.~Hu, Y.~Tian, and X.~Li, ``Learning in audio-visual context: A
  review, analysis, and new perspective,'' \emph{arXiv preprint
  arXiv:2208.09579}, 2022\color{black}.

\bibitem{wu2019dual}
Y.~Wu, L.~Zhu, Y.~Yan, and Y.~Yang, ``Dual attention matching for audio-visual
  event localization,'' in \emph{Proceedings of the IEEE/CVF international
  conference on computer vision}, 2019, pp. 6292--6300\color{black}.

\bibitem{lin2023vision}
Y.-B. Lin, Y.-L. Sung, J.~Lei, M.~Bansal, and G.~Bertasius, ``Vision
  transformers are parameter-efficient audio-visual learners,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2023, pp. 2299--2309\color{black}.

\bibitem{li2019w2vv++}
X.~Li, C.~Xu, G.~Yang, Z.~Chen, and J.~Dong, ``W2vv++ fully deep learning for
  ad-hoc video search,'' in \emph{Proceedings of the 27th ACM International
  Conference on Multimedia}, 2019, pp. 1786--1794.

\bibitem{dong2021dual}
J.~Dong, X.~Li, C.~Xu, X.~Yang, G.~Yang, X.~Wang, and M.~Wang, ``Dual encoding
  for video retrieval by text,'' \emph{IEEE Transactions on Pattern Analysis
  and Machine Intelligence}, 2021.

\bibitem{liu2021hit}
S.~Liu, H.~Fan, S.~Qian, Y.~Chen, W.~Ding, and Z.~Wang, ``Hit: Hierarchical
  transformer with momentum contrast for video-text retrieval,'' \emph{arXiv
  preprint arXiv:2103.15049}, 2021.

\bibitem{wray2019fine}
M.~Wray, D.~Larlus, G.~Csurka, and D.~Damen, ``Fine-grained action retrieval
  through multiple parts-of-speech embeddings,'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision}, 2019, pp. 450--459.

\bibitem{wu2021hanet}
P.~Wu, X.~He, M.~Tang, Y.~Lv, and J.~Liu, ``Hanet: Hierarchical alignment
  networks for video-text retrieval,'' in \emph{Proceedings of the 29th ACM
  International Conference on Multimedia}, 2021, pp. 3518--3527.

\bibitem{han2021fine}
N.~Han, J.~Chen, G.~Xiao, H.~Zhang, Y.~Zeng, and H.~Chen, ``Fine-grained
  cross-modal alignment network for text-video retrieval,'' in
  \emph{Proceedings of the 29th ACM International Conference on Multimedia},
  2021, pp. 3826--3834.

\bibitem{yang2021taco}
J.~Yang, Y.~Bisk, and J.~Gao, ``Taco: Token-aware cascade contrastive learning
  for video-text alignment,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021, pp. 11\,562--11\,572.

\bibitem{wangdig}
W.~Wang, M.~Zhang, R.~Chen, G.~Cai, P.~Zhou, P.~Peng, X.~Guo, J.~Wu, and
  X.~Sun, ``Dig into multi-modal cues for video retrieval with hierarchical
  alignment,'' in \emph{Proceedings of the International Joint Conference on
  Artificial Intelligence}, 2021.

\bibitem{ge2022bridging}
Y.~Ge, Y.~Ge, X.~Liu, D.~Li, Y.~Shan, X.~Qie, and P.~Luo, ``Bridging video-text
  retrieval with multiple choice questions,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp.
  16\,167--16\,176.

\bibitem{ma2022x}
Y.~Ma, G.~Xu, X.~Sun, M.~Yan, J.~Zhang, and R.~Ji, ``X-clip: End-to-end
  multi-grained contrastive learning for video-text retrieval,'' in
  \emph{Proceedings of the 30th ACM International Conference on Multimedia},
  2022, pp. 638--647.

\bibitem{li2020hero}
L.~Li, Y.-C. Chen, Y.~Cheng, Z.~Gan, L.~Yu, and J.~Liu, ``Hero: Hierarchical
  encoder for video+ language omni-representation pre-training,'' \emph{arXiv
  preprint arXiv:2005.00200}, 2020.

\bibitem{lei2021less}
J.~Lei, L.~Li, L.~Zhou, Z.~Gan, T.~L. Berg, M.~Bansal, and J.~Liu, ``Less is
  more: Clipbert for video-and-language learning via sparse sampling,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2021, pp. 7331--7341.

\bibitem{luo2020univl}
H.~Luo, L.~Ji, B.~Shi, H.~Huang, N.~Duan, T.~Li, J.~Li, T.~Bharti, and M.~Zhou,
  ``Univl: A unified video and language pre-training model for multimodal
  understanding and generation,'' \emph{arXiv preprint arXiv:2002.06353}, 2020.

\bibitem{ji2022cret}
K.~Ji, J.~Liu, W.~Hong, L.~Zhong, J.~Wang, J.~Chen, and W.~Chu, ``Cret:
  Cross-modal retrieval transformer for efficient text-video retrieval,'' in
  \emph{Proceedings of the 45th International ACM SIGIR Conference on Research
  and Development in Information Retrieval}, 2022, pp. 949--959.

\bibitem{dong2022partially}
J.~Dong, X.~Chen, M.~Zhang, X.~Yang, S.~Chen, X.~Li, and X.~Wang, ``Partially
  relevant video retrieval,'' in \emph{Proceedings of the 30th ACM
  International Conference on Multimedia}, 2022, pp. 246--257.

\bibitem{gao2017tall}
J.~Gao, C.~Sun, Z.~Yang, and R.~Nevatia, ``Tall: Temporal activity localization
  via language query,'' in \emph{Proceedings of the IEEE International
  Conference on Computer Vision}, 2017, pp. 5267--5275.

\bibitem{zhang2019man}
D.~Zhang, X.~Dai, X.~Wang, Y.-F. Wang, and L.~S. Davis, ``Man: Moment alignment
  network for natural language moment retrieval via iterative graph
  adjustment,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2019, pp. 1247--1257.

\bibitem{mithun2019weakly}
N.~C. Mithun, S.~Paul, and A.~K. Roy-Chowdhury, ``Weakly supervised video
  moment retrieval from text queries,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2019, pp.
  11\,592--11\,601.

\bibitem{ding2022exploring}
X.~Ding, N.~Wang, S.~Zhang, Z.~Huang, X.~Li, M.~Tang, T.~Liu, and X.~Gao,
  ``Exploring language hierarchy for video grounding,'' \emph{IEEE Transactions
  on Image Processing}, vol.~31, pp. 4693--4706, 2022.

\bibitem{miech2019howto100m}
A.~Miech, D.~Zhukov, J.-B. Alayrac, M.~Tapaswi, I.~Laptev, and J.~Sivic,
  ``Howto100m: Learning a text-video embedding by watching hundred million
  narrated video clips,'' in \emph{Proceedings of the IEEE/CVF International
  Conference on Computer Vision}, 2019, pp. 2630--2640.

\bibitem{wray2021semantic}
M.~Wray, H.~Doughty, and D.~Damen, ``On semantic similarity in video
  retrieval,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2021, pp. 3650--3660.

\bibitem{xu2016msr}
J.~Xu, T.~Mei, T.~Yao, and Y.~Rui, ``Msr-vtt: A large video description dataset
  for bridging video and language,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2016, pp. 5288--5296.

\bibitem{wang2019vatex}
X.~Wang, J.~Wu, J.~Chen, L.~Li, Y.-F. Wang, and W.~Y. Wang, ``Vatex: A
  large-scale, high-quality multilingual dataset for video-and-language
  research,'' in \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2019, pp. 4581--4591.

\bibitem{kim2019audiocaps}
C.~D. Kim, B.~Kim, H.~Lee, and G.~Kim, ``Audiocaps: Generating captions for
  audios in the wild,'' in \emph{Proceedings of the 2019 Conference of the
  North American Chapter of the Association for Computational Linguistics:
  Human Language Technologies}, 2019, pp. 119--132.

\bibitem{tian2020unified}
Y.~Tian, D.~Li, and C.~Xu, ``Unified multisensory perception: Weakly-supervised
  audio-visual video parsing,'' in \emph{Computer Vision--ECCV 2020: 16th
  European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III
  16}, 2020, pp. 436--454\color{black}.

\bibitem{lei2020tvr}
J.~Lei, L.~Yu, T.~L. Berg, and M.~Bansal, ``Tvr: A large-scale dataset for
  video-subtitle moment retrieval,'' in \emph{Proceedings of the 16th European
  Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2020, pp. 447--463.

\bibitem{arnab2021vivit}
A.~Arnab, M.~Dehghani, G.~Heigold, C.~Sun, M.~Lu{\v{c}}i{\'c}, and C.~Schmid,
  ``Vivit: A video vision transformer,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021, pp. 6836--6846.

\bibitem{neimark2021video}
D.~Neimark, O.~Bar, M.~Zohar, and D.~Asselmann, ``Video transformer network,''
  in \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 3163--3172.

\bibitem{carreira2017quo}
J.~Carreira and A.~Zisserman, ``Quo vadis, action recognition? a new model and
  the kinetics dataset,'' in \emph{Proceedings of the IEEE Conference on
  Computer Vision and Pattern Recognition}, 2017, pp. 6299--6308.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in
  \emph{Advances in neural information processing systems}, 2017, pp.
  5998--6008.

\bibitem{huang2022hierarchical}
C.~Huang, Y.~Liu, Z.~Zhang, C.~Liu, J.~Wen, Y.~Xu, and Y.~Wang, ``Hierarchical
  graph embedded pose regularity learning via spatio-temporal transformer for
  abnormal behavior detection,'' in \emph{Proceedings of the 30th ACM
  International Conference on Multimedia}, 2022, pp. 307--315\color{black}.

\bibitem{zhao2022centerclip}
S.~Zhao, L.~Zhu, X.~Wang, and Y.~Yang, ``Centerclip: Token clustering for
  efficient text-video retrieval,'' in \emph{Proceedings of the 45th
  International ACM SIGIR Conference on Research and Development in Information
  Retrieval}, 2022, pp. 970--981\color{black}.

\bibitem{gemmeke2017audio}
J.~F. Gemmeke, D.~P. Ellis, D.~Freedman, A.~Jansen, W.~Lawrence, R.~C. Moore,
  M.~Plakal, and M.~Ritter, ``Audio set: An ontology and human-labeled dataset
  for audio events,'' in \emph{2017 IEEE International Conference on Acoustics,
  Speech and Signal Processing}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2017, pp. 776--780.

\bibitem{wu2020evolutionary}
K.~Wu, J.~Liu, X.~Hao, P.~Liu, and F.~Shen, ``An evolutionary multiobjective
  framework for complex network reconstruction using community structure,''
  \emph{IEEE Transactions on Evolutionary Computation}, vol.~25, no.~2, pp.
  247--261, 2020.

\bibitem{jin2018data}
Y.~Jin, H.~Wang, T.~Chugh, D.~Guo, and K.~Miettinen, ``Data-driven evolutionary
  optimization: An overview and case studies,'' \emph{IEEE Transactions on
  Evolutionary Computation}, vol.~23, no.~3, pp. 442--458, 2018.

\bibitem{back1996evolutionary}
T.~Back, \emph{Evolutionary algorithms in theory and practice: evolution
  strategies, evolutionary programming, genetic algorithms}.\hskip 1em plus
  0.5em minus 0.4em\relax Oxford university press, 1996.

\bibitem{wu2018unsupervised}
Z.~Wu, Y.~Xiong, S.~X. Yu, and D.~Lin, ``Unsupervised feature learning via
  non-parametric instance discrimination,'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition}, 2018, pp. 3733--3742.

\bibitem{he2022masked}
K.~He, X.~Chen, S.~Xie, Y.~Li, P.~Doll{\'a}r, and R.~Girshick, ``Masked
  autoencoders are scalable vision learners,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp.
  16\,000--16\,009.

\bibitem{paul2018w}
S.~Paul, S.~Roy, and A.~K. Roy-Chowdhury, ``W-talc: Weakly-supervised temporal
  activity localization and classification,'' in \emph{Proceedings of the
  European Conference on Computer Vision}, 2018, pp. 563--579.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,''
  \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{wang2021t2vlad}
X.~Wang, L.~Zhu, and Y.~Yang, ``T2vlad: global-local sequence alignment for
  text-video retrieval,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2021, pp. 5079--5088.

\bibitem{mikolov2013efficient}
T.~Mikolov, K.~Chen, G.~Corrado, and J.~Dean, ``Efficient estimation of word
  representations in vector space,'' \emph{arXiv preprint arXiv:1301.3781},
  2013.

\end{thebibliography}
