\section{Introduction}

The lynchpin to a large portion of software documentation for programmers is the ``source code summary.''  A summary is a natural language description of the behavior of a section of source code.  Program subroutines are the typical target for summaries.  Documentation engines such as JavaDocs and Pydocs use these summaries to help programmers gain a quick understanding of what each subroutine does~\cite{Kramer:1999:ADS:318372.318577}.  Software engineering researchers have long dreamt of automating code summarization, because writing summaries by hand is expensive, especially for legacy systems which source code is often not well-documented~\cite{allamanis2018survey, forward2002relevance, haiduc2010supporting}.

The workhorse of almost all recent research into code summarization is the attentional encoder-decoder neural architecture.  The inspiration for using models of this architecture derives from machine translation in NLP, in which sentences in one natural language (e.g. French) are translated into another (e.g. English).  When provided sufficient training data (usually well into the millions of examples), the encoder portion of the model learns a representation of one language, and the decoder learns the other.  The representations are combined via an attention network or other mechanism.  Then if the encoder is provided a sentence in one language, the decoder can be used to help predict an output sentence in the other language.  This is a tidy solution for machine translation because the information needed to write a sentence in one language tends to exist in translated sentences in other languages -- the encoder usually has access to all the information it needs to represent the sentence for the decoder.

Yet the metaphor of code summarization as machine translation breaks down because the source code of a subroutine is a very different representation of program behavior than natural language (an issue known as the concept assignment problem~\cite{biggerstaff1993concept}).  In a vast majority of neural code summarization approaches, the entire subroutine code is treated as a single unit, from which a summary is then written.  For example, the code may be a sequence entered into a Transformer or RNN-based encoder~\cite{hu2018deep, leclair2019neural, ahmad2020transformer}.  Or the Abstract Syntax Tree (AST) of the subroutine may be used as the input to a Graph Neural Network (GNN)~\cite{leclair2020improved} or a path-based approach~\cite{alon2019code2seq}.  The point is that the encoder is tasked with learning the semantics of an entire subroutine all at once.

A more human-like view of code is as a sequence of statements~\cite{robson1991approaches, siegmund2014understanding, siegmund2016program, latoza2007program}.  Software engineering research literature has long recognized that when people cannot just apply domain knowledge to rapidly digest code, ``they use bottom-up comprehension, so they understand source code statement by statement''~\cite{ siegmund2014understanding}.  The idea is that the behavior of any given statement tends to be highly dependent on the statements that precede it.  A conditional may cause a statement not to execute at all, or an assignment statement may completely change the meaning of a variable used later.  People understand code in terms of what each statement does.

The traditional way to establish the behavior of code in terms of the statements is dynamic analysis.  If actual inputs are entered and the code run, then the behavior of the program may be explained definitively.  Other strategies include symbolic or concolic execution~\cite{baldoni2018survey}.  But these strategies are not practical on a large dataset -- training data for neural code summarization often run into hundreds of thousands or even millions of examples~\cite{leclair2019recommendations, allamanis2019adverse}.

In this paper, we present \textbf{Statement-based Memory}, a novel encoder for neural source code summarization.  Our idea is inspired by Dynamic Memory Networks (DMN)~\cite{kumar2016ask} in which a model learns to answer questions by connecting features in a sequence of events (e.g., given two sentences ``Alice gave the ball to Bob.  Bob went to the parlor.'' the model could answer ``In what room is the ball?'' by learning to connect the feature ``Bob.'')  From a very high level, each statement is like a fact, and the features connecting the statements are the variable names, function calls, etc.  We create a novel model based on this inspiration using a custom attention mechanism among features in a sequence of statements.  The model learns to build a representation of each statement that emphasizes the important features for different concepts.  This learned attention serves as the model's ``memories.''

Our evaluation has three components: 1) we perform a quantitative controlled experiment using automated metrics, 2) we study the subset of subroutines most improved by our approach 3) we perform an analysis of our design choices and model configurations. The quantitative experiment maintains consistency with recent research literature by comparing our approach against a recent baseline over a large number of subroutines . The subset analysis serves to provide an in-depth view of the features of subroutines most improved by our approach. Finally, the evaluation of different configurations and design choices serves to maximize the breadth of our evaluation and inform future research.

We release all implementation details, experimental materials, and results via an online appendix in Section~\ref{sec:repo}.


