\section{Conclusion}

This paper focuses on generating helpful training data for the punctuation restoration task, especially for real-world ASR texts.
We devise a reinforcement learning method to use the GPT2 model to generate additional data to train the punctuation restoration model. This method allows the GPT2 model to learn from real-world ASR text to generate more helpful training examples based on gradient feedback from the PR model. Our model improves PR performance on real-world ASR tests on IWSLT and BehancePR  (+3\% and +2.3\%, respectively). In the future, we would like to extend this research with more advanced gradient feedback to improve the generated data.

\section{Acknowledgement}: This research has been supported by the Army Research Office (ARO) grant W911NF-21-1-0112, the NSF grant CNS-1747798 to the IUCRC Center for Big Learning, and the NSF grant \# 2239570. This research is also supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program contract 2022-22072200003. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.