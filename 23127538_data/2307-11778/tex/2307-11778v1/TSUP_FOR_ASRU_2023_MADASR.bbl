\begin{thebibliography}{1}

\bibitem{singh2023model}
Abhayjeet Singh, Arjun~Singh Mehta, Ashish Khuraishi~K S, Deekshitha G, Gauri
  Date, Jai Nanavati, Jesuraja Bandekar, Karnalius Basumatary, Karthika P,
  Sandhya Badiger, Sathvik Udupa, Saurabh Kumar, Savitha, Prasanta~Kumar Ghosh,
  Prashanthi V, Priyanka Pai, Raoul Nanavati, Rohan Saxena, Sai Praneeth~Reddy
  Mora, and Srinivasa Raghavan,
\newblock ``Model adaptation for asr in low-resource indian languages,'' 2023.

\bibitem{radford2023robust}
Alec Radford, Jong~Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and
  Ilya Sutskever,
\newblock ``Robust speech recognition via large-scale weak supervision,''
\newblock in {\em International Conference on Machine Learning}. PMLR, 2023,
  pp. 28492--28518.

\bibitem{baevski2020wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli,
\newblock ``wav2vec 2.0: A framework for self-supervised learning of speech
  representations,''
\newblock {\em Advances in neural information processing systems}, vol. 33, pp.
  12449--12460, 2020.

\bibitem{bhogale2023vistaar}
Kaushal~Santosh Bhogale, Sai Sundaresan, Abhigyan Raman, Tahir Javed, Mitesh~M
  Khapra, and Pratyush Kumar,
\newblock ``Vistaar: Diverse benchmarks and training sets for indian language
  asr,''
\newblock {\em arXiv preprint arXiv:2305.15386}, 2023.

\end{thebibliography}
