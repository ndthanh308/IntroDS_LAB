 %\documentclass[ runningheads]{llncs} \pdfoutput=1 \usepackage{graphicx}
\documentclass{amsproc}
\usepackage{amssymb}
\usepackage{amsfonts}       
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage[siunitx, RPvoltages]{circuitikz}
\begin{document}
	\title{Complex Analysis of Intelligent  Systems}
	\author{  M.W.  AlMasri }
	\address{ Department of Mathematics, Statistics and Physics, Qatar University, Doha, 2713, Qatar}
	\email{mwalmasri2003@gmail.com}
	\maketitle
	\begin{abstract}
Logic gates can be written in terms of complex differential operators where the inputs and outputs are analytic functions with several variables. Using the polar representation of complex numbers, we arrive at an immediate connection between the oscillatory behavior of the system and logic gates. We explain the universal programming language (UPL) used by physical objects to process information. To assure the causality structure in UPL, we introduce the concept of layers that characterizes the computations for each time scale. 
	\end{abstract}
	\section{Introduction}
	Understanding how nature ``thinks'' is undoubtedly the ultimate aim of our scientific research. Since the last decade, we have witnessed great progress in our computational capabilities, paving the way for revolutions in the field of artificial intelligence. Interestingly, despite the numerous physical theories of computation, we still lack a decisive answer to the question:  how nature ``thinks''? Understanding this vital issue would complete the current perspective and enables us to develop further technologies at maximum capacity in terms of energy efficiency and computation capabilities. It has been suggested a few decades ago that our universe might be a giant computer\cite{Zuse}. This has inspired scientists to strongly believe that  information is physical\cite{Landauer1}. \\
	Computers are physical systems: the laws of physics dictate what they can and cannot do. Concretely, the speed with which a physical device can process information is limited solely by its energy, and the amount of information that it can process is limited by the number of degrees of freedom it possesses. Therefore, there must be an intimate relationship between the dynamical evolution of  physical states and their behavior regarding processing and storing information \cite{Landauer,Feynman,Bennett,Lloyd,Parrondo}.\\
In order to have a true description of how nature thinks, we start with the properties of elementary particles and their behaviors. The justification of this ideology stems from the feeling that nature uses one universal programming language for coding and encoding information at different scales. While it is possible to artificially construct other ways for coding and encoding information, the way that nature chooses must be the fastest and therefore the most efficient way for processing information in order not to violate the causality principle. In other words, if we assume a physical system $\mathcal{S}$ to process information at some time scale $t_{0}$ then it must be equivalent or less efficient than the way the container $\mathcal{C}$ process information at the same time scale $t_{0}$. To a large extent, the container is the universe that contains all the subsystems inside it evolving on the same time scale. We shall explain these in detail and introduce the concept of layers in computation. \\
According to quantum mechanics, subatomic particles behave like waves propagating in spacetime. The wave-particle duality was proposed by de Broglie  \cite{waves}. The de Broglie wavelength $\lambda$ associated with a particle is
\begin{eqnarray}
	\lambda=\frac{h}{p}, 
\end{eqnarray}
where $h$ is Planck's constant and $p$ is the particle's momentum. In the Davisson-Germer experiment, electrons scattered by the surface of a crystal of nickel metal produced a diffraction pattern similar to waves\footnote{C. Davisson  and L. H. Germer, \emph{Phys. Rev.} {\bf 30} (1927) 705}. Interestingly, changing diffraction patterns, as we shall see in the incoming sections, are intimately connected to the operations of logic gates.  \vskip 5mm  The correspondence between oscillatory behavior and logic gates computation is assured mathematically by writing logic gates in terms of complex differential operators acting on analytic functions. 
Oscillatory systems are omnipresent in the universe. Some notable examples are the attractor cycle oscillators, rotors, neural oscillation patterns in the brain, synchronized chaos, and Josephson junctions. Other examples in biology and physics  can be read from \cite{Winfree,Strogatz}. 

	 \section{Hilbert Space of Analytic Functions }
	Let $U$ be a non-empty open set in $\mathbb{C}^{d}$ and let $\mathcal{H}(U)$ denote the space of holomorphic functions on $U$. A complex-valued function $f: U\rightarrow \mathbb{C}$ is said to be holomorphic if it is differentiable in a neighborhood of each point in $U$.    Let $\mathcal{H}L^{2}(U,\omega)$ denotes the space of $L^{2}$-holomorphic functions with respect to the weight $\omega$, that is, 
	 \begin{eqnarray}
	 	\mathcal{H}L^{2}(U,\omega)= \{ F\in \mathcal{H}(U) | \int_{U} |F(z)|^{2}\;\omega(z)\; dz< \infty\}. 
	 \end{eqnarray}
 Here $dz$ denotes the $2d$-dimensional Lebesgue measure on $\mathbb{C}^{d}=\mathbb{R}^{2d}$ not a line integral. Some examples of holomorphic function spaces  are the weighted Bergman  and the  Segal-Bargmann  \cite{Hall,almasri1,almasri2,almasri3}. In this work, we will use the Segal-Bargmann spaces .  \vskip 5mm
The  Segal-Bargmann spaces (also known as Bargmann spaces) $\mathcal{H}L^{2}(\mathbb{C}^{d},\mu_{t})$	 are spaces 	of holomorphic functions with Gaussian integration measure $\mu_{t}=(\pi)^{-d}e^{-|z|^{2}/t}$
	and  inner product of the form \cite{Hall}
\begin{eqnarray}
	\langle f|g\rangle=(\pi t)^{-d}\int_{\mathbb{C}^{d}}\overline{f}(z)\;g (z)\; e^{-|z|^{2}/t}dz, 
\end{eqnarray}
Where $|z|^{2}=|z_{1}|^{2}+\dots +|z_{d}|^{2}$ and $dz$ is the $2d$-dimensional Lebesgue measure on $\mathbb{C}^{d}$ and $t$ is a constant equals to  $\hbar$ if the physical states under study are quantized.\vskip 5mm  
The Segal-Bargmann transform is a  unitary map $B_{t}:L^{2}(\mathbb{R}^{d},dx)\rightarrow \mathcal{H}L^{2}(\mathbb{C}^{d},\mu_{t})$ and defined as 
\begin{eqnarray}
	B_{t}f(z)=(\pi t)^{-d/4}\int_{\mathbb{R}^{d} }e^{\left(-z^{2}+2\sqrt{2}z\cdot x-x^{2}\right)/2t} f(x)\;dx.
\end{eqnarray}

and the  reproducing kernel  is defined by 
\begin{eqnarray}
	K(z,w)=\sum_{n=0}^{\infty}\frac{z^{n}}{\sqrt{n!t^{n}}}\frac{\overline{w}^{n}}{\sqrt{n!t^{n}}}=\sum_{n=0}^{\infty}\frac{1}{n!}(\frac{z\overline{w}}{t})^{n}=e^{z\overline{w}/t}
\end{eqnarray}
 The kernel   $K(z,w)$ is holomorphic in $z$ and anti-holomorphic in $w$. It  satisfies the following properties: \vskip 5mm
 1- $K(z,w)=\overline{K(w,z)}$\vskip 5mm
 2- For each fixed $z\in \mathbb{C}$, $K(z,w)$ is square-integrable $d\mu_{t}$. For all $f(z)\in \mathcal{H}L^{2}(\mathbb{C},\mu_{t})$, we may write 
 \begin{eqnarray}
 	f(z)=\int_{\mathbb{C}}K(z,w)\;f(w) \;\mu_{t}(w)\;dz.
 \end{eqnarray}\vskip 5mm
3- For all $z,w\in \mathbb{C}$ , 
\begin{eqnarray}
	\int_{\mathbb{C}}K(z,u)\;K(u,w)\; \mu_{t}(u) \;du= K(z,w)
\end{eqnarray}
The monomials $\{\frac{z^{n}}{\sqrt{n!t^{n}}}\}$ form an orthonormal basis in $\mathcal{H}L^{2}(\mathbb{C}^{n},\mu_{t})$. The orthonormality condition with $t=d=1$ is 
\begin{eqnarray}
	\frac{1}{\pi }\int_{\mathbb{C}}  e^{-|z|^{2}}\; \overline{z}^{n} z^{m}dz =  n!\; \delta_{mn}.  
\end{eqnarray} 
\vskip 5mm
Using the properties of the Bargamnn spaces, one could calculate the numerical values of the $n$th derivative of any complex functions at point $z_{0}$ by integration over the Bargamnn space. 
Let $f(z)$ be an analytic function of complex variable $z$.  The Taylor series of $f$ at a complex number $z_{0}$ is \cite{Ahlfors}
\begin{equation}\label{taylor}
	f(z)= f(z_{0})+ \frac{f^{\prime}(z_{0})}{1!} \left(z-z_{0}\right)+ \frac{f^{\prime \prime}(z_{0})}{2!} (z-z_{0})^{2}+\dots= \sum_{n=0}^{\infty} \frac{f^{(n)}(z_{0})}{n!} \left(z-z_{0}\right)^{n}.
\end{equation}
When $z_{0}=0$, the Taylor series  reduces to a Maclaurin series i.e. $\sum_{n=0}^{\infty} \frac{f^{(n)}(0)}{n!} z^{n} $.  Let us compute the inner product $\langle z^{n}|f(z)\rangle$ where $f(z)=  \sum_{n=0}^{\infty} \frac{f^{(n)}(0)}{n!} z^{n}$ is a Maclaurin series, we find 
\begin{eqnarray}\label{result}
	f^{(n)}(0)=  \langle z^{n}|f(z)\rangle
\end{eqnarray} 
which is very interesting since it gives a closed analytical expression for the $n$th derivative of any analytic complex function at $z=0$ by computing the inner product of its Maclaurin series expansion with monomial $z^{n}$  in $\mathcal{H}L^{2}(\mathbb{C},\mu_{1})$.  Practically, this  means computing Gaussian integrals of the form $\frac{1}{\pi}\int_{\mathbb{C}} \overline{z}^{n} f(z)e^{-|z|^{2}} dz$. For the Taylor series, the formula \ref{result} becomes
\begin{eqnarray}\label{resulttaylor}
	f^{(n)}(z_{0})= \langle (z-z_{0})^{n}|f(z)\rangle.
\end{eqnarray}
\vskip 5mm


The derivative of a given analytic function $f(z)$ is 
\begin{eqnarray}\label{derivative}
	f^{\prime}(z)= \lim_{h\rightarrow 0}\frac{f(z+h)-f(z)}{h}, 
\end{eqnarray}
where $h$ is the step size. For infinitesimally small $h$, we may compute the derivative approximately using a forward-difference expression, 
\begin{eqnarray}\label{forward}
	f^{\prime}(z)\approx \frac{f(z+h)-f(z)}{h},
\end{eqnarray}
Using \ref{resulttaylor}, the forward-difference expression at point $z_{0}$ assumes the form 
\begin{eqnarray}\label{result1}
	\langle (z-z_{0})|f(z)\rangle \approx \frac{1}{h}\left(f(z_{0}+h)-f(z_{0})\right)
\end{eqnarray}
Analogously, the second-order forward-difference expression is 
\begin{eqnarray}
	\langle (z-z_{0})^{2}|f(z)\rangle \approx  \frac{1}{h^{2}}\left(f(z_{0}+2h)-2f(z_{0}+h)+f(z_{0})\right). 
\end{eqnarray}
Thus, we have written the finite differences in terms of integrals over the space of holomorphic function spaces with Gaussian integration measure. Consequently,  one could use the numerical methods for integrals to compute derivatives approximately instead of finite differences\cite{Hamming}. This is more efficient since for higher-order derivatives we would have long expressions using the finite-difference method. However, using our method we can compute higher-order derivatives using one integral  similar to \ref{result}.
\vskip 5mm
Now let us look closely at \ref{result1}, using the fundamental theorem of calculus we find 
\begin{eqnarray}
	f^{\prime}(z_{0})=\langle (z-z_{0})|f(z)\rangle\approx \frac{1}{h}\int_{z_{0}}^{z_{0}+h} f^{\prime}(z) dz. 
\end{eqnarray}
Interestingly, the derivative of function $f$ at point $z_{0}$   is approximately equal to the integral of $f^{\prime}(z)$ between $z_{0}+h$ and $z_{0}$. This means that we can equate integrals over holomorphic function with Gaussian integration measure with integrals over ordinary complex space.\vskip 5mm

It is clear that working in the Bargamnn spaces enhances the space of solutions by using the inner product properties of these spaces. For example, the generalized hypergeometric function is 
\begin{eqnarray}
	_{p}F_{q}\left(a_{1},\dots, a_{p}; b_{1},\dots,b_{q};z\right)=\sum_{n=0}^{\infty}\frac{(a_{1})_{n}\dots (a_{p})_{n}}{(b_{1})_{n}\dots (b_{q})_{n}}\frac{z^{n}}{n!},
\end{eqnarray}
where $(x)_{n}=x(x+1)(x+2)\dots (x+n-1), \; \; n\geq 1$ is the  Pochhammer symbol with $(x)_{0}=1$. Using  \ref{result}, we find 
\begin{eqnarray}
	\frac{(a_{1})_{n}\dots (a_{p})_{n}}{(b_{1})_{n}\dots (b_{q})_{n}}= \langle z^{n}|	_{p}F_{q}\left(a_{1},\dots, a_{p}; b_{1},\dots,b_{q};z\right)\rangle .
\end{eqnarray}
Thus, the coefficients of generalized hypergeometric functions can be determined uniquely using inner products in the Bargmann spaces.  \vskip 5mm 
 The states of a quantum system with $n$ degrees of freedom are usually described by functions either in the configuration space $(q_{1},q_{2},\dots q_{n})$ or in the momentum space $(p_{1},p_{2},\dots p_{n})$. The complex combinations of these variables have proven to be effective both at quantum and classical levels. Moreover, they appear in the study of harmonic oscillator and Bose particle field theories as the creation and annihilation operators. \vskip 5mm
 We define the complex conjugate operators as
 \begin{eqnarray}
 	\eta_{k}=2^{-1/2} \left(q_{k}-i p_{k}\right), \\
 	\xi_{k}= 2^{-1/2}\left(q_{k}+ip_{k}\right).
 \end{eqnarray} 
 If $q_{k},p_{k}$ are self-adjoint operators satisfying the canonical commutation relations (with Planck constant $\hbar=1$)
 \begin{eqnarray}
 	[q_{k},p_{l}]=i\delta_{kl}, \; [q_{k},q_{l}]=[p_{k},p_{l}]=0,
 \end{eqnarray}
Then it follows that 
\begin{eqnarray}
	\xi_{k}=\eta^{\star}_{k}, \; \eta_{k}=\xi_{k}^{\star},\;  [\xi_{k},\eta_{l}]=\delta_{kl}, \; [\xi_{k},\xi_{l}]=[\eta_{k},\eta_{l}]=0.
\end{eqnarray}
In 1928, Fock  introduced the operator solution $\xi_{k}=\partial/\partial \eta_{k}$ of the commutation relation $[\xi_{k},\eta_{k}]=1$  in analogy with $p_{k}=-i\partial/\partial q_{k}$ of the relation $[q_{k},p_{k}]=i$ and applied it to quantum field theory\footnote{V. A. Fock, \emph{Verallgemeinerung und Loesungder Diracschen statistischen Gleichung}, Z.Phys. {\bf 49},339 (1928).}. \vskip 5mm 
Consider a quantum  harmonic oscillator with a single-mode described in terms of the  coordinates $q,p$ in the phase space. The creation and annihilation operators are 
\begin{eqnarray}
\eta=2^{-1/2} \left(q-i p\right), \\
\xi= 2^{-1/2}\left(q+ip\right).
\end{eqnarray}
with canonical commutation relation $[\xi,\eta]=1$. The Hamiltonian operator is 
\begin{eqnarray}
	H= \eta \frac{\partial }{\partial \eta}+\frac{1}{2},
\end{eqnarray}
with energy eigenvectors equal to $\frac{\eta^{n}}{\sqrt{n!}}$. 
 \vskip 5mm 
It is convenient as it will appear later in this work to represent  spin operators in terms of uncoupled quantum oscillators. Here, we use the Jordan-Schwinger map of the $\mathfrak{su}(2)$ algebra to deal with particles with arbitrary spin number by means of creation and annihilation operators. For two uncoupled quantum oscillators with annihilation operators $a$ and $b$, the spin operators read, 
 \begin{eqnarray}\label{spin1}
 	\sigma_{x}=\left(a^{\dagger}b+b^{\dagger}a\right), \\
 	\sigma_{y}= -i\left(a^{\dagger}b-b^{\dagger}a\right),\label{spin2}\\
 	\sigma_{z}=\left(a^{\dagger}a-b^{\dagger}b\right).\label{spin3}
 \end{eqnarray}
The canonical commutation relations between the spin operators are 
\begin{eqnarray}
	[\sigma_{i},\sigma_{j}]=i\;\epsilon_{ijk}\;\sigma_{k}, \;\;\; [\sigma_{i},\sigma^{2}]=0, 
\end{eqnarray}
where $i=x,y,z$. The squared spin operator reads \begin{equation}
\sigma^{2}=\frac{N}{2}\left(\frac{N}{2}+1\right)
\end{equation}
where $N=N_{1}+N_{2}$  is the total number operator with $ N_{1}=a^{\dagger}a$ and $N_{2}=b^{\dagger}b$. 
  Normalized states with occupation numbers $n_{1}$ and $n_{2}$ can be obtained by applying the creation operators on the vacuum state i.e. $|0,0\rangle$,  
\begin{eqnarray}
	|n_{1},n_{2}\rangle= \frac{(a^{\dagger})^{n_{1}}}{\sqrt{n_{1}!}}\frac{(b^{\dagger})^{n_{2}}}{\sqrt{n_{2}!}}|0,0\rangle.
\end{eqnarray} 
With $j=\frac{n_{1}+n_{2}}{2}$ and $m=\frac{n_{1}-n_{2}}{2}$ runs from $-j$ to $j$ in integer steps. \vskip 5mm
In Bargmann representation, the spin operators \ref{spin1}, \ref{spin2} and \ref{spin3} read
\begin{eqnarray}
\sigma_{x}=\left(z_{1}\frac{\partial}{\partial z_{2}}+z_{2}\frac{\partial }{\partial z_{1}}\right), \\
\sigma_{y}= -i\left(z_{1}\frac{\partial}{\partial z_{2}}-z_{2}\frac{\partial }{\partial z_{1}}\right),\\
\sigma_{z}=\left(z_{1}\frac{\partial }{\partial z_{1}}-z_{2}\frac{\partial }{\partial z_{2}}\right).
\end{eqnarray}
In this case, the normalized states are 
\begin{eqnarray}\label{normalized}
|n_{1},n_{2}\rangle=\frac{z_{1}^{n_{1}}}{\sqrt{n_{1}!}} \frac{z_{2}^{n_{2}}}{\sqrt{n_{2}!}}\equiv f_{n_{1}n_{2}}
\end{eqnarray} 
since 
\begin{align}
	\langle m_{1},m_{2}|n_{1},n_{2}\rangle=\frac{1}{\pi^{2}}\int_{\mathbb{C}^{2}}\overline{f_{m_{1}m_{2}}}\; f_{n_{1}n_{2}} \; e^{-|z|^{2}-|w|^{2}}\; dz \; dw=  \delta_{m_{1},n_{1}} \delta_{m_{2},n_{2}}.
\end{align}

	 \section{Holomorphic Representation of Logic Gates}
	
	In this section, we formulate the logic gates as differential operators written in terms of complex variables and their partial derivatives. Such representation is possible both in classical and quantum regimes. To see this, consider a hypothetical material which allows red light to pass through it and absorbs black light. In this case, if we assign the variable $z_{1}$ for the red light and $z_{2}$ for the black light we may represent the action of the material by the differential operator $\frac{\partial}{\partial z_{2}}$. Generally, it is possible to find equivalent expressions for  propositional logic in terms of holomorphic variables and their partial derivatives. The fundamental logic gates that operates between two analytic functions are  the Pauli gates plus the identity gate $(I,  \vec{\sigma})$\cite{Nielsen}. Any given two-input gate can be written in terms of the identity operator and the Pauli vector. 
	  Pauli gates are defined as complex differential operators that act on analytic functions with two-variables
	 \begin{eqnarray}
	 	X=\mathrm{NOT}= \sigma_{x}=\left(z_{1}\frac{\partial}{\partial z_{2}}+z_{2}\frac{\partial }{\partial z_{1}}\right),\\
	 	Y=\sigma_{y}=-i\left(z_{1}\frac{\partial}{\partial z_{2}}-z_{2}\frac{\partial }{\partial z_{1}}\right),\\
	 	Z=\sigma_{z}=\left(z_{1}\frac{\partial }{\partial z_{1}}-z_{2}\frac{\partial }{\partial z_{2}}\right).
	 \end{eqnarray}

 The identity gate in the case of two-variable function is 
 \begin{eqnarray}
 	I=\left(z_{1}\frac{\partial }{\partial z_{1}}+z_{2}\frac{\partial }{\partial z_{2}}\right)
 \end{eqnarray}
For the $N$-dimensional case, the identity operator reads  
\begin{eqnarray}
	I= \sum_{i=1}^{N} z_{i}\frac{\partial }{\partial z_{i}}
\end{eqnarray}

\vskip 5mm
The  Hadamard or Walsh-Hadamard gate acts on analytic functions with two-variables in the following way 
\begin{eqnarray}
H=\frac{1}{\sqrt{2}}\left(z_{1}\frac{\partial }{\partial z_{1}}+z_{1}\frac{\partial }{\partial z_{2}}+z_{2}\frac{\partial }{\partial z_{1}}-z_{2}\frac{\partial }{\partial z_{2}}\right)
\end{eqnarray}
The phase gate $S$ is 
\begin{eqnarray}
	S=\left(z\frac{\partial }{\partial z}+ iw\frac{\partial }{\partial w}\right)
\end{eqnarray}

The rotation operators about $x$-axis, $y$-axis and $z$-axis are 
\begin{eqnarray}
	R_{x}(\theta)= \cos(\theta/2) z_{1} \frac{\partial }{\partial z_{1}}-i\sin(\theta/2) z_{1}\frac{\partial}{\partial z_{2}}\\ \nonumber -i\sin(\theta/2) z_{2} \frac{\partial}{\partial z_{1}}+\cos(\theta/2) z_{2}\frac{\partial}{\partial z_{2}},\\
	R_{y}(\theta)= \cos(\theta/2)z_{1}\frac{\partial}{\partial z_{1}}-\sin(\theta/2) z_{1}\frac{\partial}{\partial z_{2}}\\ \nonumber+ \sin(\theta/2)z_{2}\frac{\partial }{\partial z_{1}}+\cos(\theta/2) z_{2}\frac{\partial }{\partial z_{2}},\\
	R_{z}(\theta)= \exp(-i\theta/2)z_{1}\frac{\partial}{\partial z_{1}}+ \exp(i\theta/2) z_{2}\frac{\partial }{\partial z_{2}}
\end{eqnarray}
\vskip 5mm
The controlled-Not gate acts on analytic functions with four-variables,
it consists of an identity operator with respect to a two-variables  $z_{1},z_{2}$ and a Not
gate operator between the remaining two,
\begin{eqnarray}
	\mathrm{CNOT}=\left(z_{1}\frac{\partial}{\partial z_{1}}+z_{2}\frac{\partial }{\partial z_{2}}+z_{3}\frac{\partial}{\partial z_{4}}+z_{4}\frac{\partial }{\partial z_{3}}\right)
\end{eqnarray}
\vskip 5mm 
The swap , Toffoli and Fredkin gates are   
\begin{eqnarray}
	\mathrm{SWAP}=\left(z_{1}\frac{\partial }{\partial z_{1}}+z_{2}\frac{\partial }{\partial z_{3}}+z_{3}\frac{\partial}{\partial z_{2}}+z_{4}\frac{\partial }{\partial z_{4}}\right)
\end{eqnarray}


\begin{align}
	\mathrm{Toffoli}=\left(z_{1}\frac{\partial}{\partial z_{1}}+z_{2}\frac{\partial}{\partial z_{2}}+z_{3}\frac{\partial}{\partial z_{3}}+z_{4}\frac{\partial}{\partial z_{4}}+z_{5}\frac{\partial }{\partial z_{5}}+z_{6}\frac{\partial }{\partial z_{6}}+z_{7}\frac{\partial}{\partial z_{8}}+z_{8}\frac{\partial }{\partial z_{7}}\right)
\end{align}

 
\begin{align}
	\mathrm{Fredkin}=\left(z_{1}\frac{\partial}{\partial z_{1}}+z_{2}\frac{\partial }{\partial z_{2}}+z_{3}\frac{\partial }{\partial z_{3}}+z_{4} \frac{\partial }{\partial z_{4}}+ z_{5}\frac{\partial}{\partial z_{7}}+z_{7}\frac{\partial }{\partial z_{5}}+z_{8}\frac{\partial }{\partial z_{8}}\right)
\end{align}
Other possible logic gates can be written as complex differential operators in a way similar to the procedure we followed in writing the previous gates. If the input function is of the form \ref{normalized}, the outputs are again normalized states. The expectation values of $\langle n_{1},n_{2}|L|n_{1},n_{2}\rangle$, where the differential operator $L$ is any logic gate operator such as $X,Y,Z,H$ etc., and the inner product is taken over the Bargmann space, are identical to the expectation values of $\langle \psi | \hat{L}|\psi\rangle$ with a wave function $\psi$, gate operator $\hat{L}$ and an inner product taken over the vector Hilbert space. Moreover, considering the inputs to be any analytic functions is also possible. However, in this case, the normalization condition may be lost, but it could be recovered by dividing with a suitable normalization constant. Below, we give a general procedure for obtaining the differential and integral representations of logic gates in two-dimensional Bargmann space. \vskip 5mm
{\bf Differential operator representation of logic gates:}  \vskip 2mm
Let $M$ be any $2\times 2$ matrix in $\mathbb{C}^{2}$, the mapping to analytical form in Bargmann space is 
\begin{equation}
M= \begin{pmatrix}
a &b\\
c &d
\end{pmatrix}\rightarrow {\bf M}(z_{1},z_{2})= a\;z_{1}\frac{\partial}{\partial z_{1}}+ b\; z_{1} \frac{\partial }{\partial z_{2}} + c\; z_{2} \frac{\partial}{\partial z_{1}} + d\;  z_{2} \frac{\partial} {\partial z_{2}}
\end{equation}
where $a,b,c$ and $d \in \mathbb{C}$. \vskip 2mm 
Let $f(z_{1},z_{2})$ be an analytic function of two variables $z_{1}$ and $z_{2}$. The expansion of $f(z_{1},z_{2})$ is 
\begin{eqnarray}
f(z_{1},z_{2})=\sum_{nm=0}^{\infty} C_{nm} z_{1}^{n}z_{2}^{m}
\end{eqnarray}
where the coefficients $C_{nm}$ are given by 
\begin{eqnarray}
C_{nm}=\frac{1}{n!m!}f^{(n)}(0)f^{(m)}(0)
\end{eqnarray}
The inner product of $f(z_{1},z_{2})$ with itself is 
\begin{eqnarray}
\langle f(z_{1},z_{2})|f(z_{1},z_{2})\rangle = \sum_{n^{\prime}m^{\prime}=0}^{\infty} \sum_{nm=0}^{\infty}\;  C^{\star}_{n^{\prime}m^{\prime}}\; C_{nm}\;  n!\;  m!\;  \delta_{n^{\prime},n} \delta_{m^{\prime},m}
\end{eqnarray}
The action of ${\bf M}(z_{1}, z_{2})$ on $f(z_{1},z_{2})$ is 
\begin{align}
{\bf M}(z_{1},z_{2})f(z_{1},z_{2})= a \;n \;f(z_{1},z_{2})+ d\; m\; f(z_{1},z_{2})\\ \nonumber+ b \;m \; \sum_{nm}^{\infty} C_{nm} z_{1}^{n+1} z_{2}^{m-1} + c\; n \; \sum_{nm} z_{1}^{n-1} z_{2}^{m+1}
\end{align} 
The generalization of the above recipe to higher-order logic gates could  be done analogously in a straightforward manner. 
   \vskip 5mm 
{\bf Integral representation of logic gates:}\vskip 2mm 
Let $f(z)$ be an analytic function in simply-connected domain $D$, and let $\Gamma$ be positively-oriented loop in $D$. The integral representation of the derivative at point $z_{0}$ (any point in the interior of $\Gamma$) is \cite{Ahlfors}
\begin{eqnarray}
f^{(n)}(z_{0})=\frac{n!}{2\pi i}\oint_{\Gamma} \frac{f(z)}{(z-z_{0})^{n+1}}\; dz
\end{eqnarray}
which is known as the generalized Cauchy formula. Consequently, the integral representation of the $X$-gate for example reads 
\begin{eqnarray}
X f(z_{1},z_{2})= \frac{z_{1}}{2\pi i} \oint_{\Gamma_{2}} \frac{f(z_{1},\xi_{2})}{\xi_{2}-z_{2}} d\xi_{2}-\frac{z_{2}}{2\pi i} \oint_{\Gamma_{1}}\frac{f(\xi_{1},z_{2})}{\xi_{1}-z_{1}} d\xi_{1}, 
\end{eqnarray}
Similarly, the $Y,Z$ and $I$ gates are 
\begin{eqnarray}
	Y f(z_{1},z_{2})= -\frac{z_{1}}{2\pi } \oint_{\Gamma_{2}} \frac{f(z_{1},\xi_{2})}{\xi_{2}-z_{2}} d\xi_{2}+\frac{z_{2}}{2\pi } \oint_{\Gamma_{1}}\frac{f(\xi_{1},z_{2})}{\xi_{1}-z_{1}} d\xi_{1}, 
\end{eqnarray}
\begin{eqnarray}
	Z f(z_{1},z_{2})= \frac{z_{1}}{2\pi i} \oint_{\Gamma_{1}} \frac{f(\xi_{1},z_{2})}{\xi_{1}-z_{1}} d\xi_{1}-\frac{z_{2}}{2\pi i} \oint_{\Gamma_{2}}\frac{f(z_{1},\xi_{2})}{\xi_{2}-z_{2}} d\xi_{2}, 
\end{eqnarray}
\begin{eqnarray}
If(z_{1},z_{2})= \frac{z_{1}}{2\pi i} \oint_{\Gamma_{1}} \frac{f(\xi_{1},z_{2})}{\xi_{1}-z_{1}} d\xi_{1}+\frac{z_{2}}{2\pi i} \oint_{\Gamma_{2}}\frac{f(z_{1},\xi_{2})}{\xi_{2}-z_{2}} d\xi_{2}, 
\end{eqnarray}

	 \section{Models of Computation}
	  The computational model consists of a computing machine $M$ connected to an environment $E$. At each time $t$, we have input channel(s) $S(t)$ (for stimulus) and output channel(s) $R(t)$ (for response) \cite{Minsky}. To describe how the computing machine $M$ works, we need to specify the outputs as a function of the inputs. Since the transmission of signals requires some time, the output must be at a time later than the time of the input channel. We assume the machine response $R(r+1)$ because of  $S(t)$ to depend on the  state of the machine  $Q(t) $ \cite{Minsky}
	 \begin{eqnarray}\label{R}
	 	R(t+1)= F(Q(t),S(t))
	 \end{eqnarray}
 and the state of the machine $M$ depend on the stimulus $S(t)$ and the state of the machine at previous time, 
 \begin{eqnarray}\label{Q}
 	Q(t+1)= G(Q(t),S(t)). 
 \end{eqnarray}
 \subsection{Memristive systems}
The memristive systems are dynamical systems defined by \cite{Chua}
\begin{eqnarray}\label{memristive1}
	\dot{x}= f(x,u,t),\\
	y= g(x,u,t) u,\label{memristive2}
\end{eqnarray}
where $u$ and $y$ are the input and output of the system, and $x$ denotes the state of the system. The connection between \ref{memristive1}, \ref{memristive2} and \ref{R}, \ref{Q} is achieved by assigning $R(t+1)=y(t+1)$, $Q(t+1)=x(t+1)$, and $u=S(t)$. Therefore, for each value of $t$, we can realize the memristive system as a computational model.
\subsection{ Chain of harmonic oscillators}
 The harmonic oscillator satisfy a second-order differential equation of the form \cite{Pain}
 \begin{eqnarray}
 	\ddot{x}+ \omega^{2}x=0
 \end{eqnarray}
The general solution is  
\begin{eqnarray}
	x(t)= A\sin(\omega t)+B \cos(\omega t), 
\end{eqnarray} 
where $A$ and $B$ are constants. \\
A single harmonic oscillator does not define a computational model by itself, some interactions with the environment are needed to define a computational model. Consider a chain of $N$ identical harmonic oscillators as the machine $M$, the interaction of a single harmonic oscillator with other oscillators would affect the whole system. In other words, it provides some stimulus $S$ to the whole system, regardless of whether this stimulus is large or negligible. The response $R$ could be described as the changing of some measurable quantities in this chain due to the interaction with this single harmonic oscillator, such as the frequency modes, etc. The new displacement $x_{n}$ of the $n$th oscillator defines the new state of the system $Q$. It is sufficient to take just one oscillator within the chain and study its change in dynamics due to the added extra oscillator to show the connection between this system and the computational model described by equations \ref{R} and \ref{Q}. \vskip 5mm
Let $|{\bf f}\rangle=\left(|f_{1}\rangle,|f_{2}\rangle,\dots |f_{N}\rangle\right)$ be a set of analytic complex functions with several variables ( the stimulus $S$), and let $M ({\bf L})$ be a computing machine with ${\bf L}$ being a vector of complex differential operators. The computation process $\mathfrak{C}$ is described by the action of ${\bf L}$ on the inputs $|{\bf f}\rangle$
\begin{equation} 
\mathfrak{C}: |{\bf f}\rangle \rightarrow {\bf L}|{\bf f}\rangle, 
	\end{equation}
and the expectation values of the outputs (the response $R$) are 
\begin{eqnarray}
	\frac{\langle {\bf f }|{\bf L}|{\bf f}\rangle}{\sqrt{\langle {\bf f}|{\bf f}\rangle}}
\end{eqnarray}
where we divided the last expression by the normalization constant $\sqrt{\langle {\bf f}|{\bf f}\rangle}$ since the inputs are arbitrary complex functions.  If both the inputs and outputs are discrete and not correlated between themselves i.e. can not be written in superposition states like quantum states, then the computation is classical. Quantum computations are characterized by the possibility of having superposition states during the computation process.  The machine $M({\bf L})$ could be in principle any dynamical system from tiny particles to the universe as a whole. Any change in the dynamical degrees of freedom associated with $M$ is in principle due to the interaction of $M$ with the surrounding environment i.e. all possible inputs.  However, this change might be very slow and may not affect the macroscopic characteristics of the system immediately. It is worth mentioning that dynamical systems are not the materials or objects around us but rather any changing system such as stock prices, ecological models, and in principle any changing system described by a set of differential equations.   \vskip 5mm
% Figure environment removed

To quantify the computation process, we compute the change of entropy taking into account the fact that entropy associated with any physical processes is always increasing\cite{Shannon,Cover} 
\begin{eqnarray}
	\Delta S= S_{\mathrm{out}}-S_{\mathrm{in}}= -\sum_{i} p^{\mathrm{out}}_{i}\log p^{\mathrm{out}}_{i}+\sum_{i} p^{\mathrm{in}}_{i} \log p_{i}^{\mathrm{in}}\geq 0
\end{eqnarray}
where $p_{i}^{\mathrm{in}}= \frac{|f_{i}\rangle \langle f_{i}|}{\langle {\bf f}|{\bf f}\rangle} $ and $p^{\mathrm{out}}_{i}= \frac{|f^{\prime}_{i}\rangle \langle f^{\prime}_{i}|}{\langle {\bf f}^{\prime}|{\bf f}^{\prime}\rangle}$ with $|{\bf f}^{\prime}\rangle ={\bf L}|{\bf f}\rangle$. \vskip 5mm

The relative entropy (Kullback–Leibler divergence) is 
\begin{eqnarray}
	D(P|| Q)= \sum_{i}p_{i} \log(\frac{p_{i}}{q_{i}})= -\sum_{i} \frac{|f_{i}\rangle \langle f_{i}|}{\langle {\bf f}|{\bf f}\rangle }\log \frac{|g_{i}\rangle \langle g_{i}|}{\langle {\bf g}|{\bf g}\rangle }- S(p_{i})
\end{eqnarray}
	with $p_{i}=\frac{|f_{i}\rangle \langle f_{i}|}{\langle {\bf f}|{\bf f}\rangle}$, $q_{i}=\frac{|g_{i}\rangle \langle g_{i}|}{\langle {\bf g}|{\bf g}\rangle}$ and $S(p_{i})=-\sum_{i} p_{i}\log p_{i}$. Consequently, other quantities such as the mutual information can be determined in terms of holomorphic functions \cite{Cover}.


	 \section{Physical Systems } 
	 All physical systems process information. In this section, we study in some sort of detail the computation mechanisms in a few basic systems.  However, it is obvious that our construction works for all physical systems in nature. \vskip 3mm  
	 \subsection{ Coupled oscillators} Simple harmonic motion is omnipresent in many  mechanical and electrical systems. For example,  electrical circuits with inductance $L$ connected across a capacitance $C$ carrying charge $Q$ obey the equation  
	  \cite{Pain}
	  \begin{eqnarray}
	  	L \ddot{Q}+\frac{Q}{C}=0
	  \end{eqnarray}
  with frequency $\omega^{2}= \frac{1}{LC}$. \\
  The general equation of motion for any simple harmonic motion with $N$ oscillators reads,
  \begin{eqnarray}
  	\ddot{{\bf x}}+\mathbf{\omega}^{2} {\bf x}=0
  \end{eqnarray}
where ${\bf x}=\left(x_{1},x_{2},\dots ,x_{N}\right)$ is the $N$-dimensional state vector and $\omega$ is $N\times N$ frequency matrix. 
% Figure environment removed
To define the basic logic gates in such systems, one needs at least two coupled oscillators at each time step $t_{0}$ \footnote{On the contrary, one could apply the basic logic gates on a single quantum particle  due to the superposition property (which leads to the quantum entanglement) of these particles, which distinguishes quantum particles from classical ones. }. Consider two  identical pendulums, each having a mass $M$ suspended on a light rigid
rod of length $\ell$. The masses are connected by a light spring of stiffness $s$. The natural length of the spring is equal to the distance between the two masses at equilibrium.  The equation of motion are 
\begin{eqnarray}
M	\ddot{x}= -M g\;\frac{x}{\ell} - s\;(x-y), \\
M \ddot{y}=-M g\;\frac{y}{\ell}+ s\;(x-y).
\end{eqnarray}
The above set of equations could be written as 
\begin{eqnarray}\label{pendulum}
	\ddot{x} +\omega_{0}^{2}\;x = - \frac{s}{M}\;(x-y), \\ \label{pendulum1}
	\ddot{y}+ \omega_{0}^{2}\;y=\frac{s}{M}\;(x-y).
\end{eqnarray}
where $\omega_{0}=\sqrt{\frac{g}{l}}$ is the natural frequency of each pendulum. To solve \ref{pendulum} and \ref{pendulum1}, we introduce the normal coordinates 

\begin{eqnarray}
	X=x+y,\\
	Y= x-y. 
\end{eqnarray}
Then, we have the following set of equations 
\begin{eqnarray}\label{e1}
\ddot{X}+ \omega_{0}^{2} X=0,\\ \label{e2}
\ddot{Y}+ \left(\omega_{0}^{2}+ 2\frac{s}{M}\right)	Y=0. 
\end{eqnarray}
One possible solution to the above set of equations is
\begin{eqnarray}
X= A\sin(\omega_{0}t+\phi)= \alpha (z_{1}-\overline{z}_{1}),\\
Y= B\sin(\omega t+\varphi)=\beta (z_{2}- \overline{z}_{2}), 
\end{eqnarray}
where $z_{1}= e^{(i\omega_{0}t+\phi)}$, $z_{2}= e^{(i\omega t+\varphi)}$, and $\omega=\sqrt{\omega_{0}^{2}+ 2s/M}$. It is sufficient to take the complex part only during our study of the logic gates for coupled oscillators. The state function of the coupled oscillator is 
\begin{eqnarray}
	|f\rangle=f(z_{1},z_{2})= \alpha \beta\;  z_{1}z_{2}
\end{eqnarray}
The action of logic gates on this state function is 
\begin{eqnarray}
	Xf=\mathrm{NOT}f= \alpha\beta \left(z^{2}_{1}+z^{2}_{2}\right), \\
	Yf= -i \alpha \beta \left(z_{1}^{2}- z_{2}^{2}\right), \\
	Zf= \alpha \beta \left(z_{1}z_{2}-z_{2}z_{1}\right)=0,\\
	If= \alpha \beta \left(z_{1}z_{2}+z_{2}z_{1}\right)=2\; \alpha\;\beta \;f, 
\end{eqnarray}
where the factor 2 in the last equation can be absorbed safely choosing suitable normalization constant. The Hadamard gate is 
\begin{eqnarray}
	Hf= \frac{\alpha \; \beta }{\sqrt{2}} \left(z_{1}z_{2}+ z_{1}^{2}+ z_{2}^{2}- z_{2}z_{1}\right)=\frac{\alpha \; \beta }{\sqrt{2}}\left(z_{1}^{2}+ z_{2}^{2}\right)=\frac{1}{\sqrt{2}}Xf
\end{eqnarray} 
Note that since our state function is classical (product state), we were able to write the action of the Hadamard gates in the previous equation in terms of the action of the $X$ gate. The inner products $\langle f|X|f\rangle=\langle f|Y|f\rangle=\langle f|H|f\rangle=0$. If one considers a more general model of higher-order oscillations, one could write down the equations of motion \ref{e1},\ref{e2} as 
\begin{eqnarray}
\ddot{X}+ n^{2}\omega_{0}^{2} X=0,\\ 
\ddot{Y}+ m^{2} \omega^{2}	Y=0.
\end{eqnarray}
In this case, we may use the ansatz 
\begin{eqnarray}
	f(z_{1},z_{2})=\frac{z_{1}^{n}}{\sqrt{n!}}\frac{z^{m}_{2}}{\sqrt{m!}}
\end{eqnarray}
and the expectation values of the logic gates assume more general form. As an example, we find for the $X$ gate 
\begin{eqnarray}
	X|f\rangle= m \frac{z_{1}^{n+1}}{\sqrt{n!}} \frac{z_{2}^{m-1}}{\sqrt{m!}}+ n  \frac{z_{1}^{n-1}}{\sqrt{n!}} \frac{z_{2}^{m+1}}{\sqrt{m!}},\\
\langle f^{\prime}|X|f\rangle= m\; \delta_{n^{\prime},n+1}\delta_{m^{\prime},m-1}+n\; \delta_{m^{\prime},m+1}\delta_{n^{\prime},n-1}. 
\end{eqnarray} 
Similar relations could be found for other gates. 
 \subsection{Turing Patterns}
Turing Patterns are described by  diffusion-reaction equations \cite{Turingbio,patterns}
\begin{eqnarray}
	\frac{\partial a}{\partial t}= D_{a} \nabla^{2}a+ f(a,b),\label{tur1}\\
	\frac{\partial b}{\partial t}=D_{b} \nabla^{2}b+g(a,b)\label{tur2},
\end{eqnarray}
where $a$ and $b$ describes the concentrations of chemicals at time $t$. The functions $f(a,b)$ and $g(a,b)$ represent the reaction terms, and $D_{a},D_{b}$ are the diffusion coefficients.  One could for example write the reaction equations using the FitzHugh–Nagumo equation. In this case, $f(a,b)= a-a^{3}-b+\alpha$ and $g(a,b)= \beta (a-b)$ where $\alpha$ and $\beta$ are constants. Solving equations \ref{tur1} and \ref{tur2} we obtain the concentrations of chemicals as a function of position and time i.e. $\{a(x,t), b(x,t)\}$. Using the Segal-Bargmann transform, we may write the solutions in terms of holomorphic variables, 
\begin{eqnarray}
	\hat{a}(z_{1},t)= (\pi t)^{-d/4} \int_{\mathbb{R}^{d}} e^{\left(- z_{1}^{2}+2\sqrt{2}z_{1}\cdot x- x^{2}\right)/2t} a(x)\;dx,\\
	\hat{b}(z_{2},t)= (\pi t)^{-d/4} \int_{\mathbb{R}^{d}} e^{\left(-z_{2}^{2}+2\sqrt{2}z_{2}\cdot x-x^{2}\right)/2t} b(x)\;dx.
\end{eqnarray}
The state function of the system is 
\begin{eqnarray}
	f(z_{1},z_{2})= \hat{a}( z_{1},t)\hat{b}(z_{2},t)
\end{eqnarray}
which is a product state. Feeding the state function into logic circuit architectures built from complex differential operators defines the computational processes of the Turing patterns. 
 
\subsection{Neural Networks}
In this section, we describe the mechanism for incorporating the developed formalism into the study of neural networks. We will restrict our analysis to simple neural networks. However, the generalization to other types of nets such as convolutional neural networks is possible. The neuron $j$ may be described mathematically by a set of two equations \cite{Mcculloch,Rosenblatt,Hopfield,Haykin,deep,Almasri}, 
\begin{eqnarray}
	u_{j}= \sum_{i=1}^{N}\omega_{ji}x_{i}, \\
	y_{i}= f(u_{j}+b_{j}),
\end{eqnarray} 
where $\omega_{j1},\omega_{j2},\dots ,\omega_{jN}$ are the synaptic weights, $f$ is the activation function and $b_{k}$ is the bias. The inputs are
\begin{eqnarray}\label{inputs}
	x_{1}=\langle f_{1}|L_{1}|f_{1}\rangle, x_{2}= \langle f_{2}|L_{2}|f_{2}\rangle, \dots, x_{N}=\langle f_{N}|L_{N}|f_{N}\rangle.
\end{eqnarray} 
The outputs $y_{j}$ should be written as inner products in the Bargmann space similar to the inputs in \ref{inputs}. Now, following any neural computation algorithms for weights such as  perceptrons, backpropogations one could find the convergence  learning process with minimal loss functions. 
	\section{Universal Programming Language }
Programming languages are systems of expressions mostly text-based formal languages that allow users to communicate with the machine language \cite{Knuth}. The first question which could be asked is whether the universe uses one way for communication between its different sub-systems or each has its distinct way of communication. Logically, the universe must follow one general way for communications between the embedded sub-systems inside. This is because the laws of physics are universal and thus there is no way to include a sub-system inside the universe that works genuinely in a very different way. \\
The universal programming language (UPL) which I shall describe here is quite different from any other programming language known in the community. First, it is the hardware and software language so no need for compilers in our setups while other languages do require compilers such as Lisp and C programming languages \cite{lisp,c}. Second, its space of possibilities is very high. One could for complex systems in biophysics create many distinguish patterns and manipulate them. Below, we give the general procedure to find the computational properties of any machine (system).\vskip 5mm

\begin{itemize}
	\item Determine the state functions of the system's ingredients as a function of time. 
	\item If the state functions are defined by real variables, apply the Segal-Bargmann transform for each variable such that the final answer is written in terms of holomorphic variables. One could use any unitary integral transform from real variables onto holomorphic variables. 
	\item Determine the joint state functions of the system. 
	\item Apply all possible logic gates (differential operators) between the system's ingredients. 
	\item Lis all  produced patterns and classify them into classical and quantum patterns. 
	\item Compute the expectation values i.e. $\langle {\bf f}|{\bf L}|{\bf f}\rangle$, with suitable normalization conditions. 
	\item If the joint state function is not written in closed analytical form but rather in numerical approximated form. Repeat the previous procedures for other joint state functions at different time iterations.
	\item For sufficient time iterations, list all the produced patterns and select the distinguished patterns i.e. which corresponds to different expectation values in the Bargmann space. 
\end{itemize}
Obtaining such lists of computational patterns for each material is like cracking the DNA of life since it allows for designing novel ways for controlling and manipulating the properties of materials for efficient computing tasks.
	 
	 \section{Hierarchical Computing: The Concept of Layers}
The universe operates at different time scales from  elementary particles with quantum signatures to objects at cosmic scale such as galaxies, supernovas ...etc. The computations are performed first at the level of elementary particles (the basic ingredients of any material). The results of such computations affect the physical properties of atoms or molecules composed of these elementary particles. The computations at the atomic level is done at different layer with different time  scale that characterizes the physical processes of molecules. Analogously, the results of computations are sent to the next level with different time scale and larger ingredients. The first level is represented by a layer and it must be of a quantum nature where each fermion by itself represents an independent logic gate as we explained in previous sections. The last layer is the universe as a whole. Practically, we take the last layer to be the layer which contains the object under study with its surrounding environment. For example, if the object under study is of physical dimensions relative to humans size, then the layers structures starts at the quantum level of the object's ingredients and ends at the level of biosphere. \vskip 5mm 
Let $\mathcal{L}_{N}(t_{N})$, where $N=1,\dots N$,  denotes the layer of computation at time scale $t_{N}$. The total computation space is 
\begin{eqnarray}
	\mathcal{CS}: \mathcal{L}_{1}(t_{1})\otimes \mathcal{L}_{2}(t_{2})\otimes \dots \otimes  \mathcal{L}_{N}(t_{N})
\end{eqnarray}
{\bf Properties:} 1.   Each individual layer is Turing-complete \cite{Church,Turing}.\footnote{The Church-Turing states “Every effectively calculable function can be computed by a Turing-machine transducer.”} \\ 2. The space products of layers are time-ordered. Events at layer with time index $t_{N-1}$ happen before the events at layer with time index $t_{N}$. This supports the arrow of time since each computational process are associated with specific time and messages between layers are causal\cite{Zeh}.  
\vskip 5mm 
The concept of layers presents a model for hierarchal computing devices where the computations are performed at different time scales with distinguish physical properties. The case $N=1$ corresponds to one layer of computation and  we shall call it a primitive computational model. On  contrary, having large number of layers corresponds to advanced computational model such as the current universe. \vskip 5mm 
The hierarchal computing is a multilayer computational model. Each layer has distinct physical properties such as unique time scale. In this type of computing, layers are organized according to their time scale from short to long. The first layer, as we mentioned before, must be of quantum signature. The results of computations at layer $i$ affects the computations performed within layer $i+1$. Intuitively, multilayer computational models are associated with higher efficiency in comparison with single layer models. Similar situation is found in the study of multilayer neural networks in deep learning \cite{deep}. However, the situation in multilayer neural networks is different from the multilayer concept in hierarchal computing since all the computations of multilayer neural networks in deep learning are performed in one time scale and thus within the same layer in the hierarchal computing scheme. 
	 
	 
	
	 
	 \section{Conclusions}
	 We formulate the theory of computation in terms of holomorphic functions in the Bargmann space. This was done first by writing the quantum logic gates as complex differential operators that act on analytic functions. Classical logic gates are embedded in the quantum gates and may be recovered immediately considering the inputs to be of classical signature(no superposition states are allowed). Moreover, the current formalism enjoys great flexibility since it is connected with the theory of analytic functions.  Building on the developed formalism, the connection between materials or any physical system in the universe with computation is straightforward. We presented a recipe for constructing  universal programming language used by the universe alongside with the hierarchy computing scheme. Some physical examples are presented in the paper. We suggest a deep study of the formalism presented here in neural dynamics models such as  Hodgkin–Huxley and FitzHugh–Nagumo models\cite{Koch,neuron}. Moreover, building a correspondence between logic gates and the different oscillation states of  Belousov–Zhabotinsky reactions can be used for building non-conventional computing devices \cite{Kurmaoto}. 
	 	\section*{Acknowledgment } The author is grateful to Qatar University for its support during his stay as a visiting lecturer. 
	\begin{thebibliography}{99}
\bibitem{Zuse}
Zuse, K., 1969. \emph{Rechnender Raum} (Calculating Space). Friedrich Vieweg und Sohn, Braunschweig.
\bibitem{Landauer1}
Landauer, R., 1991. ``Information is Physical''. \emph{Physics Today} {\bf 44}, 5, 23.
	\bibitem{Landauer}
	Landauer, R., 1961. “Irreversibility and heat generation in the computing
	process”. \emph{IBM journal of research and development}, {\bf 5}(3), pp. 183–191.
	\bibitem{Feynman}
	Feynman, R.P., 1982. ``Simulating physics with computers''.  \emph{Int. J. Theor. Phys.} {\bf 21}, 467 (1982).
	\bibitem{Bennett}
	Bennett, C. H., 1982. “The thermodynamics of computation a review”. \emph{International Journal of Theoretical Physics}, {\bf 21}(12), pp. 905–940.
	
	\bibitem{Lloyd}
	Lloyd, S., 2000. "Ultimate physical limits to computation''. \emph{Nature} {\bf  406}(6799), 1047-1054
\bibitem{Parrondo}
Parrondo, J.M.R., 2022. " Thermodynamics of Information''. \emph{Encyclopedia of Condensed Matter Physics-2nd Edition}, edited by T. Chakraborty.
		\bibitem{waves}
		 de Broglie, L., 1924. `` Recherches sur la théorie des quanta''. Ph.D. thesis, University of Paris. 
	
			
		
		
		
		
		
	 
	 \bibitem{Winfree}
	 Winfree, A.T., 1980. \emph{The Geometry of Biological Time}. Springer-Verlag, New York.
	 \bibitem{Strogatz}
	  Strogatz, S., 2004. \emph{Sync: The Emerging Science of Spontaneous Order}. Penguin Adult.
	 
	 
	
		\bibitem{Hall}
		Hall, B.C., 1999. ``Holomorphic Methods in analysis and  Mathematical Physics''. \emph{	Contemporary Mathematics},  Volume 260, pp. 1-59
		\bibitem{almasri1}
		  AlMasri, M.W. and  Wahiddin M. R. B, 2022.  ``Bargmann representation of quantum absorption refrigerators'' . \emph{Rep. Math. Phys.} {\bf 89}(2), Pages 185-198
		\bibitem{almasri2}
		AlMasri, M.W. and  Wahiddin M. R. B, 2022. ``Quantum Decomposition Algorithm
		For Master Equations of Stochastic Processes: The Damped Spin Case''. \emph{Mod. Phys. Lett. A} {\bf 37} (32), 2250216
\bibitem{almasri3}
		AlMasri, M.W. and  Wahiddin M. R. B, 2023. `` Integral Transforms and PT-symmetric Hamiltonians''. Chinese Journal of Physics, volume {\bf 85}, Pages 127-134.
				\bibitem{Ahlfors}
			Ahlfors, L., 1979. \emph{Complex Analysis}.  McGraw-Hill Education; 3rd edition.  
		\bibitem{Hamming}
		R. W. Hamming, R.W., 1973.  \emph{Numerical Methods for Scientists and Engineers} 2nd edition,  Dover Publications. 
			\bibitem{Nielsen}
		Nielsen, M.A., and Chuang, I.L., 2001. \emph{Quantum Computation and Quantum Information}.  Cambridge University Press.
		\bibitem{Minsky}
		Minsky, M.L., 1967. \emph{Computation: Finite and Infinite Machines}. Prentice-Hall
\bibitem{Chua}
Chua, L.O., and Kang, S.M., 1976. ``Memristive devices and systems,'' \emph{ Proceedings of the IEEE}, {\bf 64}(2), 209-223
\bibitem{Pain}
Pain, J. H., 2005. \emph{The Physics of Vibrations and Waves}. Six edition, John Wiley \& Sons Ltd.
\bibitem{Shannon}
Shannon, C. E., 1948. ``A mathematical theory of communication''. The Bell system technical journal {\bf 27} (3), 379-423. 


\bibitem{Cover}
Thomas, J.A., and  Cover, T.M., 2006. \emph{Information Theory}.  second edition; John Wiley \& Sons.




 











\bibitem{Turingbio}
Turing, A. M., 1952. ``The Chemical Basis of Morphogenesis''. \emph{ Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences}, {\bf 237}
(641),  pages 37-72.
\bibitem{patterns}
 Vittadello, S.T., Leyshon, T.,
 Schnoerr, D., Stumpf, M.P.H., 2021. `` Turing pattern
 design principles and their robustness''. \emph{Phil.
 	Trans. R. Soc. A} {\bf 379}: 20200272. 
 
  
 

 

 \bibitem{Mcculloch}
 McCulloch, W.S., Pits, W., 1943.  ``A Logical Calculus of the Ideas Immanent in Nervous 
 Activity''. Bull. Math. Biophys. 5, 115–133  
 \bibitem{Rosenblatt}
 Rosenblatt, F., 1958.  ``The Perceptron: A Probabilistic Model for Information Storage 
 and Organization in the Brain''. Cornell Aeronautical Laboratory. Psychological 
 Review 65(6), 386–408 
 
  \bibitem{Hopfield}
 Hopfield, J.J., 1982. ``Neural networks and physical systems with emergent collective computational
 abilities''. \emph{Proceedings of the national academy of sciences}, {\bf 79}(8), pp.2554-2558. 
 
  \bibitem{Haykin}
  Haykin, S.S., 1999. \emph{Neural Networks: A Comprehensive Foundation}. Second Edition,  Pearson Education 
 
 

 \bibitem{deep}
 LeCun,Y., Bengio, Y.,  and Hinton, G., 2015.  ``Deep learning''.  \emph{Nature},  {\bf 521} ,p. 436–444 . 



\bibitem{Almasri}
AlMasri, M.W., 2023. ``Multi-Valued Quantum Neurons''. \texttt{arXiv:2305.02018 }
\bibitem{Knuth}
Knuth, D.E., 1997. \emph{The Art of Computer Programming }. Addison-Wesley 

\bibitem{lisp}
McCarthy, J., 1960.  ``Recursive Functions of Symbolic Expressions and their Computation by Machine, part I''. \emph{Communications of the ACM.} {\bf 3}(4) : 184–195. 
\bibitem{c}
Kernighan, B.W., and Ritchie, D.M, 1988. \emph{The C Programming Language}. Second edition, Bell Telephone Laboratories. 
  
\bibitem{Church}
Church, A., 1936. "An Unsolvable Problem of Elementary Number Theory." Amer. J. Math. 58, 345-363. 
\bibitem{Turing}
Turing, A.M., 1950. ``Computing Machinery and Intelligence''. \emph{ Mind}, Volume LIX, Issue {\bf 236}, Pages 433–460.
\bibitem{Zeh}
Dieter Zeh, H., 2007. \emph{The Physical Basis of The Direction of Time}. 4th edition, Springer Berlin, Heidelberg.
\bibitem{Koch}
Koch, C., 1999. \emph{Biophysics of Computation}. Oxford University Press
 \bibitem{neuron}
 Izhikevich,  E. M. , 2007. \emph{Dynamical Systems in Neuroscience:
 	The Geometry of Excitability and Bursting}. MIT Press  

\bibitem{Kurmaoto}
Kuramoto, Y., 1984. \emph{Chemical Oscillations, Waves, and Turbulence}. Springer-Verlag Berlin Heidelberg


 

	\end{thebibliography}
\end{document}
