\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[AB(2023)]{tobii}
T.~AB.
\newblock {T}obii {PCE}ye.
\newblock \url{https://us.tobiidynavox.com/pages/pceye}, 2023.

\bibitem[Abdrabou et~al.(2019)Abdrabou, Mostafa, Khamis, and
  Elmougy]{abdrabou2019calibration}
Y.~Abdrabou, M.~Mostafa, M.~Khamis, and A.~Elmougy.
\newblock Calibration-free text entry using smooth pursuit eye movements.
\newblock In \emph{Proceedings of the 11th ACM Symposium on Eye Tracking
  Research \& Applications}, pages 1--5, 2019.

\bibitem[Bhatti et~al.(2021)Bhatti, Barz, and Sonntag]{bhatti2021eyelogin}
O.~S. Bhatti, M.~Barz, and D.~Sonntag.
\newblock Eyelogin-calibration-free authentication method for public displays
  using eye gaze.
\newblock In \emph{ACM Symposium on Eye Tracking Research and Applications},
  pages 1--7, 2021.

\bibitem[Braun and Clarke(2006)]{braun2006using}
V.~Braun and V.~Clarke.
\newblock Using thematic analysis in psychology.
\newblock \emph{Qualitative research in psychology}, 3\penalty0 (2):\penalty0
  77--101, 2006.

\bibitem[Cerrolaza et~al.(2012)Cerrolaza, Villanueva, Villanueva, and
  Cabeza]{cerrolaza2012error}
J.~J. Cerrolaza, A.~Villanueva, M.~Villanueva, and R.~Cabeza.
\newblock Error characterization and compensation in eye tracking systems.
\newblock In \emph{Proceedings of the symposium on eye tracking research and
  applications}, pages 205--208, 2012.

\bibitem[Chen et~al.(2021)Chen, Acharya, Oulasvirta, and
  Howes]{chen2021adaptive}
X.~Chen, A.~Acharya, A.~Oulasvirta, and A.~Howes.
\newblock An adaptive model of gaze-based selection.
\newblock In \emph{Proceedings of the 2021 CHI Conference on Human Factors in
  Computing Systems}, pages 1--11, 2021.

\bibitem[Corporation(2018)]{wec}
M.~Corporation.
\newblock {W}indows {E}ye {C}ontrol.
\newblock
  \url{https://www.microsoft.com/en-us/garage/wall-of-fame/eye-control-windows-10/},
  2018.

\bibitem[Corporation(2021)]{gil}
M.~Corporation.
\newblock {MS} {G}aze {I}nteraction {L}ibrary.
\newblock
  \url{https://learn.microsoft.com/en-us/windows/communitytoolkit/gaze/gazeinteractionlibrary},
  2021.

\bibitem[Cui et~al.(2023)Cui, Liu, Li, Wang, Wang, Zhao, Rashidian, Baig,
  Ramakrishnan, Wang, et~al.]{cui2023glancewriter}
W.~Cui, R.~Liu, Z.~Li, Y.~Wang, A.~Wang, X.~Zhao, S.~Rashidian, F.~Baig,
  I.~Ramakrishnan, F.~Wang, et~al.
\newblock Glancewriter: Writing text by glancing over letters with gaze.
\newblock In \emph{Proceedings of the 2023 CHI Conference on Human Factors in
  Computing Systems}, pages 1--13, 2023.

\bibitem[Gao et~al.(2022)Gao, Reddy, Berseth, Hardy, Natraj, Ganguly, Dragan,
  and Levine]{gao2022x2t}
J.~Gao, S.~Reddy, G.~Berseth, N.~Hardy, N.~Natraj, K.~Ganguly, A.~D. Dragan,
  and S.~Levine.
\newblock X2t: Training an x-to-text typing interface with online learning from
  user feedback.
\newblock \emph{arXiv preprint arXiv:2203.02072}, 2022.

\bibitem[Harezlak et~al.(2014)Harezlak, Kasprowski, and
  Stasch]{harezlak2014towards}
K.~Harezlak, P.~Kasprowski, and M.~Stasch.
\newblock Towards accurate eye tracker calibration--methods and procedures.
\newblock \emph{Procedia Computer Science}, 35:\penalty0 1073--1081, 2014.

\bibitem[Hart and Staveland(1988)]{hart1988development}
S.~G. Hart and L.~E. Staveland.
\newblock Development of nasa-tlx (task load index): Results of empirical and
  theoretical research.
\newblock In \emph{Advances in psychology}, volume~52, pages 139--183.
  Elsevier, 1988.

\bibitem[Hiroe et~al.(2018)Hiroe, Yamamoto, and Nagamatsu]{hiroe2018implicit}
M.~Hiroe, M.~Yamamoto, and T.~Nagamatsu.
\newblock Implicit user calibration for gaze-tracking systems using an averaged
  saliency map around the optical axis of the eye.
\newblock In \emph{Proceedings of the 2018 ACM Symposium on Eye Tracking
  Research \& Applications}, pages 1--5, 2018.

\bibitem[Hiroe et~al.(2023)Hiroe, Yamamoto, and Nagamatsu]{hiroe2023implicit}
M.~Hiroe, M.~Yamamoto, and T.~Nagamatsu.
\newblock Implicit user calibration for gaze-tracking systems using saliency
  maps filtered by eye movements.
\newblock In \emph{Proceedings of the 2023 Symposium on Eye Tracking Research
  and Applications}, pages 1--5, 2023.

\bibitem[Holmqvist et~al.(2011)Holmqvist, Nystr{\"o}m, Andersson, Dewhurst,
  Jarodzka, and Van~de Weijer]{holmqvist2011eye}
K.~Holmqvist, M.~Nystr{\"o}m, R.~Andersson, R.~Dewhurst, H.~Jarodzka, and
  J.~Van~de Weijer.
\newblock \emph{Eye tracking: A comprehensive guide to methods and measures}.
\newblock OUP Oxford, 2011.

\bibitem[Hoshino et~al.(2020)Hoshino, Noguchi, and Nakai]{hoshino2020gaze}
K.~Hoshino, Y.~Noguchi, and Y.~Nakai.
\newblock Gaze estimation with easy calibration method.
\newblock In \emph{Proceedings of the 2020 5th International Conference on
  Intelligent Information Technology}, pages 102--106, 2020.

\bibitem[Jacob and Karn(2003)]{jacob2003eye}
R.~J. Jacob and K.~S. Karn.
\newblock Eye tracking in human-computer interaction and usability research:
  Ready to deliver the promises.
\newblock In \emph{The mind's eye}, pages 573--605. Elsevier, 2003.

\bibitem[Kasprowski and Harezlak(2016)]{kasprowski2016implicit}
P.~Kasprowski and K.~Harezlak.
\newblock Implicit calibration using predicted gaze targets.
\newblock In \emph{Proceedings of the ninth Biennial ACM symposium on eye
  tracking research \& applications}, pages 245--248, 2016.

\bibitem[Kasprowski and Harezlak(2018)]{kasprowski2018comparison}
P.~Kasprowski and K.~Harezlak.
\newblock Comparison of mapping algorithms for implicit calibration using
  probable fixation targets.
\newblock In \emph{Proceedings of the 2018 ACM Symposium on Eye Tracking
  Research \& Applications}, pages 1--8, 2018.

\bibitem[Kohlbecher et~al.(2008)Kohlbecher, Bardinst, Bartl, Schneider,
  Poitschke, and Ablassmeier]{kohlbecher2008calibration}
S.~Kohlbecher, S.~Bardinst, K.~Bartl, E.~Schneider, T.~Poitschke, and
  M.~Ablassmeier.
\newblock Calibration-free eye tracking by reconstruction of the pupil ellipse
  in 3d space.
\newblock In \emph{Proceedings of the 2008 symposium on Eye tracking research
  \& applications}, pages 135--138, 2008.

\bibitem[Lutz et~al.(2015)Lutz, Venjakob, and Ruff]{lutz2015smoovs}
O.~H.-M. Lutz, A.~C. Venjakob, and S.~Ruff.
\newblock Smoovs: Towards calibration-free text entry by gaze using smooth
  pursuit movements.
\newblock \emph{Journal of Eye Movement Research}, 8\penalty0 (1), 2015.

\bibitem[MacKenzie and Soukoreff(2002)]{mackenzie2002text}
I.~S. MacKenzie and R.~W. Soukoreff.
\newblock Text entry for mobile computing: Models and methods, theory and
  practice.
\newblock \emph{Human--Computer Interaction}, 17\penalty0 (2-3):\penalty0
  147--198, 2002.

\bibitem[Morimoto and Mimica(2005)]{morimoto2005eye}
C.~H. Morimoto and M.~R. Mimica.
\newblock Eye gaze tracking techniques for interactive applications.
\newblock \emph{Computer vision and image understanding}, 98\penalty0
  (1):\penalty0 4--24, 2005.

\bibitem[Mott et~al.(2017)Mott, Nancel, Kumar, Harrison, and
  Oulasvirta]{mott2017cascading}
M.~E. Mott, M.~Nancel, G.~L. Kumar, C.~Harrison, and A.~Oulasvirta.
\newblock Cascading gaze dwells: on the efficiency of bottom-up activation in
  gaze-based cascading menus.
\newblock In \emph{Proceedings of the 2017 CHI Conference on Human Factors in
  Computing Systems}, pages 5308--5319. ACM, 2017.

\bibitem[Ohno and Mukawa(2004)]{ohno2004free}
T.~Ohno and N.~Mukawa.
\newblock A free-head, simple calibration, gaze tracking system that enables
  gaze-based interaction.
\newblock In \emph{Proceedings of the 2004 symposium on Eye tracking research
  \& applications}, pages 115--122, 2004.

\bibitem[Pfeuffer et~al.(2013)Pfeuffer, Vidal, Turner, Bulling, and
  Gellersen]{pfeuffer2013pursuit}
K.~Pfeuffer, M.~Vidal, J.~Turner, A.~Bulling, and H.~Gellersen.
\newblock Pursuit calibration: Making gaze calibration less tedious and more
  flexible.
\newblock In \emph{Proceedings of the 26th annual ACM symposium on User
  interface software and technology}, pages 261--270, 2013.

\bibitem[Salvucci and Goldberg(2000)]{salvucci2000identifying}
D.~D. Salvucci and J.~H. Goldberg.
\newblock Identifying fixations and saccades in eye-tracking protocols.
\newblock In \emph{Proceedings of the 2000 symposium on Eye tracking research
  \& applications}, pages 71--78, 2000.

\bibitem[Saxena et~al.(2022)Saxena, Lange, and Fink]{saxena2022towards}
S.~Saxena, E.~Lange, and L.~Fink.
\newblock Towards efficient calibration for webcam eye-tracking in online
  experiments.
\newblock In \emph{2022 Symposium on Eye Tracking Research and Applications},
  pages 1--7, 2022.

\bibitem[Schenkluhn et~al.(2022)Schenkluhn, Peukert, and
  Weinhardt]{schenkluhn2022look}
M.~Schenkluhn, C.~Peukert, and C.~Weinhardt.
\newblock A look behind the curtain: Exploring the limits of gaze typing.
\newblock In \emph{NeuroIS Retreat}, pages 251--259. Springer, 2022.

\bibitem[{\v{S}}pakov et~al.(2018){\v{S}}pakov, Istance, Viitanen, Siirtola,
  and R{\"a}ih{\"a}]{vspakov2018enabling}
O.~{\v{S}}pakov, H.~Istance, T.~Viitanen, H.~Siirtola, and K.-J. R{\"a}ih{\"a}.
\newblock Enabling unsupervised eye tracker calibration by school children
  through games.
\newblock In \emph{Proceedings of the 2018 ACM Symposium on Eye Tracking
  Research \& Applications}, pages 1--9, 2018.

\bibitem[Sugano and Bulling(2015)]{sugano2015self}
Y.~Sugano and A.~Bulling.
\newblock Self-calibrating head-mounted eye trackers using egocentric visual
  saliency.
\newblock In \emph{Proceedings of the 28th Annual ACM Symposium on User
  Interface Software \& Technology}, pages 363--372, 2015.

\bibitem[Velichkovsky et~al.(1997)Velichkovsky, Sprenger, and
  Unema]{velichkovsky1997towards}
B.~Velichkovsky, A.~Sprenger, and P.~Unema.
\newblock Towards gaze-mediated interaction: Collecting solutions of the
  “midas touch problem”.
\newblock In \emph{Human-Computer Interaction INTERACT’97: IFIP TC13
  International Conference on Human-Computer Interaction, 14th--18th July 1997,
  Sydney, Australia}, pages 509--516. Springer, 1997.

\bibitem[Wang et~al.(2016)Wang, Wang, and Ji]{wang2016deep}
K.~Wang, S.~Wang, and Q.~Ji.
\newblock Deep eye fixation map learning for calibration-free eye gaze
  tracking.
\newblock In \emph{Proceedings of the ninth biennial ACM symposium on eye
  tracking research \& applications}, pages 47--55, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Kulkarni, and Morris]{zhang2017smartphone}
X.~Zhang, H.~Kulkarni, and M.~R. Morris.
\newblock Smartphone-based gaze gesture communication for people with motor
  disabilities.
\newblock In \emph{Proceedings of the 2017 CHI Conference on Human Factors in
  Computing Systems}, pages 2878--2889, 2017.

\end{thebibliography}
