\section{Introduction}

% Importance of eye tracking
Eye tracking technology has emerged as a valuable tool in a variety of applications, including accessibility, augmented reality (AR), virtual reality (VR), and gaming \citep{morimoto2005eye}. It has been particularly beneficial for individuals with motor impairments who rely on gaze-based input methods for communication and device control \citep{zhang2017smartphone, mott2017cascading}, including people with amyotrophic lateral sclerosis (ALS). In particular, gaze typing, a common use case of eye tracking, enables users to input text by looking at keys of an on-screen keyboard, thereby offering a hands-free and non-vocal method of communication.  
Beyond current applications, eye tracking technology has the potential to unlock additional interactions with the environments around us, for example by helping to better understand user attention and personalize displays accordingly. 


% Problems with callibration
Despite this potential, calibration difficulties remain a major barrier to use \citep{abdrabou2019calibration, kasprowski2018comparison, wang2016deep, bhatti2021eyelogin, kasprowski2016implicit, hiroe2023implicit}. Calibration is a process that establishes a relationship between the user's gaze and the corresponding screen coordinates (Fig. \ref{fig:calibration}). During calibration, the system typically guides the user through looking at a set of visual targets which enables an update to the internal model of the user's eye gaze. This process is time consuming and can be tedious and uncomfortable \citep{zhang2017smartphone}. 
Even after calibration, head movements, eye fatigue, changes in lighting and other environmental conditions, and hardware inconsistencies lead to miscalibration over time, which can significantly impact system performance \citep{jacob2003eye} and necessitate re-calibrations. This problem is further exacerbated for users with motor impairments who may have difficulty maintaining a stable head position or participating in traditional calibration procedures. 
Consequently, there is a need for calibration methods that are not only accurate but also adaptive to changes in the user and environment.


% Figure environment removed


% Problem of self correction.
Automatically detecting and correcting for miscalibration could address the calibration problem, but is confounded by users compensating for miscalibrations. 
For example, when typing on dwell-based visual keyboards, users may compensate and autocorrect for miscalibration in eye tracking software by purposefully glancing at adjacent keys to activate keys of interest. While such behavior adds additional cognitive load for users, it can enable them to type despite some miscalibration. Such behavior also confounds the detection of miscalibration from the user's gaze behavior, as the system continues to receive inputs that align with its (miscalibrated) expectations.

% Our approach.
In this work, we introduce a novel approach to seamlessly calibrate eye trackers. Our approach leverages a key novel insight about differences in gaze behavior during input (e.g. typing) versus output (e.g. reading): when providing system inputs through eye gaze (e.g. typing), users compensate for miscalibration to achieve desired system performance; in contrast, when users consume system outputs (e.g. by reading text they have typed) they do not compensate for miscalibration, thereby providing a signal for detecting the calibration offset (see Fig. \ref{fig:insight}). 
We demonstrate this approach through a novel autocalibrating gaze typing prototype \systemName{}, which tracks a user's reading behavior and compare their gaze to the location of typed characters on the screen to estimate the miscalibration amount and direction. \systemName{} aims to improve the gaze typing experience by seamlessly adjusting calibration in real-time, thereby reducing the need for manual recalibration and offering a more natural and efficient interaction. Our approach can potentially benefit a wide range of users, including those with motor impairments who use gaze keyboards for everyday communication and others who use gaze typing systems for extended periods, such as gamers and virtual/augmented reality headset users.


To explore the effectiveness of our approach, we used our \systemName{} prototype to run an in-lab user study with 20 participants and conduct a semi-structured interview with 6 ALS community stakeholders. 
Our user study results suggest that the proposed technique significantly reduces typing errors, improves typing speed, and enhances user satisfaction compared to a standard static calibration approach. Furthermore, feedback from our semi-structured interview suggests that the proposed technique can add value to users who frequently use gaze typing systems to communicate with their caregivers and the outside world, and shed light on desired future improvements. 


In summary, our primary contributions are:
\begin{enumerate}
    \item The novel insight that gaze behavior differs when used for input (when miscalibration compensation may occur) vs. output (when compensation does not occur), and that this difference can be leveraged to seamlessly improve calibration.
    \item A novel gaze tracking autocalibration prototype called \systemName{}, which leverages this difference between eye gaze as input vs. output to seamlessly correct for miscalibration.
    \item An exploration of \systemName's effectiveness through a user study and semi-structured interview with stakeholders. Our results suggest that \systemName{} can significantly improve typing efficiency and experience, and shed light on needs it meets and desired future improvements.
\end{enumerate}


