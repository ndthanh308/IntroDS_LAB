\section{User Study}
\label{sec:user-study}

To explore the effectiveness of our autocalibration technique and how it shapes a user's gaze typing experience, we ran an in-lab user study with IRB approval. We compared \systemName{} to a standard manual calibration control. 
After standard calibration, miscalibration were purposefully introduced to evaluate the typing experience of the user under such conditions.
Participants typed a set of 5 unique phrases each for different miscalibration  under the two gaze typing systems. The users were made aware that the system will have miscalibrations during the study, but were not made aware of any differences between the two systems. 

\subsection{Participants}

We recruited 20 participants (14 males, 6 females) aged 18-55 who were members of organizations the authors of this work were affiliated with. All participants sighted (i.e. they did not need glasses, or their vision was correctable with glasses) and did not report any eye conditions. Two wore corrective eye glasses during their respective session. Each session lasted around 60 minutes and the participants were reimbursed through purchased gifts. Two participants had prior experience in gaze typing. One participant found the typing experience very uncomfortable during the practice session and opted out of the study. We thus report results for 19 participants.

\subsection{System Setup}
Participants were seated comfortably at a distance of approximately $75$cm from a computer monitor and head movements were not restrained. Each participant engaged with two gaze typing systems: 1) \systemName, which leverages differences between reading and typing to autocalibrate, and 2) a control that relied on traditional calibration alone. Both systems shared the exact same gaze typing interface. The only difference was that \systemName{} contained an additional layer of Python software to detect and correct for miscalibration (described in Section \ref{sec:algo}). 
We used a desktop-based tracker (typically attached to the bottom of a computer screen), and in particular a head-pose free tracker, that let the user move their head within a certain range of locations and orientations. All manual calibrations were performed via the standard Tobii SDK 9-point calibration procedure (Fig. \ref{fig:calibration}).


\subsection{Procedure}
Participants were initially introduced to gaze typing and given a brief tutorial on how to use the on-screen keyboard. The experiment consisted of an initial calibration procedure, a practice round, and trials of both \systemName{} and the control (within-subjects study). The order of the \systemName{} and control phases was counterbalanced across participants. After using each system, users provided feedback about their experience with the system via the NASA TLX questionnaire \citep{hart1988development}. Users were free to abort a typing session if they found the setup too cumbersome to continue typing.

\subsubsection{Initial Calibration and Practice Session}
All participants first performed a manual calibration. Next, participants completed a practice round in which they typed a couple of simple phrases (`happy new year', `hello world') in the gaze typing application.

% Figure environment removed

\subsubsection{System Trial (x2)}
\label{sec:trial}
For each system (\systemName{} and Control), participants first completed a manual calibration and were then asked to type 5 different phrases (1 per session). 
At the start of each of the 5 sessions, we altered the calibration of the tracker by a fixed amount of 0 (no miscalibration) or +75, -75 pixels in the x-direction, or +75, -75 pixels in the y-direction (counterbalanced order between sessions). Errors were introduced independently in the x and y directions to better isolate the impact of compensation in the two directions. This design decision was made because we learned via a pilot study that some users are more comfortable compensating in one direction versus the other. Additionally, we also learned from the pilot study the average amount of miscalibration users could work with (by compensating). The induced miscalibrations affected the entire screen uniformly.  

\subsubsection{Overall Preferences} 
\label{sec:interview}
To better understand if \systemName{} led to a more positive user experience over the control system, we asked participants to rate each system in terms of the mental workload required (right after typing 5 phrases with it) using the NASA TLX questionnaire \citep{hart1988development}. At the end of the study, we also asked them to share their opinions in written form about how they compared their experience of gaze typing between the two systems, and if they preferred one system over the other. 


\subsection{Typed Phrases}
\label{subsec:phrases}

The phrases that participants typed were randomly selected from a standard corpus to evaluate text entry systems \citep{mackenzie2002text}, representing a diverse range of words and character combinations. No two phrases were repeated across sessions for the same participant or across sessions for different participants.

\subsection{Metrics}
\label{sec:metrics}
To assess the effectiveness of \systemName{} autocalibration to ease the task of gaze typing and it's impact on user experience, we compared typing efficiency in terms of typing speed (characters per minute), number of backspaces, and abort frequency (number of sessions where the user gave up typing the phrase) as quantitative metrics. For quantitative subjective feedback, we compare NASA TLX \citep{hart1988development} responses and user preferences between the control and the \systemName{} typing systems. A two-sided t-test was performed to determine the significance of any observed differences. We also study qualitative subjective feedback from open-ended responses.