\section{System Setup}
\label{sec:interface}


% Figure environment removed





Our experimental setup consists of both hardware and software components to effectively evaluate the performance of the proposed autocalibration technique with real users. We utilized a Tobii PCEye eye tracker, with a sampling rate of 60 Hz, connected to a standard Windows laptop via USB. The eye tracker tracked gaze data directed towards a 24-inch screen that displayed an on-screen visual keyboard (Fig. \ref{fig:activation}). 
The keyboard was designed as part of an UWP application built on top of the Microsoft Gaze Interaction Library \citep{gil}. The application was written using the Tobii Pro SDK (designed to offer access to gaze data from Tobii eye trackers) in C\#. It facilitates the capture and processing of x, y coordinates from the eye tracker, providing necessary data for our autocalibration technique.
The software for our autocalibrated gaze typing technique was developed in Python, which received the 2D gaze coordinates in real-time from the UWP application via Google's remote procedure call (RPC) protocol. This allowed Python scripts to access gaze data, analyze it, and apply the necessary miscalibration corrections which could be displayed back on the visual keyboard application. 

% Figure environment removed

The customized gaze typing application is functionally similar to visual keyboards available as part of standard software such as Windows Eye Control. However, it serves as a test bed with more control to process and update the miscalibrated gaze coordinates in real-time. Figure \ref{fig:activation} illustrates the mechanism for typing a character on the visual keyboard through eye gaze. A user's detected gaze location is displayed as a red dot on the screen. The user can direct their gaze at a desired character for typing. If they fixate on a key for $50$ ms, a dwell timer of $400$ms is initiated by the system. The start of the timer is depicted by a green rectangle on the key of interest (Fig. \ref{fig:activation}(a)). If the user continues to look at the same key, the rectangle slowly changes size and decreases in area over time, eventually collapsing at the center of the key (Fig. \ref{fig:activation}(b)). Otherwise, the timer is aborted and the user must fixate and dwell again to type any character subsequently. The dwell timer is a mechanism to ensure that a user is intentionally willing to type that specific character. Once the timer is completed, the user receives visual feedback (the key turns red as shown in Fig. \ref{fig:activation}(c)) that the character is typed on the text box at the top of the screen. The eye tracker can be calibrated via a standard Tobii software available with the purchase of the tracker (Fig.\ref{fig:calibration}). It uses a procedure of following at a set of dots (in sequence) on the screen that, and then return to controlling an application of interest with their calibrated gaze.