@article{1998_SGD,
  title={Online algorithms and stochastic approximations},
  author={Saad, David},
  journal={Online Learning},
  volume={5},
  pages={6--3},
  year={1998},
  publisher={Cambridge Univ. Press}
}
@article{1998_NaturalGrad,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}
@article{2014_arXiv_Adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{2011_JMLR_AdaGrad,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}
@article{2012_RMSProp,
  title={Lecture 6.5-rmsprop, coursera: Neural networks for machine learning},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={University of Toronto, Technical Report},
  year={2012}
}
@inproceedings{2016_CVPR_ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{2015_ICML_KFAC,
  title={Optimizing neural networks with kronecker-factored approximate curvature},
  author={Martens, James and Grosse, Roger},
  booktitle={International conference on machine learning},
  pages={2408--2417},
  year={2015},
  organization={PMLR}
}
@inproceedings{2016_ICLR_distKFAC,
  title={Distributed second-order optimization using Kronecker-factored approximations},
  author={Ba, Jimmy and Grosse, Roger and Martens, James},
  booktitle={International Conference on Learning Representations},
  year={2017}
}
@inproceedings{2020_SC_KFAC,
	author = {Pauloski, J. Gregory and Zhang, Zhao and Huang, Lei and Xu, Weijia and Foster, Ian T.},
	title = {Convolutional {N}eural {N}etwork {T}raining with {D}istributed {K}-{FAC}},
	year = {2020},
	isbn = {9781728199986},
	publisher = {IEEE Press},
	booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
	articleno = {94},
	numpages = {14},
	location = {Atlanta, Georgia},
	series = {SC '20},
	doi = {10.5555/3433701.3433826}
}
@article{1980_LBFGS,
  title={Updating quasi-Newton matrices with limited storage},
  author={Nocedal, Jorge},
  journal={Mathematics of computation},
  volume={35},
  number={151},
  pages={773--782},
  year={1980}
}
@book{BFGS,
  title={Practical methods of optimization},
  author={Fletcher, Roger},
  year={2013},
  publisher={John Wiley \& Sons}
}
@article{2015_JMLR_LBFGS,
  title={Global convergence of online limited memory BFGS},
  author={Mokhtari, Aryan and Ribeiro, Alejandro},
  journal={The Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={3151--3181},
  year={2015},
  publisher={JMLR. org}
}

@inproceedings{2016_PMLR_LBFGS,
  title={A linearly-convergent stochastic L-BFGS algorithm},
  author={Moritz, Philipp and Nishihara, Robert and Jordan, Michael},
  booktitle={Artificial Intelligence and Statistics},
  pages={249--258},
  year={2016},
  organization={PMLR}
}

@inproceedings{2016_ICML_BlockBFGS,
  title={Stochastic block BFGS: Squeezing more curvature out of data},
  author={Gower, Robert and Goldfarb, Donald and Richt{\'a}rik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={1869--1878},
  year={2016},
  organization={PMLR}
}

@article{2017_stochastic_QN,
  title={Stochastic quasi-Newton methods for nonconvex stochastic optimization},
  author={Wang, Xiao and Ma, Shiqian and Goldfarb, Donald and Liu, Wei},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={2},
  pages={927--956},
  year={2017},
  publisher={SIAM}
}

@article{2018_SIAM_BFGS,
  title={Block BFGS methods},
  author={Gao, Wenbo and Goldfarb, Donald},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1205--1231},
  year={2018},
  publisher={SIAM}
}
@inproceedings{2007_PMLR_onlineLBFGS,
  title={A stochastic quasi-Newton method for online convex optimization},
  author={Schraudolph, Nicol N and Yu, Jin and G{\"u}nter, Simon},
  booktitle={Artificial intelligence and statistics},
  pages={436--443},
  year={2007},
  organization={PMLR}
}

@article{2020_NIPS_KFAC-LBFGS,
  title={Practical quasi-Newton methods for training deep neural networks},
  author={Goldfarb, Donald and Ren, Yi and Bahamou, Achraf},
  journal={arXiv preprint arXiv:2006.08877},
  year={2020}
}
@article{2021_SIAM_Superlinear,
  title={Greedy quasi-Newton methods with explicit superlinear convergence},
  author={Rodomanov, Anton and Nesterov, Yurii},
  journal={SIAM Journal on Optimization},
  volume={31},
  number={1},
  pages={785--811},
  year={2021},
  publisher={SIAM}
}
@article{2019_OMS_Superlinear,
  title={Quasi-Newton methods: superlinear convergence without line searches for self-concordant functions},
  author={Gao, Wenbo and Goldfarb, Donald},
  journal={Optimization Methods and Software},
  volume={34},
  number={1},
  pages={194--217},
  year={2019},
  publisher={Taylor \& Francis}
}
@article{2018_GPT,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}
@article{2018_BERT,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@inproceedings{2009_CVPR_ImageNet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
@article{PyTorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={arXiv preprint arXiv:1912.01703},
  year={2019}
}
@article{cifar10,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}
@inproceedings{flower102,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
  pages={722--729},
  year={2008},
  organization={IEEE}
}
@inproceedings{Hessianfree,
  title={Deep learning via hessian-free optimization.},
  author={Martens, James},
  booktitle={ICML},
  volume={27},
  pages={735--742},
  year={2010}
}
@book{ConjugateGrad,
  title={Methods of conjugate gradients for solving linear systems},
  author={Hestenes, Magnus Rudolph and Stiefel, Eduard and others},
  volume={49},
  number={1},
  year={1952},
  publisher={NBS Washington, DC}
}

@article{dosovitskiy2020vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{goldfarb2020practical,
  title={Practical quasi-Newton methods for training deep neural networks},
  author={Goldfarb, Donald and Ren, Yi and Bahamou, Achraf},
  journal={arXiv preprint arXiv:2006.08877},
  year={2020}
}

@article{liu1989limited,
  title={On the limited memory BFGS method for large scale optimization},
  author={Liu, Dong C and Nocedal, Jorge},
  journal={Mathematical programming},
  volume={45},
  number={1},
  pages={503--528},
  year={1989},
  publisher={Springer}
}
@article{PL,
  title={Gradient methods for minimizing functionals},
  author={Polyak, Boris Teodorovich},
  journal={Zhurnal vychislitel'noi matematiki i matematicheskoi fiziki},
  volume={3},
  number={4},
  pages={643--653},
  year={1963},
  publisher={Russian Academy of Sciences, Branch of Mathematical Sciences}
}
@article{MadGrad,
  title={Adaptivity without compromise: a momentumized, adaptive, dual averaged gradient method for stochastic optimization},
  author={Defazio, Aaron and Jelassi, Samy},
  journal={arXiv preprint arXiv:2101.11075},
  year={2021}
}
@book{convexOpt,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2003},
  publisher={Springer Science \& Business Media}
}
@inproceedings{interpolation,
  title={The power of interpolation: Understanding the effectiveness of SGD in modern over-parametrized learning},
  author={Ma, Siyuan and Bassily, Raef and Belkin, Mikhail},
  booktitle={International Conference on Machine Learning},
  pages={3325--3334},
  year={2018},
  organization={PMLR}
}
@article{ViT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@inproceedings{ZeRO,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}

@article{gradreg,
  title={On the origin of implicit regularization in stochastic gradient descent},
  author={Smith, Samuel L and Dherin, Benoit and Barrett, David GT and De, Soham},
  journal={arXiv preprint arXiv:2101.12176},
  year={2021}
}
@article{sLBFGS,
  title={An accelerated linearly convergent stochastic L-BFGS algorithm},
  author={Chang, Daqing and Sun, Shiliang and Zhang, Changshui},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={11},
  pages={3338--3346},
  year={2019},
  publisher={IEEE}
}
@article{BFGStool,
  title={A tool for the analysis of quasi-Newton methods with application to unconstrained minimization},
  author={Byrd, Richard H and Nocedal, Jorge},
  journal={SIAM Journal on Numerical Analysis},
  volume={26},
  number={3},
  pages={727--739},
  year={1989},
  publisher={SIAM}
}
@article{AdaDelta,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}
@inproceedings{Shampoo,
  title={Shampoo: Preconditioned stochastic tensor optimization},
  author={Gupta, Vineet and Koren, Tomer and Singer, Yoram},
  booktitle={International Conference on Machine Learning},
  pages={1842--1850},
  year={2018},
  organization={PMLR}
}
@article{VITE,
  title={A variance reduced stochastic Newton method},
  author={Lucchi, Aurelien and McWilliams, Brian and Hofmann, Thomas},
  journal={arXiv preprint arXiv:1503.08316},
  year={2015}
}
@article{dampedBFGS,
  title={Damped techniques for the limited memory BFGS method for large-scale optimization},
  author={Al-Baali, Mehiddin and Grandinetti, Lucio and Pisacane, Ornella},
  journal={Journal of Optimization Theory and Applications},
  volume={161},
  number={2},
  pages={688--699},
  year={2014},
  publisher={Springer}
}
@article{improvedDamping,
  title={Improved damped quasi--Newton methods for unconstrained optimization},
  author={Al-Baali, Mehiddin and Grandinetti, Lucio},
  journal={Pacific Journal of Optimization (To appear)},
  year={2017}
}
@inproceedings{DeiT,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International conference on machine learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}